<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 11 Jul 2024 22:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[WebVM is a server-less virtual Linux environment running client-side (150 pts)]]></title>
            <link>https://webvm.io/</link>
            <guid>40940225</guid>
            <pubDate>Thu, 11 Jul 2024 20:16:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://webvm.io/">https://webvm.io/</a>, See on <a href="https://news.ycombinator.com/item?id=40940225">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="loginLink">
                    <p><span id="networkStatus">Connect via Tailscale </span>
	              <span id="ipCopied">Copied! </span>
                    </p>
	            <p><img src="https://webvm.io/assets/tailscale.svg" height="35px">
		  </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Karpathy: Let's reproduce GPT-2 (1.6B): one 8XH100 node 24h $672 in llm.c (153 pts)]]></title>
            <link>https://github.com/karpathy/llm.c/discussions/677</link>
            <guid>40939707</guid>
            <pubDate>Thu, 11 Jul 2024 19:21:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/karpathy/llm.c/discussions/677">https://github.com/karpathy/llm.c/discussions/677</a>, See on <a href="https://news.ycombinator.com/item?id=40939707">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="presentation" data-paste-markdown-skip="">
    <tbody data-target-translation-id="6923990" data-target-translation-type="discussion">
        <tr>
    <td>
        <p dir="auto">In this post we are reproducing GPT-2 in llm.c. This is <strong>"the GPT-2"</strong>, the full, 1558M parameter version that was introduced in OpenAI's blog post <a href="https://openai.com/index/better-language-models/" rel="nofollow">Better Language Models and their Implications</a> in February 14, 2019. llm.c does so directly in C/CUDA (total of ~5,000 lines of code), without the typical training stack that would involve the Python interpreter and a significantly more complex deep learning library like PyTorch/JAX, huggingface/transformers, or etc. In 2019, training GPT-2 was an involved project from an entire team and considered a big model run but, ~5 years later, due to improvements in compute (H100 GPUs), software (CUDA, cuBLAS, cuDNN, FlashAttention) and data (e.g. the FineWeb-Edu dataset), we can reproduce this model on a single 8XH100 node in 24 hours, and for $672, which is quite incredible. There are some caveats and asterisks involved though - llm.c is still not perfectly tuned, sufficiently stabilized (we still see loss spikes and bad activation ranges now and then), and our evals are not comprehensive (e.g. we do not carefully eval multilingual, code, math); A lot of this work is still ongoing.</p>
<p dir="auto"><strong>Unicorns</strong>. The natural place to start is probably with unicorns. In the GPT-2 blog post, OpenAI prompted GPT-2 with this unicorn prompt. Let's see what our model thinks about English-speaking unicorns in the Andes mountains:</p>
<p dir="auto"><strong>Prompt</strong>: <em>In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.</em><br>
<strong>Completion</strong>: <em>It may sound like a hoax, or just a dream of the mythical animals, but it appears this may be a real case of the unicorn language. The Andean area has an abundance of minerals and is also very rich in biodiversity. According to the researchers' study, the unicorns' language is called Elveseo. To produce it, the animal forms a consonant from the lips and makes a vowel sound with the teeth, then produces a consonant sound with the mouth and makes an 'ow' sound from its chest. "The question is, what caused this, and what does this tell us about intelligence and communication?" commented study co-author Paul Marek. Speaking in the video, the unicorns had the right way to speak, the animals were able to communicate and talk in perfect English.</em></p>
<p dir="auto">Fun! :) The model is fairly coherent and qualitatively somewhere around the level of GPT-2. You can find 20 samples from both GPT-2 and the llm.c model <a href="http://llmc.s3-us-west-2.amazonaws.com/html/gpt2_vs_llmc30kedu.html" rel="nofollow">here</a>, or generate many more using instructions down below.</p>
<p dir="auto"><strong>Training</strong>. Training a GPT-2 with llm.c is quite simple because it is written in C/CUDA, so there is no need for minconda, Python, PyTorch, etc. You will want an 8XH100 GPU box, I recommend spinning one up from <a href="https://lambdalabs.com/" rel="nofollow">Lambda labs</a>. But llm.c is flexible on its compute - if you have only 1 GPU you can still get your GPT-2, you'll just have to wait 8 days instead of 1. If you have 16 GPUs (e.g. using the new Lambda 1 Click Clusters), you'll be able to train multinode and only have to wait 12 hours. Once you spin up your node, here are the complete instructions to train your GPT-2 (this only takes a ~minute from blank box to start stepping):</p>
<div dir="auto" data-snippet-clipboard-copy-content="# install cudnn so we can use FlashAttention and run fast (optional)
# https://developer.nvidia.com/cudnn-downloads
# for me, CUDA 12 (run `nvcc --version`) running on Linux x86_64 Ubuntu 22.04
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
sudo apt-get update
sudo apt-get -y install libcudnn9-dev-cuda-12

# &quot;install&quot; cudnn-frontend to ~/
git clone https://github.com/NVIDIA/cudnn-frontend.git

# install MPI (optional, if you intend to use multiple GPUs)
# (you might also have to install NVIDIA NCCL if it doesn't come with your setup)
sudo apt -y install openmpi-bin openmpi-doc libopenmpi-dev

# download and enter llm.c repo
git clone https://github.com/karpathy/llm.c.git
cd llm.c

# download the &quot;starter pack&quot; (~1GB download)
# contains GPT2-124M weights (used in tests), tokenizer, eval data .bin s
./dev/download_starter_pack.sh

# download the training dataset (FineWeb-Edu 100B token) .bin data shards
# note: this is a total of 1001 data shards. If you only want to test things
# out and don't want to do an actual run, feel free to append the number of
# training shards to download (e.g. for just 10 shards: ./edu_fineweb.sh 10)
# the full dataset is ~200GB, we can store it here in dev/data directory.
cd dev/data
./edu_fineweb.sh

# compile (~1 min 1st time for cuDNN mostly, few sec from then on)
cd ../../
make train_gpt2cu USE_CUDNN=1

# and train! (wait 24 hours here)
mpirun -np 8 ./train_gpt2cu \
	-i &quot;dev/data/edu_fineweb100B/edu_fineweb_train_*.bin&quot; \
	-j &quot;dev/data/edu_fineweb100B/edu_fineweb_val_*.bin&quot; \
	-o &quot;log_gpt2_1558M&quot; \
	-v 250 -s 300000 -g 384 \
	-h 1 \
	-b 16 -t 1024 \
	-d 1048576 \
	-r 0 \
	-z 1 \
	-c 0.1 \
	-k &quot;cosine&quot; \
	-l 0.0006 \
	-q 0.1 \
	-u 700 \
	-n 2000 \
	-x 32000 \
	-ge 1 \
	-y 1 \
	-e &quot;d48&quot;"><pre><span><span>#</span> install cudnn so we can use FlashAttention and run fast (optional)</span>
<span><span>#</span> https://developer.nvidia.com/cudnn-downloads</span>
<span><span>#</span> for me, CUDA 12 (run `nvcc --version`) running on Linux x86_64 Ubuntu 22.04</span>
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
sudo apt-get update
sudo apt-get -y install libcudnn9-dev-cuda-12

<span><span>#</span> "install" cudnn-frontend to ~/</span>
git clone https://github.com/NVIDIA/cudnn-frontend.git

<span><span>#</span> install MPI (optional, if you intend to use multiple GPUs)</span>
<span><span>#</span> (you might also have to install NVIDIA NCCL if it doesn't come with your setup)</span>
sudo apt -y install openmpi-bin openmpi-doc libopenmpi-dev

<span><span>#</span> download and enter llm.c repo</span>
git clone https://github.com/karpathy/llm.c.git
<span>cd</span> llm.c

<span><span>#</span> download the "starter pack" (~1GB download)</span>
<span><span>#</span> contains GPT2-124M weights (used in tests), tokenizer, eval data .bin s</span>
./dev/download_starter_pack.sh

<span><span>#</span> download the training dataset (FineWeb-Edu 100B token) .bin data shards</span>
<span><span>#</span> note: this is a total of 1001 data shards. If you only want to test things</span>
<span><span>#</span> out and don't want to do an actual run, feel free to append the number of</span>
<span><span>#</span> training shards to download (e.g. for just 10 shards: ./edu_fineweb.sh 10)</span>
<span><span>#</span> the full dataset is ~200GB, we can store it here in dev/data directory.</span>
<span>cd</span> dev/data
./edu_fineweb.sh

<span><span>#</span> compile (~1 min 1st time for cuDNN mostly, few sec from then on)</span>
<span>cd</span> ../../
make train_gpt2cu USE_CUDNN=1

<span><span>#</span> and train! (wait 24 hours here)</span>
mpirun -np 8 ./train_gpt2cu \
	-i <span><span>"</span>dev/data/edu_fineweb100B/edu_fineweb_train_*.bin<span>"</span></span> \
	-j <span><span>"</span>dev/data/edu_fineweb100B/edu_fineweb_val_*.bin<span>"</span></span> \
	-o <span><span>"</span>log_gpt2_1558M<span>"</span></span> \
	-v 250 -s 300000 -g 384 \
	-h 1 \
	-b 16 -t 1024 \
	-d 1048576 \
	-r 0 \
	-z 1 \
	-c 0.1 \
	-k <span><span>"</span>cosine<span>"</span></span> \
	-l 0.0006 \
	-q 0.1 \
	-u 700 \
	-n 2000 \
	-x 32000 \
	-ge 1 \
	-y 1 \
	-e <span><span>"</span>d48<span>"</span></span></pre></div>
<p dir="auto">I will describe the args in a second. You'll see a bunch of prints scroll through and then the optimization will begin:</p>
<div data-snippet-clipboard-copy-content="num_parameters: 1557686400 => bytes: 3115372800
allocated 2971 MiB for model parameters
batch_size B=16 * seq_len T=1024 * num_processes=8 and total_batch_size=1048576
=> setting grad_accum_steps=8
created directory: log_gpt2_1558M
allocating 40409 MiB for activations
val loss 11.129390
allocating 2971 MiB for parameter gradients
allocating 742 MiB for AdamW optimizer state m
allocating 742 MiB for AdamW optimizer state v
allocating 742 MiB for master copy of params
step    1/32000 | loss 11.133732 (+nanz)| norm 52.9732 (+nanz)| lr 8.57e-07 | 3056.36 ms | 42.6% bf16 MFU | 343080 tok/s
step    2/32000 | loss 10.539388 (+nanz)| norm 43.5996 (+nanz)| lr 1.71e-06 | 2747.19 ms | 47.4% bf16 MFU | 381690 tok/s
step    3/32000 | loss 9.894109 (+nanz)| norm 23.2229 (+nanz)| lr 2.57e-06 | 2753.25 ms | 47.3% bf16 MFU | 381259 tok/s
step    4/32000 | loss 9.566241 (+nanz)| norm 28.4920 (+nanz)| lr 3.43e-06 | 2741.47 ms | 47.5% bf16 MFU | 381690 tok/s
step    5/32000 | loss 9.482848 (+nanz)| norm 23.7817 (+nanz)| lr 4.29e-06 | 2752.07 ms | 47.3% bf16 MFU | 381507 tok/s
step    6/32000 | loss 9.332832 (+nanz)| norm 15.9113 (+nanz)| lr 5.14e-06 | 2751.01 ms | 47.3% bf16 MFU | 381431 tok/s
step    7/32000 | loss 9.165650 (+nanz)| norm 10.5941 (+nanz)| lr 6.00e-06 | 2753.03 ms | 47.3% bf16 MFU | 381327 tok/s
step    8/32000 | loss 9.132234 (+nanz)| norm 16.2733 (+nanz)| lr 6.86e-06 | 2748.91 ms | 47.3% bf16 MFU | 381348 tok/s
step    9/32000 | loss 9.097384 (+nanz)| norm 12.1342 (+nanz)| lr 7.71e-06 | 2748.73 ms | 47.3% bf16 MFU | 381367 tok/s
step   10/32000 | loss 9.072879 (+nanz)| norm 10.5923 (+nanz)| lr 8.57e-06 | 2749.40 ms | 47.3% bf16 MFU | 381369 tok/s
..."><pre><code>num_parameters: 1557686400 =&gt; bytes: 3115372800
allocated 2971 MiB for model parameters
batch_size B=16 * seq_len T=1024 * num_processes=8 and total_batch_size=1048576
=&gt; setting grad_accum_steps=8
created directory: log_gpt2_1558M
allocating 40409 MiB for activations
val loss 11.129390
allocating 2971 MiB for parameter gradients
allocating 742 MiB for AdamW optimizer state m
allocating 742 MiB for AdamW optimizer state v
allocating 742 MiB for master copy of params
step    1/32000 | loss 11.133732 (+nanz)| norm 52.9732 (+nanz)| lr 8.57e-07 | 3056.36 ms | 42.6% bf16 MFU | 343080 tok/s
step    2/32000 | loss 10.539388 (+nanz)| norm 43.5996 (+nanz)| lr 1.71e-06 | 2747.19 ms | 47.4% bf16 MFU | 381690 tok/s
step    3/32000 | loss 9.894109 (+nanz)| norm 23.2229 (+nanz)| lr 2.57e-06 | 2753.25 ms | 47.3% bf16 MFU | 381259 tok/s
step    4/32000 | loss 9.566241 (+nanz)| norm 28.4920 (+nanz)| lr 3.43e-06 | 2741.47 ms | 47.5% bf16 MFU | 381690 tok/s
step    5/32000 | loss 9.482848 (+nanz)| norm 23.7817 (+nanz)| lr 4.29e-06 | 2752.07 ms | 47.3% bf16 MFU | 381507 tok/s
step    6/32000 | loss 9.332832 (+nanz)| norm 15.9113 (+nanz)| lr 5.14e-06 | 2751.01 ms | 47.3% bf16 MFU | 381431 tok/s
step    7/32000 | loss 9.165650 (+nanz)| norm 10.5941 (+nanz)| lr 6.00e-06 | 2753.03 ms | 47.3% bf16 MFU | 381327 tok/s
step    8/32000 | loss 9.132234 (+nanz)| norm 16.2733 (+nanz)| lr 6.86e-06 | 2748.91 ms | 47.3% bf16 MFU | 381348 tok/s
step    9/32000 | loss 9.097384 (+nanz)| norm 12.1342 (+nanz)| lr 7.71e-06 | 2748.73 ms | 47.3% bf16 MFU | 381367 tok/s
step   10/32000 | loss 9.072879 (+nanz)| norm 10.5923 (+nanz)| lr 8.57e-06 | 2749.40 ms | 47.3% bf16 MFU | 381369 tok/s
...
</code></pre></div>
<p dir="auto">We can see that each step is about 2.75 seconds and there are 32,000 of them, so now we wait ~24 hours. At every step, this training run takes a chunk of ~1 million tokens of <a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu" rel="nofollow">FineWeb-EDU</a> (these are educational web pages from the internet), and updates the 1558 million weights of the model to be slightly better at predicting the next token in a sequence. By the end we'll have processed 32,000 * 1048576 = 33.6B tokens in total. The loss goes down as we do a better job predicting the next token. The norm will stabilize around 0.1-1, the learning rate is being warmed up over the first few steps. Our model flops utilization (MFU) is around 50%, i.e. quite efficient.</p>
<p dir="auto">Now wait 24 hours for this to finish, then you can visualize the <code>main.log</code> log file using the <a href="https://github.com/karpathy/llm.c/blob/master/dev/vislog.ipynb">dev/vislog.ipynb</a> jupyter notebook. For this you will need to also have Python and matplotlib installed, and you will see the following:</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/241138/345149886-0ddc8c19-aa6a-4342-9292-81f40e49d5ad.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjA3MzAxMDUsIm5iZiI6MTcyMDcyOTgwNSwicGF0aCI6Ii8yNDExMzgvMzQ1MTQ5ODg2LTBkZGM4YzE5LWFhNmEtNDM0Mi05MjkyLTgxZjQwZTQ5ZDVhZC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwNzExJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDcxMVQyMDMwMDVaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0wMjBhOGYxYzdhOTY4YTUyMjk0MzRhMmU4NmUyZTBiYzk4ODkzODIyZWI3OTMxMGM2ZWY5YzA1NDRhNDFkN2JiJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.D8gaGy45j3mIysF2wxtmR9MbL8gjVwPGM4Zxxv7wr10"><img width="849" alt="image" src="https://private-user-images.githubusercontent.com/241138/345149886-0ddc8c19-aa6a-4342-9292-81f40e49d5ad.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjA3MzAxMDUsIm5iZiI6MTcyMDcyOTgwNSwicGF0aCI6Ii8yNDExMzgvMzQ1MTQ5ODg2LTBkZGM4YzE5LWFhNmEtNDM0Mi05MjkyLTgxZjQwZTQ5ZDVhZC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwNzExJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDcxMVQyMDMwMDVaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0wMjBhOGYxYzdhOTY4YTUyMjk0MzRhMmU4NmUyZTBiYzk4ODkzODIyZWI3OTMxMGM2ZWY5YzA1NDRhNDFkN2JiJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.D8gaGy45j3mIysF2wxtmR9MbL8gjVwPGM4Zxxv7wr10"></a>
<p dir="auto"><strong>Evals</strong>. On the left we are tracking the loss on FineWeb-EDU validation data. If you simply run the GPT-2 released by OpenAI and evaluate its loss on this split, you get the red horizontal line (loss 2.83). You see that our run outperforms this very very quickly, by step ~5,000. However, this is not a fair comparison because GPT-2 was trained on the never-released WebText dataset, so there is a possibly large distribution shift. So e.g. if you finetune the OpenAI model for 1,000 steps at LR 1e-4, the loss quickly plunges to the blue line (loss 2.61), because it's quickly adapting to the new data statistics. I like to look at the validation loss as a sanity check, but for the actual comparison we'd want to look at fixed, 3rd party evaluations. One of the well-behaved, smooth, common, often-cited evals that also offer early signal is the <a href="https://rowanzellers.com/hellaswag/" rel="nofollow">HellaSwag</a> eval. These are simple common sense scenarios and the model has to pick the correct continuation. We evaluate HellaSwag on the right pane, where we see that we cross over the GPT-2 model around step ~25K (earlier than GPT-2, which is estimated to have been trained on ~100B tokens. This possibly has to do with increased data quality, as we also observed in our earlier <a href="https://github.com/karpathy/llm.c/discussions/481" data-hovercard-type="discussion" data-hovercard-url="/karpathy/llm.c/discussions/481/hovercard">124M run</a>). The green line is the GPT-3 model of the same size, which is pretty much the same model architecture as GPT-2 with minor differences (context length 1024 -&gt; 2048) but trained for 300B tokens (i.e. ~10X more tokens than what we trained on here). I should say that even HellaSwag is not an ideal single point of comparison because it tests simple English and common sense, it does not test e.g. multilingual, math or code. It could have been that the WebText data mixture was a lot heavier on these, and these domains were "stealing" model capacity to some extent, we don't know because it was never released. Lastly, in general, good evals are harder at low model capability like GPT-2 because e.g. the models don't understand multiple choice, and their samples are not high enough quality to make above chance dent into standard math or code evals.</p>
<p dir="auto"><strong>Args guide</strong>. Let's look at the args we passed into the training now in more detail. The GPT-2 release from OpenAI included model weights but very few details, while GPT-3 release had no weights but many details. So in many cases, we follow the GPT-3 paper hyperparameters because the GPT-2 paper has very very little information:</p>
<ul dir="auto">
<li><code>-i -j</code> are training and validation splits token files, downloaded earlier with <code>edu_fineweb.sh</code></li>
<li><code>-o</code> is the output directory to write logs and checkpoints into</li>
<li><code>-v 250</code> asks to evaluate and log the validation loss every 250 steps</li>
<li><code>-s 300000</code> asks to sample some tokens every 300000 steps. Because the total number of steps will be less than this, this is hacky way to turn sampling off and we will only sample a single time at the very end.</li>
<li><code>-g 384</code> sets the number of tokens to be sampled at the end to be 384</li>
<li><code>-h 1</code> asks to evaluate the HellaSwag accuracy</li>
<li><code>-b 16</code> sets the micro-batch size to 16 . If you are running out of memory, decrease this value, e.g. try 8, 4, 2, all the way down to 1 potentially.</li>
<li><code>-t 1024</code> sets the maximum sequence length to 1024, as GPT-2 did</li>
<li><code>-d 1048576</code> asks that the total batch size be 2 to the power 20, following the GPT-3 paper hyperparameters table. The code will make sure to meet this desired total batch size and calculate the needed gradient accumulation "inner loop" steps of the optimization. For example up above, we saw that we have 8 GPUs each doing 16 X 1024 tokens, so that is 8 X 16 X 1024 = 131,072 tokens per micro-step (a single forward backward), so the code calculated gradient accumulation steps of 8 to meet the desired 1M batch size per step. i.e. it does forward+backward 8 times and then a single update.</li>
<li><code>-r 0</code> sets recompute to zero. Recompute is a way to trade off compute and memory. If <code>-r 1</code>, then we recompute a piece of the forward pass (the GeLU) during backward. This means we don't have to cache it and save memory, at the cost of some  more compute. So if you're running out of memory, try -r 1, or -r 2 (also recompute layernorms).</li>
<li><code>-z 1</code> turns on ZeRO-1 (i.e. optimizer state sharding) across multiple GPUs. If you're training with &gt; 1 GPU, this setting is a no-brainer and should basically always be on. On 1 GPU this setting is a no-op.</li>
<li><code>-c 0.1</code> sets the weight decay to 0.1. Only (2D) weights are decayed exactly as in GPT-2, and this number comes from the GPT-3 paper</li>
<li><code>-k "cosine"</code> sets the cosine learning rate schedule, which is the default so this is a bit spurious.</li>
<li><code>-l 0.0006</code> sets the maximum learning rate to 6e-4. The GPT-3 paper says to use 2e-4 for this model size, but here we triple and it and seems to train faster and without any issues. This wasn't tuned very carefully yet.</li>
<li><code>-q 0.1</code> says that we will decay the learning rate to 10% of max LR over the course of training, following GPT-3 paper.</li>
<li><code>-u 700</code> says that we will ramp up the learning rate from 0 to max learning rate over the first 700 iterations, which at total batch size 0.5M is 350M tokens, following GPT-3 paper.</li>
<li><code>-n 2000</code> asks to save model checkpoints every 2000 steps.</li>
<li><code>-x 32000</code> asks for 32K steps in total. I chose this number because it is a nice number, and just fits into 24 hours.</li>
<li><code>-ge 1</code> sets a very recently merged gelu recompute setting for CublasLt (optional)</li>
<li><code>-y 1</code> sets the "resume" flag on. If your training for any reason crashes or hangs, you can CTRL+C and re-run this command, and it will attempt to resume the optimization. llm.c is bitwise-deterministic, so you'll get the identical result as if you didn't crash.</li>
<li><code>-e "d48"</code> asks to initialize, a depth 48 GPT-2 model from scratch.</li>
</ul>
<p dir="auto"><strong>Memory guide.</strong> The biggest constraint most people will probably face is that their GPU doesn't have 80GB. That's okay you should still be able to run everything above if you are patient, it would just run slower. So if the model doesn't fit, what do you play with? The most important one is the micro batch size <code>-b</code>. Try to decrease it but keep it to nice numbers. So e.g. 16 -&gt; 8 -&gt; 4 -&gt; 2 -&gt; 1. From there, try to also play with the recompute setting <code>-r</code> which is 0 (fastest, a lot of memory), 1 (very slightly slower, but a huge memory saving), or 2 (slightly slower, smaller memory saving). The next thing you can do is disable master weights in fp32, which you can do with <code>-w 0</code> (1 is default). We won't maintain fp32 copy of params. Empirically in a few runs before this seems to be okay, likely due to our use of stochastic rounding. If even that doesn't fit (that's unlikely right?), you could try to decrease the maximum sequence length with <code>-t</code>, default is 1024 you can take it down to 512, 256, etc., but now you are making your model worse because you're decreasing its maximum attention span.</p>
<p dir="auto"><strong>Code.</strong> Certainly I feel biased but llm.c is quite beautiful:</p>
<ul dir="auto">
<li>It only requires basic CUDA dependencies to run.</li>
<li>It is a direct, minimal and readable implementation in C/CUDA. llm.c totals about 5,000 lines of C/CUDA code. We try to be mostly C, not C++ to keep it simple. Neural net training is just one while loop of the same, simple arithmetic operations (think +, -, *, /) on a single float array, it really shouldn't be that complicated.</li>
<li>It compiles and runs very quickly (few seconds), so you're doing more stepping and less waiting.</li>
<li>It allocates all of its GPU memory a single time at the start and from then on during training has an exactly constant memory footprint. So once you start stepping, you know you're good for the rest of the run and won't OOM.</li>
<li>It is bitwise deterministic.</li>
<li>It is efficient, at just below ~50% MFU.</li>
</ul>
<p dir="auto">The main entry point and the majority of the code is in the file <a href="https://github.com/karpathy/llm.c/blob/master/train_gpt2.cu">train_gpt2.cu</a>. It contains the GPT-2 model definition and the training loop in ~2,000 LOC, and it imports a bunch of helper files with various utilities and the individual layer implementations from the <code>llmc</code> directory. <code>cloc llmc</code> reports 23 files with 3170 LOC, and <code>cloc train_gpt2.cu</code> is 1353 LOC atm.</p>
<p dir="auto"><strong>Multi-node training</strong>. If you are part of the privileged GPU-rich upper class, llm.c supports multi-node training and the most GPUs I've seen someone train llm.c with is ~500 GPUs. This biggest run I've done personally so far is on Lambda's new 1-click cluster feature with 16XH100 GPUs in 2 nodes. The downsides of unemployment. The lambda team has put up <a href="https://github.com/LambdaLabsML/llm.c-1cc/tree/main">detailed instructions</a> on how you can train llm.c models on their 1-click clusters. E.g. with the 512-GPU H100 cluster for $2,300/hr, you might be able to train your GPT-2 in ~30 minutes. You'd have to increase the total batch size (e.g. to ~8M) and possibly tune the hyperparameters a little. I haven't tried but it probably works and would be very cool :)</p>
<p dir="auto"><strong>PyTorch comparison</strong>. A relatively comparable run in PyTorch would I think look something like this, using our parallel PyTorch implementation:</p>
<div dir="auto" data-snippet-clipboard-copy-content="torchrun --standalone --nproc_per_node=8 train_gpt2.py \
    --input_bin &quot;dev/data/edu_fineweb100B/edu_fineweb_train_*.bin&quot; \
    --input_val_bin &quot;dev/data/edu_fineweb100B/edu_fineweb_val_*.bin&quot; \
    --write_tensors 0 \
    --model d48 \
    --batch_size 8 --sequence_length 1024 --total_batch_size 1048576 \
    --dtype bfloat16 \
    --compile 1 \
    --tensorcores 1 \
    --flash 1 \
    --num_iterations 32000 \
    --warmup_iters 700 \
    --weight_decay 0.1 \
    --overfit_single_batch 0 \
    --learning_rate 0.0006 \
    --zero_stage 1"><pre>torchrun --standalone --nproc_per_node=8 train_gpt2.py \
    --input_bin <span><span>"</span>dev/data/edu_fineweb100B/edu_fineweb_train_*.bin<span>"</span></span> \
    --input_val_bin <span><span>"</span>dev/data/edu_fineweb100B/edu_fineweb_val_*.bin<span>"</span></span> \
    --write_tensors 0 \
    --model d48 \
    --batch_size 8 --sequence_length 1024 --total_batch_size 1048576 \
    --dtype bfloat16 \
    --compile 1 \
    --tensorcores 1 \
    --flash 1 \
    --num_iterations 32000 \
    --warmup_iters 700 \
    --weight_decay 0.1 \
    --overfit_single_batch 0 \
    --learning_rate 0.0006 \
    --zero_stage 1</pre></div>
<p dir="auto">The PyTorch code is meant as a testing reference not an actual implementation, so the training loop is a little bit different in some places (e.g. the dataloader doesn't permute the shards, etc.), but this is still possibly useful as a point of reference. I also hacked the default vocab size to be 50257 -&gt; 50304 to get added efficiency, then the currently PyTorch nightly gives:</p>
<div data-snippet-clipboard-copy-content="step   16/32000 | train loss 8.903997 | norm 8.3474 | lr 1.37e-05 | (3381.88 ms | 310057 tok/s)
step   17/32000 | train loss 8.870140 | norm 3.7936 | lr 1.46e-05 | (3381.95 ms | 310051 tok/s)
step   18/32000 | train loss 8.875732 | norm 9.4993 | lr 1.54e-05 | (3393.09 ms | 309033 tok/s)
step   19/32000 | train loss 8.817432 | norm 2.8345 | lr 1.63e-05 | (3379.75 ms | 310253 tok/s)
step   20/32000 | train loss 8.798056 | norm 4.1234 | lr 1.71e-05 | (3386.53 ms | 309631 tok/s)
step   21/32000 | train loss 8.777574 | norm 2.8010 | lr 1.80e-05 | (3386.05 ms | 309675 tok/s)
..."><pre><code>step   16/32000 | train loss 8.903997 | norm 8.3474 | lr 1.37e-05 | (3381.88 ms | 310057 tok/s)
step   17/32000 | train loss 8.870140 | norm 3.7936 | lr 1.46e-05 | (3381.95 ms | 310051 tok/s)
step   18/32000 | train loss 8.875732 | norm 9.4993 | lr 1.54e-05 | (3393.09 ms | 309033 tok/s)
step   19/32000 | train loss 8.817432 | norm 2.8345 | lr 1.63e-05 | (3379.75 ms | 310253 tok/s)
step   20/32000 | train loss 8.798056 | norm 4.1234 | lr 1.71e-05 | (3386.53 ms | 309631 tok/s)
step   21/32000 | train loss 8.777574 | norm 2.8010 | lr 1.80e-05 | (3386.05 ms | 309675 tok/s)
...
</code></pre></div>
<p dir="auto">Now I wouldn't say I have full confidence that the PyTorch script is maximally tuned, but the following observations can be made. PyTorch seems to be taking a lot more memory (this run is ~80GB), while llm.c is at 57GB (29% improvement). Memory is important because it allows you to crank up the batch size (e.g. llm.c can go up to 24 microbatch here), which goes a bit faster. Second, we're seeing about 3386 vs. 2750ms per iteration, so llm.c is stepping ~19% faster. Some of the gains here have known origin, e.g. llm.c includes optimizations like the Fused classifier that kicks off the backward pass, which is something torch.compile does not do today afaik. But it's also possible that this script isn't fully maximally tuned, but in any case I'm showing the comparison in case 1) others would like to take a look, play with, compare, help tune and 2) to just say that llm.c is quite optimized and fast - in the specific case of GPT-2/3 training.</p>
<p dir="auto"><strong>The final model</strong>. A few links that may be helpful, for posterity:</p>
<ul dir="auto">
<li>The <a href="http://llmc.s3-us-west-2.amazonaws.com/gpt2_1558M/main.log" rel="nofollow">main.log</a> file.</li>
<li>The <a href="http://llmc.s3-us-west-2.amazonaws.com/gpt2_1558M/model_00032000.bin" rel="nofollow">model_00032000.bin</a> llm.c bin model file</li>
<li>The model converted to huggingface transformers GPT-2 model I uploaded here: <a href="https://huggingface.co/karpathy/gpt2_1558M_final2_hf" rel="nofollow">karpathy/gpt2_1558M_final2_hf</a>.</li>
</ul>
<p dir="auto"><strong>Model export</strong>. The model export can be done as follows, for example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python dev/eval/export_hf.py --input log_gpt2_128M/model_00032000.bin --output gpt2_1558M_export"><pre>python dev/eval/export_hf.py --input log_gpt2_128M/model_00032000.bin --output gpt2_1558M_export</pre></div>
<p dir="auto">This then lets you run the Eleuther eval harness, or run the huggingface sampling pipeline to get model samples:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# take model for spin
import torch

output = &quot;./gpt2_1558M_final2_hf&quot;

# set pytorch seeds
torch.manual_seed(42)
torch.cuda.manual_seed(42)

prompt = &quot;In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.&quot;
from transformers import AutoModelForCausalLM, AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained(output)
model = AutoModelForCausalLM.from_pretrained(output, attn_implementation=&quot;flash_attention_2&quot;, torch_dtype=torch.bfloat16, device_map='cuda')
model.eval()
tokens = tokenizer.encode(prompt, return_tensors=&quot;pt&quot;)
tokens = tokens.to('cuda')

output = model.generate(tokens, max_new_tokens=500, pad_token_id=tokenizer.eos_token_id, do_sample=True, top_k=50, num_return_sequences=4)
samples = tokenizer.batch_decode(output)
for sample in samples:
    print('-'*30)
    print(sample)"><pre><span># take model for spin</span>
<span>import</span> <span>torch</span>

<span>output</span> <span>=</span> <span>"./gpt2_1558M_final2_hf"</span>

<span># set pytorch seeds</span>
<span>torch</span>.<span>manual_seed</span>(<span>42</span>)
<span>torch</span>.<span>cuda</span>.<span>manual_seed</span>(<span>42</span>)

<span>prompt</span> <span>=</span> <span>"In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English."</span>
<span>from</span> <span>transformers</span> <span>import</span> <span>AutoModelForCausalLM</span>, <span>AutoTokenizer</span>
<span>tokenizer</span> <span>=</span> <span>AutoTokenizer</span>.<span>from_pretrained</span>(<span>output</span>)
<span>model</span> <span>=</span> <span>AutoModelForCausalLM</span>.<span>from_pretrained</span>(<span>output</span>, <span>attn_implementation</span><span>=</span><span>"flash_attention_2"</span>, <span>torch_dtype</span><span>=</span><span>torch</span>.<span>bfloat16</span>, <span>device_map</span><span>=</span><span>'cuda'</span>)
<span>model</span>.<span>eval</span>()
<span>tokens</span> <span>=</span> <span>tokenizer</span>.<span>encode</span>(<span>prompt</span>, <span>return_tensors</span><span>=</span><span>"pt"</span>)
<span>tokens</span> <span>=</span> <span>tokens</span>.<span>to</span>(<span>'cuda'</span>)

<span>output</span> <span>=</span> <span>model</span>.<span>generate</span>(<span>tokens</span>, <span>max_new_tokens</span><span>=</span><span>500</span>, <span>pad_token_id</span><span>=</span><span>tokenizer</span>.<span>eos_token_id</span>, <span>do_sample</span><span>=</span><span>True</span>, <span>top_k</span><span>=</span><span>50</span>, <span>num_return_sequences</span><span>=</span><span>4</span>)
<span>samples</span> <span>=</span> <span>tokenizer</span>.<span>batch_decode</span>(<span>output</span>)
<span>for</span> <span>sample</span> <span>in</span> <span>samples</span>:
    <span>print</span>(<span>'-'</span><span>*</span><span>30</span>)
    <span>print</span>(<span>sample</span>)</pre></div>
<p dir="auto">Also have a look at <a href="https://github.com/karpathy/llm.c/tree/master/dev/eval">dev/eval</a> for instructions on how to run the Eleuther Evaluation Harness, the evals from the HuggingFace Open LLM Leaderboard, etc.</p>
<p dir="auto"><strong>400B token run</strong>. I have also made the attempt to train GPT-2 for significantly longer than 33B tokens. In particular, I changed -x to 400,000 to train for 420B tokens (even more than GPT-3 model of this size, which was trained with 300B). This model run looked great until about step 330,000:</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/241138/347626140-8708850a-c29e-427e-8e14-fb6ba7d7776a.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjA3MzAxMDUsIm5iZiI6MTcyMDcyOTgwNSwicGF0aCI6Ii8yNDExMzgvMzQ3NjI2MTQwLTg3MDg4NTBhLWMyOWUtNDI3ZS04ZTE0LWZiNmJhN2Q3Nzc2YS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwNzExJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDcxMVQyMDMwMDVaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1hZTUwOTVmZTZjZjZhYWNmZTg1OTc3YzllYzVjODQzNzk1NWY4MzA4YWVkNjIzYmQ5MTllMDU1MGEwMGJkYmYzJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.Bp_T57O0jNGvZvwEP2gCddZAPRmuyJVJ6m8m_VENnxw"><img width="1293" alt="image" src="https://private-user-images.githubusercontent.com/241138/347626140-8708850a-c29e-427e-8e14-fb6ba7d7776a.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjA3MzAxMDUsIm5iZiI6MTcyMDcyOTgwNSwicGF0aCI6Ii8yNDExMzgvMzQ3NjI2MTQwLTg3MDg4NTBhLWMyOWUtNDI3ZS04ZTE0LWZiNmJhN2Q3Nzc2YS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwNzExJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDcxMVQyMDMwMDVaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1hZTUwOTVmZTZjZjZhYWNmZTg1OTc3YzllYzVjODQzNzk1NWY4MzA4YWVkNjIzYmQ5MTllMDU1MGEwMGJkYmYzJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.Bp_T57O0jNGvZvwEP2gCddZAPRmuyJVJ6m8m_VENnxw"></a>
<p dir="auto">This model dramatically beats GPT-2 and GPT-3 of its size on HellaSwag (it gets up to ~61%), but sadly becomes unstable there on and explodes. There are more smaller spikes along the way but the code is configured to detect the more simple instantaneous instability and skips update (I used the flags <code>-sl 5.0 -sg 5.0</code>), which helps mitigate and defers issues. However, I think we're not yet being sufficiently careful with our initialization, activation ranges, and overall model training stability and there are deeper issues that gradually drift the model into instability, especially for larger models and over long training duration. To be continued. If you have ideas or recommendations for stabilizing LLM model training please contribute your experience in the discussion below.</p>
<p dir="auto"><strong>FAQ</strong>:</p>
<ul dir="auto">
<li>Can I <strong>sample</strong> from the model in llm.c? kind of, but it's inefficient and a bit weird, and even more hacky if you'd like to prompt the model. Use the huggingface paths above for now.</li>
<li>Can I <strong>chat</strong> with it? no, this is currently only pretraining, not chat finetuning.</li>
<li>Can you train in <strong>fp8</strong>? No, we're currently mostly training in bf16, but early versions are very much work in progress.</li>
<li>I have a non-NVIDIA GPU can I run llm.c? No, llm.c supports C/CUDA only, but good forks exist (see main README). For example there is an actively maintained <a href="https://github.com/anthonix/llm.c">AMD fork</a> by <a data-hovercard-type="user" data-hovercard-url="/users/anthonix/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/anthonix">@anthonix</a> that is quite good.</li>
</ul>
<p dir="auto"><strong>GPT-2 (124M)</strong>. I wanted to also link to an earlier post on training the <a href="https://github.com/karpathy/llm.c/discussions/481" data-hovercard-type="discussion" data-hovercard-url="/karpathy/llm.c/discussions/481/hovercard">GPT-2 (124M) model</a> in llm.c, which has some more related information to llm.c runs. 124M is a smaller model in the GPT-2 miniseries, only 124M parameters compared to 1558M parameters.</p>
<p dir="auto"><strong>Authors</strong></p>
<p dir="auto">Substantial contributions to llm.c came from what now feels like the llm.c core dev team, in addition to self:</p>
<ul dir="auto">
<li><a data-hovercard-type="user" data-hovercard-url="/users/ngc92/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/ngc92">@ngc92</a> in all aspects of the code base</li>
<li><a data-hovercard-type="user" data-hovercard-url="/users/ademeure/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/ademeure">@ademeure</a> in CUDA kernel optimization, low precision training, cudnn, cublas, ...</li>
<li><a data-hovercard-type="user" data-hovercard-url="/users/gordicaleksa/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/gordicaleksa">@gordicaleksa</a> in all aspects of whatever is next on the TODO list, from algorithms to code to multi-node or etc.</li>
<li><a data-hovercard-type="user" data-hovercard-url="/users/rosslwheeler/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/rosslwheeler">@rosslwheeler</a> in CI and Windows support. If you're happily running llm.c on Windows you should definitely thank Ross :)</li>
<li><a href="https://lambdalabs.com/" rel="nofollow">Lambda labs</a> for sponsoring the GPUs used in the development of llm.c. The history here is that I've happily used Lambda for several years and then a few months ago I pretty please asked if they are open to not charging my account for llm.c dev work and they agreed so here we are thank you for supporting llm.c!</li>
</ul>
<p dir="auto"><strong>Coming up</strong>. Some of the next big steps we are interested in and looking at these days:</p>
<ol dir="auto">
<li>Further optimize GPT-2 training hyperparameters. For some reason, the hyperparameters cited by OpenAI in the GPT-3 paper appear to be quite suboptimal, e.g. @Yuchenj_UW on X found that you can 3X the learning rate and get faster training with no apparent downsides. There might be other similar low-hanging fruit.</li>
<li>Improve training and scaling stability, e.g. more stable optimizers, schedulers, clipping, norming, muP. (Some of these PRs already exist, if you have tips on stabilizing LLM runs please reach out with ideas to try!).</li>
<li>Mixed precision++: training with fp8 (imminent!).</li>
<li>Model inference, e.g. KV cache is the low hanging fruit here.</li>
<li>Finetuning: SFT, RLHF</li>
<li>Multimodal extensions, VQVAE and friends</li>
<li>More modern architectures, support for Llama / Gemma model series.</li>
</ol>
<p dir="auto">The goal of llm.c remains to have a simple, minimal, clean training stack for a full-featured LLM agent, in direct C/CUDA, and companion educational materials to bring many people up to speed in this awesome field.</p>
<p dir="auto">Please feel free to use the Discussions for any FAQ and related, or if you'd like something faster, #llmc on <a href="https://discord.gg/3zy8kqD9Cp" rel="nofollow">Discord</a>, or #llmdotc on CUDA MODE Discord.</p>
<p dir="auto">We'll see you next time!</p>
    </td>
  </tr>

    </tbody>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple Vision Pro U.S. Sales Are All but Dead, Market Analysts Say (105 pts)]]></title>
            <link>https://gizmodo.com/apple-vision-pro-u-s-sales-2000469302</link>
            <guid>40939627</guid>
            <pubDate>Thu, 11 Jul 2024 19:12:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gizmodo.com/apple-vision-pro-u-s-sales-2000469302">https://gizmodo.com/apple-vision-pro-u-s-sales-2000469302</a>, See on <a href="https://news.ycombinator.com/item?id=40939627">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                            <p><span>Those still holding on to their </span><a href="https://gizmodo.com/apple-vision-pro-1851249913"><span>Apple Vision Pros</span></a><span> may remain in a </span><a href="https://gizmodo.com/apple-vision-pro-already-forgotten-about-1851426564"><span>rather exclusive club</span></a><span> throughout this year. Market research shows that sales for Apple’s first big, expensive headset will remain low in 2024. The latest reports from those keeping tabs on the Cupertino, California company say AVP will have dropped off 75% by the end of August. The true test for Apple’s spatial dreams may rest on the rumored (slightly) </span><a href="https://gizmodo.com/apple-vision-pro-stopped-production-ar-headset-1851547035"><span>cheaper headset</span></a><span>.</span></p>

 <p><span>The market analyst firm IDC told </span><a href="https://www.bloomberg.com/news/articles/2024-07-11/apple-s-vision-pro-won-t-cross-500-000-sales-this-year-idc-says"><span>Bloomberg</span></a><span> the Apple Vision Pro has yet to sell 100,000 units. It’s an expensive headset, and Apple wasn’t expecting it to sell like an iPhone. Supply chain analysts have reported that <a href="https://gizmodo.com/apple-vision-pro-reality-check-1851429764">Apple cut its sales expectations for its $3,500 “spatial computer” </a></span><span>in April. But this latest report shows that sales will have dropped off a cliff in the U.S. in the third quarter of this year and will continue to slacken through the holidays.</span></p> <p><span>Last month, Apple launched the Vision Pro in international markets, including Europe, the U.K., China, Japan, and Singapore. IDC expects the AVP’s interest in those markets to keep the headset’s sales afloat until next year. The real pick-me-up for Apple’s spatial dreams would be a new, less expensive headset. Those in the know have hinted Apple is working on a “budget” Vision device slated for the latter half of 2025.</span></p>

 <p><span>Even if the <a href="https://gizmodo.com/cheaper-weaker-apple-vision-pro-1851556515">next Vision device</a> costs half the Pro model, it will still cost $1,750 and one of the most expensive consumer-end VR/AR headsets you can buy. Rumors hint that the next device could remove the pointless exterior display to save on manufacturing costs. It could also reduce the FOV and use a less-capable chip than the current M2. Bloomberg hinted that Apple was even considering tethering it to an iPhone or Mac for daily use, which would drastically reduce its portability.</span></p> <p><span>We don’t have pure statistics on how many folks returned their Vision Pro after buying it during the initial hype rush, but analysts have noted that </span><a href="https://gizmodo.com/apple-vision-pro-returns-users-didnt-know-set-it-up-1851293527"><span>many who bought one were confused by</span></a><span> its more complicated setup and what they were supposed to use it for in their daily lives.</span></p>

 <p><span>Sales expectations will put even more pressure on Apple engineers to design something that can compete with devices like the $500 </span><a href="https://gizmodo.com/meta-android-of-vr-1851521814"><span>Meta Quest 3</span></a><span> while justifying the higher price tag. Fans of the Cupertino company are already used to paying an “Apple tax” on their products, but not when the cost is literally thousands of dollars more.&nbsp;</span></p> <p><span>Apple is </span><a href="https://gizmodo.com/everything-announced-at-wwdc-2024-ios-apple-ai-1851529902"><span>working on a visionOS update</span></a><span> to improve the faux-3D spatial photos, add a few new gesture controls, and allow for a panoramic Mac screen mirroring. The latest version of visionOS won’t have a public beta, so we’ll have to wait and see if the changes will give the few on-the-fence customers a reason to pick up the ultra-expensive headset.</span></p>            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-Precision (154 pts)]]></title>
            <link>https://www.together.ai/blog/flashattention-3</link>
            <guid>40938577</guid>
            <pubDate>Thu, 11 Jul 2024 17:06:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.together.ai/blog/flashattention-3">https://www.together.ai/blog/flashattention-3</a>, See on <a href="https://news.ycombinator.com/item?id=40938577">Hacker News</a></p>
<div id="readability-page-1" class="page"><div fs-richtext-element="rich-text"><p>Attention, as a core layer of the ubiquitous Transformer architecture, is a bottleneck for large language models and long-context applications. FlashAttention (and FlashAttention-2) pioneered an approach to speed up attention on GPUs by minimizing memory reads/writes, and is now used by most <a href="https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html">libraries</a> to accelerate Transformer training and inference. This has contributed to a massive increase in LLM context length in the last two years, from 2-4K (GPT-3, OPT) to 128K (GPT-4), or even 1M (<a href="https://huggingface.co/gradientai/Llama-3-8B-Instruct-Gradient-1048k">Llama 3</a>). However, despite its success, FlashAttention has yet to take advantage of new capabilities in modern hardware, with FlashAttention-2 achieving only 35% utilization of theoretical max FLOPs on the H100 GPU. In this blogpost, we describe three main techniques to speed up attention on Hopper GPUs: exploiting asynchrony of the Tensor Cores and TMA to (1) overlap overall computation and data movement via warp-specialization and (2) interleave block-wise matmul and softmax operations, and (3) incoherent processing that leverages hardware support for FP8 low-precision.</p><p>We’re excited to release FlashAttention-3 that incorporates these techniques. It’s 1.5-2.0x faster than FlashAttention-2 with FP16, up to 740 TFLOPS, i.e., 75% utilization of H100 theoretical max FLOPS. With FP8, FlashAttention-3 reaches close to 1.2 PFLOPS, with 2.6x smaller error than baseline FP8 attention.</p><p>The improvements from FlashAttention-3 will result in:</p><ol role="list"><li><strong>More efficient GPU Utilization</strong>: The new technique uses up to 75% of an H100 GPU's maximum capabilities, up from just 35% before. This results in significantly (1.5-2x) faster than previous versions for training and running of large language models (LLMs).</li></ol><ol start="2" role="list"><li><strong>Better performance with lower precision</strong>: FlashAttention-3 can work with lower precision numbers (FP8) while maintaining accuracy. This allows for even faster processing and potentially lower memory usage, which could lead to cost savings and improved efficiency for customers running large-scale AI operations.</li></ol><ol start="3" role="list"><li><strong>Ability to use longer context in LLMs</strong>: By speeding up the attention mechanism, FlashAttention-3 enables AI models to work with much longer pieces of text more efficiently. This could allow for applications that can understand and generate longer, more complex content without slowing down.</li></ol><p>FlashAttention-3 is available on Github <a href="https://github.com/Dao-AILab/flash-attention">here.</a></p><p>Read the paper <a href="https://github.com/Dao-AILab/flash-attention">here</a>.</p><h2>FlashAttention Recap</h2><p><a href="https://arxiv.org/abs/2205.14135">FlashAttention</a> is an algorithm that reorders the attention computation and leverages tiling and recomputation to significantly speed it up and reduce memory usage from quadratic to linear in sequence length. We use tiling to load blocks of inputs from HBM (GPU memory) to SRAM (fast cache), perform attention with respect to that block, and update the output in HBM. By not writing the large intermediate attention matrices to HBM, we reduce the amount of memory reads/writes, which brings 2-4x wallclock time speedup.</p><p>‍</p><p>Here we show a diagram of FlashAttention forward pass: with tiling and softmax rescaling, we operate by blocks and avoid having to read/write from HBM, while obtaining the correct output with no approximation.</p><figure><p><img src="https://cdn.prod.website-files.com/650c3b59079d92475f37b68f/668fef78677cfc76424fd0f4_flash_recap_diagram.png" loading="lazy" alt=""></p></figure><h2>New hardware features on Hopper GPUs - WGMMA, TMA, FP8</h2><p>While FlashAttention-2 can achieve up to 70% theoretical max FLOPS on Ampere (A100) GPUs, it does not yet take advantage of new features on Hopper GPUs to maximize performance. We describe some of the new Hopper-specific features here, and why they are important.</p><p>1. WGMMA (Warpgroup Matrix Multiply-Accumulate). This new feature makes use of the new Tensor Cores on Hopper, with much higher throughput <sub>1</sub> than the older mma.sync instruction in Ampere (image from the <a href="https://resources.nvidia.com/en-us-tensor-core/gtc22-whitepaper-hopper?ncid=no-ncid">H100 white paper)</a>.</p><figure><p><img src="https://cdn.prod.website-files.com/650c3b59079d92475f37b68f/668fef94896a312df22db9bd_h100_wgmma.png" loading="lazy" alt=""></p></figure><p>2. TMA (Tensor Memory Accelerator). This is a special hardware unit that accelerates the transfer of data between global memory and shared memory, taking care of all index calculation and out-of-bound predication. This frees up registers, which is a valuable</p><figure><p><img src="https://cdn.prod.website-files.com/650c3b59079d92475f37b68f/668ff020c21b55bf4f71c935_h100_tma.png" loading="lazy" alt=""></p></figure><p>3. Low-precision with FP8. This doubles the Tensor Core throughput (e.g. 989 TFLOPS with FP16 and 1978 TFLOPS with FP8), but trades off accuracy by using fewer bits to represent floating point numbers.</p><figure><p><img src="https://cdn.prod.website-files.com/650c3b59079d92475f37b68f/668ff09c0c34e79f0eb28842_h100_wgmma_fp8.png" loading="lazy" alt=""></p></figure><div><p>FlashAttention-3 makes use of all of these new features of Hopper, using powerful abstractions from <a href="https://github.com/NVIDIA/cutlass">NVIDIA’s CUTLASS</a> library.</p><p>By rewriting FlashAttention to use these new features, we can already significantly speed it up (e.g., from 350 TFLOPS in FlashAttention-2 FP16 forward pass to around 540-570 TFLOPS). However, the asynchronous nature of the new instructions on Hopper (WGMMA and TMA) opens up additional algorithmic opportunities to overlap operations and thereby extract even greater performance. For this blogpost, we’ll explain two such techniques specific to attention. The generic technique of warp specialization, with separate producer and consumer warps doing TMA and WGMMA, is <a href="https://github.com/NVIDIA/cutlass/blob/main/media/docs/efficient_gemm.md#warp-specialization">well-covered elsewhere</a> in the context of GEMM and works the same here.</p></div><h2>Asynchrony: Overlapping GEMM and Softmax</h2><p>Why overlap?</p><p>Attention has GEMMs (those matmuls between Q and K and between attention probability P and V) and softmax as its two main operations. Why do we need to overlap them? Isn’t most of the FLOPS in the GEMMs anyway? As long as the GEMMs are fast (e.g., computed using WGMMA instructions), shouldn’t the <a href="https://horace.io/brrr_intro.html">GPU be going <em>brrrr</em></a>?</p><p>The problem is that non-matmul operations are much slower than matmul operations on modern accelerators. Special functions such as exponential (for the softmax) have even lower throughput than floating point multiply-add; they are evaluated by the multi-function unit, a unit separate from floating point multiply-add or matrix multiply-add. As an example, the H100 GPU SXM5 has 989 TFLOPS of FP16 matrix multiply, but only 3.9 TFLOPS (256x less throughput) for special functions <sub>2</sub> ! For head dimension 128, there are 512x more matmul FLOPS than exponential, which means that exponential can take 50% of the time compared to matmul. The situation is even worse for FP8, where the matmul FLOPS are twice as fast yet exponential FLOPS stay the same speed. Ideally we want matmul and softmax to operate in parallel. While the Tensor Cores are busy with matmul, the multi-function units should be calculating exponential!</p><h3>Inter-warpgroup overlapping with pingpong scheduling</h3><p>The first and easiest way to overlap GEMM and softmax is to do nothing at all! The warp schedulers already try to schedule warps so that if some warps are blocked (e.g., waiting for GEMM results), other warps can run. That is, the warp schedulers do some of this overlapping for us, for free.</p><p>However, we can improve on this by doing some of the scheduling manually. As an example, if we have 2 warpgroups (labeled 1 and 2 – each warpgroup is a group of 4 warps), we can use synchronization barriers (bar.sync) so that warpgroup 1 first does its GEMMs (e.g., GEMM1 of one iteration and GEMM0 of the next iteration), and then warpgroup 2 does its GEMMs while warpgroup 1 does its softmax, and so on. This “pingpong” schedule is illustrated in the figure below, where the same color denotes the same iteration.</p><figure><p><img src="https://cdn.prod.website-files.com/650c3b59079d92475f37b68f/668ff0a001e73d009d1b73fb_pingpong_pipelining.png" loading="lazy" alt=""></p></figure><p>This would allow us to perform the softmax in the shadow of the GEMMs of the other warpgroup. Of course, this figure is just a caricature; in practice the scheduling is not really this clean. Nevertheless, pingpong scheduling can improve FP16 attention forward pass from around 570 TFLOPS to 620 TFLOPS (head dim 128, seqlen 8K).</p><h3>Intra-warpgroup overlapping of GEMM and Softmax</h3><p>Even within one warpgroup, we can have some part of softmax running while the GEMMs of that warpgroup is running. This is illustrated in this figure, where the same color denotes the same iteration.</p><figure><p><img src="https://cdn.prod.website-files.com/650c3b59079d92475f37b68f/668ff0d6d9fd917e68abc5f3_2_stage_pipelining.png" loading="lazy" alt=""></p></figure><p>This pipelining increases throughput from around 620 TFLOPS to around 640-660 TFLOPS for FP16 attention forward, at the cost of higher register pressure. We need more registers to hold both accumulators of the GEMMs, and the input/output of softmax. Overall, we find this technique to offer a favorable tradeoff.</p><p>Low-precision: reduce quantization error with incoherent processing</p><p>LLM activation can have <a href="https://arxiv.org/abs/2208.07339">outliers</a> with much larger magnitude than the rest of the features. These outliers make it difficult to quantize, producing much larger quantization errors. We leverage incoherent processing, a technique used in the quantization literature (e.g. from <a href="https://arxiv.org/abs/2307.13304">QuIP</a>) that multiplies the query and key with a random orthogonal matrix to “spread out” the outliers and reduce quantization error. In particular, we use the Hadamard transform (with random signs), which can be done per attention head in O(d log d) instead of O(d^2) time, where d is the head dimension. Since the Hadamard transform is memory-bandwidth bound, it can be fused with previous operations such as rotary embedding (also memory-bandwidth bound) “for free”.</p><p>In our experiment where Q, K, V are generated from a standard normal distribution but 0.1% of the entries have large magnitudes (to simulate outliers), we found that incoherent processing can reduce the quantization error by 2.6x. We show numerical error comparison in the table below. Please see the paper for details.</p><figure><p><img src="https://cdn.prod.website-files.com/650c3b59079d92475f37b68f/668ff0e415c3198e0afba4ab_flash3_numerical_error.png" loading="lazy" alt=""></p></figure><h2>Attention benchmark</h2><p>We show some results with FlashAttention-3, and compare it to FlashAttention-2, as well as the implementation in Triton and cuDNN (both of which already use new hardware features of Hopper GPUs).</p><p>For FP16, we see about 1.6x-1.8x speedup over FlashAttention-2</p><figure><p><img src="https://cdn.prod.website-files.com/650c3b59079d92475f37b68f/668ff11d2cb1c308a71d0cdf_flash3_fp16_fwd.png" loading="lazy" alt=""></p></figure><figure><p><img src="https://cdn.prod.website-files.com/650c3b59079d92475f37b68f/668ff0f215c3198e0afbad52_flash3_fp16_bwd.png" loading="lazy" alt=""></p></figure><p>For FP8, we can reach close to 1.2 PFLOPS!</p><figure><p><img src="https://cdn.prod.website-files.com/650c3b59079d92475f37b68f/668ff0e74da9fa32dfc5bacf_flash3_fp8_fwd.png" loading="lazy" alt=""></p></figure><h2>Discussion</h2><p>This blogpost highlights some of the optimizations for FlashAttention available on Hopper GPUs. Other optimizations (e.g., variable length sequences, persistent kernel, and in-kernel transpose for FP8) are covered in the paper. <br>We have seen that designing algorithms that take advantage of the hardware they run on can bring significant efficiency gains and unlock new model capabilities such as long context. We look forward to future work on optimization for LLM inference, as well as generalizing our techniques to other hardware architectures.&nbsp;</p><p>We also look forward to FlashAttention-3 being integrated in a future release of PyTorch.</p><p>‍</p><p><em><sub>Footnotes:</sub></em></p><p><em><sub>1 Without the wgmma instruction, the older mma.sync instruction can only reach about ⅔ the peak throughput of Hopper Tensor Cores: https://arxiv.org/abs/2402.13499v1</sub></em></p><p><em><sub>2 The CUDA programming guide specifies that the throughput for special functions is 16 operations per streaming multiprocessor (SM) per clock cycle. We multiply 16 by 132 SMs and 1830 Mhz (clock speed used to calculate 989 TFLOPS of FP16 matmul) to get 3.9 TFLOPS</sub></em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Korvus: Single-Query RAG with Postgres (108 pts)]]></title>
            <link>https://github.com/postgresml/korvus</link>
            <guid>40938325</guid>
            <pubDate>Thu, 11 Jul 2024 16:35:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/postgresml/korvus">https://github.com/postgresml/korvus</a>, See on <a href="https://news.ycombinator.com/item?id=40938325">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto">
   <themed-picture data-catalyst-inline="true"><picture>
     <source media="(prefers-color-scheme: dark)" srcset="https://github.com/postgresml/korvus/assets/19626586/54dda262-861b-4751-a3ce-0790762f3cbe">
     <source media="(prefers-color-scheme: light)" srcset="https://github.com/postgresml/korvus/assets/19626586/f567ce57-35b2-4411-8e43-5f0887a938cb">
     <img alt="Logo" src="https://github.com/postgresml/korvus/raw/main" width="520">
   </picture></themed-picture>
</div>
<p dir="auto"><b>One query to rule them all</b></p>

<p dir="auto">
| <a href="https://postgresml.org/docs/open-source/korvus/" rel="nofollow"><b>Documentation</b></a> | <a href="https://postgresml.org/blog" rel="nofollow"><b>Blog</b></a> | <a href="https://discord.gg/DmyJP3qJ7U" rel="nofollow"><b>Discord</b></a> |
</p>
<hr>
<p dir="auto">Korvus is a search SDK that unifies the entire RAG pipeline in a single database query. Built on top of Postgres with bindings for Python, JavaScript and Rust, Korvus delivers high-performance, customizable search capabilities with minimal infrastructure concerns.</p>
<details open="">
<summary><b>📕 Table of Contents</b></summary>
<ul dir="auto">
<li><a href="#-what-is-korvus">🦅 What is Korvus?</a></li>
<li><a href="#-languages">🔠 Languages</a></li>
<li><a href="#-why-korvus">🏆 Why Korvus?</a></li>
<li><a href="#-key-features">⚡ Key Features</a></li>
<li><a href="#-system-architecture">🧩 System Architecture</a></li>
<li><a href="#-get-started">🚀 Get Started</a></li>
<li><a href="#-the-power-of-sql">🔍 The Power of SQL</a></li>
<li><a href="#-documentation">📘 Documentation</a></li>
<li><a href="#-community">🌐 Community</a></li>
<li><a href="#-contributing">🤝 Contributing</a></li>
</ul>
</details>
<details open="">
  <summary>
    
    <span aria-label="Video description demo.mp4">demo.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/19626586/347521449-2b697dc6-8c38-41a7-8c8e-ef158dacb29b.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjA3MzczMDIsIm5iZiI6MTcyMDczNzAwMiwicGF0aCI6Ii8xOTYyNjU4Ni8zNDc1MjE0NDktMmI2OTdkYzYtOGMzOC00MWE3LThjOGUtZWYxNThkYWNiMjliLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MTElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzExVDIyMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ5MjhjYmI2NGM2Y2E1OTVhZTYyYzQ0ZGYyOGI2MGFjOTc4ZmI4MzljZjQyODI1ZDkxMzY1Zjk5MGNhZmE3ZGMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.I4bPw86GlP4MsGPVpOJeUZu36dqW8adeqDfXRXOQcM8" data-canonical-src="https://private-user-images.githubusercontent.com/19626586/347521449-2b697dc6-8c38-41a7-8c8e-ef158dacb29b.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjA3MzczMDIsIm5iZiI6MTcyMDczNzAwMiwicGF0aCI6Ii8xOTYyNjU4Ni8zNDc1MjE0NDktMmI2OTdkYzYtOGMzOC00MWE3LThjOGUtZWYxNThkYWNiMjliLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MTElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzExVDIyMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ5MjhjYmI2NGM2Y2E1OTVhZTYyYzQ0ZGYyOGI2MGFjOTc4ZmI4MzljZjQyODI1ZDkxMzY1Zjk5MGNhZmE3ZGMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.I4bPw86GlP4MsGPVpOJeUZu36dqW8adeqDfXRXOQcM8" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">🦅 What is Korvus?</h2><a id="user-content--what-is-korvus" aria-label="Permalink: 🦅 What is Korvus?" href="#-what-is-korvus"></a></p>
<p dir="auto">Korvus is an all-in-one, open-source RAG (Retrieval-Augmented Generation) pipeline built for Postgres. It combines LLMs, vector memory, embedding generation, reranking, summarization and custom models into a single query, maximizing performance and simplifying your search architecture.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/19626586/344766695-9ee9d695-7630-4da7-ab2a-386e20ae4a68.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjA3MzczMDIsIm5iZiI6MTcyMDczNzAwMiwicGF0aCI6Ii8xOTYyNjU4Ni8zNDQ3NjY2OTUtOWVlOWQ2OTUtNzYzMC00ZGE3LWFiMmEtMzg2ZTIwYWU0YTY4LmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MTElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzExVDIyMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTZlYmFiNTg2MTA1NWQyNWI5MWMyNTE2OTUyMDg0ZjExNzY1ZGFmODE1Y2VkNDAzNTRlYWQ1ZGViNmZhMDYzMDYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.xD0xJlDKsRn8vbkwcYG5cUY-f42ebDlaYJlHFaZwKR0"><img src="https://private-user-images.githubusercontent.com/19626586/344766695-9ee9d695-7630-4da7-ab2a-386e20ae4a68.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjA3MzczMDIsIm5iZiI6MTcyMDczNzAwMiwicGF0aCI6Ii8xOTYyNjU4Ni8zNDQ3NjY2OTUtOWVlOWQ2OTUtNzYzMC00ZGE3LWFiMmEtMzg2ZTIwYWU0YTY4LmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MTElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzExVDIyMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTZlYmFiNTg2MTA1NWQyNWI5MWMyNTE2OTUyMDg0ZjExNzY1ZGFmODE1Y2VkNDAzNTRlYWQ1ZGViNmZhMDYzMDYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.xD0xJlDKsRn8vbkwcYG5cUY-f42ebDlaYJlHFaZwKR0" alt="korvus-demo" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔠 Languages</h2><a id="user-content--languages" aria-label="Permalink: 🔠 Languages" href="#-languages"></a></p>
<p dir="auto">Korvus provides SDK support for multiple programming languages, allowing you to integrate it seamlessly into your existing tech stack:</p>
<ul dir="auto">
<li>Python: <a href="https://pypi.org/project/korvus/" rel="nofollow">PyPI Package</a></li>
<li>JavaScript: <a href="https://www.npmjs.com/package/korvus" rel="nofollow">npm Package</a></li>
<li>Rust: <a href="https://crates.io/crates/korvus" rel="nofollow">Crates.io Package</a></li>
<li>C: <a href="https://postgresml.org/docs/api/client-sdk/" rel="nofollow">Build from source</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🏆 Why Korvus?</h2><a id="user-content--why-korvus" aria-label="Permalink: 🏆 Why Korvus?" href="#-why-korvus"></a></p>
<p dir="auto">Korvus stands out by harnessing the full power of Postgres for RAG operations:</p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Postgres-Native RAG</strong>: Korvus leverages Postgres' robust capabilities, allowing you to perform complex RAG operations directly within your database. This approach eliminates the need for external services and API calls, significantly reducing latency and complexity many times over.</p>
</li>
<li>
<p dir="auto"><strong>Single Query Efficiency</strong>: With Korvus, your entire RAG pipeline - from embedding generation to text generation - is executed in a single SQL query. This "one query to rule them all" approach simplifies your architecture and boosts performance.</p>
</li>
<li>
<p dir="auto"><strong>Scalability and Performance</strong>: By building on Postgres, Korvus inherits its excellent scalability and performance characteristics. As your data grows, Korvus grows with it, maintaining high performance even with large datasets.</p>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">⚡ Key Features</h2><a id="user-content--key-features" aria-label="Permalink: ⚡ Key Features" href="#-key-features"></a></p>
<ul dir="auto">
<li><strong>Simplified Architecture</strong>: Replace complex service oriented architectures with a single, powerful query.</li>
<li><strong>High Performance</strong>: Eliminates API calls and data movement for faster processing and greater reliability.</li>
<li><strong>Open Source</strong>: Improve your developer experience with open source software and models that run locally in Docker too.</li>
<li><strong>Multi-Language Support</strong>: Use Korvus with Python, JavaScript and Rust. Open an issue to vote for other language support.</li>
<li><strong>Unified Pipeline</strong>: Combine embedding generation, vector search, reranking, and text generation in one query.</li>
<li><strong>Postgres-Powered</strong>: Under the hood, Korvus operations are powered by efficient SQL queries on a time-tested database platform.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🧩 System Architecture</h2><a id="user-content--system-architecture" aria-label="Permalink: 🧩 System Architecture" href="#-system-architecture"></a></p>
<p dir="auto">Korvus utilizes PostgresML's pgml extension and the pgvector extension to compress the entire RAG pipeline inside of Postgres.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/19626586/343950842-53128313-ded8-4b29-91c4-f585db859c23.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjA3MzczMDIsIm5iZiI6MTcyMDczNzAwMiwicGF0aCI6Ii8xOTYyNjU4Ni8zNDM5NTA4NDItNTMxMjgzMTMtZGVkOC00YjI5LTkxYzQtZjU4NWRiODU5YzIzLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MTElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzExVDIyMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTNiOGYzZjgwZTBmZjJkMGU0ZWFlODdhOWQ1NjVhN2U3YTY0OGE0OGRhYmRiN2VmOTVkMGVmNTdiM2ZiYTRhZjEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.2Dl2cS-glyIQd1W7tP1VXdW3pVSuMlRTSoAtQo2pMp8"><img src="https://private-user-images.githubusercontent.com/19626586/343950842-53128313-ded8-4b29-91c4-f585db859c23.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjA3MzczMDIsIm5iZiI6MTcyMDczNzAwMiwicGF0aCI6Ii8xOTYyNjU4Ni8zNDM5NTA4NDItNTMxMjgzMTMtZGVkOC00YjI5LTkxYzQtZjU4NWRiODU5YzIzLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MTElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzExVDIyMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTNiOGYzZjgwZTBmZjJkMGU0ZWFlODdhOWQ1NjVhN2U3YTY0OGE0OGRhYmRiN2VmOTVkMGVmNTdiM2ZiYTRhZjEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.2Dl2cS-glyIQd1W7tP1VXdW3pVSuMlRTSoAtQo2pMp8" alt="PostgresML_Old-V-New_Diagram-Update"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Get Started</h2><a id="user-content--get-started" aria-label="Permalink: 🚀 Get Started" href="#-get-started"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">📋 Prerequisites</h3><a id="user-content--prerequisites" aria-label="Permalink: 📋 Prerequisites" href="#-prerequisites"></a></p>
<p dir="auto">To use Korvus, you need a Postgres database with pgml and pgvector installed. You have two options:</p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Self-hosted</strong>: Set up your own database with pgml and pgvector.</p>
<ul dir="auto">
<li>For instructions, see our <a href="https://postgresml.org/docs/resources/developer-docs/quick-start-with-docker" rel="nofollow">self-hosting guide</a>.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Hosted Service</strong>: Use our managed Postgres service with pgml and pgvector pre-installed.</p>
<ul dir="auto">
<li><a href="https://postgresml.org/signup" rel="nofollow">Sign up for PostgresML Cloud</a>.</li>
</ul>
</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">🏁 Quick Start</h3><a id="user-content--quick-start" aria-label="Permalink: 🏁 Quick Start" href="#-quick-start"></a></p>
<ol dir="auto">
<li>Install Korvus:</li>
</ol>

<ol start="2" dir="auto">
<li>Set the <code>KORVUS_DATABASE_URL</code> env variable:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="export KORVUS_DATABASE_URL=&quot;{YOUR DATABASE CONNECTION STRING}&quot;"><pre><span>export</span> KORVUS_DATABASE_URL=<span><span>"</span>{YOUR DATABASE CONNECTION STRING}<span>"</span></span></pre></div>
<ol start="3" dir="auto">
<li>Initialize a Collection and Pipeline:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="from korvus import Collection, Pipeline
import asyncio

collection = Collection(&quot;korvus-demo-v0&quot;)
pipeline = Pipeline(
    &quot;v1&quot;,
    {
        &quot;text&quot;: {
            &quot;splitter&quot;: {&quot;model&quot;: &quot;recursive_character&quot;},
            &quot;semantic_search&quot;: {&quot;model&quot;: &quot;Alibaba-NLP/gte-base-en-v1.5&quot;},
        }
    },
)

async def add_pipeline():
    await collection.add_pipeline(pipeline)

asyncio.run(add_pipeline())"><pre><span>from</span> <span>korvus</span> <span>import</span> <span>Collection</span>, <span>Pipeline</span>
<span>import</span> <span>asyncio</span>

<span>collection</span> <span>=</span> <span>Collection</span>(<span>"korvus-demo-v0"</span>)
<span>pipeline</span> <span>=</span> <span>Pipeline</span>(
    <span>"v1"</span>,
    {
        <span>"text"</span>: {
            <span>"splitter"</span>: {<span>"model"</span>: <span>"recursive_character"</span>},
            <span>"semantic_search"</span>: {<span>"model"</span>: <span>"Alibaba-NLP/gte-base-en-v1.5"</span>},
        }
    },
)

<span>async</span> <span>def</span> <span>add_pipeline</span>():
    <span>await</span> <span>collection</span>.<span>add_pipeline</span>(<span>pipeline</span>)

<span>asyncio</span>.<span>run</span>(<span>add_pipeline</span>())</pre></div>
<ol start="4" dir="auto">
<li>Insert documents:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="async def upsert_documents():
    documents = [
        {&quot;id&quot;: &quot;1&quot;, &quot;text&quot;: &quot;Korvus is incredibly fast and easy to use.&quot;},
        {&quot;id&quot;: &quot;2&quot;, &quot;text&quot;: &quot;Tomatoes are incredible on burgers.&quot;},
    ]
    await collection.upsert_documents(documents)

asyncio.run(upsert_documents())"><pre><span>async</span> <span>def</span> <span>upsert_documents</span>():
    <span>documents</span> <span>=</span> [
        {<span>"id"</span>: <span>"1"</span>, <span>"text"</span>: <span>"Korvus is incredibly fast and easy to use."</span>},
        {<span>"id"</span>: <span>"2"</span>, <span>"text"</span>: <span>"Tomatoes are incredible on burgers."</span>},
    ]
    <span>await</span> <span>collection</span>.<span>upsert_documents</span>(<span>documents</span>)

<span>asyncio</span>.<span>run</span>(<span>upsert_documents</span>())</pre></div>
<ol start="5" dir="auto">
<li>Perform RAG</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="async def rag():
    query = &quot;Is Korvus fast?&quot;
    print(f&quot;Querying for response to: {query}&quot;)
    results = await collection.rag(
        {
            &quot;CONTEXT&quot;: {
                &quot;vector_search&quot;: {
                    &quot;query&quot;: {
                        &quot;fields&quot;: {&quot;text&quot;: {&quot;query&quot;: query}},
                    },
                    &quot;document&quot;: {&quot;keys&quot;: [&quot;id&quot;]},
                    &quot;limit&quot;: 1,
                },
                &quot;aggregate&quot;: {&quot;join&quot;: &quot;\n&quot;},
            },
            &quot;chat&quot;: {
                &quot;model&quot;: &quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;,
                &quot;messages&quot;: [
                    {
                        &quot;role&quot;: &quot;system&quot;,
                        &quot;content&quot;: &quot;You are a friendly and helpful chatbot&quot;,
                    },
                    {
                        &quot;role&quot;: &quot;user&quot;,
                        &quot;content&quot;: f&quot;Given the context\n:{{CONTEXT}}\nAnswer the question: {query}&quot;,
                    },
                ],
                &quot;max_tokens&quot;: 100,
            },
        },
        pipeline,
    )
    print(results)

asyncio.run(rag())"><pre><span>async</span> <span>def</span> <span>rag</span>():
    <span>query</span> <span>=</span> <span>"Is Korvus fast?"</span>
    <span>print</span>(<span>f"Querying for response to: <span><span>{</span><span>query</span><span>}</span></span>"</span>)
    <span>results</span> <span>=</span> <span>await</span> <span>collection</span>.<span>rag</span>(
        {
            <span>"CONTEXT"</span>: {
                <span>"vector_search"</span>: {
                    <span>"query"</span>: {
                        <span>"fields"</span>: {<span>"text"</span>: {<span>"query"</span>: <span>query</span>}},
                    },
                    <span>"document"</span>: {<span>"keys"</span>: [<span>"id"</span>]},
                    <span>"limit"</span>: <span>1</span>,
                },
                <span>"aggregate"</span>: {<span>"join"</span>: <span>"<span>\n</span>"</span>},
            },
            <span>"chat"</span>: {
                <span>"model"</span>: <span>"meta-llama/Meta-Llama-3-8B-Instruct"</span>,
                <span>"messages"</span>: [
                    {
                        <span>"role"</span>: <span>"system"</span>,
                        <span>"content"</span>: <span>"You are a friendly and helpful chatbot"</span>,
                    },
                    {
                        <span>"role"</span>: <span>"user"</span>,
                        <span>"content"</span>: <span>f"Given the context<span>\n</span>:{{CONTEXT}}<span>\n</span>Answer the question: <span><span>{</span><span>query</span><span>}</span></span>"</span>,
                    },
                ],
                <span>"max_tokens"</span>: <span>100</span>,
            },
        },
        <span>pipeline</span>,
    )
    <span>print</span>(<span>results</span>)

<span>asyncio</span>.<span>run</span>(<span>rag</span>())</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔍 The Power of SQL</h2><a id="user-content--the-power-of-sql" aria-label="Permalink: 🔍 The Power of SQL" href="#-the-power-of-sql"></a></p>
<p dir="auto">While Korvus provides a high-level interface in multiple programming languages, its core operations are built on optimized SQL queries. This approach offers several advantages:</p>
<ul dir="auto">
<li><strong>Transparency</strong>: Advanced users can inspect and understand the underlying queries.</li>
<li><strong>Customizability</strong>: Extend Korvus's capabilities by modifying or adding to its SQL operations.</li>
<li><strong>Performance</strong>: Benefit from PostgreSQL's advanced query optimization capabilities.</li>
</ul>
<p dir="auto">Don't worry if you're not a SQL expert - Korvus's intuitive API abstracts away the complexity while still allowing you to harness the full power of SQL-based operations.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">📘 Documentation</h2><a id="user-content--documentation" aria-label="Permalink: 📘 Documentation" href="#-documentation"></a></p>
<p dir="auto">For comprehensive documentation, including API references, tutorials, and best practices, visit our <a href="https://postgresml.org/docs/open-source/korvus/" rel="nofollow">official documentation</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🌐 Community</h2><a id="user-content--community" aria-label="Permalink: 🌐 Community" href="#-community"></a></p>
<p dir="auto">Join our community to get help, share ideas, and contribute:</p>
<ul dir="auto">
<li><a href="https://discord.gg/DmyJP3qJ7U" rel="nofollow">Discord</a></li>
<li><a href="https://x.com/postgresml" rel="nofollow">Twitter</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🤝 Contributing</h2><a id="user-content--contributing" aria-label="Permalink: 🤝 Contributing" href="#-contributing"></a></p>
<p dir="auto">We welcome contributions to Korvus! Please read our <a href="https://github.com/postgresml/korvus/blob/main/CONTRIBUTING.md">Contribution Guidelines</a> before submitting pull requests.</p>
<hr>
<p dir="auto">Korvus is maintained by <a href="https://postgresml.org/" rel="nofollow">PostgresML</a>. For enterprise support and consulting services, please <a href="https://postgresml.org/contact" rel="nofollow">contact us</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Shining actress Shelley Duvall dies at 75 (137 pts)]]></title>
            <link>https://www.bbc.com/news/articles/cy77p22jr5lo</link>
            <guid>40938092</guid>
            <pubDate>Thu, 11 Jul 2024 16:06:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/cy77p22jr5lo">https://www.bbc.com/news/articles/cy77p22jr5lo</a>, See on <a href="https://news.ycombinator.com/item?id=40938092">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div data-testid="byline" data-component="byline-block"><p><time>4 hours ago</time></p><div><p><span data-testid="byline-name">By&nbsp;<!-- -->Ian Youngs<!-- -->,&nbsp;<!-- --></span><span>Culture reporter</span></p></div></div><figure><div data-component="image-block"><p><img src="https://www.bbc.com/bbcx/grey-placeholder.png"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/8562/live/3bd49400-24e6-11ef-baa7-25d483663b8e.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/8562/live/3bd49400-24e6-11ef-baa7-25d483663b8e.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/8562/live/3bd49400-24e6-11ef-baa7-25d483663b8e.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/8562/live/3bd49400-24e6-11ef-baa7-25d483663b8e.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/8562/live/3bd49400-24e6-11ef-baa7-25d483663b8e.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/8562/live/3bd49400-24e6-11ef-baa7-25d483663b8e.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/8562/live/3bd49400-24e6-11ef-baa7-25d483663b8e.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/8562/live/3bd49400-24e6-11ef-baa7-25d483663b8e.jpg.webp" loading="eager" alt="Getty Images Shelley Duvall smiling in front of a bright red umbrella"><span>Getty Images</span></p></div><p data-component="caption-block"><figcaption>Shelley Duvall spent 20 years out of the Hollywood spotlight<!-- --></figcaption></p></figure><div data-component="text-block"><p>US actress Shelley Duvall, known for films like The Shining, Annie Hall and Nashville, has died at the age of 75.<!-- --></p><p>Her partner Dan Gilroy <!-- --><a target="_blank" href="https://www.hollywoodreporter.com/movies/movie-news/shelley-duvall-dead-shining-actress-1235946118/">confirmed the news to The Hollywood Reporter<!-- --></a>. <!-- --></p><p>"My dear, sweet, wonderful life partner and friend left us. Too much suffering lately, now she’s free. Fly away, beautiful Shelley," he said, according to the outlet.<!-- --></p><p>She died in her sleep of complications from diabetes at her home in Texas, Gilroy said.<!-- --></p><p>Duvall's other credits included 1977 drama 3 Women, directed by Robert Altman, for which she won the Cannes Film Festival's best actress award and was nominated for a Bafta.<!-- --></p><p>Three years later, she starred as Olive Oyl opposite Robin Williams in Altman's musical version of Popeye.<!-- --></p><p>But Duvall fell out of favour in Hollywood and was off screens for two decades, before making her comeback in 2023's The Forest Hills.<!-- --></p></div><figure><div data-component="image-block"><p><img src="https://www.bbc.com/bbcx/grey-placeholder.png"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/cc8c/live/4ddb4b30-24e6-11ef-a13a-0b8c563da930.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/cc8c/live/4ddb4b30-24e6-11ef-a13a-0b8c563da930.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/cc8c/live/4ddb4b30-24e6-11ef-a13a-0b8c563da930.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/cc8c/live/4ddb4b30-24e6-11ef-a13a-0b8c563da930.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/cc8c/live/4ddb4b30-24e6-11ef-a13a-0b8c563da930.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/cc8c/live/4ddb4b30-24e6-11ef-a13a-0b8c563da930.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/cc8c/live/4ddb4b30-24e6-11ef-a13a-0b8c563da930.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/cc8c/live/4ddb4b30-24e6-11ef-a13a-0b8c563da930.jpg.webp" loading="lazy" alt="Getty Images Shelley Duvall talking to Woody Allen in a shot from Annie Hall"><span>Getty Images</span></p></div><p data-component="caption-block"><figcaption>Duvall's character went on a date with Woody Allen in Annie Hall<!-- --></figcaption></p></figure><div data-component="text-block"><p>With her large brown eyes and offbeat charisma, Duvall was a distinctive and compelling presence.<!-- --></p><p>She began her career, and her association with Altman, in 1970 dark comedy Brewster McCloud, and the pair reunited for McCabe and Mrs Miller in 1971. <!-- --></p><p>After filming her performance as a woman who falls for a 1930s bank robber in their next movie, Thieves Like Us, Altman told her: "I knew you were good, but I didn't know you were great."<!-- --></p><p>She said that remark was "the reason I stuck with it and became an actress".<!-- --></p><p>The director stuck with her, once saying she "was able to swing all sides of the pendulum: charming, silly, sophisticated, pathetic, even beautiful".<!-- --></p><p>Altman cast her again in 1975's Nashville, his satire of US society, politics and country music.<!-- --></p><p>Their next collaboration, 3 Women, saw Duvall play a talkative, trend-following health spa attendant. <!-- --><a target="_blank" href="https://www.theguardian.com/culture/article/2024/jul/11/shelley-duvall-best-films-ranked">The Guardian's Anne Billson ranked it as<!-- --></a> her best role, and "quite simply one of the greatest performances of the 1970s".<!-- --></p><p>Meanwhile, also in 1977, Duvall memorably played Pam, a Rolling Stone reporter who went on a date with Woody Allen's Alvy in Annie Hall.<!-- --></p></div><figure><div data-component="image-block"><p><img src="https://www.bbc.com/bbcx/grey-placeholder.png"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/0a01/live/26031930-24e6-11ef-80aa-699d54c46324.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/0a01/live/26031930-24e6-11ef-80aa-699d54c46324.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/0a01/live/26031930-24e6-11ef-80aa-699d54c46324.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/0a01/live/26031930-24e6-11ef-80aa-699d54c46324.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/0a01/live/26031930-24e6-11ef-80aa-699d54c46324.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/0a01/live/26031930-24e6-11ef-80aa-699d54c46324.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/0a01/live/26031930-24e6-11ef-80aa-699d54c46324.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/0a01/live/26031930-24e6-11ef-80aa-699d54c46324.jpg.webp" loading="lazy" alt="Getty Images Shelley Duvall screaming as an axe comes through a door in a shot from The Shining"><span>Getty Images</span></p></div><p data-component="caption-block"><figcaption>Filming The Shining took its toll on Duvall<!-- --></figcaption></p></figure><div data-component="text-block"><p>Her best-known role was perhaps Wendy, the wife of Jack Nicholson's terrifying hotel caretaker in Stanley Kubrick's 1980 horror classic The Shining.<!-- --></p><p>Filming was an ordeal. "I had to cry 12 hours a day, all day long, the last nine months straight, five or six days a week," she once recalled.<!-- --></p><p>After that, Duvall's film roles included Terry Gilliam's Time Bandits and Roxanne with Steve Martin.<!-- --></p><p>She also set up her own production companies, and made and hosted beloved 1980s children's TV show Faerie Tale Theatre.<!-- --></p><p>Her acting roles diminished in the 1990s, with Jane Campion’s The Portrait of a Lady the pick of the crop, and she dropped off the radar in 2002.<!-- --></p><p>The New York Times attributed her apparent disappearance to the impact of a 1994 earthquake that damaged her Los Angeles home, and the stress of her brother having cancer.<!-- --></p><p>Discussing her prolonged absence from the screen, <!-- --><a target="_blank" href="https://www.nytimes.com/2024/04/25/style/shelley-duvall.html">she told the paper<!-- --></a> in May she had been the victim of a fickle film industry. "I was a star. I had leading roles. People think it's just ageing, but it's not. It's violence," she said.<!-- --></p><p>Asked to explain, she said: "How would you feel if people were really nice, and then, suddenly, on a dime they turn on you?<!-- --></p><p>"You would never believe it unless it happens to you. That's why you get hurt, because you can't really believe it's true."<!-- --></p></div><p data-component="subheadline-block"><h2>'Ultimate film star'<!-- --></h2></p><div data-component="text-block"><p>Concerns about her health were raised when she appeared on the TV talk show Dr Phil in 2016 and told him: "I'm very sick. I need help."<!-- --></p><p>She also talked about receiving messages from a "shapeshifting" Robin Williams following his death, and talked about malevolent forces who were out to do her harm, the paper said.<!-- --></p><p>Speaking about that period, Gilroy told the New York Times she had become "paranoid and just kind of delusional".<!-- --></p><p>Asked by the paper why she had agreed to return to the screen in The Forest Hills, she replied: "I wanted to act again. And then this guy kept calling, and so I wound up doing it."<!-- --></p><p><a target="_blank" href="https://www.ft.com/content/c1717d96-7169-4223-8b17-cbb666be3a4b">Novelist Nicole Flattery wrote in the Financial Times<!-- --></a> in 2023 that her return showed her magic had remained intact.<!-- --></p><p>In an article dubbing her the "ultimate film star", Flattery summed up her talent, writing: "She’s a master at playing characters who act happy when they’re sad, their daffiness masking depth."<!-- --></p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to Survive 3 Years in North Korea as a Foreigner (159 pts)]]></title>
            <link>https://mydiplomaticlife.com/how-to-survive-3-years-in-north-korea-as-a-foreigner/</link>
            <guid>40937973</guid>
            <pubDate>Thu, 11 Jul 2024 15:52:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mydiplomaticlife.com/how-to-survive-3-years-in-north-korea-as-a-foreigner/">https://mydiplomaticlife.com/how-to-survive-3-years-in-north-korea-as-a-foreigner/</a>, See on <a href="https://news.ycombinator.com/item?id=40937973">Hacker News</a></p>
Couldn't get https://mydiplomaticlife.com/how-to-survive-3-years-in-north-korea-as-a-foreigner/: Error: Request failed with status code 409]]></description>
        </item>
        <item>
            <title><![CDATA[Iconography of the X Window System: The Boot Stipple (126 pts)]]></title>
            <link>https://matttproud.com/blog/posts/x-window-system-boot-stipple.html</link>
            <guid>40936808</guid>
            <pubDate>Thu, 11 Jul 2024 13:48:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matttproud.com/blog/posts/x-window-system-boot-stipple.html">https://matttproud.com/blog/posts/x-window-system-boot-stipple.html</a>, See on <a href="https://news.ycombinator.com/item?id=40936808">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
  

  
  
  <time datetime="2024-07-11T07:03:36+02:00">July 11, 2024</time>

  <p>If you are of a certain vintage, this image is burned indelibly somewhere
in your posterior parietal complex:</p>
<p><img src="https://matttproud.com/blog/x-window-system-boot-stipple/root_weave_640x480.png" alt="640 x 480 of “root_weave”"></p>
<p>Oh, my old friend.  How it’s been a long time.</p>
<h2 id="cultural-significance">Cultural Significance</h2>
<p>For the uninitiated, what are we looking at?  Could it be the <a href="https://doomwiki.org/wiki/Moir%C3%A9_error">Moiré Error</a> from
Doom? Well, no. You are looking at (part of) the boot up screen for the <a href="https://en.wikipedia.org/wiki/X_Window_System">X
Window System</a>, specifically the pattern it uses as the background of the <a href="https://en.wikipedia.org/wiki/Root_window">root
window</a>.  This pattern is technically called a <a href="https://www.merriam-webster.com/dictionary/stipple">stipple</a>.</p>
<p>What you’re seeing is pretty important and came to symbolize a lot for me as a
computer practitioner.  Over time, I came to develop a relationship with it
roughly as this:</p>
<blockquote>
<p>[…] if you gaze for long into a stipple, the stipple gazes also into you.</p>
</blockquote>
<p>What would compel me to say that?</p>
<p>Well, part of it is nostalgia, but the other part is practical.  For a long time
the X Window System had a reputation for being difficult to configure.  In
retrospect, I’m not 100% sure why it earned this reputation, because the
<a href="https://en.wikipedia.org/wiki/XF86Config">configuration file format</a>, which is plain text, has remained essentially the
same since I started using Linux in the mid-1990s.  On the other hand, the
amount of hand-written input required for the configuration file has fallen
gradually over time.  This is where the critique lies: the amount of information
that needed to be gathered.  In the old days, it used to be that mouse,
keyboard, video card, monitor, fonts, plugin+module data, etc. needed to be
spelled out in detail in <code>/etc/X11/XF86Config</code>.  If you were starting out with a
bare configuration file (e.g., after a fresh install of a system), researching
the necessary parameters for your hardware could be a real pain in the ass.  In
this era, I had dial-up Internet, and Google wasn’t a thing yet.</p>
<p>And this leads to to an interesting observation: <strong>you wouldn’t want to wing it
with the configuration</strong>, because allegedly <a href="https://superuser.com/questions/126523/can-one-really-fry-a-monitor-by-setting-the-wrong-horizsync-and-vertrefresh">you could break your monitor with a
bad <code>Monitor</code> setting</a>.  That never happened to me or my friends, or at least
none of my friends ever fessed up to it happening to them.  What I will fess up
to is giving my monitor a bad case of electrical whine on a few occasions.  Here
is an example <code>Monitor</code> setting found in an <code>XF86Config</code> file from Red Hat 5.0
(1997–8) vintage) to give you an idea of just the level of detail required for
the monitor:</p>
<div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="text"><span><span>Section "Monitor"
</span></span><span><span>  Identifier "My Monitor"
</span></span><span><span>  VendorName "Unknown"
</span></span><span><span>  ModelName "Unknown"
</span></span><span><span>
</span></span><span><span>  # HorizSync is in kHz unless units are specified.
</span></span><span><span>  # NOTE: THE VALUES HERE ARE EXAMPLES ONLY.  REFER TO YOUR MONITOR'S
</span></span><span><span>  # USER MANUAL FOR THE CORRECT NUMBERS.
</span></span><span><span>
</span></span><span><span>  HorizSync 31.5
</span></span><span><span>
</span></span><span><span>  # VertRefresh is in Hz unless units are specified.
</span></span><span><span>  # NOTE: THE VALUES HERE ARE EXAMPLES ONLY.  REFER TO YOUR MONITOR'S
</span></span><span><span>  # USER MANUAL FOR THE CORRECT NUMBERS.
</span></span><span><span>
</span></span><span><span>  VertRefresh 50-70
</span></span><span><span>
</span></span><span><span>  # Modes can be specified in two formats.  A compact one-line format, or a
</span></span><span><span>  # multi-line format.
</span></span><span><span>  #
</span></span><span><span>  # These two are equivalent:
</span></span><span><span>  
</span></span><span><span>  # ModeLine "1024x768i" 45 1024 1048 1208 1264 768 776 784 817 Interlace
</span></span><span><span>  #
</span></span><span><span>  # Mode "1024x768i"
</span></span><span><span>  #   DotClock 45
</span></span><span><span>  #   HTimings 1024 1048 1208 1264
</span></span><span><span>  #   VTimings 768 776 784 817
</span></span><span><span>  #   Flags "Interlace"
</span></span><span><span>  # EndMode
</span></span><span><span>EndSection
</span></span></code></pre></td></tr></tbody></table>
</div><p>Did your blood pressure raise looking at that?  Mine did.  Remember: this
information wasn’t a casual Google Search away for many of us back then.</p>
<p>So what does this have to do with the stipple I mentioned earlier?  Combine the
onerousness of configuration above with the fact that computers weren’t
particularly fast, and the answer will become clear.  I recall in the era that
the X Window System took on the order of — what felt like — tens of seconds to
start even for relatively simple <a href="https://en.wikipedia.org/wiki/X_window_manager">window managers</a> like <a href="https://en.wikipedia.org/wiki/Twm">twm</a>.  <em>We were using
spinning disks, after all!</em>  So it could take a while to get the X Window System
properly configured through trial and error. Misconfiguration could mean any of
the following:</p>
<ul>
<li>(allegedly) frying your hardware</li>
<li>suboptimal display (e.g., bad resolution, missing fonts) operation</li>
<li>misconfigured peripheral (e.g., no mouse)</li>
<li>misconfigured user space windowing environment (e.g., no window manager, or
it is broken)</li>
</ul>
<p>As I have gotten older, I became acutely aware that one of the most important
things that matters for technical learning and productive use is a tight
edit-run cycle<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>; and that’s where the stipple comes in.  That stipple above
is <strong>the first thing</strong> that the X Window System would display on startup if
things were going reasonably well with the X Server and its configuration. So
seeing that meant you knew the things were at least partially (if not most of
the way) working. And that was because it could take multiple seconds longer for
the window manager to follow with its startup.  Heaven forbid you were starting
a full-blown desktop environment in this era.</p>
<p>Was this the stipple’s actual purpose?  I’m frankly uncertain.  I’d hoped that
someone would have written about this already, but nobody really has — at least
that I could find.  The best I found is a whimsical <a href="https://web.archive.org/web/20130322160540/http://www.openbsd.org/faq/faq11.html">historical excerpt from the
OpenBSD FAQ</a>:</p>
<blockquote>
<p>We test as above, and… SUCCESS! We have what appears to be a very nice, high
resolution display. Note that ALL that is expected is a mesh pattern (very
good for seeing how good your monitor REALLY is and also great for calibrating
LCD displays, called the “root weave”) and a movable cursor. It is not
intended to be functional at this point.</p>
</blockquote>
<p>Nevertheless, given OpenBSD’s reputation of being a methodical project, I’m
inclined to give the FAQ authors some credence.  The early smoke testing success
signal combined with implicit branding seem like as good of a guess as any.</p>
<h2 id="today">Fast Forward to Today</h2>
<p>So why write about something that seems purely like an indulgence?  Surely the
stipple still lives with us today and requires no further discussion?  Well, up
until the early-2010s (at least on the Linux distributions I was using), this
boot up scene was common to see — <strong>until it suddenly wasn’t</strong>.</p>
<p>Linux distributions had a reputation for not being particularly bleeding edge
with the packages they contained.  So to my surprise one day this startup
behavior just stopped.  I took note of it, but I never researched why (life
comes at you fast, and I was distracted by more important things: moving abroad,
starting a family, starting a new job, etc).</p>
<p>So why did the stipple go away?  I’m not terribly certain to be honest (there
was no central bug tracker<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>), but I’ll posit some guesses based on the
contextual history:</p>
<p>There was a desire in the mid-2000s to 2010s to improve the boot speed of Linux
and its overall accessibility to newcomers.  <a href="https://canonical.com/">Canonical</a> was sinking a lot of cash
into <a href="https://en.wikipedia.org/wiki/Ubuntu">Ubuntu</a> as well as <a href="https://en.wikipedia.org/wiki/Mir_(software)">Mir</a>. This was also happening in the backdrop of
<a href="https://en.wikipedia.org/wiki/Systemd">systemd</a>’s development.  In short, there was concerted momentum to modernize
the ecosystem.</p>
<p>According to my detective work, in September 2008, a commit lands
(<a href="https://gitlab.freedesktop.org/xorg/xserver/-/commit/0bb317a78b96fddcdac319c9706b3a12f931ea44">0bb317a78b96fddcdac319c9706b3a12f931ea44</a>) in the <a href="https://www.x.org/wiki/">X.Org</a> server that adds a
flag to the X Server called <code>-retro</code> that backs a global variable called
<code>party_like_its_1989</code>. This commit removes the default stipple and the customary
<a href="https://gitlab.freedesktop.org/xorg/font/xfree86-type1/-/blob/e2a0089fc5b6404a6ab417ec6b1b75645283358f/cursor.pfa"><code>X_cursor</code></a> behaviors from boot, which look like this:</p>
<p><img src="https://matttproud.com/blog/x-window-system-boot-stipple/xfree86-startup.png" alt="X Window System starting up"></p>
<p>Looking at this, the global variable’s name alone tells us the sentiment: out
with the old; in with the new.  I’m just surprised it took several years for the
new default behavior to land in whatever distribution I was using at the time,
which is why I made the remark above about distributions not having been super
bleeding edge.  Why did it take until the mid-2010s for me to notice the
disappearance?</p>
<p>Thinking aloud, the flag’s help description of <code>"start with classic stipple and cursor"</code> doesn’t really do a good service to the reader.  Let me give you a
concrete formulation of what I mean: <strong>have you ever encountered the word
“stipple” before reading this, and did you already know what the word means?</strong> I
don’t want to be unkind to the maintainers, but I think this flag’s description
is probably lost on a majority of readers (probably intentionally so).</p>
<h3 id="getting-it-back">Getting our Stipple Back</h3>
<p>All of this talk about the stipple’s evoking a desire to bring it back.  So how
do we do that in modern software?  Do you still use <a href="https://www.x.org/releases/X11R7.6/doc/man/man1/startx.1.xhtml"><code>startx</code></a> to start your X
Server?  I’m guessing not; but if you did, it’s as easy as:</p>
<div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="shell"><span><span>startx -- -retro  <span># note the preceeding -- to provide options to the X Server</span>
</span></span></code></pre></td></tr></tbody></table>
</div><p>To make that permanent with <code>startx</code>, you could amend your <code>~/.xserverrc</code> file
to include the <code>-retro</code> flag:</p>
<div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="shell"><span><span>cp -i /etc/X11/xinit/xserverrc ~/.xserverrc
</span></span><span><span>cat ~/.xserverrc
</span></span><span><span><span>#!/bin/sh</span>
</span></span><span><span>
</span></span><span><span><span>exec</span> /usr/bin/X -nolisten tcp<span>" "</span><span>${</span><span>@</span><span>}</span><span>"  # add -retro before the -nolisten
</span></span></span></code></pre></td></tr></tbody></table>
</div><p>And of course a similar workflow as the above can be applied to all users on
the system if you amend the <code>/etc/X11/xinit/xserverrc</code> file.</p>
<p>If you are using <a href="https://en.wikipedia.org/wiki/GNOME_Display_Manager">GNOME Display Manager</a> (GDM), you
appear to be out of luck with due to the <a href="https://github.com/GNOME/gdm/blob/main/daemon/gdm-x-session.c"><code>/usr/libexec/gdm-x-session</code></a> shim not
providing a mechanism to pass through arbitrary options to the X Server.</p>
<p>Users of <a href="https://en.wikipedia.org/wiki/XDM_(display_manager)">X Display Manager</a> (XDM) can amend <code>/etc/X11/xdm/Xservers</code> file to
include the <code>-retro</code> argument à la:</p>
<div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="shell"><span><span>:0 <span>local</span> /usr/bin/X :0 vt7 -retro -nolisten tcp
</span></span></code></pre></td></tr></tbody></table>
</div><p>Users of <a href="https://en.wikipedia.org/wiki/LightDM">LightDM</a> can amend the <code>/etc/lightdm/lightdm.conf</code> file such that it
includes the following stanza:</p>
<div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span><span>2
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="text"><span><span>[Seat:*]
</span></span><span><span>xserver-command = /usr/lib/xorg/Xorg -retro
</span></span></code></pre></td></tr></tbody></table>
</div><p>I’m sure there’s a way to do this with <a href="https://en.wikipedia.org/wiki/Simple_Desktop_Display_Manager">SDDM</a>, but it won’t install on my machine
due to a networking problem.</p>
<p>Failing that, you can always use <a href="https://www.x.org/releases/X11R7.6/doc/man/man1/xsetroot.1.xhtml"><code>xsetroot</code></a> to just replace your root window’s
background.</p>
<p>But — wow — isn’t that a fuck-ugly fractal of fragmentation?  I mean, I get on a
technical level why each thing that is managing the X Server takes a different
approach (independent development by individual engineers with different design
philosophies and requirements), but this just a stupid amount of toil to pass a
measly flag. I guess it’s a shame that X.Org went the flag route and didn’t
expose a mechanism in the X Server’s configuration file.</p>
<h2 id="definition">Definition of the Stipple</h2>
<p>So how is the stipple defined?  Is it defined as a file (asset) for the X Server
to load at runtime? This part sent me on a goose chase.  I did not discover
commit <a href="https://gitlab.freedesktop.org/xorg/xserver/-/commit/0bb317a78b96fddcdac319c9706b3a12f931ea44">0bb317a78b96fddcdac319c9706b3a12f931ea44</a> until relatively late in my
research, and it would have simplified my research into this question.</p>
<p>Herein lies some fun duality; the stipple is defined <strong>both</strong>:</p>
<ul>
<li>statically in the X Window System source code in device-independent X
(<a href="https://www.x.org/wiki/Development/Documentation/XserverSourceLayout/">dix</a>)’s (<a href="https://gitlab.freedesktop.org/xorg/xserver/-/blob/72036261738c10d718cb42696289ae85b7f6f703/dix/window.c#L542-550"><code>window.c</code></a>) as an inline value literal and</li>
<li>as a standalone <a href="https://en.wikipedia.org/wiki/X_BitMap">X BitMap</a> file called <a href="https://gitlab.freedesktop.org/xorg/data/bitmaps/-/blob/master/root_weave?ref_type=heads"><code>root_weave</code></a> that gets installed as a
file in <code>/usr/include/X11/bitmaps/root_weave</code></li>
</ul>
<p>For startup, however, the X Window System only uses the static source code
definition (the data backing the <code>_back_lsb</code> or <code>_back_msb</code> variables from dix’s
<code>window.c</code> based on your machine’s <a href="https://en.wikipedia.org/wiki/Endianness">endianness</a>).</p>
<p>Behold, the stipple has a real name: <strong>root weave</strong>!</p>
<p><strong>Note:</strong> The definition of the root weave bitmap data literal and that of the
file appear to be different.</p>
<h2 id="history">History of the Root Weave</h2>
<p>Now, if you clicked the link for <code>root_weave</code> above, you probably noticed an
interesting detail: this file was last changed approximately 20 years ago.  So
it’s old, right?  Well, this is where things get most interesting in my opinion.</p>
<p>Not that long ago, <a href="https://blog.dshr.org/2024/07/x-window-system-at-40.html">we celebrated the X Window System’s 40th birthday</a>!  And
this led to me wonder: could we determine the introduction of root weave?</p>
<p>I worked backwards:</p>
<ul>
<li>I skipped checking the X.Org sources, because I knew root weave existed long
before, and I remember the X.Org and XFree86 schism relatively well.</li>
<li>OK.  Now on to <a href="https://en.wikipedia.org/wiki/XFree86">XFree86</a>.  Well, here’s the initial<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> commit from <code>Wed Apr 27 07:07:10 1994 +0000</code> (approximately 30 years ago) introducing it, so evidently
we didn’t go far enough back:
<ul>
<li><a href="https://gitlab.freedesktop.org/ajax/xfree86/-/blob/03432c3ccba2746d2fb95a636a87fe732bede83c/programs/Xserver/dix/window.c#L83-84">https://gitlab.freedesktop.org/ajax/xfree86/-/blob/03432c3ccba2746d2fb95a636a87fe732bede83c/programs/Xserver/dix/window.c#L83-84</a></li>
<li><a href="https://gitlab.freedesktop.org/ajax/xfree86/-/blob/fa85847d3586bfdd5abd4d495668d9b47ff56545/include/bitmaps/root_weave">https://gitlab.freedesktop.org/ajax/xfree86/-/blob/fa85847d3586bfdd5abd4d495668d9b47ff56545/include/bitmaps/root_weave</a></li>
</ul>
</li>
<li>So what predates XFree86?  Was XFree86 derived or forked from something else?
Can we find anything in source released from <a href="https://en.wikipedia.org/wiki/Project_Athena">Project Athena</a>?  Luckily X.Org
has a <a href="https://www.x.org/releases/">historical release archive</a>.  I trawled through the predecessors of
X11, and sure enough all of them have both the static source definition and
the bitmap!  The earliest release they had was X10R3, which according to
Wikipedia dates to February 1986.</li>
</ul>
<p>So, I think we can conclude that root weave hails from somewhere between June
1984 (X1) and February 1986.</p>
<h2 id="bitmap-ecosystem">An Ecosystem of X BitMap Files</h2>
<p>It turns out that root weave is not the only X BitMap file that comes installed,
and there are a bunch of other ones that are about as old as it.  We
have some other weaves:</p>
<ul>
<li>
<p>cross weave: kind of meh</p>
<p><img src="https://matttproud.com/blog/x-window-system-boot-stipple/cross_weave_640x480.png" alt="640 x 480 of “cross_weave”"></p>
</li>
<li>
<p>wide weave: I like it</p>
<p><img src="https://matttproud.com/blog/x-window-system-boot-stipple/wide_weave_640x480.png" alt="640 x 480 of “wide_weave”"></p>
</li>
</ul>
<p>And there are plenty of others bitmaps (some newer).  I made a quick <a href="https://en.wikipedia.org/wiki/Contact_print">contact
sheet</a> using <a href="https://imagemagick.org/">ImageMagick</a>:</p>
<div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="shell"><span><span>montage -verbose -label <span>'%f'</span> -font <span>"Go-Mono"</span> -pointsize <span>10</span> <span>\
</span></span></span><span><span><span></span>  -background <span>'#000000'</span> -fill <span>'gray'</span> -tile <span>'4x5'</span> -border <span>5</span> <span>\
</span></span></span><span><span><span></span>  -bordercolor <span>'#888888'</span> -auto-orient <span>$(</span><span>echo</span> * <span>|</span> sort<span>)</span> /tmp/contact.png
</span></span></code></pre></td></tr></tbody></table>
</div><ul>
<li>
<p>sheet 0</p>
<p><img src="https://matttproud.com/blog/x-window-system-boot-stipple/contact-0.png" alt="X BitMap Contact: 0"></p>
</li>
<li>
<p>sheet 1</p>
<p><img src="https://matttproud.com/blog/x-window-system-boot-stipple/contact-1.png" alt="X BitMap Contact: 1"></p>
</li>
<li>
<p>sheet 2</p>
<p><img src="https://matttproud.com/blog/x-window-system-boot-stipple/contact-2.png" alt="X BitMap Contact: 2"></p>
</li>
<li>
<p>sheet 3</p>
<p><img src="https://matttproud.com/blog/x-window-system-boot-stipple/contact-3.png" alt="X BitMap Contact: 3"></p>
</li>
</ul>
<p>I’m certain there is some fun and weird history with these images.  Is there
anyone around who can recount it, though?  The one that caught my eye was
“woman”.  OK, why is there one called “woman,” and why is it so aesthetically
different from the rest?  By coincidence, in my research I came across the
<a href="https://www.x.org/wiki/X11R1/">release notes for X11R1</a>; it hints that “woman” was used to demonstrate a
regression in the server’s code:</p>
<blockquote>
<p>With the “woman” bitmap, the small images are corrupt on color screens (server
bug likely). The program dumps core when colors are specified in .Xdefaults.</p>
<p>…</p>
<p>Among other things, try the command “xsetroot -bitmap include/bitmaps/woman”.</p>
</blockquote>
<p>Curious.</p>
<h2 id="detours">Other Detours</h2>
<p>Seminal software often inspires and influences other software.  Sometimes these
others are derivative products.  A good analogue for this are derivative game
engines and the tree they form (e.g., <a href="https://en.wikipedia.org/wiki/Quake_engine#Derivative_engines">Quake I derivatives</a>).  This exercise
prompted a whole bunch of fundamental history questions around software
provenance and lineage to which I didn’t have the answer:</p>
<ul>
<li>
<p>What was XFree86 based on?  Was it a <a href="https://en.wikipedia.org/wiki/Clean_room_design">clean room implementation</a> or a
derivative?  I simply didn’t know.  It turns out XFree86 is derived from the
original Project Athena.</p>
</li>
<li>
<p>What about other X Window System servers, particularly commercial ones?</p>
<ul>
<li>
<p>For instance, what about the X Server for Solaris?  Solaris 9 (I have no
ability to check earlier releases) also includes the same weave X BitMap
files.  As best as I can tell, its native X Server (<code>Xsun</code>) is a derivative
of Project Athena.</p>
</li>
<li>
<p>And one of the first Linux installations I ever used came with a commercial
X Server made by the now-defunct company <a href="https://web.archive.org/web/20030731165914/http://metrolink.com/">Metro Link</a>, which offered a
low-touch server called <a href="https://web.archive.org/web/20030812132431/http://www.metrolink.com/products/metrox/index.html">Metro-X</a>.<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>  I managed to find an ISO
of Red Hat 5.0 with Metro-X, so I booted it up.  Nearly same story with it
including these weaves, too.  This server looks to be more closely related
to XFree86, though.</p>
<p>What was fascinating about Metro-X was that it was legitimately easy to
configure in this era of non-trivial setup (even for newbies).  I remember
that fondly.  It had somewhat modern — by today’s standards — X Server
device probing functionality that just worked.</p>
<p>Here are some screenshots from the Metro-X setup wizard (it looks like it
is built on <a href="https://en.wikipedia.org/wiki/Motif_(software)">Motif</a>, which would have been customary for the era, based
on the symbols in the <code>configX</code> binary):</p>
<p><img src="https://matttproud.com/blog/x-window-system-boot-stipple/metro-x-splash.png" alt="Metro-X Splash"></p>
<p><img src="https://matttproud.com/blog/x-window-system-boot-stipple/metro-x-display.png" alt="Metro-X Display Settings"></p>
<p><img src="https://matttproud.com/blog/x-window-system-boot-stipple/metro-x-card.png" alt="Metro-X Card Settings"></p>
<p>Again, all of this was automatically probed correctly, which is nuts
considering this is Linux in 1997 (Linux Kernel 2.0.32).</p>
<p>1998-era XFree86 came with a graphical configurator, but I don’t recall it
having any autoprobing capability; it merely managed the configuration file.
Let’s contrast Metro-X’s <code>configX</code> with XFree86’s <code>XF86Setup</code>, a <a href="https://en.wikipedia.org/wiki/X_Athena_Widgets">X Athena
Widgets</a> and TCL-based tool that appears to be short-lived (removed in
2003):</p>
<p><img src="https://matttproud.com/blog/x-window-system-boot-stipple/xf86setup-splash.png" alt="XF86Setup Splash"></p>
<p><img src="https://matttproud.com/blog/x-window-system-boot-stipple/xf86setup-mouse.png" alt="XF86Setup Mouse"></p>
<p><img src="https://matttproud.com/blog/x-window-system-boot-stipple/xf86setup-keyboard.png" alt="XF86Setup Keyboard"></p>
<p><img src="https://matttproud.com/blog/x-window-system-boot-stipple/xf86setup-card.png" alt="XF86Setup Card"></p>
<p><img src="https://matttproud.com/blog/x-window-system-boot-stipple/xf86setup-monitor.png" alt="XF86Setup Monitor"></p>
<p><img src="https://matttproud.com/blog/x-window-system-boot-stipple/xf86setup-modeselection.png" alt="XF86Setup Modeselection"></p>
<p><img src="https://matttproud.com/blog/x-window-system-boot-stipple/xf86setup-other.png" alt="XF86Setup Other"></p>
<p>Regrettably Metro Link appears to have folded in October 2003, so the rest
will be in the annals of history.</p>
</li>
</ul>
</li>
</ul>
<h2 id="revisiting">Revisiting the Era with Fresh Eyes</h2>
<p>Playing around with several old versions of Linux and adjacent ecosystem
software provided an opportunity to see if the good ol’ days were in fact any
good.  Well, to be honest, this was some rough software to work with.  A lot of
creature comforts that I am used to are not there (e.g., no <code>-r</code> flag for
<code>grep</code>), and the overall user experience is extremely unpolished.  If we take a
step back from configuring the X Servers of that era and look at how the servers
are bootstrapped in terms of how <code>startx</code> and friends are implemented, wow, it
is a lot more complicated (e.g., <code>serverargs</code> and <code>clientargs</code> machinations that
look well intentioned but also incredibly fragile).</p>
<p>To counterbalance that, I have to say in spite of some improvements in the
intervening years, Linux and X seem like an accretion disk. Not enough acquired
complexity was shed.</p>
<p>I will remark that in spite of my job being a software engineer, I had never
spent a lot of time looking at the source code for the X Server (XFree86 or
X.Org) before.  It’s really nuts to see that a lot of the architecture from
X10R3 and X11R1 still persists in the code today, which is a statement that can
be said in deep admiration for legacy code but also disturbance from the power
of old decisions. Without having looked at the internals of any Wayland
implementation, I can sympathize sight unseen with the sentiments that some
developers have toward the X Window System: the code is a dead end.  I say that
with the utmost respect to the X Window System as a technology and an ecosystem.
I’ll keep using X, and I will be really sad when it’s no longer possible for me
to do so for one reason or another, as I’m extremely attached to it quirks.  But
it’s clear the future is limited.</p>
<h2 id="other-futures">Our Lost Futures</h2>
<p>We could have ended up with a different default stipple. The images above with
cross and wide weave hinted at that.</p>
<p>Here’s what it would have looked like with some of the other fun contenders from
the included bitmaps:</p>
<ul>
<li>
<p>tie_fighter</p>
<p><img src="https://matttproud.com/blog/x-window-system-boot-stipple/tie_fighter_640x480.png" alt="640 x 480 of “tie_fighter”"></p>
<p>Lucasfilm, Ltd. would not have approved.</p>
</li>
<li>
<p>xlogo16</p>
<p><img src="https://matttproud.com/blog/x-window-system-boot-stipple/xlogo16_640x480.png" alt="640 x 480 of “xlogo16”"></p>
<p>Maybe a wet dream a certain of Space Karen.  I personally like the X (as in X
Window System) logo when it stands on its own, and I wish it wasn’t now
tainted with the connotations of this booger.</p>
<p>Nevertheless, I’d like to imagine that there was a timeline where X had
stronger branding.</p>
</li>
</ul>
<p>And taking things in a more absurd direction, let’s consider <a href="https://en.wikipedia.org/wiki/Windows_3.1">Windows 3.1</a> with
respect to the stipples above.  Windows 3.1 had a very strong design language
in my mind — as did Windows NT up to and including Windows 2000.  It also turns
out that Windows 3.1 (maybe even Windows 3.0 if memory serves) had a
bitmap-style background pattern feature that included a pattern composition
tool.  So I took a stab at making the weaves in the editor:</p>
<p><img src="https://matttproud.com/blog/x-window-system-boot-stipple/win31-composer.png" alt="Windows 3.1 Pattern Composer"></p>
<p>Interesting, what would have Windows 3.1 have looked like with these weave
patterns?  Let’s find out!</p>
<ul>
<li>
<p>root weave</p>
<p><img src="https://matttproud.com/blog/x-window-system-boot-stipple/win31-root-weave.png" alt="Windows 3.1 Root Weave"></p>
</li>
<li>
<p>cross weave</p>
<p><img src="https://matttproud.com/blog/x-window-system-boot-stipple/win31-cross-weave.png" alt="Windows 3.1 Cross Weave"></p>
</li>
<li>
<p>wide weave</p>
<p><img src="https://matttproud.com/blog/x-window-system-boot-stipple/win31-wide-weave.png" alt="Windows 3.1 Wide Weave"></p>
</li>
</ul>
<p>All of this leads me to wonder what would Edward Tufte have said about the
original X ecosystem and its aesthetics.  A lot of it was spartan and clear, yet
there is some gratuitous <a href="https://books.google.ch/books/about/Visual_Design_of_the_User_Interface.html">administrative debris</a> here and there (like this
stipple).</p>
<h2 id="closing-words">Closing Words</h2>
<p>Diving deep into this gave me a lot of joy —&nbsp;and a great chance to revisit the
past. In case of errors, omissions, or other cool details, get in contact with
me.</p>
<p>So knowing now that root weave and all of that is from 1986, should I send X.Org
a pull request to rename the <code>party_like_its_1989</code> global variable to
<code>party_like_its_1986</code> or <code>party_like_the_1980s</code>.<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup>.  Something tells me
they wouldn’t welcome it.</p>


  
  


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft killed my online life after I called Gaza (236 pts)]]></title>
            <link>https://www.bbc.com/news/articles/cger582weplo</link>
            <guid>40935971</guid>
            <pubDate>Thu, 11 Jul 2024 12:31:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/cger582weplo">https://www.bbc.com/news/articles/cger582weplo</a>, See on <a href="https://news.ycombinator.com/item?id=40935971">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div data-testid="byline" data-component="byline-block"><p><time>14 hours ago</time></p><div><p><span data-testid="byline-name">By&nbsp;<!-- -->Mohamed Shalaby and Joe Tidy<!-- -->,&nbsp;<!-- --></span><span>BBC World Service</span></p></div></div><figure><div data-component="image-block"><p><img src="https://www.bbc.com/bbcx/grey-placeholder.png"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/3a75/live/9e6c73f0-3e9d-11ef-8cda-f95c899bb5f8.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/3a75/live/9e6c73f0-3e9d-11ef-8cda-f95c899bb5f8.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/3a75/live/9e6c73f0-3e9d-11ef-8cda-f95c899bb5f8.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/3a75/live/9e6c73f0-3e9d-11ef-8cda-f95c899bb5f8.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/3a75/live/9e6c73f0-3e9d-11ef-8cda-f95c899bb5f8.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/3a75/live/9e6c73f0-3e9d-11ef-8cda-f95c899bb5f8.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/3a75/live/9e6c73f0-3e9d-11ef-8cda-f95c899bb5f8.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/3a75/live/9e6c73f0-3e9d-11ef-8cda-f95c899bb5f8.jpg.webp" loading="eager" alt="Getty Images man charging his phone in a charging station in gaza strip "><span>Getty Images</span></p></div><p data-component="caption-block"><figcaption>The Israeli military campaign has badly affected internet and mobile connectivity in Gaza<!-- --></figcaption></p></figure><div data-component="text-block"><p><b id="palestinians-calling-home-to-gaza-on-skype-have-had-their-digital-lives-destroyed,-after-microsoft-closed-their-email-accounts-without-warning.">Palestinians calling home to Gaza on Skype have had their digital lives destroyed, after Microsoft closed their email accounts without warning. <!-- --></b></p><p>BBC News has spoken to 20 Palestinians living abroad who say Microsoft, which owns the voice and video chat app, kicked them out of their accounts. The total number affected is thought to be much higher. <!-- --></p><p>In some cases, these email accounts are more than 15 years old and the users have no way to retrieve emails, contacts or memories. <!-- --></p><p>Microsoft says they violated its terms of service - but will not say how - and the decision is final.<!-- --></p></div><p>The Gazans say they have no links to Hamas - designated as a terrorist organisation by some Western countries, including the US, where Microsoft is headquartered - and accuse the technology giant, the most valuable company in the world, of persecuting them unfairly.<!-- --></p><p data-component="subheadline-block"><h2>Switched off<!-- --></h2></p><div data-component="text-block"><p>Salah Elsadi is living in the US and, like many Palestinians abroad, was using Skype to call his wife, children and parents on their mobile phones in Gaza.<!-- --></p><p>The internet is frequently disrupted or switched off because of the Israeli military campaign - and standard international calls are very expensive. <!-- --></p><p>With a paid Skype subscription, it is possible to call mobiles in Gaza cheaply - and while the internet is down - so it has become a lifeline to many Palestinians. <!-- --></p><p>But in April, Mr Elsadi, like many others, was kicked out of his account - and all services linked to his Microsoft Hotmail account. <!-- --></p></div><figure><div data-component="image-block"><p><img src="https://www.bbc.com/bbcx/grey-placeholder.png"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/5a3f/live/d1877990-3ea4-11ef-96a8-e710c6bfc866.png.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/5a3f/live/d1877990-3ea4-11ef-96a8-e710c6bfc866.png.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/5a3f/live/d1877990-3ea4-11ef-96a8-e710c6bfc866.png.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/5a3f/live/d1877990-3ea4-11ef-96a8-e710c6bfc866.png.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/5a3f/live/d1877990-3ea4-11ef-96a8-e710c6bfc866.png.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/5a3f/live/d1877990-3ea4-11ef-96a8-e710c6bfc866.png.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/5a3f/live/d1877990-3ea4-11ef-96a8-e710c6bfc866.png.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/5a3f/live/d1877990-3ea4-11ef-96a8-e710c6bfc866.png.webp" loading="lazy" alt="Salah Elsadi "></p></div><p data-component="caption-block"><figcaption>Salah Elsadi says he has been locked out of life online<!-- --></figcaption></p></figure><div data-component="text-block"><p>He has missed out on job offers and can no longer access his bank accounts, which are tied to his Hotmail account, he says.<!-- --></p><p>"I've had this Hotmail for 15 years," Mr Elsadi says.<!-- --></p><p>"They banned me for no reason, saying I have violated their terms - what terms? Tell me. <!-- --></p><p>"I've filled out about 50 forms and called them many many times." <!-- --></p><p>Others have complained on social media of similar treatment. <!-- --></p><p>Some fear they are being wrongly accused of being a part of Hamas.<!-- --></p></div><p data-component="subheadline-block"><h2>'Fraudulent activity'<!-- --></h2></p><div data-component="text-block"><p>“We are civilians with no political background who just wanted to check on our families," Eiad Hametto says. He was calling his family from Saudi Arabia.<!-- --></p><p>"They’ve suspended my email account that I’ve had for nearly 20 years.<!-- --></p><p>"It was connected to all my work. <!-- --></p><p>"They killed my life online.”<!-- --></p><p>Microsoft did not respond directly to the accusation these people have been labelled as Hamas - but a spokesperson said it did not block calls or ban users based on calling region or destination. <!-- --></p><p>"Blocking in Skype can occur in response to suspected fraudulent activity," they said without elaborating. And users could appeal.<!-- --></p></div><figure><div data-component="image-block"><p><img src="https://www.bbc.com/bbcx/grey-placeholder.png"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/ad32/live/565fa320-3eac-11ef-b74c-bb483a802c97.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/ad32/live/565fa320-3eac-11ef-b74c-bb483a802c97.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/ad32/live/565fa320-3eac-11ef-b74c-bb483a802c97.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/ad32/live/565fa320-3eac-11ef-b74c-bb483a802c97.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/ad32/live/565fa320-3eac-11ef-b74c-bb483a802c97.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/ad32/live/565fa320-3eac-11ef-b74c-bb483a802c97.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/ad32/live/565fa320-3eac-11ef-b74c-bb483a802c97.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/ad32/live/565fa320-3eac-11ef-b74c-bb483a802c97.jpg.webp" loading="lazy" alt="Khalid Obaied"></p></div><p data-component="caption-block"><figcaption>Khalid Obaied was using Skype to call home to his wife and child from Belgium<!-- --></figcaption></p></figure><div data-component="text-block"><p>But many of those BBC News has spoken to say they have tried many times and are receiving the same blanket response.<!-- --></p><p>One, Khalid Obaied, has lost faith with Microsoft. <!-- --></p><p>"I don't trust them any more," he says. <!-- --></p><p>"I paid for a package to make phone calls - then, after 10 days, they ban me for no reason.<!-- --></p><p>"They have never provided a reason. <!-- --></p><p>"That means it's only because I’m a Palestinian calling Gaza.”<!-- --></p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Binance built a 100PB log service with Quickwit (187 pts)]]></title>
            <link>https://quickwit.io/blog/quickwit-binance-story</link>
            <guid>40935701</guid>
            <pubDate>Thu, 11 Jul 2024 11:57:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://quickwit.io/blog/quickwit-binance-story">https://quickwit.io/blog/quickwit-binance-story</a>, See on <a href="https://news.ycombinator.com/item?id=40935701">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main><center><img loading="lazy" src="https://quickwit.io/img/blog/2024-06-20-scaling-log-search-to-100-pb.png" alt="How Binance built a 100 PB log service with Quickwit"></center><p>Three years ago, we <a href="https://quickwit.io/blog/quickwit-first-release">open-sourced</a> Quickwit, a distributed search engine for large-scale datasets. Our goal was ambitious: to create a new breed of full-text search engine that is ten times more cost-efficient than Elasticsearch, significantly easier to configure and manage, and capable of scaling to petabytes of data <sup id="fnref-1-609909"><a href="#fn-1-609909">1</a></sup>.</p><p>While we knew the potential of Quickwit, our tests typically did not exceed 100 TB of data and 1 GB/s of indexing throughput. We lacked the real-world datasets and computing resources to test Quickwit at a multi-petabyte scale.</p><p>That is, until six months ago, when two engineers at Binance, the world's leading cryptocurrency exchange, discovered Quickwit and began experimenting with it. Within a few months, they achieved what we had only dreamed of: they successfully migrated multiple petabyte-scale Elasticsearch clusters to Quickwit, with remarkable achievements including:</p><ul><li>Scaling indexing to <strong>1.6 PB per day</strong>.</li><li>Operating a search cluster handling <strong>100 PB of logs</strong>.</li><li><strong>Saving millions of dollars</strong> annually by <strong>slashing compute costs by 80%</strong> and storage costs by 20x (for the same retention period).</li></ul><div><div><table><tbody><tr><th>Dataset</th><th></th></tr><tr><td>Uncompressed Size</td><td>100 PB</td></tr><tr><td>Size on S3 (compressed)</td><td>20 PB</td></tr><tr><td>Num documents</td><td>181 trillions</td></tr></tbody></table></div><div><table><tbody><tr><th>Indexing deployment</th><th></th></tr><tr><td>Indexing throughput</td><td>1.6 PB / day</td></tr><tr><td>Num pods</td><td>700</td></tr><tr><td>Num vCPUs</td><td><span>4000</span><span> 2800*</span></td></tr><tr><td>RAM</td><td><span>6</span><span> 5.6*</span> TB</td></tr></tbody></table></div></div><div><div><table><tbody><tr><th>Search deployment</th><th></th></tr><tr><td>Searchable dataset size</td><td>100 PB</td></tr><tr><td>Num pods</td><td>30</td></tr><tr><td>Num vCPUs</td><td>1200</td></tr><tr><td>RAM</td><td>3 TB</td></tr></tbody></table></div><div><table><tbody><tr><th>Infra costs vs. Elasticsearch</th><th></th></tr><tr><td>Compute costs</td><td>5x reduction</td></tr><tr><td>Storage costs <br><small>for same retention</small></td><td>20x reduction</td></tr><tr></tr></tbody></table></div></div><small>*First figures initially published were wrong :/</small><p>In this blog post, I will share with you how Binance built a petabyte-scale log service and overcame the challenges of scaling Quickwit to multi-petabytes.</p><p>As the world's leading cryptocurrency exchange, Binance handles an enormous volume of transactions, each generating logs that are crucial for security, compliance, and operational insights. This results in processing roughly 21 million log lines per second, equivalent to 18.5 GB/s, or 1.6 PB per day.</p><p>To manage such a volume, Binance previously relied on 20 Elasticsearch clusters. Around 600 Vector pods were pulling logs from different Kafka topics and processing them before pushing them into Elasticsearch.</p><p><img loading="lazy" alt="Binance ES setup" src="https://quickwit.io/assets/images/2024-06-20-binance-setup-kafka-vector-es-bc7ee32a83e8aae14aa3ec088d918244.png" width="1889" height="856"></p><p>However, this setup fell short of Binance's requirements in several critical areas:</p><ul><li><strong>Operational Complexity</strong>: Managing numerous Elasticsearch clusters was becoming increasingly challenging and time-consuming.</li><li><strong>Limited Retention</strong>: Binance was retaining most logs for only a few days. Their goal was to extend this to months, requiring the storage and management of 100 PB of logs, which was prohibitively expensive and complex with their Elasticsearch setup.</li><li><strong>Limited Reliability</strong>: Elasticsearch clusters with high ingestion throughput were configured without replication to limit infrastructure costs, compromising durability and availability.</li></ul><p>The team knew they needed a radical change to meet their growing needs for log management, retention, and analysis.</p><p>When Binance's engineers discovered Quickwit, they quickly realized it offered several key advantages over their existing setup:</p><ul><li><strong>Native Kafka integration</strong>: It allows ingesting logs directly from Kafka with exactly-once semantics, providing huge operational benefits. Concretely speaking, you can tear down your cluster, recreate it in a minute without losing any data, ready to ingest at 1.6 PB/day or search through petabytes, and scale up and down to handle temporary spikes.</li><li><strong>Built-in VRL transformations</strong> (Vector Remap Language): As Quickwit supports VRL, it eliminates the need for hundreds of Vector pods to handle log transformations.</li><li><strong>Object storage as the primary storage</strong>: All indexed data remains on object storage, removing the need for provisioning and managing storage on the cluster side.</li><li><strong>Better data compression</strong>: Quickwit typically achieves 2x better compression than Elasticsearch, further reducing the storage footprint of indexes.</li></ul><p>However, no users had scaled Quickwit to multi-petabytes, and any engineer knows that scaling a system by a factor of 10 or 100 can reveal unexpected issues. This did not stop them, and they were ready to take on the challenge!</p><center><img loading="lazy" src="https://quickwit.io/img/blog/2024-06-20-challenge-accepted.jpg" alt="Searching 100 PB, Challenge accepted" width="400"></center><p>Binance rapidly scaled its indexing thanks to the Kafka datasource. One month into their Quickwit PoC, they were indexing at several GB/s.</p><p>This quick progress was largely due to how Quickwit works with Kafka: Quickwit uses Kafka's consumer groups to distribute the workload across multiple pods. Each pod indexes a subset of the Kafka partitions and updates the metastore with the latest offsets, ensuring exactly-once semantics. This setup makes Quickwit's indexers stateless: you can tear down your entire cluster and restart it, and the indexers will resume from where they left off as if nothing happened.</p><p>However, Binance's scale revealed two main issues:</p><ul><li><strong>Cluster Stability Issues</strong>: A few months ago, Quickwit’s gossip protocol (called <a href="https://github.com/quickwit-oss/chitchat" target="_blank" rel="noopener noreferrer">Chitchat</a>) struggled with hundreds of pods: some indexers would leave the cluster and rejoin, making the indexing throughput unstable.</li><li><strong>Uneven Workload Distribution</strong>: Binance uses several Quickwit indexes for their logs, with varying indexing throughputs. Some have a high throughput of several GB/s, others just a few MB/s. Quickwit's placement algorithm does not spread its workload evenly. This is a known <a href="https://github.com/quickwit-oss/quickwit/issues/4630" target="_blank" rel="noopener noreferrer">issue</a>, and we will work on this later this year.</li></ul><p>To work around these limitations, Binance deployed separate indexing clusters for each high-throughput topic, keeping one cluster for smaller topics. Isolating each high-throughput cluster did not impose an operational burden thanks to stateless indexers. Additionally, all Vector pods were removed as Binance used Vector transformation directly in Quickwit.</p><p><img loading="lazy" alt="Binance Quickwit setup" src="https://quickwit.io/assets/images/2024-06-20-binance-setup-kafka-quickwit-5326a36908ce42113ac90fccaf3799e6.png" width="2110" height="1183"></p><p>After several months of migration and optimization, Binance finally achieved an indexing throughput of 1.6 PB with 10 Quickwit indexing clusters, 700 pods requesting around 2800 vCPU and 6 TB of memory, that's 6.6 MB/s per vCPU on average. On a given high-throughput Kafka topic, this figure goes up to 11 MB/s per vCPU.</p><p>Next challenge to come: scaling search!</p><p>With Quickwit now capable of efficiently indexing 1.6 PB daily, the challenge shifted to searching through petabytes of logs. With 10 clusters, Binance would normally need to deploy searcher pods for each cluster, undermining one of Quickwit’s strengths: pooling searcher resources to hit the object storage shared by all indexes.</p><p>To avoid this pitfall, Binance's engineers devised a clever workaround: they created a unified metastore by replicating all metadata from each indexing cluster metastore into one PostgreSQL database. This unified metastore enables the deployment of one unique centralized search cluster capable of searching through all indexes!</p><p><img loading="lazy" alt="Quickwit multi clusters setup" src="https://quickwit.io/assets/images/2024-06-20-quickwit-multi-indexers-clusters-setup-f83edb0ef91fcc35680e31469c451eb1.png" width="1966" height="1098"></p><p>As we speak, Binance now manages a reasonably sized cluster of 30 searcher pods, each requesting 40 vCPU and 100GB memory. To give you an idea, you only need 5 searchers (8 vCPU, 6GB memory requests) to find the needle in the haystack in 400 TB of logs. Binance runs those types of queries on petabytes but also aggregation queries, hence the higher resource requests.</p><p>Overall, Binance's migration to Quickwit was a huge success and brought several substantial benefits:</p><ul><li>80% reduction in computing resources compared to Elasticsearch.</li><li>Storage costs reduced by a factor of 20 for the same retention period.</li><li>Economically viable solution for large-scale log management, both in terms of infrastructure costs and maintenance operations.</li><li>Minimal configuration tweaking, working efficiently once the right number of pods and resources were determined.</li><li>Increased log retention to one or several months, depending on the log type, improving internal troubleshooting capabilities.</li></ul><p>In conclusion, Binance’s migration from Elasticsearch to Quickwit has been an exciting 6-month experience between Binance and Quickwit engineers, and we are very proud of this collaboration. We have already planned improvements in data compression, multi-cluster support, and better workload spread with Kafka datasources.</p><p>Huge kudos to Binance's engineers for their work and insights throughout this migration &lt;3</p></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[If AI chatbots are the future, I hate it (152 pts)]]></title>
            <link>https://www.jeffgeerling.com/blog/2024/if-ai-chatbots-are-future-i-hate-it</link>
            <guid>40935576</guid>
            <pubDate>Thu, 11 Jul 2024 11:41:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jeffgeerling.com/blog/2024/if-ai-chatbots-are-future-i-hate-it">https://www.jeffgeerling.com/blog/2024/if-ai-chatbots-are-future-i-hate-it</a>, See on <a href="https://news.ycombinator.com/item?id=40935576">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="block-jeffgeerling-system-main">
          
<article>

  

      
  
  <div>
    
            <div><p><img width="500" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/speedtest-graph-att-dropoff.png" alt="AT&amp;T Fiber Internet - speedtest graph"></p>

<p>About a week ago, my home Internet (AT&amp;T Fiber) went from the ~1 Gbps I pay for down to about 100 Mbps (<a href="https://www.jeffgeerling.com/blog/2021/monitor-your-internet-raspberry-pi">see how I monitor my home Internet with a Pi</a>). It wasn't too inconvenient, and I considered waiting it out to see if the speed recovered at some point, because latency was fine.</p>

<p>But as you can see around 7/7 on that graph, the 100 Mbps went down to about <em>eight</em>, and that's the point where my wife starts noticing how slow the Internet is. Action level.</p>

<p>So I fired up AT&amp;T's support chat. I'm a programmer, I can usually find ways around the wily ways of chatbots.</p>

<p>Except AT&amp;T's AI-powered chatbot seems to have a fiendish tendency to equate 'WiFi' with 'Internet', no doubt due to so many people thinking they are one and the same.</p>

<p><img width="500" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/att-chatbot-slow-internet-not-wifi.png" alt="ATT Chatbot - Slow Internet not WiFi"></p>

<p>We were stuck in that loop for about 5 minutes.</p>

<blockquote>
  <p>It looks like you're having trouble with your WiFi.</p>
  
  <p><em>No.</em></p>
</blockquote>

<p>After working a few different angles, I finally 'spammed 0'<sup id="fnref:olddays"><a href="#fn:olddays" role="doc-noteref">1</a></sup> by entering some variation of 'connect me to a support rep'.</p>

<p><img width="300" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/att-chatbot-connect-to-support-rep.png" alt="ATT Chatbot - connect me to support rep"></p>

<p>I'll cut to the chase—after repeating some variation of that about 8 times, eventually I got queued up in the 20 minute line to a human support rep.</p>

<p>Unfortunately for me, the human support rep, like so many in the industry, promptly ignored the data I provided in my first chat message to him<sup id="fnref:message"><a href="#fn:message" role="doc-noteref">2</a></sup>, and told me switching WiFi channels on the device (on which WiFi is currently disabled completely) would solve my issue. <em>At no cost.</em></p>

<p><img width="300" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/att-chat-support-wifi.png" alt="ATT Support Rep - WiFi is not the problem"></p>

<p>Maybe I should welcome our AI overlords?</p>

</div>
      

          <div id="block-related-content">
  
      <h2>Further reading</h2>
    
  
</div>
    
    
      
  

      

  </div>
      
  
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kids Who Get Smartphones Earlier Become Adults with Worse Mental Health (2023) (122 pts)]]></title>
            <link>https://www.afterbabel.com/p/sapien-smartphone-report</link>
            <guid>40935443</guid>
            <pubDate>Thu, 11 Jul 2024 11:16:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.afterbabel.com/p/sapien-smartphone-report">https://www.afterbabel.com/p/sapien-smartphone-report</a>, See on <a href="https://news.ycombinator.com/item?id=40935443">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><span>When parents are asked to identify their top fears about the safety of their children, what do you think tops the list? According to a survey last year by </span><a href="https://www.safehome.org/family-safety/parenting-in-america-report/" rel="">Safehome.org</a><span>, it’s not cars, strangers, or any other physical threat; it’s “internet/social media.” That’s not just for parents of teenagers and pre-teens, whose lives seem to revolve around their phones. It’s even true for parents of younger kids, ages 7-9 because every parent sees it coming and few know what to do about it. Parents don’t want their children to disappear into phones, as so many of their friends' children have; some resolve to </span><a href="https://www.waituntil8th.org/" rel="">wait until 8th grade</a><span>, or later. Then their child hits them with the main argument that makes parents buckle: “But everyone else has a phone, so I’m being left out.”</span></p><p><span>For parents who resisted, or who plan to resist, a new report may encourage many more parents to join you: </span><a href="https://sapienlabs.org/" rel="">Sapien Labs</a><span>, which runs an </span><a href="https://sapienlabs.org/global-mind-project/" rel="">ongoing global survey</a><span> of mental health with nearly a million participants so far, </span><a href="https://sapienlabs.org/wp-content/uploads/2023/05/Sapien-Labs-Age-of-First-Smartphone-and-Mental-Wellbeing-Outcomes.pdf" rel="">released a “Rapid Report” today</a><span> on a question they added in January asking young adults (those between ages 18 and 24): </span><em>“At what age did you get your own smartphone or tablet (e.g. iPad) with Internet access that you could carry with you?”</em><span>&nbsp; When they plot the age of first smartphone on the X axis against their extensive set of questions about mental health on the Y axis, they find a consistent pattern: </span><em>the younger the age of getting the first smartphone, the worse the mental health that the young adult reports today.</em><span> This is true in all the regions studied (the survey is offered in English, Spanish, French, German, Portuguese, Arabic, Hindi, and Swahili), and the relationships are consistently stronger for women.</span></p><p>We believe these findings have important implications for parents, heads of K-12 schools, and legislators currently considering bills to raise minimum ages or require age verification for some kinds of sites (especially social media and pornography). We’ll address those implications at the end of this post. But first: what did Sapien Labs do, and what did they find?</p><p><span>Sapien Labs is a non-profit research foundation with the goal of understanding how the rapidly changing social and technological environment is changing human brains and minds. Their main research project has been the </span><a href="https://sapienlabs.org/global-mind-project/" rel="">Global Mind Project</a><span>, an ongoing program that tracks mental well-being around the world using a comprehensive assessment of mental health along with questions about demographics and various cultural, technological, and lifestyle factors. They have issued a </span><a href="https://sapienlabs.org/research-and-reports/" rel="">variety of reports on the state of mental health around the world</a><span>. Among their most important findings is that in all the regions they’ve studied, mental health is worst for the youngest generations.</span></p><p><span>It didn’t used to be this way. There is a well-known finding in happiness research that, </span><a href="https://link.springer.com/article/10.1007/s00148-020-00797-z" rel="">across nearly all nations</a><span>, happiness or well-being forms a U-shaped curve across the lifespan (See </span><a href="https://us.macmillan.com/books/9781466891234/thehappinesscurve" rel="">Rauch, 2018</a><span>). Young adults and people in their 60s and 70s are happier than those in middle age. But that may be changing, </span><a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2022.837638/full" rel="">especially for women</a><span>, as Gen Z (born in and after 1996) enters young adulthood. You can see the sudden collapse of young adult mental health in some of our </span><a href="https://jonathanhaidt.substack.com/p/the-teen-mental-illness-epidemic" rel="">previous</a><span> </span><a href="https://jonathanhaidt.substack.com/p/international-mental-illness-part-one" rel="">posts</a><span> on this Substack. For example, Figure 1 shows that up until 2011, young Canadian women were the </span><em>most</em><span> likely to report having excellent or very good mental health. By 2015 they were the</span><em> least</em><span> likely, and the decline in their self-reported mental health accelerated after that, while it changed very little for older women. (The same pattern holds for </span><a href="https://jonathanhaidt.substack.com/p/international-mental-illness-part-one" rel="">Canadian men</a><span>, but to a lesser degree.)</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6432f83-2793-4a51-b24b-5cb5ff86a30f_1350x930.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6432f83-2793-4a51-b24b-5cb5ff86a30f_1350x930.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6432f83-2793-4a51-b24b-5cb5ff86a30f_1350x930.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6432f83-2793-4a51-b24b-5cb5ff86a30f_1350x930.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6432f83-2793-4a51-b24b-5cb5ff86a30f_1350x930.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6432f83-2793-4a51-b24b-5cb5ff86a30f_1350x930.png" width="1350" height="930" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f6432f83-2793-4a51-b24b-5cb5ff86a30f_1350x930.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:930,&quot;width&quot;:1350,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;trends in very good mental health in canada. Steepest declines in 15-30 year old women since 2010&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="trends in very good mental health in canada. Steepest declines in 15-30 year old women since 2010" title="trends in very good mental health in canada. Steepest declines in 15-30 year old women since 2010" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6432f83-2793-4a51-b24b-5cb5ff86a30f_1350x930.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6432f83-2793-4a51-b24b-5cb5ff86a30f_1350x930.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6432f83-2793-4a51-b24b-5cb5ff86a30f_1350x930.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6432f83-2793-4a51-b24b-5cb5ff86a30f_1350x930.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><em><strong>Figure 1.</strong><span> Percent of Canadian women reporting excellent or very good mental health, by age group. Canadian Community Health Survey (2003-2019). Graphed by </span><a href="https://jonathanhaidt.substack.com/p/international-mental-illness-part-one" rel="">Zach Rausch.</a></em></p><p><span>Why would this be? What changed in the early 2010s that could have rapidly reduced the mental health of teens around the world, with a bigger impact on girls? At the </span><a href="https://jonathanhaidt.substack.com/archive" rel="">After Babel Substack</a><span>, we have </span><a href="https://jonathanhaidt.substack.com/p/mental-health-liberal-girls" rel="">argued</a><span> that the sudden switch of </span><a href="https://jonathanhaidt.substack.com/p/do-the-kids-think-theyre-alright" rel="">teen social life</a><span> from </span><a href="https://jonathanhaidt.substack.com/p/why-some-researchers-think-im-wrong" rel="">flip phones</a><span> (which are designed for communication) to smartphones (which enabled continuous access to social media and much higher levels of phone addiction), is </span><a href="https://jonathanhaidt.substack.com/p/social-media-mental-illness-epidemic" rel="">the major cause</a><span>, though not the only one. There are unique factors at work in each country, but we know of </span><a href="https://jonathanhaidt.substack.com/p/academic-pressure-social-media" rel="">no alternative</a><span> that </span><a href="https://jonathanhaidt.substack.com/p/why-some-researchers-think-im-wrong" rel="">can explain</a><span> the </span><em>synchronized, gendered, and global decline</em><span> in teen mental health.&nbsp;</span></p><p>At Sapien Labs, they decided to test the smartphone hypothesis by adding a question about the age at which people got their first smartphone (or tablet). Is it just a coincidence that the first global generation to grow up on smartphones became the first global generation to have lower well-being than the one before them?&nbsp;</p><p>Sapien Labs uses a comprehensive assessment of mental well-being that asks participants about 47 elements of mental, social, and emotional functioning on a life impact scale. These 47 elements are aggregated into a single score called the Mental Health Quotient (MHQ), which gives extra weight to patterns that indicate severe problems. It also uses subsets of these 47 elements to create scores along six domains: Mood &amp; Outlook, Social Self, Adaptability &amp; Resilience, Drive &amp; Motivation, Cognition, and Mind-Body Connection.&nbsp;</p><p><span>(You can take the </span><a href="https://sapienlabs.org/mhq/" rel="">MHQ yourself</a><span> and you can request </span><a href="https://sapienlabs.org/global-mind-project/researcher-hub/" rel="">access to the full dataset</a><span>. For scoring and validation of the MHQ, see </span><a href="https://mental.jmir.org/2022/4/e34105" rel="">Newson, Pastukh, &amp; Thiagarajan, 2022</a><span>, and see </span><a href="https://sapienlabs.org/understanding-the-construction-of-the-mhq-score/" rel="">this blog post</a><span> that offers a clear explanation of how the MHQ is scored, and why.)&nbsp;</span></p><p>Figure 2 shows the most basic result in the report: they simply plotted the responses from the nearly 28,000 participants who answered the “first phone” question, from all countries combined.&nbsp;</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe22794c8-bbdc-4154-87d0-c51e55752e2a_856x722.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe22794c8-bbdc-4154-87d0-c51e55752e2a_856x722.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe22794c8-bbdc-4154-87d0-c51e55752e2a_856x722.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe22794c8-bbdc-4154-87d0-c51e55752e2a_856x722.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe22794c8-bbdc-4154-87d0-c51e55752e2a_856x722.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe22794c8-bbdc-4154-87d0-c51e55752e2a_856x722.png" width="856" height="722" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e22794c8-bbdc-4154-87d0-c51e55752e2a_856x722.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:722,&quot;width&quot;:856,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Mental Health Quotient by Age of first smartphone&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Mental Health Quotient by Age of first smartphone" title="Mental Health Quotient by Age of first smartphone" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe22794c8-bbdc-4154-87d0-c51e55752e2a_856x722.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe22794c8-bbdc-4154-87d0-c51e55752e2a_856x722.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe22794c8-bbdc-4154-87d0-c51e55752e2a_856x722.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe22794c8-bbdc-4154-87d0-c51e55752e2a_856x722.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><em><strong>Figure 2.</strong><span> As age of first smartphone goes up, so does the mental health reported by young adults, assessed by the MHQ. Data from SapienLabs.org.</span></em></p><p><span>MHQ scores are </span><a href="https://mental.jmir.org/2022/4/e34105" rel="">calculated from responses to the 47 questions</a><span> and converted to a scale that runs from -100 to 200, as shown here:&nbsp;</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14de3aef-b7dd-4d77-9fb1-34c63e907587_1572x362.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14de3aef-b7dd-4d77-9fb1-34c63e907587_1572x362.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14de3aef-b7dd-4d77-9fb1-34c63e907587_1572x362.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14de3aef-b7dd-4d77-9fb1-34c63e907587_1572x362.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14de3aef-b7dd-4d77-9fb1-34c63e907587_1572x362.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14de3aef-b7dd-4d77-9fb1-34c63e907587_1572x362.png" width="1456" height="335" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/14de3aef-b7dd-4d77-9fb1-34c63e907587_1572x362.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:335,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;MHQ Score Scale, -100 to 200&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="MHQ Score Scale, -100 to 200" title="MHQ Score Scale, -100 to 200" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14de3aef-b7dd-4d77-9fb1-34c63e907587_1572x362.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14de3aef-b7dd-4d77-9fb1-34c63e907587_1572x362.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14de3aef-b7dd-4d77-9fb1-34c63e907587_1572x362.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14de3aef-b7dd-4d77-9fb1-34c63e907587_1572x362.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>As you can see, the respondents who got their first smartphone before they were 10 years old are doing worse, on average, than those who didn’t get one until they were in their teens. The most mentally healthy respondents are those who did not get a phone until their late teens.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-121478547" href="https://www.afterbabel.com/p/sapien-smartphone-report#footnote-1-121478547" target="_self" rel="">1</a></span><span> You can also see that the slope is steeper for young women than for young men. The Gen Z women who got their first smartphone before they were 9 years old are in negative territory, on average.</span></p><p>The power and unique contribution of the Sapien Labs dataset come from two features of their work: First, they use a far more detailed measure of mental health than is used in most other large surveys. The second important feature is their international coverage. So, let’s zoom in and explore the six domain scores that make up the MHQ, first for the global sample, and then for the region and culture we know best: the Anglosphere.</p><p><span>As you’ll see if you read </span><a href="https://sapienlabs.org/wp-content/uploads/2023/05/Sapien-Labs-Age-of-First-Smartphone-and-Mental-Wellbeing-Outcomes.pdf" rel="">the full report</a><span>, the next step after examining the overall MHQ scores is to examine scores on the six domains of mental functioning:</span></p><ul><li><p><strong>Mood &amp; Outlook</strong><span>: Includes items about optimism, calmness, anxiety, mood swings, sadness, and anger.&nbsp;</span></p></li><li><p><strong>Social Self</strong><span>: Includes items about self-worth, relationships with others, empathy, cooperation, aggression toward others&nbsp;</span></p></li><li><p><strong>Adaptability &amp; Resilience</strong><span>: includes items about adaptability to change, ability to learn, and emotional resilience.&nbsp;&nbsp;</span></p></li><li><p><strong>Drive &amp; Motivation</strong><span>: Includes items about motivation, curiosity, enthusiasm, and addictions.</span></p></li><li><p><strong>Cognition</strong><span>: Includes items about memory, decision-making and risk-taking, focus, and concentration, unwanted thoughts, hallucinations</span></p></li><li><p><strong>Mind-Body Connection:</strong><span> Includes items about sleep quality, energy level, appetite, and physical health issues.&nbsp;</span></p></li></ul><p>Figure 3 shows that for young women, all six domain scores show the same basic pattern as the MHQ: a consistent rise. You can also see that a few of the domains seem to rise more slowly or level off somewhat after the age of 13 or 14: Drive and motivation, Mind-body connection, and Cognition. However, the other three dimensions continue to rise all the way to age 18. The domain that rises fastest, meaning that it is most highly correlated with age of first smartphone, is the “social self” domain.&nbsp;</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbff8dea-3dc7-4bef-9c12-a7bfcdd73794_1300x1168.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbff8dea-3dc7-4bef-9c12-a7bfcdd73794_1300x1168.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbff8dea-3dc7-4bef-9c12-a7bfcdd73794_1300x1168.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbff8dea-3dc7-4bef-9c12-a7bfcdd73794_1300x1168.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbff8dea-3dc7-4bef-9c12-a7bfcdd73794_1300x1168.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbff8dea-3dc7-4bef-9c12-a7bfcdd73794_1300x1168.png" width="1300" height="1168" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fbff8dea-3dc7-4bef-9c12-a7bfcdd73794_1300x1168.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1168,&quot;width&quot;:1300,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Mental Health Quotient Dimension Scores by age of first smartphone, Women&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Mental Health Quotient Dimension Scores by age of first smartphone, Women" title="Mental Health Quotient Dimension Scores by age of first smartphone, Women" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbff8dea-3dc7-4bef-9c12-a7bfcdd73794_1300x1168.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbff8dea-3dc7-4bef-9c12-a7bfcdd73794_1300x1168.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbff8dea-3dc7-4bef-9c12-a7bfcdd73794_1300x1168.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbff8dea-3dc7-4bef-9c12-a7bfcdd73794_1300x1168.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><em><strong>Figure 3:</strong><span> The 6 domains of well-being, for young women, as a function of when they got their first smartphone. From SapienLabs.org.</span></em></p><p><span>Figure 4 shows the same analysis for young men. The pattern is similar, with two important exceptions. First, the slopes are substantially lower, meaning that the mental health and well-being of young men are not as strongly related to the age at which they got their first smartphone as it is for their sisters, although it is still related. (All of the significance tests and effect sizes can be found in supplementary materials posted in this </span><a href="https://drive.google.com/drive/folders/10Mi9JzMwAbmKolPpCD8khDFjjbIzfTTC" rel="">Google Drive link</a><span>.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-121478547" href="https://www.afterbabel.com/p/sapien-smartphone-report#footnote-2-121478547" target="_self" rel="">2</a></span><span>) The second difference is that all of the lines are higher for boys, meaning that boys are doing better than girls at all ages (at least, according to their self-reports). The one exception is that the line for Adaptability &amp; Resilience reaches the same level for both sexes by age 18. Given the steeper slopes of all six lines for girls, this means that </span><em>sex differences in adult mental health are larger among those who got a smartphone earlier</em><span>.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ae6b3ac-b129-4358-981d-64f83ff4dad9_1274x1084.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ae6b3ac-b129-4358-981d-64f83ff4dad9_1274x1084.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ae6b3ac-b129-4358-981d-64f83ff4dad9_1274x1084.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ae6b3ac-b129-4358-981d-64f83ff4dad9_1274x1084.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ae6b3ac-b129-4358-981d-64f83ff4dad9_1274x1084.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ae6b3ac-b129-4358-981d-64f83ff4dad9_1274x1084.png" width="1274" height="1084" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1ae6b3ac-b129-4358-981d-64f83ff4dad9_1274x1084.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1084,&quot;width&quot;:1274,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Mental Health Quotient Dimensions and age of first smartphone relationship, men&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Mental Health Quotient Dimensions and age of first smartphone relationship, men" title="Mental Health Quotient Dimensions and age of first smartphone relationship, men" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ae6b3ac-b129-4358-981d-64f83ff4dad9_1274x1084.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ae6b3ac-b129-4358-981d-64f83ff4dad9_1274x1084.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ae6b3ac-b129-4358-981d-64f83ff4dad9_1274x1084.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ae6b3ac-b129-4358-981d-64f83ff4dad9_1274x1084.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><em><strong>Figure 4:</strong><span> The 6 domains of well-being, for young men, as a function of when they got their first smartphone. From SapienLabs.org.</span></em></p><p>One major issue in analyzing an international dataset is that there are just so many differences between countries, regions, and religions that there are many opportunities for confounding variables to lead us astray. For example, in the Sapien Labs dataset, in the less wealthy countries such as India, few young adults had received a smartphone before the age of 10, which means that the data points on the left sides of the graphs contain almost no Indians, whereas the data points on the right side (no phone until 17 or 18) contain many Indians and fewer from the USA. If Indians are mentally healthier than Americans (for other reasons), this could cause the lines to slope even if smartphones had no effect on mental health. It is important, therefore, to look at individual countries and regions. (The Sapien Labs report does this in its appendix, where you can see that the trends hold for each of the world regions).&nbsp;</p><p><span>The region that we (Jon and Zach) know best and have </span><a href="https://jonathanhaidt.substack.com/p/international-mental-illness-part-one" rel="">written on</a><span> </span><a href="https://docs.google.com/document/d/1diMvsMeRphUH7E6D1d_J7R6WbDdgnzFHDHPx9HXzR5o/edit#" rel="">extensively</a><span> is the </span><a href="https://en.wikipedia.org/wiki/Anglosphere" rel="">Anglosphere</a><span> (the English-speaking countries of The United States, Canada, The United Kingdom, Australia, New Zealand, and sometimes Ireland). We, therefore, decided to examine what Sapien Labs had found about those countries and compare it to what we have found.&nbsp;</span></p><p data-attrs="{&quot;url&quot;:&quot;https://www.afterbabel.com/p/sapien-smartphone-report?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.afterbabel.com/p/sapien-smartphone-report?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p><span>At the After Babel Substack, we have been </span><a href="https://jonathanhaidt.substack.com/p/the-teen-mental-illness-epidemic" rel="">documenting</a><span> the </span><a href="https://jonathanhaidt.substack.com/p/mental-health-liberal-girls" rel="">patterns</a><span> of rising mental illness among teens </span><a href="https://jonathanhaidt.substack.com/p/international-mental-illness-part-one" rel="">around</a><span> the </span><a href="https://jonathanhaidt.substack.com/p/international-mental-illness-part-two" rel="">world</a><span>, and, </span><a href="https://sapienlabs.org/wp-content/uploads/2023/02/Mental-State-of-the-World-2022.pdf" rel="">like Sapien Labs</a><span>, we have found that the sudden decline of teenage mental health is an international phenomenon. Our research so far indicates that the increases in mental illness in the 2010s were slightly larger in the Anglosphere than in any other region we’ve examined. Figure 4 shows the large and sudden rise in self-harm rates among teens, particularly girls, in four of these nations (you can see much more in Zach’s </span><a href="https://jonathanhaidt.substack.com/p/international-mental-illness-part-one" rel="">initial report</a><span> on the Anglosphere).</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f2c92ee-d0de-47e9-8e42-47c6fa348de5_1278x794.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f2c92ee-d0de-47e9-8e42-47c6fa348de5_1278x794.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f2c92ee-d0de-47e9-8e42-47c6fa348de5_1278x794.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f2c92ee-d0de-47e9-8e42-47c6fa348de5_1278x794.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f2c92ee-d0de-47e9-8e42-47c6fa348de5_1278x794.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f2c92ee-d0de-47e9-8e42-47c6fa348de5_1278x794.png" width="1278" height="794" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7f2c92ee-d0de-47e9-8e42-47c6fa348de5_1278x794.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:794,&quot;width&quot;:1278,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Rising rates of teenage self harm in the USA, UK, New Zealand, and Ontario Canada&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Rising rates of teenage self harm in the USA, UK, New Zealand, and Ontario Canada" title="Rising rates of teenage self harm in the USA, UK, New Zealand, and Ontario Canada" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f2c92ee-d0de-47e9-8e42-47c6fa348de5_1278x794.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f2c92ee-d0de-47e9-8e42-47c6fa348de5_1278x794.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f2c92ee-d0de-47e9-8e42-47c6fa348de5_1278x794.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f2c92ee-d0de-47e9-8e42-47c6fa348de5_1278x794.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><em><strong>Figure 5.</strong><span> Since 2010, rates of self-harm episodes have increased for teens in the&nbsp; Anglosphere countries. For data on Australia and for all sources, see </span><a href="https://jonathanhaidt.substack.com/p/international-mental-illness-part-one" rel="">Rausch and Haidt (2023)</a><span>.</span></em></p><p><span>In every Anglosphere country, the mental health of teens declined sharply around the same time (~2012) and in the same way (depression, anxiety, and self-harm, with bigger increases for girls). We have also found that the </span><a href="https://jonathanhaidt.substack.com/p/international-mental-illness-part-two" rel="">five Nordic nations show similar trends</a><span>, particularly when examining changing rates of depression and anxiety (though not always for self harm).&nbsp;</span></p><p><span>The Sapien Labs study began in 2019 so it cannot show us trends since 2010, but it can show us how young adults are doing today, and it can link variations in mental health today to variations in age of first smartphone. We wanted to get more familiar with the data and examine these links for ourselves, so we downloaded the full dataset as it was available on their </span><a href="https://brainbase.io/#!/auth/signin" rel="">Brainbase site</a><span> on May 13, 2023, which was just about 2 weeks later than the dataset used in the Sapien Lab report. Our dataset contains 1,798 more participants, for a total of 29,767. The number of participants from the six anglosphere countries was much smaller: 1,465 (823 females, 584 males). By country: 682 in the USA, 297 in the UK, 224 in Canada, 239 in Australia, 10 in New Zealand, and 13 in Ireland.</span></p><p><span>We cleaned and organized our dataset in the same way as the team at Sapien Labs, with a small modification to account for our much smaller sample size. To reduce the jerkiness of the graph lines when we drop down to lower numbers of respondents for each point, we grouped participants into 2-year buckets (or three years, for our youngest bucket, 5-8</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-121478547" href="https://www.afterbabel.com/p/sapien-smartphone-report#footnote-3-121478547" target="_self" rel="">3</a></span><span>). Figure 5 shows that the MHQ scores of Anglosphere boys and girls show patterns very similar to those reported in Figure 1 by Sapien Labs for the full 28,000-person international sample: The later the age of smartphone acquisition, the better the mental health. At least, that is true for the girls, all the way up to 18. For Anglosphere boys, there is a leveling off after the 11-12 mark. Delays beyond age 12 do not seem to be related to further increases in MHQ scores.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-121478547" href="https://www.afterbabel.com/p/sapien-smartphone-report#footnote-4-121478547" target="_self" rel="">4</a></span><span>&nbsp;</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03fcda37-b410-4509-b8bf-4d67ecba5b6f_916x836.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03fcda37-b410-4509-b8bf-4d67ecba5b6f_916x836.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03fcda37-b410-4509-b8bf-4d67ecba5b6f_916x836.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03fcda37-b410-4509-b8bf-4d67ecba5b6f_916x836.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03fcda37-b410-4509-b8bf-4d67ecba5b6f_916x836.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03fcda37-b410-4509-b8bf-4d67ecba5b6f_916x836.png" width="916" height="836" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/03fcda37-b410-4509-b8bf-4d67ecba5b6f_916x836.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:836,&quot;width&quot;:916,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Mental health quotient by age of smartphone in the Anglosphere&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Mental health quotient by age of smartphone in the Anglosphere" title="Mental health quotient by age of smartphone in the Anglosphere" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03fcda37-b410-4509-b8bf-4d67ecba5b6f_916x836.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03fcda37-b410-4509-b8bf-4d67ecba5b6f_916x836.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03fcda37-b410-4509-b8bf-4d67ecba5b6f_916x836.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03fcda37-b410-4509-b8bf-4d67ecba5b6f_916x836.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><em><strong>Figure 6.</strong><span> Anglosphere countries only: As age of first smartphone goes up, so does the mental health reported by young adults, especially for women. Data from SapienLabs.org, graphed by Zach Rausch.</span></em></p><p><span>We also plotted the six MHQ domain scores and found similar results. For females, all six dimensions of mental well-being improve as the age of smartphone acquisition increases.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5-121478547" href="https://www.afterbabel.com/p/sapien-smartphone-report#footnote-5-121478547" target="_self" rel="">5</a></span><span> The effects are particularly strong for the “social self” and “mood and outlook”, which correspond well to the rise of internalizing disorders (depression and anxiety), which </span><a href="https://jonathanhaidt.substack.com/p/international-mental-illness-part-one" rel="">Zach has shown</a><span> is rising within every Anglosphere nation.&nbsp;</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f3c076-c20f-45b1-af62-f57e255d400e_1258x740.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f3c076-c20f-45b1-af62-f57e255d400e_1258x740.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f3c076-c20f-45b1-af62-f57e255d400e_1258x740.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f3c076-c20f-45b1-af62-f57e255d400e_1258x740.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f3c076-c20f-45b1-af62-f57e255d400e_1258x740.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f3c076-c20f-45b1-af62-f57e255d400e_1258x740.png" width="1258" height="740" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/39f3c076-c20f-45b1-af62-f57e255d400e_1258x740.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:740,&quot;width&quot;:1258,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;MHQ Dimension Scores, Anglo Females&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="MHQ Dimension Scores, Anglo Females" title="MHQ Dimension Scores, Anglo Females" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f3c076-c20f-45b1-af62-f57e255d400e_1258x740.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f3c076-c20f-45b1-af62-f57e255d400e_1258x740.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f3c076-c20f-45b1-af62-f57e255d400e_1258x740.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f3c076-c20f-45b1-af62-f57e255d400e_1258x740.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><em><strong>Figure 7</strong><span>. Anglosphere countries only: female MHQ dimension scores. Well-being on all 6 dimensions increases as age of smartphone acquisition increases.</span></em><span>&nbsp;</span></p><p><span>The trends for boys are similar to girls, though the effects are smaller and there is more fluctuation.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-6-121478547" href="https://www.afterbabel.com/p/sapien-smartphone-report#footnote-6-121478547" target="_self" rel="">6</a></span><span> Figure 8 shows that at the youngest ages, increasing age corresponds with improvements in each of the six dimensions. However, for boys, improvements tend to level off after age 12. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fa838e5-6c57-495b-a04e-7f1dce08bee3_1306x744.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fa838e5-6c57-495b-a04e-7f1dce08bee3_1306x744.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fa838e5-6c57-495b-a04e-7f1dce08bee3_1306x744.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fa838e5-6c57-495b-a04e-7f1dce08bee3_1306x744.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fa838e5-6c57-495b-a04e-7f1dce08bee3_1306x744.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fa838e5-6c57-495b-a04e-7f1dce08bee3_1306x744.png" width="1306" height="744" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5fa838e5-6c57-495b-a04e-7f1dce08bee3_1306x744.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:744,&quot;width&quot;:1306,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;MHQ Dimension Scores, Anglo Males&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="MHQ Dimension Scores, Anglo Males" title="MHQ Dimension Scores, Anglo Males" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fa838e5-6c57-495b-a04e-7f1dce08bee3_1306x744.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fa838e5-6c57-495b-a04e-7f1dce08bee3_1306x744.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fa838e5-6c57-495b-a04e-7f1dce08bee3_1306x744.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5fa838e5-6c57-495b-a04e-7f1dce08bee3_1306x744.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><em><strong>Figure 8.</strong><span> Anglosphere countries only: male MHQ dimension scores. Changes are smaller and more varied compared to females.</span></em><span>&nbsp;</span></p><p data-attrs="{&quot;url&quot;:&quot;https://www.afterbabel.com/p/sapien-smartphone-report/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.afterbabel.com/p/sapien-smartphone-report/comments" rel=""><span>Leave a comment</span></a></p><p><span>It’s important to note that the report from Sapien Labs is one of their “rapid reports” made possible by their fast-growing number of participants and the easy access they offer to their data. They added the question about age of first smartphone in January and they are publishing a report, with data from nearly 28,000 participants, in May. We believe that this ability to move quickly is a public service during a global pandemic of teen mental illness. While their rapid report is not a standard academic publication and has not been through peer review (which often takes a year or more), the open access to the data has allowed us to investigate and confirm the trends they are reporting. We hope and expect that other researchers will download the dataset and offer critiques of the data, the analyses, and the conclusions drawn. This sort of “</span><a href="https://scholarlyassessmentreports.org/articles/10.29024/sar.26" rel="">post-publication peer review</a><span>” is becoming increasingly common as the problems with the existing peer review system become more widely known.</span></p><p><span>One issue to keep in mind with the Sapien Labs dataset is that the participants in each country are not a random or representative sample of the people in that country. Such studies would be extremely expensive to run, and now that so few people agree to phone solicitations or even answer their phones, it is unclear how representative such surveys can be. Those who agree to be interviewed, or who are motivated by money to participate, are not representative of the broader population. For this Sapien Labs report, participants came to the site on their own, or from online advertisements paid for by Sapien Labs, for the purpose of getting a detailed report on their wellbeing. So, the means reported for any country should not be treated like direct measures of the true means. However, samples such as these are still very useful for examining differences </span><em>within</em><span> the sample, such as those between men and women, or between those who got a smartphone early and those who got one late. And the much larger size of the Sapien Labs dataset, compared to Gallup and other survey organizations, allows for many additional analyses.&nbsp;</span></p><p><span>A second factor to keep in mind is that like all surveys, what we get is correlational data that is open to alternative interpretations. The graphs in the report are likely to suggest to most readers that getting a smartphone early </span><em>causes</em><span> later mental health problems. But with correlational data we must always consider the possibility that the causal arrow could run in reverse. In this case: having low well-being as a young adult could </span><em>cause</em><span> people to believe that they got a smartphone earlier than they did, but this seems unlikely. We must also always consider that there could be “third variables” that cause both of the first two variables to rise. In this case, one plausible confounding third variable is </span><a href="https://www.canr.msu.edu/news/permissive_parenting_style#:~:text=Permissive%20parents%20are%20not%20demanding,than%20children%20of%20a%20parent." rel="">permissive parenting</a><span>. Perhaps permissive parents (in each country) simultaneously do two things: they give their kids smartphones at very young ages, and they also give them few boundaries and little structure, which then interferes with development and produces struggling young adults. While this hypothesis is plausible and should be investigated, it is not clear how it would explain the fact that, in all the regions studied, it is the </span><em>girls</em><span> who show a tighter connection between early phone acquisition and later mental health problems, just as it is the girls who show a </span><a href="https://www.thelancet.com/journals/eclinm/article/PIIS2589-5370(18)30060-9/fulltext" rel="">tighter connection between heavy social media use</a><span> and concurrent mental health problems. Nor would it explain why mental health dropped so rapidly in the early 2010s (especially for girls) if permissive parenting (or some other variable about family life) was the real culprit.</span></p><p><span>And finally, we note that no one study is definitive, and more research is needed. We have been able to find a </span><a href="https://www.sciencedirect.com/science/article/pii/S0160791X22001439" rel="">few</a><span> </span><a href="https://doi.org/10.1080/17482798.2020.1725902" rel="">other</a><span> </span><a href="https://srcd.onlinelibrary.wiley.com/doi/10.1111/cdev.13851" rel="">studies</a><span> that </span><a href="https://wheatley.byu.edu/00000182-8d78-dff6-afab-8ffd11ce0001/teaching-by-example-pdf" rel="">examined</a><span> the age at which children got their first smartphones (We have created a new appendix [8.14] in our collaborative review doc on </span><a href="https://docs.google.com/document/d/1w-HOfseF2wF9YIpXwUUtP65-olnkPyWcgF5BiAtBEy0/edit#" rel="">Social Media and Mental Health</a><span>). So far they are mostly smaller studies that have produced mixed results. If you know of any others, please add them to the doc or put a link to them in the comments below. We want to get this right.</span></p><p><span>We cannot be </span><em>certain</em><span> that the correlations shown in the data are evidence of causality, but we think it is appropriate for those who care for children to act on the </span><em>preponderance</em><span> of the evidence (which is the standard in a civil trial) rather than waiting for evidence </span><em>beyond a reasonable doubt </em><span>(which is the standard used in a criminal trial. See proposition 2 in </span><a href="https://jonathanhaidt.substack.com/p/why-some-researchers-think-im-wrong" rel="">this post</a><span>.) There is </span><a href="https://docs.google.com/document/d/1gojn35zOhnhfgdgquf5Tj4VsZk7Gtugt-eYS-2fQnpE/edit#" rel="">increasing evidence</a><span> that smartphones have a variety of detrimental effects on child development including reductions of sleep, focus, and time with friends in person, along with increases in addictive behaviors, so it makes sense that the cumulative effect of getting one’s first phone in elementary school would be larger than for those who don’t get a phone until high school. This is an important point made in the Sapien Labs report: The relationships they find suggest that there is a </span><em>cumulative effect</em><span> of having had a smartphone (and its many apps) over many years of childhood; they do not represent the effects of having used a phone a lot in recent days or weeks (which is the focus of </span><a href="https://docs.google.com/document/d/1w-HOfseF2wF9YIpXwUUtP65-olnkPyWcgF5BiAtBEy0/edit" rel="">most of the published research</a><span>).</span></p><p><span>We think the implications for action are strongest for policies related to children and younger teens––those still in elementary and middle school (that is, age 14 and below) In most of the graphs in this post, including those for the Anglosphere, the slopes of the lines are steepest for those ages, and the links are visible for boys as well as girls (though smaller for boys). This concern to protect children before and during early puberty is consistent with a </span><a href="https://www.nature.com/articles/s41467-022-29296-3" rel="">study published last year</a><span> which found that in a large longitudinal study of British adolescents, the peak years for evidence of links between social media use and lower satisfaction with life were 11-13 for girls (which corresponds to the early part of puberty), while for boys (who begin puberty a bit later) it was 14-15.</span></p><p>On the other hand, the implications for action related to older teens and especially boys are less clear, at least within the United States and other Anglosphere nations. The lines for boys are somewhat flat in those ages, and the increases for girls generally slow down too. Furthermore, the arguments for why high school students need a smartphone (rather than an alternative, such as a flip-phone) are stronger than the arguments for why elementary and middle school students need one.&nbsp;</p><p>We, therefore, believe that the Sapien Labs findings should motivate us to think carefully about whether and when to give children their own smart devices, especially before high school. It is not the Internet per se that is harmful; so much of the internet is fantastically educational, useful, and entertaining. The most relevant questions, we think, are: 1) At what age do you want to give a child continuous access to the internet and social media, even when away from home, even when sitting in class? 2) At what age do you want to give social media companies, and other companies, continuous access to a child’s attention? And 3) does a child really need a smartphone when other kinds of phones (such as “flip phones” or Light Phones) work just as well for general communication (phone calls and texting)?</p><p><span>The group </span><a href="https://www.waituntil8th.org/" rel="">Wait Until 8th</a><span> was founded to solve the collective action problem that parents and teens are in: Even if most parents wanted to wait until high school to give their children smartphones and social media, as long as most kids have those things by 6th grade, there will be enormous pressure on their children, and hence on the parents, to relent. Unless the parents can coordinate. So Wait Until 8th asks parents to sign a pledge, when their children are in elementary school, that they will wait until 8th grade to give them a smartphone. The pledge only takes effect once ten families in that child’s grade have signed the pledge so that the child will have a community of peers and will not feel so isolated before 8th grade.</span></p><p>We think this is a great idea, we just suggest that the pledge should be: Wait Until 9th. Or Wait Until High School. Children are usually 12 or 13 at the start of 8th grade; that is still within the period of early puberty. Plus, if 8th graders have smartphones, that means that smartphones will be everywhere in middle schools, increasing the desire of 7th graders to get them. To solve collective action problems, we think it’s best to focus on setting good norms within collectives (such as schools): make elementary schools and middle schools be smartphone free.&nbsp;</p><p><span>Parents understandably want to be able to reach their children when they are away from home, and a flip phone or other “dumbphone” is a very reasonable first phone that allows parents and children to reach each other. We suggest that parents not give smartphones as first phones. Let children learn to master a simpler kind of phone, one that cannot be loaded with addictive apps. Wait Until 8th offers an </span><a href="https://www.waituntil8th.org/devices" rel="">excellent list</a><span> of the many smartphone alternatives.</span></p><p><span>Many of the teachers and heads of schools that Jon talks to are bitter about the effects of smartphones on their students and their school culture. They complain about the constant drama unfolding on social media during the school day. They complain about the distraction and the increased difficulty of getting students’ attention during class, since many students sneak looks at their frequently-buzzing phones, especially those sitting in the back rows. Many schools say that they ban phones, but what they often seem to mean is “the rule is that you can’t take out your phone during class.” That means that some students (the ones most suffering from phone addiction) will learn to do it stealthily, and many of the rest will just pull out their phones as soon as class is over, thereby </span><a href="https://www.sciencedirect.com/science/article/pii/S0022103122000634" rel="">missing out on face-to-face interactions</a><span> with the students right next to them.&nbsp;</span></p><p><span>We suggest that schools consider going phone free, meaning that students can use their phones to arrive and depart from school, but once they enter, their phones (smart or dumb) would be placed in a phone locker, or in a lockable pouch. We think the case for doing this in elementary schools and middle schools is strongest. In a few weeks, Jon will write a substack post laying out the empirical evidence that smartphones distract students and disrupt education, </span><a href="https://www.journals.uchicago.edu/doi/10.1086/691462" rel="">even when they are kept in students’ pockets</a><span>.</span></p><p>We also suggest that school districts collaborate with social scientists to do experiments on entire schools, rather than on individual students. What if a state or district identified 20 middle schools that were willing to cooperate, and then randomly assigned half of them to go phone free?&nbsp; There is no research of this kind that we can find, yet such a simple study would give us results within a single year that could potentially yield findings that improve both mental health and educational outcomes.&nbsp;</p><p><span>If there is a cumulative effect of smartphone ownership in childhood, and if the effect is due in part to heavy use of certain kinds of apps (such as social media) rather than other kinds of apps (such as watching movies, or using Wikipedia), then it becomes even more vital that we develop ways of age-gating certain apps and content. At present, </span><a href="https://en.wikipedia.org/wiki/Children%27s_Online_Privacy_Protection_Act" rel="">US law sets a minimum age of 13</a><span> at which children can sign contracts with companies to give away their data (when they check a box on the terms of service). But </span><a href="https://www.wsj.com/articles/how-13-became-the-internets-age-of-adulthood-11560850201" rel="">the law was written such that</a><span> the companies are not required to verify ages. As long as a child </span><em>says</em><span> that she is 13 or older, she’s in and can create a social media account.&nbsp;</span></p><p><span>This must change. If the minimum age were enforced, it would help parents solve their collective action problem, at least with regard to Instagram, Tiktok, and other social media sites for underage users. It is precisely Congress’s failure to enforce the age 13 rule that puts parents in the trap. Many states are now introducing legislation to remedy this omission. And there is one federal bill that does a particularly good job of focusing on age limits and age verification: The </span><a href="https://www.schatz.senate.gov/news/press-releases/schatz-cotton-murphy-britt-introduce-bipartisan-legislation-to-help-protect-kids-from-harmful-impacts-of-social-media" rel="">Protecting Kids on Social Media Act</a><span>, introduced by Senators Schatz (D-HI), Cotton (R-AR), Murphy (D-CT), and Britt (R-AL). The act would “set a minimum age of 13 to use social media apps and would require parental consent for 13 through 17 year-olds.&nbsp; The bill would also prevent social media companies from feeding content using algorithms to users under the age of 18.” The bill also requires social media companies to develop rigorous age verification methods. (There are already many in existence, and many more would appear if the bill gets passed.) We also think the </span><a href="https://www.blackburn.senate.gov/2023/5/blackburn-blumenthal-introduce-bipartisan-kids-online-safety-act" rel="">Kids Online Safety Act of 2022</a><span>, introduced by senators Blumenthal (D-CT) and Blackburn (R-TN) would do a lot to make social media less damaging to children, and easier for parents to control. The fact that so many bills are bipartisan, at both the state and federal level, is a very encouraging sign in our polarized time. Legislators often report seeing the problems in their own children.</span></p><p><strong>In conclusion:</strong><span> there is a great deal that can be done, individually and collectively, to address one of the top fears that parents express, about the safety and health of their children. The Sapien Labs data offers us new insight into the nature of the problem, and it alerts us that the problem may be global. It also guides us to the ages at which reform efforts are most likely to work.</span></p><p>POSTSCRIPTS (added on May 18, 2023)</p><p>1—We welcome additional and deeper analyses of the Sapien Labs data, and will post links here to such reports whether they support or contradict our analyses in this post.</p><p><span>2—One issue we should have discussed in the text is the inclusion of </span><em>tablets</em><span>, along with smartphones, in the Sapien Labs’ questionnaire. If their findings differ from those of other labs which asked only about age of first </span><em>smartphone</em><span>, then we won’t know whether part of the difference is the inclusion of tablets. We hope that future studies will ask about the two devices separately to figure out which devices are associated with harm at which ages (if any). </span></p><p>3—Some commentary online has made the important point that it’s not the phone itself which is harmful; it is the particular apps that the child uses, a child with a particular personality, in the context of a particular family that does (or does not) exercise oversight and apply restrictions. We agree. The original iPhone introduced by Steve Jobs was three devices: a phone, an iPod, and a web browser. Great! Three tools. Probably not harmful. It’s the addition of the app store that turned the smartphone into a portal to everything. If early acquisition of a smartphone is shown to be reliably associated with developmental problems, it would likely be because it enables continuous 18-hour-per-day access to hundreds of activities. </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Qualcomm's Oryon core: A long time in the making (145 pts)]]></title>
            <link>https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/</link>
            <guid>40935154</guid>
            <pubDate>Thu, 11 Jul 2024 10:17:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/">https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/</a>, See on <a href="https://news.ycombinator.com/item?id=40935154">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>In 2019, a startup called Nuvia came out of stealth mode. Nuvia was notable because its leadership included several notable chip architects, including <a href="https://www.theregister.com/2023/05/01/apple_nuvia_lawsuit/">one who used to work for Apple</a>. Apple chips like the M1 drew recognition for landing in the same performance neighborhood as AMD and Intel’s offerings while offering better power efficiency. Nuvia had similar goals, aiming to create a power efficient core that could could surpass designs from AMD, Apple, Arm, and Intel. Qualcomm acquired Nuvia in 2021, bringing its staff into Qualcomm’s internal CPU efforts.</p>
<div>
<figure><a href="https://chipsandcheese.com/qc_sd_timeline/"><img decoding="async" width="688" height="99" data-attachment-id="29971" data-permalink="https://chipsandcheese.com/qc_sd_timeline/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/qc_sd_timeline.png?fit=870%2C125&amp;ssl=1" data-orig-size="870,125" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="qc_sd_timeline" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/qc_sd_timeline.png?fit=870%2C125&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/qc_sd_timeline.png?fit=688%2C99&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/qc_sd_timeline.png?resize=688%2C99&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/qc_sd_timeline.png?w=870&amp;ssl=1 870w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/qc_sd_timeline.png?resize=768%2C110&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>Bringing on Nuvia staff rejuvenated Qualcomm’s internal CPU efforts, which led to the Oryon core in Snapdragon X Elite. Oryon arrives nearly five years after Nuvia hit the news, and almost eight years after Qualcomm last released a smartphone SoC with internally designed cores. For people following Nuvia’s developments, it has been a long wait.</p>
<div>
<figure><a href="https://chipsandcheese.com/oryon_cpu_cluster_slide/"><img decoding="async" width="688" height="387" data-attachment-id="29842" data-permalink="https://chipsandcheese.com/oryon_cpu_cluster_slide/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_cpu_cluster_slide.jpg?fit=2549%2C1433&amp;ssl=1" data-orig-size="2549,1433" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="oryon_cpu_cluster_slide" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_cpu_cluster_slide.jpg?fit=2549%2C1433&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_cpu_cluster_slide.jpg?fit=688%2C387&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_cpu_cluster_slide.jpg?resize=688%2C387&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_cpu_cluster_slide.jpg?w=2549&amp;ssl=1 2549w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_cpu_cluster_slide.jpg?resize=1280%2C720&amp;ssl=1 1280w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_cpu_cluster_slide.jpg?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_cpu_cluster_slide.jpg?resize=1536%2C864&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_cpu_cluster_slide.jpg?resize=2048%2C1151&amp;ssl=1 2048w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_cpu_cluster_slide.jpg?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_cpu_cluster_slide.jpg?resize=1600%2C899&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_cpu_cluster_slide.jpg?resize=1320%2C742&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_cpu_cluster_slide.jpg?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>Now, thanks to the wonderful folks who donate to our <a href="https://www.patreon.com/ChipsandCheese">Patreon members</a> and <a href="https://www.paypal.com/donate?hosted_button_id=4EMPH66SBGVSQ">Paypal donators</a>, we have a Samsung Galaxy Book4 Edge 16 inch Laptop equipped with a Qualcomm Snapdragon X1E-80-100 CPU in our possession.</p>
<p>Note, because there has not been any upstreamed Device Tree for this laptop, we were not able to get a Linux desktop installed on it so a lot of our testing had to be done on Windows Subsystem for Linux (WSL).</p>
<h2>System Architecture</h2>
<p>The Snapdragon X1E-80-10 implements 12 Oryon cores in three quad-core clusters, each with a 12 MB L2 cache. Like Kryo in the Snapdragon 820, Qualcomm opted against a hybrid core configuration. Instead, Snapdragon X Elite’s Oryon CPU clusters run at different maximum clocks to offer a combination of good single threaded and multithreaded performance.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30021"><img decoding="async" width="553" height="243" data-attachment-id="30021" data-permalink="https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/sdxe_system_arch/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_system_arch.png?fit=553%2C243&amp;ssl=1" data-orig-size="553,243" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sdxe_system_arch" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_system_arch.png?fit=553%2C243&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_system_arch.png?fit=553%2C243&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_system_arch.png?resize=553%2C243&amp;ssl=1" alt="" data-recalc-dims="1"></a></figure></div>
<p>Snapdragon X Elite’s clustered arrangement is clearly visible from a core to core latency test, which bounces cachelines between core pairs and measures how long that takes. Transfers within a core are handled reasonably quickly, but cross-cluster transfers incur high latency especially for a monolithic chip with consumer core counts.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=29802"><img loading="lazy" decoding="async" width="537" height="279" data-attachment-id="29802" data-permalink="https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/oryon_c2c/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_c2c.png?fit=537%2C279&amp;ssl=1" data-orig-size="537,279" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="oryon_c2c" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_c2c.png?fit=537%2C279&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_c2c.png?fit=537%2C279&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_c2c.png?resize=537%2C279&amp;ssl=1" alt="" data-recalc-dims="1"></a></figure></div>
<p>Latencies are less consistent compared to Qualcomm’s prior attempt at making a laptop chip. The 8cx Gen 3 has four Cortex X1 cores and four Cortex A78 cores. It likely uses Arm’s DSU interconnect, which also implements a shared L3 cache.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=29814"><img loading="lazy" decoding="async" width="359" height="199" data-attachment-id="29814" data-permalink="https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/8cx_gen3_c2c/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/8cx_gen3_c2c.png?fit=359%2C199&amp;ssl=1" data-orig-size="359,199" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="8cx_gen3_c2c" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/8cx_gen3_c2c.png?fit=359%2C199&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/8cx_gen3_c2c.png?fit=359%2C199&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/8cx_gen3_c2c.png?resize=359%2C199&amp;ssl=1" alt="" data-recalc-dims="1"></a></figure></div>
<p>Nuvia’s co-founder used to work for Apple, making M1 is a notable comparison point. Apple also uses quad core clusters with a shared L2. However, M1 uses a hybrid core arrangement. Core to core latency is similar within a cluster. Cross-cluster transfers incur high latency much like on Snapdragon X Elite, though absolute values are a bit better.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30024"><img loading="lazy" decoding="async" width="363" height="200" data-attachment-id="30024" data-permalink="https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/m1_c2c/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/m1_c2c.png?fit=363%2C200&amp;ssl=1" data-orig-size="363,200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="m1_c2c" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/m1_c2c.png?fit=363%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/m1_c2c.png?fit=363%2C200&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/m1_c2c.png?resize=363%2C200&amp;ssl=1" alt="" data-recalc-dims="1"></a><figcaption>Run under Asahi Linux, on a Macbook Air owned by dgb. Mac OS does not have system calls for setting thread affinity</figcaption></figure></div>
<p>Both Snapdragon X Elite and M1 have a System Level Cache (SLC) that can service multiple blocks on the chip, at the expense of lower performance than a cache dedicated to one block.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30027"><img loading="lazy" decoding="async" width="447" height="230" data-attachment-id="30027" data-permalink="https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/m1_system_arch/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/m1_system_arch.png?fit=447%2C230&amp;ssl=1" data-orig-size="447,230" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="m1_system_arch" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/m1_system_arch.png?fit=447%2C230&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/m1_system_arch.png?fit=447%2C230&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/m1_system_arch.png?resize=447%2C230&amp;ssl=1" alt="" data-recalc-dims="1"></a></figure></div>
<p>Snapdragon X Elite’s main competitors will be AMD’s Phoenix and Intel’s Meteor Lake. AMD’s Phoenix SoC has eight Zen 4 cores with 16 MB of L3. All eight of Phoenix’s cores are placed in the same cluster, so a core to core latency test is pretty boring to look at. Latencies are very low overall. However, it’s worth noting that AMD’s cross-cluster latencies on 16 core desktop Zen 4 variants is still better than Snapdragon X Elite or M1’s, at 80-90 ns.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=29812"><img loading="lazy" decoding="async" width="680" height="360" data-attachment-id="29812" data-permalink="https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/phx_c2c/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/phx_c2c.png?fit=680%2C360&amp;ssl=1" data-orig-size="680,360" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="phx_c2c" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/phx_c2c.png?fit=680%2C360&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/phx_c2c.png?fit=680%2C360&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/phx_c2c.png?resize=680%2C360&amp;ssl=1" alt="" data-recalc-dims="1"></a></figure></div>
<p>Intel’s Meteor Lake has a complex hybrid setup with six Redwood Cove performance cores, eight Crestmont efficiency cores, and two Crestmont low power cores. The Redwood Cove and regular Cresmont cores share a 24 MB L3, while the low power Crestmont cluster makes do with a 2 MB L2 as its last level cache.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30029"><img loading="lazy" decoding="async" width="688" height="214" data-attachment-id="30029" data-permalink="https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/mtl_system_arch/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/mtl_system_arch.png?fit=926%2C288&amp;ssl=1" data-orig-size="926,288" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="mtl_system_arch" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/mtl_system_arch.png?fit=926%2C288&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/mtl_system_arch.png?fit=688%2C214&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/mtl_system_arch.png?resize=688%2C214&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/mtl_system_arch.png?w=926&amp;ssl=1 926w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/mtl_system_arch.png?resize=768%2C239&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>Core to core latencies are low as long as we stay within Meteor Lake’s CPU tile, but crossing over to the low power E-Core cluster takes much longer.</p>
<div>
<figure><a href="https://chipsandcheese.com/2024/05/13/meteor-lakes-e-cores-crestmont-makes-incremental-progress/crestmont_c2c/"><img loading="lazy" decoding="async" width="688" height="264" data-attachment-id="28203" data-permalink="https://chipsandcheese.com/2024/05/13/meteor-lakes-e-cores-crestmont-makes-incremental-progress/crestmont_c2c/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/04/crestmont_c2c.png?fit=1252%2C481&amp;ssl=1" data-orig-size="1252,481" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="crestmont_c2c" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/04/crestmont_c2c.png?fit=1252%2C481&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/04/crestmont_c2c.png?fit=688%2C264&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/04/crestmont_c2c.png?resize=688%2C264&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/04/crestmont_c2c.png?w=1252&amp;ssl=1 1252w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/04/crestmont_c2c.png?resize=768%2C295&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/04/crestmont_c2c.png?resize=1200%2C461&amp;ssl=1 1200w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<h2>Clock Behavior</h2>
<p>CPUs conserve power by reducing clocks when idle. Transitioning from idle to a high performance state takes time. On battery power, the Snapdragon X Elite doesn’t reach maximum clock speeds until over 110 ms after load is applied. This is almost certainly a deliberate policy on Samsung’s part to extend battery life by avoiding high power states during short bursts of activity. Intel’s Meteor Lake takes that strategy to the extreme, and does not reach maximum boost clocks on battery. AMD has a very fast boost policy on both wall and battery power, reaching 5 GHz in a millisecond or less.</p>
<div>
<figure><a href="https://chipsandcheese.com/sdxe_boost/"><img loading="lazy" decoding="async" width="688" height="620" data-attachment-id="30077" data-permalink="https://chipsandcheese.com/sdxe_boost/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_boost.png?fit=947%2C853&amp;ssl=1" data-orig-size="947,853" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sdxe_boost" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_boost.png?fit=947%2C853&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_boost.png?fit=688%2C620&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_boost.png?resize=688%2C620&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_boost.png?w=947&amp;ssl=1 947w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_boost.png?resize=768%2C692&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>On wall power, Samsung has opted not to let the CPU idle. This allows for better responsiveness because the cores start out at 3.4 GHz, and can reach 4 GHz in 1.44 milliseconds. However, it makes the laptop noticeably warm even at idle, a trait not shared by Meteor Lake or Phoenix.</p>
<h2>Core Overview</h2>
<p>Qualcomm’s Oryon is an 8-wide core with very high reordering capacity. True to its lineage, Oryon inherits philosophies from both Apple’s Firestorm and Qualcomm’s own much older Kryo. But unlike Kryo and M1, Oryon can run at 4 GHz and beyond. The top end Snapdragon X Elite SKU can reach 4.3 GHz on two cores. The X1E-80-100 we tested here can reach 4 GHz.</p>
<div>
<figure><a href="https://chipsandcheese.com/cheese_oryon_diagram_revised/"><img loading="lazy" decoding="async" width="688" height="287" data-attachment-id="29978" data-permalink="https://chipsandcheese.com/cheese_oryon_diagram_revised/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/cheese_oryon_diagram_revised.png?fit=1933%2C805&amp;ssl=1" data-orig-size="1933,805" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cheese_oryon_diagram_revised" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/cheese_oryon_diagram_revised.png?fit=1933%2C805&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/cheese_oryon_diagram_revised.png?fit=688%2C287&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/cheese_oryon_diagram_revised.png?resize=688%2C287&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/cheese_oryon_diagram_revised.png?w=1933&amp;ssl=1 1933w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/cheese_oryon_diagram_revised.png?resize=768%2C320&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/cheese_oryon_diagram_revised.png?resize=1536%2C640&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/cheese_oryon_diagram_revised.png?resize=1200%2C500&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/cheese_oryon_diagram_revised.png?resize=1600%2C666&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/cheese_oryon_diagram_revised.png?resize=1320%2C550&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/cheese_oryon_diagram_revised.png?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a><figcaption>Oryon Block Diagram</figcaption></figure></div>
<p>Zen 4 still has a clock speed advantage, but the gap isn’t as big with mobile. Next to Oryon, Zen 4’s architecture looks tiny. It’s only 6-wide and has smaller out-of-order buffers. However, Zen 4 can run at higher clock speeds. The Ryzen 7840HS can reach 5.1 GHz in the HP ZBook Firefly 14 G10 A.</p>
<div>
<figure><a href="https://chipsandcheese.com/2022/11/05/amds-zen-4-part-1-frontend-and-execution-engine/zen4-drawio-2/"><img loading="lazy" decoding="async" width="688" height="456" data-attachment-id="11608" data-permalink="https://chipsandcheese.com/2022/11/05/amds-zen-4-part-1-frontend-and-execution-engine/zen4-drawio-2/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/11/Zen4.drawio.png?fit=1632%2C1082&amp;ssl=1" data-orig-size="1632,1082" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Zen4.drawio" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/11/Zen4.drawio.png?fit=1632%2C1082&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/11/Zen4.drawio.png?fit=688%2C456&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/11/Zen4.drawio.png?resize=688%2C456&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/11/Zen4.drawio.png?w=1632&amp;ssl=1 1632w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/11/Zen4.drawio.png?resize=768%2C509&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/11/Zen4.drawio.png?resize=1536%2C1018&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/11/Zen4.drawio.png?resize=1200%2C796&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/11/Zen4.drawio.png?resize=1600%2C1061&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/11/Zen4.drawio.png?resize=1320%2C875&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2022/11/Zen4.drawio.png?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a><figcaption>Zen 4 Block Diagram</figcaption></figure></div>
<p>Qualcomm states that Oryon has a 13 cycle misprediction penalty, which is the same as the common case for Zen 4.</p>
<h2>Branch Predictor</h2>
<p>The branch predictor is one of the best ways to get more performance per joule of energy spent. Modern CPUs therefore invest heavily in branch prediction. As core width and reordering capacity increase, an accurate branch predictor gets even more important because a mispredict tends to cause more wasted work.</p>
<h4>Direction Prediction</h4>
<p>The direction predictor does exactly as it sounds, it tells the branch predictor what direction the branch is likely to go. Oryon appears to have a single level direction predictor much like Golden Cove.</p>
<div>
<figure><img loading="lazy" decoding="async" width="688" height="332" data-attachment-id="29455" data-permalink="https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/image-8-22/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/06/image-8.png?fit=1194%2C577&amp;ssl=1" data-orig-size="1194,577" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Oryon Branch Predictor" data-image-description="" data-image-caption="<p>Oryon Direction Predictor</p>
" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/06/image-8.png?fit=1194%2C577&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/06/image-8.png?fit=688%2C332&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/06/image-8.png?resize=688%2C332&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/06/image-8.png?w=1194&amp;ssl=1 1194w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/06/image-8.png?resize=768%2C371&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"><figcaption>Oryon’s direction predictor</figcaption></figure></div>
<p>Oryon Branch Prediction Unit direction predictor does well against Golden Cove but does struggle against Zen 4.</p>

<h3>Branch Target Caching</h3>
<p>A branch predictor’s job can be simplified to telling the frontend what address it should fetch from next. Part of that involves determining whether a branch is taken. If it is, the predictor needs to tell the frontend where that branch goes with minimal delay. Branch Target Buffers (BTBs) cache branch destination addresses to speed that process up. Like any cache, different BTB implementations have varying performance characteristics. Modern CPUs often have multi-level BTBs too to get a balance between speed and ability to cope with large branch footprints.</p>
<p>Oryon appears to tie its BTB to the instruction cache, as taken branches see higher latency as the test loop spills out of the instruction cache. Branches contained within a 8 KB footprint can be handled with single cycle latency, something AMD calls “zero bubble” branching. Applications with a larger branch footprint can do one taken branch every three cycles, as long as code fits in the 192 KB L1 instruction cache.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=29774"><img loading="lazy" decoding="async" width="688" height="336" data-attachment-id="29774" data-permalink="https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/oryon_btb/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_btb.png?fit=1064%2C519&amp;ssl=1" data-orig-size="1064,519" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="oryon_btb" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_btb.png?fit=1064%2C519&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_btb.png?fit=688%2C336&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_btb.png?resize=688%2C336&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_btb.png?w=1064&amp;ssl=1 1064w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_btb.png?resize=768%2C375&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>Qualcomm could have a branch address calculator placed early in the decode pipeline. With that interpretation, Oryon would have a 8 KB L0 instruction cache with single cycle latency. The 192 KB L1i would have 3 cycle latency. Oryon’s BTB setup has parallels to Kryo’s, as both cores enjoy fast branching as long as the test fits within 8 KB. It also shares traits with M1, which also sees taken branch latency increase as the test exceeds certain code footprint sizes. M1 however only gets single cycle branching within 4 KB.</p>
<div>
<figure><a href="https://chipsandcheese.com/m1_btb/"><img loading="lazy" decoding="async" width="688" height="362" data-attachment-id="29956" data-permalink="https://chipsandcheese.com/m1_btb/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/m1_btb.png?fit=1223%2C643&amp;ssl=1" data-orig-size="1223,643" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="m1_btb" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/m1_btb.png?fit=1223%2C643&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/m1_btb.png?fit=688%2C362&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/m1_btb.png?resize=688%2C362&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/m1_btb.png?w=1223&amp;ssl=1 1223w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/m1_btb.png?resize=768%2C404&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/m1_btb.png?resize=1200%2C631&amp;ssl=1 1200w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>AMD’s Zen 4, as well as Arm Ltd and Intel cores for that matter, decouple their branch target caching from the instruction cache. Clam’s BTB test sees higher latency once branches exceed certain counts, with branch spacing being less of a factor.</p>
<div>
<figure><a href="https://chipsandcheese.com/2023/10/08/zen-5s-leaked-slides/zen4_btb_latency_cond/"><img loading="lazy" decoding="async" width="688" height="355" data-attachment-id="22279" data-permalink="https://chipsandcheese.com/2023/10/08/zen-5s-leaked-slides/zen4_btb_latency_cond/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/09/zen4_btb_latency_cond.png?fit=944%2C487&amp;ssl=1" data-orig-size="944,487" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen4_btb_latency_cond" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/09/zen4_btb_latency_cond.png?fit=944%2C487&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/09/zen4_btb_latency_cond.png?fit=688%2C355&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/09/zen4_btb_latency_cond.png?resize=688%2C355&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/09/zen4_btb_latency_cond.png?w=944&amp;ssl=1 944w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/09/zen4_btb_latency_cond.png?resize=768%2C396&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<h3>Indirect Branch Prediction</h3>
<p>Indirect branches can go to more than one target, adding another degree of difficulty to prediction. Oryon appears to have a 2048 entry indirect branch predictor.</p>
<figure data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/chipsandcheese.com\/2024\/07\/09\/qualcomms-oryon-core-a-long-time-in-the-making\/&quot;}">
<figure><img loading="lazy" decoding="async" width="688" height="370" data-attachment-id="29929" data-permalink="https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/oryon-indirect-predictor/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/Oryon-indirect-predictor.png?fit=8192%2C4409&amp;ssl=1" data-orig-size="8192,4409" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Oryon-indirect-predictor" data-image-description="" data-image-caption="<p>Oryon Indirect Branch Predictor</p>
" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/Oryon-indirect-predictor.png?fit=2560%2C1378&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/Oryon-indirect-predictor.png?fit=688%2C370&amp;ssl=1" tabindex="0" role="button" data-id="29929" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/Oryon-indirect-predictor.png?resize=688%2C370&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/Oryon-indirect-predictor.png?resize=3840%2C2067&amp;ssl=1 3840w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/Oryon-indirect-predictor.png?resize=768%2C413&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/Oryon-indirect-predictor.png?resize=1536%2C827&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/Oryon-indirect-predictor.png?resize=2048%2C1102&amp;ssl=1 2048w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/Oryon-indirect-predictor.png?resize=1200%2C646&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/Oryon-indirect-predictor.png?resize=1600%2C861&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/Oryon-indirect-predictor.png?resize=1320%2C710&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/Oryon-indirect-predictor.png?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></figure>
<figure><img loading="lazy" decoding="async" width="688" height="396" data-attachment-id="29927" data-permalink="https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/zen4_indirectbranch-2/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/zen4_indirectbranch.webp?fit=1169%2C673&amp;ssl=1" data-orig-size="1169,673" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zen4_indirectbranch" data-image-description="" data-image-caption="<p>Zen 4 Indirect Branch Predictor</p>
" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/zen4_indirectbranch.webp?fit=1169%2C673&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/zen4_indirectbranch.webp?fit=688%2C396&amp;ssl=1" tabindex="0" role="button" data-id="29927" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/zen4_indirectbranch.webp?resize=688%2C396&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/zen4_indirectbranch.webp?w=1169&amp;ssl=1 1169w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/zen4_indirectbranch.webp?resize=768%2C442&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></figure>
<figure><img loading="lazy" decoding="async" width="688" height="395" data-attachment-id="29930" data-permalink="https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/glc_indirectbranch-2/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/glc_indirectbranch.webp?fit=1168%2C671&amp;ssl=1" data-orig-size="1168,671" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="glc_indirectbranch" data-image-description="" data-image-caption="<p>Golden Cove Indirect Branch Predictor</p>
" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/glc_indirectbranch.webp?fit=1168%2C671&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/glc_indirectbranch.webp?fit=688%2C395&amp;ssl=1" tabindex="0" role="button" data-id="29930" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/glc_indirectbranch.webp?resize=688%2C395&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/glc_indirectbranch.webp?w=1168&amp;ssl=1 1168w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/glc_indirectbranch.webp?resize=768%2C441&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></figure>
</figure>
<p>Oryon’s indirect predictor isn’t as big as Zen 4’s 3072 entry indirect branch predictor and can’t track as many targets. But unlike Zen 4, there is no slowly increasing penalty after 32 targets for a single branch. This likely means that Oryon doesn’t use a similar mechanism to Zen 4. Now comparing Oryon to Golden Cove and they are very similar to each other but Oryon can track more targets than Golden Cove can.</p>
<p>Returns are a special case of indirect branches. Oryon has a deep 48 entry return stack. Zen 4 for comparison has a 32 entry return stack. Both are quite deep, and likely enough to handle the vast majority of code. Qualcomm’s strategy mirrors that of Apple M1’s Firestorm architecture, which <a href="https://twitter.com/dougallj/status/1580826539205496832">apparently has a 50 entry return stack</a>.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=29776"><img loading="lazy" decoding="async" width="688" height="294" data-attachment-id="29776" data-permalink="https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/oryon_returnstack/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_returnstack.png?fit=867%2C370&amp;ssl=1" data-orig-size="867,370" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="oryon_returnstack" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_returnstack.png?fit=867%2C370&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_returnstack.png?fit=688%2C294&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_returnstack.png?resize=688%2C294&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_returnstack.png?w=867&amp;ssl=1 867w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_returnstack.png?resize=768%2C328&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>When return stack capacity is exceeded, Oryon sees a sharp increase in call+return time. 4-5 ns would be 15-18 cycles at 3.7 GHz, which is high enough to be a branch mispredict. That’s similar to what Dougall discovered on Apple’s M1 too, and suggests the core clears the return stack when it overflows instead of implementing a mechanism to more gracefully handle that case.</p>
<h2>Fetch and Decode</h2>
<p>Next, the frontend has to fetch instructions from memory and decode them into micro-ops. Oryon and Apple’s Firestorm cores use a very similar strategy. Both have a huge 192 KB L1 instruction cache feeding a 8-wide decoder. AMD’s Zen 4 enjoys high instruction bandwidth for small instruction footprints, but sustained bandwidth is restricted by Zen 4’s 6-wide rename stage downstream. Compared to Oryon and Firestorm, Zen 4c’s small 32 KB instruction cache is a distinct disadvantage.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=29780"><img loading="lazy" decoding="async" width="688" height="289" data-attachment-id="29780" data-permalink="https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/oryon_ifetch/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_ifetch.png?fit=1211%2C509&amp;ssl=1" data-orig-size="1211,509" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="oryon_ifetch" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_ifetch.png?fit=1211%2C509&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_ifetch.png?fit=688%2C289&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_ifetch.png?resize=688%2C289&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_ifetch.png?w=1211&amp;ssl=1 1211w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_ifetch.png?resize=768%2C323&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_ifetch.png?resize=1200%2C504&amp;ssl=1 1200w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a><figcaption>Credit to Dougall for contributing the M1 Max test result. Zen 4 is capped at 6 micro-ops per cycle. Throughput from the micro-op cache is higher in this simple test because Zen 4 fuses adjacent NOPs into a single micro-op</figcaption></figure></div>
<p>However, AMD maintains high frontend bandwidth for very large code footprints, as it can sustain more than 12 bytes per cycle even when pulling code from L3. Oryon and M1 have much lower code fetch bandwidth after a L1i miss.</p>
<h2>Rename/Allocate</h2>
<p>Micro-ops from the frontend need to have backend resources allocated to track them during out-of-order execution. That process involves register renaming to break false write-after-write dependencies. The renamer can break other dependencies as well by creatively allocating backend resources. For example, an instruction that moves values between registers can be eliminated by having its “result” point to the source register. Instructions known to set a register to zero can similarly be optimized.</p>
<figure><table><tbody><tr><td></td><td>Oryon IPC</td><td>Zen 4 IPC</td><td>Redwood Cove IPC</td></tr><tr><td>Independent MOVs</td><td>7.4</td><td>5.73</td><td>4.77</td></tr><tr><td>Dependent MOVs</td><td>1.18</td><td>5.71</td><td>5.25</td></tr><tr><td>XOR/EOR r, r</td><td>1</td><td>5.73</td><td>4.05</td></tr><tr><td>MOV r, 0</td><td>5.32</td><td>3.77</td><td>4.97</td></tr></tbody></table></figure>
<p>Oryon has move elimination, though it’s not as robust as Intel or AMD’s implementation for chained dependent MOVs. There’s no zeroing idiom recognition for XOR-ing a register with itself, or subtracting a register from itself. Moving an immediate value of zero to a register works of course for breaking dependencies. However, throughput for that doesn’t exceed 6 IPC and suggests Oryon still uses an ALU pipe to write zero to a register.</p>
<h2>Out of Order Execution</h2>
<p>Oryon features a massive out-of-order execution engine to hide latency and extract instruction level parallelism. Its reorder buffer, which helps commit instruction results in program order, is massive with 680 entries. Both the integer and floating point register files have 384 entries available for speculative results. Add another 32 entries for known-good architectural register values, and that comes out to 416 total entries.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=29790"><img loading="lazy" decoding="async" width="688" height="387" data-attachment-id="29790" data-permalink="https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/oryon_be_slide/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_be_slide.jpg?fit=2535%2C1426&amp;ssl=1" data-orig-size="2535,1426" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="oryon_be_slide" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_be_slide.jpg?fit=2535%2C1426&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_be_slide.jpg?fit=688%2C387&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_be_slide.jpg?resize=688%2C387&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_be_slide.jpg?w=2535&amp;ssl=1 2535w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_be_slide.jpg?resize=1280%2C720&amp;ssl=1 1280w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_be_slide.jpg?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_be_slide.jpg?resize=1536%2C864&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_be_slide.jpg?resize=2048%2C1152&amp;ssl=1 2048w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_be_slide.jpg?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_be_slide.jpg?resize=1600%2C900&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_be_slide.jpg?resize=1320%2C743&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_be_slide.jpg?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>Memory ordering queues are more conservatively sized. The load and store queues have 192 and 56 entries respectively. While the load queue has comparable capacity to Redwood Cove’s and is appropriately sized to cover the reorder buffer, the store queue feels a bit small. It’s strange to see </p>
<figure><table><tbody><tr><td>Structure</td><td>Applies to instructions that…</td><td>Oryon</td><td>Zen 4</td><td>Redwood Cove</td></tr><tr><td>Reorder Buffer (ROB)</td><td>Exist</td><td>680 entry</td><td>320 entry</td><td>512 entry</td></tr><tr><td>Integer register file</td><td>Write to a 64-bit scalar integer register</td><td>416 entry</td><td>224 entry</td><td>288 entry</td></tr><tr><td>FP/vector register file</td><td>Write to a FP/vector register</td><td>416 entry</td><td>192 entry</td><td>320 entry</td></tr><tr><td>Load queue</td><td>Read from memory</td><td>192 entry</td><td>136 entry</td><td>192 entry (measured)<br>240 entry (SPR slides)</td></tr><tr><td>Store queue</td><td>Write to memory</td><td>56 entry</td><td>64 entry</td><td>112 entry</td></tr></tbody></table></figure>
<p>Where Oryon really excels is scheduling capacity. Schedulers are expensive structures because every cycle, they have to check all their entries for micro-ops that are ready to execute. And, they have to see if results coming from freshly completed micro-ops make any pending micro-ops ready. Doing all those checks and comparisons can make schedulers area and power hungry. Qualcomm has likely kept costs down by associating each scheduling queue with one execution port, ensuring each scheduler only has to select one micro-op per cycle.</p>

<p>Oryon can bring an incredible 120 scheduler entries to bear for basic integer operations alone. It’s just short of Firestorm’s 134 entries, and far higher than Zen 4’s 96 entries. The gap between Oryon and Zen 4 is even wider because Zen 4’s ALU scheduling entries are shared with memory access operations. Intel’s Redwood Cove has 97 scheduling entries shared by integer and FP/vector operations.</p>
<p>On the FP/vector side, Oryon similarly has massive scheduling capacity. Arm CPUs traditionally featured weak vector execution, since handing throughput bound workloads would be difficult in a smartphone or tablet power budget. x86 applications however have different expectations, and users expect to carry out intensive tasks locally instead of sending them to be processed on a remote server. Oryon tackles this by feeding four 128-bit execution ports with a total of 192 scheduler entries. All four pipes can handle basic floating point and vector integer operations.</p>
<div>
<figure><a href="https://chipsandcheese.com/oryon_fp-drawio/"><img loading="lazy" decoding="async" width="488" height="622" data-attachment-id="29864" data-permalink="https://chipsandcheese.com/oryon_fp-drawio/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_fp.drawio.png?fit=488%2C622&amp;ssl=1" data-orig-size="488,622" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="oryon_fp.drawio" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_fp.drawio.png?fit=488%2C622&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_fp.drawio.png?fit=488%2C622&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_fp.drawio.png?resize=488%2C622&amp;ssl=1" alt="" data-recalc-dims="1"></a></figure></div>
<p>In that respect Oryon is very similar to Firestorm, though the two cores differ in how they handle less common operations. Firestorm also stands apart in using smaller (though still large in an absolute sense) schedulers, and compensating for that with a non-scheduling queue that can delay a stall at the rename stage.</p>
<p>AMD again has the lowest scheduling capacity, instead using a huge non-scheduling queue to prevent full schedulers from causing stalls further up the pipeline. Still, Zen 4’s buffering capacity for incomplete FP/vector operations falls far short of Oryon. However, AVX(2) and AVX-512 can still give Zen 4 an edge, because wide vector operations do more work with a single micro-op. Intel’s Redwood Cove similarly stands to benefit from wider vectors, though Meteor Lake’s hybrid core setup prevents it from supporting AVX-512. </p>
<p>Oryon’s FP/vector side feels like it’s about as strong as any NEON/ASIMD setup can reasonably be. Without SVE support, Oryon can’t use vectors wider than 128-bits. Supporting FMA ops on all four pipes gives it similar floating point throughput to Zen 4, but and potentially gives Oryon an advantage with code that doesn’t use vectors wider than 128 bits. But feeding that setup requires 12 FP register file ports, because each FMA needs three inputs. Pulling that off with a 416 entry register file sounds expensive.</p>
<div>
<figure><a href="https://chipsandcheese.com/oryon_agen/"><img loading="lazy" decoding="async" width="467" height="365" data-attachment-id="29977" data-permalink="https://chipsandcheese.com/oryon_agen/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_agen.png?fit=467%2C365&amp;ssl=1" data-orig-size="467,365" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="oryon_agen" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_agen.png?fit=467%2C365&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_agen.png?fit=467%2C365&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_agen.png?resize=467%2C365&amp;ssl=1" alt="" data-recalc-dims="1"></a><figcaption>Firestorm scheduler arrangement again from Dougall</figcaption></figure></div>
<p>Oryon has less scheduling capacity for address generation ops compared to math ones, but four 16 entry schedulers are nothing to sneeze at. Together, those schedulers can hold more micro-ops than Firestorm’s AGU scheduling and non-scheduling queues combined. Zen 4 can theoretically keep 72 incomplete address generation operations in flight, but those entries are shared with integer math operations.</p>
<h2>Address Translation</h2>
<p>On any modern CPU, programs operate on virtual addresses that get translated on-the-fly to physical addresses. Address translation caches, called Translation Lookaside Buffers (TLBs), help accelerate this by caching frequently used translations. Oryon features very large TLBs, helping reduce address translation latency.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=29792"><img loading="lazy" decoding="async" width="688" height="383" data-attachment-id="29792" data-permalink="https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/oryon_mmu/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_mmu.jpg?fit=2544%2C1418&amp;ssl=1" data-orig-size="2544,1418" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="oryon_mmu" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_mmu.jpg?fit=2544%2C1418&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_mmu.jpg?fit=688%2C383&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_mmu.jpg?resize=688%2C383&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_mmu.jpg?w=2544&amp;ssl=1 2544w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_mmu.jpg?resize=768%2C428&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_mmu.jpg?resize=1536%2C856&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_mmu.jpg?resize=2048%2C1142&amp;ssl=1 2048w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_mmu.jpg?resize=1200%2C669&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_mmu.jpg?resize=1600%2C892&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_mmu.jpg?resize=1320%2C736&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_mmu.jpg?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>Oryon’s first level data TLB has 224 entries and is 7 way set associative, providing 896 KB of coverage with 4K pages. That’s a lot of capacity compared to first level TLBs on AMD and Intel CPUs. It’s reminiscent of Kryo’s 192 entry L1 DTLB, which similarly provided fast address translation coverage over a relatively large address space. And, it’s refreshing to see next to AMD, Intel, and Arm’s small L1 DTLBs.</p>
<figure><table><tbody><tr><td>Level</td><td>Oryon</td><td>Zen 4</td><td>Apple Firestorm</td></tr><tr><td>L1 DTLB</td><td>224 entry 7-way</td><td>72 entry fully associative</td><td>160 entry</td></tr><tr><td>L2 TLB</td><td>8K+ entry 8-way<br>7 cycle latency</td><td>3072 entry 24-way<br>7-8 cycle latency</td><td>3072 entry</td></tr></tbody></table></figure>
<p>But unlike Kryo, which dropped L1 TLB misses on the floor, Oryon has a large second level TLB with over 8K entries. Getting a translation from the L2 TLB appears to take 7 extra cycles, which is good especially considering Oryon’s 4 GHz+ clocks and the size of the L2 TLB.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=29796"><img loading="lazy" decoding="async" width="688" height="310" data-attachment-id="29796" data-permalink="https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/oryon_latency_4k_2m/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_latency_4k_2m.png?fit=1281%2C578&amp;ssl=1" data-orig-size="1281,578" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="oryon_latency_4k_2m" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_latency_4k_2m.png?fit=1281%2C578&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_latency_4k_2m.png?fit=688%2C310&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_latency_4k_2m.png?resize=688%2C310&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_latency_4k_2m.png?w=1281&amp;ssl=1 1281w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_latency_4k_2m.png?resize=768%2C347&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_latency_4k_2m.png?resize=1200%2C541&amp;ssl=1 1200w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a><figcaption>With 2 MB pages, each TLB entry can cover 2 MB of address space, minimizing address translation overhead. 4K pages are usually used for typical applications</figcaption></figure></div>
<p>Measurements return confusing results though, showing an increase in address translation penalties past 6 MB. That would correspond to 1536 L2 TLB entries, which is far short of the 12 MB that Zen 4’s L2 TLB would cover. Testing sizes past 128 MB shows another increase, but that doesn’t correspond to 8K entries * 4K pages = 32 MB. </p>
<h2>Cache and Memory Access</h2>
<p>Oryon uses an Apple-like caching strategy. A large 96 KB L1 and relatively fast L2 with 20 cycles of latency together mean Oryon doesn’t need a mid-level cache. Firestorm has a bigger 128 KB L1, but Oryon’s L1 is still much larger than the 32 or 48 KB L1 caches in Zen 4 or Redwood Cove.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30085"><img loading="lazy" decoding="async" width="688" height="310" data-attachment-id="30085" data-permalink="https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/oryon_latency_cycles/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_latency_cycles.png?fit=1281%2C578&amp;ssl=1" data-orig-size="1281,578" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="oryon_latency_cycles" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_latency_cycles.png?fit=1281%2C578&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_latency_cycles.png?fit=688%2C310&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_latency_cycles.png?resize=688%2C310&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_latency_cycles.png?w=1281&amp;ssl=1 1281w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_latency_cycles.png?resize=768%2C347&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_latency_cycles.png?resize=1200%2C541&amp;ssl=1 1200w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>AMD has a 1 MB L2 mid-level cache private to each core, then a 16 MB L3. That setup makes it easier to increase caching capacity, because the L2 cache can insulate the core from L3 latency. However, that advantage is minimal for mobile Zen 4 parts, which max out at 16 MB of L3. Oryon therefore provides competitive latency especially as accesses spill out of Zen 4’s L2. Meteor Lake follows a similar caching strategy to Zen 4, but has more caching capacity at the expense of higher latency.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=29824"><img loading="lazy" decoding="async" width="688" height="386" data-attachment-id="29824" data-permalink="https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/oryon_mem_slide/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_mem_slide.jpg?fit=2545%2C1427&amp;ssl=1" data-orig-size="2545,1427" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="oryon_mem_slide" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_mem_slide.jpg?fit=2545%2C1427&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_mem_slide.jpg?fit=688%2C386&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_mem_slide.jpg?resize=688%2C386&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_mem_slide.jpg?w=2545&amp;ssl=1 2545w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_mem_slide.jpg?resize=768%2C431&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_mem_slide.jpg?resize=1536%2C861&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_mem_slide.jpg?resize=2048%2C1148&amp;ssl=1 2048w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_mem_slide.jpg?resize=1200%2C673&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_mem_slide.jpg?resize=1600%2C897&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_mem_slide.jpg?resize=1320%2C740&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_mem_slide.jpg?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>After L2, Oryon has a 6 MB System Level Cache (SLC) with a claimed latency of 26-29 ns. Test sizes between 12 and 18 MB generally align with that. For example, latency at 14 MB was approximately 25 ns using 2 MB pages. Accurately assessing SLC latency is difficult because many accesses within even a 18 MB array will result in L2 hits. The SLC’s low capacity compared to the L2 cache will likely limit its relevance for CPU-side code.</p>
<p>DRAM latency is 110.9 ns with a 1 GB array, which isn’t far off Qualcomm’s claimed 102-104 ns. The Ryzen 7840HS achieves somewhat lower latency at 103.3 ns, likely because it uses DDR5 memory instead of LPDDR5X. Meteor Lake’s memory latency is worse at over 140 ns.</p>
<h3>Bandwidth</h3>
<p>x86 CPUs traditionally had a strong focus on vector execution, and have plenty of cache bandwidth to support their vector units. Oryon competes surprisingly well in this area. There’s no SVE support, but Oryon takes 128-bit vector widths about as far as they’ll reasonably go with support for four 128-bit loads per cycle. That’s a match for Zen 4’s 2×256-bit load bandwidth, though a bit behind Redwood Cove’s 3×256-bit load capability. </p>
<p>Oryon’s large L1 cache capacity should let it hold up well for smaller data footprints, but AMD and Intel’s mid-level caches provide a bandwidth advantage if data spills out of L1. AMD’s L3 also does a good job, providing more bandwidth to a single core than Qualcomm’s L2. Apple’s Firestorm doesn’t emphasize vector workloads and is outpaced by other cores in this comparison.</p>
<div>
<figure><a href="https://chipsandcheese.com/oryon_st_bw-2/"><img loading="lazy" decoding="async" width="688" height="319" data-attachment-id="30013" data-permalink="https://chipsandcheese.com/oryon_st_bw-2/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_st_bw-1.png?fit=1892%2C878&amp;ssl=1" data-orig-size="1892,878" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="oryon_st_bw" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_st_bw-1.png?fit=1892%2C878&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_st_bw-1.png?fit=688%2C319&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_st_bw-1.png?resize=688%2C319&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_st_bw-1.png?w=1892&amp;ssl=1 1892w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_st_bw-1.png?resize=768%2C356&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_st_bw-1.png?resize=1536%2C713&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_st_bw-1.png?resize=1200%2C557&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_st_bw-1.png?resize=1600%2C742&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_st_bw-1.png?resize=1320%2C613&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_st_bw-1.png?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>When reading from DRAM, a single Oryon core can achieve an incredible 80 GB/s of bandwidth. Qualcomm says each core can have over 50 in-flight requests to the system, and a L2 instance can track over 220 memory transactions. Those large queues are likely why a single Oryon core can pull so much bandwidth from DRAM.</p>
<figure><img loading="lazy" decoding="async" width="688" height="387" data-attachment-id="29822" data-permalink="https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/oryon_l2_slide/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_l2_slide.jpg?fit=2549%2C1433&amp;ssl=1" data-orig-size="2549,1433" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="oryon_l2_slide" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_l2_slide.jpg?fit=2549%2C1433&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_l2_slide.jpg?fit=688%2C387&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_l2_slide.jpg?resize=688%2C387&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_l2_slide.jpg?w=2549&amp;ssl=1 2549w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_l2_slide.jpg?resize=1280%2C720&amp;ssl=1 1280w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_l2_slide.jpg?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_l2_slide.jpg?resize=1536%2C864&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_l2_slide.jpg?resize=2048%2C1151&amp;ssl=1 2048w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_l2_slide.jpg?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_l2_slide.jpg?resize=1600%2C899&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_l2_slide.jpg?resize=1320%2C742&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_l2_slide.jpg?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></figure>
<p>Shared caches get put under more pressure under multithreaded loads, as more cores ask for bandwidth. Oryon handles this well, with the L2 providing nearly 330 GB/s of bandwidth to four cores. That’s about 82 GB/s per core, and just a bit lower than the 100 GB/s an Oryon core can get without contention.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=29920"><img loading="lazy" decoding="async" width="688" height="294" data-attachment-id="29920" data-permalink="https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/oryon_4c_bw-1/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_4c_bw-1.png?fit=1808%2C772&amp;ssl=1" data-orig-size="1808,772" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="oryon_4c_bw-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_4c_bw-1.png?fit=1808%2C772&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_4c_bw-1.png?fit=688%2C294&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_4c_bw-1.png?resize=688%2C294&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_4c_bw-1.png?w=1808&amp;ssl=1 1808w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_4c_bw-1.png?resize=768%2C328&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_4c_bw-1.png?resize=1536%2C656&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_4c_bw-1.png?resize=1200%2C512&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_4c_bw-1.png?resize=1600%2C683&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_4c_bw-1.png?resize=1320%2C564&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_4c_bw-1.png?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>Again, AMD and Intel enjoy lots of bandwidth from their core-private L2 caches, and AMD’s L3 continues to shine for larger data footprints. Intel’s Redwood Cove P-Cores have very high cache bandwidth, but that advantage falls off once data spills out into L3.</p>
<p>For all-core workloads, Oryon trades blows with Phoenix depending on which level of the memory hierarchy we hit. L1 cache bandwidth is comparable, with AMD’s eight Zen 4 cores clocking higher to take a slight lead. AMD enjoys about 25% higher L2 bandwidth across all cores. Intel’s Meteor Lake generally has a bandwidth lead thanks to a combination of high core count and Redwood Cove’s 3×256-bit per cycle load capability. However, the lead is less significant when all threads are loaded because of clock speed drops and lower bandwidth E-Cores coming into play.</p>
<div>
<figure><a href="https://chipsandcheese.com/oryon_all_thread_bw-2/"><img loading="lazy" decoding="async" width="688" height="319" data-attachment-id="29867" data-permalink="https://chipsandcheese.com/oryon_all_thread_bw-2/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_all_thread_bw-1.png?fit=1895%2C880&amp;ssl=1" data-orig-size="1895,880" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="oryon_all_thread_bw" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_all_thread_bw-1.png?fit=1895%2C880&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_all_thread_bw-1.png?fit=688%2C319&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_all_thread_bw-1.png?resize=688%2C319&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_all_thread_bw-1.png?w=1895&amp;ssl=1 1895w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_all_thread_bw-1.png?resize=768%2C357&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_all_thread_bw-1.png?resize=1536%2C713&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_all_thread_bw-1.png?resize=1200%2C557&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_all_thread_bw-1.png?resize=1600%2C743&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_all_thread_bw-1.png?resize=1320%2C613&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/oryon_all_thread_bw-1.png?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>As test sizes exceed AMD’s L2 capacity, Qualcomm’s three L2 instances can provide 16% more bandwidth than AMD’s L3. Snapdragon X Elite has three 12 MB L2 instances for 36 MB of total capacity. Using three L3 instances makes it easier to provide high bandwidth too.</p>
<p>Finally, Qualcomm has much higher DRAM bandwidth thanks to fast LPDDR5X. With over 110 GB/s of measured read bandwidth, the Snapdragon X Elite is comfortably ahead of both Phoenix and Meteor Lake.</p>
<h2>Cinebench 2024</h2>
<p>Maxon’s Cinebench has been a benchmarking staple for years because it’s able to scale with core count. Modern CPUs have a lot of cores, but delivering high multithreaded performance in a limited power budget is very difficult. Cinebench 2024 has a native ARM64 build, so the Snapdragon X Elite will be free from binary translation penalties.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30069"><img loading="lazy" decoding="async" width="688" height="203" data-attachment-id="30069" data-permalink="https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/sdxe_cb2024_mt/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_cb2024_mt.png?fit=958%2C282&amp;ssl=1" data-orig-size="958,282" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sdxe_cb2024_mt" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_cb2024_mt.png?fit=958%2C282&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_cb2024_mt.png?fit=688%2C203&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_cb2024_mt.png?resize=688%2C203&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_cb2024_mt.png?w=958&amp;ssl=1 958w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_cb2024_mt.png?resize=768%2C226&amp;ssl=1 768w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p>Qualcomm does very well. SMT helps AMD by giving each Zen 4 core explicit parallelism to work with. However, that’s not enough to counter the Snapdragon X Elite’s higher core count. The Snapdragon X Elite has 12 cores to AMD’s eight, and comes away with a 8.4% performance lead while drawing just 2% more power. From another perspective though, each Zen 4 core punches above its weight. Qualcomm is bringing 50% more cores to the table, and bigger cores too. Snapdragon X Elite should be crushing the competition on paper, but thermal and power restrictions prevent it from pulling away.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30071"><img loading="lazy" decoding="async" width="688" height="387" data-attachment-id="30071" data-permalink="https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/sdxe_cb2024_mt_slide/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_cb2024_mt_slide.jpg?fit=2553%2C1435&amp;ssl=1" data-orig-size="2553,1435" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sdxe_cb2024_mt_slide" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_cb2024_mt_slide.jpg?fit=2553%2C1435&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_cb2024_mt_slide.jpg?fit=688%2C387&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_cb2024_mt_slide.jpg?resize=688%2C387&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_cb2024_mt_slide.jpg?w=2553&amp;ssl=1 2553w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_cb2024_mt_slide.jpg?resize=1280%2C720&amp;ssl=1 1280w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_cb2024_mt_slide.jpg?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_cb2024_mt_slide.jpg?resize=1536%2C863&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_cb2024_mt_slide.jpg?resize=2048%2C1151&amp;ssl=1 2048w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_cb2024_mt_slide.jpg?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_cb2024_mt_slide.jpg?resize=1600%2C899&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_cb2024_mt_slide.jpg?resize=1320%2C742&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_cb2024_mt_slide.jpg?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a><figcaption>Demo Config A has a 80W “Device TDP”, whatever that’s supposed to mean</figcaption></figure></div>
<p>Qualcomm’s slides suggest a higher power reference device can indeed achieve such results. Higher core counts need more power and better cooling to shine. We don’t know what clock speeds Qualcomm’s higher power reference device was able to sustain. In the Samsung Book Edge4, the Snapdragon X Elite averaged 2.71 GHz. In the HP ZBook Firefly G10 A, the Ryzen 7840HS averaged 3.75 GHz, explaining how AMD’s able to get so close with fewer cores.</p>
<p>Intel’s Meteor Lake has an even higher core count but fails to impress at similar platform power. It’s only slightly faster than Apple’s M2. In the Asus Zenbook 14 OLED, the Core Ultra 7 155H’s Redwood Cove P-Cores averaged 2.75 GHz. The Crestmont E-Cores averaged 2.33 GHz. One of the six P-Cores and the two LPE-Cores didn’t see significant load during the Cinebench 2024 run.</p>
<h2>Final Words</h2>
<p>Oryon combines design philosophies from both Firestorm and the company’s much older Kryo. The result is a very solid architecture, because Qualcomm took care to bring forward the best of those worlds. Qualcomm has wanted to move beyond smartphones and take a chunk of the laptop market for a long time, and Snapdragon X Elite is the strongest shot the company has taken yet. On paper, 12 big Oryon cores should be a formidable opponent for both AMD’s eight Zen 4 cores and Meteor Lake’s 16 cores of various types.</p>
<p>We’ll leave detailed benchmarking to mainstream tech sites, since they can do so in a more controlled environment and have the budget to provide more comparison points. But at a glance, Snapdragon X Elite provides competitive performance when running native applications. Even with binary translation, Oryon is fast enough to provide usable performance. With that in mind, Oryon has fulfilled two of the conditions that drove Apple Firestorm’s 2020 success.</p>
<div>
<figure><a href="https://chipsandcheese.com/?attachment_id=30073"><img loading="lazy" decoding="async" width="688" height="386" data-attachment-id="30073" data-permalink="https://chipsandcheese.com/2024/07/09/qualcomms-oryon-core-a-long-time-in-the-making/sdxe_oryon_graphic/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_oryon_graphic.jpg?fit=1280%2C718&amp;ssl=1" data-orig-size="1280,718" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sdxe_oryon_graphic" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_oryon_graphic.jpg?fit=1280%2C718&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_oryon_graphic.jpg?fit=688%2C386&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_oryon_graphic.jpg?resize=688%2C386&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_oryon_graphic.jpg?w=1280&amp;ssl=1 1280w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_oryon_graphic.jpg?resize=768%2C431&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_oryon_graphic.jpg?resize=1200%2C673&amp;ssl=1 1200w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a><figcaption>From Qualcomm’s 2023 Snapdragon Summit</figcaption></figure></div>
<p>But Snapdragon X Elite has a steeper hill to climb than Apple’s M1. Where Apple Silicon was the only upgrade option within the Apple ecosystem, PC customers have up-to-date AMD and Intel options to choose from. The PC ecosystem owes its popularity and staying power to a tradition of excellent software compatibility. Oryon relies on binary translation to execute x86 code, which comes with a performance penalty. Compatibility expectations extend to the operating system too. PC users expect to be able to (re)install an operating system of their choice. Generally a stock Linux or Windows image will boot on x86 CPUs going back several generations, regardless of device or motherboard manufacturer. Arm devices suffer from severe platform fragmentation, and Snapdragon X Elite is no exception. OS images have to be customized for each laptop, even ones that use the same Oryon cores.</p>
<div>
<figure><a href="https://chipsandcheese.com/sdxe_ref_devices_slide/"><img loading="lazy" decoding="async" width="688" height="386" data-attachment-id="30061" data-permalink="https://chipsandcheese.com/sdxe_ref_devices_slide/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_ref_devices_slide.jpg?fit=2548%2C1428&amp;ssl=1" data-orig-size="2548,1428" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sdxe_ref_devices_slide" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_ref_devices_slide.jpg?fit=2548%2C1428&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_ref_devices_slide.jpg?fit=688%2C386&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_ref_devices_slide.jpg?resize=688%2C386&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_ref_devices_slide.jpg?w=2548&amp;ssl=1 2548w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_ref_devices_slide.jpg?resize=768%2C430&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_ref_devices_slide.jpg?resize=1536%2C861&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_ref_devices_slide.jpg?resize=2048%2C1148&amp;ssl=1 2048w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_ref_devices_slide.jpg?resize=1200%2C673&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_ref_devices_slide.jpg?resize=1600%2C897&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_ref_devices_slide.jpg?resize=1320%2C740&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2024/07/sdxe_ref_devices_slide.jpg?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a><figcaption>Qualcomm slide from their 2023 Snapdragon Summit</figcaption></figure></div>
<p>Finally, Snapdragon X Elite devices are too expensive. Phoenix and Meteor Lake laptops often cost less, even when equipped with more RAM and larger SSDs. Convincing consumers to pay more for lower specifications is already a tough sell. Compatibility issues make it even tougher. Qualcomm needs to work with OEMs to deliver competitive prices. Lower prices will encourage skeptical consumers to try Snapdragon X Elite, getting more devices into circulation. That in turn leads to more developers with ARM64 Windows devices and more ARM64 native applications.</p>
<p>Qualcomm has their work cut out for them. We look forward to their next generation of CPU cores, and hope it’ll be strong enough to keep pace with AMD and Intel’s next generation products.</p>
<p>Again, we would like to thank our <a href="https://www.patreon.com/ChipsandCheese">Patreon members</a> and <a href="https://www.paypal.com/donate?hosted_button_id=4EMPH66SBGVSQ">Paypal donators</a> for donating and if you like our articles and journalism then consider heading over to our&nbsp;<a href="https://www.patreon.com/ChipsandCheese">Patreon</a>&nbsp;or our&nbsp;<a href="https://www.paypal.com/donate/?hosted_button_id=4EMPH66SBGVSQ">PayPal</a>&nbsp;if you want to toss a few bucks our way. If you would like to talk with the Chips and Cheese staff and the people behind the scenes, then consider joining our&nbsp;<a href="https://discord.gg/TwVnRhxgY2">Discord</a>.</p>

<div data-post_id="10949" data-instance_id="1" data-additional_class="pp-multiple-authors-layout-boxed.multiple-authors-target-the-content" data-original_class="pp-multiple-authors-boxes-wrapper pp-multiple-authors-wrapper box-post-id-10949 box-instance-id-1">
<p><span>
<ul>
<li>
<div>
<p><img alt="Cheese" src="https://secure.gravatar.com/avatar/eb262496276a5c8c0a375be578f81db9?s=80&amp;d=identicon&amp;r=g" srcset="https://secure.gravatar.com/avatar/eb262496276a5c8c0a375be578f81db9?s=160&amp;d=identicon&amp;r=g 2x" height="80" width="80"> </p>
</div>

</li>
<li>
<div>
<p><img alt="clamchowder" src="https://secure.gravatar.com/avatar/7c39d2e6d35e77c8fd15c4b2d9ce4e64?s=80&amp;d=identicon&amp;r=g" srcset="https://secure.gravatar.com/avatar/7c39d2e6d35e77c8fd15c4b2d9ce4e64?s=160&amp;d=identicon&amp;r=g 2x" height="80" width="80"> </p>
</div>

</li>
</ul>
</span>
</p></div>





</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Typeset of Wall·E (2018) (443 pts)]]></title>
            <link>https://typesetinthefuture.com/2018/12/04/walle/</link>
            <guid>40934924</guid>
            <pubDate>Thu, 11 Jul 2024 09:28:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://typesetinthefuture.com/2018/12/04/walle/">https://typesetinthefuture.com/2018/12/04/walle/</a>, See on <a href="https://news.ycombinator.com/item?id=40934924">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<p>From a trash-filled Earth to the futuristic <i>Axiom</i> and back again, <i>WALL·E</i> is a finely crafted balance between consumerist dystopia and sixties space-race optimism. Please join me, then, for a detailed dive&nbsp;into the uniquely robotic future of a remarkably human film, as seen through the eyes of its eponymous hero, WALL·E.</p>

<p><em>[This article is from the&nbsp;</em><a href="https://typesetinthefuture.com/book/">Typeset in the Future book</a><i>, which is really very good&nbsp;and you’re&nbsp;probably going to want to&nbsp;</i><a href="https://www.amazon.com/gp/product/1419727141/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=titf0f-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1419727141&amp;linkId=b321076a05a18b3ffdfd5fd8924ad645">buy a copy of</a><i>. If you’d rather read the article first, don’t worry—I’ll remind you again later on.]</i></p>
<p>Before we get started, there is an important detail we must clear up. Our hero’s name is not, as you might think, WALL-E. Moreover, it <i>definitely</i> isn’t WALL•E. His name is <em>WALL·E</em>, and that dot is an <a href="https://en.wikipedia.org/wiki/Interpunct">interpunct</a>, not a hyphen or a bullet.</p>
<figure data-shortcode="caption" id="attachment_1492" aria-describedby="caption-attachment-1492"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_02_37_2_full.jpg"><img src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_02_37_2.jpg?w=1000" alt="walle_0_02_37_2" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_02_37_2.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_02_37_2.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_02_37_2.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1492">WALL·E’s front plate, clearly showing his interpunct.</figcaption></figure>
<p>An interpunct is, of course, a vertically centered dot originally used to separate words in Latin and ancient Greek. (Spaces weren’t invented until several centuries later.) The interpunct is still in use today—it’s the official decimal point in British currency (£9·99), and is used to represent the dot product of two vectors in mathematics (x · y). Most relevantly, it’s used in Japanese to separate titles, names, and positions, as in “課長補佐 · 鈴木” (Assistant Section Head · Suzuki). It is therefore entirely appropriate as the separator in WALL·E, which is short for Waste Allocation Load Lifter · Earth Class.</p>
<p>The bold extended typeface seen on WALL·E’s front plate is Gunship, designed by Dan Zadorozny, one of the unsung heroes of modern sci-fi type design. Dan is an amateur type designer from Texas whose <a href="http://iconian.com/">Iconian Fonts website</a> features more than six hundred free hand-crafted typefaces, many of which have been used by sci-fi movies, TV shows, and book designers.</p>
<p>In addition to WALL·E’s front plate, Gunship is seen on Earth and aboard the <i>Axiom</i>, the flagship spacecraft of megacorporation Buy n Large (BnL, for short), most notably for robot-facing wall and door typography. Its upper- and lowercase variants include different combinations of cutouts and curve orientations, giving designers flexibility when crafting robot signage. (Strictly speaking, this means that our hero’s name, correctly capitalized, is “waLL·e,” with the interpunct as a further customization—Gunship’s own interpunct is rectangular.)</p>
<figure data-shortcode="caption" id="attachment_1494" aria-describedby="caption-attachment-1494"><img src="https://typesetinthefuture.com/wp-content/uploads/2018/08/sampler_gunship_lowercase.png?w=1000" alt="sampler_gunship_lowercase" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/sampler_gunship_lowercase.png 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/sampler_gunship_lowercase.png?w=150&amp;h=15 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/sampler_gunship_lowercase.png?w=300&amp;h=30 300w" sizes="(max-width: 560px) 100vw, 560px"><figcaption id="caption-attachment-1494">Gunship (lowercase characters).</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1495" aria-describedby="caption-attachment-1495"><img src="https://typesetinthefuture.com/wp-content/uploads/2018/08/sampler_gunship_uppercase.png?w=1000" alt="sampler_gunship_uppercase" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/sampler_gunship_uppercase.png 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/sampler_gunship_uppercase.png?w=150&amp;h=15 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/sampler_gunship_uppercase.png?w=300&amp;h=30 300w" sizes="(max-width: 560px) 100vw, 560px"><figcaption id="caption-attachment-1495">Gunship (uppercase characters).</figcaption></figure>
<p>The movie begins with an insight into WALL·E’s typical workday, which is spent building gigantic piles of trash by compacting waste into neat, stackable cubes. After a hard day’s crushing, we follow him on his journey home, learning some useful exposition along the way. This includes a bank of electronic ads for BnL, promoting everything from liquid air to quadruple-patty burgers. Common throughout these ads is an insistence on immediate consumption—“DRINK NOW,” “HUNGRY NOW,” “RUN NOW,” “CONSUME.” And if consuming a product once isn’t enough, you can repeat the experience a second time—the signage seen below includes ads for both “100% Reused Food” and “Regurgi-Shake: Twice the Flavor.”</p>
<p><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_04_02_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_04_02.jpg?w=1000" alt="walle_0_04_02" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_04_02.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_04_02.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_04_02.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a></p>
<p>We’ve seen how corporate mergers, such as <a href="https://typesetinthefuture.com/2014/12/01/alien/"><i>Alien</i>’s Weylan Yutani</a> and <a href="https://typesetinthefuture.com/2016/06/19/bladerunner/"><i>Blade Runner</i>’s Shimata-Dominguez</a>, are an inevitability in sci-fi futures. <i>WALL·E</i>’s Buy n Large is similar, except that this company was formed by a merger between a frozen yogurt manufacturer (Buy Yogurt) and a maker of suits for the larger gentleman (Large Industries). Clearly a marriage made in heaven, this corporate combination led to a rapid expansion, culminating with Buy n Large owning every company and government in the world.</p>
<p>The Buy n Large logo is an over-italicized customization of Futura Extra Bold Oblique, as demonstrated by a super-distinctive capital G in the BUY N LARGE BANK logotype that WALL·E passes early in the movie.</p>
<figure data-shortcode="caption" id="attachment_1500" aria-describedby="caption-attachment-1500"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/sampler_futura_extra_bold_oblique.png?w=1000" alt="sampler_futura_extra_bold_oblique" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/sampler_futura_extra_bold_oblique.png 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/sampler_futura_extra_bold_oblique.png?w=150&amp;h=15 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/sampler_futura_extra_bold_oblique.png?w=300&amp;h=30 300w" sizes="(max-width: 560px) 100vw, 560px"><figcaption id="caption-attachment-1500">Futura Pro Extra Bold Oblique, released by Berthold. Original Futura design by Paul Renner.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1498" aria-describedby="caption-attachment-1498"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_03_54_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_03_54.jpg?w=1000" alt="walle_0_03_54" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_03_54.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_03_54.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_03_54.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1498">“BUY N LARGE BANK” signage, set in Futura Extra Bold Oblique, showing its distinctive capital G.</figcaption></figure>
<p>If the red-and-blue logo feels familiar, it shouldn’t be a surprise—it’s because BnL uses the exact same typeface and color scheme as real-world retail giant <a href="https://en.wikipedia.org/wiki/Costco">Costco Wholesale Corporation</a>.</p>
<figure data-shortcode="caption" id="attachment_1499" aria-describedby="caption-attachment-1499"><a href="https://en.m.wikipedia.org/wiki/File:Costco_Wholesale_logo_2010-10-26.svg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_costco_wholesale_logo.png?w=1000" alt="walle_costco_wholesale_logo" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_costco_wholesale_logo.png 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_costco_wholesale_logo.png?w=150&amp;h=45 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_costco_wholesale_logo.png?w=300&amp;h=90 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1499">The Costco Wholesale Corporation logo, in Futura Extra Bold Oblique.</figcaption></figure>
<p>There’s another curious BnL subsidiary to be found among the city’s electronic ads, on a beaten-up billboard advertising “Eggman Movers (Creating More Space).” This company is an Easter-egg reference to WALL·E production designer <a href="https://en.wikipedia.org/wiki/Ralph_Eggleston">Ralph “Eggman” Eggleston</a>, and it shares the name of the moving company from 1995’s <em><a href="https://en.wikipedia.org/wiki/Toy_Story">Toy Story</a></em>, for which Ralph was art director.</p>
<figure data-shortcode="caption" id="attachment_1503" aria-describedby="caption-attachment-1503"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_03_59_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_03_591.jpg?w=1000" alt="walle_0_03_59" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_03_591.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_03_591.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_03_591.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1503">Eggman Movers, from 2008’s <em>WALL·E</em>.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1502" aria-describedby="caption-attachment-1502"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_1_08_32_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_1_08_32.jpg?w=1000" alt="toy_story_1_08_32" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_1_08_32.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_1_08_32.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_1_08_32.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1502">Eggman Movers, from 1995’s <em>Toy Story</em>.</figcaption></figure>
<p>The presence of a Buy n Large–branded bank means Buy n Large–branded banknotes, which are unusual for being strewn across the floor of the deserted city. If you look closely at the notes, you’ll see that some of them have “10<sup>6</sup>” in the corner, and are marked “ten million dollars.” Others look to be marked “99<sup>6</sup>,” suggesting that Buy n Large stores continued the classic $9.99 pricing trick even after adding six zeroes to the end of everything. (Indeed, it says much about the Buy n Large approach to consumerism that it prints notes with the 99s already included, to avoid customers having to receive any change.)</p>
<figure data-shortcode="caption" id="attachment_1504" aria-describedby="caption-attachment-1504"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_03_52_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_03_52.jpg?w=1000" alt="walle_0_03_52" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_03_52.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_03_52.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_03_52.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1504">$10 million and $99 million bills lie abandoned on the ground near a Buy n Large Bank.</figcaption></figure>
<p>We discover later in the movie that the <em>Axiom</em> left Earth in the year 2105. This suggests that in the preceding years of overconsumption there was a period of severe hyperinflation, making a $10 million note a necessity. This is not without historical precedent—<a href="https://en.wikipedia.org/wiki/Hyperinflation_in_Zimbabwe">Earth’s most extreme example of hyperinflation</a> occurred in Zimbabwe in November 2008, just a few months after <em>WALL·E</em>’s release, when the inflation rate for the Zimbabwe dollar reached a staggering 79,600,000,000 percent per month. At this point, a single US dollar was equivalent to 2,621,984,228 Zimbabwe dollars.&nbsp;The largest-denomination note printed during this time was the $100 trillion note, which makes Buy n Large’s $10 million bill seem like small change by comparison.</p>
<figure data-shortcode="caption" id="attachment_1505" aria-describedby="caption-attachment-1505"><a href="https://commons.wikimedia.org/wiki/File:Zimbabwe_$100_trillion_2009_Obverse.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_one_hundred_trilion_dollars.jpg?w=1000" alt="walle_one_hundred_trilion_dollars" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_one_hundred_trilion_dollars.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_one_hundred_trilion_dollars.jpg?w=150&amp;h=74 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_one_hundred_trilion_dollars.jpg?w=300&amp;h=149 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1505">A $100 trillion bill from the Reserve Bank of Zimbabwe, showing some impressively pointy Futura.</figcaption></figure>
<p>WALL·E leaves the bank behind and continues his journey via the disused tracks of the BnL Transit monorail system. In the absence of working trains, these concrete tracks provide a convenient route through the middle of the deserted city.</p>
<figure data-shortcode="caption" id="attachment_1506" aria-describedby="caption-attachment-1506"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_04_12_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_04_12.jpg?w=1000" alt="walle_0_04_12" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_04_12.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_04_12.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_04_12.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1506">WALL·E climbs an escalator&nbsp;to a BnL Transit monorail station.</figcaption></figure>
<p>Despite their association with aspirational futures, monorails have been failing to become a global mass-transit system for almost two hundred years. <a href="https://en.wikipedia.org/wiki/History_of_monorail">The first passenger monorail</a> opened in 1825 in Cheshunt, England, primarily to transport bricks, though it was also utilized for transporting people, mostly for novelty purposes. Unlike the top-of-rail system seen in <em>WALL·E</em>, Cheshunt’s monorail consisted of carriages suspended beneath an overhead track, and was powered by a single horse.</p>
<p>The Cheshunt style of monorail—with suspended carriages hanging beneath a single rail—was also adopted by the <a href="https://en.wikipedia.org/wiki/Wuppertal_Suspension_Railway">Wuppertal Schwebebahn</a>, which began operation along the Wupper River in Wuppertal, Germany, in 1901. The Wuppertal’s suspended system is still in operation today, carrying more than sixty-five thousand passengers on an average weekday.</p>
<figure data-shortcode="caption" id="attachment_1507" aria-describedby="caption-attachment-1507"><a href="https://commons.wikimedia.org/wiki/File:Wuppertaler_Schwebebahn_c1913_LOC_03961u.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_wuppertal_monorail.jpg?w=1000" alt="walle_wuppertal_monorail" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_wuppertal_monorail.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_wuppertal_monorail.jpg?w=150&amp;h=111 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_wuppertal_monorail.jpg?w=300&amp;h=223 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1507">A Wuppertal Schwebebahn monorail train arrives at the Werther Brücke station in Wuppertal, 1913.</figcaption></figure>
<p>The monorail seen in <em>WALL·E</em> is of the style popularized by Swedish entrepreneur <a href="https://en.wikipedia.org/wiki/Axel_Wenner-Gren">Axel Wenner-Gren</a>, whose prototype ALWEG (<strong>A</strong>xel <strong>L</strong>ennart <strong>We</strong>nner-<strong>G</strong>ren) monorail system came to the attention of Walt Disney after a family visit to Wuppertal gave him monorail fever. Disney saw the potential for a monorail attraction at his new Disneyland theme park in California, and the Disneyland-ALWEG Monorail System opened in June 1959. The system remains in operation today (under the name Disneyland Monorail), and there are similar attractions at Disneyland Tokyo and Walt Disney World in Florida. In total, Disney monorails have transported more than one billion passengers into an aspirational transportational future.</p>
<figure data-shortcode="caption" id="attachment_1508" aria-describedby="caption-attachment-1508"><a href="https://en.wikipedia.org/wiki/File:6308-DisneyLandMonoRail-ParkStation.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_disneyland_alweg_monorail_tomorrowland_1963.jpg?w=1000" alt="walle_disneyland_alweg_monorail_tomorrowland_1963" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_disneyland_alweg_monorail_tomorrowland_1963.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_disneyland_alweg_monorail_tomorrowland_1963.jpg?w=150&amp;h=94 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_disneyland_alweg_monorail_tomorrowland_1963.jpg?w=300&amp;h=188 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1508">The Disneyland-ALWEG Monorail System at Tomorrowland station, 1963.&nbsp;<a href="https://en.wikipedia.org/wiki/File:6308-DisneyLandMonoRail-ParkStation.jpg">Photograph by Robert J. Boser, CC BY 3.0</a>.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1509" aria-describedby="caption-attachment-1509"><a href="https://en.wikipedia.org/wiki/File:6308-DisneyLandHotelMonorailStation.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_disneyland_alweg_monorail_disneyland_hotel_1963.jpg?w=1000" alt="walle_disneyland_alweg_monorail_disneyland_hotel_1963" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_disneyland_alweg_monorail_disneyland_hotel_1963.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_disneyland_alweg_monorail_disneyland_hotel_1963.jpg?w=150&amp;h=98 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_disneyland_alweg_monorail_disneyland_hotel_1963.jpg?w=300&amp;h=197 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1509">The Disneyland-ALWEG Monorail System at Disneyland Hotel station, 1963.&nbsp;<a href="https://en.wikipedia.org/wiki/File:6308-DisneyLandHotelMonorailStation.jpg">Photograph by Robert J. Boser, CC BY 3.0</a>.</figcaption></figure>
<p>It’s not entirely clear what US city WALL·E lives in, but the presence of a monorail network certainly positions it as a location that was once optimistic about the future. This mid-century futurism is borne out by other architectural features of the city, most notably a curved building seen among the billboards encountered earlier. This building is strongly reminiscent of the <a href="https://en.wikipedia.org/wiki/Space_Needle">Space Needle observation tower</a> in Seattle, Washington, which was built for the city’s <a href="https://en.wikipedia.org/wiki/Century_21_Exposition">1962 World’s Fair</a>, together with an <a href="https://en.wikipedia.org/wiki/Seattle_Center_Monorail">ALWEG monorail system</a> that is still in operation today.</p>
<figure data-shortcode="caption" id="attachment_1510" aria-describedby="caption-attachment-1510"><a href="https://flic.kr/p/6Ns9ie"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_seattle_monorail_and_space_needle.jpg?w=1000" alt="walle_seattle_monorail_and_space_needle" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_seattle_monorail_and_space_needle.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_seattle_monorail_and_space_needle.jpg?w=116&amp;h=150 116w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_seattle_monorail_and_space_needle.jpg?w=231&amp;h=300 231w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1510">Seattle’s ALWEG monorail passing in front of the city’s Space Needle, 2008. Both were built for Seattle’s 1962 World’s Fair.&nbsp;<a href="https://flic.kr/p/6Ns9ie">Photograph by Smart Destinations, CC BY-SA 2.0</a>.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1511" aria-describedby="caption-attachment-1511"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_04_02_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_04_02_space_needle.jpg?w=1000" alt="walle_0_04_02_space_needle" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_04_02_space_needle.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_04_02_space_needle.jpg?w=116&amp;h=150 116w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_04_02_space_needle.jpg?w=231&amp;h=300 231w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1511">A remarkably space-needle-like building seen close to the monorail in WALL·E’s home city.</figcaption></figure>
<p>Near the monorail, WALL·E passes a promotional poster for himself, with the caption “Working to dig you out!” This poster has definite communist propaganda undertones, showing a stylized army of WALL·Es working together to build a brighter future. The implication of this design choice—that communist values are the solution to decades of rampant consumerism—is a pretty bold political statement for what is only the fourth minute of the movie.</p>
<figure data-shortcode="caption" id="attachment_1516" aria-describedby="caption-attachment-1516"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_04_10_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_04_101.jpg?w=1000" alt="walle_0_04_10" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_04_101.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_04_101.jpg?w=150&amp;h=93 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_04_101.jpg?w=300&amp;h=185 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1516">Buy n Large poster for WALL·E robots, with the caption “Working to dig you out!”</figcaption></figure>
<p>The future to which these WALL·Es aspire is apparently just above and behind the viewer—a common trope for communist propaganda, where the aspirational group gaze is almost always in this direction.</p>
<figure data-shortcode="caption" id="attachment_1513" aria-describedby="caption-attachment-1513"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_communist_propaganda_chinese_marching.jpg?w=1000" alt="walle_communist_propaganda_chinese_marching" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_communist_propaganda_chinese_marching.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_communist_propaganda_chinese_marching.jpg?w=150&amp;h=106 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_communist_propaganda_chinese_marching.jpg?w=300&amp;h=212 300w" sizes="(max-width: 560px) 100vw, 560px"><figcaption id="caption-attachment-1513">Chinese communist propaganda poster with the caption “To go on a thousand ‘li’ march to temper a red heart.” A “li” is about 500 meters, so a thousand-li march is about 310 miles.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1514" aria-describedby="caption-attachment-1514"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_communist_propaganda_russian_family.jpg?w=1000" alt="walle_communist_propaganda_russian_family" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_communist_propaganda_russian_family.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_communist_propaganda_russian_family.jpg?w=150&amp;h=108 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_communist_propaganda_russian_family.jpg?w=300&amp;h=216 300w" sizes="(max-width: 560px) 100vw, 560px"><figcaption id="caption-attachment-1514">Soviet communist propaganda poster, with the caption “Let’s raise a generation utterly devoted to the cause of communism!” Designed by Victor Ivanov, 1947.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1515" aria-describedby="caption-attachment-1515"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_communist_propaganda_north_korean_soldier.jpg?w=1000" alt="walle_communist_propaganda_north_korean_soldier" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_communist_propaganda_north_korean_soldier.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_communist_propaganda_north_korean_soldier.jpg?w=150&amp;h=114 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_communist_propaganda_north_korean_soldier.jpg?w=300&amp;h=228 300w" sizes="(max-width: 560px) 100vw, 560px"><figcaption id="caption-attachment-1515">North Korean propaganda poster, with the caption “The party calls! To important construction!”</figcaption></figure>
<p>Indeed, this gaze is&nbsp;<em>such</em> a common trope that it became the primary styling of the promotional poster for 2014’s banned comedy movie <a href="https://en.wikipedia.org/wiki/The_Interview"><em>The Interview</em></a>, in which two Americans travel to North Korea to interview the country’s leader, <a href="https://en.wikipedia.org/wiki/Kim_Jong-un">Kim Jong-un</a>. (The <em>WALL·E</em> poster’s bottom-edge caption, punctuated by an exclamation mark, is a recurring design feature in North Korean propaganda posters.)</p>
<figure data-shortcode="caption" id="attachment_1517" aria-describedby="caption-attachment-1517"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/the_interview_poster.jpg?w=1000" alt="the_interview_poster" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/the_interview_poster.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/the_interview_poster.jpg?w=101&amp;h=150 101w, https://typesetinthefuture.com/wp-content/uploads/2018/08/the_interview_poster.jpg?w=202&amp;h=300 202w" sizes="(max-width: 560px) 100vw, 560px"><figcaption id="caption-attachment-1517">Promotional poster for <em>The Interview</em>, with the Korean-language caption “Don’t believe these American bastards!”</figcaption></figure>
<p>This aspirational style is an example of <a href="https://en.wikipedia.org/wiki/Socialist_realism">socialist realist design</a>, the officially sanctioned visual aesthetic of the Soviet Union, which positioned broad-shouldered, purposeful workers as the true heroes of the age. As a robot who is literally a rectangle, there is surely no worker more broad-shouldered and purposeful than our movie’s eponymous hero, WALL·E.</p>
<p>WALL·E’s self-promotional poster is also a fine example of <a href="https://en.wikipedia.org/wiki/Handel_Gothic">Handel Gothic</a>, one of the movie’s supporting typefaces. Originally designed in 1965 by Donald J. Handel, the font has become a mainstay of design futurism. (Indeed, it is quite possibly the originator of one of our <a href="https://typesetinthefuture.com/2016/02/18/futuristic/">rules for futuristic type</a>: Make straight things curved.)</p>
<figure data-shortcode="caption" id="attachment_1518" aria-describedby="caption-attachment-1518"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/sampler_handel_gothic_bold.png?w=1000" alt="sampler_handel_gothic_bold" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/sampler_handel_gothic_bold.png 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/sampler_handel_gothic_bold.png?w=150&amp;h=15 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/sampler_handel_gothic_bold.png?w=300&amp;h=30 300w" sizes="(max-width: 560px) 100vw, 560px"><figcaption id="caption-attachment-1518">Handel Gothic Com Bold, from Linotype. Handel Gothic was originally designed in 1965 by Donald J. Handel for FotoStar.</figcaption></figure>
<p>My favorite use of the typeface in <em>WALL·E</em> occurs later in the movie, when we see the distinctly curved E of some Handel Gothic… on a handle. (I refuse to believe this is anything but a deliberate typographic joke.)</p>
<figure data-shortcode="caption" id="attachment_1520" aria-describedby="caption-attachment-1520"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_58_30_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_58_301.jpg?w=1000" alt="walle_0_58_30" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_58_301.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_58_301.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_58_301.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1520">“Handle” Gothic.</figcaption></figure>
<p>Handel Gothic enjoyed a particular resurgence when the type family was expanded in the 1980s, and will be immediately familiar to anyone who visited <a href="https://en.wikipedia.org/wiki/Epcot">EPCOT Center</a> at <a href="https://en.wikipedia.org/wiki/Walt_Disney_World">Walt Disney World</a> in Florida, which opened in 1982. (Later in this article, we’ll look in detail at the theme park, which is now named simply Epcot.) The original EPCOT Center logo was Handel Gothic all the way, making particularly good use of a lowercase n in “Center” to bring some extra curviness, and choosing a font variant with a curved leg in its R for consistency. (It also added <a href="https://typesetinthefuture.com/2016/02/18/futuristic/">letter joining and slicing</a> for good futuristic measure.)</p>
<figure data-shortcode="caption" id="attachment_1521" aria-describedby="caption-attachment-1521"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_epcot_center_logo.png?w=1000" alt="walle_epcot_center_logo" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_epcot_center_logo.png 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_epcot_center_logo.png?w=150&amp;h=63 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_epcot_center_logo.png?w=300&amp;h=127 300w" sizes="(max-width: 560px) 100vw, 560px"><figcaption id="caption-attachment-1521">Original logo for the EPCOT Center theme park at Walt Disney World, Florida.</figcaption></figure>
<p>Handel Gothic will also be familiar to <em>Star Trek</em> fans, from its appearance in the credits for both <a href="https://en.wikipedia.org/wiki/Star_Trek:_Deep_Space_Nine"><em>Star Trek: Deep Space Nine</em></a> (1993–99) and <a href="https://en.wikipedia.org/wiki/Star_Trek:_Voyager"><em>Star Trek: Voyager</em></a> (1995–2001).</p>
<figure data-shortcode="caption" id="attachment_1522" aria-describedby="caption-attachment-1522"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/startrek_ds9_emissary_0_06_44_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/startrek_ds9_emissary_0_06_44.jpg?w=1000" alt="startrek_ds9_emissary_0_06_44" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/startrek_ds9_emissary_0_06_44.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/startrek_ds9_emissary_0_06_44.jpg?w=150&amp;h=113 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/startrek_ds9_emissary_0_06_44.jpg?w=300&amp;h=225 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1522">Opening credits from the <em>Star Trek: Deep Space Nine</em> episode “Emissary,” showing some shiny metallic Handel Gothic (in this case, with a straight-legged R).</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1523" aria-describedby="caption-attachment-1523"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/startrek_voyager_unimatrix_0_04_22_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/startrek_voyager_unimatrix_0_04_22.jpg?w=1000" alt="startrek_voyager_unimatrix_0_04_22" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/startrek_voyager_unimatrix_0_04_22.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/startrek_voyager_unimatrix_0_04_22.jpg?w=150&amp;h=113 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/startrek_voyager_unimatrix_0_04_22.jpg?w=300&amp;h=225 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1523">Opening credits from the <em>Star Trek: Voyager</em> episode “Unimatrix Zero: Part II,” showing Handel Gothic with a similarly straight-legged R.</figcaption></figure>
<p>The movie that made Handel Gothic synonymous with sci-fi, however, was almost certainly <a href="https://en.wikipedia.org/wiki/Steven_Spielberg">Steven Spielberg</a>’s <a href="https://en.wikipedia.org/wiki/Close_Encounters_of_the_Third_Kind"><em>Close Encounters of the Third Kind</em></a>, released in 1977. <em>Close Encounters</em> used the typeface for its theatrical poster and for its opening credits, with the very words “Close Encounters” offering not one but three opportunities to recognize Handel Gothic’s trademark E.</p>
<figure data-shortcode="caption" id="attachment_1524" aria-describedby="caption-attachment-1524"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/close_encounters_0_00_34_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/close_encounters_0_00_34.jpg?w=1000" alt="close_encounters_0_00_34" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/close_encounters_0_00_34.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/close_encounters_0_00_34.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/close_encounters_0_00_34.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1524">Opening credits to 1977’s <em>Close Encounters of the Third Kind</em>.</figcaption></figure>
<p>But back to WALL·E’s journey. Toward the end of his trek home, he passes many more WALL·E units, all of them rusted and dead. The sole remaining WALL·E happily cannibalizes a Caterpillar track from a nearby broken unit to replace his own damaged part, and motors onward with the new track in place.</p>
<p>It’s an easy detail to miss, but WALL·E’s home is a broken-down “BnL WALL·E Transport” vehicle, which may once have housed all the dead units he just passed. When he reverses himself into a WALL·E-size bin in a rotatable storage rack a few minutes later and rocks himself to sleep, his loneliness as the last robot on Earth is made all the more acute by the uninhabited bins around him, now filled with ordered trash.</p>
<figure data-shortcode="caption" id="attachment_1525" aria-describedby="caption-attachment-1525"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_04_24_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_04_24.jpg?w=1000" alt="walle_0_04_24" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_04_24.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_04_24.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_04_24.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1525">Defunct WALL·E units litter the landscape, becoming part of the trash they once existed to clear.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1526" aria-describedby="caption-attachment-1526"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_06_04_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_06_04.jpg?w=1000" alt="walle_0_06_04" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_06_04.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_06_04.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_06_04.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1526">A hulking WALL·E TRANSPORT, ironically rendered immobile by the piles of trash surrounding it.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1527" aria-describedby="caption-attachment-1527"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_08_59_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_08_59.jpg?w=1000" alt="walle_0_08_59" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_08_59.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_08_59.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_08_59.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1527">WALL·E tucks himself into a transportation bin, as the last remaining unit still able to do so. Where there once would have been many more WALL·E’s, there is now simply ordered trash.</figcaption></figure>
<p>Before he climbs into bed, WALL·E retrieves his favorite VHS cassette from a nearby toaster, and pops it into a VCR. It turns out this is a beaten-up copy of <a href="https://en.wikipedia.org/wiki/Hello,_Dolly!_(film)"><em>Hello, Dolly!</em></a>—1969’s awkwardly punctuated <a href="https://en.wikipedia.org/wiki/Jerry_Herman">Jerry Herman</a> musical. Delightfully, the typography of this cassette is taken directly from the movie’s 1991 VHS release, though the identity of its non-futuristic title font—half <a href="https://en.wikipedia.org/wiki/Century_type_family#Century_Schoolbook">Century Schoolbook</a>, half <a href="https://fontsinuse.com/typefaces/7590/benguiat-caslon">Benguiat Caslon</a>—has sadly eluded my detective skills.</p>
<figure data-shortcode="caption" id="attachment_1528" aria-describedby="caption-attachment-1528"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_27_18_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_27_18.jpg?w=1000" alt="walle_1_27_18" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_27_18.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_27_18.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_27_18.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1528">WALL-E’s much-watched copy of <em>Hello, Dolly!</em></figcaption></figure>
<figure data-shortcode="caption" id="attachment_1529" aria-describedby="caption-attachment-1529"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_hello_dolly_front_cover_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_hello_dolly_front_cover.jpg?w=1000" alt="walle_hello_dolly_front_cover" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_hello_dolly_front_cover.jpg 400w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_hello_dolly_front_cover.jpg?w=83&amp;h=150 83w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_hello_dolly_front_cover.jpg?w=165&amp;h=300 165w" sizes="(max-width: 400px) 100vw, 400px"></a><figcaption id="caption-attachment-1529">The front cover of 1991’s US VHS release of <em>Hello, Dolly!</em></figcaption></figure>
<p>WALL·E watches his <em>Hello, Dolly!</em> cassette via a small, portable device that looks almost exactly like an <a href="https://en.wikipedia.org/wiki/IPod_Classic#5th_generation">Apple iPod Video</a>. I say “almost,” because the real-world iPod Video had a smaller click wheel than the one seen in <em>WALL·E</em>, had white labels on its buttons, and did not support external playback from a VHS cassette player. Nonetheless, this iPod is just one example of many in WALL·E’s home that evoke nostalgia for gadgets past, reinforcing that WALL·E himself is the discarded, unwanted technology that humanity left behind.</p>
<figure data-shortcode="caption" id="attachment_1530" aria-describedby="caption-attachment-1530"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_06_48_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_06_48.jpg?w=1000" alt="walle_0_06_48" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_06_48.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_06_48.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_06_48.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1530">WALL·E’s iPod, showing <em>Hello, Dolly!</em> on its LCD color screen.</figcaption></figure>
<p>To work around the tiny scale of his iPod’s screen, WALL·E uses a plastic <a href="https://en.wikipedia.org/wiki/Fresnel_lens">Fresnel lens</a> as a magnifying device to enlarge the image to several times its original size. In doing so, he follows a trend started in <a href="https://en.wikipedia.org/wiki/Terry_Gilliam">Terry Gilliam</a>’s similarly dystopian <a href="https://en.wikipedia.org/wiki/Brazil_(1985_film)"><em>Brazil</em></a>, in which employees at the Ministry of Information Retrieval huddle around tiny CRT screens to watch westerns through Fresnel lenses when their boss isn’t looking.</p>
<figure data-shortcode="caption" id="attachment_1531" aria-describedby="caption-attachment-1531"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_27_44_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_27_44.jpg?w=1000" alt="walle_0_27_44" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_27_44.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_27_44.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_27_44.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1531">WALL·E watches a movie on his iPod’s small screen through a rectangular Fresnel lens.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1532" aria-describedby="caption-attachment-1532"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/brazil_0_07_58_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/brazil_0_07_58.jpg?w=1000" alt="brazil_0_07_58" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/brazil_0_07_58.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/brazil_0_07_58.jpg?w=150&amp;h=84 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/brazil_0_07_58.jpg?w=300&amp;h=168 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1532">In 1985’s <em>Brazil</em>, Ministry of Information employees watch movies on a small CRT screen through a rectangular Fresnel lens.</figcaption></figure>
<p>WALL·E awakes from robotic sleep on day two of the movie, low on power and dynamism. The fact that his head is a big pair of binoculars gives a great opportunity for a visual gag, as we see him literally bleary-eyed before activating the zoom lock on first his left eye, then his right, to reveal an eye-test chart in the opposing rack.</p>
<figure data-shortcode="caption" id="attachment_1533" aria-describedby="caption-attachment-1533"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_09_26_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_09_26.jpg?w=1000" alt="walle_0_09_26" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_09_26.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_09_26.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_09_26.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1533">From his bleary beginnings…</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1534" aria-describedby="caption-attachment-1534"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_09_27_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_09_27.jpg?w=1000" alt="walle_0_09_27" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_09_27.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_09_27.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_09_27.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1534">…WALL·E focuses first his left eye…</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1535" aria-describedby="caption-attachment-1535"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_09_28_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_09_28.jpg?w=1000" alt="walle_0_09_28" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_09_28.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_09_28.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_09_28.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1535">…and then his right, locking in on an eye test chart in the distance.</figcaption></figure>
<p>WALL·E’s binocular form is mimicked in the shape of his heads-up display (or HUD), which has the classic “two circles” shape used in many movies to indicate that we are looking from a character’s viewpoint through a pair of binoculars. This HUD raises an interesting question, however. Why does WALL·E have a heads-up display, with information overlaid on a video stream? A heads-up display really makes sense only if you are a human who has eyes; for a robot, any video input is combined with additional metadata from environmental sensors (such as direction, zoom, and power), and fed directly into the robot’s processor. Overlaying environmental information on a video stream implies that the robot has cameras that look at the world, and then <em>more</em> cameras that look at the augmented output of those cameras, which doesn’t make sense at all.</p>
<p>The answer, of course, is that WALL·E has a HUD because movie robots have HUDs, and movie robots have HUDs because they enable the viewer to visualize what the robots are thinking, even if it makes zero sense in technical reality. This trope began in 1973’s <a href="https://en.wikipedia.org/wiki/Westworld_(film)"><em>Westworld</em></a>, whose final act shows us the world from the vantage point of <a href="https://en.wikipedia.org/wiki/Yul_Brynner">Yul Brynner</a>’s gun-slinging robot. Although Brynner’s HUD is not augmented with data, it is nonetheless <a href="https://www.newyorker.com/tech/annals-of-technology/how-michael-crichtons-westworld-pioneered-modern-special-effects">the first use of computer-generated imagery in a feature film</a>. Director <a href="https://en.wikipedia.org/wiki/Michael_Crichton">Michael Crichton</a> cuts several times from a real-world scene to the robot’s pixelated version of the same, including a thermal image when Brynner chases his prey in the movie’s final act.</p>
<figure data-shortcode="caption" id="attachment_1536" aria-describedby="caption-attachment-1536"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/westworld_1_05_29_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/westworld_1_05_29.jpg?w=1000" alt="westworld_1_05_29" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/westworld_1_05_29.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/westworld_1_05_29.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/westworld_1_05_29.jpg?w=300&amp;h=124 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1536">A canyon in Westworld…</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1537" aria-describedby="caption-attachment-1537"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/westworld_1_05_30_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/westworld_1_05_30.jpg?w=1000" alt="westworld_1_05_30" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/westworld_1_05_30.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/westworld_1_05_30.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/westworld_1_05_30.jpg?w=300&amp;h=124 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1537">…and Yul Brynner’s pixellated view of the same.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1538" aria-describedby="caption-attachment-1538"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/westworld_1_20_11_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/westworld_1_20_11.jpg?w=1000" alt="westworld_1_20_11" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/westworld_1_20_11.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/westworld_1_20_11.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/westworld_1_20_11.jpg?w=300&amp;h=124 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1538">Yul Brynner’s gunslinging robot tracks its prey with a thermal imaging interpretation of its video input.</figcaption></figure>
<p><em>Westworld</em>’s “robot viewpoint” trope was codified by 1984’s <em><a href="https://en.wikipedia.org/wiki/The_Terminator">The Terminator</a></em> and 1987’s <em><a href="https://en.wikipedia.org/wiki/RoboCop">RoboCop</a></em>, both of which augmented their HUDs with additional data and text. Following these two movies, a heads-up display pretty much became the de facto expectation for any on-screen robot whose motives need to be understood.</p>
<figure data-shortcode="caption" id="attachment_1539" aria-describedby="caption-attachment-1539"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/terminator_1_14_34_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/terminator_1_14_34.jpg?w=1000" alt="terminator_1_14_34" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/terminator_1_14_34.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/terminator_1_14_34.jpg?w=150&amp;h=81 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/terminator_1_14_34.jpg?w=300&amp;h=162 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1539">A HUD screen from the T-800 Terminator, in 1984’s <em>The Terminator</em>. Here, the T-800 is determining an appropriate auditory response to a question from its apartment’s superintendent.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1540" aria-describedby="caption-attachment-1540"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/robocop_0_31_31_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/robocop_0_31_31.jpg?w=1000" alt="robocop_0_31_31" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/robocop_0_31_31.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/robocop_0_31_31.jpg?w=150&amp;h=81 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/robocop_0_31_31.jpg?w=300&amp;h=162 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1540">A HUD screen from the OCP Crime Prevention Unit 001, in 1987’s <em>RoboCop</em>. Here, RoboCop’s visual tracking system is being put through its paces by detecting the location of a pen. (Note that RoboCop’s HUD has highly visible scan lines, to make sure we know we are watching a live video stream in a movie.)</figcaption></figure>
<p>Pixar’s robot HUDs tend to include the shape of the robot’s eye(s) within the heads-up display, to help us associate the HUD with the character it represents. <a href="https://en.wikipedia.org/wiki/The_Incredibles"><em>The Incredibles</em></a>’ Omnidroid predates WALL·E’s binoculars in this regard. Other <em>WALL·E</em> robots—M-O, SECUR-T, and EVE—also follow suit.</p>
<figure data-shortcode="caption" id="attachment_1541" aria-describedby="caption-attachment-1541"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/incredibles_omnidroid_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/incredibles_omnidroid.jpg?w=1000" alt="incredibles_omnidroid" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/incredibles_omnidroid.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/incredibles_omnidroid.jpg?w=150&amp;h=128 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/incredibles_omnidroid.jpg?w=300&amp;h=256 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1541"><em>The Incredibles</em>’ Omnidroid has a HUD that makes the droid’s desire for self-preservation clear via some on-screen Eurostile Oblique. It also demonstrates the Pixar trend (continued in <em>WALL·E</em>) for HUDs to match the shapes of their robots’ eye(s).</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1542" aria-describedby="caption-attachment-1542"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_secur_t_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_secur_t.jpg?w=1000" alt="walle_secur_t" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_secur_t.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_secur_t.jpg?w=150&amp;h=128 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_secur_t.jpg?w=300&amp;h=256 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1542">The SECUR-T sentry robot’s eye in <em>WALL·E</em> is explicitly a camera, as reinforced by a SLR (single-lens-reflex)-camera-like HUD when taking a CAUTION photo of WALL·E’s rogue robots.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1543" aria-describedby="caption-attachment-1543"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_eve_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_eve.jpg?w=1000" alt="walle_eve" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_eve.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_eve.jpg?w=150&amp;h=128 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_eve.jpg?w=300&amp;h=256 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1543">EVE’s curved, lined HUD mirrors the curved, lined styling of her eyes and face.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1544" aria-describedby="caption-attachment-1544"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_m_o_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_m_o.jpg?w=1000" alt="walle_m_o" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_m_o.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_m_o.jpg?w=150&amp;h=128 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_m_o.jpg?w=300&amp;h=256 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1544">M-O’s wide, flat eye-panel shape is mirrored in his wide, flat on-screen HUD display. This shape, of course, requires his HUD to use <a href="https://typesetinthefuture.com/2014/11/29/fontspots-eurostile/">a certain wide, flat typeface</a> for its informative text.</figcaption></figure>
<p>Pixar’s neatest variation on the robot HUD trope occurs all the way back in 1999’s <a href="https://en.wikipedia.org/wiki/Toy_Story_2"><em>Toy Story 2</em></a>, where a plastic toy’s marketing gimmick (plus some clever camera framing) enables us to literally see through the eyes of the movie’s robotic bad guy.</p>
<figure data-shortcode="caption" id="attachment_1545" aria-describedby="caption-attachment-1545"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_ii_0_56_04_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_ii_0_56_04.jpg?w=1000" alt="toy_story_ii_0_56_04" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_ii_0_56_04.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_ii_0_56_04.jpg?w=150&amp;h=84 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_ii_0_56_04.jpg?w=300&amp;h=168 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1545">Evil Emperor Zurg, arch-enemy of Buzz Lightyear, in 1999’s <em>Toy Story 2</em>.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1546" aria-describedby="caption-attachment-1546"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_ii_0_56_06_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_ii_0_56_06.jpg?w=1000" alt="toy_story_ii_0_56_06" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_ii_0_56_06.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_ii_0_56_06.jpg?w=150&amp;h=84 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_ii_0_56_06.jpg?w=300&amp;h=168 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1546">As Buzz runs away from Zurg, a camera move brilliantly subverts the robot HUD trope…</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1547" aria-describedby="caption-attachment-1547"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_ii_0_56_08_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_ii_0_56_08.jpg?w=1000" alt="toy_story_ii_0_56_08" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_ii_0_56_08.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_ii_0_56_08.jpg?w=150&amp;h=84 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_ii_0_56_08.jpg?w=300&amp;h=168 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1547">…turning a plastic toy’s “LOOK HERE” scope…</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1548" aria-describedby="caption-attachment-1548"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_ii_0_56_10_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_ii_0_56_10.jpg?w=1000" alt="toy_story_ii_0_56_10" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_ii_0_56_10.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_ii_0_56_10.jpg?w=150&amp;h=84 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_ii_0_56_10.jpg?w=300&amp;h=168 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1548">…into the bad guy’s evil robot HUD…</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1549" aria-describedby="caption-attachment-1549"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_ii_0_56_13_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_ii_0_56_13.jpg?w=1000" alt="toy_story_ii_0_56_13" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_ii_0_56_13.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_ii_0_56_13.jpg?w=150&amp;h=84 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/toy_story_ii_0_56_13.jpg?w=300&amp;h=168 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1549">…complete with ZURG VISION logo in Eurostile Bold Oblique.</figcaption></figure>
<p>There is one further question raised by WALL·E’s binocular HUD. How does his directional compass—seen at the top center of his HUD—continue to work when he is aboard the <em>Axiom</em>? <a href="https://tvtropes.org/pmwiki/pmwiki.php/Main/AliensOfLondon?from=Main.LotsOfPlanetsHaveANorth">Lots of planets may have a north</a>, but the same is not true of spacecraft—north, south, east, and west make sense only when you’re on the surface of a sphere.</p>
<figure data-shortcode="caption" id="attachment_1550" aria-describedby="caption-attachment-1550"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_39_25_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_39_25.jpg?w=1000" alt="walle_0_39_25" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_39_25.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_39_25.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_39_25.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1550">A detail from WALL·E’s binoculars when onboard the Axiom. This compass direction indicator, from the top of the viewport, updates as he rotates, despite the notable absence of a planet.</figcaption></figure>
<p>Day two (and act two) of <em>WALL·E</em> see a Buy n Large scout ship arrive on Earth, disrupting WALL·E’s routine. Most importantly, it introduces us to EVE, who is everything WALL·E is not. EVE’s shiny white design is technologically advanced; she’s the curvy <a href="https://en.wikipedia.org/wiki/IMac_G4">iMac G4</a> to WALL·E’s boxy <a href="https://en.wikipedia.org/wiki/Macintosh_128K">Mac 128K</a>. Her design evokes sleek Apple products of the 2000s, with her head, in particular, highly reminiscent of a 2002 iMac G4’s base. Even her reboot sound is a futuristic take on Apple’s <a href="https://www.cnbc.com/2018/03/24/jim-reekes-the-apple-sound-designer-who-created-sosumi.html">famous startup chime</a>, whereas WALL·E’s post-charge chime is the version Apple introduced in 1998 and <a href="https://support.apple.com/en-us/HT202768">removed altogether in 2016</a>.</p>
<figure data-shortcode="caption" id="attachment_1551" aria-describedby="caption-attachment-1551"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_15_33_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_15_33.jpg?w=1000" alt="walle_0_15_33" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_15_33.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_15_33.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_15_33.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1551">WALL·E sees EVE for the first time, as she is released from her transporter pod to begin scanning Earth.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1552" aria-describedby="caption-attachment-1552"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_imac_g4_side_view.jpg?w=1000" alt="walle_imac_g4_side_view" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_imac_g4_side_view.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_imac_g4_side_view.jpg?w=150&amp;h=143 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_imac_g4_side_view.jpg?w=300&amp;h=285 300w" sizes="(max-width: 560px) 100vw, 560px"><figcaption id="caption-attachment-1552">Side view of an iMac G4,<br>released in 2002, with an EVE-head-like base.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1553" aria-describedby="caption-attachment-1553"><a href="https://flic.kr/p/5UTQB5"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_macintosh_128k.jpg?w=1000" alt="walle_macintosh_128k" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_macintosh_128k.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_macintosh_128k.jpg?w=114&amp;h=150 114w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_macintosh_128k.jpg?w=228&amp;h=300 228w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1553">An Apple Macintosh 128k, released in 1984, with a WALL·E-like beige body.&nbsp;<a href="https://flic.kr/p/5UTQB5">Photograph by Ian Muttoo, CC BY-SA 2.0</a>.</figcaption></figure>
<p>EVE’s evocation of Apple product design is not entirely coincidental. In a <a href="http://fortune.com/2008/05/12/fortune-apples-ive-helped-design-the-heroine-of-pixars-wall-e/">2008 interview with <em>Fortune</em> magazine</a>, director <a href="https://en.wikipedia.org/wiki/Andrew_Stanton">Andrew Stanton</a> stated: “I wanted EVE to be high-end technology—no expense spared—and I wanted it to be seamless and for the technology to be sort of hidden and subcutaneous. The more I started describing it, the more I realized I was pretty much describing the Apple playbook for design.” This led to a 2005 call to Steve Jobs—at that time, both owner of Pixar and CEO of Apple—which in turn led to Apple design head <a href="https://en.wikipedia.org/wiki/Jony_Ive">Jony Ive</a> spending a day at the Pixar headquarters in Emeryville, consulting on the EVE prototype. (It is surely entirely coincidental that EVE’s wireless arms and hands are reminiscent of Apple’s wireless <a href="https://en.wikipedia.org/wiki/Magic_Mouse">Magic Mouse</a>, released the year after <em>WALL·E</em>.)</p>
<figure data-shortcode="caption" id="attachment_1554" aria-describedby="caption-attachment-1554"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_28_01_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_28_01.jpg?w=1000" alt="walle_1_28_01" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_28_01.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_28_01.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_28_01.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1554">Eve’s wirelessly-connected fingers and hands, as seen in 2008’s <em>WALL·E</em>.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1555" aria-describedby="caption-attachment-1555"><a href="https://flic.kr/p/7F83fo"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_magic_mouse.jpg?w=1000" alt="walle_magic_mouse" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_magic_mouse.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_magic_mouse.jpg?w=150&amp;h=100 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_magic_mouse.jpg?w=300&amp;h=200 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1555">Apple’s wireless Magic Mouse, released in 2009.&nbsp;<a href="https://flic.kr/p/7F83fo">Photograph by Yutaka Tsutano, CC BY 2.0</a>.</figcaption></figure>
<p>During a dust storm, WALL·E takes EVE back to the safety of his home, where he presents her with a small multicolored cube. In the three seconds the camera pans away for WALL·E to retrieve <em>Hello, Dolly!</em>, EVE solves the <a href="https://en.wikipedia.org/wiki/Rubik%27s_Cube">Rubik’s Cube</a> and returns it to her astonished host.</p>
<figure data-shortcode="caption" id="attachment_1556" aria-describedby="caption-attachment-1556"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_25_15_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_25_15.jpg?w=1000" alt="walle_0_25_15" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_25_15.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_25_15.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_25_15.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1556">WALL·E presents EVE with a Rubik’s Cube from his trash collection.</figcaption></figure>
<p>EVE’s cube-solving time would be impressive for a human; the current world record is 4.22 seconds, <a href="http://www.guinnessworldrecords.com/news/2018/5/feliks-zemdegs-achieves-fastest-time-to-solve-a-rubiks-cube-in-4-22-seconds-524695">set by Feliks Zemdegs in May 2018</a>. Sadly, because of the camera pan, we’ll never know if EVE broke the world record for a robot, which currently stands at a mind-boggling 0.637 seconds. This record was set in November 2016 by <a href="http://www.guinnessworldrecords.com/news/2017/3/video-robot-breaks-world-record-solving-rubiks-cube-in-0-637-seconds-464392">Sub1 Reloaded</a>, a cube-solving robot built by German engineer Albert Beer. Six high-performance stepper motors turned the cube twenty-one times to complete the task, averaging just 0.03 seconds per rotation.</p>
<figure data-shortcode="caption" id="attachment_1557" aria-describedby="caption-attachment-1557"><a href="https://www.infineon.com/cms/en/about-infineon/press/press-releases/2016/INFXX201611-014.html"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_infineon_rubik_01.jpg?w=1000" alt="walle_infineon_rubik_01" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_infineon_rubik_01.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_infineon_rubik_01.jpg?w=150&amp;h=100 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_infineon_rubik_01.jpg?w=300&amp;h=200 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1557">Sub1 Reloaded, the world-record-holding Rubik’s Cube robot, in November 2016.</figcaption></figure>
<p>Spare a thought, then, for poor WALL·E. His surprise at EVE’s accomplishment is understandable—he lacks color vision and has only three digits on each hand, which means that Rubik’s Cubes are really not his specialty. (There’s a reason Guinness doesn’t have a “fastest dog” <a href="http://www.guinnessworldrecords.com/search?term=rubik">Rubik’s Cube category</a>.)</p>
<p>One other point of note: This scene is the only time the color green appears in <em>WALL·E</em> in a scene unrelated to a plant. While this breaks the movie’s careful color scripting, it’s worth it for a good gag.</p>
<p>All seems to be going well with WALL·E and EVE’s introductions, until they are rudely interrupted by EVE’s spotting a plant that WALL·E has excavated from the trash. She subsumes the plant, as per her “directive,” and enters hibernation mode. WALL·E’s attempts to wake her invariably end in comedic pain, though one of them does reveal EVE’s serial number, 051682, set in Handel Gothic. (I can’t help but wonder whether someone in Pixar’s art department was born on May 16, 1982.)</p>
<figure data-shortcode="caption" id="attachment_1558" aria-describedby="caption-attachment-1558"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_30_08_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_30_08.jpg?w=1000" alt="walle_0_30_08" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_30_08.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_30_08.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_30_08.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1558">EVE’s serial number, seen on the inside of the door above, is 051682.</figcaption></figure>
<p>WALL·E gives up on reviving EVE and disconsolately returns to his trash-crushing routine. Shortly afterward, the <em>Axiom</em>’s scout ship returns to Earth and collects EVE to take her home. Desperate not to lose his new friend, WALL·E hitches a ride on the outside of the scout, causing him grief when the ship blasts through Earth’s surrounding satellite trash. As the satellites fall away, we see that WALL·E has a Soviet-era <em><a href="https://en.wikipedia.org/wiki/Sputnik_1">Sputnik 1</a></em> satellite on his head. This is impressive, especially given that <em>Sputnik 1</em>—the first man-made object to orbit Earth—burned up on reentry to Earth’s atmosphere in 1958.</p>
<figure data-shortcode="caption" id="attachment_1559" aria-describedby="caption-attachment-1559"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_33_36_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_33_36.jpg?w=1000" alt="walle_0_33_36" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_33_36.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_33_36.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_33_36.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1559">As the <em>Axiom</em> scout ship breaks through Earth’s satellites…</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1560" aria-describedby="caption-attachment-1560"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_33_44_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_33_44.jpg?w=1000" alt="walle_0_33_44" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_33_44.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_33_44.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_33_44.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1560">…WALL·E is briefly left with <em>Sputnik 1</em> on his head.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1561" aria-describedby="caption-attachment-1561"><a href="https://www.nasa.gov/directorates/heo/scan/images/history/October1957_2.html"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_sputnik_replica.jpg?w=1000" alt="walle_sputnik_replica" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_sputnik_replica.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_sputnik_replica.jpg?w=150&amp;h=123 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_sputnik_replica.jpg?w=300&amp;h=246 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1561">A replica of the <em>Sputnik 1</em> satellite, showing its 58cm-diameter aluminum sphere and four spindly antennas</figcaption></figure>
<p>We see <em>Sputnik 1</em> again later in the movie, as a model in Captain McCrea’s display cabinet. This model is accompanied by a <a href="https://airandspace.si.edu/collection-objects/helmet-backshell-launch-entry-shuttle">NASA space shuttle launch/entry helmet</a>, as worn by space shuttle astronauts between 1982 and 1986 during launch and return from space.</p>
<figure data-shortcode="caption" id="attachment_1562" aria-describedby="caption-attachment-1562"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_03_47_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_03_47.jpg?w=1000" alt="walle_1_03_47" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_03_47.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_03_47.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_03_47.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1562">A space shuttle launch/entry helmet and a Sputnik model in Captain McCrea’s display case.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1563" aria-describedby="caption-attachment-1563"><a href="https://spaceflight.nasa.gov/gallery/images/shuttle/sts-51l/html/s85-40031.html"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_space_shuttle_helmet_super_crop.jpg?w=1000" alt="walle_space_shuttle_helmet_super_crop" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_space_shuttle_helmet_super_crop.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_space_shuttle_helmet_super_crop.jpg?w=150&amp;h=150 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_space_shuttle_helmet_super_crop.jpg?w=300&amp;h=300 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1563">Payload specialist Sharon Christa McAuliffe is briefed on the space shuttle’s launch/entry helmet during training for the January 1986 launch of flight STS-51L.</figcaption></figure>
<p>This “retro space tech” theme can also be seen on Earth during EVE’s scan for plant life. After scanning a <em>Toy Story</em> <a href="http://pixar.wikia.com/wiki/Pizza_Planet_Truck">Pizza Planet truck</a> and a portable lavatory, EVE checks a rusting <a href="https://en.wikipedia.org/wiki/Apollo_Command/Service_Module"><em>Apollo</em> command module</a> before slamming the door shut in disgust at its absence of plant-based life.</p>
<figure data-shortcode="caption" id="attachment_1564" aria-describedby="caption-attachment-1564"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_21_18_1_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_21_18_1.jpg?w=1000" alt="walle_0_21_18_1" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_21_18_1.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_21_18_1.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_21_18_1.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1564">A BnL-branded <em>Apollo</em>-style command module in a pile of trash on Earth.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1565" aria-describedby="caption-attachment-1565"><a href="https://flic.kr/p/nFr8MZ"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_apollo_14_command_module.jpg?w=1000" alt="walle_apollo_14_command_module" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_apollo_14_command_module.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_apollo_14_command_module.jpg?w=150&amp;h=100 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_apollo_14_command_module.jpg?w=300&amp;h=200 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1565">The <em>Apollo 14</em> command module, nicknamed “Kitty Hawk,” at the Kennedy Space Center in Florida.&nbsp;<a href="https://flic.kr/p/nFr8MZ">Photograph by gordonplant, CC BY 2.0</a>.</figcaption></figure>
<p>Showing recent space technology as trash or as museum pieces positions our personal experiences of space as archaic and quaint in comparison to the <em>Axiom</em>’s futuristic styling. This further reinforces WALL·E’s own obsolescence as a discarded piece of technology, and sets us up neatly for a transition to the shiny futurism of the <em>Axiom</em>.</p>
<p>The <em>Axiom</em> paints a vision of the future where every menial task, no matter how small, has a dedicated robot created expressly for the purpose. Like <em>2001: A Space Odyssey</em>’s HAL and <em>Alien</em>’s MU/TH/UR, all these robots have cute acronyms to make them human-friendly.</p>
<figure data-shortcode="caption" id="attachment_1566" aria-describedby="caption-attachment-1566"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_05_29_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_05_29.jpg?w=1000" alt="walle_0_05_29" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_05_29.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_05_29.jpg?w=150&amp;h=61 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_05_29.jpg?w=300&amp;h=122 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1566">SAUT-A (chefbot).</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1567" aria-describedby="caption-attachment-1567"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_36_37_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_36_37.jpg?w=1000" alt="walle_0_36_37" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_36_37.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_36_37.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_36_37.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1567">Microbe Obliterator, or M·O.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1568" aria-describedby="caption-attachment-1568"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_36_39_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_36_39.jpg?w=1000" alt="walle_0_36_39" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_36_39.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_36_39.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_36_39.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1568">VAQ-M (vacuumbot), BUF-4 (bufferbot), and SPR-A (spraybot).</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1569" aria-describedby="caption-attachment-1569"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_44_30_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_44_30.jpg?w=1000" alt="walle_0_44_30" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_44_30.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_44_30.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_44_30.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1569">HAN-S (massagebot), and PR-T (beauticianbot).</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1570" aria-describedby="caption-attachment-1570"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_46_22_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_46_22.jpg?w=1000" alt="walle_0_46_22" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_46_22.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_46_22.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_46_22.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1570">SR-V (tennisbot).</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1571" aria-describedby="caption-attachment-1571"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_46_26_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_46_26.jpg?w=1000" alt="walle_0_46_26" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_46_26.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_46_26.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_46_26.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1571">BIRD-E (golfbot).</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1572" aria-describedby="caption-attachment-1572"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_55_02_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_55_02.jpg?w=1000" alt="walle_0_55_02" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_55_02.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_55_02.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_55_02.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1572">SECUR-T (stewardbot).</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1573" aria-describedby="caption-attachment-1573"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_02_09_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_02_09.jpg?w=1000" alt="walle_1_02_09" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_02_09.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_02_09.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_02_09.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1573">BURN-E (maintenancebot), shortly after being locked out of the <em>Axiom</em> by WALL·E and EVE.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1574" aria-describedby="caption-attachment-1574"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_11_14_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_11_14.jpg?w=1000" alt="walle_1_11_14" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_11_14.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_11_14.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_11_14.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1574">GO-4 (gopherbot).</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1575" aria-describedby="caption-attachment-1575"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_12_21_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_12_21.jpg?w=1000" alt="walle_1_12_21" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_12_21.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_12_21.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_12_21.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1575">Waste Allocation Load Lifter · <em>Axiom</em> Class, or WALL·A.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1576" aria-describedby="caption-attachment-1576"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_19_55_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_19_55.jpg?w=1000" alt="walle_1_19_55" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_19_55.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_19_55.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_19_55.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1576">NAN-E (nannybot).</figcaption></figure>
<p>Of particular note is VN-GO, the painterbot, whose acronym perpetuates a common yet incorrect pronunciation of Dutch painter <a href="https://en.wikipedia.org/wiki/Vincent_van_Gogh">Vincent van Gogh</a>’s surname. (<a href="http://www.bbc.co.uk/blogs/magazinemonitor/2010/01/how_to_say_van_gogh.shtml">According to the BBC Pronunciation Unit</a>, it is “van Gokh,” with the kh pronounced like the ch in the Scottish word loch.)</p>
<figure data-shortcode="caption" id="attachment_1577" aria-describedby="caption-attachment-1577"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_16_25_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_16_25.jpg?w=1000" alt="walle_1_16_25" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_16_25.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_16_25.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_16_25.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1577">VN-GO (paintbot).</figcaption></figure>
<p>EVE’s acronym, sadly, is even worse. Her denomination as Extraterrestrial Vegetation Evaluator could not be more inaccurate, given that her entire reason for existing is to evaluate vegetation on the planet <a href="https://en.wiktionary.org/wiki/Terra">Terra</a> (as Earth is known in Latin). Presumably, her moniker was chosen for cuteness rather than linguistic accuracy—after all, this movie is about WALL·E and EVE, not WALL·E and TVE.</p>
<p>Also of note is TYP-E, a typingbot who is designed solely to press keys when someone approaches the elevator shaft to the captain’s quarters. TYP-E provides an excuse for one of the movie’s best visual gags—as a robot, he has a keyboard made entirely, of course, from ones and zeroes.</p>
<figure data-shortcode="caption" id="attachment_1578" aria-describedby="caption-attachment-1578"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_43_16_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_43_16.jpg?w=1000" alt="walle_0_43_16" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_43_16.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_43_16.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_43_16.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1578">TYP-E (typingbot).</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1579" aria-describedby="caption-attachment-1579"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_43_04_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_43_04.jpg?w=1000" alt="walle_0_43_04" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_43_04.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_43_04.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_43_04.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1579">In a brief over-the-shoulder shot, we see that TYP-E’s keyboard is made entirely from keys labeled <em>1</em> and <em>0</em>.</figcaption></figure>
<p>M-O’s cleaning colleagues (VAQ-M, SPR-A, and BUF-4) may bring back memories for fans of 1997’s <a href="https://en.wikipedia.org/wiki/The_Fifth_Element"><em>The Fifth Element</em></a>. In <a href="https://en.wikipedia.org/wiki/Luc_Besson">Luc Besson</a>’s over-the-top vision of the future, evil industrialist Zorg demonstrates his own array of task-specific robots by dropping a glass tumbler on the floor to trigger their “lovely ballet.” As two sentrybots stand guard, a sweeperbot, a spraybot, and a bufferbot clean up his mess before returning to a nearby storage station.</p>
<figure data-shortcode="caption" id="attachment_1580" aria-describedby="caption-attachment-1580"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/fifth_element_0_54_34_2_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/fifth_element_0_54_34_2.jpg?w=1000" alt="fifth_element_0_54_34_2" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/fifth_element_0_54_34_2.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/fifth_element_0_54_34_2.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/fifth_element_0_54_34_2.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1580"><em>The Fifth Element</em> pre-empts <em>WALL·E</em>’s cleaning robots with its own sweeperbot…</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1581" aria-describedby="caption-attachment-1581"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/fifth_element_0_54_36_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/fifth_element_0_54_36.jpg?w=1000" alt="fifth_element_0_54_36" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/fifth_element_0_54_36.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/fifth_element_0_54_36.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/fifth_element_0_54_36.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1581">…spraybot…</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1582" aria-describedby="caption-attachment-1582"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/fifth_element_0_54_38_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/fifth_element_0_54_38.jpg?w=1000" alt="fifth_element_0_54_38" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/fifth_element_0_54_38.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/fifth_element_0_54_38.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/fifth_element_0_54_38.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1582">…and bufferbot.</figcaption></figure>
<p>The <em>Axiom</em>’s robots travel around the ship via their own dedicated corridors, separate from the craft’s passenger areas. These passenger areas are split into three classes—economy, coach, and elite—each of which has a distinct architectural style. The classes themselves do not play a functional role in the movie’s plot, but one has to wonder what they mean for the <em>Axiom</em>’s society. Are children born into the classes their ancestors originally purchased, as if into some kind of futuristic caste system? Would the <em>Axiom</em> have its own <a href="https://en.wikipedia.org/wiki/Titanic_(1997_film)"><em>Titanic</em></a> moment if a passenger from economy bumped hover chairs with someone from elite? One thing’s certain: The styling of each class is extremely useful for helping viewers orient themselves within the ship’s overall structure as the action moves back and forth along its length.</p>
<p>Our introduction to the passenger area starts with the economy deck, which is compact, angular, and concrete in texture and color. Its palette is deliberately sparse, rarely moving outside the Buy n Large blue, red, and white, and making extensive use of the corporation’s Futura Extra Bold Oblique.</p>
<figure data-shortcode="caption" id="attachment_1583" aria-describedby="caption-attachment-1583"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_40_04_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_40_04.jpg?w=1000" alt="walle_0_40_04" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_40_04.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_40_04.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_40_04.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1583">The economy deck, as seen by WALL·E shortly after his arrival on the <em>Axiom</em>. Apart from a few hints of yellow, it follows the BnL corporate color scheme exclusively, with plenty of Futura Extra Bold Oblique.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1584" aria-describedby="caption-attachment-1584"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_46_17_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_46_17.jpg?w=1000" alt="walle_0_46_17" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_46_17.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_46_17.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_46_17.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1584">The economy deck, as seen when Captain McCrea announces the <em>Axiom</em>’s 700-year anniversary.</figcaption></figure>
<p>The deck’s design is highly reminiscent of the interior of the Contemporary Tower at Walt Disney World <a href="https://en.wikipedia.org/wiki/Disney%27s_Contemporary_Resort">Contemporary Resort</a>, whose A-frame concrete-and-steel structure was so futuristic when it opened in 1971 that it even had a monorail running through the middle. (As anyone who has stayed at the Contemporary can attest, however, its rates can hardly be considered “economy.”)</p>
<figure data-shortcode="caption" id="attachment_1585" aria-describedby="caption-attachment-1585"><a href="https://flic.kr/p/aCmeqK"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_axiom_economy_contemporary_interior.jpg?w=1000" alt="walle_axiom_economy_contemporary_interior" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_axiom_economy_contemporary_interior.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_axiom_economy_contemporary_interior.jpg?w=112&amp;h=150 112w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_axiom_economy_contemporary_interior.jpg?w=225&amp;h=300 225w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1585">Interior of the Contemporary Tower at Walt Disney World Contemporary Resort, as it looked in 2011. The blue raised platform on the right is a monorail station with a green-line monorail currently boarding.&nbsp;<a href="https://flic.kr/p/aCmeqK">Photograph by Sam Howzit, CC BY 2.0</a>.</figcaption></figure>
<p>The coach deck, unlike the economy deck, is curved, eclectic, and spacious, with brightly colored holo-ads scattered everywhere. It mimics Las Vegas’s Strip in gaudiness and style, with artificial neon colors used extensively and every sign encouraging <em>Axiom</em> passengers to spend more money. (How the ship’s financial economy continues to function after a seven-hundred-year flight continues to remain a mystery.)</p>
<figure data-shortcode="caption" id="attachment_1586" aria-describedby="caption-attachment-1586"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_41_12_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_41_12.jpg?w=1000" alt="walle_0_41_12" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_41_12.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_41_12.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_41_12.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1586">The central mall area of the <em>Axiom</em>’s coach deck, with garish, over-saturated holographic ads and signs.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1751" aria-describedby="caption-attachment-1751"><a href="https://www.istockphoto.com/photo/las-vegas-strip-at-night-gm458116603-17719435"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_axiom_coach_vegas_strip_crop.jpg?w=1000" alt="Las Vegas Strip at night" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_axiom_coach_vegas_strip_crop.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_axiom_coach_vegas_strip_crop.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_axiom_coach_vegas_strip_crop.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1751">A section of the Las Vegas Strip at night, showing a similar palette of over-saturated cyan, purple, pink, and yellow hues, combined with omnipresent ads encouraging consumption.&nbsp;<a href="https://www.istockphoto.com/photo/las-vegas-strip-at-night-gm458116603-17719435">Photograph by rabbit75_ist</a>.</figcaption></figure>
<p>The ceiling of the coach deck is a gigantic animated screen that can switch between day and night, complete with a BnL-branded sun or moon. The ceiling’s relationship to <em>actual</em> time is somewhat tenuous, as we see when Captain McCrea winds the sky back from 12:30 p.m. to 9:30 a.m. in order to make his morning announcements. In this regard, the ceiling is essentially an amalgam of two Las Vegas landmarks: the painted cloud ceilings of the <a href="https://en.wikipedia.org/wiki/The_Forum_Shops_at_Caesars">Forum indoor arcade</a> at <a href="https://en.wikipedia.org/wiki/Caesars_Palace">Caesars Palace</a>, whose lighting <a href="http://www.colorkinetics.com/showcase/installs/Caesars-Palace-Forum-Shops/">ebbs and changes</a> without ever making it nighttime enough for you to want to stop buying things, and the four-block-long overhead screen of the <a href="https://en.wikipedia.org/wiki/Fremont_Street_Experience">Fremont Street Experience</a>—the world’s largest video screen—whose 12.5 million LEDs illuminate Vegas partygoers every night. The result is an entirely fake sky for the <em>Axiom</em>’s population, allowing finely tuned control over their artificial environment.</p>
<figure data-shortcode="caption" id="attachment_1587" aria-describedby="caption-attachment-1587"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_45_51_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_45_51.jpg?w=1000" alt="walle_0_45_51" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_45_51.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_45_51.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_45_51.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1587">The coach deck’s sky dome ceiling, transitioning from midday to early morning.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1588" aria-describedby="caption-attachment-1588"><a href="https://flic.kr/p/XMaHuq"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_axiom_coach_caesars_palace_ceiling.jpg?w=1000" alt="walle_axiom_coach_caesars_palace_ceiling" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_axiom_coach_caesars_palace_ceiling.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_axiom_coach_caesars_palace_ceiling.jpg?w=150&amp;h=84 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_axiom_coach_caesars_palace_ceiling.jpg?w=300&amp;h=169 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1588">The painted, vaulted ceiling of the Forum Shops arcade at Caesars Palace, Las Vegas.&nbsp;<a href="https://flic.kr/p/XMaHuq">Photograph by anokarina, CC BY-SA 2.0</a>.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1589" aria-describedby="caption-attachment-1589"><a href="https://flic.kr/p/BUXLBo"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_axiom_coach_fremont_experience_ceiling.jpg?w=1000" alt="walle_axiom_coach_fremont_experience_ceiling" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_axiom_coach_fremont_experience_ceiling.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_axiom_coach_fremont_experience_ceiling.jpg?w=100&amp;h=150 100w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_axiom_coach_fremont_experience_ceiling.jpg?w=200&amp;h=300 200w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1589">The four-block-long LED ceiling of the Fremont Street Experience, Las Vegas.&nbsp;<a href="https://flic.kr/p/BUXLBo">Photograph by dconvertini, CC BY-SA 2.0</a>.</figcaption></figure>
<p>The coach deck leads to the elite deck, whose styling resembles that of a high-class lido or spa. Despite their very different palettes, the coach and elite decks share a curved, futuristic environmental styling that unifies their overall architecture. <a href="http://www.animationartconservation.com/design-with-a-purpose%2C-an-interview-with-ralph-eggleston.html">According to production designer Ralph Eggleston</a>, the architecture of this shared area is inspired by the work of architect <a href="https://en.wikipedia.org/wiki/Santiago_Calatrava">Santiago Calatrava</a>, whose signature curved supports and arches can be seen throughout both decks’ central concourse.</p>
<figure data-shortcode="caption" id="attachment_1590" aria-describedby="caption-attachment-1590"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_41_07_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_41_07.jpg?w=1000" alt="walle_0_41_07" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_41_07.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_41_07.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_41_07.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1590">Close-up of the arched supports in the central coach deck plaza.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1592" aria-describedby="caption-attachment-1592"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_42_28_3_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_42_28_3.jpg?w=1000" alt="walle_0_42_28_3" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_42_28_3.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_42_28_3.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_42_28_3.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1592">Transitional area between the coach and elite decks, showing arched supports around the central transportation line.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1595" aria-describedby="caption-attachment-1595"><a href="https://flic.kr/p/eae7XA"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_calatrava_milwaukee_cafe.jpg?w=1000" alt="walle_calatrava_milwaukee_cafe.jpg" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_calatrava_milwaukee_cafe.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_calatrava_milwaukee_cafe.jpg?w=150&amp;h=111 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_calatrava_milwaukee_cafe.jpg?w=300&amp;h=221 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1595">Café Calatrava, Milwaukee Art Museum, Wisconsin. Designed by Santiago Calatrava, completed in 2001.&nbsp;<a href="https://flic.kr/p/eae7XA">Photograph by Peter Alfred Hess, CC BY 2.0</a>.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1594" aria-describedby="caption-attachment-1594"><a href="https://flic.kr/p/cosGR9"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_calatrava_lyon_concourse.jpg?w=1000" alt="walle_calatrava_lyon_concourse" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_calatrava_lyon_concourse.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_calatrava_lyon_concourse.jpg?w=150&amp;h=113 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_calatrava_lyon_concourse.jpg?w=300&amp;h=225 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1594">Concourse and roof supports, Lyon–Saint-Exupéry Airport Railway Station, Colombier-Saugnieu, France. Designed by Santiago Calatrava, completed in 1994.&nbsp;<a href="https://flic.kr/p/cosGR9">Photograph by Ingolf, CC BY-SA 2.0</a>.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1591" aria-describedby="caption-attachment-1591"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_41_24_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_41_24.jpg?w=1000" alt="walle_0_41_24" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_41_24.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_41_24.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_41_24.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1591">An arched glass half-dome in the coach deck’s food court.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1593" aria-describedby="caption-attachment-1593"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_42_44_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_42_44.jpg?w=1000" alt="walle_0_42_44" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_42_44.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_42_44.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_42_44.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1593">Close-up of the base of the captain’s control tower, showing its arched, glass-fronted entrance.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1596" aria-describedby="caption-attachment-1596"><a href="https://flic.kr/p/82YLtB"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_calatrava_milwaukee_exterior_detail.jpg?w=1000" alt="walle_calatrava_milwaukee_exterior_detail" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_calatrava_milwaukee_exterior_detail.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_calatrava_milwaukee_exterior_detail.jpg?w=150&amp;h=100 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_calatrava_milwaukee_exterior_detail.jpg?w=300&amp;h=200 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1596">Exterior detail, Milwaukee Art Museum, Wisconsin. Designed by Santiago Calatrava, completed in 2001.&nbsp;<a href="https://flic.kr/p/82YLtB">Photograph by joevare, CC BY-ND 2.0</a>.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1597" aria-describedby="caption-attachment-1597"><a href="https://flic.kr/p/dmTZZa"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_calatrava_tenerife_arch.jpg?w=1000" alt="walle_calatrava_tenerife_arch" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_calatrava_tenerife_arch.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_calatrava_tenerife_arch.jpg?w=150&amp;h=79 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_calatrava_tenerife_arch.jpg?w=300&amp;h=158 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1597">Arched exterior of the Adán Martín Auditorio de Tenerife, Santa Cruz de Tenerife. Designed by Santiago Calatrava, completed in 2003.&nbsp;<a href="https://flic.kr/p/dmTZZa">Photograph by Rick Ligthelm, CC BY 2.0</a>.</figcaption></figure>
<p>The other main influence for the <em>Axiom</em>’s architecture is the design of the <a href="https://en.wikipedia.org/wiki/Tomorrowland">Tomorrowland</a> area of <a href="https://en.wikipedia.org/wiki/Disneyland">Disneyland</a>, in California. According to production designer Ralph Eggleston, during the movie’s production <em>WALL·E</em>’s design team visited an exhibition of Tomorrowland concept art and took inspiration from the designs therein.&nbsp;Perhaps the most obvious of these influences is the presence of a PeopleMover transportation system running through the middle of the club and elite decks, in a style very similar to the <a href="https://en.wikipedia.org/wiki/PeopleMover">PeopleMover</a> at Tomorrowland. (Do check out DaveLandWeb’s fantastic <a href="https://www.davelandweb.com/peoplemover/">PeopleMover photo page</a> for some great examples of the original in action.)</p>
<figure data-shortcode="caption" id="attachment_1598" aria-describedby="caption-attachment-1598"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_40_24_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_40_24.jpg?w=1000" alt="walle_0_40_24" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_40_24.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_40_24.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_40_24.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1598">The club deck’s circular PeopleMover loading area.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1599" aria-describedby="caption-attachment-1599"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_19_26_2_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_19_26_2.jpg?w=1000" alt="walle_1_19_26_2" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_19_26_2.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_19_26_2.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_19_26_2.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1599">Raised PeopleMover tracks running along the length of the club deck.</figcaption></figure>
<p>The evolution of Disney’s PeopleMover concept began with the <a href="https://en.wikipedia.org/wiki/1964_New_York_World%27s_Fair">1964–65 New York World’s Fair</a>, for which the Ford Motor Company asked Disney to <a href="https://www.thehenryford.org/collections-and-research/digital-collections/artifact/67807/#slide=gs-292282">design an attraction</a> to compete with General Motors’ <a href="http://www.nywf64.com/gm06.shtml">Futurama II</a> exhibit. The resulting <a href="https://www.waltdisney.org/blog/beyond-magic-skyway">Magic Skyway</a> gave fairgoers an opportunity to ride in a <a href="https://www.thehenryford.org/collections-and-research/digital-collections/artifact/361330/">driverless Ford convertible</a>—including the just-launched Ford Mustang—through a diorama that transported them from prehistoric times to a futuristic space city.</p>
<p>Following its success at the World’s Fair, the traction system behind Magic Skyway was adapted into a new feature for Tomorrowland’s 1967 relaunch. The new attraction, known as the WEDway PeopleMover, enabled <strong>W</strong>alter <strong>E</strong>lias <strong>D</strong>isney to follow Axel Lennart Wenner-Gren (of ALWEG monorail fame) in naming a futuristic transportation mechanism with his initials. It also provided an ideal inspiration for the <em>Axiom</em>’s central transport system.</p>
<p>The <em>Axiom</em>’s PeopleMover has much in common with its WEDway counterpart. Both are focused on a main circular loading area in the heart of a central plaza, with a long, straight stretch of track extending away from the loading deck. Both give passengers a tantalizing view of surrounding attractions as they are transported from one area to another. Indeed, I am sure Walt Disney would have been delighted to see his dream of future transportation integrated into the <em>Axiom</em>’s space-age environment, especially given that Disneyland’s PeopleMover was a prototype for Walt’s grander vision of futuristic living. Walt planned to build a larger PeopleMover installation as part of his <a href="https://en.wikipedia.org/wiki/EPCOT_(concept)">Experimental Prototype Community of Tomorrow</a>, or EPCOT—a new and futuristic city to be created from scratch at his planned Disney World Resort in Florida.</p>
<p>In October 1966, Walt recorded <a href="https://sites.google.com/site/theoriginalepcot/film-transcript">a short film</a> pitching his “Florida Project” to industrialists and legislators, including a detailed description of EPCOT’s transportation system. In this new city, cars and trucks were to be pushed underground, with the community’s twenty thousand residents instead traveling by WEDway and monorail to work, play, and socialize. The concept images below from Walt’s EPCOT film give an idea of just how much imagination the creative brains at WED Enterprises applied, under Walt’s careful guidance, to everyday living challenges.</p>
<figure data-shortcode="caption" id="attachment_1600" aria-describedby="caption-attachment-1600"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/epcot_0_18_23_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/epcot_0_18_23.jpg?w=1000" alt="epcot_0_18_23" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/epcot_0_18_23.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/epcot_0_18_23.jpg?w=150&amp;h=114 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/epcot_0_18_23.jpg?w=300&amp;h=228 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1600">EPCOT’s transportation was planned on a radial system, as this schematic from Walt’s EPCOT film demonstrates. City residents use a series of PeopleMover systems (shown here as light blue spokes) to travel from their homes on the outskirts of the city to the central transport hub. Should they need to travel to other parts of Disney World, they then transfer to a high-speed monorail system (shown here in red).</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1601" aria-describedby="caption-attachment-1601"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/epcot_0_20_01_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/epcot_0_20_01.jpg?w=1000" alt="epcot_0_20_01" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/epcot_0_20_01.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/epcot_0_20_01.jpg?w=150&amp;h=114 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/epcot_0_20_01.jpg?w=300&amp;h=228 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1601">Concept art showing one half of EPCOT’s main transportation lobby. The longer-distance monorail service (right) runs through the center of the lobby, with shorter-distance WEDway PeopleMover services departing from the edges of the lobby (left). Cars and trucks are pushed underground into lower levels of the city’s transportation network (bottom).</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1602" aria-describedby="caption-attachment-1602"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/epcot_0_15_58_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/epcot_0_15_58.jpg?w=1000" alt="epcot_0_15_58" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/epcot_0_15_58.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/epcot_0_15_58.jpg?w=150&amp;h=114 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/epcot_0_15_58.jpg?w=300&amp;h=228 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1602">Concept art from the EPCOT film, showing a PeopleMover and Monorail passing through the city’s central shopping district.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1603" aria-describedby="caption-attachment-1603"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/epcot_0_20_57_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/epcot_0_20_57.jpg?w=1000" alt="epcot_0_20_57" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/epcot_0_20_57.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/epcot_0_20_57.jpg?w=150&amp;h=114 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/epcot_0_20_57.jpg?w=300&amp;h=228 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1603">In Walt’s EPCOT proposal, the city’s WEDway PeopleMovers (shown here as light blue spokes) transport residents through the city’s greenbelt, past sports facilities and schools…</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1604" aria-describedby="caption-attachment-1604"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/epcot_0_21_33_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/epcot_0_21_33.jpg?w=1000" alt="epcot_0_21_33.jpg" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/epcot_0_21_33.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/epcot_0_21_33.jpg?w=150&amp;h=114 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/epcot_0_21_33.jpg?w=300&amp;h=228 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1604">…to residential areas in the city’s suburban districts, complete with footpaths and children’s play areas.</figcaption></figure>
<p>Tragically, Walt Disney died less than two months after his EPCOT introduction was filmed, passing away before the pitch was screened and before New Tomorrowland opened to the public. His ambitious vision of a prototype community did not become a reality, but its name lives on in the Epcot theme park (formerly “EPCOT Center”) at Walt Disney World in Florida—although the eventual EPCOT park became more of a permanent World’s Fair than a real-life city of the future. The WEDway PeopleMover did not realize its potential, either: The Disneyland attraction closed in 1995, to be replaced by the faster (but short-lived) <a href="https://en.wikipedia.org/wiki/Rocket_Rods">Rocket Rods</a> ride, which itself closed in 2001.</p>
<p>Disneyland park-goers can still see the PeopleMover’s abandoned tracks snaking through Tomorrowland, displaying curved, arched supports that Santiago Calatrava would surely approve of. (Thankfully, a PeopleMover can still be experienced at the <a href="https://en.wikipedia.org/wiki/Magic_Kingdom">Magic Kingdom park</a> at the Walt Disney World Resort in Florida, where the <a href="https://en.wikipedia.org/wiki/Tomorrowland_Transit_Authority_PeopleMover">Tomorrowland Transit Authority PeopleMover</a> continues to provide a leisurely tour of nearby attractions.)</p>
<figure data-shortcode="caption" id="attachment_1605" aria-describedby="caption-attachment-1605"><a href="https://flic.kr/p/7992RM"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_peoplemover_tracks_underside.jpg?w=1000" alt="walle_peoplemover_tracks_underside" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_peoplemover_tracks_underside.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_peoplemover_tracks_underside.jpg?w=150&amp;h=113 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_peoplemover_tracks_underside.jpg?w=300&amp;h=225 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1605">An overhead section of the now-disused PeopleMover track in Tomorrowland, seen in 2009.&nbsp;<a href="https://flic.kr/p/7992RM">Photograph by Loren Javier, CC BY-ND 2.0</a>.</figcaption></figure>
<p>Of course, the PeopleMover also lives on via the <em>Axiom</em>, whose reimagining of the concept is almost a microcosm of Walt’s vision for EPCOT. Aboard the <em>Axiom</em>, it’s a PeopleMover (not a monorail) that fulfills the role of high-speed arterial transport, with individual BnL hover chairs completing the “final mile” of the journey via preset illuminated paths (blue for humans, white for robots, red for stewardbots). It may not match the scale of Disney’s EPCOT dream, but it’s nonetheless fitting that Walt’s vision of a transportational future made the trip into space.</p>
<figure data-shortcode="caption" id="attachment_1606" aria-describedby="caption-attachment-1606"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_19_33_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_19_33.jpg?w=1000" alt="walle_1_19_33" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_19_33.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_19_33.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_19_33.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1606">Illuminated paths provide hover-chair routes throughout the <em>Axiom</em>…</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1607" aria-describedby="caption-attachment-1607"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_19_37_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_19_37.jpg?w=1000" alt="walle_1_19_37.jpg" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_19_37.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_19_37.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_19_37.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1607">…defining a “final mile” pathway to each passenger’s room. Here, the normally blue “human” pathways have turned bright green to indicate that plant life has been found and the <em>Axiom</em> is preparing to return to Earth.</figcaption></figure>
<p>During WALL·E’s tour of the passenger decks, we discover that the <em>Axiom</em>’s computer is voiced by none other than <em>Alien</em>’s Ellen Ripley. Casting <a href="https://en.wikipedia.org/wiki/Sigourney_Weaver">Sigourney Weaver</a> as the disembodied voice of a space-based computer is clearly ironic, especially given her experience with such voices in <em>Alien</em> and <em>Aliens</em>. <em>WALL·E</em> ups the irony by having Weaver narrate not one but two scenes that would feel all too familiar to her xenomorph-hunting counterpart, triggering bonus space-peril associations for <em>Alien</em> fans. (Weaver also plays a disembodied voice in Andrew Stanton’s <a href="https://en.wikipedia.org/wiki/Finding_Dory"><em>Finding Dory</em></a>, aping her narration of nature documentaries.)</p>
<figure data-shortcode="caption" id="attachment_1608" aria-describedby="caption-attachment-1608"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_58_17_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_58_17.jpg?w=1000" alt="walle_0_58_17" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_58_17.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_58_17.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_58_17.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1608">“Twenty seconds to self-destruct,” says Ripley, as WALL·E tries in vain to stop his LifePod’s self-destruct sequence.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1609" aria-describedby="caption-attachment-1609"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/alien_1_42_54_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/alien_1_42_54.jpg?w=1000" alt="alien_1_42_54" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/alien_1_42_54.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/alien_1_42_54.jpg?w=150&amp;h=64 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/alien_1_42_54.jpg?w=300&amp;h=128 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1609">Ripley knows what she’s talking about—she was counted down to self-destruction herself in <em>Alien</em>.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1610" aria-describedby="caption-attachment-1610"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_13_25_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_13_25.jpg?w=1000" alt="walle_1_13_25" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_13_25.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_13_25.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_13_25.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1610">“Activating airlock disposal,” says Ripley, as EVE and WALL·E try to avoid being sucked out of an industrial-sized airlock…</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1611" aria-describedby="caption-attachment-1611"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_12_54_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_12_54.jpg?w=1000" alt="walle_1_12_54" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_12_54.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_12_54.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_12_54.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1611">…with spinning red lights around the sides.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1612" aria-describedby="caption-attachment-1612"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/aliens_2_11_46_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/aliens_2_11_46.jpg?w=1000" alt="aliens_2_11_46" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/aliens_2_11_46.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/aliens_2_11_46.jpg?w=150&amp;h=81 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/aliens_2_11_46.jpg?w=300&amp;h=162 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1612">Ripley knows what she’s talking about—she narrowly avoided airlock doom herself in <em>Aliens</em>.</figcaption></figure>
<p><em>Alien</em> and <em>Aliens</em> are not the only sci-fi movies to get a nod from <em>WALL·E</em>. On the <em>Axiom</em> bridge, we meet AUTO, the ship’s autopilot robot. It might be hard to believe just by looking at him, but AUTO is actually an Evil Space-Based Computer. His design is clearly influenced by a certain other ESBC—that central red eye is a direct reference to <em>2001: A Space Odyssey</em>’s HAL, giving an immediate signal that this robot is not to be trusted.</p>
<figure data-shortcode="caption" id="attachment_1613" aria-describedby="caption-attachment-1613"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_43_41_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_43_41.jpg?w=1000" alt="walle_0_43_41" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_43_41.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_43_41.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_43_41.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1613">AUTO, the <em>Axiom</em> autopilot. Aspects of his design may be familiar to those of you who have read the <a href="https://typesetinthefuture.com/2014/01/31/2001-a-space-odyssey/"><em>2001</em> article</a>.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1614" aria-describedby="caption-attachment-1614"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/2001_1_01_53_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/2001_1_01_53.jpg?w=1000" alt="2001_1_01_53" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/2001_1_01_53.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/2001_1_01_53.jpg?w=150&amp;h=68 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/2001_1_01_53.jpg?w=300&amp;h=135 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1614">HAL, the <em>Discovery One</em> autopilot. Aspects of his design may be familiar to those of you who are reading this <em>WALL·E</em> article.</figcaption></figure>
<p>AUTO’s physical similarity to HAL gives him a practical similarity, too. On the rare occasions we see the world from AUTO’s vantage point, we get an extreme fish-eye view of the surrounding area, just as we did for HAL in <em>2001</em>. WALL·E combines HAL’s fish-eye view with <em>The Terminator</em>’s red HUD hue, making AUTO’s evil intent doubly clear to any discerning fan of sci-fi.</p>
<figure data-shortcode="caption" id="attachment_1615" aria-describedby="caption-attachment-1615"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_07_18_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_07_18.jpg?w=1000" alt="walle_1_07_18" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_07_18.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_07_18.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_07_18.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1615">AUTO’s fish-eye view, from <em>WALL·E</em>.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1616" aria-describedby="caption-attachment-1616"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/2001_1_08_35_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/2001_1_08_35.jpg?w=1000" alt="2001_1_08_35" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/2001_1_08_35.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/2001_1_08_35.jpg?w=150&amp;h=68 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/2001_1_08_35.jpg?w=300&amp;h=135 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1616">HAL’s fish-eye view, from <em>2001: A Space Odyssey</em>.</figcaption></figure>
<p>AUTO and HAL belong to a long-standing tradition of sci-fi automata whose glowing red eye(s) give away their evil nature. They really are everywhere in sci-fi movies—from the Model 101 in <em><a href="https://en.wikipedia.org/wiki/The_Terminator">The Terminator</a></em>, via the replicants in <em><a href="https://en.wikipedia.org/wiki/Blade_Runner">Blade Runner</a></em>, to the evil wriggly thing inserted into Neo’s belly button in <a href="https://en.wikipedia.org/wiki/The_Matrix"><em>The Matrix</em></a>.</p>
<figure data-shortcode="caption" id="attachment_1617" aria-describedby="caption-attachment-1617"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/terminator_1_31_21_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/terminator_1_31_21.jpg?w=1000" alt="terminator_1_31_21" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/terminator_1_31_21.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/terminator_1_31_21.jpg?w=150&amp;h=81 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/terminator_1_31_21.jpg?w=300&amp;h=162 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1617">After having all of its skin burnt off in a fire, <em>The Terminator</em>’s T-800 displays some impressive evil red eyes.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1618" aria-describedby="caption-attachment-1618"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/matrix_0_21_17_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/matrix_0_21_17.jpg?w=1000" alt="matrix_0_21_17" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/matrix_0_21_17.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/matrix_0_21_17.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/matrix_0_21_17.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1618">The evil wriggly thing that works its way into Neo’s belly in <em>The Matrix</em> has a trademark evil red eye.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1619" aria-describedby="caption-attachment-1619"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/matrix_2_01_19_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/matrix_2_01_19.jpg?w=1000" alt="matrix_2_01_19" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/matrix_2_01_19.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/matrix_2_01_19.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/matrix_2_01_19.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1619">The sentinels in <em>The Matrix</em> take evil red eyes to a whole new level.</figcaption></figure>
<p>That red glow has its benefits, however. You can always tell when an evil robot has been finally defeated from the fact that its red eye(s) slowly fade to black. <em>The Terminator</em>’s T-800, <em>The Matrix</em>’s wriggly thing, and <em>WALL·E</em>’s AUTO all follow this trope when deactivated.</p>
<figure data-shortcode="caption" id="attachment_1620" aria-describedby="caption-attachment-1620"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/red_eye_fade_the_terminator_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/red_eye_fade_the_terminator.jpg?w=1000" alt="red_eye_fade_the_terminator" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/red_eye_fade_the_terminator.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/red_eye_fade_the_terminator.jpg?w=136&amp;h=150 136w, https://typesetinthefuture.com/wp-content/uploads/2018/08/red_eye_fade_the_terminator.jpg?w=273&amp;h=300 273w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1620">As The Terminator’s T-800 is squished beneath the sheets of an industrial steel press,&nbsp;its evil red eye fades slowly to black.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1621" aria-describedby="caption-attachment-1621"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/red_eye_fade_the_matrix_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/red_eye_fade_the_matrix.jpg?w=1000" alt="red_eye_fade_the_matrix" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/red_eye_fade_the_matrix.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/red_eye_fade_the_matrix.jpg?w=150&amp;h=127 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/red_eye_fade_the_matrix.jpg?w=300&amp;h=253 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1621">After removing the wriggly thing from Neo’s belly, Trinity discards it in the rain,&nbsp;where its evil red eye fades slowly to black.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1622" aria-describedby="caption-attachment-1622"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/red_eye_fade_walle_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/red_eye_fade_walle.jpg?w=1000" alt="red_eye_fade_walle" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/red_eye_fade_walle.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/red_eye_fade_walle.jpg?w=150&amp;h=128 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/red_eye_fade_walle.jpg?w=300&amp;h=256 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1622">After switching the <em>Axiom</em> from autopilot to manual control,&nbsp;AUTO’s evil red eye fades slowly to black.</figcaption></figure>
<p>AUTO may look like the movie’s bad guy, but his actions are simply an example of artificial intelligence following its programming too literally. To understand his motives, we must remember that BnL’s original plan was for its star liners to return to Earth as soon as an EVE probe found proof that life was once more sustainable. Five years after their departure, however, BnL autopilots were sent a directive by CEO Shelby Forthright telling them to keep their craft in space indefinitely, because the cleanup process on Earth was not going to succeed. Six hundred and ninety-five years later, with no subsequent instructions to the contrary, AUTO is simply following this command to the letter, blocking any and all attempts to return to Earth.</p>
<p>In this regard, AUTO is eerily similar to <em>2001</em>’s HAL, whose murderous tendencies aboard the <em>Discovery</em> were similarly driven by an inability to reconcile a contradiction in his programming. In the movie’s sequel, <em><a href="https://en.wikipedia.org/wiki/2010:_The_Year_We_Make_Contact">2010: The Year We Make Contact</a></em>, we learn that the basic purpose of HAL’s design was “the accurate processing of information without distortion or concealment.” We also discover that HAL was instructed (via Directive NSD 342/23) to lie to Dave and Frank about the real reason for the <em>Discovery</em>’s mission. After lip-reading that they planned to disconnect him, HAL determined that the only logical way for him to both keep processing and avoid lying was for Dave and Frank to die.</p>
<p>AUTO’s own instruction is Directive A113, whose numbering may sound familiar to Pixar fans. “<a href="https://en.wikipedia.org/wiki/A113">A113</a>” appears in every Pixar film, from a family license plate in <em>Toy Story</em> to an underwater camera model in <em>Finding Nemo</em>. (Indeed, it’s even in <em><a href="https://en.wikipedia.org/wiki/Brave_(2012_film)">Brave</a></em>, where the roman numerals ACXIII appear carved just above the front door of a witch’s hut.) The reason for its repeated inclusion is that room A1-13 was the classroom for the <a href="https://filmvideo.calarts.edu/programs/character-animation">Character Animation Program</a> at the <a href="https://en.wikipedia.org/wiki/California_Institute_of_the_Arts">California Institute of the Arts</a>, where Pixar alumni <a href="https://en.wikipedia.org/wiki/John_Lasseter">John Lasseter</a>, <a href="https://en.wikipedia.org/wiki/Pete_Docter">Pete Docter</a>, and Andrew Stanton studied. (This explains why it’s also the number on the door of Riley’s classroom in <a href="https://en.wikipedia.org/wiki/Inside_Out_(2015_film)"><em>Inside Out</em></a>, and on the Scaring 101 classroom door in <a href="https://en.wikipedia.org/wiki/Monsters_University"><em>Monsters University</em></a>.) <em>WALL·E</em> may be its highest-profile outing, but it’s there in every Pixar movie if you keep your eyes peeled.</p>
<figure data-shortcode="caption" id="attachment_1623" aria-describedby="caption-attachment-1623"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_07_21_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_07_21.jpg?w=1000" alt="walle_1_07_21" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_07_21.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_07_21.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_07_21.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1623">AUTO triggers Directive A113.</figcaption></figure>
<p>The majority of <em>WALL·E</em>’s robots are voiced by <a href="https://en.wikipedia.org/wiki/Ben_Burtt">Ben Burtt</a>, the Academy Award-winning sound designer and creator of R2D2’s bleeps. AUTO’s voice, however, is provided by <a href="https://en.wikipedia.org/wiki/PlainTalk">MacInTalk</a>, a speech synthesis technology <a href="https://www.youtube.com/watch?v=2B-XwPjn9YY&amp;feature=youtu.be&amp;t=3m10s">first used to announce the Apple Macintosh computer in January 1984</a>. (You may also recognize MacInTalk as the lead vocalist on <a href="https://en.wikipedia.org/wiki/Radiohead">Radiohead</a>’s “Fitter Happier,” from 1997’s <a href="https://en.wikipedia.org/wiki/OK_Computer"><em>OK Computer</em></a> album.)</p>
<p>MacInTalk’s inclusion in <em>WALL·E</em> makes it one of only two Apple voice synthesis technologies to star in a feature film; the other is <a href="https://en.wikipedia.org/wiki/Siri">Siri</a>, who provides the voice for ’Puter, Batman’s high-tech assistant in <em><a href="https://en.wikipedia.org/wiki/The_Lego_Batman_Movie">The LEGO Batman Movie</a></em>.</p>
<figure data-shortcode="caption" id="attachment_1624" aria-describedby="caption-attachment-1624"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/lego_batman_0_08_22_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/lego_batman_0_08_22.jpg?w=1000" alt="lego_batman_0_08_22" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/lego_batman_0_08_22.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/lego_batman_0_08_22.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/lego_batman_0_08_22.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1624">“‘Puter”, Batman’s Siri-based computer assistant, from <em>The LEGO Batman Movie</em>. (The Batmobile’s interfaces are, perhaps inevitably, set in Eurostile Bold.)</figcaption></figure>
<p>Despite the technology’s age, I’m happy to report that MacInTalk voices still ship with macOS today. If you’d like to turn your Mac into an Evil Space-Based Computer, simply open the System Preferences application, select Accessibility and then Speech, and enable the “Ralph” system voice.</p>
<p>In addition to AUTO, there are two more nods to <em>2001: A Space Odyssey</em> in <em>WALL·E</em>, both of which take advantage of preexisting associations for dramatic or comedic effect. The first is WALL·E’s brief escapade in a LifePod, the design of which seems clearly inspired by <em>2001</em>’s EVA pods. That iconic ball-like shape immediately triggers an association with interstellar peril, which WALL·E soon discovers is entirely justified.</p>
<figure data-shortcode="caption" id="attachment_1625" aria-describedby="caption-attachment-1625"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/2001_1_14_18_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/2001_1_14_18.jpg?w=1000" alt="2001_1_14_18" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/2001_1_14_18.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/2001_1_14_18.jpg?w=150&amp;h=68 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/2001_1_14_18.jpg?w=300&amp;h=135 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1625">One of the <em>Discovery</em>’s EVA pods is activated in <em>2001: A Space Odyssey</em>.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1626" aria-describedby="caption-attachment-1626"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_56_42_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_56_42.jpg?w=1000" alt="walle_0_56_42.jpg" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_56_42.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_56_42.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_56_42.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1626">One of the <em>Axiom</em>’s LifePods is activated in <em>WALL·E</em>.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1627" aria-describedby="caption-attachment-1627"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/2001_1_15_38_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/2001_1_15_38.jpg?w=1000" alt="2001_1_15_38" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/2001_1_15_38.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/2001_1_15_38.jpg?w=150&amp;h=68 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/2001_1_15_38.jpg?w=300&amp;h=135 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1627">The pod design in <em>2001</em> has many similarities with its <em>WALL·E</em> counterpart…</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1628" aria-describedby="caption-attachment-1628"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_58_24_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_58_24.jpg?w=1000" alt="walle_0_58_24" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_58_24.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_58_24.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_0_58_24.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1628">…though it does not (as far as we know) include an optional satellite dish, parachute, flare set, or inflatable life raft.</figcaption></figure>
<p>The second <em>2001</em> reference is a knowing usage of <a href="https://en.wikipedia.org/wiki/Richard_Strauss">Richard Strauss</a>’s <a href="https://en.wikipedia.org/wiki/Also_sprach_Zarathustra_(Strauss)"><em>Also sprach Zarathustra</em></a>, when Captain McCrea becomes the first human to stand up and walk in possibly hundreds of years. It’s an appropriate enough use of the music—<em>2001</em>’s monoliths oversee (and supposedly trigger) several leaps in mankind’s evolution, so it’s entirely valid to hear those famous chords when the captain makes his first steps (even though this is technically a regression, not an evolution).</p>
<figure data-shortcode="caption" id="attachment_1629" aria-describedby="caption-attachment-1629"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_22_09_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_22_09.jpg?w=1000" alt="walle_1_22_09" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_22_09.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_22_09.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_22_09.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1629">Determined to tackle the mutinous AUTO, Captain McCrea steadies himself…</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1630" aria-describedby="caption-attachment-1630"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_22_14_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_22_14.jpg?w=1000" alt="walle_1_22_14" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_22_14.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_22_14.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_22_14.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1630">…and drags himself to his feet, to the tune of <em>Also sprach Zarathustra</em>.</figcaption></figure>
<p>Of course, <em>WALL·E</em> is not alone in riffing on Strauss’s classic melody. It is similarly parodied in <a href="https://en.wikipedia.org/wiki/Charlie_and_the_Chocolate_Factory_(film)"><em>Charlie and the Chocolate Factory</em></a> (as a <em>2001</em> monolith turns into a bar of chocolate) and <a href="https://en.wikipedia.org/wiki/Zoolander"><em>Zoolander</em></a> (as Hansel considers smashing Mugatu’s iMac with a nearby bone). If that’s not enough, it’s also in Pixar’s <em>Toy Story 2</em> and <a href="https://en.wikipedia.org/wiki/Cars_3"><em>Cars 3</em></a>, plus other animated movies including <a href="https://en.wikipedia.org/wiki/Kung_Fu_Panda_3"><em>Kung Fu Panda 3</em></a>, <a href="https://en.wikipedia.org/wiki/The_Pirates!_In_an_Adventure_with_Scientists!"><em>The Pirates! In an Adventure with Scientists!</em></a>, and <a href="https://en.wikipedia.org/wiki/The_Simpsons_Movie"><em>The Simpsons Movie</em></a>. On the live-action front, it’s in <em><a href="https://en.wikipedia.org/wiki/Man_on_the_Moon_(film)">Man on the Moon</a></em>, <a href="https://en.wikipedia.org/wiki/Catch-22_(film)"><em>Catch-22</em></a>, <a href="https://en.wikipedia.org/wiki/Night_at_the_Museum:_Secret_of_the_Tomb"><em>Night at the Museum: Secret of the Tomb</em></a>, <a href="https://en.wikipedia.org/wiki/Clueless_(film)"><em>Clueless</em></a>, <a href="https://en.wikipedia.org/wiki/Turner_%26_Hooch"><em>Turner &amp; Hooch</em></a>, and <a href="https://en.wikipedia.org/wiki/Harold_%26_Kumar_Go_to_White_Castle"><em>Harold &amp; Kumar Go to White Castle</em></a>, to mention just a few.</p>
<figure data-shortcode="caption" id="attachment_1631" aria-describedby="caption-attachment-1631"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/charlie_1_26_45_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/charlie_1_26_45.jpg?w=1000" alt="charlie_1_26_45" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/charlie_1_26_45.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/charlie_1_26_45.jpg?w=150&amp;h=85 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/charlie_1_26_45.jpg?w=300&amp;h=169 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1631">In 2005’s <em>Charlie and the Chocolate Factory</em>, Willy Wonka transports a bar of chocolate via television to the tune of <em>Also sprach Zarathustra</em>…</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1632" aria-describedby="caption-attachment-1632"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/charlie_1_26_48_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/charlie_1_26_48.jpg?w=1000" alt="charlie_1_26_48" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/charlie_1_26_48.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/charlie_1_26_48.jpg?w=150&amp;h=85 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/charlie_1_26_48.jpg?w=300&amp;h=169 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1632">…transforming <em>2001</em>’s famous monolith into a bar of Wonka Nutty Crunch Surprise.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1633" aria-describedby="caption-attachment-1633"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/zoolander_1_09_12_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/zoolander_1_09_12.jpg?w=1000" alt="zoolander_1_09_12" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/zoolander_1_09_12.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/zoolander_1_09_12.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/zoolander_1_09_12.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1633">In 2001’s <em>Zoolander</em>, non-evolved male models Derek Zoolander and Hansel smack an iMac chimpanzee-style to the tune of <em>Also sprach Zarathustra</em>…</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1635" aria-describedby="caption-attachment-1635"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/zoolander_1_09_21_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/zoolander_1_09_21.jpg?w=1000" alt="zoolander_1_09_21" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/zoolander_1_09_21.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/zoolander_1_09_21.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/zoolander_1_09_21.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1635">…before Hansel grabs a handy bone to use as a tool.</figcaption></figure>
<p>Despite AUTO’s best efforts, McCrea manages to switch him to MANUAL and sets the <em>Axiom</em> on a hyperjump trajectory back to Earth. The hyperjump looks exactly like you’d expect, which is exactly like the USS <em>Enterprise</em> engaging warp drive in <a href="https://en.wikipedia.org/wiki/Star_Trek:_The_Motion_Picture"><em>Star Trek: The Motion Picture</em></a>.</p>
<figure data-shortcode="caption" id="attachment_1636" aria-describedby="caption-attachment-1636"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_hyperjump_walle_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_hyperjump_walle.jpg?w=1000" alt="walle_hyperjump_walle" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_hyperjump_walle.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_hyperjump_walle.jpg?w=114&amp;h=150 114w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_hyperjump_walle.jpg?w=228&amp;h=300 228w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1636">The <em>Axiom</em> makes a hyperjump toward Earth in <em>WALL·E</em>.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1637" aria-describedby="caption-attachment-1637"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_hyperjump_startrek_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_hyperjump_startrek.jpg?w=1000" alt="walle_hyperjump_startrek" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_hyperjump_startrek.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_hyperjump_startrek.jpg?w=114&amp;h=150 114w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_hyperjump_startrek.jpg?w=228&amp;h=300 228w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1637">The <em>Enterprise</em> engages warp drive toward “thataway” in <em>Star Trek: The Motion Picture</em>.</figcaption></figure>
<p>Once again, <em>WALL·E</em> is sneakily using prior sci-fi art as a shortcut, re-creating familiar effects so that the <em>Axiom</em>’s quick journey home can be explained without exposition. (It might also account for why everyone aboard the <em>Axiom</em> experiences a brief stint of <em>The Motion Picture</em>’s wormhole effect during the jump.)</p>
<figure data-shortcode="caption" id="attachment_1639" aria-describedby="caption-attachment-1639"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/startrek_0_40_28_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/startrek_0_40_28.jpg?w=1000" alt="startrek_0_40_28" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/startrek_0_40_28.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/startrek_0_40_28.jpg?w=150&amp;h=64 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/startrek_0_40_28.jpg?w=300&amp;h=128 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1639">The <em>Enterprise</em> bridge goes all “wormhole effect” when it engages warp speed while still within the solar system.</figcaption></figure>
<figure data-shortcode="caption" id="attachment_1640" aria-describedby="caption-attachment-1640"><a href="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_24_09_full.jpg"><img loading="lazy" src="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_24_09.jpg?w=1000" alt="walle_1_24_09" srcset="https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_24_09.jpg 560w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_24_09.jpg?w=150&amp;h=62 150w, https://typesetinthefuture.com/wp-content/uploads/2018/08/walle_1_24_09.jpg?w=300&amp;h=125 300w" sizes="(max-width: 560px) 100vw, 560px"></a><figcaption id="caption-attachment-1640">EVE and WALL·E go all “wormhole effect” when the <em>Axiom</em> hyperjumps back to Earth.</figcaption></figure>
<p>As these homages show, <em>WALL·E</em> is not afraid to borrow from its predecessors to gain some free sci-fi association. Indeed, such references are celebrated and elevated, drawing on the production team’s clear fondness for vintage sci-fi to create a movie that is both a love letter to the classics and a worthy addition to the list. <em>WALL·E</em> capitalizes on our existing associations with the future to communicate complex plot points and motives with minimal dialogue and text. It is, to my mind, Pixar’s most realistic vision of an internally consistent world, despite the polar opposites of its Earth- and space-based environments. It’s political and satirical, representing utopia and dystopia with enough humor to poke fun at the downsides of both. In short, <em>WALL·E</em> envisages a future that could so easily be bleak and pessimistic—but is instead inspired by the naïveté of its inhuman heroes to re-create the optimism that took man into space in the first place.</p>
<hr>
<p><em>Wow! That was good, wasn’t it? What an amazing article! So amazing, in fact, that you probably want to impulse-buy the </em><a href="https://typesetinthefuture.com/book/">Typeset in the Future</a><em><a href="https://typesetinthefuture.com/book/"> book</a> it comes from, right this very second. Here are some convenient links to buy it from <a href="https://www.amazon.com/gp/product/1419727141/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=titf0f-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1419727141&amp;linkId=7cfbe17900870504a3a13c4e389c8456">Amazon</a> or <a href="https://www.barnesandnoble.com/w/typeset-in-the-future-dave-addey/1127947277?ean=9781419727146">Barnes and Noble</a>, or you can head down to your local bookstore (which it is much harder for me to link to) when the book is released on December 11 2018.</em></p>
<p><em>The book also includes an interview with Pixar designers Ralph Eggleston and Craig Foster about the making of </em>WALL·E<em>, plus six more equally amazing movie studies, alongside interviews with Paul Verhoeven </em>(Total Recall)<em> and Mike Okuda </em>(Star Trek)<em>. <a href="https://typesetinthefuture.com/book/">You can read more about it here if for some reason you’re still not convinced</a>.</em></p>
<p>– <a href="https://twitter.com/daveaddey">Dave Addey</a></p>
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Majority of sites and apps use dark patterns in the marketing of subscriptions (209 pts)]]></title>
            <link>https://icpen.org/news/1360</link>
            <guid>40934898</guid>
            <pubDate>Thu, 11 Jul 2024 09:23:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://icpen.org/news/1360">https://icpen.org/news/1360</a>, See on <a href="https://news.ycombinator.com/item?id=40934898">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span><span><span lang="EN-GB" xml:lang="EN-GB"><span>A global internet sweep that examined the websites and mobile apps of 642 traders has found that <strong>75,7% of them employed at least one dark pattern, and 66,8% of them employed two or more dark patterns</strong>.</span></span></span></span></p>

<p><span><span><span lang="EN-GB" xml:lang="EN-GB"><span>Dark patterns are defined as practices commonly found in online user interfaces and that steer, deceive, coerce, or manipulate consumers into making choices that often are not in their best interests. </span></span></span></span></p>

<p><span><span><span lang="EN-GB" xml:lang="EN-GB"><span>This year’s annual International Consumer Protection and Enforcement Network (ICPEN) Sweep took place between January 29 and February 2, 2024. It involved participants, or “sweepers,” from 27 consumer protection enforcement authorities in 26 countries around the world.</span></span></span></span></p>

<p><span><span><span lang="EN-GB" xml:lang="EN-GB"><span>For the first time, the ICPEN sweep was coordinated with the Global Privacy Enforcement Network (GPEN). GPEN is a network of over 80 privacy enforcement authorities, which aims to foster cross-border cooperation across privacy regulators and strengthen personal privacy protections in an increasingly global market. </span></span></span></span></p>

<p><span><span><span lang="EN-GB" xml:lang="EN-GB"><span>The collaboration recognizes the growing intersection between consumer protection and other regulatory spheres. In the case of deceptive design patterns, it was clear to both privacy and consumer protection sweepers that many websites and apps employ techniques that interfere with individuals’ ability to make choices that best protect their consumer or privacy rights.</span></span></span></span></p>

<p><span><span><span lang="EN-GB" xml:lang="EN-GB"><span>Sweepers evaluated the sites and apps based on six indicators identified by the Organisation for Economic Co-operation and Development (OECD), as being characteristic of dark commercial patterns&nbsp;<a href="#_ftn1"><span><span><span lang="EN-GB" xml:lang="EN-GB"><span><span>[1]</span></span></span></span></span></a>. </span></span></span></span></p>

<p><span><span><span lang="EN-GB" xml:lang="EN-GB"><span>The ICPEN report found that potential <strong>sneaking</strong> practices, such as the inability of the consumer to turn off auto-renewal of subscription service, and <strong>interface interference</strong>, for example making a subscription that is advantageous to the trader more prominent, were encountered especially frequent during the sweep. </span></span></span></span></p>

<p><span><span><span lang="EN-GB" xml:lang="EN-GB"><span>Both ICPEN and GPEN, who are working together to improve consumer and privacy protection for individuals around the world, published reports outlining their findings today. The ICPEN report can be found <a href="https://icpen.org/sites/default/files/2024-07/Public%20Report%20ICPEN%20Dark%20Patterns%20Sweep.pdf">here</a> and GPEN report can be found on their <a href="https://www.privacyenforcement.net/content/2024-gpen-sweep-deceptive-design-patterns">website</a>. </span></span></span></span></p>

<p><a href="https://icpen.org/sites/default/files/2024-07/Public%20Report%20ICPEN%20Dark%20Patterns%20Sweep.pdf"><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span><span>ICPEN Dark Patterns in Subscription Services Sweep </span></span></span></span></span></span></span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span><span>Public Report</span></span></span></span></span></span></span></a></p>

<hr><p><span><span><a href="#_ftnref1"><span><span><span lang="EN-GB" xml:lang="EN-GB"><span>[1]</span></span></span></span></a> Dark Commercial Patterns: OECD Digital Economy Papers” (OECD Publishing, October 26, 2022), 9-11, https://doi.org/10.1787/44f5e846-en.</span></span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A relativistic framework to establish coordinate time on the Moon and beyond (102 pts)]]></title>
            <link>https://arxiv.org/abs/2402.11150</link>
            <guid>40934608</guid>
            <pubDate>Thu, 11 Jul 2024 08:11:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2402.11150">https://arxiv.org/abs/2402.11150</a>, See on <a href="https://news.ycombinator.com/item?id=40934608">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2402.11150">View PDF</a>
    <a href="https://arxiv.org/html/2402.11150v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>As humanity aspires to explore the solar system and investigate distant worlds such as the Moon, Mars, and beyond, there is a growing need to establish and broaden coordinate time references that depend on the rate of standard clocks. According to Einstein's theory of relativity, the rate of a standard clock is influenced by the gravitational potential at the location of the clock and the relative motion of the clock. A coordinate time reference is established by a grid of synchronized clocks traceable to an ideal clock at a predetermined point in space. This allows for the comparison of local time variations of clocks due to gravitational and kinematic effects. We present a relativistic framework to introduce a coordinate time for the Moon. This framework also establishes a relationship between the coordinate times for the Moon and the Earth as determined by standard clocks located on the Earth's geoid and the Moon's equator. A clock near the Moon's equator ticks faster than one near the Earth's equator, accumulating an extra 56.02 microseconds per day over the duration of a lunar orbit. This formalism is then used to compute the clock rates at Earth-Moon Lagrange points. Accurate estimation of the rate differences of coordinate times across celestial bodies and their inter-comparisons using clocks onboard orbiters at relatively stable Lagrange points as time transfer links is crucial for establishing reliable communications infrastructure. This understanding also underpins precise navigation in cislunar space and on celestial bodies' surfaces, thus playing a pivotal role in ensuring the interoperability of various position, navigation, and timing (PNT) systems spanning from Earth to the Moon and to the farthest regions of the inner solar system.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Neil Ashby [<a href="https://arxiv.org/show-email/8d91eb14/2402.11150">view email</a>]      <br>    <strong>[v1]</strong>
        Sat, 17 Feb 2024 00:33:58 UTC (670 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Overengineered Resume with Zola, JSON Resume, Weasyprint, and Nix (2023) (145 pts)]]></title>
            <link>https://ktema.org/articles/the-overengineered-resume/</link>
            <guid>40934582</guid>
            <pubDate>Thu, 11 Jul 2024 08:06:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ktema.org/articles/the-overengineered-resume/">https://ktema.org/articles/the-overengineered-resume/</a>, See on <a href="https://news.ycombinator.com/item?id=40934582">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>










<p>Maintaining a resume is not the most interesting use of time. Naturally, when I needed to bring my own up to date, I decided to spend a great deal more time on it and overengineer the process.</p>
<p>I wanted a bunch of things that didn't necessarily fit together that well:</p>
<ul>
<li>A split between content and presentation, so that I could maintain my resume data separately from how it's rendered and swap out different rendered formats.</li>
<li>Version control. I wanted everything in Git, in text-based formats that I can diff or process with scripts.</li>
<li>Multiple output formats, at least in theory.
<ul>
<li>PDF rendering, since most career sites accept PDF uploads.</li>
<li>The option to publish my resume as a web page in the future.</li>
</ul>
</li>
<li>More visual flair and typesetting control than basic Google Docs-style resume templates. (I know applicant-tracking systems don't see visual flair, but it makes me happy).</li>
<li>Straightforward text embedding in PDFs to ensure those ATSs <em>do</em> see what they need.</li>
<li>Not to use LaTeX. It's been years since I used LaTeX in anger, and I'd prefer to stick with web technologies I know well.</li>
</ul>
<p>Here's where I ended up. (And <a href="https://ktema.org/Resume-David-Reed.pdf">here's</a> the actual output).</p>
<h2 id="building-a-data-driven-resume">Building a Data-Driven Resume</h2>
<p>I'm only aware of one standard for representing resume data: <a href="https://jsonresume.org/schema/">JSON Resume</a>. I always prefer to use standards where I can, although I'm disappointed there isn't a stronger ecosystem around this one. (And all the more that the major HR applications don't ingest it).</p>
<p>Because I wanted to avoid LaTeX, I decided to try templating my resume data into either Markdown or HTML and CSS and then rendering that content as a PDF. That also gave me the optionality I was looking for on output formats; if I wanted a resume web page, I could just publish the HTML with a different stylesheet.</p>
<p>I already use the static site generator <a href="https://www.getzola.org/">Zola</a> to build this website. Zola's Tera template engine is very similar to Jinja2, making it comfortable for me, and it's very fast.</p>
<p>The HTML-to-PDF tool space doesn't have a huge number of players in it and most of the players seem to be eccentric in some respect. I've played with this kind of rendering in the past and had some success with <a href="https://weasyprint.org/">Weasyprint</a>, so I brought it back for this effort.</p>
<p>Here's how these components come together into a data-to-PDF pipeline:</p>

<p><svg id="mermaid-svg" width="100%" xmlns="http://www.w3.org/2000/svg" style="max-width: 634.609375px;" viewBox="-8 -8 634.609375 176" role="graphics-document document" aria-roledescription="flowchart-v2" xmlns:xlink="http://www.w3.org/1999/xlink"><g><marker id="flowchart-pointEnd" viewBox="0 0 10 10" refX="10" refY="5" markerUnits="userSpaceOnUse" markerWidth="12" markerHeight="12" orient="auto"><path d="M 0 0 L 10 5 L 0 10 z" style="stroke-width: 1; stroke-dasharray: 1, 0;"></path></marker><marker id="flowchart-pointStart" viewBox="0 0 10 10" refX="0" refY="5" markerUnits="userSpaceOnUse" markerWidth="12" markerHeight="12" orient="auto"><path d="M 0 5 L 10 10 L 10 0 z" style="stroke-width: 1; stroke-dasharray: 1, 0;"></path></marker><marker id="flowchart-circleEnd" viewBox="0 0 10 10" refX="11" refY="5" markerUnits="userSpaceOnUse" markerWidth="11" markerHeight="11" orient="auto"><circle cx="5" cy="5" r="5" style="stroke-width: 1; stroke-dasharray: 1, 0;"></circle></marker><marker id="flowchart-circleStart" viewBox="0 0 10 10" refX="-1" refY="5" markerUnits="userSpaceOnUse" markerWidth="11" markerHeight="11" orient="auto"><circle cx="5" cy="5" r="5" style="stroke-width: 1; stroke-dasharray: 1, 0;"></circle></marker><marker id="flowchart-crossEnd" viewBox="0 0 11 11" refX="12" refY="5.2" markerUnits="userSpaceOnUse" markerWidth="11" markerHeight="11" orient="auto"><path d="M 1,1 l 9,9 M 10,1 l -9,9" style="stroke-width: 2; stroke-dasharray: 1, 0;"></path></marker><marker id="flowchart-crossStart" viewBox="0 0 11 11" refX="-1" refY="5.2" markerUnits="userSpaceOnUse" markerWidth="11" markerHeight="11" orient="auto"><path d="M 1,1 l 9,9 M 10,1 l -9,9" style="stroke-width: 2; stroke-dasharray: 1, 0;"></path></marker><g><g></g><g><path d="M148.546875,59L152.71354166666666,59C156.88020833333334,59,165.21354166666666,59,175.0462766921158,63.25119661576836C184.87901171756496,67.50239323153671,196.21114843512996,76.00478646307344,201.87721679391242,80.25598307884181L207.54328515269492,84.50717969461017" id="L-json_resume-zola-0" style="fill:none;" marker-end="url(#flowchart-pointEnd)"></path><path d="M132.5703125,143L139.39973958333334,143C146.22916666666666,143,159.88802083333334,143,172.38351627544913,138.9154700508983C184.87901171756496,134.8309401017966,196.21114843512996,126.66188020359323,201.87721679391242,122.57735025449153L207.54328515269492,118.49282030538983" id="L-zola_template-zola-0" style="fill:none;" marker-end="url(#flowchart-pointEnd)"></path><path d="M261.5625,101.5L265.6458333333333,101.41666666666667C269.7291666666667,101.33333333333333,277.8958333333333,101.16666666666667,286.1458333333333,101.08333333333333C294.3958333333333,101,302.7291666666667,101,306.8958333333333,101L311.0625,101" id="L-zola-html-0" style="fill:none;" marker-end="url(#flowchart-pointEnd)"></path><path d="M358.15625,17L363.5104166666667,17C368.8645833333333,17,379.5729166666667,17,393.0058283730159,21.25C406.43874007936506,25.5,422.5962301587301,34,430.6749751984127,38.25L438.75372023809524,42.5" id="L-css-weasyprint-0" style="fill:none;" marker-end="url(#flowchart-pointEnd)"></path><path d="M365.28125,101L369.4479166666667,101C373.6145833333333,101,381.9479166666667,101,394.1933283730159,96.91666666666667C406.43874007936506,92.83333333333333,422.5962301587301,84.66666666666667,430.6749751984127,80.58333333333333L438.75372023809524,76.5" id="L-html-weasyprint-0" style="fill:none;" marker-end="url(#flowchart-pointEnd)"></path><path d="M526.96875,59.5L531.0520833333334,59.416666666666664C535.1354166666666,59.333333333333336,543.3020833333334,59.166666666666664,551.5520833333334,59.083333333333336C559.8020833333334,59,568.1354166666666,59,572.3020833333334,59L576.46875,59" id="L-weasyprint-pdf-0" style="fill:none;" marker-end="url(#flowchart-pointEnd)"></path></g><g><g><g transform="translate(0, 0)"><foreignObject width="0" height="0"></foreignObject></g></g><g><g transform="translate(0, 0)"><foreignObject width="0" height="0"></foreignObject></g></g><g><g transform="translate(0, 0)"><foreignObject width="0" height="0"></foreignObject></g></g><g><g transform="translate(0, 0)"><foreignObject width="0" height="0"></foreignObject></g></g><g><g transform="translate(0, 0)"><foreignObject width="0" height="0"></foreignObject></g></g><g><g transform="translate(0, 0)"><foreignObject width="0" height="0"></foreignObject></g></g></g><g><g id="flowchart-zola-0" transform="translate(229.8046875, 101)"><polygon points="8.5,0 54.015625,0 62.515625,-17 54.015625,-34 8.5,-34 0,-17" transform="translate(-31.2578125,17)" style=""></polygon><g style="" transform="translate(-15.2578125, -9.5)"><rect></rect><foreignObject width="30.515625" height="19"><p><span>Zola</span></p></foreignObject></g></g><g id="flowchart-json_resume-1" transform="translate(74.2734375, 59)"><rect style="" rx="5" ry="5" x="-74.2734375" y="-17" width="148.546875" height="34"></rect><g style="" transform="translate(-66.7734375, -9.5)"><rect></rect><foreignObject width="133.546875" height="19"><p><span>JSON Resume Data</span></p></foreignObject></g></g><g id="flowchart-zola_template-3" transform="translate(74.2734375, 143)"><rect style="" rx="5" ry="5" x="-58.296875" y="-17" width="116.59375" height="34"></rect><g style="" transform="translate(-50.796875, -9.5)"><rect></rect><foreignObject width="101.59375" height="19"><p><span>Tera Template</span></p></foreignObject></g></g><g id="flowchart-css-5" transform="translate(338.171875, 17)"><rect style="" rx="5" ry="5" x="-19.984375" y="-17" width="39.96875" height="34"></rect><g style="" transform="translate(-12.484375, -9.5)"><rect></rect><foreignObject width="24.96875" height="19"><p><span>CSS</span></p></foreignObject></g></g><g id="flowchart-html-7" transform="translate(338.171875, 101)"><rect style="" rx="5" ry="5" x="-27.109375" y="-17" width="54.21875" height="34"></rect><g style="" transform="translate(-19.609375, -9.5)"><rect></rect><foreignObject width="39.21875" height="19"><p><span>HTML</span></p></foreignObject></g></g><g id="flowchart-pdf-8" transform="translate(597.5390625, 59)"><rect style="" rx="5" ry="5" x="-21.0703125" y="-17" width="42.140625" height="34"></rect><g style="" transform="translate(-13.5703125, -9.5)"><rect></rect><foreignObject width="27.140625" height="19"><p><span>PDF</span></p></foreignObject></g></g><g id="flowchart-weasyprint-9" transform="translate(470.875, 59)"><polygon points="8.5,0 102.6875,0 111.1875,-17 102.6875,-34 8.5,-34 0,-17" transform="translate(-55.59375,17)" style=""></polygon><g style="" transform="translate(-39.59375, -9.5)"><rect></rect><foreignObject width="79.1875" height="19"><p><span>Weasyprint</span></p></foreignObject></g></g></g></g></g></svg></p>
<p>Resume data is defined in a <code>resume.yaml</code> file, using the JSON Resume schema. I find it much more pleasant to author YAML than JSON, and Zola supports both formats just fine. Here's the opening of my resume in YAML:</p>
<pre data-lang="yaml"><code data-lang="yaml"><span><span><span>#</span> yaml-language-server: $schema=https://raw.githubusercontent.com/jsonresume/resume-schema/master/schema.json
</span></span><span><span><span>basics</span></span><span>:</span>
</span><span>  <span><span>name</span></span><span>:</span> <span>David Reed</span>
</span><span>  <span><span>label</span></span><span>:</span> <span>Technical architect, engineer, communicator</span>
</span><span>  <span><span>email</span></span><span>:</span> <span>david@ktema.org</span>
</span><span>  <span><span>url</span></span><span>:</span> <span>https://ktema.org</span>
</span><span>  <span><span>summary</span></span><span>:</span> <span>|</span>
</span><span><span>    I am a product-minded full-stack engineer and technical architect. I lead exceptional teams in building and scaling SaaS applications that shorten time-to-value for customers and maximize productivity for internal stakeholders. I've designed, shipped, and stewarded platforms that span CLI to cloud.
</span></span><span><span>
</span></span><span><span>    I'm passionate about delivering products that empower every role to do their most impactful work, from engineers to business users. I believe in async, distributed work and thrive in cross-functional teams. I strive to center compassion in everything I build.
</span></span></code></pre>
<p>The comment at the top instructs the YAML language server to use the JSON Resume schema to validate the data, which means I get hints in my editor where I've specified something invalid.</p>
<p>On the Zola side, I need a template. The template defines the structure of my resume - how the data is converted into a readable, formatted, attractive presentation. Here's the opening of the template I developed (note that it uses the Jinja2-like Tera template language):</p>
<pre data-lang="html"><code data-lang="html"><span>{% set resume = load_data(path="content/resume.yaml") %}
</span><span>
</span><span><span><span>&lt;!</span><span>DOCTYPE</span> <span>html</span><span>&gt;</span></span>
</span><span><span><span>&lt;</span><span>html</span> <span><span>lang</span><span>=</span><span><span>"</span>en<span>"</span></span></span><span>&gt;</span></span>
</span><span><span><span>&lt;</span><span>head</span><span>&gt;</span></span>
</span><span>    <span><span>&lt;</span><span>meta</span> <span><span>charset</span><span>=</span><span><span>"</span>utf-8<span>"</span></span></span> <span>/&gt;</span></span>
</span><span>    <span><span>&lt;</span><span>meta</span> <span><span>name</span><span>=</span><span><span>"</span>viewport<span>"</span></span></span> <span><span>content</span><span>=</span><span><span>"</span>width=device-width, initial-scale=1<span>"</span></span></span> <span>/&gt;</span></span>
</span><span>    <span><span>&lt;</span><span>title</span><span>&gt;</span></span>{{ resume.basics.name }}<span><span>&lt;/</span><span>title</span><span>&gt;</span></span>
</span><span><span><span>&lt;/</span><span>head</span><span>&gt;</span></span>
</span><span><span><span>&lt;</span><span>body</span><span>&gt;</span></span>
</span><span>    <span><span>&lt;</span></span><span><span>main</span><span>&gt;</span></span>
</span><span>        <span><span>&lt;</span><span>h1</span><span>&gt;</span></span>
</span><span>            {{ resume.basics.name }} <span><span>&lt;</span><span>span</span><span>&gt;</span></span>∙<span><span>&lt;/</span><span>span</span><span>&gt;</span></span> <span><span>&lt;</span><span>span</span><span>&gt;</span></span>{{ resume.basics.label }}<span><span>&lt;/</span><span>span</span><span>&gt;</span></span>
</span><span>        <span><span>&lt;/</span><span>h1</span><span>&gt;</span></span>
</span><span>        <span><span>&lt;</span><span>dl</span><span>&gt;</span></span>
</span><span>            {% if resume.basics.email %}
</span><span>            <span><span>&lt;</span><span>dt</span><span>&gt;</span></span>email<span><span>&lt;/</span><span>dt</span><span>&gt;</span></span>
</span><span>            <span><span>&lt;</span><span>dd</span><span>&gt;</span></span>
</span><span>                <span><span>&lt;</span><span>code</span><span>&gt;</span></span>{{ resume.basics.email }}<span><span>&lt;/</span><span>code</span><span>&gt;</span></span>
</span><span>            <span><span>&lt;/</span><span>dd</span><span>&gt;</span></span>
</span><span>            {% endif %}
</span><span>            {% if resume.basics.url %}
</span><span>            <span><span>&lt;</span><span>dt</span><span>&gt;</span></span>web<span><span>&lt;/</span><span>dt</span><span>&gt;</span></span>
</span><span>            <span><span>&lt;</span><span>dd</span><span>&gt;</span></span><span><span>&lt;</span><span>code</span><span>&gt;</span></span>{{ resume.basics.url }}<span><span>&lt;/</span><span>code</span><span>&gt;</span></span><span><span>&lt;/</span><span>dd</span><span>&gt;</span></span>
</span><span>            {% endif %}
</span><span>            {% if resume.basics.profiles %}
</span><span>            {% for network in resume.basics.profiles %}
</span><span>            <span><span>&lt;</span><span>dt</span><span>&gt;</span></span>{{ network.network | lower }}<span><span>&lt;/</span><span>dt</span><span>&gt;</span></span>
</span><span>            <span><span>&lt;</span><span>dd</span><span>&gt;</span></span><span><span>&lt;</span><span>code</span><span>&gt;</span></span>{{ network.username }}<span><span>&lt;/</span><span>code</span><span>&gt;</span></span><span><span>&lt;/</span><span>dd</span><span>&gt;</span></span>
</span><span>            {% endfor %}
</span><span>            {% endif %}
</span><span>        <span><span>&lt;/</span><span>dl</span><span>&gt;</span></span>
</span><span>
</span><span>        {{ resume.basics.summary | markdown | safe }}
</span><span>        <span><span>&lt;!--</span> Continues ...<span>--&gt;</span></span>
</span></code></pre>
<p>See the full template on <a href="https://github.com/davidmreed/resume-template/blob/main/templates/resume.html">GitHub</a>.</p>
<p>Taking my cues from <a href="https://simplecss.org/">Simple.css</a>, which I use for this site, I've prioritized using standard semantic HTML tags and using <a href="https://github.com/davidmreed/resume-template/blob/main/static/resume.css">CSS</a> to style them. </p>
<p>Note the critical Tera template tag at the head of the template:</p>
<pre data-lang="jinja2"><code data-lang="jinja2"><span><span><span>{%</span> <span>set</span> <span>resume</span> <span>=</span> <span>load_data</span><span>(</span><span>path</span><span>=</span><span>page</span><span>.</span><span>extra</span><span>.</span><span>resume_data</span><span>)</span> <span>%}</span></span>
</span></code></pre>
<p>This loads my resume data from <code>resume.yaml</code> into the variable <code>resume</code>, which the rest of my template then consumes to dynamically render my resume into HTML.</p>
<p>I've also decided to treat most of the resume content, as specified in YAML, as Markdown (<code>| markdown | safe</code>, in Tera). That means I can style my highlights for each position, which I apply to call out metrics and achievements in color.</p>
<p>I use only portions of the JSON Resume schema, and a couple of them I use in a way that's a bit questionable. (The story of standardized schemas, isn't it!) I've used the <code>awards</code> key in a fairly loose, unstructured way. I've also misused the <code>skill.keywords</code> key: when the word <code>"break"</code> is present as a keyword, the template starts a new sub-list of skills. (It doesn't otherwise use keywords for anything).</p>
<p>The last element stitching all of this together is a Markdown content file. Zola needs a content file in order to render the template into a page. In <a href="https://github.com/davidmreed/resume-template/blob/main/content/resume.md">this case</a>, the content file's empty save for metadata in its front matter, which defines the mapping between the data file and the template.</p>
<pre data-lang="toml"><code data-lang="toml"><span><span><span>title</span></span><span>=</span><span><span>"</span>Resume<span>"</span></span>
</span><span><span><span>template</span></span><span>=</span><span><span>"</span>resume.html<span>"</span></span>
</span><span><span>[</span><span><span>extra</span></span><span>]</span>
</span><span><span><span>resume_data</span></span><span>=</span><span><span>"</span>resume.yaml<span>"</span></span>
</span></code></pre>
<p>Because the template accepts the <code>resume_data</code> path as a parameter, I could in fact render multiple resumes by creating multiple <code>.md</code> files with different front matter.</p>
<p>At this point, I can render my resume. Once I have <code>zola</code> and <code>weasyprint</code> installed via my package manager of choice (for more on which see below), I do</p>
<pre data-lang="bash"><code data-lang="bash"><span><span><span>$</span></span><span> zola build</span>
</span><span><span><span>$</span></span><span> weasyprint public/resume/index.html Resume-David-Reed.pdf</span>
</span></code></pre>
<p>Voila - a PDF resume, beautifully rendered and ready for upload into an applicant-tracking system that could not care less about how snazzy it is.</p>
<p>That's nowhere near enough overengineering. Let's automate the whole shebang. (Although you can stop here and still have a nice data-driven resume, if automation is not your cup of tea).</p>
<h2 id="local-developer-experience">Local Developer Experience</h2>
<p>I already alluded to tooling setup, which is one of the key aspects of the developer experience I want. I don't want to worry about tools, activating virtual environments, launching a container, or any other fiddling.</p>
<p>I also don't ever want to run commands manually to synchronize some artifact A (here, a PDF) with some other artifact B (here, my data file and template). It should be magical. Magic is what software engineering is all about! Plus, a live preview function make the authoring experience so much better.</p>
<p>I've been exploring NixOS lately, so rather than building a <code>Dockerfile</code>, I set up my local environment using <code>nix-shell</code> and <code>direnv</code> following <a href="https://nixos.wiki/wiki/Development_environment_with_nix-shell">these instructions</a>. I created a <a href="https://github.com/davidmreed/resume-template/blob/main/shell.nix"><code>shell.nix</code></a> specifying my dependencies:</p>
<pre data-lang="nix"><code data-lang="nix"><span><span>{</span> <span>pkgs</span> <span>?</span> <span>import</span> <span>&lt;nixpkgs&gt;</span> <span>{</span><span>}</span> <span>}</span><span>:</span>
</span><span>  <span>pkgs</span><span>.</span><span>mkShell</span> <span>{</span>
</span><span>    <span>nativeBuildInputs</span> <span>=</span> <span>with</span> <span>pkgs</span><span>.</span><span>buildPackages</span>; <span>[</span> 
</span><span>      <span>zola</span> <span>just</span> <span>python311Packages</span><span>.</span><span>weasyprint</span> <span>inotify-tools</span> <span>yq</span>
</span><span>    <span>]</span><span>;</span>
</span><span><span>}</span>
</span></code></pre>
<p>and a <code>.envrc</code> containing</p>
<pre><code><span>use_nix
</span></code></pre>
<p>Then, after I <code>direnv allow</code>, every time I <code>cd</code> into my <code>resume</code> project, <code>weasyprint</code> and <code>zola</code> are magically available for me to use. (See the link above for full setup details).</p>
<p>I don't like memorizing commands, either, so I threw in a <a href="https://github.com/casey/just"><code>justfile</code></a> with some useful abstractions:</p>
<pre data-lang="make"><code data-lang="make"><span><span>filename</span> <span>:=</span></span> <span><span><span>"resume.yaml"</span></span>
</span><span>
</span><span><span><span>build</span></span><span>:</span>
<span></span><span></span></span><span><span></span><span>  <span><span><span>zola</span></span><span> build</span></span>
</span></span><span><span>
</span></span><span><span></span><span><span>pdf</span></span><span>:</span> <span><span>build</span></span><span>
</span></span><span><span></span><span>  <span><span><span>weasyprint</span></span><span> public/resume/index.html <span>\
</span></span></span></span></span><span><span><span><span>    Resume-<span><span>$(</span>cat resume.yaml | yq -r '.basics.name | split(" "<span>)</span></span></span> <span>|</span> <span><span>join</span></span><span>(<span><span>"</span>-<span>"</span></span></span><span></span>)<span><span><span><span>'</span>).pdf</span></span></span></span>
</span></span><span><span>
</span></span><span><span></span><span><span>render</span></span><span>:</span> <span><span>build pdf</span></span><span>
</span></span><span><span></span><span>  <span><span><span>xdg-open</span></span><span> Resume-<span><span>$(</span>cat resume.yaml | yq -r '.basics.name | split(" "<span>)</span></span></span> <span>|</span> <span><span>join</span></span><span>(<span><span>"</span>-<span>"</span></span></span><span></span>)<span><span><span><span>'</span>).pdf &amp;disown</span></span></span></span>
</span></span></code></pre>
<p>Here I use <code>yq</code> to dynamically generate the filename of my output PDF from the resume data, which mostly just means I don't hard-code my own name.</p>
<p>Now a <code>just pdf</code> creates my resume PDF, and a <code>just render</code> builds and opens the PDF in my preferred viewer. With a little more shell magic, I can add live previews:</p>
<pre data-lang="make"><code data-lang="make"><span><span><span>watch</span></span><span>:</span>
<span></span><span></span></span><span><span>  <span><span>#</span>!/usr/bin/env sh
</span></span></span><span><span></span><span>  <span><span><span>inotifywait</span></span><span><span><span> -</span>m</span><span><span> -</span>r</span> . <span>\
</span></span></span></span></span><span><span><span><span><span><span>    --</span>exclude</span> <span><span>"</span>(.*<span>\\</span>.pdf$)|public|justfile|<span>\\</span>.git<span>"</span></span> <span>\
</span></span></span></span></span><span><span><span><span><span><span>    -</span>e</span> close_write,move,create,delete <span>\
</span></span></span></span></span><span><span><span><span></span>    <span>|</span> <span>while</span> <span><span>read</span></span><span> <span><span>-</span>r</span> directory events filename</span><span>;</span> <span>do</span></span>
</span></span><span><span>      <span><span><span>just</span></span><span> render</span></span>
</span></span><span><span>    <span><span>done</span></span>
</span></span></code></pre>
<p>I derived most of this from a great <a href="https://superuser.com/a/181543">Stack Exchange answer</a>. </p>
<p>Now my workflow goes like this:</p>
<ul>
<li>I run <code>just watch</code>. The script watches the local directory for changes.</li>
<li>I edit my resume data.</li>
<li><code>inotifywait</code> catches the event and runs <code>just render</code>.</li>
<li>Zola and Weasyprint run a rebuild of my resume PDF.</li>
<li>My PDF viewer refreshes with the new content.</li>
<li>When I'm done, I hit <code>Ctrl-C</code> or kill my terminal.</li>
</ul>
<p>A full rebuild takes about a second on my machine, roughly nine tenths of which is PDF rendering time. I'd love that to be faster (the Zola HTML generation takes milliseconds!) but it works for now.</p>
<p>So that's my local development story more or less sorted out. I'm relying on my editor's support for the YAML Language Server (available in Visual Studio Code and in Vim/Neovim) to provide validation and formatting of my YAML. I haven't configured precommit checks of my YAML as I don't know of an appropriate tool that uses the same YAML library as the language server.</p>
<h2 id="continuous-integration">Continuous Integration</h2>
<p>Because my PDF is fundamentally a build product, I don't want to commit it to source control. I also don't want to be responsible for ensuring that a stored copy is up-to-date with my latest commit. Enter GitHub Actions.</p>
<p>I added <a href="https://github.com/davidmreed/resume-template/blob/main/.github/workflows/render.yaml">this workflow</a> to my repo:</p>
<pre data-lang="yaml"><code data-lang="yaml"><span><span><span>name</span></span><span>:</span> <span><span>"</span>Render Resume<span>"</span></span>
</span><span><span>on</span><span>:</span>
</span><span>  <span><span>push</span></span><span>:</span>
</span><span>    <span><span>branches</span></span><span>:</span>
</span><span>        <span>-</span> <span>main</span>
</span><span><span><span>jobs</span></span><span>:</span>
</span><span>  <span><span>render</span></span><span>:</span>
</span><span>    <span><span>runs-on</span></span><span>:</span> <span>ubuntu-latest</span>
</span><span>    <span><span>steps</span></span><span>:</span>
</span><span>    <span>-</span> <span><span>uses</span></span><span>:</span> <span>actions/checkout@v3</span>
</span><span>    <span>-</span> <span><span>uses</span></span><span>:</span> <span>cachix/install-nix-action@v23</span>
</span><span>      <span><span>with</span></span><span>:</span>
</span><span>        <span><span>nix_path</span></span><span>:</span> <span>nixpkgs=channel:nixos-unstable</span>
</span><span>    <span>-</span> <span><span>uses</span></span><span>:</span> <span>DeterminateSystems/magic-nix-cache-action@v2</span>
</span><span>    <span>-</span> <span><span>run</span></span><span>:</span> <span>nix-shell --run "just pdf"</span>
</span><span>    <span>-</span> <span><span>uses</span></span><span>:</span> <span>actions/upload-artifact@v3</span>
</span><span>      <span><span>with</span></span><span>:</span>
</span><span>        <span><span>path</span></span><span>:</span> <span><span>"</span>*.pdf<span>"</span></span>
</span></code></pre>
<p>Because <code>nix-shell</code> grabs my <code>shell.nix</code> by default, I get the same packages installed in CI that I use for local development. I could go further and pin a specific set of package versions to guarantee reproducibility. I've chosen not to do any pinning yet while I keep rolling out uses for Nix on my local machines.</p>
<p>Once the PDF is rendered, I upload it as an artifact on this commit, so that it's associated with all of its sources. I can grab the PDF from my latest commit and upload it any time I submit a job application.</p>
<p>If I wanted to use another distribution strategy, like including this PDF as an asset in my website, I could build further automation around that use case. That might be programmatically making a commit to a different repo, using my resume repo as a submodule, or something else entirely.</p>
<p>I could go further still and add rendering on branches, too. I might let a branch represent a sector to which I want to apply, like <code>nonprofit</code>. Then I can segregate tailorings of my resume for specific job roles, and merge down global changes from <code>main</code> to keep everything in sync.</p>
<h2 id="the-result">The Result</h2>
<p>It's still just a resume, but it makes my engineer brain happy.</p>
<p>If you'd like to indulge similar neuroses, you can clone a <a href="https://github.com/davidmreed/resume-template">template repository</a> and start from there.</p>
<p>Have fun!</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Second Factor SMS: Worse Than Its Reputation (282 pts)]]></title>
            <link>https://www.ccc.de/en/updates/2024/2fa-sms</link>
            <guid>40934495</guid>
            <pubDate>Thu, 11 Jul 2024 07:44:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ccc.de/en/updates/2024/2fa-sms">https://www.ccc.de/en/updates/2024/2fa-sms</a>, See on <a href="https://news.ycombinator.com/item?id=40934495">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>One-time passwords are often sent via SMS. Security researchers from the CCC recently had live access to over 200 million such SMS messages from more than 200 affected companies.</p><div><blockquote><strong>WhatsApp code: 2342</strong><br>You can also tap on this link to verify your phone:<br>v.whatsapp.com/2342<br>Do not share this code.</blockquote>
<blockquote><strong>Transfer to DE63 4306 0967 1239 7690 03</strong><br>Amount: 1,312.00 EUR<br>TAN: 161161<br>Please enter this TAN to complete the transaction.<br>This TAN is valid for 5 minutes.</blockquote>
<h3>Why SMS?</h3>
<p>Two-factor authentication via SMS (2FA-SMS) is a method to increase the security of authentications. Alongside the static password, a dynamic code sent via SMS is required. The user must enter this code during login to prove they know the password (1st factor: knowledge) and have access to the phone number (2nd factor: possession). Thus, a stolen password alone is not enough to take over the user's account.</p>
<h3>Well-Known Attack Vectors</h3>
<p>This method has been under attack for some time. Through techniques like SIM swapping or exploiting SS7 vulnerabilities in mobile networks, attackers can intercept SMS messages. Alternatively, users can be tricked through phishing attacks into revealing their one-time passwords. <a href="https://www.ccc.de/en/updates/2013/de-mail-unqualifizierte-makulatur">The CCC advised against using SMS as a second factor as early as 2013</a>. Nonetheless, 2FA-SMS is widespread. It offers more security than simple password authentication.</p>
<h3>Now Also Viewable Online!</h3>
<p>The Chaos Computer Club (CCC) now demonstrates a previously neglected attack on 2FA-SMS: Service providers are commonly used to send these messages. These providers send large volumes of SMS for various companies and services and have access to the SMS content. Thus, the security of the authentication process also depends on the security of these providers.</p>
<p>IdentifyMobile, a provider of 2FA-SMS, shared the sent one-time passwords in real-time on the internet. The CCC happened to be in the right place at the right time and accessed the data. It was sufficient to guess the subdomain "idmdatastore". Besides SMS content, recipients' phone numbers, sender names, and sometimes other account information were visible.</p>
<h3>Nearly 200 Million SMS from Over 200 Companies</h3>
<p>Over 200 companies that entrusted this provider directly or indirectly through other service providers with the security of their authentication were affected. This included companies like Google, Amazon, Facebook, Microsoft, as well as Telegram, Airbnb, FedEx, and DHL. Over 198 million SMS leaked in total.</p>
<p>By simply viewing the live feed, it would have been possible to:</p>
<ul>
<li>Take over WhatsApp numbers</li>
<li>Conduct financial transactions or log in to various services without access to the phone, provided the password was known</li>
</ul>
<h3>(Not Yet) a Catastrophe</h3>
<p>To truly misuse the SMS codes, attackers would typically still need the password. However, "1-click login" links were also included in the data. For some large affected companies, only individual services were protected by IdentifyMobile. Nevertheless, IdentifyMobile's negligence exposed companies and their customers to significant risk. This is evident from the numerous similar inquiries from data protection departments worldwide now reaching us through all channels.</p>
<p>We are happy to confirm that we did not keep the data. However, we cannot rule out that others may have accessed it.</p>
<h3>2FA-SMS is Better Than Nothing, But Other Methods Don’t rely on IdentifyMobile</h3>
<p>One-time passwords generated in an app or using hardware tokens are more secure and independent of the mobile network. If this option is available, we recommend using it. And any second factor remains better than just one, the password.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Engineering principles for building financial systems (318 pts)]]></title>
            <link>https://substack.wasteman.codes/p/engineering-principles-and-best-practices</link>
            <guid>40933110</guid>
            <pubDate>Thu, 11 Jul 2024 01:47:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://substack.wasteman.codes/p/engineering-principles-and-best-practices">https://substack.wasteman.codes/p/engineering-principles-and-best-practices</a>, See on <a href="https://news.ycombinator.com/item?id=40933110">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>Accounting hasn't really changed in the past couple of hundred years. Despite this, there is a lot of confusion around the right way of building software for financial systems. </p><p>In this post, I’ll share lessons from my years working on financial systems at big tech companies. Our focus will be building an accounting system, but the principles apply to more general financial systems as well.</p><p>This post will go over the following</p><ol><li><p>Basic financial definitions relevant to the post</p></li><li><p>High level goals of an accounting system</p></li><li><p>Engineering principles to achieve those goals </p></li><li><p>Best Practices </p></li></ol><ul><li><p><strong>General Ledger (GL)</strong><span>: The primary accounting record of the company, summarizing all financial transactions over a specific time period. You can think of this as an aggregation of it's corresponding sub-ledgers.</span></p></li><li><p><strong>Sub-ledger</strong><span>: Contains detailed information about all individual transactions related to a specific GL. Records in the sub ledger will have much more granular data then the general ledger, like who the specific customer is, specific line items in an order, etc. The difference in data between the sub-ledger and GL will depend on the type of business and volume of data you are working with. Some small businesses can get away with not having any sub-ledgers at all, but it is doubtful that they would ever need custom software to manage something that is so low in scale.</span></p></li><li><p><strong>Financial Record: </strong><span>This refers to the general ledger and sub-ledgers. </span></p></li><li><p><strong>Material: </strong><span>A financial event is considered </span><em>material</em><span> if it is significant enough to impact the decisions of stakeholders based on financial statements. Note that this definition is somewhat ambiguous by design, as different businesses have different materiality thresholds. For example what might be material for a business making $250,000 of revenue per year, will not be material for a business making $1 billion in revenue. </span></p></li></ul><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d4c2233-1b32-409a-9d0d-281470ab3469_1767x3914.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d4c2233-1b32-409a-9d0d-281470ab3469_1767x3914.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d4c2233-1b32-409a-9d0d-281470ab3469_1767x3914.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d4c2233-1b32-409a-9d0d-281470ab3469_1767x3914.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d4c2233-1b32-409a-9d0d-281470ab3469_1767x3914.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d4c2233-1b32-409a-9d0d-281470ab3469_1767x3914.png" width="378" height="837.2596153846154" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7d4c2233-1b32-409a-9d0d-281470ab3469_1767x3914.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;normal&quot;,&quot;height&quot;:3225,&quot;width&quot;:1456,&quot;resizeWidth&quot;:378,&quot;bytes&quot;:79366,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d4c2233-1b32-409a-9d0d-281470ab3469_1767x3914.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d4c2233-1b32-409a-9d0d-281470ab3469_1767x3914.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d4c2233-1b32-409a-9d0d-281470ab3469_1767x3914.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d4c2233-1b32-409a-9d0d-281470ab3469_1767x3914.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>The three main goals of your accounting system are to be </span><strong>(1) Accurate, (2) Auditable and (3) Timely.</strong></p><p>The financial record needs to reflect the known state of the business. This statement is a little broad and up to some interpretation so I will give some real examples.</p><p>If we sell a 10 units of a product that costs $9.99, the corresponding financial records must add up to $99.90. This seems obvious but when you are aggregating thousands (in a lot of cases millions) of transactions, simple summation or rounding errors between systems can cause material inaccuracies. </p><blockquote><p><strong>Wasteman’s Note: </strong><em>People say naming is the hardest problem in computer science, I would say a close second is addition. After working on large scale financial systems for the past few years, I can’t remember how many times the smallest bugs caused large discrepancies in our data. Also don’t get me started on summations over floats. I learned the hard way why you should always use integers.</em></p></blockquote><p><span>The financial record also needs to be </span><strong>complete</strong><span>. More specifically, both the sub-ledger and the general ledger are a complete representation of all business activities that occurred. If there is an event that occurred but is not in the financial record, than the system is not complete. </span></p><blockquote><p><strong>Wasteman’s Note: </strong><em>Another surprisingly really hard problem is guaranteeing completeness. As your system scales, data hops between many systems and at each hop data can easily be mutated or dropped by accident.</em><span> </span></p></blockquote><p>Very related to accuracy, your financial record must be easily auditable so that stakeholders can detect errors and accurately measure performance of your business. And even if you don’t care, the IRS definitely does. </p><p>This one depends entirely on your business and it's specific needs. Small businesses can get away with just dumping all numbers near the end of the month, just in time to close the books. Larger businesses generally want to avoid this, and have a near real time system. This allows them to monitor financials within the month, make decisions based on financial data faster, and reduce the rush to close the month/quarter in the first few days of the month.</p><p><span>But whatever that need is, our accounting system should meet the needs of your business, and whatever </span><strong>timely</strong><span> means to them.</span></p><blockquote><p><strong>Wasteman’s note: </strong><em><span>People tend to get lost in conversations about batch vs streaming systems with respect to timeliness a lot. My take is that this isn’t an important distinction to make. </span><a href="https://www.ververica.com/blog/batch-is-a-special-case-of-streaming" rel="">Batch is just a special case of streaming</a><span>. If you’re data is modeled correctly, its pretty easy to switch between them especially with unified frameworks like </span><a href="https://beam.apache.org/" rel="">Apache Beam</a><span>.</span></em></p></blockquote><p>The three main engineering principles your accounting system should abide by are</p><ol><li><p>Immutability and Durability of data</p></li><li><p>Data should be represented at the smallest grain</p></li><li><p>Code should be Idempotent</p></li></ol><p>This allows for auditability, which helps debugging and in turn accuracy. When data is immutable, you have a record of what the state of the system was at any given time. This makes it really easy to recompute the world from previous states, because no state is every lost.</p><p>Building on, once data is stated in the financial record it cannot be deleted. Any corrections to the system must be represented as a new financial transaction. For example let’s say your system had a bug and accidentally reported that a service was sold for $1000, when it should have been $900. To correct this mistake, you should first reverse the accounting entries corresponding to the mistake, and restate the accounting entry for the correct amount. </p><p>It will look something like this: </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcac99f71-fe2f-41b1-934e-6064f3ffb813_2336x1984.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcac99f71-fe2f-41b1-934e-6064f3ffb813_2336x1984.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcac99f71-fe2f-41b1-934e-6064f3ffb813_2336x1984.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcac99f71-fe2f-41b1-934e-6064f3ffb813_2336x1984.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcac99f71-fe2f-41b1-934e-6064f3ffb813_2336x1984.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcac99f71-fe2f-41b1-934e-6064f3ffb813_2336x1984.png" width="1456" height="1237" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cac99f71-fe2f-41b1-934e-6064f3ffb813_2336x1984.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1237,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:87028,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcac99f71-fe2f-41b1-934e-6064f3ffb813_2336x1984.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcac99f71-fe2f-41b1-934e-6064f3ffb813_2336x1984.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcac99f71-fe2f-41b1-934e-6064f3ffb813_2336x1984.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcac99f71-fe2f-41b1-934e-6064f3ffb813_2336x1984.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>So you can see that in the financial record, there is evidence that the balance of Accounts Receivable (AR) and Revenue was $1000 at some point, but was corrected later. Even though that balance was incorrect, we want an audit trail of what the balance was at any given moment.</p><p>Similar to the above principle, this is also critical for enabling a clear audit trail. Even though financial reports and the general ledger are aggregated, they are computed from more granular events. When the data doesn't make sense, you need the most granular data to debug what might have been the issue. </p><p>Saving data at the lowest granularity also makes it really easy to correct data that is derived from that dataset. If a single immutable dataset is the core source of truth for all views of that data, to correct the view all you need to do is rerun the pipeline that creates that view after fixing your data. </p><p>Similarly when accountants are preparing to close the books, they reconcile account balances with all the transactions that occurred to validate that the books are accurate. When a discrepancy is discovered, you can dig into the exact transaction that might be causing the issue.</p><p>Every financial event can only be processed once, duplicates in the financial record will cause obvious inaccuracies. For that reason, all code that produces financial records should be idempotent.</p><p>Over the years, I have run into quite a few gotchas that have caused me a lot of pain. Below are best practices I recommend, to avoid the many pitfalls I have personally faced.</p><p><strong>Use integers to represent financial amounts</strong><span>. Makes arithmetic much easier. Avoid floats at all costs.</span></p><p><strong>Granularity of your financial amounts should support currency conversions with minimal loss of precision</strong><span>. If you are only working with dollars, representing values in cents might be sufficient. If you are a global business, prefer micros or a </span><code>DECIMAL(19, 4)</code><span>.  The decimal choice is quite popular among financial systems, but micros has been the standard for ads financial systems. This limits loss of precision when converting between currencies</span></p><blockquote><p><strong>Wasteman’s note: </strong><em>Micros of a currency = smallest unit * 1,000,000. E.g $1.23 = 1,230,000 micros. I first came across this when working with Google’s metrics API.</em></p></blockquote><p><strong>Use consistent rounding methodologies</strong><span>. At scale the way you round can create material differences between expected amounts. For example one rounding methodology is to round all values 5 and up to the next significant digit, and 4 and below rounds down. Another valid way is to always round up. All that matters is you are consistent across the board. When you are dealing with millions of transactions, being off by 1 cent per transaction can lead to material differences. (10 million transactions off by 1 cent, leads to a difference of $100k). This may not be material to your business at this scale, but it’s material enough for the government to come after you for underpaying taxes.</span></p><blockquote><p><strong>Wasteman’s note: </strong><em>If you are a global business there can be a lot of gotchas with rounding and currency conversions. I would go as far as saying you should make a centralized library/service to handle both rounding and currency conversions. Different governments respect different rounding rules when calculating taxes, so having all these nuances abstracted into a single service will reduce complexity.</em></p></blockquote><p><strong>Delay currency conversion as long as you can</strong><span>. Preemptively converting currencies can cause loss of precision. Delay currency conversions until after aggregations occur in their local currency.</span></p><p><strong>Use integer representations of time</strong><span>. This one is a little controversial but I stand by it. There are so many libraries in different technologies that parse timestamps into objects, and they all do them differently. Avoid this headache and just use integers. Unix timestamp, or even integer based UTC datetimes work perfectly fine. The less data conversions that occur between systems, the better. (Read about Etsy’s own problems with timestamp types </span><a href="https://www.etsy.com/codeascraft/the-problem-with-timeseries-data-in-machine-learning-feature-systems" rel="">here</a><span>)</span></p><blockquote><p><strong>Wasteman’s note: </strong><em>I haven’t even talked about daylight savings related bugs. Using an incrementing integer can help you avoid this altogether. If you really insist on using datetimestamps, please at least use UTC. You would be surprised at how many very large businesses use non UTC timestamps.</em></p></blockquote><p>Thanks for reading this post, I am sure I made a controversial statement somewhere but please feel free to comment and start a discussion. I am very open to learning and hearing other people’s thoughts. And if you enjoyed this post, consider supporting me by subscribing below!</p><p>And for further reading, here are some really good blog posts on accounting tailored towards software engineers.</p><ul><li><p><a href="https://drew.thecsillags.com/posts/2017-12-06-accounting-for-software-engineers/" rel="">Accounting for Software Engineers</a></p></li><li><p><a href="https://www.moderntreasury.com/journal/accounting-for-developers-part-i#does-accounting-really-matter-in-software-development" rel="">Accounting for Developers Part 1</a></p></li><li><p><a href="https://martin.kleppmann.com/2011/03/07/accounting-for-computer-scientists.html" rel="">Accounting for Computer Scientists</a></p></li></ul></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Dut, a fast Linux disk usage calculator (344 pts)]]></title>
            <link>https://codeberg.org/201984/dut</link>
            <guid>40932492</guid>
            <pubDate>Wed, 10 Jul 2024 23:29:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://codeberg.org/201984/dut">https://codeberg.org/201984/dut</a>, See on <a href="https://news.ycombinator.com/item?id=40932492">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="readme">
			
				<h2 id="user-content-dut-a-disk-usage-calculator-for-linux" dir="auto">dut - A disk usage calculator for Linux</h2>
<h2 id="user-content-features" dir="auto">Features</h2>
<ul dir="auto">
<li>Accurate counting of hard links with an output inspired by NCDU.</li>
<li>Pure ASCII output which is fully compatible with the plain Linux tty.</li>
<li>Configurable output format. Changing the maximum depth of files shown is a simple command-line
argument.</li>
</ul>
<h2 id="user-content-examples" dir="auto">Examples</h2>
<p dir="auto">By default, <code>dut</code> will output a tree of the biggest directories it finds under your current directory.</p>
<pre><code>$ dut -n 10
 2.4G    0B       /- Local
 2.4G    0B     /- AppData
 2.4G    0B   /- NetworkService
 2.4G    0B |- ServiceProfiles
 2.5G   63M |- servicing
 5.2G  423M |   /- FileRepository
 5.2G  426M | /- DriverStore
 9.6G  2.5G |- System32
  12G  7.2G /- WinSxS
  29G  225M .
</code></pre><p dir="auto">The <code>-n 10</code> option limits it to 10 rows. To limit the depth shown, use <code>-d &lt;n&gt;</code>.</p>
<pre><code>$ dut -n 10 -d 1
 964M    0B |- MEMORY.DMP
1010M    0B |- SoftwareDistribution
 1.2G  1.0G |- SysWOW64
 1.3G  208M |- assembly
 1.8G  1.8G |- SystemApps
 2.4G    0B |- ServiceProfiles
 2.5G   63M |- servicing
 9.6G  2.5G |- System32
  12G  7.2G /- WinSxS
  29G  225M .
</code></pre><p dir="auto">The first column in the output tells you how much space a given entry takes up on your disk.
This can be an overcount, however, because of hard links (identical files that are only stored
once on the disk). Hard links under a directory are deduplicated in the first column's number,
but hard links that go outside of a directory to somewhere else will still be counted here.</p>
<p dir="auto">That's where the second column comes in. It tells you how much of an entry's size is shared
with other entries outside of it because of hard links. In the output above, we can see that
most of the entries have a lot of data shared with other entries, but the root directory only
has 225M shared with others. This tells us that there's a lot of hard links going between all
of the entries shown above.</p>
<p dir="auto">If you want to see how much of an entry's size is unique to just it, you can subtract the second
column from the first one.</p>
<p dir="auto">The full list of options can be seen with <code>dut -h</code>.</p>
<h2 id="user-content-how-to-build" dir="auto">How to build</h2>
<p dir="auto"><code>dut</code> is a single source file, so all you need is a C11 compiler:</p>
<pre><code>gcc -O3 -flto main.c -o dut
</code></pre><p dir="auto">To install, copy the <code>dut</code> executable to a directory on your PATH, e.g. <code>/usr/local/bin</code>.</p>
<p dir="auto">If get linker errors about missing symbols, you may need to add the <code>-pthread</code> option to gcc.</p>
<h2 id="user-content-benchmarks" dir="auto">Benchmarks</h2>
<p dir="auto"><code>dut</code> is remarkably fast, but it doesn't win in all cases. It loses to a couple programs when
Linux's disk caches aren't populated yet, which is usually the first time you run it on a certain
directory. On subsequent runs, <code>dut</code> beats everything else by a significant margin.</p>
<p dir="auto">Benchmarked programs:</p>
<ul dir="auto">
<li><code>du</code> from <a href="https://www.gnu.org/software/coreutils/coreutils.html" rel="nofollow">coreutils</a> (C)</li>
<li><a href="https://github.com/byron/dua-cli" rel="nofollow"><code>dua</code></a> (Rust)</li>
<li><a href="https://github.com/KSXGitHub/parallel-disk-usage" rel="nofollow"><code>pdu</code></a> (Rust)</li>
<li><a href="https://github.com/bootandy/dust" rel="nofollow"><code>dust</code></a> (Rust)</li>
<li><a href="https://github.com/dundee/gdu" rel="nofollow"><code>gdu</code></a> (Go)</li>
</ul>
<p dir="auto">If you know of a faster program, let me know and I'll add it to these benchmarks.</p>
<h3 id="user-content-benchmark-1-measuring-performance-from-linux-s-disk-cache" dir="auto">Benchmark 1: Measuring performance from Linux's disk cache</h3>
<p dir="auto">The first benchmark is calculating the total disk usage of both of the SSDs in my laptop. I did
warm-up runs beforehand to make sure everything is cached, so this benchmark doesn't touch the disk
at all.</p>
<h4 id="user-content-specs" dir="auto">Specs</h4>
<ul dir="auto">
<li>CPU: i5-10500h</li>
<li>RAM: 16 GB</li>
<li>OS: Arch Linux, kernel 6.8.4</li>
</ul>
<p dir="auto">In order to make things fair, I forced <code>dut</code> and <code>dust</code> to output in color and show 60 rows. I also
added a 10 second sleep between each program's run to limit the effects of thermal throttling.</p>
<pre><code>$ hyperfine 'dut -Cn 60 /' 'du -sh /' 'pdu /' 'dust -n 60 /' 'gdu --non-interactive /' 'dua /' -s 'sleep 10' -i
Benchmark 1: dut -Cn 60 /
  Time (mean ± σ):     467.4 ms ±  11.7 ms    [User: 410.3 ms, System: 4595.4 ms]
  Range (min … max):   442.5 ms … 485.4 ms    10 runs

Benchmark 2: du -sh /
  Time (mean ± σ):      3.566 s ±  0.049 s    [User: 0.775 s, System: 2.743 s]
  Range (min … max):    3.486 s …  3.615 s    10 runs

  Warning: Ignoring non-zero exit code.

Benchmark 3: pdu /
  Time (mean ± σ):     732.1 ms ±  13.8 ms    [User: 1887.3 ms, System: 6123.5 ms]
  Range (min … max):   717.6 ms … 755.8 ms    10 runs

Benchmark 4: dust -n 60 /
  Time (mean ± σ):      1.438 s ±  0.031 s    [User: 3.068 s, System: 6.962 s]
  Range (min … max):    1.397 s …  1.481 s    10 runs

Benchmark 5: gdu --non-interactive /
  Time (mean ± σ):      1.361 s ±  0.103 s    [User: 7.556 s, System: 7.034 s]
  Range (min … max):    1.298 s …  1.569 s    10 runs

  Warning: Statistical outliers were detected. Consider re-running this benchmark on a quiet system without any interferences from other programs. It might help to use the '--warmup' or '--prepare' options.

Benchmark 6: dua /
  Time (mean ± σ):      1.459 s ±  0.133 s    [User: 4.054 s, System: 9.640 s]
  Range (min … max):    1.346 s …  1.659 s    10 runs

Summary
  dut -Cn 60 / ran
    1.57 ± 0.05 times faster than pdu /
    2.91 ± 0.23 times faster than gdu --non-interactive /
    3.08 ± 0.10 times faster than dust -n 60 /
    3.12 ± 0.30 times faster than dua /
    7.63 ± 0.22 times faster than du -sh /
</code></pre><p dir="auto">The warning about a non-zero exit code was due to <code>du</code> reporting an error for not being able
to access directories in /proc and /root.</p>
<h3 id="user-content-benchmark-2-ssd-performance" dir="auto">Benchmark 2: SSD Performance</h3>
<p dir="auto">This bechmark is operating on the same filesystem as above, except I'm flushing the disk caches
in-between runs. This results in having to read all the data from the SSD each time instead of
getting it from RAM.</p>
<p dir="auto">This is a more niche use-case since most of the time <code>dut</code> will be running from the cache. It
only has to read from the disk on its first run in a particular directory.</p>
<h4 id="user-content-drives" dir="auto">Drives:</h4>
<ul dir="auto">
<li>Intel 660p 512G</li>
<li>SX8200PNP-512GT-S</li>
</ul>
<pre><code>$ sudo hyperfine 'dut -Cn 60 /' 'du -sh /' 'pdu /' 'dust -n 60 /' 'gdu --non-interactive /' 'dua /' -s 'sleep 10' -i -M 3 -p 'echo 1 &gt; /proc/sys/vm/drop_caches'
Benchmark 1: dut -Cn 60 /
  Time (mean ± σ):      5.773 s ±  0.184 s    [User: 0.406 s, System: 4.694 s]
  Range (min … max):    5.561 s …  5.881 s    3 runs

  Warning: Statistical outliers were detected. Consider re-running this benchmark on a quiet system without any interferences from other programs. It might help to use the '--warmup' or '--prepare' options.

Benchmark 2: du -sh /
  Time (mean ± σ):     20.779 s ±  0.058 s    [User: 0.767 s, System: 3.709 s]
  Range (min … max):   20.712 s … 20.819 s    3 runs

  Warning: Ignoring non-zero exit code.

Benchmark 3: pdu /
  Time (mean ± σ):      4.279 s ±  0.292 s    [User: 1.701 s, System: 5.543 s]
  Range (min … max):    4.072 s …  4.613 s    3 runs

Benchmark 4: dust -n 60 /
  Time (mean ± σ):      5.009 s ±  0.348 s    [User: 2.608 s, System: 6.211 s]
  Range (min … max):    4.726 s …  5.397 s    3 runs

Benchmark 5: gdu --non-interactive /
  Time (mean ± σ):      4.090 s ±  0.081 s    [User: 7.027 s, System: 6.989 s]
  Range (min … max):    4.040 s …  4.183 s    3 runs

  Warning: Statistical outliers were detected. Consider re-running this benchmark on a quiet system without any interferences from other programs. It might help to use the '--warmup' or '--prepare' options.

Benchmark 6: dua /
  Time (mean ± σ):      6.269 s ±  0.133 s    [User: 4.541 s, System: 12.786 s]
  Range (min … max):    6.162 s …  6.418 s    3 runs

Summary
  gdu --non-interactive / ran
    1.05 ± 0.07 times faster than pdu /
    1.22 ± 0.09 times faster than dust -n 60 /
    1.41 ± 0.05 times faster than dut -Cn 60 /
    1.53 ± 0.04 times faster than dua /
    5.08 ± 0.10 times faster than du -sh /
</code></pre><h3 id="user-content-benchmark-3-hdd-performance" dir="auto">Benchmark 3: HDD Performance</h3>
<p dir="auto">For this benchmark, I did the same benchmark as the last except I did it on an HDD instead. Some of
the Rust programs perform quite badly in this scenario, but <code>dua</code> still beats <code>dut</code> narrowly.</p>
<p dir="auto">The test location is my home directory on an old Linux installation. There are approximately 26k
subdirectories.</p>
<p dir="auto">The drive being measured is a 2 terabyte 5400rpm Western Digital WD20EFRX connected to my laptop
with a USB enclosure.</p>
<pre><code>$ sudo hyperfine 'dut -Cn 60' 'du -sh' 'pdu' 'dust -n 60' 'gdu --non-interactive' 'dua' -s 'sleep 10' -i -M 3 -p 'echo 1 &gt; /proc/sys/vm/drop_caches'
Benchmark 1: dut -Cn 60
  Time (mean ± σ):     36.720 s ±  0.350 s    [User: 0.078 s, System: 0.740 s]
  Range (min … max):   36.411 s … 37.100 s    3 runs

Benchmark 2: du -sh
  Time (mean ± σ):     44.810 s ±  0.043 s    [User: 0.108 s, System: 0.657 s]
  Range (min … max):   44.767 s … 44.854 s    3 runs

Benchmark 3: pdu
  Time (mean ± σ):     81.361 s ±  0.954 s    [User: 0.320 s, System: 0.935 s]
  Range (min … max):   80.675 s … 82.451 s    3 runs

Benchmark 4: dust -n 60
  Time (mean ± σ):     86.991 s ±  2.449 s    [User: 0.337 s, System: 1.042 s]
  Range (min … max):   84.411 s … 89.286 s    3 runs

Benchmark 5: gdu --non-interactive
  Time (mean ± σ):     41.096 s ±  0.229 s    [User: 1.086 s, System: 1.165 s]
  Range (min … max):   40.837 s … 41.273 s    3 runs

Benchmark 6: dua
  Time (mean ± σ):     34.472 s ±  0.965 s    [User: 9.107 s, System: 29.192 s]
  Range (min … max):   33.733 s … 35.564 s    3 runs

Summary
  dua ran
    1.07 ± 0.03 times faster than dut -Cn 60
    1.19 ± 0.03 times faster than gdu --non-interactive
    1.30 ± 0.04 times faster than du -sh
    2.36 ± 0.07 times faster than pdu
    2.52 ± 0.10 times faster than dust -n 60
</code></pre><h4 id="user-content-why-are-pdu-and-dust-so-bad-on-hdd" dir="auto">Why are <code>pdu</code> and <code>dust</code> so bad on HDD?</h4>
<p dir="auto">It's hard to say. My best guess is they have a really HDD-unfriendly access pattern, since they
both use Rayon for multithreading which uses FIFO ordering for tasks. This results in them doing
a breadth-first search of the filesystem, whereas <code>dut</code> and <code>du</code> both use depth-first search. I
don't know why one ordering is better than the other, but the difference is pretty drastic.</p>
<p dir="auto">I also think that ordering is the reason <code>dut</code> doesn't do so well on SSD either, but I'm not so
sure of that.</p>

			
		</div></div>]]></description>
        </item>
    </channel>
</rss>