<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 22 Jul 2023 17:00:07 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[I am dying of squamous cell carcinoma, and potential treatments are out of reach (147 pts)]]></title>
            <link>https://jakeseliger.com/2023/07/22/i-am-dying-of-squamous-cell-carcinoma-and-the-treatments-that-might-save-me-are-just-out-of-reach/</link>
            <guid>36827438</guid>
            <pubDate>Sat, 22 Jul 2023 16:11:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jakeseliger.com/2023/07/22/i-am-dying-of-squamous-cell-carcinoma-and-the-treatments-that-might-save-me-are-just-out-of-reach/">https://jakeseliger.com/2023/07/22/i-am-dying-of-squamous-cell-carcinoma-and-the-treatments-that-might-save-me-are-just-out-of-reach/</a>, See on <a href="https://news.ycombinator.com/item?id=36827438">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-7144">

	<!-- .entry-header -->

	<!-- #entry-meta -->

	<div>
						<p>Alex Tabarrok <a href="https://marginalrevolution.com/marginalrevolution/2015/08/is-the-fda-too-conservative-or-too-aggressive.html">writes about how</a> “when the FDA fails to approve a good drug, people die but the bodies are buried in an invisible graveyard.” I’d like to make that graveyard a little bit more visible because I’m going to be buried in it, in a few weeks or months. A squamous cell carcinoma tumor appeared on my tongue last September; the surgery for it occurred in October, followed by radiation in December – January, but the tumor reappeared at the base of my tongue in April. A massive surgery on May 25 appeared to produce “clean margins” (that is, no tumor cells remained where the surgeon operated), albeit at huge cost: I have no tongue any more, just a “flap” of muscle where it used to be, and no ability to swallow solid foods ever again. Monday I’m starting chemotherapy, but that’s almost certainly going to fail, because a CT scan shows four to six new gross tumors, four in my neck and two, possibly, in my lungs.</p>
<p>So what <em>might</em> help me? MRNA tumor vaccines. Head and neck squamous cell carcinomas (HNSCC) are notoriously treatment resistant, and mRNA vaccines have shown huge promise. Why aren’t they happening faster? Because the FDA is slow. There are some trials underway (<a href="https://trials.modernatx.com/study/?id=mRNA-4359-P101">here is one</a> from Moderna; <a href="https://trials.modernatx.com/study/?id=mRNA-2752-P101">here is another</a>), and, although I’m trying to enroll, I may be too late, since my cancer moves so aggressively. The FDA was loathe to approve initial mRNA human trials, even when those trials would have been full of people like me: those who are facing death sentences anyway.</p>
<p>Here is one story, from “<a href="https://www.fdareview.org/issues/why-the-fda-has-an-incentive-to-delay-the-introduction-of-new-drugs/">Why the FDA Has an Incentive to Delay the Introduction of New Drugs</a>:”</p>
<blockquote>
<p>In the early 1980s, when I headed the team at the FDA that was reviewing the NDA for recombinant human insulin, . . . we were ready to recommend approval a mere four months after the application was submitted (at a time when the average time for NDA review was more than two and a half years). With quintessential bureaucratic reasoning, my supervisor refused to sign off on the approval—even though he agreed that the data provided compelling evidence of the drug’s safety and effectiveness. “If anything goes wrong,” he argued, “think how bad it will look that we approved the drug so quickly.” (41)</p>
</blockquote>
<p>The problem is that delaying mRNA cancer vaccines kills people like me.</p>
<p>We need to have a much stronger “right to try” presumption: “<a href="https://www.newyorker.com/magazine/2023/06/26/relyvrio-als-fda-approval">When Dying Patients Want Unproven Drugs</a>,” we should let those patients try. I have weeks to months left; let’s try whatever there is to try, and advance medicine along the way. The “right to try” is part of fundamental freedom—and this is particularly true for palliative-stage patients without a route to a cure anyway. They are risking essentially nothing.</p>
<p>When I am dead and buried at least those who I love and who love me will know the FDA protected me and millions of others like me from ourselves. Thanks, FDA. But the dead do not vote and do not agitate for change, so the system is likely to grind on.</p>
<p>In computer science there is a convention in which one’s first program prints “Hello, world.” Now it is my turn to write “Goodbye, world.” I’m crying as I write this and am sorry to have to go so soon. I have to give back the gift, though with great sadness.</p>
<p><a href="https://www.slowboring.com/p/fda-cost-benefit">Here is more about the FDA being slow</a> and bureaucratic.</p>


<figure><a href="https://jseliger.files.wordpress.com/2023/07/dsf4195.jpg"><img data-attachment-id="7146" data-permalink="https://jakeseliger.com/2023/07/22/i-am-dying-of-squamous-cell-carcinoma-and-the-treatments-that-might-save-me-are-just-out-of-reach/dsf4195/" data-orig-file="https://jseliger.files.wordpress.com/2023/07/dsf4195.jpg" data-orig-size="6240,4160" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;X-T4&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1690014948&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;23&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="dsf4195" data-image-description="" data-image-caption="" data-medium-file="https://jseliger.files.wordpress.com/2023/07/dsf4195.jpg?w=300" data-large-file="https://jseliger.files.wordpress.com/2023/07/dsf4195.jpg?w=550" src="https://jseliger.files.wordpress.com/2023/07/dsf4195.jpg?w=1024" alt="Jake Seliger, possible figurehead for the invisible graveyard of men and women killed by the FDA's slowness " srcset="https://jseliger.files.wordpress.com/2023/07/dsf4195.jpg?w=1024 1024w, https://jseliger.files.wordpress.com/2023/07/dsf4195.jpg?w=2048 2048w, https://jseliger.files.wordpress.com/2023/07/dsf4195.jpg?w=150 150w, https://jseliger.files.wordpress.com/2023/07/dsf4195.jpg?w=300 300w, https://jseliger.files.wordpress.com/2023/07/dsf4195.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption>The author on July 22, 2023, when he is, or was, still alive. </figcaption></figure>
					</div><!-- .post-content -->

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why even let users set their own passwords? (132 pts)]]></title>
            <link>https://www.devever.net/~hl/passwords</link>
            <guid>36826111</guid>
            <pubDate>Sat, 22 Jul 2023 13:36:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.devever.net/~hl/passwords">https://www.devever.net/~hl/passwords</a>, See on <a href="https://news.ycombinator.com/item?id=36826111">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="nh">
          <main>
            <article><p>Today we seem to be living through a war on passwords. This is manifested in
various ways; in its most passive form, it takes the form of people blogging
about how passwords are bad. The more material changes are the general trend
towards no longer treating passwords as a sufficient condition for access in
favour of either mandatory “2FA” or, where 2FA is not used, <a href="https://www.devever.net/~hl/logindenial">risk-based
authentication</a>, in which some extra authentication step is
non-deterministically and randomly demanded.</p>
<p>This step is commonly something like “enter the code in an email we just sent”
when trying to login. Since this process is literally the same as most password
recovery processes, it raises the question of what the point of a password is
in the first place if you always have to go through this process when trying to
login.</p>
<p>Often this will be combined with fallacious notions such as “remember this
device”, the idea being you only have to go through all this the first time when
logging in from a particular device. This idea is fallacious because the web
has no notion of a “device”, and this is a <em>very intentional design choice</em>
made for privacy purposes. We are literally living through the gradual
phase-out of third-party cookies, amongst other functionality, specifically to
try and prevent this sort of thing, so why do web developers persist in
believing in this fiction of a “device”? My own browser erases all cookies from
an origin immediately after the last tab from that origin is closed, so these
sites are convinced I am logging in from a new “device” every single time, and
then demand I respond to one of these challenge emails.</p>
<p>Essentially these sites consider passwords so worthless as a form of security
that they essentially don't meaningfully allow people to have one anymore. The
login flow and the password recovery flow are essentially the same, the UI just
pretends otherwise. Other examples include PayPal, where you can literally
enter a credit card number to prove your identity and reset your password(!).
In other words, knowing your credit card number is considered a stronger or
equal proof of identity than either knowing your password or being able to
receive an email.<a href="#fn1" id="fn1b"><sup>1</sup></a></p>
<p>While at the same time every website for the masses now seems to be designed
around the assumption that everyone is going to set their password to
“password1”, web-based HTTP APIs are also widely popular nowadays. These
services almost invariably perform authentication via use of a token or “API
key”.</p>
<p>An API key is basically a password, except that it is randomly generated by a
website with a large amount of entropy and thus assumed to be secure. A given
website might obnoxiously refuse to trust in my ability to set a secure
password, assume the 24-character randomly generated password I keep in my
password safe is insecure, and demand I complete an email challenge every time
I login because I actually bother to exercise control over browser privacy and
persistent cookies, yet that same website is happy to let me authenticate using
an API key for API access as a single authentication step. No “2FA” here.</p>
<p>API keys are used to secure the highest-stakes APIs that exist today — all of
AWS's services, for example. Yet while API keys seem to be considered an
entirely reasonable and industry standard design approach, passwords are now
considered the unwelcome black sheep whose role as a sufficient criterion for
authentication is viewed with increasing dubiousness. (Moreover, all website
login schemes ultimately rely on some kind of session cookie, which is similar
to an API key in the sense that it is a high-entropy site-issued bearer token.
In other words, all website authentication schemes, “2FA” or not, ultimately
rely on the ability of a client to be enrolled in and use high-entropy
site-issued bearer authentication tokens as the sole criterion of access.<a href="#fn2" id="fn2b"><sup>2</sup></a>)</p>
<p>The fundamental premise is the same: provide token, gain access. It seems to me
that the basic problem here with passwords is that passwords are assumed to
have been chosen by users and users are assumed to be bad at choosing good
passwords.</p>
<p>There are agreed best practices for the handling of passwords, namely, to not
reuse passwords between accounts, use randomly generated passwords, and keep
those unique passwords for each account in a password safe. This raises the
question: if the industry agrees this is the (more or less only) correct way to
handle passwords, why actually allow users to set their own passwords?</p>
<p>Rather than allowing a user to set their own password, passwords can be issued
in exactly the same way as API keys are now: a high-entropy password is
randomly generated by the issuing website, and the user is shown the password
once only and asked to record it. If the password is lost, a new password must
be generated using the same process. The user cannot choose their password, but
can get a new randomly generated one in the event of compromise. The password
essentially becomes indistinguishable from an API key.</p>
<p>If we consider the password safe usage model to be the only reasonable way to
use passwords properly, there doesn't really seem to be any reason to allow any
other usage model than this. There's not really a good reason for a user to be
able to set their own password unless they want to set their password to
something lower in entropy to make it memorable, or reuse it between sites,
both of which are deviations from the “best practice” password safe usage
model.</p>
<p>With this model of password issuance, there is less need to constantly
second-guess the user's security with hazardous approaches like risk-based
authentication. Interestingly, however, it can be argued that this model is in
effect already widely deployed: namely in the form of TOTP “2FA” support.</p>
<p>In enrolling in TOTP-based 2FA with a website, you are given a high-entropy
randomly-generated secret and, for subsequent logins, are required to prove
possession of this secret. In other words, it's a site-generated
non-customisable “password” in much the same vein as I propose above. Moreover,
sites which support TOTP usually use a user's enablement of it as a “not an
idiot” flag and disable any non-deterministic risk-based authentication
mechanisms they may use for people without TOTP enabled. This is congruent
with my premise above that guaranteed use of a high-entropy secret obviates
the need for additional authentication.</p>
<p>Since the user-specified password functionality is now seemingly so distrusted
as a widespread industry practice, it raises the question of why not just
either use only TOTP for login, or issue a password in the same way that TOTP
secrets are issued: randomly and non-customisably.</p>
<p>The only discernible difference between TOTP and a site-generated password is
in how knowledge of the secret is proven. With TOTP, knowledge of the secret is
proven without sending it to the website. With a site-generated password,
knowledge of the secret is proven by sending that secret to the website. This
is a slight security benefit to TOTP. It doesn't seem to provide any useful
security against a compromised or impersonating website (an impersonating
website can just forward the TOTP challenge value to the real website and use
it to login as the user), so its main benefit seems to be to avoid having the
device the user is logging in as be able to glean the secret, in the event that
device is compromised. This is a potential upside, though since on successful
login the compromised client device has access to anything gated by that login
anyway, the benefit seems dubious.</p>
<p>It is interesting to note that TOTP ultimately can be viewed as just another
secret authentication token, like a password, yet is widely referred to as
“2FA”. Having two passwords isn't “2FA”; 2FA about having authenticators from
two different categories of {what you have, what you know, what you are}.</p>
<p>If TOTP is used “correctly”, meaning that the TOTP secret is enrolled onto a
different device than the one that contains your password safe, 2FA is more or
less realised — arguably. (You could also argue it's two copies of “what you
know” but with data partitioned between two devices which are unlikely to be
simultaneously compromised. This demonstrates that the {what you have, what you
know, what you are} triad is not necessarily the be all and end all of
authentication scheme security level classification.)</p>
<p>Of course, you don't necessarily know if someone is using TOTP “correctly”. For
example, whenever I register on some random site which offers TOTP, I enable it
and then put the TOTP secret in the same password safe that contains the
equally high-entropy password I chose. This seemingly pointless act is
obviously not 2FA. The reason I do this is for two reasons:</p>
<ol>
<li><p>it seems to increasingly serve as an “I'm not an idiot” flag and disable
stochastic risk-based authentication based around an assumption people
can't choose secure passwords, in which I might randomly be asked to
an additional challenge the potential necessity of which was not
documented at registration time, and which I may or may not be able to
complete, potentially resulting in account lockout;</p>
</li>
<li><p>it often seems to effectively disable password recovery flows, or at
least render them moot, making account recovery more difficult. Since
I don't lose my secrets I'm happy to assume responsibility for the
possibility of permanently locking myself out in exchange for higher
account security and disabling email as the “master key to all accounts”.</p>
</li>
</ol>
<p>While my own usage patterns are probably somewhat esoteric, in general it's
expected people will store TOTP secrets on a smartphone. However this again
raises questions about whether it really is “2FA” when you consider many people
may be accessing a website from their smartphone in the first place. In fact,
it's likely that a lot of TOTP-based “2FA” is not really 2FA at all because the
user's browser and password safe (e.g. the browser's built in saved password
functionality) and TOTP secret are on the same device and both instances of
“what you know”.</p>
<p>This isn't the only case of websites demanding “2FA”-that-isn't. Many supposed
cases of “2FA” are really 1FA where the single factor required for
authentication is considered to lie in a better category than “what you know”,
or where there are two factors at first glance, but one factor can be used to
reset the other factor.</p>
<p>For example, a site which requires a password and email verification for each
login is not 2FA if access to the same email account can be used to reset the
password; this scheme is no more secure than just requiring email verification
per login. Another example is if a site tries to insist on verifying logins
using SMS messages sent to a user's phone number. Since this (particularly bad)
design is based on the false premise that a user's phone number is more secure
than an email account or any password, such sites will often allow a reset of
all the other factors (like a password) by access to this phone number alone.
This is quite literally 1FA, just with a different single factor.</p>


<p>This again seems to reinforce that the major benefit of pushing people to
enable TOTP is to actually have them adopt a secure “password” and not actually
“2FA”, which is often not actually realised.</p>
<hr>
<p>1. Fun fact: Effectively only 5
digits of your credit card number are secret. PCI standards consider the last
four digits of your credit card number as non-secret — which is why every
e-commerce website is allowed to constantly quote those last four digits back
to you so you know what card they're talking about. What is less known is that
the same standard also specifies that the first 6 digits are also not
sensitive. This means that PCI compliance is fundamentally about protecting the
remaining 6 digits of a 16-digit credit card number. However, the last digit of
a credit card number is of course a check digit, which means of the possible 6
digit values, only 10% can be conceivably valid, meaning that effectively only
5 digits are really secret. This means PayPal allows your password to be reset
given knowledge of a 5 decimal digit secret. <a href="#fn1b">⏎</a></p>

<p>2. After being locked out of one account
by risk-based authentication, while still having access from another, I have
sometimes idly contemplated copying persistent cookies between machines. This
kind of lockout situation in which a password is not enough is particularly
ironic if I happen to have chosen a password which actually has higher entropy
than a site's session cookie. <a href="#fn2b">⏎</a></p>


</article>
          </main>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I thought I wanted to be a professor, then I served on a hiring committee (2021) (122 pts)]]></title>
            <link>https://www.science.org/content/article/i-thought-i-wanted-be-faculty-member-then-i-served-hiring-committee</link>
            <guid>36825204</guid>
            <pubDate>Sat, 22 Jul 2023 11:00:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/article/i-thought-i-wanted-be-faculty-member-then-i-served-hiring-committee">https://www.science.org/content/article/i-thought-i-wanted-be-faculty-member-then-i-served-hiring-committee</a>, See on <a href="https://news.ycombinator.com/item?id=36825204">Hacker News</a></p>
Couldn't get https://www.science.org/content/article/i-thought-i-wanted-be-faculty-member-then-i-served-hiring-committee: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Plane – open-source Jira alternative (272 pts)]]></title>
            <link>https://plane.so</link>
            <guid>36824450</guid>
            <pubDate>Sat, 22 Jul 2023 08:21:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://plane.so">https://plane.so</a>, See on <a href="https://news.ycombinator.com/item?id=36824450">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>START SIMPLE</h2><p>Simple, yet great UX, so you can get started in minutes</p><p>Start as a basic task tracking tool. Customize your workflows, based on Backlog, Unstarted, Started, Completed issues, in just a few seconds, and view it as you like.</p><dl><div><p><span><dt>Visualize as you like.</dt> <dd>Switch between List, Kanban, or Calendar across any views within clicks.</dd></span></p></div><div><p><span><dt>Custom workflows.</dt> <dd>Define unique issue states for each team, and extend them the way you like.</dd></span></p></div><div><p><span><dt>Easy Importers.</dt> <dd>Import issues from your existing issue tracker into Plane in just couple of minutes. Coming soon for self-hosted.</dd></span></p></div></dl></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bun v0.7.0 (173 pts)]]></title>
            <link>https://bun.sh/blog/bun-v0.7.0</link>
            <guid>36823723</guid>
            <pubDate>Sat, 22 Jul 2023 06:04:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bun.sh/blog/bun-v0.7.0">https://bun.sh/blog/bun-v0.7.0</a>, See on <a href="https://news.ycombinator.com/item?id=36823723">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>We're pleased to announce Bun v0.7.0, a big leap forward in terms of Node.js compatibility.</p><p>We're hiring C/C++ and Zig engineers to build the future of JavaScript! <a href="https://bun.sh/careers">Join our team →</a></p><p>Bun is an incredibly fast JavaScript runtime, bundler, transpiler, and package manager — all in one. Over the past couple months, we've been releasing a lot of changes to Bun recently, here's a recap in case you missed it:</p><ul><li><a href="https://bun.sh/blog/bun-v0.6.10"><code>v0.6.10</code></a> - <code>fs.watch()</code>, <code>bun install</code> bug fixes, <code>bun test</code> features, and improved CommonJS support</li><li><a href="https://bun.sh/blog/bun-v0.6.10"><code>v0.6.11</code></a> - Addressed a release build issue from <code>v0.6.10</code>.</li><li><a href="https://bun.sh/blog/bun-v0.6.12"><code>v0.6.12</code></a> - Sourcemap support in <code>Error.stack</code>, <code>Bun.file().exists()</code>, and Node.js bug fixes.</li><li><a href="https://bun.sh/blog/bun-v0.6.13"><code>v0.6.13</code></a> - Implemented mock <code>Date</code>, faster base64 encoding, and fixes for <code>WebSocket</code> and <code>node:tls</code>.</li><li><a href="https://bun.sh/blog/bun-v0.6.14"><code>v0.6.14</code></a> - <code>process.memoryUsage()</code>, <code>process.cpuUsage()</code>, <code>process.on('beforeExit', cb)</code>, <code>process.on('exit', cb)</code> and crash fixes</li></ul><p>To install Bun:</p><div id="RWUelGtIHM"><div><p>curl</p><div><pre><code><span><span>curl -fsSL https://bun.sh/install </span><span>|</span><span> bash</span></span></code></pre></div></div><div><p>docker</p><div><pre><code><span><span>docker run --rm --init --ulimit memlock=-1:-1 oven/bun</span></span></code></pre></div></div></div><p>To upgrade Bun:</p><h2 level="2" anchor-id="vite-support"><a name="vite-support"></a><a href="#vite-support">Vite support</a></h2><p><em>Support is still experimental and non-optimized.</em> Vite does not use Bun's bundler, module resolver, or transpiler, even when run with Bun.</p><p>With the recent strides towards Node.js API compatibilty, Bun can now run <a href="https://vitejs.dev/"><code>vite dev</code></a>, thanks to <a href="https://github.com/paperdave">@paperdave</a>! This is one of Bun's <a href="https://github.com/oven-sh/bun/issues/250">most upvoted issues</a>.</p><p>To try this with one of Vite's starter projects, use <code>bunx</code>:</p><p>Then start the dev server.</p><p><strong>Why <code>--bun</code>?</strong> The <code>--bun</code> flag tells Bun to override the <code>#! /usr/bin/env node</code> shebang in the <code>vite</code> CLI and execute the file with Bun instead of Node.js. In a future release this will be the default behavior.</p><figure><a href="https://user-images.githubusercontent.com/709451/254804727-725bf67c-c60f-4eec-b472-07d52b650a93.gif"><img src="https://user-images.githubusercontent.com/709451/254804727-725bf67c-c60f-4eec-b472-07d52b650a93.gif" caption="Hot module reloading with Vite"></a><figcaption>Hot module reloading with Vite</figcaption></figure><p>This is a great way to develop frontend code with Bun's APIs on the server when building frontend apps.</p><p>Note: if you run <code>bun vite dev</code> without <code>-b</code> or <code>--bun</code>, it will still run in Node.js as <code>vite</code>'s CLI specifies <code>#!/usr/bin/env node</code> at the top which tells Bun (and other software on your computer) to run it in Node.js.</p><h2 level="2" anchor-id="concurrency-with-worker"><a name="concurrency-with-worker"></a><a href="#concurrency-with-worker">Concurrency with <code>Worker</code></a></h2><p>Bun now supports <a href="https://developer.mozilla.org/en-US/docs/Web/API/Worker"><code>Worker</code></a> which allows you to run another JavaScript instance in a separate thread. In Bun, workers support ES Modules, CommonJS, TypeScript, JSX, and the rest of Bun's features with no extra configuration.</p><p>As in browsers, <code>Worker</code> is a global class. To create a worker from the main thread:</p><div><p>main.ts</p><div><pre><code><span><span>const</span><span> worker </span><span>=</span><span> </span><span>new</span><span> </span><span>Worker</span><span>(</span><span>"</span><span>./worker.ts</span><span>"</span><span>);</span></span>
<span><span>worker.</span><span>addEventListener</span><span>(</span><span>"</span><span>message</span><span>"</span><span>, (</span><span>event</span><span>:</span><span> </span><span>MessageEvent</span><span>) </span><span>=&gt;</span><span> {</span></span>
<span><span>  console.</span><span>log</span><span>(</span><span>"</span><span>Message from worker:</span><span>"</span><span>, event.data);</span></span>
<span><span>});</span></span>
<span><span>worker.</span><span>postMessage</span><span>(</span><span>"</span><span>Hello from main thread!</span><span>"</span><span>);</span></span>
<span></span></code></pre></div></div><p>On the worker thread:</p><div><p>worker.ts</p><div><pre><code><span><span>addEventListener</span><span>(</span><span>"</span><span>message</span><span>"</span><span>, (</span><span>event</span><span>:</span><span> </span><span>MessageEvent</span><span>) </span><span>=&gt;</span><span> {</span></span>
<span><span>  console.</span><span>log</span><span>(</span><span>"</span><span>Message from main thread:</span><span>"</span><span>, event.data);</span></span>
<span><span>  </span><span>postMessage</span><span>(</span><span>"</span><span>Hello from worker thread!</span><span>"</span><span>);</span></span>
<span><span>});</span></span>
<span></span>
<span></span></code></pre></div></div><p>This release <em>does not</em> include support for the <code>node:worker_threads</code> module, but this unblocks the work necessary for us to implement it in Bun.</p><p>The following globals have been added to Bun:</p><ul><li><code>postMessage</code></li><li><code>addEventListener</code></li><li><code>removeEventListener</code></li><li><code>onmessage</code> (getter/setter)</li></ul><p>Refer to <a href="https://bun.sh/docs/api/workers">Docs &gt; API &gt; Workers</a> to learn more about using <code>Worker</code> in Bun.</p><h3 level="3" anchor-id="using-comlink-with-bun"><a name="using-comlink-with-bun"></a><a href="#using-comlink-with-bun">Using <code>comlink</code> with Bun</a></h3><p>The popular <a href="https://github.com/GoogleChromeLabs/comlink"><code>comlink</code></a> package works in Bun without changes. This library makes it easier to share functions and state between main and worker threads.</p><h3 level="3" anchor-id="structuredclone-support"><a name="structuredclone-support"></a><a href="#structuredclone-support"><code>structuredClone()</code> support</a></h3><p>As in browsers, <code>postMessage</code> serializes messages using the <em>structured clone algorithm</em>. Bun now exposes this via the Web-standard<a href="https://developer.mozilla.org/en-US/docs/Web/API/structuredClone"><code>structuredClone()</code></a> function, which provides a mechanism for deep-cloning objects. It is similar to <code>JSON.parse(JSON.stringify(obj))</code>, but it supports more types.</p><div><pre><code><span><span>const</span><span> obj </span><span>=</span><span> { a</span><span>:</span><span> </span><span>1</span><span>, b</span><span>:</span><span> </span><span>2</span><span> };</span></span>
<span><span>const</span><span> clone </span><span>=</span><span> </span><span>structuredClone</span><span>(obj);</span></span>
<span></span></code></pre></div><h2 level="2" anchor-id="asynclocalstorage-support"><a name="asynclocalstorage-support"></a><a href="#asynclocalstorage-support"><code>AsyncLocalStorage</code> support</a></h2><p>Bun now implements <code>AsyncLocalStorage</code> from the <code>node:async_hooks</code> module. This provides a mechanism for passing contextual data through a chain of asynchronous code. This is a big step towards supporting Next.js and other frameworks that rely on this module.</p><div><pre><code><span><span>import</span><span> { AsyncLocalStorage } </span><span>from</span><span> </span><span>"</span><span>node:async_hooks</span><span>"</span><span>;</span></span>
<span></span>
<span><span>const</span><span> requestId </span><span>=</span><span> </span><span>new</span><span> </span><span>AsyncLocalStorage</span><span>();</span></span>
<span><span>let</span><span> lastId </span><span>=</span><span> </span><span>0</span><span>;</span></span>
<span></span>
<span><span>Bun.</span><span>serve</span><span>({</span></span>
<span><span>  </span><span>fetch</span><span>(</span><span>request</span><span>) {</span></span>
<span><span>    lastId</span><span>++</span><span>;</span></span>
<span><span>    </span><span>// Run the callback with 'requestId' set. async_hooks will preserve</span></span>
<span><span>    </span><span>// this value through any chain of asynchronous code.</span></span>
<span><span>    </span><span>return</span><span> requestId.</span><span>run</span><span>(lastId, </span><span>async</span><span> () </span><span>=&gt;</span><span> {</span></span>
<span><span>      console.</span><span>log</span><span>(</span><span>"</span><span>Request ID: ${requestId getStore ()}</span><span>"</span><span>);</span></span>
<span><span>      </span><span>await</span><span> Bun.</span><span>sleep</span><span>(</span><span>500</span><span>);</span></span>
<span><span>      </span><span>// Even if new requests mutate 'lastId', 'requestId' is still preserved.</span></span>
<span><span>      </span><span>return</span><span> </span><span>new</span><span> </span><span>Response</span><span>(</span><span>"</span><span>Request ID: ${requestId. getStore ()}</span><span>"</span><span>);</span></span>
<span><span>    });</span></span>
<span><span>  },</span></span>
<span><span>});</span></span>
<span></span></code></pre></div><h2 level="2" anchor-id="reduce-memory-usage-with-bun-smol"><a name="reduce-memory-usage-with-bun-smol"></a><a href="#reduce-memory-usage-with-bun-smol">Reduce memory usage with <code>bun --smol</code></a></h2><p><code>bun --smol</code> is a new CLI flag which configures the JavaScriptCore heap size to be smaller and grow slower, at a cost to runtime performance. This is useful for running Bun in memory-constrained environments.</p><p>To avoid setting the flag manually, you can set this as a default in <code>bunfig.toml</code>.</p><div><p>bunfig.toml</p><div><pre><code><span><span>smol</span><span> </span><span>=</span><span> </span><span>true</span></span>
<span></span>
<span><span>[</span><span>test</span><span>]</span></span>
<span><span># set it only for tests, if you want</span></span>
<span><span>smol</span><span> </span><span>=</span><span> </span><span>true</span></span>
<span></span></code></pre></div></div><h2 level="2" anchor-id="bail-in-bun-test"><a name="bail-in-bun-test"></a><a href="#bail-in-bun-test"><code>--bail</code> in <code>bun test</code></a></h2><p>Running <code>bun test</code> with <code>--bail=1</code> will exit after the first test failure.</p><div><pre><code><span><span>bun test v0.7.0</span></span>
<span><span></span></span>
<span><span>✓ test1 [0.02ms]</span></span>
<span><span>test2.test.js:</span></span>
<span><span>1 | import {test, expect} from 'bun:test';</span></span>
<span><span>2 |</span></span>
<span><span>3 | test('test2', () =&gt; {</span></span>
<span><span>4 |   expect(2).toEqual(3);</span></span>
<span><span>      ^</span></span>
<span><span>error: expect(received).toEqual(expected)</span></span>
<span><span>Expected: 3</span></span>
<span><span>Received: 2</span></span>
<span><span>      at /Users/colinmcd94/Documents/bun/fun/test/test2.test.js:13:8</span></span>
<span><span>✗ test2 [0.18ms]</span></span>
<span><span>Ran 2 tests across 2 files. [8.00ms]</span></span>
<span><span>Bailed out after 1 failures</span></span></code></pre></div><p>This is useful for CI environments or when you want to stop running tests after the first failure. Thanks to <a href="https://github.com/TiranexDev">@TiranexDev</a> for landing this improvement!</p><h2 level="2" anchor-id="bun-readablestreamtoformdata"><a name="bun-readablestreamtoformdata"></a><a href="#bun-readablestreamtoformdata"><code>Bun.readableStreamToFormData()</code></a></h2><p>Bun now exposes a helper for converting a <a href="https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream">ReadableStream</a> into <a href="https://developer.mozilla.org/en-US/docs/Web/API/FormData">FormData</a>.</p><p>It supports multipart form data.</p><div><pre><code><span><span>import</span><span> { readableStreamToFormData } </span><span>from</span><span> </span><span>"</span><span>bun</span><span>"</span><span>;</span></span>
<span></span>
<span><span>// without dashes</span></span>
<span><span>const</span><span> boundary </span><span>=</span><span> </span><span>"</span><span>WebKitFormBoundary</span><span>"</span><span> </span><span>+</span><span> </span><span>Math</span><span>.</span><span>random</span><span>().</span><span>toString</span><span>(</span><span>16</span><span>).</span><span>slice</span><span>(</span><span>2</span><span>);</span></span>
<span></span>
<span><span>const</span><span> myStream </span><span>=</span><span> </span><span>getStreamFromSomewhere</span><span>(); </span><span>// ...</span></span>
<span><span>const</span><span> formData </span><span>=</span><span> </span><span>await</span><span> Bun.</span><span>readableStreamToFormData</span><span>(stream, boundary);</span></span>
<span><span>formData.</span><span>get</span><span>(</span><span>"</span><span>foo</span><span>"</span><span>); </span><span>// "bar"</span></span>
<span></span></code></pre></div><p>It also supports URL-encoded form data:</p><div><pre><code><span><span>import</span><span> { readableStreamToFormData } </span><span>from</span><span> </span><span>"</span><span>bun</span><span>"</span><span>;</span></span>
<span></span>
<span><span>const</span><span> stream </span><span>=</span><span> </span><span>new</span><span> </span><span>Response</span><span>(</span><span>"</span><span>hello=123</span><span>"</span><span>).body;</span></span>
<span><span>const</span><span> formData </span><span>=</span><span> </span><span>await</span><span> </span><span>readableStreamToFormData</span><span>(stream);</span></span>
<span><span>formData.</span><span>get</span><span>(</span><span>"</span><span>hello</span><span>"</span><span>); </span><span>// "123"</span></span>
<span></span></code></pre></div><p>We added this to help fix a bug causing <code>request.formData()</code> and <code>response.formData()</code> to hang when the body was a <code>ReadableStream</code> from JavaScript.</p><h2 level="2" anchor-id="serialize-and-deserialize-in-bun-jsc"><a name="serialize-and-deserialize-in-bun-jsc"></a><a href="#serialize-and-deserialize-in-bun-jsc"><code>serialize</code> and <code>deserialize</code> in <code>bun:jsc</code></a></h2><p>The <code>bun:jsc</code> module now exports <code>serialize()</code> and <code>deserialize()</code>, which convert JavaScript objects to <code>ArrayBuffer</code> and back.</p><div><pre><code><span><span>import</span><span> { serialize, deserialize } </span><span>from</span><span> </span><span>"</span><span>bun:jsc</span><span>"</span><span>;</span></span>
<span><span>import</span><span> { deepEquals } </span><span>from</span><span> </span><span>"</span><span>bun</span><span>"</span><span>;</span></span>
<span></span>
<span><span>const</span><span> obj </span><span>=</span><span> { a</span><span>:</span><span> </span><span>1</span><span>, b</span><span>:</span><span> </span><span>2</span><span> };</span></span>
<span><span>const</span><span> buffer </span><span>=</span><span> </span><span>serialize</span><span>(obj);</span></span>
<span><span>const</span><span> clone </span><span>=</span><span> </span><span>deserialize</span><span>(buffer);</span></span>
<span></span>
<span><span>if</span><span> (</span><span>deepEquals</span><span>(obj, clone)) {</span></span>
<span><span>  console.</span><span>log</span><span>(</span><span>"</span><span>They are equal!</span><span>"</span><span>);</span></span>
<span><span>}</span></span>
<span></span></code></pre></div><p>The <code>node:v8</code> module exports these same functions, for compatibility with existing libraries that serialize/deserialize data between processes.</p><h2 level="2" anchor-id="websocket-improvements"><a name="websocket-improvements"></a><a href="#websocket-improvements"><code>WebSocket</code> improvements</a></h2><p>You can now manually send &amp; receive WebSocket <code>ping</code> and <code>pong</code> frames.</p><div><pre><code><span><span>const</span><span> ws </span><span>=</span><span> </span><span>new</span><span> </span><span>WebSocket</span><span>(</span><span>"</span><span>wss://echo.websocket.org</span><span>"</span><span>);</span></span>
<span><span>ws.</span><span>addEventListener</span><span>(</span><span>"</span><span>pong</span><span>"</span><span>, () </span><span>=&gt;</span><span> {</span></span>
<span><span>  console.</span><span>log</span><span>(</span><span>"</span><span>Received pong</span><span>"</span><span>);</span></span>
<span><span>});</span></span>
<span><span>ws.</span><span>ping</span><span>();</span></span>
<span></span></code></pre></div><p>This applies to both <code>ServerWebSocket</code> and <code>WebSocket</code>.</p><h3 level="3" anchor-id="nodebuffer-is-now-the-default-binarytype"><a name="nodebuffer-is-now-the-default-binarytype"></a><a href="#nodebuffer-is-now-the-default-binarytype"><code>nodebuffer</code> is now the default <code>binaryType</code></a></h3><p>By default, the <code>binaryType</code> for <code>WebSocket</code> and <code>ServerWebSocket</code> in Bun is now <code>nodebuffer</code> This means that binary data frames in <code>WebSocket</code> will be <code>Buffer</code> instances, instead of <code>ArrayBuffer</code> (as before). This is to match the bahavior of the <code>ws</code> package.</p><div><pre><code><span><span>const</span><span> ws </span><span>=</span><span> </span><span>new</span><span> </span><span>WebSocket</span><span>(</span><span>"</span><span>wss://echo.websocket.org</span><span>"</span><span>);</span></span>
<span></span>
<span><span>ws.</span><span>addEventListener</span><span>(</span><span>"</span><span>message</span><span>"</span><span>, (</span><span>event</span><span>:</span><span> </span><span>MessageEvent</span><span>) </span><span>=&gt;</span><span> {</span></span>
<span><span>  console.</span><span>log</span><span>(event.data </span><span>instanceof</span><span> </span><span>Buffer</span><span>); </span><span>// true</span></span>
<span><span>});</span></span>
<span></span></code></pre></div><p>To change it back to <code>ArrayBuffer</code>, set <code>ws.binaryType = "arraybuffer"</code>.</p><div><pre><code><span><span>const</span><span> ws </span><span>=</span><span> </span><span>new</span><span> </span><span>WebSocket</span><span>(</span><span>"</span><span>wss://echo.websocket.org</span><span>"</span><span>);</span></span>
<span><span>ws.binaryType </span><span>=</span><span> </span><span>"</span><span>arraybuffer</span><span>"</span><span>;</span></span>
<span></span>
<span><span>ws.</span><span>addEventListener</span><span>(</span><span>"</span><span>message</span><span>"</span><span>, (</span><span>event</span><span>:</span><span> </span><span>MessageEvent</span><span>) </span><span>=&gt;</span><span> {</span></span>
<span><span>  event.data; </span><span>// ArrayBuffer</span></span>
<span><span>});</span></span>
<span></span></code></pre></div><p>(Note that in browsers it is <code>Blob</code> by default.)</p><h3 level="3" anchor-id="close-reasons-propagate-correctly-now"><a name="close-reasons-propagate-correctly-now"></a><a href="#close-reasons-propagate-correctly-now">Close reasons propagate correctly now</a></h3><p>A bug was fixed where <code>WebSocket</code> would not propagate close reasons from third-party servers correctly. Thanks to <a href="https://github.com/electroid">@Electroid</a> for landing these improvements!</p><h2 level="2" anchor-id="node-js-compatibility-improvements"><a name="node-js-compatibility-improvements"></a><a href="#node-js-compatibility-improvements">Node.js compatibility improvements</a></h2><p>This release adds several additional improvements to Node.js compatibility.</p><h3 level="3" anchor-id="improvements-to-tlssocket-from-node-tls"><a name="improvements-to-tlssocket-from-node-tls"></a><a href="#improvements-to-tlssocket-from-node-tls">Improvements to <code>TLSSocket</code> from <code>node:tls</code></a></h3><p>The following methods were implemented on the <code>TLSSocket</code> class. Thanks to <a href="https://github.com/cirospaciari">@cirospaciari</a> for landing these improvements in <a href="https://github.com/oven-sh/bun/pull/3596"><code>#3596</code></a>.</p><ul><li><code>.getPeerFinished()</code></li><li><code>.getFinished()</code></li><li><code>.getProtocol()</code></li><li><code>.getSharedSigalgs()</code></li><li><code>.isSessionReused()</code></li><li><code>.exportKeyingMaterial()</code></li><li><code>.setMaxSendFragment()</code></li><li><code>.getPeerCertificate()</code></li><li><code>.getCertificate()</code></li><li><code>.enableTrace()</code></li><li><code>.disableRenegotiation()</code></li><li><code>.getCipher()</code></li><li><code>.getEphemeralKeyInfo()</code></li><li><code>.getTLSTicket()</code></li><li><code>.getSession()</code></li><li><code>.setSession()</code></li></ul><h3 level="3" anchor-id="base64url-hashes-are-no-longer-data-urls"><a name="base64url-hashes-are-no-longer-data-urls"></a><a href="#base64url-hashes-are-no-longer-data-urls"><code>base64url</code> hashes are no longer <code>data:</code> urls</a></h3><p>Previously, Bun would prepend <code>data:base64,</code> to the output of <code>crypto.createHash("sha256").digest("base64url")</code>. This is not what Node.js does, and it was causing issues with libraries that expected the output to be the same string as Node.js.</p><div><pre><code><span><span>crypto.</span><span>createHash</span><span>(</span><span>"</span><span>sha256</span><span>"</span><span>).</span><span>update</span><span>(</span><span>"</span><span>abc</span><span>"</span><span>).</span><span>digest</span><span>(</span><span>"</span><span>base64url</span><span>"</span><span>);</span></span>
<span></span>
<span><span>//        Node.js:  "ungWv48Bz-pBQUDeXa4iI7ADYaOWF3qctBD_YfIAFa0"</span></span>
<span><span>//     Bun v0.7.0:  "ungWv48Bz-pBQUDeXa4iI7ADYaOWF3qctBD_YfIAFa0"</span></span>
<span><span>// &lt;= Bun v0.6.14:  "data:base64,ungWv48Bz-pBQUDeXa4iI7ADYaOWF3qctBD_YfIAFa0="</span></span>
<span></span></code></pre></div><h3 level="3" anchor-id="terminal-dimensions-with-process-stdout-columns-and-process-stdout-rows"><a name="terminal-dimensions-with-process-stdout-columns-and-process-stdout-rows"></a><a href="#terminal-dimensions-with-process-stdout-columns-and-process-stdout-rows">Terminal dimensions with <code>process.stdout.columns</code> and <code>process.stdout.rows</code></a></h3><p><code>process.stdout</code> and <code>process.stderr</code> now support reading the terminal window's dimensions.</p><div><pre><code><span><span>const</span><span> { columns, rows } </span><span>=</span><span> process.stdout;</span></span>
<span><span>const</span><span> [columns, rows] </span><span>=</span><span> process.stdout.</span><span>getWindowSize</span><span>();</span></span>
<span><span>const</span><span> { columns, rows } </span><span>=</span><span> process.stderr;</span></span>
<span><span>const</span><span> [columns, rows] </span><span>=</span><span> process.stderr.</span><span>getWindowSize</span><span>();</span></span>
<span></span></code></pre></div><p>You can also use <code>process.stdout.getWindowSize()</code> if you want both dimensions at once.</p><h2 level="2" anchor-id="bugfixes"><a name="bugfixes"></a><a href="#bugfixes">Bugfixes</a></h2><p><a href="https://github.com/oven-sh/bun/pull/3656"><code>#3656</code></a> <strong>A memory leak</strong> in await <code>new Response(latin1String).arrayBuffer()</code> and <code>await Response.json(obj).json()</code> has been fixed.</p><p>After:</p><div><pre><code><span><span>cpu: Apple M1 Max</span></span>
<span><span>runtime: bun </span><span>0.7</span><span>.</span><span>0</span><span> (arm64</span><span>-</span><span>darwin)</span></span>
<span></span>
<span><span>benchmark                                                        </span><span>time</span><span> (avg)             (min … max)       p75       p99      p995</span></span>
<span><span>---------------------------------------------------------------------------------------------------</span><span> </span><span>-----------------------------</span></span>
<span><span>new</span><span> </span><span>Response</span><span>().</span><span>arrayBuffer</span><span>() (</span><span>new</span><span> string each call, latin1)    </span><span>12.9</span><span> µs</span><span>/</span><span>iter</span><span>      (</span><span>625</span><span> ns … </span><span>4.18</span><span> ms)      </span><span>1</span><span> µs </span><span>567.17</span><span> µs </span><span>711.79</span><span> µs</span></span>
<span><span>new</span><span> </span><span>Response</span><span>().</span><span>arrayBuffer</span><span>() (</span><span>new</span><span> string each call, utf16)    </span><span>12.85</span><span> µs</span><span>/</span><span>iter</span><span>     (</span><span>1.67</span><span> µs … </span><span>1.56</span><span> ms)   </span><span>2.17</span><span> µs </span><span>462.75</span><span> µs </span><span>621.13</span><span> µs</span></span>
<span><span>new</span><span> </span><span>Response</span><span>().</span><span>arrayBuffer</span><span>() (existing string, latin1)         </span><span>6.53</span><span> µs</span><span>/</span><span>iter</span><span>     (</span><span>6.21</span><span> µs … </span><span>7.07</span><span> µs)   </span><span>6.64</span><span> µs   </span><span>7.07</span><span> µs   </span><span>7.07</span><span> µs</span></span>
<span></span>
<span><span>Peak memory usage: </span><span>49</span><span> MB</span></span>
<span></span></code></pre></div><p>Before:</p><div><pre><code><span><span>cpu: Apple M1 Max</span></span>
<span><span>runtime: bun </span><span>0.7</span><span>.</span><span>0</span><span> (arm64</span><span>-</span><span>darwin)</span></span>
<span></span>
<span><span>benchmark                                                        </span><span>time</span><span> (avg)             (min … max)       p75       p99      p995</span></span>
<span><span>---------------------------------------------------------------------------------------------------</span><span> </span><span>-----------------------------</span></span>
<span><span>new</span><span> </span><span>Response</span><span>().</span><span>arrayBuffer</span><span>() (</span><span>new</span><span> string each call, latin1)   </span><span>13.51</span><span> µs</span><span>/</span><span>iter</span><span>       (</span><span>541</span><span> ns … </span><span>3.2</span><span> ms)   </span><span>1.92</span><span> µs </span><span>553.42</span><span> µs </span><span>709.92</span><span> µs</span></span>
<span><span>new</span><span> </span><span>Response</span><span>().</span><span>arrayBuffer</span><span>() (</span><span>new</span><span> string each call, utf16)    </span><span>13.07</span><span> µs</span><span>/</span><span>iter</span><span>     (</span><span>1.71</span><span> µs … </span><span>3.43</span><span> ms)   </span><span>2.13</span><span> µs </span><span>451.21</span><span> µs </span><span>651.67</span><span> µs</span></span>
<span><span>new</span><span> </span><span>Response</span><span>().</span><span>arrayBuffer</span><span>() (existing string, latin1)         </span><span>6.25</span><span> µs</span><span>/</span><span>iter</span><span>     (</span><span>5.79</span><span> µs … </span><span>6.81</span><span> µs)    </span><span>6.4</span><span> µs   </span><span>6.81</span><span> µs   </span><span>6.81</span><span> µs</span></span>
<span></span>
<span><span>Peak memory usage: </span><span>292</span><span> MB</span></span>
<span></span></code></pre></div><p><a href="https://github.com/oven-sh/bun/issues/3659"><code>#3659</code></a> A <strong>module resolution bug</strong> causing the <code>graphql</code> package to import both CommonJS and ESM versions of the same modules has been fixed. This was fixed by aligning the package.json main field order closer to what Node.js does.</p><div><pre><code><span><span>error: Cannot use GraphQLScalarType "String" from another module or realm.</span></span>
<span><span></span></span>
<span><span>Ensure that there is only one instance of "graphql" in the node_modules</span></span>
<span><span>directory. If different versions of "graphql" are the dependencies of other</span></span>
<span><span>relied on modules, use "resolutions" to ensure only one version is installed.</span></span>
<span><span></span></span>
<span><span>https://yarnpkg.com/en/docs/selective-version-resolutions</span></span>
<span><span></span></span>
<span><span>Duplicate "graphql" modules cannot be used at the same time since different</span></span>
<span><span>versions may have different capabilities and behavior. The data from one</span></span>
<span><span>version used in the function from another could produce confusing and</span></span>
<span><span>spurious results.</span></span>
<span><span></span></span></code></pre></div><p><a href="https://github.com/oven-sh/bun/pull/3663"><code>#3663</code></a> A <strong>bug in bun:test lifecycle hooks</strong> caused <code>beforeAll</code> and <code>afterAll</code> to not run when no tests were defined in a scope. This has been fixed.</p><p><a href="https://github.com/oven-sh/bun/issues/3670"><code>#3670</code></a> A <strong>bug when .env pointed to a directory</strong> caused Bun to crash. This has been fixed.</p><p><a href="https://github.com/oven-sh/bun/issues/3682"><code>#3682</code></a> A <strong>TypeScript parser bug related to ternaries with spread operators</strong> has been fixed</p><h3 level="3" anchor-id="changelog"><a name="changelog"></a><a href="#changelog">Changelog</a></h3><div><table><thead></thead><tbody><tr><td><a href="https://github.com/oven-sh/bun/pull/3253">#3253</a></td><td>feat(bun/test): Implement "bail" option for "bun test" by @TiranexDev</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3608">#3608</a></td><td>Improve our internal typedefs by @paperdave</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3257">#3257</a></td><td>Improvements to <code>WebSocket</code> and <code>ServerWebSocket</code> by @Electroid</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3630">#3630</a></td><td>$npm_lifecycle_event should have the value of the last call by @TiranexDev</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3631">#3631</a></td><td>Update docs/types for process by @colinhacks</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3637">#3637</a></td><td>structured clone by @dylan-conway</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3650">#3650</a></td><td>docs: add one missing line in typescript.md by @capaj</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3643">#3643</a></td><td>Fixes #3641 by @Jarred-Sumner</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3614">#3614</a></td><td>Support <code>napi_wrap</code> in constructors by @Jarred-Sumner</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3645">#3645</a></td><td>Implement Workers by @Jarred-Sumner</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3654">#3654</a></td><td>Fixes base64url encoding for crypto by @Jarred-Sumner</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3655">#3655</a></td><td>20% faster <code>deserialize</code> for structuredClone / postMessage with objects by @Jarred-Sumner</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3626">#3626</a></td><td>workaround <code>readable-stream</code> compatibility by @alexlamsl</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3662">#3662</a></td><td>[install] handle duplicated workspace declarations gracefully by @alexlamsl</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3664">#3664</a></td><td>package json <code>main</code> field extension order by @dylan-conway</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3596">#3596</a></td><td>[tls] General compatibility improvements by @cirospaciari</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3667">#3667</a></td><td>zig upgrade by @dylan-conway</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3671">#3671</a></td><td>fix(tls) patch checkServerIdentity by @cirospaciari</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3672">#3672</a></td><td>feature(constants) add constants/node:constants module and tests(prisma) use prima 5.0.0 + use same connection for postgres, add prisma mssql (disabled for now) by @cirospaciari</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3678">#3678</a></td><td>Better error for workspace dependency not found by @Jarred-Sumner</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3683">#3683</a></td><td>move constants module to cpp by @cirospaciari</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3687">#3687</a></td><td>fix #3682 by @dylan-conway</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3680">#3680</a></td><td>fix createDecipheriv by @cirospaciari</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3688">#3688</a></td><td>update root certificates and add tls.rootCertificates by @cirospaciari</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3089">#3089</a></td><td>Implement <code>AsyncLocalStorage</code> by @paperdave</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3693">#3693</a></td><td>Fix browser bundled string_decoder by @paperdave</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3694">#3694</a></td><td>Fix vite by @paperdave</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3698">#3698</a></td><td>Fixes #3670 by @Jarred-Sumner</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3697">#3697</a></td><td>Support streams in response.formData() &amp; request.formData, introduce Bun.readableStreamToFormData() by @Jarred-Sumner</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3706">#3706</a></td><td>Improve types for FFI number types by @colinhacks</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3707">#3707</a></td><td>fix start delay on Worker by @cirospaciari</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3709">#3709</a></td><td>set <code>_preload_modules</code> to empty array by @dylan-conway</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3708">#3708</a></td><td>fix 3702 by @dylan-conway</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3692">#3692</a></td><td>Pass constructor arguments to TextDecoder by @Parzival-3141</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3711">#3711</a></td><td>Fix builtins generator <code>$lazy</code> by @paperdave</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3710">#3710</a></td><td>fix directory caching with workaround by @paperdave</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3713">#3713</a></td><td>Fix builtins again by @paperdave</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3714">#3714</a></td><td>fix process.exit status code handling by @paperdave</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3715">#3715</a></td><td>fix <code>isFIFO</code> by @dylan-conway</td></tr><tr><td><a href="https://github.com/oven-sh/bun/pull/3717">#3717</a></td><td>string escape edgecase by @dylan-conway</td></tr></tbody></table></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Putting the “You” in CPU (216 pts)]]></title>
            <link>https://cpu.land/</link>
            <guid>36823605</guid>
            <pubDate>Sat, 22 Jul 2023 05:38:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cpu.land/">https://cpu.land/</a>, See on <a href="https://news.ycombinator.com/item?id=36823605">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<h2 id="from-the-beginning">
				From the beginning…
				<a href="https://github.com/hackclub/putting-the-you-in-cpu/tree/main/src/content/chapters/0-intro.mdx" target="_blank">Edit on GitHub</a>
			</h2>

			<p>I’ve done <a href="https://github.com/kognise" rel="noopener noreferrer" target="_blank">a lot of things with computers</a>, but I’ve always had a gap in my knowledge: what exactly happens when you run a program on your computer? I thought about this gap — I had most of the requisite low-level knowledge, but I was struggling to piece everything together. Are programs really executing directly on the CPU, or is something else going on? I’ve used syscalls, but how do they <em>work</em>? What are they, really? How do multiple programs run at the same time?</p><p>I cracked and started figuring as much out as possible. There aren’t many comprehensive systems resources if you aren’t going to college, so I had to sift through tons of different sources of varying quality and sometimes conflicting information. A couple weeks of research and almost 40 pages of notes later, I think I have a much better idea of how computers work from startup to program execution. I would’ve killed for one solid article explaining what I learned, so I’m writing the article that I wished I had.</p><p>And you know what they say… you only truly understand something if you can explain it to someone else.</p><blockquote><p>In a hurry? Feel like you know this stuff already?</p><p><a href="https://cpu.land/how-to-run-a-program">Read chapter 3</a> and I guarantee you will learn something new. Unless you’re like, Linus Torvalds himself.</p></blockquote>

			<p><a href="https://cpu.land/the-basics">
				Continue to Chapter 1: The “Basics”
				
			</a>
		</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple's interactive television box: Hacking the set top box System 7.1 in ROM (170 pts)]]></title>
            <link>http://oldvcr.blogspot.com/2023/07/apples-interactive-television-box.html</link>
            <guid>36823565</guid>
            <pubDate>Sat, 22 Jul 2023 05:30:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://oldvcr.blogspot.com/2023/07/apples-interactive-television-box.html">http://oldvcr.blogspot.com/2023/07/apples-interactive-television-box.html</a>, See on <a href="https://news.ycombinator.com/item?id=36823565">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-7628653847015489091" itemprop="description articleBody">
<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgT5ldv1fTGlQrFwP9YvESyKNAoqxHlTII0uFm4NYQRJ8gvKaGvGh0Y-2mgZNL9w-TNhZFhb77W_OvZDlmPvrRHmvLf4xlIUXLH7BbsJuOEtCPRKP3-6T3W6rUgrGEo7FDsFNujaetgxrK0BHIovLKHTwsW6njPPheMKDQFNUAv33t3jrMOxvq3HO8Ez8U/s4080/PXL_20230709_004451960.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgT5ldv1fTGlQrFwP9YvESyKNAoqxHlTII0uFm4NYQRJ8gvKaGvGh0Y-2mgZNL9w-TNhZFhb77W_OvZDlmPvrRHmvLf4xlIUXLH7BbsJuOEtCPRKP3-6T3W6rUgrGEo7FDsFNujaetgxrK0BHIovLKHTwsW6njPPheMKDQFNUAv33t3jrMOxvq3HO8Ez8U/s320/PXL_20230709_004451960.jpg"></a></p><p>

One of the coolest things to come along in the 68K Mac homebrew community is the ROM Boot Disk concept. Classic Macs have an unusually large ROM that contains a fair bit of the Mac OS, which was true even in the G3 New World Mac era (it was just on disk), so it's somewhat surprising that only one Mac officially could boot the Mac OS entirely from ROM, namely the Macintosh Classic (hold down Cmd-Option-X-O to boot from a hidden HFS volume with System 6.0.3). For many Macs that can take a ROM SIMM, you can <a href="http://synack.net/~bbraun/macromboot.html">embed a ROM volume</a> in the Mac ROM that can even be mirrored to a RAM disk. You can even <a href="http://www.bigmessowires.com/mac-rom-inator-ii/">buy them pre-populated</a>. How's <em>that</em> for immutability?
</p><p>
Well, it turns out Apple themselves were the first ones to implement a flashable Mac OS ROM volume in 1994, but hardly anyone noticed — because it was only ever used publicly in a minority subset of one of the most unusual of the Macintosh-derived systems, the Apple Interactive Television Box (a/k/a AITB or the Apple Set Top Box/STB). And that's what we're going to dig into — and reprogram! — today.
</p><p>
<a name="more"></a>
The AITB/STB was Apple's attempt to get into the early set-top box market of the 1990s. The dominance of the Apple TV today is a late phenomenon; Apple was in no position to launch such a product on their own in that era, though with the recent introduction of their QuickTime multimedia framework in 1991, they were a strong candidate for a technology partner. Apple forged an alliance with Oracle and parallel computing vendor nCube (Larry Ellison then being its single biggest stockholder), with Apple developing the front end client box and nCube boxes running Oracle Media Server handling the back end. All of this was to occur using MPEG-1 video with QuickTime as the playback system, specifically selected because of MPEG-1's bitrate of 1.5Mbit/sec and enough to run over <a href="http://oldvcr.blogspot.com/2022/05/so-long-home-t1-line-hello-hacking-t1.html">a T1/E1 line</a>. Plus, hardware decoders for the format already existed, meaning the device wouldn't have to rely on the CPU for smooth playback.
</p><p>
Apple developed the STBs in their Austin, Texas campus. It was based on stripped-down 1993 Quadra 605 hardware with extra silicon for the media features but kept serial, ADB and SCSI connections to allow it to run compatible CD-ROMs, sort of a Pippin before the Pippin, with plans to sell it for $750 [2023 dollars about $1500]. You could even hook up a printer to the serial port, but no storage was onboard: this device was to strictly boot from a central network link — in this case a T1/E1 — or from CD. Units first emerged publicly at the National Association of Broadcasters Show in Las Vegas in April 1995. There were at least two major hardware versions, STB1 and STB3 (no STB2s are known), with the STB3 being the most "common."
</p><p>
Apple partnered with cable TV companies for content delivery and AITBs were part of at least several trial deployments across the United States and Europe (most notably British Telecom), and Disney even used it briefly in at least one theme park. However, there were concerns about providing enough licensed and on-demand content, and while customers might buy that content, they tended to compensate by cutting subscriptions to the premium channels that the cable companies relied on as a regular income stream. The situation wasn't much better as a retail product given that home broadband was in its infancy and the product market was already too small for a boutique system. On top of that, the $300,000 [in 2023 over $600,000!] official development system (consisting of an nCube MediaCUBE server, 8 AITBs and 10GB of storage) made the already rarefied product thoroughly unattractive to developers, and with DOCSIS on the horizon wiring up T1 lines everywhere just didn't seem to pay off. Apple never ended up launching the hardware for retail sale, the existing trials were terminated, and most of the boxes were ultimately recalled and destroyed.
</p><p>
But, like all failed experiments, not all of them disappeared and various units have made their way into the hands of collectors and hackers. Over the years I've acquired two STB3 systems myself, one a non-working "production" model and the other a mostly functional DVT prototype. This prototype is not FCC-approved but is fundamentally identical to the "production" M4120 unit, so we'll be discussing mostly the prototype here since it works and is in much better shape. Here it is:

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhIZ95zeC9Bpz_wst7Jbp6FjJBHpbooJbr6pKcbpCRQjprz4vxt8yiOcrjOHVBFpSivbyHDQdPiY949VPdCNMTT_fTQc8M-QBr8d3_8ylZs_SKHPMteVNAArtSvUhw3vDYN3xQ5rcCkRVhTGmJkS4SaJaK9UoiCZba9_imv0kZqAUa-0-Z3dSEgcGg2M_g/s4080/PXL_20230709_003206578.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhIZ95zeC9Bpz_wst7Jbp6FjJBHpbooJbr6pKcbpCRQjprz4vxt8yiOcrjOHVBFpSivbyHDQdPiY949VPdCNMTT_fTQc8M-QBr8d3_8ylZs_SKHPMteVNAArtSvUhw3vDYN3xQ5rcCkRVhTGmJkS4SaJaK9UoiCZba9_imv0kZqAUa-0-Z3dSEgcGg2M_g/s320/PXL_20230709_003206578.jpg"></a></p><p>

The STB3 shipped in a fairly dramatic black case with a top lid. It was designed to fit into any typical home entertainment centre and will support the weight of a typical CRT television.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgTRMFQKF0pmUDYNAm0myOiQwPvl3wqRbe9tmba1nx-Briy8FRsaTBYRUR40xFfcRcyojAg9MgXynQeoiiwRdRBX92xXzI5YjQocwd9i54rFgUw3UZsGywWhrNI5LAkCevlDXE53GBqHgNFBK1m7FeK-p0skf8RsveBV8xoGsspRVyXDKRBtsyo3sY2_YM/s4080/PXL_20230709_003314972.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgTRMFQKF0pmUDYNAm0myOiQwPvl3wqRbe9tmba1nx-Briy8FRsaTBYRUR40xFfcRcyojAg9MgXynQeoiiwRdRBX92xXzI5YjQocwd9i54rFgUw3UZsGywWhrNI5LAkCevlDXE53GBqHgNFBK1m7FeK-p0skf8RsveBV8xoGsspRVyXDKRBtsyo3sY2_YM/s320/PXL_20230709_003314972.jpg"></a></p><p>

The only front control was a power button. Depending on the installed ROM, the power LED might show any or no colour at all. We'll talk about that a little later. Under the Apple logo was an IR sensor for which I lack <a href="https://wiki.preterhuman.net/Apple_Interactive_Television_Box#/media/File:Applestb-2-3_small-23938_0.jpg">the official remote control</a>. (That's okay because it turns out we don't actually need it to hack it.)

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg9TP-hNTksN-BhBcDH-llXtSIFtDhM3f7p9OCl3XX6tc2HF13QhKrV_ICC9uyu0NUEOTjNYoqVh2QAG4Wc9WqDhmVgfyry4nB7Wfupu5gOQ-4PykR_tc5ixBDPpnCAcoWvDPzymG3Tcpst4OmNFNQHlL5iWjGISw-ih8j2Jlrb6U3WYz5SXt32oMd21ug/s4080/PXL_20230709_003451706.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg9TP-hNTksN-BhBcDH-llXtSIFtDhM3f7p9OCl3XX6tc2HF13QhKrV_ICC9uyu0NUEOTjNYoqVh2QAG4Wc9WqDhmVgfyry4nB7Wfupu5gOQ-4PykR_tc5ixBDPpnCAcoWvDPzymG3Tcpst4OmNFNQHlL5iWjGISw-ih8j2Jlrb6U3WYz5SXt32oMd21ug/s320/PXL_20230709_003451706.jpg"></a></p><p>

The rear ports. Standard, the STB3 came with connectors for power (using a regular LC power supply), SCSI (using the Apple HDI-30 connector), SCART TV and VCR (both blocked), RF in/out from an antenna or cable TV connection, 8P8C network (but not Ethernet: this is for a T1/E1), standard Mac Mini-DIN serial, Mac S-video out, composite video, and stereo phono audio. A rubber grommet covers the Kensington lock slot, which I imagine was used in the hotel deployments. On the side, not visible here, is a single ADB port which only officially supports a mouse.
</p><p>
The BT version of these systems (labeled with BT branding as a "Interactive TV System Voyager 2000") reportedly used an ADSL connection, though I've never seen such a unit personally.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhTRREUvu0cy51XdH1aMLWXtD2RO4q79tAg1xqivpH0nUl9XiVV8G5QaQrzy0g9uBB298zFHJZF9AFI-lO36SbjJjpyuUWbXbQifviZaq44yfUaWpJWA3dn4NLQBFVALuZ_LkmQYk-EV_A35h8AsIxhTVYTPoeILQZUVXYoLLiUV7QEEd4f6Hs73ieAbTE/s4080/PXL_20230709_003507630.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhTRREUvu0cy51XdH1aMLWXtD2RO4q79tAg1xqivpH0nUl9XiVV8G5QaQrzy0g9uBB298zFHJZF9AFI-lO36SbjJjpyuUWbXbQifviZaq44yfUaWpJWA3dn4NLQBFVALuZ_LkmQYk-EV_A35h8AsIxhTVYTPoeILQZUVXYoLLiUV7QEEd4f6Hs73ieAbTE/s320/PXL_20230709_003507630.jpg"></a></p><p>

But what this unit also has, and most STBs don't, is a developer video card with a Mac DA-15 connector. Sadly, I've never been able to get it to work. More below when we open the case.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi55I5avhed3rjQgSrTq1JHXvUQRPBij2hGebQhfZBAxbeDm4cExbWeyoyW1GMcU_p_aHZLrqUUMEMPAlsnP4sZkjuT9C1w7tRP_kmowvyDq4WzkBlRv8PI76sHDdOFyHBSo9XXCqu-y9N8VBtNMqsOvxKaQpAKF-k89t32T74-8YXvCpg71m03bl8_pLc/s4080/PXL_20230709_003615470~2.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi55I5avhed3rjQgSrTq1JHXvUQRPBij2hGebQhfZBAxbeDm4cExbWeyoyW1GMcU_p_aHZLrqUUMEMPAlsnP4sZkjuT9C1w7tRP_kmowvyDq4WzkBlRv8PI76sHDdOFyHBSo9XXCqu-y9N8VBtNMqsOvxKaQpAKF-k89t32T74-8YXvCpg71m03bl8_pLc/s320/PXL_20230709_003615470~2.jpg"></a></p><p>

On the underside is this disclaimer that the unit is not FCC-approved. This unit is clearly further along than an EVT prototype <a href="http://oldvcr.blogspot.com/2021/10/shiner-esb-apple-network-server.html">like our "Shiner ESB" Apple Network Server prototype</a>, but because it's not FCC approved it's probably not a PVT, so therefore I'm concluding it's a DVT <a href="http://oldvcr.blogspot.com/2023/06/new-ram-card-prototype-mac-portable.html">like our Macintosh Portable prototype</a>. 

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh_U1RpMX2qAF0ooA_BfaqlW4-RCFB8Ddas3ZJlpirKHi6lQAdCuRcFVyuPDMC0wKGu27VcMWHToP51L0gybLQNQPHpF_ieSDJFKvkh-JOQJoqiBW6rtHmZDBVQ-EwRSfd2wOwq3SJhCwZtTzdKMUltGiyt3vkRzC_VcNbpesVLe69hWEXdX_gbaQiJ3iU/s4080/PXL_20230709_003715628~2.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh_U1RpMX2qAF0ooA_BfaqlW4-RCFB8Ddas3ZJlpirKHi6lQAdCuRcFVyuPDMC0wKGu27VcMWHToP51L0gybLQNQPHpF_ieSDJFKvkh-JOQJoqiBW6rtHmZDBVQ-EwRSfd2wOwq3SJhCwZtTzdKMUltGiyt3vkRzC_VcNbpesVLe69hWEXdX_gbaQiJ3iU/s320/PXL_20230709_003715628~2.jpg"></a></p><p>

Removing the top lid (there's a screw you may need to remove from the back), we see the video card, the mainboard and the power supply, which is a regular Q605 supply except with a black frame around the power port (the Q605/LC475 supply is in Apple Platinum beige). Although there is a spot where a cooling fan could go, there is neither mounting nor a power connector for one in both my units. The little three solder points next to it are where one can be installed, and some units exist where a fan is present.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjbRpIrtyRW2ZehmoMYfI2EtpKyA_HMIiVBBPR6b68QCOAbtOH5tEMNg_ntM5yFbk5PMafN9-VNnMo70MCwgSjqE1fldVAVwY7lw54pAvl_mHpZVaua-1R3DXpovg61H1-zKRU8ziy95qTHMaR6R-oXyUTPwQ9AiXkZ_HCNUpL_JTiB8eGEnehobdMzEi8/s4080/PXL_20230709_004316413.jpg"><img alt="" height="320" data-original-height="4080" data-original-width="3072" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjbRpIrtyRW2ZehmoMYfI2EtpKyA_HMIiVBBPR6b68QCOAbtOH5tEMNg_ntM5yFbk5PMafN9-VNnMo70MCwgSjqE1fldVAVwY7lw54pAvl_mHpZVaua-1R3DXpovg61H1-zKRU8ziy95qTHMaR6R-oXyUTPwQ9AiXkZ_HCNUpL_JTiB8eGEnehobdMzEi8/s320/PXL_20230709_004316413.jpg"></a></p><p>

The CPU, like the Quadra 605, is a 25MHz 68LC040. Other chips visible here are an Apple 343S0138-A (fabbed by TI) handling the PDS slot, an Apple 34320164-b (VLSI) MEMCjr memory controller, a TI TMXE320AV110 that appears to be an audio DSP, an NCR 53C96 SCSI controller, a Zilog Z8530 SCC for the serial port, and a Philips SAA7188A digital YUV to NTSC/PAL encoder (earlier Philips chips appear in the AV Macs). The RAM and ROM SIMMs are next to that, along with 4MB of RAM soldered to the board.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjUlN7v1dVzPcuWN-32LnCxp9tHw0wh_XQnSs02wAo9TM_bQIDJdYkobQzhiEY2vmq1mjKpm5UvT3fkntpSslaZ8RYkl50_sETAdjHYGnixGu5YSJrR2V6Wv0LsQJA6q0N11B9kSdvoi9h7pGzNWaMjxe1bP-kiVywaulgUV3qrSlKumWSL8KHqDRvsMaQ/s4080/PXL_20230709_004055555.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjUlN7v1dVzPcuWN-32LnCxp9tHw0wh_XQnSs02wAo9TM_bQIDJdYkobQzhiEY2vmq1mjKpm5UvT3fkntpSslaZ8RYkl50_sETAdjHYGnixGu5YSJrR2V6Wv0LsQJA6q0N11B9kSdvoi9h7pGzNWaMjxe1bP-kiVywaulgUV3qrSlKumWSL8KHqDRvsMaQ/s320/PXL_20230709_004055555.jpg"></a></p><p>

In front, red lines go to the power switch and LED, blue lines to the IR sensor, and white lines to the side-mounted ADB port.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg-3je5X16YlzzgFNQiFTkxtbERfgkjZ3HWhcjTFlSYgUdKEo2X6YQdnbFx_eCp2MEGYo1yaFWa-HYbPwZts2vjb3NIC4S0SrfFtnjfhBeozaJ7QcnctOhE-KyfInHLXr1vyNQMeH2rnPTJyJiZ4dcCZGW17kdo6nJOL7s5-ShDtu4jy-lwdWV_IUjZF_4/s4080/PXL_20230709_003928910~2.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg-3je5X16YlzzgFNQiFTkxtbERfgkjZ3HWhcjTFlSYgUdKEo2X6YQdnbFx_eCp2MEGYo1yaFWa-HYbPwZts2vjb3NIC4S0SrfFtnjfhBeozaJ7QcnctOhE-KyfInHLXr1vyNQMeH2rnPTJyJiZ4dcCZGW17kdo6nJOL7s5-ShDtu4jy-lwdWV_IUjZF_4/s320/PXL_20230709_003928910~2.jpg"></a></p><p>

And inside the front, just next to the red lines, is the board copyright (1995) and number (820-0638-01, which would be a prototype board designation).

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjW7dYb_EPZyMaNdjPWlczKCrQjySlY-nQuiRnS3gKudh9BCusz3E1RfJFWTjlmqp6v2I0oZG1R_ev-pXIfaAijn5GxDyqz-n71j_QIjsKk7p72hr_f_krhAqobA_K47VzZI6VTEDY35UaJ78hpEEjClA7jWs_NIXyc_mCR82hnZKUbpCbmWBIerOi1jiE/s4080/PXL_20230709_003741943.jpg"><img alt="" height="320" data-original-height="4080" data-original-width="3072" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjW7dYb_EPZyMaNdjPWlczKCrQjySlY-nQuiRnS3gKudh9BCusz3E1RfJFWTjlmqp6v2I0oZG1R_ev-pXIfaAijn5GxDyqz-n71j_QIjsKk7p72hr_f_krhAqobA_K47VzZI6VTEDY35UaJ78hpEEjClA7jWs_NIXyc_mCR82hnZKUbpCbmWBIerOi1jiE/s320/PXL_20230709_003741943.jpg"></a></p><p>

The board has a single PDS slot, occupied in the prototype by a video card which connects with a 90-degree adapter. This card is a simple 2D framebuffer with four 256Kx8 VRAMs to equal 1MB on board. Very few of these cards existed and seem to have only been part of developer machines.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgLyeOSuBpDHPhuh8x6XCMg9euneOlzeEg_9EoXM_1vNK9TsHrSiaVSCoB_GvChJaegtkrQkJC-xnHboL4clrJqApd5Pku_ap53ljBBaBole-NlO7lYE7s7Yz9mzETcjSd1QvAiqkFMZ4O1bird8QG0cN1K76GlWvUz4Mini1AL3WTVtPr0hsgYFThy464/s4080/PXL_20230709_003754651~2.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgLyeOSuBpDHPhuh8x6XCMg9euneOlzeEg_9EoXM_1vNK9TsHrSiaVSCoB_GvChJaegtkrQkJC-xnHboL4clrJqApd5Pku_ap53ljBBaBole-NlO7lYE7s7Yz9mzETcjSd1QvAiqkFMZ4O1bird8QG0cN1K76GlWvUz4Mini1AL3WTVtPr0hsgYFThy464/s320/PXL_20230709_003754651~2.jpg"></a></p><p>

The card identifies itself as a Micro Conversions X62SC01 (Revision A), which resembles the Micro Conversions 1724PD graphics card for the LC III and Performa 630. If there existed a driver specifically for this card, it must have been on whatever developer-bootable disk this unit didn't come with. 

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiiCu5x2uBMX99H2xHVvOBOC9kyVjEnSA792712fYjmBvceBmiRc6ZWCdgmmPajESaWJ8oCh6fj0uJd-SC8bB4ee9AiLiiWBl6iAxC-H3NdfHQSRZE9Col1cJHkKE--LfDjaRm-WugBh-4BZX4zC-iCAkK8AuozM_HBgI7UF7U-p4EUpoPMX_0syNADno4/s4080/PXL_20230709_005752133.jpg"><img alt="" height="320" data-original-height="4080" data-original-width="3072" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiiCu5x2uBMX99H2xHVvOBOC9kyVjEnSA792712fYjmBvceBmiRc6ZWCdgmmPajESaWJ8oCh6fj0uJd-SC8bB4ee9AiLiiWBl6iAxC-H3NdfHQSRZE9Col1cJHkKE--LfDjaRm-WugBh-4BZX4zC-iCAkK8AuozM_HBgI7UF7U-p4EUpoPMX_0syNADno4/s320/PXL_20230709_005752133.jpg"></a></p><p>

Pulling the card out of my working STB was a no-go; it's pretty much there for keeps (not interested in trying to pry it out lest I damage the card, the board, or both). Instead, we'll fill in the gap by switching here to the non-working "production" model, which unfortunately was improperly stored and suffered from oxidation damage. The chip with the white sticker is a socketed DIP ROM labeled "A3N(LS) C/SUM 519D8 95@@" which appears in other NTSC STB3s. The MPEG decoder is conveniently marked, a C-Cube Microsystems CL450-P160, the same one Apple used earlier with their <a href="https://wiki.preterhuman.net/Apple_MPEG_Media_System">MPEG Media System</a> card. Next to that is an Xilinx FPGA that likely serves as support video hardware.
</p><p>
The other marked chip, with green oxidation damage around the pins, is a Brooktree Bt8069 T1 transceiver. Other than the Zilog SCC the Bt8069 is the only networking chip obviously on the board; in particular, no Ethernet chips are visible. If the British Telecom units were truly ADSL, it would have had to have a different chip here or some sort of external transceiver box: even in situations where the T1 line is provisioned over DSL, that's usually <em>H</em>DSL, and the technologies are otherwise not interchangeable.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEitI5lW1lkjFtmNsXGy7mCLOK-ITjsbO_rP0EisgRadMfXyJuSLBAOlnH2Ei1-gqR6TsLsOHgcPDWSpg92GpFv_5pH3JiXR0r0jdhLJdASwa7Yy421JqNvegmgCjomaMlRHUSHo-SGQZUE9h1nH6-0_h6_BPycF_FGe5tWVZzKT9sXfAfkgTgGgAmBNPuU/s4080/PXL_20230709_005558757~2.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEitI5lW1lkjFtmNsXGy7mCLOK-ITjsbO_rP0EisgRadMfXyJuSLBAOlnH2Ei1-gqR6TsLsOHgcPDWSpg92GpFv_5pH3JiXR0r0jdhLJdASwa7Yy421JqNvegmgCjomaMlRHUSHo-SGQZUE9h1nH6-0_h6_BPycF_FGe5tWVZzKT9sXfAfkgTgGgAmBNPuU/s320/PXL_20230709_005558757~2.jpg"></a></p><p>

This unit is labeled as production and has an FCC ID and clearance sticker identifying it as a model M4120 (but with no formal name). This unit came from my hometown of San Diego County, California, based on the asset tag from The Lightspan Partnership, Inc. Lightspan Partnership, later just Lightspan, was founded in 1993 to develop edutainment software and produced a line of school-oriented Sony PlayStation titles which were sold to districts for classroom use. However, the original concept was to distribute the software via cable television so that students and parents could use it at home. This unit was obviously part of that initial, unrealized initiative. In 2003 Lightspan merged with PLATO Learning, Inc. (now Edmentum), one of the inheritors of the <a href="https://arstechnica.com/gadgets/2023/03/plato-how-an-educational-computer-system-from-the-60s-shaped-the-future/">Control Data PLATO legacy</a>, and subsequently ceased to exist.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhZBzCEBrOKoQO0gDMcBCUq4CdepuzIG_mopk1Dy5iqOaXCMXnyxFekc7ynWOlwt_I7lNfpbnbgQ5fVh6KGN-njY1haZDHXMVc3oarJxRCzxbR2UkfMba447S9yFUkrEkSy1Thj4RTDq20YUDQLpqyUlaXE_8VQWnYyZ6W6vv4BQl9LWBrwhl5Z7uHJVpc/s4080/PXL_20230709_005931032~2.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhZBzCEBrOKoQO0gDMcBCUq4CdepuzIG_mopk1Dy5iqOaXCMXnyxFekc7ynWOlwt_I7lNfpbnbgQ5fVh6KGN-njY1haZDHXMVc3oarJxRCzxbR2UkfMba447S9yFUkrEkSy1Thj4RTDq20YUDQLpqyUlaXE_8VQWnYyZ6W6vv4BQl9LWBrwhl5Z7uHJVpc/s320/PXL_20230709_005931032~2.jpg"></a></p><p>

But despite being labeled as a production, FCC-certified unit, it still has the same prototype motherboard code as the DVT unit.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhBbysjkWCQtleUXAXloYwx_CPwNnWmBY4lnhz2hiNSxrsBw1Fzk75bTZPJzpTzwMdygyr-jjKcngjKRIZVJPCsuPWZ-TClH0lEzln6O98w3JFLlcuXMyBVDoUHIbztGZiD119CIWnoHlhCukUw01iz20XZK5_MORV5HY2ECcUEWiZmf3bx6DEnKsQQV4U/s4080/PXL_20230709_003842420.jpg"><img alt="" height="320" data-original-height="4080" data-original-width="3072" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhBbysjkWCQtleUXAXloYwx_CPwNnWmBY4lnhz2hiNSxrsBw1Fzk75bTZPJzpTzwMdygyr-jjKcngjKRIZVJPCsuPWZ-TClH0lEzln6O98w3JFLlcuXMyBVDoUHIbztGZiD119CIWnoHlhCukUw01iz20XZK5_MORV5HY2ECcUEWiZmf3bx6DEnKsQQV4U/s320/PXL_20230709_003842420.jpg"></a></p><p>

Let's go back to the RAM and ROM for a second. There is a RAM slot here and you can put extra RAM into it, same as you would with a regular Q605, but the ROM's the more interesting part.
</p><p>
No, I'm not talking about these green mask ROMs that most owners of an STB3 have:

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhOoKGMcfQsMFxby3zDQDSn0HxNIEyKk8G7PSB1i1tzjrfI7A1JF0Qpjc6Q9pjL08pRDFX0Vg5AAuyic6Ab22d_GmIIbGB-t0JwErhDhjm-E-mvVst1piB707mGtW6JjQuVCMYqDBkdgELhvdSUlF7w0-OknJMZe-d7oThG-QC-Ej-HsQ2pWsVH6PFLT9A/s4080/PXL_20230706_012249967.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhOoKGMcfQsMFxby3zDQDSn0HxNIEyKk8G7PSB1i1tzjrfI7A1JF0Qpjc6Q9pjL08pRDFX0Vg5AAuyic6Ab22d_GmIIbGB-t0JwErhDhjm-E-mvVst1piB707mGtW6JjQuVCMYqDBkdgELhvdSUlF7w0-OknJMZe-d7oThG-QC-Ej-HsQ2pWsVH6PFLT9A/s320/PXL_20230706_012249967.jpg"></a></p>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh1lgi3HJyTRqY6gQIfuaIHBKZxMgneZeEldT6eMdQmnmzQZunLaV_LpvtZ-nMNGTXbojHb4d1rDWqr_YPQ62QgnSM8Ky9rEAqEz3Xk4pUv_mRmm0JrjVsEva7SCqejjdjS-aYHhgLFoR-tpfxWtoiIfRFgG33YXFKwNLE_0gpVQ3V9bLwX6NDRIQA-y6A/s4080/PXL_20230706_012350250.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh1lgi3HJyTRqY6gQIfuaIHBKZxMgneZeEldT6eMdQmnmzQZunLaV_LpvtZ-nMNGTXbojHb4d1rDWqr_YPQ62QgnSM8Ky9rEAqEz3Xk4pUv_mRmm0JrjVsEva7SCqejjdjS-aYHhgLFoR-tpfxWtoiIfRFgG33YXFKwNLE_0gpVQ3V9bLwX6NDRIQA-y6A/s320/PXL_20230706_012350250.jpg"></a></p><p>

If you dump one (I have two which are the same), you'll get a ROM checksum (</p><tt>$ff7439ee</tt><p>, SHA-1 </p><tt>1d833125adf553a50f5994746c2c01aa5a1dbbf2</tt><p>) exactly identical to the Quadra 605, which isn't surprising because the STB is derived from it. With a Q605 ROM installed, these units won't display a picture but they will let you boot over SCSI. Add something like Farallon/Netopia Timbuktu and a LocalTalk connection and you can remotely use one over the network from another classic Mac. Not too useful, but hey, they're stylish and rare, and it's great fun at parties (I'm told, I'm never invited to those sorts of parties).
</p><p>
Unfortunately, my unit, though it would initially boot from a BlueSCSI, one day suddenly decided it wouldn't. I've never been able to get it to boot from any SCSI device since, no matter what keys are held down, Option, Cmd-Option-Shift-Delete, dead chicken burnt offering, nothing. The unit otherwise works normally which leads me to suspect a fuse somewhere and/or the SCSI controller. (Don't kneejerk and say bad caps. I will hurt you.)
</p><p>
That brings us to <em>this</em> ROM.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgmBZI_T5VRmpjgPQeZz_y9QkhNgeuQkWzEbZKippjHhD64Yo7_A7B3njHUyHGdf79Z3M1JMQjAGLsmnYRNd_oU-H6kUH_HG3WZUy2bJF2n36LjSiN1W5HQ1Y7YeOgdWEFvC1l57yEGCX-9l3gDtZOruEk85wa9vSLxTMPRVMTjuuFpfiMn5zItYh-OdJc/s4080/PXL_20230706_012023599.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgmBZI_T5VRmpjgPQeZz_y9QkhNgeuQkWzEbZKippjHhD64Yo7_A7B3njHUyHGdf79Z3M1JMQjAGLsmnYRNd_oU-H6kUH_HG3WZUy2bJF2n36LjSiN1W5HQ1Y7YeOgdWEFvC1l57yEGCX-9l3gDtZOruEk85wa9vSLxTMPRVMTjuuFpfiMn5zItYh-OdJc/s320/PXL_20230706_012023599.jpg"></a></p>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgWenRFMs0VFZsd8ghQpnC5e3SIm__VBAEDo_zrWzNoGAhChyCBwIz6qnVrkGnHvTTa8VIczcCaPFnZYI_swQ6hAAstr7IXQGOSpo9WKuojU3vDnSGpN4Ex_7Ua0kHu_5iPU1Ok6Y5IXh0ubjaZqAOyxsvQRYqHZKQ0aG9dSExhga_S2OJrnk0myi_FjPc/s4080/PXL_20230706_012041156.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgWenRFMs0VFZsd8ghQpnC5e3SIm__VBAEDo_zrWzNoGAhChyCBwIz6qnVrkGnHvTTa8VIczcCaPFnZYI_swQ6hAAstr7IXQGOSpo9WKuojU3vDnSGpN4Ex_7Ua0kHu_5iPU1Ok6Y5IXh0ubjaZqAOyxsvQRYqHZKQ0aG9dSExhga_S2OJrnk0myi_FjPc/s320/PXL_20230706_012041156.jpg"></a></p><p>

This red ROM stick, labeled AP1654-01, has four 256K flash chips front and back to equal 2MB. Notice the silkscreened name "RLC FLASH SIMM." These appear to have been made initially for the RISC LC, the famous and heavily modified LC-based development prototype that emulated a 68K Mac with full compatibility and became the direct ancestor of the Power Macintosh.
</p><p>
There are <a href="https://wiki.preterhuman.net/Apple_Interactive_Television_Box#/media/File:Post-2085-0-12713200-1421865679.jpg">many versions</a> of this ROM, and this one is not labeled like most of the others in that linked image. However, I have no reason to suspect this particular one behaves much differently from the others.
</p><p>
The red ROM's biggest difference from the green ROM in that the TV outputs are enabled. When you switch on (with the back power switch) an STB3 with the red ROM, after a pause of a few seconds the LED over the power button lights red, and then shortly after yellow. In the <a href="https://wiki.preterhuman.net/Apple_Interactive_Television_Box_Setup_Guide">Setup Guide</a>, this indicates POST, followed by standby. This is very different from units with a Q605 ROM in which the LED never lights and the machine instead starts from the ADB power key, like any other Mac of this era would normally.
</p><p>  
Pressing the power button when the LED is yellow turns the LED green and this image appears on a connected composite or S-video display, captured on my INOGENI box:

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjZQNNU7QZCxPJQmdL8u-OoHW62gAEuHiH8WkwgAE77kaXxScSfbILat4PBWYpeOAGLSua-D7JlW-9g_h_vjhnvjKu1EyRY17m8sRPCa6Igofd_7tIXNTEdye2XkPOGncjRzxXWoPdzE43KdFN61IAQq0Ud5kBK54X7Hgkakhs9-JUU-JTg3Opgf_tGHVw/s1400/vlcsnap-2023-07-05-18h45m37s975.png"><img alt="" width="320" data-original-height="1050" data-original-width="1400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjZQNNU7QZCxPJQmdL8u-OoHW62gAEuHiH8WkwgAE77kaXxScSfbILat4PBWYpeOAGLSua-D7JlW-9g_h_vjhnvjKu1EyRY17m8sRPCa6Igofd_7tIXNTEdye2XkPOGncjRzxXWoPdzE43KdFN61IAQq0Ud5kBK54X7Hgkakhs9-JUU-JTg3Opgf_tGHVw/s320/vlcsnap-2023-07-05-18h45m37s975.png"></a></p><p>

But, invariably, 30 seconds-ish later, you get this:

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjl5TiGKoVXYy-_3fE1rLsEONnN5k05NWxwFnmMugouanonw1NCenO8dW1o4CJlYxUemOhaF029_9XvFJzCdWDMuQ-0aeSh0gHoAqaLpaFF3f1yPaJ5kf-cBZbC3Tq-0MBNYdv6Gqm7O0UyCg1mSKQDNvW84yFYMw-K8q83ing1Gxgqul20Wd95HmfOOh8/s1400/vlcsnap-2023-07-05-18h46m08s434.png"><img alt="" width="320" data-original-height="1050" data-original-width="1400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjl5TiGKoVXYy-_3fE1rLsEONnN5k05NWxwFnmMugouanonw1NCenO8dW1o4CJlYxUemOhaF029_9XvFJzCdWDMuQ-0aeSh0gHoAqaLpaFF3f1yPaJ5kf-cBZbC3Tq-0MBNYdv6Gqm7O0UyCg1mSKQDNvW84yFYMw-K8q83ing1Gxgqul20Wd95HmfOOh8/s320/vlcsnap-2023-07-05-18h46m08s434.png"></a></p><p>

indicating an expected response from the server never arrived. I don't know what the green button on the remote does (the manual simply says to "see the interactive service provider's instructions" for the four colour buttons). I connected speakers to the audio out but the unit makes no sound.
</p><p>
I don't know which human-readable version of the ROM this is, but we can dump it:

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgspjwVenvpQVJcrOSy9-l3ozVHvKARXEWwtwRtSsP5qGKttOAzfyxT_1ElSCX5wujF3ejFIQpABxzwfFWB33dovaLAzUALV8gwnKd4Gd1aX-zOpoUxgLEVxpKfPRXKRwrVZXAB7wRDJAk757D3ddOZEwBRfFIFZL0J3bUHUywEOoj8uktud7C4VhWkjFM/s4080/PXL_20230706_013701726.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgspjwVenvpQVJcrOSy9-l3ozVHvKARXEWwtwRtSsP5qGKttOAzfyxT_1ElSCX5wujF3ejFIQpABxzwfFWB33dovaLAzUALV8gwnKd4Gd1aX-zOpoUxgLEVxpKfPRXKRwrVZXAB7wRDJAk757D3ddOZEwBRfFIFZL0J3bUHUywEOoj8uktud7C4VhWkjFM/s320/PXL_20230706_013701726.jpg"></a></p><p>

The best tool for this purpose is of course Doug Brown's <a href="https://www.downtowndougbrown.com/programmable-mac-rom-simms/">flash SIMM programmer</a>, which can both read these ROM SIMMs (used in many 68K Macs) and write to replacement flash ROM sticks. The 2MB dump we get has a checksum of </p><tt>$b7025504</tt><p> (the first four bytes as a 32-bit big-endian unsigned integer), a version word of </p><tt>$077d</tt><p> (i.e., 1917, bytes eight and nine as a 16-bit big-endian unsigned short), and a SHA-1 of </p><tt>911eaafc5ccfe6823a7be61d44aaf0a63d081118</tt><p>. What we're going to do with this dump is based on this particular ROM version. The rest of this article may or may not fully apply to other versions and of course you follow along with your real device at your own risk.
</p><p>
The first step with any dump is see what <a href="https://github.com/ReFirmLabs/binwalk"><tt>binwalk</tt></a> makes of it, and other than copyright messages, it finds a couple surprising things are present. Nine, to be exact.
</p><div><pre>% binwalk RED.rom

DECIMAL       HEXADECIMAL     DESCRIPTION
--------------------------------------------------------------------------------
941976        0xE5F98         Copyright string: "Copyright C-Cube Microsystems 1992"
1090813       0x10A4FD        Copyright string: "Copyright 1990-91 Apple Computer Inc. Copyright 1981 Linotype AG Copyright 1990-91 Type Solutions Inc.1.0"
1090851       0x10A523        Copyright string: "Copyright 1981 Linotype AG Copyright 1990-91 Type Solutions Inc.1.0"
1090878       0x10A53E        Copyright string: "Copyright 1990-91 Type Solutions Inc.1.0"
1844352       0x1C2480        JPEG image data, JFIF standard 1.01
1846358       0x1C2C56        JPEG image data, JFIF standard 1.01
1848250       0x1C33BA        JPEG image data, JFIF standard 1.01
1849933       0x1C3A4D        JPEG image data, JFIF standard 1.01
1851587       0x1C40C3        JPEG image data, JFIF standard 1.01
1853288       0x1C4768        JPEG image data, JFIF standard 1.01
1855867       0x1C517B        JPEG image data, JFIF standard 1.01
1857571       0x1C5823        JPEG image data, JFIF standard 1.01
1859146       0x1C5E4A        JPEG image data, JFIF standard 1.01
1871674       0x1C8F3A        Copyright string: "Copyright 1987-1991"
</pre></div>
<p>
The copyrights reference fonts, but also C-Cube, the manufacturer of the MPEG decoder. It also finds nine JPEG images:

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg4sNYPow2ybQ0P8ozChGowiiU4vkiem0E_digzZZCODCRBW7iB12EjYJuPOk1p4DQJRLIIKDHJuHqM-kXQv4dOeMPSUw88h7tcP0Eh0BrZ4IBvppjZ4C-xRIqZxNgQKdux2yDMTMj1HVj9-zjkbG4xY4VwYixfZGlMSRAMU8UB0r8OzAk3mUxDnuEYWjU/s864/stbbunchc.jpg"><img alt="" width="320" data-original-height="624" data-original-width="864" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg4sNYPow2ybQ0P8ozChGowiiU4vkiem0E_digzZZCODCRBW7iB12EjYJuPOk1p4DQJRLIIKDHJuHqM-kXQv4dOeMPSUw88h7tcP0Eh0BrZ4IBvppjZ4C-xRIqZxNgQKdux2yDMTMj1HVj9-zjkbG4xY4VwYixfZGlMSRAMU8UB0r8OzAk3mUxDnuEYWjU/s320/stbbunchc.jpg"></a></p><p>

These are obviously pictures of the development team. Do you recognize any of them? Are <em>you</em> any of them?
</p><p>
Naturally, with nine pictures, you <em>know</em> what we have to do.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgrmbuP_zpI2z4cr9BIvSbQ96HdOBDZfl87m8ZD1SiajarCUvCkFXgSMoTIwBakJR1_sAk968xblsWwvbBo0I4_Xb9vx5if5n7glkCr9MrIt0AB48Fn3LRKLqHlXPz3qz332BToAWNm6HEgfX9o3gVsun5IxaIE_wVQMNkhHGaZ1vXgx1QaOEfIKJLl7dw/s864/stbbunch.jpg"><img alt="" width="320" data-original-height="624" data-original-width="864" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgrmbuP_zpI2z4cr9BIvSbQ96HdOBDZfl87m8ZD1SiajarCUvCkFXgSMoTIwBakJR1_sAk968xblsWwvbBo0I4_Xb9vx5if5n7glkCr9MrIt0AB48Fn3LRKLqHlXPz3qz332BToAWNm6HEgfX9o3gVsun5IxaIE_wVQMNkhHGaZ1vXgx1QaOEfIKJLl7dw/s320/stbbunch.jpg"></a></p><p>

More relevantly, though, now that we have a ROM dump we've just <em>got</em> to hack it. Since it's displaying a message, let's see if we can modify the message as a small proof of concept. </p><tt>strings</tt><p>, that always useful tool, shows that the "Sorry!" message appears in two places. Modifying the first one is sufficient:

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgYt8m-nsip9bekcmIMyFm6o6_OPGtMlgxE4R8sC8I0I1qQJcev4wHWKaSS7nEgcF6k3HBqaqprdBSvz_upUP1O4okVuIs9NQm96J8iJ1fevCQM6eUKAa72m_TYctmsCh5JZjRIBoLzzS4_mI9VgqGFR7B2qliH7mrhOcMF0J3iGEmUr2uix9zl1B5bKT4/s829/firsthack.png"><img alt="" height="320" data-original-height="829" data-original-width="741" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgYt8m-nsip9bekcmIMyFm6o6_OPGtMlgxE4R8sC8I0I1qQJcev4wHWKaSS7nEgcF6k3HBqaqprdBSvz_upUP1O4okVuIs9NQm96J8iJ1fevCQM6eUKAa72m_TYctmsCh5JZjRIBoLzzS4_mI9VgqGFR7B2qliH7mrhOcMF0J3iGEmUr2uix9zl1B5bKT4/s320/firsthack.png"></a></p><p>

This will change the checksum of the ROM, which is computed as the sum of all the 16-bit big endian shorts from byte 4 onward and truncated to 32 bits. The tools I wrote up to handle all this are in <a href="https://github.com/classilla/stbtools">this Github project</a>. Use </p><a href="https://github.com/classilla/stbtools/blob/main/checksum.pl"><tt>checksum.pl</tt></a><p> to recompute the ROM checksum and then use the hex editor to edit the first four bytes to match.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgbRxAXFDqgIzCZOMyXflYM7cDavcldVZ7qoGeL5S4jFKSzb011J-7T7Y5dSPGI1NkdtQ4JtIYWrh1a9NJ5PUGeW-hq722aW8xDBAECsgw3aMvcMqwzq1I64QdylGLHh3SVByIu43DaJnfUFwcYn0d38WBULCD943A9-hnLG-Vf6CrpJfAkQBm9oNP0s_0/s4080/PXL_20230712_210136841.jpg"><img alt="" width="320" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgbRxAXFDqgIzCZOMyXflYM7cDavcldVZ7qoGeL5S4jFKSzb011J-7T7Y5dSPGI1NkdtQ4JtIYWrh1a9NJ5PUGeW-hq722aW8xDBAECsgw3aMvcMqwzq1I64QdylGLHh3SVByIu43DaJnfUFwcYn0d38WBULCD943A9-hnLG-Vf6CrpJfAkQBm9oNP0s_0/s320/PXL_20230712_210136841.jpg"></a></p><p>

Then get yourself a couple 2MB flash ROMs SIMMs. They must be exactly 2MB in size; larger ROMs won't work even if you "echo" the bytes. I used the 2MB <a href="http://www.bigmessowires.com/mac-rom-inator-ii/">ROM-inator II from Big Mess O'Wires</a> but <a href="https://ko-fi.com/caymacvintage/shop">CayMac's 2MB ROM</a> should also do the job; CayMac also sells new SIMM programmers (I am not affiliated with BMOW or CayMac).
</p><p>
Burn the ROM in your programmer <a href="https://github.com/dougg3/mac-rom-simm-programmer">using the SIMM programmer tool</a>, make sure your STB3 is off, and install it in the ROM SIMM slot near the RAM slot. On the programmer, the SIMM skull and crossbones should face the skull and crossbones on the circuitboard; on the STB, the SIMM skull and crossbones should face the RAM. Connect up some sort of composite monitor and switch it on.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh2e7HhSAZB9z6i_KgAF8NAkqZSdAvclAVb_E-JNbzTuqAfLY5hVEiozGASWEPiCSi3yNu_vFN3tln1LIjwuUNivoO4Ynqy4v1OiTPwTV63OJa8fm7XGKvo2GGtW41ioNVnNNmoYWLhwJZ_4TZfl1GJ8vSDjhkbPrQlOWUP2m6d2IABpWT7gR94G5y83jM/s1400/vlcsnap-2023-07-12-13h57m41s443.png"><img alt="" width="320" data-original-height="1050" data-original-width="1400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh2e7HhSAZB9z6i_KgAF8NAkqZSdAvclAVb_E-JNbzTuqAfLY5hVEiozGASWEPiCSi3yNu_vFN3tln1LIjwuUNivoO4Ynqy4v1OiTPwTV63OJa8fm7XGKvo2GGtW41ioNVnNNmoYWLhwJZ_4TZfl1GJ8vSDjhkbPrQlOWUP2m6d2IABpWT7gR94G5y83jM/s320/vlcsnap-2023-07-12-13h57m41s443.png"></a></p><p>

Our plea for help duly appears. This simple demonstration proves that the only thing we need to do to modify the ROM is update the checksum; nothing else on the board appears to check it. It's now time to figure out what's there and how it's organized.
</p><p>
Many Apple ROMs are segmented <a href="https://preterhuman.net/macstuff/techpubs/mac/MoreToolbox/MoreToolbox-106.html#HEADING106-0">into discrete resources</a>, which are functionally equivalent with on-disk HFS resources attached to files, and can be accessed from the Toolbox in the same fashion. For example, here's the header of the (unused, disabled and not implemented) <tt>.netBOOT</tt> driver resource in the green Quadra 605 ROM:
</p><div><pre>00051c80  18 00 00 00 00 00 00 00  00 0e dc 70 00 05 1c b0  |...........p....|
00051c90  44 52 56 52 00 31 58 08  2e 6e 65 74 42 4f 4f 54  |DRVR.1X..netBOOT|
00051ca0  00 00 00 00 c0 a0 00 00  00 00 08 80 00 00 03 04  |................|
</pre></div>
<p>
We can scan the red ROM dump for similar resource headers. Starting at offset <tt>$0000</tt>, the first big-endian 32-bit word is always the ROM checksum and the second is the starting address for the boot code (technically the first sets the stack pointer, but the ROM glosses over this). We page through opaque binary data awhile until we start seeing structured patterns every so often. The first one of these patterns we get to is this.
</p><div><pre>000ac210  78 00 00 00 00 00 00 00  00 00 00 00 00 0a b3 70  |x..............p|
000ac220  62 6f 6f 74 00 03 58 04  4d 61 69 6e 6b 63 6b 63  |boot..X.Mainkckc|
000ac230  4b 75 72 74 c0 a0 00 00  00 00 07 6a 00 00 00 64  |Kurt.......j...d|
</pre></div>
<p>
This is our first ROM resource, <tt>boot#3</tt>, named <tt>MainkckcKurt</tt> (much like the string <tt>Gary</tt>, presumably <a href="https://apple.fandom.com/wiki/Gary_Davidian">Gary Davidian</a>, shows up a lot in Mac ROMs, the name <tt>Kurt</tt> is all over this one — from the "kc" bit I'm guessing <a href="https://www.linkedin.com/in/kurt-clark-529444">Kurt Clark</a>, who was an Apple senior firmware and system software engineer at the time of the AITB's development). The hex byte <tt>78</tt> indicates an enabled, live resource.
</p><p>
The ROM resources in the red ROM are stored somewhat back to front with the "header" actually serving as a footer; the resource runs from the fourth word (here <tt>$000ab370</tt>) to the beginning of the footer. How do we know it's laid out like that? Because of what we find a little later on:
</p><div><pre>000ac980  70 73 6c 74 00 14 70 73  6c 74 00 1a 73 6e 64 20  |pslt..pslt..snd |
000ac990  00 01 77 65 64 67 e9 81  77 65 64 67 e9 80 6b 63  |..wedg..wedg..kc|
000ac9a0  78 00 00 00 00 00 00 00  00 0a c2 10 00 0a c2 40  |x..............@|
000ac9b0  72 6f 76 6d 00 00 58 00  6b 63 6b 63 6b 63 6b 63  |rovm..X.kckckckc|
000ac9c0  4b 75 72 74 c0 a0 00 00  00 08 70 0c 00 00 00 6c  |Kurt......p....l|
000ac9d0  4c 4b 60 00 00 86 44 18  00 00 06 53 79 73 74 65  |LK`...D....Syste|
000ac9e0  6d 00 00 00 00 00 00 00  00 00 06 46 69 6e 64 65  |m..........Finde|
000ac9f0  72 00 00 00 00 00 00 00  00 00 07 4d 61 63 73 42  |r..........MacsB|
000aca00  75 67 00 00 00 00 00 00  00 00 0c 44 69 73 61 73  |ug.........Disas|
000aca10  73 65 6d 62 6c 65 72 00  00 00 0d 53 74 61 72 74  |sembler....Start|
000aca20  55 70 53 63 72 65 65 6e  00 00 06 46 69 6e 64 65  |UpScreen...Finde|
000aca30  72 00 00 00 00 00 00 00  00 00 09 43 6c 69 70 62  |r..........Clipb|
000aca40  6f 61 72 64 00 00 00 00  00 00 00 0a 00 14 00 00  |oard............|
</pre></div>
<p>
The characters <tt>LK</tt> herald HFS boot blocks. Yes, friends, there's an embedded disk image here, and it's doubtful the resource code <tt>rovm</tt> is used to reference it.
</p><p>
There are many fun strings in that disk image:
</p><div><pre>000af1d0  46 72 65 64 54 56 aa 0d  0d 42 72 6f 75 67 68 74  |FredTV...Brought|
000af1e0  20 74 6f 20 79 6f 75 20  62 79 20 46 72 65 64 20  | to you by Fred |
000af1f0  48 75 78 68 61 6d 20 61  6e 64 20 46 72 65 64 20  |Huxham and Fred |
000af200  4d 6f 6e 72 6f 65 2e 0d  0d a9 20 41 70 70 6c 65  |Monroe.... Apple|
000af210  20 43 6f 6d 70 75 74 65  72 2c 20 49 6e 63 2e 20  | Computer, Inc. |
000af220  31 39 39 33 0d 41 6c 6c  20 52 69 67 68 74 73 20  |1993.All Rights |
000af230  52 65 73 65 72 76 65 64  2e 0d 81 e2 20 30 01 60  |Reserved.... 0.`|
</pre></div>
<p>
Although it was known that the AITB ROM had portions of System 7.1, this red ROM actually seems to contain an entire, self-contained, miniature bootable image. There's no reason to have the string <tt>Welcome to Macintosh.</tt> unless a working System file were part of it:
</p><div><pre>000b2930  1a 00 6c 00 c0 57 65 6c  63 6f 6d 65 20 74 6f 20  |..l..Welcome to |
000b2940  4d 61 63 69 6e 74 6f 73  68 2e 00 b1 7a 00 18 00  |Macintosh...z...|
000b2950  7e 00 c0 44 65 62 75 67  67 65 72 20 69 6e 73 74  |~..Debugger inst|
000b2960  61 6c 6c 65 64 2e 00 b1  77 00 14 00 7e 00 c0 45  |alled...w...~..E|
000b2970  78 74 65 6e 73 69 6f 6e  73 20 6f 66 66 2e 00 b1  |xtensions off...|
000b2980  79 00 ca 00 5e 00 72 54  68 69 73 20 73 74 61 72  |y...^.rThis star|
000b2990  74 75 70 20 64 69 73 6b  20 77 69 6c 6c 20 6e 6f  |tup disk will no|
000b29a0  74 20 77 6f 72 6b 20 6f  6e 20 74 68 69 73 20 4d  |t work on this M|
000b29b0  61 63 69 6e 74 6f 73 68  2f 6d 6f 64 65 6c 2e 20  |acintosh/model. |
[...]
000b3e50  6d 21 40 2d 04 42 af 06  04 00 00 00 55 54 4d 61  |m!@-.B......UTMa|
000b3e60  63 69 6e 74 6f 73 68 20  53 79 73 74 65 6d 20 76  |cintosh System v|
000b3e70  65 72 73 69 6f 6e 20 37  2e 31 0d 0d 0d a9 20 41  |ersion 7.1.... A|
000b3e80  70 70 6c 65 20 43 6f 6d  70 75 74 65 72 2c 20 49  |pple Computer, I|
000b3e90  6e 63 2e 20 31 39 38 33  2d 31 39 39 32 0d 41 6c  |nc. 1983-1992.Al|
000b3ea0  6c 20 72 69 67 68 74 73  20 72 65 73 65 72 76 65  |l rights reserve|
000b3eb0  64 2e 00 00 01 f5 a8 9f  65 72 00 12 09 01 00 00  |d.......er......|
</pre></div>
<p>
Eventually we come to its footer, which now enables us to extract it.
</p><div><pre>001339d0  78 00 00 00 00 00 00 00  00 0a c9 a0 00 0a c9 d0  |x...............|
001339e0  64 69 73 6b 00 00 58 00  6b 63 6b 63 6b 63 6b 63  |disk..X.kckckckc|
001339f0  4b 75 72 74 c0 a0 00 00  00 00 07 50 00 00 00 74  |Kurt.......P...t|
</pre></div>
<p>
It's a <tt>disk</tt>, resource #0. That sounds more likely as a type code. If you look at the third and fourth 32-bit words (big-endian, again, as G-d intended), you'll find it links back to the last footer at <tt>$000ac9a0</tt> (the <tt>rovm</tt> resource), allowing us to scan the file by walking back references, and the address <tt>$000ac9d0</tt> is where we found the boot block, so that must be the starting address for this resource. That means <tt>disk#0</tt> occupies <tt>$000ac9d0</tt> to the beginning of the footer at <tt>$001339d0</tt>.
</p><p>
If this is a bootable Mac OS System 7 image, it should act like it. And, to my delight, it does. The manual says nothing about connecting an ADB keyboard to it, only a mouse, but ADB keyboards work fine. If you hold down the SHIFT key while turning the rear power switch on and waiting for it to turn yellow, you'll lose the Apple background when you power on from the front, exactly as if an extension didn't load.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEglpqRWGzWyMNbo_4QZLm1sdSM6ySTqUHbz4-DpQZDZgLI5qKf7WEgaluUOQLYXGgu6kOkzweNbdrVUvlnStpGd6HOJzV3cWAZGfDP_x6JnHyA_iZOHOmXOHIKOKw5hN6kRQEX6lCgWzeiD4oSy-LRT4C3PsE7Eq-EirStt443Q8X_zUPC15riAD4NzdrM/s1400/vlcsnap-2023-07-11-20h43m06s983.png"><img alt="" width="320" data-original-height="1050" data-original-width="1400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEglpqRWGzWyMNbo_4QZLm1sdSM6ySTqUHbz4-DpQZDZgLI5qKf7WEgaluUOQLYXGgu6kOkzweNbdrVUvlnStpGd6HOJzV3cWAZGfDP_x6JnHyA_iZOHOmXOHIKOKw5hN6kRQEX6lCgWzeiD4oSy-LRT4C3PsE7Eq-EirStt443Q8X_zUPC15riAD4NzdrM/s320/vlcsnap-2023-07-11-20h43m06s983.png"></a></p><p>

This behaviour suggests that when you first turn it on, it's doing its memory test and POST, then turns on the red LED while searching for and booting the minimal Mac OS, then turns on the yellow LED when, I guess, the "Finder" (such as it is) is ready to find its mothership.
</p><p>
Other typical Mac key combinations work, too. Pressing Command-Q will reset the machine when the timeout error message appears, as if quitting any other app. If you press Command-Option-Escape in an attempt to kill the task, you'll reset it also, or Command-Power, though possibly only at the point the timeout error message is present — one suspects this front-end program doesn't call <tt>WaitNextEvent</tt> very much. (In fact, it turns out it doesn't by the point, but that's a spoiler from near the end of this article.) It seems virtually anything that would cause a quit or system error (or any system dialogue box) will immediately force a restart. Incidentally, there is no startup chime or system beep, though there does appear to be a System Beep resource (<tt>snd #1</tt>).
</p><p>
Can the STB3 red ROM boot from anything else? The manual says it can access a CD-ROM drive connected via SCSI, and there are strings in the ROM that make reference to SCSI, but these appear to be within the byte range we identified as part of the disk image (and my SCSI isn't bootable). Apart from that, however, we now have enough understanding of how its ROM is laid out to write something that will walk it. (Eventually I'll extend it to work with other Mac ROMs, but right now the code just works with this red one.) We'll use <a href="https://github.com/classilla/stbtools/blob/main/resscan.pl"><tt>resscan.pl</tt></a> to see what driver resources are present and if there are any other disk images.
</p><div><pre>% ../resscan.pl RED.rom | grep -ai DRVR
[78000000] found DRVR #93 at 0x00133a00 0x00134150 ".STBDiskDriverkckckckckc" 
% ../resscan.pl RED.rom | grep -ai disk
[78000000] found disk #0 at 0x000ac9d0 0x001339d0 "kckckckcKurt��" 
[78000000] found DRVR #93 at 0x00133a00 0x00134150 ".STBDiskDriverkckckckckc"
(various string resources elided)
</pre></div>
<p>
There appears to be only one <tt>DRVR</tt>, versus the multiple found in the Q605 ROM (such as one for the floppy drive), plus only one ROM disk image. If it can load from SCSI at all, it appears to be handled by the OS in the ROM disk image rather than the firmware directly, suggesting a regular MacOS volume might not boot as such. Alternatively, doing so may not have been supported with this version of the ROM. Resource <tt>STR #46396</tt> does have the interesting string "Manages file access to CDi discs for QuickTime media handlers" which suggests disc support may have been intended for <a href="https://en.wikipedia.org/wiki/CD-i">greenbook CD-i</a>.
</p><p>
Of other resources present, there are several <tt>thng</tt> resources, including an "STB3 Component" that "Supports the hardware dependent features of STB3." and an "I2C Component" that "Supports I2C using Cuda," and a number of <tt>cdec</tt> (QuickTime codec) resources for Cinepak, Photo/JPEG, Apple Animation ("Decompresses images compressed using run length encoding") and Apple Graphics ("Decompresses images compressed using Sean's secret recipe") and, of course, MPEG-1. These components are specific to the STB and embedded elsewhere in ROM, not as part of the bootable image.
</p><p>
As for the OS itself, we'll now extract that byte range we computed and treat it as a disk image. Both SheepShaver and Mini vMac will mount it, but we'll use SheepShaver first to illustrate a little of what's there.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEivi109oErIiBTo1MbdgBFIq1S01HphNj3frf-D55P-qI2z5AueUhtAEnB8O17hsfc8WYrgo1LxiGewK9Z-EzXJKO_sMMKihSlojvXMWXT8sdbQ75d4bhbXvPZ72_YmrqsqSO-LCi5hzOfGSLZqTXE5dWR-wBi2-E_Z1mZiOhvHk_dJSuibrWrOQBYw23g/s899/happydisk.png"><img alt="" width="320" data-original-height="815" data-original-width="899" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEivi109oErIiBTo1MbdgBFIq1S01HphNj3frf-D55P-qI2z5AueUhtAEnB8O17hsfc8WYrgo1LxiGewK9Z-EzXJKO_sMMKihSlojvXMWXT8sdbQ75d4bhbXvPZ72_YmrqsqSO-LCi5hzOfGSLZqTXE5dWR-wBi2-E_Z1mZiOhvHk_dJSuibrWrOQBYw23g/s320/happydisk.png"></a></p><p>

First off, we're dealing with a disk image smaller than an 800K floppy; it's 540K in size. As a result the System Folder is very abbreviated: two mysterious </p><tt>INIT</tt><p>s, </p><tt>NMIer</tt><p> and </p><tt>TSDrvr INIT - 8/8</tt><p>, and very small </p><tt>Finder</tt><p> and </p><tt>System</tt><p> files. There is one font in the </p><tt>Fonts</tt><p> folder (there are other font references in the System file), and nothing in </p><tt>Apple Menu Items</tt><p>. The TSDrvr extension may be related to the known set of <a href="https://wiki.preterhuman.net/Apple_Interactive_Television_Box#Software">Set Top Box extensions</a> though none of those files have so far worked with any STB using the green ROM booting a conventional version of Mac OS. If indeed related, then the TS part of the name likely refers to <a href="https://en.wikipedia.org/wiki/MPEG_transport_stream">MPEG transport streams</a> and handles framing as movie data comes over the wire.
</p><p>
The other file is named <tt>MPEGStill</tt>. It has a single <tt>ckid</tt> (check ID) resource from MPW Projector, which is the Macintosh Programmer's Workshop version control system, and (among other binary data) that resource contains the strings <tt>SetTopProj</tt> (the project name, no doubt), <tt>Tidbits</tt> (probably the component or subproject, probably not <a href="https://tidbits.com/">the long-lived Mac newsletter</a>), <tt>jay michael puckett</tt> (author - which one of the self-portraits is he?), and <tt>AppleMPEGStill</tt>.
</p><p>
But the last string is the most interesting. It says it's a <tt>new still for non-BT trials</tt>. So what's the still image?

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEib-hWXs8j5td0A6eAhc0ob7O-BD82dJkv_DsNBSENEi5Huz6Nhhw6Cz73L98cRhbbJRdilkN7LTi2ws6EEgNLkKcYMwWZ3R4Gh0I3rV3YF2N-CwoWlHi8oJlVNm_f6qf8pXfzEDS5bnoMsTGffFex481l45Gwxr00XtPSB3ySeUMANXGVJIg47Pm-HGL8/s813/mpegstill.png"><img alt="" width="320" data-original-height="812" data-original-width="813" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEib-hWXs8j5td0A6eAhc0ob7O-BD82dJkv_DsNBSENEi5Huz6Nhhw6Cz73L98cRhbbJRdilkN7LTi2ws6EEgNLkKcYMwWZ3R4Gh0I3rV3YF2N-CwoWlHi8oJlVNm_f6qf8pXfzEDS5bnoMsTGffFex481l45Gwxr00XtPSB3ySeUMANXGVJIg47Pm-HGL8/s320/mpegstill.png"></a></p><p>

It's ... an MPEG-1 frame. And QuickTime will play it:

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi07kh4BFEuBesHidlYFP4z8lEZYzLg2ruiY5AL5cSJgU0FTRvFD4rx4cLsw2fmRc8M8Z1ffYjApx5u9OnyZ439fIFmpvcdnw9BNKBRagmRjAFO7ENfuo67KJlAYGJmcozWWxSXod9BZSkr_1hES2YN9nHZIUD9YCDsPYPyQMzUUzhPWdhQcv-PKcxIfvw/s797/ismpg.png"><img alt="" width="320" data-original-height="452" data-original-width="797" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi07kh4BFEuBesHidlYFP4z8lEZYzLg2ruiY5AL5cSJgU0FTRvFD4rx4cLsw2fmRc8M8Z1ffYjApx5u9OnyZ439fIFmpvcdnw9BNKBRagmRjAFO7ENfuo67KJlAYGJmcozWWxSXod9BZSkr_1hES2YN9nHZIUD9YCDsPYPyQMzUUzhPWdhQcv-PKcxIfvw/s320/ismpg.png"></a></p><p>

There's our image, as CIF PAL 352x288. Notice there's only one frame here; presumably the BT STBs used a British Telecom image for their backdrop still instead. Most likely the hardware MPEG decoder, via the built-in ROM codecs, is being used to decode and display the frame.
</p><p>
For our first trick, let's create a new still frame of our own. There are a few gotchas. First of all, SheepShaver seems to wipe the boot blocks when it unmounts the image, and also unblesses the System Folder, making the resulting disk image unbootable by the STB. (I'll say benignly this was the source of a lot of cussing when the red LED would turn on but then nothing else happened.) We'll use it to explore the image but for development we'll use Mini vMac instead, which also unblesses the System Folder, but if you boot the emulated Mac (I use the Macintosh II emulation) with both your boot volume and the STB volume on the command line, it leaves the boot blocks alone. We can fix the "unblessed" folder after Mini vMac unmounts it.
</p><p>
If we feed the data fork to <tt>file</tt> and <tt>ffmpeg</tt>, this is what we get.
</p><div><pre>% file MPEGStill
MPEGStill: MPEG sequence, v1, progressive Y'CbCr 4:2:0 video, CIF PAL, 25 fps
% ffmpeg -i MPEGStill
[...]
[mpegvideo @ 0x1001f8d4b70] Estimating duration from bitrate, this may be inaccurate
Input #0, mpegvideo, from 'MPEGStill':
  Duration: 00:00:00.00, bitrate: 104786 kb/s
  Stream #0:0: Video: mpeg1video, yuv420p(tv), 352x288 [SAR 1:1 DAR 11:9], 104857 kb/s, 25 tbr, 1200k tbn
</pre></div>
<p>
We'll use the famous <a href="https://en.wikipedia.org/wiki/SMPTE_color_bars#/media/File:SMPTE_Color_Bars.svg">SMPTE colour bars</a> at a 4:3 aspect ratio. Based on the specs above, we should be able to approximate it with a command line line <tt>ffmpeg -i smpte.png -s 352x288 -r 25 -c:v mpeg1video -pix_fmt yuv420p nu.mpg</tt>, but this doesn't quite work.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi2Awvj72whLl1HbYjyjSnNNn5a_4xy7S8n9L59l_CIqkz_esCE16IGsgquK5thEZdHIN7yan-EIDgY_rSfi5VlCsoXOJQPhoaRI1h77BBrZrac1K4pQPfpZh1nFUoCZnbHUD8-lHE87klJgPKxzukoYXrCLv568-T8OIrzuZTSDRUJP5H8jD0FKGjT0i8/s1920/vlcsnap-2023-07-13-20h40m31s473.png"><img alt="" width="320" data-original-height="1200" data-original-width="1920" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi2Awvj72whLl1HbYjyjSnNNn5a_4xy7S8n9L59l_CIqkz_esCE16IGsgquK5thEZdHIN7yan-EIDgY_rSfi5VlCsoXOJQPhoaRI1h77BBrZrac1K4pQPfpZh1nFUoCZnbHUD8-lHE87klJgPKxzukoYXrCLv568-T8OIrzuZTSDRUJP5H8jD0FKGjT0i8/s320/vlcsnap-2023-07-13-20h40m31s473.png"></a></p><p>

The reason is it doesn't is because </p><tt>ffmpeg</tt><p> generated an <a href="https://en.wikipedia.org/wiki/MPEG_program_stream">MPEG program stream</a> and the decoder hardware wants an <a href="https://en.wikipedia.org/wiki/MPEG_elementary_stream">MPEG <em>elementary</em> stream</a>.
</p><div><pre>% file nu.mpg
nu.mpg: MPEG sequence, v1, system multiplex
</pre></div>
<p>
While I'm sure we can get <tt>ffmpeg</tt> to cough up the video stream alone, sometimes the simplest approach is to use an additional tool, in this case <a href="http://www.hampa.ch/mpegdemux/"><tt>mpegdemux</tt></a>. It compiled out of the box on my Fedora Linux-based POWER9 Raptor Talos II workstation and generated a file that matches the original <tt>MPEGStill</tt> (and is smaller, too).
</p><div><pre>% mpegdemux -d -s 0xe0 nu.mpg nuu.mpg
% file nuu.mpg
nuu.mpg: MPEG sequence, v1, progressive Y'CbCr 4:2:0 video, CIF PAL, 25 fps
</pre></div>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVS8Hx0hPyVrWKhFynVy0EDgVytBicM2Imzzg-mfLZioKUQAqeA5tkwwznP3pgsowh6aPFYEt-weCq__LE6PHIMrRa43z9ub-EyTBHHbz-rPoRoNA2jMPOs_ew2GqTOfGw3ZEsx-jrrr2wkiSoyn-ZJlbTIH8wHKA7AmFFnIb_Au-XaLbNLquEBMK3cTo/s1176/edfindstr.png"><img alt="" width="320" data-original-height="918" data-original-width="1176" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVS8Hx0hPyVrWKhFynVy0EDgVytBicM2Imzzg-mfLZioKUQAqeA5tkwwznP3pgsowh6aPFYEt-weCq__LE6PHIMrRa43z9ub-EyTBHHbz-rPoRoNA2jMPOs_ew2GqTOfGw3ZEsx-jrrr2wkiSoyn-ZJlbTIH8wHKA7AmFFnIb_Au-XaLbNLquEBMK3cTo/s320/edfindstr.png"></a></p><p>

Finally, we'll fire up ResEdit in Mini vMac. The strings for the error message are part of the "Finder," so we'll edit those. In this case the two message lines are in resource </p><tt>STR##128</tt><p>, strings 11 and 12. More about the other strings later.
</p><p>
When we quit Mini vMac, unmounting the new STB image, we'll need to recompute the checksum and then re-bless the System Folder. Assuming you haven't changed the layout of the folders, changing byte 1119 to 16 (<tt>$10</tt>) will fix the latter. Then the tool <a href="https://github.com/classilla/stbtools/blob/main/splicedisk0.pl"><tt>splicedisk0.pl</tt></a> will take the original red ROM dump and the new STB ROM disk image and emit a new 2MB ROM with a corrected checksum ready for use (if you pass <tt>-fix16</tt>, it will also change that byte for you, but it doesn't do it by default just in case). It will complain if the boot blocks are missing or if the System Folder isn't blessed. Assuming it's happy, burn the new ROM image it generates and fire up the 'Box.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjrEBu8gbp_OeKLNDMyiBBPTmAmxxWDGOIVPQgLP6ijkxexiaKeD0c5tN2D2P1TDs27QXnw1qA6SpGpaqiQZiq9gcHgt8S1A-PCMSe9c4F6IlAqmnXZbPdmC8X9Lg6_6jj-QmJF-9wnWicsm5QpPvTbesLSr6Vd5QnJhnLg7MMZ9uT5nGzQbwu-mipyyl0/s1400/vlcsnap-2023-07-13-22h30m00s552.png"><img alt="" width="320" data-original-height="1050" data-original-width="1400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjrEBu8gbp_OeKLNDMyiBBPTmAmxxWDGOIVPQgLP6ijkxexiaKeD0c5tN2D2P1TDs27QXnw1qA6SpGpaqiQZiq9gcHgt8S1A-PCMSe9c4F6IlAqmnXZbPdmC8X9Lg6_6jj-QmJF-9wnWicsm5QpPvTbesLSr6Vd5QnJhnLg7MMZ9uT5nGzQbwu-mipyyl0/s320/vlcsnap-2023-07-13-22h30m00s552.png"></a></p><p>

Seems appropriate for <a href="https://en.wikipedia.org/wiki/Captain_Midnight_broadcast_signal_intrusion">hacking a cable network</a> box, don't you think? Showtime/Movie Channel, beware!
</p><p>
The abbreviated "Finder" is the piece doing all the magic here. If you simply replace it with the regular Finder or even a teensy tiny Finder substitute like <a href="http://www.pianofab.com/otherp.html">FaberFinder</a>, the yellow LED never appears, meaning to understand what's going on we'll need to figure out what it's up to.
</p><p>
Unlike the standard Finder, STB Finder is just a regular application (with type and creator codes <tt>APPL</tt> and <tt>fHfM</tt>). You can even run it from the extracted disk image, whereupon it turns the screen pink, hides the menu bar and pointer, and just sits there until you quit with Command-Q while it presumably waits for the non-existent power button to be pressed. The timeout error message never appears, even if you're Captain Midnight.
</p><p>
There are, of course, a few interesting resources in it. It was left checked out of Projector and ResEdit warns you about this; the <tt>ckid</tt> resource has the same project and author, and says it's "beta 7 - handles more ways an application can hose itself." (Oh, really?) Accordingly, its (actual) Finder information gives it a version of "<tt>1.0ß7, Copyright © Apple Computer, Inc. 1995</tt>".

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjWtFnwsdGGH_31bLwnKkH4rVTlkxC_lX39TMrrbw8MWvq1Bn1-wKKIZJX8nQG7NMwgUXQw83svL5K7ZXTMVHH55IBgYxZPP4WGCpY3XV-R5pIMCqzR-TuEAZTUwAxPYe8cNjToeh7KTFgtKpzhBJoXUGPMkB1uFT4VKOoNV5YnrY1P1aWdi8nm7y3hr4g/s1176/findermen.png"><img alt="" width="320" data-original-height="918" data-original-width="1176" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjWtFnwsdGGH_31bLwnKkH4rVTlkxC_lX39TMrrbw8MWvq1Bn1-wKKIZJX8nQG7NMwgUXQw83svL5K7ZXTMVHH55IBgYxZPP4WGCpY3XV-R5pIMCqzR-TuEAZTUwAxPYe8cNjToeh7KTFgtKpzhBJoXUGPMkB1uFT4VKOoNV5YnrY1P1aWdi8nm7y3hr4g/s320/findermen.png"></a></p><p>

There is an actual menu bar resource for this application, though it's never used, showing the STB Finder's internal name as </p><tt>FredTVApp</tt><p>. If it has any special response to Command-O, however, it isn't evidenced by pressing the combination on an attached keyboard (only Command-Q), and there is no corresponding resource for an "about" dialogue box.
</p><p>
Let's turn to the disassembler and go through the <tt>CODE</tt> resources now. Only <tt>CODE#1</tt> has actual program data. In these and all succeeding extracts, recall that A7 is the 68000 stack pointer, A6 is the frame pointer and A5 is the app-system globals boundary pointer. <a href="https://github.com/fuzziqersoftware/resource_dasm">The <tt>resource_dasm</tt> disassembler</a> we're using here displays the destination argument first and we will use that convention for new code for consistency. I have fixed up offsets since it got a little confused by the resource layout.
</p><p>
Although there is a fair amount of preamble, here is the <tt>main</tt> function, which I have pre-annotated. Our ability to understand the code is greatly enhanced by the presence of in-line symbols.
</p><div><pre>; main 
; start up GUI 
00000548  4E56 0000                link       A6, 0
0000054C  2F03                     move.l     -[A7], D3
0000054E  7600                     moveq.l    D3, 0x00
00000550  7600                     moveq.l    D3, 0x00
00000552  A063                     syscall    MaxApplZone
; Initialize
; set up event handlers            
; InitGraf, etc.                   
00000554  4EB9 0000 07DE           jsr        [0x000007DE]
0000055A  A852                     syscall    HideCursor
; HideMenuBar
0000055C  4EB9 0000 125E           jsr        [0x0000125E]
; HideIt (nuke menu bar selector)  
00000562  4EB9 0000 12B2           jsr        [0x000012B2]
; DrawMPEGStill
00000568  4EB9 0000 15EE           jsr        [0x000015EE]
; EventLoop
0000056E  4EB9 0000 0588           jsr        [0x00000588]
; Cleanup (doesn't do anything)
00000574  4EB9 0000 096A           jsr        [0x0000096A]
0000057A  261F                     move.l     D3, [A7]+
0000057C  4E5E                     unlink     A6
0000057E  4E75                     rts
00000580  846D 6169 6E00 0000      dc.b       "main"
</pre></div>
<p>
The long and short of it is this was written in a high-level language (most likely C), and the operating system, font and painting operations are regular Macintosh Toolbox A-line traps which the disassembler has kindly filled in for us. That means everything, including the "desktop," draws to the same screen and uses the same calls as any other System 7-compatible application. This phase of the application works on regular System 7 (more about this later on), so we can test our work in Mini vMac instead of burning flash write cycles.
</p><p>
Moving or substantially altering this code in ResEdit has side effects, usually explosive ones. Very carefully and not without a lot of trial-and-error, the first cut was to turn the <tt>HideCursor</tt> syscall into a <tt>nop $4e71</tt>, then neuter <tt>HideMenuBar</tt> and <tt>HideIt</tt> (since other things call them) by setting their first instructions to <tt>rts $4e75</tt>.
</p><p>
Next, we need to redraw the menu after the MPEG still is painted but we can't move the <tt>jsr DrawMPEGStill</tt> up without causing a crash (try it yourself), so we'll insert the <tt>DrawMenuBar $a937</tt> trap into <tt>EventLoop</tt> by obliterating the seemingly superfluous <tt>clr.w</tt> at the beginning (there weren't any spare bytes after the paint in <tt>DrawMPEGStill</tt>). Here's the rest of the event loop.
</p><div><pre>; EventLoop
00000588  4E56 FFEE                link       A6, -0x0012
0000058C  426E FFEE                clr.w      [A6 - 0x12]  &lt;&lt;&lt; MARKED FOR DEATH
00000590  6020                     bra        +0x22 /* 000005B2 */
label00000592:                     
; spin event loop
00000592  554F                     subq.w     A7, 2 
00000594  3F3C FFFF                move.w     -[A7], 0xFFFF
00000598  486E FFF0                pea.l      [A6 - 0x10]
0000059C  4878 001E                push.l     0x1E
000005A0  42A7                     clr.l      -[A7]
000005A2  A860                     syscall    WaitNextEvent
000005A4  101F                     move.b     D0, [A7]+
000005A6  486E FFF0                pea.l      [A6 - 0x10]
; call event handler
000005AA  4EB9 0000 05C8           jsr        [0x000005C8]
000005B0  584F                     addq.w     A7, 4
label000005B2:
; wait for global to turn zero: if so, terminate
; this is set by the Quit menu item
000005B2  4A2D FF44                tst.b      [A5 - 0xBC]
000005B6  66DA                     bne        -0x24 /* 00000592 */
000005B8  4E5E                     unlink     A6
000005BA  4E75                     rts
000005BC  8945 7665 6E74 4C6F 6... dc.b       "EventLoop"
</pre></div>
<p>
In Mini vMac we now have what appears to be a normal, if not particularly useful, application (and no more pink screen), with a regular pointer and menu bar. On the AITB, we get a regular pointer, a black screen, and no menu bar. Eventually the failure text comes up and we crash. But we have a mouse pointer now, so that's a start.
</p><p>
Incidentally, what displays the text is another routine called <tt>DrawMessageText</tt>, which takes two string pointers and displays them centered in Helvetica in those fixed locations. This is called by multiple routines, but if you check back in that <tt>STR#</tt> resource, most of the strings it's called to draw are blank and only the error messages are populated. This is good evidence that the red ROM we have was very late in development and possibly saw production use.
</p><p>
It appears that the "pink screen" — a simple solid window, really — is how the hardware decides where to draw the MPEG frame, essentially a Margot Robbie chroma key. For the second cut, we'll put back that <tt>clr.w</tt> in case it was salient, restore <tt>HideMenuBar</tt> to spew forth the Pepto-Bismol, and put the <tt>DrawMenuBar</tt> trap into <tt>HideIt</tt> (but elide the rest of it as before). That way the menu bar will draw on top of the pink window and should not be obliterated by it. Test run in Mini vMac:
</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhm336-6lDeTovXTcY7ywiPC5-X1W9hk6EN1Vs6O-ZgN7p3vygZFmD1WzZEWlqXxajicX1vGYQSJ2VfxJNHIzTY_MXn1WKKQL_s5fznxEJXAy3OSu8zFG3zbKvMouuAaGNc8VfyGidrJGu7-3FIOQKrp9dZaPDb0sQ-QU7exb710eGgXYMpMLWBnuakBrA/s1176/hifredtv.png"><img alt="" width="320" data-original-height="918" data-original-width="1176" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhm336-6lDeTovXTcY7ywiPC5-X1W9hk6EN1Vs6O-ZgN7p3vygZFmD1WzZEWlqXxajicX1vGYQSJ2VfxJNHIzTY_MXn1WKKQL_s5fznxEJXAy3OSu8zFG3zbKvMouuAaGNc8VfyGidrJGu7-3FIOQKrp9dZaPDb0sQ-QU7exb710eGgXYMpMLWBnuakBrA/s320/hifredtv.png"></a></p>
<p>
Those changes bring back the pink screen but keep the menu bar and pointer. Selecting the About option just makes it beep at us, by the way. Still, it's likely that this part is only the state of the machine <em>before</em> the power button is pressed, and we want to get the screen on (and not time out and crash), so we need to keep going through the disassembly.
</p><p>
It would seem logical to assume that since everything so far has been Toolbox-based, the signal that the power button was pressed is probably also a regular Toolbox Event. Attaching an ADB keyboard to the STB3 and pressing the Power key doesn't do anything, so we go back to the code. The event handler called by the event loop has typical handlers for mouse down, key down, update and activate events, as well as the "high level" event handler for Apple events, but also a mysterious handler for an application-specific <tt>app3Evt</tt> (event type 14).
</p><div><pre>label000006BE: ; app3Evt           
000006BE  4A2D FC76                tst.b      [A5 - 0x38A]
000006C2  6632                     bne        +0x34 /* 000006F6 */
000006C4  0CAA 0000 0115 0002      cmpi.l     [A2 + 0x2], 0x115
000006CC  6628                     bne        +0x2A /* 000006F6 */
000006CE  1B7C 0001 FC76           move.b     [A5 - 0x38A], 0x1
000006D4  2B6A 0006 FC6E           move.l     [A5 - 0x392], [A2 + 0x6]
000006DA  594F                     subq.w     A7, 4
000006DC  2F2D FD34                move.l     -[A7], [A5 - 0x2CC]
000006E0  4267                     clr.w      -[A7]
000006E2  2F3C 0002 001E           move.l     -[A7], 0x2001E
000006E8  7000                     moveq.l    D0, 0x00
000006EA  A82A                     syscall    ComponentDispatch
000006EC  201F                     move.l     D0, [A7]+
; StartTheBootProtocol             
000006EE  4EB9 0000 0A02           jsr        [0x00000A02]
000006F4  6050                     bra        +0x52 /* 00000746 */
label000006F6: 
000006F6  0C2D 0001 FC76           cmpi.b     [A5 - 0x38A], 0x1
000006FC  661E                     bne        +0x20 /* 0000071C */
000006FE  0CAA 0000 0115 0002      cmpi.l     [A2 + 0x2], 0x115
00000706  6614                     bne        +0x16 /* 0000071C */
00000708  701E                     moveq.l    D0, 0x1E
0000070A  D0AD FC6E                add.l      D0, [A5 - 0x392]
0000070E  B0AA 0006                cmp.l      D0, [A2 + 0x6]
00000712  6408                     bcc        +0xA /* 0000071C */
00000714  3F3C 0002                move.w     -[A7], 0x2
00000718  A895                     syscall    ShutDown
0000071A  602A                     bra        +0x2C /* 00000746 */
</pre></div>
<p>
Much of the special hardware control is done through the poorly documented <tt>ComponentDispatch</tt> trap, officially part of the Component Manager (makes sense as QuickTime was its major utilizer and this machine is basically a QuickTime box). Best guess is that it uses the "<tt>STB3 Component</tt>" at resource <tt>thng#48803</tt>, though being related to power-on it could also be the "<tt>I2C Component</tt>" (<tt>thng#48798</tt>). Here, it checks a global variable (i.e., via A5) and a code word, and if that variable is zero but the code word is <tt>0x115</tt>, it calls an internal component (to turn on the screen?) and then calls <tt>StartTheBootProtocol</tt> (which, completely unexpectedly, starts the remote boot sequence). But if the global variable is one with that same code word, it triggers the <tt>ShutDown</tt> trap (which forcibly reboots the AITB). All this sounds like what you'd get if the power button were pressed.
</p><p>
The timeout is in <tt>DoIdle</tt>, which is called within <tt>StartTheBootProtocol</tt>. We'll shortcircuit that.
</p><div><pre>; SendPowerUpMessage               
00000A3E  4EB9 0000 0BE8           jsr        [0x00000BE8]
00000A44  3600                     move.w     D3, D0
; SendBootMessage
00000A46  4EB9 0000 0C54           jsr        [0x00000C54]
00000A4C  3600                     move.w     D3, D0
; get current count
00000A4E  A975                     syscall    TickCount
00000A50  201F                     move.l     D0, [A7]+
00000A52  0680 0000 0708           addi.l     D0, 0x708
00000A58  2B40 FD04                move.l     [A5 - 0x2FC], D0
00000A5C  5C4F                     addq.w     A7, 6
00000A5E  6004                     bra        +0x6 /* 00000A64 */
label00000A60:
; call DoIdle if A5 - 0x300 is null - see flag notes elsewhere
00000A60  4EBA FF1A                jsr        [PC - 0xE6 /* 0000097C */]
label00000A64:
00000A64  4A2D FD00                tst.b      [A5 - 0x300]
00000A68  67F6                     beq        -0x8 /* 00000A60 */  &lt;&lt;&lt; MARKED FOR DEATH
00000A6A  594F                     subq.w     A7, 4
00000A6C  2F2D FD38                move.l     -[A7], [A5 - 0x2C8]
00000A70  2F3C 0000 0703           move.l     -[A7], 0x703
00000A76  7000                     moveq.l    D0, 0x00
00000A78  A82A                     syscall    ComponentDispatch
00000A7A  201F                     move.l     D0, [A7]+
00000A7C  3600                     move.w     D3, D0
00000A7E  3003                     move.w     D0, D3
00000A80  261F                     move.l     D3, [A7]+
00000A82  4E5E                     unlink     A6
00000A84  4E75                     rts
00000A86  9453 7461 7274 5468 6... dc.b       "StartTheBootProtocol"
</pre></div>
<p>
If we make that <tt>beq</tt> at <tt>$a68</tt> a <tt>nop</tt>, then as it won't ever branch to the exit point in <tt>DoIdle</tt>, the function will always exit back to the event loop and thus we'll <em>stay</em> in the event loop forever without timing out. Sounds like it should work!

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjNl5MqR2rYXUZRQTLz4E32Xc8qEz4rLc72AUKbsR3EsW0f1tgdjYXvJ3O0eYAcVwIDFBYovJN-R9zkKPhHf2_QMPaEpb7e3K_jlWeiElsyMaWYI92o6ARVInIjxKfrlJpTdCUxjeZ9gAmiVnPoEE_SNggIP_m4qWuF2duPjhUDJxdQOAPoSyMPFMvyDZ8/s1400/vlcsnap-2023-07-15-19h10m16s019.png"><img alt="" width="320" data-original-height="1050" data-original-width="1400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjNl5MqR2rYXUZRQTLz4E32Xc8qEz4rLc72AUKbsR3EsW0f1tgdjYXvJ3O0eYAcVwIDFBYovJN-R9zkKPhHf2_QMPaEpb7e3K_jlWeiElsyMaWYI92o6ARVInIjxKfrlJpTdCUxjeZ9gAmiVnPoEE_SNggIP_m4qWuF2duPjhUDJxdQOAPoSyMPFMvyDZ8/s320/vlcsnap-2023-07-15-19h10m16s019.png"></a></p><p>

And, well, it sort of worked. We have a mouse pointer and we have a "desktop." In fact, our call to draw the menu bar has clearly caused something different, as you can now see the typical rounded Mac screen borders which weren't present before. (Notice the gutters: this is from the era of CRT displays, so the displayed desktop is within the safe zone.) The mouse pointer even moves with the mouse, and we don't crash or time out! But we have no menu bar despite explicitly asking to draw it and we patched out the only other function that would disable it, so what gives?
</p><p>
Unfortunately I'm not sure what's going on here, exactly. The ROM System file lacks <tt>MDEF</tt> and <tt>MBDF</tt> resources for defining the menu bar and menus, but these resources are present elsewhere in the ROM and don't seem unusually short or weird compared to regular System 7.1. I also couldn't find anywhere obvious that the <tt>DrawMenuBar</tt> trap was patched into a no-op.
</p><p>
On the other hand, our event handler code is still active: if we press Command-Q, the device restarts as usual. If we patch the code that receives a menu click to make Command-O (menu item 1) the same as Command-Q (menu item 2, i.e., change the instruction to branch to the same spot), then Command-O will also quit and restart the STB. That means that even though we can't see our menu options, we can still activate them. Since there's code in the STB Finder to handle the Apple menu, why don't we make Command-O open something else for us?
</p><p>
To the STB disk image I added the 7.1 Chooser and associated components — since eventually we'll need to mount something over LocalTalk — and a copy of the tiny Finder substitute <a href="http://www.pianofab.com/otherp.html">FaberFinder</a> in the Apple Menu Items folder. We'll pare down their resources later. FaberFinder would be item 4 in this case ("About FredTVApp," then a separator, then the Chooser, then FaberFinder). This is the relevant code in the menu handler.
</p><div><pre>00000780  0C43 0001                cmpi.w     D3, 0x1
00000784  6608                     bne        +0xA /* 0000078E */
; beep if the first item (About FredTVApp) is selected
00000786  3F3C 0001                move.w     -[A7], 0x1
0000078A  A9C8                     syscall    SysBeep
; and exit
0000078C  6034                     bra        +0x36 /* 000007C2 */
label0000078E: 
; else handle the rest of the apple menu      
0000078E  594F                     subq.w     A7, 4
00000790  3F3C 0080                move.w     -[A7], 0x80
00000794  A949                     syscall    GetMenuHandle
00000796  205F                     movea.l    A0, [A7]+
00000798  2F08                     move.l     -[A7], A0
0000079A  3F03                     move.w     -[A7], D3
0000079C  486E FF00                pea.l      [A6 - 0x100]
000007A0  A946                     syscall    GetMenuItemText/GetItem
000007A2  554F                     subq.w     A7, 2
000007A4  486E FF00                pea.l      [A6 - 0x100]
000007A8  A9B6                     syscall    OpenDeskAcc
000007AA  301F                     move.w     D0, [A7]+
000007AC  3600                     move.w     D3, D0
000007AE  6012                     bra        +0x14 /* 000007C2 */
label000007B0:
; File menu
000007B0  3003                     move.w     D0, D3
000007B2  48C0                     ext.l      D0
; Open (does nothing)
; item 1
000007B4  5380                     subq.l     D0, 1
000007B6  670A                     beq        +0xC /* 000007C2 */
; Quit (this sets the global quit flag)
; item 2
000007B8  5380                     subq.l     D0, 1
000007BA  6702                     beq        +0x4 /* 000007BE */
</pre></div>
<p>
Since the About item can't be opened on the STB right now anyway, we're going to turn the <tt>move.w -[A7],0x01:SysBeep</tt> into a <tt>bra +0x3c</tt>, opcode <tt>$603a</tt>, so that it still works. That frees up six bytes. We'll make the last two into a <tt>moveq.l D3,#4</tt> opcode <tt>$7604</tt> and fall through into the routine immediately afterwards that opens a desk accessory, then change the branch for the Open item to hit that <tt>moveq</tt>. It should then make Command-O open the fourth item on the menu.
</p><p>
We can test this in Mini vMac, and it worked (it opened the second item of the Apple menu after the separator, which happens to be the AppleCD Player). I loaded it onto the AITB and it did nothing — it didn't crash, but it didn't do anything either. In case it would only work with a real desk accessory (the Chooser is), even though <tt>OpenDeskAcc</tt> in System 7 shouldn't care, I changed it to 3. That worked fine on Mini vMac too, and still not on the AITB. Again, it's not clear if this trap was disabled or altered, or if those apps just plain can't run in this limited environment. More thoughts on that in a little bit.
</p><p>
Do even dialogue boxes work? There are some <tt>ALRT</tt> and <tt>DITL</tt> resources in the red ROM, but instead we'll create a simple dialogue box within the STB Finder and have our Command-O hook display that box. Since the Command-O hook already branches to it, we'll just overwrite the desk accessory code above with this hand-assembled snippet and pad it out with <tt>nop</tt>s.
</p><div><pre>     clr.w -[a7]       ; 4267       ; outparam
     move.w -[a7],#128 ; 3f3c 0080  ; alert 128
     clr.l -[a7]       ; 42a7       ; no filterproc
     Alert             ; a985
     addq.l a7,#2      ; 548f       ; pop outparam
</pre></div>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEheTP23jqXTY71hRON91qq_RRLJjqOwNpiFbSjTaqml7oUqC9Ol2vOpq6QPd7FmSrAgQ9dR1LPhVh_vKECXdulAtYSTSRlZQxc0bgVKcUOk1LRqJKgmZS5mGoL8LaaOFDStwc29RRaiHSHOgUfxlrdi25QXKBrM4Yt0KCeV3rp6ptzlwfM8tr1KFAPHRIE/s1400/vlcsnap-2023-07-16-21h16m28s860.png"><img alt="" width="320" data-original-height="1050" data-original-width="1400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEheTP23jqXTY71hRON91qq_RRLJjqOwNpiFbSjTaqml7oUqC9Ol2vOpq6QPd7FmSrAgQ9dR1LPhVh_vKECXdulAtYSTSRlZQxc0bgVKcUOk1LRqJKgmZS5mGoL8LaaOFDStwc29RRaiHSHOgUfxlrdi25QXKBrM4Yt0KCeV3rp6ptzlwfM8tr1KFAPHRIE/s320/vlcsnap-2023-07-16-21h16m28s860.png"></a></p>

<p><a href="https://en.wikipedia.org/wiki/Max_Headroom_signal_hijacking">Catch the wave</a>! The OK button responds correctly to RETURN and to the mouse. The background doesn't repaint, but that's solvable (because it's no longer pink, the MPEG still is no longer painted there). Plus, it makes a beep through the stereo outputs, presumably with that ROM </p><tt>snd #1</tt><p> resource, so sound more or less works fine. Between QuickDraw, audio and some basic support for dialogue boxes at least you could do some sort of basic app with that. It seems the most likely logical resolution for the screen is 640x400, based on experimentation with the dialogue box position.
</p><p>
Still, the Promised Land is to create an AITB ROM that can run arbitrary programs it can download to memory, and the STB ROM disk must clearly do this, or it would never have worked otherwise. To discuss how it worked, it's important to remember that T1/E1 is intrinsically a serial connection: for example, <a href="http://oldvcr.blogspot.com/2022/05/so-long-home-t1-line-hello-hacking-t1.html">my old residential T1 line</a> was basically a hardwired PPP link over HDSL, and even T1-based frame relay was still just serial data with T-carrier framing. As such, the STB ROM treats the T1 connection like a serial port and executes reads and writes on it directly. AppleTalk is not involved.
</p><p>
Based on the symbols and the call chain by manually walking through the disassembly, the end state is for the local client to receive a complete HFS disk image from the remote server. As part of <tt>Initialize</tt> in <tt>main</tt>, the transmit side is setup by <tt>ITVInitWriteChannel</tt> (note the use of another acronym, ITV, which may have been in use earlier), which calls <tt>SerialOpenDrivers</tt> and <tt>SerialInitialize</tt> to handshake with the headend using <tt>SerialHandshake</tt>. When the power-on event is received, the call to <tt>StartTheBootProtocol</tt> in the event handler calls <tt>SendPowerUpMessage</tt> and <tt>SendBootMessage</tt>, which send messages through <tt>ITVWriteBytes</tt> to <tt>SerialWriteBytes</tt>. All messages to and from the cable headend are checksummed ultimately by the routine at <tt>mzbBPCalcChecksum</tt>, called by <tt>VerifyChecksum</tt> and <tt>WriteChecksum</tt>.
</p><p>
After sending the initial startup messages, <tt>StartTheBootProtocol</tt> falls into a loop repeatedly calling <tt>DoIdle</tt>, which will maintain a progress bar based on the current tick and call <tt>BackChannelDataHandler</tt> if data is available to read into the buffer. (<tt>StartTheBootProtocol</tt> is what we said didn't seem to call <tt>WaitNextEvent</tt> very much, because it turns out it doesn't.) This handler will send an abort to the headend and reset the boot state if there is a transmission failure, as will any routine where the checksum is wrong.
</p><p>
<tt>SendPowerUpMessage</tt> sets the first state, to wait for a "size" packet from the headend. Once <tt>BackChannelDataHandler</tt> assembles a complete packet, this first one goes to <tt>SizeMessageHandler</tt>; it allocates the requested memory space for the incoming disk image (or aborts) and calls <tt>SendReadyMessage</tt> which sets the next state, to start receiving data packets. These are routed to <tt>DataMessageHandler</tt> which stores the packet and calls <tt>SendAckMessage</tt>, keeping the progress bar updated. Any timeout will also abort the boot process.
</p><p>
<tt>SendAckMessage</tt> will keep the state pointing to <tt>DataMessageHandler</tt> as packets arrive until the last one, when it will call <tt>GotFinalDataMessage</tt>. <tt>GotFinalDataMessage</tt> sets a global flag to inhibit further calls to <tt>DoIdle</tt> and calls <tt>CreateDiskFromImage</tt> to mount the downloaded disk image, which in turn calls <tt>LaunchSystemUpdate</tt> to run a system update (if there is one) and finally <tt>LaunchStartupApp</tt> to run the main program. No code signature is obviously involved, meaning it will run anything it gets from the remote server assuming the checksums are all valid. The filenames it looks for appear to come from the <tt>DATA#0</tt> resource of the STB Finder, which is copied into memory early during its initialization:
</p><div><pre>00000000  00 00 00 c7 ff ff ff 44  81 01 00 20 f3 83 b9 4d  |.......D... ...M|
00000010  e5 49 1b 20 6b 44 95 eb  00 88 01 04 01 f5 0e 2e  |.I. kD..........|
00000020  53 54 42 44 69 73 6b 44  72 69 76 65 72 43 95 0c  |STBDiskDriverC..|
00000030  53 79 73 74 65 6d 55 70  64 61 74 65 0a 53 74 61  |SystemUpdate.Sta|
00000040  72 74 75 70 41 20 70 99  0a 53 74 61 72 74 75 70  |rtupA p..Startup|
00000050  44 6f 63 6f 73 3d 4d 61  63 53 54 42 3a 72 76 3d  |Docos=MacSTB:rv=|
00000060  31 2e 20 30 88 3a 63 70  3d 36 38 30 34 30 48 8e  |1. 0.:cp=68040H.|
00000070  0e 2e 53 54 42 44 69 73  6b 44 72 69 76 65 72 43  |..STBDiskDriverC|
00000080  87 09 4d 50 45 47 53 74  69 20 6c a3 09 2e 54 53  |..MPEGSti l...TS|
00000090  44 72 69 76 65 72 00 04  2e 41 49 6e 05 2e 41 4f  |Driver...AIn..AO|
000000a0  75 74 00 04 2e 42 49 6e  05 2e 42 4f 75 74 00 01  |ut...BIn..BOut..|
000000b0  00 00 00 00 28 00 00 00  00 28 00 00 00 00 00 00  |....(....(......|
000000c0  00 00 00 00 00 00 00 00  00 00 00 00 00 00 67 40  |..............g@|
000000d0  6e 83 8a 42 30 84 83 83  83 83 9b 40 6b d6 bc 88  |n..B0......@k...|
000000e0  40 46 d7 40 c2 f0 f0 b0  90 8e a6 40 44 85 83 8e  |@F.@.......@D...|
000000f0  8e 95 92 83 84 40 57 85  a8 bc f8 b3 8c b4 8b 9f  |.....@W.........|
00000100  b2 9e ec 99 ec 97 ec b4  98 86 8b a1 a6 85 89 a0  |................|
00000110  e6 af e0 9b 88 a0 b6 ab  aa 8b 99 90 a1 42 13 7f  |.............B..|
00000120  a4 40 48 a0 95 f4 94 bc  94 88 89 40 ad d5 bb fa  |.@H........@....|
00000130  db fa 40 b4 84 40 b2 40  81 f5 b7 f5 9b f8 95 b4  |..@..@.@........|
00000140  bc f0 f0 f1 00 00 00 00                           |........|
</pre></div>
<p>
I'm not sure where those spurious spaces came from, but it appears to run <tt>SystemUpdate</tt>, if it exists, then launches one of two files, which appear to be either <tt>StartupApp</tt> or <tt>StartupDoc</tt> (again, based on what's present). The same driver <tt>.STBDiskDriver</tt> that handles accessing the ROM disk likely handles the RAM disk, which is very economical. Also note that the strings in this resource indicate the unit identifies itself as a <tt>MacSTB 1.0</tt> with a 68040, which seems to be sent by the initial message routines, and the presence of the string for <tt>MPEGStill</tt>, which is what <tt>DrawMPEGStill</tt> opens and references.
</p><p>
If you label all the <tt>STR#</tt> strings in the STB Finder with numbers, you should be able to observe the boot stages as most of them call <tt>DrawMessageText</tt>, just with empty strings. I reverted our changes to the STB Finder and just made the resource change so we'd have a "clean" show. Here's the beginning:

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj-fetpyr7KH0FqMT3KdYJZUMZN3KNUlCnvLpZFspSvbXZfZ_NCjrGzIxtV-eijDeMulOl2NQb0UbuUVTCDACUzlrVsfF8mrWE3cv196lE6bLQR1JpQ4qcQ960Rm5I8HKI4lyisDkBAea7UTy0i5XRa7pNiFf7iHV8H8N3scvsh802igte8bQY24U7lZTs/s1400/vlcsnap-2023-07-20-08h20m23s738.png"><img alt="" width="320" data-original-height="1050" data-original-width="1400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj-fetpyr7KH0FqMT3KdYJZUMZN3KNUlCnvLpZFspSvbXZfZ_NCjrGzIxtV-eijDeMulOl2NQb0UbuUVTCDACUzlrVsfF8mrWE3cv196lE6bLQR1JpQ4qcQ960Rm5I8HKI4lyisDkBAea7UTy0i5XRa7pNiFf7iHV8H8N3scvsh802igte8bQY24U7lZTs/s320/vlcsnap-2023-07-20-08h20m23s738.png"></a></p><p>

And the end:

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg36gSq5Ic8BHyBsx0UTnaIOEy74u5KMwlv-XJNb6_1MsJ6bMcByY_r2CaUCzzaGZWOOWjKX1wlTVkxEpvujeHtS-IcgR4NAiYOre5bjcbK5qcUqYYRGRl1PReM3pc0WZ9Jzz6L4xWYsejUjLNwjGKqKKzUARA5ngcZCex0sA7Dsq8ZJYVTR2TtcBEAhV4/s1400/vlcsnap-2023-07-20-08h20m54s145.png"><img alt="" width="320" data-original-height="1050" data-original-width="1400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg36gSq5Ic8BHyBsx0UTnaIOEy74u5KMwlv-XJNb6_1MsJ6bMcByY_r2CaUCzzaGZWOOWjKX1wlTVkxEpvujeHtS-IcgR4NAiYOre5bjcbK5qcUqYYRGRl1PReM3pc0WZ9Jzz6L4xWYsejUjLNwjGKqKKzUARA5ngcZCex0sA7Dsq8ZJYVTR2TtcBEAhV4/s320/vlcsnap-2023-07-20-08h20m54s145.png"></a></p><p>

We never get past the beginning, of course, so we only see the Alpha and the failed Omega.
</p><p>
The actual section of code that triggers execution of the downloaded apps, <tt>DoALaunch</tt>, uses the Toolbox <tt>Launch</tt> trap at <tt>$a9f2</tt>. Notably it generates a MultiFinder extended launch param block but uses an unusual fixed set of launch flags (see <a href="https://preterhuman.net/macstuff/techpubs/mac/Toolbox/Toolbox-39.html">the <tt>SIZE</tt> resource</a>) set to <tt>$4800</tt>, which designate an application that understands suspend and resume but is not MultiFinder-aware. As such it could not run arbitrary classic Mac applications even if the rest of the operating system features were present; it can only run ones coded to work with this limited environment, even though such applications should also work on vanilla System 7 modulo any specialized calls to the AITB hardware drivers. It might be possible to generate an application that could boot something else in the way that things like the Booter application start NetBSD/mac68k, but it's not clear if this could actually boot another version of Mac OS entirely, at least not without including a lot of extra resources that would ordinarily be present in a typical Toolbox ROM.
</p><p>
And that's why we have such an odd hybrid STB Finder where most of its GUI code does nothing on the real hardware. My best guess is that the development systems booted a modified full System 7.1 rather than the bowdlerized mini-System in the red ROM, including all the <tt>thng</tt>s and other necessary STB-specific components (such as the driver for the video card I don't have). It is not obvious that the red ROM is capable of booting any operating system other than itself, which explains why most of the few AITBs in collector hands have green Quadra 605 ROMs: the Q605 ROM has a normal Toolbox and will boot a System Folder from a SCSI volume, or at least others other than mine will, and is compatible enough with the AITB to at least drive the on-board NCR SCSI controller until it can load the other <tt>INIT</tt>s for the unique hardware (the red ROM already has this support). Such a setup would be perfectly cromulent for a developer machine and the surviving units probably mostly came from those settings. That said, whatever the circulating <tt>stbextensions</tt> folder does, it doesn't seem to be enough to enable the other AITB hardware components — though it may simply be incomplete or the bootable OS had other changes.
</p><p>
Either way, given the STB Finder is "just" a regular application, you can run it and the applications it triggers from a regular System 7 installation once you've got the OS booted on an AITB, but now having done so you can test all the other AITB-specific pieces. If you try to run the STB Finder on a regular Mac and forge that event code to force a power-on event, you'll crash, shut down or do nothing because the other needed system components (and hardware) are missing. The system update functionality is particularly interesting, though as there are no known surviving examples of any of the downloaded applications we don't know exactly what they did or how. It can't be excluded that the system update would have actually reflashed the onboard ROM through an unknown mechanism, but there's no obvious facility on the logic board to do so, and over the unit's short lifetime no system update may ever have been deployed.
</p><p>
Let's tie it all together and make a Hello World ROM that you could potentially use as a jumping off point for your other applications. I'm not making this red ROM dump available publicly to avoid the litigious wrath of the Cupertino mothership, but if you have or get a red ROM dump, you can try it. Set up Mini vMac running at least System 7.1 (I use it in Macintosh II mode with System 7.5.5), and, of course, get a flash ROM SIMM and programmer. You'll need ResEdit as well. Note these steps should work with SheepShaver or Basilisk II as well, but those emulators may destroy the STB image's bootblocks and you'd have to restore them afterwards.
</p><p>
Extract the <tt>disk#0</tt> resource from the ROM using <a href="https://github.com/classilla/stbtools/blob/main/resscan.pl">our resource walker</a> (something like <tt>perl resscan.pl RED.rom disk 0</tt> will create a <tt>disk-0.dump</tt> file). Name it something like <tt>stb.img</tt>. Start Mini vMac with both your System 7 boot drive and the STB image on the command line so that they are mounted simultaneously (don't worry, the emulator won't try to boot from the STB image if it's listed second).
</p><p>
Back up the Finder from the STB image and then drag it to ResEdit, which will say it was checked out read-only; you can ignore this. Remove the single <tt>ckid</tt> resource if it annoys you. Optionally, in <tt>STR#</tt> 128 change strings three and four to your desired startup message if you like, and create a new <tt>MPEGStill</tt> file using <tt>ffmpeg</tt> and <tt>mpegdemux</tt> and ensure its type and creator are <tt>MPEG</tt> and <tt>mMPG</tt>.
</p><p>
For the actual "proof of hack" dialogue box, add the <tt>DITL</tt> and <tt>ALRT</tt> resources for your alert dialogue box to the STB Finder; the code below assumes the <tt>ALRT</tt> resource is numbered 128. Open the STB Finder's <tt>CODE</tt> resource 1 and in the hex editor make the following changes:
</p><ul>
<li>Remove the Toolbox call to <tt>HideCursor</tt> at offset <tt>$055a</tt> by changing the opcode to <tt>$4e71</tt>.
</li><li>Add a new handler for our alert routine at offset <tt>$0786</tt> by changing the three opcodes at that location to <tt>$4eba $1810 $4e71</tt>.
</li><li>Change the branch at <tt>$07b6</tt> to point to the new subroutine call by making it <tt>$67ce</tt>.
</li><li>Disable the timeout by changing the opcode at offset <tt>$0a68</tt> to <tt>$4e71</tt>.
</li><li>Neuter the call to <tt>HideIt</tt> at offset <tt>$12b6</tt> by changing the three opcodes starting at that location to <tt>$a937 $4e5e $4e75</tt>.
</li></ul><p>
Finally, add these opcodes to the end, starting at </p><tt>$1f98</tt><p> (the offset after the end of the resource).
</p><div><pre>1f98: 4e56 0000 4267 3f3c
1fa0: 0081 42a7 a985 548f
1fa8: 4e5e 4e75
</pre></div>
<p>
Close and save the modified Finder on the STB disk image and shut down Mini vMac. If you changed the folder structure of the ROM, you will need to manually rebless the System Folder with a hex editor and then merge the STB image back into the ROM with <a href="https://github.com/classilla/stbtools/blob/main/splicedisk0.pl">the splicer</a> (something like <tt>perl splicedisk0.pl RED.rom stb.img NEWRED.rom</tt>). If you didn't change the folder structure, then pass the <tt>-fix16</tt> argument and the splicer will bless the System Folder for you.
</p><p>
Burn the new ROM to your flash ROM SIMM, install it into the AITB, connect an ADB keyboard and mouse, and turn on the AITB's rear power switch. When the LED in the front turns yellow, press the power button. Press Command-O after startup to open the dialogue box.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjb1x_b5kOs_9Z1hDFbdl43qlI3w50INn95aLea276FZi8dh6xgbDhpPMFKK62mHodqugHNN6ZsmRyzX5y1z0PZ-e_9BhBQw8R1gFQcONYaCnlFuh-5Q1RYFqpZBX-YjLFBTohdksV4JpVQBXWTyk6u8__udH-0NIE7RG8orVxk1cfpNuHUx7Iub1SX-Rs/s1400/vlcsnap-2023-07-20-11h09m55s803.png"><img alt="" width="320" data-original-height="1050" data-original-width="1400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjb1x_b5kOs_9Z1hDFbdl43qlI3w50INn95aLea276FZi8dh6xgbDhpPMFKK62mHodqugHNN6ZsmRyzX5y1z0PZ-e_9BhBQw8R1gFQcONYaCnlFuh-5Q1RYFqpZBX-YjLFBTohdksV4JpVQBXWTyk6u8__udH-0NIE7RG8orVxk1cfpNuHUx7Iub1SX-Rs/s320/vlcsnap-2023-07-20-11h09m55s803.png"></a></p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjQq1IF5V5-ZrfyVypPOlwo597-SVULu2aeIo4uoqLK04w-FiJae6j9fnSTC2AXoOZ0flzqurg9C18dBFwIlqrjxKZ--wSu8M-UbKJVkNgcMCXSiNkb2dHRg2efiovV4qk4obSJb_wfdPuo4HnbhcDsCvR1AV82XGw2rFWJ3R8hjL90tgPweTbzRv-d9vM/s1400/vlcsnap-2023-07-20-11h10m13s135.png"><img alt="" width="320" data-original-height="1050" data-original-width="1400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjQq1IF5V5-ZrfyVypPOlwo597-SVULu2aeIo4uoqLK04w-FiJae6j9fnSTC2AXoOZ0flzqurg9C18dBFwIlqrjxKZ--wSu8M-UbKJVkNgcMCXSiNkb2dHRg2efiovV4qk4obSJb_wfdPuo4HnbhcDsCvR1AV82XGw2rFWJ3R8hjL90tgPweTbzRv-d9vM/s320/vlcsnap-2023-07-20-11h10m13s135.png"></a></p><p>

The AITB is now your own. Things to do: figure out how to branch to separate code immediately after power-on in the </p><tt>app3Evt</tt><p> handler at </p><tt>$06be</tt><p> (so far I get nothing but crashes trying to muck around there), figure out how the CD-ROM support works with the red ROM, and figure out a means to transfer an application disk image into memory with the real serial port (the AITB can use a serial printer, so there is at least some support for driving the Zilog SCC). And things <em>I</em> need to do: figure out what fuse I opened, or something, to make my own AITB not boot from SCSI. But now this exceptionally rare Apple machine should be much less of a mystery to you.
</p><p>
I would love to hear from you if you were involved in this machine's development (or can even just identify who was in our STB Bunch composite). If you'd prefer not to post a public comment, you can E-mail me at ckaiser at floodgap dawt com.
</p><p>
The code we put together to help walk and modify the red ROM dump <a href="https://github.com/classilla/stbtools">is available on Github</a>.
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ElKaWe – Electrocaloric heat pumps (152 pts)]]></title>
            <link>https://www.fraunhofer.de/en/research/lighthouse-projects-fraunhofer-initiatives/fraunhofer-lighthouse-projects/elkawe.html</link>
            <guid>36823524</guid>
            <pubDate>Sat, 22 Jul 2023 05:20:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fraunhofer.de/en/research/lighthouse-projects-fraunhofer-initiatives/fraunhofer-lighthouse-projects/elkawe.html">https://www.fraunhofer.de/en/research/lighthouse-projects-fraunhofer-initiatives/fraunhofer-lighthouse-projects/elkawe.html</a>, See on <a href="https://news.ycombinator.com/item?id=36823524">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p>In the ElKaWe lighthouse project, six Fraunhofer Institutes under the leadership of the Fraunhofer IPM are working on the development of electrocaloric heat pumps for heating and cooling. Today, heat pumps work almost exclusively on the basis of compressor technology. Electrocaloric heat pumps promise a significantly higher efficiency and do not require harmful refrigerants. As part of the project, scientists are developing ceramic and polymer-based electrocaloric materials and are working on an innovative system approach that enables particularly efficient heat dissipation. The work in the project is intended to demonstrate that electrocaloric heat pumps have the potential to replace compressors in the long term. Heat pumps are an important module in the heat revolution. Powered by regeneratively generated power, they form the missing link between power and heat generation. However, the increase in heat pumps for building air conditioning is slow, due to the poor economic efficiency of compressor-based heat pumps. In cooling technology, the gradual ban on refrigerants under the European F-Gas Regulations makes alternative, refrigerant-free technologies more desirable.</p> 
<h4>How does an electrocaloric heat pump work?</h4> 
<p>When an electrical field is applied to electrocaloric materials, the electrical dipole moments in the field are aligned – this additional order is accompanied by heating of the material according to thermodynamics laws. The resulting heat is dissipated via a heat sink, meaning the material cools down again to its initial temperature.&nbsp;If the electric field is now removed, order is reduced and the material cools, also in accordance with the laws of thermodynamics. Now it can absorb thermal energy from a heat source. The effect is reversible. This allows a cycle to be established that functions as an efficient heat pump for cooling or heating.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AWS networking concepts in a diagram (192 pts)]]></title>
            <link>https://miparnisariblog.wordpress.com/2023/03/29/aws-networking-concepts/</link>
            <guid>36823516</guid>
            <pubDate>Sat, 22 Jul 2023 05:18:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://miparnisariblog.wordpress.com/2023/03/29/aws-networking-concepts/">https://miparnisariblog.wordpress.com/2023/03/29/aws-networking-concepts/</a>, See on <a href="https://news.ycombinator.com/item?id=36823516">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">
	<p><a href="#content">Skip to content</a></p><!-- #masthead -->

	<div id="content">
		<main id="main" role="main">

		
			
<article id="post-528">
	<!-- .entry-header -->

	<div>
		
<p>Before March 2023 I couldn’t for the life of me understand what was going on in the AWS VPC dashboard. I mean, look at the length of the scrolling bar on the left-hand panel!</p>



<figure><img data-attachment-id="531" data-permalink="https://miparnisariblog.wordpress.com/2023/03/29/aws-networking-concepts/image-12/" data-orig-file="https://miparnisariblog.files.wordpress.com/2023/03/image.png" data-orig-size="2324,2114" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://miparnisariblog.files.wordpress.com/2023/03/image.png?w=300" data-large-file="https://miparnisariblog.files.wordpress.com/2023/03/image.png?w=660" src="https://miparnisariblog.files.wordpress.com/2023/03/image.png?w=1024" alt="" srcset="https://miparnisariblog.files.wordpress.com/2023/03/image.png?w=1024 1024w, https://miparnisariblog.files.wordpress.com/2023/03/image.png?w=2048 2048w, https://miparnisariblog.files.wordpress.com/2023/03/image.png?w=150 150w, https://miparnisariblog.files.wordpress.com/2023/03/image.png?w=300 300w, https://miparnisariblog.files.wordpress.com/2023/03/image.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>So, with the goal of figuring out the various resources involved in networking, I read (most of) this book: <a href="https://www.goodreads.com/book/show/60098024-aws-networking-fundamentals">AWS Networking Fundamentals</a>, by Toni Pasanen.</p>



<p>My first thought after finishing it was this: there’s so many resources involved because there’s a lot of types of connections you can have. AWS account to on-premise, account to account, VPC to VPC, subnet to subnet, VPC to internet, VPC to specific AWS services…</p>



<p>So anyway, I made this mind map to link all pieces together:</p>



<pre><code><img src="https://miparnisariblog.files.wordpress.com/2023/03/aws-networking-1.png" alt="aws networking mind map"></code></pre>



<p>Let me know if you find it useful and/or if you find any errors!</p>

				</div><!-- .entry-content -->

	
</article><!-- #post-## -->

				<!-- .navigation -->
	
			
<!-- #comments -->

		
		</main><!-- #main -->
	</div><!-- #content -->

	<!-- #colophon -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What we talk about when we talk about System Design (183 pts)]]></title>
            <link>https://maheshba.bitbucket.io/blog/2023/07/12/Design.html</link>
            <guid>36823375</guid>
            <pubDate>Sat, 22 Jul 2023 04:47:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://maheshba.bitbucket.io/blog/2023/07/12/Design.html">https://maheshba.bitbucket.io/blog/2023/07/12/Design.html</a>, See on <a href="https://news.ycombinator.com/item?id=36823375">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Early in my research career, I had a chance to work with some of the best system researchers<sup id="fnref:0" role="doc-noteref"><a href="#fn:0" rel="footnote">1</a></sup> in the world on a number of really interesting system designs. One of the enjoyable aspects of research was the particular process used by researchers (particularly in the SOSP/OSDI community) to come up with novel yet practical designs. This design process can be characterized as “fighting complexity with abstraction”: in any complex environment, how do you corral that complexity into cleanly defined boxes (or more technically, abstractions) and then divide functionality across these boxes?</p>

<p>Later, when I switched to “real” jobs in industry (ranging from mission-critical production services to applied R&amp;D), I found that the same design process worked quite well in solving real-world problems in production settings<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">2</a></sup>. In these settings, the sources of complexity are varied (hardware, software, distributed protocols, org boundaries, deployment cycles, customers…) and so are the end-goals (reliability, scale, code velocity, performance, dollar cost); but abstraction-driven design still enabled my teams to hit production goals quickly and safely.</p>

<p>This post is a dump of some rules to follow in this particular design process.</p>

<p>[1] <strong><em>Late-bind on designs</em></strong>. The goal of the design process is not to generate a single point solution, but to instead characterize the design space for a given problem: a single point should then fall naturally out of that space given the problem constraints. Converging early on a single design is harmful; the team should have the ability to jump from one part of the space to another right until a solution is picked.</p>

<p>[2] <strong><em>Each point solution is a DoS attack on the design process</em></strong>. Talking about individual designs in isolation slows down design. Talking about designs in the context of the design space accelerates design. New designs should be described in terms of the design space, so you can immediately convey their relative position compared to other point solutions. Expect a lot of statements of the form: “all solutions must do X”; “solution Y is just X with one change”; “any solution that does X has to also do Y”; etc. Talking about the design space rather than point designs allows you to efficiently late-bind on designs (as in point 1) by lowering the cost of switching designs at any point in the discussion.</p>

<p>[3] <strong><em>Think in parallel; Design together; Implement in parallel; Review together</em></strong>. Certain parts of the design and development process are creative and should be parallelized / sharded, while others require discipline and should be centralized / broadcast<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" rel="footnote">3</a></sup>.</p>
<ul>
  <li>Thinking / brainstorming is a creative process and should happen in parallel with no coordination.</li>
  <li>Design should be centralized. The design space is (strongly consistent) shared state between team members; new ideas should be slotted into this space with synchronous coordination.</li>
  <li>Implementation can happen in parallel. After the centralized design phase, anyone should be able to implement any part of the design. Late-binding to developers is critical; it’s typical (and preferable) for the person implementing an idea to be different from the person who came up with it. Developers often get attached to ideas if they know they’ll get to implement it.</li>
  <li>Reviewing should be centralized. The code base is shared state. API changes in particular have to be reviewed carefully by multiple people to make sure they are not one-way doors. 
In a healthy design process, Design and Review end up being centralized bottlenecks, which is okay. (In research, you have the same four steps; but the carefully reviewed deliverable is typically a paper rather than a codebase).</li>
</ul>

<p>[4] <strong><em>Talk about the problem, not existing systems</em></strong>. It’s tempting to start the design process by looking at similar systems. This carries two types of risk:</p>
<ul>
  <li><em>Solution Complexity&nbsp;» Problem Complexity</em>: Problems have some fundamental complexity (e.g., there’s some space of solutions that can solve atomic commit); however, individual solutions can have unbounded complexity limited only by human creativity (e.g., what does phase 5 of this ‘two-phase commit’ protocol really do?) and exacerbated by project pivots (due to changing business needs or getting scooped in research), team churn (or graduating students), timeline pressures (for publishing papers or landing code). You will often expend more cycles understanding the existing design than you would solving the problem from first principles.</li>
  <li><em>Solution Bias</em>: Even good solutions can bias your thinking towards a particular part of the design space. For example, someone reading the Raft paper might think that collocating learners and acceptors is fundamental (which is not true for Paxos); or someone reading Paxos might think that quorums have to constitute a majority (which is not true for Flexible Paxos).
A great time to look at other systems is after the Design phase, to see if you can map those solutions to your space. Even better, you can often reverse-engineer the details of solutions simply by understanding where they fit in your design space.</li>
</ul>

<p>[5] <strong><em>Always talk about a second application</em></strong>. For each abstraction, the “app” is the layer above it. For example, a filesystem is an app for a block device; TCP is an app for IP. You should be able to describe the functionality of a layer without ever referring to the specifics of the app (e.g., you don’t need to know what a file is when talking about an SSD’s internals). Practically, even if you are implementing only one app, it helps to always consider a second app (or even implement one in tests); to prevent application specifics from leaking into the abstraction.</p>

<p>[6] <strong><em>For each abstraction, build one implementation; plan for a second; hope for a third</em></strong>. In the opposite direction, you don’t want the abstraction’s semantics to rely on its implementation details. One way to ensure this is to talk about multiple implementations in the design process. For instance, if your replication layer is TCP-based (but you plan to also have a UDP-based variant; and you are hopeful that it’ll also work over carrier pigeons), then keeping the UDP variant in your head will prevent you from defining semantics in terms of TCP/IP channels.</p>

<p>[7] <strong><em>Abstraction is not free</em></strong>. Each abstraction layer introduces new semantics that developers have to define precisely and then reason about in generic ways (e.g., a new filesystem has to work with every possible correct implementation of a block device). As a result, abstraction is a balancing act between two types of complexity: the complexity of concreteness (where you have to understand inessential detail – e.g., a filesystem developer reasoning about an FTL implementation) and the complexity of abstractness (where you have to understand a range of possibilities – e.g., a filesystem developer thinking about all the possible implementations of the block device trim API). Each time you add a layer of abstraction, have a precise characterization for why it has to exist, as well as the division of functionality between this layer and the ones around it.</p>

<p>[8] <strong><em>Be critical (but about the right things)</em></strong>. Researchers are used to seeing new ideas emerge from the primordial swamp and are often overly optimistic (part of the PhD training is to make students think more critically about their own ideas). In contrast, developers typically work with well-established systems; and as a result can be more critical of new ideas. New projects tend to look underbaked, feeble, and full of holes<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" rel="footnote">4</a></sup>. But every well-established system at some point was just 2-3 people tossing around half-baked ideas. One way to approach design is to continually de-risk the pieces that are truly unknown; while deferring work on the pieces that are difficult but known. (In the opposite direction, researchers need to be more focused on details and practicality, but this happens naturally in an industry environment).</p>

<hr>



  </div>
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Compromised Microsoft Key: More Impactful Than We Thought (251 pts)]]></title>
            <link>https://www.wiz.io/blog/storm-0558-compromised-microsoft-key-enables-authentication-of-countless-micr</link>
            <guid>36823007</guid>
            <pubDate>Sat, 22 Jul 2023 03:40:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wiz.io/blog/storm-0558-compromised-microsoft-key-enables-authentication-of-countless-micr">https://www.wiz.io/blog/storm-0558-compromised-microsoft-key-enables-authentication-of-countless-micr</a>, See on <a href="https://news.ycombinator.com/item?id=36823007">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/">Microsoft</a> and <a href="https://www.cisa.gov/news-events/cybersecurity-advisories/aa23-193a">CISA</a> recently disclosed a security incident impacting multiple customers of Exchange Online and Outlook.com. According to Microsoft, this incident stemmed from a threat actor attributed to China, Storm-0558, acquiring a private encryption key (MSA key) and using it to forge access tokens for Outlook Web Access (OWA) and Outlook.com. Additionally, the threat actor reportedly exploited two security issues in Microsoft’s token verification process. </p><p>Microsoft have said that Outlook.com and Exchange Online were the only applications known to have been affected via the token forging technique, but Wiz Research has found that the compromised signing key was more powerful than it may have seemed, and was not limited to just those two services. Our researchers concluded that the compromised MSA key could have allowed the threat actor to forge access tokens for multiple types of Azure Active Directory applications, including every application that supports personal account authentication, such as SharePoint, Teams, OneDrive, customers’ applications that support the “login with Microsoft” functionality, and multi-tenant applications in certain conditions.</p><p>In addition, while Microsoft mitigated this risk by revoking the impacted encryption key and publishing <a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/">attacker IOCs,</a> we discovered that it may be difficult for customers to detect the use of forged tokens against their applications due to lack of logs on crucial fields related to the token verification process.</p><p>Why is it so impactful?&nbsp; Identity provider’s signing keys are probably the most powerful secrets in the modern world.&nbsp; For example, they are much more powerful than TLS keys. Even if an attacker got access to the google.com TLS key, they would still need to somehow impersonate a google.com server to gain significant impact. With identity provider keys, one can gain immediate single hop access to everything, any email box, file service or cloud account. This isn’t a Microsoft specific issue, if a signing key for Google, Facebook, Okta or any other major identity provider leaks, the implications are hard to comprehend. Our industry – and especially cloud service providers – must commit to a greater level of security and transparency concerning how they protect critical keys such as this one, to prevent future incidents and limit their potential impact.&nbsp;</p><p>In this post, we will share how we were able to confirm which private key was acquired by the threat actor and how we determined its permissions. We will also unpack some of the technical aspects of this incident and help detect potential use of this compromised key within your environments.</p><h2><span></span><a id="compromised-consumer-signing-key--who-are-you-5"></a>Compromised consumer signing key – who are you?&nbsp;</h2><p>On July 11th, 2023, Microsoft revealed that a malicious actor had obtained an MSA consumer signing key, allowing them to forge access tokens for Exchange Online and Outlook.com accounts.</p><p>Determined to learn more about the incident, we launched an investigation.</p><p>First, we checked which keys could sign OpenID tokens for Microsoft accounts and Azure Active Directory applications. We therefore examined Microsoft’s <a href="https://learn.microsoft.com/en-us/azure/active-directory/develop/access-tokens#validating-tokens">official documentation for OpenID token verification</a>. Interestingly, we discovered that all Azure personal account v2.0 applications depend on a list of <a href="https://login.microsoftonline.com/consumers/discovery/v2.0/keys">8 public keys</a>, and all Azure multi-tenant v2.0 applications with Microsoft account enabled depend on a list of <a href="https://login.microsoftonline.com/common/discovery/v2.0/keys">7 public keys</a> (at the time of writing).</p><p>Using the Internet Archive’s Wayback Machine, we noticed that one of the listed public keys that had been present <a href="http://web.archive.org/web/20160801114452/https:/login.microsoftonline.com/common/discovery/v2.0/keys">since at least 2016</a> was replaced sometime between <a href="http://web.archive.org/web/20230627150747/https:/login.microsoftonline.com/common/discovery/v2.0/keys">June 27th</a> and <a href="http://web.archive.org/web/20230705095601/https:/login.microsoftonline.com/common/discovery/v2.0/keys">July 5th</a>, 2023, matching the time frame in which Microsoft replaced the acquired key according to their blog post.</p><p><em>Metadata of the public key replaced between June 27th and July 5th</em>&nbsp;</p><p>The old public key’s certificate revealed it was issued on April 5th, 2016, and expired on April 4th, 2021, and its thumbprint matched the thumbprint of the key Microsoft <a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/#:~:text=d4b4cccda9228624656bff33d8110955779632aa">listed in their latest blog post</a>, named “Thumbprint of acquired signing key”:</p><div><p>The decoded certificate of the old key (1LTMzakihiRla_8z2BEJVXeWMqo). Obtained from the list intended June 27th, 2023 version of the certificate list for Azure common (mixed audience) applications.</p></div><p>This led us to believe that although the compromised key acquired by Storm-0558 was a private key designed for Microsoft's MSA tenant in Azure, it was also able to sign OpenID v2.0 tokens for multiple types of Azure Active Directory applications.</p><h2><span></span><a id="what-is-the-significance-of-a-compromised-openid-signing-key-16"></a>What is the significance of a compromised OpenID signing key?&nbsp;</h2><p>The Azure identity platform publishes multiple lists of trusted keys scoped to different application types. These serve to validate the integrity of tokens which are issued by Azure Active Directory (AAD). During the authentication process for an AAD application, the application must confirm the token's authenticity by verifying its signature against the correct trusted public key list. This verification determines whether the token should be trusted.</p><p># Azure Active Directory multi-tenant applications:&nbsp;<br></p><p><em>Azure Active Directory public certificates’ lists</em>&nbsp;</p><p>If any of the keys from one of these lists are compromised, there is a significant risk for applications using that list for validation. Such a compromise could enable unauthorized parties to forge valid access tokens for consumption by any application that depends on the Azure identity platform under certain conditions (see below).</p><div><p>The risks of compromised OpenID signing key </p></div><p>Based on what we can deduce from Microsoft’s blog post, Storm-0558 seemingly managed to obtain access to one of <a href="https://login.microsoftonline.com/common/discovery/v2.0/keys">several keys</a> that were intended for signing and verifying AAD access tokens. The compromised key was trusted to sign any OpenID v2.0 access token for personal accounts and mixed-audience (multi-tenant or personal account) AAD applications.</p><div><p>The types of applications that could trust the key acquired by Storm-0558</p></div><p>In other words, Storm-0558 could have theoretically used the private key it acquired to forge tokens to authenticate as any user to any affected application that trusts Microsoft OpenID v2.0 mixed audience and personal-accounts certificates.</p><h2><span></span><a id="which-applications-are-affected-27"></a>Which applications are affected?&nbsp;</h2><p>Based on our analysis, only Azure Active Directory applications that work with Microsoft’s OpenID v2.0 were affected. Version 1.0 applications were not using the compromised key for token validation and therefore were not affected.</p><h3><span></span><a id="applications-supporting-personal-microsoft-accounts-only-29"></a><strong>Applications supporting Personal Microsoft accounts only</strong></h3><p>Any Azure Active Directory application that supports “Personal Microsoft accounts only” and works against Microsoft’s v2.0 protocol was affected<strong>. This includes </strong>managed Microsoft applications, such as Outlook, SharePoint, OneDrive, and Teams, as well as customers’ applications that support Microsoft Account authentication, including those who allow the “Login with Microsoft” functionality.</p><h3><span></span><a id="applications-supporting-accounts-in-any-organizational-directory-any-azure-ad-directory--multi-tenant-and-personal-microsoft-accounts-eg-skype-xbox-31"></a><strong>Applications supporting accounts in any organizational directory (Any Azure AD directory – Multi-tenant) and personal Microsoft accounts (e.g. Skype, Xbox)</strong></h3><p>Any Azure Active Directory application that supported “mixed audience” and works against Microsoft’s v2.0 protocol was affected as well. The threat actor could forge valid access tokens and impersonate application users who signed in with their Personal Microsoft account.</p><p>To restrict the power of MSA keys in impersonating organizational accounts, Microsoft introduced an extension to the OpenID protocol. This extension advises developers to validate the issuer claim by comparing it with the issuer field in the list of the OpenID public keys. By doing this, it aims to prevent an MSA key from signing access tokens with an issuer different than the MSA tenant (9188040d-6c67-4c5b-b112-36a304b66dad). This extension is specific to Microsoft and the responsibility of its implementation rests with the application owner. Therefore, there is a concern that many applications lack this procedure and as a result, the threat actor could potentially impersonate organizational accounts as well (according to Microsoft’s blogpost, OWA was affected by a similar issue).</p><p>To assist Azure developers with adopting this validation functionality, Microsoft added it to their <a href="https://github.com/AzureAD/azure-activedirectory-identitymodel-extensions-for-dotnet/issues/2134">official Azure SDK</a> on July 12.</p><h3><span></span><a id="applications-supporting-accounts-in-any-organizational-directory-any-azure-ad-directory--multi-tenant-35"></a><strong>Applications supporting accounts in any organizational directory (Any Azure AD directory – Multi-tenant)</strong></h3><p>IIf the multi-tenant application is configured to rely on the “<a href="https://login.microsoftonline.com/common/discovery/v2.0/keys">common</a>” v2.0 keys endpoint (instead of “Organizations”), then it is affected but also should be considered misconfigured. The official Microsoft <a href="https://learn.microsoft.com/en-us/azure/active-directory/develop/access-tokens#validating-tokens">documentation</a> is not clear on when the “common” endpoint should be used, and therefore, some multi-tenant applications could be affected as well.</p><h3><span></span><a id="applications-supporting-accounts-in-this-organizational-directory-only-singletenant-37"></a><strong>Applications supporting accounts in this organizational directory only (Singletenant)</strong></h3><p>Single tenant applications were not affected.&nbsp;</p><div><p>How different types of users may have been affected depending on the application type and whether it was properly validating access tokens</p></div><h2><span></span><a id="how-does-key-forging-work-40"></a>How does key forging work?&nbsp;</h2><p>OpenID keys are fundamentally JWTs signed by an authorized private key. As part of the Azure Active Directory token validation procedure, the app developer must confirm that the key is indeed signed by the relevant authority for the intended scope, and that the token's <code>aud</code> field matches the targeted application’s scope.</p><p>To confirm whether the token was truly signed by a trusted Azure authority, the application developer queries a metadata endpoint (named <code>jwks_uri</code>) to pull the permitted certificates for signature verification and verify the token against it.</p><p>To forge a valid access token, the threat actor could have crafted a JWT token, populated it with a victim’s data (e.g. email address), and finally signed it with the trusted compromised key that is listed under the Azure Active Directory public certificates’ endpoint. By submitting the signed token to a targeted application, the malicious actor could have then impersonated the victim.</p><p>Here is a fictitious example of such a forged OpenID token signed by the compromised encryption key, <code>1LTMzakihiRla_8z2BEJVXeWMqo</code>:</p><p>According to Microsoft's guidelines, in order for the token to be considered valid, the issuer claim (<code>iss</code>) must be set to https: //sts.windows.net/9188040d-6c67-4c5b-b112-36a304b66dad/v2.0 since it was specified in the issuer field within the <code>jwks_uri</code> endpoint. As for the tenant ID claim (<code>tid</code>), it must accordingly be set to <code>9188040d-6c67-4c5b-b112-36a304b66dad</code>, the MSA tenant’s ID.</p><p>For AAD mixed-audience applications (multi-tenant and personal-account), any token signed by the MSA tenant for an Azure AD account could be deemed valid, as long as it impersonates a personal account.</p><p>For additional details, check out Microsoft's <a href="https://learn.microsoft.com/en-us/azure/active-directory/develop/access-tokens#validating-tokens">official guidelines</a> on how to verify ID Tokens.</p><h2><span></span><a id="are-azure-customers-still-at-risk-49"></a>Are Azure customers still at risk?&nbsp;</h2><p>Due to Microsoft's revocation of the compromised key, Azure Active Directory applications will no longer accept forged tokens as valid tokens. Tokens with extended expiration dates will also be rejected by these applications.</p><p>However, during previously established sessions with customer applications prior to the revocation, the malicious actor could have leveraged its access to establish persistence. This could have occurred by leveraging the obtained application permissions to issue application-specific access keys or setting up application-specific backdoors. A notable example of this is how, prior to Microsoft’s mitigation, Storm-0558 issued valid Exchange Online access tokens by forging access tokens for Outlook Web Access (OWA).</p><p>There is another potential risk to applications that retained copies of the AAD public keys prior to Microsoft's certificate revocation. Applications that rely on local certificate stores or cached keys and still trust the compromised key remain susceptible to token forgery. It is imperative for these applications to immediately refresh the list of trusted certificates. Microsoft advises refreshing the cache of local stores and certificates at least once a day.</p><h2><span></span><a id="recommendations-for-azure-users-53"></a>Recommendations for Azure users&nbsp;</h2><p>To identify whether a compromised key was used in your environment, identify all potentially affected applications in your environment, search for forged tokens usage (as explained in the next section) and leverage the Indicators of Compromise (IoCs) <a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/#:~:text=Indicators%20of%20compromise">published by Microsoft</a> on their blog to look for any activity that originates from the IP addresses provided by Microsoft.</p><p>In addition, make sure that none of the applications use a cached version of the Microsoft OpenID public certificates, and if so, refresh the cache.</p><p>Microsoft has added additional verifications to the official Azure SDK, which are designed to prevent the use of MSA keys to authenticate to organization accounts. Users of the package are advised to update it to the <a href="https://github.com/AzureAD/azure-activedirectory-identitymodel-extensions-for-dotnet">latest version</a>.</p><h2><span></span><a id="how-to-detect-the-compromised-key-in-your-environment-57"></a>How to detect the compromised key in your environment&nbsp;</h2><p>Since the threat actor can forge access tokens offline, there is no trail in the Azure portal for token issuance. The only way for cloud customers to identify whether the key was used to target their apps or users is by reviewing application-specific logs for potentially affected AAD apps. Therefore, application owners who want to protect their systems will have to check whether a forged token has been used against their applications.</p><p>To the best of our knowledge, the only affected applications were those that utilized Microsoft v2.0 access token verification using the endpoints ”<a href="https://login.microsoftonline.com/common/discovery/v2.0/keyshttps:/login.microsoftonline.com/common/discovery/v2.0/keys%20common">https://login.microsoftonline.com/common/discovery/v2.0/keyscommon</a>“ and “<a href="https://login.microsoftonline.com/consumers/discovery/v2.0/keys">https://login.microsoftonline.com/consumers/discovery/v2.0/keys</a>“. These parameters make it feasible to filter out applications that were not exposed to this issue.&nbsp;</p><p>First, to identify which AAD applications in your environment might be affected, you can run the following Azure CLI command:&nbsp;</p><p>Additionally, your AAD applications might also be associated with Azure WebApps. To identify which AAD apps are redirecting to any of your WebApps, you can run the following CLI command:&nbsp;</p><p>Next, to identify potentially malicious activities in applications, it is necessary to examine suspicious authentication attempts via OpenID tokens signed by the compromised key. This can be done by unpacking the access tokens used against the application and searching for the string <code>1LTMzakihiRla_8z2BEJVXeWMqo</code> within the <code>kid</code> field of the JOSE Header.&nbsp;</p><p><a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/#:~:text=inactive%20MSA">According to Microsoft</a>, the compromised key was inactive and therefore any access token signed by this key must be considered suspicious.</p><p>Unfortunately, there is a lack of standardized practices when it comes to application-specific logging. Therefore, in most cases, application owners do not have detailed logs containing the raw access token or its signing key. As a result, identifying and investigating such events can prove exceedingly challenging for app owners.</p><p>When examining an AAD application configured solely for multi-tenant authentication (without support for Microsoft personal accounts), it is possible to detect forged tokens by filtering for `iss` and `tid` claims within the access token. Applications commonly use these fields and they are more likely to be present in application logs. Moreover, any attempt to connect with an access token signed by the MSA tenant ID <code>9188040d-6c67-4c5b-b112-36a304b66dad</code> may indicate the use of a compromised key.</p><p>Finally, if you’ve enabled <a href="https://learn.microsoft.com/en-us/azure/azure-monitor/reference/tables/appservicehttplogs">HTTP Logs</a> in your WebApp, you might be able to see which IP addresses have accessed your application. Based on Microsoft’s blogpost, the following IP addresses are associated with the threat actor, so you should validate if your WebApp might have been impacted by running the following query in Log Analytics for each of your potentially affected Web Apps:&nbsp;</p><p>For additional guidance on searching for signs of persistence in your environment, see our <a href="https://www.wiz.io/blog/hunting-for-signs-of-persistence-in-the-cloud-an-ir-guide#hunting-for-signs-of-persistence-in-azure-24">“CircleCI Incident Sign of Persistence” blog</a>.&nbsp;</p><h2><span></span><a id="key-takeaways-72"></a>Key Takeaways&nbsp;</h2><p>The full impact of this incident is much larger than we Initially understood it to be. We believe this event will have long lasting implications on our trust of the cloud and the core components that support it, above all, the identity layer which is the basic fabric of everything we do in cloud. We must learn from it and improve.</p><p>At this stage, it is hard to determine the full extent of the incident as there were millions of applications that were potentially vulnerable, both Microsoft apps and customer apps, and the majority of them lack the sufficient logs to determine if they were compromised or not. However there are some critical actions items that application owners should perform. The first and foremost is to update their Azure SDK to the latest version and ensure their application cache is updated, otherwise their apps may still be vulnerable to a threat actor using the compromised key.</p><p>We will continue to closely monitor this incident and provide updates; this is still an ongoing investigation and there are many unanswered questions (how did the threat actor acquire the key? When exactly did it happen? Were other keys compromised as well?). Finally, we want to thank the Microsoft team for working closely with us on this blog and helping us ensure it is technically accurate.</p><div><div><p><span>See for yourself...</span></p><p>Learn what makes Wiz the platform to enable your cloud security operation</p></div><svg viewBox="0 0 162 177" fill="none" xmlns="http://www.w3.org/2000/svg"><g clip-path="url(#request-demo-block_svg__a)"><rect x="1" y="1.074" width="160" height="174" rx="2.5" fill="#fff"></rect><path fill="#0254EC" d="M1 1h160v22H1z"></path><g clip-path="url(#request-demo-block_svg__b)"><path d="M23.151 7.883c.202.21.593.315.825.36a.03.03 0 0 1 .017.011.032.032 0 0 1 .007.02.032.032 0 0 1-.007.02.03.03 0 0 1-.017.01c-.232.047-.623.152-.825.361-.19.197-.29.57-.337.815a.03.03 0 0 1-.011.018.029.029 0 0 1-.038-.001.031.031 0 0 1-.01-.019c-.034-.228-.123-.572-.354-.813-.202-.21-.593-.314-.825-.36a.03.03 0 0 1-.017-.01.032.032 0 0 1 0-.04.03.03 0 0 1 .017-.011c.233-.046.624-.15.825-.36.2-.21.302-.617.346-.859a.031.031 0 0 1 .01-.018.029.029 0 0 1 .038 0c.005.005.009.011.01.018.044.242.145.649.346.858Zm-8.61 1.626v6.395c0 .025.01.05.027.068a.09.09 0 0 0 .065.028h1.365a.09.09 0 0 0 .065-.028.098.098 0 0 0 .027-.068V9.509c0-.025-.01-.05-.027-.067a.09.09 0 0 0-.065-.028h-1.365a.089.089 0 0 0-.065.028.096.096 0 0 0-.027.067Zm2.132 6.367a.087.087 0 0 0 .034.113c.012.007.026.01.04.01h4.957a.09.09 0 0 0 .066-.027.098.098 0 0 0 .027-.068v-1.252a.098.098 0 0 0-.027-.068.093.093 0 0 0-.066-.028h-2.5a.08.08 0 0 1-.041-.01.087.087 0 0 1-.032-.115l2.6-4.892a.087.087 0 0 0-.002-.084.083.083 0 0 0-.03-.03.08.08 0 0 0-.04-.011h-4.91a.089.089 0 0 0-.066.027.099.099 0 0 0-.028.068v1.387a.1.1 0 0 0 .028.068.09.09 0 0 0 .066.028h2.18c.015 0 .029.003.041.01a.087.087 0 0 1 .034.113l-2.331 4.761Zm-2.706-6.463h-1.435a.09.09 0 0 0-.052.017.095.095 0 0 0-.033.045l-1.01 2.755a.034.034 0 0 1-.012.015.031.031 0 0 1-.037.002.033.033 0 0 1-.012-.015L10.17 9.494a.166.166 0 0 0-.056-.069.157.157 0 0 0-.081-.03h-.002a.157.157 0 0 0-.084.03.166.166 0 0 0-.057.07l-1.207 2.737a.033.033 0 0 1-.012.015.032.032 0 0 1-.036-.001.033.033 0 0 1-.012-.016l-1.01-2.755a.095.095 0 0 0-.034-.045.09.09 0 0 0-.052-.017H6.092a.09.09 0 0 0-.043.011.094.094 0 0 0-.033.031.099.099 0 0 0-.01.09l2.373 6.431a.032.032 0 0 0 .029.022.031.031 0 0 0 .019-.005.034.034 0 0 0 .012-.014l1.446-3.013a.166.166 0 0 1 .06-.069.157.157 0 0 1 .17 0c.027.017.047.04.06.069l1.446 3.013c.003.006.008.011.013.014a.032.032 0 0 0 .036-.001.035.035 0 0 0 .011-.016l2.372-6.432a.1.1 0 0 0-.01-.089.09.09 0 0 0-.076-.042Z" fill="#fff"></path></g><path fill="#fff" d="M-22 34h192v136H-22z"></path><path d="M111 45.416h21.6" stroke="url(#request-demo-block_svg__c)" stroke-linecap="round"></path><path d="M76.2 45.416h31.2" stroke="#FFAB31" stroke-linecap="round"></path><ellipse cx="142.2" cy="46.631" rx="9.6" ry="9.715" fill="#0073CF"></ellipse><path d="M145.674 37.96c-.022-.123-.043-.243 0-.363a.854.854 0 0 0-.059-.048 9.412 9.412 0 0 0-1.286-.393c-.402-.085-.801-.15-1.195-.195a9.608 9.608 0 0 0-.934-.045c-3.792 0-7.071 2.225-8.631 5.456.172.289.231.631.283.927.012.072.024.14.037.205.16.79.418 1.501.988 2.107.19.2.339.436.489.672.198.31.396.622.689.86.358.293.738.546 1.195.606 1.473.196 2.378 2.156 1.608 3.373-.244.386-.187.732.14 1.09a6.8 6.8 0 0 1 .546.712c.228.327.457.654.757.924.181.164.205.4.201.635a11.3 11.3 0 0 1-.16 1.68 9.534 9.534 0 0 0 2.264.174c-.011-.45.139-.77.627-.87a.993.993 0 0 0 .617-.462c.378-.611.917-1.05 1.466-1.483.443-.351.736-.789.8-1.37.07-.637 0-.737-.614-.808-.183-.021-.366-.038-.549-.054l-.28-.026c-.024-.003-.05-.004-.076-.006-.145-.01-.308-.02-.341-.152-.122-.488-.486-.64-.85-.793-.14-.059-.28-.117-.407-.195-.614-.375-1.249-.65-1.982-.733-.629-.07-1.387-.304-1.59-.86-.101-.276-.299-.47-.494-.662-.252-.249-.499-.491-.516-.895-.004-.131-.164-.291-.341-.28-.154.009-.163.127-.172.24a.797.797 0 0 1-.009.089c-.031.164-.077.324-.258.355-.21.033-.308-.133-.393-.289-.247-.455-.193-1.234.098-1.492.505-.444 1.246-.47 1.75-.055l.047.04c.077.07.155.14.268.1.164-.06.166-.22.153-.358-.033-.38.092-.683.36-.948.287-.282.429-.628.392-1.048-.022-.24.032-.504.332-.495.386.011.685-.164.989-.342.067-.04.135-.08.204-.117.273-.151.391-.276.251-.613-.151-.36.081-.642.485-.657.075-.002.15.008.225.018.081.011.161.022.241.017.225-.013.419-.144.483-.348.058-.193-.06-.21-.18-.228-.06-.009-.12-.017-.159-.047a2.994 2.994 0 0 0-.21-.144c-.12-.077-.24-.154-.336-.256-.319-.338-.697-.573-1.104-.782-.872-.448-1.536-.026-1.523.975.002.14.002.282-.004.422-.007.13-.048.25-.175.302-.153.062-.306-.002-.361-.131-.186-.437-.549-.652-.914-.868a7.05 7.05 0 0 1-.239-.145c-.387-.246-.387-.548-.081-.872.29-.306.601-.586.948-.824.175-.117.345-.237.402-.464.07-.268.188-.517.496-.537.238-.015.322.158.405.33.025.052.051.105.08.152.284.453.63.87 1.11 1.085.179.08.333-.028.493-.14.111-.078.224-.158.351-.18.142-.024.345-.064.332-.27-.013-.211-.208-.26-.38-.3a1.786 1.786 0 0 0-.09-.017.844.844 0 0 1-.164-.04c-.19-.078-.347-.207-.295-.436.051-.217.236-.293.444-.293.264-.002.461.14.631.324.122.133.241.27.359.405.25.287.501.574.778.83.544.504 1.234.357 1.521-.26.066-.142.041-.28.017-.417ZM150.261 41.353a9.749 9.749 0 0 1 1.539 5.278c0 .436-.028.866-.084 1.288a.311.311 0 0 1-.176.088 5.561 5.561 0 0 1-.115-.102c-.092-.082-.184-.165-.283-.236-.142-.1-.304-.128-.389.074l-.044.115c-.073.202-.149.412-.399.397l-.082-.004c-.343-.017-.693-.034-1.004-.273-1.036-.8-1.198-2.298-.483-3.188.096-.12.185-.278.199-.426.052-.666.526-.902 1.04-1.11.031-.013.062-.025.094-.036.082-.03.164-.061.24-.104.094-.054.162-.147.131-.265-.033-.12-.138-.148-.249-.14-.035.003-.07.009-.105.015a.905.905 0 0 1-.1.014c-.046.003-.093.008-.141.013-.221.024-.453.049-.563-.19-.093-.202.041-.27.179-.34.076-.038.154-.077.195-.14a7.55 7.55 0 0 1 .499-.61l.101-.118Z" fill="#71D96A"></path><path d="M139.704 46.19a.398.398 0 0 1 .112.014l.081.026h.001c.283.088.624.195.539.527-.05.194-.272.125-.481.06a1.659 1.659 0 0 0-.207-.056.56.56 0 0 1-.195-.073 1.113 1.113 0 0 0-.135-.061c-.144-.057-.294-.117-.256-.29.035-.165.18-.156.32-.148.06.004.118.007.167-.003l-.002.002.056.003ZM141.204 46.935a1.417 1.417 0 0 1-.142-.025l-.002-.002c-.029.004-.06.006-.091.008-.149.01-.307.02-.289.223.022.24.266.246.452.237.034-.001.073.002.114.005.157.012.336.025.319-.205-.014-.19-.192-.216-.361-.24Z" fill="#71D96A"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M105 39.344c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.072c0-3.353-2.687-6.071-6-6.071ZM75 39.344c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.072c0-3.353-2.687-6.071-6-6.071ZM136.2 113.42c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072Z" fill="#FFAB31"></path><path d="M45 87.919v25.501" stroke="url(#request-demo-block_svg__d)" stroke-linecap="round"></path><path d="M75 51.488c0 21.251-30 7.286-30 25.502" stroke="url(#request-demo-block_svg__e)" stroke-linecap="round"></path><path d="M45 87.918c0 21.251-30 7.286-30 25.501" stroke="url(#request-demo-block_svg__f)" stroke-linecap="round"></path><path d="M75 51.488c0 21.251 30 7.286 30 25.502" stroke="#FFAB31" stroke-linecap="round"></path><path d="M45 87.918c0 21.251 30 7.286 30 25.501" stroke="url(#request-demo-block_svg__g)" stroke-linecap="round"></path><path d="M105 87.918c0 21.251 31.2 7.286 31.2 25.501" stroke="#FFAB31" stroke-linecap="round"></path><path d="M136 126c0 21.667-30 7.429-30 26" stroke="url(#request-demo-block_svg__h)" stroke-linecap="round"></path><path d="M75 126c0 21.251 31.2 7.286 31.2 25.501" stroke="url(#request-demo-block_svg__i)" stroke-linecap="round"></path><path d="M79.8 81.846h20.4" stroke="url(#request-demo-block_svg__j)" stroke-linecap="round"></path><path d="M111 81.846h19.2" stroke="url(#request-demo-block_svg__k)" stroke-linecap="round"></path><path d="M70.2 81.846H51" stroke="url(#request-demo-block_svg__l)" stroke-linecap="round"></path><path d="M81 156h19.2" stroke="url(#request-demo-block_svg__m)" stroke-linecap="round"></path><path d="M69.2 156H50" stroke="url(#request-demo-block_svg__n)" stroke-linecap="round"></path><path d="M39 81.846H21" stroke="url(#request-demo-block_svg__o)" stroke-linecap="round"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M15 75.775c-3.314 0-6 2.718-6 6.072s2.686 6.072 6 6.072 6-2.718 6-6.072c0-3.353-2.687-6.072-6-6.072Z" fill="#FF1721"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M45 75.775c-3.314 0-6 2.718-6 6.072s2.686 6.072 6 6.072 6-2.718 6-6.072c0-3.353-2.687-6.072-6-6.072Z" fill="#3679DB"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M105 75.775c-3.314 0-6 2.718-6 6.072s2.686 6.072 6 6.072 6-2.718 6-6.072c0-3.353-2.687-6.072-6-6.072ZM75 150c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072ZM75 75.775c-3.314 0-6 2.718-6 6.072s2.686 6.072 6 6.072 6-2.718 6-6.072c0-3.353-2.687-6.072-6-6.072ZM45 150c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072ZM135 75.775c-3.314 0-6 2.718-6 6.072s2.686 6.072 6 6.072 6-2.718 6-6.072c0-3.353-2.687-6.072-6-6.072Z" fill="#FFAB31"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M105 150c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072ZM15 113.42c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072Z" fill="#71D96A"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M45 113.42c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072ZM75 113.42c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072Z" fill="#36AD82"></path></g><rect x="0.5" y="0.574" width="161" height="175" rx="3" stroke="#fff"></rect><defs><linearGradient id="request-demo-block_svg__c" x1="134.657" y1="45.416" x2="111.514" y2="45.416" gradientUnits="userSpaceOnUse"><stop stop-color="#0073CF"></stop><stop offset="1" stop-color="#FFAB31"></stop></linearGradient><linearGradient id="request-demo-block_svg__d" x1="0" y1="113.42" x2="0" y2="95.569" gradientUnits="userSpaceOnUse"><stop stop-color="#36AD82"></stop><stop offset="1" stop-color="#3679DB"></stop></linearGradient><linearGradient id="request-demo-block_svg__e" x1="45.001" y1="77.168" x2="60.065" y2="84.104" gradientUnits="userSpaceOnUse"><stop stop-color="#3679DB"></stop><stop offset="1" stop-color="#FFAB31"></stop></linearGradient><linearGradient id="request-demo-block_svg__f" x1="15.001" y1="113.598" x2="30.065" y2="120.534" gradientUnits="userSpaceOnUse"><stop stop-color="#71D96A"></stop><stop offset="1" stop-color="#3679DB"></stop></linearGradient><linearGradient id="request-demo-block_svg__g" x1="45" y1="87.918" x2="75.294" y2="113.065" gradientUnits="userSpaceOnUse"><stop stop-color="#3679DB"></stop><stop offset="1" stop-color="#36AD82"></stop></linearGradient><linearGradient id="request-demo-block_svg__h" x1="121" y1="134" x2="121" y2="144.5" gradientUnits="userSpaceOnUse"><stop stop-color="#FFAB31"></stop><stop offset="1" stop-color="#71D96A"></stop></linearGradient><linearGradient id="request-demo-block_svg__i" x1="90.6" y1="126" x2="90.6" y2="151.501" gradientUnits="userSpaceOnUse"><stop stop-color="#36AD82"></stop><stop offset="1" stop-color="#71D96A"></stop></linearGradient><linearGradient id="request-demo-block_svg__j" x1="79.8" y1="81.846" x2="103.037" y2="81.846" gradientUnits="userSpaceOnUse"><stop stop-color="#FFAB31"></stop><stop offset="1" stop-color="#FFAB31"></stop></linearGradient><linearGradient id="request-demo-block_svg__k" x1="111" y1="81.846" x2="130.2" y2="81.846" gradientUnits="userSpaceOnUse"><stop stop-color="#FFAB31"></stop><stop offset="1" stop-color="#FFAB31"></stop></linearGradient><linearGradient id="request-demo-block_svg__l" x1="70.327" y1="81.846" x2="48.457" y2="81.846" gradientUnits="userSpaceOnUse"><stop stop-color="#FFAB31"></stop><stop offset="1" stop-color="#3679DB"></stop></linearGradient><linearGradient id="request-demo-block_svg__m" x1="80.873" y1="156" x2="102.743" y2="156" gradientUnits="userSpaceOnUse"><stop stop-color="#FFAB31"></stop><stop offset="1" stop-color="#71D96A"></stop></linearGradient><linearGradient id="request-demo-block_svg__n" x1="69.327" y1="156" x2="47.457" y2="156" gradientUnits="userSpaceOnUse"><stop stop-color="#FFAB31"></stop><stop offset="1" stop-color="#FFAB31"></stop></linearGradient><linearGradient id="request-demo-block_svg__o" x1="37.925" y1="81.719" x2="21" y2="81.719" gradientUnits="userSpaceOnUse"><stop stop-color="#3679DB"></stop><stop offset="1" stop-color="#FF1721"></stop></linearGradient><clipPath id="request-demo-block_svg__a"><rect x="1" y="1.074" width="160" height="174" rx="2.5" fill="#fff"></rect></clipPath><clipPath id="request-demo-block_svg__b"><path fill="#fff" transform="translate(6 7)" d="M0 0h18v9H0z"></path></clipPath></defs></svg></div><h2><span></span><a id="references-77"></a>References&nbsp;</h2><ul><li><p><a href="https://msrc.microsoft.com/blog/2023/07/microsoft-mitigates-china-based-threat-actor-storm-0558-targeting-of-customer-email/">https://msrc.microsoft.com/blog/2023/07/microsoft-mitigates-china-based-threat-actor-storm-0558-targeting-of-customer-email/</a>&nbsp;</p></li><li><p><a href="https://www.cisa.gov/news-events/cybersecurity-advisories/aa23-193a">https://www.cisa.gov/news-events/cybersecurity-advisories/aa23-193a</a>&nbsp;</p></li><li><p><a href="https://blogs.microsoft.com/on-the-issues/2023/07/11/mitigation-china-based-threat-actor/">https://blogs.microsoft.com/on-the-issues/2023/07/11/mitigation-china-based-threat-actor/</a>&nbsp;</p></li><li><p><a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/">https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/</a>&nbsp;</p></li><li><p><a href="https://github.com/AzureAD/azure-activedirectory-identitymodel-extensions-for-dotnet/pull/2136/files">https://github.com/AzureAD/azure-activedirectory-identitymodel-extensions-for-dotnet/pull/2136/files</a>&nbsp;</p></li><li><p><a href="https://github.com/MicrosoftDocs/azure-docs/commit/f17445bb9202a89964ea7311c4374806adfcb28c">https://github.com/MicrosoftDocs/azure-docs/commit/f17445bb9202a89964ea7311c4374806adfcb28c</a>&nbsp;</p></li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Internet search tips (176 pts)]]></title>
            <link>https://gwern.net/search</link>
            <guid>36822880</guid>
            <pubDate>Sat, 22 Jul 2023 03:22:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gwern.net/search">https://gwern.net/search</a>, See on <a href="https://news.ycombinator.com/item?id=36822880">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page-metadata">
        <p>A description of advanced tips and tricks for effective Internet research of papers/​books, with real-world examples.</p>
        
        
      </div><div id="markdownBody">
        <div>
          <blockquote>
            <p>Over time, I developed a certain google-fu and expertise in finding references, papers, and books online. Some of these tricks are not well-known, like checking the Internet Archive (IA) for books.</p>
            <p>I try to write down my search workflow, and give general advice about finding and hosting documents, with <a href="#case-studies">demonstration case studies</a>⁠.</p>
          </blockquote>
        </div>
        <p>Google-fu search skill is something I’ve prided myself ever since elementary school, when the librarian challenged the class to find things in the almanac; not infrequently, I’d win. And I can still remember the exact moment it dawned on me in high school that much of the rest of my life would be spent dealing with searches, paywalls, and broken links. The Internet is the greatest almanac of all, and to the curious, a never-ending cornucopia, so I am sad to see many fail to find things after a cursory search—or not look at all. For most people, if it’s not the first hit in Google/​Google Scholar, it doesn’t exist. Below, I reveal my best Internet search tricks and try to provide a rough flowchart of how to go about an online search, explaining the subtle tricks and <a href="https://en.wikipedia.org/wiki/Tacit_knowledge" data-link-icon="wikipedia" data-link-icon-type="svg">tacit knowledge</a> of search-fu.</p>
        <p>Roughly, we need to have proper tools to create an occasion for a search: we cannot search well if we avoid searching at all. Then each search will differ by which search engine &amp; type of medium we are searching—they all have their own quirks, blind spots, and ways to modify a failed search. Often, we will run into walls, each of which has its own circumvention methods. But once we have <em>found</em> something, we are not done: we would often be foolish &amp; short-sighted if we did not then make sure it <em>stayed</em> found. Finally, we might be interested in advanced topics like ensuring in advance resources can be found in the future if need be, or learning about new things we might want to then go find. To illustrate the overall workflow &amp; provide examples of tacit knowledge, I include many Internet case studies of finding hard-to-find things.</p>
        <section id="papers">
          <h2><a href="#papers" title="Link to section: § 'Papers'">Papers</a></h2>
          <section id="search">
            <h2><a href="#search" title="Link to section: § 'Search'">Search</a></h2>
            <section id="preparation">
              <h3><a href="#preparation" title="Link to section: § 'Preparation'">Preparation</a></h3>
              <p><span>Do or do not; there is no try.</span> The first thing you must do is develop a habit of searching when you have a question: “Google is your friend.” Your only search guaranteed to fail is the one you never run. ( <a href="https://www.lesswrong.com/posts/reitXJgJXFzKpdKyd/beware-trivial-inconveniences" id="alexander-2009-trivial-inconveniences" data-link-icon="LW" data-link-icon-type="text" title="'Beware Trivial Inconveniences', Alexander 2009">Beware trivial inconveniences!</a>)</p>
              <ol>
                <li>
                  <p><strong>Query Syntax Knowledge</strong></p>
                  <p>Know your basic <a href="https://en.wikipedia.org/wiki/Logical_connective" data-link-icon="wikipedia" data-link-icon-type="svg">Boolean operators</a> &amp; the <a href="https://support.google.com/websearch/answer/2466433" data-link-icon="alphabet" data-link-icon-type="svg">key G search operators</a>: double quotes for exact matches, hyphens for negation/​exclusion, and <code>site:</code> for search a specific website or specific directory of that website (eg. <code>foo site:gwern.net/docs/genetics/</code>, or to exclude folders, <code>foo site:gwern.net -site:gwern.net/docs/</code>). You may also want to play with <a href="https://gwern.net/doc/www/www.google.com/ad76c5678e80cfed004ec8c7d6704944cee44b28.html" data-link-icon="alphabet" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://www.google.com/advanced_search" title="(Original URL: https://www.google.com/advanced_search )">Advanced Search</a> to understand what is possible. (There are <a href="https://gwern.net/doc/www/ahrefs.com/dc5e68b27bd732a5613f29f62ee9596826aaafc8.html" data-link-icon="alphabet" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://ahrefs.com/blog/google-advanced-search-operators/" title="(Original URL: https://ahrefs.com/blog/google-advanced-search-operators/ )">many more G search operators</a> ( <a href="https://docs.google.com/document/d/1ydVaJJeL1EYbWtlfj9TPfBTE5IBADkQfZrQaBZxqXGs/mobilebasic" data-link-icon="worddoc" data-link-icon-type="svg" title="Google's Advanced Search Operators">Russell description</a>) but they aren’t necessarily worth learning, because they implement esoteric functionality and most seem to be buggy<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a>⁠.)</p>
                </li>
                <li>
                  <p><strong>Hotkey Shortcuts</strong> (<em>strongly recommended</em>)</p>
                  <p>Enable some kind of hotkey search with both prompt and copy-paste selection buffer, to turn searching Google (G)/​Google Scholar (GS)/​Wikipedia (WP) into a reflex.<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a> You should be able to search instinctively within a split second of becoming curious, with a few keystrokes. (If you can’t use it while IRCing without the other person noting your pauses, it’s not fast enough.)</p>
                  <p>Example tools: <a href="https://en.wikipedia.org/wiki/AutoHotkey#Examples" data-link-icon="wikipedia" data-link-icon-type="svg">AutoHotkey</a> (Windows), <a href="https://en.wikipedia.org/wiki/Quicksilver_(software)" data-link-icon="wikipedia" data-link-icon-type="svg">Quicksilver</a> (Mac), <a href="https://github.com/astrand/xclip" data-link-icon="github" data-link-icon-type="svg">xclip</a>+<a href="https://web.archive.org/web/20220427164018/https://en.wikipedia.org/wiki/Surfraw" data-link-icon="internetarchive" data-link-icon-type="svg">Surfraw</a>⁠/ ​<a href="https://en.wikipedia.org/wiki/StumpWM" data-link-icon="wikipedia" data-link-icon-type="svg">StumpWM’s</a> <a href="https://github.com/stumpwm/stumpwm-contrib/blob/master/util/searchengines/README.org" data-link-icon="github" data-link-icon-type="svg"><code>search-engines</code></a>⁠/ ​<a href="https://en.wikipedia.org/wiki/Xmonad" data-link-icon="wikipedia" data-link-icon-type="svg">XMonad’s</a> <a href="https://hackage.haskell.org/package/xmonad-contrib-0.15/docs/XMonad-Actions-Search.html" data-link-icon="𝛌" data-link-icon-type="text"><code>Actions.Search</code></a>⁠/ ​<a href="https://hackage.haskell.org/package/xmonad-contrib-0.15/docs/XMonad-Prompt-Shell.html" data-link-icon="𝛌" data-link-icon-type="text"><code>Prompt.Shell</code></a> (Linux). <a href="https://duckduckgo.com/bangs#bangs-list">DuckDuckGo</a> offers <a href="https://duckduckgo.com/bang_lite.html">‘bangs’</a>⁠, within-engine special searches (most are equivalent to a kind of Google <code>site:</code> search), which can be used similarly or combined with prompts/​macros/​hotkeys.</p>
                  <p><a href="https://wiki.haskell.org/Xmonad/Config_archive/Gwern's_xmonad.hs" data-link-icon="code" data-link-icon-type="svg">I make</a> heavy use of the XMonad hotkeys, which I wrote, and which gives me window manager shortcuts: while using any program, I can highlight a title string, and press <code>Super-shift-y</code> to open the current selection as a GS search in a new Firefox tab within an instant; if I want to edit the title (perhaps to add an author surname, year, or keyword), I can instead open a prompt, <code>Super-y</code>, paste with <code>C-y</code>, and edit it before a <code>\n</code> launches the search. As can be imagined, this is extremely helpful for searching for many papers or for searching. (There are in-browser equivalents to these shortcuts but I disfavor them because they only work if you are in the browser, typically require more keystrokes or mouse use, and don’t usually support hotkeys or searching the copy-paste selection buffer: <a href="https://support.mozilla.org/en-US/kb/keyboard-shortcuts-perform-firefox-tasks-quickly" data-link-icon="FF" data-link-icon-type="text,sans">Firefox</a>⁠, <a href="https://support.google.com/chrome/answer/157179" data-link-icon="alphabet" data-link-icon-type="svg" title="Chrome keyboard shortcuts: Learn keyboard shortcuts and become a pro at using Chrome">Chrome</a>)</p>
                </li>
                <li>
                  <p><strong>Web Browser Hotkeys</strong></p>
                  <p>For navigating between sets of results and entries, you should have good command of your tabbed web browser. You should be able to go to the address bar, move left/​right in tabs, close tabs, open new blank tabs, unclose tabs, go to the <em>n</em><sup>th</sup> tab, etc. (In <a href="https://support.mozilla.org/en-US/kb/keyboard-shortcuts-perform-firefox-tasks-quickly" data-link-icon="FF" data-link-icon-type="text,sans">Firefox</a>⁠/ ​<a href="https://support.google.com/chrome/answer/157179" data-link-icon="alphabet" data-link-icon-type="svg" title="Chrome keyboard shortcuts: Learn keyboard shortcuts and become a pro at using Chrome">Chrome</a> Win/​Linux, those are, respectively: <code>C-l</code>, <code>C-PgUp</code>/​<code>C-PgDwn</code>, <code>C-w</code>, <code>C-t</code>/​<code>C-T</code>, <code>M-[1–9]</code>.)</p>
                </li>
              </ol>
            </section>
            <section id="searching">
              <h3><a href="#searching" title="Link to section: § 'Searching'">Searching</a></h3>
              <p>Having launched your search in, presumably, Google Scholar, you must navigate the GS results. For GS, it is often as simple as clicking on the <code>[PDF]</code> or <code>[HTML]</code> link in the top right which denotes (what GS believes to be) a fulltext link, eg:</p>
              <figure>
                <img alt="An example of a hit in Google Scholar: note the [HTML] link indicating there is a fulltext Pubmed version of this paper (often overlooked by newbies)." decoding="async" height="387" loading="lazy" src="https://gwern.net/doc/technology/google/gwern-googlescholar-search-highlightfulltextlink.png" width="1400">
                
              </figure>
              <p><span>GS: if no fulltext in upper right, look for soft walls.</span> In GS, remember that a fulltext link is <em>not</em> always denoted by a “[PDF]” link! Check the top hits by hand: there are often ‘soft walls’ which block web spiders but still let you download fulltext (perhaps after substantial hassle, like SSRN).</p>
              <p>Note that GS supports other useful features like alerts for search queries, alerts for anything citing a specific paper, and reverse citation searches (to followup on a paper to look for failures-to-replicate or criticisms of it).</p>
              <section id="drilling-down">
                <h4><a href="#drilling-down" title="Link to section: § 'Drilling Down'">Drilling Down</a></h4>
                <p>A useful hit may not turn up immediately. Life is like that.<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a> You may have to get creative:</p>
                <ul>
                  <li>
                    <p><strong>Title searches</strong>: if a paper fulltext doesn’t turn up on the first page, start tweaking (hard rules cannot be given for this, it requires development of <a href="https://en.wikipedia.org/wiki/Tacit_knowledge" data-link-icon="wikipedia" data-link-icon-type="svg">“mechanical sympathy”</a> and asking a mixture of “how would a machine think to classify this” and “how would other people think to write this”):</p>
                  </li>
                  <li>
                    <p><strong>The Golden Mean</strong>: Keep mind when searching, you want some but not too many or too few results. A few hundred hits in GS is around the sweet spot. If you have less than a page of hits, you have made your search too specific.</p>
                    <p>If nothing is turning up, try trimming the title. Titles tend to have more errors towards the end than the beginning, and people often drop So start cutting words off the end of the title to broaden the search. Think about what kinds of errors you make when you recall titles: you drop punctuation or subtitles, substitute in more familiar synonyms, or otherwise simplify it. (How might OCR software screw up a title?)</p>
                    <p>Pay attention to technical terms that pop up in association with your own query terms, particularly in the snippets or full abstracts. Which ones look like they might be more popular than yours, or indicate yours are usually used slightly different from you think they mean? You may need to switch terms.</p>
                    <p>If deleting a few terms then yields way too many hits, try to filter out large classes of hits with a negation <code>foo -bar</code>, adding as many as necessary; also useful is using OR clauses to open up the search in a more restricted way by adding in possible synonyms, with parentheses for group. This can get quite elaborate, and border on <a href="https://en.wikipedia.org/wiki/Google_hacking" data-link-icon="wikipedia" data-link-icon-type="svg">hacking</a>—I have on occasion resorted to search queries as baroque as <code>(foo OR baz) AND (qux OR quux) -bar -garply -waldo -fred</code> to the point where I hit search query length limits and CAPTCHA barriers.<a href="#fn4" id="fnref4" role="doc-noteref"><sup>4</sup></a> (By that point, it is time to consider alternate attacks.)</p>
                  </li>
                  <li>
                    <p><strong>Tweak The Title</strong>: quote the title; delete any subtitle; try the subtitle instead; be suspicious of any character which is not alphanumeric and if there are colons, split it into two title quotes (instead of searching <code>Foo bar: baz quux</code>, or <code>"Foo bar: baz quux"</code>, search <code>"Foo bar" "baz quux"</code>); swap their order.</p>
                  </li>
                  <li>
                    <p><strong>Tweak The Metadata</strong>:</p>
                    <ul>
                      <li>Add/​remove the year.</li>
                      <li>Add/​remove the first author’s surname. Try searching GS for <em>just</em> the author (<code>author:foo</code>).</li>
                    </ul>
                  </li>
                  <li>
                    <p><strong>Delete Odd Characters/​Punctuation</strong>:</p>
                    <p>Libgen had trouble with colons for a long time, and many websites still do (eg. <a href="https://en.wikipedia.org/wiki/Goodreads" data-link-icon="wikipedia" data-link-icon-type="svg">GoodReads</a>); I don’t know why colons in particular are such trouble, although hyphens/​em-dashes and any kind of quote or apostrophe or period are problematic too. Watch out for words which may be space-separated—if you want to find <a href="https://en.wikipedia.org/wiki/Arpad_Elo" data-link-icon="wikipedia" data-link-icon-type="svg">Arpad Elo’s</a> epochal <a href="https://gwern.net/doc/statistics/order/comparison/1978-elo-theratingofchessplayerspastandpresent.pdf" id="elo-1978" data-link-icon="pdf" data-link-icon-type="svg" title="'<em>The Rating of Chessplayers, Past and Present (Second Edition)</em>', Elo 1978"><em>The Rating of Chessplayers</em></a> in Libgen, you need to search “The Rating of Chess Players” instead! (This is also an example of why falling back to search by author is a good idea.)</p>
                  </li>
                  <li>
                    <p><strong>Tweak Spelling</strong>: Try alternate spellings of British/​American terms. This shouldn’t be necessary, but then, deleting colons or punctuation shouldn’t be necessary either.</p>
                  </li>
                  <li>
                    <p><strong>Check For Book Publication</strong>: many papers are published in the form of <em>book anthologies</em>, not journal articles. So look for the book if the paper is mysteriously abent.</p>
                    <p>A book will not necessarily turn up in GS and thus its constituent papers may not either; similarly, while SH does a good job of linking article paywalls to their respective book compilation in LG, it is far from infallible. If a paper was published in any kind of ‘proceeding’ or ‘conference’ or ‘series’ or anything with an ISBN, the paper may be absent from the usual places but the book readily available. It can be quite frustrating to be searching hard for a paper and realize the book was there in plain sight all along. (My suggestion in such cases for <a href="#post-finding">post-finding</a> is to cut out the relevant page range &amp; upload the paper for others to more easily find.)</p>
                  </li>
                  <li>
                    <p><strong>Use URLs</strong>: if you have a URL, try searching chunks of it, typically towards the end, stripping out dates and domain names.</p>
                  </li>
                  <li>
                    <p><strong>Date Search</strong>:</p>
                    <p>Use a search engine (eg. G/​GS) date range feature (in “Tools”) to search ±4 years: metadata can be wrong, publishing conventions can be odd (eg. a magazine published in ‘June’ may actually be published several months before or after), publishers can be <em>extremely</em> slow. This is particularly useful if you add a date constraint &amp; simultaneously loosen the search query to turn up the most temporally-relevant of what would otherwise be far too many hits. If this doesn’t turn up the relevant target, it might turn up related discussions or fixed citations, since most things are cited most shortly after publication and then vanish into obscurity.</p>
                    <figure>
                      <img alt="Click “Tools” on the far right to access date-range &amp; “verbatim” search modes in Google Search." decoding="async" height="842" loading="lazy" src="https://gwern.net/doc/technology/google/gwern-googlesearch-tools-daterange.png" width="1283">
                      
                    </figure>
                    <figure>
                      <img alt="The “verbatim” mode is useful for forcing more literal matching: without it, a search for “foobar” will insist on hits about music players, hiring contests, etc rather than the programming term itself." decoding="async" height="548" loading="lazy" src="https://gwern.net/doc/technology/google/gwern-googlesearch-tools-verbatim.png" width="1333">
                      
                    </figure>
                    <p>If a year is not specified, try to guess from the medium: popular media has heavy recentist bias &amp; prefers only contemporary research which is ‘news’, while academic publications go back a few more years; the style of the reference can give a hint as to how relatively old some mentioned research or writings is. Frequently, given the author surname and a reasonable guess at some research being a year or two old, the name + date-range + keyword in GS will be enough to find the paper.</p>
                    <ul>
                      <li>
                        <span>Consider errors</span>: typos are common. If nothing is showing up in the date-range despite a specific date, perhaps there was a typographic error. Even a diligent typist will occasionally copy metadata from a previous entry or type the same character twice or 2 characters in the wrong order, and for numbers, there is no spellcheck to help catch such errors. Authors <a href="https://gwern.net/leprechaun#citogenesis-how-often-do-researchers-not-read-the-papers-they-cite" id="gwern-leprechaun-citogenesis-how-often-do-researchers-not-read-the-papers-they-cite" title="'Leprechaun Hunting &amp; Citogenesis § Citogenesis: How Often Do Researchers Not Read The Papers They Cite?', Branwen 2014">frequently propagate bibliographic errors</a> without correcting them (demonstrating, incidentally, that they probably did not read the original and so any summaries should be taken with a grain of salt). Think about transpositions &amp; neighboring keys on a QWERTY keyboard: eg. a year like “1976” may actually be 1966, 1967, 1975, 1977, or 1986.
                      </li>
                    </ul>
                  </li>
                  <li>
                    <p><strong>Add Jargon</strong>: Add technical terminology which <em>might</em> be used by relevant papers; for example, if you are looking for an article on college admissions statistics, any such analysis would probably be using <a href="https://en.wikipedia.org/wiki/Logistic_regression" data-link-icon="wikipedia" data-link-icon-type="svg">logistic regression</a> and, even if they do not say “logistic regression” (in favor of some more precise yet unguessable term) would express their effects in terms of “odds”.</p>
                    <p>If you don’t know what jargon might be used, you may need to back off and look for a review article or textbook or WP page and spend some quality time reading. If you’re using the wrong term, period, nothing will help you; you can spend hours going through countless pages, but that won’t make the wrong term work. You may need to read through overviews until you finally recognize the skeleton of what you want under a completely different (and often rather obtuse) name. Nothing is more frustrating that <em>knowing</em> there must be a large literature on a topic (“Cowen’s Law”) but being unable to <em>find</em> it because it’s named something completely different from expected—and many fields have different names for the same concept or tool. (Occasionally people compile “Rosetta stones” to translate between fields: eg. <a href="https://gwern.net/doc/www/arxiv.org/999c2f28682d1581b2fa3d939a54c2c9bc05cad6.pdf" id="baez-stay-2009" data-link-icon="𝛘" data-link-icon-type="text" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/0903.0340?fallback=original" title="Physics, Topology, Logic and Computation: A Rosetta Stone (Original URL: https://arxiv.org/abs/0903.0340 )"><span><span>Baez &amp; Stay</span><span>2009</span></span></a>⁠, <a href="https://gwern.net/doc/www/arxiv.org/e43cd8342289fecff435e5142a48f10bbdf8e849.pdf" id="bertsekas-2018" data-link-icon="𝛘" data-link-icon-type="text" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/1804.04577?fallback=original" title="Feature-Based Aggregation and Deep Reinforcement Learning: A Survey and Some New Implementations (Original URL: https://arxiv.org/abs/1804.04577 )"><span><span>Bertsekas</span><span>2018</span></span></a>⁠, <a href="https://gwern.net/backstop#meta-learning-paradigms" id="gwern-backstop-meta-learning-paradigms"><span><span><span title="et al">Metz</span> <span>et al</span> <span>2018</span></span>’s Table 1</span></a>⁠. These are invaluable.)</p>
                  </li>
                  <li>
                    <p><strong>Even The Humble Have A Tale To Tell</strong>: Beware hastily dismissing ‘bibliographic’ websites as useless—they may have more than you think.</p>
                    <p>While a bibliographic-focused library site like <code>elibrary.ru</code> is (almost) always useless &amp; clutters up search results by hosting only the citation metadata but not fulltext, every so often I run into a peculiar foreign website (often Indian or Chinese) which happens to have a scan of a book or paper. (eg. <a href="https://gwern.net/doc/genetics/heritable/1954-darlington.pdf" id="darlington-1954" data-link-icon="pdf" data-link-icon-type="svg" title="Heredity and Environment"><span><span>Darlington</span><span>1954</span></span></a>⁠, which eluded me for well over half an hour until, taking the alternate approach of hunting its volume, I out of desperation clicked on an <a href="https://gwern.net/doc/www/krishikosh.egranth.ac.in/3df4adaed8ad670bbe2efc9d5ebbb928d4b073b2.html" rel="archived alternate nofollow" data-url-original="http://krishikosh.egranth.ac.in/handle/1/21169" title="(Original URL: http://krishikosh.egranth.ac.in/handle/1/21169 )">Indian index / ​library website</a> which… had it. Go figure.) Sometimes you have to check every hit, just in case.</p>
                  </li>
                  <li>
                    <p><strong>Search The Internet Archive</strong>:</p>
                    <p>The Internet Archive (IA) deserves special mention as a target because it has a remarkable assortment of scans &amp; uploads from all sorts of sources, including the aforementioned Indian/​Chinese libraries with more laissez-faire approaches. It also exposes OCR of them all. So not infrequently, a book may be available, or a paper exists in the middle of a scan of an entire journal volume, but the IA will be ranked very low in search queries and the snippet will be misleading due to bad OCR. A good search strategy is to drop the quotes around titles or excerpts and focus down to <code>site:archive.org</code> and check the first few hits by hand.</p>
                  </li>
                </ul>
                <section id="hard-cases">
                  <h5><a href="#hard-cases" title="Link to section: § 'Hard Cases'">Hard Cases</a></h5>
                  <p>If the basic tricks aren’t giving any hints of working, you will have to get serious. The title may be completely wrong, or it may be indexed under a different author, or not directly indexed at all, or hidden inside a database. Here are some indirect approaches to finding articles:</p>
                  <ul>
                    <li>
                      <p><strong>Reverse Citations</strong>: Take a look in GS’s “related articles” or “cited by” to find similar articles such as later versions of a paper which may be useful. (These are also good features to know about if you want to check things like “has this ever been replicated?” or are still figuring out the right jargon to search.)</p>
                    </li>
                    <li>
                      <p><strong>Anomalous Hits</strong>: Look for hints of hidden bibliographic connections and anomalous hits.</p>
                      <p>Does a paper pop up high in the search results which doesn’t <em>seem</em> to make sense, such as not containing your keywords in the displayed snippet? GS generally penalizes items which exist as simply bibliographic entries, so if one is ranked high in a sea of fulltexts, that should make you wonder why it is being prioritized. Similarly, for Google Books (GB): a book might be forbidden from displaying even snippets but rank high; that might be for a good reason—it may actually contain the fulltext hidden inside it, or something else relevant.</p>
                      <p>Likewise, you cannot trust metadata too much. The inferred or claimed title may be wrong, and a hit may be your desired target lurking in disguise.</p>
                    </li>
                    <li>
                      <p><strong>Compilation Files</strong>: Some papers can be found by searching for the volume or book title to find it indirectly, especially conference proceedings or anthologies; many papers <em>appear</em> to not be available online but are merely buried deep inside a 500-page PDF, and the G snippet listing is misleading.</p>
                      <p>Conferences are particularly complex bibliographically, so you may need to apply the same tricks as for page titles: drop parts, don’t fixate on the numbers, know that the authors or ISBN or ordering of “title:subtitle” can differ between sources, etc.</p>
                      
                    </li>
                    <li>
                      <p><strong>Search By Issue</strong>: Another approach is to look up the listing for a journal issue, and find the paper by hand; sometimes papers are listed in the journal issue’s online Table of Contents, but just don’t appear in search engines (‽). In particularly insidious cases, a paper may be digitized &amp; available—but lumped in with another paper due to error, or only as part of a catch-all file which contains the last 20 miscellaneous pages of an issue. Page range citations are particularly helpful here because they show where the overlap is, so you can download the suspicious overlapping ‘papers’ to see what they <em>really</em> contain.</p>
                      <p>Esoteric as this may sound, this has been a problem on multiple occasions. (I searched in vain for any hint of <a href="https://gwern.net/doc/psychology/animal/maze/1929-shepard.pdf" id="shepard-1929" data-link-icon="pdf" data-link-icon-type="svg" title="An Unexpected Cue in Maze Learning"><span><span>Shepard</span><span>1929</span></span></a>’s existence, half-convinced it was a typo for his 19<em>5</em>9 publication, until I turned to the raw journal scans. A particularly epic example was <a href="https://gwern.net/doc/genetics/heritable/1966-shockley.pdf" id="shockley-1966" data-link-icon="pdf" data-link-icon-type="svg" title="'Possible Transfer of Metallurgical and Astronomical Approaches to Problem of Environment versus Ethnic Heredity', Shockley 1966"><span><span>Shockley</span><span>1966</span></span></a> where after an hour of hunting, all I had was bibliographic echoes despite apparently being published in a high-profile, easily obtained, &amp; definitely digitized journal, <em>Science</em>—leaving me thoroughly baffled. I eventually looked up the ToC and inferred it had been hidden in a set of abstracts!<a href="#fn5" id="fnref5" role="doc-noteref"><sup>5</sup></a> Or a number of <a href="https://gwern.net/smpy" id="gwern-smpy" title="'SMPY Bibliography', Branwen 2018">SMPY</a> papers turned out to be split or merged with neighboring items in journal issues, and I had to fix them by hand.)</p>
                    </li>
                    <li>
                      <p><strong>Masters/​PhD Theses</strong>: sorry. It may be hopeless if it’s pre-2000. You may well find the citation and even an abstract, but actual fulltext…?</p>
                      <p>If you have a university proxy, you may be able to get a copy off <a href="https://en.wikipedia.org/wiki/ProQuest" data-link-icon="wikipedia" data-link-icon-type="svg">ProQuest</a> (specializing in US theses). If ProQuest does not allow a download but indexes it, that usually means it has a copy archived on microfilm/​microfiche, but no one has yet paid for a scan to be made; you can sign up without any special permission, and then purchase ProQuest scans for ~$43 (as of 2023), and that gives you a downloadable PDF. (They apparently scan non-digital works from their vast backlog only on request, so it’s almost like ransoming papers; which means that buying a scan makes it available to academic subscribers as part of the ProQuest database.)</p>
                      <p>Otherwise, you need full university ILL services<a href="#fn6" id="fnref6" role="doc-noteref"><sup>6</sup></a>⁠, and even that might not be enough (a surprising number of universities appear to restrict access only to the university students/​faculty, with the complicating factor of most theses being stored on microfilm).</p>
                    </li>
                    <li>
                      <p><strong><a href="https://en.wikipedia.org/wiki/Reverse_image_search" data-link-icon="wikipedia" data-link-icon-type="svg">Reverse Image Search</a></strong>: If images are involved, a reverse image search in Google Images or <a href="https://tineye.com/">TinEye</a> or <a href="https://en.wikipedia.org/wiki/Yandex_Search" data-link-icon="wikipedia" data-link-icon-type="svg">Yandex Search</a> can turn up important leads.</p>
                      <p><a href="https://en.wikipedia.org/wiki/Bellingcat" data-link-icon="wikipedia" data-link-icon-type="svg">Bellingcat</a> has a good guide by Aric Toller: <a href="https://gwern.net/doc/www/www.bellingcat.com/bd9929bbe1245e2647608c98c34b3ca746cdc0d7.html" id="toller-2019" rel="archived alternate nofollow" data-url-original="https://www.bellingcat.com/resources/how-tos/2019/12/26/guide-to-using-reverse-image-search-for-investigations/" title="'Guide To Using Reverse Image Search For Investigations', Toller 2019 (Original URL: https://www.bellingcat.com/resources/how-tos/2019/12/26/guide-to-using-reverse-image-search-for-investigations/ )">“Guide To Using Reverse Image Search For Investigations”</a>⁠. (Yandex image search appears to exploit face recognition, text OCR, and other capabilities Google Images will not, and bows less to copyright concerns.)</p>
                      <div>
                        <p>
                          Use Browser <strong>Page Info</strong> to Bypass Image Restrictions
                        </p><p>If you are having trouble downloading an image from a web page which is badly/​maliciously designed to stop you, use <a href="https://support.mozilla.org/en-US/kb/firefox-page-info-window" data-link-icon="FF" data-link-icon-type="text,sans">“View Page Info”’s</a> (<code>C-I</code>) “Media” tab ( <a href="https://gwern.net/doc/cs/2021-04-18-gwern-firefox-viewpageinfo-mediatab.png" data-link-icon="image" data-link-icon-type="svg" data-image-height="1421" data-image-width="1600" title="Screenshot of Firefox's 'View Page Info: Media' dialogue, showing all the images used on a web page for easy review &amp; download, bypassing any restrictions or obstacles the website may try to impose on the reader.">eg</a>), which will list the images in a page and let one download them directly.
                      </p></div>
                    </li>
                    <li>
                      <p><strong>Enemy Action</strong>: Is a page or topic not turning up in Google/​IA that you <em>know</em> ought to be there? Check the website’s <a href="https://en.wikipedia.org/wiki/Robots.txt" data-link-icon="wikipedia" data-link-icon-type="svg"><code>robots.txt</code></a> &amp; <a href="https://en.wikipedia.org/wiki/Sitemaps" data-link-icon="wikipedia" data-link-icon-type="svg">sitemap</a>⁠. While not as relevant as they used to be (due to increasing use of dynamic pages &amp; entities ignoring it), <code>robots.txt</code> can sometimes be relevant: key URLs may be excluded from search results, and overly-restrictive <code>robots.txt</code> can cause enormous holes in IA coverage, which may be impossible to fix (but at least you’ll know why).</p>
                    </li>
                    <li>
                      <p><strong>Patience</strong>: not every paywall can be bypassed immediately, and papers may be embargoed or proxies not immediately available.</p>
                      <p>If something is not available at the moment, it may become available in a few months. Use calendar reminders to check back in to see if an embargoed paper is available or if LG/​SH have obtained it, and whether to proceed to additional search steps like manual requests.</p>
                    </li>
                    <li>
                      <p><strong>Domain Knowledge-Specific Tips</strong>:</p>
                      <ul>
                        <li>
                          <p><span>Twitter</span>: Twitter is indexed in Google so web searches <em>may</em> turn up hits, but if you know any metadata, Twitter’s native search functions are still relatively powerful (although Twitter limits searches in many ways in order to drive business to its staggeringly-expensive ‘firehose’ &amp; historical analytics). Use of <a href="https://twitter.com/search-advanced?lang=en" data-link-icon="twitter" data-link-icon-type="svg">Twitter’s “advanced search”</a> interface, particularly the <code>from:</code> &amp; <code>to:</code> <a href="https://developer.twitter.com/en/docs/twitter-api/v1/rules-and-filtering/search-operators" data-link-icon="twitter" data-link-icon-type="svg">search query operators</a>⁠, can vastly cut down the search space. (Also of note: <code>list:</code>, <code>-filter:retweets</code>, <code>near:</code>, <code>url:</code>, &amp; <code>since:</code>/​<code>until:</code>.)</p>
                        </li>
                        <li>
                          <p><span>US federal courts</span>: US federal court documents can be downloaded off <a href="https://en.wikipedia.org/wiki/PACER_(law)" data-link-icon="wikipedia" data-link-icon-type="svg">PACER</a> after registration; it is pay-per-page ($0.10/​page) but users under a certain level each quarter (currently $15) have their fees waived, so if you are careful, you may not need to pay anything at all. There is a public mirror, called <a href="https://www.courtlistener.com/recap/" data-link-icon="PACR" data-link-icon-type="text,quad">RECAP</a>⁠, which can be searched &amp; downloaded from for free. If you fail to find a case in RECAP and must use PACER (as often happens for obscure cases), please install the <a href="https://en.wikipedia.org/wiki/Free_Law_Project#RECAP" data-link-icon="wikipedia" data-link-icon-type="svg">Firefox /  Chrome RECAP browser extension</a>⁠, which will copy anything you download into RECAP. (This can be handy if you realize later that you should’ve kept a long PDF you downloaded or want to double-check a docket.)</p>
                          <p>Navigating PACER can be difficult because it is an old &amp; highly specialized computer system which assumes you are a lawyer, or at least very familiar with PACER &amp; the American federal court system. As a rule of thumb, if you are looking up a particular case, what you want to do is to search for the first name &amp; surname (even if you have the case ID) for either criminal or civil cases as relevant, and pull up all cases which might pertain to an individual; there can be multiple cases, cases can hibernate for years, be closed, reopened as a different case number, etc. Once you have found the most active or relevant case, you want to look at the “docket”, and check the options to see <em>all</em> documents in the case. This will pull up a list of many documents as the case unfolds over time; most of these documents are legal bureaucracy, like rescheduling hearings or notifications of changed lawyers. You want the <em>longest</em> documents, as those are most likely to be useful. In particular, you want the “indictment”, the “criminal complaint”<a href="#fn7" id="fnref7" role="doc-noteref"><sup>7</sup></a>⁠, and any transcripts of trial testimony.<a href="#fn8" id="fnref8" role="doc-noteref"><sup>8</sup></a> Shorter documents, like 1–2pg entries in the docket, <em>can</em> be useful, but are much less likely to be useful unless you are interested in the exact details of how things like pre-trial negotiations unfold. So carelessly choosing the ‘download all’ option on PACER may blow through your quarterly budget without getting you anything interesting (and also may interfere with RECAP uploading documents).</p>
                          <p>There is no equivalent for state or county court systems, which are balkanized and use a thousand different systems (often privatized &amp; charging far more than PACER); those must be handled on a case by case basis. (Interesting trivia point: according to Nick Bilton’s account of the Silk Road 1 case, the FBI and other federal agencies in the SR1 investigation would deliberately steer cases into state rather than federal courts in order to hide them from the relative transparency of the PACER system. The use of multiple court systems can backfire on them, however, as in the case of SR2’s DoctorClu (see <a href="https://gwern.net/dnm-arrest" id="gwern-dnm-arrest" title="'DNM-related arrests, 2011–2015', Branwen 2012">the DNM arrest census</a> for details), where the local police filings revealed the use of hacking techniques to deanonymize SR2 <a href="https://en.wikipedia.org/wiki/Tor_(network)" data-link-icon="wikipedia" data-link-icon-type="svg">Tor</a> users, implicating CMU’s CERT center—details which were belatedly scrubbed from the PACER filings.)</p>
                        </li>
                        <li>
                          <p><span>charity financials</span>: for USA charity financial filings, do <code>Form 990 site:charity.com</code> and then check <a href="https://en.wikipedia.org/wiki/Candid_(organization)" data-link-icon="wikipedia" data-link-icon-type="svg">GuideStar</a> (eg. looking at <a href="https://gwern.net/girl-scouts" id="gwern-girl-scouts" title="'Girl Scouts &amp; Good Corporate Governance', Branwen 2011">Girl Scouts filings</a> or <a href="https://www.lesswrong.com/posts/PmrD2T6F82RkRkhQv/case-study-reading-edge-s-financial-filings" data-link-icon="LW" data-link-icon-type="text">“Case Study: Reading Edge’s financial filings”</a>). For UK charities, the <a href="https://en.wikipedia.org/wiki/Charity_Commission_for_England_and_Wales" data-link-icon="wikipedia" data-link-icon-type="svg">Charity Commission for England and Wales</a> may be helpful.</p>
                        </li>
                        <li>
                          <p><span>education research</span>: for anything related to education, do a site search of <a href="https://en.wikipedia.org/wiki/Education_Resources_Information_Center" data-link-icon="wikipedia" data-link-icon-type="svg">ERIC</a>⁠, which is similar to IA in that it will often have fulltext which is buried in the usual search results</p>
                        </li>
                        <li>
                          <p><span>Wellcome Library</span>: the <a href="https://wellcomecollection.org/">Wellcome Library</a> has many old journals or books digitized which are impossible to find elsewhere; unfortunately, their SEO is awful &amp; their PDFs are unnecessarily hidden behind click-through EULAs, so they will not show up normally in Google Scholar or elsewhere. If you see the Wellcome Library in your Google hits, check it out carefully.</p>
                        </li>
                        <li>
                          <p><span>magazines</span> (as opposed to scholarly or trade journals) are hard to get.</p>
                          <p>They are not covered in Libgen/​Sci-Hub, which outsource that to MagzDB; coverage is poor, however. An alternative is <a href="https://pdf-giant.top/" data-link-icon="pdf" data-link-icon-type="svg">pdf-giant</a>⁠. Particularly for pre-2000 magazines, one may have to resort to looking for old used copies on eBay. Some magazines are easier than others—I generally give up if I run into a <em>New Scientist</em> citation because it’s never worth the trouble.</p>
                        </li>
                      </ul>
                    </li>
                    <li>
                      <p><strong>Newspapers</strong>: like theses, tricky. I don’t know of any general solutions short of a LexisNexis subscription.<a href="#fn9" id="fnref9" role="doc-noteref"><sup>9</sup></a> An interesting resource for American papers is <a href="https://gwern.net/doc/www/chroniclingamerica.loc.gov/973fc0451da75b2330531f477d417fcc1328ad3f.html" rel="archived alternate nofollow" data-url-original="https://chroniclingamerica.loc.gov/newspapers/" title="(Original URL: https://chroniclingamerica.loc.gov/newspapers/ )">Chronicling America’s “Historic American Newspaper”</a> scans.</p>
                    </li>
                  </ul>
                </section>
              </section>
              <section id="by-quote-or-description">
                <h4><a href="#by-quote-or-description" title="Link to section: § 'By Quote or Description'">By Quote or Description</a></h4>
                <p>For quote/​description searches: if you don’t have a title and are falling back on searching quotes, try varying your search similarly to titles:</p>
                <ul>
                  <li>
                    <p><strong>Novel sentences</strong>: Try the easy search first—whatever looks most memorable or unique.</p>
                  </li>
                  <li>
                    <p><strong>Short quotes are unique</strong>: Don’t search too long a quote, a sentence or two is usually enough to be near-unique, and can be helpful in turning up other sources quoting different chunks which may have better citations.</p>
                    <ul>
                      <li><span>Break up quotes</span>: Because even phrases can be unique, try multiple sub-quotes from a big quote, especially from the beginning and end, which are likely to overlap with quotes which have prior or subsequent passages.</li>
                      <li><span>Odd idiosyncratic wording</span>: Search for oddly-specific phrases or words, especially numbers. 3 or 4 keywords is usually enough.</li>
                      <li><span>Paraphrasing</span>: Look for passages in the original text which seem like they might be based on the same source, particularly if they are simply dropped in without any hint at sourcing and don’t sound like the author; authors typically don’t cite every time they draw on a source, usually only the first time, and during editing the ‘first’ appearance of a source could easily have been moved to later in the text. All of these additional uses are something to add to your searches.</li>
                    </ul>
                  </li>
                  <li>
                    <p><strong>Robust Quotes</strong>: You are fighting a game of Chinese whispers, so look for unique-sounding sentences and terms which can survive garbling in the repeated transmissions.</p>
                    <p>Memories are urban legends told by one neuron to another over the years. Pay attention to how you mis-remember things: you distort them by simplifying them, rounding them to the nearest easiest version, and by adding in details which <em>should</em> have been there. Avoid phrases which could be easily reworded in multiple equivalent ways, as people usually will reword them when quoting from memory, screwing up literal searches. Remember the fallibility of memory and the basic principles of <a href="https://en.wikipedia.org/wiki/Textual_criticism" data-link-icon="wikipedia" data-link-icon-type="svg">textual criticism</a>: people substitute easy-to-remember versions for the <a href="https://en.wikipedia.org/wiki/Lectio_difficilior_potior" data-link-icon="wikipedia" data-link-icon-type="svg">hard</a>⁠, long<a href="#fn10" id="fnref10" role="doc-noteref"><sup>10</sup></a>⁠, or unusual original.</p>
                  </li>
                  <li>
                    <p><strong>Tweak Spelling</strong>: Watch out for punctuation and spelling differences hiding hits.</p>
                  </li>
                  <li>
                    <p><strong>Gradient Ascent</strong>: Longer, less witty versions are usually closer to the original and a sign you are on the right trail. The worse, the better. Sniff in the direction of worse versions. (Authors all too often fail to write what they were supposed to write—as Yogi Berra remarked, <a href="https://gwern.net/doc/www/quoteinvestigator.com/9901447988c3e611b2ff9a241679b89bcb56adad.html" rel="archived alternate nofollow" data-url-original="https://quoteinvestigator.com/2012/12/30/yogi-didnt-say/" title="(Original URL: https://quoteinvestigator.com/2012/12/30/yogi-didnt-say/ )">“I really didn’t say everything I said.”</a>)</p>
                  </li>
                  <li>
                    <p><strong>Search Books</strong>: Switch to GB and hope someone paraphrases or quotes it, and includes a real citation; if you can’t see the full passage or the reference section, look up the <em>book</em> in Libgen.</p>
                  </li>
                </ul>
                <section id="dealing-with-paywalls">
                  <h5><a href="#dealing-with-paywalls" title="Link to section: § 'Dealing With Paywalls'">Dealing With Paywalls</a></h5>
                  <div>
                    <blockquote>
                      <p>Gold once out of the earth is no more due unto it; What was unreasonably committed to the ground is reasonably resumed from it: Let Monuments and rich Fabricks, not Riches adorn mens ashes. The commerce of the living is not to be transferred unto the dead: It is not injustice to take that which none complains to lose, and no man is wronged where no man is possessor.</p>
                      <p><a href="https://en.wikipedia.org/wiki/Hydriotaphia,_Urn_Burial" data-link-icon="wikipedia" data-link-icon-type="svg"><em>Hydriotaphia, Urn Burial</em></a>⁠, Sir <a href="https://en.wikipedia.org/wiki/Thomas_Browne" data-link-icon="wikipedia" data-link-icon-type="svg">Thomas Browne</a></p>
                    </blockquote>
                  </div>
                  <p><span>Use Sci-Hub/​Libgen for books/​papers.</span> A paywall can usually be bypassed by using Libgen (LG)/​Sci-Hub (SH): <a href="http://libgen.rs/scimag/" data-link-icon="raven" data-link-icon-type="svg">papers</a> can be searched directly (ideally with the <a href="https://en.wikipedia.org/wiki/Digital_object_identifier" data-link-icon="wikipedia" data-link-icon-type="svg">DOI</a><a href="#fn11" id="fnref11" role="doc-noteref"><sup>11</sup></a>⁠, but title+author with no quotes will usually work), or an easier way may be to prepend<a href="#fn12" id="fnref12" role="doc-noteref"><sup>12</sup></a> <code>sci-hub.st</code> (or whatever SH mirror you prefer) to the URL of a paywall. Occasionally Sci-Hub will not have a paper or will persistently error out with some HTTP or proxy error, but searching the DOI in Libgen directly will work. Finally, there is a <a href="https://z-lib.is/fulltext">LibGen / Sci-Hub fulltext search engine</a> on the Z-Library mirror, which is a useful alternative to Google Books (despite the poor OCR).</p>
                  <p><span>Use university Internet.</span> If those don’t work and you do not have a university proxy or alumni access, many university libraries have IP-based access rules and also open WiFi or Internet-capable computers with public logins inside the library, which can be used, if you are willing to take the time to visit a university in person, for using their databases (probably a good idea to keep a list of needed items before paying a visit).</p>
                  <p><span>Public libraries too.</span> Public libraries often subscribe to commercial newspapers or magazine databases; they are inconvenient to get to, but you can usually at least check what’s available on their website. Public &amp; school libraries also have a useful trick for getting common schooling-related resources, such as the OED, or the archives of the <em>New York Times</em> or <em>New Yorker</em>: because of their usually unsophisticated &amp; transient userbase, some public &amp; school libraries will post lists of usernames/​passwords on their website (sometimes as a PDF). They shouldn’t, but they do. Googling phrases like “public library <a href="https://en.wikipedia.org/wiki/The_New_Yorker" data-link-icon="wikipedia" data-link-icon-type="svg">New Yorker</a> username password” can turn up examples of these. Used discreetly to fetch an article or two, it will do them no harm. (This trick works less well with passwords to anything else.)</p>
                  <p>If that doesn’t work, there is a more opaque ecosystem of filesharing services: booksc/​bookfi/​bookzz, private torrent trackers like Bibliotik, <a href="https://gwern.net/doc/www/old.reddit.com/f0d2bc439c217ff55bc7659a1ba27eb72ddd68e7.html" data-link-icon="reddit" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://old.reddit.com/r/Piracy/comments/2oftbu/guide_the_idiot_proof_guide_to_downloading_ebooks/" title="(Original URL: https://www.reddit.com/r/Piracy/comments/2oftbu/guide_the_idiot_proof_guide_to_downloading_ebooks/ )">IRC</a> channels with <a href="https://en.wikipedia.org/wiki/XDCC" data-link-icon="wikipedia" data-link-icon-type="svg">XDCC</a> bots like <code>#bookz</code>/​<a href="https://gwern.net/doc/www/ebooks.byethost6.com/49a1f20ea30a50b5e73e590542a13d11e7a1278f.html" rel="archived alternate nofollow" data-url-original="http://ebooks.byethost6.com/?i=1" title="(Original URL: http://ebooks.byethost6.com/?i=1 )"><code>#ebooks</code></a>⁠, old P2P networks like <a href="https://en.wikipedia.org/wiki/EMule" data-link-icon="wikipedia" data-link-icon-type="svg">eMule</a>⁠, private <a href="https://en.wikipedia.org/wiki/DC%2B%2B" data-link-icon="wikipedia" data-link-icon-type="svg">DC++</a> hubs…</p>
                  <p>Site-specific notes:</p>
                  <ul>
                    <li>
                      <p><strong>PubMed</strong>: most papers with a <a href="https://en.wikipedia.org/wiki/PubMed" data-link-icon="wikipedia" data-link-icon-type="svg">PMC</a> ID can be purchased through the Chinese scanning service <a href="https://eurekamag.com/">Eureka Mag</a>⁠; scans are $30 &amp; electronic papers are $20.</p>
                    </li>
                    <li>
                      <p><strong>Elsevier/​<code>sciencedirect.com</code></strong>: easy, always available via SH/​LG</p>
                      <p>Note that many Elsevier journal websites do not work with the SH proxy, although their <code>sciencedirect.com</code> version <em>does</em> and/​or the paper is already in LG. If you see a link to <code>sciencedirect.com</code> on a paywall, try it if SH fails on the journal website itself.</p>
                    </li>
                    <li>
                      <p><a href="https://en.wikipedia.org/wiki/PsycINFO" data-link-icon="wikipedia" data-link-icon-type="svg"><strong>PsycNET</strong></a>: one of the worst sites; SH/​LG never work with the URL method, rarely work with paper titles/​DOIs, and with my university library proxy, loaded pages ‘expire’ and redirect while breaking the browser back button (‽‽‽), combined searches don’t usually work (frequently failing to pull up even bibliographic entries), and only DOI or manual title searches in the EBSCOhost database have a chance of fulltext. (EBSCOhost itself is a fragile search engine which is difficult to query reliably in the absence of a DOI.)</p>
                      <p>Try to find the paper anywhere else besides PsycNET!</p>
                    </li>
                    <li>
                      <p><strong>ProQuest/​JSTOR</strong>: ProQuest/​JSTOR are not standard academic publishers, but have access to or mirrors of a surprisingly large number of publications.</p>
                      <p>I have been surprised how often I have hit deadends, and then discovered a copy sitting in ProQuest/​JSTOR, poorly-indexed by search engines.</p>
                    </li>
                    <li>
                      <p><strong>Custom journal websites</strong>: sometimes a journal will have its own website (eg. <em>Cell</em> or <em>Florida Tax Review</em>), but will still be ultimately run by one of the giants like Elsevier or HeinOnline. (You can often see hints of this in the site design, such as the footer, the URL structure, direct links to the publisher version, etc.)</p>
                      <p>When this is the case, it is usually a waste of time to try to use the journal website: it won’t whitelist university IPs, SH/​LG won’t know how to handle it, etc. Instead, look for the alternative version.</p>
                    </li>
                  </ul>
                </section>
              </section>
            </section>
          </section>
          <section id="request">
            <h2><a href="#request" title="Link to section: § 'Request'">Request</a></h2>
            <p><span>Human flesh search engine.</span> Last resort: if none of this works, there are a few places online you can request a copy (however, they will usually fail if you have exhausted all previous avenues):</p>
            <ul>
              <li>
                <a href="https://gwern.net/doc/www/old.reddit.com/53e945ba27eb68f361a04735673fcab833c8d5b6.html" data-link-icon="reddit" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://old.reddit.com/r/Scholar/" title="(Original URL: https://www.reddit.com/r/Scholar/ )"> / ​r / ​scholar</a>
              </li>
              <li>
                <a href="https://twitter.com/search?f=tweets&amp;vertical=default&amp;q=%23icanhazpdf&amp;src=typd" data-link-icon="twitter" data-link-icon-type="svg"><code>#icanhazpdf</code></a>
              </li>
              <li>
                <a href="https://en.wikipedia.org/wiki/Wikipedia:WikiProject_Resource_Exchange/Resource_Request" data-link-icon="wikipedia" data-link-icon-type="svg">Wikipedia Resource Request</a>
              </li>
              <li>
                <a href="https://www.lesswrong.com/posts/4sAsygakd4oCpbEKs/lesswrong-help-desk-free-paper-downloads-and-more-2014" data-link-icon="LW" data-link-icon-type="text" title="Free research help, editing and article downloads for LessWrong">LW help desk</a>
              </li>
            </ul>
            <p>Finally, you can always try to contact the author. This only occasionally works for the papers I have the hardest time with, since they tend to be old ones where the author is dead or unreachable—any author publishing a paper since 1990 will usually have been digitized <em>somewhere</em>—but it’s easy to try.</p>
          </section>
          <section id="post-finding">
            <h2><a href="#post-finding" title="Link to section: § 'Post-finding'">Post-finding</a></h2>
            <p>After finding a fulltext copy, you should find a reliable long-term link/​place to store it and make it more findable (remember—if it’s not in Google/​Google Scholar, it doesn’t exist!):</p>
            <ul>
              <li>
                <p><strong>Never Link Unreliable Hosts</strong>:</p>
                <ul>
                  <li>
                    <p><span>LG/​SH</span>: Always operate under the assumption they could be gone tomorrow. (As my uncle found out with Library.nu shortly after paying for a lifetime membership!) There are no guarantees either one will be around for long under their legal assaults or the behind-the-scenes dramas, and no guarantee that they are being properly mirrored or will be restored elsewhere.</p>
                    <p>When in doubt, make a copy. Disk space is cheaper every day. Download anything you need and keep a copy of it yourself and, ideally, host it publicly.</p>
                  </li>
                  <li>
                    <p><span>NBER</span>: never rely on a <code>papers.nber.org/tmp/</code> or <code>psycnet.apa.org</code> URL, as they are temporary. (SSRN is also undesirable due to making it increasingly difficult to download, but it is at least reliable.)</p>
                  </li>
                  <li>
                    <p><span>Scribd</span>: never link Scribd—they are a scummy website which impede downloads, and anything on Scribd usually first appeared elsewhere anyway. (In fact, if you run into anything vaguely useful-looking which exists only on Scribd, you’ll do humanity a service if you copy it elsewhere just in case.)</p>
                  </li>
                  <li>
                    <p><span>RG</span>: avoid linking to <a href="https://en.wikipedia.org/wiki/ResearchGate" data-link-icon="wikipedia" data-link-icon-type="svg">ResearchGate</a> (compromised by new ownership &amp; PDFs get deleted routinely, apparently often by authors) or <code>Academia.edu</code> (the URLs are one-time and break)</p>
                  </li>
                  <li>
                    <p><span>high-impact journals</span>: be careful linking to Nature.com or <a href="https://en.wikipedia.org/wiki/Cell_(journal)" data-link-icon="wikipedia" data-link-icon-type="svg"><em>Cell</em></a> (if a paper is not <em>explicitly</em> marked as Open Access, even if it’s available, it may disappear in a few months!<a href="#fn13" id="fnref13" role="doc-noteref"><sup>13</sup></a>); similarly, watch out for <code>wiley.com</code>, <code>tandfonline.com</code>, <code>jstor.org</code>, <code>springer.com</code>, <code>springerlink.com</code>, &amp; <code>mendeley.com</code>, who pull similar shenanigans.</p>
                  </li>
                  <li>
                    <p><code>~/</code>: be careful linking to academic personal directories on university websites (often noticeable by the <a href="https://en.wikipedia.org/wiki/Unix" data-link-icon="wikipedia" data-link-icon-type="svg">Unix</a> convention <code>.edu/~user/</code> or by directories suggestive of ephemeral hosting, like <code>.edu/cs/course112/readings/foo.pdf</code>); they have short half-lives.</p>
                  </li>
                  <li>
                    <p><code>?token=</code>: beware any PDF URL with a lot of trailing garbage in the URL such as query strings like <code>?casa_token</code> or <code>?cookie</code> or <code>?X</code> (or hosted on S3/​AWS); such links may or may not work for other people but will surely stop working soon. (Academia.edu, Nature, and Elsevier are particularly egregious offenders here.)</p>
                  </li>
                </ul>
              </li>
              <li>
                <p><strong>PDF Editing</strong>: if a scan, it may be worth editing the PDF to crop the edges, threshold to binarize it (which, for a bad grayscale or color scan, can drastically reduce filesize while increasing readability), and OCR it.</p>
                <p>I use <a href="https://gscan2pdf.sourceforge.net/" id="ratcliffe-2019" title="'gscan2pdf: A GUI to produce PDFs or DjVus from scanned documents', Ratcliffe 2019">gscan2pdf</a> but there are alternatives worth checking out.</p>
              </li>
              <li>
                <p><strong>Check &amp; Improve Metadata</strong>.</p>
                <p>Adding metadata to papers/​books is a good idea because it makes the file findable in G/​GS (if it’s not online, does it really exist?) and helps you if you decide to use bibliographic software like <a href="https://en.wikipedia.org/wiki/Zotero" data-link-icon="wikipedia" data-link-icon-type="svg">Zotero</a> in the future. Many academic publishers &amp; LG are terrible about metadata, and will not include even title/​author/​DOI/​year.</p>
                <p>PDFs can be easily annotated with metadata using <a href="https://en.wikipedia.org/wiki/ExifTool" data-link-icon="wikipedia" data-link-icon-type="svg">ExifTool</a>:: <code>exiftool -All</code> prints all metadata, and the metadata can be set individually using similar fields.</p>
                <p>For papers hidden inside volumes or other files, you should extract the relevant page range to create a single relevant file. (For extraction of PDF page-ranges, I use <a href="https://en.wikipedia.org/wiki/PDFtk" data-link-icon="wikipedia" data-link-icon-type="svg"><code>pdftk</code></a>⁠, eg: <code>pdftk 2010-davidson-wellplayed10-videogamesvaluemeaning.pdf cat 180-196 output 2009-fortugno.pdf</code>. Many publishers insert a spam page as the first page. You can drop that easily with <code>pdftk INPUT.pdf cat 2-end output OUTPUT.pdf</code>, but note that PDFtk may drop all metadata, so do that before adding any metadata. To delete pseudo-encryption or ‘passworded’ PDFs, do <code>pdftk INPUT.pdf input_pw output OUTPUT.pdf</code>; PDFs using actual encryption are trickier but <a href="#astronomy">can often be beaten</a> by off-the-shelf password-cracking utilities.)</p>
                <p>I try to set at least title/​author/​DOI/​year/​subject, and stuff any additional topics &amp; bibliographic information into the “Keywords” field. Example of setting metadata:</p>
                <div id="cb1">
                  <pre><code><span id="cb1-1"><span>exiftool</span> <span>-Author</span><span>=</span><span>"Frank P. Ramsey"</span> <span>-Date</span><span>=</span>1930 <span>-Title</span><span>=</span><span>"On a Problem of Formal Logic"</span> <span>-DOI</span><span>=</span><span>"10.1112/plms/s2-30.1.264"</span> <span>\</span></span>
<span id="cb1-2">    <span>-Subject</span><span>=</span><span>"mathematics"</span> <span>-Keywords</span><span>=</span><span>"Ramsey theory, Ramsey's theorem, combinatorics, mathematical logic, decidability, </span><span>\</span></span>
<span id="cb1-3"><span>    first-order logic,  Bernays-Schönfinkel-Ramsey class of first-order logic, _Proceedings of the London Mathematical </span><span>\</span></span>
<span id="cb1-4"><span>    Society_, Volume s2-30, Issue 1, 1930-01-01, pg264-286"</span> 1930-ramsey.pdf</span></code></pre>
                </div>
                <div>
                  <p>
                    “PDF Plus” is better than “PDF”.
                  </p><p>If two versions are provided, the “PDF” one may be intended (if there is any real difference) for printing and exclude features like hyperlinks .
                </p></div>
              </li>
              <li>
                <p><strong>Public Hosting</strong>: if possible, host a public copy; especially if it was very difficult to find, even if it was useless, it should be hosted. The life you save may be your own.</p>
              </li>
              <li>
                <p><strong>Link On WP/​Social Media</strong>: for bonus points, link it in appropriate places on Wikipedia or Reddit or Twitter; this makes people aware of the copy being available, and also supercharges visibility in search engines.</p>
              </li>
              <li>
                <p><strong>Link Specific Pages</strong>: as noted before, you can link a specific page by adding <code>#page=N</code> to the URL. Linking the relevant page is helpful to readers. (I recommend against doing this if this is done to link an <em>entire article</em> inside a book, because that article will still have bad SEO and it will be hard to find; in such cases, it’s better to crop out the relevant page range as a standalone article, eg. using <code>pdftk</code> again for <code>pdftk 1900-BOOK.pdf cat 123-456 output 1900-PAPER.pdf</code>.)</p>
              </li>
            </ul>
          </section>
          <section id="advanced">
            <h2><a href="#advanced" title="Link to section: § 'Advanced'">Advanced</a></h2>
            <p>Aside from the (highly-recommended) use of hotkeys and Booleans for searches, there are a few useful tools for the researcher, which while expensive initially, can pay off in the long-term:</p>
            <ul>
              <li>
                <p><a href="https://gwern.net/archiving#remote-caching" id="gwern-archiver-bot"><code>archiver-bot</code></a>: automatically archive your web browsing and/​or links from arbitrary websites to forestall linkrot; particularly useful for detecting &amp; recovering from dead PDF links</p>
              </li>
              <li>
                <p><strong>Subscriptions</strong> like <a href="https://pubmed.ncbi.nlm.nih.gov/" data-link-icon="nlm-ncbi" data-link-icon-type="svg">PubMed</a> &amp; GS search alerts: set up alerts for a specific search query, or for new citations of a specific paper. ( <a href="https://en.wikipedia.org/wiki/Google_Alerts" data-link-icon="wikipedia" data-link-icon-type="svg">Google Alerts</a> is not as useful as it seems.)</p>
                <ol>
                  <li><span>PubMed</span> has straightforward conversion of search queries into alerts: “Create alert” below the search bar. (Given the volume of PubMed indexing, I recommend carefully tailoring your search to be as narrow as possible, or else your alerts may overwhelm you.)</li>
                  <li>To create generic <span>GS</span> search query alert, simply use the “Create alert” on the sidebar for any search. To follow citations of a key paper, you must: 1. bring up the paper in GS; 2. click on “Cited by X”; 3. <em>then</em> use “Create alert” on the sidebar.</li>
                </ol>
              </li>
              <li>
                <p><strong>GCSE</strong>: a <a href="https://programmablesearchengine.google.com/about/" data-link-icon="alphabet" data-link-icon-type="svg">Google Custom Search Engines</a> is a specialized search queries limited to whitelisted pages/​domains etc (eg. my <a href="https://cse.google.com/cse?cx=009114923999563836576%3A1eorkzz2gp4" data-link-icon="alphabet" data-link-icon-type="svg">Wikipedia-focused anime / ​manga CSE</a>).</p>
                <p>A GCSE can be thought of as a saved search query on steroids. If you find yourself regularly including scores of the same domains in multiple searches search, or constantly blacklisting domains with <code>-site:</code> or using many negations to filter out common false positives, it may be time to set up a GCSE which does all that by default.</p>
              </li>
              <li>
                <p><strong>Clippings</strong>: <a href="https://en.wikipedia.org/wiki/Comparison_of_note-taking_software" data-link-icon="wikipedia" data-link-icon-type="svg">note-taking services</a> like <a href="https://en.wikipedia.org/wiki/Evernote" data-link-icon="wikipedia" data-link-icon-type="svg">Evernote</a>⁠/ ​<a href="https://en.wikipedia.org/wiki/Microsoft_OneNote" data-link-icon="wikipedia" data-link-icon-type="svg">Microsoft OneNote</a>: regularly making and keeping excerpts creates a personalized search engine, in effect.</p>
                <p>This can be vital for refinding old things you read where the search terms are hopelessly generic or you can’t remember an <em>exact</em> quote or reference; it is one thing to search a keyword like “autism” in a few score thousand clippings, and another thing to search that in the entire Internet! (One can also reorganize or edit the notes to add in the keywords one is thinking of, to help with refinding.) I make heavy use of Evernote clipping and it is key to refinding my references.</p>
              </li>
              <li>
                <p><strong>Crawling Websites</strong>: sometimes having copies of whole websites might be useful, either for more flexible searching or for ensuring you have anything you might need in the future. (example: <a href="https://gwern.net/dnm-archive" id="gwern-dnm-archive" title="'Darknet Market Archives (2013–2015)', Gwern 2013">“Darknet Market Archives (2013–2015)”</a>).</p>
                <p>Useful tools to know about: <a href="https://en.wikipedia.org/wiki/Wget" data-link-icon="wikipedia" data-link-icon-type="svg">wget</a>⁠, <a href="https://en.wikipedia.org/wiki/CURL" data-link-icon="wikipedia" data-link-icon-type="svg">cURL</a>⁠, <a href="https://en.wikipedia.org/wiki/HTTrack" data-link-icon="wikipedia" data-link-icon-type="svg">HTTrack</a>⁠; Firefox plugins: <a href="https://gwern.net/doc/www/noscript.net/aa40da7a98a144ecc776d63453662c8e00469bb8.html" rel="archived alternate nofollow" data-url-original="https://noscript.net/" title="(Original URL: https://noscript.net/ )">NoScript</a>⁠, <a href="https://github.com/gorhill/uBlock" data-link-icon="github" data-link-icon-type="svg">uBlock origin</a>⁠, <a href="https://addons.mozilla.org/en-US/firefox/addon/http-header-live/" data-link-icon="FF" data-link-icon-type="text,sans">Live HTTP Headers</a>⁠, <a href="https://github.com/iamadamdev/bypass-paywalls-chrome" data-link-icon="github" data-link-icon-type="svg">Bypass Paywalls</a>⁠, cookie exporting.</p>
                <p>Short of downloading a website, it might also be useful to pre-emptively archive it by using <code>linkchecker</code> to crawl it, compile a list of all external &amp; internal links, and store them for processing by another archival program (see <a href="https://gwern.net/archiving" id="gwern-archiving" title="'Archiving URLs', Gwern 2011">Archiving URLs</a> for examples). In certain rare circumstances, security tools like <a href="https://en.wikipedia.org/wiki/Nmap" data-link-icon="wikipedia" data-link-icon-type="svg"><code>nmap</code></a> can be useful to examine a mysterious server in more detail: what web server and services does it run, what else might be on it (sometimes interesting things like old anonymous FTP servers turn up), has a website moved between IPs or servers, etc.</p>
              </li>
            </ul>
          </section>
        </section>
        <section id="web-pages">
          <h2><a href="#web-pages" title="Link to section: § 'Web pages'">Web Pages</a></h2>
          <p>With proper use of pre-emptive archiving tools like <code>archiver-bot</code>, fixing linkrot in one’s own pages is much easier, but that leaves other references. Searching for lost web pages is similar to searching for papers:</p>
          <ul>
            <li>
              <p><strong>Just Search The Title</strong>: if the page title is given, search for the title.</p>
              <p>It is a good idea to include page titles in one’s own pages, as well as the URL, to help with future searches, since the URL may be meaningless gibberish on its own, and pre-emptive archiving can fail. HTML supports both <code>alt</code> and <code>title</code> parameters in link tags, and, in cases where displaying a title is not desirable (because the link is being used inline as part of normal hypertextual writing), titles can be included cleanly in <a href="https://en.wikipedia.org/wiki/Markdown" data-link-icon="wikipedia" data-link-icon-type="svg">Markdown</a> documents like this: <code>[inline text description](URL "Title")</code>.</p>
            </li>
            <li>
              <p><strong>Clean URLs</strong>: check the URL for weirdness or trailing garbage like `<code>or</code>?utm_source = feedburner&amp;utm_medium = feed&amp;utm_campaign = Feed%3A+blogspot%2FgJZg+%28Google+AI+Blog%29<code>? Or a variant domain, like a</code>mobile.foo.com<code>/</code>m.foo.com<code>/</code>foo.com/​amp/​` URL? Those are all less likely to be findable or archived than the canonical version.</p>
            </li>
            <li>
              <p><strong>Domain Site Search</strong>: restrict G search to the original domain with <code>site:</code>, or to related domains</p>
            </li>
            <li>
              <p><strong>Time-Limited Search</strong>: restrict G search to the original date-range/​years</p>
            </li>
            <li>
              <p><strong>Switch Engines</strong>: try a different search engine: corpuses can vary, and in some cases G tries to be too smart for its own good when you need a literal search; <a href="https://en.wikipedia.org/wiki/DuckDuckGo" data-link-icon="wikipedia" data-link-icon-type="svg">DuckDuckGo</a> (especially for ‘bang’ special searches), <a href="https://en.wikipedia.org/wiki/Microsoft_Bing" data-link-icon="wikipedia" data-link-icon-type="svg">Bing</a>⁠, and Yandex are usable alternatives</p>
            </li>
            <li>
              <p><strong>Check Archives</strong>: if nowhere on the clearnet, try the Internet Archive (IA) or the <a href="http://timetravel.mementoweb.org/" data-link-icon="internetarchive" data-link-icon-type="svg">Memento meta-archive search engine</a>:</p>
              <p>IA is the default backup for a dead URL. If IA doesn’t Just Work, there may be other versions in it:</p>
              <ul>
                <li>
                  <p><span>misleading redirects</span>: did the IA ‘helpfully’ redirect you to a much-later-in-time error page? Kill the redirect and check the earliest stored version for the exact URL rather than the redirect. Did the page initially load but then error out/​redirect? Disable JS with NoScript and reload.</p>
                </li>
                <li>
                  <p><span>Within-Domain Archives</span>: IA lets you list all URLs with any archived versions, by searching for <code>URL/*</code>; the list of available URLs may reveal an alternate newer/​older URL. It can also be useful to filter by filetype or substring.</p>
                  <p>For example, one might list all URLs in a domain, and if the list is too long and filled with garbage URLs, then using the “Filter results” incremental-search widget to search for “uploads/​” on a WordPress blog.<a href="#fn14" id="fnref14" role="doc-noteref"><sup>14</sup></a></p>
                  <figure>
                    <img alt="Screenshot of an oft-overlooked feature of the Internet Archive: displaying all available/​archived URLs for a specific domain, filtered down to a subset matching a string like *uploads/*." decoding="async" height="1360" loading="lazy" src="https://gwern.net/doc/cs/2019-gwern-internetarchive-domainsearch-screenshot.png" width="1036">
                    
                  </figure>
                  <ul>
                    <li>
                      <a href="https://github.com/hartator/wayback-machine-downloader" data-link-icon="github" data-link-icon-type="svg"><code>wayback_machine_downloader</code></a> (not to be confused with the <a href="https://github.com/jjjake/internetarchive" data-link-icon="github" data-link-icon-type="svg"><code>internetarchive</code> Python package</a> which provides a CLI interface to uploading files) is a Ruby tool which lets you download whole domains from IA, which can be useful for running a local fulltext search using regexps (a good <code>grep</code> query is often enough), in cases where just looking at the URLs via <code>URL/*</code> is not helpful. (An alternative which might work is <a href="https://websitedownloader.io/" title="Wayback Machine Downloader: Download the source code and assets from Wayback Machine"><code>websitedownloader.io</code></a>⁠.)
                    </li>
                  </ul>
                  <p>Example:</p>
                  <div id="cb2">
                    <pre><code><span id="cb2-1"><span>gem</span> install <span>--user-install</span> wayback_machine_downloader</span>
<span id="cb2-2"><span>~/.gem/ruby/2.7.0/bin/wayback_machine_downloader</span> wayback_machine_downloader <span>--all-timestamps</span> <span>'https://blog.okcupid.com'</span></span></code></pre>
                  </div>
                </li>
                <li>
                  <p>did <span>the domain change</span>, eg. from <code>www.foo.com</code> to <code>foo.com</code> or <code>www.foo.org</code>? Entirely different as far as IA is concerned.</p>
                </li>
                <li>
                  <p>does the <span>internal evidence of the URL</span> provide any hints? You can learn a lot from URLs just by paying attention and thinking about what each directory and argument means.</p>
                </li>
                <li>
                  <p>is this a <span>Blogspot blog</span>? Blogspot is uniquely horrible in that it has versions of each blog for every country domain: a <code>foo.blogspot.com</code> blog could be under any of <code>foo.blogspot.de</code>, <code>foo.blogspot.au</code>, <code>foo.blogspot.hk</code>, <code>foo.blogspot.jp</code>…<a href="#fn15" id="fnref15" role="doc-noteref"><sup>15</sup></a></p>
                </li>
                <li>
                  <p>did the website provide <span>RSS feeds</span>?</p>
                  <p>A little known fact is that <a href="https://en.wikipedia.org/wiki/Google_Reader" data-link-icon="wikipedia" data-link-icon-type="svg">Google Reader</a> (GR; October 2005–July 2013) stored all RSS items it crawled, so if a website’s RSS feed was configured to include full items, the RSS feed history was an alternate mirror of the whole website, and since GR never removed RSS items, it was possible to retrieve pages or whole websites from it. GR has since closed down, sadly, but before it closed, <a href="https://en.wikipedia.org/wiki/Archive_Team" data-link-icon="wikipedia" data-link-icon-type="svg">Archive Team</a> <a href="https://wiki.archiveteam.org/index.php/Google_Reader" data-link-icon="internetarchive" data-link-icon-type="svg">downloaded</a> a large fraction of GR’s historical RSS feeds, and <em>those</em> archives are <a href="https://archive.org/details/archiveteam_greader" data-link-icon="internetarchive" data-link-icon-type="svg">now hosted on IA</a>⁠. The catch is that they are stored in mega-<a href="https://en.wikipedia.org/wiki/Web_ARChive" data-link-icon="wikipedia" data-link-icon-type="svg">WARCs</a>⁠, which, for all their archival virtues, are not the most user-friendly format. The raw GR mega-WARCs are difficult enough to work with that I <a href="#searching-the-google-reader-archives" data-link-icon="alphabet" data-link-icon-type="svg">defer an example to the appendix</a>⁠.</p>
                </li>
                <li>
                  <p><a href="https://archive.is/" data-link-icon="internetarchive" data-link-icon-type="svg"><code>archive.today</code></a>: an IA-like mirror. (Sometimes bypasses paywalls or has snapshots other services do not; I strongly recommend against treating archive.today/​archive.is/​etc as anything but a temporary mirror to grab snapshots from, as <a href="https://blog.archive.today/post/660719734341386240/is-there-any-structure-in-place-to-assure-the" data-link-icon="internetarchive" data-link-icon-type="svg">it has no long-term plans</a>⁠.)</p>
                </li>
                <li>
                  <p>any <span>local archives</span>, such as those made with my <a href="#gwern-archiver-bot"><code>archiver-bot</code></a></p>
                </li>
                <li>
                  <p><span>Google Cache</span> ( <a href="https://en.wikipedia.org/wiki/Garbage_collection_%28computer_science%29" data-link-icon="wikipedia" data-link-icon-type="svg">GC</a>): GC works, sometimes, but the copies are usually the worst around, ephemeral &amp; cannot be relied upon. Google also appears to have been steadily deprecating GC over the years, as GC shows up less &amp; less in search results. A last resort.</p>
                </li>
              </ul>
            </li>
          </ul>
        </section>
        <section id="books">
          <h2><a href="#books" title="Link to section: § 'Books'">Books</a></h2>
          <section id="digital">
            <h2><a href="#digital" title="Link to section: § 'Digital'">Digital</a></h2>
            <p>E-books are rarer and harder to get than papers, although the situation has improved vastly since the early 2000s. To search for books online:</p>
            <ul>
              <li>
                <p><strong>More Straightforward</strong>: book searches tend to be faster and simpler than paper searches, and to require less cleverness in search query formulation, perhaps because they are rarer online, much larger, and have simpler titles, making it easier for search engines.</p>
                <p>Search G, not GS, for books:</p>
                <div>
                  <p>
                    No Books in Google Scholar
                  </p><p>Book fulltexts usually don’t show up in G<em>S</em> (for unknown reasons). You need to check G when searching for books.
                </p></div>
                <p>To double-check, you can try a <code>filetype:pdf</code> search; then check LG. Typically, if the main title + author doesn’t turn it up, it’s not online. (In some cases, the author order is reversed, or the title:subtitle are reversed, and you can find a copy by tweaking your search, but these are rare.).</p>
              </li>
              <li>
                <p><strong>IA</strong>: the Internet Archive has many books scanned which do not appear easily in search results (poor SEO?).</p>
                <ul>
                  <li>
                    <p>If an IA hit pops up in a search, <em>always check it</em>; the OCR may offer hints as to where to find it. If you don’t find anything or the provided, try doing an IA site search in G (<em>not</em> the IA built-in search engine), eg. <code>book title site:archive.org</code>.</p>
                  </li>
                  <li>
                    <p><span>DRM workarounds</span>: if it <em>is</em> on IA but the IA version is DRMed and is only available for “checkout”, you can jailbreak it.</p>
                    <p>Check the book out for the full period, 14 days. Download the PDF (not EPUB) version to Adobe Digital Elements version ≤4.0 (which can be run in Wine on Linux), and then import it to <a href="https://en.wikipedia.org/wiki/Calibre_(software)" data-link-icon="wikipedia" data-link-icon-type="svg">Calibre</a> with <a href="https://gwern.net/doc/www/apprenticealf.wordpress.com/f294474f6b56273006d0c67c61ffbbaed6438408.html" rel="archived alternate nofollow" data-url-original="https://apprenticealf.wordpress.com/" title="(Original URL: https://apprenticealf.wordpress.com/ )">the De-DRM plugin</a>⁠, which will produce a DRM-free PDF inside Calibre’s library. (Getting De-DRM running can be tricky, especially under Linux. I wound up having to edit some of the paths in the Python files to make them work with Wine. It also appears to fail on the most recent Google Play ebooks, ~2021.) You can then add metadata to the PDF &amp; upload it to LG<a href="#fn16" id="fnref16" role="doc-noteref"><sup>16</sup></a>⁠. (LG’s versions of books are usually better than the IA scans, but if they don’t exist, IA’s is better than nothing.)</p>
                  </li>
                </ul>
              </li>
              <li>
                <p><strong><a href="https://en.wikipedia.org/wiki/Google_Play" data-link-icon="wikipedia" data-link-icon-type="svg">Google Play</a></strong>: use the same PDF DRM as IA, can be broken same way</p>
              </li>
              <li>
                <p><strong><a href="https://en.wikipedia.org/wiki/HathiTrust" data-link-icon="wikipedia" data-link-icon-type="svg">HathiTrust</a></strong> also hosts many book scans, which can be searched for clues or hints or jailbroken.</p>
                <p>HathiTrust blocks whole-book downloads but it’s easy to download each page in a loop and stitch them together, for example:</p>
                <div id="cb3">
                  <pre><code><span id="cb3-1"><span>for</span> i <span>in</span> <span>{</span><span>1</span><span>..</span><span>151</span><span>}</span></span>
<span id="cb3-2"><span>do</span> <span>if</span> <span>[[</span> <span>!</span> <span>-s</span> <span>"</span><span>$i</span><span>.pdf"</span> <span>]];</span> <span>then</span></span>
<span id="cb3-3">    <span>wget</span> <span>"https://babel.hathitrust.org/cgi/imgsrv/download/pdf?id=mdp.39015050609067;orient=0;size=100;seq=</span><span>$i</span><span>;attachment=0"</span> <span>\</span></span>
<span id="cb3-4">          <span>-O</span> <span>"</span><span>$i</span><span>.pdf"</span></span>
<span id="cb3-5">    <span>sleep</span> 20s</span>
<span id="cb3-6"> <span>fi</span></span>
<span id="cb3-7">done</span>
<span id="cb3-8"></span>
<span id="cb3-9"><span>pdftk</span> <span>*</span>.pdf cat output 1957-super-scientificcareersandvocationaldevelopmenttheory.pdf</span>
<span id="cb3-10"></span>
<span id="cb3-11"><span>exiftool</span> <span>-Title</span><span>=</span><span>"Scientific Careers and Vocational Development Theory: A review, a critique and some recommendations"</span> <span>\</span></span>
<span id="cb3-12">    <span>-Date</span><span>=</span>1957 <span>-Author</span><span>=</span><span>"Donald E. Super, Paul B. Bachrach"</span> <span>-Subject</span><span>=</span><span>"psychology"</span> <span>\</span></span>
<span id="cb3-13">    <span>-Keywords</span><span>=</span><span>"Bureau Of Publications (Teachers College Columbia University), LCCCN: 57-12336, National Science Foundation, public domain, </span><span>\</span></span>
<span id="cb3-14"><span>    https://babel.hathitrust.org/cgi/pt?id=mdp.39015050609067;view=1up;seq=1 https://psycnet.apa.org/record/1959-04098-000"</span> <span>\</span></span>
<span id="cb3-15">    1957-super-scientificcareersandvocationaldevelopmenttheory.pdf</span></code></pre>
                </div>
                <p>Another example of this would be the Wellcome Library; while looking for <a href="https://wellcomecollection.org/works/d63gy9b7"><em>An Investigation Into The Relation Between Intelligence And Inheritance</em><span>, <span><span>Lawrence</span><span>1931</span></span></span></a>⁠, I came up dry until I checked one of the last search results, a “Wellcome Digital Library” hit, on the slim off-chance that, like the occasional Chinese/​Indian library website, it just might have fulltext. As it happens, it did—good news? Yes, but with a caveat: it provides <em>no</em> way to download the book! It provides OCR, metadata, and individual page-image downloads all under CC-BY-NC-SA (so no legal problems), but… not the book. (The OCR is also unnecessarily zipped, so that is why Google ranked the page so low and did not show any revealing excerpts from the OCR transcript: because it’s hidden in an opaque archive to save a few kilobytes while destroying SEO.) Examining the download URLs for the highest-resolution images, they follow an unfortunate schema:</p>
                <ol>
                  <li><code>https://dlcs.io/iiif-img/wellcome/1/5c27d7de-6d55-473c-b3b2-6c74ac7a04c6/full/2212,/0/default.jpg</code></li>
                  <li><code>https://dlcs.io/iiif-img/wellcome/1/d514271c-b290-4ae8-bed7-fd30fb14d59e/full/2212,/0/default.jpg</code></li>
                  <li>etc</li>
                </ol>
                <p>Instead of being sequentially numbered 1–90 or whatever, they all live under a unique hash or ID. Fortunately, one of the metadata files, the ‘manifest’ file, provides all of the hashes/​IDs (but not the high-quality download URLs). Extracting the IDs from the manifest can be done with some quick <code>sed</code> &amp; <code>tr</code> string processing, and fed into another short <code>wget</code> loop for download</p>
                <div id="cb4">
                  <pre><code><span id="cb4-1"><span>grep</span> <span>-F</span> <span>'@id'</span> manifest<span>\?</span>manifest<span>\=</span>https<span>\:</span>%2F%2Fwellcomelibrary.org%2Fiiif%2Fb18032217%2Fmanifest <span>|</span> <span>\</span></span>
<span id="cb4-2">   <span>sed</span> <span>-e</span> <span>'s/.*imageanno\/\(.*\)/\1/'</span> <span>|</span> <span>grep</span> <span>-E</span> <span>-v</span> <span>'^ .*'</span> <span>|</span> <span>tr</span> <span>-d</span> <span>','</span> <span>|</span> <span>tr</span> <span>-d</span> <span>'"'</span> <span># "</span></span>
<span id="cb4-3"># bf23642e-e89b-43a0-8736-f5c6c77c03c3</span>
<span id="cb4-4"># 334faf27-3ee1-4a63-92d9-b40d55ab72ad</span>
<span id="cb4-5"># 5c27d7de-6d55-473c-b3b2-6c74ac7a04c6</span>
<span id="cb4-6"># d514271c-b290-4ae8-bed7-fd30fb14d59e</span>
<span id="cb4-7"># f85ef645-ec96-4d5a-be4e-0a781f87b5e2</span>
<span id="cb4-8"># a2e1af25-5576-4101-abee-96bd7c237a4d</span>
<span id="cb4-9"># 6580e767-0d03-40a1-ab8b-e6a37abe849c</span>
<span id="cb4-10"># ca178578-81c9-4829-b912-97c957b668a3</span>
<span id="cb4-11"># 2bd8959d-5540-4f36-82d9-49658f67cff6</span>
<span id="cb4-12"># ...etc</span>
<span id="cb4-13"><span>I</span><span>=</span>1</span>
<span id="cb4-14"><span>for</span> HASH <span>in</span> <span>$HASHES</span><span>;</span> <span>do</span></span>
<span id="cb4-15">    <span>wget</span> <span>"https://dlcs.io/iiif-img/wellcome/1/</span><span>$HASH</span><span>/full/2212,/0/default.jpg"</span> <span>-O</span> <span>$I</span>.jpg</span>
<span id="cb4-16">    <span>I</span><span>=</span><span>$((I</span><span>+</span><span>1</span><span>))</span></span>
<span id="cb4-17">done</span></code></pre>
                </div>
                <p>And then the 59MB of JPGs can be cleaned up as usual with <code>gscan2pdf</code> (empty pages deleted, tables rotated, cover page cropped, all other pages binarized), compressed/​OCRed with <code>ocrmypdf</code>, and metadata set with <code>exiftool</code>, producing a readable, downloadable, highly-search-engine-friendly 1.8MB PDF.</p>
              </li>
              <li>
                <p>remember the <a href="https://en.wikipedia.org/wiki/Analog_hole" data-link-icon="wikipedia" data-link-icon-type="svg"><strong>Analog Hole</strong></a> works for papers/​books too:</p>
                <p>if you can find a copy to <em>read</em>, but cannot figure out how to <em>download</em> it directly because the site uses JS or complicated cookie authentication or other tricks, you can always exploit the ‘analogue hole’—fullscreen the book in high resolution &amp; take screenshots of every page; then crop, OCR etc. This is tedious but it works. And if you take screenshots at sufficiently high resolution, there will be relatively little quality loss. (This works better for books that are scans than ones born-digital.)</p>
              </li>
            </ul>
          </section>
          <section id="physical">
            <h2><a href="#physical" title="Link to section: § 'Physical'">Physical</a></h2>
            <p><span>Expensive but feasible.</span> Books are something of a double-edged sword compared to papers/​theses. On the one hand, books are much more often unavailable online, and must be bought offline, but at least you almost always <em>can</em> buy used books offline without much trouble (and often for &lt;$10 total); on the other hand, while paper/​theses are often available online, when one is not unavailable, it’s usually <em>very</em> unavailable, and you’re stuck (unless you have a university ILL department backing you up or are willing to travel to the few or only universities with paper or microfilm copies).</p><!-- TODO: outsourcing to the IA? https://openlibrary.org/sponsorship -->
            <p>Purchasing from used book sellers:</p>
            <ul>
              <li>
                <p><strong>Sellers</strong>:</p>
                <ul>
                  <li>
                    <p><span>used book search engines</span>: Google Books/​<a href="https://www.find-more-books.com/">find-more-books.com</a>: a good starting point for seller links; if buying from a marketplace like AbeBooks/​Amazon/​Barnes &amp; Noble, it’s worth searching the seller to see if they have their own website, which is potentially much cheaper. They may also have multiple editions in stock.</p>
                  </li>
                  <li>
                    <p><span>bad</span>: eBay &amp; Amazon are often bad, due to high-minimum-order+S&amp;H and sellers on Amazon seem to assume Amazon buyers are easily rooked; but can be useful in providing metadata like page count or ISBN or variations on the title</p>
                  </li>
                  <li>
                    <p><span>good</span>: <a href="https://www.abebooks.com/">AbeBooks</a>⁠, <a href="https://www.thriftbooks.com/">Thrift Books</a>⁠, <a href="https://www.betterworldbooks.com/">Better World Books</a>⁠, <a href="https://www.barnesandnoble.com/">B&amp;N</a>⁠, <a href="https://www.discoverbooks.com/">Discover Books</a>⁠.</p>
                    <p>Note: on AbeBooks, international orders can be useful (especially for behavioral genetics or psychology books) but be careful of international orders with your credit card—many debit/​credit cards will fail on international orders and trigger a fraud alert, and <a href="https://en.wikipedia.org/wiki/PayPal" data-link-icon="wikipedia" data-link-icon-type="svg">PayPal</a> is not accepted.</p>
                  </li>
                </ul>
              </li>
              <li>
                <p><strong>Price Alerts</strong>: if a book is not available or too expensive, set price watches: AbeBooks supports email alerts on stored searches, and Amazon can be monitored via <a href="https://camelcamelcamel.com/">CamelCamelCamel</a> (remember the CCC price alert you want is on the <em>used third-party</em> category, as new books are more expensive, less available, and unnecessary).</p>
              </li>
            </ul>
            <p>Scanning:</p>
            <ul>
              <li>
                <p><strong>Destructive Vs Non-Destructive</strong>: the fundamental dilemma of book scanning—destructively debinding books with a razor or guillotine cutter works much better &amp; is much less time-consuming than spreading them on a flatbed scanner to scan one-by-one<a href="#fn17" id="fnref17" role="doc-noteref"><sup>17</sup></a>⁠, because it allows use of a sheet-fed scanner instead, which is easily 5x faster and will give higher-quality scans (because the sheets will be flat, scanned edge-to-edge, and much more closely aligned), but does, of course, require effectively destroying the book.</p>
              </li>
              <li>
                <p><strong>Tools</strong>:</p>
                <ul>
                  <li>
                    <p><span>cutting</span>: For simple debinding of a few books a year, an X-acto knife/​razor is good (avoid the ‘triangle’ blades, get curved blades intended for large cuts instead of detail work).</p>
                    <p>Once you start doing more than one a month, it’s time to upgrade to a guillotine blade paper cutter (a fancier swinging-arm paper cutter, which uses a two-joint system to clamp down and cut uniformly).</p>
                    <p>A guillotine blade can cut chunks of 200 pages easily without much slippage, so for books with more pages, I use both: an X-acto to cut along the spine and turn it into several 200-page chunks for the guillotine cutter.</p>
                  </li>
                  <li>
                    <p><span>scanning</span>: at some point, it may make sense to switch to a scanning service like <a href="https://1dollarscan.com/">1DollarScan</a> (1DS has acceptable quality for the black-white scans I have used them for thus far, but watch out for their nickel-and-diming fees for OCR or “setting the PDF title”; these can be done in no time yourself using <code>gscan2pdf</code>/​<code>exiftool</code>/​<code>ocrmypdf</code> and will save a <em>lot</em> of money as they, amazingly, bill by 100-page units). Books can be sent directly to 1DS, reducing logistical hassles.</p>
                  </li>
                </ul>
              </li>
              <li>
                <p><strong>Clean Up</strong>: after scanning, crop/​threshold/​OCR/​add metadata</p>
                <ul>
                  <li><span>Adding metadata</span>: same principles as papers. While more elaborate metadata can be added, like bookmarks, I have not experimented with those yet.</li>
                </ul>
              </li>
              <li>
                <p><strong>File format</strong>: PDF, <a href="https://gwern.net/design-graveyard#djvu-files" id="gwern-design-graveyard-djvu-files">not DjVu</a></p>
                <p>Despite being a worse format in many respects, I now recommend PDF and have stopped using DjVu for new scans<a href="#fn18" id="fnref18" role="doc-noteref"><sup>18</sup></a> and have converted my old DjVu files to PDF.</p>
              </li>
              <li>
                <p><strong>Uploading</strong>: to LibGen, usually, and Gwern.net sometimes. For backups, filelockers like Dropbox, Mega, MediaFire, or Google Drive are good. I usually upload 3 copies including LG. I rotate accounts once a year, to avoid putting too many files into a single account. [I discourage <a href="https://gwern.net/archiving#why-not-internet-archive" id="gwern-archiving-why-not-internet-archive" title="‘Archiving URLs § Why Not Internet Archive?’, Branwen 2011">reliance on IA links.</a>)</p>
                <div>
                  <p>
                    Do Not Use Google Docs/​Scribd/​Dropbox/​IA/​etc for Long-Term Documents
                  </p>
                  <p>‘Document’ websites like Google Docs (GD) should be strictly avoided as primary hosting. GD does <em>not</em> appear in G/​GS, dooming a document to obscurity, and Scribd is ludicrously user-hostile with changing <a href="https://en.wikipedia.org/wiki/Dark_pattern" data-link-icon="wikipedia" data-link-icon-type="svg">dark patterns</a>⁠. Such sites cannot be searched, scraped, downloaded reliably, clipped, used on many devices, archived<a href="#fn19" id="fnref19" role="doc-noteref"><sup>19</sup></a>⁠, or counted on for the long haul. (For example, Google Docs has made many documents ‘private’, breaking public links, to the surprise of even the authors when I contact them about it, for unclear reasons.)</p><p>Such sites may be useful for collaboration or surveys, but should be regarded as strictly temporary <em>working files</em>, and moved to clean static HTML/​PDF/​XLSX hosted elsewhere as soon as possible.
                </p></div>
              </li>
              <li>
                <p><strong>Hosting</strong>: hosting papers is easy but books come with risk:</p>
                <p>Books can be dangerous; in deciding whether to host a book, my rule of thumb is host only books pre-2000 and which do not have Kindle editions or other signs of active exploitation and is effectively an ‘<a href="https://en.wikipedia.org/wiki/Orphan_work" data-link-icon="wikipedia" data-link-icon-type="svg">orphan work</a>’.</p>
                <p>As of 2019-10-23, hosting 4090 files over 9 years (very roughly, assuming linear growth, &lt;6.7 million document-days of hosting: 3763 × 0.5 × 8 × 365.25 = 6722426), I’ve received 4 takedown orders: a behavioral genetics textbook (2013), <em>The Handbook of Psychopathy</em> (2005), a recent <a href="https://en.wikipedia.org/wiki/Meta-analysis" data-link-icon="wikipedia" data-link-icon-type="svg">meta-analysis</a> <span>paper (<span><span title="et al">Roberts</span> <span>et al</span> <span>2016</span></span>), and a CUP DMCA takedown order for 27 files. I broke my rule of thumb to host the 2 books (my mistake), which leaves only the 1 paper, which I think was a fluke. So, as long as one avoids relatively recent books, the risk should be minimal.</span> <!-- Sep 2020 update: +2: IEEE, and newspaper over mirrored page; Oct 2020: CUP, 1 book --></p>
              </li>
            </ul>
          </section>
        </section>
        <section id="case-studies">
          <h2><a href="#case-studies" title="Link to section: § 'Case Studies'">Case Studies</a></h2>
          <p>Followup section to the article covering how to search the Internet effectively: &gt;14 case studies of challenging Internet searches drawn from the past 10 years. I present the problem, and step through the process of finding it, and describe my tacit knowledge and implicit strategies. These case studies make the prior tips more understandable by showing them off in practice.</p>
          <section id="missing-appendix">
            <h2><a href="#missing-appendix" title="Link to section: § 'Missing Appendix'">Missing Appendix</a></h2>
            <p><a href="https://en.wikipedia.org/wiki/Anders_Sandberg" data-link-icon="wikipedia" data-link-icon-type="svg">Anders Sandberg</a> <a href="https://twitter.com/anderssandberg/status/1176040327679029249" data-link-icon="twitter" data-link-icon-type="svg">asked</a>:</p>
            <blockquote>
              <p>Does anybody know where the online appendix to Nordhaus’ <a href="https://pdfs.semanticscholar.org/f60f/e757587be15c29ad6ee5695bc48a44df3e8a.pdf" data-link-icon="pdf" data-link-icon-type="svg" title="Nordhaus 2007">“Two Centuries of Productivity Growth in Computing”</a> is hiding?</p>
            </blockquote>
            <p>I look up the title in Google Scholar; seeing a friendly <code>psu.edu</code> PDF link (CiteSeerx), I click. The paper says “The data used in this study are provided in a background spreadsheet available at <code>http://www.econ.yale.edu/~nordhaus/Computers/Appendix.xls</code>”. Sadly, this is a lie. (Sandberg would, of course, have tried that already.)</p>
            <p>I immediately check the URL in the IA—nothing. The IA didn’t catch it at all. Maybe the <a href="https://www.cambridge.org/core/journals/journal-of-economic-history/article/two-centuries-of-productivity-growth-in-computing/856EC5947A5857296D3328FA154BA3A3" id="nordhaus-2007" data-link-icon="⛨" data-link-icon-type="text" title="'Two Centuries of Productivity Growth in Computing', Nordhaus 2007">official published paper website</a> has it? Nope, it references the same URL, and doesn’t provide a copy as an appendix or supplement. (What do we pay these publishers such enormous sums of money for, exactly?) So I back off to checking <code>http://www.econ.yale.edu/~nordhaus/</code>, to check Nordhaus’s personal website for a newer link. The Yale personal website is empty and appears to’ve been replaced by a Google Sites personal page. It links nothing useful, so I check a more thorough index, Google, by searching <code>site:sites.google.com/site/williamdnordhaus/</code>. Nothing there either (and it appears almost empty, so Nordhaus has allowed most of his stuff to be deleted and bitrot). I try a broader Google: <code>nordhaus appendix.xls</code>. This turns up some spreadsheets, but still nothing.</p>
            <p>Easier approaches having been exhausted, I return to the IA and I pull up <em>all</em> URLs archived for his original personal website: <code>https://web.archive.org/web/*/http://www.econ.yale.edu/~nordhaus/*</code> This pulls up way too many URLs to manually review, so I filter results for <code>xls</code>, which reduces to a more manageable 60 hits; reading through the hits, I spot <code>http://www.econ.yale.edu/~nordhaus/homepage/documents/Appendix_Nordhaus_computation_update_121410.xlsx</code> from 2014-10-10; this sounds right, albeit substantially later in time than expected (either 2010 or 2012, judging from the filename).</p>
            <p><a href="https://gwern.net/doc/cs/2010-nordhaus-nordhaus2007twocenturiesofproductivitygrowthincomputing-appendix.xlsx" data-link-icon="spreadsheet" data-link-icon-type="svg">Downloading it</a>⁠, opening it up and cross-referencing with the paper, it has the same spreadsheet ‘sheets’ as mentioned, like “Manual” or “Capital_Deep”, and seems to be either the original file in question or an updated version thereof (which may be even better). The spreadsheet metadata indicates it was created “04/​09/​2001, 23:20:43, <a href="https://en.wikipedia.org/wiki/Incompatible_Timesharing_System" data-link-icon="wikipedia" data-link-icon-type="svg">ITS</a> Academic Media &amp; Technology”, and modified “12/​22/​2010, 02:40:20”, so it seems to be the latter—it’s the original spreadsheet Nordhaus created when he began work several years prior to the formal 2007 publication (6 years seems reasonable given all the delays in such a process), and then was updated 3 years afterwards. Close enough.</p>
          </section>
          <section id="misremembered-book">
            <h2><a href="#misremembered-book" title="Link to section: § 'Misremembered Book'">Misremembered Book</a></h2>
            <p><a href="https://gwern.net/doc/www/old.reddit.com/e4be352758223ce0ec474b7824e48ef8e469dd6c.html" data-link-icon="reddit" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://old.reddit.com/r/science/comments/d8dcm0/todays_obesity_epidemic_may_have_been_caused_by/f1ac2sy/" title="(Original URL: https://www.reddit.com/r/science/comments/d8dcm0/todays_obesity_epidemic_may_have_been_caused_by/f1ac2sy/ )">A Redditor asked</a>:</p>
            <blockquote>
              <p>I was in a consignment type store once and picked up a book called “Eat fat, get thin”. Giving it a quick scan through, it was basically the same stuff as Atkins but this book was from the 50s or 60s. I wish I’d have bought it. I think I found a reference to it once online but it’s been drowned out since someone else released a book with the same name (and it wasn’t Barry Groves either).</p>
            </blockquote>
            <p>The easiest way to find a book given a corrupted title, a date range, and the information there are many similar titles drowning out a naive search engine query, is to skip to a specialized search engine with clean metadata (ie. a library database).</p>
            <p>Searching in WorldCat for 1950s–1970s, “Eat fat, get thin” turns up nothing relevant. This is unsurprising, as he was unlikely to’ve remembered the title <em>exactly</em>, and this title doesn’t quite sound right for the era anyway (a little too punchy and ungrammatical, and ‘thin’ wasn’t a desirable word back then compared to words like ‘slim’ or ‘sleek’ or ‘svelte’). People often oversimplify titles, so I dropped back to just “Eat fat”.</p>
            <p>This immediately turned up the book: <a href="https://en.wikipedia.org/wiki/Richard_Mackarness" data-link-icon="wikipedia" data-link-icon-type="svg">Richard Mackarness’s</a> 1958 <em>Eat Fat and Grow Slim</em>—note that it is <em>almost</em> the same title, with a comma serving as conjunction and ‘slim’ rather than the more contemporary ‘thin’, but just different enough to screw up an overly-literal search.</p>
            <p>With the same trick in mind, we could also have found it in a regular Google search query by adding additional terms to hint to Google that we want old books, not recent ones: both <code>"Eat Fat" 1950s</code> or <code>"Eat Fat" 1960s</code> would have turned it up in the first 5 search results. If we didn’t use quotes, the searches get harder because broader hits get pulled in. For example, <code>Eat fat, get thin 1950s -Hyman</code> excludes the recent book mentioned, but you still have to go down 15 hits before finding Mackarness, and <code>Eat fat, get thin -Hyman</code> requires going down 18 hits.</p>
          </section>
          <section id="missing-website">
            <h2><a href="#missing-website" title="Link to section: § 'Missing Website'">Missing Website</a></h2>
            <p><a href="https://onlinelibrary.wiley.com/doi/full/10.1002/anie.201410356" id="bučar-et-al-2015" data-link-icon="W" data-link-icon-type="text,sans" title="Disappearing Polymorphs Revisited"><span><span title="et al">Bučar</span> <span>et al</span> <span>2015</span></span></a>⁠, on the phenomenon of <a href="https://en.wikipedia.org/w/index.php?title=Polymorphism_(materials_science)&amp;oldid=999770848#Disappearing_polymorphs" data-link-icon="wikipedia" data-link-icon-type="svg">disappearing polymorphs</a> quotes striking transcripts from a major example of a disappearing crystal, when ~1998 Abbott suddenly became unable to manufacture the anti-retroviral drug <a href="https://en.wikipedia.org/wiki/Ritonavir" data-link-icon="wikipedia" data-link-icon-type="svg">ritonavir</a> (Norvir™) due to a rival (and less effective) crystal form spontaneously infecting all its plants, threatening many AIDS patients, but notes:</p>
            <blockquote>
              <p>The transcripts were originally published on the website<sup>42</sup> of the International Association of Physicians in AIDS Care [IAPAC], but no longer appear there.</p>
            </blockquote>
            <p>A search using the quotes confirms that the originals have long since vanished from the open Internet, turning up only quotes of the quotations. Unfortunately, no URL is given. The Internet Archive has comprehensive mirrors of the IAPAC, but too many to easily search through. Using the filter feature, I keyword-searched for “ritonavir”, but while this turned up a number of pages from roughly the right time period, they do not mention it and none of the quotes appear. The key turned out to be to use the trademark name instead which pulls up many more pages, and after checking a few, the IAPAC turned out to have organized all the Norvir material into a single subdirectory with a convenient <a href="https://gwern.net/doc/biology/2000-iapac-norvir/index.html"><code>index.html</code></a>⁠; the articles/​transcripts, in turn, were indexed under the linked <a href="https://gwern.net/doc/biology/2000-iapac-norvir/description.html" id="care-2000" title="'Norvir Advisory', Care 2000">“Description of the Problem” index page</a>⁠.</p>
            <p>I then pulled the Norvir subdirectory with a <code>~/.gem/ruby/2.5.0/bin/wayback_machine_downloader wayback_machine_downloader 'http://www.iapac.org/norvir/'</code> command and hosted a mirror to make it visible in Google.</p>
          </section>
          <section id="speech-book">
            <h2><a href="#speech-book" title="Link to section: § 'Speech → Book'">Speech → Book</a></h2>
            <p><a href="https://www.lesswrong.com/posts/cHEQSEPz4eipGHFy9/differential-reproduction-for-men-and-women#comment-TZQqzYPDv6vsWqfut" data-link-icon="LW" data-link-icon-type="text">Nancy Lebovitz</a> asked about a citation in a <a href="https://web.archive.org/web/20071011022938/https://psy.fsu.edu/~baumeistertice/goodaboutmen.htm" id="baumeister-2007" data-link-icon="internetarchive" data-link-icon-type="svg" title="'Is There Anything Good About Men?', Roy F. Baumeister 2007">Roy Baumeister speech about sex differences</a>:</p>
            <blockquote>
              <p>There’s an idea I’ve seen a number of times that 80% of women have had descendants, but only 40% of men. A little research tracked it back to <a href="https://web.archive.org/web/20071011022938/https://psy.fsu.edu/~baumeistertice/goodaboutmen.htm" id="baumeister-2007" data-link-icon="internetarchive" data-link-icon-type="svg" title="‘Is There Anything Good About Men?’, Baumeister 2007">this</a>⁠, but the speech doesn’t have a cite and I haven’t found a source.</p>
            </blockquote>
            <p>This could be solved by guessing that the formal citation is given in the book, and doing keyword search to find a similar passage. The second line of the speech says:</p>
            <blockquote>
              <blockquote>
                <p>For more information on this topic, read Dr.&nbsp;Baumeister’s book <em>Is There Anything Good About Men?</em> available in bookstores everywhere, including here.</p>
              </blockquote>
            </blockquote>
            <p>A search of <em>Is There Anything Good About Men</em> in Libgen turns up a copy. Download. What are we looking for? A reminder, the key lines in the speech are:</p>
            <blockquote>
              <blockquote>
                <p>…It’s not a trick question, and it’s not 50%. True, about half the people who ever lived were women, but that’s not the question. We’re asking about all the people who ever lived who have a descendant living today. Or, put another way, yes, every baby has both a mother and a father, but some of those parents had multiple children. Recent research using DNA analysis answered this question about two years ago. Today’s human population is descended from twice as many women as men. I think this difference is the single most under-appreciated fact about gender. To get that kind of difference, you had to have something like, throughout the entire history of the human race, maybe 80% of women but only 40% of men reproduced.</p>
              </blockquote>
            </blockquote>
            <p>We could search for various words or phrase from this passage which seem to be relatively unique; as it happens, I chose the rhetorical “50%” (but “80%”, “40%”, “underappreciated”, etc. all would’ve worked with varying levels of efficiency since the speech is heavily based on the book), and thus jumped straight to chapter 4, “The Most Underappreciated Fact About Men”. (If these had not worked, we could have started searching for years, based on the quote “about two years ago”.) A glance tells us that Baumeister is discussing exactly this topic of reproductive differentials, so we read on and a few pages later, on page 63, we hit the jackpot:</p>
            <blockquote>
              <p>The correct answer has recently begun to emerge from DNA studies, notably those by Jason Wilder and his colleagues. They concluded that among the ancestors of today’s human population, women outnumbered men about two to one. Two to one! In percentage terms, then, humanity’s ancestors were about 67% female and 33% male.</p>
            </blockquote>
            <p>Who’s Wilder? A C-f for “Wilder” takes us to pg286, where we immediately read:</p>
            <blockquote>
              <p>…The DNA studies on how today’s human population is descended from twice as many women as men have been the most requested sources from my earlier talks on this. The work is by Jason Wilder and his colleagues. I list here some sources in the mass media, which may be more accessible to laypersons than the highly technical journal articles, but for the specialists I list those also. For a highly readable introduction, you can Google the article <a href="https://web.archive.org/web/20040922020546/http://www.scienceagogo.com/news/20040819224859data_trunc_sys.shtml" data-link-icon="internetarchive" data-link-icon-type="svg">“Ancient Man Spread the Love Around,”</a> which was published September, 20, 2004 and is still available (last I checked) online. There were plenty of other stories in the media at about this time, when the research findings first came out. In <a href="https://www.medicalnewstoday.com/">“Medical News Today,”</a>⁠, on the same date in 2004, a story under “Genes expose secrets of sex on the side” covered much the same material.</p>
              <p>If you want the original sources, read Wilder, J. A., Mobasher, Z., &amp; Hammer, M. F. (2004). <a href="https://academic.oup.com/mbe/article/21/11/2047/1147770" data-link-icon="OUP" data-link-icon-type="text,tri">“Genetic evidence for unequal effective population sizes of human females and males”</a>⁠. <em>Molecular Biology and Evolution</em>, 21, 2047–2057. If that went down well, you might try Wilder, J. A., Kingan, S. B., Mobasher, Z., Pilkington, M. M., &amp; Hammer, M. F. (2004). <a href="https://www.nature.com/articles/ng1428" data-link-icon="n" data-link-icon-type="text">“Global patterns of human mitochondrial DNA and Y-chromosome structure are not influenced by higher migration rates of females versus males”</a>⁠. <em>Nature Genetics</em>, 36, 1122–1125. That one was over my head, I admit. A more readable source on these is Shriver, M. D. (2005), <a href="https://www.nature.com/articles/5201329" data-link-icon="n" data-link-icon-type="text">“Female migration rate might not be greater than male rate”</a>⁠. <em>European Journal of Human Genetics</em>, 13, 131–132. Shriver raises another intriguing hypothesis that could have contributed to the greater preponderance of females in our ancestors: Because couples mate such that the man is older, the generational intervals are smaller for females (ie. baby’s age is closer to mother’s than to father’s). As for the 90% to 20% differential in other species, that I believe is standard information in biology, which I first heard in one of the lectures on testosterone by the late James Dabbs, whose book <em>Heroes, Rogues, and Lovers</em> remains an authoritative source on the topic.</p>
            </blockquote>
            <p><span><span><span title="et al">Wilder</span> <span>et al</span> <span>2004</span></span>, incidentally, fits well with Baumeister remarking in 2007 that the research was done 2 or so years ago. And of course you could’ve done the same thing using Google Books: search</span> <a href="https://books.google.com/books?id=qqprY-YiWY8C&amp;printsec=frontcover&amp;dq=Baumeister+anything+good+about+men&amp;sa=X&amp;ei=4vNaUZffIoe9igLB74DQBA&amp;ved=0CDAQ6AEwAA" data-link-icon="alphabet" data-link-icon-type="svg">“Baumeister anything good about men”</a> to get to the book, then search-within-the-book for “50%”, jump to page 53, read to page 63, do a second search-within-the-book for “Wilder” and the second hit of page 287 even luckily gives you the snippet:</p>
            <blockquote>
              <p><em>Sources and References</em> 287</p>
              <p>…If you want the original sources, read Wilder, J. A., Mobasher, Z., &amp; Hammer, M. F. (2004). “Genetic evidence for unequal effective population sizes of human females and males”. <em>Molecular Biology and Evolution</em>…</p>
            </blockquote>
          </section>
          <section id="rowling-quote-on-death">
            <h2><a href="#rowling-quote-on-death" title="Link to section: § 'Rowling Quote On Death'">Rowling Quote On Death</a></h2>
            <p>Did <a href="https://en.wikipedia.org/wiki/J._K._Rowling" data-link-icon="wikipedia" data-link-icon-type="svg">J.K. Rowling</a> say the <em>Harry Potter</em> books were about ‘death’? There are a lot of Rowling statements, but checking WP and opening up each interview links (under the theory that the key interviews are linked there) and searching for ‘death’ soon turns up a relevant quote from <a href="https://gwern.net/doc/www/www.accio-quote.org/763e66fc7f7ae146fdfa894b9d224c297e0fae9d.html" rel="archived alternate nofollow" data-url-original="http://www.accio-quote.org/articles/2001/1201-bbc-hpandme.htm" title="'Harry Potter and Me' (BBC Christmas Special, British version), BBC, 2001-12-28 (Original URL: http://www.accio-quote.org/articles/2001/1201-bbc-hpandme.htm )">2001</a>:</p>
            <blockquote>
              <p>Death is an extremely important theme throughout all seven books. I would say possibly the most important theme. If you are writing about Evil, which I am, and if you are writing about someone who is essentially a <a href="https://en.wikipedia.org/wiki/Psychopathy" data-link-icon="wikipedia" data-link-icon-type="svg">psychopath</a>⁠, you have a duty to show the real evil of taking human life.</p>
            </blockquote>
          </section>
          <section id="crowley-quote">
            <h2><a href="#crowley-quote" title="Link to section: § 'Crowley Quote'">Crowley Quote</a></h2>
            <p><a href="https://www.lesswrong.com/posts/vhxywjnBH6ioRnnt3/crowley-on-religious-experience#comment-3bc4kL4QnNc9TjNTz" data-link-icon="LW" data-link-icon-type="text">Scott Alexander</a> posted a piece linking to an except titled “<a href="https://en.wikipedia.org/wiki/Aleister_Crowley" data-link-icon="wikipedia" data-link-icon-type="svg">Crowley</a> on Religious Experience”.</p>
            <p>The link was broken, but Alexander brought it up in the context of an <a href="https://www.lesswrong.com/posts/Fwt4sDDacko8Sh5iR/the-sacred-mundane#comment-qAHp6JRjeY7ixgYas" data-link-icon="LW" data-link-icon-type="text">earlier discussion</a> where he also quoted Crowley; searching <em>those</em> quotes reveals that it must have been excerpts from <em>Magick: Book 4</em>.</p>
          </section>
          <section id="finding-the-right-sage">
            <h2><a href="#finding-the-right-sage" title="Link to section: § 'Finding The Right SAGE'">Finding The Right ‘SAGE’</a></h2>
            <p><a href="https://www.lesswrong.com/posts/CKpByWmsZ8WmpHtYa/competent-elites#comment-jzCu3bdgoQ77Y5hZN" data-link-icon="LW" data-link-icon-type="text">Phil Goetz</a> noted that an anti-aging conference named “SAGE” had become impossible to find in Google due to a <em>LGBT</em> aging conference also named SAGE.</p>
            <p>Regular searches would fail, but a combination of tricks worked: <code>SAGE anti-aging conference</code> combined with restricting Google search to 2003–2005 time-range turned up a citation to its website as the fourth hit, <code>http://www.sagecrossroads.net</code> (which has ironically since died).</p>
          </section>
          <section id="uk-charity-financials">
            <h2><a href="#uk-charity-financials" title="Link to section: § 'UK Charity Financials'">UK Charity Financials</a></h2>
            <p>The <a href="https://www.lesswrong.com/posts/qqhdj3W3vSfB5E9ss/siai-an-examination?commentId=7CwWf6wN2DtNfv3tF" data-link-icon="LW" data-link-icon-type="text">Future of Humanity Institute (FHI) doesn’t clearly provide</a> charity financial forms akin to the US Form 990s, making it hard to find out information about its budget or results.</p>
            <p>FHI doesn’t show up in the CC, NPC, or <a href="https://en.wikipedia.org/wiki/Candid_(organization)" data-link-icon="wikipedia" data-link-icon-type="svg">GuideStar</a>⁠, which are the first places to check for charity finances, so I went a little broader afield and tried a site search on the FHI website: <code>budget site:fhi.ox.ac.uk</code>. This immediately turned up FHI’s own documentation of its activities and budgets, such as the 2007 annual report; I used part of its title as a new Google search: <code>future of humanity institute achievements report site:fhi.ox.ac.uk</code>.</p>
          </section>
          <section id="nobel-lineage-research">
            <h2><a href="#nobel-lineage-research" title="Link to section: § 'Nobel Lineage Research'">Nobel Lineage Research</a></h2>
            <p><a href="https://www.lesswrong.com/posts/hC83eKp9LFpw9FBks/link-holistic-learning-ebook#comment-egNZtRAF8C2KTPKsu" data-link-icon="LW" data-link-icon-type="text">John Maxwell</a> referred to a forgotten study on high correlation between Nobelist professors &amp; Nobelist grad students (almost entirely a selection effect, I would bet). I was able to refind it in 7 minutes.</p>
            <p>I wasted a few searches like <code>factor predicting Nobel prize</code> or <code>Nobel prize graduate student</code> in Google Scholar, until I search for <code>Nobel laureate "graduate student"</code>; the second hit was a citation, which is a little unusual for Google Scholar and meant it was important, and it had the critical word <em>mutual</em> in it—simultaneous partners in Nobel work is somewhat rare, but temporally separated teams don’t work for prizes, and I suspected that it was exactly what I was looking for. Googling the title, I soon found a PDF like <a href="https://gwern.net/doc/psychology/2004-viau.pdf" id="pilc2501-2004" data-link-icon="pdf" data-link-icon-type="svg" title="pilc2501 2004">“Eminent Scientists’ Demotivation in School: A symptom of an incurable disease?”<span>, <span><span>Viau</span><span>2004</span></span></span></a> <span>which confirmed it (and <span><span>Viau</span><span>2004</span></span> is interesting in its own right as a contribution to the Conscientious vs IQ question). I then followed it to a useful paragraph:</span></p>
            <blockquote>
              <p>In a study conducted with 92 American winners of the Nobel Prize, Zuckerman (1977) discovered that 48 of them had worked as graduate students or assistants with professors who were themselves Nobel Prize award-winners. As pointed out by Zuckerman (1977), the fact that 11 Nobel prizewinners have had the great physicist Rutherford as a mentor is an example of just how significant a good mentor can be during one’s studies and training. It then appears that most eminent scientists did have people to stimulate them during their childhood and mentor(s) during their studies. But, what exactly is the nature of these people’s contribution.</p>
              <ul>
                <li>Zuckerman, H. (1977). <em>Scientific Elite: Nobel Laureates in the United States</em>. New York: Free Press.</li>
              </ul>
            </blockquote>
            <p>GS lists &gt;900 citations of this book, so there may well be additional or followup studies covering the 40 years since. Or, also relevant is “Zuckerman, H. (1983). The scientific elite: Nobel laureates’ mutual influences. In R. S. Albert (Ed.), <em>Genius and eminence</em> (pp.&nbsp;241–252). New York: Pergamon Press”, and “Zuckerman H. ‘Sociology of Nobel Prizes’, <em>Scientific American</em> 217 (5): 25&amp; 1967.”</p>
          </section>
          <section id="dead-url">
            <h2><a href="#dead-url" title="Link to section: § 'Dead URL'">Dead URL</a></h2>
            <p><a href="https://www.lesswrong.com/posts/wAhgxmCf2ebHha5BJ/psa-please-list-your-references-don-t-just-link-them#comment-MMH9H4Y7iNDjfirZF" data-link-icon="LW" data-link-icon-type="text">A link to a research article in a post by Morendil</a> broke, he had not provided any formal citation data, <em>and</em> the original domain blocks all crawlers in its <code>robots.txt</code> so IA would not work. What to do?</p>
            <p>The simplest solution was to search a direct quote, turning up a Scribd mirror; Scribd is a parasite website, where people upload copies from elsewhere, which ought to make one wonder where the <em>original</em> came from. (It often shows up before the original in any search engine, because it automatically runs OCR on submissions, making them more visible to search engines.) With a copy of the journal issue to work with, you can easily find the official HP archives and <a href="https://www.hpl.hp.com/hpjournal/pdfs/IssuePDFs/1989-04.pdf" data-link-icon="pdf" data-link-icon-type="svg">download the original PDF</a>⁠.</p>
            <p>If that hadn’t worked, searching for the URL without <code>/pg_2/</code> in it yields the full citation, and then that can be looked up normally. Finally, somewhat more dangerous would be trying to find the article just by author surname &amp; year.</p>
          </section>
          <section id="description-but-no-citation">
            <h2><a href="#description-but-no-citation" title="Link to section: § 'Description But No Citation'">Description But No Citation</a></h2>
            <p>A 2013 <a href="https://gwern.net/doc/www/www.medicaldaily.com/edf8f97057799b156cf565a4ffd0494f310d3395.html" rel="archived alternate nofollow" data-url-original="https://www.medicaldaily.com/psychologists-discover-how-people-subconsciously-become-their-favorite-fictional-characters-240435" title="Psychologists Discover How People Subconsciously Become Their Favorite Fictional Characters (Original URL: https://www.medicaldaily.com/psychologists-discover-how-people-subconsciously-become-their-favorite-fictional-characters-240435 )">Medical Daily</a> on the effects of reading fiction omitted any link or citation to the research in question. But it is easy to find.</p>
            <p>The article says the authors are one Kaufman &amp; Libby, and implies it was published in the last year. So: go to Google Scholar, punch in <code>Kaufman Libby</code>, limit to ‘Since 2012’; and the correct paper ( <a href="https://gwern.net/doc/www/tiltfactor.org/227553b28ae45d80f73f5e2ffa17420c06c85833.pdf" id="kaufman-libby-2012" data-link-icon="pdf" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://tiltfactor.org/wp-content/uploads2/Kaufman_Libby2012_JPSPadvanceonlinepublication.pdf" title="Kaufman &amp; Libby 2012 (Original URL: https://tiltfactor.org/wp-content/uploads2/Kaufman_Libby2012_JPSPadvanceonlinepublication.pdf )">“Changing beliefs and behavior through experience-taking”</a>) is the first hit with fulltext available on the right-hand side as the text link “[PDF] from <code>tiltfactor.org</code>” &amp; many other domains.</p>
          </section>
          <section id="finding-followups">
            <h2><a href="#finding-followups" title="Link to section: § 'Finding Followups'">Finding Followups</a></h2>
            <p><a href="https://www.lesswrong.com/posts/X6APQeHhXH9mbredM/soylent-orange-whole-food-open-source-soylent#comment-PWDQq3f5qSqWRc82c" data-link-icon="LW" data-link-icon-type="text">Is soy milk bad for you</a> as one study suggests? Has anyone replicated it? This is easy to look into a little if you use the power of reverse citation search!</p>
            <p>Plug <code>Brain aging and midlife tofu consumption</code> into Google Scholar, one of the little links under the first hit points to “Cited by 176”; if you click on that, you can hit a checkbox for “Search within citing articles”; then you can search a query like <code>experiment OR randomized OR blind</code> which yields <a href="https://scholar.google.com/scholar?q=experiment+OR+randomized+OR+blind&amp;btnG=&amp;as_sdt=20005&amp;sciodt=0%2C9&amp;cites=14459450472515815282&amp;scipsc=1" data-link-icon="google-scholar" data-link-icon-type="svg">121 results</a>⁠. The <a href="https://gwern.net/doc/www/n.neurology.org/d3d3621441fed99260a76d7b3a08b1eacafd1fbb.html" id="henderson-al-2012" rel="archived alternate nofollow" data-url-original="https://n.neurology.org/content/78/23/1841.short" title="'Long-term soy isoflavone supplementation and cognition in women: A randomized, controlled trial', Henderson et al 2012 (Original URL: https://n.neurology.org/content/78/23/1841.short )">first result</a> shows no negative effect and a trend to a benefit, the second is inaccessible, the second &amp; third are reviews whose abstract suggests it would argue for benefits, and the fourth discusses sleep &amp; mood benefits to soy diets. At least from a quick skim, this claim is not replicating, and I am dubious about it.</p>
          </section>
          <section id="how-many-homeless">
            <h2><a href="#how-many-homeless" title="Link to section: § 'How Many Homeless?'">How Many Homeless?</a></h2>
            <p>Does NYC really have 114,000+ homeless school children? This case study demonstrates the critical skill of <em>noticing</em> the need to search at all, and the search itself is almost trivial.</p>
            <p><span>Won’t someone think of the children?</span> In March 2020, as <a href="https://en.wikipedia.org/wiki/COVID-19_pandemic_in_the_United_States" data-link-icon="wikipedia" data-link-icon-type="svg">New York coronavirus cases began their exponential increase</a> centered in Manhattan (with a similar trend to Wuhan/​Iran/​Italy), NYC Mayor <a href="https://en.wikipedia.org/wiki/Bill_de_Blasio" data-link-icon="wikipedia" data-link-icon-type="svg">Bill de Blasio</a> refused to take social distancing/​quarantine measures like ordering the NYC public school system closed, and this delay until 16 March contributed to the epidemic’s unchecked spread in NYC; one justification was that there were “114,085 homeless children” who received social services like free laundry through the schools. This number has been widely cited in the media by the <em>NYT</em>, <em>WSJ</em>, etc, and was vaguely sourced to “state data” reported by “Advocates for Children of New York”. This is a terrible reason to not deal with a pandemic that could kill tens of thousands of New Yorkers, as there are many ways to deliver services which do not require every child in NYC to attend school &amp; spread infections—but first, is this number even true?</p>
            <p><span>Basic numeracy: implausibly-large!</span> Activists of any stripe are untrustworthy sources, and a number like 114k should make any numerate person uneasy even without any <a href="https://en.wikipedia.org/wiki/Fermi_problem" data-link-icon="wikipedia" data-link-icon-type="svg">Fermi estimation</a> or fact-checking; “114,085” is suspiciously precise for such a difficult-to-measure or define thing like homelessness, and it’s well-known that the population of NYC is ~8m or 8,000k—is it really the case that around 1 in every 70 people living in NYC is a homeless child age ~5–18 attending a public school? They presumably have at least 1 parent, and probably younger siblings, so that would bring it up to &gt;228k or 1 in every &lt;35 inhabitants of NYC being homeless in general. Depending on additional factors like transiency &amp; turnover, the fraction could go much higher still. Does that make sense? No, not really. This quoted number is either surprising, or there is something missing.</p>
            <p><span>Redefining “homeless”.</span> Fortunately, the suspiciously-precise number and attribution make this a good place to start for a search. Searching for the number and the name of the activist group instantly turns up <a href="https://gwern.net/doc/www/www.advocatesforchildren.org/4396d149ff553a24534dfa3063f32211fbb8fe9c.html" rel="archived alternate nofollow" data-url-original="https://www.advocatesforchildren.org/node/1403" title="New Data Show Number of NYC Students who are Homeless Topped 100,000 for Fourth Consecutive Year (Original URL: https://www.advocatesforchildren.org/node/1403 )">the source press release</a>⁠, and the reasons for the bizarrely high number are revealed: the statistic actually redefines ‘homelessness’ to include living with relatives or friends, and counts any experience of any length in the previous year as rendering that student ‘homeless’ at the moment.</p>
            <blockquote>
              <p>The data, which come from the New York State Education Department, show that in the 2018-2019 school year, New York City district and charter schools identified 114,085, or one in ten, students as homeless. More than 34,000 students were living in New York City’s shelters, and more than twice that number (73,750) were living ‘doubled-up’ in temporary housing situations with relatives, friends, or others…“This problem is immense. The number of New York City students who experienced homelessness last year—85% of whom are Black or Hispanic—could fill the Barclays Center six times,” said Kim Sweet, AFC’s Executive Director. “The City won’t be able to break the cycle of homelessness until we address the dismal educational outcomes for students who are homeless.”</p>
            </blockquote>
            <p>The <a href="https://gwern.net/doc/www/www.coalitionforthehomeless.org/376804c98cc59e6939f6e3879828c286a3f1ee22.html" rel="archived alternate nofollow" data-url-original="https://www.coalitionforthehomeless.org/todays-read-new-york-city-had-114000-homeless-students-last-year/" title="Today's Read: New York City Had 114,000 Homeless Students Last Year (Original URL: https://www.coalitionforthehomeless.org/todays-read-new-york-city-had-114000-homeless-students-last-year/ )"><em>WSJ</em>’s article</a> (but not headline) confirms that ‘experienced’ does indeed mean ‘at any time in the year for any length of time’, rather than ‘at the moment’:</p>
            <blockquote>
              <p>City district and charter schools had 114,085 students without their own homes at some point last year, topping 100,000 for the fourth year in a row, according to state data released in a report Monday from Advocates for Children of New York, a nonprofit seeking better services for the disadvantaged. Most children were black or Hispanic, and living “doubled up” with friends, relatives or others. But more than 34,000 slept in city shelters at some point, a number larger than the entire enrollment of many districts, such as Buffalo, Rochester or Yonkers.</p>
            </blockquote>
            <p><span>Less than meet the eye.</span> So the actual number of ‘homelessness’ (in the sense that everyone reading those media articles understands it) is less than a third the quote, 34k, and that 34k number is likely itself a loose estimate of how many students would be homeless at the time of a coronavirus closure. This number is far more plausible and intuitive, and while one might wonder about what the underlying NYS Education Department numbers would reveal if fact-checked further, that’s probably unnecessary for showing how ill-founded the anti-closure argument is, since even by the activists’ own description, the relevant number is far smaller than 114k.</p>
          </section>
          <section id="citation-url-with-typo">
            <h2><a href="#citation-url-with-typo" title="Link to section: § 'Citation URL With Typo'">Citation URL With Typo</a></h2>
            <p><a href="https://gwern.net/doc/iq/high/2015-hofman.pdf" id="hofman-2015" data-link-icon="pdf" data-link-icon-type="svg" title="'Evolution of the Human Brain: From Matter to Mind', Hofman 2015">“Evolution of the Human Brain: From Matter to Mind”<span>, <span><span>Hofman</span><span>2015</span></span></span></a>⁠, discusses the limits to the intelligence of increasingly large primate brains due to considerations like increasing latency and overheating. One citation attempting to extrapolate upper bounds is “Biological limits to information processing in the human brain”<span>, <span><span title="et al">Cochrane</span> <span>et al</span> <span>1995</span></span>.</span></p>
            <p>The source information is merely a broken URL: <code>http://www.cochrane.org.uk/opinion/archive/articles.phd</code> which stands out for looking doubly-wrong: “.phd” is almost certainly a typo for “.ph<em>p</em>” (probably muscle memory on the part of Hofman from “PhD”), but it also gives a hint that the entire URL is wrong: why would an article or essay be named anything like <code>archive/articles.php</code>? That sounds like an <em>index</em> page listing all the available articles.</p>
            <p>After trying and failing to find Cochrane’s paper in the usual places, I returned to the hint. The Internet Archive doesn’t have that page under either possible URL, but the directory strongly hints that all of the papers would exist at URLs like <code>archive/brain.php</code> or <code>archive/information-processing.php</code>, and we can look up all of the URLs the IA has under that directory—how many could there be? <a href="https://web.archive.org/web/*/http://www.cochrane.org.uk/opinion/archive/*" data-link-icon="internetarchive" data-link-icon-type="svg">A lot</a>⁠, but only one has the keyword “brain” in it, providing us <a href="https://gwern.net/doc/iq/1995-cochrane-biologicallimitstoinformationprocessinginthebrain.html" id="cochrane-et-al-1995" title="'Biological limits to information processing in the human brain', Cochrane et al 1995">the paper itself</a>⁠.</p>
            <p>If that hadn’t worked, there was at least one other version hiding in the IA. When I googled the quoted title “Biological limits to information processing in the human brain”, the hits all appeared to be useless citations repeating the original Hofman citation—but for a crucial difference, as they cite a different URL (note the shift to an ‘archive.cochrane.org’ subdomain rather than the subdirectory <code>cochrane.org.uk/opinion/archive/</code>, and change of extension from <code>.html</code> to <code>.php</code>):</p>
            <ul>
              <li>
                <p>hit 5:</p>
                <blockquote>
                  <p>Biological Limits to Information Processing in the Human Brain. Retrieved from: <code>http://archive.cochrane.org.uk/opinion/archive/articles/brain9a.php</code></p>
                </blockquote>
              </li>
              <li>
                <p>hit 7:</p>
                <blockquote>
                  <p>Biological Limits to Information Processing in the Human Brain. Available online at: <code>http://archive.cochrane.org.uk/opinion/archive/articles/brain9a.php</code>; Da Costa …</p>
                </blockquote>
              </li>
            </ul>
            <p>Aside from confirming that it was indeed a ‘.php’ extension, that URL gives you <a href="https://web.archive.org/web/20161201053731/http://archive.cochrane.org.uk/opinion/archive/articles/brain9a.php" data-link-icon="internetarchive" data-link-icon-type="svg">a second copy of the paper in the IA</a>⁠. Unfortunately, the image links are broken in both versions, and the image subdirectories also seem to be empty in both IA versions, though there’s no weird JS image loading badness, so I’d guess that the image links were always broken, at least by 2004. There’s no indication it was ever published or mirrored anywhere else, so there’s not much you can do about it other than to contact Peter Cochrane (who is still alive and actively publishing although he leaves this particular article off his <a href="https://gwern.net/doc/www/petercochrane.com/d4de8653934460ebcbfc19cbf90149aa967b7949.html" rel="archived alternate nofollow" data-url-original="https://petercochrane.com/personal/publications" title="(Original URL: https://petercochrane.com/personal/publications )">publication list</a>).</p>
          </section>
          <section id="connotations">
            <h2><a href="#connotations" title="Link to section: § 'Connotations'">Connotations</a></h2>
            <p>A commenter <a href="https://www.lesswrong.com/posts/oFMywHmJffsCSDNB7/using-evolution-for-marriage-or-sex#comment-AJ5xdSRjq7mwtR7Ea" data-link-icon="LW" data-link-icon-type="text">who shall remain nameless</a> wrote</p>
            <blockquote>
              <p>I challenge you to find an example of someone saying “this den of X” where X does not have a negative connotation.</p>
            </blockquote>
            <p>I found a <a href="https://www.memphisdailynews.com/news/2012/nov/15/this-den-of-grizzlies-players-doesnt-bluff/" title="This Den of Grizzlies Players Doesn't Bluff">positive connotation within 5s</a> using my Google hotkey for <code>"this den of "</code>, and, curious about further ones, found additional uses of the phrase in regard to dealing with rattlesnakes in Google Books.</p>
          </section>
          <section id="too-narrow">
            <h2><a href="#too-narrow" title="Link to section: § 'Too Narrow'">Too Narrow</a></h2>
            <p>A failure case study: <a href="https://www.lesswrong.com/posts/wKWvodoAt3zRhyC4x/rationality-quotes-november-2012#comment-c4yECdhdDHoMvNWEs" data-link-icon="LW" data-link-icon-type="text">The_Duck</a> looked for but failed to find other uses of a famous <a href="https://en.wikipedia.org/wiki/Ludwig_Wittgenstein" data-link-icon="wikipedia" data-link-icon-type="svg">Wittgenstein</a> anecdote. His mistake was being <em>too specific</em>:</p>
            <blockquote>
              <p>Yes, clearly my Google-fu is lacking. I think I searched for phrases like “sun went around the Earth,” which fails because your quote has “sun went round the Earth.”</p>
            </blockquote>
            <p>As discussed in the search tips, when you’re formulating a search, you want to balance how many hits you get, aiming for a sweet spot of a few hundred high-quality hits to review—the broader your formulation, the more likely the hits will include your target (if it exists) but the more hits you’ll return. In The_Duck’s case, he used an overly-specific search, which would turn up only 2 hits at most; this should have been a hint to loosen the search, such as by dropping quotes or dropping keywords.</p>
            <p>In this case, my reasoning would go something like this, laid out explicitly: ‘“Wittgenstein” is almost guaranteed to be on the same page as any instance of this quote, since the quote is about Wittgenstein; LW, however, doesn’t discuss Wittgenstein much, so there won’t be many hits in the first place; to find this quote, I only need to narrow down those hits a <em>little</em>, and after “Wittgenstein”, the most fundamental core word to this quote is “Earth” or “sun”, so I’ll toss one of them in and… ah, there’s the quote!’</p>
            <p>If I were searching the general Internet, my reasoning would go more like “‘Wittgenstein’ will be on, like, a <em>million</em> websites; I need to narrow that down a <em>lot</em> to hope to find it; so maybe ‘Wittgenstein’ <em>and</em> ‘Earth’ <em>and</em> ‘Sun’… nope, nothing on the first page, so toss in <code>'goes around' OR 'go around'</code>—ah there it is!”</p>
            <p>(Actually, for the general Internet, just <code>Wittgenstein earth sun</code> turns up a first page mostly about this anecdote, several of which include all the details one could need.)</p>
          </section>
          <section id="try-it">
            <h2><a href="#try-it" title="Link to section: § 'Try It'">Try It</a></h2>
            <p>Someone asked on IRC: “anybody here know that one artist with the really creepy art sytle [sic] that starts with a z?”</p>
            <p>I googled: ‘that one artist with the really creepy art sytle [sic] that starts with a z’. It was hit #2, <a href="https://en.wikipedia.org/wiki/Zdzis%C5%82aw_Beksi%C5%84ski" data-link-icon="wikipedia" data-link-icon-type="svg">Zdzisław Beksiński</a>⁠. (DuckDuckGo, incidentally, buries Beksiński several pages in, and I didn’t find him in Bing at all.)</p>
          </section>
          <section id="really-just-try-it">
            <h2><a href="#really-just-try-it" title="Link to section: § 'Really, Just Try It'">Really, Just Try It</a></h2>
            <p>Quanticle asked:</p>
            <blockquote>
              <p>There’s a sci-fi book I’m thinking of, where the protagonist is a scout soldier fighting an endless war against an insectoid species. It reads like a cross between <em>Ender’s Game</em> and <em>Starship Troopers</em> (but is not written by John Sclazi or is <em>The Forever War</em>) and the main story takes place inside a frame story where two other people are actually “reading” this soldier’s memories from his salvaged battlesuit. There is a planet called “Golden”, where the soldier is allegedly from. Does anyone have any idea what I’m talking about?</p>
            </blockquote>
            <p>The search <code>book about a soldier from the planet golden</code> immediately turned up <a href="https://en.wikipedia.org/wiki/John_Steakley" data-link-icon="wikipedia" data-link-icon-type="svg">John Steakley’s</a> <a href="https://en.wikipedia.org/wiki/Armor_(novel)" data-link-icon="wikipedia" data-link-icon-type="svg"><em>Armor</em></a>⁠. (This was showing off a little—<em>Armor</em> is well-regarded and difficult to forget, and I’d read it a long time ago and already knew the answer, pace the hacker koan<a href="#fn20" id="fnref20" role="doc-noteref"><sup>20</sup></a>⁠.)</p>
            <p>Quanticle noted that “You know, I searched for similar phrases, but I ended up fixating on the soldier’s key phrase, where he called his battle-trance”The Machine”, and that dragged in lots of irrelevancies.” (A good intuition for search engine use would shy away from using any word or phrase as incredibly generic as “the machine”.)</p>
          </section>
          <section id="try-it-1">
            <h2><a href="#try-it-1" title="Link to section: § '(Try It!)'">(Try It!)</a></h2>
            <p>FeepingCreature asked, while designing a compiler for a custom language,</p>
            <blockquote>
              <p>Hey, what was the official name for Lisp’s “data and code” thing?</p>
            </blockquote>
            <p>I already knew that it is “<a href="https://en.wikipedia.org/wiki/Homoiconicity" data-link-icon="wikipedia" data-link-icon-type="svg">homoiconicity</a>”, but I bet that <code>official name for Lisp's "data and code" thing</code> would work if I tried it in Google. It did.</p>
          </section>
          <section id="yes-that-works-too">
            <h2><a href="#yes-that-works-too" title="Link to section: § 'Yes, That Works Too'">Yes, That Works Too</a></h2>
            <p><a href="https://gwern.net/doc/www/old.reddit.com/4780683b1e77b3f92360405ebe92ba3f468fefe9.html" data-link-icon="alphabet" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://old.reddit.com/r/slatestarcodex/comments/p21d1t/for_gods_sake_google_it/h8ibsff/" title="(Original URL: https://www.reddit.com/r/slatestarcodex/comments/p21d1t/for_gods_sake_google_it/h8ibsff/ )">Grayson81</a>:</p>
            <blockquote>
              <p>One thing that’s rather shocking to those of us who used search engines (and even directories like Yahoo before they got the idea of becoming real search engines from Google) is just how good they’ve got at understanding a vague, poorly written or mistaken search.</p>
              <p>…I remember trying to explain how Google works to my mother ten years ago and explaining why “who’s that actress? You know, the one with the eyes. Not <a href="https://en.wikipedia.org/wiki/Katy_Perry" data-link-icon="wikipedia" data-link-icon-type="svg">Katy Perry</a>” isn’t a question that a computer can answer. Now she can Google exactly that and all of the top results are telling her that she’s thinking of <a href="https://en.wikipedia.org/wiki/Zooey_Deschanel" data-link-icon="wikipedia" data-link-icon-type="svg">Zooey Deschanel</a>!</p>
            </blockquote>
          </section>
          <section id="comics">
            <h2><a href="#comics" title="Link to section: § 'Comics'">Comics</a></h2>
            <p><a href="https://juliagalef.com/">Julia Galef</a> tweeted:</p>
            <blockquote>
              <p>I read a webcomic ~15 years ago that I’ve been unable to find since, even with my best google-fu. It involved a robot living a bleak life as a working stiff. At the end he cracked open his “skull” and there was a small dying creature inside. The art style was less cartoony, and more like Moebius, I think? And maybe it was wordless? And, sorry, it wasn’t a “webcomic” in the sense of a long-running thing. It was a self-contained story, maybe 15 pages long?</p>
            </blockquote>
            <p>Ultimately rediscovering that</p>
            <blockquote>
              <p>The comic was called <a href="https://gwern.net/doc/fiction/science-fiction/2004-chivers-headcase.pdf" id="chivers-2004" data-link-icon="pdf" data-link-icon-type="svg" title="'Headcase', Chivers 2004">“Headcase”</a> and it was by Sam Chivers.</p>
            </blockquote>
            <p>Unfortunately, no mirrors of it appeared online or on Chivers’s current website, and discussions of it mentioned that it was interesting for being an <a href="https://en.wikipedia.org/wiki/Adobe_Flash" data-link-icon="wikipedia" data-link-icon-type="svg">Adobe Flash</a> webcomic. Worse still, nothing useful appeared <a href="https://web.archive.org/web/2020*/http://www.realitytax.com/*" data-link-icon="internetarchive" data-link-icon-type="svg">in the Internet Archive for the original website</a>—somehow the IA appeared to have missed any relevant <code>.swf</code> files, and ‘head’/​‘case’ turned up no relevant looking filenames. It might have been buried in the opaquely-named images, and my usual next step would be to download the IA archives and inspect every image, but in other hits, I found that an obscure comics publisher had published an anthology involving Chivers, and <a href="https://gwern.net/doc/www/theslingsandarrows.com/8a9eded3ebec4e1a610ff3ca854d8a0c2c5fe963.html" id="plowright-2020" rel="archived alternate nofollow" data-url-original="https://theslingsandarrows.com/prophecy-anthology-volume-1/" title="'<em>Prophecy Anthology Volume 1</em>, review', Plowright 2020 (Original URL: https://theslingsandarrows.com/prophecy-anthology-volume-1/ )">closer inspection</a> confirmed that “Headcase” was in fact published in their (long out of print) 2004 anthology <em>Prophecies: Volume 1</em>. (Not a prophetic name inasmuch as there was no volume 2.)</p>
            <p>In one of the usual ironies of linkrot, Chivers presumably taking down “Headcase” for print publication in <em>Prophecy</em> may have preserved it, as while I am unable to find any digital copies, the paper version is easily obtained as a used book &amp; scanned at modest cost.</p>
          </section>
          <section id="beating-pdf-passwords">
            <h2><a href="#beating-pdf-passwords" title="Link to section: § 'Beating PDF Passwords'">Beating PDF Passwords</a></h2>
            <p><span id="astronomy"><a href="https://cognitivemedium.com/vme" data-link-icon="MN" data-link-icon-type="text">A physics article</a></span> mentioned they had been unable to get <a href="https://gwern.net/doc/science/1973-drake.pdf" id="drake-1973" data-link-icon="pdf" data-link-icon-type="svg" title="'Life on a Neutron Star: An Interview With Frank Drake', Drake 1973">an old 1973 interview</a> in a popular magazine; as is usually the case for non-scholarly magazines, after looking thoroughly, I could find no trace of it anywhere (not even in libraries or used-magazine sellers) other than an expensive DVD collection of back issues 1970–2010 still being sold by the publisher. Reasoning that if they had digitized the archives and were even selling it as a DVD collection, they ought to provide subscribers access to them as well, I signed up—they didn’t! So I resorted to the DVD, as, worst-case, I should be able to get it running under <a href="https://en.wikipedia.org/wiki/Wine_(software)" data-link-icon="wikipedia" data-link-icon-type="svg">WINE</a> if nothing else, and can screenshot the interview.</p>
            <p>The DVDs turned out to store all the PDFs as encrypted PDFs and the metadata in an ancient opaque database format I’d never heard of. Despite WINE AppDB’s claims, the viewing software only partially worked, and I set about attacking the PDFs directly. They used actual encryption, so pdftk couldn’t strip the passwording. Given the viewing software, I hypothesized that there was either a single master password or per-PDF passwords stored in the database.</p>
            <p>In the hopes of it being a single short master password, I installed <a href="https://en.wikipedia.org/wiki/John_the_Ripper" data-link-icon="wikipedia" data-link-icon-type="svg">John the Ripper</a> (JtR) jumbo edition and extracted the hash of a random file to attack: <code>/snap/john-the-ripper/current/run/pdf2john.pl *.pdf &gt; ~/hash</code>. (Note: pdf2john is not in the default JtR, and it depends on JtR internal files so you can’t easily just copy it out of the <a href="https://en.wikipedia.org/wiki/GitHub" data-link-icon="wikipedia" data-link-icon-type="svg">Github</a> repo &amp; run it, as I discovered the hard way. You need to install the jumbo edition.) The password hashes of all the PDFs indeed turned out to be the same, so it used a master password. A simple attack with default password-space could be executed as <code>john-the-ripper ~/hash</code>. While I waited for all of the DVDs to copy, I saw that JtR was getting something like only a hundred thousand hashes/​s on my 16 Threadripper CPU cores, and did not have any success up to 5-character passwords.</p>
            <p>If the password wasn’t really short, CPU wouldn’t be enough. I decided to switch to <a href="https://en.wikipedia.org/wiki/Hashcat" data-link-icon="wikipedia" data-link-icon-type="svg">Hashcat</a> to put my 2×1080ti Nvidia GPUs to good use, as they ought to run hundreds of times faster than JtR. (To convert the JtR hash format to Hashcat hash format, you delete the colon-separated filename field at the beginning of each line.) Hashcat uses a <a href="https://gwern.net/doc/www/hashcat.net/87fbd82f8b8794603fb3b0cca174c21310b4741b.html" rel="archived alternate nofollow" data-url-original="https://hashcat.net/wiki/doku.php?id=mask_attack" title="(Original URL: https://hashcat.net/wiki/doku.php?id=mask_attack )">powerful but confusing</a> DSL of specifying the exact password-space, and I made a reasonable guess that if the original programmer was so lazy as to use a single master password, he would also use a simple alphanumeric password (uppercase + lowercase + decimal numbers), and nothing harder to type or read. To specify the PDF hash type and an attack starting at 1-character alphanumeric &amp; increasing, I wound up with the incantation <code>hashcat -m 10500 ~/hash.cat -w 3 --force -a 3 --increment -1 '?l?u?d' ?1?1?1?1?1?1?1?1?1?1?1</code>.</p>
            <p>Hashcat worked much better and within an hour had bruteforced on the order of 170 billion hashes and up somewhere around 8 characters. This did not succeed either. At this point, another programmer thought it’d be fun to participate and, while reverse-engineering the executable to see how it decrypted PDFs, suggested that the master password was probably hardcoded as a string literal inside the viewer executable. One could just dump all the strings inside it with the CLI utility <code>strings *.exe &gt; strings.txt</code>, and then use it as a Hashcat password list. To my chagrin, when I finally got around to trying <code>cat strings.txt | hashcat -m 10500 ~/hash.cat -w 3</code>, it finished within 1s.</p>
            <p>The password turned out to be <code>B775tO11dQvu74</code>. I was right that it was alphanumerical, but at a length of 14 characters, I doubt I would have brute-forced it. (He successfully reverse-engineered it and discovered the viewer had been used for several other magazine archives as well, apparently, and simply switched master passwords to decrypt each one; the other passwords left in the executable were <code>PbS19LuXd2pTXw</code>, <code>1386r8wRrH01</code>, &amp; <code>mfU33QQNlAFGI1</code>.)</p>
            <p>I then decrypted the PDF (<code>for PDF in *.pdf; do pdftk "$PDF" input_pw "B775tO11dQvu74" output foo.pdf &amp;&amp; mv foo.pdf "$PDF"; done</code>), extracted &amp; uploaded the interview, and archived the collection elsewhere.</p>
          </section>
          <section id="lewontins-thesis">
            <h2><a href="#lewontins-thesis" title="Link to section: § 'Lewontin’s Thesis'">Lewontin’s Thesis</a></h2>
            <p>In <a href="https://gwern.net/doc/www/www.nature.com/e4b871d14e7cf16b5f751d743dcdba1981962da0.pdf" data-link-icon="n" data-link-icon-type="text" rel="archived alternate nofollow" data-url-original="https://www.nature.com/articles/266283a0.pdf" title="Caricature of Darwinism (Original URL: https://www.nature.com/articles/266283a0.pdf )">a vituperative review in <em>Nature</em></a> in 1977-03-17, the Harvard-professor <a href="https://en.wikipedia.org/wiki/Richard_Lewontin" data-link-icon="wikipedia" data-link-icon-type="svg">R. C. Lewontin</a> excoriated <a href="https://en.wikipedia.org/wiki/Richard_Dawkins" data-link-icon="wikipedia" data-link-icon-type="svg">Richard Dawkins’s</a> classic <a href="https://en.wikipedia.org/wiki/The_Selfish_Gene" data-link-icon="wikipedia" data-link-icon-type="svg"><em>The Selfish Gene</em></a> and <a href="https://en.wikipedia.org/wiki/Sociobiology" data-link-icon="wikipedia" data-link-icon-type="svg">sociobiology</a> in general, giving as an example</p>
            <blockquote>
              <p>For more than 40 years evolutionary theory has remained free of a naive selectionism, but in recent times there has been a return to the extreme form of the adaptationist program, as evolutionists have rediscovered behaviour. Beginning with the undoubted truth that behaviour must, like morphology and physiology, be subject to the force of <a href="https://en.wikipedia.org/wiki/Natural_selection" data-link-icon="wikipedia" data-link-icon-type="svg">natural selection</a>⁠, the new Panglossians end with the old error that all describable behaviour must be the direct product of natural selection. The scientific manifestation of this trend can be seen in every issue of say, <em>The American Naturalist</em>, which is permeated by the language, if not the formal apparatus, of <a href="https://en.wikipedia.org/wiki/Game_theory" data-link-icon="wikipedia" data-link-icon-type="svg">game theory</a>⁠, and in the development of the school of ‘sociobiology’, among whose more extraordinary productions is a recent highly praised dissertation explaining <a href="https://en.wikipedia.org/wiki/Fellatio" data-link-icon="wikipedia" data-link-icon-type="svg"><em>fellatio</em></a> and <a href="https://en.wikipedia.org/wiki/Cunnilingus" data-link-icon="wikipedia" data-link-icon-type="svg"><em>cunnilingus</em></a> among the upper middle classes as an adaptive response to constant resources. The popular manifestation of this new caricature of Darwinism reaches its most extreme form in <em>The Selfish Gene</em> by Richard Dawkins.</p>
            </blockquote>
            <p>As is common in book reviews, Lewontin provides no citations, and <a href="https://twitter.com/DevoEvoMed/status/1478785200964476929" data-link-icon="twitter" data-link-icon-type="svg">2 biologists</a> were curious but unable to figure out what Lewontin was referring to despite searching.</p>
            <p>The thesis in question is easy to find in under a minute, because the context gives so many hints: Lewontin refers to it as notorious &amp; widely discussed so it will have many substantive citations (if only to attack it); it is ‘recent’ (and sociobiology was a heated controversy so it is unlikely to be ‘recent’ in the sense of ‘a quiet field of research still mulling over a provocative paper from 2 decades’ before, but more like ‘within the past 2 or 3 years’ &amp; certainly at least 1970–1977), it is a ‘dissertation’ and so single-authored &amp; almost certainly a PhD thesis by someone who became at least a postgrad researcher (because a master’s thesis would be too low-status to be discussed or praised, or singled out for abuse in <em>Nature</em>—it would be unclassy for a chaired Harvard professor to attack such a junior grad student’s work there like that), and it likely uses the words “fellatio” and “cunnilingus” as technical terms &amp; decorous Latinate scientific censoring.</p>
            <p>If we plug into Google Scholar a date-range of 1970–1977 and the simplest possible query <code>fellatio cunninglingus "evolutionary psychology" OR sociobiology</code> or <code>fellatio cunninglingus sociobiology</code> or <code>fellatio cunninglingus "evolutionary psychology"</code>, we see in GS 2 hits (for the former) or among the hits (latter), the immediately-relevant looking <a href="https://gwern.net/doc/genetics/selection/natural/human/1977-weinrich.pdf" id="weinrich-1977" data-link-icon="pdf" data-link-icon-type="svg" title="'Human sociobiology: Pair-bonding and resource predictability (effects of social class and race)', Weinrich 1977">“Human sociobiology: Pair-bonding and resource predictability (effects of social class and race)”<span>, <span><span>Weinrich</span><span>1977</span></span></span></a> and <a href="https://gwern.net/doc/genetics/selection/natural/human/1976-weinrich.pdf" id="weinrich-1976" data-link-icon="pdf" data-link-icon-type="svg" title="'Human Reproductive Strategy: I. Environmental Predictability And Reproductive Strategy; Effects Of Social Class And Race. II. Homosexuality And Non-Reproduction; Some Evolutionary Models', Weinrich 1976">“Human Reproductive Strategy: I. Environmental Predictability And Reproductive Strategy; Effects Of Social Class And…”<span>, <span><span>Weinrich</span><span>1976</span></span></span></a>⁠, both by the same author ( <a href="https://scholar.google.com/scholar?cites=15430285300114043496&amp;as_sdt=20000005&amp;sciodt=0,21" data-link-icon="google-scholar" data-link-icon-type="svg">148</a>+<a href="https://scholar.google.com/scholar?cites=4719348106040602943&amp;as_sdt=20000005&amp;sciodt=0,21" data-link-icon="google-scholar" data-link-icon-type="svg">16</a> citations, quite healthy); the single-authorship &amp; <code>search.proquest.com</code> domain for the latter immediately tells us that it’s a PhD thesis; clicking verifies that the thesis was at Harvard (which gives it both prestige Lewontin loathes &amp; ensures he could easily hear of it); the similarity of titles suggests that the paper is a condensed version of the thesis (reading the paper suggests this isn’t entirely true but is more of an update); Weinrich did indeed go on to a long career (at <a href="https://en.wikipedia.org/wiki/San_Diego_University" data-link-icon="wikipedia" data-link-icon-type="svg">San Diego University</a>⁠, publishing <a href="https://scholar.google.com/citations?user=qIeHxgkAAAAJ&amp;view_op=list_works&amp;alert_preview_top_rm=2&amp;sortby=pubdate" data-link-icon="google-scholar" data-link-icon-type="svg">up until 2014</a>); there are attacks like <a href="https://gwern.net/doc/genetics/selection/natural/human/1978-lande.pdf" id="lande-weinrich-1978" data-link-icon="pdf" data-link-icon-type="svg" title="Are Humans Maximizing Reproductive Success? [with Reply]"><span><span>Lande</span><span>1987</span></span></a> showing it did not pass without notice; and even the ProQuest preview of the abstract looks consistent with Lewontin’s summary (there can’t be that many such theses!).</p>
            <p><span>So, we can be sure that Lewontin is referring to <span><span>Weinrich</span><span>1976</span></span>.</span></p>
          </section>
          <section id="edward-tellers-atom-alphabet">
            <h2><a href="#edward-tellers-atom-alphabet" title="Link to section: § 'Edward Teller’s Atom Alphabet'">Edward Teller’s “Atom Alphabet”</a></h2>
            <p>Nuclear physicist <a href="https://en.wikipedia.org/wiki/Edward_Teller" data-link-icon="wikipedia" data-link-icon-type="svg">Edward Teller</a> wrote a rhyming ‘atom alphabet’ about the nuclear era, but only a few of the letters like A/​B/​S are ever quoted. Did he write a <em>whole</em> alphabet?</p>
            <p><a href="https://gwern.net/doc/www/old.reddit.com/a2b78313f9aa5bc4e79048c9003b6e1509d3448a.html" data-link-icon="reddit" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://old.reddit.com/r/unsong/comments/4pzyvq/edward_tellers_atom_alphabet_1946/" title="(Original URL: https://www.reddit.com/r/unsong/comments/4pzyvq/edward_tellers_atom_alphabet_1946/ )">Tracing citations back</a> to a <em>Time</em> magazine &amp; <a href="https://en.wikipedia.org/wiki/Laura_Fermi" data-link-icon="wikipedia" data-link-icon-type="svg">Laura Fermi’s</a> memoir strongly implies that he did not, and only write A/​B/​F/​H/​S. (There has been at least one effort <a href="https://www.reddit.com/r/unsong/comments/zckyg0/completing_edward_tellers_atom_alphabet_with/" data-link-icon="reddit" data-link-icon-type="svg">to write the rest</a>⁠.)</p>
          </section>
          <section id="pressley-et-al-1989">
            <h2><a href="#pressley-et-al-1989" title="Link to section: § 'Pressley et al 1989'"><span><span title="et al">Pressley</span> <span>Et Al</span> <span>1989</span></span></a></h2>
            <p>In <a href="https://www.patreon.com/posts/reading-and-85345515" data-link-icon="patreon" data-link-icon-type="svg">a discussion of learning</a>⁠, <a href="https://gwern.net/doc/www/andymatuschak.org/991e56a3a61f84d8cb1025af60ccfa6c60da6ccb.html" rel="archived alternate nofollow" data-url-original="https://andymatuschak.org/" title="(Original URL: https://andymatuschak.org/ )">Andy Matuschak</a> referenced a paper on an <a href="https://gwern.net/doc/psychology/cognitive-bias/illusion-of-depth/index" title="'illusion-of-depth bias tag', N/A 2023">illusion-of-depth</a> in reading comprehension (related to illusions of learning from using cramming rather than <a href="https://gwern.net/spaced-repetition" id="gwern-spaced-repetition" title="‘Spaced Repetition for Efficient Learning’, Gwern 2009">spaced repetition</a>), but mentioned he had been unable to find a copy anywhere to verify it. The citation for this paper was:</p>
            <blockquote>
              <p>Pressley, M., Ghatala, E. S., Pirie, J., &amp; Woloshyn, V. E. (1990). <a href="https://gwern.net/doc/psychology/cognitive-bias/illusion-of-depth/1990-pressley.pdf" id="pressley-et-al-1990" data-link-icon="pdf" data-link-icon-type="svg" title="'Being really, really certain you know the main idea doesn&amp;#39;t mean you do', Pressley et al 1990">“Being really, really certain you know the main idea doesn’t mean you do”</a>⁠. <a href="https://gwern.net/doc/psychology/1990-zutell-literacytheoryandresearch39thnationalreadingconference.pdf" id="zutell-mccormick-1990" data-link-icon="pdf" data-link-icon-type="svg" title="‘<em>Literacy Theory and Research: Analyses from Multiple Paradigms. Proceedings of the Annual Meeting of the National Reading Conference (39th, AUstin, Texas, November 28–December 2, 1989)’, Zutell &amp; McCormick 1990"><em>National Reading Conference Yearbook</em>, 39</a>⁠, 249–256.</p>
            </blockquote>
            <p>I rose to the challenge.</p>
            <p><span>Standard checks.</span> Matuschak is indeed correct that this paper does not show up in any of the usual places, nor does ‘yearbook’ #9 seem to show up; this nut will not be cracked instantly. We do not see any encouraging hints if we google the citation (only a sporadic handful of later citations to it, which are sporadic enough to suggest that they too <a href="https://gwern.net/leprechaun#citogenesis-how-often-do-researchers-not-read-the-papers-they-cite" id="gwern-leprechaun-citogenesis-how-often-do-researchers-not-read-the-papers-they-cite" title="‘Leprechaun Hunting &amp; Citogenesis § Citogenesis: How Often Do Researchers Not Read The Papers They Cite?’, Gwern 2014">are citing papers they have not read</a> &amp; that this will be hard to find). University &amp; ProQuest databases turn up nothing for either.</p>
            <p>This begins to look anomalous, so I broadened the search in Google. Here I stumbled across several of the yearbooks hosted at what looks like the National Reading Conference’s website; a targeted <code>site:</code> search, alas, fails to turn up anything useful. They may have scanned some later yearbooks, but apparently not the 1989 one…? Unfortunately, a dead end.</p>
            <p><span>Barkless dogs.</span> So we turn to book sources, like used-book search engines. We can find many of these yearbooks used at reasonable prices, but <em>not</em> #39—not a trace of it! This is odd. Being the 39<sup>th</sup> yearbook, with the others often available, would imply that it is available too: such serial publications don’t usually vary that much from year to year—if the ones before &amp; after it are easy to get, it should be too. What one notices is that the titles don’t look anything like “<em>National Reading Conference Yearbook</em>, 39”: this citation must be wrong, that’s not how they were titled! With this in mind, we can search for a used copy to buy &amp; scan, but this would be premature to do: now we have explained the prior absence of hits, and need to redo our searches; we thought there was no scan online before, but we know that was misleading so it may exist after all.</p>
            <p><span>Alternate titles.</span> Knowing this, we can search more broadly in Google, and skimming search results, look what we find! The PDF snippet reveals that our quarry, “Proceedings of the Annual Meeting of The National Reading Conference (39<sup>th</sup>…)” has been hidden behind the long uncited title “<em>Literacy Theory and Research: Analyses from Multiple Paradigms</em>”. Well, no wonder you can’t find it normally, and also (disappointingly but unsurprisingly), no wonder everyone copies the same incorrect citation.</p>
            <figure>
              <img alt="Screenshot of key Google search hit, revealing the Academia.edu PDF copy of ERIC scan of National Reading Conference Yearbook #39." decoding="async" height="301" loading="lazy" src="https://gwern.net/doc/technology/google/2023-07-08-gwern-google-searchcasestudy-pressleyetal1990academiaeduhit.png" width="1227">
              
            </figure>
            <p><span>Alternate paths.</span> <span>Downloading it, <span><span title="et al">Pressley</span> <span>et al</span> <span>1989</span></span> turns out to be buried on pg256 of this PDF; now that we know what to look for, this book turns out to have been easily findable after all—we can readily find the original non-Academia.edu PDF on our old friend</span> <a href="https://en.wikipedia.org/wiki/Education_Resources_Information_Center" data-link-icon="wikipedia" data-link-icon-type="svg">ERIC</a><a href="#fn21" id="fnref21" role="doc-noteref"><sup>21</sup></a> and can find other yearbooks easily. We can also doublecheck other strategies: for example, if we had known the full names of the authors rather than the abbreviated ones in the citation, and we had googled something like “Michael Pressley, Elizabeth Ghatala, Jennifer Pirie, Vera E. Woloshyn”, that would have matched the indexed fulltext PDFs immediately. (Since you can often find the full names of authors even if the citation abbreviates them, this is a good tactic to know.)</p>
            <p>Thus, in this instance, it’s crucial to remember that citations can be inaccurate and one must try variations. Over-fixating on the book title can hamper efforts to locate the article, which was, in reality, merely a click away.</p>
          </section>
        </section>
        <section id="see-also">
          <h2><a href="#see-also" title="Link to section: § 'See Also'">See Also</a></h2>
          <div>
            <ul>
              <li>
                <a href="https://gwern.net/fulltext" id="gwern-fulltext" title="Jailbreak copies of these and I will pay you money.">My outstanding research paper /  book bounties</a>
              </li>
              <li>
                <a href="https://gwern.net/tank" id="gwern-tank" title="AI folklore tells a story about a neural network trained to detect tanks which instead learned to detect time of day; investigating, this probably never happened.">“The Neural Net Tank Urban Legend”</a>
              </li>
              <li>
                <a href="https://gwern.net/leprechaun" id="gwern-leprechaun" title="'Leprechaun Hunting &amp; Citogenesis', Branwen 2014">“Leprechaun hunting and historical context”</a>
              </li>
            </ul>
          </div>
        </section>
        <section id="external-links">
          <h2><a href="#external-links" title="Link to section: § 'External Links'">External Links</a></h2>
          <ul>
            <li>
              <a href="https://www.millionshort.com/">“Million Short”</a> (search engine overlay which removes top 100/​1k/​10k/​100k/​1m domains from hits, exposing obscurer sites which may be highly novel)
            </li>
            <li>Practice G search problems: <a href="https://web.archive.org/web/20140221080504/https://www.wired.com/geekdad/tag/a-google-a-day/" data-link-icon="alphabet" data-link-icon-type="svg">“A Google A Day”</a>⁠; <a href="https://gwern.net/doc/www/www.codespaces.com/5a3860e4bcce8a5dd82b5ae5ab7ccf8abaec643e.html" data-link-icon="alphabet" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://www.codespaces.com/power-searching-with-google.html" title="(Original URL: https://www.codespaces.com/power-searching-with-google.html )">Google Power Searching course</a> (OK for beginners but you may want to skip the videos in favor of the slides)
            </li>
            <li>
              <a href="https://www.lesswrong.com/posts/37sHjeisS9uJufi4u/scholarship-how-to-do-it-efficiently" data-link-icon="LW" data-link-icon-type="text">“Scholarship: How to Do It Efficiently”</a>
            </li>
            <li>
              <a href="https://www.drmaciver.com/2019/05/how-to-do-hard-things/">“How to do hard things”</a>
            </li>
            <li>
              <a href="https://xkcd.com/627/" data-link-icon="XKCD" data-link-icon-type="text,quad,sans">“Tech Support Cheat Sheet”</a>
            </li>
            <li>
              <a href="https://academia.stackexchange.com/questions/90318/do-repositories-of-translated-papers-exist/93209#93209" data-link-icon="stackexchange" data-link-icon-type="svg">“Do repositories of translated papers exist?”</a>
            </li>
            <li>
              <a href="https://gwern.net/doc/www/old.reddit.com/c15cf848ea8449716b62762738bbe5cd16ba50c2.html" data-link-icon="reddit" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://old.reddit.com/r/DataHoarder/" title="(Original URL: https://www.reddit.com/r/DataHoarder/ )"> / ​r / ​DataHoarder</a>⁠/ ​<a href="https://gwern.net/doc/www/old.reddit.com/ece168c0ec8756bd91bf377d211255fd692a04a5.html" data-link-icon="reddit" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://old.reddit.com/r/Piracy/" title="(Original URL: https://www.reddit.com/r/Piracy/ )"> / ​r / ​Piracy</a>
            </li>
            <li>Archive Team’s <a href="https://wiki.archiveteam.org/index.php?title=ArchiveBot" data-link-icon="internetarchive" data-link-icon-type="svg">Archive Bot</a>
            </li>
            <li>
              <a href="https://beepb00p.xyz/pkm-search.html" id="gerasimov-2019" data-link-icon="🤖" data-link-icon-type="text" title="'Building personal search infrastructure for your knowledge and code: Overview of search tools for desktop and mobile; using Emacs and Ripgrep as desktop search engine', Gerasimov 2019">“Building personal search infrastructure for your knowledge and code: Overview of search tools for desktop and mobile; using Emacs and Ripgrep as desktop search engine”</a>
            </li>
            <li>
              <a href="https://www.lesswrong.com/posts/d6yNW5T6J9rtnGizc/give-it-a-google" data-link-icon="alphabet" data-link-icon-type="svg">“Give it a google!”</a>
            </li>
            <li>
              <a href="https://www.lesswrong.com/posts/TCTtaFPqbMrQhttCD/five-routes-of-access-to-scientific-literature" data-link-icon="LW" data-link-icon-type="text">DeepDyve suggestion</a>
            </li>
            <li>
              <a href="https://blog.gingerbeardman.com/2023/05/24/ordering-photocopies-from-japans-national-library/">“Ordering photocopies from Japan’s National Library”</a>
            </li>
            <li>Discussion: <a href="https://en.wikipedia.org/wiki/Hacker_News" data-link-icon="wikipedia" data-link-icon-type="svg">HN</a>: <a href="https://gwern.net/doc/www/news.ycombinator.com/1825cf2969c723cbf78c03c2d1b7ac593e927f8c.html" data-link-icon="hn" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://news.ycombinator.com/item?id=18666574" title="(Original URL: https://news.ycombinator.com/item?id=18666574 )">1</a>⁠, <a href="https://gwern.net/doc/www/news.ycombinator.com/30721ae2ac80c788520ed537f405c797d8eac58b.html" data-link-icon="hn" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://news.ycombinator.com/item?id=26847596" title="(Original URL: https://news.ycombinator.com/item?id=26847596 )">2</a>⁠; <a href="https://gwern.net/doc/www/old.reddit.com/0d023966a0c138c7c6861c80a2054b9b3c114aa3.html" data-link-icon="SSC" data-link-icon-type="text,tri" rel="archived alternate nofollow" data-url-original="https://old.reddit.com/r/slatestarcodex/comments/a5ljk1/internet_search_tips_effective_use_of/" title="(Original URL: https://www.reddit.com/r/slatestarcodex/comments/a5ljk1/internet_search_tips_effective_use_of/ )">Reddit</a>⁠; <a href="https://www.lesswrong.com/posts/EF6YAq2aD5dt2sgeN/summary-internet-search-tips-by-gwern-branwen" data-link-icon="LW" data-link-icon-type="text">LW</a>
            </li>
          </ul>
        </section>
        <section id="appendix">
          <h2><a href="#appendix" title="Link to section: § 'Appendix'">Appendix</a></h2>
          <section id="searching-the-google-reader-archives">
            <h2><a href="#searching-the-google-reader-archives" title="Link to section: § 'Searching the Google Reader archives'">Searching the Google Reader Archives</a></h2>
            <div>
              <blockquote>
                <p>A tutorial on how to do manual searches of the 2013 <a href="https://en.wikipedia.org/wiki/Google_Reader" data-link-icon="wikipedia" data-link-icon-type="svg">Google Reader</a> archives on the <a href="https://en.wikipedia.org/wiki/Internet_Archive" data-link-icon="wikipedia" data-link-icon-type="svg">Internet Archive</a>⁠. Google Reader provides fulltext mirrors of many websites which are long gone and not otherwise available even in the IA; however, the Archive Team archives are extremely user-unfriendly and challenging to use even for programmers. I explain how to find &amp; extract specific websites.</p>
              </blockquote>
            </div>
            <p>A little-known way to ‘undelete’ a blog or website is to use Google Reader (GR). <span>Unusual archive: Google Reader.</span> GR crawled regularly almost all blogs’ RSS feeds; RSS feeds often contain the fulltext of articles. If a blog author writes an article, the fulltext is included in the RSS feed, GR downloads it, and then the author changes their mind and edits or deletes it, GR would redownload the new version but it would continue to show the version the old version as well (you would see two versions, chronologically). If the author blogged regularly and so GR had learned to check regularly, it could hypothetically grab different edited versions, even, not just ones with weeks or months in between. Assuming that GR did not, as it sometimes did for inscrutable reasons, stop displaying the historical archives and only showed the last 90 days or so to readers; I was never able to figure out why this happened or if indeed it really did happen and was not some sort of UI problem. Regardless, if all went well, this let you undelete an article, albeit perhaps with messed up formatting or something. Sadly, GR was closed back in 2013 and you cannot simply log in and look for blogs.</p>
            <p><span>Archive Team mirrored Google Reader.</span> However, before it was closed, <a href="https://wiki.archiveteam.org/index.php?title=Google_Reader" data-link-icon="internetarchive" data-link-icon-type="svg">Archive Team</a> launched a major effort to download as much of GR as possible. So in that dump, there may be archives of all of a random blog’s posts. Specifically: if a GR user subscribed to it; if Archive Team knew about it; if they requested it in time before closure; and if GR did keep full archives stretching back to the first posting.</p>
            <p><span>AT mirror is raw binary data.</span> Downside: the Archive Team dump is <em>not</em> in an easily browsed format, and merely figuring out what it <em>might</em> have is difficult. In fact, it’s so difficult that before researching Craig Wright in November–December 2015, I never had an urgent enough reason to figure out how to get anything out of it before, and I’m not sure I’ve ever seen anyone actually use it before; Archive Team takes the attitude that it’s better to preserve the data somehow and let posterity worry about <em>using</em> it. (There is a site which claimed to be a frontend to the dump but when I tried to use it, <a href="https://github.com/hubgit/archiveteam-reader-warc-extract/issues/1" data-link-icon="github" data-link-icon-type="svg">it was broken</a> &amp; still is in December 2018.)</p>
            
            <section id="results">
              <h3><a href="#results" title="Link to section: § 'Results'">Results</a></h3>
              <p><span>Success: raw HTML.</span> My <code>dd</code> extraction was successful, and the resulting HTML/​RSS could then be browsed with a command like <code>cat *.warc | fold --spaces -width=200 | less</code>. They can probably also be converted to a local form and browsed, although they won’t include any of the site assets like images or CSS/​JS, since the original RSS feed assumes you can load any references from the original website and didn’t do any kind of <a href="https://en.wikipedia.org/wiki/Data_URI_scheme" data-link-icon="wikipedia" data-link-icon-type="svg">data-URI</a> or mirroring (not, after all, having been intended for archive purposes in the first place…)</p>
            </section>
          </section>
        </section>
        <section role="doc-endnotes" id="footnotes">
          <hr>
          <ol>
            <li id="fn1" role="doc-endnote">
              <p>For example, the <code>info:</code> operator is entirely useless. The <code>link:</code> operator, in almost a decade of me trying it once in a great while, has never returned remotely as many links to my website as Google Webmaster Tools returns for inbound links, and seems to have been disabled entirely at some point.<a href="#fnref1" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn2" role="doc-endnote">
              <p>WP is increasingly out of date &amp; unrepresentative due to increasingly narrow policies about sourcing &amp; preprints, part of its overall <a href="https://gwern.net/inclusionism" id="gwern-inclusionism" title="'In Defense of Inclusionism', Branwen 2009">deletionist decay</a>⁠, so it’s not a good place to look for references. It is a good place to look for key terminology, though.<a href="#fnref2" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn3" role="doc-endnote">
              <p>When I was a kid, I knew I could just ask my reference librarian to request any book I wanted by providing the unique ID, the <a href="https://en.wikipedia.org/wiki/ISBN" data-link-icon="wikipedia" data-link-icon-type="svg">ISBN</a>⁠, and there was a physical copy of the book inside the Library of Congress; made sense. I never understood how I was supposed to get these “paper” things my popular science books or newspaper articles would sometimes cite—where <em>was</em> a paper, exactly? If it was published in <em>The Journal of Papers</em>, where did I get this journal? My library only had a few score magazine subscriptions, certainly not all of these <em>Science</em> and <em>Nature</em> and beyond. The bitter answer turns out to be: ‘nowhere’. There is no unique identifier (the majority of papers lack any DOI still), and there is no central repository nor anyone in charge—only a chaotic patchwork of individual libraries and defunct websites. Thus, books tend to be easy to get, but a paper can be a multi-decade odyssey taking one to the depths of the Internet Archive or purchasing from sketchy Chinese websites who hire pirates to infiltrate private databases.<a href="#fnref3" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn4" role="doc-endnote">
              <p>Most search engines will treat any space or separation as an implicit <code>AND</code>, but I find it helpful to be explicit about it to make sure I’m searching what I think I’m searching.<a href="#fnref4" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn5" role="doc-endnote">
              <p>This probably explains part of why no one cites that paper, and those who cite it clearly have not actually read it, even though it invented racial admixture analysis, which, since reinvented by others, has become a major method in medical genetics.<a href="#fnref5" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn6" role="doc-endnote">
              <p>University ILL privileges are one of the most underrated fringe benefits of being a student, if you do any kind of research or hobbyist reading—you can request almost anything you can find in <a href="https://en.wikipedia.org/wiki/WorldCat" data-link-icon="wikipedia" data-link-icon-type="svg">WorldCat</a>⁠, whether it’s an ultra-obscure book or a master’s thesis from 1950! Why <em>wouldn’t</em> you make regular use of it‽ Of things I miss from being a student, ILL is near the top.<a href="#fnref6" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn7" role="doc-endnote">
              <p>The complaint and indictment are not necessarily the same thing. An indictment frequently will leave out many details and confine itself to listing what the defendant is accused of. Complaints tend to be much richer in detail. However, sometimes there will be only one and not the other, perhaps because the more detailed complaint has been sealed (possibly precisely because it is more detailed).<a href="#fnref7" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn8" role="doc-endnote">
              <p>Trial testimony can run to hundreds of pages and blow through your remaining PACER budget, so one must be careful. In particular, testimony operates under an interesting &amp; <a href="https://slate.com/news-and-politics/2017/03/outrageous-trial-transcript-fees-are-bad-for-defendants-journalists-and-democracy.html" id="eisenberg-2017" data-link-icon="S" data-link-icon-type="text,sans" title="Public Record, Astronomical Price: Court reporters charge outrageous fees to reproduce trial transcripts. That's bad for defendants, journalists, and democracy.">controversial</a> <a href="https://en.wikipedia.org/wiki/Price_discrimination" data-link-icon="wikipedia" data-link-icon-type="svg">price discrimination</a> system related to how <a href="https://en.wikipedia.org/wiki/Court_reporter" data-link-icon="wikipedia" data-link-icon-type="svg">court stenographers</a> report—who are not necessarily paid employees but may be contractors or freelancers—intended to ensure covering transcription costs: the transcript initially may cost hundreds of dollars, intended to extract full value from those who need the trial transcript immediately, such as lawyers or journalists, but then a while later, PACER drops the price to something more reasonable. That is, the first “original” fee costs a fortune, but then “copy” fees are cheaper. So for <a href="https://www.uscourts.gov/services-forms/federal-court-reporting-program">the US federal court system</a>⁠, the “original”, when ordered within hours of the testimony, will cost &lt;$7.25/​page but then the second person ordering the same transcript pays only &lt;$1.20/​page &amp; everyone subsequently &lt;$0.90/​page, and as further time passes, that drops to &lt;$0.60 (and I believe after a few months, PACER will then charge only the standard $0.10). So, when it comes to trial transcript on PACER, patience pays off.<a href="#fnref8" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn9" role="doc-endnote">
              <p>I’ve heard that LexisNexis terminals are sometimes available for public use in places like federal libraries or courthouses, but I have never tried this myself.<a href="#fnref9" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn10" role="doc-endnote">
              <p>Curiously, in historical textual criticism of copied manuscripts, it’s the opposite: <a href="https://en.wikipedia.org/wiki/Lectio_brevior" data-link-icon="wikipedia" data-link-icon-type="svg">shorter = truer</a>⁠. But with memories or paraphrases, longer = truer, because those tend to elide details and mutate into catchier versions when the transmitter is not ostensibly exactly copying a text.<a href="#fnref10" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn11" role="doc-endnote">
              <p>The quick summary of DOIs is that they are “ISBNs but for research papers”; they are those odd slash-separated alphanumeric strings you see around, typically of a form like <code>10.000/abc.1234</code>. (Unlike ISBNs, the DOI standard is <em>very</em> loose, with about the only hard requirement being that there must be one <code>/</code> character in it, so almost any string is a DOI, even hateful ones like this genuine DOI: <code>10.1890/0012-9658(2001)082[1655:SVITDB]2.0.CO;2</code>.) Many papers have no DOI, or the DOI was assigned retroactively, but if they have a DOI, it can be the most reliable way to query any database for them.<a href="#fnref11" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn12" role="doc-endnote">
              <p>I advise prepending, like <code>https://sci-hub.st/https://journal.com</code> instead of appending, like <code>https://journal.com.sci-hub.st/</code> because the former is slightly easier to type but more importantly, Sci-Hub does not have SSL certificates set up properly (I assume they’re missing a wildcard) and so appending the Sci-Hub domain will fail to work in many web browsers due to HTTPS errors! However, if prepended, it’ll always work correctly.<a href="#fnref12" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn13" role="doc-endnote">
              <p>Academic publishers like to use the dark pattern of putting a little icon, labeled “full access” or “access” etc, where an Open Access indicator would go, knowing that if you are not intimately familiar with that publisher’s site design &amp; examining it carefully, you’ll be fooled. Another dark pattern is the unannounced temporary paper: in particular, the <a href="https://en.wikipedia.org/wiki/American_Psychological_Association" data-link-icon="wikipedia" data-link-icon-type="svg">APA</a>⁠, <a href="https://en.wikipedia.org/wiki/National_Bureau_of_Economic_Research" data-link-icon="wikipedia" data-link-icon-type="svg">NBER</a>⁠, &amp; <em>Cell</em> are fond of unpaywalling PDFs to exploit media coverage, and then unpredictably, silently, revoking access later and breaking links.<a href="#fnref13" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn14" role="doc-endnote">
              <p>To further illustrate this IA feature: if one was looking for Alex St.&nbsp;John’s entertaining memoir <a href="https://web.archive.org/web/20130227012620/http://www.alexstjohn.com/WP/2013/02/16/judgment-day-continued/" data-link-icon="internetarchive" data-link-icon-type="svg">“Judgment Day Continued…”</a>⁠, a 2013 account of organizing the wild <a href="https://doomwiki.org/wiki/Judgment_Day">1996 <em>Doom</em> tournament</a> thrown by Microsoft, but one didn’t have the URL handy, one could search the entire domain by going to <code>https://web.archive.org/web/*/http://www.alexstjohn.com/*</code> and using the filter with “judgment”, or if one at least remembered it was in 2013, one could narrow it down further to <code>https://web.archive.org/web/*/http://www.alexstjohn.com/WP/2013/*</code> and then filter or search by hand.<a href="#fnref14" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn15" role="doc-endnote">
              <p>If any Blogspot employee is reading this, <em>for god’s sake stop this insanity</em>!<a href="#fnref15" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn16" role="doc-endnote">
              <p>Uploading is not as hard as it may seem. <a href="https://library.bz/main/upload/" data-link-icon="raven" data-link-icon-type="svg">There is a web interface</a> (user/​password: “genesis”/​“upload”). Uploading large files can fail, so I usually use the FTP server: <code>curl -T "$FILE" ftp://anonymous@ftp.libgen.is/upload/</code>. <a href="#fnref16" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn17" role="doc-endnote">
              <p>Although flatbed scanning is sometimes destructive too—I’ve cracked the spine of books while pressing them flat into a flatbed scanner.<a href="#fnref17" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn18" role="doc-endnote">
              <p>My workaround is to export from gscan2pdf as DjVu, which avoids the bug, then convert the DjVu files with <code>ddjvu -format=pdf</code>; this strips any OCR, so I add OCR with <a href="https://github.com/ocrmypdf/OCRmyPDF" data-link-icon="github" data-link-icon-type="svg"><code>ocrmypdf</code></a> and metadata with <code>exiftool</code>.<a href="#fnref18" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn19" role="doc-endnote">
              <p>One exception is Google Docs: one can append <code>/mobilebasic</code> to (as of 2023-01-04) get a simplified HTML view which can be archived. For example, <a href="https://web.archive.org/web/20230104213430/https://docs.google.com/document/d/1oIlLt1uqutTP8725wezfZ2mjc-IPfOFCdc6hlRIb-KM/mobilebasic" data-link-icon="alphabet" data-link-icon-type="svg" title="BerSevenTimes, 2022-11-21">“A Comprehensive Guide to Dakimakuras as a Hobby”</a> is available only as a Google Docs page but the URL <code>https://docs.google.com/document/d/1oIlLt1uqutTP8725wezfZ2mjc-IPfOFCdc6hlRIb-KM/mobilebasic</code> will work with the Internet Archive.<a href="#fnref19" role="doc-backlink">↩︎</a></p>
            </li>
            <li id="fn20" role="doc-endnote">
              <p><a href="http://www.catb.org/jargon/html/koans.html" data-link-icon="ESR" data-link-icon-type="text,tri,sans" title="Some AI Koans">“Tom Knight and the Lisp Machine”</a> (from the <a href="https://en.wikipedia.org/wiki/Jargon_File" data-link-icon="wikipedia" data-link-icon-type="svg">Jargon File</a>):</p>
              <blockquote>
                <p>A novice was trying to fix a broken <a href="https://en.wikipedia.org/wiki/Lisp_machine" data-link-icon="wikipedia" data-link-icon-type="svg">Lisp machine</a> by turning the power off and on.</p>
                <p><a href="https://en.wikipedia.org/wiki/Tom_Knight_(scientist)" data-link-icon="wikipedia" data-link-icon-type="svg">Knight</a>⁠, seeing what the student was doing, spoke sternly: “You cannot fix a machine by just power-cycling it with no understanding of what is going wrong.”</p>
                <p>Knight turned the machine off and on.</p>
              </blockquote><a href="#fnref20" role="doc-backlink">↩︎</a>
            </li>
            <li id="fn21" role="doc-endnote">
              <p>ERIC is one of the good websites for fulltext &amp; scans. It’s always a harbor in the storms of the Internet, with irreplaceable scans, especially of older gray literature like pre-WWW government publications or preprints.<a href="#fnref21" role="doc-backlink">↩︎</a></p>
            </li>
          </ol>
        </section>
        <section id="backlinks-section">
          <h2><a href="#backlinks-section" title="Link to section: § 'Further Reading'">Further Reading</a></h2><a id="backlinks" href="https://gwern.net/metadata/annotation/backlink/%252Fsearch.html" title="Reverse citations/backlinks for this page (the list of other pages which link to this page).">[Backlinks]</a>
        </section>
        <section id="link-bibliography-section">
          <h2><a href="#link-bibliography-section" title="Link to section: § 'Link Bibliography'">Link Bibliography</a></h2><a id="link-bibliography" href="https://gwern.net/metadata/annotation/link-bibliography/%252Fsearch.html" title="Bibliography of links cited in this page (forward citations). Lazily-transcluded version at footer of page for easier scrolling.">[Link bibliography]</a>
        </section>
        <section id="similars-section">
          <h2><a href="#similars-section" title="Link to section: § 'Similar Links'">Similar Links</a></h2><a id="similars" href="https://gwern.net/metadata/annotation/similar/%252Fsearch.html" title="Similar links for this link (by text embedding). Lazily-transcluded version at footer of page for easier scrolling.">[Similars]</a>
        </section>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FBI improperly used 702 surveillance powers on US senator (313 pts)]]></title>
            <link>https://thehill.com/homenews/administration/4110850-fbi-improperly-used-702-surveillance-powers-on-us-senator/</link>
            <guid>36822654</guid>
            <pubDate>Sat, 22 Jul 2023 02:39:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thehill.com/homenews/administration/4110850-fbi-improperly-used-702-surveillance-powers-on-us-senator/">https://thehill.com/homenews/administration/4110850-fbi-improperly-used-702-surveillance-powers-on-us-senator/</a>, See on <a href="https://news.ycombinator.com/item?id=36822654">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	
<p>The FBI improperly used surveillance powers to conduct searches for information on a U.S. senator, a state lawmaker and a state judge, according to court records released Friday as part of a public records request.&nbsp;</p>



<p>The FBI’s improper use of Section 702 of the Foreign Intelligence Surveillance Act was documented in an opinion from the Foreign Intelligence Surveillance Court (FISC) and is sure to pose challenges for an intelligence community lobbying for the reauthorization for what it sees as one of its most vital tools.</p>





<p>The tool – which allowed for warrantless spying on foreigners located abroad – has long been criticized as a backdoor tool for gaining information on Americans who may be communicating with those being surveilled.</p>



<p>And critics complain the information gathered by the agency through 702 is too easily tapped for investigations with no foreign nexus.</p>



<p>The surveillance court outlined three examples of instances where FBI personnel conducted searches of “sensitive query terms,” like those of U.S. public officials or candidates, without first seeking approval from the FBI’s deputy director.</p>



<p>“In June 2022, an analyst conducted four queries of Section 702 information using the last names of a U.S. Senator and a state senator, without further limitation,” the opinion states.&nbsp;</p>



<p>While the two were believed to be targets of “a specific foreign intelligence service,” the National Security Division at the Department of Justice determined the FBI did not meet the needed standard for running such a query.&nbsp;</p>



<p>And in October of that year, “a Staff Operations Specialist ran a query using the Social Security number of a state judge who “had complained to [the] FBI about alleged civil right violations perpetrated by a municipal chief of police.”</p>





<p>The opinion does not make clear the identity of those searched.</p>



<p>The American Civil Liberties Union (ACLU), whose efforts prompted the release of the court opinion, highlighted other alarming patterns.</p>



<p>“These disturbing new revelations show how Section 702 surveillance, a spy program the government claims is focused on foreign adversaries, is routinely used against Americans, immigrants, and people who are not accused of any wrongdoing,” Patrick Toomey, deputy director of the ACLU’s National Security Project, said in a statement.</p>





<p>“The FBI continues to break the rules put in place to protect Americans, running illegal searches on public officials including a U.S. senator, and it’s long past time for Congress to step in. As Congress debates reauthorizing Section 702, these opinions make clear why fundamental reforms are urgently needed.”</p>



<p>The FBI and Justice Department in recent weeks have noted the roll out of some FISA reforms – pointing to a&nbsp;<a href="https://thehill.com/policy/national-security/3978746-fisa-702-searches-foreign-nationals-rise-citizen-queries-drop/" target="_blank" rel="noreferrer noopener">drop in overall queries</a>&nbsp;that involved U.S. citizens.</p>



<p>The opinion, originally filed in April, does comment on improvements from the bureau.</p>





<p>“Despite the reported errors, there is reason to believe that the FBI has been doing a better job in applying the querying standard,” Judge Rudolph Contreras writes in the opinion.</p>



<p>“In some cases, F.B.I. personnel apparently misapplied the querying standard to a group of similarly situated persons, but those violations do not approach the scale of a number of prior ones.”</p>



<p>The FBI stressed that detail in its response to the opinion’s release.</p>





<p>“The 2023 FISC Opinion confirms the significant improvement in the FBI’s Section 702 querying compliance since the implementation of our substantial reforms,” FBI Director Christopher Wray said in a statement.&nbsp;</p>



<p>“Section 702 is critical in our fight against foreign adversaries. We take seriously our role in protecting national security and we take just as seriously our responsibility to be good stewards of our Section 702 authorities. Compliance is an ongoing endeavor, and we recently announced new additional accountability measures. We will continue to focus on using our Section 702 authorities to protect American lives and keeping our Homeland safe, while safeguarding civil rights and liberties.”</p>



<p>It’s not the first time a lawmaker has been improperly searched via FISA 702, with Rep. Darin LaHood (R-Ill.) saying in March that his name was searched using the tool.</p>





<p>Section 702 is set to expire at the end of the year, and lawmakers on both sides of the aisle have said they will refuse to back its reauthorization without significant reforms.</p>



<p>The FBI on Friday sent a letter to House and Senate leaders noting that several different reviews found agents have complied with FISA guidelines at least 98 percent of the time.</p>



<p>But in a call with reporters Friday, a senior FBI official said the agency is working on building trust with lawmakers who may feel personally impacted by the issue.</p>





<p>“We are communicating as much as we can to build that level of confidence so that they understand how we are using the tool and how we are holding people accountable for when they are not using the tool correctly. But also to make sure they understand when we do and do not do such things as query members of Congress,” the official said in response to a question from The Hill.</p>



<p>“There was an unacceptably high level of non compliance and various non compliance queering behavior that was going on,” the official added.&nbsp;</p>



<p>“We’ve been very open about [how] we accepted the fact that that was unacceptable. That’s not what we expect from ourselves as an organization.”&nbsp;</p>







<p>Sen. Ron Wyden (D-Ore.), however, said lawmakers are not assured that intelligence agencies are being fully forthcoming about how they use FISA.</p>



<p>“For years, as government officials have provided misleadingly narrow testimony about who is targeted under Section 702, I have pushed to get the government to come clean.&nbsp; The revelation that 702 is used against ‘foreign governments and related entities’ directly impacts Americans’ privacy, as American journalists, businesspeople, students and others all have legitimate reason to communicate with foreign governments,” Wyden said in a statement.</p>



<p>“The fact they can be swept up in 702 collection further highlights the need for reforms to protect their privacy.”</p>

</div><p>Copyright 2023 Nexstar Media Inc. All rights reserved. This material may not be published, broadcast, rewritten, or redistributed.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Using Prolog in Windows NT Network Configuration (1996) (115 pts)]]></title>
            <link>https://web.archive.org/web/20030218034509/http://www.research.microsoft.com/research/dtg/davidhov/pap.htm</link>
            <guid>36821871</guid>
            <pubDate>Sat, 22 Jul 2023 00:24:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://web.archive.org/web/20030218034509/http://www.research.microsoft.com/research/dtg/davidhov/pap.htm">https://web.archive.org/web/20030218034509/http://www.research.microsoft.com/research/dtg/davidhov/pap.htm</a>, See on <a href="https://news.ycombinator.com/item?id=36821871">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Employees Bid on Anchor Brewery (171 pts)]]></title>
            <link>https://vinepair.com/booze-news/anchor-employees-brewery-takeover-bid/</link>
            <guid>36821861</guid>
            <pubDate>Sat, 22 Jul 2023 00:23:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vinepair.com/booze-news/anchor-employees-brewery-takeover-bid/">https://vinepair.com/booze-news/anchor-employees-brewery-takeover-bid/</a>, See on <a href="https://news.ycombinator.com/item?id=36821861">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
		<p><em>This is a developing story, check back for updates.</em></p>
<p>At a meeting last Wednesday at Anchor Brewing Co., executives told brewery employees that the historic San Francisco firm would be shut down after over a century and a half in business. One week later, employees have something to tell the executives: if you’ll sell us Anchor, we’ll figure out a way to buy it.</p>
<p>In a brief letter sent Wednesday evening and shared with VinePair, the business agent for Anchor Brewing Union advised Sapporo USA president Mike Minami “that workers of Anchor Brewing have met, discussed, and decided to launch an effort to purchase the brewery and run it as a worker co-op.”</p>
<p>“We are not asking for a handout or charity,” wrote Pedro de Sá, a business agent at International Longshore and Warehouse Union Local 6, which represents roughly 40 workers at the brewery. “All we want is a fair shot at being able to continue to do our jobs, make the beer we love, and keep this historic institution open. We do not want the brewery and brand we love to be sold off before we even had a chance.”</p>
<p>de Sá, speaking on behalf of union workers who voted earlier in the day to take this step, asked Minami to respond by the end of the day on Friday, July 21 indicating whether Sapporo USA was open to working “cooperatively and transparently through this process” with the union, specifically with regards to “creat[ing] the framework and rais[ing] the funds necessary for this purchase.”</p>
<p>Patrick Machel, a production worker at the brewery and a shop steward for the Anchor Brewing Union, says that the vast majority of the union’s rank-and-file workers, as well as an unspecified number of managers, support the longshot effort. “Most of us that work here were born and raised here. We work here because we love it, we grew up with Steam Beer,” he tells VinePair. Now, they’ll try to save Anchor from the scrap heap.</p>
<p>VinePair first <a href="https://vinepair.com/booze-news/anchor-brewing-company-sale/">reported</a> that Sapporo USA was on the verge of selling or shuttering Anchor on the evening of July 11. Less than 12 hours after our initial report, Sam Singer, a representative for Anchor and Sapporo USA, issued a press release announcing the brewery would “cease operations and liquidate the business following a combination of challenging economic factors and declining sales.” (The release did not mention Sapporo USA, but current and former workers were quick to tell <a href="https://vinepair.com/articles/sapporo-usa-anchor-brewing-liquidation-analysis/">VinePair’s Hop Take column</a> that the parent company mismanaged the brewery into dysfunction.)</p>
<p>As word spread of Anchor’s imminent closure last week, San Franciscans <a href="https://www.sfgate.com/food/article/anchor-brewing-final-beers-flying-off-shelves-sf-18199789.php">flocked</a> to the unmistakable Art Deco plant on Potrero Hill to pay their respects to the brewery that has kept the City by The Bay stocked with steam beer since 1871. Lines at the neighboring Anchor Public Taps stretched around the block as people clamored to buy whatever beer was left in the tanks.</p>
<p>What would happen to Anchor? In a year of searching, the company’s release claims, no buyer had emerged to acquire it whole, as a going concern. (The release does not state the price Sapporo USA was asking for the firm; it acquired Anchor six years ago in a provisional $85 million deal.) Last week, Narragansett Beer <a href="https://vinepair.com/booze-news/narragansett-beer-petition-anchor-brewing/">circulated</a> a petition to drum up support for rescuing the brewery, and several private-equity investors, perhaps impressed by the outpouring of local love for the august old brand, expressed interest to this reporter about acquiring it.</p>
<p>This past weekend, a handful of San Francisco entrepreneur types <a href="https://www.sfchronicle.com/food/wine/article/save-anchor-steam-18199818.php">described</a> to the hometown paper their plans for resurrecting Anchor; the ideas included a website to tease future crowdfunding opportunities, and a reality show about bringing the idiosyncratic brewery back to life working-titled “How hard could it be.” But the plan outlined last week in the release still stands: to turn Anchor over to an assignee for the benefit of creditors (A.B.C.), a third-party manager tasked with the orderly wind-down and sale of the business and its assets to whoever would buy them, and for whatever purpose.</p>
<p>Workers want to preempt Anchor’s real estate, equipment, and intellectual property being sold off piecemeal to the highest bidders by acquiring it from Sapporo USA and running it as a co-op, says Machel.</p>
<p>“We couldn’t go down without some way of fighting for ourselves and the community we love.”</p>
<p><em><strong>This story is a part of <a href="https://vinepair.com/business-of-drinks/">VP Pro</a>, our free content platform and newsletter for the drinks industry, covering wine, beer, and liquor — and beyond. <a href="https://vinepair.com/vp-pro-join/">Sign up for VP Pro now!</a></strong></em></p>		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hollywood is on strike because CEOs fell for Silicon Valley’s magical thinking (144 pts)]]></title>
            <link>https://www.latimes.com/business/technology/story/2023-07-21/column-hollywood-sag-aftra-strike-strike-silicon-valleys-magical-thinking</link>
            <guid>36821347</guid>
            <pubDate>Fri, 21 Jul 2023 23:19:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.latimes.com/business/technology/story/2023-07-21/column-hollywood-sag-aftra-strike-strike-silicon-valleys-magical-thinking">https://www.latimes.com/business/technology/story/2023-07-21/column-hollywood-sag-aftra-strike-strike-silicon-valleys-magical-thinking</a>, See on <a href="https://news.ycombinator.com/item?id=36821347">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-element="story-body" data-subscriber-content=""> <p>In one respect, the <a href="https://www.latimes.com/entertainment-arts/business/story/2023-07-16/sag-aftra-strike-actors-writers-strike-hollywood-production-film-tv-disruption-fall-season"><u>actors and writers of Hollywood</u></a> uniting on the picket lines in <a href="https://www.latimes.com/entertainment-arts/business/story/2023-07-14/actors-strike-sag-aftra-joins-writers-guild-picket-lines"><u>a historic, industry-shaking strike</u></a> is a tale as old as time: one of workers fighting bosses for better pay. Yet the reason this battle is shaping up to be so uniquely intractable and momentous — as you might have gathered from all the headlines about  artificial intelligence and streaming economics — is very much of our moment.</p><p>But it’s not, ultimately, technology that’s at the root of the problem. It’s that the studio executives both new and old have embraced the powerful — and ultimately disastrous — magical thinking pumped out by Silicon Valley for the last  10 years.</p><p>Studio heads are touting the disruptive properties of digital streaming, the transformative power of AI, a brave, unpredictable new world for entertainment writ large — and how writers and actors must adapt to this new future. But just as it did when it was issuing from the tech sector during the 2010s, this talk too often amounts to a smokescreen that lets executives and investors line their pockets and risks leaving workers holding the bag.</p><p>“These companies blew up a successful business model that the public enjoyed,  that was immensely profitable,  and they replaced it with a mishmash that we have now,” Adam Conover, the star of “Adam Ruins Everything”<i> </i>and a  negotiating committee member of the Writers Guild of America, tells me. “And now, they’re refusing to update the contract to reflect those changes.”</p><p>We’ve heard a lot about the ways that studios want to reserve the right to use AI — to create endlessly usable digital replicas of actors, to generate scripts that writers <a href="https://www.latimes.com/business/technology/story/2023-05-11/column-the-writers-strike-is-only-the-beginning-a-rebellion-against-ai-is-underway"><u>will be paid lower rates to fix up</u></a>. We’ve also heard about the new economic picture ushered in by streaming, about an industry in the throes of change, and the necessity of belt-tightening as a result. </p><p>We’ve heard Disney Chief Executive Bob Iger saying the  demand by the Screen Actors Guild for fair payment in the new digital landscape “isn’t realistic,” and heard how Netflix saw declining user sign-ups and stock prices last year. Yet  Iger reportedly makes <a href="https://www.rollingstone.com/tv-movies/tv-movie-features/disney-staffers-angry-ceo-bob-iger-actors-strike-writers-strike-1234789713/" target="_blank"><u>$27 million a year</u></a>, while Netflix <a href="https://www.wsj.com/articles/netflix-nflx-q2-earnings-report-2023-92a620c8" target="_blank"><u>just raked in $1.5 billion in net profit in the last quarter</u></a>.</p><p>So what’s really going on? And how did we get here?</p><p>First, we need to understand why the 2010s may well come to be remembered as the great decade of magical thinking for Silicon Valley. Drunk on a truly transformational first decade of the 21st century — one that saw Google, Amazon, the iPhone and social media storm the world stage — flush tech investors turned their sights toward the next generation of startups, eager to see them do the same.</p><p>The formula for seeking out that next multibillion-dollar “unicorn,” in hindsight, was pretty simple: The next wave of startups had to promise that it would disrupt a stale industry with a newer, high-tech, app-driven alternative, promise the potential for vast scale and promise that it could do so fast. So we saw the rise of Uber and Lyft, each of which vowed to revolutionize transit, and we got the likes of WeWork, which set out to usher in the future of co-working, and Theranos, which would do the same for at-home blood testing.</p><p>We know how it ended. Uber and Lyft have never been sustainably profitable, WeWork collapsed dramatically when it became clear that it was merely a wildly over-leveraged real estate company, and Theranos’ futuristic medical technology was outright fraudulent. </p><p>Unlike many of the 21st century’s first-wave tech companies and products, which found both markets and roads to profitability, these were pipe dreams, propped up by a fire hose of investment cash, big-talking founders and the very real — and at the time, quite understandable! — sense that Silicon Valley was the place that determined how the future was made.</p><p>As the 2010s began, Netflix sat somewhere between the old guard and the new. It introduced online streaming in 2007, and had a real product with real demand, as well as an established business in its DVD-by-mail rental service. Yet its ambitions were hypercharged by a newfangled sense that it could disrupt the old school Hollywood industry and scale endlessly — there was no reason everyone in the world with access to a screen couldn’t subscribe.</p><p><a href="https://www.reuters.com/article/us-netflix-stock/netflix-shares-soar-after-icahn-reports-10-percent-stake-purchase-idUSBRE89U1GA20121101" target="_blank"><u>Big-name investors</u></a> sank hundreds of millions into Netflix’s new vision. As it began producing original content in 2013, it applied a distinctly next-wave Silicon Valley ethos. It would make massive upfront investments, bankrolling huge productions such as the David Fincher-helmed, Kevin Spacey-starring “House of Cards,” elbowing its way into the prestige TV pack, promising not only to compete but also to do it better: It would offer all the episodes at once, on demand, and viewers could consume them whenever and however they wanted. Cable would become obsolete. The future was cutting the cord.</p><p>As with Uber and Lyft, whose bottomless chests of venture capital allowed them to conquer new markets once dominated by stodgy old competitors — in their case, the taxi cartels and livery cab companies — price was no object.</p><p>Right out the gate, episodes for original Netflix shows such as “House of Cards” and “Orange Is the New Black”<i> </i>cost $4 million a pop. (So did episodes of shows that few remember today, such as “Hemlock Grove.”) The spending was profligate — it soon rose to rates of <a href="https://www.indiewire.com/features/general/netflix-originals-budget-15-billion-1202036683/" target="_blank"><u>$15 billion a year</u></a> on new content — but as it did for the magical valley startups, the strategy “worked.”</p><p>“What happens is Netflix becomes the Wall Street darling, and all these other companies,” like Amazon, Disney, Apple, HBO, Paramount and NBC, “race to adopt Netflix’s business model,” Conover says. </p><p>Herein lies the trouble. Amid this boom, which for a few years ushered in a gold rush for writers and talent, Netflix et al. adopted another key ingredient of Silicon Valley’s approach: secrecy. Data about shows’ performance and viewer habits were kept proprietary; we  knew only what the streamers wanted us to know. That went for customers, performers, writers and for investors. Streaming is an inscrutable black box, about which so many stories might be told.</p><p>It’s a sticking point in the negotiations — actors and writers on streaming series want a better way to calculate the value of their work, given that the residuals they earn are so much lower than for network or cable shows. The studios have resisted. “The reason nobody really wants to open the books on this is because if Wall Street got a look,” one Hollywood insider <a href="https://www.vulture.com/2023/06/streaming-industry-netflix-max-disney-hulu-apple-tv-prime-video-peacock-paramount.html" target="_blank"><u>told New York Magazine</u></a>, “they’d have a collective stroke.”</p><p>What we’re seeing now is the fantastical thinking that Netflix and its followers could continue endless expansion running up against the physics of the real world — there are now 238 million Netflix subscribers, but those numbers <a href="https://www.latimes.com/entertainment-arts/business/story/2022-04-19/lat-et-ct-netflix-loses-subscriber-first-quarter">dropped for the first time</a> last year, and the company had to claw them back by nibbling at the corners, <a href="https://www.latimes.com/entertainment-arts/business/story/2021-03-11/netflix-password-sharing-policing">cutting off password sharing</a> and launching new, cheaper tiers that run ads.</p><p>The boom times are over. Executives know it. Wall Street knows it. And the story that we’re in a revolutionary moment of technological transformation will run out of gas soon. So the bosses are using that moment to do what Silicon Valley wound up doing when its other big swings didn’t pan out: squeeze labor. </p><p>Just as Uber and Lyft, which promised drivers rich rewards and flexible fares, started reducing rates and making it harder to earn those rewards, Netflix and the streaming cohort cut in its mold are now trying to square their promises of world conquest by slashing worker pay under the fog of magical thinking.</p><p>It’s been noted, and correctly so, that entertainment industry labor disputes often erupt when there’s a change in technology — from theaters screening projected films to the cathode ray tube of the home television, say, or the rise of YouTube and other online content in the 2000s  — and that happens for a reason. Historically, executives and management use a disorienting new technology to try to justify lowering wages of their workers, and they have done so since the days of the Industrial Revolution. </p><p>“The old CEOs knew they had to work with the unions, bargain with us,” Conover says. “The new ones don’t. So part of the point of the strike is us as labor showing the tech CEOs that no, you actually do have to deal fairly with the unions.”</p><p>Conover notes that it’s jarring to see the streamers plead poverty as an excuse not to negotiate with talent in good faith, given that show budgets and profits have both gone up. </p><p>“Netflix lied to the public and Wall Street,” he says, telling them, “‘you can watch every show ever made in perpetuity, with no ads, for $15.99 a month forever.’ That’s like Movie Pass” (the much-hyped app that allowed users to see unlimited movies for a monthly fee, before quickly going bankrupt). “That’s ludicrous.” </p><p>Ludicrous if you want to pay the people who actually create those shows for you, anyway.</p><p>What Netflix and the streamers are trying to do now is seal in a new standard under which writers and actors are treated in much the way that Uber and the gig app companies treat their independent contractor drivers. </p><p>“Uber is a perfect example,” Conover says. “Its drivers need to supply their own cars, their own gas, their own insurance and so on.” The drivers are on their own, with few to no benefits or protections, and are expected to maximize profits for the company. “And Netflix is trying to do the same thing.”</p><p>Unlike Uber, Netflix really <i>is </i>quite profitable. But in order to sustain the mythical levels of growth it has promised investors, it is turning to similar tactics — cutting workers’ hours, making work more precarious and unpredictable and reducing pay. It’s a far cry from the sleek, automated futures promised by the studio executives.</p><p>As with the biggest companies of Silicon Valley’s magical thinking era, it’s often hard to parse whether the ones touting the game-changing technologies themselves even believe in these visions — do studio execs really think consumers want to watch a parade of digital replicas of their favorite actors parroting lines from an AI-generated script? Or are they simply aware that the mere threat of such a future gives them leverage and power over the workers of today?</p><p>In the end, the answer is immaterial. Silicon Valley’s invasion of Hollywood brought with it science fictional notions of growth for the industry, a penchant for secrecy and unaccountability and the expectation that it could get away with treating workers like robots or invisible code. We’re seeing what happens when those notions meet, for one of the first times, with a powerful, organized resistance.</p><p>Personally, I’m hoping this one gets a Hollywood ending — and not the ending so many Silicon Valley startups got over the last 10 years.</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NativePHP: A framework for building desktop apps using PHP (155 pts)]]></title>
            <link>https://nativephp.com/docs/1/getting-started/introduction</link>
            <guid>36820555</guid>
            <pubDate>Fri, 21 Jul 2023 22:06:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nativephp.com/docs/1/getting-started/introduction">https://nativephp.com/docs/1/getting-started/introduction</a>, See on <a href="https://news.ycombinator.com/item?id=36820555">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><span>⚠️</span>
                    <span>
                        NativePHP is currently an <em>alpha</em> release and is not ready for production applications
                        yet.
                    </span>
                </p><div>
                    <h2 id="hello-nativephp"><a href="#hello-nativephp"><p>#</p></a>Hello, NativePHP!</h2>
<p>NativePHP is a new framework for rapidly building rich, native desktop applications using PHP. If you're already a PHP
developer, you'll feel right at home. If you're new to PHP, we think you'll find NativePHP easy to pick up and use.
Whatever your path, we think you're going to be productive quickly.</p>
<p>NativePHP is taking the world by storm, enabling PHP developers to create true cross-platform, native apps
using the tools and technologies they already know: HTML, CSS, Javascript, and, of course, PHP.</p>
<p>And they said PHP was dead.</p>
<h2 id="what-exactly-is-nativephp"><a href="#what-exactly-is-nativephp"><p>#</p></a>What exactly is NativePHP?</h2>
<p>Strictly speaking, NativePHP is a combination of elements:</p>
<ol>
<li>A collection of easy-to-use classes - abstractions - to enable you to interact with a variety of host operating
system features.</li>
<li>A set of tools to enable building and bundling your native application using either the Electron or Tauri browser
environment.</li>
<li>A static PHP runtime that allows your app to run on any user's system with zero effort on their part.</li>
</ol>
<h2 id="what-nativephp-isnt"><a href="#what-nativephp-isnt"><p>#</p></a>What NativePHP isn't</h2>
<p>NativePHP is not an especially opinionated way to build native apps. Right now, we only support a Laravel driver, but
we're already working on making it work whatever framework you're using - and even if you're not using a framework at
all.</p>
<p>NativePHP is not a GUI framework. We don't want to tell you how to build your app. You can choose whatever UI toolset
makes you and your team feel most productive.</p>
<p>Building a React front-end? No problem. Vue? Sure. Livewire or Inertia? Doesn't matter! Plain old HTML and CSS?
You got it. Tailwind? Bootstrap? Material UI? Whatever you want.</p>
<p>NativePHP is not some new custom fork of PHP. This is the good old PHP you know and love.</p>
<h2 id="whats-in-the-box"><a href="#whats-in-the-box"><p>#</p></a>What's in the box?</h2>
<p>NativePHP comes with a bunch of useful features out of the box, including:</p>
<ul>
<li>Window management</li>
<li>Menu management</li>
<li>File management</li>
<li>Database support (SQLite)</li>
<li>Native notifications</li>
</ul>
<p>All of this and more is explored in the rest of these docs.</p>
<h2 id="what-can-i-build-with-nativephp"><a href="#what-can-i-build-with-nativephp"><p>#</p></a>What can I build with NativePHP?</h2>
<p>Honestly, anything you want. We believe NativePHP is going to empower thousands of developers to build all kinds of
applications. The only limit is your imagination.</p>
<p>You could build a menubar app that lets you manage your cron jobs, or a cool new launcher app, or a screen recorder
that puts cowboy hats on every smiley-face emoji it sees.</p>
<p>(You should totally build that last one.)</p>
<h2 id="whats-next"><a href="#whats-next"><p>#</p></a>What's next?</h2>
<p>Go read the docs! We've tried to make them as comprehensive as possible, but if you find something missing, please
feel free to <a href="https://github.com/nativephp/nativephp.com">contribute</a>.</p>
<p>This site and all the NativePHP are open source and available on <a href="https://github.com/nativephp">GitHub</a>.</p>
<p>Ready to jump in? <a href="https://nativephp.com/docs/1/getting-started/installation">Let's get started</a>.</p>
<h2 id="credits"><a href="#credits"><p>#</p></a>Credits</h2>
<p>NativePHP wouldn't be possible without the following projects and the hard work of all of their wonderful contributors:</p>
<ul>
<li>
<a href="https://php.net/">PHP</a>
</li>
<li>
<a href="https://electronjs.org/">Electron</a>
</li>
<li>
<a href="https://tauri.studio/">Tauri</a>
</li>
<li>
<a href="https://laravel.com/">Laravel</a>
</li>
<li>
<a href="https://symfony.com/">Symfony</a>
</li>
<li>
<a href="https://github.com/crazywhalecc/static-php-cli/">Static PHP CLI</a>
</li>
</ul>
<p>NativePHP is a copyright of and maintained by <a href="https://twitter.com/marcelpociot">Marcel Pociot</a> and
<a href="https://twitter.com/simonhamp">Simon Hamp</a>.</p>

                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Managing Kitchen Fruit Flies with a Little Shop of Horrors (330 pts)]]></title>
            <link>https://blog.zaccohn.com/Fruitflies-and-the-Little-Shop-of-Horrors/</link>
            <guid>36820469</guid>
            <pubDate>Fri, 21 Jul 2023 21:58:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.zaccohn.com/Fruitflies-and-the-Little-Shop-of-Horrors/">https://blog.zaccohn.com/Fruitflies-and-the-Little-Shop-of-Horrors/</a>, See on <a href="https://news.ycombinator.com/item?id=36820469">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p><img src="https://blog.zaccohn.com/images/blog_pitcherplants.jpeg" alt=""></p>

<p>I live in Seattle on a fairly wooded property. Every summer since we’ve moved here, we end up with <em>swarms</em> of fruit flies in the kitchen. They congregate around the compost bin and the fruit bowl (where there are always lots of bananas). We aren’t slobbish - I do the dishes and wipe down the counters every night, take the compost out and wash the bin 2-3x a week. Keeping everything washed and clean helps, but the fruit flies still build up over time. And if there’s even the slightest deviation from the cleaning schedule, within 2-3 days the fruit flies have built up exponentially and there are 50-100 of them swarming around.</p>

<p>Our previous remedy, iterated on and honed over years, was to leave a few traps out. We found what worked best was a short, wide brimmed glass (or tuppaware container) with a little bit of wine, a splash of apple cider vinegar, a drop of dish soap, then hit it with a spray of hot water to get a lot of suds and bubbles. When the swarms were particularly bad, one of these traps could catch dozens overnight, but we had to refill and refresh them constantly and the mass-graves of floating fruit flies were somewhat unsightly.</p>

<p>Earlier this Spring I was reading about symbotic relationships between humans and nature, and that gave me an idea to try some carnivorous plants.</p>

<p>Venus Fly Traps are the most well known type of carnivorous plant. They have sensitive little trigger hairs in their leaves, and when a fly lands and disturbs one of the hairs, the two lobes snap shut to trap the fly. The plant digests the fly before opening back up, ready for its next meal. The downside is they can take a week or more to open back up! That’s not nearly high-volume enough to deal with my fruit fly problem.</p>

<p>Some additional research taught me about a more passive type of carnivorous plant called a “pitcher plant.” There are many varieties, but generally their leaves form tubes that are open on top. These tubes are full of liquid - a mixture of rainwater and digestive fluids. Flies are attracted to the scent, fly in, then fall into the liquid. They’re trapped there until they drown, then are slowly digested. The same pitcher can catch many, many flies, and even smaller pitcher plants can have between 6 and 12 pitchers.</p>

<p>These sounded perfect! I ran up to the local plant nursery and got three carnivorous “Pitcher plants.” I got two different varieties - which internet research suggests are a Purple Pitcher Plant (<a href="https://en.m.wikipedia.org/wiki/Sarracenia_purpurea">Sarracenia Purpurea</a>) and what I think is a <a href="https://en.wikipedia.org/wiki/Sarracenia_leucophylla">Sarracenia Leucophylla</a> (but could be a <a href="https://en.wikipedia.org/wiki/Sarracenia_flava">Sarracenia Flava</a>).</p>

<p>I named them Audrey III, Audrey IV, and Audrey V. They were about the size in the photos when I got them. They were mature enough to have 6-8 open pitchers, and were growing another 6-8 juvenile pitchers. Each plant was roughly $10 each.</p>

<p>I’ve been disappointed by Audrey III and V’s performance (they’re either the Leucophylla or Flava species), but Audrey IV (the Purple Pitcher Plant) is a <strong>beast</strong>. These days I see one fruit fly buzzing around sometimes, but never more than that. When I look in Audrey IV’s pitchers, she’s been busy - just now I counted ten or eleven fruitflies and two house flies.</p>

<p>Passive countermeasures like Audrey IV works great because it prevents them from going exponential. If you’re taking fruit flies out early and continuously, they don’t have a chance to reproduce. A female fruit fly starts mating 8 hours after it emerges from the larval state, and lays about 400 eggs, which take 12-15 hours to hatch at typical room temperature. Needless to say - you gotta keep these under control!</p>

<p><img src="https://blog.zaccohn.com/images/blog_lavender.jpeg" width="100"> I did notice for a time they were still congregating by the compost and weren’t being drawn to Audrey’s sweet scents. More internet research seemed to indicate they didn’t like don’t like the smell of lavender, so I cut some lavender flowers and put them between the compost bin’s lid and filter. That didn’t seem to be effective, so I spritzed some much higher density lavender essential oil on the compost bin filter. Later that night I watched as a fly kept going into the holes in the lid, then back out, then in, but then back out. It didn’t like the smell! Success!</p>

<p>Since then, there’s been no congregation of fruit flies around the compost. I still see one or two flying around the kitchen, but Audrey IV is keeping them under control.</p>

<p>So that’s my official two-part recommendation for managing fruit flies: get yourself an Audrey IV and spritz some lavender essential oil on your compost bin filter to keep them out.</p>

<h2 id="taking-care-of-a-pitcher-plant">Taking care of a Pitcher Plant</h2>
<p>A few notes on taking care of your new Audrey.</p>
<ol>
  <li><strong>You have to use distilled water.</strong> If you water them with sink water they’ll be dead within a day or two. These plants evolved in swampy, very nutrient-poor soils (that’s why they evolved to get their nutrients from their prey). The minerals in sink water are enough to overwhelm and poison your pitcher plants.</li>
  <li><strong>Damp, but not soaked, soil.</strong> When you water them, you want the soil to be damp but not waterlogged. Although you should look up the needs of your specific species of Audrey.</li>
  <li><strong>Filling the pitcher.</strong> For certain types of pitcher plants, you’ll want to fill up their pitchers with (distilled) water. Some types of pitcher plants have an opening at the top without any sort of leaf covering it (like Audrey IV). These types of plants are designed to supplement their digestive juices with rain water they catch. Since it presumably doesn’t rain inside your house like it does outside, you’ll want to use an eye dropper or a straw to drip some distilled water into the pitchers. Generally try to fill them 3/4 of the way. If your pitcher plant has a “hood” - or part of the leaf that’s covering the opening - that’s designed to shield it from the rain and you may not need to fill it up. Look up your particular species for specific instructions.</li>
  <li><strong>Hand-feeding your pitcher plant.</strong> Outside of fruit fly season, you’ll want to feed your pitcher plant a snack every so often. I use dehydrated mealworms or bloodworms from the pet food store (typically used to feed reptiles, etc). Use tweezers to grab one and drop it into a pitcher. Keep an eye on how fast they digest to figure out the optimal feeding schedule for your plant - but it’s probably going to be close to 3-4 per plant once every 2-3 weeks.</li>
</ol>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Book Review: The Laws of Trading (141 pts)]]></title>
            <link>https://astralcodexten.substack.com/p/your-book-review-the-laws-of-trading</link>
            <guid>36820105</guid>
            <pubDate>Fri, 21 Jul 2023 21:32:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://astralcodexten.substack.com/p/your-book-review-the-laws-of-trading">https://astralcodexten.substack.com/p/your-book-review-the-laws-of-trading</a>, See on <a href="https://news.ycombinator.com/item?id=36820105">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>[</span><em>This is one of the finalists in the 2023 book review contest, written by an ACX reader who will remain anonymous until after voting is done. I’ll be posting about one of these a week for several months. When you’ve read them all, I’ll ask you to vote for a favorite, so remember which ones you liked</em><span>]</span></p><p><span>A book about trading isn’t ever </span><strong>actually</strong><span> about trading</span></p><p><span>. It is either:</span></p><ul><li><p><span>A former trader sharing stories from their glory days, e.g. </span><em>Liar’s Poker</em><span>, the exposé that morphed into a how-to guide, or</span></p></li><li><p><span>Tales of Icarus flying too close to the sun, where readers revel in schadenfreude, e.g., </span><em>When Genius Failed</em><span>.</span></p></li></ul><p><span>With </span><em><a href="https://www.amazon.com/Laws-Trading-Traders-Decision-Making-Everyone/dp/1119574218/ref=sr_1_1?crid=1CFYGH6Q0TUPK&amp;keywords=the+laws+of+trading&amp;qid=1689973717&amp;sprefix=the+laws+of+trading%2Caps%2C144&amp;sr=8-1" rel="">The Laws of Trading</a></em><span>, Agustin Lebron has written something different: part love letter to trading, part philosophical treatise on epistemology and modeling the world around us, and part guide to applied decision-making. Lebron’s Laws are Laws of the Jungle, not Laws of Nature. He views financial markets as the most competitive Darwinian environment on Earth, where participants must adapt or die.</span></p><p><span>According to Lebron, the book is for people working in finance and trading, as well as anyone in the business of making rational decisions.</span><em> </em><span>This explicitly rationalist bent is similar to Julia Galef’s </span><em>The Scout Mindset </em><span>or Annie Duke’s </span><em>Thinking in Bets. </em><span>Where </span><em>The Laws of Trading </em><span>sets itself apart is with the best description of financial market dynamics that I’ve ever seen while diving deep into philosophical concepts.</span></p><p><span>Why trust Lebron? He is an engineer, worked as a quantitative trader and researcher at Jane Street, and has a deep understanding of trading. He has what Taleb would describe as </span><strong>skin in the game</strong><em>.</em><span> You and I may read Astral Codex Ten in our spare time, post on LessWrong, and navel gaze about our epistemic certainty, but at the end of the day most of us are pursuing rationality for fun, as a hobby. Traders like Lebron pursue rationality as a profession: Their livelihood depends on having a better model of the world than their competition. There are lessons to learn from them that apply to our daily lives.</span></p><p><em>Know why you are doing a trade before you trade.</em><span>&nbsp;</span></p><blockquote><p>“What is trading about? Fundamentally, it’s about the relationship between you and the rest of the world.”</p></blockquote><p>Right now, you’re making a trade.&nbsp;</p><p>You’re trading your time to read this book review. You have a cost: you could be spending time with your loved ones, exercising, working, sleeping. You might be hoping to learn something, to take away lessons that you can apply to your life, or simply to entertain yourself. Here, off the bat, are two key insights:</p><ol><li><p>We are all making trades, all of the time.</p></li><li><p>We need a framework for thinking about these trades.</p></li></ol><p>Lebron’s first law states that we must know ourselves and our motivations for trading before we trade. We tell ourselves many stories, but someone with intellectual honesty – the person with the most alignment between their motivations and actions – will take money from the person who didn’t go through the work to understand their own motivations.&nbsp;</p><p><span>There is a reason that Citadel and other hedge funds </span><a href="https://www.investopedia.com/terms/p/paymentoforderflow.asp" rel="">pay millions of dollars to trade with retail</a><span>. They know why they are trading: to maximize profit. And the dilettante who “trades for fun” will be eaten alive by a firm with a much better model of a) the world and b) the dilettante themself.</span></p><p>Why did I write this book review? To test my intellectual mettle. I could easily have posted this book review elsewhere, but no, I wanted to see how I stack up against other ACX Book Review contest participants.&nbsp;</p><p>Similarly, this is often the reason people get into trading. One motivation that Lebron explicitly calls out is intellectual validation. You can toil in obscurity for years as an academic. But in trading, there is a quick feedback loop. If your P&amp;L showed $10M last year and the guy sitting next to you showed $8M, you have demonstrated who is “cleverer” and established a clear hierarchy.&nbsp;</p><p><span>What lessons here transfer to our daily lives? Like Paul Graham, Lebron encourages us to </span><a href="http://www.paulgraham.com/identity.html" rel="">keep our identities small</a><span>. He gives the standard decision-making advice to write down your framework and reasoning for why you made a decision at a specific point in time, in order to avoid biases after the fact.&nbsp;</span></p><p>This section of the book contained good general advice, but nothing that will be particularly new for the median ACX reader.&nbsp;&nbsp;</p><p><em>You’re never happy with the amount you traded.</em></p><p><span>Now we start to get into the good stuff. Financial markets are an information aggregation mechanism, relying on multiple parties’ beliefs and recursive Bayesian updates of an individual actor’s beliefs based on the beliefs of others</span></p><p><span>.</span></p><p><span>Market mechanics demonstrate Bayesian beliefs in action. The following quote is quite long, so skip over it if you don’t want to dive deep into the psychology of making a market. I retained it in full because this is quite literally the best description I’ve ever seen of the Bayesian dance between two </span><a href="https://www.investopedia.com/terms/m/marketmaker.asp" rel="">market makers</a><span>:</span></p><blockquote><p><em>“You are a market maker in South African mining companies. Through years of effort and continual improvement, you have built a trading model for the company Veldt Resources. You walk into work one day, ready to set up your trading for the day. It's a stock that doesn't trade much, and usually there are only two market makers: you and another (we'll call her Jo). She's sharp, and she competes well to trade against customer orders that come in.</em></p><p><em>Your model has Veldt valued at 54.35 ZAR (South African rand). You're going to start quoting the stock, so you're about to turn on your machine making a market 54.25 - 54.45 (1000x)</em></p><em>. Before you turn on, you check the current market and notice that Jo has already turned on and she's making her market 53.50 - 54.00 (2000x). If you were to turn on your machine, your market would cross her market, and you would buy 1000 shares from her for 54.00.</em><p><em>You now need to make a decision. Whose model do you believe more, yours or Jo's? If you believe yours, you should turn on your machine, trade at 54.00, and expect to make money. If you believe Jo's model, you should adjust your own model parameters to match her market and turn on, making a similar market to hers.</em></p><p><em>What to do? As with many dichotomies, this is a false one. And as with many decision processes, Bayesian reasoning lights the way…</em></p><p><em>…Jo presumably believes Veldt is worth around 53.75 (the average of her bid and offer). But how confident is she in her belief? The width of her market can give you a clue. It's 0.50 ZAR, whereas yours was going to be 0.20 ZAR wide. All other things equal, you should think that Jo only has 40% (0.20/0.50) of the confidence in her fair value as you do in yours.</em></p><p><em>On some absolute scale of confidence, you can say you had a belief-strength of 100 in your fair value of 54.35 (before seeing Jo's market), and Jo has a belief-strength of 40 in her fair value of 53.75 (before seeing yours). And it turns out the weighted average of these two beliefs is quite a reasonable way to combine them: 100/140 * 54.35 + 40/140 * 53.75 = 54.18. Your updated fair value, having seen Jo's market, is thus 54.18 ZAR.</em></p><p><em>This procedure is a quick, heuristic, and reduced version of Bayesian belief-updating, and a good reference on the subject is A.L. Barker's 1995 paper.</em></p><p><em>After updating, you now believe that the stock is worth 54.18. Assuming your trading costs, risk limits, and return requirements are satisfied, buying 1000 shares for 54.00 is a good trade. Naively, you might just put out a 54.00 bid for 1000 shares, trade with half the 2000 share offer, and hope to collect your expected-value ZAR.</em></p><p><em>In practice, however, you might be able to make even more. If Jo is making a 0.50 wide market, maybe she'd be willing to sell lower than 54.00. It's conceivable that if you put out a 53.90 bid for 1000 shares, Jo will sell at that price, and you collect an extra 100 ZAR!</em></p><p><em>Of course, Jo could react differently. She could see your bid and use that information to change her market, in much the same way you did before turning on. These are difficult decisions, ones where experience with the product and the market make a big difference in being able to eke out a little extra edge. Let's play it safe however and pay 54.00 for 1000 shares.</em></p><p><em>You trade, and Jo reacts by immediately canceling her market. This is not an uncommon occurrence in illiquid stocks, especially in emerging markets, so you're not too surprised. You wait a couple of minutes, mentally visualizing Jo in front of her six monitors, evaluating her trade and her model.</em></p><p><em>Finally, she turns back on. Her new market is 53.50 - 54.05 (10000x)! You reason that Jo has seen that someone (you) disagrees with her valuation of the stock. Jo is a good Bayesian like you, and so she has incorporated that information into her model and updated her beliefs about the fair value of the stock. Her updated belief is that she now wants to sell even more stock, at a marginally higher price. Clearly, she almost entirely discounts the information you've communicated to her with your trade.</em></p><p><em>How should you react? It seems fairly clear that, assuming Jo is not a crazy or incompetent market maker (usually a fair assumption), your trade was a bad one. You bought 1000 shares, when in retrospect, you would have wanted to buy much less, probably zero.</em></p><p><em>Imagine instead that Jo had turned back on with a market of 54.00 - 54.50 (1000x). Her reaction now clearly indicates the information you gave her with your trade is valuable, and she has adjusted her beliefs accordingly. Your trade was probably a good one. Don't you wish you had bought all 2000 shares on offer?</em></p><p><em>No matter what Jo's reaction is, you will be unhappy with your trade. Note that Jo will be unhappy too, since retrospectively she should have either made her initial market bigger or smaller. Welcome to the joyous world of trading!”</em></p></blockquote><p>Whether or not you make money, you have regrets! If you profited, you could have made more. If you lost money, you shouldn’t have made the trade at all. Like death and taxes, you can’t avoid adverse selection.&nbsp;</p><p>Lebron continues to highlight a few areas of trading that have adverse selection problems.</p><p><span>First, IPOs. If you buy the stock in an IPO, you expect the share price to “pop” on the first day of trading. However, if others also have this expectation, the round will be oversubscribed. You can only get the quantity of shares that you bid for when the market </span><strong>doesn’t</strong><span> think the shares will go up. So if you are able to get the shares that you want, the IPO is likely a dud. See also: Venture Capital fundraising.&nbsp;</span></p><p>Second, powerful entities that change the rules of the game while you’re playing. Exchanges nullify “erroneous” trades. Brokerages limit buying. Anyone who tried to buy GameStop stock on Robinhood on January 28, 2021, knows this form of adverse selection all too well.</p><p>Lebron also highlights “special trades”, in which you should throw the “normal rules” out of the window. This advice generalizes to other areas of life:&nbsp;</p><blockquote><p><em>“The normal rules do not apply. If you remove yourself from our usual routine, if you think hard and clearly about the specific situation, maybe you can do something good. Perhaps even great. Others will be paralyzed by inaction, but perhaps you won’t be. Crises can be opportunities.”</em></p></blockquote><p><em>Take only the risks you’re being paid to take. Hedge the others.</em><span>&nbsp;</span></p><p>In trading, as in life, you can make the right call in expected value terms but still lose due to randomness. Some of that randomness is avoidable. Some of it is not — and can be accounted for by hedging. Here, Lebron encourages us to rely on multiple risk measures and actively seek to understand the risks that we might be subject to.&nbsp;</p><p>That’s all well and good in the world of finance, with derivatives contracts. But how might this apply in other areas of life?</p><p>If you work for a publicly traded company and are compensated in stock, sell your shares as soon as you receive them. This is not because I don’t expect the share price of Microsoft/Meta/Apple/etc. to go up. The stock may very well outperform the market. But you are not being compensated for the added risk that you take on here. Your employment prospects at Microsoft/Meta/Apple/etc. are highly correlated with the share price. When the share price is down is when layoffs happen. Former Enron employees can chime in here.</p><p>Similarly, it makes sense to hedge anything that is outside of your control. Let’s say you’ve decided the crypto bear market of 2023 is a great time to start a new crypto company. Your success depends on things within your control, such as:</p><ul><li><p>Your idea</p></li><li><p>Your hard work and ability to execute</p></li><li><p>Your network for hiring</p></li><li><p>Your ability to fundraise</p></li><li><p>Etc.</p></li></ul><p>As well as some things outside of your control, such as:</p><ul><li><p>Interest rates</p></li><li><p>The current VC fundraising environment&nbsp;</p></li><li><p>The performance of crypto as a sector&nbsp;</p></li><li><p>The performance of tech overall</p></li><li><p>Etc.</p></li></ul><p><span>It might make sense to </span><strong>short </strong><span>the overall tech sector or a basket of publicly traded crypto-related companies so that your trade of time and foregone income to start your new crypto company is associated with only the risks you can control.</span></p><p>But some risks you can’t hedge. These are the more interesting ones. There is counterparty risk (your trading partner blows up), liquidity risk (the market you used to hedge dries up), or even political risk:</p><blockquote><p><em>“Living in the developed world, it’s easy to fall into the seductive assumption that the rule of law applies strongly everywhere. This is far from the case. A foreigner trading in an emerging market is frequently among the first “victims” of any political turmoil.”</em></p></blockquote><p>Lebron is meticulous in the ways that he thinks about risk. He highlights that in the markets, you need to be exceedingly paranoid to survive:</p><blockquote><p><em>“Certainly, the modern compendium of mental illnesses (DSM-5) takes a dim view of people who think everyone is out to get them. Yet financial markets are different: people really are out to get you, after all.”</em></p></blockquote><p>I don’t think enough people consider risk and the hedges you can take in the context of a career. I’ve spent the past several years working at startups, where I’ve placed a hugely levered career bet. I’m trading my time and the opportunity cost of another job to work at my current employer. My salary, stock options, expertise, and social capital that I build from working 10 hours per day is fundamentally long (and has risks associated with):</p><ul><li><p>The tech industry</p></li><li><p>My startup’s industry</p></li><li><p>My individual startup&nbsp;</p></li><li><p>Our customers’ business viability&nbsp;</p></li></ul><blockquote><p><em>“Many trades that look different on the surface can in fact be the same trade in disguise, and trades whose edge appears to derive from one risk are actually bets on another risk.”</em></p></blockquote><p><span>It might make sense to hedge some of that risk – simply having friends that work at other companies and in other industries so that all of my social capital isn’t in one basket is a start</span></p><p><span>.&nbsp;</span></p><p>My only gripe here is that I would have liked to see Lebron call out ergodicity more explicitly. Blowing up your account might be fine as a trader – if you have a decent prior track record, you can probably just get a job at a different firm – but in life other losses are less reversible. As far as we know, this is the only universe we have access to. It doesn’t matter if your bet was positive EV and you won in 51% or 75% or even 99% of universes. You should place a high premium on staying alive and having enough bankroll to play the next round of the game. This is more important outside of finance than in the world of trading.</p><p><em>Put on a risk using the most liquid instrument for that risk.</em><span>&nbsp;</span></p><p>Liquidity isn’t something I think about in daily life. But I probably should. A personal example: I gave up the liquidity of a month-to-month gym contract in New York City in February 2020. I paid one year upfront for a 10% discount. Oops.</p><p><span>Lebron also reminds us that the </span><a href="https://byrnehobart.medium.com/the-30-year-mortgage-is-an-intrinsically-toxic-product-200c901746a" rel="">30-Year Mortgage is an Intrinsically Toxic Product</a><span>, a concept that will resonate with all of the Georgists here.&nbsp;</span></p><blockquote><p><em>“The usual path to homeownership exposes people to a financial decision that would, it seems clear, be ridiculed if it were taken by any self-respecting public company.”&nbsp;</em></p></blockquote><p>Among other issues:</p><ul><li><p><em>“The home is bought and sold through an opaque cartel of brokers whose interests are demonstrably not aligned with those of their customers”</em></p></li><li><p><em>“The ability to service the debt (the mortgage) is highly correlated with local economic conditions. This means that if you lose your job and need to sell your house, you will typically find it an exceedingly bad time to try to sell your house.”</em></p></li><li><p><em>“Residential real estate has historically returned significantly below equity markets over long time horizons”&nbsp;</em></p></li></ul><p><span>But I’m not so sure that these lessons are directly applicable to other areas of life. Some of the best things in life come from lashing yourself to the mast, burning the boats behind you, </span><strong>willingly giving up</strong><span> liquidity. The deepest monogamous relationships are built from an irrational investment in one other person, saying “In sickness and in health, until death do us part.” How many scientific problems were solved because one person had an irrational willingness to: Just. Keep. Going.&nbsp;</span></p><p>Sometimes it’s powerful to use the sunk cost fallacy to your advantage. Investing in relationships, subject matter expertise, even putting down roots via *gulp* homeownership reduces your liquidity, but also leads to some of the best (if intangible) things in life.</p><p>If you can’t explain your edge in five minutes, you don’t have a very good one.&nbsp;</p><p>OR&nbsp;</p><p>The long-term profitability of an edge is inversely proportional to how long it takes to explain it.</p><p><span>The Efficient Market Hypothesis is one of the core concepts taught in Finance 101. The Efficient Market Hypothesis is a </span><strong>lie</strong><span>. The person that better understands the nature of a small sliver of the world (e.g. Apple’s share price) will make more money than others.</span></p><p>Modern financial markets are exceedingly competitive. This means that the bigger you think your edge is, the more likely it is that you’re wrong.&nbsp;</p><blockquote><p><em>“Evolutionary thinking applies quite directly when thinking about the evolution of markets. Having an edge in a mature market means understanding the world better than other traders, even ones who are already highly skilled. In fact, the marginal trader in modern financial markets is quite sophisticated and skilled indeed.”</em></p></blockquote><p><span>Lebron here warns us of getting too cute with data, of changing variables. Enough randomness will produce an “edge” that is likely to break down the second a trading strategy hits the real world. You can always find a statistical correlation if you change enough variables. But this is fundamentally the same problem facing the </span><a href="https://slatestarcodex.com/2014/04/28/the-control-group-is-out-of-control/" rel="">replication crisis</a><span> in social sciences.&nbsp;</span></p><p>Lebron argues that we need stories here. Edge is expressed in stories: an edge does not exist without a clear mental representation of that edge. Pure linear algebra does not suffice.</p><p><span>I’m not so sure. It seems like AI companies are pushing forward technology in a way that suggests that mental representations are not the only path to intelligence. Lebron discounts “black box” trading strategies without much discussion of their potential merits. Are all of </span><a href="https://en.wikipedia.org/wiki/Renaissance_Technologies" rel="">RenTech’s</a><span> models explainable by a story? The firm is notoriously secretive, so I don’t know, but I’d guess not.</span></p><blockquote><p><em>“Frequently a good trade appears, has a seemingly insurmountable difficulty, and it is mere persistence that knocks down the final barrier. There may have been many others who looked at the idea, wanted to do it, but couldn’t get past that last hurdle.”</em></p></blockquote><p><span>Before Sam Bankman-Fried was the face of Why Effective Altruism is Bad, before he even founded FTX, he made money </span><a href="https://www.bloomberg.com/news/articles/2021-04-01/the-ex-jane-street-trader-who-s-building-a-multi-billion-crypto-empire" rel="">arbitraging the difference between Bitcoin prices on Japanese and American exchanges</a><span>. I’m reminded of that trade here. It isn’t a particularly elegant trade, it doesn’t require deep technical knowledge or any models. It was a </span><strong>schlep</strong><span>. It was all operational work: figuring out how to open a Japanese bank account, transferring money between the US and Japan, standing in line for hours every day at both US and Japanese banks (presumably this wasn’t the same person).&nbsp;</span></p><p>In as technical a field as trading, sheer willpower is often what gets things done in the end.</p><p><em>The model expresses the edge.</em><span>&nbsp;</span></p><p>Lebron drills into us that a model is the tool for expressing an edge. The model is not the edge. The model does not give us unique knowledge about the world. The map is not the territory.&nbsp;</p><p>He dives into the difference between generative (G) and phenomenological (P) models. G models express a worldview and fit data into that way of thinking, whereas P models solely look at the empirical data to build a worldview.</p><p>Models of the world differ from models of markets, though. Markets have quick feedback loops, are explicit in terms of what they measure, and are easy to quantify at a specific point in time. Most of our models for the world, though, are ill-defined and explicit.</p><p><span>Models are only as good as our assumptions. As an aside, this is a common criticism of rationality or Effective Altruism – you can justify any worldview if you assign your model input weights in just the right way</span></p><p><span>. I also tend to think that “traditional” EA is overly dependent on P models, and doesn’t embrace the G models that led to economic reforms in India in the 1990s or the economic policies that led to rapid economic development in Southeast Asia in the second half of the 20th Century. Interestingly, I think a lot of longtermist EA, specifically AI alignment, leans the other way, relying on G models which explicitly assume a certain P(doom) and work backwards from there. (Though I won’t pretend to be an expert here or to understand everything, so take this with a grain of salt.)&nbsp;</span></p><p><span>Overall, startups and tech seem to take heed to Lebron’s lesson much better than the folks hanging out on this part of the internet: </span><em>“Even if a model makes good predictions about some future value or event, that knowledge is useless without also knowing how to take advantage of that prediction.”</em></p><p>Now we get a bit philosophical. By acting, you change the nature of the market. Your model predicts things that might not be true as soon as you start trading (and changing the environment) based on it.&nbsp;</p><p>When you’re right, everyone else sees the same trades that your model does and will beat you to them. When your model is wrong, others don’t act, meaning adverse selection rears its ugly head once again. So your model shows you with an edge, but in practice you only make the trades where you don’t have an edge.&nbsp;</p><p>Lebron closes by arguing that G models are best for understanding other people, and are good in and of themselves:&nbsp;</p><blockquote><p><em>“You can also see connections to traditional moral philosophy in thinking about modeling the behavior of others. To have a good G model about someone else is to have some measure of empathy and compassion for that person: what they’re like, what they think and feel, putting yourself in their shoes. Pragmatically, developing the skill of empathy and compassion for others is, aside from a moral good in itself, an excellent way to understand better the people who surround you. More people working to develop good G models of others is surely a small step to a better world.”</em></p></blockquote><p><em>If you think your costs are negligible relative to your edge, you’re wrong about at least one of them.</em></p><p>This section of the book displayed a good amount of epistemic humility, words that I didn’t expect to be typing in the context of a book about trading.</p><p><span>Lebron tells us that trades don’t exist independently in the universe — in the n-dimensional space of all possible trades seeking to optimize profitability, if you have a gigantic mountain of profitability, someone else has probably at least discovered the base. So you probably </span><strong>don’t</strong><span> have a profitable trade; rather, you are misunderstanding something about your trade. You’ve either overestimated profitability or underestimated cost.</span></p><p>Lebron highlights four types of trading costs: </p><p>[graph that didn’t show up correctly here: two axes and four quadrants, with the axes being visible ←→ invisible costs and linear ←→ nonlinear costs]</p><p>Here, we’ll focus on Quadrant 4, where he highlights a few interesting phenomena.</p><p>Herding. It’s likely that if you have a profitable trading strategy, either:</p><ol><li><p>Other firms discovered a similar strategy independently and/or</p></li><li><p>You’ve “stolen” the idea from someone else (say if you leave a firm), or vice versa</p></li></ol><p>Lebron highlights Long Term Capital Management (LTCM) as an example here, which suffered a famous blowup in 1998. This hedge fund is often discussed in the context of betting on Russia just before it defaulted on its debt, but an under-discussed aspect is the market mechanics. Other firms were copying LTCM’s trades, so there was a liquidity issue and a cascade of failures when the firm’s margin positions needed to be unwound.&nbsp;</p><p>Lebron also discusses opportunity cost, a concept with which most will be familiar. But here, he discusses the cost in the context of trading. Ultimately, this is an explore/exploit problem. How should a trading firm weigh maximizing profit for today’s strategies, as opposed to working on organizational efficiencies so that you can have the capacity to work on tomorrow’s strategies?</p><p>There is a clear career parallel here: I’ve seen so many people get locked into their current role due to inertia, whereas the ones who succeed long-term appear to prioritize their own learning and exploration.</p><p>As a case study, Lebron discusses how Bell Labs (AT&amp;T) maintained a position of dominance for half a century. He attributes this to four things:</p><p>First, they hired the best. There was interaction between three groups that did not interact at most organizations.</p><ol><li><p>Scientists and engineers who conducted exploratory research.</p></li><li><p>More applied engineers, who took the work of the first group and integrated their discoveries into existing problems at AT&amp;T.</p></li><li><p>A third group of engineers who put the work from the first two groups into production.</p></li></ol><p>This seems to have been cargo-culted at most modern tech companies. Ping-pong tables and nap pods don’t replace a true culture of cross-pollination of ideas in a boring cafeteria.&nbsp;</p><p><span>I’m reminded of the story of Richard Feynman in academia</span></p><p><span>. His colleagues who kept their office doors closed made progress on their research in the short-term, but hit stumbling blocks. Those who kept their doors open didn’t seem to make much progress initially, but eventually outpaced the “closed door” scientists. They had new ideas and research directions based on all the interesting conversations they were having with others.</span></p><p>The simple lesson here is to get outside of your bubble a bit more. Maybe the normies have something valuable to say once in a while.&nbsp;</p><p>Second, an emphasis on continuing education. This blew me away: Bell Labs developed a syllabus of graduate-level courses and taught it to any interested employee. They didn’t outsource the curriculum or the teaching.</p><p><span>Third, a technical staff that was held in just as high of an esteem as the PhDs who managed them. This seems to be why there is little innovation in government: talented engineers are treated as second-class citizens in research labs, so they work for Stripe and OpenAI instead. Similarly, one can attribute the lack of innovation in hospitals to doctors holding all of the institutional power. Often, all a hospital needs to save lives is </span><a href="https://en.wikipedia.org/wiki/The_Checklist_Manifesto" rel="">simple practices that other businesses figured out long ago</a><span>, but the hubris of MDs prevents this from happening. But I digress.&nbsp;&nbsp;</span></p><p>Fourth, a culture that embraced failure. While many companies say they have a culture of “failing fast”, how many actually mean it?&nbsp;</p><p>Some of the best parts of this book are the diversions. This book is in a sense nostalgic – edges are lost over time, trading firms come and go, entire markets disappear. All you have along the way is the knowledge that for one instant, in one market, you had knowledge that the rest of the world didn’t and used it to make one profitable trade.</p><p><em>Just because something has never happened doesn’t mean it can’t.&nbsp;</em></p><p><em>Corollary: Enough people relying on something being true makes it false.</em></p><p><span>“Impossible” and </span><a href="https://arxiv.org/pdf/1103.5672.pdf" rel="">“25-standard deviation” events</a><span> sure seem to happen awfully often in the financial industry.&nbsp;</span></p><p>Consider an airplane engine that has a 1/1,000 chance of failing. Each plane has two engines, so that if one fails the other can still operate and get everyone to the ground safely. That’s great if the engines act as completely independent variables, but what if failures are correlated?&nbsp;</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png" width="1200" height="742" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:742,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:&quot;Chart&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="Chart" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The key insight here is that small correlations create large changes in failure probabilities. Namely, a relatively “small” correlation of 0.1 increases the probability of engine failure 100x.&nbsp;</p><p>The feedback loop of markets is great at hiding these correlations until something goes wrong. When it does, you have highly-correlated mortgage-backed securities kicking off the 2008 Financial Crisis.</p><p>One of Lebron’s more interesting insights is that markets are stochastic, self-organized feedback systems, which means that both momentum trades (a price that is going up will continue to go up) and mean-reversion trades (the exact opposite) are valuable at different points in time.</p><p>I found this to be a good framework for thinking about AI. Some folks are clearly betting on momentum – that GPT-X products will continue to improve, reaching AGI (if it hasn’t already). The other side of the coin is bets on mean-reversion, which focus on the S-curves of technology and take a historical view. I’m old enough to remember that in 2016 everyone was talking about how self-driving cars would mean the end of truckers, and there’s more demand than ever for them today.</p><p><em>Working to align everyone’s interests is time well spent.</em><span>&nbsp;</span></p><p>This is the principal-agent problem. Whenever the person investing the money is not also providing the capital, you’re going to have problems.&nbsp;</p><p>Follow the incentives. When a fund manager is paid 2% of assets under management (AUM), the incentive is to raise as much money as possible. When they are paid 20% of profits, they’re incentivized to make high-risk investments, as their upside is uncapped but their downside is capped at $0.</p><p>High-water mark provisions help with this. Basically if your fund had $1 billion AUM last year and you lost 30% this year, you now have $700 million. As the fund manager, you don’t get paid until you’re back to the $1 billion mark.</p><p>But…then you just shut down your fund, return the $700 million, and start a new fund.</p><p>Lebron argues that the only way to resolve this problem is to perfectly align capital and labor.</p><p>I wonder how much of the Renaissance Medallion fund’s success comes from a) this perfect alignment of incentives vs. b) capital limits, meaning that strategies can be executed that would not work at a larger scale.&nbsp;</p><p>Lebron argues that everyone acting as an owner is a good thing. And I tend to agree! But there’s a free-rider problem here that he doesn’t address. I’m writing this book review instead of working at my day job as a tech employee. I’m an owner — but my salary and equity was negotiated a few years ago when I signed my job offer. If I were a salesperson working on commission, perhaps I’d be singing a different tune. Aligning incentives is easier when you’re working at a job where performance is a) easily measurable and b) a direct output of your labor (say, as the Portfolio Manager at a hedge fund).</p><p>Lebron also argues that, within an organization, consistency of culture is more important than the specific culture. I fully agree – this is particularly egregious at tech companies. Many claim to support work-life balance but then ask you to work weekends, or say “we’re a family” but then lay off employees the second they have trouble raising the next round of funding. Employees can see right through this. Put your flag in the ground and say what you actually stand for. If you stand for everything, you stand for nothing.&nbsp;</p><p><em>If you don’t master technology and data, you’re losing to someone who does.</em></p><p>This point is self-explanatory and I don’t think it needs further exploration for the average Astral Codex Ten reader.&nbsp;</p><p>Will machines take over the world? Lebron straddles the line here and states in the context of trading, a human-machine hybrid still does the best work, given our complementary skill sets. Humans have higher-level thinking and understanding context, whereas computers possess the speed and iteration ability necessary to implement models. This book was released in 2019 — I’d love to see if Lebron has updated his priors at all based on recent developments in AI.</p><p>There’s also an interesting diversion here into software development. Specifically, Lebron tries to quantify technical debt, which I haven’t seen done before.</p><p><em>If you’re not getting better, you’re getting worse.</em></p><p>The markets are a very scary place, and you are in an existential arms race with your competitors.&nbsp; Adapt or die. At the individual level, group (trading desk/business unit) level, firm level, and market level. Adapt or die.&nbsp;</p><p>That may seem harsh. But no – Lebron praises trading as a positive-sum game. International financial markets allow the flow of capital from rich to poor countries, giving rich investors a return and raising the standard of living in the developing world.&nbsp;</p><p>This is a striking perspective to have on trading. I’ve heard traders describe the work they do as “net neutral” and “adding no value to the world”. Conversely, Lebron views trading as an act of creativity, a way to make the world, in one small way, a better place through creating efficiencies in markets. His philosophical approach to markets is best demonstrated through this story of a trader named Mark,&nbsp;</p><blockquote><p><em>“Tomorrow will be more difficult than today, and the day after more difficult still, and on until the day he decides to retire from the business. There is no respite and there are no pauses to the inexorable adaptation of markets.</em></p><p><em>It’s easy to view Mark’s job as a soul-destroying, almost Sisyphean effort. And indeed, it’s this ceaseless competition that does, over time, break the will of many market participants. But I will argue in what follows that the best traders view their situation with very much the opposite perspective: as a liberating and redemptive force…</em></p><p><em>…Profitable traders are some of the most intelligent, driven, perceptive, and adaptable people on earth. To relegate such a person to a life of maintenance and literally trading on past glories sounds and is soul-destroying. The essence of trading, the thing that makes it such an interesting and stimulating undertaking, is this very process of adaptation and competition.”</em></p></blockquote><p><span>One can imagine Lebron, in a previous life, penning the words </span><a href="https://en.wikipedia.org/wiki/The_Myth_of_Sisyphus" rel="">“One must imagine Sisyphus happy.”</a></p><p>Beyond the philosophy, while reading this book I was struck by the fact that trading is one of the few true apprenticeship systems that remains for white-collar work. You can career switch into the technology industry without a degree. There is a clear educational path to becoming a doctor or a lawyer. But trading is a bunch of dudes (and it’s almost always men) behind closed doors working on intellectually challenging problems. Lebron recognizes this as well:</p><blockquote><p><em>“Autodidacts in trading are like jailhouse lawyers: for every person who’s truly discovered and developed a successful strategy sui generis, there is an army of people who either significantly undervalued the teaching that others provided, or they are deluding themselves about the profitability of their trading.”</em></p></blockquote><p><em>The Laws of Trading</em><span> opens the door to this world a crack and allows the rest of us to peek in, ever so slightly.</span></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Llama: Add grammar-based sampling (386 pts)]]></title>
            <link>https://github.com/ggerganov/llama.cpp/pull/1773</link>
            <guid>36819906</guid>
            <pubDate>Fri, 21 Jul 2023 21:17:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ggerganov/llama.cpp/pull/1773">https://github.com/ggerganov/llama.cpp/pull/1773</a>, See on <a href="https://news.ycombinator.com/item?id=36819906">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  <task-lists disabled="" sortable="">
    <div>
      <p dir="auto">EDITED after updates</p>
<p dir="auto">Inspired by <a data-error-text="Failed to load title" data-id="1704730522" data-permission-text="Title is private" data-url="https://github.com/ggerganov/llama.cpp/issues/1397" data-hovercard-type="pull_request" data-hovercard-url="/ggerganov/llama.cpp/pull/1397/hovercard" href="https://github.com/ggerganov/llama.cpp/pull/1397">#1397</a> and <a href="https://github.com/grantslatton/llama.cpp/commit/007e26a99d485007f724957fa8545331ab8d50c3">grantslatton's CFG work</a>, this adds an API that takes a serialized context-free grammar to guide and constrain sampling. Also adds a sample Backus-Naur form (BNF)-like syntax in <code>main</code> for specifying a grammar for generations.</p>
<h2 dir="auto">Testing</h2>
<p dir="auto">(M2 Max, 30B)</p>
<details>
<summary>Chess</summary>
<div data-snippet-clipboard-copy-content=" % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'A good game:\n\n' --grammar-file grammars/chess.gbnf
main: build = 674 (e550234)
main: seed  = 1688014137
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


main: grammar:
root ::= [1] [.] [ ] move [ ] move [<U+000A>] root_4 
move ::= move_5 move_9 
root_2 ::= [1-9] root_3 [.] [ ] move [ ] move [<U+000A>] 
root_3 ::= [0-9] | 
root_4 ::= root_2 root_4 | root_2 
move_5 ::= pawn | nonpawn | castle 
pawn ::= pawn_14 [a-h] [1-8] pawn_16 
nonpawn ::= [NBKQR] nonpawn_10 nonpawn_11 nonpawn_12 [a-h] [1-8] 
castle ::= [O] [-] [O] castle_17 
move_9 ::= [+#] | 
nonpawn_10 ::= [a-h] | 
nonpawn_11 ::= [1-8] | 
nonpawn_12 ::= [x] | 
pawn_13 ::= [a-h] [x] 
pawn_14 ::= pawn_13 | 
pawn_15 ::= [=] [NBKQR] 
pawn_16 ::= pawn_15 | 
castle_17 ::= [-] [O] | 

 A good game:

1. e4 e5
2. Nf3 Nc6
3. Bb5 a6
4. Ba4 Nf6

llama_print_timings:        load time =  1144.33 ms
llama_print_timings:      sample time =    35.87 ms /    32 runs   (    1.12 ms per token)
llama_print_timings: prompt eval time =  1126.34 ms /     7 tokens (  160.91 ms per token)
llama_print_timings:        eval time =  5214.99 ms /    31 runs   (  168.23 ms per token)
llama_print_timings:       total time =  6398.45 ms"><pre><code> % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'A good game:\n\n' --grammar-file grammars/chess.gbnf
main: build = 674 (e550234)
main: seed  = 1688014137
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


main: grammar:
root ::= [1] [.] [ ] move [ ] move [&lt;U+000A&gt;] root_4 
move ::= move_5 move_9 
root_2 ::= [1-9] root_3 [.] [ ] move [ ] move [&lt;U+000A&gt;] 
root_3 ::= [0-9] | 
root_4 ::= root_2 root_4 | root_2 
move_5 ::= pawn | nonpawn | castle 
pawn ::= pawn_14 [a-h] [1-8] pawn_16 
nonpawn ::= [NBKQR] nonpawn_10 nonpawn_11 nonpawn_12 [a-h] [1-8] 
castle ::= [O] [-] [O] castle_17 
move_9 ::= [+#] | 
nonpawn_10 ::= [a-h] | 
nonpawn_11 ::= [1-8] | 
nonpawn_12 ::= [x] | 
pawn_13 ::= [a-h] [x] 
pawn_14 ::= pawn_13 | 
pawn_15 ::= [=] [NBKQR] 
pawn_16 ::= pawn_15 | 
castle_17 ::= [-] [O] | 

 A good game:

1. e4 e5
2. Nf3 Nc6
3. Bb5 a6
4. Ba4 Nf6

llama_print_timings:        load time =  1144.33 ms
llama_print_timings:      sample time =    35.87 ms /    32 runs   (    1.12 ms per token)
llama_print_timings: prompt eval time =  1126.34 ms /     7 tokens (  160.91 ms per token)
llama_print_timings:        eval time =  5214.99 ms /    31 runs   (  168.23 ms per token)
llama_print_timings:       total time =  6398.45 ms
</code></pre></div>
</details>
<details>
<summary>"Chess" without grammar</summary>
<div data-snippet-clipboard-copy-content="% ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'A good game:\n\n'  

main: build = 645 (fd0eb66)
main: seed  = 1686286016
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 A good game:

Sir Thomas Gresham, when he was building his famous Exchange at London, had the following dialogue with a mason, whose name was Richard B
llama_print_timings:        load time =  1185.47 ms
llama_print_timings:      sample time =    21.57 ms /    32 runs   (    0.67 ms per token)
llama_print_timings: prompt eval time =  1167.67 ms /     7 tokens (  166.81 ms per token)
llama_print_timings:        eval time =  4977.97 ms /    31 runs   (  160.58 ms per token)
llama_print_timings:       total time =  6188.21 ms"><pre><code>% ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'A good game:\n\n'  

main: build = 645 (fd0eb66)
main: seed  = 1686286016
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 A good game:

Sir Thomas Gresham, when he was building his famous Exchange at London, had the following dialogue with a mason, whose name was Richard B
llama_print_timings:        load time =  1185.47 ms
llama_print_timings:      sample time =    21.57 ms /    32 runs   (    0.67 ms per token)
llama_print_timings: prompt eval time =  1167.67 ms /     7 tokens (  166.81 ms per token)
llama_print_timings:        eval time =  4977.97 ms /    31 runs   (  160.58 ms per token)
llama_print_timings:       total time =  6188.21 ms
</code></pre></div>
</details>
<details>
<summary>Arithmetic</summary>
<div data-snippet-clipboard-copy-content=" % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Some arithmetic practice:\n\n' \                      
--grammar 'root  ::= (expr &quot;=&quot; ws num &quot;\n&quot;)+
expr  ::= term ([-+*/] term)*
term  ::= ident | num | &quot;(&quot; ws expr &quot;)&quot; ws
ident ::= [a-z] [a-z0-9_]* ws
num   ::= [0-9]+ ws
ws    ::= [ \t\n]*'
main: build = 674 (e550234)
main: seed  = 1688014196
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


main: grammar:
root ::= root_5 
root_1 ::= expr [=] ws num [<U+000A>] 
expr ::= term expr_8 
ws ::= ws_12 
num ::= num_11 ws 
root_5 ::= root_1 root_5 | root_1 
term ::= ident | num | [(] ws expr [)] ws 
expr_7 ::= [-+*/] term 
expr_8 ::= expr_7 expr_8 | 
ident ::= [a-z] ident_10 ws 
ident_10 ::= [a-z0-9_] ident_10 | 
num_11 ::= [0-9] num_11 | [0-9] 
ws_12 ::= [ <U+0009><U+000A>] ws_12 | 

 Some arithmetic practice:

10 *a*1 +b*2 =640

10 *a*2 +b*3 =656


llama_print_timings:        load time =  1165.00 ms
llama_print_timings:      sample time =    41.11 ms /    32 runs   (    1.28 ms per token)
llama_print_timings: prompt eval time =  1147.76 ms /     7 tokens (  163.97 ms per token)
llama_print_timings:        eval time =  5113.92 ms /    31 runs   (  164.97 ms per token)
llama_print_timings:       total time =  6323.27 ms"><pre><code> % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Some arithmetic practice:\n\n' \                      
--grammar 'root  ::= (expr "=" ws num "\n")+
expr  ::= term ([-+*/] term)*
term  ::= ident | num | "(" ws expr ")" ws
ident ::= [a-z] [a-z0-9_]* ws
num   ::= [0-9]+ ws
ws    ::= [ \t\n]*'
main: build = 674 (e550234)
main: seed  = 1688014196
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


main: grammar:
root ::= root_5 
root_1 ::= expr [=] ws num [&lt;U+000A&gt;] 
expr ::= term expr_8 
ws ::= ws_12 
num ::= num_11 ws 
root_5 ::= root_1 root_5 | root_1 
term ::= ident | num | [(] ws expr [)] ws 
expr_7 ::= [-+*/] term 
expr_8 ::= expr_7 expr_8 | 
ident ::= [a-z] ident_10 ws 
ident_10 ::= [a-z0-9_] ident_10 | 
num_11 ::= [0-9] num_11 | [0-9] 
ws_12 ::= [ &lt;U+0009&gt;&lt;U+000A&gt;] ws_12 | 

 Some arithmetic practice:

10 *a*1 +b*2 =640

10 *a*2 +b*3 =656


llama_print_timings:        load time =  1165.00 ms
llama_print_timings:      sample time =    41.11 ms /    32 runs   (    1.28 ms per token)
llama_print_timings: prompt eval time =  1147.76 ms /     7 tokens (  163.97 ms per token)
llama_print_timings:        eval time =  5113.92 ms /    31 runs   (  164.97 ms per token)
llama_print_timings:       total time =  6323.27 ms
</code></pre></div>
</details>
<details>
<summary>Arithmetic - no grammar</summary>
<div data-snippet-clipboard-copy-content=" % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Some arithmetic practice:\n\n'                                            
main: build = 645 (fd0eb66)
main: seed  = 1686286388
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 Some arithmetic practice:

\begin{code}
package main

import (
    &quot;fmt&quot;
)

func main() {
    fmt.Println(
llama_print_timings:        load time =  1171.65 ms
llama_print_timings:      sample time =    21.37 ms /    32 runs   (    0.67 ms per token)
llama_print_timings: prompt eval time =  1153.88 ms /     7 tokens (  164.84 ms per token)
llama_print_timings:        eval time =  4991.68 ms /    31 runs   (  161.02 ms per token)
llama_print_timings:       total time =  6187.91 ms"><pre><code> % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Some arithmetic practice:\n\n'                                            
main: build = 645 (fd0eb66)
main: seed  = 1686286388
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 Some arithmetic practice:

\begin{code}
package main

import (
    "fmt"
)

func main() {
    fmt.Println(
llama_print_timings:        load time =  1171.65 ms
llama_print_timings:      sample time =    21.37 ms /    32 runs   (    0.67 ms per token)
llama_print_timings: prompt eval time =  1153.88 ms /     7 tokens (  164.84 ms per token)
llama_print_timings:        eval time =  4991.68 ms /    31 runs   (  161.02 ms per token)
llama_print_timings:       total time =  6187.91 ms
</code></pre></div>
</details>
<details>
<summary>JSON</summary>
<div data-snippet-clipboard-copy-content="% ./main -m $LLAMA_30B_Q4_0 -n 64 -p $'A bit about me:\n\n' --grammar-file grammars/json.gbnf
main: build = 674 (e550234)
main: seed  = 1688014289
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 64, n_keep = 0


main: grammar:
root ::= object 
object ::= [{] ws object_11 [}] 
value ::= object | array | string | number | boolean 
array ::= [[] ws array_15 []] 
string ::= [&quot;] string_16 [&quot;] ws 
number ::= number_17 number_18 ws 
boolean ::= boolean_19 ws 
ws ::= [ <U+0009><U+000A>] ws | 
object_8 ::= string [:] ws value object_10 
object_9 ::= [,] ws string [:] ws value 
object_10 ::= object_9 object_10 | 
object_11 ::= object_8 | 
array_12 ::= value array_14 
array_13 ::= [,] ws value 
array_14 ::= array_13 array_14 | 
array_15 ::= array_12 | 
string_16 ::= [ <U+0009>!#-[]-~] string_16 | 
number_17 ::= [-] | 
number_18 ::= [0-9] number_18 | [0-9] 
boolean_19 ::= [t] [r] [u] [e] | [f] [a] [l] [s] [e] 

 A bit about me:

{
	&quot;fullName&quot;: &quot;Ramon Rodriguez&quot;,
	&quot;username&quot;: &quot;ramon&quot;,
	&quot;email&quot;: &quot;ramon@mail.com&quot;,
	&quot;phoneNumber&quot;: &quot;+1234567890&quot;,
	&quot;address&quot;: {
		
llama_print_timings:        load time =  1273.70 ms
llama_print_timings:      sample time =    82.93 ms /    64 runs   (    1.30 ms per token)
llama_print_timings: prompt eval time =  1256.36 ms /     8 tokens (  157.04 ms per token)
llama_print_timings:        eval time = 10432.05 ms /    63 runs   (  165.59 ms per token)
llama_print_timings:       total time = 11795.36 ms"><pre><code>% ./main -m $LLAMA_30B_Q4_0 -n 64 -p $'A bit about me:\n\n' --grammar-file grammars/json.gbnf
main: build = 674 (e550234)
main: seed  = 1688014289
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 64, n_keep = 0


main: grammar:
root ::= object 
object ::= [{] ws object_11 [}] 
value ::= object | array | string | number | boolean 
array ::= [[] ws array_15 []] 
string ::= ["] string_16 ["] ws 
number ::= number_17 number_18 ws 
boolean ::= boolean_19 ws 
ws ::= [ &lt;U+0009&gt;&lt;U+000A&gt;] ws | 
object_8 ::= string [:] ws value object_10 
object_9 ::= [,] ws string [:] ws value 
object_10 ::= object_9 object_10 | 
object_11 ::= object_8 | 
array_12 ::= value array_14 
array_13 ::= [,] ws value 
array_14 ::= array_13 array_14 | 
array_15 ::= array_12 | 
string_16 ::= [ &lt;U+0009&gt;!#-[]-~] string_16 | 
number_17 ::= [-] | 
number_18 ::= [0-9] number_18 | [0-9] 
boolean_19 ::= [t] [r] [u] [e] | [f] [a] [l] [s] [e] 

 A bit about me:

{
	"fullName": "Ramon Rodriguez",
	"username": "ramon",
	"email": "ramon@mail.com",
	"phoneNumber": "+1234567890",
	"address": {
		
llama_print_timings:        load time =  1273.70 ms
llama_print_timings:      sample time =    82.93 ms /    64 runs   (    1.30 ms per token)
llama_print_timings: prompt eval time =  1256.36 ms /     8 tokens (  157.04 ms per token)
llama_print_timings:        eval time = 10432.05 ms /    63 runs   (  165.59 ms per token)
llama_print_timings:       total time = 11795.36 ms
</code></pre></div>
</details>
<details>
<summary>"JSON" - no grammar</summary>
<div data-snippet-clipboard-copy-content=" % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'A bit about me:\n\n'                                                                          
main: build = 645 (fd0eb66)
main: seed  = 1686286615
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 A bit about me:

A former teacher, now a full-time writer. I am the author of two novels: _The Man in the Moon_ and _The Riddle
llama_print_timings:        load time =  1291.32 ms
llama_print_timings:      sample time =    21.48 ms /    32 runs   (    0.67 ms per token)
llama_print_timings: prompt eval time =  1274.63 ms /     8 tokens (  159.33 ms per token)
llama_print_timings:        eval time =  4990.01 ms /    31 runs   (  160.97 ms per token)
llama_print_timings:       total time =  6306.01 ms"><pre><code> % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'A bit about me:\n\n'                                                                          
main: build = 645 (fd0eb66)
main: seed  = 1686286615
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 A bit about me:

A former teacher, now a full-time writer. I am the author of two novels: _The Man in the Moon_ and _The Riddle
llama_print_timings:        load time =  1291.32 ms
llama_print_timings:      sample time =    21.48 ms /    32 runs   (    0.67 ms per token)
llama_print_timings: prompt eval time =  1274.63 ms /     8 tokens (  159.33 ms per token)
llama_print_timings:        eval time =  4990.01 ms /    31 runs   (  160.97 ms per token)
llama_print_timings:       total time =  6306.01 ms
</code></pre></div>
</details>
<details>
<summary>Japanese</summary>
<div data-snippet-clipboard-copy-content=" % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Building a website can be done in 10 simple steps (from the original Japanese):\n\n' --grammar-file grammars/japanese.gbnf
main: build = 674 (e550234)
main: seed  = 1688013430
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


main: grammar:
root ::= root_2 root_5 
jp-char ::= hiragana | katakana | punctuation | cjk 
root_2 ::= jp-char root_2 | jp-char 
root_3 ::= [ <U+0009><U+000A>] root_4 
root_4 ::= jp-char root_4 | jp-char 
root_5 ::= root_3 root_5 | 
hiragana ::= [<U+3041>-<U+309F>] 
katakana ::= [<U+30A1>-<U+30FF>] 
punctuation ::= [<U+3001>-<U+303E>] 
cjk ::= [<U+4E00>-<U+9FFF>] 

 Building a website can be done in 10 simple steps (from the original Japanese):

一、目的は何なのか
二、お客さまを思い出して
三、お客さまのこと
llama_print_timings:        load time =  2957.19 ms
llama_print_timings:      sample time =    42.67 ms /    32 runs   (    1.33 ms per token)
llama_print_timings: prompt eval time =  2941.56 ms /    21 tokens (  140.07 ms per token)
llama_print_timings:        eval time =  5384.28 ms /    31 runs   (  173.69 ms per token)
llama_print_timings:       total time =  8387.61 ms"><pre><code> % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Building a website can be done in 10 simple steps (from the original Japanese):\n\n' --grammar-file grammars/japanese.gbnf
main: build = 674 (e550234)
main: seed  = 1688013430
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


main: grammar:
root ::= root_2 root_5 
jp-char ::= hiragana | katakana | punctuation | cjk 
root_2 ::= jp-char root_2 | jp-char 
root_3 ::= [ &lt;U+0009&gt;&lt;U+000A&gt;] root_4 
root_4 ::= jp-char root_4 | jp-char 
root_5 ::= root_3 root_5 | 
hiragana ::= [&lt;U+3041&gt;-&lt;U+309F&gt;] 
katakana ::= [&lt;U+30A1&gt;-&lt;U+30FF&gt;] 
punctuation ::= [&lt;U+3001&gt;-&lt;U+303E&gt;] 
cjk ::= [&lt;U+4E00&gt;-&lt;U+9FFF&gt;] 

 Building a website can be done in 10 simple steps (from the original Japanese):

一、目的は何なのか
二、お客さまを思い出して
三、お客さまのこと
llama_print_timings:        load time =  2957.19 ms
llama_print_timings:      sample time =    42.67 ms /    32 runs   (    1.33 ms per token)
llama_print_timings: prompt eval time =  2941.56 ms /    21 tokens (  140.07 ms per token)
llama_print_timings:        eval time =  5384.28 ms /    31 runs   (  173.69 ms per token)
llama_print_timings:       total time =  8387.61 ms
</code></pre></div>
</details>
<details>
<summary>Japanese - no grammar</summary>
<div data-snippet-clipboard-copy-content="% ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Building a website can be done in 10 simple steps (from the original Japanese):\n\n' 
main: build = 674 (e550234)
main: seed  = 1688013483
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 Building a website can be done in 10 simple steps (from the original Japanese):

1. Determine your goal for your site.
2. Make a plan.
3. Select the domain name.
4. Choose web
llama_print_timings:        load time =  2955.05 ms
llama_print_timings:      sample time =    22.96 ms /    32 runs   (    0.72 ms per token)
llama_print_timings: prompt eval time =  2937.10 ms /    21 tokens (  139.86 ms per token)
llama_print_timings:        eval time =  5032.41 ms /    31 runs   (  162.34 ms per token)
llama_print_timings:       total time =  8013.71 ms"><pre><code>% ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Building a website can be done in 10 simple steps (from the original Japanese):\n\n' 
main: build = 674 (e550234)
main: seed  = 1688013483
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 Building a website can be done in 10 simple steps (from the original Japanese):

1. Determine your goal for your site.
2. Make a plan.
3. Select the domain name.
4. Choose web
llama_print_timings:        load time =  2955.05 ms
llama_print_timings:      sample time =    22.96 ms /    32 runs   (    0.72 ms per token)
llama_print_timings: prompt eval time =  2937.10 ms /    21 tokens (  139.86 ms per token)
llama_print_timings:        eval time =  5032.41 ms /    31 runs   (  162.34 ms per token)
llama_print_timings:       total time =  8013.71 ms
</code></pre></div>
</details>
<h2 dir="auto">Approach</h2>
<h3 dir="auto">Grammar API</h3>
<p dir="auto">The <code>llama</code> API accepts a data structure representing a context-free grammar over 32-bit code points:</p>
<div data-snippet-clipboard-copy-content="    // grammar element type
    enum llama_gretype {
        // end of rule definition
        LLAMA_GRETYPE_END            = 0,

        // start of alternate definition for rule
        LLAMA_GRETYPE_ALT            = 1,

        // non-terminal element: reference to rule
        LLAMA_GRETYPE_RULE_REF       = 2,

        // terminal element: character (code point)
        LLAMA_GRETYPE_CHAR           = 3,

        // modifies a preceding LLAMA_GRETYPE_CHAR or LLAMA_GRETYPE_CHAR_ALT to
        // be an inclusive range ([a-z])
        LLAMA_GRETYPE_CHAR_RNG_UPPER = 4,

        // modifies a preceding LLAMA_GRETYPE_CHAR or
        // LLAMA_GRETYPE_CHAR_RNG_UPPER to add an alternate char to match ([ab], [a-zA])
        LLAMA_GRETYPE_CHAR_ALT       = 5,
    };

    typedef struct llama_grammar_element {
        enum llama_gretype type;
        uint32_t           value; // Unicode code point or rule ID
    } llama_grammar_element;

    LLAMA_API struct llama_grammar * llama_grammar_init(
            const llama_grammar_element ** rules,
                                 size_t    n_rules,
                                 size_t    start_rule_index);"><pre><code>    // grammar element type
    enum llama_gretype {
        // end of rule definition
        LLAMA_GRETYPE_END            = 0,

        // start of alternate definition for rule
        LLAMA_GRETYPE_ALT            = 1,

        // non-terminal element: reference to rule
        LLAMA_GRETYPE_RULE_REF       = 2,

        // terminal element: character (code point)
        LLAMA_GRETYPE_CHAR           = 3,

        // modifies a preceding LLAMA_GRETYPE_CHAR or LLAMA_GRETYPE_CHAR_ALT to
        // be an inclusive range ([a-z])
        LLAMA_GRETYPE_CHAR_RNG_UPPER = 4,

        // modifies a preceding LLAMA_GRETYPE_CHAR or
        // LLAMA_GRETYPE_CHAR_RNG_UPPER to add an alternate char to match ([ab], [a-zA])
        LLAMA_GRETYPE_CHAR_ALT       = 5,
    };

    typedef struct llama_grammar_element {
        enum llama_gretype type;
        uint32_t           value; // Unicode code point or rule ID
    } llama_grammar_element;

    LLAMA_API struct llama_grammar * llama_grammar_init(
            const llama_grammar_element ** rules,
                                 size_t    n_rules,
                                 size_t    start_rule_index);
</code></pre></div>
<h3 dir="auto">Sampling</h3>
<p dir="auto">The grammar sampling code models a nondeterministic pushdown automaton, maintaining N stacks for the possible parse states. Sampling a token is done in two steps: a sampling API that filters candidates to those that match one of the parse stacks (<code>llama_sample_grammar</code>) and adding the chose token to the grammar (<code>llama_grammar_accept_token</code>).</p>
<h3 dir="auto">Examples</h3>
<p dir="auto">Adds <code>--grammar</code> and <code>--grammar-file</code> arguments to <code>main</code> taking a simple extended BNF to constrain generations. The parser for this format is implemented in <code>examples/grammar-parser.{h,cpp}</code>:</p>
<div data-snippet-clipboard-copy-content="// ... Supports character
// ranges, grouping, and repetition operators. As an example, a grammar for
// arithmetic might look like:
//
// root  ::= expr
// expr  ::= term ([-+*/] term)*
// term  ::= num | &quot;(&quot; space expr &quot;)&quot; space
// num   ::= [0-9]+ space
// space ::= [ \t\n]*"><pre><code>// ... Supports character
// ranges, grouping, and repetition operators. As an example, a grammar for
// arithmetic might look like:
//
// root  ::= expr
// expr  ::= term ([-+*/] term)*
// term  ::= num | "(" space expr ")" space
// num   ::= [0-9]+ space
// space ::= [ \t\n]*
</code></pre></div>
<p dir="auto">The <code>root</code> rule identifies the start of the grammar.</p>
<p dir="auto"><del>## Caveats</del></p>
<ul dir="auto">
<li><del>the binary format makes the code harder to understand and more brittle</del></li>
<li><del>the grammar contemplates 16-bit chars but it's just being applied to the 8-bit UTF-8 chars in token strings currently</del></li>
<li><del>the 1-char lookahead sampling is probably biasing generations in a weird way; further investigation on quality of outputs is probably needed</del></li>
</ul>
    </div>
  </task-lists>
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FreeWilly 1 and 2, two new open-access LLMs (126 pts)]]></title>
            <link>https://stability.ai/blog/freewilly-large-instruction-fine-tuned-models</link>
            <guid>36818923</guid>
            <pubDate>Fri, 21 Jul 2023 20:03:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stability.ai/blog/freewilly-large-instruction-fine-tuned-models">https://stability.ai/blog/freewilly-large-instruction-fine-tuned-models</a>, See on <a href="https://news.ycombinator.com/item?id=36818923">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-block-type="2" id="block-92ab10ed08f1f3488e0d">
  <p>Stability AI and its <a href="https://carper.ai/" target="_blank"><span>CarperAI lab</span></a> are proud to announce <a href="https://huggingface.co/stabilityai/FreeWilly1-Delta-SafeTensor" target="_blank"><span>FreeWilly1</span></a> and its successor <a href="https://huggingface.co/stabilityai/FreeWilly2" target="_blank"><span>FreeWilly2</span></a>, two powerful new, open access, Large Language Models (LLMs). Both models demonstrate exceptional reasoning ability across varied benchmarks. FreeWilly1 leverages the original LLaMA 65B foundation model and was carefully fine-tuned with a new synthetically-generated dataset using Supervised Fine-Tune (SFT) in standard Alpaca format. Similarly, FreeWilly2 leverages the LLaMA 2 70B foundation model to reach a performance that compares favorably with GPT-3.5 for some tasks.</p><p>Both models are research experiments, and are released to foster open research under a non-commercial license. While we have conducted internal red-teaming to ensure the model remains polite and harmless, we welcome the community's feedback and help in further red-teaming.</p><p><strong>Data Generation and Collection</strong></p><p>The training for the FreeWilly models was directly inspired by the methodology pioneered by Microsoft in its paper: "Orca: Progressive Learning from Complex Explanation Traces of GPT-4.” While our data generation process is similar, we differ in our data sources.</p><p>Our variant of the dataset, containing 600,000 data points (roughly 10% of the dataset size the original Orca paper used), was created by prompting language models with high-quality instructions from the following datasets created by <a href="https://huggingface.co/conceptofmind" target="_blank"><span>Enrico Shippole</span></a>:</p><ol data-rte-list="default"><li><p><a href="https://huggingface.co/datasets/conceptofmind/cot_submix_original" target="_blank"><span>COT Submix Original</span></a></p></li><li><p><a href="https://huggingface.co/datasets/conceptofmind/niv2_submix_original" target="_blank"><span>NIV2 Submix Original</span></a></p></li><li><p><a href="https://huggingface.co/datasets/conceptofmind/flan2021_submix_original" target="_blank"><span>FLAN 2021 Submix Original</span></a></p></li><li><p><a href="https://huggingface.co/datasets/conceptofmind/t0_submix_original" target="_blank"><span>T0 Submix Original</span></a></p></li></ol><p>With this approach, we generated 500,000 examples with one simpler LLM model and an additional 100,000 with a more sophisticated LLM model. To ensure fair comparisons, we carefully filtered these datasets and removed examples that originated from evaluation benchmarks. Despite training on one-tenth the sample size of the original Orca paper (significantly reducing the cost and carbon footprint of training the model compared to the original paper), the resulting FreeWilly models demonstrate exceptional performance across various benchmarks – validating our approach to synthetically generated datasets.</p><p><strong>Performance Evaluation</strong></p><p>To internally evaluate these models, we used EleutherAI’s <a href="https://github.com/EleutherAI/lm-evaluation-harness" target="_blank"><span>lm-eval-harness</span></a>, to which we added <a href="https://github.com/dmahan93/lm-evaluation-harness/tree/add-agieval" target="_blank"><span>AGIEval</span></a>.</p><p>Both FreeWilly models excel in many areas, including intricate reasoning, understanding linguistic subtleties, and answering complex questions related to specialized domains, e.g. Law and mathematical problem-solving.</p><p><strong>Open LLM Leaderboard benchmarks:</strong></p><p>These FreeWilly results were evaluated by Stability AI researchers and independently reproduced by Hugging Face on July 21st, 2023, and published in their leaderboard.</p>
</div><div data-block-type="2" id="block-yui_3_17_2_1_1689965544627_21970">
  <p><strong>Contributing to an open future</strong></p><p>FreeWilly1 and FreeWilly2 set a new standard in the field of open access Large Language Models. They both significantly advance research, enhance natural language understanding, and enable complex tasks. We are excited about the endless possibilities that these models will bring to the AI community, and the new applications they will inspire.</p><p>We would like to express our sincere gratitude to our passionate team of researchers, engineers, and collaborators, whose remarkable efforts and dedication have enabled us to reach this significant milestone.</p><p>Stay tuned for more exciting developments, and begin exploring the incredible potential of FreeWilly today!</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Journalists should be skeptical of all sources including scientists (439 pts)]]></title>
            <link>https://natesilver.substack.com/p/journalists-should-be-skeptical-of</link>
            <guid>36818896</guid>
            <pubDate>Fri, 21 Jul 2023 20:01:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://natesilver.substack.com/p/journalists-should-be-skeptical-of">https://natesilver.substack.com/p/journalists-should-be-skeptical-of</a>, See on <a href="https://news.ycombinator.com/item?id=36818896">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>I’m not usually one for scandals. My eyes glaze over at Congressional hearings. I’ve never read the Mueller Report. There are usually too many threads to unwind, and too many competing claims to evaluate. But I’m going to make an exception here, because we have a scandal where the facts are relatively simple and clear — but which was nevertheless extremely consequential.</p><p><span>Here’s the scandal. In March 2020, a group of scientists — in particular</span></p><p><span>, Kristian G. Andersen the of The Scripps Research Institute, Andrew Rambaut of The University of Edinburgh, Edward C. Holmes of the University of Sydney, and Robert F. Garry of Tulane University — published a paper in </span><em>Nature Medicine</em><span> that seemingly contradicted their true beliefs about COVID’s origins and which they knew to be misleading. The </span><a href="https://www.nature.com/articles/s41591-020-0820-9" rel="">paper</a><span>, “The proximal origin of SARS-CoV-2”, has been </span><a href="https://scholar.google.com/scholar?cites=4180430536993184356&amp;as_sdt=5,33&amp;sciodt=0,33&amp;hl=en" rel="">cited more than 5,900 times</a><span> and was enormously influential in shaping the debate about the origins of COVID-19.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp" width="820" height="385" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:385,&quot;width&quot;:820,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:31870,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>We know this because of a series of leaked and </span><a href="https://foia.state.gov/learn/foia.aspx" rel="">FOIAed</a><span> emails and Slack messages that have been reported on by </span><em>Public</em><span>, </span><em>Racket News, The Intercept </em><span>and </span><em>The Nation </em><span>along with other small, independent media outlets. You can find a detailed summary of the claims and a copy of the emails and messages </span><a href="https://public.substack.com/p/covid-origins-scientist-denounces" rel="">here</a><span> at </span><em>Public</em><span>. There’s also good context around the messages </span><a href="https://usrtk.org/covid-19-origins/timeline-the-proximal-origin-of-sars-cov-2/" rel="">here</a><span> (very detailed) or </span><a href="https://rogerpielkejr.substack.com/p/covidgate" rel="">here</a><span> and </span><a href="https://rogerpielkejr.substack.com/p/the-truth-is-never-going-to-come" rel="">here</a><span> (more high-level). </span></p><p><span>The messages show that the authors were highly uncertain about COVID’s origins — and if anything, they leaned more toward a lab leak than a spillover from an animal source. But none of that was expressed in the “Proximal Origin” paper, which instead said that </span><strong>“we do not believe that any type of laboratory-based scenario is plausible”.</strong><span> Granted, there is a little bit of ass-covering — “More scientific data could swing the balance of evidence to favor one hypothesis over another,” they also wrote in the paper. But the message — natural origin good, lab leak bad — was received clearly enough by mainstream news outlets. “No, the new coronavirus wasn't created in a lab, scientists say”, </span><a href="https://www.cbc.ca/news/science/coronavirus-wasnt-created-in-lab-no-signs-genetic-engineering-1.5508735" rel="">reported</a><span> the CBC in covering the paper. “COVID-19 coronavirus epidemic has a natural origin” was the </span><a href="https://www.sciencedaily.com/releases/2020/03/200317175442.htm" rel="">headline</a><span> at Science Daily.</span></p><p><span>In the Slack and email messages, the authors worked to manipulate the media narrative about COVID-19’s origins and to ensure that their private uncertainty wasn’t conveyed in conversations with reporters. They also thought they were going to get away with it. “The truth is never going to come out ”, </span><a href="https://twitter.com/mbalter/status/1679098392587255809/photo/1" rel="">wrote</a><span> Rambaut in one message. This went beyond mere motivated reasoning. There was an enormous gap between what the authors believed privately and what they stated publicly, including in the “Proximal Origin” paper — again, see the above links for more detail.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png" width="1456" height="182" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:182,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:93385,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 1456w" sizes="100vw"></picture></div></a></figure></div><p><span>What were the authors’ motivations to mislead the public? I think that’s also pretty straightforward. In fact, you can find prominent virologists </span><a href="https://www.nature.com/articles/d41586-021-01383-3" rel="">quoted on record</a><span> as to why the lab leak theory was so </span><em>problematic</em><span> — even if it wasn’t necessarily </span><em>wrong</em><span>. The problems fall into three buckets:</span></p><ol><li><p><span>Evidence of a lab leak could cause a political backlash — understandably, given that COVID has killed almost 7 million people — resulting in a reduction in funding for gain-of-function research and other virological research. That’s potentially important to the authors or the authors’ bosses — and the authors were </span><a href="https://twitter.com/HansMahncke/status/1682193300055285760?s=20" rel="">very aware</a><span> of the career implications for how the story would play out;</span></p></li><li><p><span>Evidence of a lab leak could </span><a href="https://www.nytimes.com/2023/02/27/business/energy-department-theory-coronavirus-china.html" rel="">upset China and undermine research collaborations</a><span>;</span></p></li><li><p><span>Evidence of a lab leak could provide validation to Trump and Republicans who </span><a href="https://www.politico.com/news/2021/06/15/wuhan-lab-trump-officials-covid-494700" rel="">touted the theory</a><span> — remember, all of this was taking place during an election year, and medical, epidemiological and public health experts had few reservations about </span><a href="https://www.cnn.com/2020/06/05/health/health-care-open-letter-protests-coronavirus-trnd/index.html" rel="">weighing in on political matters</a><span>.</span></p></li></ol><p><span>To be clear, I’m not sure how COVID originated either. I’d “buy” the lab leak at a 50 percent likelihood (I think </span><a href="https://alexwasburne.substack.com/p/the-short-case-for-a-lab-origin" rel="">this</a><span> is pretty convincing) and sell it at 80 percent, which still leaves a lot of wiggle room for me to be persuaded one way or the other.</span></p><p>But I think this is a big scandal either way. As someone who has spent a lot of time trying to convey statistical and epistemic uncertainty to the public, I’m deeply disappointed by the scientists’ conduct here and how unmoored they were from any attempt at truth-seeking.</p><p><span>The COVID origins story has also been a </span><a href="https://www.slowboring.com/p/the-medias-lab-leak-fiasco" rel="">journalistic fiasco</a><span>, with the lab leak having been dismissed as a “</span><a href="https://www.nytimes.com/2020/02/17/business/media/coronavirus-tom-cotton-china.html" rel="">conspiracy theory</a><span>” and as </span><a href="https://www.nytimes.com/2020/03/08/technology/coronavirus-misinformation-social-media.html" rel="">misinformation</a><span> even though many prominent scientists believed it to be plausible all along. Perhaps it’s tempting to give the media a pass — they </span><em>were</em><span> manipulated by the “Proximal Origin” authors, after all. But I’m not inclined to, for two reasons.</span></p><p><span>First, the coverage of the recently leaked emails and Slack messages at major center-left outlets like The New York Times has been pathetic. The Times </span><a href="https://www.nytimes.com/2023/07/11/us/politics/covid-lab-leak-fauci.html" rel="">portrayed</a><span> Andersen as the victim of a Republican witch-hunt — rather than someone at the center of a major scientific scandal of his own making.</span></p><p><span>And second, journalists ought to have decent bullshit detectors — including toward scientists, academics and other experts.</span></p><p><span>Maybe you think Andersen </span><em>et. al.</em><span> are bad apples, but the messages make clear that they were speaking for a pretty broad swath of the scientific community. Still — and maybe this is wishful thinking — but I’m going to assert that people like him are in the minority among scientists. I fairly often speak with scientists and academics myself — especially when I’m working on a research-driven book project, as I am now — and those experiences are overwhelmingly positive.</span></p><p><span>And yet, even if the incidence of bad apples is relatively rare among scientists and academics — rarer than it might be among politicians or other groups that journalists intrinsically treat with more skepticism — it’s clearly not </span><em>exceedingly</em><span> rare. It was just this week that the </span><a href="https://stanforddaily.com/2023/07/19/stanford-president-resigns-over-manipulated-research-will-retract-at-least-3-papers/" rel="">president of Stanford was forced to resign in a research scandal</a><span>. (Perhaps not coincidently, the scandal was broken by the student newspaper, </span><em>The Stanford Daily</em><span>, and not by a major center-left outlet like The Times.)</span></p><p><span>I also think journalists are more prone toward being manipulated by bad apples in academia and science than they were ten or twenty years ago. As a result of</span><a href="https://www.nytimes.com/2021/09/08/us/politics/how-college-graduates-vote.html" rel=""> increasing educational polarization</a><span>, both journalists and the expert class of scientists and academics are far more aligned politically than they once were (the very large majority are left-of-center and vote Democratic in American elections). Even if “trust the science” or “trust the experts” is </span><em>usually</em><span> right — and I think it </span><em>usually</em><span> is right! — it leaves an opening for bad apples like Andersen to exploit the trust that honest scientists have worked so hard to earn.</span></p><p><span>There’s also a generational divide in journalism, with younger journalists tending to be more openly left/progressive than their older peers — and tending to be more </span><a href="https://www.vocabulary.com/dictionary/Manichean" rel="">Manichean</a><span> in dividing the world between good and evil rather than proceeding from the notion that people and news stories are complicated and it’s not particularly their job to pass moral judgment. It’s slightly amusing that The Times fired their Pulitzer Prize-winning coronavirus reporter in middle of the pandemic — a reporter who </span><a href="https://donaldgmcneiljr1954.medium.com/how-i-learned-to-stop-worrying-and-love-the-lab-leak-theory-f4f88446b04d" rel="">saw the lab leak theory as credible</a><span> — and replaced him with another reporter who </span><a href="https://www.cnn.com/2021/05/27/media/covid-19-origins-lab-leak-media/index.html" rel="">dismissed discussion of the lab leak as “racist”</a><span>. </span></p><p>But this really isn’t complicated. All I’m suggesting is that journalists ought to treat scientists like they do any other source — that is to say, with an appropriate dose of skepticism.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Big Tech as the New Big Tobacco (175 pts)]]></title>
            <link>https://www.bigtechwiki.com/index.php/Big_Tech_as_the_New_Big_Tobacco</link>
            <guid>36818640</guid>
            <pubDate>Fri, 21 Jul 2023 19:44:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bigtechwiki.com/index.php/Big_Tech_as_the_New_Big_Tobacco">https://www.bigtechwiki.com/index.php/Big_Tech_as_the_New_Big_Tobacco</a>, See on <a href="https://news.ycombinator.com/item?id=36818640">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="bodyContent">
				<p>From BigTechWiki</p>
				
				
				<p><a href="#column-one">Jump to navigation</a><a href="#searchInput">Jump to search</a></p><!-- start content -->
				<div id="mw-content-text" lang="en" dir="ltr"><ul><li>Republicans and Democrats began to view Big Tech in the light Big Tobacco was, with one saying the comparison was “an appropriate analogy”</li></ul>
<ul><li>Lawmakers like Republicans Ken Buck and Cynthia Lummis and Democrat Ed Markey compared Facebook and Big Tech to Big Tobacco. Markey described Instagram as “that first childhood cigarette, meant to get teens hooked early.” Lummis agreed that comparing Facebook and Big Tech to Big Tobacco was an “appropriate analogy.” Republican Rep. Bill Johnston compared Big Tech CEOs to those from large tobacco companies, accusing the tech firms of being equally dangerous to society. Buck compared big tech to big tobacco, saying they were “harming our kids for profit.” Richard Blumenthal, who led a lawsuit against Big Tobacco in the 1990s as AG of CT, said Facebook and Big Tech were facing a “Big Tobacco moment,” comparing Facebook’s strategy papers with those done by Tobacco companies on reaching middle schoolers.<sup id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup></li></ul>
<ul><li>Big Tech directly followed in Big Tobacco’s footsteps by funding academic research
<ul><li>Big Tobacco had a long history of commissioning and funding academic research to pull focus away from the proven harms of their products. Big Tech similarly started to fund institutions to ensure the “ethical development” of their technology, which led to questions about conflicts of interest and research independence. Researchers from Cornell noted that Big Tech and Big Tobacco’s funding of scientific research and development were similar in both industries: “Pump vast sums of money” into researching the problems they were creating.<sup id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup></li>
<li>Both Big Tech and Big Tobacco wanted to influence research to ensure their industries sustained support and were seen as socially responsible. Researchers from Cornell said Big Tobacco invested in Academia in order to influence the research questions of those studying tobacco, hoping to find friendly academics who could be leveraged and recast the companies as socially responsible. Big Tobacco’s funding agencies worked to maintain an impartial and scientific image, even as it mainly funded research that was not about tobacco’s health impacts.</li>
<li>Much like Big Tobacco, the Academics that Big Tech invested in routinely failed to disclose their funding from Big Tech, which created a false impression of independence. The whole goal of funding the research was to exploit the confidence that is had in academia and research, because Think Tanks and organizations were treated as “neutral arbiters” by journalists and lawmakers.</li>
<li>At Big Tech funded agencies, public relations officials and lawyers were involved in plotting the overall research direction and tone. Internal Google documents directed scientists to “strike a positive tone” in their research. Further internal memos from Google showed that the company intended to use friendly academics as a key aim in its strategy to lobby against the EU’s Digital Markets Act. Big Tobacco has given hundreds of millions to research over the years and their efforts spanned across the globe. Big tobacco started its own research group, The Tobacco Industry Research Committee, in 1964 and pumped more than $130 million into the effort by 1986.</li>
<li>Big Tobacco continued this trend of investing in research across the globe, giving tens of thousands of Pounds to two think tanks in the UK that advised the government on Tobacco laws. The two think tanks criticized plans to force retailers to sell cigarettes in unbranded cartons, which was a measure supported by cancer charities and opposed by Big Tobacco. In 2019, it was reported that Tobacco companies had contributed to at least 106 think tanks in two dozen countries. The think tanks they contributed to were found to oppose plain cigarette packaging, had written to regulators in support of new tobacco products or promoted industry funded research. Big Tobacco also contributed to The Heritage Foundation, the Cato Institute and Americans For Tax Reform. As Big Tech faced pressure from proposed tech legislation, they significantly increased their spending on outside organizations, giving to nearly 771 third party organizations since 2015. A significant spike in funding of outside groups by Big Tech after federal and state officials increased scrutiny on their anti-competitive behaviors. Amazon went from contributing to 45 outside organizations in 2015 to 251 outside organizations in 2020. Google more than doubled the amount of outside groups it gave to in 2018 and 2019 compared to 2017 as it faced pressures from California’s consumer privacy law. All of this increased spending by Big Tech put a heavy pressure on academic staff to seek external sources of funding.<sup id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup></li>
<li>Who Big Tech gives to and how much they contributed is murky, as think tanks and nonprofits aren’t required to disclose their funding. Despite Amazon, Facebook and Google voluntarily disclosing who they contributed to, the companies did not divulge the amounts of their contributions.</li>
<li>However, it was found that in the past 5 years, six leading academic institutes in the EU had taken tens of millions of pounds of funding from Google, Facebook, Amazon and Microsoft to research issues linked to the tech firm’s business models. The Institute For Ethics In Artificial Intelligence at the Technical University of Munich received a $7.5 million grant from Facebook in 2019. The Humboldt Institute for Internet and Society in Berlin accepted almost 14 million Euros from Google since it was founded in 2012.<sup id="cite_ref-4"><a href="#cite_note-4">[4]</a></sup></li>
<li>In the U.S., Big Tech individually contributed to various renowned and highly influential think tanks and nonprofits. Those think tanks and nonprofits included but are not limited to the Cato Institute, Heritage Foundation, International Center for Law &amp; Economics, the Information Technology &amp; Innovation foundation and the Global Antitrust Institute at George Mason University.</li>
<li>Big Tech was rewarded handsomely for their contributions to nonprofits and think tanks. Some lobbyists, scholars and think tank officials argued that Google’s donations to nonprofit groups helped explain why it had avoided damaging regulatory and enforcement decisions in the U.S. Further, the major nonprofits that Big Tech had contributed to helped facilitate introductions between the government and Big Tech.</li>
<li>The Global Antitrust Institute at George Mason University had trained more than 850 foreign judges and regulators on Antitrust at their seminars.</li>
<li>While not all of the nonprofits and think tanks held events on behalf of Big Tech, many did advocate for Big Tech in other ways. The Cato Institute argued publicly that people should be “extremely skeptical about predictions of entrenched monopoly power” for big tech. The Progressive Policy Institute president and founder Will Marshall published an op-ed arguing against breaking up Big Tech monopolies while simultaneously calling them “innovative and successful.”</li></ul></li>
<li>Big Tobacco was a lobbying “juggernaut” that invented the special interest lobbying model Big Tech used
<ul><li>In 1998, the Big Tobacco spent nearly $73 million on federal lobbying and employed over 200 lobbyists. When adjusted for inflation, the #73 million in 1998 equated to $122 million in 2021. The Dean of Harvard’s graduate school of arts and sciences said Big Tobacco had “invested in the kind of special interest lobbying” that characterized the late 20th and early 21st century American politics. Big Tobacco was known for their “giant spending” and effective lobbying.</li>
<li>Big Tobacco was said to have a “substantial” presence on Capitol Hill and had a lobbying effort so large it could only be described as a “juggernaut” by OpenSecrets. The Dean of Harvard’s graduate school of arts and sciences said Big Tobacco spent “boatloads” of money in Congress to prevent regulation as more information became public about the harm their products caused. Still to this day, Big Tobacco employed a massive amount of lobbyists, with Altria employing at least 409 lobbyists in 49 states and Reynolds employing 257 lobbyists in 39 states.</li>
<li>Big Tobacco were also big spenders politically in the 90’s and early 2000’s. In 1996, the tobacco industry contributed more than $10 million to political campaigns. In 1998, they contributed more than $8.6 million. In 2000, Big Tobacco again spent more than $8.6 million on political campaigns. And in 2002, Big Tobacco spent $9.29 million on political campaigns. Reynolds American and Altria Group also donated $1.5 million to Donald Trump’s inauguration.</li></ul></li>
<li>Big Tech invested in lobbying to the same degree that Big Tobacco did and have similarly become Washington lobbyists biggest cash cow
<ul><li>A June 2021 NY Times headline read “Tech Giants, Fearful of Proposals to Curb Them, Blitz Washington With Lobbying.” And in 2020, Big Tech spent more on lobbying than any other industry at a combined $51.72 million. Facebook spent the most out of any company in 2020 and the same year spent the most it ever had on lobbying: $19.68 million. Following in second was Amazon, who spent $17.86 million on lobbying, which was also the most the company had ever spent in a year on lobbying. Google spent $7.53 million on lobbying and Apple spent $6.6 million on lobbying in 2020. When asked what they were looking to achieve with their lobbying, none of the tec companies would detail their targets.<sup id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup></li></ul></li>
<li>Big Tobacco created the model for Big Tech’s pre-empting legislation and regulation Big Tobacco offered to fund research and write legislation that would carve ou several loopholes and prevent stricter rules in the future
<ul><li>Starting in the 1980s, Big Tobacco worked to pre-empt legislation with their own corporate-written legislation, a trend that continued into recent policy debates over the legal age to buy tobacco products. Big Tobacco had worked to pre-empt laws to raise the legal age to buy smoking products from 18 to 21 by pushing new legislation that would make enforcement difficult and nullify tougher local laws. A spokesman for the Campaign For Tobacco-Free Kids argued that Big Tobacco were “masters at proposing or supporting a bill that looked good on the surface but often included provisions that [were] harmful to public health.”</li>
<li>By pre-empting legislation, Tobacco was able to halt any local efforts to limit how tobacco used. It was said that by pre-empting legislation with their own corporate-backed bills, Big Tobacco could effectively tie the hands of city governments who wanted to limit tobacco use further. Tobacco companies had been working to pre-empt legislation for decades, including pre-empting versions of the Clean Indoor Air Acts in the 1980s and 1990s. In 1994, a Philip Morris Employee even wrote that the company was “dead serious about achieving pre-emption in all 50 states.”</li></ul></li>
<li>Big Tech followed suit and began supporting legislation they felt they could control to build goodwill after scandals ravaged the industry
<ul><li>Following the Cambridge Analytica scandal, Facebook appeared to back some government regulation. The company launched a new campaign that offered concessions on the Big Tech regulatory debate to generate some goodwill while trying to reframe the larger debate on its own terms. Zuckerberg said in testimony that he welcomed privacy and misinformation regulation as long as it was the “right regulation.”</li>
<li>Zuckerberg went so far as to call on congress to make “thoughtful reform” of Section 230, which safeguarded tech platforms from being held liable for content individual users posted. Zuckerberg said a company’s liability protection under Section 230 should be conditional on their ability to prove they can moderate harmful content – regardless if it successfully removed all harmful content. Zuckerberg's proposal for Section 230 immunity reforms “could theoretically shore up Facebook’s power” as it forced smaller social media companies and startups to develop costly content moderation systems. However, Facebook executives testified before Congress that they wanted Congress to pre-empt local laws that likely included stricter privacy protections than a federal bill.</li>
<li>Ironically, just weeks before Zuckerberg’s 2018 testimony, Facebook poured hundreds of thousands into fighting a privacy ballot initiative in California. Facebook gave $200,000 to a PAC dedicated to defeating “a state ballot initiative that would expand Californian’s privacy controls. After his testimony, Facebook withdrew support for the group and then declined to say if they were involved in other efforts to oppose privacy legislation.</li></ul></li>
<li>Big Tech also used more subtle means to influence policy, like leaning heavily and quietly on trade associations.
<ul><li>A Big Tech lobbyist admitted that there was “strength in numbers” and said Big Tech could use trade associations to “do a little bit of heavy lifting.” Big Tech had increasingly been leaning on industry associations to influence public policy in Washington. Lobbyist Kate Mills, a partner at a Amazon-hired lobbying firm, admitted that Big Tech’s strategy involved leaning heavily and quietly on trade associations.</li>
<li>Amazon, Facebook and Google funded a bevy of political groups that had helped push positive polling and engaged in other “fingerprint-free tactics” designed to deter regulators seeking to break up or penalize the industry. An advocacy group funded by Big Tech had secretly written an op-ed for a local small businessman in Arizona that opposed the state’s investigation into Google. The small business owner was unaware Google had backed the group that approached him to publish the op-ed.</li>
<li>In a single year, Amazon reported spending $6.36 million on state focused “government relations efforts” in 44 states.</li></ul></li></ul>
<ul><li>Big Tech supported a wide range of industry associations that advocated and lobbied for them in D.C.
<ul><li>Big Tech has contributed to a wide range of industry associations, including but not limited to NetChoice, U.S. Chamber of Commerce, The Consumer Technology Association, The Competitive Enterprise Institute, Americans for Tax Reform, TechNet, The Small Business &amp; Entrepreneurship Council, The Internet Association and ComPITA</li>
<li>The various organizations pushed for Big Tech’s goals and defended them when they came under fire. NetChoice, “Tech’s most aggressive lobbying presence in D.C.” was a vocal opponent of antitrust action against Google. NetChoice attacked Texas’ lawsuit against Google’s anticompetitive advertising practices and attacked the DOJ’s antitrust lawsuit against Google.</li>
<li>The Consumer Technology Association spent $10 million on lobbying for Big Tech and opposed local tech regulations on their behalf. The Consumer Technology Association counted Facebook, Alphabet, Apple and Amazon as members. The group opposed proposed right to repair laws in Nevada and elsewhere.</li>
<li>Other organizations provided extra support for Big Tech when they were railing against antitrust or privacy legislation. The Progressive Policy Institute joined Google, Facebook and Amazon (all of which were donors) when the companies were fighting back against Senator Warren’s call to break up Big Tech. Facebook’s Lobbyist co-chaired a technology council at the Illinois Chamber of Commerce as the Chamber was backing the gutting of an online privacy law.</li>
<li>Facebook turned to a lower-profile trade groups such as The Internet Association and CompTIA to help block privacy legislation. 21 days after a judge ruled against Facebook in a biometric privacy act lawsuit, a Facebook backed law weakening Illinois’ biometric privacy act was introduced in the Illinois state legislature. Facebook and CompTIA were directly described as “having a hand in blocking or weakening biometric privacy bills in Montana, Washington, And Illinois.”</li>
<li>CompTIA pushed for changes to the biometric information privacy act on Facebook’s behalf, along with donating to the Republican Party of Texas, where the Republican Attorney General was the sole enforcer of the State’s Biometric Privacy Regulations</li>
<li>In 2020, Facebook launched an astroturf organization to convince federal regulators that Facebook was crucial to free speech. Facebook created American Edge to combat potential federal regulations through advertising and other means. After American Edge was formed as a nonprofit organization, it set up an accompanying social welfare group, which was a common tactic used to obscure donors. American Edge said it was important to create policies that don’t weaken companies that “share American values” as they competed globally.</li></ul></li>
<li>Much like Big Tobacco was in the 90s, Big Tech became mammoth political donors, collectively spending more than $100 million between 2016-2020
<ul><li>Most of Big Tech’s campaign contributions went towards Democrats, which increased year by year as Democrats grew louder about tech reform. Between 2016-2020, Alphabet, Google’s parent company, contributed more than $44 million in political donations. Between 2018-2020, Amazon contributed more than $26 million to political campaigns. Apple contributed more than $12 million to political campaigns between 2016-2020 and Facebook contributed more than $18 million to political campaigns between 2016-2020. Facebook also donated to all four co-sponsors of an Illinois bill to weaken the 2008 biometric information privacy act.</li></ul></li>
<li>Adding to their influence campaigns, Big Tech followed Big Tobacco’s playbook of employing revolving door techniques both Big Tobacco and Big Tech have had former employees in high level government positions and have hired former high level government officials
<ul><li>Big Tobacco found a way to deeply ingratiate themselves with the Trump and Bush administrations. Several top Bush administration staffers had backgrounds in Tobacco, including Senior Adviser Karl Rove. Vice President Pence had extensive ties to the Tobacco industry, receiving $39k in donations from RJ Reynolds and more than $60k from the industry group National Association of Convenience Stores. Senator Blumenthal noted that many of Trump’s appointees had “deep commitments to the Tobacco industry.” Former head of the FDA Scott Gottlieb worked for the e-cigarette company Kure and condemned the influence of Anti-tobacco “activists” in the FDA. The former Solicitor General Noel Francisco represented RJ Reynolds on behalf of the corporate law firm Jones Day prior to joining the federal government.</li>
<li>Big Tobacco also hired former Trump Officials as lobbyists. RJ Reynolds hired former Health and Human Services Secretary Tom Price’s deputy Chief of Staff as their lobbyists.</li>
<li>Google had an ally in the DOJ’s antitrust division during the Trump Administration and a former FTC commissioner joined a law firm Google had hired. Makan Delrahim, who led the DOJ antitrust division under Donald Trump, formerly worked on behalf of Google. After leaving office, former FTC commissioner Joshua Wright joined a law firm that represented Google before the FTC.</li></ul></li>
<li>Big Tobacco and Big Tech had a habit of running from their names after losing public trust in 2003, Philip Morris changed its name to ‘Altria Group’ after public started to feel their name “meant death”
<ul><li>Philip Morris said the name change brought “clarity” to its corporation and operating companies. In 2003, Philip Morris changed its name to ‘Altria Group’. The company said the name change brought “clarity” to its corporate structure and the relationship between the parent company to its operating companies. Philip Morris’ Senior Vice President at the time said “When people say ‘Philip Morris’, people don’t know which company you’re talking about [...] We’re more than a tobacco company.”</li>
<li>Philip Morris also owned Kraft Foods along with their tobacco company</li>
<li>In reality, the name change was a financial decision brought as a way to distance the company from the “death” people associated with them. A former FDA commissioner said Philip Morris was “running away from tobacco” with their name change. The company’s connection with Tobacco had long depressed its stock price, despite being the largest packaged goods company. To consumers, Philip Morris meant tobacco, and tobacco meant death.</li></ul></li>
<li>Facebook planned to change its company name to ‘Meta’ after facing fire for spreading misinformation
<ul><li>Facebook planned to change the name of its company to ‘Meta’ as a signal of its ambition to be known for more than social media. Facebook was reportedly investing in what it called the ‘Metaverse’ which was a digital world where people used various devices to engage with each other in a 3d environment.</li>
<li>The name change came after internal memos leaked showing the company knew about the damage it caused society. At the time of the name change, Facebook was facing some of the most intense scrutiny in its history after an internal whistleblower had leaked internal documents showing Facebook knew about the harmful effects it was having.</li>
<li>Much like Philip Morris, Facebook’s renaming was seen as a way to distance itself from the social networking controversies it was facing. TV personality Jim Cramer kind of let the cat out of the bag when he said the secret of Facebook’s valuation was because of its “habit of reinvention” Facebook’s name change was seen as directly resembling Philip Morris’ decision to change their name after controversies plagued the company. Fast Company said “for a company that brisle[d] at references to its services being akin to cigarettes, taking a page from the Big Tobacco playbook [was] a stunner.” But at the end of the day, the name change would have no impact on Facebook’s operations or executive structure. The change was largely cosmetic.<sup id="cite_ref-6"><a href="#cite_note-6">[6]</a></sup></li></ul></li>
<li>Big Tech spent more on federal lobbying from 2010-202 than the nation’s largest banks from 2000-2010 or Big Tobacco from 1996-1999
<ul><li>Since 2000, the four largest Big Tech companies – Amazon, Apple, Alphabet/Google, and Facebook – have spent $465,026,307 on federal lobbying. $434,474,221 of that total has come since 2010.</li>
<li>Additionally, nine groups that the four Big Tech companies fund have spent $98,061,827 on federal lobbying since 2000. $80,400,019 of that total has come since 2010.</li>
<li>Big Tech’s federal lobbying total eclipses that of other major toxic industries: Since 2010, the nation’s largest opioid manufacturers have spent $282,292,834 on federal lobbying. America’s seven largest banks in the leadup to the financial crisis spent $194,193,858 on federal lobbying from 2000 to 2010. From 1996 to 1999, the nation’s largest tobacco companies spent $155,750,398 on federal lobbying, or $261,306,596 in 2021 dollars.</li></ul></li></ul>
<div><ol>
<li id="cite_note-1"><span><a href="#cite_ref-1">↑</a></span> <span><a rel="nofollow" href="https://www.nytimes.com/2021/10/09/technology/facebook-big-tobacco-regulation.html">https://www.nytimes.com/2021/10/09/technology/facebook-big-tobacco-regulation.html</a></span>
</li>
<li id="cite_note-2"><span><a href="#cite_ref-2">↑</a></span> <span><a rel="nofollow" href="https://arxiv.org/abs/2009.13676">https://arxiv.org/abs/2009.13676</a></span>
</li>
<li id="cite_note-3"><span><a href="#cite_ref-3">↑</a></span> <span><a rel="nofollow" href="https://www.theguardian.com/business/ng-interactive/2019/jan/23/free-market-thinktanks-tobacco-industry">https://www.theguardian.com/business/ng-interactive/2019/jan/23/free-market-thinktanks-tobacco-industry</a></span>
</li>
<li id="cite_note-4"><span><a href="#cite_ref-4">↑</a></span> <span><a rel="nofollow" href="https://www.newstatesman.com/science-tech/big-tech/2021/07/how-google-quietly-funds-europe-s-leading-tech-policy-institutes">https://www.newstatesman.com/science-tech/big-tech/2021/07/how-google-quietly-funds-europe-s-leading-tech-policy-institutes</a></span>
</li>
<li id="cite_note-5"><span><a href="#cite_ref-5">↑</a></span> <span><a rel="nofollow" href="https://www.nytimes.com/2021/06/22/technology/amazon-apple-google-facebook-antitrust-bills.html">https://www.nytimes.com/2021/06/22/technology/amazon-apple-google-facebook-antitrust-bills.html</a></span>
</li>
<li id="cite_note-6"><span><a href="#cite_ref-6">↑</a></span> <span><a rel="nofollow" href="https://www.fastcompany.com/90424503/facebook-google-amazon-are-ramping-up-their-secretive-influence-campaigns-in-dc">https://www.fastcompany.com/90424503/facebook-google-amazon-are-ramping-up-their-secretive-influence-campaigns-in-dc</a></span>
</li>
</ol></div>
<!-- 
NewPP limit report
Cached time: 20230721193631
Cache expiry: 86400
Reduced expiry: false
Complications: []
CPU time usage: 0.034 seconds
Real time usage: 0.037 seconds
Preprocessor visited node count: 51/1000000
Post‐expand include size: 0/2097152 bytes
Template argument size: 0/2097152 bytes
Highest expansion depth: 2/40
Expensive parser function count: 0/100
Unstrip recursion depth: 0/20
Unstrip post‐expand size: 498/5000000 bytes
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%    0.000      1 -total
-->

<!-- Saved in parser cache with key btwiki_db:pcache:idhash:29-0!canonical and timestamp 20230721193631 and revision id 413. Serialized with JSON.
 -->
</div>
				
				<!-- end content -->
				
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Don’t Make Fun of Renowned Dan Brown (2013) (168 pts)]]></title>
            <link>https://onehundredpages.wordpress.com/2013/06/12/dont-make-fun-of-renowned-dan-brown/</link>
            <guid>36818501</guid>
            <pubDate>Fri, 21 Jul 2023 19:35:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://onehundredpages.wordpress.com/2013/06/12/dont-make-fun-of-renowned-dan-brown/">https://onehundredpages.wordpress.com/2013/06/12/dont-make-fun-of-renowned-dan-brown/</a>, See on <a href="https://news.ycombinator.com/item?id=36818501">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
		<main id="main" role="main">

		
			
<article id="post-945">
	
	<!-- .entry-header -->

	<div>
		<div>
<p><a href="https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg"><img data-attachment-id="946" data-permalink="https://onehundredpages.wordpress.com/2013/06/12/dont-make-fun-of-renowned-dan-brown/dan-brown/" data-orig-file="https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg" data-orig-size="236,363" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="dan brown" data-image-description="" data-image-caption="" data-medium-file="https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg?w=195" data-large-file="https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg?w=236" alt="dan brown" src="https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg?w=768" srcset="https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg 236w, https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg?w=98 98w" sizes="(max-width: 236px) 100vw, 236px"></a></p>
<p>Renowned author Dan Brown woke up in his luxurious four-poster bed in his expensive $10 million house – and immediately he felt angry. Most people would have thought that the 48-year-old man had no reason to be angry. After all, the famous writer had a new book coming out. But that was the problem. A new book meant an inevitable attack on the rich novelist by the wealthy wordsmith’s fiercest foes. The critics.</p>
</div>
<p>Renowned author Dan Brown hated the critics. Ever since he had become one of the world’s top renowned authors they had made fun of him. They had mocked bestselling book&nbsp;<i>The Da Vinci Code</i>, successful novel&nbsp;<i>Digital Fortress</i>, popular tome&nbsp;<i>Deception Point</i>, money-spinning volume&nbsp;<i>Angels &amp; Demons</i>&nbsp;and chart-topping work of narrative fiction&nbsp;<i>The Lost Symbol</i>.</p>
<p>The critics said his writing was clumsy, ungrammatical, repetitive and repetitive. They said it was full of unnecessary tautology. They said his prose was swamped in a sea of mixed metaphors. For some reason they found something funny in sentences such as “His eyes went white, like a shark about to attack.”&nbsp;<i>They even say my books are packed with banal and superfluous description</i>, thought the 5ft 9in man. He particularly hated it when they said his imagery was nonsensical. It made his insect eyes flash like a rocket.</p>
<p>Renowned author Dan Brown got out of his luxurious four-poster bed in his expensive $10 million house and paced the bedroom, using the feet located at the ends of his two legs to propel him forwards. He knew he shouldn’t care what a few jealous critics thought. His new book Inferno was coming out on Tuesday, and the 480-page hardback published by Doubleday with a recommended US retail price of $29.95 was sure to be a hit. Wasn’t it?</p>
<div>
<p><i>I’ll call my agent</i>, pondered the prosperous scribe. He reached for the telephone using one of his two hands. “Hello, this is renowned author Dan Brown,” spoke renowned author Dan Brown. “I want to talk to literary agent John Unconvincingname.”</p>
<p>“Mr Unconvincingname, it’s renowned author Dan Brown,” told the voice at the other end of the line. Instantly the voice at the other end of the line was replaced by a different voice at the other end of the line. “Hello, it’s literary agent John Unconvincingname,” informed the new voice at the other end of the line.</p>
<p>“Hello agent John, it’s client Dan,” commented the pecunious scribbler. “I’m worried about new book Inferno. I think critics are going to say it’s badly written.”</p>
<p>The voice at the other end of the line gave a sigh, like a mighty oak toppling into a great river, or something else that didn’t sound like a sigh if you gave it a moment’s thought. “Who cares what the stupid critics say?” advised the literary agent. “They’re just snobs. You have millions of fans.”</p>
<p><i>That’s true</i>, mused the accomplished composer of thrillers that combined religion, high culture and conspiracy theories. His books were read by everyone from renowned politician President Obama to renowned musician Britney Spears. It was said that a copy of&nbsp;<i>The Da Vinci Code</i>&nbsp;had even found its way into the hands of renowned monarch the Queen. He was grateful for his good fortune, and gave thanks every night in his prayers to renowned deity God.</p>
<p>“Think of all the money you’ve made,” recommended the literary agent. That was true too. The thriving ink-slinger’s wealth had allowed him to indulge his passion for great art. Among his proudest purchases were a specially commissioned landscape by acclaimed painter Vincent van Gogh and a signed first edition by revered scriptwriter William Shakespeare.</p>
<p>Renowned author Dan Brown smiled, the ends of his mouth curving upwards in a physical expression of pleasure. He felt much better. If your books brought innocent delight to millions of readers, what did it matter whether you knew the difference between a transitive and an intransitive verb?</p>
<p>“Thanks, John,” he thanked. Then he put down the telephone and perambulated on foot to the desk behind which he habitually sat on a chair to write his famous books on an Apple iMac MD093B/A computer. New book Inferno, the latest in his celebrated series about fictional Harvard professor Robert Langdon, was inspired by top Italian poet Dante. It wouldn’t be the last in the lucrative sequence, either. He had all the sequels mapped out. The Mozart Acrostic. The Michelangelo Wordsearch. The Newton Sudoku.</p>
<p>The 190lb adult male human being nodded his head to indicate satisfaction and returned to his bedroom by walking there. Still asleep in the luxurious four-poster bed of the expensive $10 million house was beautiful wife Mrs Brown. Renowned author Dan Brown gazed admiringly at the pulchritudinous brunette’s blonde tresses, flowing from her head like a stream but made from hair instead of water and without any fish in. She was as majestic as the finest sculpture by Caravaggio or the most coveted portrait by Rodin.&nbsp;<i>I like the attractive woman</i>, thought the successful man.</p>
<p>Perhaps one day, inspired by beautiful wife Mrs Brown, he would move into romantic poetry, like market-leading British rhymester John Keats.<i>That would be good</i>, opined the talented person, and got back into the luxurious four-poster bed. He felt as happy as a man who has something to be happy about and is suitably happy about it.</p>
<p>Inferno by Dan Brown 470pp, Bantam Press, rrp £20</p>

</div>

			
						</div><!-- .entry-content -->

	
	<!-- .entry-footer -->
</article><!-- #post-## -->

			
<!-- #comments -->

				<!-- .navigation -->
	
		
		</main><!-- #main -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Slackware Linux distribution turns 30 years old (205 pts)]]></title>
            <link>https://www.theregister.com/2023/07/20/slackware_turns_30/</link>
            <guid>36818233</guid>
            <pubDate>Fri, 21 Jul 2023 19:17:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/07/20/slackware_turns_30/">https://www.theregister.com/2023/07/20/slackware_turns_30/</a>, See on <a href="https://news.ycombinator.com/item?id=36818233">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>This week the Slackware Linux project is celebrating its 30th anniversary. It is the oldest Linux distribution that is still in active maintenance and development.</p>
<p>Version 1.0 of Slackware was <a href="http://www.slackware.com/announce/1.0.php" rel="nofollow">announced</a> on the July 16, 1993, and project lead Patrick Volkerding, who still maintains the distribution today, celebrated with a <a href="https://www.patreon.com/posts/thirty-years-86196804" rel="nofollow">modest announcement</a>:</p>

<p>The current version, Slackware 15, <a href="https://www.theregister.com/2021/04/16/slackware_15_beta/">went into beta in 2021</a> and <a href="https://www.theregister.com/2022/02/07/slackware/">was released early last year</a>.</p>
<p>It wasn't the first distribution; that was arguably MCC Interim Linux, whose first release candidate, <a href="http://debian.mcc.ac.uk/non-debian/mcc-interim/old/0.97-p2-12/README" rel="nofollow">version 0.97</a> appeared just a couple of months after the kernel itself in 1991. Interim lacked a lot of characteristics which today are givens, such as a package manager. Several other distros <a href="https://www.linuxjournal.com/article/2755" rel="nofollow">followed</a> closely behind it, notably including SLS, the Softlanding Linux system. As this 2020 <a href="https://casadevall.pro/articles/2020/06/softlanding-linux-system-1.0.5/" rel="nofollow">write-up</a> shows, SLS was pretty basic, but it quickly inspired two offspring.</p>
<p>The <a href="https://www.theregister.com/2015/12/30/ian_murdock_debian_founder/">late Ian Murdock</a> was inspired to begin work on Debian by his dissatisfaction with SLS, as his original 1993 <a href="https://groups.google.com/g/comp.os.linux.development/c/Md3Modzg5TU/m/xty88y5OLaMJ" rel="nofollow">announcement</a> says. It took a couple of months to get that first release together, though, meaning that Debian is just very slightly younger. Its first release arrived about two months after Slackware 1.0, as <a href="https://www.theregister.com/2018/08/16/debian_at_25/">we noted for Debian's 25th anniversary</a>.</p>

    

<p>Slackware Linux began as a project to clean up and improve upon SLS, and since it's still going today, we have to say that it's succeeded in that mission. There are three variants of Slackware these days. The eponymous form remains an x86-32 system, whereas Slackware64 targets 21st century 64-bit x86 hardware. (There's also an <a href="https://arm.slackware.com/" rel="nofollow">Arm64 version</a> too, but the former PowerMac and IBM S/390 versions have been discontinued.) <em>The Reg</em> FOSS Desk put it onto one of our older machines for a test drive, and came away pleasantly surprised.</p>
<div><p><a href="https://regmedia.co.uk/2023/07/19/slack-15-boot.png" target="_blank"><img src="https://regmedia.co.uk/2023/07/19/slack-15-boot.png?x=648&amp;y=360&amp;infer_y=1" alt="Slackware64 v15 has an unwelcoming boot screen, but it's not 1996 any more. You can always just Google what to do next." title="Slackware64 v15 has an unwelcoming boot screen, but it's not 1996 any more. You can always just Google what to do next." height="360" width="648"></a></p><p>Slackware64 v15 has an unwelcoming boot screen, but it's not 1996 any more. You can always just Google what to do next</p>
</div>
<p>Way back in about 1996, emboldened by his success with <a href="https://techmonitor.ai/technology/lasermoon_touts_inexpensive_standard_linux_system_for_scientific_academic_users_unix_95_branding_in_prospect" rel="nofollow">Lasermoon Linux/FT</a> on his work PC, Slackware 3 was the first ever distro that this vulture tried to install on his own home PC: a Sunrace laptop, with external hard disk and CD-ROM drives on its built-in Adaptec SCSI interface. (Its internal IDE hard disk was occupied by OS/2 2.0, which was our personal go-to operating system of the time.) We never managed to find the correct incantation to get kernel 1.2 to load its <code>aha152x</code> driver correctly, and retired defeated.</p>
<ul>

<li><a href="https://www.theregister.com/2023/07/19/mint_212/">Mint 21.2 is desktop Linux without the faff</a></li>

<li><a href="https://www.theregister.com/2023/07/18/linux_desktop_debate/">Linux has nearly half of the desktop OS Linux market</a></li>

<li><a href="https://www.theregister.com/2023/07/17/almalinux_project_switches_focus/">AlmaLinux project climbs down from being a one-to-one RHEL clone</a></li>

<li><a href="https://www.theregister.com/2023/07/13/wayland_is_coming/">Three signs that Wayland is becoming the favored way to get a GUI on Linux</a></li>
</ul>
<p>What's surprising about Slackware today is that in some ways, it's superficially quite similar to how it was back then. There are no fripperies such as live graphical desktops here. It boots to a login prompt, and then you're expected to manually run a <code>setup</code> program, and use very 1990s DOS-style text-mode menus to tick boxes for the components that you want installed.</p>
<div><p><a href="https://regmedia.co.uk/2023/07/19/slack64-15-setup.png" target="_blank"><img src="https://regmedia.co.uk/2023/07/19/slack64-15-setup.png?x=648&amp;y=353&amp;infer_y=1" alt="The Slackware setup program doesn't look much different since the 20th century, but behind the scenes, it automates a ton of stuff away. " title="The Slackware setup program doesn't look much different since the 20th century, but behind the scenes, it automates a ton of stuff away. " height="353" width="648"></a></p><p>The Slackware setup program doesn't look much different since the 20th century, but behind the scenes, it automates a ton of stuff away</p>
</div>
<p>The flipside of this is that all of our hardware was automatically detected, and it was all remarkably easy from then on. The setup program includes a choice of graphical desktop environments, and we particularly appreciated the jokey description of Xfce as a "Cholesterol Free Desktop Environment." In fact, quite a few elements of the setup program are jokily informal – for instance, the option for individual confirmation of every package warns that installing this way will take a couple of years.</p>
<p>It didn't configure a graphical login screen by default, or even an ordinary user account, but all that was needed was to type <code>startx</code> and the desktop launched, complete with AMD Radeon graphics drivers preconfigured, and ready to connect to a wireless network. To be honest, we expected substantially more manual effort than this. It's not all a complete doddle: for example, in order to run an online update, you have to manually edit a provided list of mirrors, and uncomment one (and only one) of them.</p>

        

<p>Slackware 15 is very much <em>not</em> a lightweight distribution. Running a full update brought us perilously close to filling up our 16GB root partition, and it wasn't particularly snappy on the elderly Thinkpad W500 that we chose to test it on – although it was a bit quicker than the <a href="https://www.theregister.com/2023/07/19/mint_212/">copy of Linux Mint 21.2</a> it was dual-booting alongside. However, all the controls and config is right there, laid out for you, and if you manually prune some things, you could trim it to size quite easily.</p>
<p>It has online repositories, automatic dependency resolution, and all the bells and whistles that you'd expect from a 21st century distro – just with some of the look and feel of an original 1990s distro. It even still uses LILO by default. Running that first update, we found some worrying warnings online about building a corresponding <code>initrd</code> after you update the kernel… but all that stuff has gone away. In version 15, it's just taken care of for you, automatically.</p>

        

<p>Slackware today is in fact a modern distro, which just happens to look old fashioned due to its simple text-mode installation program, lack of a graphical desktop manager, and a few other cosmetic details. We're not sure if this is from tradition, or whether it's intentional (perhaps to scare away annoying newbies) – or, of course, it may be both. Today it's considerably easier to install than much younger distributions such as Alpine Linux or Arch Linux – or indeed than any of the BSDs, of which it's faintly reminiscent. Oh, and like BSD, it's systemd-free as well. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[IMAX emulates PalmPilot software to power Oppenheimer’s 70 mm release (218 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2023/07/imax-emulates-palmpilot-software-to-power-oppenheimers-70-mm-release/</link>
            <guid>36817900</guid>
            <pubDate>Fri, 21 Jul 2023 18:52:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2023/07/imax-emulates-palmpilot-software-to-power-oppenheimers-70-mm-release/">https://arstechnica.com/gadgets/2023/07/imax-emulates-palmpilot-software-to-power-oppenheimers-70-mm-release/</a>, See on <a href="https://news.ycombinator.com/item?id=36817900">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      The other kind of PDA    —
</h4>
            
            <h2 itemprop="description">IMAX TikTok shows an emulated Palm PDA controlling <em>Oppenheimer's</em> 600-lb reel. </h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/07/oppenheimer-800x362.jpg" alt="Cillian Murphy in">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/07/oppenheimer-scaled.jpg" data-height="1157" data-width="2560">Enlarge</a> <span>/</span> Cillian Murphy in <em> Oppenheimer</em>.</p></figcaption>  </figure>

  




<!-- cache hit 296:single/related:d5a2ef92719af72bf29e17b49d627ab5 --><!-- empty -->
<p>It's a big week for IMAX, which has been promoting today's release of <em>Oppenheimer</em>. It's a particularly big deal for IMAX because the film is the first to get a 70 mm IMAX release since 2020's <em>Tenet</em>. So, you could understand why the company took to social media to boast of the size and magnitude of running the film, which is <a href="https://apnews.com/article/oppenheimer-christopher-nolan-0f8c1fdc4a358decee6105cac91a90ae">said</a> to be 11 miles long and 600 pounds. But in addition to the blockbuster IMAX release is something that hasn't been a showstopper in ages: a PDA.</p>
<p>And you can't discuss personal digital assistants (PDAs) without mentioning PalmPilots. The Palm computing devices were once the epitome of handheld technological organization. But Palm Computing, which endured a series of acquisitions before HP <a href="https://www.businessinsider.com/live-hps-earnings-call-2011-8">sunset the brand</a> in 2011, made other devices besides PalmPilots. One of those is the Palm m130, which is apparently IMAX projectionists' ideal controller for running 70 mm film.</p>
<p>As shown in IMAX's TikTok video below, the 70 mm print for <em>Oppenheimer</em> is so large that they had to extend their film platter. That's fascinating and all, but so is the emulated 2002 PDA apparently running things:</p>
<blockquote cite="https://www.tiktok.com/@imax/video/7255327705313430830" data-video-id="7255327705313430830">
<section><a title="@imax" href="https://www.tiktok.com/@imax?refer=embed" target="_blank" rel="noopener">@imax</a> Constantly pushing the boundaries of film . <a title="oppenheimer" href="https://www.tiktok.com/tag/oppenheimer?refer=embed" target="_blank" rel="noopener">#Oppenheimer</a> <a title="christophernolan" href="https://www.tiktok.com/tag/christophernolan?refer=embed" target="_blank" rel="noopener">#ChristopherNolan</a> <a title="imax" href="https://www.tiktok.com/tag/imax?refer=embed" target="_blank" rel="noopener">#IMAX</a> <a title="♬ original sound - IMAX" href="https://www.tiktok.com/music/original-sound-7255327683477883690?refer=embed" target="_blank" rel="noopener">♬ original sound - IMAX</a></section>
</blockquote>
<p><br>
The m130 wasn't even <a href="https://www.wired.com/2002/03/new-palm-a-tough-sell-for-biz/">top of the line</a> when it came out in 2002. It did, however, bring color (12-bit, to be exact) to Palm's M-series of handhelds. It debuted at $279 with a 2-inch, 160×160 screen and a 33 Motorola Dragonball VZ processor. But that was just the magic needed for IMAX's purposes, and so it hasn't changed a thing. The only difference is that it's using emulations in at least some cases. According to <a href="https://www.theverge.com/23801118/imax-movie-palm-pilot-oppenheimer">The Verge</a>, the TikTok video shows the PDA emulated on a 10.1-inch Windows tablet for businesses, the Winmate W10IB3S-PCH2AC-POE Panel PC. It's easy to find Palm OS emulators <a href="https://cloudpilot-emu.github.io/">online</a>, as noted by <a href="https://www.vice.com/en/article/88x5gb/imax-still-runs-on-palmpilot-operating-system">Vice's Motherboard</a>.</p>                                            
                                                        
<p>The PDA emulation controls the theater's Quick Turn Reel Units (where workers <a href="https://www.youtube.com/watch?v=_uFyp1WS1Fw">load the physical film reels</a>), which can also have integrated controllers instead.</p>
<p>Motherboard contacted IMAX about the antiquity and a company spokesperson said, "The original Quick Turn Reel Units operated on PalmPilots. In advance of the release of <em>Oppenheimer</em>, IMAX Engineering designed and manufactured an emulator that mimics the look and feel of a PalmPilot to keep it simple and familiar for IMAX film projectionists."</p>
<p>It's possible that some IMAX theaters still have physical PDAs. Ars Technica reached out to IMAX for clarification and will update this story if we hear back. As The Verge noted, a YouTuber named Yves Leibowitz, who shares video from an IMAX theater at an aquarium with 70 mm support, has physical Palm devices in his <a href="https://www.youtube.com/watch?v=_uFyp1WS1Fw">videos</a>.</p>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/07/Untitled.jpg" data-height="1014" data-width="1215" alt="A closer look at the emulated PDA. "><img alt="A closer look at the emulated PDA. " src="https://cdn.arstechnica.net/wp-content/uploads/2023/07/Untitled-640x534.jpg" width="640" height="534" srcset="https://cdn.arstechnica.net/wp-content/uploads/2023/07/Untitled.jpg 2x"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/07/Untitled.jpg" data-height="1014" data-width="1215">Enlarge</a> <span>/</span> A closer look at the emulated PDA. </p></figcaption></figure>
<p>So what does the timeless emulator do? An IMAX rep told The Verge that it includes controls for the left and right sides of a 3D projector, which is "from the days of the 45-minute 3D documentaries, where there was a right eye print and a left eye print which both ran through the projector at the same time.” Workers can use the emulator to set which platter is ready for film or for feeding the projector film. The emulator can also tell a worker when the platters are available to run.</p>
<h2>If it ain't broke...</h2>
<p>Twenty-one-year-old emulated PDAs may not be what you'd expect to power one of the year's most publicized movie releases, but if you look at the converse speeds at which technology and business processes tend to evolve, it feels less surprising.</p>                                            
                                                        
<p>Earlier this year, we got a sneak peek at a Chuck E. Cheese that was <em>finally</em> moving its animatronics off <a href="https://arstechnica.com/information-technology/2023/01/chuck-e-cheese-still-uses-floppy-disks-in-2023-but-not-for-long/">floppy disks</a> and into the modern age of ... DVDs. The company's not alone in using dated technologies that mainstream consumers have largely forgotten. Businesses with long-standing procedures and systems often rely on technologies prominent when those systems were created. It's common for machines for things like medical equipment, aircraft, embroidery machines, and plastic molding to <a href="https://arstechnica.com/gadgets/2023/03/why-the-floppy-disk-just-wont-die/">rely on floppy disks</a>.</p>
<p>Similarly, IMAX is seemingly working with technology it's familiar with and, thus, doesn't require new or advanced training or big purchases and upgrades.</p>
<p>Meanwhile, 70 mm IMAX film releases like <em>Oppenheimer</em> don't come often, and when they do, only 30 theaters in the world can support them, <a href="https://www.cnbc.com/2023/07/19/where-to-watch-oppenheimer-in-70mm-imax-.html">CNBC</a> reported, and not necessarily all of them will (<em>Tenet's</em> 70 mm release, for example, was limited to 11 theaters due to pandemic restrictions, CNBC said). That makes any need for upgrades and overhauls less urgent.</p>
<p>“If 70mm IMAX had a resurgence then I’d expect that they’d update the [Quick Turn Reel Unit] controllers. Until then, it’s best to ride it until the wheels fall off,” an IMAX rep told The Verge.</p>
<p>For anyone still wondering what the big deal is about <a href="https://www.filmlinc.org/daily/what-is-70mm/">70 mm film</a> (besides the size), the movie's <a href="https://www.oppenheimermovie.com/tickets/formats/">website</a> says <em>Oppenheimer</em> was "shot using a combination of 5-perf 65 mm and 15 perf IMAX film." The site claims that "when presented on 70 mm IMAX, the sequences shot on 15 perf IMAX are printed full quality in their native format—the highest quality imaging format ever devised, offering 10 times the resolution of standard formats, and filling the giant IMAX screens from top to bottom."</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MiniZinc (225 pts)]]></title>
            <link>https://www.minizinc.org/</link>
            <guid>36817628</guid>
            <pubDate>Fri, 21 Jul 2023 18:32:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.minizinc.org/">https://www.minizinc.org/</a>, See on <a href="https://news.ycombinator.com/item?id=36817628">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p>
                    MiniZinc is a <a href="https://www.minizinc.org/license.html">free and open-source</a> <b>constraint modeling language</b>.  
                </p>
                <p>
                    You can use MiniZinc to model constraint satisfaction and optimization problems in a <b>high-level</b>,
                    <b>solver-independent</b> way, taking advantage of a large
                    <a href="https://www.minizinc.org/doc-latest/en/lib.html">library of pre-defined constraints</a>.
                    Your model is then compiled into FlatZinc, a solver input language that is understood by
                    <a href="https://www.minizinc.org/software.html#flatzinc">a wide range of solvers</a>.
                </p>
                
                <p>
                    MiniZinc is developed at <a href="http://www.monash.edu/">Monash University</a> with support from <a href="https://optima.org.au/">OPTIMA</a>.

                </p><h2>Getting started</h2>
                <p>  
                  To get started with MiniZinc, <a href="https://www.minizinc.org/software.html">download the MiniZinc distribution
                  and the IDE</a> and have a look at the <a href="https://www.minizinc.org/doc-latest/en/index.html">MiniZinc Handbook</a>,
                  which contains a tutorial introduction (also available in <a href="https://www.minizinc.org/doc-latest/chi/index.html">Chinese</a>).
                </p>

                <h2>Learn MiniZinc</h2>
                <p>We have developed an extensive online course!
                    Head over to Coursera's <a href="https://www.coursera.org/learn/basic-modeling">Basic Modeling for Discrete Optimization</a>
                    and <a href="https://www.coursera.org/learn/advanced-modeling">Advanced Modeling for Discrete Optimization</a>
                    courses for an in-depth introduction to constraint modeling using MiniZinc.
                </p>
                
                <p>The book <a href="https://www.springer.com/gp/book/9783030417314"><i>Building Decision Support Systems using MiniZinc</i></a> by Mark Wallace
                    introduces readers to the principles of intelligent decision support systems (IDSS) and how to build them with MiniZinc.</p>

                <h2>Merchandise</h2>
                <p>Get your <a href="https://www.redbubble.com/people/guidodiug/works/32129494-minizinc">MiniZinc stickers, mugs, t-shirts</a> etc. (sold at cost price)!</p>

                <h2>News</h2>

                <ul>
                <li><b>2023-06-20</b> MiniZinc 2.7.6 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.6">change log</a>).</li>
                <li><b>2023-06-07</b> MiniZinc 2.7.5 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.5">change log</a>).</li>
                <li><b>2023-05-11</b> MiniZinc 2.7.4 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.4">change log</a>).</li>
                <li><b>2023-04-20</b> MiniZinc 2.7.3 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.3">change log</a>).</li>    
                <li><b>2023-04-05</b> MiniZinc 2.7.2 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.2">change log</a>).</li>    
                <li><b>2023-03-31</b> MiniZinc 2.7.1 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.1">change log</a>).</li>    
                <li><b>2023-02-23</b> MiniZinc 2.7.0 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.0">change log</a>).</li>
                <li><b>2023-02-13</b> First <a href="https://www.minizinc.org/challenge2023/call_for_problems.html">Call for MiniZinc problem submissions</a> has been made for the MiniZinc Challenge 2023.</li>
                <li><b>2022-08-04</b> The MiniZinc Challenge 2022 results available <a href="https://www.minizinc.org/challenge2022/results2022.html">here</a>. </li>
                <li><b>2022-06-23</b> MiniZinc 2.6.4 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.6.4">change log</a>).</li>
                <li><b>2022-05-06</b> MiniZinc 2.6.3 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.6.3">change log</a>).</li>
                <li><b>2022-03-03</b> MiniZinc 2.6.2 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.6.2">change log</a>).</li>
                <li><b>2022-03-10</b> First <a href="https://www.minizinc.org/challenge2022/call_for_problems.html">Call for MiniZinc problem submissions</a> has been made for the MiniZinc Challenge 2022.</li>
                <li><b>2022-03-03</b> MiniZinc 2.6.1 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.6.1">change log</a>).</li>
                <li><b>2022-02-22</b> MiniZinc 2.6.0 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.6.0">change log</a>).</li>
                <li><b>2021-10-29</b> The MiniZinc Challenge 2021 results available <a href="https://www.minizinc.org/challenge2021/results2021.html">here</a>. </li>
                <li><b>2021-05-07</b> First <a href="https://www.minizinc.org/challenge2021/call_for_problems.html">Call for MiniZinc problem submissions</a> has been made for the MiniZinc Challenge 2021.</li>
                <li><b>2021-03-19</b> MiniZinc 2.5.5 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.5.5">change log</a>).</li>
                <li><b>2021-03-16</b> MiniZinc 2.5.4 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.5.4">change log</a>).</li>
                <li><b>2020-11-24</b> MiniZinc 2.5.3 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.5.3">change log</a>).</li>
                <li><b>2020-11-09</b> MiniZinc 2.5.2 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.5.2">change log</a>).</li>
                <li><b>2020-10-22</b> MiniZinc 2.5.1 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.5.1">change log</a>).</li>
                <li><b>2020-10-06</b> MiniZinc 2.5.0 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.5.0">change log</a>).</li>
                <li><b>2020-05-22</b> <a href="https://www.springer.com/gp/book/9783030417314"><i>Building Decision Support Systems using MiniZinc</i></a> by Mark Wallace is now available</li>
                <li><b>2020-03-04</b> MiniZinc 2.4.3 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.4.3">change log</a>).</li>
                <li><b>2020-01-10</b> MiniZinc 2.4.2 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.4.2">change log</a>).</li>
                <li><b>2019-12-20</b> MiniZinc 2.4.1 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.4.1">change log</a>).</li>
                <li><b>2019-12-13</b> MiniZinc 2.4.0 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.4.0">change log</a>).</li>
                <li><b>2019-10-03</b> The MiniZinc Challenge 2019 results available <a href="https://www.minizinc.org/challenge2019/results2019.html">here</a>. </li>
                <li><b>2019-09-12</b> MiniZinc 2.3.2 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.3.2">change log</a>).</li>
                <li><b>2019-07-10</b> MiniZinc 2.3.1 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.3.1">change log</a>).</li>
                <li><b>2019-06-26</b> MiniZinc 2.3.0 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.3.0">change log</a>).</li>
                <li><b>2019-03-07</b> First <a href="https://www.minizinc.org/challenge2019/call_for_problems.html">Call for MiniZinc problem submissions</a> has been made for the MiniZinc Challenge 2019.</li>
                <li><b>2018-10-31</b> MiniZinc 2.2.3 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.2.3">change log</a>).</li>
                <li><b>2018-10-26</b> MiniZinc 2.2.2 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.2.2">change log</a>).</li>
                <li><b>2018-09-20</b> Amendments of the MiniZinc Challenge 2018 results had to be made due to an issue with the solution checker. More details are available <a href="https://www.minizinc.org/challenge2018/results2018.html">here</a>. Thanks to Gustav Björdal and Michael Marte for reporting.</li>
                <li><b>2018-09-06</b> MiniZinc 2.2.1 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.2.1">change log</a>).</li>
                <li><b>2018-08-28</b> The MiniZinc Challenge 2018 results available <a href="https://www.minizinc.org/challenge2018/results2018.html">here</a>. </li>
                <li><b>2018-08-24</b> MiniZinc 2.2.0, a major release with many new features has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.2.0">change log</a>).</li>
                <li><b>2018-03-08</b> 11th edition of the <a href="https://www.minizinc.org/challenge2018/challenge.html">MiniZinc Challenge</a> has been announced.</li>
                <li><b>2018-01-10</b> MiniZinc 2.1.7 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.1.7">change log</a>).</li>
                <li><a href="https://www.minizinc.org/oldnews.html">Older news items</a></li>
                </ul>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[For BSD Unix, It's Sayonara (1992) (120 pts)]]></title>
            <link>https://www.tech-insider.org/unix/research/1992/0622.html</link>
            <guid>36817482</guid>
            <pubDate>Fri, 21 Jul 2023 18:22:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tech-insider.org/unix/research/1992/0622.html">https://www.tech-insider.org/unix/research/1992/0622.html</a>, See on <a href="https://news.ycombinator.com/item?id=36817482">Hacker News</a></p>
<div id="readability-page-1" class="page">
<b>News</b><p><b>For BSD Unix, It's Sayonara </b></p>
<p>Jason Levitt and Evan Schuman<br>
Open Systems Today </p>
<p>June 22, 1992</p>
<p>Berkeley, Calif. -- The end of a major computing era will come next month 
when the final release of BSD Unix gets shipped, marking the University of 
California at Berkeley's withdrawal from the operating system business. </p>
<p>A lack of funding and the increasing sophistication of commercial Unix 
implementations have combined to halt Unix development at the university, 
meaning that 4.4BSD Unix-set to go Alpha by next month, with general 
availability by December-will be Berkeley's last OS. </p>
<p>BSD has been popular in the academic community for many reasons, mostly 
because-since 1988-it has not required a license fee and often features 
cutting-edge technology years before commercial computer vendors' versions. </p>
<p>"With any commercial version of Unix, you usually have to sign your life 
away," said Evi Nemeth, an associate professor of computer science at the 
University of Colorado at Boulder, adding that this no-license feature made BSD 
ideal for teaching students about operating systems and networking. </p>
<p>BSD Unix was responsible for much of the Unix innovation during the 1980s and 
came into being around 1978 when Berkeley graduate student Bill Joy added 
virtual memory capability to a VAX 11/780 port of Unix. The resulting system was 
named 3BSD (4BSD in 1980) and became the dominant Unix version at universities.
</p>
<p>Since that time, nearly all of the important Unix enhancements have come from 
the BSD releases of Unix. Collectively, these enhancements are often referred to 
as the Berkeley "extensions" and are now part of System V Release 4. The 
programming API for OSF/1 is based on 4.3BSD libraries and system calls. </p>
<p>Originally, BSD was funded by the government through DARPA. But that funding 
was cut off in 1988 when the vendor community started to show a strong interest 
in doing its own development. </p>
<p>Since 1988, BSD research and staffing has been supplied through vendor 
grants, mostly from Hewlett-Packard, the Open Software Foundation and Cray 
Research. </p>
<p>Kirk McKusick, the Berkeley research computer scientist who is in charge of 
the BSD project, added that NASA Ames also has been a major sponsor. </p>
<p>"It's becoming increasingly difficult to get funding from the private 
sector," he said. "With the recession, these companies are obviously looking at 
the bottom line and external research is an item that can be easily reduced."
</p>
<p>While fund raising has gotten more difficult, today's technology has forced 
the operating system to grow substantially more complicated, with the 100 
different commands from a few years ago now at 500 commands, McKusick said. </p>
<p>"The complexity has grown almost exponentially," he said, adding that his 
staff of four would need be doubled to "continue the level of quality." </p>
<p>Also, McKusick said, the university itself "is not as interested in having us 
around as they did 10 years ago" because vendors today-such as Cisco 
Systems-have packaged some of the networking technology that made his team so 
indispensable before for systems administration. </p>
<p>"We are so good at getting our stuff disseminated that we are no longer 
needed," he said. </p>
<p>Another factor contributing to the OS' demise, said Keith Bostic, fellow 
Berkeley programmer and the project's second-in-command, was the increasing 
sophistication of vendors in working with Unix. </p>
<p>In the early 1980s, Bostic said, just about the entire Unix community was 
either using a form of BSD or AT&amp;T's System V. "If you bought {Unix} from DEC, 
you were running BSD. If you bought {Unix} from Sun, you were running BSD," he 
said. "In today's climate, it is not the same as 1980." </p>
<p>Bostic said that today's Unix vendors are more sophisticated and are making 
many more changes to whatever version of Unix they are starting with. </p>
<p>BSD 4.3 "was the last version that major vendors shipped right out of the 
box. Vendors now tend to pick and choose," he said. "The vendors are basically 
going to lose a research group." </p>
<p>There are still options to secure BSD code, with one company, Berkeley 
Software Design (Falls Church, Va.), a company employing former Berkeley 
programmer Mike Karels, planning to offer a commercial version of Unix for SPARC 
systems based on the 4.4BSD code but free of AT&amp;T source licensing requirements. 
It currently offers BSD/386, a version of Unix for 386 machines based on the 
Berkeley NET2 release. </p>
<p>And there are several outfits that will distribute the code freely, often 
directly on the net. </p>
<p>The University of Colorado's Nemeth, regarded as an expert on Unix security 
and perhaps best known for having co-authored the Unix System Administration 
Handbook, said last week that she would like to have her university conduct some 
of the operating system research that Berkeley is now abandoning. </p>
<p>One of the most popular accomplishments of the BSD team, said Nemeth and 
others, was its sifting through mountains of software out in the industry, 
finding the best examples and incorporating them into a BSD version. McKusick 
said it was often a matter of convincing contributors "that they would rather 
have fame than fortune." </p>
<p>Nemeth cited a more colorful-and oft-cited-description: "It was a matter of 
their taking it in and peeing on it until it smelled like Berkeley." </p>
<p>"This is a valuable function and the community needs the service," she said, 
adding that she is trying to convince DARPA to resume funding BSD research at 
her university with it paying for three to four full-time staff, two or three 
graduate students and two or three undergraduate students. Nemeth estimated that 
she would need about $700,000. </p>
<p>But she said last week that she now is leaning toward securing interim 
funding from industry, in an attempt to demonstrate to DARPA that her people can 
do the job effectively. </p>
<p>Nemeth said that she is hesitant, though, to have vendor support made 
permanent. "I don't see having to constantly hustle for money."</p>

<p>Copyright 1992 CMP Publications, Inc. All rights reserved.</p>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Web Environment Integrity API (433 pts)]]></title>
            <link>https://github.com/RupertBenWiser/Web-Environment-Integrity</link>
            <guid>36817305</guid>
            <pubDate>Fri, 21 Jul 2023 18:09:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity">https://github.com/RupertBenWiser/Web-Environment-Integrity</a>, See on <a href="https://news.ycombinator.com/item?id=36817305">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-turbo-body="">
      


    <div>
      <p><a href="#start-of-content">Skip to content</a>
      <span data-view-component="true">
    <span data-view-component="true"></span>
</span></p><header role="banner" data-color-mode="light" data-light-theme="light" data-dark-theme="dark">
  

  <div>
    <div>
      <a href="https://github.com/" aria-label="Homepage" data-ga-click="(Logged out) Header, go to homepage, icon:logo-wordmark">
        
      </a>

        <div>
          <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="d70e84e9f9dca6c4052317ffe225baad48a9b2d4823c9c6c4d304f38494e8473">
            Sign&nbsp;up
          </a>
        </p></div>

      
    </div>


    <div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
              <p><span id="product-explore-heading">Explore</span></p><ul aria-labelledby="product-explore-heading">
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to All features&quot;,&quot;label&quot;:&quot;ref_cta:All features;&quot;}" href="https://github.com/features">
      All features

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Documentation&quot;,&quot;label&quot;:&quot;ref_cta:Documentation;&quot;}" href="https://docs.github.com/">
      Documentation

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to GitHub Skills&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Skills;&quot;}" href="https://skills.github.com/">
      GitHub Skills

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Blog&quot;,&quot;label&quot;:&quot;ref_cta:Blog;&quot;}" href="https://github.blog/">
      Blog

    
</a></li>

            </ul>
          </div>
      </div>
</li>


                <li>
      
      <div>
          <div>
              <p><span id="solutions-for-heading">For</span></p><ul aria-labelledby="solutions-for-heading">
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Enterprise&quot;,&quot;label&quot;:&quot;ref_cta:Enterprise;&quot;}" href="https://github.com/enterprise">
      Enterprise

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Teams&quot;,&quot;label&quot;:&quot;ref_cta:Teams;&quot;}" href="https://github.com/team">
      Teams

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Startups&quot;,&quot;label&quot;:&quot;ref_cta:Startups;&quot;}" href="https://github.com/enterprise/startups">
      Startups

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Education&quot;,&quot;label&quot;:&quot;ref_cta:Education;&quot;}" href="https://education.github.com/">
      Education

    
</a></li>

            </ul>
          </div>
          <div>
              <p><span id="solutions-by-solution-heading">By Solution</span></p><ul aria-labelledby="solutions-by-solution-heading">
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to CI/CD &amp;amp; Automation&quot;,&quot;label&quot;:&quot;ref_cta:CI/CD &amp;amp; Automation;&quot;}" href="https://github.com/solutions/ci-cd/">
      CI/CD &amp; Automation

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to DevOps&quot;,&quot;label&quot;:&quot;ref_cta:DevOps;&quot;}" href="https://resources.github.com/devops/">
      DevOps

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to DevSecOps&quot;,&quot;label&quot;:&quot;ref_cta:DevSecOps;&quot;}" href="https://resources.github.com/devops/fundamentals/devsecops/">
      DevSecOps

    
</a></li>

            </ul>
          </div>
          <div>
              <p><span id="solutions-resources-heading">Resources</span></p><ul aria-labelledby="solutions-resources-heading">
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Customer Stories&quot;,&quot;label&quot;:&quot;ref_cta:Customer Stories;&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to White papers, Ebooks, Webinars&quot;,&quot;label&quot;:&quot;ref_cta:White papers, Ebooks, Webinars;&quot;}" href="https://resources.github.com/">
      White papers, Ebooks, Webinars

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Partners&quot;,&quot;label&quot;:&quot;ref_cta:Partners;&quot;}" href="https://partner.github.com/">
      Partners

    
</a></li>

            </ul>
          </div>
      </div>
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
              <p><span id="open-source-repositories-heading">Repositories</span></p><ul aria-labelledby="open-source-repositories-heading">
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to Topics&quot;,&quot;label&quot;:&quot;ref_cta:Topics;&quot;}" href="https://github.com/topics">
      Topics

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to Trending&quot;,&quot;label&quot;:&quot;ref_cta:Trending;&quot;}" href="https://github.com/trending">
      Trending

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to Collections&quot;,&quot;label&quot;:&quot;ref_cta:Collections;&quot;}" href="https://github.com/collections">
      Collections

    
</a></li>

            </ul>
          </div>
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:RupertBenWiser/Web-Environment-Integrity" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="TOFqL3IsSOkP2RP7Whs-FRbAKNymOsfTq1lEcorjNQ_UqiuwYjvFpkj7Mf5KZWKttIePXlBbsmxJzfzA_D6Amg" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="RupertBenWiser/Web-Environment-Integrity" data-current-org="" data-current-owner="RupertBenWiser" data-logged-in="false">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="feedback-dialog" aria-modal="true" aria-disabled="true" aria-describedby="feedback-dialog-title feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      <div data-view-component="true">        <!-- '"` --><!-- </textarea></xmp> --><form id="code-search-feedback-form" data-turbo="false" action="/search/feedback" accept-charset="UTF-8" method="post">
          <p>We read every piece of feedback, and take your input very seriously.</p>
          
          
          <label for="include_email">Include my email address so I can be contacted</label>
</form></div>
      
</modal-dialog></div>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="custom-scopes-dialog" aria-modal="true" aria-disabled="true" aria-describedby="custom-scopes-dialog-title custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      
      
</modal-dialog></div>
    </custom-scopes>
  </div>
</qbsearch-input><div>
            <p><a href="https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FRupertBenWiser%2FWeb-Environment-Integrity" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="01e3ed5febbe8bc7ce93175543274d99ddddc9287a0c31d4bea8d40f578b6b71" data-ga-click="(Logged out) Header, clicked Sign in, text:sign-in">
              Sign in
            </a>
          </p></div>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=RupertBenWiser%2FWeb-Environment-Integrity" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="01e3ed5febbe8bc7ce93175543274d99ddddc9287a0c31d4bea8d40f578b6b71" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div>
  </div>
</header>

      
    </div>

  








    


    
    <include-fragment data-base-src="https://github.com/notifications/beta/shelf"></include-fragment>






  <div itemscope="" itemtype="http://schema.org/SoftwareSourceCode" data-commit-hovercards-enabled="" data-discussion-hovercards-enabled="" data-issue-and-pr-hovercards-enabled="">
    <main id="js-repo-pjax-container">
      
  




    






  
  <div id="repository-container-header" data-turbo-replace="">

      <div>

        <div>
      
    
    <p><span itemprop="author">
      <a rel="author" data-hovercard-type="user" data-hovercard-url="/users/RupertBenWiser/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/RupertBenWiser">
        RupertBenWiser
</a>    </span>
    <span>/</span>
    <strong itemprop="name">
      <a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity">Web-Environment-Integrity</a>
    </strong>

    <span></span><span>Public</span>
  </p></div>

        <div id="repository-details-container" data-turbo-replace="">
            <ul>
    
      

  <li>
            <a href="https://github.com/login?return_to=%2FRupertBenWiser%2FWeb-Environment-Integrity" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;notification subscription menu watch&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="293d9a82a60f90833694d5820eee59ef0df39d68f49e83d7e5b15d78ce605170" aria-label="You must be signed in to change notification settings" data-view-component="true">    Notifications
</a>
  </li>

  <li>
          <a icon="repo-forked" id="fork-button" href="https://github.com/login?return_to=%2FRupertBenWiser%2FWeb-Environment-Integrity" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;repo details fork button&quot;,&quot;repository_id&quot;:632520759,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="5aa5809df7db030699b13deecdd19445904a135559f2af25249dddf6be869a54" data-view-component="true">    Fork
    <span id="repo-network-counter" data-pjax-replace="true" data-turbo-replace="true" title="21" data-view-component="true">21</span>
</a>
  </li>

  <li>
        <div data-view-component="true">
        <a href="https://github.com/login?return_to=%2FRupertBenWiser%2FWeb-Environment-Integrity" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:632520759,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="63d22802c5b163a4f30d19ed6eef47b4d81941c9749061a904d7b89bc133e5db" aria-label="You must be signed in to star a repository" data-view-component="true">    <span data-view-component="true">
          Star
</span>          <span id="repo-stars-counter-star" aria-label="64 users starred this repository" data-singular-suffix="user starred this repository" data-plural-suffix="users starred this repository" data-turbo-replace="true" title="64" data-view-component="true">64</span>
</a>        </div>
  </li>


    

</ul>

        </div>
      </div>

        <div id="responsive-meta-container" data-turbo-replace="">

    

    <p>
        <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/stargazers">
          
          <span>64</span>
          stars
</a>        <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/forks">
          
          <span>21</span>
          forks
</a>        <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/activity">
          
          <span>Activity</span>
</a>    </p>

      <div>
        <div data-view-component="true">
        <a href="https://github.com/login?return_to=%2FRupertBenWiser%2FWeb-Environment-Integrity" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:632520759,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="63d22802c5b163a4f30d19ed6eef47b4d81941c9749061a904d7b89bc133e5db" aria-label="You must be signed in to star a repository" data-view-component="true">    <span data-view-component="true">
          Star
</span>
</a>        </div>
        <p>
                <a href="https://github.com/login?return_to=%2FRupertBenWiser%2FWeb-Environment-Integrity" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;notification subscription menu watch&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="293d9a82a60f90833694d5820eee59ef0df39d68f49e83d7e5b15d78ce605170" aria-label="You must be signed in to change notification settings" data-view-component="true">    Notifications
</a>
        </p>
      </div>
  </div>


          <nav data-pjax="#js-repo-pjax-container" aria-label="Repository" data-view-component="true">

  <ul data-view-component="true">
      <li data-view-component="true">
  <a id="code-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity" data-tab-item="i0code-tab" data-selected-links="repo_source repo_downloads repo_commits repo_releases repo_tags repo_branches repo_packages repo_deployments /RupertBenWiser/Web-Environment-Integrity" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g c" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Code&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" aria-current="page" data-view-component="true">
    
              
        <span data-content="Code">Code</span>
          <span id="code-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="Not available" data-view-component="true"></span>


    
</a></li>
      <li data-view-component="true">
  <a id="issues-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/issues" data-tab-item="i1issues-tab" data-selected-links="repo_issues repo_labels repo_milestones /RupertBenWiser/Web-Environment-Integrity/issues" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g i" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Issues&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true">
    
              
        <span data-content="Issues">Issues</span>
          <span id="issues-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="51" data-view-component="true">51</span>


    
</a></li>
      <li data-view-component="true">
  <a id="pull-requests-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/pulls" data-tab-item="i2pull-requests-tab" data-selected-links="repo_pulls checks /RupertBenWiser/Web-Environment-Integrity/pulls" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g p" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Pull requests&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true">
    
              
        <span data-content="Pull requests">Pull requests</span>
          <span id="pull-requests-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="2" data-view-component="true">2</span>


    
</a></li>
      <li data-view-component="true">
  <a id="actions-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/actions" data-tab-item="i3actions-tab" data-selected-links="repo_actions /RupertBenWiser/Web-Environment-Integrity/actions" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g a" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Actions&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true">
    
              
        <span data-content="Actions">Actions</span>
          <span id="actions-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="Not available" data-view-component="true"></span>


    
</a></li>
      <li data-view-component="true">
  <a id="projects-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/projects" data-tab-item="i4projects-tab" data-selected-links="repo_projects new_repo_project repo_project /RupertBenWiser/Web-Environment-Integrity/projects" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g b" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Projects&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true">
    
              
        <span data-content="Projects">Projects</span>
          


    
</a></li>
      <li data-view-component="true">
  <a id="security-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/security" data-tab-item="i5security-tab" data-selected-links="security overview alerts policy token_scanning code_scanning /RupertBenWiser/Web-Environment-Integrity/security" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g s" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Security&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true">
    
              
        <span data-content="Security">Security</span>
          <include-fragment src="/RupertBenWiser/Web-Environment-Integrity/security/overall-count" accept="text/fragment+html"></include-fragment>

    
</a></li>
      <li data-view-component="true">
  <a id="insights-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/pulse" data-tab-item="i6insights-tab" data-selected-links="repo_graphs repo_contributors dependency_graph dependabot_updates pulse people community /RupertBenWiser/Web-Environment-Integrity/pulse" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Insights&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true">
    
              
        <span data-content="Insights">Insights</span>
          <span id="insights-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="Not available" data-view-component="true"></span>


    
</a></li>
</ul>
    <div data-view-component="true">        <details data-view-component="true">
    <summary role="button" data-view-component="true">          <div>
            
            <p><span>More</span>
          </p></div>
</summary>
    <details-menu role="menu" data-view-component="true">          <ul>
              
              
              
              
              
              
              
          </ul>
</details-menu>
</details></div>
</nav>

  </div>

  



<turbo-frame id="repo-content-turbo-frame" target="_top" data-turbo-action="advance">
    <div id="repo-content-pjax-container">
  


  

  <include-fragment src="/RupertBenWiser/Web-Environment-Integrity/spoofed_commit_check/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4" data-test-selector="spoofed-commit-check"></include-fragment>

  <div data-view-component="true">
  <div data-view-component="true">        
        
        <div>
  
<div>
  <details id="branch-select-menu" data-hydro-click-payload="{&quot;event_type&quot;:&quot;repository.click&quot;,&quot;payload&quot;:{&quot;target&quot;:&quot;REFS_SELECTOR_MENU&quot;,&quot;repository_id&quot;:632520759,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="44d089c48373dc35e4e44d462abd09000039cc8c32fc11bab9faf0bfe1d7ba67">
    <summary data-hotkey="w" title="Switch branches or tags">
      
      <span data-menu-button="">main</span>
      <span></span>
    </summary>

    
<div>
    <header>
      <span>Switch branches/tags</span>
      
    </header>

    <input-demux data-action="tab-container-change:input-demux#storeInput tab-container-changed:input-demux#updateInput">
      <tab-container>
        

        

        <div role="tabpanel" id="ref-list-branches" data-filter-placeholder="Filter branches/tags" tabindex="">
          <ref-selector type="branch" data-targets="input-demux.sinks" data-action="
              input-entered:ref-selector#inputEntered
              tab-selected:ref-selector#tabSelected
              focus-list:ref-selector#focusFirstListMember
            " query-endpoint="/RupertBenWiser/Web-Environment-Integrity/refs" cache-key="v0:1689925634.0" current-committish="bWFpbg==" default-branch="bWFpbg==" name-with-owner="UnVwZXJ0QmVuV2lzZXIvV2ViLUVudmlyb25tZW50LUludGVncml0eQ==" prefetch-on-mouseover="">

            <template data-target="ref-selector.fetchFailedTemplate">
              <div class="SelectMenu-message" data-index="{{ index }}">Could not load branches</div>
            </template>

              <template data-target="ref-selector.noMatchTemplate">
    <div class="SelectMenu-message">Nothing to show</div>
</template>


            

              

<template data-target="ref-selector.itemTemplate">
  <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/tree/{{ urlEncodedRefName }}" class="SelectMenu-item" role="menuitemradio" rel="nofollow" aria-checked="{{ isCurrent }}" data-index="{{ index }}">
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check SelectMenu-icon SelectMenu-icon--check">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    <span class="flex-1 css-truncate css-truncate-overflow {{ isFilteringClass }}">{{ refName }}</span>
    <span hidden="{{ isNotDefault }}" class="Label Label--secondary flex-self-start">default</span>
  </a>
</template>


              
          </ref-selector>

        </div>

        
      </tab-container>
    </input-demux>
  </div>

  </details>

</div>


<div data-modal-dialog-overlay="">
  <modal-dialog role="dialog" id="warn-tag-match-create-branch-dialog" aria-modal="true" aria-labelledby="warn-tag-match-create-branch-dialog-header" data-view-component="true">
      <header>
        <div>
          <p>
            <h2 id="warn-tag-match-create-branch-dialog-header">Name already in use</h2>
          </p>
          
        </div>
      </header>
    <div>
      
          <p>      A tag already exists with the provided branch name. Many Git commands accept both tag and branch names, so creating this branch may cause unexpected behavior. Are you sure you want to create this branch?
</p>

    </div>
      
</modal-dialog></div>



  <p>
    <a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/branches">
          
          <strong>2</strong>
          <span>branches</span>
    </a>
    <a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/tags">
      
        <strong>0</strong>
        <span>tags</span>
    </a>
  </p>

  

  <include-fragment src="/RupertBenWiser/Web-Environment-Integrity/overview_actions/main"></include-fragment>


    <p><span>
        
<get-repo>
    
    <details data-action="
               toggle:get-repo#onDetailsToggle
               keydown:get-repo#onDetailsKeydown">
        <summary data-hydro-click="{&quot;event_type&quot;:&quot;repository.click&quot;,&quot;payload&quot;:{&quot;repository_id&quot;:632520759,&quot;target&quot;:&quot;CLONE_OR_DOWNLOAD_BUTTON&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="2a850bb66106159d97ab9bd5e4e79b14c52c6a46a2f26d039aa174ad06cbde5f" data-view-component="true">    <span>
      <span>Code</span>
    </span>
      <span>
        
      </span>
</summary>  
      <div data-target="get-repo.modal">
    <tab-container data-view-component="true">
  <div with_panel="true" data-view-component="true">
    
    <ul role="tablist" aria-label="Choose where to access your code" data-view-component="true">
        <li role="presentation" data-view-component="true">
  </li>
        <li role="presentation" data-view-component="true">
  </li>
</ul>    
</div>    <div id="local-panel" role="tabpanel" tabindex="0" aria-labelledby="local-tab" data-view-component="true">          <ul>
              <li>
  <a href="https://docs.github.com/articles/which-remote-url-should-i-use" target="_blank" aria-label="Which remote URL should I use?">
  
</a>

<div>
  <p>
  Clone
</p></div>

<tab-container>

  

  <div role="tabpanel">
    

    <p>
        Use Git or checkout with SVN using the web URL.
    </p>
  </div>


  
</tab-container>

</li>
<li data-platforms="windows,mac">
  <a data-hydro-click="{&quot;event_type&quot;:&quot;clone_or_download.click&quot;,&quot;payload&quot;:{&quot;feature_clicked&quot;:&quot;OPEN_IN_DESKTOP&quot;,&quot;git_repository_type&quot;:&quot;REPOSITORY&quot;,&quot;repository_id&quot;:632520759,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="0e082088e719e3706dceff570cd728dcc71018e70b8c36e4cd0ce22013aec0f8" data-action="click:get-repo#showDownloadMessage" href="https://desktop.github.com/">
    
    Open with GitHub Desktop
</a></li>
<li>
  <a rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;clone_or_download.click&quot;,&quot;payload&quot;:{&quot;feature_clicked&quot;:&quot;DOWNLOAD_ZIP&quot;,&quot;git_repository_type&quot;:&quot;REPOSITORY&quot;,&quot;repository_id&quot;:632520759,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="3228739be0257e0437c387b54e0f4d4c40aeacbd38fbcf1c77cc602cca3390f7" data-ga-click="Repository, download zip, location:repo overview" data-open-app="link" data-turbo="false" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/archive/refs/heads/main.zip">
    
    Download ZIP
</a></li>

          </ul>
</div>
    
</tab-container></div>
    </details>


</get-repo>

    </span>

    <span>
        

    </span>
</p></div>




        


<div>
  <div>
    <h2>Latest commit</h2>
    <div data-issue-and-pr-hovercards-enabled="">
      
  <div>
  <p><a data-test-selector="commits-avatar-stack-avatar-link" data-hovercard-type="user" data-hovercard-url="/users/yoavweiss/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/yoavweiss">
        <img data-test-selector="commits-avatar-stack-avatar-image" src="https://avatars.githubusercontent.com/u/786187?s=48&amp;v=4" width="24" height="24" alt="@yoavweiss">
</a>      <a data-test-selector="commits-avatar-stack-avatar-link" data-hovercard-type="user" data-hovercard-url="/users/RupertBenWiser/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/RupertBenWiser">
        <img data-test-selector="commits-avatar-stack-avatar-image" src="https://avatars.githubusercontent.com/u/26461279?s=48&amp;v=4" width="24" height="24" alt="@RupertBenWiser">
</a>  </p>
</div>
  <div>
    <div>
          <p><a title="View all commits by yoavweiss" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commits?author=yoavweiss">yoavweiss</a>
    
   and
  <a title="View all commits by RupertBenWiser" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commits?author=RupertBenWiser">RupertBenWiser</a>
  

        <span>
          <a data-pjax="true" data-test-selector="commit-tease-commit-message" title="Create CODE_OF_CONDUCT.md" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4">Create CODE_OF_CONDUCT.md</a>
        </span>
    </p></div>
    <div>
        <include-fragment accept="text/fragment+html" src="/RupertBenWiser/Web-Environment-Integrity/commit/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4/rollup?direction=sw"></include-fragment>
      <p><a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame">
        7998217
      </a></p><a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame">
        <relative-time datetime="2023-07-21T07:46:43Z">Jul 21, 2023</relative-time>
      </a>
    </div>
  </div>
  <div>
      <div>
        <p><a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-test-selector="commit-tease-commit-message" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4">Create CODE_OF_CONDUCT.md</a>
      </p></div>
    <p><code>7998217</code>
    </p>
  </div>
      <div>
        <h2>Git stats</h2>
        <ul>
          <li>
            <a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commits/main">
              
              <span>
                    <strong>22</strong>
                    <span aria-label="Commits on main">
                      commits
                    </span>
              </span>
            </a>
          </li>
        </ul>
      </div>
    </div>
  </div>
    <h2 id="files">Files</h2>
    


    <p><a data-hotkey="y" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/tree/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4">Permalink</a></p><div data-view-component="true">
  <p>
    Failed to load latest commit information.


  
</p></div>  <div role="grid" aria-labelledby="files" data-hpc="">
      <div role="row">
        <p>Type</p>
        <p>Name</p>
        <p>Latest commit message</p>
        <p>Commit time</p>
      </div>

        <div role="row">
          

          <div role="rowheader">
            <p><span><a title="This path skips through empty directories" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/tree/main/.github/workflows"><span>.github/</span>workflows</a></span>
          </p></div>

          <div role="gridcell">
              <p><span>
                    <a data-pjax="true" title="Add github workflow to publish to gh-pages branch

This should auto process the bikeshed on push to main and publish
to the gh-pages branch.

Also updating the WebIDL to pass validation." href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/f8448c38fd41470d828ad1b1ec691a2b424f1118">Add github workflow to publish to gh-pages branch</a>
              </span>
          </p></div>

          <p role="gridcell">
              <relative-time tense="past" datetime="2023-06-20T14:19:28Z" data-view-component="true">June 20, 2023 14:19</relative-time>
          </p>

        </div>
        <div role="row">
          

          <div role="rowheader">
            <p><span><a title="docs" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/tree/main/docs">docs</a></span>
          </p></div>

          <div role="gridcell">
              <p><span>
                    <a data-pjax="true" title="Add hash type and DOMException" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/f6bf35350c59e856deafdac65569b71a3413155b">Add hash type and DOMException</a>
              </span>
          </p></div>

          <p role="gridcell">
              <relative-time tense="past" datetime="2023-07-17T10:55:18Z" data-view-component="true">July 17, 2023 10:55</relative-time>
          </p>

        </div>
        <div role="row">
          

          <div role="rowheader">
            <p><span><a title=".gitignore" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/.gitignore">.gitignore</a></span>
          </p></div>

          <div role="gridcell">
              <p><span>
                    <a data-pjax="true" title="Add gitignore

Ignoring local spec files generated in the docs directory." href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/1866c954426f2529f008362b6b7686cbff605388">Add gitignore</a>
              </span>
          </p></div>

          <p role="gridcell">
              <relative-time tense="past" datetime="2023-06-20T15:20:21Z" data-view-component="true">June 20, 2023 15:20</relative-time>
          </p>

        </div>
        <div role="row">
          

          <div role="rowheader">
            <p><span><a title="CODE_OF_CONDUCT.md" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/CODE_OF_CONDUCT.md">CODE_OF_CONDUCT.md</a></span>
          </p></div>

          <div role="gridcell">
              <p><span>
                    <a data-pjax="true" title="Create CODE_OF_CONDUCT.md" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4">Create CODE_OF_CONDUCT.md</a>
              </span>
          </p></div>

          <p role="gridcell">
              <relative-time tense="past" datetime="2023-07-21T09:46:43+02:00" data-view-component="true">July 21, 2023 09:46</relative-time>
          </p>

        </div>
        <div role="row">
          

          <div role="rowheader">
            <p><span><a title="README.md" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/README.md">README.md</a></span>
          </p></div>

          <div role="gridcell">
              <p><span>
                    <a data-pjax="true" title="Update spec link to be github page instead" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/b8a049e76e04de712993a821a7482a85e281adbc">Update spec link to be github page instead</a>
              </span>
          </p></div>

          <p role="gridcell">
              <relative-time tense="past" datetime="2023-06-21T10:00:27Z" data-view-component="true">June 21, 2023 10:00</relative-time>
          </p>

        </div>
        <div role="row">
          

          <div role="rowheader">
            <p><span><a title="explainer.md" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/explainer.md">explainer.md</a></span>
          </p></div>

          <div role="gridcell">
              <p><span>
                    <a data-pjax="true" title="use eTLD+1, not TLD" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/c7366e82ecdba4c49aef945175ef90e8c9d6b47d">use eTLD+1, not TLD</a>
              </span>
          </p></div>

          <p role="gridcell">
              <relative-time tense="past" datetime="2023-04-27T10:01:28+01:00" data-view-component="true">April 27, 2023 10:01</relative-time>
          </p>

        </div>
    </div>




</div>

  
    
      <div id="readme" data-tagsearch-path="README.md" data-tagsearch-lang="Markdown">

        <div>
          <p>
            <h2>
              <a href="#readme" data-view-component="true">README.md</a>
            </h2>
          </p>
        </div>

          <div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">Web Environment Integrity API</h2>
<p dir="auto">This repository details the proposal to add a new API for determining the integrity
of web environments:</p>
<div dir="auto" data-snippet-clipboard-copy-content="const attestation = await navigator.getEnvironmentIntegrity(&quot;...&quot;);"><pre><span>const</span> <span>attestation</span> <span>=</span> <span>await</span> <span>navigator</span><span>.</span><span>getEnvironmentIntegrity</span><span>(</span><span>"..."</span><span>)</span><span>;</span></pre></div>
<p dir="auto">The <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/explainer.md">explainer</a> goes gives a high level overview of the proposal.</p>
<p dir="auto">The <a href="https://rupertbenwiser.github.io/Web-Environment-Integrity/" rel="nofollow">spec</a> currently describes how this is being prototyped in Chromium.</p>
</article>
          </div>
      </div>



</div>
  <div data-pjax="" data-view-component="true">
        <div>
            <h2>About</h2>

    <p>
      No description, website, or topics provided.
    </p>


    <h3>Resources</h3>
    <p>
      <a data-analytics-event="{&quot;category&quot;:&quot;Repository Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:readme&quot;}" href="#readme">
        
        Readme
</a>    </p>

  

    <h3>Code of conduct</h3>
    <p>
      <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/CODE_OF_CONDUCT.md" data-analytics-event="{&quot;category&quot;:&quot;Repository Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:code of conduct&quot;}">
        
        Code of conduct
      </a>
    </p>


<include-fragment src="/RupertBenWiser/Web-Environment-Integrity/hovercards/citation/sidebar_partial?tree_name=main">
</include-fragment>



<p>
  <a data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/activity" data-view-component="true">
    
    <span>Activity</span>
</a></p>

<h3>Stars</h3>
<p>
  <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/stargazers" data-view-component="true">
    
    <strong>64</strong>
    stars
</a></p>

<h3>Watchers</h3>
<p>
  <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/watchers" data-view-component="true">
    
    <strong>20</strong>
    watching
</a></p>

<h3>Forks</h3>
<p>
  <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/forks" data-view-component="true">
    
    <strong>21</strong>
    forks
</a></p>

  <div>
    <p><a href="https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FRupertBenWiser%2FWeb-Environment-Integrity&amp;report=RupertBenWiser+%28user%29">
        Report repository
</a>  </p></div>

          </div>

        
        
            <div>
                <h2 data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame">
  <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/releases" data-view-component="true">
    Releases
</a></h2>

    <p>No releases published</p>

              </div>

        
        
            <div>
                <h2>
  <a href="https://github.com/users/RupertBenWiser/packages?repo_name=Web-Environment-Integrity" data-view-component="true">
    Packages
      
</a></h2>


      <p>
        No packages published <br>
      </p>



              </div>

        
        
            <div>
                <h2>
  <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/graphs/contributors" data-view-component="true">
    Contributors
      <span title="3" data-view-component="true">3</span>
</a></h2>


    
  <ul>
    <li>
      <a href="https://github.com/apps/github-actions">
        <img src="https://avatars.githubusercontent.com/in/15368?s=64&amp;v=4" alt="@github-actions[bot]" size="32" height="32" width="32" data-view-component="true">
      </a>
      <span data-view-component="true">
        <a href="https://github.com/apps/github-actions">
          <strong>github-actions[bot]</strong>
          
        </a>
</span>    </li>
    <li>
      <a href="https://github.com/yoavweiss" data-hovercard-type="user" data-hovercard-url="/users/yoavweiss/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self">
        <img src="https://avatars.githubusercontent.com/u/786187?s=64&amp;v=4" alt="@yoavweiss" size="32" height="32" width="32" data-view-component="true">
      </a>
      <span data-view-component="true">
        <a href="https://github.com/yoavweiss">
          <strong>yoavweiss</strong>
          <span>Yoav Weiss</span>
        </a>
</span>    </li>
    <li>
      <a href="https://github.com/bakkot" data-hovercard-type="user" data-hovercard-url="/users/bakkot/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self">
        <img src="https://avatars.githubusercontent.com/u/1653598?s=64&amp;v=4" alt="@bakkot" size="32" height="32" width="32" data-view-component="true">
      </a>
      <span data-view-component="true">
        <a href="https://github.com/bakkot">
          <strong>bakkot</strong>
          <span>Kevin Gibbons</span>
        </a>
</span>    </li>
</ul>





              </div>

        
        
              </div>
  
</div></div>

</turbo-frame>


    </main>
  </div>

          




  

    <template id="site-details-dialog">
  <details class="details-reset details-overlay details-overlay-dark lh-default color-fg-default hx_rsm" open="">
    <summary role="button" aria-label="Close dialog"></summary>
    <details-dialog class="Box Box--overlay d-flex flex-column anim-fade-in fast hx_rsm-dialog hx_rsm-modal">
      <button class="Box-btn-octicon m-0 btn-octicon position-absolute right-0 top-0" type="button" aria-label="Close dialog" data-close-dialog="">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
      </button>
      <div class="octocat-spinner my-6 js-details-dialog-spinner"></div>
    </details-dialog>
  </details>
</template>

    

    <template id="snippet-clipboard-copy-button">
  <div class="zeroclipboard-container position-absolute right-0 top-0">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn js-clipboard-copy m-2 p-0 tooltipped-no-delay" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon m-2">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none m-2">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>
<template id="snippet-clipboard-copy-button-unpositioned">
  <div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 tooltipped-no-delay d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>




    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TSMC warns over deepening slump in chipmaking sector (101 pts)]]></title>
            <link>https://www.ft.com/content/f433971d-fd8e-4ed3-91e9-e25a96284ea0</link>
            <guid>36817267</guid>
            <pubDate>Fri, 21 Jul 2023 18:06:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ft.com/content/f433971d-fd8e-4ed3-91e9-e25a96284ea0">https://www.ft.com/content/f433971d-fd8e-4ed3-91e9-e25a96284ea0</a>, See on <a href="https://news.ycombinator.com/item?id=36817267">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="site-content" data-trackable="trial-barrier-grid" data-barrier="trial" data-barrier-is-sandbox="false">
			<div data-o-component="o-subs-card" data-offer-id="41218b9e-c8ae-c934-43ad-71b13fcb4465" data-offer-prominence="primary" data-offer-title="Trial" data-tracking-context="{&quot;title&quot;:&quot;Trial&quot;,&quot;brief&quot;:&quot;Try full digital access and see why over 1 million readers subscribe to the FT&quot;,&quot;offerId&quot;:&quot;41218b9e-c8ae-c934-43ad-71b13fcb4465&quot;,&quot;price&quot;:&quot;$1 for 4 weeks&quot;,&quot;prominence&quot;:&quot;primary&quot;,&quot;skuIds&quot;:[],&quot;description&quot;:&quot;For 4 weeks receive unlimited Premium digital access to the FT's trusted, award-winning business news&quot;}">
					<h3>Try unlimited access</h3>

					<p>Try full digital access and see why over 1 million readers subscribe to the FT</p><p>Only
						CHF&nbsp;1 for 4 weeks
				</p>

					

				</div>
			<p>
				<h4>Explore our subscriptions</h4>
			</p>
			<div>
					<h5>Individual</h5>
					<p>Find the plan that suits you best.</p>
					
				</div>
			<div>
					<h5>Professional</h5>
					<p>Premium access for businesses and educational institutions.</p>
					
				</div>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: What are the best papers you read in your life? (188 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=36817231</link>
            <guid>36817231</guid>
            <pubDate>Fri, 21 Jul 2023 18:04:01 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=36817231">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="36818754"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36818754" href="https://news.ycombinator.com/vote?id=36818754&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Claude Shannon's "A Mathematical Theory of Communication"[1] is often considered a classic. I think this is because:<p>1. It's quite readable as a narrative.</p><p>2. The maths is not pages of first principle derivations as if the reader is not familiar with the basics of algebraic substitution.</p><p>3. The diagrams and graphs are genuinely useful and remove the need for many, many thousands of words that others may have used instead of, or in addition to, the core narrative.</p><p>4. It deals with an abstract concept but roots it in concrete mathematical and physical terms. He touches on specific examples.</p><p>5. It's quite short given the breadth of subject area.</p><p>[1] <a href="https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf" rel="nofollow noreferrer">https://people.math.harvard.edu/~ctm/home/text/others/shanno...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36819339"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36819339" href="https://news.ycombinator.com/vote?id=36819339&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>His easily-understandable yet mind-blowing ideas of hyperspheres of information (and a reliable communications channel having a definition!? What?) changed my brain permanently.<p>This is the paper I was going to cite as well.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="36819215"><td></td></tr>
            <tr id="36818482"><td></td></tr>
            <tr id="36818350"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36818350" href="https://news.ycombinator.com/vote?id=36818350&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>If you are looking for quality I suggest you look at the IPCC reports. Each word is carefully chosen, every claim backed by mountains of evidence. They're written to be read and understood by non-experts. They exist to inform decision making that will literally determine the fate of our species. As such, they may be failing at their goal, but not for a lack of effort by the authors.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36818777"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36818777" href="https://news.ycombinator.com/vote?id=36818777&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>Agreed, with one caveat. Over time governments have more and more been trying to influence the reports. It all came to a head with the last one, where a set of researchers released their draft ahead of time in protest over undue influence. They still synthesize relevant research from past years, but there are some problems now. Research published after the first draft cannot be included, so the report is somewhat outdated by the time it's released. Beautifully crafted though.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36818726"><td></td></tr>
                  <tr id="36821453"><td></td></tr>
            <tr id="36818660"><td></td></tr>
            <tr id="36819037"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819037" href="https://news.ycombinator.com/vote?id=36819037&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Gillian Russell, “Epistemic Viciousness in the Martial Arts,”<p>It is about traditional martial arts masters, trapped in their echo chamber, sniffing their own farts. The whole industry gets its ass kicked by mixed martial arts. Basically street thugs versus shaolin kung fu masters.</p><p>it describes in-group bias, echo chambers, and cognitive dissonance in large groups. Very applicable in modern science, politics and so on.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36817581"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36817581" href="https://news.ycombinator.com/vote?id=36817581&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>The Bitcoin whitepaper. It started my curiosity in the computer security industry (employed for 5 years now) and the rabbithole of trying to understand every design decision behind the cryptosystem.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36818276"><td></td></tr>
            <tr id="36818960"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36818960" href="https://news.ycombinator.com/vote?id=36818960&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>Agreed, this is a must-read, very well-written paper. Even though it turned out the world didn't really need cryptocurrencies.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36820340"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36820340" href="https://news.ycombinator.com/vote?id=36820340&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Agree with your assessment of cryptocurrencies in general but having seen the adoption of Bitcoin in authoritarian and inflationary regimes, the world most certainly does need access to a digital peer-to-peer currency that is censorship-resistant and virtually immune to debasement.<p>Even if you argue that Bitcoin as it has evolved has flaws, it is the best implementation we’ve come up with so far. Like democracy, it isn’t perfect but it is much better for its use case than anything else we have come up with to date.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="36820043"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36820043" href="https://news.ycombinator.com/vote?id=36820043&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>The Bitcoin whitepaper is one of my cherished reads. The other is the BitTorrent whitepaper. Both technologies changed the technical and non-technical worlds, and the fundamental protocols are clearly explained in their respective papers.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36818851"><td></td></tr>
            <tr id="36818368"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36818368" href="https://news.ycombinator.com/vote?id=36818368&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>Not sure anybody here appreciates social science, but I will never not give a shout-out to "Decoupling Rape" by Whiteman and Cooper. Such an authentic account, while still managing to stay relevant to abstract and higher-order debates in my field. I suspect many have not read it because it is so heart-wrenching though.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36818521"><td></td></tr>
                <tr id="36818709"><td></td></tr>
                        <tr id="36818604"><td></td></tr>
            <tr id="36821359"><td></td></tr>
            <tr id="36818397"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36818397" href="https://news.ycombinator.com/vote?id=36818397&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Like Kleobis and Biton, we won't know until I am dead.<p>However thus far, a paper that literally changed my life: "Value Dependence Graphs: Representation Without Taxation", D. Weise, R. F. Crew, M. Ernst, B. Steensgaard, POPL 1994.  (This was the proverbial butterfly flap that moved me through three countries).</p><p>There are many many other good papers and it's not a one-dimension metric so it's hard to pick out winners.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36819045"><td></td></tr>
                <tr id="36819896"><td></td></tr>
                  <tr id="36820899"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36820899" href="https://news.ycombinator.com/vote?id=36820899&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Probably this paper [1] is very well known among the classic HN audience, but I dare to leave this link here for the ones who missed it. It is an easy read and it just explains with plain words the backbone of the UNIX system as it was envisioned 50 years ago.<p>[1] <a href="https://dsf.berkeley.edu/cs262/unix.pdf" rel="nofollow noreferrer">https://dsf.berkeley.edu/cs262/unix.pdf</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36819051"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819051" href="https://news.ycombinator.com/vote?id=36819051&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>"A Security Kernel Based on the Lambda-Calculus" by Jonathan A. Rees is pretty high up there: <a href="https://dspace.mit.edu/handle/1721.1/5944" rel="nofollow noreferrer">https://dspace.mit.edu/handle/1721.1/5944</a><p>I read this a few years back as I was going down an object-capability rabbit hole and found it extremely compelling. (And also made me disappointed that most of the systems we use today do not work like this! Code execution vulnerabilities would be so much less immediately hazardous if they did.)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36818522"><td></td></tr>
            <tr id="36819113"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819113" href="https://news.ycombinator.com/vote?id=36819113&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>This is probably among the best I have read: <a href="https://scholars.unh.edu/cgi/viewcontent.cgi?article=1462&amp;context=dissertation" rel="nofollow noreferrer">https://scholars.unh.edu/cgi/viewcontent.cgi?article=1462&amp;co...</a><p>In a system with growing inequality where the rich benefit at the expense of the poor, this artificial redistribution can go on for some time, but once the inequality gets so bad that people revolt, then the amount of "guard labor" that needs to be performed goes up. Poverty and desperation makes people more likely to perform "guard labor" because it gives them a chance to escape poverty and avoid being targeted themselves which further feeds into authoritarian politicians gaining more power as they have no trouble finding soldiers willing to maintain the inequality. This works but only until guard labor reaches such a critical mass that half the population engages in it. Once that point is crossed, guard labor will start defecting against the current political leadership and conduct a military coup.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36818472"><td></td></tr>
            <tr id="36819993"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819993" href="https://news.ycombinator.com/vote?id=36819993&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Congestion Avoidance and Control (1988) by Van Jacobson: <a href="https://ee.lbl.gov/papers/congavoid.pdf" rel="nofollow noreferrer">https://ee.lbl.gov/papers/congavoid.pdf</a><p>Often called "the paper which saved the internet" due to solving congestion collapse on the ARPANET, and inventing the fundamentals of TCP Congestion Control still used countless times every single day on all computers everywhere. It's very readable and presents complex math in easily understood graphs for non-math people.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36820767"><td></td></tr>
            <tr id="36818724"><td></td></tr>
            <tr id="36818995"><td></td></tr>
                <tr id="36820616"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36820616" href="https://news.ycombinator.com/vote?id=36820616&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>I remember seeing “Possible Girls” cited somewhere as an example of the pointlessness of contemporary academic philosophy, but for years I couldn't find it again. A very entertaining re-read, thanks for sharing.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36819937"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819937" href="https://news.ycombinator.com/vote?id=36819937&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>A quantitative description of membrane current and its application to conduction and excitation in nerve
A L HODGKIN, A F HUXLEY
J Physiol. 1952 Aug;117(4):500-44.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36818376"><td></td></tr>
                <tr id="36818908"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36818908" href="https://news.ycombinator.com/vote?id=36818908&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Didn't think I'd come across a DTW paper here.<p>Have you seen anything worth reading in that line of literature which addresses a more practical issue of segment sizing and segment overlap on accuracy?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="36819023"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819023" href="https://news.ycombinator.com/vote?id=36819023&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>“What is it like to be a bat” (Nagel)<p>“The Spandrels of San Marco and the Panglossian Paradigm”, (Gould et al)</p><p>“ A quantitative description of membrane current and its application to conduction and excitation in nerve” (hodgkin and huxley)</p><p>a few other that don’t come to mind right now
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36819126"><td></td></tr>
            <tr id="36818311"><td></td></tr>
            <tr id="36819093"><td></td></tr>
                <tr id="36821415"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36821415" href="https://news.ycombinator.com/vote?id=36821415&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>There's a lot of non-Chomskian linguistics out there. Basically if you look for "linguistic typology" there's a probably at least 90% chance that Chomsky will be totally irrelevant.<p>(Some of my favourites in that area used to be Martin Haspelmath, Balthasar Bickel, Gilbert Lazard, ... - but I haven't kept myself up to date with the literature for years now)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="36819313"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819313" href="https://news.ycombinator.com/vote?id=36819313&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>My idea of being explicit and clear changed dramatically after I was exposed to D. Harel's "Statecharts: a visual formalism for complex systems".<p>Ironically, I think the paper presents more than just the idea and examples of statecharts, rather it also _implicitly_ contains a _method_ for discovering mechanism - the long winded example of the author's digital watch, in my eyes, is a marvel.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36819208"><td></td></tr>
            <tr id="36819111"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819111" href="https://news.ycombinator.com/vote?id=36819111&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>Have most people read a paper? I see threads like these with some many interesting suggestion, but are they read by people outside of their general area of study or expertise? I read quite a bit of fiction, but I've never really been able to read anything much past an abstract which much understanding. I have no science background. Am I missout on something?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36820644"><td></td></tr>
            <tr id="36819246"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36819246" href="https://news.ycombinator.com/vote?id=36819246&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>Generally you need background knowledge to read papers. A quick way to gain necessary background knowledge is to read literature reviews or surveys. If you can't understand even reviews, surveys, or introductions, it is time to read textbooks.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36818920"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36818920" href="https://news.ycombinator.com/vote?id=36818920&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>"Retinoic Acid and Arsenic Trioxide for Acute Promyelocytic Leukemia" by Lo-Coco et al. from 2013.[0]<p>This paper presents a cure for an extremely aggressive cancer using vitamin A and arsenic. Its a unique, relatively benign treatment strategy that completely avoids chemotherapy. As far as I know this is the best result in all of oncology, though the cancer it treats is very rare.</p><p>The most well known paper in oncology that is probably more interesting to a general audience is "The Hallmarks of Cancer" by Hanahan and Weinberg.[1]</p><p>[0] <a href="https://www.nejm.org/doi/full/10.1056/nejmoa1300874" rel="nofollow noreferrer">https://www.nejm.org/doi/full/10.1056/nejmoa1300874</a></p><p>[1] <a href="https://www.cell.com/cell/fulltext/S0092-8674(00)81683-9?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0092867400816839%3Fshowall%3Dtrue" rel="nofollow noreferrer">https://www.cell.com/cell/fulltext/S0092-8674(00)81683-9?_re...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36819128"><td></td></tr>
            <tr id="36818962"><td></td></tr>
            <tr id="36818985"><td></td></tr>
            <tr id="36818688"><td></td></tr>
                <tr id="36818888"><td></td></tr>
                <tr id="36818987"><td></td></tr>
                        <tr id="36819024"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819024" href="https://news.ycombinator.com/vote?id=36819024&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>I can give example of one of worst papers.<p>Original IPFS paper is one of worst papers that I had read.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36820673"><td></td></tr>
                  <tr id="36819087"><td></td></tr>
            <tr id="36819066"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819066" href="https://news.ycombinator.com/vote?id=36819066&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>Lisanne Bainbridge, Ironies of Automation. Especially timely now when every company is bolting a LLM onto the side of their software.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36820388"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36820388" href="https://news.ycombinator.com/vote?id=36820388&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Not a paper, but <i>The Extravagant Universe</i> by Robert Kirschner describes decades worth of observation and data collection in astronomy, coming together with experimental discoveries from particle colliders and evolving theory in order to eventually converge upon the now-standard ΛCDM model in cosmology. Also includes an enormous background on the century worth of discoveries that eventually resulted in the type-1A supernova becoming a sufficiently reliable standard candle to measure the distance to galaxies far enough away that the redshift demonstrated accelerating expansion of the universe. So many things they needed to work out, from dust diffraction patterns to the differences in how spectrum evolves over the two weeks or so from the initial explosion event to figure out exactly when in the timeline each observation is taking place. Combine that with the logistics of telescope scheduling and the sparsity of observations when you're looking at something as large as the entire universe and your telescope can only cover so much at any one time. It gives you a tremendous appreciation for the sheer amount of work and patience that goes into this, slowly collecting evidence over decades, waiting for technology to develop before certain evidence is even possible to collect, and eventually seeing lines of evidence all point in the same direction, but only after a literal lifetime of work to get there.<p>Nothing else has ever made me appreciate how hard science really is and how little the general public understands it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mali Government takes back .ml domain, brings down one of largest Lemmy servers (124 pts)]]></title>
            <link>https://very.bignutty.xyz/notes/9hfv05qcs5xf7irr</link>
            <guid>36817179</guid>
            <pubDate>Fri, 21 Jul 2023 18:00:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://very.bignutty.xyz/notes/9hfv05qcs5xf7irr">https://very.bignutty.xyz/notes/9hfv05qcs5xf7irr</a>, See on <a href="https://news.ycombinator.com/item?id=36817179">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="splash"><p><img id="splashIcon" src="https://very.bignutty.xyz/static-assets/splash.svg?1689984012144"><span id="splashText">Loading...</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Death Valley Just Had the Hottest Midnight on Record (106 pts)]]></title>
            <link>https://www.msn.com/en-us/weather/topstories/death-valley-just-had-the-hottest-midnight-on-record/ar-AA1e2u4W</link>
            <guid>36817046</guid>
            <pubDate>Fri, 21 Jul 2023 17:50:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.msn.com/en-us/weather/topstories/death-valley-just-had-the-hottest-midnight-on-record/ar-AA1e2u4W">https://www.msn.com/en-us/weather/topstories/death-valley-just-had-the-hottest-midnight-on-record/ar-AA1e2u4W</a>, See on <a href="https://news.ycombinator.com/item?id=36817046">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[There’s a heatwave in the sea and scientists are worried (146 pts)]]></title>
            <link>https://www.bbc.com/future/article/20230720-theres-a-heatwave-in-the-sea-and-scientists-are-worried</link>
            <guid>36816982</guid>
            <pubDate>Fri, 21 Jul 2023 17:45:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/future/article/20230720-theres-a-heatwave-in-the-sea-and-scientists-are-worried">https://www.bbc.com/future/article/20230720-theres-a-heatwave-in-the-sea-and-scientists-are-worried</a>, See on <a href="https://news.ycombinator.com/item?id=36816982">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="headline-futurearticle20230720-theres-a-heatwave-in-the-sea-and-scientists-are-worried"><div><p>(Image credit: </p><!-- --><p>European Union/Copernicus Sentinel-2</p><!-- --><p>)</p></div><div><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0g237hm.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0g237hm.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0g237hm.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0g237hm.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0g237hm.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0g237hm.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0g237hm.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0g237hm.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="Satellite image of coral bleaching at Islamorada, Florida (Credit: European Union/Copernicus Sentinel-2)" src="https://ychef.files.bbci.co.uk/976x549/p0g237hm.jpg" alt="Satellite image of coral bleaching at Islamorada, Florida (Credit: European Union/Copernicus Sentinel-2)" id=""></picture></div></div><div><article><div><p>Could warmer ocean temperatures be a sign climate change has progressed further than we thought?</p><div><p>T</p><div><p>The month of June and the first few days of July were hotter than any in recorded history, <a href="https://public.wmo.int/en/media/news/preliminary-data-shows-hottest-week-record-unprecedented-sea-surface-temperatures-and">according to the World Meteorological Organization (WMO)</a>. Residents in the south of the US and <a href="https://www.bbc.com/news/world-europe-66242277">southern Europe</a> have been enduring sweltering temperatures, bringing <a href="https://www.bbc.co.uk/news/world-us-canada-66218321">excessive heat warnings</a>, <a href="https://www.bbc.com/news/science-environment-66237960">wildfires</a> and <a href="https://www.bbc.com/reel/video/p0fz7y12/why-extreme-heat-makes-air-quality-worse">plummeting air quality</a>. However, records are not just being broken on land – but in the water.</p>
<p>Global ocean sea surface temperatures were higher than any previous June on record, according to a <a href="https://climate.copernicus.eu/copernicus-record-north-atlantic-warmth-hottest-june-record-globally">report by the Copernicus Climate Change Service</a>, with satellite readings in the <a href="https://climate.copernicus.eu/record-breaking-north-atlantic-ocean-temperatures-contribute-extreme-marine-heatwaves">North Atlantic in particular "off the charts</a>". Last month also <a href="https://www.noaa.gov/news/earth-just-had-its-hottest-june-on-record">set a record</a> at the US National Oceanic and Atmospheric Administration (NOAA) for the biggest difference between expected and actual sea surface temperatures.</p>
<p><a href="https://www.noaa.gov/news/ongoing-marine-heat-waves-in-us-waters-explained">Water temperatures around Florida</a>, in particular, <a href="https://twitter.com/BMcNoldy/status/1678095286206382086">have been particularly warm</a>. Scientists have also been <a href="https://www.integratedecosystemassessment.noaa.gov/regions/california-current/california-current-marine-heatwave-tracker-blobtracker">tracking a large ongoing marine heatwave off the west coast of the US and Canada</a>&nbsp;since it formed in May.</p>
<p>While the heatwave has since lessened in the north-east Atlantic, according to non-profit science organisation&nbsp;<a href="https://www.mercator-ocean.eu/en/news/mercator-ocean-marine-heatwave-bulletin-for-11-july-2023">Mercator Ocean</a> International, another in the western Mediterranean now appears to be intensifying, particularly around the Strait of Gibraltar. This week, sea surface temperatures along the coasts of Southern Spain and North Africa were 2-4C (3.6-7.2F) higher than they would normally be at this time of year, with some spots 5C (9F) above the long-term average.</p>
<p>Extreme marine temperatures have also recently been observed around <a href="https://www.esa.int/ESA_Multimedia/Images/2023/06/UK_suffers_marine_heatwave">Ireland, the UK and in the Baltic Sea</a>, as well as <a href="https://www.mercator-ocean.eu/en/news/sea-surface-temperatures-record-high-2023/">areas near New Zealand and Australia</a>. More recently, scientists <a href="https://www.mercator-ocean.eu/en/news/marine-heatwaves-europe-july-18-2023/">suspect a possible heatwave</a> south of Greenland in the Labrador Sea.</p>
<p>"We are having these huge marine heatwaves in different areas of the ocean unexpectedly evolve very early in the year, very strong and over large areas," says Karina von Schuckmann, an oceanographer at Mercator Ocean.</p></div></div><div id="future/article/20230720-theres-a-heatwave-in-the-sea-and-scientists-are-worried-p0g237dg"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0g237dg.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0g237dg.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0g237dg.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0g237dg.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0g237dg.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0g237dg.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0g237dg.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0g237dg.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="The northern Atlantic Ocean and Mediterranean Sea have experienced record-breaking sea temperatures over the past few months (Credit: European Union/Copernicus)" src="https://ychef.files.bbci.co.uk/976x549/p0g237dg.jpg" alt="The northern Atlantic Ocean and Mediterranean Sea have experienced record-breaking sea temperatures over the past few months (Credit: European Union/Copernicus)" id=""></picture><div><p>The northern Atlantic Ocean and Mediterranean Sea have experienced record-breaking sea temperatures over the past few months (Credit: European Union/Copernicus)</p></div></div><div><p>Carlo Buontempo, director of the European Union's Copernicus Climate Change Service, says scientists expect big temperature variations in the Pacific Ocean associated with the <a href="https://www.bbc.com/future/article/20230525-what-will-an-el-nino-in-2023-mean-for-you">El Niño weather</a> pattern, a phase of planet-warming weather <a href="https://www.bbc.co.uk/news/science-environment-65839060">which is just beginning</a><em>, </em>although NOAA is <a href="https://www.noaa.gov/news/ongoing-marine-heat-waves-in-us-waters-explained">monitoring</a> a large heatwave in the Gulf of Alaska that has been sitting offshore since late 2022. (<em>Read more from BBC Future about <a href="https://www.bbc.com/future/article/20230525-what-will-an-el-nino-in-2023-mean-for-you">what another El Niño will mean for you</a></em>.)</p>
<p>But what we're currently seeing in the North Atlantic is "truly unprecedented", says Buontempo.</p>
<p>Scientists are still trying to unravel its full causes.</p>
<p>Short-term changes in regional atmospheric and ocean circulation patterns can provide the conditions for periods of intense heat in the sea lasting for weeks, months or even years.</p>
<p>But long-term increases in ocean temperature driven by an increase in greenhouse gas emissions are a key factor in recent heatwaves. About 90% of excess heat generated by anthropogenic climate change has been stored in the ocean, and the past two decades have seen a <a href="https://essd.copernicus.org/articles/15/1675/2023/essd-15-1675-2023.html">doubling in the rate of heat</a> accumulating in the Earth's climate system.</p>
<p><em>You might also like:</em></p>
<ul>
<li><strong><a href="https://www.bbc.com/future/article/20230706-the-simple-ways-cities-can-adapt-to-heatwaves">The simple ways cities can adapt to heatwaves</a>)</strong></li>
<li><strong><a href="https://www.bbc.com/future/article/20230718-the-fiery-row-behind-europes-mythological-heatwave-names">The fiery row behind Europe's mythological heatwave names</a></strong></li>
<li><strong><a href="https://www.bbc.com/future/article/20230630-will-texas-become-too-hot-for-humans">Will Texas become too hot for humans?</a></strong></li>
</ul>
<p>A 2021 <a href="https://www.ipcc.ch/report/ar6/wg1/chapter/chapter-9/">expert report</a> by the Intergovernmental Panel on Climate Change (IPCC) found marine heatwaves doubled in frequency between 1982 and 2016, and have become both more intense and longer since the 1980s.</p>
<p>Another potential contributing factor is the volume of aerosols in the atmosphere, which <a href="https://earthobservatory.nasa.gov/features/Aerosols">have a slight cooling effect</a> but appear to <a href="https://www.nasa.gov/feature/esnt/2022/nasa-study-finds-evidence-that-fuel-regulation-reduced-air-pollution-from-shipping">have dropped</a> as a result of a drive to clean up the shipping industry. More recently, there has been an unusual lack of dust blown from the Sahara, which also normally has <a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2021JC017282">a cooling impact</a>.</p></div><div><p>The current marine heatwaves could even get worse. While experts do not think <a href="https://public.wmo.int/en/media/press-release/world-meteorological-organization-declares-onset-of-el-ni%C3%B1o-conditions">El Niño</a> itself was a driver of the North Atlantic event, <a href="https://public.wmo.int/en/media/news/preliminary-data-shows-hottest-week-record-unprecedented-sea-surface-temperatures-and">the WMO expects it</a> to add fuel to wider ocean heating.</p>
<p>Experts are concerned because marine heatwaves can affect ocean life, fisheries and weather patterns.</p>
<p>Record high temperatures along the Western Australian coast during the summer of 2010/2011 resulted in "<a href="https://www.sciencedirect.com/science/article/abs/pii/S0924796312002059?via%3Dihub">devastating" fish mortality</a>&nbsp;and destroyed kelp forests, <a href="https://link.springer.com/chapter/10.1007/978-3-030-71330-0_12">fundamentally changing the coastal ecosystem</a>. Several years later, an unprecedented marine heatwave caused by climate change and amplified by a strong El Niño caused <a href="https://elibrary.gbrmpa.gov.au/jspui/bitstream/11017/3206/1/Final-report-2016-coral-bleaching-GBR.pdf">the worst coral bleaching ever seen</a> on the Great Barrier Reef in 2016.</p>
<p>Marine heatwaves can <a href="https://www.nature.com/articles/s41598-018-24530-9">trigger mass coral bleaching events</a> and have already been increasing the <a href="https://www.nature.com/articles/s41586-018-0041-2">stress that reef ecosystems</a> are under around the world. The high termpeatures can cause the coral polyps to expel the zooxanthellae living inside their tissue, causing them to turn white and leaving them <a href="https://oceanservice.noaa.gov/facts/coral_bleach.html">more vulnerable to disease and other threats</a>.</p>
<p>In the Mediterranean Sea, exceptional temperatures over the 2015-19 period led to <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/gcb.16301">repeated mass deaths</a> of key species such as corals and seaweed. <a href="https://www.annualreviews.org/doi/abs/10.1146/annurev-marine-032122-121437">One recent study</a> described marine heatwaves such as these as "pervasive stressors to marine ecosystems globally".</p>
<p>Marine heatwaves are also making it easier for <a href="https://www.iucn.org/resources/issues-briefs/invasive-alien-species-and-climate-change">invasive species</a> to thrive. Japanese kelp, for example, <a href="https://www.frontiersin.org/articles/10.3389/fmars.2019.00084/full">proliferated in New Zealand</a> when a marine heatwave in 2017-2018 in the Tasman Sea killed off <a href="https://www.frontiersin.org/articles/10.3389/fmars.2019.00084/full">native southern bull kelp</a> in the area.</p>
<p>Dan Smale, a marine ecologist at the UK's Marine Biological Association and a member of the <a href="http://www.marineheatwaves.org/">Marine Heatwaves International Working Group</a>, says "short, sharp shocks" do not give species time to redistribute and <a href="https://www.nature.com/articles/s41558-019-0412-1">those at the limit of temperatures their bodies can cope with are particularly at risk</a>. But even around the UK coastline, which is not considered to be an extreme environment and where scientists expect ecosystems to gradually change, a marine heatwave could end up being lethal if it continues through the summer.&nbsp;</p>
<p>However, there is still a lot to learn about the impact of marine heatwaves compared with those on land because monitoring is more difficult and there is a lack of long-term records, says Smale. "The data we get from satellites since the early 1980s has been amazing… but the problem is trying to then go deeper," he says.</p></div><div id="future/article/20230720-theres-a-heatwave-in-the-sea-and-scientists-are-worried-p0g237j6"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0g237j6.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0g237j6.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0g237j6.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0g237j6.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0g237j6.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0g237j6.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0g237j6.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0g237j6.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="High water temperatures can destroy vital marine habitats such as kelp forests, which offer sanctuary and provide food for many fish species (Credit: Getty Images)" src="https://ychef.files.bbci.co.uk/976x549/p0g237j6.jpg" alt="High water temperatures can destroy vital marine habitats such as kelp forests, which offer sanctuary and provide food for many fish species (Credit: Getty Images)" id=""></picture><div><p>High water temperatures can destroy vital marine habitats such as kelp forests, which offer sanctuary and provide food for many fish species (Credit: Getty Images)</p></div></div><div><p>A significant drop in phytoplankton <a href="https://www.mercator-ocean.eu/en/news/record-high-sea-surface-temperatures-north-atlantic-drop-in-phytoplankton-el-nino-costal-el-nino/">has already been seen</a> in the western North Atlantic, which Mercator Ocean attributes to the recent heatwave. This spring bloom is crucial because it <a href="https://www.mccip.org.uk/sites/default/files/2021-07/15_plankton_2020.pdf">provides most of the energy</a> needed to sustain the region's marine food chain and makes a substantial contribution to global ocean CO2 uptake.</p>
<p>The economics of regional fisheries could be affected too. A 2012 heatwave over the north-west Atlantic led marine species that favour warm water to move northwards and migrate earlier, <a href="https://tos.org/oceanography/article/fisheries-management-in-a-changing-climate-lessonsfrom-the-2012-ocean-heat-">changing when and how much</a> seafood could be caught.</p>
<p>The North Atlantic is also a key driver of extreme weather. High sea surface temperatures <a href="https://www.nasa.gov/audience/forstudents/k-4/stories/nasa-knows/what-are-hurricanes-k4.html">can fuel hurricanes</a>, although whether the developing El Niño will exacerbate or <a href="https://doi.org/10.1175/JCLI-D-13-00687.1">dampen this effect</a> over the next year remains to be seen. Further inland, the warmth of the North Atlantic is the most important factor behind the alternating cycle of drought and heavy rain in <a href="https://earthobservatory.nasa.gov/images/88670/atlantic-multi-decadal-oscillation-and-drought-in-africa">central Africa</a>.</p>
<p>More broadly, experts say the persistence of recent marine heatwaves is a worrying sign about how climate change is unfolding, alongside <a href="https://www.bbc.co.uk/news/world-europe-66197368">heatwaves on land</a>, unusual <a href="https://www.researchgate.net/publication/371731505_Water_ice_society_and_ecosystems_in_the_Hindu_Kush_Himalaya_An_outlook">melting of snow cover in the Himalayas</a> and a <a href="https://www.bbc.com/news/science-environment-64649596">loss of sea ice</a>. Von Schuckmann notes that, even if humans stopped pumping CO2 into the air tomorrow, the oceans would continue to warm up for many years yet. "I am concerned as a climate scientist that we are further than we thought we are."</p>
<p>--</p>
<p><em>Join one million Future fans by liking us on </em><a href="https://www.facebook.com/BBCFuture/"><strong><em>Facebook</em></strong></a><em>, or follow us on </em><a href="https://twitter.com/BBC_Future"><strong><em>Twitter</em></strong></a><em> or </em><a href="https://www.instagram.com/bbcfuture_official/"><strong><em>Instagram</em></strong></a><em>.</em></p>
<p><em>If you liked this story, </em><a href="https://cloud.email.bbc.com/SignUp10_08"><strong><em>sign up for the weekly bbc.com features newsletter</em></strong></a><em>, called "The Essential List" – a handpicked selection of stories from BBC </em><a href="https://www.bbc.com/future/"><strong><em>Future</em></strong></a><em>, </em><a href="https://www.bbc.com/culture/"><strong><em>Culture</em></strong></a><em>, </em><a href="https://www.bbc.com/worklife/"><strong><em>Worklife</em></strong></a><em>, </em><a href="https://www.bbc.com/travel/"><strong><em>Travel</em></strong></a> <em>and </em><a href="https://www.bbc.com/reel"><strong><em>Reel</em></strong></a><em> delivered to your inbox every Friday.</em></p></div></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA['Mystery company' buys land worth $800M near Travis AFB, raising concerns (110 pts)]]></title>
            <link>https://abc7news.com/travis-afb-air-force-base-flannery-associates-llc-john-garamendi/13527836/</link>
            <guid>36816387</guid>
            <pubDate>Fri, 21 Jul 2023 17:00:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://abc7news.com/travis-afb-air-force-base-flannery-associates-llc-john-garamendi/13527836/">https://abc7news.com/travis-afb-air-force-base-flannery-associates-llc-john-garamendi/13527836/</a>, See on <a href="https://news.ycombinator.com/item?id=36816387">Hacker News</a></p>
<div id="readability-page-1" class="page"><article data-testid="prism-article-body"><p><span>FAIRFIELD, Calif. (KGO) -- </span>The United States Air Force is investigating a company that's purchased $800 million of land near Travis Air Force Base, one of the most critical military bases in the U.S. But after eight months of investigation, government officials have been unable to identify who's behind it nor rule out any threat to national security.</p><p>"We're very, very concerned about this," said Rep. John Garamendi (D-CA08). "It's so extensive and so secret and it's impossible to get any information about what's happening here."</p><p>Congressman Garamendi raised the alarm to the U.S. Air Force -- prompting a federal investigation.</p><p><b>MORE: <a data-testid="prism-linkbase" href="https://abc7news.com/chinese-surveillance-balloon-antony-blinken-spy-operation-photos/12788242/">Chinese surveillance balloon part of massive program over 5 continents: Blinken</a></b></p><p><b>Stephanie Sierra:</b> "In your briefings on the matter, do you have any reason to believe the purchase of this land is for spying?"</p><p><b>Rep. Garamendi:</b> "I have every reason in the world to believe that this land is adjacent to a critical national security platform Travis Air Force Base. Therefore -- an area where spy operations or any other nefarious activity could take place...that could detrimentally impact the ability of Travis Air Force Base to operate in a moment of national emergency."</p><p>Public records show the company "Flannery Associates LLC" began purchasing land around the military base in 2018. The controversy was first reported by the <a data-testid="prism-linkbase" rel="nofollow" href="https://www.wsj.com/articles/investors-bought-nearly-1-billion-in-land-near-a-california-air-force-base-officials-want-to-know-who-exactly-they-are-fd868e38" target="_blank">Wall Street Journal</a>. Investigators say those acquisitions ramped up in 2023.</p><p>"Now literally three sides of that base are totally controlled by the Flannery group," Rep. Garamendi said.</p><p>Yet no one - including local, state, and federal officials -- can seem to track down who's behind the group.</p><p>"Who are these people?" Garamendi said. "Where did they get the money where they could pay five to ten times the normal value that others would pay for this farmland?"</p><p>Even after eight months of investigation, Garamendi says federal authorities are still struggling to get those answers.</p><p><b>MORE: <a data-testid="prism-linkbase" href="https://abc7news.com/jonathan-and-diana-toebbe-spy-couple-nuclear-submarine-navy-engineer/12435396/">Navy engineer, wife sentenced after trying to sell US nuclear submarines secrets</a></b></p><p>"To this day we don't know where these people are coming from," Garamendi said.</p><p><a data-testid="prism-linkbase" href="https://abc7news.com/about/newsteam/stephanie-sierra/">I-Team reporter Stephanie Sierra</a> asked Garamendi if there is any reason to believe China is tied to this group.</p><p>"I have reason to be concerned," he responded.</p><p>Last year 300 acres of farmland were purchased near Minot Air Force Base in North Dakota. Garamendi called it a '"spy base."</p><p>"That base is where we launch our airplanes to figure out what's going on across the world," he said. "A company in China was acquiring land around that base and wanted to build a 400-foot silo that could look directly into the base... and we were like 'whoa, whoa, whoa, what's going on there?'"</p><p>Garamendi says the attorney representing Flannery Associates indicated the firm is made up of a group of families, 97 percent of whom are allegedly American, looking to diversify their portfolio from equities to real assets - including agricultural land.</p><p>But the congressman is skeptical.</p><p>"We have heard scheme after scheme that makes no sense at all," Rep. Garamendi said. "We're going to build a deep water port. Really? Around Travis Air Force Base? Which is 10 miles from the Bay. No, you're not... We're going to farm... well at that price you're going to lose a lot of money farming. Well, we're going to build a city... No, you're not going to build a city...so none of the reasons why the land is being acquired make any sense at all."</p><p><b>MORE: <a data-testid="prism-linkbase" href="https://abc7news.com/homes-near-travis-air-force-base-affordable-housing-solano-county-houses-in-fairfield-georgetown-project/9016432/">Why 300 homes next to Travis AFB have been sitting empty for a decade</a></b></p><p>The attorney representing Flannery Associates sent a letter to the U.S. Dept. of Agriculture, one of several agencies investigating the matter, issuing a formal response.</p><p><i>"No foreign person or group holds any significant interest or substantial control over Flannery, either now or at the time of any land purchase made by Flannery,"</i> the letter said.</p><p>The company added they don't comment on its investments.</p><p><b>Sierra:</b> "What do you think is happening?"</p><p><b>Rep. Garamendi:</b> "I don't know, it doesn't make any sense... It's the secrecy... Why are you doing this in secret? If you're not a nefarious operation, why are you keeping it secret?"</p><p>According to Garamendi, Flannery Associates has also acquired land around the interstate electrical grid system stemming from the Columbia River into Central California - including land that houses wind turbines that provide significant power into Northern California.</p><p>In the meantime, Garamendi says the company continues to negatively impact the farming community in Solano County. He says at least 10 landowners are being sued by Flannery, accused of being engaged in an illegal scheme to prevent the company from buying their land.</p><p><b>Take a look at more <a data-testid="prism-linkbase" href="https://abc7news.com/iteam/">stories and videos by the ABC7 News I-Team.</a></b> </p><div data-testid="prism-inline-image"><figure data-testid="prism-figure"><a data-testid="prism-linkbase" href="https://abc7news.com/abc-news-live-local-watch/11513295/"><img alt="Now Streaming 24/7 Click Here" data-testid="prism-image" draggable="false" src="https://cdn.abcotvs.com/dip/images/11518842_247-NOWSTREAMING_1280x720.png"></a><figcaption></figcaption></figure></div><p> <i>If you're on the ABC7 News app, <a data-testid="prism-linkbase" href="https://abc7news.com/abc-news-live-local-watch/11513295/">click here to watch live</a></i></p></article></div>]]></description>
        </item>
    </channel>
</rss>