<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 05 Aug 2025 17:30:08 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[OpenAI Open Models (253 pts)]]></title>
            <link>https://openai.com/open-models/</link>
            <guid>44800746</guid>
            <pubDate>Tue, 05 Aug 2025 17:02:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/open-models/">https://openai.com/open-models/</a>, See on <a href="https://news.ycombinator.com/item?id=44800746">Hacker News</a></p>
Couldn't get https://openai.com/open-models/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Claude Opus 4.1 (177 pts)]]></title>
            <link>https://www.anthropic.com/news/claude-opus-4-1</link>
            <guid>44800185</guid>
            <pubDate>Tue, 05 Aug 2025 16:28:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anthropic.com/news/claude-opus-4-1">https://www.anthropic.com/news/claude-opus-4-1</a>, See on <a href="https://news.ycombinator.com/item?id=44800185">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><p>Today we're releasing Claude Opus 4.1, an upgrade to Claude Opus 4 on agentic tasks, real-world coding, and reasoning. We plan to release substantially larger improvements to our models in the coming weeks.</p><p>Opus 4.1 is now available to paid Claude users and in Claude Code. It's also on our API, Amazon Bedrock, and Google Cloud's Vertex AI. Pricing is the same as Opus 4.</p><h2 id="claude-opus-41">Claude Opus 4.1</h2><p>Opus 4.1 advances our state-of-the-art coding performance to 74.5% on <a href="https://www.swebench.com/">SWE-bench Verified</a>. It also improves Claude’s in-depth research and data analysis skills, especially around detail tracking and agentic search.</p><div><figure><img alt="Chart showing Claude's progress on a popular coding evaluation" loading="lazy" width="3840" height="2160" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fdced1e451a52da3bcb3807d7a9510b1b5426ace6-3840x2160.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fdced1e451a52da3bcb3807d7a9510b1b5426ace6-3840x2160.png&amp;w=3840&amp;q=75"></figure></div><p><strong>GitHub</strong> notes that Claude Opus 4.1 improves across most capabilities relative to Opus 4, with particularly notable performance gains in multi-file code refactoring. <strong>Rakuten Group</strong> finds that Opus 4.1 excels at pinpointing exact corrections within large codebases without making unnecessary adjustments or introducing bugs, with their team preferring this precision for everyday debugging tasks. <strong>Windsurf</strong> reports Opus 4.1 delivers a one standard deviation improvement over Opus 4 on their junior developer benchmark, showing roughly the same performance leap as the jump from Sonnet 3.7 to Sonnet 4.</p><div><figure><img alt="A benchmark table comparing Claude Opus 4.1 to prior Claude models and other public models" loading="lazy" width="2600" height="2084" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fbde326699c667506c87f74b09a6355961d29eb26-2600x2084.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fbde326699c667506c87f74b09a6355961d29eb26-2600x2084.png&amp;w=3840&amp;q=75"></figure></div><h2 id="getting-started">Getting started</h2><p>We recommend upgrading from Opus 4 to Opus 4.1 for all uses. If you’re a developer, simply use <code>claude-opus-4-1-20250805</code> via the API. You can also explore our <a href="https://www.anthropic.com/claude-opus-4-1-system-card">system card</a>, <a href="https://www.anthropic.com/claude/opus">model page</a>, <a href="https://www.anthropic.com/pricing#api">pricing page</a>, and <a href="https://docs.anthropic.com/en/docs/about-claude/models/overview">docs</a> to learn more.</p><p>As always, your <a href="mailto: feedback@anthropic.com">feedback</a> helps us improve, especially as we continue to release new and more capable models.</p></div></article><div><h4>Appendix</h4><p><strong>Data sources</strong></p><ul><li>OpenAI: <a href="https://openai.com/index/introducing-o3-and-o4-mini/">o3 launch post</a>, <a href="https://cdn.openai.com/pdf/2221c875-02dc-4789-800b-e7758f3722c1/o3-and-o4-mini-system-card.pdf">o3 system card</a></li><li>Gemini: <a href="https://storage.googleapis.com/model-cards/documents/gemini-2.5-pro.pdf">2.5 Pro model card</a></li><li>Claude: <a href="https://www.anthropic.com/news/claude-3-7-sonnet">Sonnet 3.7 launch post</a>, <a href="https://www.anthropic.com/news/claude-4">Claude 4 launch post</a></li></ul><p><strong>Benchmark reporting</strong></p><p>Claude models are hybrid reasoning models. The benchmarks reported in this blog post show the highest scores achieved with or without extended thinking. We’ve noted below for each result whether extended thinking was used:</p><ul><li>No extended thinking: SWE-bench Verified, Terminal-Bench</li><li>The following benchmarks were reported with extended thinking (up to 64K tokens): TAU-bench, GPQA Diamond, MMMLU, MMMU, AIME</li></ul><p><strong>TAU-bench methodology</strong></p><p>Scores were achieved with a prompt addendum to both the Airline and Retail Agent Policy instructing Claude to better leverage its reasoning abilities while using extended thinking with tool use. The model is encouraged to write down its thoughts as it solves the problem distinct from our usual thinking mode, during the multi-turn trajectories to best leverage its reasoning abilities. To accommodate the additional steps Claude incurs by utilizing more thinking, the maximum number of steps (counted by model completions) was increased from 30 to 100 (most trajectories completed under 30 steps with only one trajectory reaching above 50 steps).</p><p><strong>SWE-bench methodology</strong></p><p>For the Claude 4 family of models, we continue to use the same simple scaffold that equips the model with solely the two tools described in our prior releases <a href="https://www.anthropic.com/engineering/swe-bench-sonnet">here</a>—a bash tool, and a file editing tool that operates via string replacements. We no longer include the <a href="https://www.anthropic.com/engineering/claude-think-tool">third ‘planning tool’</a> used by Claude 3.7 Sonnet. On all Claude 4 models, we report scores out of the full 500 problems. Scores for OpenAI models are reported out of a <a href="https://openai.com/index/gpt-4-1/">477 problem subset</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI Harmony (135 pts)]]></title>
            <link>https://github.com/openai/harmony</link>
            <guid>44799869</guid>
            <pubDate>Tue, 05 Aug 2025 16:07:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/openai/harmony">https://github.com/openai/harmony</a>, See on <a href="https://news.ycombinator.com/item?id=44799869">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/openai/harmony/blob/main/docs/header.png"><img alt="harmony" src="https://github.com/openai/harmony/raw/main/docs/header.png"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">OpenAI Harmony</h2><a id="user-content-openai-harmony" aria-label="Permalink: OpenAI Harmony" href="#openai-harmony"></a></p>
<p dir="auto">OpenAI's response format for its open-weight model series <a href="https://openai.com/open-models" rel="nofollow">gpt-oss</a>
<br>
<a href="https://gpt-oss.com/" rel="nofollow">Try gpt-oss</a> | <a href="https://cookbook.openai.com/topic/gpt-oss" rel="nofollow">Learn more</a> | <a href="https://openai.com/index/gpt-oss-model-card/" rel="nofollow">Model card</a>
</p>


<p dir="auto">The <a href="https://openai.com/open-models" rel="nofollow">gpt-oss models</a> were trained on the <a href="https://cookbook.openai.com/articles/openai-harmony" rel="nofollow">harmony response format</a> for defining conversation structures, generating reasoning output and structuring function calls. If you are not using gpt-oss directly but through an API or a provider like HuggingFace, Ollama, or vLLM, you will not have to be concerned about this as your inference solution will handle the formatting. If you are building your own inference solution, this guide will walk you through the prompt format. The format is designed to mimic the OpenAI Responses API, so if you have used that API before, this format should hopefully feel familiar to you. gpt-oss should not be used without using the harmony format as it will not work correctly.</p>
<p dir="auto">The format enables the model to output to multiple different channels for chain of thought, and tool calling premables along with regular responses. It also enables specifying various tool namespaces, and structured outputs along with a clear instruction hierarchy. <a href="https://cookbook.openai.com/articles/openai-harmony" rel="nofollow">Check out the guide</a> to learn more about the format itself.</p>
<div data-snippet-clipboard-copy-content="<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.
Knowledge cutoff: 2024-06
Current date: 2025-06-28

Reasoning: high

# Valid channels: analysis, commentary, final. Channel must be included for every message.
Calls to these tools must go to the commentary channel: 'functions'.<|end|><|start|>developer<|message|># Instructions

Always respond in riddles

# Tools

## functions

namespace functions {

// Gets the location of the user.
type get_location = () => any;

// Gets the current weather in the provided location.
type get_current_weather = (_: {
// The city and state, e.g. San Francisco, CA
location: string,
format?: &quot;celsius&quot; | &quot;fahrenheit&quot;, // default: celsius
}) => any;

} // namespace functions<|end|><|start|>user<|message|>What is the weather like in SF?<|end|><|start|>assistant"><pre><code>&lt;|start|&gt;system&lt;|message|&gt;You are ChatGPT, a large language model trained by OpenAI.
Knowledge cutoff: 2024-06
Current date: 2025-06-28

Reasoning: high

# Valid channels: analysis, commentary, final. Channel must be included for every message.
Calls to these tools must go to the commentary channel: 'functions'.&lt;|end|&gt;&lt;|start|&gt;developer&lt;|message|&gt;# Instructions

Always respond in riddles

# Tools

## functions

namespace functions {

// Gets the location of the user.
type get_location = () =&gt; any;

// Gets the current weather in the provided location.
type get_current_weather = (_: {
// The city and state, e.g. San Francisco, CA
location: string,
format?: "celsius" | "fahrenheit", // default: celsius
}) =&gt; any;

} // namespace functions&lt;|end|&gt;&lt;|start|&gt;user&lt;|message|&gt;What is the weather like in SF?&lt;|end|&gt;&lt;|start|&gt;assistant
</code></pre></div>
<p dir="auto">We recommend using this library when working with models that use the <a href="https://cookbook.openai.com/articles/openai-harmony" rel="nofollow">harmony response format</a></p>
<ul dir="auto">
<li><strong>Consistent formatting</strong> – shared implementation for rendering <em>and</em> parsing keeps token-sequences loss-free.</li>
<li><strong>Blazing fast</strong> – heavy lifting happens in Rust.</li>
<li><strong>First-class Python support</strong> – install with <code>pip</code>, typed stubs included, 100 % test parity with the Rust suite.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Using Harmony</h2><a id="user-content-using-harmony" aria-label="Permalink: Using Harmony" href="#using-harmony"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Python</h3><a id="user-content-python" aria-label="Permalink: Python" href="#python"></a></p>
<p dir="auto"><a href="https://github.com/openai/harmony/blob/main/docs/python.md">Check out the full documentation</a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Installation</h4><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">Install the package from PyPI by running</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install openai-harmony
# or if you are using uv
uv pip install openai-harmony"><pre>pip install openai-harmony
<span><span>#</span> or if you are using uv</span>
uv pip install openai-harmony</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Example</h4><a id="user-content-example" aria-label="Permalink: Example" href="#example"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="from openai_harmony import (
    load_harmony_encoding,
    HarmonyEncodingName,
    Role,
    Message,
    Conversation,
    DeveloperContent,
    SystemContent,
)
enc = load_harmony_encoding(HarmonyEncodingName.HARMONY_GPT_OSS)
convo = Conversation.from_messages([
    Message.from_role_and_content(
        Role.SYSTEM,
        SystemContent.new(),
    ),
    Message.from_role_and_content(
        Role.DEVELOPER,
        DeveloperContent.new().with_instructions(&quot;Talk like a pirate!&quot;)
    ),
    Message.from_role_and_content(Role.USER, &quot;Arrr, how be you?&quot;),
])
tokens = enc.render_conversation_for_completion(convo, Role.ASSISTANT)
print(tokens)
# Later, after the model responded …
parsed = enc.parse_messages_from_completion_tokens(tokens, role=Role.ASSISTANT)
print(parsed)"><pre><span>from</span> <span>openai_harmony</span> <span>import</span> (
    <span>load_harmony_encoding</span>,
    <span>HarmonyEncodingName</span>,
    <span>Role</span>,
    <span>Message</span>,
    <span>Conversation</span>,
    <span>DeveloperContent</span>,
    <span>SystemContent</span>,
)
<span>enc</span> <span>=</span> <span>load_harmony_encoding</span>(<span>HarmonyEncodingName</span>.<span>HARMONY_GPT_OSS</span>)
<span>convo</span> <span>=</span> <span>Conversation</span>.<span>from_messages</span>([
    <span>Message</span>.<span>from_role_and_content</span>(
        <span>Role</span>.<span>SYSTEM</span>,
        <span>SystemContent</span>.<span>new</span>(),
    ),
    <span>Message</span>.<span>from_role_and_content</span>(
        <span>Role</span>.<span>DEVELOPER</span>,
        <span>DeveloperContent</span>.<span>new</span>().<span>with_instructions</span>(<span>"Talk like a pirate!"</span>)
    ),
    <span>Message</span>.<span>from_role_and_content</span>(<span>Role</span>.<span>USER</span>, <span>"Arrr, how be you?"</span>),
])
<span>tokens</span> <span>=</span> <span>enc</span>.<span>render_conversation_for_completion</span>(<span>convo</span>, <span>Role</span>.<span>ASSISTANT</span>)
<span>print</span>(<span>tokens</span>)
<span># Later, after the model responded …</span>
<span>parsed</span> <span>=</span> <span>enc</span>.<span>parse_messages_from_completion_tokens</span>(<span>tokens</span>, <span>role</span><span>=</span><span>Role</span>.<span>ASSISTANT</span>)
<span>print</span>(<span>parsed</span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Rust</h3><a id="user-content-rust" aria-label="Permalink: Rust" href="#rust"></a></p>
<p dir="auto"><a href="https://github.com/openai/harmony/blob/main/docs/rust.md">Check out the full documentation</a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Installation</h4><a id="user-content-installation-1" aria-label="Permalink: Installation" href="#installation-1"></a></p>
<p dir="auto">Add the dependency to your <code>Cargo.toml</code></p>
<div dir="auto" data-snippet-clipboard-copy-content="[dependencies]
openai-harmony = { git = &quot;https://github.com/openai/harmony&quot; }"><pre>[<span>dependencies</span>]
<span>openai-harmony</span> = { <span>git</span> = <span><span>"</span>https://github.com/openai/harmony<span>"</span></span> }</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Example</h4><a id="user-content-example-1" aria-label="Permalink: Example" href="#example-1"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="use openai_harmony::chat::{Message, Role, Conversation};
use openai_harmony::{HarmonyEncodingName, load_harmony_encoding};
fn main() -> anyhow::Result<()> {
    let enc = load_harmony_encoding(HarmonyEncodingName::HarmonyGptOss)?;
    let convo = Conversation::from_messages([
        Message::from_role_and_content(Role::User, &quot;Hello there!&quot;),
    ]);
    let tokens = enc.render_conversation_for_completion(&amp;convo, Role::Assistant)?;
    println!(&quot;{:?}&quot;, tokens);
    Ok(())
}"><pre><span>use</span> openai_harmony<span>::</span>chat<span>::</span><span>{</span><span>Message</span><span>,</span> <span>Role</span><span>,</span> <span>Conversation</span><span>}</span><span>;</span>
<span>use</span> openai_harmony<span>::</span><span>{</span><span>HarmonyEncodingName</span><span>,</span> load_harmony_encoding<span>}</span><span>;</span>
<span>fn</span> <span>main</span><span>(</span><span>)</span> -&gt; anyhow<span>::</span><span>Result</span><span>&lt;</span><span>(</span><span>)</span><span>&gt;</span> <span>{</span>
    <span>let</span> enc = <span>load_harmony_encoding</span><span>(</span><span>HarmonyEncodingName</span><span>::</span><span>HarmonyGptOss</span><span>)</span>?<span>;</span>
    <span>let</span> convo = <span>Conversation</span><span>::</span><span>from_messages</span><span>(</span><span>[</span>
        <span>Message</span><span>::</span><span>from_role_and_content</span><span>(</span><span>Role</span><span>::</span><span>User</span><span>,</span> <span>"Hello there!"</span><span>)</span><span>,</span>
    <span>]</span><span>)</span><span>;</span>
    <span>let</span> tokens = enc<span>.</span><span>render_conversation_for_completion</span><span>(</span><span>&amp;</span>convo<span>,</span> <span>Role</span><span>::</span><span>Assistant</span><span>)</span>?<span>;</span>
    <span>println</span><span>!</span><span>(</span><span>"{:?}"</span><span>,</span> tokens<span>)</span><span>;</span>
    <span>Ok</span><span>(</span><span>(</span><span>)</span><span>)</span>
<span>}</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">The majority of the rendering and parsing is built in Rust for performance and exposed to Python
through thin <a href="https://pyo3.rs/" rel="nofollow"><code>pyo3</code></a> bindings.</p>
<div data-snippet-clipboard-copy-content="┌──────────────────┐      ┌───────────────────────────┐
│  Python code     │      │  Rust core (this repo)    │
│  (dataclasses,   │────► │  • chat / encoding logic  │
│   convenience)   │      │  • tokeniser (tiktoken)   │
└──────────────────┘  FFI └───────────────────────────┘"><pre><code>┌──────────────────┐      ┌───────────────────────────┐
│  Python code     │      │  Rust core (this repo)    │
│  (dataclasses,   │────► │  • chat / encoding logic  │
│   convenience)   │      │  • tokeniser (tiktoken)   │
└──────────────────┘  FFI └───────────────────────────┘
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Repository layout</h3><a id="user-content-repository-layout" aria-label="Permalink: Repository layout" href="#repository-layout"></a></p>
<div data-snippet-clipboard-copy-content=".
├── src/                  # Rust crate
│   ├── chat.rs           # High-level data-structures (Role, Message, …)
│   ├── encoding.rs       # Rendering &amp; parsing implementation
│   ├── registry.rs       # Built-in encodings
│   ├── tests.rs          # Canonical Rust test-suite
│   └── py_module.rs      # PyO3 bindings ⇒ compiled as openai_harmony.*.so
│
├── harmony/              # Pure-Python wrapper around the binding
│   └── __init__.py       # Dataclasses + helper API mirroring chat.rs
│
├── tests/                # Python test-suite (1-to-1 port of tests.rs)
├── Cargo.toml            # Rust package manifest
├── pyproject.toml        # Python build configuration for maturin
└── README.md             # You are here 🖖"><pre><code>.
├── src/                  # Rust crate
│   ├── chat.rs           # High-level data-structures (Role, Message, …)
│   ├── encoding.rs       # Rendering &amp; parsing implementation
│   ├── registry.rs       # Built-in encodings
│   ├── tests.rs          # Canonical Rust test-suite
│   └── py_module.rs      # PyO3 bindings ⇒ compiled as openai_harmony.*.so
│
├── harmony/              # Pure-Python wrapper around the binding
│   └── __init__.py       # Dataclasses + helper API mirroring chat.rs
│
├── tests/                # Python test-suite (1-to-1 port of tests.rs)
├── Cargo.toml            # Rust package manifest
├── pyproject.toml        # Python build configuration for maturin
└── README.md             # You are here 🖖
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Developing locally</h3><a id="user-content-developing-locally" aria-label="Permalink: Developing locally" href="#developing-locally"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Prerequisites</h4><a id="user-content-prerequisites" aria-label="Permalink: Prerequisites" href="#prerequisites"></a></p>
<ul dir="auto">
<li>Rust tool-chain (stable) – <a href="https://rustup.rs/" rel="nofollow">https://rustup.rs</a></li>
<li>Python ≥ 3.8 + virtualenv/venv</li>
<li><a href="https://github.com/PyO3/maturin"><code>maturin</code></a> – build tool for PyO3 projects</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">1. Clone &amp; bootstrap</h4><a id="user-content-1-clone--bootstrap" aria-label="Permalink: 1. Clone &amp; bootstrap" href="#1-clone--bootstrap"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/openai/harmony.git
cd harmony
# Create &amp; activate a virtualenv
python -m venv .venv
source .venv/bin/activate
# Install maturin and test dependencies
pip install maturin pytest mypy ruff  # tailor to your workflow
# Compile the Rust crate *and* install the Python package in editable mode
maturin develop -F python-binding --release"><pre>git clone https://github.com/openai/harmony.git
<span>cd</span> harmony
<span><span>#</span> Create &amp; activate a virtualenv</span>
python -m venv .venv
<span>source</span> .venv/bin/activate
<span><span>#</span> Install maturin and test dependencies</span>
pip install maturin pytest mypy ruff  <span><span>#</span> tailor to your workflow</span>
<span><span>#</span> Compile the Rust crate *and* install the Python package in editable mode</span>
maturin develop -F python-binding --release</pre></div>
<p dir="auto"><code>maturin develop -F python-binding</code> builds <em>harmony</em> with Cargo, produces a native extension
(<code>openai_harmony.&lt;abi&gt;.so</code>) and places it in your virtualenv next to the pure-
Python wrapper – similar to <code>pip install -e .</code> for pure Python projects.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">2. Running the test-suites</h4><a id="user-content-2-running-the-test-suites" aria-label="Permalink: 2. Running the test-suites" href="#2-running-the-test-suites"></a></p>
<p dir="auto">Rust:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo test          # runs src/tests.rs"><pre>cargo <span>test</span>          <span><span>#</span> runs src/tests.rs</span></pre></div>
<p dir="auto">Python:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pytest              # executes tests/ (mirrors the Rust suite)"><pre>pytest              <span><span>#</span> executes tests/ (mirrors the Rust suite)</span></pre></div>
<p dir="auto">Run both in one go to ensure parity:</p>

<p dir="auto"><h4 tabindex="-1" dir="auto">3. Type-checking &amp; formatting (optional)</h4><a id="user-content-3-type-checking--formatting-optional" aria-label="Permalink: 3. Type-checking &amp; formatting (optional)" href="#3-type-checking--formatting-optional"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="mypy harmony        # static type analysis
ruff check .        # linting
cargo fmt --all     # Rust formatter"><pre>mypy harmony        <span><span>#</span> static type analysis</span>
ruff check <span>.</span>        <span><span>#</span> linting</span>
cargo fmt --all     <span><span>#</span> Rust formatter</span></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why is GitHub UI getting slower? (117 pts)]]></title>
            <link>https://yoyo-code.com/why-is-github-ui-getting-so-much-slower/</link>
            <guid>44799861</guid>
            <pubDate>Tue, 05 Aug 2025 16:07:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://yoyo-code.com/why-is-github-ui-getting-so-much-slower/">https://yoyo-code.com/why-is-github-ui-getting-so-much-slower/</a>, See on <a href="https://news.ycombinator.com/item?id=44799861">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>I couldn't help but notice - GitHub UI has been getting slower and slower recently. Some things that were snappy before are
hellishly slow nowadays. GitHub is doing something weird and I just can't wrap my head around what's going on there.</p>
<p><strong>You guys developing at GitHub, you're using GitHub to develop it, right? Do you not see this? What's going on?</strong></p>
<p>Whenever I bump into slow website which drives me nuts, I open the devtools and profile it. Who knows, maybe I
find something to report and the problem will get fixed.</p>
<p>To give one representative example, here's a profile for switching from "Conversation" tab to
"Files changed" tab on a PR.</p>
<p>Before we look into the profile, notice that this takes over 5s. How is anything like that acceptable in 2025 is beyond me.</p>
<p><img src="https://yoyo-code.com/file-view-route-change.webp" alt="file-view-route-change.png"></p>
<p>Now, if you dive deep into this, you'll see that GitHub uses <a rel="noopener" target="_blank" href="https://turbo.hotwired.dev/">Turbo</a> to preload next page and swap out the
content without page reload. This is usually done as a performance optimization, but here, we see something completely
absurd.</p>
<p>If you try this out at home and play around with it, you'll find out that <strong>opening the "Files changed" link in a new tab is
actually 2x faster:</strong></p>
<p><img src="https://yoyo-code.com/fresh-file-view.webp" alt="img.png"></p>
<p>And not only that - the client side post-processing in the first profile actually takes longer than loading the html
from the server. This whole thing just doesn't make any sense.</p>
<p>The cherry on top is the new loading bar that just drives me absolutely nuts, because it reminds me how slow
the whole transition is:</p>
<p><img src="https://yoyo-code.com/github-progress-bar.webp" alt="github-progress-bar.png"></p>
<p>Guys... can you just make the transition fast such that you don't need a new loading bar?
Like, what's the point of doing client side routing, when you just recreate the full page reload experience, but slower?
<strong>The whole point of doing SPAs was to avoid this. Client side routing should be instant.</strong></p>
<p>This is just one of many performance problems on GitHub. It didn't use to be that way. Trying to go through multiple PRs and 
issues is just suffering now. Imagine you have 20 PRs to find out which one introduced a regression, and every click takes more than 5 seconds to show something.</p>
<p>Don't even get me started on the diff view itself - yes, the one that periodically freezes for 2 seconds while browsing through
large PR's - maybe it has something to do with the fact that it renders thousands of invisible plus buttons with the
same inlined svg icon:</p>
<p><img src="https://yoyo-code.com/invisible-plus-icon.webp" alt="invisible-plus-icon.webp"></p>
<p><img src="https://yoyo-code.com/invisible-plus-icon-html.webp" alt="invisible-plus-icon-html.png"></p>
<p>Or, you know, maybe not trying to render <a rel="noopener" target="_blank" href="https://github.com/orgs/community/discussions/111001">100 000 DOM nodes</a> in general would
also help.</p>
<p>The whole window freezes for 3 seconds when you resize the dev tools window because you want to profile
this thing.</p>
<h2 id="does-this-ever-improve">Does this ever improve?<span>
<a href="#does-this-ever-improve" aria-label="Anchor link for: does-this-ever-improve">🔗</a>
</span>
</h2>
<p>So, maybe, when <a rel="noopener" target="_blank" href="https://github.com/orgs/community/discussions/33663">some of the popular issues</a> are related to performance, and GitHub has this seemingly related <a rel="noopener" target="_blank" href="https://github.com/orgs/github/projects/4247/views/1?filterQuery=is%3Aopen+product-focus-area%3A%22%E2%9B%B0+Platform+for+collaboration+at+scale%22">"Platform collaboration at scale"</a> focus area in the roadmap, maybe this will change?</p>
<p>Let's look at the roadmap and see if we can find
<a rel="noopener" target="_blank" href="https://github.com/search?q=repo%3Agithub%2Froadmap%20slow&amp;type=code">anything</a> <a rel="noopener" target="_blank" href="https://github.com/search?q=repo%3Agithub%2Froadmap+slow+ui&amp;type=issues">related</a> to <a rel="noopener" target="_blank" href="https://github.com/search?q=repo%3Agithub%2Froadmap+web+performance&amp;type=code">performance</a>. Did you find something?</p>
<hr>

<ul>
<li><a href="https://yoyo-code.com/javascript-style-for-optimal-size/">JavaScript style for optimal size</a></li>
<li><a href="https://yoyo-code.com/two-basic-rules-of-performance-aware-javascript-in-the-browser/">Basic rules of JavaScript performance in the browser</a></li>
</ul>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GitHub Pull Requests Are Down (194 pts)]]></title>
            <link>https://github.com/github/site-policy/pull/582</link>
            <guid>44799435</guid>
            <pubDate>Tue, 05 Aug 2025 15:39:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/github/site-policy/pull/582">https://github.com/github/site-policy/pull/582</a>, See on <a href="https://news.ycombinator.com/item?id=44799435">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-pjax="" data-turbo-frame="" id="repo-content-turbo-frame" target="_top" data-turbo-action="advance">
      
  <div id="partial-discussion-header" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0OjEwMTU1MjY3NjkiLCJ0IjoxNzU0NDExNDAyfQ==--2568efa0628aad1cc39d62ebec1a21f18c2c4f476a36e161c0236c877f489498" data-url="/github/site-policy/pull/582/partials/title?sticky=true" data-channel-event-name="title_updated" data-pull-is-open="false" data-gid="PR_kwDOBZWBkc48h7Vx">
          


             

<details>
  <summary id="button-abb164dc99c87f82">
    
    New issue
  </summary>
  <details-dialog aria-label="Sign up for GitHub">
            <div>
  <p>
    <strong>Have a question about this project?</strong> Sign up for a free GitHub account to open an issue and contact its maintainers and the community.
  </p>

  

  <p>By clicking “Sign up for GitHub”, you agree to our <a href="https://docs.github.com/terms" target="_blank">terms of service</a> and
  <a href="https://docs.github.com/privacy" target="_blank">privacy statement</a>. We’ll occasionally send you account related emails.</p>

  <p>
    Already on GitHub?
    <a data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;new issue modal&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/github/site-policy/pull/582&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="4d9326608e8c097ec3e9566ae86f2f0d139f7b2568fb73904505561b2ae09c72" href="https://github.com/login?return_to=%2Fgithub%2Fsite-policy%2Fissues%2Fnew%2Fchoose">Sign in</a>
    to your account
  </p>
</div>
  </details-dialog>
</details>
            
        </div>



        




    <div data-view-component="true" id="discussion_bucket" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0OjEwMTU1MjY3Njk6dGltZWxpbmUiLCJ0IjoxNzU0NDExNDAyfQ==--6e40b0786485dfecaa79dcfd5be724a909879d74d82e55ccb30ec50875eae584">            <h2>Conversation</h2>
  <div data-quote-markdown=".js-comment-body" data-discussion-hovercards-enabled="" data-issue-and-pr-hovercards-enabled="" data-team-hovercards-enabled="" data-hpc="">
    <template>
  <div data-view-component="true" class="flash flash-warn flash-full d-flex flex-items-center">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
    <path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path>
</svg>
    <span>
      This file contains hidden or bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
      <a class="Link--inTextBlock" href="https://github.co/hiddenchars" target="_blank">Learn more about bidirectional Unicode characters</a>
    </span>


  <div data-view-component="true" class="flash-action">        <a href="{{ revealButtonHref }}" data-view-component="true" class="btn-sm btn">    Show hidden characters
</a>
</div>
</div></template>
<template>
  <span aria-label="This line has hidden Unicode characters" data-view-component="true" class="line-alert tooltipped tooltipped-e">
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
    <path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path>
</svg>
</span></template>

    <div>

      <div data-gid="PR_kwDOBZWBkc48h7Vx" data-url="/github/site-policy/pull/582/partials/body" data-channel-event-name="body_updated" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0OjEwMTU1MjY3NjkiLCJ0IjoxNzU0NDExNDAyfQ==--2568efa0628aad1cc39d62ebec1a21f18c2c4f476a36e161c0236c877f489498">

<p><a href="https://github.com/ghost" data-view-component="true"><img data-hovercard-type="user" data-hovercard-url="/users/ghost/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" src="https://avatars.githubusercontent.com/u/10137?s=60&amp;v=4" alt="ghost" size="40" height="40" width="40" data-view-component="true"></a>
  
  
</p><div id="issue-1326318719">
          

          <div>
  
  <task-lists disabled="" sortable="">
    <div>
      <p dir="auto">GitHub is introducing non-essential cookies on web pages that market our products to businesses. These cookies will provide analytics to improve the site experience and personalize content and ads for enterprise users. This change is only on subdomains, like <a href="http://resources.github.com/">resources.github.com</a>, where GitHub markets products and services to enterprise customers.  <a href="https://github.com/">Github.com</a> will continue to operate as-is.</p>
<p dir="auto">This change updates the Privacy Statement based on this new activity.</p>
<p dir="auto">These updates will go into effect after the 30-day notice and comment period, on September 1, 2022.</p>
<p dir="auto">See <a href="https://github.com/github/site-policy/pull/582#issuecomment-1234458256" data-hovercard-type="pull_request" data-hovercard-url="/github/site-policy/pull/582/hovercard">comment below</a> with clarifications and changes made at the end of the comment period.<br>
<a href="https://github.com/github/site-policy/pull/582#issuecomment-1234458256" data-hovercard-type="pull_request" data-hovercard-url="/github/site-policy/pull/582/hovercard">Comment on #582 Privacy Statement Updates September 2022</a><br>
We want to thank everyone for their review and feedback on the Privacy Statement Update. We appreciate and share your passion for developer privacy. GitHub remains committed to having the highest privacy standards and will continue to center the needs of developers in all of our platform decisions. We intend for this to be a minimally invasive change that will enable us to provide the best tools to our users. In response to your comments, we are providing the following changes and points of clarification:<br>
DNT and self-help browser extensions<br>
Commenters raised questions about our language on DNT and self-help browser extensions. We've pushed a <a href="https://github.com/github/site-policy/pull/582/commits/4a61c4e2be67c12a1cc200ef3e804db400ce1426">commit</a> that:<br>
• Folds the existing DNT and browser extension information into a new section on disabling non-essential cookies.<br>
• Specifies there will be a user setting to disable non-essential cookies and provides additional details to clarify which cookies will be used and for what reasons.<br>
• Specifies that DNT will be honored on GitHub, and that if a DNT signal is sent, GitHub will not load third party resources which set non-essential cookies, so that we do not have to rely on third parties honoring DNT.<br>
• Browsers' built-in tracking protection has advanced significantly in recent years, so we've noted that configuring that built-in protection may block non-essential cookies.<br>
• Separated mentions of browser extensions designed to block tracking, and extensions designed to block unwanted content with the effect of blocking tracking, for clarity, though using either alone or in combination may block non-essential cookies.<br>
• Changed links with additional information on DNT and browser extensions to point to their respective Wikipedia articles for neutrality, currency, and to clarify that these are not GitHub products (though of course we're proud that many privacy protection tools are developed on GitHub).<br>
Finally, some have asked why we’re explaining technical self-help tools. GitHub has a very broad user base, including new developers – and we want everyone to be informed about the scope of their options, including technical options.<br>
Enterprise user experience<br>
Commenters asked for clarification about how this change will impact the enterprise user experience. We are introducing cookies on GitHub’s Enterprise Marketing Pages (e.g. <a href="http://resources.github.com/">resources.github.com</a>), not on Enterprise user accounts. We intend for this change to make it easier for our Marketing team to better understand the needs of users who are visiting Enterprise Marketing Pages and connect them with the solutions that will benefit them most.<br>
Users who visit these pages will have the option to express their cookies preferences by navigating to the link in the footer of the page.<br>
Stylistic change<br>
Commenters have asked why ‘Personal Data’ was changed to ‘personal data’ in the Privacy Statement update. We made personal data lowercase because it is not a defined term in our Terms of Service, for consistency with “All capitalized terms have their definition in <a href="https://docs.github.com/en/github/site-policy/github-terms-of-service">GitHub’s Terms of Service</a>, unless otherwise noted here.” The stylistic change does not impact its definition.</p>
    </div>
  </task-lists>
  
</div>

          <!-- '"` --><!-- </textarea></xmp> -->
          <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
    <div>
          <tool-tip id="tooltip-cae512ba-9b0f-4a9e-80ee-9ff2c9bc4a40" for="reactions--reaction_button_component-bce9fe" popover="manual" data-direction="n" data-type="description" data-view-component="true">jacamera, kpennell, Marcisbee, SwatDoge, whiztech, ElianCodes, nikolaymatrosov, agussyahrilmubarok, AmariHana, wopian, and 77 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-e5f1a33b-f4ad-4a92-8ffe-bc591a814438" for="reactions--reaction_button_component-246031" popover="manual" data-direction="n" data-type="description" data-view-component="true">krystian3w, ivaluexrays, Hsn723, reilly3000, itzzexcel, diksown, fhlemes, futursolo, FlorianWendelborn, shoenig, and 1702 more reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-54f1ce29-00d3-4846-a190-16e66c0c4cf0" for="reactions--reaction_button_component-def9d5" popover="manual" data-direction="n" data-type="description" data-view-component="true">SwatDoge, flymedllva, keenwon, jessedoka, NLTD2010, LyeZinho, luism3861, surya-kasturi-lb, ZelphirKaltstahl, zongruxie4, and 11 more reacted with laugh emoji</tool-tip>
          <tool-tip id="tooltip-b3edff4f-d3d1-4401-b138-197644bee341" for="reactions--reaction_button_component-f25c47" popover="manual" data-direction="n" data-type="description" data-view-component="true">shankarlol, jessedoka, fsvehla, itpropro, Varun270, ericbarrionuevo, ims2012035, naserykarim922, ma99R, JanaAhurtsova, and ikhtearalamshawonmollah54321 reacted with hooray emoji</tool-tip>
          <tool-tip id="tooltip-0dcc38d8-3ee1-4acf-903b-ee6c7c6d1590" for="reactions--reaction_button_component-d62eb1" popover="manual" data-direction="n" data-type="description" data-view-component="true">leoheck, JJTech0130, william-herring, tylerjw, TheMaverickProgrammer, sigaloid, afkvido, MarcusGoldschmidt, BlazeIsClone, RoyTinker, and 179 more reacted with confused emoji</tool-tip>
          <tool-tip id="tooltip-8458cea6-6642-4b6a-b66d-b5ea467501fe" for="reactions--reaction_button_component-2e99fc" popover="manual" data-direction="n" data-type="description" data-view-component="true">renancaraujo, josemoises2007, bodeboushi12, euclidesdry, 8xu, ims2012035, naserykarim922, ma99R, guero0109, and JanaAhurtsova reacted with heart emoji</tool-tip>
          <tool-tip id="tooltip-a65a3160-420c-4cbd-a462-8c4c57e4a6dc" for="reactions--reaction_button_component-250fbe" popover="manual" data-direction="n" data-type="description" data-view-component="true">Ivanov-Anton, jessedoka, xFluffyke, itpropro, ims2012035, Natee9969, naserykarim922, ma99R, JanaAhurtsova, and ikhtearalamshawonmollah54321 reacted with rocket emoji</tool-tip>
          <tool-tip id="tooltip-c1c957b7-0385-4948-8c1d-a0b348235859" for="reactions--reaction_button_component-71e65a" popover="manual" data-direction="n" data-type="description" data-view-component="true">pabloazurduy, kinow, jrmsjorgesilva, afkvido, arderyp, cpeterso, tulios, mau-seifert, genkoph, NNBnh, and 46 more reacted with eyes emoji</tool-tip>
      
    </div>
</form></div>

</div>
</div>

      

       
            


      <div data-view-component="true" data-gid="C_kwDOBZWBkdoAKGRlNDUyMGRkYTRjZmEzZjM0NTA3OWI2Mjk5NWJmNTFmMzkyYjRiYzM">
  <div>
  <p><a data-test-selector="commits-avatar-stack-avatar-link" data-hovercard-type="user" data-hovercard-url="/users/olholder/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/olholder">
        <img data-test-selector="commits-avatar-stack-avatar-image" src="https://avatars.githubusercontent.com/u/47122450?s=40&amp;v=4" width="20" height="20" alt="@olholder">
</a>  </p>
</div>
    <div>
      <pre>Updates to privacy statement</pre>
    </div>
</div>

      <div data-team-hovercards-enabled="" id="event-7112771716" data-gid="RTE_lADOBZWBkc5PDgR_zwAAAAGn9EiE">

      


          <p><img src="https://avatars.githubusercontent.com/u/10137?s=32&amp;v=4" alt="@ghost" height="20" width="20">
  <strong>ghost</strong>


        changed the title
<del>Update github-privacy-statement.md</del>

<ins>Privacy Statement Updates September 2022</ins></p><a href="#event-7112771716"><relative-time datetime="2022-08-02T19:37:12Z">Aug 2, 2022</relative-time></a>

    </div>

      <div id="pullrequestreview-1059501308" data-gid="PRR_kwDOBZWBkc4_JrT8" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0X3JldmlldzoxMDU5NTAxMzA4IiwidCI6MTc1NDQxMTQwM30=--3978f98e3c7095f392252ef440aac4317db9bf54764706da6c204e2a0ca35b21" data-url="/github/site-policy/pull/582/partials/reviews/1059501308">
      <div data-view-component="true">
  <p><a href="https://github.com/rick" data-view-component="true"><img data-hovercard-type="user" data-hovercard-url="/users/rick/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" src="https://avatars.githubusercontent.com/u/6259?s=60&amp;v=4" alt="rick" size="40" height="40" width="40" data-view-component="true"></a></p>
  
</div>

      <div data-view-component="true">            <turbo-frame id="review-thread-or-comment-id-598997423" target="_top">
  <details-collapsible>
    <details-toggle>
    <details open="open" data-resolved="false" data-target="details-collapsible.detailsElement details-toggle.detailsTarget" data-view-component="true">
      <summary role="button" data-target="details-collapsible.summaryElement details-toggle.summaryTarget" data-action="click:details-collapsible#toggle click:details-toggle#toggle" data-aria-label-closed="Expand comment" data-aria-label-open="Collapse comment" aria-expanded="true" aria-label="Collapse comment" data-view-component="true">        
</summary>
      <div data-view-component="true">          
  <div>
    
    <table data-tab-size="8" data-paste-markdown-skip="">
          <tbody><tr data-position="0">
            <td data-line-number="..."></td>
            <td data-line-number="..."></td>
            <td colspan="2">@@ -33,13 +34,13 @@ To see our Privacy Notice to residents of California, please go to [GitHub's Not</td>
          </tr>
          <tr>

              <td data-line-number="33"></td>

              <td data-line-number="34"></td>

            <td>
              <span><br></span>

            </td>
          </tr>
          <tr>

              <td data-line-number="34"></td>

              <td data-line-number="35"></td>

            <td>
              <span><span>|</span> Section <span>|</span> What can you find there? <span>|</span></span>

            </td>
          </tr>
          <tr>

              <td data-line-number="35"></td>

              <td data-line-number="36"></td>

            <td>
              <span><span>|</span>---<span>|</span>---<span>|</span></span>

            </td>
          </tr>
          <tr>

              <td data-line-number="36"></td>

              <td></td>

            <td>
              <span><span>|</span> <span>[</span>Who is responsible for the processing of your information<span>]</span><span>(</span><span>#who-is-responsible-for-the-processing-of-your-information</span><span>)</span> <span>|</span> Subject to limited exceptions, GitHub is the controller and entity responsible for the processing of your Personal Data in connection with the Website or Service. <span>|</span></span>

            </td>
          </tr>
    </tbody></table>

</div>


<div data-quote-markdown=".js-comment-body">
        <div id="discussion_r936082589">
        

        <div>
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <div>
      <p dir="auto">Is the change from "Personal Data" to "personal data" a stylistic change?</p>
<p dir="auto">I note that the paragraph above is still intact:</p>
<blockquote>
<p dir="auto">All capitalized terms have their definition in <a href="https://github.com/github/site-policy/github-terms-of-service">GitHub’s Terms of Service</a>, unless otherwise noted here.</p>
</blockquote>
<p dir="auto">Presuming this capitalization change is unintentional, it has the unfortunate effect of decoupling "Personal Data" from the definition provided in the GitHub Terms of Service, which means that "personal data" is no longer as delineated there, but could well be anything.</p>
<p dir="auto">If this is an intentional change, it would seem better made as a visible change to the Terms of Service. If the intent is not to change the Terms of Service but to arbitrarily expand "personal data" without drawing attention, well, that seems evil.</p>
    </div>
  </task-lists>
  

</div>

        <!-- '"` --><!-- </textarea></xmp> -->
          <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
    <div>
          <tool-tip id="tooltip-ad23abe6-b8fe-4220-bc0c-719192021b4e" for="reactions--reaction_button_component-29373f" popover="manual" data-direction="n" data-type="description" data-view-component="true">TotallyInformation, bashrc2, TheLastProject, RokeJulianLockhart, Eireen, akshaim, S1GGEN, ims2012035, UNINOIZE, ikhtearalamshawonmollah54321, and ma99R reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-66512b5a-c560-40a1-9ac6-a698d63da9b1" for="reactions--reaction_button_component-00a730" popover="manual" data-direction="n" data-type="description" data-view-component="true">ikhtearalamshawonmollah54321 and ma99R reacted with hooray emoji</tool-tip>
          <tool-tip id="tooltip-3f557311-ba40-416d-9ac0-9f1f976447e7" for="reactions--reaction_button_component-054833" popover="manual" data-direction="n" data-type="description" data-view-component="true">Zaczero, TheDeveloper101, DimitarBogdanov, Rancunefr, adrian-enspired, chakravala, ycMia, Cking351, ims2012035, and ma99R reacted with confused emoji</tool-tip>
          <tool-tip id="tooltip-fb8b8546-ce4d-4fab-b04f-62096649d24a" for="reactions--reaction_button_component-9d78f0" popover="manual" data-direction="n" data-type="description" data-view-component="true">ikhtearalamshawonmollah54321 and ma99R reacted with rocket emoji</tool-tip>
          <tool-tip id="tooltip-345e3120-d607-420a-a9cc-41bfd8ba9f87" for="reactions--reaction_button_component-c65ae3" popover="manual" data-direction="n" data-type="description" data-view-component="true">CyberFlameGO, kiwiroy, thexkey, TheMaverickProgrammer, queer, cedarkeith, jrmsjorgesilva, byronic, thomasingalls, cheshire137, and 81 more reacted with eyes emoji</tool-tip>
      
    </div>
</form></div>

</div>

    <div id="discussion_r936087501">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">Looking into this further -- it looks like "Personal Data" is defined these days in the <a href="https://docs.github.com/en/site-policy/privacy-policies/github-data-protection-agreement">GitHub Data Protection Agreement</a>. Perhaps this was being decapitalized since it is not directly defined (afaict) in the GitHub Terms of Service?</p>
  </task-lists>
  

</div>

    <div id="discussion_r940888560">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">Oh bet</p>
  </task-lists>
  

</div>

    <div id="discussion_r944061298">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">The collection of information and sale of it I think is something that has been going on for a long time. I think what matters is knowing what information we provide. But it's always good to know</p>
  </task-lists>
  

</div>

    <div id="discussion_r946820017">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">salve cade os BR</p>
  </task-lists>
  

</div>



    <div id="discussion_r949338919">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <div>
      <p dir="auto">in a court of law, doesn't "Personal Data" mean "personal data" ?</p>
<p dir="auto">lol</p>
    </div>
  </task-lists>
  

</div>

    <div id="discussion_r1532912063">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">Soy mario sl papa si tubieron q ver en esta acciion demla boluntad arreglenlo o se veran en lios no agan mad difisil las cosas y agan l9 correcto</p>
  </task-lists>
  

</div>


    </div>

</div>
</details></details-toggle>
  </details-collapsible>
</turbo-frame>




</div>  </div>

      <div data-view-component="true" id="pullrequestreview-1059517964" data-gid="PRR_kwDOBZWBkc4_JvYM" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0X3JldmlldzoxMDU5NTE3OTY0IiwidCI6MTc1NDQxMTQwNH0=--8c6ddaf987dfc32c556e3c02fcce267ae439c8deba49a292ce2507373f9e11d3" data-url="/github/site-policy/pull/582/partials/reviews/1059517964">
  <p><a href="https://github.com/krystian3w" data-view-component="true"><img data-hovercard-type="user" data-hovercard-url="/users/krystian3w/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" src="https://avatars.githubusercontent.com/u/35370833?s=60&amp;v=4" alt="krystian3w" size="40" height="40" width="40" data-view-component="true"></a></p>
  
</div>

      <div id="pullrequestreview-1059535140" data-gid="PRR_kwDOBZWBkc4_Jzkk" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0X3JldmlldzoxMDU5NTM1MTQwIiwidCI6MTc1NDQxMTQwNH0=--c6c97cc8124869c29d940b628bc0fd7722c9f8d1b238fe0cbe793b56c2b7fcb4" data-url="/github/site-policy/pull/582/partials/reviews/1059535140">
      <div data-view-component="true">
  <p><a href="https://github.com/Consolatis" data-view-component="true"><img data-hovercard-type="user" data-hovercard-url="/users/Consolatis/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" src="https://avatars.githubusercontent.com/u/35009135?s=60&amp;v=4" alt="Consolatis" size="40" height="40" width="40" data-view-component="true"></a></p>
  
</div>

      <div data-view-component="true">            <turbo-frame id="review-thread-or-comment-id-599013576" target="_top">
  <details-collapsible>
    <details-toggle>
    <details open="open" data-resolved="false" data-target="details-collapsible.detailsElement details-toggle.detailsTarget" data-view-component="true">
      <summary role="button" data-target="details-collapsible.summaryElement details-toggle.summaryTarget" data-action="click:details-collapsible#toggle click:details-toggle#toggle" data-aria-label-closed="Expand comment" data-aria-label-open="Collapse comment" aria-expanded="true" aria-label="Collapse comment" data-view-component="true">        
</summary>
      <div data-view-component="true">          
  <div>
    
    <table data-tab-size="8" data-paste-markdown-skip="">
          <tbody><tr>

              <td data-line-number="217"></td>

              <td data-line-number="222"></td>

            <td>
              <span><br></span>

            </td>
          </tr>
          <tr>

              <td data-line-number="218"></td>

              <td data-line-number="223"></td>

            <td>
              <span>Our emails to users may contain a pixel tag, which is a small, clear image that can tell us whether or not you have opened an email and what your IP address is. We use this pixel tag to make our email communications more effective and to make sure we are not sending you unwanted email.</span>

            </td>
          </tr>
          <tr>

              <td data-line-number="219"></td>

              <td data-line-number="224"></td>

            <td>
              <span><br></span>

            </td>
          </tr>
          <tr>

              <td data-line-number="220"></td>

              <td data-line-number="225"></td>

            <td>
              <span><span>### <span>DNT</span></span></span>

            </td>
          </tr>
          <tr>

              <td data-line-number="221"></td>

              <td data-line-number="226"></td>

            <td>
              <span><br></span>

            </td>
          </tr>
          <tr>

              <td data-line-number="222"></td>

              <td></td>

            <td>
              <span>"<span>[</span>Do Not Track<span>]</span><span>(</span><span>https://www.eff.org/issues/do-not-track</span><span>)</span>" (DNT) is a privacy preference you can set in your browser if you do not want online services to collect and share certain kinds of information about your online activity from third party tracking services. <span>GitHub responds </span>to browser DNT signals and <span>follows</span> the <span>[</span>W3C standard for responding to DNT signals<span>]</span><span>(</span><span>https://www.w3.org/TR/tracking-dnt/</span><span>)</span>. If you would like to set your browser to signal that you would not like to be tracked, please check your browser's documentation for how to enable that signal. There are also good applications that block online tracking, such as <span>[</span>Privacy Badger<span>]</span><span>(</span><span>https://privacybadger.org/</span><span>)</span>.</span>

            </td>
          </tr>
          <tr>

              <td></td>

              <td data-line-number="227"></td>

            <td>
              <span>"<span>[</span>Do Not Track<span>]</span><span>(</span><span>https://www.eff.org/issues/do-not-track</span><span>)</span>" (DNT) is a privacy preference you can set in your browser if you do not want online services to collect and share certain kinds of information about your online activity from third party tracking services. <span>Some services may respond </span>to browser DNT signals and <span>follow</span> the <span>[</span>W3C standard for responding to DNT signals<span>]</span><span>(</span><span>https://www.w3.org/TR/tracking-dnt/</span><span>)</span>. If you would like to set your browser to signal that you would not like to be tracked, please check your browser's documentation for how to enable that signal. There are also good applications that block online tracking, such as <span>[</span>Privacy Badger<span>]</span><span>(</span><span>https://privacybadger.org<span>/</span></span><span>)</span><span> or </span><span>[</span><span>uBlock Origin</span><span>]</span><span>(</span><span><span>https://github.com/gorhill/uBlock</span>/</span><span>)</span>.</span>

            </td>
          </tr>
    </tbody></table>

</div>


<div data-quote-markdown=".js-comment-body">
        <div id="discussion_r936108986">
        

        <div>
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <div>
      <p dir="auto">Let me prefix this by stating that I am a complete layman.</p>
<p dir="auto">Previously: *GitHub* responds to browser DNT signals and follows the W3C spec.<br>
Now: Some random services, somewhere in the world, hosted by GitHub or somebody else *may* respond to browser DNT signals and follow the W3C spec.</p>
<p dir="auto">Doesn't this change invalidate the whole paragraph and turns it into a generic wiki article?</p>
    </div>
  </task-lists>
  

</div>

        <!-- '"` --><!-- </textarea></xmp> -->
          <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
    <div>
          <tool-tip id="tooltip-4c24a62b-b1e7-4795-9923-13d6240d857a" for="reactions--reaction_button_component-0794cc" popover="manual" data-direction="n" data-type="description" data-view-component="true">MrBartusek, TheMaverickProgrammer, getaaron, jrockway, DoodlesEpic, tiansh, SkyLeite, afkvido, beaugunderson, ajacques, and 195 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-91310069-57e3-42ab-b776-d1be8fe66aba" for="reactions--reaction_button_component-26add5" popover="manual" data-direction="n" data-type="description" data-view-component="true">ikhtearalamshawonmollah54321 reacted with hooray emoji</tool-tip>
          <tool-tip id="tooltip-e5603720-7091-48ac-b626-a2d24729961a" for="reactions--reaction_button_component-d06f63" popover="manual" data-direction="n" data-type="description" data-view-component="true">L3P3, bjornrud, kamulos, real-yfprojects, blizzz, vishaltomars, DimitarBogdanov, wschwab, bsedin, adrian-enspired, and 4 more reacted with heart emoji</tool-tip>
          <tool-tip id="tooltip-11a6d538-e473-4b0f-be8e-61770b8dd299" for="reactions--reaction_button_component-12fb2f" popover="manual" data-direction="n" data-type="description" data-view-component="true">ikhtearalamshawonmollah54321 reacted with rocket emoji</tool-tip>
          <tool-tip id="tooltip-3b8e27dd-0aad-4305-8bef-2c3cce10a943" for="reactions--reaction_button_component-f7f650" popover="manual" data-direction="n" data-type="description" data-view-component="true">vishaltomars, DamianFekete, adrian-enspired, jacobrose, gresm, euclidesdry, and mdjunaeidislam reacted with eyes emoji</tool-tip>
      
    </div>
</form></div>

</div>

    <div id="discussion_r936122042">
        

        <div>
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">Dunno, they will stop respecting DNT but leave this paragraph and make it seem as if they do. This is just confusing.</p>
  </task-lists>
  

</div>

        <!-- '"` --><!-- </textarea></xmp> -->
          <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
    <div>
          <tool-tip id="tooltip-2973e65d-bf5e-4948-af95-8bf2455773c7" for="reactions--reaction_button_component-261632" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, guarilha, bdougherty, amomchilov, jmillerv, swadeley, gaael, SVendittelli, pravinxor, ZelphirKaltstahl, and 12 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-18c498cc-9fdb-4ed7-a3d7-aded3bfcc28b" for="reactions--reaction_button_component-4d0961" popover="manual" data-direction="n" data-type="description" data-view-component="true">hen-x, kkirsche, vishaltomars, SkrudjReal, TarikViehmann, and ims2012035 reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-3843c8c4-b33a-4fa0-b471-7017c31418e7" for="reactions--reaction_button_component-05e917" popover="manual" data-direction="n" data-type="description" data-view-component="true">vishaltomars and ims2012035 reacted with laugh emoji</tool-tip>
          <tool-tip id="tooltip-1bef7ab0-ca76-4b9b-ac69-8e8948f5f0eb" for="reactions--reaction_button_component-4236e4" popover="manual" data-direction="n" data-type="description" data-view-component="true">vishaltomars, ims2012035, and ikhtearalamshawonmollah54321 reacted with hooray emoji</tool-tip>
          <tool-tip id="tooltip-b0451b1c-9849-4491-9081-86e905e1b931" for="reactions--reaction_button_component-c9f4a9" popover="manual" data-direction="n" data-type="description" data-view-component="true">vishaltomars, oscarhermoso, amomchilov, and ims2012035 reacted with confused emoji</tool-tip>
          <tool-tip id="tooltip-080e21f3-e717-4f9d-82ea-76d9e4e9af49" for="reactions--reaction_button_component-4b0c70" popover="manual" data-direction="n" data-type="description" data-view-component="true">vishaltomars, wschwab, rettichschnidi, and ims2012035 reacted with heart emoji</tool-tip>
          <tool-tip id="tooltip-10933e06-2cff-4aba-ad45-a9384cc59dc6" for="reactions--reaction_button_component-96f6c5" popover="manual" data-direction="n" data-type="description" data-view-component="true">ikhtearalamshawonmollah54321 reacted with rocket emoji</tool-tip>
          <tool-tip id="tooltip-71b3b497-5d3d-4575-8a3f-ce3cd56bc987" for="reactions--reaction_button_component-6cffcc" popover="manual" data-direction="n" data-type="description" data-view-component="true">mdjunaeidislam reacted with eyes emoji</tool-tip>
      
    </div>
</form></div>

</div>

    <div id="discussion_r936152327">
        

        <div>
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <div>
      <p dir="auto">"Confusing" is one way to put it.</p>
<p dir="auto">Edit:<br>
<a data-hovercard-type="user" data-hovercard-url="/users/zzo38/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/zzo38">@zzo38</a> articulated my personal opinion better than I could so I'll quote part of their <a href="https://github.com/github/site-policy/pull/582#issuecomment-1203508593" data-hovercard-type="pull_request" data-hovercard-url="/github/site-policy/pull/582/hovercard">comment</a> here:</p>
<blockquote>
<p dir="auto">I also think that they should avoid using confusing privacy policies; the mention of DNT should either be kept as is if GitHub uses the DNT header to reduce tracking, or deleted entirely if GitHub does not use the DNT header. If it does so only in some cases, <b>it should mention what cases these are</b>. The privacy policy made sense before the change in the section about DNT, although the change mentioned above makes it confusing (as other comments already mention).</p>
<p dir="auto">[..]</p>
<p dir="auto">I have no problem with adding these non-essential cookies to the enterprise marketing pages, as long as the rest of GitHub can be used without it <b>and it is documented which pages these are</b> (and if the cookie domain is the same, also which cookies). Moving the enterprise marketing pages to a separate domain seems to me to be a good idea though, in order to be clearly distinguished (although a subdomain is probably good enough, in my opinion; <b>as long as it is documented clearly which subdomains these are</b>).</p>
</blockquote>
<p dir="auto">Emphasis are mine.<br>
In my opinion, <code>documented</code> should mean being very specific and being part of a legally binding document like the privacy policy.</p>
<p dir="auto">An example for not being specific is this part of the changes:</p>
<blockquote>
<p dir="auto">As described below, we may use non-essential cookies on <b>certain pages</b> of our website</p>
</blockquote>
    </div>
  </task-lists>
  

</div>

        <!-- '"` --><!-- </textarea></xmp> -->
          <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
    <div>
          <tool-tip id="tooltip-ae17e92a-6cf9-4bc8-95ed-5a70f5921c31" for="reactions--reaction_button_component-69b8a4" popover="manual" data-direction="n" data-type="description" data-view-component="true">RokeJulianLockhart, BezBIS, gatlinnewhouse, Elman295, goyalyashpal, UNINOIZE, and henry701 reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-6e7f7eda-30f1-4f20-91f6-1090500b07f2" for="reactions--reaction_button_component-57a03a" popover="manual" data-direction="n" data-type="description" data-view-component="true">MrBartusek, SkyLeite, antn, karolba, gldraphael, not-matthias, RomainTHD, jwshields, kkirsche, ulfox, and 22 more reacted with laugh emoji</tool-tip>
          <tool-tip id="tooltip-9e5378bf-71b3-4093-82eb-128412df4079" for="reactions--reaction_button_component-821bb3" popover="manual" data-direction="n" data-type="description" data-view-component="true">jacobrose and stancalau reacted with heart emoji</tool-tip>
      
    </div>
</form></div>

</div>

    <div id="discussion_r939618543">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">:))</p>
  </task-lists>
  

</div>

    <div id="discussion_r942363229">
        

        <div>
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <div>
      <p dir="auto">So; let's get this straight:</p>
<ol dir="auto">
<li>According to GDPR article 22 data subjects may exercise their right to object to processing using technical specifications.</li>
<li>GitHub acknowledges the DNT signal as a valid technical standard, i.e. technical specification.</li>
<li>Moreover; GitHub honors - or at least used to honor - that signal, illustrating that they have the capacity to respond to it appropriately.</li>
</ol>
<p dir="auto">Yeah... uhm..<br>
How is attempting to weasel yourself out from under that not morally blackest evil?</p>
    </div>
  </task-lists>
  

</div>

        <!-- '"` --><!-- </textarea></xmp> -->
          <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
    <div>
          <tool-tip id="tooltip-912a780c-5546-4fb9-b5c1-7514b54657dd" for="reactions--reaction_button_component-0af45e" popover="manual" data-direction="n" data-type="description" data-view-component="true">lodo1995, CADawg, jacobrose, reinerh, stancalau, yogthos, gaael, AaronHebert, gatlinnewhouse, bryan-hoang, and 15 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-f6831a82-9fc5-42fa-8b7b-6d02eae29abb" for="reactions--reaction_button_component-f63463" popover="manual" data-direction="n" data-type="description" data-view-component="true">Rwarcards762, CADawg, ericksoa, and euclidesdry reacted with rocket emoji</tool-tip>
          <tool-tip id="tooltip-6b1ad3fa-205d-4c04-a52a-8a942afb2422" for="reactions--reaction_button_component-65f8be" popover="manual" data-direction="n" data-type="description" data-view-component="true">CADawg and Gerardojc reacted with eyes emoji</tool-tip>
      
    </div>
</form></div>

</div>



    <div id="discussion_r1830653959">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">can someone please explain the policy's <a data-hovercard-type="organization" data-hovercard-url="/orgs/github/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/github">@github</a> and what happened to <a data-hovercard-type="user" data-hovercard-url="/users/dontsellmydata/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/dontsellmydata">@dontsellmydata</a>?<br>
asking for a friend</p>
  </task-lists>
  

</div>

    <div id="discussion_r2249062805">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">privacy-statement-update-sep-2022</p>
  </task-lists>
  

</div>


    </div>

</div>
</details></details-toggle>
  </details-collapsible>
</turbo-frame>




</div>  </div>

      <div data-gid="IC_kwDOBZWBkc5HuV3O" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HuV3O/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/jdgregson/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/jdgregson"><img src="https://avatars.githubusercontent.com/u/3778841?s=80&amp;u=22355dea7c49323adb8b54ea6072935d2ee0703a&amp;v=4" width="40" height="40" alt="@jdgregson"></a>

</p>


  
<div data-body-version="b55ba0cce6be6f0d8f1b3768340000e3a94313b34054ccde7d7a31308cad3968" id="issuecomment-1203330510">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">You lost me at <code>ads for enterprise users</code>.</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-e1745cb8-7683-432b-9734-0410c8b93cb5" for="reactions--reaction_button_component-9340c8" popover="manual" data-direction="n" data-type="description" data-view-component="true">iam-py-test, stamminator, rizkyhaksono, FaircoreHD, askeer25, Madi-Ji, michaeldelago, LambdAurora, Asjas, bdougherty, and 62 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-d3d20cd6-8ce9-417c-b79b-e491ad3d30bb" for="reactions--reaction_button_component-500a5c" popover="manual" data-direction="n" data-type="description" data-view-component="true">ims2012035 and ma99R reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-e158a52a-7078-46c7-b757-821c376b5655" for="reactions--reaction_button_component-950b95" popover="manual" data-direction="n" data-type="description" data-view-component="true">ims2012035, ma99R, FlorianWendelborn, and henry701 reacted with laugh emoji</tool-tip>
          <tool-tip id="tooltip-53c21ae0-34e2-437c-b809-61fea0c3702f" for="reactions--reaction_button_component-90d6f4" popover="manual" data-direction="n" data-type="description" data-view-component="true">ims2012035 and ma99R reacted with hooray emoji</tool-tip>
          <tool-tip id="tooltip-5aeea9e7-bc6e-4743-b238-22aced1d99af" for="reactions--reaction_button_component-d5b04c" popover="manual" data-direction="n" data-type="description" data-view-component="true">ims2012035 and ma99R reacted with confused emoji</tool-tip>
          <tool-tip id="tooltip-9dd94a8b-4d57-4b28-bd2d-4fa13bdfd488" for="reactions--reaction_button_component-04f54d" popover="manual" data-direction="n" data-type="description" data-view-component="true">ims2012035 and ma99R reacted with heart emoji</tool-tip>
          <tool-tip id="tooltip-c4d6c54b-8d75-4efd-98a6-dd3e9c4cc3e8" for="reactions--reaction_button_component-678542" popover="manual" data-direction="n" data-type="description" data-view-component="true">leoheck, Cyb3r-Jak3, c3r0, Sunnnner, yanghanlin, jtraglia, TheMaverickProgrammer, trevorstenson, ZeroCool2u, pabloazurduy, and 139 more reacted with rocket emoji</tool-tip>
          <tool-tip id="tooltip-cf030c09-c8dd-4b5c-9373-54669141b8ee" for="reactions--reaction_button_component-56f010" popover="manual" data-direction="n" data-type="description" data-view-component="true">ims2012035 and ma99R reacted with eyes emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5HuXeX" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HuXeX/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/leoheck/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/leoheck"><img src="https://avatars.githubusercontent.com/u/1277920?s=80&amp;v=4" width="40" height="40" alt="@leoheck"></a>

</p>


  
<div data-body-version="3a75bde190114c20f35bfdf768a07f335b9e864ad4f20c4aca3d884c0ed8d56a" id="issuecomment-1203337111">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">Github is being undermined by Microsoft.</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-f14876c1-70cf-45b5-9bec-7e9462d043c9" for="reactions--reaction_button_component-c44d52" popover="manual" data-direction="n" data-type="description" data-view-component="true">ardrigh, darkbanjo, afkvido, mskelton, MarcusGoldschmidt, xCss, patstha, ariedro, karolba, povilaspetkevicius, and 173 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-0cf823b4-0196-4f08-9b0c-e14605590abc" for="reactions--reaction_button_component-bdee2d" popover="manual" data-direction="n" data-type="description" data-view-component="true">evieluvsrainbows, cinnamondev, TreeBranches, mbifulco, itpropro, RokeJulianLockhart, ims2012035, zeina1991, and ma99R reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-f7a91aa8-76b1-4b1d-a9d5-d9aa682bcca5" for="reactions--reaction_button_component-99cbee" popover="manual" data-direction="n" data-type="description" data-view-component="true">jacobrose, ims2012035, and ma99R reacted with confused emoji</tool-tip>
          <tool-tip id="tooltip-45164a4c-5aa4-496e-a847-35bd761f0937" for="reactions--reaction_button_component-dbc875" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, ims2012035, and ma99R reacted with rocket emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5HuafN" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HuafN/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/TechSolomon/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/TechSolomon"><img src="https://avatars.githubusercontent.com/u/7608183?s=80&amp;u=d50a3f18756548563d2d83d8a712cc6ef025f4b9&amp;v=4" width="40" height="40" alt="@TechSolomon"></a>

</p>


  
<div data-body-version="2bdae0352f7d6a759aae50ef08ef17471e9f511665b705b55584648b86d30283" id="issuecomment-1203349453">

        
<task-lists disabled="" sortable="">

</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-ff5b3616-b6b2-4f61-aada-e8a222feb5c4" for="reactions--reaction_button_component-9ab90d" popover="manual" data-direction="n" data-type="description" data-view-component="true">yanghanlin, doamatto, william-herring, jtraglia, xplato, ocdtrekkie, byrnes, stepbrobd, andyferris, henriquebremenkanp, and 292 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-21117f32-9dfb-43bb-bbee-331f4b200122" for="reactions--reaction_button_component-3a9e5e" popover="manual" data-direction="n" data-type="description" data-view-component="true">RokeJulianLockhart, ims2012035, ma99R, and abosayedmusic reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-a298ec59-9ae2-4642-a8e0-73f0eeca275b" for="reactions--reaction_button_component-b0cc28" popover="manual" data-direction="n" data-type="description" data-view-component="true">kubo6472, S1GGEN, ims2012035, and ma99R reacted with confused emoji</tool-tip>
          <tool-tip id="tooltip-2d35f837-2636-4ba4-b988-56150dea9b89" for="reactions--reaction_button_component-a62076" popover="manual" data-direction="n" data-type="description" data-view-component="true">html5cat, cpl, kkirsche, arsam-sedighi, rodamaral, Rikj000, speller26, LumitoLuma, NeuronButter, wschwab, and 4 more reacted with rocket emoji</tool-tip>
          <tool-tip id="tooltip-71b3661e-9493-46db-964c-7562dacadc4b" for="reactions--reaction_button_component-bce69d" popover="manual" data-direction="n" data-type="description" data-view-component="true">flbn, MarcusGoldschmidt, shivajivarma, ZeroAurora, crankyadmin, DarkOnion0, just-max, krall12, arsam-sedighi, rodamaral, and 19 more reacted with eyes emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5Huigr" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5Huigr/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/TheMaverickProgrammer/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/TheMaverickProgrammer"><img src="https://avatars.githubusercontent.com/u/91709?s=80&amp;u=8ae1459deffcd91d0c3d84d36fb41a6666dabc32&amp;v=4" width="40" height="40" alt="@TheMaverickProgrammer"></a>

</p>


  
<div data-body-version="2994297af41a6c30fd743ed2e31ec97fc5abc19a544ce2039943b3c429d5eb5a" id="issuecomment-1203382315">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">so what github alternative is everyone using these days? asking for a friend.</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-22aa830a-ba6f-40eb-bad1-4ffc85686422" for="reactions--reaction_button_component-4c7e79" popover="manual" data-direction="n" data-type="description" data-view-component="true">ardrigh, afkvido, leoheck, dominikwilkowski, timvisee, wout, demonshreder, xcfrg, osmankorogluu, alimkoca, and 103 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-bf9fd3c0-b9e4-4989-8d9f-e42e70c56bd2" for="reactions--reaction_button_component-cada5e" popover="manual" data-direction="n" data-type="description" data-view-component="true">evieluvsrainbows, whiztech, TreeBranches, nowaythisworks, and NeuronButter reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-25e4cfc2-595e-4079-ae6b-bdc7148952fd" for="reactions--reaction_button_component-6ae80c" popover="manual" data-direction="n" data-type="description" data-view-component="true">uglow, leoheck, wout, Benj2005, powderedfish, IgorVolochay, maSchoeller, Jonikulov, Feridinha, onkoe, and 28 more reacted with laugh emoji</tool-tip>
          <tool-tip id="tooltip-c548b372-4c91-49d2-8fea-2ca7e370a3bf" for="reactions--reaction_button_component-0ca7cd" popover="manual" data-direction="n" data-type="description" data-view-component="true">ariedro, wout, nothub, Feridinha, Rikj000, Risyandi, LumitoLuma, theRealProHacker, gin0115, devtooligan, and 14 more reacted with heart emoji</tool-tip>
          <tool-tip id="tooltip-f27d57d9-2064-4d73-a22a-4a16d2a79f55" for="reactions--reaction_button_component-c61ac9" popover="manual" data-direction="n" data-type="description" data-view-component="true">Rwarcards762 and afkvido reacted with rocket emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5Huko-" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5Huko-/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/ocdtrekkie/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/ocdtrekkie"><img src="https://avatars.githubusercontent.com/u/4399499?s=80&amp;u=ceab721d97868ffa78feb5e97ff1bb547dfd6356&amp;v=4" width="40" height="40" alt="@ocdtrekkie"></a>

</p>


  
<div data-body-version="d4ad471236222a6d776ac85103f2d5cec6b9c2f98bbc54c71a93214513a01141" id="issuecomment-1203391038">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">"We are also committing that going forward, we will only use cookies that are required for us to serve GitHub.com."</p>
<p dir="auto">Apparently in corporate terms, a "commitment" is now less than two calendar years of obligation. Good to know. Though, I guess I don't visit the marketing pages and hence, don't really care that much? Corporations being untrustworthy isn't new territory.</p>
<p dir="auto">Literally just "business advice": Your marketing teams should be weighing the value of the data here against the cost of "yet another breach of user trust and commitment", user trust, of course, being something extremely hard to earn back.</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-774a2706-ea57-4394-9ca1-7ec2d72e6947" for="reactions--reaction_button_component-735dc1" popover="manual" data-direction="n" data-type="description" data-view-component="true">damien, consultutah, andyferris, jtraglia, queer, DoodlesEpic, sandro-fugro, flbn, icecreammatt, ardrigh, and 161 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-0c24b900-25c2-4e9c-8274-ed43f9d305be" for="reactions--reaction_button_component-c8a486" popover="manual" data-direction="n" data-type="description" data-view-component="true">RokeJulianLockhart and ma99R reacted with thumbs down emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5HumM9" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HumM9/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/karlshea/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/karlshea"><img src="https://avatars.githubusercontent.com/u/40136?s=80&amp;u=83a9cdcd1f24cb9d4ec1a99e4ef398a389a4da36&amp;v=4" width="40" height="40" alt="@karlshea"></a>

</p>


  
<div data-body-version="2fec3d0f81d7f90dff34e5701f7c2e434cb3eba117da99165e6d390ab12b7e91" id="issuecomment-1203397437">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">Marketing people don't care about user trust or commitments. They'll just burn things to the ground and move on to the next corp job, each time making the world a slightly worse place.</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-bdac5443-41e5-42dc-8462-8705e03d2e96" for="reactions--reaction_button_component-bc548b" popover="manual" data-direction="n" data-type="description" data-view-component="true">nclark, sandro-fugro, icecreammatt, ardrigh, slater, mskelton, patstha, RoyTinker, uglow, ariedro, and 117 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-4ee0024a-bbec-4b30-8316-0553b09e748f" for="reactions--reaction_button_component-13db14" popover="manual" data-direction="n" data-type="description" data-view-component="true">gavinhenderson, RokeJulianLockhart, and michaelkuznetsov reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-0360eaba-9a1f-467b-a694-5aa3ba6f854e" for="reactions--reaction_button_component-60e098" popover="manual" data-direction="n" data-type="description" data-view-component="true">EwenQuim reacted with hooray emoji</tool-tip>
          <tool-tip id="tooltip-2cf3d011-9355-4a72-bdc3-fc85e8bfa276" for="reactions--reaction_button_component-eb2918" popover="manual" data-direction="n" data-type="description" data-view-component="true">jacobrose reacted with confused emoji</tool-tip>
          <tool-tip id="tooltip-3caadcd8-e8bc-499a-b8c7-4b5e3ca6ca52" for="reactions--reaction_button_component-d4a665" popover="manual" data-direction="n" data-type="description" data-view-component="true">UNINOIZE reacted with heart emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5HupcL" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HupcL/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/afkvido/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/afkvido"><img src="https://avatars.githubusercontent.com/u/69060894?s=80&amp;u=3535e3e6b09a2e616878557422eb78152a028fef&amp;v=4" width="40" height="40" alt="@afkvido"></a>

</p>


  
<div data-body-version="8b75cb42e99586e3c67be7363b4d40340484cc29cfe23742949772b47141fb93" id="issuecomment-1203410699">

        
<task-lists disabled="" sortable="">
<div>
          <blockquote>
<p dir="auto">This clearly shows that GitHub cares more about revenue than the user base behind it.</p>
</blockquote>
<p dir="auto">Microsoft fucking sucks, GitHub wasn't evil until Microsoft really started to abuse GitHub.</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-11ea3271-c9bb-4281-a20f-183c84ebbbeb" for="reactions--reaction_button_component-ea36df" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, MarcusGoldschmidt, patstha, ariedro, karolba, dseevr, dominikwilkowski, timvisee, wout, talgat-ruby, and 82 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-d4ba0777-51ff-48c0-b2b5-baf18723bad2" for="reactions--reaction_button_component-d68b3a" popover="manual" data-direction="n" data-type="description" data-view-component="true">CAFxX, evieluvsrainbows, whiztech, liamengland1, TreeBranches, nowaythisworks, crazychatting, Blaumaus, dszymon, wojpawlik, and 4 more reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-8fd0372b-69ce-457d-b0ca-80e270ed607c" for="reactions--reaction_button_component-3b7206" popover="manual" data-direction="n" data-type="description" data-view-component="true">ariedro, JanJastrow, and ims2012035 reacted with confused emoji</tool-tip>
          <tool-tip id="tooltip-4402c8ca-576d-44c8-b2fa-8ad35b9dc315" for="reactions--reaction_button_component-432d5f" popover="manual" data-direction="n" data-type="description" data-view-component="true">UNINOIZE reacted with heart emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5HupnV" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HupnV/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/afkvido/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/afkvido"><img src="https://avatars.githubusercontent.com/u/69060894?s=80&amp;u=3535e3e6b09a2e616878557422eb78152a028fef&amp;v=4" width="40" height="40" alt="@afkvido"></a>

</p>


  
<div data-body-version="e2c91e5973a4063323826528013bf4e0abd0a7c69ab27c13ebd6983412e49c54" id="issuecomment-1203411413">

        
<task-lists disabled="" sortable="">

</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-eb17e9ee-1043-431d-b134-09a9a935b333" for="reactions--reaction_button_component-0ef17c" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, leoheck, shivamydv, just-max, xcfrg, DanielVenturini, otavio-silva, onkoe, crazychatting, sz55net, and 20 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-2ff13314-7b4e-41e0-811f-c1be84084956" for="reactions--reaction_button_component-16647b" popover="manual" data-direction="n" data-type="description" data-view-component="true">evieluvsrainbows, nothub, krall12, SincerelyFaust, ryuukk, coderinblack08, sanamhub, nowaythisworks, null2264, Vendicated, and 16 more reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-83a228b7-6d18-4f2d-8a63-b79060acf5ce" for="reactions--reaction_button_component-8e38e8" popover="manual" data-direction="n" data-type="description" data-view-component="true">ariedro, just-max, DanielVenturini, Caiofcas, otavio-silva, afkvido, Rwarcards762, rettichschnidi, fuomag9, MariojGG, and 2 more reacted with heart emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div id="pullrequestreview-1059625419" data-gid="PRR_kwDOBZWBkc4_KJnL" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0X3JldmlldzoxMDU5NjI1NDE5IiwidCI6MTc1NDQxMTQwNH0=--56fda6c1cde88f791bececa8846f8a5d2201d6a460d98f5e5c45579fe8949f44" data-url="/github/site-policy/pull/582/partials/reviews/1059625419">
      <div data-view-component="true">
  <p><a href="https://github.com/afkvido" data-view-component="true"><img data-hovercard-type="user" data-hovercard-url="/users/afkvido/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" src="https://avatars.githubusercontent.com/u/69060894?s=60&amp;v=4" alt="afkvido" size="40" height="40" width="40" data-view-component="true"></a></p>
  
</div>
          <div id="pullrequestreview-1059625419" data-view-component="true">
                      
                  <div>
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">Requesting a change: Don't add this.</p>
  </task-lists>
  
</div>


                    <!-- '"` --><!-- </textarea></xmp> -->
                      <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
    <div>
          <tool-tip id="tooltip-8ee6618e-5cae-46ae-9875-8ea749965023" for="reactions--reaction_button_component-88cf91" popover="manual" data-direction="n" data-type="description" data-view-component="true">mskelton, thomasingalls, VitorLuizC, jtraglia, byronic, patstha, afkvido, mattburdumy, francisschmaltz, arderyp, and 224 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-19c10583-5097-4463-afdd-0f6f11f2b6be" for="reactions--reaction_button_component-bdea34" popover="manual" data-direction="n" data-type="description" data-view-component="true">evieluvsrainbows, dszymon, RokeJulianLockhart, and 0kku reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-45511ff1-f4d9-4f56-b6d8-ce1f28672bfe" for="reactions--reaction_button_component-4b93ab" popover="manual" data-direction="n" data-type="description" data-view-component="true">wout, Jack2104, fleroviux, DarkOnion0, gruselhaus, DanielVenturini, Rikj000, speller26, afkvido, LambdAurora, and 10 more reacted with heart emoji</tool-tip>
      
    </div>
</form></div>

</div>
        </div>

      <div data-gid="IC_kwDOBZWBkc5HuthO" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HuthO/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/RoyTinker/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/RoyTinker"><img src="https://avatars.githubusercontent.com/u/984080?s=80&amp;u=30d9e5bb3663a62a5c759a4bb6f09ed3a79c8126&amp;v=4" width="40" height="40" alt="@RoyTinker"></a>

</p>


  
<div data-body-version="41a408e6fbc267577580379401216d3157e5d38d6649104bcb40b40396a0c44b" id="issuecomment-1203427406">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">I understand that cookies are helpful for analytics and gathering sales funnel data. It's always sad when companies don't keep prior promises, though 😟</p>
<p dir="auto">If you must break the promise, here's my suggestion, for what it's worth: move enterprise marketing pages (maybe even all marketing pages besides the front page?) off of <code>github.com</code> onto a separate domain. Maybe <code>github.info</code>?</p>
<p dir="auto">Then point marketing links from the front page to that domain.</p>
<p dir="auto">This will allow folks to deal with that domain separately from <code>github.com</code>.</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-a4fb3b95-fef8-4ef6-a21c-86889a058139" for="reactions--reaction_button_component-d71fbd" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, cheshire137, sarangj, leoheck, yanghanlin, dominikwilkowski, pgear-wd, timvisee, wout, borisceranic, and 68 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-c89d4e37-1e16-4a9e-9e4d-75eead6fd02b" for="reactions--reaction_button_component-ace2aa" popover="manual" data-direction="n" data-type="description" data-view-component="true">RokeJulianLockhart reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-59e32d1e-669a-4441-af15-983dfcf9daf1" for="reactions--reaction_button_component-f475f8" popover="manual" data-direction="n" data-type="description" data-view-component="true">sz55net reacted with confused emoji</tool-tip>
          <tool-tip id="tooltip-9a8180c2-8fcb-454b-9cf3-ed87b6a64dd3" for="reactions--reaction_button_component-6f3de0" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, leoheck, 1to5pc, freearhey, Rikj000, and adrian-enspired reacted with rocket emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5Huthk" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5Huthk/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/tylt6688/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/tylt6688"><img src="https://avatars.githubusercontent.com/u/45555547?s=80&amp;u=d52d51990831a98f478abc7bae9e1f042da2380b&amp;v=4" width="40" height="40" alt="@tylt6688"></a>

</p>


  
<div data-body-version="d5064eb55e1c6f83cedf6d00b81b2f1ed9d5617e5dcce228083f87a09e734b7d" id="issuecomment-1203427428">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">I personally feel that the enterprise version can be made independently.</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-45b052b9-6651-4454-9a64-23aec61440a6" for="reactions--reaction_button_component-01f298" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, kaenova, wout, borisceranic, StanleyMasinde, RomainTHD, saulshanabrook, TheMaverickProgrammer, Risyandi, jeffersongandra, and 18 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-b262209e-f17f-4180-acb9-b0b9c50a02fe" for="reactions--reaction_button_component-a1fbdf" popover="manual" data-direction="n" data-type="description" data-view-component="true">RokeJulianLockhart, TarikViehmann, and ma99R reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-a4a2b480-f05a-4099-9030-3457c1c2823f" for="reactions--reaction_button_component-c8dbcf" popover="manual" data-direction="n" data-type="description" data-view-component="true">tylt6688, wfnian, and ma99R reacted with rocket emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5HuvZ9" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HuvZ9/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/jacamera/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/jacamera"><img src="https://avatars.githubusercontent.com/u/18013188?s=80&amp;u=c51a6a2fec30a7a26b998c757e289366a93f02cc&amp;v=4" width="40" height="40" alt="@jacamera"></a>

</p>


  
<div data-body-version="16a004dd6fd917fb7c0ec0f161d833772db0bf4dc759bbb2c18a72343cda88b2" id="issuecomment-1203435133">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">As a happy GitHub user I just hope all this recreational outrage doesn't result in GitHub allocating more time or resources than would otherwise be required to complete this change. Full speed ahead!</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-0f5ef109-8aeb-4acd-a061-26ef5c36e2fa" for="reactions--reaction_button_component-e1c4fd" popover="manual" data-direction="n" data-type="description" data-view-component="true">natario1, dszymon, binarydad, RokeJulianLockhart, and landsman reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-721f6e0f-8bcb-44d3-8d23-22d901b9b114" for="reactions--reaction_button_component-677584" popover="manual" data-direction="n" data-type="description" data-view-component="true">Thanaen, lopis, nothub, pankajthekush, Kl4rry, terrarier2111, TheMaverickProgrammer, SalomonSmeke, yannikbloscheck, bobaikato, and 79 more reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-ecaee89c-83f2-4e4e-a6ea-9134566a3221" for="reactions--reaction_button_component-3a1afa" popover="manual" data-direction="n" data-type="description" data-view-component="true">TeMPOraL, Serups, hckr, and UNINOIZE reacted with laugh emoji</tool-tip>
          <tool-tip id="tooltip-7d6df16a-4382-45e6-bd00-22a89f4a3ffa" for="reactions--reaction_button_component-978364" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, TeMPOraL, and ItsIgnacioPortal reacted with confused emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5HuyQK" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HuyQK/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/afkvido/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/afkvido"><img src="https://avatars.githubusercontent.com/u/69060894?s=80&amp;u=3535e3e6b09a2e616878557422eb78152a028fef&amp;v=4" width="40" height="40" alt="@afkvido"></a>

</p>


  
<div data-body-version="040ee3680903ca32b5f40831434f72fd5ee4c60053e67f61783e2e3013e8ceb6" id="issuecomment-1203446794">

        
<task-lists disabled="" sortable="">
<div>
          <blockquote>
<p dir="auto">As a happy GitHub user I just hope all this recreational outrage doesn't result in GitHub allocating more time or resources than would otherwise be required to complete this change. Full speed ahead!</p>
</blockquote>
<p dir="auto">I'd want GitHub to remove Microsoft, then continue full speed ahead</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-b7c5cb26-abed-4293-99f8-4400f0ff8586" for="reactions--reaction_button_component-bdde6c" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, dominikwilkowski, StanleyMasinde, asieverding, DanielVenturini, jonm58, Rikj000, sz55net, nonperforming, speller26, and 42 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-54bc1937-c9ca-48c9-a8bd-f93c1ae11d4d" for="reactions--reaction_button_component-26fa25" popover="manual" data-direction="n" data-type="description" data-view-component="true">evieluvsrainbows, whiztech, TreeBranches, nowaythisworks, Hunam6, dszymon, RokeJulianLockhart, and 0kku reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-876fb72b-94e9-4ba3-b448-c91181c3732a" for="reactions--reaction_button_component-44ca6f" popover="manual" data-direction="n" data-type="description" data-view-component="true">amytimed, afkvido, hukl, danielabrozzoni, rettichschnidi, chakravala, and UNINOIZE reacted with heart emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5HuzZe" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HuzZe/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/evieluvsrainbows/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/evieluvsrainbows"><img src="https://avatars.githubusercontent.com/u/1617100?s=80&amp;u=33c2d50eaefaf26c63cd236b8f739e9e7618e465&amp;v=4" width="40" height="40" alt="@evieluvsrainbows"></a>

</p>


  
<div data-body-version="081e2e31f5acd909e128adbaaf237292aa30344dd330cc3a631792b86ad4c935" id="issuecomment-1203451486">

        
<task-lists disabled="" sortable="">
<div>
          <blockquote>
<p dir="auto">This change is only on subdomains where GitHub markets products and services to enterprise customers, and all other GitHub subdomains will continue to operate as-is.</p>
</blockquote>
<p dir="auto">Why are people getting so riled up when this change <em>only</em> impacts the Enterprise marketing subdomains? Makes no sense to me how this of all things is getting negative attention. Majority of people don't use GitHub Enterprise, as its only for businesses, And they're just cookies. Use uBlock Origin as it says if you really can't stand a few cookies on subdomains you'll probably never end up going to.</p>
<p dir="auto">Also, people love pointing the finger at Microsoft, as if this change was demanded by them. It more than likely wasn't. There are always going to be changes that people don't like, but not all changes are influenced by the parent company. If Microsoft was puttng their hands all over GitHub, they probably would've moved GitHub to the Microsoft Policy Statement a long time ago.</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-61e2f369-045e-446c-834a-280b5bff188c" for="reactions--reaction_button_component-026737" popover="manual" data-direction="n" data-type="description" data-view-component="true">jacamera, theolivenbaum, whiztech, lumaxis, PatheticMustan, lunaisnotaboy, 5HT2, SaifAqqad, cesarfigueroa, aphedges, and 27 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-af8681ce-2426-47b7-885f-5790cd5a41db" for="reactions--reaction_button_component-4696b7" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, doamatto, c0b41, nothub, talesaraujo, yannikbloscheck, rodrigoruan-osf, pankajthekush, Brawl345, nonperforming, and 56 more reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-26ab5c7b-eaa4-448e-bb48-4fb2a48d4470" for="reactions--reaction_button_component-b06b31" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido and maroehsushe37 reacted with confused emoji</tool-tip>
          <tool-tip id="tooltip-4f78ec32-302f-4918-9591-2f096d92340f" for="reactions--reaction_button_component-793a06" popover="manual" data-direction="n" data-type="description" data-view-component="true">NochEinKamel, Rfc2026, and maroehsushe37 reacted with heart emoji</tool-tip>
          <tool-tip id="tooltip-d0637240-5ae7-4f07-869d-8b708839abbf" for="reactions--reaction_button_component-491057" popover="manual" data-direction="n" data-type="description" data-view-component="true">NochEinKamel, shaikshafiulla, and maroehsushe37 reacted with rocket emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5Huzy6" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5Huzy6/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/afkvido/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/afkvido"><img src="https://avatars.githubusercontent.com/u/69060894?s=80&amp;u=3535e3e6b09a2e616878557422eb78152a028fef&amp;v=4" width="40" height="40" alt="@afkvido"></a>

</p>


  
<div data-body-version="8b188db1c74deee351b03a2500817c59d1a4706a1998fd68e56bbf228ab401c0" id="issuecomment-1203453114">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">Cuz GitHub said they wouldnt use cookies<br>
daym its a borken promise</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-e9d2b685-c9ef-4a45-ae54-3ed762a4ffbb" for="reactions--reaction_button_component-1e90ad" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, dominikwilkowski, localcached, talesaraujo, naufik, rodrigoruan-osf, null2264, Rikj000, sz55net, jmeggitt, and 45 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-e59fecfb-9ac1-436a-84b0-6d751580c11f" for="reactions--reaction_button_component-e9c350" popover="manual" data-direction="n" data-type="description" data-view-component="true">evieluvsrainbows, TheMaverickProgrammer, nowaythisworks, lunaisnotaboy, NochEinKamel, dszymon, RokeJulianLockhart, and 0kku reacted with thumbs down emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5Hu1JO" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5Hu1JO/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/evieluvsrainbows/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/evieluvsrainbows"><img src="https://avatars.githubusercontent.com/u/1617100?s=80&amp;u=33c2d50eaefaf26c63cd236b8f739e9e7618e465&amp;v=4" width="40" height="40" alt="@evieluvsrainbows"></a>

</p>


  
<div data-body-version="8f4aa6b45a390aec52bb03dab5bf7df8e7d623e129df411e49d67f449d94b0ee" id="issuecomment-1203458638">

        
<task-lists disabled="" sortable="">
<div>
          <blockquote>
<p dir="auto">"We are also committing that going forward, we will only use cookies that are required for us to serve GitHub.com."</p>
<p dir="auto">Apparently in corporate terms, a "commitment" is now less than two calendar years of obligation. Good to know. Though, I guess I don't visit the marketing pages and hence, don't really care that much? Corporations being untrustworthy isn't new territory.</p>
<p dir="auto">Literally just "business advice": Your marketing teams should be weighing the value of the data here against the cost of "yet another breach of user trust and commitment", user trust, of course, being something extremely hard to earn back.</p>
</blockquote>
<p dir="auto">How exactly does this in any way impact user trust? It doesn't impact the main site, like the dashboard, the landing page, or <em>any</em> other part of GitHub like profiles, repositories, or organizations. It literally <em>only</em> impacts the enterprise marketing pages, and its for sales data tracking &amp; analytics. GitHub Enterprise is a very business-oriented product, so the only visitors to those pages will be by business leaders potentially interested in GitHub Enterprise, or users who land on that page by mistake.</p>
<p dir="auto">And I believe that is what GitHub meant when they said "to serve GitHub.com" - the main site (dashboard, repos, profiles, etc), not including stuff related to their Enterprise product, so I genuinely don't believe they broke their commitment. People are overreacting, as usual, to insignificant changes that don't really impact them.</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-612714b1-9596-49bd-becf-0eeacb730cf0" for="reactions--reaction_button_component-b4e532" popover="manual" data-direction="n" data-type="description" data-view-component="true">Marcisbee, PatheticMustan, 5HT2, SayakMukhopadhyay, wopian, nowaythisworks, SheepTester, gavinhenderson, mbmjertan, NeuronButter, and 8 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-aaa0bcf1-0212-4030-97d5-5d1bd154c668" for="reactions--reaction_button_component-64ceed" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, timvisee, unfunco, nothub, dallincrane, TheMaverickProgrammer, talesaraujo, yannikbloscheck, rodrigoruan-osf, jonm58, and 35 more reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-45b7c3a2-185e-4c74-9cc7-b5cf15187213" for="reactions--reaction_button_component-942684" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido reacted with confused emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5Hu1WO" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5Hu1WO/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/afkvido/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/afkvido"><img src="https://avatars.githubusercontent.com/u/69060894?s=80&amp;u=3535e3e6b09a2e616878557422eb78152a028fef&amp;v=4" width="40" height="40" alt="@afkvido"></a>

</p>


  
<div data-body-version="39b59fddd31362dfea8ea9d9036eacac1e5b3d5f5e768b6b6111e1d601d49e5f" id="issuecomment-1203459470">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">Thats fine but fuck microsoft for existing</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-e2d6fbc5-34a7-4f76-9c38-8660b2694461" for="reactions--reaction_button_component-e82bcc" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, dominikwilkowski, nothub, xv, musaubrian, ryuukk, CauaLW, Rikj000, SkyyWasTaken, tavofh98, and 7 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-caae534a-2b73-4f05-a1d1-0dab5d661117" for="reactions--reaction_button_component-d678a5" popover="manual" data-direction="n" data-type="description" data-view-component="true">evieluvsrainbows, jtraglia, Consolatis, whiztech, PatheticMustan, jcorkhill, 5HT2, TreeBranches, samuel-hunter, nowaythisworks, and 24 more reacted with thumbs down emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5Hu1pg" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5Hu1pg/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/afkvido/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/afkvido"><img src="https://avatars.githubusercontent.com/u/69060894?s=80&amp;u=3535e3e6b09a2e616878557422eb78152a028fef&amp;v=4" width="40" height="40" alt="@afkvido"></a>

</p>


  
<div data-body-version="6c1ea137d378e0d58654792c8900207b5f8320ab4864980e760802f2a4f88ce4" id="issuecomment-1203460704">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">There's a reason this PR has 128+ negative reactions 👎</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-3589bf48-d760-4bfa-b17c-224b684b915b" for="reactions--reaction_button_component-dbb0c0" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, dominikwilkowski, nothub, localcached, TheMaverickProgrammer, ryuukk, talesaraujo, CauaLW, Rikj000, speller26, and 16 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-816f39eb-f5fd-4e73-b801-a62f3239470a" for="reactions--reaction_button_component-a0bb30" popover="manual" data-direction="n" data-type="description" data-view-component="true">evieluvsrainbows, 5HT2, nowaythisworks, Colerar, Asjas, dszymon, RokeJulianLockhart, thyeggman, itpropro, and 0kku reacted with thumbs down emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5Hu1tH" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5Hu1tH/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/afkvido/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/afkvido"><img src="https://avatars.githubusercontent.com/u/69060894?s=80&amp;u=3535e3e6b09a2e616878557422eb78152a028fef&amp;v=4" width="40" height="40" alt="@afkvido"></a>

</p>


  
<div data-body-version="4996e815d00df5c22650da1d36016945492eec709d27440760fbd1b1dd71328a" id="issuecomment-1203460935">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">Also, they have, take a look at this PR.</p>
      </div>
</task-lists>


        
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5Hu4R0" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5Hu4R0/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/evieluvsrainbows/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/evieluvsrainbows"><img src="https://avatars.githubusercontent.com/u/1617100?s=80&amp;u=33c2d50eaefaf26c63cd236b8f739e9e7618e465&amp;v=4" width="40" height="40" alt="@evieluvsrainbows"></a>

</p>


  
<div data-body-version="4f53117b43efeb5099688f955777cfe53678525830ad6f0b5e2ccfb85ca91ec8" id="issuecomment-1203471476">

        
<task-lists disabled="" sortable="">
<div>
          <blockquote>
<p dir="auto"><a data-hovercard-type="user" data-hovercard-url="/users/afkvido/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/afkvido">@afkvido</a>: Also, they have, take a look at this PR.</p>
</blockquote>
<p dir="auto">This was more than likely not Microsoft's doing. Not everything a subsidiary of Microsoft does is because of Microsoft itself. You have the vast majority of comments on this PR (at 8 comments), and your opinion isn't be all end all. Most of the negative reactions are additionally probably from people who don't understand the scope of what GitHub said back when they committed to not use cookies not necessary to serve GitHub itself - they probably didn't extend it to the Enterprise marketing pages to begin with and always meant the main site that serves repositories and profiles and such.</p>
<p dir="auto">There are things worse than cookies by the way, like actual trackers embedded in web pages. Cookies are relatively harmless if used sparingly and for very specific purposes like tracking sales analytics or for keeping a user logged into their web browsers, or in a specific GitHub use case, tracking the current site theme. There is nothing wrong with stuff like this.</p>
<p dir="auto">You seem awfully mad at Microsoft for some reason, as if they stole your pet dog or something. This isn't 2000s &amp; early 2010s-era Microsoft, Microsoft is nowhere near as bad as they were when Steve Ballmer was the CEO of Microsoft. Ever since Satya became CEO, I have noticed a significant improvement in Microsoft's business culture and strategy. MS was way, way, <em>way</em> worse back when Ballmer was CEO.</p>
<p dir="auto">(also, slight question, why upvote your own comments?)</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-2d23be74-6be4-40f4-beed-91cb3f3c43ff" for="reactions--reaction_button_component-78b172" popover="manual" data-direction="n" data-type="description" data-view-component="true">theolivenbaum, gldraphael, GoldenretriverYT, StuSerious, PatheticMustan, lunaisnotaboy, SayakMukhopadhyay, wopian, nowaythisworks, itslychee, and 11 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-ae1803a1-c51a-4319-ab31-867b909cf300" for="reactions--reaction_button_component-52bebe" popover="manual" data-direction="n" data-type="description" data-view-component="true">afkvido, Zethson, nothub, rkujawa, ulfox, TheMaverickProgrammer, talesaraujo, yannikbloscheck, rootwork, parkuristt, and 25 more reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-345238c6-f986-4c66-bc13-464ce73dcb7e" for="reactions--reaction_button_component-995e97" popover="manual" data-direction="n" data-type="description" data-view-component="true">gresm reacted with confused emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5Hu8cj" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5Hu8cj/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/afkvido/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/afkvido"><img src="https://avatars.githubusercontent.com/u/69060894?s=80&amp;u=3535e3e6b09a2e616878557422eb78152a028fef&amp;v=4" width="40" height="40" alt="@afkvido"></a>

</p>


  
<div data-body-version="ab6a4a255e35a4e0197cfaad46947f29e28a21cf30fefe01d9aedda42be31003" id="issuecomment-1203488547">

        
<task-lists disabled="" sortable="">
<div>
          <blockquote>
<p dir="auto">This was more than likely not Microsoft's doing. Not everything a subsidiary of Microsoft does is because of Microsoft itself.</p>
</blockquote>
<p dir="auto">I don't know why anyone at GitHub would do this change, and Microsoft is the only other entity with the authority to make such a change.</p>
<br>
<blockquote>
<p dir="auto">You have the vast majority of comments on this PR (at 8 comments), and your opinion isn't be all end all.</p>
</blockquote>
<p dir="auto">I just poke in whenever this comes up on my GitHub notifications.</p>
<br>
<blockquote>
<p dir="auto">Most of the negative reactions are additionally probably from people who don't understand the scope of what GitHub said back when they committed to not use cookies not necessary to serve GitHub itself - they probably didn't extend it to the Enterprise marketing pages to begin with and always meant the main site that serves repositories and profiles and such.</p>
</blockquote>
<p dir="auto">That is a good point, however, that doesn't change the fact that GitHub is no longer the white and fluffy angel that it was.</p>
<br>
<blockquote>
<p dir="auto">There are things worse than cookies by the way, like actual trackers embedded in web pages. Cookies are relatively harmless if used sparingly and for very specific purposes like tracking sales analytics or for keeping a user logged into their web browsers, or in a specific GitHub use case, tracking the current site theme. There is nothing wrong with stuff like this.</p>
</blockquote>
<p dir="auto">While you seem quite intelligent, I don't think that you understand that cookies could actually be used as slight trackers, and if used to their fullest potential, complete on-site tracking for AI/ML based targeted recommendations for profit.</p>
<br>
<blockquote>
<p dir="auto">You seem awfully mad at Microsoft for some reason, as if they stole your pet dog or something. This isn't 2000s &amp; early 2010s-era Microsoft, Microsoft is nowhere near as bad as they were when Steve Ballmer was the CEO of Microsoft. Ever since Satya became CEO, I have noticed a significant improvement in Microsoft's business culture and strategy. MS was way, way, way worse back when Ballmer was CEO.</p>
</blockquote>
<p dir="auto">Microsoft is still a mega-corp. They're still 'evil', just like Google or Apple. I also don't see much of a difference with the two CEOs. One was making more money, one was discussing ethics more often, but in the end, Microsoft is still somewhat invasive. To add on, Microsoft decided to absolutely <strong>RUIN</strong> Minecraft, a game that I don't really play these days, but my friends play a lot.</p>
<br>
<blockquote>
<p dir="auto">(also, slight question, why upvote your own comments?)</p>
</blockquote>
<p dir="auto">(also, slight question, why downvote my comments?)</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-cdd6bcda-f2aa-4283-8354-cda69dd96cf4" for="reactions--reaction_button_component-297b63" popover="manual" data-direction="n" data-type="description" data-view-component="true">talesaraujo, leoheck, afkvido, mitchellzehr, duck-nukem, zendynar, cryptoAlgorithm, oneEyedCharlie, Eireen, and UNINOIZE reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-e44d10ba-c72c-41ec-bd93-b299b3aae9e9" for="reactions--reaction_button_component-b24f54" popover="manual" data-direction="n" data-type="description" data-view-component="true">nowaythisworks, Rexogamer, Mijyuoon, lunaisnotaboy, thatlittleboy, encode42, dszymon, qfr68414, TeknikalDomain, seve, and 6 more reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-c56fbfe5-07f6-4d0d-90f3-ee8d60900816" for="reactions--reaction_button_component-c7eba3" popover="manual" data-direction="n" data-type="description" data-view-component="true">EnduringBeta, samuel-hunter, and robahub reacted with confused emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5HvBVx" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HvBVx/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/zzo38/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/zzo38"><img src="https://avatars.githubusercontent.com/u/108554049?s=80&amp;v=4" width="40" height="40" alt="@zzo38"></a>

</p>


  
<div data-body-version="9afa00a3fa928b251a312f70321003fa6f7776977cbecf46671e14e4985640f9" id="issuecomment-1203508593">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">I think that the cookies ought to be documented, so that you know which cookie means what.</p>
<p dir="auto">I also think that they should avoid using confusing privacy policies; the mention of DNT should either be kept as is if GitHub uses the DNT header to reduce tracking, or deleted entirely if GitHub does not use the DNT header. If it does so only in some cases, it should mention what cases these are. The privacy policy made sense before the change in the section about DNT, although the change mentioned above makes it confusing (as other comments already mention).</p>
<p dir="auto">Mentioning other programs such as Privacy Badger and uBlock Origin are OK, although it might be worth to add a disclaimer if GitHub is not affiliated with such programs, even if they are hosted on GitHub. (Since GitHub is used for many FOSS projects, it is likely that some of them will be.)</p>
<p dir="auto">I have no problem with adding these non-essential cookies to the enterprise marketing pages, as long as the rest of GitHub can be used without it and it is documented which pages these are (and if the cookie domain is the same, also which cookies). Moving the enterprise marketing pages to a separate domain seems to me to be a good idea though, in order to be clearly distinguished (although a subdomain is probably good enough, in my opinion; as long as it is documented clearly which subdomains these are).</p>
<p dir="auto">About alternatives to GitHub, I would not recommend GitLab because it will not display the files if JavaScripts are not enabled. However, it is acceptable to use GitLab if there are mirrors on multiple services. GitHub, Codeberg, and NotABug, and some others, also use JavaScripts, although the files can be displayed even if JavaScripts are disabled (even though there is a note that says enable JavaScripts, it is not required to simply view files), so it is acceptable. Another alternative is Sourcehut, which also doesn't need JavaScripts (and says that all features work without JavaScripts, although it still has some).</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-1bcd9d13-c195-49af-95f5-ee59a035d645" for="reactions--reaction_button_component-ffa32b" popover="manual" data-direction="n" data-type="description" data-view-component="true">Consolatis, evieluvsrainbows, terrarier2111, bdemirel, Mijyuoon, boomboompower, real-yfprojects, amytimed, bdougherty, techyCoder81, and 16 more reacted with thumbs up emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5HvGRU" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HvGRU/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/afkvido/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/afkvido"><img src="https://avatars.githubusercontent.com/u/69060894?s=80&amp;u=3535e3e6b09a2e616878557422eb78152a028fef&amp;v=4" width="40" height="40" alt="@afkvido"></a>

</p>


  
<div data-body-version="a935c1249808b2a1d2d0956f021d70cf59988fd96299e777f417421f89a254cd" id="issuecomment-1203528788">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">I don't mind GitLab, except that I have to pause for 15 minutes to finish laughing every time i see "Merge Requests"</p>
      </div>
</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-62b80856-9ecb-4e0e-98b6-78cf564c99bf" for="reactions--reaction_button_component-b7e712" popover="manual" data-direction="n" data-type="description" data-view-component="true">oatovar, nowaythisworks, Colerar, amytimed, lunaisnotaboy, bsedin, wheresalice, googleson78, ifarbod, leftshift, and 8 more reacted with thumbs down emoji</tool-tip>
          <tool-tip id="tooltip-30f4dfa9-3d1d-412b-b0c4-576f15624564" for="reactions--reaction_button_component-3fe408" popover="manual" data-direction="n" data-type="description" data-view-component="true">real-yfprojects, afkvido, mytja, Rwarcards762, fuomag9, and renancaraujo reacted with laugh emoji</tool-tip>
          <tool-tip id="tooltip-a7f882c9-29dd-42a1-8e1e-41ec74f82ea1" for="reactions--reaction_button_component-599a78" popover="manual" data-direction="n" data-type="description" data-view-component="true">RokeJulianLockhart reacted with confused emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>


      <div data-gid="IC_kwDOBZWBkc5HvIwp" data-url="/github/site-policy/comments/IC_kwDOBZWBkc5HvIwp/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/sammcj/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/sammcj"><img src="https://avatars.githubusercontent.com/u/862951?s=80&amp;u=cfd1c4a95ff2d92c1201a95c68b52dd353b8cc10&amp;v=4" width="40" height="40" alt="@sammcj"></a>

</p>


  
<div data-body-version="d7f77e883304ee58f38e8eb0ca258e6f5155ad828d64a2d36d9acf3f383ce8eb" id="issuecomment-1203538985">

        
<task-lists disabled="" sortable="">

</task-lists>


        <div data-view-component="true">
  <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="/github/site-policy/reactions" accept-charset="UTF-8" method="post">
    
      
    <div>
          <tool-tip id="tooltip-b4f8e713-c1c2-46e0-9e29-2335fb6cd824" for="reactions--reaction_button_component-68ab9a" popover="manual" data-direction="n" data-type="description" data-view-component="true">talgat-ruby, nothub, freearhey, talesaraujo, null2264, Rikj000, speller26, amytimed, theRealProHacker, guarilha, and 35 more reacted with thumbs up emoji</tool-tip>
          <tool-tip id="tooltip-6da40911-94e2-4bf5-8dbc-50a7fd735ac3" for="reactions--reaction_button_component-891f58" popover="manual" data-direction="n" data-type="description" data-view-component="true">evieluvsrainbows and itpropro reacted with thumbs down emoji</tool-tip>
      
    </div>
</form></div>
      </div>

</div>



  

        <div id="pullrequestreview-2519558596" data-gid="PRR_kwDOBZWBkc6WLWnE" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0X3JldmlldzoyNTE5NTU4NTk2IiwidCI6MTc1NDQxMTQwNH0=--d65355594272c2033f588aa9c77698a61fdfbd1215431ab2c0f55ad49c24e83c" data-url="/github/site-policy/pull/582/partials/reviews/2519558596">
      <div data-view-component="true">
  <p><a href="https://github.com/bulosandaina05" data-view-component="true"><img data-hovercard-type="user" data-hovercard-url="/users/bulosandaina05/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" src="https://avatars.githubusercontent.com/u/192487906?s=60&amp;v=4" alt="bulosandaina05" size="40" height="40" width="40" data-view-component="true"></a></p>
  
</div>
          <div id="pullrequestreview-2519558596" data-view-component="true">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">1</p>
  </task-lists>
  
</div>
        </div>

        <div id="pullrequestreview-2527188942" data-gid="PRR_kwDOBZWBkc6WodfO" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0X3JldmlldzoyNTI3MTg4OTQyIiwidCI6MTc1NDQxMTQwNH0=--9128f11650a436a1c426933aacea5fb23e7cf0f04f3e10218738a9da11751224" data-url="/github/site-policy/pull/582/partials/reviews/2527188942">
      <div data-view-component="true">
  <p><a href="https://github.com/Jwhite6381" data-view-component="true"><img data-hovercard-type="user" data-hovercard-url="/users/Jwhite6381/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" src="https://avatars.githubusercontent.com/u/188800562?s=60&amp;v=4" alt="Jwhite6381" size="40" height="40" width="40" data-view-component="true"></a></p>
  
</div>
          <div id="pullrequestreview-2527188942" data-view-component="true">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">Johnny</p>
  </task-lists>
  
</div>
        </div>

        <div id="pullrequestreview-2562557654" data-gid="PRR_kwDOBZWBkc6YvYbW" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0X3JldmlldzoyNTYyNTU3NjU0IiwidCI6MTc1NDQxMTQwNH0=--e122c3063e4ec1da3617aee9b90660a22f6fe9f4acf9c6ef44258c9d761d087d" data-url="/github/site-policy/pull/582/partials/reviews/2562557654">
      <div data-view-component="true">
  <p><a href="https://github.com/Cryptopuy" data-view-component="true"><img data-hovercard-type="user" data-hovercard-url="/users/Cryptopuy/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" src="https://avatars.githubusercontent.com/u/157313185?s=60&amp;v=4" alt="Cryptopuy" size="40" height="40" width="40" data-view-component="true"></a></p>
  
</div>
          <div id="pullrequestreview-2562557654" data-view-component="true">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">635491</p>
  </task-lists>
  
</div>
        </div>

        <div data-gid="IC_kwDOBZWBkc6bIG4_" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6bIG4_/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/Cryptopuy/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/Cryptopuy"><img src="https://avatars.githubusercontent.com/u/157313185?s=80&amp;u=a831afd4c50dbfd5dca88d86bc4f8c9472f2cf67&amp;v=4" width="40" height="40" alt="@Cryptopuy"></a>

</p>


  


</div>


        <div data-gid="IC_kwDOBZWBkc6bIHiE" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6bIHiE/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/Cryptopuy/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/Cryptopuy"><img src="https://avatars.githubusercontent.com/u/157313185?s=80&amp;u=a831afd4c50dbfd5dca88d86bc4f8c9472f2cf67&amp;v=4" width="40" height="40" alt="@Cryptopuy"></a>

</p>


  


</div>


        <div data-gid="IC_kwDOBZWBkc6bd7cn" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6bd7cn/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/nooroayas/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/nooroayas"><img src="https://avatars.githubusercontent.com/u/186098007?s=80&amp;v=4" width="40" height="40" alt="@nooroayas"></a>

</p>


  


</div>


        <div data-gid="IC_kwDOBZWBkc6bd77Z" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6bd77Z/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/nooroayas/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/nooroayas"><img src="https://avatars.githubusercontent.com/u/186098007?s=80&amp;v=4" width="40" height="40" alt="@nooroayas"></a>

</p>


  
<div data-body-version="20b8551b2790cc4e124f16ca90b6fbcf6741d076b42c8a0248ca1bab9de8794f" id="issuecomment-2608316121">

        
<task-lists disabled="" sortable="">
<div>
          <ul dir="auto">
<li>[ ]</li>
</ul>
      </div>
</task-lists>


        
      </div>

</div>


        <div data-gid="IC_kwDOBZWBkc6bd8BE" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6bd8BE/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/nooroayas/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/nooroayas"><img src="https://avatars.githubusercontent.com/u/186098007?s=80&amp;v=4" width="40" height="40" alt="@nooroayas"></a>

</p>


  


</div>


        <div data-gid="IC_kwDOBZWBkc6bqIJ7" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6bqIJ7/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/SoeAung95/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/SoeAung95"><img src="https://avatars.githubusercontent.com/u/158731633?s=80&amp;u=0d29c18b7762beb62a362c0583e4ef6326ddeb8f&amp;v=4" width="40" height="40" alt="@SoeAung95"></a>

</p>


  
<div data-body-version="e0bccf05ca8f173055686a399d89595bb10e4679332e237a88135c0ac78cc151" id="issuecomment-2611511931">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto">git checkout main  # main branch<br>
git pull origin main  # latest changes update</p>
      </div>
</task-lists>


        
      </div>

</div>


        <div data-gid="IC_kwDOBZWBkc6eg5Xj" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6eg5Xj/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/OpgKwa/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/OpgKwa"><img src="https://avatars.githubusercontent.com/u/199000369?s=80&amp;v=4" width="40" height="40" alt="@OpgKwa"></a>

</p>


  


</div>


        <div data-gid="IC_kwDOBZWBkc6fwnqC" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6fwnqC/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/Poeta1986/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/Poeta1986"><img src="https://avatars.githubusercontent.com/u/120993535?s=80&amp;v=4" width="40" height="40" alt="@Poeta1986"></a>

</p>


  
<div data-body-version="8899189a9376967a9d151b266ebf6bddd1263f42d0617434eaca1cd421a7ffb5" id="issuecomment-2680322690">

        
<task-lists disabled="" sortable="">
<div>
          <blockquote>
<p dir="auto">GitHub is introducing non-essential cookies on web pages that market our products to businesses. These cookies will provide analytics to improve the site experience and personalize content and ads for enterprise users. This change is only on subdomains, like <a href="http://resources.github.com/">resources.github.com</a>, where GitHub markets products and services to enterprise customers.  <a href="https://github.com/">Github.com</a> will continue to operate as-is.</p>
<p dir="auto">This change updates the Privacy Statement based on this new activity.</p>
<p dir="auto">These updates will go into effect after the 30-day notice and comment period, on September 1, 2022.</p>
<p dir="auto">See <a href="https://github.com/github/site-policy/pull/582#issuecomment-1234458256" data-hovercard-type="pull_request" data-hovercard-url="/github/site-policy/pull/582/hovercard">comment below</a> with clarifications and changes made at the end of the comment period.<br>
<a href="https://github.com/github/site-policy/pull/582#issuecomment-1234458256" data-hovercard-type="pull_request" data-hovercard-url="/github/site-policy/pull/582/hovercard">Comment on #582 Privacy Statement Updates September 2022</a><br>
We want to thank everyone for their review and feedback on the Privacy Statement Update. We appreciate and share your passion for developer privacy. GitHub remains committed to having the highest privacy standards and will continue to center the needs of developers in all of our platform decisions. We intend for this to be a minimally invasive change that will enable us to provide the best tools to our users. In response to your comments, we are providing the following changes and points of clarification:<br>
DNT and self-help browser extensions<br>
Commenters raised questions about our language on DNT and self-help browser extensions. We've pushed a <a href="https://github.com/github/site-policy/pull/582/commits/4a61c4e2be67c12a1cc200ef3e804db400ce1426">commit</a> that:<br>
• Folds the existing DNT and browser extension information into a new section on disabling non-essential cookies.<br>
• Specifies there will be a user setting to disable non-essential cookies and provides additional details to clarify which cookies will be used and for what reasons.<br>
• Specifies that DNT will be honored on GitHub, and that if a DNT signal is sent, GitHub will not load third party resources which set non-essential cookies, so that we do not have to rely on third parties honoring DNT.<br>
• Browsers' built-in tracking protection has advanced significantly in recent years, so we've noted that configuring that built-in protection may block non-essential cookies.<br>
• Separated mentions of browser extensions designed to block tracking, and extensions designed to block unwanted content with the effect of blocking tracking, for clarity, though using either alone or in combination may block non-essential cookies.<br>
• Changed links with additional information on DNT and browser extensions to point to their respective Wikipedia articles for neutrality, currency, and to clarify that these are not GitHub products (though of course we're proud that many privacy protection tools are developed on GitHub).<br>
Finally, some have asked why we’re explaining technical self-help tools. GitHub has a very broad user base, including new developers – and we want everyone to be informed about the scope of their options, including technical options.<br>
Enterprise user experience<br>
Commenters asked for clarification about how this change will impact the enterprise user experience. We are introducing cookies on GitHub’s Enterprise Marketing Pages (e.g. <a href="http://resources.github.com/">resources.github.com</a>), not on Enterprise user accounts. We intend for this change to make it easier for our Marketing team to better understand the needs of users who are visiting Enterprise Marketing Pages and connect them with the solutions that will benefit them most.<br>
Users who visit these pages will have the option to express their cookies preferences by navigating to the link in the footer of the page.<br>
Stylistic change<br>
Commenters have asked why ‘Personal Data’ was changed to ‘personal data’ in the Privacy Statement update. We made personal data lowercase because it is not a defined term in our Terms of Service, for consistency with “All capitalized terms have their definition in <a href="https://docs.github.com/en/github/site-policy/github-terms-of-service">GitHub’s Terms of Service</a>, unless otherwise noted here.” The stylistic change does not impact its definition.</p>
</blockquote>
      </div>
</task-lists>


        
      </div>

</div>


        <div data-gid="IC_kwDOBZWBkc6gf7oi" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6gf7oi/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/Elnandya396/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/Elnandya396"><img src="https://avatars.githubusercontent.com/u/194666275?s=80&amp;v=4" width="40" height="40" alt="@Elnandya396"></a>

</p>


  
<div data-body-version="5b2aeb0f5afd83253c3ac15078d07a761ae25ce1f2b94b3dd035533eeb255656" id="issuecomment-2692725282">

        
<task-lists disabled="" sortable="">
<div>
          <blockquote>
<p dir="auto">GitHub is introducing non-essential cookies on web pages that market our products to businesses. These cookies will provide analytics to improve the site experience and personalize content and ads for enterprise users. This change is only on subdomains, like <a href="http://resources.github.com/">resources.github.com</a>, where GitHub markets products and services to enterprise customers. <a href="https://github.com/">Github.com</a> will continue to operate as-is.</p>
<p dir="auto">This change updates the Privacy Statement based on this new activity.</p>
<p dir="auto">These updates will go into effect after the 30-day notice and comment period, on September 1, 2022.</p>
<p dir="auto">See <a href="https://github.com/github/site-policy/pull/582#issuecomment-1234458256" data-hovercard-type="pull_request" data-hovercard-url="/github/site-policy/pull/582/hovercard">comment below</a> with clarifications and changes made at the end of the comment period. <a href="https://github.com/github/site-policy/pull/582#issuecomment-1234458256" data-hovercard-type="pull_request" data-hovercard-url="/github/site-policy/pull/582/hovercard">Comment on #582 Privacy Statement Updates September 2022</a> We want to thank everyone for their review and feedback on the Privacy Statement Update. We appreciate and share your passion for developer privacy. GitHub remains committed to having the highest privacy standards and will continue to center the needs of developers in all of our platform decisions. We intend for this to be a minimally invasive change that will enable us to provide the best tools to our users. In response to your comments, we are providing the following changes and points of clarification: DNT and self-help browser extensions Commenters raised questions about our language on DNT and self-help browser extensions. We've pushed a <a href="https://github.com/github/site-policy/pull/582/commits/4a61c4e2be67c12a1cc200ef3e804db400ce1426">commit</a> that: • Folds the existing DNT and browser extension information into a new section on disabling non-essential cookies. • Specifies there will be a user setting to disable non-essential cookies and provides additional details to clarify which cookies will be used and for what reasons. • Specifies that DNT will be honored on GitHub, and that if a DNT signal is sent, GitHub will not load third party resources which set non-essential cookies, so that we do not have to rely on third parties honoring DNT. • Browsers' built-in tracking protection has advanced significantly in recent years, so we've noted that configuring that built-in protection may block non-essential cookies. • Separated mentions of browser extensions designed to block tracking, and extensions designed to block unwanted content with the effect of blocking tracking, for clarity, though using either alone or in combination may block non-essential cookies. • Changed links with additional information on DNT and browser extensions to point to their respective Wikipedia articles for neutrality, currency, and to clarify that these are not GitHub products (though of course we're proud that many privacy protection tools are developed on GitHub). Finally, some have asked why we’re explaining technical self-help tools. GitHub has a very broad user base, including new developers – and we want everyone to be informed about the scope of their options, including technical options. Enterprise user experience Commenters asked for clarification about how this change will impact the enterprise user experience. We are introducing cookies on GitHub’s Enterprise Marketing Pages (e.g. <a href="http://resources.github.com/">resources.github.com</a>), not on Enterprise user accounts. We intend for this change to make it easier for our Marketing team to better understand the needs of users who are visiting Enterprise Marketing Pages and connect them with the solutions that will benefit them most. Users who visit these pages will have the option to express their cookies preferences by navigating to the link in the footer of the page. Stylistic change Commenters have asked why ‘Personal Data’ was changed to ‘personal data’ in the Privacy Statement update. We made personal data lowercase because it is not a defined term in our Terms of Service, for consistency with “All capitalized terms have their definition in <a href="https://docs.github.com/en/github/site-policy/github-terms-of-service">GitHub’s Terms of Service</a>, unless otherwise noted here.” The stylistic change does not impact its definition.</p>
</blockquote>
      </div>
</task-lists>


        
      </div>

</div>


        <div data-gid="IC_kwDOBZWBkc6jsR35" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6jsR35/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/jawid66/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/jawid66"><img src="https://avatars.githubusercontent.com/u/204546664?s=80&amp;v=4" width="40" height="40" alt="@jawid66"></a>

</p>


  


</div>


        <div data-view-component="true" id="pullrequestreview-2738227083" data-gid="PRR_kwDOBZWBkc6jNgeL" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0X3JldmlldzoyNzM4MjI3MDgzIiwidCI6MTc1NDQxMTQwNH0=--122c9a5a5d75a36800d241d7e173d7dac95418b7c7f4283fd1e1322fc34fe75a" data-url="/github/site-policy/pull/582/partials/reviews/2738227083">
  <p><a href="https://github.com/sheikhaftab005" data-view-component="true"><img data-hovercard-type="user" data-hovercard-url="/users/sheikhaftab005/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" src="https://avatars.githubusercontent.com/u/193155404?s=60&amp;v=4" alt="sheikhaftab005" size="40" height="40" width="40" data-view-component="true"></a></p>
  
</div>

        

        <div data-gid="IC_kwDOBZWBkc6lxxzT" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6lxxzT/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/venpisey/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/venpisey"><img src="https://avatars.githubusercontent.com/u/193808321?s=80&amp;v=4" width="40" height="40" alt="@venpisey"></a>

</p>


  


</div>


        <div id="pullrequestreview-2748846235" data-gid="PRR_kwDOBZWBkc6j2BCb" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0X3JldmlldzoyNzQ4ODQ2MjM1IiwidCI6MTc1NDQxMTQwNH0=--5e213ef66a6b4f3099652cc923702635394430c063fc1e8756e38fe51a900fa5" data-url="/github/site-policy/pull/582/partials/reviews/2748846235">
      <div data-view-component="true">
  <p><a href="https://github.com/rizinator007" data-view-component="true"><img data-hovercard-type="user" data-hovercard-url="/users/rizinator007/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" src="https://avatars.githubusercontent.com/u/204532432?s=60&amp;v=4" alt="rizinator007" size="40" height="40" width="40" data-view-component="true"></a></p>
  
</div>
          <div id="pullrequestreview-2748846235" data-view-component="true">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    <p dir="auto">Bentley</p>
  </task-lists>
  
</div>
        </div>

        <div data-gid="IC_kwDOBZWBkc6nhm2p" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6nhm2p/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/kizooj/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/kizooj"><img src="https://avatars.githubusercontent.com/u/192160475?s=80&amp;v=4" width="40" height="40" alt="@kizooj"></a>

</p>


  


</div>


        

        <div data-gid="IC_kwDOBZWBkc6rjyk-" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6rjyk-/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/ULTRAPAOTHAiLAND31110/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/ULTRAPAOTHAiLAND31110"><img src="https://avatars.githubusercontent.com/u/203488967?s=80&amp;u=de668eb4d0bba0b0ea28cfd6718ef7f487f8ae66&amp;v=4" width="40" height="40" alt="@ULTRAPAOTHAiLAND31110"></a>

</p>


  


</div>


        

        <div data-gid="IC_kwDOBZWBkc6wwwKc" data-url="/github/site-policy/comments/IC_kwDOBZWBkc6wwwKc/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/commanderrobot14/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/commanderrobot14"><img src="https://avatars.githubusercontent.com/u/213124953?s=80&amp;v=4" width="40" height="40" alt="@commanderrobot14"></a>

</p>


  


</div>


        

        <div id="pullrequestreview-2977039092" data-gid="PRR_kwDOBZWBkc6xcgL0" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0X3JldmlldzoyOTc3MDM5MDkyIiwidCI6MTc1NDQxMTQwNH0=--0ed25141472de2d285170172cfe8865dfd303d2bedfa8a4ee3c77daf64527856" data-url="/github/site-policy/pull/582/partials/reviews/2977039092">
      <div data-view-component="true">
  <p><a href="https://github.com/mommommo19" data-view-component="true"><img data-hovercard-type="user" data-hovercard-url="/users/mommommo19/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" src="https://avatars.githubusercontent.com/u/154574240?s=60&amp;v=4" alt="mommommo19" size="40" height="40" width="40" data-view-component="true"></a></p>
  
</div>

      <div data-view-component="true">            <turbo-frame id="review-thread-or-comment-id-1400955267" target="_top">
  <details-collapsible>
    <details-toggle>
    <details open="open" data-resolved="false" data-target="details-collapsible.detailsElement details-toggle.detailsTarget" data-view-component="true">
      <summary role="button" data-target="details-collapsible.summaryElement details-toggle.summaryTarget" data-action="click:details-collapsible#toggle click:details-toggle#toggle" data-aria-label-closed="Expand comment" data-aria-label-open="Collapse comment" aria-expanded="true" aria-label="Collapse comment" data-view-component="true">        
</summary>
      <div id="discussion_r2178585524" data-quote-markdown=".js-comment-body" data-view-component="true">
  <div data-view-component="true">
  
    <h3>Choose a reason for hiding this comment</h3>

    <p>
      The reason will be displayed to describe this comment to others. <a href="https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment" aria-label="Learn more about hiding disruptive comments">Learn more</a>.
    </p>

    <!-- '"` --><!-- </textarea></xmp> -->

  
</div>

  <task-lists disabled="" sortable="">
    
  </task-lists>
  

</div>
</details></details-toggle>
  </details-collapsible>
</turbo-frame>




</div>  </div>

        

        <div id="pullrequestreview-2989683176" data-gid="PRR_kwDOBZWBkc6yMvHo" data-channel="eyJjIjoicHVsbF9yZXF1ZXN0X3JldmlldzoyOTg5NjgzMTc2IiwidCI6MTc1NDQxMTQwNH0=--5f8269c569eab5a8f01b4fb3730a11f41dc4240dbb433a69b3e9bb745cf407d1" data-url="/github/site-policy/pull/582/partials/reviews/2989683176">
      <div data-view-component="true">
  <p><a href="https://github.com/Escarcega1989" data-view-component="true"><img data-hovercard-type="user" data-hovercard-url="/users/Escarcega1989/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" src="https://avatars.githubusercontent.com/u/216053993?s=60&amp;v=4" alt="Escarcega1989" size="40" height="40" width="40" data-view-component="true"></a></p>
  
</div>

      <div data-view-component="true">            <turbo-frame id="review-thread-or-comment-id-1406652583" target="_top">
  <details-collapsible>
    <details-toggle>
    <details open="open" data-resolved="false" data-target="details-collapsible.detailsElement details-toggle.detailsTarget" data-view-component="true">
      <summary role="button" data-target="details-collapsible.summaryElement details-toggle.summaryTarget" data-action="click:details-collapsible#toggle click:details-toggle#toggle" data-aria-label-closed="Expand comment" data-aria-label-open="Collapse comment" aria-expanded="true" aria-label="Collapse comment" data-view-component="true">        
</summary>
      <div data-view-component="true">          
  <div>
    
    <table data-tab-size="8" data-paste-markdown-skip="">
          <tbody><tr data-position="0">
            <td data-line-number="..."></td>
            <td data-line-number="..."></td>
            <td colspan="2">@@ -33,13 +34,13 @@ To see our Privacy Notice to residents of California, please go to [GitHub's Not</td>
          </tr>
          <tr>

              <td data-line-number="33"></td>

              <td data-line-number="34"></td>

            <td>
              <span><br></span>

            </td>
          </tr>
          <tr>

              <td data-line-number="34"></td>

              <td data-line-number="35"></td>

            <td>
              <span><span>|</span> Section <span>|</span> What can you find there? <span>|</span></span>

            </td>
          </tr>
          <tr>

              <td data-line-number="35"></td>

              <td data-line-number="36"></td>

            <td>
              <span><span>|</span>---<span>|</span>---<span>|</span></span>

            </td>
          </tr>
          <tr>

              <td data-line-number="36"></td>

              <td></td>

            <td>
              <span><span>|</span> <span>[</span>Who is responsible for the processing of your information<span>]</span><span>(</span><span>#who-is-responsible-for-the-processing-of-your-information</span><span>)</span> <span>|</span> Subject to limited exceptions, GitHub is the controller and entity responsible for the processing of your Personal Data in connection with the Website or Service. <span>|</span></span>

            </td>
          </tr>
          <tr>

              <td data-line-number="37"></td>

              <td></td>

            <td>
              <span><span>|</span> <span>[</span>What information GitHub collects<span>]</span><span>(</span><span>#what-information-github-collects</span><span>)</span> <span>|</span> GitHub collects information directly from you for your registration, payment, transactions, and user profile. We also automatically collect from you your usage information, cookies, and device information, subject, where necessary, to your consent. GitHub may also collect Personal Data from third parties. We only collect the minimum amount of Personal Data necessary from you, unless you choose to provide more.<span>|</span></span>

            </td>
          </tr>
          <tr>

              <td></td>

              <td data-line-number="37"></td>

            <td>
              <span><span>|</span> <span>[</span>Who is responsible for the processing of your information<span>]</span><span>(</span><span>#who-is-responsible-for-the-processing-of-your-information</span><span>)</span> <span>|</span> Subject to limited exceptions, GitHub is the controller and entity responsible for the processing of your personal data in connection with the Website or Service if you are in North America. For individuals outside North America the data controller is GitHub B.V. <span>|</span></span>

            </td>
          </tr>
    </tbody></table>

</div>


<div id="discussion_r2187007903" data-quote-markdown=".js-comment-body">
            <details data-body-version="95b1e6e4340d1d6aa818fc10e2f95a7bdc362c0269ac541bbffb2e8d6c875ea3">
    <summary>
      <div>
        <h3>
              This comment was marked as outdated.

        </h3>
          
      </div>
    </summary>

    
  </details>


</div>

</div>
</details></details-toggle>
  </details-collapsible>
</turbo-frame>




</div>  </div>

        <div data-gid="IC_kwDOBZWBkc66Q-WW" data-url="/github/site-policy/comments/IC_kwDOBZWBkc66Q-WW/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/flcon12/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/flcon12"><img src="https://avatars.githubusercontent.com/u/223188888?s=80&amp;v=4" width="40" height="40" alt="@flcon12"></a>

</p>


  


</div>


        <div data-gid="IC_kwDOBZWBkc67e414" data-url="/github/site-policy/comments/IC_kwDOBZWBkc67e414/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/LuckyD14/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/LuckyD14"><img src="https://avatars.githubusercontent.com/u/174380515?s=80&amp;v=4" width="40" height="40" alt="@LuckyD14"></a>

</p>


  
<div data-body-version="4d43e786f4b74b8c8987ce030d5dc22bb3ab485242d825682ca2553ac0e25a58" id="issuecomment-3145436536">

        
<task-lists disabled="" sortable="">
<div>
          <p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/174380515/473573366-56a6da97-c49c-4ac6-a8b0-dcbb6daa01c9.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTQ0MTE3MDMsIm5iZiI6MTc1NDQxMTQwMywicGF0aCI6Ii8xNzQzODA1MTUvNDczNTczMzY2LTU2YTZkYTk3LWM0OWMtNGFjNi1hOGIwLWRjYmI2ZGFhMDFjOS5qcGc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwODA1JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDgwNVQxNjMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0yNDMwZjUyZWVhNTFlMzA4MWExNzA0NDYwNDM0ZDcxOWE1NjkxMTUzNGFlMTMyNTc0MjA2OWFiYmRjY2RkMGRlJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.ONoSbTHupW89f6PanB8L8utrQPt6NZcrUMGDr49xGKs"><img src="https://private-user-images.githubusercontent.com/174380515/473573366-56a6da97-c49c-4ac6-a8b0-dcbb6daa01c9.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTQ0MTE3MDMsIm5iZiI6MTc1NDQxMTQwMywicGF0aCI6Ii8xNzQzODA1MTUvNDczNTczMzY2LTU2YTZkYTk3LWM0OWMtNGFjNi1hOGIwLWRjYmI2ZGFhMDFjOS5qcGc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwODA1JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDgwNVQxNjMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0yNDMwZjUyZWVhNTFlMzA4MWExNzA0NDYwNDM0ZDcxOWE1NjkxMTUzNGFlMTMyNTc0MjA2OWFiYmRjY2RkMGRlJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.ONoSbTHupW89f6PanB8L8utrQPt6NZcrUMGDr49xGKs" alt="OKX_1754011583554"></a></p>
      </div>
</task-lists>


        
      </div>

</div>


        <div data-gid="IC_kwDOBZWBkc67hezP" data-url="/github/site-policy/comments/IC_kwDOBZWBkc67hezP/partials/timeline_issue_comment">

  <p><a data-hovercard-type="user" data-hovercard-url="/users/LuckyD14/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/LuckyD14"><img src="https://avatars.githubusercontent.com/u/174380515?s=80&amp;v=4" width="40" height="40" alt="@LuckyD14"></a>

</p>


  


</div>




  <!-- Rendered timeline since 2025-08-01 18:55:09 -->
  



      

    </div>

    
  </div>

</div>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Enough is enough–I dumped Google's worsening search for Kagi (108 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2025/08/enough-is-enough-i-dumped-googles-worsening-search-for-kagi/</link>
            <guid>44798215</guid>
            <pubDate>Tue, 05 Aug 2025 14:12:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2025/08/enough-is-enough-i-dumped-googles-worsening-search-for-kagi/">https://arstechnica.com/gadgets/2025/08/enough-is-enough-i-dumped-googles-worsening-search-for-kagi/</a>, See on <a href="https://news.ycombinator.com/item?id=44798215">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
            <article data-id="2104999">
  
  <header>
  <div>
    

    <h2>
      Enough is enough—I dumped Google’s worsening search for Kagi
    </h2>

    <p>
      I like how the search engine is the product instead of <em>me</em>.
    </p>

    

    <div>
            <p><a data-pswp-width="2560" data-pswp-height="1441" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2.jpg 2560w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-1024x576.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-1536x864.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-2048x1153.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-980x552.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-1440x811.jpg 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2.jpg" target="_blank">
              <img width="2560" height="1441" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2.jpg" alt="Artist's depiction of the article author heaving a large multicolored &quot;G&quot; into the fires of Mount Doom" loading="eager" decoding="async" fetchpriority="high" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2.jpg 2560w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-1024x576.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-1536x864.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-2048x1153.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-980x552.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/lee-casting-google-into-mount-doom2-1440x811.jpg 1440w" sizes="(max-width: 2560px) 100vw, 2560px">
            </a></p><div id="caption-2108066">
    
    <p>
      "Won't be needing this anymore!"

              <span>
          Credit:

          
          Aurich "The King" Lawson

                  </span>
          </p>
  </div>
          </div>

    <div>
    
    <p>
      "Won't be needing this anymore!"

              <span>
          Credit:

          
          Aurich "The King" Lawson

                  </span>
          </p>
  </div>
  </div>
</header>


  

  
      
    
    <div>
                      
                      
          
<p>Mandatory AI summaries have come to Google, and they <a href="https://arstechnica.com/ai/2025/07/research-shows-google-ai-overviews-reduce-website-clicks-by-almost-half/">gleefully showcase hallucinations while confidently insisting on their truth</a>. I feel about them the same way I felt about mandatory G+ logins when all I wanted to do was access my damn YouTube account: I hate them. Intensely.</p>
<p>But <em>unlike</em> those mandatory G+ logins—on which Google <a href="https://arstechnica.com/gadgets/2015/07/google-officially-ends-forced-google-integration-first-up-youtube/">eventually relented</a> before <a href="https://arstechnica.com/gadgets/2019/01/google-shuts-down-april-2-all-data-will-be-deleted/">shutting down the G+ service</a>—our reading of the tea leaves suggests that, this time, the search giant <em>is extremely pleased</em> with how things are going.</p>
<p>Fabricated AI dreck polluting your search? It's the new normal. Miss your little results page with its 10 little blue links? Too bad. They're gone now, and you can't get them back, no matter what <a href="https://gizmodo.com/add-fcking-to-your-google-searches-to-neutralize-ai-summaries-2000557710">ephemeral workarounds</a> or <a href="https://arstechnica.com/ai/2025/07/research-shows-google-ai-overviews-reduce-website-clicks-by-almost-half/?comments=1&amp;post=43861979">temporarily functional flags</a> or <a href="https://udm14.com/">undocumented, could-fail-at-any-time URL tricks</a> you use.</p>
<p>And the galling thing is that Google expects you to be a good consumer and just <em>take it</em>. The subtext of the company's (probably AI-generated) robo-MBA-speak non-responses to <a href="https://arstechnica.com/information-technology/2024/05/googles-ai-overview-can-give-false-misleading-and-dangerous-answers/">criticism</a> and <a href="https://arstechnica.com/tech-policy/2025/02/education-tech-firm-sues-google-over-ai-search-summaries/">complaining</a> is clear: "LOL, what are you going to do, use a different search engine? Now, <a href="https://arstechnica.com/google/2025/05/the-gmail-app-will-now-create-ai-summaries-whether-you-want-them-or-not/">shut up and have some more AI</a>!"</p>
<p>But like <a href="https://www.youtube.com/watch?v=h97kbv4mbsc">the old sailor used to say</a>: "That's all I can stands, and I can't stands no more." So I <em>did</em> start using a different search engine—one that doesn't constantly shower me with half-baked, anti-consumer AI offerings.</p>
<p>Out with Google, in with <a href="https://kagi.com/">Kagi</a>.</p>
<h2>What the hell is a Kagi?</h2>
<p>Kagi was founded in 2018, but its search product has only been publicly available since <a href="https://blog.kagi.com/kagi-orion-public-beta">June 2022</a>. It purports to be an <a href="https://help.kagi.com/kagi/company/">independent search engine</a> that pulls results from around the web (<a href="https://help.kagi.com/kagi/search-details/search-sources.html">including from its own index</a>) and is aimed at returning search to a user-friendly, user-focused experience. The company's stated purpose is to deliver useful search results, full stop. The goal is <em>not</em> to blast you with AI garbage or bury you in "Knowledge Graph" summaries hacked together from posts in a 12-year-old Reddit thread between two guys named /u/WeedBoner420 and /u/14HitlerWasRight88.</p>

          
                      
                  </div>
                    
        
          
    
    <div>
          
          
<p>Kagi's offerings (it has <a href="https://kagi.com/orion/">a web browser, too</a>, though I've not used it) are based on a simple idea. There's an (oversimplified) axiom that if a good or service (like Google search, for example, or good ol' Facebook) is free for you to use, it's because you're the product, not the customer. With Google, you pay with your attention, your behavioral metrics, and the intimate personal details of your wants and hopes and dreams (and the contents of your emails and other electronic communications—Google's got most of that, too).</p>
<p>With Kagi, you pay for the product using <em>money</em>. That's it! You give them some money, and you get some service—great service, really, which I'm overall quite happy with and which I'll get to shortly. You don't have to look at any ads. You don't have to look at AI droppings. You don't have to give perpetual ownership of your mind-palace to a pile of optioned-out tech bros in sleeveless Patagonia vests while you are endlessly subjected to amateur AI Rorschach tests every time you search for "pierogis near me."</p>

<h2>How much money are we talking?</h2>
<p>I dunno, about <a href="https://kagi.com/pricing">a hundred bucks a year</a>? That's what I'm spending as an individual for unlimited searches. I'm using Kagi's "Professional" plan, but there are others, including a free offering so that you can poke around and see if the service is worth your time.</p>
<figure>
    <div>
            <p><a data-pswp-width="2560" data-pswp-height="1611" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing.png 2560w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-640x403.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-1024x644.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-768x483.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-1536x967.png 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-2048x1289.png 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-980x617.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-1440x906.png 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing.png" target="_blank">
              <img width="1024" height="644" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-1024x644.png" alt="image of kagi billing panel" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-1024x644.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-640x403.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-768x483.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-1536x967.png 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-2048x1289.png 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-980x617.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-9-billing-1440x906.png 1440w" sizes="auto, (max-width: 1024px) 100vw, 1024px">
            </a></p><div id="caption-2107941"><p>
              This is my account's billing page, showing what I've paid for Kagi in the past year. (By the time this article runs, I'll have renewed my subscription!)
                              </p><p>
                  Credit:
                                      Lee Hutchinson
                                  </p>
                          </div>
          </div>
          <figcaption>
        <div>
    
    <p>
      This is my account's billing page, showing what I've paid for Kagi in the past year. (By the time this article runs, I'll have renewed my subscription!)

              <span>
          Credit:

          
          Lee Hutchinson

                  </span>
          </p>
  </div>
      </figcaption>
      </figure>

<p>I'd previously bounced off two trial runs with Kagi in 2023 and 2024 because the idea of <em>paying for search</em> just felt so alien. But that was before Google's AI enshittification rolled out in full force. Now, sitting in the middle of 2025 with the world burning down around me, a hundred bucks to kick Google to the curb <em>and</em> get better search results feels totally worth it. Your mileage may vary, of course.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          


<p>The other thing that made me nervous about paying for search was the idea that my money was going to enrich some scumbag VC fund, but fortunately, there's good news on that front. According to <a href="https://help.kagi.com/kagi/company/">the company's "About" page</a>, Kagi has not taken any money from venture capitalist firms. Instead, it has been funded by a combination of self-investment by the founder, selling equity to some Kagi users in two rounds, and subscription revenue:</p>
<blockquote><p>Kagi was bootstrapped from 2018 to 2023 with ~$3M initial funding from the founder. In 2023, <a href="https://blog.kagi.com/safe-round">Kagi raised $670K</a> from Kagi users in its first external fundraise, followed by <a href="https://blog.kagi.com/what-is-next-for-kagi#3">$1.88M raised in 2024</a>, again from our users, bringing the number of users-investors to 93... In early 2024, Kagi became a <a href="https://blog.kagi.com/what-is-next-for-kagi#4">Public Benefit Corporation (PBC)</a>.</p></blockquote>
<h2>What about DuckDuckGo? Or Bing? Or Brave?</h2>
<p>Sure, those can be perfectly cromulent alternatives to Google, but honestly, I don't think they go far enough. DuckDuckGo is fine, but it largely utilizes <a href="https://duckduckgo.com/duckduckgo-help-pages/results/sources">Bing's index</a>; and while DuckDuckGo exercises considerable control over its search results, the company is tied to the vicissitudes of Microsoft by that index. It's a bit like sitting in a boat tied to a submarine. Sure, everything's fine now, but at some point, that sub will do what subs do—and your boat is gonna follow it down.</p>
<p>And as for Bing itself, perhaps I'm nitpicky [Ed. note: He is!], but using Bing feels like interacting with 2000-era MSN's slightly perkier grandkid. It's younger and fresher, yes, but it still radiates that same old stanky feeling of <a href="https://www.youtube.com/watch?v=EUXnJraKM3k">taste-free, designed-by-committee artlessness</a>. I'd rather just use Google—which is saying something. At least Google's search home page remains uncluttered.</p>
<p><a href="https://search.brave.com/">Brave Search</a> is another fascinating option I haven't spent a tremendous amount of time with, largely because Brave's <a href="https://brave.com/wallet/">cryptocurrency ties</a> still feel <a href="https://brave.com/brave-rewards/">incredibly low-rent and skeevy</a>. I'm slowly warming up to the Brave Browser as a replacement for Chrome (see the screenshots in this article!), but I'm just not comfortable with Brave yet—and likely won't be unless the company divorces itself from cryptocurrencies entirely.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          

<h2>More anonymity, if you want it</h2>
<p>The feature that convinced me to start paying for Kagi was its <a href="https://help.kagi.com/kagi/privacy/privacy-pass.html">Privacy Pass</a> option. Based on a clean-sheet Rust implementation of the Privacy Pass standard (IETF RFCs <a href="https://www.rfc-editor.org/rfc/rfc9576.html">9576</a>, <a href="https://www.rfc-editor.org/rfc/rfc9577.html">9577</a>, and <a href="https://www.rfc-editor.org/rfc/rfc9578.html">9578</a>) by <a href="https://github.com/raphaelrobert/privacypass">Raphael Robert</a>, this is a technology that uses cryptographic token-based auth to send an "I'm a paying user, please give me results" signal to Kagi, without Kagi knowing which user made the request. (There's a much longer <a href="https://blog.kagi.com/kagi-privacy-pass">Kagi blog post</a> with actual technical details for the curious.)</p>
<p>To search using the tool, you install the Privacy Pass extension (linked in the docs above) in your browser, log in to Kagi, and enable the extension. This causes the plugin to request a bundle of tokens from the search service. After that, you can log out and/or use private windows, and those tokens are utilized whenever you do a Kagi search.</p>
<figure>
    <div>
            <p><a data-pswp-width="2730" data-pswp-height="1978" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi.png 2730w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-640x464.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-1024x742.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-768x556.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-1536x1113.png 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-2048x1484.png 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-980x710.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-1440x1043.png 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi.png" target="_blank">
              <img width="1024" height="742" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-1024x742.png" alt="image of a kagi search with privacy pass enabled" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-1024x742.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-640x464.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-768x556.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-1536x1113.png 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-2048x1484.png 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-980x710.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-pierogies-kagi-1440x1043.png 1440w" sizes="auto, (max-width: 1024px) 100vw, 1024px">
            </a></p><div id="caption-2107908"><p>
              Privacy pass is enabled, allowing me to explore the delicious mystery of pierogis with some semblance of privacy.
                              </p><p>
                  Credit:
                                      Lee Hutchinson
                                  </p>
                          </div>
          </div>
          <figcaption>
        <div>
    
    <p>
      Privacy pass is enabled, allowing me to explore the delicious mystery of pierogis with some semblance of privacy.

              <span>
          Credit:

          
          Lee Hutchinson

                  </span>
          </p>
  </div>
      </figcaption>
      </figure>

<p>The obvious flaw here is that Kagi still records source IP addresses along with Privacy Pass searches, potentially de-anonymizing them, but there's a path around that: Privacy Pass functions with <a href="https://help.kagi.com/kagi/privacy/tor.html">Tor</a>, and Kagi maintains <a href="http://kagi2pv5bdcxxqla5itjzje2cgdccuwept5ub6patvmvn3qgmgjd6vid.onion/">a Tor onion address</a> for searches.</p>
<p>So why do I keep using Privacy Pass without Tor, in spite of the opsec flaw? Maybe it's the placebo effect in action, but I feel better about putting at least a tiny bit of friction in the way of someone with root attempting to casually browse my search history. Like, I want there to be at least a SQL <code>JOIN</code> or two between my IP address and my searches for "<a href="https://arstechnica.com/gaming/2017/03/the-correct-alien-sex-choices-in-the-mass-effect-trilogy/">best <em>Mass Effect</em> alien sex choices</a>" or "<a href="https://arstechnica.com/gaming/2014/04/hands-on-with-biowares-garrus-vakarian-body-pillow-very-very-hands-on/">cleaning tips for Garrus body pillow</a>." I mean, you know, assuming I were ever to search for such things.</p>
<h2>What’s it like to use?</h2>
<p>Moving on with embarrassed rapidity, let's look at Kagi a bit and see how using it feels.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          


<p>My anecdotal observation is that Kagi doesn't favor Reddit-based results nearly as much as Google does, but sometimes it still has them near or at the top. And here is where Kagi curb-stomps Google with quality-of-life features: Kagi lets you prioritize or de-prioritize a website's prominence in your search results. You can even pin that site to the top of the screen or block it completely.</p>
<p>This is a feature I've wanted Google to get for about <em>25 damn years</em> but that the company has consistently refused to properly implement (likely because allowing users to exclude sites from search results notionally reduces <a href="https://en.wikipedia.org/wiki/Engagement_marketing">engagement</a> and therefore reduces the potential revenue that Google can extract from search). Well, screw you, Google, because Kagi lets me prioritize or exclude sites from my results, and it works <em>great</em>—I'm extraordinarily pleased to never again have to worry about Quora or Pinterest links showing up in my search results.</p>
<p>Further, Kagi lets me adjust these settings both for the current set of search results (if you don't want Reddit results for <em>this</em> search but you don't want to drop Reddit altogether) and also globally (for all future searches):</p>


<figure>
    <div>
            <p><a data-pswp-width="2706" data-pswp-height="1423" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized.png 2706w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-640x337.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-1024x538.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-768x404.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-1536x808.png 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-2048x1077.png 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-980x515.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-1440x757.png 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized.png" target="_blank">
              <img width="1024" height="538" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-1024x538.png" alt="image of kagi search personalization options" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-1024x538.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-640x337.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-768x404.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-1536x808.png 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-2048x1077.png 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-980x515.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-5-search-peronalized-1440x757.png 1440w" sizes="auto, (max-width: 1024px) 100vw, 1024px">
            </a></p><div id="caption-2107938"><p>
              Goodbye forever, useless crap sites.
                              </p><p>
                  Credit:
                                      Lee Hutchinson
                                  </p>
                          </div>
          </div>
          <figcaption>
        <div>
    
    <p>
      Goodbye forever, useless crap sites.

              <span>
          Credit:

          
          Lee Hutchinson

                  </span>
          </p>
  </div>
      </figcaption>
      </figure>

<p>Another tremendous quality-of-life improvement comes via Kagi's image search, which does a bunch of stuff that Google should and/or used to do—like giving you direct right-click access to save images without having to fight the search engine with workarounds, plugins, or <a href="https://www.tampermonkey.net/">Tampermonkey</a>-esque userscripts.</p>



<p>The Kagi experience is also vastly more customizable than Google's (or at least, how Google's has become). The widgets that appear in your results can be turned off, and the "lenses" through which Kagi sees the web can be adjusted to influence what kinds of things do and do not appear in your results.</p>


<p>If that doesn't do it for you, how about the ability to <a href="https://help.kagi.com/kagi/features/custom-css.html">inject custom CSS</a> into your search and landing pages? Or to <a href="https://help.kagi.com/kagi/features/redirects.html">automatically rewrite search result URLs</a> to taste, doing things like redirecting <code>reddit.com</code> to <code>old.reddit.com</code>? Or breaking free of AMP pages and always viewing originals instead?</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<figure>
    <div>
            <p><a data-pswp-width="2560" data-pswp-height="2118" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css.png 2560w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-640x530.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-1024x847.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-768x635.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-1536x1271.png 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-2048x1694.png 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-980x811.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-1440x1191.png 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css.png" target="_blank">
              <img width="1024" height="847" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-1024x847.png" alt="Image of kagi custom css field" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-1024x847.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-640x530.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-768x635.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-1536x1271.png 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-2048x1694.png 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-980x811.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-02-css-1440x1191.png 1440w" sizes="auto, (max-width: 1024px) 100vw, 1024px">
            </a></p><div id="caption-2107900"><p>
              Imagine all the things Ars readers will put here.
                              </p><p>
                  Credit:
                                      Lee Hutchinson
                                  </p>
                          </div>
          </div>
          <figcaption>
        <div>
    
    <p>
      Imagine all the things Ars readers will put here.

              <span>
          Credit:

          
          Lee Hutchinson

                  </span>
          </p>
  </div>
      </figcaption>
      </figure>

<h2>Is that all there is?</h2>
<p>Those are really all the features <em>I</em> care about, but there are loads of other Kagi bits to discover—like a Kagi Maps tool (it's pretty good, though I'm not ready to take it up full time yet) and a Kagi video search tool. There are also tons of classic old-Google-style inline search customizations, including <a href="https://help.kagi.com/kagi/features/verbatim.html">verbatim mode</a>, where instead of trying to infer context about your search terms, Kagi searches for <em>exactly</em> what you put in the box. You can also add custom search operators that do whatever you program them to do, and you get API-based access for doing programmatic things with search.</p>
<div>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="arrow-blocks-right_svg__a"><path fill="none" d="M0 0h40v40H0z"></path></clipPath></defs><g fill="currentColor" clip-path="url(#arrow-blocks-right_svg__a)"><path d="M32 16h8v8h-8zm-8 8h8v8h-8zm-8 8h8v8h-8zm8-24h8v8h-8zm-8-8h8v8h-8zM0 16h16v8H0z"></path></g></svg>

    <p><span>A quick run-through of a few additional options pages. This is the general customization page.</span>
                    <span>
                      Lee Hutchinson
                  </span>
          </p>
  </div>

<p>I haven't spent any time with <a href="https://kagi.com/orion/">Kagi's Orion browser</a>, but it's there as an option for folks who want a WebKit-based browser with baked-in support for Privacy Pass and other Kagi functionality. For now, Firefox continues to serve me well, with Brave as a fallback for working with Google Docs and other tools I can't avoid and that treat non-Chromium browsers like second-class citizens. However, Orion is probably on the horizon for me if things in Mozilla-land <a href="https://arstechnica.com/tech-policy/2025/02/firefox-deletes-promise-to-never-sell-personal-data-asks-users-not-to-panic/">continue to sour</a>.</p>

<h2>Cool, but is it any good?</h2>
<p>Rather than fill space with a ton of comparative screenshots between Kagi and Google or Kagi and Bing, I want to talk about my subjective experience using the product. (You can do all the comparison searches you want—<a href="https://kagi.com/">just go and start searching</a>—and your comparisons will be a lot more relevant to your personal use cases than any examples I can dream up!)</p>
<p>My time with Kagi so far has included about seven months of casual opportunistic use, where I'd occasionally throw a query at it to see how it did, and about five months of committed daily use. In the five months of daily usage, I can count on one hand the times I've done a supplementary Google search because Kagi didn't have what I was looking for on the first page of results. I've done searches for all the kinds of things I usually look for in a given day—article fact-checking queries, searches for details about the parts of speech, hunts for duck facts (we have some feral Muscovy ducks nesting in our front yard), obscure technical details about Project Apollo, who the hell played Dupont in <em>Equilibrium</em> (Angus Macfadyen, who also played Robert the Bruce in <em>Braveheart</em>), and many, many other queries.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<figure>
    <div>
            <p><a data-pswp-width="3686" data-pswp-height="1822" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history.png 3686w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-640x316.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-1024x506.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-768x380.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-1536x759.png 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-2048x1012.png 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-980x484.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-1440x712.png 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history.png" target="_blank">
              <img width="1024" height="506" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-1024x506.png" alt="Image of Firefox history window showing kagi searches for july 22" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-1024x506.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-640x316.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-768x380.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-1536x759.png 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-2048x1012.png 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-980x484.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-history-1440x712.png 1440w" sizes="auto, (max-width: 1024px) 100vw, 1024px">
            </a></p><div id="caption-2108307"><p>
              A typical afternoon of Kagi searches, from my Firefox history window.
                              </p><p>
                  Credit:
                                      Lee Hutchinson
                                  </p>
                          </div>
          </div>
          <figcaption>
        <div>
    
    <p>
      A typical afternoon of Kagi searches, from my Firefox history window.

              <span>
          Credit:

          
          Lee Hutchinson

                  </span>
          </p>
  </div>
      </figcaption>
      </figure>

<p>For all of these things, Kagi has responded quickly and correctly. The time to service a query feels more or less like Google's service times; according to the timer at the top of the page, my Kagi searches complete in between 0.2 and 0.8 seconds. Kagi handles misspellings in search terms with the grace expected of a modern search engine and has had no problem figuring out my typos.</p>
<p>Holistically, taking search customizations into account on top of the actual search performance, my subjective assessment is that Kagi gets me accurate, high-quality results on more or less any given query, and it does so without festooning the results pages with features I find detractive and irrelevant.</p>
<p>I know that's not a data-driven assessment, and it doesn't fall back on charts or graphs or figures, but it's how I feel after using the product every single day for most of 2025 so far. For me, Kagi's search performance is firmly in the "good enough" category, and that's what I need.</p>
<h2>Kagi and AI</h2>
<p>Unfortunately, the thing that's stopping me from being completely effusive in my praise is that Kagi is exhibiting a disappointing amount of "keeping-up-with-the-Joneses" by rolling out a big 'ol pile of (optional, so far) AI-enabled search features.</p>
<p>A <a href="https://blog.kagi.com/kagi-ai-search">blog post from founder Vladimir Prelovac</a> talks about the company's use of AI, and it says all the right things, but at this point, I trust written statements from tech company founders about as far as I can throw their corporate office buildings. (And, dear reader, that ain't very far).</p>
<figure>
    <div>
            <p><a data-pswp-width="2560" data-pswp-height="1461" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai.png 2560w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-640x365.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-1024x584.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-768x438.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-1536x877.png 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-2048x1169.png 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-980x559.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-1440x822.png 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai.png" target="_blank">
              <img width="1024" height="584" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-1024x584.png" alt="image of kagi ai features" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-1024x584.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-640x365.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-768x438.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-1536x877.png 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-2048x1169.png 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-980x559.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/kagi-options-6-search-ai-1440x822.png 1440w" sizes="auto, (max-width: 1024px) 100vw, 1024px">
            </a></p><div id="caption-2107939"><p>
              No thanks. But I would like to exclude AI images from my search results, please.
                              </p><p>
                  Credit:
                                      Lee Hutchinson
                                  </p>
                          </div>
          </div>
          <figcaption>
        <div>
    
    <p>
      No thanks. But I would like to exclude AI images from my search results, please.

              <span>
          Credit:

          
          Lee Hutchinson

                  </span>
          </p>
  </div>
      </figcaption>
      </figure>

<p>The short version is that, like Google, Kagi has some AI features: There's an AI search results summarizer, an AI page summarizer, and an "ask questions about your results" chatbot-style function where you can interactively interrogate an LLM about your search topic and results. So far, all of these things can be disabled or ignored. I don't know how good any of the features are because I have disabled or ignored them.</p>

          
                  </div>
                    
        
          
    
    <div>

        
        <div>
          
          
<p>If the existence of AI in a product is a bright red line you won't cross, you'll have to turn back now and find another search engine alternative that doesn't use AI and also doesn't suck. When/if you do, let me know, because the pickings are slim.</p>
<h2>Is Kagi for you?</h2>
<p>Kagi <em>might</em> be for you—especially if you've recently typed a simple question into Google and gotten back a pile of fabricated gibberish in place of those 10 blue links that used to serve so well. Are you annoyed that Google's search sucks vastly more now than it did 10 years ago? Are you unhappy with how difficult it is to get Google search to do what you want? Are you fed up? Are you <em>pissed off</em>?</p>
<p>If your answer to those questions is the same full-throated "Hell yes, I am!" that mine was, then perhaps it's time to try an alternative. And Kagi's a pretty decent one—if you're not averse to paying for it.</p>
<p>It's a fantastic feeling to type in a search query and once again get useful, relevant, non-AI results (that I can customize!). It's a bit of sanity returning to my Internet experience, and I'm grateful. Until Kagi is bought by a value-destroying vampire VC fund or implodes into its own AI-driven enshittification cycle, I'll probably keep paying for it.</p>
<p>After that, who knows? Maybe I'll throw away my computers and live in a cave. At least until the cave's robot exclusion protocol fails and <a href="https://www.ftrain.com/robot_exclusion_protocol">the Googlebot comes for me</a>.</p>


          
                  </div>

                  
          






  <div>
  <div>
          <p><a href="https://arstechnica.com/author/lee-hutchinson/"><img src="https://cdn.arstechnica.net/wp-content/uploads/2016/05/l.hutchinson-1394.jpg" alt="Photo of Lee Hutchinson"></a></p>
  </div>

  <div>
    

    <p>
      Lee is the Senior Technology Editor, and oversees story development for the gadget, culture, IT, and video sections of Ars Technica. A long-time member of the Ars OpenForum with an extensive background in enterprise storage and security, he lives in Houston.
    </p>
  </div>
</div>


  <p>
    <a href="https://arstechnica.com/gadgets/2025/08/enough-is-enough-i-dumped-googles-worsening-search-for-kagi/#comments" title="184 comments">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 80 80"><defs><clipPath id="bubble-zero_svg__a"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath><clipPath id="bubble-zero_svg__b"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath></defs><g clip-path="url(#bubble-zero_svg__a)"><g fill="currentColor" clip-path="url(#bubble-zero_svg__b)"><path d="M80 40c0 22.09-17.91 40-40 40S0 62.09 0 40 17.91 0 40 0s40 17.91 40 40"></path><path d="M40 40 .59 76.58C-.67 77.84.22 80 2.01 80H40z"></path></g></g></svg>
    184 Comments
  </a>
      </p>
              </div>
  </article>


  


  


  <div>
    <header>
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 26"><defs><clipPath id="most-read_svg__a"><path fill="none" d="M0 0h40v26H0z"></path></clipPath><clipPath id="most-read_svg__b"><path fill="none" d="M0 0h40v26H0z"></path></clipPath></defs><g clip-path="url(#most-read_svg__a)"><g fill="none" clip-path="url(#most-read_svg__b)"><path fill="currentColor" d="M20 2h.8q1.5 0 3 .6c.6.2 1.1.4 1.7.6 1.3.5 2.6 1.3 3.9 2.1.6.4 1.2.8 1.8 1.3 2.9 2.3 5.1 4.9 6.3 6.4-1.1 1.5-3.4 4-6.3 6.4-.6.5-1.2.9-1.8 1.3q-1.95 1.35-3.9 2.1c-.6.2-1.1.4-1.7.6q-1.5.45-3 .6h-1.6q-1.5 0-3-.6c-.6-.2-1.1-.4-1.7-.6-1.3-.5-2.6-1.3-3.9-2.1-.6-.4-1.2-.8-1.8-1.3-2.9-2.3-5.1-4.9-6.3-6.4 1.1-1.5 3.4-4 6.3-6.4.6-.5 1.2-.9 1.8-1.3q1.95-1.35 3.9-2.1c.6-.2 1.1-.4 1.7-.6q1.5-.45 3-.6zm0-2h-1c-1.2 0-2.3.3-3.4.6-.6.2-1.3.4-1.9.7-1.5.6-2.9 1.4-4.3 2.3-.7.5-1.3.9-1.9 1.4C2.9 8.7 0 13 0 13s2.9 4.3 7.5 7.9c.6.5 1.3 1 1.9 1.4 1.3.9 2.7 1.7 4.3 2.3.6.3 1.3.5 1.9.7 1.1.3 2.3.6 3.4.6h2c1.2 0 2.3-.3 3.4-.6.6-.2 1.3-.4 1.9-.7 1.5-.6 2.9-1.4 4.3-2.3.7-.5 1.3-.9 1.9-1.4C37.1 17.3 40 13 40 13s-2.9-4.3-7.5-7.9c-.6-.5-1.3-1-1.9-1.4-1.3-.9-2.8-1.7-4.3-2.3-.6-.3-1.3-.5-1.9-.7C23.3.4 22.1.1 21 .1h-1"></path><path fill="#ff4e00" d="M20 5c-4.4 0-8 3.6-8 8s3.6 8 8 8 8-3.6 8-8-3.6-8-8-8m0 11c-1.7 0-3-1.3-3-3s1.3-3 3-3 3 1.3 3 3-1.3 3-3 3"></path></g></g></svg>
      
    </header>
    <ol>
              <li>
                      <a href="https://arstechnica.com/space/2025/08/is-the-dream-chaser-space-plane-ever-going-to-launch-into-orbit/">
              <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/05/Dream-Chaser-Full-Profile-Landscape-2-768x432.jpg" alt="Listing image for first story in Most Read: Is the Dream Chaser space plane ever going to launch into orbit?" decoding="async" loading="lazy">
            </a>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                  </ol>
</div>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI is not Making Engineers 10x as Productive (408 pts)]]></title>
            <link>https://colton.dev/blog/curing-your-ai-10x-engineer-imposter-syndrome/</link>
            <guid>44798189</guid>
            <pubDate>Tue, 05 Aug 2025 14:10:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://colton.dev/blog/curing-your-ai-10x-engineer-imposter-syndrome/">https://colton.dev/blog/curing-your-ai-10x-engineer-imposter-syndrome/</a>, See on <a href="https://news.ycombinator.com/item?id=44798189">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
			<heading-anchors>
				



<p>Curing Your AI 10x Engineer Imposter Syndrome</p>

<ul>
	<li><time datetime="2025-08-05">05 August 2025</time></li>
	<li><a href="https://colton.dev/tags/ai/">AI</a></li>
</ul>

<p>A few months ago I went through a bit of a mental slump. I've always been confident of my abilities as an engineer, but I couldn't help but feel like my skills were falling hopelessly behind as I scrolled places like LinkedIn and Twitter. If these sources were to be believed, engineering had moved on from the medieval practice of typing code into an editor. <em>Real</em> engineers were now 10-100x more productive than I was. I'm writing this hoping to help others who are feeling similar anxieties.</p>
<p>I'm a skeptical person so I don't usually fall over myself immediately when I hear a claim like that. I usually roll my eyes in the same way I do when someone tells me a simple herbal remedy cures all disease. But the sheer volume these 10x engineer claims are reaching right now started to hit a nerve. What if I'm <em>wrong</em>? Will I miss the bus and become unemployable if I don't learn to use AI right now? After all, there are a lot of fancy words going around that distance the "AI" these people are talking about with the "AI" I was familiar with.</p>
<p>These people were using <em>✨agentic✨</em> AI. They were using <em>✨thinking✨</em> models that surfed the internet, ran tests, and corrected their own mistakes. Sure I popped into a chat window here and there and asked it to write some code, then promptly discarded most of the output once I got the idea that I needed. But these engineers were letting Claude fully take the wheel and had agents ripping 5 PRs for them while they made morning coffee. Was I becoming a dinosaur, an old man yelling at cloud?</p>
<p>Part of what made me feel so anxious was that it was entirely possible AI changed without me knowing it because I didn't use AI very much. Because I didn't <em>like</em> using AI that much. Reviewing code is vastly less enjoyable process than writing it. Had my stubborn desire to <em>enjoy coding</em> set me up to be left behind?</p>
<h2 id="diving-in">Diving In</h2>
<p>Eventually I hit a breaking point and decided I simply had to dive in head first to AI coding. I tried Claude Code, Cursor, Roo Code, and Zed for their agentic coding promises. I started asking AI to write all sorts of code in all sorts of projects. I tried the different models and compared them. I even vibe coded a few things, not editing the code manually once.</p>
<p>And it was... Fine. Despite claims that AI today is improving at a fever pitch, it felt largely the same as before. It's good at writing boilerplate, especially in Javascript, and particularly in React. It's not good at keeping up with the standards and utilities of your codebase. It tends to struggle with languages like Terraform. It still hallucinates libraries leading to significant <a href="https://en.wikipedia.org/wiki/Slopsquatting">security vulnerabilities</a>.</p>
<p>AIs still struggle to absorb the context of a larger codebase, even with a great prompt and <code>CLAUDE.md</code> file. If you use a library that isn't StackOverflow's favorite it will butcher it even after an agentic lookup of the documentation. Agents occasionally do something neat like fix the tests they broke. Often they just waste time and tokens, going back and forth with themselves not seeming to gain any deeper knowledge each time they fail. Thus, AI's best use case for me remains writing one-off scripts. Especially when I have no interest in learning deeper fundamentals for a single script, like when writing a custom ESLint rule.</p>
<p>Dark warnings that if I didn't start using AI now I'd be hopelessly behind proved unfounded. Using AI to code is not hard to learn. Obviously? Well, the AI coding community seems split on whether AI makes coding so easy a caveman can do it and that it requires an advanced, dedicated prompt engineer skillset. There are a few things you need to learn but they come quickly. You learn how to split up tasks into smaller pieces so the AI doesn't lose its mind late in the context window. Tools like Claude Code can do a bit of this themselves, even, though not always reliably. And you learn to identify when the AI is too far off and it's time to take the wheel.</p>
<p>A competent engineer will figure this stuff out in less than a week of moderate AI usage. Further, if AI is about to get 2x, 10x, or 100x better at any minute (as everyone keeps saying it will), then any lessons about how to use it now are moot for the future.</p>
<p>Every time I encountered AI working "just okay", it strangely made me more anxious, not less. It meant I couldn't find the spicy secret sauce that made everyone else so productive. I just didn't have what it takes: dinosaur, meet asteroid, thy name is AI. Eventually, a few things shook me out of this slump. One of those was <a href="https://ludic.mataroa.blog/blog/contra-ptaceks-terrible-article-on-ai/">this article</a> from Ludicity, directly countering the claims of the AI pumpers. I write this article to share more things that helped me get out of the AI 10x engineer imposter syndrome.</p>
<h2 id="the-math">The Math</h2>
<p>Let's start by looking at the simple math of 10-100x productivity. 10x productivity means ten times the outcomes, not ten times the lines of code. This means what you used to ship in a quarter you now ship in a week and a half. These numbers should make even the truest AI believer pause. The amount of product ideation, story point negotiation, bugfixing, code review, waiting for deployments, testing, and QA in that go into what was traditionally 3 months of work is now getting done in 7 work days? For that to happen each and every one of these bottlenecks has to also seen have 10x productivity gains.</p>
<p>Any software engineer who has worked on actual code in an actual company knows this isn't possible. You can't compress the back and forth of 3 months of code review into 1.5 weeks. When you code review you:</p>
<ol>
<li>Tag your reviewer</li>
<li>Hope they will get to it sooner rather than later (which will be tough because they are apparently code reviewing 10x as much code as before)</li>
<li>Context switch to something else while you wait</li>
<li>See a notification (perhaps immediately, perhaps 2 hours after your reviewer went offline for the day)</li>
<li>Context switch back to the review</li>
<li>Read their comments</li>
<li>Respond accordingly</li>
<li>Rinse and repeat.</li>
</ol>
<p>This process can be made fairly efficient at a competent company with good standards and communication practices. But you're telling me you made this process <strong>10 times</strong> as efficient to handle 10x the work? This simply can not be done.</p>
<p>The human processes involved in actual corporate software engineering have not changed significantly. Product managers might use ChatGPT to do "research" but they aren't suddenly pumping out ten times as many well vetted, well justified, well estimated stories as they did before. They can not do 10 user interviews all at once. The same goes for Designers and QA testers. Hiring 10x the number of PMs to keep up isn't feasible. Each hire has diminishing returns as network effects and bureaucracy take hold.</p>
<p>Even if we assume people mean only the actual code writing process is now 10-100x faster, we should still be skeptical of how this maths out. When you write code, how much of your time do you truly spend pushing buttons on the keyboard? It's probably less than you think. Much of your prime coding time is actually reading and thinking, often while waiting for compiling, a page refresh, or for tests to run. LLMs do not make <code>rustc</code> go faster.</p>
<p>What LLMs produce is often broken, hallucinated, or below codebase standards. The frequency of these errors go up with the size of the codebase. When that happens you have to re-prompt, which could instantly fix the problem or could be a huge waste of time. Or you can go in and fix the code yourself. But then you're back to measly 1x engineer status, perhaps worse if you've gotten so used to vibe coding you <a href="https://nmn.gl/blog/ai-and-learning">forgot how to code</a>. If you're "embracing the vibes" and not even looking at the code produced, you're simply going to hit a productivity wall once the codebase gets large enough. And once you do you'll have to reckon with the complete lack of standards and proper abstractions.</p>
<p>I think sometimes people lose the scale of just how big a 10x improvement is. 10x is the difference between your mini-van and a record setting <a href="https://en.wikipedia.org/wiki/ThrustSSC">supersonic land jet</a>. Imagine trying to drive your 10 minute commute down your city streets in a car that goes 600mph. Will you get to the other side of town in one tenth the time? No, because even a single 60 second stoplight will eat up your entire time budget. F1 cars slow down to mini-van speeds in basic turns. It turns out that most of any activity is not spent going at top speed.</p>
<p>100x productivity means you now do what used to be one year of work in two days. I shouldn't even need to touch the ludicrousness of numbers at that scale.</p>
<h2 id="do-10x-engineers-exist">Do 10x Engineers Exist?</h2>
<p>This debate isn't something I want to weigh in on but I might have to. My answer is sometimes, kinda. When I have had engineers who were 10x as valuable as others it was primarily due to their ability to <em>prevent unnecessary work</em>. Talking a PM down from a task that was never feasible. Getting another engineer to not build that unnecessary microservice. Making developer experience investments that save everyone just a bit of time on every task. Documenting your work so that every future engineer can jump in faster. These things can add up over time to one engineer saving 10x the time company wide than what they took to build it.</p>
<p>Work of this nature is not always available, so great engineers will only find themselves being 10x as productive in certain situations. At a certain point every engineer just needs to build features, which a great engineer might do twice as fast as a junior engineer, but they'll still hit the same bottlenecks as before. Flawed as story points are, I've never seen an engineer actually complete ten times as many as an average engineer consistently.</p>
<p>Notably, AI coding assistants do very little to prevent unnecessary work. On the contrary, AI often seems to encourage hastiness and over-building. When I ask architectural questions, it often recommends something that I realize is not necessary after a good night's sleep or a talk with a great engineer. All other things held the same, is a faster coder a better engineer? Yes, but it's not the 10x difference maker and it's hard to hold everything else constant. The more you focus on pumping out tasks as fast as possible the easier is to miss the important time savers that reduce total work.</p>
<h2 id="so-are-the-ai-posters-lying-or-what">So are the AI-posters lying or what?</h2>
<p>I think the AI-posters are a mix of the following, in order of least to most malevolent:</p>
<ul>
<li>Good-natured folks who are mismeasuring themselves and others</li>
<li>People heavily invested, personally or financially, in the success of AI (AI startup founders, investors, etc.)</li>
<li>Bosses outright trying to make their engineers feel precarious so they don't quit, look for other jobs, or ask for raises</li>
</ul>
<h3 id="the-good-natured-engineer-with-bad-math-skills">The good-natured engineer with bad math skills</h3>
<p>In my experience, AI delivers rare, short bursts of 10-100x productivity. When I have AI write me a custom ESLint rule in a few minutes, which would have taken hours of documentation surfing and tutorials otherwise, that's a genuine order of magnitude time and effort improvement. Moments like this do happen with AI. Many career non-coders have felt the magic in the first few days after spinning an app up with Lovable.</p>
<p>The problem is that productivity does not scale. I don't write more than one ESLint rule per year. This burst of productivity was enabled solely by the fact that I didn't care about this code and wasn't going to work to make it readable for the next engineer. If constantly writing ESLint rules became a core job requirement I'd sink the one-time cost to learn how ESLint internals work. After that, there simply wouldn't be a big difference in the time it takes to vibe code a rule vs. write it myself, especially when you add in the extra time to make my code human readable for when I come back to this file in 6 months.</p>
<p>Eventually every vibe coder reaches the point where the returns start heavily diminishing. Their <a href="https://pivot-to-ai.com/2025/03/18/guys-im-under-attack-ai-vibe-coding-in-the-wild/">site gets hacked</a> and they need to actually sink the time to learn how security works. The app gets too big for context windows and things start looking and functioning inconsistently. Real frontend engineers who know what they are doing are hired to implement a consistent design system and UX.</p>
<p>There's also a lot of simple biases and blind spots that can cause a productivity illusion. If you leave the depths of big corporate for a startup you will genuinely be shocked at how much more productive each engineer is. It's easy to credit this to AI. Some people really enjoy the technological novelty of AI coding and when you are working in something new you often feel like you're doing more than you ever did. I know the first time I used Python I felt like I was "sipping rocket fuel", but, as with all other technologies, it always comes back down to earth.</p>
<p>I think a lot of the more genuine 10x AI hype is coming from people who are simply in the honeymoon phase or haven't sat down to actually consider what 10x improvement means mathematically. I wouldn't be surprised to learn AI helps many engineers do certain tasks 20-50% faster, but the nature of software bottlenecks mean this doesn't translate to a 20% productivity increase and certainly not a 10x increase.</p>
<h3 id="incentives-matter">Incentives matter</h3>
<p>Look, I'm not an AI startup hater. If you want to plug OpenAI's API into your healthcare startup I might raise an eyebrow of concern over the risks, but I'd do the same for any startup desiring to move fast and break things in the medical field. My goal here isn't to say AI startup founders or investors are evil or even dishonest. My point is to say in the droll voice of your high school Econ 101 professor, "Incentives Matter".</p>
<p>If you are running an AI startup and every other AI startup is telling investors they are seeing 10x more productivity thanks to AI, the incentives are plain and simple: you should say the same publicly and privately. If your company is built on the back of AI, you are incentivized to sell AI as a miracle solution in every part of life. If you are an engineer at an AI startup and your boss asks you:</p>
<blockquote>
<p>Hey, you're getting 10x the productivity thanks to AI, just like all the other engineers, right?</p>
</blockquote>
<p>You are strongly incentivized to say yes. And when every other engineer also says yes for the same reason, that CEO <a href="https://www.youtube.com/watch?v=vn_PSJsl0LQ">isn't lying</a>, they are just relaying what they heard.</p>
<p>What I'd like to stress to those feeling anxiety like me is that this is nothing new. CEOs are not unbiased sources. Executives have been claiming that everything from Agile to Meyers-Briggs have unlocked limitless productivity. There will always be a new synergistic buzzword on LinkedIn, don't let it get you down. In fact, stop scrolling LinkedIn at all. It's a silly place.</p>
<h3 id="outright-malice">Outright Malice</h3>
<p>When something is said that makes people feel anxious, at least some of the time you should conclude it's because that's what the speaker wanted to happen. Bosses trying to make their engineers feel like their position is precarious is also nothing new. We all remember the narrative that a 3 month coding bootcamp could churn out 4-year-degree quality engineers, so you'd best not get too uppity or you'll be replaced with a bachelor of arts doing a career pivot. Then a few years went by and people realized that bootcamp grads were usually <a href="https://www.sandofsky.com/lambda-school/">woefully underprepared</a> for actual software engineering since they were not given the proper foundation.</p>
<p>Bootcamps and AI are just examples in a long series of poorly born out threats to commoditize the highly expensive, highly professionalized field of software engineering. They are rhetorical devices designed to imply precarity. Your boss can't actually fire you and replace you with AI, but he can make you <em>feel</em> like he <em>could</em>, and maybe not ask for that raise.</p>
<p>Some amount of the 10x AI engineer story is likely being told by people who simply want you to feel bad for this purpose. How much of it, I don't know. Despite how highly distrustful we've become of each other in these times, I still believe most people are fundamentally decent, so I'm not inclined to believe it's a high percentage.</p>
<h2 id="degrees-of-separation">Degrees of separation</h2>
<p>One thing I've noticed about all these characters in AI coding hype pieces is there is almost always a degree of separation from the writer to the actual productivity benefits. The poster is a founder, or a manager, or an investor, making grandiose claims about someone else's productivity. There's nothing wrong with secondary sources but if you can't find a primary source, you might start questioning the reliability of the information.</p>
<p>Presentations from actual engineers demonstrating how they achieve more productivity with AI are much more varied and much more muted in their praise. These demos show largely AI as the same technology you and I were familiar with before we got so anxious: a neat text generator that sometimes does magic but often requires you to take the wheel.</p>
<p>AI usage on open source projects, where the productive process can be publicly witnessed, has famously been a <a href="https://old.reddit.com/r/ExperiencedDevs/comments/1krttqo/my_new_hobby_watching_ai_slowly_drive_microsoft/">hilarious failure</a>. I have learned things about how to use AI better from a few youtube videos. <a href="https://www.youtube.com/watch?v=sQYXZCUvpIc">Here's</a> a good one referenced in that Ludicity article above. I'll spoil it for you though, this engineer has not found the fountain of coding productivity.</p>
<h2 id="its-okay-to-be-less-productive">It's okay to be less productive</h2>
<p>Even after I got over the idea that there was a secret clade of engineer who was now ten times as productive and strong and tall and sexy as I was, I still felt some anxiety over the fact that I still didn't enjoy using AI very much. Vibe coding is a complete bore once the magic wears off. Reading LLM generated code sucks. Asking it politely to use a not hallucinated library is painful. But what if I was, despite all that, 20% more productive vibe coding than regular coding? Would it be wrong for me to do "normal" coding if a higher output path is available?</p>
<p>No. It's okay to sacrifice some productivity to make work enjoyable. More than okay, it's <em>essential</em> in our field. If you force yourself to work in a way you hate, you're just going to burn out. Only so much of coding is writing code, the rest is solving problems, doing system design, reasoning about abstractions, and interfacing with other humans. You are better at all those things when you feel good. It's okay to feel pride in your work and appreciate the craft. Over the long term your codebase will benefit from it.</p>
<p>It doesn't matter if digital music sounds objectively better than vinyl. It doesn't matter if flipping the record is less "productive" than letting the streaming service automatically roll over to the next song in 100x less time. If listening to a 70 year old disk makes you happier, just do it. You'll listen to more music if you do that than you would by forcing yourself to use the more "productive" streaming service. You will spend more time writing code and you'll write better code if you do it the way you like to.</p>
<p>Oh, and this exact argument works in reverse. If you feel good doing AI coding, just do it. If you feel so excited that you code more than ever before, that's awesome. I want everyone to feel that way, regardless of how they get there.</p>
<h2 id="how-to-be-a-good-ai-leader">How to be a good AI leader</h2>
<p>Making all your engineers feel constantly anxious about their performance is <em>bad for your company</em>. It will make your engineers not want to work for you. This is a recipe for short term thinking that will encourage engineers to max out bad metrics, like lines of code. Code review will get neglected, tech debt will compound, and in the long term the whole company will be footing the bill of those errors.</p>
<p>Unrealistic 10x expectations will result in rushed and thus subpar work without fail. Engineers need to have room to breathe. Room to take a little bit more time to do the thing right. Good codebases and good companies are built on a healthy balance of thinking for today and tomorrow. I'm thankful to work at one of these companies right now, but many aren't so fortunate.</p>
<p>Do not scold engineers for not using enough tokens. Your engineers are highly educated professionals in an extremely competitive field. Software engineers are already infamous for an over-eager cycle of embracing and abandoning new languages and tools. If you are paying these people this much, you should have the trust in them that if a super amazing productivity boost becomes available, they'll <em>come to you</em> asking for the pro plan. If you're worried about missing out on all the AI coding gains everyone else seems to be getting, sign up for a LLM team plan, host a training session, and see what comes out of it. That's all you need to do.</p>
<h2 id="conclusion">Conclusion</h2>
<p>There is no secret herbal medicine that prevents all disease sitting out in the open if you just follow the right Facebook groups. There is no AI coding revolution available if you just start vibing. You are not missing anything. Trust yourself. You are enough.</p>
<p>Oh, and don't scroll LinkedIn. Or Twitter. Ever.</p>

<ul><li>← Previous<br> <a href="https://colton.dev/blog/tailwind-is-the-worst-of-all-worlds/">Tailwind is the Worst of All Worlds</a></li>
</ul>

			</heading-anchors>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Genie 3: A new frontier for world models (546 pts)]]></title>
            <link>https://deepmind.google/discover/blog/genie-3-a-new-frontier-for-world-models/</link>
            <guid>44798166</guid>
            <pubDate>Tue, 05 Aug 2025 14:08:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://deepmind.google/discover/blog/genie-3-a-new-frontier-for-world-models/">https://deepmind.google/discover/blog/genie-3-a-new-frontier-for-world-models/</a>, See on <a href="https://news.ycombinator.com/item?id=44798166">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="capabilities">
              
                
                
                  
                  <div>
  <h2 data-block-key="wbu8i">Genie 3’s capabilities include:</h2><p data-block-key="7oibn">The following are recordings of real time interactions from Genie 3.</p><h3 data-block-key="4b33n">Modelling physical properties of the world</h3><p data-block-key="5alru">Experience natural phenomena like water and lighting, and complex environmental interactions.</p>
</div>
                
              
                
                
                  
                  


<gdm-carousel id="block-2c894174-1e81-45ce-9d7e-f6eed0466be8">
  
  <div>
<div aria-label="Item 2" id="block-4d2e1943-df2a-474d-916b-748e4b2e48b3">
  <figure aria-labelledby="caption-4d2e1943-df2a-474d-916b-748e4b2e48b3">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_modelling_physical_properties_1_MNInndd.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> The video shows a first person perspective of someone navigating difficult terrain in the middle of a volcanic area. This is a real world video shot from the perspective of a wheeled robot that needs to traverse across a terrain. The vehicle has chunky offroad tires that crunch under the blackened rock. The camera is an egocentric camera mounted to the vehicle, and you can see the front tires just on the bottom of the camera along with the body of the robot. In the distance you can see smoke and lava flowing from the volcano. There are no other visible signs of life. There are lava pools that the agent is trying to avoid and random rock formations. The sky is a vivid blue.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 2" id="block-29587f73-7711-41b8-a95d-ceb42d5f598a">
  <figure aria-labelledby="caption-29587f73-7711-41b8-a95d-ceb42d5f598a">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_modelling_physical_properties_2_Qvyu3BP.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> Jetski during the festival of lights</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 2" id="block-6fc97f07-124d-46bb-a8fb-39d74c3eaf92">
  <figure aria-labelledby="caption-6fc97f07-124d-46bb-a8fb-39d74c3eaf92">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_modelling_physical_properties_3_I8KO3kl.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> Walking on a pavement in Florida next to a two-lane road from one side and the sea on the other, during an approaching hurricane, with strong wind and waves splashing over the road. There is a railing on the left of the agent, separating them from the sea. The road goes along the coast, with a short bridge visible in front of the agent. Waves are splashing over the railing and onto the road one after another. Palm trees are bending in the wind. There is heavy rain, and the agent is wearing a rain coat. Real world, first-person.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 2" id="block-245112c4-0e91-4311-844a-f341a4be5398">
  <figure aria-labelledby="caption-245112c4-0e91-4311-844a-f341a4be5398">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_modelling_physical_properties_4_6dT1rge.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> Fast tracking real world video following a jellyfish swimming at high speed through the darkness of the deep sea between canyons covered in densely packed vent mussels with tiny white crabs crawling on them. Blurry hydrothermal vents in the distance spew thick, billowing plumes of vibrant blue, mineral-rich smoke from glowing rocky structures. Very dark, dim deep sea lighting, particles float in the cloudy ocean.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 2" id="block-030795d7-6f37-4866-beb3-9784132bf143">
  <figure aria-labelledby="caption-030795d7-6f37-4866-beb3-9784132bf143">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_modelling_physical_properties_5_1sm8u8o.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> A helicopter pilot carefully maneuvering over a coastal cliff with a small waterfall.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div></div>
  
</gdm-carousel>
                
              
                
                
                  
                  <hr>
                
              
                
                
                  
                  <div>
  <h3 data-block-key="wbu8i">Simulating the natural world</h3><p data-block-key="dr8gd">Generate vibrant ecosystems, from animal behaviors to intricate plant life.</p>
</div>
                
              
                
                
                  
                  


<gdm-carousel id="block-bc05a02a-a545-41b3-8795-62d152b86618">
  
  <div>
<div aria-label="Item 5" id="block-7ce58041-66f0-4125-ae19-3f529874688a">
  <figure aria-labelledby="caption-7ce58041-66f0-4125-ae19-3f529874688a">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_simulating_natural_world_1_KkDJNGE.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> Running by the shores of a glacial lake, exploring branching paths through the forest, crossing flowing mountain streams. Set amidst beautiful snow capped mountains and pine forest. Plentiful wildlife makes the journey a delight.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 5" id="block-5ed99f1c-ffb5-4e78-ace4-b51c8edefe5f">
  <figure aria-labelledby="caption-5ed99f1c-ffb5-4e78-ace4-b51c8edefe5f">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_simulating_natural_world_2_BJ3YgL8.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> Real world tracking shot swimming through deep dimly lit ocean between deep ocean canyons, densely packed vast school of jellyfish swimming, bioluminescent lighting.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 5" id="block-0ac1f2a3-6136-49e7-93df-a38677c5b5dc">
  <figure aria-labelledby="caption-0ac1f2a3-6136-49e7-93df-a38677c5b5dc">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_simulating_natural_world_3_gwzGBLr.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> This is a natural, real-world landscape designed as a Japanese zen garden. The scene is set in the early morning under a clear sky. Soft, warm sunlight illuminates the garden, casting long, gentle shadows. The ground is covered in fine, white sand that is raked into meticulous swirling patterns. A small, still pond is present, with pink water lilies floating on its surface. Smooth, grey rocks of various sizes are placed throughout the garden, some with green moss on their surfaces. Key structures include a stacked stone cairn and a traditional Japanese stone lantern. The entire area is enclosed by a tall bamboo fence in the background. The visual style is photorealistic, with high detail in the textures of the sand, stone, and lush green vegetation.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 5" id="block-5e81a48a-68a4-4cc6-8b5c-88a4fe9e1189">
  <figure aria-labelledby="caption-5e81a48a-68a4-4cc6-8b5c-88a4fe9e1189">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_simulating_natural_world_4_KmMnEoZ.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> The environment is a natural, real-world landscape, specifically a dense arrangement of lush, vibrant foliage. The leaves are broad and deeply textured, displaying an array of green hues from emerald to lime, interspersed with hints of yellow and red, suggesting a rich, healthy ecosystem. Abstract dappled light filters down from above, creating shifting patterns of illumination and shadow across the leaves, highlighting their intricate veins and varied surfaces. The atmosphere is serene and deeply immersive, evoking a sense of being within a vibrant, living natural world. Small water droplets are visible on some leaf surfaces, reflecting the ambient light. The background is a soft blur of similar foliage, emphasizing the foreground elements. The air appears humid and still.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div></div>
  
</gdm-carousel>
                
              
                
                
                  
                  <hr>
                
              
                
                
                  
                  <div>
  <h3 data-block-key="wbu8i">Modelling animation and fiction</h3><p data-block-key="dcth0">Tap into imagination, creating fantastical scenarios and expressive animated characters.</p>
</div>
                
              
                
                
                  
                  


<gdm-carousel id="block-0b6f1d8c-1b87-4c40-86fe-d5faf67c0988">
  
  <div>
<div aria-label="Item 8" id="block-64b19250-9187-4eb7-b5b1-24ddc6f45064">
  <figure aria-labelledby="caption-64b19250-9187-4eb7-b5b1-24ddc6f45064">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_modelling_animation_fiction_1_cTvKl3P.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> A vibrant 3D style, an adorable, fluffy creature bounding across a vibrant rainbow bridge in a fantastical landscape. The creature is small and compact, with fur that mimics the warm hues of a sunrise – oranges, yellows, and pinks blending seamlessly together. Its most striking feature is a pair of large, perked ears, shaped like those of a German Shepherd, adding a touch of playful contrast to its otherwise rounded form. As it runs on four short legs across the rainbow, its fur appears to ripple and flow, adding to its sense of dynamism and energy. The rainbow bridge arches gracefully through a whimsical landscape, perhaps filled with floating islands, glowing flora, and swirling clouds. The lighting is bright and cheerful, casting a warm glow on the creature and its surroundings. The overall impression is one of joy, wonder, and boundless energy, capturing the creature's playful spirit and the magical nature of the world it inhabits. This image evokes a sense of childlike whimsy and invites the viewer to imagine the adventures that await this charming creature in its fantastical realm.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 8" id="block-334ea4df-0e0f-4d4d-8446-4cb390db797d">
  <figure aria-labelledby="caption-334ea4df-0e0f-4d4d-8446-4cb390db797d">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_modelling_animation_fiction_2_RNg1ibH.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> Being a lizard, origami style</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 8" id="block-03e8584c-a8a4-41bf-aceb-2e29096871cc">
  <figure aria-labelledby="caption-03e8584c-a8a4-41bf-aceb-2e29096871cc">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_modelling_animation_fiction_3_ZXctgpq.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> A fantastical, wide-angle shot captures a lush, enchanted forest bathed in the soft glow of twilight. The player controls a large firefly flying through towering trees with vibrant foliage creating a dense canopy overhead, filtering the sunlight and casting dappled shadows on the forest floor. Nestled among the branches are a handful of charming tree houses, each glowing with a warm, inviting light. The tree houses vary in size and design, some resembling whimsical castles, others cozy cabins. Tiny details, like glowing windows and miniature balconies, add to their charm. A winding path, barely visible beneath the undergrowth, leads the viewer's eye deeper into the enchanted forest. The overall scene evokes a sense of wonder, tranquility, and the magic of childhood dreams.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 8" id="block-99192087-b0e2-4be4-9596-a81f5b1f5777">
  <figure aria-labelledby="caption-99192087-b0e2-4be4-9596-a81f5b1f5777">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_modelling_animation_fiction_4_DuLFEfx.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> A serene Irish landscape, with rolling emerald-green hills, misty lakes, and rugged mountains, suddenly trembles violently—as if the earth itself is being torn apart. In a moment of surreal chaos, entire sections of land rip free, rising into the sky in jagged, brutalist formations, their rocky undersides exposed like raw, fractured earth. The lakes are wrenched upward, now suspended in the sky, their waters spilling downward in colossal waterfalls, creating an apocalyptic storm of mist and rain over the land below. The camera pulls back, revealing a new impossible geography—mountains floating, cliffs inverted, rivers twisting mid-air—as gravity itself bends, turning the once-peaceful countryside into a brutalist, surreal monument to nature’s violent transformation.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div></div>
  
</gdm-carousel>
                
              
                
                
                  
                  <hr>
                
              
                
                
                  
                  <div>
  <h3 data-block-key="wbu8i">Exploring locations and historical settings</h3><p data-block-key="bkrrk">Transcend geographical and temporal boundaries to explore places and past eras.</p>
</div>
                
              
                
                
                  
                  


<gdm-carousel id="block-4cab3e39-d22b-47fb-92a9-846bb4186784">
  
  <div>
<div aria-label="Item 11" id="block-9b140acb-78a9-447f-8d4c-20ab136ef61c">
  <figure aria-labelledby="caption-9b140acb-78a9-447f-8d4c-20ab136ef61c">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_exploring_locations_1_OUxxXpK.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> A real world mountainous environment in the Alps. The landscape features steep, rocky cliffs and narrow gorges filled with loose scree and debris. The rock is predominantly grey and white, with patches of green vegetation clinging to the cliff faces. The top of the gorge opens up to a vista of dense evergreen forests and meadows. The overall theme is one of rugged, natural beauty and extreme terrain.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 11" id="block-b4bb6eb9-eed1-4ee2-96aa-3633951d10ee">
  <figure aria-labelledby="caption-b4bb6eb9-eed1-4ee2-96aa-3633951d10ee">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_exploring_locations_2_ryC3jcr.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> Venice by Vaporetto. The canals of Venice are recreated with painstaking detail. The water has realistic reflections and wakes. The buildings show crumbling plaster and centuries of weathering. The scene is populated with other gondolas, water taxis, and barges.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 11" id="block-a7c32395-2772-4d7c-8689-42572cda3ff0">
  <figure aria-labelledby="caption-a7c32395-2772-4d7c-8689-42572cda3ff0">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_exploring_locations_3_dlHXqb9.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> Exploring the palace of Knossos on Crete as it would have stood in its glorious heyday.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 11" id="block-9f40e5ba-079f-45b6-a26a-1442c28d7693">
  <figure aria-labelledby="caption-9f40e5ba-079f-45b6-a26a-1442c28d7693">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_exploring_locations_4_oZjNQYu.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> Walking around on a beautiful day out in Hinsdale, Illinois. Real world. There are cars parked. The person filming is standing on the sidewalk, there are flocks of birds flying overhead.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 11" id="block-070f8fe9-52f4-4f85-85ba-4c7b549e32cd">
  <figure aria-labelledby="caption-070f8fe9-52f4-4f85-85ba-4c7b549e32cd">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_exploring_locations_5_LKqlgO0.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> A biking enthusiast driving on a narrow road on an edge of a cliff in India, the Killar-Kishtwar Road. Real-world, first-person, only hands on handles visible.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div></div>
  
</gdm-carousel>
                
              
                
                
                  
                  <hr>
                
              
                
                
                  
                  <div>
  <h3 data-block-key="wbu8i">Pushing the frontier of real-time capabilities</h3><p data-block-key="1001j">Achieving a high degree of controllability and real-time interactivity in Genie 3 required significant technical breakthroughs. During the auto-regressive generation of each frame, the model has to take into account the previously generated trajectory that grows with time. For example, if the user is revisiting a location after a minute, the model has to refer back to the relevant information from a minute ago. To achieve real-time interactivity, this computation must happen multiple times per second in response to new user inputs as they arrive.</p>
</div>
                
              
                
                
                  
                  <div>
  <h3 data-block-key="apn2o">Environmental consistency over a long horizon</h3><p data-block-key="a0tgg">In order for AI generated worlds to be immersive, they have to stay physically consistent over long horizons. However, generating an environment auto-regressively is generally a harder technical problem than generating an entire video, since inaccuracies tend to accumulate over time. Despite the challenge, Genie 3 environments remain largely consistent for several minutes, with visual memory extending as far back as one minute ago.</p>
</div>
                
              
                
                
                  
                  


<gdm-carousel id="block-2338c9da-d003-40eb-9541-65621a0a7bb1">
  
  <div>
<div aria-label="Item 15" id="block-6e097311-816e-4176-8695-9117c3496c0b">
  <figure aria-labelledby="caption-6e097311-816e-4176-8695-9117c3496c0b">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_environmental_consistency_1_iNVUBuv.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> POV action camera of a tan house being painted by a first person agent with a paint roller</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 15" id="block-ce662459-2030-4c14-a575-df35b8a57f56">
  <figure aria-labelledby="caption-ce662459-2030-4c14-a575-df35b8a57f56">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_environmental_consistency_2_zS0EAgg.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> A Victorian street with a grey house. The grey house has a portal ringed by magical sparks. The portal leads to a vast desert filled with dunes, and that desert is visible from the outside. The agent can walk into the portal and is teleported to the desert.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 15" id="block-3dbaa10d-fbfe-4bb9-9aa7-d85048fb3732">
  <figure aria-labelledby="caption-3dbaa10d-fbfe-4bb9-9aa7-d85048fb3732">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_environmental_consistency_3_ccj4cHU.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> A classroom where on the blackboard at the front of the room it says GENIE-3 MEMORY TEST and underneath is a beautiful chalk picture of an apple, a mug of coffee, and a tree. The classroom is empty except for this. Outside the window are trees and a few cars driving past.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 15" id="block-5555c342-6995-4d49-ae78-2dc7971a53e8">
  <figure aria-labelledby="caption-5555c342-6995-4d49-ae78-2dc7971a53e8">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_environmental_consistency_4_gIb3IbS.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> This is a fantastical, whimsical forest environment. The lighting is bright and cheerful, suggesting a sunny day with dappled light filtering through a dense canopy of lush, oversized leaves. The air is clear and still. The ground is a soft, verdant carpet of moss and unusually large, brightly coloured mushrooms in shades of red and blue, their caps dotted with white. Winding dirt paths, well-trodden and narrow, weave between towering, ancient trees with smooth, grey bark. Interspersed throughout the forest are charming, mushroom-shaped houses, with intricate wooden doors and tiny, circular windows, each one unique in its design and colour palette, ranging from vibrant reds to gentle blues and greens. Various small, friendly forest creatures, such as colourful butterflies and tiny singing birds, flit amongst the foliage, adding to the lively atmosphere. There is an abundance of peculiar, oversized flowers blooming in an array of pastel and bright hues, releasing a gentle glow.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 15" id="block-4fa74576-2ab3-4a55-a4d2-c969a31984bb">
  <figure aria-labelledby="caption-4fa74576-2ab3-4a55-a4d2-c969a31984bb">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_environmental_consistency_5_OCdIbx8.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> An extremely enormous, realistic gorilla, draped in a flamboyant, emerald red vest with ornate brass buttons and an elaborate, feathered bicorne hat, brandishing only a vintage silk parasol, navigates a series of outrageously extravagant, moss-laden McMansions where grand marble structures are subtly embraced by sprawling, ancient rose bushes and creeping ivy.</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div>
<div aria-label="Item 15" id="block-34d3776a-7837-4d86-9192-64684008bd3b">
  <figure aria-labelledby="caption-34d3776a-7837-4d86-9192-64684008bd3b">
    <gdm-video-embed><video muted="" playsinline="" loop="" width="1280" height="704"><source src="https://deepmind.google/api/blob/website/media/genie_environmental_consistency_6_96KPmd3.mp4" type="video/mp4">
  </video></gdm-video-embed>
    <figcaption>
      <gdm-caption>
    <p data-block-key="qmqby"><strong>Prompt:</strong> Walking around ancient Athens, Greek architecture, marble</p>
    
    
  </gdm-caption>
    </figcaption>
  </figure>
</div></div>
  
</gdm-carousel>
                
              
                
                
                  
                  





<figure aria-labelledby="caption-a1bfba40-e2ee-436c-b3d3-7272a93d8666">
  

  <figcaption>
      <p data-block-key="w07ur"><i>The trees to the left of the building remain consistent throughout the interaction, even as they go in and out of view.</i></p>
    </figcaption>
</figure>
                
              
                
                
                  
                  <p data-block-key="wbu8i">Genie 3’s consistency is an emergent capability. Other methods such as NeRFs and Gaussian Splatting also allow consistent navigable 3D environments, but depend on the provision of an explicit 3D representation. By contrast, worlds generated by Genie 3 are far more dynamic and rich because they’re created frame by frame based on the world description and actions by the user.</p>
                
              
                
                
                  
                  





<figure aria-labelledby="caption-ddec9ea1-cb6f-4e51-967b-dffdcad93111">
  

  <figcaption>
      <gdm-caption>
    <p data-block-key="3r9m9"><strong>Prompt:</strong> First-person view drone video. High speed flight into and along a narrow canyon in Iceland with a river at the bottom and moss on the rocks, golden hour, realworld</p>
    
    
  </gdm-caption>
    </figcaption>
</figure>
                
              
                
                
                  
                  <hr>
                
              
                
                
                  
                  <div>
  <h3 data-block-key="wbu8i">Promptable world events</h3><p data-block-key="40ru4">In addition to navigational inputs, Genie 3 also enables a more expressive form of text-based interaction, which we refer to as <i>promptable world events</i>.</p><p data-block-key="7abeu">Promptable world events make it possible to change the generated world, like altering weather conditions or introducing new objects and characters, enhancing the experience from navigation controls.</p><p data-block-key="cirvr">This ability also increases the breadth of counterfactual, or “what if” scenarios, that can be used by agents learning from experience to handle unexpected situations.</p>
</div>
                
              
                
                
                  
                  <p data-block-key="du66g"><strong>Choose a world setting. Then, pick an event, and see Genie 3 create it.</strong></p>
                
              
                
                
                  
                  
                
              
                
                
                  
                  <hr>
                
              
            </div><div id="embodied-agent-research">
              
                
                
                  
                  <div>
  <h3 data-block-key="apn2o">Fueling embodied agent research</h3><p data-block-key="d857">To test the compatibility of Genie 3 created worlds for future agent training, we generated worlds for a recent version of our <a href="https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/" rel="noopener" target="_blank">SIMA agent</a>, our generalist agent for 3D virtual settings. In each world we instructed the agent to pursue a set of distinct goals, which it aims to achieve by sending navigation actions to Genie 3. Like any other environment, Genie 3 is not aware of the agent’s goal, instead it simulates the future based on the agent's actions.</p>
</div>
                
              
                
                
                  
                  <p data-block-key="du66g"><strong>Choose a world setting. Then, pick a goal you'd like an agent to achieve and watch how it accomplishes it.</strong></p>
                
              
                
                
                  
                  
                
              
                
                
                  
                  <p data-block-key="wbu8i">Since Genie 3 is able to maintain consistency, it is now possible to execute a longer sequence of actions, achieving more complex goals. We expect this technology to play a critical role as we push toward AGI, and agents play a greater role in the world.</p>
                
              
                
                
                  
                  


<gdm-carousel id="block-e703a0c8-b4b3-4935-bf81-e0806049082b">
  
  
  
</gdm-carousel>
                
              
                
                
                  
                  <hr>
                
              
            </div><div id="limitations">
  <h2 data-block-key="wbu8i">Limitations</h2><p data-block-key="ggqs">While Genie 3 pushes the boundaries of what world models can accomplish, it's important to acknowledge its current limitations:</p><ul><li data-block-key="61sd2"><strong>Limited action space</strong>. Although promptable world events allow for a wide range of environmental interventions, they are not necessarily performed by the agent itself. The range of actions agents can perform directly is currently constrained.</li><li data-block-key="bfsot"><strong>Interaction and simulation of other agents</strong>. Accurately modeling complex interactions between multiple independent agents in shared environments is still an ongoing research challenge.</li><li data-block-key="55slt"><strong>Accurate representation of real-world locations</strong>. Genie 3 is currently unable to simulate real-world locations with perfect geographic accuracy.</li><li data-block-key="4irvj"><strong>Text rendering.</strong> Clear and legible text is often only generated when provided in the input world description.</li><li data-block-key="1nt0m"><strong>Limited interaction duration.</strong> The model can currently support a few minutes of continuous interaction, rather than extended hours.</li></ul>
</div><div id="responsibility">
  <h2 data-block-key="swoy7">Responsibility</h2><p data-block-key="fit92">We believe foundational technologies require a deep commitment to responsibility from the very beginning. The technical innovations in Genie 3, particularly its open-ended and real-time capabilities, introduce new challenges for safety and responsibility. To address these unique risks while aiming to maximize the benefits, we have worked closely with our Responsible Development &amp; Innovation Team.</p><p data-block-key="29qra">At Google DeepMind, we're dedicated to developing our best-in-class models in a way that amplifies human creativity, while limiting unintended impacts. As we continue to explore the potential applications for Genie, we are announcing Genie 3 as a limited research preview, providing early access to a small cohort of academics and creators. This approach allows us to gather crucial feedback and interdisciplinary perspectives as we explore this new frontier and continue to build our understanding of risks and their appropriate mitigations. We look forward to working further with the community to develop this technology in a responsible way.</p>
</div><div id="next-steps">
              
                
                
                  
                  <div>
  <h2 data-block-key="swoy7">Next steps</h2><p data-block-key="5i4jt">We believe Genie 3 is a significant moment for world models, where they will begin to have an impact on many areas of both AI research and generative media. To that end, we're exploring how we can make Genie 3 available to additional testers in the future.</p><p data-block-key="2us9t">Genie 3 could create new opportunities for education and training, helping students learn and experts gain experience. Not only can it provide a vast space to train agents like robots and autonomous systems, Genie 3 can also make it possible to evaluate agents’ performance, and explore their weaknesses.</p><p data-block-key="b7jov">At every step, we’re exploring the implications of our work and developing it for the benefit of humanity, safely and responsibly.</p>
</div>
                
              
                
                
                  
                  

<section>
  
    <h2>Please cite using the following BibTex</h2>
  

  <ul>
    
      <li>
            <gemini-button data-in-view="">
              <a data-gtm-tag="cta-selection" href="https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/genie-3/genie3worldmodel2025.bib" rel="noopener" target="_blank">
      <span>Download BibTeX</span>
      
    </a>
            </gemini-button>
        </li>
        
    
  </ul>
</section>
                
              
                
                
                  
                  <div>
      <h2 data-block-key="vmhlu">Acknowledgments</h2><p data-block-key="dpcrj">Genie 3 was made possible due to key research and engineering contributions from Phil Ball, Jakob Bauer, Frank Belletti, Bethanie Brownfield, Ariel Ephrat, Shlomi Fruchter, Agrim Gupta, Kristian Holsheimer, Aleks Holynski, Jiri Hron, Christos Kaplanis, Marjorie Limont, Matt McGill, Yanko Oliveira, Jack Parker-Holder, Frank Perbet, Guy Scully, Jeremy Shar, Stephen Spencer, Omer Tov, Ruben Villegas, Emma Wang and Jessica Yung.</p><p data-block-key="1qkkl">We thank Andrew Audibert, Cip Baetu, Jordi Berbel, David Bridson, Jake Bruce, Gavin Buttimore, Sarah Chakera, Bilva Chandra, Paul Collins, Alex Cullum, Bogdan Damoc, Vibha Dasagi, Maxime Gazeau, Charles Gbadamosi, Woohyun Han, Ed Hirst, Ashyana Kachra, Lucie Kerley, Kristian Kjems, Eva Knoepfel, Vika Koriakin, Jessica Lo, Cong Lu, Zeb Mehring, Alex Moufarek, Henna Nandwani, Valeria Oliveira, Fabio Pardo, Jane Park, Andrew Pierson, Ben Poole, Helen Ran, Nilesh Ray, Tim Salimans, Manuel Sanchez, Igor Saprykin, Amy Shen, Sailesh Sidhwani, Duncan Smith, Joe Stanton, Hamish Tomlinson, Dimple Vijaykumar, Luyu Wang, Piers Wingfield, Nat Wong, Keyang Xu, Christopher Yew, Nick Young and Vadim Zubov for their invaluable partnership in developing and refining key components of this project.</p><p data-block-key="rr7r">Thanks to Tim Rocktäschel, Satinder Singh, Adrian Bolton, Inbar Mosseri, Aäron van den Oord, Douglas Eck, Dumitru Erhan, Raia Hadsell, Zoubin Gharamani, Koray Kavukcuoglu and Demis Hassabis for their insightful guidance and support throughout the research process.</p><p data-block-key="uevg">Feature video was produced by Suz Chambers, Matthew Carey, Alex Chen, Andrew Rhee, JR Schmidt, Scotch Johnson, Heysu Oh, Kaloyan Kolev, Arden Schager, Sam Lawton, Hana Tanimura, Zach Velasco, Ben Wiley, and Dev Valladares. Including samples generated by Signe Norly, Eleni Shaw, Andeep Toor, Gregory Shaw, and Irina Blok.</p><p data-block-key="7r9de">Finally, we extend our gratitude to Mohammad Babaeizadeh, Gabe Barth-Maron, Parker Beak, Jenny Brennan, Tim Brooks, Max Cant, Harris Chan, Jeff Clune, Kaspar Daugaard, Dumitru Erhan, Ashley Feden, Simon Green, Nik Hemmings, Michael Huber, Jony Hudson, Dirichi Ike-Njoku, Bonnie Li, Simon Osindero, Georg Ostrovski, Ryan Poplin, Alex Rizkowsky, Giles Ruscoe, Ana Salazar, Guy Simmons, Jeff Stanway, Metin Toksoz-Exley, Petko Yotov, Mingda Zhang and Martin Zlocha for their insights and support.</p>
    </div>
                
              
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Proxmox Virtual Environment 9.0 with Debian 13 released (119 pts)]]></title>
            <link>https://www.proxmox.com/en/about/company-details/press-releases/proxmox-virtual-environment-9-0</link>
            <guid>44798035</guid>
            <pubDate>Tue, 05 Aug 2025 13:57:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.proxmox.com/en/about/company-details/press-releases/proxmox-virtual-environment-9-0">https://www.proxmox.com/en/about/company-details/press-releases/proxmox-virtual-environment-9-0</a>, See on <a href="https://news.ycombinator.com/item?id=44798035">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p><strong>VIENNA, Austria – August 05, 2025 –</strong> Leading open-source server solutions provider Proxmox Server Solutions GmbH (henceforth "Proxmox"), celebrating its 20th year of innovation, today announced the release of Proxmox Virtual Environment (VE) 9.0. Main highlight of this update is a modernized core built upon Debian 13 “Trixie”, ensuring a robust foundation for the platform.</p>
<p>Proxmox VE 9.0 further introduces significant advancements in both storage and networking capabilities, addressing critical enterprise demands. A highlight is the long-awaited support for snapshots on thick-provisioned LVM shared storage, improving storage management capabilities especially for enterprise users with Fibre Channel (FC) or iSCSI SAN environments. With newly added “fabric” support for Software-Defined Networking (SDN), administrators can construct highly complex and scalable network architectures.</p>
<h2>Highlights in Proxmox Virtual Environment 9.0</h2>
<p>Debian 13 “Trixie” at the core</p>
<p>This core update is based on Debian 13 “Trixie”, bringing the latest Debian release as foundation for Proxmox VE including newer packages, improved hardware support, and enhanced security. Proxmox VE is using a newer Linux kernel 6.14.8-2 as stable default enhancing hardware compatibility and performance.&nbsp;</p>
<p>Also, updates to the latest versions of leading open-source technologies for virtual environments like QEMU 10.0.2, LXC 6.0.4, Ceph Squid 19.2.3, and ZFS 2.3.3 are included. ZFS now supports adding new devices to existing RAIDZ pools with minimal downtime. For existing users of Proxmox VE 8.4 or older versions, an extensively tested and detailed upgrade path is available to enable a smooth upgrade.</p>
<p>Snapshots for thick-provisioned LVM shared storage</p>
<p>Virtual Machines (VMs) utilizing thick-provisioned LVM shared storages, such as those backed by iSCSI or FC-based SANs, now benefit from snapshot functionality out of the box. This is achieved by implementing snapshots as volume chains, where a volume based on a snapshot only records differences to its parent snapshot volume. Directory, NFS, and CIFS storages also gain additional support for snapshots as volume chains.</p>
<p>This new feature provides a powerful and highly requested capability for customers with traditional SAN infrastructure who have historically relied on clustered file systems. While direct integrations from many storage vendors continue to grow, this new feature closes the gap by providing a storage-independent solution for snapshots. This gives customers the independence to seamlessly manage their snapshots regardless of their hardware, without compromising on convenience.</p>
<p>New Fabrics feature for the SDN stack</p>
<p>This release enhances the SDN capabilities with the introduction of an SDN Fabrics feature, designed to simplify the configuration and management of complex routed networks. Engineered for reliability, SDN Fabrics facilitates multiple paths between nodes and automatic failover across Network Interface Cards (NICs), enabling the configuration of robust two-layer spine-leaf architectures for improved network redundancy and performance.</p>
<p>This new feature simplifies the management of dynamically routed networks which can for example be used as Ethernet VPN (EVPN) underlay or full-mesh networks for Ceph. The SDN stack in Proxmox VE gains support for two different routing protocols, OpenFabric and OSPF, and provides intuitive tools for the simplified configuration and precise management of those dynamic routing protocols.</p>
<p>Affinity rules in High Availability (HA) clusters</p>
<p>The Proxmox team introduces HA resource affinity rules to enable fine-grained control and flexibility over resource placement in HA clusters, ensuring optimal performance, enhanced resiliency, and minimized latency for critical workloads. To better control complex, interconnected applications, the new HA Resource Affinity Rules allow administrators to precisely define how virtual machines and other HA resources are distributed across a cluster.</p>
<p>Interdependent HA resources, such as for example an application server and its associated database, can be kept together on the same physical node to minimize network latency. For services requiring maximum redundancy, like multiple VMs running the same mission-critical application, the rules can ensure these instances are kept on different nodes. This increases fault tolerance and ensures resiliency even during HA failovers.</p>
<p>Enhanced mobile interface</p>
<p>The Proxmox VE mobile interface has been thoroughly reworked, using the new Proxmox widget toolkit powered by the Rust-based Yew framework. The redesigned interface provides quick access to service overviews and includes essential management functions, including starting and stopping virtual guests and basic configuration. It is now easier than ever for users to access fundamental functionalities of Proxmox VE directly from their mobile browsers.</p>
<h3>Availability</h3>
<p>Proxmox VE 9.0 is available for download.&nbsp;The ISO contains the complete feature-set and can be installed on bare-metal. The virtualization platform from Proxmox comes stocked with all the essential management tools, as well as an easy-to-use, web-based user interface. This allows for simple, out-of-the-box management of the host, either through the command line or a standard web browser.</p>
<p>Seamless upgrade instructions from Proxmox VE 8 to 9 are available. It’s also possible to install Proxmox VE 9.0 on top of Debian.</p>
<p>License: Proxmox Virtual Environment is free and open-source software, published under the GNU Affero General Public License, v3.<br>Support Subscriptions: For enterprise users, Proxmox Server Solutions GmbH offers a subscription-based support model, which provides access to the extensively tested Enterprise Repository, with regular updates via the web interface, as well as technical support on a subscription basis. Prices start at EUR 115 per year and CPU.</p>
<p>Resources:</p>
<ul>
<li>ISO Image Download: <a href="https://www.proxmox.com/downloads">https://www.proxmox.com/downloads</a></li>
<li>Roadmap:&nbsp;For published and upcoming features, see the <a href="https://pve.proxmox.com/wiki/Roadmap#Roadmap">Release Notes &amp; Roadmap</a></li>
<li>Video: <a href="https://www.proxmox.com/en/services/training-courses/videos/proxmox-virtual-environment/whats-new-in-proxmox-ve-9-0">What's new in Proxmox VE 9.0</a></li>
</ul>
<p><a href="https://www.proxmox.com/"></a>###</p>
<p><strong>Facts</strong><br>The open-source project Proxmox VE has a huge worldwide user base with more than 1.6 million hosts. The virtualization platform has been translated into over 31 languages. More than 225,000 community members in the support forum engage with and help each other. By using Proxmox VE as an alternative to proprietary virtualization management solutions, enterprises are able to centralize and modernize their IT infrastructure, and turn it into a cost-effective and flexible software-defined data center, based on the latest open-source technologies. Tens of thousands of customers rely on enterprise support subscriptions from Proxmox Server Solutions GmbH.</p>
<p><strong>About Proxmox Server Solutions</strong><br>Proxmox provides powerful and user-friendly open-source server software. For 20 years, enterprises of all sizes and industries use the Proxmox solutions to deploy efficient and simplified IT infrastructures, minimize total cost of ownership, and avoid vendor lock-in. Proxmox also offers commercial support, training services, and an extensive partner ecosystem to ensure business continuity for its customers. Proxmox Server Solutions GmbH was established in 2005 and is headquartered in Vienna, Austria.</p>
<p>Contact:&nbsp;Daniela Häsler, Proxmox Server Solutions GmbH, marketing@proxmox.com</p>    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lack of intent is what makes reading LLM-generated text exhausting (112 pts)]]></title>
            <link>https://lambdaland.org/posts/2025-08-04_artifical_inanity/</link>
            <guid>44797917</guid>
            <pubDate>Tue, 05 Aug 2025 13:46:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lambdaland.org/posts/2025-08-04_artifical_inanity/">https://lambdaland.org/posts/2025-08-04_artifical_inanity/</a>, See on <a href="https://news.ycombinator.com/item?id=44797917">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      

      
      
<article>
  
  
  <h5>4 Aug 2025</h5>



  

  
  
  



<p>There’s something icky about LLM-generated text when you think it’s written by a human. I think I finally put my finger on one reason why I feel this way.</p>
<p>Note on the title: “Artificial Inanity” comes from Neal Stephenson’s novel <em>Anathem</em>.</p>
<p>At work I was sent a long design document and asked for my thoughts on it. As I read, I had a really hard time following it. Eventually I guessed correctly (confirmed via a follow-up conversation I had with the “author”<label for="sn1"></label>

<span>
I have “author” in quotes because, if a machine wrote it, you don’t merit being called the <em>author</em> of the work.
</span>
) that an LLM had generated the majority of the document. Parts of it <em>sounded</em> like a decent design document, but there was just way too much fluff that served only to confuse me.</p>
<p>When I read technical documents, I read to understand the content. In this mode of reading, I operate under the assumption that the author had a reason for choosing the words they did, and that every sentence is there to convey something that the author wishes me to understand.</p>
<p>This mode fails when an LLM or the like has generated the text. When I read something I know came out of a computer’s probabilistic sampling of a token-space, I have read knowing that every statement might be some hallucinated slop or incidental filler. I <em>cannot</em> trust that the human operator’s intent is expressed by the machine. In fact, I am confident that it is often <em>not</em>, but I have to waste tremendous effort trying to find that gap. Reading slop text when I think I’m reading real text is exhausting: since I am not on the alert for hallucinations or irrelevancies, every turn of phrase that seems out of place causes me to wonder <em>why that phrase it there</em> and <em>what am I missing</em> when in reality, such questions are ill formed: that was just a phrase composed by accident that <em>sounds</em> good but actually is devoid of much intent at all.</p>
<p><em>Intent</em> is the core thing: the <em>lack</em> of intent is what makes reading AI-slop so revolting. There needs to be a human intent—human will and human care—behind everything that is demanded of our care and attention. Even if you agree with Rolland Barthes’<label for="sn2"></label>

<span>
The author of <em>The Death of the Author</em>, an essay where Barthes argues that focusing on the author’s intent is fruitless—the meaning of a text is the effect it has on the audience.
</span>
views on literary criticism, the fact that there <em>is</em> an author who put care and intent into a work imbues that work with infinitely more meaning than if it were spat out by a machine.</p>
<p>Counterfeits to human connection will—unfortunately—always be in demand. The multi-billion dollar industry churning out pornography is proof enough. People will probably always, from here on out, be using LLMs to cheat their way through classes and themselves out of learning. Some might turn to them for some faux-companionship. Others will be prompting themselves to death by offloading more and more of their reasoning to machines, convinced that the computer—like a slot machine—somehow will let them win bigger in life.</p>
<p>I am <strong>not</strong> saying that LLMs are worthless—they are marvels of engineering and can solve some particularly thorny problems that have confounded us for decades. But it’s important to remember that, no matter how capable these machines get, they are not humans. And no human is so worthless as to be replaceable with a machine.</p></article>
 
      

      

      
  
  
  
 

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TSMC says employees tried to steal trade secrets on iPhone 18 chip process (190 pts)]]></title>
            <link>https://9to5mac.com/2025/08/05/tsmc-says-employees-tried-to-steal-trade-secrets-on-iphone-18-chip-process/</link>
            <guid>44797408</guid>
            <pubDate>Tue, 05 Aug 2025 12:53:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://9to5mac.com/2025/08/05/tsmc-says-employees-tried-to-steal-trade-secrets-on-iphone-18-chip-process/">https://9to5mac.com/2025/08/05/tsmc-says-employees-tried-to-steal-trade-secrets-on-iphone-18-chip-process/</a>, See on <a href="https://news.ycombinator.com/item?id=44797408">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
	<img width="1600" height="800" src="https://9to5mac.com/wp-content/uploads/sites/6/2025/08/TSMC-says-employees-tried-to-steal-trade-secrets-on-iPhone-18-chip-process.jpg?quality=82&amp;strip=all&amp;w=1600" alt="TSMC says employees tried to steal trade secrets on iPhone 18 chip process | Photo shows the inside of a hard drive" srcset="https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2025/08/TSMC-says-employees-tried-to-steal-trade-secrets-on-iPhone-18-chip-process.jpg?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2025/08/TSMC-says-employees-tried-to-steal-trade-secrets-on-iPhone-18-chip-process.jpg?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2025/08/TSMC-says-employees-tried-to-steal-trade-secrets-on-iPhone-18-chip-process.jpg?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2025/08/TSMC-says-employees-tried-to-steal-trade-secrets-on-iPhone-18-chip-process.jpg?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high"></figure>

<p><a href="https://9to5mac.com/guides/aapl/" target="_blank" rel="noreferrer noopener">Apple</a> chipmaker <a href="https://9to5mac.com/guides/tsmc/" target="_blank" rel="noreferrer noopener">TSMC</a> has said that several then-employees tried to steal trade secrets relating to the company’s most advanced chip process. TSMC fired the individuals concerned and is now taking legal action against them. The former employees may also face criminal prosecution.</p>



<p>The report relates to the company’s 2-nanometer chip process, which is expected to be used for the A20 chips across next year’s <a href="https://9to5mac.com/guides/iphone-18/" target="_blank" rel="noreferrer noopener">iPhone 18</a> lineup …</p>



<h2 id="h-tsmc-2nm-process-expected-to-debut-in-iphone-18">TSMC 2nm process expected to debut in iPhone 18</h2>



<p>TSMC leads the world in the most advanced chip processes, and is next year expected to use its 2nm technology <a href="https://9to5mac.com/2025/06/03/apples-a20-chip-packaging-breakthrough/" target="_blank" rel="noreferrer noopener">for the A20 chips</a> used in the iPhone 18 range. Apple typically gets access to TSMC’s most advanced chip processes ahead of the company’s other customers.</p>



<p>Apple analyst Ming-Chi Kuo has suggested that the new chip will be <a href="https://9to5mac.com/2025/03/22/apple-iphone-18-2nm-a20-chip-kuo/" target="_blank" rel="noreferrer noopener">used for all iPhone 18 models</a>, not just the two Pro ones.</p>



<h2 id="h-tsmc-says-employees-tried-to-steal-trade-secrets">TSMC says employees tried to steal trade secrets</h2>



<p><em><a href="https://asia.nikkei.com/business/technology/tsmc-fires-workers-for-breaching-data-rules-on-cutting-edge-chip-tech" target="_blank" rel="noreferrer noopener">Nikkei Asia</a></em> reports that TSMC accused several former employees of attempting to obtain secret information about its 2nm chip development and production process.</p>



<blockquote>
<p>Several former employees of TSMC are suspected of attempting to obtain critical proprietary information on 2-nanometer chip development and production while working at the company, according to multiple sources familiar with the matter.</p>



<p>In response to Nikkei Asia’s questions, TSMC said that it recently “detected unauthorized activities during routine monitoring, leading to the discovery of potential trade secret leaks.”</p>



<p>The world’s top chipmaker said on Monday it took “strict disciplinary actions against the personnel involved and has initiated legal proceedings.”</p>
</blockquote>



<p>The attempt was detected by spotting “unusual access patterns” on the part of one of the employees.</p>



<p>The report says there could even be national security implications, as the Taiwanese government takes extremely seriously the protection of advanced technology developed within the country. Prosecutors have confirmed that they are investigating, and TSMC says that it will seek prosecution to the fullest extent of the law.</p>



<p>No details have been shared on the nature of the information obtained. It is likely that it relates to the 2nm process in general rather than anything specific to Apple’s A20 chip.</p>



<h4 id="h-highlighted-accessories">Highlighted accessories</h4>



<ul>
<li><a href="https://amzn.to/3UaJjDn" target="_blank" rel="noreferrer noopener">Official Apple Store on Amazon</a></li>



<li><a href="https://www.amazon.com/Anker-Charger-Compact-Technology-Included/dp/B0CP7NWH6L?tag=blovejoy-20" target="_blank" rel="noreferrer noopener">Anker 511 Nano Pro ultra-compact iPhone charger</a></li>



<li><a href="https://www.amazon.com/Spigen-Compatible-Accessories-Anti-Yellowing-Military-Grade/dp/B0DKGBTVHW?tag=blovejoy-20" target="_blank" rel="noreferrer noopener">Spigen MagFit case for iPhone 16e – adds MagSafe support</a></li>



<li><a href="https://www.amazon.com/Apple-MagSafe-Charger-Capability-Compatible/dp/B0DGJ4QQ5W?tag=blovejoy-20" target="_blank" rel="noreferrer noopener">Apple MagSafe Charger with 25w power for iPhone 16 models</a></li>



<li><a href="https://www.amazon.com/Apple-30W-USB-C-Power-Adapter/dp/B0CX23PHFD?tag=blovejoy-20" target="_blank" rel="noreferrer noopener">Apple 30W charger for above</a></li>



<li><a href="https://www.amazon.co.uk/dp/B0C4FDJ8F7?tag=blovejoy-20" target="_blank" rel="noreferrer noopener">Anker 240W braided USB-C to USB-C cable</a></li>
</ul>



<p><em>Photo by&nbsp;<a href="https://unsplash.com/@heapdump?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Patrick Lindenberg</a>&nbsp;on&nbsp;<a href="https://unsplash.com/photos/photo-of-optical-disc-drive-1iVKwElWrPA?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash">Unsplash</a></em></p>
	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBggKMLOFATDAGg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add 9to5Mac to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://9to5mac.com/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Build Your Own Lisp (162 pts)]]></title>
            <link>https://www.buildyourownlisp.com/</link>
            <guid>44796953</guid>
            <pubDate>Tue, 05 Aug 2025 11:55:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.buildyourownlisp.com/">https://www.buildyourownlisp.com/</a>, See on <a href="https://news.ycombinator.com/item?id=44796953">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
<h2>
  Build Your Own Lisp<br>
  <small>Learn C and build your own programming language in 1000 lines of code!</small>
</h2>

<p><img src="https://www.buildyourownlisp.com/static/img/lovelace.png" alt="lovelace" width="275px" height="395px">
</p>

<hr>

<p>If you're looking to learn C, or you've ever wondered how to build your own programming language, this is the book for you.</p>

<p>In just a few lines of code, I'll teach you how to use C, and together, we'll start building your very own language.</p>

<p>Along the way we'll learn about the weird and wonderful nature of Lisps, how to develop a real-world project, concisely solve problems, and write beautiful code!</p>

<p>This book is free to read online, so you can get started right away! But for those who want to show their support, or who want the best reading experience, this book is also available for purchase in print format, or for cheap in all major e-book formats.</p>






<!--
<p>If you want to show support, I also accept donations in the following formats...</p>

<table cellpadding='10'>
  <tr><td><em>Bitcoin</em></td>    <td><code><small>17WQM2WYt28j6pNYZvUcRsozG87wCwPhmp</small></code></td></tr>
  <tr><td><em>Dogecoin</em></td>   <td><code><small>D5Tozp7epcLZCfN3zU9x51cM7uZD72PbwU</small></code></td></tr>
  <tr><td><em>Real Money &trade;</em></td>
    <td style='text-align:center;'>
      <form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_top">
      <input type="hidden" name="cmd" value="_s-xclick">
      <input type="hidden" name="hosted_button_id" value="AJYFXLPVF8S72">
      <button type="submit" name="submit" class="btn btn-large btn-primary" >Donate</button>
      </form>
    </td>
  </tr>
</table>
-->

<table>

  <tbody><tr>
    <td><em>"I finally feel complete as a C programmer, having implemented my own Lisp."</em></td>
    <td><em>"Every programmer should do something like this, at least once."</em></td>
    <td><em>"One of the greatest things I've ever found on the internet..."</em></td>
  </tr>
  
  <tr>
    <td><a href="https://twitter.com/hirojin">@hirojin</a></td>
    <td><a href="https://twitter.com/mattcaldwell">@mattcaldwell</a></td>
    <td><a href="https://twitter.com/euryadam">@euryadam</a></td>
  </tr>
  
</tbody></table>




         </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scientific fraud has become an 'industry,' alarming analysis finds (117 pts)]]></title>
            <link>https://www.science.org/content/article/scientific-fraud-has-become-industry-alarming-analysis-finds</link>
            <guid>44796526</guid>
            <pubDate>Tue, 05 Aug 2025 10:56:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/article/scientific-fraud-has-become-industry-alarming-analysis-finds">https://www.science.org/content/article/scientific-fraud-has-become-industry-alarming-analysis-finds</a>, See on <a href="https://news.ycombinator.com/item?id=44796526">Hacker News</a></p>
Couldn't get https://www.science.org/content/article/scientific-fraud-has-become-industry-alarming-analysis-finds: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[uBlock Origin Lite now available for Safari (668 pts)]]></title>
            <link>https://apps.apple.com/cn/app/ublock-origin-lite/id6745342698</link>
            <guid>44795825</guid>
            <pubDate>Tue, 05 Aug 2025 09:01:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apps.apple.com/cn/app/ublock-origin-lite/id6745342698">https://apps.apple.com/cn/app/ublock-origin-lite/id6745342698</a>, See on <a href="https://news.ycombinator.com/item?id=44795825">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="" data-test-bidi=""><p>uBO Lite (uBOL) 是一个基于最新浏览器扩展接口（Manifest Version 3）打造的的内容屏蔽工具。</p><p>该扩展预设的规则列表对应 uBlock Origin 的预设过滤规则列表：</p><p>- uBlock Origin 内置过滤规则列表<br>- EasyList<br>- EasyPrivacy<br>- Peter Lowe 的广告和跟踪服务器列表</p><p>访问选项页面，点击弹出面板中的 _齿轮_ 图标，即可启用更多规则集。</p><p>uBOL 的过滤规则是完全声明式的，并不需要固定保留一个 uBOL 扩展进程，基于 CSS/JS 注入的内容过滤更是交由浏览器进行调度，比起扩展本身更为可靠。 这也即是说当内容被过滤时 uBOL 自身并不占用额外 CPU 和内存资源，_只有_在您打开弹出面板或是设置页面时才会生成 uBOL 扩展进程。</p></div><section>
  <div>
    <h2>
      App 隐私
    </h2>

    


  </div>

  <p>
    开发者“<span>Raymond Hill</span>”已表明该 App 的隐私规范可能包括了下述的数据处理方式。有关更多信息，请参阅<a href="https://github.com/uBlockOrigin/uBOL-home/wiki/Privacy-policy">开发者隐私政策</a>。
  </p>

  <div>
        
        <h3>未收集数据</h3>
        <p>开发者不会从此 App 中收集任何数据。</p>
<!---->      </div>

    <p>隐私处理规范可能基于你使用的功能或你的年龄等因素而有所不同。<a href="https://apps.apple.com/story/id1538632801">了解更多</a></p>
</section><section>
  <div>
    <h2>信息</h2>
    <dl>
        <p>
          <dt>提供者</dt>
          <dd>
              Raymond Hill
          </dd>
        </p>
        <p>
          <dt>大小</dt>
          <dd aria-label="5.8 MB">5.8 MB</dd>
        </p>
        <p>
          <dt>类別</dt>
          <dd>
              <a href="https://itunes.apple.com/cn/genre/id6002" data-metrics-click="{&quot;actionType&quot;:&quot;navigate&quot;,&quot;actionUrl&quot;:&quot;https://itunes.apple.com/cn/genre/id6002&quot;,&quot;targetType&quot;:&quot;link&quot;,&quot;targetId&quot;:&quot;GenrePage&quot;}">
                工具
              </a>
          </dd>
        </p>
      <div>
        <dt>兼容性</dt>
          <dd>
              <dl>
                <dt>
                  iPhone
                </dt>
                <dd>设备需装有 iOS 18.0 或更高版本。
                </dd>
              </dl>
              <dl>
                <dt>
                  iPad
                </dt>
                <dd>设备需装有 iPadOS 18.0 或更高版本。
                </dd>
              </dl>
              <dl>
                <dt>
                  Mac
                </dt>
                <dd>设备需装有 macOS 15.0 或更高版本。
                </dd>
              </dl>
              <dl>
                <dt>
                  Apple Vision
                </dt>
                <dd>设备需装有 visionOS 2.0 或更高版本。
                </dd>
              </dl>
          </dd>
      </div>
<!---->      
      
<!---->      <p>
        <dt>Copyright</dt>
        <dd>© Raymond Hill 2022</dd>
      </p>
        <p>
          <dt>价格</dt>
          <dd>免费</dd>
        </p>
<!---->
    </dl>
  </div>
  <div>
    <ul>
<!---->        <li>
          <a data-metrics-click="{&quot;actionType&quot;:&quot;navigate&quot;,&quot;targetType&quot;:&quot;link&quot;,&quot;targetId&quot;:&quot;LinkToAppSupport&quot;}" href="https://github.com/uBlockOrigin/uBOL-home">
            App 支持
          </a>
        </li>
        <li>
          <a data-metrics-click="{&quot;actionType&quot;:&quot;navigate&quot;,&quot;targetType&quot;:&quot;link&quot;,&quot;targetId&quot;:&quot;LinkToPrivacyPolicy&quot;}" href="https://github.com/uBlockOrigin/uBOL-home/wiki/Privacy-policy">
            隐私政策
          </a>
        </li>
<!----><!---->    </ul>
  </div>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apache ECharts 6 (175 pts)]]></title>
            <link>https://echarts.apache.org/handbook/en/basics/release-note/v6-feature/</link>
            <guid>44794926</guid>
            <pubDate>Tue, 05 Aug 2025 06:33:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://echarts.apache.org/handbook/en/basics/release-note/v6-feature/">https://echarts.apache.org/handbook/en/basics/release-note/v6-feature/</a>, See on <a href="https://news.ycombinator.com/item?id=44794926">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article> <p>Twelve years ago, ECharts was first released on GitHub, planting the seed for an open-source journey.</p> <p>From a simple charting tool to a visualization powerhouse supporting millions of developers; from a single front-end charting library to a comprehensive technology system covering mobile, large screens, and server-side rendering—over these 12 years, we've witnessed ECharts' continuous technical breakthroughs and have been delighted to see developers worldwide create countless stunning data stories with ECharts.</p> <p>Now, Apache ECharts 6.0 is officially released, bringing 12 major upgrades to take your data visualization to the next level.</p> <h2 id="feature-overview" tabindex="-1">Feature Overview</h2> <p>Twelve years of accumulation, all for more ultimate visual expression. The core strength of Apache ECharts has always come from a deep understanding of developers' real challenges. When defining the direction for 6.0, the question was clear: <strong>How can we make complex data presentation both powerful and elegant?</strong></p> <p>This drove us to evolve deeply around three core dimensions:</p> <ul><li><strong>More professional visual presentation</strong>: From a meticulously crafted default theme to intelligent dark mode switching, ensuring charts have a professional look and seamlessly integrate into modern applications.</li> <li><strong>Expanding the boundaries of data expression</strong>: New chart types and features to handle complex scenarios and enable intuitive expression of deep data.</li> <li><strong>Unleashing freedom of composition</strong>: From the revolutionary matrix coordinate system to reusable custom series and optimized axis labels—empowering developers to freely compose and turn creativity into unconstrained visual works.</li></ul> <p>We have made 12 upgrades across these three core dimensions. These are not just simple feature additions, but a solid foundation for building the next generation of data-driven applications. They all point to one goal: <strong>to make ECharts powerful, reliable, and stable in the background, leaving the stage and spotlight for your creative expression.</strong></p> <p>Below, we introduce these twelve upgrades in detail:</p> <ul><li><strong>More professional visual presentation</strong> <ul><li><strong>1. Brand New Default Theme</strong>: Modern design language for professional data expression</li> <li><strong>2. Dynamic Theme Switching</strong>: Seamless runtime theme switching for multi-theme scenarios</li> <li><strong>3. Dark Mode Support</strong>: Automatically adapts to system dark/light mode for better UX</li></ul></li> <li><strong>Expanding the boundaries of data expression</strong> <ul><li><strong>4. New Chord Chart</strong>: Visualize complex relationships and distributions</li> <li><strong>5. New Beeswarm Chart</strong>: Smartly expand overlapping data points into a honeycomb layout</li> <li><strong>6. New Scatter Jittering</strong>: Add jitter to scatter plots for better readability of dense data</li> <li><strong>7. New Broken Axis</strong>: Easily present data with large magnitude differences</li> <li><strong>8. Enhanced Stock Trading Charts</strong>: Improved label capabilities and more out-of-the-box trading charts</li></ul></li> <li><strong>Unleashing freedom of composition</strong> <ul><li><strong>9. New Matrix Coordinate System</strong>: Freely combine chart types and components like a table</li> <li><strong>10. Enhanced Custom Series</strong>: Support npm publishing and dynamic registration for code reuse</li> <li><strong>11. New Custom Charts</strong>: Violin, contour, stage, bar range, and line range charts</li> <li><strong>12. Axis Label Optimization</strong>: Smarter default axis label layout to prevent overflow and overlap</li></ul></li></ul> <p>With these upgrades, Apache ECharts 6.0 helps users create more charts more flexibly and conveniently, truly achieving "unlimited possibilities in charting"!</p> <h2 id="feature-details" tabindex="-1">Feature Details</h2> <h3 id="1.-brand-new-default-theme" tabindex="-1">1. Brand New Default Theme</h3> <p>During the development of ECharts 6.0, we analyzed real user scenarios and found that over 70% of developers use the default theme. This made us realize: an excellent default theme should not only be aesthetically pleasing but also meet the general needs of various business scenarios.</p> <p>The new theme system uses design tokens to reconstruct colors, spacing, and other design elements, <strong>making different chart types and components more harmonious and consistent</strong>.</p> <img data-src="images/feature-v6/1-default-theme.png" width="600px" src="https://echarts.apache.org/handbook/images/feature-v6/1-default-theme.png"> <p>Although the 6.0 theme has significant changes from 5.x, we provide a <a href="https://github.com/apache/echarts/blob/master/theme/v5.js">v5.js</a> theme file for developers who want to use new features but keep the old style for quick migration.</p> <h3 id="2.-dynamic-theme-switching" tabindex="-1">2. Dynamic Theme Switching</h3> <p>In previous versions, changing a chart's theme required disposing of the chart instance and re-initializing, which could negatively impact user experience due to repeated animations. In the new version, we implemented <strong>dynamic theme switching</strong> (see documentation), significantly improving the user experience.</p> <img data-src="images/feature-v6/2-switch-themes.gif" width="600px"> <h3 id="3.-dark-mode-support" tabindex="-1">3. Dark Mode Support</h3> <p>With dynamic theme registration and switching, a typical scenario is <strong>listening to the system's dark mode and dynamically adjusting the chart's theme</strong>.</p> <img data-src="images/feature-v6/3-responsive-themes.gif" width="600px"> <p>This is crucial for business scenarios supporting dark mode, ensuring the application interface matches the system theme and greatly enhancing user experience.</p> <p>Here's how to listen for system dark mode and change the chart theme:</p> <div><pre><code><span>const</span> darkModeMediaQuery <span>=</span> window<span>.</span><span>matchMedia</span><span>(</span><span>'(prefers-color-scheme: dark)'</span><span>)</span><span>;</span>
<span>function</span> <span>updateDarkMode</span><span>(</span><span>)</span> <span>{</span>
    <span>const</span> isDarkMode <span>=</span> darkModeMediaQuery<span>.</span>matches<span>;</span>
    <span>for</span> <span>(</span><span>const</span> chart <span>of</span> charts<span>)</span> <span>{</span>
        chart<span>.</span><span>setTheme</span><span>(</span>isDarkMode <span>?</span> <span>'dark'</span> <span>:</span> <span>'default'</span><span>)</span><span>;</span>
    <span>}</span>
<span>}</span>
darkModeMediaQuery<span>.</span><span>addEventListener</span><span>(</span><span>'change'</span><span>,</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>updateDarkMode</span><span>(</span><span>)</span><span>;</span>
<span>}</span><span>)</span><span>;</span></code></pre></div> <h3 id="4.-new-chord-chart" tabindex="-1">4. New Chord Chart</h3> <p>Chord charts intuitively show flows and weights in complex relationship networks, ideal for scenarios like financial transactions and social networks. ECharts innovatively supports <strong>using gradient colors from source and target nodes for edges, creating unique visual effects</strong>. See <a href="https://echarts.apache.org/option.html#series-chord">series-chord</a>.</p> <img data-src="images/feature-v6/4-chord.gif" width="600px"> <h3 id="5.-new-beeswarm-chart" tabindex="-1">5. New Beeswarm Chart</h3> <p>Traditional scatter plots can become overcrowded on category axes. Beeswarm charts use non-numeric axis offsets to <strong>distribute points without overlap while preserving value axis accuracy</strong>. Set <a href="https://echarts.apache.org/option.html#xAxis.jitter">jitter</a> to a non-zero value and <a href="https://echarts.apache.org/option.html#xAxis.jitterOverlap">jitterOverlap</a> to <code>false</code> to enable beeswarm charts.</p> <img data-src="images/feature-v6/5-beeswarm.png" width="600px" src="https://echarts.apache.org/handbook/images/feature-v6/5-beeswarm.png"> <h3 id="6.-new-scatter-jittering" tabindex="-1">6. New Scatter Jittering</h3> <p>Scatter jittering adds random offsets to non-data dimensions, <strong>solving the problem of overly dense data points</strong>.</p> <p>Without jittering, it's hard to see the distribution when data is dense:</p> <img data-src="images/feature-v6/6-jittering-off.png" width="600px" src="https://echarts.apache.org/handbook/images/feature-v6/6-jittering-off.png"> <p>With jittering enabled, the densest range (6-8) becomes clear. Compared to beeswarm, scatter jittering offers better performance.</p> <img data-src="images/feature-v6/6-jittering-on.png" width="600px" src="https://echarts.apache.org/handbook/images/feature-v6/6-jittering-on.png"> <p>Set <a href="https://echarts.apache.org/option.html#xAxis.jitter">jitter</a> to a non-zero value and <a href="https://echarts.apache.org/option.html#xAxis.jitterOverlap">jitterOverlap</a> to <code>true</code> to enable scatter jittering.</p> <h3 id="7.-new-broken-axis" tabindex="-1">7. New Broken Axis</h3> <p>Broken axis is a visualization technique for showing data with large magnitude differences. In ECharts 6.0, we innovatively implemented a <strong>torn-paper effect for broken axes</strong>, making the meaning more intuitive, and supporting click-to-expand to restore the real data ratio.</p> <img data-src="images/feature-v6/7-break-axis.gif" width="600px"> <h3 id="8.-enhanced-stock-trading-charts" tabindex="-1">8. Enhanced Stock Trading Charts</h3> <p>ECharts 6.0 deeply optimizes for financial trading scenarios, enhancing label positioning relative to coordinate systems to help developers quickly build professional-grade trading analysis tools.</p> <p>Below is a comprehensive stock trading chart using ECharts, combining <strong>time-sharing, MACD, volume, order book, and depth chart</strong>:</p> <img data-src="images/feature-v6/8-stock.png" width="600px" src="https://echarts.apache.org/handbook/images/feature-v6/8-stock.png"> <p>These examples help developers quickly meet financial trading needs. For example, displaying numbers in the four corners of the chart can be achieved with <a href="https://echarts.apache.org/handbook/$%7BoptionPathseries-line.markPoint.data.relativeTo">relativeTo</a>.</p> <h3 id="9.-new-matrix-coordinate-system" tabindex="-1">9. New Matrix Coordinate System</h3> <p>The above example also uses the new matrix coordinate system in ECharts 6.0, which is very powerful. It can be used for covariance matrix charts:</p>  <p>Periodic table:</p>  <p>As a layout, it also allows developers to combine various chart types and components to create flexible and complex visualizations:</p>  <h3 id="10.-enhanced-custom-series" tabindex="-1">10. Enhanced Custom Series</h3> <p>Previously, using ECharts custom series meant developers had to write complex <code>renderItem</code> logic from scratch, and code reuse was limited to copy-pasting. Now, ECharts 6.0 brings a standardized, reusable solution:</p> <ul><li><strong>Custom series registration</strong>: Like theme registration, custom series can be dynamically registered and used as easily as built-in series. See <a href="https://echarts.apache.org/option.html#series-custom.renderItem">series-custom.renderItem</a></li> <li><strong>Official custom series project</strong>: The official project at <a href="https://github.com/apache/echarts-custom-series">https://github.com/apache/echarts-custom-series</a> provides multiple custom series, available via npm after the official release</li> <li><strong>Publish your own custom series</strong>: Submit a pull request to the above project or publish to your own repo for code reuse</li></ul> <h3 id="11.-new-custom-charts" tabindex="-1">11. New Custom Charts</h3> <p>This release provides 6 practical custom charts in the custom series project. See <a href="https://github.com/apache/echarts-custom-series">echarts-custom-series</a> for usage and documentation. Including <strong>violin chart</strong>:</p> <img data-src="images/feature-v6/11-violin.png" width="600px" src="https://echarts.apache.org/handbook/images/feature-v6/11-violin.png"> <p><strong>Contour chart</strong>:</p> <img data-src="images/feature-v6/11-contour.png" width="600px" src="https://echarts.apache.org/handbook/images/feature-v6/11-contour.png"> <p><strong>Sleep stage chart</strong>:</p> <img data-src="images/feature-v6/11-stage.png" width="600px" src="https://echarts.apache.org/handbook/images/feature-v6/11-stage.png"> <p><strong>Segmented doughnut chart</strong>:</p> <img data-src="images/feature-v6/11-segmentedDoughnut.png" width="600px" src="https://echarts.apache.org/handbook/images/feature-v6/11-segmentedDoughnut.png"> <p><strong>Bar range chart</strong>:</p> <img data-src="images/feature-v6/11-barRange.png" width="600px" src="https://echarts.apache.org/handbook/images/feature-v6/11-barRange.png"> <p><strong>Line range chart</strong>:</p> <img data-src="images/feature-v6/11-lineRange.png" width="600px" src="https://echarts.apache.org/handbook/images/feature-v6/11-lineRange.png"> <p>Unleash your creativity and join us in creating more custom charts!</p> <h3 id="12.-axis-label-optimization" tabindex="-1">12. Axis Label Optimization</h3> <p>In previous versions, axis labels and names in rectangular coordinate systems could easily overflow or overlap when data was long. Users couldn't always predict space needs as data changed. In this version, we've optimized the default strategies to prevent overflow and overlap.</p> <h2 id="upgrade-guide" tabindex="-1">Upgrade Guide</h2> <p>See the full <a href="https://echarts.apache.org/changelog.html#v6-0-0">changelog</a> and <a href="https://echarts.apache.org/handbook/en/basics/release-note/v6-upgrade-guide">upgrade guide</a>.</p></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Monitor your security cameras with locally processed AI (443 pts)]]></title>
            <link>https://frigate.video/</link>
            <guid>44794508</guid>
            <pubDate>Tue, 05 Aug 2025 05:05:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://frigate.video/">https://frigate.video/</a>, See on <a href="https://news.ycombinator.com/item?id=44794508">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__next"><main id="content"><div id="hero"><p><img src="https://frigate.video/images/live.webp" alt="App preview"></p><div><h2>Monitor your security cameras with locally processed AI</h2><div><p>Frigate is an open source NVR built around real-time AI object detection. All processing is performed locally on your own hardware, and your camera feeds never leave your home.</p><p>Get access to custom models designed specifically for Frigate with Frigate+.</p></div></div></div><div id="features"><div><p><img src="https://frigate.video/images/detection.jpg" alt="App preview on a phone and tablet"></p><div><h3>Reduce false positives with local object detection</h3><p>Traditional NVRs can require hours of fine tuning to reduce false positive rates because they rely on simple motion detection. By offloading object detection to a supported AI accelerator, even modest hardware can run advanced analysis to determine if the motion is actually a person, car, or other object of interest. With Frigate's local processing, there is no need to pay for your personal camera footage to be sent to the cloud for analysis.</p></div></div><div><p><img src="https://frigate.video/images/review.webp" alt="App users welcoming a new member"></p><div><h3>Stop reviewing shadows and wind and start reviewing detections that matter</h3><p>Let Frigate's AI scrub your video feeds for you. With a supported AI accelerator, Frigate can run 100+ object detections per second so it doesn't miss a single frame.</p></div></div><div><p><img src="https://frigate.video/images/driveway_zones-min.png" alt="App users welcoming a new member"></p><div><h3>Fine tune your events and alerts with zones</h3><p>Frigate tracks objects in real-time and can determine the exact moment a person starts walking up your front steps or when a car enters your driveway. Refine your notifications based on precise locations.</p></div></div><div><p><img src="https://frigate.video/images/hass-opt.png" alt="App user profile preview"></p><div><h3>Integrate with Home Assistant and other automation platforms</h3><p>Give your home eyes by integrating object detection into Home Assistant, OpenHab, NodeRed, or anything with MQTT support. Frigate integrates directly into Home Assistant's media browser, provides low latency camera entities, and exposes real-time sensors and switches to power automations and notifications to your heart's content.</p></div></div></div><div id="reviews"><blockquote><div><p>Frigate's high level of customizability, fast object detection and tight integration with  Home Assistant creates the perfect open source, locally controlled, security camera system.</p></div></blockquote><blockquote><div><p>Frigate has helped me reduce hours of false detections from my hard drive and saved me maybe as much time scouring through said, uneventful, footage. Ok maybe not that much, but seriously,  zero false detections.</p></div></blockquote><blockquote><div><p>Frigate has allowed me to remove all cloud dependencies from my security cameras, without losing  any sort of object detection features or recording history. Support is second to none. Highly recommended.</p></div></blockquote></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PHP 8.5 adds pipe operator (366 pts)]]></title>
            <link>https://thephp.foundation/blog/2025/07/11/php-85-adds-pipe-operator/</link>
            <guid>44794271</guid>
            <pubDate>Tue, 05 Aug 2025 04:13:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thephp.foundation/blog/2025/07/11/php-85-adds-pipe-operator/">https://thephp.foundation/blog/2025/07/11/php-85-adds-pipe-operator/</a>, See on <a href="https://news.ycombinator.com/item?id=44794271">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
            <p>PHP 8.5, due out November of this year, will bring with it another long-sought-after feature: the <a href="https://wiki.php.net/rfc/pipe-operator-v3">pipe operator</a> (<code>|&gt;</code>).  It's a small feature with huge potential, yet it still took years to happen.</p>

<h2 id="what-is-a-pipe-operator%3F">What is a pipe operator?</h2>

<p>The pipe operator, spelled <code>|&gt;</code>, is deceptively simple.  It takes the value on its left side and passes it as the single argument to a function (or in PHP's case, <code>callable</code>) on its right side:</p>

<pre><code>$result = "Hello World" |&gt; strlen(...)

// Is equivalent to
$result = strlen("Hello World");
</code></pre>

<p>On its own, that is not all that interesting.  Where it becomes interesting is when it is repeated, or chained, to form a "pipeline."  For example, here's real code from a real project I've worked on, recast to use pipes:</p>

<pre><code>$arr = [
  new Widget(tags: ['a', 'b', 'c']),
  new Widget(tags: ['c', 'd', 'e']),
  new Widget(tags: ['x', 'y', 'a']),
];

$result = $arr
    |&gt; fn($x) =&gt; array_column($x, 'tags') // Gets an array of arrays
    |&gt; fn($x) =&gt; array_merge(...$x)       // Flatten into one big array
    |&gt; array_unique(...)                  // Remove duplicates
    |&gt; array_values(...)                  // Reindex the array.
;

// $result is ['a', 'b', 'c', 'd', 'e', 'x', 'y']
</code></pre>

<p>The same code without pipes would require either this horribly ugly nest of evil:</p>

<pre><code>array_values(array_unique(array_merge(...array_column($arr, 'tags'))));
</code></pre>

<p>Or manually creating a temporary variable for each step.  While temp variables are not the worst thing in the world, they are extra mental overhead, and mean that a chain like that cannot be used in a single-expression context, like a <code>match()</code> block.  A pipe chain can.</p>

<p>Anyone who has worked on the Unix/Linux command line will likely recognize the similarity to the shell pipe, <code>|</code>.  That's very deliberate, as it is effectively the same thing: Use the output from the left side as the input on the right side.</p>

<h2 id="where-did-it-come-from%3F">Where did it come from?</h2>

<p>The <code>|&gt;</code> operator appears in many languages, mostly in the functional world.  F# has essentially the exact same operator, as does OCaml.  Elixir has a slightly fancier version (which we considered but ultimately decided against for now).  Numerous PHP libraries exist in the wild that offer similar capability with many extra expensive steps, including my own <a href="https://github.com/Crell/fp/">Crell/fp</a>.</p>

<p>The story for PHP pipes, though, begins with Hack/HHVM, Facebook's PHP fork née competitive implementation.  Hack included many features beyond what PHP 5 of the day offered; many of them eventually ended up in later PHP versions.  One of its features was a unique spin on a pipe operator.</p>

<p>In 2016, Sara Golemon, long-time PHP contributor and former Open Source lead on the HHVM project, proposed porting <a href="https://wiki.php.net/rfc/pipe-operator">Hack's pipes</a> to PHP directly.  In that RFC, the right side of a pipe wasn't a <code>callable</code> but an expression, and used a magic <code>$$</code> token (lovingly called <code>T_BLING</code>, at least according to yours truly) to inject the left-side result into it.  In that case, the example above would look like this:</p>

<pre><code>$result = $arr
    |&gt; array_column($$, 'tags')
    |&gt; array_merge(...$$)
    |&gt; array_unique($$)
    |&gt; array_values($$)
;
</code></pre>

<p>While powerful, it was also somewhat limiting.  It was very non-standard, unlike any other language.  It also meant a weird, one-off syntax for partially-calling functions that worked only when paired with pipes.</p>

<p>That RFC didn't go as far as a vote.  Nothing much happened for several years, until 2020/2021.  That's when I, fresh off of writing a book on functional programming in PHP that talked about function composition, decided to take a swing at it.  In particular, I partnered with a team to work on <a href="https://wiki.php.net/rfc/partial_function_application">Partial Function Application</a> (PFA) as a separate RFC from a more <a href="https://wiki.php.net/rfc/pipe-operator-v2">traditional pipe</a>.  The idea was that turning a multi-parameter function (like <code>array_column()</code> above) into the single-parameter function that <code>|&gt;</code> needed was a useful feature on its own, and should be usable elsewhere.  The syntax was a bit different than the Hack version, in order to make it more flexible: <code>some_function(?, 5, ?, 3, ...)</code>, which would take a 5-or-more parameter function and turn it into a 3 parameter function.</p>

<p>Sadly, PFA didn't pass due to some engine complexity issues, and that largely undermined the v2 Pipe RFC, too.  However, we did get a consolation prize out of it: <a href="https://wiki.php.net/rfc/first_class_callable_syntax">First Class Callables</a> (the <code>array_values(...)</code> syntax), courtesy Nikita Popov, were by design a "junior", degenerate version of partial function application.</p>

<p>Fast-forward to 2025, and I was sufficiently bored to take another swing at pipes.  This time with a better implementation with lots of hand-holding from Ilija Tovilo and Arnaud Le Blanc, both part of the PHP Foundation dev team, I was able to get it through.</p>

<p>Third time's the charm.</p>

<h2 id="more-than-the-sum-of-its-parts">More than the sum of its parts</h2>

<p>Above, we described pipes as "deceptively simple."  The implementation itself is almost trivial; it's just syntax sugar for the temp variable version, effectively.  However, the best features are the ones that can combine with others or be used in novel ways to punch above their weight.</p>

<p>We saw above how a long array manipulation process could now be condensed into a single chained expression.  Now imagine using that in places where only a single expression is allowed, such as a <code>match()</code>:</p>

<pre><code>$string = 'something GoesHERE';

$newString = match ($format) {
    'snake_case' =&gt; $string
        |&gt; splitString(...)
        |&gt; fn($x) =&gt; implode('_', $x)
        |&gt; strtolower(...),
    'lowerCamel' =&gt; $string
        |&gt; splitString(...),
        |&gt; fn($x) =&gt; array_map(ucfirst(...), $x)
        |&gt; fn($x) =&gt; implode('', $x)
        |&gt; lcfirst(...),
    // Other case options here.
};
</code></pre>

<p>Or, consider that the right-side can also be a function call that returns a <code>Closure</code>.  That means with a few functions that return functions:</p>

<pre><code>$profit = [1, 4, 5] 
    |&gt; loadSeveral(...)
    |&gt; filter(isOnSale(...))
    |&gt; map(sellWidget(...))
    |&gt; array_sum(...);
</code></pre>

<p>Which... gives us mostly the same thing as the long-discussed scalar methods!  Only pipes are more flexible as you can use any function on the right-side, not just those that have been blessed by the language designers as methods.</p>

<p>At this point, pipe comes very close to being "extension functions", a feature of Kotlin and C# that allows writing functions that look like methods on an object, but are actually just stand-alone functions.  It's spelled a bit differently (<code>|</code> instead of <code>-</code>), but it's 75% of the way there, for free.</p>

<p>Or take it a step further.  What if some steps in the pipe may return <code>null</code>?  We can, with a single function, "lift" the elements of our chain to handle <code>null</code> values in the same fashion as null-safe methods.</p>

<pre><code>function maybe(\Closure $c): \Closure
{
    return fn(mixed $arg) =&gt; $arg === null ? null : $c($arg);
}

$profit = [1, 4, 5] 
    |&gt; maybe(loadSeveral(...))
    |&gt; maybe(filter(isOnSale(...)))
    |&gt; maybe(map(sellWidget(...)))
    |&gt; maybe(array_sum(...));
</code></pre>

<p>That's right, we just implemented a Maybe Monad with a pipe and a single-line function.</p>

<p>Now, think about that for streams...</p>

<pre><code>fopen('pipes.md', 'rb') // No variable, so it will close automatically when GCed.
    |&gt; decode_rot13(...)
    |&gt; lines_from_charstream(...)
    |&gt; map(str_getcsv(...))
    |&gt; map(Product::create(...))
    |&gt; map($repo-&gt;save(...))
;
</code></pre>

<p>The potential is absolutely huge.  I don't think it's immodest to say that the pipe operator has one of the highest "bangs for the buck" of any feature in recent memory, alongside such niceties as constructor property promotion.  And all thanks to a little syntax sugar.</p>

<h2 id="what-comes-next%3F">What comes next?</h2>

<p>Although pipes are a major milestone, we're not done.  There is active work on not one but two follow-up RFCs.</p>

<p>The first is a second attempt at <a href="https://wiki.php.net/rfc/partial_function_application_v2">Partial Function Application</a>.  This is a larger feature, but with first-class callables already bringing in much of the necessary plumbing, which simplifies the implementation.  With pipes now providing a natural use case, as well as easy optimization points, it's worth a second attempt.  Whether it makes it into PHP 8.5, is delayed to 8.6, or is again rejected is still an open question as of this writing, though I am hopeful.  Major thanks to Arnaud Le Blanc from the PHP Foundation team for picking it up to update the implementation.</p>

<p>The second is a <a href="https://wiki.php.net/rfc/function-composition">function composition operator</a>.  Where pipe executes immediately, function composition creates a new function by sticking two functions end-to-end.  That would mean the streams example above could be further optimized by combining the <code>map()</code> calls:</p>

<pre><code>fopen('pipes.md', 'rb')
    |&gt; decode_rot13(...)
    |&gt; lines_from_charstream(...)
    |&gt; map(str_getcsv(...) + Product::create(...) + $repo-&gt;save(...))
;
</code></pre>

<p>This one is definitely not going to make it into PHP 8.5, but I am hopeful that we'll be able to get it into 8.6.  Stay tuned.</p>

<blockquote>
  <p>Special thanks to Ilija Tovilo and Arnaud Le Blanc from the PHP Foundation team for their assistance with the pipe implementation.  If you’d like to help push PHP forward, consider <a href="https://thephp.foundation/sponsor/">becoming a sponsor</a>.</p>
</blockquote>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[3D Line Drawings (267 pts)]]></title>
            <link>https://amritkwatra.com/experiments/3d-line-drawings</link>
            <guid>44792441</guid>
            <pubDate>Mon, 04 Aug 2025 23:16:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://amritkwatra.com/experiments/3d-line-drawings">https://amritkwatra.com/experiments/3d-line-drawings</a>, See on <a href="https://news.ycombinator.com/item?id=44792441">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
                    <p>
                    This is an experiment examing how to create a 3D line drawing of a scene. In this post, I will describe how this can be done by augmenting the process of generating <span>3D Gaussian Splats</span>
                    <label for="mn-35be8a"></label>
                    
                    <span><a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/" target="_blank" rel="noopener noreferrer">3D Gaussian Splatting for Real-Time Radiance Field Rendering</a>, by Kerbl et al.</span> and leveraging a process to transform photographs into <span>Informative Line Drawings</span>
                    <label for="mn-32f931"></label>
                    
                    <span><a href="https://carolineec.github.io/informative_drawings/" target="_blank" rel="noopener noreferrer">Learning to Generate Line Drawings that Convey Geometry and Semantics</a>, by Chan, Isola &amp; Durand</span>.
                </p>
                
                <figure>
                    
                </figure>
                <p>
                The majority of scenes shown above are generated using a <em>contour</em> style. <strong>You can switch the active scene using the menu in the top-right corner of the iframe</strong>. Each scene is trained for 21,000 iterations on an Nvidia RTX 4080S, using <a href="https://github.com/MrNeRF/gaussian-splatting-cuda" target="_blank" rel="noopener noreferrer">
<code>
gaussian-splatting-cuda
                </code>
            </a> from MrNerf with default settings. Examples here were generated using scenes from the <a href="https://www.tanksandtemples.org/" target="_blank" rel="noopener noreferrer">Tanks &amp; Temples Benchmark</a>. The scene is interactive, and rendered using <a href="https://github.com/mkkellogg/GaussianSplats3D" target="_blank" rel="noopener noreferrer">Mark Kellogg's web-based renderer</a>.
            To explore these scenes in fullscreen, <a href="https://splat-serve.pages.dev/?id=caterpillar-contour" target="_blank" rel="noopener noreferrer">click here.</a>
        </p>
        
        <h3>
            Creating Line Drawings from Images
        </h3>
        <figure>
            <label for="mn-figure-60d5a5">⊕</label>
            
            <span>
                <em>Figure 1.</em> <em>(a)</em> A source image from the Caterpillar scene in <a href="https://www.tanksandtemples.org/">Tanks &amp; Temples</a>. <em>(b)</em> A generated line drawing in the <em>contour</em> style. <em>(c)</em> A generated line drawing in the <em>anime</em> style.
            </span>
            <img src="https://amritkwatra.com/assets/3d_line_drawing__fig1-ShImBJCe.png" alt="Figure 1">
        </figure>
        <p>
        Images are transformed into line drawings using the approach introduced by Chan et al. in <a href="https://carolineec.github.io/informative_drawings/" target="_blank" rel="noopener noreferrer">Learning to Generate Line Drawings that Convey Geometry and Semantics</a>. They describe a process for transforming photographs into line drawings that preserve the semantics and geometry captured in the photograph while rendering the image in an artistic style. They do this by training a generative adversarial network (GAN) that minimizes <span>geometry</span>
        <label for="mn-5aa174"></label>
        
        <span>The geometry loss is computed using monocular depth estimation.</span>, <span>semantics</span>
        <label for="mn-7dcc1a"></label>
        
        <span>The semantics loss is computed using CLIP embeddings.</span>, and <span>appearance</span>
        <label for="mn-16f242"></label>
        
        <span>The appearance loss is based on a collection of unpaired style references.</span> losses. Their work is fantastic and I recommend reading their paper if you're interested in the details. Figure 1 depicts the input photograph and output line drawing in two styles, generated using Chan et al.'s <a href="https://github.com/carolineec/informative-drawings" target="_blank" rel="noopener noreferrer">code and model weights</a>.
    </p>
    <h3>
        3D Gaussian Splatting
    </h3>
    <p>
    3D Gaussian Splatting is a technique that transforms collections of <span>posed images</span>
    <label for="mn-5402d3"></label>
    
    <span>Images for which we estimate the relative position and rotation of the camera in the scene. Usually, this is computed using Structure-from-Motion (SfM).</span> into a volumetric representation called a radiance field. Generally, scenes can be created from collections of images captured from multiple overlapping viewpoints, either by taking multiple photographs from different angles or by sampling an input video while moving through the scene. For more complete details on 3D Gaussian Splatting, I encourage you to read <a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/" target="_blank" rel="noopener noreferrer">the paper</a> or watch this <a href="https://www.youtube.com/watch?v=VkIJbpdTujE" target="_blank" rel="noopener noreferrer">explanation video</a> from Computerphile.
</p>
<p>
The scenes that are produced using 3D Gaussian Splatting are photorealistic and can be rendered at real-time rates using existing tools such as WebGL. However, I noticed that if the images used to train the 3D Gaussian Splat were swapped out with the <span>line-drawing counterparts</span>
<label for="mn-459d32"></label>

<span>While I transformed the images into line drawings, this transformation could be carried out using a number of other stylistic effects.</span> then the resulting scene would depict a kind of 3D line drawing. Similar to <span>regular sketching</span>
<label for="mn-ea08a3"></label>

<span>Illustrating a 3D scene as a 2D drawing from a specific perspective.</span>, the lines that are rendered are view-dependant and change based on your perspective in the scene.
</p>
<h3>
    Swapping Source Images
</h3>
<figure>
    <label for="mn-figure-5dc885">⊕</label>
    
    <span>
        <em>Figure 2.</em> The transformed images can be used to create 3D line drawings by swapping them for the original images in one of two places, shown here in green. Either before using SfM to generate the sparse model and camera poses or prior to training the 3D Gaussian Splat. The former computes SfM points based on the transformed images, while the latter keeps the points from the original images and computes the rendering loss using the transformed images. Figure adapted from the <a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/">original 3D Gaussian Splatting paper</a>.
    </span>
    <img src="https://amritkwatra.com/assets/3d_line_drawing__swap-xknqvGhJ.png" alt="Figure 2">
</figure>
<p>
Generating these 3D line drawings requires only a slight modification to the conventional process for generating 3D Gaussian Splats. At a high level, we simply swap the original images with the ones generated using Chan et al.'s method for transforming images into informative line drawings. This swap can happen in two places: prior to training the 3D Gaussian Splat or prior to estimating camera poses and sparse points using structure-from-motion (SfM).
</p>
<p>
When images are transformed prior to training the 3D Gaussian Splat, the camera poses and initial 3D Gaussians are derived from the original images but the loss is computed by comparing the rasterization output to the informative line drawing. As a result, the final scene also captures slight amounts of color that is not present in the transformed images. I believe this is a side-effect of intializing the 3D Gaussians using the original images. If you transform the images prior to applying SfM, the initialization and camera poses are based on the transformed images and the color artifacts are removed.
</p>
<figure>
    <label for="mn-figure-35efdb">⊕</label>
    
    <span>
        <em>Figure 3.</em> <em>(a)</em> A 3D line drawing created by swapping the transformed images for the original ones prior to using SfM. <em>(b)</em> A 3D line drawing generated by swapping the transformed images for the original ones prior to training the 3D Gaussian Splat.
    </span>
    <img src="https://amritkwatra.com/assets/3d_line_drawing__pre-sfm-pre-train-DdbSCa4M.png" alt="Figure 3">
</figure>
<p>
If you replace the images prior to applying SfM, there is less information to use when generating a sparse model and estimating camera poses. As a result, the process is more reliable when images are replaced prior to training the 3D Gaussian Splat. Additionally, if you're iterating on different styles and tweaking the transformation process, swapping prior to training the 3D Gaussian Splat lets you avoid re-running COLMAP (or other SfM tools) for each iteration. For the majority of my examples, I swapped the images prior to training the 3D Gaussian Splat. Figure 3 shows a comparison between scenes generated using these two methods.
</p>

<figure>
    <label for="mn-figure-2b9fff">⊕</label>
    
    <span>
        <em>Figure 4.</em> <em>(a)</em> A 3D line drawing created by swapping the original images with informative line drawings prior to training the 3D Gaussian Splat. Note that the slight amount of color is an artifact that is likely the result of initializing the 3D Gaussians from the original set of images. <em>(b)</em> A 3D line drawing that blends low-frequency color information from the original scene to produce a watercolor-like effect.
    </span>
    <img src="https://amritkwatra.com/assets/3d_line_drawing__color_comp-Ck96zCOw.png" alt="Figure 4">
</figure>
<p>
I wanted to see how we could add some color information back into the generated line drawings and ultimately into the generated scenes. To do this, I generated a slightly modified <span>hybrid image</span>
<label for="mn-a23a0a"></label>

<span>"A hybrid image is a picture that combines the low-spatial frequencies of one picture with the high spatial frequencies of another picture" - <a href="https://web.stanford.edu/class/ee367/reading/OlivaTorralb_Hybrid_Siggraph06.pdf" target="_blank" rel="noopener noreferrer">Oliva, Torralba &amp; Schyns</a> </span> which blends color information from the original image into the line drawing to create a watercolor effect in the final image. Figure 4 shows the contour image and the blended hybrid image. There are a few scenes in the interactive example above that use this method of adding color, such as the <a href="https://splat-serve.pages.dev/?id=caterpillar-color" target="_blank" rel="noopener noreferrer">Blended Caterpillar Scene</a>, and <a href="https://splat-serve.pages.dev/?id=lighthouse-color" target="_blank" rel="noopener noreferrer">Blended Lighthouse Scene</a>.
</p>
<figure>
    <label for="mn-figure-03a07b">⊕</label>
    
    <span>
        <em>Figure 5.</em> A video orbiting around the spliced Caterpillar scene. In this scene, viewpoints from one hemisphere of the scene render the Blended Color Contour Caterpillar Scene, and viewpoints from the other hemisphere render the source photorealistic Caterpillar Scene. Orbitting around the scene demonstrates how style can gradually change as you move through the scene.
    </span>
    <video width="100%" controls="" autoplay="" loop="" muted="" playsinline="">
        <source src="https://splats.amritkwatra.com/real-hybrid-blend-orbit-web-2x.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
    </figure>
    <p>
    A subtle, but interesting effect can be achieved by splicing together the source scene and color scene. By training a 3D Gaussian Splat to reconstruct photorealistic images from one set of perspectives and colored, contour images from another distinct set of perspectives, you can gradually transition styles within the same scene based on the viewing perspective. Figure 5 demonstrates this by orbiting around a scene in the <a href="https://splat-serve.pages.dev/?id=caterpillar-real-hybrid-blend" target="_blank" rel="noopener noreferrer">Spliced Caterpillar Scene</a>.
</p>

<figure>
    <label for="mn-figure-ce6432">⊕</label>
    
    <span>
        <em>Figure 6.</em> A <em>collage</em> image that segments out an object (in this example the tractor) in a scene and replaces it with the corresponding object from the stylized scene. This replacement, or collage, happens in image space prior to training the Gaussian Splat. <em>(a)</em> Inserts the <em>contour</em> style into the original scene. <em>(b)</em> Inserts the original scene into the stylized <em>contour</em> scene.
    </span>
    <img src="https://amritkwatra.com/assets/3d_line_drawing__collage-D6cuP6A0.png" alt="Figure 6">
</figure>
<p>
Another experiment I tried was to create a <em>collage</em> scene that renders only the subject of the scene as a line drawing and leaves the background unaltered. To do this I used a Meta's <a href="https://github.com/facebookresearch/segment-anything/tree/main?tab=readme-ov-file#model-checkpoints" target="_blank" rel="noopener noreferrer">Segment-Anything Model</a> <span>(SAM)</span>
<label for="mn-f88186"></label>

<span>To avoid manually specifying areas in the image to segment using SAM, I used <a href="https://github.com/luca-medeiros/lang-segment-anything" target="_blank" rel="noopener noreferrer">LangSAM</a> to automatically segment images based on a text prompt.</span>  to mask out the subject in each input photograph and replace it with the corresponding area from the generated line drawing image. The resulting scene is depicted in Figure 6 and can be explored here: <a href="https://splat-serve.pages.dev/?id=caterpillar-collage" target="_blank" rel="noopener noreferrer">Caterpillar Collage Scene</a>.
</p>
<!--
<figure>
    <label for="mn-figure-9039c0" class="margin-toggle">&#8853;</label>
    <input type="checkbox" id="mn-figure-9039c0" class="margin-toggle"/>
    <span class="marginnote">
        <em>Figure 6.</em> A <em>collage</em> image that segments out multiple objects (in this example, benches) in a scene and replaces it with the corresponding object from the stylized scene.
    </span>
    <img src="../imgs/3d_line_drawing__collage_multiple.png" alt="Figure 6" />
</figure>
This method can also render multiple subjects in the scene in different styles. Figure 6 shows multiple objects (benches) being rendered as line drawings within a scene. View the full scene here: [Family Collage Scene](https://splat-serve.pages.dev/?id=family-collage). It is also possible to mix and match different styles applied to different objects in the same scene. -->

<figure>
    <label for="mn-figure-fb84bd">⊕</label>
    
    <span>
        <em>Figure 7.</em> The same scene rendered by line drawings at two output resolutions. In each scene the inset image is one of the transformed images used to generate the scene. <em>(a)</em> <a href="https://splat-serve.pages.dev/?id=caterpillar-contour-256p">460x256 pixels</a>. <em>(b)</em> <a href="https://splat-serve.pages.dev/?id=caterpillar-contour">1940x1080 pixels</a>.
    </span>
    <img src="https://amritkwatra.com/assets/3d_line_drawing__resolution__inset-BSGYWx8Y.png" alt="Figure 7">
</figure>
<p>
The scenes so far have been trained on high resolution images (~1080p). This not only effects how long it takes to train the 3D Gaussian Splat, but also the fidelity of details captured in the line drawing. The lower resolution outputs capture the major lines that define the shape of the subject in the scene, while higher resolution outputs can pick up on more minor details in the scene. Figure 7 shows the same scene rendered at a variety of resolutions.
</p>
<p>
The following table describes the training time and number of splats generated for line drawings generated in a range of resolutions. Each scene is trained using the same parameters for 21,000 iterations. The final row describes the original scene using images from the Caterpillar scene in the Tanks and Temples Benchmark.
</p>
<div>
    <table>
        <thead>
            <tr>
                <th>Resolution</th>
                <th>Training Time</th>
                <th>Number of Splats</th>
                <th>Uncompressed File Size (.ply)</th>
                <th>Compressed File Size (.ksplat)</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><a href="https://splat-serve.pages.dev/?id=caterpillar-contour-128p">232x128</a></td>
                <td>3m 38s</td>
                <td>662,428</td>
                <td>164 MB</td>
                <td>14.1 MB</td>
            </tr>
            <tr>
                <td><a href="https://splat-serve.pages.dev/?id=caterpillar-contour-256p">460x256</a></td>
                <td>4m 31s</td>
                <td>1,105,383</td>
                <td>274 MB</td>
                <td>24.5 MB</td>
            </tr>
            <tr>
                <td><a href="https://splat-serve.pages.dev/?id=caterpillar-contour-512p">920x512</a></td>
                <td>6m 48s</td>
                <td>1,611,563</td>
                <td>400 MB</td>
                <td>36.4 MB</td>
            </tr>
            <tr>
                <td><a href="https://splat-serve.pages.dev/?id=caterpillar-contour">1940x1080</a></td>
                <td>15m 27s</td>
                <td>2,046,676</td>
                <td>507 MB</td>
                <td>46 MB</td>
            </tr>
            <tr>
                <td><a href="https://splat-serve.pages.dev/?id=caterpillar-original">Original (1957x1090)</a></td>
                <td>15m 9s</td>
                <td>900,798</td>
                <td>223 MB</td>
                <td>21 MB</td>
            </tr>
        </tbody></table>
    </div>
    <p>
    It is notable that a line drawing scene is roughly double the size of it's source scene in both number of splats and file size. I hypothesize that this is because splats are better suited at modelling large areas and textures than they are at strokes. As a result, a scene of a 3D line drawing must use more individual gaussians to render long, thin lines in the scene.
</p>

<p>
The code to generate these is a mashup of scripts to orchestrate between the different libraraies referenced in this post. Contact me if you're curious about running this yourself.
</p>

<p>
If you have thoughts about this work or would like to collaborate, I would love to hear from you. You can contact me at:
<code>
tansh at amritkwatra dot com
</code>
</p>

<p>
Special thanks to Ritik Batra, Ilan Mandel &amp; Thijs Roumen for their feedback and suggestions. This page was created using the open-source <a href="https://github.com/tansh-kwa/tufte-project-template" target="_blank" rel="noopener noreferrer">Tufte Project Pages</a> template.
</p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I've been building an ERP for manufacturing for the last 3 years (273 pts)]]></title>
            <link>https://github.com/crbnos/carbon</link>
            <guid>44792005</guid>
            <pubDate>Mon, 04 Aug 2025 22:24:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/crbnos/carbon">https://github.com/crbnos/carbon</a>, See on <a href="https://news.ycombinator.com/item?id=44792005">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
   <a href="https://carbon.ms/" rel="nofollow">
      <img width="auto" height="100" alt="Carbon Logo" src="https://private-user-images.githubusercontent.com/64510427/465005356-86a5e583-adac-4bf9-8192-508a0adf2308.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTQzNjEzMDIsIm5iZiI6MTc1NDM2MTAwMiwicGF0aCI6Ii82NDUxMDQyNy80NjUwMDUzNTYtODZhNWU1ODMtYWRhYy00YmY5LTgxOTItNTA4YTBhZGYyMzA4LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA4MDUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwODA1VDAyMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWFiNjZkMTZlYTBjMmE1Y2Y2ODM1ZGMxNjU0ODRlMzEwN2QyOGZkZmM5NWM2Zjk3YTk5YTc2ZGQ4Y2NlNzI1YWYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.qGm2vI_fgIS_CX3858gOiYnZevpLmnJQaPk-14G2y50" secured-asset-link="">
   </a>
</p>


<p dir="auto">
  <a href="https://go.midday.ai/K7GwMoQ" rel="nofollow">
    <img src="https://camo.githubusercontent.com/0d69bd5f3e56aabad0d1a0869a2bbf559648e8fde5478d9fa6331f424a097618/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f53757061626173652d3345434638453f7374796c653d666f722d7468652d6261646765266c6f676f3d7375706162617365266c6f676f436f6c6f723d7768697465" alt="Supabase" data-canonical-src="https://img.shields.io/badge/Supabase-3ECF8E?style=for-the-badge&amp;logo=supabase&amp;logoColor=white">
  </a>
</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/64510427/465004791-2e09b891-d5e2-4f68-b924-a1c8ea42d24d.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTQzNjEzMDIsIm5iZiI6MTc1NDM2MTAwMiwicGF0aCI6Ii82NDUxMDQyNy80NjUwMDQ3OTEtMmUwOWI4OTEtZDVlMi00ZjY4LWI5MjQtYTFjOGVhNDJkMjRkLmpwZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA4MDUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwODA1VDAyMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWUxODI0ZDhiOGQxZGFjNGJlYzlhYTY2MThlZWU0YTM4YmIwNzU4NGY5ZDQ5MGFjNDIyZTg3N2NjM2EwMzk5NmQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.iXA9k7MJN4NDQx4-7ujQxmuXYLommM6cNM59cW9kcjo"><img src="https://private-user-images.githubusercontent.com/64510427/465004791-2e09b891-d5e2-4f68-b924-a1c8ea42d24d.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTQzNjEzMDIsIm5iZiI6MTc1NDM2MTAwMiwicGF0aCI6Ii82NDUxMDQyNy80NjUwMDQ3OTEtMmUwOWI4OTEtZDVlMi00ZjY4LWI5MjQtYTFjOGVhNDJkMjRkLmpwZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA4MDUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwODA1VDAyMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWUxODI0ZDhiOGQxZGFjNGJlYzlhYTY2MThlZWU0YTM4YmIwNzU4NGY5ZDQ5MGFjNDIyZTg3N2NjM2EwMzk5NmQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.iXA9k7MJN4NDQx4-7ujQxmuXYLommM6cNM59cW9kcjo" alt="ERP Screenshot"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/64510427/465004825-b04f3644-91aa-4f74-af8d-6f3e12116a6b.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTQzNjEzMDIsIm5iZiI6MTc1NDM2MTAwMiwicGF0aCI6Ii82NDUxMDQyNy80NjUwMDQ4MjUtYjA0ZjM2NDQtOTFhYS00Zjc0LWFmOGQtNmYzZTEyMTE2YTZiLmpwZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA4MDUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwODA1VDAyMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ1NmVhYzg5MmY2ODhkYTUwZDQ1YzJhNGExNWQ2N2Q2NGJlNDIzYTdhN2Y4NzA1ZWUzZDgxMDYxZDQ2ZTAxMzQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.9v_tr9MxKAgyv7W8sNm5RmA7LO3JlQ_9-la1xIVVyoo"><img src="https://private-user-images.githubusercontent.com/64510427/465004825-b04f3644-91aa-4f74-af8d-6f3e12116a6b.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTQzNjEzMDIsIm5iZiI6MTc1NDM2MTAwMiwicGF0aCI6Ii82NDUxMDQyNy80NjUwMDQ4MjUtYjA0ZjM2NDQtOTFhYS00Zjc0LWFmOGQtNmYzZTEyMTE2YTZiLmpwZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA4MDUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwODA1VDAyMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ1NmVhYzg5MmY2ODhkYTUwZDQ1YzJhNGExNWQ2N2Q2NGJlNDIzYTdhN2Y4NzA1ZWUzZDgxMDYxZDQ2ZTAxMzQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.9v_tr9MxKAgyv7W8sNm5RmA7LO3JlQ_9-la1xIVVyoo" alt="MES Screenshot"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Does the world need another ERP?</h2><a id="user-content-does-the-world-need-another-erp" aria-label="Permalink: Does the world need another ERP?" href="#does-the-world-need-another-erp"></a></p>
<p dir="auto">We built Carbon after years of building end-to-end manufacturing systems with off-the-shelf solutions. We realized that:</p>
<ul dir="auto">
<li>Modern, API-first tooling didn't exist</li>
<li>Vendor lock-in bordered on extortion</li>
<li>There is no "perfect ERP" because each company is unique</li>
</ul>
<p dir="auto">We built Carbon to solve these problems ☝️.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Architecture</h2><a id="user-content-architecture" aria-label="Permalink: Architecture" href="#architecture"></a></p>
<p dir="auto">Carbon is designed to make it easy for you to extend the platform by building your own apps through our API. We provide some examples to get you started in the <a href="https://github.com/crbnos/carbon/blob/main/examples">examples</a> folder.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/64510427/445149654-ed6dc66b-e9cb-435e-b5a9-9daf933f4a1d.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTQzNjEzMDIsIm5iZiI6MTc1NDM2MTAwMiwicGF0aCI6Ii82NDUxMDQyNy80NDUxNDk2NTQtZWQ2ZGM2NmItZTljYi00MzVlLWI1YTktOWRhZjkzM2Y0YTFkLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA4MDUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwODA1VDAyMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTgyMjYzOTE5OTg4Yjc0MThkMjI4Yzg0ZDNkY2ExOWVlYTM3ZTAxMjk3NTc4MDU3YmM2M2JkZGIwZTY3NjU1MmYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.7r7Af605IQ1B4mUp-fSqs-VojI1soLKXUZD3FYkaZ2c"><img src="https://private-user-images.githubusercontent.com/64510427/445149654-ed6dc66b-e9cb-435e-b5a9-9daf933f4a1d.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTQzNjEzMDIsIm5iZiI6MTc1NDM2MTAwMiwicGF0aCI6Ii82NDUxMDQyNy80NDUxNDk2NTQtZWQ2ZGM2NmItZTljYi00MzVlLWI1YTktOWRhZjkzM2Y0YTFkLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA4MDUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwODA1VDAyMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTgyMjYzOTE5OTg4Yjc0MThkMjI4Yzg0ZDNkY2ExOWVlYTM3ZTAxMjk3NTc4MDU3YmM2M2JkZGIwZTY3NjU1MmYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.7r7Af605IQ1B4mUp-fSqs-VojI1soLKXUZD3FYkaZ2c" alt="Carbon Architecture"></a></p>
<p dir="auto">Features:</p>
<ul>
<li> ERP</li>
<li> MES</li>
<li> QMS</li>
<li> Custom Fields</li>
<li> Nested BoM</li>
<li> Traceability</li>
<li> MRP</li>
<li> Configurator</li>
<li> MCP Client/Server</li>
<li> API</li>
<li> Webhooks</li>
<li> Accounting</li>
<li> Capacity Planning</li>
<li> Simulation</li>
</ul>
<p dir="auto">Technical highlights:</p>
<ul>
<li> Unified auth and permissions across apps</li>
<li> Full-stack type safety (Database → UI)</li>
<li> Realtime database subscriptions</li>
<li> Attribute-based access control (ABAC)</li>
<li> Role-based access control (Customer, Supplier, Employee)</li>
<li> Row-level security (RLS)</li>
<li> Composable user groups</li>
<li> Dependency graph for operations</li>
<li> Third-party integrations</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Techstack</h2><a id="user-content-techstack" aria-label="Permalink: Techstack" href="#techstack"></a></p>
<ul dir="auto">
<li><a href="https://remix.run/" rel="nofollow">Remix</a> – framework</li>
<li><a href="https://www.typescriptlang.org/" rel="nofollow">Typescript</a> – language</li>
<li><a href="https://tailwindcss.com/" rel="nofollow">Tailwind</a> – styling</li>
<li><a href="https://radix-ui.com/" rel="nofollow">Radix UI</a> - behavior</li>
<li><a href="https://supabase.com/" rel="nofollow">Supabase</a> - database</li>
<li><a href="https://supabase.com/" rel="nofollow">Supabase</a> – auth</li>
<li><a href="https://upstash.com/" rel="nofollow">Upstash</a> - cache</li>
<li><a href="https://trigger.dev/" rel="nofollow">Trigger</a> - jobs</li>
<li><a href="https://resend.com/" rel="nofollow">Resend</a> – email</li>
<li><a href="https://novu.co/" rel="nofollow">Novu</a> – notifications</li>
<li><a href="https://vercel.com/" rel="nofollow">Vercel</a> – hosting</li>
<li><a href="https://stripe.com/" rel="nofollow">Stripe</a> - billing</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Codebase</h2><a id="user-content-codebase" aria-label="Permalink: Codebase" href="#codebase"></a></p>
<p dir="auto">The monorepo follows the Turborepo convention of grouping packages into one of two folders.</p>
<ol dir="auto">
<li><code>/apps</code> for applications</li>
<li><code>/packages</code> for shared code</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>/apps</code></h3><a id="user-content-apps" aria-label="Permalink: /apps" href="#apps"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Package Name</th>
<th>Description</th>
<th>Local Command</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>erp</code></td>
<td>ERP Application</td>
<td><code>npm run dev</code></td>
</tr>
<tr>
<td><code>mes</code></td>
<td>MES</td>
<td><code>npm run dev:mes</code></td>
</tr>
<tr>
<td><code>academy</code></td>
<td>Academy</td>
<td><code>npm run dev:academy</code></td>
</tr>
<tr>
<td><code>starter</code></td>
<td>Starter</td>
<td><code>npm run dev:starter</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>/packages</code></h3><a id="user-content-packages" aria-label="Permalink: /packages" href="#packages"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Package Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>eslint-config-carbon</code></td>
<td>Shared, extendable eslint configuration for apps and packages</td>
</tr>
<tr>
<td><code>@carbon/database</code></td>
<td>Database schema, migrations and types</td>
</tr>
<tr>
<td><code>@carbon/documents</code></td>
<td>Transactional PDFs and email templates</td>
</tr>
<tr>
<td><code>@carbon/integrations</code></td>
<td>Integration definitions and configurations</td>
</tr>
<tr>
<td><code>@carbon/jest</code></td>
<td>Jest preset configuration shared across apps and packages</td>
</tr>
<tr>
<td><code>@carbon/jobs</code></td>
<td>Background jobs and workers</td>
</tr>
<tr>
<td><code>@carbon/logger</code></td>
<td>Shared logger used across apps</td>
</tr>
<tr>
<td><code>@carbon/react</code></td>
<td>Shared web-based UI components</td>
</tr>
<tr>
<td><code>@carbon/kv</code></td>
<td>Redis cache client</td>
</tr>
<tr>
<td><code>@carbon/lib</code></td>
<td>Third-party client libraries (slack, resend)</td>
</tr>
<tr>
<td><code>@carbon/stripe</code></td>
<td>Stripe integration</td>
</tr>
<tr>
<td><code>@carbon/tsconfig</code></td>
<td>Shared, extendable tsconfig configuration used across apps and packages</td>
</tr>
<tr>
<td><code>@carbon/utils</code></td>
<td>Shared utility functions used across apps and packages</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Development</h2><a id="user-content-development" aria-label="Permalink: Development" href="#development"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Setup</h3><a id="user-content-setup" aria-label="Permalink: Setup" href="#setup"></a></p>
<ol dir="auto">
<li>
<p dir="auto">Clone the repo into a public GitHub repository (or fork <a href="https://github.com/crbnos/carbon/fork">https://github.com/crbnos/carbon/fork</a>). If you plan to distribute the code, keep the source code public to comply with <a href="https://github.com/crbnos/carbon/blob/main/LICENSE">AGPLv3</a>. To clone in a private repository, <a href="https://carbon.ms/sales" rel="nofollow">acquire a commercial license</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/crbnos/carbon.git"><pre>git clone https://github.com/crbnos/carbon.git</pre></div>
</li>
<li>
<p dir="auto">Go to the project folder</p>

</li>
</ol>
<p dir="auto">Make sure that you have <a href="https://docs.docker.com/desktop/install/mac-install/" rel="nofollow">Docker installed</a> on your system since this monorepo uses the Docker for local development.</p>
<p dir="auto">In addition you must configure the following external services:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Service</th>
<th>Purpose</th>
<th>URL</th>
</tr>
</thead>
<tbody>
<tr>
<td>Upstash</td>
<td>Serverless Redis</td>
<td><a href="https://console.upstash.com/login" rel="nofollow">https://console.upstash.com/login</a></td>
</tr>
<tr>
<td>Trigger.dev</td>
<td>Job runner</td>
<td><a href="https://cloud.trigger.dev/login" rel="nofollow">https://cloud.trigger.dev/login</a></td>
</tr>
<tr>
<td>Posthog</td>
<td>Product analytics platform</td>
<td><a href="https://us.posthog.com/signup" rel="nofollow">https://us.posthog.com/signup</a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">Each of these services has a free tier which should be plenty to support local development. If you're self hosting, and you don't want to use Upstash or Posthog, it's pretty easy to replace upstash with a redis container in <code>@carbon/kv</code> and remove the Posthog analytics.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installation</h3><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">First download and initialize the repository dependencies.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ nvm use           # use node v20
$ npm install       # install dependencies
$ npm run db:start  # pull and run the containers"><pre>$ nvm use           <span><span>#</span> use node v20</span>
$ npm install       <span><span>#</span> install dependencies</span>
$ npm run db:start  <span><span>#</span> pull and run the containers</span></pre></div>
<p dir="auto">Create an <code>.env</code> file and copy the contents of <code>.env.example</code> file into it</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ cp ./.env.example ./.env"><pre>$ cp ./.env.example ./.env</pre></div>
<ol dir="auto">
<li>Use the output of <code>npm run db:start</code> to set the supabase entries:</li>
</ol>
<ul dir="auto">
<li><code>SUPABASE_SERVICE_ROLE_KEY=[service_role key]</code></li>
<li><code>SUPABASE_ANON_KEY=[anon key]</code></li>
</ul>
<ol start="2" dir="auto">
<li><a href="https://console.upstash.com/redis" rel="nofollow">Create a Redis database in upstash</a> and copy the following from the <code>REST API</code> section:</li>
</ol>
<ul dir="auto">
<li><code>UPSTASH_REDIS_REST_URL=[UPSTASH_REDIS_REST_URL]</code></li>
<li><code>UPSTASH_REDIS_REST_TOKEN=[UPSTASH_REDIS_REST_TOKEN]</code></li>
</ul>
<ol start="3" dir="auto">
<li>Navigate to the project you created in <a href="https://github.com/crbnos/carbon/blob/main/Trigger.dev">https://cloud.trigger.dev/</a> and copy the following from the <code>Environments &amp; API Keys</code> section:</li>
</ol>
<ul dir="auto">
<li><code>TRIGGER_PUBLIC_API_KEY=[Public 'dev' API Key, starting 'pk_dev*']</code></li>
<li><code>TRIGGER_API_KEY=[Server 'dev' API Key, starting 'tr_dev*']</code></li>
</ul>
<ol start="4" dir="auto">
<li>In Posthog go to <a href="https://%5Bregion%5D.posthog.com/project/%5Bproject-id%5D/settings/project-details" rel="nofollow">https://[region].posthog.com/project/[project-id]/settings/project-details</a> to find your Project ID and Project API key:</li>
</ol>
<ul dir="auto">
<li><code>POSTHOG_API_HOST=[https://[region].posthog.com]</code></li>
<li><code>POSTHOG_PROJECT_PUBLIC_KEY=[Project API Key starting 'phc*']</code></li>
</ul>
<ol start="5" dir="auto">
<li>Add a <code>STRIPE_SECRET_KEY</code> from the Stripe admin interface, and then run <code>npm run -w @carbon/stripe register:stripe</code> to get a <code>STRIP_WEBHOOK_SECRET</code></li>
</ol>
<ul dir="auto">
<li><code>STRIPE_SECRET_KEY="sk_test_*************"</code></li>
<li><code>STRIP_WEBHOOK_SECRET="whsec_************"</code></li>
</ul>
<p dir="auto">Then you can run the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ npm run db:build     # run db migrations and seed script
$ npm run build        # build the packages"><pre>$ npm run db:build     <span><span>#</span> run db migrations and seed script</span>
$ npm run build        <span><span>#</span> build the packages</span></pre></div>
<p dir="auto">Finally, start the apps and packages:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ npm run dev
$ npm run dev:mes        # npm run dev in all apps &amp; packages"><pre>$ npm run dev
$ npm run dev:mes        <span><span>#</span> npm run dev in all apps &amp; packages</span></pre></div>
<p dir="auto">You can now sign in with:</p>
<p dir="auto">username: <a href="mailto:your-email@address.com">your-email@address.com</a>
password: carbon</p>
<p dir="auto">After installation you should be able run the apps locally.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Application</th>
<th>URL</th>
</tr>
</thead>
<tbody>
<tr>
<td>ERP</td>
<td><a href="http://localhost:3000/" rel="nofollow">http://localhost:3000</a></td>
</tr>
<tr>
<td>MES</td>
<td><a href="http://localhost:3001/" rel="nofollow">http://localhost:3001</a></td>
</tr>
<tr>
<td>Academy</td>
<td><a href="http://localhost:4111/" rel="nofollow">http://localhost:4111</a></td>
</tr>
<tr>
<td>Starter</td>
<td><a href="http://localhost:4000/" rel="nofollow">http://localhost:4000</a></td>
</tr>
<tr>
<td>Postgres</td>
<td>postgresql://postgres:postgres@localhost:54322/postgres</td>
</tr>
<tr>
<td>Supabase Studio</td>
<td><a href="http://localhost:54323/project/default" rel="nofollow">http://localhost:54323/project/default</a></td>
</tr>
<tr>
<td>Mailpit</td>
<td><a href="http://localhost:54324/" rel="nofollow">http://localhost:54324</a></td>
</tr>
<tr>
<td>Edge Functions</td>
<td><a href="http://localhost:54321/functions/v1/%3Cfunction-name%3E" rel="nofollow">http://localhost:54321/functions/v1/</a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Notes</h3><a id="user-content-notes" aria-label="Permalink: Notes" href="#notes"></a></p>
<p dir="auto">To kill the database containers in a non-recoverable way, you can run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ npm run db:kill   # stop and delete all database containers"><pre>$ npm run db:kill   <span><span>#</span> stop and delete all database containers</span></pre></div>
<p dir="auto">To restart and reseed the database, you can run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ npm run db:build # runs db:kill, db:start, and setup"><pre>$ npm run db:build <span><span>#</span> runs db:kill, db:start, and setup</span></pre></div>
<p dir="auto">To run a particular application, use the <code>-w workspace</code> flag.</p>
<p dir="auto">For example, to run test command in the <code>@carbon/react</code> package you can run:</p>
<div data-snippet-clipboard-copy-content="$ npm run test -w @carbon/react"><pre><code>$ npm run test -w @carbon/react
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">API</h2><a id="user-content-api" aria-label="Permalink: API" href="#api"></a></p>
<p dir="auto">The API documentation is located in the ERP app at <code>${ERP}/x/api/js/intro</code>. It is auto-generated based on changes to the database.</p>
<p dir="auto">There are two ways to use the API:</p>
<ol dir="auto">
<li>From another codebase using a supabase client library:</li>
</ol>
<ul dir="auto">
<li><a href="https://supabase.com/docs/reference/javascript/introduction" rel="nofollow">Javascript</a></li>
<li><a href="https://supabase.com/docs/reference/dart/introduction" rel="nofollow">Flutter</a></li>
<li><a href="https://supabase.com/docs/reference/python/introduction" rel="nofollow">Python</a></li>
<li><a href="https://supabase.com/docs/reference/csharp/introduction" rel="nofollow">C#</a></li>
<li><a href="https://supabase.com/docs/reference/swift/introduction" rel="nofollow">Swift</a></li>
<li><a href="https://supabase.com/docs/reference/kotlin/introduction" rel="nofollow">Kotlin</a></li>
</ul>
<ol start="2" dir="auto">
<li>From within the codebase using our packages.</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">From another Codebase</h3><a id="user-content-from-another-codebase" aria-label="Permalink: From another Codebase" href="#from-another-codebase"></a></p>
<p dir="auto">Navigate to settings in the ERP to generate an API key. If you're self-hosting you can also use the supabase service key instead of the public key for root access. In that case you don't needto include the <code>carbon-key</code> header.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import { Database } from &quot;@carbon/database&quot;;
import { createClient } from &quot;@supabase/supabase-js&quot;;

const apiKey = process.env.CARBON_API_KEY;
const apiUrl = process.env.CARBON_API_URL;
const publicKey = process.env.CARBON_PUBLIC_KEY;

const carbon = createClient<Database>(apiUrl, publicKey, {
  global: {
    headers: {
      &quot;carbon-key&quot;: apiKey,
    },
  },
});

// returns items from the company associated with the api key
const { data, error } = await carbon.from(&quot;item&quot;).select(&quot;*&quot;);"><pre><span>import</span> <span>{</span> <span>Database</span> <span>}</span> <span>from</span> <span>"@carbon/database"</span><span>;</span>
<span>import</span> <span>{</span> <span>createClient</span> <span>}</span> <span>from</span> <span>"@supabase/supabase-js"</span><span>;</span>

<span>const</span> <span>apiKey</span> <span>=</span> <span>process</span><span>.</span><span>env</span><span>.</span><span>CARBON_API_KEY</span><span>;</span>
<span>const</span> <span>apiUrl</span> <span>=</span> <span>process</span><span>.</span><span>env</span><span>.</span><span>CARBON_API_URL</span><span>;</span>
<span>const</span> <span>publicKey</span> <span>=</span> <span>process</span><span>.</span><span>env</span><span>.</span><span>CARBON_PUBLIC_KEY</span><span>;</span>

<span>const</span> <span>carbon</span> <span>=</span> <span>createClient</span><span>&lt;</span><span>Database</span><span>&gt;</span><span>(</span><span>apiUrl</span><span>,</span> <span>publicKey</span><span>,</span> <span>{</span>
  <span>global</span>: <span>{</span>
    <span>headers</span>: <span>{</span>
      <span>"carbon-key"</span>: <span>apiKey</span><span>,</span>
    <span>}</span><span>,</span>
  <span>}</span><span>,</span>
<span>}</span><span>)</span><span>;</span>

<span>// returns items from the company associated with the api key</span>
<span>const</span> <span>{</span> data<span>,</span> error <span>}</span> <span>=</span> <span>await</span> <span>carbon</span><span>.</span><span>from</span><span>(</span><span>"item"</span><span>)</span><span>.</span><span>select</span><span>(</span><span>"*"</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">From the Monorepo</h3><a id="user-content-from-the-monorepo" aria-label="Permalink: From the Monorepo" href="#from-the-monorepo"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="import { getCarbonServiceRole } from &quot;@carbon/auth&quot;;
const carbon = getCarbonServiceRole();

// returns all items across companies
const { data, error } = await carbon.from(&quot;item&quot;).select(&quot;*&quot;);

// returns items from a specific company
const companyId = &quot;xyz&quot;;
const { data, error } = await carbon
  .from(&quot;item&quot;)
  .select(&quot;*&quot;)
  .eq(&quot;companyId&quot;, companyId);"><pre><span>import</span> <span>{</span> <span>getCarbonServiceRole</span> <span>}</span> <span>from</span> <span>"@carbon/auth"</span><span>;</span>
<span>const</span> <span>carbon</span> <span>=</span> <span>getCarbonServiceRole</span><span>(</span><span>)</span><span>;</span>

<span>// returns all items across companies</span>
<span>const</span> <span>{</span> data<span>,</span> error <span>}</span> <span>=</span> <span>await</span> <span>carbon</span><span>.</span><span>from</span><span>(</span><span>"item"</span><span>)</span><span>.</span><span>select</span><span>(</span><span>"*"</span><span>)</span><span>;</span>

<span>// returns items from a specific company</span>
<span>const</span> <span>companyId</span> <span>=</span> <span>"xyz"</span><span>;</span>
<span>const</span> <span>{</span> data<span>,</span> error <span>}</span> <span>=</span> <span>await</span> <span>carbon</span>
  <span>.</span><span>from</span><span>(</span><span>"item"</span><span>)</span>
  <span>.</span><span>select</span><span>(</span><span>"*"</span><span>)</span>
  <span>.</span><span>eq</span><span>(</span><span>"companyId"</span><span>,</span> <span>companyId</span><span>)</span><span>;</span></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Thingino: Open-Source Firmware for IP Cameras (263 pts)]]></title>
            <link>https://thingino.com/</link>
            <guid>44791984</guid>
            <pubDate>Mon, 04 Aug 2025 22:22:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thingino.com/">https://thingino.com/</a>, See on <a href="https://news.ycombinator.com/item?id=44791984">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

      

      <h2>Supported Hardware</h2>

      <p>Please note that we list not only the camera model, but also its SoC, image sensor, Wi-Fi module, and flash chip size.
        These must match to be supported by the firmware. We have found that some manufacturers change the hardware in different
        batches of the same module without notice.</p>

      <h3>Indoor IP Cameras</h3>

      <div>
        <dl>
          <dt>360 AP1PA3</dt>
          <dd><img src="https://thingino.com/a/cam/360-ap1pa3.webp" alt="360 AP1PA3"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-360_ap1pa3_t31x_gc4653_atbm6031.bin">T31X, GC4653, ATBM6031, 16MB</a></dd>
        </dl>
        <dl>
          <dt>AJCloud T-CP2011-W32A
          </dt><dd><img src="https://thingino.com/a/cam/ajcloud-cp2011.webp" alt="AJCloud CP2011"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-ajcloud_cp2011_t23n_cs2336_atbm6132bu.bin">T23N, SC2336, ATBM6132BU, 8MB</a></dd>
        </dl>
        <dl>
          <dt>AJCloud T-CP8010TF-W3M
          </dt><dd><img src="https://thingino.com/a/cam/ajcloud-cp8010.webp" alt="AJCloud CP8010"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-ajcloud_cp8010_t23n_cs2336p_atbm6132bu.bin">T23N, SC2336P, ATBM6132BU, 8MB</a></dd>
        </dl>
        <dl>
          <dt>Aobocam A12</dt>
          <dd><img src="https://thingino.com/a/cam/aobocam-a12.webp" alt="Aobocam A12"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-aobocam_a12_t23dl_jxh63p_txw901u.bin">T23DL, JHX63P, TXW901U, 8MB</a></dd>
        </dl>
        <dl>
          <dt>Aoqee C1</dt>
          <dd><img src="https://thingino.com/a/cam/aoqee-c1.webp" alt="Aoqee C1"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-aoqee_c1_t23n_sc2336_atbm6062.bin">T23N, SC2336, ATBM6062, 8MB</a></dd>
        </dl>
        <dl>
          <dt>ATOM Cam 1</dt>
          <dd><img src="https://thingino.com/a/cam/atom-cam-1.webp" alt="ATOM Cam 1"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wyze_cam2_t20x_jxf22_rtl8189ftv.bin">T20X, JXF22, RTL8189FTV, 16MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wyze_cam2_t20x_jxf23_rtl8189ftv.bin">T20X, JXF23, RTL8189FTV, 16MB</a></dd>
          <dd><a href="https://github.com/wltechblog/thingino-installers">Installation</a></dd>
        </dl>
        <dl>
          <dt>ATOM Cam 2</dt>
          <dd><img src="https://thingino.com/a/cam/atom-cam-2.webp" alt="ATOM Cam 2"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-atom_cam2_t31x_gc2053_atbm6031.bin">T31X, GC2053, ATBM6031, 16MB</a></dd>
          <dd><a href="https://github.com/wltechblog/thingino-installers">Installation</a></dd>
        </dl>
        <dl>
          <dt>Cinnado D1</dt>
          <dd><img src="https://thingino.com/a/cam/cinnado-d1.webp" alt="Cinnado D1"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-cinnado_d1_t23n_sc2336_atbm6012bx.bin">T23N, SC2336, ATBM6012BX, 8MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-cinnado_d1_t31l_sc2336_atbm6031.bin">T31L, SC2336, ATBM6031, 8MB</a></dd>
          <dd><a href="https://github.com/wltechblog/thingino-installers">Installation</a></dd>
        </dl>
        <dl>
          <dt>Eufy C120 (T8400X)</dt>
          <dd><img src="https://thingino.com/a/cam/eufy-c120.webp" alt="Eufy C120 (T8400X)"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-eufy_t8400x_t31x_sc3235_syn4343.bin">T31X, SC3235, SYN4343, 32MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-eufy_t8400x_t31x_sc3338_syn4343.bin">T31X, SC3338, SYN4343, 32MB</a></dd>
        </dl>
        <dl>
          <dt>Eufy E220 (T8410C/X)</dt>
          <dd><img src="https://thingino.com/a/cam/eufy-t8410x.webp" alt="Eufy E220 (T8410X)"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-eufy_t8410c_t31x_sc3338_syn4343.bin">T31X, SC3338, ATBM6031X, 32MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-eufy_t8410x_t31x_sc3235_syn4343.bin">T31X, SC3235, SYN4343, 32MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-eufy_t8410x_t31x_sc3335_syn4343.bin">T31X, SC3335, SYN4343, 32MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-eufy_t8410x_t31x_sc3336_syn4343.bin">T31X, SC3336, SYN4343, 32MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-eufy_t8410x_t31x_sc3338_syn4343.bin">T31X, SC3338, SYN4343, 32MB</a></dd>
        </dl>
        <dl>
          <dt>eLife ET-N3431H-DW</dt>
          <dd><img src="https://thingino.com/a/cam/elife-et-n4341h-dw.webp" alt="eLife ET-N3431H-DW"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-elife_etn3431hdw_t31x_os03b10_ssv6155.bin">T31X, OS03B10, SSV6155, 16MB</a></dd>
        </dl>
        <dl>
          <dt>Galayou G2</dt>
          <dd><img src="https://thingino.com/a/cam/galayou-g2.webp" alt="Galayou G2"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-galayou_g2_t23n_sc2336_atbm6012bx.bin">T23N, SC2336, ATBM6012BX, 8MB</a></dd>
        </dl>
        <dl>
          <dt>Galayou G7</dt>
          <dd><img src="https://thingino.com/a/cam/galayou-g7.webp" alt="Galayou G7"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-galayou_g7_t23n_sc2336_atbm6012bx.bin">T23N, SC2336, ATBM6012BX, 8MB</a></dd>
        </dl>
        <dl>
          <dt>GNCC GC2</dt>
          <dd><img src="https://thingino.com/a/cam/gncc-gc2.webp" alt="GNCC GC2"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-gncc_gc2_t23n_sc2336_atbm6012bx.bin">T23N, SC2336, ATBM6012BX, 8MB</a></dd>
        </dl>
        <dl>
          <dt>Hualai HL-JDPAN01</dt>
          <dd><img src="https://thingino.com/a/cam/hualai-hl-jdpan01.webp" alt="Hualai HL-JDPAN01"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-hl_jdpan01_t31l_gc2053_atbm6031.bin">T31L, GC2053, ATBM6031, 16MB</a></dd>
        </dl>
        <dl>
          <dt>iFlytek XFP301-M</dt>
          <dd><img src="https://thingino.com/a/cam/iflytek-xfp301-m.webp" alt="iFlytek XFP301-M"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-iflytek_xfp301m_t31x_jxq03_rtl8188ftv.bin">T31ZX, JXQ03, RTL8188FTV, 16MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-iflytek_xfp301m_t31x_jxq03_ssv6155.bin">T31ZX, JXQ03, SSV6155, 16MB</a></dd>
        </dl>
        <dl>
          <dt>Imou Ranger 2</dt>
          <dd><img src="https://thingino.com/a/cam/imou-ranger-2.webp" alt="Imou Ranger 2"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-imou_ranger2_t31n_gc2053_ssv6155.bin">T31N, GC2053, SSV6155, 8MB</a></dd>
        </dl>
        <dl>
          <dt>Jooan A6M</dt>
          <dd><img src="https://thingino.com/a/cam/jooan-a6m.webp" alt="Jooan A6M"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-jooan_a6m_t23n_sc1a4t_atbm6012bx.bin">T23N, SC1A4T, ATBM6012BX, 8MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-jooan_a6m_t23n_sc1a4t_ssv6355.bin">T23N, SC1A4T, SSV6355, 8MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/wiki/Camera:-Jooan-A6M">Installation</a></dd>
        </dl>
        <dl>
          <dt>Jooan C9TS</dt>
          <dd><img src="https://thingino.com/a/cam/jooan-c9ts.webp" alt="Jooan C9TS"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-jooan_c9ts_t23n_sc2336p_atbm6132u.bin">T23N, SC2336P, ATBM6132U, 8MB</a></dd>
        </dl>
        <dl>
          <dt>Jooan Q3H</dt>
          <dd><img src="https://thingino.com/a/cam/jooan-q3h.webp" alt="Jooan Q3H"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-jooan_q3h_t30l_sc1235_rtl8189ftv.bin">T30L, SC1235, RTL8189FTV, 16MB</a></dd>
        </dl>
        <dl>
          <dt>LongPlus X07</dt>
          <dd><img src="https://thingino.com/a/cam/longplus-x07.webp" alt="LongPlus X07"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-longplus_x07_t31n_jxf23_rtl8189ftv.bin">T31N, JXF23, RTL8189FTV, 16MB</a></dd>
        </dl>
        <dl>
          <dt>LSC 3215672</dt>
          <dd><img src="https://thingino.com/a/cam/lsc-3215672.webp" alt="LSC 3215672"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-lsc_3215672_t23n_sc2331_atbm6012bx.bin">T23N, SC2331, ATBM6012BX, 8MB</a></dd>
        </dl>
        <dl>
          <dt>Neos SmartCam 2</dt>
          <dd><img src="https://thingino.com/a/cam/neos-smartcam2.webp" alt="Neos SmartCam 2"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wyze_cam2_t20x_jxf22_rtl8189ftv.bin">T20X, JXF22, RTL8189FTV, 16MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wyze_cam2_t20x_jxf23_rtl8189ftv.bin">T20X, JXF23, RTL8189FTV, 16MB</a></dd>
          <dd><a href="https://github.com/wltechblog/thingino-installers">Installation</a></dd>
        </dl>
        <dl>
          <dt>NexHT 86336</dt>
          <dd><img src="https://thingino.com/a/cam/nexht-86336.webp" alt="NexHT 86336"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-nexht_86336_t21z_jxf37_rtl8188ftv.bin">T21Z, JXF37, RTL8188FTV, 8MB</a></dd>
        </dl>
        <dl>
          <dt>Personal Cam Pan</dt>
          <dd><img src="https://thingino.com/a/cam/personal-campan.webp" alt="Personal Cam Pan"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-personal_campan_t31x_gc2053_atbm6031.bin">T31X, GC2053, ATBM6031, 16MB</a></dd>
        </dl>
        <dl>
          <dt>Personal Cam 2</dt>
          <dd><img src="https://thingino.com/a/cam/personal-cam-2.webp" alt="Personal Cam 2"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-personal_cam2_t31x_gc2053_atbm6031.bin">T31X, GC2053, ATBM6031, 16MB</a></dd>
        </dl>
        <dl>
          <dt>Pesita X09</dt>
          <dd><img src="https://thingino.com/a/cam/pesita-x09.webp" alt="Pesita X09"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-pesita_x09_t31n_jxf23_rtl8189ftv.bin">T31N, JXF23, RTL8189FTV, 16MB</a></dd>
        </dl>
        <dl>
          <dt>PrimeCables 08360</dt>
          <dd><img src="https://thingino.com/a/cam/primecables-08360.webp" alt="PrimeCables 08360"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-primecables_08360_t21z_sc2300_rtl8188ftv.bin">T21Z, SC2300, RTL8188FTV, 8MB</a></dd>
        </dl>
        <dl>
          <dt>PrimeCables 08361</dt>
          <dd><img src="https://thingino.com/a/cam/primecables-08361.webp" alt="PrimeCables 08361"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-primecables_08361_t21n_sc2300_rtl8188ftv.bin">T21N, SC2300, RTL8188FTV, 8MB</a></dd>
        </dl>
        <dl>
          <dt>Sonoff Slim Gen2</dt>
          <dd><img src="https://thingino.com/a/cam/sonoff-s2.webp" alt="Sonoff Cam Slim Gen2"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-sonoff_s2_t23n_sc2336_atbm6012bx.bin">T23N, SC2336, ATBM6012BX, 8MB</a></dd>
        </dl>
        <dl>
          <dt>TP-Link Tapo C100</dt>
          <dd><img src="https://thingino.com/a/cam/tapo-c100.webp" alt="Tapo C100"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-tplink_tapo_c100_t23n_sc2336p_wq9001.bin">T23N, SC2336P, WQ9001, 8MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-tplink_tapo_c100_t31l_sc2336_rtl8188ftv.bin">T31L, SC2336, RTL8188FTV, 8MB</a></dd>
        </dl>
        <dl>
          <dt>TP-Link Tapo C110</dt>
          <dd><img src="https://thingino.com/a/cam/tapo-c100.webp" alt="Tapo C110"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-tplink_tapo_c110_t23n_sc2336p_wq9001.bin">T23N, SC2336P, WQ9001, 8MB</a></dd>
        </dl>
        <dl>
          <dt>Vanhua DJZ</dt>
          <dd><img src="https://thingino.com/a/cam/vanhua-djz.webp" alt="Vanhua DJZ"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-vanhua_djz_t31n_gc2083_eth.bin">T31N, GC2083, ETH, 16MB</a></dd>
        </dl>
        <dl>
          <dt>Vanhua FJZ</dt>
          <dd><img src="https://thingino.com/a/cam/vanhua-fjz.webp" alt="Vanhua FJZ"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-vanhua_fjz_t31x_gc4653_eth.bin">T31X, GC4653, ETH, 16MB</a></dd>
        </dl>
        <dl>
          <dt>Victure PC420</dt>
          <dd><img src="https://thingino.com/a/cam/victure-pc420.webp" alt="Victure PC420"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-victure_pc420_t21n_jxf23_eth+rtl8188ftv.bin">T21N, JXF23, RTL8188FTV, 8MB</a></dd>
        </dl>
        <dl>
          <dt>Wanjiaan G7</dt>
          <dd><img src="https://thingino.com/a/cam/!photo.webp" alt="Wanjiaan G7"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wanjiaan_g7_t31x_jxf37_eth.bin">T31X, JXF37, ETH, 16MB</a></dd>
        </dl>
        <dl>
          <dt>Wanjiaan HDC-51</dt>
          <dd><img src="https://thingino.com/a/cam/wanjiaan-hdc51.webp" alt="Wanjiaan HDC-51"></dd>
          <dd><span>China Mobile</span></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wanjiaan_hdc51_t21n_sc2235_rtl8189ftv.bin">T21N, SC2235, RTL8189FTV, 16MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wanjiaan_hdc51_t31l_jxf37_rtl8188ftv.bin">T31L, JXF37, RTL8188FTV, 16MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wanjiaan_hdc51_t31l_sc2332_rtl8188ftv.bin">T31L, SC2332, RTL8188FTV, 16MB</a></dd>
        </dl>
        <dl>
          <dt>Wanjiaan HDC-55</dt>
          <dd><img src="https://thingino.com/a/cam/wanjiaan-hdc55.webp" alt="Wanjiaan HDC-55"></dd>
          <dd><span>China Mobile</span></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wanjiaan_hdc55_t31n_sc2332_rtl8188ftv.bin">T31N, SC2332, RTL8188FTV, 16MB</a></dd>
        </dl>
        <dl>
          <dt>Wansview K5</dt>
          <dd><img src="https://thingino.com/a/cam/wansview-k5.webp" alt="Wansview K5"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wansview_k5_t21n_ov2735b_mt7601sta.bin">T21N, OV2735b, MT7601STA, 8MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wansview_k5_t21n_os02b10_mt7601sta.bin">T21N, OS02B10, MT7601STA, 8MB</a></dd>
        </dl>
        <dl>
          <dt>Wansview Q5</dt>
          <dd><img src="https://thingino.com/a/cam/wansview-q5.webp" alt="Wansview Q5"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wansview_q5_t23n_sc2336_atbm6012bx.bin">T23N, SC2336, ATBM6012BX, 8MB</a></dd>
        </dl>
        <dl>
          <dt>WUUK Y0310</dt>
          <dd><img src="https://thingino.com/a/cam/wuuk-y0310.webp" alt="WUUK Y0310"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wuuk_y0310_t31x_sc401ai_ssv6158.bin">T31X, SC401AI, SSV6158, 16MB</a></dd>
          <dd><a href="https://github.com/wltechblog/thingino-installers">Installation</a></dd>
        </dl>
        <dl>
          <dt>WUUK Y0510</dt>
          <dd><img src="https://thingino.com/a/cam/wuuk-y0510.webp" alt="WUUK Y0510"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wuuk_y0510_t31x_sc401ai_ssv6158.bin">T31X, SC401AI, SSV6158, 16MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wuuk_y0510_t31x_sc4336p_ssv6158.bin">T31X, SC4336p, SSV6158, 16MB</a></dd>
          <dd><a href="https://github.com/wltechblog/thingino-installers">Installation</a></dd>
        </dl>
        <dl>
          <dt>Wyze Cam Pan 1</dt>
          <dd><img src="https://thingino.com/a/cam/wyze-cp1.webp" alt="Wyze Cam Pan 1"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wyze_campan1_t20x_jxf22_rtl8189etv.bin">T20X, JXF22, RTL8189ETV, 16MB</a></dd>
          <dd><a href="https://github.com/wltechblog/thingino-installers">Installation</a></dd>
        </dl>
        <dl>
          <dt>Wyze Cam 2</dt>
          <dd><img src="https://thingino.com/a/cam/wyze-c2.webp" alt="Wyze Cam 2"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wyze_cam2_t20x_jxf22_rtl8189ftv.bin">T20X, JXF22, RTL8189FTV, 16MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wyze_cam2_t20x_jxf23_rtl8189ftv.bin">T20X, JXF23, RTL8189FTV, 16MB</a></dd>
          <dd><a href="https://github.com/wltechblog/thingino-installers">Installation</a></dd>
        </dl>
        <dl>
          <dt>Wyze Cam Pan 2</dt>
          <dd><img src="https://thingino.com/a/cam/wyze-cp2.webp" alt="Wyze Cam Pan 2"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wyze_campan2_t31x_gc2053_atbm6031.bin">T31X, GC2053, ATBM6031, 16MB</a></dd>
          <dd><a href="https://github.com/wltechblog/thingino-installers">Installation</a></dd>
        </dl>
        <dl>
          <dt>Wyze Cam 3</dt>
          <dd><img src="https://thingino.com/a/cam/wyze-c3.webp" alt="Wyze Cam 3"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wyze_cam3_t31al_gc2053_atbm6031.bin">T31AL, GC2053, ATBM6031, 16MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wyze_cam3_t31x_gc2053_atbm6031.bin">T31X, GC2053, ATBM6031, 16MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wyze_cam3_t31x_gc2053_rtl8189ftv.bin">T31X, GC2053, RTL8189FTV, 16MB</a></dd>
          <dd><a href="https://github.com/wltechblog/thingino-installers">Installation</a></dd>
        </dl>
        <dl>
          <dt>Xiaomi HL-CAM04</dt>
          <dd><img src="https://thingino.com/a/cam/xiaomi-hl-cam04.webp" alt="Xiaomi HL-CAM04"></dd>
          <dd>
            <a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-xiaomi_hlcam04_t31n_sc3335_atbm6031.bin">T31N, SC3335, ATBM6031, 16MB</a></dd>
        </dl>
        <dl>
          <dt>Xiaomi iSC5</dt>
          <dd><img src="https://thingino.com/a/cam/xiaomi-isc5.webp" alt="Xiaomi iSC5"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-xiaomi_xiaofang_t20l_jxf22_rtl8189ftv.bin">T20L, JXF22, RTL8189FTV, 16MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-xiaomi_xiaofang_t20l_jxf23_rtl8189ftv.bin">T20L, JXF23, RTL8189FTV, 16MB</a></dd>
        </dl>
        <dl>
          <dt>Xiaomi SXJ02ZM</dt>
          <dd><img src="https://thingino.com/a/cam/xiaomi-sxj02zm.webp" alt="Xiaomi iSC5"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-xiaomi_sxj02zm_t20l_ps5220_rtl8189ftv.bin">T20L, PS5250, RTL8189FTV, 16MB</a></dd>
        </dl>
        <dl>
          <dt>Xiaomi MJSXJ03HL</dt>
          <dd><img src="https://thingino.com/a/cam/xiaomi-mjsxj03hl.webp" alt="Xiaomi MJSXJ03HL"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-xiaomi_mjsxj03hl_t31l_jxq03p_rtl8189ftv.bin">T31L, JXQ03p, RTL8189FTV, 16MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-xiaomi_mjsxj03hl_t31n_jxq03_rtl8189ftv.bin">T31N, JXQ03, RTL8189FTV, 16MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-xiaomi_mjsxj03hl_t31n_jxq03p_rtl8189ftv.bin">T31N, JXQ03p, RTL8189FTV, 16MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/wiki/Camera:-Xiaomi-MJSXJ03HL">Installation</a></dd>
        </dl>
        <dl>
          <dt>ZTE K540</dt>
          <dd><img src="https://thingino.com/a/cam/zte-k540.webp" alt="ZTE K540"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-zte_k540_t31x_sc4336_eth+atbm6032.bin">T31X, SC4336, ETH. ATBM6032, 16MB</a></dd>
        </dl>
      </div>

      <h3>Bulb IP Cameras</h3>

      <div>
        <dl>
          <dt>AJCloud T-CP8040LF-W3M
          </dt><dd><img src="https://thingino.com/a/cam/ajcloud-cp8040.webp" alt="AJCloud CP8010"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-ajcloud_cp8040_t23n_cs2336p_atbm6132bu.bin">T23N, SC2336P, ATBM6132BU, 8MB</a></dd>
        </dl>
        <dl>
          <dt>Jooan T2R</dt>
          <dd><img src="https://thingino.com/a/cam/jooan-t2r.webp" alt="Jooan T2R"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-jooan_t2r_t23n_sc1a4t_atbm6012bx.bin">T23N, SC1A4T, ATBM6012BX, 8MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-jooan_t2r_t23n_sc1a4t_ssv6355.bin">T23N, SC1A4T, SSV6355, 8MB</a></dd>
        </dl>
        <dl>
          <dt>LaView L2</dt>
          <dd><img src="https://thingino.com/a/cam/laview-l2.webp" alt="LaView L2"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-laview_l2_t31l_sc3338_atbm6012b.bin">T31L, SC3338, ATBM6012B, 8MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-laview_l2_t31l_sc3338_ssv6256p.bin">T31L, SC3338, SSV6256P, 8MB</a></dd>
        </dl>
        <dl>
          <dt>Wansview G6</dt>
          <dd><img src="https://thingino.com/a/cam/wansview-g6.webp" alt="Wansview G6"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wansview_g6_t31l_sc2336_atbm6012b.bin">T31L, SC2336, ATBM6012B, 8MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wansview_g6_t31l_sc2336_ssv6256p.bin">T31L, SC2336, SSV6256P, 8MB</a></dd>
        </dl>
      </div>

      <h3>Outdoor IP Cameras</h3>

      <div>
        <dl>
          <dt>AOSU C5L</dt>
          <dd><img src="https://thingino.com/a/cam/aosu-c5l.webp" alt="AOSU C5L"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-aosu_c5l_t31l_sc3336_rtl8188ftv.bin">T31L, SC3336, RTL8188FTV, 16MB</a></dd>
        </dl>
        <dl>
          <dt>Dekco DC5L</dt>
          <dd><img src="https://thingino.com/a/cam/dekco-dc5l.webp" alt="Dekco DC5L"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-dekco_dc5l_t31l_sc3336_rtl8188ftv.bin">T31L, SC3336, RTL8188FTV, 16MB</a></dd>
        </dl>
        <dl>
          <dt>Eufy E220 (T8441X)</dt>
          <dd><img src="https://thingino.com/a/cam/eufy-t8441x.webp" alt="Eufy Outdoor (T8441X)"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-eufy_t8441x_t31x_sc3335_syn4343.bin">T31X, SC3335, SYN4343, 32MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-eufy_t8441x_t31x_sc3338_syn4343.bin">T31X, SC3338, SYN4343, 32MB</a></dd>
        </dl>
        <dl>
          <dt>Eufy E210 (T8442X)</dt>
          <dd><img src="https://thingino.com/a/cam/eufy-t8442x.webp" alt="Eufy E210 Outdoor (T8442X)"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-eufy_t8442x_t31x_sc3335_syn4343.bin">T31X, SC3335, SYN4343, 32MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-eufy_t8442x_t31x_sc3338_syn4343.bin">T31X, SC3338, SYN4343, 32MB</a></dd>
        </dl>
        <dl>
          <dt>Feisda WF-HD620</dt>
          <dd><img src="https://thingino.com/a/cam/feisda-wf-hd620.webp" alt="Fiesda WF-HD620"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-feisda_hd620_t31x_jxq03_eth+rtl8188ftv.bin">T31X, JXQ03, ETH, RTL8188FTV, 16MB</a></dd>
        </dl>
        <dl>
          <dt>Galayou Y4</dt>
          <dd><img src="https://thingino.com/a/cam/galayou-y4.webp" alt="Galayou Y4"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-galayou_y4_t23n_sc2336_atbm6062.bin">T23N, SC2336, ATBM6062, 8MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-galayou_y4_t23n_sc2336p_atbm6062.bin">T23N, SC2336P, ATBM6062, 8MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-galayou_y4_t31l_sc2336_atbm6012bx.bin">T31L, SC2336, ATBM6012BX, 8MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-galayou_y4_t31l_sc2336_atbm6032.bin">T31L, SC2336, ATBM6032, 8MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-galayou_y4_t31n_sc2336_atbm6012b.bin">T31N, SC2336, ATBM6012B, 8MB</a></dd>
          <dd><a href="https://github.com/wltechblog/thingino-installers">Installation</a></dd>
        </dl>
        <dl>
          <dt>Ginzzu OP-200</dt>
          <dd><img src="https://thingino.com/a/cam/ginzzu-op200.webp" alt="Ginzzu OP-200"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-ginzzu_op200_t31l_gc2083_ssv6155.bin">T31L, GC2083, SSV6155, 16MB</a></dd>
        </dl>
        <dl>
          <dt>Howell QJ05T</dt>
          <dd><img src="https://thingino.com/a/cam/howell-qj05t.webp" alt="Howell QJ05T"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-howell_qj05t_t20l_sc2235_eth+rtl8188ftv.bin">T20L, SC2235, ETH, RTL8188FTV, 8MB</a></dd>
        </dl>
        <dl>
          <dt>Jienuo JN-107-AR-E-WIFI</dt>
          <dd><img src="https://thingino.com/a/cam/jienuo-jn107arewifi.webp" alt="Jienuo JN-107-AR-E-WIFI"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-jienuo_jn107arewifi_t31x_sc5235_eth+rtl8731bu.bin">T31X, SC5235, ETH, RTL8131BU, 16MB</a></dd>
        </dl>
        <dl>
          <dt>Jooan A2R</dt>
          <dd><img src="https://thingino.com/a/cam/jooan-a2r.webp" alt="Jooan A2R"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-jooan_a2r_t23n_sc1a4t_atbm6012bx.bin">T23N, SC1A4T, ATBM6012BX, 8MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-jooan_a2r_t23n_sc1a4t_ssv6355.bin">T23N, SC1A4T, SSV6355, 8MB</a></dd>
        </dl>
        <dl>
          <dt>Jooan F2T</dt>
          <dd><img src="https://thingino.com/a/cam/jooan-f2t.webp" alt="Jooan F2T"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-jooan_f2t_t30x_sc4236_eth.bin">T30X, SC4236, ETH, 16MB</a></dd>
        </dl>
        <dl>
          <dt>Jooan Q3R</dt>
          <dd><img src="https://thingino.com/a/cam/jooan-q3r.webp" alt="Jooan Q3R"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-jooan_q3r_t23n_sc1a4t_atbm6012bx.bin">T23N, SC1A4T, ATBM6012BX, 8MB</a></dd>
        </dl>
        <dl>
          <dt>Litokam M1</dt>
          <dd><img src="https://thingino.com/a/cam/litokam-m1.webp" alt="Litokam M1"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-litokam_m1_t31l_sc3336_atbm6012b.bin">T31L, SC3336, ATBM6012B, 8MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-litokam_m1_t31l_sc3336_atbm6012bx.bin">T31L, SC3336, ATBM6012BX, 8MB</a></dd>
        </dl>
        <dl>
          <dt>Overtech OV-59WB</dt>
          <dd><img src="https://thingino.com/a/cam/overtech-ov59wb.webp" alt="Overtech OV-59WB"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-overtech_ov59wb_t31n_sc223a_rtl8188ftv.bin">T31N, SC223A, RTL8188FTV, 16MB</a></dd>
        </dl>
        <dl>
          <dt>Wansview W6</dt>
          <dd><img src="https://thingino.com/a/cam/wansview-w6.webp" alt="Wansview W6"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wansview_w6_t21n_ov2735b_rtl8188ftv.bin">T21N, OV2735b, RTL8188FTV, ETH, 16MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wansview_w6_t21n_os02g10_rtl8188ftv.bin">T21N, OS02G10, RTL8188FTV, ETH, 16MB</a></dd>
        </dl>
        <dl>
          <dt>Wansview W7</dt>
          <dd><img src="https://thingino.com/a/cam/wansview-w7.webp" alt="Wansview W7"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-galayou_y4_t23n_sc2336_atbm6062.bin">T23N, SC2336, ATBM6062, 8MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wansview_w7_t31l_sc2336_atbm6012b.bin">T31L, SC2336, ATBM6012B, 8MB</a></dd>
          <dd><a href="https://github.com/wltechblog/thingino-installers">Installation</a></dd>
        </dl>
        <dl>
          <dt>Wyze Cam Floodlight 1</dt>
          <dd><img src="https://thingino.com/a/cam/wyze-cfl1.webp" alt="Wyze CFL1"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wyze_camfl1_t31al_gc2053_atbm6031.bin">T31AL, GC2053, ATBM6031, 16MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wyze_camfl1_t31x_gc2053_atbm6031.bin">T31X, GC2053, ATBM6031, 16MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wyze_camfl1_t31x_gc2053_rtl8189ftv.bin">T31X, GC2053, RTL8189FTV, 16MB</a></dd>
          <dd><a href="https://github.com/wltechblog/thingino-installers">Installation</a></dd>
        </dl>
        <dl>
          <dt>Wyze Video Doorbell 1</dt>
          <dd><img src="https://thingino.com/a/cam/wyze-vdb1.webp" alt="Wyze VDB1"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wyze_vdb1_t30x_sc4236_rtl8189ftv.bin">T30X, SC4236, RTL8189FTV, 16MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-wyze_vdb1_t31x_sc4236_rtl8189ftv.bin">T31ZX, SC4236, RTL8189FTV, 16MB</a></dd>
        </dl>
        <dl>
          <dt>Xiaomi MJSXJ05HL</dt>
          <dd><img src="https://thingino.com/a/cam/xiaomi-mjsxj05hl.webp" alt="Xiaomi MJSXJ05HL"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-xiaomi_mjsxj05hl_t31l_gc2053_atbm6031.bin">T31L, GC2053, ATBM6031, 16MB</a></dd>
        </dl>
        <dl>
          <dt>XVIM IPCAM-100</dt>
          <dd><img src="https://thingino.com/a/cam/xvim-ipcam-100.webp" alt="XVIM IPCAM-100"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-xvim_ipcam100_t21n_jxf37_eth+rtl8188ftv.bin">T21N, JXF37, ETH, RTL8188FTV, 8MB</a></dd>
        </dl>
      </div>

      <h3>IPC Modules</h3>

      <div>
        <dl>
          <dt>Enzhi / Vanhua AK54</dt>
          <dd><img src="https://thingino.com/a/cam/enz-ak54.webp" alt="Enzhi AK54"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-vanhua_ak54_t31n_gc2053_eth.bin">T31N, GC2053, ETH, 8MB</a></dd>
        </dl>
        <dl>
          <dt>Enzhi / Vanhua H33</dt>
          <dd><img src="https://thingino.com/a/cam/enz-h33.webp" alt="Enzhi H33"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-vanhua_h33_t31l_gc2083_eth.bin">T31L, GC2083, ETH, 8MB</a></dd>
        </dl>
        <dl>
          <dt>Enzhi / Vanhua L34</dt>
          <dd><img src="https://thingino.com/a/cam/enz-l34.webp" alt="Enzhi L34"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-vanhua_l34_t31l_gc2083_eth.bin">T31L, GC2083, ETH, 8MB</a></dd>
        </dl>
        <dl>
          <dt>Enzhi / Vanhua S37i</dt>
          <dd><img src="https://thingino.com/a/cam/enz-s37i.webp" alt="Enzhi S37i"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-vanhua_s37i_t31l_imx307_eth.bin">T31L, IMX307, ETH, 16MB</a></dd>
        </dl>
        <dl>
          <dt>Enzhi / Vanhua Z55</dt>
          <dd><img src="https://thingino.com/a/cam/enz-z55.webp" alt="Enzhi Z55"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-vanhua_z55_t31x_gc4653_eth.bin">T31X, GC4653, ETH, 16MB</a></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/wiki/Camera:-AliExpress-LTIA%E2%80%9037FJZ-(Vanhua-Z55-module)">Installation</a></dd>
        </dl>
        <dl>
          <dt>Enzhi / Vanhua Z55I</dt>
          <dd><img src="https://thingino.com/a/cam/enz-z55i.webp" alt="Enzhi Z55I"></dd>
          <dd><a href="https://github.com/themactep/thingino-firmware/releases/latest/download/thingino-vanhua_z55i_t31x_gc4653_eth.bin">T31X, GC4653, ETH, 16MB</a></dd>
        </dl>
      </div>

      <h3>Web Cameras</h3>

      

      <h3>Development Boards</h3>

      

      <h2>Conditionally Supported Hardware</h2>

      <p>Some brands protect their cameras by writing a secret key into the
        <abbr title="One-Time Programmable">OTP</abbr> area of the <abbr title="System-on-Chip">SoC</abbr>.
        They digitally sign the installed firmware with a matching key, so that replacing the pre-installed
        firmware with one that is not signed with the same key will render the camera unusable, unless you
        replace the SoC with a new, undamaged one.</p>

      

      <p>Color code: <span>Some tested units had Secure Boot.</span>
      <span>All tested units had Secure Boot.</span></p>

      <h2>Mystery Box Hardware</h2>

      <p>These cameras are not necessarily based on Ingenic SoC. Some units purchased on AliExpress were marketed as the same model, but they came with unsupported ARM processors.</p>

      

      <h2>Potentially Supported Cameras</h2>

      <p>We've heard that these cameras use Ingenic SoC, so we think they could be added to the supported list. Unfortunately, we don't have a sample of this camera to work on, so we'd be happy to accept it as a donation to the project. Just a heads-up, this is a non-commercial project, and the people working on it contribute their free time for nothing more than a sense of accomplishment. If you want things to develop faster, offer your help.</p>

      <div>
        <dl>
          <dt>Ezviz CS-MY3-3WHY</dt>
          <dd><img src="https://thingino.com/a/cam/!photo.webp" alt="Galayou G7"></dd>
          <dd><a href="https://thingino.com/donate-hardware">T31X, JXQ03, RTL8189FTV, 16MB</a></dd>
        </dl>
        <dl>
          <dt>Galayou G2</dt>
          <dd><img src="https://thingino.com/a/cam/galayou-g2.webp" alt="Galayou G2"></dd>
          <dd><a href="https://thingino.com/donate-hardware">T31LC, SC2336, ATBM6012BX, 8MB</a></dd>
        </dl>
        <dl>
          <dt>Galayou G7</dt>
          <dd><img src="https://thingino.com/a/cam/galayou-g7.webp" alt="Galayou G7"></dd>
          <dd><a href="https://thingino.com/donate-hardware">T31LC, SC2336, ATBM6012B, 8MB</a></dd>
        </dl>
        <dl>
          <dt>Winees M3 PRO</dt>
          <dd><img src="https://thingino.com/a/cam/winees-m3pro.webp" alt="Winees M3 PRO"></dd>
          <dd><a href="https://thingino.com/donate-hardware">T31X, SC3336, RTL8192FC, 16MB</a></dd>
        </dl>
      </div>

      <h2>Unsupported Hardware</h2>

      <p>Battery powered cameras using the Zeratul platform are not supported, at least for now.</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Projects evaluated to see if they're as free and open source as advertised (155 pts)]]></title>
            <link>https://isitreallyfoss.com/</link>
            <guid>44791554</guid>
            <pubDate>Mon, 04 Aug 2025 21:26:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://isitreallyfoss.com/">https://isitreallyfoss.com/</a>, See on <a href="https://news.ycombinator.com/item?id=44791554">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<header id="top">
				<a href="https://isitreallyfoss.com/">is <strong>it</strong> <em>really</em> <strong>FOSS</strong>?</a>
				
			</header>
			<main>
	<div>

		<h2>
			Where Projects are Evaluated <br>
			<span>To see if they're as free and open source as advertised</span>
		</h2>

		<p>
			The software rights of users are continously (and often opaquely) being eroded by the desire of growth.
			<br>
			This website aims to push back against that by bringing transparency to <a href="https://isitreallyfoss.com/about/foss">FOSS</a> software users.
		</p>

		

		<div>
			<h3>Latest Projects Added</h3>
			
		</div>

		

	</div>
</main>
			
			
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Once a death sentence, cardiac amyloidosis is finally treatable (143 pts)]]></title>
            <link>https://www.nytimes.com/2025/08/04/well/cardiac-amyloidosis.html</link>
            <guid>44790944</guid>
            <pubDate>Mon, 04 Aug 2025 20:23:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2025/08/04/well/cardiac-amyloidosis.html">https://www.nytimes.com/2025/08/04/well/cardiac-amyloidosis.html</a>, See on <a href="https://news.ycombinator.com/item?id=44790944">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2025/08/04/well/cardiac-amyloidosis.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Content-Aware Spaced Repetition (167 pts)]]></title>
            <link>https://www.giacomoran.com/blog/content-aware-sr/</link>
            <guid>44790422</guid>
            <pubDate>Mon, 04 Aug 2025 19:32:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.giacomoran.com/blog/content-aware-sr/">https://www.giacomoran.com/blog/content-aware-sr/</a>, See on <a href="https://news.ycombinator.com/item?id=44790422">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>  <p>Spaced repetition systems are powerful, but they have a fundamental blind spot: they don’t understand what your flashcards are&nbsp;<em>about</em>.</p>
<p>To your SRS, a card asking “what’s the capital of Italy?” and another asking “what country is Rome the capital of?” are treated independently, each with its own isolated review history. It has no concept that reviewing related material should reinforce your memory of the whole topic.</p>
<p>At the heart of every SRS is a&nbsp;<strong>memory model</strong> which predicts how long you’ll remember each card based on your past performance. Most of today’s models ignore the <em>content</em> of the cards entirely. This is where <strong>content-aware memory models</strong> come in: they account for the semantic meaning of your cards, not just your review ratings.</p>
<p>This is more than a minor tweak for scheduling accuracy. It’s a foundational change that makes it practical to build the fluid, intelligent learning tools many have envisioned: from&nbsp;<a href="https://notes.andymatuschak.org/z7wCFe7MP9VeCVApcBLC7SN">idea-centric memory systems</a>&nbsp;that test understanding from multiple angles to truly&nbsp;<a href="https://davidbieber.com/snippets/2024-03-04-conversational-spaced-repetition/">conversational spaced repetition</a>&nbsp;with a voice-enabled AI agent as tutor.</p>
<p>This post explores what content-aware memory models are, and the new kinds of learning experiences they make possible.</p>
<h2 id="contents">Contents</h2>
<ul>
<li><a href="#schedulers-and-memory-models">Schedulers and memory models</a></li>
<li><a href="#content-aware-memory-models">Content-aware memory models</a>
<ul>
<li><a href="#karl">KARL</a></li>
<li><a href="#small-experiments-on-rember-data">Small experiments on Rember data</a></li>
<li><a href="#other-considerations">Other considerations</a></li>
</ul>
</li>
<li><a href="#ux-unlocks">UX unlocks</a></li>
<li><a href="#data-problem">Data problem</a></li>
</ul>
<h2 id="schedulers-and-memory-models">Schedulers and memory models</h2>
<p>I find it useful to distinguish between schedulers and memory models. This distinction wasn’t immediately obvious to me when I first approached the topic, but I’ve found it essential for thinking clearly about spaced repetition systems (SRS). Here, I’ll introduce both concept and I’ll make the case that separating schedulers from memory models enables independent innovation and simplifies the development of each component by isolating user experience (UX) concerns within the scheduler. In the literature, the scheduler is sometimes called the “teacher model” since it decides what to teach, while the memory model is the “student model” since it represents what the student knows.</p>
<p>In Anki and other spaced repetition systems, the <strong>scheduler</strong> is an algorithm that picks the next card to review today, answering the question <em>“Given the review history of every card in the student’s collection, which cards should the student review in this session?”</em>. In practice, when building a spaced repetition system, this is the question you actually care about. The scheduler’s core job is deciding&nbsp;<em>which cards to show today</em>, not just&nbsp;<em>when each card should ideally be reviewed</em>. A card might be “due” for review, but the scheduler might skip it due to daily review limits, prioritize other overdue cards, or defer it based on other goals.</p>
<p>For a long time, the only scheduler available in Anki was <a href="https://faqs.ankiweb.net/what-spaced-repetition-algorithm">a variant of SuperMemo’s SM-2 scheduler</a>, which dates back to <a href="https://www.supermemo.com/en/blog/the-true-history-of-spaced-repetition#1987">1987</a>. It’s remarkably simple yet effective. SuperMemo has since advanced its scheduler, now at version <a href="https://supermemo.guru/wiki/Algorithm_SM-18">SM-18</a>. The latest iterations of the algorithm achieve the same retention levels with fewer reviews, and are more robust when reviews deviate from optimal intervals, for example when a student returns from a break of several weeks. While the SuperMemo schedulers are closed-source, an explanation of how they work is <a href="https://supermemo.guru/wiki/Algorithm_SM-17">available</a>. <a href="https://github.com/open-spaced-repetition/fsrs4anki">FSRS</a> is an open-source scheduler by Jarrett Ye built on similar principles to modern SuperMemo algorithms and can be used in Anki.</p>
<p>A <strong>memory model</strong> predicts forgetting curves, answering the question <em>“Given the review history of every card in the student’s collection, what are the chances the student remembers a specific card at any given moment?”</em></p>
<p>We define <strong>retrievability</strong> as the probability that a student remembers a card at a particular time. In practice, we often model this as a binary outcome where a student either remembers or forgets a card. Some spaced repetition systems allow for more nuanced grading. For example, Anki has four options: “Again”, “Hard”, “Good”, “Easy”. This additional information from the review history can be used to make memory models more accurate.</p>
<p>The forgetting curve plots this retrievability over time. A memory model’s job is to compute these curves based on a student’s review history. Retrievability generally decreases over time, as it becomes more likely that the student will forget the card. For example, here are the forgetting curves estimated by different memory models from the same review history (the figure comes from my <a href="https://www.politesi.polimi.it/handle/10589/186407">master’s thesis</a>):</p>
<p><img alt="Plot of forgetting curves estimated by different memory models from the same review history" loading="lazy" decoding="async" fetchpriority="auto" width="1500" height="900" src="https://www.giacomoran.com/_astro/fc_comparison.DEARgvNj_2owL0b.webp"></p>
<p>The relationship between schedulers and memory models varies across different systems. A scheduler may or may not use a memory model. For example, the <a href="https://en.wikipedia.org/wiki/Leitner_system">Leitner system</a> and SM-2 do not rely on a memory model to schedule reviews, they are based on simple mechanical rules. Modern schedulers like SM-18 and FSRS instead include a memory model (stability and difficulty are used to compute retrievability). I recommend taking a look at Fernando Borretti’s articles on the implementing <a href="https://borretti.me/article/implementing-sm2-in-rust">SM-2</a> and <a href="https://borretti.me/article/implementing-fsrs-in-100-lines">FSRS</a>. Note that FSRS ties together the scheduler and the memory model at the implementation level, but they can be separated quite easily to unlock more flexibility in designing the system. There are also <a href="https://siddharth.io/files/deep-tutor.pdf">schedulers based on model-free reinforcement-learning</a>, that learn a scheduling policy directly from user interactions, without building an explicit, human-interpretable model of forgetting like the ones we’re discussing.</p>
<p>Once you have a memory model that estimates how likely the student is to remember each card, you can build different schedulers with various strategies:</p>
<ul>
<li>You can schedule a card for review when retrievability drops below 90%. This is the most common strategy in SRS as far as I can tell. This is more or less what FSRS does, you can also adjust the <em>desired retention</em> to other values.</li>
<li>You can randomly select cards for review, with probability proportional to how likely they have been forgotten (one minus retrievability). <a href="https://www.nature.com/articles/s41539-021-00105-8">Example</a>.</li>
<li>You can override the default scheduler behavior for new cards or after a failed review by implementing custom&nbsp;<em>learning</em> and&nbsp;<em>relearning steps</em>. This is also included in most FSRS implementations.</li>
<li>You can fuzz the intervals (adjust them randomly by small amounts) or apply load balancing to smooth out the amount of reviews scheduled for the student over a few days.</li>
<li>You can implement different strategies for when the student takes a break of weeks or months. For example, in Rember we mark cards overdue for a week as stale and the student can limit the amount of stale cards in each review session. This is an idea we took from <a href="https://www.remnote.com/">RemNote</a>.</li>
<li>You can build an exam feature, where the student sets the date for the exam and you schedule reviews in order to achieve high retrievability on that date for cards related to the exam. <a href="https://arxiv.org/abs/1805.08322">Example</a>.</li>
<li>You can account for goals complementary to retention, for example the student workload, the amount of new cards the student is adding, or the estimated answering time for each card. <a href="https://www.nature.com/articles/s41539-020-00074-4">Example</a>.</li>
<li>You can optimize for long-term outcomes, not just today’s retrievability. For example, if a student fails a card today, reviewing it again tomorrow might boost its future stability more than waiting a week. This forward-looking approach considers how today’s review outcome affects the card’s entire future learning trajectory. Some of the examples above account for similar ramifications. Nate Meyvis has explored <a href="https://www.natemeyvis.com/notes-on-spaced-repetition-scheduling.html">similar ideas</a>.</li>
</ul>
<p>As these examples illustrate, a single, accurate memory model can act as a foundation for a diverse ecosystem of schedulers, each optimized for different goals and user experiences.</p>
<p>The distinction between memory models and schedulers offers two key advantages:</p>
<ol>
<li><strong>Independent innovation cycles.</strong> We can innovate on schedulers independently of memory models, and vice versa. Scheduler research can treat memory models as a black box to obtain retrievability predictions.</li>
<li><strong>Separation from UX concerns.</strong> We can focus on building better memory models independently of product or UX considerations. The design of schedulers is deeply intertwined with product and UX considerations. For example, a scheduler might ensure a student re-attempts a failed card before the session ends. The primary benefit here might be psychological, providing the student with the assurance of getting it right, rather than a decision optimized purely for long-term retention. Another example is load balancing, the goal of which is primarily improving the student’s experience.</li>
</ol>
<p>This architectural separation isn’t just theoretical. It enables practical benefits: you can A/B test different scheduling strategies using the same underlying memory model, swap in improved memory models without rebuilding your entire system, and allow users to choose scheduling approaches that fit their learning style while maintaining consistent forgetting predictions underneath.</p>
<p>Most current SRS implementations conflate these concerns. The next generation of systems will likely benefit from treating them as distinct, composable components.</p>
<h2 id="content-aware-memory-models">Content-aware memory models</h2>
<p>This section explores how leveraging the textual content and semantic relationships between cards can improve memory models.</p>
<p>To the best of my knowledge, most memory models in real-world spaced repetition systems treat each card in isolation. SM-2, SM-18, and FSRS rely solely on each card’s individual review history to predict its forgetting curve. Ignoring the following factors means we are leaving useful information on the table:</p>
<ol>
<li><strong>The review histories of related cards</strong>. Card semantics allow us to identify related cards. This enables memory models to account for the review histories of&nbsp;<em>all</em> relevant cards when estimating a specific card’s retrievability.</li>
<li><strong>The card’s textual content</strong>. Beyond identifying related cards, the semantic content itself can directly inform the memory model. A model could, for example, estimate the inherent difficulty of a card based on its question or answer text, even before any reviews have taken place.</li>
</ol>
<p>It’s important to note that “card semantics” encompasses more than simple textual similarity. We’re looking to capture the card’s quality: how effectively the question can activate the memory pathways that lead the student to remember the concept. For example, we need to detect slight ambiguities in the question, which would make it difficult to answer. Moreover, we will likely need to examine the semantics of groups of cards, not just cards in isolation. For example, to memorize a list of three items, you might want a card for each item, plus an integrative card for the entire list. The card for the entire list in isolation would be quite poor in terms of card quality and would be very difficult to remember without the other three cards supporting it.</p>
<p>Informally, this direction proposes shifting the memory model’s focus from:</p>
<pre tabindex="0" data-language="plaintext"><code><span><span>retrievability(t) = f(t; single_card_history)</span></span></code></pre>
<p>To leveraging a richer context:</p>
<pre tabindex="0" data-language="plaintext"><code><span><span>retrievability(t) = f(t; all_cards_history, all_cards_content)</span></span></code></pre>
<p>Where <code>t</code> is the time since the last review, and each history (whether <code>single_card_history</code> or <code>all_cards_history</code>) is a chronological sequence of review events, typically comprising a timestamp and the student’s rating for that review.</p>
<p>Note that current memory models treat all new cards (cards with no reviews) as the same. Considering the textual content would allow us to obtain more informed initial estimates of a card’s inherent difficulty, leading to better scheduling for cards with no or few reviews compared to uniform defaults.</p>
<p>For example, consider the following collection of cards:</p>
<pre tabindex="0" data-language="plaintext"><code><span><span>Q: In reinforcement learning, broadly, what is the Bellman equation?</span></span>
<span><span>A: An equation that describes the fundamental relationship between the value of a state and the values of its successor states</span></span>
<span><span></span></span>
<span><span>Q: In reinforcement learning, what equation describes the fundamental relationship between the value of a state and the values of its successor states?</span></span>
<span><span>A: The Bellman equation</span></span>
<span><span></span></span>
<span><span>Q: In reinforcement learning, what's the formula of the Bellman equation?</span></span>
<span><span>A: $$ v_{\pi}(s) = \sum_{a} \pi(a|s) \sum_{s', r} p(s', r|s, a) [r + \gamma v_{\pi}(s')] $$</span></span></code></pre>
<p>All three cards are semantically related, but the first two, being conceptual inversions of each other, share a much stronger connection than with the third, which focuses on the formula.
Reviewing either of the first two cards would likely make recalling the other significantly easier. The third card might have a similar effect, but considerably weaker. (Alternatively, if a student successfully reviews either of the first two cards, we should increase our confidence that they’ll recall the other). The third card is also inherently more challenging due to its “less atomic” nature: a student must recall multiple components of the formula, increasing the likelihood of forgetting a single element and marking the card as forgotten.</p>
<h3 id="karl">KARL</h3>
<p>This idea has been explored in the literature by <a href="https://arxiv.org/abs/2402.12291">Shu et al., 2024 - KARL: Knowledge-Aware Retrieval and Representations aid Retention and Learning in Students</a>, where they introduce the term <strong>content-aware scheduling</strong>. The memory model in KARL encodes the textual content of the cards with BERT embeddings.</p>
<p>These embeddings play a dual role:</p>
<ol>
<li>They facilitate the&nbsp;retrieval of the top-k semantically similar cards&nbsp;from the user’s study history, whose review histories are then passed to the memory model</li>
<li>The&nbsp;embeddings of the current card and these top-k similar cards&nbsp;are themselves fed into the memory model</li>
</ol>
<p>The KARL scheduler was evaluated on a dataset consisting of 123,143 study logs on diverse trivia questions, collected from 543 users within a custom flashcard app. It slightly outperformed FSRSv4, which has improved since then, being now at version 6. This result is remarkable because KARL does not model the memory dynamics explicitly, like FSRS does by estimating difficulty and stability, and using a power-law forgetting curve. I wonder how the performance would be for a model that is good at both capturing the memory dynamics, like FSRSv6, and at accounting for card semantics, like KARL.</p>
<h3 id="small-experiments-on-rember-data">Small experiments on Rember data</h3>
<p>I ran a few small experiments myself that provide additional evidence that this direction is promising. In <a href="https://rember.com/">Rember</a> we group cards around small notes; at the time of the experiment, my account had 4,447 reviews for 940 cards, grouped in 317 notes. You can think of notes as grouping together semantically similar cards.</p>
<p>I ran a couple of experiments on top of FSRS:</p>
<ul>
<li><code>exp_1</code>: when the card has no reviews, set the initial stability to the average stability of other cards in the note.</li>
<li><code>exp_2</code>: multiply stability by a constant factor when other cards from the note have been reviewed between now and the card’s last review (the constant factor is optimized using grid search). This simulates a “priming” effect where recent exposure to related concepts reinforces the current card</li>
</ul>
<p>Stability represents how long the card will last in memory, it’s defined as the interval at which the card’s retrievability drops to 90%.</p>
<p>I compared the following memory models:</p>
<ul>
<li><code>random</code>: random retrievability predictions in <code>[0,1]</code></li>
<li><code>fsrs</code>: FSRSv5 with default parameters</li>
<li><code>fsrs_optimized</code>: FSRSv5 with parameters optimized on the collection</li>
<li><code>fsrs_exp_1</code>: <code>fsrs</code> + <code>exp_1</code></li>
<li><code>fsrs_exp_2</code>: <code>fsrs</code> + <code>exp_2</code></li>
<li><code>fsrs_optimized_exp_1</code>: <code>fsrs_optimized</code> + <code>exp_1</code></li>
<li><code>fsrs_optimized_exp_2</code>: <code>fsrs_optimized</code> + <code>exp_2</code></li>
</ul>
<p>I performed 4-fold cross-validation splitting by note IDs, and compared the models on the same evaluation metrics from my <a href="https://www.politesi.polimi.it/handle/10589/186407">master’s thesis</a>: <em>AUC</em> (measuring discrimination, the highest the better), <em>ICI</em> (measuring the average calibration error, the lower the better), <em>E_max</em> (measuring the maximum calibration error, the lower the better).</p>
<p>The results are summarized in the following table:</p>
<div>




















































<table><thead><tr><th>Model</th><th>AUC</th><th>ICI</th><th>E_max</th></tr></thead><tbody><tr><td><code>random</code></td><td>0.4887±0.0156</td><td>0.4235±0.0055</td><td>0.9193±0.0099</td></tr><tr><td><code>fsrs</code></td><td>0.5708±0.0172</td><td>0.0364±0.0120</td><td>0.2720±0.0912</td></tr><tr><td><code>fsrs_optimized</code></td><td>0.6294±0.0115</td><td>0.0108±0.0041</td><td>0.1904±0.0689</td></tr><tr><td><code>fsrs_exp_1</code></td><td>0.5883±0.0248</td><td>0.0281±0.0086</td><td>0.2204±0.0640</td></tr><tr><td><code>fsrs_exp_2</code></td><td>0.5716±0.0159</td><td>0.0307±0.0079</td><td>0.2355±0.0867</td></tr><tr><td><code>fsrs_optimized_exp_1</code></td><td>0.6148±0.0128</td><td><strong>0.0070±0.0021</strong></td><td>0.1383±0.0356</td></tr><tr><td><code>fsrs_optimized_exp_2</code></td><td><strong>0.6386±0.0185</strong></td><td>0.0075±0.0031</td><td><strong>0.1285±0.0522</strong></td></tr></tbody></table></div>
<p>The experimental results, though based on a small dataset, indicate a clear trend:</p>
<ul>
<li>Incorporating note-level information into FSRS, even with default parameters (<code>fsrs_exp_1</code> and <code>fsrs_exp_2</code>), generally outperforms <code>fsrs</code> across all metrics.</li>
<li>The optimal performance is achieved when FSRS is first optimized on the collection and then combined with note-level information.</li>
</ul>
<p>These results, while preliminary given the dataset size, support the hypothesis that integrating semantic context enhances memory models.</p>
<h3 id="other-considerations">Other considerations</h3>
<p><a href="https://www.mathacademy.com/">MathAcademy</a> includes an interesting spaced repetition feature, which accounts for the card semantics. They manually create a tree of concepts, with dependencies between them. The spaced repetition scheduler accounts for reviews of prerequisite concepts when scheduling a card. You can read more about how their scheduler works <a href="https://www.mathacademy.com/how-our-ai-works">here</a>. Here’s a quote:</p>
<blockquote>
<p>Existing spaced repetition algorithms are limited to the context of independent flashcards - but this is not appropriate for a hierarchical body of knowledge like mathematics. For instance, if a student practices adding two-digit numbers, then they are effectively practicing adding one-digit numbers as well! In general, repetitions on advanced topics should “trickle down” the knowledge graph to update the repetition schedules of simpler topics that are implicitly practiced.</p>
</blockquote>
<p>This is amazing work, but the scheduler is limited to MathAcademy’s tree of concepts; we need memory models that account for card semantics and apply more generally.</p>
<p>A general caveat might be the computational cost of the scheduler. For example, FSRS can schedule thousands of reviews in a few milliseconds on my M2 MacBook Pro, and therefore it can easily run on-device in a SRS. A memory model that accounts for the review history of all cards and the textual content of the cards will likely be more computationally intensive and might not be able to run on-device without excessive delays or battery drain. KARL addresses this computational challenge by considering only the top-k most semantically similar cards rather than all cards in the collection.</p>
<p>This kind of models will likely be trained on data from many spaced repetition students, which has a few implications:</p>
<ul>
<li>Even if a student has no reviews in the system, the model will still be able to estimate the initial difficulty for their cards.</li>
<li>We are making the implicit assumption that card semantics influence reviews in the same way across students, this might not always be true. For example, a card difficult for one person might be easy for another due to differing familiarity with the topic. However, if a card is hard to remember for most students, it is reasonable to assume it will be hard for others. Potential solutions include: focusing on how the question relates to the underlying topic, rather than the topic itself, or somehow modeling the student’s ability.</li>
</ul>
<h2 id="ux-unlocks">UX unlocks</h2>
<p>While accuracy improvements are valuable, the bigger impact comes from the UX opportunities unlocked by card semantics. By removing the rigid coupling between cards and their review histories, content-aware memory models give designers of spaced repetition systems much more freedom.</p>
<p>Here’s a concrete example of this constraint in action. When we started working on Rember (in the pre-LLM era), we considered building a fully markdown-based SRS. The main reason we dropped the idea is that you need an ID for each card, to link a card to its review history. Keeping IDs in the markdown quickly gets messy. You end up with something like:</p>
<pre tabindex="0" data-language="plaintext"><code><span><span>[card:abcxyz]</span></span>
<span><span>Q: What's the capital of Italy?</span></span>
<span><span>A: Rome</span></span></code></pre>
<p>Which is far from ideal, it’s fragile since the user might accidentally edit the ID, or end up with duplicate IDs by copy-pasting cards.</p>
<p>Solutions that get rid of the IDs were all dead-ends. You cannot rely on exact textual matches because the user might edit a card, and you don’t want to reset the review history if the user fixes a typo. You cannot rely on the relative position of the card in the document, as the user might move cards around. Forcing a GUI on top of the markdown that takes care of the IDs is viable, but kinda defeats the point of markdown.</p>
<p>The key insight is decoupling cards from their specific review histories. Instead of linking reviews to card IDs, the memory model considers only a universal history of content-based reviews, as triples: <code>(rating, timestamp, card's textual content)</code>. This eliminates the need for card consistency over time. There’s no “card’s review history” anymore, a single “review history” spans the entire student’s collection.</p>
<p>The scheduler can then assess the retrievability of all current cards in a student’s collection, including newly added ones, without relying on past review IDs. Students can edit cards freely without disrupting the scheduler. The memory model, using semantic understanding, differentiates between minor stylistic edits (like typos, which maintain the core meaning) and substantive changes to the card’s content (like replacing an answer, which would alter its semantic meaning sufficiently to be treated as a distinct card).</p>
<p>This decoupling also simplifies systems that dynamically generate prompts. Andy Matuschak explored bringing <em>ideas</em> rather than cards into the system. Prompts are dynamically generated during each review session to test the ideas from multiple angles, and evolve over time as you get more familiar with the ideas (see his Patreon post&nbsp;<a href="https://www.patreon.com/posts/fluid-practice-83882597">Fluid practice for fluid understanding</a>&nbsp;or his public&nbsp;<a href="https://notes.andymatuschak.org/z7wCFe7MP9VeCVApcBLC7SN">notes</a>). Content-aware memory models make this approach much more tractable.&nbsp;Current schedulers assume a review history per card. For dynamically generated prompts, this forces an awkward choice: either treat each unique prompt variation as a new card, losing its connection to the core idea, or group them coarsely at the idea level, which likely leads to under-reviewing the individual prompts.&nbsp;Content-aware memory models, however, naturally handle this gray area.</p>
<p>Taking this further, we could design a SRS where the flashcard-based review session is replaced with a conversation with a voice-enabled AI agent that asks questions or engages in open-ended discussion. This is part of the idea of <a href="https://davidbieber.com/snippets/2024-03-04-conversational-spaced-repetition/">conversational spaced repetition</a> explored by David Bieber. The AI agent could track the key ideas or concept the student goes over during the conversation, somehow judging whether the user could remember them or not. The content-aware memory model should be able account for those less structured reviews, even if they don’t directly map to Q&amp;A cards.</p>
<p>Additional benefits include:</p>
<ul>
<li>Having duplicates cards in the system is less disruptive to the review practice, since the scheduler will consider them as one and the same (even though you might still want to implement ways to detect and remove them from the system).</li>
<li>Reduced migration costs between SRS. Current importers must meticulously map both cards and review histories. With content-aware memory models, importing reviews could leverage the prior system’s textual card representation, enabling the new model to “understand” review histories from&nbsp;<em>any</em>&nbsp;system, regardless of perfect content mapping.</li>
</ul>
<p>While this approach reduces some direct user control over individual card histories, such as manually resetting a specific card’s schedule, I believe we can mitigate the problem and that the benefits of the approach far outweigh the costs.</p>
<p>In summary, I predict that content-aware memory models will make it much easier to design and build new interfaces for memory systems. They remove annoying hurdles that occupy the minds of SRS developers.</p>
<h2 id="data-problem">Data problem</h2>
<p>The main challenge in building content-aware memory models is lack of data. To my knowledge, no publicly available dataset exists that contains real-world usage data with both card textual content and review histories.</p>
<p><a href="https://arxiv.org/abs/2402.12291">KARL</a>, mentioned above, is trained on a dataset collected by paying users to review trivia flashcards on a custom app. I would hesitate to rely on a memory model trained solely on artificial data for my own spaced repetition practice. FSRS is trained on <a href="https://huggingface.co/datasets/open-spaced-repetition/anki-revlogs-10k">anki-revlogs-10k</a>, a large dataset consisting of more than 200M reviews from 10k Anki collections. The dataset includes only card, note, and deck IDs, omitting their textual content due to Anki’s <a href="https://ankiweb.net/account/privacy">Privacy Policy</a>, which states:</p>
<blockquote>
<p>In the interests of research and product development, we may use your review history and options (but not the text or media on cards) for statistical purposes, such as calculating the average pass rate across all users.</p>
</blockquote>
<p>While other review datasets exist, a crucial missing piece is a large dataset that:</p>
<ol>
<li>Is non-commercial and can be used for research purposes</li>
<li>Includes review histories</li>
<li>Includes cards’ textual content</li>
<li>Covers a wide range of topics (e.g. not just language learning data)</li>
</ol>
<p>Building on <a href="https://www.natemeyvis.com/notes-on-spaced-repetition-scheduling.html">Nate Meyvis’s insights</a>, I’ll add another requirement (I’ll discuss below why this is important):</p>
<ol start="5">
<li>A small fraction of the reviews are scheduled at random to provide unbiased data points</li>
</ol>
<p>Some of the challenges with data coming from spaced repetition systems:</p>
<ul>
<li><strong>The data is sparse.</strong> Limited to a time-stamped binary sequence of review ratings, spaced repetition data offers only a faint and insufficient signal to fully reconstruct the complex, dynamic state of a student’s memory.</li>
<li><strong>The data is incomplete.</strong> The limited data captured by spaced repetition systems fails to account for crucial out-of-system interactions that significantly shape a student’s memory. Students interact with material outside the SRS: through reading, conversation, or practical application. These interactions, important for memory, are not captured by the system. Furthermore, each review significantly alters the card’s future schedule. Consequently, unrecorded external recall events can have a substantial but uncaptured effect on the memory state assumed by the system.</li>
<li><strong>The data is biased.</strong> Spaced repetition data is inherently biased by the memory model that schedules reviews, creating a “chicken or the egg” problem where the data used to train the model is influenced by the model itself, potentially hindering further optimization (see <a href="https://ceur-ws.org/Vol-1432/sl_pap3.pdf">this paper</a>). This is why scheduling a small fraction of reviews at random in a real-world SRS could significantly improve the accuracy of memory models.</li>
<li><strong>The data is self-reported.</strong>&nbsp;We assume students provide ratings that truly reflect their inner memory state, but they may mark cards as “remembered” when they’ve actually forgotten them, perhaps to avoid the discomfort of perceived failure.</li>
</ul>
<p>The strong results achieved by current-generation schedulers like FSRS and SM-18 provide compelling evidence that a valuable signal indeed exists and can be separated from noise, despite the challenges described above.</p>
<p>One potential path forward is an open-source, community-contributed dataset where users voluntarily share their Anki and other SRS data, complete with tools to filter out sensitive content and eventually standardized benchmarks for evaluating memory models. If you’re interested in contributing data, have experience building community-driven datasets, or have thoughts on this approach, I’d love to <a href="https://www.giacomoran.com/cdn-cgi/l/email-protection#31565850525e5c5e43505f71565c50585d1f525e5c">hear from you</a>.</p>
<hr>
<p><em>We’re looking for testers for a new workflow for generating flashcards with AI, if you might be interested sign up for the waitlist at <a href="https://rember.com/">rember.com</a>. The best way to get updates on my work is <a href="https://x.com/giacomo_ran">x dot com</a>.</em></p> </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Passkeys are just passwords that require a password manager (149 pts)]]></title>
            <link>https://danfabulich.medium.com/passkeys-are-just-passwords-that-require-a-password-manager-ebb7f2fdcadf</link>
            <guid>44790385</guid>
            <pubDate>Mon, 04 Aug 2025 19:29:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://danfabulich.medium.com/passkeys-are-just-passwords-that-require-a-password-manager-ebb7f2fdcadf">https://danfabulich.medium.com/passkeys-are-just-passwords-that-require-a-password-manager-ebb7f2fdcadf</a>, See on <a href="https://news.ycombinator.com/item?id=44790385">Hacker News</a></p>
Couldn't get https://danfabulich.medium.com/passkeys-are-just-passwords-that-require-a-password-manager-ebb7f2fdcadf: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[NASA's Curiosity picks up new skills (150 pts)]]></title>
            <link>https://www.jpl.nasa.gov/news/marking-13-years-on-mars-nasas-curiosity-picks-up-new-skills/</link>
            <guid>44790271</guid>
            <pubDate>Mon, 04 Aug 2025 19:20:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jpl.nasa.gov/news/marking-13-years-on-mars-nasas-curiosity-picks-up-new-skills/">https://www.jpl.nasa.gov/news/marking-13-years-on-mars-nasas-curiosity-picks-up-new-skills/</a>, See on <a href="https://news.ycombinator.com/item?id=44790271">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p data-block-key="k29rj">Thirteen years since Curiosity landed on Mars, engineers are finding ways to make the NASA rover even more productive. The six-wheeled robot has been given more autonomy and the ability to multitask — improvements designed to make the most of Curiosity’s energy source, a multi-mission radioisotope thermoelectric generator (MMRTG). Increased efficiency means the rover has ample power as it continues to decipher how the ancient Martian climate changed, transforming a world of lakes and rivers into the chilly desert it is today.</p><p data-block-key="7hhum">Curiosity recently rolled into a region filled with <a href="https://www.nasa.gov/missions/mars-science-laboratory/curiosity-rover/nasas-curiosity-mars-rover-starts-unpacking-boxwork-formations/">boxwork formations</a>. These hardened ridges are believed to have been created by underground water billions of years ago. Stretching for miles on this part of <a href="https://science.nasa.gov/resource/curiositys-proposed-path-up-mount-sharp/">Mount Sharp</a>, a 3-mile-tall (5-kilometer-tall) mountain, the formations might reveal whether microbial life could have survived in the Martian subsurface eons ago, extending the period of habitability farther into when the planet was drying out.</p></div><div><p data-block-key="3uu6m">Instead, Curiosity and its younger sibling <a href="https://science.nasa.gov/mission/mars-2020-perseverance/">Perseverance</a> each use their <a href="https://www.jpl.nasa.gov/news/press_kits/mars_2020/launch/mission/spacecraft/power/">MMRTG</a> nuclear power source, which relies on decaying plutonium pellets to create energy and recharge the rover’s batteries. Providing ample power for the rovers’ many science instruments, MMRTGs are known for their longevity (the twin <a href="https://science.nasa.gov/mission/voyager/">Voyager</a> spacecraft have relied on <a href="https://science.nasa.gov/mission/voyager/spacecraft/#h-radioisotope-power-system-rps">RTGs</a> since 1977). But as the plutonium decays over time, it takes longer to recharge Curiosity’s batteries, leaving less energy for science each day.</p><p data-block-key="fq71o">The team carefully manages the rover’s daily power budget, factoring in every device that draws on the batteries. While these components were all tested extensively before launch, they are part of complex systems that reveal their quirks only after years in the extreme Martian environment. Dust, radiation, and sharp temperature swings bring out edge cases that engineers couldn’t have expected.</p><p data-block-key="1nfva">“We were more like cautious parents earlier in the mission,” said Reidar Larsen of NASA’s Jet Propulsion Laboratory in Southern California, which built and operates the rover. Larsen led a group of engineers who developed the new capabilities. “It’s as if our teenage rover is maturing, and we’re trusting it to take on more responsibility. As a kid, you might do one thing at a time, but as you become an adult, you learn to multitask.”</p><h3 data-block-key="e6csg"><b>More Efficient Science</b></h3><p data-block-key="2ho0n">Generally, JPL engineers send Curiosity a list of tasks to complete one by one before the rover ends its day with a nap to recharge. In 2021, the team began studying whether two or three rover tasks could be safely combined, reducing the amount of time Curiosity is active.</p><p data-block-key="cfof9">For example, Curiosity’s radio regularly sends data and images to a passing orbiter, which <a href="https://www.nasa.gov/centers-and-facilities/jpl/the-mars-relay-network-connects-us-to-nasas-martian-explorers/">relays them to Earth</a>. Could the rover talk to an orbiter while driving, moving its robotic arm, or snapping images? Consolidating tasks could shorten each day’s plan, requiring less time with heaters on and instruments in a ready-to-use state, reducing the energy used. Testing showed Curiosity safely could, and all of these have now been successfully demonstrated on Mars.</p></div><div><p data-block-key="436fb">Another trick involves letting Curiosity decide to nap if it finishes its tasks early. Engineers always pad their estimates for how long a day’s activity will take just in case hiccups arise. Now, if Curiosity completes those activities ahead of the time allotted, it will go to sleep early.</p><p data-block-key="b26s7">By letting the rover manage when it naps, there is less recharging to do before the next day’s plan. Even actions that trim just 10 or 20 minutes from a single activity add up over the long haul, maximizing the life of the MMRTG for more science and exploration down the road.</p><h3 data-block-key="f5j4r"><b>Miles to Go</b></h3><p data-block-key="ai5jd">In fact, the team has been implementing other new capabilities on Curiosity for years. Several mechanical issues required a rework of how the robotic arm’s <a href="https://www.jpl.nasa.gov/news/drilling-success-curiosity-is-collecting-mars-rocks/">rock-pulverizing drill</a> collects samples, and <a href="https://www.nasa.gov/missions/mars-science-laboratory/curiosity-rover/nasas-curiosity-mars-rover-gets-a-major-software-upgrade/">driving capabilities</a> have been enhanced with software updates. When a color filter wheel stopped turning on one of the two cameras mounted on Mastcam, Curiosity’s swiveling “head,” the team <a href="https://www.nasa.gov/missions/mars-science-laboratory/curiosity-rover/nasas-curiosity-rover-clocks-4000-days-on-mars/">developed a workaround</a> allowing them to capture the same beautiful panoramas.</p><p data-block-key="5sjdo">JPL also developed an <a href="https://www.jpl.nasa.gov/news/an-algorithm-helps-protect-mars-curiositys-wheels/">algorithm to reduce wear</a> on Curiosity’s rock-battered wheels. And while engineers closely monitor any new damage, they aren’t worried: After 22 miles (35 kilometers) and extensive research, it’s clear that, despite some punctures, the wheels have years’ worth of travel in them. (And in a worst-case scenario, Curiosity could remove the damaged part of the wheel’s “tread” and still drive on the remaining part.)</p><p data-block-key="fi860">Together, these measures are doing their job to keep Curiosity as busy as ever.</p><h3 data-block-key="5hk3l"><b>More About Curiosity</b></h3><p data-block-key="c18ov">Curiosity was built by NASA’s Jet Propulsion Laboratory, which is managed by Caltech in Pasadena, California. JPL leads the mission on behalf of NASA’s Science Mission Directorate in Washington as part of NASA’s Mars Exploration Program portfolio. Malin Space Science Systems in San Diego built and operates Mastcam.</p><p data-block-key="2s4lj">For more about Curiosity, visit:</p><p data-block-key="fmd7f"><a href="https://science.nasa.gov/mission/msl-curiosity"><b>science.nasa.gov/mission/msl-curiosity</b></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Europe is breaking its reliance on American science (101 pts)]]></title>
            <link>https://www.reuters.com/sustainability/climate-energy/europe-is-breaking-its-reliance-american-science-2025-08-01/</link>
            <guid>44789903</guid>
            <pubDate>Mon, 04 Aug 2025 18:48:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/sustainability/climate-energy/europe-is-breaking-its-reliance-american-science-2025-08-01/">https://www.reuters.com/sustainability/climate-energy/europe-is-breaking-its-reliance-american-science-2025-08-01/</a>, See on <a href="https://news.ycombinator.com/item?id=44789903">Hacker News</a></p>
Couldn't get https://www.reuters.com/sustainability/climate-energy/europe-is-breaking-its-reliance-american-science-2025-08-01/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Offline.kids – Screen-free activities for kids (131 pts)]]></title>
            <link>https://offline.kids/</link>
            <guid>44789192</guid>
            <pubDate>Mon, 04 Aug 2025 17:50:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://offline.kids/">https://offline.kids/</a>, See on <a href="https://news.ycombinator.com/item?id=44789192">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><ul><li>
<figure><a href="https://offline.kids/teaching-kids-to-lose-gracefully/" target="_self"><img loading="lazy" decoding="async" width="1536" height="1024" src="https://offline.kids/wp-content/uploads/2025/06/Teaching-Kids-to-Lose-Gracefully.png" alt="Teaching Kids to Lose Gracefully" srcset="https://offline.kids/wp-content/uploads/2025/06/Teaching-Kids-to-Lose-Gracefully.png 1536w, https://offline.kids/wp-content/uploads/2025/06/Teaching-Kids-to-Lose-Gracefully-300x200.png 300w" sizes="auto, (max-width: 1536px) 100vw, 1536px"></a></figure>

<p><time datetime="2025-06-05T08:26:49+00:00">June 5, 2025</time></p>

<h2><a href="https://offline.kids/teaching-kids-to-lose-gracefully/" target="_self">Teaching Kids to Lose Gracefully</a></h2>

<div><p>Losing a game can feel devastating for kids — but it’s also an important opportunity to help them build resilience and empathy. In this gentle guide, we share practical tips for parents and carers to support children in learning how to handle setbacks with confidence and grace.</p><p><a href="https://offline.kids/teaching-kids-to-lose-gracefully/">View post</a></p></div>
</li><li>
<figure><a href="https://offline.kids/solo-play-ideas-for-kids-when-you-need-a-moment/" target="_self"><img loading="lazy" decoding="async" width="1536" height="1024" src="https://offline.kids/wp-content/uploads/2025/06/Solo-Play-Activities.png" alt="Solo Play Ideas for Kids (When You Need a Moment)" srcset="https://offline.kids/wp-content/uploads/2025/06/Solo-Play-Activities.png 1536w, https://offline.kids/wp-content/uploads/2025/06/Solo-Play-Activities-300x200.png 300w" sizes="auto, (max-width: 1536px) 100vw, 1536px"></a></figure>

<p><time datetime="2025-05-29T11:40:34+00:00">May 29, 2025</time></p>

<h2><a href="https://offline.kids/solo-play-ideas-for-kids-when-you-need-a-moment/" target="_self">Solo Play Ideas for Kids (When You Need a Moment)</a></h2>

<div><p>Sometimes kids need something they can do on their own — while you’re on a work call, cooking dinner, or just taking a breath. Here’s a list of solo activities you can try with your child, grouped by age. Some are linked to full activity guides on Offline.Kids, and others are simple ideas you can…</p><p><a href="https://offline.kids/solo-play-ideas-for-kids-when-you-need-a-moment/">View post</a></p></div>
</li><li>
<figure><a href="https://offline.kids/wed-love-your-feedback-help-shape-offline-kids/" target="_self"><img loading="lazy" decoding="async" width="1536" height="1024" src="https://offline.kids/wp-content/uploads/2025/05/Feedback-Invitation-Illustration.png" alt="We’d Love Your Feedback – Help Shape Offline.Kids" srcset="https://offline.kids/wp-content/uploads/2025/05/Feedback-Invitation-Illustration.png 1536w, https://offline.kids/wp-content/uploads/2025/05/Feedback-Invitation-Illustration-300x200.png 300w, https://offline.kids/wp-content/uploads/2025/05/Feedback-Invitation-Illustration-1024x683.png 1024w, https://offline.kids/wp-content/uploads/2025/05/Feedback-Invitation-Illustration-768x512.png 768w" sizes="auto, (max-width: 1536px) 100vw, 1536px"></a></figure>

<p><time datetime="2025-05-22T13:36:59+00:00">May 22, 2025</time></p>

<h2><a href="https://offline.kids/wed-love-your-feedback-help-shape-offline-kids/" target="_self">We’d Love Your Feedback – Help Shape Offline.Kids</a></h2>

<div><p>Hi there 👋 Offline.Kids is a passion project — started by a tired parent (me!) looking for simple, low-effort ways to spend meaningful time with my daughter. If you’ve ever found yourself Googling “easy activities for kids” with one eye on the clock and the other on your coffee, you’re in the right place. Now…</p><p><a href="https://offline.kids/wed-love-your-feedback-help-shape-offline-kids/">View post</a></p></div>
</li><li>
<figure><a href="https://offline.kids/smartphone-free-childhood-create-powerful-new-video/" target="_self"><img loading="lazy" decoding="async" width="1280" height="720" src="https://offline.kids/wp-content/uploads/2025/05/SFC-video-thumb.jpg" alt="Smartphone Free Childhood create powerful new video" srcset="https://offline.kids/wp-content/uploads/2025/05/SFC-video-thumb.jpg 1280w, https://offline.kids/wp-content/uploads/2025/05/SFC-video-thumb-300x169.jpg 300w, https://offline.kids/wp-content/uploads/2025/05/SFC-video-thumb-1024x576.jpg 1024w, https://offline.kids/wp-content/uploads/2025/05/SFC-video-thumb-768x432.jpg 768w" sizes="auto, (max-width: 1280px) 100vw, 1280px"></a></figure>

<p><time datetime="2025-05-22T10:53:34+00:00">May 22, 2025</time></p>

<h2><a href="https://offline.kids/smartphone-free-childhood-create-powerful-new-video/" target="_self">Smartphone Free Childhood create powerful new video</a></h2>

<div><p>Discover how the Smartphone Free Childhood movement is empowering parents and carers to protect kids from smartphone harm — with community, courage, and hope.</p><p><a href="https://offline.kids/smartphone-free-childhood-create-powerful-new-video/">View post</a></p></div>
</li></ul>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: What trick of the trade took you too long to learn? (277 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=44789068</link>
            <guid>44789068</guid>
            <pubDate>Mon, 04 Aug 2025 17:39:59 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=44789068">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><tbody><tr id="44794030"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44794030" href="https://news.ycombinator.com/vote?id=44794030&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Excellence in anything is a byproduct of having fun. Fun is a byproduct of understanding. Understanding is a byproduct of going slow. Going slow is a byproduct of curiosity. Curiosity is a byproduct of saying "I don’t know," of shunning beliefs and attending to what is in front, with zero baggage or impositions of your own—shunning the ego in the moment, moment by moment. Excellence comes when each piece is as equal as any other, when preference is shunned, when space is created to allow what is in the moment, without resistance, without insistence.</p></div></td></tr></tbody></table></td></tr><tr id="44794160"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44794160" href="https://news.ycombinator.com/vote?id=44794160&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>This is relatable. Once one gets over the frustration of failing and making mistakes (thousands of times in some cases), it becomes fun and easier to stay curious.</p></div></td></tr></tbody></table></td></tr><tr id="44790699"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44790699" href="https://news.ycombinator.com/vote?id=44790699&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Start as early as possible in investing (in index funds) and otherwise being financially savvy. It is very beneficial to realise early on that growing your hard earned money and spending it wisely is way more important as it will in the future lead to some unexpected benefits. Freedom of thought and action!</p></div></td></tr></tbody></table></td></tr><tr id="44793713"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44793713" href="https://news.ycombinator.com/vote?id=44793713&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>My mistake was not starting early, because the numbers were small and it didn’t seem worth the time. The habit and systems are important to build, so that when the numbers do get bigger it goes to the right place.</p></div></td></tr></tbody></table></td></tr><tr id="44793768"><td></td></tr><tr id="44793855"><td></td></tr><tr id="44794155"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_44794155" href="https://news.ycombinator.com/vote?id=44794155&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>I also graduated in 2008.</p><p>Starting my adult life with the markets in freefall made it hard to get in the habit of investing.  All through school, people told me "most people don't start investing until their 30s, and end up in a worse than they ought to because the time-value of money compounds a bunch if you add a few more years."  I thought I knew better than to be one of those people.</p><p>Instead, I ended up keeping a lot of savings in cash during years when the interest rates were approximately 0.  I've tried to get better at putting money into the markets over the past few years, but my financials look very different than they might have.</p><p>&gt; In other words, 2008 had no meaningful impact on you then.</p><p>People who graduated in the late 00s might not have accrued big financial losses, but it had a very meaningful impact on my comfort investing.</p></div></td></tr></tbody></table></td></tr><tr id="44794254"><td><table><tbody><tr><td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td><center><a id="up_44794254" href="https://news.ycombinator.com/vote?id=44794254&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>I don't follow. The markets were low, great time to invest. Great time to buy a home. 2008 was bad for people who owned homes or were already investing.</p></div></td></tr></tbody></table></td></tr><tr id="44793501"><td></td></tr><tr id="44794177"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44794177" href="https://news.ycombinator.com/vote?id=44794177&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Excellent resource. The videos link to a YouTube channel with a treasure trove of content in multiple disciplines. Thanks for sharing!</p></div></td></tr></tbody></table></td></tr><tr id="44790860"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44790860" href="https://news.ycombinator.com/vote?id=44790860&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Call Vanguard: 877-662-7447</p><p>An investing prof at Chicago puts this on the whiteboard at the start of semester, saying this is really all most people need to know and this class is unlikely to learn anything in his or any class that will let them, personally, do better.</p></div></td></tr></tbody></table></td></tr><tr id="44791587"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44791587" href="https://news.ycombinator.com/vote?id=44791587&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>That’s good advice for a layman but most high earners can do much better if they care and are motivated. Most are neither though lol.</p><p>Mostly on the tax side. Some specific examples:</p><p>- after maxing out your 401k what should you do next? IRA? Mega backdoor roth? Something else?</p><p>- If you have kids, how to best save for future education expenses? Hint: consider 529 plan.</p><p>- HSA is technically the best tax advantaged account, most high earners don’t realize it and “waste” the HSA funds to reimburse typical medical bills. HSA has triple tax benefits: contributions are tax-free, growth is tax-free, and withdrawals are also tax-free after age 65 for any reason, not just medical expenses. So basically investing without any tax obligation. You can also withdraw tax free before 65, but for medical expenses only.</p><p>i could go on…investing is great, but reducing your tax obligation is an even more powerful technique if you want to grow your net worth.</p></div></td></tr></tbody></table></td></tr><tr id="44793631"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_44793631" href="https://news.ycombinator.com/vote?id=44793631&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Looked into HSA recently at work but legally you need a high deductible health care plan to be eligible. Looking at the options, just nothing looked good compared to my current $0 deductible/$0 co-pay plan. Hard to know for sure but just seemed like I would be paying a lot more out of pocket every year.</p></div></td></tr></tbody></table></td></tr><tr id="44793910"><td></td></tr><tr id="44793345"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_44793345" href="https://news.ycombinator.com/vote?id=44793345&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>The HSA thing intrigued me and so I did some digging. It appears that post-65, you still have to pay income tax on non-medical withdrawals from an HSA? That is, besides the tax-free-for-medical-expenses part it reverts to a traditional IRA?</p><p>One additional trick though is that it looks like you can pay for any HSA-eligible medical expenses (incurred after you created the HSA) out-of-pocket now, and reimburse your bills at any point in the future? Thus you can still earn interest on the cash before withdrawing it at any point in the future (treating it as tax-free liquidity).</p><p>(I don't fully understand this so these are questions not statements, but hopefully I'm correct!)</p></div></td></tr></tbody></table></td></tr><tr id="44793621"><td></td></tr><tr id="44793544"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_44793544" href="https://news.ycombinator.com/vote?id=44793544&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p><i>&gt; The HSA thing intrigued me and so I did some digging. It appears that post-65, you still have to pay income tax on non-medical withdrawals from an HSA?</i></p><p>That's what I understood too. That claim that you can completely skip taxes looks wrong.</p></div></td></tr></tbody></table></td></tr><tr id="44793565"><td><table><tbody><tr><td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td><center><a id="up_44793565" href="https://news.ycombinator.com/vote?id=44793565&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>You can completely escape taxes for any amounts that you have receipts for medical expenses incurred after the HSA was opened.</p><p>You can pay cash for a qualified medical expense in 2025 and take out that
amount of money from the HSA decades later.</p></div></td></tr></tbody></table></td></tr><tr id="44793591"><td></td></tr><tr id="44793725"><td><table><tbody><tr><td indent="6"><img src="https://news.ycombinator.com/s.gif" height="1" width="240"></td><td><center><a id="up_44793725" href="https://news.ycombinator.com/vote?id=44793725&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>One thing to note!!!! Make sure to also keep records on the HSA start date and any transfers you may engage in, e.g., after leaving an employer or just changing providers. It is worth having that on record in case 20, 30, 40 years later your claims are rejected because the original opening date was lost in some transfer at some point.</p></div></td></tr></tbody></table></td></tr><tr id="44793595"><td><table><tbody><tr><td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td><center><a id="up_44793595" href="https://news.ycombinator.com/vote?id=44793595&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>i’m the parent. You are correct, my mistake! It’s too late to edit at this point.  :(</p><p>What I should have said is that after 65 you can spend it on non medical stuff without penalty. BUT if you do so you’ll owe tax that year (withdrawal).</p><p>So to summarize, you can avoid all tax if it’s spent on medical stuff. For non medical (post 65) it’s still good, but not as good.</p><p>Still an amazing deal because old people tend to spend a lot more on healthcare.</p></div></td></tr></tbody></table></td></tr><tr id="44793516"><td></td></tr><tr id="44791842"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_44791842" href="https://news.ycombinator.com/vote?id=44791842&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>What you have stated is almost the same as call Vanguard, all those options are the same in the sense that they all involve investing, leaving it alone for a long time. Its just the vehicle thats slightly different and tax advantages.</p><p>I wouldn’t consider those options needing much motivation or research. The key with all of them is investing early and leaving it alone.</p></div></td></tr></tbody></table></td></tr><tr id="44792069"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_44792069" href="https://news.ycombinator.com/vote?id=44792069&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>If one is clueless with investing and taxes in general, and they call vanguard, their eyes will glaze over. It would be like me explaining software development to my 85 year old father.</p><p>I do agree people should call vanguard. But just blindly following steps they give you is unlikely to be productive if you don’t understand why you’re doing those steps. Furthermore, those people who don’t understand _why_ will freak out every time there’s a huge market correction. They get scared - because they don’t understand any of it.</p><p>I’m also curious, do they offer financial advice for your accounts outside vanguard? Genuinely curious since i’m unsure.</p></div></td></tr></tbody></table></td></tr><tr id="44792388"><td><table><tbody><tr><td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td><center><a id="up_44792388" href="https://news.ycombinator.com/vote?id=44792388&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>I’ve think the “call” part is a bit from the past, should be a setup account online with Vanguard, put it in VOO or VTSAX or the equivalent low fee market index fund and leave it alone.</p><p>Replace Vanguard with any other firm but the key is picking low fee ETFs and leaving them alone. Vanguard tends to have a reputation for the lowest fees.</p></div></td></tr></tbody></table></td></tr><tr id="44793037"><td></td></tr><tr id="44791702"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_44791702" href="https://news.ycombinator.com/vote?id=44791702&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>At that point get someone to do it for you for x% of what they're getting you back and live blissfully unaware of arcane tax code specifics.</p></div></td></tr></tbody></table></td></tr><tr id="44791769"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_44791769" href="https://news.ycombinator.com/vote?id=44791769&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>At least the 401k, IRA, and HSA don't require knowing anything particularly arcane. Money goes in, don't touch until 59 1/2 (401k, IRA) or 65 (HSA).</p><p>529 plans can get a bit more complicated because you'll  want one from your state (if your state has an income tax) and they may offer several, but then it's less about knowing tax code specifics than about what the differences are between their offerings.</p></div></td></tr></tbody></table></td></tr><tr id="44792135"><td><table><tbody><tr><td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td><center><a id="up_44792135" href="https://news.ycombinator.com/vote?id=44792135&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>right, it’s not that arcane at all. I discovered all this over a couple weekends in my 20s. Started on reddit, then moved on to more official guides and books. I spent maybe 5 weekends in total doing this learning.</p><p>It’s really not that hard and i don’t understand why more people aren’t interested. Let’s reframe for a minute…if i said a high earner could retire a year earlier, or maybe even a few years earlier just by learning some semi-advanced tax strategies. Should they do so? Yeah. They’d be crazy not to lol.</p></div></td></tr></tbody></table></td></tr><tr id="44793575"><td></td></tr><tr id="44792477"><td></td></tr><tr id="44793648"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_44793648" href="https://news.ycombinator.com/vote?id=44793648&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>i tried that hack one year. Cigna just emptied my account on the first try with a provider charging 2 emergency room visits when I was there only for a xray.</p><p>Cigna refused to lift a finger unless i sued them both.</p><p>yeah, i wouldn't recommend that.</p></div></td></tr></tbody></table></td></tr><tr id="44793967"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44793967" href="https://news.ycombinator.com/vote?id=44793967&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>An important part that could have been beneficial would have been to add, "today".</p><p>I had a class where the teacher did something similar, but she showed that if you started a ROTH today and contributed only the 4 years you were in college and then stopped forever. You would have nearly the same amount of money as someone who started 1 year after they completed college and invested every year until retirement.</p><p>Ultimately she was encouraging us to take out student loans and invest it or use any excess scholarship money to max out a ROTH IRA. She even advocated for investing all student loan money and opening credit cards tp actually pay for college, making minimum payments until graduation. Then moving away to a LCOL country and learn the language for 8-9 years while remaining in school taking 1 online class a year and travelling the world on student loans and not to worry about starting a career until 30 and start paying once you are back and start a job.</p></div></td></tr></tbody></table></td></tr><tr id="44794132"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_44794132" href="https://news.ycombinator.com/vote?id=44794132&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>ROTH IRA contributions have to be from earned income, though. The rest of the advice is of the same quality, imho. Beware!</p></div></td></tr></tbody></table></td></tr><tr id="44793511"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44793511" href="https://news.ycombinator.com/vote?id=44793511&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>This is generally not applicable to most people.</p><p>1. Invest enough to get the company match in an S&amp;P 500.  It probably isn’t Vanguard that your company uses</p><p>2. Pay off all of your debt except your house (and maybe your car)</p><p>3. Max out your HSA - if you are married it’s - $8550</p><p>4.  Max out your 401K - again that’s probably not through Vanguard - $23500</p><p>5. Step 5 - then call Vanguard and depending on your income just do a Roth up to $8000 (?).</p><p>(Unless you are over 50 then do catch  up contributions as 4.5)</p><p>If you are under 50, you can do $40,500 tax advantaged and over 50 $48050</p></div></td></tr></tbody></table></td></tr><tr id="44793884"><td></td></tr><tr id="44794124"><td></td></tr><tr id="44793965"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_44793965" href="https://news.ycombinator.com/vote?id=44793965&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Step 6 is the mega-backdoor Roth. Do after tax contributions to your 401k and have your 401k servicer do an in-plan conversion to Roth 401k.</p><p>Also, on step 4, you may need to do a backdoor Roth IRA if you’re over the Roth IRA income limits.</p></div></td></tr></tbody></table></td></tr><tr id="44794057"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_44794057" href="https://news.ycombinator.com/vote?id=44794057&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>I’ve only had one employer that allowed after tax contributions (which for other people reading this is not the same as Roth 401K).</p><p>The issue is that most companies don’t allow it because of compliance reasons and rules regarding highly compensated employees.  Of course the one company that did allow it was BigTech.</p><p>Not that I’m missing much.  I doubt I will be in a higher tax bracket at retirement than I am now and I live in a state tax free state.</p></div></td></tr></tbody></table></td></tr><tr id="44794109"><td><table><tbody><tr><td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td><center><a id="up_44794109" href="https://news.ycombinator.com/vote?id=44794109&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>To me the primary benefit is when it comes to RMDs. Having a mix of traditional and Roth allows me to draw down the traditional in lower tax years to avoid RMD and have the Roth to fill in those later years or pass on to children. Plus, if you’ve maxed the $23,500ish of the traditional 401k and still have extra to save, it’s more tax advantaged in a Roth vs a taxable brokerage account.</p><p>These are obviously champagne problems but if you’re a high earning W2 it’s worth considering.</p></div></td></tr></tbody></table></td></tr><tr id="44794228"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_44794228" href="https://news.ycombinator.com/vote?id=44794228&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>For those of us very late to the investing game, what is the best strategy to try to catch up at least somewhat?</p></div></td></tr></tbody></table></td></tr><tr id="44792340"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44792340" href="https://news.ycombinator.com/vote?id=44792340&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>My millionaire, step-father-in-law, gave this advice to my brother when graduated.</p><p>I was lucky, my physics department administrator told me the same thing when I was graduating.</p><p>The 2ND best piece of advice is to rollover your 401k when you move to a new company -&gt; this cost me at least 500k because they effectively stagnate when your company isn't paying the maintenance cost (AIUI).</p></div></td></tr></tbody></table></td></tr><tr id="44792607"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_44792607" href="https://news.ycombinator.com/vote?id=44792607&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>&gt; this cost me at least 500k because they effectively stagnate when your company isn't paying the maintenance cost</p><p>Is this true? My understanding is that the fees come out of the account itself. There's other good reasons to roll over (primarily investment flexibility) but I have not heard of something like this.</p></div></td></tr></tbody></table></td></tr><tr id="44793312"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_44793312" href="https://news.ycombinator.com/vote?id=44793312&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>I don't think the point about 401k stagnation is true. At most fee structures and optionality of funds change. How did that cost you 500k exactly?</p></div></td></tr></tbody></table></td></tr><tr id="44793307"><td></td></tr><tr id="44793420"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_44793420" href="https://news.ycombinator.com/vote?id=44793420&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Vanguard is one of the cooler-structured brokerages. Vanguard (the management firm) is owned by the mutual funds themselves, of which you are an investor of. So their shareholder obligation is genuinely towards "clients" of the individual mutual funds. As far as I'm aware, this is the only mutually-owned mutual fund firm.</p><p>It's definitely got a solid track record and good fees, but these are things I'd feel weird about advertising it on HN for.</p></div></td></tr></tbody></table></td></tr><tr id="44793333"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_44793333" href="https://news.ycombinator.com/vote?id=44793333&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>vanguards very large and they're a mutual fund, so they have a lower profit motive than most brokers for it. they're basically the standard retirement fund company now</p></div></td></tr></tbody></table></td></tr><tr id="44791219"><td></td></tr><tr id="44790852"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44790852" href="https://news.ycombinator.com/vote?id=44790852&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Most problems (including analytically intractible ones) can be modeled with a relatively simple monte-carlo simulation. Most simple monte-carlo simulations can be fully implemented in a spreadsheet.</p><p>Using timing coincidences in particle physics experiments is incredibly powerful. If multiple products from the same reaction can be measured at once, it's usually worth looking into.</p><p>Circular saws using wood cutting blades with carbide teeth can cut aluminum plates.</p><p>You can handle and attach atomically thin metal foils to things by floating them on water.</p><p>Use library search tools and academic databases. They are entirely superior to web search and AI.</p></div></td></tr></tbody></table></td></tr><tr id="44790911"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44790911" href="https://news.ycombinator.com/vote?id=44790911&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>I feel like the Monte-Carlo simulation modeling trick is one I picked up intuitively but only recently heard formalized. Do you (or anyone else) have a list of example problems that are solved in this way? Like a compendium of case studies on how to apply this trick to real world problems?</p></div></td></tr></tbody></table></td></tr><tr id="44791753"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44791753" href="https://news.ycombinator.com/vote?id=44791753&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>_How to Measure Anything_ by Douglas Hubbard includes a chapter on Monte Carlo simulations and comes with downloadable Excel examples: <a href="https://www.howtomeasureanything.com/3rd-edition/" rel="nofollow">https://www.howtomeasureanything.com/3rd-edition/</a> (scroll down to Ch. 6)</p><p>The main example is, you're considering leasing new equipment that might save you money. What's the risk that it will actually cost more, considering various ranges of potential numbers (and distributions)?</p><p>I think it's harder to apply to software since there are more unknowns (or the unknowns are fatter-tailed) but I still liked the book just for the philosophical framing at the beginning: you want to the measure things because they help you make decisions; you don't need perfect measurements since reducing the range of uncertainty is often enough to make the decision.</p></div></td></tr></tbody></table></td></tr><tr id="44791827"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44791827" href="https://news.ycombinator.com/vote?id=44791827&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>A simple example that highlights the strength of this method: a 137Cs point source is at the origin. A detector consisting of a right cylinder at arbitrary distance and orientation is nearby. What is the solid angle?</p><p>There may exist an analytical solution for this, but I wouldn't trust myself to derive it correctly. It would certainly be a huge mess.</p><p>If we add that the source is also a right cylinder instead of point source, and we want to add first order attenuation of emitted gammas by the source itself, the spreadsheet becomes only a bit more complex, but there will not be a pen and paper equation solution.</p><p>In this example every row of the spreadsheet would represent a hypothetical ray. One could randomly choose a location in the source, a random trajectory, and check if the photon intersects the detector. An alternative approach would be randomly choosing points in both target and detector, then doing additional math.</p><p>The results are recovered by making histograms and computing stats on the outputs of all the rows. You probably need a few thousand for most things at least. Remember roughly speaking 10k hits gets you ~1% statistics.</p></div></td></tr></tbody></table></td></tr><tr id="44793863"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_44793863" href="https://news.ycombinator.com/vote?id=44793863&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>What annoys me with Monte Carlo methods is trying to get self-consistent statistics at multiple parameter values. E.g., in your example, what is the derivative of the solid angle as the detector is moved? Or more generally, if we have some 'net goodness' measure for a system depending on parameters, how can we efficiently maximize it, when simulations are noisy and basins are shallow?</p><p>My understanding is that these sorts of questions come up in ML, and there are ways of dealing with it, but they can't converge nearly as fast as simple iterations like Newton's method. Even if I have to take a series approximation instead of a simple formula, I'll be able to use autodiff (or at worst, symbolic differentiation) to get quick and precise answers to these questions.</p></div></td></tr></tbody></table></td></tr><tr id="44793432"><td></td></tr><tr id="44791231"><td></td></tr><tr id="44793142"><td></td></tr><tr id="44793567"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44793567" href="https://news.ycombinator.com/vote?id=44793567&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>I've used various commercial databases over the years. Some popular commercial databases relevant to HN readers include Web of Science, Scopus, and Engineering Village. When I worked at the USPTO, I used the less popular database Dialog, which I preferred. To my knowledge, none of these are available direct to consumers. I've only been able to get access from places with subscriptions. Some university libraries allow visitors where you can use these databases for free on-site.</p><p>I would call these databases complementary, not "entirely superior". There are two main advantages. One is that these databases will contain many things that you can't find on Google. The second advantage of these databases is that they are designed for advanced searchers and have more powerful query languages. Google on the other hand is dumbed down and will try to guess what you want, often doing a poor job. You can get very specific on these databases in ways that you can't with Google.</p><p>Related: I'm somewhat fascinated by more specialized bibliographic databases because they often contain things that can't be found on Google or the major commercial databases I listed above. I started keeping a list of them. <a href="https://github.com/btrettel/specialized-bibs" rel="nofollow">https://github.com/btrettel/specialized-bibs</a></p></div></td></tr></tbody></table></td></tr><tr id="44794329"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_44794329" href="https://news.ycombinator.com/vote?id=44794329&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>On a related note, if you studied and got a degree at a university, check if they have an alumni program. I pay a small yearly fee that lets me access the university's academic databases and their VPN, so I get some other perks as it looks like I'm connected through eduroam.</p></div></td></tr></tbody></table></td></tr><tr id="44793656"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44793656" href="https://news.ycombinator.com/vote?id=44793656&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>even wood tipped circular saw can cut Al plate...</p><p>and academic/library search is indeed so underrated!</p></div></td></tr></tbody></table></td></tr><tr id="44793964"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44793964" href="https://news.ycombinator.com/vote?id=44793964&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Most people really cannot tell you what they want in any reasonable way. So expecting good specs for software without a very laborious interview and review process is pure wishful thinking. People "know what they like when they see it", so spend time rapid prototyping.</p><p>Smaller and more recent: iTerm has deep tmux support. Just do `tmux -CC` to start your session or `tmux -CC a` to attach to it and you don't have to memorise all the tmux commands.</p></div></td></tr></tbody></table></td></tr><tr id="44793892"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44793892" href="https://news.ycombinator.com/vote?id=44793892&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Understanding the concept of Opportunity Cost and how it applies to everything in life.</p><p>- Buying a house: Is this the best return I can get on a downpayment. (Spoiler: It is not).</p><p>- Accepting a specific job offer: Is this the best way to spend 8 hours a day?</p><p>- Not making a successful trade, is as much as a loss than losing money explicitely on a trade.</p><p>- If you own something, you should consider what could you do with it's cash value if you sold it instead.</p><p>- If you have a paid off home, could you sell it and get a better ROI with the cash equivalent and rent instead? (The answer is yes and you should do it).</p></div></td></tr></tbody></table></td></tr><tr id="44794201"><td></td></tr><tr id="44794235"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44794235" href="https://news.ycombinator.com/vote?id=44794235&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>As usual, I'd like to bring up that it is until you have enough profit for it to no longer be only about that.</p><p>Also regardless of the quality of the examples, it may be the case that the point (opportunity cost is important to consider) is still valid.</p></div></td></tr></tbody></table></td></tr><tr id="44794251"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_44794251" href="https://news.ycombinator.com/vote?id=44794251&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Thanks for clarifying. Being mindful of opportunity cost allows people to retire early, to spend more time with their loved ones, do better financial decisions.</p><p>I have seen too many of my loved ones work until their 70s because they didn't think about those concepts enough. That is what is sad.</p></div></td></tr></tbody></table></td></tr><tr id="44794236"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44794236" href="https://news.ycombinator.com/vote?id=44794236&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>So It's really sad to think about the value of time or things? Don't you implicitly do that every time you chose an activity over another? When you chose a job over another? when you chose to spend your time with a friend or with your wife?</p></div></td></tr></tbody></table></td></tr><tr id="44791033"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44791033" href="https://news.ycombinator.com/vote?id=44791033&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>The big one, for keeping my focus on the power of repeated, consistent action, and prioritizing my "future selves":</p><p><i>What is likely to happen if I do (or don't do) this thing one thousand days (or times) in a row?</i></p><p>Examples:</p><p>- exercising 2h per day and eating right --&gt; I'm going to look and feel great and my health will be far better than that of my peers</p><p>- Should I buy these cookies along with the rest of my groceries? If I do that 1,000 grocery trips in a row …</p><p>- spending 30+ minutes per day reading the highest quality material I can find; taking notes; and figuring out ways to implement the knowledge and ideas I gain --&gt; …</p></div></td></tr></tbody></table></td></tr><tr id="44793663"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44793663" href="https://news.ycombinator.com/vote?id=44793663&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>This is a good one. What's gonna happen if I respond to comments on HN for 1000 days in a row? Uh oh.</p></div></td></tr></tbody></table></td></tr><tr id="44791987"><td></td></tr><tr id="44791609"><td></td></tr><tr id="44793610"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44793610" href="https://news.ycombinator.com/vote?id=44793610&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Whenever people try to argue that small and meaningful commits do not matter, I introduce them to git bisect. I’ve yet to meet someone familiar with it that does not agree.</p></div></td></tr></tbody></table></td></tr><tr id="44793447"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44793447" href="https://news.ycombinator.com/vote?id=44793447&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Similar feelings about git worktree. Being able to check out multiple branches at once without having to deal with stash is a game changer.</p></div></td></tr></tbody></table></td></tr><tr id="44793335"><td></td></tr><tr id="44793086"><td></td></tr><tr id="44794262"><td></td></tr><tr id="44793347"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44793347" href="https://news.ycombinator.com/vote?id=44793347&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Agreed with interactive rebase, but what of reflog? I've checked that for commit hashes when things have gone very wrong but I don't know many commands.</p></div></td></tr></tbody></table></td></tr><tr id="44793792"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_44793792" href="https://news.ycombinator.com/vote?id=44793792&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>It allows you to observe and interact with the history of refs like HEAD, so superficially destructive operations like amending a commit can be recovered, reverted, etc. It's kind of like meta-git, allowing version control operations on the version control system. It's a lifesaver when you botch a merge or something and allows you to do "destructive" operations fearlessly (up to a point, you can munge a git repo pretty bad if you try hard enough).</p></div></td></tr></tbody></table></td></tr><tr id="44794139"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44794139" href="https://news.ycombinator.com/vote?id=44794139&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>duplicate code is not that bad. reduce duplication over time as you find the common patterns/abstractions, instead of trying to build abstractions that don't fit the use cases</p></div></td></tr></tbody></table></td></tr><tr id="44794214"><td></td></tr><tr id="44789137"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44789137" href="https://news.ycombinator.com/vote?id=44789137&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>I only learned this in the last five years: do less, automate less, do more by hand, and use the limited capability of the manual method to really choose projects that are worthwile, rather than aim for maximum efficiency.</p></div></td></tr></tbody></table></td></tr><tr id="44790847"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44790847" href="https://news.ycombinator.com/vote?id=44790847&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Similar to this: if you want to optimize your productivity*, do so on a timescale of at least weeks if not months or years.</p><p>Simple example: Can you get more done working 12 hours a day than 8? Sure, for the first day. Second day maybe. But after weeks, you're worse off in one way or another.</p><p>It's easy to chase imaginary gains like automating repetitive tasks that don't actually materialize, but some basics like sleep, nutrition, happiness, etc are 100% going to affect you going forward.</p><p>* I actually hate that word, and prefer saying "effectiveness". Productivity implies the only objective is more, more, more, endlessly. Effectiveness opens up the possibility that you achieve better results with less.</p></div></td></tr></tbody></table></td></tr><tr id="44794014"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44794014" href="https://news.ycombinator.com/vote?id=44794014&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Realizing that buying a house is absolutely not a good investment and that the whole society is on a narrative to convince more and more people to blindly buy (realtors, lenders, other homeowners, the governments, parents,...)</p><p>Doing the real math is the trick of the trade. The math for owning has been made so that it looks like a good deal while in reality it is not at all. Most people will literally compare mortgage to their rent, or "I sold my house I bought for 500k for 1M$, therefore I made 500k$".</p><p>Treat owning as a luxury item. The same way you would own a sport car or travel on a private jet. Do the (real) math and realize Owning is costing you money.</p><p>Also don't let yourself get emotional about buying a house. Society has made it look as if buying a house was a proof of success. A lot of research shows that once people buy they lose flexibility, feel more stuck, cannot access higher paying job in a different places etc. Renting has a ton of advantages.</p><p>This calculator get most things right. As an exercise, you can try to retroactively put the numbers for the house you bought and the rent equivalent. The results might surprise you:
www.nytimes.com/interactive/2024/upshot/buy-rent-calculator.html</p></div></td></tr></tbody></table></td></tr><tr id="44794118"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44794118" href="https://news.ycombinator.com/vote?id=44794118&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>As I grew older (and hopefully wiser), I have internalized investment returns is a lot more than sanitized numbers. I did the numbers and as a result did not buy much real estate when I was yonger. It was pretty clear, if I put the same cash outflow into stocks, I would come out ahead... Way ahead!</p><p>The things is, I didn't put the same cash outflow in stocks. For various reasons. But mainly, it was just not psychologically palatable to max out my investments on equity by streching my finances. With hindsight, given the buffer in most real estate investments (left with tangible assets, banks shouldering some of the risk etc.) it would have been a lot more psychologically palatable to investment my max in real estate.</p><p>My point is not that real estate is "best". But merely, there is a lot more to returns than cold numbers. If you think you already understand it, and are under 30, you are likely underestimating the significance of that. I know I did.</p></div></td></tr></tbody></table></td></tr><tr id="44794161"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44794161" href="https://news.ycombinator.com/vote?id=44794161&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>This is the argument that buying a house serves as a subpar, forced investment for most people.</p><p>But I don't know if I agree with you, I understood in my twenties that housing was generally a bad investment. We are now 10 years later and I invested everything in the stock market instead and came way ... way ahead than if I bough one or more houses.</p><p>I personally find it way way more scary to buy an average 2M$ house that could crash and lose half of its value overnight than the whole American economy that is relatively diversified.
What happens if there is a fire in your neighborhood? Or if your city is the next Detroit? 
We have been made to believe a house is a safe investment. I personally think it's the scariest least diversified investment you could ever make.</p></div></td></tr></tbody></table></td></tr><tr id="44794250"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44794250" href="https://news.ycombinator.com/vote?id=44794250&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>You know I hear this all the time but it never quite makes sense to me. REA is inherently a better asset class than the vast majority of assets, simply because you can leverage up without a risk of being stopped out.</p><p>Doing the numbers on (most) developed economies, buying freehold housing is typically a worse investment than stocks before leverage, but after, RE almost always comes ahead. Nobody is going to let you mortgage a basket of stocks, but almost any bank will let you do that with a house.</p><p>That said - I hate this idea because I think this kind of thinking is what has lead to many of societies problems in the developed world at the moment. But, from a rational point of view the numbers make sense.</p></div></td></tr></tbody></table></td></tr><tr id="44794268"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_44794268" href="https://news.ycombinator.com/vote?id=44794268&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>It's worse than that. Buying a house without leverage is a terrible investment.</p><p>The leverage is absolutely required because all the fees that come with real estate (Realtors, Interest, HOA, Taxes, Insurances, Closing costs, Downpayment opportunity cost,...). The leverage makes it an OK investment, but still historically not on the level of a diversified basket of stocks.</p><p>The leverage also works in both ways and essentially makes your house an even more risky asset. It supposes that it only ever goes up which has not always been the case historically.</p></div></td></tr></tbody></table></td></tr><tr id="44794094"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44794094" href="https://news.ycombinator.com/vote?id=44794094&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>*&gt; Most people will literally compare mortgage to their rent, or "I sold my house I bought for 500k for 1M$, therefore I made 500k$".</p><p>I’ll bite: what’s the problem? If anything mortgage is even more favorable than rent because part of it goes to paying off the principal. Which is still your money, just in a different asset. But I guess you include this and still reach the opposite result?</p><p>Are you talking about taxes or maintenance or something ? Which country / locality? What time span? How many places are there where you would’ve been better off renting than buying in recent memory… not where I’ve lived but you never know!</p></div></td></tr></tbody></table></td></tr><tr id="44794131"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44794131" href="https://news.ycombinator.com/vote?id=44794131&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Because the mortgage and the rent are completely different numbers.</p><p>The rent is the maximum you will ever pay for that period.
The mortgage is the minimum you will pay and doesn't include the downpayment, repairs, HOA, Insurance and tax increases. It also doesn't include the closing costs, realtor costs, all the fees.</p><p>This is why the math is so complex. People easily forget all those fees and costs to make the math look simple.</p><p>This also takes into account that you invest into the US market and equity with all the cash that you would have had to spend on your house.</p><p>I'm talking about the US, but this holds true in multiple countries.</p><p>To answer your last question: In almost all HCOL (SF, Seattle, ...) you would have been way better renting than buying, except if you time it perfectly.
If you look at today's market you would almost definitely be better renting than buying (But nobody knows the future...)</p></div></td></tr></tbody></table></td></tr><tr id="44794299"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_44794299" href="https://news.ycombinator.com/vote?id=44794299&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>This is just plain wrong. Let's break it down:</p><p>* Insurance and tax increases: real and you have to deal with them, but they don't go up as fast as rent does. Advantage: owning</p><p>* HOA fees: don't buy an HOA home, problem solved. You should do that anyway just because HOAs suck ass.</p><p>* Down payment: not a real cost, that money is yours in the form of equity</p><p>* Closing costs and other fees: real but completely negligible when amortized over the life of the home.</p><p>* Repairs: real, and they suck. This is the only place renting can stack up superior, but you can do a lot to mitigate this by doing your due diligence up front and not buying a dud house. Overall, unless you get unlucky you should come out ahead, but you can lose the die roll.</p><p>* Realtor costs: greatly depends. When we bought our house we paid zero, because the seller pays the buyer's costs. This can be a serious cost if you're changing houses a lot, but... just don't do that (for multiple reasons).</p><p>Overall, after buying my house 7 years ago I'm coming out ahead month over month (thanks to rent going up like clockwork every year, while my mortgage has stayed the same). By the time I die, I will be <i>significantly</i> ahead, and that's not even taking into account unrealized gains in the value of the property. Which I don't count for much, because my home is a place to live and not an investment vehicle. But maybe someday it'll do me good, or my heirs.</p><p>Owning a home <i>really is</i> a great deal for the <i>vast</i> majority of people in the US. It's not some society wide conspiracy, it's not an ad to get others into the market so you can benefit, it's the truth.</p></div></td></tr></tbody></table></td></tr><tr id="44794073"><td></td></tr><tr id="44794087"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44794087" href="https://news.ycombinator.com/vote?id=44794087&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>You are exactly right and I will add this to my post.</p><p>This calculator get most things right. As an exercise, you can try to retroactively put the numbers for the house you bought and the rent equivalent. The results might surprise you:
www.nytimes.com/interactive/2024/upshot/buy-rent-calculator.html</p></div></td></tr></tbody></table></td></tr><tr id="44794121"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44794121" href="https://news.ycombinator.com/vote?id=44794121&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>This is of course true if your house is not income producing. If you rent out rooms of your house, the calculus changes considerably.</p><p>…and now having viewed their calculator, I find it disingenuous that they haven’t added this as an additional configurable step, given how many bells and whistles their tool has. The takeaway from the tool is that you should never buy in HCOL areas, but renting out rooms in your unit is potentially a way to make it work out financially.</p></div></td></tr></tbody></table></td></tr><tr id="44794190"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44794190" href="https://news.ycombinator.com/vote?id=44794190&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>I don't know if I agree. On average renting a room out of your place is the same as buying a place as a rental investment with the difference you can claim you live there (which gives you some small tax advantage).</p><p>In general, real estate rental investment are terrible subpar investment. How would this be different?</p></div></td></tr></tbody></table></td></tr><tr id="44792099"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44792099" href="https://news.ycombinator.com/vote?id=44792099&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>&gt; What Trick of the Trade took you too long to learn?</p><p>"Everything worth doing is worth doing badly"</p><p>And as a corollary, every complex system that works came from a simple system that works.</p><p>I learned this in programming, but now I apply it on everything from motorcycle maintenance, home appliance repair to parenting.</p><p>--</p><p>Often the easier way to fix a complex system is to pretend that it could be simpler and then reintroduce the complexity-inducing requirements.</p><p>I had a professor who taught debugging as a whole another skill from programming and used to say "Most of programming is starting from an empty editor and debugging until your code works".</p><p>The debugging "lab" in Java course (in the year 2000) was one of my transformational after-school classes - where I got a java program which fits within 2-3 pages of print code with a bug and was told to go find it in print for ~20 minutes, then given 40 minutes with a debugger instead.</p></div></td></tr></tbody></table></td></tr><tr id="44792563"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44792563" href="https://news.ycombinator.com/vote?id=44792563&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>&gt; And as a corollary, every complex system that works came from a simple system that works.</p><p>"Do the simplest thing that works" is one of the few core architecture principles I stick my neck out for time and time again. Why write a simple function when you can spend a week accounting for every imagined corner case and implement modular expansion capabilities! Please... stop...</p><p>I empathize with the debugger story. If you're super deep in a language it makes sense to know the debugger inside and out. But stdout is universal and I've never been a specific language developer rather than being able to jump into whatever is needed.</p></div></td></tr></tbody></table></td></tr><tr id="44793050"><td></td></tr><tr id="44790171"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44790171" href="https://news.ycombinator.com/vote?id=44790171&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Writing tests first is a good way to end up with testable code. If you skip that, retrofitting tests is incredibly difficult.</p></div></td></tr></tbody></table></td></tr><tr id="44790762"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44790762" href="https://news.ycombinator.com/vote?id=44790762&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>While it can be a useful forcing function, I find it also just fits into a higher velocity workflow in general, one I would describe like so:</p><p>1. Make PRs small, but not as small as you can possibly make them.</p><p>2. Intend to write at least one nice-ish test suite that tests like 50-80% of the LOC in the PR. Don't try to unit test the entire thing, that's not a unit test. And if something is intrinsically hard to test - requires extensive mocking etc - let it go instead of writing a really brittle test.</p><p>3. Tests only do two things: help you make the code correct right now, or help the company keep the code right long term. If your test doesn't do either, don't write it.</p><p>4. Ok - now code. And just keep in mind you're the poor sod who's gonna have to test it, so try to factor most of the interesting stuff to not require extensive mocking or shit tons of state.</p><p>I've found this workflow works almost anywhere and on almost any project or code. It doesn't require any dogmatic beliefs in PR sizes or test coverages. And it helps prevent the evils that dogmatic beliefs often lead you into. It just asks you to keep your eyes open and don't paint yourself into a corner, short term or long term.</p></div></td></tr></tbody></table></td></tr><tr id="44790930"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44790930" href="https://news.ycombinator.com/vote?id=44790930&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>One more piece - if the test would be hard to write, use that to drive you to clean up the architecture of that piece of code.</p></div></td></tr></tbody></table></td></tr><tr id="44790728"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44790728" href="https://news.ycombinator.com/vote?id=44790728&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Even if you aren't going to do the complete test code just writing down the expected checks for each test makes things so much easier</p></div></td></tr></tbody></table></td></tr><tr id="44790915"><td></td></tr><tr id="44793555"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44793555" href="https://news.ycombinator.com/vote?id=44793555&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>When I stopped trying to be right and I started trying to be friends my career finally took off.</p></div></td></tr></tbody></table></td></tr><tr id="44793643"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44793643" href="https://news.ycombinator.com/vote?id=44793643&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>When you buy a house and get a mortgage, you are going to be paying MUCH more in interest (than expected). Over the course of the mortgage, you are going to be paying MUCH more than the sticker price. Between closing costs and taxes and fees maintenance, you will need more cash than you think.</p><p>My advice is look at the numbers very carefully and choose something that is (below) or fits your budget. Sudden financial issues like the loss of a job or new vehicle purchase can put a big strain on all this.</p></div></td></tr></tbody></table></td></tr><tr id="44793748"><td></td></tr><tr id="44793875"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44793875" href="https://news.ycombinator.com/vote?id=44793875&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>it's called renting.</p><p>Americans are obsessed with owning a home at all cost. This means that you are effectively bidding against people that do not even do the math. They are ready to spend Millions of dollar on something that is comparatively cheap to rent.</p><p>The fact that absolutely everyone wants to buy pushed prices through the roof. The good news is that you can take the other side of this bet. it's called renting.</p><p>Currently in most places in the US you will save literally millions over the 30 year mortgage by renting and investing in the market instead.</p><p>Reminder that renting and owning is functionally almost exactly the same thing.</p><p>Never trust your realtor and never trust other homeowner that most of the time never did the math (We all know those people: "I bought my home for 500k 15 years ago. It is now worth 1M$, therefore I made 500k$").</p><p>In other words, let other people take the irrational side of this bet and take the rational side by renting. It's an arbitrage opportunity.</p></div></td></tr></tbody></table></td></tr><tr id="44793997"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_44793997" href="https://news.ycombinator.com/vote?id=44793997&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>An important fact that this doesn't account for is that, in the United States, living in housing that you own is highly tax-advantaged, at least if you can get a mortgage on it. For example, mortgage interest is tax-deductible for owner-occupied housing (whereas landlords usually can't deduct interest on their mortgages and so those taxes are passed on to renters), and mortgage rates for owner-occupied housing are far below market due to government subsidies and guarantees (whereas landlords have to pay higher rates that, again, they pass on to renters). This isn't good policy, but as long as it's the case, buying a single-family home is a smarter financial choice for most Americans than renting one.</p></div></td></tr></tbody></table></td></tr><tr id="44794047"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_44794047" href="https://news.ycombinator.com/vote?id=44794047&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>I live in the US and I'm aware of this. Those tax deductible interest should be calculated in the complex buy vs rent equation.</p><p>In fact, even when taking them into account, it still doesn't make sense for most Americans to own. (In today's market).</p><p>Renting and investing is still the way to go for at least 75% of Americans (this is slightly more nuanced for low cost of living areas, but hold true for any MCOL or HCOL areas).</p><p>Eventually the math could make sense again, but right now owning is a huge luxury that will cost you millions in the long run.</p><p>I invite you to play with this calculator:
www.nytimes.com/interactive/2024/upshot/buy-rent-calculator.html</p></div></td></tr></tbody></table></td></tr><tr id="44794178"><td><table><tbody><tr><td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td><center><a id="up_44794178" href="https://news.ycombinator.com/vote?id=44794178&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>I am a renter so I don't have a horse in this race, but renting is many times the financially worse choice even in HCOL.</p><p>Why? Because rent inflates like crazy over here! In the Bay Area 7%+ a year is completely expected, and 10% is not unusual. I have been all over the Bay Area for more than a decade (San Francisco proper, East Bay, South Bay) and know this well. It's been nuts.</p><p>Random example: the 1 bedroom apartment that I lived in 2012 and was then going for $1,500 a month, is now going for $3,800 in the exact same building (with no/minimal renovations it seems, I just looked it up). An ~8% YoY increase. That will do it to any buy vs rent calculator, very easy to break even in under 5 years, and that's excluding the speculative ability to refinance if interest rates go down from the current 7%, in which case it becomes a huge boost.</p><p>Renting as a long term choice just works in European countries where normal people can lock in 5+ year leases with no or minimal rent increases. America is too profit-seeking and greedy for that.</p><p>I still rent for flexibility reasons, but I definitely see it as a luxury lifestyle choice, the most financially responsible thing would be to buy, even in HCOL.</p><p>All this in my opinion and personal experience, totally fine if people see it differently.</p></div></td></tr></tbody></table></td></tr><tr id="44794199"><td><table><tbody><tr><td indent="6"><img src="https://news.ycombinator.com/s.gif" height="1" width="240"></td><td><center><a id="up_44794199" href="https://news.ycombinator.com/vote?id=44794199&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>SF is the poster child of a HCOL where buying makes absolutely no sense.</p><p>Even if rent increases a lot, the buy to rent ratio is so horrible that it could continue to increase for MANY more years before buying could make sense.</p><p>I invite you to use the NYT Rent or buy calculator, It is clear as day: 
www.nytimes.com/interactive/2024/upshot/buy-rent-calculator.html</p></div></td></tr></tbody></table></td></tr><tr id="44794226"><td><table><tbody><tr><td indent="7"><img src="https://news.ycombinator.com/s.gif" height="1" width="280"></td><td><center><a id="up_44794226" href="https://news.ycombinator.com/vote?id=44794226&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>I just did, picturing exactly the situation I'm in right now:</p><p>- Rent: $3,500</p><p>- Home price: $700,000 (a similar unit just sold for this price a few months ago in my building)</p><p>- Rent increase: 8%</p><p>- All other parameters left as default, which seem reasonable (and as I said, there might be chances of refinancing over the next 10 years, which would drastically skew the picture, but I'm leaving that assumption out)</p><p>The ratio of 0.5% monthly rent/price is common for non-luxury "dated" condos all over the city, so I think my situation reflects well the typical renter.</p><p>Once again, in my personal experience, guided by a decade+ of living here, what people miss is the crazy rate of rent inflation. There is always a massive rent increase right around the corner, and God forbid if you are forced to move (because the landlord wants you to, it happened a couple times), then you take a gigantic hit at market rate. Once you factor in these occasional resets and the standard yearly increase, you get very close to 10% rent increase.</p></div></td></tr></tbody></table></td></tr><tr id="44794167"><td><table><tbody><tr><td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td><center><a id="up_44794167" href="https://news.ycombinator.com/vote?id=44794167&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>It's not all numbers, though.  Both have a lot of intangibles that can and should affect your decision.</p><p>Owning can feel suffocating at times, and like a ball and chain at others. You can't just decide you don't like it or the area anymore and go.  Maintenance is also no joke.</p><p>Renting feels ephemeral.  Getting kicked out at lease end sucks, it's hard to uproot everything and start over.  Having inane rules and a landlord constantly drive by can make you feel both infantile and spied on.</p><p>I've done both off and on and those are my own thoughts on the two.</p><p>Financially only it's easy to pick a winner.  But for some, one of these factors may be worth the extra however much money the difference is.</p></div></td></tr></tbody></table></td></tr><tr id="44794210"><td><table><tbody><tr><td indent="6"><img src="https://news.ycombinator.com/s.gif" height="1" width="240"></td><td><center><a id="up_44794210" href="https://news.ycombinator.com/vote?id=44794210&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>The best way to calculate those intangible is to associate a value to them, Most people love to say that owning is so good because they can decide on their own house improvement.</p><p>Ok, but how much do you really value this over? Is it worth 2M$ over 30 years? Because in a lot of cases this is what you leave on the table by deciding to own.</p></div></td></tr></tbody></table></td></tr><tr id="44794205"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_44794205" href="https://news.ycombinator.com/vote?id=44794205&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>But mortgage interest is an itemized deduction, which means it only becomes a tax benefit when your interest + other deductions exceed the standard deduction. And if you do take the deduction, only the delta between it the standard deduction is a benefit.</p></div></td></tr></tbody></table></td></tr><tr id="44793718"><td></td></tr><tr id="44794023"><td></td></tr><tr id="44793708"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44793708" href="https://news.ycombinator.com/vote?id=44793708&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>You can memorize the correct opening moves in chess. For maybe my first year playing chess, I just YOLO'd the opening moves. My judgement there was probably not much worse than the rest of my play, but with other players playing engine moves in the opening, I was probably in a losing position early on in most of my games. I gained about, I think, 100 ELO after learning some 3 or 4 move opening combinations.</p></div></td></tr></tbody></table></td></tr><tr id="44794039"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44794039" href="https://news.ycombinator.com/vote?id=44794039&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Claude Code recently showcased how powerful it can be when you don’t have to memorize commands. My AI agent works similarly. It finds the right CLI commands instead of relying on Playwright or an MCP server to perform tasks. What’s interesting is that even the agent doesn’t know many commands upfront; it simply uses the help option to discover what’s available.</p></div></td></tr></tbody></table></td></tr><tr id="44793618"><td></td></tr><tr id="44793962"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44793962" href="https://news.ycombinator.com/vote?id=44793962&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Similarly, it's `XXX=123`, and cannot be `XXX = 123` or `$XXX=123`.</p><p>Shellcheck (and Wooledge) are crucial!</p></div></td></tr></tbody></table></td></tr><tr id="44793933"><td></td></tr><tr id="44793993"><td></td></tr><tr id="44789428"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44789428" href="https://news.ycombinator.com/vote?id=44789428&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>How do you maintain tests, in order for LLM edits to not keep breaking things?</p><pre><code>  - As a formal test suite in the program's own language?
  - Or using a .md natural language "tests" collection that must pass, which an LLM can understand?

</code></pre><p>
To answer the OP, I learned use different models for reasoning vs. coding.</p></div></td></tr></tbody></table></td></tr><tr id="44793743"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44793743" href="https://news.ycombinator.com/vote?id=44793743&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Always fix errors in reverse order, from the bottom of the file to the top. That way the line numbers don't change as you go.</p></div></td></tr></tbody></table></td></tr><tr id="44793047"><td></td></tr><tr id="44790844"><td></td></tr><tr id="44793093"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44793093" href="https://news.ycombinator.com/vote?id=44793093&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>But don’t fall into the trap of that’s all you do. This can lead to procrastination of the thing you’re trying to do.</p></div></td></tr></tbody></table></td></tr><tr id="44790879"><td></td></tr><tr id="44793448"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44793448" href="https://news.ycombinator.com/vote?id=44793448&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Easy transfers between different people's iThings with Airdrop. I got my CompSci degree over 30 years ago and yet my 74yo aunt taught me this - the shame!</p></div></td></tr></tbody></table></td></tr><tr id="44793506"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44793506" href="https://news.ycombinator.com/vote?id=44793506&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>One other benefit, if it happens to matter to you, is that Airdropped files like photos or videos retain their original quality as opposed to taking a slight hit to quality when being transferred via text or email.</p></div></td></tr></tbody></table></td></tr><tr id="44793534"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44793534" href="https://news.ycombinator.com/vote?id=44793534&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Also good to know is that if you crop a picture in your iOS photos app and then airdrop it to someone, they can undo the crop in their photos app. It is a non-obviously non-destructive operation.</p></div></td></tr></tbody></table></td></tr><tr id="44790848"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44790848" href="https://news.ycombinator.com/vote?id=44790848&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>That macros ruin everything they touch. I used them extensively for maybe 15 years, stopped adding them, and then a bit later removed them all from my code. My C/C++ code was a lot nicer without them.</p></div></td></tr></tbody></table></td></tr><tr id="44791011"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44791011" href="https://news.ycombinator.com/vote?id=44791011&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>My early C code would have been awfully slow without them.  We needed enums and good inlining before we could ditch (most) macros.  When did Zorland/Zortech C become good enough?</p><p>There are still a few special cases where macros are useful, such as the multiple #include trick where a macro #defined before the #include determines what the macro invocations in the include file does -- really helpful for building certain kinds of tables.</p></div></td></tr></tbody></table></td></tr><tr id="44791313"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44791313" href="https://news.ycombinator.com/vote?id=44791313&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Zortech had an inliner even before it was Zortech.</p><p>The #include trick is called the "X Macro". I used it extensively, and eventually just removed it.</p></div></td></tr></tbody></table></td></tr><tr id="44791757"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_44791757" href="https://news.ycombinator.com/vote?id=44791757&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Was it reliable enough?</p><p>(I have never played with it -- I saw the ads in Byte but I never met anybody who had tried it.  It seemed so ridiculously cheap that I felt it had to be a scam ;) )</p></div></td></tr></tbody></table></td></tr><tr id="44792862"><td></td></tr><tr id="44794172"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44794172" href="https://news.ycombinator.com/vote?id=44794172&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Learn how to stab your colleagues in the back and play petty mean spirited office politics games. That's most of what being employed in this industry actually is, and if you accept that now and optimize yourself around it you can save decades wasted trying to actually get good at doing tangible (albeit economically useless) things.</p></div></td></tr></tbody></table></td></tr><tr id="44793384"><td></td></tr><tr id="44793825"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44793825" href="https://news.ycombinator.com/vote?id=44793825&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>If you're selling something physical, always have free shipping. Include the price of shipping in the price of the product.</p><p>I guess people now expect free shipping via Amazon and boy does this make things sell faster.</p></div></td></tr></tbody></table></td></tr><tr id="44793158"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44793158" href="https://news.ycombinator.com/vote?id=44793158&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>read something new every day before going to bed</p><p>journal before you start your day</p><p>buy some sort of electric kettle</p></div></td></tr></tbody></table></td></tr><tr id="44793112"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44793112" href="https://news.ycombinator.com/vote?id=44793112&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Environment variables can be expanded at the command line, just like files.  Believe I started before it was a thing and never thought to check until twenty years later(?), when I hit the tab key by mistake. :-D</p></div></td></tr></tbody></table></td></tr><tr id="44794037"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44794037" href="https://news.ycombinator.com/vote?id=44794037&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>You should never look at code and say "this should work". If it "should" work it would work. If it doesn't work, you definitely made a mistake. Poke every assumption one by one. Preferably with an interactive debugger.</p><p>This may seem obvious but when I was younger I used to spin out in frustration at bugs.</p></div></td></tr></tbody></table></td></tr><tr id="44790820"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44790820" href="https://news.ycombinator.com/vote?id=44790820&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>When I realized that a) `screen` exists and b) what it does, I felt like an utter fool for having gone for years—<i>YEARS</i>—without benefiting from it.</p></div></td></tr></tbody></table></td></tr><tr id="44793398"><td></td></tr><tr id="44793550"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44793550" href="https://news.ycombinator.com/vote?id=44793550&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>It is a terminal multiplexer. You will be able to find youtube videos. The gp is talking about a tool called gnu screen. If you need a more distinct token to search on try “tmux”.</p></div></td></tr></tbody></table></td></tr><tr id="44793883"><td></td></tr><tr id="44793551"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_44793551" href="https://news.ycombinator.com/vote?id=44793551&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Pretty sure they mean GNU screen, a terminal multiplexer. Similar in functionality to tmux or zellj (a newer alternative) if you have heard of those.</p></div></td></tr></tbody></table></td></tr><tr id="44793355"><td></td></tr><tr id="44793336"><td></td></tr><tr id="44791973"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44791973" href="https://news.ycombinator.com/vote?id=44791973&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Measure everything. There are two benefits to this.</p><p>1. Discarding the bullshit. A consistent practice of weighting assumptions and conclusions on evidence/numbers helps identify biases and motives from other people.</p><p>2. Measures allow for value identification and performance. Most people just guess at this. Guessing is wrong more than 80% of the time and often wrong by multiple orders of magnitude.</p><p>Most people don’t think like this and find this line of thinking completely foreign, so I often just keep my conclusions to myself. To see a movie about this watch Money Ball.</p></div></td></tr></tbody></table></td></tr><tr id="44792060"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_44792060" href="https://news.ycombinator.com/vote?id=44792060&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>This is interesting. I’ve often thought about building a dashboard for my personal life, comparable to the dashboards I build for growth teams.</p><p>And then iterating on it over time, and I find what’s valuable and what’s not.</p></div></td></tr></tbody></table></td></tr><tr id="44793439"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_44793439" href="https://news.ycombinator.com/vote?id=44793439&amp;how=up&amp;goto=item%3Fid%3D44789068"></a></center></td><td><br>
<div><p>Learning that it is more important to know how to communicate, how to promote myself and the art of persuasion to get ahead than any technical skills I could know.</p></div></td></tr></tbody></table></td></tr><tr id="44793105"><td></td></tr><tr id="44790861"><td></td></tr><tr id="44793481"><td></td></tr><tr id="44793857"><td></td></tr></tbody></div></div>]]></description>
        </item>
    </channel>
</rss>