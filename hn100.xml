<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 25 Apr 2024 19:00:07 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[FCC Votes to Restore Net Neutrality Rules (210 pts)]]></title>
            <link>https://www.nytimes.com/2024/04/25/technology/fcc-net-neutrality-open-internet.html</link>
            <guid>40160429</guid>
            <pubDate>Thu, 25 Apr 2024 17:23:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/04/25/technology/fcc-net-neutrality-open-internet.html">https://www.nytimes.com/2024/04/25/technology/fcc-net-neutrality-open-internet.html</a>, See on <a href="https://news.ycombinator.com/item?id=40160429">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/04/25/technology/fcc-net-neutrality-open-internet.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[We have 4 days to contest KYC being required by internet services (342 pts)]]></title>
            <link>https://www.federalregister.gov/documents/2024/01/29/2024-01580/taking-additional-steps-to-address-the-national-emergency-with-respect-to-significant-malicious</link>
            <guid>40158752</guid>
            <pubDate>Thu, 25 Apr 2024 15:31:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.federalregister.gov/documents/2024/01/29/2024-01580/taking-additional-steps-to-address-the-national-emergency-with-respect-to-significant-malicious">https://www.federalregister.gov/documents/2024/01/29/2024-01580/taking-additional-steps-to-address-the-national-emergency-with-respect-to-significant-malicious</a>, See on <a href="https://news.ycombinator.com/item?id=40158752">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
        <h3>Request Access</h3>
        

        <p>
  Due to aggressive automated scraping of FederalRegister.gov and eCFR.gov, programmatic access to these sites is limited to access to our extensive developer APIs.
</p>

<p>
  If you are human user receiving this message, we can add your IP address to a set of IPs that can access FederalRegister.gov &amp; eCFR.gov; complete the CAPTCHA (bot test) below and click "Request Access". This process will be necessary for each IP address you wish to access the site from, requests are valid for approximately one quarter (three months) after which the process may need to be repeated.
</p>

<form action="/request" method="post">
  

          

  
</form>

<p>
  <em>An official website of the United States government.</em>
</p>

<p>
  If you want to request a wider IP range, first request access for your current IP, and then use the "Site Feedback" button found in the lower left-hand side to make the request.
</p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Launch HN: Nango (YC W23) – Source-available unified API (108 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=40158481</link>
            <guid>40158481</guid>
            <pubDate>Thu, 25 Apr 2024 15:09:02 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=40158481">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="40158481">
      <td><span></span></td>      <td><center><a id="up_40158481" href="https://news.ycombinator.com/vote?id=40158481&amp;how=up&amp;goto=item%3Fid%3D40158481"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=40158481">Launch HN: Nango (YC W23) – Source-available unified API</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_40158481">107 points</span> by <a href="https://news.ycombinator.com/user?id=rguldener">rguldener</a> <span title="2024-04-25T15:09:02"><a href="https://news.ycombinator.com/item?id=40158481">3 hours ago</a></span> <span id="unv_40158481"></span> | <a href="https://news.ycombinator.com/hide?id=40158481&amp;goto=item%3Fid%3D40158481">hide</a> | <a href="https://hn.algolia.com/?query=Launch%20HN%3A%20Nango%20(YC%20W23)%20%E2%80%93%20Source-available%20unified%20API&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=40158481&amp;auth=3e790d79d449d3b4c831cdedc309e0340089c37e">favorite</a> | <a href="https://news.ycombinator.com/item?id=40158481">59&nbsp;comments</a>        </span>
              </td></tr>
    <tr></tr><tr><td colspan="2"></td><td><div><p>Hey everyone, we are Bastien and Robin from Nango (<a href="https://www.nango.dev/">https://www.nango.dev</a>). We take care of the annoyances of external APIs (167 and counting) so you can quickly build custom integrations for your SaaS, while retaining full control over how they work.
2 min demo video: <a href="https://www.loom.com/share/d04c67b47e284e86b91b4b99fba548ec" rel="nofollow">https://www.loom.com/share/d04c67b47e284e86b91b4b99fba548ec</a></p><p>SaaS engineering teams face a tough choice: they can build each integration in-house from scratch, which gives them full control but takes a lot of time and maintenance effort. Or they can use pre-built solutions, which are fast and easy but less flexible and might not fulfill all customer needs.</p><p>Nango combines the best of both worlds. We let you quickly ship custom integrations without building complex infrastructure or diving deep into the quirks of each API. You control the business logic, data models, and customer-specific configurations, like custom field mappings. We handle (O)Auth and run your integrations reliably in production.</p><p>Under the hood, your integrations run as typescript “lambdas” on Nango. A typical integration has 3-5 lambdas of 20-50 lines of code each. These lambdas live inside your git repo, are version-controlled with the rest of your app, and get deployed to Nango with a CLI (<a href="https://docs.nango.dev/understand/core-concepts">https://docs.nango.dev/understand/core-concepts</a>).</p><p>Our runtime has a built-in scheduler for continuous background syncs, monitoring to know if your integrations run as expected, detailed logging of everything that happens in Nango, and pre-built infrastructure to deal with (O)auth, retries, rate-limit handling, webhook floods, data caching, de-duplication, etc. More here: <a href="https://docs.nango.dev/understand/architecture">https://docs.nango.dev/understand/architecture</a></p><p>We have found that ChatGPT and Copilot let you build integrations on Nango very fast without having to learn each API’s intricacies. LLMs are great at figuring out which endpoint to use, what parameters it takes, etc. Paired with our runtime, this lets you build complex, high-scale integrations in hours instead of weeks.</p><p>We’ve put a ton of effort into dealing with API complexities, so you don’t have to. Even integrations that looked simple at first ended up forcing us to extend our infra to deal with their quirks and gotchas.</p><p>For example, we had to figure out 100+ different OAuth implementations (see <a href="https://www.nango.dev/blog/why-is-oauth-still-hard">https://www.nango.dev/blog/why-is-oauth-still-hard</a> and <a href="https://news.ycombinator.com/item?id=35713518">https://news.ycombinator.com/item?id=35713518</a>). We had to deal with a half-dozen non-standard auth methods (Github apps, Stripe apps, Netsuite, etc.), expiring webhooks, ways to deal with data dependencies, weird pagination methods, API keys that change with every API call, dozens of different ways to register for webhooks, etc. It’s a constantly moving target, but it is a challenge we have come to love, and we think the approach makes sense: we specialize in finicky details that vary from API to API—you specialize in making your product great and offering more integrations to your users.</p><p>Last but not least, Nango is open source (<a href="https://github.com/NangoHQ/nango">https://github.com/NangoHQ/nango</a>) under the ELv2 license (allows most use cases, except for direct copy-cats). Anybody can contribute new APIs &amp; share their integration templates with the community.</p><p>The fastest way to see Nango in action is with our interactive demo here (no signup required): <a href="https://app.nango.dev/hn-demo">https://app.nango.dev/hn-demo</a></p><p>Or take a look at our docs: <a href="https://docs.nango.dev/">https://docs.nango.dev</a></p><p>We would love to hear your feedback and look forward to the comments!</p></div></td></tr>        <tr></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ex-athletic director arrested for framing principal with AI-generated voice (169 pts)]]></title>
            <link>https://www.thebaltimorebanner.com/education/k-12-schools/eric-eiswert-ai-audio-baltimore-county-YBJNJAS6OZEE5OQVF5LFOFYN6M/</link>
            <guid>40158183</guid>
            <pubDate>Thu, 25 Apr 2024 14:43:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thebaltimorebanner.com/education/k-12-schools/eric-eiswert-ai-audio-baltimore-county-YBJNJAS6OZEE5OQVF5LFOFYN6M/">https://www.thebaltimorebanner.com/education/k-12-schools/eric-eiswert-ai-audio-baltimore-county-YBJNJAS6OZEE5OQVF5LFOFYN6M/</a>, See on <a href="https://news.ycombinator.com/item?id=40158183">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Baltimore County Police arrested<b> </b>Pikesville High School’s former athletic director Thursday morning and charged him with using artificial intelligence to impersonate Principal Eric Eiswert, leading the public to believe Eiswert made <a href="https://www.thebaltimorebanner.com/education/k-12-schools/pikesville-high-principal-eric-eiswert-NT7K7N4K6RDEJNL5Z7ULTEG7VY/" target="_blank">racist and antisemitic comments</a> behind closed doors.</p><p>Dazhon Darien, 31, was charged with disrupting school activities, after investigators determined Darien faked Eiswert’s voice and circulated the audio on social media in January, according to the Baltimore County State’s Attorney’s Office.<b> </b>Darien’s nickname, DJ, was among the names mentioned in the audio clips he allegedly faked.</p><p>“The audio clip ... had profound repercussions,” police wrote in charging documents. “It not only led to Eiswert’s temporary removal from the school but also triggered a wave of hate-filled messages on social media and numerous calls to the school. The recording also caused significant disruptions for the PHS staff and students.”</p><p>He is also charged with theft and retaliating against a witness, related to alleged illicit payments he made to a school athletics coach, as well as stalking, prosecutors said.</p><p>Baltimore County Police Chief Robert McCullough, County Executive Johnny Olszewski, and School Superintendent Myriam Rogers announced a 1:30 pm press conference to discuss the case.</p><p>Eiswert’s voice, which police and <a href="https://www.thebaltimorebanner.com/education/k-12-schools/eric-eiswert-ai-deepfake-YUNO6ITYM5FWZPQAE24RIBV5CQ/" target="_blank">AI experts believe was simulated</a>, made disparaging comments toward Black students and the surrounding Jewish community, was widely circulated on social media.</p><div id="blueconic--fallback"><p><h3>Read More</h3></p></div><p>Questions about the audio’s authenticity quickly followed. Police wrote in charging documents that Darien had accessed the school’s network on multiple occasions in December and January searching for OpenAI tools, and used “Large Language Models” that practice “deep learning, which involves pulling in vast amounts of data from various sources on the internet, can recognize text inputted by the user, and produce conversational results.” They also connected Darien to an email account that had distributed the recording.</p><p>Many current and former students <a href="https://www.thebaltimorebanner.com/education/k-12-schools/pikesville-high-principal-eric-eiswert-recording-ai-DZ6ZURS3Y5F7HEQMMGBH244Y3E/" target="_blank">believed Eiswert was responsible</a> for the offensive remarks, while former colleagues denounced the audio and defended Eiswert’s character. Eiswert himself has denied making those comments and said the comments do not align with his views.</p><p>The audio, posted to the popular Instagram account<b> </b><a href="https://www.instagram.com/reel/C2NEEDrMo8_/?igsh=MTYwZWE4MnpxdDFvbA%3D%3D" target="_blank">murder_ink_bmore</a>, prompted a Baltimore County Public Schools and Baltimore County Police investigation. Eiswert has not been working in the school since the investigation began.</p><p>The voice refers to “ungrateful Black kids who can’t test their way out of a paper bag” and questions how hard it is to get those students to meet grade-level expectations. The speaker<b> </b>uses names of people who appear to be staff members and says they should not have been hired, and that<b> </b>he should get rid of another person “one way or another.”</p><p>“And if I have to get one more complaint from one more Jew in this community, I’m going to join the other side,” the voice said.</p><p>Darien was being investigated as of December in a theft investigation that had been initiated by Eiswert. Police say Darien had authorized a $1,916 payment to the school’s junior varsity basketball coach, who was also his roommate, under the pretense that he was an assistant girls soccer coach. He was not, school officials said. Eiswert determined that Darien had submitted the payment to the school payroll system, bypassing proper procedures. Darien had been notified of the investigation, police said.</p><p>Police say the clip was received by three teachers the night before it went viral. The first was Darien; a third said she received the email and then got a call from Darien and teacher Shaena Ravenell telling her to check her email. Ravenell told police that she had forwarded the email to a student’s cell phone, “who she knew would rapidly spread the message around various social media outlets and throughout the school,” and also sent it to the media and the NAACP, police said.</p><p>She did not mention receiving it from Darien until confronted about his involvement. Ravenell has not been charged with a crime and could not immediately be reached for comment.</p><p>Rogers, the superintendent, in January called the comments “disturbing” and “highly offensive and inappropriate statements about African American students, Pikesville High School staff, and Pikesville’s Jewish community.”</p><p>Billy Burke, head of the Council of Administrative &amp; Supervisory Employee, the union that represents Eiswert, was the only official to suggest the audio was AI-generated.</p><p>Burke said he was disappointed in the public’s assumption of Eiswert’s guilt. At a January school board meeting, he said the principal needed police presence at his home because he and his family have been harassed and threatened. Burke had also received harassing emails, he said at the time.</p><p>Police said the school’s front desk staff was “inundated with phone calls from parents and students expressing concern and disparaging remarks toward school staff and administrators.” The flood of calls made it difficult to field phone calls from parents trying to make arrangements for their children and other school functions, officials told police.</p><p>“The school leadership expressed that staff did not feel safe, which required an increase in police presence at the school to address safety concerns and fears,” police said.</p><p>Teachers, under the impression the recording was authentic, “expressed fears that recording devices could have been planted in various places in the school,” police said.</p><p>“The recording’s release deeply affected the trust between teachers and the administration,” police said. “One individual shared that they fielded sensitive phone calls in their vehicle in the parking lot instead of speaking in school.”</p><p>Experts in detecting audio and video fakes told The Banner in March that there was <a href="https://www.thebaltimorebanner.com/education/k-12-schools/eric-eiswert-ai-deepfake-YUNO6ITYM5FWZPQAE24RIBV5CQ/" target="_blank">overwhelming evidence</a> the voice is AI-generated. They noted its flat tone, unusually clean background sounds and lack of consistent breathing sounds or pauses as hallmarks of AI. They also ran the audio through several different AI-detection techniques, which consistently concluded it was a fake, though they could not be 100% sure.</p><p>AI voice-generation tools are now widely available online, and a single minute’s recording of someone’s voice can be enough to simulate it with a $5-a-month AI tool, the <a href="https://www.niemanlab.org/2024/02/with-elections-looming-worldwide-heres-how-to-identify-and-investigate-ai-audio-deepfakes/" target="_blank">Nieman Journalism Lab reported</a> in February.</p><p>There are few regulations to prevent AI imitations, called deepfakes, and few perpetrators are prosecuted.</p><div id="article_eoa_container"><p><h3>More From The Banner</h3></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Palm OS and the devices that ran it (121 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2024/04/palm-os-and-the-devices-that-ran-it-an-ars-retrospective/</link>
            <guid>40156569</guid>
            <pubDate>Thu, 25 Apr 2024 12:16:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2024/04/palm-os-and-the-devices-that-ran-it-an-ars-retrospective/">https://arstechnica.com/gadgets/2024/04/palm-os-and-the-devices-that-ran-it-an-ars-retrospective/</a>, See on <a href="https://news.ycombinator.com/item?id=40156569">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            <h4>
      palm of your hand    —
</h4>
            
            <h2 itemprop="description">Before smartphones, we had PDAs in our pockets. Palm did them best. </h2>
                    </header>
        <section>
            <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/04/palm-pilot-retrospective-800x450.jpg" alt="Palm OS and the devices that ran it: An Ars retrospective">
      <figcaption><p>Aurich Lawson</p></figcaption>  </figure>

  




<!-- cache miss 386:single/related:8e1406f73e58a704cf7b0ac7d7e2fc33 --><!-- empty -->
<p>“Gadgets aren’t fun anymore,” sighed my wife, watching me tap away on my Palm Zire 72 as she sat on the couch with her MacBook Air, an iPhone, and an Apple Watch.</p>
<p>And it’s true: The smartphone has all but eliminated entire classes of gadgets, from point-and-shoot cameras to MP3 players, GPS maps, and even flashlights. But arguably no style of gadget has been so thoroughly superseded as the personal digital assistant, the handheld computer that dominated the late '90s and early 2000s. The PDA even set the template for <i>how</i> its smartphone successors would render it obsolete, moving from simple personal information management to encompass games, messaging, music, and photos.</p>
<p>But just as smartphones would do, PDAs offered a dizzying array of operating systems and applications, and a great many of them ran Palm OS. (I bought my first Palm, an m505, new in 2001, upgrading from an HP 95LX.) Naturally, there’s no way we could enumerate every single such device in this article. So in this Ars retrospective, we’ll look back at some notable examples of the technical evolution of the Palm operating system and the devices that ran it—and how they paved the way for what we use now.</p>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/04/palmfeature2-scaled.jpg" data-height="1928" data-width="2560" alt="You never forget your first(s). Here were my Palms from back in the day, my original m505, and later, my first Zire 72.&nbsp;They’re beat up, but with new batteries, they still work great."><img alt="You never forget your first(s). Here were my Palms from back in the day, my original m505, and later, my first Zire 72.&nbsp;They’re beat up, but with new batteries, they still work great." src="https://cdn.arstechnica.net/wp-content/uploads/2024/04/palmfeature2-640x482.jpg" width="640" height="482" srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/04/palmfeature2-1280x964.jpg 2x"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/04/palmfeature2-scaled.jpg" data-height="1928" data-width="2560">Enlarge</a> <span>/</span> You never forget your first(s). Here were my Palms from back in the day, my original m505, and later, my first Zire 72.&nbsp;They’re beat up, but with new batteries, they still work great.</p><p>Cameron Kaiser</p></figcaption></figure>
<h2>When Zoom(er) wasn’t meeting software</h2>
<p>In the mid-to-late 1980s, portable computing primarily meant either heavy, luggable workstations or a unique class of pocket computers with tiny screens, small memories, and calculator-like keyboards. Jeff Hawkins, then vice president of research at portable systems builder GRiD, thought he could do better. He wanted to build a system where the screen itself becomes the input device, replacing keyboards with pens and styluses.</p>                                            
                                                        
<p>While handwriting recognition was an even bigger challenge for systems back then, Hawkins’ PalmPrint system simplified the task by merely matching strokes to characters instead of trying to recognize entire words. PalmPrint became GridPen, the core of the 1989 GriDPad 1900, or what we would call today the first commercially successful tablet computer. Using a resistive 10-inch black-and-white LCD as the screen and writing surface, it ran MS-DOS on a lower-power 10 MHz Intel 80C86 and weighed just about two kilograms (4.5 pounds), selling at an MSRP of $2,500 (about $6,200 in 2024 dollars).</p>
<p>The GriDPad line went on to be very successful for GRiD, but Hawkins increasingly considered his own creation to be too bulky and expensive. Surveying existing GriDPad corporate customers about a portable machine they would <i>personally</i> use, the feedback was unanimous: It had to be a lot lighter, a lot smaller, and under a cool grand.</p>
<p>GRiD itself wasn’t interested in producing a low-end mass-market device, but such a unit was well within the market range of Tandy Corporation, GRiD’s parent since 1988 and the owners of Radio Shack. Tandy management was entranced by the concept of what Hawkins called the “Zoomer,” so much so that the company was willing to invest $300,000 in Hawkins’ new venture to develop it, which he called Palm Computing.</p>
<p>Hawkins selected GeoWorks’ PC/GEOS as the operating system based on <a href="https://oldvcr.blogspot.com/2023/06/o-brother-geobook-lets-get-thou-back-on.html">its proven ability</a> to run on inexpensive hardware, and Tandy brought on longtime partner Casio (also a major pocket computer manufacturer) as the new device’s OEM. To manage the growing company, Hawkins hired Apple-Claris alumnus Donna Dubinsky as CEO and later Ed Colligan as VP of marketing, fresh from Macintosh peripherals maker Radius.</p>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/04/palmfeature3-scaled.jpg" data-height="2560" data-width="1928" alt="The Tandy Zoomer, here in the Casio Z-7000 OEM version."><img alt="The Tandy Zoomer, here in the Casio Z-7000 OEM version." src="https://cdn.arstechnica.net/wp-content/uploads/2024/04/palmfeature3-640x850.jpg" width="640" height="850" srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/04/palmfeature3-1280x1700.jpg 2x"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/04/palmfeature3-scaled.jpg" data-height="2560" data-width="1928">Enlarge</a> <span>/</span> The Tandy Zoomer, here in the Casio Z-7000 OEM version.</p><p>Cameron Kaiser</p></figcaption></figure>
<p>Unfortunately, the Zoomer’s development became increasingly troubled due to corporate interference and software churn, and although underclocking its x86-compatible CPU to 7 MHz dramatically extended its battery life, it also made the unit slow and ponderous. Still, the Zoomer got to market in October 1993 at a pound in weight (less than half a kilogram) and for $599 ($1,240 in 2024), markedly undercutting Apple’s Newton MessagePad. On the other hand, it was still too large and was basically treated (and judged) as a PC, and even though its handwriting recognition was better than the Newton’s, it was still outsold four to one.</p>

                                                </div>

            
            
                            <nav>Page: <span>1 <a href="https://arstechnica.com/gadgets/2024/04/palm-os-and-the-devices-that-ran-it-an-ars-retrospective/2/">2</a> <a href="https://arstechnica.com/gadgets/2024/04/palm-os-and-the-devices-that-ran-it-an-ars-retrospective/3/">3</a> <a href="https://arstechnica.com/gadgets/2024/04/palm-os-and-the-devices-that-ran-it-an-ars-retrospective/4/">4</a> <a href="https://arstechnica.com/gadgets/2024/04/palm-os-and-the-devices-that-ran-it-an-ars-retrospective/5/">5</a> <span>...</span> <a href="https://arstechnica.com/gadgets/2024/04/palm-os-and-the-devices-that-ran-it-an-ars-retrospective/11/">11</a> <a href="https://arstechnica.com/gadgets/2024/04/palm-os-and-the-devices-that-ran-it-an-ars-retrospective/12/">12</a> <a href="https://arstechnica.com/gadgets/2024/04/palm-os-and-the-devices-that-ran-it-an-ars-retrospective/2/"><span>Next <span>→</span></span></a></span></nav>
            
        </section>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tribler: An attack-resilient micro-economy for media (189 pts)]]></title>
            <link>https://github.com/Tribler/tribler/wiki</link>
            <guid>40156534</guid>
            <pubDate>Thu, 25 Apr 2024 12:13:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Tribler/tribler/wiki">https://github.com/Tribler/tribler/wiki</a>, See on <a href="https://news.ycombinator.com/item?id=40156534">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wiki-body" data-view-component="true">
                <p><h2>Tribler: an attack-resilient micro-economy for media</h2><a id="user-content-tribler-an-attack-resilient-micro-economy-for-media" aria-label="Permalink: Tribler: an attack-resilient micro-economy for media" href="#tribler-an-attack-resilient-micro-economy-for-media"></a></p>
<ul>
<li>Anonymous Tor-like downloads and fast search</li>
<li>Earn <em>seeding</em> tokens</li>
<li>Reward content creators</li>
</ul>
<p><img src="https://camo.githubusercontent.com/fa24f6586363adda54210b8fcd595e9207b7cf1f14d240d1c5d7ade721d7d6c5/68747470733a2f2f666f72756d2e747269626c65722e6f72672f75706c6f6164732f64656661756c742f6f726967696e616c2f31582f353634376365613935316338383837333663326634633738653031323039363730303830353038382e706e67" alt="Tribler Search V7.0" data-canonical-src="https://forum.tribler.org/uploads/default/original/1X/5647cea951c888736c2f4c78e012096700805088.png"></p>
<p>Tribler is a Bittorrent-compatible alternative to Youtube.
It is designed to protect your privacy, build a web-of-trust, be attack-resilient, and
reward content creators directly.
We are building a micro-economy without banks, without advertisers,
and without any government.
Together <a href="http://news.harvard.edu/gazette/story/2007/08/creating-a-computer-currency/" rel="nofollow">with Harvard University</a>, the Tribler team deployed one of the first
fully distributed ledgers in August 2007, see <a href="http://news.bbc.co.uk/2/hi/technology/6971904.stm" rel="nofollow">BBC News coverge</a> and a <a href="http://www.newscientist.com/article/dn12565-bandwidth-could-be-a-new-global-currency.html" rel="nofollow">New Scientist article</a>.
In coming years we will further expand our micro-economy based on <em>bandwidth tokens</em>.
We aim to become the key place where audiences find their torrents, creative talents
get discovered, and artists get financial rewards from their fans.
Tribler is the place where 100 percent of the money goes to artists and the people that run the infrastructure.</p>
<p>Our mission: <em>re-inventing media and money</em>.</p>
<p>Over 2 million people have used Tribler over the years.
The Tribler project was started in 2005 at Delft University of Technology
and over 100+ developers contributed code to it.
We are continuously improving it and further expanding the scientific developers team.</p>
<p>Technical foundations of Tribler are the Bittorrent protocol,
an overlay for P2P communication across NAT/firewalls,
gradual building of trust in public keys with Bittorrent seeding,
and our token economy with incentives for Tor-like relaying and hidden seeding.
For 12 years we have been building a very robust self-organising Peer-to-Peer system.
Today Tribler is robust: "the only way to take Tribler down is to take The Internet down" (but a single software bug could end everything).</p>
<p><h2>Current items under active development</h2><a id="user-content-current-items-under-active-development" aria-label="Permalink: Current items under active development" href="#current-items-under-active-development"></a></p>
<p>This wiki page contains our main technical documentation, highlights:</p>
<ul>
<li>Trustchain: our 10.000 transactions per second ledger</li>
<li>Token economy and decentral market</li>
</ul>
<table role="table">
<thead>
<tr>
<th>Topic and open Github issue</th>
<th>Researcher</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/7586">On-device decentralised AI</a> - phd level</td>
<td>Petru</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/7290">Trustworthy data for generative AI</a> - phd level</td>
<td>Marcel</td>
</tr>
<tr>
<td><a href="https://github.com/Tribler/tribler/issues/7258">5G overlay network for decentralised On-Device Machine Learning</a></td>
<td>Orestis Kanaris</td>
</tr>
<tr>
<td><a href="https://github.com/Tribler/tribler/issues/7254">True decentralised on-device machine learning</a></td>
<td>Quinten</td>
</tr>
<tr>
<td><a href="https://github.com/Tribler/tribler/issues/7435">exploring LLM as a database</a></td>
<td>Xueyuan Chen</td>
</tr>
<tr>
<td><a href="https://github.com/Tribler/tribler/issues/7431">Offline digital Euro: a first design and implementation</a></td>
<td>Leon</td>
</tr>
<tr>
<td><a href="https://github.com/Tribler/tribler/issues/7481">passport-grade digital identity with DDoS protection using IP reputation</a></td>
<td>Adrian</td>
</tr>
<tr>
<td><a href="https://github.com/Tribler/tribler/issues/6942">Web3Recommend: Decentralised Web3 social recommendations with trust and relevance balance</a></td>
<td><a href="https://github.com/rmadhwal">Rohan Madhwal</a></td>
</tr>
<tr>
<td>Making Trustchain scale to enterprise level <a href="https://github.com/Tribler/tribler/issues/4140">with a large stress testing experiment</a>
</td>
<td>Bulat Nasrulin</td>
</tr>
<tr>
<td>IPv8 resilient overlay: <a href="https://github.com/Tribler/tribler/issues/2541">Sybil-resilience through latency-based shadow-banning</a>
</td>
<td>Quinten Stokkink</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/5576">Universal wallet</a> for identity, attestations, and money</td>
<td>Rowdy Chotkan</td>
</tr>
<tr>
<td><a href="https://github.com/Tribler/tribler/issues/4256">Gossiping torrent popularity to scale to millions of torrents</a></td>
<td>Sandip, Alexander and Andrei</td>
</tr>
</tbody>
</table>
<p>Open projects for new TUDelft master thesis students: Tor-like streaming, self-sovereign identity and authentication on Android, relevance ranking of search results (+swarm popularity), perfect metadata through distributed crowdsourcing, self-reinforcing trust, and perfect network connectivity using NAT/Firewall traversal.
Speculative projects with long-term focus: <a href="https://github.com/Tribler/tribler/issues/2882">prediction market for climate change</a>. A <a href="https://www.google.nl/search?q=anti+hft" rel="nofollow">market designed against</a> frontrunners and high-frequency trading abusers in general.</p>
<table role="table">
<thead>
<tr>
<th>Project: Waiting for new developers</th>
<th>Prior Dev</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/Tribler/tribler/issues/4481">Deceptively simple trust model</a></td>
<td>Alexander Stannat</td>
</tr>
<tr>
<td>Beyond decentral exchanges: <a href="https://github.com/Tribler/tribler/issues/5221">Single universal global market</a>
</td>
<td>Joost V.</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/4629">EuroToken - an open alternative to Facebook Libra</a> and JPMorgan coin</td>
<td>Wessel Blokzijl</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/5134">ArtistCoin - Fairness for artists</a>, audio streaming service without any intermediaries</td>
<td>Tim W.</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/10">Real-time updates to the trust model and visualisation</a> of random walks</td>
<td>Can Umut</td>
</tr>
<tr>
<td>Youtube-like scale: <a href="https://github.com/Tribler/tribler/issues/3971">Gigachannels with 1 billion magnet links</a>
</td>
<td>Vadim</td>
</tr>
<tr>
<td>A <a href="https://github.com/Tribler/tribler/issues/3337">live token economy</a> and distributed <a href="https://github.com/Tribler/tribler/issues/2559">marketplace for bandwidth tokens</a>
</td>
<td>Martijn de Vos</td>
</tr>
<tr>
<td>Low-level debugging of <a href="https://github.com/Tribler/tribler/issues/2620">Tor-like tunnels</a> and <a href="https://github.com/Tribler/tribler/issues/2548">performance in general</a>
</td>
<td>Vadim</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/2571">Blockchain: detect freeriders, refuse service</a>; anon compatible</td>
<td>Ewout Bongers</td>
</tr>
<tr>
<td>self-sovereign identity+trust: <a href="https://github.com/Tribler/tribler/issues/2682">overview</a>, <a href="https://github.com/Tribler/tribler/issues/2812">biometric validation</a>, boosted <a href="https://github.com/Tribler/tribler/issues/3013">privacy</a>, and <a href="https://github.com/Tribler/tribler/issues/2918">voting pass</a>
</td>
<td>8 students</td>
</tr>
<tr>
<td>Distributed Apps: <a href="https://github.com/Tribler/tribler/issues/2943">autonomous code execution using IPv8 plugins</a>
</td>
<td>Mitchell Olsthoorn</td>
</tr>
<tr>
<td>P2P 4G - <a href="https://github.com/Tribler/tribler/issues/4827">Universal connectivity using imperfect hardware</a>
</td>
<td>Matt S.</td>
</tr>
<tr>
<td>Financial Engineering: <a href="https://github.com/Tribler/tribler/issues/4044">decentralised non-profit payment services</a>
</td>
<td>Jetse Brouwer</td>
</tr>
<tr>
<td>Walker infrastructure with <a href="https://github.com/Tribler/tribler/issues/2754">48 NAT boxes and automated NAT puncturing</a>
</td>
<td>Remko Naber</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/2925">Autonomous self-replicating code</a> buy servers with Bitcoins</td>
<td>4 students</td>
</tr>
<tr>
<td>Prototype projects "Blockchain Engineering" Master course around <a href="https://github.com/Tribler/tribler/issues?q=is%3Aissue++label%3A%22MSc+course+work%22">threshold encryption, trustchain, self-sovereign ID, etc</a>
</td>
<td>45 master students</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/2457">Bottom-up consensus model with full scalability</a> using checkpointing</td>
<td>Kelong Cong</td>
</tr>
<tr>
<td>PageRank-like trust model with <a href="https://github.com/Tribler/tribler/issues/1844">Sybil-attack resilience</a>
</td>
<td>Pim Otte</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/3357">Towards global consensus on trust</a> within the Tribler micro-economy</td>
<td>Jan-Gerrit Harms</td>
</tr>
<tr>
<td>Decentral market primitives: <a href="https://github.com/Tribler/tribler/issues/3486">market order and execution engine fairness</a>
</td>
<td>Marc Juchli</td>
</tr>
<tr>
<td>Decentral market: <a href="https://github.com/Tribler/tribler/issues/2887">privacy for traders and spam-resilience</a>
</td>
<td>Bas van Ijzendoorn</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/3064">Secure hardware storage</a> of keys using PUF hardware</td>
<td>Ade Ade Setyawan Sajim</td>
</tr>
<tr>
<td>Blockchain: <a href="https://github.com/Tribler/tribler/issues/2533">self-reinforcing trust</a> with collection of credit records</td>
<td>Pim Veldhuisen</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/1882">Fast anonymous streaming</a> with Tor-like onion routing</td>
<td>Quinten Stokkink</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/2231">Attack-resilient social media</a> on mobile devices, using LibTribler</td>
<td>Paul Brussee</td>
</tr>
<tr>
<td>Blockchain walker with attack-resilience and integrated NAT puncturing, <a href="https://github.com/Tribler/tribler/issues/2623">trusted peer discovery</a>
</td>
<td>Changliang</td>
</tr>
<tr>
<td>Blockchain: <a href="https://github.com/Tribler/tribler/issues/1842">earn credits with seeding</a> on Kodi-like devices</td>
<td>Bohao Zhang</td>
</tr>
<tr>
<td><a href="https://github.com/Tribler/tribler/issues/2455">crowdsourcing of rich metadata</a></td>
<td>Stijn van Schooten</td>
</tr>
<tr>
<td>Determine popularity+age of content with spam and attack resilience, <a href="https://github.com/Tribler/tribler/issues/2783">swarm size community</a>
</td>
<td>Chengxin Ma</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/2547">Adversarial search</a>: blockchain-based spam resilience in Youtube-like systems</td>
<td>Jelle Licht</td>
</tr>
<tr>
<td>Scalability: <a href="https://github.com/Tribler/tribler/issues/21">donating TeraBytes</a> to crowdsourcing projects</td>
<td>Wouter Smit</td>
</tr>
<tr>
<td>Connecting banks to decentral markets through PSD2 open APIs</td>
<td>Kypianou</td>
</tr>
<tr>
<td>Crowdsourcing and investments</td>
<td>Bart Gout</td>
</tr>
<tr>
<td>re-use our decentral market platform for real-world business case, <a href="https://github.com/Tribler/tribler/issues/2606">crowdsourcing real-estate</a>
</td>
<td>4 bsc students</td>
</tr>
<tr>
<td>Establish + Real-time display of <a href="https://github.com/Tribler/tribler/issues/2905">Blockchain trust</a>
</td>
<td>20 Context project students</td>
</tr>
</tbody>
</table>
<p><h2>Aim: solving trust</h2><a id="user-content-aim-solving-trust" aria-label="Permalink: Aim: solving trust" href="#aim-solving-trust"></a></p>
<p>Social media today is obsessed with profit, filled with advertisements,
overflowing with falsehoods, and infested with fake news.
We're trying to fix these hard problems in a unique way: by building trust.
Our audacious ambition is a clean-slate re-creation of The Internet itself with
foundations of trust.
Craiglist and eBay showed us in 1995 that trustworthy trade was possible online.
Uber, Etsy, and AirBnB show that entire industries can be disrupted by
a single platform with a natural monopoly.</p>
<p>For the past 18 years we have build and deployed platforms to create trust.
Before Wikipedia and Youtube existed we studied the mechanisms behind trust and user-generated content on a small scale.
Several years before Wikipedia emerged we <a href="https://static.usenix.org/events/usenix2000/freenix/full_papers/pouwelse/pouwelse.pdf" rel="nofollow">deployed a music encyclopedia with unconstrained write access</a>, it never became popular because we focused too much on software, instead community growth.</p>
<p>Today we keep a narrow focus and continuously expand Tribler with trustworthy
decentralized technology. We launched sub-second keyword search for
Bittorrent swarms without any server back in 2010 (see <a href="https://www.youtube.com/watch?v=ZXWMhreGiAU" rel="nofollow">our old Google Tech Talk</a> on this topic). One of our operational trust browsing prototypes:
<img src="https://user-images.githubusercontent.com/15870543/27395330-b5621bce-56af-11e7-9ee8-60edb4b0e091.png" alt="trust browser"></p>
<p>Further reading:</p>
<ul>
<li>Our work from 2004, <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.76.3107&amp;rep=rep1&amp;type=pdf" rel="nofollow">2-year in-depth measurement and analysis of Bittorrent (.pdf 25 pages)</a>, largest measurement to date.  Covers eight months of the BitTorrent/Suprnova.org file sharing ecosystem. In particular, we show measurement results of the popularity and the availability of BitTorrent, of its download performance, of the content lifetime, and of the structure of the community responsible for verifying uploaded content.</li>
</ul>
<p><h2>Tribler features and innovations</h2><a id="user-content-tribler-features-and-innovations" aria-label="Permalink: Tribler features and innovations" href="#tribler-features-and-innovations"></a></p>
<p>Tribler supports torrent search without websites, anonymous downloading, torrent streaming, channels of torrents, and sharing content for tokens. <a href="http://sigmm.org/records/records1201/featured03.html" rel="nofollow">Overview of Tribler (.html 5 pages)</a>.
All Tribler features are implemented in a completely distributed manner, not relying on any centralized component.
Still, Tribler manages to remain fully backwards compatible with BitTorrent. <a href="http://iptps06.cs.ucsb.edu/papers/Pouw-Tribler06.pdf" rel="nofollow">The 2006 overview of Tribler (.pdf 6 pages)</a> featuring taste groups, friends, friends-of-friends and faster downloads by donating bandwidth to friends (<a href="http://svn.tribler.org/bt2-design/coop-download/trunk/note.tex" rel="nofollow">protocol spec</a> of friend boosting).
Note that <a href="http://svn.tribler.org/bt2-design/proto-spec-unified/trunk/proto-spec-current.pdf" rel="nofollow">the 2006-2009 Tribler protocol specification (.pdf 47 pages)</a> is now mostly outdated, as we switched to our new synchronization protocol called Dispersy (see below).</p>
<p>Trust in social media content is essential for a sustainable ecosystem.
We introduced channels of Bittorrent swarms <a href="https://www.tribler.org/LivePlaylists/" rel="nofollow">in 2009</a> with the Tribler 4.x release.
Each user can vote on channels to increase their visibility and tell everybody the
channel owner is not a spammer and not spreading fake items.
The reputation of both the voters and channel owner are important.</p>
<p>Tribler protects your privacy by not storing anything on any server.
To protect your privacy even more, we have prototyped search algorithms
based on homomorphic cryptography.
We presented a <a href="https://github.com/Tribler/tribler/files/1649968/privacy_overlay.pdf">new algorithm system for privacy-respecting
scalable Gnutella-like search</a> in 2014.
Our approach to scalability is a similarity function in the encrypted domain (homomorphic), enabling semantic clustering with privacy.</p>
<p>Back in 2006 we introduced long-lived identities to separate trustworthy peers from
freeriders and spammers (<a href="https://www.tribler.org/PermID/" rel="nofollow">PermID</a>). To protect your
privacy further we also devised an alternative to onion routing which potentially
could have stronger security guarantees (correlation attack).
See the details in this thesis on
<a href="https://repository.tudelft.nl/islandora/object/uuid%3A3c7f869c-44b9-41f7-8deb-36ba284606cd" rel="nofollow">Multi-core architecture for anonymous Internet streaming</a>
which includes a performance analysis of running code.</p>
<p>Further reading for developers:</p>
<ul>
<li><a href="https://github.com/Tribler/tribler/wiki/Compiling-Tribler-from-sources-under-Eclipse">Running Tribler from sources in Eclipse</a></li>
<li>
<a href="http://jenkins.tribler.org/" rel="nofollow">Jenkins server for continuous integration, unit tests, installer builders and performance testing</a>. You will find a lot of automatic running scripts there for things like correctness, NAT puncture performance and GUI tests.</li>
<li><a href="https://github.com/Tribler/tribler/wiki/Tribler-Development-Pointers">Tribler development pointers / starting point for new developers</a></li>
<li><a href="https://github.com/Tribler/tribler/tree/devel/doc">Python source code doc directory</a></li>
<li><a href="https://github.com/Tribler/tribler/blob/devel/doc/restapi/introduction.rst">Tribler can run as a background process with this API</a></li>
</ul>
<p><h2>Our primitive 2007 distributed ledger and Trustchain (2012)</h2><a id="user-content-our-primitive-2007-distributed-ledger-and-trustchain-2012" aria-label="Permalink: Our primitive 2007 distributed ledger and Trustchain (2012)" href="#our-primitive-2007-distributed-ledger-and-trustchain-2012"></a></p>
<p>We deployed one of the worlds first fully distributed ledgers in August of <a href="http://news.bbc.co.uk/2/hi/technology/6971904.stm" rel="nofollow">2007</a>.
For over a decade we meticulously measured, analysed, improved, and enhanced this live system.
Today it defines the state-of-the-art in blockchain research, but in the early days it barely functioned at all.
A total of five Ph.D. students of Delft contributed key parts and upgrades.</p>
<p>At launch we called our initiative "<em>bandwidth-as-a-currency</em>". Today we have specific terminology for what we did: a token economy.
We are making Internet bandwidth a tradable commodity without any middleman or need for any centralised governance.
Our efforts span over a decade, making us the veterans in the field.
Our ledger provides an incentive for Bittorrent seeding and Tor-like relaying.
For numerous years the tit-for-tat algorithm provided the only incentive for contributions in Bittorrent.
No incentive for seeding existed, except when central servers kept track of your uploads and downloads.
We measured closed invite-only communities for numerous years and mathematically showed their rich-get-richer properties. For details see <a href="http://publicatio.bibl.u-szeged.hu/2509/1/SRE-p2p11-final-version.pdf" rel="nofollow">Fast download but eternal seeding: the reward and punishment of sharing ratio enforcement</a> and our measurement paper <a href="http://www.usenix.org/event/iptps10/tech/full_papers/Meulpolder.pdf" rel="nofollow">understanding bandwidth economics and ratio enforcement (.pdf 5 pages)</a>.
We measured 508,269 peers in 444 swarms within five BitTorrent communities, ranging from public to highly elite. We observe download performance, connectability, seeder/leecher ratios, seeding duration, and statistics regarding the resource supply.</p>
<p>We got inspiration for a novel blockchain design based on operating our own ledger and studying token economies.
Our current work is called Trustchain, a unique design from 2012 where all participants have their own personal blockchain and create their own genesis block.
Our older work used a graph-based approach and graph-based reputation algorithms.
Trustchain records transactions in a tamper-proof and scalable manner.
It does not require mining and does not try to solve the double spending problem.
Our primitive 2007 ledger pre-dates Bitcoin, additionally our 2012 DAG-based approach pre-dates IOTA and the Texas DAG patents.</p>
<p>We are fans of Bitcoin, but also showed in <a href="https://web.archive.org/web/20141218123940/http://www.pds.ewi.tudelft.nl/~victor/bitcoin.html" rel="nofollow">an early analysis</a> the flaws in this concept.
Our approach to digital signatures is the essential difference which sets us apart from others.
Mono-signatures form the foundation of all other projects we have seen in the past decade.
Meaning, in systems such as Bitcoin a transaction is already valid with a single signature.
Our Trustchain design does not permit transactions with merely a single signature.
Trustchain only supports multi-party agreement recording, others are not valid.
We believe that we created a more powerful system by removing single-signature transactions.
Only time can tell the usefullness of this academically-pure and minimal design.</p>
<p>The foundation of our approach is making repeated successful interactions between actors explicit and durable.
Cryptographically signed records of successful encounters serve as proof-of-work certificates.
The validity and value of these certificates is determined by a trust and reputation system.
Relaying for anonymity and seeding in Tribler constitutes work which is rewarded with a signed certificate.
Helping others and uploading in Bittorrent swarms is rewarded with bandwidth tokens (e.g. signed certificates).
Mining in our system becomes download parts of a swarm and uploading them to multiple interested parties.
In 2013 we got the credit mining part of our system operational in early Beta.
The screenshot below from November 2013 shows the boosting of various swarms.
Note the investment yields of "struck gold" and "poor" in the right column.</p>
<p><img src="https://cloud.githubusercontent.com/assets/325224/2731498/e3ac1522-c62d-11e3-9711-dd2ba72652d0.png" alt="Screenshot of our credit mining Beta code from November 2013, showing the boosting of various swarms"></p>
<p>Further reading:</p>
<ul>
<li><a href="https://tools.ietf.org/html/draft-pouwelse-trustchain-00" rel="nofollow">Trustchain IETF Draft Internet Standards proposal</a></li>
<li>
<a href="http://www.asci.tudelft.nl/media/proceedings_asci_conference_2010/asci2010_submission_14.pdf" rel="nofollow">Scientific 2010 publication on BarterCast ledger (.pdf 8 pages)</a>.</li>
<li>Our <a href="http://www.pds.ewi.tudelft.nl/~epema/Papers/2009/HotP2P2009.pdf" rel="nofollow">original BarterCast protocol</a> publication 2009.</li>
<li>The <a href="http://www.ifi.uzh.ch/ce/publications/Accounting_Mechanisms.pdf" rel="nofollow">DropEdge enhancement was proposed to BarterCast together with Harvard and Berkeley scientists (.pdf 42 pages)</a> which makes the ledger harder to attack.</li>
<li>
<a href="https://link.springer.com/content/pdf/10.1007/978-3-642-30054-7_19.pdf" rel="nofollow">Reducing the storage cost of our ledger and reputation system</a> form 2012.</li>
<li>Key Internet deployment evaluation: <a href="https://ieeexplore.ieee.org/document/6663517" rel="nofollow">A Network Science Perspective of a Distributed Reputation Mechanism (.pdf 9 pages)</a>, from 2013.</li>
</ul>
<p><h2>Our methodology: keep focus and dream big</h2><a id="user-content-our-methodology-keep-focus-and-dream-big" aria-label="Permalink: Our methodology: keep focus and dream big" href="#our-methodology-keep-focus-and-dream-big"></a></p>
<p>For our narrow focus of a Bittorrent client we are exploring the fundamentals of
identity, trust, and trade. With over 1 billion users of Youtube and Bittorrent we know there
is a mass audience ready for something better.</p>
<p>Our approach has very boring foundations, when compared to newer and more sexy work, like IPFS, FileCoin, or Storj.
We first measured Bittorrent in 2002, it is a flourishing mature ecosystem and ready for an upgrade.
Bootstrapping an ecosystem is hard, we designed and deployed a superior alternative to Bittorrent.
It became an official <a href="https://datatracker.ietf.org/doc/rfc7574/" rel="nofollow">IETF Internet Standard</a>, but completely flopped.
This formed our preference for simplicity, elegance and our allergy for bloatware, clean-slate work, and over-engineering.
Numerous other projects try to create a generic approach using an ICO for funding and
promising the early adopters a dazzling return-on-investment.
Tribler is different. <em>rant warning</em>. We are non-profit academics.
We do not want to replace the old elite with a new crypto-currency elite.
What is changed if we replace backroom deals, lobbyists, middleman, and legal monopolies with the tools of the new elite:
algorithms, early investor rewards, proof-of-dominating-stake, and smart contracts?
Replacing the analog world and breading digital-native inequality does not make the world a better place.
We are creating a micro-economy based on fairness, trust, equality, and self-governance.
By design we banish rent-seeking. Critical infrastructure rarely makes profit. We are trying to build critical infrastructure.</p>
<p><h2>Tor-inspired onion routing</h2><a id="user-content-tor-inspired-onion-routing" aria-label="Permalink: Tor-inspired onion routing" href="#tor-inspired-onion-routing"></a></p>
<p>As of December 2014 Tribler has a build-in version of a Tor-like anonymity system. This is completely disconnected from 'The' Tor network. It is still ongoing work. It gives you probably superior protection than a VPN, but no protection against resourceful spying agencies.</p>
<p>We have implemented the <a href="https://github.com/Tribler/tribler/blob/v6.3.1/Tribler/community/tunnel/community.py#L271">main parts of the Tor wire protocol within Tribler</a>.
Instead of the TCP protocol that 'the' Tor network uses, we use UDP.
The enables us to do NAT puncturing and traversal.
We have created our own network using this Tor variant, our code is not compatible with normal Tor.
Work started as a <a href="https://github.com/Tribler/tribler/issues/119">small trial</a> in December 2013 with anonymous Bittorrent downloading.
Essential part of our work is that everybody who downloads anonymously also becomes a relay.
This brings the Bittorrent tit-for-tat idea to darknets.
With this ongoing work we aim to offer in 2018 with Tribler V7.0 proxied downloading for any Bittorrent swarm.</p>
<p><img src="https://camo.githubusercontent.com/399d6eeb8c0a4d7b34ae8df87f56f11ca97ed253280754a1608cdacdac4777b3/68747470733a2f2f662e636c6f75642e6769746875622e636f6d2f6173736574732f313536343235372f313730353337342f65653265623265612d363064632d313165332d383937372d3138313138353431366136332e706e67" alt="December 2013 trial with TOR-like onion routing for anonymous swarm downloading" data-canonical-src="https://f.cloud.github.com/assets/1564257/1705374/ee2eb2ea-60dc-11e3-8977-181185416a63.png"></p>
<p>Lengthy documentation in the form of two master thesis documents is available. First is a general documentation of the tunnel and relay mechanism, <a href="http://repository.tudelft.nl/islandora/object/uuid%3A997890d1-4141-4597-92eb-3dbaa4dc44a1?collection=education" rel="nofollow">Anonymous HD video streaming, .pdf 68 pages</a>.
Second is focused on encryption part, called <a href="http://repository.tudelft.nl/islandora/object/uuid%3Ace3bd867-6540-426d-87d0-348bdf78279d?collection=education" rel="nofollow">Anonymous Internet: Anonymizing peer-to-peer traffic using applied cryptography, .pdf 85 pages</a>.
In addition, there are the specifications for the protocols
for <a href="https://github.com/Tribler/tribler/wiki/Anonymous-Downloading-and-Streaming-specifications">anonymous downloading</a> and <a href="https://github.com/Tribler/tribler/wiki/Hidden-Services-Specifications-for-anonymous-seeding">hidden seeding</a> on this wiki.</p>
<p><h2>overlay protocol for synchronization</h2><a id="user-content-overlay-protocol-for-synchronization" aria-label="Permalink: overlay protocol for synchronization" href="#overlay-protocol-for-synchronization"></a></p>
<p>The current foundation of Tribler is the Dispersy overlay. Dispersy functionality includes: making connections, sending messages, puncturing NAT boxes, and distributed database synchronization. Every 5 seconds Dispersy sends out a message to establish a new connection or re-connect to a known peer.
Note that <a href="https://github.com/qstokkink/py-ipv8">we are transitioning to a new overlay</a> for the durations of 2018.</p>
<p>Overlay communication, peer discovery and content discovery (keyword search) are essential building blocks of a peer-to-peer system. Tribler preserves the content and peers it discovered in the past. Every Tribler client runs a full SQL database engine. Several times per second each Tribler peer sends and receives updates for this database. Our protocol for distributed database synchronization is called Dispersy.
See a simple messaging client written with just a few lines of code as <a href="https://github.com/jarradh/DispersyExample">a simple tutorial example</a>; <a href="https://github.com/Tribler/dispersy/blob/devel/doc/tutorial-part1.org">outdated broken tutorial</a>.</p>
<p>The detailed wire protocol specification:
<a href="https://github.com/Tribler/dispersy/blob/devel/docs/wire_protocol.rst#dispersy-introduction-request">introduction-request-1</a></p>
<p><a href="https://d2k0ddhflgrk1i.cloudfront.net/EWI/Over%20de%20faculteit/Afdelingen/Software%20Technology/Distributed%20Systems/Technical%20Reports/2013/PDS-2013-002.pdf" rel="nofollow">Dispersy is a fully decentralized system for synchronization (.pdf)</a>, capable of running in challenged network environments. Key features of Dispersy are stateless synchronization using Bloomfilters, decentralized NAT traversal, and data bundle selection algorithms that allow the system to scale over 100,000 bundles in the presence of high churn and high-load scenario's.</p>
<p>Dispersy uses a simple database schema, with the <em>sync</em> table containing the data bundles to synchronise across peers in the <em>packet</em> field.
<img src="https://cloud.githubusercontent.com/assets/325224/3511069/a4b9d182-06ac-11e4-827b-69c71374492a.png" alt="dispersy1"></p>
<p><h2>Android port of LibTribler</h2><a id="user-content-android-port-of-libtribler" aria-label="Permalink: Android port of LibTribler" href="#android-port-of-libtribler"></a></p>
<p>Android porting teams are working on the <a href="https://github.com/rjagerman/AT3">downloading and Tor-like protocol part</a> of Tribler and the <a href="https://github.com/wtud/tsap">overlay, channels and search</a> portions. As of June 2014 there is initial running code. The focus is on stability and creating a mature build environment using Jenkins. See below two actual screenshot of current running code. Download the alpha  .APK here: <a href="https://jenkins.tribler.org/job/Build-Tribler_Android-Python/lastBuild/" rel="nofollow">https://jenkins.tribler.org/job/Build-Tribler_Android-Python/lastBuild/</a></p>
<p><img src="https://raw.githubusercontent.com/wtud/tsap/39add25ce1533be02cf5e544f096d15ee71e0c30/screenshots/home_screen_portrait_readme.png" alt="LibTribler running as an CML-RPC service on Android"></p>
<p><img src="https://camo.githubusercontent.com/a18b5cd459e4ba97f4bc3b55e7e92b31d4b20ce7/687474703a2f2f666f72756d2e747269626c65722e6f72672f646f776e6c6f61642f66696c652e7068703f69643d323033" alt="TOR-like tunnels on Android with Bittorrent downloading"></p>
<p><h2>Stealth app for Android</h2><a id="user-content-stealth-app-for-android" aria-label="Permalink: Stealth app for Android" href="#stealth-app-for-android"></a></p>
<p>The following work is ongoing. We have an <a href="https://github.com/AlexKolpa/AndroidStealth/issues?state=open">operational Android app</a> that can spread itself via NFC. The app can spread viral via friends, even if it is blocked from a central app store.</p>
<p>Original student assignment: <em>The aim is to create an Open Source Android smartphone app to help bypass restrictions by non-democratic governments.  The Arab Spring showed the importance of video recording of mass protests. However, possession of a video recording on your phone of human rights violations and mass uprisings brings grave danger. The idea is to make this app “check-point-proof”, meaning that a somewhat knowledgeable person will not detect the presence of the app and will not discover any video content. The app itself should be hidden, you can make a “stealth” app by somehow removing the app icon from your app list (sadly it simply still shows up in the uninstall app list). The app is activated simply by “dialing” a secret telephone number or other method your deem secure. Starting point for your work can be found here: <a href="http://stackoverflow.com/questions/5921071/how-to-create-a-stealth-like-android-app" rel="nofollow">http://stackoverflow.com/questions/5921071/how-to-create-a-stealth-like-android-app</a>.
Your Stealth app need to be able to virally spread and be able to bypass an government restrictions on the official app store. Include the feature for NFC and direct-wifi transfer of the .apk with an easy on-screen manual and steps. Thus users can pass your app along to their friends.</em></p>
<p><h2>NAT Traversal: 80% success rate</h2><a id="user-content-nat-traversal-80-success-rate" aria-label="Permalink: NAT Traversal: 80% success rate" href="#nat-traversal-80-success-rate"></a></p>
<p>Peer-to-Peer (P2P) networks work on the presumption that all nodes in the network are connectable. However, NAT boxes and firewalls prevent connections to many nodes on the Internet.
We created a method to puncture NATs which does not require a server. Our method is therefore a simple no-server-needed alternative to the complex STUN, TURN and <a href="http://tools.ietf.org/html/rfc5245" rel="nofollow">ICE</a> approaches.
<a href="https://dl.ifip.org/db/conf/networking/networking2011-2/HalkesP11.pdf" rel="nofollow">We conducted one of the largest measurements of NAT/Firewall behavior and puncture efficiency in the wild</a>. Our method is a UDP hole-punching technique. We measured the success rate using volunteers running Tribler. Number of users in our trials are 907 and 1531 people. Our results show that UDP hole punching is an effective method to increase the connectability of peers on the Internet: approximately 64% of all peers are behind a NAT box or firewall. More than 80% of hole punching attempts between these peers succeed.</p>
<p><a href="http://tools.ietf.org/html/draft-ietf-ppsp-peer-protocol-03#section-3.10.2" rel="nofollow">Brief description of our UDP puncture method in IETF draft</a></p>
<p><a href="http://kayapo.tribler.org/trac/raw-attachment/wiki/NATtraversal/remko_1035363_Onderzoekstaak_-_Final_Version.pdf" rel="nofollow">Lengthy thesis work on UDP puncturing from 2005</a></p>
<p><h2>Roadmap 2030: a proven alternative model for capitalism</h2><a id="user-content-roadmap-2030-a-proven-alternative-model-for-capitalism" aria-label="Permalink: Roadmap 2030: a proven alternative model for capitalism" href="#roadmap-2030-a-proven-alternative-model-for-capitalism"></a></p>
<p>As Tribler scientists and engineer we are actively trying to make a better world.
Our micro-economy is our living lab for experimenting with alternative models for capitalism.
We aim to re-invent money by creating the first sustainable economy without
any moral hazards from bankers, politicians, and megacorporation.
Citizens and only the citizens are in control with self-governance.</p>
<p><strong><a href="http://www.youtube.com/watch?v=JQiLaKdzD0E" rel="nofollow">Our grand vision in a 1+ hour lecture given at Stanford University, via their Youtube channel</a></strong>.
We want to do more then be a Youtube alternative.
Our grand vision is liberating both media and money.
See the talk <a href="http://www.stanford.edu/class/ee380/Abstracts/120530.html" rel="nofollow">Abstract</a> and <a href="http://www.tribler.org/trac/raw-attachment/wiki/P2P-Collective/EE380_Tribler_talk_Stanford__Pouwelse_Delft_University.pdf" rel="nofollow">slides (.pdf 78 pages)</a>. Keywords: transform money, “Bank-of-Bits”, global financial meltdown isolation. Use cooperation&amp;stability, not volatility&amp;greed.
Alter the essence of capitalism (rich get richer) by abolishing compound interest rate and facilitation of safe zero-cost money transfers &amp; lending.
We aim for a direct assault on the essence of capitalism, aiming even further then the Bitcoin accomplishment (bypassing the central bank).</p>
<p>Further reading:</p>
<ul>
<li>Our writup on InternetSociety.org on <a href="http://www.internetsociety.org/articles/moving-toward-censorship-free-internet" rel="nofollow">liberating the media and Internet itself</a>.</li>
<li>The challenge is to design a micro-economy where the attacker might even control the underlying infrastructure. <a href="http://torrentfreak.com/researchers-anonymous-bittorrent-client-120601/" rel="nofollow">Our 2012 annoucement of our new focus on attack-resilience</a> was covered by numerous news organisations. <a href="http://www.foxnews.com/tech/2012/02/10/forget-megaupload-researchers-call-new-file-sharing-network-invincible/" rel="nofollow">Fox News</a> and Russian Today called us the <a href="http://rt.com/usa/internet-war-new-tribler-941/" rel="nofollow">the new weapon in the battle for Internet liberty</a>.</li>
</ul>
<p><h2>Tribler history</h2><a id="user-content-tribler-history" aria-label="Permalink: Tribler history" href="#tribler-history"></a></p>
<ul>
<li>2019: Release of Gigachannels and Python3 compatibility</li>
<li>2018: Release of Tribler 7</li>
<li>2017: Release of IPv8 digital identity framework, successor of Dispersy</li>
<li>2017: First live tests with decentral marketplace</li>
<li>2016: New blockchain deployment testing</li>
<li>2014: Test network goes live for anonymous Tor-like downloading (not connected in any with with 'the' Tor project)</li>
<li>2013: Anonymous Tor-like download trial</li>
<li>2012: Tribler Mobile live streaming from a phone camera</li>
<li>2011: Libswift accepted as an upcoming IETF Internet Standard</li>
<li>2010: Release of Dispersy network overlay framework</li>
<li>2010: <a href="https://repository.tudelft.nl/islandora/object/uuid:52b586ea-6144-4b4e-a5a1-b05255ce493a/datastream/OBJ" rel="nofollow">Splash</a> framework for data synchronization tested</li>
<li>2010: Wikipedia.org uses our technology for live trial</li>
<li>2009: Large HD streaming trial with BBC</li>
<li>2008: Social network without servers and "easy" invites</li>
<li>2007: Our distributed ledger launched in the wild</li>
<li>2006: Tribler 1st release</li>
<li>2005: First Tribler code = social Bittorrent</li>
<li>2004: Slashdot for first time with largest Bittorrent study</li>
</ul>

              </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[David Frankel is a man on a mission against robocalls (147 pts)]]></title>
            <link>https://spectrum.ieee.org/how-to-stop-robocalls</link>
            <guid>40156527</guid>
            <pubDate>Thu, 25 Apr 2024 12:13:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/how-to-stop-robocalls">https://spectrum.ieee.org/how-to-stop-robocalls</a>, See on <a href="https://news.ycombinator.com/item?id=40156527">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="Why One Man Spent 12 Years Fighting Robocalls" data-elid="2667800049" data-post-url="https://spectrum.ieee.org/how-to-stop-robocalls" data-authors="Michael Koziol" data-page-title="Why One Man Spent 12 Years Fighting Robocalls - IEEE Spectrum"><p>
	At some point, our phone habits changed. It used to be that if the phone rang, you answered it. With the advent of caller ID, you’d only pick up if it was someone you recognized. And now, with spoofing and robocalls, it can seem like a gamble to pick up the phone, period. In 2023, <a href="https://robocallindex.com/" rel="noopener noreferrer" target="_blank"><u>robocall blocking service Youmail</u></a> estimates there were <a href="https://www.techdirt.com/2024/01/16/americans-received-55-million-robocalls-in-2023-a-9-jump-from-2022/" rel="noopener noreferrer" target="_blank"><u>more than 55 billion robocalls</u></a> in the United States. How did robocalls proliferate so much that now they seem to be dominating phone networks? And <a href="https://spectrum.ieee.org/how-your-phone-company-aims-to-stop-robocalls" target="_self"><u>can any of this be undone</u></a>? <em><em><a href="https://spectrum.ieee.org/">IEEE Spectrum</a></em></em>spoke with <a href="https://www.linkedin.com/in/davidfrankel2" rel="noopener noreferrer" target="_blank"><u>David Frankel of ZipDX</u></a>, who’s been fighting robocalls for over a decade, to find out.
</p><p>David Frankel is<a href="https://www.zipdx.info/about/team-members/" rel="noopener noreferrer" target="_blank"><u>the founder of ZipDX</u></a>, a company that provides audioconferencing solutions. He also created the <a href="https://legalcallsonly.org/what-is-rraptor/" rel="noopener noreferrer" target="_blank"><u>Rraptor</u></a> automated robocall surveillance system.</p><p><strong>How did you get involved in trying to stop robocalls?</strong></p><p><strong>David Frankel: </strong>Twelve years ago, I was working in <a href="https://spectrum.ieee.org/topic/telecommunications/">telecommunications</a> and a friend of mine called me <a href="https://www.ftc.gov/news-events/news/press-releases/2013/04/ftc-announces-robocall-challenge-winners" rel="noopener noreferrer" target="_blank"><u>about a contest</u></a> that the Federal Trade Commission (FTC) was starting. They were seeking the public’s help to find solutions to the robocall problem. I spent time and energy putting together a contest entry. I didn’t win, but I became so engrossed in the problem, and like a dog with a bone, I just haven’t let go of it.
</p><p><strong>How can we successfully combat robocalls?</strong></p><p><strong>Frankel: </strong>Well, I don’t know the answer, because I don’t feel like we’ve succeeded yet. I’ve been very involved in something called<a href="https://tracebacks.org/" rel="noopener noreferrer" target="_blank"><u>traceback</u></a>—in fact, it was my FTC contest entry. It’s a semiautomated process where, in fact, with the cooperation of individual phone companies, you go from telco A to B to C to D, until you ultimately get somebody that sent that call. And then you can find the customer who paid them to put this call on the network.
</p><p>
	I’ve got a second tool—a <a href="https://legalcallsonly.org/what-is-rraptor/" rel="noopener noreferrer" target="_blank"><u>robocall surveillance network</u></a>. We’ve got tens of thousands of telephone numbers that just wait for robocalls. We can correlate that with other data and reveal where these calls are coming from. Ideally, we stop them at the source. It’s a sort of sewage that’s being pumped into the telephone network. We want to go upstream to find the source of the sewage and deal with it there.
</p><p><strong>Can </strong><a href="https://spectrum.ieee.org/ai-robocalls-2667266649" target="_self"><u><strong>more regulation</strong></u></a><strong> help?</strong></p><p><strong>Frankel: </strong>Well, regulations are really, really tough for a couple of reasons. One is, it’s a bureaucratic, slow-moving process. It’s also a cat-and-mouse game, because, as quick as you start talking about new regulations, people start talking about how to circumvent them.
</p><p>
	There’s also this notion of regulatory capture. At the Federal Communications Committee, the loudest voices come from the telecommunications operators. There’s an imbalance in the control that the consumer ultimately has over who gets to invade their telephone versus these other interests.
</p><p><strong>Is the robocall situation getting better or worse?</strong></p><p><strong>Frankel: </strong>It’s been fairly steady state. I’m just disappointed that it’s not substantially reduced from where it’s been. We made progress on explicit fraud calls, but we still have too many of these lead-generation calls. We need to get this whacked down by 80 percent. I always think that we’re on the cusp of doing that, that this year is going to be the year. There are people attacking this from a number of different angles. Everybody says there’s no silver bullet, and I believe that, but I hope that we’re about to crest the hill.
</p><p><strong>Is this a fight that’s ultimately winnable?</strong></p><p><strong>Frankel: </strong>I think we’ll be able to take back our phone network. I’d love to retire, having something to show for our efforts. I don’t think we’ll get it to zero. But I think that we’ll be able to push the genie a long way back into the bottle. The measure of success is that we all won’t be scared to answer our phone. It’ll be a surprise that it’s a robocall—instead of the expectation that it’s a robocall.
</p><p><em>This article appears in the May 2024 issue as “5 Questions for David Frankel.”</em><br></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A useful front-end confetti animation library (352 pts)]]></title>
            <link>https://github.com/catdad/canvas-confetti</link>
            <guid>40156330</guid>
            <pubDate>Thu, 25 Apr 2024 11:53:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/catdad/canvas-confetti">https://github.com/catdad/canvas-confetti</a>, See on <a href="https://news.ycombinator.com/item?id=40156330">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><h2 tabindex="-1" dir="auto"><a href="https://github.com/catdad/canvas-confetti/"><img src="https://camo.githubusercontent.com/eb786c99b352202fd6215ba451ff5a45f1d77973e4d5217742702e108510e097/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f6361746461642d6578706572696d656e74732f6361746461642d6578706572696d656e74732d6f7267403565643738622f63616e7661732d636f6e66657474692f6c6f676f2e6a7067" alt="Canvas Confetti" data-canonical-src="https://cdn.jsdelivr.net/gh/catdad-experiments/catdad-experiments-org@5ed78b/canvas-confetti/logo.jpg"></a></h2><a id="" aria-label="Permalink: " href="#"></a></div>
<p dir="auto"><a href="https://github.com/catdad/canvas-confetti/actions/workflows/ci.yml?query=branch%3Amaster"><img src="https://github.com/catdad/canvas-confetti/actions/workflows/ci.yml/badge.svg" alt="github actions ci"></a>
<a href="https://www.jsdelivr.com/package/npm/canvas-confetti" rel="nofollow"><img src="https://camo.githubusercontent.com/b4d4962066dbc03d8bdaf0fb0a4f62e9fa6e8ec8ef395eee6f529d04b2274da3/68747470733a2f2f646174612e6a7364656c6976722e636f6d2f76312f7061636b6167652f6e706d2f63616e7661732d636f6e66657474692f62616467653f7374796c653d726f756e646564" alt="jsdelivr" data-canonical-src="https://data.jsdelivr.com/v1/package/npm/canvas-confetti/badge?style=rounded"></a>
<a href="https://www.npmjs.com/package/canvas-confetti" rel="nofollow"><img src="https://camo.githubusercontent.com/c1b0ce113e31fce5713bd1f7b5653dd3243260c93e1e27837d3cc27bc51ded60/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f646d2f63616e7661732d636f6e66657474692e737667" alt="npm-downloads" data-canonical-src="https://img.shields.io/npm/dm/canvas-confetti.svg"></a>
<a href="https://www.npmjs.com/package/canvas-confetti" rel="nofollow"><img src="https://camo.githubusercontent.com/a237711cc7988d9297c6b690272b0ebd0fc0ea896bd5eae4198447ec4542fa8b/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f762f63616e7661732d636f6e66657474692e737667" alt="npm-version" data-canonical-src="https://img.shields.io/npm/v/canvas-confetti.svg"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demo</h2><a id="user-content-demo" aria-label="Permalink: Demo" href="#demo"></a></p>
<p dir="auto"><a href="https://catdad.github.io/canvas-confetti/" rel="nofollow">catdad.github.io/canvas-confetti</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Install</h2><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<p dir="auto">You can install this module as a component from NPM:</p>
<div dir="auto" data-snippet-clipboard-copy-content="npm install --save canvas-confetti"><pre>npm install --save canvas-confetti</pre></div>
<p dir="auto">You can then <code>require('canvas-confetti');</code> to use it in your project build. <em>Note: this is a client component, and will not run in Node. You will need to build your project with something like <a href="https://github.com/webpack/webpack">webpack</a> in order to use this.</em></p>
<p dir="auto">You can also include this library in your HTML page directly from a CDN:</p>
<div dir="auto" data-snippet-clipboard-copy-content="<script src=&quot;https://cdn.jsdelivr.net/npm/canvas-confetti@1.9.2/dist/confetti.browser.min.js&quot;></script>"><pre><span>&lt;</span><span>script</span> <span>src</span>="<span>https://cdn.jsdelivr.net/npm/canvas-confetti@1.9.2/dist/confetti.browser.min.js</span>"<span>&gt;</span><span>&lt;/</span><span>script</span><span>&gt;</span></pre></div>
<p dir="auto"><em>Note: you should use the latest version at the time that you include your project. You can see all versions <a href="https://github.com/catdad/canvas-confetti/releases">on the releases page</a>.</em></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Reduced Motion</h2><a id="user-content-reduced-motion" aria-label="Permalink: Reduced Motion" href="#reduced-motion"></a></p>
<p dir="auto">Thank you for joining me in this very important message about motion on your website. See, <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-reduced-motion" rel="nofollow">not everyone likes it, and some actually prefer no motion</a>. They have <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-reduced-motion" rel="nofollow">ways to tell us about it</a> and we should listen. While I don't want to go as far as tell you not to have confetti on your page just yet, I do want to make it easy for you to respect what your users want. There is a <code>disableForReducedMotion</code> option you can use so that users that have trouble with chaotic animations don't need to struggle on your website. This is disabled by default, but I am considering changing that in a future major release. If you have strong feelings about this, <a href="https://github.com/catdad/canvas-confetti/issues/new">please let me know</a>. For now, please confetti responsibly.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">API</h2><a id="user-content-api" aria-label="Permalink: API" href="#api"></a></p>
<p dir="auto">When installed from <code>npm</code>, this library can be required as a client component in your project build. When using the CDN version, it is exposed as a <code>confetti</code> function on <code>window</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>confetti([options {Object}])</code> → <code>Promise|null</code></h3><a id="user-content-confettioptions-object--promisenull" aria-label="Permalink: confetti([options {Object}]) → Promise|null" href="#confettioptions-object--promisenull"></a></p>
<p dir="auto"><code>confetti</code> takes a single optional object. When <code>window.Promise</code> is available, it will return a Promise to let you know when it is done. When promises are not available (like in IE), it will return <code>null</code>. You can polyfill promises using any of the popular polyfills. You can also provide a promise implementation to <code>confetti</code> through:</p>
<div dir="auto" data-snippet-clipboard-copy-content="const MyPromise = require('some-promise-lib');
const confetti = require('canvas-confetti');
confetti.Promise = MyPromise;"><pre><span>const</span> <span>MyPromise</span> <span>=</span> <span>require</span><span>(</span><span>'some-promise-lib'</span><span>)</span><span>;</span>
<span>const</span> <span>confetti</span> <span>=</span> <span>require</span><span>(</span><span>'canvas-confetti'</span><span>)</span><span>;</span>
<span>confetti</span><span>.</span><span>Promise</span> <span>=</span> <span>MyPromise</span><span>;</span></pre></div>
<p dir="auto">If you call <code>confetti</code> multiple times before it is done, it will return the same promise every time. Internally, the same canvas element will be reused, continuing the existing animation with the new confetti added. The promise returned by each call to <code>confetti</code> will resolve once all animations are done.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto"><code>options</code></h4><a id="user-content-options" aria-label="Permalink: options" href="#options"></a></p>
<p dir="auto">The <code>confetti</code> parameter is a single optional <code>options</code> object, which has the following properties:</p>
<ul dir="auto">
<li><code>particleCount</code> <em>Integer (default: 50)</em>: The number of confetti to launch. More is always fun... but be cool, there's a lot of math involved.</li>
<li><code>angle</code> <em>Number (default: 90)</em>: The angle in which to launch the confetti, in degrees. 90 is straight up.</li>
<li><code>spread</code> <em>Number (default: 45)</em>: How far off center the confetti can go, in degrees. 45 means the confetti will launch at the defined <code>angle</code> plus or minus 22.5 degrees.</li>
<li><code>startVelocity</code> <em>Number (default: 45)</em>: How fast the confetti will start going, in pixels.</li>
<li><code>decay</code> <em>Number (default: 0.9)</em>: How quickly the confetti will lose speed. Keep this number between 0 and 1, otherwise the confetti will gain speed. Better yet, just never change it.</li>
<li><code>gravity</code> <em>Number (default: 1)</em>: How quickly the particles are pulled down. 1 is full gravity, 0.5 is half gravity, etc., but there are no limits. You can even make particles go up if you'd like.</li>
<li><code>drift</code> <em>Number (default: 0)</em>: How much to the side the confetti will drift. The default is 0, meaning that they will fall straight down. Use a negative number for left and positive number for right.</li>
<li><code>flat</code> <em>Boolean (default: false)</em>: Optionally turns off the tilt and wobble that three dimensional confetti would have in the real world. Yeah, they look a little sad, but y'all asked for them, so don't blame me.</li>
<li><code>ticks</code> <em>Number (default: 200)</em>: How many times the confetti will move. This is abstract... but play with it if the confetti disappear too quickly for you.</li>
<li><code>origin</code> <em>Object</em>: Where to start firing confetti from. Feel free to launch off-screen if you'd like.
<ul dir="auto">
<li><code>origin.x</code> <em>Number (default: 0.5)</em>: The <code>x</code> position on the page, with <code>0</code> being the left edge and <code>1</code> being the right edge.</li>
<li><code>origin.y</code> <em>Number (default: 0.5)</em>: The <code>y</code> position on the page, with <code>0</code> being the top edge and <code>1</code> being the bottom edge.</li>
</ul>
</li>
<li><code>colors</code> <em>Array&lt;String&gt;</em>: An array of color strings, in the HEX format... you know, like <code>#bada55</code>.</li>
<li><code>shapes</code> <em>Array&lt;String|Shape&gt;</em>: An array of shapes for the confetti. There are 3 built-in values of <code>square</code>, <code>circle</code>, and <code>star</code>. The default is to use both squares and circles in an even mix. To use a single shape, you can provide just one shape in the array, such as <code>['star']</code>. You can also change the mix by providing a value such as <code>['circle', 'circle', 'square']</code> to use two third circles and one third squares. You can also create your own shapes using the <a href="#confettishapefrompath-path-matrix---shape"><code>confetti.shapeFromPath</code></a> or <a href="#confettishapefromtext-text-scalar-color-fontfamily---shape"><code>confetti.shapeFromText</code></a> helper methods.</li>
<li><code>scalar</code> <em>Number (default: 1)</em>: Scale factor for each confetti particle. Use decimals to make the confetti smaller. Go on, try teeny tiny confetti, they are adorable!</li>
<li><code>zIndex</code> <em>Integer (default: 100)</em>: The confetti should be on top, after all. But if you have a crazy high page, you can set it even higher.</li>
<li><code>disableForReducedMotion</code> <em>Boolean (default: false)</em>: Disables confetti entirely for users that <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-reduced-motion" rel="nofollow">prefer reduced motion</a>. The <code>confetti()</code> promise will resolve immediately in this case.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>confetti.shapeFromPath({ path, matrix? })</code> → <code>Shape</code></h3><a id="user-content-confettishapefrompath-path-matrix---shape" aria-label="Permalink: confetti.shapeFromPath({ path, matrix? }) → Shape" href="#confettishapefrompath-path-matrix---shape"></a></p>
<p dir="auto">This helper method lets you create a custom confetti shape using an <a href="https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/d" rel="nofollow">SVG Path string</a>. Any valid path should work, though there are a few caveats:</p>
<ul dir="auto">
<li>All paths will be filed. If you were hoping to have a stroke path, that is not implemented.</li>
<li>Paths are limited to a single color, so keep that in mind.</li>
<li>All paths need a valid transform matrix. You can pass one in, or you can leave it out and use this helper to calculate the matrix for you. Do note that calculating the matrix is a bit expensive, so it is best to calculate it once for each path in development and cache that value, so that production confetti remain fast. The matrix is deterministic and will always be the same given the same path value.</li>
<li>For best forward compatibility, it is best to re-generate and re-cache the matrix if you update the <code>canvas-confetti</code> library.</li>
<li>Support for path-based confetti is limited to browsers which support <a href="https://developer.mozilla.org/en-US/docs/Web/API/Path2D" rel="nofollow"><code>Path2D</code></a>, which should really be all major browser at this point.</li>
</ul>
<p dir="auto">This method will return a <code>Shape</code> -- it's really just a plain object with some properties, but shhh... we'll pretend it's a shape. Pass this <code>Shape</code> object into the <code>shapes</code> array directly.</p>
<p dir="auto">As an example, here's how you might do a triangle confetti:</p>
<div dir="auto" data-snippet-clipboard-copy-content="var triangle = confetti.shapeFromPath({ path: 'M0 10 L5 0 L10 10z' });

confetti({
  shapes: [triangle]
});"><pre><span>var</span> <span>triangle</span> <span>=</span> <span>confetti</span><span>.</span><span>shapeFromPath</span><span>(</span><span>{</span> <span>path</span>: <span>'M0 10 L5 0 L10 10z'</span> <span>}</span><span>)</span><span>;</span>

<span>confetti</span><span>(</span><span>{</span>
  <span>shapes</span>: <span>[</span><span>triangle</span><span>]</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>confetti.shapeFromText({ text, scalar?, color?, fontFamily? })</code> → <code>Shape</code></h3><a id="user-content-confettishapefromtext-text-scalar-color-fontfamily---shape" aria-label="Permalink: confetti.shapeFromText({ text, scalar?, color?, fontFamily? }) → Shape" href="#confettishapefromtext-text-scalar-color-fontfamily---shape"></a></p>
<p dir="auto">This is the highly anticipated feature to render emoji confetti! Use any standard unicode emoji. Or other text, but... maybe don't use other text.</p>
<p dir="auto">While any text should work, there are some caveats:</p>
<ul dir="auto">
<li>For flailing confetti, something that is mostly square works best. That is, a single character, especially an emoji.</li>
<li>Rather than rendering text every time a confetti is drawn, this helper actually rasterizes the text. Therefore, it does not scale well after it is created. If you plan to use the <code>scalar</code> value to scale your confetti, use the same <code>scalar</code> value here when creating the shape. This will make sure the confetti are not blurry.</li>
</ul>
<p dir="auto">The options for this method are:</p>
<ul dir="auto">
<li><code>options</code> <em><code>Object</code></em>:
<ul dir="auto">
<li><code>text</code> <em><code>String</code></em>: the text to be rendered as a confetti. If you can't make up your mind, I suggest "🐈".</li>
<li><code>scalar</code> <em><code>Number, optional, default: 1</code></em>: a scale value relative to the default size. It matches the <code>scalar</code> value in the confetti options.</li>
<li><code>color</code> <em><code>String, optional, default: #000000</code></em>: the color used to render the text.</li>
<li><code>fontFamily</code> <em><code>String, optional, default: native emoji</code></em>: the font family name to use when rendering the text. The default follows <a href="https://nolanlawson.com/2022/04/08/the-struggle-of-using-native-emoji-on-the-web/" rel="nofollow">best practices for rendring the native OS emoji of the device</a>, falling back to <code>sans-serif</code>. If using a web font, make sure this <a href="https://developer.mozilla.org/en-US/docs/Web/API/FontFace/load" rel="nofollow">font is loaded</a> before rendering your confetti.</li>
</ul>
</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="var scalar = 2;
var pineapple = confetti.shapeFromText({ text: '🍍', scalar });

confetti({
  shapes: [pineapple],
  scalar
});"><pre><span>var</span> <span>scalar</span> <span>=</span> <span>2</span><span>;</span>
<span>var</span> <span>pineapple</span> <span>=</span> <span>confetti</span><span>.</span><span>shapeFromText</span><span>(</span><span>{</span> <span>text</span>: <span>'🍍'</span><span>,</span> scalar <span>}</span><span>)</span><span>;</span>

<span>confetti</span><span>(</span><span>{</span>
  <span>shapes</span>: <span>[</span><span>pineapple</span><span>]</span><span>,</span>
  scalar
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>confetti.create(canvas, [globalOptions])</code> → <code>function</code></h3><a id="user-content-confetticreatecanvas-globaloptions--function" aria-label="Permalink: confetti.create(canvas, [globalOptions]) → function" href="#confetticreatecanvas-globaloptions--function"></a></p>
<p dir="auto">This method creates an instance of the <code>confetti</code> function that uses a custom canvas. This is useful if you want to limit the area on your page in which confetti appear. By default, this method will not modify the canvas in any way (other than drawing to it).</p>
<p dir="auto"><em>Canvas can be misunderstood a bit though, so let me explain why you might want to let the module modify the canvas just a bit. By default, a <code>canvas</code> is a relatively small image -- somewhere around 300x150, depending on the browser. When you resize it using CSS, this sets the display size of the canvas, but not the image being represented on that canvas. Think of it as loading a 300x150 jpeg image in an <code>img</code> tag and then setting the CSS for that tag to <code>1500x600</code> -- your image will end up stretched and blurry. In the case of a canvas, you need to also set the width and height of the canvas image itself. If you don't want to do that, you can allow <code>confetti</code> to set it for you.</em></p>
<p dir="auto">Note also that you should persist the custom instance and avoid initializing an instance of confetti with the same canvas element more than once.</p>
<p dir="auto">The following global options are available:</p>
<ul dir="auto">
<li><code>resize</code> <em>Boolean (default: false)</em>: Whether to allow setting the canvas image size, as well as keep it correctly sized if the window changes size (e.g. resizing the window, rotating a mobile device, etc.). By default, the canvas size will not be modified.</li>
<li><code>useWorker</code> <em>Boolean (default: false)</em>: Whether to use an asynchronous web worker to render the confetti animation, whenever possible. This is turned off by default, meaning that the animation will always execute on the main thread. If turned on and the browser supports it, the animation will execute off of the main thread so that it is not blocking any other work your page needs to do. Using this option will also modify the canvas, but more on that directly below -- do read it. If it is not supported by the browser, this value will be ignored.</li>
<li><code>disableForReducedMotion</code> <em>Boolean (default: false)</em>: Disables confetti entirely for users that <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-reduced-motion" rel="nofollow">prefer reduced motion</a>. When set to true, use of this confetti instance will always respect a user's request for reduced motion and disable confetti for them.</li>
</ul>
<p dir="auto"><em><strong>Important: If you use <code>useWorker: true</code>, I own your canvas now. It's mine now and I can do whatever I want with it (don't worry... I'll just put confetti inside it, I promise). You must not try to use the canvas in any way (other than I guess removing it from the DOM), as it will throw an error. When using workers for rendering, control of the canvas must be transferred to the web worker, preventing any usage of that canvas on the main thread. If you must manipulate the canvas in any way, do not use this option.</strong></em></p>
<div dir="auto" data-snippet-clipboard-copy-content="var myCanvas = document.createElement('canvas');
document.body.appendChild(myCanvas);

var myConfetti = confetti.create(myCanvas, {
  resize: true,
  useWorker: true
});
myConfetti({
  particleCount: 100,
  spread: 160
  // any other options from the global
  // confetti function
});"><pre><span>var</span> <span>myCanvas</span> <span>=</span> <span>document</span><span>.</span><span>createElement</span><span>(</span><span>'canvas'</span><span>)</span><span>;</span>
<span>document</span><span>.</span><span>body</span><span>.</span><span>appendChild</span><span>(</span><span>myCanvas</span><span>)</span><span>;</span>

<span>var</span> <span>myConfetti</span> <span>=</span> <span>confetti</span><span>.</span><span>create</span><span>(</span><span>myCanvas</span><span>,</span> <span>{</span>
  <span>resize</span>: <span>true</span><span>,</span>
  <span>useWorker</span>: <span>true</span>
<span>}</span><span>)</span><span>;</span>
<span>myConfetti</span><span>(</span><span>{</span>
  <span>particleCount</span>: <span>100</span><span>,</span>
  <span>spread</span>: <span>160</span>
  <span>// any other options from the global</span>
  <span>// confetti function</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>confetti.reset()</code></h3><a id="user-content-confettireset" aria-label="Permalink: confetti.reset()" href="#confettireset"></a></p>
<p dir="auto">Stops the animation and clears all confetti, as well as immediately resolves any outstanding promises. In the case of a separate confetti instance created with <a href="#confetticreatecanvas-globaloptions--function"><code>confetti.create</code></a>, that instance will have its own <code>reset</code> method.</p>
<div dir="auto" data-snippet-clipboard-copy-content="confetti();

setTimeout(() => {
  confetti.reset();
}, 100);"><pre><span>confetti</span><span>(</span><span>)</span><span>;</span>

<span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>confetti</span><span>.</span><span>reset</span><span>(</span><span>)</span><span>;</span>
<span>}</span><span>,</span> <span>100</span><span>)</span><span>;</span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="var myCanvas = document.createElement('canvas');
document.body.appendChild(myCanvas);

var myConfetti = confetti.create(myCanvas, { resize: true });

myConfetti();

setTimeout(() => {
  myConfetti.reset();
}, 100);"><pre><span>var</span> <span>myCanvas</span> <span>=</span> <span>document</span><span>.</span><span>createElement</span><span>(</span><span>'canvas'</span><span>)</span><span>;</span>
<span>document</span><span>.</span><span>body</span><span>.</span><span>appendChild</span><span>(</span><span>myCanvas</span><span>)</span><span>;</span>

<span>var</span> <span>myConfetti</span> <span>=</span> <span>confetti</span><span>.</span><span>create</span><span>(</span><span>myCanvas</span><span>,</span> <span>{</span> <span>resize</span>: <span>true</span> <span>}</span><span>)</span><span>;</span>

<span>myConfetti</span><span>(</span><span>)</span><span>;</span>

<span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>myConfetti</span><span>.</span><span>reset</span><span>(</span><span>)</span><span>;</span>
<span>}</span><span>,</span> <span>100</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<p dir="auto">Launch some confetti the default way:</p>

<p dir="auto">Launch a bunch of confetti:</p>
<div dir="auto" data-snippet-clipboard-copy-content="confetti({
  particleCount: 150
});"><pre><span>confetti</span><span>(</span><span>{</span>
  <span>particleCount</span>: <span>150</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto">Launch some confetti really wide:</p>
<div dir="auto" data-snippet-clipboard-copy-content="confetti({
  spread: 180
});"><pre><span>confetti</span><span>(</span><span>{</span>
  <span>spread</span>: <span>180</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto">Get creative. Launch a small poof of confetti from a random part of the page:</p>
<div dir="auto" data-snippet-clipboard-copy-content="confetti({
  particleCount: 100,
  startVelocity: 30,
  spread: 360,
  origin: {
    x: Math.random(),
    // since they fall down, start a bit higher than random
    y: Math.random() - 0.2
  }
});"><pre><span>confetti</span><span>(</span><span>{</span>
  <span>particleCount</span>: <span>100</span><span>,</span>
  <span>startVelocity</span>: <span>30</span><span>,</span>
  <span>spread</span>: <span>360</span><span>,</span>
  <span>origin</span>: <span>{</span>
    <span>x</span>: <span>Math</span><span>.</span><span>random</span><span>(</span><span>)</span><span>,</span>
    <span>// since they fall down, start a bit higher than random</span>
    <span>y</span>: <span>Math</span><span>.</span><span>random</span><span>(</span><span>)</span> <span>-</span> <span>0.2</span>
  <span>}</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto">I said creative... we can do better. Since it doesn't matter how many times we call <code>confetti</code> (just the total number of confetti in the air), we can do some fun things, like continuously launch more and more confetti for 30 seconds, from multiple directions:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// do this for 30 seconds
var duration = 30 * 1000;
var end = Date.now() + duration;

(function frame() {
  // launch a few confetti from the left edge
  confetti({
    particleCount: 7,
    angle: 60,
    spread: 55,
    origin: { x: 0 }
  });
  // and launch a few from the right edge
  confetti({
    particleCount: 7,
    angle: 120,
    spread: 55,
    origin: { x: 1 }
  });

  // keep going until we are out of time
  if (Date.now() < end) {
    requestAnimationFrame(frame);
  }
}());"><pre><span>// do this for 30 seconds</span>
<span>var</span> <span>duration</span> <span>=</span> <span>30</span> <span>*</span> <span>1000</span><span>;</span>
<span>var</span> <span>end</span> <span>=</span> <span>Date</span><span>.</span><span>now</span><span>(</span><span>)</span> <span>+</span> <span>duration</span><span>;</span>

<span>(</span><span>function</span> <span>frame</span><span>(</span><span>)</span> <span>{</span>
  <span>// launch a few confetti from the left edge</span>
  <span>confetti</span><span>(</span><span>{</span>
    <span>particleCount</span>: <span>7</span><span>,</span>
    <span>angle</span>: <span>60</span><span>,</span>
    <span>spread</span>: <span>55</span><span>,</span>
    <span>origin</span>: <span>{</span> <span>x</span>: <span>0</span> <span>}</span>
  <span>}</span><span>)</span><span>;</span>
  <span>// and launch a few from the right edge</span>
  <span>confetti</span><span>(</span><span>{</span>
    <span>particleCount</span>: <span>7</span><span>,</span>
    <span>angle</span>: <span>120</span><span>,</span>
    <span>spread</span>: <span>55</span><span>,</span>
    <span>origin</span>: <span>{</span> <span>x</span>: <span>1</span> <span>}</span>
  <span>}</span><span>)</span><span>;</span>

  <span>// keep going until we are out of time</span>
  <span>if</span> <span>(</span><span>Date</span><span>.</span><span>now</span><span>(</span><span>)</span> <span>&lt;</span> <span>end</span><span>)</span> <span>{</span>
    <span>requestAnimationFrame</span><span>(</span><span>frame</span><span>)</span><span>;</span>
  <span>}</span>
<span>}</span><span>(</span><span>)</span><span>)</span><span>;</span></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TSMC unveils 1.6nm process technology with backside power delivery (251 pts)]]></title>
            <link>https://www.tomshardware.com/tech-industry/tsmc-unveils-16nm-process-technology-with-backside-power-delivery-rivals-intels-competing-design</link>
            <guid>40156275</guid>
            <pubDate>Thu, 25 Apr 2024 11:47:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/tech-industry/tsmc-unveils-16nm-process-technology-with-backside-power-delivery-rivals-intels-competing-design">https://www.tomshardware.com/tech-industry/tsmc-unveils-16nm-process-technology-with-backside-power-delivery-rivals-intels-competing-design</a>, See on <a href="https://news.ycombinator.com/item?id=40156275">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">

<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-1920-80.jpg.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-320-80.jpg" alt="TSMC fire at new plant" srcset="https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV.jpg"></picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: TSMC)</span>
</figcaption>
</div>

<div id="article-body">
<p>TSMC announced its leading-edge 1.6nm-class process technology today, a new A16 manufacturing process that will be the company's first Angstrom-class production node and promises to outperform its predecessor, N2P, by a significant margin. The technology's most important innovation will be its backside power delivery network (BSPDN).</p><p>Just like TSMC's 2nm-class nodes (N2, N2P, and N2X), the company's 1.6nm-class fabrication process will rely on gate-all-around (GAA) nanosheet transistors, but unlike the current and next-generation nodes, this one uses backside power delivery dubbed Super Power Rail. Transistor and BSPDN innovations enable tangible performance and efficiency improvements compared to TSMC's N2P: the new node promises an up to 10% higher clock rate at the same voltage and a 15% - 20% lower power consumption at the same frequency and complexity. In addition, the new technology could enable 7% - 10% higher transistor density, depending on the actual design.&nbsp;</p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-320-80.png.webp 320w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-970-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-1024-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-1200-80.png.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-320-80.png" alt="TSMC" srcset="https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-320-80.png 320w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-970-80.png 970w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-1024-80.png 1024w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-1200-80.png 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK.png"></picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: TSMC)</span></figcaption></figure><p>The most important innovation of TSMC's A16 process, which was unveiled at the company's <a data-analytics-id="inline-link" href="https://www.tsmc.com/static/english/campaign/Symposium2024/index.htm" data-url="https://www.tsmc.com/static/english/campaign/Symposium2024/index.htm" target="_blank" rel="sponsored noopener" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">North American Technology Symposium 2024</a>, is the introduction of the Super Power Rail (SPR), a sophisticated backside power delivery network (BSPDN). This technology is tailored specifically for AI and HPC processors that tend to have both complex signal wiring and dense power delivery networks.&nbsp;</p><p>Backside power delivery will be implemented into many upcoming process technologies as it allows for an increase in transistor density and improved power delivery, which affects performance. Meanwhile, there are several ways to implement a BSPDN. TSMC's Super Power Rail plugs the backside power delivery network to each transistor's source and drain using a special contract that also reduces resistance to get the maximum performance and power efficiency possible. From a production perspective, this is one of the most complex BSPDN implementations and is more complex than Intel's Power Via.&nbsp;</p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-320-80.png.webp 320w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-970-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-1024-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-1200-80.png.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-320-80.png" alt="TSMC" srcset="https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-320-80.png 320w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-970-80.png 970w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-1024-80.png 1024w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-1200-80.png 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L.png"></picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: TSMC)</span></figcaption></figure><p>The choice of backside power rail implementation is perhaps why TSMC decided not to add this feature to its N2P and N2X process technologies, as it would make using the production nodes considerably more expensive. Meanwhile, by offering a 1.6nm-class node with GAA nanosheet transistors and SPR as well as 2nm-class nodes with GAAFETs only, the company will now have two distinct nodes that will not compete with each other directly but offer distinctive advantages for different customers.&nbsp;</p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-320-80.png.webp 320w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-970-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-1024-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-1200-80.png.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-320-80.png" alt="TSMC" srcset="https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-320-80.png 320w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-970-80.png 970w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-1024-80.png 1024w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-1200-80.png 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK.png"></picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: TSMC)</span></figcaption></figure><p>The production timeline for A16 indicates that volume production of A16 will commence in the second half of 2026. Therefore, actual A16-made products will likely debut in 2027. This timeline positions A16 to potentially compete with Intel's 14A node, which will be the Intel's most advanced node at the time.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-Bhv28ghXS2smx6QV966UDU"><section><p>Join the experts who read Tom's Hardware for the inside track on enthusiast PC tech news — and have for over 25 years. We'll send breaking news and in-depth reviews of CPUs, GPUs, AI, maker hardware and more straight to your inbox.</p></section></div>
</div>
<div id="slice-container-authorBio-Bhv28ghXS2smx6QV966UDU"><p>Anton Shilov is a Freelance News Writer at Tom’s Hardware US. Over the past couple of decades, he has covered everything from CPUs and GPUs to supercomputers and from modern process technologies and latest fab tools to high-tech industry trends.</p></div>



<!-- Drop in a standard article here maybe? -->


</section>





<div id="slice-container-relatedArticles"><p><h5>Most Popular</h5></p></div>








</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How NASA Repaired Voyager 1 from 15B Miles Away (140 pts)]]></title>
            <link>https://arstechnica.com/space/2024/04/recoding-voyager-1-nasas-interstellar-explorer-is-finally-making-sense-again/</link>
            <guid>40155293</guid>
            <pubDate>Thu, 25 Apr 2024 09:28:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/space/2024/04/recoding-voyager-1-nasas-interstellar-explorer-is-finally-making-sense-again/">https://arstechnica.com/space/2024/04/recoding-voyager-1-nasas-interstellar-explorer-is-finally-making-sense-again/</a>, See on <a href="https://news.ycombinator.com/item?id=40155293">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
  




<!-- cache miss 366:single/related:7b642dbe541c5baf60cd5beb87e2ab40 --><!-- empty -->
<p>Engineers have partially restored a 1970s-era computer on NASA's Voyager 1 spacecraft after five months of long-distance troubleshooting, building confidence that humanity's first interstellar probe can eventually resume normal operations.</p>
<p>Several dozen scientists and engineers gathered Saturday in a conference room at NASA's Jet Propulsion Laboratory, or connected virtually, to wait for a new signal from Voyager 1. The ground team sent a command up to Voyager 1 on Thursday to recode part of the memory of the <a href="https://arstechnica.com/space/2024/02/humanitys-most-distant-space-probe-jeopardized-by-computer-glitch/">spacecraft's Flight Data Subsystem (FDS)</a>, one of the probe's three computers.</p>
<p>“In the minutes leading up to when we were going to see a signal, you could have heard a pin drop in the room," said Linda Spilker, project scientist for NASA's two Voyager spacecraft at JPL. "It was quiet. People were looking very serious. They were looking at their computer screens. Each of the subsystem (engineers) had pages up that they were looking at, to watch as they would be populated."</p>
<h2>Finally, a breakthrough</h2>
<p>Launched nearly 47 years ago, Voyager 1 is flying on an outbound trajectory more than 15 billion miles (24 billion kilometers) from Earth, and it takes 22-and-a-half hours for a radio signal to cover that distance at the speed of light. This means it takes nearly two days for engineers to uplink a command to Voyager 1 and get a response.</p>
<p>In November, Voyager 1 suddenly stopped transmitting its usual stream of data containing information about the spacecraft's health and measurements from its scientific instruments. Instead, the spacecraft's data stream was entirely unintelligible. Because the telemetry was unreadable, experts on the ground could not easily tell what went wrong. They hypothesized the source of the problem might be in the memory bank of the FDS.</p>
<p>There was a breakthrough last month when engineers sent up a novel command to "poke" Voyager 1's FDS to send back a readout of its memory. This readout allowed engineers to <a href="https://arstechnica.com/space/2024/04/the-diagnosis-is-in-bad-memory-knocked-nasas-aging-voyager-1-offline/">pinpoint the location of the problem in the FDS memory</a>. The FDS is responsible for packaging engineering and scientific data for transmission to Earth.</p>
<p>After a few weeks, NASA was ready to uplink a solution to get the FDS to resume packing engineering data. This data stream includes information on the status of the spacecraft—things like power levels and temperature measurements. This command went up to Voyager 1 through one of NASA's large Deep Space Network antennas Thursday.</p>                                            
                                                        
<p>Then, the wait for a response. Spilker, who started working on Voyager right out of college in 1977, was in the room when Voyager 1's signal reached Earth Saturday.</p>
<p>"When the time came to get the signal, we could clearly see all of a sudden, boom, we had data, and there were tears and smiles and high fives," she told Ars. "Everyone was very happy and very excited to see that, hey, we're back in communication again with Voyager 1. We're going to see the status of the spacecraft, the health of the spacecraft, for the first time in five months."</p>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/04/voyager1team.jpg" data-height="1125" data-width="1500" alt="Voyager 1's team celebrates the arrival of a radio signal from the spacecraft Saturday."><img alt="Voyager 1's team celebrates the arrival of a radio signal from the spacecraft Saturday." src="https://cdn.arstechnica.net/wp-content/uploads/2024/04/voyager1team-640x480.jpg" width="640" height="480" srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/04/voyager1team-1280x960.jpg 2x"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/04/voyager1team.jpg" data-height="1125" data-width="1500">Enlarge</a> <span>/</span> Voyager 1's team celebrates the arrival of a radio signal from the spacecraft Saturday.</p></figcaption></figure>
<p>Throughout the five months of troubleshooting, Voyager's ground team continued to receive signals indicating the spacecraft was still alive. But until Saturday, they lacked insight into specific details about the status of Voyager 1.</p>
<p>“It’s pretty much just the way we left it," Spilker said. "We're still in the initial phases of analyzing all of the channels and looking at their trends. Some of the temperatures went down a little bit with this period of time that's gone on, but we're pretty much seeing everything we had hoped for. And that's always good news.”</p>
<h2>Relocating code</h2>
<p>Through their investigation, Voyager's ground team discovered a single chip responsible for storing a portion of the FDS memory stopped working, probably due to either a cosmic ray hit or a failure of aging hardware. This affected some of the computer's software code.</p>
<p>"That took out a section of memory," Spilker said. "What they have to do is relocate that code into a different portion of the memory, and then make sure that anything that uses those codes, those subroutines, know to go to the new location of memory, for access and to run it."</p>
<p>Only about 3 percent of the FDS memory was corrupted by the bad chip, so engineers needed to transplant that code into another part of the memory bank. But no single location is large enough to hold the section of code in its entirety, NASA said.</p>
<p>So the Voyager team divided the code into sections for storage in different places in the FDS. This wasn't just a copy-and-paste job. Engineers needed to modify some of the code to make sure it will all work together. "Any references to the location of that code in other parts of the FDS memory needed to be updated as well," NASA said in a statement.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Boeing retaliated against its own engineers working for FAA, union says (120 pts)]]></title>
            <link>https://www.seattletimes.com/business/boeing-aerospace/boeing-retaliated-against-its-own-engineers-working-for-faa-union-says/</link>
            <guid>40155240</guid>
            <pubDate>Thu, 25 Apr 2024 09:20:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.seattletimes.com/business/boeing-aerospace/boeing-retaliated-against-its-own-engineers-working-for-faa-union-says/">https://www.seattletimes.com/business/boeing-aerospace/boeing-retaliated-against-its-own-engineers-working-for-faa-union-says/</a>, See on <a href="https://news.ycombinator.com/item?id=40155240">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-content">
    <p>Boeing’s white-collar union alleged Tuesday that company management retaliated against engineers overseeing design work on behalf of the Federal Aviation Administration, heightening concerns about a self-regulation regime that’s come under renewed fire since Jan. 5, when a fuselage panel blew out midair.</p><p>In 2022, as Boeing worked to integrate new avionics packages into its 777 and 787 widebody aircraft,  two of its engineers insisted the company needed to reevaluate prior engineering work completed on the two aircraft. The engineering union contends Boeing managers objected to this on the grounds that it would add costs and slow production.</p><p>After the FAA backed the engineers about how the work should be performed and the dispute was settled, in mid-2023 Boeing gave both men negative performance reviews, which cuts pay raises and promotion prospects.</p><p>The two “did the right thing and stuck to their guns despite heavy pressure from Boeing, and then got hit with career-damaging performance reviews,” said Rich Plunkett, the union’s director of strategic development. “This helps show why Boeing doesn’t have a healthy safety culture.”</p><p>The union said one of the engineers quit Boeing over the way he was treated; it’s appealing the performance downgrade to management on behalf of the other.</p><p>Boeing denies the charge of retaliation. </p><p>“After an extensive review of documentation and interviewing more than a dozen witnesses, our investigators found no evidence of retaliation or interference,” spokesperson Bobbie Egan said Tuesday. “We have determined the allegations are unsubstantiated.” </p>
<p>“We have zero tolerance for retaliation and encourage our employees to speak up when they see an issue,” Egan said.</p><p>If proven, the union allegations would undercut Boeing’s recent insistence that it prioritizes safety over cost and schedule considerations and maintains an open culture that protects employees who flag safety issues.</p><p>The&nbsp;union, the Society of Professional Engineering Employees in Aerospace, SPEEA, has filed a complaint with the National Labor Relations Board demanding access to the report of the internal Boeing investigation that concluded the negative reviews did not amount to interfering in the oversight work of the two engineers.</p><p>Boeing said it is “looking into the union’s requests” but added that investigations into interference claims are typically confidential.</p><p>“Providing the report to any party outside the FAA would be a departure from our standard practice, ” Boeing said.</p>
<h2>Eyes of the FAA</h2><p>More than 1,000 engineers inside Boeing are authorized to act as the FAA’s eyes in overseeing work. They are legally required to have “a commitment to safety above all other priorities” and so must be independent and free of interference from management concerns about added cost and schedule delays.</p><p>But after the two deadly 737 MAX crashes five years ago, some of these engineers alleged management during the MAX’s development had <a href="https://www.seattletimes.com/business/boeing-aerospace/engineers-say-boeing-pushed-to-limit-safety-testing-in-race-to-certify-planes-including-737-max/">interfered to limit safety testing</a>. </p><p>That coupled with the failure of this internal oversight organization to flag the obvious flaws in <a href="https://www.seattletimes.com/seattle-news/times-watchdog/the-inside-story-of-mcas-how-boeings-737-max-system-gained-power-and-lost-safeguards/">the new flight control software that led to the crashes</a> raised serious doubts about Boeing’s ability to certify its own work.</p><p>Congress subsequently began to reverse the yearslong trend of delegating more of the FAA’s safety oversight to Boeing itself. </p><p>After a chain of quality lapses last year and then the fuselage panel blowout on an Alaska Airlines 737 MAX in January, Boeing leadership said it would revamp its safety reporting systems and has repeatedly insisted that all employees can raise safety concerns without fear of retaliation.</p><p>In February, the report of an FAA-appointed panel of independent aviation experts flagged concerns that the employees who represent the FAA fear raising safety issues because Boeing’s internal safety reporting systems fails to ensure “open communication and non-retaliation.”</p>
<p>The findings of that report were <a href="https://www.seattletimes.com/business/boeing-workers-still-scared-to-raise-safety-concerns-says-faa-appointed-experts/">highlighted just last week in a hearing before the U.S. Senate Committee</a> on Commerce, Science and Transportation. One finding was that some employees did not receive a raise they had been expecting after bringing up safety concerns.&nbsp;</p><p>After that hearing, Boeing said retaliation is strictly prohibited.&nbsp;</p><p>“Boeing can tell Congress and the media all it wants about how ‘retaliation is strictly prohibited,’” said Plunkett. “But our union is fighting retaliation cases on a regular basis.”</p><h2>Following FAA guidelines</h2><p>The job of the Boeing engineers authorized to work on behalf of the FAA is to check on the work of company engineers as they develop designs and instruct them what must be accomplished to get those designs approved as compliant with regulations.</p>      <p>The union said when overseeing the 777 and 787 avionics integration in 2022, the two engineers insisted the company reevaluate prior engineering calculations, citing an FAA advisory document updated in 2013 that provided guidelines on how to obtain airworthiness approval&nbsp;for such work.</p><p>An FAA advisory typically outlines a standard way of achieving compliance. It’s not mandatory and does not constitute a regulation.</p><p>According to the union, Boeing managers “strongly objected” to the conclusion that the prior work should be redone, “saying that going back to run calculations using the new assumptions would cost money and cause production delays.”</p>
<p>Eventually, after six months of back and forth, the FAA backed the two engineers and Boeing had to redo the analysis. </p><p>Subsequently, however, “when they came up for their next performance reviews, the two engineers received identical negative evaluations,” the union said.</p><p>SPEEA said that when its staff met with Boeing officials on the matter, “the manager of the two engineers admitted that he had rated them both poorly at the request of the 777 and 787 managers who had been forced to resubmit their work.”</p><p>Still, Boeing refused to change the performance evaluations. </p><p>While one of the engineers chose to leave Boeing, the other filed a complaint in the company’s “Speak Up” reporting system alleging retaliation. </p><p>In a meeting with the engineer, accompanied by a SPEEA official, Boeing labor relations personnel told him that his complaint “did not meet the legal threshold of interference, nor the legal definition of retaliation, and as a result, they were closing his case,” the union said.</p>
<p>Because that internal complaint implied interference with an FAA designee, Boeing had to file a report on the incident with the safety agency. As it appeals the performance downgrade, the union now seeks access to that report.</p><p>In 2022, responding to Congress, the FAA introduced new policies to prevent “undue pressure” on the engineers working on its behalf at aviation manufacturers.</p><p>The new regulations require Boeing to monitor for, report and investigate all allegations of interference and to report the results to the FAA. The agency now has the SPEEA charges.</p><p>“The FAA is investigating these allegations,” spokesperson Ian Gregor said Tuesday. </p>    
        <div>
   <p><span>
         Dominic Gates:      </span>
       <span>206-464-2963</span> or <span><a href="mailto:dgates@seattletimes.com">dgates@seattletimes.com</a>;</span>      <span>Dominic Gates is a Pulitzer Prize-winning aerospace journalist for The Seattle Times.</span>   </p>
</div>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tiny GPU: A minimal GPU implementation in Verilog (217 pts)]]></title>
            <link>https://github.com/adam-maj/tiny-gpu</link>
            <guid>40153815</guid>
            <pubDate>Thu, 25 Apr 2024 05:36:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/adam-maj/tiny-gpu">https://github.com/adam-maj/tiny-gpu</a>, See on <a href="https://news.ycombinator.com/item?id=40153815">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">tiny-gpu</h2><a id="user-content-tiny-gpu" aria-label="Permalink: tiny-gpu" href="#tiny-gpu"></a></p>
<p dir="auto">A minimal GPU implementation in Verilog optimized for learning about how GPUs work from the ground up.</p>
<p dir="auto">Built with &lt;15 files of fully documented Verilog, complete documentation on architecture &amp; ISA, working matrix addition/multiplication kernels, and full support for kernel simulation &amp; execution traces.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Table of Contents</h3><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#overview">Overview</a></li>
<li><a href="#architecture">Architecture</a>
<ul dir="auto">
<li><a href="#gpu">GPU</a></li>
<li><a href="#memory">Memory</a></li>
<li><a href="#core">Core</a></li>
</ul>
</li>
<li><a href="#isa">ISA</a></li>
<li><a href="#execution">Execution</a>
<ul dir="auto">
<li><a href="#core-1">Core</a></li>
<li><a href="#thread">Thread</a></li>
</ul>
</li>
<li><a href="#kernels">Kernels</a>
<ul dir="auto">
<li><a href="#matrix-addition">Matrix Addition</a></li>
<li><a href="https://github.com/adam-maj/tiny-gpu/blob/master/tree/master?tab=readme-ov-file#matrix-multiplication">Matrix Multiplication</a></li>
</ul>
</li>
<li><a href="#simulation">Simulation</a></li>
<li><a href="#advanced-functionality">Advanced Functionality</a></li>
<li><a href="#next-steps">Next Steps</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Overview</h2><a id="user-content-overview" aria-label="Permalink: Overview" href="#overview"></a></p>
<p dir="auto">If you want to learn how a CPU works all the way from architecture to control signals, there are many resources online to help you.</p>
<p dir="auto">GPUs are not the same.</p>
<p dir="auto">Because the GPU market is so competitive, low-level technical details for all modern architectures remain proprietary.</p>
<p dir="auto">While there are lots of resources to learn about GPU programming, there's almost nothing available to learn about how GPU's work at a hardware level.</p>
<p dir="auto">The best option is to go through open-source GPU implementations like <a href="https://github.com/VerticalResearchGroup/miaow">Miaow</a> and <a href="https://github.com/hughperkins/VeriGPU/tree/main">VeriGPU</a> and try to figure out what's going on. This is challenging since these projects aim at being feature complete and functional, so they're quite complex.</p>
<p dir="auto">This is why I built <code>tiny-gpu</code>!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is tiny-gpu?</h2><a id="user-content-what-is-tiny-gpu" aria-label="Permalink: What is tiny-gpu?" href="#what-is-tiny-gpu"></a></p>
<div dir="auto"><p dir="auto">Important</p>
<p dir="auto"><strong>tiny-gpu</strong> is a minimal GPU implementation optimized for learning about how GPUs work from the ground up.</p>
<p dir="auto">Specifically, with the trend toward general-purpose GPUs (GPGPUs) and ML-accelerators like Google's TPU, tiny-gpu focuses on highlighting the general principles of all of these architectures, rather than on the details of graphics-specific hardware.</p>
</div>
<p dir="auto">With this motivation in mind, we can simplify GPUs by cutting out the majority of complexity involved with building a production-grade graphics card, and focus on the core elements that are critical to all of these modern hardwareaccelerators.</p>
<p dir="auto">This project is primarily focused on exploring:</p>
<ol dir="auto">
<li><strong>Architecture</strong> - What does the architecture of a GPU look like? What are the most important elements?</li>
<li><strong>Parallelization</strong> - How is the SIMD progamming model implemented in hardware?</li>
<li><strong>Memory</strong> - How does a GPU work around the constraints of limited memory bandwidth?</li>
</ol>
<p dir="auto">After understanding the fundamentals laid out in this project, you can checkout the <a href="#advanced-functionality">advanced functionality section</a> to understand some of the most important optimizations made in production grade GPUs (that are more challenging to implement) which improve performance.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Architecture</h2><a id="user-content-architecture" aria-label="Permalink: Architecture" href="#architecture"></a></p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/adam-maj/tiny-gpu/blob/master/docs/images/gpu.png"><img src="https://github.com/adam-maj/tiny-gpu/raw/master/docs/images/gpu.png" alt="GPU" width="48%"></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/adam-maj/tiny-gpu/blob/master/docs/images/core.png"><img src="https://github.com/adam-maj/tiny-gpu/raw/master/docs/images/core.png" alt="Core" width="48%"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">GPU</h2><a id="user-content-gpu" aria-label="Permalink: GPU" href="#gpu"></a></p>
<p dir="auto">tiny-gpu is built to execute a single kernel at a time.</p>
<p dir="auto">In order to launch a kernel, we need to do the following:</p>
<ol dir="auto">
<li>Load global program memory with the kernel code</li>
<li>Load data memory with the necessary data</li>
<li>Specify the number of threads to launch in the device control register</li>
<li>Launch the kernel by setting the start signal to high.</li>
</ol>
<p dir="auto">The GPU itself consists of the following units:</p>
<ol dir="auto">
<li>Device control register</li>
<li>Dispatcher</li>
<li>Variable number of compute cores</li>
<li>Memory controllers for data memory &amp; program memory</li>
<li>Cache</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Device Control Register</h3><a id="user-content-device-control-register" aria-label="Permalink: Device Control Register" href="#device-control-register"></a></p>
<p dir="auto">The device control register usually stores metadata specifying how kernels should be executed on the GPU.</p>
<p dir="auto">In this case, the device control register just stores the <code>thread_count</code> - the total number of threads to launch for the active kernel.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Dispatcher</h3><a id="user-content-dispatcher" aria-label="Permalink: Dispatcher" href="#dispatcher"></a></p>
<p dir="auto">Once a kernel is launched, the dispatcher is the unit that actually manages the distribution of threads to different compute cores.</p>
<p dir="auto">The dispatcher organizes threads into groups that can be executed in parallel on a single core called <strong>blocks</strong> and sends these blocks off to be processed by available cores.</p>
<p dir="auto">Once all blocks have been processed, the dispatcher reports back that the kernel execution is done.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Memory</h2><a id="user-content-memory" aria-label="Permalink: Memory" href="#memory"></a></p>
<p dir="auto">The GPU is built to interface with an external global memory. Here, data memory and program memory are separated out for simplicity.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Global Memory</h3><a id="user-content-global-memory" aria-label="Permalink: Global Memory" href="#global-memory"></a></p>
<p dir="auto">tiny-gpu data memory has the following specifications:</p>
<ul dir="auto">
<li>8 bit addressability (256 total rows of data memory)</li>
<li>8 bit data (stores values of &lt;256 for each row)</li>
</ul>
<p dir="auto">tiny-gpu program memory has the following specifications:</p>
<ul dir="auto">
<li>8 bit addressability (256 rows of program memory)</li>
<li>16 bit data (each instruction is 16 bits as specified by the ISA)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Memory Controllers</h3><a id="user-content-memory-controllers" aria-label="Permalink: Memory Controllers" href="#memory-controllers"></a></p>
<p dir="auto">Global memory has fixed read/write bandwidth, but there may be far more incoming requests across all cores to access data from memory than the external memory is actually able to handle.</p>
<p dir="auto">The memory controllers keep track of all the outgoing requests to memory from the compute cores, throttle requests based on actual external memory bandwidth, and relay responses from external memory back to the proper resources.</p>
<p dir="auto">Each memory controller has a fixed number of channels based on the bandwidth of global memory.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Cache (WIP)</h3><a id="user-content-cache-wip" aria-label="Permalink: Cache (WIP)" href="#cache-wip"></a></p>
<p dir="auto">The same data is often requested from global memory by multiple cores. Constantly access global memory repeatedly is expensive, and since the data has already been fetched once, it would be more efficient to store it on device in SRAM to be retrieved much quicker on later requests.</p>
<p dir="auto">This is exactly what the cache is used for. Data retrieved from external memory is stored in cache and can be retrieved from there on later requests, freeing up memory bandwidth to be used for new data.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Core</h2><a id="user-content-core" aria-label="Permalink: Core" href="#core"></a></p>
<p dir="auto">Each core has a number of compute resources, often built around a certain number of threads it can support. In order to maximize parallelization, these resources need to be managed optimally to maximize resource utilization.</p>
<p dir="auto">In this simplified GPU, each core processed one <strong>block</strong> at a time, and for each thread in a block, the core has a dedicated ALU, LSU, PC, and register file. Managing the execution of thread instructions on these resources is one of the most challening problems in GPUs.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Scheduler</h3><a id="user-content-scheduler" aria-label="Permalink: Scheduler" href="#scheduler"></a></p>
<p dir="auto">Each core has a single scheduler that manages the execution of threads.</p>
<p dir="auto">The tiny-gpu scheduler executes instructions for a single block to completion before picking up a new block, and it executes instructions for all threads in-sync and sequentially.</p>
<p dir="auto">In more advanced schedulers, techniques like <strong>pipelining</strong> are used to stream the execution of multiple instructions subsequent instructions to maximize resource utilization before previous instructions are fully complete. Additionally, <strong>warp scheduling</strong> can be use to execute multiple batches of threads within a block in parallel.</p>
<p dir="auto">The main constraint the scheduler has to work around is the latency associated with loading &amp; storing data from global memory. While most instructions can be executed synchronously, these load-store operations are asynchronous, meaning the rest of the instruction execution has to be built around these long wait times.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Fetcher</h3><a id="user-content-fetcher" aria-label="Permalink: Fetcher" href="#fetcher"></a></p>
<p dir="auto">Asynchronously fetches the instruction at the current program counter from program memory (most should actually be fetching from cache after a single block is executed).</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Decoder</h3><a id="user-content-decoder" aria-label="Permalink: Decoder" href="#decoder"></a></p>
<p dir="auto">Decodes the fetched instruction into control signals for thread execution.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Register Files</h3><a id="user-content-register-files" aria-label="Permalink: Register Files" href="#register-files"></a></p>
<p dir="auto">Each thread has it's own dedicated set of register files. The register files hold the data that each thread is performing computations on, which enables the same-instruction multiple-data (SIMD) pattern.</p>
<p dir="auto">Importantly, each register file contains a few read-only registers holding data about the current block &amp; thread being executed locally, enabling kernels to be executed with different data based on the local thread id.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">ALUs</h3><a id="user-content-alus" aria-label="Permalink: ALUs" href="#alus"></a></p>
<p dir="auto">Dedicated arithmetic-logic unit for each thread to perform computations. Handles the <code>ADD</code>, <code>SUB</code>, <code>MUL</code>, <code>DIV</code> arithmetic instructions.</p>
<p dir="auto">Also handles the <code>CMP</code> comparison instruction which actually outputs whether the result of the difference between two registers is negative, zero or positive - and stores the result in the <code>NZP</code> register in the PC unit.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">LSUs</h3><a id="user-content-lsus" aria-label="Permalink: LSUs" href="#lsus"></a></p>
<p dir="auto">Dedicated load-store unit for each thread to access global data memory.</p>
<p dir="auto">Handles the <code>LDR</code> &amp; <code>STR</code> instructions - and handles async wait times for memory requests to be processed and relayed by the memory controller.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">PCs</h3><a id="user-content-pcs" aria-label="Permalink: PCs" href="#pcs"></a></p>
<p dir="auto">Dedicated program-counter for each unit to determine the next instructions to execute on each thread.</p>
<p dir="auto">By default, the PC increments by 1 after every instruction.</p>
<p dir="auto">With the <code>BRnzp</code> instruction, the NZP register checks to see if the NZP register (set by a previous <code>CMP</code> instruction) matches some case - and if it does, it will branch to a specific line of program memory. <em>This is how loops and conditionals are implemented.</em></p>
<p dir="auto">Since threads are processed in parallel, tiny-gpu assumes that all threads "converge" to the same program counter after each instruction - which is a naive assumption for the sake of simplicity.</p>
<p dir="auto">In real GPUs, individual threads can branch to different PCs, causing <strong>branch divergence</strong> where a group of threads threads initially being processed together has to split out into separate execution.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">ISA</h2><a id="user-content-isa" aria-label="Permalink: ISA" href="#isa"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/adam-maj/tiny-gpu/blob/master/docs/images/isa.png"><img src="https://github.com/adam-maj/tiny-gpu/raw/master/docs/images/isa.png" alt="ISA"></a></p>
<p dir="auto">tiny-gpu implements a simple 11 instruction ISA built to enable simple kernels for proof-of-concept like matrix addition &amp; matrix multiplication (implementation further down on this page).</p>
<p dir="auto">For these purposes, it supports the following instructions:</p>
<ul dir="auto">
<li><code>BRnzp</code> - Branch instruction to jump to another line of program memory if the NZP register matches the <code>nzp</code> condition in the instruction.</li>
<li><code>CMP</code> - Compare the value of two registers and store the result in the NZP register to use for a later <code>BRnzp</code> instruction.</li>
<li><code>ADD</code>, <code>SUB</code>, <code>MUL</code>, <code>DIV</code> - Basic arithmetic operations to enable tensor math.</li>
<li><code>LDR</code> - Load data from global memory.</li>
<li><code>STR</code> - Store data into global memory.</li>
<li><code>CONST</code> - Load a constant value into a register.</li>
<li><code>RET</code> - Signal that the current thread has reached the end of execution.</li>
</ul>
<p dir="auto">Each register is specified by 4 bits, meaning that there are 16 total registers. The first 13 register <code>R0</code> - <code>R12</code> are free registers that support read/write. The last 3 registers are special read-only registers used to supply the <code>%blockIdx</code>, <code>%blockDim</code>, and <code>%threadIdx</code> critical to SIMD.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Execution</h2><a id="user-content-execution" aria-label="Permalink: Execution" href="#execution"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Core</h3><a id="user-content-core-1" aria-label="Permalink: Core" href="#core-1"></a></p>
<p dir="auto">Each core follows the following control flow going through different stages to execute each instruction:</p>
<ol dir="auto">
<li><code>FETCH</code> - Fetch the next instruction at current program counter from program memory.</li>
<li><code>DECODE</code> - Decode the instruction into control signals.</li>
<li><code>REQUEST</code> - Request data from global memory if necessary (if <code>LDR</code> or <code>STR</code> instruction).</li>
<li><code>WAIT</code> - Wait for data from global memory if applicable.</li>
<li><code>EXECUTE</code> - Execute any computations on data.</li>
<li><code>UPDATE</code> - Update register files and NZP register.</li>
</ol>
<p dir="auto">The control flow is laid out like this for the sake of simplicity and understandability.</p>
<p dir="auto">In practice, several of these steps could be compressed to be optimize processing times, and the GPU could also use <strong>pipelining</strong> to stream and coordinate the execution of many instructions on a cores resources without waiting for previous instructions to finish.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Thread</h3><a id="user-content-thread" aria-label="Permalink: Thread" href="#thread"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/adam-maj/tiny-gpu/blob/master/docs/images/thread.png"><img src="https://github.com/adam-maj/tiny-gpu/raw/master/docs/images/thread.png" alt="Thread"></a></p>
<p dir="auto">Each thread within each core follows the above execution path to perform computations on the data in it's dedicated register file.</p>
<p dir="auto">This resembles a standard CPU diagram, and is quite similar in functionality as well. The main difference is that the <code>%blockIdx</code>, <code>%blockDim</code>, and <code>%threadIdx</code> values lie in the read-only registers for each thread, enabling SIMD functionality.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Kernels</h2><a id="user-content-kernels" aria-label="Permalink: Kernels" href="#kernels"></a></p>
<p dir="auto">I wrote a matrix addition and matrix multiplication kernel using my ISA as a proof of concept to demonstrate SIMD programming and execution with my GPU. The test files in this repository are capable of fully simulating the execution of these kernels on the GPU, producing data memory states and a complete execution trace.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Matrix Addition</h3><a id="user-content-matrix-addition" aria-label="Permalink: Matrix Addition" href="#matrix-addition"></a></p>
<p dir="auto">This matrix addition kernel adds two 1 x 8 matrices by performing 8 element wise additions in separate threads.</p>
<p dir="auto">This demonstration makes use of the <code>%blockIdx</code>, <code>%blockDim</code>, and <code>%threadIdx</code> registers to show SIMD programming on this GPU. It also uses the <code>LDR</code> and <code>STR</code> instructions which require async memory management.</p>
<p dir="auto"><code>matadd.asm</code></p>
<div dir="auto" data-snippet-clipboard-copy-content=".threads 8
.data 0 1 2 3 4 5 6 7          ; matrix A (1 x 8)
.data 0 1 2 3 4 5 6 7          ; matrix B (1 x 8)

MUL R0, %blockIdx, %blockDim
ADD R0, R0, %threadIdx         ; i = blockIdx * blockDim + threadIdx

CONST R1, #0                   ; baseA (matrix A base address)
CONST R2, #8                   ; baseB (matrix B base address)
CONST R3, #16                  ; baseC (matrix C base address)

ADD R4, R1, R0                 ; addr(A[i]) = baseA + i
LDR R4, R4                     ; load A[i] from global memory

ADD R5, R2, R0                 ; addr(B[i]) = baseB + i
LDR R5, R5                     ; load B[i] from global memory

ADD R6, R4, R5                 ; C[i] = A[i] + B[i]

ADD R7, R3, R0                 ; addr(C[i]) = baseC + i
STR R7, R6                     ; store C[i] in global memory

RET                            ; end of kernel"><pre><span>.threads </span><span>8</span>
<span>.data </span><span>0</span><span> </span><span>1</span><span> </span><span>2</span><span> </span><span>3</span><span> </span><span>4</span><span> </span><span>5</span><span> </span><span>6</span><span> </span><span>7</span><span>          ; matrix A (1 x 8)</span>
<span>.data </span><span>0</span><span> </span><span>1</span><span> </span><span>2</span><span> </span><span>3</span><span> </span><span>4</span><span> </span><span>5</span><span> </span><span>6</span><span> </span><span>7</span><span>          ; matrix B (1 x 8)</span>

<span>MUL</span><span> R0</span><span>,</span><span> %blockIdx</span><span>,</span><span> %blockDim</span>
<span>ADD</span><span> R0</span><span>,</span><span> R0</span><span>,</span><span> %threadIdx</span><span>         ; i = blockIdx * blockDim + threadIdx</span>

<span>CONST R1</span><span>,</span><span> #</span><span>0</span><span>                   ; baseA (matrix A base address)</span>
<span>CONST R2</span><span>,</span><span> #</span><span>8</span><span>                   ; baseB (matrix B base address)</span>
<span>CONST R3</span><span>,</span><span> #</span><span>16</span><span>                  ; baseC (matrix C base address)</span>

<span>ADD</span><span> R4</span><span>,</span><span> R1</span><span>,</span><span> R0</span><span>                 ; addr(A[i]) = baseA + i</span>
<span>LDR R4</span><span>,</span><span> R4</span><span>                     ; load A[i] from global memory</span>

<span>ADD</span><span> R5</span><span>,</span><span> R2</span><span>,</span><span> R0</span><span>                 ; addr(B[i]) = baseB + i</span>
<span>LDR R5</span><span>,</span><span> R5</span><span>                     ; load B[i] from global memory</span>

<span>ADD</span><span> R6</span><span>,</span><span> R4</span><span>,</span><span> R5</span><span>                 ; C[i] = A[i] + B[i]</span>

<span>ADD</span><span> R7</span><span>,</span><span> R3</span><span>,</span><span> R0</span><span>                 ; addr(C[i]) = baseC + i</span>
<span>STR</span><span> R7</span><span>,</span><span> R6</span><span>                     ; store C[i] in global memory</span>

<span>RET</span><span>                            ; end of kernel</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Matrix Multiplication</h3><a id="user-content-matrix-multiplication" aria-label="Permalink: Matrix Multiplication" href="#matrix-multiplication"></a></p>
<p dir="auto">The matrix multiplication kernel multiplies two 2x2 matrices. It performs element wise calculation of the dot product of the relevant row and column and uses the <code>CMP</code> and <code>BRnzp</code> instructions to demonstrate branching within the threads (notably, all branches converge so this kernel works on the current tiny-gpu implementation).</p>
<p dir="auto"><code>matmul.asm</code></p>
<div dir="auto" data-snippet-clipboard-copy-content=".threads 4
.data 1 2 3 4                  ; matrix A (2 x 2)
.data 1 2 3 4                  ; matrix B (2 x 2)

MUL R0, %blockIdx, %blockDim
ADD R0, R0, %threadIdx         ; i = blockIdx * blockDim + threadIdx

CONST R1, #1                   ; increment
CONST R2, #2                   ; N (matrix inner dimension)
CONST R3, #0                   ; baseA (matrix A base address)
CONST R4, #4                   ; baseB (matrix B base address)
CONST R5, #8                   ; baseC (matrix C base address)

DIV R6, R0, R2                 ; row = i // N
MUL R7, R6, R2
SUB R7, R0, R7                 ; col = i % N

CONST R8, #0                   ; acc = 0
CONST R9, #0                   ; k = 0

LOOP:
  MUL R10, R6, R2
  ADD R10, R10, R9
  ADD R10, R10, R3             ; addr(A[i]) = row * N + k + baseA
  LDR R10, R10                 ; load A[i] from global memory

  MUL R11, R9, R2
  ADD R11, R11, R7
  ADD R11, R11, R4             ; addr(B[i]) = k * N + col + baseB
  LDR R11, R11                 ; load B[i] from global memory

  MUL R12, R10, R11
  ADD R8, R8, R12              ; acc = acc + A[i] * B[i]

  ADD R9, R9, R1               ; increment k

  CMP R9, R2
  BRn LOOP                    ; loop while k < N

ADD R9, R5, R0                 ; addr(C[i]) = baseC + i
STR R9, R8                     ; store C[i] in global memory

RET                            ; end of kernel"><pre><span>.threads </span><span>4</span>
<span>.data </span><span>1</span><span> </span><span>2</span><span> </span><span>3</span><span> </span><span>4</span><span>                  ; matrix A (2 x 2)</span>
<span>.data </span><span>1</span><span> </span><span>2</span><span> </span><span>3</span><span> </span><span>4</span><span>                  ; matrix B (2 x 2)</span>

<span>MUL</span><span> R0</span><span>,</span><span> %blockIdx</span><span>,</span><span> %blockDim</span>
<span>ADD</span><span> R0</span><span>,</span><span> R0</span><span>,</span><span> %threadIdx</span><span>         ; i = blockIdx * blockDim + threadIdx</span>

<span>CONST R1</span><span>,</span><span> #</span><span>1</span><span>                   ; increment</span>
<span>CONST R2</span><span>,</span><span> #</span><span>2</span><span>                   ; N (matrix inner dimension)</span>
<span>CONST R3</span><span>,</span><span> #</span><span>0</span><span>                   ; baseA (matrix A base address)</span>
<span>CONST R4</span><span>,</span><span> #</span><span>4</span><span>                   ; baseB (matrix B base address)</span>
<span>CONST R5</span><span>,</span><span> #</span><span>8</span><span>                   ; baseC (matrix C base address)</span>

<span>DIV</span><span> R6</span><span>,</span><span> R0</span><span>,</span><span> R2</span><span>                 ; row = i // N</span>
<span>MUL</span><span> R7</span><span>,</span><span> R6</span><span>,</span><span> R2</span>
<span>SUB</span><span> R7</span><span>,</span><span> R0</span><span>,</span><span> R7</span><span>                 ; col = i % N</span>

<span>CONST </span><span>R8</span><span>,</span><span> #</span><span>0</span><span>                   ; acc = 0</span>
<span>CONST </span><span>R9</span><span>,</span><span> #</span><span>0</span><span>                   ; k = 0</span>

<span>LOOP</span><span>:</span>
<span>  </span><span>MUL</span><span> </span><span>R10</span><span>,</span><span> R6</span><span>,</span><span> R2</span>
<span>  </span><span>ADD</span><span> </span><span>R10</span><span>,</span><span> </span><span>R10</span><span>,</span><span> </span><span>R9</span>
<span>  </span><span>ADD</span><span> </span><span>R10</span><span>,</span><span> </span><span>R10</span><span>,</span><span> R3</span><span>             ; addr(A[i]) = row * N + k + baseA</span>
<span>  LDR </span><span>R10</span><span>,</span><span> </span><span>R10</span><span>                 ; load A[i] from global memory</span>

<span>  </span><span>MUL</span><span> </span><span>R11</span><span>,</span><span> </span><span>R9</span><span>,</span><span> R2</span>
<span>  </span><span>ADD</span><span> </span><span>R11</span><span>,</span><span> </span><span>R11</span><span>,</span><span> R7</span>
<span>  </span><span>ADD</span><span> </span><span>R11</span><span>,</span><span> </span><span>R11</span><span>,</span><span> R4</span><span>             ; addr(B[i]) = k * N + col + baseB</span>
<span>  LDR </span><span>R11</span><span>,</span><span> </span><span>R11</span><span>                 ; load B[i] from global memory</span>

<span>  </span><span>MUL</span><span> </span><span>R12</span><span>,</span><span> </span><span>R10</span><span>,</span><span> </span><span>R11</span>
<span>  </span><span>ADD</span><span> </span><span>R8</span><span>,</span><span> </span><span>R8</span><span>,</span><span> </span><span>R12</span><span>              ; acc = acc + A[i] * B[i]</span>

<span>  </span><span>ADD</span><span> </span><span>R9</span><span>,</span><span> </span><span>R9</span><span>,</span><span> R1</span><span>               ; increment k</span>

<span>  </span><span>CMP</span><span> </span><span>R9</span><span>,</span><span> R2</span>
<span>  BRn </span><span>LOOP</span><span>                    ; loop while k &lt; N</span>

<span>ADD</span><span> </span><span>R9</span><span>,</span><span> R5</span><span>,</span><span> R0</span><span>                 ; addr(C[i]) = baseC + i</span>
<span>STR</span><span> </span><span>R9</span><span>,</span><span> </span><span>R8</span><span>                     ; store C[i] in global memory</span>

<span>RET</span><span>                            ; end of kernel</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Simulation</h2><a id="user-content-simulation" aria-label="Permalink: Simulation" href="#simulation"></a></p>
<p dir="auto">tiny-gpu is setup to simulate the execution of both of the above kernels. Before simulating, you'll need to install <a href="https://steveicarus.github.io/iverilog/usage/installation.html" rel="nofollow">iverilog</a> and <a href="https://docs.cocotb.org/en/stable/install.html" rel="nofollow">cocotb</a>.</p>
<p dir="auto">Once you've installed the pre-requisites, you can run the kernel simulations with <code>make test_matadd</code> and <code>make test_matmul</code>.</p>
<p dir="auto">Executing the simulations will output a log file in <code>test/logs</code> with the initial data memory state, complete execution trace of the kernel, and final data memory state.</p>
<p dir="auto">If you look at the initial data memory state logged at the start of the logfile for each, you should see the two start matrices for the calculation, and in the final data memory at the end of the file you should also see the resultant matrix.</p>
<p dir="auto">Below is a sample of the execution traces, showing on each cycle the execution of every thread within every core, including the current instruction, PC, register values, states, etc.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/adam-maj/tiny-gpu/blob/master/docs/images/trace.png"><img src="https://github.com/adam-maj/tiny-gpu/raw/master/docs/images/trace.png" alt="execution trace"></a></p>
<p dir="auto"><strong>For anyone trying to run the simulation or play with this repo, please feel free to DM me on <a href="https://twitter.com/majmudaradam" rel="nofollow">twitter</a> if you run into any issues - I want you to get this running!</strong></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Advanced Functionality</h2><a id="user-content-advanced-functionality" aria-label="Permalink: Advanced Functionality" href="#advanced-functionality"></a></p>
<p dir="auto">For the sake of simplicity, there were many additional features implemented in modern GPUs that heavily improve performance &amp; functionality that tiny-gpu omits. We'll discuss some of those most critical features in this section.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Multi-layered Cache &amp; Shared Memory</h3><a id="user-content-multi-layered-cache--shared-memory" aria-label="Permalink: Multi-layered Cache &amp; Shared Memory" href="#multi-layered-cache--shared-memory"></a></p>
<p dir="auto">In modern GPUs, multiple different levels of caches are used to minimize the amount of data that needs to get accessed from global memory. tiny-gpu implements only one cache layer between individual compute units requesting memory and the memory controllers which stores recent cached data.</p>
<p dir="auto">Implementing multi-layered caches allows frequently accessed data to be cached more locally to where it's being used (with some caches within individual compute cores), minimizing load times for this data.</p>
<p dir="auto">Different caching algorithms are used to maximize cache-hits - this is a critical dimension that can be improved on to optimize memory access.</p>
<p dir="auto">Additionally, GPUs often use <strong>shared memory</strong> for threads within the same block to access a single memory space that can be used to share results with other threads.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Memory Coalescing</h3><a id="user-content-memory-coalescing" aria-label="Permalink: Memory Coalescing" href="#memory-coalescing"></a></p>
<p dir="auto">Another critical memory optimization used by GPUs is <strong>memory coalescing.</strong> Multiple threads running in parallel often need to access sequential addresses in memory (for example, a group of threads accessing neighboring elements in a matrix) - but each of these memory requests is put in separately.</p>
<p dir="auto">Memory coalescing is used to analyzing queued memory requests and combine neighboring requests into a single transaction, minimizing time spent on addressing, and making all the requests together.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Pipelining</h3><a id="user-content-pipelining" aria-label="Permalink: Pipelining" href="#pipelining"></a></p>
<p dir="auto">In the control flow for tiny-gpu, cores wait for one instruction to be executed on a group of threads before starting execution of the next instruction.</p>
<p dir="auto">Modern GPUs use <strong>pipelining</strong> to stream execution of multiple sequential instructions at once while ensuring that instructions with dependencies on each other still get executed sequentially.</p>
<p dir="auto">This helps to maximize resource utilization within cores as resources are not sitting idle while waiting (ex: during async memory requests).</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Warp Scheduling</h3><a id="user-content-warp-scheduling" aria-label="Permalink: Warp Scheduling" href="#warp-scheduling"></a></p>
<p dir="auto">Another strategy used to maximize resource utilization on course is <strong>warp scheduling.</strong> This approach involves breaking up blocks into individual batches of theads that can be executed together.</p>
<p dir="auto">Multiple warps can be executed on a single core simultaneously by executing instructions from one warp while another warp is waiting. This is similar to pipelining, but dealing with instructions from different threads.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Branch Divergence</h3><a id="user-content-branch-divergence" aria-label="Permalink: Branch Divergence" href="#branch-divergence"></a></p>
<p dir="auto">tiny-gpu assumes that all threads in a single batch end up on the same PC after each instruction, meaning that threads can be executed in parallel for their entire lifetime.</p>
<p dir="auto">In reality, individual threads could diverge from each other and branch to different lines based on their data. With different PCs, these threads would need to split into separate lines of execution, which requires managing diverging threads &amp; paying attention to when threads converge again.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Synchronization &amp; Barriers</h3><a id="user-content-synchronization--barriers" aria-label="Permalink: Synchronization &amp; Barriers" href="#synchronization--barriers"></a></p>
<p dir="auto">Another core functionality of modern GPUs is the ability to set <strong>barriers</strong> so that groups of threads in a block can synchronize and wait until all other threads in the same block have gotten to a certain point before continuing execution.</p>
<p dir="auto">This is useful for cases where threads need to exchange shared data with each other so they can ensure that the data has been fully processed.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Next Steps</h2><a id="user-content-next-steps" aria-label="Permalink: Next Steps" href="#next-steps"></a></p>
<p dir="auto">Updates I want to make in the future to improve the design, anyone else is welcome to contribute as well:</p>
<ul>
<li> Add a simple cache for instructions</li>
<li> Build an adapter to use GPU with Tiny Tapeout 7</li>
<li> Add basic branch divergence</li>
<li> Add basic memory coalescing</li>
<li> Add basic pipelining</li>
<li> Optimize control flow and use of registers to improve cycle time</li>
<li> Write a basic graphics kernel or add simple graphics hardware to demonstrate graphics functionality</li>
</ul>
<p dir="auto"><strong>For anyone curious to play around or make a contribution, feel free to put up a PR with any improvements you'd like to add 😄</strong></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HTML Attributes vs. DOM Properties (317 pts)]]></title>
            <link>https://jakearchibald.com/2024/attributes-vs-properties/</link>
            <guid>40152682</guid>
            <pubDate>Thu, 25 Apr 2024 02:34:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jakearchibald.com/2024/attributes-vs-properties/">https://jakearchibald.com/2024/attributes-vs-properties/</a>, See on <a href="https://news.ycombinator.com/item?id=40152682">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Attributes and properties are <em>fundamentally</em> different things. You can have an attribute and property of the same name set to different values. For example:</p>
<div><pre><code><span><span><span>&lt;</span>div</span> <span>foo</span><span><span>=</span><span>"</span>bar<span>"</span></span><span>&gt;</span></span>…<span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
  <span>const</span> div <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>'div[foo=bar]'</span><span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttribute</span><span>(</span><span>'foo'</span><span>)</span><span>)</span><span>;</span> <span>// 'bar'</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span>foo<span>)</span><span>;</span> <span>// undefined</span>

  div<span>.</span>foo <span>=</span> <span>'hello world'</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttribute</span><span>(</span><span>'foo'</span><span>)</span><span>)</span><span>;</span> <span>// 'bar'</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span>foo<span>)</span><span>;</span> <span>// 'hello world'</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre></div><p>It seems like fewer and fewer developers know this, partially thanks to frameworks:</p>
<div><pre><code><span><span><span>&lt;</span>input</span> <span>className</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>type</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>aria-label</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>value</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>/&gt;</span></span></code></pre></div><p>If you do the above in a framework's templating language, you're using attribute-like syntax, but under the hood it'll sometimes be setting the property instead, and when it does that differs from framework to framework. In some cases, it'll set a property <em>and</em> an attribute as a side-effect, but that isn't the framework's fault.</p>
<p>Most of the time, these distinctions don't matter. I think it's good that developers can have a long and happy career without caring about the differences between properties and attributes. But, if you need to dig down into the DOM at a lower level, it helps to know. Even if you feel you know the difference, maybe I'll touch on a couple of details you hadn't considered. So let's dig in…</p>
<h2 id="the-key-differences"><a href="#the-key-differences">The key differences</a></h2>
<p>Before we get to the interesting stuff, let's get some of the technical differences out of the way:</p>
<h3 id="html-serialisation"><a href="#html-serialisation">HTML serialisation</a></h3>
<p>Attributes serialise to HTML, whereas properties don't:</p>
<div><pre><code><span>const</span> div <span>=</span> document<span>.</span><span>createElement</span><span>(</span><span>'div'</span><span>)</span><span>;</span>

div<span>.</span><span>setAttribute</span><span>(</span><span>'foo'</span><span>,</span> <span>'bar'</span><span>)</span><span>;</span>
div<span>.</span>hello <span>=</span> <span>'world'</span><span>;</span>

console<span>.</span><span>log</span><span>(</span>div<span>.</span>outerHTML<span>)</span><span>;</span> <span>// '&lt;div foo="bar"&gt;&lt;/div&gt;'</span></code></pre></div><p>So when you're looking at the elements panel in browser developer tools, you're only seeing attributes on elements, not properties.</p>
<h3 id="value-types"><a href="#value-types">Value types</a></h3>
<p>In order to work in the serialised format, attribute values are always strings, whereas properties can be any type:</p>
<div><pre><code><span>const</span> div <span>=</span> document<span>.</span><span>createElement</span><span>(</span><span>'div'</span><span>)</span><span>;</span>
<span>const</span> obj <span>=</span> <span>{</span> <span>foo</span><span>:</span> <span>'bar'</span> <span>}</span><span>;</span>

div<span>.</span><span>setAttribute</span><span>(</span><span>'foo'</span><span>,</span> obj<span>)</span><span>;</span>
console<span>.</span><span>log</span><span>(</span><span>typeof</span> div<span>.</span><span>getAttribute</span><span>(</span><span>'foo'</span><span>)</span><span>)</span><span>;</span> <span>// 'string'</span>
console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttribute</span><span>(</span><span>'foo'</span><span>)</span><span>)</span><span>;</span> <span>// '[object Object]'</span>

div<span>.</span>hello <span>=</span> obj<span>;</span>
console<span>.</span><span>log</span><span>(</span><span>typeof</span> div<span>.</span>hello<span>)</span><span>;</span> <span>// 'object'</span>
console<span>.</span><span>log</span><span>(</span>div<span>.</span>hello<span>)</span><span>;</span> <span>// { foo: 'bar' }</span></code></pre></div><h3 id="case-sensitivity"><a href="#case-sensitivity">Case sensitivity</a></h3>
<p>Attribute names are case-insensitive, whereas property names are case-sensitive.</p>
<div><pre><code><span><span><span>&lt;</span>div</span> <span>id</span><span><span>=</span><span>"</span>test<span>"</span></span> <span>HeLlO</span><span><span>=</span><span>"</span>world<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
  <span>const</span> div <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>'#test'</span><span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttributeNames</span><span>(</span><span>)</span><span>)</span><span>;</span> <span>// ['id', 'hello']</span>

  div<span>.</span><span>setAttribute</span><span>(</span><span>'FOO'</span><span>,</span> <span>'bar'</span><span>)</span><span>;</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttributeNames</span><span>(</span><span>)</span><span>)</span><span>;</span> <span>// ['id', 'hello', 'foo']</span>

  div<span>.</span>TeSt <span>=</span> <span>'value'</span><span>;</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span>TeSt<span>)</span><span>;</span> <span>// 'value'</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span>test<span>)</span><span>;</span> <span>// undefined</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre></div><p>However, attribute <em>values</em> are case-sensitive.</p>
<p>Ok, here's where things start to get blurry:</p>
<h2 id="reflection"><a href="#reflection">Reflection</a></h2>
<p>Take a look at this:</p>
<div><pre><code><span><span><span>&lt;</span>div</span> <span>id</span><span><span>=</span><span>"</span>foo<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
  <span>const</span> div <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>'#foo'</span><span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttribute</span><span>(</span><span>'id'</span><span>)</span><span>)</span><span>;</span> <span>// 'foo'</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span>id<span>)</span><span>;</span> <span>// 'foo'</span>

  div<span>.</span>id <span>=</span> <span>'bar'</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttribute</span><span>(</span><span>'id'</span><span>)</span><span>)</span><span>;</span> <span>// 'bar'</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span>id<span>)</span><span>;</span> <span>// 'bar'</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre></div><p>This seems to contradict the first example in the post, but the above only works because <code>Element</code> has an <code>id</code> getter &amp; setter that 'reflects' the <code>id</code> attribute.</p>
<p>When a property reflects an attribute, the <em>attribute</em> is the source of the data. When you set the property, it's updating the attribute. When you read from the property, it's reading the attribute.</p>
<p>For convenience, most specs will create a property equivalent for every defined attribute. It didn't work in the example at the start of the article, because <code>foo</code> isn't a spec-defined attribute, so there isn't a spec-defined <code>foo</code> property that reflects it.</p>
<p><a href="https://html.spec.whatwg.org/multipage/grouping-content.html#the-ol-element">Here's the spec for <code>&lt;ol&gt;</code></a>. The "Content attributes" section defines the attributes, and the "DOM interface" defines the properties. If you click on <code>reversed</code> in the DOM interface, it takes you to this:</p>
<blockquote>

<p>The <code>reversed</code> and <code>type</code> IDL attributes must <a href="https://html.spec.whatwg.org/multipage/common-dom-interfaces.html#reflect">reflect</a> the respective content attributes of the same name.</p>
</blockquote>

<p>But not all of these reflectors are as simple as these.</p>
<h3 id="naming-differences"><a href="#naming-differences">Naming differences</a></h3>
<p>Ok, this is relatively minor, but sometimes the property has a different name to the attribute it reflects.</p>
<p>In some cases it's just to add the kind of casing you'd expect from a property:</p>
<ul>
<li>On <code>&lt;img&gt;</code>, <code>el.crossOrigin</code> reflects the <code>crossorigin</code> attribute.</li>
<li>On all elements, <code>el.ariaLabel</code> reflects the <code>aria-label</code> attribute (the aria reflectors became cross browser in late 2023. Before that you could only use the attributes).</li>
</ul>
<p>In some cases, names had to be changed due to old JavaScript reserved words:</p>
<ul>
<li>On all elements, <code>el.className</code> reflects the <code>class</code> attribute.</li>
<li>On <code>&lt;label&gt;</code>, <code>el.htmlFor</code> reflects the <code>for</code> attribute.</li>
</ul>
<h3 id="validation-type-coercion-and-defaults"><a href="#validation-type-coercion-and-defaults">Validation, type coercion, and defaults</a></h3>
<p>Properties come with validation and defaults, whereas attribute don't:</p>
<div><pre><code><span>const</span> input <span>=</span> document<span>.</span><span>createElement</span><span>(</span><span>'input'</span><span>)</span><span>;</span>

console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'type'</span><span>)</span><span>)</span><span>;</span> <span>// null</span>
console<span>.</span><span>log</span><span>(</span>input<span>.</span>type<span>)</span><span>;</span> <span>// 'text'</span>

input<span>.</span>type <span>=</span> <span>'number'</span><span>;</span>

console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'type'</span><span>)</span><span>)</span><span>;</span> <span>// 'number'</span>
console<span>.</span><span>log</span><span>(</span>input<span>.</span>type<span>)</span><span>;</span> <span>// 'number'</span>

input<span>.</span>type <span>=</span> <span>'foo'</span><span>;</span>

console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'type'</span><span>)</span><span>)</span><span>;</span> <span>// 'foo'</span>
console<span>.</span><span>log</span><span>(</span>input<span>.</span>type<span>)</span><span>;</span> <span>// 'text'</span></code></pre></div><p>In this case, the validation is handled by the <code>type</code> getter. The setter allowed the invalid value <code>'foo'</code>, but when the getter saw the invalid value, or no value, it returned <code>'text'</code>.</p>
<p>Some properties perform type coercion:</p>
<div><pre><code><span><span><span>&lt;</span>details</span> <span>open</span><span>&gt;</span></span>…<span><span><span>&lt;/</span>details</span><span>&gt;</span></span>
<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
  <span>const</span> details <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>'details'</span><span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>details<span>.</span><span>getAttribute</span><span>(</span><span>'open'</span><span>)</span><span>)</span><span>;</span> <span>// ''</span>
  console<span>.</span><span>log</span><span>(</span>details<span>.</span>open<span>)</span><span>;</span> <span>// true</span>

  details<span>.</span>open <span>=</span> <span>false</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>details<span>.</span><span>getAttribute</span><span>(</span><span>'open'</span><span>)</span><span>)</span><span>;</span> <span>// null</span>
  console<span>.</span><span>log</span><span>(</span>details<span>.</span>open<span>)</span><span>;</span> <span>// false</span>

  details<span>.</span>open <span>=</span> <span>'hello'</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>details<span>.</span><span>getAttribute</span><span>(</span><span>'open'</span><span>)</span><span>)</span><span>;</span> <span>// ''</span>
  console<span>.</span><span>log</span><span>(</span>details<span>.</span>open<span>)</span><span>;</span> <span>// true</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre></div><p>In this case, the <code>open</code> property is a boolean, returning whether the attribute exists. The setter also coerces the type - even though the setter is given <code>'hello'</code>, it's turned to a boolean rather than going directly to the attribute.</p>
<p>Properties like <code>img.height</code> coerce the attribute value to a number. The setter converts the incoming value to a number, and treats negative values as 0.</p>
<h3 id="value-on-input-fields"><a href="#value-on-input-fields"><code>value</code> on input fields</a></h3>
<p><code>value</code> is a fun one. There's a <code>value</code> property and a <code>value</code> attribute. However, the <code>value</code> property does not reflect the <code>value</code> attribute. Instead, the <code>defaultValue</code> property reflects the <code>value</code> attribute.</p>
<p>I know, I know.</p>
<p>In fact, the <code>value</code> property doesn't reflect <em>any</em> attribute. That isn't unusual, there's loads of these (<code>offsetWidth</code>, <code>parentNode</code>, <code>indeterminate</code> on checkboxes for some reason, and many more).</p>
<p>Initially, the <code>value</code> property defers to the <code>defaultValue</code> property. Then, once the <code>value</code> property is set, either via JavaScript or through user interaction, it switches to an internal value. It's as if it's implemented <em>roughly</em> like this:</p>
<div><pre><code><span>class</span> <span>HTMLInputElement</span> <span>extends</span> <span>HTMLElement</span> <span>{</span>
  <span>get</span> <span>defaultValue</span><span>(</span><span>)</span> <span>{</span>
    <span>return</span> <span>this</span><span>.</span><span>getAttribute</span><span>(</span><span>'value'</span><span>)</span> <span>??</span> <span>''</span><span>;</span>
  <span>}</span>

  <span>set</span> <span>defaultValue</span><span>(</span><span>newValue</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span><span>setAttribute</span><span>(</span><span>'value'</span><span>,</span> <span>String</span><span>(</span>newValue<span>)</span><span>)</span><span>;</span>
  <span>}</span>

  #value <span>=</span> <span>undefined</span><span>;</span>

  <span>get</span> <span>value</span><span>(</span><span>)</span> <span>{</span>
    <span>return</span> <span>this</span><span>.</span>#value <span>??</span> <span>this</span><span>.</span>defaultValue<span>;</span>
  <span>}</span>

  <span>set</span> <span>value</span><span>(</span><span>newValue</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span>#value <span>=</span> <span>String</span><span>(</span>newValue<span>)</span><span>;</span>
  <span>}</span>

  <span>// This happens when the associated form resets</span>
  <span>formResetCallback</span><span>(</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span>#value <span>=</span> <span>undefined</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre></div><p>So:</p>
<div><pre><code><span><span><span>&lt;</span>input</span> <span>type</span><span><span>=</span><span>"</span>text<span>"</span></span> <span>value</span><span><span>=</span><span>"</span>default<span>"</span></span> <span>/&gt;</span></span>
<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
  <span>const</span> input <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>'input'</span><span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'value'</span><span>)</span><span>)</span><span>;</span> <span>// 'default'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>value<span>)</span><span>;</span> <span>// 'default'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>defaultValue<span>)</span><span>;</span> <span>// 'default'</span>

  input<span>.</span>defaultValue <span>=</span> <span>'new default'</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'value'</span><span>)</span><span>)</span><span>;</span> <span>// 'new default'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>value<span>)</span><span>;</span> <span>// 'new default'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>defaultValue<span>)</span><span>;</span> <span>// 'new default'</span>

  <span>// Here comes the mode switch:</span>
  input<span>.</span>value <span>=</span> <span>'hello!'</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'value'</span><span>)</span><span>)</span><span>;</span> <span>// 'new default'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>value<span>)</span><span>;</span> <span>// 'hello!'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>defaultValue<span>)</span><span>;</span> <span>// 'new default'</span>

  input<span>.</span><span>setAttribute</span><span>(</span><span>'value'</span><span>,</span> <span>'another new default'</span><span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'value'</span><span>)</span><span>)</span><span>;</span> <span>// 'another new default'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>value<span>)</span><span>;</span> <span>// 'hello!'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>defaultValue<span>)</span><span>;</span> <span>// 'another new default'</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre></div><p>This would have made way more sense if the <code>value</code> attribute was named <code>defaultvalue</code>. Too late now.</p>
<h2 id="attributes-should-be-for-configuration"><a href="#attributes-should-be-for-configuration">Attributes should be for configuration</a></h2>
<p>In my opinion, attributes should be for configuration, whereas properties can contain state. I also believe that the light-DOM tree should have a single owner.</p>
<p>In that sense, I think <code>&lt;input value&gt;</code> gets it right (aside from the naming). The <code>value</code> attribute configures the default value, whereas the <code>value</code> property gives you the current state.</p>
<p>It also makes sense that validation applies when getting/setting properties, but never when getting/setting attributes.</p>
<p>I say 'in my opinion', because a couple of recent HTML elements have done it differently.</p>
<p>The <code>&lt;details&gt;</code> and <code>&lt;dialog&gt;</code> elements represent their open state via the <code>open</code> attribute, and the browser will self add/remove this attribute in response to user interaction.</p>
<p>I think this was a design mistake. It breaks the idea that attributes are for configuration, but more importantly it means that the system in charge of maintaining the DOM (a framework, or vanilla JS) needs to be prepared for the DOM to change itself.</p>
<p>I think it should have been:</p>
<div><pre><code><span><span><span>&lt;</span>details</span> <span>defaultopen</span><span>&gt;</span></span>…<span><span><span>&lt;/</span>details</span><span>&gt;</span></span></code></pre></div><p>And a <code>details.open</code> property to get/set the current state, along with a CSS pseudo-class for targeting that state.</p>
<p>I guess <code>contenteditable</code> also breaks that contract, but… well… it's a opt-in to a lot of breakage.</p>
<h2 id="how-frameworks-handle-the-difference"><a href="#how-frameworks-handle-the-difference">How frameworks handle the difference</a></h2>
<p>Back to the example from earlier:</p>
<div><pre><code><span><span><span>&lt;</span>input</span> <span>className</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>type</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>aria-label</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>value</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>/&gt;</span></span></code></pre></div><p>How do frameworks handle this?</p>
<h3 id="preact-and-vuejs"><a href="#preact-and-vuejs">Preact and VueJS</a></h3>
<p>Aside from a predefined set of cases where they favour attributes, they'll set the prop as a property if <code>propName in element</code>, otherwise they'll set an attribute. Basically, they prefer properties over attributes. Their render-to-string methods do the opposite, and ignore things that are property-only.</p>
<ul>
<li><a href="https://github.com/preactjs/preact/blob/aa95aa924dd5fe28798f2712acdabdc2e9fa38c9/src/diff/props.js#L37"><code>setProperty</code> in Preact</a>.</li>
<li><a href="https://github.com/vuejs/core/blob/958286e3f050dc707ad1af293e91bfb190bdb191/packages/runtime-dom/src/patchProp.ts#L69"><code>shouldSetAsProp</code> in VueJS</a>.</li>
</ul>
<h3 id="react"><a href="#react">React</a></h3>
<p>React does things the other way around. Aside from a predefined set of cases where they favour properties, they'll set an attribute. This makes their render-to-string method similar in logic.</p>
<p>This explains why custom elements don't seem to work in React. Since they're custom, their properties aren't in React's 'predefined list', so they're set as attributes instead. Anything that's property-only on the custom element simply won't work. This will be fixed in React 19, where they'll switch to the Preact/VueJS model for custom elements.</p>
<p>The funny thing is, React popularised using <code>className</code> instead of <code>class</code> in what <em>looks like</em> an attribute. But, even though you're using the property name rather than the attribute name, <a href="https://github.com/facebook/react/blob/699d03ce1a175442fe3443e1d1bed14f14e9c197/packages/react-dom-bindings/src/client/ReactDOMComponent.js#L388-L389">React will set the <code>class</code> attribute under the hood</a>.</p>
<ul>
<li><a href="https://github.com/facebook/react/blob/699d03ce1a175442fe3443e1d1bed14f14e9c197/packages/react-dom-bindings/src/client/ReactDOMComponent.js#L349"><code>setProp</code> in React</a>.</li>
</ul>
<h3 id="lit-html"><a href="#lit-html">lit-html</a></h3>
<p>Lit does things a little differently:</p>
<div><pre><code><span><span><span>&lt;</span>input</span> <span>type</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>.value</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>/&gt;</span></span></code></pre></div><p>It keeps the distinction between attributes and properties, requiring you to prefix the name with <code>.</code> if you want to set the property rather than the attribute.</p>
<ul>
<li><a href="https://lit.dev/docs/templates/expressions/">Lit's expression docs</a>.</li>
</ul>
<h2 id="and-thats-yer-lot"><a href="#and-thats-yer-lot">And that's yer lot</a></h2>
<p>That's pretty much everything I know about the difference between properties and attributes. If there's something I've missed, or you have a question, let me know in the comments below!</p>
<p>Thanks to my <a href="https://offthemainthread.tech/">podcast husband</a> <a href="https://surma.dev/">Surma</a> for his usual reviewing skills.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fine tune LLAMA3 on million scale dataset in consumer GPU using QLora, DeepSpeed (133 pts)]]></title>
            <link>https://medium.com/@sumandas0/fine-tune-llama3-on-million-scale-dataset-in-consumer-gpu-using-qlora-deepspeed-3ae8ad75299a</link>
            <guid>40152486</guid>
            <pubDate>Thu, 25 Apr 2024 02:03:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medium.com/@sumandas0/fine-tune-llama3-on-million-scale-dataset-in-consumer-gpu-using-qlora-deepspeed-3ae8ad75299a">https://medium.com/@sumandas0/fine-tune-llama3-on-million-scale-dataset-in-consumer-gpu-using-qlora-deepspeed-3ae8ad75299a</a>, See on <a href="https://news.ycombinator.com/item?id=40152486">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a rel="noopener follow" href="https://medium.com/@sumandas0?source=post_page-----3ae8ad75299a--------------------------------"><div aria-hidden="false"><p><img alt="Suman" src="https://miro.medium.com/v2/resize:fill:88:88/1*cPgbuLwwvCkde8ztQQcNFA.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div><h2 id="6688">Highlights,</h2><p id="9884"><strong>Model</strong> : LLAMA-8b-instruct</p><p id="e592"><strong>Dataset</strong>: Openhermes-2.5(700k training, 300k testing)</p><p id="7df9"><strong>GPU</strong>: 4 RTX 4090, 24GB</p><h2 id="88aa">Bit of background about me,</h2><p id="cd1d">I’m a full-time software engineer 2, at the core of our platform team. In my scarce free time, I explore various aspects of the machine learning world, with interests in tabular data, NLP, and sound. Whatever I’m sharing here are scraps from all over the internet consolidated into one place. I have decent experience in training small NLP models and have submitted a solution in a Kaggle competition using DeBERTa v3, scoring enough to be in the top 50%, but I have never tried working with large language models. This is my first time, so please let me know if there are any oversights. Yes, this is my first blog post. Writing this will definitely help me, and hopefully, it will be useful for any readers as well</p><h2 id="023a">LLama</h2><p id="7eff">Who don’t know about this long necked creature revolutionizing the AI field from its birth. Joke apart release of llama where the whole OSS powered LLM kicked of the revolution which don’t seems like stopping in near future.</p><p id="b306">To learn more on llama in depth and technical do checkout this <a href="https://www.linkedin.com/posts/ujamil_llama-explained-kv-cache-rotary-positional-activity-7100620274642866176-XaKO/" rel="noopener ugc nofollow" target="_blank">Post | LinkedIn</a> , this is one of the most technically simplified explanation I can found all over the internet. Few things they implemented in their architecture like Grouped Multi Query Attention, KV-Cache, Rotary Positional Embeddings(RoPE) which are very cool. These are not in scope of this article. They continued releasing their versions of LLama with latest version came few days ago. And this time with massive data compacted into few GBs of parameters.</p><figure><figcaption><a href="https://www.forbes.com/sites/janakirammsv/2024/04/19/meta-unveils-llama-310-key-facts-about-the-advanced-llm/" rel="noopener ugc nofollow" target="_blank">Meta Unveils Llama 3–10 Key Facts About The Advanced LLM (forbes.com)</a></figcaption></figure><h2 id="226e">Deepspeed</h2><blockquote><p id="0a5f"><em>DeepSpeed is a deep learning optimization library that makes distributed training and inference easy, efficient, and effective.</em></p><p id="eddb"><a href="https://github.com/microsoft/DeepSpeed" rel="noopener ugc nofollow" target="_blank"><em>https://github.com/microsoft/DeepSpeed</em></a></p></blockquote><p id="dee0">I will be training this model using four RTX 4090 GPUs that I’ve rented from <a href="http://vast.ai/" rel="noopener ugc nofollow" target="_blank">vast.ai</a>, so we need to take some steps to train the models across multiple GPUs. Training on multiple GPUs is a complex task compared to training on a single GPU. Why? When we train on a single GPU, the Optimizer state, parameters and gradients reside in a single system, which helps iterating over models on one GPU.</p><p id="c422">Now, if we add another GPU, there are two systems that will train the models, each with its own state(Optimizer state, parameters and gradients). After one epoch or several steps, we would like to obtain a single result. Now imagine two systems training two batches of data in parallel; they need to communicate about their state and converge the results with minimal data loss. There are multiple ways to utilize multiple GPUs: we can replicate parameters, gradients, and optimizer state across all GPUs, or we could shard only the optimizer state, or the optimizer state and gradients. DeepSpeed helps in distributing the load over the GPUs without any issues. And accelerate package from Huggingface lets us do this like its piece of cake.</p><p id="91cc">I will use stage 3 which will shard all parameters, gradients and optimizer state which will let us training over less memory requirement,</p><figure></figure><p id="2411">More details in their blog, <a href="https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/" rel="noopener ugc nofollow" target="_blank">ZeRO &amp; DeepSpeed: New system optimizations enable training models with over 100 billion parameters — Microsoft Research</a></p><h2 id="9ade">QLoRA</h2><p id="ebf1">Until I write something about QLoRA, please take a look into this blog to get more technical context <a href="https://wandb.ai/sauravmaheshkar/QLoRA/reports/What-is-QLoRA---Vmlldzo2MTI2OTc5" rel="noopener ugc nofollow" target="_blank">What is QLoRA? | QLoRA — Weights &amp; Biases (wandb.ai)</a>, basically 70B/8B models are very large in size means when you fine tune it you will not be able to fully fine tune with any GPU in normal people’s budget, so we tried to fine tune it with very low resource and came LoRA which helped us just training over parameters with low rank and merging them with original weights, then came QLoRA which helped even more reducing memory consumption by quantizing the pre trained LLM to 4 bit precision, quantizing is a topic in itself so not going beyond this.</p><p id="51ad">Also take a look into this article <a href="https://www.entrypointai.com/blog/lora-fine-tuning/" rel="noopener ugc nofollow" target="_blank">LoRA Fine-tuning &amp; Hyperparameters Explained (in Plain English) | Entry Point AI</a></p><h2 id="50cb">Lets start finetuning LLamA 3</h2><p id="a905">We will be finetuning the llama3 instruct model <a href="https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct" rel="noopener ugc nofollow" target="_blank">meta-llama/Meta-Llama-3–8B-Instruct · Hugging Face</a> over <a href="https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B" rel="noopener ugc nofollow" target="_blank">openhermes</a> dataset provided by teknium.</p><h2 id="0e59">Data preparation</h2><p id="a219">Meta has their own chat format so tried to follow the format they provided and read their encoding algorithm in their llama3 repository,</p><p id="b4df"><strong>Load the dataset</strong></p><pre><span id="0492">from datasets import load_dataset<p>dataset = load_dataset("teknium/OpenHermes-2.5")</p></span></pre><p id="3943"><strong>The encoding utility I took inspiration from</strong><a href="https://github.com/meta-llama/llama3/blob/af6eedf7042fb51d00b2b26d8ef1ceaab73e1670/llama/tokenizer.py#L202" rel="noopener ugc nofollow" target="_blank"><strong> llama3 repo</strong></a><strong>,</strong></p><pre><span id="2427">def _return_header(message)-&gt; str:<br>    role = message["from"]<br>    header = ""<br>    if role == "system":<br>        header = "system"<br>    elif role == "gpt":<br>        header = "assistant"<br>    elif role == "human":<br>        header = "user"<br>    return header<p>def encode_header(message):<br>    text = ''<br>    text = text + "&lt;|start_header_id|&gt;"<br>    header = _return_header(message)<br>    text = text + header<br>    text = text + "&lt;|end_header_id|&gt;"<br>    text = text + "\n\n"<br>    return text</p><p>def encode_message(message)-&gt;str:<br>    text = encode_header(message)<br>    text = text + message["value"].strip()<br>    text = text + "&lt;|eot_id|&gt;"<br>    return text</p><p>def encode_dialog_prompt(dialog):<br>    text = ''<br>    text = text + "&lt;|begin_of_text|&gt;"<br>    for message in dialog:<br>        text = text + encode_message(message)<br>    return text</p></span></pre><pre><span id="c697">ds = dataset.map(lambda x: {"content":encode_dialog_prompt(x['conversations'])}, num_proc=10)</span></pre><p id="6128">Remove redundunt columns and split it into train and validation</p><pre><span id="6147">ds = ds.remove_columns(['custom_instruction', 'topic', 'model_name', 'model', 'skip_prompt_formatting', 'category', 'conversations', 'views', 'language', 'id', 'title', 'idx', 'hash', 'avatarUrl', 'system_prompt', 'source'])<br>train_test_split = ds["train"].train_test_split(test_size=0.3)</span></pre><p id="e8fc"><strong>And push it to hub,</strong></p><pre><span id="c29e">train_test_split.push_to_hub("sumandas/openhermes-2.5-llama3")</span></pre><p id="6614">The resultant dataset, <a href="https://huggingface.co/datasets/sumandas/openhermes-2.5-llama3" rel="noopener ugc nofollow" target="_blank">sumandas/openhermes-2.5-llama3 · Datasets at Hugging Face</a>, example text</p><pre><span id="3556">&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt; You are an AI assistant. Provide a detailed answer so user don’t need to search outside to understand the answer.&lt;|eot_id|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt; Instructions: Given a sentence, generate what should be the most likely next statement. The next statement should be reasonable and logically correct. Input: The screen is full of white bubbles and words, while a pair of hands plays the piano. The bubbles and words disappear and it Output:&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt; Output: becomes apparent that the hands are creating a visual representation of the music being played, captivating the audience with this unique sensory experience.&lt;|eot_id|&gt;</span></pre><h2 id="1ba2">Now its time for training LLama3</h2><p id="cab1">All of the resources were already available in internet I just fine tuned those for my setup and requirements,</p><p id="ebdc"><strong>Prerequisites,</strong></p><ol><li id="0bf2">Install cuda dev kit <code>conda install cuda</code> or follow <a href="https://developer.nvidia.com/cuda-downloads?target_os=Linux" rel="noopener ugc nofollow" target="_blank">developer.nvidia.com/cuda-downloads?target_os=Linux</a></li><li id="0a0a">Install deepspeed</li><li id="cd39">Install flash-attention <em>pip install flash-attn — no-build-isolation</em></li><li id="6a5a">Install these libraries, I use <a href="https://github.com/astral-sh/uv" rel="noopener ugc nofollow" target="_blank">uv</a> for faster dependency resolution,</li></ol><pre><span id="2bb2">git+https://github.com/huggingface/transformers<br>git+https://github.com/huggingface/accelerate<br>git+https://github.com/huggingface/peft<br>git+https://github.com/huggingface/trl<br>huggingface-hub<br>bitsandbytes<br>evaluate<br>datasets<br>einops<br>wandb<br>tiktoken<br>xformers<br>sentencepiece<br>deepspeed<br>torch==2.2.2</span></pre><p id="ebd9"><strong>Training code</strong></p><p id="d43d">This is Swiss knife training code where you can train in multiple mode as per you convenience, found this in this repo <a href="https://github.com/pacman100/LLM-Workshop" rel="noopener ugc nofollow" target="_blank">pacman100/LLM-Workshop: LLM Workshop by Sourab Mangrulkar (github.com)</a>,</p><blockquote><p id="93e4">The <code>training.py</code> file is the one we will launch using accelerate with proper configs, just putting the training.py gist here, <a href="https://gist.github.com/sumandas0/0483db8514ea43e45cc5e5f5525914ab" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/sumandas0/0483db8514ea43e45cc5e5f5525914ab</a></p></blockquote><p id="831b">This training code uses SFTTrainer from huggingface, more details <a href="https://huggingface.co/docs/trl/en/sft_trainer" rel="noopener ugc nofollow" target="_blank">Supervised Fine-tuning Trainer (huggingface.co)</a></p><p id="7822">You can do multiple thing with this, you can train with loftq, unsloth, FFT, normal lora but I will just use QloRa with Deepspeed ZerO stage 3.</p><p id="cc17"><strong>First lets define the accelerate config for using deepspeed</strong></p><figure></figure><blockquote><p id="2bfa">Note, If you increase the number of GPU update number in <em>num_processes</em></p></blockquote><p id="56e5">Now lets just run the accelerate command to start training,</p><pre><span id="7326">accelerate launch --config_file "deepspeed_config.yaml"  train.py \<br>--seed 100 \<br>--model_name_or_path "meta-llama/Meta-Llama-3-8B-Instruct" \<br>--dataset_name "sumandas/openhermes-2.5-llama3" \<br>--chat_template_format "none" \<br>--add_special_tokens False \<br>--append_concat_token False \<br>--splits "train,test" \<br>--max_seq_len 2048 \<br>--num_train_epochs 1 \<br>--logging_steps 5 \<br>--log_level "info" \<br>--logging_strategy "steps" \<br>--evaluation_strategy "epoch" \<br>--save_strategy "steps" \<br>--push_to_hub \<br>--hub_private_repo True \<br>--report_to "wandb" \<br>--hub_strategy "every_save" \<br>--bf16 True \<br>--packing True \<br>--learning_rate 1e-4 \<br>--lr_scheduler_type "cosine" \<br>--weight_decay 1e-4 \<br>--warmup_ratio 0.0 \<br>--max_grad_norm 1.0 \<br>--output_dir "llama3-openhermes-2.5" \<br>--per_device_train_batch_size 4\<br>--per_device_eval_batch_size 4\<br>--gradient_accumulation_steps 2 \<br>--gradient_checkpointing True \<br>--use_reentrant True \<br>--dataset_text_field "content" \<br>--use_flash_attn True \<br>--use_peft_lora True \<br>--lora_r 8 \<br>--lora_alpha 16 \<br>--lora_dropout 0.1 \<br>--lora_target_modules "all-linear" \<br>--use_4bit_quantization True \<br>--use_nested_quant True \<br>--bnb_4bit_compute_dtype "bfloat16" \<br>--bnb_4bit_quant_storage_dtype "bfloat16"</span></pre><p id="85c8"><strong>Notes,</strong></p><ol><li id="7f33">Set env variable HF_HUB_ENABLE_HF_TRANSFER=1 first</li><li id="10d8">output_dir will also be the repo created in huggingface where all the checkpoints will be stored, checkpoints will be created every 500 steps by default</li><li id="e8df">I set chat template format as <code>none</code> , because I already formatted those in my way, if you have other format do use for e.g chatml, zephyr</li><li id="9507"><code>lora_target_modules</code> is set as all-linear which is QLoRa specific where they published paper to show fine tuning all linear layers gives us comparable result to full fine tune.</li><li id="7c14">For setting up hyperparameters for LoRa, take a look into this awesome blog <a href="https://www.entrypointai.com/blog/lora-fine-tuning/" rel="noopener ugc nofollow" target="_blank">LoRA Fine-tuning &amp; Hyperparameters Explained (in Plain English) | Entry Point AI</a></li><li id="c733">Set up WANDB_API_KEY=&lt;key&gt; if you are reporting to wandb else remove <code>report_to='wandb'</code></li></ol><p id="bc6b">This should be it and your training should be running in full force, look for GPU utilization.</p><h2 id="f2df">Observation</h2><p id="38ff">Ran the fine tuning for only 1 epoch, took around 15 hours. Loss curve</p><figure><figcaption>fig: training loss <a href="https://wandb.ai/sumandas0/huggingface/reports/train-loss-24-04-25-02-44-11---Vmlldzo3Njg1NzIw?accessToken=hinzctjy4lbm48zwjoamnmhxs5r56zp8l88iqpss2jb0xo2w2bu049jkiqd59btj" rel="noopener ugc nofollow" target="_blank">train/loss (24/04/25 02:44:11) | huggingface — Weights &amp; Biases (wandb.ai)</a></figcaption></figure><p id="38c3"><strong>WandB summary</strong></p><pre><span id="e856">{<br>  "train/learning_rate": 0.00004551803455482833,<br>  "eval/steps_per_second": 0.893,<br>  "_wandb.runtime": 51487,<br>  "_runtime": 51480.36651659012,<br>  "_timestamp": 1713698971.6200776,<br>  "train/epoch": 1.0571428571428572,<br>  "train/grad_norm": 0.14189070214353952,<br>  "train/global_step": 8325,<br>  "eval/samples_per_second": 7.141,<br>  "_step": 1665,<br>  "eval/loss": 0.963840126991272,<br>  "train/loss": 0.9674,<br>  "eval/runtime": 7532.9797<br>}</span></pre><h2 id="602e">Last steps,</h2><p id="02a5">After the finetuning what model you will get is small adapter model not full model that you can just start using just now, we need to add the adapter to the original meta llama3 weights,</p><p id="d092">Load PEFT adapter model,</p><pre><span id="866d">from peft import PeftModel<br>from transformers import AutoModelForCausalLM<p>base_model = AutoModelForCausalLM.from_pretrained("meta-llama/Meta-Llama-3-8B-Instruct",torch_dtype=torch.bfloat16, device_map="auto")<br>adapter_model = PeftModel.from_pretrained(base_model, "sumandas/llama3-openhermes-2.5")<br>adapter_model.merge_and_unload()</p></span></pre><p id="11a1">Now save the adapter model into hf,</p><pre><span id="c058">adapter_model.push_to_hub("sumandas/llama3-openhermes-2.5")</span></pre><h2 id="6ffe">Inference</h2><pre><span id="2c4c">import torch<br>import transformers<br>from transformers import pipeline<p>pipe = pipeline("text-generation", model="sumandas/llama3-openhermes-2.5",model_kwargs={"torch_dtype": torch.bfloat16},<br>    device="cuda")</p><p>generate_kwargs = {<br>    "do_sample": True,<br>    "temperature": 0.7,<br>    "max_new_tokens": 35,<br>}</p></span></pre><pre><span id="e8fe">pipe("&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt; Describe the food of Thailand&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;",max_length=2048)</span></pre><p id="a1a4">Response,</p><pre><span id="dce7">Thai cuisine is a blend of bold flavors and aromatic ingredients that create a harmonious balance of sweet, sour, salty, bitter, and spicy taste. The food in Thailand varies between different regions, but some common ingredients found throughout include rice, noodles, vegetables, herbs, and spices. Rice is a staple of Thai cuisine and is served with almost every meal, whether it is stir-fried, boiled, or used to make congee or fried rice. Noodles, made from rice or wheat, are also very popular and can be found served with various broths, sauces, and toppings in many Thai dishes. Thai food is known for its use of fresh herbs and spices such as lemongrass, galangal, coriander, basil, kaffir lime leaves, ginger, and garlic, which give the dishes their distinct flavors. Thai chilies are also widely used to add varying levels of heat to the food. Some popular Thai dishes include Tom Yum soup (hot and sour soup with lemongrass, kaffir lime leaves, and chilies), Pad Thai (stir-fried rice noodles with vegetables, peanuts, and a tangy sauce), and green curry (a spicy curry made with green chilies, coconut milk, and Thai basil). Many Thai dishes are also accompanied by a variety of sauces and condiments, including fish sauce, soy sauce, chili paste, and tamarind sauce. Fresh fruits like mango, papaya, and pineapple are also commonly enjoyed as a sweet ending to a meal. Overall, Thai food is a vibrant and flavorful cuisine that combines traditional ingredients and cooking techniques with a balance of flavors that tantalize the taste buds.&lt;|eot_id|&gt;</span></pre><p id="9238">Do send my model and dataset some love if it has any worth :)</p><p id="45d9"><a href="https://huggingface.co/datasets/sumandas/openhermes-2.5-llama3" rel="noopener ugc nofollow" target="_blank">sumandas/openhermes-2.5-llama3 · Datasets at Hugging Face</a></p><p id="2c72"><a href="https://huggingface.co/sumandas/llama3-openhermes-2.5" rel="noopener ugc nofollow" target="_blank">sumandas/llama3-openhermes-2.5 · Hugging Face</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Air Force picks Anduril, General Atomics to develop unmanned fighter jets (213 pts)]]></title>
            <link>https://breakingdefense.com/2024/04/air-force-picks-anduril-general-atomics-for-next-round-of-cca-work/</link>
            <guid>40152049</guid>
            <pubDate>Thu, 25 Apr 2024 01:11:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://breakingdefense.com/2024/04/air-force-picks-anduril-general-atomics-for-next-round-of-cca-work/">https://breakingdefense.com/2024/04/air-force-picks-anduril-general-atomics-for-next-round-of-cca-work/</a>, See on <a href="https://news.ycombinator.com/item?id=40152049">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="entry-351504">
<div id="attachment_351513"><p><img aria-describedby="caption-attachment-351513" decoding="async" fetchpriority="high" src="https://sites.breakingmedia.com/uploads/sites/3/2024/04/Kendall-scaled-e1713972110235.jpg" alt="SecAF Kendall speaks at SLOC" width="2560" height="1442" srcset="https://sites.breakingmedia.com/uploads/sites/3/2024/04/Kendall-scaled-e1713972110235.jpg 2560w, https://sites.breakingmedia.com/uploads/sites/3/2024/04/Kendall-scaled-e1713972110235-350x197.jpg 350w, https://sites.breakingmedia.com/uploads/sites/3/2024/04/Kendall-scaled-e1713972110235-1024x577.jpg 1024w, https://sites.breakingmedia.com/uploads/sites/3/2024/04/Kendall-scaled-e1713972110235-768x433.jpg 768w, https://sites.breakingmedia.com/uploads/sites/3/2024/04/Kendall-scaled-e1713972110235-1536x865.jpg 1536w, https://sites.breakingmedia.com/uploads/sites/3/2024/04/Kendall-scaled-e1713972110235-2048x1154.jpg 2048w, https://sites.breakingmedia.com/uploads/sites/3/2024/04/Kendall-scaled-e1713972110235-1070x603.jpg 1070w" sizes="(max-width: 2560px) 100vw, 2560px"></p><p id="caption-attachment-351513">Secretary of the Air Force Frank Kendall speaks with students and guests during the Senior Leader Orientation Course at Joint Base Andrews, Md., Nov. 13, 2023. (U.S. Air Force photo by Eric Dietrich)</p></div>
<p><em><strong>UPDATED 4/24/24 at 5:48 PM ET with details from an Air Force press release and comments from CCA vendors.&nbsp;</strong></em></p>
<p><span>WASHINGTON — Defense startup Anduril and drone maker General Atomics Aeronautical Systems (GA-ASI) have been picked by the Air Force to build and test drone prototypes for the next phase of the service’s</span><a href="https://breakingdefense.com/tag/collaborative-combat-aircraft/"> <span>Collaborative Combat Aircraft</span></a><span> program, the Air Force announced tonight.</span></p>
<p><span>The Air Force’s decision winnows down a pool of five competitors to two. As a result, three other vendors — Boeing, Lockheed Martin and Northrop Grumman — have been eliminated from the running.</span></p>

<p><span>“The companies not selected to build these production representative CCA vehicles, and execute the flight test program, will continue to be part of the broader industry partner vendor pool consisting of more than 20 companies to compete for future efforts, including future production contracts,” the Air Force said.</span><span>&nbsp;</span></p>
<p><span>As Breaking Defense</span><a href="https://breakingdefense.com/2023/12/exclusive-5-companies-in-early-running-for-air-forces-cca-drone-wingmen/#:~:text=Boeing%2C%20General%20Atomics%2C%20Lockheed%20Martin,aircraft%2C%20Breaking%20Defense%20has%20learned."> <span>first reported</span></a><span>, the five contractors were previously picked by the Air Force for the program’s first phase, which largely focused on design work. Today’s selection narrows down the vendors who will take their designs from the drawing board to the real world. As Air Force acquisition chief Andrew Hunter recently told lawmakers in a congressional hearing, the upcoming CCA stage will see those vendors “complete detailed designs, build prototypes and test production-representative test articles.”</span></p>

<p><span>Unveiled by the service as a major multibillion dollar program in the fiscal year 2024 budget, the CCA effort aims to initially field</span><a href="https://breakingdefense.com/2023/03/air-force-plans-nominal-buy-of-200-ngad-fighters-1000-drone-wingmen-kendall-says/"><span> as many as 1,000 drones</span></a><span>. According to the service’s press release today, officials plan to make a “competitive production decision” by FY26 for the first round of CCA work and “field a fully operational capability before the end of the decade.”</span></p>
<p><b><i>RELATED:</i></b><a href="https://breakingdefense.com/2024/04/in-a-world-first-darpa-project-demonstrates-ai-dogfighting-in-real-jet/"> <b><i>In a ‘world first,’ DARPA project demonstrates AI dogfighting in a real jet</i></b></a></p>


<p><span>At the Air &amp; Space Forces Association Warfare Symposium in February,</span><a href="https://breakingdefense.com/2024/02/air-force-plans-cca-downselect-within-months-second-increment-in-fy25-kendall/"> <span>Kendall revealed</span></a><span> that the CCA competition underway right now would be the program’s first “increment,” with a second to follow in the FY25 budget. That second increment would provide vendors eliminated today, as well as</span><a href="https://breakingdefense.com/2024/02/take-2-kratos-aims-for-prime-status-on-second-cca-increment/"> <span>new ones</span></a><span>, another shot at a CCA contract.</span><a href="https://breakingdefense.com/2023/10/is-a-us-aussie-japanese-loyal-wingman-drone-in-the-cards/"> <span>International collaboration</span></a><span> could also feature in the second increment, Kendall said, and the service’s release today indicated foreign military sales could be on the table for the program.&nbsp;</span></p>
<p><span>During the February roundtable, Kendall further revealed the “possibility” that more than one vendor could see their drone bid enter service for the first increment. He also floated the chance of carrying up to three vendors through the preceding test phase if industry helped share some of the cost.&nbsp;</span></p>
<p><span>With only two vendors making the cut today, it’s unclear if that idea bore any fruit. Asked recently whether industry was convinced to pick up some of the tab, Hunter told reporters that “cost sharing is not core to our approach on CCA.”</span></p>
<p><span>The service’s press release today said that the down select decision “does not exclude any of the vendors from competing for the future Increment 1 production contract” — likely suggesting companies would have to spend internal funds to move their designs forward and compete for an eventual production deal.</span></p>
<h2><b>What Companies Pitched, And What Comes Next</b></h2>
<p><span>When it comes to specific designs, GA-ASI has</span><a href="https://breakingdefense.com/2023/11/general-atomics-exec-eyes-williams-pratt-engines-as-company-searches-for-cca-propulsion/"> <span>stated</span></a><span> that the company’s Gambit drone family would be its entry, while</span><a href="https://breakingdefense.com/2023/09/defense-startup-anduril-acquires-uas-maker-blue-force-technologies/"> <span>Anduril’s acquisition</span></a><span> last year of autonomous aircraft vendor Blue Force positioned the Fury drone to be Anduril’s bid. In images today touting the company’s win, Anduril showcased the Fury drone, appearing to confirm the drone was the company’s bid.</span></p>
<p><span>“There is no time to waste on business as usual. With the CCA program, Secretary Kendall and the Air Force have embraced a fast-moving, forward-looking approach to field autonomous systems at speed and scale,” Anduril CEO and Co-Founder Brian Schimpf said in a statement. “We are honored to be selected for this unprecedented opportunity, which signals a demand for continued expansion of the defense industrial base. Anduril is proud to pave the way for other non-traditional defense companies to compete and deliver on large scale programs.”</span></p>
<p><span>“Throughout our 30-year history, GA-ASI has been at the forefront of rapidly advancing unmanned aircraft systems that support our warfighters,” GA-ASI President David Alexander said in a statement. “The USAF is moving forward with GA-ASI due to our focused commitment to unmanned air-to-air combat operations and unmatched UAS experience, ensuring the production of the CCA aircraft at scale to deliver affordable combat mass for the warfighter.”</span></p>
<p><span>Boeing said in a statement today that the aerospace giant offered a “proprietary solution tailored to the U.S. Air Force’s unique CCA phase one requirements,” and did not pitch the MQ-25 Stingray or MQ-28 Ghost Bat.</span><span>&nbsp;</span></p>
<p><span>“While we are disappointed that we won’t be moving forward in this phase of the Air Force’s CCA program, we are undeterred in our commitment to providing next-generation autonomous combat aircraft for U.S. and global military customers. Work continues on our robust and growing autonomous family, including the MQ-25 Stingray and future derivatives, the MQ-28 Ghost Bat, and a number of proprietary programs we can’t disclose,” Boeing said.&nbsp;</span></p>
<p><span>Lockheed and Northrop have also not confirmed what candidates they put forward.</span></p>
<p><span>In a statement, Lockheed said</span><span> the company “remains committed to advancing the state of the art in autonomous systems for air and ground missions. Our work to develop and integrate pathfinding open architectures, ground control systems like the Multi-Domain Combat System™, human factors interfaces, and mission systems continues. For some time, we’ve been focused on bringing to life the transformative power of autonomous and AI/ML enabled operations in crewed and uncrewed DoD systems, with particular focus on integrating CCA with F-35 and F-22. These commitments and work are ongoing.”</span></p>
<p><span>A representative for Northrop did not immediately respond to a request for comment.&nbsp;</span></p>
<p><span>A second parallel effort under CCA is also known to be working on the drones’ autonomous software, though it’s unclear what companies are involved. Hunter</span><a href="https://breakingdefense.com/2023/05/air-force-expects-sizeable-vendor-pool-for-drone-wingmen/"> <span>said last year</span></a><span> the service already had 20 to 30 vendors working on that element of CCA work, and more recently said in February that the autonomy piece would continue independent of progress on the hardware side.</span></p>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Beginner's Guide to the ESP8266 (226 pts)]]></title>
            <link>https://tttapa.github.io/ESP8266/Chap01%20-%20ESP8266.html</link>
            <guid>40151982</guid>
            <pubDate>Thu, 25 Apr 2024 01:03:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tttapa.github.io/ESP8266/Chap01%20-%20ESP8266.html">https://tttapa.github.io/ESP8266/Chap01%20-%20ESP8266.html</a>, See on <a href="https://news.ycombinator.com/item?id=40151982">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

   
<i>Pieter P, 08-03-2017</i>
   <p>
        Some time ago, I wrote <a href="http://www.instructables.com/id/A-Beginners-Guide-to-Arduino/">a Beginner's Guide to Arduino</a> that seems to be very popular, so I decided to create a follow-up: <b>A Beginner's Guide to the ESP8266</b>. That's right, a tutorial on how to use the world's most popular $3 Wi-Fi board.
   </p>
   
   <p>
        This is going to be a very in-depth tutorial, covering some networking concepts as well. If you're a beginner, and just want to go straight to the more exciting Wi-Fi part, feel free to do so, I included short <i>TL;DR's </i>in the longer, more technical parts.
   </p>
   
   <p>
        A short overview of what I'll cover in this article: 
   </p>
   <div>
       <ol>
           <li><b>What is an ESP8266?</b> A short overview of what an ESP8266 is, and what you can do with it</li>
           <li><b>Deciding on what board to buy</b>: There's loads of different ESP8266 available these days, finding the one that's best for you can be hard</li>
           <li><b>Installing the software</b>: you need to install some software to program the ESP8266, and maybe a USB driver</li>
           <li><b>Setting up the hardware</b>: some modules and boards need some external components</li>
           <li><b>The ESP8266 as a microcontroller</b>: the ESP8266 can be used as a normal microcontroller, just like an Arduino</li>
           <li><b>Network protocols</b>: Before we start using the Wi-Fi capabilities of the ESP8266, I'll teach you some of the network protocols involved</li>
           <li><b>Setting up a Wi-Fi connection</b>: That's probably why you're reading this, right?</li>
           <li><b>Name resolution</b>: Find the ESP8266 on your local network using mDNS</li>
           <li><b>Setting up a simple web server</b>: This enables you to add web pages to the ESP8266, and browse them from your computer or phone</li>
           <li><b>Setting up an advanced web server</b>: a more advanced server with a real file system that allows you to upload new files over Wi-Fi</li>
           <li><b>OTA - uploading programs over Wi-Fi</b>: You don't have to upload programs over USB, you can use Wi-Fi instead</li>
           <li><b>Wirelessly controlling your RGB lighting</b>: Change the color of your LED strips using your phone or computer</li>
           <li><b>Getting the time</b>: Connect to a time server using NTP and sync the ESP's clock</li>
           <li><b>Monitoring sensors</b>: log the temperature in your living room, save it in flash memory and show it in a fancy graph in your browser</li>
           <li><b>Getting email notifications</b>: Turn on a notification light when you've got unread emails</li>
           <li><b>Advanced features</b>: use DNS, captive portals, Wi-Fi connector libraries, OSC ...</li>
       </ol>
   </div>
   
   <p>
        This guide expects some basic knowledge of microcontrollers like the Arduino. If that's something you're not already familiar with, I'd recommend you to read my <a href="https://www.instructables.com/id/A-Beginners-Guide-to-Arduino/">Beginner's Guide to Arduino</a> first, it covers a lot of the basics that I won't go into in this article.
   </p>
   <p>
        I really want to focus on the ESP8266-specific things, like Wi-Fi and other network protocols, the ESP's hardware, software, IoT, etc ...
   </p>
   <h3>What is an ESP8266?</h3>
   <p>
        The ESP8266 is a System on a Chip (SoC), manufactured by the Chinese company <a href="https://espressif.com/en/">Espressif</a>. It consists of a Tensilica L106 32-bit <b>micro controller</b> unit (MCU) and a <b>Wi-Fi transceiver</b>. It has <b>11 GPIO pins</b>* (General Purpose Input/Output pins), and an <b>analog input</b> as well. This means that you can program it like any normal Arduino or other microcontroller. And on top of that, you get Wi-Fi communication, so you can use it to connect to your Wi-Fi network, connect to the Internet, host a web server with real web pages, let your smartphone connect to it, etc ... The possibilities are endless! It's no wonder that this chip has become the most popular IOT device available. 
   </p>
   
   <p>
        There are many different modules available, standalone modules like the <a href="http://en.ai-thinker.com/html/Products/WIFI_Module/ESP_01-14Series/">ESP-## series</a> by AI Thinker, or complete development boards like the <a href="http://nodemcu.com/index_en.html">NodeMCU DevKit</a> or the <a href="http://www.wemos.cc/">WeMos D1</a>. Different boards may have different pins broken out, have different Wi-Fi antennas, or a different amount of flash memory on board.
   </p>
   
   <p><small>(*) The ESP8266 chip itself has 17 GPIO pins, but 6 of these pins (6-11) are used for communication with the on-board flash memory chip.</small>
   </p>
   <h3>Programming</h3>
   <p>
        There are different ways to program the ESP8266, but I'll only cover the method using the Arduino IDE. This is really easy for beginners, and it's a very familiar environment if you've used Arduino boards before. 
   </p>
   <p>
        Just keep in mind that it's not limited to this option: there's also an official SDK available to program it in real C, this is very useful if you want to optimize your code or do some advanced tricks that aren't supported by the Arduino IDE. Another possibility is to flash it with a <a href="https://github.com/nodemcu/nodemcu-firmware">LUA</a> interpreter, so you can upload and run LUA scripts. Or maybe you're more familiar with Python? Then you should check out the <a href="http://micropython.org/download#esp8266">MicroPython firmware</a> to interpret MicroPython scripts. I'm sure there's other languages available as well, so just do a quick Google search and write your code in the language of your choice.
   </p>
   <h3>Requirements</h3>
   <p>
        You'll need a couple of things in order to follow this guide:
   </p>
   <div>
       <ul>
           <li>An ESP8266 board</li>
           <li>A computer that can run the Arduino IDE (Windows, Mac or Linux)</li>
           <li>A USB-to-Serial converter, it is very important that you use a <b>3.3V</b> model*</li>
           <li>A USB cable</li>
           <li>A 3.3V power supply or voltage regulator*</li>
           <li>A Wi-Fi network to connect to</li>
       </ul>
       <p><small>(*) Your board may already include these. More information can be found in the next chapter.</small>
       </p>
   </div>
    
<hr>
            
            
        </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You are what you read, even if you don't always remember it (729 pts)]]></title>
            <link>https://blog.jim-nielsen.com/2024/you-are-what-you-read/</link>
            <guid>40151952</guid>
            <pubDate>Thu, 25 Apr 2024 00:58:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.jim-nielsen.com/2024/you-are-what-you-read/">https://blog.jim-nielsen.com/2024/you-are-what-you-read/</a>, See on <a href="https://news.ycombinator.com/item?id=40151952">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          <p>Here’s Dave Rupert (<a href="https://notes.jim-nielsen.com/#2024-03-22T1029">from my notes</a>):</p>
<blockquote>
<p>the goal of a book isn’t to get to the last page, it’s to expand your thinking.</p>
</blockquote>
<p>I have to constantly remind myself of this. Especially in an environment that prioritizes optimizing and maximizing personal productivity, where it seems if you can’t measure (let alone remember) the impact of a book in your life then it wasn’t worth reading.</p>
<p>I don’t believe that, but I never quite had the words for expressing why I don’t believe that. Dave’s articulation hit pretty close.</p>
<p>Then a couple days later my wife sent me this quote from Ralph Waldo Emerson:</p>
<blockquote>
<p>I cannot remember the books I've read any more than the meals I have eaten; even so, they have made me.</p>
</blockquote>
<p>YES!</p>
<p>Damn, great writers are sO gOOd wITh wORdz, amirite?</p>
<p>Emerson articulates with acute brevity something I couldn’t suss out in my own thoughts, let alone put into words. It makes me jealous.</p>
<p>Anyhow, I wanted to write this down to reinforce remembering it.</p>
<p>And in a similar vein for the online world: I cannot remember the blog posts I’ve read any more than the meals I’ve eaten; even so, they’ve made me.</p>
<p>It’s a good reminder to be mindful of my content diet — you are what you <del>eat</del> read, even if you don’t always remember it.</p>
<h2 id="update-2024-04-12">Update 2024-04-12</h2>
<p><a href="https://mastodon.online/@halas#.">@halas@mastodon.social</a> shared this story in response, which I really liked:</p>
<blockquote>
<p>At the university I had a professor who had a class with us in the first year and then in the second. At the beginning of the second year’s classes he asked us something from the material of previous year. When met with silence he nodded thoughtfully and said: “Education is something you have even if you don't remember anything”</p>
</blockquote>
<p>I love stories that stick with people like that, e.g. “something a teacher told me once...”</p>
<p><a href="https://blog.jim-nielsen.com/2024/immeasurable-impact/">Some impact is immeasurable</a>.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Airlines required to refund passengers for canceled, delayed flights (652 pts)]]></title>
            <link>https://abcnews.go.com/Politics/airlines-give-automatic-refunds-canceled-flights-delayed-3/story?id=109573733</link>
            <guid>40150639</guid>
            <pubDate>Wed, 24 Apr 2024 22:29:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://abcnews.go.com/Politics/airlines-give-automatic-refunds-canceled-flights-delayed-3/story?id=109573733">https://abcnews.go.com/Politics/airlines-give-automatic-refunds-canceled-flights-delayed-3/story?id=109573733</a>, See on <a href="https://news.ycombinator.com/item?id=40150639">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="prism-article-body"><p>Good news for airline travelers: the Department of Transportation on Wednesday announced it is rolling out new rules that will require airlines to automatically give cash refunds to passengers for canceled and significantly delayed flights.</p><p>"This is a big day for America's flying public," said Transportation Secretary Pete Buttigieg at a Wednesday morning news conference. Buttigieg said the new rules -- which require prompt refunds -- are the biggest expansion of passenger rights in the department's history.</p><p>Airlines can no longer decide how long a delay must be before a refund is issued. Under the new DOT rules, the delays covered would be more than three hours for domestic flights and more than six hours for international flights, the agency said.</p><p>This includes tickets purchased directly from airlines, travel agents and third-party sites such as Expedia and Travelocity.</p><p>The DOT rules lay out that passengers will be "entitled to a refund if their flight is canceled or significantly changed, and they do not accept alternative transportation or travel credits offered."</p><div data-testid="prism-inline-image"><figure data-testid="prism-figure"><img alt="PHOTO: A person walks through the terminal as planes remain at gates at Ronald Reagan Washington National Airport in Arlington, Va., Wednesday, Jan. 11, 2023." data-testid="prism-image" draggable="false" src="https://i.abcnewsfe.com/a/2b5ef9d0-6caa-4597-893b-48a6a419bb31/airport-file-ap-jef-240424_1713963231114_hpMain.jpg"><figcaption><div data-testid="prism-caption"><p><span data-testid="prism-truncate"><span><span>A person walks through the terminal as planes remain at gates at Ronald Reagan Washington National Airport in Arlington, Va., Wednesday, Jan. 11, 2023.</span></span></span></p><p><span>Patrick Semansky/AP, FILE</span></p></div></figcaption></figure></div><p>DOT will also require airlines to give cash refunds if your bags are lost and not delivered within 12 hours.</p><p>The refunds must be issued within seven days, according to the new DOT rules, and must be in cash unless the passenger chooses another form of compensation. Airlines can no longer issue refunds in forms of vouchers or credits when consumers are entitled to receive cash.</p><p>Airlines will have six months to comply with the new rules.</p><div data-testid="prism-inline-image"><figure data-testid="prism-figure"><img alt="PHOTO: U.S. Secretary of Transportation Pete Buttigieg speaks at a press conference at the Reagan National Airport on April 24, 2024." data-testid="prism-image" draggable="false" src="https://i.abcnewsfe.com/a/22e4aad0-0b73-4e97-a784-ba8ba3bf64af/airport-abc-ml-240424_1713973025448_hpMain_16x9.jpg"><figcaption><div data-testid="prism-caption"><p><span data-testid="prism-truncate"><span><span>U.S. Secretary of Transportation Pete Buttigieg speaks at a press conference at the Reagan National Airport on April 24, 2024.</span></span></span></p><p><span>ABC News, POOL</span></p></div></figcaption></figure></div><p>"Passengers deserve to get their money back when an airline owes them -- without headaches or haggling," Buttigieg said in a statement.</p><p>The DOT said it is also working on rules related to family seating fees, enhancing rights for wheelchair-traveling passengers for safe and dignified travel and mandating compensation and amenities if flights are delayed or canceled by airlines.</p><p>Buttigieg said the DOT is also protecting airline passengers from being surprised by hidden fees -- a move he estimates will have Americans billions of dollars every year.</p><section data-testid="prism-collection"><header><p><h2>Related Stories</h2></p></header></section><p><a data-testid="prism-linkbase" href="https://www.transportation.gov/briefing-room/biden-harris-administration-announces-final-rule-requiring-automatic-refunds-airline" target="_blank">The DOT rules</a> include that passengers will receive refunds for extra services paid for and not provided, such as Wi-Fi, seat selection or inflight entertainment.</p><p>The rules come after the agency <a data-testid="prism-linkbase" href="https://abcnews.go.com/International/southwest-airlines-fined-record-140-million-dot-2022/story?id=105733507" target="_blank">handed Southwest Airlines a record $140 million fine</a> for its <a data-testid="prism-linkbase" href="https://abcnews.go.com/Business/stranded-southwest-customers-details-exhaustive-efforts-home-amid/story?id=95848764" target="_blank">operational meltdown</a> during the 2022 holiday travel season.</p><p>Buttigieg said Southwest's fine sets a "new standard" for airlines and passenger rights.</p><p>"To be clear, we want the airline sector to thrive. It is why we put so much into helping them survive the pandemic and honestly it's why we're being so rigorous on passenger protection," he said.</p><p>Buttigieg reiterated that refund requirements are already the standard for airlines, but the new DOT rules hold the airlines to account and makes sure passengers get the "refunds that are owed to them."</p><p>"Airlines are not enthusiastic about us holding them to a higher standard," Buttigieg said, adding that he "knows they will be able to adapt to this."</p><p>Airlines for America, the trade association for the country's leading passenger and cargo airlines, told ABC News in a statement that its members "offer a range of options -- including fully refundable fares." Is said consumers are "given the choice of refundable ticket options with terms and conditions that best fit their needs at first search results."</p><p>The group said the 11 largest U.S. airlines issued $43 billion in customer refunds from 2020 through 2023 nearly $11 billion in refunds just last year.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bicycle use now exceeds car use in Paris (125 pts)]]></title>
            <link>https://english.elpais.com/lifestyle/2024-04-24/the-cycling-revolution-in-paris-continues-bicycle-use-now-exceeds-car-use.html</link>
            <guid>40150545</guid>
            <pubDate>Wed, 24 Apr 2024 22:20:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://english.elpais.com/lifestyle/2024-04-24/the-cycling-revolution-in-paris-continues-bicycle-use-now-exceeds-car-use.html">https://english.elpais.com/lifestyle/2024-04-24/the-cycling-revolution-in-paris-continues-bicycle-use-now-exceeds-car-use.html</a>, See on <a href="https://news.ycombinator.com/item?id=40150545">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-dtm-region="articulo_cuerpo"><p>It’s rush hour on Rue de Rivoli, one of the main arteries of the French capital. The bicycles pass one after another in quick succession, ringing their bell when a pedestrian crosses without looking. Five years ago, it was cars that monopolized this three-kilometer axis that runs in front of Paris City Hall and <a href="https://english.elpais.com/culture/2023-07-01/the-restitution-of-art-to-its-origins.html">the Louvre Museum</a>. Not anymore. Two-wheel transportation has prevailed, favored by a paradigm shift in urban mobility. The cycling revolution, promoted by local authorities, is beginning to bear fruit: according to a recent study by the Paris Région Institute, a public agency, bicycles already surpass cars as a means of transportation in the interior of Paris, accounting for 11.2% of trips compared to 4.3%. A similar trend is seen in trips between the suburbs and the city center: 14% are made by bicycle and 11.8% by car.</p><p>Rue de Rivoli, with its two-way cycle lanes and its dedicated lane for buses and taxis, is perhaps one of the most emblematic examples of the change that the city has experienced in recent years. But it’s not the only one. The perpendicular Boulevard de Sébastopol has become the route most frequented by cyclists, with figures that usually exceed 10,000 daily trips, according to the count kept by the association Paris en Selle.</p><p>When it is sunny, the density can be so high that traffic jams sometimes occur, and the narrowness of the lane causes friction between bikes, creating moments of tension. City officials led by Mayor Anne Hidalgo, a Socialist, have tried to remedy this situation by building other bike lanes on parallel streets.</p><p>From north to south and east to west, the map of the capital has been filled with infrastructure that gives the bicycle a privileged place. Paris has more than 1,000 kilometers (621 miles) of facilities adapted for cyclists, including more than 300 km (186 m) of bike lanes and 52 km (32 m) of provisional lanes, according to the latest available municipal data, from 2021. The rest are lanes shared with cars or lanes only marked with paint on the ground.</p><p>By 2026, local officials want the entire city to be suitable for two-wheel transportation. To this end, it has set aside $250 million, $100 million more than in Hidalgo’s first term. This summer’s Olympic Games will serve as an accelerator of this new “bike plan,” with routes that will allow access to the Olympic venues.</p><p>But there is still some way to go. The Paris en Selle association warns that only 27% of the “bike plan” has been carried out despite the fact that 62% of Hidalgo’s second term in office has already elapsed. The Deputy Mayor of Paris for Transportation, David Belliard, acknowledges that there are delays, but does not lose hope. Progress is noticeable.</p><p>In some thoroughfares, the number of bikes already surpasses vehicles. Between 2022 and 2023, the use of bike lanes doubled at peak times, according to data collected by the capital’s 128 counters. The goal is to create a network of cycling paths that run along the busiest metro lines, to unclog public transit and offer an equally fast and safe alternative for commuters.</p><p>The number of people who travel by bicycle has increased exponentially. Vélib, the municipal urban bicycle rental service, has increased its fleet with 3,000 new bikes since March. Edmée Doroszlai, a 62-year-old Parisian, still remembers the first time she started riding on two wheels in the early 1980s. “It was monstrous, almost impossible and very dangerous,” she says from the center of Paris, with her bike at her side.</p><p>“There is also a big change in how men behave when they see a woman on a bike,” she adds, alluding to the normalization of its use. The presence of adapted infrastructure, she confirms, has encouraged her to use it more, as have many families who travel on cycle paths with small children.</p><p>“We still have to go further,” Belliard insisted in an interview with BFMTV earlier this month. The councilor was reacting to the study by the Paris Région Institute, the regional urban planning and environment agency, which indicated that 11.2% of trips in Paris were made by bike between 2022 and 2023, compared to 4.3% by car. The change in trend is clear. In 2021, two wheels still represented 5.6% of trips, while cars were 9%, according to Belliard.</p><figure><span><img alt="Notre Dame" decoding="auto" height="262" srcset="https://imagenes.elpais.com/resizer/v2/QUBHQ6LEH2CCT3MOQ2GH7ABCC4.jpg?auth=9815ecb7d31b0dfd6408c2465c80f0735bd2e8c3f36692e516985133b830715d&amp;width=414 414w,https://imagenes.elpais.com/resizer/v2/QUBHQ6LEH2CCT3MOQ2GH7ABCC4.jpg?auth=9815ecb7d31b0dfd6408c2465c80f0735bd2e8c3f36692e516985133b830715d&amp;width=828 640w,https://imagenes.elpais.com/resizer/v2/QUBHQ6LEH2CCT3MOQ2GH7ABCC4.jpg?auth=9815ecb7d31b0dfd6408c2465c80f0735bd2e8c3f36692e516985133b830715d&amp;width=980 1000w,https://imagenes.elpais.com/resizer/v2/QUBHQ6LEH2CCT3MOQ2GH7ABCC4.jpg?auth=9815ecb7d31b0dfd6408c2465c80f0735bd2e8c3f36692e516985133b830715d&amp;width=1960 1960w" width="414" sizes="(min-width:1199px) 1155px,(min-width:1001px) calc(100vw - 44px),(min-width:768px) 767px, 100vw" src="https://imagenes.elpais.com/resizer/v2/QUBHQ6LEH2CCT3MOQ2GH7ABCC4.jpg?auth=9815ecb7d31b0dfd6408c2465c80f0735bd2e8c3f36692e516985133b830715d&amp;width=414" loading="lazy"></span><figcaption><span>Bike path on the banks of the Seine, in Paris.</span><span>Ciclistas y 'pic-nics' en la orilla sur del Sena, en París (Jon Hicks)</span></figcaption></figure><p>In addition to surpassing the car as a means of travel within Paris, the research indicates that residents of the nearest suburbs also prefer to use the bike, with 14% of trips compared to 11.8% for cars. The figures are even better during rush hour, when 18.9% of trips are made by bike and only 6.6% by car. Travel on foot, however, continues to lead mobility within the municipality with 53%, followed by those made on public transit, with 30%. The study was carried out with 3,337 residents of the capital region who agreed to be fitted with a GPS tracker.</p><p>The bike gradually gained popularity during the public transist strike that paralyzed the capital in December 2019, in protest of <a href="https://english.elpais.com/international/2023-03-17/france-braces-for-more-unrest-after-macron-passes-pension-reform-by-decree.html">President Emmanuel Macron’s pension reform</a>. But it was also prominent <a href="https://english.elpais.com/society/2023-05-20/millions-ditched-cars-for-bikes-during-the-pandemic-these-cities-want-the-habit-to-stick.html">after the Covid confinement</a> in 2020, when the city tested the so-called “coronapistes,” temporary cycling lanes that progressively became permanent. Like Rivoli’s.</p><h3>Better connections with neighborhoods</h3><p>“The network is very good,” says Arnaud Faure, 31, co-owner of the Bivouac Cycles bicycle repair shop in Saint Ouen, a banlieue (suburb) in the north of the city. He has been in the French capital for two years and every day he travels 13 km (8 miles) to get to work and again the same to get back home. He says that almost all of his journey is along bike paths. But he cites two drawbacks. On one hand, the lack of safe parking, a determining factor for bicycle use. On the other hand, the fact that “just like in big cities, traffic is dense and can sometimes be dangerous.”</p><p>In 12 years, car traffic has decreased by 40% in Paris, according to City Hall. “But these rapid changes in habits have been accompanied by tension” in the streets, the mayor has admitted. “It takes time for everyone to find their place and feel safe,” she added, following road regulations that seek to raise awareness about the shared use of public space. Last summer, posters appeared throughout the city reminding everyone that pedestrians have the priority and that the speed limit for cars is 30 km/h (18 mph).</p><p>The city’s plan includes increasing the number of parking spaces for bicycles. The goal is to build more than 130,000 new spots. “Parking at train stations must be developed on a massive scale,” stresses Aymeric Cotard, 29, a member of the association Mieux se déplacer à bicyclette [Better to get around by bike]. One of the large projects that should be completed this year, with 1,200 spaces, is located just behind the Gare du Nord, one of the busiest stations in France. For Cotard, however, it will be insufficient. In <a href="https://english.elpais.com/international/2023-02-27/we-didnt-know-if-they-were-being-taken-to-another-country-where-do-stolen-dutch-bikes-go.html">the Dutch city</a> of Utrecht, the station has 12,500 spaces for bikes.</p><p>The idea is that people who live in the suburbs and take the train daily to work will also use the bicycle once they arrive in Paris. It is one of the main challenges of the coming years, along with facilitating continuous journeys between the capital and its suburbs. “This requires the banlieue cities to do their job and the city of Paris to also improve its entrances, which are inhospitable and unpleasant by bike,” warns Cotard. In addition, it is necessary to provide infrastructure for a flow of cyclists that will be even greater in the future.</p><p>The process takes time and has encountered some opposition. But the morphology of the city is changing, adapting to the bike. And, with it, its resilience to the effects of climate change.</p><p><i>Sign up for </i><a href="https://plus.elpais.com/newsletters/lnp/1/333/?lang=en"><i><u>our weekly newsletter</u></i></a> <i>to get more English-language news coverage from EL PAÍS USA Edition</i></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Magic Numbers (159 pts)]]></title>
            <link>https://exple.tive.org/blarg/2024/04/24/magic-numbers/</link>
            <guid>40149446</guid>
            <pubDate>Wed, 24 Apr 2024 20:50:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://exple.tive.org/blarg/2024/04/24/magic-numbers/">https://exple.tive.org/blarg/2024/04/24/magic-numbers/</a>, See on <a href="https://news.ycombinator.com/item?id=40149446">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-6105" role="article" itemscope="" itemtype="http://schema.org/BlogPosting">

	<header>

		
		

	</header>

	<section itemprop="articleBody">

		<p><strong>April 24, 2024</strong></p>

		<p>The <a href="https://en.wikipedia.org/wiki/Maximum_transmission_unit">Maximum Transmission Unit</a> – MTU – of an <a href="https://en.wikipedia.org/wiki/Ethernet">Ethernet</a> frame is 1500 bytes.</p>
<p>1500 bytes is a bit out there as numbers go, or at least it seems that way if you touch computers for a living. It’s not a power of two or anywhere close, it’s <em>suspiciously</em> base-ten-round, and computers don’t care all that much about base ten, so how did we get here? </p>
<p>Well, today I learned that the size of an Ethernet header – 36 bytes – comes from the fact that MTU plus Ethernet header is 1536 bytes, which is 12288 bits, which takes 2^12 microseconds to transmit at 3Mb/second, because the <a href="https://en.wikipedia.org/wiki/Xerox_Alto">Xerox Alto</a> computer for which Ethernet was invented had a internal data path that ran at 3Mhz, so the interface could <em>just</em> write the bits into the Alto’s memory at the precise speed at which they arrived, saving the very-expensive-then cost of extra silicon for an interface or any buffering hardware. </p>
<p>Now, “we need to pick just the right magic number <em>here</em> so we can take data straight off the wire and blow it directly into the memory of this specific machine over <em>there</em>” is to any modern sensibilities insane. It’s obviously, dangerously insane. But back when the idea of network security didn’t exist because computers barely existed and networks mostly didn’t exist and unvetted and unsanctioned access to those networks definitely didn’t exist, I bet it seemed like a very reasonable tradeoff.</p>
<p>It really is amazing how many of the things we sort of ambiently accept as standards today, if we even realize we’re making that decision at all, are what they are only because some now-esoteric property of the now-esoteric hardware on which the tech was first invented let the inventors save a few bucks.</p>

		
	</section> <!-- end article section -->

	

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[IBM to Acquire HashiCorp, Inc for $6.4 billion (355 pts)]]></title>
            <link>https://newsroom.ibm.com/2024-04-24-IBM-to-Acquire-HashiCorp-Inc-Creating-a-Comprehensive-End-to-End-Hybrid-Cloud-Platform</link>
            <guid>40149136</guid>
            <pubDate>Wed, 24 Apr 2024 20:24:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newsroom.ibm.com/2024-04-24-IBM-to-Acquire-HashiCorp-Inc-Creating-a-Comprehensive-End-to-End-Hybrid-Cloud-Platform">https://newsroom.ibm.com/2024-04-24-IBM-to-Acquire-HashiCorp-Inc-Creating-a-Comprehensive-End-to-End-Hybrid-Cloud-Platform</a>, See on <a href="https://news.ycombinator.com/item?id=40149136">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wd_move_content_up">

<p>$6.4 billion acquisition adds suite of leading hybrid and multi-cloud lifecycle management products to help clients grappling with today's AI-driven application growth and complexity</p><p>HashiCorp's capabilities to drive significant synergies across multiple strategic growth areas for IBM, including Red Hat, watsonx, data security, IT automation and Consulting</p><p>As a part of IBM, HashiCorp is expected to accelerate innovation and enhance its go-to-market, growth and monetization initiatives</p><p>Transaction expected to be accretive to Adjusted EBITDA within the first full year, post close, and free cash flow in year two</p>
<p>Apr 24, 2024</p>

			
		
</div><div wd_resize="formatNews" wd_print_url="https://newsroom.ibm.com/2024-04-24-IBM-to-Acquire-HashiCorp-Inc-Creating-a-Comprehensive-End-to-End-Hybrid-Cloud-Platform?printable=1"><p>,  /<a href="http://www.prnewswire.com/" target="_blank">PRNewswire</a>/ -- IBM (NYSE: <a href="http://www.ibm.com/investor" rel="nofollow" target="_blank">IBM</a>) and HashiCorp Inc. (NASDAQ: HCP), a leading multi-cloud infrastructure automation company, today announced they have entered into a definitive agreement under which IBM will acquire HashiCorp for <span>$35</span> per share in cash, representing an enterprise value of <span>$6.4 billion</span>. HashiCorp's suite of products provides enterprises with extensive Infrastructure Lifecycle Management and Security Lifecycle Management capabilities to enable organizations to automate their hybrid and multi-cloud environments. Today's announcement is a continuation of IBM's deep focus and investment in hybrid cloud and AI, the two most transformational technologies for clients today.</p>

<p><a href="https://mma.prnewswire.com/media/2319830/IBM_LOGO_1.html" rel="nofollow" target="_blank"><img alt="IBM Corporation logo. (PRNewsfoto/IBM Corporation)" src="https://mma.prnewswire.com/media/2319830/IBM_LOGO_1.jpg" title="IBM Corporation logo. (PRNewsfoto/IBM Corporation)"> </a></p>

<p>"Enterprise clients are wrestling with an unprecedented expansion in infrastructure and applications across public and private clouds, as well as on-prem environments. The global excitement surrounding generative AI has exacerbated these challenges and CIOs and developers are up against dramatic complexity in their tech strategies," said <span>Arvind Krishna</span>, IBM chairman and chief executive officer. "HashiCorp has a proven track record of enabling clients to manage the complexity of today's infrastructure and application sprawl. Combining IBM's portfolio and expertise with HashiCorp's capabilities and talent will create a comprehensive hybrid cloud platform designed for the AI era."</p>

<p>The rise of cloud-native workloads and associated applications is driving a radical expansion in the number of cloud workloads enterprises are managing. In addition, generative AI deployment continues to grow alongside traditional workloads. As a result, developers are working with increasingly heterogeneous, dynamic, and complex infrastructure strategies. This represents a massive challenge for technology professionals.</p>

<p>HashiCorp's capabilities enable enterprises to use automation to deliver lifecycle management for infrastructure and security, providing a system of record for the critical workflows needed for hybrid and multi-cloud environments. HashiCorp's Terraform is the industry standard for infrastructure provisioning in these environments. HashiCorp's offerings help clients take a cloud-agnostic, and highly interoperable approach to multi-cloud management, and complement IBM's commitment to industry collaboration (including deep and expanding partnerships with hyperscale cloud service providers), developer communities, and open-source hybrid cloud and AI innovation.</p>

<p>"Our strategy at its core is about enabling companies to innovate in the cloud, while providing a consistent approach to managing cloud at scale. The need for effective management and automation is critical with the rise of multi-cloud and hybrid cloud, which is being accelerated by today's AI revolution," said <span>Armon Dadgar</span>, HashiCorp co-founder and chief technology officer. "I'm incredibly excited by today's news and to be joining IBM to accelerate HashiCorp's mission and expand access to our products to an even broader set of developers and enterprises."</p>

<p>"Today is an exciting day for our dedicated teams across the world as well as the developer communities we serve," said <span>Dave McJannet</span>, HashiCorp chief executive officer. "IBM's leadership in hybrid cloud along with its rich history of innovation, make it the ideal home for HashiCorp as we enter the next phase of our growth journey. I'm proud of the work we've done as a standalone company, I am excited to be able to help our customers further, and I look forward to the future of HashiCorp as part of IBM."</p>

<p><b>Transaction Rationale</b></p>

<ul type="disc">
	<li><b>Strong Strategic Fit – </b>The acquisition of HashiCorp by IBM creates a comprehensive end-to-end hybrid cloud platform built for AI-driven complexity. The combination of each company's portfolio and talent will deliver clients extensive application, infrastructure and security lifecycle management capabilities</li>
	<li><b>Accelerates growth in key focus areas – </b>Upon close, HashiCorp is expected to drive significant synergies for IBM, including across multiple strategic growth areas like Red Hat, watsonx, data security, IT automation and Consulting. For example, the powerful combination of Red Hat's Ansible Automation Platform's configuration management and Terraform's automation will simplify provisioning and configuration of applications across hybrid cloud environments. The two companies also anticipate an acceleration of HashiCorp's growth initiatives by leveraging IBM's world-class go-to-market strategy, scale, and reach, operating in more than 175 countries across the globe</li>
	<li><b>Expands Total Addressable Market (TAM) – </b>The acquisition will create the opportunity to deliver more comprehensive hybrid and multi-cloud offerings to enterprise clients. HashiCorp's offerings, combined with IBM and Red Hat, will give clients a platform to automate the deployment and orchestration of workloads across evolving infrastructure including hyperscale cloud service providers, private clouds and on-prem environments. This will enhance IBM's ability to address the total cloud opportunity, which according to IDC had a TAM of <span>$1.1 trillion</span> in 2023, with a compound annual growth rate in the high teens through 2027.<sup>1</sup></li>
	<li><b>Attractive Financial Opportunity – </b>The transaction will accelerate IBM's growth profile over time driven by go-to-market and product synergies. This growth combined with operating efficiencies, is expected to achieve substantial near-term margin expansion for the acquired business. It is anticipated that the transaction will be accretive to Adjusted EBITDA within the first full year, post close, and free cash flow in year two.</li>
</ul>

<p>HashiCorp boasts a roster of more than 4,400 clients, including Bloomberg, Comcast, Deutsche Bank, GitHub, J.P Morgan Chase, Starbucks and Vodafone. HashiCorp's offerings have widescale adoption in the developer community and are used by 85% of the Fortune 500. Their community products across infrastructure and security were downloaded more than 500 million times in HashiCorp's FY2024 and include:</p>

<ul type="disc">
	<li><b>Terraform</b> – provides organizations with a single workflow to provision their cloud, private datacenter, and SaaS infrastructure and continuously manage infrastructure throughout its lifecycle</li>
	<li><b>Vault</b> – provides organizations with identity-based security to automatically authenticate and authorize access to secrets and other sensitive data</li>
	<li><b>Additional products</b> – <i>Boundary</i> for secure remote access;<i> Consul</i> for service-based networking; <i>Nomad</i> for workload orchestration; <i>Packer</i> for building and managing images as code; and <i>Waypoint</i> internal developer platform</li>
</ul>

<p><b>Transaction Details</b></p>

<p>Under the terms of the agreement, IBM will acquire HashiCorp for <span>$35</span> per share in cash, or <span>$6.4 billion</span> enterprise value, net of cash. HashiCorp will be acquired with available cash on hand.</p>

<p>The boards of directors of IBM and HashiCorp have both approved the transaction. The acquisition is subject to approval by HashiCorp shareholders, regulatory approvals and other customary closing conditions.</p>

<p>The Company's largest shareholders and investors, who collectively hold approximately 43% of the voting power of&nbsp;HashiCorp's outstanding common stock, entered into a voting agreement with IBM pursuant to which each has agreed to vote all of their common shares in favor of the transaction and against any alternative transactions.</p>

<p>The transaction is expected to close by the end of 2024.</p>

<p>____________________<br>
<sup>1</sup> The total cloud opportunity is the sum of the cloud-directed spends across Hardware, IT services and SW for Private and Public cloud implementation, sourced from IDC's Worldwide Black Book Live Edition, <span>March 2024</span> (V1 2024)</p>

<p><b>Conference Call Details</b></p>

<p>IBM's regular quarterly earnings conference call is scheduled to begin at <span>5:00 p.m. ET</span>, today. The Webcast may be accessed <a href="https://www.ibm.com/investor/events/earnings-1q24" rel="nofollow" target="_blank">here</a>. Presentation charts will be available shortly before the Webcast.</p>

<p><b>About IBM</b></p>

<p>IBM is a leading provider of global hybrid cloud and AI, and consulting expertise. We help clients in more than 175 countries capitalize on insights from their data, streamline business processes, reduce costs and gain the competitive edge in their industries. Thousands of government and corporate entities in critical infrastructure areas such as financial services, telecommunications and healthcare rely on IBM's hybrid cloud platform and Red Hat OpenShift to affect their digital transformations quickly, efficiently and securely. IBM's breakthrough innovations in AI, quantum computing, industry-specific cloud solutions and consulting deliver open and flexible options to our clients. All of this is backed by IBM's legendary commitment to trust, transparency, responsibility, inclusivity and service. Visit&nbsp;<a href="http://www.ibm.com/" rel="nofollow" target="_blank">www.ibm.com</a>&nbsp;for more information.&nbsp;</p>

<p><b>About HashiCorp</b></p>

<p>HashiCorp&nbsp;is The Infrastructure Cloud™ company, helping organizations automate multi-cloud and hybrid environments with Infrastructure Lifecycle Management and Security Lifecycle Management. HashiCorp&nbsp;offers The Infrastructure Cloud on the HashiCorp&nbsp;Cloud Platform (HCP) for managed cloud services, as well as self-hosted enterprise offerings and community source-available products. The company is headquartered in <span>San Francisco, California</span>. For more information, visit&nbsp;<a href="https://urldefense.proofpoint.com/v2/url?u=http-3A__hashicorp.com&amp;d=DwMFaQ&amp;c=BSDicqBQBDjDI9RkVyTcHQ&amp;r=W9dONwI1yR8TY6fdJkjNwdlDQU2ROvWbv1mlvkWQFLs&amp;m=uOTnwadDTxZ2XD2uC6bDCFPG-9K-Oq5GBVfeuYs3n7-_Z1xbsLo_2585JrS2L788&amp;s=RF6C-_LsY0GUJ3MnM2K_hfDsjYfnI-WCPo4lNlnulgE&amp;e=" rel="nofollow" target="_blank">HashiCorp.com</a>.</p>

<p><b>Press Contacts:</b></p>

<p>IBM:<br>
<span>Tim Davidson</span>, 914-844-7847<br>
<a href="mailto:tfdavids@us.ibm.com" rel="nofollow" target="_blank">tfdavids@us.ibm.com</a></p>

<p>HashiCorp:<br>
<span>Matthew Sherman</span> / <span>Jed Repko</span> / <span>Haley Salas</span> / <span>Joycelyn Barnett</span><br>
<span>Joele Frank</span>, Wilkinson Brimmer Katcher<br>
212-355-4449</p>



<p><i><b>Additional Information and Where to Find It</b></i></p>

<p><i>HashiCorp, Inc. ("HashiCorp"), the members of HashiCorp's board of directors and certain of HashiCorp's executive officers are participants in the solicitation of proxies from stockholders in connection with the pending acquisition of HashiCorp (the "Transaction"). HashiCorp plans to file a proxy statement (the "Transaction Proxy Statement") with the Securities and Exchange Commission (the "SEC") in connection with the solicitation of proxies to approve the Transaction. <span>David McJannet</span>, <span>Armon Dadgar</span>, <span>Susan St. Ledger</span>, <span>Todd Ford</span>, <span>David Henshall</span>, <span>Glenn Solomon</span> and <span>Sigal Zarmi</span>, all of whom are members of HashiCorp's board of directors, and <span>Navam Welihinda</span>, HashiCorp's chief financial officer, are participants in HashiCorp's solicitation. Information regarding such participants, including their direct or indirect interests, by security holdings or otherwise, will be included in the Transaction Proxy Statement and other relevant documents to be filed with the SEC in connection with the Transaction. Additional information about such participants is available under the captions "Board of Directors and Corporate Governance," "Executive Officers" and "Security Ownership of Certain Beneficial Owners and Management" in HashiCorp's definitive proxy statement in connection with its 2023 Annual Meeting of Stockholders (the "2023 Proxy Statement"), which was filed with the SEC on <span>May 17, 2023</span> (and is available at&nbsp;<a href="https://urldefense.proofpoint.com/v2/url?u=https-3A__www.sec.gov_ix-3Fdoc-3D_Archives_edgar_data_1720671_000114036123025250_ny20008192x1-5Fdef14a.htm&amp;d=DwMGaQ&amp;c=BSDicqBQBDjDI9RkVyTcHQ&amp;r=W9dONwI1yR8TY6fdJkjNwdlDQU2ROvWbv1mlvkWQFLs&amp;m=WIP1VyxuvBGNlzTUaYuNxHpbet03ywNI-NapdbhVOxO7G4LhtR2egnoPZFg5wgFk&amp;s=DAxP0uH2PZLVIrXRiK8JS2ywGdYGNx-kvMHxAEWkP_4&amp;e=" rel="nofollow" target="_blank">https://www.sec.gov/ix?doc=/Archives/edgar/data/1720671/000114036123025250/ny20008192x1_def14a.htm</a>). To the extent that holdings of HashiCorp's securities have changed since the amounts printed in the 2023 Proxy Statement, such changes have been or will be reflected on Statements of Change in Ownership on Form 4 filed with the SEC (which are available at&nbsp;<a href="https://urldefense.proofpoint.com/v2/url?u=https-3A__www.sec.gov_cgi-2Dbin_browse-2Dedgar-3Faction-3Dgetcompany-26CIK-3D0001720671-26type-3D-26dateb-3D-26owner-3Donly-26count-3D40-26search-5Ftext-3D&amp;d=DwMGaQ&amp;c=BSDicqBQBDjDI9RkVyTcHQ&amp;r=W9dONwI1yR8TY6fdJkjNwdlDQU2ROvWbv1mlvkWQFLs&amp;m=WIP1VyxuvBGNlzTUaYuNxHpbet03ywNI-NapdbhVOxO7G4LhtR2egnoPZFg5wgFk&amp;s=bqavEZgqjNge6kAvbmk0zLhMXTAYmIjA5rzwhQaJDd8&amp;e=" rel="nofollow" target="_blank">https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&amp;CIK=0001720671&amp;type=&amp;dateb=&amp;owner=only&amp;count=40&amp;search_text=</a>). Information regarding HashiCorp's transactions with related persons is set forth under the caption "Related Person Transactions" in the 2023 Proxy Statement. Certain illustrative information regarding the payments to that may be owed, and the circumstances in which they may be owed, to HashiCorp's named executive officers in a change of control of HashiCorp is set forth under the caption "Executive Compensation—Potential Payments upon Termination or Change in Control" in the 2023 Proxy Statement. With respect to Ms. St. Ledger, certain of such illustrative information is contained in the Current Report on Form 8-K filed with the SEC on <span>June 7, 2023</span> (and is available at&nbsp;<a href="https://urldefense.proofpoint.com/v2/url?u=https-3A__www.sec.gov_ix-3Fdoc-3D_Archives_edgar_data_1720671_000162828023021270_hcp-2D20230607.htm&amp;d=DwMGaQ&amp;c=BSDicqBQBDjDI9RkVyTcHQ&amp;r=W9dONwI1yR8TY6fdJkjNwdlDQU2ROvWbv1mlvkWQFLs&amp;m=WIP1VyxuvBGNlzTUaYuNxHpbet03ywNI-NapdbhVOxO7G4LhtR2egnoPZFg5wgFk&amp;s=4QQvgxl7VrRT-9dgZy45Vw0gBhmWz7KH8fzaGjGwkIk&amp;e=" rel="nofollow" target="_blank">https://www.sec.gov/ix?doc=/Archives/edgar/data/1720671/000162828023021270/hcp-20230607.htm</a>).&nbsp;Promptly after filing the definitive Transaction Proxy Statement with the SEC, HashiCorp will mail the definitive Transaction Proxy Statement and a WHITE proxy card to each stockholder entitled to vote at the special meeting to consider the Transaction. STOCKHOLDERS ARE URGED TO READ THE TRANSACTION PROXY STATEMENT (INCLUDING ANY AMENDMENTS OR SUPPLEMENTS THERETO) AND ANY OTHER RELEVANT DOCUMENTS THAT HASHICORP WILL FILE WITH THE SEC WHEN THEY BECOME AVAILABLE BECAUSE THEY WILL CONTAIN IMPORTANT INFORMATION. Stockholders may obtain, free of charge, the preliminary and definitive versions of the Transaction Proxy Statement, any amendments or supplements thereto, and any other relevant documents filed by HashiCorp with the SEC in connection with the Transaction at the SEC's website (<a href="https://urldefense.proofpoint.com/v2/url?u=http-3A__www.sec.gov&amp;d=DwMGaQ&amp;c=BSDicqBQBDjDI9RkVyTcHQ&amp;r=W9dONwI1yR8TY6fdJkjNwdlDQU2ROvWbv1mlvkWQFLs&amp;m=WIP1VyxuvBGNlzTUaYuNxHpbet03ywNI-NapdbhVOxO7G4LhtR2egnoPZFg5wgFk&amp;s=97Mk6TtDEGohehH043KUy50rAX9jXPHlNPxdtGwcYPc&amp;e=" rel="nofollow" target="_blank">http://www.sec.gov</a>). Copies of HashiCorp's definitive Transaction Proxy Statement, any amendments or supplements thereto, and any other relevant documents filed by HashiCorp with the SEC in connection with the Transaction will also be available, free of charge, at HashiCorp's investor relations website (<a href="https://urldefense.proofpoint.com/v2/url?u=https-3A__ir.hashicorp.com_&amp;d=DwMGaQ&amp;c=BSDicqBQBDjDI9RkVyTcHQ&amp;r=W9dONwI1yR8TY6fdJkjNwdlDQU2ROvWbv1mlvkWQFLs&amp;m=WIP1VyxuvBGNlzTUaYuNxHpbet03ywNI-NapdbhVOxO7G4LhtR2egnoPZFg5wgFk&amp;s=zgti-5JjrLH_7Ja9Wdc81ipMwWNQ-4K0YQu2LW5qZnw&amp;e=" rel="nofollow" target="_blank">https://ir.hashicorp.com/</a>), or by emailing HashiCorp's investor relations department (<a href="mailto:ir@hashicorp.com" rel="nofollow" target="_blank">ir@hashicorp.com</a>).</i></p>

<p><i><b>Forward-Looking Statements</b></i></p>

<p><i>Certain statements contained in this communication may be characterized as forward-looking under the Private Securities Litigation Reform Act of 1995. These statements involve a number of risks, uncertainties and other factors that could cause actual results to differ materially.</i></p>

<p><i>Statements in this communication regarding IBM and HashiCorp that are forward-looking may include statements regarding: (i) the Transaction; (ii) the expected timing of the closing of the Transaction; (iii) considerations taken into account in approving and entering into the Transaction; (iv) the anticipated benefits to, or impact of, the Transaction on IBM's and HashiCorp's businesses; and (v) expectations for IBM and HashiCorp following the closing of the Transaction. There can be no assurance that the Transaction will be consummated.</i></p>

<p><i>Risks and uncertainties that could cause actual results to differ materially from those indicated in the forward-looking statements, in addition to those identified above, include: (i) the possibility that the conditions to the closing of the Transaction are not satisfied, including the risk that required approvals from HashiCorp's stockholders for the Transaction or required regulatory approvals to consummate the Transaction are not obtained, on a timely basis or at all; (ii) the occurrence of any event, change or other circumstance that could give rise to a right to terminate the Transaction, including in circumstances requiring HashiCorp to pay a termination fee; (iii) possible disruption related to the Transaction to IBM's and HashiCorp's current plans, operations and business relationships, including through the loss of customers and employees; (iv) the amount of the costs, fees, expenses and other charges incurred by IBM and HashiCorp related to the Transaction; (v) the risk that IBM's or HashiCorp's stock price may fluctuate during the pendency of the Transaction and may decline if the Transaction is not completed; (vi) the diversion of IBM and HashiCorp management's time and attention from ongoing business operations and opportunities; (vii) the response of competitors and other market participants to the Transaction; (viii) potential litigation relating to the Transaction; (ix) uncertainty as to timing of completion of the Transaction and the ability of each party to consummate the Transaction; and (x) other risks and uncertainties detailed in the periodic reports that IBM and HashiCorp filed with the SEC, including IBM's and HashiCorp's respective Annual Reports on Form 10-K.&nbsp; All forward-looking statements in this communication are based on information available to IBM and HashiCorp as of the date of this communication, and, except as required by law, IBM and HashiCorp do not assume any obligation to update the forward-looking statements provided to reflect events that occur or circumstances that exist after the date on which they were made.</i></p>

<p>SOURCE IBM</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[IBM to buy HashiCorp in $6.4B deal (502 pts)]]></title>
            <link>https://www.reuters.com/markets/deals/ibm-buy-hashicorp-64-billion-deal-expand-cloud-software-2024-04-24/</link>
            <guid>40149095</guid>
            <pubDate>Wed, 24 Apr 2024 20:21:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/markets/deals/ibm-buy-hashicorp-64-billion-deal-expand-cloud-software-2024-04-24/">https://www.reuters.com/markets/deals/ibm-buy-hashicorp-64-billion-deal-expand-cloud-software-2024-04-24/</a>, See on <a href="https://news.ycombinator.com/item?id=40149095">Hacker News</a></p>
Couldn't get https://www.reuters.com/markets/deals/ibm-buy-hashicorp-64-billion-deal-expand-cloud-software-2024-04-24/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Eric Schmidt-backed Augment, a GitHub Copilot rival, launches out of stealth (130 pts)]]></title>
            <link>https://techcrunch.com/2024/04/24/eric-schmidt-backed-augment-a-github-copilot-rival-launches-out-of-stealth-with-252m/</link>
            <guid>40149071</guid>
            <pubDate>Wed, 24 Apr 2024 20:19:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2024/04/24/eric-schmidt-backed-augment-a-github-copilot-rival-launches-out-of-stealth-with-252m/">https://techcrunch.com/2024/04/24/eric-schmidt-backed-augment-a-github-copilot-rival-launches-out-of-stealth-with-252m/</a>, See on <a href="https://news.ycombinator.com/item?id=40149071">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p id="speakable-summary">AI is supercharging coding — and developers are embracing it.</p>
<p>In a recent StackOverflow poll, 44% of software engineers said that they <a href="https://stackoverflow.blog/2023/06/14/hype-or-not-developers-have-something-to-say-about-ai/" target="_blank" rel="noopener">use AI tools as part of their development processes</a> now and 26% plan to soon. Gartner <a href="https://www.gartner.com/en/newsroom/press-releases/2024-04-11-gartner-says-75-percent-of-enterprise-software-engineers-will-use-ai-code-assistants-by-2028" target="_blank" rel="noopener">estimates</a> that over half of organizations are currently piloting or have already deployed AI-driven coding assistants, and that 75% of developers will use coding assistants in some form by 2028.</p>
<p>Ex-Microsoft software developer Igor Ostrovsky <span>believes that soon, there won’t be a developer who </span><em>doesn’</em><em>t&nbsp;</em><span>use AI in their workflows.&nbsp;</span>“Software engineering remains a difficult and all-too-often tedious and frustrating job, particularly at scale,” he told TechCrunch. “AI can improve software quality, team productivity and help restore the joy of programming.”</p>
<p>So Ostrovsky <span>decided to build the AI-powered coding platform that he himself would want to use.</span></p>
<p>That platform is <a href="https://www.augmentcode.com/" target="_blank" rel="noopener">Augment</a>, and on Wednesday it <a href="https://www.augmentcode.com/blog/augment-inc-raises-227-million">emerged</a> from stealth with $252 million in funding at a near-unicorn ($977 million) post-money valuation. With investments from former Google CEO Eric Schmidt and VCs including Index Ventures, Sutter Hill Ventures, Lightspeed Venture Partners, Innovation Endeavors and Meritech Capital, Augment aims to shake up the still-nascent market for generative AI coding technologies.</p>
<p>“Most companies are dissatisfied with the programs they produce and consume; software is too often fragile, complex and expensive to maintain with development teams bogged down with long backlogs for feature requests, bug fixes, security patches, integration requests, migrations and upgrades,” Ostrovsky said. “Augment has both the best team and recipe for empowering programmers and their organizations to deliver high-quality software quicker.”</p>
<p>Ostrovsky spent nearly seven years at Microsoft before joining Pure Storage, a startup developing flash data storage hardware and software products, as a founding engineer. While at Microsoft, Ostrovsky worked on components of Midori, a next-generation operating system the company never released but whose concepts have made their way into other Microsoft projects over the last decade.</p>
<p>In 2022, Ostrovsky and Guy Gur-Ari, previously an AI research scientist at Google, teamed up to create Augment’s MVP. To fill out the startup’s executive ranks, Ostrovsky and Gur-Ari brought on Scott Dietzen, ex-CEO of Pure Storage, and Dion Almaer, formerly a Google engineering director and a VP of engineering at Shopify.</p>
<p>Augment remains a strangely hush-hush operation.</p>
<p>In our conversation, Ostrovsky wasn’t willing to say much about the user experience or even the generative AI models driving Augment’s features (whatever they may be) — save that Augment is using fine-tuned “industry-leading” open models of some sort.</p>
<p>He did say how Augment plans to make money: standard software-as-a-service subscriptions. Pricing and other details will be revealed later this year, Ostrovsky added, closer to Augment’s planned GA release.</p>
<p>“Our funding provides many years of runway to continue to build what we believe to be the best team in enterprise AI,” he said. “We’re accelerating product development and building out Augment’s product, engineering and go-to-market functions as the company gears up for rapid growth.”</p>
<p>Rapid growth is perhaps the best shot Augment has at making waves in an increasingly cutthroat industry.</p>
<p>Practically every tech giant offers its own version of an AI coding assistant. Microsoft has GitHub Copilot, which is by far the firmest entrenched with over 1.3 million paying individual and 50,000 enterprise customers as of February. Amazon has AWS’ CodeWhisperer. And Google has Gemini Code Assist, recently rebranded from Duet AI for Developers.</p>
<p>Elsewhere, there’s a torrent of coding assistant startups: <a href="https://techcrunch.com/2023/02/06/magic-dev-code-generating-startup-raises-23m/" data-mrf-link="https://techcrunch.com/2023/02/06/magic-dev-code-generating-startup-raises-23m/">Magic</a><span>,&nbsp;</span><a href="https://techcrunch.com/2023/11/08/code-generating-ai-platform-tabnine-nabs-25m-investment/" data-mrf-link="https://techcrunch.com/2023/11/08/code-generating-ai-platform-tabnine-nabs-25m-investment/">Tabnine</a><span>,&nbsp;</span><a href="https://techcrunch.com/2023/11/16/codegen-raises-new-capital-llm-automation-for-software-dev/" data-mrf-link="https://techcrunch.com/2023/11/16/codegen-raises-new-capital-llm-automation-for-software-dev/">Codegen</a>, <a href="https://techcrunch.com/2024/01/29/refact-launches-to-make-code-generating-ai-more-appealing-to-enterprises/">Refact</a>, <a href="https://techcrunch.com/2023/10/10/tabbyml-github-copilot-alternative-raises-3-2-million/">TabbyML</a>, <a href="https://techcrunch.com/2023/11/02/sweep-aims-to-automate-basic-dev-tasks-using-large-language-models/">Sweep</a>,<span>&nbsp;</span><a href="https://techcrunch.com/2023/12/12/laredo-wants-to-use-gen-ai-to-automate-dev-work/" data-mrf-link="https://techcrunch.com/2023/12/12/laredo-wants-to-use-gen-ai-to-automate-dev-work/">Laredo</a> and <span>Cognition (which <a href="https://www.theinformation.com/articles/six-month-old-ai-coding-startup-valued-at-2-billion-by-founders-fund?offer=rtsu-engagement-24&amp;utm_campaign=RTSU+-+Cognition%2FFou&amp;utm_content=3915&amp;utm_medium=email&amp;utm_source=cio&amp;utm_term=2713" target="_blank" rel="noopener">reportedly</a> just raised $175 million), </span>to name a few. <span><a href="https://techcrunch.com/2023/06/21/harness-releases-generative-ai-assistant-to-help-ease-developer-workloads/">Harness</a></span> and <span>JetBrains, which developed the Kotlin programming language, recently </span><a href="https://techcrunch.com/2023/12/07/as-a-new-ai-driven-coding-assistant-is-launched-the-battle-for-ai-mindshare-moves-to-developers/">released</a><span> their <a href="https://techcrunch.com/2023/12/07/as-a-new-ai-driven-coding-assistant-is-launched-the-battle-for-ai-mindshare-moves-to-developers/">own</a>. So did&nbsp;<a href="https://techcrunch.com/2024/03/20/sentrys-ai-powered-autofix-helps-developers-quickly-debug-and-fix-their-production-code/">Sentry</a> (albeit with more of a cybersecurity bent).&nbsp;</span></p>
<p>Can they all — plus Augment now — do business harmoniously together? It seems unlikely. Eye-watering compute costs alone make the AI coding assistant business a challenging one to maintain. Overruns related to training and serving models forced generative AI coding startup <a href="https://techcrunch.com/2022/12/10/with-kites-demise-can-generative-ai-for-code-succeed/" data-mrf-link="https://techcrunch.com/2022/12/10/with-kites-demise-can-generative-ai-for-code-succeed/">Kite</a> to shut down in December 2022. <a href="https://aibusiness.com/nlp/github-copilot-loses-20-a-month-per-user" target="_blank" rel="noopener">Even Copilot loses money</a>, to the tune of around $20 to $80 a month per user, according to The Wall Street Journal.</p>
<p>Ostrovsky implies that there’s momentum behind Augment already; he claims that “h<span>undreds” of software developers across “dozens” of companies, including payment startup <a href="https://techcrunch.com/2023/06/06/eric-schmidt-keeta-cross-border-payments-fintech/">Keeta</a> (which is also Eric Schmidt-backed), are using Augment in early access. But will the uptake sustain? That’s the million-dollar question, indeed.</span></p>
<p>I also wonder if Augment has made any steps toward solving the technical setbacks plaguing code-generating AI, particularly around vulnerabilities.</p>
<p>An analysis by GitClear, the developer of the code analytics tool of the same name, <a href="https://visualstudiomagazine.com/Articles/2024/01/25/copilot-research.aspx">found</a> that coding assistants are resulting in more mistaken code being pushed to codebases, creating headaches for software maintainers. Security researchers have warned that generative coding tools can <a href="https://www.techtarget.com/searchsecurity/news/366571117/GitHub-Copilot-replicating-vulnerabilities-insecure-code" target="_blank" rel="noopener">amplify</a> existing bugs and exploits in projects. And Stanford researchers have <a href="https://www.theregister.com/2022/12/21/ai_assistants_bad_code/" target="_blank" rel="noopener">found</a> that developers who accept code recommendations from AI assistants tend to produce less secure code.</p>
<p>Then there’s copyright to worry about.</p>
<p>Augment’s models were undoubtedly trained on publicly available data, like all generative AI models — some of which may’ve been copyrighted or under a restrictive license. Some vendors have argued that <a href="https://www.copyright.gov/fair-use/#:~:text=Fair%20use%20is%20a%20legal,protected%20works%20in%20certain%20circumstances." target="_blank" rel="noopener" data-mrf-link="https://www.copyright.gov/fair-use/#:~:text=Fair%20use%20is%20a%20legal,protected%20works%20in%20certain%20circumstances.">fair use doctrine</a> shields them from copyright claims while at the same time rolling out tools to mitigate potential infringement. But that hasn’t stopped coders from <a href="https://www.finnegan.com/en/insights/articles/insights-from-the-pending-copilot-class-action-lawsuit.html" target="_blank" rel="noopener" data-mrf-link="https://www.finnegan.com/en/insights/articles/insights-from-the-pending-copilot-class-action-lawsuit.html">filing</a> class action lawsuits over what they allege are open licensing and IP violations.</p>
<p>To all this, Ostrovsky says: “Current AI coding assistants don’t adequately understand the programmer’s intent, improve software quality nor facilitate team productivity, and they don’t properly protect intellectual property. Augment’s engineering team boasts deep AI and systems expertise. We’re poised to bring AI coding assistance innovations to developers and software teams.”</p>
<p>Augment, which is based in Palo Alto, has around 50 employees; Ostrovsky expects that number to double by the end of the year.</p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta Reports First Quarter 2024 Results (125 pts)]]></title>
            <link>https://investor.fb.com/investor-news/press-release-details/2024/Meta-Reports-First-Quarter-2024-Results/default.aspx</link>
            <guid>40148998</guid>
            <pubDate>Wed, 24 Apr 2024 20:12:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://investor.fb.com/investor-news/press-release-details/2024/Meta-Reports-First-Quarter-2024-Results/default.aspx">https://investor.fb.com/investor-news/press-release-details/2024/Meta-Reports-First-Quarter-2024-Results/default.aspx</a>, See on <a href="https://news.ycombinator.com/item?id=40148998">Hacker News</a></p>
Couldn't get https://investor.fb.com/investor-news/press-release-details/2024/Meta-Reports-First-Quarter-2024-Results/default.aspx: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The Rise and Fall of the LAN Party (207 pts)]]></title>
            <link>https://aftermath.site/lan-party-merritt-k-book-read-only-memory-rom</link>
            <guid>40148833</guid>
            <pubDate>Wed, 24 Apr 2024 19:56:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aftermath.site/lan-party-merritt-k-book-read-only-memory-rom">https://aftermath.site/lan-party-merritt-k-book-read-only-memory-rom</a>, See on <a href="https://news.ycombinator.com/item?id=40148833">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Today it is trivially easy to play games on a computer with one’s friends over the internet. I can log into a game like <em>Fortnite</em>, party up with a squad and chat in either the game’s built-in voice protocol or use another service like Discord, and be in a game within minutes. I can do this from my computer, a game console, or even my phone. But before the wide availability of high-speed internet, things were more complicated.</p><hr><p><em>The following is excerpted from the book </em>LAN Party, <em>by Merritt K.&nbsp;<a rel="noreferrer noopener" href="https://readonlymemory.com/shop/book/lan-party/" target="_blank">The book is available for purchase now.</a></em></p><hr><p>In the 1990s and early 2000s, three-dimensional graphics in videogames were becoming more and more complex. Titles like 1998’s <em>Half-Life</em> pushed games in more cinematic directions, with lighting and textures that went beyond anything released even a few years earlier. Other first-person shooters (FPS) like <em>Counter-Strike</em> (itself originally a mod for <em>Half-Life</em>) and <em>Unreal Tournament</em> built on the work of earlier titles like <em>DOOM</em>, <em>Wolfenstein 3D</em>, and <em>Duke Nukem 3D</em>. Many of these titles were designed for multiplayer action. However, the typically low network speeds of the period meant that these games, unlike slower-paced and less graphically intensive strategy games, were nearly unplayable over an internet connection. In this moment, in which communications technology was being outpaced by graphical power, the LAN (local area network) party was born.</p><p>The term itself conjures up strong sensory memories for those who were there—sweaty bodies packed into a basement or convention hall, a&nbsp;dozen CPUs noticeably warming the space, the heft of a CRT monitor being maneuvered into position. For those on the outside, these were scenes of incomprehension or ridicule. But for those who were there, the LAN party was a singular event, a&nbsp;defining social occasion of the early 21st century. It represented the last gasps of the isolated gamer stereotype, ushering in an age in which gaming was not only mainstream, but a social, networked activity.</p><p>Of course, people had been bringing together computers for some time prior to the Y2K era. (The demoparty, in which participants cracked code to evade copyright protection and share artistic creations, was an important antecedent to the LAN party.) But it was in this particular period—in the United States, at least—that the social and technological configuration of the LAN party became a true phenomenon. Participants hauled their monitors, towers, and peripherals to a central location, where they would set up their machines and connect them through a network switch. This&nbsp;local connection enabled speeds far beyond those available to the average internet user, enabling lag-free gameplay, not to mention high-speed file sharing at a time when downloading or transporting large files could be an extremely onerous task.</p><p>LAN parties ranged from small, private gatherings to massive, multi-day events with thousands of participants, such as QuakeCon, DreamHack, The Gathering, and Euskal Encounter. Both types are represented in this book, though the focus is more on the former. As accessible digital photography was emerging around the same time as LAN parties—and perhaps because computer enthusiasts were more likely than the general population to own gadgets like digital cameras—these events are extraordinarily well documented.</p><h6>Gaming at the Turn of the Millennium</h6><p>What do these photos show? Young people—primarily young men—goofing off and playing games, of course. But it’s more than that. Technological and cultural artifacts of the era are strewn throughout, illustrating trends, obsessions, and now-forgotten relics. One of my favorite photos in the book depicts, among other things: a Windows XP error dialogue box; a beige Microsoft keyboard; a disposable film camera; a pair of wraparound headphones that I and nearly everyone else I knew owned in the early 2000s; and a pile of burned CD-Rs, one of which has “<em>StarCraft</em>” written on it in permanent marker. Junk foods and caffeinated beverages appear frequently in the collection, with the energy drink Bawls Guarana in particular popping up again and again. While Mountain Dew&nbsp;has since acquired a reputation as the gamer beverage of choice, Bawls was certainly the unofficial sponsoring drink of the LAN party.</p><p>Some games feature prominently in the mythos of the LAN party and in the photos collected in this book. The aforementioned <em>Counter-Strike</em> and <em>Unreal Tournament</em> are two of them, being primarily team-based first-person shooters that laid the groundwork for the ongoing popularity of the genre. These games are best played with minimum latency; they each support large numbers of players and feature quick rounds, which made them big hits at LAN parties. Certain maps in these games have become iconic, celebrated and recreated in other titles—for <em>Counter-Strike</em>, Dust II (de_dust2) is probably the best-known, while for <em>Unreal Tournament</em>, it’s Facing Worlds (CTF-Face). Both of these maps are so significant, so well-remembered and influential that they have their own Wikipedia pages.</p><p>Other first-person shooters popular at turn-of-the-century LAN parties include <em>Starsiege: Tribes</em>, <em>Tom Clancy’s Rainbow Six: Rogue Spear</em>, and id’s <em>Quake</em> series. <em>Quake III Arena</em> was released in 1999 and eschewed a single-player narrative component, instead focusing on highspeed multiplayer battles. The engine developed for the game was later used for a number of other successful games, including the awkwardly titled <em>Star Wars Jedi Knight II: Jedi Outcast</em>, which contained a robust multiplayer mode that players built on by creating elaborate rituals around lightsaber duels.</p><p>Of course, not all of the games played at LAN parties were first-person shooters. Real-time strategy (RTS) games were also quite popular in the early 2000s, with Blizzard’s <em>StarCraft</em> (1998) and <em>Warcraft III : Reign of Chaos</em> (2002) celebrated for their intricate design, customizability, and multiplayer capabilities. These games, like many 3FPS games of the era, came with tools that made it easy for players to create their own content. This led to a boom in hobbyist developer creativity that in turn generated entirely new genres of videogames such as the multiplayer online battle arena (MOBA), later refined by immensely successful titles like <em>League of Legends</em> and <em>Dota 2</em>. Other well-loved RTS games of the era include Westwood’s <em>Command &amp; Conquer</em> franchise, Ensemble’s <em>Age of Empires</em> series, and Creative Assembly’s <em>Total War</em> titles.</p><p>When it came to console gaming in the Y2K era, the Nintendo 64 set a new standard for multiplayer games with the introduction of four controller ports in 1996, and most subsequent machines followed its lead. Microsoft released the original Xbox in 2001, and its launch title, <em>Halo: Combat Evolved</em>, kicked off a new generation of console-based first-person shooters. In addition to featuring split-screen multiplayer, the Xbox supported a form of LAN play called <em>System Link</em>, which allowed up to sixteen players to play games like <em>Halo</em> simultaneously. The <em>Halo</em> series and Xbox also happened to be instrumental in the decline of the LAN party—more on that later.</p><figure><img alt="" src="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?w=1440&amp;h=810&amp;crop=1" srcset="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=480,270&amp;quality=75 480w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=960,540&amp;quality=75 960w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=640,360&amp;quality=75 640w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=1280,720&amp;quality=75 1280w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=768,432&amp;quality=75 768w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=1536,864&amp;quality=75 1536w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=1024,576&amp;quality=75 1024w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=2048,1152&amp;quality=75 2048w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=1280,720&amp;quality=75 1280w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=2560,1440&amp;quality=75 2560w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=1440,810&amp;quality=75 1440w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=2880,1620&amp;quality=75 2880w" sizes="100vw" loading="lazy"><figcaption><span>Pg 26: © Erwin de Gier Amsterdam (The Netherlands), 1998</span></figcaption></figure><h6>Y2K Cultural Trends</h6><p>Beyond games, LAN party photos also demonstrate some other cultural trends of the period. The late 90s and early 2000s saw the rise of the nu metal musical genre, which included artists like Limp Bizkit, Slipknot, Korn, and Linkin Park. These groups harnessed feelings of isolation and teenage angst and fused rock instrumentation with hip-hop style and delivery, creating a kind of music that was beloved and reviled in equal measure for its direct, unselfconscious emotional pleas, macho posturing, and nihilistic themes.</p><p>Simultaneously, anime and Japanese subcultures were becoming more popular in the US due to the introduction of shows like Dragon Ball Z and Sailor Moon on American children’s networks. The growth of the internet, too, was making it easier than ever for young people interested in anime and other niche topics to share their interests and learn more about them on message boards and webrings. Anime and nu metal often went together in the form of the animated music video (AMV), where fans would stitch together clips of their favorite shows as makeshift music videos for their favorite angsty tracks.</p><p>The influence of anime and nu metal, as well as the mainstreaming of hip-hop to white suburban audiences, the dark guns-and-leather aesthetics of the films Blade and The Matrix, skater culture, and more can be seen in many of the photos in this book—in the clothing people are wearing, the posters on their walls, and desktop backgrounds. What has today become massively mainstream—anime, gaming, comic books, and so on—was, in the early 2000s, still on the fringes of normalcy. Remember: Iron Man didn’t kick off the Marvel Cinematic Universe until 2008. Crunchyroll, the anime streaming platform, didn’t exist until 2006.</p><p>In the same vein, this period also saw the birth of meme culture online. Early internet memes like “Mr. T Ate My Balls,” “All your base are belong to us,” and l33tspeak spread through forums like Something Awful and Flash portals such as Newgrounds, giving young internet users a kind of shared secret language. In the late 2000s, as social networks like Facebook gained traction among college students and more and more people got online, meme culture gradually became mass culture.</p><h6>Creative Chaos</h6><p>In addition to the cultural trends of the time, these pictures also show people bringing computers into places where they didn’t traditionally belong. In the 1990s and early 2000s, bulky desktop computers often lived in home offices or even dedicated “computer rooms.” Some lucky few kids at that time had their own personal computers in their bedrooms, but in my experience, this was rare.</p><p>During LAN parties, participants brought computers into garages, basements, living rooms, and other spaces, setting them up on dining-room tables, TV trays, kitchen counters, and any available surface. The raw excitement on the part of the participants is evident in the sometimes absurd lengths they went to in order to participate in LAN parties—computer towers crammed between cushions in the back seat of a van to ensure their safe transportation across town; cables crisscrossing the floor to connect machines; CRT monitors balanced haphazardly around the room.</p><p>It’s this passion, I think, which partly explains the appeal of these photos—even to those who weren’t around at the time. This book is full of images of people being truly excited about computers and playing games on them. There’s a sense, in looking at these photos, that these people were on the cusp of something—even if they weren’t necessarily aware of it at the time. Since the home computer boom of the 1990s and the introduction of high-speed internet in the 2000s, the omnipresence of computers and communication technology has rendered them mundane to many people. It’s almost quaint to see people so genuinely thrilled to be playing PC games with their friends when, today, doing so is an everyday occurrence.</p><p>Making a LAN party happen took work. It took physical effort, technical know-how, and a willingness to hack things together. The range of computer equipment depicted in the photos is testament to that. Yes, there are the standard massive, beige CRT monitors associated with the period, but we see computer towers ranging from stock models in the same color to complex monstrosities built by enthusiastic geeks. This was before Apple’s sleek industrial design took over the tech world, before LED lights were standard on pretty much any gaming PC. It was the era of user-driven customization, and LAN parties are perfectly emblematic of that time.</p><h6>The Decline Of The LAN Party</h6><p>LAN parties occurred throughout the 1990s, peaked (in the US, at least) in the early-mid-2000s and began to decline in the early 2010s. Of course, people do still throw LAN parties, especially people who grew up with them, but their heyday has long since passed. So what killed the LAN party? The most obvious answer is the widespread introduction of communication infrastructure that made it possible to play games like first-person shooters over the internet with low latency.</p><p>LAN parties were a creation of circumstance, which withered away once it was no longer a necessity to transport computers to the same physical space in order to get an ideal gaming experience. It’s certainly true that it is now more convenient than ever for many people to play games online with strangers or friends. But convenience in technology often comes with a commensurate loss of control on the part of users.</p><p>In 2004, Bungie released <em>Halo 2</em> for the Xbox. The game built on the original’s landmark success by introducing online play through Microsoft’s Xbox Live service. It went on to become the most popular Xbox Live title of all time and was played until the discontinuation of the service on the original Xbox in 2010.</p><figure><img alt="" src="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?w=1440&amp;h=810&amp;crop=1" srcset="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=480,270&amp;quality=75 480w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=960,540&amp;quality=75 960w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=640,360&amp;quality=75 640w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=1280,720&amp;quality=75 1280w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=768,432&amp;quality=75 768w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=1536,864&amp;quality=75 1536w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=1024,576&amp;quality=75 1024w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=2048,1152&amp;quality=75 2048w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=1280,720&amp;quality=75 1280w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=2560,1440&amp;quality=75 2560w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=1440,810&amp;quality=75 1440w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=2880,1620&amp;quality=75 2880w" sizes="100vw" loading="lazy"><figcaption><span>Pgs 70-71: © Kiel Oleson/Electronox  Lee’s Summit, MO (USA), 2002</span></figcaption></figure><p>The Xbox Live service was easy to use, popularizing the method of allowing players to party up with their friends and enter into matchmaking queues. This was a major shift from the then prevalent system of presenting players with a list of servers to join, each hosted by different players and groups. As well as being a more seamless experience emphasizing ease of use, this new model also represented a move away from user control. Matchmaking is now the dominant mode of playing multiplayer games online. There are certainly advantages inherent in it—developers can try to create fairer matchups based on skill and players can keep their ranks and reputations across games—but it also puts players at the mercy of a company’s algorithms and servers.</p><p>Many of the most popular multiplayer videogames today are entirely server-side, meaning that they cannot be played without connecting to the game’s servers. This is advantageous for developers and publishers, who can ensure that players have the latest updates, prevent cheating, and create large worlds in which numerous players can be online and interacting at once. But it also means that control of game experiences has shifted significantly away from users. Even games that have offline components often do not have any kind of peer-to-peer or private server functionality, meaning that it is impossible for a group to play them together in a LAN environment.</p><p>The way we buy and play games has also changed. Today, digital platforms like Steam and the Epic Game Store allow players to purchase titles without leaving their homes. But digital copies of games, and their management through these platforms, mean that the old practices of burning copies of games or sharing legal “spawn installations” of games to facilitate multiplayer experiences are less and less possible.</p><p>Thus, the story that LAN parties died because they were simply an obsolete social structure is a little too straightforward. It may be true that most people would prefer to play games in the comfort of their own home rather than transporting expensive and bulky equipment elsewhere, but technological and economic forces also contributed to the decline of LAN events. The fact is that the shift to digital, producer-owned environments in every aspect of gaming—from sales to play—tremendously benefits the corporations publishing and selling games, sometimes at the expense of those purchasing and playing them.</p><h6>Looking Back</h6><p>In the photos collected in this book, then, we can see some things that have been lost, or at least forgotten—an adventurous spirit around computing and a world in which ownership of software and play belonged more to individuals than corporations. I don’t mean to suggest that LAN parties were utopian spaces. They were, of course, mostly—but&nbsp;certainly not exclusively—attended and organized by young white men, and even many of the larger events were male-dominated spaces, hostile to women. Nonetheless, from my position, decades later, I can’t help but look fondly on images of LAN parties. At a time when communications technology paradoxically seems to produce a sense of disconnection for many people through algorithmically generated echo chambers and the indexing of personal worth to follower counts or likes, seeing people literally coming together with and around computers is almost aspirational.</p><p>It’s tempting to see the mainstreaming of gaming and tech as a uniformly positive trend. And certainly, more people having access to these things and feeling like they belong in associated spaces is a good thing. But there are always trade-offs. The ubiquity of, and widespread access to, tech has come with an unprecedented rise in surveillance through our devices, a loss of control over our personal data, and a sense of alienation fostered by tech companies who want to own as much of our attention as possible.</p><p>For people like me, who grew up during the 1990s and 2000s, it can sometimes feel like the exciting period of the internet and computing is over. Pictures of LAN parties represent that early era of the internet, when it was a place that you visited rather than a parallel layer of reality. As we’ve watched that mysterious, alluring, and perilous internet get progressively fenced off, paywalled, and centralized by a few massive corporations, some of us are beginning to reflect on our relationship to&nbsp;it.</p><p>Perhaps this thing that was so important to us in our youth, that we’ve stubbornly stuck with despite sweeping structural changes, is no longer so relevant to our lives. Maybe it’s time to start figuring out new ways to use the internet and computers to enrich our world. And maybe LAN parties can offer one model for that.</p><p><em>Excerpted from </em>LAN PARTY: Inside the Multiplayer Revolution<em>, by merritt k</em></p><p><em>Text © 2023 merritt k&nbsp;</em></p><p><em>© 2024 Thames &amp; Hudson Ltd, London</em></p><p><em>Reprinted by permission of Thames &amp; Hudson Inc, </em><a href="http://www.thamesandhudsonusa.com/" target="_blank" rel="noreferrer noopener"><em>www.thamesandhudsonusa.com</em></a></p><figure><img alt="" src="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?w=1440&amp;h=810&amp;crop=1" srcset="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=480,270&amp;quality=75 480w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=960,540&amp;quality=75 960w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=640,360&amp;quality=75 640w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=1280,720&amp;quality=75 1280w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=768,432&amp;quality=75 768w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=1536,864&amp;quality=75 1536w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=1024,576&amp;quality=75 1024w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=2048,1152&amp;quality=75 2048w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=1280,720&amp;quality=75 1280w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=2560,1440&amp;quality=75 2560w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=1440,810&amp;quality=75 1440w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=2880,1620&amp;quality=75 2880w" sizes="100vw" loading="lazy"><figcaption><span>Pg 118: © Robert McNeil  Brisbane (Australia), 2006</span></figcaption></figure></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[McKinsey Under Criminal Investigation over Opioid-Related Consulting (358 pts)]]></title>
            <link>https://www.wsj.com/articles/mckinsey-faces-criminal-probe-over-opioid-related-consulting-a3f816d4</link>
            <guid>40148729</guid>
            <pubDate>Wed, 24 Apr 2024 19:47:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/articles/mckinsey-faces-criminal-probe-over-opioid-related-consulting-a3f816d4">https://www.wsj.com/articles/mckinsey-faces-criminal-probe-over-opioid-related-consulting-a3f816d4</a>, See on <a href="https://news.ycombinator.com/item?id=40148729">Hacker News</a></p>
Couldn't get https://www.wsj.com/articles/mckinsey-faces-criminal-probe-over-opioid-related-consulting-a3f816d4: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Nearsightedness is at epidemic levels – and the problem begins in childhood (211 pts)]]></title>
            <link>https://theconversation.com/nearsightedness-is-at-epidemic-levels-and-the-problem-begins-in-childhood-225255</link>
            <guid>40148707</guid>
            <pubDate>Wed, 24 Apr 2024 19:44:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theconversation.com/nearsightedness-is-at-epidemic-levels-and-the-problem-begins-in-childhood-225255">https://theconversation.com/nearsightedness-is-at-epidemic-levels-and-the-problem-begins-in-childhood-225255</a>, See on <a href="https://news.ycombinator.com/item?id=40148707">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Myopia, or the need for corrected vision to focus or see objects at a distance, has become a lot more common in recent decades. <a href="https://doi.org/10.1038/519276a">Some even consider myopia</a>, also known as nearsightedness, an epidemic.</p>

<p>Optometry researchers estimate that <a href="http://dx.doi.org/10.1016/j.ophtha.2016.01.006">about half of the global population</a> will need corrective lenses to offset myopia by 2050 if current rates continue – up from 23% in 2000 and <a href="https://myopiainstitute.org/myopia/#">less than 10% in some countries</a>. </p>

<p>The associated health care costs are huge. In the United States alone, spending on corrective lenses, eye tests and related expenses <a href="https://www.doi.org/10.3389/fmed.2021.718724">may be as high as US$7.2 billion a year</a>.</p>

<p>What explains the rapid growth in myopia? </p>

<p><a href="https://scholar.google.com/citations?user=fExMMysAAAAJ&amp;hl=en">I’m a vision scientist</a> who has studied visual perception and perceptual defects. To answer that question, first let’s examine what causes myopia – and what reduces it.</p>

<figure>
            <p><iframe data-src="https://www.youtube.com/embed/ezP3oCRaBBQ?wmode=transparent&amp;start=0" frameborder="0" allowfullscreen="" width="100%" height="400"></iframe></p>
            <figcaption><span>A closer look at myopia.</span></figcaption>
          </figure>

<h2>How myopia develops</h2>

<p>While having two myopic parents does mean you’re more likely to be nearsighted, <a href="https://doi.org/10.1007/978-981-13-8491-2_5">there’s no single myopia gene</a>. That means the causes of myopia are more behavioral than genetic. </p>

<p>Optometrists have learned a great deal about the progression of myopia by <a href="https://www.scientificamerican.com/article/space-perception-in-the-chick/">studying visual development in infant chickens</a>. They do so by putting little helmets on baby chickens. Lenses on the face of the helmet cover the chicks’ eyes and are adjusted to affect how much they see.</p>

<p>Just like in humans, if visual input is distorted, a chick’s eyes grow too large, <a href="https://doi.org/10.1016/j.cub.2006.02.065">resulting in myopia</a>. And it’s progressive. Blur leads to eye growth, which causes more blur, which makes the eye grow even larger, and so on. </p>

<p>Two recent studies featuring extensive surveys of children and their parents provide strong support for the idea that an <a href="https://doi.org/10.1186/s12889-022-14377-1">important driver of the uptick</a> in myopia is that <a href="https://doi.org/10.1111/aos.14980">people are spending more time</a> focusing on objects immediately in front of our eyes, whether a screen, a book or a drawing pad. The more time we spend focusing on something within arm’s length of our faces, dubbed “near work,” the greater the odds of having myopia. </p>

<p>So as much as <a href="https://www.cbc.ca/news/canada/excessive-screen-use-eyes-myopia-1.6815857">people might blame new technologies like smartphones</a> and too much “screen time” for hurting our eyes, the truth is even activities as valuable as reading a good book can affect your eyesight.</p>

<h2>Outside light keeps myopia at bay</h2>

<p>Other research has shown that this unnatural eye growth can be interrupted by sunlight.</p>

<p>A 2022 study, for example, found that myopia rates <a href="https://doi.org/10.1186/s12889-022-14377-1">were more than four times greater</a> for children who didn’t spend much time outdoors – say, once or twice a week – compared with those who were outside daily. At the same time, kids who spent more than three hours a day while not at school reading or looking at a screen close-up were four times more likely to have myopia than those who spent an hour or less doing so. </p>

<p>In another paper, from 2012, researchers <a href="https://www.doi.org/10.1016/j.ophtha.2012.04.020">conducted a meta-analysis of seven studies</a> that compared duration of time spent outdoors with myopia incidence. They also found that more time spent outdoors was associated with lower myopia incidence and progression. The odds of developing myopia dropped by 2% for each hour spent outside per week. </p>

<p>Other researchers have reported similar effects and argued for <a href="https://doi.org/10.1159/000501937">much more time outdoors</a> and changes in early-age schooling to reduce myopia prevalence. </p>

<figure>
            <p><iframe data-src="https://www.youtube.com/embed/LAkFtka3UFw?wmode=transparent&amp;start=0" frameborder="0" allowfullscreen="" width="100%" height="400"></iframe></p>
            <figcaption><span>‘Why so many people need glasses now.’</span></figcaption>
          </figure>

<h2>What’s driving the epidemic</h2>

<p>That still doesn’t explain why it’s on the rise so rapidly.</p>

<p>Globally, a <a href="https://www.doi.org/10.1097/MD.0000000000014777">big part of this is due to the rapid development</a> and industrialization of countries in East Asia over the last 50 years. Around that time, young people began spending more time in classrooms reading and focusing on other objects very close to their eyes and less time outdoors. </p>

<p>This is also what researchers <a href="https://doi.org/10.1111/opo.12879">observed in the North American Arctic</a> after World War II, when schooling was mandated for Indigenous people. Myopia rates for Inuit went from the single digits before the 1950s to upwards of 70% by the 1970s as all children began attending schools for the first time.</p>

<p>Countries in Western Europe, <a href="https://doi.org/10.1001/archophthalmol.2009.303">North America</a> and Australia have shown <a href="https://doi.org/10.1097/OPX.0000000000000069">increased rates of myopia</a> in recent years but nothing approaching what has been observed recently in <a href="https://doi.org/10.1016/j.preteyeres.2017.09.004">China, Japan, Singapore and a few other East Asian countries</a>. The two main factors identified as leading to increased myopia are <a href="https://www.chinasmack.com/chinese-school-desks-with-railings-prevent-near-sightedness">increased reading</a> and other activities that require focusing on an object close to one’s eyes and a <a href="https://doi.org/10.1371/journal.pone.0181772">reduction in time spent outdoors</a>.</p>

<p>The surge in myopia cases will likely have its worst effects 40 or 50 years from now because <a href="https://doi.org/10.1186/s12889-022-14377-1">it takes time</a> for the young people being diagnosed with nearsightedness now to experience the most severe vision problems.</p>

<h2>Treating myopia</h2>

<p>Fortunately, just a few minutes a day with glasses or contact lenses that correct for blur <a href="https://doi.org/10.1016/s0042-6989(98)00304-6">stops the progression of myopia</a>, which is why early vision testing and vision correction are important to limit the development of myopia. Eye checks for children are mandatory in some countries, <a href="https://www.orthoptics.org.uk/patients-and-public/childrens-vision-screening/">such as the U.K.</a> and <a href="http://en.moe.gov.cn/news/press_releases/202404/t20240408_1124412.html">now China</a>, as well as <a href="https://nationalcenter.preventblindness.org/vision-screening-requirements-by-state/">most U.S. states</a>.</p>

<p>People with with high myopia, however, have <a href="https://doi.org/10.3390/ijerph16142595">increased risk of blindness and other severe eye problems</a>, such as retinal detachment, in which the retina pulls away from the the back of the eye. The chances of myopia-related <a href="https://www.webmd.com/eye-health/macular-degeneration/what-is-myopic-macular-degeneration">macular degeneration</a> increase by <a href="https://doi.org/10.1111/opo.12945">40% for each diopter of myopia</a>. A diopter is a unit of measurement used in eye prescriptions.</p>

<p>But there appear to be two sure-fire ways to offset or delay these effects: Spend less time focusing on objects close to your face, like books and smartphones, and spend more time outside in the bright, natural light. Given the first one is difficult advice to take in our modern age, the next best thing is taking frequent breaks – or perhaps spend more time reading and scrolling outside in the sun.</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I now lack the juice to fuel the bluster to conceal that I am a simpleton (332 pts)]]></title>
            <link>https://lithub.com/i-now-lack-the-juice-to-fuel-the-bluster-to-conceal-that-i-am-a-simpleton-padgett-powell-legend/</link>
            <guid>40148563</guid>
            <pubDate>Wed, 24 Apr 2024 19:32:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lithub.com/i-now-lack-the-juice-to-fuel-the-bluster-to-conceal-that-i-am-a-simpleton-padgett-powell-legend/">https://lithub.com/i-now-lack-the-juice-to-fuel-the-bluster-to-conceal-that-i-am-a-simpleton-padgett-powell-legend/</a>, See on <a href="https://news.ycombinator.com/item?id=40148563">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							        
									<p><span itemprop="articleBody"><p>Forty years ago, Padgett Powell’s erudite coming of age novel <a href="https://bookshop.org/a/132/9781936787722" target="_blank"><em>Edisto</em></a> was released and introduced readers to a 12-year-old literary prodigy named Simons Everson Manigault. Following an acrimonious separation between the “Duchess” and the “Progenitor” (Simons’ parents), the young boy finds himself living in the Manigault&nbsp;summer home in Edisto, South Carolina while his mother descends into alcoholism.</p>
<p>With his domestic reality crumbling to its foundations, Simons spends most of his time at the Baby Grand, a Black nightclub whose patrons take a shine to the young truant. When the Manigault maid’s biracial grandson arrives in Edisto looking for his mother, Simons names him “Taurus” and the name sticks. The unlikely pair develop a friendship, ushering Simons into the world of mid-century American race relations, the sexual revolution, and the infelicitous vortex of confusion that is puberty.</p>
<p>In addition to celebrating <em>Edisto’s</em> milestone anniversary this year, Powell will be releasing <em>Blasphemy and Other Ancestors </em>(Gordon Hill Press), a collaborative book co-authored with myself, Darius James, and Lee Henderson about the tag end of existence and the abasements that memory holds in store for characters living outside of their time.</p>
<p>I corresponded with Powell to discuss the relationship between cornpone and Flann O’Brien, the “rotten taste of America” informing literary culture, and building a career around the “fey interface between believing in the South and making fun of believing in the South.”</p>
<p><strong>*</strong></p>
<p><strong>Jean Marc Ah-Sen: </strong>What was the central attraction of writing <em>Edisto</em>, a bildungsroman that explored Black and white race relations in the South? Why do you think so many writers feel compelled to start their careers writing about emotional and intellectual maturation, and to which characteristics of the coming-of-age novel do you attribute its pride of place among a broadly defined readership?</p>
<span>The attractive characteristic of a young narrator is the absurdity of it and the license of it.</span>
<p><strong>Padgett Powell:</strong> Let me warn us that these questions are too <em>recherche</em> for me. I now lack the juice to fuel the bluster to conceal that I am a simpleton.</p>
<p>A professor in college was roundly pregnant on a Monday, absent Wednesday, and giving her lecture on “The Miller’s Tale” on Friday with the baby on her hip. I thought “What if that little bastard picks this stuff up and knows Chaucer when he’s five?” My own brother had a good mouth on him, there was already the mother in front of me—the novel was there for the writing. The cerebral cogitation was done. Just Strunk &amp; White some sentences and connect them head to tail and throw in everything you’ve ever seen or heard. Done.</p>
<p>You don’t write about “emotional and intellectual maturation.” The attractive characteristic of a young narrator is the absurdity of it and the license of it. Huck Finn is a 14-year-old uneducated antebellum white boy in Mississippi? Huck Finn is Mark Twain being as smart as Mark Twain was. Huck Finn turns him loose. The absurdity of the proposition is like lightning.</p>
<p><strong>JMA: </strong><em>Edisto</em> explored the legacy and aftermath of the reconstruction era all the way into the 1960s. Donald Barthelme in particular praised you for writing about things readers had never heard before between Black and white characters. Did you have a sense that books written about a similar milieu before or around the time of <em>Edisto’s</em> publication were characteristic of a mealy-mouthedness when it came to racial politics?</p>
<p><strong>PP:</strong> I am innocent of anything written along these lines or the spectrum of candor in them. Because I was arrested for my underground newspaper <em>Tough Shit</em> in high school and the principal sent it to my college to dematriculate me from it, and I had as a result narrated the events of my arrest to four eminences at that college, the Dean of Men there put me in a dorm room with the odd Black boy out because he figured I was radical enough to be liberal enough to handle early integration.</p>
<p>“I didn’t want some redneck to eat him up,” he put it to me three weeks into the semester. I said I wouldn’t. Jinx took me to his bar—it’s in the book, verisimilitudinously. I saw some low country Black life behind some doors. We’d had a long-term maid, a complicated woman—in the book as Theenie, verbatim. I saw some mullet fishing in Florida where a woman berated a fellow for his sloth; “You so slow, no wonder your wife left you.” His name was Buckwheat, a name I could not alter or drop, as prudence would have suggested; she called him Wheat, and when he said, “She din’ leave me, she died,” the woman yelled, “The ultimate leff!” If these are things not heard before, it is only because no one has listened and written them down. You could not publish them in America today because of liberal-editing racism.</p>
<p><strong>JMA: </strong>Twelve years after the release of <em>Edisto</em>, you returned to the world of the Manigault family with <em>Edisto Revisited</em>. What were your motivations for dropping back into the land of mullet fishing, moonshine, and professorial mores during Simons’ university years? Did you always have a sense that there was more to Simons’ story that warranted revisiting, or was there some realization that came afterwards that signaled the attractive possibilities of the story continuing in a sequel?</p>
<p><strong>PP:</strong> I had no sense of more to tell, certainly no sense that more was merited, but it was what I could write at the time and I wrote it. Let me lean us up on Flannery O’Connor, our late racist goddesshead: “When I told you to write what is easy I meant what is possible. It is never easy.” If I have misquoted her, it is because my brain has little spots of something in it.</p>
<p><strong>JMA: </strong>Your career has been described as participating in the American Southern literary tradition. Was this an association you felt honored by, or perhaps something that you were suspicious of? Do you think that writing embodying the principles of the American South needs to be constantly evolving, or is it something that needs to be carefully curated, and whose boundaries must be clearly defined, in order for it to endure?</p>
<p><strong>PP:</strong> It might be fun to tear it all up after the Jews Will Not Replace Us boys in their khakis protest, holding copies of <em>Absalom! Absalom!</em> upside down in the style of Trump with his Bible with duped General Milley at his side. It could all go into the big smelter with the Bobbie E. Lee bronze. But then some smartass would invent another plantation house, another confederate widow, another lost utterancer of the not yet lost cause.</p>
<p>I have made a career of dancing without dancing in the fey interface between believing in the South and making fun of believing in the South, which is why no one has ever heard of me. It’s a lame-ass position. The proper term is chicken-shit.</p>
<p>Who would object if clubists wanted to shove you into a cubbyhole with Faulkner and O’Connor and their queer son Tennessee and too straight son Walker and what-litter-is-he-from son Don? Not I. And my God, Barry Hannah got more out of the whiskey oracle than anyone dead. I do not like the sentimental blood-and-grits crowd and I do not like the apotheosis of Story as Panacea, the from-farm-to-porch menu. Cornpone. No.</p>
<p>Southern writing, not often actually defined, means a deep-down knowing that people are beat to shit. An earnest suspicion of earnestness, a recognition and denial of whippedness. I am now spinning cornpone myself. End of the foregoing. Let’s go read some Flann O’Brien. Those brothers are whipped for real.</p>
<p><strong>JMA: </strong>The book that you are perhaps most known for is <a href="https://bookshop.org/a/132/9780061859434" target="_blank"><em>The Interrogative Mood</em>, <em>A </em><em>Novel?</em></a> which is entirely written in the form of meditative questions—“If you were to participate in a spice war, what spice would you fight for?” is my personal favorite. Did you conceive the book as a rascally wedge that could be placed between experimental and commercial fiction? Or was the book perhaps an effort to assert the primacy of artistic questioning over the fatuousness of shopworn opinions?</p>
<p><strong>PP:</strong> You continue to try to flatter. But this is sharp flattery. It moves me to pomposity: experimental fiction means no more or less than fiction whose central thrust in not made-up people doing made-up things. Let’s call that MUPDMUT. With some liberty, Mupdeemut. Experimental fiction may of course have Mupdeemut in it, but not as the thrust of it—something beyond our believing in Mupdeemut is at hand.</p>
<p>When Hulga’s leg is stolen by a Bible salesman, we are to believe it. When our friend Colby has gone too far and is to be hanged, we are not to believe it. We have the pleasure of seeing Colby in his anguish, but we have a larger or smaller pleasure of distraction from the dictate to pretend this horseshit actually happens. That is the “experiment.”</p>
<p>Does the imperative to not believe exceed the pleasure of the imperative to believe? Donald Barthelme believed it did if the writing still contained emotional payoff. O’Connor would have said, did say, to hell with it. “If [the Devil] is only a symbol, to hell with it.” The imperative to believe is at one level rather childish, as in Once upon a time… This is why Coleridge had the wit to call it a “suspension of disbelief,” not precisely an imperative to believe. What an upgrade to be told, “Don’t <em>believe</em> this, you morons.” What you do, mischievously, is believe <em>more</em>. At which point the “experiment” has succeeded.</p>
<p><em>The Int. Mood</em> goes way too far, in Colby terms, and dispenses with Mupdeemut altogether, except for the occasional Jimi Hendrix’s being offered a BLT as he affects to play you a tune. There is no history of intellection in its conception or intent and no prefiguring in its execution (Huck Finn shows you prefigurating for a book like <em>Edisto</em>).</p>
<p>I received an email from a colleague who wanted me to talk to the Dean that opened, “Is it time for us to have a chat with the dean? Are we remembering what was promised us, last spring, at lunch? Are we going to let history repeat itself?” I suffered pique at this and wrote back, “Are your emotions pure? Are your nerves adjustable? How do you stand in relation to the potato? Should it still be Constantinople?”</p>
<p>The pleasure in this was extreme. I thought how funny it would be—Reply All—for her to receive 600 of these questions, and wrote 600 of them, and then could not stop and wrote 142 pages of them. I saw the “rules” immediately, using her model, but exaggerating the forces. Relieve the silly with the grave, the arch with the colloquial, perfect the overt non-sequitur, watch rhythm, let each sentence deliver its impact—a stonking of someone who would presume write your ass with questions as annoying as they were. Marvelous fun, therapeutic because I was fair exercising some deep contours in my shallow brain, and I felt fine every time I wrote a batch of these things, which I began to liken to thousands of redundant missiles like those we have in our nuclear silos.</p>
<p><strong>JMA: </strong>Your prose tends to be voice-driven and characterized by a kind of malapert urbanity. Can you talk about how this stylized way of writing developed, and if it was an artistic response to things you were reading (whether inhospitably or with a deal of enthusiasm)?</p>
<p><strong>PP:</strong> I am ignorant of “malapert” but I do get “urbanity.” Here is as an almost certainly impertinent answer that I do not intend to be impertinent: I learned to write the English I have written by taking three years of Latin, in the putatively desolate educational backwater of Jacksonville, Florida, ending in the tenth grade translating <em>The Aeneid</em>. I was in homeroom sitting with Allen Collins of Lynyrd Skynyrd. We was gettin’ it. We did not know we was gettin’ it.</p>
<p><strong>JMA: </strong>Does the prose voice that you adopt develop in parallel to the thematic concerns that you will tackle in a given work, or does it emerge as a result of other considerations?</p>
<p><strong>PP:</strong> It emerges with no consideration for anything but the next correct word.</p>
<p><strong>JMA:</strong> The destiny of all books is to become unmoored from the time which birthed them, and as new readers discover them, their relationship can become not just tinged, but entirely defined by a sense of presentism. You spent a large part of your career teaching at the University of Florida Creative Writing program, and I’m wondering how you would address this reality when and if it occurred in the classroom? Is there, in point of fact, a “right” and “wrong” way to read?</p>
<p><strong>PP:</strong> We read formative work asking only what might make it better, by which I meant power in the writing. As I came to the end, the students seemed to have been coached toward a new kind of “better” that meant what was less offensive, and the offense was a multi-headed, surprising beast. One student got in trouble with others when he created a character named Phone Ho. I was mystified by all this and got away rather than try to breast the tide.</p>
<p>I was not going to be able to teach writing, if I ever had taught it. I was turned in for use of the phrase “tsunami of inclusivity.” The phrase was examined for “racial content.” It was judged to be empty of racial content. A prior student suggested I use “politicalicity” as in “tsunami of politicalicity” and I paid him $20 for the word, inserted the phrase, and retired. Please see my students Kevin Wilson and Chris Bachelder, and Kevin Canty and Chris Adrian. There are more. These are just my Kevins and my Chrises, as Trump would put it. God are we doomed.</p>
<span>The destiny of all books is to become unmoored from the time which birthed them.</span>
<p><strong>JMA: </strong>Your latest work will be the novelette “The New Book” in our omnibus book <em>Blasphemy and Other Ancestors</em>. Your offering concerns a man of letters taking on an assistant and training him in the righteous arts of romance, but it also features a metafictionally aware narrator playing against a hypothetical reader’s reservations about events unfolding in Florida. I’m curious if this was a way to express frustration with the sensibilities of modern readership or literary criticism?</p>
<p><strong>PP:</strong> I think not. What I recall was writing a fairly comprehensible sketch in the South-satire genre, kind of my schtick, getting tired of my schtick, and for relief sliding into something untenably surreal in which even I could not keep straight what I was talking about. So I shet that thing down. My hero turned into Ted Turner, and Monteagle, Tennessee became the Philippines in WWII, and a girl at Walmart turned into Vanna White and I was doomed.</p>
<p><strong>JMA: </strong>In an industry that routinely heaps indignity after indignity on its practitioners, what has been the most startling development that you have encountered in recent years while releasing your books? Was it an issue arising as a matter of course from past frustrations, or did it spring from some unprecedented corner of the industry?</p>
<p><strong>PP:</strong> It sprang from the unprecedented corner of my own publisher. My book <em>Indigo</em> had been edited and copyedited by two astute, eminent editors, was set to roll, when a “sensitivity editor” was brought in because someone in marketing at the house was not “comfortable representing the book.” (For the record I never saw any evidence that anyone represented the book)</p>
<p>The sensitivity editor, who I suspect was given four times the money I was given for the book, fell to with their sensitivity broadaxe. In a long true account of a dust-up at a restaurant in old Austin, not new Austin, a Black man on my roofing crew came to my defense and knocked out a white restaurant manager, who was at the moment presuming to assault me. Willie had noticed that the manager had Black back-up and felt I should too. “Old Padge need him some brothers too,” he would explain later.</p>
<p>The piece was essentially a portrait of a hero, Willie Ebert Brown, in a terrain of racial relations that had hope in it. The sentence that announced the Black back-up for the manager was this: “A sturdy-looking Black guy came out of the kitchen.” This is choice low fruit for a sensitivity editor. “Objectifying description,” she wrote, “that may invoke associations with slavery.”</p>
<p>I should have desisted publishing the book, but I am a chicken-shit person and I really wanted a book with a beautiful photo of an indigo snake on its cover. My celebration of Willie was thrown out; my invocation of slavery (to which who objects, its absurdity aside?) was one of a hundred other crimes in the piece. Liberal racism had its way: remove racism by removing race.</p>
<p>There is not a person of color in my book except a very positive small tribute to Barack Obama as a tool by which we might argue the French can slow their roll about how racist we are and they aren’t. How that was not deemed racist is a wonder, because it somewhat is. It’s not a wonder: liberal racism is a photo-negative argument. I apologize for this rant. Chicken-shit and now tired too.</p>
<p><strong>JMA: </strong>For decades now, readers and writers alike have speculated about where the future of literature is headed, with some espousing the belief that literary fiction in particular is going the way of opera and ballet. I think it could be argued that anything betraying a high literary sensibility is already beholden to blue-blooded patronage and sponsorship, whether we are talking about arts grants and awards bodies or content subscription models like Substack or Patreon. Do you think that literary fiction can find mass appeal among readers or has its place always been in contradistinction to an upmarket reading sensibility?</p>
<p><strong>PP:</strong> Does “an upmarket reading sensibility” mean people who buy books at the airport? I confess to feeling loose reading this question. Let’s do a loose answer: a really good book, with anomalies here and there, will not sell well to a mass American market. If you make money here, you have done something wrong. It’s the rotten taste of America, the same force that explains a Trump. We have problems way larger than a poor good writer and a successful conman at large in Washington.</p>
</span></p>
									
																		
																		
									<br><hr>
									
							    										
								</div></div>]]></description>
        </item>
    </channel>
</rss>