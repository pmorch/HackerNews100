<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 18 Jul 2024 18:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Mistral NeMo (277 pts)]]></title>
            <link>https://mistral.ai/news/mistral-nemo/</link>
            <guid>40996058</guid>
            <pubDate>Thu, 18 Jul 2024 14:45:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mistral.ai/news/mistral-nemo/">https://mistral.ai/news/mistral-nemo/</a>, See on <a href="https://news.ycombinator.com/item?id=40996058">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Today, we are excited to release Mistral NeMo, a 12B model built in collaboration with NVIDIA. Mistral NeMo offers a large context window of up to 128k tokens. Its reasoning, world knowledge, and coding accuracy are state-of-the-art in its size category. As it relies on standard architecture, Mistral NeMo is easy to use and a drop-in replacement in any system using Mistral 7B.</p><p>We have released pre-trained base and instruction-tuned checkpoints checkpoints under the Apache 2.0 license to promote adoption for researchers and enterprises. Mistral NeMo was trained with quantisation awareness, enabling FP8 inference without any performance loss.</p><p>The following table compares the accuracy of the Mistral NeMo base model with two recent open-source pre-trained models, Gemma 2 9B, and Llama 3 8B.</p><p><img src="https://mistral.ai/images/news/mistral-nemo/nemo-base-performance.png" alt="Mistral NeMo base model performance compared to Gemma 2 9B and Llama 3 8B" width="100%"></p><p>Table 1: Mistral NeMo base model performance compared to Gemma 2 9B and Llama 3 8B.</p><h2 id="multilingual-model-for-the-masses">Multilingual Model for the Masses</h2><p>The model is designed for global, multilingual applications. It is trained on function calling, has a large context window, and is particularly strong in English, French, German, Spanish, Italian, Portuguese, Chinese, Japanese, Korean, Arabic, and Hindi. This is a new step toward bringing frontier AI models to everyone’s hands in all languages that form human culture.</p><p><img src="https://mistral.ai/images/news/mistral-nemo/mistral-nemo-benchmarks.png" alt="Mistral NeMo performance on multilingual benchmarks" width="100%"></p><p>Figure 1: Mistral NeMo performance on multilingual benchmarks.</p><h3 id="tekken-a-more-efficient-tokenizer">Tekken, a more efficient tokenizer</h3><p>Mistral NeMo uses a new tokenizer, Tekken, based on Tiktoken, that was trained on over more than 100 languages, and compresses natural language text and source code more efficiently than the SentencePiece tokenizer used in previous Mistral models. In particular, it is ~30% more efficient at compressing source code, Chinese, Italian, French, German, Spanish, and Russian. It is also 2x and 3x more efficient at compressing Korean and Arabic, respectively. Compared to the Llama 3 tokenizer, Tekken proved to be more proficient in compressing text for approximately 85% of all languages.</p><p><img src="https://mistral.ai/images/news/mistral-nemo/new-tokenizer-tekken.png" alt="Tekken compression rate" width="100%"></p><p>Figure 2: Tekken compression rate.</p><h2 id="instruction-fine-tuning">Instruction fine-tuning</h2><p>Mistral NeMO underwent an advanced fine-tuning and alignment phase. Compared to Mistral 7B, it is much better at following precise instructions, reasoning, handling multi-turn conversations, and generating code.</p><p><img src="https://mistral.ai/images/news/mistral-nemo/mistral-nemo-multilingual.png" alt="Mistral NeMo instruction-tuned model accuracy" width="100%"></p><p>Table 2: Mistral NeMo instruction-tuned model accuracy. Evals done with GPT4o as judge on official references.</p><h2 id="links">Links</h2><p>Weights are hosted on HuggingFace both for the <a href="https://huggingface.co/mistralai/Mistral-Nemo-Base-2407">base</a> and for the <a href="https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407">instruct</a> models. You can try Mistral NeMo now with mistral-inference and adapt it with mistral-finetune. Mistral NeMo is exposed on la Plateforme under the name <code>open-mistral-nemo-2407</code>. This model is also packaged in a container as NVIDIA NIM inference microservice and available from <a href="https://ai.nvidia.com/">ai.nvidia.com</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Objects of Our Life (143 pts)]]></title>
            <link>https://stevejobsarchive.com/exhibits/objects-of-our-life</link>
            <guid>40995515</guid>
            <pubDate>Thu, 18 Jul 2024 13:43:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stevejobsarchive.com/exhibits/objects-of-our-life">https://stevejobsarchive.com/exhibits/objects-of-our-life</a>, See on <a href="https://news.ycombinator.com/item?id=40995515">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main"><div><hgroup><p>Steve’s talk at the 1983 International Design Conference in Aspen</p></hgroup></div><div><figure><div><div aria-labelledby="video-controls-group" role="group" tabindex="0"><p><span id="video-controls-group">Video controls</span></p><div><p><span>0 seconds elapsed of 0 total seconds</span></p></div></div></div><figcaption><p>Clips from Steve’s talk at the IDCA</p></figcaption></figure></div><div id="introduction"><div><p><hgroup><h2>Introduction by Jony Ive</h2></hgroup></p></div><div><p>Steve rarely attended design conferences. This was 1983, before the launch of the Mac, and still relatively early days of Apple. I find it breathtaking how profound his understanding was of the dramatic changes that were about to happen as the computer became broadly accessible. Of course, beyond just being prophetic, he was fundamental in defining products that would change our culture and our lives forever.&nbsp;</p><p>

On the eve of launching the first truly personal computer, Steve is not solely preoccupied with the founding technology and functionality of the product’s design. This is extraordinarily unusual, as in the early stages of dramatic innovation, it is normally the primary technology that benefits from all of the attention and focus.</p><p>

Steve points out that the design effort in the U.S. at the time had been focused on the automobile, with little consideration or effort given to consumer electronics. While it is not unusual to hear leaders talk about the national responsibility to manufacture, I thought it was interesting that he talked about a nation’s responsibility to design.</p><p>

In the talk, Steve predicts that by 1986 sales of the PC would exceed sales of cars, and that in the following ten years, people would be spending more time with a PC than in a car. These were absurd claims for the early 1980s. Describing what he sees as the inevitability that this would be a pervasive new category, he asks the designers in the audience for help. He asks that they start to think about the design of these products, because designed well or designed poorly, they still would be made.</p><p>

Steve remains one of the best educators I’ve ever met in my life. He had that ability to explain incredibly abstract, complex technologies in terms that were accessible, tangible and relevant. You hear him describe the computer as doing nothing more than completing fairly mundane tasks, but doing so very quickly. He gives the example of running out to grab a bunch of flowers and returning by the time you could snap your fingers – speed rendering the task magical.</p><p>

When I look back on our work, what I remember most fondly are not the products but the process. Part of Steve’s brilliance was how he learned to support the creative process, encouraging and developing ideas even in large groups of people. He treated the process of creating with a rare and wonderful reverence.</p><p>
The revolution Steve described over 40 years ago did of course happen, partly because of his profound commitment to a kind of civic responsibility. He cared, way beyond any sort of functional imperative. His was a victory for beauty, for purity and, as he would say, for giving a damn. He truly believed that by making something useful, empowering and beautiful, we express our love for humanity.</p></div></div><div id="story"><div><p><hgroup><h2>The Story</h2></hgroup></p></div><div><p>On a sunny June morning in 1983, Steve waits at the back of a giant tent, ready to take the stage at the International Design Conference in Aspen. This year’s theme is “The Future Isn’t What It Used to Be,” and he is here to talk about computers to an audience of several hundred designers and design-lovers.</p><p>The night before, Steve gave a demonstration of the Lisa computer, one of the first commercially available machines with a mouse and a graphical user interface. These innovations meant that people would no longer need to type commands or punch arrow keys to use a computer. Instead they could use a mouse to click, drag, and navigate among icons, menus, and graphics—and even draw and paint.</p></div><div><figure><img alt="" height="3066" width="4718" data-orientation="LANDSCAPE" src="https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_1539/f_auto/q_auto/v1/Aspen/Final_Retouched/Aspen__Historical_Society_Thompson_02_mosyaj?_a=DATAdtd+ZAA0" srcset="https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_640/f_auto/q_auto/v1/Aspen/Final_Retouched/Aspen__Historical_Society_Thompson_02_mosyaj?_a=DATAdtd+ZAA0 640w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_750/f_auto/q_auto/v1/Aspen/Final_Retouched/Aspen__Historical_Society_Thompson_02_mosyaj?_a=DATAdtd+ZAA0 750w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_828/f_auto/q_auto/v1/Aspen/Final_Retouched/Aspen__Historical_Society_Thompson_02_mosyaj?_a=DATAdtd+ZAA0 828w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_1080/f_auto/q_auto/v1/Aspen/Final_Retouched/Aspen__Historical_Society_Thompson_02_mosyaj?_a=DATAdtd+ZAA0 1080w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_1200/f_auto/q_auto/v1/Aspen/Final_Retouched/Aspen__Historical_Society_Thompson_02_mosyaj?_a=DATAdtd+ZAA0 1200w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_1920/f_auto/q_auto/v1/Aspen/Final_Retouched/Aspen__Historical_Society_Thompson_02_mosyaj?_a=DATAdtd+ZAA0 1920w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_2048/f_auto/q_auto/v1/Aspen/Final_Retouched/Aspen__Historical_Society_Thompson_02_mosyaj?_a=DATAdtd+ZAA0 2048w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_3840/f_auto/q_auto/v1/Aspen/Final_Retouched/Aspen__Historical_Society_Thompson_02_mosyaj?_a=DATAdtd+ZAA0 3840w" sizes="(min-width:1180px) 50vw, 100vw"><figcaption><p>Interior of <!-- -->Aspen Amphitheater<!-- -->, 1983</p></figcaption></figure></div><div><p>Steve had been happy to introduce Apple’s latest product, but he knows that this morning’s speech, here under the gauzy Eero Saarinen–designed tent in the flower-filled fields of the Aspen Institute, is the main event. Called to the stage, he bounds down the center aisle, notebook in hand. He leaps up to take his place at the podium. He is the cofounder and chair of Apple, a “legend in his own time,” according to his onstage introduction—but he is also 28 and excited for this, his first formal talk to a gathering of esteemed designers. He has chosen not to title his presentation; the program refers to it only as “Talk.” </p><p>He leans into the microphone. “They paid me sixty dollars, so I wore a tie,” he says, gesturing to the striped bow tie he has paired with a sports jacket and jeans. A grin stretches across his face; the audience laughs. He takes off his jacket, realizes there is nowhere to put it, and drops it to the floor, where it lays in a crumpled heap for the rest of his talk.</p><p>“How many of you own an Apple?” he asks from the stage.</p><p>No reaction.</p><p>“Any, or…just any personal computer?”&nbsp;</p><p>A bit of rustling from the audience. They are shifting in their seats. For most of them, design is still a craft of pencils, paper, rubber cement, straight edges, and clay. </p><p>Steve laughs. “Uh–oh. How many of you’ve used one, or seen one—anything like that?”&nbsp;</p><p>He must see a few hands raised in the audience. “Good. OK.” Steve rolls up his shirt sleeves. He has his work cut out for him.</p></div><div><figure><img alt="" height="2527" width="3840" data-orientation="LANDSCAPE" src="https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_1539/f_auto/q_auto/v1/Aspen/Final_Retouched/Cropped%20-%20Lisa%20ad%2007082024/sja_001_pro_i090_a_BYNAi1528_-_Crop_hmbqlr?_a=DATAdtd+ZAA0" srcset="https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_640/f_auto/q_auto/v1/Aspen/Final_Retouched/Cropped%20-%20Lisa%20ad%2007082024/sja_001_pro_i090_a_BYNAi1528_-_Crop_hmbqlr?_a=DATAdtd+ZAA0 640w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_750/f_auto/q_auto/v1/Aspen/Final_Retouched/Cropped%20-%20Lisa%20ad%2007082024/sja_001_pro_i090_a_BYNAi1528_-_Crop_hmbqlr?_a=DATAdtd+ZAA0 750w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_828/f_auto/q_auto/v1/Aspen/Final_Retouched/Cropped%20-%20Lisa%20ad%2007082024/sja_001_pro_i090_a_BYNAi1528_-_Crop_hmbqlr?_a=DATAdtd+ZAA0 828w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_1080/f_auto/q_auto/v1/Aspen/Final_Retouched/Cropped%20-%20Lisa%20ad%2007082024/sja_001_pro_i090_a_BYNAi1528_-_Crop_hmbqlr?_a=DATAdtd+ZAA0 1080w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_1200/f_auto/q_auto/v1/Aspen/Final_Retouched/Cropped%20-%20Lisa%20ad%2007082024/sja_001_pro_i090_a_BYNAi1528_-_Crop_hmbqlr?_a=DATAdtd+ZAA0 1200w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_1920/f_auto/q_auto/v1/Aspen/Final_Retouched/Cropped%20-%20Lisa%20ad%2007082024/sja_001_pro_i090_a_BYNAi1528_-_Crop_hmbqlr?_a=DATAdtd+ZAA0 1920w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_2048/f_auto/q_auto/v1/Aspen/Final_Retouched/Cropped%20-%20Lisa%20ad%2007082024/sja_001_pro_i090_a_BYNAi1528_-_Crop_hmbqlr?_a=DATAdtd+ZAA0 2048w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_3840/f_auto/q_auto/v1/Aspen/Final_Retouched/Cropped%20-%20Lisa%20ad%2007082024/sja_001_pro_i090_a_BYNAi1528_-_Crop_hmbqlr?_a=DATAdtd+ZAA0 3840w" sizes="(min-width:1180px) 50vw, 100vw"><figcaption><p>Apple Lisa Computer Print Advertisement, 1983</p></figcaption></figure></div><div><p>Computers were so rare in American homes at this time that the U.S. Census wouldn’t begin tracking their presence for another year. Even then, in 1984, only 8 percent of households had a computer (and of those that did, roughly 70 percent of those machines had been bought in the past two years). By contrast, 98 percent of households had televisions.</p><p>People didn’t own computers, but they did have a sense that the machine was about to become very, very important. A few months before Steve spoke at Aspen, <i>Time Magazine</i> had bucked its own tradition to name the computer its Man of the Year, the machine thus joining the ranks of presidents, monarchs, astronauts, and peacemakers. And on the strength of the personal computer’s promise, Apple had just become the youngest company to join the Fortune 500. </p><p>What this new machine would mean for daily life, however, was still unclear in 1983. An internal Apple document cautions that many people encountering a computer for the first time “might be a little bit afraid. They still aren’t sure they can actually operate a computer, but know it’s time they join the <!-- -->‘revolution’.”</p><p>Steve has come to Aspen as a standard-bearer for this revolution. Back at Apple headquarters in Cupertino, California, he is leading the development of everything he thinks the company will need to bring computers to “the rest of us”: the publicity, the advertising, the educational programs, the groundbreaking television commercial, and above all, the right machine. The Macintosh, of course, would be that machine, combining the best of the Lisa with other breakthroughs and packaging them all in a squat, friendly little case with a footprint hardly bigger than a typewriter.</p><p>But he cannot talk about the work secretly in development, much less show it. His only tools are his passion and the blue spiral notebook he has placed on the lectern in front of him. </p></div><div><figure><blockquote><span>“</span>When you have a million people using something, then that’s when creativity really starts to happen on a rapid scale.<!-- -->”</blockquote></figure></div><div><p>On stage, Steve launches into a history of computing. He regularly consults his notebook, reading or glancing at its pages to confirm the year that the first computer-science degree was granted or details about the pioneering ENIAC computer and the timesharing models that followed.</p><p>In the middle of this studied presentation, he interrupts himself. “Let me digress for a minute,” he says. Then he goes off script.</p><p>“One of the reasons I’m here is because I need your help.”</p><p>For this, the heart of his message to the designers in Aspen, he doesn’t need his notes.</p><p>He predicts that the industry will sell three million computers in 1983 and ten million in 1986, “whether they look like a piece of shit or they look great.” The audience, pleasantly scandalized, laughs at his swearing, but Steve doesn’t crack a smile. He doesn’t say so, but he has already seen proof of what he considers indiscriminate taste: sales of the IBM PC, the computer Steve is likely thinking of when he says that current machines “look like garbage” and are a “pain in the ass,” have just overtaken sales of Apple’s flagship Apple II. </p></div><div><figure><blockquote><span>“</span>We have a shot at putting a great object [out] there, and it doesn’t cost any more money to make it look great.<!-- -->”</blockquote></figure></div><div><p>One American industry after another—cars, televisions, cameras, watches—has lost market share to foreign competition, he explains, and he is worried that the same will happen with the computer if it becomes what he calls <!-- -->“one more piece-of-junk-object.”<!-- --> This moment, when “computers and society are out on a first date”—and here he interlaces his fingers to show how close that relationship could one day become—offers a rare opportunity that they must seize together. The audience is present at the birth of something monumental, and they can help define it. His voice rises with emotion. “We need help. We really, really need your help.”</p></div><div><figure><blockquote><span>“</span>We have a chance to make these things beautiful, and we have a chance to communicate something through the design of the objects themselves.<!-- -->”</blockquote></figure></div><div><p>Steve has spent the past few years learning everything he can about design. He has always loved beautiful objects, and from its very beginning, Apple paid particular attention to product design. On the day the company was incorporated, Apple’s first board chair Mike Markkula circulated a memo reminding the staff, “People DO judge a book by its cover.” </p></div><div><figure><img alt="" height="3840" width="2903" data-orientation="PORTRAIT" src="https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_1539/f_auto/q_auto/v1/Aspen/Final_Retouched/Apple_Marketing_Philosophy_1_ma4wlr?_a=DATAdtd+ZAA0" srcset="https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_640/f_auto/q_auto/v1/Aspen/Final_Retouched/Apple_Marketing_Philosophy_1_ma4wlr?_a=DATAdtd+ZAA0 640w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_750/f_auto/q_auto/v1/Aspen/Final_Retouched/Apple_Marketing_Philosophy_1_ma4wlr?_a=DATAdtd+ZAA0 750w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_828/f_auto/q_auto/v1/Aspen/Final_Retouched/Apple_Marketing_Philosophy_1_ma4wlr?_a=DATAdtd+ZAA0 828w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_1080/f_auto/q_auto/v1/Aspen/Final_Retouched/Apple_Marketing_Philosophy_1_ma4wlr?_a=DATAdtd+ZAA0 1080w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_1200/f_auto/q_auto/v1/Aspen/Final_Retouched/Apple_Marketing_Philosophy_1_ma4wlr?_a=DATAdtd+ZAA0 1200w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_1920/f_auto/q_auto/v1/Aspen/Final_Retouched/Apple_Marketing_Philosophy_1_ma4wlr?_a=DATAdtd+ZAA0 1920w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_2048/f_auto/q_auto/v1/Aspen/Final_Retouched/Apple_Marketing_Philosophy_1_ma4wlr?_a=DATAdtd+ZAA0 2048w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_3840/f_auto/q_auto/v1/Aspen/Final_Retouched/Apple_Marketing_Philosophy_1_ma4wlr?_a=DATAdtd+ZAA0 3840w" sizes="(min-width:1180px) 50vw, 100vw"><figcaption><p>The Apple Marketing Philosophy, 1977</p></figcaption></figure></div><div><p>To serve as Apple’s first in-house designer, Steve hired Jerry Manock, who had worked a few miles up the road at Hewlett-Packard. Steve adored his HP-35 calculator, not just for its functionality but also for how it felt in his hand and for the haptic response of the keys when he pressed them. He wanted that attention to detail applied to Apple’s products. And as Apple hired more designers and worked with outside firms like Hovey-Kelley Design (whose co-founder David Kelley would go on to launch IDEO), Steve did everything he could to learn from the experts. He studied their fashion choices; a few days after he saw industrial designer Rob Gemmell in gray Nikes with cutting-edge Velcro straps, Steve showed up at work with a pair of his own. He sat in on meetings of the newly formed Apple design guild, where his being the only non-designer present did not stop him from offering merciless criticisms—a provocation some saw as presumptuous and others took as an invitation to push back or try to educate him.</p><p>He wanted to talk about everything he saw, and he wanted to see everything. He looked closely at kitchen appliances and VW vans, wine labels, gallery paintings, motorcycles, and telephones. He took the Macintosh team to San Francisco’s de Young Museum to see an exhibit of Tiffany lamps. He asked Joanna Hoffman, a Macintosh marketing manager, about the Issey Miyake-designed clothes she had saved her money to buy: Did she think their asymmetry and superlative craftsmanship could ever have wide appeal in the United States? </p><p>He was developing his eye, absorbing into his bones the lesson that good design is not mere decoration or ornament, but a paring away to help an object reveal its essence and, ultimately, evoke an emotional connection with its user.&nbsp;</p><p>Along with several Apple designers, he toyed with the idea of filling a room with objects they loved, then directing new hires to spend their first day at work in that room. He curated his own life, choosing to live in an empty space with just a few exquisite things—a Tiffany lamp, a custom-assembled stereo system.&nbsp;</p></div><div><figure><img alt="" height="978" width="1304" data-orientation="LANDSCAPE" src="https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_1539/f_auto/q_auto/v1/Aspen/TEMP/TEMP_Steve_and_Tiffany_lamp_Diana_Walker_x75sqx?_a=DATAdtd+ZAA0" srcset="https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_640/f_auto/q_auto/v1/Aspen/TEMP/TEMP_Steve_and_Tiffany_lamp_Diana_Walker_x75sqx?_a=DATAdtd+ZAA0 640w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_750/f_auto/q_auto/v1/Aspen/TEMP/TEMP_Steve_and_Tiffany_lamp_Diana_Walker_x75sqx?_a=DATAdtd+ZAA0 750w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_828/f_auto/q_auto/v1/Aspen/TEMP/TEMP_Steve_and_Tiffany_lamp_Diana_Walker_x75sqx?_a=DATAdtd+ZAA0 828w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_1080/f_auto/q_auto/v1/Aspen/TEMP/TEMP_Steve_and_Tiffany_lamp_Diana_Walker_x75sqx?_a=DATAdtd+ZAA0 1080w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_1200/f_auto/q_auto/v1/Aspen/TEMP/TEMP_Steve_and_Tiffany_lamp_Diana_Walker_x75sqx?_a=DATAdtd+ZAA0 1200w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_1920/f_auto/q_auto/v1/Aspen/TEMP/TEMP_Steve_and_Tiffany_lamp_Diana_Walker_x75sqx?_a=DATAdtd+ZAA0 1920w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_2048/f_auto/q_auto/v1/Aspen/TEMP/TEMP_Steve_and_Tiffany_lamp_Diana_Walker_x75sqx?_a=DATAdtd+ZAA0 2048w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_3840/f_auto/q_auto/v1/Aspen/TEMP/TEMP_Steve_and_Tiffany_lamp_Diana_Walker_x75sqx?_a=DATAdtd+ZAA0 3840w" sizes="(min-width:1180px) 50vw, 100vw"><figcaption><div><p>Steve at home, sitting under his Tiffany lamp, photographed by Diana Walker in 1982</p></div></figcaption></figure></div><div><p>He later told an interviewer, “It comes down to trying to expose yourself to the best things that humans have done, and then try to bring those things into what you are doing.”</p><p>He flew to Japan, where he met with Akio Morita, CEO of Sony, who gave him a first-generation Walkman, the portable music player Steve admired. He attended his first Aspen conference in 1981; the theme was “The Italian Idea,” and the work of designers such as Mario Bellini, Ettore Sottsass, Gae Aulenti, and Richard Sapper took center stage. He wrote to Mario Bellini and visited Italy to meet with Olivetti’s Ettore Sottsass. When Apple designers Gemmell and Manock proposed sponsoring a competition in which several top European designers would be invited to create a cohesive design language for a family of seven Apple products, Steve leapt at the idea.</p><p>By the spring of 1982, he was vowing, “I want our design not just to be the best in the personal computer industry, but the best in the world.”</p><p>No wonder he had prepared so carefully for the Aspen talk—he understood the opportunities and the stakes.</p></div><div><figure><blockquote><span>“</span>We have an opportunity to do it great or to do it so-so. And what a lot of us at Apple are working on is trying to do it great.<!-- -->”</blockquote></figure></div><div><p>Back on stage, Steve has returned to his blue notebook. He talks about the computer in the context of other media, the evolution from radio to television to videodisc. He explains how email works, describes drawing with a computer and a mouse, imagines a world in which computers are portable but&nbsp; have “radio links,” narrates in great detail an interactive map he saw from MIT, tries to explain why computer programs are “archetypal,” and points to the possibility that one day we might be able, in any given situation, to ask a computer, “What would Aristotle have said?”—and get an answer.&nbsp;</p></div><div><figure><img alt="" height="768" width="1103" data-orientation="LANDSCAPE" src="https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_1539/f_auto/q_auto/v1/Aspen/Final_Retouched/4Cam_Rig_W-JB_MN_AL_cbyxuk?_a=DATAdtd+ZAA0" srcset="https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_640/f_auto/q_auto/v1/Aspen/Final_Retouched/4Cam_Rig_W-JB_MN_AL_cbyxuk?_a=DATAdtd+ZAA0 640w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_750/f_auto/q_auto/v1/Aspen/Final_Retouched/4Cam_Rig_W-JB_MN_AL_cbyxuk?_a=DATAdtd+ZAA0 750w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_828/f_auto/q_auto/v1/Aspen/Final_Retouched/4Cam_Rig_W-JB_MN_AL_cbyxuk?_a=DATAdtd+ZAA0 828w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_1080/f_auto/q_auto/v1/Aspen/Final_Retouched/4Cam_Rig_W-JB_MN_AL_cbyxuk?_a=DATAdtd+ZAA0 1080w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_1200/f_auto/q_auto/v1/Aspen/Final_Retouched/4Cam_Rig_W-JB_MN_AL_cbyxuk?_a=DATAdtd+ZAA0 1200w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_1920/f_auto/q_auto/v1/Aspen/Final_Retouched/4Cam_Rig_W-JB_MN_AL_cbyxuk?_a=DATAdtd+ZAA0 1920w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_2048/f_auto/q_auto/v1/Aspen/Final_Retouched/4Cam_Rig_W-JB_MN_AL_cbyxuk?_a=DATAdtd+ZAA0 2048w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_3840/f_auto/q_auto/v1/Aspen/Final_Retouched/4Cam_Rig_W-JB_MN_AL_cbyxuk?_a=DATAdtd+ZAA0 3840w" sizes="(min-width:1180px) 50vw, 100vw"><figcaption><p>MIT’s Aspen Movie Map, 1978–1980</p></figcaption></figure></div><div><p>The examples he offers demystify and catalyze in equal measure; they show what he is seeing, what others are imagining, and how it all fits together with breakthroughs that have come before. This is how Steve viewed innovation throughout his life: a constant accretion of what he called “sedimentary layers,” each one with the potential to raise humanity a bit higher, each generation building on the ideas of its predecessors.</p></div><div><figure><blockquote><span>“</span>So what do you want to talk about?<!-- -->”</blockquote></figure></div><div><p>Steve ends his speech and without a pause starts taking questions. Apart from scripted product demonstrations, he always preferred the give-and-take of Q&amp;As over prepared remarks, and this talk is no exception. His formal comments in the blue notebook ran about 20 minutes, but the Q&amp;A will last nearly twice as long. He has developed a rapport with the audience, and their questions cover a wide range of issues: networking, privacy, graphic design, hiring and recruiting, and voice recognition.&nbsp;</p><p>The biggest applause comes when Steve describes “Kids Can’t Wait,” Apple’s program to put a computer in every school in California. This audience of people who have never used computers now want their children to have access to them.</p><p>In response to a question about computer-based tools for graphic design, he lays out a much larger core ambition, one that will become a life-long theme. “We’re solving the problems of injecting some liberal arts into these computers,” he says. Computers should include multiple fonts and graphics because they are beautiful in themselves but also because they serve as the gateway to so much more. An engaging, easy-to-understand interface will help draw people to the computer, making it possible for them to discover new ideas and convey their own in new ways and with new tools. </p><p>“Where we’ve got to get to,” he says, is a place where no college student would think of writing a paper without a computer, where “people three, four years from now are using these things and they go, ‘Wasn’t this the way it always was?’” This sense of inevitability—so hard won, so hard to describe, and so obvious when achieved—is, for Steve, a hallmark of success. His sedimentary model of innovation works only if each generation takes the existing tools for granted.&nbsp;</p><p>Perhaps the most revealing moment in the Q&amp;A comes when Steve is asked about Apple’s low rate of employee turnover. He starts to answer by talking about the wide distribution of stock options, then swerves to describe what he thinks really underpins people’s commitment to their work. “We feel that for some crazy reason we’re in the right place at the right time to put something back,” he says, pausing to collect his thoughts. “Most of us didn’t make the clothes we’re wearing, and we didn’t cook or grow the food that we eat, and we’re speaking a language that was developed by other people; we use mathematics that was developed by other people.” He is emphasizing every word. “We are constantly taking–and the ability to put something back into that pool of human experiences is extremely neat.” This desire to <a rel="noopener" aria-describedby=":Ramjld4lacmvdm:" href="https://putsomethingback.stevejobsarchive.com/">“put something back”</a> would drive his work throughout his life.</p><p>The questions could go on, but Steve looks offstage and prompts, “I don’t know how much time we have?” As the crowd rises to their feet in a standing ovation, Steve picks up his coat off the floor, gives it a shake, and speeds up the aisle and out of the tent. A newspaper will later report, “An undercurrent was felt most of the day Wednesday and part of Thursday over whether Jobs was good or bad—visionary or huckster,” but Steve has no time for such debates. He has come to Aspen to speak but also to learn. Maya Lin, the 23-year-old student architect of the new stark and controversial Vietnam Veterans Memorial, is speaking nearby. He wants to hear her talk. </p></div></div><div id="steve-s-talk"><div><p><hgroup><h2>Steve’s Talk</h2></hgroup></p></div><div><figure><div><div aria-labelledby="video-controls-group" role="group" tabindex="0"><p><span id="video-controls-group">Video controls</span></p><div><p><span>0 seconds elapsed of 0 total seconds</span></p></div></div></div><figcaption><p>Courtesy of GrassRoots Television</p></figcaption></figure></div></div><div id="before-and-after-the-talk"><div><p><hgroup><h2>Before and After Steve’s Talk </h2></hgroup></p></div><div><p>Steve spoke at the Aspen Conference two other times in addition to his mainstage talk on the morning of June 15, 1983. 
</p><p>
The night before, dressed in a leather bomber jacket and a button-down shirt, Steve gave a demonstration of the Lisa computer in what he called a “multimedia show.” That “show” has been lost, as has most of Steve’s presentation, but we have a few minutes of it. 
</p><p>
Steve also spent 45 minutes in an informal Q&amp;A session several hours after his mainstage talk. In New Balance sneakers, jeans, and a T-shirt from Ciao!, an Italian restaurant in San Francisco whose logo he loved, he sat backwards astride a metal folding chair and answered questions. Though the video shakes, the wind cuts through the audio, and questions are often muffled, Steve’s thoughts are worth sharing. 
</p><p>
Here are a few of our favorite clips.</p></div><div data-state="closed" id="artificial-intelligence" role="region" aria-labelledby="radix-:R96l96lacmvdm:" data-orientation="vertical"><div><figure><div><div><p><img alt="" height="486" width="720" data-orientation="LANDSCAPE" src="https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_1539/f_auto/q_auto/v1/Aspen/Temp%20-%20Before%20and%20After%20poster%20stills/Aspen_AI_v04.00_00_02_05.Still001_or7198?_a=DATAdtd+ZAA0" srcset="https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_640/f_auto/q_auto/v1/Aspen/Temp%20-%20Before%20and%20After%20poster%20stills/Aspen_AI_v04.00_00_02_05.Still001_or7198?_a=DATAdtd+ZAA0 640w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_750/f_auto/q_auto/v1/Aspen/Temp%20-%20Before%20and%20After%20poster%20stills/Aspen_AI_v04.00_00_02_05.Still001_or7198?_a=DATAdtd+ZAA0 750w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_828/f_auto/q_auto/v1/Aspen/Temp%20-%20Before%20and%20After%20poster%20stills/Aspen_AI_v04.00_00_02_05.Still001_or7198?_a=DATAdtd+ZAA0 828w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_1080/f_auto/q_auto/v1/Aspen/Temp%20-%20Before%20and%20After%20poster%20stills/Aspen_AI_v04.00_00_02_05.Still001_or7198?_a=DATAdtd+ZAA0 1080w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_1200/f_auto/q_auto/v1/Aspen/Temp%20-%20Before%20and%20After%20poster%20stills/Aspen_AI_v04.00_00_02_05.Still001_or7198?_a=DATAdtd+ZAA0 1200w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_1920/f_auto/q_auto/v1/Aspen/Temp%20-%20Before%20and%20After%20poster%20stills/Aspen_AI_v04.00_00_02_05.Still001_or7198?_a=DATAdtd+ZAA0 1920w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_2048/f_auto/q_auto/v1/Aspen/Temp%20-%20Before%20and%20After%20poster%20stills/Aspen_AI_v04.00_00_02_05.Still001_or7198?_a=DATAdtd+ZAA0 2048w, https://res.cloudinary.com/dkpjmxbwo/image/upload/c_fill,w_3840/f_auto/q_auto/v1/Aspen/Temp%20-%20Before%20and%20After%20poster%20stills/Aspen_AI_v04.00_00_02_05.Still001_or7198?_a=DATAdtd+ZAA0 3840w" sizes="(min-width:1180px) 50vw, 100vw"></p></div><div aria-labelledby="video-controls-group" role="group" tabindex="0"><p><span id="video-controls-group">Video controls</span></p><div><p><span>0 seconds elapsed of 0 total seconds</span></p></div></div></div></figure></div><div><p>In this, our only clip from the footage of Steve’s Lisa demonstration on the evening of June 14, he draws parallels between the human brain and the computer.</p></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: What's Prolog Like in 2024? (240 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=40994552</link>
            <guid>40994552</guid>
            <pubDate>Thu, 18 Jul 2024 11:23:06 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=40994552">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="40994552">
      <td><span></span></td>      <td><center><a id="up_40994552" href="https://news.ycombinator.com/vote?id=40994552&amp;how=up&amp;goto=item%3Fid%3D40994552"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=40994552">Ask HN: What's Prolog Like in 2024?</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_40994552">147 points</span> by <a href="https://news.ycombinator.com/user?id=overclock351">overclock351</a> <span title="2024-07-18T11:23:06"><a href="https://news.ycombinator.com/item?id=40994552">3 hours ago</a></span> <span id="unv_40994552"></span> | <a href="https://news.ycombinator.com/hide?id=40994552&amp;goto=item%3Fid%3D40994552">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20What%27s%20Prolog%20Like%20in%202024%3F&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=40994552&amp;auth=4b49720694479595027657117ba41a25b6f08f14">favorite</a> | <a href="https://news.ycombinator.com/item?id=40994552">72&nbsp;comments</a>        </span>
              </td></tr>
    <tr><td></td></tr><tr><td colspan="2"></td><td><div><p>Hi, i am a compsci student that stumbled upon prolog and logic programming during my studies.</p><p>While i have seen the basics of vanilla prolog (atoms, predicates, cuts, lists and all that jazz) and a godawful implementation of an agent communication system that works on SICStus prolog. I would like to know more because i think that this language might be a powerhouse in per se.</p><p>Since my studies are quite basic in this regards i would like to expand my knowledge on it and kind of specialize myself both in this world and another world (ontologies :D) that i really enjoy.</p><p>What's prolog like in 2024? what are you wonderful people doing with it?</p><p>thanks from a dumbass :D</p></div></td></tr>        <tr><td></td></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Collection of Dark Patterns and Unethical Design (148 pts)]]></title>
            <link>https://hallofshame.design/collection/</link>
            <guid>40993389</guid>
            <pubDate>Thu, 18 Jul 2024 07:41:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hallofshame.design/collection/">https://hallofshame.design/collection/</a>, See on <a href="https://news.ycombinator.com/item?id=40993389">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <main>

        

        <div>
        <article>
            <header>
                <h2>
                    Catalog of Dark Patterns
                </h2>
            </header>
            <p>
                    Discover a variety of dark pattern examples, sorted by category, to better understand deceptive design practices.
                </p>
        </article>


            <div>
                <section>
                        <header>
                            

                            <p>What's a Bait and switch? This tactic lures users with an enticing offer, only to change the terms unexpectedly. The original promise often has hidden conditions, misleading users into commitments they didn't intend, eroding trust.</p>
                        </header>
                        
                        <a href="https://hallofshame.design/tag/bait-and-switch/">View All</a>
                    </section>
                <section>
                        <header>
                            

                            <p>What's Confirmshaming? When a product or a service is guilting or shaming a user for not signing up for some product or service.</p>
                        </header>
                        
                        <a href="https://hallofshame.design/tag/confirmshaming/">View All</a>
                    </section>
                <section>
                        <header>
                            

                            <p>What's a Disguised Ad? When an advertisement on a website pretends to be a UI element and makes you click on it to forward you to another website.</p>
                        </header>
                        
                        <a href="https://hallofshame.design/tag/disguised-ads/">View All</a>
                    </section>
                <section>
                        <header>
                            

                            <p>What's a Hidden Cost? At the last stage of your checkout process, you would see some additional charges that were added to your final bill without mentioning them in previous steps. (i.e. delivery charges, taxes, etc.)</p>
                        </header>
                        
                        <a href="https://hallofshame.design/tag/hidden-costs/">View All</a>
                    </section>
                <section>
                        <header>
                            

                            <p>What's a Misdirection? A flow or a UI element is designed in a way to trick your attention to distract you from the desired action (i.e. using smaller contrast color on primary buttons).</p>
                        </header>
                        
                        <a href="https://hallofshame.design/tag/misdirection/">View All</a>
                    </section>
                <section>
                        <header>
                            

                            <p>What is nagging? Nagging by apps and websites uses users' time and attention with constant interruptions. Over time, this pressure can make users give in to these requests, even if it's not in their best interest.</p>
                        </header>
                        
                        <a href="https://hallofshame.design/tag/nagging/">View All</a>
                    </section>
                <section>
                        <header>
                            

                            <p>What's a Privacy Zuckering? A service or a website tricks you into sharing more information with it than you really want to.</p>
                        </header>
                        
                        <a href="https://hallofshame.design/tag/privacy-zuckering/">View All</a>
                    </section>
                <section>
                        <header>
                            

                            <p>What's a Roach Motel? This dark pattern is usually used for subscription services. It is easy to sign up for it, but it's much harder to cancel it (i.e. you have to call customer support).</p>
                        </header>
                        
                        <a href="https://hallofshame.design/tag/roach-motel/">View All</a>
                    </section>
                <section>
                        <header>
                            

                            <p>What's a Sneak into Basket? When buying something, during your checkout, a website adds some additional items to your cart, making you take the action of removing it from your cart.</p>
                        </header>
                        
                        <a href="https://hallofshame.design/tag/sneak-into-basket/">View All</a>
                    </section>
                <section>
                        <header>
                            

                            <p>What's a Trick Questions? Common pattern used during sign-up flows. Usually, these are checkboxes located at the end of a form. At first glance, they all mean the same thing, but after the second reading, you see a completely different meaning.</p>
                        </header>
                        
                        <a href="https://hallofshame.design/tag/trick-questions/">View All</a>
                    </section>
            </div>
        </div>

    </main>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My daughter (7 years old) used HTML to make a website (621 pts)]]></title>
            <link>https://naya.lol</link>
            <guid>40992982</guid>
            <pubDate>Thu, 18 Jul 2024 06:24:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://naya.lol">https://naya.lol</a>, See on <a href="https://news.ycombinator.com/item?id=40992982">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Amazon's Kindle Direct Publishing is a dystopian nightmare (256 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=40992654</link>
            <guid>40992654</guid>
            <pubDate>Thu, 18 Jul 2024 05:05:21 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=40992654">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Imagine this scenario: You get pulled over by a robot cop. The robot immediately terminates your driver's license <i>forever</i> for driving an 18-wheeler without proper certification. You point to the Mini Cooper you were driving when the robot pulled you over. The robot ignores you.</p><p>Eventually, a different robot shows up, listens to your defense, sees the Mini Cooper, and watches you start the car with your own keys. There is no 18-wheeler in sight. The new robot says it will get back to you in 5 business days.</p><p>Two weeks go by, and a third different robot tells you your appeal has been denied for "driving in such a way that creates a negative experience for other drivers". All the stuff about 18-wheeler certification is never mentioned or acknowledged again.</p><p>You appeal again and again. All your appeals are heard by yet more robots, who always uphold the original robot's decision, regurgitating the same bland phrase about creating a negative driving experience. THE END</p><p>This is basically what has happened to me with Amazon's KDP. I published my paperback through Ingram Spark and my Kindle eBook through KDP. My eBook passed review and was for sale for a few days. I claimed the paperback on my author central page, where it appeared side by side with the Kindle version. I was told to wait a week and the two versions should link up automatically (so they appear as the same book). If not, I should send an email to Amazon support.</p><p>Then the eBook was blocked, and a day later I got this in an email from KDP's Content Review Team:</p><p>&gt; During our review, we found that the following book(s) creates a misleading customer experience by impairing customers' ability to make good buying decisions.</p><p>&gt; Land Without a Continent: A Road Trip through Mexico and Central America</p><p>&gt; Items that can cause a misleading customer experience include:</p><pre><code>  - Similarity of the contributor name to another author
  - Similarity of the title to a previously published book
  - Similarity of the cover to a previously published book
  - Cover text or images that do not accurately represent the contents of the book
  - Title or subtitle that do not accurately represent the contents of the book
  - Similarity of the description to a previously published known work
</code></pre><p>
I replied to their email pointing out that there is no book with a remotely similar name, description and author name as my book. I even did a reverse image search on my cover, and the only hit was my book on Amazon. It seems obvious to me that their AI-powered fraud detection system hallucinated that I plagiarized my own paperback.</p><p>The next day, they terminated my account. I appealed. I got an automated reply saying to give them 5 business days to review my case. That stretched into two weeks. Finally, I got an email stating my appeal was denied with only this message:</p><p>&gt; We found that you have published titles with misleading metadata (including cover), which creates a negative customer experience.</p><p>It seems like they picked the only one of the six bullet points that couldn't be easily disproven, and ran with it. I continued to email and managed to get a few more informal appeals, all denied with the exact same vague nonsense message. I even emailed jeff@amazon.com.</p><p>I had finally given up, when I got an email from Robert from their Executive Customer Relations Team. Hooray a human being (maybe)! A day later, Robert upheld the termination with the exact same vague reason above and some semi-belligerent language about how this was my last appeal.</p><p>Here's plenty more reading:</p><p>https://writersweekly.com/angela-desk/and-even-more-complaints-about-amazon-kdp-kindle-direct-publishing</p><p>https://www.trustpilot.com/review/kdp.amazon.com</p><p>https://medium.com/@peteylao/my-cover-story-aka-how-i-managed-to-get-my-kdp-account-suspended-terminated-and-finally-fd3631e84aba</p><p>https://judylmohr.com/2024/02/02/my-amazon-nightmares-2024/</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Americans' confidence in higher education has taken a nosedive (116 pts)]]></title>
            <link>https://lithub.com/americans-confidence-in-higher-education-has-taken-a-nosedive/</link>
            <guid>40991894</guid>
            <pubDate>Thu, 18 Jul 2024 02:03:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lithub.com/americans-confidence-in-higher-education-has-taken-a-nosedive/">https://lithub.com/americans-confidence-in-higher-education-has-taken-a-nosedive/</a>, See on <a href="https://news.ycombinator.com/item?id=40991894">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<a href="https://lithub.com/category/the-hub/">
		<div>
			<p><img src="https://s26162.pcdn.co/wp-content/plugins/lb-content-widgets/img/lit-horn.svg">
			</p>
			<p>
				<h2>The Hub</h2>
			</p>
			<p>
				<h2>News, Notes, Talk</h2>
			</p>
		</div>
		</a>
		
				<div>
				
				
				
				
				<p>According to <a href="https://news.gallup.com/poll/646880/confidence-higher-education-closely-divided.aspx" target="_blank">a new Gallup poll</a>, Americans are losing the thread with higher education. Confidence in college has taken a nosedive, with one out of three poll responders claiming they have “little or no confidence” in higher education. This contrasts sharply with a 2015 poll, when 57% of those surveyed claimed to to be fairly or “very” confident in the old hallowed halls.</p>
<p>Poll responders <a href="https://news.gallup.com/poll/646880/confidence-higher-education-closely-divided.aspx" target="_blank">cited several reasons</a> for a rising ambivalence. But among these, “pushing political agendas, not teaching relevant skills, and being overly expensive,” took the cake. The faith-ebbing trend holds true across all demographics surveyed. Though conservatives skewed quite a bit angrier as a block, with Republicans citing fear of liberal “indoctrination” as a big reason for foregoing four-year-ed.</p>
<p>Perhaps this news won’t shock you to your socks, considering the interlocking crises of 1) <a href="https://www.luminafoundation.org/news-and-views/sticker-shock-americans-say-college-costs-are-too-high-and-unclear/" target="_blank">un-affordability</a>, 2) fresh light on the <a href="https://knowyourdebt.debtcollective.org/student" target="_blank">scam that is student loans</a>, 3) an unpromising job market with diminishing returns for un-STEM professions and 3) the many tortured varietals of “free speech” discourse. Every corner of academia is famously in trouble, from <a href="https://www.insidehighered.com/blogs/higher-ed-gamma/adjunctification-gen-ed-0" target="_blank">adjuncts</a> to alumni.</p>
<p>And considering too how <a href="https://www.thenation.com/article/society/student-journalists-campus-repression-palestine-protests/" target="_blank">poorly students have been treated by the mainstream media</a>, I’m personally hard-pressed to imagine the high-ed advocate who <em>could</em> claim full confidence in The University. Still, it’s striking that responders are citing more than material objections. Increasingly, to-college or not-to-college feels like an ethical question.</p>
<p>Even if today’s young person goes in knowing that their private college humanities degree could prove professionally useless, it was plausible till recently that such a degree could at least yield cryptic intellectual benefits.</p>
<p>In a 2020 piece for <em>The New Republic</em>, Dr. Wim Wiewel of Lewis &amp; Clark University outlined <a href="https://newrepublic.com/article/157845/case-liberal-arts-college-coronavirus-crisis" target="_blank">three core goals of a liberal arts education</a>: “to encourage lifelong exploration of the self and one’s own values; to develop the skills needed to embark on meaningful careers; and to prepare for full, and civil, participation in public life.” This rubric surely conveys the enlightenment-era tea yours truly was sipping, when I elected to take on a BFA for a six figure ticket price. But such benefits look starry-eyed from here.</p>
<p>These days, there are very different corridors for “civil participation.” And, thanks to an <a href="https://www.newyorker.com/culture/2022-in-review/the-year-in-quiet-quitting" target="_blank">ongoing interrogation of office life under capitalism</a>, the definition of a “meaningful career” isn’t static, either. “Public life” is increasingly siloed, too, in a country where large parts of the population <a href="https://theintercept.com/2023/09/15/deconstructed-naomi-klein-doppelganger-book/" target="_blank">fail to agree on basic tenets of reality</a>. Let alone how schools should operate.</p>
<p>This is all to say: I get it, youth of America. Ad hoc classes plus robust hobbies plus library creepin’ plus learning a trade with a strong union looks more and more reasonable to me, as a life plan. And a(n unscientifically conducted) poll of the Lit Hub masthead seems to agree. But to each their own.</p>
<p>It could also be a matter of time. As the Gallup poll notes, confidence in community college and two year programs is up.</p>
<p><em>Image <a href="https://www.buzzfeed.com/mx/luisdelvalle/mundo-enfermo-y-triste" target="_blank">via</a></em></p>
				
										
									
				

				

			</div>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A RP2040 based DECstation 3000 emulator that can run DECWindows (163 pts)]]></title>
            <link>https://github.com/rscott2049/DECstation2040</link>
            <guid>40991182</guid>
            <pubDate>Wed, 17 Jul 2024 23:11:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/rscott2049/DECstation2040">https://github.com/rscott2049/DECstation2040</a>, See on <a href="https://news.ycombinator.com/item?id=40991182">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">DECstation 2040</h2><a id="user-content-decstation-2040" aria-label="Permalink: DECstation 2040" href="#decstation-2040"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">1.0 Introduction</h2><a id="user-content-10-introduction" aria-label="Permalink: 1.0 Introduction" href="#10-introduction"></a></p>
<p dir="auto">This document outlines the DECstation 2040, a RP2040 based DECstation 3000
emulator that can run DECWindows. A summary of features:</p>
<p dir="auto">Hardware:</p>
<ul dir="auto">
<li>RP2040, running at 1.8v/300 MHz</li>
<li>32 MB of PSRAM</li>
<li>8 MB SPI flash</li>
<li>uSD card socket</li>
<li>Monochrome VGA at 1024 x 864</li>
<li>Ethernet RMII PHY support (socket on rev 1.5, integrated in rev 2.1)</li>
</ul>
<p dir="auto">Software:</p>
<ul dir="auto">
<li>4 port PSRAM PIO engine</li>
<li>PIO driven VGA, with seperate 16x16 cursor plane overlay</li>
<li>USB HID to DECWindows keyboard and mouse</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">1.1 Software</h2><a id="user-content-11-software" aria-label="Permalink: 1.1 Software" href="#11-software"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">PIO:</h3><a id="user-content-pio" aria-label="Permalink: PIO:" href="#pio"></a></p>
<p dir="auto">The PSRAM/HyperRAM PIO engine provides 42/32 MB/s (write/read) of memory
bandwidth. Further, four PIO engines are used to provide four seperate
read/write memory ports. This allows independent memory access for
the emulated CPU, video DMA, and receive/send Ethernet traffic. Note that
all 32 instruction slots are used.</p>
<p dir="auto">The video PIO engine can support up to a sysclk/2 pixel rate. Thus,
for the 300 MHz sysclk typically used, it is possible to run 1080p60 at
a pixel rate of 148.5 MHz. The default video rate is 1024 x 768 @ 70Hz,
as this matches the screen used for development and the pixel rate
is an integral divisor from sysclk. Only five PIO instruction slots are
used.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">DMA:</h3><a id="user-content-dma" aria-label="Permalink: DMA:" href="#dma"></a></p>
<p dir="auto">To drive the video PIO engine, five DMA channels are used. They are allocated
as follows:</p>
<ul dir="auto">
<li>ctrl_dma_chan - points to DMA channel command packets</li>
<li>data_dma_chan - executes DMA command packets</li>
<li>ps_read_chan - points to PSRAM read data buffer</li>
<li>inc_dma_chan - used to generate loop counter indices</li>
<li>cur_inc_dma_chan - used as cursor loop counter</li>
</ul>
<p dir="auto">This project uses the RP2040 DMA sniffer to dynamically generate PSRAM
addresses, which eliminates the need to have a per-line PSRAM command packet.
Further, it uses the inc_dma_chan to enable DMA command loops, eliminating
per-line DMA commands needed to send commands to the PIO pixel and PSRAM
PIO engines. This makes the amount of memory needed to drive video
independent of the display format. Currently, 86 DMA command packets are
used vs. approximately 2250 required for 1080p if a per-line DMA structure
was used.</p>
<p dir="auto">In order to eliminate the latency from when the PSRAM PIO engine FIFO
has read data, and its delivery to SRAM, we use the ps_read_chan. This
channel is chained to after a PSRAM DMA command is executed. Without
this channel, the PSRAM PIO engine FIFO would be not be emptied until
the next DMA command is executed. This impacts the non-video PSRAM
channels, as they must wait unitl the video PSRAM command is complete.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">USB:</h3><a id="user-content-usb" aria-label="Permalink: USB:" href="#usb"></a></p>
<p dir="auto">The USB HID code supports (at least) two keyboard/mouse combo types:
Rii mini X1 (model: RT-MWK01), purchased at MicroCenter, and Logitech
K830.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Emulator:</h3><a id="user-content-emulator" aria-label="Permalink: Emulator:" href="#emulator"></a></p>
<p dir="auto">Dmitry's code at <a href="http://dmitry.gr/?r=05.Projects&amp;proj=33.%20LinuxCard" rel="nofollow">http://dmitry.gr/?r=05.Projects&amp;proj=33.%20LinuxCard</a> was
modified to support the RP2040, as well as adding support for video and USB
mouse/keyboard input. With overclocking and running the assembly language
version of the CPU emulator, Dmitry's Linux image reports a BOGOMIPS rating
of 13.44.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">2.0) Getting started</h2><a id="user-content-20-getting-started" aria-label="Permalink: 2.0) Getting started" href="#20-getting-started"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">2.1) Hardware</h2><a id="user-content-21-hardware" aria-label="Permalink: 2.1) Hardware" href="#21-hardware"></a></p>
<p dir="auto">Build either rev 1.5 or 2.1, using the appropriate emu_brd directory. Please
note that rev 2.1 is still undergoing Ethernet debug, and has exhibited
significant packet drops. I use JLCPCB for board fabrication, and there are
Digikey BOM spreadsheets in doc/bom. Recommend building two boards: one to
use as a 1.8v CMSIS debugger, and the other as the target. Feel free to only
populate the RP2040 related components on the CMSIS debugger.</p>
<p dir="auto">The surface mount parts aren't too troublesome - I find the PSRAM BGA to be
much easier to solder than the RP2040 QFN. My technique is to use a hot-air
SMT rework tool. Recommended assembly steps:</p>
<ol dir="auto">
<li>Solder the voltage regulator, check for 1.8v and 3.3v when done.</li>
<li>Solder all of the passives, the RP2040, flash, and the USB connectors
if building rev 2.1. (Note that two bodge wires are needed to connect J5
and J11 D+/D- as my assumption that USB-A could serve as non-host connector
was incorrect).
When done, use blink_bringup (below) to check connections. (Edit blink.c
to enable the pins to check).</li>
<li>Solder the HyperRAM chip, run mem_test to check connections.</li>
<li>Solder the voltage translator chips, edit blink.c and run to check
connections.</li>
<li>Solder the connectors.</li>
</ol>
<p dir="auto">For rev 1.5:
Needs modified waveshare LAN8722 board. In addition to the modifications
outlined at: <a href="https://github.com/maximeborges/pico-rmii-ethernet">https://github.com/maximeborges/pico-rmii-ethernet</a>, pin 13 of
the 7 x 2 connector (originally NC) is used as VDDIO for the LAN8722 chip.
To make this modification, cut the existing connection between LAN8722 pin
9 to 3.3v, and route pin 9 to pin 13 of the connector. This allows the use
of 1.8v I/O from the DECstation 2040 board. Also needed is a 6 pin header
to VGA connector. See rev 2.1 schematic for VGA pins needed.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">2.2) Software</h2><a id="user-content-22-software" aria-label="Permalink: 2.2) Software" href="#22-software"></a></p>
<p dir="auto">Start with:
<a href="http://dmitry.gr/?r=05.Projects&amp;proj=33.%20LinuxCard" rel="nofollow">http://dmitry.gr/?r=05.Projects&amp;proj=33.%20LinuxCard</a>
Download the images, particularly the ultrix.gui image. This should be placed
on a FAT32 for uMIPS. Edit uc_main.c to select which image to run.</p>
<p dir="auto">Next, go to where this README.md is stored. Then set current directory to sw.
Edit the "source_this" file to reflect the location of the Pico SDK, and source
this file to set the PICO_SDK environment variable for the current session.</p>
<p dir="auto">A good place to start is with the blink_bringup directory. CD to this,
and do:</p>
<p dir="auto"><code>cmake -B build -S .</code></p>
<p dir="auto">Build software via</p>
<p dir="auto"><code>./build.sh</code></p>
<p dir="auto">This will generate an .elf file in build/src. Use picotool to load this onto
the target board. After rebooting, should get "hello, world" on USB serial, as
well as on the hardware serial port. A 500 Hz square wave should be present
on GPIO21 (ret_clk). This can be changed via editing the src/blink.c file.
I use this tool incrementally while soldering the board, to verify connectivity.</p>
<p dir="auto">Next, build the CMSIS debugger. CD to the picoprobe directory and
build with:</p>
<p dir="auto"><code>cmake -B build -DCUSTOMPROBE=1 make -C build</code></p>
<p dir="auto">Program with</p>
<p dir="auto"><code>sudo picotool load build/customprobe.elf</code></p>
<p dir="auto">Now go to the psram directory and do:</p>
<p dir="auto"><code>cmake -B build -S .</code></p>
<p dir="auto">Build software via</p>
<p dir="auto"><code>./build.sh</code></p>
<p dir="auto">This will generate most of the available packages. Of interest are:</p>
<ul dir="auto">
<li>mem_test - a simple memory tester</li>
<li>fb_test - test program for the frame buffer library</li>
<li>fb_mem_test - memory test with frame buffer enabled</li>
<li>pico-rv32ima - RISC-V linux emulation</li>
<li>uMIPS - DECstation emulation</li>
<li>pico_rmii_ethernet_httpd - test program for RMII.</li>
</ul>
<p dir="auto">There are shell scripts to load the above:</p>
<ul dir="auto">
<li>cl_sram.sh   - sd command line</li>
<li>eth_sram.sh  - ethernet test</li>
<li>fb_flash.sh  - framebuffer library test, run from flash</li>
<li>fb_sram.sh   - framebuffer library test, run from SRAM</li>
<li>fbm_flash.sh - memory test with framebuffer enabled, run from flash</li>
<li>fbm_sram.sh  - memory test with framebuffer enabled, run from SRAM</li>
<li>mt_sram.sh   - memory test, run from SRAM</li>
<li>mt_flash.sh  - memory test, run from flash</li>
<li>um_flash.sh - uMIPS emulator, run from flash</li>
<li>um_sram.sh  - uMIPS emulator, run from SRAM</li>
</ul>
<p dir="auto">Running the code:
Connect the debugger board to the SWD port on the target.
Start the CMSIS debugger via sw/start_cmsis.sh.
Execute one of the scripts above. This will load the program into RP2040
SRAM and start it.</p>
<p dir="auto">If you wish to run from flash, comment out the no_flash line in the source CMakeLists.txt. Note that the uMIPS emulator requires "copy_to_ram" to be enabled
when running from flash.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">3.0) Commentary</h2><a id="user-content-30-commentary" aria-label="Permalink: 3.0) Commentary" href="#30-commentary"></a></p>
<p dir="auto">This project has been a voyage of discovery. The first doc/build_log.txt entry
was on 23-mar-2023, but I'd been thinking of building a business card
ever since I'd read Dmitry's LinuxCard web page. I've learned how to
use the RP2040 PIO engines and the DMA subsystem to push pixels. I'm
amazed at how flexible and capable the RP2040 has turned out to be. Hats off
to the RP2040 designers!</p>
<p dir="auto">Most enjoyable moments:</p>
<ul dir="auto">
<li>When the PSRAM PIO engine finally ran the memory test overnight.</li>
<li>When the second solution to the problem of how to get the DMA subsytem
to do a counted loop actually worked without killing SD card access.</li>
<li>When the DMA cursor read data during blanking worked, giving smooth
cursor movement.</li>
</ul>
<p dir="auto">Less than enjoyable moments:</p>
<ul dir="auto">
<li>Realizing the "optimization" of reordering data on the PSRAM to improve
layout was wrong, after submitting the design to JLCPCB.</li>
<li>Realizing that the first flash part chosen didn't support "Continuous Read
Mode". On the other hand, this did force me to learn how to do SRAM builds,
speeding up development.</li>
<li>Having the wrong footprint for the level translator on rev 1.3.</li>
<li>Finding out that Digikey no longer stocked the Ethernet connector on
rev 2.0, after submitting PCB. Related - the PSRAM was out of stock, so
clicked on the recommended alternative. Was disappointed when the box
showed up, and it was the waferscale part. Tiny, but unsolderable.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">4.0) Next steps</h2><a id="user-content-40-next-steps" aria-label="Permalink: 4.0) Next steps" href="#40-next-steps"></a></p>
<ul dir="auto">
<li>Use the ps_get_buf DMA subroutine to setup the cursor PSRAM command. This
will reduce the memory footprint.</li>
<li>Write the lance Ethernet emulation code for uMIPS.</li>
<li>Port MicroMac <a href="https://axio.ms/projects/2024/06/16/MicroMac.html" rel="nofollow">https://axio.ms/projects/2024/06/16/MicroMac.html</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">5.0) Acknowledgements</h2><a id="user-content-50-acknowledgements" aria-label="Permalink: 5.0) Acknowledgements" href="#50-acknowledgements"></a></p>
<p dir="auto">This project would not exist without Dmitry's excellent LinuxCard project,
at: <a href="http://dmitry.gr/?r=05.Projects&amp;proj=33.%20LinuxCard" rel="nofollow">http://dmitry.gr/?r=05.Projects&amp;proj=33.%20LinuxCard</a></p>
<p dir="auto">Inspiration and software framework:
<a href="https://github.com/Wren6991/PicoDVI.git">https://github.com/Wren6991/PicoDVI.git</a></p>
<p dir="auto">DEC mouse and keyboard support used code from:
<a href="https://hackaday.io/project/19576-dec-mouse-adapter" rel="nofollow">https://hackaday.io/project/19576-dec-mouse-adapter</a> and
<a href="https://github.com/pkoning2/lk201emu.git">https://github.com/pkoning2/lk201emu.git</a></p>
<p dir="auto">Ethernet:
<a href="https://github.com/maximeborges/pico-rmii-ethernet">https://github.com/maximeborges/pico-rmii-ethernet</a></p>
<p dir="auto">Also, Hackaday.com for articles on SMT soldering, USB-C, etc., giving me
confidence that I could actually do this project!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Pictures/video</h2><a id="user-content-picturesvideo" aria-label="Permalink: Pictures/video" href="#picturesvideo"></a></p>
<p dir="auto">A selection of pictures from doc/photos follows. See doc/photos for pictures
of previous versions and how the emulated video output progressed from first
pixel to current.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Video showing <a href="https://youtu.be/O6Lyjsey6ek" rel="nofollow">Xmaze/worms</a> running</h3><a id="user-content-video-showing-xmazeworms-running" aria-label="Permalink: Video showing Xmaze/worms running" href="#video-showing-xmazeworms-running"></a></p>
<div dir="auto"><h3 tabindex="-1" dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/rscott2049/DECstation2040/blob/main/doc/photos/PXL_20240622_180827183.jpg"><img src="https://github.com/rscott2049/DECstation2040/raw/main/doc/photos/PXL_20240622_180827183.jpg" alt="Rev 1.5"></a></h3><a id="" aria-label="Permalink: " href="#"></a></div>
<p dir="auto">Rev 1.5</p>
<div dir="auto"><h3 tabindex="-1" dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/rscott2049/DECstation2040/blob/main/doc/photos/PXL_20240629_191452477.MP_exported_2450.jpg"><img src="https://github.com/rscott2049/DECstation2040/raw/main/doc/photos/PXL_20240629_191452477.MP_exported_2450.jpg" alt="Rev 1.5"></a></h3><a id="user-content--1" aria-label="Permalink: " href="#-1"></a></div>
<p dir="auto">Rev 1.5 running</p>
<div dir="auto"><h3 tabindex="-1" dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/rscott2049/DECstation2040/blob/main/doc/photos/PXL_20240622_180952507.jpg"><img src="https://github.com/rscott2049/DECstation2040/raw/main/doc/photos/PXL_20240622_180952507.jpg" alt="Rev 2.1"></a></h3><a id="user-content--2" aria-label="Permalink: " href="#-2"></a></div>
<p dir="auto">Rev 2.1</p>
<div dir="auto"><h3 tabindex="-1" dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/rscott2049/DECstation2040/blob/main/doc/photos/PXL_20240629_191452477.MP_exported_2450.jpg"><img src="https://github.com/rscott2049/DECstation2040/raw/main/doc/photos/PXL_20240629_191452477.MP_exported_2450.jpg" alt="Rev 2.1"></a></h3><a id="user-content--3" aria-label="Permalink: " href="#-3"></a></div>
<p dir="auto">Rev 2.1 running</p>
<div dir="auto"><h3 tabindex="-1" dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/rscott2049/DECstation2040/blob/main/doc/photos/PXL_20240621_225529491.jpg"><img src="https://github.com/rscott2049/DECstation2040/raw/main/doc/photos/PXL_20240621_225529491.jpg" alt="Helper cat in the parts box"></a></h3><a id="user-content--4" aria-label="Permalink: " href="#-4"></a></div>
<p dir="auto">Helper cat in the parts box</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SAPwned: SAP AI vulnerabilities expose customers' cloud environments and privat (209 pts)]]></title>
            <link>https://www.wiz.io/blog/sapwned-sap-ai-vulnerabilities-ai-security</link>
            <guid>40990768</guid>
            <pubDate>Wed, 17 Jul 2024 22:02:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wiz.io/blog/sapwned-sap-ai-vulnerabilities-ai-security">https://www.wiz.io/blog/sapwned-sap-ai-vulnerabilities-ai-security</a>, See on <a href="https://news.ycombinator.com/item?id=40990768">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2><a id="does-ai-have-an-isolation-problem-0"></a><strong>Does AI have an isolation problem?&nbsp;</strong>&nbsp;&nbsp;</h2><p>Over the past months, we on the Wiz Research Team have conducted extensive tenant isolation research on multiple AI service providers. We believe these services are more susceptible to tenant isolation vulnerabilities, since by definition, they allow users to run AI models and applications – which is equivalent to executing arbitrary code. As AI infrastructure is fast becoming a staple of many business environments, the implications of these attacks are becoming more and more significant.&nbsp;&nbsp;</p><p>We will be presenting our findings from this research project at the upcoming Black Hat conference, in our session “<a rel="noreferrer noopener" target="_blank" href="https://www.wiz.io/events/blackhat-wiz-talk"><u>Isolation or Hallucination? Hacking AI Infrastructure Providers for Fun and Weights</u></a>”.&nbsp;</p><p>For the latest installment of this project, we researched SAP’s AI offering, aptly named “SAP AI Core.” This is our 3rd report in the series, following our research on the <a rel="noreferrer noopener" target="_blank" href="https://www.wiz.io/blog/wiz-and-hugging-face-address-risks-to-ai-infrastructure"><u>Hugging Face</u></a> and <a rel="noreferrer noopener" target="_blank" href="https://www.wiz.io/blog/wiz-research-discovers-critical-vulnerability-in-replicate"><u>Replicate</u></a> platforms. This blog will explore the vulnerability chain and detail our findings, dubbed “SAPwned,” while also looking at the potential impact and broader takeaways for securing managed AI platforms.&nbsp;</p><h2><a id="executive-summary-4"></a><strong>Executive Summary</strong>&nbsp;</h2><p>The AI training process requires access to vast amounts of sensitive customer data, which turns AI training services into attractive targets for attackers. SAP AI Core offers integrations with HANA and other cloud services, to access customers’ internal data via cloud access keys. These credentials are highly sensitive, and our research goal was to determine if potential malicious actors could gain access to these customer secrets.</p><p>Our research into SAP AI Core began through executing legitimate AI training procedures using SAP’s infrastructure. By executing arbitrary code, we were able move laterally and take over the service – gaining access to customers’ private files, along with credentials to customers’ cloud environments: AWS, Azure, SAP HANA Cloud, and more. <strong>The vulnerabilities we found could have allowed attackers to access customers’ data and contaminate internal artifacts – spreading to related services and other customers’ environments.</strong>&nbsp;</p><p>Specifically, the access we gained allowed us to:&nbsp;</p><ul><li><p>Read and modify Docker images on SAP’s internal container registry&nbsp;</p></li><li><p>Read and modify SAP’s Docker images on Google Container Registry&nbsp;</p></li><li><p>Read and modify artifacts on SAP’s internal Artifactory server&nbsp;</p></li><li><p>Gain cluster administrator privileges on SAP AI Core’s Kubernetes cluster&nbsp;</p></li><li><p>Access customers’ cloud credentials and private AI artifacts&nbsp;</p></li></ul><figure><figcaption>Step-by-step illustration of our research findings&nbsp;</figcaption></figure><p>The root cause of these issues was the ability for attackers to run malicious AI models and training procedures, which are essentially code. After reviewing several leading AI services, we believe the industry must improve its isolation and sandboxing standards when running AI models.&nbsp;&nbsp;</p><p>All vulnerabilities have been reported to SAP’s security team and fixed by SAP, as acknowledged <a rel="noreferrer noopener" target="_blank" href="https://support.sap.com/en/my-support/knowledge-base/security-notes-news/credits-for-security-researchers.html?anchorId=M7#M7"><u>on their website</u></a>. We thank them for their cooperation. No customer data was compromised.&nbsp;</p><p>Following is a technical dive into our vulnerability chain and findings.&nbsp;</p><h2><a id="introduction-the-research-begins-14"></a><strong>Introduction: The research begins</strong>&nbsp;</h2><p>SAP AI Core is a service that allows users to develop, train and run AI services in a scalable and managed way, utilizing SAP’s vast cloud resources. Similar to other cloud providers (and AI infrastructure providers), the customer’s code runs within SAP’s shared environment – posing a risk of cross-tenant access.&nbsp;</p><p>Our research began as an SAP customer, with basic permissions allowing us to create AI projects. So, we started out by creating a regular AI application on SAP AI Core. SAP’s platform allowed us to provide an Argo Workflow file, which in turn spawned a new Kubernetes Pod according to our configuration.&nbsp;</p><figure><figcaption>Example Argo Workflow configuration on SAP AI Core&nbsp;</figcaption></figure><p>This allowed us to run our own arbitrary code within the Pod by design – no vulnerability needed. However, our environment was quite restricted. We quickly realized our Pod had extremely limited network access, as enforced by an Istio proxy sidecar – so scanning the internal network wasn’t an option for us. Yet.&nbsp;&nbsp;</p><h2><a id="bug-1-bypassing-network-restrictions-with-the-power-of-1337-19"></a><strong>Bug #1: Bypassing network restrictions with the power of 1337</strong>&nbsp;</h2><p>The first thing we tried was to configure our Pod with “interesting” privileges. However, SAP’s admission controller blocked all the dangerous security options we tried – for example, running our container as <code>root</code>.&nbsp;</p><p>Despite that, we found two interesting configurations that the admission controller failed to block.&nbsp;</p><p>The first is <code>shareProcessNamespace</code>, which allowed us to share the process namespace with our sidecar container. Since our sidecar was the Istio proxy, we gained access to Istio’s configuration, including an access token to the cluster’s centralized Istiod server.&nbsp;</p><figure><figcaption>Accessing the Istio token via our sidecar container&nbsp;</figcaption></figure><p>The other is <code>runAsUser</code> (and <code>runAsGroup</code>). Although we couldn’t be root, all other UIDs were allowed – including Istio’s UID, which ironically enough was <code>1337</code> (yeah, really). We set our UID to 1337 and successfully ran as the Istio user. Since Istio itself is <a rel="noreferrer noopener" target="_blank" href="https://istio.io/latest/docs/reference/config/analysis/ist0144/"><u>excluded from Istio’s iptables rules</u></a> – we were now running without any traffic restrictions!&nbsp;</p><figure><figcaption>Sending requests to the internal network – before and after UID 1337&nbsp;</figcaption></figure><p>Free from our traffic shackles, we started scanning our Pod’s internal network. Using our Istio token, we were able to read configurations from the Istiod server and gain insight on the internal environment – which led us to the following findings.&nbsp;</p><h2><a id="bug-2-loki-leaks-aws-tokens-27"></a><strong>Bug #2: Loki leaks AWS tokens</strong>&nbsp;&nbsp;</h2><p>We found an instance of Grafana Loki on the cluster, so we requested the <code>/config</code> endpoint to view Loki’s configuration. The API responded with the full configuration, including AWS secrets that Loki used to access S3:&nbsp;</p><figure><figcaption>Configuration excerpt from SAP’s Loki server&nbsp;</figcaption></figure><p>These secrets granted access to Loki’s S3 bucket, containing a large trove of logs from AI Core services (which SAP says aren’t sensitive) and customer Pods.&nbsp;</p><figure><figcaption>Partial file list from Loki’s S3 bucket&nbsp;</figcaption></figure><h2><a id="bug-3-unauthenticated-efs-shares-expose-user-files-32"></a><strong>Bug #3: Unauthenticated EFS shares expose user files</strong>&nbsp;</h2><p>Within the internal network, we found 6 instances of AWS Elastic File System (EFS), listening on port 2049. A <a rel="noreferrer noopener" target="_blank" href="https://youtu.be/HcNmkCRXFdE"><u>common problem</u></a> with EFS instances is their default configuration as public – meaning credentials aren’t needed to view or edit files, as long as you have network access to their NFS ports. These instances were no different, and using simple open-source NFS tools, we were able to freely access the shares’ contents.&nbsp;</p><p>Listing files stored on these EFS instances has revealed mass amounts of AI data, including code and training datasets, categorized by customer ID:&nbsp;</p><figure></figure><figure><figcaption>Partial file list from two EFS shares; each folder represents a different customer ID</figcaption></figure><h2><a id="bug-4-unauthenticated-helm-server-compromises-internal-docker-registry-and-artifactory-37"></a><strong>Bug #4: Unauthenticated Helm server compromises internal Docker Registry and Artifactory</strong>&nbsp;</h2><p>Our most interesting finding on the network was a service named Tiller, which is the server component of the Helm package manager (in version 2).&nbsp;</p><p>Communication with Tiller is made via its gRPC interface on port 44134, which is by default exposed without any authentication.&nbsp;&nbsp;</p><p>Querying this server on our internal network revealed highly privileged secrets to SAP’s Docker Registry as well as its Artifactory server:&nbsp;&nbsp;</p><figure><figcaption>Container registry and Artifactory credentials – exposed by Helm server query</figcaption></figure><p>Using these secrets’ read access, a potential attacker could read internal images and builds, extracting commercial secrets and possibly customer data.&nbsp;</p><p>Using the secrets’ write access, an attacker could poison images and builds, conducting a supply-chain attack on SAP AI Core services.&nbsp;</p><h2><a id="bug-5-unauthenticated-helm-server-compromises-k8s-cluster-exposing-google-access-tokens-and-customer-secrets-45"></a><strong>Bug #5: Unauthenticated Helm server compromises K8s cluster, exposing Google access tokens and customer secrets</strong>&nbsp;</h2><p>The Helm server was exposed to both read and write operations. While the read access exposed sensitive secrets (as can be seen above), the server’s write access allowed for a complete cluster takeover.&nbsp;</p><p>Tiller’s <code>install</code> command takes a Helm package and deploys it to the K8s cluster. We created a malicious Helm package that spawns a new Pod with <code>cluster-admin</code> privileges, and ran the install command.&nbsp;</p><p>We were now running with full privileges on the cluster!&nbsp;</p><figure><figcaption>Partial list of K8s permissions we obtained via Helm&nbsp;</figcaption></figure><p>Using this access level, an attacker could directly access other customer’s Pods and steal sensitive data, such as models, datasets, and code. This access also allows attackers to interfere with customer’s Pods, taint AI data and manipulate models’ inference.&nbsp;</p><p>Furthermore, this access level would have allowed us to view customers’ own secrets – even secrets that are beyond the scope of SAP AI Core. For example, our AI Core account contained secrets to our AWS account (for S3 data access), our SAP HANA account (for Data Lake access), and our Docker Hub account (to pull our images). Using our newfound access level, we queried for those secrets, and managed to access all of them in plaintext:&nbsp;</p><figure><figcaption>Accessing customer secrets using our K8s permissions&nbsp;</figcaption></figure><p>The same query also revealed an SAP access key to Google Container Registry, named <code>sap-docker-registry-secret</code>. We have confirmed that this key grants both read and write permissions – further enlarging the scope of a potential supply-chain attack.&nbsp;</p><h2><a id="takeaways-54"></a><strong>Takeaways</strong>&nbsp;</h2><p>Our research into SAP AI Core demonstrates the importance of defense in depth. The main security obstacle we were facing was Istio blocking our traffic from reaching the internal network. Once we were able to bypass that obstacle, we gained access to several internal assets that did not require any additional authentication – meaning the internal network was perceived as trusted. Hardening those internal services could have minimized the impact of this attack and downgraded it from a complete service takeover to a minor security incident.&nbsp;&nbsp;</p><p>In line with our previous Kubernetes-related vulnerabilities, this research also demonstrates the tenant isolation pitfalls of using K8s in managed services. The crucial separation between the control plane (service logic) and the data plane (customer compute) is being impacted by the K8s architecture, which allows logical connections between them through APIs, identities, shared compute, and software-segmented networks.&nbsp;</p><p>Furthermore, this research demonstrates the unique challenges that the AI R&amp;D process introduces. AI training requires running arbitrary code by definition; therefore, appropriate guardrails should be in place to assure that untrusted code is properly separated from internal assets and other tenants.&nbsp;</p><h2><a id="disclosure-timeline-59"></a>Disclosure timeline&nbsp;</h2><ul><li><p><strong>Jan. 25, 2024</strong> – Wiz Research reports security findings to SAP&nbsp;</p></li><li><p><strong>Jan. 27, 2024</strong> – SAP replies and assigns a case number&nbsp;</p></li><li><p><strong>Feb. 16, 2024</strong> – SAP fixes first vulnerability and rotates relevant secrets&nbsp;</p></li><li><p><strong>Feb. 28, 2024 </strong>– Wiz Research bypasses the patch using 2 new vulnerabilities, reports to SAP&nbsp;</p></li><li><p><strong>May 15, 2024</strong> – SAP deploys fixes for all reported vulnerabilities&nbsp;</p></li><li><p><strong>Jul. 17, 2024 </strong>– Public disclosure&nbsp;</p></li></ul><h2><a id="stay-in-touch-61"></a>Stay in touch!&nbsp;</h2><p>Hi there! We are Hillai Ben-Sasson (<a rel="noreferrer noopener" target="_blank" href="https://twitter.com/hillai"><u>@hillai</u></a>), Shir Tamari (<a rel="noreferrer noopener" target="_blank" href="https://twitter.com/shirtamari"><u>@shirtamari</u></a>), Nir Ohfeld (<a rel="noreferrer noopener" target="_blank" href="https://twitter.com/nirohfeld"><u>@nirohfeld</u></a>), Sagi Tzadik (<a rel="noreferrer noopener" target="_blank" href="https://twitter.com/sagitz_"><u>@sagitz_</u></a>) and Ronen Shustin (<a rel="noreferrer noopener" target="_blank" href="https://twitter.com/ronenshh"><u>@ronenshh</u></a>) from the Wiz Research Team. We are a group of veteran white-hat hackers with a single goal: to make the cloud a safer place for everyone. We primarily focus on finding new attack vectors in the cloud and uncovering isolation issues in cloud vendors.&nbsp;</p><p>We would love to hear from you! Feel free to contact us on Twitter or via email: <a rel="noreferrer noopener" target="_blank" href="mailto:research@wiz.io"><u>research@wiz.io</u></a>. &nbsp;</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: SQLite Transaction Benchmarking Tool (104 pts)]]></title>
            <link>https://github.com/seddonm1/sqlite-bench</link>
            <guid>40990641</guid>
            <pubDate>Wed, 17 Jul 2024 21:44:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/seddonm1/sqlite-bench">https://github.com/seddonm1/sqlite-bench</a>, See on <a href="https://news.ycombinator.com/item?id=40990641">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">sqlite-bench</h2><a id="user-content-sqlite-bench" aria-label="Permalink: sqlite-bench" href="#sqlite-bench"></a></p>
<p dir="auto">A project to test SQLite Transaction behavior.</p>
<p dir="auto">Code to accompany blog post: <a href="https://reorchestrate.com/posts/sqlite-transactions" rel="nofollow">https://reorchestrate.com/posts/sqlite-transactions</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to use</h2><a id="user-content-how-to-use" aria-label="Permalink: How to use" href="#how-to-use"></a></p>
<p dir="auto">Compile by running <code>cargo build --release</code>.</p>
<p dir="auto">Run like: <code>cargo run --release -- --help</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="Benchmarking SQLite

Usage: sqlite-bench [OPTIONS] --path <PATH> --output <OUTPUT>

Options:
  -p, --path <PATH>           Path to the SQLite file
  -o, --output <OUTPUT>       Path to the output result file
  -s, --seed <SEED>           Number of records to seed the into the table [default: 1000000]
  -t, --threads <THREADS>...  Number of concurrent threads to spawn [default: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16]
  -s, --scans <SCANS>...      Scan operations to perform per transaction [default: 0 10]
  -u, --updates <UPDATES>...  Update operations to perform per transaction [default: 0 1 10]
  -h, --help                  Print help
  -V, --version               Print version"><pre>Benchmarking SQLite

Usage: sqlite-bench [OPTIONS] --path <span>&lt;</span>PATH<span>&gt;</span> --output <span>&lt;</span>OUTPUT<span>&gt;</span>

Options:
  -p, --path <span>&lt;</span>PATH<span>&gt;</span>           Path to the SQLite file
  -o, --output <span>&lt;</span>OUTPUT<span>&gt;</span>       Path to the output result file
  -s, --seed <span>&lt;</span>SEED<span>&gt;</span>           Number of records to seed the into the table [default: 1000000]
  -t, --threads <span>&lt;</span>THREADS<span>&gt;</span>...  Number of concurrent threads to spawn [default: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16]
  -s, --scans <span>&lt;</span>SCANS<span>&gt;</span>...      Scan operations to perform per transaction [default: 0 10]
  -u, --updates <span>&lt;</span>UPDATES<span>&gt;</span>...  Update operations to perform per transaction [default: 0 1 10]
  -h, --help                  Print <span>help</span>
  -V, --version               Print version</pre></div>
<p dir="auto">It is a good idea to run this against an in-memory filesystem first to protect your solid-state-drive.</p>
<p dir="auto">MacOS:</p>
<div dir="auto" data-snippet-clipboard-copy-content="diskutil erasevolume apfs 'ramdisk' `hdiutil attach -nobrowse -nomount ram://33554432`"><pre>diskutil erasevolume apfs <span><span>'</span>ramdisk<span>'</span></span> <span><span>`</span>hdiutil attach -nobrowse -nomount ram://33554432<span>`</span></span></pre></div>
<p dir="auto">Linux:</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo mkdir -p /mnt/ramdisk
sudo mount -t tmpfs -o size=16g tmpfs /mnt/ramdisk"><pre>sudo mkdir -p /mnt/ramdisk
sudo mount -t tmpfs -o size=16g tmpfs /mnt/ramdisk</pre></div>
<p dir="auto">A multiplatform Docker image is available at: <a href="https://github.com/users/seddonm1/packages/container/package/sqlite-bench">https://github.com/users/seddonm1/packages/container/package/sqlite-bench</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Product Hunt for Music (131 pts)]]></title>
            <link>https://tracklist.it/</link>
            <guid>40989451</guid>
            <pubDate>Wed, 17 Jul 2024 19:31:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tracklist.it/">https://tracklist.it/</a>, See on <a href="https://news.ycombinator.com/item?id=40989451">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h5> Welcome to <b>TrackList</b>! </h5><h3> The place to discover and share new music 🎧 </h3><p><a href="https://tracklist.it/how-it-works">Learn more</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Little Languages (1986) [pdf] (153 pts)]]></title>
            <link>https://staff.um.edu.mt/afra1/seminar/little-languages.pdf</link>
            <guid>40989069</guid>
            <pubDate>Wed, 17 Jul 2024 18:51:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://staff.um.edu.mt/afra1/seminar/little-languages.pdf">https://staff.um.edu.mt/afra1/seminar/little-languages.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=40989069">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[NVIDIA Transitions Fully Towards Open-Source Linux GPU Kernel Modules (774 pts)]]></title>
            <link>https://developer.nvidia.com/blog/nvidia-transitions-fully-towards-open-source-gpu-kernel-modules/</link>
            <guid>40988954</guid>
            <pubDate>Wed, 17 Jul 2024 18:40:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developer.nvidia.com/blog/nvidia-transitions-fully-towards-open-source-gpu-kernel-modules/">https://developer.nvidia.com/blog/nvidia-transitions-fully-towards-open-source-gpu-kernel-modules/</a>, See on <a href="https://news.ycombinator.com/item?id=40988954">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>With the R515 driver, NVIDIA released a set of <a href="https://developer.nvidia.com/blog/nvidia-releases-open-source-gpu-kernel-modules/" data-wpel-link="internal" target="_self" rel="noopener noreferrer">Linux GPU kernel</a> modules in May 2022 as open source with dual GPL and MIT licensing. The initial release targeted datacenter compute GPUs, with GeForce and Workstation GPUs in an alpha state.&nbsp;</p>



<p>At the time, we announced that more robust and fully-featured GeForce and Workstation Linux support would follow in subsequent releases and the NVIDIA Open Kernel Modules would eventually supplant the closed-source driver.&nbsp;</p>



<p>NVIDIA GPUs share a common driver architecture and capability set. The same driver for your desktop or laptop runs the world’s most advanced AI workloads in the cloud. It’s been incredibly important to us that we get it just right.&nbsp;</p>



<p>Two years on, we’ve achieved equivalent or better application performance with our open-source GPU kernel modules and added substantial new capabilities:</p>



<ul>
<li>Heterogeneous memory management (HMM) support</li>



<li>Confidential computing</li>



<li>The coherent memory architectures of our Grace platforms</li>



<li>And more</li>
</ul>



<p>We’re now at a point where transitioning fully to the open-source GPU kernel modules is the right move, and we’re making that change in the upcoming R560 driver release.</p>



<h2 id="supported_gpus">Supported GPUs<a href="#supported_gpus"><i></i></a></h2>



<p>Not every GPU is compatible with the open-source GPU kernel modules.</p>



<p>For cutting-edge platforms such as NVIDIA Grace Hopper or NVIDIA Blackwell, you must use the open-source GPU kernel modules. The proprietary drivers are unsupported on these platforms.</p>



<p>For newer GPUs from the Turing, Ampere, Ada Lovelace, or Hopper architectures, NVIDIA recommends switching to the open-source GPU kernel modules.</p>



<p>For older GPUs from the Maxwell, Pascal, or Volta architectures, the open-source GPU kernel modules are not compatible with your platform. Continue to use the NVIDIA proprietary driver.</p>



<p>For mixed deployments with older and newer GPUs in the same system, continue to use the proprietary driver.</p>



<p>If you are not sure, NVIDIA provides a new detection helper script to help guide you on which driver to pick. For more information, see the <strong>Using the installation helper script</strong> section later in this post.</p>



<h2 id="installer_changes">Installer changes<a href="#installer_changes"><i></i></a></h2>



<p>In general, the default version of the driver installed by all installation methods is switching from the proprietary driver to the open-source driver. There are a few specific scenarios that deserve special attention:</p>



<ul>
<li>Package managers with the CUDA metapackage</li>



<li>Runfile</li>



<li>Installation helper script</li>



<li>Package manager details</li>



<li>Windows Subsystem for Linux</li>



<li>CUDA Toolkit</li>
</ul>



<h3 id="using_package_managers_with_the_cuda_metapackage">Using package managers with the CUDA metapackage<a href="#using_package_managers_with_the_cuda_metapackage"><i></i></a></h3>



<p>When you are installing CUDA Toolkit using a package manager (not the .run file), installation metapackages exist and are commonly used. By installing a top-level <code>cuda</code> package, you install a combination of CUDA Toolkit and the associated driver release. For example, by installing cuda during the CUDA 12.5 release time frame, you get the proprietary NVIDIA driver 555 along with CUDA Toolkit 12.5.&nbsp;</p>



<p>Figure 1 shows this package structure.</p>


<div>
<figure><a href="https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/cuda-package-installation-before-12-6.png" data-wpel-link="internal" target="_self" rel="noopener noreferrer"><img decoding="async" width="624" height="201" src="https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/cuda-package-installation-before-12-6.png" alt="Diagram shows the flow of installing CUDA software that includes installing both the nvidia-driver-555 and cuda-toolkit-12.5 modules." srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/cuda-package-installation-before-12-6.png 624w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/cuda-package-installation-before-12-6-300x97.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/cuda-package-installation-before-12-6-179x58.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/cuda-package-installation-before-12-6-500x161.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/cuda-package-installation-before-12-6-160x52.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/cuda-package-installation-before-12-6-362x117.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/cuda-package-installation-before-12-6-341x110.png 341w" sizes="(max-width: 624px) 100vw, 624px"></a><figcaption><em>Figure 1. CUDA packages before CUDA Toolkit 12.6</em></figcaption></figure></div>


<p>Previously, using the open-source GPU kernel modules would mean that you could use the top-level metapackage. You would have had to install the distro-specific NVIDIA driver open package along with the cuda-toolkit-X-Y package of your choice.</p>



<p>Beginning with the CUDA 12.6 release, the flow effectively switches places (Figure 2).</p>


<div>
<figure><a href="https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/cuda-package-installation-after-12-6.png" data-wpel-link="internal" target="_self" rel="noopener noreferrer"><img decoding="async" width="624" height="202" src="https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/cuda-package-installation-after-12-6.png" alt="Diagram shows the revised flow of installing CUDA software, where the nvidia-driver-open-560 and cuda-toolkit-12.6 modules are installed instead." srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/cuda-package-installation-after-12-6.png 624w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/cuda-package-installation-after-12-6-300x97.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/cuda-package-installation-after-12-6-179x58.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/cuda-package-installation-after-12-6-500x162.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/cuda-package-installation-after-12-6-160x52.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/cuda-package-installation-after-12-6-362x117.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/cuda-package-installation-after-12-6-340x110.png 340w" sizes="(max-width: 624px) 100vw, 624px"></a><figcaption><em>Figure 2. CUDA packages after the CUDA Toolkit 12.6 release</em></figcaption></figure></div>


<h3 id="using_the_runfile">Using the runfile<a href="#using_the_runfile"><i></i></a></h3>



<p>If you install CUDA or the NVIDIA drivers using the <code>.run</code> file, the installer queries your hardware and automatically installs the best-fit driver for your system. UI toggles are also available to select between the proprietary driver and the open source driver, as you choose.</p>



<p>If you’re installing through the CUDA .run file and using the <code>ncurses</code> user interface, you now see a menu similar to the following:</p>


<div><pre title="">┌──────────────────────────────────────────────────────────────────────────────┐
│ CUDA Driver                                                                  │
│   [ ] Do not install any of the OpenGL-related driver files                  │
│   [ ] Do not install the nvidia-drm kernel module                            │
│   [ ] Update the system X config file to use the NVIDIA X driver             │
│ - [X] Override kernel module type                                            │
│      [X] proprietary                                                         │
│      [ ] open                                                                │
│   Change directory containing the kernel source files                        │
│   Change kernel object output directory                                      │
│   Done                                                                       │
│                                                                              │
│                                                                              │
│                                                                              │
│ Up/Down: Move | Left/Right: Expand | 'Enter': Select | 'A': Advanced options │
└──────────────────────────────────────────────────────────────────────────────┘

</pre></div>


<p>If you’re installing through the driver .run file, you see a similar choice presented (Figure 3).</p>


<div>
<figure><img loading="lazy" decoding="async" width="937" height="417" src="https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/runfile-interactive-selection.png" alt="Screenshot shows the user interface highlighting two buttons labeled NVIDIA Proprietary and MIT/GPL, respectively. It suggests the user choose the MIT/GPL button to install the correct kernel module type." srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/runfile-interactive-selection.png 937w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/runfile-interactive-selection-300x134.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/runfile-interactive-selection-625x278.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/runfile-interactive-selection-179x80.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/runfile-interactive-selection-768x342.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/runfile-interactive-selection-645x287.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/runfile-interactive-selection-500x223.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/runfile-interactive-selection-160x71.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/runfile-interactive-selection-362x161.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/runfile-interactive-selection-247x110.png 247w" sizes="(max-width: 937px) 100vw, 937px"><figcaption><em>Figure 3. New runfile interactive selection (driver installer)</em></figcaption></figure></div>


<p>You can also pass overrides using the command line to install without the user interface or if you are using automation tools such as Ansible.</p>


<div><pre title=""># sh ./cuda_12.6.0_560.22_linux.run --override --kernel-module-type=proprietary

# sh ./NVIDIA-Linux-x86_64-560.run --kernel-module-type=proprietary
</pre></div>


<h3 id="using_the_installation_helper_script">Using the installation helper script<a href="#using_the_installation_helper_script"><i></i></a></h3>



<p>As mentioned earlier, if you’re unsure which driver to pick for the GPUs in your system, NVIDIA created a helper script to guide you through the selection process.&nbsp;</p>



<p>To use it, first install the <code>nvidia-driver-assistant</code> package with your package manager, then run the script:</p>


<div><pre title="">$ nvidia-driver-assistant
</pre></div>


<h3 id="package_manager_details">Package manager details<a href="#package_manager_details"><i></i></a></h3>



<p>For a consistent experience, NVIDIA recommends that you use package managers to install CUDA Toolkit and the drivers. However, the specific details of which package management systems are used by different distributions or how packages are structured can vary depending on your particular distribution.&nbsp;</p>



<p>This section outlines the specific details, caveats, or migration steps needed for various platforms.&nbsp;</p>



<h4>apt: Ubuntu and Debian-based distributions</h4>



<p>Run the following command:</p>


<div><pre title="">$ sudo apt-get install nvidia-open
</pre></div>


<p>To upgrade using the <code>cuda</code> metapackage on Ubuntu 20.04, first switch to open kernel modules:</p>


<div><pre title="">$ sudo apt-get install -V nvidia-kernel-source-open

$ sudo apt-get install nvidia-open
</pre></div>


<h4>dnf: Red Hat Enterprise Linux, Fedora, Kylin, Amazon Linux, or Rocky Linux</h4>



<p>Run the following command:</p>


<div><pre title="">$ sudo dnf module install nvidia-driver:open-dkms
</pre></div>


<p>To upgrade using the <code>cuda</code> metapackage on dnf-based distros, module streams must be disabled:</p>


<div><pre title="">$ echo "module_hotfixes=1" | tee -a /etc/yum.repos.d/cuda*.repo
$ sudo dnf install --allowerasing nvidia-open
$ sudo dnf module reset nvidia-driver
</pre></div>


<h4>zypper: SUSE Linux Enterprise Server, or OpenSUSE</h4>



<p>Run one of the following commands:</p>


<div><pre title=""># default kernel flavor
$ sudo zypper install nvidia-open
</pre></div>

<div><pre title=""># azure kernel flavor (sles15/x86_64)
$ sudo zypper install nvidia-open-azure
</pre></div>

<div><pre title=""># 64kb kernel flavor (sles15/sbsa) required for Grace-Hopper
$ sudo zypper install nvidia-open-64k
</pre></div>


<h4>Package manager summary</h4>



<p>For simplification, we’ve condensed the package manager recommendations in table format. All releases beyond driver version 560 and CUDA Toolkit 12.6 will use these packaging conventions.</p>



<figure><table><tbody><tr><td><strong>Distro</strong></td><td><strong>Install the latest&nbsp;</strong></td><td><strong>Install a specific release&nbsp;</strong></td></tr><tr><td>Fedora/RHEL/Kylin</td><td><code>dnf module install nvidia-driver:open-dkms</code></td><td><code>dnf module install nvidia-driver:560-open</code></td></tr><tr><td>openSUSE/SLES</td><td><code>zypper install <strong>nvidia-open{-azure,-64k}</strong></code></td><td><code>zypper install <strong>nvidia-open-560{-azure,-64k}</strong></code></td></tr><tr><td>Debian</td><td><code>apt-get install <strong>nvidia-open</strong></code></td><td><code>apt-get install <strong>nvidia-open-560</strong></code></td></tr><tr><td>Ubuntu</td><td><code>apt-get install <strong>nvidia-open</strong></code></td><td><code>apt-get install <strong>nvidia-open-560</strong></code></td></tr></tbody></table><figcaption><em>Table 1. Package manager installation recommendations</em></figcaption></figure>



<p>For more information, see <a href="https://docs.nvidia.com/datacenter/tesla/drivers/index.html" data-wpel-link="internal" target="_self" rel="noopener noreferrer">NVIDIA Datacenter Drivers</a>.</p>



<h3 id="windows_subsystem_for_linux">Windows Subsystem for Linux<a href="#windows_subsystem_for_linux"><i></i></a></h3>



<p>Windows Subsystem for Linux (WSL) uses the NVIDIA kernel driver from the host Windows operating system. You shouldn’t install any driver into this platform specifically. If you are using WSL, no change or action is required.</p>



<h3 id="cuda_toolkit">CUDA Toolkit<a href="#cuda_toolkit"><i></i></a></h3>



<p>The installation of CUDA Toolkit remains unchanged through package managers. Run the following command:</p>


<div><pre title="">$ sudo apt-get/dnf/zypper install cuda-toolkit
</pre></div>


<h2 id="more_information">More information<a href="#more_information"><i></i></a></h2>



<p>For more information about how to install NVIDIA drivers or the CUDA Toolkit, including how to ensure that you install the proprietary drivers if you’re unable to migrate to the open-source GPU kernel modules at this time, see <a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/#driver-installation" data-wpel-link="internal" target="_self" rel="noopener noreferrer">Driver Installation</a> in the <em>CUDA Installation Guide</em>.</p>
</div></div>]]></description>
        </item>
    </channel>
</rss>