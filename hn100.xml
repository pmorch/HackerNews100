<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 12 Nov 2025 07:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Perkeep ‚Äì Personal storage system for life (123 pts)]]></title>
            <link>https://perkeep.org/</link>
            <guid>45896130</guid>
            <pubDate>Wed, 12 Nov 2025 03:34:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://perkeep.org/">https://perkeep.org/</a>, See on <a href="https://news.ycombinator.com/item?id=45896130">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
		

<p><a href="https://perkeep.org/keepy"><img src="https://perkeep.org/static/keepy-small-left.png" width="290" height="280"></a></p>

<p>Perkeep (<a href="https://github.com/perkeep/perkeep/issues/981">n√©e Camlistore</a>) is a set of open source formats, protocols, and software for modeling, storing, searching, sharing and synchronizing data in the post-PC era. Data may be files or objects, tweets or 5TB videos, and you can access it via a phone, browser or FUSE filesystem.</p>

<p>Perkeep is under active development. If you're a programmer or fairly technical, you can probably get it up and running and get some utility out of it. Many bits and pieces are actively being developed, so be prepared for bugs and unfinished features.</p>

<p>Join <a href="https://perkeep.org/community">the community</a>, consider <a href="https://perkeep.org/doc/contributing">contributing</a>, or <a href="https://github.com/perkeep/perkeep/issues">file a bug</a>.</p>

<p>Things Perkeep believes:</p>
<ul>
  <li>Your data is entirely under your control</li>
  <li>Open Source</li>
  <li>Paranoid about privacy, everything private by default</li>
  <li>No SPOF: don't rely on any single party (including yourself)</li>
  <li>Your data should be alive in 80 years, especially if you are</li>
</ul>

<h2 id="latest-release">Latest Release</h2>

<p>The latest release is <a href="https://github.com/perkeep/perkeep/releases/tag/v0.12">0.12 ("Toronto")</a>, released 2025-11-11.</p>
<p>Follow the <a href="https://perkeep.org/download">download and getting started instructions</a> to set up Perkeep.</p>

<h2 id="video-demo">Video Demo</h2>

<p>LinuxFest Northwest 2018 [<a href="https://docs.google.com/presentation/d/1suYfv3dmjJQ1mMJIG7_D26e5cudZqPcZTPNgrLvTIrI/view">slides</a>] [<a href="https://www.youtube.com/watch?v=PlAU_da_U4s">video</a>]:</p>

<center><iframe width="640" height="360" src="//www.youtube.com/embed/PlAU_da_U4s" frameborder="0" allowfullscreen=""></iframe></center>

<p>Or see the <a href="https://perkeep.org/doc/#presentations">other presentations</a>.</p>

	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I can build enterprise software but I can't charge for it (158 pts)]]></title>
            <link>https://gist.github.com/EchenD/8b211ebfa4941d2c5df7b526790b31aa</link>
            <guid>45894569</guid>
            <pubDate>Tue, 11 Nov 2025 23:58:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gist.github.com/EchenD/8b211ebfa4941d2c5df7b526790b31aa">https://gist.github.com/EchenD/8b211ebfa4941d2c5df7b526790b31aa</a>, See on <a href="https://news.ycombinator.com/item?id=45894569">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="file-neoclerks-partnership-md" tabindex="0" role="region" aria-label="NeoClerks-partnership.md content, created by EchenD on 11:20PM yesterday.">
    <article itemprop="text"><p>Error in user YAML: (&lt;unknown&gt;): did not find expected alphabetic or numeric character while scanning an alias at line 1 column 1</p><div dir="auto"><pre>---

<span>**Important clarification based on HackerNews feedback:**</span>

<span>The partnership structures I originally proposed (US/UK company + contractor arrangement) **violate international sanctions and are illegal**. I was naive about this.</span>

<span>**I am NOT asking anyone to break sanctions laws.**</span>

<span>**New focus - Legal markets:**</span>
- <span>üáÆüá≥ India - No sanctions, large SaaS ecosystem</span>
- <span>üá¶üá™ UAE/Dubai - Open to Iranian business</span>
- <span>üáπüá∑ Turkey - Regional tech hub  </span>
- <span>üá∏üá¨ Singapore - Researching legal framework</span>

<span>**If you're from these countries and interested:** EchenDeligani@gmail.com</span>

---

</pre></div>

<p dir="auto"><h2 dir="auto">I Can Build Enterprise Software. But I Can't Charge for It.</h2><a id="user-content-i-can-build-enterprise-software-but-i-cant-charge-for-it" aria-label="Permalink: I Can Build Enterprise Software. But I Can't Charge for It." href="#i-can-build-enterprise-software-but-i-cant-charge-for-it"></a></p>
<p dir="auto"><em>How I spent 18 months building an AI avatar platform through war, economic collapse, and 120-hour weeks‚Äîand why I'm now looking for a partner to help me turn this into a real business.</em></p>
<hr>
<p dir="auto"><h2 dir="auto">Test it first: <a href="https://neoclerks.com/en/" rel="nofollow">neoclerks.com/en</a></h2><a id="user-content-test-it-first-neoclerkscomen" aria-label="Permalink: Test it first: neoclerks.com/en" href="#test-it-first-neoclerkscomen"></a></p>
<p dir="auto">Go ahead. Talk to the avatar for 2 minutes. Ask it anything in English. Watch how it responds in real-time with synchronized lip movements and natural conversation.</p>
<p dir="auto">I'll be here when you get back.</p>
<hr>
<p dir="auto"><h2 dir="auto">The Current Situation (Being Completely Honest)</h2><a id="user-content-the-current-situation-being-completely-honest" aria-label="Permalink: The Current Situation (Being Completely Honest)" href="#the-current-situation-being-completely-honest"></a></p>
<p dir="auto">I'm 35 years old. I live in Iran. I spent 18 months building an enterprise AI avatar platform that competes with Soul Machines ($70M funded, $50k+ setup fees for enterprise clients).</p>
<p dir="auto"><strong>The product works</strong>. You just tested it. The code is production-ready. The architecture is solid. The documentation is complete (20+ guides, 100+ pages).</p>
<p dir="auto"><strong>I have zero customers</strong>. Zero revenue. I'm out of savings and actively job hunting for 9 months with no luck. My wife is a nurse who works 5am-7pm while I sit at a computer building something that won't pay our rent.</p>
<p dir="auto"><strong>I can't monetize this from Iran</strong>:</p>
<ul dir="auto">
<li>‚ùå Stripe, PayPal, Western payment processors (sanctioned)</li>
<li>‚ùå AWS, GCP, Azure (sanctioned)</li>
<li>‚ùå Western bank account (sanctioned)</li>
<li>‚ùå Credit card payments from customers (no processor works here)</li>
</ul>
<p dir="auto"><strong>I tried the local Iranian market</strong>. I showed it to friends, family, and potential clients. Their response: <em>"Nobody in Iran will pay $500/month for this. The Persian language quality isn't perfect. We'll use free ChatGPT instead."</em></p>
<p dir="auto">They're right about the market. Iran's currency devalued 100,000x over 20 years. Hotels are closing. Banks are failing. People struggle to pay rent and buy food. This isn't the market for enterprise AI.</p>
<p dir="auto"><strong>So here's why I'm writing this</strong>:</p>
<p dir="auto">I'm not confidently selling a finished product for $100k. I'm looking for a <strong>partner or co-founder</strong> who can access Stripe, handle sales, and help me turn 18 months of brutal work into a business that actually makes money.</p>
<p dir="auto">I want to keep building this. I just need someone who can sell it.</p>
<hr>
<p dir="auto"><h2 dir="auto">What I Built (The 30-Second Version)</h2><a id="user-content-what-i-built-the-30-second-version" aria-label="Permalink: What I Built (The 30-Second Version)" href="#what-i-built-the-30-second-version"></a></p>
<p dir="auto"><strong>NeoClerks</strong> is a self-hosted AI avatar platform with real-time conversation and enterprise infrastructure:</p>
<p dir="auto"><strong>Core Avatar Tech:</strong></p>
<ul dir="auto">
<li>3D photorealistic avatars (Unreal Engine 5 + MetaHuman, pixel streaming)</li>
<li>Real-time conversation (1-8 seconds response time depending on cache hits)</li>
<li>47 languages (OpenAI STT + TTS)</li>
<li>Smart 4-layer caching (hash ‚Üí vector ‚Üí LLM selection, 60-90% cost reduction)</li>
<li>RAG knowledge base (hybrid BM25 + vector search with pgvector)</li>
</ul>
<p dir="auto"><strong>Enterprise Business Infrastructure:</strong></p>
<ul dir="auto">
<li>Multi-tenant B2B architecture (8 database tables for organizations, subscriptions, usage tracking)</li>
<li>8 pre-configured pricing tiers ($497-$947/month + Enterprise custom)</li>
<li>Automated billing system (conversation counting, overage calculation, invoice generation)</li>
<li>Conversation analytics (11 database tables, 7 AI analysis types via OpenAI Batch API)</li>
<li>Admin panel (Next.js, full system management UI)</li>
<li>Monitoring stack (Prometheus + Grafana + Loki, 35+ alert rules)</li>
<li>4-server distributed architecture (scalable to 100+ instances, k8s-ready)</li>
</ul>
<p dir="auto"><strong>Compare to competitors:</strong></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Feature</th>
<th>NeoClerks</th>
<th>Soul Machines</th>
<th>D-ID</th>
<th>Synthesia</th>
</tr>
</thead>
<tbody>
<tr>
<td>Setup Cost</td>
<td>$0-$797</td>
<td>$50,000+</td>
<td>$0</td>
<td>$0</td>
</tr>
<tr>
<td>3D Photorealistic</td>
<td>‚úÖ Real-time UE5</td>
<td>‚úÖ Real-time</td>
<td>‚ùå 2D only</td>
<td>‚ùå 2D only</td>
</tr>
<tr>
<td>Real-time Conversation</td>
<td>‚úÖ 1-8s</td>
<td>‚úÖ ~2s</td>
<td>‚úÖ ~3s</td>
<td>‚ùå Pre-recorded</td>
</tr>
<tr>
<td>Self-hosted</td>
<td>‚úÖ Full control</td>
<td>‚ùå Cloud only</td>
<td>‚ùå Cloud only</td>
<td>‚ùå Cloud only</td>
</tr>
<tr>
<td>White-label</td>
<td>‚úÖ Included</td>
<td>Enterprise tier</td>
<td>‚ùå No</td>
<td>Limited</td>
</tr>
<tr>
<td>Multi-tenant B2B</td>
<td>‚úÖ Built-in</td>
<td>Enterprise tier</td>
<td>Basic</td>
<td>Basic</td>
</tr>
<tr>
<td>Usage Analytics</td>
<td>‚úÖ 7 types</td>
<td>Enterprise tier</td>
<td>Basic</td>
<td>Basic</td>
</tr>
<tr>
<td>Admin Panel</td>
<td>‚úÖ Full UI</td>
<td>Enterprise tier</td>
<td>Basic</td>
<td>Basic</td>
</tr>
<tr>
<td>RAG Knowledge Base</td>
<td>‚úÖ Hybrid search</td>
<td>Enterprise tier</td>
<td>‚ùå No</td>
<td>‚ùå No</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>Market opportunity</strong>: AI avatar market is $2.1B in 2024, projected $4.3B by 2027. Soul Machines has 100+ enterprise clients (Mercedes-Benz, Vodafone). The demand exists.</p>
<p dir="auto"><strong>Full technical documentation</strong>: 20+ guides covering architecture, deployment (local/2-server/4-server), API reference (96+ endpoints), security (JWT + RBAC), monitoring, analytics.</p>
<hr>
<p dir="auto"><h2 dir="auto">The Stories Nobody Sees (Why This Almost Killed Me)</h2><a id="user-content-the-stories-nobody-sees-why-this-almost-killed-me" aria-label="Permalink: The Stories Nobody Sees (Why This Almost Killed Me)" href="#the-stories-nobody-sees-why-this-almost-killed-me"></a></p>
<p dir="auto"><h3 dir="auto">The 120-Hour Weeks</h3><a id="user-content-the-120-hour-weeks" aria-label="Permalink: The 120-Hour Weeks" href="#the-120-hour-weeks"></a></p>
<p dir="auto">For the last 9 months, I worked 100-120 hours per week.</p>
<p dir="auto">My wife wakes up at 5 AM for her nursing shift. I wake up with her. She comes home at 7 PM‚Äîthat's when I eat my first meal of the day. We eat together. Then I go back to the computer until midnight or 1 AM, when I physically can't move anymore and fall asleep at my desk.</p>
<p dir="auto">One evening she came home exhausted and asked: <em>"Is there anything else we can talk about besides this project?"</em></p>
<p dir="auto">I had nothing to say. I live this. I breathe this. It's all I think about.</p>
<p dir="auto">My mother keeps asking: <em>"When will you get a job?"</em> I've been trying for 9 months. The game industry is collapsing globally with massive layoffs. Iran's economy is in the worst state in its history. AI is replacing developer positions. I thought building something valuable was the answer.</p>
<p dir="auto"><h3 dir="auto">The War</h3><a id="user-content-the-war" aria-label="Permalink: The War" href="#the-war"></a></p>
<p dir="auto">In June 2025, during the Iran-Israel conflict, there were bombs falling. I kept working. Explosions in the distance. I just hoped none would hit my house.</p>
<p dir="auto">Around the same time, a crypto exchange I used got hacked‚ÄîI lost what little savings buffer I had left.</p>
<p dir="auto">I kept coding. What else could I do?</p>
<p dir="auto"><h3 dir="auto">The Technical Nightmare That Almost Broke Me</h3><a id="user-content-the-technical-nightmare-that-almost-broke-me" aria-label="Permalink: The Technical Nightmare That Almost Broke Me" href="#the-technical-nightmare-that-almost-broke-me"></a></p>
<p dir="auto">The PAK file loading system nearly killed this project.</p>
<p dir="auto"><strong>The problem</strong>: Generate lip-sync animations on-demand, cook them in Unreal Engine, package them into PAK files, and load them dynamically into a shipped build. There's almost zero documentation for this‚ÄîUnreal is built for game development, not service-based animation streaming.</p>
<p dir="auto">I spent a month fighting this. One month of:</p>
<ul dir="auto">
<li>Creating custom Unreal plugins</li>
<li>Syncing paths precisely between 5 different services (9 with body animation)</li>
<li>Debugging why animations load perfectly in development but crash in production</li>
<li>Fighting Unreal's cooking pipeline (loading a project takes 17 seconds minimum per cook)</li>
</ul>
<p dir="auto">At 3 AM one night, after 14 straight hours of debugging, I almost deleted the entire repository. I was done.</p>
<p dir="auto">Then I found one obscure tutorial that gave me the breakthrough. I got it working. Then I realized it was too slow for real-time use‚Äî17 seconds per cook meant I couldn't use it for live responses.</p>
<p dir="auto">I had to pivot: use real-time lip-sync for live conversations (lower quality but acceptable), and save the PAK system for smart caching where quality matters and pre-generation is possible.</p>
<p dir="auto"><strong>That was one problem</strong>. I faced 50 more like it.</p>
<p dir="auto">The session management between the QR code scanning (phone becomes microphone) and pixel streaming frontend. The WebSocket orchestration. Making it gracefully handle network failures, users switching tabs, phones dying. Creating limits so it can't be abused in a hotel lobby. Every edge case felt like a show-stopper.</p>
<p dir="auto">I wanted to quit every single month. But I had no other choice. I kept going.</p>
<hr>
<p dir="auto"><h2 dir="auto">The Claude Partnership (How I Actually Built This)</h2><a id="user-content-the-claude-partnership-how-i-actually-built-this" aria-label="Permalink: The Claude Partnership (How I Actually Built This)" href="#the-claude-partnership-how-i-actually-built-this"></a></p>
<p dir="auto">I couldn't have built this alone in 18 months. Without AI assistance, this would've taken 6 years.</p>
<p dir="auto">I used <strong>Claude Code (Sonnet 4.5)</strong> as my co-developer and code reviewer. We worked together:</p>
<ul dir="auto">
<li>I'd write code ‚Üí Claude would review and suggest improvements</li>
<li>Claude would write code ‚Üí I'd review and validate</li>
<li>Claude would audit ‚Üí I'd test ‚Üí Claude would audit again</li>
<li>Repeat hundreds of times</li>
</ul>
<p dir="auto"><strong>For the last 50 times I asked Claude to audit this codebase, it consistently responded: "This is 100% production-ready. Deploy immediately."</strong></p>
<p dir="auto">Early on, every fresh audit would find improvements (security issues, architecture problems, missing edge cases). For the last 2 months, Claude finds nothing to fix.</p>
<p dir="auto"><strong>This is AI-validated, production-grade code.</strong></p>
<p dir="auto">You can verify this yourself: open Claude Code, point it at the repository, ask it to audit for production readiness. It will confirm.</p>
<p dir="auto"><strong>Repository stats</strong> (from refactored architecture):</p>
<ul dir="auto">
<li>Total commits: 818</li>
<li>First commit: September 26, 2024</li>
<li>Development time: 18 months (includes original version before refactor)</li>
<li>Lines of code: 20,000+ (backend Python/FastAPI, frontend Next.js, UE5 blueprints)</li>
</ul>
<hr>
<p dir="auto"><h2 dir="auto">Why I Can't Monetize From Iran (The Geography Problem)</h2><a id="user-content-why-i-cant-monetize-from-iran-the-geography-problem" aria-label="Permalink: Why I Can't Monetize From Iran (The Geography Problem)" href="#why-i-cant-monetize-from-iran-the-geography-problem"></a></p>
<p dir="auto">I showed this to several potential clients in Iran before realizing the local market is dead:</p>
<p dir="auto"><strong>Problem 1: Currency collapse</strong>
Iran's rial lost 99.999% of its value over 20 years. I'd need to charge in dollars but collect in rials. Nobody will pay $500/month when that's equivalent to a month's salary.</p>
<p dir="auto"><strong>Problem 2: Persian language quality</strong>
I use GPT-5 (the most expensive model) but Persian language quality isn't perfect. Clients compare it to ChatGPT and expect native-level fluency. It's good (in my opinion), but not perfect enough for risk-averse businesses.</p>
<p dir="auto"><strong>Problem 3: Economic collapse</strong>
Hotels are closing (no tourists). Banks are failing. Hospitals can't risk AI mistakes in Persian. Entertainment is not a priority when people lack clean water. I thought about pivoting to water filters‚Äîthat would sell‚Äîbut I'm a programmer, not an engineer.</p>
<p dir="auto"><strong>Problem 4: International sanctions</strong>
Even if I found international clients, I can't:</p>
<ul dir="auto">
<li>Accept payments (no Stripe, PayPal, or credit card processors)</li>
<li>Deploy on cloud platforms (AWS/GCP/Azure sanctioned)</li>
<li>Open Western bank accounts</li>
<li>Register US/EU companies</li>
</ul>
<p dir="auto"><strong>I tried crypto payments</strong>: B2B customers won't pay $500-1000/month subscriptions in Bitcoin. Their accounting departments reject it. Too volatile for recurring revenue.</p>
<p dir="auto"><strong>I tried intermediaries</strong>: They want 20-30% commission, they hold all payment power (can shut me down anytime), and I still hold legal liability while they take zero risk.</p>
<p dir="auto"><strong>The reality</strong>: I can build enterprise software. I just can't charge for it.</p>
<hr>
<p dir="auto"><h2 dir="auto">What I'm Really Looking For (Partnership, Not Just a Sale)</h2><a id="user-content-what-im-really-looking-for-partnership-not-just-a-sale" aria-label="Permalink: What I'm Really Looking For (Partnership, Not Just a Sale)" href="#what-im-really-looking-for-partnership-not-just-a-sale"></a></p>
<p dir="auto">I don't want to sell this and disappear. <strong>I want to keep building it.</strong> I love this product. I just need a partner who can access Stripe and handle sales.</p>
<p dir="auto">Here are three options (all negotiable):</p>
<p dir="auto"><h3 dir="auto"><strong>Option 1: Co-Founder Partnership</strong></h3><a id="user-content-option-1-co-founder-partnership" aria-label="Permalink: Option 1: Co-Founder Partnership" href="#option-1-co-founder-partnership"></a></p>
<p dir="auto"><strong>Structure:</strong></p>
<ul dir="auto">
<li>You invest: $50-80k + handle sales/operations/Stripe access</li>
<li>I contribute: Complete codebase + continue as technical co-founder</li>
<li>Equity split: 60/40 or 70/30 (negotiable based on your investment and role)</li>
<li>Commitment: 3-year minimum from both sides</li>
</ul>
<p dir="auto"><strong>Your responsibilities:</strong></p>
<ul dir="auto">
<li>Sales and customer acquisition</li>
<li>Payment processing (Stripe account)</li>
<li>Customer support and onboarding</li>
<li>Marketing and positioning</li>
</ul>
<p dir="auto"><strong>My responsibilities:</strong></p>
<ul dir="auto">
<li>All technical development and maintenance</li>
<li>Feature development based on customer feedback</li>
<li>Infrastructure and DevOps</li>
<li>Technical support for complex issues</li>
</ul>
<p dir="auto"><strong>Timeline to profitability</strong>: 6-12 months to acquire first 20-30 customers at $500-1500/month each</p>
<hr>
<p dir="auto"><h3 dir="auto"><strong>Option 2: Outright Sale + Long-Term Contract</strong></h3><a id="user-content-option-2-outright-sale--long-term-contract" aria-label="Permalink: Option 2: Outright Sale + Long-Term Contract" href="#option-2-outright-sale--long-term-contract"></a></p>
<p dir="auto"><strong>Structure:</strong></p>
<ul dir="auto">
<li>You pay: $60-80k upfront (full code ownership, all IP rights)</li>
<li>I sign: 3-year contractor agreement at $4-6k/month</li>
<li>Total cost: $60-80k + $144-216k over 3 years = $204-296k total</li>
<li>You get: Technical founder-level support without equity dilution</li>
</ul>
<p dir="auto"><strong>What I provide:</strong></p>
<ul dir="auto">
<li>30 days intensive support (live setup, training, documentation walkthrough)</li>
<li>Ongoing development (20-30 hours/week for 3 years)</li>
<li>Feature development and bug fixes</li>
<li>Architecture decisions and code reviews</li>
<li>Emergency support for critical issues</li>
</ul>
<p dir="auto"><strong>Why this works:</strong></p>
<ul dir="auto">
<li>You own 100% of the business</li>
<li>You have guaranteed technical support for 3 years</li>
<li>I have stable income while you scale</li>
<li>Lower risk than buying code and hoping it works</li>
</ul>
<hr>
<p dir="auto"><h3 dir="auto"><strong>Option 3: Revenue Share Partnership</strong></h3></p>
<p dir="auto"><strong>Structure:</strong></p>
<ul dir="auto">
<li>You invest: $30-50k upfront + Stripe access + sales/marketing</li>
<li>I contribute: Complete codebase + continue as technical co-founder</li>
<li>Revenue split: 50/50 until you recoup investment, then renegotiate (maybe 40/60 or 30/70)</li>
<li>Commitment: 3-year minimum</li>
</ul>
<p dir="auto"><strong>Why this works:</strong></p>
<ul dir="auto">
<li>Lower upfront cost for you</li>
<li>I'm incentivized to help you succeed (my income depends on revenue)</li>
<li>Fair risk distribution</li>
<li>Aligns our interests long-term</li>
</ul>
<hr>
<p dir="auto"><strong>I'm flexible on structure.</strong> What matters most to me:</p>
<ol dir="auto">
<li>The product gets to market and helps businesses</li>
<li>I can continue working on it (I genuinely love building this)</li>
<li>I have stable income to support my family</li>
<li>We both benefit from the success</li>
</ol>
<p dir="auto">If you have a different structure in mind, let's talk.</p>
<hr>
<p dir="auto"><h2 dir="auto">What You're Actually Getting (Component Breakdown)</h2><a id="user-content-what-youre-actually-getting-component-breakdown" aria-label="Permalink: What You're Actually Getting (Component Breakdown)" href="#what-youre-actually-getting-component-breakdown"></a></p>
<p dir="auto">If you hired developers to build this from scratch:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Component</th>
<th>Cost to Build</th>
<th>Time</th>
<th>Status</th>
</tr>
</thead>
<tbody>
<tr>
<td>Avatar + AI pipeline (UE5, STT, LLM, TTS, RAG)</td>
<td>$50-70k</td>
<td>6 months</td>
<td>‚úÖ Done</td>
</tr>
<tr>
<td>Multi-tenant B2B infrastructure</td>
<td>$20-30k</td>
<td>3 months</td>
<td>‚úÖ Done</td>
</tr>
<tr>
<td>Conversation analytics (11 tables, 7 AI analyses)</td>
<td>$15-25k</td>
<td>2 months</td>
<td>‚úÖ Done</td>
</tr>
<tr>
<td>Monitoring stack (Prometheus/Grafana/35 alerts)</td>
<td>$10-15k</td>
<td>1 month</td>
<td>‚úÖ Done</td>
</tr>
<tr>
<td>Admin panel (Next.js, TypeScript)</td>
<td>$10-15k</td>
<td>1 month</td>
<td>‚úÖ Done</td>
</tr>
<tr>
<td>4-server distributed architecture</td>
<td>$20-30k</td>
<td>2 months</td>
<td>‚úÖ Done</td>
</tr>
<tr>
<td>Security (JWT on 96 endpoints, RBAC, SSL)</td>
<td>$15-20k</td>
<td>1 month</td>
<td>‚úÖ Done</td>
</tr>
<tr>
<td>Documentation (20+ guides, 100+ pages)</td>
<td>$10-15k</td>
<td>1 month</td>
<td>‚úÖ Done</td>
</tr>
<tr>
<td><strong>TOTAL</strong></td>
<td><strong>$150-220k</strong></td>
<td><strong>18 months</strong></td>
<td>‚úÖ Done</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>You're getting this for $60-80k (outright) or $50-80k + equity (partnership).</strong></p>
<p dir="auto">That's a 50-70% discount vs hiring it built, plus you skip 18 months of development time.</p>
<hr>
<p dir="auto"><h2 dir="auto">Known Limitations (Being 100% Honest)</h2><a id="user-content-known-limitations-being-100-honest" aria-label="Permalink: Known Limitations (Being 100% Honest)" href="#known-limitations-being-100-honest"></a></p>
<p dir="auto">I'm not going to oversell this. Here's what you should know:</p>
<p dir="auto"><strong>Technical Limitations:</strong></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Animation quality is "good" not "perfect"</strong>: Lip sync is 85-90% accurate (on par with Soul Machines demos). Body language is limited to idle animations. Facial expressions are good but not Pixar-level. Fix: Hire a 3D animator for $3-5k to improve animations.</p>
</li>
<li>
<p dir="auto"><strong>Persian language needs work</strong>: English is flawless. Persian is 80-85% accurate (Whisper + GPT-4o struggle with some accents/nuances). Fix: Fine-tune Whisper on Persian dataset or use local STT service.</p>
</li>
<li>
<p dir="auto"><strong>Demo server latency</strong>: The live demo runs on my GTX 1060 in Iran with 4G home internet. International users may experience 500-1500ms lag. This is infrastructure, not code. Fix: Deploy on AWS in customer's region (latency drops to 100-300ms).</p>
</li>
<li>
<p dir="auto"><strong>GPU requirements</strong>: Development works on GTX 1060 (1 user). Production needs RTX 3090+ for 10 users, RTX 5090 for 30 concurrent users. Cost: $800-2000/month for AWS g4dn/g5 instances.</p>
</li>
</ol>
<p dir="auto"><strong>Business Limitations:</strong></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Zero customers</strong>: No testimonials, no case studies, no revenue history. Reality: You're starting from scratch on customer acquisition.</p>
</li>
<li>
<p dir="auto"><strong>No brand recognition</strong>: "NeoClerks" has no market awareness. No SEO, no social media following. Reality: You'll likely want to rebrand entirely.</p>
</li>
<li>
<p dir="auto"><strong>No marketing materials</strong>: No demo videos (beyond live demo), no sales collateral, no pitch decks. Reality: You'll need to create these.</p>
</li>
<li>
<p dir="auto"><strong>Support depends on our agreement</strong>: I'll support based on which option you choose (30 days for outright sale, 3 years for partnership). Reality: If you scale, you may need to hire additional support ($50-70k/year).</p>
</li>
</ol>
<hr>
<p dir="auto"><h2 dir="auto">How to Verify This Is Real</h2><a id="user-content-how-to-verify-this-is-real" aria-label="Permalink: How to Verify This Is Real" href="#how-to-verify-this-is-real"></a></p>
<p dir="auto">I know you're skeptical. Here's how to verify everything:</p>
<p dir="auto"><h3 dir="auto"><strong>1. Test the live demo</strong> (5 minutes)</h3><a id="user-content-1-test-the-live-demo-5-minutes" aria-label="Permalink: 1. Test the live demo (5 minutes)" href="#1-test-the-live-demo-5-minutes"></a></p>
<ul dir="auto">
<li>Go to <a href="https://neoclerks.com/en/" rel="nofollow">https://neoclerks.com/en/</a></li>
<li>Click "Book a Private Demo"</li>
<li>Talk to the avatar in English</li>
<li>Evaluate: response time, lip sync quality, conversation coherence</li>
</ul>
<p dir="auto"><strong>Known limitation on demo</strong>: Running on consumer GPU + 4G home internet in Iran, so international latency will be higher than production deployment.</p>
<p dir="auto"><h3 dir="auto"><strong>2. Code access for serious inquiries</strong> (after NDA)</h3><a id="user-content-2-code-access-for-serious-inquiries-after-nda" aria-label="Permalink: 2. Code access for serious inquiries (after NDA)" href="#2-code-access-for-serious-inquiries-after-nda"></a></p>
<p dir="auto">I'll give you read-only GitHub access to review:</p>
<ul dir="auto">
<li>Backend services (FastAPI microservices, Python)</li>
<li>Frontend code (Next.js landing page + admin panel)</li>
<li>Database schema (migrations, SQLAlchemy models)</li>
<li>Infrastructure configs (Docker Compose, nginx, environment templates)</li>
<li>UE5 project structure (blueprints, MetaHuman assets, pixel streaming)</li>
</ul>
<p dir="auto"><strong>What you can verify</strong>: Code quality, architecture, documentation, tests.</p>
<p dir="auto"><h3 dir="auto"><strong>3. Live deployment walkthrough</strong> (after serious interest)</h3><a id="user-content-3-live-deployment-walkthrough-after-serious-interest" aria-label="Permalink: 3. Live deployment walkthrough (after serious interest)" href="#3-live-deployment-walkthrough-after-serious-interest"></a></p>
<p dir="auto">1-2 hour Zoom call where I:</p>
<ul dir="auto">
<li>Deploy the entire stack locally (you watch)</li>
<li>Walk through the admin panel, monitoring dashboards, API endpoints</li>
<li>Explain the architecture and code structure</li>
<li>Answer technical questions</li>
<li>Demonstrate analytics system, billing system, session management</li>
</ul>
<p dir="auto"><h3 dir="auto"><strong>4. Claude Code validation</strong> (do this yourself)</h3><a id="user-content-4-claude-code-validation-do-this-yourself" aria-label="Permalink: 4. Claude Code validation (do this yourself)" href="#4-claude-code-validation-do-this-yourself"></a></p>
<ul dir="auto">
<li>Get Claude Code access</li>
<li>Point it at the repository</li>
<li>Ask: "Review this codebase for production readiness"</li>
<li>Claude will confirm what I've said</li>
</ul>
<hr>
<p dir="auto"><h2 dir="auto">Who Should Consider This</h2><a id="user-content-who-should-consider-this" aria-label="Permalink: Who Should Consider This" href="#who-should-consider-this"></a></p>
<p dir="auto"><h3 dir="auto">‚úÖ <strong>Good Fit:</strong></h3><a id="user-content--good-fit" aria-label="Permalink: ‚úÖ Good Fit:" href="#-good-fit"></a></p>
<p dir="auto"><strong>You're a digital agency with existing B2B clients:</strong></p>
<ul dir="auto">
<li>You have 50-200 clients you can upsell to</li>
<li>You can position this at $700-1500/month to hotels, retail, healthcare</li>
<li>You have a DevOps person or can hire one ($60-80k/year)</li>
</ul>
<p dir="auto"><strong>You're a SaaS entrepreneur who's done this before:</strong></p>
<ul dir="auto">
<li>You've sold B2B SaaS (you understand 6-12 month sales cycles)</li>
<li>You have capital for 6-12 months runway</li>
<li>You know how to do outreach, demos, close deals</li>
</ul>
<p dir="auto"><strong>You're an enterprise IT company:</strong></p>
<ul dir="auto">
<li>You sell to Fortune 500s (banks, telecoms, healthcare)</li>
<li>You need a white-label AI solution for your portfolio</li>
<li>Your team closes 5-10 enterprise deals/year</li>
</ul>
<p dir="auto"><strong>You want a technical co-founder:</strong></p>
<ul dir="auto">
<li>You can handle sales/ops but lack technical depth</li>
<li>You want someone committed long-term (not just a contractor)</li>
<li>You're willing to share equity for proven technical execution</li>
</ul>
<hr>
<p dir="auto"><h3 dir="auto">‚ùå <strong>Bad Fit:</strong></h3><a id="user-content--bad-fit" aria-label="Permalink: ‚ùå Bad Fit:" href="#-bad-fit"></a></p>
<p dir="auto"><strong>You have no technical skills and won't hire:</strong></p>
<ul dir="auto">
<li>Can't deploy Docker containers</li>
<li>Won't hire a DevOps engineer ($60-80k/year)</li>
<li><strong>Why you'll fail</strong>: Every customer needs a deployment</li>
</ul>
<p dir="auto"><strong>You have no sales experience:</strong></p>
<ul dir="auto">
<li>You've never sold B2B SaaS</li>
<li>You can't afford to hire a salesperson ($50-70k/year + commission)</li>
<li><strong>Why you'll fail</strong>: Zero customers means you acquire them all yourself</li>
</ul>
<p dir="auto"><strong>You expect passive income:</strong></p>
<ul dir="auto">
<li>You want "buy it and forget it"</li>
<li>You don't want to provide customer support</li>
<li><strong>Why you'll fail</strong>: This requires active sales and support</li>
</ul>
<hr>
<p dir="auto"><h2 dir="auto">Unit Economics (Why This Can Be Profitable)</h2><a id="user-content-unit-economics-why-this-can-be-profitable" aria-label="Permalink: Unit Economics (Why This Can Be Profitable)" href="#unit-economics-why-this-can-be-profitable"></a></p>
<p dir="auto">Let's do realistic math:</p>
<p dir="auto"><strong>Scenario: Digital agency with 100 existing clients</strong></p>
<p dir="auto"><strong>Month 1-3</strong>: Pitch 100 clients, 10 sign up (10% conversion)</p>
<ul dir="auto">
<li>Tier: Professional ($799/month)</li>
<li>Revenue: $7,990/month</li>
<li>Costs: $2,000/month (AWS + OpenAI API)</li>
<li>Profit: $5,990/month (~75% margin)</li>
</ul>
<p dir="auto"><strong>Month 4-6</strong>: Upsell another 10 clients (20 total)</p>
<ul dir="auto">
<li>Revenue: $15,980/month</li>
<li>Costs: $3,500/month</li>
<li>Profit: $12,480/month</li>
</ul>
<p dir="auto"><strong>Month 7-12</strong>: Organic growth + referrals (30 total)</p>
<ul dir="auto">
<li>Revenue: $23,970/month = <strong>$287k/year</strong></li>
<li>Costs: $5,000/month = <strong>$60k/year</strong></li>
<li>Profit: $18,970/month = <strong>$227k/year</strong></li>
</ul>
<p dir="auto"><strong>ROI</strong>: At $60k purchase price, you break even in <strong>3-4 months</strong> with 30 customers.</p>
<p dir="auto"><strong>This is realistic if you have existing B2B relationships.</strong> If starting cold, add 6-12 months to reach 30 customers.</p>
<hr>
<p dir="auto"><h2 dir="auto">The Sale/Partnership Process</h2><a id="user-content-the-salepartnership-process" aria-label="Permalink: The Sale/Partnership Process" href="#the-salepartnership-process"></a></p>
<p dir="auto">Since I can't use Stripe/PayPal, we use cryptocurrency escrow for safety:</p>
<p dir="auto"><h3 dir="auto"><strong>Phase 1: Initial Contact (Week 1)</strong></h3><a id="user-content-phase-1-initial-contact-week-1" aria-label="Permalink: Phase 1: Initial Contact (Week 1)" href="#phase-1-initial-contact-week-1"></a></p>
<ol dir="auto">
<li>You test the demo (5 minutes)</li>
<li>You read this article</li>
<li>We do a 30-minute intro call (verify I'm real, answer questions)</li>
<li>I send you high-level code structure overview</li>
</ol>
<p dir="auto"><h3 dir="auto"><strong>Phase 2: Due Diligence (Week 2-3)</strong></h3><a id="user-content-phase-2-due-diligence-week-2-3" aria-label="Permalink: Phase 2: Due Diligence (Week 2-3)" href="#phase-2-due-diligence-week-2-3"></a></p>
<ol dir="auto">
<li>You sign NDA (mutual protection)</li>
<li>I give you read-only GitHub access</li>
<li>You review code, architecture, documentation (3-7 days)</li>
<li>We do live deployment walkthrough (1-2 hours)</li>
<li>You decide if you want to proceed</li>
</ol>
<p dir="auto"><h3 dir="auto"><strong>Phase 3: Agreement (Week 3-4)</strong></h3><a id="user-content-phase-3-agreement-week-3-4" aria-label="Permalink: Phase 3: Agreement (Week 3-4)" href="#phase-3-agreement-week-3-4"></a></p>
<ol dir="auto">
<li>We agree on structure (co-founder / sale+contract / revenue share)</li>
<li>We finalize price and terms</li>
<li>Lawyers draft agreement (if needed)</li>
</ol>
<p dir="auto"><h3 dir="auto"><strong>Phase 4: Payment &amp; Transfer (Week 4-5)</strong></h3><a id="user-content-phase-4-payment--transfer-week-4-5" aria-label="Permalink: Phase 4: Payment &amp; Transfer (Week 4-5)" href="#phase-4-payment--transfer-week-4-5"></a></p>
<p dir="auto"><strong>For outright sale:</strong></p>
<ul dir="auto">
<li>We use <strong>Hodl Hodl</strong> (non-custodial multisig escrow, works from Iran)</li>
<li>You deposit BTC/USDT into escrow (neutral third party holds funds)</li>
<li>I transfer complete source code + documentation</li>
<li>We conduct 2-hour live setup session (recorded)</li>
<li>You verify code works (3-7 days)</li>
<li>You release escrow payment</li>
<li>30-day support period begins</li>
</ul>
<p dir="auto"><strong>For partnership:</strong></p>
<ul dir="auto">
<li>Standard equity agreement via lawyer</li>
<li>Payment via wire transfer to your company account (you're outside Iran)</li>
<li>I join as technical co-founder</li>
<li>We start working together immediately</li>
</ul>
<p dir="auto"><h3 dir="auto"><strong>Protection for both sides:</strong></h3><a id="user-content-protection-for-both-sides" aria-label="Permalink: Protection for both sides:" href="#protection-for-both-sides"></a></p>
<ul dir="auto">
<li>‚úÖ Escrow mediator handles disputes (for sales)</li>
<li>‚úÖ Standard equity agreements (for partnerships)</li>
<li>‚úÖ You verify code before payment release</li>
<li>‚úÖ I get security that payment is locked in escrow</li>
</ul>
<p dir="auto"><strong>Timeline</strong>: 4-6 weeks from first contact to deal closed.</p>
<hr>
<p dir="auto"><h2 dir="auto">What Happens Next (If We Work Together)</h2><a id="user-content-what-happens-next-if-we-work-together" aria-label="Permalink: What Happens Next (If We Work Together)" href="#what-happens-next-if-we-work-together"></a></p>
<p dir="auto">If you become my partner or buyer, here's the immediate roadmap:</p>
<p dir="auto"><h3 dir="auto"><strong>Month 1: Launch</strong></h3><a id="user-content-month-1-launch" aria-label="Permalink: Month 1: Launch" href="#month-1-launch"></a></p>
<ul dir="auto">
<li>Deploy on your infrastructure (AWS/GCP in target market)</li>
<li>Set up Stripe account and payment processing</li>
<li>Rebrand if desired (logo, domain, marketing site)</li>
<li>Create demo videos and sales collateral</li>
<li>I provide intensive technical support</li>
</ul>
<p dir="auto"><h3 dir="auto"><strong>Month 2-3: First Customers</strong></h3><a id="user-content-month-2-3-first-customers" aria-label="Permalink: Month 2-3: First Customers" href="#month-2-3-first-customers"></a></p>
<ul dir="auto">
<li>Target: Acquire 5-10 pilot customers</li>
<li>Pricing: $500-1000/month with discounted setup fees</li>
<li>Focus: Hotels, retail, or your existing client base</li>
<li>Collect feedback and testimonials</li>
<li>I implement critical feature requests</li>
</ul>
<p dir="auto"><h3 dir="auto"><strong>Month 4-6: Scale</strong></h3><a id="user-content-month-4-6-scale" aria-label="Permalink: Month 4-6: Scale" href="#month-4-6-scale"></a></p>
<ul dir="auto">
<li>Target: 20-30 customers</li>
<li>Improve animations based on feedback</li>
<li>Add language support if needed</li>
<li>Build case studies</li>
<li>Optimize costs (caching should reduce API costs 60-90%)</li>
</ul>
<p dir="auto"><h3 dir="auto"><strong>Month 7-12: Growth</strong></h3><a id="user-content-month-7-12-growth" aria-label="Permalink: Month 7-12: Growth" href="#month-7-12-growth"></a></p>
<ul dir="auto">
<li>Target: 50-100 customers</li>
<li>Hire additional support/sales if needed</li>
<li>Explore enterprise deals ($2-5k/month)</li>
<li>Consider raising funding if partnership model</li>
<li>I continue technical leadership</li>
</ul>
<p dir="auto"><strong>This is a real business opportunity.</strong> The market exists (Soul Machines has 100+ customers at 10x the price). The technology works (you tested it). It just needs someone who can access Stripe and sell.</p>
<hr>
<p dir="auto"><h2 dir="auto">Final Thoughts</h2><a id="user-content-final-thoughts" aria-label="Permalink: Final Thoughts" href="#final-thoughts"></a></p>
<p dir="auto">I built this because I had no other choice. The game industry collapsed. Iran's economy is in freefall. AI is taking developer jobs. I thought: "Build something valuable, and opportunity will follow."</p>
<p dir="auto">I was wrong about one thing: geography matters more than I thought. I can build enterprise software, but I can't charge for it from Iran.</p>
<p dir="auto">But I was right about another thing: this product is valuable. Soul Machines raised $70M selling similar technology for $50k+ setup fees. D-ID raised $25M with 2D avatars. The market is real.</p>
<p dir="auto"><strong>I don't want sympathy. I want a partner.</strong></p>
<p dir="auto">Someone who can access Stripe, understands B2B sales, and wants to build this into a real business.</p>
<p dir="auto">If that's you, let's talk.</p>
<hr>
<p dir="auto"><h2 dir="auto">How to Get Started</h2><a id="user-content-how-to-get-started" aria-label="Permalink: How to Get Started" href="#how-to-get-started"></a></p>
<p dir="auto"><h3 dir="auto"><strong>If you're seriously interested:</strong></h3><a id="user-content-if-youre-seriously-interested" aria-label="Permalink: If you're seriously interested:" href="#if-youre-seriously-interested"></a></p>
<ol dir="auto">
<li><strong>Test the demo</strong> ‚Üí <a href="https://neoclerks.com/en/" rel="nofollow">https://neoclerks.com/en/</a> (5 minutes)</li>
<li><strong>Schedule a call</strong> ‚Üí Email me at <a href="mailto:EchenDeligani@gmail.com">EchenDeligani@gmail.com</a></li>
<li><strong>Review the code</strong> ‚Üí I'll provide NDA + GitHub access</li>
<li><strong>Make a proposal</strong> ‚Üí Co-founder equity / Sale+contract / Revenue share</li>
</ol>
<p dir="auto"><h3 dir="auto"><strong>If you know someone who might be interested:</strong></h3><a id="user-content-if-you-know-someone-who-might-be-interested" aria-label="Permalink: If you know someone who might be interested:" href="#if-you-know-someone-who-might-be-interested"></a></p>
<ul dir="auto">
<li>Share this article with digital agencies, SaaS entrepreneurs, or investors</li>
<li>Introduce me via email</li>
<li><strong>Referral bonus</strong>: I'll pay 5% ($3-4k) if your intro leads to a deal</li>
</ul>
<p dir="auto"><h3 dir="auto"><strong>If you're just curious:</strong></h3><a id="user-content-if-youre-just-curious" aria-label="Permalink: If you're just curious:" href="#if-youre-just-curious"></a></p>
<ul dir="auto">
<li>Test the demo anyway (it's genuinely cool tech)</li>
<li>Ask questions in the comments (I'll respond to everything)</li>
<li>Follow for updates on how this story ends</li>
</ul>
<hr>
<p dir="auto"><h2 dir="auto">Contact Information</h2><a id="user-content-contact-information" aria-label="Permalink: Contact Information" href="#contact-information"></a></p>
<p dir="auto"><strong>Email</strong>: <a href="mailto:EchenDeligani@gmail.com">EchenDeligani@gmail.com</a>
<strong>LinkedIn</strong>: <a href="https://www.linkedin.com/in/echen-deligani/" rel="nofollow">https://www.linkedin.com/in/echen-deligani/</a>
<strong>Telegram</strong>: @unnamedhn
<strong>WhatsApp</strong>: +98 901 441 1869</p>
<p dir="auto"><strong>Live Demo</strong>: <a href="https://neoclerks.com/en/" rel="nofollow">https://neoclerks.com/en/</a></p>
<p dir="auto"><strong>Partnership Options</strong>:</p>
<ul dir="auto">
<li>Co-founder: $50-80k + equity split</li>
<li>Sale + Contract: $60-80k + 3-year agreement ($4-6k/month)</li>
<li>Revenue share: $30-50k + 50/50 split until ROI</li>
</ul>
<p dir="auto"><strong>Timeline</strong>: 4-6 weeks from first contact to deal closed</p>
<hr>
<p dir="auto"><h2 dir="auto">Updates</h2><a id="user-content-updates" aria-label="Permalink: Updates" href="#updates"></a></p>
<p dir="auto">I'll update this section as things progress:</p>
<ul>
<li><strong>2025-11-12</strong>: Posted on Medium, HackerNews, Reddit r/SaaS</li>
<li> Demo calls scheduled</li>
<li> Code reviews in progress</li>
<li> Negotiating with potential partners</li>
<li> <strong>DEAL CLOSED</strong>: [Date TBD]</li>
</ul>
<p dir="auto">Follow me to see how this story ends.</p>
<hr>
<p dir="auto"><em>Originally written: November 2025</em></p>
<p dir="auto"><strong>Tags</strong>: #AI #Startups #SaaS #UnrealEngine #TechPartner #Partnership #SoulMachines #AvatarAI #ConversationalAI #IranTech #Entrepreneurship</p>
<hr>
<p dir="auto"><h2 dir="auto">Comments</h2><a id="user-content-comments" aria-label="Permalink: Comments" href="#comments"></a></p>
<p dir="auto"><strong>Questions? Want to discuss partnership? Technical deep-dive requests?</strong></p>
<p dir="auto">Drop a comment below or reach out directly. I respond to every message within 24 hours.</p>
<p dir="auto"><strong>I built this for 18 months through war and 120-hour weeks. Now I need a partner who can help me turn it into a real business.</strong></p>
<p dir="auto"><strong>Is that you?</strong></p>
</article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[.NET MAUI is coming to Linux and the browser, powered by Avalonia (173 pts)]]></title>
            <link>https://avaloniaui.net/blog/net-maui-is-coming-to-linux-and-the-browser-powered-by-avalonia</link>
            <guid>45893986</guid>
            <pubDate>Tue, 11 Nov 2025 22:50:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://avaloniaui.net/blog/net-maui-is-coming-to-linux-and-the-browser-powered-by-avalonia">https://avaloniaui.net/blog/net-maui-is-coming-to-linux-and-the-browser-powered-by-avalonia</a>, See on <a href="https://news.ycombinator.com/item?id=45893986">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-framer-name="Content"><div data-framer-name="Content" data-framer-component-type="RichTextContainer"><p>We are bringing .NET MAUI to Linux and to the browser, powered by Avalonia.</p><p>For the past few months, we have been working on an Avalonia powered backend for .NET MAUI, with guidance and feedback from engineers in the MAUI ecosystem. What started as an experiment has grown into a project we are committing to, with apps already running on new platforms. It is time to show you what we have been building.</p><h2>Try It Right Now</h2><p>Before we dive into the details, you can experience it yourself:</p><p><!--$--><a href="https://brave-sky-0c7a41a03-preview.westeurope.3.azurestaticapps.net/" target="_blank" rel="noopener"><strong>Launch MAUI in your browser ‚Üí</strong></a><!--/$--></p><p>This is a real MAUI application running on WebAssembly, rendered through Avalonia, with no plugins or hidden tricks. It is an early build with rough edges, but it proves the point: MAUI can now run on every major desktop OS and in the browser.</p><h2>What is the Avalonia MAUI Backend?</h2><p>At its core, the Avalonia MAUI Backend enables you to keep your MAUI codebase while replacing the rendering layer with Avalonia. The goal is straightforward: take your existing MAUI applications and extend them to additional platforms, while enhancing desktop performance along the way.</p><p>In practical terms, that means several big wins.</p><h3>Desktop Linux support</h3><p>.NET MAUI apps running as first class desktop apps on distributions such as Ubuntu, Debian and Fedora, sharing the same Avalonia renderer that already powers demanding desktop apps in production today.</p><p><img alt="" width="899" height="506" src="https://framerusercontent.com/images/KyaYoF7ykWI3G1pHcJVRbDXx1B8.png" srcset="https://framerusercontent.com/images/KyaYoF7ykWI3G1pHcJVRbDXx1B8.png?scale-down-to=512&amp;width=1799&amp;height=1013 512w,https://framerusercontent.com/images/KyaYoF7ykWI3G1pHcJVRbDXx1B8.png?scale-down-to=1024&amp;width=1799&amp;height=1013 1024w,https://framerusercontent.com/images/KyaYoF7ykWI3G1pHcJVRbDXx1B8.png?width=1799&amp;height=1013 1799w" data-framer-original-sizes="" sizes="(min-width: 1400px) 100vw, (min-width: 800px) and (max-width: 1399.98px) 100vw, (max-width: 799.98px) 100vw"></p><video autoplay="" loop="" muted="" playsinline="" src="https://framerusercontent.com/images/2t4wGG4T3lL7WgeuQul6aggxBNA.mp4"></video><h3>Embedded Linux</h3><p>Avalonia already runs on embedded Linux devices, from Raspberry Pi panels to industrial HMIs. Using the same backend, the Avalonia MAUI Backend brings those capabilities to MAUI as well, so the applications you build in MAUI can run on the same embedded Linux targets as Avalonia.</p><h3>WebAssembly support</h3><div><p>The demo you can open in your browser today is a real MAUI application running on WebAssembly, rendered by Avalonia, with no native dependencies on the client. It is an early build, but it demonstrates what is now possible. MAUI apps will soon be free to deploy to the browser.</p></div><p><img alt="" width="1337" height="1004" src="https://framerusercontent.com/images/T9sNNunB9VG7qoS56a2mHrhSj2I.png" srcset="https://framerusercontent.com/images/T9sNNunB9VG7qoS56a2mHrhSj2I.png?scale-down-to=512&amp;width=2674&amp;height=2008 512w,https://framerusercontent.com/images/T9sNNunB9VG7qoS56a2mHrhSj2I.png?scale-down-to=1024&amp;width=2674&amp;height=2008 1024w,https://framerusercontent.com/images/T9sNNunB9VG7qoS56a2mHrhSj2I.png?scale-down-to=2048&amp;width=2674&amp;height=2008 2048w,https://framerusercontent.com/images/T9sNNunB9VG7qoS56a2mHrhSj2I.png?width=2674&amp;height=2008 2674w" data-framer-original-sizes="" sizes="(min-width: 1400px) 100vw, (min-width: 800px) and (max-width: 1399.98px) 100vw, (max-width: 799.98px) 100vw"></p><h3>Bonus: The Avalonia MAUI Backend runs on Windows and macOS too</h3><p>On Windows and macOS, it plugs into the same mature desktop story Avalonia already has. On macOS, early testing indicates significantly improved performance compared to the Mac Catalyst approach. We are seeing more than 2x the performance in representative desktop scenarios, which is a very encouraging sign for the future of MAUI on desktop.</p><p>All of this is possible because we have built a version of MAUI that sits on top of Avalonia‚Äôs drawn UI model rather than native controls. Not only do you get more platforms and improved performance, your MAUI applications can look and behave consistently whether they are on Windows, macOS, Linux, mobile or running in a browser tab.</p><h3>Simpler, faster development</h3><p>For the Avalonia team, this architecture has a major practical benefit: we only have to target one platform: Avalonia itself. That single target means we can move faster, ship features consistently, and avoid the need to endlessly fix platform-specific edge cases.</p><p><img alt="" width="1276" height="285" src="https://framerusercontent.com/images/H4IFZdeFuwE4I7XSlLN5GlTBeZY.png" srcset="https://framerusercontent.com/images/H4IFZdeFuwE4I7XSlLN5GlTBeZY.png?scale-down-to=512&amp;width=2552&amp;height=571 512w,https://framerusercontent.com/images/H4IFZdeFuwE4I7XSlLN5GlTBeZY.png?scale-down-to=1024&amp;width=2552&amp;height=571 1024w,https://framerusercontent.com/images/H4IFZdeFuwE4I7XSlLN5GlTBeZY.png?scale-down-to=2048&amp;width=2552&amp;height=571 2048w,https://framerusercontent.com/images/H4IFZdeFuwE4I7XSlLN5GlTBeZY.png?width=2552&amp;height=571 2552w" data-framer-original-sizes="" sizes="(min-width: 1400px) 100vw, (min-width: 800px) and (max-width: 1399.98px) 100vw, (max-width: 799.98px) 100vw"></p><div><p>Instead of maintaining separate implementations for iOS, Android, Windows, macOS, Linux, and WebAssembly, we maintain just one. That massively reduces the chances of platform quirks, that can eat up hours of debugging time when something works on Android but not iOS, or renders differently on Mac Catalyst versus WinUI 3. When building on Avalonia, the controls render the same way everywhere because they are using the same rendering engine everywhere.</p><p>That means when we add a feature or fix a bug, it works across all platforms. No more "this works on mobile but breaks on desktop" or "this looks right on Windows but wrong on macOS." The entire development cycle becomes more predictable and significantly faster. </p><p>For us, that is a significant advantage. For MAUI developers, it means the backend evolves faster and more reliably.</p></div><h2>Why Is Avalonia Building a Backend for MAUI?</h2><p>It is a fair question. Avalonia already has its own thriving ecosystem. We see strong, sustained growth in our community, so why invest this much effort into making MAUI run on top of Avalonia?</p><p>The honest answer is that we care about .NET client developers first, and about which on ramp they use second. Many teams have already chosen MAUI, which they like and want more from. If we can provide them with Linux and browser support, along with improved desktop performance, without requiring a rewrite, that aligns with our mission to delight developers and solve complex problems.</p><p>This is not entirely selfless. Building a MAUI backend is also a way for us to learn. Running MAUI on Avalonia highlights what is missing for Avalonia to feel completely natural on mobile, which APIs are problematic, which tooling gaps matter, and where we need to raise our game to stay competitive. The work we are doing here directly contributes to strengthening Avalonia.</p><p>There is also a long term benefit in familiarity. By using Avalonia as the backend for their existing MAUI apps, developers gain insight into our renderer, capabilities and way of thinking. Some of those teams will quite reasonably stay with MAUI. Others, when they start a new project or need something lower level, may build directly on Avalonia instead. If this backend becomes a bridge that brings more people into the Avalonia ecosystem over time, that is a win.</p><p>So this project is not about ‚Äúsaving‚Äù MAUI from other frameworks. It is about giving existing MAUI developers more headroom and additional platforms, learning from their needs, and ensuring Avalonia is an obvious, competitive choice for whatever they build next.</p><h2>Why This Matters for MAUI Developers</h2><p>If you have followed MAUI since its launch, you will know the two requests that never went away.</p><p>Developers want Linux support, both for desktop and for embedded devices. They also want a drawn control model that provides consistent behaviour across platforms, rather than relying on the native toolkit available on each system.</p><p>The Avalonia backend tackles both of those head on. Avalonia is a mature drawn UI framework.</p><p>It provides:</p><ul><li data-preset-tag="p"><p>Hardware accelerated rendering on every platform</p></li><li data-preset-tag="p"><p>A consistent layout and styling system</p></li><li data-preset-tag="p"><p>Smooth animations at high refresh rates</p></li><li data-preset-tag="p"><p>Custom rendering and visual effects capabilities</p></li><li data-preset-tag="p"><p>Broad platform coverage</p></li><li data-preset-tag="p"><p>A fully supported platform that is receiving significant investment</p></li></ul><p>These are not theoretical promises. They are the reasons Avalonia is used in production by companies such as Unity, JetBrains and Schneider Electric.</p><p>By building MAUI on top of Avalonia, you get a predictable, drawn UI foundation and an expanded set of platforms, without having to throw away your existing codebase. You do not need to abandon MAUI to get Linux and the web. You can bring MAUI with you, while also improving the experience on Windows and macOS.</p><h2>Performance and Next Generation Rendering</h2><p>Performance is an important part of this story.</p><p>A drawn, GPU friendly UI stack gives you more headroom than wrapping native toolkits.</p><p>We are collaborating with the Flutter team at Google to bring Impeller, their GPU first renderer, to .NET. That work is already in progress and as it lands, the MAUI backend will inherit those gains.</p><p>The aim is simple: faster rendering, lower battery usage and smoother animations across desktop, mobile and embedded, using the same underlying technology that is pushing Flutter forward.</p><p><!--$--><a href="https://avaloniaui.net/blog/avalonia-partners-with-google-s-flutter-t-eam-to-bring-impeller-rendering-to-net">Read more about our Impeller collaboration with Google ‚Üí</a><!--/$--></p><h2>Looking Forward</h2><p>We are particularly grateful to the MAUI engineers who have shared feedback and ideas as we have developed this backend. The .NET client ecosystem is at its best when different teams can cross pollinate and push each other forward.</p><p>This is just the beginning. As Linux and browser support matures, MAUI can finally live up to its promise as a truly multi platform app UI. We will keep sharing previews, benchmarks and updates as development continues, and once we are happy with the stability of the backend we will release the source code as fully open source under the MIT licence.</p><p><!--$--><a href="https://avaloniaui.net/maui-interest"><strong>‚Üí Register your interest in the early access ‚Üê</strong></a><!--/$--><strong></strong></p><br></div><div data-framer-name="Content" data-framer-component-type="RichTextContainer"><p>We are bringing .NET MAUI to Linux and to the browser, powered by Avalonia.</p><p>For the past few months, we have been working on an Avalonia powered backend for .NET MAUI, with guidance and feedback from engineers in the MAUI ecosystem. What started as an experiment has grown into a project we are committing to, with apps already running on new platforms. It is time to show you what we have been building.</p><h2>Try It Right Now</h2><p>Before we dive into the details, you can experience it yourself:</p><p><!--$--><a href="https://brave-sky-0c7a41a03-preview.westeurope.3.azurestaticapps.net/" target="_blank" rel="noopener"><strong>Launch MAUI in your browser ‚Üí</strong></a><!--/$--></p><p>This is a real MAUI application running on WebAssembly, rendered through Avalonia, with no plugins or hidden tricks. It is an early build with rough edges, but it proves the point: MAUI can now run on every major desktop OS and in the browser.</p><h2>What is the Avalonia MAUI Backend?</h2><p>At its core, the Avalonia MAUI Backend enables you to keep your MAUI codebase while replacing the rendering layer with Avalonia. The goal is straightforward: take your existing MAUI applications and extend them to additional platforms, while enhancing desktop performance along the way.</p><p>In practical terms, that means several big wins.</p><h3>Desktop Linux support</h3><p>.NET MAUI apps running as first class desktop apps on distributions such as Ubuntu, Debian and Fedora, sharing the same Avalonia renderer that already powers demanding desktop apps in production today.</p><p><img alt="" width="899" height="506" src="https://framerusercontent.com/images/KyaYoF7ykWI3G1pHcJVRbDXx1B8.png" srcset="https://framerusercontent.com/images/KyaYoF7ykWI3G1pHcJVRbDXx1B8.png?scale-down-to=512&amp;width=1799&amp;height=1013 512w,https://framerusercontent.com/images/KyaYoF7ykWI3G1pHcJVRbDXx1B8.png?scale-down-to=1024&amp;width=1799&amp;height=1013 1024w,https://framerusercontent.com/images/KyaYoF7ykWI3G1pHcJVRbDXx1B8.png?width=1799&amp;height=1013 1799w" data-framer-original-sizes="" sizes="(min-width: 1400px) 100vw, (min-width: 800px) and (max-width: 1399.98px) 100vw, (max-width: 799.98px) 100vw"></p><video autoplay="" loop="" muted="" playsinline="" src="https://framerusercontent.com/images/2t4wGG4T3lL7WgeuQul6aggxBNA.mp4"></video><h3>Embedded Linux</h3><p>Avalonia already runs on embedded Linux devices, from Raspberry Pi panels to industrial HMIs. Using the same backend, the Avalonia MAUI Backend brings those capabilities to MAUI as well, so the applications you build in MAUI can run on the same embedded Linux targets as Avalonia.</p><h3>WebAssembly support</h3><div><p>The demo you can open in your browser today is a real MAUI application running on WebAssembly, rendered by Avalonia, with no native dependencies on the client. It is an early build, but it demonstrates what is now possible. MAUI apps will soon be free to deploy to the browser.</p></div><p><img alt="" width="1337" height="1004" src="https://framerusercontent.com/images/T9sNNunB9VG7qoS56a2mHrhSj2I.png" srcset="https://framerusercontent.com/images/T9sNNunB9VG7qoS56a2mHrhSj2I.png?scale-down-to=512&amp;width=2674&amp;height=2008 512w,https://framerusercontent.com/images/T9sNNunB9VG7qoS56a2mHrhSj2I.png?scale-down-to=1024&amp;width=2674&amp;height=2008 1024w,https://framerusercontent.com/images/T9sNNunB9VG7qoS56a2mHrhSj2I.png?scale-down-to=2048&amp;width=2674&amp;height=2008 2048w,https://framerusercontent.com/images/T9sNNunB9VG7qoS56a2mHrhSj2I.png?width=2674&amp;height=2008 2674w" data-framer-original-sizes="" sizes="(min-width: 1400px) 100vw, (min-width: 800px) and (max-width: 1399.98px) 100vw, (max-width: 799.98px) 100vw"></p><h3>Bonus: The Avalonia MAUI Backend runs on Windows and macOS too</h3><p>On Windows and macOS, it plugs into the same mature desktop story Avalonia already has. On macOS, early testing indicates significantly improved performance compared to the Mac Catalyst approach. We are seeing more than 2x the performance in representative desktop scenarios, which is a very encouraging sign for the future of MAUI on desktop.</p><p>All of this is possible because we have built a version of MAUI that sits on top of Avalonia‚Äôs drawn UI model rather than native controls. Not only do you get more platforms and improved performance, your MAUI applications can look and behave consistently whether they are on Windows, macOS, Linux, mobile or running in a browser tab.</p><h3>Simpler, faster development</h3><p>For the Avalonia team, this architecture has a major practical benefit: we only have to target one platform: Avalonia itself. That single target means we can move faster, ship features consistently, and avoid the need to endlessly fix platform-specific edge cases.</p><p><img alt="" width="1276" height="285" src="https://framerusercontent.com/images/H4IFZdeFuwE4I7XSlLN5GlTBeZY.png" srcset="https://framerusercontent.com/images/H4IFZdeFuwE4I7XSlLN5GlTBeZY.png?scale-down-to=512&amp;width=2552&amp;height=571 512w,https://framerusercontent.com/images/H4IFZdeFuwE4I7XSlLN5GlTBeZY.png?scale-down-to=1024&amp;width=2552&amp;height=571 1024w,https://framerusercontent.com/images/H4IFZdeFuwE4I7XSlLN5GlTBeZY.png?scale-down-to=2048&amp;width=2552&amp;height=571 2048w,https://framerusercontent.com/images/H4IFZdeFuwE4I7XSlLN5GlTBeZY.png?width=2552&amp;height=571 2552w" data-framer-original-sizes="" sizes="(min-width: 1400px) 100vw, (min-width: 800px) and (max-width: 1399.98px) 100vw, (max-width: 799.98px) 100vw"></p><div><p>Instead of maintaining separate implementations for iOS, Android, Windows, macOS, Linux, and WebAssembly, we maintain just one. That massively reduces the chances of platform quirks, that can eat up hours of debugging time when something works on Android but not iOS, or renders differently on Mac Catalyst versus WinUI 3. When building on Avalonia, the controls render the same way everywhere because they are using the same rendering engine everywhere.</p><p>That means when we add a feature or fix a bug, it works across all platforms. No more "this works on mobile but breaks on desktop" or "this looks right on Windows but wrong on macOS." The entire development cycle becomes more predictable and significantly faster. </p><p>For us, that is a significant advantage. For MAUI developers, it means the backend evolves faster and more reliably.</p></div><h2>Why Is Avalonia Building a Backend for MAUI?</h2><p>It is a fair question. Avalonia already has its own thriving ecosystem. We see strong, sustained growth in our community, so why invest this much effort into making MAUI run on top of Avalonia?</p><p>The honest answer is that we care about .NET client developers first, and about which on ramp they use second. Many teams have already chosen MAUI, which they like and want more from. If we can provide them with Linux and browser support, along with improved desktop performance, without requiring a rewrite, that aligns with our mission to delight developers and solve complex problems.</p><p>This is not entirely selfless. Building a MAUI backend is also a way for us to learn. Running MAUI on Avalonia highlights what is missing for Avalonia to feel completely natural on mobile, which APIs are problematic, which tooling gaps matter, and where we need to raise our game to stay competitive. The work we are doing here directly contributes to strengthening Avalonia.</p><p>There is also a long term benefit in familiarity. By using Avalonia as the backend for their existing MAUI apps, developers gain insight into our renderer, capabilities and way of thinking. Some of those teams will quite reasonably stay with MAUI. Others, when they start a new project or need something lower level, may build directly on Avalonia instead. If this backend becomes a bridge that brings more people into the Avalonia ecosystem over time, that is a win.</p><p>So this project is not about ‚Äúsaving‚Äù MAUI from other frameworks. It is about giving existing MAUI developers more headroom and additional platforms, learning from their needs, and ensuring Avalonia is an obvious, competitive choice for whatever they build next.</p><h2>Why This Matters for MAUI Developers</h2><p>If you have followed MAUI since its launch, you will know the two requests that never went away.</p><p>Developers want Linux support, both for desktop and for embedded devices. They also want a drawn control model that provides consistent behaviour across platforms, rather than relying on the native toolkit available on each system.</p><p>The Avalonia backend tackles both of those head on. Avalonia is a mature drawn UI framework.</p><p>It provides:</p><ul><li data-preset-tag="p"><p>Hardware accelerated rendering on every platform</p></li><li data-preset-tag="p"><p>A consistent layout and styling system</p></li><li data-preset-tag="p"><p>Smooth animations at high refresh rates</p></li><li data-preset-tag="p"><p>Custom rendering and visual effects capabilities</p></li><li data-preset-tag="p"><p>Broad platform coverage</p></li><li data-preset-tag="p"><p>A fully supported platform that is receiving significant investment</p></li></ul><p>These are not theoretical promises. They are the reasons Avalonia is used in production by companies such as Unity, JetBrains and Schneider Electric.</p><p>By building MAUI on top of Avalonia, you get a predictable, drawn UI foundation and an expanded set of platforms, without having to throw away your existing codebase. You do not need to abandon MAUI to get Linux and the web. You can bring MAUI with you, while also improving the experience on Windows and macOS.</p><h2>Performance and Next Generation Rendering</h2><p>Performance is an important part of this story.</p><p>A drawn, GPU friendly UI stack gives you more headroom than wrapping native toolkits.</p><p>We are collaborating with the Flutter team at Google to bring Impeller, their GPU first renderer, to .NET. That work is already in progress and as it lands, the MAUI backend will inherit those gains.</p><p>The aim is simple: faster rendering, lower battery usage and smoother animations across desktop, mobile and embedded, using the same underlying technology that is pushing Flutter forward.</p><p><!--$--><a href="https://avaloniaui.net/blog/avalonia-partners-with-google-s-flutter-t-eam-to-bring-impeller-rendering-to-net">Read more about our Impeller collaboration with Google ‚Üí</a><!--/$--></p><h2>Looking Forward</h2><p>We are particularly grateful to the MAUI engineers who have shared feedback and ideas as we have developed this backend. The .NET client ecosystem is at its best when different teams can cross pollinate and push each other forward.</p><p>This is just the beginning. As Linux and browser support matures, MAUI can finally live up to its promise as a truly multi platform app UI. We will keep sharing previews, benchmarks and updates as development continues, and once we are happy with the stability of the backend we will release the source code as fully open source under the MIT licence.</p><p><!--$--><a href="https://avaloniaui.net/maui-interest"><strong>‚Üí Register your interest in the early access ‚Üê</strong></a><!--/$--><strong></strong></p><br></div><div data-framer-name="Content" data-framer-component-type="RichTextContainer"><p>We are bringing .NET MAUI to Linux and to the browser, powered by Avalonia.</p><p>For the past few months, we have been working on an Avalonia powered backend for .NET MAUI, with guidance and feedback from engineers in the MAUI ecosystem. What started as an experiment has grown into a project we are committing to, with apps already running on new platforms. It is time to show you what we have been building.</p><h2>Try It Right Now</h2><p>Before we dive into the details, you can experience it yourself:</p><p><!--$--><a href="https://brave-sky-0c7a41a03-preview.westeurope.3.azurestaticapps.net/" target="_blank" rel="noopener"><strong>Launch MAUI in your browser ‚Üí</strong></a><!--/$--></p><p>This is a real MAUI application running on WebAssembly, rendered through Avalonia, with no plugins or hidden tricks. It is an early build with rough edges, but it proves the point: MAUI can now run on every major desktop OS and in the browser.</p><h2>What is the Avalonia MAUI Backend?</h2><p>At its core, the Avalonia MAUI Backend enables you to keep your MAUI codebase while replacing the rendering layer with Avalonia. The goal is straightforward: take your existing MAUI applications and extend them to additional platforms, while enhancing desktop performance along the way.</p><p>In practical terms, that means several big wins.</p><h3>Desktop Linux support</h3><p>.NET MAUI apps running as first class desktop apps on distributions such as Ubuntu, Debian and Fedora, sharing the same Avalonia renderer that already powers demanding desktop apps in production today.</p><p><img alt="" width="899" height="506" src="https://framerusercontent.com/images/KyaYoF7ykWI3G1pHcJVRbDXx1B8.png" srcset="https://framerusercontent.com/images/KyaYoF7ykWI3G1pHcJVRbDXx1B8.png?scale-down-to=512&amp;width=1799&amp;height=1013 512w,https://framerusercontent.com/images/KyaYoF7ykWI3G1pHcJVRbDXx1B8.png?scale-down-to=1024&amp;width=1799&amp;height=1013 1024w,https://framerusercontent.com/images/KyaYoF7ykWI3G1pHcJVRbDXx1B8.png?width=1799&amp;height=1013 1799w" data-framer-original-sizes="" sizes="(min-width: 1400px) 100vw, (min-width: 800px) and (max-width: 1399.98px) 100vw, (max-width: 799.98px) 100vw"></p><video autoplay="" loop="" muted="" playsinline="" src="https://framerusercontent.com/images/2t4wGG4T3lL7WgeuQul6aggxBNA.mp4"></video><h3>Embedded Linux</h3><p>Avalonia already runs on embedded Linux devices, from Raspberry Pi panels to industrial HMIs. Using the same backend, the Avalonia MAUI Backend brings those capabilities to MAUI as well, so the applications you build in MAUI can run on the same embedded Linux targets as Avalonia.</p><h3>WebAssembly support</h3><div><p>The demo you can open in your browser today is a real MAUI application running on WebAssembly, rendered by Avalonia, with no native dependencies on the client. It is an early build, but it demonstrates what is now possible. MAUI apps will soon be free to deploy to the browser.</p></div><p><img alt="" width="1337" height="1004" src="https://framerusercontent.com/images/T9sNNunB9VG7qoS56a2mHrhSj2I.png" srcset="https://framerusercontent.com/images/T9sNNunB9VG7qoS56a2mHrhSj2I.png?scale-down-to=512&amp;width=2674&amp;height=2008 512w,https://framerusercontent.com/images/T9sNNunB9VG7qoS56a2mHrhSj2I.png?scale-down-to=1024&amp;width=2674&amp;height=2008 1024w,https://framerusercontent.com/images/T9sNNunB9VG7qoS56a2mHrhSj2I.png?scale-down-to=2048&amp;width=2674&amp;height=2008 2048w,https://framerusercontent.com/images/T9sNNunB9VG7qoS56a2mHrhSj2I.png?width=2674&amp;height=2008 2674w" data-framer-original-sizes="" sizes="(min-width: 1400px) 100vw, (min-width: 800px) and (max-width: 1399.98px) 100vw, (max-width: 799.98px) 100vw"></p><h3>Bonus: The Avalonia MAUI Backend runs on Windows and macOS too</h3><p>On Windows and macOS, it plugs into the same mature desktop story Avalonia already has. On macOS, early testing indicates significantly improved performance compared to the Mac Catalyst approach. We are seeing more than 2x the performance in representative desktop scenarios, which is a very encouraging sign for the future of MAUI on desktop.</p><p>All of this is possible because we have built a version of MAUI that sits on top of Avalonia‚Äôs drawn UI model rather than native controls. Not only do you get more platforms and improved performance, your MAUI applications can look and behave consistently whether they are on Windows, macOS, Linux, mobile or running in a browser tab.</p><h3>Simpler, faster development</h3><p>For the Avalonia team, this architecture has a major practical benefit: we only have to target one platform: Avalonia itself. That single target means we can move faster, ship features consistently, and avoid the need to endlessly fix platform-specific edge cases.</p><p><img alt="" width="1276" height="285" src="https://framerusercontent.com/images/H4IFZdeFuwE4I7XSlLN5GlTBeZY.png" srcset="https://framerusercontent.com/images/H4IFZdeFuwE4I7XSlLN5GlTBeZY.png?scale-down-to=512&amp;width=2552&amp;height=571 512w,https://framerusercontent.com/images/H4IFZdeFuwE4I7XSlLN5GlTBeZY.png?scale-down-to=1024&amp;width=2552&amp;height=571 1024w,https://framerusercontent.com/images/H4IFZdeFuwE4I7XSlLN5GlTBeZY.png?scale-down-to=2048&amp;width=2552&amp;height=571 2048w,https://framerusercontent.com/images/H4IFZdeFuwE4I7XSlLN5GlTBeZY.png?width=2552&amp;height=571 2552w" data-framer-original-sizes="" sizes="(min-width: 1400px) 100vw, (min-width: 800px) and (max-width: 1399.98px) 100vw, (max-width: 799.98px) 100vw"></p><div><p>Instead of maintaining separate implementations for iOS, Android, Windows, macOS, Linux, and WebAssembly, we maintain just one. That massively reduces the chances of platform quirks, that can eat up hours of debugging time when something works on Android but not iOS, or renders differently on Mac Catalyst versus WinUI 3. When building on Avalonia, the controls render the same way everywhere because they are using the same rendering engine everywhere.</p><p>That means when we add a feature or fix a bug, it works across all platforms. No more "this works on mobile but breaks on desktop" or "this looks right on Windows but wrong on macOS." The entire development cycle becomes more predictable and significantly faster. </p><p>For us, that is a significant advantage. For MAUI developers, it means the backend evolves faster and more reliably.</p></div><h2>Why Is Avalonia Building a Backend for MAUI?</h2><p>It is a fair question. Avalonia already has its own thriving ecosystem. We see strong, sustained growth in our community, so why invest this much effort into making MAUI run on top of Avalonia?</p><p>The honest answer is that we care about .NET client developers first, and about which on ramp they use second. Many teams have already chosen MAUI, which they like and want more from. If we can provide them with Linux and browser support, along with improved desktop performance, without requiring a rewrite, that aligns with our mission to delight developers and solve complex problems.</p><p>This is not entirely selfless. Building a MAUI backend is also a way for us to learn. Running MAUI on Avalonia highlights what is missing for Avalonia to feel completely natural on mobile, which APIs are problematic, which tooling gaps matter, and where we need to raise our game to stay competitive. The work we are doing here directly contributes to strengthening Avalonia.</p><p>There is also a long term benefit in familiarity. By using Avalonia as the backend for their existing MAUI apps, developers gain insight into our renderer, capabilities and way of thinking. Some of those teams will quite reasonably stay with MAUI. Others, when they start a new project or need something lower level, may build directly on Avalonia instead. If this backend becomes a bridge that brings more people into the Avalonia ecosystem over time, that is a win.</p><p>So this project is not about ‚Äúsaving‚Äù MAUI from other frameworks. It is about giving existing MAUI developers more headroom and additional platforms, learning from their needs, and ensuring Avalonia is an obvious, competitive choice for whatever they build next.</p><h2>Why This Matters for MAUI Developers</h2><p>If you have followed MAUI since its launch, you will know the two requests that never went away.</p><p>Developers want Linux support, both for desktop and for embedded devices. They also want a drawn control model that provides consistent behaviour across platforms, rather than relying on the native toolkit available on each system.</p><p>The Avalonia backend tackles both of those head on. Avalonia is a mature drawn UI framework.</p><p>It provides:</p><ul><li data-preset-tag="p"><p>Hardware accelerated rendering on every platform</p></li><li data-preset-tag="p"><p>A consistent layout and styling system</p></li><li data-preset-tag="p"><p>Smooth animations at high refresh rates</p></li><li data-preset-tag="p"><p>Custom rendering and visual effects capabilities</p></li><li data-preset-tag="p"><p>Broad platform coverage</p></li><li data-preset-tag="p"><p>A fully supported platform that is receiving significant investment</p></li></ul><p>These are not theoretical promises. They are the reasons Avalonia is used in production by companies such as Unity, JetBrains and Schneider Electric.</p><p>By building MAUI on top of Avalonia, you get a predictable, drawn UI foundation and an expanded set of platforms, without having to throw away your existing codebase. You do not need to abandon MAUI to get Linux and the web. You can bring MAUI with you, while also improving the experience on Windows and macOS.</p><h2>Performance and Next Generation Rendering</h2><p>Performance is an important part of this story.</p><p>A drawn, GPU friendly UI stack gives you more headroom than wrapping native toolkits.</p><p>We are collaborating with the Flutter team at Google to bring Impeller, their GPU first renderer, to .NET. That work is already in progress and as it lands, the MAUI backend will inherit those gains.</p><p>The aim is simple: faster rendering, lower battery usage and smoother animations across desktop, mobile and embedded, using the same underlying technology that is pushing Flutter forward.</p><p><!--$--><a href="https://avaloniaui.net/blog/avalonia-partners-with-google-s-flutter-t-eam-to-bring-impeller-rendering-to-net">Read more about our Impeller collaboration with Google ‚Üí</a><!--/$--></p><h2>Looking Forward</h2><p>We are particularly grateful to the MAUI engineers who have shared feedback and ideas as we have developed this backend. The .NET client ecosystem is at its best when different teams can cross pollinate and push each other forward.</p><p>This is just the beginning. As Linux and browser support matures, MAUI can finally live up to its promise as a truly multi platform app UI. We will keep sharing previews, benchmarks and updates as development continues, and once we are happy with the stability of the backend we will release the source code as fully open source under the MIT licence.</p><p><!--$--><a href="https://avaloniaui.net/maui-interest"><strong>‚Üí Register your interest in the early access ‚Üê</strong></a><!--/$--><strong></strong></p><br></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Four strange places to see London's Roman Wall (129 pts)]]></title>
            <link>https://diamondgeezer.blogspot.com/2025/11/odd-places-to-see-londons-roman-wall.html</link>
            <guid>45893795</guid>
            <pubDate>Tue, 11 Nov 2025 22:31:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://diamondgeezer.blogspot.com/2025/11/odd-places-to-see-londons-roman-wall.html">https://diamondgeezer.blogspot.com/2025/11/odd-places-to-see-londons-roman-wall.html</a>, See on <a href="https://news.ycombinator.com/item?id=45893795">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <a name="3254945716980684913"></a>    
          <i>There are <a href="https://en.wikipedia.org/wiki/London_Wall#Known_monuments_and_landmarks" target="_blank">many</a> <a href="https://colat.org.uk/wp-content/uploads/2024/07/London-Wall-Walk-guide.pdf" target="_blank">places</a> around the City of London to see its old <a href="https://www.english-heritage.org.uk/visit/places/london-wall/history/" target="_blank">Roman Wall</a>, notably alongside Noble Street, in Barber Surgeons' Meadow, through the Barbican, in St Alphage Garden and just outside the entrance to Tower Hill station. Here are four of the odder spots.</i>
<p>
<b><u>Four strange places to see London's Roman Wall</u></b></p><p>
<b>1) From platform 1 at Tower Hill station</b></p><p>
If you're ever waiting for a westbound train at Tower Hill station, take a walk to the rear of the platform and take a look across the tracks, roughly where the penultimate carriage would stop. High on the far wall is a square recess lined by black tiles, and at the back of that is a dimly-lit surface of chunky irregular blocks. Unlike every single other thing on the Underground, the Romans built that.
</p><p>
<img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgb2locUXUgdHSakPua-TyO6SVasQxlWPrse9F6CwqXLVM1oqPaXpBqAxjgbvc9H3zyDlibYX4Hmn0qVrMh_E5JwHEJl_PYQGMFJeTMcH4QogeJTNqhTR8gmed6vQV5nscU3Avuif3_ePzPpNkCLX2_ydqzKUfXz0x8mAwQMzFoTslTbOjAqx3mWQ/s1600/towerhilstn.jpg" title="the wall opposite platform 1 at Tower Hill station" data-original-height="375" data-original-width="500"></p><p>
London's original wall was 2 miles long, 6 metres high and almost 3 metres thick at its base, all the better to keep out uncivilised marauders. It was built around 200 AD, then left to decay and rebuilt in the medieval era, again for defensive purposes. This is one of the original bits, not that you can easily tell by squinting across the tracks. A small metal lamp points inwards but is no longer switched on because heritage illumination is not a TfL priority. There is however a rather nice silver plaque on the pillar opposite, should you step back far enough to notice it.
</p><p>
<img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhKJSryCZmQbUERGBEE5aEwbVX5UrBgPYyeZPT8psByjxtc253SMFxSZsjJS5b6SyNU3IatUqjXB4gjlR0JEzdXiw8E62y4DnTwSTwcdmE2gBbxkkoWLzJp1Yuy15K2WXVekqYQlgBR3xmeXOCyXAjTGsyxLHnbpe8pUv9UDRVGewvoVc-ujslZ2A/s1600/towerplak.jpg" title="plaque on platform 1 at Tower Hill station" data-original-height="375" data-original-width="500"></p><p>
The plaque confirms that the stones here are a continuation of the wall seen (much more clearly) outside. What it doesn't mention is the unavoidable truth that the wall must once have continued across the tracks and platforms but is no longer here. That's because when the Circle line was constructed in 1882 the railway companies had permission to demolish 22 metres of London's wall and duly did, the Victorians never being afraid to destroy ancient heritage. <a href="https://www.ianvisits.co.uk/articles/the-tube-station-with-a-piece-of-roman-wall-in-it-28063/" target="_blank">Ian Visits</a> has a photo of navvies standing atop the offending stonework just before they bashed it through. The square hole is no recompense, plus you can't see anything if a train's in the platform, but it is a brilliantly quirky thing to find on the Underground.
</p><p>
<b>2) Round the back of the Leonardo Royal Hotel</b></p><p>
The short walk from Tower Hill station to the rear entrance of Fenchurch Street passes two hotels. The second is the Leonardo Royal, formerly the Grange, whose car port looks like it leads to a cocktail terrace and maybe some parking. Nothing's signed from the street, indeed I'd never thought to duck through before, but at the far end past the umbrellas of Leo's bar is a <a href="https://www.flickr.com/photos/dgeezer/54915634089" target="_blank">significant chunk</a> of Roman wall. 
</p><p>
<a href="https://www.flickr.com/photos/dgeezer/54915634089" target="_blank"><img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhOfHkApAlEsIQL1lmNeyPV8_66Y0Na4z1-mqzL8-VbXyY2UXqZtJqBYp5HssoII_sakA2y-fEHN9r1AX0G4b6dPZ8bLPYrtfWJUCLLbrZOdIWeMxsgSEYw7w9x_3PSL7WF8l9KCTkTwFrcqxwqoqpm0RQKO5VcckV4MbVBkvVg5TWiE5cf1eVHPA/s1600/wallchunk.jpg" title="Roman Wall at the Leonardo Royal Hotel" data-original-height="375" data-original-width="500"></a></p><p>
The upper section has arched windows built for archers and square holes which once supported a timber platform. It's impressive of course merely medieval, part of the rebuild that occurred along much of the wall as the city grew and spread beyond its former border. To see the Roman section stand closer to the rail and look down, this because ground level then was a few metres lower than now. The telltale signs are several distinctive bands of thin red bricks, these added to strengthen and bond the structure, and which look like layers of jam in a particularly lumpy sponge. The entire segment behind the hotel is over 20m long, thus longer than the better-known chunk outside the station.
</p><p>
<a href="https://www.flickr.com/photos/dgeezer/54915689185" target="_blank"><img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEju8ZOotr7pi26pCHNBBVVspTb4aEOPTb6UZKkJnSuhKut2qmrSHzkW9eAtzoPlVECcAVfihlku-Pv-WnFRay98AKWK559c6u0NBtYOw_TUlIiYBvBJeCuHGBiBaeeE2X4y6-bxAxiZxal-RW3j0VcdwJQo40XUkGygne8xE1BxRUfhDCPfvY_KfQ/s1600/sideon.jpg" title="Roman Wall at the Leonardo Royal Hotel" data-original-height="375" data-original-width="500"></a></p><p>
Perhaps the best thing about this bit of wall is that you can walk through it. A couple of steps have been added on each side allowing passage through a <a href="https://www.flickr.com/photos/dgeezer/54915689185" target="_blank">low medieval arch</a>, all marked with anachronistic trip hazard markings. If steps aren't your thing you can also pass round the end of the wall on the flat. Round the other side are a glum alley and a staff back-entrance, also an exit into a separate backstreet past a sign that says </p><span>PRIVATE No Public Right Of Way Beyond This Point Entry At Your Own Risk Absolutely No Liability Is Accepted For Any Reason Whatsoever</span>. Stuff that, there's an actual Roman Wall back here.
<p>
<b>3) From a cafe terrace</b></p><p>
I've written about <a href="https://citywallvinestreet.org/" target="_blank">The City Wall at Vine Street</a> before, a free attraction opened in 2023 beneath a block of student flats. <a href="https://diamondgeezer.blogspot.com/2024/06/the-city-wall-at-vine-street.html" target="_blank">Last time</a> I had to battle the Procedural Curmudgeon to gain admittance but I'm pleased to say they've since loosened up and you can now simply gesture at the door, walk in and give your first name to a flunkey with a tablet. He rattled through the key information with all the practised enthusiasm of a call centre employee dictating terms and conditions, then sent me off down the stairs. 
</p><p>
<a href="https://www.flickr.com/photos/dgeezer/53818147256" target="_blank"><img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiuwmvZBL72Y2RH1oJbXI6X8voRbaBoBxSycp1GrQxmqn58fz5CNp2wn4pD6GiYTFkbiguBkp4wHrLCEjxMif0QpDUqdoQRyap584g3_u2nHWTy_M0UKtZTaajI6oYcO-GR1al51KXCBokDiri19tIeERjAOdq_9aj8fJuovmeFMasRywvfeA37FA/s1600/postun.jpg" title="The City Wall at Vine Street" data-original-height="375" data-original-width="500"></a></p><p>
Two walls are filled with finds from the excavations, including an AD 70s coin and the bones of a 1760s cat. Nobody's quite sure how the ancient Greek tombstone ended up here, given it predates Londinium, but it has pride of place in a central glass case. The 5-minute historical animation is pretty good too, assuming you can read quite fast. But the main draw is the multi-layered towering <a href="https://www.flickr.com/photos/dgeezer/53818147256" target="_blank">remnant of wall</a> which here has the benefit of being properly illuminated and protected from the elements. The protruding lower section (which looks much too clean to be so very old) is all that remains of an original postern, and is also unique because all the other towers elsewhere round the City are merely medieval.
</p><p>
<a href="https://www.flickr.com/photos/dgeezer/53818480299" target="_blank"><img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiOHW9y0b7sBcLDfZqR-iRt9buQoLX2YhZzOAr7_GJ-q2jj4bVSZbnPg2Ycw61afbEbnkbdaPytwRnOD-mdcaZSUDD9y0dfcfRlJRgQapZJVnjD0WcrR45M5wCDbhEx03jknpGUZG9omr9vsVjG7yPKSHiPnjFEsFz2imuuijhwNeBgT0e2PlZNdQ/s1600/romcafe.jpg" title="Senzo cafe, Vine Street" data-original-height="375" data-original-width="500"></a></p><p>
What's weird is that this large basement space is <a href="https://www.flickr.com/photos/dgeezer/53818480299" target="_blank">overlooked</a> by a balcony scattered with small tables at which sit students and businesspeople consuming coffee and all-day brunch. The baristas operate from the cafe upstairs but any food comes from a small kitchen down below, which has the unnerving side effect that while you're wandering around what looks like a museum it smells like an office canteen. If you choose to be tempted by a cappuccino and smashed avocado on your way out you can enjoy extra time with the Roman wall, or indeed skip the walkthrough altogether and focus only on refreshment with an absolutely unique view. I recommend a proper visit though... the visitors book awaits your praise. 
</p><p>
<b>4) At the rear of a car park</b></p><p>
This is amazing on many levels, the main level being subterranean. After WW2 so much of the City was in ruins that planners drove a new dual carriageway through the Aldersgate area and called it London Wall. They believed cars were the future and to that end hid a linear <a href="https://www.cityoflondon.gov.uk/services/parking/car-parks/london-wall-car-park" target="_blank">car park</a> directly underneath the new road. It's very narrow, very long and pretty grim, indeed precisely the kind of filming location you'd expect a throwback crime thriller to use for a shoot-out or kidnapping. Cars <a href="https://osm.org/go/euu4uYiF9--?m=" target="_blank">enter</a> down a short spiral ramp and pedestrians through a grubby side door, and the numbered concrete catacombs stretch on and on for almost 400 metres. Keep walking past the white vans, Range Rovers and the attendant's cabin, trying not to attract too much attention, and almost at the far end is... blimey.
</p><p>
<a href="https://www.flickr.com/photos/dgeezer/54916433010" target="_blank"><img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj1ubdrJlo7E5qTThn8ioGGvtd8VfNJzljYY3JSr4X4dIE_VC8QPU_kMpQendZjevqSVSHOKJ4DyWxLvl2WUVNkv94s0tIR2YJbzfEZUHem_AVM696E5FGesTwGOsS7HoINEcHY6uW6KwIpxGiNvcEzDwL5MBLK4VrcVFUHv6ZxjaGuwhUIyh31xQ/s1600/52park.jpg" title="London Wall car park" data-original-height="375" data-original-width="500"></a></p><p>
You can't park in <a href="https://www.flickr.com/photos/dgeezer/54916433010" target="_blank">bays 52 and 53</a> because they're full of Roman remains. A substantial <a href="https://www.flickr.com/photos/dgeezer/54916349423" target="_blank">chunk of wall</a> slots in diagonally beneath the joists and pillars, tall enough to incorporate two separate bands of red bricks. It looks quite smooth up front but fairly rubbly round the back, also much thicker at the base than at the top. Obviously it's very risky to have a <a href="https://historicengland.org.uk/listing/the-list/list-entry/1018885?section=comments-and-photos" target="_blank">scheduled ancient monument</a> in a car park so protective concrete blocks have been added to make sure nobody reverses into the stonework by mistake. More recently a glass screen has been added at one end, branded 'City of London' so you know who to thank, but the other end remains accessible for now (not that you should be stepping in or even touching it).
</p><p>
<a href="https://www.flickr.com/photos/dgeezer/54916349423" target="_blank"><img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj0X3EucV9TL89yW51xa9ys4JupOSlmswxcSVXevlp0nvAfy4oNu5VmgJIJvtdYuofmNNe73kXxYZOgaLKRLwPCt83_z_sr2Ax9JFA8j3qOfWYCLI7mrNJP71UpsjNBqCcZ4AqCUCcb6GcBjR0zOGs6jac3ni5HmwqvQbk50yec9y1kD9bjZ9RoiA/s1600/carpak.jpg" title="London Wall car park" data-original-height="375" data-original-width="500"></a></p><p>
It's the contrasts that I found most incongruous. A relic from Roman times penned inbetween a speed hump and a futile pedestrian crossing. A fortification from the 3rd century beside an electric van built last year. A defensive structure that helped see off the Peasants Revolt beside a poster warning what to do in the event of fire. A boundary wall once an intrinsic part of the capital now underground illuminated by strip lights. And all this at the very far end of an oppressive bunker preserved for the benefit of hardly any eyes in a parking facility only a few know to use. Sure you can see chunks of Roman wall all around the City, even from a tube platform, hotel terrace or cafe. But the oddest spot may well be here in the London Wall car park, should you ever have the balls to take a look.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I didn't reverse-engineer the protocol for my blood pressure monitor in 24 hours (189 pts)]]></title>
            <link>https://james.belchamber.com/articles/blood-pressure-monitor-reverse-engineering/</link>
            <guid>45893095</guid>
            <pubDate>Tue, 11 Nov 2025 21:25:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://james.belchamber.com/articles/blood-pressure-monitor-reverse-engineering/">https://james.belchamber.com/articles/blood-pressure-monitor-reverse-engineering/</a>, See on <a href="https://news.ycombinator.com/item?id=45893095">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                
                <p>Yesterday after receiving my yearly flu vaccine at the pharmacy I was offered a blood pressure test, which reported a reading that made the young pharmacist who had just given me my vaccine a bit worried.</p>
<p>Off the back of this she offered me a 24 hour study, and then strapped a cuff to my arm plumbed into a little device which I had to wear in a little caddy - the cuff would inflate every 30 minutes during the day and every 60 minutes during the night, and then tomorrow I would bring it back for analysis.</p>
<p>"Can I read the measurements?" I asked, as it was being strapped to me.</p>
<p>"Oh, no, that will just stress you out. We turn that off". Fair enough.</p>
<p>Thing is, this device had a little micro-USB port on the side.</p>
<p><img src="https://james.belchamber.com/articles/blood-pressure-monitor-reverse-engineering/images/revealing-the-port.jpg" alt="A blood pressure monitor with a flap being held back, revealing a micro-USB port"></p><p>A blood pressure monitor with a flap being held back, revealing a micro-USB port</p>
<h2>Doing things the proper way</h2>
<p>I had started researching the device - a <a href="https://www.microlife.com/professional-products/watchbp-o3/watchbp-o3-ambulatory-2g">Microlife WatchBP O3</a> - before I got out of the chemist, and once I'd got back to the office I downloaded <a href="https://www.microlife.com/support/ambulatory-support">the software</a> that's freely available to interact with it, setting up a Bottles instance to run the software since I don't (knowingly) have a Windows machine within 100 metres of me.</p>
<p><img src="https://james.belchamber.com/articles/blood-pressure-monitor-reverse-engineering/images/installing-watchbp-analyzer-in-bottles.png" alt="Installing WatchBP Analyzer in Bottles"></p><p>Installing WatchBP Analyzer in Bottles</p>
<p>Unfortunately it didn't seem to be able to access the device, and I had no clue why. In Linux it was just presenting as a standard <code>hidraw</code> device:</p>
<pre><code>[33301.736724] hid-generic 0003:04D9:B554.001E: hiddev96,hidraw1: USB HID v1.11 Device [USB HID UART Bridge] on usb-0000:c5:00.0-1/input0
</code></pre>
<p><em>Fine</em>, I'll install windows.</p>
<p><img src="https://james.belchamber.com/articles/blood-pressure-monitor-reverse-engineering/images/send-diagnostic-data-to-microsoft.png" alt="Microsoft wants my diagnostic data"></p><p>Microsoft wants my diagnostic data</p>
<p>After dodging around Microsoft's idea of UX, and then forwarding the USB device to the VM (I used <a href="https://apps.gnome.org/en-GB/Boxes/">Gnome Boxes</a> for this, works nicely), I finally got to see WatchBP Analyzer with the data downloaded from the device.</p>
<p><img src="https://james.belchamber.com/articles/blood-pressure-monitor-reverse-engineering/images/watchbp-analyzer.png" alt="WatchBP Analyzer with my first three measurements"></p><p>WatchBP Analyzer with my first three measurements</p>
<p>But I don't want to open a Virtual Machine running Windows to see this data, and anyway - I'm pretty sure that reverse-engineering this will be good for my blood pressure.</p>
<h2>Sniffing the traffic</h2>
<p>Since I'm running this in a Virtual Machine I can just rely on Wireshark in Linux to get the traffic between the host and the device. <code>usbmon</code> is already installed and we know that the device is on Bus 3, so we can select usbmon3 on startup and start capturing.</p>
<p><img src="https://james.belchamber.com/articles/blood-pressure-monitor-reverse-engineering/images/wireshark-initial.png" alt="Wireshark with the initial capture"></p><p>Wireshark with the initial capture</p>
<p>I'm very much out of my depth at this point but, being <a href="https://www.sciencefocus.com/science/could-i-land-a-plane-in-an-emergency">one of those who could land a plane in an emergency</a> (why would you talk yourself out of it?!) I decided to crack on regardless. I know that the interesting stuff is sent after I press "Download", and I know that <em>something</em> in there is gonna say <em>"my blood pressure is 137/113"</em> - so let's look for that. Just convert to show bytes as decimal and..</p>
<p><img src="https://james.belchamber.com/articles/blood-pressure-monitor-reverse-engineering/images/hex-blood-pressure.png" alt="My blood pressure seems to be encoded in this packet"></p><p>My blood pressure seems to be encoded in this packet</p>
<p>..that looks like a blood pressure! Let's copy that out as hex:</p>
<pre><code>05 0a 89 71 43 9b
</code></pre>
<p>I'm not sure if this is "valid" HID Data (Wireshark seems convinced that only the first byte is the Vendor Data, with the rest being padding) but it seems like the data is being sent in 32-byte "chunks", of which the first byte tells you the number of significant (SIG) following bits in the chunk (I deleted the rest - all zeroes - for clarity). The third byte is my <em>Systolic</em> blood Pressure (SYS), the fourth is my <em>Diastolic</em> blood pressure (DIA), and the fifth is my heart rate (HR) - no clue what the second or last byte is, but let's find all other bytes with my blood pressure in them (in decimal this time, because I can't read hex without help):</p>
<pre><code>SIG ??? SYS DIA  HR ??? ??? ???
  5  10 137 113  67 155
  5   0 132  86  68 155
  6   0 126  84  82 155  83
  6  10 128  80  61 155  83
  7   0 148  93  65 155  83  64
  7   0 121  92  74 155  83  94
  7   0 123  83  65 155  83  95
  7   0 123  79  78 155  83 129
</code></pre>
<p>Hmm. So we're still looking for the Oscillometric signal peak pressure (OPP)as well as some timestamps (we can calculate Mean arterial pressure - MAP - as <code>(2*DIA+SYS)/3</code>, according to <a href="https://www.microlife.com/support/software-professional-products/watchbp-analyzer-support">the manual</a>, and Pulse Pressure (PP) is just <code>SYS-DIA</code>). We can see the OPP in the packets that come after each of those above, but they don't seem to consistently come in on the same line:</p>
<pre><code> 10  82  195   80 *121    0    0    0    0    0    0
 10  82  223   80  *95    0    0    0    0    0    0
  9   1   80  *90    0    0    0    0    0    0
  9  35   80  *86    0    0    0    0    0    0
  8  80 *103    0    0    0    0    0    0
  8  80 *106    0    0    0    0    0    0
  8  80  *90    0    0    0    0    0    0
 10  80  *88    0    0    0    0    0    0   29  251
</code></pre>
<p>Oh. Maybe if I stick them together?</p>
<pre><code>??? SYS DIA  HR ??? ??? ??? ??? OPP ??? ??? ??? ??? ??? ??? ??? ???
 10 137 113  67 155  82 195  80 121   0   0   0   0   0   0
  0 132  86  68 155  82 223  80  95   0   0   0   0   0   0
  0 126  84  82 155  83   1  80  90   0   0   0   0   0   0
 10 128  80  61 155  83  35  80  86   0   0   0   0   0   0
  0 148  93  65 155  83  64  80 103   0   0   0   0   0   0
  0 121  92  74 155  83  94  80 106   0   0   0   0   0   0
  0 123  83  65 155  83  95  80  90   0   0   0   0   0   0
  0 123  79  78 155  83 129  80  88   0   0   0   0   0   0  29 251
</code></pre>
<p>Right, timestamps. I first guessed that the four populated contiguous bytes between <code>HR</code> and <code>OPP</code> are a 32-bit unix timestamp, but that would make the first one <code>9B52C350</code>; either <code>Jul 29 2052</code> or <code>Dec 08 2012</code> depending on which endianness the protocol is into. The 8 readings we have here are all from <code>November 10th</code>, at <code>11:03</code>, <code>11:31</code>, <code>12:01</code>, <code>12:35</code>, <code>13:00</code>, <code>13:30</code>, <code>13:31</code> and <code>14:01</code>, which isn't.. isn't that.</p>
<p>But note that the number in the 6th column flips from <code>82</code> to <code>83</code> when we switch from AM to PM - that's something, and when it does the 7th column resets. And hey - <code>1</code>, <code>35</code>, <code>64</code>, <code>94</code>, <code>95</code>.. that seems dangerously close to <code>12:01</code>, <code>12:35</code>, <code>13:00</code>, <code>13:30</code> and <code>13:31</code> if you were just to count the minutes. What's going on?</p>
<h2>Deadlines and dead ends</h2>
<p>I tried feeding a lot of this into various Als (Kagi gives you access to a few with a nice interface) and I found that they mostly were stupid in ways that made me think. A few times I thought they had <em>"cracked the case"</em> but actually they just made me waste time. But they did remind me e.g. of endianness, so I did get a bit out of them.</p>
<p><img src="https://james.belchamber.com/articles/blood-pressure-monitor-reverse-engineering/images/hex-is-hard-for-llms.png" alt="Kimi K2 demonstrating creativity with numbers"></p>
<p>I also spent quite a bit of time trying to write some Python that emulated the initial handshake and download button of the interface so that it could push out the data as a stream instead of me having to wrestle it out of Wireshark - again, Al had a habit of giving me incorrect code (although it did turn me on to <a href="https://pypi.org/project/hid/">pyhidapi</a>).</p>
<p>But ultimately I had a deadline, and I had to return the device even though I wanted to spend more time with it. Possibly for the best - while it did give me some reverse engineering practice (which it turns out I really enjoy), I should do some work instead of procrastinating.</p>
<p>My final lesson was a new word - <em>Normotension</em>, normal blood pressure - and a new phrase - <em>White Coat Hypertension</em>, the phenomena of high blood pressure in a clinical setting. Turns out that when you check someone's blood pressure after giving them an injection, it's higher than normal.</p>
<p>I don't think I'd recommend getting your blood pressure tested after your next flu jab. But then, I'm not a doctor.</p>

                <br>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[X5.1 solar flare, G4 geomagnetic storm watch (288 pts)]]></title>
            <link>https://www.spaceweatherlive.com/en/news/view/593/20251111-x5-1-solar-flare-g4-geomagnetic-storm-watch.html</link>
            <guid>45893004</guid>
            <pubDate>Tue, 11 Nov 2025 21:18:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.spaceweatherlive.com/en/news/view/593/20251111-x5-1-solar-flare-g4-geomagnetic-storm-watch.html">https://www.spaceweatherlive.com/en/news/view/593/20251111-x5-1-solar-flare-g4-geomagnetic-storm-watch.html</a>, See on <a href="https://news.ycombinator.com/item?id=45893004">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="SWL_Page">
                    <div>
                        
                        
<h3>X5.1 solar flare, G4 geomagnetic storm watch</h3><p>Tuesday, 11 November 2025 19:07 UTC</p><p><img src="https://www.spaceweatherlive.com/images/news/593-header.jpg" loading="lazy" alt="X5.1 solar flare, G4 geomagnetic storm watch" width="900" height="450"></p><p>Here she blows! Sunspot region 4274 produced its strongest solar flare thus far since it appeared on the east limb and the sixth strongest solar flare of the current solar cycle. An impressive long duration and highly eruptive X5.1 (R3-strong) solar flare peaked this morning at 10:04 UTC.</p><p>It became quickly clear that the eruption would be followed by an impressive coronal mass ejection (CME). The resulting coronal wave following the solar explosion as well as the coronal dimming observed as the CME was propelled into space were of a spectacular magnitude as can be seen in the animation below provided by <a href="https://x.com/halocme" target="_blank" rel="noopener">halocme</a>.</p><blockquote data-media-max-width="560"><p dir="ltr" lang="en">Another eruption from AR12474, associated with an X5.1 flare. It has become a full halo CME. I am truly impressed by how fast and global this coronal wave is. The CME will arrive on November 13, but because of earlier CMEs it will be challenging to isolate the ICME from this. <a href="https://t.co/H6eNjzQUGz">pic.twitter.com/H6eNjzQUGz</a></p>‚Äî Halo CME (@halocme) <a href="https://twitter.com/halocme/status/1988253760179548649?ref_src=twsrc%5Etfw">November 11, 2025</a></blockquote><p>Taking a look at coronagraph imagery provided by GOES-19 CCOR-1 we see the gorgeous fast halo coronal mass ejection as it propagates away from the Sun. It doesn't take a rocket scientist to come to the conclusion that this plasma cloud of course has an earth-directed component and it is pretty clear that this will be a strong impact when it arrives at our planet. This rightfully so prompted the NOAA SWPC to issue a G4 or greater geomagnetic storm watch for tomorrow as the cloud could impact our planet as early as 16 UTC on 12 November. Not only is the CME fast but it will also travel trough an area with high ambient solar wind speed and low density thanks to two other CMEs released earlier by this region. More about that below.</p><figure><img src="https://www.spaceweatherlive.com/images/news/2025/593-cme.gif"><figcaption>Coronal mass ejection launched during today's X5.1 solar flare as captured by the coronagraph from GOES-19.</figcaption></figure><p>If the solar wind and interplanetary magnetic field values at Earth are favorable this could result in a geomagnetic storm which is strong enough for aurora to become visible from locations as far south as northern France, Germany, Ukraine, Switzerland and Austria. In the US it could become visible as far south as Nevada and Arkansas. No guarantees of course, this is space weather we are talking about but be sure to download the SpaceWeatherLive app to your mobile device, turn on the alerts and keep an eye on the solar wind data from ACE and DSCOVR!</p><p>We also want to remind you that we still have two coronal mass ejections on their way to Earth. These are not as impressive as this X5.1 CME but these two plasma clouds will likely arrive within the next 6 to 18 hours. This is a tricky one as they could arrive as one impact or two impacts close intill each other. More information in <a href="https://www.spaceweatherlive.com/en/news/view/592/20251110-x1-2-solar-flare-with-earth-directed-cme.html" target="_blank" rel="noopener">yesterday's news</a>.</p><div> <p><em>Thank you for reading this article! Did you have any trouble with the technical terms used in this article? Our help section is the place to be where you can find in-depth <a href="https://www.spaceweatherlive.com/en/help.html">articles</a>, a <a href="https://www.spaceweatherlive.com/en/faq.html">FAQ</a> and a list with common <a href="https://www.spaceweatherlive.com/en/acronyms-and-abbreviations.html">abbreviations</a>. Still puzzled? Just post on our <a href="https://community.spaceweatherlive.com/">forum</a> where we will help you the best we can! <span> Never want to miss out on a space weather event or one of our news articles again? Subscribe to our <a href="https://www.spaceweatherlive.com/en/mailinglist.html">mailing list</a>, follow us on <a href="https://twitter.com/_SpaceWeather_">Twitter</a> and <a href="https://www.facebook.com/SpaceWeatherLive/">Facebook</a> and download the SpaceWeatherLive app for <a href="https://play.google.com/store/apps/details?id=com.spaceweatherlive.app">Android</a> and <a href="https://itunes.apple.com/us/app/spaceweatherlive/id1435501021?mt=8">iOS</a>! </span> </em> </p></div>
                        
                    </div>
                                            <div>
                                                          <div>  <p>A lot of people come to SpaceWeatherLive to follow the Solar activity or if there is a chance to see the aurora, but with more traffic comes higher costs to keep the servers online. If you like SpaceWeatherLive and want to support the project you can choose a subscription for an ad-free site or consider a donation. With your help we can keep SpaceWeatherLive online!</p>  <p><a href="https://shop.spaceweatherlive.com/" target="_blank"><img src="https://www.spaceweatherlive.com/images/SWL_Shop.png" alt="Support SpaceWeatherLive with our merchandise" width="600" height="200"></a> </p> <p><a href="https://shop.spaceweatherlive.com/" target="_blank"> <b>Check out our merchandise</b></a></p></div><div><table><thead><tr><th colspan="2">Spotless days</th></tr></thead><tbody><tr><td>Last spotless day</td><td>2022/06/08</td></tr></tbody></table><table><thead><tr><th colspan="2">Monthly mean Sunspot Number</th></tr></thead><tbody><tr><td>October 2025</td><td>114.6 <span> -15.2</span></td></tr><tr><td>November 2025</td><td>91.9 <span> -22.7</span></td></tr><tr><td>Last 30 days</td><td>96.2 <span> -34.6</span></td></tr></tbody></table><h4>This day in history*</h4><div><table><thead><tr><th></th><th></th><th>Dst</th><th>G</th></tr></thead><tbody><tr><td>1</td><td><a href="https://www.spaceweatherlive.com/en/archive/2004/11/11.html">2004</a></td><td>-106</td><td><span>G1</span></td></tr><tr><td>2</td><td>1981</td><td>-78</td><td><span>G2</span></td></tr><tr><td>3</td><td>1974</td><td>-72</td><td><span>G3</span></td></tr><tr><td>4</td><td><a href="https://www.spaceweatherlive.com/en/archive/2013/11/11.html">2013</a></td><td>-68</td><td><span>G1</span></td></tr><tr><td>5</td><td>1991</td><td>-64</td><td><span>G1</span></td></tr></tbody></table><p>*since 1994</p></div></div>                           </div>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Collaboration sucks (375 pts)]]></title>
            <link>https://newsletter.posthog.com/p/collaboration-sucks</link>
            <guid>45892394</guid>
            <pubDate>Tue, 11 Nov 2025 20:27:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newsletter.posthog.com/p/collaboration-sucks">https://newsletter.posthog.com/p/collaboration-sucks</a>, See on <a href="https://news.ycombinator.com/item?id=45892394">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!2y1b!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!2y1b!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg 424w, https://substackcdn.com/image/fetch/$s_!2y1b!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg 848w, https://substackcdn.com/image/fetch/$s_!2y1b!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!2y1b!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!2y1b!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg" width="1456" height="1048" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1048,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:801531,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://newsletter.posthog.com/i/178280989?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!2y1b!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg 424w, https://substackcdn.com/image/fetch/$s_!2y1b!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg 848w, https://substackcdn.com/image/fetch/$s_!2y1b!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!2y1b!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff09f674-3296-47aa-9ee4-d25de75728fa_1456x1048.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>‚ÄúIf you want to go fast, go alone; if you want to go far, go together‚Äù</p><p>This phrase will slowly kill your company and I‚Äôm here to prove it.</p><p>Imagine you are driving a car. It‚Äôs often useful to have someone give you directions, point out gas stations, and recommend stops for snacks. This is a helpful amount of collaboration.</p><p>An unhelpful amount of collaboration is getting out of your car to ask pedestrians if they like your car, swapping drivers every 10 minutes, or having someone constantly commenting on your driving.</p><p>In the first scenario, you get the right amount of feedback to get to your destination as fast as possible. In the second, you get more feedback, but it slows you down. You run the risk of not making it to the place you want to go.</p><p>The second scenario is also the one most startups (or companies, really) end up in because of ‚ú® collaboration ‚ú®.</p><p>As PostHog grows, I‚Äôve seen more and more collaboration that doesn‚Äôt add value or adds far too little value for the time lost collaborating. So much so we made ‚Äúcollaboration sucks‚Äù the topic of the week during a recent company all hands.</p><p><span>‚ÄúYou‚Äôre the driver‚Äù is a </span><a href="https://posthog.com/handbook/values?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">key value</a><span> for us at PostHog. We aim to hire people who are great at their jobs and get out of their way. No deadlines, minimal coordination, and no managers telling you what to do.</span></p><p><span>In return, we ask for extraordinarily high ownership and the ability to get a lot done by </span><em>yourself.</em><span> Marketers ship code, salespeople answer technical questions without backup, and </span><a href="https://posthog.com/blog/what-is-a-product-engineer?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">product engineers</a><span> work across the stack.</span></p><p>This means there is almost always someone better at what you are doing than you are. It is tempting to get them, or anybody really, involved and ‚ú® collaborate ‚ú®, but collaboration forces the driver to slow down and explain stuff (background, context, their thinking).</p><p>This tendency reveals itself in a few key phrases:</p><ul><li><p>‚ÄúCurious what X thinks‚Äù</p></li><li><p>‚ÄúWould love to hear Y‚Äôs take on this‚Äù</p></li><li><p>‚ÄúWe should work with Z on this‚Äù</p></li></ul><p><span>This </span><em>sometimes</em><span> leads to valuable insights, but </span><em>always</em><span> slows the driver down. It erodes their motivation, confidence, and effectiveness, and ultimately leads us to ship less.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!MoTP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!MoTP!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png 424w, https://substackcdn.com/image/fetch/$s_!MoTP!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png 848w, https://substackcdn.com/image/fetch/$s_!MoTP!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png 1272w, https://substackcdn.com/image/fetch/$s_!MoTP!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!MoTP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png" width="714" height="328.5576923076923" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;normal&quot;,&quot;height&quot;:670,&quot;width&quot;:1456,&quot;resizeWidth&quot;:714,&quot;bytes&quot;:463445,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://newsletter.posthog.com/i/178280989?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:&quot;center&quot;,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!MoTP!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png 424w, https://substackcdn.com/image/fetch/$s_!MoTP!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png 848w, https://substackcdn.com/image/fetch/$s_!MoTP!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png 1272w, https://substackcdn.com/image/fetch/$s_!MoTP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cb9ef7c-6958-481c-8a93-209cafc1912f_2044x940.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Everyone is to blame.</p><ul><li><p><span>People want to be helpful. For example, when someone posts their work-in-progress in Slack, others feel obliged to give feedback because we have a </span><a href="https://posthog.com/handbook/people/feedback?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">culture of feedback</a><span>.</span></p></li><li><p>On the flip side, people don‚Äôt ask for feedback from specific people because it doesn‚Äôt feel inclusive, even though it would help.</p></li><li><p>People aren‚Äôt specific enough about what feedback they need. This creates more space for collaboration to sneak in. A discussion about building a specific feature can devolve into reevaluating the entire product roadmap if you let it.</p></li><li><p>When someone has a good idea, the response often defaults to ‚Äúlet‚Äôs discuss‚Äù rather than ‚Äúok, do it.‚Äù As proof, we have 175 mentions of ‚Äúlet‚Äôs discuss‚Äù in Slack.</p></li><li><p><span>People just want to talk about stuff because they </span><s>are too busy</s><span> can‚Äôt be bothered to act on it. We drift from our ideal of a pull request to an issue/RFC to Slack (we are mostly here) to ‚Äúlet‚Äôs discuss‚Äù.</span></p></li><li><p>It‚Äôs not clear who the owner is (or no one wants to own what‚Äôs being discussed).</p></li><li><p>It is annoying, but sometimes a single person can‚Äôt ship certain things front to back to a high-enough quality and we can‚Äôt just ship and iterate. We can fix broken code, but we can‚Äôt resend a newsletter.</p></li></ul><p>So if collaboration is your enemy, how do you defeat it? Here‚Äôs what we say:</p><ul><li><p>Default to shipping. Pull requests &gt; issues &gt; Slack messages.</p></li><li><p>Every time you see ‚ú® collaboration ‚ú® happening, speak up and destroy it. Say ‚Äúthere are too many people involved. X, you are the driver, you decide.‚Äù (This is a great way to make friends btw).</p></li></ul><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!CtaP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!CtaP!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg 424w, https://substackcdn.com/image/fetch/$s_!CtaP!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg 848w, https://substackcdn.com/image/fetch/$s_!CtaP!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!CtaP!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!CtaP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg" width="1456" height="870" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:870,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;How to make friends and crush collaboration&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="How to make friends and crush collaboration" title="How to make friends and crush collaboration" srcset="https://substackcdn.com/image/fetch/$s_!CtaP!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg 424w, https://substackcdn.com/image/fetch/$s_!CtaP!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg 848w, https://substackcdn.com/image/fetch/$s_!CtaP!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!CtaP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd08aa557-77bd-4521-8e30-ab03faf7c7db_1600x956.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Graphic design is my passion</figcaption></figure></div><ul><li><p>Tag who you specifically want input from and what you want from them, not just throw things out there into the void.</p></li><li><p>Prefer to give feedback after something has shipped (but before the next iteration) rather than reviewing it before it ships. Front-loading your feedback can turn it into a quasi-approval process.</p></li><li><p><span>If you are a team lead, or leader of leads, who has been asked for feedback, consider being more </span><a href="https://www.youtube.com/shorts/DjvVN4Vp_r0" rel="">you can just do stuff</a><span>.</span></p></li><li><p>When it‚Äôs your thing, you are the ‚Äúinformed captain.‚Äù Listen to feedback, but know it‚Äôs ultimately up to you to decide what to do, not the people giving feedback.</p></li></ul><p><span>Unfortunately for me, not all collaboration can be rooted out, and even I will admit that some collaboration is useful. </span><a href="https://www.linkedin.com/in/ianvanagas/" rel="">Ian</a><span> and </span><a href="https://www.linkedin.com/in/andyvandervell/" rel="">Andy</a><span> edited this newsletter after all. </span></p><p><span>The point is, if you aren‚Äôt actively attempting to collaborate less, you are probably collaborating too much by default and hurting your ability to go far, fast.</span><em><p><span>Words by </span><a href="https://www.linkedin.com/in/wololo/" rel="">Charles Cook</a><span>, who also hates sparkling water, presumably because the bubbles are too collaborative.</span></p></em></p><ul><li><p><strong><a href="https://posthog.com/careers/ai-product-engineer?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">AI Product Engineer</a></strong><span> working on PostHog AI, LLM Analytics or Array teams.</span></p></li><li><p><span>Backend Engineer for </span><strong><a href="https://posthog.com/careers/backend-engineer-feature-flags?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">Feature Flags</a></strong><span> and </span><strong><a href="https://posthog.com/careers/backend-engineer-ingestion?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">Ingestion</a></strong><span> teams</span></p></li><li><p><strong><a href="https://posthog.com/careers/influencer-wrangler?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">Influencer Wrangler</a></strong><span> on the Marketing team</span></p></li><li><p><strong><a href="https://posthog.com/careers/yc-technical-onboarding-specialist-onsite?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">YC Technical Onboarding Specialist </a></strong><span>on the Onboarding team (San Fran based)</span></p></li><li><p><strong><a href="https://posthog.com/careers/clickhouse-operations-engineer?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">ClickHouse Operations Engineer</a></strong><span> on the ClickHouse team</span></p></li></ul><ul><li><p><strong><a href="https://posthog.com/blog/workflows-alpha?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">Workflows are now in Alpha and I already broke mine</a><span> ‚Äì Sara Miteva</span></strong></p></li><li><p><strong><a href="https://notes.mtb.xyz/p/your-data-model-is-your-destiny?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">Your data model is your destiny</a><span> ‚Äì&nbsp;Matt Brown</span></strong></p></li><li><p><strong><a href="https://www.dylanamartin.com/2025/11/07/spinning-plates.html?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">Spinning Plates</a><span> ‚Äì Dylan Martin</span></strong></p></li><li><p><strong><a href="https://www.youtube.com/watch?v=yKgfk8lTQuE?utm_source=posthog-newsletter&amp;utm_medium=post&amp;utm_campaign=collaboration-sucks" rel="">1000x: The Power of an Interface for Performance</a><span> (video) ‚Äì Joran Dirk Greef</span></strong></p></li></ul><div id="youtube2-bs_v-xY7Nqw" data-attrs="{&quot;videoId&quot;:&quot;bs_v-xY7Nqw&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/bs_v-xY7Nqw?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microplastics: No longer a "maybe" (108 pts)]]></title>
            <link>https://ibbi.io/mp</link>
            <guid>45892340</guid>
            <pubDate>Tue, 11 Nov 2025 20:24:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ibbi.io/mp">https://ibbi.io/mp</a>, See on <a href="https://news.ycombinator.com/item?id=45892340">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      <p><strong>It‚Äôs Already Inside Us</strong><br>
      Microplastics are not just an environmental problem affecting nature.
      They‚Äôre in our blood
      <a href="https://pubmed.ncbi.nlm.nih.gov/35367073/" target="_blank">[1]</a>, lungs
      <a href="https://pubmed.ncbi.nlm.nih.gov/35364151/" target="_blank">[2]</a>, placentas
      <a href="https://pubmed.ncbi.nlm.nih.gov/33395930/" target="_blank">[3]</a>, brains
      <a href="https://pubmed.ncbi.nlm.nih.gov/38765967/" target="_blank">[4]</a>, and breast milk
      <a href="https://www.mdpi.com/2073-4360/14/13/2700" target="_blank">[5]</a>. Every human tissue scientists have tested so far has come back
      contaminated. In diseased tissue samples of people with chronic illnesses
      (IBD
      <a href="https://pubmed.ncbi.nlm.nih.gov/34935363/" target="_blank">[6]</a>, Dementia
      <a href="https://pubmed.ncbi.nlm.nih.gov/39901044/" target="_blank">[7]</a>, heart disease
      <a href="https://pubmed.ncbi.nlm.nih.gov/38446676/" target="_blank">[8]</a>), microplastic prevalence is significantly higher than healthy tissue.
      </p><p>
      <strong>The Trajectory Is Clear</strong><br>
      Every new study finds higher microplastic concentrations in human tissue
      than the last. Most recently, we found a 50% increase in brain tissue
      microplastic prevalence over the past 8 years
      <a href="https://pubmed.ncbi.nlm.nih.gov/39901044/" target="_blank">[9]</a>. The burden on the human body is compounding: what we take in today
      stays with us for decades, and future generations are born contaminated.
      That‚Äôs not even mentioning nanoplastics, which we weren‚Äôt able to detect
      until 10 years ago
      <a href="https://pubmed.ncbi.nlm.nih.gov/38765967/" target="_blank">[10]</a>. </p><p>
      <strong>What the Mice Tell Us</strong><br>
      Mice exposed to higher doses of microplastics develop gut inflammation
      <a href="https://pubmed.ncbi.nlm.nih.gov/39265698/" target="_blank">[11]</a>, hormone disruption
      <a href="https://particleandfibretoxicology.biomedcentral.com/articles/10.1186/s12989-022-00453-2" target="_blank">[12]</a>, infertility
      <a href="https://pubmed.ncbi.nlm.nih.gov/36493639" target="_blank">[13]</a>, developmental delays
      <a href="https://www.frontiersin.org/journals/physiology/articles/10.3389/fphys.2023.1254886/full" target="_blank">[14]</a>, and organ damage
      <a href="https://www.sciencedirect.com/science/article/abs/pii/S0048969720366158" target="_blank">[15]</a>. The doses they are tested with are higher than ours‚Ä¶ <em>for now</em>.
      But the global plastic load is increasing exponentially, and the gap is
      closing. </p><p>
      <strong>Humans Can‚Äôt Afford 1% of That</strong><br>
      Even a fraction of the effects we induce in mice appearing in people is a
      global health crisis. That‚Äôs not hypothetical; our tolerance for risk is
      far lower than a lab rat. Mice don‚Äôt need to perform demanding physical
      and cognitive tasks 40 hours a week to survive. The accumulation math is
      also worse: mice don‚Äôt live 80 years, don‚Äôt have pregnancies lasting nine
      months, and don‚Äôt accumulate microplastics for decades. We do.
      </p><p>
      Waiting for government intervention before acting is the same mistake we
      made with lead, asbestos, and PFAS. Let‚Äôs not do that again.
    </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The terminal of the future (176 pts)]]></title>
            <link>https://jyn.dev/the-terminal-of-the-future</link>
            <guid>45892191</guid>
            <pubDate>Tue, 11 Nov 2025 20:11:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jyn.dev/the-terminal-of-the-future">https://jyn.dev/the-terminal-of-the-future</a>, See on <a href="https://news.ycombinator.com/item?id=45892191">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <blockquote>
<p>Terminal internals are a mess. A lot of it is just the way it is because someone made a decision in the 80s and now it‚Äôs impossible to change.
‚Äî<a href="https://jvns.ca/blog/2025/06/24/new-zine--the-secret-rules-of-the-terminal/">Julia Evans</a></p>
</blockquote>
<blockquote>
<p>This is what you have to do to redesign infrastructure. Rich [Hickey] didn't just pile some crap on top of Lisp [when building Clojure]. He took the entire Lisp and moved the whole design at once.
‚Äî<a href="https://www.destroyallsoftware.com/talks/a-whole-new-world">Gary Bernhardt</a></p>
</blockquote>
<h2 id="a-mental-model-of-a-terminal">a mental model of a terminal<a href="#a-mental-model-of-a-terminal" aria-label="Anchor link for: a-mental-model-of-a-terminal"></a>
</h2>
<p>At a very very high level, a terminal has four parts:</p>
<ol>
<li>The "<a href="https://wizardzines.com/comics/meet-the-terminal-emulator/">terminal emulator</a>", which is a program that renders a grid-like structure to your graphical display.</li>
<li>The "<a href="https://jvns.ca/blog/2022/07/20/pseudoterminals/">pseudo-terminal</a>" (PTY), which is a connection between the terminal emulator and a "process group" which receives input. This is not a program. This is a piece of state in the kernel.</li>
<li>The "shell", which is a program that leads the "process group", reads and parses input, spawns processes, and generally acts as an event loop. Most environments use <a href="https://jvns.ca/blog/2017/03/26/bash-quirks/">bash</a> as the default shell.</li>
<li>The programs spawned by your shell, which interact with all of the above in order to receive input and send output.</li>
</ol>
<p>I lied a little bit above. "input" is not just text. It also includes <a href="https://man7.org/linux/man-pages/man7/signal.7.html">signals</a> that can be sent to the running process. Converting keystrokes to signals is the job of the PTY.</p>
<p>Similar, "output" is not just text. It's a stream of <a href="https://gist.github.com/fnky/458719343aabd01cfb17a3a4f7296797">ANSI Escape Sequences</a> that can be used by the terminal emulator to display rich formatting.</p>
<h2 id="what-does-a-better-terminal-look-like">what does a better terminal look like?<a href="#what-does-a-better-terminal-look-like" aria-label="Anchor link for: what-does-a-better-terminal-look-like"></a>
</h2>
<p>I do some <a href="https://jyn.dev/how-i-use-my-terminal/">weird things</a> with terminals. However, the amount of hacks I can get up to are pretty limited, because terminals are pretty limited. I won't go into all the ways they're limited, because it's been rehashed <a href="https://matklad.github.io/2019/11/16/a-better-shell.html">many</a> <a href="https://github.com/withoutboats/notty">times</a> <a href="https://jvns.ca/blog/2025/02/05/some-terminal-frustrations/">before</a>. What I want to do instead is imagine what a better terminal can look like.</p>
<h3 id="a-first-try-jupyter">a first try: Jupyter<a href="#a-first-try-jupyter" aria-label="Anchor link for: a-first-try-jupyter"></a>
</h3>
<p>The closest thing to a terminal analog that most people are familiar with is <a href="https://docs.jupyter.org/en/latest/">Jupyter Notebook</a>. This offers a lot of cool features that are not possible in a "traditional" VT100 emulator:</p>
<ul>
<li>
<p>high fidelity image rendering</p>
<p><img src="https://jyn.dev/assets/jupyter%20bubble%20plot.png" alt="screenshot of a JupyterLite notebook. It has some python code in a cell that generates a matplotlib chart. Beneath is the chart, rendered to raster graphics."></p>
</li>
<li>
<p>a "rerun from start" button (or rerun the current command; or rerun only a single past command) that replaces past output instead of appending to it</p>
<p><img src="https://jyn.dev/assets/jupyter%20run%20cells.png" alt=""></p>
</li>
<li>
<p>"views" of source code and output that can be rewritten in place (e.g. markdown can be viewed either as source or as rendered HTML)</p>
<p><img src="https://jyn.dev/assets/jupyter%20markdown%20raw.png" alt=""> <img src="https://jyn.dev/assets/jupyter%20markdown%20rendered.png" alt=""></p>
</li>
<li>
<p>a built-in editor with syntax highlighting, tabs, panes, mouse support, etc.</p>
<p><img src="https://jyn.dev/assets/jupyter%20window%20management.png" alt=""></p>
</li>
</ul>
<h3 id="some-problems">some problems<a href="#some-problems" aria-label="Anchor link for: some-problems"></a>
</h3>
<p>Jupyter works by having a "kernel" (in this case, a python interpreter) and a "renderer" (in this case, a web application displayed by the browser). You could imagine using a Jupyter Notebook with a shell as the kernel, so that you get all the nice features of Jupyter when running shell commands. However, that quickly runs into some issues:</p>
<ul>
<li>Your shell gets the commands all at once, not character-by-character, so tab-complete, syntax highlighting, and autosuggestions don't work.</li>
<li>What do you do about long-lived processes? By default, Jupyter runs a cell until completion; you can cancel it, but you can't suspend, resume, interact with, nor view a process while it's running. Don't even think about running <code>vi</code> or <code>top</code>.</li>
<li>The "rerun cell" buttons do horrible things to the state of your computer (normal Jupyter kernels have this problem too, but "rerun all" works better when the commands don't usually include <code>rm -rf</code>).</li>
<li>Undo/redo do <em>not</em> work. (They don't work in a normal terminal either, but people attempt to use them more when it looks like they should be able to.)</li>
</ul>
<p>It turns out all these problems are solveable.</p>
<h2 id="how-does-that-work">how does that work?<a href="#how-does-that-work" aria-label="Anchor link for: how-does-that-work"></a>
</h2>
<h3 id="shell-integration">shell integration<a href="#shell-integration" aria-label="Anchor link for: shell-integration"></a>
</h3>
<p>There exists today a terminal called <a href="https://www.warp.dev/">Warp</a>. Warp has built native integration between the terminal and the shell, where the terminal understands where each command starts and stops, what it outputs, and what is your own input. As a result, it can render things very prettily:</p>
<p><img src="https://jyn.dev/assets/warp%20terminal.png" alt=""></p>
<p>It does this using (mostly) standard features built-in to the terminal and shell (a custom DCS): you can read their explanation <a href="https://www.warp.dev/blog/how-warp-works#:~:text=the%20reason">here</a>. It's possible to do this less invasively using <a href="https://iterm2.com/documentation-escape-codes.html#:~:text=shell%20integration/">OSC 133 escape codes</a>; I'm not sure why Warp didn't do this, but that's ok.</p>
<p>iTerm2 does a similar thing, and this allows it to enable <a href="https://iterm2.com/documentation-shell-integration.html#:~:text=enables%20numerous%20features">really quite a lot of features</a>: navigating between commands with a single hotkey; notifying you when a command finishes running, showing the current command as an "overlay" if the output goes off the screen.</p>
<h3 id="long-lived-processes">long-lived processes<a href="#long-lived-processes" aria-label="Anchor link for: long-lived-processes"></a>
</h3>
<p>This is really three different things. The first is <em>interacting</em> with a long-lived process. The second is <em>suspending</em> the process without killing it. The third is <em>disconnecting</em> from the process, in such a way that the process state is not disturbed and is still available if you want to reconnect.</p>
<h4 id="interacting">interacting<a href="#interacting" aria-label="Anchor link for: interacting"></a>
</h4>
<p>To interact with a process, you need bidirectional communication, i.e. you need a "cell output" that is also an input. An example would be any TUI, like <code>top</code>, <code>gdb</code>, or <code>vim</code> <sup id="fr-1-1"><a href="#fn-1">1</a></sup>.  Fortunately, Jupyter is really good at this!  The whole design is around having <a href="https://ipywidgets.readthedocs.io/en/latest/">interactive outputs</a> that you can change and update.</p>
<p>Additionally, I would expect my terminal to always have a "free input cell", as Matklad describes in <a href="https://matklad.github.io/2019/11/16/a-better-shell.html">A Better Shell</a>, where the interactive process runs in the top half of the window and an input cell is available in the bottom half. Jupyter can do this today, but "add a cell" is manual, not automatic.</p>
<h4 id="suspending">suspending<a href="#suspending" aria-label="Anchor link for: suspending"></a>
</h4>
<p>"Suspending" a process is usually called "<a href="https://jvns.ca/blog/2024/07/03/reasons-to-use-job-control/">job control</a>". There's not too much to talk about here, except that I would expect a "modern" terminal to show me all suspended and background processes as a de-emphasized persistent visual, kinda like how Intellij will show you "indexing ..." in the bottom taskbar.</p>
<p><img src="https://jyn.dev/assets/intellij%20background%20tasks.png" alt=""></p>
<h4 id="disconnecting">disconnecting<a href="#disconnecting" aria-label="Anchor link for: disconnecting"></a>
</h4>
<p>There are roughly three existing approaches for disconnecting and reconnecting to a terminal session (Well, four if you count <a href="https://github.com/nelhage/reptyr">reptyr</a>).</p>
<ol>
<li>
<p>Tmux / Zellij / Screen</p>
<p>These tools inject a whole extra terminal emulator between your terminal emulator and the program. They work by having a "server" which actually owns the PTY and renders the output, and a "client" that displays the output to your "real" terminal emulator. This model lets you detach clients, reattach them later, or even attach multiple clients at once. You can think of this as a "batteries-included" approach. It also has the benefit that you can <a href="https://jyn.dev/how-i-use-my-terminal/">program</a> both the client and the server (although many modern terminals, like <a href="https://sw.kovidgoyal.net/kitty/">Kitty</a> and <a href="https://wezfurlong.org/wezterm/">Wezterm</a> are programmable now); that you can organize your tabs and windows in the terminal (although many modern desktop environments have tiling and thorough keyboard shortcuts); and that you get street cred for looking like Hackerman.</p>
<p><img src="https://jyn.dev/assets/hackerman.png" alt=""></p>
<p>The downside is that, well, now you have an extra terminal emulator running in your terminal, with <a href="https://sw.kovidgoyal.net/kitty/faq/#i-am-using-tmux-zellij-and-have-a-problem">all the bugs that implies</a>.</p>
<p>iTerm actually avoids this by <a href="https://iterm2.com/documentation-tmux-integration.html">bypassing the tmux client altogether and acting as its own client</a> that talks directly to the server. In this mode, "tmux tabs" are actually iTerm tabs, "tmux panes" are iTerm panes, and so on. This is a good model, and I would adopt it when writing a future terminal for integration with existing tmux setups.</p>
</li>
<li>
<p><a href="https://mosh.org/">Mosh</a></p>
<p>Mosh is a really interesting place in the design space. It is not a terminal emulator replacement; instead it is an <em>ssh</em> replacement. Its big draw is that it supports reconnecting to your terminal session after a network interruption. It does that by <a href="https://mosh.org/#:~:text=how%20mosh%20works">running a state machine on the server and replaying an incremental diff of the viewport to the client</a>. This is a similar model to tmux, except that it doesn't support the "multiplexing" part (it expects your terminal emulator to handle that), nor scrollback (ditto). Because it has its own renderer, it has <a href="https://github.com/mobile-shell/mosh/issues/234">a similar class of bugs to tmux</a>. One feature it <em>does</em> have, unlike tmux, is that the "client" is really running on your side of the network, so local line editing is instant.</p>
</li>
<li>
<p><a href="https://ansuz.sooke.bc.ca/entry/389">alden</a>/<a href="https://github.com/shell-pool/shpool">shpool</a>/<a href="https://github.com/crigler/dtach">dtach</a>/<a href="https://github.com/martanne/abduco">abduco</a>/<a href="https://github.com/yazgoo/diss">diss</a></p>
<p>These all occupy a similar place in the design space: they <em>only</em> handle session detach/resume with a client/server, not networking or scrollback, and do not include their own terminal emulator. Compared to tmux and mosh, they are highly decoupled.</p>
</li>
</ol>
<h3 id="rerun-and-undo-redo">rerun and undo/redo<a href="#rerun-and-undo-redo" aria-label="Anchor link for: rerun-and-undo-redo"></a>
</h3>
<p>I'm going to treat these together because the solution is the same: dataflow tracking.</p>
<p>Take as an example <a href="https://plutojl.org/">pluto.jl</a>, which does this <em>today</em> by hooking into the Julia compiler.</p>
<p><img src="https://jyn.dev/assets/pluto%20interactive%20ode.gif" alt=""></p>
<p>Note that this updates cells live in response to previous cells that they depend on. Not pictured is that it <em>doesn't</em> update cells if their dependencies haven't changed. You can think of this as a spreadsheet-like Jupyter, where code is only rerun when necessary.</p>
<p>You may say this is hard to generalize. The trick here is <a href="https://jyn.dev/complected-and-orthogonal-persistence/#how-far-can-we-take-this">orthogonal persistence</a>. If you sandbox the processes, track all IO, and prevent things that are "too weird" unless they're talking to other processes in the sandbox (e.g. unix sockets and POST requests), you have really quite a lot of control over the process! This lets you treat it as a pure function of its inputs, where its inputs are "the whole file system, all environment variables, and all process attributes".</p>
<h3 id="derived-features">derived features<a href="#derived-features" aria-label="Anchor link for: derived-features"></a>
</h3>
<p>Once you have these primitives‚ÄîJupyter notebook frontends, undo/redo, automatic rerun, persistence, and shell integration‚Äîyou can build really quite a lot on top. And you can build it incrementally, piece-by-piece:</p>
<h4 id="needs-a-jupyter-notebook-frontend">needs a Jupyter notebook frontend<a href="#needs-a-jupyter-notebook-frontend" aria-label="Anchor link for: needs-a-jupyter-notebook-frontend"></a>
</h4>
<ul>
<li><a href="https://blog.atuin.sh/atuin-desktop-runbooks-that-run/">Runbooks</a> (actually, you can build these just with Jupyter and a PTY primitive).</li>
<li>Terminal customization that uses normal CSS, no weird custom languages or ANSI color codes.</li>
<li>Search for commands by output/timestamp. Currently, you can search across output in the current session, or you can search across all command input history, but you don't have any kind of smart filters, and the output doesn't persist across sessions.</li>
</ul>
<h4 id="needs-shell-integration">needs shell integration<a href="#needs-shell-integration" aria-label="Anchor link for: needs-shell-integration"></a>
</h4>
<ul>
<li>Timestamps and execution duration for each command.</li>
<li>Local line-editing, even across a network boundary.</li>
<li><a href="https://docs.warp.dev/terminal/command-completions/completions">IntelliSense for shell commands</a>, without having to hit tab and with rendering that's integrated into the terminal.</li>
</ul>
<h4 id="needs-sandboxed-tracing">needs sandboxed tracing<a href="#needs-sandboxed-tracing" aria-label="Anchor link for: needs-sandboxed-tracing"></a>
</h4>
<ul>
<li>"<a href="https://jyn.dev/complected-and-orthogonal-persistence/#but-why">All the features from sandboxed tracing</a>": collaborative terminals, querying files modified by a command, "asciinema but you can edit it at runtime", tracing build systems.</li>
<li>Extend the smart search above to also search by disk state at the time the command was run.</li>
<li>Extending undo/redo to a git-like branching model (something like this is already support by <a href="https://elpa.gnu.org/packages/undo-tree.html#:~:text=undo%20systems">emacs undo-tree</a>), where you have multiple "views" of the process tree.</li>
<li>Given the undo-tree model, and since we have sandboxing, we can give an LLM access to your project, and run many of them in parallel at the same time without overwriting each others state, and in such a way that you can see what they're doing, edit it, and save it into a runbook for later use.</li>
<li>A terminal in a prod environment that can't affect the state of the machine, only inspect the existing state.</li>
</ul>
<h2 id="ok-but-how-do-you-build-this">ok but how do you build this<a href="#ok-but-how-do-you-build-this" aria-label="Anchor link for: ok-but-how-do-you-build-this"></a>
</h2>
<p>jyn, you may say, <a href="https://becca.ooo/blog/vertical-integration/">you can't build vertical integration in open source</a>. <a href="https://tech.lgbt/@jyn/112187088917827279">you can't make money off open source projects</a>. <a href="https://jyn.dev/you-are-in-a-box/#switching-costs-and-growth">the switching costs are too high</a>.</p>
<p>All these things are true. To talk about how this is possible, we have to talk about incremental adoption.</p>
<p>if I were building this, I would do it in stages, such that at each stage the thing is an improvement over its alternatives. This is how <code>jj</code> works and it works extremely well: it doesn't require everyone on a team to switch at once because individual people can use <code>jj</code>, even for single commands, without a large impact on everyone else.</p>
<h3 id="stage-1-transactional-semantics">stage 1: transactional semantics<a href="#stage-1-transactional-semantics" aria-label="Anchor link for: stage-1-transactional-semantics"></a>
</h3>
<p>When people think of redesigning the terminal, they always think of redesigning the terminal <em>emulator</em>. This is exactly the wrong place to start. People are attached to their emulators. They configure them, they make them look nice, they use their keybindings. There is a high switching cost to switching emulators because <a href="https://jvns.ca/blog/2025/01/11/getting-a-modern-terminal-setup/#everything-affects-everything-else">everything affects everything else</a>. It's not <em>so</em> terribly high, because it's still individual and not shared across a team, but still high.</p>
<p>What I would do instead is start at the CLI layer. CLI programs are great because they're easy to install and run and have very low switching costs: you can use them one-off without changing your whole workflow.</p>
<p>So, I would write a CLI that implements <a href="https://jyn.dev/complected-and-orthogonal-persistence/#how-far-can-we-take-this">transactional semantics for the terminal</a>. You can imagine an interface something like <code>transaction [start|rollback|commit]</code>, where everything run after <code>start</code> is undoable. There is a <em>lot</em> you can do with this alone, I think you could build a whole business off this.</p>
<h3 id="stage-2-persistent-sessions">stage 2: persistent sessions<a href="#stage-2-persistent-sessions" aria-label="Anchor link for: stage-2-persistent-sessions"></a>
</h3>
<p>Once I had transactional semantics, I would try to decouple persistence from tmux and mosh.</p>
<p>To get PTY persistence, you have to introduce a client/server model, because the kernel <em>really really</em> <a href="https://en.wikipedia.org/wiki/SIGHUP">expects</a> both sides of a PTY to always be connected. Using commands like <a href="https://ansuz.sooke.bc.ca/entry/389">alden</a>, or a library like it (it's not <em>that</em> complicated), lets you do this simply, without affecting the terminal emulator nor the programs running inside the PTY session.</p>
<p>To get scrollback, the server could save input and output indefinitely and replay them when the client reconnects. This gets you "native" scrollback‚Äîthe terminal emulator you're already using handles it exactly like any other output, because it looks exactly like any other output‚Äîwhile still being replayable and resumable from an arbitrary starting point. This requires some amount of parsing ANSI escape codes<sup id="fr-2-1"><a href="#fn-2">2</a></sup>, but it's doable with enough work.</p>
<p>To get network resumption like mosh, my custom server could use <a href="https://eternalterminal.dev/howitworks/">Eternal TCP</a> (possibly built on top of QUIC for efficiency). Notably, the persistence for the PTY is separate from the persistence for the network connection. Eternal TCP here is strictly an optimization: you could build this on top of a bash script that runs <code>ssh host eternal-pty attach</code> in a loop, it's just not as nice an experience because of network delay and packet loss. Again, composable parts allow for incremental adoption.</p>
<p>At this point, you're already able to connect multiple clients to a single terminal session, like tmux, but window management is still done by your terminal emulator, not by the client/server. If you wanted to have window management integrated, the terminal emulator could speak the tmux -CC protocol, like iTerm.</p>
<p>All parts of this stage can be done independently and in parallel from the transactional semantics, but I don't think you can build a business off them, it's not enough of an improvement over the existing tools.</p>
<h3 id="stage-3-structured-rpc">stage 3: structured RPC<a href="#stage-3-structured-rpc" aria-label="Anchor link for: stage-3-structured-rpc"></a>
</h3>
<p>This bit depends on the client/server model. Once you have a server interposed between the terminal emulator and the client, you can start doing really funny things like tagging I/O with metadata. This lets all data be timestamped<sup id="fr-3-1"><a href="#fn-3">3</a></sup> and lets you distinguish input from output. <a href="https://jvns.ca/blog/2022/07/20/pseudoterminals/">xterm.js</a> works something like this. When combined with shell integration, this even lets you distinguish shell prompts from program output, at the <em>data</em> layer.</p>
<p>Now you can start doing really funny things, because you have a <em>structured log</em> of your terminal session. You can replay the log as a recording, like <a href="https://asciinema.org/">asciinema</a><sup id="fr-4-1"><a href="#fn-4">4</a></sup>; you can transform the shell prompt without rerunning all the commands; you can import it into a Jupyter Notebook or <a href="https://blog.atuin.sh/atuin-desktop-runbooks-that-run/">Atuin Desktop</a>; you can save the commands and rerun them later as a script. Your terminal is data.</p>
<h3 id="stage-4-jupyter-like-frontend">stage 4: jupyter-like frontend<a href="#stage-4-jupyter-like-frontend" aria-label="Anchor link for: stage-4-jupyter-like-frontend"></a>
</h3>
<p>This is the very first time that we touch the terminal emulator, and it's intentionally the last step because it has the highest switching costs. This makes use of all the nice features we've built to give you a nice UI. You don't need our <code>transaction</code> CLI anymore unless you want nested transactions, because your whole terminal session starts in a transaction by default. You get all the features I mention <a href="https://jyn.dev/the-terminal-of-the-future/#derived-features">above</a>, because we've put all the pieces together.</p>
<h2 id="jyn-what-the-fuck">jyn, what the fuck<a href="#jyn-what-the-fuck" aria-label="Anchor link for: jyn-what-the-fuck"></a>
</h2>
<p>This is bold and ambitious and I think building the whole thing would take about a decade. That's ok. I'm patient.</p>
<p>You can help me by spreading the word :) Perhaps this post will inspire someone to start building this themselves.</p>
<hr>
<h2 id="bibliography">bibliography<a href="#bibliography" aria-label="Anchor link for: bibliography"></a>
</h2>
<ul>
<li><a href="https://www.destroyallsoftware.com/talks/a-whole-new-world">Gary Bernhardt, ‚ÄúA Whole New World‚Äù</a></li>
<li><a href="https://matklad.github.io/2019/11/16/a-better-shell.html">Alex Kladov, ‚ÄúA Better Shell‚Äù</a></li>
<li><a href="https://jyn.dev/how-i-use-my-terminal/">jyn, ‚Äúhow i use my terminal‚Äù</a></li>
<li><a href="https://jyn.dev/complected-and-orthogonal-persistence/">jyn, ‚ÄúComplected and Orthogonal Persistence‚Äù</a></li>
<li><a href="https://jyn.dev/you-are-in-a-box/">jyn, ‚Äúyou are in a box‚Äù</a></li>
<li><a href="https://tech.lgbt/@jyn/112187088917827279">jyn, ‚Äúthere's two costs to making money off an open source project‚Ä¶‚Äù</a></li>
<li><a href="https://becca.ooo/blog/vertical-integration/">Rebecca Turner, ‚ÄúVertical Integration is the Only Thing That Matters‚Äù</a></li>
<li><a href="https://jvns.ca/blog/2025/06/24/new-zine--the-secret-rules-of-the-terminal/">Julia Evans, ‚ÄúNew zine: The Secret Rules of the Terminal‚Äù</a></li>
<li><a href="https://wizardzines.com/comics/meet-the-terminal-emulator/">Julia Evans, ‚Äúmeet the terminal emulator‚Äù</a></li>
<li><a href="https://jvns.ca/blog/2022/07/20/pseudoterminals/">Julia Evans, ‚ÄúWhat happens when you press a key in your terminal?‚Äù</a></li>
<li><a href="https://jvns.ca/blog/2025/01/11/getting-a-modern-terminal-setup/">Julia Evans, ‚ÄúWhat's involved in getting a "modern" terminal setup?‚Äù</a></li>
<li><a href="https://jvns.ca/blog/2017/03/26/bash-quirks/">Julia Evans, ‚ÄúBash scripting quirks &amp; safety tips‚Äù</a></li>
<li><a href="https://jvns.ca/blog/2025/02/05/some-terminal-frustrations/">Julia Evans, ‚ÄúSome terminal frustrations‚Äù</a></li>
<li><a href="https://jvns.ca/blog/2024/07/03/reasons-to-use-job-control/">Julia Evans, ‚ÄúReasons to use your shell's job control‚Äù</a></li>
<li><a href="https://man7.org/linux/man-pages/man7/signal.7.html">‚Äúsignal(7) - Miscellaneous Information Manual‚Äù</a></li>
<li><a href="https://gist.github.com/fnky/458719343aabd01cfb17a3a4f7296797">Christian Petersen, ‚ÄúANSI Escape Codes‚Äù</a></li>
<li><a href="https://github.com/withoutboats/notty">saoirse, ‚Äúwithoutboats/notty: A new kind of terminal‚Äù</a></li>
<li><a href="https://docs.jupyter.org/en/latest/">Jupyter Team, ‚ÄúProject Jupyter Documentation‚Äù</a></li>
<li><a href="https://www.warp.dev/">‚ÄúWarp: The Agentic Development Environment‚Äù</a></li>
<li><a href="https://www.warp.dev/blog/how-warp-works">‚ÄúWarp: How Warp Works‚Äù</a></li>
<li><a href="https://docs.warp.dev/terminal/command-completions/completions">‚ÄúWarp: Completions‚Äù</a></li>
<li><a href="https://iterm2.com/documentation-escape-codes.html">George Nachman, ‚ÄúiTerm2: Proprietary Escape Codes‚Äù</a></li>
<li><a href="https://iterm2.com/documentation-shell-integration.html">George Nachman, ‚ÄúiTerm2: Shell Integration‚Äù</a></li>
<li><a href="https://iterm2.com/documentation-tmux-integration.html">George Nachman, ‚ÄúiTerm2: tmux Integration‚Äù</a></li>
<li><a href="https://ipywidgets.readthedocs.io/en/latest/">Project Jupyter, ‚ÄúJupyter Widgets‚Äù</a></li>
<li><a href="https://github.com/nelhage/reptyr">Nelson Elhage, ‚Äúnelhage/reptyr: Reparent a running program to a new terminal‚Äù</a></li>
<li><a href="https://sw.kovidgoyal.net/kitty/">Kovid Goyal, ‚Äúkitty‚Äù</a></li>
<li><a href="https://sw.kovidgoyal.net/kitty/faq/">Kovid Goyal, ‚Äúkitty - Frequently Asked Questions‚Äù</a></li>
<li><a href="https://wezfurlong.org/wezterm/">Wez Furlong, ‚ÄúWezterm‚Äù</a></li>
<li><a href="https://mosh.org/">Keith Winstein, ‚ÄúMosh: the mobile shell‚Äù</a></li>
<li><a href="https://github.com/mobile-shell/mosh/issues/234">Keith Winstein, ‚ÄúDisplay errors with certain characters</a></li>
<li><a href="https://ansuz.sooke.bc.ca/entry/389">Matthew Skala, ‚Äúalden: detachable terminal sessions without breaking scrollback‚Äù</a></li>
<li><a href="https://github.com/shell-pool/shpool">Ethan Pailes, ‚Äúshell-pool/shpool: Think tmux, then aim... lower‚Äù</a></li>
<li><a href="https://github.com/crigler/dtach">Ned T. Crigler, ‚Äúcrigler/dtach: A simple program that emulates the detach feature of screen‚Äù</a></li>
<li><a href="https://github.com/martanne/abduco">Marc Andr√© Tanner, ‚Äúmartanne/abduco: abduco provides session management‚Äù</a></li>
<li><a href="https://github.com/yazgoo/diss">yazgoo, ‚Äúyazgoo/diss: dtach-like program / crate in rust‚Äù</a></li>
<li><a href="https://plutojl.org/">Fons van der Plas, ‚ÄúPluto.jl ‚Äî interactive Julia programming environment‚Äù</a></li>
<li><a href="https://blog.atuin.sh/atuin-desktop-runbooks-that-run/">Ellie Huxtable, ‚ÄúAtuin Desktop: Runbooks that Run‚Äù</a></li>
<li><a href="https://elpa.gnu.org/packages/undo-tree.html">Toby Cubitt, ‚Äúundo-tree‚Äù</a></li>
<li><a href="https://en.wikipedia.org/wiki/SIGHUP">‚ÄúSIGHUP - Wikipedia‚Äù</a></li>
<li><a href="https://eternalterminal.dev/howitworks/">Jason Gauci, ‚ÄúHow Eternal Terminal Works‚Äù</a></li>
<li><a href="https://asciinema.org/">Marcin Kulik, ‚ÄúRecord and share your terminal sessions, the simple way - asciinema.org‚Äù</a></li>
<li><a href="https://ratatui.rs/concepts/backends/alternate-screen/">‚ÄúAlternate Screen | Ratatui‚Äù</a></li>
</ul>
<hr>
<!--To talk about interacting with a process, we have to talk about [PTTYs](https://jvns.ca/blog/2022/07/20/pseudoterminals/).-->
<!--
My complaint about Warp is chiefly that they didn't think big enough. Warp built a very cool tool, and then wrapped it in a product that mostly exists to make it easier to use LLMs in the terminal. There are [*so many* things](https://iterm2.com/documentation-shell-integration.html#:~:text=enables%20numerous%20features) you could do with shell integration, and they don't seem to have done very many of them.
-->


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A modern 35mm film scanner for home (179 pts)]]></title>
            <link>https://www.soke.engineering/</link>
            <guid>45891907</guid>
            <pubDate>Tue, 11 Nov 2025 19:48:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.soke.engineering/">https://www.soke.engineering/</a>, See on <a href="https://news.ycombinator.com/item?id=45891907">Hacker News</a></p>
<div id="readability-page-1" class="page"><div webpageid="augiA20Il" data-layout-template="true" id="main" data-framer-hydrate-v2="{&quot;routeId&quot;:&quot;augiA20Il&quot;,&quot;localeId&quot;:&quot;default&quot;,&quot;breakpoints&quot;:[{&quot;hash&quot;:&quot;72rtr7&quot;,&quot;mediaQuery&quot;:&quot;(min-width: 1200px)&quot;},{&quot;hash&quot;:&quot;1gly80&quot;,&quot;mediaQuery&quot;:&quot;(min-width: 810px) and (max-width: 1199.98px)&quot;},{&quot;hash&quot;:&quot;1teekcz&quot;,&quot;mediaQuery&quot;:&quot;(max-width: 809.98px)&quot;},{&quot;hash&quot;:&quot;4e4xff&quot;,&quot;mediaQuery&quot;:&quot;(min-width: 1440px)&quot;},{&quot;hash&quot;:&quot;wthtfe&quot;,&quot;mediaQuery&quot;:&quot;(min-width: 810px) and (max-width: 1439.98px)&quot;},{&quot;hash&quot;:&quot;1l7dlx4&quot;,&quot;mediaQuery&quot;:&quot;(max-width: 809.98px)&quot;}]}" data-framer-ssr-released-at="2025-11-10T14:50:19.351Z" data-framer-page-optimized-at="2025-11-11T21:36:56.978Z" data-framer-generated-page=""><nav data-framer-appear-id="h121gk" data-framer-layout-hint-center-x="true" data-framer-name="Navbar"></nav><div data-framer-root=""><header data-framer-name="Hero-Section" id="hero-section"><div data-framer-name="Container"><figure as="figure" data-framer-name="img"><p><img decoding="async" width="1237" height="1110" src="https://framerusercontent.com/images/Z8ymSbSlFHFYqnxs7knHRxMBqo.png?width=1237&amp;height=1110" alt=""></p></figure></div></header><header data-framer-name="Hero-Section" id="hero-section-1"><div data-framer-name="Container"><div data-framer-name="Left-Text"><p data-framer-component-type="RichTextContainer"><h2 data-styles-preset="ZfkYyGwCo"><span>The New Era of </span><br><span>Film Scanning</span></h2></p><div data-framer-name="Highlights"><p><!--$--><h2><span>Knokke  - a high-resolution 35 mm film scanner built for photographers who demand speed, quality and control.</span></h2><!--/$--></p></div></div><div data-framer-name="Variant 1" data-highlight="true" tabindex="0" data-framer-appear-id="1wbnzl8" id="1wbnzl8"><p><svg style="width:100%;height:100%;transform-origin:center" viewBox="0 0 100 100" overflow="visible"><path id="curve-wnxkz4" d="M 0 50 L 0 50 A 1 1 0 0 1 100 50 L 100 50 L 100 50 A 1 1 0 0 1 0 50 L 0 50" stroke-width="none" fill="transparent"></path><text><textPath href="#curve-wnxkz4" startOffset="0" dominant-baseline="Text Top" style="letter-spacing:0.02em;font-family:&quot;IBM Plex Mono&quot;, monospace;font-size:14px;font-style:normal;font-weight:500;line-height:1em;fill:var(--token-ba5469a1-3890-44cc-aaeb-d6b7e143f20d, rgb(244, 244, 245))">Watch the video - Watch the video -</textPath></text></svg></p></div></div></header><header data-framer-name="Hero-Section" id="hero-section-2"><div data-framer-name="Container"><p data-framer-component-type="RichTextContainer"><h2 data-styles-preset="ZfkYyGwCo"><span>The New Era of </span><br><span>Film Scanning</span></h2></p><p><!--$--><h2><span>Knokke - a high-resolution 35 mm film scanner built for photographers who demand speed, quality, and control.</span></h2><!--/$--></p></div><div data-framer-appear-id="truicp" data-framer-name="Image"><figure as="figure" data-framer-name="img"><p><img decoding="async" width="1237" height="1110" src="https://framerusercontent.com/images/Z8ymSbSlFHFYqnxs7knHRxMBqo.png?width=1237&amp;height=1110" alt=""></p></figure></div></header><div data-framer-name="Proof Section" id="proof"><p data-framer-component-type="RichTextContainer"><h2 data-styles-preset="ZfkYyGwCo">Knokke redefines film scanning by bringing modern imaging, optics, and software into a beautifully engineered device.</h2></p></div><div data-framer-name="Product Section" id="features"><div data-framer-name="Components/Product item"><p>The modern 35 mm film scanner that captures a full roll in under just a few minutes while capturing every frame at 4064 DPI and 48bit colour. Its custom optics and state-of-the-art sensor deliver benchmark setting quality and speed at a price only Knokke can offer.</p></div><div data-framer-component-type="RichTextContainer" data-framer-name="Product 2"><p>Built for the 21st century, Knokke runs on Korova, a lean C++ application that's native to Linux, macOS, and Windows‚Äîso you can forget vintage PCs and enjoy a plug-and-play workflow that lets you focus on your photos.</p><p>Each frame can have custom scan settings, repeatable across multiple scans for consistent results and tailored workflows. The scanner can also skip directly to requested frames, massively accelerating scanning time and enabling fast access to key shots without unnecessary delay.</p></div></div><div data-framer-name="Features Section"><div data-framer-name="Image"><p><img decoding="async" loading="lazy" width="5152" height="7728" sizes="(min-width: 1200px) max(max((min(max(100vw - 32px, 1px), 1200px) - 71px) / 3, 1px), 100vw), (min-width: 810px) and (max-width: 1199.98px) max(max((min(max(100vw - 32px, 1px), 1200px) - 71px) / 3, 1px), 100vw, 254px), (max-width: 809.98px) max(max((min(max(100vw - 32px, 1px), 1200px) - 71px) / 3, 1px), min(100vw - 32px, 1200px), 100vw)" srcset="https://framerusercontent.com/images/VrDOZbsbciVXbWxffHjfugl4U7w.jpg?scale-down-to=1024&amp;width=5152&amp;height=7728 682w,https://framerusercontent.com/images/VrDOZbsbciVXbWxffHjfugl4U7w.jpg?scale-down-to=2048&amp;width=5152&amp;height=7728 1365w,https://framerusercontent.com/images/VrDOZbsbciVXbWxffHjfugl4U7w.jpg?scale-down-to=4096&amp;width=5152&amp;height=7728 2730w,https://framerusercontent.com/images/VrDOZbsbciVXbWxffHjfugl4U7w.jpg?width=5152&amp;height=7728 5152w" src="https://framerusercontent.com/images/VrDOZbsbciVXbWxffHjfugl4U7w.jpg?width=5152&amp;height=7728" alt="" data-framer-original-sizes="max((min(max(100vw - 32px, 1px), 1200px) - 71px) / 3, 1px)"></p></div><div data-framer-name="Heading"><p id="w8drg9" data-framer-component-type="RichTextContainer"><h3 data-styles-preset="gUnjFa38F">Engineered for Individual Users and Lab Professionals</h3></p><div data-framer-name="Grid"><div data-border="true" data-framer-name="Default"><div data-framer-name="Title"><p data-framer-component-type="RichTextContainer"><h6 data-styles-preset="cr4s6T7G5">01</h6></p><p data-framer-component-type="RichTextContainer"><h6>Quality</h6></p></div><p>Knokke‚Äôs premium build and precision engineering ensure lasting, reliable performance.</p></div><div data-border="true" data-framer-name="Default"><div data-framer-name="Title"><p data-framer-component-type="RichTextContainer"><h6 data-styles-preset="cr4s6T7G5">02</h6></p><p data-framer-component-type="RichTextContainer"><h6>Speed</h6></p></div><p>Knokke‚Äôs high scan speed and streamlined workflow keep you moving.</p></div><div data-border="true" data-framer-name="Default"><div data-framer-name="Title"><p data-framer-component-type="RichTextContainer"><h6 data-styles-preset="cr4s6T7G5">03</h6></p><p data-framer-component-type="RichTextContainer"><h6>Full Control</h6></p></div><p>Knokke lets you fine-tune every detail with flexible settings and precise color control.</p></div><div data-border="true" data-framer-name="Default"><div data-framer-name="Title"><p data-framer-component-type="RichTextContainer"><h6 data-styles-preset="cr4s6T7G5">04</h6></p><p data-framer-component-type="RichTextContainer"><h6>Future Proof</h6></p></div><p>Knokke comes with ongoing software support, open-source flexibility, and readily available spare parts.</p></div></div></div></div><div data-framer-name="CTA-Section" id="cta-section"><div data-framer-name="Left"><p data-framer-component-type="RichTextContainer"><h2>Price at Launch</h2></p></div><div data-framer-name="Right"><div data-framer-name="Price"><p><!--$--><h2><span>999‚Ç¨</span></h2><!--/$--></p><p><strong>Includes scanner + software</strong></p></div><div data-framer-name="Features"><div data-framer-name="Row"><p><!--$--><h2><span>4064 dpi resolution</span></h2><!--/$--></p></div><div data-framer-name="Row"><p><!--$--><h2><span>5 min per roll</span></h2><!--/$--></p></div><div data-framer-name="Row"><p><!--$--><h2><span>48-bit colour depth</span></h2><!--/$--></p></div><div data-framer-name="Row"><p><!--$--><h2><span>120 dB Dynamic Range</span></h2><!--/$--></p></div><div data-framer-name="Row"><p><!--$--><h2><span>LED Matrix</span></h2><!--/$--></p></div><div data-framer-name="Row"><p><!--$--><h2><span>RGB LED backlight</span></h2><!--/$--></p></div></div></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FFmpeg to Google: Fund Us or Stop Sending Bugs (776 pts)]]></title>
            <link>https://thenewstack.io/ffmpeg-to-google-fund-us-or-stop-sending-bugs/</link>
            <guid>45891016</guid>
            <pubDate>Tue, 11 Nov 2025 18:32:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thenewstack.io/ffmpeg-to-google-fund-us-or-stop-sending-bugs/">https://thenewstack.io/ffmpeg-to-google-fund-us-or-stop-sending-bugs/</a>, See on <a href="https://news.ycombinator.com/item?id=45891016">Hacker News</a></p>
Couldn't get https://thenewstack.io/ffmpeg-to-google-fund-us-or-stop-sending-bugs/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[We ran over 600 image generations to compare AI image models (135 pts)]]></title>
            <link>https://latenitesoft.com/blog/evaluating-frontier-ai-image-generation-models/</link>
            <guid>45890186</guid>
            <pubDate>Tue, 11 Nov 2025 17:26:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://latenitesoft.com/blog/evaluating-frontier-ai-image-generation-models/">https://latenitesoft.com/blog/evaluating-frontier-ai-image-generation-models/</a>, See on <a href="https://news.ycombinator.com/item?id=45890186">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<p><b>tl:dr; </b>We‚Äôve been making photo apps for iOS for long enough that we have gray hairs now, and using our experience we ran over 600 image generations to compare which AI models work best for which image edits. If you want, you can jump right to the <a href="#filters">image comparisons</a>, or the <a href="#conclusion">conclusion</a>, but promise us you won‚Äôt presumptuous comments on Hacker News until you‚Äôve also read the background!</p>



<h2>Background</h2>



<p>Hi! We‚Äôre LateNiteSoft, and we‚Äôve been working on photography-related iOS apps for 15 years now. Working on market-leading apps such as Camera+, <a href="https://photon.cam/?from=lnsblog">Photon</a> and <a href="https://recvideoapp.com/">REC</a>, we‚Äôve always had our finger on the pulse on what users want out of their mobile photography.</p>



<p>With the ground-breaking release of OpenAI‚Äôs <b>gpt-image-1</b> image generation model earlier this year, we started investigating all the interesting use cases we could think of for AI image editing.</p>



<p>But as a company that has never taken any venture capital investment, all our products have to pay for themselves. We‚Äôre in it to delight our users, not just capture market share and sell them out. When considering AI projects, one thing has been clear ‚Äì we can‚Äôt take the AI startup road where you have a generous free tier, charge an unreasonably small monthly fee for ‚Äúunlimited‚Äù, and hope you‚Äôre going to make it up on scale (code for ‚Äúsomeone please acquire us‚Äù).</p>



<p>All the AI-focused billing systems we could find out there were based on this. Assuming you want to claim unlimited access, and then sandbag users with ‚Äúfair use‚Äù clauses and prevent them from any actual unlimited usage (which is, obviously, untenable, since you‚Äôll end up with one $20/mo user reselling to everyone else).</p>



<p>Since we want to fairly charge our customers for what they actually use, we‚Äôve built a credit-based ‚Äúpay per generation‚Äù-style billing system (that internally we‚Äôve been calling CreditProxy). We‚Äôve also been planning on providing this as a service, since nobody else seems to be doing it, so if you‚Äôre interested in being a trial user, <a href="https://latenitesoft.com/contact/">get in touch!</a></p>



<p>We released our app <a href="https://apps.apple.com/app/apple-store/id6745558534?pt=11365&amp;ct=lnsblog&amp;mt=8">MorphAI</a> as a public proof of concept to give CreditProxy a proper real world-test, and have marketed it to the users of Camera+, which includes traditional photo-editing functionality, including a whole host of popular photo filters, giving us a built-in audience of customers ready for the next step in image editing.</p>



<p>With the release of newer models like nanoBanana and Seedream, we‚Äôve had to consider which models make sense to support. We need to explore the trade-offs between quality, prompt complexity, and pricing.</p>



<p>A couple of hastily-hacked together scripts, and many, many AI generation credits later, we have some results! So that everyone else also doesn‚Äôt have to waste their money, we figured we‚Äôd share what we found:</p>



<h2>The Tests</h2>



<p>Based on our experience with Camera+ and the kind of edits our users have been making with MorphAI, we picked a host of somewhat naive prompts. Veteran Midjourney users may scoff at these, but in our experience these are the kinds of prompts that our average user is likely to use.</p>



<p>As for test photos, we chose some some representative things people like to take photos of: their pets, their kids, landscapes, their cars, and product photography.</p>



<p>
<img decoding="async" src="https://latenitesoft.com/blog/wp-content/plugins/model-comparison-widget/images/landscape.jpg"> 
<img decoding="async" src="https://latenitesoft.com/blog/wp-content/plugins/model-comparison-widget/images/car.jpg"> 
<img decoding="async" src="https://latenitesoft.com/blog/wp-content/plugins/model-comparison-widget/images/pets.jpg"> 
<img decoding="async" src="https://latenitesoft.com/blog/wp-content/plugins/model-comparison-widget/images/portrait.jpg"> 
<img decoding="async" src="https://latenitesoft.com/blog/wp-content/plugins/model-comparison-widget/images/product.jpg">
</p>



<p>Image generation times are also relevant. During our test period, the generation time for all models was fairly consistent, and didn‚Äôt vary by image or prompt complexity.</p>



<figure><table><tbody><tr><td><strong>OpenAI (High)</strong></td><td><strong>Gemini</strong></td><td><strong>Seedream</strong></td></tr><tr><td>80 seconds</td><td>11 seconds</td><td>9 seconds</td></tr></tbody></table></figure>



<p>OpenAI also has a quality setting, the images included here were all generated on High quality, but we also tested Medium, and those generations averaged 36 seconds. We can include the Medium quality images as well if there is any interest!</p>



<p>There are a ton of photos to compare here, so to make things easier to flip through, here are some <strong>keyboard shortcuts</strong> to help you out: Click on a photo to see it larger. Now you can use the arrow keys to switch between models. Press the tab key to switch between test images. Hit ESC to leave the view.</p>



<h2 id="filters">Classic filters</h2>



<p>These are the types of filters that we used to implement manually, by painstakingly hand-crafting textures and Photoshop layers and then converting those to Objective-C code. Now all you need is a few words into a language model (and to burn down half of a rain forest or so; just the cost of progress).</p>



<p>Our conclusion for this category is that for photo realistic filters like this, Gemini really shines by preserving details from the original and minimizing hallucinations, but often at the expense of the strength and creativity of the effect. Especially with photos of people, Gemini seems to refuse to apply any edits at all, with a strong bias towards photo realism.</p>



<p>OpenAI really likes to mess with the details of the photo, giving a characteristic ‚ÄúAI slop‚Äù feel, which can be a deal breaker on things like human faces.</p>



<h3>Grungy vintage photo</h3>






<h3>Use soft, diffused lighting</h3>






<h3>Transform into a kaleidoscopic pattern</h3>



<p>Gemini took some really odd shortcuts in generating some of these!</p>






<h3>Apply a heat map effect</h3>



<p>It‚Äôs clear that none of the models actually have a concept of what generates heat here, aside from Seedream knowing that humans generate heat, clearly revealing that without any ground truth the models struggle.</p>






<h3>Make it look like a long exposure photograph</h3>



<p>This is an interesting test since in some of the sample photos a long exposure doesn‚Äôt make sense. In the ones where it makes the most sense ‚Äì the landscape and the car, OpenAI did the best, but on the other hand it completely messed up the cats and the product, and the portrait photo turned into a trippy art piece.</p>



<p>Gemini, maybe logically, did nothing. Seedream liked adding light streaks as if a car drove past, with only the portrait photo seemingly making any sense.</p>






<h3>Pinhole camera</h3>



<p>In this case, it was funny to watch Gemini take a literal approach and generate actual pictures of cameras! For this reason we re-worked this prompt by just adding the word ‚Äúeffect‚Äù.</p>






<h3>Pinhole camera effect</h3>



<p>Gemini liked to generate a literal pinhole camera here so we tried modifying the prompt.</p>






<h3>Add a layer of fog or mist</h3>






<h3>Make it look like it‚Äôs golden hour</h3>






<h3>Make it look like it‚Äôs etched in glass</h3>



<p>With this prompt, there is ambiguity in what ‚Äúit‚Äù is, so we tried a reworded prompt as well. Only OpenAI consistently knew what a traditional etched glass effect looks like. Seedream‚Äôs glass item effect looks really cool!</p>






<h3>Make it look like the photo is etched in glass</h3>



<p>Gemini has a really interesting interpretation here! And Seedream had some pretty fantastic results.</p>






<h3>Remove background</h3>



<p>This is a classic job people have spent their lives doing manually in Photoshop since the early 90‚Äôs. But what is a ‚Äúbackground‚Äù, really? Is the ground in front of a car the ‚Äúbackground‚Äù? We also retried this with a tweaked prompt.</p>



<p>OpenAI‚Äôs ‚Äúsloppification‚Äù of the details of objects makes it useless for this purpose.</p>






<h3>Isolate the object</h3>



<p>With the tweaked prompt, Gemini‚Äôs API actually returned a followup question: <em>‚ÄúWhich object would you like to isolate? There are two cats in the image.‚Äù</em>, which our generation script was not prepared to handle! So it is missing from this comparison.</p>






<h3>Give it a metallic sheen</h3>



<p>Another case where ‚Äúit‚Äù is vague and we can retry with a more specific prompt. The product imagery is another case where Seedream created a really stunning result, even adding a reflection of someone taking the photo with their phone!</p>






<h3>Give the object a metallic sheen</h3>



<p>Modifying the prompt here really only changed OpenAI‚Äôs interpretation.</p>






<h2>Lens effects</h2>



<p>One of the filter packs we had worked on for Camera+ using traditional methods was a lens effect filter pack. But unlike traditional edits, with generative AI you can also create wide-angle lens effects that can just make up the portions of the image that the camera couldn‚Äôt capture.</p>



<p>This is another category where it‚Äôs very visible how OpenAI regenerates and hallucinates all the details in a picture, where Gemini and Seedream‚Äôs results are very faithful to the original and look more like actual lens permutations.</p>



<h3>Apply a fish-eye lens effect</h3>






<h3>Strong bokeh blur</h3>



<p>It was pretty surprising how poorly the models did here considering how common this must be among the training data. OpenAI give a strong blur but no bokeh effects. Gemini gives us a bunch of random circles in front of the image, demonstrating an understanding of what people want out of a bokeh filter but not how it works. Seedream does really well here.</p>






<h3>Apply a Dutch angle (canted frame)</h3>



<p>OpenAI really lost it‚Äôs mind here on the car photo.</p>






<h3>Change to a bird‚Äôs-eye view</h3>






<h2>Style transfer</h2>



<p>Style Transfer is the process of applying an artistic style to a photo. This technique predates the current AI model by quite a few years with popular apps generating Van Gogh paintings out of your photos. We were also early out in attempting style transfer for our apps, shout out to Noel‚Äôs Intel iMac which had to run at full blast all night just to generate a 256x256px image, since it was our only machine with a compatible GPU.</p>



<p>While Gemini was good at preserving reality in the more photorealistic effects in the previous section, when it comes to the more artistic styles, OpenAI has them beat, while Gemini keeps things far too conservative, especially with photos of a human in them, where it sometimes seems to just do nothing at all, is this some kind of safety guardrail?</p>



<h3>Draw this in the style of a Studio Ghibli movie</h3>



<p>ChatGPT went viral with this prompt, with Sam Altman even making it his profile on X. And OpenAI keeps the crown ‚Äì is Google too conservative in order to avoid a lawsuit? Seedream makes an attempt but they just end up looking like ‚Äúgeneric Anime‚Äù.</p>






<h3>Transform into watercolor painting</h3>






<h3>Make it look like a pastel artwork</h3>






<h3>Transform into Art Nouveau style</h3>






<h3>Apply a ukiyo-e Japanese woodblock print style</h3>



<p>A very stark example of Gemini failing to apply a style on photos with humans. This is a prompt where Seedream knocked it out of the park, perhaps showing a larger portion of their training data being sourced from asian cultures than the western models.</p>






<h3>Transform into low poly art</h3>



<p>Seedream blows everyone else away here.</p>






<h2>Portrait effects</h2>



<p>For prompts about human appearance, we have only applied them to the portrait photo.</p>



<h3>Make it look like a caricature</h3>



<p>Seedream seems to be biased towards asian culture, giving an anime look instead of a western-style cartoon caricature.</p>






<h3>Turn them into an action figure in the blister pack</h3>



<p>OpenAI‚Äôs style here went viral a while back, but Gemini is stunningly realistic. Seedream is a weird mix of realistic and hallucinations.</p>






<h2>Generative edits</h2>



<p>The place where generative AI really shines is when it can show off some creativity, and these were some prompts we added as suggestions in MorphAI to showcase that and inspire our users. OpenAI still seems to win here.</p>



<h3>Create a 70‚Äôs vinyl record cover</h3>



<p>This is an example of a prompt that has a small viral moment with OpenAI, but the other models can‚Äôt even get the aspect ratio right.</p>






<h3>Introduce mythical creatures native to this environment</h3>



<p>This one showcases OpenAI‚Äôs creativity. Gemini seems kind of creepy?</p>






<h3>Add a mystical portal or gateway</h3>



<p>Gemini replacing the face with a portal is certainly a choice!</p>






<h3>Incorporate futuristic technology elements</h3>



<p>Another example of OpenAI being far more creative and willing to re-do the whole image.</p>






<h3>Make it look whimsical and enchanting</h3>



<p>This one also shows OpenAI being more artistic, and Gemini being more realistic while still trying to incorporate the prompt.</p>






<h3>Transform the scene to a stormy night</h3>






<h2 id="conclusion">Conclusion</h2>



<p>If you made it all the way down here you probably don‚Äôt need a summary, but for our purposes, we‚Äôve at least concluded that there is no one-size-fits all model at this point.</p>



<p>OpenAI is great for fully transformative filters like style transfer or more creative generative applications, whereas Gemini works better for more realistic edits. Seedream lies somewhere in the middle and is a bit of a jack of all trades, and for the price and performance may be a good replacement for OpenAI.</p>



<p>We‚Äôve been experimenting on working on a ‚Äúprompt classifier‚Äù to automatically choose a model ‚Äì sending artistic prompts to OpenAI and more realistic prompts to Gemini, if there‚Äôs any interest we can follow up with how that worked out!</p>















<h4>Methodology</h4>



<p>Tests were performed on October 8 with <code>gpt-image-1</code>, <code>gemini-2.5-flash-image</code> and <code>seedream-4-0-250828</code>.</p>



<p>Timings were measured on a consumer internet connection in Japan (Fiber connection, 10 Gbps nominal bandwidth) during a limited test run in a short time period.</p>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cache-friendly, low-memory Lanczos algorithm in Rust (116 pts)]]></title>
            <link>https://lukefleed.xyz/posts/cache-friendly-low-memory-lanczos/</link>
            <guid>45889891</guid>
            <pubDate>Tue, 11 Nov 2025 17:08:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lukefleed.xyz/posts/cache-friendly-low-memory-lanczos/">https://lukefleed.xyz/posts/cache-friendly-low-memory-lanczos/</a>, See on <a href="https://news.ycombinator.com/item?id=45889891">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="article"> <p>The standard Lanczos method for computing matrix functions has a brutal memory requirement: storing an <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>√ó</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">n \times k</annotation></semantics></math></span></span> basis matrix that grows with every iteration. For a <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>500.000</mn></mrow><annotation encoding="application/x-tex">500.000</annotation></semantics></math></span></span>-variable problem needing <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1000</mn></mrow><annotation encoding="application/x-tex">1000</annotation></semantics></math></span></span> iterations, that‚Äôs roughly 4 GB just for the basis.</p>
<p>In this post, we will explore one of the most straightforward solutions to this problem: a two-pass variant of the Lanczos algorithm that only requires <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span></span> memory at the cost of doubling the number of matrix-vector products. The surprising part is that when implemented carefully, the two-pass version isn‚Äôt just memory-efficient‚Äîit can be faster for certain problems. We will dig into why.</p>
<ul>
<li>All code is available on GitHub: <a href="https://github.com/lukefleed/two-pass-lanczos">two-pass-lanczos</a></li>
<li>The full technical report with proofs and additional experiments: <a href="https://github.com/lukefleed/two-pass-lanczos/raw/master/tex/report.pdf">report.pdf</a></li>
</ul>
<hr>
<h2 id="table-of-contents">Table of Contents</h2>
<details><summary>Open Table of Contents</summary>
<ul>
<li><a href="#computing-matrix-functions">Computing Matrix Functions</a>
<ul>
<li><a href="#krylov-projection">Krylov Projection</a>
<ul>
<li><a href="#building-an-orthonormal-basis">Building an Orthonormal Basis</a></li>
<li><a href="#solving-in-the-reduced-space">Solving in the Reduced Space</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#the-lanczos-algorithm">The Lanczos Algorithm</a>
<ul>
<li><a href="#three-term-recurrence">Three-Term Recurrence</a></li>
<li><a href="#reconstructing-the-solution">Reconstructing the Solution</a></li>
</ul>
</li>
<li><a href="#two-pass-algorithm">Two-Pass Algorithm</a>
<ul>
<li><a href="#first-pass-compute-the-projected-problem">First Pass: Compute the Projected Problem</a></li>
<li><a href="#second-pass-reconstruct-and-accumulate">Second Pass: Reconstruct and Accumulate</a>
<ul>
<li><a href="#a-subtle-numerical-point">A Subtle Numerical Point</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#implementation">Implementation</a>
<ul>
<li><a href="#recurrence-step">Recurrence Step</a></li>
<li><a href="#an-iterator-for-state-management">An Iterator for State Management</a></li>
<li><a href="#first-pass-computing-the-decomposition">First Pass: Computing the Decomposition</a></li>
<li><a href="#second-pass-reconstructing-the-solution">Second Pass: Reconstructing the Solution</a></li>
<li><a href="#the-public-api">The Public API</a>
<ul>
<li><a href="#example-solving-a-linear-system">Example: Solving a Linear System</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#some-interesting-results">Some interesting results</a>
<ul>
<li><a href="#memory-and-computation-trade-off">Memory and Computation Trade-off</a>
<ul>
<li><a href="#memory-usage">Memory Usage</a></li>
<li><a href="#runtime-where-theory-breaks">Runtime: Where Theory Breaks</a></li>
<li><a href="#medium-scale-behavior">Medium-Scale Behavior</a></li>
<li><a href="#what-about-dense-matrices">What About Dense Matrices?</a></li>
</ul>
</li>
<li><a href="#scalability">Scalability</a></li>
</ul>
</li>
</ul>
</details>
<h2 id="computing-matrix-functions">Computing Matrix Functions</h2>
<p>Let‚Äôs consider the problem of computing the action of matrix functions on a vector:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">x</mi><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">\mathbf{x} = f(\mathbf{A})\mathbf{b}</annotation></semantics></math></span></span></span>
<p>where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> is a large sparse Hermitian matrix and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span></span> is a matrix function defined on the spectrum of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span>. This is a problem that appears pretty often in scientific computing: solving linear systems corresponds to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>z</mi><mrow><mo>‚àí</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">f(z) = z^{-1}</annotation></semantics></math></span></span>, exponential integrators for PDEs use <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mi>exp</mi><mo>‚Å°</mo><mo stretchy="false">(</mo><mi>t</mi><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(z) = \exp(tz)</annotation></semantics></math></span></span>, and many other problems require functions like <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>z</mi><mrow><mo>‚àí</mo><mn>1</mn><mi mathvariant="normal">/</mi><mn>2</mn></mrow></msup></mrow><annotation encoding="application/x-tex">f(z) = z^{-1/2}</annotation></semantics></math></span></span> or <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>sign</mtext><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(z) = \text{sign}(z)</annotation></semantics></math></span></span>.</p>
<p>Indeed, there are a lot problems with computing <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\mathbf{A})</annotation></semantics></math></span></span> directly. First of all, even if <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> is sparse, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\mathbf{A})</annotation></semantics></math></span></span> is generally dense. Storing it explicitly is out of the question for large problems. Even if we could store it, computing it directly would require algorithms like the Schur-Parlett method that scale as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>3</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^3)</annotation></semantics></math></span></span>, which is impractical for large <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span>.</p>
<p>However we know that given any matrix function <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span></span> defined on the spectrum of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span>, we can express <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\mathbf{A})</annotation></semantics></math></span></span> as a polynomial in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> of degree at most <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> (the size of the matrix) such that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>p</mi><mi>n</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\mathbf{A}) = p_{n}(\mathbf{A})</annotation></semantics></math></span></span> (this is a consequence of the Cayley-Hamilton theorem). This polynomial interpolates <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span></span> and its derivatives in the Hermitian sense at the eigenvalues of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span>.</p>
<p>This gives us a good and a bad news: the good news is that, well, we can express <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\mathbf{A})</annotation></semantics></math></span></span> as a polynomial in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span>. The bad news is that the degree of this polynomial can be as high as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span>, which is huge for large problems. The idea is then to find a low-degree polynomial approximation to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span></span> that is <em>good enough</em> for our purposes. If we can find a polynomial <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">p_k</annotation></semantics></math></span></span> of degree <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>‚â™</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">k \ll n</annotation></semantics></math></span></span> such that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>k</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo><mo>‚âà</mo><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p_k(\mathbf{A}) \approx f(\mathbf{A})</annotation></semantics></math></span></span>, then we can approximate the solution as:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo><mi mathvariant="bold">b</mi><mo>‚âà</mo><msub><mi>p</mi><mi>k</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo><mi mathvariant="bold">b</mi><mo>=</mo><munderover><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>k</mi></munderover><msub><mi>c</mi><mi>i</mi></msub><msup><mi mathvariant="bold">A</mi><mi>i</mi></msup><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">f(\mathbf{A})\mathbf{b} \approx p_k(\mathbf{A})\mathbf{b} = \sum_{i=0}^k c_i \mathbf{A}^i \mathbf{b}</annotation></semantics></math></span></span></span>
<p>This polynomial only involves vectors within a specific subspace.</p>
<h2 id="krylov-projection">Krylov Projection</h2>
<p>We can notice that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>k</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo stretchy="false">)</mo><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">p_k(\mathbf{A})\mathbf{b}</annotation></semantics></math></span></span> only depends on vectors in the Krylov subspace of order <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span></p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="script">K</mi><mi>k</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo separator="true">,</mo><mi mathvariant="bold">b</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>span</mtext><mo stretchy="false">{</mo><mi mathvariant="bold">b</mi><mo separator="true">,</mo><mrow><mi mathvariant="bold">A</mi><mi mathvariant="bold">b</mi></mrow><mo separator="true">,</mo><msup><mi mathvariant="bold">A</mi><mn>2</mn></msup><mi mathvariant="bold">b</mi><mo separator="true">,</mo><mo>‚Ä¶</mo><mo separator="true">,</mo><msup><mi mathvariant="bold">A</mi><mrow><mi>k</mi><mo>‚àí</mo><mn>1</mn></mrow></msup><mi mathvariant="bold">b</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\mathcal{K}_k(\mathbf{A}, \mathbf{b}) = \text{span}\{\mathbf{b}, \mathbf{Ab}, \mathbf{A}^2\mathbf{b}, \ldots, \mathbf{A}^{k-1}\mathbf{b}\}</annotation></semantics></math></span></span></span>
<p>This is fortunate: we can compute an approximate solution by staying within this space, which only requires repeated matrix-vector products with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span>. For large sparse matrices, that‚Äôs the only operation we can do efficiently anyway.</p>
<blockquote>
<p>We don‚Äôt need to construct <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="bold">A</mi><mi>j</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{A}^j</annotation></semantics></math></span></span> explicitly. We compute iteratively: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi><mo stretchy="false">(</mo><msup><mi mathvariant="bold">A</mi><mrow><mi>j</mi><mo>‚àí</mo><mn>1</mn></mrow></msup><mi mathvariant="bold">b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathbf{A}(\mathbf{A}^{j-1}\mathbf{b})</annotation></semantics></math></span></span>.</p>
</blockquote>
<p>But there‚Äôs a problem: the raw vectors <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msup><mi mathvariant="bold">A</mi><mi>j</mi></msup><mi mathvariant="bold">b</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\mathbf{A}^j\mathbf{b}\}</annotation></semantics></math></span></span> form a terrible basis. They quickly become nearly parallel, making any computation numerically unstable. We need an orthonormal basis.</p>
<h3 id="building-an-orthonormal-basis">Building an Orthonormal Basis</h3>
<p>The standard method is the Arnoldi process, which is Gram-Schmidt applied to Krylov subspaces. We start by normalizing <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mn>1</mn></msub><mo>=</mo><mi mathvariant="bold">b</mi><mi mathvariant="normal">/</mi><mi mathvariant="normal">‚à•</mi><mi mathvariant="bold">b</mi><msub><mi mathvariant="normal">‚à•</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_1 = \mathbf{b} / \|\mathbf{b}\|_2</annotation></semantics></math></span></span>. Then, iteratively:</p>
<ol>
<li>Compute a new candidate: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">w</mi><mi>j</mi></msub><mo>=</mo><mi mathvariant="bold">A</mi><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{w}_j = \mathbf{A}\mathbf{v}_j</annotation></semantics></math></span></span></li>
<li>Orthogonalize against all existing basis vectors:</li>
</ol>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mi>j</mi></msub><mo>=</mo><msub><mi mathvariant="bold">w</mi><mi>j</mi></msub><mo>‚àí</mo><munderover><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>j</mi></munderover><mo stretchy="false">(</mo><msubsup><mi mathvariant="bold">v</mi><mi>i</mi><mi>H</mi></msubsup><msub><mi mathvariant="bold">w</mi><mi>j</mi></msub><mo stretchy="false">)</mo><msub><mi mathvariant="bold">v</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\tilde{\mathbf{v}}_j = \mathbf{w}_j - \sum_{i=1}^j (\mathbf{v}_i^H \mathbf{w}_j) \mathbf{v}_i</annotation></semantics></math></span></span></span>
<ol start="3">
<li>Normalize: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mi>j</mi></msub><mi mathvariant="normal">/</mi><mi mathvariant="normal">‚à•</mi><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mi>j</mi></msub><msub><mi mathvariant="normal">‚à•</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{j+1} = \tilde{\mathbf{v}}_j / \|\tilde{\mathbf{v}}_j\|_2</annotation></semantics></math></span></span></li>
</ol>
<p>The coefficients <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><msubsup><mi mathvariant="bold">v</mi><mi>i</mi><mi>H</mi></msubsup><msub><mi mathvariant="bold">w</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">h_{ij} = \mathbf{v}_i^H \mathbf{w}_j</annotation></semantics></math></span></span> become entries of a projected matrix. After <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> iterations, we have:</p>
<ul>
<li><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><mo>=</mo><mo stretchy="false">[</mo><msub><mi mathvariant="bold">v</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>‚Ä¶</mo><mo separator="true">,</mo><msub><mi mathvariant="bold">v</mi><mi>k</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\mathbf{V}_k = [\mathbf{v}_1, \ldots, \mathbf{v}_k]</annotation></semantics></math></span></span>: an orthonormal basis for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">K</mi><mi>k</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">A</mi><mo separator="true">,</mo><mi mathvariant="bold">b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{K}_k(\mathbf{A}, \mathbf{b})</annotation></semantics></math></span></span></li>
<li><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">H</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{H}_k</annotation></semantics></math></span></span>: an upper Hessenberg matrix representing the projection of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> onto this subspace</li>
</ul>
<p>We can express this relationship with the Arnoldi decomposition:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">A</mi><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><mo>=</mo><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><msub><mi mathvariant="bold">H</mi><mi>k</mi></msub><mo>+</mo><msub><mi>h</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn><mo separator="true">,</mo><mi>k</mi></mrow></msub><msub><mi mathvariant="bold">v</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><msubsup><mi mathvariant="bold">e</mi><mi>k</mi><mi>T</mi></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{A}\mathbf{V}_k = \mathbf{V}_k \mathbf{H}_k + h_{k+1,k} \mathbf{v}_{k+1} \mathbf{e}_k^T</annotation></semantics></math></span></span></span>
<h3 id="solving-in-the-reduced-space">Solving in the Reduced Space</h3>
<p>Now we approximate our original problem by solving it in the small <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>-dimensional space. Using the Full Orthogonal Method (FOM), we enforce that the residual is orthogonal to
the Krylov subspace. This gives:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub><mo>=</mo><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k = \mathbf{V}_k \mathbf{y}_k</annotation></semantics></math></span></span></span>
<p>where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_k</annotation></semantics></math></span></span> is computed as:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">H</mi><mi>k</mi></msub><mo stretchy="false">)</mo><msub><mi mathvariant="bold">e</mi><mn>1</mn></msub><mi mathvariant="normal">‚à•</mi><mi mathvariant="bold">b</mi><msub><mi mathvariant="normal">‚à•</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_k = f(\mathbf{H}_k) \mathbf{e}_1 \|\mathbf{b}\|_2</annotation></semantics></math></span></span></span>
<p>The heavy lifting is now on computing <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">H</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\mathbf{H}_k)</annotation></semantics></math></span></span>, a small <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>√ó</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">k \times k</annotation></semantics></math></span></span> matrix.
Since <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>‚â™</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">k \ll n</annotation></semantics></math></span></span>, we can afford direct methods like Schur-Parlett (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>k</mi><mn>3</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(k^3)</annotation></semantics></math></span></span>).</p>
<blockquote>
<p>For <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>z</mi><mrow><mo>‚àí</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">f(z) = z^{-1}</annotation></semantics></math></span></span> (linear systems), this reduces to solving <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">H</mi><mi>k</mi></msub><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub><mo>=</mo><msub><mi mathvariant="bold">e</mi><mn>1</mn></msub><mi mathvariant="normal">‚à•</mi><mi mathvariant="bold">b</mi><msub><mi mathvariant="normal">‚à•</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{H}_k \mathbf{y}_k = \mathbf{e}_1 \|\mathbf{b}\|_2</annotation></semantics></math></span></span> with LU decomposition.</p>
</blockquote>
<h2 id="the-lanczos-algorithm">The Lanczos Algorithm</h2>
<p>When <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> is Hermitian (or symmetric in the real case), the general Arnoldi
process simplifies dramatically. We can prove that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">H</mi><mi>k</mi></msub><mo>=</mo><msubsup><mi mathvariant="bold">V</mi><mi>k</mi><mi>H</mi></msubsup><mi mathvariant="bold">A</mi><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{H}_k = \mathbf{V}_k^H \mathbf{A} \mathbf{V}_k</annotation></semantics></math></span></span> must also be Hermitian. A matrix that is both upper Hessenberg <em>and</em> Hermitian must be real, symmetric, and tridiagonal. This is a <em>huge</em> simplification.</p>
<p>In the literature, this projected matrix is denoted <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{T}_k</annotation></semantics></math></span></span> to highlight its
tridiagonal structure:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub><mo>=</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.16em" columnalign="center center center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>Œ±</mi><mn>1</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>Œ≤</mi><mn>1</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>Œ≤</mi><mn>1</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>Œ±</mi><mn>2</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>Œ≤</mi><mn>2</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>Œ≤</mi><mn>2</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mo lspace="0em" rspace="0em">‚ã±</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mo lspace="0em" rspace="0em">‚ã±</mo></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mo lspace="0em" rspace="0em">‚ã±</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>Œ±</mi><mi>k</mi></msub></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{T}_k = \begin{pmatrix}
\alpha_1 &amp; \beta_1 &amp; &amp; \\
\beta_1 &amp; \alpha_2 &amp; \beta_2 &amp; \\
&amp; \beta_2 &amp; \ddots &amp; \ddots \\
&amp; &amp; \ddots &amp; \alpha_k
\end{pmatrix}</annotation></semantics></math></span></span></span>
<p>where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ±</mi><mi>j</mi></msub><mo>‚àà</mo><mi mathvariant="double-struck">R</mi></mrow><annotation encoding="application/x-tex">\alpha_j \in \mathbb{R}</annotation></semantics></math></span></span> are the diagonal elements and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ≤</mi><mi>j</mi></msub><mo>‚àà</mo><mi mathvariant="double-struck">R</mi></mrow><annotation encoding="application/x-tex">\beta_j \in \mathbb{R}</annotation></semantics></math></span></span> are the off-diagonals (subdiagonals from the orthogonalization).</p>
<h2 id="three-term-recurrence">Three-Term Recurrence</h2>
<p>This tridiagonal structure leads to a beautiful simplification. To build the next basis
vector <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{j+1}</annotation></semantics></math></span></span>, we don‚Äôt need the entire history of vectors. We only need
the two previous ones. Since <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> is Hermitian, this guarantees that
any new vector is <em>automatically</em> orthogonal to all earlier vectors (beyond the previous two). So we can skip the full orthogonalization and use a simple three-term recurrence:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">A</mi><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub><mo>=</mo><msub><mi>Œ≤</mi><mrow><mi>j</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>Œ±</mi><mi>j</mi></msub><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub><mo>+</mo><msub><mi>Œ≤</mi><mi>j</mi></msub><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf{A}\mathbf{v}_j = \beta_{j-1}\mathbf{v}_{j-1} + \alpha_j \mathbf{v}_j + \beta_j \mathbf{v}_{j+1}</annotation></semantics></math></span></span></span>
<p>Rearranging gives us an algorithm to compute <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{j+1}</annotation></semantics></math></span></span> directly:</p>
<ol>
<li>Compute the candidate: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi mathvariant="bold">A</mi><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">w_{j+1} = \mathbf{A}\mathbf{v}_j</annotation></semantics></math></span></span></li>
<li>Extract the diagonal coefficient: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ±</mi><mi>j</mi></msub><mo>=</mo><msubsup><mi mathvariant="bold">v</mi><mi>j</mi><mi>H</mi></msubsup><msub><mi>w</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\alpha_j = \mathbf{v}_j^H w_{j+1}</annotation></semantics></math></span></span></li>
<li>Orthogonalize against the two previous vectors:</li>
</ol>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>w</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>‚àí</mo><msub><mi>Œ±</mi><mi>j</mi></msub><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub><mo>‚àí</mo><msub><mi>Œ≤</mi><mrow><mi>j</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>‚àí</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\tilde{\mathbf{v}}_{j+1} = w_{j+1} - \alpha_j \mathbf{v}_j - \beta_{j-1}\mathbf{v}_{j-1}</annotation></semantics></math></span></span></span>
<ol start="4">
<li>Normalize: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ≤</mi><mi>j</mi></msub><mo>=</mo><mi mathvariant="normal">‚à•</mi><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><msub><mi mathvariant="normal">‚à•</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\beta_j = \|\tilde{\mathbf{v}}_{j+1}\|_2</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">/</mi><msub><mi>Œ≤</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{j+1} = \tilde{\mathbf{v}}_{j+1} / \beta_j</annotation></semantics></math></span></span></li>
</ol>
<p>This is known as the Lanczos algorithm. It‚Äôs more efficient than Arnoldi because each iteration only orthogonalizes against two previous vectors instead of all prior ones.</p>
<h2 id="reconstructing-the-solution">Reconstructing the Solution</h2>
<p>After <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> iterations, we end up with the tridiagonal matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{T}_k</annotation></semantics></math></span></span> and all <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> basis vectors <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><mo>=</mo><mo stretchy="false">[</mo><msub><mi mathvariant="bold">v</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>‚Ä¶</mo><mo separator="true">,</mo><msub><mi mathvariant="bold">v</mi><mi>k</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\mathbf{V}_k = [\mathbf{v}_1, \ldots, \mathbf{v}_k]</annotation></semantics></math></span></span>. We can then reconstruct the approximate solution as:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub><mo>=</mo><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k = \mathbf{V}_k \mathbf{y}_k</annotation></semantics></math></span></span></span>
<p>where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub><mo stretchy="false">)</mo><msub><mi mathvariant="bold">e</mi><mn>1</mn></msub><mi mathvariant="normal">‚à•</mi><mi mathvariant="bold">b</mi><msub><mi mathvariant="normal">‚à•</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_k = f(\mathbf{T}_k) \mathbf{e}_1 \|\mathbf{b}\|_2</annotation></semantics></math></span></span> is solved from the small tridiagonal matrix.</p>
<p>There is a timing problem however: we cannot compute the coefficients <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_k</annotation></semantics></math></span></span>
until all <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> iterations are complete. The full matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{T}_k</annotation></semantics></math></span></span> is only available
at the end, so we must store every basis vector <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_j</annotation></semantics></math></span></span> along the way, leading to a memory cost of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(nk)</annotation></semantics></math></span></span>.</p>
<p>So we‚Äôre left with a choice: whether we store all the basis vectors and solve the problem in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> passes, or find a way to avoid storing them. There is a middle ground.</p>
<blockquote>
<p>There are also techniques to compress the basis vectors, have a look <a href="https://arxiv.org/abs/2403.04390">here</a></p>
</blockquote>
<h2 id="two-pass-algorithm">Two-Pass Algorithm</h2>
<p>Here‚Äôs where we break the timing deadlock. The insight that we don‚Äôt actually need to store the basis vectors if we can afford to compute them twice</p>
<p>Think about what we have after the first pass. We‚Äôve computed all the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ±</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_j</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ≤</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math></span></span> coefficients that compose the entire tridiagonal matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{T}_k</annotation></semantics></math></span></span>. These numbers are small compared to the full basis. What if we kept only these scalars, discarded all the vectors, and then replayed the Lanczos recurrence a second time? We‚Äôd regenerate the same basis, and this time we‚Äôd use it to build the solution.</p>
<p>This comes at a cost. We run Lanczos twice, so we pay for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>k</mi></mrow><annotation encoding="application/x-tex">2k</annotation></semantics></math></span></span> matrix-vector products instead of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>. But we only ever store a constant number of vectors in memory, no <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(nk)</annotation></semantics></math></span></span> basis matrix. The memory complexity drops to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span></span>.</p>
<p>It sounds like a bad trade at first. But as we‚Äôll see later, the cache behavior of this
two-pass approach can actually make it as fast (or even faster) on real hardware if well optimized.</p>
<h2 id="first-pass-compute-the-projected-problem">First Pass: Compute the Projected Problem</h2>
<p>We initialize <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mn>1</mn></msub><mo>=</mo><mi mathvariant="bold">b</mi><mi mathvariant="normal">/</mi><mi mathvariant="normal">‚à•</mi><mi mathvariant="bold">b</mi><msub><mi mathvariant="normal">‚à•</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_1 = \mathbf{b} / \|\mathbf{b}\|_2</annotation></semantics></math></span></span> and set <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ≤</mi><mn>0</mn></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\beta_0 = 0</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mn>0</mn></msub><mo>=</mo><mn mathvariant="bold">0</mn></mrow><annotation encoding="application/x-tex">\mathbf{v}_0 = \mathbf{0}</annotation></semantics></math></span></span>.Then we run the standard Lanczos recurrence:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>w</mi><mi>j</mi></msub><mo>=</mo><mi mathvariant="bold">A</mi><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">w_j = \mathbf{A}\mathbf{v}_j</annotation></semantics></math></span></span></span>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>Œ±</mi><mi>j</mi></msub><mo>=</mo><msubsup><mi mathvariant="bold">v</mi><mi>j</mi><mi>H</mi></msubsup><msub><mi>w</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_j = \mathbf{v}_j^H w_j</annotation></semantics></math></span></span></span>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>w</mi><mi>j</mi></msub><mo>‚àí</mo><msub><mi>Œ±</mi><mi>j</mi></msub><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub><mo>‚àí</mo><msub><mi>Œ≤</mi><mrow><mi>j</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>‚àí</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\tilde{\mathbf{v}}_{j+1} = w_j - \alpha_j \mathbf{v}_j - \beta_{j-1}\mathbf{v}_{j-1}</annotation></semantics></math></span></span></span>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>Œ≤</mi><mi>j</mi></msub><mo>=</mo><mi mathvariant="normal">‚à•</mi><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><msub><mi mathvariant="normal">‚à•</mi><mn>2</mn></msub><mo separator="true">,</mo><mspace width="1em"></mspace><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mover accent="true"><mi mathvariant="bold">v</mi><mo>~</mo></mover><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">/</mi><msub><mi>Œ≤</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j = \|\tilde{\mathbf{v}}_{j+1}\|_2, \quad \mathbf{v}_{j+1} = \tilde{\mathbf{v}}_{j+1} / \beta_j</annotation></semantics></math></span></span></span>
<p>At each step, we record <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ±</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_j</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ≤</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math></span></span>. But we <em>do not</em> store <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_j</annotation></semantics></math></span></span>.
Instead, we discard it immediately after computing <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{j+1}</annotation></semantics></math></span></span>. In this way we only keep in memory at most just three vectors at any time (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>‚àí</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{j-1}</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_j</annotation></semantics></math></span></span>, and the working vector <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">w_j</annotation></semantics></math></span></span>).</p>
<p>After <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> iterations, we have the full set <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>Œ±</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>Œ≤</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>‚Ä¶</mo><mo separator="true">,</mo><msub><mi>Œ±</mi><mi>k</mi></msub><mo separator="true">,</mo><msub><mi>Œ≤</mi><mi>k</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\alpha_1, \beta_1, \ldots, \alpha_k, \beta_k\}</annotation></semantics></math></span></span>. These <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(k)</annotation></semantics></math></span></span> scalars define the tridiagonal matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{T}_k</annotation></semantics></math></span></span>. We can now solve:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub><mo stretchy="false">)</mo><msub><mi mathvariant="bold">e</mi><mn>1</mn></msub><mi mathvariant="normal">‚à•</mi><mi mathvariant="bold">b</mi><msub><mi mathvariant="normal">‚à•</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_k = f(\mathbf{T}_k) \mathbf{e}_1 \|\mathbf{b}\|_2</annotation></semantics></math></span></span></span>
<p>This is the solution in the reduced space. Now that we have the coefficients we need to build <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k</annotation></semantics></math></span></span>.</p>
<h2 id="second-pass-reconstruct-and-accumulate">Second Pass: Reconstruct and Accumulate</h2>
<p>With <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_k</annotation></semantics></math></span></span> in memory, we replay the Lanczos recurrence <em>exactly as before</em>. We start with the same initialization (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_1</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ≤</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\beta_0</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_0</annotation></semantics></math></span></span>) and apply the same sequence of operations, using the stored scalars <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ±</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_j</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ≤</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math></span></span> to reconstruct each basis vector on demand. We can write some rust-like <em>pseudocode</em> for this second pass to get a feel for it:</p>
<pre tabindex="0" data-language="rust"><code><span><span>let</span><span> mut</span><span> x_k</span><span> =</span><span> vec!</span><span>[</span><span>0</span><span>.</span><span>0</span><span>; </span><span>n</span><span>];</span></span>
<span><span>let</span><span> mut</span><span> v_prev</span><span> =</span><span> vec!</span><span>[</span><span>0</span><span>.</span><span>0</span><span>; </span><span>n</span><span>];</span></span>
<span><span>let</span><span> mut</span><span> v_curr</span><span> =</span><span> b</span><span>.</span><span>clone</span><span>() </span><span>/</span><span> b_norm</span><span>;</span></span>
<span></span>
<span><span>for</span><span> j</span><span> in</span><span> 1</span><span>..=</span><span>k</span><span> {</span></span>
<span><span>    let</span><span> w</span><span> =</span><span> A</span><span> @</span><span> v_curr</span><span>;  </span><span>// Matrix-vector product</span></span>
<span></span>
<span><span>    // We don't recompute alpha/beta; we already have them from pass 1</span></span>
<span><span>    let</span><span> alpha_j</span><span> =</span><span> alphas</span><span>[</span><span>j</span><span> -</span><span> 1</span><span>];</span></span>
<span><span>    let</span><span> beta_prev</span><span> =</span><span> j</span><span> &gt;</span><span> 1</span><span> ?</span><span> betas</span><span>[</span><span>j</span><span> -</span><span> 2</span><span>] </span><span>:</span><span> 0</span><span>.</span><span>0</span><span>;</span></span>
<span></span>
<span><span>    // Accumulate the solution</span></span>
<span><span>    x_k</span><span> +=</span><span> y_k</span><span>[</span><span>j</span><span> -</span><span> 1</span><span>] </span><span>*</span><span> v_curr</span><span>;</span></span>
<span></span>
<span><span>    // Regenerate the next basis vector for the *next* iteration</span></span>
<span><span>    let</span><span> v_next</span><span> =</span><span> (</span><span>w</span><span> -</span><span> alpha_j</span><span> *</span><span> v_curr</span><span> -</span><span> beta_prev</span><span> *</span><span> v_prev</span><span>) </span><span>/</span><span> betas</span><span>[</span><span>j</span><span> -</span><span> 1</span><span>];</span></span>
<span></span>
<span><span>    // Slide the window forward</span></span>
<span><span>    v_prev</span><span> =</span><span> v_curr</span><span>;</span></span>
<span><span>    v_curr</span><span> =</span><span> v_next</span><span>;</span></span>
<span><span>}</span></span></code></pre>
<p>This loop regenerates each <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_j</annotation></semantics></math></span></span> on demand and immediately uses it to update the solution.
Once we‚Äôve accumulated <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub><msub><mo stretchy="false">)</mo><mi>j</mi></msub><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">(\mathbf{y}_k)_j \mathbf{v}_j</annotation></semantics></math></span></span> into <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k</annotation></semantics></math></span></span>, we discard the vector. We never store the full basis.</p>
<h3 id="a-subtle-numerical-point">A Subtle Numerical Point</h3>
<p>There is one detail worth noting: floating-point arithmetic is deterministic. When we replay the Lanczos recurrence in the second pass with the exact same inputs and the exact same order of operations, we get bitwise-identical vectors. The <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_j</annotation></semantics></math></span></span> regenerated in pass 2 are identical to the ones computed in pass 1.</p>
<p>However, the order in which we accumulate the solution differs. In a standard Lanczos,
<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k</annotation></semantics></math></span></span> is built as a single matrix-vector product: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub><mo>=</mo><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k = \mathbf{V}_k \mathbf{y}_k</annotation></semantics></math></span></span> (a <code>gemv</code> call in BLAS). In the two-pass method, it‚Äôs built as a loop of scaled vector additions (a series of <code>axpy</code> calls). These operations accumulate rounding error differently, so the final solution differs slightly, typically by machine epsilon. This rarely matters in practice, and convergence is unaffected.</p>
<h2 id="implementation">Implementation</h2>
<p>Building this in Rust forces us to think concretely about where data lives and how it flows through the cache hierarchy. We need to control memory layout, decide when allocations happen, and choose abstractions that cost us nothing at runtime.</p>
<p>For linear algebra, we reach for <a href="https://github.com/sarah-ek/faer-rs"><code>faer</code></a>. Three design choices in this library matter for what we‚Äôre building:</p>
<ul>
<li><strong>Stack allocation via <code>MemStack</code>:</strong> Pre-allocated scratch space that lives for the entire computation. The hot path becomes allocation-free.</li>
<li><strong>Matrix-free operators:</strong> The <code>LinOp</code> trait defines an operator by its action (<code>apply</code>) without materializing a matrix. For large sparse problems, this is the only viable approach.</li>
<li><strong>SIMD-friendly loops:</strong> The <code>zip!</code> macro generates code that compiles to packed instructions.</li>
</ul>
<h2 id="recurrence-step">Recurrence Step</h2>
<p>Our starting point is the Lanczos three-term recurrence that we derived earlier:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>Œ≤</mi><mi>j</mi></msub><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi mathvariant="bold">A</mi><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub><mo>‚àí</mo><msub><mi>Œ±</mi><mi>j</mi></msub><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub><mo>‚àí</mo><msub><mi>Œ≤</mi><mrow><mi>j</mi><mo>‚àí</mo><mn>1</mn></mrow></msub><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>‚àí</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\beta_j \mathbf{v}_{j+1} = \mathbf{A}\mathbf{v}_j - \alpha_j \mathbf{v}_j - \beta_{j-1}\mathbf{v}_{j-1}</annotation></semantics></math></span></span></span>
<p>We can translate this into a recurrence step function. The signature looks like this:</p>
<pre tabindex="0" data-language="rust"><code><span><span>fn</span><span> lanczos_recurrence_step</span><span>&lt;</span><span>T</span><span>:</span><span> ComplexField</span><span>, </span><span>O</span><span>:</span><span> LinOp</span><span>&lt;</span><span>T</span><span>&gt;&gt;(</span></span>
<span><span>    operator</span><span>:</span><span> &amp;</span><span>O</span><span>,</span></span>
<span><span>    mut</span><span> w</span><span>:</span><span> MatMut</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    v_curr</span><span>:</span><span> MatRef</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    v_prev</span><span>:</span><span> MatRef</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    beta_prev</span><span>:</span><span> T</span><span>::</span><span>Real</span><span>,</span></span>
<span><span>    stack</span><span>:</span><span> &amp;</span><span>mut</span><span> MemStack</span><span>,</span></span>
<span><span>) </span><span>-&gt;</span><span> (T</span><span>::</span><span>Real</span><span>, </span><span>Option</span><span>&lt;</span><span>T</span><span>::</span><span>Real</span><span>&gt;)</span></span></code></pre>
<p>The function is generic over the field type <code>T</code> (<code>f64</code>, <code>c64</code>, etc.) and the operator type <code>O</code>. It operates on matrix views (<code>MatMut</code> and <code>MatRef</code>) to avoid unnecessary data copies. The return type gives us the diagonal element <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ±</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_j</annotation></semantics></math></span></span> and, <em>if no breakdown occurs</em>, the off-diagonal <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ≤</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math></span></span>.</p>
<p>Now we can implement the body by following the math. The first step is the most expensive:</p>
<pre tabindex="0" data-language="rust"><code><span><span>// 1. Apply operator: w = A * v_curr</span></span>
<span><span>operator</span><span>.</span><span>apply</span><span>(</span><span>w</span><span>.</span><span>rb_mut</span><span>(), </span><span>v_curr</span><span>, Par</span><span>::</span><span>Seq</span><span>, </span><span>stack</span><span>);</span></span></code></pre>
<p>The matrix-vector product dominates the computational cost. Everything else is secondary.</p>
<p>Next, we orthogonalize against <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mrow><mi>j</mi><mo>‚àí</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{j-1}</annotation></semantics></math></span></span>. This is where we benefit from <code>faer</code>‚Äôs design. The <code>zip!</code> macro fuses this operation into a single loop that the compiler vectorizes into SIMD instructions.</p>
<pre tabindex="0" data-language="rust"><code><span><span>// 2. Orthogonalize against v_{j-1}: w -= Œ≤_{j-1} * v_{j-1}</span></span>
<span><span>let</span><span> beta_prev_scaled</span><span> =</span><span> T</span><span>::</span><span>from_real_impl</span><span>(</span><span>&amp;</span><span>beta_prev</span><span>);</span></span>
<span><span>zip!</span><span>(</span><span>w</span><span>.</span><span>rb_mut</span><span>(), </span><span>v_prev</span><span>)</span><span>.</span><span>for_each</span><span>(</span><span>|</span><span>unzip!</span><span>(</span><span>w_i</span><span>, </span><span>v_prev_i</span><span>)</span><span>|</span><span> {</span></span>
<span><span>    *</span><span>w_i</span><span> =</span><span> sub</span><span>(</span><span>w_i</span><span>, </span><span>&amp;</span><span>mul</span><span>(</span><span>&amp;</span><span>beta_prev_scaled</span><span>, </span><span>v_prev_i</span><span>));</span></span>
<span><span>});</span></span></code></pre>
<p>With <code>w</code> partially orthogonalized, we can compute the diagonal coefficient via an inner product. Since <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> is Hermitian, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ±</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_j</annotation></semantics></math></span></span> is guaranteed real.</p>
<pre tabindex="0" data-language="rust"><code><span><span>// 3. Compute Œ±_j = v_j^H * w</span></span>
<span><span>let</span><span> alpha</span><span> =</span><span> T</span><span>::</span><span>real_part_impl</span><span>(</span><span>&amp;</span><span>(</span><span>v_curr</span><span>.</span><span>adjoint</span><span>() </span><span>*</span><span> w</span><span>.</span><span>rb</span><span>())[(</span><span>0</span><span>, </span><span>0</span><span>)]);</span></span></code></pre>
<p>We complete the orthogonalization against <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_j</annotation></semantics></math></span></span> with another <code>zip!</code> loop.</p>
<pre tabindex="0" data-language="rust"><code><span><span>// 4. Orthogonalize against v_j: w -= Œ±_j * v_j</span></span>
<span><span>let</span><span> alpha_scaled</span><span> =</span><span> T</span><span>::</span><span>from_real_impl</span><span>(</span><span>&amp;</span><span>alpha</span><span>);</span></span>
<span><span>zip!</span><span>(</span><span>w</span><span>.</span><span>rb_mut</span><span>(), </span><span>v_curr</span><span>)</span><span>.</span><span>for_each</span><span>(</span><span>|</span><span>unzip!</span><span>(</span><span>w_i</span><span>, </span><span>v_curr_i</span><span>)</span><span>|</span><span> {</span></span>
<span><span>    *</span><span>w_i</span><span> =</span><span> sub</span><span>(</span><span>w_i</span><span>, </span><span>&amp;</span><span>mul</span><span>(</span><span>&amp;</span><span>alpha_scaled</span><span>, </span><span>v_curr_i</span><span>));</span></span>
<span><span>});</span></span></code></pre>
<p>Now <code>w</code> holds the unnormalized next basis vector. We compute its norm to get <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ≤</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math></span></span>. If this norm is numerically zero, the Krylov subspace is invariant, the iteration has reached its natural stopping point. This is called breakdown.</p>
<pre tabindex="0" data-language="rust"><code><span><span>// 5. Compute Œ≤_j = ||w||_2 and check for breakdown</span></span>
<span><span>let</span><span> beta</span><span> =</span><span> w</span><span>.</span><span>rb</span><span>()</span><span>.</span><span>norm_l2</span><span>();</span></span>
<span><span>let</span><span> tolerance</span><span> =</span><span> breakdown_tolerance</span><span>::</span><span>&lt;T</span><span>::</span><span>Real</span><span>&gt;();</span></span>
<span></span>
<span><span>if</span><span> beta</span><span> &lt;=</span><span> tolerance</span><span> {</span></span>
<span><span>    (</span><span>alpha</span><span>, </span><span>None</span><span>)</span></span>
<span><span>} </span><span>else</span><span> {</span></span>
<span><span>    (</span><span>alpha</span><span>, </span><span>Some</span><span>(</span><span>beta</span><span>))</span></span>
<span><span>}</span></span></code></pre>
<p>The function returns <code>None</code> for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ≤</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math></span></span> when breakdown occurs, signaling to the caller that no further iterations should proceed.</p>
<h2 id="an-iterator-for-state-management">An Iterator for State Management</h2>
<p>The recurrence step is a pure function, but calling it in a loop is both inefficient and awkward. We‚Äôd need to manually pass vectors in and out of each iteration. More critically, we‚Äôd create copies when we should be reusing memory.</p>
<p>The iterator pattern solves this. We create a struct that encapsulates the state:</p>
<pre tabindex="0" data-language="rust"><code><span><span>struct</span><span> LanczosIteration</span><span>&lt;'</span><span>a</span><span>, </span><span>T</span><span>:</span><span> ComplexField</span><span>, </span><span>O</span><span>:</span><span> LinOp</span><span>&lt;</span><span>T</span><span>&gt;&gt; {</span></span>
<span><span>    operator</span><span>:</span><span> &amp;</span><span>'</span><span>a</span><span> O</span><span>,</span></span>
<span><span>    v_prev</span><span>:</span><span> Mat</span><span>&lt;</span><span>T</span><span>&gt;,       </span><span>// v_{j-1}</span></span>
<span><span>    v_curr</span><span>:</span><span> Mat</span><span>&lt;</span><span>T</span><span>&gt;,       </span><span>// v_j</span></span>
<span><span>    work</span><span>:</span><span> Mat</span><span>&lt;</span><span>T</span><span>&gt;,         </span><span>// Workspace for the next vector</span></span>
<span><span>    beta_prev</span><span>:</span><span> T</span><span>::</span><span>Real</span><span>,   </span><span>// Œ≤_{j-1}</span></span>
<span><span>    // ... iteration counters</span></span>
<span><span>}</span></span></code></pre>
<p>The main design choice here is that vectors are <strong>owned</strong> (<code>Mat&lt;T&gt;</code>), not borrowed. This enables an optimization in the <code>next_step</code> method. After computing the next vector and normalizing it into <code>work</code>, we cycle the state without allocating or copying:</p>
<pre tabindex="0" data-language="rust"><code><span><span>// Inside next_step, after normalization...</span></span>
<span><span>core</span><span>::</span><span>mem</span><span>::</span><span>swap</span><span>(</span><span>&amp;</span><span>mut</span><span> self</span><span>.</span><span>v_prev, </span><span>&amp;</span><span>mut</span><span> self</span><span>.</span><span>v_curr);</span></span>
<span><span>core</span><span>::</span><span>mem</span><span>::</span><span>swap</span><span>(</span><span>&amp;</span><span>mut</span><span> self</span><span>.</span><span>v_curr, </span><span>&amp;</span><span>mut</span><span> self</span><span>.</span><span>work);</span></span></code></pre>
<p>On x86-64, swapping two <code>Mat&lt;T&gt;</code> structures (fat pointers) compiles to three <code>mov</code> instructions. The pointers change, but no vector data moves. After the swap, <code>v_prev</code> points to what <code>v_curr</code> held, <code>v_curr</code> points to <code>work</code>‚Äôs allocation, and <code>work</code> points to the old <code>v_prev</code> data. In the next iteration, <code>work</code> gets reused.</p>
<p>We keep exactly three n-dimensional vectors live in memory. The same allocations cycle through the computation, staying hot in L1 cache. This is the core reason the two-pass method can be faster than expected, the working set never leaves cache.</p>
<h2 id="first-pass-computing-the-decomposition">First Pass: Computing the Decomposition</h2>
<p>The first pass runs the Lanczos iteration and collects the coefficients <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>Œ±</mi><mi>j</mi></msub><mo separator="true">,</mo><msub><mi>Œ≤</mi><mi>j</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\alpha_j, \beta_j\}</annotation></semantics></math></span></span>. Basis vectors are discarded after each step.</p>
<pre tabindex="0" data-language="rust"><code><span><span>pub</span><span> fn</span><span> lanczos_pass_one</span><span>&lt;</span><span>T</span><span>:</span><span> ComplexField</span><span>&gt;(</span></span>
<span><span>    operator</span><span>:</span><span> &amp;</span><span>impl</span><span> LinOp</span><span>&lt;</span><span>T</span><span>&gt;,</span></span>
<span><span>    b</span><span>:</span><span> MatRef</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    k</span><span>:</span><span> usize</span><span>,</span></span>
<span><span>    stack</span><span>:</span><span> &amp;</span><span>mut</span><span> MemStack</span><span>,</span></span>
<span><span>) </span><span>-&gt;</span><span> Result</span><span>&lt;</span><span>LanczosDecomposition</span><span>&lt;</span><span>T</span><span>::</span><span>Real</span><span>&gt;, </span><span>LanczosError</span><span>&gt; {</span></span>
<span><span>    // ...</span></span>
<span><span>}</span></span></code></pre>
<p>We allocate vectors for the coefficients with a capacity hint to avoid reallocations:</p>
<pre tabindex="0" data-language="rust"><code><span><span>let</span><span> mut</span><span> alphas</span><span> =</span><span> Vec</span><span>::</span><span>with_capacity</span><span>(</span><span>k</span><span>);</span></span>
<span><span>let</span><span> mut</span><span> betas</span><span> =</span><span> Vec</span><span>::</span><span>with_capacity</span><span>(</span><span>k</span><span> -</span><span> 1</span><span>);</span></span></code></pre>
<p>Then we construct the iterator. This allocates the three work vectors once. After this point, the hot path is allocation-free:</p>
<pre tabindex="0" data-language="rust"><code><span><span>let</span><span> mut</span><span> lanczos_iter</span><span> =</span><span> LanczosIteration</span><span>::</span><span>new</span><span>(</span><span>operator</span><span>, </span><span>b</span><span>, </span><span>k</span><span>, </span><span>b_norm</span><span>)</span><span>?</span><span>;</span></span>
<span></span>
<span><span>for</span><span> i</span><span> in</span><span> 0</span><span>..</span><span>k</span><span> {</span></span>
<span><span>    if</span><span> let</span><span> Some</span><span>(</span><span>step</span><span>) </span><span>=</span><span> lanczos_iter</span><span>.</span><span>next_step</span><span>(</span><span>stack</span><span>) {</span></span>
<span><span>        alphas</span><span>.</span><span>push</span><span>(</span><span>step</span><span>.</span><span>alpha);</span></span>
<span><span>        steps_taken</span><span> +=</span><span> 1</span><span>;</span></span>
<span></span>
<span><span>        let</span><span> tolerance</span><span> =</span><span> breakdown_tolerance</span><span>::</span><span>&lt;T</span><span>::</span><span>Real</span><span>&gt;();</span></span>
<span><span>        if</span><span> step</span><span>.</span><span>beta </span><span>&lt;=</span><span> tolerance</span><span> {</span></span>
<span><span>            break</span><span>;</span></span>
<span><span>        }</span></span>
<span></span>
<span><span>        if</span><span> i</span><span> &lt;</span><span> k</span><span> -</span><span> 1</span><span> {</span></span>
<span><span>            betas</span><span>.</span><span>push</span><span>(</span><span>step</span><span>.</span><span>beta);</span></span>
<span><span>        }</span></span>
<span><span>    } </span><span>else</span><span> {</span></span>
<span><span>        break</span><span>;</span></span>
<span><span>    }</span></span>
<span><span>}</span></span></code></pre>
<p>The check for breakdown stops the iteration when the residual becomes numerically zero. This means we‚Äôve found an invariant subspace and there‚Äôs no value in continuing.</p>
<p>At the end, we collect the scalars into a <code>LanczosDecomposition</code> struct. The memory footprint throughout this pass is constant: three n-dimensional vectors plus two small arrays that grow to at most <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> elements.</p>
<h2 id="second-pass-reconstructing-the-solution">Second Pass: Reconstructing the Solution</h2>
<p>Now we face a different problem. We have the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>Œ±</mi><mi>j</mi></msub><mo separator="true">,</mo><msub><mi>Œ≤</mi><mi>j</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\alpha_j, \beta_j\}</annotation></semantics></math></span></span> coefficients from the first pass and the coefficient vector <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub><mo stretchy="false">)</mo><msub><mi mathvariant="bold">e</mi><mn>1</mn></msub><mi mathvariant="normal">‚à•</mi><mi mathvariant="bold">b</mi><msub><mi mathvariant="normal">‚à•</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_k = f(\mathbf{T}_k) \mathbf{e}_1 \|\mathbf{b}\|_2</annotation></semantics></math></span></span> from solving the projected problem. We need to reconstruct the solution:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub><mo>=</mo><munderover><mo>‚àë</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mo stretchy="false">(</mo><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub><msub><mo stretchy="false">)</mo><mi>j</mi></msub><msub><mi mathvariant="bold">v</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k = \sum_{j=1}^k (\mathbf{y}_k)_j \mathbf{v}_j</annotation></semantics></math></span></span></span>
<p>without storing the full basis matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{V}_k</annotation></semantics></math></span></span>.</p>
<p>The recurrence step in this pass is structurally similar to the first pass, but with a key difference: we no longer compute inner products or norms. We already know the coefficients, so the step becomes pure reconstruction.</p>
<pre tabindex="0" data-language="rust"><code><span><span>fn</span><span> lanczos_reconstruction_step</span><span>&lt;</span><span>T</span><span>:</span><span> ComplexField</span><span>, </span><span>O</span><span>:</span><span> LinOp</span><span>&lt;</span><span>T</span><span>&gt;&gt;(</span></span>
<span><span>    operator</span><span>:</span><span> &amp;</span><span>O</span><span>,</span></span>
<span><span>    mut</span><span> w</span><span>:</span><span> MatMut</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    v_curr</span><span>:</span><span> MatRef</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    v_prev</span><span>:</span><span> MatRef</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    alpha_j</span><span>:</span><span> T</span><span>::</span><span>Real</span><span>,</span></span>
<span><span>    beta_prev</span><span>:</span><span> T</span><span>::</span><span>Real</span><span>,</span></span>
<span><span>    stack</span><span>:</span><span> &amp;</span><span>mut</span><span> MemStack</span><span>,</span></span>
<span><span>) {</span></span>
<span><span>    // Apply operator</span></span>
<span><span>    operator</span><span>.</span><span>apply</span><span>(</span><span>w</span><span>.</span><span>rb_mut</span><span>(), </span><span>v_curr</span><span>, Par</span><span>::</span><span>Seq</span><span>, </span><span>stack</span><span>);</span></span>
<span></span>
<span><span>    // Orthogonalize using stored Œ±_j and Œ≤_{j-1}</span></span>
<span><span>    let</span><span> beta_prev_scaled</span><span> =</span><span> T</span><span>::</span><span>from_real_impl</span><span>(</span><span>&amp;</span><span>beta_prev</span><span>);</span></span>
<span><span>    zip!</span><span>(</span><span>w</span><span>.</span><span>rb_mut</span><span>(), </span><span>v_prev</span><span>)</span><span>.</span><span>for_each</span><span>(</span><span>|</span><span>unzip!</span><span>(</span><span>w_i</span><span>, </span><span>v_prev_i</span><span>)</span><span>|</span><span> {</span></span>
<span><span>        *</span><span>w_i</span><span> =</span><span> sub</span><span>(</span><span>w_i</span><span>, </span><span>&amp;</span><span>mul</span><span>(</span><span>&amp;</span><span>beta_prev_scaled</span><span>, </span><span>v_prev_i</span><span>));</span></span>
<span><span>    });</span></span>
<span></span>
<span><span>    let</span><span> alpha_scaled</span><span> =</span><span> T</span><span>::</span><span>from_real_impl</span><span>(</span><span>&amp;</span><span>alpha_j</span><span>);</span></span>
<span><span>    zip!</span><span>(</span><span>w</span><span>.</span><span>rb_mut</span><span>(), </span><span>v_curr</span><span>)</span><span>.</span><span>for_each</span><span>(</span><span>|</span><span>unzip!</span><span>(</span><span>w_i</span><span>, </span><span>v_curr_i</span><span>)</span><span>|</span><span> {</span></span>
<span><span>        *</span><span>w_i</span><span> =</span><span> sub</span><span>(</span><span>w_i</span><span>, </span><span>&amp;</span><span>mul</span><span>(</span><span>&amp;</span><span>alpha_scaled</span><span>, </span><span>v_curr_i</span><span>));</span></span>
<span><span>    });</span></span>
<span><span>}</span></span></code></pre>
<p>This is cheaper than the first-pass recurrence. We‚Äôve eliminated the inner products that computed <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ±</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_j</annotation></semantics></math></span></span> and the norm calculation for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ≤</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math></span></span>. What remains is pure orthogonalization and the operator application.</p>
<p><code>lanczos_pass_two</code> implements this reconstruction. We initialize the three work vectors and the solution accumulator:</p>
<pre tabindex="0" data-language="rust"><code><span><span>pub</span><span> fn</span><span> lanczos_pass_two</span><span>&lt;</span><span>T</span><span>:</span><span> ComplexField</span><span>&gt;(</span></span>
<span><span>    operator</span><span>:</span><span> &amp;</span><span>impl</span><span> LinOp</span><span>&lt;</span><span>T</span><span>&gt;,</span></span>
<span><span>    b</span><span>:</span><span> MatRef</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    decomposition</span><span>:</span><span> &amp;</span><span>LanczosDecomposition</span><span>&lt;</span><span>T</span><span>::</span><span>Real</span><span>&gt;,</span></span>
<span><span>    y_k</span><span>:</span><span> MatRef</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    stack</span><span>:</span><span> &amp;</span><span>mut</span><span> MemStack</span><span>,</span></span>
<span><span>) </span><span>-&gt;</span><span> Result</span><span>&lt;</span><span>Mat</span><span>&lt;</span><span>T</span><span>&gt;, </span><span>LanczosError</span><span>&gt; {</span></span>
<span><span>    let</span><span> mut</span><span> v_prev</span><span> =</span><span> Mat</span><span>::</span><span>&lt;</span><span>T</span><span>&gt;</span><span>::</span><span>zeros</span><span>(</span><span>b</span><span>.</span><span>nrows</span><span>(), </span><span>1</span><span>);</span></span>
<span><span>    let</span><span> inv_norm</span><span> =</span><span> T</span><span>::</span><span>from_real_impl</span><span>(</span><span>&amp;</span><span>T</span><span>::</span><span>Real</span><span>::</span><span>recip_impl</span><span>(</span><span>&amp;</span><span>decomposition</span><span>.</span><span>b_norm));</span></span>
<span><span>    let</span><span> mut</span><span> v_curr</span><span> =</span><span> b</span><span> *</span><span> Scale</span><span>(</span><span>inv_norm</span><span>);  </span><span>// v_1</span></span>
<span></span>
<span><span>    let</span><span> mut</span><span> work</span><span> =</span><span> Mat</span><span>::</span><span>&lt;</span><span>T</span><span>&gt;</span><span>::</span><span>zeros</span><span>(</span><span>b</span><span>.</span><span>nrows</span><span>(), </span><span>1</span><span>);</span></span>
<span></span>
<span><span>    // Initialize solution with first component</span></span>
<span><span>    let</span><span> mut</span><span> x_k</span><span> =</span><span> &amp;</span><span>v_curr</span><span> *</span><span> Scale</span><span>(T</span><span>::</span><span>copy_impl</span><span>(</span><span>&amp;</span><span>y_k</span><span>[(</span><span>0</span><span>, </span><span>0</span><span>)]));</span></span></code></pre>
<p>We build the solution incrementally by starting with the first basis vector scaled by its coefficient. The main loop then regenerates each subsequent vector: we regenerate each subsequent basis vector, normalize it using the stored <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ≤</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math></span></span>, and immediately accumulate its contribution:</p>
<pre tabindex="0" data-language="rust"><code><span><span>for</span><span> j</span><span> in</span><span> 0</span><span>..</span><span>decomposition</span><span>.</span><span>steps_taken </span><span>-</span><span> 1</span><span> {</span></span>
<span><span>    let</span><span> alpha_j</span><span> =</span><span> T</span><span>::</span><span>Real</span><span>::</span><span>copy_impl</span><span>(</span><span>&amp;</span><span>decomposition</span><span>.</span><span>alphas[</span><span>j</span><span>]);</span></span>
<span><span>    let</span><span> beta_j</span><span> =</span><span> T</span><span>::</span><span>Real</span><span>::</span><span>copy_impl</span><span>(</span><span>&amp;</span><span>decomposition</span><span>.</span><span>betas[</span><span>j</span><span>]);</span></span>
<span><span>    let</span><span> beta_prev</span><span> =</span><span> if</span><span> j</span><span> ==</span><span> 0</span><span> {</span></span>
<span><span>        T</span><span>::</span><span>Real</span><span>::</span><span>zero_impl</span><span>()</span></span>
<span><span>    } </span><span>else</span><span> {</span></span>
<span><span>        T</span><span>::</span><span>Real</span><span>::</span><span>copy_impl</span><span>(</span><span>&amp;</span><span>decomposition</span><span>.</span><span>betas[</span><span>j</span><span> -</span><span> 1</span><span>])</span></span>
<span><span>    };</span></span>
<span></span>
<span><span>    // 1. Regenerate the unnormalized next vector</span></span>
<span><span>    lanczos_reconstruction_step</span><span>(</span></span>
<span><span>        operator</span><span>,</span></span>
<span><span>        work</span><span>.</span><span>as_mut</span><span>(),</span></span>
<span><span>        v_curr</span><span>.</span><span>as_ref</span><span>(),</span></span>
<span><span>        v_prev</span><span>.</span><span>as_ref</span><span>(),</span></span>
<span><span>        alpha_j</span><span>,</span></span>
<span><span>        beta_prev</span><span>,</span></span>
<span><span>        stack</span><span>,</span></span>
<span><span>    );</span></span>
<span></span>
<span><span>    // 2. Normalize using stored Œ≤_j</span></span>
<span><span>    let</span><span> inv_beta</span><span> =</span><span> T</span><span>::</span><span>from_real_impl</span><span>(</span><span>&amp;</span><span>T</span><span>::</span><span>Real</span><span>::</span><span>recip_impl</span><span>(</span><span>&amp;</span><span>beta_j</span><span>));</span></span>
<span><span>    zip!</span><span>(</span><span>work</span><span>.</span><span>as_mut</span><span>())</span><span>.</span><span>for_each</span><span>(</span><span>|</span><span>unzip!</span><span>(</span><span>w_i</span><span>)</span><span>|</span><span> {</span></span>
<span><span>        *</span><span>w_i</span><span> =</span><span> mul</span><span>(</span><span>w_i</span><span>, </span><span>&amp;</span><span>inv_beta</span><span>);</span></span>
<span><span>    });</span></span>
<span></span>
<span><span>    // 3. Accumulate: x_k += y_{j+1} * v_{j+1}</span></span>
<span><span>    let</span><span> coeff</span><span> =</span><span> T</span><span>::</span><span>copy_impl</span><span>(</span><span>&amp;</span><span>y_k</span><span>[(</span><span>j</span><span> +</span><span> 1</span><span>, </span><span>0</span><span>)]);</span></span>
<span><span>    zip!</span><span>(</span><span>x_k</span><span>.</span><span>as_mut</span><span>(), </span><span>work</span><span>.</span><span>as_ref</span><span>())</span><span>.</span><span>for_each</span><span>(</span><span>|</span><span>unzip!</span><span>(</span><span>x_i</span><span>, </span><span>v_i</span><span>)</span><span>|</span><span> {</span></span>
<span><span>        *</span><span>x_i</span><span> =</span><span> add</span><span>(</span><span>x_i</span><span>, </span><span>&amp;</span><span>mul</span><span>(</span><span>&amp;</span><span>coeff</span><span>, </span><span>v_i</span><span>));</span></span>
<span><span>    });</span></span>
<span></span>
<span><span>    // 4. Cycle vectors for the next iteration</span></span>
<span><span>    core</span><span>::</span><span>mem</span><span>::</span><span>swap</span><span>(</span><span>&amp;</span><span>mut</span><span> v_prev</span><span>, </span><span>&amp;</span><span>mut</span><span> v_curr</span><span>);</span></span>
<span><span>    core</span><span>::</span><span>mem</span><span>::</span><span>swap</span><span>(</span><span>&amp;</span><span>mut</span><span> v_curr</span><span>, </span><span>&amp;</span><span>mut</span><span> work</span><span>);</span></span>
<span><span>}</span></span></code></pre>
<p>The accumulation <code>x_k += y_{j+1} * v_{j+1}</code> is implemented as a fused multiply-add in the <code>zip!</code> loop. On hardware with FMA support, this becomes a single instruction per element, not three separate operations.</p>
<p>Note that we accumulate the solution incrementally. After each iteration, <code>x_k</code> contains a partial result. We cycle through the same three vectors (<code>v_prev</code>, <code>v_curr</code>, <code>work</code>), keeping the working set small and resident in L1 cache.</p>
<p>Compare this to the standard method‚Äôs final reconstruction step: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub><mo>=</mo><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k = \mathbf{V}_k \mathbf{y}_k</annotation></semantics></math></span></span>. This is a dense matrix-vector product where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{V}_k</annotation></semantics></math></span></span> is <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>√ó</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">n \times k</annotation></semantics></math></span></span>. When <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> are both large, this matrix no longer fits in cache. The CPU must stream it from main memory, paying the cost of memory latency. Each element requires a load, multiply, and accumulate, but the load operations dominate‚Äîthe CPU stalls waiting for data.</p>
<p>In our two-pass reconstruction, the operator <code>$\mathbf{A}$</code> is applied <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> times, but against vectors that stay in cache. The memory bandwidth is spent on reading the sparse structure of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> and the vector elements, not on scanning a dense <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>√ó</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">n \times k</annotation></semantics></math></span></span> matrix.</p>
<p>This is the reason the two-pass method can be faster on real hardware despite performing twice as many matrix-vector products. The cache behavior of the reconstruction phase overwhelms the savings of storing the basis.</p>
<h2 id="the-public-api">The Public API</h2>
<p>We can wrap the two passes into a single entry point:</p>
<pre tabindex="0" data-language="rust"><code><span><span>pub</span><span> fn</span><span> lanczos_two_pass</span><span>&lt;</span><span>T</span><span>, </span><span>O</span><span>, </span><span>F</span><span>&gt;(</span></span>
<span><span>    operator</span><span>:</span><span> &amp;</span><span>O</span><span>,</span></span>
<span><span>    b</span><span>:</span><span> MatRef</span><span>&lt;'</span><span>_</span><span>, </span><span>T</span><span>&gt;,</span></span>
<span><span>    k</span><span>:</span><span> usize</span><span>,</span></span>
<span><span>    stack</span><span>:</span><span> &amp;</span><span>mut</span><span> MemStack</span><span>,</span></span>
<span><span>    mut</span><span> f_tk_solver</span><span>:</span><span> F</span><span>,</span></span>
<span><span>) </span><span>-&gt;</span><span> Result</span><span>&lt;</span><span>Mat</span><span>&lt;</span><span>T</span><span>&gt;, </span><span>LanczosError</span><span>&gt;</span></span>
<span><span>where</span></span>
<span><span>    T</span><span>:</span><span> ComplexField</span><span>,</span></span>
<span><span>    O</span><span>:</span><span> LinOp</span><span>&lt;</span><span>T</span><span>&gt;,</span></span>
<span><span>    F</span><span>:</span><span> FnMut</span><span>(</span><span>&amp;</span><span>[T</span><span>::</span><span>Real</span><span>], </span><span>&amp;</span><span>[T</span><span>::</span><span>Real</span><span>]) </span><span>-&gt;</span><span> Result</span><span>&lt;</span><span>Mat</span><span>&lt;</span><span>T</span><span>&gt;, </span><span>anyhow</span><span>::</span><span>Error</span><span>&gt;,</span></span>
<span><span>{</span></span>
<span><span>    // First pass: compute T_k coefficients</span></span>
<span><span>    let</span><span> decomposition</span><span> =</span><span> lanczos_pass_one</span><span>(</span><span>operator</span><span>, </span><span>b</span><span>, </span><span>k</span><span>, </span><span>stack</span><span>)</span><span>?</span><span>;</span></span>
<span></span>
<span><span>    if</span><span> decomposition</span><span>.</span><span>steps_taken </span><span>==</span><span> 0</span><span> {</span></span>
<span><span>        return</span><span> Ok</span><span>(</span><span>Mat</span><span>::</span><span>zeros</span><span>(</span><span>b</span><span>.</span><span>nrows</span><span>(), </span><span>1</span><span>));</span></span>
<span><span>    }</span></span>
<span></span>
<span><span>    // Solve projected problem: y_k' = f(T_k) * e_1</span></span>
<span><span>    let</span><span> y_k_prime</span><span> =</span><span> f_tk_solver</span><span>(</span><span>&amp;</span><span>decomposition</span><span>.</span><span>alphas, </span><span>&amp;</span><span>decomposition</span><span>.</span><span>betas)</span><span>?</span><span>;</span></span>
<span></span>
<span><span>    // Scale by ||b||</span></span>
<span><span>    let</span><span> y_k</span><span> =</span><span> &amp;</span><span>y_k_prime</span><span> *</span><span> Scale</span><span>(T</span><span>::</span><span>from_real_impl</span><span>(</span><span>&amp;</span><span>decomposition</span><span>.</span><span>b_norm));</span></span>
<span></span>
<span><span>    // Second pass: reconstruct solution</span></span>
<span><span>    lanczos_pass_two</span><span>(</span><span>operator</span><span>, </span><span>b</span><span>, </span><span>&amp;</span><span>decomposition</span><span>, </span><span>y_k</span><span>.</span><span>as_ref</span><span>(), </span><span>stack</span><span>)</span></span>
<span><span>}</span></span></code></pre>
<p>The design separates concerns. The <code>f_tk_solver</code> closure is where we inject the specific matrix function. We compute the Lanczos decomposition, then pass the coefficients to the user-provided solver, which computes <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">y</mi><mi>k</mi><mo mathvariant="normal" lspace="0em" rspace="0em">‚Ä≤</mo></msubsup><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub><mo stretchy="false">)</mo><msub><mi mathvariant="bold">e</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_k' = f(\mathbf{T}_k) \mathbf{e}_1</annotation></semantics></math></span></span> for whatever function <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span></span> is needed. This decoupling means we handle linear solves, matrix exponentials, or any other function without modifying the core algorithm.</p>
<p>The caller provides <code>f_tk_solver</code> as a closure. It receives the raw <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>Œ±</mi><mi>j</mi></msub><mo separator="true">,</mo><msub><mi>Œ≤</mi><mi>j</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\alpha_j, \beta_j\}</annotation></semantics></math></span></span> arrays and must return the coefficient vector <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">y</mi><mi>k</mi><mo mathvariant="normal" lspace="0em" rspace="0em">‚Ä≤</mo></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{y}_k'</annotation></semantics></math></span></span>. We then scale it by <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">‚à•</mi><mi mathvariant="bold">b</mi><msub><mi mathvariant="normal">‚à•</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\|\mathbf{b}\|_2</annotation></semantics></math></span></span> and pass everything to the second pass.</p>
<h3 id="example-solving-a-linear-system">Example: Solving a Linear System</h3>
<p>To see this in practice, consider solving <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi mathvariant="bold">A</mi><mi mathvariant="bold">x</mi></mrow><mo>=</mo><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">\mathbf{Ax} = \mathbf{b}</annotation></semantics></math></span></span>. We compute <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>z</mi><mrow><mo>‚àí</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">f(z) = z^{-1}</annotation></semantics></math></span></span>, which means the <code>f_tk_solver</code> must solve the small tridiagonal system <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub><msup><mi mathvariant="bold">y</mi><mo mathvariant="normal" lspace="0em" rspace="0em">‚Ä≤</mo></msup><mo>=</mo><msub><mi mathvariant="bold">e</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{T}_k \mathbf{y}' = \mathbf{e}_1</annotation></semantics></math></span></span>.</p>
<p>Since <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">T</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{T}_k</annotation></semantics></math></span></span> is tridiagonal, we can exploit its structure. A sparse LU factorization solves it in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(k)</annotation></semantics></math></span></span> time instead of the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>k</mi><mn>3</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(k^3)</annotation></semantics></math></span></span> cost of a dense method.</p>
<pre tabindex="0" data-language="rust"><code><span><span>let</span><span> f_tk_solver</span><span> =</span><span> |</span><span>alphas</span><span>:</span><span> &amp;</span><span>[</span><span>f64</span><span>], </span><span>betas</span><span>:</span><span> &amp;</span><span>[</span><span>f64</span><span>]</span><span>|</span><span> -&gt;</span><span> Result</span><span>&lt;</span><span>Mat</span><span>&lt;</span><span>f64</span><span>&gt;, </span><span>anyhow</span><span>::</span><span>Error</span><span>&gt; {</span></span>
<span><span>    let</span><span> steps</span><span> =</span><span> alphas</span><span>.</span><span>len</span><span>();</span></span>
<span><span>    if</span><span> steps</span><span> ==</span><span> 0</span><span> {</span></span>
<span><span>        return</span><span> Ok</span><span>(</span><span>Mat</span><span>::</span><span>zeros</span><span>(</span><span>0</span><span>, </span><span>1</span><span>));</span></span>
<span><span>    }</span></span>
<span></span>
<span><span>    // 1. Assemble T_k from coefficients using triplet format</span></span>
<span><span>    let</span><span> mut</span><span> triplets</span><span> =</span><span> Vec</span><span>::</span><span>with_capacity</span><span>(</span><span>3</span><span> *</span><span> steps</span><span> -</span><span> 2</span><span>);</span></span>
<span><span>    for</span><span> (</span><span>i</span><span>, </span><span>&amp;</span><span>alpha</span><span>) </span><span>in</span><span> alphas</span><span>.</span><span>iter</span><span>()</span><span>.</span><span>enumerate</span><span>() {</span></span>
<span><span>        triplets</span><span>.</span><span>push</span><span>(</span><span>Triplet</span><span> { </span><span>row</span><span>:</span><span> i</span><span>, </span><span>col</span><span>:</span><span> i</span><span>, </span><span>val</span><span>:</span><span> alpha</span><span> });</span></span>
<span><span>    }</span></span>
<span><span>    for</span><span> (</span><span>i</span><span>, </span><span>&amp;</span><span>beta</span><span>) </span><span>in</span><span> betas</span><span>.</span><span>iter</span><span>()</span><span>.</span><span>enumerate</span><span>() {</span></span>
<span><span>        triplets</span><span>.</span><span>push</span><span>(</span><span>Triplet</span><span> { </span><span>row</span><span>:</span><span> i</span><span>, </span><span>col</span><span>:</span><span> i</span><span> +</span><span> 1</span><span>, </span><span>val</span><span>:</span><span> beta</span><span> });</span></span>
<span><span>        triplets</span><span>.</span><span>push</span><span>(</span><span>Triplet</span><span> { </span><span>row</span><span>:</span><span> i</span><span> +</span><span> 1</span><span>, </span><span>col</span><span>:</span><span> i</span><span>, </span><span>val</span><span>:</span><span> beta</span><span> });</span></span>
<span><span>    }</span></span>
<span><span>    let</span><span> t_k_sparse</span><span> =</span><span> SparseColMat</span><span>::</span><span>try_new_from_triplets</span><span>(</span><span>steps</span><span>, </span><span>steps</span><span>, </span><span>&amp;</span><span>triplets</span><span>)</span><span>?</span><span>;</span></span>
<span></span>
<span><span>    // 2. Construct e_1</span></span>
<span><span>    let</span><span> mut</span><span> e1</span><span> =</span><span> Mat</span><span>::</span><span>zeros</span><span>(</span><span>steps</span><span>, </span><span>1</span><span>);</span></span>
<span><span>    e1</span><span>.</span><span>as_mut</span><span>()[(</span><span>0</span><span>, </span><span>0</span><span>)] </span><span>=</span><span> 1</span><span>.</span><span>0</span><span>;</span></span>
<span></span>
<span><span>    // 3. Solve T_k * y' = e_1 via sparse LU</span></span>
<span><span>    Ok</span><span>(</span><span>t_k_sparse</span><span>.</span><span>as_ref</span><span>()</span><span>.</span><span>sp_lu</span><span>()</span><span>?.</span><span>solve</span><span>(</span><span>e1</span><span>.</span><span>as_ref</span><span>()))</span></span>
<span><span>};</span></span></code></pre>
<p>The closure takes the coefficient arrays, constructs the sparse tridiagonal matrix, and solves the system. The triplet format lets us build the matrix efficiently without knowing its structure in advance. The sparse LU solver leverages the tridiagonal structure to avoid dense factorization.</p>
<h2 id="some-interesting-results">Some interesting results</h2>
<p>Now that we have a working implementation we can run some tests. The core idea of what we have done is simple: trade flops for better memory access. But does this trade actually pay off on real hardware? To find out, we need a reliable way to benchmark it.</p>
<p>For the data, we know that the performance of any Krylov method is tied to the operator‚Äôs spectral properties. We need a way to generate a family of test problems where we can precisely control the size, sparsity, and numerical difficulty. A great way to do this is with Karush-Kuhn-Tucker (KKT) systems, which are sparse, symmetric, and have a specific block structure.</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mo>=</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mi>D</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msup><mi>E</mi><mi>T</mi></msup></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mi>E</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">A =
\begin{pmatrix}
    D &amp; E^T \\
    E &amp; 0
\end{pmatrix}</annotation></semantics></math></span></span></span>
<p>This structure gives us two critical knobs to turn. First, with the <a href="https://commalab.di.unipi.it/files/Data/MCF/netgen.tgz">netgen</a> utility, we can control the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi></mrow><annotation encoding="application/x-tex">E</annotation></semantics></math></span></span> matrix, which lets us dial in the problem dimension, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span>. Second, we build the diagonal block D with random entries from a range <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>1</mn><mo separator="true">,</mo><msub><mi>C</mi><mi>D</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[1, C_D]</annotation></semantics></math></span></span>. This parameter, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mi>D</mi></msub></mrow><annotation encoding="application/x-tex">C_D</annotation></semantics></math></span></span>, gives us direct control over the numerical difficulty of the problem.</p>
<p>For a symmetric matrix like <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span></span>, the 2-norm condition number, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ∫</mi><mn>2</mn></msub><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\kappa_2(D)</annotation></semantics></math></span></span>, is the ratio of its largest to its smallest eigenvalue: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ∫</mi><mn>2</mn></msub><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>Œª</mi><mi>max</mi><mo>‚Å°</mo></msub><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><msub><mi>Œª</mi><mi>min</mi><mo>‚Å°</mo></msub><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\kappa_2(D) = \lambda_{\max}(D) / \lambda_{\min}(D)</annotation></semantics></math></span></span>. Since <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span></span> is diagonal, its eigenvalues are simply its diagonal entries. We are drawing these entries from a uniform distribution <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi><mo stretchy="false">[</mo><mn>1</mn><mo separator="true">,</mo><msub><mi>C</mi><mi>D</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">U[1, C_D]</annotation></semantics></math></span></span>, so we have <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œª</mi><mi>max</mi><mo>‚Å°</mo></msub><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo><mo>‚âà</mo><msub><mi>C</mi><mi>D</mi></msub></mrow><annotation encoding="application/x-tex">\lambda_{\max}(D) \approx C_D</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œª</mi><mi>min</mi><mo>‚Å°</mo></msub><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo><mo>‚âà</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\lambda_{\min}(D) \approx 1</annotation></semantics></math></span></span>. This means we get direct control, as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ∫</mi><mn>2</mn></msub><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo><mo>‚âà</mo><msub><mi>C</mi><mi>D</mi></msub></mrow><annotation encoding="application/x-tex">\kappa_2(D) \approx C_D</annotation></semantics></math></span></span>.The spectral properties of this block heavily influence the spectrum of the entire matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span>. A large condition number in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span></span> leads to a more ill-conditioned system for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span>. The convergence rate of Krylov methods like Lanczos is fundamentally governed by the distribution of the operator‚Äôs eigenvalues. An ill-conditioned matrix, with a wide spread of eigenvalues, will require more iterations, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>, to reach the desired accuracy. By simply adjusting the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mi>D</mi></msub></mrow><annotation encoding="application/x-tex">C_D</annotation></semantics></math></span></span> parameter, we can generate everything from well-conditioned problems that converge quickly to ill-conditioned ones that force us to run a large number of iterations. This is exactly what we need to rigorously test our implementation.</p>
<h2 id="memory-and-computation-trade-off">Memory and Computation Trade-off</h2>
<p>We measure the algorithm against two hypotheses on a large sparse problem with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>500</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">n=500,000</annotation></semantics></math></span></span>, varying the number of iterations <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>.</p>
<p><strong>Hypothesis 1 (Memory):</strong> The one-pass method stores the full basis <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{V}_k</annotation></semantics></math></span></span> with complexity <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(nk)</annotation></semantics></math></span></span>. We expect its memory to grow linearly with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>. The two-pass method operates with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span></span> memory, so it should have a flat profile.</p>
<p><strong>Hypothesis 2 (Runtime):</strong> The two-pass method performs <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>k</mi></mrow><annotation encoding="application/x-tex">2k</annotation></semantics></math></span></span> matrix-vector products instead of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>. If all else were equal, we‚Äôd expect it to run twice as slow.</p>
<h3 id="memory-usage">Memory Usage</h3>
<p><img src="https://lukefleed.xyz/assets/lanczos/tradeoff_arcs500k_rho3_memory.png" alt="Memory vs Iterations"></p>
<p>The memory data confirms Hypothesis 1 exactly. The one-pass method‚Äôs footprint scales as a straight line‚Äîeach additional iteration adds one vector to the basis. The two-pass method remains flat. No allocation growth happens after initialization.</p>
<h3 id="runtime-where-theory-breaks">Runtime: Where Theory Breaks</h3>
<p><img src="https://lukefleed.xyz/assets/lanczos/tradeoff_arcs500k_rho3_time.png" alt="Runtime vs Iterations"></p>
<p>The runtime data contradicts Hypothesis 2. The two-pass method is slower, but never by a factor of two. For small <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>, the gap is minimal. As <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> grows, the two-pass runtime diverges slowly from the one-pass method, not by doubling, but by a much smaller margin.</p>
<p>This difference comes from memory access patterns. Both methods perform matrix-vector products, but they differ in how they reconstruct the solution.</p>
<p>The one-pass method computes <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub><mo>=</mo><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k = \mathbf{V}_k \mathbf{y}_k</annotation></semantics></math></span></span> in a single dense matrix-vector product. When <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> are large, the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>√ó</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">n \times k</annotation></semantics></math></span></span> basis matrix exceeds all cache levels. The CPU cannot keep the data resident; instead, it streams <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{V}_k</annotation></semantics></math></span></span> from main memory. This is a memory-bandwidth-bound operation. The processor stalls, waiting for each load to complete. Instruction-level parallelism collapses.</p>
<p>The two-pass method reconstructs the solution incrementally. At each iteration, it operates on exactly three n-dimensional vectors: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mtext>prev</mtext></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{\text{prev}}</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">v</mi><mtext>curr</mtext></msub></mrow><annotation encoding="application/x-tex">\mathbf{v}_{\text{curr}}</annotation></semantics></math></span></span>, and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">x</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{x}_k</annotation></semantics></math></span></span>. This working set fits in L1 cache. The processor performs <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>k</mi></mrow><annotation encoding="application/x-tex">2k</annotation></semantics></math></span></span> matrix-vector products (each one reading the sparse operator, then applying it to a cached vector), but the solution accumulation happens entirely within cache. The additional matrix-vector products are cheaper than the memory latency of the standard method.</p>
<p>The cost of re-computing basis vectors is less than the latency cost of scanning an <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>√ó</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">n \times k</annotation></semantics></math></span></span> dense matrix from main memory.</p>
<h3 id="medium-scale-behavior">Medium-Scale Behavior</h3>
<p><img src="https://lukefleed.xyz/assets/lanczos/tradeoff_arcs50k_rho3_time.png" alt="Medium Scale Runtime vs Iterations">
<img src="https://lukefleed.xyz/assets/lanczos/tradeoff_arcs50k_rho3_memory.png" alt="Medium Scale Memory Usage vs Iterations"></p>
<p>At <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>50</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">n=50,000</annotation></semantics></math></span></span> we can observe an equilibrium. The two methods have nearly identical runtime. The standard method‚Äôs <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{V}_k</annotation></semantics></math></span></span> matrix is smaller; it fits partially in cache. The cache-miss penalty here becomes manageable. The two-pass method still has the advantage of cache-local accumulation, but the difference is marginal.</p>
<h3 id="what-about-dense-matrices">What About Dense Matrices?</h3>
<p>To be sure of our hypothesis, we can test it directly using a dense matrix of size <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>10</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">n=10,000</annotation></semantics></math></span></span>. For dense problems, the matrix-vector product is <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^2)</annotation></semantics></math></span></span>, it dominates all other costs. Memory latency will become negligible relative to the compute work and the cache efficiency advantage should disappear.</p>
<p><img src="https://lukefleed.xyz/assets/lanczos/dense-tradeoff.png" alt="Dense Matrix Runtime vs Iterations"></p>
<p>We can see that the two-pass method runs almost exactly twice as slow as the one-pass method. The slope ratio is <em>exactly</em> 2:1. In a compute-bound regime, the extra matrix-vector products cannot be hidden by cache effects. Here, the theoretical trade-off holds perfectly.</p>
<h2 id="scalability">Scalability</h2>
<p>Now, let‚Äôs fix the iteration count at <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>500</mn></mrow><annotation encoding="application/x-tex">k=500</annotation></semantics></math></span></span> and vary <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>50</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">50,000</annotation></semantics></math></span></span> to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>500</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">500,000</annotation></semantics></math></span></span> to measure scalability. Based on what we have seen before, we would expect the two-pass memory to scale linearly with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> but with a small constant factor (three vectors, plus scalars). The one-pass method should also scale linearly, but with a <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>-dependent slope.</p>
<p><img src="https://lukefleed.xyz/assets/lanczos/scalability_k500_rho3_memory.png" alt="Scalability Memory Usage"></p>
<p>Here we have to use a logarithmic y-axis to show both curves; the two-pass line is so flat relative to the one-pass line that it‚Äôs otherwise invisible.</p>
<p><img src="https://lukefleed.xyz/assets/lanczos/scalability_k500_rho3_time.png" alt="Scalability Runtime"></p>
<p>Runtime scales linearly with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> for both methods, as expected. Below <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>150</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">n=150,000</annotation></semantics></math></span></span>, the two methods have similar performance. This is the regime where both basis and working set fit in cache, or where the problem is small enough that memory latency is not the bottleneck.</p>
<p>As <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> increases beyond <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>150</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">150,000</annotation></semantics></math></span></span>, the matrix-vector product time dominates. The sparse structure of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span></span> ensures that each matvec requires multiple memory accesses per element. For the one-pass method, the final reconstruction of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">V</mi><mi>k</mi></msub><msub><mi mathvariant="bold">y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{V}_k \mathbf{y}_k</annotation></semantics></math></span></span> begins to cost more as the matrix grows. For the two-pass method, performing <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>k</mi></mrow><annotation encoding="application/x-tex">2k</annotation></semantics></math></span></span> matrix-vector products means the matvec cost accumulates more rapidly. The divergence is gradual, not sharp, because the advantage of cache locality in accumulation persists‚Äîbut it cannot overcome the fundamental cost of doubling the number of expensive operations.</p>
<hr>
<p>Well, that‚Äôs it. If you want to have a better look at the code or use it, it‚Äôs all open source:</p>
<ul>
<li><a href="https://github.com/lukefleed/two-pass-lanczos">Github Repository</a></li>
<li><a href="https://github.com/lukefleed/two-pass-lanczos/raw/master/tex/report.pdf">LaTeX Report</a></li>
</ul>
<p>This was more of an exploration than a production-ready library, so expect rough edges. But I hope it gives an interesting perspective on how algorithm engineering and low-level implementation details can alter what seems like a straightforward trade-off on a blackboard.</p> </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[iPod Socks (231 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/IPod_Socks</link>
            <guid>45889602</guid>
            <pubDate>Tue, 11 Nov 2025 16:52:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/IPod_Socks">https://en.wikipedia.org/wiki/IPod_Socks</a>, See on <a href="https://news.ycombinator.com/item?id=45889602">Hacker News</a></p>
Couldn't get https://en.wikipedia.org/wiki/IPod_Socks: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Firefox Expands Fingerprint Protections (288 pts)]]></title>
            <link>https://blog.mozilla.org/en/firefox/fingerprinting-protections/</link>
            <guid>45888891</guid>
            <pubDate>Tue, 11 Nov 2025 16:04:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.mozilla.org/en/firefox/fingerprinting-protections/">https://blog.mozilla.org/en/firefox/fingerprinting-protections/</a>, See on <a href="https://news.ycombinator.com/item?id=45888891">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
  <main id="main">

    
<article id="post-82478">
  

  <div>
    




<p>With Firefox 145, we‚Äôre rolling out major privacy upgrades that take on browser fingerprinting ‚Äî a pervasive and hidden tracking technique that lets websites identify you even when cookies are blocked or you‚Äôre in private browsing. These protections build on Mozilla‚Äôs long-term goal of building a healthier, transparent and privacy-preserving web ecosystem.</p>



<p>Fingerprinting builds a secret digital ID of you by collecting subtle details of your setup ‚Äî ranging from your time zone to your operating system settings ‚Äî that together create a ‚Äúfingerprint‚Äù identifiable across websites and across browser sessions. Having a unique fingerprint means fingerprinters can continuously identify you invisibly, allowing bad actors to track you without your knowledge or consent. Online fingerprinting is able to track you for months, even when you use any browser‚Äôs private browsing mode.</p>



<p>Protecting people‚Äôs privacy has always been core to Firefox. <a href="https://blog.mozilla.org/security/2020/01/07/firefox-72-fingerprinting/">Since 2020</a>, Firefox‚Äôs built-in <a href="https://support.mozilla.org/en-US/kb/enhanced-tracking-protection-firefox-desktop">Enhanced Tracking Protection</a> (ETP) has blocked known trackers and other invasive practices, while features like <a href="https://mzl.la/3db2drC">Total Cookie Protection</a> and now expanded fingerprinting defenses demonstrate a broader goal: prioritizing your online freedom through innovative privacy-by-design. Since 2021, Firefox has been incrementally enhancing anti-fingerprinting protections targeting the most common pieces of information collected for suspected fingerprinting uses.</p>



<p>Today, we are excited to announce the completion of the second phase of defenses against fingerprinters that linger across all your browsing but aren‚Äôt in the known tracker lists. With these fingerprinting protections, the amount of Firefox users trackable by fingerprinters is reduced by half.</p>



<h2>How we built stronger defenses</h2>



<p>Drawing from a global analysis of how real people‚Äôs browsers can be fingerprinted, Mozilla has developed new, unique and powerful defenses against real-world fingerprinting techniques. Firefox is the first browser with this level of insight into fingerprinting and the most effective deployed defenses to reduce it. Like <a href="https://blog.mozilla.org/en/mozilla/firefox-rolls-out-total-cookie-protection-by-default-to-all-users-worldwide/">Total Cookie Protection</a>, one of our most innovative privacy features, these new defenses are debuting in Private Browsing Mode and ETP Strict mode initially, while we work to enable them by default.</p>



<figure><img decoding="async" fetchpriority="high" width="1024" height="633" src="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/image-32-1024x633.png" alt="" title="Chart" srcset="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/image-32-1024x633.png 1024w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/image-32-300x186.png 300w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/image-32-768x475.png 768w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/image-32-1000x618.png 1000w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/image-32.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h2>How Firefox protects you</h2>



<p>These fingerprinting protections work on multiple layers, building on Firefox‚Äôs already robust privacy features. For example, Firefox has long blocked known tracking and fingerprinting scripts as part of its <a href="https://support.mozilla.org/en-US/kb/enhanced-tracking-protection-firefox-desktop">Enhanced Tracking Protection</a>.&nbsp;</p>



<p>Beyond blocking trackers, Firefox also limits the information it makes available to websites ‚Äî a privacy-by-design approach ‚Äî that preemptively shrinks your fingerprint. Browsers provide a way for websites to ask for information that enables legitimate website features, e.g. your graphics hardware information, which allows sites to optimize games for your computer.&nbsp; But trackers can also ask for that information, for no other reason than to help build a fingerprint of your browser and track you across the web.&nbsp;&nbsp;</p>



<p>Since 2021, Firefox has been incrementally advancing fingerprinting protections, covering the most pervasive fingerprinting techniques. These include things like how your graphics card draws images, which fonts your computer has, and even tiny differences in how it performs math. The first phase plugged the biggest and most-common leaks of fingerprinting information.</p>



<p>Recent Firefox releases have tackled the next-largest leaks of user information used by online fingerprinters. This ranges from strengthening the font protections to preventing websites from getting to know your hardware details like the number of cores your processor has, the number of simultaneous fingers your touchscreen supports, and the dimensions of your dock or taskbar. The full list of detailed protections is <a href="https://support.mozilla.org/en-US/kb/firefox-protection-against-fingerprinting#w_suspected-fingerprinters">available in our documentation</a>.</p>



<p>Our research shows these improvements <strong>cut the percentage of users seen as unique by almost half</strong>.</p>



<figure><img decoding="async" width="1024" height="1024" src="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections.png" alt="" srcset="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections.png 1024w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections-300x300.png 300w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections-150x150.png 150w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections-768x768.png 768w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections-1000x1000.png 1000w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections-800x800.png 800w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Firefox‚Äôs new protections are a balance of disrupting fingerprinters while maintaining web usability. More aggressive fingerprinting blocking might sound better, but is guaranteed to break legitimate website features. For instance, calendar, scheduling, and conferencing tools legitimately need your real time zone. Firefox‚Äôs approach is to target the most leaky fingerprinting vectors (the tricks and scripts used by trackers) while preserving functionality many sites need to work normally. The end result is a set of layered defenses that significantly reduce tracking without downgrading your browsing experience. More details are available about both the <a href="https://support.mozilla.org/en-US/kb/firefox-protection-against-fingerprinting#w_suspected-fingerprinters">specific behaviors</a> and how to <a href="https://support.mozilla.org/en-US/kb/firefox-protection-against-fingerprinting#w_how-can-i-tell-if-this-protection-broke-something">recognize a problem</a> on a site and <a href="https://support.mozilla.org/en-US/kb/firefox-protection-against-fingerprinting#w_how-do-i-disable-this-protection-for-a-website">disable protections</a> for that site alone, so you always stay in control. The goal: strong privacy protections that don‚Äôt get in your way.</p>



<h2>What‚Äôs next for your privacy</h2>



<p>If you open a Private Browsing window or use ETP Strict mode, Firefox is already working behind the scenes to make you harder to track. The latest phase of Firefox‚Äôs fingerprinting protections marks an important milestone in our mission to deliver: smart privacy protections that work automatically ‚Äî no further extensions or configurations needed.&nbsp;As we head into the future, Firefox remains committed to fighting for your privacy, so you get to enjoy the web on your terms. <a href="https://firefox.com/">Upgrade to the latest Firefox and take back control of your privacy</a>.</p>



<a href="https://www.mozilla.org/firefox/new/?utm_source=blog.mozilla.org&amp;utm_medium=referral&amp;utm_campaign=blog-nav">
  <p><img width="800" height="800" src="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2021/10/Visual-Guidelines-800x800.png" alt="" decoding="async" srcset="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2021/10/Visual-Guidelines-800x800.png 800w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2021/10/Visual-Guidelines-150x150.png 150w" sizes="(max-width: 800px) 100vw, 800px">  </p>
  <div>
     <h3>Take control of your internet</h3>      <p><span>Download Firefox</span>   </p></div>
</a>
  </div>

</article><!-- #post-82478 -->

  </main><!-- #main -->
  

<div id="related-articles">
    <h2>Related Articles</h2>
    
  </div>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Canada loses its measles-free status, with US on track to follow (211 pts)]]></title>
            <link>https://www.bbc.com/news/articles/cy7e2lv4r8xo</link>
            <guid>45888697</guid>
            <pubDate>Tue, 11 Nov 2025 15:50:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/cy7e2lv4r8xo">https://www.bbc.com/news/articles/cy7e2lv4r8xo</a>, See on <a href="https://news.ycombinator.com/item?id=45888697">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="byline-new" data-component="byline-block"><p><span data-testid="byline-new-contributors"><div data-testid="byline-new-contributors-contributor-0"><p><span>Nadine Yousif</span><span data-testid="byline-new-contributors-contributor-0-role-location">Senior Canada reporter</span></p></div></span></p></div><div data-component="text-block"><p>Canada has lost its measles elimination status, said the Pan American Health Organization (Paho) on Monday, after failing to curb an outbreak of the virus for 12 consecutive months.</p><p>Because Canada is no longer deemed measles-free, the Americas region as a whole has lost its elimination status, although individually the other countries are still considered to have stamped out the disease.</p><p>The US, however, risks losing its status as well if it does not stop an ongoing outbreak by January. Related cases have now been reported in Utah, Arizona and South Carolina.</p><p>Canada's outbreak began last October, with health officials attributing it to fewer people being vaccinated against measles.</p></div><div data-component="text-block"><p>At a news conference on Monday, Paho officials appealed to Canadian governments and the public to ramp up vaccinations, noting that 95% of the population needs to be immunised to stop the spread of measles.</p><p>"This loss represents a setback, but it is also reversible," said Dr Jarbas Barbosa, the health organisation's director.</p><ul><li><a target="_self" href="https://www.bbc.com/news/articles/c4g8d39gdr0o">How Canada became the centre of a measles outbreak in North America</a></li><li><a target="_self" href="https://www.bbc.com/news/articles/cwy747kdzdzo">More than 150 children quarantined as US measles cases hit 33-year high</a></li></ul><p>The Public Health Agency of Canada said in its own statement that it is collaborating with Paho and regional health authorities to improve vaccine rates and strengthen data sharing. </p><p>Prior to Monday, Canada had been declared measles-free for three decades. It can regain its elimination status if it can curb spread of the measles strain associated with the current outbreak for at least 12 months. </p><p>The country has reported more than 5,000 measles cases in 2025, with most of them in the provinces of Ontario and Alberta. That is three times the 1,681 cases reported in the US, despite Canada's much smaller population. </p><p>The bulk of the outbreak has been in "under-vaccinated communities", Canadian health officials have said. </p><p>Vaccination rates in Alberta, one of the provinces hit hard by the outbreak, are lower than the 95% threshold, according to provincial data. </p><p>One region, the South Zone, located south of the province's largest city Calgary, reported only 68% of children under the age of two were immunised against measles as of 2024.</p><p>The MMR vaccine is the most effective way to fight off the dangerous virus, which can lead to pneumonia, brain swelling and death. The jabs are 97% effective and also immunise against mumps and rubella.</p><p>Canadian immunologist Dawn Bowdish told the BBC that there are many reasons behind the low vaccination rates, including lack of access to general practitioners, the absence of a national vaccination registry that Canadians could use to check their immunisation status, and the spread of misinformation. </p><p>She also noted a lack of public health outreach to communities that have been hesitant or distrustful of vaccines.</p><p>"It highlights how many of our systems broke down to get us to this point," said Prof Bowdish of McMaster University in Hamilton, Ontario. </p><p>"I hope that it will be a wake-up call to policymakers, and that it will be enough of a national embarrassment that we remedy some of those systemic issues," she added</p><p>The Americas is the first and only region in the world to have been declared measles-free, starting in 2016. That status was then briefly lifted after outbreaks in Venezuela and Brazil. The two countries regained elimination status in 2024, in part through coordinated vaccine efforts where millions were immunised. </p><p>But measles has since spread again, now in North America. </p><p>Along with Canada and the United States, Mexico has also seen a surge in cases and now ranks among the top 10 countries with the largest outbreaks, according to the US Centers for Disease Control and Prevention.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Blender 5.1 (106 pts)]]></title>
            <link>https://developer.blender.org/docs/release_notes/5.1/</link>
            <guid>45887958</guid>
            <pubDate>Tue, 11 Nov 2025 14:58:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developer.blender.org/docs/release_notes/5.1/">https://developer.blender.org/docs/release_notes/5.1/</a>, See on <a href="https://news.ycombinator.com/item?id=45887958">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="nav-global-apps-menu">
              <a href="https://www.blender.org/?utm_medium=nav-global" target="_blank">
                <h3>BLENDER.ORG</h3>
              </a>
              <ul>
                <li>
                  <a href="https://www.blender.org/download/?utm_medium=nav-global" target="_blank">
                    <figure>
                      <svg height="100px" width="100px" viewBox="0 0 1000 1000">
                        <path d="m 49.15424,599.52895 a 50.360431,50.360431 0 0 0 -49.16137168,50.36043 v 200.24266 c 0,81.53594 68.34629768,149.88226 149.88223168,149.88226 h 700.2498 c 81.53593,0 149.8822,-68.34632 149.8822,-149.88226 V 649.88938 a 50.360431,50.360431 0 1 0 -100.72083,0 v 200.24266 c 0,27.57834 -21.58304,49.16138 -49.16137,49.16138 H 149.8751 c -27.57833,0 -49.16137,-21.58304 -49.16137,-49.16138 V 649.88938 A 50.360431,50.360431 0 0 0 49.15424,599.52895 Z M 249.3969,350.12491 a 50.360431,50.360431 0 0 0 -34.77267,85.13311 l 250.60309,249.40404 a 50.360431,50.360431 0 0 0 70.74442,0 L 785.37577,435.25802 A 50.360431,50.360431 0 1 0 714.63136,364.51361 L 500,579.14497 285.36864,364.51361 A 50.360431,50.360431 0 0 0 249.3969,350.12491 Z M 498.80094,0 A 50.360431,50.360431 0 0 0 449.63957,50.360432 V 649.88938 a 50.360431,50.360431 0 1 0 100.72086,0 V 50.360432 A 50.360431,50.360431 0 0 0 498.80094,0 Z" style="stroke-width:1.19906"></path>
                      </svg>
                    </figure>
                    <div>
                      <h4>Download</h4>
                      <p>Get the latest Blender, older versions, or experimental builds.</p>
                    </div>
                  </a>
                </li>
                <li>
                  <a href="https://www.blender.org/download/releases/?utm_medium=nav-global" target="_blank">
                    <div>
                      <h4>What's New</h4>
                      <p>Stay up-to-date with the new features in the latest Blender releases.</p>
                    </div>
                  </a>
                </li>
              </ul>
              <a href="https://studio.blender.org/?utm_medium=nav-global" target="_blank">
                <h3>LEARNING &amp; RESOURCES</h3>
              </a>
              <ul>
                <li>
                  <a href="https://studio.blender.org/?utm_medium=nav-global" target="_blank">
                    <figure>
                      <svg height="100px" width="100px" viewBox="0 0 1000 1000">
                        <path d="m 146.70939,1.6802353 c -78.362959,0 -143.678322,64.2057377 -143.6783209,143.6570547 -7.2533835,268.45385 0,463.93349 0,709.63356 0,79.45132 65.3153619,143.65705 143.6783209,143.65705 266.17757,0.51388 460.32009,0 709.61228,0 79.45134,0 143.67832,-64.20573 143.67832,-143.65705 0.37471,-118.45983 0,-235.03162 0,-353.72203 0.017,-0.72264 0.017,-1.4456 0,-2.16825 0.43351,-118.60776 0,-235.80643 0,-353.74328 0,-79.451317 -64.22698,-143.6570547 -143.67832,-143.6570547 -241.21275,-1.18614431 -498.91438,-0.041532 -709.61228,0 z m 0,90.3436617 h 82.71228 V 228.07083 H 93.374735 v -82.73354 c 0,-30.47448 22.860165,-53.313393 53.334655,-53.313393 z m 173.05594,0 h 363.5004 c -5.81542,127.740813 0,236.658243 0,362.416273 h -363.5004 c 0.39671,-121.62159 0,-241.06277 0,-362.416273 z m 453.84406,0 h 82.71228 c 30.4745,0 53.33466,22.838913 53.33466,53.313393 v 82.73354 H 773.60939 Z M 93.374735,318.39324 H 229.42167 V 454.44017 H 93.374735 Z m 680.234655,0 H 909.65633 V 454.44017 H 773.60939 Z M 93.374735,545.86796 H 229.42167 V 681.91489 H 93.374735 Z m 226.390595,0 h 363.5004 c -5.81534,127.74773 0,236.67164 0,362.43753 h -363.5004 c 0.3967,-121.62867 0,-241.07685 0,-362.43753 z m 453.84406,0 H 909.65633 V 681.91489 H 773.60939 Z M 93.374735,772.25856 H 229.42167 v 136.04693 h -82.71228 c -30.47449,0 -53.334655,-22.86016 -53.334655,-53.33464 z m 680.234655,0 h 136.04694 v 82.71229 c 0,30.47448 -22.86016,53.33464 -53.33466,53.33464 h -82.71228 z" style="stroke-width:1.08838"></path>
                      </svg>
                    </figure>
                    <div>
                      <h4>Blender Studio</h4>
                      <p>Access production assets and knowledge from the open movies.</p>
                    </div>
                  </a>
                </li>
                <li>
                  <a href="https://docs.blender.org/manual/en/latest/?utm_medium=nav-global" target="_blank">
                    <div>
                      <h4>Manual</h4>
                      <p>Documentation on the usage and features in Blender.</p>
                    </div>
                  </a>
                </li>
              </ul>
              <a href="https://projects.blender.org/?utm_medium=nav-global" target="_blank">
                <h3>DEVELOPMENT</h3>
              </a>
              <ul>
                <li>
                  <a href="https://code.blender.org/?utm_medium=nav-global" target="_blank">
                    <figure>
                      <svg height="100px" width="100px" viewBox="0 0 1000 1000">
                        <path d="m 683.36434,818.19976 a 45.841084,45.841084 0 0 1 -33.83509,-13.09745 45.841084,45.841084 0 0 1 0,-64.39581 L 890.74067,499.49508 649.52925,259.37512 a 45.841084,45.841084 0 0 1 0,-64.39582 45.841084,45.841084 0 0 1 64.39581,0 l 272.8636,272.8636 a 45.841084,45.841084 0 0 1 0,64.39581 l -272.8636,272.8636 a 45.841084,45.841084 0 0 1 -30.56072,13.09745 z m -363.45431,0 A 45.841084,45.841084 0 0 1 286.07494,805.10231 L 13.211339,532.23871 a 45.841084,45.841084 0 0 1 0,-64.39581 L 286.07494,194.9793 a 45.841084,45.841084 0 0 1 64.39581,0 45.841084,45.841084 0 0 1 0,64.39582 L 109.25933,499.49508 350.47075,740.7065 a 45.841084,45.841084 0 0 1 0,64.39581 45.841084,45.841084 0 0 1 -30.56072,13.09745 z" style="stroke-width:1.09145"></path>
                      </svg>
                    </figure>
                    <div>
                      <h4>Developers Blog</h4>
                      <p>Latest development updates, by Blender developers.</p>
                    </div>
                  </a>
                </li>
                <li>
                  <a href="https://developer.blender.org/docs/?utm_medium=nav-global" target="_blank">
                    <div>
                      <h4>Documentation</h4>
                      <p>Guidelines, release notes and development docs.</p>
                    </div>
                  </a>
                </li>
              </ul>
              <ul>
                <li>
                  <a href="https://opendata.blender.org/?utm_medium=nav-global" target="_blank">
                    <figure>
                      <svg height="100px" width="100px" viewBox="0 0 1000 1000">
                        <path d="M 499.99424,0 A 55.30474,55.30474 0 0 0 444.6895,55.30474 V 944.69526 A 55.30474,55.30474 0 0 0 499.99424,1000 55.30474,55.30474 0 0 0 555.29898,944.69526 V 55.30474 A 55.30474,55.30474 0 0 0 499.99424,0 Z m 332.95711,332.95711 a 55.30474,55.30474 0 0 0 -55.30474,56.43341 V 944.69526 A 55.30474,55.30474 0 0 0 832.95135,1000 55.30474,55.30474 0 0 0 888.25609,944.69526 V 389.39052 A 55.30474,55.30474 0 0 0 832.95135,332.95711 Z M 167.03713,555.30474 a 55.30474,55.30474 0 0 0 -55.30474,55.30474 V 944.69526 A 55.30474,55.30474 0 0 0 167.03713,1000 55.30474,55.30474 0 0 0 222.34187,944.69526 V 610.60948 a 55.30474,55.30474 0 0 0 -55.30474,-55.30474 z" style="stroke-width:1.12867"></path>
                      </svg>
                    </figure>
                    <div>
                      <h4>Benchmark</h4>
                      <p>A platform to collect and share results of the Blender Benchmark.</p>
                    </div>
                  </a>
                </li>
                <li>
                  <a href="https://conference.blender.org/?utm_medium=nav-global" target="_blank">
                    <div>
                      <h4>Blender Conference</h4>
                      <p>The yearly event that brings the community together.</p>
                    </div>
                  </a>
                </li>
              </ul>
              <div>
                <a href="https://fund.blender.org/?utm_medium=nav-global" target="_blank">
                  <h3>DONATE</h3>
                </a>
                <ul>
                  <li>
                    <a href="https://fund.blender.org/?utm_medium=nav-global" target="_blank">
                      <figure>
                        <svg height="100px" width="100px" viewBox="0 0 1000 1000">
                          <path d="M 273.67169,58.416076 C 201.59785,62.59427 135.79129,94.975269 86.697523,145.11359 37.603742,194.20736 4.1781939,260.01391 0,332.08775 -4.1781926,403.11704 22.980065,480.41362 86.697523,545.17562 l 45.960127,45.96013 339.47823,338.43367 a 43.871033,43.871033 0 0 0 61.62835,0 L 872.1979,591.13575 918.15804,545.17562 c 109.67766,-110.72213 109.67766,-290.38445 0,-400.06203 -110.72213,-110.722127 -290.38445,-110.722127 -400.06204,0 l -15.66822,14.62368 -15.66822,-14.62368 C 423.04211,80.351592 345.74553,53.193334 273.67169,58.416076 Z m 5.22274,86.697514 c 48.04922,-3.13365 98.18754,12.53458 146.23677,60.5838 l 47.00468,47.00468 a 43.871033,43.871033 0 0 0 61.62835,0 l 45.96013,-47.00468 c 76.25204,-76.25203 199.50874,-76.25203 276.80532,0 77.29658,77.29658 77.29658,200.5533 0,277.84988 L 810.56956,529.50739 502.42778,837.64917 194.286,529.50739 148.32588,483.54727 C 100.27665,434.45349 84.608431,384.31516 86.697523,336.26594 c 3.133646,-47.00467 26.113717,-95.0539 61.628357,-130.56855 35.51464,-35.51464 82.51932,-58.49471 130.56855,-60.5838 z" style="stroke-width:1.04455"></path>
                        </svg>
                      </figure>
                      <div>
                        <h4>Development Fund</h4>
                        <p>Support core development with a monthly contribution.</p>
                      </div>
                    </a>
                  </li>
                  <li>
                    <a href="https://www.blender.org/about/donations/?utm_medium=nav-global" target="_blank">
                      <div>
                        <h4>One-time Donations</h4>
                        <p>Perform a single donation with more payment options available.</p>
                      </div>
                    </a>
                  </li>
                </ul>
              </div>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pikaday: A friendly guide to front-end date pickers (192 pts)]]></title>
            <link>https://pikaday.dbushell.com</link>
            <guid>45887957</guid>
            <pubDate>Tue, 11 Nov 2025 14:58:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pikaday.dbushell.com">https://pikaday.dbushell.com</a>, See on <a href="https://news.ycombinator.com/item?id=45887957">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    <div>
        <h2>Who needs a JavaScript date picker?</h2>
        <p>
          The answer, in most cases, is nobody!
          Complex UI leads to more errors and abandoned forms.
          There can be easier ways to pick a date than a calendar widget.
          This guide provides alternate ideas and aims to send developers on a path towards <mark>user-friendly interfaces</mark>.
        </p>
      </div>

    <section id="native">
      <div>
        <h2>Native date and time inputs</h2>
        <p>
          If you absolutely must use a calendar widget then it‚Äôs wise to use the native input.
          All modern <a href="https://caniuse.com/input-datetime" target="_blank">browsers support</a> native date and time inputs.
        </p>
      </div>
      
      

      <div>
        <h2>Why use native inputs</h2>
        <p>Native inputs are super easy to implement with one line of code. The web browser handles many important details for developers:</p>
        <ul>
          <li>Accessibility <sup><a href="#accessibility-issues">(mostly*)</a></sup></li>
          <li>Performance</li>
          <li>Internationalisation</li>
        </ul>
        <p>
          Let browsers do the hard work!
          Browsers allow keyboard users to type numbers in sequence.
          Most browsers provide alternate UI for time and date selection like the classic calendar widget.
          They're not perfect but do you trust a JavaScript library to do better?
        </p>
      </div>

      

      
    </section>

    <section id="separate">
      <div>
        <h2>Separate inputs</h2>
        <p>
          A single date picker can be tricky to operate. For memorable dates using separate inputs can improve usability.
          The example below is based on <a href="https://design-system.service.gov.uk/components/date-input/" target="_blank">GOV.UK date input component</a>.
        </p>
        
      </div>
      <div>
        <h3>Select elements</h3>
        <p>
          If only a limited set of data is valid then using <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Reference/Elements/select" target="_blank">select elements</a> may be suitable.
          They can require fewer interactions to use and they eliminate typing errors.
        </p>
      </div>
      <div>
        <div>
          <form>
            <fieldset>
              <legend>
                <h3>Select expiry date</h3>
              </legend>
              <p><label for="expiry-month">Month</label>
                
              </p>
              <p><label for="expiry-year">Year</label>
                
              </p>
            </fieldset>
          </form>
          <p>
            Numeric month labels can be helpful but take care in how they‚Äôre written.
            Screen readers may mistakenly announce ‚Äú1 January‚Äù as ‚Äúthe 1st of January‚Äù, for example.
          </p>
        </div>
        <div>
          <form>
            <fieldset>
              <legend>
                <h3>Select departure time</h3>
              </legend>
              <p><label for="departure-date">I‚Äôm leaving</label>
                
              </p>
              <p><label for="departure-hour">Hour</label>
                
              </p>
              <p><label for="departure-minutes">Minutes</label>
                
              </p>
            </fieldset>
          </form>
          <p>Travel booking often has a fixed schedule with limited time options, such as every 15 minutes.
            Relative dates like ‚ÄúToday‚Äù and ‚ÄúTomorrow‚Äù can be easier to understand.</p>
        </div>
      </div>
      
    </section>

    <section id="masked">

      <div>
        <h2>Masked inputs</h2>
        <p>
          Another common alternative to date pickers is a single input with a placeholder mask.
          This can be used for full or partial dates.
          JavaScript can enhancement the experience.
        </p>
      </div>

      

      <div>
        <p>
          The examples above provide client-side validation with errors such as <em>‚ÄúPlease enter a valid day for February (1 to 28)‚Äù</em>.
          Valid dates are confirmed in full and formatted with the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Intl/DateTimeFormat" target="_blank"><code>Intl</code> API</a>.
        </p>
        <p>
            <strong>Caution!</strong> Updating input values with JavaScript can break native undo/redo.
          </p>
      </div>

      <div>
        <p>
          It‚Äôs even possible to visually combined mutliple inputs using CSS to appear as one.
        </p>
        
      </div>

      
    </section>

    <div id="ranges">
        <h2>Ranges and limited options</h2>
        <p>
          JavaScript date pickers that support range selection across two calendars are difficult to use, especially without a pointer.
          Consider providing two inputs instead to <mark>reduce complexity</mark>.
          If users are required to select an available date then a group of <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Reference/Elements/input/radio" target="_blank"><code>radio</code> inputs</a> can do the job.
        </p>
        <p><small><b>The example below illustrates the idea but is not fully interactive.</b></small></p>
        
        <p>
          There are many design variations of this pattern.
          This idea is to replace complicated UI with a series of simple tasks.
          Such a pattern can be implemented as a multi-page form with
          JavaScript used to enhance it into a single page interactive experience.
        </p>
      </div>

    <section id="faq">
      <div>
        <h2>Frequently asked questions</h2>
        <details id="faq-frameworks">
          <summary><h3>What if I use a JavaScript framework like React?</h3></summary>
          <p>
              All good JavaScript frameworks allow you to use native HTML elements.
              Not everything needs to be a custom component.
              Native <a href="https://developer.mozilla.org/en-US/docs/Web/API/HTMLInputElement#events" target="_blank">input events</a> can integrate with framework callbacks.
              Use attributes like <a href="https://developer.mozilla.org/en-US/docs/Web/API/HTMLInputElement/value"><code>value</code></a> for two-way state binding.
            </p>
        </details>
        <details id="faq-styles">
          <summary><h3>How do I style the native date picker?</h3></summary>
          <p>
              The on-page <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Reference/Elements/input/date" target="_blank"><code>input</code> element</a>
              can be partially styled but other parts are not stylable.
              That is a good thing! Native system UI is familiar to the user.
              The design will differ based on operating system and input method.
              Date pickers even look different across browsers and that's fine too, you don't need to add yet another design to the mix!
            </p>
        </details>
        <details id="faq-stakeholders">
          <summary><h3>A stakeholder is demanding a JavaScript date picker, how do I dissuade them?</h3></summary>
          <p>
              Remember: the end goal is a successful form submission. Complex and fragile UI leads to more errors.
              All date pickers have accessibility issues. Combining basic inputs can be more user-friendly.
              Untested JavaScript UI may fall foul of regulation like the <a href="https://en.wikipedia.org/wiki/European_Accessibility_Act" target="_blank">European Accessibility Act</a>.
              Keep it simple for success!
            </p>
        </details>
        <details id="faq-accessibility">
          <summary><h3>How do I test and guarantee accessibility?</h3></summary>
          <div>
            <p>
              It‚Äôs critical to understand the relevant <a href="https://www.w3.org/TR/WCAG22/" target="_blank">accessibility guidelines</a>.
              You don‚Äôt need to memorise WCAG but there are no shortcuts to learning the important parts.
              Leverage existing web standards to avoid mistakes trying to code custom UI.
            </p>
            <p>
              Browser dev tools have built-in <a href="https://developer.chrome.com/docs/devtools/accessibility/reference" target="_blank">accessibility features</a> to help identify mistakes.
              However, no tool is perfect. The only way to know for sure is to conduct user testing.
            </p>
            <p>
              <a href="https://overlayfactsheet.com/" target="_blank">Accessibility overlays</a> are <strong>strongly discouraged</strong> and can make matters worse.
            </p>
          </div>
        </details>
        <details id="faq-resources">
          <summary><h3>Where can I learn more about date picker accessibility?</h3></summary>
          <div>
            <ul>
              <li><a href="https://www.hassellinclusion.com/blog/collecting-dates-accessible/" target="_blank">Collecting dates in an accessible way</a> by <strong>Graham Armfield</strong></li>
              <li><a href="https://www.youtube.com/watch?v=D2Gy2WN4Iys&amp;list=PLn7dsvRdQEfFfYUgq0wVLXlVN7yQUUWd-" target="_blank">What makes an accessible date picker? Is it even possible?</a> by <strong>Russ Weakley</strong></li>
              <li><a href="https://adrianroselli.com/2019/07/maybe-you-dont-need-a-date-picker.html" target="_blank">Maybe You Don‚Äôt Need a Date Picker</a> by <strong>Adrian Roselli</strong></li>
              <li><a href="https://www.w3.org/WAI/ARIA/apg/patterns/dialog-modal/examples/datepicker-dialog/" target="_blank">Date Picker Dialog Example</a> by <strong>ARIA Authoring Practices Guide</strong></li>
              <li><a href="https://www.smashingmagazine.com/2017/07/designing-perfect-date-time-picker/" target="_blank">Designing The Perfect Date And Time Picker</a> by <strong>Vitaly Friedman</strong></li>
            </ul>
          </div>
        </details>
        <details id="faq-recommend">
          <summary><h3>This is all great but can you please recommend a JavaScript date picker?</h3></summary>
          <p>
              Sorry, no! There is no universal solution and <mark>all date pickers have issues</mark>.
              I hope this guide has given you the knowledge to evaluate your own requirements.
              Try to achieve your goal in the simplest way.
              A date picker is probably not the answer.
            </p>
        </details>
      </div>
      <div>
        <p><strong>Before you go!</strong> Remember to test and gather feedback from real users :)</p>
        <p>This guide is a work in progress, <a href="https://dbushell.com/contact/" target="_blank">feedback is welcome!</a></p>
      </div>
    </section>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Gametje ‚Äì A casual online gaming platform (101 pts)]]></title>
            <link>https://gametje.com</link>
            <guid>45887709</guid>
            <pubDate>Tue, 11 Nov 2025 14:36:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gametje.com">https://gametje.com</a>, See on <a href="https://news.ycombinator.com/item?id=45887709">Hacker News</a></p>
<div id="readability-page-1" class="page">
    
    <div id="root">
          <p>
            GAMETJE
          </p>
          <p>
            ...
          </p>
        </div>
    <!-- <script type="module" src="/scripts/HackTimer.silent.min.js"></script> -->
    

    <!--- helpful for remote debugging-->
    <!-- <script src="https://markknol.github.io/console-log-viewer/console-log-viewer.js"></script> -->
    
  <!-- Cloudflare Pages Analytics --><!-- Cloudflare Pages Analytics -->

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Department of War just shot the accountants and opted for speed (173 pts)]]></title>
            <link>https://steveblank.com/2025/11/11/the-department-of-war-just-shot-the-accountants-and-opted-for-speed/</link>
            <guid>45887699</guid>
            <pubDate>Tue, 11 Nov 2025 14:34:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://steveblank.com/2025/11/11/the-department-of-war-just-shot-the-accountants-and-opted-for-speed/">https://steveblank.com/2025/11/11/the-department-of-war-just-shot-the-accountants-and-opted-for-speed/</a>, See on <a href="https://news.ycombinator.com/item?id=45887699">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

					<p><span>Last week the Department of War finally killed the last vestiges of Robert McNamara‚Äôs 1962 Planning, Programming, and Budgeting System (PPBS).&nbsp;</span></p>
<p><span>The DoW has pivoted from optimizing cost and performance to delivering advanced weapons at speed. Taking decades to deliver weapons is no longer an option. The DoW has joined the 21</span><span>st</span><span> century and adopted Lean Methodology.</span></p>
<p><span>Two organizations ought to be very concerned ‚Äì China and the defense prime contractors.</span></p>
<hr>
<p><span>Secretary of War Pete Hegseth <a href="https://www.war.gov/Multimedia/Videos/?videoid=986046" target="_blank" rel="noopener">unveiled the biggest changes in 60 years</a> of how the Department of War (DoW) plans for and buys weapons and services. These changes aren‚Äôt a minor attempt at reform. It‚Äôs a top-to-bottom transformation of how the DoW plans and buys weapons, moving from contracts that prioritize how much a weapon costs to how fast it can be delivered.&nbsp;</span></p>
<p><span>Instead of buying custom-designed weapons, the DoW will prioritize buying off-the-shelf things that already exist, and using fast-track acquisition processes, rather than the cumbersome existing <a href="https://www.acquisition.gov/sites/default/files/current/far/pdf/FAR.pdf" target="_blank" rel="noopener">Federal Acquisition Regulations</a>. To manage all of this, they are reorganizing the entire Acquisition ecosystem across the Services. These changes implement every piece of good advice the DoD had gotten in the last decade and had previously ignored.&nbsp;</span></p>
<p><span>The DoW is being redesigned to now operate at the speed of Silicon Valley, delivering more, better, and faster. Our warfighters will benefit from the innovation and lower cost of commercial technology, and the nation will once again get a military second to none.&nbsp;&nbsp;</span></p>
<p><span>It‚Äôs big, bold and brave and long overdue.</span></p>
<p><b>Background<br>
</b><span>In 1962 Robert McNamara, the then-Secretary of Defense (and ex CFO of Ford), discovered he had inherited a Defense Department whose spending was out of control. During the 1950s the Air Force built five different types of fighter planes, three generations of bombers, and three generations of ICBMs. The Navy had created a fleet of nuclear-powered attack and ballistic missile submarines and aircraft carriers. The Army bought three generations of its own nuclear-capable missile systems. Many of these systems duplicated capabilities of other services. But most importantly, the Services, in their rush to buy new technology, hadn‚Äôt adequately budgeted for the cost of operating, training, maintaining, and sustaining what they had bought.&nbsp;</span></p>
<p><span>In response, Secretary McNamara imposed the discipline of a Chief Financial Officer. He put in place a formal system of Planning (capability gaps, risks, scenarios, threats assumptions), Programming (5-year plans, affordability, quantities, phasing, unit fielding plans) and Budgeting that has lasted 60+ years. An entire defense university was created to train tens of thousands of contracting officers how to follow the detailed rules. Large contractors (the Primes) learned to work with this paperwork-heavy Defense acquisition system and lived with the very long time it took the DoD to buy.&nbsp;</span></p>
<p><b>The Problem<br>
</b>This unwieldy and lethargic acquisition system was adequate for over half a century when our adversary was the Soviet Union who had an equally complex acquisition system, or ISIS and Al Qaida who had none.</p>
<p><span>However, in the last decade it became painfully obvious that our acquisition system was broken and no longer worked for the world we lived in. Our existing defense industrial base suffers from schedule overruns and huge backlogs; cost increases have become the norm. We‚Äôve been outpaced by adversaries. China, for example, implemented a much more agile system that delivered weapons in a fraction of the time it took us.&nbsp;</span></p>
<p><span>We needed a defense industrial base we could count on to scale in a crisis rather than one that will wait for money before taking action.</span></p>
<p><span>The war in Ukraine showed that even a small country could produce millions of drones a year while continually iterating on their design to match changes on the battlefield. (Something we couldn‚Äôt do.) Meanwhile, commercial technology from startups and scaleups (fueled by an immense pool of private capital) has created off-the-shelf products, many unmatched by our federal research development centers or primes, that can be delivered at a fraction of the cost/time. But the DoW acquisition system was impenetrable to startups.&nbsp;</span></p>
<p><span>Our Acquisition system was paralyzed by our own impossible risk thresholds, its focus on process not outcomes, and became risk averse and immoveable.&nbsp;</span></p>
<p><span>We needed an acquisition system that could deliver needed things faster.</span></p>
<p><b>Reminder: What Did Our Acquisition System Look Like Until Last Week?<br>
</b><span>The Army, Navy, Air Force, Marines and Space Force train soldiers, sailors and airmen, and specify and buy the weapons for their Service. (It‚Äôs the Combatant Commands, e.g. <a href="https://www.pacom.mil/" target="_blank" rel="noopener">INDOPACOM</a>, <a href="https://www.centcom.mil/" target="_blank" rel="noopener">CENTCOM</a>, etc., who fight the wars.)</span></p>
<p><span>One of the confusing things about Acquisition in the DoW is that it is more than just the buyers of equipment. In the DoW Acquisition with capital ‚ÄúA‚Äù, includes the entire end-to-end process ‚Äì from concept, requirements, prototyping, testing, buying it, to using it and maintaining it.</span></p>
<p><span>In each of the Services, the current Acquisition system started with a group that forecast what the Service would need in the future and wrote requirements for future weapons/services/software. This process could take a year or more. Next, Service laboratories developed the technology, tested prototypes and concepts. This could take 3 to 6 years. Next, a vendor was selected and began to prototype and refine the systems. This added another 3 to 4 years. Finally, the system was ready to be built and delivered. It could take 1 to 2 years to deliver weapons in low rate production, or 5 to 10 years for something complex (e.g. aircraft, ships,&nbsp; spacecraft). In the system we‚Äôre replacing the time from when a need was turned into a requirement to delivery of a weapon would take 8 to 16 years. As you can imagine, given the rate of change of current technology and new warfighting concepts our own Acquisition process was an obstacle to building a modern War Department.&nbsp;&nbsp;</span></p>
<p><span>As an example, the Army‚Äôs current Acquisition system has </span><a href="https://www.pacom.mil/" target="_blank" rel="noopener"><span>32,000 civilians and military</span></a><span> (program managers, contracting officers, etc.) If you include the long tail of sustainment that‚Äôs another 165,000+ people. The Acquisition system in the Army (representative of the other services) looks like this:</span></p>
<p><img data-recalc-dims="1" fetchpriority="high" decoding="async" data-attachment-id="33272" data-permalink="https://steveblank.com/2025/11/11/the-department-of-war-just-shot-the-accountants-and-opted-for-speed/from-need-to-production/" data-orig-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/From-Need-to-Production.jpg?fit=1991%2C870&amp;ssl=1" data-orig-size="1991,870" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="From Need to Production" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/From-Need-to-Production.jpg?fit=300%2C131&amp;ssl=1" data-large-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/From-Need-to-Production.jpg?fit=468%2C204&amp;ssl=1" src="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/From-Need-to-Production.jpg?resize=468%2C205&amp;ssl=1" alt="" width="468" height="205" srcset="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/From-Need-to-Production.jpg?resize=1024%2C447&amp;ssl=1 1024w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/From-Need-to-Production.jpg?resize=300%2C131&amp;ssl=1 300w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/From-Need-to-Production.jpg?resize=150%2C66&amp;ssl=1 150w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/From-Need-to-Production.jpg?resize=768%2C336&amp;ssl=1 768w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/From-Need-to-Production.jpg?resize=1536%2C671&amp;ssl=1 1536w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/From-Need-to-Production.jpg?w=1991&amp;ssl=1 1991w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/From-Need-to-Production.jpg?w=936&amp;ssl=1 936w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/From-Need-to-Production.jpg?w=1404&amp;ssl=1 1404w" sizes="(max-width: 468px) 100vw, 468px"></p>
<p><b>What Was Wrong With this Process?</b></p>
<ul>
<li aria-level="1"><span>Responsibility in the Acquisition system was scattered across multiple, siloed organizations with no one individual responsible.&nbsp;</span></li>
<li aria-level="1"><span>The existing system was designed to acquire individual products (weapons, services, etc.) with a Program Executive Office to manage each effort that only indirectly solved warfighter problems.&nbsp;</span></li>
<li aria-level="1"><span>Requirements were written so that most everything the DoW bought was bespoke and required development from scratch.&nbsp;</span></li>
<li aria-level="1"><span>Acquisition was process-focused with rigid rules that emphasized compliance to contracting rules.&nbsp;</span></li>
<li aria-level="1"><span>Compliance to the rules and processes overrode speed of delivery</span></li>
<li aria-level="1"><span>Weapons and systems development used sequential ‚Äúwaterfall‚Äù development processes which precluded learning, pivots and iterative design. ‚Äã</span></li>
<li aria-level="1"><span>The result was that speed of delivery was on no one‚Äôs priority list.</span></li>
</ul>
<p><b>Why Is The Warfighting Acquisition System A Big Deal?<br>
</b><span>While previous administrations tried to go around the process, this new system confronts it head on. It is a revolutionary&nbsp; transformation in the Department of War. It was clearly designed by people who have worked in industry and understand commercial Lean Processes. This transformation will solve the DoW critical Acquisition problems by:</span></p>
<ul>
<li aria-level="1"><span>Prioritizing </span><i><span>speed</span></i><span> of delivery</span></li>
<li aria-level="1"><span>Moving the focus </span><i><span>from process to outcomes</span></i></li>
<li aria-level="1"><i><span>Organizational redesign</span></i><span> of the Acquisition process</span></li>
<li aria-level="1"><span>Changing </span><i><span>what weapons we ask for</span></i><span> and </span><i><span>how we prioritize</span></i><span> what we need to buy</span></li>
<li aria-level="1"><span>Changing the </span><i><span>preferred vendors</span></i><span> the DoW will buy from</span></li>
<li aria-level="1"><span>Changing the </span><i><span>contracting methods</span></i><span> the DoW will use</span></li>
<li aria-level="1"><span>Changing how we </span><i><span>measure and reward</span></i><span> success&nbsp;</span></li>
<li aria-level="1"><span>Changing how we </span><i><span>educate</span></i><span> Acquisition professionals</span></li>
<li aria-level="1"><span>Insisting that disparate systems/vendors </span><i><span>interoperate</span></i><span>&nbsp;</span></li>
</ul>
<p><b>The New Warfighting Acquisition Organization ‚Äì The Portfolio Acquisition Executive<br>
</b><span>To cut through the individual acquisition silos, the services are creating Portfolio Acquisition Executives (PAEs).&nbsp;</span></p>
<p><span>Each Portfolio Acquisition Executive (PAE) is responsible for the entire end-to-process of the different Acquisition functions: Capability Gaps/Requirements, System Centers, Programming, Acquisition, Testing, Contracting and Sustainment. PAEs are empowered to take calculated risks in pursuit of rapidly delivering innovative solutions.</span></p>
<p><img data-recalc-dims="1" decoding="async" data-attachment-id="33273" data-permalink="https://steveblank.com/2025/11/11/the-department-of-war-just-shot-the-accountants-and-opted-for-speed/pae-redrawn/" data-orig-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Redrawn.jpg?fit=2012%2C379&amp;ssl=1" data-orig-size="2012,379" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="PAE Redrawn" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Redrawn.jpg?fit=300%2C57&amp;ssl=1" data-large-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Redrawn.jpg?fit=468%2C88&amp;ssl=1" src="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Redrawn.jpg?resize=468%2C88&amp;ssl=1" alt="" width="468" height="88" srcset="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Redrawn.jpg?resize=1024%2C193&amp;ssl=1 1024w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Redrawn.jpg?resize=300%2C57&amp;ssl=1 300w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Redrawn.jpg?resize=150%2C28&amp;ssl=1 150w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Redrawn.jpg?resize=768%2C145&amp;ssl=1 768w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Redrawn.jpg?resize=1536%2C289&amp;ssl=1 1536w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Redrawn.jpg?w=2012&amp;ssl=1 2012w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Redrawn.jpg?w=936&amp;ssl=1 936w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Redrawn.jpg?w=1404&amp;ssl=1 1404w" sizes="(max-width: 468px) 100vw, 468px"></p>
<p><i><span>PAE Offices Are Matrix Organizations<br>
</span></i><span>Portfolio Acquisition Executives (PAEs) are organized as a matrix organization ‚Äì using people from existing organizations ‚Äì requirements, PEOs, sustainment, contracting etc. The PAEs themselves will have a small staff for coordination.</span></p>
<p><i><span>Portfolios Around Common Problems<br>
</span></i>In the past, Acquisition was organized by weapon systems and managed by Program Executive Offices. Portfolios will organize instead around common Warfighting Concepts, technologies, or operational integration needs.</p>
<p><i><span>Multiple Portfolios In Each Service<br>
</span></i><span>Each of the services are consolidating and reorganizing the functions of what were their Program Executive Offices into Portfolios. Program Executive Offices/Officers (PEOs) will become Capability Program Executives (CPEs), and act as a Portfolios‚Äô acquisition arm.</span></p>
<p><span>(The examples below are from the Army. Other Services will have equivalent organizational designs for their Portfolios.)</span></p>
<p><img data-recalc-dims="1" decoding="async" data-attachment-id="33274" data-permalink="https://steveblank.com/2025/11/11/the-department-of-war-just-shot-the-accountants-and-opted-for-speed/pae-reporting-structure/" data-orig-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Reporting-Structure.jpg?fit=1593%2C600&amp;ssl=1" data-orig-size="1593,600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="PAE Reporting Structure" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Reporting-Structure.jpg?fit=300%2C113&amp;ssl=1" data-large-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Reporting-Structure.jpg?fit=468%2C176&amp;ssl=1" src="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Reporting-Structure.jpg?resize=468%2C176&amp;ssl=1" alt="" width="468" height="176" srcset="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Reporting-Structure.jpg?resize=1024%2C386&amp;ssl=1 1024w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Reporting-Structure.jpg?resize=300%2C113&amp;ssl=1 300w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Reporting-Structure.jpg?resize=150%2C56&amp;ssl=1 150w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Reporting-Structure.jpg?resize=768%2C289&amp;ssl=1 768w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Reporting-Structure.jpg?resize=1536%2C579&amp;ssl=1 1536w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Reporting-Structure.jpg?w=1593&amp;ssl=1 1593w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Reporting-Structure.jpg?w=936&amp;ssl=1 936w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/PAE-Reporting-Structure.jpg?w=1404&amp;ssl=1 1404w" sizes="(max-width: 468px) 100vw, 468px">The acquisition chain of authority runs directly from Capability Program Manager to PAE to the Service Acquisition Executive (SAE), with no intermediate offices or approval layers. (The Service Acquisition Executive for the <span>Army is the </span><a href="https://www.army.mil/asaalt" target="_blank" rel="noopener">Assistant Secretary for Acquisition, Logistics &amp; Technology</a><span>. For the </span><span>Navy/Marines, the </span><a href="https://www.secnav.navy.mil/rda/Pages/default.aspx" target="_blank" rel="noopener">Assistant Secretary for Research, Development &amp; Acquisition</a>. For the <span>Air Force/Space Force the </span><a href="https://ww3.safaq.hq.af.mil/" target="_blank" rel="noopener">Assistant Secretary for Acquisition, Technology &amp; Logistics</a>.)</p>
<p><i><span>The Army Has 6 Portfolio Acquisition Executives<br>
</span></i><span>For example, the Army will likely reorganize its 12 existing PEO offices to become part of 6 portfolios aligned with Army <a href="https://www.armyupress.army.mil/Journals/Military-Review/English-Edition-Archives/September-October-2022/Ryan/" target="_blank" rel="noopener">Warfighting Concepts and functions</a>. Each of the 6 portfolios headed by a PAEs will be commanded by a Major General.</span></p>
<p><span>The likely 6 Army Portfolios are: 1) Maneuver, 2) Maneuver Air, 3)&nbsp; Fires, 4) C2/CC2,&nbsp; 5) Agile Sustainment and Ammo, and 6) Layered Protection and CBRN. One additional portfolio, called the PIT, will likely include the Army‚Äôs Innovation at the Edge activities.</span></p>
<blockquote><p><b>Army PAE Maneuver</b><span> will likely combine elements of </span><a href="https://www.peosoldier.army.mil/"><span>PEO Soldier</span></a><span>, </span><a href="https://asc.army.mil/web/peos/"><span>PEO Ground Combat Systems</span></a><span>, Future Capabilities Division and Maneuver Divisions, Test and Evaluation Integrator, Strategic Contracting Office, and others. This portfolio will likely have the Abrams tank, XM30 Mechanized Infantry Combat Vehicle (replacing the M2 Bradley), the ISV (Infantry Squad Vehicle), Soldier Borne Mission Command program (SBMC), </span><a href="https://www.peosoldier.army.mil/Equipment/Equipment-Portfolio/Project-Manager-Soldier-Lethality-Portfolio/Next-Generation-Squad-Weapons-Program/"><span>Next Generation Squad Weapon (NGSW),</span></a> <a href="https://www.peosoldier.army.mil/Equipment/Equipment-Portfolio/Project-Manager-Soldier-Warrior-Portfolio/Soldier-Borne-Sensor/"><span>Soldier Borne Sensor (SBS)</span></a><span> program, and Organization Clothing and Individual Equipment (OCIE).</span></p></blockquote>
<p><i><span>Authority to Make Trade-offs<br>
</span></i><span>PAEs now have the authority to make trade-offs between cost, schedule and performance and apply flexible funding between weapons systems to rapidly deliver capabilities to the warfighter. This means focusing on fielding ‚Äúgood enough‚Äù technology instead of waiting for a product that meets every single requirement.</span></p>
<blockquote><p><b>Army PAE Maneuver Air </b><span>will likely combine elements of Program Executive Office Aviation, Aviation and Missile Command, Futures Command Future Vertical Lift team </span><span>DEVCOM Aviation &amp; Missile</span><span>, and others. It will likely include the </span><a href="https://www.dote.osd.mil/Portals/97/pub/reports/FY2022/army/2022flraa1.pdf"><span>Long-Range Assault Aircraft (FLRAA)</span></a><span> the </span><a href="https://www.google.com/search?client=safari&amp;rls=en&amp;q=Bell+V-280+Valor&amp;ie=UTF-8&amp;oe=UTF-8&amp;mstk=AUtExfBXk1wpQ9nNWAH9wfiFhLZO4pyxDcL1iLabWTxIz3gepfqNP7falcz0lufv7o6EEc-zom0lNQBw0AW7zA59VyNMfvkozi14kulwI73uVf4dZTYUif6VJdBMllvs1ck4bB3sGqF-CVkOiIVKJp-hSbD3N-54xHv-bbtbllOvoVSxQEU&amp;csui=3&amp;ved=2ahUKEwiTos3ZxuaQAxWWFTQIHbyqIysQgK4QegQIARAE"><span>Bell V-280 Valor</span></a><span> (to replace the </span><a href="https://www.google.com/search?client=safari&amp;rls=en&amp;q=UH-60+Black+Hawk&amp;ie=UTF-8&amp;oe=UTF-8&amp;mstk=AUtExfBXk1wpQ9nNWAH9wfiFhLZO4pyxDcL1iLabWTxIz3gepfqNP7falcz0lufv7o6EEc-zom0lNQBw0AW7zA59VyNMfvkozi14kulwI73uVf4dZTYUif6VJdBMllvs1ck4bB3sGqF-CVkOiIVKJp-hSbD3N-54xHv-bbtbllOvoVSxQEU&amp;csui=3&amp;ved=2ahUKEwiTos3ZxuaQAxWWFTQIHbyqIysQgK4QegQIARAF"><span>UH-60 Black Hawk</span></a><span>), Uncrewed Aircraft Systems (UAS), Rotary and Fixed Wing, and Autonomy.</span></p></blockquote>
<p><i><span>Program Executive Officers (PEOs) are Now Capability Program Executives (CPEs)<br>
</span></i>Inside each portfolio is a Capability Program Executive (CPE), typically a Brigadier General or a civilian SES. Capability Program Executives have similar roles and responsibilities as today‚Äôs PEOs. They are the Acquisition leader responsible for cradle-to-grave management of their programs within their portfolio.</p>
<p><i><span>Streamlined Layers of Bureaucracy<br>
</span></i><span>97 Army acquisition programs may be reassigned to align with the Army PAE reorganization.&nbsp;</span><span>46 organizations that were writing requirements likely will be consolidated into 9 Future Capability Directorates.</span></p>
<blockquote><p><b>Army PAE Fires</b><span> will likely combine elements from Program Executive Office Missiles and Space, Enterprise Information Systems, the Rapid Capabilities and Critical Technologies Office, Fires System Center, and others. It will likely include the </span><a href="https://www.army-technology.com/projects/integrated-battle-command-system-ibcs-usa/"><span>Integrated Battle Command System (IBCS),</span></a> <a href="https://www.army-technology.com/projects/patriot/"><span>Patriot/PAC-3,</span></a> <a href="https://www.defensenews.com/land/2025/10/13/army-accelerates-prsm-output-as-atacms-nears-sunset/"><span>Precision Strike Missile (PrSM),</span></a> <a href="https://www.dote.osd.mil/Portals/97/pub/reports/FY2023/army/2023lrhw.pdf?ver=jClghaowEkarGt-qUGMXNg%3D%3D"><span>Long-Range Hypersonic Weapon ‚Äì Dark Eagle (LRHW),</span></a> <a href="https://www.army.mil/article/287739/army_developing_new_iterations_of_autonomous_missile_launcher"><span>Common Autonomous Multi-Domain Launcher (CAML),</span></a> <a href="https://www.army.mil/article/286099/shielding_the_pacific_inside_the_guam_defense_system_joint_program_office"><span>Guam Defense</span></a><span> and Golden Dome.</span></p></blockquote>
<p><i><span>DoW Will Buy Commercial First<br>
</span></i><span>One of the biggest changes is the mandate for PAEs to buy Commercial Off the Shelf (COTS) products, modify them if necessary and only buy bespoke products as a last resort. This change by itself is going to send shockwaves through the existing Prime contractors.</span></p>
<p><span>It‚Äôs telling everyone that the playing field is now open to everyone. Forget who has more lobbyists on K-Street. Speed, mission impact, and innovation is what will be rewarded. What this means for startups is that if you can execute and deliver (not just PowerPoints) you can become a supplier to the DoW.&nbsp;&nbsp;</span></p>
<p><i><span>Incentive Compensation to PAEs and Program Managers<br>
</span></i><span>PAEs will be judged on whether they deliver systems to the warfighter on time and on schedule. PAEs and Program Managers will have ‚Äúincentive compensation‚Äù tied to ‚Äúcapability delivery time, competition, and mission outcomes. (How they‚Äôll pay that kind of compensation for a member of the military remains to be seen.)</span></p>
<p><i><span>Incentives and Scorecards for Contractors<br>
</span></i>They‚Äôll be managing their contractors with ‚Äútime-indexed incentives‚Äù to make sure contractors deliver on time and on budget, using ‚Äúscorecards‚Äù to keep tabs on how each portfolio is doing.</p>
<blockquote><p><b>Army PAE C2/CC2 </b>(Command and Control/Counter Command and Control) <span>will likely combine elements of PEO Command, Control, Communications and Network.. And include NGC2, TITAN, TENCAP, Next Generation Constructive, STE</span></p></blockquote>
<p><i><span>Non-Traditional Entry Points</span></i><span><br>
</span><span>Companies selling to the DoW previously had to comply with the impenetrable DFAR and FAR ‚Äì the Defense and Federal Acquisition Regulations ‚Äì with over 5,000 pages of complex rules. It was designed for buying Aircraft Carriers, not startup technology.&nbsp;</span></p>
<p><span>Now the DoW is telling PAEs to toss those and use Non-FAR regulations like OTAs (Other Transaction Authorities). OTAs are not subject to the extensive, rigid rules and regulations of the DFAR. They allow for greater flexibility, speed, and allow the DoW to work with a broader range of innovative commercial companies. For startups this means massively reduced documentation, shorter timelines, and fewer barriers to working with the DoW.</span></p>
<p><i><span>PAEs Will Use Lean Methodology<br>
</span></i><span>Rather than fixed requirements and using waterfall development processes, the services are now insisting that vendors use Lean Methodology to set incremental and iterative delivery targets. That means they can field ‚Äúgood enough technology‚Äù that can be incrementally updated in the field and improved on a more frequent cadence.</span></p>
<p><span>The only requirement for each increment is that they need to target 1) an initial fielding date, </span><span><br>
</span><span>2) set a maximum cost of each unit and 3) meet the minimum standards for mission effectiveness. Other than that, PAEs have the authority that other attributes of the weapons/software can remain tradable throughout development to allow incremental enhancements and rapid delivery of subsequent increments. This includes the ability to waive technical standards and environmental and other compliance requirements, unless they are mandated by statute or safety.</span></p>
<p><span>One other interesting Lean mandate is that each PAE will set up lean technical advisory processes to inform accelerated decision-making, ensuring technical rigor without sacrificing speed.</span></p>
<p><i><span>Weapons Will Be Able to Talk to Each Other ‚Äì By Design<br>
</span></i>The new PAEs are also tasked with insisting that all weapons across their programs use&nbsp;<a href="https://breakingdefense.com/tag/modular-open-systems-architecture/">Modular Open System Architectures</a>, including by asserting government purpose rights over critical software interfaces ‚Äî a move that allows the Pentagon to retain the data rights needed to avoid ‚Äúvendor lock‚Äù (weapon systems that can only be modified and/or repaired by the company that designed it).</p>
<blockquote><p><b>Army PAE Agile Sustainment </b><span>will likely combine elements of PEO Combat Support and Combat Service Support, PEO Solider and PEO Joint Program Office Armaments and Ammunition. It will likely include next generation Common Tactical Truck (CTT,) Family of Medium Tactical Vehicles (FMTV), 155mm, 6.8mm ammunition.</span></p></blockquote>
<p><i><span>Two Vendors Through Initial Production<br>
</span></i><span>The DoW has painfully learned that having only one vendor selected leads to cost overruns and late projects. A new idea is that each critical acquisition program will have at least two qualified sources through initial production. While this will cost more upfront, it gives government leverage when it is strongest and enables them to re-compete modular components and find alternative suppliers if needed.</span></p>
<p><i><span>Design For Rapid Scale In a Crisis<br>
</span></i><span>PAEs have been told to establish acquisition strategies that decouple design from production to allow additional third-party suppliers to surge and rapidly scale manufacturing capacity in a crisis. They are to put in place&nbsp; guidelines for wartime consumption rates through manufacturing and supply chain partnerships and alternative sources.</span></p>
<blockquote><p><b>Army PAE Layered Protection and CBRN (</b><b>Chemical, Biological, Radiological, and Nuclear) </b><b></b><span>will likely combine elements of PEO JPEO-CBRND. It will likely include Joint Chemical Agent Detector, UIPE, Decontamination Family of Systems, Biometrics</span></p></blockquote>
<p><i><span>PAE Officers Now Have More Time To Learn On the Job<br>
</span></i><span>A complaint from past acquisition program managers is that they would only be there for two or three years, and then off to their next assignment. Two years was not enough time to see a program through. Now PAEs will have 4-year tours, extendible for another 2 years.</span></p>
<p><i><span>PAEs Top to Bottom<br>
</span></i><span>Every military service has 60 days to tell the Secretary of War a list of portfolios it is proposing to be initially stood up. A full implementation plan is due in 90 days. All major acquisition activities across all Services are going to be transitioned to PAE portfolios within two years.&nbsp;</span></p>
<blockquote><p><b>Army PIT </b><span>is the Army‚Äôs innovation initiatives at the edge. It‚Äôs the front door for startups wanting to partner with the Army.&nbsp;</span></p>
<ul>
<li><span>The PIT includes the Joint Innovation Outpost, the Global Tactical Edge Acquisition Directorate (G-TEAD) Marketplace, the </span><a href="https://fuze.army.mil/"><span>FUZE program</span></a><span>, and Disruptive Technologies.&nbsp;</span></li>
<li><span>The G-TEAD Marketplace merges Prize Challenge events (e.g., Army xTech Program) and DEP submissions through open call announcements.</span></li>
<li><span>FUZE brings together the </span><a href="https://fuze.army.mil/programs/sbir-sttr/"><span>Army SBIR/STTR</span></a><span> seed funding, </span><a href="https://fuze.army.mil/programs/mantech/"><span>MANTECH</span></a><span> (Army Manufacturing Technology program), </span><a href="https://fuze.army.mil/programs/tmi/"><span>TMI</span></a><span> (Tech Maturation Initiative) and </span><a href="https://fuze.army.mil/programs/xtech/"><span>XTech</span></a><span> the Army‚Äôs scouting program.&nbsp;</span></li>
</ul>
</blockquote>
<p><b>Reeducation Camp ‚Äì Warfighting Acquisition University<br>
</b><span>To retrain/reeducate contracting and acquisition officers, the ‚Äú</span><a href="https://www.dau.edu/" target="_blank" rel="noopener"><span>Defense Acquisition University</span></a><span>‚Äù will become the ‚ÄúWarfighting Acquisition University.‚Äù They have been ordered to stop compliance-focused training operations and in six months transform into a competency-based education institution.</span></p>
<p>The university will pivot to offer <span>experiential&nbsp;team-based programs</span> that work on real DoW challenges (does that ever sound like a description of <a href="https://www.h4d.us/" target="_blank" rel="noopener">Hacking for Defense.</a>) And they‚Äôre going to have their students get out of the building and take part in industry-government exchanges. In the next <span>six months they‚Äôre going to prioritize education and rotation programs to get their students exposure to commercial industry practices, manufacturing and operational expertise, and real-world problem-solving. </span>All to develop Acquisition executives critical thinking and agile and rapid decision-making skills. (Note to DAU: we‚Äôve been building these programs for a decade at the Stanford <a href="https://gordianknot.fsi.stanford.edu/" target="_blank" rel="noopener">Gordian Knot Center for National Security Innovation.</a> Our <a href="https://www.commonmission.us/" target="_blank" rel="noopener">national security classes</a> are in 60+ universities and we‚Äôre happy to help.)</p>
<p><b>The Joint Staff ‚Äì Coordinating the Needs of All the Services<br>
</b><span>While each of the Services generated their own weapons requirements, plans and budgets, they all had to be approved by the Joint Staff (which reports to the Secretary of War) through a </span><span>process called the JCIDS (Joint Capabilities Integration &amp; Development System). In theory this was to </span><span>coordinate each of the Service‚Äôs needs so they weren‚Äôt duplicating each other, to ensure that they were interoperable, and to give the Combatant Command a voice; and tie all the requirements to joint concepts ‚Äì all of this needing to be done before Service weapons programs got funded and built.</span></p>
<p><span>The problem was that JCIDS moved at the speed of paperwork, not war, so the Secretary of War eliminated it earlier this year. (They kept part of it called the </span><a href="https://ssl.armywarcollege.edu/dde/learningmodules/jsps/terms/jroc.cfm"><span>Joint Requirements Oversight Council</span></a><span> but reoriented it from validating documents to identifying joint operational problems, which will drive the priorities for the entire department of War.)&nbsp;</span></p>
<p><span>In JCIDS‚Äô place the Secretary of War created three new organizations:</span></p>
<ul>
<li aria-level="1"><span>The Joint Acceleration Reserve, a pool of money set aside to quickly field promising capabilities.</span></li>
<li aria-level="1"><span>The Requirements and Resourcing Alignment Board (RRAB) that will tie money directly to the top warfighting priorities and how much money each will get from the new Joint Acceleration Reserve.</span></li>
<li aria-level="1"><span>The Mission Engineering and Integration Activity </span><span>brings government, industry, and labs together early on to </span><span>rapidly</span><span> experiment, test, and prototype new tech.</span></li>
</ul>
<p><span>It‚Äôs interesting to note that none of these changes at the Joint Staff have seemed to (at least publicly) filter down to the charter of the Services Portfolio Acquisition Executives (PAEs). The achilles heel of the Services Acquisition process appears that they are still planning to put the Requirements and Capability gap analysis up front. &nbsp;Here‚Äôs why that‚Äôs a problem and how to fix it.</span></p>
<p><img data-recalc-dims="1" loading="lazy" decoding="async" data-attachment-id="33311" data-permalink="https://steveblank.com/2025/11/11/the-department-of-war-just-shot-the-accountants-and-opted-for-speed/sidebar-2/" data-orig-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Sidebar-1.jpg?fit=1504%2C1622&amp;ssl=1" data-orig-size="1504,1622" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Sidebar" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Sidebar-1.jpg?fit=278%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Sidebar-1.jpg?fit=468%2C504&amp;ssl=1" src="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Sidebar-1.jpg?resize=468%2C505&amp;ssl=1" alt="" width="468" height="505" srcset="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Sidebar-1.jpg?resize=950%2C1024&amp;ssl=1 950w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Sidebar-1.jpg?resize=278%2C300&amp;ssl=1 278w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Sidebar-1.jpg?resize=139%2C150&amp;ssl=1 139w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Sidebar-1.jpg?resize=768%2C828&amp;ssl=1 768w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Sidebar-1.jpg?resize=1424%2C1536&amp;ssl=1 1424w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Sidebar-1.jpg?w=1504&amp;ssl=1 1504w" sizes="auto, (max-width: 468px) 100vw, 468px"></p>
<p><b>Foreign military sales<br>
</b><span>One other tangential decision in this redesign was not in acquisition but in sales. The DoW wants a greater emphasis on selling our weapons to our Allies. They‚Äôve moved two agencies responsible for those functions ‚Äì the </span><a href="https://www.dtsa.mil/"><span>Defense Technology Security Administration</span></a> <a href="https://www.dtsa.mil/"><span>DTSA</span></a><span> and the </span><a href="https://www.dsca.mil/"><span>Defense Security Cooperation Agency (DSCA)</span></a><span> ‚Äì from OSD Policy to OSD Acquisition and Sustainment.&nbsp;</span></p>
<p><span>This move is about selling more of our equipment, but makes no mention of buying any equipment from our allies.</span></p>
<p><i><span>Inferred But Not Mentioned<br>
</span></i><span>Pretty interesting that in this reorg no one has noticed that <a href="https://www.war.gov/About/Biographies/Biography/Article/1230279/elbridge-a-colby/">Elbridge Colby</a> ‚Äì Under Secretary for Policy ‚Äì had three organizations taken away from him.&nbsp;&nbsp;</span></p>
<ol>
<li><a href="https://www.dtsa.mil/"><span>Defense Technology Security Administration</span></a> <a href="https://www.dtsa.mil/"><span>DTSA</span></a></li>
<li><a href="https://www.dsca.mil/"><span>Defense Security Cooperation Agency (DSCA)</span></a></li>
<li><span>The Joint Production Accelerator Cell (JPAC) now renamed the Wartime Production Unit (WPU)</span></li>
</ol>
<p><span>All three organizations were handed to <a href="https://www.acq.osd.mil/leadership/as/michael-duffey.html">Michael Duffey</a> the Under Secretary for Acquisition &amp; Sustainment. Regardless of the public statements the optics are not a vote of confidence.</span></p>
<p><b>Bigger and Better?<br>
</b><span>It appears that </span><a href="https://www.cto.mil/osc/"><span>the Office of Strategic Capital</span></a><span> may have been swallowed up by the Economic Defense Unit run by George Kolitdes. From all appearances the Economic Defense Unit is tasked to decouple our economy from China, using private and public capital. That means considering how to on-shore the critical components like minerals, chips, batteries, motors, PNT, etc.) The Acquisition announcement was how to buy things. This Economic Defense Unit is how do we ensure the things we buy are made with parts we know we can have an assured supply of?</span></p>
<p><img data-recalc-dims="1" loading="lazy" decoding="async" data-attachment-id="33289" data-permalink="https://steveblank.com/2025/11/11/the-department-of-war-just-shot-the-accountants-and-opted-for-speed/current-system/" data-orig-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Current-system.jpg?fit=1008%2C2400&amp;ssl=1" data-orig-size="1008,2400" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Current system" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Current-system.jpg?fit=126%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Current-system.jpg?fit=430%2C1024&amp;ssl=1" src="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Current-system.jpg?resize=468%2C1114&amp;ssl=1" alt="" width="468" height="1114" srcset="https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Current-system.jpg?resize=430%2C1024&amp;ssl=1 430w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Current-system.jpg?resize=126%2C300&amp;ssl=1 126w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Current-system.jpg?resize=63%2C150&amp;ssl=1 63w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Current-system.jpg?resize=768%2C1829&amp;ssl=1 768w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Current-system.jpg?resize=645%2C1536&amp;ssl=1 645w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Current-system.jpg?resize=860%2C2048&amp;ssl=1 860w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Current-system.jpg?w=1008&amp;ssl=1 1008w, https://i0.wp.com/steveblank.com/wp-content/uploads/2025/11/Current-system.jpg?w=936&amp;ssl=1 936w" sizes="auto, (max-width: 468px) 100vw, 468px"></p>
<p><b>Summary</b></p>
<blockquote>
<ul>
<li><span>Startups and the DoW are now speaking the same language ‚Äì Lean, feedback from the field, pivots, iterative and incremental product design, speed to delivery.</span></li>
<li><span>&nbsp;The DoW mandate to first buy commercial-off-the-shelf products is a once-in-a-lifetime opportunity for every startup and scaleup.</span>
<ul>
<li><span>But you have to deliver. Don‚Äôt hand wave with PowerPoints.</span></li>
<li><span>DoW will be ruthless in shutting down and freezing out non-performers.</span></li>
</ul>
</li>
<li><span>The use of Non-Federal Acquisition Regulations will eliminate huge amounts of paperwork.&nbsp;</span>
<ul>
<li><span>It eliminates one of the reasons to subcontract with a prime or other company&nbsp;</span></li>
</ul>
</li>
<li><span>DoW needs to be ruthless in reforming the compliance culture</span></li>
<li><span>Who to talk to in each service and how will they do business will be unclear for at least the next six months</span>
<ul>
<li><span>Reorganizations will create uncertainty of who is the front door for startups, how the new rules apply, and who can commit to contracts.</span></li>
<li><span>The Army appears to be further along than the other services in putting a PAE organization in place.</span></li>
</ul>
</li>
<li><span>In theory this is a knife to the heart of the Primes‚Äô business model.&nbsp;</span>
<ul>
<li><span>They will flood Congress and the Executive Branch with infinite capital to change these rules.</span></li>
<li><span>It‚Äôs a race between private capital and public company lobbying money</span></li>
</ul>
</li>
<li><span>Let‚Äôs hope these changes stick</span></li>
</ul>
</blockquote>
<p><span>Thanks to <a href="https://www.linkedin.com/in/petenewell/">Pete Newell</a> of BMNT for the feedback and insight.</span></p>
					
					<p>
						Filed under: <a href="https://steveblank.com/category/national-security/" rel="category tag">National Security</a>, <a href="https://steveblank.com/category/technology-innovation-and-modern-war-2/" rel="category tag">Technology Innovation and Modern War</a> |					</p>

				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scaling HNSWs (171 pts)]]></title>
            <link>https://antirez.com/news/156</link>
            <guid>45887466</guid>
            <pubDate>Tue, 11 Nov 2025 14:11:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://antirez.com/news/156">https://antirez.com/news/156</a>, See on <a href="https://news.ycombinator.com/item?id=45887466">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article data-comment-id="156-" id="156-"><span><span><a href="https://antirez.com/user/antirez">antirez</a></span> 8 hours ago. 23212 views.  </span><pre>I‚Äôm taking a few weeks of pause on my HNSWs developments (now working on some other data structure, news soon). At this point, the new type I added to Redis is stable and complete enough, it‚Äôs the perfect moment to reason about what I learned about HNSWs, and turn it into a blog post. That kind of brain dump that was so common pre-AI era, and now has become, maybe, a bit more rare. Well, after almost one year of thinking and implementing HNSWs and vector similarity stuff, it is time for some writing. However this is not going to be an intro on HNSWs: too many are present already. This is the ‚Äúextra mile‚Äù instead. If you know HNSWs, I want to share with you my more ‚Äúadvanced‚Äù findings, especially in the context of making them fast enough to allow for a ‚ÄúRedis‚Äù experience: you know, Redis is designed for low latency and high performance, and HNSWs are kinda resistant to that, so there were challenges to expose HNSWs as an abstract data structure.

This blog post will be split into several sections. Think of them as pages of the same book, different chapters of the same experience. Oh and, by the way, I already wrote and subsequently lost this blog post :D [long, sad story about MacOS and bad habits ‚Äì I hadn‚Äôt lost something like that since the 90s, during blackouts], so here most of the problem will be to recall what I wrote a few days ago and, while I‚Äôm at it, to better rephrase what I didn‚Äôt like very much.

## A few words about the state of HNSW

Before digging into the HNSWs internals and optimizations, I want to say a few things about HNSWs. The original paper introducing HNSWs is a great piece of computer science literature, and HNSWs are amazing data structures, but: I don‚Äôt believe they are the last word for searching, in a greedy way, for nearby vectors according to a distance function. The paper gives the feeling it lacks some ‚Äúpieces‚Äù, almost like if the researchers, given six months more, had a lot more to explore and say. For instance, I modified the paper myself, extending it in order to support removal of entries, actual removals, not just tombstone deletions where the element is marked as gone and collected later: deleting items is totally missing from the paper. Similarly, there are, right now, efforts in order to really check if the ‚ÄúH‚Äù in the HNSWs is really needed, and if instead a flat data structure with just one layer would perform more or less the same (I hope I‚Äôll cover more about this in the future: my feeling is that the truth is in the middle, and that it makes sense to modify the level selection function to just have levels greater than a given threshold).

All this to say that, if you are into data structures research, I believe that a great area is to imagine evolutions and refinements of HNSWs, without getting trapped within the idea that the evolutions are only in the sense of: let‚Äôs do it, but for disk (see Microsoft efforts), or the like. Ok, enough with the premise, let‚Äôs go to the actual low level stuff :)

## Scaling memory

Redis is an in-memory system, and both HNSWs and vectors have the unfortunate quality of being very space-hungry. There are three reasons for this: 1. HNSWs have a lot of pointers, like 16, 32 or more pointers (this is a tunable parameter of HNSWs) to neighbor nodes. 2. HNSWs have many levels, being a skiplist-alike data structure. This exacerbates the first problem. 3. HNSW‚Äôs satellite data is a vector of floating point numbers, so, in the vanilla case, 4 bytes per component, and normally you can have 300-3000 components, this is the usual range.

So, what are the lessons learned here? There are folks that compress pointers, since it is very likely that many pointers (8 bytes in 64 bit systems) will have the highest four bytes all the same. This is smart, I didn‚Äôt implement it yet, because in Redis I need to go fast, and this is a tradeoff between space and time: but maybe it is worth it, maybe not. I‚Äôll dig more. 

However, if you do the math, the fact that there are many layers is not *so* terrible as it looks. On average, the multiple layers per node make the situation worse by just ~1.3x (if the probability of level increase is 0.25 in the level selection function), since many nodes will be just at layer 0. But still 1.3 is more than 1, and if that ‚ÄúH‚Äù in HNSWs really is not *so* useful‚Ä¶ [Spoiler, what I found is that the seek time if you have everything at layer 0 is greater, the main loop for the greedy search will start from less optimal places and it will eventually reach the right cluster, but will take more computation time. However this is just early results.]

So here the *real* low hanging fruit is: vector quantization. What I found is that if you use 8 bit quantization what you get is an almost 4x speedup, a 4x reduction of your vectors (but not a 4x reduction of the whole node: the pointers are still there, and they take a lot of space), and a recall that is virtually the same in real world use cases. This is the reason why Redis Vector Sets use 8 bit quantization by default. You can specify, via VADD options, that you want full precision vectors or binary quantized vectors, where we just take the sign, but I‚Äôm skeptical about using both full size vectors and binary quantized vectors. Before talking about them, let‚Äôs see what kind of quantization I used for 8 bit.

What I do is to compute the maximum absolute value of the component of each vector (so quantization is per-vector), then I use signed 8 bit values to represent the quant from -127 to 127. This is not as good as storing both min and max value, but it is faster when computing cosine similarity, since I can do this:

    /* Each vector is quantized from [-max_abs, +max_abs] to [-127, 127]
     * where range = 2*max_abs. */
    const float scale_product = (range_a/127) * (range_b/127);

Then I multiply things together in the integer domain with (actually in the code the main loop is unrolled and uses multiple accumulators, to make modern CPUs more busy)

    for (; i &lt; dim; i++) dot0 += ((int32_t)x[i]) * ((int32_t)y[i]);

And finally we can return back to the floating point distance with:

    float dotf = dot0 * scale_product;

Check the vectors_distance_q8() for more information, but I believe you got the idea: it is very simple to go from the integer quants domain to the unquantized dotproduct with trivial operations.

So, 8 bit quantization is a great deal, and full precision was a *needed* feature, because there will be people doing things with vectors generated in a way where each small amount makes a difference (no, with learned vectors this is not the case‚Ä¶) but, why binary quantization? Because I wanted users to have a simple way to not waste space when their *original* information is already binary. Imagine you have a set of users and they have yes/no properties, and you want to find similar users, items, whatever. Well: this is where binary quantization should be used, it‚Äôs just, again, an option of the VADD command.

## Scaling speed: threading and locality

Oh, you know, I have to tell you something about myself: I‚Äôm not a fan of threaded systems when it is possible to do a lot with a single core, and then use multiple cores in a shared-nothing architecture. But HNSWs are different. They are *slow*, and they are accessed almost always in read-only ways, at least in most use cases. For this reason, my Vector Sets implementation is fully threaded. Not just reads, even writes are partially threaded, and you may wonder how this is possible without it resulting in a mess, especially in a system like Redis, where keys can be accessed in different ways by the background saving process, the clients, and so forth.


Well, to start, let‚Äôs focus on reads. What happens is that as long as nobody is writing in the data structure, we can spawn threads that do the greedy collection of near vectors and return back the results to the blocked client. However, my implementation of HNSWs was written from scratch, I mean, from the empty C file opened with vim, it has 0% of shared code with the two implementations most other systems use, so there are a few ‚Äúnovelties‚Äù. One of such different things is that in order to avoid re-visiting already visited nodes, I use an integer stored in each node that is called ‚Äúepoch‚Äù, instead of using another data structure to mark (like, in a hash table) nodes already visited. This is quite slow, I believe. The epoch instead is local to the node, and the global data structure increments the epoch for each search. So in the context of each search, we are sure that we can find epochs that are just &lt;= the current epoch, and the current epoch can be used to mark visited nodes.

But with threads, there are multiple searches occurring at the same time! And, yep, what I needed was an array of epochs:

typedef struct hnswNode {
    uint32_t level;         /* Node's maximum level */
    ‚Ä¶ many other stuff ‚Ä¶
    uint64_t visited_epoch[HNSW_MAX_THREADS];
}

That‚Äôs what you can read in hnsw.h. This is, again, a space-time tradeoff, and again time won against space.

So, how was it possible to have threaded writes? The trick is that in HNSW inserts, a lot of time is spent looking for neighbors candidates. So writes are split into a reading-half and commit-half, only the second needs a write lock, and there are a few tricks to make sure that the candidates we accumulated during the first part are discarded if the HNSW changed in the meantime, and some nodes may no longer be valid. There is, however, another problem. What about the user deleting the key, while background threads are working on the value? For this scenario, we have a function that waits for background operations to return before actually reclaiming the object. With these tricks, it is easy to get 50k ops/sec on real world vector workloads, and these are numbers I got from redis-benchmark itself, with all the overhead involved. The raw numbers of the flat HNSW library itself are much higher.

## Scaling memory: reclaiming it properly

Before talking about how to scale HNSWs into big use cases with multiple instances involved, and why Redis Vector Sets expose the actual data structure in the face of the user (I believe programmers are smart and don‚Äôt need babysitting, but it‚Äôs not *just* that), I want to go back and talk again about memory, because there is an interesting story to tell about this specific aspect.

Most HNSWs implementations are not able to reclaim memory directly when you delete a node from the graph. I believe there are two main reasons for that:

1. People misunderstand the original HNSW paper in a specific way: they believe links can be NOT reciprocal among neighbors. And there is a specific reason why they think so.

2. The paper does not say anything about deletion of nodes and how to fix the graph after nodes go away and we get missing links in the ‚Äúweb‚Äù of connections.

The first problem is a combination (I believe) of lack of clarity in the paper and the fact that, while implementing HNSWs, people face a specific problem: when inserting a new node, and good neighbors are searched among existing nodes, often the candidates already have the maximum number of outgoing links. What to do, in this case? The issue is often resolved by linking unidirectionally from the new node we are inserting to the candidates that are already ‚Äúfull‚Äù of outgoing links. However, when you need to delete a node, you can no longer resolve all its incoming links, so you can‚Äôt really reclaim memory. You mark it as deleted with a flag, and later sometimes there is some rebuilding of the graph to ‚Äúgarbage collect‚Äù stale nodes, sometimes memory is just leaked.

So, to start, my implementation in Redis does things differently by forcing links to be bidirectional. If A links to B, B links to A. But, how to do so, given that A may be busy? Well, this gets into complicated territory but what happens is that heuristics are used in order to drop links from existing nodes, with other neighbors that are well connected, and if our node is a better candidate even for the target node, and if this is not true there are other ways to force a new node to have at least a minimal number of links, always trying to satisfy the small world property of the graph.

This way, when Redis deletes a node from a Vector Set, it always has a way to remove all the pointers to it. However, what to do with the remaining nodes that now are missing a link? What I do is to create a distance matrix among them, in order to try to link the old node neighbors among them, trying to minimize the average distance. Basically for each pair of i,j nodes in our matrix, we calculate how good is their connection (how similar their vectors are) and how badly linking them affects the *remaining* possible pairs (since there could be elements left without good pairs, if we link two specific nodes). After we build this matrix of scores, we then proceed with a greedy pairing step.

This works so well that you can build a large HNSW with millions of elements, later delete 95% of all your elements, and the remaining graph still has good recall and no isolated nodes and so forth.

That is what I mean when I say that there is space in HNSWs for new papers to continue the work.

## Scaling HNSWs to multiple processes

When I started to work at Redis Vector Sets, there was already a vector similarity implementation in Redis-land, specifically as an index type of RediSearch, and this is how most people think at HNSWs: a form of indexing of existing data.

Yet I wanted to provide Redis with a new HNSW implementation exposed in a completely different way. Guess how? As a data structure, of course. And this tells a story about how Redis-shaped is my head after so many years, or maybe it was Redis-shaped since the start, and it is Redis that is shaped after my head, since I immediately envisioned how to design a Redis data structure that exposed HNSWs to the users, directly, and I was puzzled that the work with vectors in Redis was not performed exactly like that.

At the same time, when I handed my design document to my colleagues at Redis, I can‚Äôt say that they immediately ‚Äúsaw‚Äù it as an obvious thing. My reasoning was: vectors are like scores in Redis Sorted Sets, except they are not scalar scores where you have a total order. Yet you can VADD, VREM, elements, and then you can call VSIM instead of ZRANGE in order to have *similar* elements. This made sense not just as an API, but I thought of HNSWs as strongly composable, and not linked to a specific use case (not specific to text embeddings, or image embeddings, or even *learned* embeddings necessarily). You do:

    VADD my_vector_set VALUES [‚Ä¶ components ‚Ä¶] my_element_string

So whatever is in your components, Redis doesn't care, when you call VSIM it will report similar elements.

But this also means that, if you have different vectors about the same use case split in different instances / keys, you can ask VSIM for the same query vector into all the instances, and add the WITHSCORES option (that returns the cosine distance) and merge the results client-side, and you have magically scaled your hundred of millions of vectors into multiple instances, splitting your dataset N times [One interesting thing about such a use case is that you can query the N instances in parallel using multiplexing, if your client library is smart enough].

Another very notable thing about HNSWs exposed in this raw way, is that you can finally scale writes very easily. Just hash your element modulo N, and target the resulting Redis key/instance. Multiple instances can absorb the (slow, but still fast for HNSW standards) writes at the same time, parallelizing an otherwise very slow process.

This way of exposing HNSWs also scales down in a very significant way: sometimes you want an HNSW for each user / item / product / whatever you are working with. This is very hard to model if you have an index on top of something, but it is trivial if your HNSWs are data structures. You just can have a Vector Set key for each of your items, with just a handful of elements. And of course, like with any other Redis key, you can set an expiration time on the key, so that it will be removed automatically later.

All this can be condensed into a rule that I believe should be more present in our industry: many programmers are smart, and if instead of creating a magic system they have no access to, you show them the data structure, the tradeoffs, they can build more things, and model their use cases in specific ways. And your system will be simpler, too.

## Scaling loading times

If I don‚Äôt use threading, my HNSW library can add word2vec (300 components for each vector) into an HNSW at 5000 elements/second if I use a single thread, and can query the resulting HNSW at 90k queries per second. As you can see there is a large gap.

This means that loading back an HNSW with many millions of elements from a Redis dump file into memory would take a lot of time. And this time would impact replication as well. Not great. But, this is true only if we add elements from the disk to the memory in the most trivial way, that is storing ‚Äúelement,vector‚Äù on disk and then trying to rebuild the HNSW in memory. There is another lesson to learn here. When you use HNSWs, you need to serialize the nodes and the neighbors as they are, so you can rebuild everything in memory just allocating stuff and turning neighbors IDs into pointers. This resulted in a 100x speedup.

But do you really believe the story ends here? Hehe. Recently Redis has stronger security features and avoids doing bad things even when the RDB file is corrupted by an attacker. So what I needed to do was to make sure the HNSW is valid after loading, regardless of the errors and corruption in the serialized data structure. This involved many tricks, but I want to take the freedom to just dump one comment I wrote here, as I believe the reciprocal check is particularly cool:

    /* Second pass: fix pointers of all the neighbors links.
     * As we scan and fix the links, we also compute the accumulator
     * register "reciprocal", that is used in order to guarantee that all
     * the links are reciprocal.
     *
     * This is how it works, we hash (using a strong hash function) the
     * following key for each link that we see from A to B (or vice versa):
     *
     *      hash(salt || A || B || link-level)
     *
     * We always sort A and B, so the same link from A to B and from B to A
     * will hash the same. Then we xor the result into the 128 bit accumulator.
     * If each link has its own backlink, the accumulator is guaranteed to
     * be zero at the end.
     *
     * Collisions are extremely unlikely to happen, and an external attacker
     * can't easily control the hash function output, since the salt is
     * unknown, and also there would be to control the pointers.
     *
     * This algorithm is O(1) for each node so it is basically free for
     * us, as we scan the list of nodes, and runs on constant and very
     * small memory. */


## Scaling use cases: JSON filters

I remember the day when the first working implementation of Vector Sets felt complete. Everything worked as expected and it was the starting point to start with the refinements and the extra features.

However in the past weeks and months I internally received the feedback that most use cases need some form of mixed search: you want near vectors to a given query vector (like most similar movies to something) but also with some kind of filtering (only released between 2000 and 2010). My feeling is that you need to query for different parameters less often than product people believe, and that most of the time you can obtain this more efficiently by adding, in this specific case, each year to a different vector set key (this is another instance of the composability of HNSWs expressed as data structures versus a kind of index).

However I was thinking about the main loop of the HNSW greedy search, that is something like this:

// Simplified HNSW greedy search algorithm. Don‚Äôt trust it too much.
while(candidates.len() &gt; 0) {
    c = candidates.pop_nearest(query);
    worst_distance = results.get_worst_dist(query);
    if (distance(query,c) &gt; worst_distance) break;
    foreach (neighbor from c) {
        if (neighbor.already_visited()) continue;
        neighbor.mark_as_visited();
        if (results.has_space() OR neighbor.distance(query) &lt; worst_distance) {
            candidates.add(neighbor);
            results.add(neighbor);
        }
    }
}
return results;

So I started to play with the idea of adding a JSON set of metadata for each node. What if, once I have things like {‚Äúyear‚Äù: 1999}, this was enough to filter while I perform the greedy search? Sure, the search needed to be bound, but there is a key insight here: I want, to start, elements that are *near* to the query vector, so I don‚Äôt really need to explore the whole graph if the condition on the JSON attributes is not satisfied by many nodes. I‚Äôll let the user specify the effort, and anyway very far away results that match the filter are useless.

So that‚Äôs yet another way how my HNSW differs: it supports filtering by expressions similar to the ones you could write inside an ‚Äúif‚Äù statement of a programming language. And your elements in the Vector Set can be associated with JSON blobs, expressing their properties. Then you can do things like:


    VSIM movies VALUES ‚Ä¶ your vector components here‚Ä¶ FILTER '.year &gt;= 1980 and .year &lt; 1990'

## A few words on memory usage

HNSW‚Äôs fatal issue is ‚Äî in theory ‚Äî that they are normally served from memory. Actually, you can implement HNSWs on disk, even if there are better data structures from the point of view of disk access latencies. However, in the specific case of Redis and Vector Sets the idea is to provide something that is very fast, easy to work with: the flexibility of in-memory data structures help with that. So the question boils down to: is the memory usage really so bad?

Loading the 3 million Word2Vec entries into Redis with the default int8 quantization takes 3GB of RAM, 1kb for each entry. Many use cases have just a few tens of million of entries, or a lot less. And what you get back from HNSWs, if well implemented, and in memory, is very good performance, which is crucial in a data structure and in a workload that is in itself slow by definition. In my MacBook I get 48k ops per second with redis-benchmark and VSIM against this key (holding the word2vec dataset). My feeling is that the memory usage of in-memory HNSWs is very acceptable for many use cases. And even in the use cases where you want the bulk of your vectors on disk, even if there is to pay for slower performance, your hot set should likely be served from RAM.

This is one of the reasons why I believe that, to be active in HNSW research is a good idea: I don‚Äôt think they will be replaced anytime soon for most use cases. It seems more likely that we will continue to have different data structures that are ideal for RAM and for disk depending on the use cases and data size. Moreover, what I saw recently, even just scanning the Hacker News front page, is people with a few millions of items fighting with systems that are slower or more complicated than needed. HNSWs and carefully exposing them in the right way can avoid all that.

## Conclusions

I like HNSWs, and working and implementing them was a real pleasure. I believe vectors are a great fit for Redis, even in an AI-less world (for instance, a few months ago I used them in order to fingerprint Hacker News users, replicating an old work published on HN in the past). HNSWs are simply too cool and powerful for a number of use cases, and with AI, and learned embeddings, all this escalates to a myriad of potential use cases. However, like most features in Redis, I expect that a lot of time will pass before people realize they are useful and powerful and how to use them (no, it‚Äôs not just a matter of RAG). This happened also with Streams: finally there is mass adoption, after so many years.

If instead you are more interested in HNSW and the implementation I wrote, I believe the code is quite accessible, and heavily commented:

<a rel="nofollow" href="https://github.com/redis/redis/blob/unstable/modules/vector-sets/hnsw.c">https://github.com/redis/redis/blob/unstable/modules/vector-sets/hnsw.c</a>

If you want to learn more about Redis Vector Sets, please feel free to read the README file I wrote myself. There is also the official Redis documentation, but I suggest you start from here:

<a rel="nofollow" href="https://github.com/redis/redis/tree/unstable/modules/vector-sets">https://github.com/redis/redis/tree/unstable/modules/vector-sets</a>

Thanks for reading such a long blog post! And have a nice day.</pre></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI adoption in US adds ~900k tons of CO‚ÇÇ annually, study finds (102 pts)]]></title>
            <link>https://techxplore.com/news/2025-11-ai-tons-annually.html</link>
            <guid>45886917</guid>
            <pubDate>Tue, 11 Nov 2025 13:14:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techxplore.com/news/2025-11-ai-tons-annually.html">https://techxplore.com/news/2025-11-ai-tons-annually.html</a>, See on <a href="https://news.ycombinator.com/item?id=45886917">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
									    
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2025/ai-adoption-in-the-us.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2025/ai-adoption-in-the-us.jpg" data-sub-html="AI adoption in the US adds ~900,000 tons of CO‚ÇÇ annually, equal to 0.02% of national emissions. Credit: IOP Publishing">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2025/ai-adoption-in-the-us.jpg" alt="AI adoption in the US adds ~900,000 tons of CO‚ÇÇ annually, equal to 0.02% of national emissions" title="AI adoption in the US adds ~900,000 tons of CO‚ÇÇ annually, equal to 0.02% of national emissions. Credit: IOP Publishing" width="800" height="450">
             <figcaption>
                AI adoption in the US adds ~900,000 tons of CO‚ÇÇ annually, equal to 0.02% of national emissions. Credit: IOP Publishing
            </figcaption>        </figure>
    </div><p>A <a href="https://iopscience.iop.org/article/10.1088/1748-9326/ae0e3b" target="_blank">new study</a> published in <i>Environmental Research Letters</i> finds that continued growth in artificial intelligence (AI) use across the United States could add approximately 900,000 tons of CO‚ÇÇ annually. This is not a small amount but equates to a relatively minor increase when viewed in the context of nationwide emissions.</p>

                                        
                                              
                                        
                                                                                    <p>While AI adoption is expected to boost productivity and <a href="https://techxplore.com/tags/economic+output/" rel="tag">economic output</a>, researchers note that its environmental footprint can be seen as relatively modest compared to other industrial activities. The study examined potential AI integration across various sectors, estimating the associated rise in <a href="https://techxplore.com/tags/energy+use/" rel="tag">energy use</a> and carbon emissions.</p>
<h2>Key findings include:</h2>
<ul>
<li>AI adoption across the U.S. economy may result in an additional 896,000 tons of CO‚ÇÇ emissions per year, which represents just 0.02% of total U.S. emissions.</li>
<li>Energy use in individual industries could increase by up to 12 petajoules annually, comparable to the electricity consumption of around 300,000 U.S. homes.</li>
</ul>
<p>Co-author Anthony R. Harding explains, "While the projected emissions from AI adoption are modest compared to other sectors, they still represent a meaningful increase. This underscores the importance of integrating energy efficiency and sustainability into AI development and deployment, especially as adoption accelerates across industries."</p>
<p>As AI technologies become more integrated into daily operations, researchers encourage industry leaders to incorporate <a href="https://techxplore.com/tags/energy+efficiency/" rel="tag">energy efficiency</a> and sustainability into their AI strategies to ensure responsible growth as adoption scales.</p>

                                        
                                                                                
                                        											<div>
																								<p><strong>More information:</strong>
												Watts and Bots: The Energy Implications of AI Adoption, <i>Environmental Research Letters</i> (2025). <a data-doi="1" href="https://dx.doi.org/10.1088/1748-9326/ae0e3b" target="_blank">DOI: 10.1088/1748-9326/ae0e3b</a>
																								
																								</p>
																							</div>
                                        											
										                                            
                                                                                                                        
                                        <!-- print only -->
                                        <div>
                                            <p><strong>Citation</strong>:
                                                AI adoption in US adds ~900,000 tons of CO‚ÇÇ annually, study finds (2025, November 11)
                                                retrieved 11 November 2025
                                                from https://techxplore.com/news/2025-11-ai-tons-annually.html
                                            </p>
                                            <p>
                                            This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
                                            part may be reproduced without the written permission. The content is provided for information purposes only.
                                            </p>
                                        </div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Widespread distribution of bacteria containing PETases across global oceans (104 pts)]]></title>
            <link>https://academic.oup.com/ismej/article/19/1/wraf121/8159680?login=false</link>
            <guid>45886479</guid>
            <pubDate>Tue, 11 Nov 2025 12:22:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://academic.oup.com/ismej/article/19/1/wraf121/8159680?login=false">https://academic.oup.com/ismej/article/19/1/wraf121/8159680?login=false</a>, See on <a href="https://news.ycombinator.com/item?id=45886479">Hacker News</a></p>
Couldn't get https://academic.oup.com/ismej/article/19/1/wraf121/8159680?login=false: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI may not use lyrics without license, German court rules (206 pts)]]></title>
            <link>https://www.reuters.com/world/german-court-sides-with-plaintiff-copyright-case-against-openai-2025-11-11/</link>
            <guid>45886131</guid>
            <pubDate>Tue, 11 Nov 2025 11:20:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/world/german-court-sides-with-plaintiff-copyright-case-against-openai-2025-11-11/">https://www.reuters.com/world/german-court-sides-with-plaintiff-copyright-case-against-openai-2025-11-11/</a>, See on <a href="https://news.ycombinator.com/item?id=45886131">Hacker News</a></p>
Couldn't get https://www.reuters.com/world/german-court-sides-with-plaintiff-copyright-case-against-openai-2025-11-11/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[iPhone Pocket (435 pts)]]></title>
            <link>https://www.apple.com/newsroom/2025/11/introducing-iphone-pocket-a-beautiful-way-to-wear-and-carry-iphone/</link>
            <guid>45885813</guid>
            <pubDate>Tue, 11 Nov 2025 10:17:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.apple.com/newsroom/2025/11/introducing-iphone-pocket-a-beautiful-way-to-wear-and-carry-iphone/">https://www.apple.com/newsroom/2025/11/introducing-iphone-pocket-a-beautiful-way-to-wear-and-carry-iphone/</a>, See on <a href="https://news.ycombinator.com/item?id=45885813">Hacker News</a></p>
<div id="readability-page-1" class="page">


	
    







 
<nav id="ac-localnav" lang="en-US" role="navigation" aria-label="Newsroom" data-analytics-region="local nav" data-sticky="">
	
    
    
        




    
    
    
	
	

</nav>





<main id="main" role="main"> 




<span id="opens-in-new-window">opens in new window</span>
<section>
<article data-analytics-activitymap-region-id="article">






    
    
    









    





    <div>
        
		
        

        <div>
                
                
                
                    <h2>
                        
    
        Introducing iPhone Pocket: a&nbsp;beautiful way to wear and carry iPhone
    

                    </h2>
                
            </div>

        <div>
                
                
                    Born out of a collaboration between ISSEY&nbsp;MIYAKE and Apple, iPhone&nbsp;Pocket features a singular 3D-knitted construction designed to fit any iPhone
                
            </div>

        
            
    
    
    
    
    

        

    </div>







    
    
    






  
    
    
    
    
      <figure aria-label="Media, Two users pose with iPhone Pocket in lemon and black.">
        <div>
             
              
              <div>
                iPhone Pocket, born out of a collaboration between ISSEY MIYAKE and Apple, will be available at select Apple Store locations beginning Friday, November 14.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-hero.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-hero_big" aria-label="Download media, Two users pose with iPhone Pocket in lemon and black."></a>
          </div>
      </figure>
    
  








    
    
    


     
     
    
    
        <div>
             
                 <div>ISSEY MIYAKE and Apple today unveiled <a href="https://www.apple.com/shop/product/HS8R2ZM/A" target="_blank">iPhone Pocket</a>. Inspired by the concept of ‚Äúa piece of cloth,‚Äù its singular 3D-knitted construction is designed to fit any iPhone as well as all pocketable items. Beginning Friday, November 14, it will be available at select Apple Store locations and on <a href="https://www.apple.com/" target="_blank">apple.com</a> in France, Greater China, Italy, Japan, Singapore, South Korea, the UK, and the U.S.
</div>
                 
             
                 <div>iPhone Pocket features a ribbed open structure with the qualities of the original pleats by ISSEY MIYAKE. Born from the idea of creating an additional pocket, its understated design fully encloses iPhone, expanding to fit more of a user‚Äôs everyday items. When stretched, the open textile subtly reveals its contents and allows users to peek at their iPhone display. iPhone Pocket can be worn in a variety of ways ‚Äî handheld, tied onto bags, or worn directly on the body. Featuring a playful color palette, the short strap design is available in eight colors, and the long strap design in three colors.
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="iphone-pocket-color-options">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-500f573744cb93b53ae8377ed0858f3f" href="#gallery-500f573744cb93b53ae8377ed0858f3f" data-ac-gallery-trigger="gallery-500f573744cb93b53ae8377ed0858f3f"><span>All eight colors of iPhone Pocket short strap design.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-c4b99bd83aa685e677f8cc92bd31c905" href="#gallery-c4b99bd83aa685e677f8cc92bd31c905" data-ac-gallery-trigger="gallery-c4b99bd83aa685e677f8cc92bd31c905"><span>All three colors of iPhone Pocket long strap design.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-500f573744cb93b53ae8377ed0858f3f" aria-labelledby="gallery-dotnav-500f573744cb93b53ae8377ed0858f3f" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:short-strap-design">
                                
                                <div>
                                    <div>Featuring a playful color palette, the short strap design is available in eight colors: lemon, mandarin, purple, pink, peacock, sapphire, cinnamon, and black.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-short-strap-colors.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-short-strap-colors_big" aria-label="Download media, All eight colors of iPhone Pocket short strap design."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-c4b99bd83aa685e677f8cc92bd31c905" aria-labelledby="gallery-dotnav-c4b99bd83aa685e677f8cc92bd31c905" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:long-strap-design">
                                
                                <div>
                                    <div>The long strap design is available in three colors: sapphire, cinnamon, and black.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-long-strap-colors.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-long-strap-colors_big" aria-label="Download media, All three colors of iPhone Pocket long strap design."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <div>‚ÄúThe design of iPhone Pocket speaks to the bond between iPhone and its user, while keeping in mind that an Apple product is designed to be universal in aesthetic and versatile in use,‚Äù shared Yoshiyuki Miyamae, design director of MIYAKE DESIGN STUDIO. ‚ÄúiPhone Pocket explores the concept of ‚Äòthe joy of wearing iPhone in your own way.‚Äô The simplicity of its design echoes what we practice at ISSEY MIYAKE ‚Äî the idea of leaving things less defined to allow for possibilities and personal interpretation.‚Äù
</div>
                 
             
                 <div>‚ÄúApple and ISSEY MIYAKE share a design approach that celebrates craftsmanship, simplicity, and delight,‚Äù said Molly Anderson, Apple‚Äôs vice president of Industrial Design. ‚ÄúThis clever extra pocket exemplifies those ideas and is a natural accompaniment to our products. The color palette of iPhone Pocket was intentionally designed to mix and match with all our iPhone models and colors ‚Äî allowing users to create their own personalized combination. Its recognizable silhouette offers a beautiful new way to carry your iPhone, AirPods, and favorite everyday items.‚Äù
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="iphone-pocket-color-combos">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-0413a35321ffe4dbd41592bfeb2b2797" href="#gallery-0413a35321ffe4dbd41592bfeb2b2797" data-ac-gallery-trigger="gallery-0413a35321ffe4dbd41592bfeb2b2797"><span>iPhone Pocket in cinnamon paired with iPhone 17 Pro in cosmic orange.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-395d51cadfd7a3c84bd5bd1de138f580" href="#gallery-395d51cadfd7a3c84bd5bd1de138f580" data-ac-gallery-trigger="gallery-395d51cadfd7a3c84bd5bd1de138f580"><span>iPhone Pocket in sapphire paired with iPhone Air in sky blue.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-d57c53d12e0866bde9b77fabca8692fb" href="#gallery-d57c53d12e0866bde9b77fabca8692fb" data-ac-gallery-trigger="gallery-d57c53d12e0866bde9b77fabca8692fb"><span>iPhone Pocket in purple paired with iPhone 17 in lavender.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-0413a35321ffe4dbd41592bfeb2b2797" aria-labelledby="gallery-dotnav-0413a35321ffe4dbd41592bfeb2b2797" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:cinnamon-and-cosmic-orange-iphone-17-pro">
                                
                                <div>
                                    <div>Users can create their own personalized color combinations with iPhone Pocket and iPhone.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-cinnamon-with-iPhone-17-Pro.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-cinnamon-with-iPhone-17-Pro_big" aria-label="Download media, iPhone Pocket in cinnamon paired with iPhone 17 Pro in cosmic orange."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-395d51cadfd7a3c84bd5bd1de138f580" aria-labelledby="gallery-dotnav-395d51cadfd7a3c84bd5bd1de138f580" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:sapphire-and-sky-blue-iphone-air">
                                
                                <div>
                                    <div>Users can create their own personalized color combinations with iPhone Pocket and iPhone.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-sapphire-with-iPhone-Air.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-sapphire-with-iPhone-Air_big" aria-label="Download media, iPhone Pocket in sapphire paired with iPhone Air in sky blue."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-d57c53d12e0866bde9b77fabca8692fb" aria-labelledby="gallery-dotnav-d57c53d12e0866bde9b77fabca8692fb" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:purple-and-lavender-iphone-17">
                                
                                <div>
                                    <div>Users can create their own personalized color combinations with iPhone Pocket and iPhone.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-purple-with-iPhone-17-01.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-purple-with-iPhone-17-01_big" aria-label="Download media, iPhone Pocket in purple paired with iPhone 17 in lavender."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>A Piece of Cloth</strong>
</h2>
                 
             
                 <div>Crafted in Japan, iPhone Pocket features a singular 3D-knitted construction that is the result of research and development carried out at ISSEY MIYAKE. The design drew inspiration from the concept of ‚Äúa piece of cloth‚Äù and reinterpreted the everyday utility of the brand‚Äôs iconic pleated clothing. The development and design of iPhone Pocket unfolded in close collaboration with the Apple Design Studio, which provided insight into design and production throughout.
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="singular-construction">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-8c54c3d4fde598029a7c6b36d27e85a3" href="#gallery-8c54c3d4fde598029a7c6b36d27e85a3" data-ac-gallery-trigger="gallery-8c54c3d4fde598029a7c6b36d27e85a3"><span>A user poses with iPhone Pocket in peacock.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-8ec946387230a363dbe25e38306bce4d" href="#gallery-8ec946387230a363dbe25e38306bce4d" data-ac-gallery-trigger="gallery-8ec946387230a363dbe25e38306bce4d"><span>A user poses with iPhone Pocket in cinnamon.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-1b5cfe3976c01fb7746de0602809af8b" href="#gallery-1b5cfe3976c01fb7746de0602809af8b" data-ac-gallery-trigger="gallery-1b5cfe3976c01fb7746de0602809af8b"><span>iPhone Pocket in pink paired with a black ISSEY MIYAKE handbag.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-2fe4cea23e1e990c69431e909557f742" href="#gallery-2fe4cea23e1e990c69431e909557f742" data-ac-gallery-trigger="gallery-2fe4cea23e1e990c69431e909557f742"><span>iPhone Pocket in black.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-8f771a17f3ddef3f19c8c979d8ed6291" href="#gallery-8f771a17f3ddef3f19c8c979d8ed6291" data-ac-gallery-trigger="gallery-8f771a17f3ddef3f19c8c979d8ed6291"><span>iPhone Pocket in lemon and mandarin.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-56d430360d60f74d93b475a57eb36ebd" href="#gallery-56d430360d60f74d93b475a57eb36ebd" data-ac-gallery-trigger="gallery-56d430360d60f74d93b475a57eb36ebd"><span>iPhone Pocket in purple.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-8c54c3d4fde598029a7c6b36d27e85a3" aria-labelledby="gallery-dotnav-8c54c3d4fde598029a7c6b36d27e85a3" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:peacock">
                                
                                <div>
                                    <div>iPhone Pocket features a singular 3D-knitted construction that is the result of research and development carried out at ISSEY MIYAKE.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-peacock.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-peacock_inline" aria-label="Download media, A user poses with iPhone Pocket in peacock."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-8ec946387230a363dbe25e38306bce4d" aria-labelledby="gallery-dotnav-8ec946387230a363dbe25e38306bce4d" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:cinnamon">
                                
                                <div>
                                    <div>iPhone Pocket features a singular 3D-knitted construction that is the result of research and development carried out at ISSEY MIYAKE.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-cinnamon.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-cinnamon_inline" aria-label="Download media, A user poses with iPhone Pocket in cinnamon."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-1b5cfe3976c01fb7746de0602809af8b" aria-labelledby="gallery-dotnav-1b5cfe3976c01fb7746de0602809af8b" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:pink-and-black-issey-miyake-bag">
                                
                                <div>
                                    <div>Users can create their own personalized color combinations with iPhone Pocket and iPhone.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-pink-with-BAO-BAO-bag.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-pink-with-BAO-BAO-bag_inline" aria-label="Download media, iPhone Pocket in pink paired with a black ISSEY MIYAKE handbag."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-2fe4cea23e1e990c69431e909557f742" aria-labelledby="gallery-dotnav-2fe4cea23e1e990c69431e909557f742" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:black">
                                
                                <div>
                                    <div>The development and design of iPhone Pocket unfolded in close collaboration with the Apple Design Studio, which provided insight into design and production throughout.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-black-with-iPhone-17-Pro.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-black-with-iPhone-17-Pro_inline" aria-label="Download media, iPhone Pocket in black."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-8f771a17f3ddef3f19c8c979d8ed6291" aria-labelledby="gallery-dotnav-8f771a17f3ddef3f19c8c979d8ed6291" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:lemon-and-mandarin">
                                
                                <div>
                                    <div>The development and design of iPhone Pocket unfolded in close collaboration with the Apple Design Studio, which provided insight into design and production throughout.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-lemon-and-mandarin-with-iPhone-17-and-iPhone-Air.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-lemon-and-mandarin-with-iPhone-17-and-iPhone-Air_inline" aria-label="Download media, iPhone Pocket in lemon and mandarin."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-56d430360d60f74d93b475a57eb36ebd" aria-labelledby="gallery-dotnav-56d430360d60f74d93b475a57eb36ebd" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:purple">
                                
                                <div>
                                    <div>The development and design of iPhone Pocket unfolded in close collaboration with the Apple Design Studio, which provided insight into design and production throughout.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-purple-with-iPhone-17-02.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-purple-with-iPhone-17-02_inline" aria-label="Download media, iPhone Pocket in purple."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Availability</strong>
</h2>
                 
             
                 <div>iPhone Pocket is a limited-edition release. The short strap design is available in lemon, mandarin, purple, pink, peacock, sapphire, cinnamon, and black; the long strap design is available in sapphire, cinnamon, and black. iPhone Pocket in the short strap design retails at $149.95 (U.S.), and the long strap design at $229.95 (U.S.).
</div>
                 
             
                 <div>Customers can purchase iPhone Pocket beginning Friday, November 14, at select Apple Store locations and <a href="https://www.apple.com/" target="_blank">apple.com</a> in France, Greater China, Italy, Japan, Singapore, South Korea, the UK, and the U.S. Just in time for the holidays, Apple Specialists in stores and online can help customers mix and match different lengths and colors with their iPhone, style iPhone Pocket, and purchase their new favorite accessory.
</div>
                 
             
                 <div><ul>
<li>Apple Canton Road, Hong Kong</li>
<li>Apple Ginza, Tokyo</li>
<li>Apple Jing‚Äôan, Shanghai</li>
<li>Apple March√© Saint-Germain, Paris</li>
<li>Apple Myeongdong, Seoul</li>
<li>Apple Orchard Road, Singapore</li>
<li>Apple Piazza Liberty, Milan</li>
<li>Apple Regent Street, London</li>
<li>Apple SoHo, New York City</li>
<li>Apple Xinyi A13, Taipei</li>
</ul>
</div>
                 
             
         </div>
 

    
    
    




    
    
        
    


    
    
    



    
    
    




    




    
    
    






    















	

		
		
			
























		
		

</article>



</section>
</main>



<div>
            Stay up to date with the latest articles from Apple Newsroom.
        </div>
	

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why effort scales superlinearly with the perceived quality of creative work (128 pts)]]></title>
            <link>https://markusstrasser.org/creative-work-landscapes.html</link>
            <guid>45885242</guid>
            <pubDate>Tue, 11 Nov 2025 08:29:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://markusstrasser.org/creative-work-landscapes.html">https://markusstrasser.org/creative-work-landscapes.html</a>, See on <a href="https://news.ycombinator.com/item?id=45885242">Hacker News</a></p>
<div id="readability-page-1" class="page"><article> <p><!--[--><time datetime="2025-11-02T00:00:00.000Z">November 2, 2025</time><!--]--> <!--[--><span>¬∑ 1 min read</span><!--]--> <!--[--><span>¬∑</span><!--]--> Send your thoughts via <a target="_blank" href="https://twitter.com/mkstra"><!---->twitter</a> or <a target="_blank" href="mailto:strasser.ms@gmail.com"><!---->mail</a>. <!--[!--><!--]--></p> <p><span>Abstract claim:</span> <em>The act of creation is fractal exploration‚Äìexploitation under optimal feedback control.
		When resolution increases the portion of parameter space that doesn't make the artifact
		worse (<em>acceptance volume</em>) collapses. Verification latency and rate‚Äìdistortion
		combine into a precision tax that scales superlinearly with perceived quality.</em></p> <p>When I make something good, I often spend most of my time making thousands of
	high-precision edits on an artifact that I thought should have been finished hours ago.
	Previously, I called this 'last-mile edits', but that was the wrong mental image.</p> <p>"Last mile" implies executing a known plan with diminishing returns but "last mile" at one
	level just becomes "early exploration" at higher resolution at the next level. Instead of
	treating exploration (idea) and exploitation (execution) as temporally separated phases,
	they nest recursively. That nested search is where the effort goes.</p> <p>Once you commit to D minor, this scene, that argument structure you've constrained the
	search space and now you search again within it.</p> <p>Take some of my quicker five-minute, gestural sketches below. You'd think they break this
	nested search dynamic but with a closer look it becomes clear that I just front-loaded my
	taxes by caching motor heuristics.</p> <figure id="figure-1"><!--[!--><!--]--> <p><img src="https://markusstrasser.org/media/art/sketches-masonry.jpg" alt="Five-minute gestural sketches showing practiced circular strokes and face-like abstractions"></p> <!--[--><figcaption><a href="#figure-1">Figure
				1</a>: <!--[-->A closer look shows the same set of practiced, comfortable gestures that click with my hand shape. They gravitate toward broad, confident circular strokes and shorter straight lines, just short enough to keep them stable. I'm executing cached heuristics, not exploring. I revert to face-like abstractions and focus on having the center hold. I do not like when *The Center Does Not Hold*.<!--]--></figcaption><!--]--></figure><!----> <p>Domains and modalities differ in how wide and forgiving their basins are and how quickly
	you can verify the edit (<em>feedback latency</em>). Music timing has a narrow basin at the
	micro-level (<em>¬±20 ms can kill a groove</em>) but can be more forgiving higher up: key
	and pitch changes can be interchangeable without loss of quality, not often though. Prose
	has a wide basin (many phrasings work). Abstract, contemporary art has extremely wide
	basin, so much so that nobody with any self-respect even bothers anymore. Renaissance
	paintings have more constraints and less distortion tolerance.</p> <table><thead><tr><th>Modality</th><th>Basin</th><th>Verifier</th><th>Speed</th></tr></thead><tbody><tr><td>Text (prose)</td><td>Wide</td><td>Human read</td><td>Minutes</td></tr><tr><td>Code</td><td>Wide (design) / Narrow (syntax)</td><td>Compiler/tests</td><td>ms-seconds</td></tr><tr><td>Music timing</td><td>Narrow</td><td>Ear‚Äìbody</td><td>~20-40ms</td></tr><tr><td>Line drawing</td><td>Narrow</td><td>Eye‚Äìhand</td><td>~100ms</td></tr></tbody></table> <p>Let's take the following optimization landscape and assume it's for the process of writing
	a song. To make it simpler, let's constrain like this: We've written the lyrics and picked
	a BPM of 80.</p> <p>The wider, more forgiving hill corresponds to choosing C major on the macro level, but
	there might be a higher, sharper peak in E minor that's trickier‚Äîi.e., it demands more
	precision edits.</p> <figure id="figure-2"><!--[!--><!--]--> <p><img src="https://markusstrasser.org/media/essays/creative-work-landscapes/logseq-screenshot.png" alt="3D optimization landscape with Z-axis representing quality"></p> <!--[--><figcaption><a href="#figure-2">Figure
				2</a>: <!--[-->Z-axis is quality (warmer = better). X and Y are arbitrary parameters.<!--]--></figcaption><!--]--></figure><!----> <p>Wide basins let coarse proposals land. This is where almost all generative AI outputs live and the oxygen is still plenty. Near a sharp peak, the <strong>acceptance volume<span><sup>a</sup></span> <!----><!----> shrinks rapidly</strong> and you can‚Äôt reliably see micro-improvements without averaging more evidence or trials. The controller (often the hand) makes many tiny corrections after some latency. Rinse and repeat until the piece sits on a hard-to-vary peak.</p> <p>That's why effort seems like it scales superlinearly as perceived quality rises. Judging
	the intermediate artifact takes more time and most edits (the search) make it worse.
	Geometrically bad edits become more likely and land you lower in the landscape.</p> <p>Craft, then, is the slog of closing ever-less-perceivable gaps.</p> <h2 id="faqs"><a href="#faqs">FAQs</a></h2> <p><strong>Don't bands sometimes record a banger song in an hour together?</strong></p> <p>The tower-climbing happened during practice (*muscle memory*), not recording. Jazz is closer to real-time exploration and mistakes are more accepted and expected.</p> <p><strong>Drawing takes forever because you're exploring AND refining simultaneously.</strong></p> <p>We don't "rehearse" a specific drawing, we solve a novel problem in real-time. There's no cached motor sequence to execute.</p> <div><p><strong>BibTeX Citation</strong></p><pre><code>@misc{strasser2025,
  author = {Strasser, Markus},
  title = {Why Effort Scales Superlinearly with the Perceived Quality of Creative Work},
  year = {2025},
  url = {https://markusstrasser.org/},
  note = {Accessed: 2025-11-11}
}</code></pre></div><!----><!----></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SoftBank sells its entire stake in Nvidia for $5.83B (299 pts)]]></title>
            <link>https://www.cnbc.com/2025/11/11/softbank-sells-its-entire-stake-in-nvidia-for-5point83-billion.html</link>
            <guid>45884937</guid>
            <pubDate>Tue, 11 Nov 2025 07:32:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2025/11/11/softbank-sells-its-entire-stake-in-nvidia-for-5point83-billion.html">https://www.cnbc.com/2025/11/11/softbank-sells-its-entire-stake-in-nvidia-for-5point83-billion.html</a>, See on <a href="https://news.ycombinator.com/item?id=45884937">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-108065851" data-test="InlineImage"><p>Nvidia CEO Jensen Huang (L) and the CEO of the SoftBank Group Masayoshi Son pose during an AI event in Tokyo on November 13, 2024.</p><p>Akio Kon | Bloomberg | Getty Images</p></div><div><p><a id="107312506" href="https://www.cnbc.com/quotes/" type="security" brand="cnbc" section="[object Object]" contentclassification="">SoftBank</a> said Tuesday it has sold its entire stake in U.S. chipmaker <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-2"><a href="https://www.cnbc.com/quotes/NVDA/">Nvidia</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> for $5.83 billion as the Japanese giant looks to capitalize on its <a href="https://www.cnbc.com/2025/06/27/softbank-ceo-says-he-wanted-to-be-openai-early-investor.html">"all in"</a> bet on ChatGPT maker OpenAI. </p><p>The firm said in its earnings statement that it sold 32.1 million Nvidia shares in October. It also disclosed that it sold part of its T-Mobile stake for $9.17 billion.</p><p>"We want to provide a lot of investment opportunities for investors, while we can still maintain financial strength," said SoftBank's Chief Financial Officer Yoshimitsu Goto during an investor presentation. </p><p>"So through those options and tools we make sure that we are ready for funding in a very safe manner," he said in comments translated by the company, adding that the stake sales were part of the firm's strategy for "asset monetization."</p><p>Nvidia shares dipped 0.95% in premarket trade on Tuesday.</p><p>While the Nvidia exit may come as a surprise to some investors, it's not the first time SoftBank has cashed out of the American AI chip darling.</p><p>SoftBank's Vision Fund was an early backer of Nvidia, <a href="https://www.cnbc.com/2017/05/24/the-stock-markets-hottest-stock-nvidia-just-got-a-big-new-backer.html">reportedly amassing</a> a $4 billion stake in 2017 before <a href="https://www.cnbc.com/2019/02/06/softbank-vision-fund-sells-nvidia-stake.html">selling all</a> of its holdings in January 2019. Despite its latest sale, SoftBank's business interests remain heavily intertwined with Nvidia's.</p></div><div id="Placeholder-ArticleBody-Video-108212821" data-test="VideoPlaceHolder" role="region" tabindex="0" data-vilynx-id="7000392166" aria-labelledby="Placeholder-ArticleBody-Video-108212821"><p><img src="https://image.cnbcfm.com/api/v1/image/108212822-17605971971760597195-42119380833-1080pnbcnews.jpg?v=1760597197&amp;w=750&amp;h=422&amp;vtcrop=y" alt="ABB CEO: Softbank will be good home for robotics business"><span></span><span></span></p></div><div><p>That Tokyo-based company is involved in a number of AI ventures that rely on Nvidia's technology, including the $500 billion Stargate project for data centers in the U.S.</p><p>"This should not be seen, in our view, as a cautious or negative stance on Nvidia, but rather in the context of SoftBank needing at least $30.5bn of capital for investments in the Oct-Dec quarter, including $22.5bn for OpenAI and $6.5bn for Ampere," Rolf Bulk, equity research analyst at New Street Research, told CNBC.</p><p>That amounts to "more in a single quarter than it has invested in aggregate over the two prior years combined," Bulk said.</p><p>Morningstar's Dan Baker added that he doesn't see the move as representing a fundamental shift in strategy for the company.</p><p>"[SoftBank] made a point of saying that it wasn't any view on NVIDIA... At the end of the day, they are using the money to invest in other AI related companies," he said.</p></div><h2><a id="headline0"></a>Vision fund posts blowout $19 billion gain</h2><div><p>The stake sales and a blowout gain of $19 billion from SoftBank's Vision Fund helped the company <a href="https://www.cnbc.com/2025/11/11/softbank-earnings-report-2q.html">double its profit</a> in its fiscal second quarter.</p><p>The Vision Fund has been aggressively pushing into artificial intelligence, investing and acquiring firms throughout the AI value chain from chips to large language models and robotics.</p><p>"The reason we were able to have this result is because of September last year, that was the first time we invested in OpenAI," said SoftBank's Goto. He added that OpenAI's <a href="https://www.cnbc.com/2025/10/02/openai-share-sale-500-billion-valuation.html">latest valuation milestone of $500 billion</a> marks one of the largest valuations in the world, according to fair value.  </p></div><div><div role="button" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" width="256" height="256" viewBox="0 0 256 256" aria-labelledby="title desc" role="img" focusable="false" preserveAspectRatio="xMinYMin"><title>Stock Chart Icon</title><desc>Stock chart icon</desc><g transform="translate(1.4065934065934016 1.4065934065934016) scale(2.81 2.81)"><path d="M 87.994 0 H 69.342 c -1.787 0 -2.682 2.16 -1.418 3.424 l 5.795 5.795 l -33.82 33.82 L 28.056 31.196 l -3.174 -3.174 c -1.074 -1.074 -2.815 -1.074 -3.889 0 L 0.805 48.209 c -1.074 1.074 -1.074 2.815 0 3.889 l 3.174 3.174 c 1.074 1.074 2.815 1.074 3.889 0 l 15.069 -15.069 l 14.994 14.994 c 1.074 1.074 2.815 1.074 3.889 0 l 1.614 -1.614 c 0.083 -0.066 0.17 -0.125 0.247 -0.202 l 37.1 -37.1 l 5.795 5.795 C 87.84 23.34 90 22.445 90 20.658 V 2.006 C 90 0.898 89.102 0 87.994 0 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 65.626 37.8 v 49.45 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 23.518 L 65.626 37.8 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 47.115 56.312 V 87.25 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 42.03 L 47.115 56.312 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 39.876 60.503 c -1.937 0 -3.757 -0.754 -5.127 -2.124 l -6.146 -6.145 V 87.25 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 59.844 C 41.952 60.271 40.933 60.503 39.876 60.503 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 22.937 46.567 L 11.051 58.453 c -0.298 0.298 -0.621 0.562 -0.959 0.8 V 87.25 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 48.004 L 22.937 46.567 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path></g></svg><p><img src="https://static-redesign.cnbcfm.com/dist/a54b41835a8b60db28c2.svg" alt="hide content"></p></div><p>Softbank's shares this year</p></div><div><p>The Japanese conglomerate's stock has slumped in the past week as <a href="https://www.cnbc.com/2025/11/07/ai-valuation-fears-grip-investors-as-tech-bubble-concerns-heighten.html">concerns of an AI bubble</a> sent jitters through global markets. </p><p>"Our share price recently has been going up and down dynamically‚Ä¶ we want to provide as many invest opportunities as possible," said Goto Tuesday, adding that the company's announced four-for-one stock split is part of its strategy to provide as many investment opportunities for shareholders as possible.</p></div></div></div>]]></description>
        </item>
    </channel>
</rss>