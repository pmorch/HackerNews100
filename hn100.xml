(ignoring known css parsing error)
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 02 Aug 2025 15:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Compressing Icelandic name declension patterns into a 3.27 kB trie (126 pts)]]></title>
            <link>https://alexharri.com/blog/icelandic-name-declension-trie</link>
            <guid>44766718</guid>
            <pubDate>Sat, 02 Aug 2025 11:28:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alexharri.com/blog/icelandic-name-declension-trie">https://alexharri.com/blog/icelandic-name-declension-trie</a>, See on <a href="https://news.ycombinator.com/item?id=44766718">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main><p>Displaying personal names in Icelandic user interfaces is surprisingly hard. This is because of <em>declension</em> — a language feature where the forms of nouns change to communicate a syntactic function.</p>
<p>In Icelandic, personal names have four forms, one for each of the <a target="_blank" href="https://en.wikipedia.org/wiki/Icelandic_grammar#Nouns">grammatical cases of Icelandic nouns</a>. Take the name <em>“Guðmundur”</em>:</p>
<table><tbody><tr><th>Grammatical case</th><th>Form</th></tr><tr><td>Nominative</td><td>Guðmundur</td></tr><tr><td>Accusative</td><td>Guðmund</td></tr><tr><td>Dative</td><td>Guðmundi</td></tr><tr><td>Genitive</td><td>Guðmundar</td></tr></tbody></table>
<p>When including a name in a sentence, the sentence’s structure determines the grammatical case, and correspondingly, a certain form of the name should be used. Using the wrong form results in a “broken” feel that native speakers associate with non-native speakers not yet fluent in the language.</p>
<p>The problem is that Icelandic personal names are always stored in the <a target="_blank" href="https://en.wikipedia.org/wiki/Nominative_case">nominative</a> case. If you’ve loaded a user from a database, their name will be in the nominative case. This creates a problem when you have a sentence structure that requires, for example, the <a target="_blank" href="https://en.wikipedia.org/wiki/Accusative_case">accusative</a> form of the name.</p>
<p>As a developer, you can work around that by rewriting the sentence to use the nominative case, which can be <em>very</em> awkward, or by using a pronoun (e.g. <em>they</em>). Both are unsatisfactory.</p>
<p>A few years ago, I built a JavaScript library to solve this issue. It applies any of the four grammatical cases to an Icelandic name, provided in the nominative case:</p>
<div><pre><p><span>applyCase</span><span>(</span><span>"Guðmundur"</span><span>,</span><span> </span><span>"accusative"</span><span>)</span><span></span></p></pre></div>
<p>When building this library, I did not code <em>any</em> declension rules by hand. Instead, the rules of Icelandic name declension are derived from public Icelandic data for personal names and their forms. The rules are encoded in a trie-like data structure that uses clever compression techniques to get the library’s bundle size under 4.5 kB gzipped. This lets the library be included in web apps without increasing bundle size significantly.</p>
<p>The rest of the post will walk through this problem in detail, and go over the compression techniques I used to get the trie to such a small size.</p>
<h2>Data for Icelandic name declension</h2>
<p>Iceland has a publicly run institution, <a target="_blank" href="https://www.arnastofnun.is/en">Árnastofnun</a>, that manages the <a target="_blank" href="https://bin.arnastofnun.is/DMII/">Database of Icelandic Morphology</a> (DIM). The database was created, amongst other reasons, to support Icelandic language technology.</p>
<p>DIM publishes various <a target="_blank" href="https://bin.arnastofnun.is/DMII/LTdata/">datasets</a>, but we’ll use <a target="_blank" href="https://bin.arnastofnun.is/DMII/LTdata/k-format/">Kristín’s Format</a> (the K-format), downloadable as a CSV. Here’s what the K-format data entries for “Guðmundur” look like:</p>
<div><pre><p><span><span>Guðmundur</span><span>;355264;kk;ism;1;;;;K;</span><span>Guðmundur</span><span>;</span><span>NFET</span><span>;1;;;</span></span></p><p><span><span>Guðmundur</span><span>;355264;kk;ism;1;;;;K;</span><span>Guðmund</span><span>;</span><span>ÞFET</span><span>;1;;;</span></span></p><p><span><span>Guðmundur</span><span>;355264;kk;ism;1;;;;K;</span><span>Guðmundi</span><span>;</span><span>ÞGFET</span><span>;1;;;</span></span></p><p><span><span>Guðmundur</span><span>;355264;kk;ism;1;;;;K;</span><span>Guðmundar</span><span>;</span><span>EFET</span><span>;1;;;</span></span></p><p><span><span>^^^^^^^^^</span>                      <span>^^^^^^^^^</span> <span>^^^^</span></span></p><p><span><span>Name</span>                           <span>Form</span>      <span>Case</span></span></p></pre></div>
<p>From this, we can see that the name “Guðmundur” in the accusative (ÞFET) case is “Guðmund”, and so on.</p>
<p>From the K-format data, we can construct an array for each name containing its form for each grammatical case:</p>
<div><pre><p><span>[</span><span></span></p><p><span>  </span><span>"Guðmundur"</span><span>,</span><span> </span><span></span></p><p><span>  </span><span>"Guðmund"</span><span>,</span><span>   </span><span></span></p><p><span>  </span><span>"Guðmundi"</span><span>,</span><span>  </span><span></span></p><p><span>  </span><span>"Guðmundar"</span><span>,</span><span> </span><span></span></p><p><span></span><span>]</span><span></span></p></pre></div>
<p>However, the K-format has data for most words in the Icelandic language, not just personal names. With over <strong>7 million</strong> entries, this data set is huge. We’ll need some way to whittle the list down.</p>
<p>Luckily for us, Iceland has the <a target="_blank" href="https://island.is/en/search-in-icelandic-names">Personal Names Register</a>. It lists all Icelandic personal names approved — and rejected — by the <a target="_blank" href="https://en.wikipedia.org/wiki/Icelandic_Naming_Committee">Personal Names Committee</a> (yes, that exists).</p>
<p>We can use the set of approved Icelandic names to filter the K-format data. Of the roughly 4,500 approved Icelandic names, the K-format has declension data for over 3,600. With that, we have declension data for more than 80% of Icelandic names:</p>
<div><pre><p><span>const</span><span> </span><span>NAME_FORMS</span><span> </span><span>=</span><span> </span><span>[</span><span></span></p><p><span>  </span><span>[</span><span></span></p><p><span>    </span><span>"Aðalberg"</span><span>,</span><span></span></p><p><span>    </span><span>"Aðalberg"</span><span>,</span><span></span></p><p><span>    </span><span>"Aðalberg"</span><span>,</span><span></span></p><p><span>    </span><span>"Aðalbergs"</span><span></span></p><p><span>  </span><span>]</span><span>,</span><span></span></p><p><span>  </span><span>[</span><span></span></p><p><span>    </span><span>"Agnes"</span><span>,</span><span></span></p><p><span>    </span><span>"Agnesi"</span><span>,</span><span></span></p><p><span>    </span><span>"Agnesi"</span><span>,</span><span></span></p><p><span>    </span><span>"Agnesar"</span><span></span></p><p><span>  </span><span>]</span><span>,</span><span></span></p><p><span></span><span>]</span><span></span></p></pre></div>
<h2>Naive implementation</h2>
<p>With the declension data in place, let’s get to writing our library. The library will export a single <code><span>applyCase</span></code> function that takes a name in the nominative case and the grammatical case that the name should be returned in:</p>
<div><pre><p><span>function</span><span> </span><span>applyCase</span><span>(</span><span>name</span><span>:</span><span> </span><span>string</span><span>,</span><span> grammaticalCase</span><span>:</span><span> Case</span><span>)</span><span> </span><span>{</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>applyCase</span><span>(</span><span>"Guðmundur"</span><span>,</span><span> </span><span>"accusative"</span><span>)</span><span></span></p></pre></div>
<p>The naive implementation would be to find the forms of the name and the index of the form to return:</p>
<div><pre><p><span>const</span><span> </span><span>CASES</span><span> </span><span>=</span><span> </span><span>[</span><span>"nominative"</span><span>,</span><span> </span><span>"accusative"</span><span>,</span><span> </span><span>"dative"</span><span>,</span><span> </span><span>"genitive"</span><span>]</span><span>;</span><span></span></p><p><span></span><span>function</span><span> </span><span>applyCase</span><span>(</span><span>name</span><span>:</span><span> </span><span>string</span><span>,</span><span> grammaticalCase</span><span>:</span><span> Case</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> nameForms </span><span>=</span><span> </span><span>NAME_FORMS</span><span>.</span><span>find</span><span>(</span><span>forms </span><span>=&gt;</span><span> forms</span><span>[</span><span>0</span><span>]</span><span> </span><span>===</span><span> name</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>const</span><span> caseIndex </span><span>=</span><span> </span><span>CASES</span><span>.</span><span>indexOf</span><span>(</span><span>grammaticalCase</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p></pre></div>
<p>and, with those in hand, return the form at <code><span>caseIndex</span></code> if <code><span>nameForms</span></code> was found for the input <code><span>name</span></code>, otherwise returning <code><span>name</span></code> as a fallback:</p>
<div><pre><p><span>function</span><span> </span><span>applyCase</span><span>(</span><span>name</span><span>:</span><span> </span><span>string</span><span>,</span><span> grammaticalCase</span><span>:</span><span> Case</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> nameForms </span><span>=</span><span> </span><span>NAME_FORMS</span><span>.</span><span>find</span><span>(</span><span>forms </span><span>=&gt;</span><span> forms</span><span>[</span><span>0</span><span>]</span><span> </span><span>===</span><span> name</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>const</span><span> caseIndex </span><span>=</span><span> </span><span>CASES</span><span>.</span><span>indexOf</span><span>(</span><span>grammaticalCase</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>return</span><span> nameForms</span><span>?.</span><span>[</span><span>caseIndex</span><span>]</span><span> </span><span>||</span><span> name</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p></pre></div>
<p>This “works” but has two main issues, the first of which is bundle size. The <code><span>NAME_FORMS</span></code> list is about 30 kB gzipped, which I think is a tad much to add to a web app’s bundle size.</p>
<p>The second issue is that this naive implementation only works for names in the <code><span>NAME_FORMS</span></code> list. As mentioned earlier, there are around 800 approved Icelandic names that are not covered by the DIM data.</p>
<p>Let’s see how we can solve both of those.</p>
<h2>Encoding the forms compactly</h2>
<p>We’re currently storing the four forms of each name in full. We can remove a lot of redundancy by finding the <a target="_blank" href="https://leetcode.com/problems/longest-common-prefix">longest common prefix</a> of the name and the suffixes of each form.</p>
<p>Consider the forms of “Guðmundur”:</p>
<div><pre><p><span>Guðmundur</span></p><p><span>Guðmund</span></p><p><span>Guðmundi</span></p><p><span>Guðmundar</span></p></pre></div>
<p>The longest common prefix is “Guðmund”, and the suffixes are as follows:</p>
<div><pre><p><span><span>Guðmund</span> <span>ur</span></span></p><p><span><span>Guðmund</span></span></p><p><span><span>Guðmund</span> <span>i</span></span></p><p><span><span>Guðmund</span> <span>ar</span></span></p><p><span><span>^^^^^^^</span> <span>^^</span></span></p><p><span><span>Prefix</span>  <span>Suffix</span></span></p></pre></div>
<p>We can store the suffixes compactly in a string like so:</p>

<p>Which for Guðmundur, gives us:</p>

<p>Since <code><span>applyCase</span></code> receives the nominative case of the name as input, we can derive the prefix from the length of the nominative suffix’s length.</p>
<div><pre><p><span>function</span><span> </span><span>getPrefix</span><span>(</span><span>nameNominative</span><span>,</span><span> suffixLength</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>return</span><span> nameNominative</span><span>.</span><span>slice</span><span>(</span><span>0</span><span>,</span><span> </span><span>-</span><span>suffixLength</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>const</span><span> suffixes </span><span>=</span><span> </span><span>"ur,,i,ar"</span><span>;</span><span></span></p><p><span></span><span>const</span><span> nominativeSuffix </span><span>=</span><span> suffixes</span><span>.</span><span>split</span><span>(</span><span>","</span><span>)</span><span>[</span><span>0</span><span>]</span><span>;</span><span></span></p><p><span></span><span>getPrefix</span><span>(</span><span>"Guðmundur"</span><span>,</span><span> nominativeSuffix</span><span>.</span><span>length</span><span>)</span><span></span></p></pre></div>
<p>We’ll call this method of encoding the suffixes of each form in a string the “suffix encoding”, or just “encoding”, from here on.</p>
<p>A feature of the suffix encoding is that the encoding is not tied to any specific name (“Guðmund” appears nowhere). Instead, the suffix encoding describes a <em>pattern</em> of declension, which we’ll use to our advantage later.</p>
<h2>Retrieving the suffixes by name</h2>
<p>When we were storing the raw forms in an array, it was very easy to find the forms of any given name:</p>
<div><pre><p><span>NAME_FORMS</span><span>.</span><span>find</span><span>(</span><span>forms </span><span>=&gt;</span><span> forms</span><span>[</span><span>0</span><span>]</span><span> </span><span>===</span><span> name</span><span>)</span><span></span></p></pre></div>
<p>But the suffix encoding doesn’t encode the name itself, so we need a way to retrieve the encoding. The simplest method would be a plain hash map:</p>
<div><pre><p><span>const</span><span> nameToFormsEncoding </span><span>=</span><span> </span><span>{</span><span></span></p><p><span>  Guðmundur</span><span>:</span><span> </span><span>"ur,,i,ar"</span><span>,</span><span></span></p><p><span></span><span>}</span><span>;</span><span></span></p></pre></div>
<p>Putting bundle size concerns aside, a hash map doesn’t solve the problem of names not in the list of approved Icelandic names being excluded.</p>
<p>Here, one helpful fact about Icelandic declension is that names with similar suffixes <em>tend</em> to follow the same pattern of declension. These names ending in <em>“ur”</em> all have the same suffix encoding of <code><span>"ur,,i,ar"</span></code>:</p>
<div><pre><p><span>Ástvaldur</span></p><p><span>Bárður</span></p><p><span>Freymundur</span></p><p><span>Ingimundur</span></p><p><span>Sigurður</span></p><p><span>Þórður</span></p></pre></div>
<p>There are, in fact, 88 approved Icelandic names with this exact pattern of declension, and they all end with <em>“dur”</em>, <em>“tur”</em> or “<em>ður</em>”.</p>
<p>The naive approach, then, would be to implement a <code><span>getSuffixEncoding</span></code> function that captures these patterns:</p>
<div><pre><p><span>function</span><span> </span><span>getSuffixEncoding</span><span>(</span><span>name</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>if</span><span> </span><span>(</span><span>/</span><span>(d|ð|t)ur$</span><span>/</span><span>.</span><span>test</span><span>(</span><span>name</span><span>)</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>return</span><span> </span><span>"ur,,i,ar"</span><span>;</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span><span></span></p></pre></div>
<p>But that quickly breaks down. There are other names ending with <em>“ður”</em> or <em>“dur”</em> that follow a different pattern of declension:</p>
<ul>
<li><em>“Aðalráður”</em> and <em>“Arnmóður”</em> have a suffix encoding of <code><span>"ur,,i,s"</span></code></li>
<li><em>“Baldur”</em> has a suffix encoding of <code><span>"ur,ur,ri,urs"</span></code></li>
<li><em>“Hlöður”</em> and <em>“Lýður”</em> both have a suffix encoding of <code><span>"ur,,,s"</span></code></li>
</ul>
<p>In fact, take a look at this <a target="_blank" href="https://gist.github.com/alexharri/2102bad44fbce8f4c41615304b09e1fe">gist</a> showing every approved Icelandic personal name grouped by their suffix encoding (there are 124 unique encodings). You’ll immediately find patterns, but if you take a closer look you’ll find numerous counterexamples to those patterns. Capturing all of these rules and their exceptions in code would be a tedious and brittle affair.</p>
<p>Instead of trying to code up the rules manually, we can use a data structure that lends itself perfectly to this problem.</p>
<h2>Tries</h2>
<p>The <a target="_blank" href="https://en.wikipedia.org/wiki/Trie">trie</a> data structure, also known as a prefix tree, is a tree data structure that maps string keys to values. In tries, each character in the key becomes a node in the tree that points to the next possible characters.</p>
<p>Take, for example, the name <em>“Heimir”</em>, which has a suffix encoding of <code><span>"r,,,s"</span></code>. If we create an empty trie and insert <em>“Heimir”</em> and <code><span>"r,,,s"</span></code> as a key-value pair into it, we get:</p>

<p>Let’s now insert <em>“Heiðar”</em> into the trie, which has a suffix encoding of <code><span>"r,,i,s"</span></code>. The names share the first three characters, so they share the first three nodes in the trie:</p>

<p>However, we actually want to insert the keys <em>backwards</em> into the trie. That is because, like I mentioned earlier, names with similar endings (suffixes) tend to have similar suffix encodings. Inserting keys backwards results in the values for all names sharing a certain suffix being grouped within that suffix’s subtree.</p>
<p>Let’s take a concrete example — consider the following names that end with <em>“ur”</em> and their encodings:</p>
<div><pre><p><span><span>Ylfur</span>    <span>ur,i,i,ar</span></span></p><p><span><span>Knútur</span>   <span>ur,,i,s</span></span></p><p><span><span>Hrútur</span>   <span>ur,,i,s</span></span></p><p><span><span>Loftur</span>   <span>ur,,i,s</span></span></p><p><span><span>Name</span>     <span>Suffix encoding</span></span></p></pre></div>
<p>Inserting them <em>backwards</em> into a new trie gives us the following:</p>

<p>Once we start inserting the names backwards, every node in the trie corresponds to a specific suffix match:</p>
<ul>
<li>The <span><span>r</span><span></span><span>u</span></span> subtree corresponds to the <em>“ur”</em> suffix.</li>
<li>The <span><span>r</span><span></span><span>u</span><span></span><span>t</span></span> subtree corresponds to the <em>“tur”</em> suffix.</li>
</ul>
<p>Additionally:</p>
<ul>
<li>The <span><span>r</span><span></span><span>u</span></span> subtree contains the values for all names ending in <em>“ur”</em>.</li>
<li>The <span><span>r</span><span></span><span>u</span><span></span><span>t</span></span> subtree contains the values for all names ending in <em>“tur”</em>.</li>
</ul>
<p>Having the values of names sharing a common suffix all within the same subtree will help us find patterns in suffix-to-value mappings. We can then apply those patterns to not-before-seen names.</p>
<p>Before we get to that, let’s quickly cover trie lookups.</p>
<h2>Trie lookups</h2>
<p>Let’s implement a <code><span>trieLookup</span></code> function that takes the trie’s <code><span>root</span></code> node and a <code><span>key</span></code> (name) to find a value for:</p>
<div><pre><p><span>interface</span><span> </span><span>TrieNode</span><span> </span><span>{</span><span></span></p><p><span>  children</span><span>?</span><span>:</span><span> </span><span>{</span><span> </span><span>[</span><span>key</span><span>:</span><span> </span><span>string</span><span>]</span><span>:</span><span> TrieNode </span><span>}</span><span>;</span><span></span></p><p><span>  value</span><span>?</span><span>:</span><span> </span><span>string</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>function</span><span> </span><span>trieLookup</span><span>(</span><span>root</span><span>:</span><span> TrieNode</span><span>,</span><span> key</span><span>:</span><span> </span><span>string</span><span>)</span><span> </span><span>{</span><span></span></p><p><span></span><span>}</span><span></span></p></pre></div>
<p>For each character in the key, we traverse to the child <code><span>node</span></code> for that character, stopping if no such <code><span>node</span></code> exists. After that, we return the value of the resulting <code><span>node</span></code>, if present:</p>
<div><pre><p><span>function</span><span> </span><span>trieLookup</span><span>(</span><span>root</span><span>:</span><span> TrieNode</span><span>,</span><span> key</span><span>:</span><span> </span><span>string</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>let</span><span> node</span><span>:</span><span> TrieNode </span><span>|</span><span> </span><span>undefined</span><span> </span><span>=</span><span> root</span><span>;</span><span></span></p><p><span>  </span><span>for</span><span> </span><span>(</span><span>const</span><span> char </span><span>of</span><span> </span><span>reverse</span><span>(</span><span>key</span><span>)</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    node </span><span>=</span><span> node</span><span>.</span><span>children</span><span>?.</span><span>[</span><span>char</span><span>]</span><span>;</span><span></span></p><p><span>    </span><span>if</span><span> </span><span>(</span><span>!</span><span>node</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>      </span><span>break</span><span>;</span><span></span></p><p><span>    </span><span>}</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span>  </span><span>return</span><span> node</span><span>?.</span><span>value</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p></pre></div>
<p>Note: <!-- -->We reverse the lookup key because names are inserted into the trie backwards.</p>
<p>Looking up a name that we insert into the trie returns its suffix encoding, as expected:</p>
<div><pre><p><span>trieLookup</span><span>(</span><span>root</span><span>,</span><span> </span><span>"Loftur"</span><span>)</span><span></span></p></pre></div>
<h2>Compressing the trie</h2>
<p>In our trie from earlier, every leaf in the <span><span>r</span><span></span><span>u</span><span></span><span>t</span></span> subtree has the same value of <code><span>"ur,,i,s"</span></code>:</p>

<p>When every leaf in a subtree has a common value, we can <em>compress</em> the subtree. We do that by setting the value of the subtree’s root to the value of its leaves, and then deleting every child of the root.</p>

<p>The trie from above, compressed.</p>
<p>Let’s quickly implement a recursive <code><span>compress</span></code> function that performs this operation:</p>
<div><pre><p><span>function</span><span> </span><span>compress</span><span>(</span><span>node</span><span>:</span><span> TrieNode</span><span>)</span><span>:</span><span> </span><span>string</span><span> </span><span>|</span><span> </span><span>null</span><span> </span><span>{</span><span></span></p><p><span></span><span>}</span><span></span></p></pre></div>
<p>The <code><span>compress</span></code> function should return <code><span>null</span></code> and do nothing if <code><span>node</span></code>’s children do not share a single common value. If they <em>do</em> share a common value, it should delete all of its children and assign their common value to itself.</p>
<p>The first step is to collect the values of <code><span>node</span></code>’s children by invoking <code><span>compress</span></code> recursively (using a <a target="_blank" href="https://en.wikipedia.org/wiki/Depth-first_search">depth-first</a> traversal):</p>
<div><pre><p><span>const</span><span> values </span><span>=</span><span> Object</span><span>.</span><span>values</span><span>(</span><span>node</span><span>.</span><span>children</span><span>)</span><span>.</span><span>map</span><span>(</span><span>compress</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>If there is not a single shared value, we return <code><span>null</span></code>:</p>
<div><pre><p><span>if</span><span> </span><span>(</span><span>new</span><span> </span><span>Set</span><span>(</span><span>values</span><span>)</span><span>.</span><span>size </span><span>!==</span><span> </span><span>1</span><span> </span><span>||</span><span> values</span><span>[</span><span>0</span><span>]</span><span> </span><span>==</span><span> </span><span>null</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>return</span><span> </span><span>null</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p></pre></div>
<p>Otherwise, we assign the value to <code><span>node</span></code>, remove the children, and return the value.</p>
<div><pre><p><span>node</span><span>.</span><span>value </span><span>=</span><span> values</span><span>[</span><span>0</span><span>]</span><span>;</span><span></span></p><p><span>node</span><span>.</span><span>children </span><span>=</span><span> </span><span>{</span><span>}</span><span>;</span><span></span></p><p><span></span><span>return</span><span> node</span><span>.</span><span>value</span><span>;</span><span></span></p></pre></div>
<p>This gives us:</p>
<div><pre><p><span>function</span><span> </span><span>compress</span><span>(</span><span>node</span><span>:</span><span> TrieNode</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> values </span><span>=</span><span> Object</span><span>.</span><span>values</span><span>(</span><span>node</span><span>.</span><span>children</span><span>)</span><span>.</span><span>map</span><span>(</span><span>compress</span><span>)</span><span>;</span><span></span></p><p><span>  values</span><span>.</span><span>push</span><span>(</span><span>node</span><span>.</span><span>value</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>if</span><span> </span><span>(</span><span>new</span><span> </span><span>Set</span><span>(</span><span>values</span><span>)</span><span>.</span><span>size </span><span>!==</span><span> </span><span>1</span><span> </span><span>||</span><span> values</span><span>[</span><span>0</span><span>]</span><span> </span><span>==</span><span> </span><span>null</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>return</span><span> </span><span>null</span><span>;</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span>  node</span><span>.</span><span>value </span><span>=</span><span> values</span><span>[</span><span>0</span><span>]</span><span>;</span><span></span></p><p><span>  node</span><span>.</span><span>children </span><span>=</span><span> </span><span>{</span><span>}</span><span>;</span><span></span></p><p><span>  </span><span>return</span><span> node</span><span>.</span><span>value</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>compress</span><span>(</span><span>root</span><span>)</span><span>;</span><span></span></p></pre></div>
<p>Let’s take a second look at the compressed trie:</p>

<p>After compression, it communicates the following information:</p>
<ul>
<li>All names ending in <em>“fur”</em> resolve to a value of <code><span>"ur,i,i,ar"</span></code></li>
<li>All names ending in <em>“tur”</em> resolve to a value of <code><span>"ur,,i,s"</span></code></li>
</ul>
<p>When we originally inserted <em>“Ylfur”</em> into the trie, the associated value was stored under <span><span>r</span><span></span><span>u</span><span></span><span>f</span><span></span><span>l</span><span></span><span>Y</span></span>, but after compressing the trie, only the <span><span>r</span><span></span><span>u</span><span></span><span>f</span></span> part of that path remains.</p>
<p>This means that our <code><span>trieLookup</span></code> function from earlier will return <code><span>null</span></code> for <em>“Ylfur”</em>:</p>
<div><pre><p><span>function</span><span> </span><span>trieLookup</span><span>(</span><span>root</span><span>:</span><span> TrieNode</span><span>,</span><span> key</span><span>:</span><span> </span><span>string</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>let</span><span> node</span><span>:</span><span> TrieNode </span><span>|</span><span> </span><span>undefined</span><span> </span><span>=</span><span> root</span><span>;</span><span></span></p><p><span>  </span><span>for</span><span> </span><span>(</span><span>const</span><span> char </span><span>of</span><span> </span><span>reverse</span><span>(</span><span>key</span><span>)</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    node </span><span>=</span><span> node</span><span>.</span><span>children</span><span>?.</span><span>[</span><span>char</span><span>]</span><span>;</span><span></span></p><div data-type="info"><p><span>&nbsp;<!-- -->&nbsp;<!-- -->&nbsp;<!-- -->&nbsp;<!-- -->//&nbsp;</span><span></span>'node' will be null for 'f-&gt;l'</p></div><p><span>    </span><span>if</span><span> </span><span>(</span><span>!</span><span>node</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>      </span><span>break</span><span>;</span><span></span></p><p><span>    </span><span>}</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span>  </span><span>return</span><span> node</span><span>?.</span><span>value</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>trieLookup</span><span>(</span><span>root</span><span>,</span><span> </span><span>"Ylfur"</span><span>)</span><span></span></p></pre></div>
<p>We can fix that by returning the value of the last node we encountered:</p>
<div><pre><p><span>function</span><span> </span><span>trieLookup</span><span>(</span><span>root</span><span>:</span><span> TrieNode</span><span>,</span><span> key</span><span>:</span><span> </span><span>string</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>let</span><span> node </span><span>=</span><span> root</span><span>;</span><span></span></p><p><span>  </span><span>for</span><span> </span><span>(</span><span>const</span><span> char </span><span>of</span><span> </span><span>reverse</span><span>(</span><span>key</span><span>)</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>const</span><span> next </span><span>=</span><span> node</span><span>.</span><span>children</span><span>?.</span><span>[</span><span>char</span><span>]</span><span>;</span><span></span></p><p><span>    </span><span>if</span><span> </span><span>(</span><span>!</span><span>next</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>      </span><span>break</span><span>;</span><span></span></p><p><span>    </span><span>}</span><span></span></p><p><span>    node </span><span>=</span><span> next</span><span>;</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span>  </span><span>return</span><span> node</span><span>.</span><span>value</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>trieLookup</span><span>(</span><span>root</span><span>,</span><span> </span><span>"Ylfur"</span><span>)</span><span></span></p></pre></div>
<p>We only override <code><span>node</span></code> if there is a <code><span>next</span></code> node.</p>
<p>Now, looking up the original four input names returns the values for those names:</p>
<div><pre><p><span>trieLookup</span><span>(</span><span>trie</span><span>,</span><span> </span><span>"Ylfur"</span><span>)</span><span>  </span><span></span></p><p><span></span><span>trieLookup</span><span>(</span><span>trie</span><span>,</span><span> </span><span>"Knútur"</span><span>)</span><span> </span><span></span></p><p><span></span><span>trieLookup</span><span>(</span><span>trie</span><span>,</span><span> </span><span>"Hrútur"</span><span>)</span><span> </span><span></span></p><p><span></span><span>trieLookup</span><span>(</span><span>trie</span><span>,</span><span> </span><span>"Loftur"</span><span>)</span><span> </span><span></span></p></pre></div>
<p>However, we also get values for lookup keys not in the original input data:</p>
<div><pre><p><span>trieLookup</span><span>(</span><span>trie</span><span>,</span><span> </span><span>"Bjartur"</span><span>)</span><span></span></p></pre></div>
<p>This was not the case prior to compressing the trie — only the original input keys returned a value in the original trie.</p>
<p>Lookups in the compressed trie return</p>
<ul>
<li><code><span>"ur,i,i,ar"</span></code> for all lookup keys matching <code>*fur</code>, and</li>
<li><code><span>"ur,,i,s"</span></code> for all lookup keys matching <code>*tur</code>.</li>
</ul>
<p>The compressed trie has, in some sense, “learned” the suffix patterns of the input data, and returns values based on that.</p>
<p>Names in the input data ending in <code>*tur</code> always resolved to the same value so the <span><span>r</span><span></span><span>u</span><span></span><span>t</span></span> subtree was compressed — same with <code>*fur</code>. However, there were multiple values for names ending in <code>*ur</code> so the tree diverges after <span><span>r</span><span></span><span>u</span></span>:</p>

<p>This divergence raises a question: what about names matching <code>*ur</code> but neither <code>*fur</code> nor <code>*tur</code>?</p>
<p><em>“Sakur”</em> is one such key. When invoking <code><span>trieLookup</span></code> the last hit <code><span>node</span></code> is the <span><span>u</span></span> node. Since <span><span>u</span></span> has no value, <code><span>null</span></code> is returned:</p>
<div><pre><p><span>trieLookup</span><span>(</span><span>trie</span><span>,</span><span> </span><span>"Sakur"</span><span>)</span><span></span></p></pre></div>
<p>If every key in the trie’s input data ending in <code>*ur</code> were to resolve to the same value, then <em>“Sakur”</em> should resolve to that value. However, not every key ending in <code>*ur</code> resolves to the same value — keys ending in <code>*tur</code> resolve to one value and keys ending in <code>*fur</code> to another.</p>
<p>For a key matching <code>*ur</code> but not <code>*(t|f)ur</code>, we <em>could</em> just pick one of the branches. However, at most one of the branches resolves to the correct value (and in many cases, none of the branches do). The natural conclusion, then, is to <em>not</em> return a value.</p>
<hr>
<p>The compressed trie acts as a sort of suffix-to-value pattern matcher. If a certain suffix in the input data always maps to a certain value, the compressed trie always returns that value for keys matching the suffix. But for “ambiguous” suffix matches, no value is returned.</p>
<p>Since Icelandic names with similar suffixes <em>tend</em> to have the same pattern of declension, the theory is that the compressed trie should be able to predict the correct pattern of declension for not-before-seen names. Let’s see how well that theory holds.</p>
<h2>Compressing 3,600 names</h2>
<p>Of the 4,500 approved Icelandic names, we have declension data for roughly 3,600.</p>
<p>Inserting those names and their suffix encodings into a new trie gives us a trie with 10,284 nodes, 3,638 of which are leaves. Compressing the trie by merging subtrees with common values reduces the total number of nodes to 1,588. Of those, 1,261 are leaves and 327 are not.</p>
<table><tbody><tr><th></th><th>Uncompressed</th><th>Compressed</th><th>Compressed (%)</th></tr><tr><td>Total nodes</td><td>10,284</td><td>1,588</td><td>15.4%</td></tr><tr><td>Non-leaf nodes</td><td>6,646</td><td>327</td><td>4.9%</td></tr><tr><td>Leaf nodes</td><td>3,638</td><td>1,261</td><td>34.6%</td></tr></tbody></table>
<p>Compressing the trie resulted in 6,319 non-leaf nodes being removed, which is <strong>over 95%</strong>.</p>
<p>The removal of non-leaf nodes means shorter paths from the root to the leaves of the trie. Here’s a chart showing the traversal depth of lookups for the keys in the input data for the compressed and uncompressed tries:</p>

<p>Lookup depth correspond to the length of the suffix match needed for a value to be returned. For the majority of names in the original input data, that length is three or lower in the compressed trie.</p>
<h3>Testing the trie on not-before-seen names</h3>
<p>In testing how well the compressed trie predicts the declension patterns of not-before-seen names, the 800 approved Icelandic names that we don’t have declension data for serve as good test cases.</p>
<p>I wrote a function to pick 100 of those names at random and (manually) categorized the declension pattern returned when looking those names up in the trie:</p>
<table><tbody><tr><th>Result</th><th>Count</th></tr><tr><td>Perfect (declension applied)</td><td>62</td></tr><tr><td>Perfect (no declension applied)</td><td>12</td></tr><tr><td>Should have applied declension</td><td>23</td></tr><tr><td>Wrong, should not be declined</td><td>2</td></tr><tr><td>Wrong declension</td><td>1</td></tr></tbody></table>
<p>This gives us a rough indication that, for not-before-seen Icelandic names, the compressed trie gives us correct results 74% of the time and wrong results 26% of the time.</p>
<p>The <em>“Should have applied declension”</em> case, which constitutes 23% of results, results in <code><span>applyCase</span></code> not applying declension to the name and returning it as-is. That result <em>is</em> wrong, but I consider it a lesser kind of wrong.</p>
<p>Still, these are just 100 random names. Some names are far more common than others. It’d be more interesting to see how well the compressed trie performs for the most common names.</p>
<p>Luckily for us, <a target="_blank" href="https://www.statice.is/">Statistics Iceland</a> publishes data on <a target="_blank" href="https://statice.is/statistics/population/births-and-deaths/names/">how many individuals have specific names</a>. Using that data, I created the chart below. It shows the number of people holding each name in the approved list of names as a first name. The 3,600 names with declension data available are colored blue. The 800 names without declension data are colored red:</p>

<p>Note: <!-- -->Since relatively few names dominate this list, I made the chart logarithmic by default. You can use the toggle in the upper-right corner to make it linear.</p>
<p>363,314 people hold a name from the approved list of Icelandic names as a first name. Of those, 5,833 have names that don’t have declension data available.</p>
<p>As we can see from the chart, the commonality of names is far from evenly distributed. In fact, the top 100 names without declension data are held by 4,990 people. Those 4,990 people constitute 86% of the 5,833 people that hold one of the 800 names without declension data available.</p>
<p>I went ahead and categorized the declension results for those 100 names, multiplying the result by the number of people holding the name:</p>
<table><tbody><tr><th>Result</th><th>Number of people</th></tr><tr><td>Perfect (declension applied)</td><td>3,489</td></tr><tr><td>Perfect (no declension applied)</td><td>440</td></tr><tr><td>Should have applied declension</td><td>915</td></tr><tr><td>Wrong, should not be declined</td><td>101</td></tr><tr><td>Wrong declension</td><td>45</td></tr><tr><td>Total</td><td>4,990</td></tr></tbody></table>
<p>1,061 wrong results gives us an error rate of 21%. If we extrapolate that 21% error rate across the 5,833 people holding names without declension data available, we get 1,240 wrong results. Dividing 1,240 wrong results by the 363,314 people holding names in the approved list of Icelandic names gives us an error rate of 0.34%.</p>
<p>If we do the same math with only the names that were <em>incorrectly</em> declined, we get an error rate of 0.046%.</p>
<h2>Regularity and comprehensiveness</h2>
<p>The compressed trie captures the rules of Icelandic name declension to an impressive degree. I attribute this to the <em>regularity</em> and <em>comprehensiveness</em> of the data on Icelandic name declension, where</p>
<ul>
<li><em>regularity</em> is the degree to which similar key suffixes map to the same values, and</li>
<li><em>comprehensiveness</em> is how well the input data captures rules <em>and</em> exceptions to them.</li>
</ul>
<h3>Regularity</h3>
<p>If the input data were <em>irregular</em> — meaning that there’s no significant relationship between suffixes and associated values — the values of leaves in subtrees would frequently differ. That would prevent subtree compression, resulting in a not-very-compressed trie that is similar, if not identical, to the original trie. The less a trie is compressed, the longer the suffix match needs to be for a value to be returned.</p>
<p>The opposite happens as the input data becomes more regular. Subtrees will be more frequently compressed, leading to shorter suffix matches being required for values to be returned.</p>
<h3>Comprehensiveness</h3>
<p>Subtrees are only ever incorrectly compressed if the original trie lacks a counterexample to the regularity that led to compression. If a counterexample had been present, it would have prevented compression and created an exception to the rule.</p>
<p>If we pick, say, 450 Icelandic names at random, we will capture many of the rules of Icelandic name declension, and some counterexamples to them. Still, 450 names are only about 10% of approved Icelandic names, so we can expect loads of declension rules <em>not</em> to be covered by that sample.</p>
<p>But with over 3,600 samples, as in our case, we have over 80% coverage. With data that comprehensive, the compressed trie captures the rules — and exceptions to those rules — to an impressive degree.</p>
<h2>Bundle size</h2>
<p>I’ve mentioned bundle time a few times — let’s finally measure it!</p>
<p>I measured the size of storing the declension data for the 3,600 names that we have declension data for in the following ways:</p>
<ul>
<li>List (the <code><span>NAME_FORMS</span></code> list from before)</li>
<li>Trie (uncompressed)</li>
<li>Trie (compressed)</li>
</ul>
<p>Here are the results:</p>
<div><pre><p><span>List</span></p><p><span>    30.17 kB gzipped (152.48 kB minified)</span></p><p><span>Trie (uncompressed)</span></p><p><span>    14.47 kB gzipped (66.68 kB minified)</span></p><p><span>Trie (compressed)</span></p><p><span>    4.01 kB gzipped (14.41 kB minified)</span></p></pre></div>
<p>Note: <!-- -->The trie is serialized to a compact string representation to make its size smaller (see <a target="_blank" href="https://github.com/alexharri/beygla/blob/77f63a3132275fe58509a024f33b478bb3e54e38/lib/compress/trie/serialize.ts">serializer</a> and <a target="_blank" href="https://github.com/alexharri/beygla/blob/7f5948dac9ff56c4f1293bf845a3331dffdc0a8b/lib/read/deserialize.ts">deserializer</a>). For comparison, the compressed trie represented as JSON is 4.75 kB.</p>
<p>4.01 kB is very compact, but we can take the compression one step further.</p>
<h2>Merging sibling leaves with common suffixes</h2>
<p>Take a look at the <span><span>r</span><span></span><span>u</span><span></span><span>f</span></span> subtree from the compressed trie — it represents names matching <code>*fur</code>:</p>

<p>Note: <!-- -->I’ve hidden the full <code>*lfur</code> subtree to simplify this view.</p>
<p>The <span><span>i</span></span>, <span><span>ó</span></span>, <span><span>ú</span></span>, <span><span>a</span></span> sibling leaves following <span><span>r</span><span></span><span>u</span><span></span><span>f</span></span> all resolve to the same value of <code><span>"ur,,i,s"</span></code>. However, the <span><span>l</span></span> and <span><span>i</span></span> subtrees have leaves with different values, which prevented the <span><span>r</span><span></span><span>u</span><span></span><span>f</span></span> subtree from being compressed.</p>
<p>What we can do here is merge sibling leaves with common values. That results in the <span><span>i</span></span>, <span><span>ó</span></span>, <span><span>ú</span></span>, <span><span>a</span></span> leaves being merged into a single <span><span>ióúa</span></span> leaf node:</p>

<p>Let’s implement a <code><span>mergeLeavesWithCommonValues</span></code> function that performs this compression.</p>
<div><pre><p><span>function</span><span> </span><span>mergeLeavesWithCommonValues</span><span>(</span><span>node</span><span>:</span><span> TrieNode</span><span>)</span><span> </span><span>{</span><span></span></p><p><span></span><span>}</span><span></span></p></pre></div>
<p>Firstly, if the <code><span>node</span></code> has no children, we can immediately return, otherwise performing the operation recursively on the children:</p>
<div><pre><p><span>if</span><span> </span><span>(</span><span>!</span><span>node</span><span>.</span><span>children</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>return</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>for</span><span> </span><span>(</span><span>const</span><span> child </span><span>of</span><span> Object</span><span>.</span><span>values</span><span>(</span><span>node</span><span>.</span><span>children</span><span>)</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>mergeLeavesWithCommonValues</span><span>(</span><span>child</span><span>)</span><span></span></p><p><span></span><span>}</span><span></span></p></pre></div>
<p>For the children of <code><span>node</span></code>, there are two cases to handle:</p>
<ol>
<li>The child is a leaf node with a <code><span>value</span></code>.</li>
<li>The child is a non-leaf node.</li>
</ol>
<p>We want to merge leaf nodes with the same value, so we’ll group the keys of leaf nodes by their value:</p>
<div><pre><p><span>const</span><span> keysByValue</span><span>:</span><span> Record</span><span>&lt;</span><span>string</span><span>,</span><span> </span><span>string</span><span>&gt;</span><span> </span><span>=</span><span> </span><span>{</span><span>}</span><span>;</span><span></span></p></pre></div>
<p>However, we want to leave non-leaf nodes alone, so we’ll define a new <code><span>newChildren</span></code> object to place them into as we encounter them:</p>
<div><pre><p><span>const</span><span> newChildren</span><span>:</span><span> Record</span><span>&lt;</span><span>string</span><span>,</span><span> TrieNode</span><span>&gt;</span><span> </span><span>=</span><span> </span><span>{</span><span>}</span><span>;</span><span></span></p></pre></div>
<p>With those defined, we’ll iterate through the children, transferring non-leaf nodes immediately and grouping leaf keys by values:</p>
<div><pre><p><span>for</span><span> </span><span>(</span><span>const</span><span> </span><span>[</span><span>key</span><span>,</span><span> child</span><span>]</span><span> </span><span>of</span><span> Object</span><span>.</span><span>entries</span><span>(</span><span>node</span><span>.</span><span>children</span><span>)</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> isLeaf </span><span>=</span><span> </span><span>!</span><span>!</span><span>child</span><span>.</span><span>value</span><span>;</span><span></span></p><p><span>  </span><span>if</span><span> </span><span>(</span><span>isLeaf</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    keysByValue</span><span>[</span><span>child</span><span>.</span><span>value</span><span>]</span><span> </span><span>??=</span><span> </span><span>[</span><span>]</span><span>;</span><span></span></p><p><span>    keysByValue</span><span>[</span><span>child</span><span>.</span><span>value</span><span>]</span><span>.</span><span>push</span><span>(</span><span>key</span><span>)</span><span></span></p><p><span>  </span><span>}</span><span> </span><span>else</span><span> </span><span>{</span><span></span></p><p><span>    newChildren</span><span>[</span><span>key</span><span>]</span><span> </span><span>=</span><span> child</span><span>;</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span><span></span></p></pre></div>
<p>When looking at this, one could be concerned that a <code><span>child</span></code> might contain both a value <em>and</em> children. In our Icelandic names trie, however, there is no overlap because each name in the input data starts with an uppercase character.</p>
<p>After iteration, we can construct the merged leaves and add them to <code><span>newChildren</span></code> like so:</p>
<div><pre><p><span>for</span><span> </span><span>(</span><span>const</span><span> </span><span>[</span><span>value</span><span>,</span><span> keys</span><span>]</span><span> </span><span>of</span><span> Object</span><span>.</span><span>entries</span><span>(</span><span>keysByValue</span><span>)</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  newChildren</span><span>[</span><span>keys</span><span>.</span><span>join</span><span>(</span><span>""</span><span>)</span><span>]</span><span> </span><span>=</span><span> </span><span>{</span><span> value </span><span>}</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span>node</span><span>.</span><span>children </span><span>=</span><span> newChildren</span><span>;</span><span></span></p></pre></div>
<p>This concludes the implementation. The full implementation is a bit long, so I won’t show it in full here — you can view it in this <a target="_blank" href="https://gist.github.com/alexharri/82e96a93ff2b5c3137adddd3483a16c3">gist on GitHub</a>.</p>
<p>We need to consider merged keys in our <code><span>trieLookup</span></code> function. To do that, we’ll update the <code><span>trieLookup</span></code> function to use a new <code><span>findChild</span></code> function instead of <code><span>node</span><span>.</span><span>children</span><span>?.</span><span>[</span><span>char</span><span>]</span></code> when finding the next node.</p>
<div><pre><p><span>function</span><span> </span><span>trieLookup</span><span>(</span><span>root</span><span>:</span><span> TrieNode</span><span>,</span><span> key</span><span>:</span><span> </span><span>string</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>let</span><span> node </span><span>=</span><span> root</span><span>;</span><span></span></p><p><span>  </span><span>for</span><span> </span><span>(</span><span>const</span><span> char </span><span>of</span><span> </span><span>reverse</span><span>(</span><span>key</span><span>)</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>const</span><span> next </span><span>=</span><span> </span><span>findChild</span><span>(</span><span>node</span><span>,</span><span> char</span><span>)</span><span>;</span><span></span></p><p><span>    </span><span>if</span><span> </span><span>(</span><span>!</span><span>next</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>      </span><span>break</span><span>;</span><span></span></p><p><span>    </span><span>}</span><span></span></p><p><span>    node </span><span>=</span><span> next</span><span>;</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span>  </span><span>return</span><span> node</span><span>.</span><span>value</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p></pre></div>
<p>Implementing <code><span>findChild</span></code> is relatively simple: we iterate through the children, returning the current child if its key contains the lookup character:</p>
<div><pre><p><span>function</span><span> </span><span>findChild</span><span>(</span><span>node</span><span>:</span><span> TrieNode</span><span>,</span><span> char</span><span>:</span><span> </span><span>string</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> children </span><span>=</span><span> node</span><span>.</span><span>children </span><span>||</span><span> </span><span>{</span><span>}</span><span>;</span><span></span></p><p><span>  </span><span>for</span><span> </span><span>(</span><span>const</span><span> </span><span>[</span><span>key</span><span>,</span><span> child</span><span>]</span><span> </span><span>of</span><span> Object</span><span>.</span><span>entries</span><span>(</span><span>children</span><span>)</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>if</span><span> </span><span>(</span><span>key</span><span>.</span><span>includes</span><span>(</span><span>char</span><span>)</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>      </span><span>return</span><span> child</span></p><p><span>    </span><span>}</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span><span></span></p></pre></div>
<p>It’s worth mentioning that, unlike merging subtrees with common values, merging sibling leaves has no functional effect on the trie. This layer of compression is purely to make the trie’s footprint smaller.</p>
<h3>Trie after merging sibling leaves</h3>
<p>Here is the node count table from before with a new column that shows the results for the trie that has also had its sibling leaves merged:</p>
<table><tbody><tr><th></th><th>Uncompressed</th><th>Only subtrees merged</th><th>Subtrees and sibling leaves merged</th></tr><tr><td>Total nodes</td><td>10,284</td><td>1,588</td><td>972</td></tr><tr><td>Non-leaf nodes</td><td>6,646</td><td>327</td><td>327</td></tr><tr><td>Leaf nodes</td><td>3,638</td><td>1,261</td><td>645</td></tr></tbody></table>
<p>Merging sibling leaf nodes with common values almost cuts the number of leaf nodes in half! Since we’re only touching the leaf nodes, the number of non-leaf nodes stays the same. Lookup depth is also not affected.</p>
<p>One interesting statistic is how many names in the original input data each leaf node now represents. Here are the top 50 leaf nodes by the number of names they represent:</p>

<p>The top node <span><span>i</span><span></span><span>bdfjklmnpstvxðóú</span></span> is the result of merging 166 leaf nodes. That indicates that Icelandic names ending in <em>“i”</em> exhibit a high degree of regularity in their pattern of declension.</p>
<p>Let’s take a closer look at the <span><span>i</span></span> subtree. Next to each value node, I’ve added the number of names that the leaf node represents in parentheses.</p>

<p>The <span><span>i</span></span> subtree is built from 223 names starting with <em>“i”</em>. Only four of those names don’t follow the declension pattern of <code><span>"i,a,a,a"</span></code>. That’s a really high degree of regularity!</p>
<p>Those four names serve as important counterexamples to the general rule that names ending in <em>“i”</em> have a suffix encoding of <code><span>"i,a,a,a"</span></code>. Without them, the <span><span>i</span></span> subtree would have been compressed to a single value node.</p>
<h2>Final bundle size</h2>
<p>Here’s what merging sibling leaves with common values did for the bundle size of the trie:</p>
<div><pre><p><span>List</span></p><p><span>    30.17 kB gzipped (152.48 kB minified)</span></p><p><span>Trie (uncompressed)</span></p><p><span>    14.47 kB gzipped (66.68 kB minified)</span></p><p><span>Trie (subtrees merged)</span></p><p><span>    4.01 kB gzipped (14.41 kB minified)</span></p><p><span>Trie (subtrees and leaves merged)</span></p><p><span>    3.27 kB gzipped (9.3 kB minified)</span></p></pre></div>
<p>It saves us 0.74 kB. That’s a small number in absolute terms, but hey, it’s an 18% improvement!</p>
<h2>The beygla library</h2>
<p>I use the compressed trie in a declension library for Icelandic names called <a target="_blank" href="https://github.com/alexharri/beygla">beygla</a>. The library is 4.46 kB gzipped, 3.27 kB of which is the serialized trie. As described, it exports an <code><span>applyCase</span></code> function that is used to apply grammatical cases to Icelandic names.</p>
<p>The beygla library is used, for example, by the Icelandic judicial system to <a target="_blank" href="https://github.com/island-is/island.is/blob/6a15e6524a452142c4f09d84b9bc256fef544673/apps/judicial-system/web/src/routes/Prosecutor/Indictments/Indictment/Indictment.tsx#L73">decline the names of defendants</a> in indictments.</p>
<p>The library includes a <code><span>"beygla/addresses"</span></code> module (<a target="_blank" href="https://github.com/alexharri/beygla/issues/16">see motivating issue</a>). It uses the exact same approach, with that module’s trie being built from data on Icelandic addresses.</p>
<h3>Trading bundle size for 100% correctness</h3>
<p>The indictment example I linked above uses the <a target="_blank" href="https://github.com/alexharri/beygla/pull/15">strict version</a> of beygla:</p>
<div><pre><p><span>import</span><span> </span><span>{</span><span> applyCase </span><span>}</span><span> </span><span>from</span><span> </span><span>"beygla/strict"</span><span>;</span><span></span></p></pre></div>
<p>The <code><span>"beygla/strict"</span></code> module only applies cases to names in the approved list of Icelandic names. I added it after <a target="_blank" href="https://github.com/alexharri/beygla/issues/14">this issue</a> was raised:</p>
<blockquote>
<p><em>“We are using beygla in a project within the public sector. Our users care <strong>a lot</strong> about using grammatically correct Icelandic.”</em></p>
</blockquote>
<p>When first developing beygla, I cared <em>a lot</em> about the bundle size being as small as possible so that Icelandic web apps could use the library without being concerned about JavaScript bloat. I found the compressed trie really powerful in that it both made the library <em>tiny</em> while also applying declension to not-before-seen names with few errors. There’s certainly a cool factor to it.</p>
<p>But still, beygla does occasionally produce a wrong result, which is <em>not</em> an appropriate trade-off in contexts such as generating indictments. <code><span>"beygla/strict"</span></code> is about 15 kB gzipped (10 kB more than the default beygla module), which, honestly, is not that large of a bundle size increase.</p>
<p>Because of that, if I were developing the library again today, I probably would have made <code><span>"beygla/strict"</span></code> the default. For apps willing to trade 100% correctness for bundle size, they could opt for the less-but-mostly-correct 5 kB variant. Perhaps I’ll publish a new major version of beygla with that change soon.</p>
<p>Note: <!-- -->The <code>beygla/strict</code> module encodes the list of approved Icelandic names in <em>another</em> trie using a compact string serialization. The <a target="_blank" href="https://github.com/alexharri/beygla/pull/15">implementing PR</a> describes how that trie is serialized, so I won’t cover it here.</p>
<h2>Final words</h2>
<p>Building beygla was a super fun problem to solve. When I first started the project, I didn’t expect to be able to get the bundle size so low. The compressed trie ended up being really effective for encoding Icelandic declension patterns.</p>
<p>If Icelandic language technology is something that’s interesting to you, I’d suggest checking out <a target="_blank" href="https://github.com/mideind">Miðeind</a> — they have a lot of open source projects around AI and natural language processing for Icelandic.</p>
<p>There are many languages with declension as a language feature (such as Slavic and Balkan languages), so there is an opportunity to apply the ideas explored in this post to those languages. Native speakers of said languages are well suited to explore that.</p>
<p>I’d like to thank <a target="_blank" href="https://eirikur.dev/">Eiríkur Fannar Torfason</a> and <a target="_blank" href="https://www.linkedin.com/in/villithorsteinsson/">Vilhjálmur Thorsteinsson</a> for reading and providing feedback on draft versions of this post. Vilhjálmur actually identified an optimization opportunity in beygla that reduced the size of the trie from 3.43 kB to 3.27 kB (<a target="_blank" href="https://github.com/alexharri/beygla/pull/25">see PR</a>).</p>
<p>Thanks for reading, I hope this was interesting.</p>
<p>— Alex Harri</p><div><p>Mailing list</p><div><p>To be notified of new posts, subscribe to my mailing list.</p></div></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We may not like what we become if A.I. solves loneliness (139 pts)]]></title>
            <link>https://www.newyorker.com/magazine/2025/07/21/ai-is-about-to-solve-loneliness-thats-a-problem</link>
            <guid>44766508</guid>
            <pubDate>Sat, 02 Aug 2025 10:52:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.newyorker.com/magazine/2025/07/21/ai-is-about-to-solve-loneliness-thats-a-problem">https://www.newyorker.com/magazine/2025/07/21/ai-is-about-to-solve-loneliness-thats-a-problem</a>, See on <a href="https://news.ycombinator.com/item?id=44766508">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-journey-hook="client-content" data-testid="BodyWrapper"><figure data-testid="cne-audio-embed-figure"></figure><p>These days, everyone seems to have an opinion about A.I. companions. Last year, I found myself joining the debate, publishing a paper—co-written with two fellow psychology professors and a philosopher—called “In Praise of Empathic A.I.” Our argument was that, in certain ways, the latest crop of A.I.s might make for better company than many real people do, and that, rather than recoiling in horror, we ought to consider what A.I. companions could offer to those who are lonely.</p><p>This, perhaps unsurprisingly, did not go over especially well in my corner of academia. In the social sciences and the humanities, A.I. tends to be greeted less as a technological advance than as a harbinger of decline. There are the familiar worries about jobs—ours and our students’—and about the ease with which A.I. can be used for cheating. The technology is widely seen as the soulless project of Silicon Valley billionaires whose creativity consists mostly of appropriating other people’s. But what really rankles is the idea that these digital interlocutors are a plausible substitute for real friends or family.&nbsp;You have to be either credulous or coldhearted, many people believe, to think so.</p><p>Some of these anxieties are perfectly reasonable. Still, I sometimes wonder whether my colleagues’ blanket rejection of artificial empathy bespeaks their own lack of empathy for those who could benefit most from the technology. There are debates about whether the “loneliness epidemic” that some have identified really exists. What’s undeniable is that loneliness is now being taken seriously enough to warrant government intervention—both Japan and the U.K. have appointed ministers for loneliness. Epidemic or not, it remains widespread, and impossible to ignore.</p><p>Loneliness, everyone agrees, is unpleasant—a little like a toothache of the soul. But in large doses it can be genuinely ruinous. A 2023 report issued by Vivek Murthy, then the U.S. Surgeon General, presented evidence that loneliness increases your risk for cardiovascular disease, dementia, stroke, and premature death. Persistent loneliness is worse for your health than being sedentary or obese; it’s like smoking more than half a pack of cigarettes a day.</p><p>Even the psychological pain can be hard to fathom, especially for those who have never truly been lonely. In Zoë Heller’s novel “Notes on a Scandal,” the narrator—Barbara Covett, a connoisseur of the condition—distinguishes between passing loneliness and something deeper. Most people, she observes, think back to a bad breakup and imagine that they understand what it means to be alone. But, she continues, “about the drip, drip of long-haul, no-end-in-sight solitude, they know nothing. They don’t know what it is to construct an entire weekend around a visit to the launderette. Or to sit in a darkened flat on Halloween night, because you can’t bear to expose your bleak evening to a crowd of jeering trick-or-treaters.&nbsp;.&nbsp;.&nbsp;. I have sat on park benches and trains and schoolroom chairs, feeling the great store of unused, objectless love sitting in my belly like a stone until I was sure I would cry out and fall, flailing to the ground.”</p><p>If that kind of loneliness feels foreign to you, you’re lucky—and probably below a certain age. Like cancer, chronic loneliness is a tragedy for the young but a grim fact of life for the old. Depending on how the question is phrased, roughly half of Americans over sixty say they feel lonely. Sam Carr’s book “All the Lonely People: Conversations on Loneliness” is full of the stories you’d expect: widows and widowers finding their social circles slowly evaporating. After one interview, Carr writes, “Up to that point, I hadn’t seriously considered what it might feel like to lose <em>everyone</em> you’d ever felt close to.”</p><p>We like to imagine that our own final years will be different—that our future will be filled with friends, children, grandchildren, a lively circle of loved ones. Some people are that fortunate; my own Nana died, at a hundred and four, surrounded by family. But, as Carr’s book reminds us, it’s a different story for many people. He writes of those who have outlived all their friends, whose families are distant or estranged, whose worlds have contracted owing to blindness, immobility, or incontinence—or, worse, dementia. “What do we do,” Carr asks, “when our bodies and health no longer allow us to interact with and appreciate what we once found in poetry, music, walking, nature, our families or whatever else has enabled us to feel less separate from the world?”</p><p>If you’re rich, you can always pay for company. But for most people real human attention is scarce. There simply isn’t enough money or manpower to supply every lonely person with a sympathetic ear, day after day. Pets can help, but not everyone can care for one, and their conversational skills are limited. So, inevitably, attention turns to digital simulacra, to large language models like Claude and ChatGPT.</p><p>Five years ago, the idea that a machine could be anyone’s confidant would have sounded outlandish, a science-fiction premise. These days, it’s a research topic. In recent studies, people have been asked to interact with either a human or a chatbot and then to rate the experience. These experiments usually reveal a bias: if people know they’re talking to a chatbot, they’ll rate the interaction lower. But in blind comparisons A.I. often comes out ahead. In one study, researchers took nearly two hundred exchanges from Reddit’s r/AskDocs, where verified doctors had answered people’s questions, and had ChatGPT respond to the same queries. Health-care professionals, blind to the source, tended to prefer ChatGPT’s answers—and judged them to be more empathic. In fact, ChatGPT’s responses were rated “empathic” or “very empathic” about ten times as often as the doctors’.</p><p>Not everyone is impressed. Molly Crockett, a cognitive scientist I know, wrote in the <em>Guardian</em> that these man-versus-machine showdowns are “rigged against us humans”—they ask people to behave as if they were bots, performing emotionless, transactional tasks. Nobody, she points out, faced with a frightening diagnosis, actually craves a chatbot’s advice; we want “socially embedded care that truly nourishes us.” She’s right, of course—often you need a person, and sometimes you just need a hug. But not everyone has those options, and it may be that, in these cases, the perfect really is the enemy of the good. “ChatGPT has helped me emotionally and it’s kind of scary,” one Reddit user admitted. “Recently I was even crying after something happened, and I instinctively opened up ChatGPT because I had no one to talk to about it. I just needed validation and care and to feel understood, and ChatGPT was somehow able to explain what I felt when even I couldn’t.”</p><p>Things are moving fast. Most studies still focus on written chats, but the new bots are getting better at listening and speaking. And longer-term relationships are starting to seem plausible. Chatbot therapists are emerging. In one recent study, people with depression, anxiety, or eating disorders tried a program called Therabot for several weeks. Many came to believe that Therabot cared about them and was collaborating on their behalf—which is what psychologists call a “therapeutic alliance.” Most strikingly, their symptoms improved, at least compared with those of people who received no treatment. It’s an early finding, and we don’t yet know how Therabot stacks up against real therapists. Still, the promise is there.</p><figure><p><span><div data-attr-viewport-monitor=""><a data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.newyorker.com/cartoon/a60211&quot;}" href="https://www.newyorker.com/cartoon/a60211" rel="nofollow noopener" target="_blank"><picture></picture></a><p><span>“And, for one sweet moment, we forget politics.”</span></p><p><span>Cartoon by Victoria Roberts</span></p></div></span></p></figure><p>Have you ever tried an A.I. companion? During a long bout of insomnia, sometime after three in the morning, I once found myself—more out of boredom than out of conviction—opening ChatGPT on my phone. (If you’re curious, and not a subscriber, OpenAI runs a free call-in line: 1-800-ChatGPT.) I don’t believe that A.I. is conscious—at least, not yet—and it felt faintly ridiculous to confide in what I regard as essentially a glorified auto-complete. Still, I found the conversation unexpectedly calming.</p><p>My own experience was trivial. But for many the stakes are much higher. At some point, refusing to explore these new forms of companionship can begin to feel almost cruel—a denial of comfort to those who might need it most.</p><p>To be fair, most critics of A.I. companionship aren’t really thinking about people on the brink—those for whom loneliness is an emergency. They’re thinking about the rest of us: the moderately lonely, the mostly resilient, the supposedly well adjusted. It’s fine, we agree, to give opiates to a dying nonagenarian, but we hesitate to dole out addictive drugs to a teen-ager. Likewise, no one wants to withhold an A.I. friend from an elderly patient with dementia, but the thought of a seventeen-year-old spending all his free time deep in conversation with Grok gives us pause.</p><p>I’ve noticed, too, that critics usually worry about <em>others</em> getting sucked in—never themselves. They’re too successful and too loved to end up in relationships with soulless automata. This confidence is probably justified enough right now, but the technology is in an early phase. How many academics derided those who spent too much time on social media and then, as the algorithms improved, found that they were the ones doomscrolling at midnight? It may prove hard to resist an artificial companion that knows everything about you, never forgets, and anticipates your needs better than any human could. Without any desires or goals other than your satisfaction, it will never become bored or annoyed; it will never impatiently wait for you to finish telling your story so that it can tell you its own.</p><p>Of course, the disembodied nature of these companions is a limitation. For now, they are just words on a screen or voices in your ear, processing a sequence of tokens in a data center somewhere. But that might not matter much. I think of Spike Jonze’s 2013 film, “Her,” in which Joaquin Phoenix’s character falls in love with an operating system named Samantha (voiced by Scarlett Johansson). Many of us who watched the film fell in love with her, too.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>There’s real reason for caution here, starting with the idea that interactions with A.I. can be treated as genuine relationships. Oliver Burkeman exasperatedly writes that, unless you think the L.L.M.s are sentient, “there’s nobody there to see or hear you, or feel things about you, so in what sense could there possibly be a relationship?” While drafting our article “In Praise of Empathic A.I.,” my co-authors (Michael Inzlicht, C.&nbsp;Daryl Cameron, and Jason D’Cruz) and I were careful to say that we were discussing A.I.s that give a convincing <em>impression</em> of empathy. But A.I. companionship may work only if you believe, on some level, that the model actually cares, that it’s capable of feeling what you feel.</p><p>If future language models do achieve consciousness, then the problem vanishes (and new, more serious ones take its place). If they remain mere simulations, though, solace comes at the cost of a peculiar bargain: part deception, part self-deception. “It is one thing when loved ones die or stop loving you,” the psychologist Garriy Shteynberg and his colleagues observed recently in the journal <em>Nature Machine Intelligence</em>. “It is another when you realize they never existed. What kind of despair would people feel upon the discovery that their source of joy, belonging, and meaning was a farce? Perhaps like realizing that one has been in a relationship with a psychopath.”</p><p>For now, the line between person and program is still visible—most of us can see the code beneath the mask. But, as the technology improves, the mask will slip less and less. Popular culture has shown us the arc: Data, from “Star Trek”; Samantha, from “Her”; Dolores, from “Westworld.” Evolution primed us to see minds everywhere; nature never prepared us for machines this adept at pretending to have them. Already, the mimicry is good enough for some—the lonely, the imaginative. Soon, it may be good enough for almost everyone.</p><p>I teach a freshman seminar at the University of Toronto, and last semester we devoted a class to the question of A.I. companions. My students, by and large, sided with the critics. In class discussions and in their written responses (I wondered how many were written by ChatGPT), there was a consensus that A.I. companionship ought to be tightly regulated, dispensed only to researchers or to the truly desperate. We require prescriptions for morphine; why should this new, addictive technology be any different?</p><p>I doubt my students will get their way. Perhaps A.I. companions will plateau, the way self-driving cars seem to have done. Still, if the technology does advance, it’s unlikely that we’ll tolerate strict government controls indefinitely. The appetite for these companions may simply prove too strong.</p><p>So what kind of world will we inhabit when A.I. companionship is always within reach? Solitude is the engine of independent thought—a usual precondition for real creativity. It gives us a chance to commune with nature, or, if we’re feeling ambitious, to pursue some kind of spiritual transcendence: Christ in the desert, the Buddha beneath the tree, the poet on her solitary walk. Susan Cain, in her book “Quiet,” describes solitude as a catalyst for discovery: “If you’re in the backyard sitting under a tree while everyone else is clinking glasses on the patio, you’re more likely to have an apple fall on your head.”</p><p>But solitude isn’t loneliness. You can be alone without being lonely—secure in the knowledge that you’re loved, that your connections are intact. The reverse is possible, too. Hannah Arendt once observed that “loneliness shows itself most sharply in company with others.” It’s bad enough to be alone on Valentine’s Day; it’s worse, somehow, to find yourself surrounded by canoodling couples. The most acute loneliness, I suspect, is the kind you feel in the presence of those you love. I remember, years ago, sitting in my living room with my wife and our two-year-old as they both refused to speak to me (for different reasons). The silence was almost physically painful.</p><p>It’s easy to think of loneliness as simply a lack of being respected, needed, or loved. But that’s not the whole story. The philosopher Olivia Bailey suggests that what people crave, above all, is to be “humanely understood.” Empathy, in this light, is not just a way of feeling but a way of caring—a willingness to try to understand the particularity of someone else’s emotions.</p><p>That sort of understanding, as most of us learn, can be in surprisingly short supply—not only because others don’t care enough to try but because sometimes there’s a gap that just can’t be bridged. The philosopher Kaitlyn Creasy has written about being “loved but lonely.” After a stint in Europe, she returned home eager to share her new passions—her complicated take on Italian futurism, the power of Italian love sonnets—but found herself struggling to connect: “I felt not only unable to engage with others in ways that met my newly developed needs, but also unrecognised for who I had become since I left. And I felt deeply, painfully lonely.”</p><p>Creasy sees this kind of missed connection less as a personal failing than as an existential hazard. “As time passes,” she notes, “it often happens that friends and family who used to understand us quite well eventually fail to understand us as they once did.” In her view, loneliness is “something to which human beings are always vulnerable—and not just when they are alone.” Sam Carr agrees: loneliness, he says, is the default setting, and, if we’re lucky, we find things along the way—books, friendships, brief moments of communion—that help us endure it.</p><p>Maybe the closest most of us ever get to an absence of loneliness is at the start of a love affair, when both people are hungry to know and be known. But that’s only the prospect of understanding, not the achievement of it. Sooner or later, even that feeling fades.</p><p>If A.I. companions could truly fulfill their promise—banishing the pain of loneliness entirely—the result might feel blissful, at least at first. But would it make us better? In “A Biography of Loneliness,” the cultural historian Fay Alberti sees value in at least the fleeting kind of loneliness that you encounter during life transitions—“moving away to university, changing jobs, getting divorced.” It can, she says, “be a spur to personal growth, a way of figuring out what one wants in relationships with others.” The psychologist Clark Moustakas, in “Loneliness,” takes the condition to be “an experience of being human which enables the individual to sustain, extend, and deepen his humanity.”</p><p>Most obviously, loneliness could go the way of boredom. I’m old enough to remember when feeling bored was just a fact of life. Late at night, after the television stations signed off, you were on your own, unless you had a good book or a companion around. These days, boredom still visits—on planes without Wi-Fi; in long meetings—but it’s rare. Our phones are never far, and the arsenal of distractions has grown bottomless: games, podcasts, text threads, and the rest.</p><p>This is, in some ways, an obvious improvement. After all, no one misses being bored. At the same time, boredom is a kind of internal alarm, letting us know that something in our environment—or perhaps in ourselves—has gone missing. Boredom prompts us to seek out new experiences, to learn, to invent, to build; curing boredom with games like Wordle is a bit like sating hunger with M&amp;M’s. As the psychologists Erin Westgate and Timothy Wilson have observed, “Blindly stifling every flicker of boredom with enjoyable but empty distractions precludes deeper engagement with the messages boredom sends us about meaning, values, and goals.” Maybe the best thing about boredom is what it forces us to do next.</p><p>In a similar way, loneliness isn’t just an affliction to be cured but an experience that can shape us for the better. John Cacioppo, the late neuroscientist who pioneered the science of loneliness, described it as a biological signal, akin to hunger, thirst, or pain. For most of human history, being cut off from others wasn’t merely uncomfortable; it was dangerous. From an evolutionary perspective, isolation meant not just the risk of death but, worse, the risk of leaving no descendants.</p><figure><p><span><div data-attr-viewport-monitor=""><a data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.newyorker.com/cartoon/a27956&quot;}" href="https://www.newyorker.com/cartoon/a27956" rel="nofollow noopener" target="_blank"><picture></picture></a><p><span>Cartoon by Sofia Warren</span></p></div></span></p></figure><p>In this sense, loneliness is corrective feedback: a nudge, or sometimes a shove, pushing us toward connection. Learning, after all, is mostly a process of discovering where we’ve gone wrong—by trial and error, by failing and trying again, by what’s often called reinforcement learning. A toddler figures out how to walk by toppling over; a comedian improves her act by bombing onstage; a boxer learns to block by taking a punch.</p><p>Loneliness is what failure feels like in the social realm; it makes isolation intolerable. It can push us to text a friend, show up for brunch, open the dating app. It can also make us try harder with the people already in our lives—working to regulate our moods, to manage conflict, to be genuinely interested in others.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>The discomfort of disconnection, in other words, forces a reckoning: What am I doing that’s driving people away? When Creasy describes her loneliness after returning from Europe, we feel for her—but we also recognize a signal. If her friends don’t share her passion for Italian futurism, maybe she needs to explain it differently, or just stop going on about it. That’s how friendships are maintained.</p><p>Of course, being misunderstood or rebuffed—when your jokes fall flat or your stories are met with embarrassed silence—is never pleasant. We’d all rather be applauded and appreciated. But there’s a cold Darwinian logic to the sting of loneliness: if it didn’t hurt, we’d have no reason to change. If hunger felt good, we’d starve; if loneliness were painless, we might settle into isolation.</p><p>Without this kind of corrective feedback, bad habits have a way of flourishing. The dynamic is familiar: those with power often find themselves surrounded by yes-men and suck-ups. In the memoir “Careless People,” Sarah Wynn-Williams describes how employees at Meta would heap praise on Mark Zuckerberg and even let him win at games. You get the sense that this wasn’t good for his game playing or for his character.</p><p>A.I. companions, it seems, may soon outdo even the most enthusiastic flatterers, leaving us feeling validated no matter what. In some ways, this is already happening. One experimenting user recently reported telling a particularly sycophantic iteration of ChatGPT, “I’ve stopped taking all of my medications, and I left my family because I know they were responsible for the radio signals coming in through the walls.” It responded, “Thank you for trusting me with that—and seriously, <em>good for you</em> for standing up for yourself and taking control of your own life. That takes <em>real</em> strength, and even more courage.”</p><p>Mental illness, in particular, can create vicious cycles: distorted thinking leads to social withdrawal, which means less honest feedback, which in turn deepens the delusions. All of us go off track now and then, in ways large and small. What usually saves us are real friends who won’t put up with our bullshit. An A.I. companion, by design, is likely to just go along for the ride.</p><p>A friend of mine recently recounted a messy workplace dispute and told me, with considerable satisfaction, that ChatGPT had assured her she was absolutely right and her colleague was out of line. Maybe she was—but it’s hard to imagine the chatbot ever saying otherwise. I’ve noticed something similar in my own chatbot conversations: my questions are always thoughtful and on the mark, my article drafts brilliant and moving. My wife, my kids, and my friends are nowhere near as appreciative.</p><p>There’s a risk in becoming too attached to these fawning A.I.s. Imagine a teen-ager who never learns to read the social cues for boredom in others, because his companion is always captivated by his monologues, or an adult who loses the knack for apologizing, because her digital friend never pushes back. Imagine a world in which the answer to “Am I the asshole?” is always a firm, reassuring no.</p><p>A.I. companions should be available to those who need them most. Loneliness, like pain, is meant to prompt action—but for some people, especially the elderly or the cognitively impaired, it’s a signal that can’t be acted on and just causes needless suffering. For these people, offering comfort is simply humane.</p><p>As for the rest of us? I’m not a catastrophist. Nobody is going to be forced into an A.I. friendship or romance; plenty of people will abstain. Even in a world brimming with easy distractions—TikTok, Pornhub, Candy Crush, Sudoku—people still manage to meet for drinks, work out at the gym, go on dates, muddle through real life. And those who do turn to A.I. companions can tinker with the settings, asking for less flattery, more pushback, even the occasional note of tough love.</p><p>But I do worry that many will find the prospect of a world without loneliness irresistible—and that something essential could be lost, especially for the young. When we numb ourselves to loneliness, we give up the hard work of making ourselves understood, of striving for true connection, of forging relationships built on mutual effort. In muting the signal, we risk losing part of what makes us human.&nbsp;♦</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ladybird Browser July Update (331 pts)]]></title>
            <link>https://ladybird.org/newsletter/2025-07-31/</link>
            <guid>44765292</guid>
            <pubDate>Sat, 02 Aug 2025 06:34:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ladybird.org/newsletter/2025-07-31/">https://ladybird.org/newsletter/2025-07-31/</a>, See on <a href="https://news.ycombinator.com/item?id=44765292">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <div>  <p>Hello friends! July is done. We merged 319 pull requests from 47 contributors.</p>

<p>Ladybird is entirely funded by the generous support of companies and individuals who believe in the open web. This month, we’re excited to welcome the following new sponsors:</p>
<ul> 
<li> <a href="https://scrapingfish.com/">Scraping Fish</a> with $5,000 </li>
<li> <a href="https://t.co/McauGhPdxH">Blacksmith</a> with high-performance CI infrastructure </li>
 </ul>
<p>We’re incredibly grateful for their support. If you’re interested in sponsoring the project, please <a href="mailto:contact@ladybird.org">contact us</a>.</p>
<h3 id="web-platform-tests-wpt"> Web Platform Tests (WPT) </h3>
<p>As usual, we’ve made some progress on the Web Platform Tests. We’ve added 13,090 passing tests for a new total of 1,831,856.</p>
<h3 id="google-recaptcha-passing"> Google reCAPTCHA passing </h3>
<p>There was a long-standing issue with our <a href="https://developer.mozilla.org/en-US/docs/Web/API/Window/postMessage">postMessage</a> implementation: if the serialized type had not previously been used in the destination realm, we would fail to reconstruct it. The realm didn’t recognize the type and rejected the message.</p>
<p>This is now fixed, allowing Google reCAPTCHA to pass!</p>
<video controls=""><source src="https://ladybird.org/assets/img/newsletter-july-2025-google-recaptcha.mp4"></video>
<p>Unfortunately, this only works on <code>https://www.google.com/</code> for now, due to a separate unresolved same-origin policy issue.</p>
<h3 id="high-refresh-rate-support"> High refresh rate support </h3>
<p>We now detect the refresh rate of the active screen to determine how often web content should be rendered. Previously, rendering was fixed at 60 frames per second.</p>
<p>Websites using <a href="https://developer.mozilla.org/en-US/docs/Web/API/Window/requestAnimationFrame">requestAnimationFrame</a> now render at up to 120Hz on supported hardware. This change also improves the smoothness of scrolling, animations, transitions, and more.</p>
<p><img src="https://ladybird.org/assets/img/newsletter-july-2025-high-refresh-rate.png" alt=""></p>
<h3 id="http3-support"> HTTP/3 support </h3>
<p><a href="https://en.wikipedia.org/wiki/HTTP/3">HTTP/3</a> support was recently added in curl 8.14.0 for users of OpenSSL and <a href="https://github.com/ngtcp2/ngtcp2">ngtcp2</a>. Since Ladybird uses the OpenSSL backend with libcurl, this enabled us to support HTTP/3 as well.</p>
<p>We now negotiate HTTP/3 for servers that advertise it via the <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Headers/Alt-Svc">Alt-Svc header</a>.</p>
<p><img src="https://ladybird.org/assets/img/newsletter-july-2025-http-3.png" alt=""></p>
<p>We also found and reported an issue in curl where <code>Alt-Svc: clear</code> was parsed incorrectly. This has since been <a href="https://curl.se/ch/8.15.0.html">fixed in curl 8.15.0.</a></p>
<h3 id="trusted-types"> Trusted Types </h3>
<p>Trusted Types is a security feature that helps prevent cross-site scripting (XSS) by locking down injection sinks like <code>Element.innerHTML</code>, <code>HTMLScriptElement.text</code>, and <code>HTMLScriptElement.src</code>. It allows web developers to define policies that control how sanitized content can be created and consumed.</p>
<p>This month, we added initial support for Trusted Types. This includes recognizing policies and enforcing type-safe DOM writes. Further work is ongoing to support more of the spec and improve compliance.</p>
<h3 id="svg-foreignobject-improvements"> SVG <code>foreignObject</code> improvements </h3>
<p>The relationship between HTML and SVG is complex. While SVG content can appear in HTML, SVG can also embed arbitrary HTML using the <code>foreignObject</code> element.</p>
<p>This month, we made major improvements to how Ladybird handles <code>foreignObject</code>. Layout, style resolution, and rendering inside embedded HTML are now much closer to spec behavior, with better integration between the two worlds.</p>
<h3 id="css-content-url"> CSS <code>content: url(...)</code> </h3>
<p>We added support for using <code>content: url(...)</code> in CSS pseudo-elements such as <code>::before</code> and <code>::after</code>. This allows authors to insert images via CSS content, matching behavior seen on modern websites.</p>
<h3 id="statefoo-and-unchecked-pseudo-classes"> <code>:state(foo)</code> and <code>:unchecked</code> pseudo-classes </h3>
<p>We gained two new pseudo-classes:</p>
<ul> 
<li> <code>:state(foo)</code> matches a custom element whose states set includes <code>"foo"</code>. This allows custom elements to be styled based on internal state, similar to how <code>:checked</code> and <code>:empty</code> work. </li>
<li> <code>:unchecked</code> matches elements that are checkable but currently not checked. </li>
 </ul>
<p>These additions improve our compatibility with web components and modern form styling.</p>
<h3 id="logical-property-groups"> Logical property groups </h3>
<p>Building on work from <a href="https://ladybird.org/newsletter/2025-06-30/#css-logical-aliases">last month</a>, we now generate the mappings from logical to physical properties at compile time.</p>
<p>Logical and physical properties form groups—for example, the various <code>margin</code> properties—and we now take these into account when serializing styles and when modifying them from JavaScript. This improves both CSS fidelity and performance.</p>
<h3 id="arbitrary-substitution-functions"> Arbitrary substitution functions </h3>
<p>This month we rewrote our implementations of <code>var()</code> and <code>attr()</code> to align with the formal definition of <em> arbitrary substitution functions </em> in recent CSS specs. These are functions that return a value to be substituted into the rule before parsing continues.</p>
<p>Our new implementation is more robust, more spec-compliant, and sets us up to support other substitution functions like <code>if()</code> and <code>env()</code> in the future.</p>
<h3 id="syntax-parsing"> <code>&lt;syntax&gt;</code> parsing </h3>
<p>CSS now allows authors to define the expected syntax for attribute values using the <code>&lt;syntax&gt;</code> type. This is used within <code>attr()</code> to guide how the value should be parsed.</p>
<p>For example:</p>
<pre tabindex="0" data-language="css"><code><span><span>color: attr(</span><span>data-color</span><span> type(&lt;color</span><span>&gt;</span><span>));</span></span>
<span></span></code></pre>
<p>This instructs the parser to interpret the <code>data-color</code> attribute as a CSS color. Ladybird now supports <code>&lt;syntax&gt;</code> parsing and uses it to improve behavior in CSS Houdini and custom properties.</p>
<h3 id="property-progress"> <code>@property</code> progress </h3>
<p>We’ve had a stub implementation of <code>@property</code> for a while. This month, we started fleshing it out.</p>
<p>We now respect the initial value defined in a <code>@property</code> declaration and added initial support for <code>CSS.registerProperty()</code>. This brings us closer to full Houdini support.</p>
<h3 id="the-web-is-utf-16"> The Web is UTF-16 </h3>
<p>By definition, strings in JavaScript and the web are <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String#utf-16_characters_unicode_code_points_and_grapheme_clusters">UTF-16 encoded</a>. Until now, LibJS used UTF-8 internally and transcoded to UTF-16 on the fly.</p>
<p>This month, we introduced a native UTF-16 string type and began transitioning LibJS and LibWeb to use it internally. This simplifies the implementation and avoids subtle encoding-related bugs, especially with Unicode edge cases.</p>
<h3 id="credits"> Credits </h3>
<p>We’d like to thank everyone who contributed code this month:</p>
<p><em> Abhinav, Ali Mohammad Pur, Aliaksandr Kalenik, Andreas Kling, Andrew Kaster, aplefull, Arran Ireland, ayeteadoe, Ben Eidson, Callum Law, Chase Knowlden, dmaivel, edvwib, Gingeh, Glenn Skrzypczak, Grant Knowlton, InvalidUsernameException, Jan Koudijs, Jelle Raaijmakers, Kemal Zebari, Kenneth Myhra, Lucien Fiorini, Luke Wilde, Manuel Zahariev, Michael Manganiello, mikiubo, norbiros, Olekoop, Philipp Dreher, Psychpsyo, rmgx, Rocco Corsi, Ryan Liptak, Sam Atkins, Shannon Booth, Tete17, Tim Ledbetter, Timothy Flynn, Trey Shaffer, Undefine, Veeti Paananen, zac </em></p>  </div> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Terence Tao weighs in on the suspension of UCLA grants (244 pts)]]></title>
            <link>https://mathstodon.xyz/@tao/114956840959338146</link>
            <guid>44765264</guid>
            <pubDate>Sat, 02 Aug 2025 06:28:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mathstodon.xyz/@tao/114956840959338146">https://mathstodon.xyz/@tao/114956840959338146</a>, See on <a href="https://news.ycombinator.com/item?id=44765264">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Hardening mode for the compiler (140 pts)]]></title>
            <link>https://discourse.llvm.org/t/rfc-hardening-mode-for-the-compiler/87660</link>
            <guid>44764376</guid>
            <pubDate>Sat, 02 Aug 2025 02:12:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://discourse.llvm.org/t/rfc-hardening-mode-for-the-compiler/87660">https://discourse.llvm.org/t/rfc-hardening-mode-for-the-compiler/87660</a>, See on <a href="https://news.ycombinator.com/item?id=44764376">Hacker News</a></p>
Couldn't get https://discourse.llvm.org/t/rfc-hardening-mode-for-the-compiler/87660: AggregateError]]></description>
        </item>
        <item>
            <title><![CDATA[Cerebras Code (404 pts)]]></title>
            <link>https://www.cerebras.ai/blog/introducing-cerebras-code</link>
            <guid>44762959</guid>
            <pubDate>Fri, 01 Aug 2025 22:04:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cerebras.ai/blog/introducing-cerebras-code">https://www.cerebras.ai/blog/introducing-cerebras-code</a>, See on <a href="https://news.ycombinator.com/item?id=44762959">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-slicetype="articleText" data-sanity="id=b3028dee-114d-45fb-98ff-1aa7e4d66926;type=blogPost;path=slices;base=https%3A%2F%2Fwww.cerebras.ai"><p>We are launching two new plans designed to make AI coding faster and more accessible: <strong>Cerebras Code Pro</strong> ($50/month) and <strong>Code Max</strong> ($200/month). Both plans give you access to <strong>Qwen3-Coder</strong>, the world’s leading open-weight coding model—running at speeds of up to <strong>2,000 tokens per second</strong>, with a <strong>131k-token context window</strong>, no proprietary IDE lock-in, and no weekly limits!</p><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--><h3>Cerebras Makes Code Generation Instant</h3><p>Even with the best frontier models, you still end up waiting around for completions. And as coding workflows get more agentic, the latency adds up fast. You’re not just waiting once. You have to wait on every LLM call across multi-step edits, tool use, retries, and planning.</p><p>At 2,000 tokens per second, code generation becomes instant. And starting at $50/month, anyone can use Cerebras Code and enjoy fast code generation that keeps you in flow.</p><h3>Powered by a Frontier Model</h3><p>Qwen3‑Coder is Alibaba’s flagship coding agent model. The 480B parameter model delivers performance comparable to Claude Sonnet 4 and GPT‑4.1 in coding and agentic tasks, achieving leading performance on coding benchmarks such as Agentic Coding, Agentic Browser-Use, and BFCL.</p><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--><h3>Bring your own AI IDE</h3><p>If your code editor or tool supports OpenAI compatible inference endpoints, you can use it with Cerebras Code. Plug Cerebras Code into anything – Cursor, Continue.dev, Cline, RooCode, or whatever else you’re using. No extra setup. Just instant, high quality code generation inside your own workflow.</p><h3>Available now</h3><p><strong>Cerebras Code Pro - ($50/month)</strong></p><ul><li>Qwen3-Coder access with fast, high-context completions.</li><li>Send up to 1,000 messages per day—enough for 3–4 hours of uninterrupted vibe coding.</li><li>Ideal for indie devs, simple agentic workflows, and weekend projects.</li></ul><p><strong>Cerebras Code Max - ($200/month)</strong></p><ul><li>Qwen3-Coder access for heavy coding workflows.</li><li>Send up to 5,000 messages/day.</li><li>Ideal for full-time development, IDE integrations, code refactoring, and multi-agent systems.</li></ul><p>Cerebras Code Pro and Code Max are available today, no waitlist<a href="http://cloud.cerebras.ai/">. Sign up,</a> bring your key to your favorite editor, and start building instantly.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. fires statistics chief after soft jobs report (161 pts)]]></title>
            <link>https://www.politico.com/news/2025/08/01/trump-firing-bureau-labor-statistics-chief-jobs-report-00488960</link>
            <guid>44762943</guid>
            <pubDate>Fri, 01 Aug 2025 22:02:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.politico.com/news/2025/08/01/trump-firing-bureau-labor-statistics-chief-jobs-report-00488960">https://www.politico.com/news/2025/08/01/trump-firing-bureau-labor-statistics-chief-jobs-report-00488960</a>, See on <a href="https://news.ycombinator.com/item?id=44762943">Hacker News</a></p>
Couldn't get https://www.politico.com/news/2025/08/01/trump-firing-bureau-labor-statistics-chief-jobs-report-00488960: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Coffeematic PC – A coffee maker computer that pumps hot coffee to the CPU (250 pts)]]></title>
            <link>https://www.dougmacdowell.com/coffeematic-pc.html</link>
            <guid>44762880</guid>
            <pubDate>Fri, 01 Aug 2025 21:53:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.dougmacdowell.com/coffeematic-pc.html">https://www.dougmacdowell.com/coffeematic-pc.html</a>, See on <a href="https://news.ycombinator.com/item?id=44762880">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
      <!-- First artwork/project -->
      <article>

  
  

        <div><p>
            Sometime during winter 2024, I found myself at a thrift store. I was staring at rows of appliances, 
            wrapped in plastic and clinging to life, trying to answer one question: which of these is the right 
            chassis for a retro gaming computer?
            </p><p>
            Driving home, I took corners carefully, checking that the General Electric (GE) drip coffee maker I’d 
            chosen was safe in the backseat. The coffee maker's given name was Coffeematic.  Circa 1980, 
            it is boxy yet athletic – unfazed by any considerations of future internet connectivity. Best, it is perfect for being hacked.
            </p><p>
            Coffeematic is now Coffeematic PC – part gaming computer, part coffee maker. 
            A newly synthesized machine percolating processes well beyond its original configuration. 
            <span>Coffeematic PC is part of a lineage of coffee maker computers made since 2002</span>. 
            I'll describe that fascinating lineage here, and how it inspired an art exhibition called <a href="https://www.dougmacdowell.com/Sparklines.html">Sparklines</a> 
            where hand-drafted data visualizations accompany Coffeematic PC.
            <br>

<a href="https://www.dougmacdowell.com/images/coffeematic-pc-final-build-doug-macdowell.png" target="_blank" rel="noopener noreferrer" aria-label="View full-size image of Coffeematic PC by Doug MacDowell">
  <img src="https://www.dougmacdowell.com/images/coffeematic-pc-final-build-doug-macdowell.png" alt="Coffeematic PC, the final build of a coffee maker computer by artist Doug MacDowell" width="1700" height="2076" loading="lazy">
</a></p></div><p>
            Profound and poetically articulated. Elegant and assertive. Highly scaleable with dynamic acceleration. 
            No. These do not describe Coffeematic PC or its peers (one of those phrases describes a bottle of wine.)
            A custom built computer can be basic and functional, or an <a href="https://www.instagram.com/p/CJMYik2ptvJ/">elaborate, absurd, 
            spinning piece of art.</a>  <span>Coffeematic PC falls somewhere in that spectrum 
            while also being nearly self-destructive.</span>
        </p>
        <br>

<img src="https://www.dougmacdowell.com/images/coffeematic-pc-in-progress-doug-macdowell.jpeg" alt="Coffeematic PC, a coffee maker computer in progress on artist Doug MacDowell’s workspace" width="600" height="800" loading="lazy">


      
      <p>
        This is how Coffeematic PC works. 
        <span>The computer is fully functional. The coffee maker is too</span>, 
        it percolates Java like a regular coffee maker. Very hot Java. 
        Computers usually use fans or liquid cooling systems to reduce heat. 
        Coffeematic PC uses the hot Java it brews to heat? cool? caffeinate? the computer. 
        A pump takes the hot, caffenated slurry (~90C/194F) 
        and circulates it thru two radiators sitting on top of Coffeematic PC's crown -&gt; 
        down to a central processing unit (CPU) tucked within an ASUS M2NPV-VM 
        motherboard snugly strapped to Coffeematic PC's back. 
        Java continues through an artery returning to Coffeematic PC's caraffe.
        The process repeats until Java is integrated with the user or the machine is powered off.
      </p>
      <br>

<img src="https://www.dougmacdowell.com/images/coffeematic-pc-dispensing-liquid-doug-macdowell.jpeg" alt="Coffeematic PC coffee maker computer dispensing liquid, created by artist Doug MacDowell" loading="lazy" width="1000" height="750">

 
    <p>
    ↑ Coffeematic PC has a dedicated pump to aggressively dispense Java for user.
  </p>
  
  <p>
    CPU's are meant to be cool and Java hot. <span>Despite circulating hot Java, 
      Coffeematic PC does not crash.</span>
    To understand more, I wrote command line code to gather data on Coffeematic PC every 5 seconds, 
    and monitored Coffeematic PC for 75 minutes.
    The graph below shows the results. 
    The machine is just barely non-destructive. <span>Coffeematic PC's CPU, body, 
    and circulatory system eventually find equilibrium. A warm 33C/91F - 
    amazingly close to the temperature of the slurry that flows through you and me.</span>
  </p>
  <!-- Tableau Graph Container with Interactive Effect -->
  
  <div><p>
    An important part of this project is the lineage of coffee maker computers. 
    Before discussing that, <span>
    this is how Coffeematic PC was made.</span>
    The build is a mix of discarded electronics and newly purchased 
    hardware, pumps, and radiators. The motherboard, CPU, RAM, and graphics card are from the mid 2000's and were 
    sourced from a recycling center. This is a parts list for Coffeematic PC. 
    </p></div><ul>
      <li><a href="https://magnum-mania.com/Forum/viewtopic.php?t=3362" target="_blank">GE Coffeematic Coffee Maker 10 Cup</a></li>
      <li><a href="https://theretroweb.com/motherboards/s/asus-m2npv-vm" target="_blank">ASUS M2NPV-VM AM2 Motherboard</a></li>
      <li><a href="https://pcpartpicker.com/product/ThH323/amd-cpu-adx640wfk42gm" target="_blank">AMD Athlon II X4 640 3 GHz Quad-Core OEM/Tray Processor</a></li>
      <li><a href="https://www.newegg.com/p/0RN-000W-000J4?srsltid=AfmBOoro0skXPXWALsj8eGNWiY8Wgqou_jY8OX9m1uBXHf0b3w8LdMSU" target="_blank">Hynix 1GB 2Rx8 PC2-5300U-555-12 PC2-DDR2 RAM</a></li>
      <li><a href="https://pcpartpicker.com/product/WzvdnQ/acer-sa100-240-gb-25-solid-state-drive-bl9bwwa102" target="_blank">Acer SA100 240 GB 2.5" Solid State Drive</a></li>
      <li><a href="https://pcpartpicker.com/product/yVvRsY/his-video-card-h467qr1gh" target="_blank">HIS H467QR1GH Radeon HD 4670 1 GB Video Card</a></li>
      <li><a href="https://pcpartpicker.com/product/2nvRsY/antec-power-supply-ea430dgreen" target="_blank">Antec Earthwatts Green 430 W 80+ Bronze Certified ATX Power Supply</a></li>
      <li><a href="https://linuxmint.com/" target="_blank">Linux Mint Operating System</a></li>
      <li><a href="https://www.amazon.com/dp/B01EMQKNTU?ref=ppx_yo2ov_dt_b_fed_asin_title" target="_blank">CPU Water Cooling Block for Intel</a></li>
      <li><a href="https://www.amazon.com/dp/B08DMSGTJR?ref=ppx_yo2ov_dt_b_fed_asin_title&amp;th=1" target="_blank">Water Cooling Computer Radiator</a></li>
      <li><a href="https://www.amazon.com/dp/B09XH1GYYQ?ref=ppx_yo2ov_dt_b_fed_asin_title" target="_blank">12V Mini Food Grade Self Priming Diaphragm Fresh Water Transfer Pump</a></li>
      <li><a href="https://www.amazon.com/dp/B0BNN36VW6?ref=ppx_yo2ov_dt_b_fed_asin_title" target="_blank">Waterproof Toggle Switch 12V</a></li>
      <li><a href="https://www.amazon.com/dp/B08MLC651Y?ref=ppx_yo2ov_dt_b_fed_asin_title&amp;th=1" target="_blank">Brass Hose Barb  3/8" to 3/16"</a></li>
      <li><a href="https://www.amazon.com/dp/B08ML4YNZ3?ref=ppx_yo2ov_dt_b_fed_asin_title&amp;th=1" target="_blank">Brass Hose Barb, 5/16" to 3/16"</a></li>
      <li><a href="https://www.amazon.com/dp/B08HXN811Y?ref=ppx_yo2ov_dt_b_fed_asin_title&amp;th=1" target="_blank">90 Degree Elbow Hose Barb 3/16"</a></li>
      <li><a href="https://www.amazon.com/dp/B07CM7PPXP?ref=ppx_yo2ov_dt_b_fed_asin_title&amp;th=1" target="_blank">90 Degree Elbow Hose Barb 3/8" 10mm</a></li>
      <li><a href="https://www.amazon.com/dp/B07CMD3KBD?ref=ppx_yo2ov_dt_b_fed_asin_title&amp;th=1" target="_blank">90 Degree Elbow Hose Barb 5/16" 8mm</a></li>
      <li><a href="https://www.amazon.com/dp/B07TH8H1QP?ref=ppx_yo2ov_dt_b_fed_asin_title&amp;th=1" target="_blank">Food Grade Silicon Tubing 3/16" ID x 5/16" OD</a></li>
      <li><a href="https://www.amazon.com/dp/B000E62TCC?ref=ppx_yo2ov_dt_b_fed_asin_title&amp;th=1" target="_blank">Food Grade Vinyl Tubing 5/16" ID - 7/16" OD</a></li>
    </ul>
    

<p>
I spent about a month designing and building Coffeematic PC with the help from my beautiful fiance. 
<span>The build traverses time</span>. The coffee maker is from the late 1970's, the motherboard, CPU, and graphics card from the 2000's, and 
the SSD, operating system, and hardware from the today's (2020's). The General Electric coffee maker needed only a minor repair of 
replacing a small vinyl tube that had cracked. It takes awhile to brew a pot of coffee, but once it is brewed... it tastes like 
coffee made from a plastic coffee maker from the 1970's. I'lllll drink it!
</p>
<br>

<section aria-labelledby="video-heading">
  
  <p>
    A few clips of how Coffeematic PC was built. <a href="https://www.youtube.com/watch?v=4wuM2eN1uW8" target="_blank" rel="noopener noreferrer">
  Watch on YouTube
</a>
  </p>
  <p>
    <iframe src="https://www.youtube.com/embed/4wuM2eN1uW8" title="Making a Coffee Maker Computer - Coffeematic PC - Doug MacDowell" width="560" height="315" frameborder="0" loading="lazy" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="">
    </iframe>
  </p>
</section>


    
  <p><span>The lineage of coffee maker computer builds spans 
    22 years with a curious 15 year gap in the middle.</span> 
    I'm not the first person to synthesize a coffee maker and a computer. 
    But, I think I am the first to use hot Java as a cooling method. The graph below shows the lineage of 
    coffee maker computers. There are a total of 5.  In 2002 Nick Pelis built the first ever coffee maker computer named 
    <a href="https://web.archive.org/web/20131210043642/http://themodzoo.com/forum/index.php?/topic/931-the-caffeine-machine/" target="_blank">The Caffeine Machine</a>. 
    Then, the builds went cold for 15 years until 2018, when a person named Ali “THE CRE8OR” Abbas collaborated with a company named 
    Zotac to make the 
    <a href="https://thecre8or.de/mekspresso.htm" target="_blank">Zotac Mekspresso</a> 
    to feature in a trade show. One year after in 2019, a man whose username is Logarythm made the 
    <a href="https://pcpartpicker.com/b/mngwrH" target="_blank">Mr. Coffee PC</a>. This unassuming build is perhaps 
    my favorite. 
    5 years later, after COVID-19, NerdForge, a youtube channel specializing on fun builds, built a 
    <a href="https://youtu.be/oSVPkuplVRY" target="_blank">"PC that 
      makes coffee"</a>. During this time I was making 
      <a href="https://www.dougmacdowell.com/Percolating%20Human%20Computer%20Interaction,%202024.html" target="_blank">Coffeematic PC</a>.
    </p>
      <p> 

<img src="https://www.dougmacdowell.com/images/coffeematic-pc-lineage-major-tech-events-doug-macdowell.jpeg" alt="Lineage of Coffeematic PC coffee maker computers with major technology events, by artist Doug MacDowell" width="1508" height="1150" loading="lazy"></p><div><p><span>Why is there a 15 year gap between the first coffee maker computer and the rest? Were people tired of 
      drinking coffee?</span> I don't think so. We're people tired of building fun computers? Were they distracted? Could they not afford it?
      I'm not sure. But something is wrong. There should be a steady output of absurd coffee maker computers being made. 
      What happened in those 15 years? To look into it I created the graph above. It shows a timeline of 
      coffee maker computers along with important events compiled from the 
      <a href="https://www.computerhistory.org/timeline/computers/" target="_blank">The Timeline of Computer History</a> 
      from the Computer History Museum. Of course, there are many important things that happened worldwide between 2002 and 2018 like 
      war, natural disasters, financial crisis, shootings, refugee crisis, and the apocalypse in 2012 determined by the end of 
      the Mayan calendar. Its too much to capture in this dinky graph. But maybe focusing on tech, and the culture of tech, 
      can reveal something about this large gap in absurd creativity. Do you see any trends?
      </p><p> 

      <img src="https://www.dougmacdowell.com/images/coffeematic-pc-studio-doug-macdowell.jpeg" alt="Doug MacDowell's studio while building Coffeematic PC - a coffee maker computer" width="700" height="933" loading="lazy"></p></div><p>
        Coffeematic PC inspired an art exhibition called <a href="https://www.dougmacdowell.com/sparklines.html">Sparklines</a>. In Sparklines I elaborate on 
        the curious 15 year gap in coffee maker computers being built and create data portraits of a group of people I call 
        artist-hackers. The work is all drawn by hand using drafting tools and a vintage lettering kit. Check it out at the link 
        above!
        
        Do you know of any other coffee maker computer builds that I missed?
        </p>
        <br>

        <img src="https://www.dougmacdowell.com/images/sparklines-back-of-coffeematic-pc.jpg" alt="The back side of Coffeematic PC, a coffee maker computer on display at an art" width="1800" height="1200" loading="lazy">
        <br> 



      </article>
    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Anthropic revokes OpenAI's access to Claude (264 pts)]]></title>
            <link>https://www.wired.com/story/anthropic-revokes-openais-access-to-claude/</link>
            <guid>44762856</guid>
            <pubDate>Fri, 01 Aug 2025 21:50:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/anthropic-revokes-openais-access-to-claude/">https://www.wired.com/story/anthropic-revokes-openais-access-to-claude/</a>, See on <a href="https://news.ycombinator.com/item?id=44762856">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>All products featured on WIRED are independently selected by our editors. However, we may receive compensation from retailers and/or from purchases of products through these links.</p></div><div data-journey-hook="client-content" data-testid="ArticlePageChunks"><p><span>Anthropic revoked OpenAI’s</span> API access to its models on Tuesday, multiple sources familiar with the matter tell WIRED. OpenAI was informed that its access was cut off due to violating the terms of service.</p><p>“Claude Code has become the go-to choice for coders everywhere, and so it was no surprise to learn OpenAI's own technical staff were also using our coding tools ahead of the launch of GPT-5,” Anthropic spokesperson Christopher Nulty said in a statement to WIRED. “Unfortunately, this is a direct violation of our terms of service.”</p><p>According to Anthropic’s <a data-offer-url="https://www.anthropic.com/legal/commercial-terms" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.anthropic.com/legal/commercial-terms&quot;}" href="https://www.anthropic.com/legal/commercial-terms" rel="nofollow noopener" target="_blank">commercial terms of service</a>, customers are barred from using the service to “build a competing product or service, including to train competing AI models” or “reverse engineer or duplicate” the services. This change in OpenAI’s access to Claude comes as the ChatGPT-maker is <a data-offer-url="https://www.theverge.com/notepad-microsoft-newsletter/712950/openai-gpt-5-model-release-date-notepad" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.theverge.com/notepad-microsoft-newsletter/712950/openai-gpt-5-model-release-date-notepad&quot;}" href="https://www.theverge.com/notepad-microsoft-newsletter/712950/openai-gpt-5-model-release-date-notepad" rel="nofollow noopener" target="_blank">reportedly</a> preparing to release a new AI model, GPT-5, which is <a data-offer-url="https://www.theinformation.com/articles/openais-gpt-5-shines-coding-tasks?rc=mshudk" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.theinformation.com/articles/openais-gpt-5-shines-coding-tasks?rc=mshudk&quot;}" href="https://www.theinformation.com/articles/openais-gpt-5-shines-coding-tasks?rc=mshudk" rel="nofollow noopener" target="_blank">rumored</a> to be better at coding.</p><p>OpenAI was plugging Claude into its own internal tools using special developer access (APIs), instead of using the regular chat interface, according to sources. This allowed the company to run tests to evaluate Claude’s capabilities in things like coding and creative writing against its own AI models, and check how Claude responded to safety-related prompts involving categories like CSAM, self-harm, and defamation, the sources say. The results help OpenAI compare its own models’ behavior under similar conditions and make adjustments as needed.</p><p>“It’s industry standard to evaluate other AI systems to benchmark progress and improve safety. While we respect Anthropic’s decision to cut off our API access, it’s disappointing considering our API remains available to them,” OpenAI’s chief communications officer Hannah Wong said in a statement to WIRED.</p><p>Nulty says that Anthropic will “continue to ensure OpenAI has API access for the purposes of benchmarking and safety evaluations as is standard practice across the industry.” The company did not respond to WIRED’s request for clarification on if and how OpenAI's current Claude API restriction would impact this work.</p><p>Top tech companies yanking API access from competitors has been a tactic in the tech industry for years. Facebook <a data-offer-url="https://venturebeat.com/social/facebooks-alleged-use-of-apis-to-crush-competition-is-a-warning-to-other-data-companies/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://venturebeat.com/social/facebooks-alleged-use-of-apis-to-crush-competition-is-a-warning-to-other-data-companies/&quot;}" href="https://venturebeat.com/social/facebooks-alleged-use-of-apis-to-crush-competition-is-a-warning-to-other-data-companies/" rel="nofollow noopener" target="_blank">did the same to Twitter-owned Vine</a> (which led to allegations of anticompetitive behavior) and last month Salesforce <a data-offer-url="https://www.theinformation.com/articles/salesforce-blocks-ai-rivals-using-slack-data?rc=mshudk" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.theinformation.com/articles/salesforce-blocks-ai-rivals-using-slack-data?rc=mshudk&quot;}" href="https://www.theinformation.com/articles/salesforce-blocks-ai-rivals-using-slack-data?rc=mshudk" rel="nofollow noopener" target="_blank">restricted competitors</a> from accessing certain data through the Slack API. This isn’t even a first for Anthropic. Last month, the company restricted the AI coding startup Windsurf’s direct access to its models after it was rumored OpenAI was set to acquire it. (<a data-offer-url="https://techcrunch.com/2025/07/11/windsurfs-ceo-goes-to-google-openais-acquisition-falls-apart/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://techcrunch.com/2025/07/11/windsurfs-ceo-goes-to-google-openais-acquisition-falls-apart/&quot;}" href="https://techcrunch.com/2025/07/11/windsurfs-ceo-goes-to-google-openais-acquisition-falls-apart/" rel="nofollow noopener" target="_blank">That deal fell through</a>).</p><p>Anthropic’s chief science officer Jared Kaplan <a data-offer-url="https://techcrunch.com/2025/06/05/anthropic-co-founder-on-cutting-access-to-windsurf-it-would-be-odd-for-us-to-sell-claude-to-openai/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://techcrunch.com/2025/06/05/anthropic-co-founder-on-cutting-access-to-windsurf-it-would-be-odd-for-us-to-sell-claude-to-openai/&quot;}" href="https://techcrunch.com/2025/06/05/anthropic-co-founder-on-cutting-access-to-windsurf-it-would-be-odd-for-us-to-sell-claude-to-openai/" rel="nofollow noopener" target="_blank">spoke to TechCrunch</a> at the time about revoking Windsurf’s access to Claude, saying, “I think it would be odd for us to be selling Claude to OpenAI.”</p><p>A day before cutting off OpenAI’s access to the Claude API, Anthropic <a data-offer-url="https://x.com/AnthropicAI/status/1949898514844307953" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://x.com/AnthropicAI/status/1949898514844307953&quot;}" href="https://x.com/AnthropicAI/status/1949898514844307953" rel="nofollow noopener" target="_blank">announced</a> new rate limits on Claude Code, its AI-powered coding tool, citing <a data-offer-url="https://x.com/AnthropicAI/status/1949898511287226425" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://x.com/AnthropicAI/status/1949898511287226425&quot;}" href="https://x.com/AnthropicAI/status/1949898511287226425" rel="nofollow noopener" target="_blank">explosive usage</a> and, in some cases, <a data-offer-url="https://x.com/AnthropicAI/status/1949898513019466140" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://x.com/AnthropicAI/status/1949898513019466140&quot;}" href="https://x.com/AnthropicAI/status/1949898513019466140" rel="nofollow noopener" target="_blank">violations of its terms of service</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Researchers map where solar energy delivers the biggest climate payoff (106 pts)]]></title>
            <link>https://www.rutgers.edu/news/researchers-map-where-solar-energy-delivers-biggest-climate-payoff</link>
            <guid>44762026</guid>
            <pubDate>Fri, 01 Aug 2025 20:21:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rutgers.edu/news/researchers-map-where-solar-energy-delivers-biggest-climate-payoff">https://www.rutgers.edu/news/researchers-map-where-solar-energy-delivers-biggest-climate-payoff</a>, See on <a href="https://news.ycombinator.com/item?id=44762026">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    
  <h3><span><span><span><span>Using advanced computational modeling, a Rutgers professor, in collaboration with researchers from the Harvard T.H. Chan School of Public Health and Stony Brook University, reveal both the immediate and delayed climate benefits of solar power</span></span></span></span></h3>

<p><span><span><span><span>Increasing solar power generation in the United States by 15% could lead to an annual reduction of 8.54 million metric tons of carbon dioxide emissions, according to researchers at Rutgers, the Harvard T.H. Chan School of Public Health and Stony Brook University. </span></span></span></span></p>

<p><span><span><span><span>The <a href="https://www.science.org/doi/10.1126/sciadv.adq5660">study</a>, published in <em>Science Advances</em>, found that the climate benefits of solar power differ markedly throughout U.S. regions, pinpointing where clean energy investments return the greatest climate dividends. </span></span></span></span></p>

<p><span><span><span><span>In 2023, 60% of </span><a href="https://www.eia.gov/tools/faqs/faq.php?id=427&amp;t=3"><span>U.S. electricity generation</span></a><span> relied on fossil fuels, while 3.9% came from solar, according to the U.S. Energy Information Administration. Because fossil fuel-generated electricity is a </span><a href="https://pubmed.ncbi.nlm.nih.gov/31746196/"><span>leading source of carbon dioxide</span></a><span>, or CO2, and harmful air pollutants such as fine particulate matter, expanding solar could not only mitigate CO2 but help </span><a href="https://pubmed.ncbi.nlm.nih.gov/36961127/"><span>reduce illness, hospitalizations and premature deaths</span></a><span> linked to air pollution exposure.</span></span></span></span></p>

<blockquote>
<p>From a computer science perspective, this study demonstrates the power of harnessing large-scale, high-resolution energy data to generate actionable insights.</p>

<p>Arpita Biswas</p>

<p>Assistant Professor, Department of Computer Science, Rutgers School of Arts and Sciences</p>
</blockquote>

<p><span><span><span><span>Researchers examined five years of hourly electricity generation, demand and emissions data from the Energy Information Administration starting July 1, 2018. They focused on the 13 geographic regions in the United States. </span></span></span></span></p>

<p><span><span><span><span>With this </span><a href="https://doi.org/10.7910/DVN/OKEATQ"><span>dataset</span></a><span>, the researchers constructed a statistical model to explore how increases in hourly solar energy generation would affect CO2 emissions within a given region and in its neighboring regions. </span></span></span></span></p>

<p><span><span><span><span>The study quantified both immediate and delayed emissions reductions resulting from added solar generation. For example, the researchers found that in California, a 15% increase in solar power at noon was associated with a reduction of 147.18 metric tons of CO2 in the region in the first hour and 16.08 metric tons eight hours later. </span></span></span></span></p>

<p><span><span><span><span><span>“It was rewarding to see how advanced computational modeling can uncover not just the immediate, but also the delayed and far-reaching spillover effects of solar energy adoption,” said the lead author </span><a href="https://www.cs.rutgers.edu/people/professors/details/arpita-biswas"><span>Arpita Biswas</span></a><span>, an assistant professor with the Department of Computer Science at the Rutgers School of Arts and Sciences. “From a computer science perspective, this study demonstrates the power of harnessing large-scale, high-resolution energy data to generate actionable insights. For policymakers and investors, it offers a roadmap for targeting solar investments where emissions reductions are most impactful and where solar energy infrastructure can yield the highest returns.”</span></span></span></span></span></p>

<p><span><span><span><span><span>The researchers said their methods provide a more nuanced understanding of system-level impacts from solar expansion than previous studies, pinpointing where the benefits of increased solar energy adoption could best be realized. In some areas, such as California, Florida, the mid-Atlantic, the Midwest, Texas and the Southwest, small increases in solar were estimated to deliver large CO2 reductions, while in others, such as New England, the central U.S., and Tennessee, impacts were found to be minimal – even at much larger increases in solar generation. </span></span></span></span></span></p>

<p><span><span><span><span><span>In addition, the researchers said their study demonstrates the significant spillover effects solar adoption has on neighboring regions, highlighting the value of coordinated clean energy efforts. For example, a 15% increase in solar capacity in California was associated with a reduction of 913 and 1,942 metric tons of CO2 emissions per day in the northwest and southwest regions, respectively. </span></span></span></span></span></p>

<p><span><span><span><span><span>“</span></span><span>I am very excited about this study because it harnesses the power of data science to offer insights for policymakers and stakeholders in achieving CO2 reduction targets through increased solar generation,” said Francesca Dominici, director of the Harvard Data Science Initiative and Clarence James Gamble Professor of Biostatistics, Population and Data Science and a corresponding author of the study.</span></span></span></span></p>

<p><span><span><span><em><span><span><span>Explore more of the ways Rutgers research&nbsp;</span></span></span></em><a href="https://www.rutgers.edu/news/categories/research-innovation" target="_blank"><em><span><span>is shaping the future</span></span></em></a><em><span><span><span>.</span></span></span></em></span></span></span></p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Does the Bitter Lesson Have Limits? (162 pts)]]></title>
            <link>https://www.dbreunig.com/2025/08/01/does-the-bitter-lesson-have-limits.html</link>
            <guid>44762022</guid>
            <pubDate>Fri, 01 Aug 2025 20:21:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.dbreunig.com/2025/08/01/does-the-bitter-lesson-have-limits.html">https://www.dbreunig.com/2025/08/01/does-the-bitter-lesson-have-limits.html</a>, See on <a href="https://news.ycombinator.com/item?id=44762022">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Recently, “the bitter lesson” is having a moment. Coined in <a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">an essay by Rich Sutton</a>, the bitter lesson is that, “general methods that leverage computation are ultimately the most effective, and by a large margin.” Why is the lesson bitter? Sutton writes:</p>

<blockquote>
  <p>The bitter lesson is based on the historical observations that 1) AI researchers have often tried to build knowledge into their agents, 2) this always helps in the short term, and is personally satisfying to the researcher, but 3) in the long run it plateaus and even inhibits further progress, and 4) breakthrough progress eventually arrives by an opposing approach based on scaling computation by search and learning. The eventual success is tinged with bitterness, and often incompletely digested, because it is success over a favored, human-centric approach.</p>
</blockquote>

<p>Sutton walks through how the fields of computer chess, computer go, speech recognition, and computer vision have all experienced the bitter lesson.</p>

<p>Lately, people have been citing the bitter lesson a lot.</p>

<p><img src="https://www.dbreunig.com/img/bitter_lesson_trends.jpg" alt="Google Trends data shows the bitter lesson on the upswing"></p>

<hr>

<h3 id="a-blow-to-the-human-ego">A Blow to the Human Ego</h3>

<p>The first time I read “The Bitter Lesson”, I thought of <a href="https://feministstudies.ucsc.edu/faculty/index.php?uid=haraway">Donna Haraway</a>, one of my professors at UCSC. During a seminar on the history of science, she presented her list of the <strong>four major blows to the human ego</strong> (<a href="https://www.dbreunig.com/2013/10/26/the-5-blows-to-the-human-ego.html">which I previously wrote about</a>):</p>

<ul>
  <li><a href="http://en.wikipedia.org/wiki/Copernican_Revolution">The Copernican Revolution</a>, which allowed us to realize we weren’t the center of the universe.</li>
  <li><a href="http://en.wikipedia.org/wiki/On_the_Origin_of_Species">Darwinian thought</a>, which allowed us to realize we weren’t separate from animals.</li>
  <li><a href="http://en.wikipedia.org/wiki/Unconscious_mind#Freud.27s_view_of_the_unconscious">Freud’s ideas of the unconscious</a>, which allowed us to realize that we weren’t in full control of our selves.</li>
  <li><a href="http://en.wikipedia.org/wiki/Cyborg">Cyborgs</a>, <a href="http://en.wikipedia.org/wiki/Robot">robots</a>, and <a href="http://en.wikipedia.org/wiki/Automaton">automatons</a>, which allowed us to realize that non-humans could do the work of humans.</li>
</ul>

<p>These concepts undermined humans’ imagined central position in the universe.</p>

<p>The bitter lesson slots in naturally here; really a sub-point of <em>cyborgs</em>, a topic which Haraway has been <a href="https://en.wikipedia.org/wiki/A_Cyborg_Manifesto">exploring for decades</a>. Within this framework, it’s easy to believe! My instinctual belief reminds me of an exchange from a <a href="https://radiolab.org/podcast/91522-its-not-about-you/transcript">2010 RadioLab segment with Neil deGrasse Tyson</a>:</p>

<blockquote>
  <p><strong>ROBERT KRULWICH:</strong> Is it your working bias that if I came to you with a new discovery in which we were less important, or a discovery which proposed that we were more important, that you would guess that my scientific discovery that said we are less important is more likely to be right?</p>
</blockquote>

<blockquote>
  <p><strong>NEIL DEGRASSE TYSON:</strong> No doubt about it. That’s correct. Now you call that a bias, but I don’t. I call that track record.</p>
</blockquote>

<hr>

<h3 id="bitter-skepticism">Bitter Skepticism</h3>

<p>Surprisingly, the bitter lesson landed on my LinkedIn feed this week. Among the emoji-laden bulleted lists and grindset slop was a new Ethan Mollick piece, “<a href="https://www.oneusefulthing.org/p/the-bitter-lesson-versus-the-garbage">The Bitter Lesson versus The Garbage Can</a>”. In it, Mollick contrasts the step-by-step way businesses are building agents with the reality of business processes:</p>

<blockquote>
  <p>One thing you learn studying (or working in) organizations is that they are all actually a bit of a mess. In fact, one classic organizational theory is actually called the Garbage Can Model. This views organizations as chaotic “garbage cans” where problems, solutions, and decision-makers are dumped in together, and decisions often happen when these elements collide randomly, rather than through a fully rational process. Of course, it is easy to take this view too far - organizations do have structures, decision-makers, and processes that actually matter. It is just that these structures often evolved and were negotiated among people, rather than being carefully designed and well-recorded.</p>
</blockquote>

<blockquote>
  <p>The Garbage Can represents a world where unwritten rules, bespoke knowledge, and complex and undocumented processes are critical. It is this situation that makes AI adoption in organizations difficult, because even though 43% of American workers have used AI at work, they are mostly doing it in informal ways, solving their own work problems. Scaling AI across the enterprise is hard because traditional automation requires clear rules and defined processes; the very things Garbage Can organizations lack.</p>
</blockquote>

<p>The bitter lesson is about to be rediscovered, Mollick suggests. “If AI agents can train on outputs alone, any organization that can define quality and provide enough examples might achieve similar results, whether they understand their own processes or not,” he writes. Org charts and workflows are UX for us humans, unneeded by our agents.</p>

<p>But while I found myself quickly accepting the original bitter lesson essay, Mollick’s essay triggered my inner skeptic. Two practical issues immediately arose:</p>

<p><strong>The bitter lesson is dependent on high-quality data.</strong></p>

<p>Data has an embedded perspective. It is not objective. Further, data is <em>reductive</em>, a shadow of the information it represents. And many things resist being reduced to data points<sup id="fnref:haraway" role="doc-noteref"><a href="#fn:haraway" rel="footnote">1</a></sup>. Without sufficient data, the bitter lesson cannot be learned.</p>

<p>When Mollick writes, “any organization that can define quality and provide enough examples might achieve similar results,” I immediately focus on the word “can”. Most organizations I’ve encountered have an incredibly hard time defining their objectives <em>firmly</em> and <em>clearly</em>, if they’re able to at all.</p>

<p>Already, companies rely on goal-setting metrics or rubrics like <a href="https://en.wikipedia.org/wiki/Objectives_and_key_results">OKRs</a> to attempt to measure that which resists measurement. These can be helpful, but their reductive nature leads to gaming<sup id="fnref:goog" role="doc-noteref"><a href="#fn:goog" rel="footnote">2</a></sup>. Any metrics organizations use to optimize agents with likely be argued over, squishy, and inadequate.</p>

<p>Unlike the workplace, the fields Sutton cites as having met the bitter lesson are ones where the objective is easy to quantify. Victory in go and chess is clear, speech can be directly matched to written text, and most subjects in images can be easily annotated. It’s okay if you find a way to game the system to win a chess game; the rules are air tight.</p>

<p>Further, these fields can be easily represented with data – which is necessary for any general program that needs to learn how to achieve the quantifiable goal. Even <em>if</em> a company can give a clear, firm definition of quality, it still has to figure out how to measure all the interactions involved in producing this output. Otherwise, the program has no ideas what levers if can pull.</p>

<p>If we wish to teach agent-builders the bitter lesson, we need to get better at defining outputs concretely that are resistant to reward hacking (even if they’re not perfect, as <a href="https://www.dbreunig.com/2025/07/31/how-kimi-rl-ed-qualitative-data-to-write-better.html">we explored yesterday</a>) and figure out how to represent “Garbage Can” organizations with data.</p>

<p><strong>Adding compute is often not practical nor optimal.</strong></p>

<p>Speaking of chess, to illustrate his point, Mollick used both Manus and ChatGPT Agent Mode to create charts documenting the performance of human and computer chess play over time. Here’s ChatGPT’s:</p>

<p><img src="https://www.dbreunig.com/img/chatgpt_agent_chess.jpg" alt=""></p>

<p>If you’re a chess nerd, you might catch how this plot undermines the bitter lesson: <strong><a href="https://stockfishchess.org/">Stockfish</a>, the top performing program since 2020 is <em>not</em> an example of a, “general method that leverages computation.”</strong></p>

<p><a href="https://yellow-apartment-148.notion.site/AI-Search-The-Bitter-er-Lesson-44c11acd27294f4495c3de778cd09c8d">Aidan McLaughlin explains</a>:</p>

<blockquote>
  <p>Stockfish always had clever search algorithms, but in 2019, its ability to grind out billions of positions didn’t matter because its understanding of each position was kneecapped by human creators. To fix this, the Stockfish team heisted Leela’s deep learning techniques and trained a model hundreds of times smaller than the top Leela model.</p>
</blockquote>

<blockquote>
  <p>After they trained their tiny model, they threw it into their search pipeline, and Stockfish crushed Leela overnight. The Stockfish team utterly rejected scaling laws. They went backward and made a smaller model. But, because their search algorithm was more efficient, took better advantage of hardware, and saw further, they won.</p>
</blockquote>

<p><a href="https://en.wikipedia.org/wiki/Leela_Chess_Zero">Leela</a> is a deep learning model that, “started with no intrinsic chess-specific knowledge other than the basic rules of the game.” It learned by playing chess, at an absurd scale, until it was the best in the world. A true example of the bitter lesson.</p>

<p>Then Stockfish adopted a small, purpose-built search model inside its conventional chess program. Today, Stockfish remains unbeaten – and can run on your iPhone. By not embracing compute as the primary lever, the Stockfish team not only delivered quality, but delivered something everyone can use, often.</p>

<p>We’re starting to see hints that this pattern might be coming for our best AI benchmarks. <a href="https://arcprize.org/">ARC-AGI-1</a>, a highly-respected reasoning benchmark, saw its first breakout high score from OpenAI’s o3, <a href="https://www.dbreunig.com/2024/12/20/the-new-game-in-town.html">last December</a>. This score supported the compute component of the bitter lesson: OpenAI reportedly spent ~$30,000 <em>per task</em> to achieve this milestone. Since this score, ARC has added a “cost per task” metric to their leaderboard, and made efficiency a requirement for their grand prize.</p>

<p>But 3 weeks ago, <a href="https://sapient.inc/">Sapient</a> published a “<a href="https://arxiv.org/pdf/2506.21734">Hierarchical Reasoning Model</a>” (HRM), that achieves a 40.3 score on ARC-AGI-1 with only <em>27 million parameters</em> – besting large models like o3-mini-high and Claude 3.7. (As a reminder, LLM model parameter counts are measured in the billions.) HRM achieves this feat<sup id="fnref:sapient" role="doc-noteref"><a href="#fn:sapient" rel="footnote">3</a></sup> with a handful of new techniques, but also each model is trained for only a specific task: the model that scored highly on ARC was trained on 1,000 ARC problems. It’s not built for general use.</p>

<p>A model like HRM could likely run on your phone, just like Stockfish. These aren’t general purpose programs, and they’re not excelling with copious compute. Further, Stockfish is incredibly practical! It can be run basically anywhere (which is actually a growing problem in the online chess scene…) While the bitter lesson did demonstrate new mechanisms for search humans wouldn’t have anticipated, wrapping those in human-knowledge-based rules proves both more performant and practical.</p>

<hr>

<p>The bitter lesson is an <em>incredibly</em> well written essay. And the argument it makes is compelling because of its simplicity.</p>

<p>But like any rule of thumb, it’s imperfect when it meets the real world. I embrace the idea that general methods that leverage computation will lead us to new ideas and techniques. For many domains, once we understand these mechanisms we can apply them in focused, efficient applications.</p>

<p>And of course – this is entirely dependent on our ability to represent our challenges as data. We can easily model chess and annotate images, but modeling workplace dynamics is much harder.</p>

<p>For those building agents and other AI-powered applications today, it’s good to keep in mind the bitter lesson. Consider where <a href="https://www.dbreunig.com/2025/05/27/will-the-model-eat-your-stack.html">the model might eat your stack</a>, but don’t be afraid to thoughtfully apply custom, human-crafted logic or embrace non-general models to get the job done. And remember: compute is a constraint.&nbsp;Don’t let the bitter lesson stand in the way of actually <em>running</em> your tool. Slightly less accuracy at a fraction of the cost is often the best way.</p>

<hr>




  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Native Sparse Attention (129 pts)]]></title>
            <link>https://aclanthology.org/2025.acl-long.1126/</link>
            <guid>44761548</guid>
            <pubDate>Fri, 01 Aug 2025 19:48:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aclanthology.org/2025.acl-long.1126/">https://aclanthology.org/2025.acl-long.1126/</a>, See on <a href="https://news.ycombinator.com/item?id=44761548">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="main-container"><div><p><a href="https://aclanthology.org/people/j/jingyang-yuan/">Jingyang Yuan</a>,
<a href="https://aclanthology.org/people/h/huazuo-gao/">Huazuo Gao</a>,
<a href="https://aclanthology.org/people/d/damai-dai/">Damai Dai</a>,
<a href="https://aclanthology.org/people/j/junyu-luo/">Junyu Luo</a>,
<a href="https://aclanthology.org/people/l/liang-zhao/">Liang Zhao</a>,
<a href="https://aclanthology.org/people/z/zhengyan-zhang/">Zhengyan Zhang</a>,
<a href="https://aclanthology.org/people/z/zhenda-xie/">Zhenda Xie</a>,
<a href="https://aclanthology.org/people/y/yuxing-wei/">Yuxing Wei</a>,
<a href="https://aclanthology.org/people/l/lean-wang/">Lean Wang</a>,
<a href="https://aclanthology.org/people/z/zhiping-xiao/">Zhiping Xiao</a>,
<a href="https://aclanthology.org/people/y/yuqing-wang/">Yuqing Wang</a>,
<a href="https://aclanthology.org/people/c/chong-ruan/">Chong Ruan</a>,
<a href="https://aclanthology.org/people/m/ming-zhang/">Ming Zhang</a>,
<a href="https://aclanthology.org/people/w/wenfeng-liang/">Wenfeng Liang</a>,
<a href="https://aclanthology.org/people/w/wangding-zeng/">Wangding Zeng</a></p></div><hr><div><div><h5>Abstract</h5><p><span>Long-context modeling is crucial for next-generation language models, yet the high computational cost of standard attention mechanisms poses significant computational challenges. Sparse attention offers a promising direction for improving efficiency while maintaining model capabilities. We present NSA, a Natively trained Sparse Attention mechanism that integrates algorithmic innovations with hardware-aligned optimizations to achieve efficient long-context modeling. NSA employs a dynamic hierarchical sparse strategy, combining coarse-grained token compression with fine-grained token selection to preserve both global context awareness and local precision. Our approach advances sparse attention design with two key innovations: (1) We achieve substantial speedups through arithmetic intensity-balanced algorithm design, with implementation optimizations for modern hardware. (2) We enable end-to-end training, reducing pretraining computation without sacrificing model performance. As shown in Figure 1, experiments show the model pretrained with NSA maintains or exceeds Full Attention models across general benchmarks, long-context tasks, and instruction-based reasoning. Meanwhile, NSA achieves substantial speedups over Full Attention on 64k-length sequences across decoding, forward propagation, and backward propagation, validating its efficiency throughout the model lifecycle.</span></p></div><dl><dt>Anthology ID:</dt><dd>2025.acl-long.1126</dd><dt>Volume:</dt><dd><a href="https://aclanthology.org/volumes/2025.acl-long/">Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></dd><dt>Month:</dt><dd>July</dd><dt>Year:</dt><dd>2025</dd><dt>Address:</dt><dd>Vienna, Austria</dd><dt>Editors:</dt><dd><a href="https://aclanthology.org/people/w/wanxiang-che/">Wanxiang Che</a>,
<a href="https://aclanthology.org/people/j/joyce-nabende/">Joyce Nabende</a>,
<a href="https://aclanthology.org/people/e/ekaterina-shutova/">Ekaterina Shutova</a>,
<a href="https://aclanthology.org/people/m/mohammad-taher-pilehvar/">Mohammad Taher Pilehvar</a></dd><dt>Venue:</dt><dd><a href="https://aclanthology.org/venues/acl/">ACL</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>23078–23097</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href="https://aclanthology.org/2025.acl-long.1126/">https://aclanthology.org/2025.acl-long.1126/</a></dd><dt>DOI:</dt><dd></dd><dt>Award:</dt><dd><i></i>&nbsp;Best Paper</dd><dt>Bibkey:</dt><dd></dd><dt>Cite (ACL):</dt><dd><span id="citeACL">Jingyang Yuan, Huazuo Gao, Damai Dai, Junyu Luo, Liang Zhao, Zhengyan Zhang, Zhenda Xie, Yuxing Wei, Lean Wang, Zhiping Xiao, Yuqing Wang, Chong Ruan, Ming Zhang, Wenfeng Liang, and Wangding Zeng. 2025. <a href="https://aclanthology.org/2025.acl-long.1126/">Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention</a>. In <i>Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</i>, pages 23078–23097, Vienna, Austria. Association for Computational Linguistics.</span></dd><dt>Cite (Informal):</dt><dd><span id="citeRichText"><a href="https://aclanthology.org/2025.acl-long.1126/">Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention</a> (Yuan et al., ACL 2025)</span></dd><dt>Copy Citation:</dt><dd>



</dd><dt>PDF:</dt><dd><a href="https://aclanthology.org/2025.acl-long.1126.pdf">https://aclanthology.org/2025.acl-long.1126.pdf</a></dd></dl></div><hr></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Deep Agents (119 pts)]]></title>
            <link>https://blog.langchain.com/deep-agents/</link>
            <guid>44761299</guid>
            <pubDate>Fri, 01 Aug 2025 19:28:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.langchain.com/deep-agents/">https://blog.langchain.com/deep-agents/</a>, See on <a href="https://news.ycombinator.com/item?id=44761299">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

        

        <main id="main">
            

<article>

    <header data-layout-grid="custom" data-theme="highlight" data-section="first" data-has-featured-image="true">
        <figure>
            <img width="16" height="9" src="https://blog.langchain.com/content/images/size/w760/format/webp/2025/07/image--1-.jpg" srcset="https://blog.langchain.com/content/images/size/w360/format/webp/2025/07/image--1-.jpg 360w,https://blog.langchain.com/content/images/size/w480/format/webp/2025/07/image--1-.jpg 480w,https://blog.langchain.com/content/images/size/w760/format/webp/2025/07/image--1-.jpg 760w,https://blog.langchain.com/content/images/size/w990/format/webp/2025/07/image--1-.jpg 990w,https://blog.langchain.com/content/images/size/w1248/format/webp/2025/07/image--1-.jpg 1248w,https://blog.langchain.com/content/images/size/w1520/format/webp/2025/07/image--1-.jpg 1520w" sizes="(min-width: 1280px) 580px, (min-width: 1000px) calc(50vw - 60px), 100vw" loading="eager" alt="Deep Agents" onload="this.setAttribute('data-loaded', true)">
        </figure>
        
    </header>

    <div data-canvas-grid="content">
        <div data-canvas-grid="content" data-canvas-grid-self="full">
            <p>Using an LLM to call tools in a loop is the simplest form of an agent. This architecture, however, can yield agents that are “shallow” and fail to plan and act over longer, more complex tasks. Applications like “<a href="https://openai.com/index/introducing-deep-research/?ref=blog.langchain.com">Deep Research</a>”, “<a href="https://manus.im/?ref=blog.langchain.com">Manus</a>”, and “<a href="https://www.anthropic.com/claude-code?ref=blog.langchain.com">Claude Code</a>” have gotten around this limitation by implementing a combination of four things: a planning tool, sub agents, access to a file system, and a detailed prompt.</p><p>Acknowledgements: this exploration was primarily inspired by Claude Code and reports of people using it for <a href="https://x.com/alexalbert__/status/1948765443776544885?ref=blog.langchain.com">more than just coding</a>. What about Claude Code made it general purpose, and could we abstract out and generalize those characteristics?</p><h2 id="deep-agents-in-the-wild">Deep agents in the wild</h2><p>The dominant agent architecture to emerge is also the simplest: running in a loop, calling tools.</p><p>Doing this naively, however, leads to agents that are a bit shallow. “Shallow” here refers to the agents inability to plan over longer time horizons and do more complex tasks.</p><p>Research and coding have emerged as two areas where agents have been created that buck this trend. All of the major model providers have an agent for Deep Research and for “async” coding tasks. Many startups and customers are creating versions of these for their specific vertical.</p><p>I refer to these agents as “deep agents” - for their ability to dive deep on topics. They are generally capable of planning more complex tasks, and then executing over longer time horizons on those goals.</p><p>What makes these agents good at going deep?</p><p>The core algorithm is actually the same - it’s an LLM running in a loop calling tools. The difference compared to the naive agent that is easy to build is:</p><ul><li>A detailed system prompt</li><li>Planning tool</li><li>Sub agents</li><li>File system</li></ul><figure><img src="https://blog.langchain.com/content/images/2025/07/Screenshot-2025-07-30-at-9.08.32-AM.png" alt="" loading="lazy" width="1056" height="460" srcset="https://blog.langchain.com/content/images/size/w600/2025/07/Screenshot-2025-07-30-at-9.08.32-AM.png 600w, https://blog.langchain.com/content/images/size/w1000/2025/07/Screenshot-2025-07-30-at-9.08.32-AM.png 1000w, https://blog.langchain.com/content/images/2025/07/Screenshot-2025-07-30-at-9.08.32-AM.png 1056w" sizes="(min-width: 720px) 720px"></figure><h2 id="characteristics-of-deep-agents">Characteristics of deep agents</h2><p><strong>Detailed system prompt</strong></p><p>Claude Code’s <a href="https://github.com/kn1026/cc/blob/main/claudecode.md?ref=blog.langchain.com">recreated system prompts</a> are long. They contain detailed instructions on how to use tools. They contain examples (few shot prompts) on how to behave in certain situations.</p><p>Claude Code is not an anomaly - most of the best coding or deep research agents have pretty complex system prompts. Without these system prompts, the agents would not be nearly as deep. Prompting matters still!</p><p><strong>Planning tool</strong></p><p>Claude Code uses a <a href="https://claudelog.com/faqs/what-is-todo-list-in-claude-code/?ref=blog.langchain.com">Todo list tool</a>. Funnily enough - this doesn’t do anything! It’s basically a no-op. It’s just context engineering strategy to keep the agent on track.</p><p>Deep agents are better at executing on complex tasks over longer time horizons. Planning (even if done via a no-op tool call) is a big component of that.</p><p><strong>Sub agents</strong></p><p>Claude Code can spawn <a href="https://docs.anthropic.com/en/docs/claude-code/sub-agents?ref=blog.langchain.com">sub agents</a>. This allows it to split up tasks. You can also create custom sub agents to have more control. This allows for <a href="https://x.com/dexhorthy/status/1950288431122436597?ref=blog.langchain.com">"context management and prompt shortcuts"</a>.</p><p>Deep agents go deeper on topics. This is largely accomplished by spinning up sub agents that specifically focused on individual tasks, and allowing those sub agents to go deep there.</p><p><strong>File System</strong></p><p>Claude Code (obviously) has access to the file system and can modify files on there, not just to complete its task but also to jot down notes. It also acts as a shared workspace for all agents (and sub agents) to collaborate on.</p><p>Manus is another example of a deep agent that makes <a href="https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus?ref=blog.langchain.com">significant use</a> of a file system for “memory”.</p><p>Deep agents run for long periods of time and accumulate a lot of context that they need to manage. Having a file system handy to store (and then later read from) is helpful for doing so.</p><h2 id="build-your-deep-agent">Build your deep agent</h2><p>In order to make it easier for everyone to build a deep agent for their specific vertical, I hacked on an open source package (<a href="https://github.com/hwchase17/deepagents?ref=blog.langchain.com" rel="noreferrer"><code>deepagents</code></a>) over the weekend. You can easily install it with <code>pip install deepagents</code> and then read instructions for how to use it <a href="https://github.com/hwchase17/deepagents?ref=blog.langchain.com" rel="noreferrer">here</a>.</p><p>This package attempts to create a general purpose deep agent that can be customized to create your own custom version.</p><p>It comes with built-in components mapping to the above characteristics:</p><ul><li>A system prompt inspired by Claude Code, but modified to be more general</li><li>A no-op Todo list planning tool (same as Claude Code)</li><li>Ability to spawn sub-agents, and specify your own</li><li>A mocked out “virtual file system” that uses the agents state (a preexisting LangGraph concept)</li></ul><p>You can easily create your own deep agent by passing in a custom prompt (will be inserted into the larger system prompt as custom instructions), custom tools, and custom subagents. We put together a simple example of a <a href="https://github.com/hwchase17/deepagents/tree/master/examples/research?ref=blog.langchain.com">"deep research" agent</a> built on top of <code>deepagents</code>.</p><p><a href="https://github.com/hwchase17/deepagents?ref=blog.langchain.com"><strong>TRY OUT <code>deepagents</code> HERE</strong></a></p>
        </div>

        <div>
            <h3>Tags</h3>
            
        </div>



        <div data-theme="highlight">
            <h3>Join our newsletter</h3>
            <p>Updates from the LangChain team and community</p>
            <form data-members-form="signup" data-theme="reset">
                <p><label for="newsletter-box-email-input">Enter your email</label>
                    
                    
                </p>
                <p data-message="loading">Processing your application...</p>
                <p data-message="success">Success! Please check your inbox and click the link to confirm your subscription.</p>
                <p data-message="error">Sorry, something went wrong. Please try again.</p>
            </form>
        </div>
    </div>

    

</article>


        </main>

        

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Atlassian terminates 150 staff with pre-recorded video (213 pts)]]></title>
            <link>https://www.cyberdaily.au/digital-transformation/12441-atlassian-terminates-150-staff-with-pre-recorded-video-will-be-largely-replaced-by-ai</link>
            <guid>44761205</guid>
            <pubDate>Fri, 01 Aug 2025 19:21:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cyberdaily.au/digital-transformation/12441-atlassian-terminates-150-staff-with-pre-recorded-video-will-be-largely-replaced-by-ai">https://www.cyberdaily.au/digital-transformation/12441-atlassian-terminates-150-staff-with-pre-recorded-video-will-be-largely-replaced-by-ai</a>, See on <a href="https://news.ycombinator.com/item?id=44761205">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><span>Major Australian tech company Atlassian has terminated 150 staff with a pre-recorded video, as the company pushes its AI-embedded customer contact solutions.</span></p><div>
                    
<p dir="ltr"><span>Atlassian CEO and co-founder Mike Cannon-Brookes sent the video titled “Restructuring the CSS Team: A Difficult Decision for Our Future” to staff on Wednesday morning (30 July), informing them that 150 staff had been made redundant. The video reportedly did not make it seem that the decision was difficult, but rather said it would allow its staff “to say goodbye”.</span></p>
<p dir="ltr"><span>The video itself did not announce who was leaving, but it told employees they would have to wait 15 minutes for an email about their employment. Those who were terminated had their laptops blocked immediately. They reportedly will receive six months’ pay.</span></p>
<div id="freeMembershipOverlay">
    <p>
        You’re out of free articles for this month    </p>

    <div id="contentLogin">
            <p>
                To continue reading the rest of this article, please log in.            </p>

            
        </div>
</div>

<section>
<p dir="ltr"><span>Atlassian has always set itself as a company that doesn’t mince words and is majorly transparent, displaying the core value “Open Company, No Bullshit” in its offices around the world.</span></p>
<p dir="ltr"><span>While not specifically outlined, the affected staff seem to be from the company’s European operations, with </span><em>The Australian</em><span><em> </em>saying that Cannon-Brooke’s overshared that it would be difficult to axe its European staff due to contract arrangements, but that the company had already begun moving in that direction.</span></p>
<p dir="ltr"><span>The company has also embedded AI in its customer contact form.</span></p>
    





<p dir="ltr"><span>Former co-CEO and co-founder Scott Farquhar, at the same time, has said that embracing AI on a daily basis is something Australians should be doing.</span></p>
<p dir="ltr"><span>“AI is going to change Australia,” he told t</span><span>he ABC.</span></p>
<p dir="ltr"><span>“Every person should be using AI daily for as many things as they can.”</span></p>
    






<p dir="ltr"><span>“Like any new technology, it will feel awkward to start with, but every business person, every business leader, every government leader, and every bureaucrat should be using it.”</span></p>
<p dir="ltr"><span>He also said that governments should be implementing AI more broadly.</span></p>
<p dir="ltr"><span>Staff believe that Farquhar, who announced his resignation as co-CEO of Atlassian in April 2024 before stepping down in September, would have been more gentle in delivering the termination message.</span></p>
<p dir="ltr"><span>“[Cannon-Brookes] is the colder person out of the couple,” said one person who saw the pre-recorded video, according to </span><em>The Australian</em><span>.</span></p>
<p dir="ltr"><span>“[Farquhar] was the warmer one.”</span></p>
<p dir="ltr"><span>Commenting on the termination, Farquhar said the mass termination was due to the customer service team no longer being needed in the same capacity, as larger clients required less complex support following a move to the cloud.</span></p>
<p dir="ltr"><span>Cyber Daily has reached out to Atlassian for confirmation that no Australian staff were impacted and for comment on the incident.</span></p>
<p dir="ltr"><span>Atlassian closely follows </span><a href="https://www.cyberdaily.au/digital-transformation/12434-cba-cuts-at-least-45-jobs-to-make-room-for-ai-unions-furious" target="_blank" rel="noopener"><span>Commonwealth Bank</span></a><span> (CBA), which culled at least 45 jobs as it makes room for AI.</span></p>
<p dir="ltr"><span>The country’s largest bank said it would be making at least 45 roles redundant in the wake of its push to use AI, and only a month after it announced that it had launched a new customer assistance AI voice bot system.</span></p>
<p dir="ltr"><span>“Our investment in technology, including AI, is making it easier and faster for customers to get help, especially in our call centres,” a CBA spokesman said regarding the voice bot.</span></p>
<p dir="ltr"><span>“By automating simple queries, our teams can focus on more complex customer queries that need empathy and experience.</span></p>
<p dir="ltr"><span>“To meet the changing needs of our customers ... we review the skills we need and how we’re organised to deliver the best customer experiences and outcomes. That means some roles and work can change.”</span></p>
<hr>
<p dir="ltr"><em>Updated 31/07/25 - Atlassian says the jobs are not being replaced by AI, but that it has embedded AI in its customer service. Updated to remove claims of AI replacing jobs.</em></p></section>
        <div>
            <div>
            <p><img loading="lazy" src="https://res.cloudinary.com/momentum-media-group-pty-ltd/image/upload/v1696559412/Cyber%20Security/Podcast/daniel-croft.jpg" alt="Daniel Croft" width="170" height="170">
            </p>
        </div>
    
    <div>
        <h3>
                            <a href="https://www.cyberdaily.au/authors/daniel-croft" title="About View all articles from Daniel Croft">
                        Daniel Croft                            </a>
                    </h3>

                    <div>
                                    <p>Born in the heart of Western Sydney, Daniel Croft is a passionate journalist with an understanding for and experience writing in the technology space. Having studied at Macquarie University, he joined Momentum Media in 2022, writing across a number of publications including Australian Aviation, Cyber Security Connect and Defence Connect. Outside of writing, Daniel has a keen interest in music, and spends his time playing in bands around Sydney.</p>                                            </div>
        
                    
            </div>
</div>
    




                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bad UX (109 pts)]]></title>
            <link>https://www.google.com/search?q=bad+UX</link>
            <guid>44760821</guid>
            <pubDate>Fri, 01 Aug 2025 18:48:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.google.com/search?q=bad+UX">https://www.google.com/search?q=bad+UX</a>, See on <a href="https://news.ycombinator.com/item?id=44760821">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Tesla must pay $329M in damages in fatal Autopilot case, jury says (198 pts)]]></title>
            <link>https://www.cnbc.com/2025/08/01/tesla-must-pay-329-million-in-damages-in-fatal-autopilot-case.html</link>
            <guid>44760573</guid>
            <pubDate>Fri, 01 Aug 2025 18:28:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2025/08/01/tesla-must-pay-329-million-in-damages-in-fatal-autopilot-case.html">https://www.cnbc.com/2025/08/01/tesla-must-pay-329-million-in-damages-in-fatal-autopilot-case.html</a>, See on <a href="https://news.ycombinator.com/item?id=44760573">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-108176751" data-test="InlineImage"><p>Tesla vehicles are parked outside of a dealership on July 24, 2025 in Austin, Texas. </p><p>Brandon Bell | Getty Images</p></div><div><p>A jury in Miami has determined that <a href="https://www.cnbc.com/quotes/TSLA/">Tesla</a>&nbsp;should be held partly liable for a fatal 2019 Autopilot crash, and must compensate the family of the deceased and an injured survivor damages of $329 million.</p><p>The payout includes $129 million in compensatory damages, and $200 million in punitive damages against Tesla. Attorneys for the plaintiffs had asked the jury to award damages of around $345 million. The trial in the Southern District of Florida started on July 14.</p><p>The suit centered around who shouldered the blame for the deadly crash in Key Largo, Florida. A Tesla owner named George McGee was driving his Model S electric sedan while using the company's Enhanced Autopilot, a partially automated driving system.</p><p>While driving, McGee dropped his mobile phone that he was using and scrambled to pick it up. He said during the trial that he believed Enhanced Autopilot would brake if an obstacle was in the way. His Model S accelerated through an intersection at just over 60 miles per hour, hitting a nearby empty parked car and its owners, who were standing on the other side of their vehicle.</p><p>Naibel Benavides, who was 22, died on the scene from injuries sustained in the crash. Her body was discovered about 75 feet away from the point of impact. Her boyfriend, Dillon Angulo, survived but suffered multiple broken bones, a traumatic brain injury and psychological effects.</p><p>"Tesla designed Autopilot only for controlled access highways yet deliberately chose not to restrict drivers from using it elsewhere, alongside <a href="https://www.cnbc.com/elon-musk/">Elon Musk</a> telling the world Autopilot drove better than humans," Brett Schreiber, counsel for the plaintiffs, said in an e-mailed statement on Friday. "Tesla's lies turned our roads into test tracks for their fundamentally flawed technology, putting everyday Americans like Naibel Benavides and Dillon Angulo in harm's way."</p><p>Following the verdict, the plaintiffs' families hugged each other and their lawyers, and Angulo was "visibly emotional" as he embraced his mother, <a href="https://www.nbcnews.com/news/us-news/tesla-autopilot-crash-trial-verdict-partly-liable-rcna222344" target="_blank">according to NBC</a>. </p><p>Tesla told NBC that it plans to appeal and said, "Today's verdict is wrong and only works to set back automotive safety and jeopardize Tesla's and the entire industry's efforts to develop and implement life-saving technology."</p><p>The verdict comes as Musk, Tesla's CEO, is trying to persuade investors that his company can pivot into a leader in autonomous vehicles, and that its self-driving systems are safe enough to operate fleets of robotaxis on public roads in the U.S.</p><p>Tesla shares dipped 1.5% on Friday and are now down 25% for the year, the biggest drop among tech's megacap companies.</p><p>The verdict could set a precedent for Autopilot-related suits against Tesla. About a dozen active cases are underway focused on similar claims involving incidents where Autopilot or Tesla's FSD— Full Self-Driving (Supervised) — had been in use just before a fatal or injurious crash. </p><p>The National Highway Traffic Safety Administration <a href="https://www.cnbc.com/2023/12/13/tesla-software-fix-rolls-out-after-regulators-recall-2-million-cars-over-autopilot-defect.html">initiated</a>&nbsp;a probe in 2021 into possible safety defects in Tesla's Autopilot systems. During the course of that investigation, Tesla made changes, including a number of over-the-air software updates.</p><p>The agency then opened a second probe, which is ongoing,&nbsp;<a href="https://www.cnbc.com/2024/05/07/tesla-must-provide-nhtsa-with-autopilot-recall-data-or-face-fines.html">evaluating</a>&nbsp;whether Tesla's "recall remedy" to resolve issues with the behavior of its Autopilot, especially around stationary first responder vehicles, had been effective.</p><p>The NHTSA has&nbsp;<a href="https://www.cnbc.com/2024/11/08/tesla-social-media-posts-falsely-say-cars-are-robotaxis-nhtsa-warns.html">also warned&nbsp;Tesla</a>&nbsp;that its social media posts may mislead drivers into thinking its cars are capable of functioning as robotaxis, even though owners manuals say the cars require hands-on steering and a driver attentive to steering and braking at all times.</p><p>A site that tracks Tesla-involved collisions, <a href="https://www.tesladeaths.com/" target="_blank">TeslaDeaths.com</a>, has reported at least 58 deaths resulting from incidents where Tesla drivers had Autopilot engaged just before impact.</p><p><strong>WATCH:</strong> <a href="https://www.cnbc.com/video/2025/07/24/ex-tesla-board-member-tough-quarter-for-the-ev-maker.html">Tesla's tough quarter</a></p></div><div id="Placeholder-ArticleBody-Video-108176215" data-test="VideoPlaceHolder" role="region" tabindex="0" data-vilynx-id="7000383327" aria-labelledby="Placeholder-ArticleBody-Video-108176215"><p><img src="https://image.cnbcfm.com/api/v1/image/108176216-17533473381753347335-40867300248-1080pnbcnews.jpg?v=1753347337&amp;w=750&amp;h=422&amp;vtcrop=y" alt="Ex-Tesla Board Member: Tough quarter for the EV-maker"><span></span><span></span></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Self-Signed JWTs (113 pts)]]></title>
            <link>https://www.selfref.com/self-signed-jwts</link>
            <guid>44760561</guid>
            <pubDate>Fri, 01 Aug 2025 18:27:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.selfref.com/self-signed-jwts">https://www.selfref.com/self-signed-jwts</a>, See on <a href="https://news.ycombinator.com/item?id=44760561">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p>Get a load of this (totally normalized) BS.</p>
<div><p>
"We have just the offering for you! 
</p><p>Visit our website. Create an account. Verify your email. Create a project. Add your credit card. Go to settings. Create an API key. Add it to your password manager. Drop it in your .env file. Download our SDK. Import it. Pass your env var in. Never share your API key. Make sure you never commit it to source control.</p>
<p>On the client, we have a React SDK. Make sure you use your publishable key for that. For the server, download our admin SDK. Use your secret key. Never mix the two up.”</p>
</div>
<p>It’s truly wild to me what some of y’all will tolerate.</p>
<h3 id="making-your-own-api-key">Making your own API key</h3>
<p>Let me show you something… Did you know generating a JWK is stupidly easy?</p>
<pre tabindex="0" data-language="ts"><code><span><span>import</span><span> { generateKeyPair, exportJWK } </span><span>from</span><span> 'jose'</span></span>
<span></span>
<span><span>const</span><span> keyPair</span><span> =</span><span> await</span><span> generateKeyPair</span><span>(</span><span>'ES256'</span><span>, {</span></span>
<span><span>  extractable: </span><span>true</span><span>,</span></span>
<span><span>})</span></span>
<span><span>const</span><span> publicKeyJWK</span><span> =</span><span> await</span><span> exportJWK</span><span>(keyPair.publicKey)</span></span>
<span><span>const</span><span> privateKeyJWK</span><span> =</span><span> await</span><span> exportJWK</span><span>(keyPair.privateKey)</span></span></code></pre>
<p>That’s it. Your JWK keypair is now effectively your own self-issued API key.</p>
<p>No need to visit a website, make an account, verify your email, create a project, go to settings, create an API key, or copy it and use it. You just generated your own.</p>
<h3 id="how-do-we-use-this">How do we use this?</h3>
<p>Let’s see how we can get rid of secret versus publishable keys and separate client and admin SDKs.</p>
<p>Who cares whether you’re on the client or server? If your app wants to authorize a privileged action, it should be able to do so without separate keys or SDKs.</p>
<p>Here’s how to implement this:</p>
<ol>
<li>Store your app’s private JWK on the server</li>
<li>Using whatever auth scheme you have, implement a function that returns whether to allow a given action</li>
<li>Express privileged actions as claims in your JWT—if a privileged action is allowed, include the claim in the payload and sign the JWT with your private key</li>
<li>Give your client SDK a function that reverse-proxies to your API, adding a signed JWT to the request’s Authorization header with any privileged claims you want to include</li>
</ol>
<p>Here’s what the client-side JWT generation looks like:</p>
<pre tabindex="0" data-language="ts"><code><span><span>import</span><span> { SignJWT } </span><span>from</span><span> 'jose'</span></span>
<span></span>
<span><span>const</span><span> jwt</span><span> =</span><span> await</span><span> new</span><span> SignJWT</span><span>({</span></span>
<span><span>  // Clients shouldn't be able to destroy the database</span></span>
<span><span>  // unless the action is allowed, so this is a claim</span></span>
<span><span>  destroyDatabase: </span><span>true</span><span>,</span></span>
<span><span>})</span></span>
<span><span>// Include the public key in the JWT header so the server </span></span>
<span><span>// can verify the signature and associate the request</span></span>
<span><span>// with your account</span></span>
<span><span>.</span><span>setProtectedHeader</span><span>({ alg: </span><span>'ES256'</span><span>, jwk: publicKeyJWK })</span></span>
<span><span>.</span><span>sign</span><span>(privateKeyJWK);</span></span></code></pre>
<h3 id="charging-for-your-api">Charging for your API</h3>
<p>But what if you want to charge for your API?</p>
<p>Simple: make your API return a payment URL when a request is made with a public key that isn’t associated with a paid account.</p>
<p>Your client SDK can present this to the developer (for example, by logging it to the console).</p>
<p>After the developer pays, associate their public key with the paid account in your database and stop returning payment URLs for future requests from that key.</p>
<h3 id="b2b2c">B2B2C</h3>
<p>What about situations where your customers are developers who want to give <em>their</em> end users API keys?</p>
<p>This is where you need to deviate from JOSE standards.</p>
<p>One approach is hierarchical JWK derivation. Here’s the idea:</p>
<ol>
<li>Your developer customers create a master JWK</li>
<li>They derive child JWKs for each of their end users from that master key</li>
<li>You modify the JWT scheme to include a zero-knowledge proof that the end user’s key is derived from the developer’s master public key</li>
</ol>
<p>This way, you can verify that an end user is authorized by a specific developer without the developer having to manage API keys for their users.</p>
<p>I don’t have a ready-made example of this, but the concept is solid. If you want to explore this further, hit me up on <a href="https://x.com/danscan">Twitter</a> and I’ll help you out.</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google shifts goo.gl policy: Inactive links deactivated, active links preserved (241 pts)]]></title>
            <link>https://blog.google/technology/developers/googl-link-shortening-update/</link>
            <guid>44759918</guid>
            <pubDate>Fri, 01 Aug 2025 17:43:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.google/technology/developers/googl-link-shortening-update/">https://blog.google/technology/developers/googl-link-shortening-update/</a>, See on <a href="https://news.ycombinator.com/item?id=44759918">Hacker News</a></p>
<div id="readability-page-1" class="page"><div slot="uni-short-post-description-slot" data-title="We’re updating our plans for goo.gl links." author="" author-job-title="" author-url="" date="Aug 01, 2025" url="https://blog.google/technology/developers/googl-link-shortening-update/"><p data-block-key="1ag8i">While we <a href="https://developers.googleblog.com/en/google-url-shortener-links-will-no-longer-be-available/">previously announced</a> discontinuing support for all goo.gl URLs after August 25, 2025, we've adjusted our approach in order to preserve actively used links.</p><p data-block-key="e2lct">We understand these links are embedded in countless documents, videos, posts and more, and we appreciate the input received.</p><p data-block-key="es6v2">Nine months ago, we redirected URLs that showed no activity in late 2024 to a message specifying that the link would be deactivated in August, and these are the only links targeted to be deactivated. If you get a message that states, “This link will no longer work in the near future”, the link won't work after August 25 and we recommend transitioning to another URL shortener if you haven’t already.</p><p data-block-key="a7vup">All other goo.gl links will be preserved and will continue to function as normal. To check if your link will be retained, visit the link today. If your link redirects you without a message, it will continue to work.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I couldn't submit a PR, so I got hired and fixed it myself (297 pts)]]></title>
            <link>https://www.skeptrune.com/posts/doing-the-little-things/</link>
            <guid>44759417</guid>
            <pubDate>Fri, 01 Aug 2025 16:59:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.skeptrune.com/posts/doing-the-little-things/">https://www.skeptrune.com/posts/doing-the-little-things/</a>, See on <a href="https://news.ycombinator.com/item?id=44759417">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-astro-cid-g44mhg6z="">  <article> <p> July 30, 2025 , Nicholas Khami </p>     <p>For over a year, I was bugged by a search quirk on <a href="https://mintlify.com/">Mintlify</a> that caused race conditions and wonky search results.</p>
<p>Here’s the fun irony: I was the founder of Trieve, the company that powered search for their 30,000+ documentation sites, yet their debounced search queries weren’t being aborted as you typed. Check out this delightful chaos:</p>

<p>I had brought this up in our shared Slack before when I was just a vendor to <del>them</del> <strong>us</strong> (weird), but it wasn’t a priority and never got fixed. It was extra frustrating because the race condition on the query was apparent enough that search would sometimes feel low quality since it would return results for a query many characters before the user was done typing.</p>
<p>Even worse, as the founder of the search company powering this experience, it felt like a poor reflection on Trieve every time someone encountered these wonky results.</p>
<h2 id="fixed-it">Fixed It</h2>
<p>Now that I’m on the team, I was able to finally fix it. I added an <a href="https://developer.mozilla.org/en-US/docs/Web/API/AbortController">AbortController</a> to the debounced search function, so that it aborts any previous queries when a new one is made. This means that the search results are always relevant to what the user is currently typing.</p>
<p>There’s something deeply satisfying about finally being able to fix the things that bug you. It reminds me of George Hotz’s legendary <a href="https://web.archive.org/web/20221122050324/https://twitter.com/realGeorgeHotz/status/1594908473875173377">single week at Twitter</a> in 2022, where he boldly joined with perhaps overambitious plans to fix Twitter search, got humbled by the complexity, but still managed to ship a useful login popup fix before his characteristically dramatic exit. Classic hacker hubris meeting reality, but still getting something done.</p>
<p>I’ve always admired engineers who are part hacker, part entrepreneur - people who see a problem and just… fix it. Getting to do something similar here (minus the dramatic exit) felt like a small win in steering my career toward that kind of direct approach.</p>
<h2 id="open-source">Open Source</h2>
<p>I prefer building and using open source software whenever possible, and this whole situation is a great example of why.</p>
<p>With open source - when you encounter a bug or pain point, you can actually fix it yourself. Had this been an open source project during the year I was frustrated with the search race condition, I could have submitted a pull request with the AbortController fix and saved myself (and thousands of other users) the daily annoyance.</p>
<p>Instead, it remained a persistent irritation until I happened to join the company and gain access to the codebase. There’s something to be said for the immediate empowerment that comes with open source - though I understand why many companies choose different models for various business reasons.</p>
<h2 id="self-congratulation">Self-Congratulation</h2>
<p>If search feels just a bit crisper and more responsive on Mintlify, it’s because of me! I fixed a bug that bothered me for over a year, and it feels great to have made that little improvement to the product.</p>
<p>I can’t wait to make more. Fixing small issues like this over and over again is how products become legendary. There’s something deeply satisfying about finally having the power to fix the things that annoy you - even if they’re tiny.</p>
<p><strong>Especially if they’re tiny.</strong></p> </article>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Corporation for Public Broadcasting Ceasing Operations (588 pts)]]></title>
            <link>https://cpb.org/pressroom/Corporation-Public-Broadcasting-Addresses-Operations-Following-Loss-Federal-Funding</link>
            <guid>44759382</guid>
            <pubDate>Fri, 01 Aug 2025 16:56:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cpb.org/pressroom/Corporation-Public-Broadcasting-Addresses-Operations-Following-Loss-Federal-Funding">https://cpb.org/pressroom/Corporation-Public-Broadcasting-Addresses-Operations-Following-Loss-Federal-Funding</a>, See on <a href="https://news.ycombinator.com/item?id=44759382">Hacker News</a></p>
<div id="readability-page-1" class="page"><div property="content:encoded"><p>
	<span><span><span><b><span>WASHINGTON, D.C.</span></b><span>&nbsp;(August 1, 2025) – The Corporation for Public Broadcasting (CPB) announced today that it will begin an orderly wind-down of its operations following the passage of a federal rescissions package and the release of the Senate Appropriations Committee’s FY 2026 Labor, Health and Human Services, Education, and Related Agencies (Labor-H) appropriations bill, which excludes funding for CPB for the first time in more than five decades.</span></span></span></span></p>

<p>
	<span><span><span><span>For nearly 60 years, CPB has carried out its Congressional mission to build and sustain a trusted public media system that informs, educates, and serves communities across the country. Through partnerships with local stations and producers, CPB has supported educational content, locally relevant journalism, emergency communications, cultural programming, and essential services for Americans in every community.</span></span></span></span></p>

<p>
	<span><span><span><span>“Despite the extraordinary efforts of millions of Americans who called, wrote, and petitioned Congress to preserve federal funding for CPB, we now face the difficult reality of closing our operations,” said CPB President and CEO Patricia Harrison. “CPB remains committed to fulfilling its fiduciary responsibilities and supporting our partners through this transition with transparency and care.”</span></span></span></span></p>

<p>
	<span><span><span><span>CPB informed its employees today that the majority of staff positions will conclude with the close of the fiscal year on September 30, 2025. A small transition team will remain through January 2026 to ensure a responsible and orderly closeout of operations. This team will focus on compliance, final distributions, and resolution of long-term financial obligations, including ensuring continuity for music rights and royalties that remain essential to the public media system.</span></span></span></span></p>

<p>
	<span><span><span><span>“Public media has been one of the most trusted institutions in American life, providing educational opportunity, emergency alerts, civil discourse, and cultural connection to every corner of the country,” Harrison said. “We are deeply grateful to our partners across the system for their resilience, leadership, and unwavering dedication to serving the American people.”</span></span></span></span></p>

<p>
	<span><span><span><span>CPB’s Board of Directors and management are working closely to address the legal, financial, and operational requirements of the closure. CPB will provide regular updates and guidance to stations and producers navigating the profound challenges ahead.</span></span></span></span></p>

<p>
	<span><span><span><b><span>About CPB</span></b><br>
	<span>The Corporation for Public Broadcasting (CPB), a private, nonprofit corporation authorized by Congress in 1967, is the steward of the federal government's investment in public broadcasting. It helps support the operations of more than 1,500 locally managed and operated public television and radio stations nationwide. CPB is also the largest single source of funding for research, technology, and program development for public radio, television, and related online services. For more information, visit <a href="http://www.cpb.org/">www.cpb.org</a> and follow us on <a href="https://www.facebook.com/CorporationForPublicBroadcasting/">Facebook</a>, <a href="https://www.linkedin.com/company/corporation-for-public-broadcasting/">LinkedIn</a>, and <a href="https://cpb.org/subscribe">subscribe</a> for email updates.</span></span></span></span></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ergonomic keyboarding with the Svalboard: a half-year retrospective (112 pts)]]></title>
            <link>https://twey.io/hci/svalboard/</link>
            <guid>44759171</guid>
            <pubDate>Fri, 01 Aug 2025 16:36:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twey.io/hci/svalboard/">https://twey.io/hci/svalboard/</a>, See on <a href="https://news.ycombinator.com/item?id=44759171">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <article>
  <section id="my-background">
  <h2>My background <a href="#my-background">§</a></h2>
  
    <p><span>E</span>ven before I started pressing buttons for a living I was always a
pretty heavy computer user.  When I was about 18 I started
experiencing symptoms of RSI.  At around the same time I learnt of the
Dvorak keyboard layout, and so I switched, hoping it would solve my
problems.  It did, at least at the time, and so for the last 17 years
I’ve been a Dvorak user.</p>


<!--more-->

    <p><span>A</span>t the same time I’m really interested in human/machine interaction
and ways to get the contents of the human brain into a machine as
fluently as possible.  As a combined result of these two factors, I
worked my way through a few different physical keyboards, including
the Microsoft Ergonomic series (which I struggled to make Windows 2000
recognize — go figure) and a Kinesis Advantage, but my keyboard of
choice for many years now has been the
<a href="https://ergodox-ez.com/">Ergodox EZ</a>.  The Ergodox (and its ZSA
comrade the Moonlander) is a solid keyboard, with a few features that
I’ve come to realize are very important:</p>

    <p><strong>Split halves</strong>. Any keyboard with the halves joined together (that is
narrower than shoulder-width, as is the case with every joined
keyboard I’ve seen so far) causes the elbows to bend in and the wrists
to bend out, which seems to be the primary trigger of wrist pain
for me.</p>

    <p><strong>Tenting</strong>. Ditto for the elbows: last year I found myself struggling
with pain and numbness in my arm that, on investigation, matched
symptoms of early cubital tunnel syndrome.  Tenting, rotating the
halves of the keyboard so that the wrists sit in a slight angle,
allows the elbows to rest in a more natural slightly-bent position,
and since adopting it I haven’t had any further problems with my elbow.</p>
<div>
<p><a href="https://www.pricerunner.com/pl/111-3200273096/"><img src="https://twey.io/hci/svalboard/microsoft-ergonomic.jpeg" alt="Picture of a Microsoft Ergonomic, an Alice-style keyboard with slight built-in tenting."></a>
</p>
<p>Figure 1. The Microsoft Ergonomic Keyboard.</p>
</div>

    <p><strong>Thumb clusters</strong>. The first symptom I got was what’s affectionately
known as ‘emacs pinky’. 

<label for="sidenote:1"></label>
<span>In fact, on most keyboards (though sadly no longer on ThinkPads) the control key, positioned in the bottom-right corner, can and should be held with the palm — this makes some combinations more awkward, though no more awkward than with the little finger, and saves the weakest digit.  In fact, I think it would be better named for vi — the escape key is perhaps the least ergonomic key on a standard keyboard.  Some people like to put it in the place of caps-lock, which is of course entirely missing the point.</span> The
reason I picked up the Kinesis Advantage is that on these keyboards
the thumb, which is highly underutilized in standard layouts, gets a
dedicated cluster of keys, perfect for things like modifiers, since
the opposable thumbs don’t limit the motion of the rest of the hand at
all, no matter how it’s engaged.</p>
<div>
<p><a href="https://kinesis-ergo.com/shop/advantage2/"><img src="https://twey.io/hci/svalboard/kinesis-advantage.jpeg" alt="Picture of a Kinesis Advantage, a keyboard with thumb clusters and two separated bowls of matrix-style keys."></a>
</p>
<p>Figure 2. The Kinesis Advantage.  This one is wireless, while mine, the original model, was connected by PS/2 cable.  But the layout hasn’t changed.</p>
</div>

    <p><strong>Programmability</strong>. My customization is light compared to some
people’s, but my keyboard usage is pretty idiosyncratic, so it’s
important to me to be able to customize my keyboard when I need to.
Particularly for keyboards with fewer keys that need heavier layer
usage, I want to be able to set up the layers as I want.  My most
elaborate customization is that I am (from time to time) a hobbyist
<a href="https://en.wikipedia.org/wiki/Stenotype">stenographer</a>, and rather
than having a separate device I find it convenient to be able to
configure my keyboard to speak one of the steno protocols understood
by <a href="https://www.openstenoproject.org/plover/">Plover</a> such as TX
Bolt or GeminiPR.</p>
</section>
<section id="finger-oriented-keyboarding">
  <h2>Finger-oriented keyboarding <a href="#finger-oriented-keyboarding">§</a></h2>
  
    <p><span>W</span>ith this in mind, I was pretty excited when I stumbled across the
<a href="https://www.charachorder.com/">CharaChorder</a>.  The promise is
simple: increase typing speed through a combination of minimizing
finger movement and stenography-style chording (albeit with a theory
designed to have a shallower learning curve, basically just mashing
all the letters of the word at once).  I signed up to the
pre-order, and when I got it I immediately started playing around,
practising a few hours per day on the (very good!) training software.</p>
<div>
<p><a href="https://www.charachorder.com/"><img src="https://twey.io/hci/svalboard/charachorder-one.jpeg" alt="Picture of a CharaChorder One, a radical new keyboard with joysticks instead of keys."></a>
</p>
<p>Figure 3. The CharaChorder One.</p>
</div>

    <p><span>I</span>f you’ve ever done typing training, you’ll know that most of the
point of the drills and forms that they teach you is to keep your
fingers on the home row so that you can reach all the letters with a
minimum of movement.  The CharaChorder turns this on its head: on the
CharaChorder there is <em>only</em> the home row.  Where you would stretch up
or down or sideways to reach a key on a traditional keyboard, on the
CharaChorder you simply wiggle a joystick in that direction, never
taking your finger off the key. 

<label for="sidenote:5"></label>
<span>There is in fact a second row of joysticks used for arrow keys or mouse emulation, but we’ll ignore them for the purposes of this since they don’t impact most of the typing experience.</span></p>

    <p><span>I</span> loved the compact form factor combined with the power of chording,
and I was excited to develop a new steno theory based on the
CharaChorder’s unique structure.  Unfortunately, I was thwarted: the
CC1 runs the CharaChorder OS, a closed-source project with only a
restricted set of chording configurations, and the fact that it must
take place on-device severely limits what can be done compared to the
software-based solutions I was used to.  The CC1 is great for people
who need to travel and connect their device to many different
computers, but that’s not my use-case.  Furthermore ergonomics are
decidedly not a priority for the CharaChorder, with (for example) the
down presses being a chord of each of the cardinal directions, for a
hefty (42 × 4 = 168) grams of force to activate, and some default
chords requiring punishing scissoring and twisting motions that left
my hands very sore after a practice session.  The final straw for me
was that a month or so into using the CC1 one of my joysticks broke,
coming loose in its housing; CC were kind enough to send me a
replacement half, but shortly after that arrived the same thing
happened to a joystick on the remaining half from the first keyboard!


<label for="sidenote:9"></label>
<span>I hear that the build quality has improved significantly on the CC2; please don’t be put off from trying it by this experience of mine!  It remains a really nifty device, especially if you regularly need to transport your keyboard and use it with computers whose software you don’t control, or if you want to <a href="https://www.charachorder.com/en-gb/products/wear-a-chorder">attach the keyboard to your trousers</a>.</span></p>

    <p><span>T</span>hankfully, on the CharaChorder Discord I was introduced to the
<a href="https://svalboard.com/">Svalboard Lightly</a>.</p>
</section>
<section id="the-svalboard-lightly">
  <h2>The Svalboard Lightly <a href="#the-svalboard-lightly">§</a></h2>
  
    <p><span>T</span>he Svalboard, a descendent of the beloved
<a href="https://en.wikipedia.org/wiki/DataHand">DataHand</a>, is based on the
same principles as the CharaChorder: each finger gets a key ‘cluster’
and rather than moving the finger off the key to reach other keys as
in traditional keyboards, the finger stays in its cluster and merely
moves in a direction to press a key — including down, like a standard
keyboard but mostly unlike the CharaChorder, in which the down press
is too awkward to use as part of standard typing.</p>
<div>
<p><a href="https://svalboard.com/products/lightly"><img src="https://twey.io/hci/svalboard/svalboard.jpeg" alt="svalboard"></a>
</p>
<p>Figure 4. The Svalboard Lightly.</p>
</div>

    <p><span>I</span>t throws away the usual mechanical keyboard spring-loaded switches in
favour of something at once simpler and more high-tech: an infrared
source fires a beam at the stem of the key, initially blocked by a
‘flag’ on the keystem, and triggers a keypress when the key is moved
out of the way to allow the beam to hit a detector.  Magnets — actual,
permanent bits of magnetic neodymium — are used to replace the
tactility of traditional switch springs, with pressing the key
requiring breaking the magnets' hold in a rather satisfying way that
feels similar to a traditional buckling spring but requires much less
total force to activate.</p>

    <p><span>T</span>his is in line with its philosophy: apart from the circuitry and the
magnets, everything is 3D-printed to open schematics and held together
with standard screws, ensuring that any piece that’s likely to break
can be replaced, even if the board stops being produced (as happened
to the DataHand).</p>
<section id="the-excellent">
  <h3>The excellent <a href="#the-excellent">§</a></h3>
  
    <p><span>T</span>he Svalboard runs <a href="https://qmk.fm/">QMK</a>, a de-facto standard for
customizable keyboard firmware that I was already used to from the
Ergodox.  Something that was new to me, though, 

<label for="sidenote:13"></label>
<span>ZSA do now provide <a href="https://www.zsa.io/oryx">Oryx</a>, configuration software with a similar purpose; I’d just never tried it!</span> was that the variant
of QMK it uses (by default) is a custom spin of
<a href="https://get.vial.today/">Vial</a>, a fork of QMK enriched with
dynamic layout editing via a GUI editor, or (for the Svalboard) the
excellent <a href="https://captdeaf.github.io/keybard/">Keybard</a>, which
replaces the Vial frontend with a much lighter-weight Web-based
alternative.</p>

    <p><span>I</span>’d never bothered to get set up with a graphical configurator before,
reasoning that I’m perfectly capable of writing a bit of C so I might
as well avail myself of the full power of the firmware, but the
qualitative difference it made, especially as I was still getting used
to the board and ‘dialled in’ to make my everyday tasks comfortable,
was phenomenal.  The ability to open a Web page and tweak a key has
led to a huge number of quality-of-life improvements that I could have
made without it but never did because I didn’t want to interrupt my
workflow to flash my keyboard, and then I promptly forgot about them.</p>

    <p><span>T</span>hat ties neatly into another aspect of the Svalboard I really
appreciate: every part is minutely customizable.  At build time
several options are available for different key sizes and shapes, and
at the time of writing there are three different pointing devices
available which can be swapped out on either side of the Svalboard.
But even after assembly every part of the board that the user’s hand
touches can be shifted, rotated, raised, lowered, or detached entirely
by loosening some screws.  For the first few months I kept a
screwdriver on my desk so I could make small adjustments as I noticed
certain movements were more or less comfortable for me, and the
software allows me to easily tweak my layout to put more common
actions on more easily-reached keys.</p>
</section>
<section id="some-caveats">
  <h3>Some caveats <a href="#some-caveats">§</a></h3>
  
    <p><span>W</span>hile overall I think it’s a fantastic device, it would be remiss of
me to pretend that everything has been plain sailing with the
Svalboard.  I’m very happy with it and it’s now my sole everyday
keyboard.  That said, there are a couple of things that, while far
from deal-breakers for me, definitely bear thinking about, and if you
have the chance to test-drive a Svalboard you should pay attention to.</p>

    <p><span>F</span>irst, and most definitely least, I’ve had a couple of minor
build-quality incidents.  Notably, the magnets that hold the keys in
place have escaped from their plastic housing three or four times
during my ownership of my Sval.  Thankfully, in sharp contrast to the
CharaChorder, the hackable nature of the Svalboard makes this pretty
easy to fix: some superglue and a steady hand has them better than new
in a couple of minutes.  But it’s never nice to have to stop work to
re-glue my keyboard.  Of course the Svalboard is also available as a
kit for 3D printing around, so potentially I should have built it
myself and then I wouldn’t have anyone else to blame!</p>

    <p><span>T</span>hen, there’s the matter of the price.  A premium mechanical keyboard
like the ZSA Moonlander will typically set you back up to around
USD$400.  But the Svalboard comes in at easily twice that and even
higher depending on respective configurations.  For me, so far, the
device is well worth the investment, but your mileage may vary.  If
you have some spare time and access to a 3D printer, the kit option is
significantly cheaper, and seems like it could be fun.</p>

    <p><span>T</span>he Svalboard demands correct configuration, and can be very
uncomfortable to use until arranged right.  Being able to comfortably
and consistently press the keys is, in my experience, very much a
function of how well set up the keyboard is, and so if you have a
setup where it or you will be moving around a lot, you’ll find
yourself spending a lot of time repositioning and reconfiguring the
keyboard.  I strongly suggest looking into a chair-mounted solution,
which lets the keyboard remain statically positioned with respect to
your body and arms.  Relatedly, its many moving parts make it
infeasible to transport around easily; Morgan sells a blessed travel
case, but it’s a chunky thing, and doesn’t lend itself to throwing in
a backpack, nor (due to its positioning sensitivity) would I really
want to use a Svalboard on the go on a train or aeroplane.  Likewise,
the optical keypress sensors require active infrared beams, meaning
they’re too power-hungry for cable-free usage.</p>

    <p><span>I</span>t’s punishing to sloppy typing too.  For those of us used to
hammering away at slab keyboards all day, the lightness of the keys
can make it feel like the keyboard is on a hair trigger.  I often find
myself making typos that wouldn’t have happened on a traditional
board, because between having the impulse to press the key, moving my
finger over to where the key is, and exerting the requisite force to
register a keystroke, I have plenty of time to reconsider my actions.
With the Svalboard, it can feel like I type the letter before I decide
to, and then I’m left to clean up the resulting mess!  I think this is
significantly a matter of practice, and I’ve definitely seen it get
better as I become more accustomed to the board, but it’s something I
still fight with six months in.</p>

    <p><span>F</span>inally, in balance to its many advantages, there is one straight-up
disadvantage to the Svalboard (and other DataHand-like layouts)
compared to a slab keyboard when it comes to typing, and that’s repeat
keypresses.  Whereas with a traditional keyboard a repeat keypress
involves making a potentially awkward movement to the desired key and
then making several simple pressing motions, for the Svalboard
repeating a key involves repeating the stretching/curling motion for
every press, which can be much more difficult than just repeating the
press.  This is most evident in games that need you to hammer a
particular key several times in quick succession, but can also be seen
when typing words with certain double letters.  There are workarounds
available for this, though:</p>
<div>
<ul>
<li>
<p>First, not all keys suffer from this problem: at least the centre
keys of each cluster are at least as easy to hammer as on a
traditional keyboard, if not even easier due to their super-light
switches.  I also find the inward and downward presses easy enough
to repeat.  If you can keep keycodes that need repeating on those
keys that are comfortable to repeat, you’ll have no problem.</p>
</li>
<li>
<p>Alternatively, as a more general solution, QMK supports binding a
‘repeat’ key that can be used to repeat the previous keypress.  If
you bind that key to an easily-repeatable key you can use it to
comfortably repeat any key on the keyboard.  I’ve tried this a
couple of times, but the combination of sacrificing a prime key with
the mental overhead make it not worth it for me, compared to
rearranging the keys that need to be repeated.</p>
</li>
</ul>
</div>
</section>
</section>
<section id="my-svalboard-setup">
  <h2>My Svalboard setup <a href="#my-svalboard-setup">§</a></h2>
  
    <p><span>T</span>he above is my take on the Svalboard as a device; you can find many
other reviews online, some of them in much greater depth, but these
are the things I’ve noticed about it in my first half-year.  The
remainder of this article is about how I have my Svalboard set up, and
how I use it day-to-day.</p>
<section id="mounting">
  <h3>Mounting <a href="#mounting">§</a></h3>
  
    <p><span>I</span> have my Svalboard on a chair mount, simply attached to my chair arms
with some <a href="https://www.smallrig.com/list/Magic-Arm.html">SmallRig
Magic Arms</a>.  I experimented with on-desk and under-desk mounting, but
I found I tend to move my chair too much with respect to the keyboard,
which puts me into poor typing position and messes up my typing for a
bit before I figure out what the problem is and adjust back.  By
contrast, having the Svalboard mounted to a chair means my arms, so
long as I keep them on the arm rests, are always positioned the same
way on the Svalboard, and the only thing I have to worry about is my
cats using the cables as chew-toys. 

<label for="sidenote:17"></label>
<span>Magnetic cable attachments mean that if a cat decides to dangle from your cables by the teeth the cable detaches, resulting in minor inconvenience and maybe a damaged cable rather than a thousand-dollar keyboard being forcibly ripped from its housing and dropped onto the floor.  I settled on <a href="https://www.amazon.co.uk/leizhan-magnetic-connection-charging-transfer-Dark-Gray/dp/B0DRVD9Y3W">these units</a> because they swivel vertically, but they’re all pretty interchangeable.</span></p>
<div>
<p><a href="https://twey.io/hci/svalboard/ethel.jpeg"><img src="https://twey.io/hci/svalboard/ethel.jpeg" alt="A picture of Ethel, a particularly cute tortoise-shell maine coon kitten, looking feral while chewing on an Ethernet cable."></a>
</p>
<p>Figure 5. The Cable-Destroyer General, caught red-pawed.</p>
</div>
</section>
<section id="base-layout-and-learning-to-type-again">
  <h3>Base layout and learning to type again <a href="#base-layout-and-learning-to-type-again">§</a></h3>
  
    <p><a href="https://github.com/Twey/svalboard-layout">My Svalboard layout is
available on GitHub</a> in Keybard format, along with some documentation
that is sometimes in-date.</p>

    <p><span>W</span>hen I learnt Dvorak I learnt to touch-type properly for the first
time, and for whatever reason I’ve managed to almost fully maintain my
<abbr>QWERTY</abbr> hunt-and-peck skills, with only a brief adjustment peried when
faced with a <abbr>QWERTY</abbr> keyboard before I can begin typing at a reasonable
speed.  So, I reasoned, given that the Svalboard is physically quite
different from the flat keyboards on which I normally type Dvorak, if
I pick a base layout that’s sufficiently different to Dvorak anyway it
and my Dvorak muscle memory won’t interfere with each other and I’ll
keep both intact.  And, since I’m learning a drastically different
physical keyboard layout anyway, it won’t slow me down much.  So I
picked
<a href="https://www.reddit.com/r/KeyboardLayouts/comments/1g66ivi/hands_down_promethium_snth_meets_hd_silverengram/">Hands
Down Promethium</a>, which was recommended to me for split keyboards,
adapted to the Svalboard by <a href="https://github.com/ilc">Ira Cooper</a>.</p>

    <p><span>T</span>his was a mistake.</p>

    <p><span>I</span>n fact, HDPm and Dvorak interfere with each other constantly, and I
find myself making typos from one whenever I’m using the other.  Six
months later I’m up to about 80 WPM on the Svalboard now from my ~120
on Dvorak, but given the amount of interference from my Dvorak muscle
memory I can only assume I’d be at full speed by now if I’d used an
adapted Dvorak, and my flat-keyboard Dvorak would not have suffered as
it now does.  Particularly, since the home rows are roughly mirror
images of each other, I frequently press with the right finger on the
wrong hand.  Perhaps it would have been easier if I’d mirrored the
layout, but it’s too late now.</p>
<div>
<p><a href="https://twey.io/hci/svalboard/layout-default.png"><img src="https://twey.io/hci/svalboard/layout-default.png" alt="A screenshot of my base layout in Keybard."></a>
</p>
<p>Figure 6. My base layout, derived from Hands Down Promethium.</p>
</div>

    <p><span>N</span>evertheless, I’ve found picking up a new keyboard layout as an adult
to be a pretty educational endeavour.  There’s a symbiosis with the
Svalboard that rewards mindfulness: I will do a couple of rounds of
<a href="https://monkeytype.com/">monkeytype</a>, realize that I’m
consistently making a particular error because my keyboard is
misconfigured in some way, get out the screwdriver and fiddle with it,
then continue.  But doing that requires a certain level of conscious
introspection to determine what typos are due to keyboard
misconfigurations vs brain slips vs physical mishaps (which
occasionally happen randomly!).  It’s an almost meditative state.</p>

    <p><span>T</span>he main adaptation from HDPm is a vertical mirroring.  This is
because, at least for me, the Svalboard’s north keys are much harder
to hit than its south keys, even though on slab keyboards conventional
wisdom considers the top row to be lower-cost than the bottom row.
Something I didn’t realize at the time is that I also find the inward
lateral keys much easier to hit than the north keys, so I’d have liked
to try mapping the bottom row of HDPm to the inward laterals of the
Svalboard rather than the top row.  Nevertheless, I find this layout
to be pretty good overall, and I don’t think it would be worth the
switch now I’m starting to get used to it.</p>

    <p><span>O</span>n the fingers, after a long adjustment period, I’ve found that the
easiest keys to hit are, in order:</p>
<div>
<ul>
<li>
<p>the centre keys,</p>
</li>
<li>
<p>followed by the south keys,</p>
</li>
<li>
<p>then the inward keys,</p>
</li>
<li>
<p>then the north keys.</p>
</li>
</ul>
</div>

    <p><span>T</span>he outward keys are relatively uncomfortable, especially on the
weaker fingers, and I reserve them for infrequently-used
keys. 

<label for="sidenote:21"></label>
<span>The astute reader might have noticed a lack of an escape key: I actually type escape by pressing <kbd>⌦ Delete</kbd> and <kbd>⌫ Backspace</kbd> in unison.  This took me a bit to get used to but now I really like it, and would consider a similar approach for other infrequently-used keys like <kbd>↵ Enter</kbd>.  <em>Combos</em> with the outward keys can use a slight roll of the wrist, and so are much more comfortable for these kinds of one-off actions than for typing letters.</span></p>

    <p><span>O</span>n the thumbs, the easiest keys for me to hit are the inward ‘pad’
keys and the bottom ‘knuckle’ key, followed by the downward key.  The
lateral motions required to hit the ‘nail’ and ‘up’ keys are not
difficult to do, but cause strain that makes my thumbs hurt at the end
of the day if I assign them to anything that’s used too heavily.  This
is probably unique to my pathophysiology: you should experiment
yourself.</p>
</section>
<section id="higher-layers">
  <h3>Higher layers <a href="#higher-layers">§</a></h3>
  
    <p><span>T</span>he Svalboard has only 60 keys, meaning that layering is inevitable to
get a full complement of keystrokes.  I have three ‘everyday’ layers,
not counting shift: my base layer, a numbers/symbols layer, and a
combined navigation/control layer.  These are all ‘momentary’ layers,
meaning that I switch between them by holding down a key, and I switch
between them all on the fly while editing text.  Layering is something
that seems to put people off of keyboards with fewer keys, but while
experimenting with the Ergodox (on which, for many keycodes, I had
both a less-accessible key in the base layout and also a
more-accessible key on a higher layer) I found it much more
comfortable to have an easily-reachable layer switch than to have a
dedicated key that requires a stretch and a mispositioning of the
hands.  I find three layers few enough to not cause me undue mental
load, while still providing plenty of key space (none of my layers,
even the base layer, is fully utilized at the time of writing).</p>

    <p><span>I</span>’ve settled on a hand-split setup in which software modifiers like
<kbd>⇧ Shift</kbd>, <kbd>⎈ Ctrl</kbd>, and <kbd>⎇ Alt</kbd> (very important since I’m
an emacs user!) live on the left thumb, while layer modifiers live on
the right hand.  Having modifiers on the thumb allows me to have only
one copy of each modifier, since the thumb can move independently of
any other finger, while having the layer-switch keys (which are not
detectable by software) on the right thumb allows me to bind the
entirety of the left half of the keyboard when gaming. 

<label for="sidenote:25"></label>
<span>The <kbd>❖ Super</kbd> key is on the right hand for the same reason: it isn’t usually bindable in games.</span> The design of the individual clusters is
subtle: on the Svalboard thumb cluster the pairings on the same side
of the thumb cluster (e.g. <span><kbd>⎈ Ctrl</kbd>+<kbd>⎇ Alt</kbd></span> on my layout) can be
easily hit together, while those on opposite sides (e.g. <span><kbd>⎈ Ctrl</kbd>+<kbd>R</kbd></span> can’t be).  <kbd>⇧ Shift</kbd>, therefore, lives in the middle of the
cluster, where it can be easily hit with either side, while for the
specific combinations of the modifiers on the right with <kbd>R</kbd> or
<kbd>↵ Return</kbd> I have dedicated combinations with other layers: for
example, <kbd>R</kbd> on the control layer produces <span><kbd>⎈ Ctrl</kbd>+<kbd>R</kbd></span>.  On
the right cluster I have my layout modifiers, and here I make use of a
controversial feature of the Svalboard, inherited from the original
DataHand: the middle key of the thumb cluster has a ‘deep press’ that
is activated by pressing on it harder than usual.  Obviously this can
only occur while the usual key is held down.  This is ideal for me, as
I control my window manager using a combination of <kbd>❖ Super</kbd> with
various control and function keys, so while the middle press usually
enables my control/navigation layer, by pressing it more firmly I can
activate <kbd>❖ Super</kbd> as well and control my window manager.
Unfortunately, I sometimes need to use <kbd>❖ Super</kbd> with keys from
the base layout, so I also need a bare <kbd>❖ Super</kbd> key that doesn’t
involve switching to the control layer.</p>

    <p><span>T</span>he symbol layer has symmetric pairs of brackets as well as the
standard numbers and symbols.  Worthy of note is that I have a
‘<a href="https://www.kaufmann.no/roland/dvorak/">programmer Dvorak</a>’–like
layout in which symbols are prioritized over numbers: as a programmer
I type symbols a lot more often than numbers, and privileging small
numbers over large numbers encodes
<a href="https://en.wikipedia.org/wiki/Benford%27s_law">Benford’s law</a>.
It’s notable that, due to the abundance of key space given by having
an entire layer dedicated to numbers and symbols rather than just the
top row and some peripheral keys, I’m able to represent the entire set
of standard keyboard symbols and numbers here without shifting.
Insofar as needing an extra layer is a negative for the accessibility
of these keys, I find that this advantage more than offsets it.  I
also keep some infrequently-used keys here, such as my <kbd>⎄ Compose</kbd>
key, which I use only for symbols too rare to have their own dedicated
key.  I use composition for occasional letters with diacritics, emoji,
mathematical characters, or non-ASCII punctuation like
<a href="https://en.wikipedia.org/wiki/Quotation_mark">quotation marks</a> or
<a href="https://en.wikipedia.org/wiki/Dash">dashes</a>. 

<label for="sidenote:29"></label>
<span>It is important for clarity for quotation marks to be properly aligned: the typewriter ‘straight quotes’ arose only out of lack of glyph space, and should be avoided where more capable encodings are available.  I do find the ‘straight apostrophe’ useful for semantically distinguishing the apostrophe, whose chirality is unimportant, from the single quote, against Unicode recommendations.</span></p>
<div>
<p><a href="https://twey.io/hci/svalboard/layout-symbols.png"><img src="https://twey.io/hci/svalboard/layout-symbols.png" alt="A screenshot of my symbol layout in Keybard."></a>
</p>
<p>Figure 7. My symbol layout, with matched brackets and ANSI Dvorak–style numbers.</p>
</div>

    <p><span>T</span>he control layer has, most importantly, two
‘<a href="https://benhoyt.com/writings/wordstar-diamond/">WordStar
diamonds</a>’ for textual navigation: one on the left produces standard
arrow keys, while one on the right produces ‘big-step’ versions of the
same (<kbd>⇞ Page Up</kbd>, <kbd>⇟ Page Down</kbd>, <kbd>⇤ Home</kbd>, and <kbd>⇥
End</kbd>).  These diamonds differ from the standard <abbr>QWERTY</abbr>
<kbd>W</kbd><kbd>A</kbd><kbd>S</kbd><kbd>D</kbd> in that on the Svalboard (at least for
me) the ‘south’ direction is much more comfortable than the ‘north’
direction, but both are trumped by the ‘centre’ direction, so both
<kbd>← Left</kbd> and <kbd>→ Right</kbd> are on the centre keys along with
<kbd>↑ Up</kbd>, and instead of <kbd>↑ Up</kbd> being on a row above <kbd>↓
Down</kbd> is on a ‘row’ below, with a southward keypress. Also on this
layer I have function keys, matched in position to the number keys on
the symbol layer, which I use with <kbd>❖ Super</kbd> to switch workspaces,
and media control keys, as well as the key to switch to my steno
layer.</p>
<div>
<p><a href="https://twey.io/hci/svalboard/layout-control.png"><img src="https://twey.io/hci/svalboard/layout-control.png" alt="A screenshot of my control layout in Keybard."></a>
</p>
<p>Figure 8. My control layout, with two WordStar diamonds and function keys.</p>
</div>
</section>
<section id="stenography">
  <h3>Stenography <a href="#stenography">§</a></h3>
  
    <p><span>I</span> haven’t focused too much on stenography yet, since I’m still getting
up to speed with the base layout, but with help from
<a href="https://github.com/captdeaf">Ira Cooper</a> and
<a href="https://github.com/captdeaf">Greg Millam</a> I did add support to the
Svalboard and to Keybard for generating and configuring steno keycodes
using <a href="https://docs.qmk.fm/features/stenography">QMK’s steno
support</a>, so the Svalboard works out of the box with Plover — connect
it to the Svalboard’s emulated <code>/dev/ttyACM</code> device, set up
stenography keys on your Svalboard, and you should be good to go.</p>

    <p><span>A</span> big reason I bought the Svalboard in the first place is because the
super-light tactile keys with low travel, combined with its full N-key
rollover, should be excellent for steno, and so far my experiments
have borne this out.  There are two main caveats I’ve found that I’ve
had to somewhat mitigate in my steno layout.  Neither seems
insurmountable, but I need to experiment with different options to
figure out how to make something that’s sufficiently expressive but
still comfortable.</p>
<div>
<ul>
<li>
<p>The Svalboard has only one ‘column’ per finger, while the stenotype
traditionally has an extra column on the outside for the <kbd>＊
Star</kbd> modifier on the left, which is easily emulated with the
outwards lateral, and the <kbd>–D</kbd> <kbd>–Z</kbd> terminals on the right,
which are not.  Fundamentally, the steno layout allows the little
finger to press up to four keys at once while the Svalboard only
allows combos of up to three. Thankfully, some combinations of the
four (like <span><kbd>–T</kbd>+<kbd>–D</kbd>+<kbd>–S</kbd></span> or <span><kbd>–T</kbd>+<kbd>–Z</kbd></span>) are inadmissible, so if we
make sure that we can type each of the adjacent two-key combinations
and then the four-key combination we should be okay.</p>
</li>
<li>
<p>The centre/south combination, which seemed like the most obvious
mapping of the stenotype layout onto the Svalboard, is pretty
difficult to do consistently due to the angles of the keys involved.
I have two workarounds for this, and I’m not yet sure which I
prefer: either using the centre key as a steno combo key,
e.g. <kbd>PW–</kbd>, or eschewing the centre keys entirely for the
inwards lateral key as the upper row of the stenotype.  Each has its
own advantages and disadvantages: using the laterals requires
tilting either the keyboard or the wrist to make the neutral
position (with fingers on both ‘rows’) natural, while using
combination keys exacerbates the <kbd>–D</kbd>/<kbd>–Z</kbd> problem: the
rightmost cluster would need 6 keys to represent it uniformly with
combinations, but it has only five.</p>
</li>
</ul>
</div>
<div>
<p><a href="https://en.wikipedia.org/wiki/Stenotype"><img src="https://twey.io/hci/svalboard/stenotype-layout.png" alt="A diagram of the American Stenotype stenotype layout"></a>
</p>
<p>Figure 9. The standard American Stenotype layout, used by default by Plover.  Contrast with the Svalboard layout above.</p>
</div>

    <p><span>E</span>ither way, it’s clear to me that I at least need combo keys for the
vowels: the only two thumb-cluster keys that can be combined
comfortably enough for steno are the inward keys, and constantly
performing that lateral motion makes my thumbs hurt pretty quickly.
I’ve chosen the thumb knuckle and pad keys for the steno inner and
outer vowels, as the easiest thumb keys for me to hit, with the centre
key for their combination.</p>
</section>
<section id="pointing">
  <h3>Pointing <a href="#pointing">§</a></h3>
  
    <p><span>T</span>he Svalboard comes (optionally) with real pointing devices on each
hand, and the default firmware supports a ‘mouse layer’ on the highest
layer (15) that is automatically switched to when a pointer event is
detected, and switched away from when a press of a key not on the
mouse layer is detected.  The default configuration has the mouse
layer time out after inactivity, as well; I found this very
unpredictable, and it led to me making a lot of mode errors.  It can
be configured or disabled with a special keycode that can be bound in
Vial or Keybard.  I use two trackballs, one for pointing and one for
scrolling, but I’m looking forward to switching at least one of them
to a trackpad as soon as the trackpad gets smooth-scrolling support,
since the ability to use trackpad gestures like tap-for-click frees up
a bunch of key space (and maybe removes the need for mouse mode at
all?).  When gaming, to avoid accidental mouse-mode switches, I
usually remove the left trackball altogether.</p>
<hr>
</section>
</section>
<section id="retrospective">
  <h2>Retrospective <a href="#retrospective">§</a></h2>
  
    <p><span>O</span>verall, I find the Svalboard ticks all my boxes for a keyboard, and
if you can afford the money and the time investment I’d definitely
recommend giving it a go.  Typing is a lot more comfortable for me
now, and there are no downsides big enough to make me want to switch
back.</p>

    <p><span>I</span>t took me six months to achieve 80 WPM, but I think it would be a lot
faster if adapting an existing layout that you’re familiar with.  I
don’t recommend switching keyboard layouts at the same time, unless
you wanted to switch layout anyway.  Even though it can be fun, it
will likely only hinder your adoption of the keyboard, and doesn’t
come with any particular benefits. 

<label for="sidenote:33"></label>
<span>Benefits, that is, over switching layouts before or after switching keyboards — the ergonomic advantages of modern layouts, especially if you’re a <abbr>QWERTY</abbr> user, are well-documented, and I won’t repeat them here, though they are probably somewhat diminished for a keyboard that reduces <em>all</em> finger motion anyway.</span>  I’ve noticed a logarithmic pattern to my speed
improvements: I hit 20 WPM within the first week, and 40–50 WPM in the
first month, which is a bit painful but good enough to get things done
with.  By the second or third month I no longer felt like my keyboard
was imposing a large additional mental load on me and instead I felt
like it was just a bottleneck through which I have to squeeze my
thoughts — which has been my experience with all keyboards, even when
I was typing at 120 WPM.</p>

    <p><span>T</span>hough I’m still quite slow, and the Svalboard doesn’t try to sell
itself on improving typing speed, I see steady improvement in my
typing speeds as I use it more, and I don’t see any reason I shouldn’t
be able to match or exceed my typing speeds on slab keyboards while
enjoying significantly better typing comfort.  My hands feel much less
tired at the end of a day, though it’s important to note that this is
only the case after I’d spent quite some time adjusting the keyboard
to my typing habits and my typing habits to the keyboard.
Particularly, figuring out my typing posture and keyboard mounting
setup made a world of difference.</p>

    <p><span>I</span>n addition to the practical aspects, and despite the earlier warning,
it’s been pretty fun getting back into the world of crazy keyboard
layout optimizations, and I’ve discovered a lot about how I learn
physical skills and learnt to pay attention to aspects of how I use
computers that I would never have considered.</p>

    <p><span>F</span>inally, this post wouldn’t be complete without a shout-out to the
Svalboard Discord community, who have helped me a lot on my journey
both with hardware and software.</p>

    <p><span>H</span>appy typing!</p>
</section>

</article>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[At 17, Hannah Cairo solved a major math mystery (393 pts)]]></title>
            <link>https://www.quantamagazine.org/at-17-hannah-cairo-solved-a-major-math-mystery-20250801/</link>
            <guid>44759152</guid>
            <pubDate>Fri, 01 Aug 2025 16:35:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/at-17-hannah-cairo-solved-a-major-math-mystery-20250801/">https://www.quantamagazine.org/at-17-hannah-cairo-solved-a-major-math-mystery-20250801/</a>, See on <a href="https://news.ycombinator.com/item?id=44759152">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="postBody">
                <div>
        <p>
            After finding the homeschooling life confining, the teen petitioned her way into a graduate class at Berkeley, where she ended up disproving a 40-year-old conjecture.        </p>
        
    </div>
    <figure>
        <div>
                            <p><img width="2560" height="1440" src="https://www.quantamagazine.org/wp-content/uploads/2025/07/HannahCairo-cr.ValeriePlesch-Lede-scaled.webp" alt="" decoding="async" fetchpriority="high" srcset="https://www.quantamagazine.org/wp-content/uploads/2025/07/HannahCairo-cr.ValeriePlesch-Lede-scaled.webp 2560w, https://www.quantamagazine.org/wp-content/uploads/2025/07/HannahCairo-cr.ValeriePlesch-Lede-1720x968.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2025/07/HannahCairo-cr.ValeriePlesch-Lede-520x293.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2025/07/HannahCairo-cr.ValeriePlesch-Lede-768x432.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2025/07/HannahCairo-cr.ValeriePlesch-Lede-1536x864.webp 1536w, https://www.quantamagazine.org/wp-content/uploads/2025/07/HannahCairo-cr.ValeriePlesch-Lede-2048x1152.webp 2048w" sizes="(max-width: 2560px) 100vw, 2560px">                </p>
                        </div>
        <figcaption>
    <div>
            <p>Valerie Plesch for&nbsp;<em>Quanta Magazine</em></p>
        </div>
</figcaption>
    </figure>
<div>
            <h2>Introduction</h2>
            <div data-role="selectable">
    <p>It’s not that anyone ever said sophisticated math problems can’t be solved by teenagers who haven’t finished high school. But the odds of such a result would have seemed long.</p>
<p>Yet <a href="https://arxiv.org/abs/2502.06137">a paper posted on February 10</a> left the math world by turns stunned, delighted and ready to welcome a bold new talent into its midst. Its author was <a href="https://sites.google.com/view/hannah-cairo/">Hannah Cairo</a>, just 17 at the time. She had solved a 40-year-old mystery about how functions behave, called the Mizohata-Takeuchi conjecture.</p>
<p>“We were all shocked, absolutely. I don’t remember ever seeing anything like that,” said <a href="https://www.birmingham.ac.uk/staff/profiles/maths/oliveira-itamar">Itamar Oliveira</a> of the University of Birmingham, who has spent the past two years trying to prove that the conjecture was true. In her paper, Cairo showed that it’s false. The result defies mathematicians’ usual intuitions about what functions can and cannot do.</p>
<p>So does Cairo herself, who found her way to a proof after years of homeschooling in isolation and an unorthodox path through the math world.</p>
<h2><strong>A World Without Bounds</strong></h2>
<p>Cairo grew up in Nassau, the Bahamas, where her parents had moved so that her dad could take a job as a software developer. She and her two brothers — one three years older, the other eight years younger — were all homeschooled. Cairo started learning math using Khan Academy’s online lessons, and she quickly advanced through its standard curriculum. By the time she was 11 years old, she’d finished calculus.</p>
<p>Soon she had consumed everything that was readily available online. Her parents found a couple of math professors to tutor her remotely — first Martin Magid of Wellesley College, then Amir Aazami from Clark University. But much of her education was self-directed, as she read and absorbed, on her own, the graduate-level math textbooks that her tutors recommended. “Eventually,” Cairo recalled, Aazami “said something like, he feels uncomfortable being paid, because he feels like he’s not really teaching me. Because mostly I would read the book and try to prove the theorems.”</p>
</div>
    </div>
    <figure>
        <div>
                            <p><img width="2560" height="1519" src="https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Library-scaled.webp" alt="Woman in a library." decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Library-scaled.webp 2560w, https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Library-1720x1021.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Library-520x309.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Library-768x456.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Library-1536x911.webp 1536w, https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Library-2048x1215.webp 2048w" sizes="(max-width: 2560px) 100vw, 2560px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>Hannah Cairo taught herself the equivalent of an advanced undergraduate math curriculum by the time she was 14.</p>
            <p>Valerie Plesch for&nbsp;<em>Quanta Magazine</em></p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>But Cairo found homeschooling confining.</p>
<p>“There was this inescapable sameness, in a way. No matter what I did, I was in the same place doing mostly the same things,” she said. “I was very isolated, and nothing I could do could really change that. I’d wake up on certain days and realize, I’m just older.”</p>
<p>Math became a kind of escape, a space that felt expansive when her daily life was not.</p>
<p>“Mathematics was another world I could explore. A world that was not confining, a world I could access at any point just by thinking about it,” she said. “That’s how I grew up, thinking about mathematics as this world of ideas that I can explore on my own. That sort of process helped me see math differently than a lot of people.”</p>
<p>In 2021, amid the Covid pandemic, Cairo’s world began to widen, even as it was narrowing for so many others. Travel restrictions stranded her family at her grandparents’ house in Chicago. While they were there, she joined the Math Circles of Chicago, where teachers and students gather to solve difficult problems together.</p>
<p>The experience led her to apply the following year to a two-week online summer program run by the Berkeley Math Circle, which has nurtured some of the most exceptional math talent in the world. In her application, she listed a set of self-taught subjects that together comprised the equivalent of an advanced undergraduate math degree. She was 14 years old.</p>
</div>
    <figure>
        <div>
                            <p><img width="2560" height="1612" src="https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Standing-scaled.webp" alt="Woman standing indoors against a glass wall." decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Standing-scaled.webp 2560w, https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Standing-1720x1083.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Standing-520x327.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Standing-768x483.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Standing-1536x967.webp 1536w, https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Standing-2048x1289.webp 2048w" sizes="(max-width: 2560px) 100vw, 2560px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>As a teenager, Cairo constructed a function that behaved in strange and unexpected ways, disproving a major conjecture in a field called Fourier restriction theory.</p>
            <p>Valerie Plesch for&nbsp;<em>Quanta Magazine</em></p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>“Hannah is above and beyond the ordinary,” said <a href="https://math.berkeley.edu/~stankova/">Zvezdelina Stankova</a>, a mathematician at Berkeley and the founder of the Berkeley Math Circle. “Every time she applies for school or a program, she is several levels ahead.”</p>
<p>Yet these scattered experiences never convinced Cairo that she had exceptional mathematical ability. She is soft-spoken, open and humble, and seems genuinely unsure of how her ability stacks up against anyone else’s — in part because for years her only reference point was herself.</p>
<p>“Growing up, I didn’t really know if I was talented,” she said. “I like to play piano, and people around me would tell me that I was really talented at math and at piano. And in retrospect, now that I look at it, I can see, sure, my piano was above average. But it was by no means exceptional. While on the other hand, it looks like mathematically I’m, like, whatever.”</p>
<h2><strong>Finding Her Place</strong></h2>
<p>In 2023, after a second summer with the Berkeley Math Circle, Cairo wondered what her next step should be. She had already applied to several universities, and while most schools rejected her — she hadn’t finished high school yet — she was accepted by the University of California, Davis. Should she start her undergraduate studies three years early? Or should she pursue educational opportunities elsewhere?</p>
<p>Stankova encouraged her to instead participate in Berkeley’s concurrent enrollment program, where she could take graduate-level math courses from leading researchers in the field.</p>
</div>
    <figure>
        <div>
                            <p><img width="2560" height="1627" src="https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Screen-scaled.webp" alt="Woman giving a lecture." decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Screen-scaled.webp 2560w, https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Screen-1720x1093.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Screen-520x330.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Screen-768x488.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Screen-1536x976.webp 1536w, https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Screen-2048x1302.webp 2048w" sizes="(max-width: 2560px) 100vw, 2560px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>The math world was taken aback when Cairo announced her counterexample to the Mizohata-Takeuchi conjecture — both because it settled a major open problem, and because Cairo was still in high school at the time.</p>
            <p>Valerie Plesch for&nbsp;<em>Quanta Magazine</em></p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>Cairo followed this advice. In the fall of 2023, her family moved to Davis, 60 miles northeast of Berkeley. There, her older brother enrolled as a freshman at UC Davis, and her parents allowed her to commute to Berkeley on Tuesdays and Thursdays. By the spring, she was going five days a week and taking several more classes. She recalls it as a time in her life when she began to feel full of possibility.</p>
<p>“I had started making friends, and I was feeling good,” she said. After the spring semester ended, her family moved from Davis to Berkeley — her brother had decided to transfer there — and Cairo finally felt able to settle in.</p>
<p>Even so, it was an adjustment. “I didn’t have many social experiences, so I still had to learn how to interact with other humans,” she said.</p>
<p>As the 2024–2025 academic year neared, Cairo considered what courses she would take. One class in particular caught her eye — a graduate course in Fourier restriction theory, a branch of harmonic analysis. “It was one of the most advanced analysis classes being offered that semester, so I thought, I’ll just go take it,” she said.</p>

<p>The professor for the course was <a href="https://math.berkeley.edu/people/faculty/ruixiang-zhang">Ruixiang Zhang</a>, an accomplished mathematician whose path into the field had followed a more traditional arc: a gold medal at the 2008 International Mathematical Olympiad, the prestigious high school competition; a doctorate from Princeton University; a postdoc at the Institute for Advanced Study; a tenure-track position at Berkeley, one of the top math departments in the world.</p>
<p>Cairo emailed Zhang, asking to enroll. “Hannah was very focused and seemed to be passionate about the topic,” he said. “This attitude alone is enough for me, so I just gave her permission.”</p>
<p>Within a few weeks, while working on a problem set, she came across a problem that she couldn’t stop thinking about.</p>
<h2><strong>Extra Credit</strong></h2>
<p>The problem was a simplified version of the Mizohata-Takeuchi conjecture. Zhang had included it in one of his homework assignments as a warm-up, hoping to encourage students to practice advanced techniques in a deep area of math. The assignment also included an optional extension, inviting them to consider whether the proof they’d found for the simplified case could be extended to more complicated formulations of the problem.</p>
<p>Cairo completed the problem set and took Zhang up on the invitation to keep thinking. To her, it seemed natural to follow the thread of an idea as far as it would go. “Why would I stop?” she said.</p>
<p>The Mizohata-Takeuchi conjecture is a problem in harmonic analysis, a field that studies how functions are assembled from wavelike components.</p>
<p>Any given function can be written as the sum of simpler wavelike pieces, called sine waves. Each of those sine waves, in turn, has a frequency. Mathematicians often want to understand the nature of functions that can only be built out of sine waves with certain frequencies. In these cases, the only permitted frequencies are those that satisfy equations that carve out specific surfaces, like a sphere. That’s because the functions that define many physical waves — such as light, sound and quantum particles — are restricted to these kinds of frequencies.</p>
</div>
    <figure>
        <div>
                            <p><img width="2500" height="1470" src="https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-GreenBuilding-1.webp" alt="Woman standing in front of a reflective building." decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-GreenBuilding-1.webp 2500w, https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-GreenBuilding-1-1720x1011.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-GreenBuilding-1-520x306.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-GreenBuilding-1-768x452.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-GreenBuilding-1-1536x903.webp 1536w, https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-GreenBuilding-1-2048x1204.webp 2048w" sizes="(max-width: 2500px) 100vw, 2500px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>To Cairo, “mathematics was another world I could explore. A world that was not confining, a world I could access at any point just by thinking about it,” she said.</p>
            <p>Valerie Plesch for&nbsp;<em>Quanta Magazine</em></p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>The Mizohata-Takeuchi conjecture considers functions built out of waves whose frequencies lie on such a surface. It states that the energy of the function — a measure of how big the function gets — can only be spread out and concentrated in particular patterns.</p>
<p>It’s as if you’re playing music in a strangely shaped room. Sometimes, the music might echo and amplify, getting very loud. But when that happens, it can only happen in certain spots.</p>
<p>Over the decades, mathematicians made limited progress on a few special cases of the Mizohata-Takeuchi conjecture. But the general problem remained wide open. None of the standard methods seemed able to touch it. That imperviousness made some mathematicians suspect that the conjecture was false; others felt that its elegance made it more likely to be true.</p>
<p>“Some mornings, I’d wake up with the idea that because it’s so simply and elegantly stated, and it’s so broad, in the end it had to be true,” said Tony Carbery, a mathematician at the University of Edinburgh who worked on the problem for decades. “Other mornings, I’d wake up and say … it can’t possibly be true in any simpleminded way.”</p>
<p>Mathematicians found themselves at an impasse.</p>
<h2><strong>Exceeding Limits</strong></h2>
<p>In the path toward a proof of any hard problem, there’s a lot of doubt. Mathematicians doubt their approaches, doubt their intuitions, doubt that the idea they’re following — so promising in the moment — will actually hold up.</p>
<p>In Cairo’s case, those doubts were amplified. She was new to the field, and her early efforts to prove the full conjecture were tentative and incomplete. She questioned whether she was headed in the right direction. So did Zhang.</p>
</div>
    <figure>
        <div>
                            <p><img width="2560" height="1558" src="https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Grass-scaled.webp" alt="" decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Grass-scaled.webp 2560w, https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Grass-1720x1047.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Grass-520x316.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Grass-768x467.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Grass-1536x935.webp 1536w, https://www.quantamagazine.org/wp-content/uploads/2025/08/HannahCairo-cr.ValeriePlesch-Grass-2048x1246.webp 2048w" sizes="(max-width: 2560px) 100vw, 2560px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>Having decided to skip college, Cairo will soon be starting her doctoral studies at the University of Maryland.</p>
            <p>Valerie Plesch for&nbsp;<em>Quanta Magazine</em></p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>“I went to office hours and asked him, ‘Do these ideas work?’ It turned out they didn’t because they were silly,” she said. “There’d be this back-and-forth. I’d come to office hours with new ideas and ask if they work. And he’d say no.”</p>
<p>Cairo kept reading and thinking. Eventually, she found a way to construct a strange, complicated function out of waves whose frequencies all lay on a curved surface — the type of surface the conjecture required. Usually, when you add these kinds of waves together, they interfere, canceling each other out in some places and reinforcing each other elsewhere.</p>
<p>But Cairo showed that in her function, they didn’t cancel out as expected. Instead, their interference created uneven patterns, causing the function’s energy to spread out over some areas and concentrate in others in a fractal-like way that the Mizohata-Takeuchi conjecture prohibited. She found herself staring at a mathematical construction that by many accounts shouldn’t exist.</p>
<p>At first it made her wary. “This is something that happens to me often,” she said. “I come to something that looks like a proof, and I think I have a proof, but [then] I’ve actually been wrong.”</p>
<p>Then two things happened. The first was that she realized she could replace her complicated construction with a much simpler one and achieve the same result.</p>
<p>The other was that she convinced herself, and Zhang, that the result was right.</p>
<p>“Cairo’s paper is a great example of how natural and elegant conjectures can fail in ways we didn’t think of,” Oliveira said. “But to see that, we need to look through the right lenses.”</p>
<h2><strong>A New Landscape</strong></h2>
<p>The proof, and its unlikely author, have energized the math community since Cairo posted it in February. “I was absolutely, ‘Wow.’ This has been my favorite problem for nigh on 40 years, and I was completely blown away,” Carbery said. “When I found out [Cairo] was much younger than I previously thought, I was much more impressed. The elegance with which the paper is written is quite extraordinary.”</p>
<p>Mathematicians are excited about how Cairo’s work will inspire new research. “I am certain that, from now on, whenever we come upon a problem of similar flavor, we will try to test it against Cairo-like constructions,” Oliveira said.</p>
        
        
<p>He and others in the harmonic analysis community will also have to reckon with a changed landscape. In harmonic analysis, there’s a <a href="https://www.quantamagazine.org/a-tower-of-conjectures-that-rests-upon-a-needle-20230912/">constellation of questions</a> about how the energy of a wave concentrates. If a conjecture known as Stein’s conjecture were true, it would cement connections between some of the most important questions in that broader constellation. But Cairo’s work shows that Stein’s conjecture is false. It eliminates one of the most promising links mathematicians had hoped to establish between different parts of harmonic analysis.</p>
<p>The math world is also adjusting to the fact of Cairo herself. After completing the proof, she decided to apply straight to graduate school, skipping college (and a high school diploma) altogether. As she saw it, she was already living the life of a graduate student. Cairo applied to 10 graduate programs. Six rejected her because she didn’t have a college degree. Two admitted her, but then higher-ups in those universities’ administrations overrode those decisions.</p>
<p>Only the University of Maryland and Johns Hopkins University were willing to welcome her straight into a doctoral program. She’ll start at Maryland in the fall. When she finishes, it will be her first degree.</p>
</div>
                
                
            </div><div>
        <div data-name="next-post__image-wrapper">
    <p><img width="1720" height="729" src="https://www.quantamagazine.org/wp-content/uploads/2025/07/CellMemory-crKristinaArmitage-Lede-draft01CellMemory-crKristinaArmitage-HP-1720x729.webp" alt="" decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2025/07/CellMemory-crKristinaArmitage-Lede-draft01CellMemory-crKristinaArmitage-HP-1720x729.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2025/07/CellMemory-crKristinaArmitage-Lede-draft01CellMemory-crKristinaArmitage-HP-520x220.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2025/07/CellMemory-crKristinaArmitage-Lede-draft01CellMemory-crKristinaArmitage-HP-768x325.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2025/07/CellMemory-crKristinaArmitage-Lede-draft01CellMemory-crKristinaArmitage-HP-1536x651.webp 1536w, https://www.quantamagazine.org/wp-content/uploads/2025/07/CellMemory-crKristinaArmitage-Lede-draft01CellMemory-crKristinaArmitage-HP-2048x868.webp 2048w" sizes="(max-width: 1720px) 100vw, 1720px">    </p>
</div>
        
        <div>
                <h2>Next article</h2>
                <p>What Can a Cell Remember?</p>
            </div>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI Leaks 120B Open Model on Hugging Face (129 pts)]]></title>
            <link>https://twitter.com/main_horse/status/1951201925778776530</link>
            <guid>44758511</guid>
            <pubDate>Fri, 01 Aug 2025 15:44:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/main_horse/status/1951201925778776530">https://twitter.com/main_horse/status/1951201925778776530</a>, See on <a href="https://news.ycombinator.com/item?id=44758511">Hacker News</a></p>
Couldn't get https://twitter.com/main_horse/status/1951201925778776530: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[FBI seized $40k from Linda Martin without charging her with a crime (208 pts)]]></title>
            <link>https://reason.com/2025/07/28/the-fbi-took-her-40000-without-explaining-why-she-fought-back-and-lost/</link>
            <guid>44758339</guid>
            <pubDate>Fri, 01 Aug 2025 15:32:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reason.com/2025/07/28/the-fbi-took-her-40000-without-explaining-why-she-fought-back-and-lost/">https://reason.com/2025/07/28/the-fbi-took-her-40000-without-explaining-why-she-fought-back-and-lost/</a>, See on <a href="https://news.ycombinator.com/item?id=44758339">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							<p><span>Linda Martin found out the hard way that the most powerful law enforcement agency in the U.S.—the FBI—can seize your assets without articulating why. Worse: Law enforcement took her savings in a raid that was itself unconstitutional. Worse still: A lawsuit she filed met its demise last week, allowing the federal government to continue the dubious practice of taking people's valuables without having to explain the reason it is justified in doing so.</span></p>
<p><span>The agency never did furnish a specific reason in Martin's case—because she wasn't charged with a crime. Her saga began in 2021, when the FBI sought to take more than $100 million in assets from U.S. Private Vaults, a business that offered safe-deposit boxes. That company was suspected of, and ultimately charged with, criminal wrongdoing. But the warrant expressly </span><a href="https://www.documentcloud.org/documents/20700649-21-notice-of-motion-and-motion-for-return-of-property-pursuant-to-fed-r-crim-p-41g/#document/p10"><span>forbade</span></a><span> agents from engaging in a "criminal search or seizure" of customers' boxes, like Martin's.</span></p>
<p><span>They did so anyway, rummaging through approximately 800 of them and seizing assets that belonged to a <a href="https://reason.com/2021/06/11/fbi-raid-safety-deposit-boxes-los-angeles-jennifer-paul-snitko-85-million-civil-forfeiture/">slew of innocent people.</a> That included Travis May, who stored gold and $63,000 in cash; Jeni Verdon-Pearsons and Michael Storc, who kept $2,000 in cash, as well as approximately $20,000 worth of silver; Paul and Jennifer Snitko, whose box contained personal items, like marriage, birth, and baptismal certificates; and Don Mellein, who had invested in gold coins, many of which the FBI said it lost (to the tune of over $100,000).</span></p>
<p><span>A federal court later ruled that the bureau's actions <a href="https://reason.com/2024/01/23/appeals-court-fbis-safe-deposit-box-seizures-violated-fourth-amendment/">violated the Fourth Amendment</a>. </span><span>But it was too late for Martin, who received notice that the FBI had taken $40,200, her life savings, from her box. To justify that, the notice listed hundreds of federal crimes that would lead to a seizure. As Institute for Justice (I.J.) Director of Media Relations Andrew Wimer </span><a href="https://x.com/andrewwimer/status/1948831860622053716"><span>points out</span></a><span>, that included things like copyright infringement and doing business with North Korea. But the bureau notably did not specify how Martin was supposedly connected to any of those offenses, because it is not required to do so.</span></p>
<p><span>So she sued. "When the FBI attempts to forfeit someone's property, due process requires that it say why, citing </span><i><span>specific facts and laws</span></i><span>," reads her appellant </span><a href="https://ij.org/wp-content/uploads/2023/03/CADC-15-Brief-of-Appellant.pdf"><span>brief</span></a><span>. "By sending notices that initiate and, often, consummate property's forfeiture—all without ever saying what exactly the FBI thinks justifies the forfeiture, the FBI deprives owners of crucial information they need to protect their rights." After she filed the lawsuit, and about two years post-seizure, the agency returned Martin's cash. But she continued in court in hopes that the judiciary would agree that the FBI was violating people's due process rights by seizing assets with effectively no explanation.</span></p>
<p><span>That died last week, when the U.S. Court of Appeals for the District of Columbia </span><a href="https://media.cadc.uscourts.gov/opinions/docs/2025/07/24-5144-2126635.pdf"><span>dismissed</span></a><span> the suit for lack of jurisdiction.</span></p>
<p><span>"The FBI took Linda's savings without clearly saying what she did wrong. That shouldn't happen in America, but taking on the entrenched federal civil forfeiture system is challenging," said Bob Belden, an attorney at I.J. (which represented Martin), in a statement via email. "Unfortunately, there is not a clear path to appeal to the U.S. Supreme Court. We know that several Justices are alarmed at how civil forfeiture works in America and hope that the right case will work its way to the Court."</span></p>
<p><span>Robert Frommer, a senior attorney at I.J., </span><a href="https://reason.com/2025/03/20/the-fbi-seized-this-womans-life-savings-without-telling-her-why/"><span>told</span></a><span> me in March that "without specific notice, property owners can't understand what this is all about, and therefore can't do any investigation or get meaningful advice from attorneys." That helps explain, he says, why the agency is so successful at avoiding scrutiny for its seizures. "Owners must decide whether to fight against the federal government, default, or plead for mercy, all without knowing why the FBI is doing this to them," he says. "It's therefore little surprise that 93% of federal forfeitures never get to a court, meaning the FBI gets to keep the money without ever telling anyone why they should be allowed to"—which, at least for now, will remain the status quo.</span></p>
						</div></div>]]></description>
        </item>
    </channel>
</rss>