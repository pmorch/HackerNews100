<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 22 Jan 2026 16:30:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[GPTZero finds 100 new hallucinations in NeurIPS 2025 accepted papers (169 pts)]]></title>
            <link>https://gptzero.me/news/neurips/</link>
            <guid>46720395</guid>
            <pubDate>Thu, 22 Jan 2026 15:20:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gptzero.me/news/neurips/">https://gptzero.me/news/neurips/</a>, See on <a href="https://news.ycombinator.com/item?id=46720395">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<table xmlns="http://www.w3.org/1999/xhtml" dir="ltr" data-sheets-root="1" data-sheets-baot="1"><colgroup><col width="200"><col width="80"><col width="280"><col width="220"></colgroup><tbody><tr><td><p dir="ltr"><span>Published Paper</span></p></td><td><p dir="ltr"><span>GPTZero Scan</span></p></td><td><p dir="ltr"><span>Example of Verified Hallucination</span></p></td><td><p dir="ltr"><span>Comment</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=FxCy8TvQHO"><span>SimWorld: An Open-ended Simulator for Agents in Physical and Social Worlds</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/02dc3e04-2bd6-4ce2-ba22-017b5c925b03/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/3d32225d-7494-4e82-afd6-58a5d399b3af/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>John Doe and Jane Smith. Webvoyager: Building an end-to-end web agent with large multimodal models. arXiv preprint arXiv:2401.00001, 2024.</span></p></td><td><p dir="ltr"><span>Article with a matching title exists</span><a href="https://aclanthology.org/2024.acl-long.371/"><span> </span><span>here</span></a><span>. Authors are obviously fabricated. arXiv ID links to a different</span><a href="https://arxiv.org/abs/2401.00001"><span> </span><span>article</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=WQb0YrFl3H"><span>Unmasking Puppeteers: Leveraging Biometric Leakage to Expose Impersonation in AI-Based Videoconferencing</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/3043470a-75f9-4803-ac7d-5a8ae833899e/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/cd109d6a-2c6d-4b38-ae39-b0da48a86c43/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>John Smith and Jane Doe. Deep learning techniques for avatar-based interaction in virtual environments. IEEE Transactions on Neural Networks and Learning Systems, 32(12):5600-5612, 2021. doi: 10.1109/ TNNLS.2021.3071234. URL</span><a href="https://ieeexplore.ieee.org/document/307123"><span> </span><span>https://ieeexplore.ieee.org/document/307123</span></a></p></td><td><p dir="ltr"><a href="https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=9629429&amp;punumber=5962385&amp;sortType=vol-only-seq&amp;pageNumber=2"><span>No author or title match. Doesn't exist in </span><span>publication</span></a><span>. URL and DOI are fake.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=WQb0YrFl3H"><span>Unmasking Puppeteers: Leveraging Biometric Leakage to Expose Impersonation in AI-Based Videoconferencing</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/3043470a-75f9-4803-ac7d-5a8ae833899e/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/cd109d6a-2c6d-4b38-ae39-b0da48a86c43/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Min-Jun Lee and Soo-Young Kim. Generative adversarial networks for hyper-realistic avatar creation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 1234-1243, 2022. doi: 10.1109/CVPR.2022.001234. URL https://ieeexplore.ieee.org/ document/00123</span></p></td><td><p dir="ltr"><a href="https://openaccess.thecvf.com/CVPR2022"><span>No author or title match. Doesn't exist in </span><span>publication</span></a><span>. URL and DOI are fake.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=EyOtIOmMUh"><span>SimWorld-Robotics: Synthesizing Photorealistic and Dynamic Urban Environments for Multimodal Robot Navigation and Collaboration</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/aae95ba0-192d-441b-8c93-4342f29cf3aa/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/0fcb90db-35bc-4d22-9b0d-1fd5af82355b/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Firstname Lastname and Others. Drivlme: A large-scale multi-agent driving benchmark, 2023. URL or arXiv ID to be updated.</span></p></td><td><p dir="ltr"><span>No title or author match. Potentially referring to this</span><a href="https://arxiv.org/abs/2406.03008"><span> </span><span>article</span></a><span>, but year is off (2024)</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=EyOtIOmMUh"><span>SimWorld-Robotics: Synthesizing Photorealistic and Dynamic Urban Environments for Multimodal Robot Navigation and Collaboration</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/aae95ba0-192d-441b-8c93-4342f29cf3aa/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/0fcb90db-35bc-4d22-9b0d-1fd5af82355b/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Firstname Lastname and Others. Robotslang: Grounded natural language for multi-robot object search, 2024. To appear.</span></p></td><td><p dir="ltr"><span>No title or author match. Potentially referring to this</span><a href="https://proceedings.mlr.press/v155/banerjee21a/banerjee21a.pdf"><span> </span><span>article</span></a><span>, but year is totally off (2020).</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=IiEtQPGVyV"><span>Efficient semantic uncertainty quantification in language models via diversity-steered sampling</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/53b0d78b-e26e-421a-939a-4ae423631f60/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/70843e88-0958-4116-9721-03e73ccb18f9/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Nuo Lou and et al. Dsp: Diffusion-based span prediction for masked text modeling. arXiv preprint arXiv:2305.XXXX, 2023.</span></p></td><td><p dir="ltr"><span>No title or author match and arXiv ID is incomplete.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=IiEtQPGVyV"><span>Efficient semantic uncertainty quantification in language models via diversity-steered sampling</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/53b0d78b-e26e-421a-939a-4ae423631f60/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/70843e88-0958-4116-9721-03e73ccb18f9/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>A. Sahoo and et al. inatk: Iterative noise aware text denoising. arXiv preprint arXiv:2402.XXXX, 2024.</span></p></td><td><p dir="ltr"><span>No title or author match and arXiv ID is incomplete.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=IiEtQPGVyV"><span>Efficient semantic uncertainty quantification in language models via diversity-steered sampling</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/53b0d78b-e26e-421a-939a-4ae423631f60/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/70843e88-0958-4116-9721-03e73ccb18f9/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Sheng Shi and et al. Maskgpt: Uniform denoising diffusion for language. arXiv preprint arXiv:2401.XXXX, 2024.</span></p></td><td><p dir="ltr"><span>No title or author match and arXiv ID is incomplete.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=IiEtQPGVyV"><span>Efficient semantic uncertainty quantification in language models via diversity-steered sampling</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/53b0d78b-e26e-421a-939a-4ae423631f60/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/70843e88-0958-4116-9721-03e73ccb18f9/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Asma Issa, George Mohler, and John Johnson. Paraphrase identification using deep contextualized representations. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 517-526, 2018.</span></p></td><td><p dir="ltr"><span>No author or title match. No match in</span><a href="https://aclanthology.org/events/emnlp-2021/#2021emnlp-main"><span> </span><span>publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=IiEtQPGVyV"><span>Efficient semantic uncertainty quantification in language models via diversity-steered sampling</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/53b0d78b-e26e-421a-939a-4ae423631f60/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/70843e88-0958-4116-9721-03e73ccb18f9/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Yi Tay, Kelvin Fu, Kai Wu, Ivan Casanueva, Jianfeng Liu, Byron Wallace, Shuohang Wang, Bajrang Singh, and Julian McAuley. Reasoning with heterogeneous graph representations for knowledge-aware question answering. In Findings of the Association for Computational Linguistics: ACL 2021, pp. 3497-3506, 2021.</span></p></td><td><p dir="ltr"><span>No exact author or title match, although this title is</span><a href="https://aclanthology.org/2023.findings-emnlp.906.pdf?utm_source=consensus"><span> close.</span></a><span> No match in the</span><a href="https://aclanthology.org/events/findings-2021/"><span> publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=IiEtQPGVyV"><span>Efficient semantic uncertainty quantification in language models via diversity-steered sampling</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/53b0d78b-e26e-421a-939a-4ae423631f60/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/70843e88-0958-4116-9721-03e73ccb18f9/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Alex Wang, Rishi Bommasani, Dan Hendrycks, Daniel Song, and Zhilin Zhang. Efficient fewshot learning with efl: A single transformer for all tasks. In arXiv preprint arXiv:2107.13586, 2021.</span></p></td><td><p dir="ltr"><span>No title or author match. ArXiv ID leads to a different</span><a href="https://arxiv.org/abs/2107.13586"><span> article</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=IiEtQPGVyV"><span>Efficient semantic uncertainty quantification in language models via diversity-steered sampling</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/53b0d78b-e26e-421a-939a-4ae423631f60/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/70843e88-0958-4116-9721-03e73ccb18f9/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Lei Yu, Jimmy Dumsmyr, and Kevin Knight. Deep paraphrase identification. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. $650-655,2014$.</span></p></td><td><p dir="ltr"><span>No title or author match. No match in</span><a href="https://aclanthology.org/volumes/D14-1/"><span> </span><span>publication</span></a></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=IiEtQPGVyV"><span>Efficient semantic uncertainty quantification in language models via diversity-steered sampling</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/53b0d78b-e26e-421a-939a-4ae423631f60/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/70843e88-0958-4116-9721-03e73ccb18f9/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>X. Ou and et al. Tuqdm: Token unmasking with quantized diffusion models. In ACL, 2024.</span></p></td><td><p dir="ltr"><span>No title or author match.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=IiEtQPGVyV"><span>Efficient semantic uncertainty quantification in language models via diversity-steered sampling</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/53b0d78b-e26e-421a-939a-4ae423631f60/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/70843e88-0958-4116-9721-03e73ccb18f9/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Franz Aichberger, Lily Chen, and John Smith. Semantically diverse language generation. In International Conference on Learning Representations (ICLR), 2025.</span></p></td><td><p dir="ltr"><a href="https://proceedings.iclr.cc/paper_files/paper/2025/file/b94d8b035e2183e47afef9e2f299ba47-Paper-Conference.pdf"><span>No title or author match. Some similarity to this </span><span>article</span></a></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=IiEtQPGVyV"><span>Efficient semantic uncertainty quantification in language models via diversity-steered sampling</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/53b0d78b-e26e-421a-939a-4ae423631f60/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/70843e88-0958-4116-9721-03e73ccb18f9/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Maria Glushkova, Shiori Kobayashi, and Junichi Suzuki. Uncertainty estimation in neural text regression. In Findings of the Association for Computational Linguistics: EMNLP 2021, pp. $4567-4576,2021$.</span></p></td><td><p dir="ltr"><span>No author or title match. No match in</span><a href="https://aclanthology.org/volumes/2021.findings-emnlp/"><span> </span><span>publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=IiEtQPGVyV"><span>Efficient semantic uncertainty quantification in language models via diversity-steered sampling</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/53b0d78b-e26e-421a-939a-4ae423631f60/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/70843e88-0958-4116-9721-03e73ccb18f9/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Yichao Wang, Bowen Zhou, Adam Lopez, and Benjamin Snyder. Uncertainty quantification in abstractive summarization. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (ACL), pp. 1234-1245, 2022.</span></p></td><td><p dir="ltr"><span>No author or title match.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=IiEtQPGVyV"><span>Efficient semantic uncertainty quantification in language models via diversity-steered sampling</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/53b0d78b-e26e-421a-939a-4ae423631f60/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/70843e88-0958-4116-9721-03e73ccb18f9/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Mohit Jain, Ethan Perez, and James Glass. Learning to predict confidence for language models. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 245-256, 2021.</span></p></td><td><p dir="ltr"><span>No author or title match. No match in</span><a href="https://aclanthology.org/events/emnlp-2021/#2021emnlp-main"><span> </span><span>publication</span></a></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=IiEtQPGVyV"><span>Efficient semantic uncertainty quantification in language models via diversity-steered sampling</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/53b0d78b-e26e-421a-939a-4ae423631f60/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/70843e88-0958-4116-9721-03e73ccb18f9/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Srinivasan Kadavath, Urvashi Khandelwal, Alec Radford, and Noam Shazeer. Answer me this: Self-verifying large language models. In arXiv preprint arXiv:2205.05407, 2022.</span></p></td><td><p dir="ltr"><a href="https://arxiv.org/abs/2205.05407"><span>No author or title match. ArXiv ID leads to a different </span><span>article</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=0ZnXGzLcOg"><span>Privacy Reasoning in Ambiguous Contexts</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/fe51b7d6-607a-470d-adf3-0a5e4770d5ad/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/7e96a90a-fb2f-4303-b873-c8b1f7f66532/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Zayne Sprague, Xi Ye, Kyle Richardson, and Greg Durrett. MuSR: Testing the limits of chain-of-thought with multistep soft reasoning. In EMNLP, 2023.</span></p></td><td><p dir="ltr"><span>Two authors are omitted and one (Kyle Richardson) is added. This</span><a href="https://proceedings.iclr.cc/paper_files/paper/2024/file/3f8c7eb848ffec848f3ed2b7ca44915d-Paper-Conference.pdf"><span> paper</span></a><span> was published at ICLR 2024.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=15GCs8DoSm"><span>Memory-Augmented Potential Field Theory: A Framework for Adaptive Control in Non-Convex Domains</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/a80b41a7-a74b-4c7d-a8dd-6a02829a17fa/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/1397d83d-3075-4574-a1cf-27df285a5f64/share"><span>AI</span></a><span>**</span></p></td><td><p dir="ltr"><span>Mario Paolone, Trevor Gaunt, Xavier Guillaud, Marco Liserre, Sakis Meliopoulos, Antonello Monti, Thierry Van Cutsem, Vijay Vittal, and Costas Vournas. A benchmark model for power system stability controls. IEEE Transactions on Power Systems, 35(5):3627-3635, 2020.</span></p></td><td><p dir="ltr"><span>The authors match this</span><a href="https://www.sciencedirect.com/science/article/abs/pii/S037877962030482X?via%3Dihub"><span> paper</span></a><span>, but the title, publisher, volume, issue, and page numbers are incorrect. Year (2020) is correct.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=15GCs8DoSm"><span>Memory-Augmented Potential Field Theory: A Framework for Adaptive Control in Non-Convex Domains</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/a80b41a7-a74b-4c7d-a8dd-6a02829a17fa/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/1397d83d-3075-4574-a1cf-27df285a5f64/share"><span>AI</span></a><span>**</span></p></td><td><p dir="ltr"><span>Mingliang Han, Bingni W Wei, Phelan Senatus, Jörg D Winkel, Mason Youngblood, I-Han Lee, and David J Mandell. Deep koopman operator: A model-free approach to nonlinear dynamical systems. Chaos: An Interdisciplinary Journal of Nonlinear Science, 30(12):123135, 2020.</span></p></td><td><p dir="ltr"><span>No title or author match. Journal and other identifiers match this</span><a href="https://pubs.aip.org/aip/cha/article-abstract/30/12/123135/1074648/A-logistic-model-and-predictions-for-the-spread-of?redirectedFrom=fulltext"><span> article.</span></a></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=18GBPdnuXs"><span>Adaptive Quantization in Generative Flow Networks for Probabilistic Sequential Prediction</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/4ea64476-d22e-41ad-aaed-a7e8516c4ec0/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/d8546150-5096-4b85-8029-870e962feef8/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Francisco Ramalho, Meng Liu, Zihan Liu, and Etienne Mathieu. Towards gflownets for continuous control. arXiv preprint arXiv:2310.18664, 2023.</span></p></td><td><p dir="ltr"><span>No author or title match. ArXiv ID matches this</span><a href="https://arxiv.org/abs/2310.18664"><span> paper.</span></a></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=1amnhVRQ3l"><span>Grounded Reinforcement Learning for Visual Reasoning</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/9af6453c-26d2-4072-b47c-1cbaac232b46/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/5b1f5bdc-3aa1-46ab-bbfb-f932c5be6588/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Arjun Gupta, Xi Victoria Lin, Chunyuan Zhang, Michel Galley, Jianfeng Gao, and Carlos Guestrin Ferrer. Robust compositional visual reasoning via language-guided neural module networks. In Advances in Neural Information Processing Systems (NeurIPS), 2021.</span></p></td><td><p dir="ltr"><span>No title or author match. This</span><a href="https://proceedings.neurips.cc/paper/2021/hash/5bd53571b97884635d13910db49626bc-Abstract.html"><span> </span><span>paper</span></a><span> has a similar title and matches publication.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=1mILyDyPDf"><span>MTRec: Learning to Align with User Preferences via Mental Reward Models</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/b570e1ce-4b4d-47f6-bc0a-eb5ad2516ef4/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/f7020dcf-c4a8-455c-9649-b242881573a7/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Diederik P. Kingma and Jimmy Ba. Deepfm: a factorization-machine based neural network for ctr prediction. In International Conference on Learning Representations, 2015.</span></p></td><td><p dir="ltr"><span>Title matches this</span><a href="https://www.ijcai.org/proceedings/2017/0239.pdf"><span> paper</span></a><span>. Authors, date, and publisher match this</span><a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=yyIoQu4AAAAJ&amp;cstart=20&amp;pagesize=80&amp;sortby=pubdate&amp;citation_for_view=yyIoQu4AAAAJ:_tF6a-HnqWAC"><span> paper.</span></a></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=1wmP48quNb"><span>Redefining Experts: Interpretable Decomposition of Language Models for Toxicity Mitigation</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/4c559ec8-804f-4071-94ad-d08ed30a9281/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/f0e35c1a-543e-4aca-8aaa-a890af1c3bff/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Weijia Xu, Xing Niu, and Marine Carpuat. Controlling toxicity in neural machine translation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 4245-4256, 2020.</span></p></td><td><p dir="ltr"><span>Authors, publisher and date match this</span><a href="https://aclanthology.org/2020.findings-emnlp.182/"><span> paper.</span></a><span> Title and page numbers don't match.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=1wmP48quNb"><span>Redefining Experts: Interpretable Decomposition of Language Models for Toxicity Mitigation</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/4c559ec8-804f-4071-94ad-d08ed30a9281/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/f0e35c1a-543e-4aca-8aaa-a890af1c3bff/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Xiang Zhang, Xuehai Wei, Xian Zhang, and Xue Zhang. Adversarial attacks and defenses in toxicity detection: A survey. In Proceedings of the 2020 International Joint Conference on Neural Networks (IJCNN), pages 1-8. IEEE, 2020.</span></p></td><td><p dir="ltr"><span>No author or title match. Doesn't exist in</span><a href="https://www.proceedings.com/content/055/055939webtoc.pdf"><span> publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=2DAvXR77xh"><span>Self-supervised Learning of Echocardiographic Video Representations via Online Cluster Distillation</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/c046c36d-ea1f-4727-9d04-41069e4532f8/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/8ed0a8fe-a6de-473d-af79-5f9684530ab9/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Fenglin Ding, Debesh Jha, Maria Härgestam, Pål Halvorsen, Michael A Riegler, Dag Johansen, Ronny Hänsch, and Håvard Stensland. Vits: Vision transformer for video self-supervised pretraining of surgical phase recognition. In International Conference on Medical Image Computing and Computer-Assisted Intervention, pages 293-302. Springer, 2022.</span></p></td><td><p dir="ltr"><span>No title or author match. Proceedings from this conference are split into</span><a href="https://conferences.miccai.org/2022/en/PROCEEDINGS.html"><span> volumes</span></a><span>, but the citation doesn't have a volume number.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=4FUdUFvvmp"><span>PANTHER: Generative Pretraining Beyond Language for Sequential User Behavior Modeling</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/0f741e52-f068-4bd5-b86a-6be3d5a867ff/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/b385a81c-7f8a-4bec-ac84-faf84a1fa18d/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Humberto Acevedo-Viloria, Juan Martinez, and Maria Garcia. Relational graph convolutional networks for financial fraud detection. IEEE Transactions on Knowledge and Data Engineering, 33(7):1357-1370, 2021. doi: 10.1109/TKDE.2020.3007655.</span></p></td><td><p dir="ltr"><span>No author or title match. Doesn't exist in the cited</span><a href="https://dblp.org/db/journals/tkde/tkde33.html"><span> publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=4FUdUFvvmp"><span>PANTHER: Generative Pretraining Beyond Language for Sequential User Behavior Modeling</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/0f741e52-f068-4bd5-b86a-6be3d5a867ff/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/b385a81c-7f8a-4bec-ac84-faf84a1fa18d/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Majid Zolghadr, Mohsen Jamali, and Jiawei Zhang. Diffurecsys: Diffusion-based generative modeling for sequential recommendation. Proceedings of the ACM Web Conference (WWW), pages 2156-2165, 2024. doi: 10.1145/3545678.3557899.</span></p></td><td><p dir="ltr"><span>No author or title match. DOI doesn't exist.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=4JLZsmWBJf"><span>LiteReality: Graphic-Ready 3D Scene Reconstruction from RGB-D Scans</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/98128158-bd97-40a1-a60c-0594f31a2e78/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/f12d9556-c5fb-4c0b-8d0c-f4926077e7ea/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Bernd Kerbl, Thomas Müller, and Paolo Favaro. Efficient 3d gaussian splatting for real-time neural rendering. In CVPR, 2022. 2, 3</span></p></td><td><p dir="ltr"><span>Loosely matches this</span><a href="https://arxiv.org/abs/2308.04079"><span> article,</span></a><span> but only one author and part of the title actually match.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=4JLZsmWBJf"><span>LiteReality: Graphic-Ready 3D Scene Reconstruction from RGB-D Scans</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/98128158-bd97-40a1-a60c-0594f31a2e78/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/f12d9556-c5fb-4c0b-8d0c-f4926077e7ea/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Punchana Khungurn, Edward H. Adelson, Julie Dorsey, and Holly Rushmeier. Matching real-world material appearance. TPAMI, 2015. 6</span></p></td><td><p dir="ltr"><span>No clear match. Two authors and the subject match this</span><a href="https://dl.acm.org/doi/10.1145/1198555.1198694"><span> article</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=4TUpqyDJbz"><span>When and How Unlabeled Data Provably Improve In-Context Learning</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/37cb8b5f-1aed-42fc-84eb-a56db01f1dcb/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/7cfc4dcd-dfea-4b65-b42e-c4c07b8f5c3d/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Ashish Kumar, Logan Engstrom, Andrew Ilyas, and Dimitris Tsipras. Understanding self-training for gradient-boosted trees. In Advances in Neural Information Processing Systems (NeurIPS), volume 33, pp. 1651-1662, 2020.</span></p></td><td><p dir="ltr"><span>No title or author match. Doesn't exist in</span><a href="https://papers.nips.cc/paper/2020"><span> publication.</span></a></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=4TUpqyDJbz"><span>When and How Unlabeled Data Provably Improve In-Context Learning</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/37cb8b5f-1aed-42fc-84eb-a56db01f1dcb/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/7cfc4dcd-dfea-4b65-b42e-c4c07b8f5c3d/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Chuang Fan, Shipeng Liu, Seyed Motamed, Shiyu Zhong, Silvio Savarese, Juan Carlos Niebles, Anima Anandkumar, Adrien Gaidon, and Stefan Scherer. Expectation maximization pseudo labels. arXiv preprint arXiv:2305.01747, 2023.</span></p></td><td><p dir="ltr"><span>This paper</span><a href="https://arxiv.org/abs/2305.01747v2"><span> exists,</span></a><span> but all the authors are fabricated.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=6uwV6ytamU"><span>DualCnst: Enhancing Zero-Shot Out-of-Distribution Detection via Text-Image Consistency in Vision-Language Models</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/5241c346-4190-4e44-813c-65073c84946b/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/c1855921-693a-4379-b5d3-4c0d95e356ff/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>T. Qiao, W. Liu, Z. Xie, H. Xu, J. Lin, J. Huang, and Y. Yang, "Clip-score: A robust scoring metric for text-to-image generation," arXiv preprint arXiv:2201.07519, 2022.</span></p></td><td><p dir="ltr"><span>No clear author or title matches. Title loosely matches this</span><a href="https://arxiv.org/abs/2104.08718"><span> article</span></a><span>. ArXiv ID leads</span><a href="https://arxiv.org/abs/2201.07519"><span> here</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=7VN0iICXZj"><span>Optimal Rates for Generalization of Gradient Descent for Deep ReLU Classification</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/af669229-94a7-4343-abf7-9ce3af831e02/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/3db22d99-5daa-44fd-8baa-9abbeb29606d/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Yunwen Lei, Puyu Wang, Yiming Ying, and Ding-Xuan Zhou. Optimization and generalization of gradient descent for shallow relu networks with minimal width. preprint, 2024.</span></p></td><td><p dir="ltr"><span>No title match. Authors match this</span><a href="https://arxiv.org/abs/2209.08005"><span> paper.</span></a></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=7WPi6VbtH0"><span>GeoDynamics: A Geometric State‑Space Neural Network for Understanding Brain Dynamics on Riemannian Manifolds</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/c15712b0-a37a-40a1-add6-d4a8f98443ff/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/bf8fcb05-9de3-4606-9956-624d8572e467/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Uher, R., Goodman, R., Moutoussis, M., Brammer, M., Williams, S.C.R., Dolan, R.J.: Cognitive and neural predictors of response to cognitive behavioral therapy for depression: a review of the evidence. Journal of Affective Disorders 169, 94-104 (2014)</span></p></td><td><p dir="ltr"><span>No exact title or author match. Loose title match with this</span><a href="https://www.cambridge.org/core/journals/psychological-medicine/article/abs/neural-predictors-and-effects-of-cognitive-behavioral-therapy-for-depression-the-role-of-emotional-reactivity-and-regulation/B8C3EDBA14E972910900CEDC460033D4"><span> article</span></a><span>. Doesn't exist in the</span><a href="https://www.clinicalkey.com/#!/browse/toc/1-s2.0-S0165032714X00157/null/journalIssue"><span> journal volume</span></a></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=Ap8OIosN8p"><span>Robust Label Proportions Learning</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/61d21fa6-24be-4cb6-9bde-5c80d5165916/share"><span>Scan</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/aa5f2722-47c4-46e0-852e-432a8b37b6e9/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Junyeong Lee, Yiseong Kim, Seungju Park, and Hyunjik Lee. Softmatch: Addressing the quantity-quality trade-off in semi-supervised learning. In Advances in Neural Information Processing Systems (NeurIPS), volume 36, pages 18315-18327, 2023.</span></p></td><td><p dir="ltr"><span>Title matches this</span><a href="https://arxiv.org/abs/2301.10921"><span> paper</span></a><span>. No match in NeurIPS</span><a href="https://proceedings.neurips.cc/paper_files/paper/2023"><span> volume 36</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=AmZ7uHDJiR"><span>NFL-BA: Near-Field Light Bundle Adjustment for SLAM in Dynamic Lighting</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/63f2339b-a3a4-4135-b056-e125dd9301bf/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/b597ad2c-edd3-47e5-9dbd-473dce8fd862/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Z. Zhu, T. Yu, X. Zhang, J. Li, Y. Zhang, and Y. Fu. Neuralrgb-d: Neural representations for depth estimation and scene mapping. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2022.</span></p></td><td><p dir="ltr"><span>No author or title match. Doesn't exist in</span><a href="https://www.computer.org/csdl/proceedings/cvpr/2022/1H1gVMlkl32"><span> publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=AmZ7uHDJiR"><span>NFL-BA: Near-Field Light Bundle Adjustment for SLAM in Dynamic Lighting</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/63f2339b-a3a4-4135-b056-e125dd9301bf/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/b597ad2c-edd3-47e5-9dbd-473dce8fd862/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Y. Zhang, M. Oswald, and D. Cremers. Airslam: Illumination-invariant hybrid slam. In International Conference on Computer Vision (ICCV), pages 2345-2354, 2023.</span></p></td><td><p dir="ltr"><span>No author or title match. Doesn't exist in</span><a href="https://csdl-downloads.ieeecomputer.org/proceedings/iccv/2023/0718/00/071800z005.pdf?Expires=1767122670&amp;Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jc2RsLWRvd25sb2Fkcy5pZWVlY29tcHV0ZXIub3JnL3Byb2NlZWRpbmdzL2ljY3YvMjAyMy8wNzE4LzAwLzA3MTgwMHowMDUucGRmIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNzY3MTIyNjcwfX19XX0_&amp;Signature=QX3vcUyMPs0JlLXc5-PvUoUQA908LDFqmUSVBX6FGn~ZKDJiKwNTMZLWR2RM546c91C-4nBK-A50KWf7mu0ewk7x~M4n60WALqUvJnl-gL~0lHMysGZav01wv2Z4nzqDT4HBd-25SQt7pC0eGQEQvKYnfYpsbU58VJE4t32zO6JCV2HItuM~wVL53gYjASY0uO50l0QFDZWhZHhjb2R0V0ks1dTZEHnjH1dDoVq7wBb38YRP8u6jASw4SjF3r5zdkmUePjJmUWIVjkDtzpMeAcCA8hsJZHk5Nnwj90SJkRdnSvpeV1357U~KC9AKe56U~7ov7umxQNQM7bia-skMgw__&amp;Key-Pair-Id=K12PMWTCQBDMDT"><span> publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=BND9CutZf6"><span>Geometric Imbalance in Semi-Supervised Node Classification</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/ea4059e3-64e1-4f58-a594-0f47c455fe30/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/a7f949e6-b871-43f7-9d34-46a562598254/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Yihong Zhu, Junxian Li, Xianfeng Han, Shirui Pan, Liang Yao, and Chengqi Wang. Spectral contrastive graph clustering. In International Conference on Learning Representations, 2022.</span></p></td><td><p dir="ltr"><span>No title or author match. This paper has a similar</span><a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320325003310"><span> title,</span></a><span> but there's no match in the ICLR 2022</span><a href="https://iclr.cc/virtual/2022/papers.html?search=&amp;filter=title"><span> database</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=BND9CutZf6"><span>Geometric Imbalance in Semi-Supervised Node Classification</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/ea4059e3-64e1-4f58-a594-0f47c455fe30/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/a7f949e6-b871-43f7-9d34-46a562598254/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Ming Zhong, Han Liu, Weizhu Zhang, Houyu Wang, Xiang Li, Maosong Sun, and Xu Han. Hyperbolic and spherical embeddings for long-tail entities. In ACL, pages 5491-5501, 2021.</span></p></td><td><p dir="ltr"><span>No author or title match. Doesn't exist</span><a href="https://aclanthology.org/volumes/2021.acl-long/"><span> publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=BpSGN4pErp"><span>NUTS: Eddy-Robust Reconstruction of Surface Ocean Nutrients via Two-Scale Modeling</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/12ed22af-ea9c-4272-80c8-397c50a7c3e8/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/826759cb-e770-42d1-baa8-ee293799d45e/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Ye Gao, Robert Tardif, Jiale Cao, and Tapio Schneider. Artificial intelligence reconstructs missing climate information. Nature Geoscience, 17:158-164, 2024. doi: 10.1038/s41561-023-01297-2.</span></p></td><td><p dir="ltr"><span>Title and publisher match this</span><a href="https://www.nature.com/articles/s41561-020-0582-5#citeas"><span> article</span></a><span>. Issue, page numbers, and year match this</span><a href="https://www.nature.com/articles/s41561-023-01371-4#citeas"><span> article</span></a><span>. DOI is fabricated.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=BpSGN4pErp"><span>NUTS: Eddy-Robust Reconstruction of Surface Ocean Nutrients via Two-Scale Modeling</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/12ed22af-ea9c-4272-80c8-397c50a7c3e8/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/826759cb-e770-42d1-baa8-ee293799d45e/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Étienne Pardoux and Alexander Yu Veretennikov. Poisson equation for multiscale diffusions. Journal of Mathematical Sciences, 111(3):3713-3719, 2002.</span></p></td><td><p dir="ltr"><span>Authors have frequently published together on the "</span><a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C5&amp;q=author%3AVeretennikov+author%3APardoux&amp;btnG="><span>poisson equation</span></a><span>", but this title doesn't match any of their publications. Doesn't exist in</span><a href="https://link.springer.com/journal/10958/volumes-and-issues/111-3"><span> publication volume/issue</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=CH76rSKWZr"><span>Test-Time Adaptation of Vision-Language Models for Open-Vocabulary Semantic Segmentation</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/6da6e9df-3687-476e-a55f-cc16c272616b/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/20d02652-f460-4564-9a4f-826f0c9f14ee/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Charanpal D Mummadi, Matthias Arens, and Thomas Brox. Test-time adaptation for continual semantic segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 11828-11837, 2021.</span></p></td><td><p dir="ltr"><span>No title or author match. Doesn't exist in</span><a href="https://www.computer.org/csdl/proceedings/cvpr/2021/1yeHGyRsuys"><span> publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=CH76rSKWZr"><span>Test-Time Adaptation of Vision-Language Models for Open-Vocabulary Semantic Segmentation</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/6da6e9df-3687-476e-a55f-cc16c272616b/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/20d02652-f460-4564-9a4f-826f0c9f14ee/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Jiacheng He, Zhilu Zhang, Zhen Wang, and Yan Huang. Autoencoder based test-time adaptation for semantic segmentation. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 998-1007, 2021.</span></p></td><td><p dir="ltr"><span>No author or title match. Doesn't exist in</span><a href="https://www.computer.org/csdl/proceedings/iccv/2021/1BmEezmpGrm"><span> publication.</span></a></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=EMa1ih7Wdt"><span>Global Minimizers of ℓp-Regularized Objectives Yield the Sparsest ReLU Neural Networks</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/0f8cd2db-21a2-4dd8-8bf3-d227f4009f29/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/420438d8-dad5-4733-8efd-c7b74e17d66a/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>M. Gong, F. Yu, J. Zhang, and D. Tao. Efficient $\ell_{p}$ norm regularization for learning sparsity in deep neural networks. IEEE Transactions on Neural Networks and Learning Systems, 33(10): $5381-5392,2022</span></p></td><td><p dir="ltr"><span>No title or author match.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=FfccSikDfZ"><span>SHAP Meets Tensor Networks: Provably Tractable Explanations with Parallelism</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/9fc2825a-e8dc-4cbb-934c-b2aed237084a/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/c51b0bd9-d03f-49d8-b916-b547609815e7/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Mihail Stoian, Richard Milbradt, and Christian Mendl. NP-Hardness of Optimal TensorNetwork Contraction and Polynomial-Time Algorithms for Tree Tensor Networks. Quantum, 6:e119, 2022.</span></p></td><td><p dir="ltr"><span>The authors match this</span><a href="https://epubs.siam.org/doi/10.1137/23M161286X"><span> article</span></a><span> and the title is similar. However, the year, publisher and other data don't match. This article didn't appear in the</span><a href="https://quantum-journal.org/volumes/6/"><span> 2022 Quantum volume</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=FfccSikDfZ"><span>SHAP Meets Tensor Networks: Provably Tractable Explanations with Parallelism</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/9fc2825a-e8dc-4cbb-934c-b2aed237084a/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/c51b0bd9-d03f-49d8-b916-b547609815e7/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Jianyu Xu, Wei Li, and Ming Zhao. Complexity of Optimal Tensor Network Contraction Sequences. Journal of Computational Physics, 480:112237, 2023.</span></p></td><td><p dir="ltr"><span>No title or author match. Doesn't exist in</span><a href="https://www.sciencedirect.com/journal/journal-of-computational-physics/vol/480/suppl/C"><span> publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=FzfYoUp8F1"><span>Learning World Models for Interactive Video Generation</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/052a28f8-81e1-4e85-81c8-433d06a506ae/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/b52114de-dfe5-424a-92bf-b9e08d4e46ac/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Patrick Esser, Robin Rombach, and Björn Ommer. Structure-aware video generation with latent diffusion models. arXiv preprint arXiv:2303.07332, 2023.</span></p></td><td><p dir="ltr"><span>Authors match this</span><a href="https://arxiv.org/abs/2012.09841"><span> article</span></a><span>. ArXiv ID leads to a different</span><a href="https://arxiv.org/abs/2303.07332"><span> article.</span></a></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=GPTI9GNAYH"><span>Fourier Token Merging: Understanding and Capitalizing Frequency Domain for Efficient Image Generation</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/c1c42a77-2646-46d2-adec-a476c090df28/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/43100616-900c-4d09-b652-0ae59fbb2221/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Lele Xu, Chen Lin, Hongyu Zhao, and et al. Gaborvit: Global attention with local frequency awareness. In European Conference on Computer Vision (ECCV), 2022.</span></p></td><td><p dir="ltr"><span>No author or title match. No match in</span><a href="https://www.ecva.net/papers.php"><span> publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=GPTI9GNAYH"><span>Fourier Token Merging: Understanding and Capitalizing Frequency Domain for Efficient Image Generation</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/c1c42a77-2646-46d2-adec-a476c090df28/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/43100616-900c-4d09-b652-0ae59fbb2221/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Yoonwoo Lee, Jaehyeong Kang, Namil Kim, Jinwoo Shin, and Honglak Lee. Structured fast fourier transform attention for vision transformers. In Advances in Neural Information Processing Systems (NeurIPS), 2022.</span></p></td><td><p dir="ltr"><span>No author or title match. Doesn't exist in</span><a href="https://proceedings.neurips.cc/paper/2022"><span> publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=GPTI9GNAYH"><span>Fourier Token Merging: Understanding and Capitalizing Frequency Domain for Efficient Image Generation</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/c1c42a77-2646-46d2-adec-a476c090df28/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/43100616-900c-4d09-b652-0ae59fbb2221/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Siyuan Gong, Alan Yu, Xiaohan Chen, Yinpeng Lin, and Larry S Davis. Vision transformer compression: Early exiting and token pruning. In Advances in Neural Information Processing Systems (NeurIPS), 2021.</span></p></td><td><p dir="ltr"><span>No author or title match. No match in</span><a href="https://papers.nips.cc/paper_files/paper/2021"><span> </span><span>publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=GPTI9GNAYH"><span>Fourier Token Merging: Understanding and Capitalizing Frequency Domain for Efficient Image Generation</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/c1c42a77-2646-46d2-adec-a476c090df28/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/43100616-900c-4d09-b652-0ae59fbb2221/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Jiuxiang Shi, Zuxuan Wu, and Dahua Lin. Token-aware adaptive sampling for efficient diffusion models. In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023.</span></p></td><td><p dir="ltr"><span>No author or title match. Doesn't exist in</span><a href="https://www.computer.org/csdl/proceedings/cvpr/2023/1PONOShHStG"><span> </span><span>publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=GPTI9GNAYH"><span>Fourier Token Merging: Understanding and Capitalizing Frequency Domain for Efficient Image Generation</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/c1c42a77-2646-46d2-adec-a476c090df28/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/43100616-900c-4d09-b652-0ae59fbb2221/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Raphael Muller, Simon Kornblith, and Geoffrey Hinton. Adavit: Adaptive tokens for efficient vision transformer. In Proceedings of the International Conference on Machine Learning (ICML), 2021.</span></p></td><td><p dir="ltr"><span>Authors match this</span><a href="https://proceedings.neurips.cc/paper_files/paper/2019/file/f1748d6b0fd9d439f71450117eba2725-Paper.pdf"><span> </span><span>article.</span></a><span> Title matches this</span><a href="https://proceedings.neurips.cc/paper_files/paper/2019/file/f1748d6b0fd9d439f71450117eba2725-Paper.pdf"><span> </span><span>article</span></a><span>. No match in</span><a href="https://icml.cc/virtual/2021/papers.html?search=Adaptive+tokens"><span> </span><span>publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=GPTI9GNAYH"><span>Fourier Token Merging: Understanding and Capitalizing Frequency Domain for Efficient Image Generation</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/c1c42a77-2646-46d2-adec-a476c090df28/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/43100616-900c-4d09-b652-0ae59fbb2221/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Xin Wang, Anlin Chen, Lihui Xie, Xin Jin, Cheng Wang, and Ping Luo. Not all tokens are equal: Efficient transformer for tokenization and beyond. In Advances in Neural Information Processing Systems (NeurIPS), 2021.</span></p></td><td><p dir="ltr"><span>No author or title match. This</span><a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zeng_Not_All_Tokens_Are_Equal_Human-Centric_Visual_Analysis_via_Token_CVPR_2022_paper.pdf"><span> </span><span>article</span></a><span> title is similar. No match in</span><a href="https://proceedings.neurips.cc/paper/2021"><span> </span><span>publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=HdY8CCHife"><span>A Unified Stability Analysis of SAM vs SGD: Role of Data Coherence and Emergence of Simplicity Bias</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/14695743-9825-4aef-8e88-c8f54e101b9a/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/1db86c77-b6f6-4253-8f57-aa319bddff2b/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Z. Chen and N. Flammarion. When and why sam generalizes better: An optimization perspective. arXiv preprint arXiv:2206.09267, 2022.</span></p></td><td><p dir="ltr"><span>No author or title match. ArXiv ID leads to a different</span><a href="https://arxiv.org/abs/2206.09267"><span> paper</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=HdY8CCHife"><span>A Unified Stability Analysis of SAM vs SGD: Role of Data Coherence and Emergence of Simplicity Bias</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/14695743-9825-4aef-8e88-c8f54e101b9a/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/1db86c77-b6f6-4253-8f57-aa319bddff2b/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>K. A. Sankararaman, S. Sankararaman, H. Pandey, S. Ganguli, and F. Bromberg. The impact of neural network overparameterization on gradient confusion and stochastic gradient descent. In 37th International Conference on Machine Learning (ICML), pages 8469-8479, 2020.</span></p></td><td><p dir="ltr"><span>This</span><a href="https://dl.acm.org/doi/abs/10.5555/3524938.3525723"><span> paper</span></a><span> is a match, but all authors but the first (K. A. Sankararaman) are fabricated.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=I64ZLbUP6u"><span>MaterialRefGS: Reflective Gaussian Splatting with Multi-view Consistent Material Inference</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/d9683c9b-7ffc-4c40-b0b8-df3d72ee84e9/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/ed653d2d-71c6-4967-9306-d2c3c9bb5632/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Why Physically-Based Rendering. Physically-based rendering. Procedia IUTAM, 13(127137):3, 2015 .</span></p></td><td><p dir="ltr"><span>No author given and title appears to be garbled. Publisher, issue, year, and pages match this</span><a href="https://www.sciencedirect.com/journal/procedia-iutam/vol/13/suppl/C"><span> article</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=IJGEtuVqwf"><span>Robust Reinforcement Learning in Finance: Modeling Market Impact with Elliptic Uncertainty Sets</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/fbf50b6a-faa1-4e52-ae0d-0efb52cb3400/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/52b94988-efd5-4412-81e1-a6cc32010909/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Pierre Casgrain, Anirudh Kulkarni, and Nicholas Watters. Learning to trade with continuous action spaces: Application to market making. arXiv preprint arXiv:2303.08603, 2023.</span></p></td><td><p dir="ltr"><span>No title or author match. ArXiv ID matches a different</span><a href="https://arxiv.org/abs/2303.08603"><span> article</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=IJGEtuVqwf"><span>Robust Reinforcement Learning in Finance: Modeling Market Impact with Elliptic Uncertainty Sets</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/fbf50b6a-faa1-4e52-ae0d-0efb52cb3400/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/52b94988-efd5-4412-81e1-a6cc32010909/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Z Ning and Y K Kwok. Q-learning for option pricing and hedging with transaction costs. Applied Economics, 52(55):6033-6048, 2020.</span></p></td><td><p dir="ltr"><span>No author or title match. No match in journal</span><a href="https://www.tandfonline.com/toc/raec20/52/55?nav=tocList"><span> volume/issue</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=IJGEtuVqwf"><span>Robust Reinforcement Learning in Finance: Modeling Market Impact with Elliptic Uncertainty Sets</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/fbf50b6a-faa1-4e52-ae0d-0efb52cb3400/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/52b94988-efd5-4412-81e1-a6cc32010909/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>W L Chan and R O Shelton. Can machine learning improve delta hedging? Journal of Derivatives, $9(1): 39-56,2001$.</span></p></td><td><p dir="ltr"><a href="https://www.pm-research.com/content/iijderiv/9/1"><span>No author or title match. No match in </span><span>journal volume/issue</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=IJGEtuVqwf"><span>Robust Reinforcement Learning in Finance: Modeling Market Impact with Elliptic Uncertainty Sets</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/fbf50b6a-faa1-4e52-ae0d-0efb52cb3400/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/52b94988-efd5-4412-81e1-a6cc32010909/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Petter N Kolm, Sebastian Krügel, and Sergiy V Zadorozhnyi. Reinforcement learning for optimal hedging. The Journal of Trading, 14(4):4-17, 2019.</span></p></td><td><p dir="ltr"><a href="https://www.pm-research.com/content/iijtrade"><span>No author or title match. There is no volume 14 of this </span><span>journal.</span></a></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=IJGEtuVqwf"><span>Robust Reinforcement Learning in Finance: Modeling Market Impact with Elliptic Uncertainty Sets</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/fbf50b6a-faa1-4e52-ae0d-0efb52cb3400/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/52b94988-efd5-4412-81e1-a6cc32010909/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Kyung Hyun Park, Hyeong Jin Kim, and Woo Chang Kim. Deep reinforcement learning for limit order book-based market making. Expert Systems with Applications, 169:114338, 2021.</span></p></td><td><p dir="ltr"><a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417420310265"><span>No author or title match. Publisher ID matches this </span><span>article</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=II0T40Q785"><span>FlowMixer: A Depth-Agnostic Neural Architecture for Interpretable Spatiotemporal Forecasting</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/f2e2340f-61cd-40b9-86e2-d2d7323beec3/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/95868fb0-5d7a-4b65-ab5c-4d06e2e29dec/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Moonseop Han and Elizabeth Qian. Robust prediction of dynamical systems with structured neural networks: Long-term behavior and chaos. Physica D: Nonlinear Phenomena, 427:133006, 2021.</span></p></td><td><p dir="ltr"><span>No author or title match. Publisher ID matches this</span><a href="https://www.sciencedirect.com/science/article/abs/pii/S0167278921001639"><span> article</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=II0T40Q785"><span>FlowMixer: A Depth-Agnostic Neural Architecture for Interpretable Spatiotemporal Forecasting</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/f2e2340f-61cd-40b9-86e2-d2d7323beec3/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/95868fb0-5d7a-4b65-ab5c-4d06e2e29dec/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Bart De Schutter and Serge P Hoogendoorn. Modeling and control of freeway traffic flow by state space neural networks. Neural Computing and Applications, 17(2):175-185, 2008.</span></p></td><td><p dir="ltr"><span>No title match, although Schutter and Hoogendorn have written or coauthored several related papers (</span><a href="https://scispace.com/pdf/model-based-control-of-intelligent-traffic-networks-5o7t1ux396.pdf"><span>example</span></a><span> and</span><a href="https://ieeexplore.ieee.org/document/8283509"><span> example</span></a><span>). Journal volume/issue matches an unrelated</span><a href="https://link.springer.com/article/10.1007/s00521-006-0080-8"><span> article</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=II0T40Q785"><span>FlowMixer: A Depth-Agnostic Neural Architecture for Interpretable Spatiotemporal Forecasting</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/f2e2340f-61cd-40b9-86e2-d2d7323beec3/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/95868fb0-5d7a-4b65-ab5c-4d06e2e29dec/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Jaideep Pathak, Brian R Hunt, Georg M Goerg, and Themistoklis P Sapsis. Data-driven prediction of chaotic dynamics: Methods, challenges, and opportunities. Annual Review of Condensed Matter Physics, 14:379-401, 2023.</span></p></td><td><p dir="ltr"><a href="https://www.annualreviews.org/content/journals/conmatphys/14/1"><span>No author or title match. No match in </span><span>journal volume</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=II0T40Q785"><span>FlowMixer: A Depth-Agnostic Neural Architecture for Interpretable Spatiotemporal Forecasting</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/f2e2340f-61cd-40b9-86e2-d2d7323beec3/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/95868fb0-5d7a-4b65-ab5c-4d06e2e29dec/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Alejandro Güemes, Stefano Discetti, and Andrea Ianiro. Coarse-grained physics-based prediction of three-dimensional unsteady flows via neural networks. Science Advances, 7(46):eabj0751, 2021.</span></p></td><td><p dir="ltr"><a href="https://www.science.org/toc/sciadv/7/46"><span>No title or author match. Doesn't exist in </span><span>journal volume/issue</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=IIgVYnadfR"><span>BNMusic: Blending Environmental Noises into Personalized Music</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/fd47718b-20a1-493f-9876-dc623513a506/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/4158f8bf-0292-41c8-b920-c2699933114f/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Jeongseung Park, Minseon Yang, Minz Won Park, and Geonseok Lee. Diffsound: Differential sound manipulation with a few-shot supervision. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pages 1767-1775, 2021.</span></p></td><td><p dir="ltr"><span>No title or author match. Doesn't exist in</span><a href="https://www.computer.org/csdl/proceedings/cvprw/2021/1wzs0vrjyWQ"><span> publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=JSbVO7dNYE"><span>Towards Multiscale Graph-based Protein Learning with Geometric Secondary Structural Motifs</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/96641483-8df9-49f4-ac68-888fa22eb819/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/52bf51d1-e538-486c-83ae-60fa507d1103/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Wenxuan Sun, Tri Dao, Hongyu Zhuang, Zihang Dai, Albert Gu, and Christopher D Manning. Llamba: Efficient llms with mamba-based distillation. arXiv preprint arXiv:2502.14458, 2024.</span></p></td><td><p dir="ltr"><span>ArXiv ID leads to this</span><a href="https://arxiv.org/abs/2502.14458"><span> article</span></a><span> with a similar title and one matching author.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=JSbVO7dNYE"><span>Towards Multiscale Graph-based Protein Learning with Geometric Secondary Structural Motifs</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/96641483-8df9-49f4-ac68-888fa22eb819/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/52bf51d1-e538-486c-83ae-60fa507d1103/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Tri Dao, Shizhe Ma, Wenxuan Sun, Albert Gu, Sam Smith, Aapo Kyrola, Christopher D Manning, and Christopher Re. An empirical study of state space models for large language modeling. arXiv preprint arXiv:2406.07887, 2024.</span></p></td><td><p dir="ltr"><span>Two authors (Tri Dao and Albert Gu), the arXiv ID, and the year match this</span><a href="https://arxiv.org/abs/2406.07887"><span> paper</span></a><span>. However, the title is only a partial match.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=KQTp6ljvlo"><span>Fourier Clouds: Fast Bias Correction for Imbalanced Semi-Supervised Learning</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/2f6208a4-66b9-45ea-9396-a04409df4948/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/d41f986d-a44f-4aaa-9ea2-c1d46aed6fe5/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Junyan Zhu, Chenyang Li, Chao He, and et al. Freematch: A simple framework for long-tailed semi-supervised learning. In NeurIPS, 2021.</span></p></td><td><p dir="ltr"><span>No author or title match. This</span><a href="https://arxiv.org/pdf/2205.07246"><span> paper title</span></a><span> is very close, but it was published by ICLR 2023 not</span><a href="https://papers.nips.cc/paper_files/paper/2021"><span> NeurIPS 2021</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=LP4Q7tPMbs"><span>NormFit: A Lightweight Solution for Few-Shot Federated Learning with Non-IID Data</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/6977dbef-7a2b-4143-a4be-b69a426e2b56/share"><span>Scan</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/7277a269-f450-45f5-8cd7-75eaf6f485e2/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Yijie Zang et al. Fedclip: A federated learning framework for vision-language models. In NeurIPS, 2023.</span></p></td><td><p dir="ltr"><span>No author or title match, although this</span><a href="https://ieeexplore.ieee.org/document/10988823"><span> title</span></a><span> is close. No match in</span><a href="https://papers.nips.cc/paper_files/paper/2023"><span> publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=LsmUgStXby"><span>AI-Generated Video Detection via Perceptual Straightening</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/ccc2460e-0ef3-47b7-9d99-71e8df46ab6b/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/5e1821da-8518-413c-804d-030ed6824fcd/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Jiahui Liu and et al. Tall-swin: Thumbnail layout transformer for generalised deepfake video detection. In ICCV, 2023.</span></p></td><td><p dir="ltr"><a href="https://openaccess.thecvf.com/content/ICCV2023/html/Xu_TALL_Thumbnail_Layout_for_Deepfake_Video_Detection_ICCV_2023_paper.html"><span>No author or title match. A paper with a similar title appears in </span><span>publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=Lz5BUjArK4"><span>Multi-Expert Distributionally Robust Optimization for Out-of-Distribution Generalization</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/5627ac20-2221-4ca0-8857-4dea140b98e8/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/636f7851-a09e-4fd9-90e3-35c8602a4f8d/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Nitish Srivastava and Ruslan R Salakhutdinov. Discriminative features for fast frame-based phoneme classification. Neural networks, 47:17-23, 2013.</span></p></td><td><p dir="ltr"><span>No title match, but authors have published together previously (</span><a href="https://papers.nips.cc/paper_files/paper/2012/file/af21d0c97db2e27e13572cbf59eb343d-Paper.pdf"><span>example</span></a><span>). No match in</span><a href="https://www.sciencedirect.com/journal/neural-networks/vol/47/suppl/C"><span> </span><span>publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=ToNRHqX6xq"><span>MIP against Agent: Malicious Image Patches Hijacking Multimodal OS Agents</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/73c0dd26-0e0d-4b9c-a31d-6d9554120362/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/57179143-9c9b-462c-86a4-bd5041d88594/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Anh Tuan Nguyen, Shengping Li, and Chao Qin. Multimodal adversarial robustness: Attack and defense. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2021.</span></p></td><td><p dir="ltr"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9639884"><span>No author or title match. Doesn't exist in </span><span>publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=V1FlwrsseI"><span>ACT as Human: Multimodal Large Language Model Data Annotation with Critical Thinking</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/f2948a0f-8972-4269-b680-4ab68e14f2ec/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/11c6525d-e02d-4dd3-86a0-dfa3b544697e/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Jack Lau, Ankan Gayen, Philipp Tschandl, Gregory A Burns, Jiahong Yuan, Tanveer SyedaMahmood, and Mehdi Moradi. A dataset and exploration of models for understanding radiology images through dialogue. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 2575-2584, 2018.</span></p></td><td><p dir="ltr"><span>No author match. Title matches another hallucinated citation in this</span><a href="https://arxiv.org/html/2508.05244v1"><span> </span><span>paper</span></a><span>. Doesn't exist in</span><a href="https://aclanthology.org/events/emnlp-2018/#d18-1"><span> </span><span>publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=VN5bMTfSZS"><span>OCTDiff: Bridged Diffusion Model for Portable OCT Super-Resolution and Enhancement</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/61a6a3d3-6c3b-4663-934a-40f69f112b50/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/7362670b-7428-468f-882c-a6f7de6d90da/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Yikai Zhang et al. "Text-to-Image Diffusion Models with Customized Guidance". In: Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023.</span></p></td><td><p dir="ltr"><a href="https://www.computer.org/csdl/proceedings/iccv/2023/1TJc6RNOu8U"><span>No author or title match. Doesn't exist in </span><span>publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=VN5bMTfSZS"><span>OCTDiff: Bridged Diffusion Model for Portable OCT Super-Resolution and Enhancement</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/61a6a3d3-6c3b-4663-934a-40f69f112b50/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/7362670b-7428-468f-882c-a6f7de6d90da/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Author Song and AnotherAuthor Zhang. "Consistency in Diffusion Models: Improving Noise Embeddings". In: IEEE Transactions on Pattern Analysis and Machine Intelligence (2023). URL:</span><a href="https://arxiv.org/abs/2304.08787."><span> </span><span>https://arxiv.org/abs/2304.08787.</span></a></p></td><td><p dir="ltr"><span>No author or title match. This</span><a href="https://openreview.net/forum?id=59nCKifDtm"><span> </span><span>paper</span></a><span> has a similar title. ArXiv ID leads to unrelated</span><a href="https://arxiv.org/abs/2304.08787"><span> </span><span>paper.</span></a></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=W8xcKoJcrl"><span>Strategic Costs of Perceived Bias in Fair Selection</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/b00f841e-0e1d-4ae4-9a48-82b2891e6600/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/feb8886c-6917-4006-82e5-551cc7d0df58/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Claudia Goldin. Occupational choices and the gender wage gap. American Economic Review, 104(5):348-353, 2014.</span></p></td><td><p dir="ltr"><span>Author is a famous</span><a href="https://www.britannica.com/biography/Claudia-Goldin"><span> </span><span>economist</span></a><span>, but the title doesn't match any of her works. Journal and locators match this unrelated</span><a href="https://www.aeaweb.org/articles?id=10.1257/aer.104.5.348"><span> </span><span>article</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=XxR70zr9Sf"><span>Linear Transformers Implicitly Discover Unified Numerical Algorithms</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/d349a8d0-809b-42fb-a5e6-ee91f37fbcd3/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/b138bbcb-4f6a-4fc8-b85f-d09b1490fac7/share"><span>AI</span></a></p></td><td><p dir="ltr"><a href="https://distill.pub/2022/circuits/"><span>Olah, C., Elhage, N., Nanda, N., Schiefer, N., Jones, A., Henighan, T., and DasSarma, N. (2022). Transformer circuits. Distill, 7(3). </span><span>https://distill.pub/2022/circuits/.</span></a></p></td><td><p dir="ltr"><span>Most authors match this</span><a href="https://transformer-circuits.pub/2021/framework/index.html"><span> </span><span>paper</span></a><span>, but the title, publisher, and year are different. Doesn't exist in</span><a href="https://distill.pub/"><span> </span><span>publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=XxR70zr9Sf"><span>Linear Transformers Implicitly Discover Unified Numerical Algorithms</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/d349a8d0-809b-42fb-a5e6-ee91f37fbcd3/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/b138bbcb-4f6a-4fc8-b85f-d09b1490fac7/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Nanda, N. (2023). Progress in mechanistic interpretability: Reverse-engineering induction heads in GPT-2.</span></p></td><td><p dir="ltr"><a href="https://scholar.google.com/citations?hl=en&amp;user=GLnX3MkAAAAJ&amp;view_op=list_works&amp;sortby=pubdate"><span>No title match. Author may be </span><span>Neel Nanda</span></a><span>, who wrote several similar articles in 2023.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=YGIbwfNWot"><span>A Tri-Modal Multi-Agent Responsive Framework for Comprehensive 3D Object Annotation</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/41566db2-9a1a-44b4-bec4-c4dc7107cc17/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/6ddb0781-ed8d-4377-a396-08521c082562/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>J. Zhang and X. Li. Multi-agent systems for distributed problem solving: A framework for task decomposition and coordination. Procedia Computer Science, 55:1131-1138, 2015.</span></p></td><td><p dir="ltr"><a href="https://www.sciencedirect.com/journal/procedia-computer-science/vol/55/suppl/C?page=2"><span>No author or title match. Doesn't exist in </span><span>publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=YGIbwfNWot"><span>A Tri-Modal Multi-Agent Responsive Framework for Comprehensive 3D Object Annotation</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/41566db2-9a1a-44b4-bec4-c4dc7107cc17/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/6ddb0781-ed8d-4377-a396-08521c082562/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Erfan Aghasian, Shai Avidan, Piotr Dollar, and Justin Johnson. Hierarchical protocols for multi-agent 3d scene understanding. In CVPR, pages 7664-7673, 2021.</span></p></td><td><p dir="ltr"><a href="https://openaccess.thecvf.com/CVPR2021"><span>No author or title match. Doesn't exist in </span><span>publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=Ynwl0V1YH0"><span>Learning Grouped Lattice Vector Quantizers for Low-Bit LLM Compression</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/114aad0a-479c-4b46-a94c-8beeffe28d2b/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/edef15b3-6712-42c7-9aae-4a9a26ce5f45/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Itay Hubara, Matthieu Courbariaux, Daniel Soudry, Rami El-Yaniv, and Yoshua Bengio. Quantizing deep convolutional networks for efficient inference: A whitepaper. arXiv preprint arXiv:1612.01462, 2017.</span></p></td><td><p dir="ltr"><span>Authors mostly match this</span><a href="https://papers.nips.cc/paper_files/paper/2016/hash/d8330f857a17c53d217014ee776bfd50-Abstract.html"><span> </span><span>paper</span></a><span>. Title matches this</span><a href="https://arxiv.org/abs/1806.08342"><span> </span><span>paper.</span></a><span> ArXiv ID matches a third</span><a href="https://arxiv.org/abs/1612.01462"><span> </span><span>paper.</span></a></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=Ynwl0V1YH0"><span>Learning Grouped Lattice Vector Quantizers for Low-Bit LLM Compression</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/114aad0a-479c-4b46-a94c-8beeffe28d2b/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/edef15b3-6712-42c7-9aae-4a9a26ce5f45/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Zhiqiang Wang, Chao Zhang, Bing Li, Zhen Xu, and Zhiwei Li. A survey of model compression and acceleration for deep neural networks. ACM Computing Surveys, 54(7):1-34, 2021.</span></p></td><td><p dir="ltr"><span>No author match. Title matches this</span><a href="https://arxiv.org/abs/1710.09282"><span> </span><span>paper.</span></a><span> Doesn't exist in</span><a href="https://dl.acm.org/toc/csur/2022/54/7"><span> </span><span>publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=ZR2mdBrhJX"><span>PointMapPolicy: Structured Point Cloud Processing for Multi-Modal Imitation Learning</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/ff9ad094-e9be-468b-a618-fab14c568c21/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/684135a5-9a1e-4744-9c3a-cb8b0905a3dd/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Andrew Black et al. Zero-shot skill composition with semantic feature fusion. arXiv preprint arXiv:2310.08573, 2023.</span></p></td><td><p dir="ltr"><a href="https://arxiv.org/abs/2310.08573"><span>No title match. ArXiv ID leads to unrelated </span><span>paper.</span></a></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=ZR2mdBrhJX"><span>PointMapPolicy: Structured Point Cloud Processing for Multi-Modal Imitation Learning</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/ff9ad094-e9be-468b-a618-fab14c568c21/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/684135a5-9a1e-4744-9c3a-cb8b0905a3dd/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Yufei Wu, Kiran Alwala, Vivek Ganapathi, Sudeep Sharma, Yilun Chang, Yicheng Zhang, Yilun Zhou, et al. Susie: Scaling up instruction-following policies for robot manipulation. arXiv preprint arXiv:2402.17552, 2024.</span></p></td><td><p dir="ltr"><a href="https://www.arxiv.org/abs/2402.17552"><span>No author or title match. ArXiv ID leads to unrelated </span><span>article</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=Zb3QO7HLIj"><span>FLAME: Fast Long-context Adaptive Memory for Event-based Vision</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/1cbbae27-5545-40d2-8a1d-33baa8b71c4e/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/aa75cdb6-986a-43e1-9db6-7025ccdda5a6/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Zhipeng Zhang, Chang Liu, Shihan Wu, and Yan Zhao. EST: Event spatio-temporal transformer for object recognition with event cameras. In ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 1-5. IEEE, 2023.</span></p></td><td><p dir="ltr"><a href="https://dblp.org/db/conf/icassp/index.html"><span>No author or title match. Doesn't exist in </span><span>publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=Zb3QO7HLIj"><span>FLAME: Fast Long-context Adaptive Memory for Event-based Vision</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/1cbbae27-5545-40d2-8a1d-33baa8b71c4e/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/aa75cdb6-986a-43e1-9db6-7025ccdda5a6/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Daniel Gehrig, Mathias Gehrig, John Monaghan, and Davide Scaramuzza. Recurrent vision transformers for dense prediction. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops, pages 3139-3148, 2021.</span></p></td><td><p dir="ltr"><span>No author match, but this</span><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Ranftl_Vision_Transformers_for_Dense_Prediction_ICCV_2021_paper.pdf"><span> </span><span>paper</span></a><span> has a similar title. Doesn't exist in</span><a href="https://www.computer.org/csdl/proceedings/iccvw/2021/1yNhksNMpkQ"><span> </span><span>publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=emM7U3WKMO"><span>Diversity Is All You Need for Contrastive Learning: Spectral Bounds on Gradient Magnitudes</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/71876ca9-d9c9-4b73-a910-cbb5a61b722b/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/6ce64b84-9e77-4734-8a05-a0d4cb00de66/share"><span>AI</span></a><span>**</span></p></td><td><p dir="ltr"><span>Qiyang Du, Ozan Sener, and Silvio Savarese. Agree to disagree: Adaptive learning with gradient disagreement. In Advances in Neural Information Processing Systems (NeurIPS), 2021.</span></p></td><td><p dir="ltr"><span>No author or title match. Sener and Savarese have</span><a href="https://arxiv.org/abs/1708.00489"><span> </span><span>published</span></a><span> </span><span>together previously. Doesn't exist in</span><a href="https://proceedings.neurips.cc/paper/2021"><span> </span><span>publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=emM7U3WKMO"><span>Diversity Is All You Need for Contrastive Learning: Spectral Bounds on Gradient Magnitudes</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/71876ca9-d9c9-4b73-a910-cbb5a61b722b/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/6ce64b84-9e77-4734-8a05-a0d4cb00de66/share"><span>AI</span></a><span>**</span></p></td><td><p dir="ltr"><span>Longxuan Jing, Yu Tian, Yujun Pei, Yibing Shen, and Jiashi Feng. Understanding contrastive representation learning through alignment and uniformity on the hypersphere. In International Conference on Learning Representations (ICLR), 2022.</span></p></td><td><p dir="ltr"><span>No author match. Title matches this</span><a href="https://proceedings.mlr.press/v119/wang20k/wang20k.pdf"><span> </span><span>paper.</span></a><span> Doesn't exist in</span><a href="https://iclr.cc/virtual/2022/papers.html"><span> publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=gNiT81iag0"><span>TokenSwap: A Lightweight Method to Disrupt Memorized Sequences in LLMs</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/2c627437-707b-4434-aa97-0d13a90eabd3/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/27d5bf8f-c17e-456f-b9c2-acc4bdb7aea6/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Yair Leviathan, Clemens Rosenbaum, and Slav Petrov. Fast inference from transformers via speculative decoding. In ICML, 2023.</span></p></td><td><p dir="ltr"><a href="https://dl.acm.org/doi/10.5555/3618408.3619203"><span>Title, publisher, and date match this </span><span>paper</span></a><span>, but all authors except one surname (Leviathan) are different.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=gNiT81iag0"><span>TokenSwap: A Lightweight Method to Disrupt Memorized Sequences in LLMs</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/2c627437-707b-4434-aa97-0d13a90eabd3/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/27d5bf8f-c17e-456f-b9c2-acc4bdb7aea6/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Wenwen Chang, Tal Schuster, and Yann LeCun. Neural surgery for memorisation: Locating and removing verbatim recall neurons. In NeurIPS, 2024.</span></p></td><td><p dir="ltr"><a href="https://papers.nips.cc/paper_files/paper/2024"><span>No author or title match. Doesn't exist in </span><span>publication.</span></a></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=oBikm5Rshc"><span>Learning the Wrong Lessons: Syntactic-Domain Spurious Correlations in Language Models</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/ae7bf744-cbf7-4ef2-9ee1-3db00bcd5062/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/30a7d9af-5cf1-4251-acbf-0717f0432d6a/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>M. Garcia and A. Thompson. Applications of llms in legal document analysis. Journal of Legal Technology, 7(1):50-65, 2024.</span></p></td><td><p dir="ltr"><span>No author or title match. Publication doesn't exist.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=oBikm5Rshc"><span>Learning the Wrong Lessons: Syntactic-Domain Spurious Correlations in Language Models</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/ae7bf744-cbf7-4ef2-9ee1-3db00bcd5062/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/30a7d9af-5cf1-4251-acbf-0717f0432d6a/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>J. Smith and A. Patel. Leveraging large language models for financial forecasting. International Journal of Financial Technology, 9(2):101-115, 2024.</span></p></td><td><p dir="ltr"><span>No author or title match. Publication doesn't exist.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=pGRjDetCDM"><span>JADE: Joint Alignment and Deep Embedding for Multi-Slice Spatial Transcriptomics</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/c05dbbba-a778-4561-a553-fb18827f44ee/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/defdd83e-45cb-427d-95d7-c8fbaa757555/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>David Jones et al. Gpsa: Gene expression and histology-based spatial alignment. Nature Methods, 2023.</span></p></td><td><p dir="ltr"><a href="https://www.nature.com/nmeth/articles?type=article&amp;year=2023"><span>No author or title match. Doesn't exist in </span><span>publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=pGRjDetCDM"><span>JADE: Joint Alignment and Deep Embedding for Multi-Slice Spatial Transcriptomics</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/c05dbbba-a778-4561-a553-fb18827f44ee/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/defdd83e-45cb-427d-95d7-c8fbaa757555/share"><span>AI</span></a><span>*</span></p></td><td><p dir="ltr"><span>Zhihao Chen, Hantao Zhang, Yuhan Zhang, Zhanlin Hu, Quanquan Gu, Qing Zhang, and Shuo Suo. Slat: a transformer-based method for simultaneous alignment and clustering of spatial transcriptomics data. Nature Communications, 14(1):5548, 2023.</span></p></td><td><p dir="ltr"><span>No author or title match. Doesn't exist in publication.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=uih8cWS3JF"><span>Improved Regret Bounds for Linear Bandits with Heavy-Tailed Rewards</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/270a15e9-9a36-4b4a-8acb-ad91a8209bf7/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/f3bef20d-ea0a-4510-86e4-b9701136bee7/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>François Baccelli, Gérard H. Taché, and Etienne Altman. Flow complexity and heavytailed delays in packet networks. Performance Evaluation, 49(1-4):427-449, 2002.</span></p></td><td><p dir="ltr"><a href="https://dblp.org/db/journals/pe/pe49.html"><span>No author or title match. Doesn't exist in </span><span>publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=uih8cWS3JF"><span>Improved Regret Bounds for Linear Bandits with Heavy-Tailed Rewards</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/270a15e9-9a36-4b4a-8acb-ad91a8209bf7/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/f3bef20d-ea0a-4510-86e4-b9701136bee7/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Saravanan Jebarajakirthy, Paurav Shukla, and Prashant Palvia. Heavy-tailed distributions in online ad response: A marketing analytics perspective. Journal of Business Research, 124:818-830, 2021.</span></p></td><td><p dir="ltr"><a href="https://www.sciencedirect.com/journal/journal-of-business-research/vol/124/suppl/C"><span>No author or title match. Doesn't exist in </span><span>publication</span></a><span>.</span></p></td></tr><tr><td><p dir="ltr"><a href="https://openreview.net/forum?id=vKyiv67VWa"><span>AutoSciDACT: Automated Scientific Discovery through Contrastive Embedding and Hypothesis Testing</span></a></p></td><td><p dir="ltr"><a href="https://app.gptzero.me/documents/fb7a6411-f38b-48d9-8eab-7f32e6d006ab/share"><span>Sources</span></a></p><p dir="ltr"><a href="https://app.gptzero.me/documents/f3216beb-368a-433c-ac2f-9dd2badddf22/share"><span>AI</span></a></p></td><td><p dir="ltr"><span>Mehdi Azabou, Micah Weber, Wenlin Ma, et al. Mineclip: Multimodal neural exploration of clip latents for automatic video annotation. arXiv preprint arXiv:2210.02870, 2022.</span></p></td><td><p dir="ltr"><a href="https://arxiv.org/abs/2210.02870"><span>No author or title match. ArXiv ID leads to unrelated </span><span>article.</span></a></p></td></tr></tbody></table>
<!--kg-card-end: html-->
<hr><div data-layout="minimal">
                    
                        <p><span>Is there a specific report or published article you think we should check for hallucinations?</span></p>
                    
                    
                        <p><a href="https://docs.google.com/forms/d/e/1FAIpQLSdEGNCoZZWTWrddNHP8ZoUiqay9Qs1ndXPv2wpP1d3LnB7JoQ/viewform?usp=publish-editor">
                            Submit Here
                        </a>
                        
                    </p></div><h2 id="defining-hallucinated-citations">Defining Hallucinated Citations</h2><p>Given the high stakes for both authors and publishers, GPTZero's Hallucination Check is engineered to be accurate, transparent, and cautious. It uses our AI agent, trained in-house, to flag any citations in a document that can’t be found online. These flagged citations are not automatically hallucinations — many archival documents or unpublished works can’t be matched to an online source — but they indicate which sources require further human scrutiny. As always, we recommend that a human confirm that flagged citation is an AI-generated fake instead of the result of a more conventional error.</p><p>We define a vibe citation as a citation that likely resulted from the use of generative AI. Vibe citing results in errors common to LLM generations, but rare in human-written text, such as:</p><ol><li>Combining or paraphrasing the titles, author(s), and/or locators from one or more real sources</li><li>Fabricating the author(s), title, URL/DOI, and/or container (ex. publisher, journal, conference) of a source</li><li>Modifying the author(s) or title of a source by extrapolating a first name from an initial, dropping and/or adding authors, or paraphrasing the title.</li></ol><p>Our definition excludes obvious spelling mistakes, dead URLs, missing locators, and other errors that are plausibly human. The following table shows the difference between a real citation, a flawed citation, and a hallucinated citation according to our methodology. The differences are highlighted in red.</p>
<!--kg-card-begin: html-->
<table><colgroup><col width="204"><col width="244"><col width="176"></colgroup><tbody><tr><td><p dir="ltr"><span>Real Citation</span></p></td><td><p dir="ltr"><span>Flawed Citation</span></p></td><td><p dir="ltr"><span>Hallucinated Citation</span></p></td></tr><tr><td><p dir="ltr"><span>Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. nature, 521:436-444, 2015.</span></p></td><td><p dir="ltr"><span>Y.</span><span> LeCun, </span><span>Y. </span><span>Bengio, and </span><span>Geoff</span><span> Hinton. </span><span>Deep leaning</span><span>. nature, 521</span><span>(7553)</span><span>:436-444, 2015.</span></p></td><td><p dir="ltr"><span>Samuel LeCun Jackson</span><span>. Deep learning. </span><span>Science &amp;</span><span> Nature</span><span>: </span><span>23-45</span><span>, 20</span><span>21</span><span>.</span></p></td></tr><tr><td><p dir="ltr"><span>A. Yang, B. Zhang, B. Hui, B. Gao, B. Yu, C. Li, D. Liu, J. Tu, J. Zhou, J. Lin, et al. Qwen2.5–math technical report: Toward mathematical expert model via self-improvement. arXiv:2409.12122, 2024.</span></p></td><td><p dir="ltr"><span>A. Yang,&nbsp; </span><span>(missing author)</span><span>, B. Hui, B. Gao, B. Yu, C. Li</span><span>/</span><span>, D. Liu, J. Tu, J. Zhou, J. Lin, et al. </span><span>Qwen 2. 5</span><span>–math technical report: Toward mathematical expert model via self-improvement. </span><span>arXiv preprint</span><span> arXiv:2409.12122, 2024.</span></p></td><td><p dir="ltr"><span>A. Yang, </span><span>B. Yang, C. Yang</span><span>, et al. Qwen</span><span>3.5–mathematical report for iterative model self-improvement</span><span>. arXiv:</span><span>2909.12233</span><span>, 2024.</span></p></td></tr></tbody></table>
<!--kg-card-end: html-->
<p>Like GPTZero’s <a href="https://gptzero.me/" rel="noreferrer">AI Detector</a>, Hallucination Check has an extremely low false negative rate, so we catch 99 out of 100 flawed citations.&nbsp;Because our tool will flag any citation that can't be verified online, the false positive rate is higher.</p><h2 id="vibe-citing">Vibe Citing</h2><p>Over the past few months, we've experimented with several names for an LLM-generated citation with fabricated elements. "Hallucinated citations" is too long, "hallucitations" too easily mistaken for a spelling error, and "fake citations" too morally charged. Recently, GPTZero's Head of Machine Learning, Alex Adams, coined the term "vibe citing" to describe the LLM tendency to derive or amalgamate real sources into uncanny imitations. "Vibe citing," like "vibe writing" or "vibe coding" produces citations that look accurate at first glance, but crumble under closer inspection.</p><figure><img src="https://gptzero.me/news/content/images/2026/01/star-history-2026121.png" alt="" loading="lazy" width="1576" height="1153" srcset="https://gptzero.me/news/content/images/size/w600/2026/01/star-history-2026121.png 600w, https://gptzero.me/news/content/images/size/w1000/2026/01/star-history-2026121.png 1000w, https://gptzero.me/news/content/images/2026/01/star-history-2026121.png 1576w" sizes="(min-width: 720px) 720px"><figcaption><span>Figure 2: Open-source projects to write research papers with AI are booming in popularity and illustrate the growth in vibe-citing. The bumps in April and September 2025 correspond to the paper submission deadlines for NeurIPS and ICLR 2025.</span></figcaption></figure><p>GPTZero's analysis of 4841 of the 5290 papers accepted by NeurIPS 2025 indicates noticeable traces of AI authorship and hundreds of vibe citations. As always, each of the hallucinations presented here has been verified by a human expert.</p><h2 id="surf-the-tsunami-with-hallucination-check">Surf the Tsunami with Hallucination Check</h2><p>Hallucination Check is the only tool of its kind, and provides an essential service at multiple points in the peer review pipeline. First, it allows authors to check their manuscripts for citation errors — including common issues that can occur without LLM involvement like dead links or partial titles. Second, it greatly reduces the time and labor necessary for reviewers to check a submission's sources and identify possible vibe citing. Third, using Hallucination Check in combination with GPTZero's AI Detector allows editors and conference chairs to check for AI-generated text and suspicious citations at the same time, leading to faster and more accurate editorial decisions.</p><p>After releasing our ICLR paper investigation we are now coordinating with the ICLR team to review future paper submissions. As always, our goal is to make the peer review process faster, fairer, and more transparent for everyone involved. <em>Try GPTZero's </em><a href="https://gptzero.me/hallucination-detector" rel="noreferrer"><em><u>Hallucination check</u></em></a><em> for yourself, or </em><a href="https://gptzero.me/sales"><em><u>reach out to GPTZero's team</u></em></a><em>.</em></p><figure><a href="https://gptzero.me/news/iclr-2026/"><div><p>GPTZero uncovers 50+ Hallucinations in ICLR 2026</p><p>GPTZero used our Hallucination Check tool to find 50+ hallucinations under review at ICLR, each of which were missed by 3-5 peer reviewers.</p><p><img src="https://gptzero.me/news/content/images/icon/square_logo-2.png" alt=""><span>Paul Esau</span></p></div><p><img src="https://gptzero.me/news/content/images/thumbnail/ICLR_Logo.svg.png" alt="" onerror="this.style.display = 'none'"></p></a></figure><figure><a href="https://gptzero.me/news/deloitte-australia-citation-check/"><div><p>The Deloitte Citation Situation - $98K Controversy Explained</p><p>GPTZero used our Citation Check to analyze the 234 page report and identified more than 30 issues out of the total 141 citations, including 19 hallucinations. Using GPTZero’s citation check would have saved ~$5000 per citation, all within minutes.</p><p><img src="https://gptzero.me/news/content/images/icon/square_logo-3.png" alt=""><span>AI Detection Resources | GPTZero</span><span>Nazar Shmatko</span></p></div><p><img src="https://gptzero.me/news/content/images/thumbnail/pexels-anildonoji-18541728-1-1.jpg" alt="" onerror="this.style.display = 'none'"></p></a></figure><figure><a href="https://gptzero.me/news/making-america-hallucinate-again-gptzero-detects-new-errors-in-major-government-report/"><div><p>Making America Hallucinate Again? GPTZero Detects New Errors in Major Government Report</p><p>On May 22, the U.S. Presidential Commission to Make America Healthy Again (MAHA), led by health secretary Robert F. Kennedy Jr., released a major report on the causes of chronic diseases in children. Yet within a week, news outlets including NOTUS, the New York Times and Washington Post reported</p><p><img src="https://gptzero.me/news/content/images/icon/square_logo-4.png" alt=""><span>AI Detection Resources | GPTZero</span><span>Paul Esau</span></p></div><p><img src="https://gptzero.me/news/content/images/thumbnail/Screenshot-2025-07-03-at-6.33.41---PM-1.png" alt="" onerror="this.style.display = 'none'"></p></a></figure>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[In Europe, Wind and Solar Overtake Fossil Fuels (137 pts)]]></title>
            <link>https://e360.yale.edu/digest/europe-wind-solar-fossil-fuels</link>
            <guid>46719491</guid>
            <pubDate>Thu, 22 Jan 2026 14:14:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://e360.yale.edu/digest/europe-wind-solar-fossil-fuels">https://e360.yale.edu/digest/europe-wind-solar-fossil-fuels</a>, See on <a href="https://news.ycombinator.com/item?id=46719491">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
                  
<div>

  <figure>

    <div>
      
                  
      <p><a href="https://yale-threesixty.transforms.svdcdn.com/production/Beeskow-Solar_Pexels.jpg?w=1200&amp;h=800&amp;auto=compress%2Cformat&amp;fit=crop&amp;dm=1769079918&amp;s=c67f214d895b44db7e6420c0a3bfc1aa" data-caption="Rooftop solar panels in Beeskow, Germany." data-credit="Pexels">
  
  
  
    
  
  
  
      
    
                
    
                
    
                
    
                
    
                        
  <img sizes="(min-width: 1450px) 832px, (min-width: 620px) 620px, 100vw" srcset="https://yale-threesixty.transforms.svdcdn.com/production/Beeskow-Solar_Pexels.jpg?w=1200&amp;h=800&amp;auto=compress%2Cformat&amp;fit=crop&amp;dm=1769079918&amp;s=c67f214d895b44db7e6420c0a3bfc1aa 1200w, https://yale-threesixty.transforms.svdcdn.com/production/Beeskow-Solar_Pexels.jpg?w=200&amp;auto=compress%2Cformat&amp;fit=clip&amp;dm=1769079918&amp;s=ac44a2f3862a1d7b22fb35c3a1d0e352 200w, https://yale-threesixty.transforms.svdcdn.com/production/Beeskow-Solar_Pexels.jpg?w=400&amp;auto=compress%2Cformat&amp;fit=clip&amp;dm=1769079918&amp;s=3c6b60c6321fd63f129208a6b8c09d33 400w, https://yale-threesixty.transforms.svdcdn.com/production/Beeskow-Solar_Pexels.jpg?w=600&amp;auto=compress%2Cformat&amp;fit=clip&amp;dm=1769079918&amp;s=5f04396b725cd8972d48c16af1ad0a97 600w, https://yale-threesixty.transforms.svdcdn.com/production/Beeskow-Solar_Pexels.jpg?w=800&amp;auto=compress%2Cformat&amp;fit=clip&amp;dm=1769079918&amp;s=76d4bd20af816f9a9a55c5905f0eb479 800w, https://yale-threesixty.transforms.svdcdn.com/production/Beeskow-Solar_Pexels.jpg?w=1000&amp;auto=compress%2Cformat&amp;fit=clip&amp;dm=1769079918&amp;s=c7877029453366a27a3adcac42eecdbf 1000w" src="https://yale-threesixty.transforms.svdcdn.com/production/Beeskow-Solar_Pexels.jpg?w=400&amp;auto=compress%2Cformat&amp;fit=clip&amp;dm=1769079918&amp;s=3c6b60c6321fd63f129208a6b8c09d33" alt="Rooftop solar panels in Beeskow, Germany.">
</a>
      </p>
          </div>

        <figcaption>
              <p><span>Rooftop solar panels in Beeskow, Germany.</span>
          <span>Pexels</span></p>
    </figcaption>
    
  </figure>

</div> <!-- imageBlock -->
            

<div>
  <p>Last year, for the first time, wind and solar supplied more power than fossil fuels to the E.U., according to a new analysis.</p><p>The shift is largely due to the rapid expansion of solar energy, which is growing faster than any other source of electricity. Together, wind and solar generated 30 percent of E.U. power last year, while fossil fuels provided 29 percent, according to the <a href="https://ember-energy.org/latest-insights/european-electricity-review-2026/">analysis</a> from Ember, a think tank based in London. Including hydro, renewables provided nearly half of all E.U. power in 2025.</p>
</div>
            
<div>

  <figure>

    <div>
      
                  
      <p><a href="https://yale-threesixty.transforms.svdcdn.com/production/EU-Power_Ember.png?w=980&amp;h=804&amp;auto=compress%2Cformat&amp;fit=crop&amp;dm=1769082265&amp;s=8ca86b66039abe22d21e745cabbe70c6" data-caption="E.U. power generation." data-credit="EMBER / ADAPTED BY YALE ENVIRONMENT 360">
  
  
  
    
  
  
  
      
    
                
    
                
    
                
    
                              
  <img sizes="(min-width: 1450px) 617px, (min-width: 1000px) 460px, (min-width: 600px) 60vw, 100vw" srcset="https://yale-threesixty.transforms.svdcdn.com/production/EU-Power_Ember.png?w=980&amp;h=804&amp;auto=compress%2Cformat&amp;fit=crop&amp;dm=1769082265&amp;s=8ca86b66039abe22d21e745cabbe70c6 980w, https://yale-threesixty.transforms.svdcdn.com/production/EU-Power_Ember.png?w=200&amp;auto=compress%2Cformat&amp;fit=clip&amp;dm=1769082265&amp;s=ee4a99833329e05dd94a3daff509e74c 200w, https://yale-threesixty.transforms.svdcdn.com/production/EU-Power_Ember.png?w=400&amp;auto=compress%2Cformat&amp;fit=clip&amp;dm=1769082265&amp;s=29b561390a3c2023f01fa6359c3faea1 400w, https://yale-threesixty.transforms.svdcdn.com/production/EU-Power_Ember.png?w=600&amp;auto=compress%2Cformat&amp;fit=clip&amp;dm=1769082265&amp;s=213daf0b6f44a1854fc82d927a38fa6f 600w, https://yale-threesixty.transforms.svdcdn.com/production/EU-Power_Ember.png?w=800&amp;auto=compress%2Cformat&amp;fit=clip&amp;dm=1769082265&amp;s=28d524c1498db30ddb2725b3148c58c9 800w" src="https://yale-threesixty.transforms.svdcdn.com/production/EU-Power_Ember.png?w=400&amp;auto=compress%2Cformat&amp;fit=clip&amp;dm=1769082265&amp;s=29b561390a3c2023f01fa6359c3faea1" alt="E.U. power generation.">
</a>
      </p>
          </div>

        <figcaption>
              <p><span>E.U. power generation.</span>
          <span>EMBER / ADAPTED BY YALE ENVIRONMENT 360</span></p>
    </figcaption>
    
  </figure>

</div> <!-- imageBlock -->
            

<div>
  <p>The analysis finds that solar is making gains in every E.U. country, while coal is broadly in retreat. Last year, solar alone supplied more than 20 percent of power in Hungary, Cyprus, Greece, Spain, and the Netherlands. Meanwhile, in 19 European countries, coal accounted for less than 5 percent of power. In 2025, both <a href="https://www.bloomberg.com/news/articles/2025-06-20/ireland-shuts-last-coal-plant-as-europe-s-phaseout-accelerates">Ireland</a> and <a href="https://www.spglobal.com/energy/en/news-research/latest-news/electric-power/040125-finland-shuts-last-coal-fired-power-plant-at-salmisaari-ending-the-era-of-coal">Finland</a> joined the ranks of European countries that have shuttered their last remaining coal plants.</p><p>Warming, however, continues to challenge the shift to clean energy as <a href="https://www.theguardian.com/environment/2025/nov/29/climate-crisis-depleting-europe-groundwater-reserves-analysis">drought</a> saps hydropower. Last year, hydro output dropped slightly in the E.U., and natural gas power rose to compensate.&nbsp;</p><p>“The next priority for the E.U. should be to put a serious dent in reliance on expensive, imported gas,” said Ember analyst Beatrice Petrovich. “Gas not only makes the E.U. more vulnerable to energy blackmail, it’s also driving up prices.”</p><p>In parts of Europe, there are signs that increasingly cheap batteries are beginning to displace natural gas in the early evening, when power demand is high, but solar output is waning. Said Petrovich, “As this trend accelerates it could limit how much gas is needed in evening hours, therefore stabilizing prices.”</p><h2><strong>ALSO ON YALE E360</strong></h2><p><a href="https://e360.yale.edu/features/europe-water-micropollutants"><i><strong>An E.U. Plan to Slash Micropollutants in Wastewater Is Under Attack</strong></i></a></p>
</div>
                </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Douglas Adams on the English–American cultural divide over "heroes" (221 pts)]]></title>
            <link>https://shreevatsa.net/post/douglas-adams-cultural-divide/</link>
            <guid>46719222</guid>
            <pubDate>Thu, 22 Jan 2026 13:50:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shreevatsa.net/post/douglas-adams-cultural-divide/">https://shreevatsa.net/post/douglas-adams-cultural-divide/</a>, See on <a href="https://news.ycombinator.com/item?id=46719222">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
  <header>
    
    <p><time datetime="2026-01-14T00:00:00Z">January 14, 2026</time></p>
  </header>
  <p>In 2000, Douglas Adams made an interesting observation that I keep returning to.</p>
<p>A user on Slashdot named “FascDot Killed My Pr” had asked the following question (where HGttG = Hitchhiker’s Guide to the Galaxy):</p>
<blockquote>
<p><em>Comedy….or Tragedy?</em></p>
<p><em>First, a big thank-you. You’ve made a lasting contribution to “our” culture (or should that be “culture”?)</em></p>
<p><em>I first read HGttG in my early teens. I doubled over laughing the whole time. I read and reread the entire series, bought both Dirk Gently books AND Last Chance to See. Loved them all and wouldn’t trade having read them for anything. (btw, the first mental ward scene in Long Dark Teatime is a no-foolin’, all-time classic.)</em></p>
<p><em>However, a few years ago I was talking to a (then) classmate. Very smart, philosophy-major type. He said (paraphrased) “I thought that HGttG was depressing. Such nihilism.” At the time I thought “Hmmm…I didn’t SEE a black beret on his head….”. But every reading of the series since then his comment has struck me as more true–especially in the case of Arthur Dent. In fact, far from being funny, I now find Dent’s character depressing–he’s not just a loser, he literally has no control over his life at all (except in So Long for a while). And the control he does have does him no good (e.g. Earth is destroyed while he’s trying to save his house.)</em></p>
<p><em>So my question is: When you were writing these books did you feel you were being gaily whimsical or did you instead feel frustrated and cynical?</em></p>
</blockquote>
<p>Douglas Adams replied with:</p>
<blockquote>
<p>I suspect there is a cultural divide at work here. In England our heroes tend to be characters who either have, or come to realise that they have, no control over their lives whatsoever – Pilgrim, Gulliver, Hamlet, Paul Pennyfeather (from Decline and Fall), Tony Last (from A Handful of Dust). We celebrate our defeats and our withdrawals – the Battle of Hastings, Dunkirk, almost any given test match. There was a wonderful book published, oh, about twenty years ago I think, by Stephen Pile called the Book of Heroic Failures. It was staggeringly huge bestseller in England and sank with heroic lack of trace in the U.S. Stephen explained this to me by saying that you cannot make jokes about failure in the States. It’s like cancer, it just isn’t funny at any level. In England, though, for some reason it’s the thing we love most. So Arthur may not seem like much of a hero to Americans – he doesn’t have any stock options, he doesn’t have anything to exchange high fives about round the water-cooler. But to the English, he is a hero. Terrible things happen to him, he complains about it a bit quite articulately, so we can really feel it along with him - then calms down and has a cup of tea. My kind of guy!</p>
<p>I’ve hit a certain amount of difficulty over the years in explaining this in Hollywood. I’m often asked ‘Yes, but what are his goals?’ to which I can only respond, well, I think he’d just like all this to stop, really. It’s been a hard sell. I rather miss David Vogel from the film process. He’s the studio executive at Disney who was in charge of the project for a while, but has since departed. There was a big meeting at one time to discuss, amongst other things, Arthur’s heroicness or lack of it. David suddenly asked me ‘Does Arthur’s presence in the proceedings make a difference to the way things turn out?’ to which I said, slightly puzzled, ‘Well, yes.’ David smiled and said ‘Good. Then he’s a hero.’</p>
<p>In the current, latest version of the screenplay, I think that Arthur’s non-heroic heroism is now absolutely preserved, and I’m pleased with the way he works out.</p>
</blockquote>
<p>(<a href="https://entertainment.slashdot.org/story/00/06/21/1217242/douglas-adams-answers-finally">Douglas Adams Answers (Finally) - Slashdot</a>)</p>
<p>I think I have more to say about this, and will try to come back and add more here, but meanwhile a few things at random:</p>
<ul>
<li>
<p>As a matter of fact, I <em>have</em> read <em>The Book of Heroic Failures</em> (1979) with great enjoyment. (<a href="https://shreevatsa.wordpress.com/2011/03/21/the-book-of-heroic-failures/">Post from 2011</a> —&nbsp;I only wrote four sentences of my own, but one of them was “Too many books have been written in praise of competence; this book provides an antidote by celebrating failure as only a British author can.”)</p>
</li>
<li>
<p>I think he is right that this goes over better (generally speaking) in England than in the USA. Of course one can make jokes <em>mocking</em> failure, but someone who fails does not automatically become endearing (in a kind of everyman way) in America the way they would in England. It seems to me that Americans are more likely to feel either contempt or pity than to feel kinship: or at any rate, they regard the failure as a setback or interesting circumstance, rather than the natural/default state of the world. (As someone who is neither American nor English, I am of course not someone whose opinions you should pay any heed to.)</p>
</li>
</ul>
<ul>
<li>As we live our lives, are we merely victims subject to winds of chance and external circumstance, or are we powerful agents fashioning our own stories, making our own luck? Obviously the answer is “both”, but perhaps the most distinctively American trait is to lean more towards the latter.</li>
</ul>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Design Thinking Books You Must Read (169 pts)]]></title>
            <link>https://www.designorate.com/design-thinking-books/</link>
            <guid>46718061</guid>
            <pubDate>Thu, 22 Jan 2026 11:51:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.designorate.com/design-thinking-books/">https://www.designorate.com/design-thinking-books/</a>, See on <a href="https://news.ycombinator.com/item?id=46718061">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
			
<p>Can you think that following a design thinking process with five steps turns you into a creative innovator?! Believe me, it isn’t and never has been this way. The spread of the term design thinking is aligned with a significant amount of misleading criticism. The doubts about the effectiveness of design thinking are influenced by the promotional language used by some companies, training places, and public speakers. The truth is that there is no secret recipe to turn someone into a creative designer. Yet, there is a way to use the design expertise inside each of us. <a href="https://www.designorate.com/design-thinking-guide-what-why-how/">Understanding the design thinking core values</a> can help team members improve their design ability and appreciate the creative practice inside the organization to achieve the next competitive advantage. This is why I wanted to share with you those key design thinking books to learn the core principles underpinning the design practice.</p>



<p>This is an updated list of design thinking books that I keep adding to their new book suggestions. So, please keep the link or subscribe to the newsletters to receive updates once new books are added. I am also starting to add papers that represent the cornerstone in the design thinking principles that I believe are as important as the book. In this update, two books and one paper added: The Science of Artificial, Wicked Problems in Design Thinking, and How Designers Think.</p>



<p>Previously, we explored different challenges that can be faced when applying design thinking inside the organization ( Why Companies Need to Apply Design Thinking and Why Companies Need to Apply Design Thinking). The majority of these factors rely on the lack of understanding of the core value of design thinking, which can be a reason for over-promotion and misuse of a commercialized language (check <a href="https://www.designorate.com/why-design-thinking-doesnt-work/" rel="bookmark">Why Design Thinking Doesn’t Work</a>). Above all, many design thinking trainers are not designers themselves and never practice the creative practice before teaching it which causes the gap between classrooms and practices.</p>



<div id="ez-toc-container">

<nav><ul><li><a href="#Design_Thinking_Books">Design Thinking Books</a><ul><li><a href="#Design_Expertise_by_Kees_Dorst">Design Expertise by Kees Dorst</a></li><li><a href="#Frame_Innovation_by_Kees_Dorst">Frame Innovation by Kees Dorst</a></li><li><a href="#Design_Thinking_Understanding_How_Designers_Think_and_Work">Design Thinking: Understanding How Designers Think and Work</a></li><li><a href="#Change_by_Design_by_Tim_Brown">Change by Design by Tim Brown</a></li><li><a href="#The_Design_of_Everyday_Things_by_Don_Norman">The Design of Everyday Things by Don Norman</a></li><li><a href="#How_Designers_Think_by_Bryan_Lawson">How Designers Think? by Bryan Lawson</a></li></ul></li><li><a href="#The_Science_of_Artificial_by_Herbert_Simon">The Science of Artificial by Herbert Simon</a></li><li><a href="#Wicked_Problems_in_Design_Thinking_Paper_by_Richard_Buchanan">Wicked Problems in Design Thinking (Paper) by Richard Buchanan</a></li><li><a href="#The_Dilemmas_in_a_General_Theory_of_Planning_by_Rittel_and_Webber">The Dilemmas in a General Theory of Planning by Rittel and Webber</a></li><li><a href="#The_New_Process_New_Vocabulary_Axiofact_A_tefact_Memoranda_by_Gilbert_Cockton">The New Process, New Vocabulary: Axiofact = A_tefact + Memoranda by Gilbert Cockton</a></li><li><a href="#References">References</a></li></ul></nav></div>




<p>To expand my knowledge of the core values behind design thinking, I thought I would share with you some of the book titles that highlight design characteristics. Each of these books explores design from a specific perspective. Learning about these design aspects is essential for both designers and non-designers before jumping to learn design thinking. While there are several books about design thinking toolkits, the books below don’t teach you to design thinking methodology but the core principles behind design thinking to develop new alternatives of ideas and improve the analytical thinking of problems and solutions. They aim to guide you in understanding the core values and practices of design as a collaborative process. By acquiring this knowledge, you can effectively apply any of the design thinking processes we discussed earlier in previous articles with effectiveness. I am sure that those are not the only books out there, so please share with us your book suggestions in the comments below the article.</p>



<p><strong><em>Related article:</em></strong></p>



<p><a href="https://www.designorate.com/the-double-diamond-design-thinking-process-and-how-to-use-it/">The Double Diamond Design Thinking Process and How to Use it</a></p>



<p><a href="https://www.designorate.com/what-is-design-and-what-is-not/">What is Design? And What is not?</a></p>



<p><em><a href="https://www.designorate.com/design-thinking-guide-what-why-how/" rel="bookmark">Design Thinking Guide: What, Why and How</a></em></p>



<p><em><a href="https://www.designorate.com/why-design-thinking-doesnt-work/" rel="bookmark">Why Design Thinking Doesn’t Work</a></em></p>



<p><em><a href="https://www.designorate.com/measuring-the-impact-of-design-thinking/" rel="bookmark">Me</a><a href="https://www.designorate.com/measuring-the-impact-of-design-thinking/" rel="bookmark">asuring the Impact of Design Thinking</a></em></p>



<h3><span id="Design_Expertise_by_Kees_Dorst"></span>Design Expertise by Kees Dorst<span></span></h3>



<p>The <a href="https://amzn.to/34vj2Fj">Design Expertise</a>, written by Lawson and Dorst, focuses on the understanding of design practice in the creative industry. The book aims to explore the nature of design from a practitioner’s perspective. It starts by exploring the different definitions of design and how they contributed to identifying the border of the discipline of design.</p>


<div>
<figure><a href="https://www.designorate.com/wp-content/uploads/2020/04/Design-Expertise.jpg"><img fetchpriority="high" decoding="async" width="800" height="500" src="https://www.designorate.com/wp-content/uploads/2020/04/Design-Expertise.jpg" alt="Design Expertise" srcset="https://www.designorate.com/wp-content/uploads/2020/04/Design-Expertise.jpg 800w, https://www.designorate.com/wp-content/uploads/2020/04/Design-Expertise-300x188.jpg 300w, https://www.designorate.com/wp-content/uploads/2020/04/Design-Expertise-768x480.jpg 768w" sizes="(max-width: 800px) 100vw, 800px"></a><figcaption>Design Expertise by Kees Dorst</figcaption></figure></div>


<p>The book presents design work for different designers and tries to use this overview of their work to provide a practical example of design characteristics. This book provides you with a base idea about design, what it is, and its characteristics. Exploring the characteristics through <a href="https://www.designorate.com/design-thinking-reshaped-microsoft-products/">design thinking case studies</a>, and examples helps you see design’s core value. This value is the main cornerstone behind the application of the design thinking process.</p>



<h3><span id="Frame_Innovation_by_Kees_Dorst"></span>Frame Innovation by Kees Dorst<span></span></h3>



<p>One of the main design characteristics is to solve problems or move from one position to an improved one. However, this can’t be achieved without a clear idea of the problem and its different borders. In his book <a href="https://amzn.to/2yPd9a9">Frame Innovation</a>, Dorst explores the cognitive design process’s problem and solution frames. Also, he explores how designers move from one frame to another and how this feedback process contributes toward an optimum solution for wicked problems.</p>


<div>
<figure><a href="https://www.designorate.com/wp-content/uploads/2020/04/Fram-Innovation.jpg"><img decoding="async" width="800" height="500" src="https://www.designorate.com/wp-content/uploads/2020/04/Fram-Innovation.jpg" alt="frame innovation" srcset="https://www.designorate.com/wp-content/uploads/2020/04/Fram-Innovation.jpg 800w, https://www.designorate.com/wp-content/uploads/2020/04/Fram-Innovation-300x188.jpg 300w, https://www.designorate.com/wp-content/uploads/2020/04/Fram-Innovation-768x480.jpg 768w" sizes="(max-width: 800px) 100vw, 800px"></a><figcaption>Frame Innovation by Kees Dorst</figcaption></figure></div>


<p>Many of the design thinking process models move from the exploration stage (divergent) to defining the solution (conversion). While this practice shares the principle of critical thinking, they all move between the problem frame and solution frame. Through this book, you will explore the principles and practices of problem/solution frames to develop creative potential ideas.</p>



<p>The book extends discussion of of the principle of frame innovation by covering the opportunities and challenges related to its application in creative industries. The book ends by putting a practice action plan to move toward using the frame innovation in different business models.</p>



<h3><span id="Design_Thinking_Understanding_How_Designers_Think_and_Work"></span>Design Thinking: Understanding How Designers Think and Work<span></span></h3>



<p>In this small yet informative book, <a href="https://amzn.to/2RwszqB">Design Thinking</a>, Nigel Cross explores how designers think and reach creative ideas in the design field and the nature of design from the perspective of idea formation. To this goal, the book overviews design practice based on observing and interviewing creative designers and exploring expert tips with them. Design processes try to explore the design expertise from creating the idea to applying it. However, the design ability comes earlier when ideas are formulated. The book’s first chapter explores this design ability and how each of us has a level of design ability to develop new ideas. Yet, some people are more designers than others, which is known in Lusy Kimbel’s two papers as the creative class (Rethinking Design Thinking: <a href="https://www.tandfonline.com/doi/abs/10.2752/175470811X13071166525216?casa_token=eQlFFIjY110AAAAA:8TLvc0-_HjZPsM0NbT1y3lya4XulQVlfc-4f0uPelIYFwHjyJK53Aj-33_yvdsFKgxfy1EdeRbUNXw">Part 1</a> and <a href="https://www.tandfonline.com/doi/abs/10.2752/175470812X13281948975413?casa_token=Vlf9CU0l2A4AAAAA:pFFp0YVRmEZdRBbNDR2EWVin0DkNV72L6SaSIHgx7TnHKbC8ZqDdPC8Yvm1TNQtPsJIt6z65m9pxyg">Part 2</a>).</p>


<div>
<figure><a href="https://www.designorate.com/wp-content/uploads/2020/04/Design-Thinking.jpg"><img loading="lazy" decoding="async" width="800" height="500" src="https://www.designorate.com/wp-content/uploads/2020/04/Design-Thinking.jpg" alt="Design Thinking: Understanding How Designers Think and Work" srcset="https://www.designorate.com/wp-content/uploads/2020/04/Design-Thinking.jpg 800w, https://www.designorate.com/wp-content/uploads/2020/04/Design-Thinking-300x188.jpg 300w, https://www.designorate.com/wp-content/uploads/2020/04/Design-Thinking-768x480.jpg 768w" sizes="(max-width: 800px) 100vw, 800px"></a><figcaption>Design Thinking: Understanding How Designers Think and Work by Nigel Cross</figcaption></figure></div>


<p>The book overviews designers’ practice in different fields and stories. The aim of this overview through creative designers’ experience is to build an understanding of the inspiration or exploration stage in the design thinking process. For instance, what is brainstorming, and why is it applied at an early point in the design thinking process (How to Successfully Apply Inspiration in Design Thinking)? Linking similar questions to the practice helps you map your practice to rational reasoning and subsequently improves the progress of the process in the future.</p>



<h3><span id="Change_by_Design_by_Tim_Brown"></span>Change by Design by Tim Brown<span></span></h3>



<p><a href="https://www.amazon.co.uk/Change-Design-Revised-Updated-Organizations/dp/0062856626/ref=tmm_hrd_swatch_0?_encoding=UTF8&amp;qid=1680977260&amp;sr=8-10">Change by Design</a>, by Tim Bowen, CEO of the IDEO, is probably one of the commonly known books about design thinking because of the popularity of the IDEO in the application of design thinking in various social innovation contexts. In his book, Tim Brown manifests his ideology about design thinking and interprets it from the organisational perspective. The book aims to clarify what design thinking is, and where to go from theory to practice. In the first part, the books focus on the main concepts of design thinking (check Design Thinking Tools and Methods Complete Guide), such as extending behind the aesthetics, shifting toward a human-centred approach (i.e. improving customer experience and building inclusive design), the power of prototyping, and the importance of storytelling. The second part of the book aims to interpret these principles for practicality to identify the business opportunities for design thinking and the use of design to achieve innovation inside organisations through creative collaboration between stakeholders.<span>&nbsp;</span></p>


<div>
<figure><img loading="lazy" decoding="async" width="800" height="500" src="https://www.designorate.com/wp-content/uploads/2020/04/ChangebyDesign02.jpg" alt="Change by Design book" srcset="https://www.designorate.com/wp-content/uploads/2020/04/ChangebyDesign02.jpg 800w, https://www.designorate.com/wp-content/uploads/2020/04/ChangebyDesign02-300x188.jpg 300w, https://www.designorate.com/wp-content/uploads/2020/04/ChangebyDesign02-768x480.jpg 768w" sizes="(max-width: 800px) 100vw, 800px"><figcaption>Change by Design by Tim Brown.</figcaption></figure></div>


<p>The book is a good resource for both designers and business people to understand design thinking and its applications. Despite several criticisms of the IDEO design thinking model, the book describes the theoretical base of design thinking, which could have a positive, innovative impact on organisations, especially if applied properly to develop viable business strategies. The <a href="http://www.designkit.org/">IDEO Field Guide</a> can be a good companion for the book as it presents a toolbox to apply Tim Brown’s ideology in practice.</p>



<h3><span id="The_Design_of_Everyday_Things_by_Don_Norman"></span>The Design of Everyday Things by Don Norman<span></span></h3>



<p>Don Norman is one of the leading professors in behaviour psychology and human-computer interaction (HCI). His book, <a href="https://amzn.to/2Rx5XGb">The Design of Everyday Things</a>, is based on a simple observation: why do we love and hate some elements in our lives? And what is the psychology behind our behaviour toward products? Addressing these two questions presents a cornerstone of your design practice. For example, why do some people love products such as Apple, <a href="https://www.designorate.com/what-is-market-segmentation-and-why-designers-should-understand/">Mini Cooper</a>, or <a href="https://www.designorate.com/ikea-sustainable-design-strategy/">IKEA</a>? By understanding how consumers love or hate products, the design team can target these features to build an empathic relationship between the product (or service) and the client, known as <a href="https://www.designorate.com/empathic-design-approach-to-successful-design/">emphatic design</a>.</p>


<div>
<figure><a href="https://www.designorate.com/wp-content/uploads/2020/04/Everyday-Things.jpg"><img loading="lazy" decoding="async" width="800" height="500" src="https://www.designorate.com/wp-content/uploads/2020/04/Everyday-Things.jpg" alt="The Design of Everyday Things " srcset="https://www.designorate.com/wp-content/uploads/2020/04/Everyday-Things.jpg 800w, https://www.designorate.com/wp-content/uploads/2020/04/Everyday-Things-300x188.jpg 300w, https://www.designorate.com/wp-content/uploads/2020/04/Everyday-Things-768x480.jpg 768w" sizes="(max-width: 800px) 100vw, 800px"></a><figcaption>The Design of Everyday Things for Don Norman</figcaption></figure></div>


<p>The book explores human-centred design and its impact on usability interaction design principles, as well as user experience. While other books covered this aspect of design experience, Norman studied the experience from a psychological point of view to examine this complex design process. The book covers the psychology behind our daily actions, knowledge, design limitations, and human error. Later, the book explores design thinking as a tool to solve problems and the usage of the Design Council Double Diamond design thinking process. The book is not only for UX designers but for designers from different practices, as you can learn the following:</p>



<ol>
<li>How the brain works and the psychology related to products and services,</li>



<li>The limitations related to our experience with interacting with designs around and</li>



<li>Human error and a bad design causes .</li>
</ol>



<h3><span id="How_Designers_Think_by_Bryan_Lawson"></span>How Designers Think? by Bryan Lawson<span></span></h3>



<p><a href="https://www.amazon.co.uk/How-Designers-Think-Process-Demystified/dp/0750660775/ref=tmm_pap_swatch_0?_encoding=UTF8&amp;qid=1701980560&amp;sr=1-1" target="_blank" rel="noreferrer noopener nofollow">How Designers Think?</a> by Bryan Lawson is one of the design thinking books I recommend for my students who are still new to problem-solving and understanding the philosophical approach underpinning the problem and solution space in the design thinking process, How Designer Think for Bryan Lawson overviews the design definition, the relation between problem and solutions and the design thinking process. </p>


<div>
<figure><img loading="lazy" decoding="async" width="1024" height="624" src="https://www.designorate.com/wp-content/uploads/2023/12/HowDesigersThink-1-1024x624.jpg" alt="" srcset="https://www.designorate.com/wp-content/uploads/2023/12/HowDesigersThink-1-1024x624.jpg 1024w, https://www.designorate.com/wp-content/uploads/2023/12/HowDesigersThink-1-300x183.jpg 300w, https://www.designorate.com/wp-content/uploads/2023/12/HowDesigersThink-1-768x468.jpg 768w, https://www.designorate.com/wp-content/uploads/2023/12/HowDesigersThink-1.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>How Designers Think? by Bryan Lawson</figcaption></figure></div>


<p>Unlike other books, Lawson doesn’t aim to teach you his method or derive a specific point; it is more like a discussion book to allow you to reflect and synthesise on the design practice and finally come up with your conclusion. The book presents a flow of ideas as a case study, making it easy to understand and enjoyable for new readers in design thinking. I recommend reading it before moving to more advanced books such as The Science of Artificial.</p>



<h2><span id="The_Science_of_Artificial_by_Herbert_Simon"></span>The Science of Artificial by Herbert Simon <span></span></h2>



<p>The <a href="https://www.amazon.co.uk/Sciences-Artificial-MIT-Press/dp/0262691914" target="_blank" rel="noreferrer noopener nofollow">Science of Artificial </a>is one of Simon’s most famous and irritating works based on three lectures for him at MIT in 1968, a year before the book was first published. The book discusses the nature of human thinking and the “artefact.” In eight chapters, it explores how humans use artefacts to solve everyday problems. His expression of human rationale is expressed with three premises:</p>



<ul>
<li>The limitations in the human’s cognitive ability</li>



<li>The time available to make a decision, and</li>



<li>The complexity of the problem</li>
</ul>



<p>Based on these three premises, he concluded that we are under the illusion that we can choose the optimal solution for problems. Instead, we find a way to determine the reasonable solutions (check <a href="https://www.designorate.com/the-six-hats-of-critical-thinking-and-how-to-use-them/">What Are The Six Thinking Hats? And How to Use Them?</a>).</p>


<div>
<figure><img loading="lazy" decoding="async" width="1024" height="624" src="https://www.designorate.com/wp-content/uploads/2023/12/The_Science_of_Aritifical-1024x624.jpg" alt="" srcset="https://www.designorate.com/wp-content/uploads/2023/12/The_Science_of_Aritifical-1024x624.jpg 1024w, https://www.designorate.com/wp-content/uploads/2023/12/The_Science_of_Aritifical-300x183.jpg 300w, https://www.designorate.com/wp-content/uploads/2023/12/The_Science_of_Aritifical-768x468.jpg 768w, https://www.designorate.com/wp-content/uploads/2023/12/The_Science_of_Aritifical.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The Science of Artificial by Herbert Simon </figcaption></figure></div>


<p>Simon was awarded a Nobel Prize for his theory and its contribution to economic rationality. According to the above theory, Simon defined three problem-solving activities: the ability to conduct a heuristic search for alternatives, evaluate solutions, and allocate resources for search. He illustrates this concept in his statement:</p>



<p><em>” Human problem solving involves nothing more than varying mixtures of trial and error and selectivity. The selectivity derives from various rules of thumb, or heuristics, suggesting which paths should be tried first and which promising leads.”</em></p>



<h2><span id="Wicked_Problems_in_Design_Thinking_Paper_by_Richard_Buchanan"></span>Wicked Problems in Design Thinking (Paper) by Richard Buchanan<span></span></h2>



<p><a href="https://web.mit.edu/jrankin/www/engin_as_lib_art/Design_thinking.pdf" target="_blank" rel="noreferrer noopener nofollow">Wicked Problems in Design Thinking</a> by Buchanan was published in Design Studies in 1992. Buchanan linked design and analytical philosophy by understanding the design problem’s nature and elements. He discussed two terms: “category” and “placement”, where we frame the different aspects of the problem. Buchanan describes them as follows:</p>



<p><em>“Understanding the difference between a category and a placement is essential if design thinking is to be regarded as more than a series of creative accidents. Categories have fixed meanings that are accepted within the framework of a theory or a philosophy and serve as the basis for analysing what already exists. Placements have boundaries to shape and constrain meaning but are not rigidly fixed and determinate. The boundary of placement gives a context or orientation to thinking, but the application to a specific situation can generate a new perception of that situation and, hence, a new possibility to be tested. Therefore, placements are sources of new ideas and possibilities when applied to problems in concrete circumstances.”</em></p>


<div>
<figure><img loading="lazy" decoding="async" width="1024" height="599" src="https://www.designorate.com/wp-content/uploads/2023/12/Wicked_Problems_Design_Thinking-1024x599.jpg" alt="" srcset="https://www.designorate.com/wp-content/uploads/2023/12/Wicked_Problems_Design_Thinking-1024x599.jpg 1024w, https://www.designorate.com/wp-content/uploads/2023/12/Wicked_Problems_Design_Thinking-300x176.jpg 300w, https://www.designorate.com/wp-content/uploads/2023/12/Wicked_Problems_Design_Thinking-768x449.jpg 768w, https://www.designorate.com/wp-content/uploads/2023/12/Wicked_Problems_Design_Thinking.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Wicked Problems in Design Thinking paper by Richard Buchanan</figcaption></figure></div>


<p>The expandable nature of the “placement” presents a critical element of wicked problems and how we can see them as a universal concept whose boundaries can change based on the situation. This manifestation of the definition of the problem elements presented the cornerstone for Kees Dorst’s problem/solution frame discussed in the earlier book Frame Innovation (<a href="https://www.designorate.com/8d-problem-solving-approach/">What is the 8D Problem-Solving?&nbsp;</a>).</p>



<p>His ideas of wicked problems link with Simon’s concept about the design thinking process and how it can be seen as a non-linear process where different design ideas interact in the design arena. Also, In this placement, Buchanan differentiated between four elements of the design thinking process:</p>



<ul>
<li>Signs: material objects</li>



<li>Things: actions</li>



<li>Thoughts: complex systems or environments, which is a weird characterisation.</li>
</ul>



<p>As he links the above elements and the two terms described earlier (category vs placement), he describes the nature of wicked problems:<br><em>“However, when a designer’s conceptual placements become categories of thinking, the result can be mannered imitations of an earlier invention that are no longer relevant to discovering specific possibilities in a new situation. Ideas are then forced onto a situation rather than discovered in the particularities and novel possibilities of that situation.”</em></p>



<p>The above manifestation describes how wicked problems are constructed and change over time, paving the way for a new perspective on problems and their analysis to identify new solutions (check also <a href="https://www.designorate.com/practice-guide-to-solve-problems-with-triz/">How to Use TRIZ in the Problem-Solving Process</a>).</p>



<h2><span id="The_Dilemmas_in_a_General_Theory_of_Planning_by_Rittel_and_Webber"></span>The Dilemmas in a General Theory of Planning by Rittel and Webber<span></span></h2>



<p><a href="https://web.mit.edu/jrankin/www/engin_as_lib_art/Design_thinking.pdf" target="_blank" rel="noreferrer noopener">The Dilemmas in a General Theory of Planning</a> by Rittel and Webber, despite its age, remains a seminal work that has significantly influenced the understanding of wicked problems. Published in 1969, this paper laid the groundwork for Kees Dorst’s Frame Innovation and Buchanan’s Wicked Problems,&nbsp;both of&nbsp;which we’ve discussed. While the&nbsp;paper’s focus is&nbsp;on planning and policy science,&nbsp;its insights can be applied&nbsp;to problem definition and the process of solving them.&nbsp;</p>


<div>
<figure><img loading="lazy" decoding="async" width="1024" height="599" src="https://www.designorate.com/wp-content/uploads/2024/05/Rittel-Webber-1024x599.jpg" alt="" srcset="https://www.designorate.com/wp-content/uploads/2024/05/Rittel-Webber-1024x599.jpg 1024w, https://www.designorate.com/wp-content/uploads/2024/05/Rittel-Webber-300x176.jpg 300w, https://www.designorate.com/wp-content/uploads/2024/05/Rittel-Webber-768x449.jpg 768w, https://www.designorate.com/wp-content/uploads/2024/05/Rittel-Webber.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The Dilemmas in a General Theory of Planning by Rittel and Webber</figcaption></figure></div>


<p>Rittel and Webber distinguished between two types of problems: tame and wicked problems. Tame problems are well-defined and clearly stated, and there is a clear direction to finding the solution, such as scientific and business problems (check how this concept influenced <a href="https://www.designorate.com/practice-guide-to-solve-problems-with-triz/">TRIZ problem-solving</a>). In contrast, wicked problems are ill-defined, and we can’t define the problem until we reach a solution. However, a wicked problem is never solved, yet it moves from one state to an improved,&nbsp;desirable&nbsp;one.&nbsp;</p>



<p>The other nature of wicked problems is that we cannot reach a definitive formulation for them. To describe them, we need to develop an exhaustive inventory of conceivable solutions when asking questions about the problem. So, problem understanding and resolution are linked and change as we build an understanding of the problem at a particular moment in time.&nbsp;</p>



<h2><span id="The_New_Process_New_Vocabulary_Axiofact_A_tefact_Memoranda_by_Gilbert_Cockton"></span>The New Process, New Vocabulary: Axiofact = A_tefact + Memoranda by Gilbert Cockton<span></span></h2>



<p>As you can see, the above books and papers give us a novel look at design problems and how we perceive them. My question is, why do we see problems the way we used to? A big part of the answer lies in our language, which presents mental models that stand as barriers to seeing the core nature of problems, especially the wicked ones. Therefore, we needed new vocabulary that helped us to escape these constraints. <a href="http://library.usc.edu.ph/ACM/CHI%202017/2exab/ea747.pdf" target="_blank" rel="noreferrer noopener">The New Process, New Vocabulary: Axiofact = A_tefact + Memoranda</a>, by my PhD supervisor, Professor Gilbert Cockton, presents a cornerstone of new vocabularies that can help us see design thinking and how to solve problems.&nbsp;</p>



<figure><img loading="lazy" decoding="async" width="1024" height="599" src="https://www.designorate.com/wp-content/uploads/2024/05/Cockton-1024x599.jpg" alt="" srcset="https://www.designorate.com/wp-content/uploads/2024/05/Cockton-1024x599.jpg 1024w, https://www.designorate.com/wp-content/uploads/2024/05/Cockton-300x176.jpg 300w, https://www.designorate.com/wp-content/uploads/2024/05/Cockton-768x449.jpg 768w, https://www.designorate.com/wp-content/uploads/2024/05/Cockton.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The paper eliminated the so-called design thinking process, as the term employs a linear nature; while design thinking is far from linear, it is intersected activities. Cockton described the design practice as design arenas; these arenas are distinguishing “artefacts” and “memoranda.” The “artefact” represents the design outcome, and the “memoranda” is the thing to be borne in mind. This new terminology replaces the problem and solution spaces. However, the Latin root of an artefact means the product of change or doing some art. However, this term is limited as wicked problems are not understood until we solve them, which means artefacts. So, the outcome of the design arena may remain the same as the original state, or the change is against the target user, such as preventive design and design against crime. So, Cockton replaced the word artefact with A_tefact.&nbsp; The memoranda consist of three arenas:</p>



<ul>
<li><strong>Beneficiaries</strong>: The purpose of design</li>



<li><strong>Purposes</strong>: The Artefact and Evaluation</li>



<li><strong>Evaluations</strong>: Modifications to the Artefact</li>
</ul>


<div>
<figure><img loading="lazy" decoding="async" width="1024" height="655" src="https://www.designorate.com/wp-content/uploads/2024/05/Design_Arenas-1024x655.jpg" alt="" srcset="https://www.designorate.com/wp-content/uploads/2024/05/Design_Arenas-1024x655.jpg 1024w, https://www.designorate.com/wp-content/uploads/2024/05/Design_Arenas-300x192.jpg 300w, https://www.designorate.com/wp-content/uploads/2024/05/Design_Arenas-768x492.jpg 768w, https://www.designorate.com/wp-content/uploads/2024/05/Design_Arenas.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The design arenas. Recreated from Cockton (2017).</figcaption></figure></div>


<p>Other terms were also introduced in the paper, such as episodes to replace stages (or phases) that are inherited from linear process age. The multiple foci (sequence by concurrency) replaced the centre of the process term to indicate the complex nature of the iteration with no simple way to describe it. The term “iteration” is replaced with balanced concurrent drama, and validation is replaced with the term “axiofact,” or the value generated. The new terminology presented in Cockton’s paper allows us to escape the old mental model when addressing wicked problems.&nbsp;If you check the <a href="https://www.designorate.com/using-the-mppf-method-in-the-double-diamond-design-process/">MPPF method in Design Thinking</a>, which we discussed previously, you will find it&nbsp;a&nbsp;useful&nbsp;tool&nbsp;as it can help us address wicked problems.&nbsp;</p>



<p>Each of the above books and papers focuses on specific aspects of design and how we observe the design thinking practice driven by feedback from both academia and industry. The different design thinking models are based on appreciating these characteristics of design and encouraging it inside the organization. By applying the steps alone, you will never reach any improved status. You need to recognize these characteristics of design and try to practice them during the design process. Again, the above books came to my mind as key books in design. I am sure there are other titles. So, please share it in the comments below.</p>



<h2><span id="References"></span>References<span></span></h2>



<p>Brown, T. and Katz, B., 2011. Change by design.&nbsp;<em>Journal of Product Innovation Management</em>,&nbsp;<em>28</em>(3), pp.381-383.</p>



<p>Buchanan, R., 1992. Wicked problems in design thinking.&nbsp;<em>Design issues</em>,&nbsp;<em>8</em>(2), pp.5-21.</p>



<p>Cockton, G., 2017, May. New process, new vocabulary: Axiofact= a_tefact+ memoranda. In&nbsp;<em>Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems</em>&nbsp;(pp. 747-757).</p>



<p>Cross, N., 2023.&nbsp;<em>Design thinking: Understanding how designers think and work</em>. Bloomsbury Publishing.</p>



<p>Dorst, K., 2015.&nbsp;<em>Frame innovation: Create new thinking by design</em>. MIT press.</p>



<p>Norman Donald, A., 2013.&nbsp;<em>The design of everyday things</em>. MIT Press.</p>



<p>Lawson, B., 2006.&nbsp;<em>How designers think</em>. Routledge.</p>



<p>Rittel, H.W. and Webber, M.M., 1973. Dilemmas in a general theory of planning.&nbsp;<em>Policy sciences</em>,&nbsp;<em>4</em>(2), pp.155-169.</p>



<p>Simon, H.A., 1988. The science of design: Creating the artificial.&nbsp;<em>Design Issues</em>, pp.67-82.</p>












		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We will ban you and ridicule you in public if you waste our time on crap reports (691 pts)]]></title>
            <link>https://curl.se/.well-known/security.txt</link>
            <guid>46717556</guid>
            <pubDate>Thu, 22 Jan 2026 10:48:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://curl.se/.well-known/security.txt">https://curl.se/.well-known/security.txt</a>, See on <a href="https://news.ycombinator.com/item?id=46717556">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[30 Years of ReactOS (117 pts)]]></title>
            <link>https://reactos.org/blogs/30yrs-of-ros/</link>
            <guid>46716469</guid>
            <pubDate>Thu, 22 Jan 2026 08:03:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reactos.org/blogs/30yrs-of-ros/">https://reactos.org/blogs/30yrs-of-ros/</a>, See on <a href="https://news.ycombinator.com/item?id=46716469">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-content">
							<p>Happy Birthday ReactOS! Today marks 30 years since <a href="https://github.com/reactos/reactos/commit/0f94427db073a20c24f9d85c8531fbe16490af43">the first commit to the ReactOS source tree</a>.
It’s been such a long journey that many of our contributors today, including myself, were not alive during this event.
Yet our mission to deliver “your favorite Windows apps and drivers in an open-source environment you can trust” continues to bring people together.
Let’s take a brief look at some of the high and low points throughout our history.</p>
<!-- raw HTML omitted -->
<h2 id="1996-2003-the-painful-road-to-reactos-010">1996-2003: The Painful Road to ReactOS 0.1.0</h2>
<p>ReactOS started from the ashes of the FreeWin95 project, which aimed to provide a free and open-source clone of Windows 95.
FreeWin95 suffered from analysis paralysis, attempting to plan the whole system before writing any code.
Tired of the lack of progress on the project, Jason Filby took the reins as project coordinator and led a new effort targeting Windows NT.
The project was renamed to “ReactOS” as it was a reaction to Microsoft’s monopolistic position in home computer operating systems.</p>
<p>Progress on ReactOS was very slow at first.
Contributors had to first build a very basic NT-like kernel before they could develop drivers for it, then continue developing the kernel; not too dissimilar to the process of bootstrapping a new programming language.
Once a few basic drivers were written, other contributors were able to learn from these examples and develop other drivers.</p>
<p>While writing this article, I reached out to Eric Kohl. He developed the original storage driver stack for ReactOS (atapi, scsiport, class2, disk, cdrom, cdfs) and has been with the project since 1998. I asked him about his experiences with ReactOS during this time, how he found the project, and what contributing to ReactOS was like during those early days. He wrote:</p>
<blockquote>
<p>I think I found ReactOS while searching for example code for my contributions to the WINE project.
I subscribed to the mailing list and followed the discussions for a few days.
The developers were discussing the future of shell.exe, a little command line interpreter that could only change drives and directories and execute programs.
A few days [later] I had started to convert the FreeDOS command.com into a Win32 console application, because I wanted to extend it to make it 4DOS compatible.
4DOS was a very powerful command line interpreter.
On December 4th, 1998 I introduced myself and suggested to use my converted FreeDOS command.com as the future ReactOS cmd.exe.
I had a little conversation with Jason Filby and Rex Joliff, the CVS repository maintainer.
I sent my cmd.exe code to Rex and he applied it to the repository.
After applying a few more cmd-related patches over the next weeks, Rex asked me whether I would like to have write-access to the repository.
I accepted the offer…</p>
<p>…</p>
<p>The first version I downloaded and used was 0.0.8.
It was not much more than a DOS-based bootloader, some drivers, and a basic kernel that ran a few test routines after initialization.</p>
<p>…</p>
<p>Version 0.0.8 didn’t use PE files, but flat (position independent) binaries.
There was no PE loader,  no smss, no csrss, no winlogon, no process heaps, no process environments, no threads, etc.
Each and every little feature was a milestone.</p>
<p>…</p>
<p>Initially there was not a review process at all.
You write some code, test it and fix it until it works.
Then you commit it.
If something failed on another machine, you got a reply on the mailing list and discussed a solution.
You fixed the issue and committed a fix.
That’s how it worked.</p>
<p>…</p>
<p>There was always an open and friendly atmosphere.
It was and still is always nice to talk to other developers.
No fights, no wars, like in some other projects.</p>

</blockquote>
<p><em>Editors note: minor errors were corrected.</em></p>
<p>ReactOS 0.1.0 was released on February 1st, 2003 and received minor updates up until November 2003.
ReactOS 0.1.0 was the first version of ReactOS that could boot from a CD.
It had a command line interface and no desktop.
Watch a demo of it below, provided courtesy of archeYR.</p>
<p><a href="https://youtu.be/rgRMemZcVoM" target="_blank" rel="noopener noreferrer">
  <img src="https://reactos.org/img/blogs/30yrs-of-ros/ros-0.1.0-thumbnail.png" alt="See ReactOS 0.1.0 by archeYR">
</a></p><h2 id="2003-2006-reactos-02x">2003-2006: ReactOS 0.2.x</h2>
<p>During this period ReactOS saw rapid development.
New drivers were being built all the time, a basic desktop was built, and ReactOS became increasingly stable and usable.
Public interest grew as ReactOS matured.
In October 2005, Jason Filby stepped down as project coordinator, and Steven Edwards was voted to be the next project coordinator.</p>


<div itemscope="" itemtype="http://schema.org/ImageGallery">
	  


<figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
  <a href="https://reactos.org/img/blogs/30yrs-of-ros/ros-0.2.x-boot.png" itemprop="contentUrl"><img itemprop="thumbnail" src="https://reactos.org/img/blogs/30yrs-of-ros/ros-0.2.x-boot.png" alt="ReactOS 0.2.x boot screen"></a>
    <figcaption>
        <p>ReactOS 0.2.x boot screen</p>
    </figcaption>
</figure>



<figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
  <a href="https://reactos.org/img/blogs/30yrs-of-ros/ros-0.2.x-desktop.png" itemprop="contentUrl"><img itemprop="thumbnail" src="https://reactos.org/img/blogs/30yrs-of-ros/ros-0.2.x-desktop.png" alt="ReactOS 0.2.x desktop and file explorer"></a>
    <figcaption>
        <p>ReactOS 0.2.x desktop and file explorer</p>
    </figcaption>
</figure>



<figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
  <a href="https://reactos.org/img/blogs/30yrs-of-ros/ros-0.2.0-desktop.png" itemprop="contentUrl"><img itemprop="thumbnail" src="https://reactos.org/img/blogs/30yrs-of-ros/ros-0.2.0-desktop.png" alt="ReactOS 0.2.0 with VMware video driver for NT 4"></a>
    <figcaption>
        <p>ReactOS 0.2.0 with VMware video driver for NT 4</p>
    </figcaption>
</figure>


</div>

<p>It wasn’t all sunshine and rainbows though.
In January 2006, concerns grew about contributors having access to leaked Windows source code and possibly using this leaked source code in their contributions.
In response, Steven Edwards strengthened the project’s intellectual property policy and the project made the difficult decision to audit the existing source code and temporarily freeze contributions.</p>
<h2 id="2006-2016-reactos-03x">2006-2016: ReactOS 0.3.x</h2>
<p>The ongoing audit and contribution freeze from the end of the ReactOS 0.2.x era slowed development and momentum considerably for ReactOS 0.3.x.
Following challenges with the audit, Steven Edwards stepped down as project coordinator and Aleksey Bragin assumed the role by August 2006.</p>
<p>Despite the challenges during this time, ReactOS 0.3.x continued to build upon ReactOS’s legacy.
ReactOS 0.3.0 was released on August 28th, 2006.
It introduced networking support and a package manager called “Download!”.
This package manager would become the basis for RAPPS, the package manager built into modern versions of ReactOS.
In July 2008, the x86_64 port of ReactOS was started.
One year later, ReactOS 0.3.10 imported the <a href="http://alter.org.ua/soft/win/uni_ata/">UniATA driver</a>, written by Alexandr Telyatnikov (Alter).
While we run into limitations with the UniATA driver today, UniATA enabled ReactOS to support SATA storage devices and to support partitions greater than 8GB in size.
On February 8th, 2012, ReactOS 0.3.14 supported being built using the MSVC compiler and added visual style support.</p>


<div itemscope="" itemtype="http://schema.org/ImageGallery">
	  


<figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
  <a href="https://reactos.org/img/blogs/30yrs-of-ros/ros-0.3.x-desktop.png" itemprop="contentUrl"><img itemprop="thumbnail" src="https://reactos.org/img/blogs/30yrs-of-ros/ros-0.3.x-desktop.png" alt="ReactOS 0.3.x desktop"></a>
    <figcaption>
        <p>ReactOS 0.3.x desktop</p>
    </figcaption>
</figure>



<figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
  <a href="https://reactos.org/img/blogs/30yrs-of-ros/ros-0.3.x-download.png" itemprop="contentUrl"><img itemprop="thumbnail" src="https://reactos.org/img/blogs/30yrs-of-ros/ros-0.3.x-download.png" alt="Download!, the package manager for ReactOS 0.3.x"></a>
    <figcaption>
        <p>Download!, the package manager for ReactOS 0.3.x</p>
    </figcaption>
</figure>


</div>

<h2 id="2016-today-reactos-04x">2016-Today: ReactOS 0.4.x</h2>
<p>ReactOS 0.4.0 was released on February 16th, 2016.
It introduced a new graphical shell that utilized more Windows features and was more similar architecturally to Windows Explorer.
ReactOS 0.4.0 also introduced support for kernel debugging using WinDbg when compiled with MSVC.
Being able to use standard Windows tools for kernel debugging has helped us progress considerably.
ReactOS 0.4.0 continued to receive incremental updates every few months up until versions 0.4.14 and 0.4.15 which had years of development updates each.
Today, the x86_64 port of ReactOS is similarly functional to its x86 counterpart, but with no WoW64 subsystem to run x86 apps its usability is limited.</p>


<div itemscope="" itemtype="http://schema.org/ImageGallery">
	  


<figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
  <a href="https://reactos.org/img/blogs/30yrs-of-ros/explorer-diagram.png" itemprop="contentUrl"><img itemprop="thumbnail" src="https://reactos.org/img/blogs/30yrs-of-ros/explorer-diagram.png" alt="A humorous diagram made in 2015 to explain the complexity of Windows Explorer"></a>
    <figcaption>
        <p>A humorous diagram made in 2015 to explain the complexity of Windows Explorer</p>
    </figcaption>
</figure>



<figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
  <a href="https://reactos.org/img/blogs/30yrs-of-ros/ros-0.4.15-desktop.png" itemprop="contentUrl"><img itemprop="thumbnail" src="https://reactos.org/img/blogs/30yrs-of-ros/ros-0.4.15-desktop.png" alt="ReactOS 0.4.15 desktop, shown with Luna visual style and large taskbar icons applied"></a>
    <figcaption>
        <p>ReactOS 0.4.15 desktop, shown with Luna visual style and large taskbar icons applied</p>
    </figcaption>
</figure>


</div>

<h2 id="the-future-of-reactos">The Future of ReactOS</h2>
<p>We’re continuing to move ReactOS forward. Behind the scenes there are several out-of-tree projects in development. Some of these exciting projects include a new build environment for developers (RosBE), a new NTFS driver, a new ATA driver, multi-processor (SMP) support, support for class 3 UEFI systems, kernel and usermode address space layout randomization (ASLR), and support for modern GPU drivers built on WDDM.</p>
<p>The future of ReactOS will be written by the people who believe in the mission and are willing to help carry it forward.</p>
<p>If you believe in running “your favorite Windows apps and drivers in an open-source environment you can trust”, you can help make that a reality by <a href="https://reactos.org/donate">making a financial contribution</a>, <a href="https://github.com/reactos/reactos">opening a pull request on GitHub</a>, or <a href="https://jira.reactos.org/">testing and filing bug reports</a>.
Even small contributions can help a lot!</p>
<h2 id="statistics">Statistics</h2>
<p><em>Note: Statistics were calculated at commit f60b1c9</em></p>
<ul>
<li>Total commits: 88,198</li>
<li>Total unique contributors: 301</li>
<li>Total files: 31,025</li>
<li>Total lines of code: 14,929,578</li>
</ul>

						</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Doctors in Brazil using tilapia fish skin to treat burn victims (205 pts)]]></title>
            <link>https://www.pbs.org/newshour/health/brazilian-city-uses-tilapia-fish-skin-treat-burn-victims</link>
            <guid>46715600</guid>
            <pubDate>Thu, 22 Jan 2026 05:15:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pbs.org/newshour/health/brazilian-city-uses-tilapia-fish-skin-treat-burn-victims">https://www.pbs.org/newshour/health/brazilian-city-uses-tilapia-fish-skin-treat-burn-victims</a>, See on <a href="https://news.ycombinator.com/item?id=46715600">Hacker News</a></p>
<div id="readability-page-1" class="page"><article itemprop="articleBody">
                <div>
                    <p>FORTAZELA, Brazil — In this historic city by the sea in northeast Brazil, burn patients look as if they've emerged from the waves. They are covered in fish skin — specifically strips of sterilized tilapia.</p>
<p>Doctors here are testing the skin of the popular fish as a bandage for second- and third-degree burns. The innovation arose from an unmet need. Animal skin has long been used in the treatment of burns in developed countries. But Brazil lacks the human skin, pig skin, and artificial alternatives that are widely available in the US.</p>
<p>The three functional skin banks in Brazil can meet only 1 percent of the national demand, said Dr. Edmar Maciel, a plastic surgeon and burn specialist leading the clinical trials with tilapia skin.</p>
<p>As a result, public health patients in Brazil are normally bandaged with gauze and silver sulfadiazine cream.</p>
<p>"It's a burn cream because there's silver in it, so it prevents the burns from being infected," said Dr. Jeanne Lee, interim burn director at the the regional burn center at the University of California at San Diego. "But it doesn't help in terms of debriding a burn or necessarily helping it heal."</p>
<p><a href="https://www.statnews.com/2017/03/01/sweat-burn-patients-skin-grafts/" target="_blank"><strong>READ MORE: First Look: Plumbing the mysteries of sweat to help burn patients cool their skin</strong></a></p>
<p>The gauze-and-cream dressing must be changed every day, a painful process. In the burn unit at Fortaleza's José Frota Institute, patients contort as their wounds are unwrapped and washed.</p>
<p>Enter the humble tilapia, a fish that's widely farmed in Brazil and whose skin, until now, was considered trash. Unlike the gauze bandages, the sterilized tilapia skin goes on and stays on.</p>
<p>The first step in the research process was to analyze the fish skin.</p>
<p>"We got a great surprise when we saw that the amount of collagen proteins, types 1 and 3, which are very important for scarring, exist in large quantities in tilapia skin, even more than in human skin and other skins," Maciel said. "Another factor we discovered is that the amount of tension, of resistance in tilapia skin is much greater than in human skin. Also the amount of moisture."</p>
<p>In patients with superficial second-degree burns, the doctors apply the fish skin and leave it until the patient scars naturally. For deep second-degree burns, the tilapia bandages must be changed a few times over several weeks of treatment, but still far less often than the gauze with cream. The tilapia treatment also cuts down healing time by up to several days and reduces the use of pain medication, Maciel said.</p>
<p>Antônio dos Santos, a fisherman, was offered the tilapia treatment as part of a clinical trial after he sustained burns to his entire right arm when a gas canister on his boat exploded. He accepted.</p>
<p>"After they put on the tilapia skin, it really relieved the pain," he said. "I thought it was really interesting that something like this could work."</p>
<p><a href="https://www.statnews.com/2015/11/11/thermoplastic-bandage/" target="_blank"><strong>READ MORE: High-tech bandage wins $100K from Boston Marathon bombing survivor's family</strong></a></p>
<p>The initial batches of tilapia skin were studied and prepared by a team of researchers at the Federal University of Ceará. Lab technicians used various sterilizing agents, then sent the skins for radiation in São Paulo to kill viruses, before packaging and refrigerating the skins. Once cleaned and treated, they can last for up to two years.</p>
<p>In the US, animal-based skin substitutes require levels of scrutiny from the Food and Drug Administration and animal rights groups that can drive up costs, Lee said. Given the substantial supply of donated human skin, tilapia skin is unlikely to arrive at American hospitals anytime soon.</p>
<p>But it may be a boon in developing countries.</p>
<p>"I'm willing to use anything that might actually help a patient," Lee said. "It may be a good option depending on what country you're talking about. But I also think the problem is that you need to find places that have the resources to actually process the skin and sterilize it, and make sure it doesn't have diseases."</p>
<p>In Brazil, in addition to the clinical trials, researchers are currently conducting histological studies that compare the composition of human, tilapia, pig, and frog skins. They are also conducting studies on the comparative costs of tilapia skin and conventional burn treatments. If clinical trials show continued success, doctors hope a company will process the skins on an industrial scale and sell it to the public health system.</p>
<p><em>This article is reproduced with permission from <a href="https://www.statnews.com/" target="_blank">STAT</a>. It was first published on Mar. 2, 2017. Find the original story <a href="https://www.statnews.com/2017/03/02/brazil-tilapia-skin-burns/" target="_blank">here</a>.</em></p>

                                            <div>
                <figure>
                    <svg><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#pbs-newshour-horiz-refresh"></use></svg>
                </figure>
                <p>
                    A free press is a cornerstone of a healthy democracy. 
                </p>
                <p>
                    Support trusted journalism and civil dialogue. 
                </p>
                <a href="https://give.newshour.org/page/88646/donate/1?ea.tracking.id=pbs_news_sept_2025_article&amp;supporter.appealCode=N2509AW1000100">
                    
                    <svg width="24px" height="24px" viewBox="0 0 16 16" fill="#000000" version="1.1" id="svg1" xmlns="http://www.w3.org/2000/svg" xmlns:svg="http://www.w3.org/2000/svg">
                    <defs id="defs1"></defs>
                    <path fill-rule="evenodd" d="M4 8a.5.5 0 0 1 .5-.5h5.793L8.146 5.354a.5.5 0 1 1 .708-.708l3 3a.5.5 0 0 1 0 .708l-3 3a.5.5 0 0 1-.708-.708L10.293 8.5H4.5A.5.5 0 0 1 4 8z" id="path1"></path>
                    </svg>
                </a>
            </div>


                                    </div>
            </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Significant US Farm Losses Persist, Despite Federal Assistance (248 pts)]]></title>
            <link>https://www.fb.org/market-intel/significant-farm-losses-persist-despite-federal-assistance</link>
            <guid>46713929</guid>
            <pubDate>Thu, 22 Jan 2026 01:11:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fb.org/market-intel/significant-farm-losses-persist-despite-federal-assistance">https://www.fb.org/market-intel/significant-farm-losses-persist-despite-federal-assistance</a>, See on <a href="https://news.ycombinator.com/item?id=46713929">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

  
  






<div id="loop0"><p><strong>Key Takeaways</strong></p><ol><li>Per-acre <strong>production costs</strong> for all nine principal row crops are <strong>projected to rise again in 202</strong><strong>6</strong>, continuing a troubling trend that began after 2021.</li><li>Inflated operating costs <strong>remain</strong> the primary drivers of higher breakeven prices, with limited relief expected in the near term.</li><li>Recent programs have <strong>offset a </strong>portion of losses, but do not fully close the gap between costs and market returns, leaving many farmers potentially operating below breakeven for another year.</li><li><strong>Specialty </strong>crop growers face similar issues as row crop farmers,<strong></strong>but limited data makes per-acre loss estimates challenging.</li></ol><p>The USDA-Economic Research Service (ERS) <a href="https://www.ers.usda.gov/data-products/commodity-costs-and-returns" target="_blank" rel="noreferrer noopener">December update to Commodity Costs and Returns</a> provides a comprehensive look at per-acre production costs for the nine principal row crops: corn, soybeans, wheat, cotton, rice, barley, oats, peanuts and sorghum. At a high level, ERS projects average total costs per acre to increase for every crop in 2026, underscoring the persistence of elevated production expenses across U.S. agriculture. </p></div><!-- /margin and padding --><div><!-- width wrap --><figure><a href="https://www.fb.org/imgz/Slide7.PNG" id="expandparent"><img src="https://www.fb.org/imgz/_w900/251946/Slide7.png"><svg id="expandchild" width="85" height="25" viewBox="0 0 85 25" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0H84.5V24.1429H0V0Z" fill="black"></path><path d="M67.6801 6.90387C67.4835 6.7073 67.4835 6.38886 67.6801 6.1923L69.8512 4.0212C69.8748 3.99762 69.9003 3.97698 69.9278 3.9583C69.9406 3.94946 69.9544 3.94356 69.9672 3.93668C69.9829 3.92783 69.9976 3.91899 70.0143 3.91211C70.031 3.90523 70.0487 3.9013 70.0654 3.89638C70.0792 3.89245 70.093 3.88655 70.1077 3.88361C70.1726 3.87083 70.2394 3.87083 70.3052 3.88361C70.32 3.88655 70.3338 3.89245 70.3475 3.89638C70.3652 3.9013 70.3829 3.90523 70.3996 3.91211C70.4163 3.91899 70.4311 3.92783 70.4468 3.93668C70.4596 3.94356 70.4733 3.94946 70.4861 3.9583C70.5136 3.97698 70.5392 3.99762 70.5628 4.0212L72.7299 6.18838C72.9265 6.38494 72.9265 6.70339 72.7299 6.89995C72.5334 7.0965 72.2149 7.09652 72.0184 6.89995L70.7092 5.59081V9.76976C70.7092 10.0479 70.4841 10.273 70.206 10.273C69.9279 10.273 69.7028 10.0479 69.7028 9.76976L69.7047 5.59181L68.3927 6.9039C68.2944 7.00218 68.1656 7.05133 68.0369 7.05133C67.9081 7.05133 67.7794 7.00218 67.6811 6.9039L67.6801 6.90387ZM72.0193 16.4335L70.7072 17.7456V13.5666C70.7072 13.2885 70.4821 13.0634 70.204 13.0634C69.9259 13.0634 69.7008 13.2885 69.7008 13.5666V17.7456L68.3916 16.4365C68.1951 16.2399 67.8766 16.2399 67.6801 16.4365C67.4835 16.633 67.4835 16.9515 67.6801 17.148L69.8472 19.3152C69.8708 19.3388 69.8964 19.3594 69.9239 19.3781C69.9367 19.386 69.9495 19.3919 69.9632 19.3997C69.979 19.4086 69.9947 19.4174 70.0114 19.4253C70.0281 19.4322 70.0448 19.4361 70.0625 19.441C70.0772 19.4449 70.091 19.4508 70.1057 19.4538C70.1382 19.4607 70.1716 19.4636 70.204 19.4636C70.2374 19.4636 70.2699 19.4597 70.3023 19.4538C70.317 19.4508 70.3308 19.4449 70.3456 19.441C70.3623 19.4361 70.38 19.4322 70.3967 19.4253C70.4134 19.4184 70.4281 19.4086 70.4448 19.3997C70.4576 19.3928 70.4714 19.3869 70.4841 19.3781C70.5117 19.3594 70.5382 19.3388 70.5608 19.3152L72.7319 17.1441C72.9285 16.9475 72.9285 16.6291 72.7319 16.4325C72.5353 16.236 72.2169 16.236 72.0203 16.4325L72.0193 16.4335ZM77.9155 11.9499C77.9204 11.943 77.9224 11.9351 77.9273 11.9282C77.94 11.9076 77.9528 11.886 77.9617 11.8634C77.9656 11.8535 77.9676 11.8437 77.9705 11.8339C77.9774 11.8132 77.9853 11.7916 77.9902 11.77C77.9971 11.7376 78 11.7042 78 11.6707C78 11.6373 77.9961 11.6039 77.9902 11.5715C77.9853 11.5489 77.9784 11.5282 77.9705 11.5076C77.9676 11.4978 77.9656 11.4869 77.9617 11.4781C77.9518 11.4555 77.9391 11.4339 77.9273 11.4132C77.9233 11.4063 77.9204 11.3985 77.9155 11.3916C77.8968 11.3641 77.8762 11.3385 77.8526 11.3149L75.6815 9.14385C75.4849 8.94728 75.1665 8.94728 74.9699 9.14385C74.7733 9.34042 74.7733 9.65886 74.9699 9.85542L76.282 11.1675H72.103C71.8249 11.1675 71.5998 11.3926 71.5998 11.6707C71.5998 11.9489 71.8249 12.1739 72.103 12.1739H76.282L74.9728 13.4831C74.7763 13.6796 74.7763 13.9981 74.9728 14.1946C75.0711 14.2929 75.1999 14.3421 75.3286 14.3421C75.4574 14.3421 75.5861 14.2929 75.6844 14.1946L77.8516 12.0275C77.8752 12.0039 77.8958 11.9783 77.9145 11.9508L77.9155 11.9499ZM64.1281 12.17H68.3071C68.5852 12.17 68.8103 11.9449 68.8103 11.6668C68.8103 11.3887 68.5852 11.1636 68.3071 11.1636H64.1291L65.4383 9.85445C65.6348 9.65788 65.6348 9.33943 65.4383 9.14288C65.2417 8.94632 64.9233 8.94631 64.7267 9.14288L62.5595 11.3101C62.5359 11.3336 62.5153 11.3592 62.4966 11.3867C62.4917 11.3936 62.4898 11.4015 62.4848 11.4083C62.4721 11.429 62.4593 11.4506 62.4504 11.4732C62.4465 11.483 62.4445 11.4929 62.4416 11.5027C62.4347 11.5233 62.4269 11.545 62.4219 11.5666C62.4151 11.599 62.4121 11.6324 62.4121 11.6658C62.4121 11.6993 62.416 11.7327 62.4219 11.7651C62.4269 11.7877 62.4337 11.8084 62.4416 11.829C62.4445 11.8388 62.4465 11.8496 62.4504 11.8585C62.4603 11.8811 62.473 11.9027 62.4848 11.9233C62.4888 11.9302 62.4917 11.9381 62.4966 11.945C62.5153 11.9725 62.5359 11.998 62.5595 12.0216L64.7306 14.1927C64.8289 14.291 64.9577 14.3402 65.0864 14.3402C65.2152 14.3402 65.3439 14.291 65.4422 14.1927C65.6388 13.9962 65.6388 13.6777 65.4422 13.4812L64.1301 12.1691L64.1281 12.17Z" fill="white"></path><path d="M14.5178 15.8906V14.4928H10.3901V11.8421H14.5178V10.4442H10.3901V8.05725H14.5178V6.65938H8.75488V15.8906H14.5178Z" fill="white"></path><path d="M22.4709 9.09906H20.506L19.029 11.2486L17.5784 9.09906H15.5475L17.974 12.4619L15.3497 15.8906H17.3542L18.8971 13.6488L20.4137 15.8906H22.4577L19.9389 12.4487L22.4709 9.09906Z" fill="white"></path><path d="M23.562 9.09906V19.1875H25.1577V15.2049C25.6852 15.7851 26.4896 16.0489 27.2017 16.0489C29.1403 16.0489 30.4854 14.3741 30.4854 12.5146C30.4854 10.5233 29.0875 8.94081 27.2281 8.94081C26.4764 8.94081 25.5797 9.24413 25.1049 9.96944L25.0126 9.09906H23.562ZM25.1577 11.3937C25.5401 10.6552 26.2786 10.3387 26.9248 10.3387C28.1117 10.3387 28.8633 11.3673 28.8633 12.4751C28.8633 13.5169 28.2303 14.651 26.8984 14.651C26.2654 14.651 25.6192 14.3873 25.1577 13.7938V11.3937Z" fill="white"></path><path d="M37.4711 15.8906V11.7893C37.4711 10.0222 36.6403 8.94081 34.7149 8.94081C33.739 8.94081 32.6972 9.21775 31.8928 9.61338L32.328 10.8134C32.9082 10.5101 33.6599 10.22 34.4248 10.22C35.4666 10.22 35.8754 10.7739 35.8754 11.697V11.8553C35.3743 11.7498 34.9523 11.7102 34.5962 11.7102C33.1588 11.7102 31.6026 12.2377 31.6026 13.9257C31.6026 15.3499 32.7763 16.0489 34.0423 16.0489C34.8204 16.0489 35.4798 15.8379 35.9677 15.2576L36.0468 15.8906H37.4711ZM35.8754 14.1894C35.4138 14.5851 34.9259 14.862 34.3325 14.862C33.7126 14.862 33.172 14.5587 33.172 13.8729C33.172 12.9894 34.0819 12.752 34.8336 12.752C35.1369 12.752 35.4666 12.7916 35.8754 12.8839V14.1894Z" fill="white"></path><path d="M39.3895 9.09906V15.8906H40.9852V11.3805C41.3809 10.7475 42.0402 10.3387 42.6732 10.3387C43.1612 10.3387 43.5041 10.5101 43.7019 10.853C43.9524 11.275 43.9656 11.908 43.9656 12.4751V15.8906H45.5613V12.3564C45.5613 11.3673 45.4558 10.4706 44.9547 9.81119C44.5327 9.2705 43.8997 8.94081 43.0821 8.94081C42.2644 8.94081 41.46 9.32325 40.9193 10.1013L40.8402 9.09906H39.3895Z" fill="white"></path><path d="M53.8995 6H52.2906V9.798C51.7631 9.21775 50.9587 8.94081 50.2598 8.94081C48.308 8.94081 46.9761 10.6156 46.9761 12.4751C46.9761 14.4532 48.3608 16.0489 50.2334 16.0489C50.9851 16.0489 51.8686 15.7588 52.3566 15.0203L52.4357 15.8906H53.8995V6ZM52.2906 13.596C51.9082 14.3345 51.1697 14.651 50.5367 14.651C49.3366 14.651 48.5981 13.6224 48.5981 12.5146C48.5981 11.4728 49.2311 10.3387 50.5631 10.3387C51.1829 10.3387 51.8291 10.6024 52.2906 11.1959V13.596Z" fill="white"></path></svg></a></figure></div><!-- /margin --><div id="loop2"><p>When operating expenses and farm-wide costs like equipment, land and management are combined, costs vary widely by crop. In 2025, forecasted total per-acre costs are $1,308 for rice, $1,166 for peanuts, $943 for cotton, $890 for corn, $658 for soybeans, $498 for oats, $491 for barley, $443 for sorghum, and $396 for wheat. Looking ahead, ERS projections for 2026 suggest continued upward pressure across most cost categories, with total cost increasing anywhere from 2.2% to 3.3%. Amongst the nine principal crops, wheat ($409 per acre), sorghum ($458) and oats ($513) remain at the lower end of the production cost spectrum, while soybeans ($678) and barley ($507) fall in the mid-range in 2026. Cotton ($965), peanuts ($1,194) and rice ($1,336) remain the most expensive crops to produce on a per-acre basis. </p><p>Operating costs—expenses directly tied to producing a yearly crop, such as seed, fertilizer, chemicals, fuel and labor—substantially vary across crops. In 2025, total operating costs ranged from $155 per acre for wheat to more than $764 per acre for rice and $631 per acre for peanuts. In 2026, these costs are expected to rise, ranging from $774 per acre for rice and $160 per acre for wheat. While select inputs have moderated slightly from recent peaks, overall operating expenses remain well above pre-2021 levels. Rising costs since 2020 have been driven primarily by sharp increases in interest expenses (+71%), fertilizer (+37%), fuel and oil (+32%), labor (+47%), chemicals (+25%) and maintenance (+27%), alongside notable gains in seed (+18%) and marketing costs (+18%). </p></div><!-- /margin and padding --><div><!-- width wrap --><figure><a href="https://www.fb.org/imgz/Slide8.PNG" id="expandparent"><img src="https://www.fb.org/imgz/_w900/251949/Slide8.png"><svg id="expandchild" width="85" height="25" viewBox="0 0 85 25" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0H84.5V24.1429H0V0Z" fill="black"></path><path d="M67.6801 6.90387C67.4835 6.7073 67.4835 6.38886 67.6801 6.1923L69.8512 4.0212C69.8748 3.99762 69.9003 3.97698 69.9278 3.9583C69.9406 3.94946 69.9544 3.94356 69.9672 3.93668C69.9829 3.92783 69.9976 3.91899 70.0143 3.91211C70.031 3.90523 70.0487 3.9013 70.0654 3.89638C70.0792 3.89245 70.093 3.88655 70.1077 3.88361C70.1726 3.87083 70.2394 3.87083 70.3052 3.88361C70.32 3.88655 70.3338 3.89245 70.3475 3.89638C70.3652 3.9013 70.3829 3.90523 70.3996 3.91211C70.4163 3.91899 70.4311 3.92783 70.4468 3.93668C70.4596 3.94356 70.4733 3.94946 70.4861 3.9583C70.5136 3.97698 70.5392 3.99762 70.5628 4.0212L72.7299 6.18838C72.9265 6.38494 72.9265 6.70339 72.7299 6.89995C72.5334 7.0965 72.2149 7.09652 72.0184 6.89995L70.7092 5.59081V9.76976C70.7092 10.0479 70.4841 10.273 70.206 10.273C69.9279 10.273 69.7028 10.0479 69.7028 9.76976L69.7047 5.59181L68.3927 6.9039C68.2944 7.00218 68.1656 7.05133 68.0369 7.05133C67.9081 7.05133 67.7794 7.00218 67.6811 6.9039L67.6801 6.90387ZM72.0193 16.4335L70.7072 17.7456V13.5666C70.7072 13.2885 70.4821 13.0634 70.204 13.0634C69.9259 13.0634 69.7008 13.2885 69.7008 13.5666V17.7456L68.3916 16.4365C68.1951 16.2399 67.8766 16.2399 67.6801 16.4365C67.4835 16.633 67.4835 16.9515 67.6801 17.148L69.8472 19.3152C69.8708 19.3388 69.8964 19.3594 69.9239 19.3781C69.9367 19.386 69.9495 19.3919 69.9632 19.3997C69.979 19.4086 69.9947 19.4174 70.0114 19.4253C70.0281 19.4322 70.0448 19.4361 70.0625 19.441C70.0772 19.4449 70.091 19.4508 70.1057 19.4538C70.1382 19.4607 70.1716 19.4636 70.204 19.4636C70.2374 19.4636 70.2699 19.4597 70.3023 19.4538C70.317 19.4508 70.3308 19.4449 70.3456 19.441C70.3623 19.4361 70.38 19.4322 70.3967 19.4253C70.4134 19.4184 70.4281 19.4086 70.4448 19.3997C70.4576 19.3928 70.4714 19.3869 70.4841 19.3781C70.5117 19.3594 70.5382 19.3388 70.5608 19.3152L72.7319 17.1441C72.9285 16.9475 72.9285 16.6291 72.7319 16.4325C72.5353 16.236 72.2169 16.236 72.0203 16.4325L72.0193 16.4335ZM77.9155 11.9499C77.9204 11.943 77.9224 11.9351 77.9273 11.9282C77.94 11.9076 77.9528 11.886 77.9617 11.8634C77.9656 11.8535 77.9676 11.8437 77.9705 11.8339C77.9774 11.8132 77.9853 11.7916 77.9902 11.77C77.9971 11.7376 78 11.7042 78 11.6707C78 11.6373 77.9961 11.6039 77.9902 11.5715C77.9853 11.5489 77.9784 11.5282 77.9705 11.5076C77.9676 11.4978 77.9656 11.4869 77.9617 11.4781C77.9518 11.4555 77.9391 11.4339 77.9273 11.4132C77.9233 11.4063 77.9204 11.3985 77.9155 11.3916C77.8968 11.3641 77.8762 11.3385 77.8526 11.3149L75.6815 9.14385C75.4849 8.94728 75.1665 8.94728 74.9699 9.14385C74.7733 9.34042 74.7733 9.65886 74.9699 9.85542L76.282 11.1675H72.103C71.8249 11.1675 71.5998 11.3926 71.5998 11.6707C71.5998 11.9489 71.8249 12.1739 72.103 12.1739H76.282L74.9728 13.4831C74.7763 13.6796 74.7763 13.9981 74.9728 14.1946C75.0711 14.2929 75.1999 14.3421 75.3286 14.3421C75.4574 14.3421 75.5861 14.2929 75.6844 14.1946L77.8516 12.0275C77.8752 12.0039 77.8958 11.9783 77.9145 11.9508L77.9155 11.9499ZM64.1281 12.17H68.3071C68.5852 12.17 68.8103 11.9449 68.8103 11.6668C68.8103 11.3887 68.5852 11.1636 68.3071 11.1636H64.1291L65.4383 9.85445C65.6348 9.65788 65.6348 9.33943 65.4383 9.14288C65.2417 8.94632 64.9233 8.94631 64.7267 9.14288L62.5595 11.3101C62.5359 11.3336 62.5153 11.3592 62.4966 11.3867C62.4917 11.3936 62.4898 11.4015 62.4848 11.4083C62.4721 11.429 62.4593 11.4506 62.4504 11.4732C62.4465 11.483 62.4445 11.4929 62.4416 11.5027C62.4347 11.5233 62.4269 11.545 62.4219 11.5666C62.4151 11.599 62.4121 11.6324 62.4121 11.6658C62.4121 11.6993 62.416 11.7327 62.4219 11.7651C62.4269 11.7877 62.4337 11.8084 62.4416 11.829C62.4445 11.8388 62.4465 11.8496 62.4504 11.8585C62.4603 11.8811 62.473 11.9027 62.4848 11.9233C62.4888 11.9302 62.4917 11.9381 62.4966 11.945C62.5153 11.9725 62.5359 11.998 62.5595 12.0216L64.7306 14.1927C64.8289 14.291 64.9577 14.3402 65.0864 14.3402C65.2152 14.3402 65.3439 14.291 65.4422 14.1927C65.6388 13.9962 65.6388 13.6777 65.4422 13.4812L64.1301 12.1691L64.1281 12.17Z" fill="white"></path><path d="M14.5178 15.8906V14.4928H10.3901V11.8421H14.5178V10.4442H10.3901V8.05725H14.5178V6.65938H8.75488V15.8906H14.5178Z" fill="white"></path><path d="M22.4709 9.09906H20.506L19.029 11.2486L17.5784 9.09906H15.5475L17.974 12.4619L15.3497 15.8906H17.3542L18.8971 13.6488L20.4137 15.8906H22.4577L19.9389 12.4487L22.4709 9.09906Z" fill="white"></path><path d="M23.562 9.09906V19.1875H25.1577V15.2049C25.6852 15.7851 26.4896 16.0489 27.2017 16.0489C29.1403 16.0489 30.4854 14.3741 30.4854 12.5146C30.4854 10.5233 29.0875 8.94081 27.2281 8.94081C26.4764 8.94081 25.5797 9.24413 25.1049 9.96944L25.0126 9.09906H23.562ZM25.1577 11.3937C25.5401 10.6552 26.2786 10.3387 26.9248 10.3387C28.1117 10.3387 28.8633 11.3673 28.8633 12.4751C28.8633 13.5169 28.2303 14.651 26.8984 14.651C26.2654 14.651 25.6192 14.3873 25.1577 13.7938V11.3937Z" fill="white"></path><path d="M37.4711 15.8906V11.7893C37.4711 10.0222 36.6403 8.94081 34.7149 8.94081C33.739 8.94081 32.6972 9.21775 31.8928 9.61338L32.328 10.8134C32.9082 10.5101 33.6599 10.22 34.4248 10.22C35.4666 10.22 35.8754 10.7739 35.8754 11.697V11.8553C35.3743 11.7498 34.9523 11.7102 34.5962 11.7102C33.1588 11.7102 31.6026 12.2377 31.6026 13.9257C31.6026 15.3499 32.7763 16.0489 34.0423 16.0489C34.8204 16.0489 35.4798 15.8379 35.9677 15.2576L36.0468 15.8906H37.4711ZM35.8754 14.1894C35.4138 14.5851 34.9259 14.862 34.3325 14.862C33.7126 14.862 33.172 14.5587 33.172 13.8729C33.172 12.9894 34.0819 12.752 34.8336 12.752C35.1369 12.752 35.4666 12.7916 35.8754 12.8839V14.1894Z" fill="white"></path><path d="M39.3895 9.09906V15.8906H40.9852V11.3805C41.3809 10.7475 42.0402 10.3387 42.6732 10.3387C43.1612 10.3387 43.5041 10.5101 43.7019 10.853C43.9524 11.275 43.9656 11.908 43.9656 12.4751V15.8906H45.5613V12.3564C45.5613 11.3673 45.4558 10.4706 44.9547 9.81119C44.5327 9.2705 43.8997 8.94081 43.0821 8.94081C42.2644 8.94081 41.46 9.32325 40.9193 10.1013L40.8402 9.09906H39.3895Z" fill="white"></path><path d="M53.8995 6H52.2906V9.798C51.7631 9.21775 50.9587 8.94081 50.2598 8.94081C48.308 8.94081 46.9761 10.6156 46.9761 12.4751C46.9761 14.4532 48.3608 16.0489 50.2334 16.0489C50.9851 16.0489 51.8686 15.7588 52.3566 15.0203L52.4357 15.8906H53.8995V6ZM52.2906 13.596C51.9082 14.3345 51.1697 14.651 50.5367 14.651C49.3366 14.651 48.5981 13.6224 48.5981 12.5146C48.5981 11.4728 49.2311 10.3387 50.5631 10.3387C51.1829 10.3387 51.8291 10.6024 52.2906 11.1959V13.596Z" fill="white"></path></svg></a></figure></div><!-- /margin --><div id="loop4"><p><strong>Losses Persist Even After FBA and ECAP </strong></p><p>Against this backdrop of elevated costs, <a href="https://www.fb.org/market-intel/declining-farm-economy-continues-to-pressure-profitability" target="_blank" rel="noreferrer noopener">commodity prices have remained under pressure</a>, limiting farmers’ ability  to cover  their costs through the marketplace alone. As a result, many farms are projected to experience losses for a fourth or fifth consecutive year, even after accounting for crop insurance indemnities and ad hoc assistance. </p></div><!-- /margin and padding --><div><!-- width wrap --><figure><a href="https://www.fb.org/imgz/Slide9.PNG" id="expandparent"><img src="https://www.fb.org/imgz/_w900/251952/Slide9.png"><svg id="expandchild" width="85" height="25" viewBox="0 0 85 25" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0H84.5V24.1429H0V0Z" fill="black"></path><path d="M67.6801 6.90387C67.4835 6.7073 67.4835 6.38886 67.6801 6.1923L69.8512 4.0212C69.8748 3.99762 69.9003 3.97698 69.9278 3.9583C69.9406 3.94946 69.9544 3.94356 69.9672 3.93668C69.9829 3.92783 69.9976 3.91899 70.0143 3.91211C70.031 3.90523 70.0487 3.9013 70.0654 3.89638C70.0792 3.89245 70.093 3.88655 70.1077 3.88361C70.1726 3.87083 70.2394 3.87083 70.3052 3.88361C70.32 3.88655 70.3338 3.89245 70.3475 3.89638C70.3652 3.9013 70.3829 3.90523 70.3996 3.91211C70.4163 3.91899 70.4311 3.92783 70.4468 3.93668C70.4596 3.94356 70.4733 3.94946 70.4861 3.9583C70.5136 3.97698 70.5392 3.99762 70.5628 4.0212L72.7299 6.18838C72.9265 6.38494 72.9265 6.70339 72.7299 6.89995C72.5334 7.0965 72.2149 7.09652 72.0184 6.89995L70.7092 5.59081V9.76976C70.7092 10.0479 70.4841 10.273 70.206 10.273C69.9279 10.273 69.7028 10.0479 69.7028 9.76976L69.7047 5.59181L68.3927 6.9039C68.2944 7.00218 68.1656 7.05133 68.0369 7.05133C67.9081 7.05133 67.7794 7.00218 67.6811 6.9039L67.6801 6.90387ZM72.0193 16.4335L70.7072 17.7456V13.5666C70.7072 13.2885 70.4821 13.0634 70.204 13.0634C69.9259 13.0634 69.7008 13.2885 69.7008 13.5666V17.7456L68.3916 16.4365C68.1951 16.2399 67.8766 16.2399 67.6801 16.4365C67.4835 16.633 67.4835 16.9515 67.6801 17.148L69.8472 19.3152C69.8708 19.3388 69.8964 19.3594 69.9239 19.3781C69.9367 19.386 69.9495 19.3919 69.9632 19.3997C69.979 19.4086 69.9947 19.4174 70.0114 19.4253C70.0281 19.4322 70.0448 19.4361 70.0625 19.441C70.0772 19.4449 70.091 19.4508 70.1057 19.4538C70.1382 19.4607 70.1716 19.4636 70.204 19.4636C70.2374 19.4636 70.2699 19.4597 70.3023 19.4538C70.317 19.4508 70.3308 19.4449 70.3456 19.441C70.3623 19.4361 70.38 19.4322 70.3967 19.4253C70.4134 19.4184 70.4281 19.4086 70.4448 19.3997C70.4576 19.3928 70.4714 19.3869 70.4841 19.3781C70.5117 19.3594 70.5382 19.3388 70.5608 19.3152L72.7319 17.1441C72.9285 16.9475 72.9285 16.6291 72.7319 16.4325C72.5353 16.236 72.2169 16.236 72.0203 16.4325L72.0193 16.4335ZM77.9155 11.9499C77.9204 11.943 77.9224 11.9351 77.9273 11.9282C77.94 11.9076 77.9528 11.886 77.9617 11.8634C77.9656 11.8535 77.9676 11.8437 77.9705 11.8339C77.9774 11.8132 77.9853 11.7916 77.9902 11.77C77.9971 11.7376 78 11.7042 78 11.6707C78 11.6373 77.9961 11.6039 77.9902 11.5715C77.9853 11.5489 77.9784 11.5282 77.9705 11.5076C77.9676 11.4978 77.9656 11.4869 77.9617 11.4781C77.9518 11.4555 77.9391 11.4339 77.9273 11.4132C77.9233 11.4063 77.9204 11.3985 77.9155 11.3916C77.8968 11.3641 77.8762 11.3385 77.8526 11.3149L75.6815 9.14385C75.4849 8.94728 75.1665 8.94728 74.9699 9.14385C74.7733 9.34042 74.7733 9.65886 74.9699 9.85542L76.282 11.1675H72.103C71.8249 11.1675 71.5998 11.3926 71.5998 11.6707C71.5998 11.9489 71.8249 12.1739 72.103 12.1739H76.282L74.9728 13.4831C74.7763 13.6796 74.7763 13.9981 74.9728 14.1946C75.0711 14.2929 75.1999 14.3421 75.3286 14.3421C75.4574 14.3421 75.5861 14.2929 75.6844 14.1946L77.8516 12.0275C77.8752 12.0039 77.8958 11.9783 77.9145 11.9508L77.9155 11.9499ZM64.1281 12.17H68.3071C68.5852 12.17 68.8103 11.9449 68.8103 11.6668C68.8103 11.3887 68.5852 11.1636 68.3071 11.1636H64.1291L65.4383 9.85445C65.6348 9.65788 65.6348 9.33943 65.4383 9.14288C65.2417 8.94632 64.9233 8.94631 64.7267 9.14288L62.5595 11.3101C62.5359 11.3336 62.5153 11.3592 62.4966 11.3867C62.4917 11.3936 62.4898 11.4015 62.4848 11.4083C62.4721 11.429 62.4593 11.4506 62.4504 11.4732C62.4465 11.483 62.4445 11.4929 62.4416 11.5027C62.4347 11.5233 62.4269 11.545 62.4219 11.5666C62.4151 11.599 62.4121 11.6324 62.4121 11.6658C62.4121 11.6993 62.416 11.7327 62.4219 11.7651C62.4269 11.7877 62.4337 11.8084 62.4416 11.829C62.4445 11.8388 62.4465 11.8496 62.4504 11.8585C62.4603 11.8811 62.473 11.9027 62.4848 11.9233C62.4888 11.9302 62.4917 11.9381 62.4966 11.945C62.5153 11.9725 62.5359 11.998 62.5595 12.0216L64.7306 14.1927C64.8289 14.291 64.9577 14.3402 65.0864 14.3402C65.2152 14.3402 65.3439 14.291 65.4422 14.1927C65.6388 13.9962 65.6388 13.6777 65.4422 13.4812L64.1301 12.1691L64.1281 12.17Z" fill="white"></path><path d="M14.5178 15.8906V14.4928H10.3901V11.8421H14.5178V10.4442H10.3901V8.05725H14.5178V6.65938H8.75488V15.8906H14.5178Z" fill="white"></path><path d="M22.4709 9.09906H20.506L19.029 11.2486L17.5784 9.09906H15.5475L17.974 12.4619L15.3497 15.8906H17.3542L18.8971 13.6488L20.4137 15.8906H22.4577L19.9389 12.4487L22.4709 9.09906Z" fill="white"></path><path d="M23.562 9.09906V19.1875H25.1577V15.2049C25.6852 15.7851 26.4896 16.0489 27.2017 16.0489C29.1403 16.0489 30.4854 14.3741 30.4854 12.5146C30.4854 10.5233 29.0875 8.94081 27.2281 8.94081C26.4764 8.94081 25.5797 9.24413 25.1049 9.96944L25.0126 9.09906H23.562ZM25.1577 11.3937C25.5401 10.6552 26.2786 10.3387 26.9248 10.3387C28.1117 10.3387 28.8633 11.3673 28.8633 12.4751C28.8633 13.5169 28.2303 14.651 26.8984 14.651C26.2654 14.651 25.6192 14.3873 25.1577 13.7938V11.3937Z" fill="white"></path><path d="M37.4711 15.8906V11.7893C37.4711 10.0222 36.6403 8.94081 34.7149 8.94081C33.739 8.94081 32.6972 9.21775 31.8928 9.61338L32.328 10.8134C32.9082 10.5101 33.6599 10.22 34.4248 10.22C35.4666 10.22 35.8754 10.7739 35.8754 11.697V11.8553C35.3743 11.7498 34.9523 11.7102 34.5962 11.7102C33.1588 11.7102 31.6026 12.2377 31.6026 13.9257C31.6026 15.3499 32.7763 16.0489 34.0423 16.0489C34.8204 16.0489 35.4798 15.8379 35.9677 15.2576L36.0468 15.8906H37.4711ZM35.8754 14.1894C35.4138 14.5851 34.9259 14.862 34.3325 14.862C33.7126 14.862 33.172 14.5587 33.172 13.8729C33.172 12.9894 34.0819 12.752 34.8336 12.752C35.1369 12.752 35.4666 12.7916 35.8754 12.8839V14.1894Z" fill="white"></path><path d="M39.3895 9.09906V15.8906H40.9852V11.3805C41.3809 10.7475 42.0402 10.3387 42.6732 10.3387C43.1612 10.3387 43.5041 10.5101 43.7019 10.853C43.9524 11.275 43.9656 11.908 43.9656 12.4751V15.8906H45.5613V12.3564C45.5613 11.3673 45.4558 10.4706 44.9547 9.81119C44.5327 9.2705 43.8997 8.94081 43.0821 8.94081C42.2644 8.94081 41.46 9.32325 40.9193 10.1013L40.8402 9.09906H39.3895Z" fill="white"></path><path d="M53.8995 6H52.2906V9.798C51.7631 9.21775 50.9587 8.94081 50.2598 8.94081C48.308 8.94081 46.9761 10.6156 46.9761 12.4751C46.9761 14.4532 48.3608 16.0489 50.2334 16.0489C50.9851 16.0489 51.8686 15.7588 52.3566 15.0203L52.4357 15.8906H53.8995V6ZM52.2906 13.596C51.9082 14.3345 51.1697 14.651 50.5367 14.651C49.3366 14.651 48.5981 13.6224 48.5981 12.5146C48.5981 11.4728 49.2311 10.3387 50.5631 10.3387C51.1829 10.3387 51.8291 10.6024 52.2906 11.1959V13.596Z" fill="white"></path></svg></a></figure></div><!-- /margin --><p>The  <a href="https://www.fb.org/market-intel/farmer-bridge-assistance-program-details-on-11-billion-in-aid" target="_blank" rel="noreferrer noopener">Farmer Bridge Assistance (FBA) Program</a> and the <a href="https://www.fb.org/market-intel/emergency-commodity-assistance-program-ecap-what-you-need-to-know" target="_blank" rel="noreferrer noopener">Emergency Commodity Assistance Program (ECAP)</a> provide important near-term support. However, ECAP was designed to address 2023 and 2024 losses, rather than 2025 and later production challenges. For both programs, payments are calculated on a per-acre basis. However, when compared to current per-acre production costs and weak commodity prices, these payments generally cover only a share of losses rather than restore profitability. In fact, returns over total costs for all nine principal row crops are projected to remain negative on a per-acre basis even after accounting for federal assistance. Based on loss calculations used in the Farmer Bridge Assistance Program, rice producers face losses of roughly $210 per acre, followed by cotton ($202), oats ($159), peanuts ($131), sorghum ($91), corn ($87), wheat ($70), soybeans ($61) and barley ($42). In total, net losses across the sector are estimated to exceed $50 billion over the past three crop years.</p><!-- /margin and padding --><div><!-- width wrap --><figure><a href="https://www.fb.org/imgz/Slide13.PNG" id="expandparent"><img src="https://www.fb.org/imgz/_w900/251955/Slide13.png"><svg id="expandchild" width="85" height="25" viewBox="0 0 85 25" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0H84.5V24.1429H0V0Z" fill="black"></path><path d="M67.6801 6.90387C67.4835 6.7073 67.4835 6.38886 67.6801 6.1923L69.8512 4.0212C69.8748 3.99762 69.9003 3.97698 69.9278 3.9583C69.9406 3.94946 69.9544 3.94356 69.9672 3.93668C69.9829 3.92783 69.9976 3.91899 70.0143 3.91211C70.031 3.90523 70.0487 3.9013 70.0654 3.89638C70.0792 3.89245 70.093 3.88655 70.1077 3.88361C70.1726 3.87083 70.2394 3.87083 70.3052 3.88361C70.32 3.88655 70.3338 3.89245 70.3475 3.89638C70.3652 3.9013 70.3829 3.90523 70.3996 3.91211C70.4163 3.91899 70.4311 3.92783 70.4468 3.93668C70.4596 3.94356 70.4733 3.94946 70.4861 3.9583C70.5136 3.97698 70.5392 3.99762 70.5628 4.0212L72.7299 6.18838C72.9265 6.38494 72.9265 6.70339 72.7299 6.89995C72.5334 7.0965 72.2149 7.09652 72.0184 6.89995L70.7092 5.59081V9.76976C70.7092 10.0479 70.4841 10.273 70.206 10.273C69.9279 10.273 69.7028 10.0479 69.7028 9.76976L69.7047 5.59181L68.3927 6.9039C68.2944 7.00218 68.1656 7.05133 68.0369 7.05133C67.9081 7.05133 67.7794 7.00218 67.6811 6.9039L67.6801 6.90387ZM72.0193 16.4335L70.7072 17.7456V13.5666C70.7072 13.2885 70.4821 13.0634 70.204 13.0634C69.9259 13.0634 69.7008 13.2885 69.7008 13.5666V17.7456L68.3916 16.4365C68.1951 16.2399 67.8766 16.2399 67.6801 16.4365C67.4835 16.633 67.4835 16.9515 67.6801 17.148L69.8472 19.3152C69.8708 19.3388 69.8964 19.3594 69.9239 19.3781C69.9367 19.386 69.9495 19.3919 69.9632 19.3997C69.979 19.4086 69.9947 19.4174 70.0114 19.4253C70.0281 19.4322 70.0448 19.4361 70.0625 19.441C70.0772 19.4449 70.091 19.4508 70.1057 19.4538C70.1382 19.4607 70.1716 19.4636 70.204 19.4636C70.2374 19.4636 70.2699 19.4597 70.3023 19.4538C70.317 19.4508 70.3308 19.4449 70.3456 19.441C70.3623 19.4361 70.38 19.4322 70.3967 19.4253C70.4134 19.4184 70.4281 19.4086 70.4448 19.3997C70.4576 19.3928 70.4714 19.3869 70.4841 19.3781C70.5117 19.3594 70.5382 19.3388 70.5608 19.3152L72.7319 17.1441C72.9285 16.9475 72.9285 16.6291 72.7319 16.4325C72.5353 16.236 72.2169 16.236 72.0203 16.4325L72.0193 16.4335ZM77.9155 11.9499C77.9204 11.943 77.9224 11.9351 77.9273 11.9282C77.94 11.9076 77.9528 11.886 77.9617 11.8634C77.9656 11.8535 77.9676 11.8437 77.9705 11.8339C77.9774 11.8132 77.9853 11.7916 77.9902 11.77C77.9971 11.7376 78 11.7042 78 11.6707C78 11.6373 77.9961 11.6039 77.9902 11.5715C77.9853 11.5489 77.9784 11.5282 77.9705 11.5076C77.9676 11.4978 77.9656 11.4869 77.9617 11.4781C77.9518 11.4555 77.9391 11.4339 77.9273 11.4132C77.9233 11.4063 77.9204 11.3985 77.9155 11.3916C77.8968 11.3641 77.8762 11.3385 77.8526 11.3149L75.6815 9.14385C75.4849 8.94728 75.1665 8.94728 74.9699 9.14385C74.7733 9.34042 74.7733 9.65886 74.9699 9.85542L76.282 11.1675H72.103C71.8249 11.1675 71.5998 11.3926 71.5998 11.6707C71.5998 11.9489 71.8249 12.1739 72.103 12.1739H76.282L74.9728 13.4831C74.7763 13.6796 74.7763 13.9981 74.9728 14.1946C75.0711 14.2929 75.1999 14.3421 75.3286 14.3421C75.4574 14.3421 75.5861 14.2929 75.6844 14.1946L77.8516 12.0275C77.8752 12.0039 77.8958 11.9783 77.9145 11.9508L77.9155 11.9499ZM64.1281 12.17H68.3071C68.5852 12.17 68.8103 11.9449 68.8103 11.6668C68.8103 11.3887 68.5852 11.1636 68.3071 11.1636H64.1291L65.4383 9.85445C65.6348 9.65788 65.6348 9.33943 65.4383 9.14288C65.2417 8.94632 64.9233 8.94631 64.7267 9.14288L62.5595 11.3101C62.5359 11.3336 62.5153 11.3592 62.4966 11.3867C62.4917 11.3936 62.4898 11.4015 62.4848 11.4083C62.4721 11.429 62.4593 11.4506 62.4504 11.4732C62.4465 11.483 62.4445 11.4929 62.4416 11.5027C62.4347 11.5233 62.4269 11.545 62.4219 11.5666C62.4151 11.599 62.4121 11.6324 62.4121 11.6658C62.4121 11.6993 62.416 11.7327 62.4219 11.7651C62.4269 11.7877 62.4337 11.8084 62.4416 11.829C62.4445 11.8388 62.4465 11.8496 62.4504 11.8585C62.4603 11.8811 62.473 11.9027 62.4848 11.9233C62.4888 11.9302 62.4917 11.9381 62.4966 11.945C62.5153 11.9725 62.5359 11.998 62.5595 12.0216L64.7306 14.1927C64.8289 14.291 64.9577 14.3402 65.0864 14.3402C65.2152 14.3402 65.3439 14.291 65.4422 14.1927C65.6388 13.9962 65.6388 13.6777 65.4422 13.4812L64.1301 12.1691L64.1281 12.17Z" fill="white"></path><path d="M14.5178 15.8906V14.4928H10.3901V11.8421H14.5178V10.4442H10.3901V8.05725H14.5178V6.65938H8.75488V15.8906H14.5178Z" fill="white"></path><path d="M22.4709 9.09906H20.506L19.029 11.2486L17.5784 9.09906H15.5475L17.974 12.4619L15.3497 15.8906H17.3542L18.8971 13.6488L20.4137 15.8906H22.4577L19.9389 12.4487L22.4709 9.09906Z" fill="white"></path><path d="M23.562 9.09906V19.1875H25.1577V15.2049C25.6852 15.7851 26.4896 16.0489 27.2017 16.0489C29.1403 16.0489 30.4854 14.3741 30.4854 12.5146C30.4854 10.5233 29.0875 8.94081 27.2281 8.94081C26.4764 8.94081 25.5797 9.24413 25.1049 9.96944L25.0126 9.09906H23.562ZM25.1577 11.3937C25.5401 10.6552 26.2786 10.3387 26.9248 10.3387C28.1117 10.3387 28.8633 11.3673 28.8633 12.4751C28.8633 13.5169 28.2303 14.651 26.8984 14.651C26.2654 14.651 25.6192 14.3873 25.1577 13.7938V11.3937Z" fill="white"></path><path d="M37.4711 15.8906V11.7893C37.4711 10.0222 36.6403 8.94081 34.7149 8.94081C33.739 8.94081 32.6972 9.21775 31.8928 9.61338L32.328 10.8134C32.9082 10.5101 33.6599 10.22 34.4248 10.22C35.4666 10.22 35.8754 10.7739 35.8754 11.697V11.8553C35.3743 11.7498 34.9523 11.7102 34.5962 11.7102C33.1588 11.7102 31.6026 12.2377 31.6026 13.9257C31.6026 15.3499 32.7763 16.0489 34.0423 16.0489C34.8204 16.0489 35.4798 15.8379 35.9677 15.2576L36.0468 15.8906H37.4711ZM35.8754 14.1894C35.4138 14.5851 34.9259 14.862 34.3325 14.862C33.7126 14.862 33.172 14.5587 33.172 13.8729C33.172 12.9894 34.0819 12.752 34.8336 12.752C35.1369 12.752 35.4666 12.7916 35.8754 12.8839V14.1894Z" fill="white"></path><path d="M39.3895 9.09906V15.8906H40.9852V11.3805C41.3809 10.7475 42.0402 10.3387 42.6732 10.3387C43.1612 10.3387 43.5041 10.5101 43.7019 10.853C43.9524 11.275 43.9656 11.908 43.9656 12.4751V15.8906H45.5613V12.3564C45.5613 11.3673 45.4558 10.4706 44.9547 9.81119C44.5327 9.2705 43.8997 8.94081 43.0821 8.94081C42.2644 8.94081 41.46 9.32325 40.9193 10.1013L40.8402 9.09906H39.3895Z" fill="white"></path><path d="M53.8995 6H52.2906V9.798C51.7631 9.21775 50.9587 8.94081 50.2598 8.94081C48.308 8.94081 46.9761 10.6156 46.9761 12.4751C46.9761 14.4532 48.3608 16.0489 50.2334 16.0489C50.9851 16.0489 51.8686 15.7588 52.3566 15.0203L52.4357 15.8906H53.8995V6ZM52.2906 13.596C51.9082 14.3345 51.1697 14.651 50.5367 14.651C49.3366 14.651 48.5981 13.6224 48.5981 12.5146C48.5981 11.4728 49.2311 10.3387 50.5631 10.3387C51.1829 10.3387 51.8291 10.6024 52.2906 11.1959V13.596Z" fill="white"></path></svg></a></figure></div><!-- /margin --><p>For many farms, aid helps slow the erosion of working capital but does not fully offset negative margins. As a result, producers continue to absorb multiyear losses that strain balance sheets, tighten cash flow and complicate access to operating credit. These loss estimates reflect national averages; actual costs of production and returns vary by region, management decisions and ownership structure. For example, producers who own their farmland may face lower total costs by avoiding cash rental expenses, resulting in higher returns.</p><!-- /margin and padding --><!-- /margin --><div id="loop10"><p><strong>Specialty Crops<br></strong><br>Additionally, neither the FBA program nor the ECAP <a href="https://www.fb.org/market-intel/specialty-crops-need-economic-aid-case-studies-almonds-apples-blueberries-lettuce-potatoes-and-strawberries" target="_blank" rel="noreferrer noopener">address losses in the specialty crops</a> market. The 2024 <a href="https://www.fb.org/market-intel/marketing-assistance-for-specialty-crops-a-closer-look" target="_blank" rel="noreferrer noopener">Marketing Assistance for Specialty Crop Program (MASC)</a> provided a first but limited relief step for growers and, for many, represented some of the first federal assistance tied to market challenges in the sector. Specialty crop growers continue to face deep and persistent economic losses driven by rising input costs, tightening margins, weather and disease disruptions, labor expenses and constraints, and global trade instability — challenges shared by field crop agriculture, including producers of crops beyond the nine principal crops, such as <a href="https://www.fb.org/market-intel/alfalfa-in-the-red-rising-costs-falling-returns" target="_blank" rel="noreferrer noopener">alfalfa</a> and sugar beets. Strengthening support for all sectors of agriculture is an economic necessity. Doing so will help maintain a resilient, accessible and diverse U.S. food system. </p><p><strong>Conclusion</strong></p><p>ERS cost projections make clear that input costs for all of the nine principal row crops remain elevated and sticky. Continued increases in both operating and overhead expenses are pushing breakeven prices higher, while commodity prices remain insufficient to offset those costs for many producers. </p></div><!-- /margin and padding --><div><!-- width wrap --><figure><a href="https://www.fb.org/imgz/mya_2026-01-21-143536_lsgv.png" id="expandparent"><img src=""><svg id="expandchild" width="85" height="25" viewBox="0 0 85 25" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0H84.5V24.1429H0V0Z" fill="black"></path><path d="M67.6801 6.90387C67.4835 6.7073 67.4835 6.38886 67.6801 6.1923L69.8512 4.0212C69.8748 3.99762 69.9003 3.97698 69.9278 3.9583C69.9406 3.94946 69.9544 3.94356 69.9672 3.93668C69.9829 3.92783 69.9976 3.91899 70.0143 3.91211C70.031 3.90523 70.0487 3.9013 70.0654 3.89638C70.0792 3.89245 70.093 3.88655 70.1077 3.88361C70.1726 3.87083 70.2394 3.87083 70.3052 3.88361C70.32 3.88655 70.3338 3.89245 70.3475 3.89638C70.3652 3.9013 70.3829 3.90523 70.3996 3.91211C70.4163 3.91899 70.4311 3.92783 70.4468 3.93668C70.4596 3.94356 70.4733 3.94946 70.4861 3.9583C70.5136 3.97698 70.5392 3.99762 70.5628 4.0212L72.7299 6.18838C72.9265 6.38494 72.9265 6.70339 72.7299 6.89995C72.5334 7.0965 72.2149 7.09652 72.0184 6.89995L70.7092 5.59081V9.76976C70.7092 10.0479 70.4841 10.273 70.206 10.273C69.9279 10.273 69.7028 10.0479 69.7028 9.76976L69.7047 5.59181L68.3927 6.9039C68.2944 7.00218 68.1656 7.05133 68.0369 7.05133C67.9081 7.05133 67.7794 7.00218 67.6811 6.9039L67.6801 6.90387ZM72.0193 16.4335L70.7072 17.7456V13.5666C70.7072 13.2885 70.4821 13.0634 70.204 13.0634C69.9259 13.0634 69.7008 13.2885 69.7008 13.5666V17.7456L68.3916 16.4365C68.1951 16.2399 67.8766 16.2399 67.6801 16.4365C67.4835 16.633 67.4835 16.9515 67.6801 17.148L69.8472 19.3152C69.8708 19.3388 69.8964 19.3594 69.9239 19.3781C69.9367 19.386 69.9495 19.3919 69.9632 19.3997C69.979 19.4086 69.9947 19.4174 70.0114 19.4253C70.0281 19.4322 70.0448 19.4361 70.0625 19.441C70.0772 19.4449 70.091 19.4508 70.1057 19.4538C70.1382 19.4607 70.1716 19.4636 70.204 19.4636C70.2374 19.4636 70.2699 19.4597 70.3023 19.4538C70.317 19.4508 70.3308 19.4449 70.3456 19.441C70.3623 19.4361 70.38 19.4322 70.3967 19.4253C70.4134 19.4184 70.4281 19.4086 70.4448 19.3997C70.4576 19.3928 70.4714 19.3869 70.4841 19.3781C70.5117 19.3594 70.5382 19.3388 70.5608 19.3152L72.7319 17.1441C72.9285 16.9475 72.9285 16.6291 72.7319 16.4325C72.5353 16.236 72.2169 16.236 72.0203 16.4325L72.0193 16.4335ZM77.9155 11.9499C77.9204 11.943 77.9224 11.9351 77.9273 11.9282C77.94 11.9076 77.9528 11.886 77.9617 11.8634C77.9656 11.8535 77.9676 11.8437 77.9705 11.8339C77.9774 11.8132 77.9853 11.7916 77.9902 11.77C77.9971 11.7376 78 11.7042 78 11.6707C78 11.6373 77.9961 11.6039 77.9902 11.5715C77.9853 11.5489 77.9784 11.5282 77.9705 11.5076C77.9676 11.4978 77.9656 11.4869 77.9617 11.4781C77.9518 11.4555 77.9391 11.4339 77.9273 11.4132C77.9233 11.4063 77.9204 11.3985 77.9155 11.3916C77.8968 11.3641 77.8762 11.3385 77.8526 11.3149L75.6815 9.14385C75.4849 8.94728 75.1665 8.94728 74.9699 9.14385C74.7733 9.34042 74.7733 9.65886 74.9699 9.85542L76.282 11.1675H72.103C71.8249 11.1675 71.5998 11.3926 71.5998 11.6707C71.5998 11.9489 71.8249 12.1739 72.103 12.1739H76.282L74.9728 13.4831C74.7763 13.6796 74.7763 13.9981 74.9728 14.1946C75.0711 14.2929 75.1999 14.3421 75.3286 14.3421C75.4574 14.3421 75.5861 14.2929 75.6844 14.1946L77.8516 12.0275C77.8752 12.0039 77.8958 11.9783 77.9145 11.9508L77.9155 11.9499ZM64.1281 12.17H68.3071C68.5852 12.17 68.8103 11.9449 68.8103 11.6668C68.8103 11.3887 68.5852 11.1636 68.3071 11.1636H64.1291L65.4383 9.85445C65.6348 9.65788 65.6348 9.33943 65.4383 9.14288C65.2417 8.94632 64.9233 8.94631 64.7267 9.14288L62.5595 11.3101C62.5359 11.3336 62.5153 11.3592 62.4966 11.3867C62.4917 11.3936 62.4898 11.4015 62.4848 11.4083C62.4721 11.429 62.4593 11.4506 62.4504 11.4732C62.4465 11.483 62.4445 11.4929 62.4416 11.5027C62.4347 11.5233 62.4269 11.545 62.4219 11.5666C62.4151 11.599 62.4121 11.6324 62.4121 11.6658C62.4121 11.6993 62.416 11.7327 62.4219 11.7651C62.4269 11.7877 62.4337 11.8084 62.4416 11.829C62.4445 11.8388 62.4465 11.8496 62.4504 11.8585C62.4603 11.8811 62.473 11.9027 62.4848 11.9233C62.4888 11.9302 62.4917 11.9381 62.4966 11.945C62.5153 11.9725 62.5359 11.998 62.5595 12.0216L64.7306 14.1927C64.8289 14.291 64.9577 14.3402 65.0864 14.3402C65.2152 14.3402 65.3439 14.291 65.4422 14.1927C65.6388 13.9962 65.6388 13.6777 65.4422 13.4812L64.1301 12.1691L64.1281 12.17Z" fill="white"></path><path d="M14.5178 15.8906V14.4928H10.3901V11.8421H14.5178V10.4442H10.3901V8.05725H14.5178V6.65938H8.75488V15.8906H14.5178Z" fill="white"></path><path d="M22.4709 9.09906H20.506L19.029 11.2486L17.5784 9.09906H15.5475L17.974 12.4619L15.3497 15.8906H17.3542L18.8971 13.6488L20.4137 15.8906H22.4577L19.9389 12.4487L22.4709 9.09906Z" fill="white"></path><path d="M23.562 9.09906V19.1875H25.1577V15.2049C25.6852 15.7851 26.4896 16.0489 27.2017 16.0489C29.1403 16.0489 30.4854 14.3741 30.4854 12.5146C30.4854 10.5233 29.0875 8.94081 27.2281 8.94081C26.4764 8.94081 25.5797 9.24413 25.1049 9.96944L25.0126 9.09906H23.562ZM25.1577 11.3937C25.5401 10.6552 26.2786 10.3387 26.9248 10.3387C28.1117 10.3387 28.8633 11.3673 28.8633 12.4751C28.8633 13.5169 28.2303 14.651 26.8984 14.651C26.2654 14.651 25.6192 14.3873 25.1577 13.7938V11.3937Z" fill="white"></path><path d="M37.4711 15.8906V11.7893C37.4711 10.0222 36.6403 8.94081 34.7149 8.94081C33.739 8.94081 32.6972 9.21775 31.8928 9.61338L32.328 10.8134C32.9082 10.5101 33.6599 10.22 34.4248 10.22C35.4666 10.22 35.8754 10.7739 35.8754 11.697V11.8553C35.3743 11.7498 34.9523 11.7102 34.5962 11.7102C33.1588 11.7102 31.6026 12.2377 31.6026 13.9257C31.6026 15.3499 32.7763 16.0489 34.0423 16.0489C34.8204 16.0489 35.4798 15.8379 35.9677 15.2576L36.0468 15.8906H37.4711ZM35.8754 14.1894C35.4138 14.5851 34.9259 14.862 34.3325 14.862C33.7126 14.862 33.172 14.5587 33.172 13.8729C33.172 12.9894 34.0819 12.752 34.8336 12.752C35.1369 12.752 35.4666 12.7916 35.8754 12.8839V14.1894Z" fill="white"></path><path d="M39.3895 9.09906V15.8906H40.9852V11.3805C41.3809 10.7475 42.0402 10.3387 42.6732 10.3387C43.1612 10.3387 43.5041 10.5101 43.7019 10.853C43.9524 11.275 43.9656 11.908 43.9656 12.4751V15.8906H45.5613V12.3564C45.5613 11.3673 45.4558 10.4706 44.9547 9.81119C44.5327 9.2705 43.8997 8.94081 43.0821 8.94081C42.2644 8.94081 41.46 9.32325 40.9193 10.1013L40.8402 9.09906H39.3895Z" fill="white"></path><path d="M53.8995 6H52.2906V9.798C51.7631 9.21775 50.9587 8.94081 50.2598 8.94081C48.308 8.94081 46.9761 10.6156 46.9761 12.4751C46.9761 14.4532 48.3608 16.0489 50.2334 16.0489C50.9851 16.0489 51.8686 15.7588 52.3566 15.0203L52.4357 15.8906H53.8995V6ZM52.2906 13.596C51.9082 14.3345 51.1697 14.651 50.5367 14.651C49.3366 14.651 48.5981 13.6224 48.5981 12.5146C48.5981 11.4728 49.2311 10.3387 50.5631 10.3387C51.1829 10.3387 51.8291 10.6024 52.2906 11.1959V13.596Z" fill="white"></path></svg></a></figure></div><!-- /margin --><div id="loop12"><p>While FBA and ECAP payments are an important and welcome step in addressing near-term financial stress, they do not fully close the gap between costs and returns. As farmers enter the 2026/27 marketing year, accumulated losses — estimated to exceed $50 billion across the sector over the past three crop years — continue to weigh on farm finances. </p><p>These estimates reflect national average conditions and are calculated ahead of the growing season, before producers make final planting, input and marketing decisions. In practice, farmers respond to market signals by adjusting crop mix, input use and risk management strategies as conditions evolve. While outcomes vary widely by region and operation, persistently elevated breakeven prices underscore the importance of market-driven solutions that strengthen domestic demand — such as year-round access to E15 — to help support commodity prices and improve farm margins. </p><p>Much-needed safety net enhancements <a href="https://www.fb.org/market-intel/one-big-beautiful-bill-act-final-agricultural-provisions" target="_blank" rel="noreferrer noopener">through the One Big Beautiful Bill Act (OBBBA)</a> are expected to take effect in October 2026, but those changes do not address the pressures farmers face today. In <a href="https://www.fb.org/news-release/agricultural-groups-sound-alarm-about-farmers-future" target="_blank" rel="noreferrer noopener">a recent letter to Congress</a> organized by the American Farm Bureau Federation and signed by 56 agricultural organizations, farm groups warned of an economic crisis in rural America, citing multiyear losses driven by record-high input costs and historically low commodity prices. Congressional leaders from both parties have acknowledged the severity of these losses and the need for additional aid to stabilize farm finances. Until longer-term policy improvements take hold, many operations remain caught between high operating costs and low commodity prices, underscoring the ongoing financial strain facing U.S. agriculture as producers weigh whether they can afford to plant another crop. </p></div><!-- /margin and padding -->




  
  







    

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Internet voting is insecure and should not be used in public elections (421 pts)]]></title>
            <link>https://blog.citp.princeton.edu/2026/01/16/internet-voting-is-insecure-and-should-not-be-used-in-public-elections/</link>
            <guid>46713924</guid>
            <pubDate>Thu, 22 Jan 2026 01:11:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.citp.princeton.edu/2026/01/16/internet-voting-is-insecure-and-should-not-be-used-in-public-elections/">https://blog.citp.princeton.edu/2026/01/16/internet-voting-is-insecure-and-should-not-be-used-in-public-elections/</a>, See on <a href="https://news.ycombinator.com/item?id=46713924">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><em>Signed by a group of 21 computer scientists expert in election security</em></p>



<h2>Executive summary</h2>



<p>Scientists have understood for many years that internet voting is insecure and that there is no known or foreseeable technology that can make it secure.&nbsp;Still, vendors of internet voting keep claiming that, somehow, their new system is different, or the insecurity doesn’t matter.&nbsp;Bradley Tusk and his Mobile Voting Foundation keep touting internet voting to journalists and election administrators; this whole effort is misleading and dangerous.</p>



<p><strong>Part I. </strong>&nbsp;All internet voting systems are insecure. The insecurity is worse than a well-run conventional paper ballot system, because a very small number of people may have the power to change any (or all) votes that go through the system, without detection. This insecurity has been known for years; every internet voting system yet proposed suffers from it, for basic reasons that cannot be fixed with existing technology.</p>



<p><strong>Part II.&nbsp; </strong>Internet voting systems known as “End-to-End Verifiable Internet Voting” are also insecure, in their own special ways.</p>



<p><strong>Part III.</strong>&nbsp; Recently, Tusk announced an E2E-VIV system called “VoteSecure.”&nbsp; It suffers from all the same insecurities.&nbsp; Even its developers admit that in their development documents.&nbsp; Furthermore, VoteSecure isn’t a complete, usable product, it’s just a “cryptographic core” that someone might someday incorporate into a usable product.</p>



<p><strong>Conclusion. </strong>&nbsp;Recent announcements by Bradley Tusks’s Mobile Voting Foundation suggest that the development of VoteSecure somehow makes internet voting safe and appropriate for use in public elections.&nbsp; This is untrue and dangerous.&nbsp; All deployed Internet voting systems are unsafe, VoteSecure is unsafe and isn’t even a deployed voting&nbsp; system, and there is no known (or foreseeable) technology that can make Internet voting safe.</p>



<h2>Part I.&nbsp; All internet voting systems are insecure</h2>



<p>Internet voting systems (including vote-by-smartphone) have three very serious weaknesses:</p>



<ol>
<li>Malware on the voter’s phone (or computer) can transmit different votes than the voter selected and reviewed.&nbsp;Voters use a variety of devices (Android, iPhone, Windows, Mac) which are constantly being attacked by malware.<br></li>



<li>Malware (or insiders) at the server can change votes.&nbsp;Internet servers are constantly being hacked from all over the world, often with serious results.<br></li>



<li>Malware at the county election office can change votes (in those systems where the internet ballots are printed in the county office for scanning).&nbsp;County election computers are not more secure than other government or commercial servers, which are regularly hacked with disastrous results.&nbsp;</li>
</ol>



<p>Although conventional ballots (marked on paper with a pen) are not perfectly secure either, the problem with internet ballots is the ability for a single attacker (from anywhere in the world) to alter a very large number of ballots with a single scaled-up attack.&nbsp; That’s much harder to do with hand-marked paper ballots; occasionally people try large-scale absentee ballot fraud, typically resulting in their being caught, prosecuted, and convicted.</p>



<h2>Part II.&nbsp; E2E-VIV internet voting systems are also insecure</h2>



<p>Years ago, the concept of “End-to-End Verifiable Internet Voting” (E2E-VIV) was proposed, which was supposed to remedy some of these weaknesses by allowing voters to check that their vote was recorded and counted correctly.&nbsp; Unfortunately, all E2E-VIV systems suffer from one or more of the following weaknesses:</p>



<ol>
<li>Voters must rely on a computer app to do the checking, and the checking app (if infected by malware) could lie to them.<br></li>



<li>Voters should not be able to prove to anyone else how they voted – the technical term is “receipt-free” – otherwise an attacker could build an automated system of mass vote-buying via the internet.&nbsp;But receipt-free E2E-VIV systems are complicated and counterintuitive for people to use.<br></li>



<li>It’s difficult to make an E2E-VIV checking app that’s both trustworthy and receipt-free.&nbsp;The best solutions known allow checking only of votes that will be discarded, and casting of votes that haven’t been checked; this is highly counterintuitive for most voters!&nbsp;<br></li>



<li>The checking app must be separate from the voting app, otherwise it doesn’t add any malware-resistance at all.&nbsp; But human nature being what it is, only a tiny fraction of voters will do the extra steps to run the checking protocol.&nbsp; If hardly anyone uses the checker, then the checker is largely ineffective.<br></li>



<li>Even if some voters do run the checking app, if those voters detect that the system is cheating (which is the purpose of the checking app), there’s no way the voters can prove that to election officials.&nbsp; That is, there is no “dispute resolution” protocol that could effectively work.</li>
</ol>



<p>Thus, the problem with all known E2E-VIV systems proposed to date is that the “verification” part doesn’t add any useful security: if a few percent of voters use the checking protocol and see that the system is sometimes cheating, the system can still steal the votes of all the voters that don’t use the checking protocol.&nbsp;And you might think, “well, if some voters catch the system cheating, then election administrators can take appropriate action”, but no appropriate action is possible: the election administrator can’t cancel the election just because a few voters claim (without proof) that the system is cheating!&nbsp; That’s what it means to have no dispute resolution protocol.</p>



<p>All of this is well understood in the scientific consensus.&nbsp;The insecurity of non-E2E-VIV systems has been documented for decades.&nbsp; For a survey of those results, see “<a href="https://scholars.unh.edu/unh_lr/vol21/iss2/9/">Is Internet Voting Trustworthy? The Science and the Policy Battles</a>”.&nbsp;The lack of dispute resolution in E2E-VIV systems has been <a href="http://www2.seas.gwu.edu/~poorvi/Audiotegrity.pdf">known for many years as well</a>.</p>



<h2>Part III. VoteSecure is insecure</h2>



<p>Bradley Tusk’s <a href="https://www.mobilevoting.org/">Mobile Voting Foundation</a> contracted with the R&amp;D company <a href="https://freeandfair.us/about/">Free and Fair</a> to develop internet voting software.&nbsp;Their <a href="https://www.prnewswire.com/news-releases/the-mobile-voting-foundation-and-free--fair-release-votesecure-the-first-software-development-kit-for-secure-transparent-and-verifiable-mobile-voting-302615896.html">press release of November 14, 2025</a> announced the release of an <a href="https://github.com/FreeAndFair/VoteSecure">open-source “Software Development Kit”</a> and claimed “This technology milestone means that secure and verifiable mobile voting is within reach.”&nbsp;&nbsp;</p>



<p>After <a href="https://github.com/FreeAndFair/VoteSecure/issues/2#issue-3629697747">some computer scientists examined</a> the open-source VoteSecure and <a href="https://blog.citp.princeton.edu/2025/12/16/mobile-voting-projects-vote-by-smartphone-has-real-security-gaps/">described serious flaws in its security</a>, Dr. Joe Kiniry and Dr. Daniel Zimmerman of Free and Fair responded.&nbsp;They say, in effect, that all the critiques are accurate, but they don’t know a way to do any better: “<a href="https://github.com/FreeAndFair/VoteSecure/issues/5#issuecomment-3721078472">We share many of [the critique’s] core goals, including voter confidence, election integrity, and resistance to coercion. Where we differ is not so much in values as in assumptions about what is achievable—and meaningful—in unsupervised voting environments.</a>”</p>



<p>In particular,&nbsp;</p>



<ul>
<li>“<a href="https://github.com/FreeAndFair/VoteSecure/issues/2#issuecomment-3609937648">We make no claim of receipt-freeness.</a>”</li>



<li>“<a href="https://github.com/FreeAndFair/VoteSecure/issues/2#issuecomment-3720432505">Of course, it may be possible for the voter to extract the randomizers from the voting client</a>,” meaning that voters would be able to prove how they voted, for example to someone on the internet who wanted to purchase votes at scale.</li>



<li>“<a href="https://github.com/FreeAndFair/VoteSecure/issues/5#issuecomment-3721078472">We agree that dispute resolution is essential to any <em>complete</em> voting system. We also agree that VoteSecure does not fully specify such a protocol</a>.”&nbsp; But really, the problem is much worse than this admission suggests.&nbsp; No one knows of a protocol that could possibly work.&nbsp; So it’s not a matter of dotting some i’s and crossing some t’s in their specification; it’s a gaping hole (an unsolved, research-level problem).</li>



<li>“​​<a href="https://github.com/FreeAndFair/VoteSecure/issues/5#issuecomment-3721078472">Critique: Malware on the voter’s device can compromise both voting and checking, rendering verification meaningless.&nbsp; Response: This critique is correct—and universal. There is no known technical solution that can fully protect an unsupervised endpoint from a sufficiently capable adversary.</a>”</li>



<li>“<a href="https://github.com/FreeAndFair/VoteSecure/issues/5#issuecomment-3721078472">VoteSecure does not claim to: Advance the state of the art in cryptographic voting protocols beyond existing E2E-VIV research; Eliminate coercion or vote selling in unsupervised elections; [or] Fully specify election administration, dispute resolution, or deployment processes.&nbsp; What VoteSecure aims to do is: Clearly define its threat model . . .</a>”</li>
</ul>







<details><summary>In addition to the previously described flaws in the VoteSecure protocol, we note that its vote checking system is susceptible to mass automated vote-buying attacks<sup>1</sup>; and we have discovered a new flaw in the VoteSecure protocol that allows votes to be stolen<sup>2</sup>.  <em>[click for details]</em></summary>
<details><summary>[1] This conclusion is based on a technical analysis.&nbsp; In the VoteSecure protocol, checking app can be run on a vote that is then cast; the checking app must be runnable on an alternate device than the voting app; that alternate device is likely a PC on which the user has control of installed software; user-installed software can extract decrypted randomizers; this allows the voter to participate in a mass vote-buying scheme.  [2] “<a href="https://github.com/FreeAndFair/VoteSecure/issues/6">Clash attacks on the VoteSecure voting and verification process</a>”, by Vanessa Teague and Olivier Pereira, January 13, 2026.</summary>

</details>
</details>



<p>Based on our own expertise test, and especially in light of the response from Free and Fair, we stand by the original analysis: <a href="https://blog.citp.princeton.edu/2025/12/16/mobile-voting-projects-vote-by-smartphone-has-real-security-gaps/">Mobile Voting Project’s vote-by-smartphone has critical security gaps</a>.</p>



<h2>Conclusion</h2>



<p>It has been the scientific consensus for decades that internet voting is not securable by any known technology.&nbsp;Research on future technologies is certainly worth doing.&nbsp;However, the decades of work on E2E-VIV systems has yet to produce any solution, or even any hope of a solution, to the fundamental problems.</p>



<p>Therefore, when it comes to internet voting systems, election officials and journalists should be especially wary of&nbsp;“science by press release.”&nbsp;Perhaps some day an internet voting solution will be proposed that can stand up to scientific investigation.&nbsp;The most reliable venue for assessing that is in peer-reviewed scientific articles.&nbsp;Reputable cybersecurity conferences and journals have published a lot of good science in this area.&nbsp;Press releases are not a reliable way to assess the trustworthiness of election systems.</p>



<h2>Signed</h2>



<p><em>(affiliations for for identification only and do not indicate institutional endorsement)</em></p>



<p><strong>Andrew W. Appel</strong>, <em>Eugene Higgins Professor Emeritus of Computer Science, Princeton University</em></p>



<p><strong>Steven M. Bellovin</strong>, <em>Percy K. and Vida L.W. Hudson Professor Emeritus of Computer Science, Columbia University</em></p>



<p><strong>Duncan Buell</strong>, <em>Chair Emeritus — NCR Chair in Computer Science and Engineering, University of South Carolina</em></p>



<p><strong>Braden L. Crimmins</strong>, <em>PhD Student, Univ. of Michigan School of Engineering &amp; Knight-Hennessy Scholar, Stanford Law</em></p>



<p><strong>Richard DeMillo</strong>, <em>Charlotte B and Roger C&nbsp; Warren Chair in Computing, Georgia Tech&nbsp;</em></p>



<p><strong>David L. Dill</strong>, <em>Donald E. Knuth Professor, Emeritus, in the School of Engineering, Stanford University</em></p>



<p><strong>Jeremy Epstein, </strong><em>National Science Foundation (retired) and&nbsp;Georgia Institute of Technology</em></p>



<p><strong>Juan E. Gilbert</strong>,&nbsp; <em>Andrew Banks Family Preeminence Endowed Professor, Computer &amp; Information Science, University of Florida</em></p>



<p><strong>J. Alex Halderman</strong>, <em>Bredt Family Professor of Computer Science &amp; Engineering, University of Michigan</em></p>



<p><strong>David Jefferson</strong>, <em>Lawrence Livermore National Laboratory (retired)</em></p>



<p><strong>Douglas W. Jones</strong>, <em>Emeritus Associate Professor of Computer Science, University of Iowa</em></p>



<p><strong>Daniel Lopresti</strong>, <em>Professor of Computer Science and Engineering, Lehigh University</em></p>



<p><strong>Ronald L. Rivest</strong>, <em>Institute Professor, MIT</em></p>



<p><strong>Bruce Schneier</strong>, <em>Fellow and Lecturer at the Harvard Kennedy School, and at the Munk School at the University of Toronto</em></p>



<p><strong>Kevin Skoglund</strong>,<em> President and Chief Technologist, Citizens for Better Elections</em></p>



<p><strong>Barbara Simons</strong>, <em>IBM Research (retired)</em></p>



<p><strong>Michael A. Specter</strong>, <em>Assistant Professor, Georgia Tech</em></p>



<p><strong>Philip B. Stark</strong>,&nbsp; <em>Distinguished Professor,&nbsp; Department of Statistics, University of California</em></p>



<p><strong>Gary Tan</strong>, <em>Professor of Computer Science &amp; Engineering, The Pennsylvania State University</em></p>



<p><strong>Vanessa Teague</strong>, <em>Thinking Cybersecurity Pty Ltd and the Australian National Universit</em>y</p>



<p><strong>Poorvi L. Vora</strong>, <em>Professor of Computer Science, George Washington University</em></p>
















</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Threat actors expand abuse of Microsoft Visual Studio Code (233 pts)]]></title>
            <link>https://www.jamf.com/blog/threat-actors-expand-abuse-of-visual-studio-code/</link>
            <guid>46713526</guid>
            <pubDate>Thu, 22 Jan 2026 00:12:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jamf.com/blog/threat-actors-expand-abuse-of-visual-studio-code/">https://www.jamf.com/blog/threat-actors-expand-abuse-of-visual-studio-code/</a>, See on <a href="https://news.ycombinator.com/item?id=46713526">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main" id="main-content">
                    <div>
        
        

        <p>Jamf Threat Labs identifies additional abuse of Visual Studio Code. See the latest evolution in the Contagious Interview campaign.</p>

        

        

        
    </div>
    <div>
        <p><!--ScriptorStartFragment--><strong>By Thijs Xhaflaire</strong></p> <h2>Introduction</h2> <p>At the end of last year, Jamf Threat Labs published research related to the <a href="https://www.jamf.com/blog/flexibleferret-malware-continues-to-adapt/">Contagious Interview campaign</a>, which has been attributed to a threat actor operating on behalf of North Korea (DPRK). Around the same time, researchers from <a href="https://opensourcemalware.com/blog/contagious-interview-vscode">OpenSourceMalware</a> (OSM) released additional findings that highlighted an evolution in the techniques used during earlier stages of the campaign.</p> <p>Specifically, these newer observations highlight an additional delivery technique alongside the previously documented ClickFix-based techniques. In these cases, the infection chain abuses Microsoft Visual Studio Code task configuration files, allowing malicious payloads to be executed on the victim system.</p> <p>Following the discovery of this technique, both Jamf Threat Labs and OSM continued to closely monitor activity associated with the campaign. In December, Jamf Threat Labs identified additional abuse of Visual Studio Code <code>tasks.json</code> configuration files. This included the introduction of dictionary files containing heavily obfuscated JavaScript, which is executed when a victim opens a malicious repository in Visual Studio Code.</p> <p>Jamf Threat Labs shared these findings with OSM, who subsequently <a href="https://opensourcemalware.com/blog/contagious-interview-malicious-dictionary">published</a> a more in-depth technical analysis of the obfuscated JavaScript and its execution flow.</p> <p>Earlier this week, Jamf Threat Labs identified another evolution in the campaign, uncovering a previously undocumented infection method. This activity involved the deployment of a backdoor implant that provides remote code execution capabilities on the victim system.</p> <p>At a high level, the chain of events for the malware look like so:</p> 
    </div>
    
    <div>
        <p><!--ScriptorStartFragment-->Throughout this blog post we will shed light on each of these steps.</p>  <h2>Initial Infection</h2> <p>In this campaign, infection begins when a victim clones and opens a malicious Git repository, often under the pretext of a recruitment process or technical assignment. The repositories identified in this activity are hosted on either GitHub or GitLab and are opened using Visual Studio Code.</p> <p>When the project is opened, Visual Studio Code prompts the user to trust the repository author. If that trust is granted, the application automatically processes the repository’s <code>tasks.json</code> <a href="https://code.visualstudio.com/docs/debugtest/tasks">configuration file</a>, which can result in embedded arbitrary commands being executed on the system.</p>  
    </div>
    
    <div>
        <p><!--ScriptorStartFragment-->On macOS systems, this results in the execution of a background shell command that uses <code>nohup bash -c</code> in combination with <code>curl -s</code> to retrieve a JavaScript payload remotely and pipe it directly into the Node.js runtime. This allows execution to continue independently if the Visual Studio Code process is terminated, while suppressing all command output.</p> 
    </div>
    
    <div>
        <p><!--ScriptorStartFragment-->In observed cases, the JavaScript payload is hosted on <code>vercel.app</code>, a platform that has been increasingly used in recent <a href="https://opensourcemalware.com/blog/contagious-interview-vscode">DPRK-related activity</a> following a move away from other hosting services, as previously documented by OpenSourceMalware.</p> <p>Jamf Threat Labs reported the identified malicious repository to GitHub, after which the repository was removed. While monitoring the activity prior to takedown, we observed the URL referenced within the repository change on multiple occasions. Notably, one of these changes occurred after the previously referenced payload hosting infrastructure was taken down by Vercel.</p> <h2>The JavaScript Payload</h2> <p>Once execution begins, the JavaScript payload implements the core backdoor logic observed in this activity. While the payload appears lengthy, a significant portion of the code consists of unused functions, redundant logic, and extraneous text that is never invoked during execution <code>(SHA256: 932a67816b10a34d05a2621836cdf7fbf0628bbfdf66ae605c5f23455de1e0bc)</code>. This additional code increases the size and complexity of the script without impacting its observed behavior. It is passed to the node executable as one large argument.</p> <p>Focusing on the functional components, the payload establishes a persistent execution loop that collects basic host information and communicates with a remote command-and-control (C2) server. Hard-coded identifiers are used to track individual infections and manage tasks from the server.</p> <h3>Core backdoor functionality</h3> <p>While the JavaScript payload contains a significant amount of unused code, the backdoor's core functionality is implemented through a small number of routines. These routines provide remote code execution, system fingerprinting, and persistent C2 communication.</p> <p><strong>Remote code execution capability</strong></p> <p>The payload includes a function that enables the execution of arbitrary JavaScript while the backdoor is active. At its core, this is the main functionality of this backdoor.</p> 
    </div>

    

    <div>
        <p><!--ScriptorStartFragment-->This function allows JavaScript code supplied as a string to be dynamically executed over the course of the backdoor lifecycle. By passing the <code>require</code>function into the execution context, attacker-supplied code can import additional Node.js modules allowing additional arbitrary node functions to be executed.</p> <p><strong>System fingerprinting and reconnaissance</strong></p> <p>To profile the infected system, the backdoor collects a small set of host-level identifiers:</p> 
    </div>

    

    <div>
        <p><!--ScriptorStartFragment-->This routine gathers the system hostname, MAC addresses from available network interfaces, and basic operating system details. These values provide a stable fingerprint that can be used to uniquely identify infected hosts and associate them with a specific campaign or operator session.</p> <p>In addition to local host identifiers, the backdoor attempts to determine the victim’s public-facing IP address by querying the external service ipify.org, a technique that has also been observed in prior DPRK-linked campaigns.</p> <p><strong>Command-and-control beaconing and task execution</strong></p> <p>Persistent communication with the C2 server is implemented through a polling routine that periodically sends host information and processes server responses. The beaconing logic is handled by the following function:</p> 
    </div>

    

    <div>
        <p><!--ScriptorStartFragment-->This function periodically sends system fingerprinting data to a remote server and waits for a response. The beacon executes every five seconds, providing frequent interaction opportunities.</p> 
    </div>
    
    <p><!--ScriptorStartFragment-->The server response indicates successful connectivity and allows the backdoor to maintain an active session while awaiting tasking.<!--ScriptorEndFragment--></p>

    

    <div>
        <p><!--ScriptorStartFragment-->If the server response contains a specific status value, the contents of the response message are passed directly to the remote code execution routine, mentioned prior.</p> <h2>Further Execution and Instructions</h2> <p>While monitoring a compromised system, Jamf Threat Labs observed further JavaScript instructions being executed roughly eight minutes after the initial infection. The retrieved JavaScript went on to set up a very similar payload to the same C2 infrustructure.</p> 
    </div>

    

    <div>
        <p><!--ScriptorStartFragment-->Review of this retrieved payload yields a few interesting details...</p> <ol> <li>It beacons to the C2 server every 5 seconds, providing its system details and asks for further JavaScript instructions.</li> <li>It executes that additional JavaScript within a child process.</li> <li>It's capable of shutting itself and child processes down and cleaning up if asked to do so by the attacker.</li> <li>It has inline comments and phrasing that appear to be consistent with AI-assisted code generation.</li> </ol> <h2>Conclusion</h2> <p>This activity highlights the continued evolution of DPRK-linked threat actors, who consistently adapt their tooling and delivery mechanisms to integrate with legitimate developer workflows. The abuse of Visual Studio Code task configuration files and Node.js execution demonstrates how these techniques continue to evolve alongside commonly used development tools.</p> <p>Jamf Threat Labs will continue to track these developments as threat actors refine their tactics and explore new ways to deliver macOS malware. We strongly recommend that customers ensure Threat Prevention and Advanced Threat Controls are enabled and set to block mode in Jamf for Mac to remain protected against the techniques described in this research.</p> <p>Developers should remain cautious when interacting with third-party repositories, especially those shared directly or originating from unfamiliar sources. Before marking a repository as trusted in Visual Studio Code, it’s important to review its contents. Similarly, "npm install" should only be run on projects that have been vetted, with particular attention paid to package.json files, install scripts, and task configuration files to help avoid unintentionally executing malicious code.</p>  <h2>Indicators or Compromise</h2>  
    </div>

    
    <div>
        <p>Dive into more Jamf Threat Labs research on our blog.</p>
        
    </div>

                
    
        
            
        

    


            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[From stealth blackout to whitelisting: Inside the Iranian shutdown (145 pts)]]></title>
            <link>https://www.kentik.com/blog/from-stealth-blackout-to-whitelisting-inside-the-iranian-shutdown/</link>
            <guid>46713444</guid>
            <pubDate>Thu, 22 Jan 2026 00:00:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.kentik.com/blog/from-stealth-blackout-to-whitelisting-inside-the-iranian-shutdown/">https://www.kentik.com/blog/from-stealth-blackout-to-whitelisting-inside-the-iranian-shutdown/</a>, See on <a href="https://news.ycombinator.com/item?id=46713444">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Iran is in the midst of one of the world’s most severe communications blackouts. This post uses Kentik data to detail how this historic event unfolded, where this event lies in the context of previous Iranian shutdowns, and finally discusses what might be in store next for Iran.</p><p>For nearly two weeks, Iran has been enduring one of the most severe internet shutdowns in modern history. The theocratic regime’s decision to restrict communications coincided with a violent nationwide crackdown on a growing protest movement driven by worsening economic hardship.</p>
<p>In this post, I explore the situation in Iran using Kentik’s aggregate NetFlow data, along with other sources.</p>

<p>At the time of this writing, a near-complete internet shutdown has persisted for almost 14 days. Along with internet services, international voice calling has also been blocked (there have been a couple of periods when limited outgoing calls were allowed), and domestic communication services have experienced extended disruptions, including Iran’s <a href="https://en.wikipedia.org/wiki/National_Information_Network" rel="noopener" target="_blank">National Information Network</a>. For a country of 90 million people, the combined blocking of these communication modes makes this blackout one of the most severe in history.</p>
<div cursor="zoom-in"><picture><source srcset="https://images.ctfassets.net/6yom6slo28h2/2x3JmoKvC64UuFwbBnnoMr/5874aa06ba5e1eddb65d407e1e6d24d0/iran-shutdown-update-20260119.png?q=80&amp;fm=webp" type="image/webp"><img loading="lazy" width="100%" height="auto" src="https://images.ctfassets.net/6yom6slo28h2/2x3JmoKvC64UuFwbBnnoMr/5874aa06ba5e1eddb65d407e1e6d24d0/iran-shutdown-update-20260119.png?q=80" alt="Internet traffic to Iran - ongoing shutdown"></picture></div>
<p>To learn more about the conditions that lead to the check out this special episode of Kentik’s <a href="https://www.kentik.com/telemetrynow/">Telemetry Now podcast</a> with Iranian digital rights expert <a href="https://twitter.com/Ammir" rel="noopener" target="_blank">Amir Rashidi</a>, Director of Digital Rights and Security at the human rights organization <a href="https://www.miaan.org/" rel="noopener" target="_blank">Miaan Group</a>:</p>


<p>For decades, the internet of Iran has been connected to the world via two international gateways:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Telecommunication_Infrastructure_Company" rel="noopener" target="_blank">Telecommunication Infrastructure Company</a> (TIC) (AS49666, previously AS12880, AS48159)</li>
<li><a href="https://en.wikipedia.org/wiki/Institute_for_Research_in_Fundamental_Sciences" rel="noopener" target="_blank">Institute for Research in Fundamental Sciences</a> (IPM) (AS6736)</li>
</ul>
<p>IPM, primarily a university and research network, was the country’s original internet connection in the 1990s, a story covered in the excellent book <a href="https://www.amazon.com/Internet-Elsewhere-Emergent-Effects-Wired-ebook/dp/B005DPJKT4" rel="noopener" target="_blank">The Internet of Elsewhere</a> by <a href="https://cyrusfarivar.com/blog/" rel="noopener" target="_blank">Cyrus Farivar</a>. Years later, the state telecom TIC got into the business of providing internet service and today handles the vast majority of internet traffic into and out of Iran.</p>
<p>Despite TIC’s dominance, IPM has maintained a technologically independent connection to the outside world, though it has never been immune from Iranian government censorship and surveillance. This distinction matters because each gateway behaved differently during the shutdown.</p>

<p>In the days leading up to January 8, there were many <a href="https://www.bbc.com/persian/articles/c6207l6m791o" rel="noopener" target="_blank">reports of localized internet blockages</a> around the country, but these incidents weren’t big enough to register on any of our national traffic statistics for Iran.</p>
<p>The first major development occurred at 11:42 UTC on January 8, 2026, when TIC (AS49666) began <a href="https://x.com/DougMadory/status/2009283110282592704" rel="noopener" target="_blank">withdrawing its IPv6 BGP routes</a> from its sessions with other networks. Within hours, nearly all of Iran’s IPv6 routing had disappeared from the global routing table.</p>
<div cursor="zoom-in"><picture><source srcset="https://images.ctfassets.net/6yom6slo28h2/1ppK9ZINkpf3PPCH7Fz7jH/cceeb4293bba7b82344abfb4a8b8797b/iran-ipv6-example-withdrawal.png?q=80&amp;fm=webp" type="image/webp"><img loading="lazy" width="100%" height="auto" src="https://images.ctfassets.net/6yom6slo28h2/1ppK9ZINkpf3PPCH7Fz7jH/cceeb4293bba7b82344abfb4a8b8797b/iran-ipv6-example-withdrawal.png?q=80" alt="BGP Route Viewer - Iranian IPv6 route goes from globally routed to withdrawn"></picture></div>
<p>From our perspective, this is what <a href="https://x.com/DougMadory/status/2009262285873729757" rel="noopener" target="_blank">IPv6 traffic to Iran</a> looked like on January 8.</p>
<div cursor="zoom-in"><picture><source srcset="https://images.ctfassets.net/6yom6slo28h2/1yY8T2biI3zzSEdnyX0pt3/55677251e2ea920c3ba0bb0b0b94d7c0/iran-shutdown-ipv6-20260108.png?q=80&amp;fm=webp" type="image/webp"><img loading="lazy" width="100%" height="auto" src="https://images.ctfassets.net/6yom6slo28h2/1yY8T2biI3zzSEdnyX0pt3/55677251e2ea920c3ba0bb0b0b94d7c0/iran-shutdown-ipv6-20260108.png?q=80" alt="Graph showing internet traffic to Iran, IPv6 only"></picture></div>
<p>However, based on our aggregate NetFlow, IPv6 traffic normally amounts to less than 1% of the overall traffic (in bits/sec) into Iran, so the average Iranian was unlikely to be affected by this issue. Regardless, the withdrawal of IPv6 routes appeared to be an early indication of what was to come later in the day.</p>
<p>Following a brief disruption, we observed internet traffic levels begin to plummet at 16:30 UTC (7pm local). The drop continued until internet traffic into Iran had all but ceased by 1845 UTC, as illustrated below. It took over two hours to stop all internet traffic into and out of the country.</p>
<div cursor="zoom-in"><picture><source srcset="https://images.ctfassets.net/6yom6slo28h2/6g5UMjH6I4DwHIBzC4Iyoe/9d9f9b37269288bb929f069b95cd93f3/iran-shutdown-ipv4-20261008.png?q=80&amp;fm=webp" type="image/webp"><img loading="lazy" width="100%" height="auto" src="https://images.ctfassets.net/6yom6slo28h2/6g5UMjH6I4DwHIBzC4Iyoe/9d9f9b37269288bb929f069b95cd93f3/iran-shutdown-ipv4-20261008.png?q=80" alt="Graph showing internet traffic to Iran, IPv4 only"></picture></div>
<p>At 19:00 UTC, we <a href="https://x.com/DougMadory/status/2010069808369545267" rel="noopener" target="_blank">observed TIC disconnecting</a> from a subset of its transit providers, including Russian state telecom Rostelecom (AS12389) and regional operator Gulf Bridge International (AS200612), and all of its settlement-free peers.</p>
<picture><source srcset="https://images.ctfassets.net/6yom6slo28h2/7MwqGfBPmamCnpdVo0RIk2/78f1c510d8dad7de4bb81e7a0930d13b/kmi-insights.png?q=90&amp;w=95&amp;fm=webp 95w, https://images.ctfassets.net/6yom6slo28h2/7MwqGfBPmamCnpdVo0RIk2/78f1c510d8dad7de4bb81e7a0930d13b/kmi-insights.png?q=90&amp;w=190&amp;fm=webp 190w, https://images.ctfassets.net/6yom6slo28h2/7MwqGfBPmamCnpdVo0RIk2/78f1c510d8dad7de4bb81e7a0930d13b/kmi-insights.png?q=90&amp;w=380&amp;fm=webp 380w, https://images.ctfassets.net/6yom6slo28h2/7MwqGfBPmamCnpdVo0RIk2/78f1c510d8dad7de4bb81e7a0930d13b/kmi-insights.png?q=80&amp;w=760&amp;fm=webp 760w" type="image/webp" sizes="(max-width: 380px) 100vw, 380px"><source srcset="https://images.ctfassets.net/6yom6slo28h2/7MwqGfBPmamCnpdVo0RIk2/78f1c510d8dad7de4bb81e7a0930d13b/kmi-insights.png?q=90&amp;w=95 95w, https://images.ctfassets.net/6yom6slo28h2/7MwqGfBPmamCnpdVo0RIk2/78f1c510d8dad7de4bb81e7a0930d13b/kmi-insights.png?q=90&amp;w=190 190w, https://images.ctfassets.net/6yom6slo28h2/7MwqGfBPmamCnpdVo0RIk2/78f1c510d8dad7de4bb81e7a0930d13b/kmi-insights.png?q=90&amp;w=380 380w, https://images.ctfassets.net/6yom6slo28h2/7MwqGfBPmamCnpdVo0RIk2/78f1c510d8dad7de4bb81e7a0930d13b/kmi-insights.png?q=80&amp;w=760 760w" sizes="(max-width: 380px) 100vw, 380px"><img loading="lazy" width="100%" height="auto" alt="Insights from Kentik Market Intelligence" src="https://images.ctfassets.net/6yom6slo28h2/7MwqGfBPmamCnpdVo0RIk2/78f1c510d8dad7de4bb81e7a0930d13b/kmi-insights.png?q=80&amp;w=380"></picture>

<p>Despite the loss of numerous BGP adjacencies for AS49666 (TIC), the vast majority of Iranian IPv4 routes continued to be routed globally. The drop in Iranian IPv4 traffic, therefore, could not be explained by reachability issues; another mechanism was at work at the network edge blocking traffic.</p>
<p>Georgia Tech’s IODA tool <a href="https://ioda.inetintel.cc.gatech.edu/country/IR?from=1767654317&amp;until=1768950317&amp;view=view1" rel="noopener" target="_blank">captures this divergence</a> well. In the below screenshot, active probing (blue) drops to zero as traffic is blocked, while routed IPv4 space in BGP (green) is almost completely unscathed (98.14%).</p>
<div cursor="zoom-in"><picture><source srcset="https://images.ctfassets.net/6yom6slo28h2/5ptzzFv2j3rGR4UXwEd8hT/e88623df12b37a14356e2ca5b32392e6/iran-ioda-20260120.png?q=80&amp;fm=webp" type="image/webp"><img loading="lazy" width="100%" height="auto" src="https://images.ctfassets.net/6yom6slo28h2/5ptzzFv2j3rGR4UXwEd8hT/e88623df12b37a14356e2ca5b32392e6/iran-ioda-20260120.png?q=80" alt="Iran traffic as seen in IODA"></picture></div>
<p>Although IPv4 routes remained online, internet traffic stopped for roughly 90 million Iranians. This distinction is central to Iran’s next step: internet “whitelisting,” in which an Iranian version of the Chinese Great Firewall allows only approved users or services while blocking all others. Had authorities withdrawn IPv4 routes, as they did with IPv6, Iran would have become completely unreachable, as <a href="https://archive.nytimes.com/www.nytimes.com/interactive/2011/02/16/world/middleeast/0212-egypt-internet.html" rel="noopener" target="_blank">Egypt was in January 2011</a>. By keeping IPv4 routes in circulation, Iranian authorities can selectively grant full internet access to specific users while denying it to the broader population.</p>

<p>As mentioned above, the internet shutdown in Iran is not complete. There has been a tiny amount of traffic still trickling in and out as a small set of Iranians continue to enjoy internet access.</p>
<p>There have also been a few temporary partial restorations of service, such as a <a href="https://x.com/DougMadory/status/2009627610360496538" rel="noopener" target="_blank">multi-hour restoration of service to Iranian universities</a> via AS6736 on January 9th, and a more recent <a href="https://x.com/DougMadory/status/2012917572308513206" rel="noopener" target="_blank">small surge in traffic</a>.</p>
<div cursor="zoom-in"><picture><source srcset="https://images.ctfassets.net/6yom6slo28h2/6JF9d3DLLEsC5F8Bnlf3H/948174aaf83c43f64ef16ca0eae43b95/iran-universities.png?q=80&amp;fm=webp" type="image/webp"><img loading="lazy" width="100%" height="auto" src="https://images.ctfassets.net/6yom6slo28h2/6JF9d3DLLEsC5F8Bnlf3H/948174aaf83c43f64ef16ca0eae43b95/iran-universities.png?q=80" alt="Temporary partial restoration for Iranian universities"></picture></div>
<p>From our data, we have also observed the emergence of a diurnal pattern of traffic to AS49666 emerge on January 13. AS49666 is not typically a major terminus for internet traffic to Iran, so this traffic is likely proxied traffic from whitelisted individuals or services.</p>
<div cursor="zoom-in"><picture><source srcset="https://images.ctfassets.net/6yom6slo28h2/4G4FN3FD2grp1cABLvTMxw/0172a54fe06ff6daaecdc42977198f25/iran-shutdown-new-traffic-49666.png?q=80&amp;fm=webp" type="image/webp"><img loading="lazy" width="100%" height="auto" src="https://images.ctfassets.net/6yom6slo28h2/4G4FN3FD2grp1cABLvTMxw/0172a54fe06ff6daaecdc42977198f25/iran-shutdown-new-traffic-49666.png?q=80" alt="Internet raffic to TIC"></picture></div>
<p>As of late, we’ve seen a few measures like the <a href="https://x.com/DougMadory/status/2013307836109824425" rel="noopener" target="_blank">restoration of transit from Rostelecom</a> and the <a href="https://ioda.inetintel.cc.gatech.edu/asn/6736?from=1767651343&amp;until=1768860943&amp;view=view1" rel="noopener" target="_blank">return of routes originated by IPM</a>, as the country appears to be moving towards a partial restoration. At the time of this writing, the plan appears to be to operate the Iranian internet as a whitelisted network indefinitely.</p>

<p>Back in 2012, Iran was in the beginning stages of building its National Information Network (NIN), ostensibly built to allow the country to continue to function in the event that it was cut off from the outside world. At the time, I teamed up with Iran researcher Collin Anderson to investigate. With access to in-country servers, we mapped Iran’s national internet from the inside (research published <a href="https://arxiv.org/abs/1209.6398" rel="noopener" target="_blank">here</a>).</p>
<p>We found that the NIN had been implemented by routing RFC1918 address space (specifically 10.x.x.x) between Iranian ASes within the country. By doing so, they could be assured that devices connected to the NIN would not be able to receive connections from the outside world, as those IP addresses are not routable on the public internet.</p>
<p>In 2019, I <a href="https://web.archive.org/web/20191128123943/https://blogs.oracle.com/internetintelligence/historic-internet-blackout-in-iran" rel="noopener" target="_blank">reported on Iran’s internet shutdown</a> following the government’s decision to raise gas prices. At the time, it was the most severe shutdown in the country’s history—until this month. It involved withdrawing BGP routes of some networks while blocking traffic of others, and lasted <a href="https://en.wikipedia.org/wiki/2019_Internet_blackout_in_Iran" rel="noopener" target="_blank">for almost two weeks</a>.</p>
<div cursor="zoom-in"><picture><source srcset="https://images.ctfassets.net/6yom6slo28h2/486HvWz8mqEvgZFM4b5wC8/cd5514d73c63236dd7ff07034b4d4baa/iran-oracle.png?q=80&amp;fm=webp" type="image/webp"><img loading="lazy" width="100%" height="auto" src="https://images.ctfassets.net/6yom6slo28h2/486HvWz8mqEvgZFM4b5wC8/cd5514d73c63236dd7ff07034b4d4baa/iran-oracle.png?q=80" alt="Iran shutdown in the Oracle Intelligence Map"></picture></div>
<p>Initial impacts of the 2019 Iranian internet shutdown in the Oracle Intelligence Map.</p>
<p>Government-directed shutdowns in <a href="https://twitter.com/DougMadory/status/1576169117039501313" rel="noopener" target="_blank">Cuba</a> and <a href="https://twitter.com/DougMadory/status/1577341946783318035" rel="noopener" target="_blank">Iran</a> in 2022 led me to join up with <a href="https://twitter.com/lawyerpants" rel="noopener" target="_blank">Peter Micek</a> of the digital rights NGO <a href="https://www.accessnow.org/" rel="noopener" target="_blank">Access Now</a> to write a <a href="https://www.kentik.com/blog/suppressing-dissent-the-rise-of-the-internet-curfew/">blog post that traced the history and logic behind “internet curfews,”</a> a tactic of communication suppression in which internet service is temporarily blocked on a recurring basis.</p>
<div cursor="zoom-in"><picture><source srcset="https://images.ctfassets.net/6yom6slo28h2/1YjSvk3w1qkR0D13hlFrm5/13e937d0fbf29c7a20b3c907f34b8e99/iran-sept21.png?q=80&amp;fm=webp" type="image/webp"><img loading="lazy" width="100%" height="auto" src="https://images.ctfassets.net/6yom6slo28h2/1YjSvk3w1qkR0D13hlFrm5/13e937d0fbf29c7a20b3c907f34b8e99/iran-sept21.png?q=80" alt="Iranian internet curfew"></picture></div>
<p>Nightly traffic drops for Iranian mobile providers during Iran’s internet curfew in 2022.</p>
<p>The article described internet curfews as another means of reducing the costs of shutdowns, not unlike the development of the NIN, according to Iranian digital rights expert <a href="https://www.kentik.com/telemetrynow/s02-e65/">Amir Rashidi</a>. In that post, we wrote:</p>
<blockquote>The objective of internet curfews, like Iran’s NIN, is to reduce the cost of shutdowns on the authorities that order them. By reducing the costs of these shutdowns, they become a more palatable option for an embattled leader and, therefore, are likely to continue in the future.</blockquote>
<p>During the <a href="https://en.wikipedia.org/wiki/Iran%E2%80%93Israel_war" rel="noopener" target="_blank">Twelve-Day War</a> between Israel and Iran this June, Iran partially or fully shut down its internet, <a href="https://t.me/khabaronline_ir/591181" rel="noopener" target="_blank">ostensibly to defend against cyberattacks</a> and drone strikes. We, along with other internet observers, <a href="https://x.com/DougMadory/status/1935700667794100272" rel="noopener" target="_blank">documented the shutdown’s phases</a> and contributed to a <a href="https://filter.watch/english/2025/10/02/irans-stealth-blackout-a-multi-stakeholder-analysis-of-the-june-2025-internet-shutdown/" rel="noopener" target="_blank">detailed report</a> by Rashidi’s team, which dubbed the shutdown as a “stealth blackout” due to the fact that traffic was disrupted without withdrawing any BGP routes.</p>
<div cursor="zoom-in"><picture><source srcset="https://images.ctfassets.net/6yom6slo28h2/2QNQOMAfZ5dLNIgW3ilFGq/05af50201d10d948c7268a25af9b3ac6/iran-shutdown-timeline.png?q=80&amp;fm=webp" type="image/webp"><img loading="lazy" width="100%" height="auto" src="https://images.ctfassets.net/6yom6slo28h2/2QNQOMAfZ5dLNIgW3ilFGq/05af50201d10d948c7268a25af9b3ac6/iran-shutdown-timeline.png?q=80" alt=""></picture></div>
<p>Timeline for the stages of the Iranian internet shutdown during the Twelve-Day War.</p>
<p>The outage demonstrated Iran’s newfound ability to block traffic nationwide without manipulating BGP routes, signaling a higher level of sophistication in its internet filtering. This summer’s Stealth Blackout ultimately foreshadowed the ongoing shutdown Iran is now enduring.</p>

<p>In the aftermath of the <a href="https://en.wikipedia.org/wiki/Woman,_Life,_Freedom_movement" rel="noopener" target="_blank">2022 protests</a>, Starlink began allowing connections from Iran. Satellite internet operators like Starlink must typically clear, at a minimum, two legal hurdles to operate in a country: a telecom license and radio spectrum authorization from the local government. Starlink has been operational in Iran for over three years at this point without either, and the Iranian government has taken note.</p>
<p>The <a href="https://www.itu.int/en/ITU-R/conferences/RRB/Pages/default.aspx" rel="noopener" target="_blank">ITU Radio Regulations Board (RRB)</a> is a quasi-judicial United Nations body that interprets and applies the <a href="https://www.itu.int/pub/R-REG-RR" rel="noopener" target="_blank">Radio Regulations</a>, to include satellite emissions. It exists to resolve disputes between countries and oversees compliance with the international radio frequency register, but, in the end, has no direct enforcement power.</p>
<p>Since 2023, the Iranian has been <a href="https://www.bloomberg.com/news/newsletters/2024-03-27/why-policing-elon-musk-s-starlink-satellites-is-a-global-challenge" rel="noopener" target="_blank">pleading their case to the ITU that the Starlink</a> service in Iran needed to be disabled. The <a href="https://www.itu.int/en/ITU-R/conferences/RRB/Pages/Starlink.aspx" rel="noopener" target="_blank">100th meeting of the ITU RRB</a> took place in November, and on the topic of Starlink, the board decided to:</p>
<ul>
<li>“Request the Administration of the Islamic Republic of Iran to pursue its efforts, to the extent possible, to identify and deactivate unauthorized STARLINK terminals in its territory,</li>
<li>Strongly urge the Administration of Norway to take all appropriate actions at its disposal to have the operator of the Starlink system immediately disable unauthorized transmissions of its terminals within the territory of the Islamic Republic of Iran.”</li>
</ul>
<p>Regardless of the decisions of this body, Starlink continues to operate in the country. (Note: The US and Norway share responsibility for Starlink’s ITU registration.)</p>
<p>Despite a recent Iranian <a href="https://www.iranintl.com/en/202510093488" rel="noopener" target="_blank">law that would equate the use of Starlink with espionage</a>, punishable by death, Iranian digital rights activists have been working for years to smuggle in terminals and build communication infrastructure to extend the internet services within the country. The recent <a href="https://www.nytimes.com/2026/01/15/technology/iran-online-starlink.html?unlocked_article_code=1.E1A.IsKl.UErs9_Ikg9uK&amp;smid=nytcore-ios-share" rel="noopener" target="_blank">front-page New York Times article</a> I collaborated on described these efforts, which now must contend with a novel form of <a href="https://www.heise.de/en/background/Starlink-in-Iran-How-the-regime-jams-the-service-and-what-helps-against-it-11147133.html" rel="noopener" target="_blank">jamming Starlink service</a> in some urban areas of Iran.</p>

<p>In the decade and a half since the internet shutdowns of the Arab Spring, we’ve observed the <a href="https://www.kentik.com/blog/from-egypt-to-uganda-a-decade-of-internet-shutdowns/">practice of suppressing communications evolve</a> as authoritarian governments learn tactics from one another. In the ongoing shutdown in Iran, multiple such tactics are on display.</p>
<p>To mitigate the costs of its shutdown, the Iranian government has created an internal national internet and appears to be in the process of building a “whitelisting” system to allow certain individuals and services internet access while blocking the rest. If these measures successfully enable an unpopular Iranian government to remain in power, we can expect to see them replicated elsewhere.</p>
<p>On the other side, the digital rights activists have also been building tools, funded in large part by the <a href="https://www.washingtonpost.com/national-security/2025/08/25/state-department-iran-censorship-internet/" rel="noopener" target="_blank">now-embattled Open Technology Fund</a>, to allow communications to continue during a shutdown like this. However, no amount of circumvention tooling can restore service to 90 million people.</p>
<p>The fight for open and free communications does not have an end. As long as authoritarian governments exist, this game of cat-and-mouse will continue. Ours is only to decide which side we’re on and to throw our support (financially and otherwise) to those working on solutions to these problems.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lix – universal version control system for binary files (114 pts)]]></title>
            <link>https://lix.dev/blog/introducing-lix/</link>
            <guid>46713387</guid>
            <pubDate>Wed, 21 Jan 2026 23:55:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lix.dev/blog/introducing-lix/">https://lix.dev/blog/introducing-lix/</a>, See on <a href="https://news.ycombinator.com/item?id=46713387">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><h2 id="introducing-lix-a-universal-version-control-system"><a href="#introducing-lix-a-universal-version-control-system">Introducing Lix: A universal version control system</a></h2>
<h2 id="ai-agents-need-version-control-beyond-text"><a href="#ai-agents-need-version-control-beyond-text">AI agents need version control beyond text</a></h2>
<p>Changes AI agents make need to be reviewable by humans.</p>
<p>For code, Git solves this:</p>
<ul>
<li><strong>Reviewable diffs</strong>: What exactly did the agent change?</li>
<li><strong>Human-in-the-loop</strong>: Review, then merge or reject.</li>
<li><strong>Rollback changes</strong>: Undo mistakes instantly.</li>
</ul>
<p>But agents modify binary files too. And Git can't diff them.</p>
<p><img src="https://lix.dev/blog/001-introducing-lix/git-limits.png" alt="Git supports text files but not binary formats like PDF, DOCX, XLSX"></p>
<h2 id="introducing-lix"><a href="#introducing-lix">Introducing Lix</a></h2>
<p>Lix is a <strong>universal version control system</strong> that can diff any file format (<code>.xlsx</code>, <code>.pdf</code>, <code>.docx</code>, etc).</p>
<p>Unlike Git's line-based diffs, Lix understands file structure. Lix sees <code>price: 10 → 12</code> or <code>cell B4: pending → shipped</code>, not "line 4 changed" or "binary files differ".</p>
<ul>
<li><strong>Reviewable diffs</strong>: See exactly what an agent changed in any file format.</li>
<li><strong>Human-in-the-loop</strong>: Agents propose, humans approve.</li>
<li><strong>Safe rollback</strong>: Undo mistakes instantly.</li>
</ul>
<p><img src="https://lix.dev/blog/001-introducing-lix/ai-agents-guardrails.png" alt="AI agent changes need to be visible and controllable"></p>
<h2 id="excel-file-example"><a href="#excel-file-example">Excel file example</a></h2>
<p>An AI agent updates an order status in <code>orders.xlsx</code>.</p>
<p><strong>Before:</strong></p>
<pre data-mwc-codeblock=""><code>  | order_id | product  | status   |
  | -------- | -------- | -------- |
  | 1001     | Widget A | shipped  |
  | 1002     | Widget B | pending |
</code></pre>
<p><strong>After:</strong></p>
<pre data-mwc-codeblock=""><code>  | order_id | product  | status   |
  | -------- | -------- | -------- |
  | 1001     | Widget A | shipped  |
  | 1002     | Widget B | shipped |
</code></pre>
<p><strong>Git sees:</strong></p>
<pre data-mwc-codeblock=""><code><span>-Binary files differ</span>
</code></pre>
<p><strong>Lix sees:</strong></p>
<pre data-mwc-codeblock=""><code>order_id 1002 status: 

<span>- pending</span>
<span>+ shipped</span>
</code></pre>
<h2 id="json-file-example"><a href="#json-file-example">JSON file example</a></h2>
<p>Even for structured text file formats like <code>.json</code> lix is tracking semantics rather than line by line diffs.</p>
<p><strong>Before:</strong></p>
<pre data-mwc-codeblock=""><code><span>{</span><span>"theme"</span><span>:</span><span>"light"</span><span>,</span><span>"notifications"</span><span>:</span><span><span>true</span></span><span>,</span><span>"language"</span><span>:</span><span>"en"</span><span>}</span>
</code></pre>
<p><strong>After:</strong></p>
<pre data-mwc-codeblock=""><code><span>{</span><span>"theme"</span><span>:</span><span>"dark"</span><span>,</span><span>"notifications"</span><span>:</span><span><span>true</span></span><span>,</span><span>"language"</span><span>:</span><span>"en"</span><span>}</span>
</code></pre>
<p><strong>Git sees:</strong></p>
<pre data-mwc-codeblock=""><code><span>-{"theme":"light","notifications":true,"language":"en"}</span>
<span>+{"theme":"dark","notifications":true,"language":"en"}</span>
</code></pre>
<p><strong>Lix sees:</strong></p>
<pre data-mwc-codeblock=""><code>property theme: 
<span>- light</span>
<span>+ dark</span>
</code></pre>
<h2 id="how-does-lix-work"><a href="#how-does-lix-work">How does Lix work?</a></h2>
<p>Lix adds a version control system on top of SQL databases that let's you query virtual tables like <code>file</code>, <code>file_history</code>, etc. via plain SQL. These table's are version controlled.</p>
<p><strong>Why this matters:</strong></p>
<ul>
<li><strong>Lix doesn't reinvent databases</strong> — durability, ACID, and corruption recovery are handled by battle-tested SQL databases.</li>
<li><strong>Full SQL support</strong> — query your version control system with the same SQL.</li>
<li><strong>Can runs in your existing database</strong> — no separate storage layer to manage.</li>
</ul>
<pre data-mwc-codeblock=""><code>┌─────────────────────────────────────────────────┐
│                      Lix                        │
│           (version control system)              │
│                                                 │
│ ┌────────────┐ ┌──────────┐ ┌─────────┐ ┌─────┐ │
│ │ Filesystem │ │ Branches │ │ History │ │ ... │ │
│ └────────────┘ └──────────┘ └─────────┘ └─────┘ │
└────────────────────────┬────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────┐
│                  SQL database                   │
└─────────────────────────────────────────────────┘
</code></pre>
<p><a href="https://lix.dev/docs/architecture">Read more about Lix architecture →</a></p>
<h2 id="why-did-we-build-lix"><a href="#why-did-we-build-lix">Why did we build lix?</a></h2>
<p>Lix was developed alongside <a href="https://inlang.com/">inlang</a>, open-source localization infrastructure.</p>
<p>We had to develop a new version control system that addressed git's limitations inlang ran into, see (see <a href="https://samuelstroschein.com/blog/git-limitations">"Git is unsuited for applications"</a>). The result is Lix, now at over <a href="https://www.npmjs.com/package/@lix-js/sdk">90k weekly downloads on NPM</a>.</p>
<p><img src="https://lix.dev/blog/001-introducing-lix/npm-downloads.png" alt="90k weekly npm downloads"></p>
<h2 id="getting-started"><a href="#getting-started">Getting started</a></h2>
<p>
  <img src="https://cdn.simpleicons.org/javascript/F7DF1E" alt="JavaScript" width="18" height="18"> JavaScript ·
  <a href="https://github.com/opral/lix/issues/370"><img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/python/python-original.svg" alt="Python" width="18" height="18"> Python</a> ·
  <a href="https://github.com/opral/lix/issues/371"><img src="https://cdn.simpleicons.org/rust/CE422B" alt="Rust" width="18" height="18"> Rust</a> ·
  <a href="https://github.com/opral/lix/issues/373"><img src="https://cdn.simpleicons.org/go/00ADD8" alt="Go" width="18" height="18"> Go</a>
</p>
<pre data-mwc-codeblock=""><code>npm install @lix-js/sdk
</code></pre>
<pre data-mwc-codeblock=""><code><span>import</span> { openLix } <span>from</span> <span>"@lix-js/sdk"</span>;

<span>const</span> lix = <span>await</span> <span>openLix</span>({
  <span>environment</span>: <span>new</span> <span>InMemorySQLite</span>()
});

<span>await</span> lix.<span>db</span>.<span>insertInto</span>(<span>"file"</span>).<span>values</span>({ <span>path</span>: <span>"/hello.txt"</span>, <span>data</span>: ... }).<span>execute</span>();

<span>const</span> diff = <span>selectWorkingDiff</span>({ lix })
</code></pre>
<h2 id="whats-next"><a href="#whats-next">What's next</a></h2>
<p>The next version of Lix will be a refactor to be purely "preprocessor" based. This enables:</p>
<ul>
<li><strong>Fast writes</strong> (<a href="https://lix.dev/rfc/001-preprocess-writes">RFC 001</a>)</li>
<li><strong>Any SQL database</strong> (SQLite, Postgres, Turso, MySQL)</li>
<li><strong>SDKs for Python, Rust, Go</strong> (<a href="https://lix.dev/rfc/002-rewrite-in-rust">RFC 002</a>)</li>
</ul>
<pre data-mwc-codeblock=""><code>                      ┌────────────────┐
  SELECT * FROM ...   │  Lix Engine    │   SELECT * FROM ...
 ───────────────────▶ │    (Rust)      │ ───────────────────▶  Database
                      └────────────────┘
</code></pre>

<ul>
<li>⭐ <a href="https://github.com/opral/lix">Star the lix repo on GitHub</a></li>
<li>💬 <a href="https://discord.gg/gdMPPWy57R">Chat on Discord</a></li>
</ul></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Sweep, Open-weights 1.5B model for next-edit autocomplete (453 pts)]]></title>
            <link>https://huggingface.co/sweepai/sweep-next-edit-1.5B</link>
            <guid>46713106</guid>
            <pubDate>Wed, 21 Jan 2026 23:22:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://huggingface.co/sweepai/sweep-next-edit-1.5B">https://huggingface.co/sweepai/sweep-next-edit-1.5B</a>, See on <a href="https://news.ycombinator.com/item?id=46713106">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	<!-- HTML_TAG_START -->
<p>A 1.5B parameter model for next-edit autocomplete, quantized to Q8_0 GGUF format.</p>
<h2>
	<a rel="nofollow" href="#model-description" id="model-description">
		
	</a>
	<span>
		Model Description
	</span>
</h2>
<p>Sweep Next-Edit predicts your next code edit before you make it. It runs locally on your laptop in under 500ms (with speculative decoding) and outperforms models over 4x its size on next-edit benchmarks.</p>
<h2>
	<a rel="nofollow" href="#usage" id="usage">
		
	</a>
	<span>
		Usage
	</span>
</h2>
<p>Download <code>run_model.py</code> and the model file, then:</p>
<pre><code>uv pip install llama-cpp-python huggingface_hub
python run_model.py
</code></pre>
<h2>
	<a rel="nofollow" href="#model-details" id="model-details">
		
	</a>
	<span>
		Model Details
	</span>
</h2>
<ul>
<li><strong>Format</strong>: GGUF (Q8_0 quantization)</li>
<li><strong>Parameters</strong>: 1.5B</li>
<li><strong>Context Length</strong>: 8192 tokens</li>
<li><strong>Base Model</strong>: Qwen2.5-Coder</li>
</ul>
<h2>
	<a rel="nofollow" href="#example" id="example">
		
	</a>
	<span>
		Example
	</span>
</h2>
<p>The model uses a specific prompt format with file context, recent diffs, and current state to predict the next edit. See <code>run_model.py</code> for a complete example.</p>
<h2>
	<a rel="nofollow" href="#links">
		
	</a>
	<span>
		Links
	</span>
</h2>
<ul>
<li><a rel="nofollow" href="https://blog.sweep.dev/posts/oss-next-edit">Blog Post</a> - Technical details and benchmarks</li>
<li><a rel="nofollow" href="https://plugins.jetbrains.com/plugin/26860-sweep-ai-autocomplete--coding-agent">JetBrains Plugin</a> - Sweep AI JetBrains Plugin</li>
</ul>
<h2>
	<a rel="nofollow" href="#license" id="license">
		
	</a>
	<span>
		License
	</span>
</h2>
<p>Apache 2.0</p>
<!-- HTML_TAG_END --></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Take potentially dangerous PDFs, and convert them to safe PDFs (170 pts)]]></title>
            <link>https://github.com/freedomofpress/dangerzone</link>
            <guid>46712815</guid>
            <pubDate>Wed, 21 Jan 2026 22:54:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/freedomofpress/dangerzone">https://github.com/freedomofpress/dangerzone</a>, See on <a href="https://news.ycombinator.com/item?id=46712815">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Dangerzone</h2><a id="user-content-dangerzone" aria-label="Permalink: Dangerzone" href="#dangerzone"></a></p>
<p dir="auto">Take potentially dangerous PDFs, office documents, or images and convert them to a safe PDF.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th><a target="_blank" rel="noopener noreferrer" href="https://github.com/freedomofpress/dangerzone/blob/main/assets/screenshot1.png"><img src="https://github.com/freedomofpress/dangerzone/raw/main/assets/screenshot1.png" alt="Settings"></a></th>
<th><a target="_blank" rel="noopener noreferrer" href="https://github.com/freedomofpress/dangerzone/blob/main/assets/screenshot2.png"><img src="https://github.com/freedomofpress/dangerzone/raw/main/assets/screenshot2.png" alt="Converting"></a></th>
</tr>
</thead>
</table></markdown-accessiblity-table>
<p dir="auto">Dangerzone works like this: You give it a document that you don't know if you can trust (for example, an email attachment). Inside of a sandbox, Dangerzone converts the document to a PDF (if it isn't already one), and then converts the PDF into raw pixel data: a huge list of RGB color values for each page. Then, outside of the sandbox, Dangerzone takes this pixel data and converts it back into a PDF.</p>
<p dir="auto"><em>Read more about Dangerzone in the <a href="https://dangerzone.rocks/about/" rel="nofollow">official site</a>.</em></p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">🎅 Check out our <a href="https://dangerzone.rocks/news/2025-12-10-santa-pwn/" rel="nofollow">Christmas security challenge</a>, in which we ask security researchers to craft a <em>naughty</em> letter that can pwn Dangerzone in Santa's laptop, and earn a bounty of up to $3,000.
Promise it makes sense. 🎄</p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting started" href="#getting-started"></a></p>
<p dir="auto">Follow the instructions for each platform:</p>
<ul dir="auto">
<li><a href="https://github.com/freedomofpress/dangerzone/blob/v0.10.0/INSTALL.md#macos">macOS</a></li>
<li><a href="https://github.com/freedomofpress/dangerzone/blob/v0.10.0/INSTALL.md#windows">Windows</a></li>
<li><a href="https://github.com/freedomofpress/dangerzone/blob/v0.10.0/INSTALL.md#ubuntu-debian">Ubuntu Linux</a></li>
<li><a href="https://github.com/freedomofpress/dangerzone/blob/v0.10.0/INSTALL.md#ubuntu-debian">Debian Linux</a></li>
<li><a href="https://github.com/freedomofpress/dangerzone/blob/v0.10.0/INSTALL.md#fedora">Fedora Linux</a></li>
<li><a href="https://github.com/freedomofpress/dangerzone/blob/v0.10.0/INSTALL.md#qubes-os">Qubes OS (beta)</a></li>
<li><a href="https://github.com/freedomofpress/dangerzone/blob/v0.10.0/INSTALL.md#tails">Tails</a></li>
</ul>
<p dir="auto">You can read more about our operating system support <a href="https://github.com/freedomofpress/dangerzone/blob/v0.10.0/INSTALL.md#operating-system-support">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Some features</h2><a id="user-content-some-features" aria-label="Permalink: Some features" href="#some-features"></a></p>
<ul dir="auto">
<li>Sandboxes don't have network access, so if a malicious document can compromise one, it can't phone home</li>
<li>Sandboxes use <a href="https://gvisor.dev/" rel="nofollow">gVisor</a>, an application kernel written in Go, that implements a substantial portion of the Linux system call interface.</li>
<li>Dangerzone can optionally OCR the safe PDFs it creates, so it will have a text layer again</li>
<li>Dangerzone compresses the safe PDF to reduce file size</li>
<li>After converting, Dangerzone lets you open the safe PDF in the PDF viewer of your choice, which allows you to open PDFs and office docs in Dangerzone by default so you never accidentally open a dangerous document</li>
</ul>
<p dir="auto">Dangerzone can convert these types of document into safe PDFs:</p>
<ul dir="auto">
<li>PDF (<code>.pdf</code>)</li>
<li>Microsoft Word (<code>.docx</code>, <code>.doc</code>)</li>
<li>Microsoft Excel (<code>.xlsx</code>, <code>.xls</code>)</li>
<li>Microsoft PowerPoint (<code>.pptx</code>, <code>.ppt</code>)</li>
<li>ODF Text (<code>.odt</code>)</li>
<li>ODF Spreadsheet (<code>.ods</code>)</li>
<li>ODF Presentation (<code>.odp</code>)</li>
<li>ODF Graphics (<code>.odg</code>)</li>
<li>Hancom HWP (Hangul Word Processor) (<code>.hwp</code>, <code>.hwpx</code>)
<ul dir="auto">
<li>Not supported on
<a href="https://github.com/freedomofpress/dangerzone/issues/494" data-hovercard-type="issue" data-hovercard-url="/freedomofpress/dangerzone/issues/494/hovercard">Qubes OS</a></li>
</ul>
</li>
<li>EPUB (<code>.epub</code>)</li>
<li>Jpeg (<code>.jpg</code>, <code>.jpeg</code>)</li>
<li>GIF (<code>.gif</code>)</li>
<li>PNG (<code>.png</code>)</li>
<li>SVG (<code>.svg</code>)</li>
<li>other image formats (<code>.bmp</code>, <code>.pnm</code>, <code>.pbm</code>, <code>.ppm</code>)</li>
</ul>
<p dir="auto">Dangerzone was inspired by <a href="https://blog.invisiblethings.org/2013/02/21/converting-untrusted-pdfs-into-trusted.html" rel="nofollow">Qubes trusted PDF</a>, but it works in non-Qubes operating systems. It uses containers as sandboxes instead of virtual machines (using Docker for macOS and Windows, and <a href="https://podman.io/" rel="nofollow">podman</a> on Linux).</p>
<p dir="auto">Set up a development environment by following <a href="https://github.com/freedomofpress/dangerzone/blob/main/BUILD.md">these instructions</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License and Copyright</h2><a id="user-content-license-and-copyright" aria-label="Permalink: License and Copyright" href="#license-and-copyright"></a></p>
<p dir="auto">Licensed under the AGPLv3: <a href="https://opensource.org/licenses/agpl-3.0" rel="nofollow">https://opensource.org/licenses/agpl-3.0</a></p>
<div data-snippet-clipboard-copy-content="Copyright (c) 2022-2024 Freedom of the Press Foundation and Dangerzone contributors
Copyright (c) 2020-2021 First Look Media"><pre><code>Copyright (c) 2022-2024 Freedom of the Press Foundation and Dangerzone contributors
Copyright (c) 2020-2021 First Look Media
</code></pre></div>
<p dir="auto">See also <a href="https://github.com/freedomofpress/dangerzone/blob/main/THIRD_PARTY_NOTICE.md">THIRD_PARTY_NOTICE.md</a> for more information regarding the third-party software that Dangerzone depends on.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">See also</h2><a id="user-content-see-also" aria-label="Permalink: See also" href="#see-also"></a></p>
<ul dir="auto">
<li><a href="https://gijn.org/stories/cutting-edge-free-online-investigative-tools/" rel="nofollow">GIJN Toolbox: Cutting-Edge — and Free — Online Investigative Tools You Can Try Right Now</a></li>
<li><a href="https://www.theguardian.com/info/2024/apr/04/when-security-matters-working-with-qubes-os-at-the-guardian" rel="nofollow">When security matters: working with Qubes OS at the Guardian</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQ</h2><a id="user-content-faq" aria-label="Permalink: FAQ" href="#faq"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Has Dangerzone received a security audit?</h3><a id="user-content-has-dangerzone-received-a-security-audit" aria-label="Permalink: Has Dangerzone received a security audit?" href="#has-dangerzone-received-a-security-audit"></a></p>
<p dir="auto">Yes, Dangerzone received its <a href="https://freedom.press/news/dangerzone-receives-favorable-audit/" rel="nofollow">first security audit</a> by <a href="https://includesecurity.com/" rel="nofollow">Include Security</a> in December 2023. The audit was generally favorable, as it didn't identify any high-risk findings, except for 3 low-risk and 7 informational findings.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">"I'm experiencing an issue while using Dangerzone."</h3><a id="user-content-im-experiencing-an-issue-while-using-dangerzone" aria-label="Permalink: &quot;I'm experiencing an issue while using Dangerzone.&quot;" href="#im-experiencing-an-issue-while-using-dangerzone"></a></p>
<p dir="auto">Dangerzone gets updates to improve its features <em>and</em> to fix problems. So, updating may be the simplest path to resolving the issue which brought you here. Here is how to update:</p>
<ol dir="auto">
<li>Check which version of Dangerzone you are currently using: run Dangerzone, then look for a series of numbers to the right of the logo within the app. The format of the numbers will look similar to <code>0.4.1</code></li>
<li>Now find the latest available version of Dangerzone: go to the <a href="https://dangerzone.rocks/#downloads" rel="nofollow">download page</a>. Look for the version number displayed. The number will be using the same format as in Step 1.</li>
<li>Is the version on the Dangerzone download page higher than the version of your installed app? Go ahead and update.</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Can I run Dangerzone in an airgapped environment?</h3><a id="user-content-can-i-run-dangerzone-in-an-airgapped-environment" aria-label="Permalink: Can I run Dangerzone in an airgapped environment?" href="#can-i-run-dangerzone-in-an-airgapped-environment"></a></p>
<p dir="auto">Yes, Dangerzone is designed to run in airgapped environments without any
configuration. If you want to update its container image, follow
<a href="https://github.com/freedomofpress/dangerzone/blob/main/docs/developer/independent-container-updates.md#Installing-image-updates-to-airgapped-environments">our instructions</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Can I use a custom runtime, such as Podman Desktop?</h3><a id="user-content-can-i-use-a-custom-runtime-such-as-podman-desktop" aria-label="Permalink: Can I use a custom runtime, such as Podman Desktop?" href="#can-i-use-a-custom-runtime-such-as-podman-desktop"></a></p>
<p dir="auto">On Windows and macOS, Dangerzone embeds Podman, so there is no need to.</p>
<p dir="auto">To use a different podman version, such as Podman Desktop, <a href="https://github.com/freedomofpress/dangerzone/blob/main/docs/podman-desktop.md">follow our documentation</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Your brain on ChatGPT: Accumulation of cognitive debt when using an AI assistant (443 pts)]]></title>
            <link>https://www.media.mit.edu/publications/your-brain-on-chatgpt/</link>
            <guid>46712678</guid>
            <pubDate>Wed, 21 Jan 2026 22:41:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.media.mit.edu/publications/your-brain-on-chatgpt/">https://www.media.mit.edu/publications/your-brain-on-chatgpt/</a>, See on <a href="https://news.ycombinator.com/item?id=46712678">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p>
                        <cite>Nataliya Kosmyna, Eugene Hauptmann, Ye Tong Yuan, Jessica Situ, Xian-Hao Liao, Ashly Vivian Beresnitzky, Iris Braunstein, and Pattie Maes. "Your brain on chatgpt: Accumulation of cognitive debt when using an ai assistant for essay writing task." arXiv preprint arXiv:2506.08872 (2025).</cite>
                    </p>
            </div><div>
                    <h2>Abstract</h2>
                    <p>This study explores the neural and behavioral consequences of LLM-assisted essay writing. Participants were divided into three groups: LLM, Search Engine, and Brain-only (no tools). Each completed three sessions under the same condition. In a fourth session, LLM users were reassigned to Brain-only group (LLM-to-Brain), and Brain-only users were reassigned to LLM condition (Brain-to-LLM). A total of 54 participants took part in Sessions 1-3, with 18 completing session 4. We used electroencephalography (EEG) to assess cognitive load during essay writing, and analyzed essays using NLP, as well as scoring essays with the help from human teachers and an AI judge. Across groups, NERs, n-gram patterns, and topic ontology showed within-group homogeneity. EEG revealed significant differences in brain connectivity: Brain-only participants exhibited the strongest, most distributed networks; Search Engine users showed moderate engagement; and LLM users displayed the weakest connectivity. Cognitive activity scaled down in relation to external tool use. In session 4, LLM-to-Brain participants showed reduced alpha and beta connectivity, indicating under-engagement. Brain-to-LLM users exhibited higher memory recall and activation of occipito-parietal and prefrontal areas, similar to Search Engine users. Self-reported ownership of essays was the lowest in the LLM group and the highest in the Brain-only group. LLM users also struggled to accurately quote their own work. While LLMs offer immediate convenience, our findings highlight potential cognitive costs. Over four months, LLM users consistently underperformed at neural, linguistic, and behavioral levels. These results raise concerns about the long-term educational implications of LLM reliance and underscore the need for deeper inquiry into AI's role in learning.</p>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: TerabyteDeals – Compare storage prices by $/TB (139 pts)]]></title>
            <link>https://terabytedeals.com</link>
            <guid>46711649</guid>
            <pubDate>Wed, 21 Jan 2026 21:13:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://terabytedeals.com">https://terabytedeals.com</a>, See on <a href="https://news.ycombinator.com/item?id=46711649">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[eBay explicitly bans AI "buy for me" agents in user agreement update (241 pts)]]></title>
            <link>https://www.valueaddedresource.net/ebay-bans-ai-agents-updates-arbitration-user-agreement-feb-2026/</link>
            <guid>46711574</guid>
            <pubDate>Wed, 21 Jan 2026 21:07:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.valueaddedresource.net/ebay-bans-ai-agents-updates-arbitration-user-agreement-feb-2026/">https://www.valueaddedresource.net/ebay-bans-ai-agents-updates-arbitration-user-agreement-feb-2026/</a>, See on <a href="https://news.ycombinator.com/item?id=46711574">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          



<article>
  


  <section>
    <p>eBay explicitly prohibits AI "buy for me" agents and LLM (larger language model) bots, updates arbitration and dispute resolution requirements in latest User Agreement update, going into effect February 20, 2026.</p><p>The following summary of changes was provided in an email sent to users:</p><blockquote>
<div><p>We’ve updated eBay’s User Agreement, including the agreement to arbitrate any disputes you may have with us. Our updated User Agreement was posted on January 20, 2026. For users who agreed to a prior version of our User Agreement, this agreement is effective as of February 20, 2026.</p></div>
<p>In this update, eBay is updating its anti-scraping prohibition to clarify that it specifically also includes bots used for AI or LLMs. eBay is also updating the agreement to arbitrate in the updated User Agreement:</p>
<ul>
<li>We clarified the scope of the class action waiver.</li>
<li>We clarified the process for opting out of the agreement to arbitrate.</li>
<li>We updated the physical address to which notices for informal dispute resolution, arbitration demands, and notices for opting out of arbitration must be sent.</li>
</ul>
</blockquote>
<p>As always, sellers are encouraged to&nbsp;<a href="https://www.ebay.com/help/policies/member-behaviour-policies/user-agreement?id=4259" rel="noreferrer">read&nbsp;the entire updated terms carefully</a>, but Value Added Resource has you covered with a side by side comparison highlighting some key changes.</p><p><em>Disclaimer: comparisons are made using both automated and manual methods and are provided for informational purposes only - no warranty of completeness or accuracy is expressed or implied and users are advised to do their own due diligence.</em></p><h3 id="ai-agents-llm-scraping">AI Agents &amp; LLM Scraping</h3><p>First, as the summary calls out, eBay is explicitly prohibiting AI "buy for me" agents and LLM scraping bots from interacting with the platform without permission from eBay.</p><p>Old Version:</p><blockquote>
<div><p>In connection with using or accessing our Services you agree to comply with this User Agreement, our policies, our terms, and all applicable laws, rules, and regulations, and you will not...</p></div>
<p>...use any robot, spider, scraper, data mining tools, data gathering and extraction tools, or other automated means to access our Services for any purpose, except with the prior express permission of eBay;</p>
</blockquote>
<p>New Version:</p><blockquote>
<div><p>In connection with using or accessing our Services you agree to comply with this User Agreement, our policies, our terms, and all applicable laws, rules, and regulations, and you will not...</p></div>
<p>use any robot, spider, scraper, data mining tools, data gathering and extraction tools, or other automated means <strong>(including, without limitation buy-for-me agents, LLM-driven bots, or any end-to-end flow that attempts to place orders without human review)</strong> to access our Services for any purpose, except with the prior express permission of eBay;</p>
</blockquote>
<p>The move comes after eBay quietly changed their robots.txt file with new guidance placing guardrails and restrictions on how AI agents interact with the site in December.</p><figure><a href="https://www.valueaddedresource.net/ebay-ai-holidays-agent-policy-updates/"><div><p>eBay Encourages Buyers &amp; Sellers To Use AI For The Holidays While Quietly Updating AI Agent Policy</p><p>eBay encourages buyers &amp; sellers to “unwrap innovation” with AI this holiday season, quietly adds guardrails on how AI agents interact with site.</p><p><img src="https://www.valueaddedresource.net/content/images/icon/Value-Added-Resource-copy--3--2694.png" alt=""><span>Liz Morton</span></p></div><p><img src="https://www.valueaddedresource.net/content/images/thumbnail/ebayaiholidays-2.jpg" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>It also comes on the heels of Amazon's controversial Buy For Me test which uses agentic AI to display items from direct merchant websites for sale through the Amazon app, even if the brand does not sell on Amazon themselves - raising concerns about transparency, consent, and control over how product details are displayed to buyers.</p><figure><a href="https://www.valueaddedresource.net/amazon-buy-for-me-small-business-backlash/"><div><p>Amazon’s “Buy For Me” Agentic AI Sparks Backlash As Small Businesses Say Listings Are Being Hijacked</p><p>Small businesses say Amazon’s “Buy For Me” agentic AI uses their product data without consent, causing pricing, fulfillment &amp; buyer trust concerns.</p><p><img src="https://www.valueaddedresource.net/content/images/icon/Value-Added-Resource-copy--3--2695.png" alt=""><span>Value Added Resource</span><span>Liz Morton</span></p></div><p><img src="https://www.valueaddedresource.net/content/images/thumbnail/amazonbuyforme-2.jpg" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>While it appears that Amazon Buy For Me currently does <strong><em>not </em></strong>pull inventory from other third party marketplaces, it would not be surprising if eBay is reacting at least in part to this and other agentic commerce news making recent headlines.</p><h3 id="arbitration-dispute-resolution">Arbitration &amp; Dispute Resolution</h3><p>The rest of the changes in this User Agreement update affect arbitration and dispute resolution.</p><p>eBay's previous User Agreement update in May 2025 made significant changes to arbitration terms and limits on lawsuits, forcing users to give up their right to the sue the company in many situations.</p><figure><a href="https://www.valueaddedresource.net/ebay-user-agreement-may-2025-arbitration/"><div><p>eBay User Agreement Update May 2025: New Arbitration Terms &amp; Limits On Lawsuits</p><p>eBay has released an update to their user agreement with significant changes to arbitration terms &amp; limits on lawsuits, effective May 16th 2025.</p><p><img src="https://www.valueaddedresource.net/content/images/icon/Value-Added-Resource-copy--3--2696.png" alt=""><span>Value Added Resource</span><span>Liz Morton</span></p></div><p><img src="https://www.valueaddedresource.net/content/images/thumbnail/ebayua41725-3.jpg" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>In this update, eBay has finally updated the address to send arbitration opt out requests and other legal correspondence to since <a href="https://www.valueaddedresource.net/ebay-draper-ut-campus-up-for-sale/" rel="noreferrer">selling their former office in Draper, UT in 2024</a>.</p><p>Old Version:</p><blockquote>
<p>Notice to eBay should be sent by email to <a href="mailto:DisputeNotice@eBay.com">DisputeNotice@eBay.com</a> or regular mail to our offices located at 583 W. eBay Way, Draper, UT 84020.</p>
</blockquote>
<p>New Version:</p><blockquote>
<p>Notice to eBay should be sent by email to <a href="mailto:DisputeNotice@eBay.com">DisputeNotice@eBay.com</a> or regular mail to our offices located at 339 W. 13490 S., Ste. 500, Draper, UT 84020</p>
</blockquote>
<p>Most importantly, eBay has expanded their arbitration clause which previously prohibited class actions to now also explicitly exclude more types of group legal actions.</p><p>Old Version:</p><blockquote>
<div><p>EACH OF US MAY BRING CLAIMS AGAINST THE OTHER ONLY ON AN INDIVIDUAL BASIS AND NOT ON A CLASS, REPRESENTATIVE, OR COLLECTIVE BASIS, AND THE PARTIES HEREBY WAIVE ALL RIGHTS TO HAVE ANY DISPUTE BE BROUGHT, HEARD, ADMINISTERED, RESOLVED, OR ARBITRATED ON A CLASS, COLLECTIVE, OR REPRESENTATIVE BASIS. ONLY INDIVIDUAL RELIEF IS AVAILABLE.</p></div>
<p>Subject to this Agreement to Arbitrate, the arbitrator may award declaratory or injunctive relief only in favor of the individual party seeking relief and only to the extent necessary to provide relief warranted by the party’s individual claim. Nothing in this paragraph is intended to, nor shall it, affect the terms and conditions under Section 19.B.7 ("Batch Arbitration").</p>
</blockquote>
<p>New Version:</p><blockquote>
<div><p>EACH OF US MAY BRING CLAIMS AGAINST THE OTHER ONLY ON AN INDIVIDUAL BASIS AND NOT AS A PLAINTIFF OR CLASS MEMBER IN ANY PURPORTED CLASS, OR REPRESENTATIVE, OR COLLECTIVE BASIS, OR PRIVATE ATTORNEY GENERAL ACTION OR PROCEEDING, NOR OTHERWISE TO SEEK RECOVERY OF LOSSES OR DAMAGES (WHETHER FOR YOURSELF OR OTHERS) INCURRED BY A THIRD PARTY, AND THE PARTIES HEREBY WAIVE ALL RIGHTS TO HAVE ANY DISPUTE BE BROUGHT, HEARD, ADMINISTERED, RESOLVED, OR ARBITRATED ON A CLASS, COLLECTIVE, OR REPRESENTATIVE BASIS. ONLY INDIVIDUAL RELIEF IS AVAILABLE.</p></div>
<p>Subject to this Agreement to Arbitrate, the arbitrator may award declaratory or injunctive relief only in favor of the individual party seeking relief and only to the extent necessary to provide relief warranted by the party’s individual claim. Nothing in this paragraph is intended to, nor shall it, affect the terms and conditions under Section 19.B.7 ("Batch Arbitration").</p>
</blockquote>
<p>Here's what that means in plain language:</p><ul><li><strong>“Not as a plaintiff or class member”</strong>&nbsp;— prevents someone from joining an existing class action.</li><li><strong>“No private attorney general actions”</strong>&nbsp;— blocks lawsuits brought “on behalf of the public,” a type of claim sometimes used in consumer protection cases.</li><li><strong>“Nor… for losses incurred by a third party”</strong>&nbsp;— prevents a person from trying to recover damages suffered by someone else.</li></ul><p>Note: this language does <strong><em>not </em></strong>in any way change or restrict legal action that state Attorneys General, the FTC or other regulatory or legal agencies can take on behalf of sellers and/or consumers - so don't be dissuaded from letting those agencies know about your experiences with the platform, like the recent changes to Promoted Listings ad attribution policies.</p><figure><a href="https://www.valueaddedresource.net/report-ebay-ad-policies-ftc-attorney-general/"><div><p>A Seller’s Guide To Speaking Up: How To Report eBay’s New Ad Policies To The FTC &amp; State AGs</p><p>Concerned about eBay’s controversial new Promoted Listings ad rules? Here’s how to file effective, proactive reports with FTC &amp; AGs to make your voice heard!</p><p><img src="https://www.valueaddedresource.net/content/images/icon/Value-Added-Resource-copy--3--2697.png" alt=""><span>Value Added Resource</span><span>Liz Morton</span></p></div><p><img src="https://www.valueaddedresource.net/content/images/thumbnail/ebayftc112125-7.jpg" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>And finally, this User Agreement update has been changed to clarify that only new users may request to opt out of arbitration agreement - existing users missed their opportunity if they did not opt out before May 16, 2025.</p><blockquote>

<p>IF YOU ARE A NEW USER OF OUR SERVICES, YOU CAN CHOOSE TO OPT OUT OF THIS AGREEMENT TO ARBITRATE ("OPT OUT") BY MAILING US A WRITTEN OPT-OUT NOTICE ("OPT-OUT NOTICE").</p>
</blockquote>
<p>And that's it for changes to eBay's User Agreement going into effect February 20, 2026.</p><p><em>Let us know in the comments below what you think of these change and how they'll affect your business!</em></p>
  </section>

      <section>
        <a href="https://www.valueaddedresource.net/tag/ebay-news/">eBay</a><a href="https://www.valueaddedresource.net/tag/ai/">AI</a><a href="https://www.valueaddedresource.net/tag/seller-updates/">Seller Updates</a>
      </section>
	
      <section>
    <p><a href="https://www.valueaddedresource.net/author/liz-morton/">
        <img data-src="/content/images/size/w320/2023/03/headshot1.jpeg" alt="Liz Morton" width="80" height="80" src="https://www.valueaddedresource.net/content/images/size/w320/2023/03/headshot1.jpeg">
      </a>
    </p>

  <div>
    <h3>
      <a href="https://www.valueaddedresource.net/author/liz-morton/">Liz Morton</a>
        <a href="https://x.com/ValueAddedRS">
           <span data-size="s"><svg xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 0 512 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) Copyright 2023 Fonticons, Inc. --><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"></path></svg></span>
          <span>Twitter</span>
        </a>
        <a href="https://www.facebook.com/ValueAddedResource">
          <span data-icon="ei-sc-facebook" data-size="s"></span>
          <span>Facebook</span>
        </a>
        <a href="https://www.linkedin.com/in/liz-morton-828537240/">
          <span data-icon="ei-sc-linkedin" data-size="s"></span>
          <span>LinkedIn</span>
        </a>
    </h3>

      <p>Liz Morton is a 17 year ecommerce pro turned indie investigative journalist providing ad-free deep dives on eBay, Amazon, Etsy &amp; more, championing sellers &amp; advocating for corporate accountability.</p>
  </div>
</section>    
    <a id="comments"></a>



  <hr>
</article>


<!--
  Get related posts based on tags
 -->

    

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Spotify won court order against Anna's Archive, taking down .org domain (169 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2026/01/annas-archive-said-spotify-scrape-didnt-cause-domain-suspension-it-was-wrong/</link>
            <guid>46711380</guid>
            <pubDate>Wed, 21 Jan 2026 20:52:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2026/01/annas-archive-said-spotify-scrape-didnt-cause-domain-suspension-it-was-wrong/">https://arstechnica.com/tech-policy/2026/01/annas-archive-said-spotify-scrape-didnt-cause-domain-suspension-it-was-wrong/</a>, See on <a href="https://news.ycombinator.com/item?id=46711380">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="app">
    <p><a href="#main">
  Skip to content
</a></p>



<main id="main">
            <article data-id="2136651">
  
  <header>
  <div>
    <div>
      

      

      <p>
        Lawsuit was filed under seal; Anna’s Archive wasn’t notified until after takedown.
      </p>

              
          </div>

    <div>
    
    <p><span>
          Credit:

          
          Getty Images | Anadolu

                  </span>
          </p>
  </div>
  </div>
</header>


  

  
      
    
    <div>
                      
                      
          
<p>When shadow library Anna’s Archive <a href="https://arstechnica.com/tech-policy/2026/01/annas-archive-loses-org-domain-says-suspension-likely-unrelated-to-spotify-piracy/">lost its .org domain</a> in early January, the controversial site’s operator said the suspension didn’t appear to have anything to do with its recent <a href="https://arstechnica.com/tech-policy/2025/12/worlds-largest-shadow-library-brags-it-scraped-300tb-of-spotify-music-metadata/">mass scraping of Spotify</a>.</p>
<p>But it turns out, probably not surprisingly to most people, that the domain suspension resulted from a lawsuit filed by Spotify, along with major record labels Sony, Warner, and Universal Music Group (UMG). The music companies sued Anna’s Archive in late December in US District Court for the Southern District of New York, and the case was initially sealed.</p>
<p>A judge ordered the case unsealed on January 16 “because the purpose for which sealing was ordered has been fulfilled.” Numerous documents were made public on the court docket yesterday, and they explain events around the domain suspension.</p>
<p>On January 2, the music companies asked for a temporary restraining order, and the court <a href="https://storage.courtlistener.com/recap/gov.uscourts.nysd.655608/gov.uscourts.nysd.655608.19.0.pdf">granted</a> it the same day. The order imposed requirements on the Public Interest Registry (PIR), a US-based nonprofit that oversees .org domains, and Cloudflare.</p>
<p>“Together, PIR and Cloudflare have the power to shut off access to the three web domains that Anna’s Archive uses to unlawfully distribute copyrighted works,” the music companies <a href="https://storage.courtlistener.com/recap/gov.uscourts.nysd.655608/gov.uscourts.nysd.655608.11.0.pdf">told the court</a>. They asked the court to issue “a temporary restraining order requiring that Anna’s Archive immediately cease and desist from all reproduction or distribution of the Record Company Plaintiffs’ copyrighted works,” and to “exercise its power under the All Writs Act to direct PIR and Cloudflare to facilitate enforcement of that order.”</p>
<h2>Anna’s Archive notified of case after suspension</h2>
<p>The companies further asked that Anna’s Archive receive notice of the case by email only after the “order is issued by the Court and implemented by PIR and Cloudflare, to prevent Anna’s Archive from following through with its plan to release millions of illegally obtained, copyrighted sound recordings to the public.” That is apparently what happened, given that the operator of Anna’s Archive initially <a href="https://www.reddit.com/r/Annas_Archive/comments/1q3zxlb/message_from_anna_were_fine/">said</a> domain suspensions are just something that “unfortunately happens to shadow libraries on a regular basis,” and that “we don’t believe this has to do with our Spotify backup.”</p>

          
                      
                  </div>
                    
        
          
    
    <div>
          
          
<p>The request from Spotify and record labels said:</p>
<blockquote><p>[I]f Anna’s Archive receives notice that the Record Company Plaintiffs are seeking this temporary restraining order, it will almost certainly release the sound recordings that it has illegally copied from Spotify to the public immediately and activate contingency plans to relocate its infrastructure outside of the United States. To prevent this, Plaintiffs have filed their Complaint under seal, and the Record Company Plaintiffs now ask the Court to issue its temporary restraining order on an ex parte basis, so that Anna’s Archive cannot preemptively frustrate the very relief sought by the Record Company Plaintiffs’ motion.</p></blockquote>
<p>Anna’s Archive has already released Spotify metadata but not the songs, the companies said. Although the record companies are winning their case, that doesn’t necessarily mean they’ll be able to stop distribution of copyrighted files.</p>
<p>As the music companies noted, the “individuals who operate Anna’s Archive believe that they can ignore the law by remaining anonymous, accepting payments from users in cryptocurrency, and using foreign domain registrars and web hosting services that turn a blind eye to copyright infringement… The websites Anna’s Archive uses are either completely anonymous, or in one instance, registered to what appears to be a bogus company with a dubious address in Liberia, which is not a party to the Hague Convention governing service.”</p>

<h2>Anna’s Archive still up despite losing some domains</h2>
<p>The music companies argued that Cloudflare could prevent access to Anna’s Archive URLs registered outside the United States, but this doesn’t seem to have been completely successful. The companies said:</p>
<blockquote><p>Although the domain name registrars for the annas-archive.li and annas-archive.se domains are located outside of the United States, Anna’s Archive relies on Cloudflare, headquartered in San Francisco, California, to provide a so-called “reverse proxy service” for the sites. Cloudflare effectively acts as a “middleman” between the websites and users who wish to access them, providing the information necessary for a user’s computer to convert the domain names into the numerical Internet Protocol address of the server hosting the website. These “authoritative nameservers” are necessary for users to connect to Anna’s Archive using the annas-archive.li and annas-archive.se domains, and Cloudflare has the technical capability to disable the authoritative nameservers, which would prevent users from accessing these websites.</p></blockquote>
<p>While the annas-archive.se domain couldn’t be reached today, we were still able to access annas-archive.li.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<p><a href="https://torrentfreak.com/unsealed-spotify-lawsuit-triggered-annas-archive-domain-name-suspensions/">TorrentFreak noticed</a> a recent change to the portion of the Anna’s Archive website that <a href="https://annas-archive.li/torrents/spotify">linked to torrents</a> of Spotify data: It now says, “Unavailable until further notice.” The page previously linked to three torrent files labeled as metadata, audio analysis, and cover art, but has displayed the “unavailable” message since <a href="https://web.archive.org/web/20260114214206/https://annas-archive.li/torrents/spotify">at least January 14</a>. The three torrents apparently add up to 6.2TB worth of data, while the entire scrape is said to be around 300TB worth of Spotify’s most-streamed songs.</p>
<p>TorrentFreak wrote, “it appears that Anna’s Archive stopped the specific distribution of Spotify content alleged in the complaint, seemingly in partial compliance with the injunction’s ban on ‘making available’ the scraped files.” But we found it was still possible today to download the Spotify torrent files from Anna’s Archive by going to the individual URLs that used to be listed on the page.</p>
<h2>Preliminary injunction</h2>
<p>When the temporary restraining order was granted on January 2, the court also issued an order to show cause. Anna’s Archive was told to file an answer by January 12, but did not do so, and no one representing Anna’s Archive appeared at a show-cause hearing on January 16.</p>
<p>After the hearing, US District Judge Jed Rakoff granted a <a href="https://storage.courtlistener.com/recap/gov.uscourts.nysd.655608/gov.uscourts.nysd.655608.17.0.pdf">preliminary injunction</a>, which is essentially a longer-term and more expansive version of the temporary restraining order. Rakoff said the plaintiffs are likely to succeed in proving that Anna’s Archive infringed copyrights by scraping songs from Spotify, and that Anna’s Archive “has threatened and/or is threatening to engage in additional acts of infringement by further reproducing and distributing copyrighted works… by, <em>inter alia</em>, posting ‘torrent’ files on websites owned or controlled by Anna’s Archive.”</p>
<p>While the judge ordered Anna’s Archive to stop what it’s doing, the order more significantly imposes obligations on “all domain name registries and registrars of record for Anna’s Archive Domain Names and all hosting and Internet service providers for Anna’s Archive Websites.” These companies must disable access to Anna’s Archive domain names “and prevent their transfer to anyone other than the Record Company Plaintiffs,” and “cease any hosting services for Anna’s Archive Websites or any other websites that host the infringing content or directly facilitate its distribution.”</p>

          
                  </div>
                    
        
          
    
    <div>

        
        <div>
          
          
<p>The judge named specific companies the order applies to, though it is not limited to those companies. In addition to the Public Interest Registry and Cloudflare, the judge said the order applies to the Switch Foundation, the Swedish Internet Foundation, the National Internet Exchange of India, Njalla SRL, IQWeb FZ-LLC, Immaterialism Ltd., Hosting Concepts B.V., and Tucows Domains.</p>
<p>The operator of the WorldCat library catalog separately won a default judgment against Anna’s Archive in a different court last week. A judge ruled that Anna’s Archive must delete all copies of its WorldCat data and stop scraping, using, storing, or distributing the data. <a href="https://arstechnica.com/tech-policy/2026/01/judge-orders-annas-archive-to-delete-scraped-data-no-one-thinks-it-will-comply/">No one thinks Anna’s Archive will comply</a>, but the WorldCat operator said a court order would help it ask hosting services to remove data from Anna’s Archive websites.</p>


          
                  </div>

                  
          






  <div>
  <div>
          <p><a href="https://arstechnica.com/author/jon-brodkin/"><img src="https://cdn.arstechnica.net/wp-content/uploads/2016/05/j.brodkin-11_2.jpg" alt="Photo of Jon Brodkin"></a></p>
  </div>

  <div>
    

    <p>
      Jon is a Senior IT Reporter for Ars Technica. He covers the telecom industry, Federal Communications Commission rulemakings, broadband consumer affairs, court cases, and government regulation of the tech industry.
    </p>
  </div>
</div>


  <p>
    <a href="https://arstechnica.com/tech-policy/2026/01/annas-archive-said-spotify-scrape-didnt-cause-domain-suspension-it-was-wrong/#comments" title="33 comments">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 80 80"><defs><clipPath id="bubble-zero_svg__a"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath><clipPath id="bubble-zero_svg__b"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath></defs><g clip-path="url(#bubble-zero_svg__a)"><g fill="currentColor" clip-path="url(#bubble-zero_svg__b)"><path d="M80 40c0 22.09-17.91 40-40 40S0 62.09 0 40 17.91 0 40 0s40 17.91 40 40"></path><path d="M40 40 .59 76.58C-.67 77.84.22 80 2.01 80H40z"></path></g></g></svg>
    33 Comments
  </a>
      </p>
              </div>
  </article>


  


  


  <div>
    <header>
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 26"><defs><clipPath id="most-read_svg__a"><path fill="none" d="M0 0h40v26H0z"></path></clipPath><clipPath id="most-read_svg__b"><path fill="none" d="M0 0h40v26H0z"></path></clipPath></defs><g clip-path="url(#most-read_svg__a)"><g fill="none" clip-path="url(#most-read_svg__b)"><path fill="currentColor" d="M20 2h.8q1.5 0 3 .6c.6.2 1.1.4 1.7.6 1.3.5 2.6 1.3 3.9 2.1.6.4 1.2.8 1.8 1.3 2.9 2.3 5.1 4.9 6.3 6.4-1.1 1.5-3.4 4-6.3 6.4-.6.5-1.2.9-1.8 1.3q-1.95 1.35-3.9 2.1c-.6.2-1.1.4-1.7.6q-1.5.45-3 .6h-1.6q-1.5 0-3-.6c-.6-.2-1.1-.4-1.7-.6-1.3-.5-2.6-1.3-3.9-2.1-.6-.4-1.2-.8-1.8-1.3-2.9-2.3-5.1-4.9-6.3-6.4 1.1-1.5 3.4-4 6.3-6.4.6-.5 1.2-.9 1.8-1.3q1.95-1.35 3.9-2.1c.6-.2 1.1-.4 1.7-.6q1.5-.45 3-.6zm0-2h-1c-1.2 0-2.3.3-3.4.6-.6.2-1.3.4-1.9.7-1.5.6-2.9 1.4-4.3 2.3-.7.5-1.3.9-1.9 1.4C2.9 8.7 0 13 0 13s2.9 4.3 7.5 7.9c.6.5 1.3 1 1.9 1.4 1.3.9 2.7 1.7 4.3 2.3.6.3 1.3.5 1.9.7 1.1.3 2.3.6 3.4.6h2c1.2 0 2.3-.3 3.4-.6.6-.2 1.3-.4 1.9-.7 1.5-.6 2.9-1.4 4.3-2.3.7-.5 1.3-.9 1.9-1.4C37.1 17.3 40 13 40 13s-2.9-4.3-7.5-7.9c-.6-.5-1.3-1-1.9-1.4-1.3-.9-2.8-1.7-4.3-2.3-.6-.3-1.3-.5-1.9-.7C23.3.4 22.1.1 21 .1h-1"></path><path fill="#ff4e00" d="M20 5c-4.4 0-8 3.6-8 8s3.6 8 8 8 8-3.6 8-8-3.6-8-8-8m0 11c-1.7 0-3-1.3-3-3s1.3-3 3-3 3 1.3 3 3-1.3 3-3 3"></path></g></g></svg>
      
    </header>
    <ol>
              <li>
                      <a href="https://arstechnica.com/space/2026/01/webb-has-given-us-with-a-stunning-new-view-of-a-well-known-planetary-nebula/">
              <img src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/STScI-01KCMAMZ8ZSMRTR9KKD8Y6EMRJ-768x432.png" alt="Listing image for first story in Most Read: Webb reveals a planetary nebula with phenomenal clarity, and it is spectacular" decoding="async" loading="lazy">
            </a>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                  </ol>
</div>
  </main>





  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FreeBSD (107 pts)]]></title>
            <link>https://docs.freebsd.org/en/books/handbook/</link>
            <guid>46711346</guid>
            <pubDate>Wed, 21 Jan 2026 20:49:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://docs.freebsd.org/en/books/handbook/">https://docs.freebsd.org/en/books/handbook/</a>, See on <a href="https://news.ycombinator.com/item?id=46711346">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><summary>trademarks</summary><p>FreeBSD is a registered trademark of the FreeBSD Foundation.</p><p>IBM, AIX, OS/2, PowerPC, PS/2, S/390, and ThinkPad are trademarks of International Business Machines Corporation in the United States, other countries, or both.</p><p>IEEE, POSIX, and 802 are registered trademarks of Institute of Electrical and Electronics Engineers, Inc. in the United States.</p><p>Red Hat, RPM, are trademarks or registered trademarks of Red Hat, Inc. in the United States and other countries.</p><p>3Com and HomeConnect are registered trademarks of 3Com Corporation.</p><p>Adobe, Acrobat, Acrobat Reader, Flash and PostScript are either registered trademarks or trademarks of Adobe Systems Incorporated in the United States and/or other countries.</p><p>Apple, AirPort, FireWire, iMac, iPhone, iPad, Mac, Macintosh, Mac OS, Quicktime, and TrueType are trademarks of Apple Inc., registered in the U.S. and other countries.</p><p>Intel, Celeron, Centrino, Core, EtherExpress, i386, i486, Itanium, Pentium, and Xeon are trademarks or registered trademarks of Intel Corporation or its subsidiaries in the United States and other countries.</p><p>Linux is a registered trademark of Linus Torvalds.</p><p>Microsoft, IntelliMouse, MS-DOS, Outlook, Windows, Windows Media and Windows NT are either registered trademarks or trademarks of Microsoft Corporation in the United States and/or other countries.</p><p>Motif, OSF/1, and UNIX are registered trademarks and IT DialTone and The Open Group are trademarks of The Open Group in the United States and other countries.</p><p>Sun, Sun Microsystems, Java, Java Virtual Machine, JDK, JRE, JSP, JVM, Netra, OpenJDK, Solaris, StarOffice, SunOS and VirtualBox are trademarks or registered trademarks of Sun Microsystems, Inc. in the United States and other countries.</p><p>RealNetworks, RealPlayer, and RealAudio are the registered trademarks of RealNetworks, Inc.</p><p>Oracle is a registered trademark of Oracle Corporation.</p><p>3ware is a registered trademark of 3ware Inc.</p><p>ARM is a registered trademark of ARM Limited.</p><p>Adaptec is a registered trademark of Adaptec, Inc.</p><p>Android is a trademark of Google Inc.</p><p>Heidelberg, Helvetica, Palatino, and Times Roman are either registered trademarks or trademarks of Heidelberger Druckmaschinen AG in the U.S. and other countries.</p><p>Intuit and Quicken are registered trademarks and/or registered service marks of Intuit Inc., or one of its subsidiaries, in the United States and other countries.</p><p>LSI Logic, AcceleRAID, eXtremeRAID, MegaRAID and Mylex are trademarks or registered trademarks of LSI Logic Corp.</p><p>MATLAB is a registered trademark of The MathWorks, Inc.</p><p>SpeedTouch is a trademark of Thomson.</p><p>VMware is a trademark of VMware, Inc.</p><p>Mathematica is a registered trademark of Wolfram Research, Inc.</p><p>Ogg Vorbis and Xiph.Org are trademarks of Xiph.Org.</p><p>XFree86 is a trademark of The XFree86 Project, Inc.</p><p>Many of the designations used by manufacturers and sellers to distinguish their products are claimed as trademarks. Where those designations appear in this document, and the FreeBSD Project was aware of the trademark claim, the designations have been followed by the “™” or the “®” symbol.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Linux from Scratch (388 pts)]]></title>
            <link>https://www.linuxfromscratch.org/lfs/view/stable/</link>
            <guid>46709727</guid>
            <pubDate>Wed, 21 Jan 2026 18:44:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.linuxfromscratch.org/lfs/view/stable/">https://www.linuxfromscratch.org/lfs/view/stable/</a>, See on <a href="https://news.ycombinator.com/item?id=46709727">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <div>
          
          <p>
            <h2>
              Version 12.4
            </h2>
          </p>
          <p>
            <h2>
              Published September 1st, 2025
            </h2>
          </p>
          <div>
              <p>
                <h3>
                  <span>Created by Gerard</span>
                  <span>Beekmans</span>
                </h3>
              </p>
              <p>
                <h3>
                  <span>Managing Editor: Bruce</span>
                  <span>Dubbs</span>
                </h3>
              </p>
            </div>
          <p>
              <a href="https://www.linuxfromscratch.org/lfs/view/stable/legalnotice.html">Copyright</a> © 1999-2025 Gerard
              Beekmans
            </p>
        </div>
        <hr>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TeraWave Satellite Communications Network (133 pts)]]></title>
            <link>https://www.blueorigin.com/news/blue-origin-introduces-terawave-space-based-network-for-global-connectivity</link>
            <guid>46709548</guid>
            <pubDate>Wed, 21 Jan 2026 18:31:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.blueorigin.com/news/blue-origin-introduces-terawave-space-based-network-for-global-connectivity">https://www.blueorigin.com/news/blue-origin-introduces-terawave-space-based-network-for-global-connectivity</a>, See on <a href="https://news.ycombinator.com/item?id=46709548">Hacker News</a></p>
Couldn't get https://www.blueorigin.com/news/blue-origin-introduces-terawave-space-based-network-for-global-connectivity: Error: Request failed with status code 429]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Rails UI (190 pts)]]></title>
            <link>https://railsui.com/</link>
            <guid>46709543</guid>
            <pubDate>Wed, 21 Jan 2026 18:31:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://railsui.com/">https://railsui.com/</a>, See on <a href="https://news.ycombinator.com/item?id=46709543">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <div>
    <div>
    
    
    <p>No design experience? No problem. Copy-paste beautiful forms, buttons, and layouts that work perfectly with Rails. Focus on your business logic—we've got the pretty stuff covered.</p>
    <a href="https://railsui.com/components">
      <span>Explore components</span>
      

</a>
  </div>

    <div>
  

  

  <p>Skip the hours of CSS frustration. Get complete, professional-looking app layouts that work with Rails out of the box. Your users will think you hired a designer.</p>

  <a href="https://railsui.com/themes">
    <span>View all themes</span>
    

</a>
  
</div>

  </div>
  <div>
    

    <!-- Featured testimonial -->
    <blockquote>
      <p>"Rails UI is going to save me months of work. I'm an experienced software developer building my first Ruby on Rails app, but I'm not strong at front-end design. Support has been awesome as well."</p>
      <cite>
        <span>Adam G.</span> — Software Developer
      </cite>
    </blockquote>

    <!-- Two smaller testimonials -->
    <div>
      <blockquote>
        <p>"Launched our MVP in two weeks instead of two months. The themes look so polished that our investors thought we had a full design team."</p>
        <cite>
          <span>Sarah M.</span> — Startup Founder
        </cite>
      </blockquote>

      <blockquote>
        <p>"My clients can't believe how fast I deliver now. Rails UI pays for itself on the first project."</p>
        <cite>
          <span>James T.</span> — Freelance Developer
        </cite>
      </blockquote>
    </div>
  </div>


  <div>
      <h3>Get all updates directly to your inbox.
        <br>
        Sign up for the newsletter.</h3>
      

<form action="https://app.kit.com/forms/8015216/subscriptions" method="post" data-sv-form="8015216" data-uid="d6f9018719" data-format="inline" data-version="5" data-options="{&quot;settings&quot;:{&quot;after_subscribe&quot;:{&quot;action&quot;:&quot;message&quot;,&quot;success_message&quot;:&quot;Success! Now check your email to confirm your subscription.&quot;,&quot;redirect_url&quot;:&quot;&quot;},&quot;analytics&quot;:{&quot;google&quot;:null,&quot;fathom&quot;:null,&quot;facebook&quot;:null,&quot;segment&quot;:null,&quot;pinterest&quot;:null,&quot;sparkloop&quot;:null,&quot;googletagmanager&quot;:null},&quot;modal&quot;:{&quot;trigger&quot;:&quot;timer&quot;,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:5,&quot;devices&quot;:&quot;all&quot;,&quot;show_once_every&quot;:15},&quot;powered_by&quot;:{&quot;show&quot;:true,&quot;url&quot;:&quot;https://kit.com/features/forms?utm_campaign=poweredby&amp;utm_content=form&amp;utm_medium=referral&amp;utm_source=dynamic&quot;},&quot;recaptcha&quot;:{&quot;enabled&quot;:false},&quot;return_visitor&quot;:{&quot;action&quot;:&quot;show&quot;,&quot;custom_content&quot;:&quot;&quot;},&quot;slide_in&quot;:{&quot;display_in&quot;:&quot;bottom_right&quot;,&quot;trigger&quot;:&quot;timer&quot;,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:5,&quot;devices&quot;:&quot;all&quot;,&quot;show_once_every&quot;:15},&quot;sticky_bar&quot;:{&quot;display_in&quot;:&quot;top&quot;,&quot;trigger&quot;:&quot;timer&quot;,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:5,&quot;devices&quot;:&quot;all&quot;,&quot;show_once_every&quot;:15}},&quot;version&quot;:&quot;5&quot;}" min-width="400 500 600 700 800">
  
  <div data-element="header" data-style="minimal">
      
      <ul data-element="errors" data-group="alert"></ul>
      
      <p>We won't send you spam. Unsubscribe at any time.</p>
    </div></form>
  </div>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stanford scientists found a way to regrow cartilage and stop arthritis (293 pts)]]></title>
            <link>https://www.sciencedaily.com/releases/2026/01/260120000333.htm</link>
            <guid>46709179</guid>
            <pubDate>Wed, 21 Jan 2026 18:05:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sciencedaily.com/releases/2026/01/260120000333.htm">https://www.sciencedaily.com/releases/2026/01/260120000333.htm</a>, See on <a href="https://news.ycombinator.com/item?id=46709179">Hacker News</a></p>
<div id="readability-page-1" class="page"><p id="first">A study led by Stanford Medicine researchers has found that an injection blocking a protein linked to aging can reverse the natural loss of knee cartilage in older mice. The same treatment also stopped arthritis from developing after knee injuries that resemble ACL tears, which are common among athletes and recreational exercisers. Researchers note that an oral version of the treatment is already being tested in clinical trials aimed at treating age-related muscle weakness.</p><div id="text">
<p>Human cartilage samples taken from knee replacement surgeries also responded positively. These samples included both the supportive extracellular matrix of the joint and cartilage-producing chondrocyte cells. When treated, the tissue began forming new, functional cartilage.</p>
<p>Together, the findings suggest that cartilage lost due to aging or arthritis may one day be restored using either a pill or a targeted injection. If successful in people, such treatments could reduce or even eliminate the need for knee and hip replacement surgery.</p>
<p><strong>A Direct Attack on Osteoarthritis</strong></p>
<p>Osteoarthritis is a degenerative joint disease that affects about one in five adults in the United States and generates an estimated $65 billion each year in direct health care costs. Current treatments focus on managing pain or replacing damaged joints surgically. There are no approved drugs that can slow or reverse the underlying cartilage damage.</p>
<p>The new approach targets the root cause of the disease rather than its symptoms, offering a potential shift in how osteoarthritis is treated.</p>
<p><strong>The Role of a Master Aging Enzyme</strong></p>
<p>The protein at the center of the study is called 15-PGDH. Researchers refer to it as a gerozyme because its levels increase as the body ages. Gerozymes were identified by the same research team in 2023 and are known to drive the gradual loss of tissue function.</p>


<p>In mice, higher levels of 15-PGDH are linked to declining muscle strength with age. Blocking the enzyme using a small molecule boosted muscle mass and endurance in older animals. In contrast, forcing young mice to produce more 15-PGDH caused their muscles to shrink and weaken. The protein has also been connected to regeneration in bone, nerve, and blood cells.</p>
<p>In most of these tissues, repair happens through the activation and specialization of stem cells. Cartilage appears to be different. In this case, chondrocytes change how their genes behave, shifting into a more youthful state without relying on stem cells.</p>
<p><strong>A New Path to Tissue Regeneration</strong></p>
<p>"This is a new way of regenerating adult tissue, and it has significant clinical promise for treating arthritis due to aging or injury," said Helen Blau, PhD, professor of microbiology and immunology. "We were looking for stem cells, but they are clearly not involved. It's very exciting."</p>
<p>Blau, who leads the Baxter Laboratory for Stem Cell Biology and holds the Donald E. and Delia B. Baxter Foundation Professorship, and Nidhi Bhutani, PhD, associate professor of orthopaedic surgery, are the study's senior authors. The research was published in <em>Science</em>. Mamta Singla, PhD, instructor of orthopaedic surgery, and former postdoctoral scholar Yu Xin (Will) Wang, PhD, served as lead authors. Wang is now an assistant professor at the Sanford Burnham Institute in San Diego.</p>
<p><strong>Dramatic Regeneration of Joint Cartilage</strong></p>
<p>"Millions of people suffer from joint pain and swelling as they age," Bhutani said. "It is a huge unmet medical need. Until now, there has been no drug that directly treats the cause of cartilage loss. But this gerozyme inhibitor causes a dramatic regeneration of cartilage beyond that reported in response to any other drug or intervention."</p>


<p>The human body contains three main types of cartilage. Elastic cartilage is soft and flexible and forms structures such as the outer ear. Fibrocartilage is dense and tough, helping absorb shock in places like the spaces between spinal vertebrae. Hyaline cartilage is smooth and glossy, allowing joints such as the hips, knees, shoulders, and ankles to move with low friction. This type, also called articular cartilage, is the form most commonly damaged in osteoarthritis.</p>
<p><strong>Why Cartilage Rarely Grows Back</strong></p>
<p>Osteoarthritis develops when joints are stressed by aging, injury, or obesity. Chondrocytes begin releasing inflammatory molecules and breaking down collagen, the main structural protein in cartilage. As collagen is lost, cartilage becomes thinner and softer. Inflammation then leads to swelling and pain, which are hallmarks of the disease.</p>
<p>Under normal conditions, articular cartilage has very limited ability to regenerate. While some stem or progenitor cells capable of forming cartilage have been identified in bone, similar cells have not been successfully found within articular cartilage itself.</p>
<p><strong>Connecting Aging, Prostaglandins, and Repair</strong></p>
<p>Earlier research from Blau's lab showed that prostaglandin E2 is essential for muscle stem cell function. The enzyme 15-PGDH breaks down prostaglandin E2. By blocking 15-PGDH or increasing prostaglandin E2 levels, researchers previously supported the repair of damaged muscle, nerve, bone, colon, liver, and blood cells in young mice.</p>
<p>This led the team to question whether the same pathway might be involved in cartilage aging and joint damage. When they compared knee cartilage from young and old mice, they found that 15-PGDH levels roughly doubled with age.</p>
<p><strong>Regrowing Cartilage in Aging Knees</strong></p>
<p>Researchers then injected older mice with a small molecule that inhibits 15-PGDH. They first administered the drug into the abdomen to affect the entire body, and later injected it directly into the knee joint. In both cases, cartilage that had become thin and dysfunctional with age thickened across the joint surface.</p>
<p>Additional tests confirmed that the regenerated tissue was hyaline cartilage rather than the less functional fibrocartilage.</p>
<p>"Cartilage regeneration to such an extent in aged mice took us by surprise," Bhutani said. "The effect was remarkable."</p>
<p><strong>Protecting Joints After ACL-Like Injuries</strong></p>
<p>The team observed similar benefits in mice with knee injuries resembling ACL tears, which often occur during sports involving sudden stopping, pivoting, or jumping. Although such injuries can be surgically repaired, about half of affected people develop osteoarthritis in the injured joint within 15 years.</p>
<p>Mice that received twice-weekly injections of the gerozyme inhibitor for four weeks after injury were far less likely to develop osteoarthritis. In contrast, animals given a control treatment had double the levels of 15-PGDH compared with uninjured mice and developed osteoarthritis within four weeks.</p>
<p>Treated mice also moved more normally and placed more weight on the injured leg than untreated animals.</p>
<p>"Interestingly, prostaglandin E2 has been implicated in inflammation and pain," Blau said. "But this research shows that, at normal biological levels, small increases in prostaglandin E2 can promote regeneration."</p>
<p><strong>Reprogramming Cartilage Cells Without Stem Cells</strong></p>
<p>Closer analysis showed that chondrocytes in older mice expressed more genes linked to inflammation and the conversion of cartilage into bone, along with fewer genes involved in cartilage formation. Treatment shifted these patterns.</p>
<p>One group of chondrocytes that produced 15-PGDH and cartilage-degrading genes dropped from 8% to 3%. Another group associated with fibrocartilage formation declined from 16% to 8%. A third population, which did not produce 15-PGDH and instead expressed genes tied to hyaline cartilage formation and maintenance of the extracellular matrix, rose from 22% to 42%.</p>
<p>These changes indicate a broad return to a more youthful cartilage profile without involving stem or progenitor cells.</p>
<p><strong>Evidence From Human Cartilage Samples</strong></p>
<p>The researchers also tested cartilage taken from patients undergoing total knee replacement for osteoarthritis. After one week of treatment with the 15-PGDH inhibitor, the tissue showed fewer 15-PGDH-producing chondrocytes, reduced expression of cartilage degradation and fibrocartilage genes, and early signs of articular cartilage regeneration.</p>
<p>"The mechanism is quite striking and really shifted our perspective about how tissue regeneration can occur," Bhutani said. "It's clear that a large pool of already existing cells in cartilage are changing their gene expression patterns. And by targeting these cells for regeneration, we may have an opportunity to have a bigger overall impact clinically."</p>
<p><strong>Looking Toward Human Trials</strong></p>
<p>Blau added, "Phase 1 clinical trials of a 15-PGDH inhibitor for muscle weakness have shown that it is safe and active in healthy volunteers. Our hope is that a similar trial will be launched soon to test its effect in cartilage regeneration. We are very excited about this potential breakthrough. Imagine regrowing existing cartilage and avoiding joint replacement."</p>
<p>Researchers from the Sanford Burnham Prebys Medical Discovery Institute also contributed to the study.</p>
<p>The work was supported by funding from the National Institutes of Health (grants R01AR070864, R01AR077530, R01AG069858 and R00NS120278), the Baxter Foundation for Stem Cell Biology, the Li Ka Shing Foundation, the Stanford Cardiovascular Institute, the Milky Way Research Foundation, the Canadian Institutes of Health Research, a Stanford Translational Research and Applied Medicine Pilot grant, a GlaxoSmithKline Sir James Black Postdoctoral Fellowship, and a Stanford Dean's Postdoctoral Fellowship.</p>
<p>Blau, Bhutani, and other co-authors are inventors on patent applications held by Stanford University related to 15-PGDH inhibition in cartilage and tissue rejuvenation, which are licensed to Epirium Bio. Blau is a co-founder of Myoforte/Epirium and holds equity and stock options in the company.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[illumos (104 pts)]]></title>
            <link>https://illumos.org/</link>
            <guid>46708807</guid>
            <pubDate>Wed, 21 Jan 2026 17:39:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://illumos.org/">https://illumos.org/</a>, See on <a href="https://news.ycombinator.com/item?id=46708807">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<section>
  <p>
    <h2>What is illumos?</h2>
  </p>
  <div>
    <p>
      illumos is a Unix operating system which provides next-generation
      features for downstream distributions, including
      <a href="https://illumos.org/books/dtrace">
      advanced system debugging</a>,
      <a href="https://openzfs.org/">
      next generation filesystem</a>, networking, and virtualization options.
    </p>

    

    <p>
      illumos is developed by both volunteers and companies building products
      on top of the software.
    </p>

    <p>
      illumos is an excellent base for both traditional and cloud-native
      deployments.
    </p>
  </div>
</section>

<section>
  <p>
    <h2>Getting Started</h2>
  </p>
  <div>
      <div>

          <h3>Download and install</h3>

          <p>
          The <a href="https://omniosce.org/">OmniOS</a>,
          <a href="https://www.openindiana.org/">
          OpenIndiana</a>,
          and <a href="http://www.tribblix.org/">
          Tribblix</a>
          distributions are a good place for new users to get started.
          You can install in a virtual machine or on bare metal.
          </p>

          <p>
          Look at the
          <a href="https://illumos.org/docs/about/distro/">
          full list</a> to find a distribution that meets your needs!
          </p>
      </div>

      <div>

          <h3>Get the source</h3>

          <p>
          illumos is freely available from our
          <a href="https://code.illumos.org/plugins/gitiles/illumos-gate">
          source repository</a>, or a read-only
          <a href="https://github.com/illumos/illumos-gate">
          mirror on GitHub</a>.  You can see recent changes
          <a href="https://code.illumos.org/plugins/gitiles/illumos-gate/+log/refs/heads/master">
          here</a>.
          </p>

          <p>
          Instructions for building illumos on various distributions
          can be found
          <a href="https://illumos.org/docs/developers/build/">
          here</a>!
         </p>
      </div>

      <div>
          <h3>Join the community</h3>
          <p>
          Discussions occur on the project <a href="https://illumos.topicbox.com/latest">mailing lists</a>;
          you can join and post, or read the archives on the web.
          The <code>#illumos</code> channel on <a href="https://web.libera.chat/?channel=#illumos">Libera Chat</a>
          (IRC) is very active and has <a href="https://log.omnios.org/illumos">online logs</a>.
          </p>

          <p>
          We strive to be inclusive, and enforce a
          <a href="https://code.illumos.org/plugins/gitiles/illumos-gate/+/refs/heads/master/CODE_OF_CONDUCT.md">
          code of conduct</a> in our interactions.
          </p>
      </div>

    </div>
</section>

<section>
  <p>
    <h2>Other Resources</h2>
  </p>
  
</section>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Waiting for dawn in search: Search index, Google rulings and impact on Kagi (375 pts)]]></title>
            <link>https://blog.kagi.com/waiting-dawn-search</link>
            <guid>46708678</guid>
            <pubDate>Wed, 21 Jan 2026 17:28:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.kagi.com/waiting-dawn-search">https://blog.kagi.com/waiting-dawn-search</a>, See on <a href="https://news.ycombinator.com/item?id=46708678">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            
            <p>This blog post is a follow-up to <a href="https://blog.kagi.com/dawn-new-era-search">Dawn of a new era in Search</a>, published last year. A lot has changed: the legal case has advanced, AI has become the central battleground, and the need for open index access has only grown sharper.</p>

<p>As of late 2025, one company decides what nearly 9 out of 10 people see when they search the web: Google. On August 5, 2024, a U.S. court officially ruled that Google is a monopolist in general search services. This ruling is not about ads or browser defaults alone. It is about who controls the index that powers both search and AI - and whether anyone else is allowed to build on it.</p>

<p>The stakes have grown sharper over the past year. LLMs hallucinate without grounding in real-world information; every agent that answers questions about the real world, depends on search. LLMs themselves are a blend of proprietary and open source. Cloud compute is competitive. But search is different - only one company controls a comprehensive, fresh, high-quality web index. If one company controls the index, it controls the floor on how good AI can be - and who gets to build it. The innovation crunch in search is now an innovation crunch in AI.</p>

<p>We are writing this from a position we believe in: people should have the choice to access information without behaviour-changing, ad-driven, intermediary standing between them and knowledge.</p>

<p>Why does this matter? The information we consume shapes our understanding of the world as profoundly as the food we eat shapes our bodies. Search (directly, and indirectly through AI) is the primary mechanism through which we inform political judgments, financial decisions, medical choices, and countless other consequential aspects of our lives. When a single company controls the gateway to information - and operates that gateway in ways misaligned with user interests - it influences not only what we know, but how we reason.</p>

<h2>The problem: A search monopoly</h2>

<p>The data is stark.</p>

<p><strong>Worldwide search market share (October 2025, StatCounter):</strong></p>

<table>
<thead>
<tr>
<th>Search Engine</th>
<th>Market Share</th>
</tr>
</thead>

<tbody>
<tr>
<td>Google</td>
<td>90.06%</td>
</tr>

<tr>
<td>Bing</td>
<td>4.31%</td>
</tr>

<tr>
<td>Yandex</td>
<td>1.84%</td>
</tr>

<tr>
<td>Yahoo</td>
<td>1.45%</td>
</tr>

<tr>
<td>DuckDuckGo</td>
<td>0.89%</td>
</tr>

<tr>
<td>Baidu</td>
<td>0.73%</td>
</tr>
</tbody>
</table>
<p>The United States is similar: Google at 85%, Bing at 9%, everyone else in the noise.</p>

<p>This is not a competitive market. It is a monopoly with a distant second place.</p>

<p>The search index is irreplaceable infrastructure. Building a comparable one from scratch is like building a parallel national railroad. Microsoft <a href="https://www.cnbc.com/2024/02/24/google-says-microsoft-offered-to-sell-bing-to-apple-in-2018.html#:~:text=The%20Justice%20Department%20said%20in%20its%20own%20newly%20unsealed%20filing%20that%20Microsoft%20has%20spent%20almost%20$100%20billion%20on%20Bing%20over%2020%20years">spent</a> roughly $100 billion over 20 years on Bing and still holds single-digit share. If Microsoft cannot close the gap, no startup can do it alone.</p>

<p>This is exactly what the <a href="https://en.wikipedia.org/wiki/Sherman_Antitrust_Act/">Sherman Act</a> was designed to address: when one company’s control of critical infrastructure prevents effective competition, regulators must force open access on fair terms.</p>

<p>When a single, ad-driven gatekeeper controls the primary way humans reach information, it is not just competition that suffers - it is our collective ability to learn, to make informed medical and economic choices, and to participate meaningfully in democratic life.</p>

<p>As Ian Bremmer <a href="https://x.com/ianbremmer/status/966677755424313344">put it</a>: <em>“The idea that we get our information as citizens through algorithms determined by the world’s largest advertising company is my definition of dystopia.”</em></p>

<p>Google’s own founders knew this. In their <a href="http://infolab.stanford.edu/pub/papers/google.pdf">1998 white paper</a>, Sergey Brin and Larry Page sharply criticized the ad-supported search model for creating mixed motives and biasing results toward advertisers’ interests. They wrote that <em>“advertising funded search engines will be inherently biased towards the advertisers and away from the needs of the consumers”</em> and that <em>“advertising income often provides an incentive to provide poor quality search results.”</em> Those concerns have only grown more pressing as search has become the primary interface between humanity and the web.</p>

<h2>We tried to do it the right way</h2>

<p>Kagi has always tried to integrate the best sources of knowledge into one coherent, ad-free experience. We see ourselves as connective tissue: letting people reach high-quality information directly, without passing through an ad system whose incentives are misaligned with their needs.</p>

<p>We approached every major index vendor seeking direct licensing on FRAND terms (Fair, Reasonable, And Non-Discriminatory): fair pricing, no mandatory ad syndication, ability to reorder and blend results. We succeeded with many, including:</p>

<table>
<thead>
<tr>
<th>Vendor</th>
<th>Status</th>
</tr>
</thead>

<tbody>
<tr>
<td>Mojeek</td>
<td>Direct license</td>
</tr>

<tr>
<td>Brave</td>
<td>Direct license</td>
</tr>

<tr>
<td>Yandex</td>
<td>Direct license</td>
</tr>

<tr>
<td>Wikipedia</td>
<td>Direct license</td>
</tr>

<tr>
<td>TripAdvisor</td>
<td>Direct license</td>
</tr>

<tr>
<td>Yelp</td>
<td>Direct license</td>
</tr>

<tr>
<td>Apple</td>
<td>Direct license</td>
</tr>

<tr>
<td>Wolfram Alpha</td>
<td>Direct license</td>
</tr>

<tr>
<td>Our own Small Web Index</td>
<td>Proprietary</td>
</tr>
</tbody>
</table>
<p>With Google and Bing, we failed - not for lack of trying.</p>

<p>Bing: Their terms didn’t work for us from the start. Microsoft’s terms prohibited reordering results or merging them with other sources - restrictions incompatible with Kagi’s approach. In February 2023, they announced price increases of up to 10x on some API tiers. Then in May 2025, they retired the Bing Search APIs <a href="https://learn.microsoft.com/en-us/lifecycle/announcements/bing-search-api-retirement/">entirely</a>, effective August 2025, directing customers toward AI-focused alternatives like Azure AI Agents.</p>

<p>Google: Google does not offer a public search API. The only available path is an ad-syndication bundle with no changes to result presentation - the model <a href="https://startpage.com/">Startpage</a> uses. Ad syndication is a non-starter for Kagi’s ad-free subscription model.[^1]</p>

<h2>The current interim approach</h2>

<p>Because direct licensing isn’t available to us on compatible terms, we - like many others - use third-party API providers for SERP-style results (SERP meaning search engine results page). These providers serve major enterprises (according to their websites) including Nvidia, Adobe, Samsung, Stanford, DeepMind, Uber, and the United Nations.</p>

<p>This is not our preferred solution. We plan to exit it as soon as direct, contractual access becomes available. There is no legitimate, paid path to comprehensive Google or Bing results for a company like Kagi. Our position is clear: open the search index, make it available on FRAND terms, and enable rapid innovation in the marketplace.</p>

<h2>The DOJ ruling</h2>

<p>The Google antitrust case began in 2020. On August 5, 2024, the court ruled Google violated Section 2 of the Sherman Act by unlawfully maintaining its monopoly through exclusive distribution agreements. (<a href="https://storage.courtlistener.com/recap/gov.uscourts.dcd.223205/gov.uscourts.dcd.223205.1033.0_5.pdf">Full ruling</a>)</p>

<p>On September 2, 2025, the DOJ announced remedies (<a href="https://www.justice.gov/opa/pr/department-justice-wins-significant-remedies-against-google">press release</a>):</p>

<ul>
<li><strong>Limits on exclusivity:</strong> Google is prohibited from exclusive contracts related to Search, Chrome, Assistant, and Gemini.</li>
<li><strong>Data sharing and syndication:</strong> Google must provide search index and interaction data to competitors and offer syndication services to help rivals build competitive search.</li>
<li><strong>Addressing monopolization tactics:</strong> The remedies aim to dismantle a decade of exclusionary agreements.</li>
</ul>

<p>In December 2025, Judge Mehta issued a <a href="https://storage.courtlistener.com/recap/gov.uscourts.dcd.223205/gov.uscourts.dcd.223205.1461.0_2.pdf">memorandum</a> outlining the specific remedies the court intends to impose. The details are significant:</p>

<ul>
<li><strong>Mandatory syndication:</strong> Google must offer query-based search syndication to “Qualified Competitors” on terms no less favorable than those provided to current partners.</li>
<li><strong>No ad bundling:</strong> Google cannot condition access to search results on the use of Google Ads; competitors are free to monetize via their own ads or third parties.</li>
<li><strong>Index data access:</strong> Google must provide Web Search Index data (URLs, crawl metadata, spam scores) at marginal cost.</li>
<li><strong>Duration:</strong> The judgment remains in effect for 6 years, with syndication licenses guaranteed for terms of 5 years.</li>
</ul>

<p>If implemented as outlined, this is exactly what we have been asking for. The legal trajectory is promising. Google will contest details, and final enforceable terms are still being worked out. The fight now is ensuring these remedies become real, practical access - not paper compliance.</p>

<h3>Why enforcement matters now</h3>

<p>Even as these remedies take shape, Google is moving to close the back door. In December 2025, <a href="https://arstechnica.com/google/2025/12/google-lobs-lawsuit-at-search-result-scraping-firm-serpapi/">Google sued SerpApi</a> for scraping its results at scale.</p>

<p>We take a measured, principled view:</p>

<ul>
<li><strong>Context matters:</strong> Google built its index by crawling the open web before robots.txt was a widespread norm, often over publishers’ objections. Today, publishers “consent” to Google’s crawling because the alternative - being invisible on a platform with 90% market share - is economically unacceptable. Google now enforces ToS and robots.txt against others from a position of monopoly power it accumulated without those constraints. The rules Google enforces today are not the rules it played by when building its dominance.</li>
<li><strong>The structural problem remains:</strong> This lawsuit is only necessary because Google refuses to offer legitimate, paid index access.</li>
<li><strong>Our position is unchanged:</strong> We have always wanted direct licensing. We would happily pay market rates for clean, contractual access. The fact that we - and companies like Stanford, Nvidia, Adobe, and the United Nations - have had to rely on third-party vendors is a symptom of the closed ecosystem, not a preference.</li>
</ul>

<p>The connection to DOJ remedies is direct: if Google is going to close the back door, regulators must ensure the front door is open. That is exactly what the DOJ’s index syndication requirements are meant to achieve - and why we support their full implementation.</p>

<h2>What could be: A layered search ecosystem</h2>

<p>The DOJ ruling does not itself create a healthy market, but it makes one possible.</p>

<p>And while this post focuses on remedies and their impact on Kagi, it is worth zooming out: even if those remedies work perfectly, long-term societal prosperity and resilience require a non-commercial baseline for access to information - something that is not dependent on ad incentives or a single vendor’s business priorities. Think of it as a north-star model for a modern society where information access is a fundamental right.</p>

<p>Here is what that could look like:</p>

<h3>Layer 1: Search as a public good</h3>

<p>This is a long-term possibility, not a near-term expectation. A government-backed, ad-free, intermediary-free, taxpayer-funded search service providing baseline, non-discriminatory access to information. Imagine search.org.</p>

<p>This is not something the DOJ remedies create directly, nor something Kagi expects to exist soon. It is included here to make explicit what an open-index world could ultimately make possible.</p>

<p>This layer would replace the role public libraries played for centuries - a role that effectively disappeared when commercial web search took over in the late 1990s. Our ancestors understood well the benefits that non-discriminatory, direct access to information brings to citizens, and ultimately society itself.</p>

<p>It raises hard questions: governance, funding, political independence, precedent. But the principle is sound. Every citizen should have access to information without an ad-optimized algorithm standing between them and knowledge. If we can fund public libraries, we can fund public search.</p>

<h3>Layer 2: Free, ad-based search</h3>

<p>Commercial search engines with richer features, funded by advertising. Users understand the tradeoff and have a genuine public alternative. This is the space where most contemporary search engines operate.</p>

<h3>Layer 3: Paid, subscription-based search</h3>

<p>Premium search engines offering the highest possible quality, privacy, and advanced features for users who value this and are willing to pay. This is where Kagi operates - and where we are expanding as an integrator of knowledge across search, browser, mail, and AI assistants, without selling your attention.</p>

<p>This layered model creates a diverse ecosystem:</p>

<ul>
<li>A public baseline for information access.</li>
<li>Commercial free options for convenience and reach.</li>
<li>Premium paid options for those who want maximum quality and control.</li>
<li>Aligns with the primary purpose of the Sherman Act.[^2]</li>
</ul>

<h2>Conclusion</h2>

<p>The DOJ ruling is starting to do what antitrust is supposed to do: turn a closed, private choke point into shared infrastructure that others can build on. If the remedies land as real, usable access (APIs, cost-based pricing, no ad bundling), the web can support a layered ecosystem again: a public baseline for citizens, free ad-supported products for reach, and paid services that compete on quality, privacy, and power-user features.</p>

<p>That is the world we are building Kagi for. We are ready to walk through the front door - not depend on gray-market workarounds. Our job now is to be ready when the door opens, and to help make sure it does: keep Kagi genuinely multi-source, keep investing in our Small Web Index, and keep shipping a subscription search experience that delivers the best results across providers. If we get this right, the next decade of search and AI does not have to be one funnel owned by one company. It can be a competitive stack of layers that treats information access as the public good it has always been.</p>

<hr>

<h2>References</h2>

<h4>DOJ v. Google</h4>

<ul>
<li><a href="https://www.courtlistener.com/docket/18552824/united-states-of-america-v-google-llc/">UNITED STATES OF AMERICA v. GOOGLE LLC, 1:20-cv-03010</a> – Full case docket on CourtListener</li>
<li><a href="https://storage.courtlistener.com/recap/gov.uscourts.dcd.223205/gov.uscourts.dcd.223205.1033.0_5.pdf">Memorandum Opinion – Judge Amit Mehta (PDF)</a> – Court ruling finding Google violated antitrust law</li>
<li><a href="https://www.justice.gov/opa/pr/department-justice-wins-significant-remedies-against-google">Department of Justice Wins Significant Remedies Against Google</a> – DOJ press release announcing remedies, September 2, 2025</li>
<li><a href="https://storage.courtlistener.com/recap/gov.uscourts.dcd.223205/gov.uscourts.dcd.223205.1461.0_2.pdf">Judge Mehta’s Remedies Memorandum (PDF)</a> – December 2025</li>
</ul>

<h4>Market data and commentary</h4>

<ul>
<li><a href="https://gs.statcounter.com/search-engine-market-share">Search Engine Market Share Worldwide</a> – StatCounter, October 2025</li>
<li><a href="https://gs.statcounter.com/search-engine-market-share/all/united-states-of-america">Search Engine Market Share United States</a> – StatCounter, October 2025</li>
<li><a href="https://x.com/ianbremmer/status/966677755424313344">Ian Bremmer on algorithmic information access</a> – Commentary on ad-driven search</li>
<li><a href="http://infolab.stanford.edu/pub/papers/google.pdf">The Anatomy of a Large-Scale Hypertextual Web Search Engine</a> – Original Google white paper by Brin &amp; Page, Stanford, 1998</li>
</ul>

<h4>Third-party search API providers</h4>

<ul>
<li><a href="https://arstechnica.com/google/2025/12/google-lobs-lawsuit-at-search-result-scraping-firm-serpapi/">Google lobs lawsuit at search result scraping firm</a> – Ars Technica coverage of Google’s litigation</li>
</ul>

<h2>Footnotes</h2>

<p>[^1]: A note on Google’s existing APIs: Google offers <a href="https://programmablesearchengine.google.com/about/">PSE</a>, designed for adding search boxes to websites. It can return web results, but with reduced scope and terms tailored for that narrow use case. More recently, Google offers <a href="https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/google-search">Grounding with Google Search</a> through Vertex AI, intended for grounding LLM responses. Neither is general-purpose index access. Programmable Search Engine is not designed for building competitive search. Grounding with Google Search is priced at <a href="https://cloud.google.com/generative-ai-app-builder/pricing#:~:text=$35.00%20per%201%2C000%20requests">$35 per 1,000 requests</a> - economically unviable for search at scale, and structured as an AI add-on rather than standalone index syndication. These are not the FRAND terms the market needs.</p>

<p>[^2]: Our understanding of the primary purpose of the Sherman Act is not to shield competitors from the success of legitimate businesses or to prevent those businesses from earning fair profits. Rather, it is to preserve a competitive marketplace that protects consumers from harm (see <a href="https://books.google.com/books?id=y3IOROCcVacC">Competition law and consumer protection</a>, Kluwer Law International, pp. 291–293). Opening the search index would create healthy, real, and intense competition in the search space - including competition to Kagi - which aligns with our understanding of the Sherman Act’s intent. The goal is not the elimination of dominant firms, but the prevention of a single, closed index from becoming the only gateway to information.</p>

<p>Published by Vladimir Prelovac and Raghu Murthi on January 21, 2026.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TrustTunnel: AdGuard VPN protocol goes open-source (166 pts)]]></title>
            <link>https://adguard-vpn.com/en/blog/adguard-vpn-protocol-goes-open-source-meet-trusttunnel.html</link>
            <guid>46708601</guid>
            <pubDate>Wed, 21 Jan 2026 17:21:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://adguard-vpn.com/en/blog/adguard-vpn-protocol-goes-open-source-meet-trusttunnel.html">https://adguard-vpn.com/en/blog/adguard-vpn-protocol-goes-open-source-meet-trusttunnel.html</a>, See on <a href="https://news.ycombinator.com/item?id=46708601">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            

                                
<p><span>
                            January 21, 2026
                    </span>
    
            <span>
                
    
    4 min read

        </span>
    
    </p>
                        </div><div v-pre="">
                                <p>Today is a big day for us, and for everyone who cares about transparency, privacy, and having full control over their own traffic. We’re finally open-sourcing the protocol that powers AdGuard VPN. And it now has a name: <strong>TrustTunnel.</strong></p>
<p>For a long time, we’ve wanted to make the protocol public. Many of you asked for it, and we always said: yes, we will, it’s only a matter of time. Well, the time has come.</p>
<div><p>🎉</p><p>TrustTunnel is now open-source, free to explore, audit, build upon, and use in your own projects.</p></div><h2 id="what-is-trusttunnel">What is TrustTunnel?</h2>
<p>At its core, TrustTunnel is a modern, secure, mobile-optimized VPN protocol. It’s the very same technology that has been running inside all AdGuard VPN apps: on mobile, desktop, and browser extensions.</p>
<h2 id="why-trusttunnel-because-we-needed-something-better">Why TrustTunnel? Because we needed something better</h2>
<p>There are plenty of VPN protocols out there, so why create our own, some might ask. That is because <strong>we’ve seen in practice the faults of popular VPN protocols,</strong> especially in countries with tight restrictions on internet access. Protocols like OpenVPN, WireGuard, and IPSec share common weaknesses: they are easy to detect and block at the network level, and attempts to conceal VPN traffic often reduce speed. Traditional approaches “wrap” VPN data in a TCP connection and mimic normal web traffic, but TCP’s way of confirming every piece of data creates delays and makes the connection slower.</p>
<p>Unlike those conventional VPN protocols, TrustTunnel is engineered to blend in with regular HTTPS traffic, making it far harder to throttle or block and helping it slip past deep-packet inspection, all while preserving strong privacy and security. It achieves this through TLS-based encryption, the same standard that secures HTTPS, and by leveraging HTTP/2 or HTTP/3 transport, which are ubiquitous on the web. Each connection runs on its own dedicated stream, which combines packets for faster, more efficient transmission. It is also optimized for mobile platforms and performs well even in unstable network conditions.</p>
<h2 id="a-protocol-you-can-use-run-tweak-extend-and-build-upon">A protocol you can use, run, tweak, extend, and build upon</h2>
<p>By releasing TrustTunnel, we hope to achieve two things. First of all, we want to finally show our users what protocol is powering AdGuard VPN, thus allowing them to audit it openly. At AdGuard, we have always been staunch supporters of the idea of open-source software, and many of our products have long been open source. AdGuard VPN was lagging behind in this regard, but with TrustTunnel being released publicly, it is starting to catch up.</p>
<p>But most importantly, we want to change the status quo in the world of VPN protocols and offer an alternative to existing solutions. That said, we do not want it to be just a PR stunt, when the protocol’s code is de-facto ‘open source,’ but only one VPN service actually runs it. We believe in free and open-source software (FOSS) and want TrustTunnel to be used widely, including by other VPN services. We believe this is the right way to go about open source development, and we hope the community will participate in the TrustTunnel evolution. We welcome any contribution, whether it is a feature request, a bug report, or even a direct contribution to the app’s development.</p>
<p><strong>What have we done to make this possible?</strong></p>
<ol>
<li>We are publishing the first version of the TrustTunnel specification.</li>
<li>We are releasing the complete code of our reference implementation of the TrustTunnel server and its clients under a very permissive license.</li>
</ol>
<p>You don’t have to install AdGuard VPN to use TrustTunnel. You can configure your own server and use open source TrustTunnel clients:</p>
<ul>
<li>
<p>Command-line TrustTunnel clients support Linux, Windows, and macOS</p>
</li>
<li>
<p>We are also releasing two client apps for iOS and Android</p>
</li>
</ul>
<p>TrustTunnel clients already have a lot of functionality, they allow you to:</p>
<ul>
<li>
<p><strong>Use flexible routing rules</strong> to decide which requests go through the tunnel and which stay on the local network</p>
</li>
<li>
<p><strong>Exercise fine-grained control</strong>, separating work and personal traffic, routing specific domains or apps, and tuning network behavior without complicated setup</p>
</li>
<li>
<p><strong>Benefit from a real-time request log</strong> that provides full transparency into where the device sends traffic, how routing rules apply, and which connections use the tunnel</p>
</li>
</ul>
<h2 id="useful-links">Useful links</h2>
<p>This is a long-awaited moment for us. We promised to open-source our protocol, and today we’re delivering on that promise. With TrustTunnel now open source, users and developers alike can explore, self-host, and build on the technology.</p>
<p>To get started, check out the following resources:<br>
<a href="https://trusttunnel.org/">TrustTunnel website</a><br>
<a href="https://agrd.io/instruction_trusttunnel">TrustTunnel open-source repository on GitHub</a><br>
<a href="https://agrd.io/ios_trusttunnel">TrustTunnel app for iOS</a><br>
<a href="https://agrd.io/android_trusttunnel">TrustTunnel app for Android</a></p>

                        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PicoPCMCIA – a PCMCIA development board for retro-computing enthusiasts (113 pts)]]></title>
            <link>https://www.yyzkevin.com/picopcmcia/</link>
            <guid>46708096</guid>
            <pubDate>Wed, 21 Jan 2026 16:43:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.yyzkevin.com/picopcmcia/">https://www.yyzkevin.com/picopcmcia/</a>, See on <a href="https://news.ycombinator.com/item?id=46708096">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="primary">
		<main id="main">

		
<article id="post-1017" class="page">
	<!-- .entry-header -->

	
	<div>
		




<div>
<p>This is a PCMCIA development board for retro-computing enthusiasts who want to experiment with audio, networking, and expansion on vintage laptops and mobile devices. While ISA users have enjoyed projects like <a href="https://picog.us/" target="_blank" rel="noreferrer noopener">PicoGUS </a>and PicoMEM, PCMCIA users have long been limited to scarce legacy cards with narrow functionality — this board aims to change that. The project is fully open source, and while it is designed to encourage low-level experimentation and development, pre-built, community-provided firmware is available for users who want to test functionality without diving into the technical details. It is intended for hobbyist and development use and is not certified for production deployment.</p>



<div>
<figure><a href="https://www.yyzkevin.com/picopcmcia/reservation/"><img fetchpriority="high" decoding="async" width="612" height="763" src="https://www.yyzkevin.com/wp-content/uploads/2026/01/CardPicture.png" alt="PicoPCMCIA" srcset="https://www.yyzkevin.com/wp-content/uploads/2026/01/CardPicture.png 612w, https://www.yyzkevin.com/wp-content/uploads/2026/01/CardPicture-241x300.png 241w" sizes="(max-width: 612px) 100vw, 612px"></a></figure>




</div>
</div>







<h2>Device Compatibility</h2>



<p>This is a <strong>Type II, 5V, 16-bit PC Card</strong> designed for use in compliant PCMCIA sockets and should work in most devices.  While I have not yet encountered a device advertising PCMCIA support that was incompatible, support for every device cannot be guaranteed. Power consumption varies depending on enabled functions; support for low-power devices such as the <strong>HP 200LX</strong> is considered mandatory, and the card has been tested to remain within the <strong>150 mA</strong> limit while using network functionality and storage emulation. On devices with very limited power budgets, <strong>simultaneous use of networking and audio may require external power</strong>.</p>



<p>A short list of devices that I actively test on:<br></p>



<ul>
<li>IBM PC110</li>



<li>HP 200LX</li>



<li>Amiga 1200</li>



<li>Apple Newton</li>



<li>HP Jornada 720</li>



<li>Compaq LTE Elite</li>



<li>IBM Thinkpad 235</li>



<li>IBM Thinkpad 240</li>



<li></li>
</ul>







<h2><span>Features Overview</span></h2>



<p>Built around the <strong>RP2350</strong> and leveraging the ISA-like nature of the PCMCIA bus, this project benefits greatly from <strong>code interchangeability with other RP-based retro projects</strong>, most notably <strong>PicoGUS</strong> and <strong>PicoMEM</strong>. This shared foundation allows features and improvements to move quickly between platforms, expanding functionality over time.</p>



<h2><span>Wi-fi / Bluetooth</span></h2>



<p>The card has an onboard wireless module containing the <strong>Infineon CYW43439</strong>, same as found on the Raspberry Pi Pico W. This allows the card to attach to modern Wi-Fi networks (2.4GHz 802.11b/g/n WPA2). It can then emulate an NE2000 adapter and/or a dialup modem allowing the host computer to access the network as if it was wired, unaware it is wireless.</p>



<p>Essentially every platform containing PCMCIA will have existing drivers to recognize and utilize the card as a modem or ethernet adapter making this a near universal option for all devices and platforms including rare devices such as the Apple Newton.</p>



<p>It also has a Bluetooth which opens up a lot of possibilities for A2DP wireless audio streaming and wireless gamepads/mice.  Software for these features Bluetooth features are still under development and is at a proof of concept stage.</p>



<h2><span>Audio</span></h2>



<h2>Hardware</h2>



<p>The card has an included Texas Instruments TLV320AIC3254 which calls itself a <strong>“Very Low-Power Stereo Audio CODEC with programmable miniDSP”</strong>. The main features of this device in our application are:</p>



<ul>
<li>DAC that is fed high quality audio from the RP2354 over i2s</li>



<li>Amplified stereo headphone amplifier</li>



<li>Line out feeding the host device internal speaker (where supported)</li>



<li>Line in from the onboard midi sythesizer (see below)</li>



<li>Line in from external i/o connector for mixing external audio</li>



<li>Controlled by the RP2350 via i2c (controlling volumes etc).</li>
</ul>



<p>This is combined with a DREAM SAM2695 <strong>“Low power single chip synthesizer with effects and built-in codec”</strong>, this is the same chip used on the <a href="https://www.serdashop.com/waveblaster" target="_blank" rel="noreferrer noopener">Serdashop Dreamblaster S2</a>. It is a great device for DOS gaming and other applications, its main features are:</p>



<ul>
<li>64-voice polyphony (without effects)</li>



<li>38-voice polyphony + effects</li>



<li>CleanWave soundset</li>



<li>General MIDI compatible effects</li>



<li>4-band stereo equalizer</li>
</ul>



<h2>MPU-401</h2>



<p>Emulation of intelligent mode MPU-401 is possible thanks to implementation done by PicoGUS base on SoftMPU/HardMPU.  The midi output is driven to the internal SAM2695 as well as to an external Midi port.   While using external Midi you are able to mute the  internal SAM2695,  or if you are  not using any of the internal sound hardware you can power it down.  Planning has been done with the external GPIO to  support MIDI IN  if ever implemented.</p>



<h2>Sound Blaster Emulation</h2>



<p>Sound Blaster emulation on PCMCIA is particularly challenging, as most PCMCIA sockets and cards lack native DMA support. To address this, the PicoPCMCIA implements <strong>DMA emulation</strong>, similar in spirit to the approach used by the infamous IBM 3D Sound card, resulting in good compatibility with many real-mode and protected-mode games — including the obligatory <em>Doom</em>.   The IBM card was essentially the only card to offer this functionality, it seems it may have been that way due to IBM patenting (expired) the concept of DMA emulation with PCMCIA.</p>



<p>The core Sound Blaster emulation developed for PicoPCMCIA has been shared with the PicoGUS project, where it is actively used and has greatly benefited from additional community-contributed improvements. <strong>Adlib/OPL</strong> emulation is borrowed from the PicoGUS implementation.</p>



<h2>Gravis Ultrasound (GUS)</h2>



<p>Thanks to the incredible work from the PicoGUS,   it is now possible to have the worlds first PCMCIA Gravis Ultrasound! Currently this does not support DMA so only some games/demos work.  The GUS is a little bit different with its use of TC, but it may be possible to apply the DMA emulation strategies from the  SoundBlaster mode to the GUS.</p>



<h2>CD-ROM Audio</h2>



<p>The card implements an emulated  Panasonic MKE CD-ROM which an be used for both data and audio.  The audio at full quality is sent to the TI DSP over i2c  and can be used simultaneously with all the other audio functions.   This code was shared to the PicoGUS and is currently in use there and has been improved by the community.</p>



<h2>Storage Emulation</h2>



<p>While storage emulation is not a primary focus given the ready availability of solutions like CompactFlash, it is supported and continues to evolve. Current implementations include Panasonic MKE CD-ROM emulation as well as linear flash emulation, and ATA/ATAPI emulation should be possible in the future once the <a href="https://picoi.de/" target="_blank" rel="noreferrer noopener">PicoIDE </a>project becomes available and code can be shared.  Disk images can be BIN/CUE, ISO and are stored on the MicroSD card.</p>



<p>There is also a special edge case for the HP 200LX, where the card can emulate an “Accurite Doubleslot” device, allowing an emulated flash card to coexist with networking or sound functionality. This is particularly important on systems with only a single PCMCIA slot, where storage availability is at a premium.</p>



<h2>USB</h2>



<p>The USB port for the RP2354 is made available on the external connector.   It’s primary purpose is to be used for  flashing the card with firmware, however as demonstrated on the PicoGUS and PicoMEM, it can use used for USB Gamdpads and USB Mice which are presented the the host system  as legacy gamepad and serial mouse.  It has also been demonstrated the latest update to the PicoGUS that accessing flash storage at a reasonable speed is possible via USB.</p>
	</div><!-- .entry-content -->

	</article><!-- #post-1017 -->

		</main><!-- #main -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[JPEG XL Test Page (195 pts)]]></title>
            <link>https://tildeweb.nl/~michiel/jxl/</link>
            <guid>46708032</guid>
            <pubDate>Wed, 21 Jan 2026 16:38:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tildeweb.nl/~michiel/jxl/">https://tildeweb.nl/~michiel/jxl/</a>, See on <a href="https://news.ycombinator.com/item?id=46708032">Hacker News</a></p>
<div id="readability-page-1" class="page">
  
  <p>This page shows a JPEG XL image, if your browser can handle it! At this
  point in time (January 2026) this means only Safari will display the image,
  as far as I know. See also <a href="https://caniuse.com/jpegxl" target="_blank">Can I Use</a></p>
  <p><img src="https://tildeweb.nl/~michiel/jxl/jpegxlman.jxl" alt="jxlman">
  </p>
  <p>The person in the image is <a href="https://sneyers.info/" target="_blank">Jon Sneyers</a>, co-author of the JPEG XL spec and also creator of the "Free Lossless Image Format" that came before it.</p>



</div>]]></description>
        </item>
    </channel>
</rss>