<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 12 Sep 2023 19:00:09 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[iPhone 15 and iPhone 15 Plus (142 pts)]]></title>
            <link>https://www.apple.com/newsroom/2023/09/apple-debuts-iphone-15-and-iphone-15-plus/</link>
            <guid>37485290</guid>
            <pubDate>Tue, 12 Sep 2023 18:23:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.apple.com/newsroom/2023/09/apple-debuts-iphone-15-and-iphone-15-plus/">https://www.apple.com/newsroom/2023/09/apple-debuts-iphone-15-and-iphone-15-plus/</a>, See on <a href="https://news.ycombinator.com/item?id=37485290">Hacker News</a></p>
<div id="readability-page-1" class="page">


	
    







 
<nav id="ac-localnav" lang="en-US" role="navigation" aria-label="Newsroom" data-analytics-region="local nav" data-sticky="">
	
    
    
        




    
    

</nav>



<main id="main" role="main"> 



<span id="opens-in-new-window">opens in new window</span>

	

<section>
<article data-analytics-activitymap-region-id="article">






    
    
    











    <div>
        

        <div>
                    
                    
                        <span>PRESS RELEASE</span>
                    
                    
                        <span>September 12, 2023</span>
                    
                    
                </div>

        <div>
                
                
                
                    <h2>
                        
    
        Apple debuts iPhone&nbsp;15 and iPhone&nbsp;15&nbsp;Plus
    

                    </h2>
                
            </div>

        <div>
                
                
                    A huge leap forward for iPhone with a gorgeous new design featuring a durable, color-infused back glass and new contoured edge; the Dynamic Island; a 48MP Main camera with 2x Telephoto; and USB‑C
                
            </div>

        
            
    
    
    
    
    

        

    </div>







    
    
    


    
        
        
        
        
            <figure aria-label="Media, iPhone 15 Plus in black is shown from the back next to iPhone 15 in pink, which is shown from the front.">
                <div>
                         
                            
                            <div>
                                iPhone 15 and iPhone 15 Plus feature a gorgeous new and durable design, the Dynamic Island, a powerful 48MP Main camera, and A16 Bionic.
                            </div>
                        
                        
                        
                        
                        <a href="https://www.apple.com/newsroom/images/2023/09/apple-debuts-iphone-15-and-iphone-15-plus/article/Apple-iPhone-15-lineup-hero-230912.zip" download="" data-analytics-title="Download image" aria-label="Download media, iPhone 15 Plus in black is shown from the back next to iPhone 15 in pink, which is shown from the front."></a>
                    </div>
            </figure>
        
    










    
    
    


     
     
    
    
        <div>
             
                 <div><span>CUPERTINO, CALIFORNIA</span> Apple today announced <a href="https://www.apple.com/iphone-15/" target="_blank">iPhone 15</a> and iPhone 15 Plus, featuring an industry-first color-infused back glass with a stunning, textured matte finish, and a new contoured edge on the aluminum enclosure. Both models feature the Dynamic Island, and an advanced camera system designed to help users take fantastic photos of everyday moments in their lives. A powerful 48MP Main camera enables super-high-resolution photos and a new 2x Telephoto option to give users a total of three optical zoom levels — like having a third camera. The iPhone 15 lineup also introduces the next generation of portraits, making it easier to capture portraits with great detail and low-light performance. Building on Apple’s innovative satellite infrastructure, Roadside Assistance via satellite can connect users to AAA if they have car trouble while off the grid. With A16 Bionic for powerful, proven performance; a USB‑C connector; Precision Finding for Find My friends; and industry-leading durability features, iPhone 15 and iPhone 15 Plus represent a huge leap forward.
</div>
                 
             
                 <div>iPhone 15 and iPhone 15 Plus will be available in five stunning new colors: pink, yellow, green, blue, and black. Pre-orders begin Friday, September 15, with availability beginning Friday, September 22.&nbsp;
</div>
                 
             
                 <div>“iPhone 15 and iPhone 15 Plus represent a huge leap forward with exciting camera innovations that inspire creativity, the intuitive Dynamic Island, and features like Roadside Assistance via satellite that make a real difference in users’ lives,” said Kaiann Drance, Apple’s vice president of Worldwide iPhone Product Marketing. “We’re also pushing the power of computational photography to new levels this year with a 48MP Main camera featuring a new 24MP default for super-high-resolution photos, a new 2x Telephoto option, and next-generation portraits.”
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, A row of iPhone 15 devices show the lineup’s new colors: black, blue, green, yellow, and pink.">
        <div>
             
              
              <div>
                iPhone 15 and iPhone 15 Plus will be available in five stunning new colors: black, blue, green, yellow, and pink.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2023/09/apple-debuts-iphone-15-and-iphone-15-plus/article/Apple-iPhone-15-lineup-color-lineup-230912.zip" download="" data-analytics-title="Download image" aria-label="Download media, A row of iPhone 15 devices show the lineup’s new colors: black, blue, green, yellow, and pink."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>A Beautiful and Durable Design with an Advanced Display</strong>
</h2>
                 
             
                 <div>Available in 6.1-inch and 6.7-inch display sizes,<sup>1</sup> iPhone 15 and iPhone 15 Plus feature the Dynamic Island, an innovative way to interact with important alerts and Live Activities. The elegant experience fluidly expands and adapts so users can see the next direction in Maps; easily control music; and, with third-party app integrations, get real-time updates on food delivery, ride sharing, sports scores, travel plans, and more. The Super Retina XDR display is great for watching content, streaming Apple Fitness+ workouts, and playing games. Peak HDR brightness now reaches up to 1600 nits so HDR photos and videos look better than ever. And when it is sunny, peak outdoor<strong> </strong>brightness reaches up to 2000 nits — twice as bright as the previous generation.
</div>
                 
             
         </div>
 

    
    
    


    
    <div data-component-list="ScrollAnimationDefault AutoPlayVideo">
        <div>Both models feature the Dynamic Island, which fluidly expands and adapts to a user’s alerts and Live Activities, creating an intuitive experience that feels magical.</div>
        
            <a aria-label="Download video: Dynamic Island" data-analytics-title="Download video - Dynamic Island" download="" href="https://www.apple.com/newsroom/videos/iphone-15-dynamic-island-incoming-call/downloads/Apple-iPhone-15-lineup-Dynamic-Island-incoming-call-230912.zip">
            </a>
        
    </div>






    
    
    


     
     
    
    
        <div>Both models feature a sophisticated new look that’s built to last. For the first time in a smartphone, color is infused throughout the back glass, creating five beautiful colors. The back glass is strengthened with an optimized dual-ion exchange process before being polished with nanocrystalline particles and etched to create a luxurious, textured matte finish. A new contoured edge on the aerospace-grade aluminum enclosure feels even nicer in users’ hands, and the Ceramic Shield front cover continues to be tougher than any other smartphone glass. With a water- and dust-resistant design<sup>2</sup> and industry-leading durability features, iPhone lasts and holds its value longer than any other smartphone. Plus, the internal design provides powerful sustained performance, while improving ease and affordability of repairs.
</div>
 

    
    
    

    
    
    






  
    
    
    
    
      <figure aria-label="Media, iPhone 15 in blue is shown from the front and back.">
        <div>
             
              
              <div>
                iPhone 15 and iPhone 15 Plus introduce a new contoured edge and durable, color-infused back glass.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2023/09/apple-debuts-iphone-15-and-iphone-15-plus/article/Apple-iPhone-15-lineup-design-230912.zip" download="" data-analytics-title="Download image" aria-label="Download media, iPhone 15 in blue is shown from the front and back."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>A Powerful Camera to Capture Every Moment in Super-High Resolution</strong>
</h2>
                 
             
                 <div>The advanced camera system on iPhone 15 and iPhone 15 Plus helps users capture everyday moments and cherished memories. A 48MP Main camera shoots sharp photos and videos while capturing fine details, with a quad-pixel sensor and 100 percent Focus Pixels for fast autofocus. Using the power of computational photography, the Main camera gives users a new 24MP super-high-resolution default, offering incredible image quality at a practical file size ideal for storing and sharing. By intelligently integrating hardware and software, an additional 2x Telephoto option gives users three optical-quality zoom levels — 0.5x, 1x, 2x — for the first time on an iPhone dual-camera system.
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="camera-system">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-e050e6d6ae8c64044be8e986173bbda7" href="#gallery-e050e6d6ae8c64044be8e986173bbda7" data-ac-gallery-trigger="gallery-e050e6d6ae8c64044be8e986173bbda7"><span>A photo taken on iPhone 15 shows a mountain landscape.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-980f98e80875fb0e628e85a8d1b36b02" href="#gallery-980f98e80875fb0e628e85a8d1b36b02" data-ac-gallery-trigger="gallery-980f98e80875fb0e628e85a8d1b36b02"><span>A photo taken on iPhone 15 shows a person wearing a yellow scarf that stretches across the frame.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-784dfd5b06a24bbb2cc23fa19fc81689" href="#gallery-784dfd5b06a24bbb2cc23fa19fc81689" data-ac-gallery-trigger="gallery-784dfd5b06a24bbb2cc23fa19fc81689"><span>A photo taken on iPhone 15 shows a person smiling.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-ed5c8276a13440124e20240fd55fded7" href="#gallery-ed5c8276a13440124e20240fd55fded7" data-ac-gallery-trigger="gallery-ed5c8276a13440124e20240fd55fded7"><span>A portrait taken on iPhone 15 shows a dog sitting up with paws lifted.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-ea41d74b68fd65cc33becc85081f8392" href="#gallery-ea41d74b68fd65cc33becc85081f8392" data-ac-gallery-trigger="gallery-ea41d74b68fd65cc33becc85081f8392"><span>A portrait taken on iPhone 15 shows a person posing with their hand beneath their chin.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-99b37a9af06c81b0b218e0f5b1a682a0" href="#gallery-99b37a9af06c81b0b218e0f5b1a682a0" data-ac-gallery-trigger="gallery-99b37a9af06c81b0b218e0f5b1a682a0"><span>A portrait taken on iPhone 15 shows a person wearing a vibrant green shirt and standing in front of a pink and yellow background.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-45590faedbdf989fef12255a6f2947fc" href="#gallery-45590faedbdf989fef12255a6f2947fc" data-ac-gallery-trigger="gallery-45590faedbdf989fef12255a6f2947fc"><span>A picture taken in Night mode on iPhone 15 shows a person lying down. </span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-e050e6d6ae8c64044be8e986173bbda7" aria-labelledby="gallery-dotnav-e050e6d6ae8c64044be8e986173bbda7" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:landscape-48mp">
                                
                                <div>
                                    <div>A new 48MP Main camera takes stunning photos with incredible image quality and details.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2023/09/apple-debuts-iphone-15-and-iphone-15-plus/article/Apple-iPhone-15-48MP-01-230912.zip" download="" data-analytics-title="Download image" aria-label="Download media, A photo taken on iPhone 15 shows a mountain landscape."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-980f98e80875fb0e628e85a8d1b36b02" aria-labelledby="gallery-dotnav-980f98e80875fb0e628e85a8d1b36b02" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:ultra-wide">
                                
                                <div>
                                    <div>With the Ultra Wide camera, users can capture unique perspectives.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2023/09/apple-debuts-iphone-15-and-iphone-15-plus/article/Apple-iPhone-15-Ultra-Wide-230912.zip" download="" data-analytics-title="Download image" aria-label="Download media, A photo taken on iPhone 15 shows a person wearing a yellow scarf that stretches across the frame."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-784dfd5b06a24bbb2cc23fa19fc81689" aria-labelledby="gallery-dotnav-784dfd5b06a24bbb2cc23fa19fc81689" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:portrait-48mp">
                                
                                <div>
                                    <div>The powerful 48MP Main camera shoots sharp photos and videos while capturing fine details.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2023/09/apple-debuts-iphone-15-and-iphone-15-plus/article/Apple-iPhone-15-48MP-02-230912.zip" download="" data-analytics-title="Download image" aria-label="Download media, A photo taken on iPhone 15 shows a person smiling."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-ed5c8276a13440124e20240fd55fded7" aria-labelledby="gallery-dotnav-ed5c8276a13440124e20240fd55fded7" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:portrait-mode-01">
                                
                                <div>
                                    <div>With next-generation portraits, it’s even easier to get stunning portraits of friends, family, and pets — with zero shutter lag.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2023/09/apple-debuts-iphone-15-and-iphone-15-plus/article/Apple-iPhone-15-Portrait-mode-24MP-01-230912.zip" download="" data-analytics-title="Download image" aria-label="Download media, A portrait taken on iPhone 15 shows a dog sitting up with paws lifted."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-ea41d74b68fd65cc33becc85081f8392" aria-labelledby="gallery-dotnav-ea41d74b68fd65cc33becc85081f8392" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:portrait-mode-02">
                                
                                <div>
                                    <div>iPhone automatically captures depth information, so users can take portraits without having to switch to Portrait mode.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2023/09/apple-debuts-iphone-15-and-iphone-15-plus/article/Apple-iPhone-15-Portrait-mode-24MP-02-230912.zip" download="" data-analytics-title="Download image" aria-label="Download media, A portrait taken on iPhone 15 shows a person posing with their hand beneath their chin."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-99b37a9af06c81b0b218e0f5b1a682a0" aria-labelledby="gallery-dotnav-99b37a9af06c81b0b218e0f5b1a682a0" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:photo-mode">
                                
                                <div>
                                    <div>Portraits will have richer color, great low-light performance, and can be taken in super-high resolution.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2023/09/apple-debuts-iphone-15-and-iphone-15-plus/article/Apple-iPhone-15-Portrait-mode-24MP-03-230912.zip" download="" data-analytics-title="Download image" aria-label="Download media, A portrait taken on iPhone 15 shows a person wearing a vibrant green shirt and standing in front of a pink and yellow background."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-45590faedbdf989fef12255a6f2947fc" aria-labelledby="gallery-dotnav-45590faedbdf989fef12255a6f2947fc" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:night-mode">
                                
                                <div>
                                    <div>When it’s dark, Night mode gets better with sharper details and more vivid colors.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2023/09/apple-debuts-iphone-15-and-iphone-15-plus/article/Apple-iPhone-15-Night-mode-230912.zip" download="" data-analytics-title="Download image" aria-label="Download media, A picture taken in Night mode on iPhone 15 shows a person lying down. "></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>Next-generation portraits on iPhone 15 and iPhone 15 Plus feature sharper detail, more vivid colors, and improved low-light performance. For the first time, users can take portraits without having to switch to Portrait mode. When there’s a person, dog, or cat in the frame, or when a user taps to focus, iPhone automatically captures depth information, so users can turn photos into stunning portraits later in the Photos app on iPhone, iPad, or Mac. For greater creative control, users can also adjust the focus point after the photo has been taken. Shooting at night gets better with improvements to Night mode, including sharper details and more vivid colors. When lighting is bright or uneven, new Smart HDR captures subjects and the background with more true-to-life renderings of skin tones, while ensuring photos have brighter highlights, richer midtones, and deeper shadows when viewed in the Photos app. This advanced HDR rendering is also available to third-party apps, so images can look even better when shared online. These improvements benefit the 48MP Main camera, Ultra Wide camera, and TrueDepth front camera.
</div>
 

    
    
    


    
    <div data-component-list="ScrollAnimationDefault AutoPlayVideo">
        <div>iPhone 15 detects when there’s a person in the frame and captures rich depth information automatically — so users can turn it into a stunning portrait right away or later on in the Photos app.</div>
        
            <a aria-label="Download video: Portraits" data-analytics-title="Download video - Portraits" download="" href="https://www.apple.com/newsroom/videos/iphone-15-portrait-mode/downloads/Apple-iPhone-15-lineup-Portrait-mode-demo-230912.zip">
            </a>
        
    </div>






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>A16 Bionic: Proven, Powerful Performance</strong>
</h2>
                 
             
                 <div>The fast and efficient A16 Bionic chip brings proven performance to iPhone 15 and iPhone 15 Plus, powering the Dynamic Island, computational photography capabilities, and more. With two high-performance cores that use 20 percent less power and four high-efficiency cores, the 6-core CPU is faster than the previous generation and easily handles intensive tasks while delivering extraordinary battery life. The 5-core GPU has 50 percent more memory bandwidth for smooth graphics when streaming videos and playing games. A new 16-core Neural Engine is capable of nearly 17 trillion operations per second, enabling even faster machine learning computations for features like Live Voicemail transcriptions in iOS 17 and third-party app experiences — all while protecting critical privacy and security features using the Secure Enclave.&nbsp;
</div>
                 
             
         </div>
 

    
    
    


    
    <div data-component-list="ScrollAnimationDefault AutoPlayVideo">
        <div>A16 Bionic, with a 5-core GPU, enables smoother graphics when streaming videos and playing games — all while powering incredible computational photography capabilities and the Dynamic Island, with privacy built in.</div>
        
            <a aria-label="Download video: A16 Bionic" data-analytics-title="Download video - A16 Bionic" download="" href="https://www.apple.com/newsroom/videos/iphone-15-gaming/downloads/Apple-iPhone-15-lineup-gaming-230912.zip">
            </a>
        
    </div>






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Expanded Safety Capabilities for Peace of Mind</strong>
</h2>
                 
             
                 <div>The iPhone 15 lineup offers critical safety capabilities to provide assistance when it matters most, including Crash Detection<sup>3</sup> and Emergency SOS via satellite.<sup>4</sup> Currently available in 14 countries and regions on three continents, Emergency SOS via satellite has made a significant impact in users’ lives. This groundbreaking safety service will come to Spain and Switzerland later this month.
</div>
                 
             
                 <div>Building on this innovative satellite infrastructure, iPhone 15 and iPhone 15 Plus introduce Roadside Assistance via satellite. Beginning in the U.S., when a user has car trouble and cellular and Wi-Fi coverage are not available, they can now connect to AAA, the country’s largest roadside assistance provider.<sup>5</sup> An intuitive interface, including a short questionnaire to capture important details, will transmit the information via satellite so AAA can message with the user directly and dispatch help to their exact location. Access to Roadside Assistance via satellite will be included for free for two years. Service is covered according to AAA membership, but is also available separately for nonmembers.<sup>6</sup>
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="safety-capabilities">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-50a72d4626ddc145afcf663f144fb85b" href="#gallery-50a72d4626ddc145afcf663f144fb85b" data-ac-gallery-trigger="gallery-50a72d4626ddc145afcf663f144fb85b"><span>iPhone 15 shows the questionnaire for Roadside Assistance via satellite, including the question, “What do you need assistance with?”</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-f3edadab26b48ade36a9047a192f58c4" href="#gallery-f3edadab26b48ade36a9047a192f58c4" data-ac-gallery-trigger="gallery-f3edadab26b48ade36a9047a192f58c4"><span>iPhone 15 displays satellite information, with the message “Connecting… keep pointing at satellite” on the screen. </span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-fe59b4b503422aa65dbab0dff31da564" href="#gallery-fe59b4b503422aa65dbab0dff31da564" data-ac-gallery-trigger="gallery-fe59b4b503422aa65dbab0dff31da564"><span>iPhone 15 shows a call to 911 with the message “No connection. Try emergency text via satellite.”</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-51b3e8d0b764fa6240ff9c1b835c125b" href="#gallery-51b3e8d0b764fa6240ff9c1b835c125b" data-ac-gallery-trigger="gallery-51b3e8d0b764fa6240ff9c1b835c125b"><span>iPhone 15 shows the message “It looks like you’ve been in a crash. iPhone will trigger Emergency SOS if you don’t respond.”</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-50a72d4626ddc145afcf663f144fb85b" aria-labelledby="gallery-dotnav-50a72d4626ddc145afcf663f144fb85b" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:roadside-assistance-questionnaire">
                                
                                <div>
                                    <div>Roadside Assistance via satellite can connect users to AAA if they have car trouble while outside of cellular and Wi-Fi coverage.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2023/09/apple-debuts-iphone-15-and-iphone-15-plus/article/Apple-iPhone-15-lineup-Roadside-Assistance-questionnaire-230912.zip" download="" data-analytics-title="Download image" aria-label="Download media, iPhone 15 shows the questionnaire for Roadside Assistance via satellite, including the question, “What do you need assistance with?”"></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-f3edadab26b48ade36a9047a192f58c4" aria-labelledby="gallery-dotnav-f3edadab26b48ade36a9047a192f58c4" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:roadside-assistance-via-satellite">
                                
                                <div>
                                    <div>The intuitive interface guides the user where to point their iPhone to connect to a satellite.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2023/09/apple-debuts-iphone-15-and-iphone-15-plus/article/Apple-iPhone-15-lineup-Roadside-Assistance-via-satellite-230912.zip" download="" data-analytics-title="Download image" aria-label="Download media, iPhone 15 displays satellite information, with the message “Connecting… keep pointing at satellite” on the screen. "></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-fe59b4b503422aa65dbab0dff31da564" aria-labelledby="gallery-dotnav-fe59b4b503422aa65dbab0dff31da564" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:emergency-sos">
                                
                                <div>
                                    <div>In emergency situations, Apple’s groundbreaking safety service Emergency SOS via satellite enables users to connect with first responders while off the grid.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2023/09/apple-debuts-iphone-15-and-iphone-15-plus/article/Apple-iPhone-15-lineup-Emergency-SOS-230912.zip" download="" data-analytics-title="Download image" aria-label="Download media, iPhone 15 shows a call to 911 with the message “No connection. Try emergency text via satellite.”"></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-51b3e8d0b764fa6240ff9c1b835c125b" aria-labelledby="gallery-dotnav-51b3e8d0b764fa6240ff9c1b835c125b" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:crash-detection">
                                
                                <div>
                                    <div>Crash Detection uses advanced sensors paired with Apple-designed algorithms to detect a severe car crash and automatically dial emergency services when a user is unconscious or unable to reach their iPhone.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2023/09/apple-debuts-iphone-15-and-iphone-15-plus/article/Apple-iPhone-15-lineup-Crash-Detection-230912.zip" download="" data-analytics-title="Download image" aria-label="Download media, iPhone 15 shows the message “It looks like you’ve been in a crash. iPhone will trigger Emergency SOS if you don’t respond.”"></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Powerful Connection Capabilities</strong>
</h2>
                 
             
                 <div>The iPhone 15 lineup offers convenient new ways to charge, find friends in busy places, and stay connected while traveling. Both models use a USB‑C connector, a universally accepted standard for charging and transferring data, allowing the same cable to charge iPhone, Mac, iPad, and the updated AirPods Pro (2nd generation). Users can also charge AirPods or Apple Watch directly from iPhone with the USB‑C connector.<sup>7</sup> Both models support MagSafe and future Qi2 chargers for wireless charging.
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, iPhone 15 is shown next to AirPods Pro (2nd generation).">
        <div>
             
              
              <div>
                iPhone 15 users can charge the updated AirPods Pro (2nd generation) or Apple Watch right from their iPhone with the new USB-C connector.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2023/09/apple-debuts-iphone-15-and-iphone-15-plus/article/Apple-iPhone-15-lineup-AirPods-Pro-2nd-gusB-C-connection-230912.zip" download="" data-analytics-title="Download image" aria-label="Download media, iPhone 15 is shown next to AirPods Pro (2nd generation)."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>Both models feature the second-generation Ultra Wideband chip, enabling two iPhone devices with this chip to connect at three times the range as before. This opens up a new way to use Precision Finding for Find My friends, so iPhone 15 users can share their location and find each other, even in crowds. Precision Finding is built with the same privacy protections that users have come to trust in Find My.<sup>8</sup>
</div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, Three iPhone 15 devices demonstrate Find My friends, including a screen with a map view, a screen that points in the direction of the friend, and a screen with a green check mark to show that the user has arrived in the right place.">
        <div>
             
              
              <div>
                With Precision Finding for Find My friends, iPhone 15 users can share their location and find each other, even in a crowded place.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2023/09/apple-debuts-iphone-15-and-iphone-15-plus/article/Apple-iPhone-15-lineup-Precision-Finding-3-up-230912.zip" download="" data-analytics-title="Download image" aria-label="Download media, Three iPhone 15 devices demonstrate Find My friends, including a screen with a map view, a screen that points in the direction of the friend, and a screen with a green check mark to show that the user has arrived in the right place."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <div>iPhone 15 models continue to deliver a high-quality, superfast 5G experience<sup>9</sup> and improved audio quality on phone calls, including those made on FaceTime or third-party apps. Sound quality gets even better when users select Voice Isolation to come through loud and clear, even if they are somewhere noisy.&nbsp;
</div>
                 
             
                 <div>iPhone 15 and iPhone 15 Plus have eSIM, a more convenient and secure alternative to a physical SIM card, with support from more than 295 carriers. When traveling the world, users can stay connected through affordable international roaming plans from their existing carrier, or purchase prepaid eSIM plans in over 50 countries and regions, including Australia, Italy, Thailand, and more.
</div>
                 
             
                 <h2><strong>Featuring iOS 17</strong>
</h2>
                 
             
                 <div>iPhone 15 and iPhone 15 Plus feature iOS 17,<sup>10 </sup>making iPhone even more personal and intuitive with new capabilities:
</div>
                 
             
                 <div><ul>
<li>The <strong>Phone app</strong> gets major updates with <strong>Contact Posters</strong>, which allows users to customize how they appear to their contacts, and <strong>Live Voicemail</strong>, which leverages the power of A16 Bionic to see real-time on-device transcription as someone leaves a voicemail. Users can even pick up the call while the caller is leaving their message.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li><strong>Messages</strong> gets a new stickers experience, more powerful search, transcription of audio messages, and <strong>Check In</strong>, which allows users to automatically notify friends and family when they have made it to their destination safely.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li><strong>NameDrop</strong> gives users a new way to use AirDrop to more easily share contact information by simply bringing two iPhone devices together. The same gesture can be used to AirDrop content and more.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li><strong>StandBy</strong> gives users a customizable full-screen experience with glanceable information designed to be viewed from a distance when iPhone is on its side and charging. With support for Live Activities, Siri, incoming calls, and larger notifications, StandBy is perfect for a nightstand, kitchen counter, or desk.</li>
</ul>
</div>
                 
             
                 <div>iOS 17 delivers many more updates, including Journal,<sup>11</sup> a new app that helps iPhone users reflect and practice gratitude through journaling; improvements to autocorrect and Dictation; greater protection for Private Browsing in Safari; password and passkey sharing with iCloud Keychain; pet recognition in Photos; and much more.&nbsp;
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="ios-17">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-9a4fc8233360718344b5a88b3c98cae7" href="#gallery-9a4fc8233360718344b5a88b3c98cae7" data-ac-gallery-trigger="gallery-9a4fc8233360718344b5a88b3c98cae7"><span>iPhone 15 displays a person’s photo with an incoming call.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-ca7404fe8b74d66aabdfafa099c2491b" href="#gallery-ca7404fe8b74d66aabdfafa099c2491b" data-ac-gallery-trigger="gallery-ca7404fe8b74d66aabdfafa099c2491b"><span>iPhone 15 shows a text message exchange with a menu of emoji stickers and Live Stickers.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-92728a9c2e5f7d1b3182758637cdfb60" href="#gallery-92728a9c2e5f7d1b3182758637cdfb60" data-ac-gallery-trigger="gallery-92728a9c2e5f7d1b3182758637cdfb60"><span>iPhone 15 shows a person’s photo with the message “Share Your Contact.”</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-9a4fc8233360718344b5a88b3c98cae7" aria-labelledby="gallery-dotnav-9a4fc8233360718344b5a88b3c98cae7" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:contact-posters">
                                
                                <div>
                                    <div>Contact Posters in iOS 17 provides users with a new way to express themselves and bring a completely new look to incoming calls.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2023/09/apple-debuts-iphone-15-and-iphone-15-plus/article/Apple-iPhone-15-lineup-Contact-Posters-230912.zip" download="" data-analytics-title="Download image" aria-label="Download media, iPhone 15 displays a person’s photo with an incoming call."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-ca7404fe8b74d66aabdfafa099c2491b" aria-labelledby="gallery-dotnav-ca7404fe8b74d66aabdfafa099c2491b" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:stickers-experience">
                                
                                <div>
                                    <div>An all-new stickers experience in iOS 17 introduces emoji stickers and adds the ability to create Live Stickers by lifting subjects from photos.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2023/09/apple-debuts-iphone-15-and-iphone-15-plus/article/Apple-iPhone-15-lineup-Live-Stickers-230912.zip" download="" data-analytics-title="Download image" aria-label="Download media, iPhone 15 shows a text message exchange with a menu of emoji stickers and Live Stickers."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-92728a9c2e5f7d1b3182758637cdfb60" aria-labelledby="gallery-dotnav-92728a9c2e5f7d1b3182758637cdfb60" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:namedrop">
                                
                                <div>
                                    <div>NameDrop, a new AirDrop feature in iOS 17, allows users to easily share contact information by simply bringing their iPhone devices together.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2023/09/apple-debuts-iphone-15-and-iphone-15-plus/article/Apple-iPhone-15-lineup-NameDrop-230912.zip" download="" data-analytics-title="Download image" aria-label="Download media, iPhone 15 shows a person’s photo with the message “Share Your Contact.”"></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Better for the Environment</strong>
</h2>
                 
             
                 <div>iPhone 15 and iPhone 15 Plus are designed with the environment in mind. As Apple continues to work toward its 2030 goal of making every product carbon neutral — from design to manufacturing to customer use — the company is prioritizing clean electricity across the entire supply chain and designing products with recycled and other low-carbon materials. iPhone 15 and iPhone 15 Plus now use even more recycled content, with 100 percent recycled cobalt in the battery and 100 percent recycled copper in the main logic board, copper wire in the Taptic Engine, and copper foil in the inductive charger in MagSafe — all firsts for iPhone. Both models also include 75 percent recycled aluminum in the enclosure, 100 percent recycled rare earth elements in all magnets, and 100 percent recycled gold in the USB‑C connector as well as the gold plating and tin soldering in multiple printed circuit boards. The iPhone 15 lineup meets Apple’s high standards for energy efficiency and is free of mercury, PVC, and beryllium. Over 99 percent of the packaging is fiber-based, bringing Apple closer to its goal of completely removing plastic from its packaging by 2025.
</div>
                 
             
                 <div>To further reduce impact on the planet, Apple will no longer use leather in any new Apple products, including iPhone accessories. Apple is introducing a new FineWoven Case with MagSafe and FineWoven Wallet with MagSafe, made from a durable and elegant microtwill with a soft, suedelike feel. The material is made from 68 percent post-consumer recycled content and has significantly lower carbon emissions compared to leather.
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, Three iPhone 15 devices are shown in cases made of FineWoven material. Two cases have pockets on the back. ">
        <div>
             
              
              <div>
                New FineWoven accessories for iPhone are made from a luxurious and durable microtwill. This FineWoven material is made of 68 percent post-consumer recycled content and has significantly lower emissions compared to leather.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2023/09/apple-debuts-iphone-15-and-iphone-15-plus/article/Apple-iPhone-15-lineup-FineWoven-3-up-230912.zip" download="" data-analytics-title="Download image" aria-label="Download media, Three iPhone 15 devices are shown in cases made of FineWoven material. Two cases have pockets on the back. "></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 
                 
             
                 <div><ul>
<li>iPhone 15 and iPhone 15 Plus will be available in pink, yellow, green, blue, and black in 128GB, 256GB, and 512GB storage capacities, starting at <strong>$799</strong> (U.S.) or <strong>$33.29</strong> (U.S.) per month, and <strong>$899 </strong>(U.S.) or <strong>$37.45</strong> (U.S.) per month, respectively.<sup>12</sup></li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Apple offers great ways to save and upgrade to the latest iPhone. Customers in the U.S. can get <strong>$200-$650</strong> (U.S.) in credit when they trade in iPhone 11 or later and upgrade to iPhone 15 or iPhone 15 Plus by visiting the <a href="https://www.apple.com/store/" target="_blank">Apple Store Online</a>, or at an Apple Store location. To see what their device is worth and for terms and conditions, customers can visit <a href="https://www.apple.com/shop/trade-in/" target="_blank">apple.com/shop/trade-in</a>.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Customers can get iPhone 15 for as low as <strong>$0</strong> (U.S.) per month when they trade in an iPhone 11 or later with select U.S. carriers. For eligibility requirements and more details, see&nbsp;<a href="https://www.apple.com/shop/buy-iphone/carrier-offers/" target="_blank">apple.com/shop/buy-iphone/carrier-offers</a>.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Customers in more than 40 countries and regions, including <em>Australia</em>, <em>Canada</em>, <em>China</em>, <em>France</em>, <em>Germany</em>, <em>India</em>, <em>Japan</em>, <em>Mexico</em>, the <em>UAE</em>, the <em>U.K.</em>, and the <em>U.S.</em>, will be able to pre-order iPhone 15 and iPhone 15 Plus beginning at 5 a.m. PDT this Friday, September 15, with availability beginning Friday, September 22.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>iPhone 15 and iPhone 15 Plus will be available in <em>Macao, Malaysia</em>, <em>Türkiye</em>, <em>Vietnam</em>, and 17 other countries and regions beginning Friday, September 29.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>FineWoven Wallet with MagSafe and FineWoven Case with MagSafe will both be available for <strong>$59</strong> (U.S.) in five new colors for the iPhone 15 lineup: black, taupe, mulberry, pacific blue, and evergreen. In addition to an iPhone 15 and iPhone 15 Plus Clear Case, available for <strong>$49</strong> (U.S.), a Silicone Case with MagSafe will be available for <strong>$49</strong> (U.S.) in black, storm blue, clay, light pink, guava, orange sorbet, cypress, and winter blue.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>iOS 17 will be available as a free software update on Monday, September 18.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Available starting on September 18, iCloud+ will offer two new plans: 6TB for <strong>$29.99</strong> (U.S.) per month and 12TB for <strong>$59.99 </strong>(U.S.) per month, providing additional storage to keep files, photos, videos, and more safe, accessible, and easy to share. The new plans are great for users with large photo and video libraries or those using Family Sharing, and will provide access to premium features, including Private Relay, Hide My Email, Custom Email Domains, and HomeKit Secure Video support.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Customers who purchase iPhone 15 and iPhone 15 Plus will receive three free months of Apple Arcade and Apple Fitness+ with a new subscription.</li>
</ul>
</div>
                 
             
         </div>
 

    
    
    




    
    
        
    


    
    
    



    
    
    




    




    
    
    





    
    
    <div>
            <ol>
<li>The display has rounded corners that follow a beautiful curved design, and these corners are within a standard rectangle. When measured as a standard rectangular shape, the screen is 6.06 inches (iPhone&nbsp;15) or 6.68 inches (iPhone&nbsp;15&nbsp;Plus) diagonally. The actual viewable area is smaller.</li>
<li>iPhone 15 and iPhone 15 Plus are splash-, water-, and dust-resistant. They were tested under controlled laboratory conditions, and have a rating of IP68 under IEC standard 60529 (maximum depth of 6 meters for up to 30 minutes). Splash, water, and dust resistance are not permanent conditions. Resistance might decrease as a result of normal wear. Do not attempt to charge a wet iPhone; refer to the user guide for cleaning and drying instructions. Liquid damage is not covered under warranty.</li>
<li>Crash Detection is designed for four-wheel passenger vehicle crashes with certain mass, G-force, and speed profiles consistent with severe, life-threatening crashes. It was designed for severe, life-threatening, high-impact front and rear collisions, sideswipe, T-bone, and rollover crashes. Crash Detection is available worldwide on iPhone 15, iPhone 15 Plus, iPhone 15 Pro, iPhone 15 Pro Max, iPhone 14, iPhone 14 Plus, iPhone 14 Pro, iPhone 14 Pro Max, Apple Watch Series 9, Apple Watch Ultra 2, Apple Watch Series 8, Apple Watch Ultra, and Apple Watch SE (2nd generation).</li>
<li>Emergency SOS via satellite and Find My via satellite are currently available in 14 countries and regions, including <em>Australia</em>, <em>Austria</em>, <em>Belgium</em>, <em>Canada</em>, <em>France</em>, <em>Germany</em>, <em>Ireland</em>, <em>Italy</em>, <em>Luxembourg</em>,&nbsp;the <em>Netherlands</em>, <em>New Zealand</em>, <em>Portugal</em>, the <em>U.K.</em>, and the <em>U.S.,</em> and will be available in <em>Spain</em> and <em>Switzerland</em> later this month.</li>
<li><span>Emergency SOS via satellite and Roadside Assistance via satellite were designed for use in open spaces with a clear line of sight to the sky. Performance may be impacted by obstructions such as trees or surrounding buildings.</span></li>
<li><span>Roadside Assistance via satellite is launching in the U.S.</span><em> </em><span>with AAA and is included for free for two years starting at the time of activation of a new iPhone 15, iPhone 15 Plus, iPhone 15 Pro, iPhone 15 Pro Max, iPhone 14, iPhone 14 Plus, iPhone 14 Pro, or iPhone 14 Pro Max. This satellite service requires iOS 17. AAA may charge for roadside assistance services. iPhone 15 and iPhone 14 users who are not AAA members can take advantage of Roadside Assistance via satellite on a pay-per-use basis for AAA’s roadside assistance services.</span><br>
</li>
<li>iPhone 15 supports 4K at 60 fps HDR video output using a USB‑C Digital AV Multiport Adapter to allow users to connect to an HDMI display, while also connecting a standard USB device and a USB‑C charging cable.<br>
</li>
<li><span>Precision Finding for Find My friends requires <a href="https://support.apple.com/en-us/HT212274/" target="_blank" rel="nofollow" data-analytics-exit-link="">Ultra Wideband</a> and isn't available in all countries or regions. With iOS 17, Precision Finding will be available to Apple Watch Series 9 and Apple Watch Ultra 2 users to help them locate their iPhone 15, iPhone 15 Plus, iPhone 15 Pro, or iPhone 15 Pro Max. Later this fall, iPhone 15 users will be able to use Precision Finding for Find My friends to locate friends and family wearing Apple Watch Series 9 and Apple Watch Ultra 2.</span></li>
<li><span>A data plan is required. 5G, Gigabit LTE, VoLTE, and Wi-Fi calling are available in select markets and through select carriers. Speeds are based on theoretical throughput and vary based on site conditions and carrier. For details on 5G and LTE support, customers can contact their carrier or visit </span><a href="https://www.apple.com/iphone/cellular/" target="_blank">apple.com/iphone/cellular</a><span>.</span><br>
</li>
<li>Some features may not be available for all countries or all areas. View a complete list at <a href="https://www.apple.com/ios/feature-availability/" target="_blank">apple.com/ios/feature-availability</a>.</li>
<li>Journal is coming in a software update later this year.</li>
<li>Pricing for iPhone 15 and iPhone 15 Plus includes a $30 connectivity discount that requires activation with AT&amp;T, T‑Mobile, or Verizon. Available to qualified customers and requires 24-month installment loan when they select Citizens One or Apple Card Monthly Installments (ACMI) as payment type at checkout at Apple. Customers need to select AT&amp;T, T‑Mobile, or Verizon as their carrier when they check out. An iPhone purchased with ACMI is always unlocked, so customers can switch carriers at any time. Subject to credit approval and credit limit. Taxes and shipping are not included in ACMI and are subject to their card’s variable APR. Additional Apple Card Monthly Installments terms are in the <a href="https://www.goldmansachs.com/terms-and-conditions/Apple-Card-Customer-Agreement.pdf" target="_blank" rel="nofollow" data-analytics-exit-link="">Apple Card Customer Agreement</a>. Additional iPhone Payments terms are <a href="https://www.apple.com/legal/sales-support/iphoneinstallments_us/" target="_blank">here</a>. ACMI is not available for purchases made online at special storefronts. The last month’s payment for each product will be the product’s purchase price, less all other payments at the monthly payment amount. ACMI financing is subject to change at any time for any reason, including but not limited to installment term lengths and eligible products. See <a href="https://support.apple.com/en-us/HT211204/" target="_blank" rel="nofollow" data-analytics-exit-link="">support.apple.com/kb/HT211204</a> for information about upcoming changes to ACMI financing.</li>
</ol>

        </div>



    
    
    






    
















	
	
	
		















	
	

</article>



</section>
</main>


	

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Fine-tune your own Llama 2 to replace GPT-3.5/4 (180 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=37484135</link>
            <guid>37484135</guid>
            <pubDate>Tue, 12 Sep 2023 16:53:51 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=37484135">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="37484135">
      <td><span></span></td>      <td><center><a id="up_37484135" href="https://news.ycombinator.com/vote?id=37484135&amp;how=up&amp;goto=item%3Fid%3D37484135"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=37484135">Fine-tune your own Llama 2 to replace GPT-3.5/4</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_37484135">182 points</span> by <a href="https://news.ycombinator.com/user?id=kcorbitt">kcorbitt</a> <span title="2023-09-12T16:53:51"><a href="https://news.ycombinator.com/item?id=37484135">2 hours ago</a></span> <span id="unv_37484135"></span> | <a href="https://news.ycombinator.com/hide?id=37484135&amp;goto=item%3Fid%3D37484135">hide</a> | <a href="https://hn.algolia.com/?query=Fine-tune%20your%20own%20Llama%202%20to%20replace%20GPT-3.5%2F4&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=37484135&amp;auth=785780757f882461cfb5cfe0b8ea0a6759660ad0">favorite</a> | <a href="https://news.ycombinator.com/item?id=37484135">33&nbsp;comments</a>        </span>
              </td></tr>
    <tr></tr><tr><td colspan="2"></td><td><div><p>There has been a lot of interest on HN in fine-tuning open-source LLMs recently (eg. Anyscale's post at <a href="https://news.ycombinator.com/item?id=37090632">https://news.ycombinator.com/item?id=37090632</a>). I've been playing around with fine-tuning models for a couple of years, and wanted to share some insights and practical code. I’ve condensed what I’ve learned into a small set of notebooks at <a href="https://github.com/OpenPipe/OpenPipe/tree/main/examples/classify-recipes">https://github.com/OpenPipe/OpenPipe/tree/main/examples/clas...</a>, covering labeling data, fine-tuning, running efficient inference, and evaluating costs/performance. The 7B model we train here matches GPT-4’s labels 95% of the time on the test set, and for the 5% of cases where they disagree it’s often because the correct answer is genuinely ambiguous.</p><p>What is fine-tuning? You can think of it as a more-powerful form of prompting, where instead of writing your instructions in text you actually encode them in the weights of the model itself. You do this by training an existing model on example input/output pairs that demonstrate the task you want your fine-tuned model to learn. Fine-tuning can work with as few as 50 examples but I usually try to get 1000+ if possible.</p><p>Prompting still has some big advantages over fine-tuning. It's way easier/faster to iterate on your instructions than label data and re-train a model. And operationally it's easier to deploy one big model and just adjust its behavior as necessary vs deploying many small fine-tuned models that will likely each get lower utilization.</p><p>Fine-tuning has one huge advantage though: it is far more effective at guiding a model's behavior than prompting, so you can often get away with a <i>much</i> smaller model. That gets you faster responses and lower inference costs. A fine-tuned Llama 7B model is 50x cheaper than GPT-3.5 on a per-token basis, and for many use cases can produce results that are as good or better!</p><p>For example, classifying the 2M recipes at <a href="https://huggingface.co/datasets/corbt/all-recipes" rel="nofollow noreferrer">https://huggingface.co/datasets/corbt/all-recipes</a> with GPT-4 would cost $23k. Even with GPT-3.5 it would cost over $1k. The model we fine-tuned performs similarly to GPT-4 and costs just $19 to run over the entire dataset.</p><p>Disclaimer: My brother David and I are working on an open-source product called OpenPipe (<a href="https://github.com/openpipe/openpipe">https://github.com/openpipe/openpipe</a>) to help engineers adopt fine-tuning as simply as possible. But none of the information above depends on our startup. The current post is just about sharing information that we’ve learned about fine-tuning. I hope it’s useful!</p></div></td></tr>        <tr></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New world record with an electric racing car: From 0 to 100 in 0.956 seconds (165 pts)]]></title>
            <link>https://ethz.ch/en/news-and-events/eth-news/news/2023/09/from-zero-to-one-hundred-in-0-956-seconds.html</link>
            <guid>37482517</guid>
            <pubDate>Tue, 12 Sep 2023 15:14:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ethz.ch/en/news-and-events/eth-news/news/2023/09/from-zero-to-one-hundred-in-0-956-seconds.html">https://ethz.ch/en/news-and-events/eth-news/news/2023/09/from-zero-to-one-hundred-in-0-956-seconds.html</a>, See on <a href="https://news.ycombinator.com/item?id=37482517">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="content">
                
                    
    
    <!-- Panorama header -->
    
        <picture>
          <img alt="The hand-built electric racing car &quot;mythen&quot;" title="" src="https://ethz.ch/en/news-and-events/eth-news/news/2023/09/from-zero-to-one-hundred-in-0-956-seconds/_jcr_content/par/lead/imagePanorama.imageformat.carousel.865608672.jpg">
    
        </picture>
    

    <!-- Blog header -->
    
    <!-- Tags when not blog -->
    
        
    
    
    

    <!-- Articleheader -->
    <div>
    <p>
            Students from ETH Zurich and Lucerne University of Applied Sciences and Arts have broken the previous world record for acceleration with their hand-built electric racing car, mythen. The vehicle accelerated from zero to 100 km/h in 0.956 seconds over a distance of 12.3 metres.
        </p>
    

</div>

    <!-- Nav & News images -->
    

    <!-- Details -->
    <div>
        <p><span>
            <time datetime="2023-09-12T00:00:00Z">12.09.2023</time>
            
            
            
                <br>
                <span>(Photograph: Alessandro Della Bella / ETH Zürich)</span>
            
        </span></p><ul>
            <li>
                <a id="newsCommentsLink" href="#comment-system">
                    
                    <span>Number of comments</span>
                </a>
            </li>
            <!-- Socialsharing (configurable) -->
            
    
        
            
                <li>
            
            
            
                </li>
            
        
        
    

        </ul>
    </div>

    <!-- ArticleLeadImage -->
    

    <!-- Parsys 1 --> 
    <div>

<div>
            <p>The members of the Academic Motorsports Club Zurich (AMZ) are absolutely thrilled. For the better part of a year, these students from ETH Zurich and the Lucerne University of Applied Sciences and Arts have spent every spare minute working on their electric vehicle, which they named <i>mythen</i>, overcoming setbacks and going back to the drawing board time and time again for certain components. Now, Guinness World Records has confirmed that <i>mythen</i> broke the previous world acceleration record for electric vehicles. On the <span>Switzerland Innovation Park</span> in Duebendorf, Switzerland, directly opposite the students’ workshop, their racing car accelerated from zero to 100 km/h (zero to 62.15 mph) in just 0.956 seconds, accomplishing this feat over a distance of merely 12.3 metres. At the wheel was Kate Maggetti. This beats the previous world record of 1.461 seconds, set in September 2022 by a team from the University of Stuttgart by more than a third.</p>
        </div>
<div>
            <figure>
            <div>
                <a onclick="javascript:ETHZ_Design.Video.showOverlay(event, this);" onkeypress="javascript:ETHZ_Design.Video.showOverlay(event, this);" tabindex="0" aria-label="YouTube video -  Agree to privacy policy to play video.">
                    <div>
                        <p><img src="https://ethz.ch/bin/ethz/components/previewImage/youtube/mvoFemftA34.jpg"></p>
                        </div>
                    
                </a>
                <p>
                    By playing the video you accept the privacy policy of YouTube.<a href="https://policies.google.com/privacy?gl=CH&amp;hl=en">Learn more</a>
                    <a onclick="javascript:ETHZ_Design.Video.loadIframe(event, this, 'youtube');" onkeypress="javascript:ETHZ_Design.Video.loadIframe(event, this, 'youtube');" tabindex="0" role="button">OK</a>
                </p>
            </div>
            <figcaption>(Video: ETH Zurich / JG VIDEO GmbH)</figcaption>
                </figure>
            </div>
<div>
                
                
                <p>“Working on the project in addition to my studies was very intense. But even so, it was a lot of fun working with other students to continually produce new solutions and put into practice what we learned in class. And, of course, it is an absolutely unique experience to be involved in a world record,” says Yann Bernard, head of motor at AMZ.</p> 
<h2><b>Lighter, stronger, more traction</b></h2> 
<p>All of <i>mythen’s</i> components, from the printed circuit boards (PCBs) to the chassis and the battery, were developed by the students themselves and optimised for their function. Thanks to the use of lightweight carbon and aluminium honeycomb, the race car weighs in at only around 140 kilos (309 pounds). Four-wheel hub motors that the students developed themselves and a special powertrain give the vehicle its impressive power of 240 kilowatts, or around 326 hp. <br> </p>
            </div>
<div><h2>Photo gallery from the race track</h2>
        

    </div>
<div>
                
                
                <p>“But power isn’t the only thing that matters when it comes to setting an acceleration record – effectively transferring that power to the ground is also key,” says Dario Messerli, head of aerodynamics at AMZ. Conventional Formula One cars solve this through aerodynamics: a rear or front wing pushes the car to the ground. However, this effect only comes into play when the car has reached a certain speed. To ensure strong traction right from the start, the AMZ team has developed a kind of vacuum cleaner that holds the vehicle down to the ground by suction. </p> 
<h2><b>Hotly contested world record</b></h2> 
<p>The AMZ team had set the world acceleration record for electric cars twice before – in 2014 and again in 2016. In the following years, their record was broken by a team from the University of Stuttgart. Now the world record is back in Swiss hands, and the ETH Zurich students are confident they will not relinquish it again any time soon. </p>
            </div>
<div>
                
                	<h2>About the Academic Motorsports Club Zurich (AMZ)</h2>
                
                
                <p><span>AMZ was founded by ETH Zurich students in 2006. Since then, its 30, or so, members have developed a new race car each year, which they have entered into various international design competitions – known as Formula Student in Europe. After initially developing three vehicles powered by an internal-combustion engine, since 2010 AMZ has been building purely electrically powered race cars. The club offers students the opportunity to put their acquired theoretical knowledge into practice in an extraordinarily complex, technical environment. AMZ is financially independent and is supported by numerous sponsors as well as various Swiss universities.</span><span></span></p>
            </div>
<div>
            <p>
                
                	<h2>Contact</h2>
                
                
                
            </p>
        </div>



</div>
    <!-- Socialsharing (display only) -->
    
    
        
            
            
            
        
        
    


    <!-- Parsys 2 -->
    
    <!-- Taglist -->
    
        
            
        
    

    <!-- Comments -->
    
    	
    



	    
    

                
                
            </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Why does Google rank the real Python documentation below content farms? (150 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=37482216</link>
            <guid>37482216</guid>
            <pubDate>Tue, 12 Sep 2023 14:53:16 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=37482216">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="37482741"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37482741" href="https://news.ycombinator.com/vote?id=37482741&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><br><div>
                  <p><span>Google search is now practically shit. Instead of adapting it's rank so it links to high-quality content, it forces sites to adapt to its ranking model so they have to produce meaningless crap.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37482828"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37482828" href="https://news.ycombinator.com/vote?id=37482828&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><br><div>
                  <p><span>I don't think word count is a new metric. It's just that documentation wasn't much of an ad revenue market in the past. Link juice also flows for backlinks. These sites definitely get heavily linked by blog spam.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37482951"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37482951" href="https://news.ycombinator.com/vote?id=37482951&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><br><div>
                  <p><span>While I believe this is still a bad metric, I also believe that finally it should be up to the user to decide which sites they want ranked first - I'd definitely boost python.org while banning these content farms.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37483895"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37483895" href="https://news.ycombinator.com/vote?id=37483895&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>Some day I'm going to start paying these people:<p><a href="https://kagi.com/" rel="nofollow noreferrer">https://kagi.com</a></p><p>DuckDuckGo is a bit better than Google at avoiding content farms and semantic web spam, but I think it's mostly for the same reason Linux and MacOS used to have zero malware.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="37482282"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37482282" href="https://news.ycombinator.com/vote?id=37482282&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>Because the page you've linked has 24,599 words in total, out of which only 43 words are dedicated to "str.endswith". You can make a beefy SEO article specifically on this method by talking about it a bit, and then providing a lot of examples in various different scenarios.<p>The bottom line being that there is nothing you can do about it unless Python themselves fundamentally change how the documentation is structured, which I doubt they have plans to do.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37482795"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37482795" href="https://news.ycombinator.com/vote?id=37482795&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>I disagree - Google can and should modify their algorithms until the site that users actually want is first.
Tracking which sites users click on for those searches, or maybe which sites users with those searches click on last should give a pretty strong signal that python.org should be ranked far above the spam farms no matter what the content percentage difference is. Content percentage is a clearly gameable metric that shouldn't outweigh other factors.<p>I'm honestly surprised Google employees haven't fixed this somehow, surely they have thousands of people running into this problem daily.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37483039"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37483039" href="https://news.ycombinator.com/vote?id=37483039&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>&gt; Google can and should modify their algorithms until the site that users actually want is first.<p>Who, exactly? A professional Python programmer probably has their IDE/editor set up so it can shows a brief document for `str.endswith` already. Someone who is new to Python (probably not even a programmer yet) might actually prefer the hand-holding from those content farm pages.</p><p>[1]: <a href="https://news.ycombinator.com/item?id=37483100">https://news.ycombinator.com/item?id=37483100</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37483233"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37483233" href="https://news.ycombinator.com/vote?id=37483233&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>&gt; A professional Python programmer probably has their IDE/editor set up so it can shows a brief document for `str.endswith` already. Someone who is new to Python (probably not even a programmer yet) might actually prefer the hand-holding from those content farm pages.<p>Someone who has been exposed to the most basic Python features and knows they want info on str.endswith can just type help(str.endswith) in the Python interactive environment.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37483906"><td></td></tr>
                <tr id="37484035"><td></td></tr>
                              <tr id="37482940"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37482940" href="https://news.ycombinator.com/vote?id=37482940&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>Google has never worked this way. By adding more examples to an SEO article you are also actively farming long-tail clicks, which will make people spend more time on the page and if Google was to use that as a metric (there have been rumours) then it is beneficial to the SEO site as well.<p>Like I said, Python or any other language can fix this issue by changing the entire mindset of how documentation is built. You can then get the OSS community involved on GitHub to slam dunk on all the SEO spammers.</p><p>Just look at MDN or Web.dev, both have their content repos up on GitHub and people contribute metric tons of useful info. And both of these sites have healthy standings in the context of SEO.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37483684"><td></td></tr>
                <tr id="37483778"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_37483778" href="https://news.ycombinator.com/vote?id=37483778&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>I do agree with you but I didn’t feel it was necessary to point that out. MDN doesn’t use SEO titles so my guess is, that is where it loses out a bit, but for most in-depth JS/CSS stuff, I generally get MDN as a top result.<p>Can’t remember the last time I visited W3S/GFG to be honest.</p><p>It’s about to get worse though as it appears that DigitalOcean is putting a nail in the coffin for CSS-Tricks and Google will absolutely demote it because of inactivity, only the most linked-to pages will survive until DO decides to shit the bed and try and move the entire site to their Tutorials platform.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="37482959"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37482959" href="https://news.ycombinator.com/vote?id=37482959&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>It seems that you believe Google is not taking those signals in consideration in their algorithm.<p>Google search rank has been an ML driven algorithm for ages now and take into account dozens of signals. User rejection (how fast people come back to the search from a result click) and obviously which results get clicked more often are examples of that.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37483437"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37483437" href="https://news.ycombinator.com/vote?id=37483437&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>I do believe that they do this, but that their weighting is off, sorry for not being clear. I was mostly responding to the parent comment talking about ratios.<p>Based on other comments saying they like the sites I consider spammy, maybe the weights aren't even wrong, they're just not optimized for me!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37482880"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37482880" href="https://news.ycombinator.com/vote?id=37482880&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>&gt; Google can and should modify their algorithms until the site that users actually want is first.<p>Why?</p><p>Google is an ad company, that has integrated search.</p><p>Why would they cut their own bottom line in order to make data happy?</p><p>You aren’t their customer.  You are Google’s data.  Google’s customers buy your data.</p><p>Why would they change anything about their business model, which works amazingly well?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37482998"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37482998" href="https://news.ycombinator.com/vote?id=37482998&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>Because not paying attention to the quality of the product means google is A-okay with the normal brand arc and is on the part where the brand cuts quality to boost profits while coasting on name recognition- I.e the enshittification phase.<p>They can coast for an indeterminate amount of time, but with the risk that eventually the consumer will be fed up and stop using them, especially if a decent alternative pops up.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37483602"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_37483602" href="https://news.ycombinator.com/vote?id=37483602&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>Decent alternatives have been bandied about here for over a decade.  Guess what?  There are none.<p>Google’s business model is selling user data to the highest bidder.  Google’s other business model is selling opportunity to collect data on people.</p><p>You as a search user are not a customer, but a data point.</p><p>There is literally no incentive for this to change.</p><p>Desiring an ad company to not show ads is a ridiculous desire.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37484016"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_37484016" href="https://news.ycombinator.com/vote?id=37484016&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>That’s not quite right - users are customers paying for a service, search, in exchange for a payment, I.e. their time and eyeballs.<p>At the same time google coordinates with to their other customer and swaps the time and eyeballs for money.</p><p>But users are definitely a customer paying with time in return for search results.</p><p>If the product becomes too popular to obnoxious, people don’t even need an alternative to quit. It’s happened with other products. Not everyone will quit, but the customer base will shrink.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="37483159"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37483159" href="https://news.ycombinator.com/vote?id=37483159&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><br><div>
                  <p><span>Their business model depends on users finding their search results useful. I think Google’s business is far more fragile than it looks. That’s why they’re doing all the things that are now in the crosshairs of regulators.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37482974"><td></td></tr>
                  <tr id="37483303"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37483303" href="https://news.ycombinator.com/vote?id=37483303&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>&gt; Google can and should modify their algorithms until the site that users actually want is first.<p>That is what Google is doing!  But remember, the advertiser is the user, not the person running the search.</p><p>If you want to be the user, and get good search, pay for kagi.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37482986"><td></td></tr>
                <tr id="37483141"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37483141" href="https://news.ycombinator.com/vote?id=37483141&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><br><div>
                  <p><span>You can also raise/lower domains in kagi.  So if you're a python developer, you can boost docs.python.org to personalize your results.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37482535"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37482535" href="https://news.ycombinator.com/vote?id=37482535&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>Honestly, changing the way they do it is a fine idea. Massive documentation pages were how we did it in the olden days. And I think they're still good for when you want to read through and get an understanding of the whole library. But having that also broken up into a lot of small pages that link back to the main doc would be really helpful to people who are searching for specific solutions.<p>I think that could mostly be done in an automated fashion to start. Then into the master doc you can start adding hinting and extra material that gets rendered into the sub-pages. So it could be approached gradually.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37483093"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37483093" href="https://news.ycombinator.com/vote?id=37483093&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><br><div>
                  <p><span>You're not wrong, but I think now the majority don't want an understanding, they just want answers.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37484008"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37484008" href="https://news.ycombinator.com/vote?id=37484008&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>&gt; unless Python themselves fundamentally change how the documentation is structured, which I doubt they have plans to do.<p>Nor should they, in my opinion. Quality of documentation is more important than that.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37482767"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37482767" href="https://news.ycombinator.com/vote?id=37482767&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><br><div>
                  <p><span>I really hope they don't enshittify their documentation just to rank in Google.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37483822"><td></td></tr>
                  <tr id="37482790"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37482790" href="https://news.ycombinator.com/vote?id=37482790&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>It’s a general problem.  In the past I have seen great HN threads sharing exclude lists etc to avoid the scrapers.  Google could, of course, track a few thousand canonical sources so that just python and SO and a few others don’t get beaten to the top in their specific expert areas, but it doesn’t genrtalize.  Google has no real algorithmic idea who is copying who.<p>And then it hits me: the proper documentation for things are on pages without ads!  Perhaps that’s the signal google needs to start weighing heaviest…? ;)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37483224"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37483224" href="https://news.ycombinator.com/vote?id=37483224&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>&gt; <i>Google has no real algorithmic idea who is copying who.</i><p>This is an irrelevant distraction, because Google's literal army of nearly 200,000 full time employees, a large number of whom are Python developers, do know. Geeksforgeeks, w3schools, programiz, tutorialspoint, and python-reference.readthedocs, which all rank higher than the official documentation, are not flash-in-the-pan sites. They've been polluting the search results for literally years. Trivial manual processes at Google scale would be 1000% fine and effective.</p><p>Google could, if it gave half a shit, give every employee a Chrome browser extension that lets them manually vote on the reasonability of site rankings within known problem genres for their own searches.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37482862"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37482862" href="https://news.ycombinator.com/vote?id=37482862&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>SO isn't a canonical source, they're another content farm using nofollow links to the content they appropriate to maintain their search edge.<p>Its entire purpose is to inject itself as a search middleman. Even worse, I find myself landing there from google results to a question they had closed as not worthy of the site, but worthy enough still to keep up for the search juice.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37482899"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37482899" href="https://news.ycombinator.com/vote?id=37482899&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>&gt; I find myself landing there from google results to a question they had closed as not worthy of the site<p>Well, you did google for the question and not for the answer. ;)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37483055"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37483055" href="https://news.ycombinator.com/vote?id=37483055&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><br><div>
                  <p><span>True, and it was even more accurate a few years ago. Now Google moved towards understanding queries and giving context-specific answers rather than a strictly keyword based engine. You were considered a bad googler if you asked it a question, now it's the norm.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="37483100"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37483100" href="https://news.ycombinator.com/vote?id=37483100&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>Hot take here, but as someone that doesn't code daily, I prefer those sites over the actual docs in most cases.<p>If I need to get something done quick, those sites will give me a quick 5 second refresher with clear examples.</p><p>Actually, in the doc you described as "obviously the correct hit", all I see is</p><p>&gt; str.endswith(suffix[, start[, end]])</p><p>&gt; Return True if the string ends with the specified suffix, otherwise return False. suffix can also be a tuple of suffixes to look for. With optional start, test beginning at that position. With optional end, stop comparing at that position.</p><p>Meanwhile, the first hit in Google for me is Programiz, which has actual real examples without any additional clicking around or trying to understand how the information is structured.</p><p>Besides, I know the docs exist, I don't need a google search for it. I'll click on the content farms every time because they've consistently been the fastest way for me to get what I need.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37483183"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37483183" href="https://news.ycombinator.com/vote?id=37483183&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>Yeah I enjoy the content farms. Who needs documentation on a simple problems when you can instead have something easy like this:<p>Many are asking questions about the Python Documentation How To Check Null Python 2023. Here are some solutions to How To Check Null Python 2023:</p><p>&lt;ADVERTISEMENT&gt;</p><p>Solution 1: Type "if variable is None"</p><p>&lt;ADVERTISEMENT&gt;</p><p>The first solution out of many is to type "if variable is None". This is the best way to solve Python issues, recommended by experts.</p><p>&lt;ADVERTISEMENT&gt;</p><p>Solution 2: Download Windows Computer Cleaner
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37483753"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37483753" href="https://news.ycombinator.com/vote?id=37483753&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><br><div>
                  <p><span>This got a chuckle out of me, but plenty of content farms for programming are extraordinarily useful. One could make the case W3schools is a content farm, and that's raised a whole generation of programmers for their knowledge.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37483251"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37483251" href="https://news.ycombinator.com/vote?id=37483251&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><br><div>
                  <p><span>That seems a bit disingenuous on your part. I picked the top 3 hits on Google and they are all very helpful and to the point - Programiz, W3Schools, Tutorialspoint. Granted, I have ublock origin, as most people should have anyway.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37483229"><td></td></tr>
            <tr id="37483322"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37483322" href="https://news.ycombinator.com/vote?id=37483322&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>Except those farms don't do any original research and just copy off each other. They're littered with mistakes and you will see the same mistake pop up across all of them.<p>These days for obscure terms, you don't even get the luxury of reading garbage written by people who barely understand the topic at hand, instead you get meaningless fluff generated en masse using LLMs.</p><p>Honestly, I'd rather spend time parsing whatever doxygen spits out than try to figure out what the needlessly verbose yet inaccurate LLM output is trying to get at.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37483060"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37483060" href="https://news.ycombinator.com/vote?id=37483060&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><br><div>
                  <p><span>Personally, it's because the docs aren't that good unless you're looking for something very specific. People are talking about the fact that there are no ads, but I would think it's because of the bounce rate. I could see there being a lot of people learning Python who go to the docs, see a large chunk of text with OK examples, and then bouncing to go to the other sites that have more examples. This is something that's happened to me a lot when I was doing Python development. Some of the stuff is very helpful on the docs (e.g. asyncio), but for other things the actual stuff that I want to do gets lost in the details of the docs. So while ads probably play a part, I think the bounce rate is a bigger factor, especially for people who aren't necessarily developers.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37483914"><td></td></tr>
            <tr id="37483017"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37483017" href="https://news.ycombinator.com/vote?id=37483017&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>I've come across this many times and I've come to think it's an issue with that specific page in particular. I think the problem is partly on Python's end: they've got a single page where they've jammed in all of the built in types (str, dict, list, complex, ...). It's a huge list of types and a correspondingly huge page!<p>I suspect if there were separate pages for each type then it would be ranked higher... and it would actually be more useful. I don't get why they've done it like that.</p><p>The higher ranked pages admittedly have a whole page just for a single method, which is too far in the other extreme and is obviously more for SEO than use. But with the Python docs the way they are, we'll never know whether a more sensible official page would beat them or not.</p><p>As some evidence that it's not just Google allowing spammers to shine through - sometimes for a search about a built-in type I actually do get official docs at the top, but it turns out to be the tutorial page about the class (which is not a giant mish-mash).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37483018"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37483018" href="https://news.ycombinator.com/vote?id=37483018&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>As others have said, the pages with the most ads are the ones Google wants you to go to. Their highest priority is making money. Sometimes, that means showing you the right, best content, but a lot of the time now that's not the case.<p>Which is why LLMs have Google scared, in my view.</p><p>If an LLM has all the answers, you don't need to hand over your question to Google so it can steer you to the "right" (ad-filled) answers. It just knows, and tells you. Yes, hallucinations are still a problem but they aren't a growing one. LLMs that can provide you a reference to the right docs will be a thing soon if they aren't already.</p><p>How does Google make money in a world where fewer and fewer people need to ask them for where to find the answer?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37484019"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37484019" href="https://news.ycombinator.com/vote?id=37484019&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><br><div>
                  <p><span>I'm not sure I would consider those results "low-quality". Not necessarily for this use case, but often time 3rd party sites do a better job of providing examples and readable documentation than the "official docs". Also, if you want to use the official documentation, just use the search bar of docs.python.org. Then Google gets none of your views!</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37482832"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37482832" href="https://news.ycombinator.com/vote?id=37482832&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>Agreed that Google is not very helpful here, but searching the Python docs directly works pretty well:<p><a href="https://docs.python.org/3/search.html?q=endswith" rel="nofollow noreferrer">https://docs.python.org/3/search.html?q=endswith</a></p><p>Otherwise I really like ChatGPT like this: you put in minimal work into the query and it usually fills in useful info. If you use "Advanced Data Analysis" mode it will run those examples in the browser.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37483216"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37483216" href="https://news.ycombinator.com/vote?id=37483216&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>There are a lot of ways to look at it.<p>The "You're not the customer"-perspective: You as a user of google search is not the customer. The customer is the people placing ads on Google search, and secondary the people placing ads on the pages google search leads users to.</p><p>The "its an algorithm"-perspective: Google is a search engine, not a collection of curated links. In the past, Google has been very much against having human rate results, but I think they actual have focus groups that come in a lab and do some searches and rates what they see (under the guise of being a different search engine, most likely). Google is very conservative about adjusting their algorithm (or at least have been) and small changes can lead to huge changes in income.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37482920"><td></td></tr>
            <tr id="37483006"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37483006" href="https://news.ycombinator.com/vote?id=37483006&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>Checkout devdocs.io. I'd suggest using this if you want to search official docs. But first you need to enable whatever language you want to search. I enabled python 3.11 and searched `endswith` and immediately found the documentation.<p>I know this doesn't answer your question, but I hope this helps you in the interim.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37482969"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37482969" href="https://news.ycombinator.com/vote?id=37482969&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><br><div>
                  <p><span>Because adding exceptions to an algorithm doesn't scale, they won't add any. Because customer service doesn't scale, they don't have any. And so on. Frustrating isn't it? It's what happens when you let engineers design a product. Letting system behaviour at the limits dictate everything.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37484191"><td></td></tr>
            <tr id="37483021"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37483021" href="https://news.ycombinator.com/vote?id=37483021&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><br><div>
                  <p><span>While not answering the question, prefixing the query with `site:docs.python.org` will get you what you need. If you're doing this a lot then I recommend at least adding a search shortcut to:<pre><code>    https://www.google.com/search?q=site%3Adocs.python.org+%s
</code></pre>
then you can type something like `py endswith` in the address bar. Or use ddg's "I'm feeling lucky" (prefix the query with !) and go directly to the first result:<pre><code>    https://duckduckgo.com/?q=!+site%3Adocs.python.org+%s
</code></pre>
Even better, just use <a href="https://devdocs.io/" rel="nofollow noreferrer">https://devdocs.io/</a></span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37484044"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37484044" href="https://news.ycombinator.com/vote?id=37484044&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><br><div>
                  <p><span>i'd love a search page that lower the page rank if it contains ads. Maybe even a search that blocks all pages containing ads.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37483167"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37483167" href="https://news.ycombinator.com/vote?id=37483167&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>I highly recommend comparing google results with kagi.com results. The extreme difference in quality has a simple explanation: kagi.com is a paid service so it can downrank sites with many ads and tracking scripts.<p>Google needs that sweet surveillance money so its results are filled with crappy content farms both human- and LLM-generated. Kagi doesn't need to make money so it can happily link to the highest quality sites, even if they don't take part in the targeted advertising economy.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37483009"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37483009" href="https://news.ycombinator.com/vote?id=37483009&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>Have you ever seen Google ads on the Python documentation?<p>But more seriously... I think it's because the language and framing of the python documentation is difficult for a new user to understand.</p><p>Yes, Python is miles better than some other languages at documentation, but it's still more of a reference than a tutorial. I remember when I first started learning Python, I read blog entries (e.g. blogspam) more than I did the official docs.</p><p>In my intermediate phase, I searched Python docs but I didn't need Google's help for that.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37482891"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37482891" href="https://news.ycombinator.com/vote?id=37482891&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>Not an answer to OP question, but if you find yourself googling "python endswith" (as per example) then your DX is somehow broken.<p>Invest in good code editor with linting. No more googling for such trivial things
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                      <tr id="37483403"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37483403" href="https://news.ycombinator.com/vote?id=37483403&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><br><div>
                  <p><span>As someone that loves python and uses it daily, the official docs are terrible for getting a quick answer. They're impenetrable as a result of being exhaustive. If you google anything react related their official docs will be the first to show.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37483091"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37483091" href="https://news.ycombinator.com/vote?id=37483091&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>The real question is, why are these content farm sites indexed at all? They are spam, and should be blocked, just like the way GMail blocks spam. They should never appear in any search result for anything ever, let alone be ranked first!<p>If someone simply took Google and just applied a huge blocklist so that garbage sites like those never got indexed, it would be the perfect search engine.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37483042"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37483042" href="https://news.ycombinator.com/vote?id=37483042&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>Those sites are plastered with Google ads so it makes Google more money to recommend them over a useful result.<p>Additionally Google guidelines for search ranking prioritize meaningless fluff and spam because they want to waste as much of your time as possible. More wasted time = more ad exposure.</p><p>The worlds largest search engine is owned by the worlds largest advertising company. I am surprised no one saw this coming lol
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37482810"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37482810" href="https://news.ycombinator.com/vote?id=37482810&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>I wanted to start a new search engine that would index content from ad-free websites only.<p>Then I realised StackOverflow has ads nowadays and my search offering would be useless for like 98% of devs.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37483835"><td></td></tr>
            <tr id="37483185"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37483185" href="https://news.ycombinator.com/vote?id=37483185&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>Every one of those "well-known low-quality content farms" is a better result for someone searching "python endswith" than the official documentation.<p>You don't have to parse through a veritable novel of irrelevant results to find what you're looking for.</p><p>They provide example code to show you how to use the method.</p><p>They break down the usage more thoroughly than the official docs.</p><p>They _show_ you the different parameters you could pass to the method.</p><p>Some of them provide interactive REPLs where you can play with and test the method.</p><p>The docs break it down _technically_ but they leave questions. Are start/end inclusive? What does it mean to "stop comparing at that position"? Why would you use the start parameter if you're trying to find the end of the string? If you use start does the end parameter count from 0 or from start? What happens if you pass a start or end that are outside the bounds of the string?</p><p>Look, I think the Python docs are great and use them all the time. But for the average person looking for info on `endswith` - whether that's someone new trying to understand how it works, or someone experienced looking to understand the parameter types - those pages are more approachable.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37483129"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37483129" href="https://news.ycombinator.com/vote?id=37483129&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><br><div>
                  <p><span>Your post inspired me to do some research on options for blocking these sites and I stumbled upon the uBlacklist browser add-on. It's open source, easily configurable, supports multiple search engines, and you can even use community block-lists instead of building your own.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37482965"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37482965" href="https://news.ycombinator.com/vote?id=37482965&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>Short answer: The rea Python documentation is paying less money to Google than the content farm.<p>Long answer: Balancing the many interests of search result parties, the decrease of consumer satisfaction is by Googles  benchmarks outweigh by money received from their paying customers.</p><p>Use Bing, results are relevant and they do not yet rank paying farms as number one.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37482902"><td></td></tr>
            <tr id="37483012"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37483012" href="https://news.ycombinator.com/vote?id=37483012&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><br><div>
                  <p><span>GeeksForGeeks is the bane of my existence and IMO a symptom that the entire system has perverse incentives. Fortunately, I've moved 90% of my code inquiries to LLMs, to great success.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37482887"><td></td></tr>
            <tr id="37482972"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37482972" href="https://news.ycombinator.com/vote?id=37482972&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><br><div>
                  <p><span>Hey at least the first result isn't some StackOverflow overlord schooling you on why you should never use <i>endswith</i>, right? /ₛ</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37482942"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37482942" href="https://news.ycombinator.com/vote?id=37482942&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><br><div>
                  <p><span>I've completely stopped using Google for this kind of thing. ChatGPT or devdocs.io to go straight to the docs</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37483008"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37483008" href="https://news.ycombinator.com/vote?id=37483008&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>Google search heavily focuses on the last page that users visit for a query. And python documentation is hard for most novice programmers to understand.<p>My guess would be that engineers first go to documentation, don't understand it, go to low-quality-content-farms which answer their questions in natural language. It's low quality but it's enough for novice use cases such as python endsWith.</p><p>And this leads to a big reduction in Google's ranking of python docs.</p><p>TLDR : most novice programmers don't/can't read docs.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37483136"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37483136" href="https://news.ycombinator.com/vote?id=37483136&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>I think your TLDR is accurate, but I think the mechanism is likely even simpler than Google looking at the last page visit.<p>The docs are written by and for experienced programmers. They're very dense with information but light on examples and comments that explain things for dummies.</p><p>Its popularity means the vast majority of Python users are novices who would find the docs hard to read. Geeksforgeeks et al are providing content for them and so is actually a better resource to show the majority of searchers (especially given that it's a basic string formatting question, something very likely to be searched by for novices).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37482874"><td></td></tr>
            <tr id="37482939"><td></td></tr>
            <tr id="37483513"><td></td></tr>
            <tr id="37483150"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37483150" href="https://news.ycombinator.com/vote?id=37483150&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>It's a genuine problem, not only with Python but with other languages.<p>However, the  api library reference is only one kind of documentation, and not necessarily what everyone is looking for. For whatever language I'm working in, I keep the library docs handy for immediate use, and only go to search the web when I'm looking for something beyond a dry reference. Maybe I want a tutorial, or short how-to for a specific task. Maybe I'm looking for something deeper, with context and explanation.</p><p>I somewhat agree with another comment here: the library reference docs should be a keystroke or click away in your development environment. Are there plugins for your preferred editor or IDE to make this possible? Use those.  If you're looking for a different kind of documentation and it's not part on the official python site, maybe that's something to be addressed.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37482855"><td></td></tr>
            <tr id="37482953"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37482953" href="https://news.ycombinator.com/vote?id=37482953&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><br><div>
                  <p><span>We are to a point where I think Google should start manually de-ranking content mills and blogspam, or even stop indexing them altogether.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37482762"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37482762" href="https://news.ycombinator.com/vote?id=37482762&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>the worst thing about those sites is they are slow.<p>I get why at least with the python docs, they're a little dense. some of those others have example uses which I could imagine people find useful.</p><p>geeksforgeeks with the login nag page is pretty bad.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37482933"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37482933" href="https://news.ycombinator.com/vote?id=37482933&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><br><div>
                  <p><span>Because Google is run by business executives and clueless product managers. The engineers have been forced into the back to only think on whatever the current sprint is and told to buzz off when it comes to biznass decisions only those with MBAd can solve.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37482693"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37482693" href="https://news.ycombinator.com/vote?id=37482693&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><p><span>Google can't make money serving ads if you go to the ad-free python.org.<p>Obviously I'm not saying they're singling out python or documentation in general as some kind of cash cow. More realistically the story is that, sites that serve ads make money, and can spend money on cat-and-mousing SEO to keep making more money. Technical docs aren't going to do that. Google could whitelist them but it seems they turn a blind eye for the aforementioned reason.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37482943"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37482943" href="https://news.ycombinator.com/vote?id=37482943&amp;how=up&amp;goto=item%3Fid%3D37482216"></a></center>    </td><td><br><div>
                  <p><span>Google shouldn’t whitelist them but use them as a test case for the ranking algorithm. If a content farm comes up ahead of the official documentation site then the algorithm is obviously broken.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The New Godot Development Fund (146 pts)]]></title>
            <link>https://godotengine.org/article/godot-developer-fund/</link>
            <guid>37481872</guid>
            <pubDate>Tue, 12 Sep 2023 14:28:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://godotengine.org/article/godot-developer-fund/">https://godotengine.org/article/godot-developer-fund/</a>, See on <a href="https://news.ycombinator.com/item?id=37481872">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p>We are excited to introduce a major improvement in funding the development efforts of the Godot Engine – the <a href="https://fund.godotengine.org/">Godot Development Fund</a>! The goal for the Development Fund is to create a direct way for everyone to help us secure stable funding and ensure the longevity of the project.</p>

<p>The Development Fund was <a href="https://godotengine.org/article/funding-breakdown-and-hiring-process/">soft-launched in July</a> and already welcomed a lot of new and old sponsors, but we need to take it to the next level to sustain the current development pace, and increase it with new hires.</p>

<h2 id="reducing-platform-fees-amplifying-impact">Reducing platform fees, amplifying impact</h2>

<p>The Development Fund will make the Godot Project more sustainable and independent. This new platform lets us significantly reduce platform fees, and as a non-profit we do not charge VAT on donations, unlike a platform like Patreon does. So your contributions go directly towards the development and improvement of the Godot Engine itself.</p>

<p>If you are currently supporting us <a href="https://www.patreon.com/godotengine">through Patreon</a>, we encourage you to switch to the <a href="https://fund.godotengine.org/">Godot Development Fund</a> to increase the effectiveness of your donations.</p>



<p>The support of the community is what keeps making it possible to reach <a href="https://godotengine.org/article/godot-4-0-sets-sail/">new heights</a>. With you, we can achieve even more!</p>

<p>Every donation, no matter the size, helps us immensely! With your help we can hire more developers, create high quality demos, pay for hosting services and infrastructure, and make the best possible Godot Engine. The more funds we have, the more we can give back to you and the entire gamedev community.</p>

<h2 id="future-enhancements">Future enhancements</h2>

<p>While this is a good, fully functioning starting point for the platform, we will keep improving the Developer Fund.</p>

<p>In the future, the platform will give automated rewards, like a special Discord role, and you’ll be able to showcase your contribution level next to your username on our main platforms.</p>

<h2 id="freedom-and-independence">Freedom and independence</h2>

<p>By relying more on recurring user-funded contributions and company sponsorships, we reduce our dependence on large one-time grants from corporations. This financial independence empowers us to prioritize the needs and interests of our community and the open source principles at the core of our projects. Your help ensures that we can create our own journey, uphold our core values, and continue to evolve the engine in ways that truly benefit you, the users.</p>

<h2 id="a-heartfelt-thanks">A heartfelt thanks</h2>

<p>We would like to take a moment to express our deepest gratitude for your ongoing support, dedication, and passion for Godot. It’s thanks to you and our amazing community that the Godot Engine is what it is today. Let’s continue to make it the game engine of choice for developers worldwide!</p>

<p>We absolutely understand that not everyone can donate. In that case, please share the Godot Dev Fund link! Spreading the word is an excellent way to help.</p>

<p>Join us at the <a href="https://fund.godotengine.org/">Godot Development Fund</a>.</p>

<p>Thank you for making it all possible.</p>

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We built the fastest CI in the world and it failed (268 pts)]]></title>
            <link>https://earthly.dev/blog/shutting-down-earthly-ci/</link>
            <guid>37481513</guid>
            <pubDate>Tue, 12 Sep 2023 14:07:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://earthly.dev/blog/shutting-down-earthly-ci/">https://earthly.dev/blog/shutting-down-earthly-ci/</a>, See on <a href="https://news.ycombinator.com/item?id=37481513">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Imagine you live in a world where no part of the build has to repeat unless the changes actually impacted it. A world in which all builds happened with automatic parallelism. A world in which you could reproduce very reliably any part of the build on your laptop. Fairy tales, right? Well, that’s what we built, and to everyone’s surprise, nobody wanted it. It’s like flying cars - they sound amazing, but in practice, things are more difficult than they might seem.</p>
<p>Back in April 2020, we at Earthly set out on this quest to improve CI/CD tooling. We dared to ask questions like “What if the CI could run on your laptop?” And “what would the fastest CI system on the planet look like?” With these questions in mind, we came to a pretty strange, but pretty interesting answer… the build system and the CI need to be the same. And it needs to be distributed.</p>
<p>Now we all know dreaming big is easy. Execution is where things get hard.</p>
<h2 id="what-does-success-look-like">What Does Success Look Like?</h2>
<p><picture><source srcset="https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/4340-1000-09225aea3.webp 1000w, https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/4340-1200-09225aea3.webp 1200w" type="image/webp"><source srcset="https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/4340-1000-09225aea3.png 1000w, https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/4340-1200-09225aea3.png 1200w" type="image/png"><img height="400px" src="https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/4340-800-09225aea3.png"></picture></p>
<p>In a startup, you don’t have the luxury of building a mature product with all the possible bells and whistles before shipping it to your customers. Mature products take many years and many engineers to build out.</p>
<p>And yet, you are going up against the incumbents - companies that have hundreds of millions in funding, (maybe even IPO’d), they have hundreds of engineers, they have a 10-year head start, and a ton of reputation. How can you even compete?</p>
<p>Well, you know what they say… “Competition is for losers”. The answer is that you don’t. At least not on the same level. You’ll never be more mature, or have more features, or more integrations. Instead, you can be 10x better in one, very specific way. And you’ll appeal to the few teams where the very specific problem you’re solving is so painful that they’re willing to make compromises on everything else.</p>
<p>You’re not going after the whole market in the beginning. You’re just going after just enough enthusiasts, mavens, early adopters - whatever you want to call them - for whom the solution that you built on a shoestring budget is dramatically better in their specific situation than any incumbent. So much better, that they’re willing to pay the cost of adoption, and they’re willing to suffer through the bugs and the missing bells and whistles.</p>
<p>Then, once you have captured that segment, you invest more, extend to a wider audience, get more feedback, then again invest more, extend again, and so on. It’s important to understand this dynamic in order to gauge what success looks like at the earliest stages.</p>
<p>So if your MVP is not getting enough validation, you can’t just slap more features on it, because, again, features are not what will make you successful. Incumbents win feature contests.</p>
<p>Successful products will show validation at a small scale, despite all their limitations, bugs, and general annoyances. If you can’t find a small group of people passionate enough about your product in its experimental stage, you’re going to have a hard time capturing an audience even with a feature-rich product. It’s a recipe for building something nobody wants.</p>
<p>What early-stage validation looks like is a small group of people who have a lot of passion for what you do. Nobody has heard about your stuff, but your users are passionately shouting from the rooftops about it. You walk into their office and everyone has stickers with your company on their laptops, and everyone wants to talk to you.</p>
<h2 id="the-master-plan-for-earthly-ci">The Master Plan for Earthly CI</h2>
<p><picture><source srcset="https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/4610-1000-28f43921c.webp 1000w, https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/4610-1200-28f43921c.webp 1200w" type="image/webp"><source srcset="https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/4610-1000-28f43921c.png 1000w, https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/4610-1200-28f43921c.png 1200w" type="image/png"><img height="400px" src="https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/4610-800-28f43921c.png"></picture></p>
<p>To build out the vision of Earthly CI, we devised a master plan. We knew that we didn’t want to go on a crazy complex implementation for 3 years only to emerge from a cave with a product that would not fit the needs of the real world. So we split up the end-vision into several independent products that we would validate along the way.</p>
<p>Thus, instead of building Earthly CI from day 0, we first built the syntax, and the general experience around running builds on-demand. The key value we delivered was build consistency: there is a level of guarantee that the build will execute the same, regardless of the environment it runs in. The syntax of this build tool is the same as the CI down the road, but it only ran locally initially and in other CIs. We called this <strong>first milestone</strong> Earthly.</p>
<p>Then we built remote runners that can be invoked from anywhere - again your laptop or any CI. These remote runners bring you all the key benefits of Earthly CI but without being a CI. The key value is build speed. And I’m talking 2-20X faster CI pipelines, thanks to the caching and parallelism. We called this <strong>second milestone</strong> Earthly Satellites.</p>
<p>And finally, <strong>the third milestone</strong>, Earthly CI - the platform that brings everything together, the CI that is ridiculously fast and can run anywhere. This is the full CI that is meant to compete with all the other big CIs like GitHub Actions, CircleCI, Jenkins and so on.</p>
<p>What was particularly appealing about this plan was that Earthly, the build system, targets one problem: <strong>build consistency</strong>, while the final version, Earthly CI, targets another problem: <strong>build speed</strong>. This meant that Earthly, which is free, would not cannibalize in any way the monetization of Earthly CI. We wouldn’t be giving away too much for free – as Jenkins did – and instead, it would serve as a sustainable and scalable business model. It made sense to use the build system as a way to then create bottom-up adoption for Earthly CI - and the fact that we were building it first allowed us to build traction that one day will magically just convert over to Earthly CI users.</p>
<p>Little did we know that this difference in value proposition – consistency vs.&nbsp;speed – actually became a problem down the road…</p>
<h3 id="milestone-1-earthly">Milestone 1: Earthly</h3>
<p>Earthly was the lowest-stakes validation. I just built the first version on my own, threw it up on GitHub, and then launched it on Reddit and HackerNews. Zero funding (apart from my wife’s patience), so close to zero risk. If it takes off, I go raise money. If it doesn’t I’ll try something else.</p>
<p>We now know that Earthly is used widely across thousands of repositories, by companies big and small, like VMware, Adobe, Namely, Roche, ExpressVPN, Bluecore, and many others. But the early signs were that people were using Earthly even when it was a one-person unfunded project riddled with bugs and limitations. That’s validation.</p>
<h3 id="milestone-2-earthly-satellites">Milestone 2: Earthly Satellites</h3>
<p>After fixing the obvious issues in Earthly, and widened support to appeal to more types of organizations, we were now building momentum. And with enough capital, we were able to now work on the next milestone: Earthly Satellites.</p>
<p>The interesting thing about Satellites was that we were getting the validation even before we built them. Earthly being open-source, you could already run your own Earthly remote runner (since we use Buildkit underneath, it was essentially a remote Buildkit), connect Earthly to it, and get similar benefits to Satellites even before this was a commercial offering. And so people did this on their own, hosting it in their own environment, without us managing it for them. Once we had this packaged up in a managed offering, people were flocking to it, mainly because they did not want to manage remote runners on their own. The initial version of Satellites was buggy, inefficient, and unstable. Yet people came to it despite those inefficiencies, because there was nothing else that would give them CI/CD speed at that level. That’s validation.</p>
<p>Interestingly, we didn’t really see it for what it was at the time. We were only thinking of the end vision of taking over the CI world completely, and Satellites was just an implementation milestone that we happened to publish as a product along the way. So we just shrugged and figured, “Ok, if this is how people react to this incomplete offering, imagine how they will react to the full vision of Earthly CI!”</p>
<h3 id="milestone-3-earthly-ci">Milestone 3: Earthly CI</h3>
<p>Almost everyone who was using Satellites was using them in a CI/CD use case. Meaning that they executed remote Satellite builds via CI with the main goal of speeding up their pipelines. In this configuration, the CI vendor is merely a pass-through that deals with triggering pipelines. The actual execution happens on the satellites. To us, that was validation that Earthly CI was needed. Why not just simplify the stack? Why pay both the CI vendor and us, when you can just pay us?</p>
<p>Plus, many Earthly community members were asking about the possibility of hooking up Earthly Satellites directly to GitHub. More validation.</p>
<p>Whenever we spoke to VPs of engineering, the promise of 2-20X faster builds was making their eyes light up!</p>
<p>The closer we were getting to the Earthly CI launch, the more of a slam dunk it seemed it was going to be.</p>
<p>But, as you already know what this blog post is about, making Earthly CI successful turned out to be more challenging than we thought.</p>
<h2 id="the-early-symptoms">The Early Symptoms</h2>
<p><picture><source srcset="https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/4680-1000-cda93061f.webp 1000w, https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/4680-1200-cda93061f.webp 1200w" type="image/webp"><source srcset="https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/4680-1000-cda93061f.png 1000w, https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/4680-1200-cda93061f.png 1200w" type="image/png"><img height="400px" src="https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/4680-800-cda93061f.png"></picture></p>
<p>For Earthly CI, we did a <a href="https://earthly.dev/blog/launching-earthly-ci/">solid launch</a>, landed on <a href="https://techcrunch.com/2023/02/23/earthly-wants-to-reinvent-continuous-integration-to-make-it-faster-and-cheaper/">TechCrunch</a>, and lined up <a href="https://earthly.dev/blog/remote-code-execution/">a few blog articles for Reddit and HackerNews</a>.</p>
<p>From the launch we got about 50 emails signing up on the waitlist in the first week or two, outpacing the goals we had. We started setting up calls with these people, and, right off the bat, we could sense a big difference between existing Earthly users vs.&nbsp;people who were coming to us for the first time.</p>
<p>These weren’t the raving fans we were used to talking with. New people would look at Earthly CI with a skeptical eye. They were mostly thinking that “all CIs are the same - they just have different syntax,” and then they would not really look any further as to why we might actually be different. As a result, the conversation invariably turned to the <strong>cost of migration</strong>. How difficult would it be for them to rewrite and adapt a bunch of existing scripts to be able to use Earthly effectively?</p>
<p>Existing users, by contrast, were already fans, had already done the work of the migration, and already saw the benefits of Earthly. They were ready to champion us in their organizations, even if not everyone in their organization was on board yet.</p>
<p>We kept talking to as many teams as we could, to understand the apprehension toward Earthly CI, but it always came back to weighing the cost of migration vs.&nbsp;the benefit. And we could never win this up-front, mainly because these prospects had no idea whether we could deliver on the benefits we promised at scale. We don’t have a long-established reputation like our incumbents. Existing users claimed we were 10x easier to use, but how can you prove that to a new client on a quick Zoom call? So it didn’t make sense for them to jump head-first into an expensive and time-consuming migration effort just because some startup they had never heard of promised to deliver the sun and the moon.</p>
<p>We also tried getting existing Earthly Satellite customers to switch to Earthly CI – after all, they were all using Satellites <strong>in their CIs</strong>. The problem with this group was that they were already getting 95% of the value of Earthly CI through Satellites. Their builds were already really fast. Compared to a GitHub Actions + Satellite setup, Earthly CI wasn’t better, or at least, it wasn’t better enough to warrant the switch.</p>
<p>And then, after the launch traffic died down… There was silence.</p>
<h2 id="the-most-ridiculous-negative-lead-qualification-criteria-ever">The Most Ridiculous Negative Lead Qualification Criteria Ever</h2>
<p><picture><source srcset="https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/4880-1000-c7746413a.webp 1000w, https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/4880-1200-c7746413a.webp 1200w" type="image/webp"><source srcset="https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/4880-1000-c7746413a.png 1000w, https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/4880-1200-c7746413a.png 1200w" type="image/png"><img height="400px" src="https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/4880-800-c7746413a.png"></picture></p>
<p>The odd thing about direct calls with prospects was that we could never convince them to try out any of our products when talking to them face to face. Not Earthly CI, not Satellites, not even Earthly. At this point, we probably had over 100 calls with prospects. We were hearing over and over how they spent 2 years migrating to their current setup, how they put so much effort into it, and how throwing all that away would be so wasteful. And how annoying it is to switch CIs.</p>
<p>And yet, when users were coming on their own to our website, through a mix of product-led / word of mouth and content marketing, the adoption of Earthly was happening every single day. At a very significant and increasing rate.</p>
<p>What seemed like absolutely impossible with one approach was being proven as very much possible - perhaps even easy - with a different approach.</p>
<p>In retrospect, it’s of course obvious that there’s no way to sell developer products via traditional means. And we already knew that. We were just shocked at how stark of a difference the approach could create. It became clear that a direct GTM approach would not help us validate a product like Earthly CI.</p>
<p>We ended up with the most ridiculous negative qualification criteria I have ever heard of: if the prospect requires a demo, then they’re not worth going after. The type of prospect that <em>does</em> convert will come to us after they downloaded Earthly, read some docs, and wrote a bunch of Earthfiles. These teams never need a demo. It’s weird, but demoing is one of the strongest negative signals we have.</p>
<p>The moral of the story here is that when you introduce a developer tool that requires integration work (work outside of the development team’s commonly expected flow, work that replicates already existing work, and work that requires learning a new syntax or API), you can never force, or hurry anyone to adopt it. This can only happen on the user’s schedule. <strong>People will buy a developer tool, but you can’t sell it</strong>. We all know that engineers like to get their hands dirty and explore things on their own. This conclusion is the corollary of that well-known fact. That’s why you can’t hard sell to engineers. You can only soft-sell.</p>
<h2 id="problems-converting-earthly-users">Problems Converting Earthly Users</h2>
<p><picture><source srcset="https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/5140-1000-fdae51e43.webp 1000w, https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/5140-1200-fdae51e43.webp 1200w" type="image/webp"><source srcset="https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/5140-1000-fdae51e43.png 1000w, https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/5140-1200-fdae51e43.png 1200w" type="image/png"><img height="400px" src="https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/5140-800-fdae51e43.png"></picture></p>
<p>Our other big channel was converting existing Earthly users into Earthly CI users. This was a key segment because there is no migration concern - everyone in this segment has already converted to Earthfiles. It should be just a flip of a switch, right?… Right?…</p>
<p>Not so fast. What about the GitHub plugins ecosystem? Do you have a codecov action? Do you have manual triggers? Can I trigger based on a git tag creation? Can I select the machine size? Can I cancel stale builds? Can I trust your platform with our build secrets?</p>
<p>Our Earthly CI MVP, despite being the fastest CI ever, never met some key requirements for people. Sure, there were a few enthusiasts who did play around with Earthly CI and started using it. But there were no sizeable organizations, with budgets, willing to use it more widely than just 2-3 engineers. And even the few Earthly CI users, after a while converted into Satellites users, to get the benefit of the combination of a richer GitHub ecosystem and the speed of the Satellites.</p>
<p>But for the most part, the Earthly community came to our product mainly for the value proposition of <em>consistent builds</em>. Since we were now trying to sell the <em>fast builds</em> value prop instead, well, our audience just wasn’t qualified that way. The match was poor.</p>
<p>And the few organizations that did have both of these needs ended up becoming Satellite customers instead. Not that we minded the Satellite customers, but it wasn’t helping to validate Earthly CI as a product.</p>
<h2 id="validating-the-invalidation">Validating the Invalidation</h2>
<p>At this point, we could see that things weren’t going according to plan. Calls weren’t converting. Existing Satellite customers weren’t converting. And existing Earthly users weren’t converting.</p>
<p>We knew that we needed to change things up, but we weren’t yet thinking that Earthly CI itself was the problem.</p>
<p>At this point, the messaging on our website was saying “Earthly makes CI super simple” and most of the content on the first page was about CI, CI, CI. Gavin Johnson, our PMM, had the interesting idea to A/B-test swapping the word “CI” for the word “build” on our website: “Earthly makes builds super simple”. Inside I kinda thought that it was somewhat of a ridiculous idea… we’re trying to push for our grand vision, and we don’t want to be bucketed into the “builds” space by investors (a space with limited commercial success). CI is where it’s at. But I didn’t have any better ideas either, so we went with it.</p>
<p>And then the results came in.</p>
<p>This one-word change ended up <strong>doubling</strong> conversions to the “Get Earthly” page – the main CTA on our website. 🤯</p>
<p>Now we were starting to get really doubtful about this Earthly CI thing.</p>
<h2 id="lessons-from-another-life">Lessons From Another Life</h2>
<p><picture><source srcset="https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/5320-1000-3e1530d42.webp 1000w, https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/5320-1200-3e1530d42.webp 1200w" type="image/webp"><source srcset="https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/5320-1000-3e1530d42.png 1000w, https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/5320-1200-3e1530d42.png 1200w" type="image/png"><img height="400px" src="https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/5320-800-3e1530d42.png"></picture></p>
<p>In the fall of 2016, long before Earthly, I, along with two co-founders, a really smart code analysis scientist, and an incredibly dedicated team, started ShiftLeft (nowadays called <a href="https://qwiet.ai/">Qwiet.ai</a>). Our vision was to build a security agent that you could install in production and it would protect your cloud app from attacks on vulnerabilities that you have in your source code. This was an incredibly complex system, which required that we build an entire code analyzer that would work with multiple programming languages, runtime agents for individual runtimes, and a distributed backend to integrate everything. The complexity was akin to three companies, all being built by one tiny startup.</p>
<p>And yet, we somehow got one programming language to work end-to-end after over a year of effort, even if it was incredibly buggy initially. We tried to put it on the market - after all “if you’re not embarrassed by your first version, you launched too late”. After several attempts, we realized that it wasn’t appealing to the market. ShiftLeft being a security product, our target audience was heavily regulated enterprises. These enterprises, by definition, have a lot of red tape, and it is difficult to put anything in production without extensive bureaucracy. To make matters worse, you had to put this both in CI/CD, for the code analysis, and in production, for the runtime protection, thus creating a virtually impossible insertion motion.</p>
<p>But to overcome the difficulty of insertion, we always thought that it just needed more features. With enough features, surely the customer will accept the difficulty of insertion anyway! I mean… looking at the product it was obvious that it had all these rough edges. Maybe it’s more appealing if we smooth out the rough edges. It just needs to bake in the oven for a bit longer.</p>
<p>And bake it we did. For another year and a half. And still… Nobody. Wanted. It.</p>
<p>Looking back on the experience, we made many mistakes, which, at this point, sound like startup cliche:</p>
<ul>
<li>We did not build the product incrementally, with user feedback informing every step of the execution.</li>
<li>There were some early signals that certain aspects of the product did not align with what the industry needs, but we didn’t listen. We just kept building.</li>
</ul>
<p>Luckily, we later realized that this complex product can be split into two other products: a security code introspector for security experts, and a standalone code analyzer that is 40 times faster than any other code analyzer on the market. Yay! But we lost over a year of work and hired too many people to execute in a direction that never materialized into anything successful. It would have been so much more efficient if we started out by building smaller components of the end vision and selling those components as independent products first. The team would have been leaner, we would have had an MVP faster, and we would have had customer feedback much sooner, to help direct the roadmap.</p>
<p>My biggest regret from the experience was that we did not stop earlier when the signs were there.</p>
<p>Fast forward to today, learning from mistakes of the past, at Earthly we built everything incrementally. And we even put products on the market that initially seemed like purely engineering intermediate milestones. Each product builds on top of the previous achievements, thus allowing for incremental iteration with the customer in mind. We’re now seeing our latest incremental iteration not working in the marketplace. And, knowing what I know about early products, it’s not the missing features that are the problem.</p>
<h2 id="whats-next-for-earthly">What’s Next for Earthly?</h2>
<p><picture><source srcset="https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/5430-1000-9985df375.webp 1000w, https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/5430-1200-9985df375.webp 1200w" type="image/webp"><source srcset="https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/5430-1000-9985df375.png 1000w, https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/5430-1200-9985df375.png 1200w" type="image/png"><img height="400px" src="https://earthly.dev/blog/generated/assets/images/shutting-down-earthly-ci/5430-800-9985df375.png"></picture></p>
<p>Here’s how I rationalize what’s happening:</p>
<ul>
<li>People want faster builds.</li>
<li>People hate switching CIs.</li>
<li>There is a stigma toward new CIs in general. Specifically that they are undifferentiated. It’s hard to shake that bias, and we scare people off as soon as they see “CI” on our website.</li>
<li>Design-partner type of engagements don’t work when we try to engage with customers directly, due to the perceived high cost of migration.</li>
<li>The Earthly CI MVP isn’t validating, failing to create a significant enough early adopter group.</li>
<li>When we tell people that they can get faster builds without switching their CI (i.e.&nbsp;through Earthly Satellites), their eyes light up.</li>
</ul>
<p>Failing to create enough meaningful initial traction with an MVP, for some the conclusion might be simple: “It just needs more features,” or “just put it back in the oven.” But I know what a promising product’s initial traction looks like, and this is not it. If this were the real deal, there would be a group of people tolerating the absence of features for the benefits. But that’s not happening here, or at least not to a meaningful enough degree.</p>
<p>So, our conclusion is that we need to shut down Earthly CI and refocus our energy on what is working: Earthly and Earthly Satellites.</p>
<p>But Vlad, you’re deprecating the thing you just launched?</p>
<p>Well, yes. We failed fast. And that is a success in my book (or at least that’s what I keep telling myself to feel better about it). Imagine if we had built only Earthly CI from the get-go. Just like with ShiftLeft, the components of the end-vision ended up being more valuable than the original end-vision itself. Only this time, we discovered that much more efficiently.</p>
<h2 id="wrapping-up">Wrapping Up</h2>
<p>Earthly CI is shutting down on October 1st, 2023. If you are a user, you have my sincere gratitude for experimenting with Earthly CI - it’s because of people like you that there is any innovation in the world. You took a chance on us, and we appreciate it from the bottom of our hearts.</p>
<p>Migration off Earthly CI is really easy because Earthly works with any CI. And if you want to keep getting fast builds, you can plug in Earthly Satellites (there’s now a <a href="https://cloud.earthly.dev/">free tier</a> too - yay!). Despite Earthly CI having been marked as beta / experimental, we will fully support your transition off of it. We will be hands-on in the <a href="https://earthly.dev/slack">Earthly Slack community</a> to help you out every step of the way! We remain committed to serving our users with the utmost care.</p>
<p>It seems that Earthly Satellites are taking off, not just because we are delivering fast and consistent builds, but also, crucially, because we are <strong>letting users keep their own CI</strong>. Given this signal, it makes sense for us, as a company, to continue to invest in this direction. In fact, by shutting down Earthly CI, we have more time to execute on a number of things that the Earthly community have been asking us about:</p>
<ul>
<li><p>Satellite metrics – including CPU, memory, disk, and network I/O usage.</p></li>
<li><p>Build history – for both local and Satellites builds – in the web UI.</p></li>
<li><p>Auto-skip – the ability to skip a build instantly if the changed files don’t impact it.</p></li>
<li><p>The ability to execute Dockerfile builds remotely on Satellites, as a fast drop-in replacement for <code>docker build</code>.</p></li>
<li><p>Self-hosted Satellites (a better-supported version of <a href="https://docs.earthly.dev/ci-integration/remote-buildkit">our self-hosted, remote Buildkit</a>).</p></li>
<li><p>The ability to spread a single build onto multiple Satellites for added speed.</p></li>
<li><p>Compute v2 - fully distributed, serverless Satellites (this one will take a while to get right).</p></li>
</ul>
<p>If you’re not a user and you came to this post just for the story, then boy do I have some goodies for you to check out 🙂.</p>
<p>Earthly Satellites are ridiculously fast remote build runners that work seamlessly with any CI. It is available via Earthly Cloud and free to get started. Satellites are built on top of our open source build framework, Earthly. Earthly gives you write once, run anywhere build consistency, making it super easy to reproduce CI failures on your local computer. Earthly and Satellites together are like peanut butter and jelly – fast, consistent builds that work with any CI and are easy to debug locally. Come check us out at <a href="https://earthly.dev/">earthly.dev</a>!</p>
<div id="blog-bottom-cta-control">
<p>
<span>Earthly makes CI/CD super simple</span> <br> <span>Fast, repeatable CI/CD with an instantly familiar syntax – like Dockerfile and Makefile had a baby.</span>
</p>
<p>
<a href="https://earthly.dev/" target="_blank" onclick="blogHomepageCTAClick1()">Learn More</a>
</p>
</div>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Unity plan pricing and packaging updates (217 pts)]]></title>
            <link>https://blog.unity.com/news/plan-pricing-and-packaging-updates</link>
            <guid>37481344</guid>
            <pubDate>Tue, 12 Sep 2023 13:55:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.unity.com/news/plan-pricing-and-packaging-updates">https://blog.unity.com/news/plan-pricing-and-packaging-updates</a>, See on <a href="https://news.ycombinator.com/item?id=37481344">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><blockquote>
<p>Effective January 1, 2024, we will introduce a new Unity Runtime Fee that’s based on game installs. We will also add cloud-based asset storage, Unity DevOps tools, and AI at runtime at no extra cost to Unity subscription plans this November.</p>
</blockquote>

<p>As many of you know, the Unity Engine is in fact two substantial software components – the Unity Editor and the Unity Runtime. The Unity Runtime is code that executes on player devices and makes Made with Unity games work at scale, with billions of monthly downloads.</p>

<p>We are introducing a Unity Runtime Fee that is based upon each time a qualifying game is downloaded by an end user. We chose this because each time a game is downloaded, the Unity Runtime is also installed.&nbsp; Also we believe that an initial install-based fee allows creators to keep the ongoing financial gains from player engagement, unlike a revenue share.</p></div><div><h2><p>Thresholds for revenue and installs</p></h2></div><div><p>Games qualify for the Unity Runtime Fee after two criteria have been met: 1) the game has passed a minimum revenue threshold in the last 12 months, and 2) the game has passed a minimum lifetime install count. We set high revenue and game install thresholds to avoid impacting those who have yet to find scale, meaning they don’t need to pay the fee until they have reached significant success.</p>

<p>Only games that meet the following thresholds qualify for the Unity Runtime Fee:</p>

<ul><li><strong>Unity Personal </strong>and <strong>Unity Plus: </strong>Those<strong> </strong>that have made $200,000 USD or more in the last 12 months AND have at least 200,000 lifetime game installs.</li>
	<li><strong>Unity Pro </strong>and <strong>Unity Enterprise</strong>: Those that have made $1,000,000 USD or more in the last 12 months AND have at least 1,000,000 lifetime game installs.</li>
</ul></div><div><h2><p>Flexibility and discounts for Unity Personal, Pro, and Enterprise</p></h2></div><div><p>With this new policy, as of January 1, 2024, we will offer Unity Personal to anyone regardless of how much revenue they make to provide more flexibility in how creators manage their licenses. Once a game passes the revenue and install thresholds, the studio would pay a small flat fee for each install (see the table below).</p>

<p>To adjust for scale, Unity Pro and Unity Enterprise subscribers will be eligible for volume discounts that rapidly reduce the per-install cost of the Unity Runtime Fee. This means that in addition to other benefits, the cost of Unity Pro and Unity Enterprise licenses can be offset by the savings as the game grows.</p>

<p>Finally, we structured our fees so that they take into account the variability of game monetization between more established regions like North America and Europe versus emerging gaming regions such as India. A breakdown of the pricing and discount structure is below. See the <a href="http://www.unity.com/pricing-updates" target="_blank">FAQ</a> for additional details.</p></div><div><table><thead><tr><th>&nbsp;</th><th><strong>Unity Personal and Unity Plus</strong></th><th><strong>Unity Pro</strong></th><th><strong>Unity Enterprise</strong></th></tr><tr><td colspan="4"><strong>Unity Runtime Fee thresholds to be met</strong></td></tr><tr><td><strong>Revenue Threshold (USD)</strong></td><td>$200,000&nbsp;(last 12mo)</td><td>$1,000,000&nbsp;(last 12mo)</td><td>$1,000,000&nbsp;(last 12mo)</td></tr><tr><td><strong>Install&nbsp;Threshold</strong></td><td>200,000&nbsp;(life to date)</td><td>1,000,000&nbsp;(life to date)</td><td>1,000,000&nbsp;(life to date)</td></tr><tr><td><strong>Installs over the Install Threshold</strong></td><td colspan="3"><strong>Standard monthly rate</strong></td></tr><tr><td><strong>1–100,000</strong></td><td rowspan="4">$0.20 per install</td><td>$0.15 per install</td><td>$0.125 per install</td></tr><tr><td><strong>100,001–500,000</strong></td><td>$0.075 per install</td><td>$0.06 per install</td></tr><tr><td><strong>500,001–1,000,000</strong></td><td>$0.03 per install</td><td>$0.02 per install</td></tr><tr><td><strong>1,000,001+</strong></td><td>$0.02 per install</td><td>$0.01 per install</td></tr><tr></tr><tr><td><strong>Installs over the Install Threshold</strong></td><td colspan="3"><strong>Emerging market monthly rate</strong></td></tr><tr><td><strong>1+</strong></td><td>$0.02 per install</td><td>$0.01 per install</td><td>$0.005 per install</td></tr></thead></table>
</div><div><h2><p>Fee reduction for use of Unity services</p></h2></div><div><p>Qualifying customers may be eligible for credits toward the Unity Runtime Fee based on the adoption of Unity services beyond the Editor, such as Unity Gaming Services or Unity LevelPlay mediation for mobile ad-supported games. This program enables deeper partnership with Unity to succeed across the entire game lifecycle. Please reach out to your account manager to learn more.</p></div><div><h2><p>New services and tools. No seat price changes.</p></h2></div><div><p>This November, we will update some of the Unity subscription plans to add extra value. New capabilities include better collaboration (Unity DevOps), cloud-based asset management (Unity Asset Manager), role and access controls (Team Administration), and the ability to add AI functionality at runtime (Unity Sentis). These new tools and services will come with no increase in seat prices as we continue to help creators adapt to the growing complexity of game development. Here’s a breakdown:</p>

<ul><li><strong>All Unity plans</strong> will get <a href="https://unity.com/products/sentis" target="_blank">Unity Sentis</a>, which enables you to embed a running AI model in the Unity Runtime, inside your game or application, without needing to pay additional cloud-compute costs or introducing latency.</li>
	<li><strong>Unity Personal</strong> will include the Unity Asset Manager free tier (10GB storage total), a maximum of 3 Unity DevOps seats featuring 5GB of storage and 200 Windows build minutes, and Team Administration base roles.</li>
	<li><strong>Unity Pro</strong> will include the Unity Asset Manager (50GB of storage per seat, pooled for a team to share) along with an equal number of Unity DevOps seats featuring 5GB of storage and 200 Windows build minutes. Team Administration tools to manage access will also be included.</li>
	<li><strong>Unity Enterprise </strong>will include the Unity Asset Manager (120GB of storage per seat, pooled for a team to share) along with an equal number of Unity DevOps seats with 5GB of storage and 200 Windows build minutes. Team Administration tools, including custom roles and SSO, provide a higher degree of control.</li>
</ul><p>Finally, Unity Plus is being retired for new subscribers effective today, September 12, 2023, to simplify the number of plans we offer. Existing subscribers do not need to take immediate action and will receive an email mid-October with an offer to upgrade to Unity Pro, for one year, at the current Unity Plus price.</p>

<p>For more information, see the <a href="http://www.unity.com/pricing-updates" target="_blank">detailed FAQ</a>, <a href="https://support.unity.com/hc/en-us/requests/new" target="_blank">contact Unity support</a>, talk with us on the <a href="https://forum.unity.com/threads/unity-plan-pricing-and-packaging-updates.1482750/" target="_blank">Unity forums</a>, or contact your account manager. Thank you for creating with Unity.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Relativity of Wrong (1989) (110 pts)]]></title>
            <link>https://hermiene.net/essays-trans/relativity_of_wrong.html</link>
            <guid>37481166</guid>
            <pubDate>Tue, 12 Sep 2023 13:45:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hermiene.net/essays-trans/relativity_of_wrong.html">https://hermiene.net/essays-trans/relativity_of_wrong.html</a>, See on <a href="https://news.ycombinator.com/item?id=37481166">Hacker News</a></p>
<div id="readability-page-1" class="page">





<div>
<p>I received a letter from a reader the other day. It was handwritten in crabbed penmanship so that it was very difficult to read. Nevertheless, I tried to make it out just in case it might prove to be important.</p>

<p>In the first sentence, he told me he was majoring in English Literature, but felt he needed to teach me science. (I sighed a bit, for I knew very few English Lit majors who are equipped to teach me science, but I am very aware of the vast state of my ignorance and I am prepared to learn as much as I can from anyone, however low on the social scale, so I read on.)</p>

<p>It seemed that in one of my innumerable essays, here and elsewhere, I had expressed a certain gladness at living in a century in which we finally got the basis of the Universe straight.</p>

<p>I didn't go into detail in the matter, but what I meant was that we now know the basic rules governing the Universe, together with the gravitational interrelationships of its gross components, as shown in the theory of relativity worked out between 1905 and 1916. We also know the basic rules governing the subatomic particles and their interrelationships, since these are very neatly described by the quantum theory worked out between 1900 and 1930. What's more, we have found that the galaxies and clusters of galaxies are the basic units of the physical Universe, as discovered between 1920 and 1930.</p>

<p>These are all twentieth-century discoveries, you see.</p>

<p>The young specialist in English Lit, having quoted me, went on to lecture me severely on the fact that in <em>every</em> century people have thought they understood the Universe at last, and in <em>every</em> century they were proven to be wrong. It follows that the one thing we can say about out modern "knowledge" is that it is <em>wrong</em>.</p>

<p>The young man then quoted with approval what Socrates had said on learning that the Delphic oracle had proclaimed him the wisest man in Greece. "If I am the wisest man," said Socrates, "it is because I alone know that I know nothing." The implication was that I was very foolish because I knew a great deal.</p>

<p>Alas, none of this was new to me. (There is very little that is new to me; I wish my corresponders would realize this.) This particular thesis was addressed to me a quarter of a century ago by John Campbell, who specialized in irritating me. He also told me that all theories are proven wrong in time.</p>

<p>My answer to him was, "John, when people thought the Earth was flat, they were wrong. When people thought the Earth was spherical, they were wrong. But if <em>you</em> think that thinking the Earth is spherical is <em>just as wrong</em> as thinking the Earth is flat, then your view is wronger than both of them put together."</p>

<p>The basic trouble, you see, is that people think that "right" and "wrong" are absolute; that everything that isn't perfectly and completely right is totally and equally wrong.</p>

<p>However, I don't think that's so. It seems to me that right and wrong are fuzzy concepts, and I will devote this essay to an explanation of why I think so.</p>
</div>

<div>
<p>First, let me dispose of Socrates because I am sick and tired of this pretense that knowing you know nothing is a mark of wisdom.</p>

<p>No one knows <em>nothing</em>. In a matter of days, babies learn to recognize their mothers.</p>

<p>Socrates would agree, of course, and explain that knowledge of trivia is not what he means. He means that in the great abstractions over which human beings debate, one should start without preconceived, unexamined notions, and that he alone knew this. (What an enormously arrogant claim!)</p>

<p>In his discussions of such matters as "What is justice?" or "What is virtue?" he took the attitude that he knew nothing and had to be instructed by others. (This is called "Socratic irony," for Socrates knew very well that he knew a great deal more than the poor souls he was picking on.) By pretending ignorance, Socrates lured others into propounding their views on such abstractions. Socrates then, by a series of ignorant-sounding questions, forced the others into such a mélange of self-contradictions that they would finally break down and admit they didn't know what they were talking about.</p>

<p>It is the mark of the marvelous toleration of the Athenians that they let this continue for decades and that it wasn't till Socrates turned seventy that they broke down and forced him to drink poison.</p>
</div>

<div>
<p>Now where do we get the notion that "right" and "wrong" are absolutes? It seems to me that this arises in the early grades, when children who know very little are taught by teachers who know very little more.</p>

<p>Young children learn spelling and arithmetic, for instance, and here we tumble into apparent absolutes.</p>

<p>How do you spell "sugar?" Answer: s-u-g-a-r. That is <em>right</em>. Anything else is <em>wrong</em>.</p>

<p>How much is 2 + 2? The answer is 4. That is <em>right</em>. Anything else is <em>wrong</em>.</p>

<p>Having exact answers, and having absolute rights and wrongs, minimizes the necessity of thinking, and that pleases both students and teachers. For that reason, students and teachers alike prefer short-answer tests to essay tests; multiple-choice over blank short-answer tests; and true-false tests over multiple-choice.</p>

<p>But short-answer tests are, to my way of thinking, useless as a measure of the student's understanding of a subject. They are merely a test of the efficiency of his ability to memorize.</p>

<p>You can see what I mean as soon as you admit that right and wrong are relative.</p>

<p>How do you spell "sugar?" Suppose Alice spells it p-q-z-z-f and Genevieve spells it s-h-u-g-e-r. Both are wrong, but is there any doubt that Alice is wronger than Genevieve? For that matter, I think it is possible to argue that Genevieve's spelling is superior to the "right" one.</p>

<p>Or suppose you spell "sugar": s-u-c-r-o-s-e, or C<sub>12</sub>H<sub>22</sub>O<sub>11</sub>. Strictly speaking, you are wrong each time, but you're displaying a certain knowledge of the subject beyond conventional spelling.</p>

<p>Suppose then the test question was: how many different ways can you spell "sugar?" Justify each.</p>

<p>Naturally, the student would have to do a lot of thinking and, in the end, exhibit how much or how little he knows. The teacher would also have to do a lot of thinking in the attempt to evaluate how much or how little the student knows. Both, I imagine, would be outraged.</p>

<p>Again, how much is 2 + 2? Suppose Joseph says: 2 + 2 = purple, while Maxwell says: 2 + 2 = 17. Both are wrong but isn't it fair to say that Joseph is wronger than Maxwell?</p>

<p>Suppose you said: 2 + 2 = an integer. You'd be right, wouldn't you? Or suppose you said: 2 + 2 = an even integer. You'd be righter. Or suppose you said: 2 + 2 = 3.999. Wouldn't you be <em>nearly</em> right?</p>

<p>If the teacher wants 4 for an answer and won't distinguish between the various wrongs, doesn't that set an unnecessary limit to understanding?</p>

<p>Suppose the question is, how much is 9 + 5?, and you answer 2. Will you not be excoriated and held up to ridicule, and will you not be told that 9 + 5 = 14?</p>

<p>If you were then told that 9 hours had pass since midnight and it was therefore 9 o'clock, and were asked what time it would be in 5 more hours, and you answered 14 o'clock on the grounds that 9 + 5 = 14, would you not be excoriated again, and told that it would be 2 o'clock? Apparently, in that case, 9 + 5 = 2 after all.</p>

<p>Or again suppose, Richard says: 2 + 2 = 11, and before the teacher can send him home with a note to his mother, he adds, "To the base 3, of course." He'd be right.</p>

<p>Here's another example. The teacher asks: "Who is the fortieth President of the United States?" and Barbara says, "There isn't any, teacher."</p>

<p>"Wrong!" says the teacher, "Ronald Reagan is the fortieth President of the United States."</p>

<p>"Not at all," says Barbara, "I have here a list of all the men who have served as President of the United States under the Constitution, from George Washington to Ronald Reagan, and there are only thirty-nine of them, so there is no fortieth President."</p>

<p>"Ah," says the teacher, "but Grover Cleveland served two nonconsecutive terms, one from 1885 to 1889, and the second from 1893 to 1897. He counts as both the twenty-second and twenty-fourth President. That is why Ronald Reagan is the thirty-ninth person to serve as President of the United States, and is, at the same time, the fortieth President of the United States."</p>

<p>Isn't that ridiculous? Why should a person be counted twice if his terms are nonconsecutive, and only once if he served two consecutive terms? Pure convention! Yet Barbara is marked wrong—just as wrong as if she had said that the fortieth President of the United States is Fidel Castro.</p>

<p>Therefore, when my friend the English Literature expert tells me that in every century scientists think they have worked out the Universe and are <em>always wrong</em>, what I want to know is <em>how</em> wrong are they? Are they always wrong to the same degree? Let's take an example.</p>
</div>

<div>
<p>In the early days of civilization, the general feeling was that the Earth was flat.</p>

<p>This was not because people were stupid, or because they were intent on believing silly things. They felt it was flat on the basis of sound evidence. It was <em>not</em> just a matter of "That's how it looks," because the Earth does <em>not</em> look flat. It looks chaotically bumpy, with hills, valleys, ravines, cliffs, and so on.</p>

<p>Of course, there are plains where, over limited areas, the Earth's surface <em>does</em> look fairly flat. One of those plains is in the Tigris-Euphrates area where the first historical civilization (one with writing) developed, that of the Sumerians.</p>

<p>Perhaps it was the appearance of the plain that may have persuaded the clever Sumerians to accept the generalization that the Earth was flat; that if you somehow evened out all the elevations and depressions, you would be left with flatness. Contributing to the notion may have been the fact that stretches of water (ponds and lakes) looked pretty flat on quiet days.</p>

<p>Another way of looking at it is to ask what is the "curvature" of Earth's surface. Over a considerable length, how much does the surface deviate (on the average) from perfect flatness. The flat-Earth theory would make it seem that the surface doesn't deviate from flatness at all, that its curvature is 0 to the mile.</p>

<p>Nowadays, of course, we are taught that the flat-Earth theory is <em>wrong</em>; that it is all wrong, terribly wrong, absolutely. But it isn't. The curvature of the Earth is <em>nearly</em> 0 per mile, so that although the flat-Earth theory is wrong, it happens to be <em>nearly</em> right. That's why the theory lasted so long.</p>

<p>There were reasons, to be sure, to find the flat-Earth theory unsatisfactory and, about 350 B.C., the Greek philosopher Aristotle summarized them. First, certain stars disappeared beyond the Southern Hemisphere as one traveled north, and beyond the Northern Hemisphere as one traveled south. Second, the Earth's shadow on the Moon during a lunar eclipse was always the arc of a circle. Third, here on Earth itself, ships disappeared beyond the horizon hull-first in whatever direction they were traveling.</p>

<p>All three observations could not be reasonably explained if the Earth's surface were flat, but could be explained by assuming the Earth to be a sphere.</p>

<p>What's more, Aristotle believed that all solid matter tended to move toward a common center, and if solid matter did this, it would end up as a sphere. A given volume of matter is, on the average, closer to a common center if it is a sphere than if it is any other shape whatever.</p>

<p>About a century after Aristotle, the Greek philosopher Eratosthenes noted that the Sun cast a shadow of different lengths at different latitudes (all the shadows would be the same length if the Earth's surface were flat). From the difference in shadow length, he calculated the size of the earthly sphere and it turned out to be 25,000 miles in circumference.</p>

<p>The curvature of such a sphere is about 0.000126 per mile, a quantity very close to 0 per mile as you can see, and one not easily measured by the techniques at the disposal of the ancients. The tiny difference between 0 and 0.000126 accounts for the fact that it took so long to pass from the flat Earth to the spherical Earth.</p>

<p>Mind you, even a tiny difference, such at that between 0 and 0.000126, can be extremely important. That difference mounts up. The Earth cannot be mapped over large areas with any accuracy at all if the difference isn't taken into account and if the Earth isn't considered a sphere rather than a flat surface. Long ocean voyages can't be undertaken with any reasonable way of locating one's own position in the ocean unless the Earth is considered spherical rather than flat.</p>

<p>Furthermore, the flat Earth presupposes the possibility of an infinite Earth, or of the existence of an "end" to the surface. The spherical Earth, however, postulates an Earth that is both endless and yet finite, and it is the latter postulate that is consistent with all later findings.</p>

<p>So although the flat-Earth theory is only slightly wrong and is a credit to its inventors, all things considered, it is wrong enough to be discarded in favor of the spherical-Earth theory.</p>
</div>

<div>
<p>And yet is the Earth a sphere?</p>

<p>No, it is <em>not</em> a sphere; not in the strict mathematical sense. A sphere has certain mathematical properties—for instance, all diameters (that is, all straight lines that pass from one point on its surface, through the center, to another point on its surface) have the same length.</p>

<p>That, however, is not true of the Earth. Various diameters of the Earth differ in length.</p>

<p>What gave people the notion the Earth wasn't a true sphere? To begin with, the Sun and the Moon have outlines that are perfect circles within the limits of measurement in the early days of the telescope. This is consistent with the supposition that the Sun and Moon are perfectly spherical in shape.</p>

<p>However, when Jupiter and Saturn were observed by the first telescopic observers, it became quickly apparent that the outlines of those planets were not circles, but distinct ellipses. That meant that Jupiter and Saturn were not true spheres.</p>

<p>Isaac Newton, toward the end of the seventeenth century, showed that a massive body would form a sphere under the pull of gravitational forces (exactly as Aristotle had argued), but only if it were not rotating. If it were rotating, a centrifugal effect would be set up which would lift the body's substance against gravity, and the effect would be greater the closer to the equator you progressed. The effect would also be greater the more rapidly a spherical object rotated and Jupiter and Saturn rotated very rapidly indeed.</p>

<p>The Earth rotated much more slowly than Jupiter or Saturn so the effect should be smaller, but it should still be there. Actual measurements of the curvature of the Earth were carried out in the eighteenth century and Newton was proved correct.</p>

<p>The Earth has an equatorial bulge, in other words. It is flattened at the poles. It is an "oblate spheroid" rather than a sphere. This means that the various diameters of the earth differ in length. The longest diameters are any of those that stretch from one point on the equator to an opposite point on the equator. The "equatorial diameter" is 12,755 kilometers (7,927 miles). The shortest diameter is from the North Pole to the South Pole and this "polar diameter" is 12,711 kilometers (7,900 miles).</p>

<p>The difference between the longest and shortest diameters is 44 kilometers (27 miles), and that means that the "oblateness" of the Earth (its departure from true sphericity) is 44/12,755, or 0.0034. This amounts to 1/3 of 1 percent.</p>

<p>To put it another way, on a flat surface, curvature is 0 per mile everywhere. On Earth's spherical surface, curvature is 0.000126 per mile everywhere (or 8 inches per mile). On Earth's oblate spheroidical surface, the curvature varies from 7.973 inches to the mile to 8.027 inches to the mile.</p>

<p>The correction in going from spherical to oblate spheroidal is much smaller than going from flat to spherical. Therefore, although the notion of the Earth as sphere is wrong, strictly speaking, it is not <em>as</em> wrong as the notion of the Earth as flat.</p>

<p>Even the oblate-spheroidal notion of the Earth is wrong, strictly speaking. In 1958, when the satellite <em>Vanguard 1</em> was put into orbit about the Earth, it was able to measure the local gravitational pull of the Earth—and therefore its shape—with unprecedented precision. It turned out that the equatorial bulge south of the equator was slightly bulgier than the bulge north of the equator, and that the South Pole sea level was slightly nearer the center of the Earth than the North Pole sea level was.</p>

<p>There seemed no other way of describing this than by saying the Earth was pearshaped and at once many people decided that the Earth was nothing like a sphere but was shaped like a Bartlett pear dangling in space. Actually, the pearlike deviation from oblate-spheroid perfect was a matter of yards rather than miles and the adjustment of curvature was in the millionths of an inch per mile.</p>

<p>In short, my English Lit friend, living in a mental world of absolute rights and wrongs, may be imagining that because all theories are <em>wrong</em>, the Earth may be thought spherical now, but cubical next century, and a hollow icosahedron the next, and a doughnut shape the one after.</p>

<p>What actually happens is that once scientists get hold of a good concept they gradually refine and extend if with a greater and greater subtlety as their instruments of measurement improve. Theories are not so much wrong as incomplete.</p>
</div>

<div>
<p>This can be pointed out in many other cases than just the shape of the Earth. Even when a new theory seems to represent a revolution, it usually arises out of small refinements. If something more than a small refinement were needed, then the old theory would never have endured.</p>

<p>Copernicus switched from an Earth-centered planetary system to a Sun-centered one. In doing so, he switched from something that was obvious to something that was apparently ridiculous. However, it was a matter of finding better ways of calculating the motion of the planets in the sky and, eventually, the geocentric theory was just left behind. It was precisely because the old theory gave results that were fairly good by the measurement standards of the time that kept it in being so long.</p>

<p>Again, it is because the geological formations of the Earth change <em>so</em> slowly and the living things upon it evolve <em>so</em> slowly that it seemed reasonable at first to suppose that there was <em>no</em> change and that Earth and life always existed as they do today. If that were so, it would make no difference whether Earth and life were billions of years old or thousands. Thousands were easier to grasp.</p>

<p>But when careful observation showed that Earth and life were changing at a rate that was very tiny but <em>not</em> zero, then it became clear that Earth and life had to be very old. Modern geology came into being, and so did the notion of biological evolution.</p>

<p>If the rate of change were more rapid, geology and evolution would have reached their modern state in ancient times. It is only because the difference between the rate of change in a static Universe and the rate of change in an evolutionary one is that between zero and very nearly zero that the creationists can continue propagating their folly.</p>

<p>Again, how about the two great theories of the twentieth century; relativity and quantum mechanics?</p><p>Newton's theories of motion and gravitation were very close to right, and they would have been absolutely right if only the speed of light were infinite. However, the speed of light is finite, and that had to be taken into account in Einstein's relativistic equations, which were an extension and refinement of Newton's equations.</p>

<p>You might say that the difference between infinite and finite is itself infinite, so why didn't Newton's equations fall to the ground at once? Let's put it another way, and ask how long it takes light to travel over a distance of a meter.</p>

<p>If light traveled at infinite speed, it would take light 0 seconds to travel a meter. At the speed at which light actually travels, however, it takes it 0.0000000033 seconds. It is that difference between 0 and 0.0000000033 that Einstein corrected for.</p>

<p>Conceptually, the correction was as important as the correction of Earth's curvature from 0 to 8 inches per mile was. Speeding subatomic particles wouldn't behave the way they do without the correction, nor would particle accelerators work the way they do, nor nuclear bombs explode, nor the stars shine. Nevertheless, it was a tiny correction and it is no wonder that Newton, in his time, could not allow for it, since he was limited in his observations to speeds and distances over which the correction was insignificant.</p>

<p>Again, where the prequantum view of physics fell short was that it didn't allow for the "graininess" of the Universe. All forms of energy had been thought to be continuous and to be capable of division into indefinitely smaller and smaller quantities.</p>

<p>This turned out to be not so. Energy comes in quanta, the size of which is dependent upon something called Planck's constant. If Planck's constant were equal to 0 erg-seconds, then energy would be continuous, and there would be no grain to the Universe. Planck's constant, however, is equal to 0.000000000000000000000000066 erg-seconds. That is indeed a tiny deviation from zero, so tiny that ordinary questions of energy in everyday life need not concern themselves with it. When, however, you deal with subatomic particles, the graininess is sufficiently large, in comparison, to make it impossible to deal with them without taking quantum considerations into account.</p>
</div>

<div>
<p>Since the refinements in theory grow smaller and smaller, even quite ancient theories must have been sufficiently right to allow advances to be made; advances that were not wiped out by subsequent refinements.</p>

<p>The Greeks introduced the notion of latitude and longitude, for instance, and made reasonable maps of the Mediterranean basin even without taking sphericity into account, and we still use latitude and longitude today.</p>

<p>The Sumerians were probably the first to establish the principle that planetary movements in the sky exhibit regularity and can be predicted, and they proceeded to work out ways of doing so even though they assumed the Earth to be the center of the Universe. Their measurements have been enormously refined but the principle remains.</p>

<p>Newton's theory of gravitation, while incomplete over vast distances and enormous speeds, is perfectly suitable for the Solar System. Halley's Comet appears punctually as Newton's theory of gravitation and laws of motion predict. All of rocketry is based on Newton, and <em>Voyager II</em> reached Uranus within a second of the predicted time. None of these things were outlawed by relativity.</p>

<p>In the nineteenth century, before quantum theory was dreamed of, the laws of thermodynamics were established, including the conservation of energy as first law, and the inevitable increase of entropy as the second law. Certain other conservation laws such as those of momentum, angular momentum, and electric charge were also established. So were Maxwell's laws of electromagnetism. All remained firmly entrenched even after quantum theory came in.</p>

<p>Naturally, the theories we now have might be considered wrong in the simplistic sense of my English Lit correspondent, but in a much truer and subtler sense, they need only be considered incomplete.</p>

<p>For instance, quantum theory has produced something called "quantum weirdness" which brings into serious question the very nature of reality and which produces philosophical conundrums that physicists simply can't seem to agree upon. It may be that we have reached a point where the human brain can no longer grasp matters, or it may be that quantum theory is incomplete and that once it is properly extended, all the "weirdness" will disappear.</p>

<p>Again, quantum theory and relativity seem to be independent of each other, so that while quantum theory makes it seem possible that three of the four known interactions can be combined into one mathematical system, gravitation—the realm of relativity—as yet seems intransigent.</p>

<p>If quantum theory and relativity can be combined, a true "unified field theory" may become possible.</p>

<p>If all this is done, however, it would be a still finer refinement that would affect the edges of the known—the nature of the big bang and the creation of the Universe, the properties at the center of black holes, some subtle points about the evolution of galaxies and supernovas, and so on.</p>

<p>Virtually all that we know today, however, would remain untouched and when I say I am glad that I live in a century when the Universe is essentially understood, I think I am justified.</p>
</div>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sony develops energy harvesting module from electromagnetic wave noise (137 pts)]]></title>
            <link>https://www.sony-semicon.com/en/news/2023/2023090701.html</link>
            <guid>37480512</guid>
            <pubDate>Tue, 12 Sep 2023 13:02:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sony-semicon.com/en/news/2023/2023090701.html">https://www.sony-semicon.com/en/news/2023/2023090701.html</a>, See on <a href="https://news.ycombinator.com/item?id=37480512">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              <article>
                  <p><span><span lang="EN-US">Atsugi, Japan — Sony Semiconductor Solutions Corporation (SSS) today announced that it has developed an energy harvesting<sup>*1</sup> module that uses electromagnetic wave noise energy.</span></span></p>
<p><span lang="EN-US">The new module applies technology that SSS has cultivated in the tuner development process to generate power from electromagnetic wave noise with a high level of efficiency. For example, this technology can use the constant electromagnetic wave noise generated by robots inside factories, monitors and lighting in offices, monitors and TVs in stores and homes, and the like to provide the stable power supply needed to run low-power consumption IoT sensors and communications equipment.<o:p></o:p></span></p>
<p><span lang="EN-US">With attention on the challenge of providing power to the increasing number of IoT devices as they grow in popularity and sophistication, this highly efficient energy harvesting technology shows promise for a wide range of applications. SSS aims to employ the new technology as part of its effort to build a power circulation model, thereby contributing to the development of a sustainable IoT society.<o:p></o:p></span></p>
<p><span>*1:&nbsp;&nbsp; Technology that harvests minute amounts of energy that exist in the environment and living things for conversion into electricity.</span></p>

<div>
<p><img src="https://www.sony-semicon.com/files/62/news/n_2023_2023090701/image.jpg" width="2111" height="974"></p>
<p><span><span lang="EN-US">Energy harvesting framework using electromagnetic wave noise</span></span></p>
</div>
<div>
<p><img src="https://www.sony-semicon.com/files/62/news/n_2023_2023090701/usecase.jpg" width="2400" height="438"></p>
<p><span lang="EN-US">Usage scenarios<br></span><span lang="EN-US">Factory (Left), Office (Middle), Retail (Right)</span></p>

</div>
<p><span lang="EN-US">Energy harvesting is a technology that is expected to contribute to both the development of IoT and the sustainability of the global environment, with research being carried out mainly in fields such as electrical waves, light, heat, and vibration. SSS’s new technology is the energy harvesting technology to generate power utilizing the electromagnetic wave noise that all electrical equipment generates.</span></p>
<p><span lang="EN-US">Based on antenna technology created during tuner development at SSS, this new module uses the metal parts of electronic devices that serve as the source of electromagnetic wave noise as part of an antenna and employs a rectifier circuit<sup>*2</sup> with enhanced electricity conversion efficiency, for a highly original structure. This allows it to convert electromagnetic wave noise in a range of several Hz to 100 MHz into electrical energy and supply power to low-power consumption IoT sensors and communications equipment, or to charge batteries, despite its compact size. This is the industry’s first<sup>*3</sup> energy harvesting technology based on this method that achieves highly efficient power generation. By efficiently utilizing previously ignored electromagnetic wave noise as a new power source, it enables a stable power supply for equipment.<o:p></o:p></span></p>
<p><span lang="EN-US">The minimal number of constituent components used in the module yields a compact design that allows for greater freedom of installation. Also, as long as electronic devices are powered, energy can be harvested even while they are not in active use, making this technology promising in a wide variety of usage situations such as factories, offices, stores, and homes, both indoors and outdoors.<o:p></o:p></span></p>
<p><span>*2:&nbsp;&nbsp; An electrical circuit that converts alternating current to direct current. In general, alternating current is used to transmit electrical energy, so a rectifier circuit is used in power sources of equipment that require direct current.</span></p>
<p><span>*3:&nbsp;&nbsp; As an energy harvesting technology. According to SSS research. As of announcement on September 7, 2023.</span></p>


<div>
<p><img src="https://www.sony-semicon.com/files/62/news/n_2023_2023090701/module.jpg" width="2442" height="1141"></p>
<p>Developed module (size: 7 mm square)</p>
</div>

<p><strong><span lang="EN-US">Main Features</span></strong></p>
<ul>
<li><span lang="EN-US"><span><strong>High level of power generation<br></strong></span></span>Utilizing electronic equipment that generates a significant amount of electromagnetic wave noise such as household appliances, computers, lighting equipment, vending machines, elevators, automobiles, and industrial equipment as an energy source enables this module to harvest from several dozen μW to several dozen mW of power. Doing so makes it possible to supply power to low-power consumption IoT sensors and communications equipment</li>
<li><span lang="EN-US"><strong><span>Applicable to a wide range of use cases<br></span></strong></span><strong>-</strong> As long as electronic devices are powered, power can be harvested even when they are not in active use. This method therefore differs from other energy harvesting methods which use sunlight, electrical waves, and temperature differences, all of which are susceptible to environmental factors such as lighting brightness and indoor environments. Thus, the new module enables continuous harvesting.<br> <strong>-</strong> The minimal number of constituent components used in the module yields a compact design that allows for greater freedom of installation.</li>
</ul>
<ul>
<li><strong><span lang="EN-US"><span>Device status can be identified<br></span></span></strong>Because this technology continuously harvests electromagnetic wave noise from electronic devices, it can also identify the internal status of the electronic device by detecting changes in the harvested voltage. This means, for instance, that it can be used for applications such as detecting whether lighting is functioning normally or predicting device failure, for example in robots with built-in motors.</li>
</ul>
<p><span lang="EN-US">SSS looks forward to working with partners from various industries to develop products based on this technology, which shows promise across a wide variety of applications.<o:p></o:p></span></p>

              </article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[QtWayland 6.6 Brings Robustness Through Compositor Handoffs (102 pts)]]></title>
            <link>http://blog.davidedmundson.co.uk/blog/qt6_wayland_robustness/</link>
            <guid>37480331</guid>
            <pubDate>Tue, 12 Sep 2023 12:47:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://blog.davidedmundson.co.uk/blog/qt6_wayland_robustness/">http://blog.davidedmundson.co.uk/blog/qt6_wayland_robustness/</a>, See on <a href="https://news.ycombinator.com/item?id=37480331">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-484">
	
	<!-- .entry-header -->

	<div>
		<p>Every release has a killer feature. Qt 6.6 features the opposite - staying alive. This blog post describes work to make Qt clients more robust and seemlessly migrate between compositors, providing resistance against compositor crashes and more.</p>
<h2>Prologue</h2>
<p>Right now if you restart pulseaudio your sound might cut out, restart NetworkManager and you lose your wifi, restart an X11 window manager and your decorations disappear.</p>
<p>But within a second it's all back to normal exactly where you left off with everything recovering fine.</p>
<p>This isn't true for display servers. If X11 restarts you're back at the login prompt. All drafts lost, games unsaved, work wasted.</p>
<h2>Past</h2>
<p>For X11 this was unfixable; clients relied on memory stored by the Xserver, they made synchronous calls that were expected to return values, and multiple clients talked to multple clients.</p>
<p>This was a real problem in my early days of Linux, X11 would lock up frequently enough that most distributions had a shortcut key to restart the server and send you back to the login prompt.</p>
<p>It's less of an issue now as X11 has been in a lengthy period of feature freeze.</p>
<h2>Present</h2>
<p>Wayland makes it possible to fix all this. Memory allocations are client side, all operations are async, all protocols are designed that the compositor always has complete control.</p>
<p>Yet the current user-facing state is <strong>considerably worse</strong>:</p>
<ul>
<li>
<p>Compositors and displays servers are now the same process, doubling the space for errors</p>
</li>
<li>
<p>Compositors are typically extensible with 3rd party plugins and scripts</p>
</li>
<li>
<p>The wayland security model means the compositor absorbs even more functions from global shortcuts to screencasting and input-method handling</p>
</li>
<li>
<p>The wayland ecosystem  is not in a period of feature freeze with wayland protocols constantly evolving to cover missing features and new ideas.</p>
<p>Even if there was a perfect compositor:</p>
</li>
<li>
<p><a href="https://bugs.kde.org/report.cgi?bug_severity=crash&amp;bug_status=RESOLVED&amp;classification=Plasma&amp;cumulate=0&amp;product=kwin&amp;resolution=FIXED&amp;resolution=UPSTREAM&amp;resolution=DOWNSTREAM&amp;saved_report_id=14&amp;x_axis_field=resolution&amp;width=1024&amp;height=600&amp;action=wrap&amp;format=pie">40% of kwin's crash bug reports are either upstream or downstream causes</a> </p>
</li>
<li>
<p>The current compositor developer experience is limited with developers having to relogin and restart their apps and development setup just to test their latest changes.</p>
</li>
</ul>
<h2>Plan</h2>
<p>The solution for this? Instead of exiting when the compositor closes, simply...don't!</p>
<p>If we could connect to a new compositor we just need to send the right amount of information to bring it in sync and notify the application code of any changes to bring this in sync.</p>
<p>For Qt applications all this information is handled in the backend, in the Wayland Qt Platform Abstraction (QPA).</p>
<p>Qt already has to handle screens and input devices being removed, clipboards being revoked and drag and drops cancelled. Supporting a whole reset isn't introducing any new work, we just have to trigger all of these actions at once, then reconnect to the newly restored compositor and restore our contents.</p>
<p>Applications already have to support all of these events too as well as handle callbacks to redraw buffers. There's no changes needed at an application code level, it's all done as transparently as possible. </p>
<p>Handling OpenGL is a challenge, right now we don't have a way to keep that alive. Fortunately we put in lots of effort previously in supporting GPU resets throughout the Qt stack. The QtWayland backend fakes to the applications that a GPU reset has occured through the Qt abstractions.</p>
<p>For the majority of applications including all QtQuick users this happens automatically and flawlessly, building on the work <a href="https://blog.davidedmundson.co.uk/blog/plasma-rendering-handling-nvidia-context-loss/" title="that we put in previously">that we put in previously</a>.</p>
<p>Whilst the overall concepts might sound invasive, the final merge-request to support all of this for all Qt applications was fewer lines than supporting middle-click paste.</p>
<p>Almost no work needs doing on the compositor side. For a compositor there's no difference between a new client, and a client that was running previously reconnecting. The only big change we made within Kwin is having a helper process so the whole process can be seemless and race-free.</p>
<h2>Proof</h2>
<p><iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/u4HnwqidYFo?si=zmIxcs9555Zv6gsP" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<h2>Path Forward</h2>
<p>This post is about Qt, but the world is bigger than that. Not only does this technique work here, but we have pending patches for GTK, SDL and even XWayland, with key parts of SDL merged but disabled already.</p>
<p>The challenge for the other toolkits is we can't use the same OpenGL trick as Qt. They either lack GPU reset handling either at a toolkit level or within the applications. </p>
<p>Supporting OpenGL requires new infrastructure. We've tried from the start to get some infrastructure in place to allow this.It was clear that proposing library changes for client reconnection support was an uphill battle whilst being unproven in the wild.</p>
<p>After Qt6 is rolled out to a wider audience and shown to work reliably, we'll refocus efforts on pushing upstream changes to the other platforms. </p>
<h2>Potential Perks</h2>
<p>This isn't just about crashes. If support becomes mainstream there will be additional opportunities:</p>
<ul>
<li>
<p>We can easily upgrade to new features without having to log out and back. This is one of the reasons why kwin development is happening at such a rapid pace in recent months. We're not having to test in fake nested sessions or waste time logging in and setting up between changes.</p>
</li>
<li>
<p>We can support multihead, running different compositors per group of outputs and move seemlessly between them.</p>
</li>
<li>
<p>It's feasible to switch between compositors at runtime. With the application handling the reconnect logic, they can easily handle the case where compositor feature sets vary.</p>
<p><iframe loading="lazy" width="560" height="315" src="https://www.youtube-nocookie.com/embed/JYfzAuRmBjo?si=jBnMHRqb4kmpX4ot" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</p></li>
<li>
<p>Checkpoint restore in userspace, being able to suspend your application to disk and then pick up where you left off like nothing happened. It could never work for X applications, but with wayland reconnect support we can make it work. </p>
</li>
</ul>
<p><iframe loading="lazy" width="560" height="315" src="https://www.youtube-nocookie.com/embed/bWWQT3HamBw?si=h0bsJeMYR1cslZtx" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<h2>Participating</h2>
<p>More information about the long term goal this can be found at <a href="https://invent.kde.org/plasma/kwin/-/wikis/Restarting">the kwin wiki</a>, or each out to me directly if you want to add support.</p>
<p>Discuss this at <a href="https://discuss.kde.org/t/protected-qtwayland-6-6-brings-robustness-through-compositor-handoffs/4866">discuss.kde.org</a>.</p>
	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Vitalik Buterin reveals X account hack was caused by SIM-swap attack (170 pts)]]></title>
            <link>https://cointelegraph.com/news/vitalik-buterin-reveals-x-account-hack-was-caused-by-sim-swap-attack</link>
            <guid>37479774</guid>
            <pubDate>Tue, 12 Sep 2023 12:03:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cointelegraph.com/news/vitalik-buterin-reveals-x-account-hack-was-caused-by-sim-swap-attack">https://cointelegraph.com/news/vitalik-buterin-reveals-x-account-hack-was-caused-by-sim-swap-attack</a>, See on <a href="https://news.ycombinator.com/item?id=37479774">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-gtm-locator="a1" data-v-398ae7b2=""><article id="article-116348" data-v-398ae7b2=""><p itemprop="description" data-v-398ae7b2=""> The Ethereum co-founder has regained control of his T-Mobile account, confirming that a SIM-swap attack resulted in the hack of his X account.  </p><div data-v-1b2c826e="" data-v-398ae7b2=""><p><span data-v-1b2c826e=""></span><span data-v-1b2c826e=""> 8091 </span><span data-v-1b2c826e=""> Total views </span></p><p><span data-v-1b2c826e=""> 59 </span><span data-v-1b2c826e=""> Total shares </span></p></div><div data-v-398ae7b2=""><picture><source media="(min-width: 1200px)" srcset="https://images.cointelegraph.com/images/717_aHR0cHM6Ly9zMy5jb2ludGVsZWdyYXBoLmNvbS91cGxvYWRzLzIwMjMtMDkvNDlkMDQ3Y2ItZmQzMC00ZTVkLTkzOWEtYzY0OTA4YzE0Y2U0LmpwZw==.jpg 1x, https://images.cointelegraph.com/images/1434_aHR0cHM6Ly9zMy5jb2ludGVsZWdyYXBoLmNvbS91cGxvYWRzLzIwMjMtMDkvNDlkMDQ3Y2ItZmQzMC00ZTVkLTkzOWEtYzY0OTA4YzE0Y2U0LmpwZw==.jpg 2x"><source media="(min-width: 992px)" srcset="https://images.cointelegraph.com/images/587_aHR0cHM6Ly9zMy5jb2ludGVsZWdyYXBoLmNvbS91cGxvYWRzLzIwMjMtMDkvNDlkMDQ3Y2ItZmQzMC00ZTVkLTkzOWEtYzY0OTA4YzE0Y2U0LmpwZw==.jpg 1x, https://images.cointelegraph.com/images/1174_aHR0cHM6Ly9zMy5jb2ludGVsZWdyYXBoLmNvbS91cGxvYWRzLzIwMjMtMDkvNDlkMDQ3Y2ItZmQzMC00ZTVkLTkzOWEtYzY0OTA4YzE0Y2U0LmpwZw==.jpg 2x"><source media="(min-width: 768px)" srcset="https://images.cointelegraph.com/images/638_aHR0cHM6Ly9zMy5jb2ludGVsZWdyYXBoLmNvbS91cGxvYWRzLzIwMjMtMDkvNDlkMDQ3Y2ItZmQzMC00ZTVkLTkzOWEtYzY0OTA4YzE0Y2U0LmpwZw==.jpg 1x, https://images.cointelegraph.com/images/1276_aHR0cHM6Ly9zMy5jb2ludGVsZWdyYXBoLmNvbS91cGxvYWRzLzIwMjMtMDkvNDlkMDQ3Y2ItZmQzMC00ZTVkLTkzOWEtYzY0OTA4YzE0Y2U0LmpwZw==.jpg 2x"><source media="(min-width: 480px)" srcset="https://images.cointelegraph.com/images/747_aHR0cHM6Ly9zMy5jb2ludGVsZWdyYXBoLmNvbS91cGxvYWRzLzIwMjMtMDkvNDlkMDQ3Y2ItZmQzMC00ZTVkLTkzOWEtYzY0OTA4YzE0Y2U0LmpwZw==.jpg 1x, https://images.cointelegraph.com/images/1494_aHR0cHM6Ly9zMy5jb2ludGVsZWdyYXBoLmNvbS91cGxvYWRzLzIwMjMtMDkvNDlkMDQ3Y2ItZmQzMC00ZTVkLTkzOWEtYzY0OTA4YzE0Y2U0LmpwZw==.jpg 2x"><img srcset="https://images.cointelegraph.com/images/480_aHR0cHM6Ly9zMy5jb2ludGVsZWdyYXBoLmNvbS91cGxvYWRzLzIwMjMtMDkvNDlkMDQ3Y2ItZmQzMC00ZTVkLTkzOWEtYzY0OTA4YzE0Y2U0LmpwZw==.jpg 1x, https://images.cointelegraph.com/images/960_aHR0cHM6Ly9zMy5jb2ludGVsZWdyYXBoLmNvbS91cGxvYWRzLzIwMjMtMDkvNDlkMDQ3Y2ItZmQzMC00ZTVkLTkzOWEtYzY0OTA4YzE0Y2U0LmpwZw==.jpg 2x" src="https://images.cointelegraph.com/images/1434_aHR0cHM6Ly9zMy5jb2ludGVsZWdyYXBoLmNvbS91cGxvYWRzLzIwMjMtMDkvNDlkMDQ3Y2ItZmQzMC00ZTVkLTkzOWEtYzY0OTA4YzE0Y2U0LmpwZw==.jpg" alt="Vitalik Buterin reveals X account hack was caused by SIM-swap attack"></picture><!----></div><!----><!----><div data-v-398ae7b2=""><!----><div data-v-398ae7b2=""><p>Ethereum co-founder Vitalik Buterin has confirmed that the recent hack of his X (Twitter) account was the result of a SIM-swap attack.</p><p>Speaking on the decentralized social media network Farcaster on Sept. 12, Buterin <a href="https://warpcast.com/vitalik.eth/0x8ea2d0" target="_blank" rel="noopener nofollow">said</a> that he has finally recovered his T-Mobile account after the hacker managed to gain control of it via a SIM swap attack.</p><blockquote>“Yes, it was a SIM swap, meaning that someone socially-engineered T-mobile itself to take over my phone number.”</blockquote><p>The Ethereum co-founder added some lessons and learnings from his experience with X. </p><figure><img src="https://s3.cointelegraph.com/uploads/2023-09/9e52f433-f051-4cfc-822f-3a673681d71e.PNG"><figcaption><em>Vitalik Buterin confirms how his X account was accessed by hackers. Source: Warpcast</em></figcaption></figure><p>“A phone number is sufficient to password reset a Twitter account even if not used as 2FA,” he said, adding that users can “completely remove [a] phone from Twitter.”</p><blockquote>“I had seen the ‘phone numbers are insecure, don't authenticate with them’ advice before, but did not realize this.”</blockquote><p>On Sept. 9, Buterin’s X account was <a href="https://cointelegraph.com/news/ethereum-vitalik-buterin-x-hackers-drain" data-amp="https://cointelegraph-com.cdn.ampproject.org/c/s/cointelegraph.com/news/ethereum-vitalik-buterin-x-hackers-drain/amp"></a><a href="https://cointelegraph.com/news/ethereum-vitalik-buterin-x-hackers-drain" data-amp="https://cointelegraph-com.cdn.ampproject.org/c/s/cointelegraph.com/news/ethereum-vitalik-buterin-x-hackers-drain/amp">taken over by scammers</a> who posted a fake NFT giveaway prompting users to click a malicious link, which resulted in victims collectively losing over $691,000.</p><p>On Sept. 10, Ethereum developer Tim Beiko strongly recommended removing phone numbers from X accounts and having 2FA enabled. “Seems like a no-brainer to have this default on, or to default turn it on when an account reaches, say, &gt;10k followers,” he said to platform owner Elon Musk.</p><blockquote><div lang="en" dir="ltr"><p>Twitter opsec PSA: </p><p>If you have a phone number linked on your account, even with other 2FA, it can be used to reset your PW. Need to specifically disable it + remove phone #. </p><p>If your Twitter account pre-dates crypto, strongly recommend double-checking, and adding strong 2FA! <a href="https://t.co/uXrvHYhQvJ">pic.twitter.com/uXrvHYhQvJ</a></p></div>— timbeiko.eth ☀️ (@TimBeiko) <a href="https://twitter.com/TimBeiko/status/1700659107764785336?ref_src=twsrc%5Etfw">September 9, 2023</a></blockquote>

<p><strong><em>Related: </em></strong><a href="https://cointelegraph.com/news/crypto-sim-swap-how-easy-is-sim-swap-crypto-hack" data-amp="https://cointelegraph-com.cdn.ampproject.org/c/s/cointelegraph.com/news/crypto-sim-swap-how-easy-is-sim-swap-crypto-hack/amp"><strong><em>How easy is a SIM swap attack? Here’s how to prevent one</em></strong></a></p><p>A SIM-swap or simjacking attack is a technique used by hackers to gain control of a victim’s mobile phone number. With control of the number, scammers can use two-factor authentication (2FA) to access social media, bank, and crypto accounts. </p><p>It is not the first time T-Mobile has been involved in this type of attack vector. In 2020, the telecoms giant was sued for allegedly enabling the theft of $8.7 million worth of crypto in a series of SIM-swap attacks.</p><p>T-Mobile was also sued again in February 2021 when a customer lost $450,000 in Bitcoin in another SIM-swap attack.</p><p><em>Article updated to include additional comments from Tim Beiko.</em></p><p><strong><em>Magazine: <a href="https://cointelegraph.com/magazine/bitcoin-ogs-experts-how-to-protect-your-crypto/">How to protect your crypto in a volatile market: Bitcoin OGs and experts weigh in</a></em></strong></p><template data-name="subscription_form" data-type="markets_outlook"></template>


</div><!----><!----><!----><!----><p><img alt="" src="https://zoa.cointelegraph.com/pixel?postId=116348&amp;regionId=1" data-v-398ae7b2=""></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You're barely managing (124 pts)]]></title>
            <link>https://barely-managing.bearblog.dev/youre-barely-managing/</link>
            <guid>37479641</guid>
            <pubDate>Tue, 12 Sep 2023 11:51:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://barely-managing.bearblog.dev/youre-barely-managing/">https://barely-managing.bearblog.dev/youre-barely-managing/</a>, See on <a href="https://news.ycombinator.com/item?id=37479641">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I believe the following to be true:</p>
<ol>
<li>Bad managers are the cause of a lot of employee unhappiness.</li>
<li>Bad managers are the cause of a lot of workplace failure, i.e., late projects, subpar products, and unmet goals.</li>
<li>Managers are one of the most under-supported cohorts of employees on the planet.</li>
</ol>
<p>How many managers do you know who studied to be managers of people?</p>
<p>I mean more than a couple of one-day courses; I mean someone who studied to be a manager the way someone studied to be a software engineer or doctor.</p>
<p>I personally don’t know anyone, and while those degrees definitely exist, it’s got me wondering: of the total managers in the world, how many of them have those qualifications? Is it even 1%?</p>
<p>Just imagine if other professions had that split of self-taught vs. formally taught. Plumbers, doctors, lawyers... There would be massive variability in the quality of their work and their overall success, and yet that’s the exact gamble every company around the world is taking.</p>
<p>So how are the 99% becoming managers?</p>
<p>Julie Zhuo, <a href="https://www.juliezhuo.com/" target="_blank">author of The Making of a Manager</a>, writes about the four paths to becoming a manager:</p>
<ul>
<li><strong>The Apprentice</strong>: The team is expanding and is too large for one manager, and so you are tapped to step into a newly needed role.</li>
<li><strong>The Pioneer</strong>: You were the founding member of a new group and, by proxy, its leader.</li>
<li><strong>The New Boss</strong>: You are hired to manage an entirely new team.</li>
<li><strong>The Successor</strong>: The previous manager has left, and you are the obvious choice.</li>
</ul>
<p>With the exception of the ‘New Boss’, most of the ways that people become managers are through time under a pre-existing manager, and this is what drives me to believe 99% of managers aren't trained. It's always a role someone grows into.</p>
<p>We are always taking someone who is highly performant or experienced (not necessarily the same thing) in the 'doing' of a role in the tam, what I call the ‘technical’ stuff, and based off some light leadership examples such as leading projects or being a mentor, are deemed fit enough to now run an entire team.</p>
<p>I wouldn’t have as much of an issue with this if it weren’t for the fact that once people become managers, they are almost certainly left to fend for themselves and self-teach themselves the job.</p>
<p>It makes absolutely no sense, and no other profession in the world works like this. We don’t promote someone to doctor after seeing some promising medical abilities and hoping they magically teach themselves how to not kill someone.</p>
<p>What flummoxes me even more is that so much risk to the company hinges on how successful managers are at their jobs, and yet companies turn such a blind eye to this problem.</p>
<p>Companies will invest millions of dollars to reduce the amount of variance in risk in finance, security, intellectual property, and other key areas, but not enough goes towards getting all of their managers up to the same level of competence and onto the same page.</p>
<p>They often leave it to the local level, hoping the manager above the new manager mentors them, which just creates a circular problem if that manager themselves isn’t a good mentor (not everyone who can do can teach) or worse, is a bad manager themselves. Not to mention they themselves have been self-taught; what bad habits have they not corrected?</p>
<p>This then leaves HR (or whatever we are calling this department this month) to try and pick up the slack. While I have found HR to be great in a one-on-one capacity, provided they themselves are good at their job, I’ve been witness to multiple roll-outs of ‘one-size-fits-all’ management training days and intranet portal content, and they never meet the mark.</p>
<p>They are often too generic and impersonal, and they are often starting at ground zero, like how to approve leave and manage expense claims. They never get into the nitty gritty or teach anything that can be truly applied in the 'field'.</p>
<p>It’s not enough, and it’s hurting everyone. I generally believe that most managers are barely managing.</p>
<blockquote>
<p>I generally believe that most managers are barely managing</p>
</blockquote>
<p>Both in the sense that I do not believe them to be doing enough as a manager for their team and the company, but also in the sense that I can often see them drowning, personally struggling to do their job. Surviving, not thriving.</p>
<p>This series will provide my personal guidance on both how to be a manager and how to do the job of managing people.</p>
<p>I care for both the people you are responsible for. I want them to not quit because of you.</p>
<p>I also care for you, the manager, who has found themselves in such a position of power and responsibility with minimal support.</p>
<p>You do not need to read this entire thing A-Z like a tome, but instead I encourage you to casually work through the core articles (they will be highlighted) and then jump around to any others that catch your interest.</p>
<p>Bookmark this blog, come back to it when a problem arises at work, and find the piece of advice that is applicable to you and figure out how to implement it. Then don't come back until the next time you need it.</p>
<p>Feel free to reach out if you have a question, all my links are in my <a href="https://linktr.ee/antranaut" target="_blank">Linktree</a> and if you want to show some extra gratitude you can buy me a coffee through my <a href="https://linktr.ee/antranaut" target="_blank">Linktree</a>.</p>
<p>Good Luck and don't fuck it up.</p>
<p><a href="https://barely-managing.bearblog.dev/" target="_blank">Return to the front page</a></p>
<p><a href="https://barely-managing.bearblog.dev/the-role-of-a-manager/" target="_blank">Next Article: The role of a manager</a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Phoenix 1.7 for Elixir: Edit a Form in a Modal (142 pts)]]></title>
            <link>https://blog.appsignal.com/2023/09/12/phoenix-1-7-for-elixir-edit-a-form-in-a-modal.html</link>
            <guid>37479323</guid>
            <pubDate>Tue, 12 Sep 2023 11:12:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.appsignal.com/2023/09/12/phoenix-1-7-for-elixir-edit-a-form-in-a-modal.html">https://blog.appsignal.com/2023/09/12/phoenix-1-7-for-elixir-edit-a-form-in-a-modal.html</a>, See on <a href="https://news.ycombinator.com/item?id=37479323">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>In part one of this series, we introduced the <code>CoreComponents</code> that get generated when bootstrapping a new
Phoenix project. In part two, we implemented a create modal.</p>
<p>Now, we will implement
an edit modal.</p>
<p><em>You can continue following along with our <a href="https://github.com/Adzz/petacular">companion repo</a>.</em></p>
<h2 id="editing-a-form-in-a-modal">Editing a Form in a Modal</h2>
<p>You will first notice that each item will need a different changeset. We
want to edit each item, so we need to be able to build a changeset from
a different struct each time.</p>
<p>You <em>could</em> do this by iterating over all of the items in <code>mount</code>
and rendering a different modal for every row, but this won't work at all. You would have to have
one changeset per assign, which doesn't work when you have a list to add to. It would
also mean a lot more HTML because you'd render the whole modal once per row. It's an all-round bad idea.</p>
<p>Instead, we need a way to build the correct changeset based on the item we click on.
We can do that by using another <code>JS</code> function — <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.JS.html#push/1"><code>push</code></a>.
This will push an event to the backend, along with any attributes that we want to send. If we add an edit button per row, the click action can push an event to the backend
with the <code>pet_id</code> as a param. Then, we can select the pet from the list of assigns and build
a changeset out of it.</p>
<p>First, add the button to the markup. It might be nice to use an icon for this, so let's take
a quick detour to icons.</p>
<h2 id="icons-in-phoenix">Icons in Phoenix</h2>
<p>Phoenix 1.7 ships with a vendored heroicons library and an <code>&lt;.icon&gt;</code> component in <code>CoreComponents</code>.
It works by supplying the name of an icon as a <code>name</code> attr, like so:</p>

<p>The names for the available icons are the filenames contained in the following
path: <code>assets/vendor/heroicons/optimized/20/solid/</code>.
Looking at the files doesn't tell us much about what they look like because we just see svg
markup.</p>
<p>What would be cool is if we could render a dev-only route that displays all icons on one page.
Then when we consider using an icon, we can go to that page and peruse them all at our leisure.</p>
<p>First, let's add the route:</p>

<p>Then, we can make the necessary <code>PetacularWeb.Pages.StoryBookLive</code> module. We'll now write a function that
generates all the icon names from the files in the assets folder, then iterate over them
and create an icon from each one. This will give us a dynamic list of icons to render.</p>
<p>Here are the <code>icon_names</code> (this assumes you will start your server from the project's route):</p>

<p>Then the markup:</p>

<p>There is one more thing to do, though. Tailwind will purge all classes it doesn't see
being used when the app is built. Usually, this is great because it means the bundle size is
smaller, with more lightweight pages. However, here, it is going to bite us. When you
refer to classes dynamically, Tailwind doesn't see those classes being used, so it purges them. <a href="https://tailwindcss.com/docs/content-configuration#dynamic-class-names">Tailwind's docs warn about this</a>.</p>
<p>We need to tell Tailwind <em>not</em> to purge all the icon modules so we can render them. We do that by adding a line of config into <code>tailwind.config.js</code>, like so:</p>

<p>Now, we can head to <code>http://localhost:4000/dev/storybook</code> and see all the icons. See
<a href="https://github.com/Adzz/petacular/commit/91a0ff0e3af688a47864dc030a83b0f705e8f021">this commit</a>
for all of the changes.</p>

<h3 id="back-to-editing-our-form">Back to Editing Our Form</h3>
<p>Okay, now we can select our edit icon and put it on the page.</p>

<p>We will put this in a button and add a <code>phx-click</code> that opens our edit modal for us. All
this can live in the <a href="https://github.com/Adzz/petacular/blob/main/lib/petacular_web/pages/home_live.ex">homepage</a> we used in parts one and two.</p>

<p>We also need to create our <code>Edit</code> modal. This will be similar to our <code>Create</code> modal, but a bit different, so we'll just create a new modal.</p>
<p>We can put this in our <code>~H</code> component just before the other modal:</p>

<p>Now we need to add a changeset to the assigns. Initially, we can put any changeset in mount because when we open the modal, we are going to seed it:</p>

<h2 id="add-the-open_edit_modal-function">Add the <code>open_edit_modal</code> Function</h2>
<p>Now let's implement the <code>open_edit_modal</code> function. This has to do two things:</p>
<ol>
<li>Open the modal.</li>
<li>Trigger a message to the backend so we can seed the changeset.</li>
</ol>

<p>The handler for this event needs to select the relevant pet from the list of pets and
put that into the changeset:</p>

<p>When we open the modal, the page will re-render the form because the changeset has changed,
and the form will be seeded with the correct data. We can verify this by using
<code>|&gt; IO.inspect(limit: :infinity, label: "")</code> on the form value:</p>

<h3 id="debugging-an-issue-with-the-open_edit_modal">Debugging an Issue with the <code>open_edit_modal</code></h3>
<p>If you open the modal, you will see the correct value printed. But there is a problem — it's
not showing on the page! What on earth could be the issue? This one is a doozy, so I will
save you some hours of debugging.</p>
<p>The function that we use to <a href="https://github.com/Adzz/petacular/blob/main/lib/petacular_web/components/core_components.ex#L591">open our modal</a> has this line, which focuses the first "focussable"
element in the modal:</p>

<p>This is done for accessibility, and so is generally a good idea.</p>
<p>The input happens to be the first focussable thing in our edit form. Phoenix also ensures
that the client is the source of truth for <a href="https://hexdocs.pm/phoenix_live_view/form-bindings.html#javascript-client-specifics">an input's value</a>:</p>
<blockquote>
<p>For any given input with focus, LiveView will never overwrite the input's current value, even if it deviates from the server's rendered updates.</p>
</blockquote>
<p>So what happens in our case? We push an asynchronous message to the backend, which changes an assign (the edit
form), causing a re-render — <code>|&gt; JS.push("open_edit_modal", value: %{pet_id: pet_id})</code>. Then we
open the modal with JavaScript, but because the message to the server is async, the modal
opens <em>before</em> we get a reply. The first focussable element is the input field, so that gets
focus, then the server responds. This would normally re-render the input field, but now won't, because the input has focus!</p>
<h3 id="fixing-the-issue">Fixing the Issue</h3>
<p>We've done everything right, yet are left adrift. What are our options?</p>
<ol>
<li>Remove the auto-focus capabilities of the modal.</li>
<li>Have the edit modal focus on something that is not the input first.</li>
<li>Somehow make the form opening synchronous to the server message.</li>
</ol>
<p>I honestly don't know which is better, but let's reason them out. One is easy to do — just <a href="https://github.com/Adzz/petacular/blob/main/lib/petacular_web/components/core_components.ex#L600">remove this line</a>
from the <code>show_modal</code> function — but may have accessibility implications, which makes it a non-starter.</p>
<p>The second option seems reasonable at first. We could maybe set the <code>tabindex</code> on the heading,
but <a href="https://developer.mozilla.org/en-US/docs/Web/Accessibility/Understanding_WCAG/Keyboard">mdn</a>
recommends the following:</p>
<blockquote>
<p>If an element can be focused using the keyboard, then it should be interactive; that is, the user should be able to do something to it and produce a change of some kind (for example, activating a link or changing an option).</p>
</blockquote>
<p>So that's out.</p>
<p>The third option is possible, but requires some ceremony. Instead of opening the modal with JS, you could have the backend trigger a JS event that opens the modal when it's finished
seeding the changeset. That requires adding a handler in JS to listen for the event
and also means that the modal open is slower, because it requires at least one round trip to
the server. For me, that is out as well.</p>
<p>The solution? A secret fourth option — set the value of the field with JS. This means
the field will open quickly, be set to the correct value, and auto-focus.</p>
<p>To support that, we alter our <a href="https://github.com/Adzz/petacular/blob/main/lib/petacular_web/pages/home_live.ex#L74"><code>open_edit_modal</code></a>
function to accept the name, then use <code>JS.set_attribute</code> to set the field value.</p>

<h2 id="implementing-the-update-in-our-phoenix-application">Implementing the Update in Our Phoenix Application</h2>
<p>Now the only thing left to do is implement the <code>edit_pet</code> handler. This is similar to the
create version, where we flash an error and close the modal on success. We first want to
select the pet we are editing, which means we need the pet's id. How can we get that?</p>
<p>The easiest way is to use a hidden input on the form. That way, when the form is submitted, the pet id will also be sent. To do that, we need to add the hidden input:</p>

<p>And set the value when we open the modal:</p>

<p>We will see the id of the pet appear in the params, allowing us to select
the pet we are editing from the assigns:</p>

<p>See <a href="https://github.com/Adzz/petacular/commit/364bec4c35c796bcd19f63ccd42ad230c0ed4afc">this commit</a>
for all the relevant changes.</p>
<p>And with that, we are done!</p>
<h2 id="wrapping-up">Wrapping Up</h2>
<p>This concludes our three-part series in which we took a fresh Phoenix 1.7 application and built a create and edit modal for
it.</p>
<p>Hopefully, this gives you some new ideas you can extend and implement for your own apps.</p>
<p>Happy coding!</p>
<p><strong>P.S. If you'd like to read Elixir Alchemy posts as soon as they get off the press, <a href="https://blog.appsignal.com/elixir-alchemy">subscribe to our Elixir Alchemy newsletter and never miss a single post</a>!</strong></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CVE-2023-4863: Heap buffer overflow in WebP (Chrome) (274 pts)]]></title>
            <link>https://chromereleases.googleblog.com/2023/09/stable-channel-update-for-desktop_11.html</link>
            <guid>37478403</guid>
            <pubDate>Tue, 12 Sep 2023 08:58:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chromereleases.googleblog.com/2023/09/stable-channel-update-for-desktop_11.html">https://chromereleases.googleblog.com/2023/09/stable-channel-update-for-desktop_11.html</a>, See on <a href="https://news.ycombinator.com/item?id=37478403">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><span itemprop="datePublished">
Monday, September 11, 2023
</span>
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NASA says distant exoplanet could have rare water ocean, possible hint of life (113 pts)]]></title>
            <link>https://www.theguardian.com/science/2023/sep/11/nasa-planet-ocean-life-james-webb-telescope</link>
            <guid>37477683</guid>
            <pubDate>Tue, 12 Sep 2023 07:03:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/science/2023/sep/11/nasa-planet-ocean-life-james-webb-telescope">https://www.theguardian.com/science/2023/sep/11/nasa-planet-ocean-life-james-webb-telescope</a>, See on <a href="https://news.ycombinator.com/item?id=37477683">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Scientists at <a href="https://www.theguardian.com/science/nasa" data-link-name="in body link" data-component="auto-linked-tag">Nasa</a> have announced the existence of a possible rare water ocean on a giant exoplanet scores of light years away and also a chemical hint of a sign of potential life.</p><figure id="bc15e85b-826f-4ddf-b8a5-0c15e6345a96" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" deferuntil="idle" props="{&quot;richLinkIndex&quot;:1,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/artanddesign/gallery/2023/aug/28/beyond-the-light-exhibition-nasa-discoveries-new-york-in-pictures&quot;,&quot;text&quot;:&quot;The story of light: Nasa discoveries reimagined – in pictures&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;elementId&quot;:&quot;bc15e85b-826f-4ddf-b8a5-0c15e6345a96&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0}}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;}"></gu-island></figure><p>The “intriguing” discovery was made by the space agency’s James Webb telescope, peering 120 light years from Earth in the constellation Leo, building on earlier studies of the region using Webb’s predecessors, Hubble and Kepler.</p><p>Researchers have named the exoplanet K2-18 b, an unremarkable moniker for something with such potential significance. Almost nine times the mass of Earth, it is, Nasa, says: “a Hycean exoplanet, one which has the potential to possess a hydrogen-rich atmosphere and a water ocean-covered surface”.</p><p>The space agency said that its observations of the chemical make-up of the planet’s atmosphere suggested the possibility of an ocean world. “The abundance of methane and carbon dioxide, and shortage of ammonia, support the hypothesis that there may be a water ocean underneath a hydrogen-rich atmosphere in K2-18 b,” it said.</p><p>But the agency also hinted at even more remarkable possibility in the potential finding of a molecule called dimethyl sulfide (DMS), which on Earth is only produced by life.</p><p>“The bulk of the DMS in Earth’s atmosphere is emitted from phytoplankton in marine environments,” the Nasa press release said.</p><p>The presence of DMS, however, is still to be confirmed, and requires further investigation. “Upcoming Webb observations should be able to confirm if DMS is indeed present in the atmosphere of K2-18 b at significant levels,” said Nikku Madhusudhan, a University of Cambridge astronomer and lead author of the Nasa research.</p><p>It would not be the first time Nasa has found indications of water on other planets. Water vapor was previously discovered on the <a href="https://www.nasa.gov/specials/ocean-worlds/#:~:text=Are%20there%20oceans%20on%20planets,in%20a%20five%2Dday%20orbit." data-link-name="in body link">smaller exoplanet, HAT-P-11b</a>, roughly the size of Neptune in the constellation Cygnus, also 120 light years away.</p><p>But scientists are excited by the revelation, even though they caution it does not necessarily mean the planet could support life.</p><p>“Our findings underscore the importance of considering diverse habitable environments in the search for life elsewhere,” said Madhusudhan.</p><p>“Traditionally, the search for life on exoplanets has focused primarily on smaller rocky planets, but the larger Hycean worlds are significantly more conducive to atmospheric observations.”</p><p>Orbiting the cool dwarf star K2-18, the exoplanet, 2.6 times the radius of Earth, lies in what Nasa calls the <a href="https://webbtelescope.org/glossary.html#h3-CK-8c9217a9-bf37-4563-863a-4b60ff8f5576" data-link-name="in body link">habitable zone</a>, a region around a star where planets with liquid water may be present.</p><p>Its interior likely contains a large mantle of high-pressure ice, similar to Neptune, Nasa says, but likely has a thinner hydrogen-rich atmosphere and an ocean surface. Hycean worlds are predicted to have oceans of water, but on K2-18 b it is also possible the ocean is too hot to be habitable.</p><p>The planet’s existence was first discovered by <a href="https://www.nasa.gov/feature/ames/nasas-k2-mission-the-kepler-space-telescopes-second-chance-to-shine" data-link-name="in body link">Nasa’s K2 mission</a> in 2015, but Webb’s improved technology over the earlier telescopes allowed for a more detailed analysis, and revelation it could be an ocean world. Scientists were able to study a tiny fraction of the star’s light as it passed through the exoplanet’s atmosphere.</p><p>“This result was only possible because of the extended wavelength range and unprecedented sensitivity of Webb, which enabled robust detection of spectral features with just two transits,” Madhusudhan said.</p><p>“For comparison, one transit observation with Webb provided comparable precision to eight observations with Hubble conducted over a few years and in a relatively narrow wavelength range.”</p><p>Nasa celebrated the first anniversary of operation of the Webb space telescope in July by releasing an <a href="https://www.theguardian.com/science/2023/jul/12/nasa-releases-image-of-star-forming-region-rho-ophiuchi-james-webb" data-link-name="in body link">“unprecedented” closeup image</a> of the nearest star-forming region to Earth.</p><p>In little more than a year, it has allowed humans to look closer towards the origins of the universe than ever before, and produced high-resolution pictures of far-distant worlds and the mysterious structures that surround them.</p><p>They include the “rare and fleeting” phase of a <a href="https://www.theguardian.com/science/2023/mar/15/james-webb-space-telescope-dying-star-nasa" data-link-name="in body link">star on the cusp of death</a>; early galaxies formed just <a href="https://www.theguardian.com/science/2022/nov/18/james-webb-telescope-finds-two-of-the-oldest-and-most-distant-galaxies-ever-seen" data-link-name="in body link">350m years after the big bang</a>; and evidence of “<a href="https://www.theguardian.com/science/2023/feb/22/universe-breakers-james-webb-telescope-detects-six-ancient-galaxies" data-link-name="in body link">universe breaker galaxies</a>” far larger than scientists thought possible, with the potential to upend current theories of cosmology.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reasons to not use your own domain for email (118 pts)]]></title>
            <link>https://www.bautista.dev/reasons-to-not-use-your-own-domain-for-email</link>
            <guid>37477558</guid>
            <pubDate>Tue, 12 Sep 2023 06:37:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bautista.dev/reasons-to-not-use-your-own-domain-for-email">https://www.bautista.dev/reasons-to-not-use-your-own-domain-for-email</a>, See on <a href="https://news.ycombinator.com/item?id=37477558">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I have been using my own domain for email for over 10 years. I am grandfathered into the free version of Google Workspace and have also used Fastmail and ProtonMail.</p>
<p>One of my concerns is that, if I were unable to renew my domain (e.g., in case of death), someone else could register it and start receiving my emails. This is a serious issue because your email account is as good as a password due to most websites using it as a way to reset your password. Can you imagine if someone in the future got a hold of gmail.com?</p>
<p>Another concern is privacy. Using a unique domain name for email stands out, especially when it has your name. I am starting to use iCloud's Hide My Email to change my email address on accounts I have created over the years because of this. I can also change where the emails are forwarded whenever I want to.</p>
<p>Your domain name can be the weakest link to accessing your online accounts. Make sure to take extra steps to protect your information, such as enabling 2FA.</p>
<p>Domain names registered by the more conventional email hosts are not immune to these problems. We need to start assuming email addresses are only temporarily in use by the current user. Or should we implement regulations? I shudder at the thought.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Open source P2P alternative to Slack and Discord built on Tor and IPFS (385 pts)]]></title>
            <link>https://github.com/TryQuiet/quiet</link>
            <guid>37477512</guid>
            <pubDate>Tue, 12 Sep 2023 06:29:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/TryQuiet/quiet">https://github.com/TryQuiet/quiet</a>, See on <a href="https://news.ycombinator.com/item?id=37477512">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><p dir="auto">
   <a target="_blank" rel="noopener noreferrer nofollow" href="https://avatars.githubusercontent.com/u/59660937?s=200&amp;v=4"><img width="150" height="150" src="https://avatars.githubusercontent.com/u/59660937?s=200&amp;v=4" alt="Logo"></a>
  </p>
  <h2 tabindex="-1" dir="auto"><b>Quiet</b></h2>
  

Quiet is an alternative to team chat apps like Slack, Discord, and Element that does not require trusting a central server or running one's own. In Quiet, all data syncs directly between a team's devices over <a href="https://torproject.org/" rel="nofollow">Tor</a> with no server required.
<blockquote>
<p dir="auto">NOTE: Quiet is not audited and should not be used when privacy and security are critical. It lacks basic features and probably won't replace your Slack or Discord yet. That said, it works surprisingly well and we use it daily as a Slack replacement.</p>
</blockquote>
<p dir="auto">Quiet is for fans of software freedom, decentralization and privacy tech, and for anyone craving a future where humanity can collaborate effectively online without trusting our communities, networks, and data to giant corporations.</p>
<p dir="auto"><strong>Quiet is written (mostly) in TypeScript, with Electron and React Native frontends, and welcomes outside contributions! See: <a href="#contributing-to-quiet">Contributing to Quiet</a></strong></p>
<div dir="auto">
  <p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/213678/177447638-29d6805c-5458-4f5e-b4ed-7a5d6cb51f6e.png"><img src="https://user-images.githubusercontent.com/213678/177447638-29d6805c-5458-4f5e-b4ed-7a5d6cb51f6e.png" alt="Screenshot"></a></p></div>
<h2 tabindex="-1" dir="auto">How it works</h2>
<p dir="auto">While apps like Slack, Discord, and Signal use central servers, Quiet syncs messages directly between a team's devices, over Tor, with no server required.</p>
<p dir="auto">Each group of people (Quiet calls them "communities") gets their own insular network, so that data from one community never touches the devices of Quiet users in <em>other</em> communities. Not even in encrypted form!</p>
<p dir="auto">Message syncing is taken care of by a project called <a href="https://orbitdb.org/" rel="nofollow">OrbitDB</a>, which works like a mashup of Git, a <a href="https://en.wikipedia.org/wiki/Gossip_protocol" rel="nofollow">gossip protocol</a>, and <a href="https://en.wikipedia.org/wiki/BitTorrent" rel="nofollow">BitTorrent</a>; it broadcasts new messages, syncs the latest messages, and fetches files. Syncing means that users typically receive all messages sent while they were offline.</p>
<p dir="auto">Invites, access, and usernames are granted by a community owner, i.e. whoever creates the community. The owner hands out an "invitation code" which invitees use to connect to the owner's device, register a username, and get a standard cryptographic certificate so they can prove to other peers they're part of the community.</p>
<p dir="auto">See our <a href="https://github.com/TryQuiet/monorepo/wiki/Quiet-FAQ">FAQ</a> for answers to common questions and a comparison of Quiet with similar apps.</p>
<h2 tabindex="-1" dir="auto">Getting started</h2>
<p dir="auto">To try Quiet, download the <a href="https://github.com/TryQuiet/quiet/releases/tag/quiet%401.8.0">latest release</a> for your platform (.dmg for macOS, .exe for Windows, etc.) and install it in the normal way. Then create a community and open the community's settings to invite members.</p>
<p dir="auto">If you'd like to help develop Quiet, see <a href="#contributing-to-quiet">Contributing to Quiet</a>.</p>
<h2 tabindex="-1" dir="auto">Features</h2>
<ul dir="auto">
<li><strong>Team Chat</strong> - Create a "community" for your team or organization and invite members.</li>
<li><strong>End-to-end Encryption</strong> - All data is encrypted end-to-end between member devices.</li>
<li><strong>Channels</strong> - Organize chats in Slack-like channels.</li>
<li><strong>Images</strong> - Send and receive images, with copy/paste, drag &amp; drop, and image previews.</li>
<li><strong>Files</strong> - Send and receive giant files without arbitrary limits.</li>
<li><strong>Notifications</strong> - Get desktop notifications for new messages, with optional sounds.</li>
<li><strong>Invite links</strong> - Share invite links, just like in WhatsApp, Signal, or Discord.</li>
<li><strong>Keyboard Controls</strong> - Navigate channels without using the mouse.</li>
<li><strong>Desktop Apps</strong> - Desktop apps for Mac, Windows, and Linux.</li>
<li><strong>Android App</strong> - A fully peer-to-peer Android app with working notifications.</li>
<li><strong>No email or phone number required</strong> - Unlike Slack, Discord, WhatsApp, Telegram, and Signal, no email or phone number is required to create or join a community.</li>
</ul>
<h2 tabindex="-1" dir="auto">Planned (but still-missing) features</h2>
<ul dir="auto">
<li><strong>iOS App</strong> - Join communities and sync messages on iOS, with no central server.</li>
<li><strong>Direct Messages</strong> - Send and receive direct messages that are encrypted to the recipient and unreadable by other community members.</li>
<li><strong>Mentions</strong> - Send @ mentions that notify other users.</li>
<li><strong>Removal</strong> - Remove users from your community.</li>
<li><strong>User Profiles</strong> - Add an avatar or bio.</li>
<li><strong>Message Deletion</strong> - Delete individual messages and set timed deletion rules ("disappearing messages") for the community.</li>
<li><strong>Status</strong> - See your own connection status and the online status of other users.</li>
<li><strong>Reactions</strong> - React with emojis.</li>
<li><strong>Multiple Communities</strong> - Join multiple communities, as you would in Slack or Discord.</li>
<li><strong>Account Recovery</strong> - Recover owner accounts from a backup phrase.</li>
<li><strong>Private channels</strong> - Create private channels with multiple members that are unreadable to the community at large.</li>
</ul>
<h2 tabindex="-1" dir="auto">Post-1.0 Features</h2>
<ul dir="auto">
<li><strong>Large Communities</strong> - Create a community with 1000 members or more (right now ~30-100 members is the limit.)</li>
<li><strong>Moderation</strong> - Appoint moderators who can hide messages and shadowban or remove users.</li>
<li><strong>Spam and Denial-of-Service Protection</strong> - Settings to automatically remove users who send disruptive messages.</li>
<li><strong>Search</strong> - Robust message search.</li>
<li><strong>Threads</strong> - Reply to messages in threads.</li>
<li><strong>Tor Bridges</strong> - Connect via public or private bridges to avoid Internet censorship.</li>
<li><strong>Tor Browser Support</strong> - Join communities as a full member with Tor Browser, without downloading an app.</li>
<li><strong>Browser Support</strong> - Join communities with <em>any</em> modern browser via <a href="https://gitlab.torproject.org/tpo/core/arti/-/issues/103" rel="nofollow">Arti-in-WASM</a>.</li>
<li><strong>Publishing</strong> - Share files (or entire websites) from your community to the web, via Tor, <a href="https://github.com/asn-d6/onionbalance">OnionBalance</a>, and <a href="https://www.tor2web.org/" rel="nofollow">Tor2web</a> + IPFS.</li>
</ul>
<h2 tabindex="-1" dir="auto">Technical overview</h2>
<p dir="auto">This is a concise technical summary of the main points.</p>
<ol dir="auto">
<li><strong>Granting access:</strong> community owners use standard PKI (<a href="https://pkijs.org/" rel="nofollow">PKI.js</a>) to grant access, with each community owner serving as the community's <a href="https://en.wikipedia.org/wiki/Certificate_authority" rel="nofollow">certificate authority</a>; this is handled by Quiet and transparent to users.</li>
<li><strong>Authentication:</strong> a valid signed certificate from the community owner is required to connect to peers, receive connections from peers, and for messages to be visible to other peers.</li>
<li><strong>Networking:</strong> peers connect via <a href="https://en.wikipedia.org/wiki/Tor_(network)#Onion_services" rel="nofollow">Tor onion services</a>, exclusively with their fellow community members.</li>
<li><strong>Privacy:</strong> Tor encrypts all data in transit, and a Quiet user's device connects only to the devices of their fellow community members, so all messages are encrypted to recipients.</li>
<li><strong>Syncing:</strong> IPFS and <a href="https://orbitdb.org/" rel="nofollow">OrbitDB</a>, an <a href="https://ipfs.io/" rel="nofollow">IPFS</a>-based <a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type" rel="nofollow">CRDT</a>, ensure that all data (messages, user data, etc) syncs between peers with <a href="https://arxiv.org/abs/2012.00472" rel="nofollow">eventual consistency</a>.</li>
<li><strong>Asynchronous messaging:</strong> because messages sync to all members, members can communicate without being contemporaneously online, provided that there is "continuous liveness", a continuous chain of online peers who each sync the latest updates, between the sender and the recipient.</li>
<li><strong>Identity:</strong> a valid certificate from the community owner on account creation establishes a username, which the owner attests is unique; in future versions, Quiet will warn all members if community owners are caught issuing non-unique usernames, to protect against impersonation by malicious or compromised owners. (See: <a href="https://github.com/TryQuiet/monorepo/issues/119" data-hovercard-type="issue" data-hovercard-url="/TryQuiet/quiet/issues/119/hovercard">#119</a>)</li>
<li><strong>Invitation:</strong> to invite new members, community owners provide (via some other secure channel) an onion address that points to a registration API which accepts a certificate signing request, responds with a signed certificate, and provides sufficient peer information to connect to other peers; in future versions this onion address will expire. (See: <a href="https://github.com/TryQuiet/monorepo/issues/536" data-hovercard-type="issue" data-hovercard-url="/TryQuiet/quiet/issues/536/hovercard">#536</a>)</li>
<li><strong>Account recovery:</strong> owners must back up their data (e.g. by copying a folder, or someday with a wallet-style passphrase) and members request new accounts from owners.</li>
<li><strong>User removal:</strong> TBD, but likely a combination of expiring invitation onion addresses, certificate revocation, and message-layer encryption with updated keys.</li>
<li><strong>Multiple device support:</strong> TBD, but most likely based on <a href="https://github.com/local-first-web/auth">local-first-web/auth</a></li>
<li><strong>Mobile push notifications:</strong> barring a major victory for consumer rights, iOS notifications require using a centralized push notification service that connects to Apple, but message data can still be encrypted; in proof-of-concept, Quiet works well as an always-on background app on Android, so Android versions will likely not require a push notification server.</li>
<li><strong>Stack:</strong> Our backend is in Node.js (on iOS/Android we use <a href="https://github.com/nodejs-mobile">nodejs-mobile</a>); we use Electron on desktop and React Native on mobile.</li>
</ol>
<h2 tabindex="-1" dir="auto">Our Mission</h2>
<p dir="auto">We are building Quiet to sharpen the tools that <a href="https://en.wikipedia.org/wiki/Open_society" rel="nofollow">open societies</a> use to hold power accountable. Each year, movements use the Internet to hold power accountable in breathtaking new ways. But the rise of big tech has made the Internet <em>itself</em> seem like <em>yet another</em> unaccountable power. The medium that brought us <em>Occupy</em> Wall Street now looks like regular old Wall Street. We believe this happened because software became too dependent on company-run infrastructure, which undermined the role <a href="https://en.wikipedia.org/wiki/Free_software" rel="nofollow">free software</a> has historically played in holding the software industry accountable. Our goal is to fix that.</p>
<p dir="auto">In the 2000s, when key dominant tech products had viable free software competitors that were radically pro-user (products like <a href="https://en.wikipedia.org/wiki/Firefox" rel="nofollow">Firefox</a>, <a href="https://en.wikipedia.org/wiki/BitTorrent" rel="nofollow">BitTorrent</a>, <a href="https://www.videolan.org/" rel="nofollow">VLC</a>, <a href="https://en.wikipedia.org/wiki/HandBrake" rel="nofollow">Handbrake</a>, or <a href="https://en.wikipedia.org/wiki/Linux" rel="nofollow">Linux</a>) there was a limit to how much big tech could abuse users before users fled.</p>
<p dir="auto">But software for communication and collaboration seemed to require servers, whose cost grew with the software's popularity, so the question "who runs the server?" became a dilemma for free software projects. Should the project itself run the server? What about when costs grew too high? Should users run the server? But only a small niche of hobbyists have servers! Should an organization run the server? If so, then that organization now controls the data and relationships that make the product useful, limiting the freedom to <a href="https://en.wikipedia.org/wiki/Fork_(software_development)#Forking_of_free_and_open-source_software" rel="nofollow">fork</a> and flee that makes free software so accountable and desirable. Reddit, for example, <a href="https://www.reddit.com/r/changelog/comments/6xfyfg/an_update_on_the_state_of_the_redditreddit_and/" rel="nofollow">was once free software</a>, but because forking Reddit's <em>code</em> would never have resulted in anything more than an empty website (since all the conversations and relationships that make Reddit what it is sit on <em>company-run servers</em>) Reddit being free software never gave Reddit's users any real power to hold it accountable.</p>
<p dir="auto"><a href="https://en.wikipedia.org/wiki/Federation_(information_technology)" rel="nofollow">Federation</a> is a proposed solution to this dilemma, but Gmail shows its limits. After all, email is the most well-known federated product, but Google can still build must-have features like spam filtering on the server side, and Gmail controls a user's email address, so exiting Gmail means updating dozens or hundreds of accounts created with that address. Exiting Gmail might be easier than exiting Facebook or Instagram, but no Gmail competitor can make exiting Gmail as easy and delightful an experience as Firefox made exiting Internet Explorer, because Gmail controls infrastructure, where Internet Explorer never did. So while federation does help, we must do better if we want to hold big tech accountable.</p>
<p dir="auto">Regulation is an even weaker proposed solution. Even when regulation works—and a quick look at the media, telecom, energy, or banking industries will illustrate its limits—regulation tends to create a cozy relationship between industry and regulators that makes industries easy targets for government subversion. For example, the highly-regulated telecom industry <a href="https://www.theguardian.com/world/2013/jun/06/nsa-phone-records-verizon-court-order" rel="nofollow">bends</a> <a href="https://www.vice.com/en/article/wx8jax/researchers-find-powerful-ss7-cellphone-location-surveillance-in-europe-middle-east-australia" rel="nofollow">over</a> <a href="https://en.wikipedia.org/wiki/Room_641A" rel="nofollow">backwards</a> every time governments want help carrying out unpopular mass surveillance. Is this what we want from big tech?</p>
<p dir="auto">We're building Quiet because we believe that, for a broad and growing class of software, the best answer to the "who runs the server?" dilemma is "no one." Eliminate the server; in terms of accountability, it is a burden and a weakness. By eliminating servers from software's <a href="https://en.wikipedia.org/wiki/Attack_surface" rel="nofollow">attack surface</a>, software can be more private and secure. By eliminating exponentially growing server costs and the expertise-intensive work of scaling servers, software can be built by smaller teams under less financial pressure to betray users. Most importantly, by eliminating the server operator's control of relationships and data, users will be free to fork and exit, so they will once again have real power to hold software accountable.</p>
<p dir="auto">We're building Quiet to spark a new phase of the free software movement where it is easy and normal to build apps this way. We want to make a private alternative to Slack &amp; Discord that people love, to figure out the best and easiest technical approach along the way, and—by doing all this—to blaze a trail that other free software teams building other products can follow. Once one team (us, we hope!) can build a good alternative to Slack that doesn't use servers, other teams can build alternatives to Google Docs, Figma, Asana, Trello, 1Password, and so on, until someday—and this is technically much more difficult—humanity can build fully-forkable alternatives to things like Facebook, Twitter, Instagram, or even more complex applications. Big tech's users will be free to flee, and the Internet can stop being yet another unaccountable power, and keep being the breathtaking medium for holding power accountable that open societies need.</p>
<p dir="auto">Join us, and let's figure this out.</p>
<h2 tabindex="-1" dir="auto">Contributing to Quiet</h2>
<p dir="auto">Even though Quiet is completely peer-to-peer, it is mostly written in TypeScript and will be familiar to anyone accustomed to Node.js web development. Desktop and mobile versions share a common Node.js <a href="https://github.com/TryQuiet/monorepo/tree/develop/packages/backend">backend</a> and React <a href="https://github.com/TryQuiet/monorepo/tree/develop/packages/state-manager">state manager</a>, with <a href="https://torproject.org/" rel="nofollow">Tor</a> binaries for each platform and architecture, using Electron and React Native and for their respective frontends.</p>
<p dir="auto">To get started hacking on Quiet, follow the instructions for <a href="https://github.com/TryQuiet/quiet/blob/develop/packages/desktop/README.md">Quiet Desktop</a> or <a href="https://github.com/TryQuiet/monorepo/tree/develop/packages/mobile#readme">Quiet Mobile</a>. (If you're new to the project, start with Quiet Desktop, as it's more stable and vastly easier to start hacking on.) Here are some <a href="https://github.com/orgs/TryQuiet/projects/3/views/1?filterQuery=label%3A%22good+first+issue%22">good first issues</a>, and you can see upcoming priorities in our <a href="https://github.com/orgs/TryQuiet/projects/3/views/1">project board</a>.</p>
<p dir="auto">Most of all, if you're interested in contributing, be in touch! Drop us a line at <a href="mailto:h@quiet.chat">h@quiet.chat</a> and we'll add you to the project's Quiet community and (if you like) plan an onboarding session.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: How is Rust used in the Linux kernel today? (107 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=37477205</link>
            <guid>37477205</guid>
            <pubDate>Tue, 12 Sep 2023 05:31:45 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=37477205">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="37477847"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37477847" href="https://news.ycombinator.com/vote?id=37477847&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><p><span>The basic infrastructure for writing drivers in Rust is upstream but there's nothing upstream using it yet.  Others have mentioned stuff that may eventually make its way upstream, but from what I've seen there's pretty heavy resistance from maintainers whenever (re)writing something in Rust gets brought up.<p>Before Rust starts getting used "for real" in the kernel there's a lot of barriers to overcome.  Most maintainers aren't hugely proficient in Rust and absolutely do not have the time to learn.  Needing yet another toolchain is annoying (especially when you need bits that aren't in stable yet), anything you write in Rust probably won't get built in distro kernels for a long time, and anything you work on today is hugely uncharted territory since it's all so new.</p><p>I think one thing a lot of people don't understand from "outside" the kernel development sphere is that standards for getting stuff upstream are typically pretty high for most subsystems, a lot higher than most open source projects.  There are a lot of open questions about Rust in Linux that don't have clear answers, and Linux <i>really</i> struggles with consensus.  Yes it has a dictator, but that dictator very rarely dictates anything that hugely moves the needle.</p><p>I do think "real" kernel bits written in Rust will get upstream and will get used, but it will be a very slow burn.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37481055"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37481055" href="https://news.ycombinator.com/vote?id=37481055&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><p><span>It might be helpful to consider the Firefox situation, too. That is also a relatively large, established, and actively-developed software system that began to include some Rust code later on in its existence.<p>If I'm not mistaken, the first stable Firefox releases including notable usage of Rust code came out in late 2017. So that's about 6 years of Rust in Firefox.</p><p>From a Firefox user's perspective, I can't say that I'm impressed by it.</p><p>Building Firefox from source is more involved than it was before. As you mentioned, additional tooling for Rust is required in such a situation.</p><p>I haven't really noticed any real Firefox feature, functionality, or performance improvements that I could directly attribute to the use of Rust.</p><p>It also doesn't seem like using Rust has allowed the Firefox developers to be significantly more efficient or productive than they were before.</p><p>Maybe an argument could be made that some security issues, for example, have been avoided thanks to Rust, but that's not really provable in any meaningful way.</p><p>After seeing the Firefox situation, my expectations for the use of Rust in the Linux kernel are pretty low.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37481211"><td></td></tr>
            <tr id="37481628"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37481628" href="https://news.ycombinator.com/vote?id=37481628&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><br><div>
                  <p><span>I remember seeing a blog post by Mozilla explaining how the new css engine, which is measurably faster, would never have been implemented in C++ because the engineers were not confident they could handle the tricky concurrency issues in that language.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37478035"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37478035" href="https://news.ycombinator.com/vote?id=37478035&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><p><span>&gt; Most maintainers aren't hugely proficient in Rust and absolutely do not have the time to learn.<p>Can LLMs help here with code (re)writing?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37478104"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37478104" href="https://news.ycombinator.com/vote?id=37478104&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><br><div>
                  <p><span>The proficiency required to make sure the LLM is not screwing up the code in some subtle way, is probably even higher than the proficiency required to rewrite the code yourself. So probably not.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37478249"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37478249" href="https://news.ycombinator.com/vote?id=37478249&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><br><div>
                  <p><span>Basically, you have to review code generated by an LLM the same way that you would review code written by a human programmer, which requires (at least) the same level of proficiency as writing code yourself - if not, as you wrote, higher proficiency.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37478376"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37478376" href="https://news.ycombinator.com/vote?id=37478376&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><br><div>
                  <p><span>Code written in Rust for LLM would likely be easier to review than C code due to its strong type system and the inclusion of the borrow checker. However, I anticipate there might be more 'unsafe' code, especially at the language boundaries, compared to typical Rust application code. Thus, the benefits might be somewhat diminished.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37480001"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_37480001" href="https://news.ycombinator.com/vote?id=37480001&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><br><div>
                  <p><span>The whole point of being in kernel space is to write unsafe code -- either unsafe in a memory sense or in a "I am just blasting characters at this pcie port" sense.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37480290"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_37480290" href="https://news.ycombinator.com/vote?id=37480290&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><p><span>Yes and no. It's true that there's some portion of the kernel space code that can't be written provably safely. But there's good reason to believe that a lot of it can and that belief is what's driving this integration.<p>Whether Rust in the kernel succeeds or not will likely be determined by whether or not a sufficiently clear boundary can be drawn between the bit that must be unsafe (in the Rust sense) and the rest. And how much code is in the latter. I don't think we know the answer yet but some knowledgable people are willing to run the experiment on the basis that the probability seems quite high that a safe subset can be determined.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="37478107"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37478107" href="https://news.ycombinator.com/vote?id=37478107&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><p><span>LLMs rewriting what? A) Rust modules to C so that it can be reviewed and merged by old school kernel hackers? B) C to unsafe Rust so that you lose any advantage of using Rust and get the worst of both world? C) Or rewrite the kernel maintainer's brains while they sleep so they become magically proficient in Rust when they wake up?<p>If you're talking about option A) or B), we already have things like mrustc and c2rust. These are though problems, LLMs aren't _that_ smart yet.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37478381"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37478381" href="https://news.ycombinator.com/vote?id=37478381&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><br><div>
                  <p><span>I’m just a layman when it comes to these kind of things. But here’s my take anyway: AFAICT, the issue isn’t so much about rewriting the code. However, if we would use automation for that, we would probably need <i>proofs</i> that the new code is better than the old one. And creating suchs proofs seems incredibly hard as soon as we walk out of “hello world” territory. People has spent years on trying to make suchs systems, but it’s still not widely used. So until then, we need people who read and analyze the code, and also have wast knowledge of the kernel’s inner workings, and today that seems to be the bottleneck. Those people doesn’t really grow on trees.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="37477668"><td></td></tr>
                <tr id="37478425"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37478425" href="https://news.ycombinator.com/vote?id=37478425&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><br><div>
                  <p><span>Actually this would be a very good first candidate for a Rust module - it's a significant newly developed piece of software, so nobody can say that they "(re)wrote it in Rust" just for the heck of it, and its impact is relatively isolated (only used on Apple Silicon Macs), so if something did break, it would mostly only hurt Asahi Linux, which is currently experimental anyway.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37478490"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37478490" href="https://news.ycombinator.com/vote?id=37478490&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><br><div>
                  <p><span>Well it's less that they rewrote it in Rust for the heck of it and more that they wrote it in Rust for the heck of it. Seems like it's going OK for them, though.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37478642"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37478642" href="https://news.ycombinator.com/vote?id=37478642&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><br><div>
                  <p><span>Well no, actually they explain their reasons for doing it in the article others linked here (<a href="https://asahilinux.org/2022/11/tales-of-the-m1-gpu/" rel="nofollow noreferrer">https://asahilinux.org/2022/11/tales-of-the-m1-gpu/</a>, section "A new language for the Linux kernel"), and it sounds pretty convincing - if you start a basically new and very complex driver project, and if there is a language more modern than C that might help you and is officially supported by the kernel, then why not use it?</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37478653"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37478653" href="https://news.ycombinator.com/vote?id=37478653&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><br><div>
                  <p><span>Not “for the heck of it”, it brings significant benefits compared to rawdogging it in C++.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37478995"><td></td></tr>
                <tr id="37479345"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_37479345" href="https://news.ycombinator.com/vote?id=37479345&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><br><div>
                  <p><span>Mo. C++ is not allowed in the kernel but Rust is. I think that says a lot given that both were proposed.</span></p></div></td></tr>
        </tbody></table></td></tr>
                                    <tr id="37478515"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37478515" href="https://news.ycombinator.com/vote?id=37478515&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><br><div>
                  <p><span>I wouldn't say it's alpha quality  at this point. It's running "in-production" on all Asahi Linux laptops.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37478659"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37478659" href="https://news.ycombinator.com/vote?id=37478659&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><br><div>
                  <p><span>...which is currently available as an alpha release. I wonder if there's a connection here ;)</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37478855"><td></td></tr>
            <tr id="37478846"><td></td></tr>
                <tr id="37478918"><td></td></tr>
                <tr id="37479152"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_37479152" href="https://news.ycombinator.com/vote?id=37479152&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><br><div>
                  <p><span>That version is majorly out of date, their website indeed does not mention how out of date it is (that said I have no idea as to whether the devs consider the latest releases stable/RC).</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37482565"><td><table>  <tbody><tr>    <td indent="6"><img src="https://news.ycombinator.com/s.gif" height="1" width="240"></td><td>
      <center><a id="up_37482565" href="https://news.ycombinator.com/vote?id=37482565&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><br><div>
                  <p><span>Right... actually, according to their latest blog post (from beginning of August), they expected to release the "Fedora Asahi remix" by end of August. Looks like that didn't quite work out, but a release (I guess they mean a RC or production release, not alpha or beta?) seems to be imminent...</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37479317"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_37479317" href="https://news.ycombinator.com/vote?id=37479317&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><br><div>
                  <p><span>If you click on that post it goes to an announcement that is more then 1.5 years old, many releases have followed since. That link simply hasn't been updated.</span></p></div></td></tr>
        </tbody></table></td></tr>
                                    <tr id="37478485"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37478485" href="https://news.ycombinator.com/vote?id=37478485&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><br><div>
                  <p><span>Yeah, I’d say Hector Martin’s got at least the most complete example of Rust code that can go into the kernel. Though he’d be far better off working alongside actual distro maintainers as he focuses on the M1 driver, rather than bandaid-fixing his distro because he can’t handle GRUB.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37477544"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37477544" href="https://news.ycombinator.com/vote?id=37477544&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><p><span>No, the only rust code accepted into any released kernels is basic framework infrastructure so that someday, maybe, in the future, real functionality could be written in rust.<p>There are many out-of-tree examples of rust kernel code, but as of right now, none have been merged.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37482922"><td></td></tr>
                  <tr id="37478710"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37478710" href="https://news.ycombinator.com/vote?id=37478710&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><p><span>Funny you ask, I was wondering the same thing last night so I went through the rust-for-linux mailing list archive. This thread is pretty telling:<p><a href="https://lore.kernel.org/rust-for-linux/bddea099-4468-4f96-2e06-2b207b608485@usi.ch/" rel="nofollow noreferrer">https://lore.kernel.org/rust-for-linux/bddea099-4468-4f96-2e...</a></p><p><a href="https://lore.kernel.org/rust-for-linux/c61a60ef-fa9d-44ea-9852-ae7b18bc1ab1@lunn.ch/" rel="nofollow noreferrer">https://lore.kernel.org/rust-for-linux/c61a60ef-fa9d-44ea-98...</a></p><p>The above thread is really strange that they picked such a niche thing in networking to contribute to, as sockets don't have many uses within the kernel itself other than NFS or dhcp or stuff like that. They should have aimed to add things to the QoS layer, qdisc, classifier, whatever, there's tens of those and you can easily add another. Start small.</p><p>The problem really is that the people who want to see Rust in the linux kernel have next to no linux kernel background and have a poor understanding of how Linux works and how things are generally done.</p><p>Also the people who contribute big things to the linux kernel usually have a clear business case behind them and a big company paying them to work on it full time.</p><p>For example I could imagine Microsoft eventually contributing in this regard, say they want some more Hyper-V virtual hardware drivers in Linux and they decided to do that in Rust. They've been lately using Rust in the Windows kernel so it's not that unrealistic to think it may happen.</p><p>A filesystem written in Rust would be cool... but it's probably going to have to be a new one rather than a rewrite, I can't imagine people going through the trouble of rewriting btrfs in Rust. And big names like Facebook could actually back that effort.</p><p>I really love using Rust for middleware things, however right now I can't convince myself to use it on low level things like OSes or microcontrollers since it seems to be a lot of trouble with getting Rust to play nice with FreeRTOS for example, and there seems to be no production ready rtos written in Rust either.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37480127"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37480127" href="https://news.ycombinator.com/vote?id=37480127&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><p><span>&gt; Funny you ask, I was wondering the same thing last night so I went through the rust-for-linux mailing list archive. This thread is pretty telling:<p>&gt; <a href="https://lore.kernel.org/rust-for-linux/bddea099-4468-4f96-2e06-2b207b608485@usi.ch/" rel="nofollow noreferrer">https://lore.kernel.org/rust-for-linux/bddea099-4468-4f96-2e...</a></p><p>&gt; <a href="https://lore.kernel.org/rust-for-linux/c61a60ef-fa9d-44ea-9852-ae7b18bc1ab1@lunn.ch/" rel="nofollow noreferrer">https://lore.kernel.org/rust-for-linux/c61a60ef-fa9d-44ea-98...</a></p><p>I don’t see how either post supports your points. The first is about OOT vs in-tree modules and the second isn’t about anything specific to Rust. You just picked a random post from someone learning about kernel development who happened to be using Rust.</p><p>The people doing core Rust for Linux work (not random mailing list participants) are actually very qualified and very knowledgeable about Linux. I don’t think your characterization of them is fair at all.</p><p>Grabbing random mailing list posts from non core maintainers and trying to extrapolate conclusions about an entire multi-year is not a good way to evaluate a project.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37480476"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37480476" href="https://news.ycombinator.com/vote?id=37480476&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><p><span>&gt;The people doing core Rust for Linux work (not random mailing list<p>&gt;participants) are actually very qualified and very knowledgeable about</p><p>&gt; Linux. I don’t think your characterization of them is fair at all.</p><p>Alright, they are very qualified and knowledgeable, what is a fair characterization of the work they're doing?</p><p>It's been a year, let's see how much stuff they managed to merge,
My terminal window has 135 rows:</p><p>cd linux/</p><p>git log --oneline rust/</p><p><i>output</i>
&lt;space&gt;
<i>output</i>
&lt;space&gt;
<i>output</i>
&lt;space&gt;
<i>no output</i></p><p>Oh wow, how many people was it again?</p><p>git shortlog -s -n -e --all --no-merges rust/ | wc -l</p><p>29</p><p>Most of those guys have single digits number of commits and there are 7 guys with double digits number of commits so let's say there's about 7 people most active doing rust in linux.</p><p>Do you know Rust yourself? Take a look at the bulk of the patches that got merged, could you write that if someone paid you? My guess is yes, because it looks pretty average to me. (No offense to you personally).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37481017"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37481017" href="https://news.ycombinator.com/vote?id=37481017&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><p><span>There's been 1500+ commits since 2020 on the 'main' Kernel fork that has Rust support [0]. Many of them through collaboration and backs and forths of review (look at the PRs on the fork).<p>My understanding is that the `rust-next` branch represents what's ready for Linus to merge. So there's a whole lot that's not in there, which you're  missing in your evaluation.</p><p>Last year a Kernel dev from Western Digital wrote an NVME driver in Rust [1] (look at slides 15 &amp; 16) which I would consider to be qualified and knowledgeable.</p><p>I wouldn't measure the effort solely on what's been merged to mainline as there's been 6 merge windows from 6.1 to now. Many of those commits are laying the groundwork for the next few years.</p><p>[0] <a href="https://github.com/torvalds/linux/compare/master...Rust-for-Linux:linux:rust">https://github.com/torvalds/linux/compare/master...Rust-for-...</a>
[1] <a href="https://lpc.events/event/16/contributions/1180/attachments/1017/1961/deck.pdf" rel="nofollow noreferrer">https://lpc.events/event/16/contributions/1180/attachments/1...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37481349"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_37481349" href="https://news.ycombinator.com/vote?id=37481349&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><p><span>&gt; Last year a Kernel dev from Western Digital wrote an NVME driver in Rust [1] (look at slides 15 &amp; 16) which I would consider to be qualified and knowledgeable.<p>NVMe drives are probably the simplest form of storage you can possibly think of in today's day and age, from a user perspective. Which is a perfect candidate for a proof of concept like that. Not saying that it's not good work.</p><p>In those 1500+ commits I see a lot of noise, and some good stuff, I like the alloc stuff, chardevs, buffer management, the async executor stuff looks really good <i>scrolls</i> <i>scrolls</i>, <i>scrolls</i>, okay yes.</p><p>A lot of this stuff looks meaningful and I hope to see it merged in the near future.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="37480312"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37480312" href="https://news.ycombinator.com/vote?id=37480312&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><br><div>
                  <p><span>I don't have a dog in this fight, but " someone learning about kernel development who happened to be using Rust" sounds to me like anecdotal evidence for the assertion that most rust contributors don't know how kernel development works.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37480485"><td></td></tr>
                        <tr id="37480479"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37480479" href="https://news.ycombinator.com/vote?id=37480479&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><p><span>The biggest point is in your second paragraph.<p>"The problem really is that the people who want to see Rust in the linux kernel have next to no linux kernel background and have a poor understanding of how Linux works and how things are generally done."</p><p>Is this a non topic then?</p><p>Having drivers in Rust is one thing. Drivers were done in C++ before. But you use a subset because a language targeting kernel needs to use kernel facilities. You won't be able to use your standard library. Syntax needs to be resolved to what kernel provides, or dropped.</p><p>That's why C++ in kernel never took off that seriously, when you restrict it, and when you already have to accommodate for kernel's "API mindset", what's left of language in between isn't that important.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37480680"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37480680" href="https://news.ycombinator.com/vote?id=37480680&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><p><span>If C could get constexpr and templates (with concepts) I would be very happy.<p>Everything else in C++ is just syntactic sugar to me. Very useful syntactic sugar, but just sugar.</p><p>Alright placement new is quite nice too. Since  there are so many ways to allocate memory in the linux kernel.</p><p>As far as RAII goes, ehhhh I don't know. KASAN and kmemleak do a pretty ok job.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="37479884"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37479884" href="https://news.ycombinator.com/vote?id=37479884&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><p><span>You can write arbitrary kernel modules in Rust, I think there are a few floating around.<p>Core kernel will never have Rust in it, and that is a correct decision. Linux and C have a long history of just working, and there is value in making sure that C code you write is correct and explicitly thinking about memory and what gets modified where. Correct coding is more than just memory safety, and compilers can't check everything for you.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37479725"><td></td></tr>
            <tr id="37477507"><td></td></tr>
            <tr id="37477277"><td></td></tr>
                <tr id="37477960"><td></td></tr>
                  <tr id="37478120"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37478120" href="https://news.ycombinator.com/vote?id=37478120&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><p><span>Heres to hoping that one day maybe someone writes a Bluetooth driver in rust to improve the reliability a bit.<p>But then again as I understand it the spec is so massive and has plenty of problems it may not be something that is improved by rust.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37478847"><td></td></tr>
            <tr id="37478245"><td></td></tr>
                <tr id="37478312"><td></td></tr>
                <tr id="37479712"><td></td></tr>
            <tr id="37478349"><td></td></tr>
                <tr id="37478492"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_37478492" href="https://news.ycombinator.com/vote?id=37478492&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><br><div>
                  <p><span>My comment is not about changing the language but about the fact that whenever we rewrite it, we improve the quality because of the lessons learned during past iterations.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37479232"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_37479232" href="https://news.ycombinator.com/vote?id=37479232&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><p><span>&gt; My comment is not about changing the language but about the fact that whenever we rewrite it, we improve the quality because of the lessons learned during past iterations.<p>So many developers have said this over the years but it almost never comes true.</p><p>You just end up with different bugs in a different language.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37478565"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_37478565" href="https://news.ycombinator.com/vote?id=37478565&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><p><span>You're correct; sorry.<p>I dunno why I misread "write in any language" with "write in another language".</p><p>I'm still skeptical about rewriting - the bluetooth spec is notoriously buggy itself, and many "bugs" and glitches in BT are due to how poorly the spec is written.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37482707"><td><table>  <tbody><tr>    <td indent="6"><img src="https://news.ycombinator.com/s.gif" height="1" width="240"></td><td>
      <center><a id="up_37482707" href="https://news.ycombinator.com/vote?id=37482707&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><br><div>
                  <p><span>Your last sentence is exactly what I was thinking. The problem with BT isn't necessarily on the kernel's bluetooth driver. The spec is buggy and also a lot of makers of bluetooth devices don't implement the spec properly. But the spec itself isn't spectacular to begin with.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37479106"><td><table>  <tbody><tr>    <td indent="6"><img src="https://news.ycombinator.com/s.gif" height="1" width="240"></td><td>
      <center><a id="up_37479106" href="https://news.ycombinator.com/vote?id=37479106&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><p><span>I'm not too sure I agree that the spec itself is buggy, certainly the implementations vary wildly from Sony almost doing their own thing to Chinese off the shelf copy pasting whatever makes a noise.<p>That said I have worked extensively with Bluetooth within Ericsson and while there is a learning curve, I never found the spec to be lacking.</p><p>Latest example : 
<a href="https://www.bluetooth.org/DocMan/handlers/DownloadDoc.ashx?doc_id=556599" rel="nofollow noreferrer">https://www.bluetooth.org/DocMan/handlers/DownloadDoc.ashx?d...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37478718"><td><table>  <tbody><tr>    <td indent="6"><img src="https://news.ycombinator.com/s.gif" height="1" width="240"></td><td>
      <center><a id="up_37478718" href="https://news.ycombinator.com/vote?id=37478718&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><br><div>
                  <p><span>A rewrite might simply make it more resilient through changes in the base architecture. However, I know nothing about Linux's bluetooth stack and I assume that it's probably taking into account a lot of those glitches already.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37479104"><td><table>  <tbody><tr>    <td indent="6"><img src="https://news.ycombinator.com/s.gif" height="1" width="240"></td><td>
      <center><a id="up_37479104" href="https://news.ycombinator.com/vote?id=37479104&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><br><div>
                  <p><span>Well, english is not my first language. What I meant probably got lost in translation :)</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37478883"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_37478883" href="https://news.ycombinator.com/vote?id=37478883&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><br><div>
                  <p><span>That highly depends on who is doing the rewriting and whether they were involved in writing the current system. If someone new starts rewriting the system in a memory safe language then it's quite likely they will make many of the same mistakes the original author did.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="37478509"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37478509" href="https://news.ycombinator.com/vote?id=37478509&amp;how=up&amp;goto=item%3Fid%3D37477205"></a></center>    </td><td><br><div>
                  <p><span>Debatably, as language rewrites can bring their own problems. Especially with a newer language like Rust that lacks experienced eyes to review. You get more benefit rewriting the bluetooth drivers in their current languages.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Death by a Thousand Microservices (456 pts)]]></title>
            <link>https://renegadeotter.com/2023/09/10/death-by-a-thousand-microservices.html</link>
            <guid>37477095</guid>
            <pubDate>Tue, 12 Sep 2023 05:05:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://renegadeotter.com/2023/09/10/death-by-a-thousand-microservices.html">https://renegadeotter.com/2023/09/10/death-by-a-thousand-microservices.html</a>, See on <a href="https://news.ycombinator.com/item?id=37477095">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="postBody">
    <h3 id="the-church-of-complexity">The Church of Complexity</h3>

<p>There is a pretty well-known sketch in which an engineer is explaining to the project manager how an overly complicated maze of 
microservices works in order to get a user’s birthday - and fails to do so anyway. The scene accurately describes the 
absurdity of the state of the current tech culture. We laugh, and yet bringing this up in a 
serious conversation is tantamount to professional heresy, rendering you borderline un-hirable.</p>

<p>
    <iframe src="https://www.youtube.com/embed/y8OnoxKotPQ?si=7qBEqGaN7ATD-Gex" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; 
        picture-in-picture; web-share" allowfullscreen="">
    </iframe>
</p>

<p>How did we get here? How did our aim become not addressing the task at hand but instead setting a pile of 
cash on fire by <strong>solving problems we don’t have</strong>?</p>

<h3 id="the-perfect-storm">The perfect storm</h3>

<p>There are a few things in recent history that may have contributed to the current state of things. First, a whole army of 
developers 
writing Javascript for the browser started self-identifying as 
“full-stack”, diving into server development and asynchronous code. Javascript is Javascript, right? What difference does it make 
what you create using it - user interfaces, servers, games, or embedded systems. <em>Right</em>? 
Node was still kind of a <a href="https://www.youtube.com/watch?v=M3BM9TB-8yA" target="_blank">learning project of one person</a>, and 
Javascript back then was a deeply problematic choice for server development.
<a href="https://notes.ericjiang.com/posts/751" target="_blank">Pointing this out</a> to still green server-side developers usually 
resulted in a lot of huffing and puffing. This is all they knew, after all. The world outside of Node 
effectively did not exist, the Node way was the only known way, and so this was the genesis of the 
stubborn, dogmatic thinking 
that we deal with to this day.</p>

<photo-element source="complexity/theway.webp" aspect="landscape" alt="Performance"></photo-element>

<p><strong>And then</strong>, a steady stream of 
<a href="https://en.wikipedia.org/wiki/Big_Tech" target="_blank">FAANG</a> veterans started merging into the river of startups, 
mentoring the newly-minted and highly impressionable young Javascript server-side engineers. The apostles of the Church of Complexity would 
assertively claim that “how they did things over at Google” was unquestionable and correct - even if it made no sense under 
current context and size. What 
do you <em>mean</em> you don’t have a separate <em>User Preferences Service</em>? That just <em>will not scale, bro!</em></p>

<p>But, it’s easy to blame the veterans and the newcomers for all of this. What else was happening? Oh yeah - easy money.</p>

<p>What do you do when you are flush with venture capital? You don’t 
<a href="https://www.youtube.com/embed/BzAdXyPYKQo?si=3lOVi1rhtaPC-nv4" target="_blank">go for revenue</a>, surely! On more than one 
occasion I received an email from management, asking everyone to be in the office, tidy up their desks and look busy, as a 
clouder of Patagonia vests was about to be paraded through the office. Investors needed to see explosive growth, but not in 
profitability, 
no. They just needed to see how quickly the company could hire ultra-expensive software engineers to do … <em>something</em>.</p>

<p>And now that you have these developers, what do you do with them? Well, they could build a simpler system that is easier to 
grow and
maintain, or they could conjure up a monstrous constellation of “microservices” that no one really 
understands. Microservices 
- the new way of writing scalable software! Are we just going to pretend that the concept of “distributed systems” never existed?
(Let’s skip the whole parsing of the nuances that microservices are not real distributed systems).</p>

<p>Back in the days when the tech industry was not such a bloated farce, distributed systems were respected, feared, and generally 
avoided - reserved only as the weapon of last resort for particularly gnarly problems. Everything with a distributed system 
becomes more challenging and time-consuming - development, debugging, deployment, testing, resilience. But I don’t know - maybe 
it’s all 
super easy now because 
<em>toooollling</em>.</p>

<p>There is no standard tooling for microservices-based development - there is no common 
framework. Working on distributed systems has gotten only marginally easier in 2020s. The Dockers and the 
Kuberneteses of the world did not magically take away the inherent complexity of a distributed setup.</p>

<p>I love referring to this
<a href="https://kenkantzer.com/learnings-from-5-years-of-tech-startup-code-audits/" target="_blank">summary of 5 years of startup audits</a>, 
as it is packed with common-sense conclusions based on hard evidence (and paid insights):</p>

<blockquote>
  <p>… the startups we audited that are now doing the best usually had an almost brazenly ‘Keep It Simple’ approach to
engineering. Cleverness for cleverness sake was abhorred. On the flip side, the companies where we were like ”woah,
these folks are smart as hell” for the most part kind of faded.</p>
</blockquote>

<p>Literally - “complexity kills”.</p>

<p>The 
<a href="https://podcasts.apple.com/mt/podcast/lessons-from-5-years-of-startup-code-audits/id341623264?i=1000567623452" target="_blank">audit</a>
revealed an interesting pattern, where many startups experienced a sort of collective imposter syndrome while building 
straight-forward, simple,
performant systems. There is a dogma attached to not starting out with microservices on day one - 
no matter the problem. “Everyone is doing microservices, yet we have a single Django monolith maintained by just a few engineers, 
and a MySQL instance - what are we doing wrong?”. The answer is almost always “nothing”.</p>

<p>Likewise, it’s common for seasoned engineers to experience 
hesitation and inadequacy in today’s tech world, and the good news is 
that, 
no - it’s probably not you. It’s common for teams to pretend like they are doing “webs cale”, hiding behind libraries, ORMs, and 
cache - 
confident in their expertise (they crushed that Leetcode!), yet they may not even be
<a href="https://www.reddit.com/r/programming/comments/f46f5a/comment/fhp26k8/?context=3" target="_blank">aware of database indexing basics</a>. 
You are operating in a sea of unjustified overconfidence, waste, and Dunning-Kruger, so who is really the imposter here?</p>

<h3 id="there-is-nothing-wrong-with-a-monolith">There is nothing wrong with a monolith</h3>

<p>The idea that you cannot grow without a system that looks like the infamous diagram of Afghanistan war 
strategy is largely a myth.</p>

<photo-element source="complexity/af.png" aspect="landscape"></photo-element>

<p>Dropbox, Twitter, Facebook, Instagram, Shopify, Stack Overflow - these companies and others started out as monolithic 
code bases. Many have a monolith at their core to this day. Stack Overflow makes it a 
<a href="https://stackexchange.com/performance" target="_blank">point of pride</a> how little hardware they need to run the massive site. 
Shopify is still a <a href="https://blog.quastor.org/p/shopify-ensures-consistent-reads">Rails monolith</a>, leveraging the tried and true 
<a href="https://twitter.com/ShopifyEng/status/1597983928018948096" target="_blank">Resque</a> to proces billions of tasks.</p>

<p>WhatsApp went supernova with their 
<a href="https://blog.quastor.org/p/whatsapp-scaled-1-billion-users-50-engineers" target="_blank">Erlang monolith and 50 engineers</a>.
How?</p>

<blockquote>
  <p>WhatsApp consciously keeps the engineering staff small to only about 50 engineers.</p>

  <p>Individual engineering teams are also small, consisting of 1 - 3 engineers and teams are each given a great deal of autonomy.</p>

  <p>In terms of servers, WhatsApp prefers to use a smaller number of servers and vertically scale each server to the highest 
extent possible.</p>
</blockquote>

<p>Instagram was acquired for billions - with a crew of 12.</p>

<p>And do you imagine Threads as an effort involving a whole Meta campus? Nope. They followed the
<a href="https://instagram-engineering.com/static-analysis-at-scale-an-instagram-story-8f498ab71a0c" target="_blank">Instagram model</a>, 
and this is the entire Threads team:</p>

<photo-element source="complexity/threads-team.webp" aspect="landscape"></photo-element>

<p>Perhaps claiming that <em>your</em> particular problem domain requires a massively complicated distributed system and an open office 
stuffed 
to the gills with turbo-geniuses is just crossing over into 
arrogance rather than brilliance?</p>

<h3 id="dont-solve-problems-you-dont-have">Don’t solve problems you don’t have</h3>

<p>It’s a simple question - what problem are you solving? Is it scale? How do you know how to break it all up for scale and performance? 
Do you have enough data to show what needs to be a separate service and why? Distributed systems are built for size and 
resilience. Can your system scale and be resilient at the same time? What happens if one of the services goes down or comes to a crawl? 
Just scale it up, yes? What about the <em>other</em> services that will get flooded with load? Did you war-game the endless permutations 
of things that can and will go wrong? Is there back pressure? Circuit breakers? Queues? Jitter? Sensible timeouts on every 
endpoint? Are there fool-proof guards to make sure a simple change does not bring everything down? 
The knobs you need to be aware of and tune are endless, and they are all specific to your system’s particular signature of 
usage and traffic.</p>

<p>The truth is that most companies will never reach the massive size that will actually require building a true distribute 
system. Your cos playing Amazon and Google - without 
their scale, expertise, and endless resources - is very likely just an egregious waste of money and time.</p>

<p><em>The only thing harder than a distributed system is a BAD distributed system</em>.</p>

<photo-element source="complexity/twitter3.png" aspect="landscape" alt="Performance"></photo-element>

<h3 id="but-each-teambut-separate-but-api">“But each team…but separate… but API”</h3>

<p>Trying to shove a distributed topology into your company’s structure is a noble effort, but it almost always backfires. It’s a 
common approach 
to break up a problem into smaller pieces and then solve those one by one. So, the thinking goes, if you break up one service 
into multiple ones, everything becomes easier, right?</p>

<p>The theory is sweet and elegant - each microservice is being maintained rigorously by a dedicated team, 
walled off behind a beautiful, backward-compatible, versioned API. In fact, this is all so steely that you rarely even have to 
communicate with that team - as if the microservice was maintained by a 3rd party vendor. It’s <em>simple</em>!</p>

<p>If that doesn’t sound familiar, that’s because this rarely happens. In reality, our Slack channels are <em>flooded</em> with 
messages from teams communicating about releases, bugs, configuration updates, breaking changes, and PSAs. Everyone 
needs to be on top of everything, all the time. And if that wasn’t great, it’s normal for one 
already-slammed team to half-ass multiple 
microservices instead of doing a great job on a single one, often changing ownership as people come and go.</p>

<p>In order to win the race, we don’t build <em>one</em> good race car - we build a fleet of shitty golf carts.</p>

<photo-element source="complexity/twitter2.png" aspect="landscape" alt="Performance"></photo-element>

<h3 id="what-you-lose">What you lose</h3>

<p>There are multiple pitfalls to building with microservices, and often that minefield is either not fully appreciated or simply 
ignored. Teams spend months writing highly customized tooling and learning lessons not 
related at all to the core product. Here are just some often overlooked aspects…</p>

<h4 id="say-goodbye-to-dry">Say goodbye to DRY</h4>

<p>After decades of teaching developers to write Don’t Repeat Yourself code, it seems we just stopped talking about it altogether.
Microservices by default are not DRY, with every service stuffed with redundant boilerplate. Very often the overhead of such 
“plumbing” is so heavy, and the size of the microservices is so small, that the average instance of a service has more “service” 
than 
“product”. So what about the common code that <em>can</em> be factored out?</p>

<ul>
  <li>Have a common library?</li>
  <li>How does the common library get updated? Keep different versions everywhere?</li>
  <li>Force updates regularly, creating dozens of pull requests across all repositories?</li>
  <li>Keep it all in a monorepo? That comes with its <em>own</em> set of problems.</li>
  <li>Allow for some code duplication?</li>
  <li>Forget it, each team gets to reinvent the wheel every time.</li>
</ul>

<p>Each company going this route faces these choices, and there are no good “ergonomic” options - you <em>have</em> to 
choose your version of the pain.</p>

<h4 id="developer-ergonomics-will-crater">Developer ergonomics will crater</h4>

<p>“Developer ergonomics” is the friction, the amount of effort a developer
must go through in order to get something done, be it working on a new feature or resolving a bug.</p>

<p>With microservices, an engineer has to have a mental map of the entire system in order to know what services  to bring up for any 
particular task, what teams to talk to, whom to talk to, and what about. The “you have to know everything before 
doing anything” 
principle. How 
do you keep on top of it? Spotify, a 
multi-billion dollar company, spent probably not negligible internal resources to build 
<a href="https://backstage.spotify.com/" target="_blank">Backstage</a>, software for cataloging its endless systems and services.</p>

<p>This should at least give you a clue that this game is not for everyone, and the price of the ride is <em>high</em>. So what about 
the <em>tooooling</em>? The Not Spotifies of the world are left with McGivering their own solutions, robustness and portability of 
which you can probably guess.</p>

<p>And how many teams actually streamline the process of starting a <em>YASS</em> - “yet another stupid service”? 
This includes:</p>

<ul>
  <li>Developer privileges in GitHub/GitLab</li>
  <li>Default environment variables and configuration</li>
  <li>CI/CD</li>
  <li>Code quality checkers</li>
  <li>Code review settings</li>
  <li>Branch rules and protections</li>
  <li>Monitoring and observability</li>
  <li>Test harness</li>
  <li>Infrastructure-as-code</li>
</ul>

<p>And of course, multiply this list by the number of programming languages used throughout the company. Maybe you have a 
usable 
template or a runbook? Maybe a frictionless, one-click system to 
launch a new service from scratch? It takes months to iron out all the kinks with this kind of automation. So, you can either 
work on your product, or you can be working on <em>toooooling</em>.</p>

<h4 id="integration-tests---lol">Integration tests - LOL</h4>

<p>As if the everyday microservices grind was not enough, you also forfeit the peace of mind offered by solid integration tests. 
Your single-service and unit tests are passing, but are your critical paths still intact after 
each commit? Who is in charge of the overall integration test suite, in Postman or wherever else? Is there one?</p>

<photo-element source="complexity/unit.gif" aspect="original-size" alt="Service tests"></photo-element>

<p>Integration testing a distributed setup is a nearly-impossible problem, so we pretty much gave up on that and replaced it with 
another one - Observability. Just like “microservices” are the new “distributed systems”, “observability” is the new 
“debugging in production”. Surely, you are not writing real software if you are not doing…. observability!</p>

<p>Observability has become its own sector, and you will pay in both pretty penny and in developer 
time for it. It doesn’t come as plug-and-pay either - you need to understand and implement canary releases, feature flags, etc. 
Who is doing that? One already 
<a href="https://renegadeotter.com/2023/07/26/i-am-not-your-cloud-person.html">overwhelmed</a> engineer?</p>

<p>As you can see, breaking up your problem does not make solving it easier - all you get is another set of <em>even 
harder problems</em>.</p>

<h3 id="what-about-just-services">What about just “services”?</h3>

<p>Why do your services need to be “micro”? What’s wrong with
<a href="https://leeatchison.com/app-architectures/moving-beyond-microservices-hype/" target="_blank">just services</a>? Some
startups have gone as far as create <em>a service for
each function</em>, and yes, “isn’t that just like Lambda” is a valid question. This 
gives you an idea of how far gone this unchecked cargo cult is.</p>

<p>So what do we do? 
<a href="https://www.fearofoblivion.com/build-a-modular-monolith-first" target="_blank">Starting with a monolith</a>
is one obvious choice. A pattern that could also  work in many instances is “trunk &amp; 
branches”, where the main “meat and potatoes” monolith is helped by “branch” services. A branch service can be a service that 
takes care of a clearly-identifiable and
separately-scalable load. A CPU-hungry <em>Image-Resizing Service</em> makes way more sense than a <em>User Registration Service</em>. Or do you
get so many registrations per second that it requires independent horizontal scaling?</p>

<photo-element source="complexity/really.gif" aspect="original-size" alt="Vertical"></photo-element>



<h3 id="the-pendulum-is-swinging-back">The pendulum is swinging back</h3>
<p>The hype, however, seems to be dying down. The VC cash faucet is tightening, and so the
businesses have been market-corrected into exercising common-sense decisions, recognizing that perhaps splurging on 
web-scale architectures when they don’t have web-scale problems is not sustainable.</p>

<photo-element source="complexity/twitter1.png" aspect="landscape" alt="Vertical"></photo-element>

<photo-element source="complexity/twitter4.png" aspect="landscape" alt="AWS"></photo-element>

<p>Ultimately, when faced with the need to travel from New York to Philadelphia, you have two options. 
You can either attempt to construct a highly intricate spaceship for an orbital descent to your destination, or you can simply 
purchase an Amtrak train ticket for a 90-minute ride. <em>That</em> is the problem at hand.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hacking the Book8088 for better accuracy (134 pts)]]></title>
            <link>https://martypc.blogspot.com/2023/09/hacking-book8088-for-better-accuracy.html</link>
            <guid>37476588</guid>
            <pubDate>Tue, 12 Sep 2023 03:05:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://martypc.blogspot.com/2023/09/hacking-book8088-for-better-accuracy.html">https://martypc.blogspot.com/2023/09/hacking-book8088-for-better-accuracy.html</a>, See on <a href="https://news.ycombinator.com/item?id=37476588">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-1388372834381468609">
<p>The <a href="https://arstechnica.com/gadgets/2023/07/going-deep-with-the-book-8088-the-brand-new-laptop-that-runs-like-its-1981/" target="_blank">Book8088 </a>is an interesting little machine. It is essentially a 1980's computer in a laptop form factor.</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEicW3ytc0vuyQCaJm6SbVo5Rcfjz6bkeRZx42BMrd3qOhE1TtlsiX1j5moJM5LJ-7Jh3xDrYxLRgae2ZG9eogUMbvngsUOtMEcvKAW2SEe8zmC0fcIOUPK2mNI7yD7RoCU362oKkGhXofdqB4J3RgOdwg7fs7mlA5smWoZt2cJv-l_W69xRNToQvJJx9c2B/s1348/book8088.JPG" imageanchor="1"><img data-original-height="1158" data-original-width="1348" height="344" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEicW3ytc0vuyQCaJm6SbVo5Rcfjz6bkeRZx42BMrd3qOhE1TtlsiX1j5moJM5LJ-7Jh3xDrYxLRgae2ZG9eogUMbvngsUOtMEcvKAW2SEe8zmC0fcIOUPK2mNI7yD7RoCU362oKkGhXofdqB4J3RgOdwg7fs7mlA5smWoZt2cJv-l_W69xRNToQvJJx9c2B/w400-h344/book8088.JPG" width="400"></a></p><p>With apologies to <a href="https://github.com/skiselev" target="_blank">Sergey Kiselev</a>, whom the manufacturers of the Book8088 <a href="https://forum.vcfed.org/index.php?threads/chinese-8088-based-laptop-system-with-pirated-8088-bios.1243152/" target="_blank">did a little dirty</a>, I couldn't resist ordering one myself to tinker with.&nbsp;</p><p>The Book8088 is trying hard to basically be compatible with the original IBM PC, containing some of the same or equivalent chips. It's natural to want to put it through its paces, and one of the best tests for IBM PC compatibility has to be the <a href="https://www.pouet.net/prod.php?which=65371" target="_blank">8088MPH demo</a>.&nbsp;&nbsp;If 8088MPH will run we must be operating pretty darn close to the original.&nbsp;</p><p>Looking at the specs of the Book8088, there's good reason to be optimistic.&nbsp; The machine supports a real 8088 CPU.&nbsp; Even better, there's a socketed CRTC chip, so the complex CRTC abuse the demo performs doesn't need to be emulated in any fashion.</p><p>My Book8088 came with an NEC V20 CPU.&nbsp; This CPU is a lot faster than the 8088, we'll need to replace it:</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjalO2Z-FXpF5Dx_XFwmjDfH6H4GXGnvfw0dDWNT4ssXg-Eg1zlFqoCU0wIviGS0bZAOV6YJtXL1KaVdbkCB0FRNxUx_8JZjsTNpS60pERli_DFHKSQ5kppJGYl_0daJ5ILqaXkWLJkuRgA8HSwHw54mmXl4zCOGKpULU9OnW7FmJtgqFnnAfpwtc6XvDpG/s1175/cpu_swap.jpg" imageanchor="1"><img data-original-height="998" data-original-width="1175" height="340" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjalO2Z-FXpF5Dx_XFwmjDfH6H4GXGnvfw0dDWNT4ssXg-Eg1zlFqoCU0wIviGS0bZAOV6YJtXL1KaVdbkCB0FRNxUx_8JZjsTNpS60pERli_DFHKSQ5kppJGYl_0daJ5ILqaXkWLJkuRgA8HSwHw54mmXl4zCOGKpULU9OnW7FmJtgqFnnAfpwtc6XvDpG/w400-h340/cpu_swap.jpg" width="400"></a></p><p>Additionally, the CRTC chip I received is not the same as you would find in an original IBM CGA card. Instead there's a Hitachi CRTC - let's replace it with a CGA-accurate Motorola MC6845:</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiOXlRQicpK5W-gUlwdURecUC6O99l_7Xe2E8-EBanRWo5eOWEmNZYF_cC1qxLX2xiRcM2Y6u3mLuC0pWbU9TbKDxS1J-traLp_OpRvAhe2mcnJhBkRvKRL72wQ0j6BVNdgKKpSugH7TQUAncE1W7dsPdHbS1PzYE5GR_NgeM8h4JCsaZfT72Ci9LemMwWa/s962/crtc_swap.jpg" imageanchor="1"><img data-original-height="805" data-original-width="962" height="335" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiOXlRQicpK5W-gUlwdURecUC6O99l_7Xe2E8-EBanRWo5eOWEmNZYF_cC1qxLX2xiRcM2Y6u3mLuC0pWbU9TbKDxS1J-traLp_OpRvAhe2mcnJhBkRvKRL72wQ0j6BVNdgKKpSugH7TQUAncE1W7dsPdHbS1PzYE5GR_NgeM8h4JCsaZfT72Ci9LemMwWa/w400-h335/crtc_swap.jpg" width="400"></a></p><p>Now, as it turns out, most of the demo <i>does</i> run, albeit in RGBI mode which loses out on all the cool composite artifact color effects. But most notably the famous Kefrens Bars effect does not display - the screen just goes blank.&nbsp; What's going wrong on the Book8088 vs a real IBM PC 5150?</p><p><a href="https://medium.com/@davidly_33504/the-book-8088-is-too-fast-c0a2f01a1cc8" target="_blank">As others have noted</a>, even with an 8088 swap, there's something a little fishy going on.</p><h2>DRAM Refresh DMA</h2><p>The original IBM PC used DRAM - 'dynamic' memory that had to be periodically refreshed, or it would lose charge and subsequently its memory contents. IBM was trying to keep the costs of the IBM PC down, so decided to utilize some of the accessory chips that the PC had to perform the task of DRAM refresh rather than add dedicated circuitry to handle it. Therefore one of three channels of the system's timer chip and one of four channels of the system's DMA controller are dedicated solely to the task of refreshing memory.&nbsp;</p><p>By default, every 72 CPU cycles, the timer chip counts down to 0 and sends an output pulse to the DMA controller, triggering a DMA request which eventually pulls the READY line to the CPU low, potentially stalling the CPU if it is in the middle of a bus transaction. During this time certain address lines are strobed, which is all that is needed to refresh the memory cells.</p><p>This has a variable impact on system performance. If the CPU is primarily performing long, arithmetic instructions such as division or multiplication, it won't really slow things down at all. If the CPU is instead copying memory with a string instruction, or executing a sequence of very short instructions&nbsp; requiring rapid fetching, then the impact can be quite substantial.&nbsp; Averaged out, the 8088 CPU in the IBM PC is about 5% slower than it otherwise would be without DRAM refresh.</p><p>If you're curious to know more about how DMA works on the IBM PC, I wrote a <a href="https://martypc.blogspot.com/2023/05/exploring-dma-on-ibm-pc.html" target="_blank">previous article on it</a>.</p><p>The Book8088 and many modern hobby PC clones like it usually forgo DRAM and its complications and instead use SRAM chips. The S stands for Static, and like the name suggests it does not require refreshing. Therefore we don't need to have this process going on at all, so we don't need to have timer channel #1 ticking away and we don't need DMA channel #0 configured for DRAM refresh, and our CPU can run 5% faster. Isn't that just a bonus?</p><p>Well, yes and no. When talking about compatibility with the original IBM PC, there were several software titles that made assumptions about the exact speed of the 8088 CPU, and they made those assumptions with the DRAM refresh performance impact baked-in. If we don't simulate DRAM refresh, we open ourselves up to compatibility issues.</p><p>The Kefrens effect in the 8088MPH demo is a good example. It is a perfectly cycle-counted effect. This effect does not tightly poll the CGA status register to determine when the CGA card is in hblank or vblank, or really where it is on the screen at all. It does not set up a normal screen resolution - instead, it draws a scanline at a time, 'racing the beam'. This is possible due to the fact that the CGA clock is an exact multiple of the CPU clock, so that a single CPU cycle equates to 3 pixels or 'hdots' on screen. Knowing that a single scanline takes 912 hdots to display means if we execute an effect somehow utilizing exactly 304 CPU cycles per scanline, that effect will run in perfect synchronization with the CGA card. And so that's exactly what the Kefrens effect does - it's some impressive coding.</p><table><tbody><tr><td><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEimrhVOWMuCJZzaX5gLtvs-K7mybXE9YXpMZ5_BYG9sNgFeLLjw5pR_Yckxgdy-vfLzbsHLObw2_06bTn50GQri-yJ250FNnBEB3WSiU_2x-1M4xUhxJzTr0KGeSty4udEsyvrPL-0fzdcrV-lPSGCUxuIw8pQhEolIyqa-4WAZjR_94lgqp8-BllKI8zmV/s658/kefrens_02.png"><img data-original-height="547" data-original-width="658" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEimrhVOWMuCJZzaX5gLtvs-K7mybXE9YXpMZ5_BYG9sNgFeLLjw5pR_Yckxgdy-vfLzbsHLObw2_06bTn50GQri-yJ250FNnBEB3WSiU_2x-1M4xUhxJzTr0KGeSty4udEsyvrPL-0fzdcrV-lPSGCUxuIw8pQhEolIyqa-4WAZjR_94lgqp8-BllKI8zmV/s16000/kefrens_02.png"></a></td></tr><tr><td>Kefrens Bars in 8088MPH - it looks better in motion!</td></tr></tbody></table><p>The reason that this effect does not work on a stock Book8088 is that the painstaking cycle counting done for the effect takes into account the wait state cycles incurred by DRAM refresh DMA on the IBM PC.</p><p>Since the Book8088 isn't doing DRAM refresh, the corresponding wait states don't occur, the effect runs too fast, and quickly is out of sync with the CGA card. Vsync signals happen at the wrong times, and I imagine the LCD controller on the Book8088 gets very upset and refuses to display an image at all.</p><h2>Can we just turn DMA on?</h2><p>It would be nice if we could just program the timer channel #1 to the appropriate value, and set up DMA channel #0 like the BIOS does, and then DRAM refresh would operate as it does on the IBM PC, just harmlessly addressing the system's SRAM but making our 8088 CPU operate at the correct speed.</p><p>We can write a short assembly program that attempts to do just that, and assemble it to 'startdma.com':</p>

<!--HTML generated using hilite.me--><div><pre><span>; startdma.asm</span>
<span>; begin DRAM refresh DMA if for some reason your BIOS didn't</span>

<span>cpu</span> <span>8086</span>
<span>org</span> <span>100h</span>

<span>%include "macros.asm"</span>
<span>%include "library.asm"</span>

<span>main:</span>

<span>begin:</span>  <span>jmp</span> <span>start</span>

        <span>e_init_dmac</span><span>         equ</span> <span>03h</span>     <span>; Initialize DMAC initialized</span>
        <span>dmac_ch0_addr_reg</span><span>   equ</span> <span>00h</span>     <span>; DMAC channel 0 base addres (W)</span>
        <span>dmac_ch0_count_reg</span><span>  equ</span> <span>01h</span>     <span>; DMAC channel 0 word count (W)</span>
        <span>dmac_mask_reg</span><span>       equ</span> <span>0Ah</span>     <span>; DMAC single mask bit register (W)</span>
        <span>dmac_mode_reg</span><span>       equ</span> <span>0Bh</span>     <span>; DMAC mode register (R/W)</span>
        <span>dmac_cmd_reg</span><span>        equ</span> <span>08h</span>     <span>; DMAC command register</span>
        
<span>start:</span>
        <span>; set up DRAM refresh on DMA channel 0</span>
        
        <span>mov</span>     <span>al</span>, <span>0ffh</span>                <span>; 16-bit memory refresh counter = 0FFFFh</span>
        <span>out</span>     <span>dmac_ch0_count_reg</span>, <span>al</span>  <span>; write low byte</span>
        <span>nop</span>
        <span>out</span>     <span>dmac_ch0_count_reg</span>, <span>al</span>  <span>; write high byte</span>
        <span>inc</span>     <span>ax</span>                      <span>; al = 0</span>
        <span>out</span>     <span>dmac_mask_reg</span>,<span>al</span>        <span>; unmask all DMA channels</span>
        <span>mov</span>     <span>al</span>, <span>58h</span>                 <span>; single mode, auto-init, read, channel 0</span>
        <span>out</span>     <span>dmac_mode_reg</span>,<span>al</span>        <span>; DMA Mode register</span>
        <span>mov</span>     <span>al</span>,<span>0</span>       
        <span>out</span>     <span>dmac_cmd_reg</span>, <span>al</span>        <span>; DMA Command register</span>
        
        <span>; set up pit channel #1 DMA timer</span>
        
                <span>pit_set_mode</span> <span>1</span>, <span>PIT_RWM_LSB</span>, <span>2</span>, <span>0</span>   <span>; Pit channel 1, LSB, RateGenerator, binary</span>
        <span>mov</span>     <span>al</span>, <span>12h</span>                             <span>; Default refresh value of 18</span>
                <span>pit_write_byte</span> <span>1</span>                    <span>; Write reload value to start timer</span>
                
                <span>dos_exit</span> <span>0</span>
        <span>ret</span>
</pre></div>


<p>We can run startdma.com and try 8088MPH, and... it makes no difference whatsoever.</p><p>If the designers of the Book8088 didn't really consider this to be an issue, it's quite possible they didn't bother to connect the output of the timer channel #1.&nbsp; Helpfully, ArsTechnica released <a href="https://cdn.arstechnica.net/wp-content/uploads/2023/07/Book8088-manual-and-original-BIOS.zip" target="_blank">schematics for this system</a>. Let's take a look:</p><table><tbody><tr><td><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjcZnFJ92XPOM_IbJW9EosKSk8gpz9sc1Hzi9m_zYd6HmrDm18u1S2p5gD0HjCkr6neRc3M9Pf_vhfysVD8QK1nr5NdUZBrvi9DooYuSyarnk6lSgvZZeYGLC7sei4fOD5dt8WK_UECjuOn7ntGWcV4diDm7ezqNduIJY_djtVBs9-wwPFyMdIYd63f_42z/s478/pit_schematic.PNG"><img data-original-height="363" data-original-width="478" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjcZnFJ92XPOM_IbJW9EosKSk8gpz9sc1Hzi9m_zYd6HmrDm18u1S2p5gD0HjCkr6neRc3M9Pf_vhfysVD8QK1nr5NdUZBrvi9DooYuSyarnk6lSgvZZeYGLC7sei4fOD5dt8WK_UECjuOn7ntGWcV4diDm7ezqNduIJY_djtVBs9-wwPFyMdIYd63f_42z/s16000/pit_schematic.PNG"></a></td></tr><tr><td>The Book8088 timer schematic</td></tr></tbody></table><p>Well, drat. Just as we feared, the output of timer channel #1, the "OUT1" pin, isn't connected to anything. At least they were kind enough to connect the channel #1 clock input and the gate pin, so the timer channel is usable and can be programmed, but it won't ever trigger the DMA controller.</p><p>Over on the DMA controller, we see a similar situation:</p><table><tbody><tr><td><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh3UB2CCuEWnzJ3HFA4OcdFtWIRlT_mS_kwuVrBSww-E4xP7-aeZPC5XA1Zrero9YzTKsZ45_5TWKqzTWFvTusu-z-pUA08EiiXGDl64AckaA0Mg1yK7kk1C1mAgwKCg91MKD0HfAscIvv6XG2tt2Knte0WnIAdq5OWAMK6gI4vQ8t0MZ2BsKeYE6NFek1i/s515/dma_schematic.png"><img data-original-height="515" data-original-width="454" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh3UB2CCuEWnzJ3HFA4OcdFtWIRlT_mS_kwuVrBSww-E4xP7-aeZPC5XA1Zrero9YzTKsZ45_5TWKqzTWFvTusu-z-pUA08EiiXGDl64AckaA0Mg1yK7kk1C1mAgwKCg91MKD0HfAscIvv6XG2tt2Knte0WnIAdq5OWAMK6gI4vQ8t0MZ2BsKeYE6NFek1i/s16000/dma_schematic.png"></a></td></tr><tr><td>The Book8088 DMA schematic</td></tr></tbody></table><p>The "DREQ0" pin that would normally connect to the timer's OUT1 pin is tied to ground.&nbsp;</p><p>We can physically fix this by reconnecting the timer and DMA controller, although that ground connection is a bit of a pain - we'll need to cut that trace.</p><h2>Fixing the Book8088</h2><p>The DMA controller is a Renesas CS82C37A , a CMOS variant of the original Intel 8237A Programmable Interrupt Controller. It is in a 44-PLCC package. Taking a peek at the white paper shows us the pinout:</p><div><table><tbody><tr><td><a href="https://blogger.googleusercontent.com/img/a/AVvXsEhWqPz8AUg6dgwcJOeUB12BOy3TGYW-k4Fwi54t4zzW2aQAcKvhGSchbJNSEPak3_6K9c770Pt4IyyUDJLuszpo5V5SlZZZRDDRCEEf3IVNUI1_6ZtwJn8uy4E6_SYZYmMdFcpb_67TvbSyqIhFYW6ZBEq2oOmKsVoTfRUAeiFrSzRQnpsv9OEvZRjbECSe"><img alt="" data-original-height="909" data-original-width="807" height="400" src="https://blogger.googleusercontent.com/img/a/AVvXsEhWqPz8AUg6dgwcJOeUB12BOy3TGYW-k4Fwi54t4zzW2aQAcKvhGSchbJNSEPak3_6K9c770Pt4IyyUDJLuszpo5V5SlZZZRDDRCEEf3IVNUI1_6ZtwJn8uy4E6_SYZYmMdFcpb_67TvbSyqIhFYW6ZBEq2oOmKsVoTfRUAeiFrSzRQnpsv9OEvZRjbECSe=w355-h400" width="355"></a></td></tr><tr><td>DMA controller pinout</td></tr></tbody></table><p>DREQ0 is Pin22. We just need to look at the helpfully supplied PCB diagram:</p></div><table><tbody><tr><td><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi0J1uJ1v1GmwmtPvZ-k0a_XAMMFxbkuTE_At9IWG7b5fZAKdw0kQIcxxCRDSNX9gGTyHI4NNL4L5qf2vPmiAS5W5GkTVqL-UqfrCouk3vjj16rGnRVJTEj7BsvFP7bza8f39jErwF7XknuSeF10BudKGDJHPmXUgISKRjy9TQqmxCpAKp4N3T7R6xGSJl0/s611/dma_pinout.png"><img data-original-height="605" data-original-width="611" height="317" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi0J1uJ1v1GmwmtPvZ-k0a_XAMMFxbkuTE_At9IWG7b5fZAKdw0kQIcxxCRDSNX9gGTyHI4NNL4L5qf2vPmiAS5W5GkTVqL-UqfrCouk3vjj16rGnRVJTEj7BsvFP7bza8f39jErwF7XknuSeF10BudKGDJHPmXUgISKRjy9TQqmxCpAKp4N3T7R6xGSJl0/s320/dma_pinout.png" width="320"></a></td></tr><tr><td>DREQ0 pin</td></tr></tbody></table><p>Unfortunately, this pin is connected to a rather wide trace with a via to ground, making it a bit of a pain to cut, but thankfully there is enough access to the side of the socket so is fairly straightforward, as long as we are careful.</p><table><tbody><tr><td><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgjVvELCuETtPYBNfwyAjydMGUJFbrmvvfb43p3kJgMnA3pIBnptEvhP9a5HIbOUwPwumCuPlRkQNHQhYZYX70UUCqLMZCdYTIbCm0Dn_YXaziahx_0BjfvhQeLy9oFdTay96hmcOZ94kuWzMmVM3yRVPdqYQmQuTMHZu01pZJ_-QoUaG_uUFKcZxKz3l9J/s1367/cutme2.jpg" imageanchor="1"><img data-original-height="769" data-original-width="1367" height="225" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgjVvELCuETtPYBNfwyAjydMGUJFbrmvvfb43p3kJgMnA3pIBnptEvhP9a5HIbOUwPwumCuPlRkQNHQhYZYX70UUCqLMZCdYTIbCm0Dn_YXaziahx_0BjfvhQeLy9oFdTay96hmcOZ94kuWzMmVM3yRVPdqYQmQuTMHZu01pZJ_-QoUaG_uUFKcZxKz3l9J/w400-h225/cutme2.jpg" width="400"></a></td></tr><tr><td>Scrape the trace off before the via here, carefully.</td></tr></tbody></table><p>Use a continuity checker to verify that this pin is no longer connected to ground. Even a tiny sliver of trace can cause issues.</p><p>We will also need the DACK0 line, pin #28, for part of our DRAM refresh logic. This pin runs out to the ISA connector. This is an odd choice, since with DREQ0 connected to ground, the DACK0 line isn't very useful.&nbsp; Even more puzzling is DACK1 is tied to ground, but DREQ1 is not.</p><p>I am not sure what contributed to these design decisions, did they get their lines crossed?</p><p>This being a surface-mount socket, our options for attaching our wires are a little limited. If we take stranded, 28 gauge wire, we can effectively drape them across the contacts of the empty socket, then push the chip back in on top of them. A gentle tug proves these connections reasonably secure. Be sure to check there is no connectivity between adjacent pins - the stranded wires can splay out and potentially short.</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3yq9pM-fvtCa6mBoJowWsO91kZ-U-J3YT5SQR4PAZkooyfuTGcVM9a3eQJKPlwK-CDq678gtF28o5rjULzEwrAqjHsSMtffG-qZ6QVqbrGTl8IdoQ0oPEyuWMf6CnYYiMS4RL_NjltLhniWUOKo97n5kc3wbljC353GYw4awyto6ZA6EUxEtFlFk1jzlH/s1575/dmac_wires01.JPG"><img data-original-height="1160" data-original-width="1575" height="295" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3yq9pM-fvtCa6mBoJowWsO91kZ-U-J3YT5SQR4PAZkooyfuTGcVM9a3eQJKPlwK-CDq678gtF28o5rjULzEwrAqjHsSMtffG-qZ6QVqbrGTl8IdoQ0oPEyuWMf6CnYYiMS4RL_NjltLhniWUOKo97n5kc3wbljC353GYw4awyto6ZA6EUxEtFlFk1jzlH/w400-h295/dmac_wires01.JPG" width="400"></a></p><p>DREQ0 will go over to the timer chip, but it can't connect to the output of timer channel #1 directly.&nbsp; The timer is driven in Rate Generator mode, which stays high most of the time, dropping low on a 1 count for one tick.&nbsp; DREQ0 is level-triggered; if directly connected, DRAM refresh DMA would run constantly, and our PC would be much slower than intended.</p><table><tbody><tr><td><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhdLHZyNdc308_1Mj5wmXKFtBvTF2Kfls2S2r2OQsgxkRutENe7DCfYeiEto2ciKm59oYIuPyp0aALTK5ywY_capRquzNPgyZjdc7FrEwQZTGzXpmgy2ydNZyJ511XZrb6izyJdtASx7qfiI-uYGhI5PP24dqqie_rZt64K_mxqLnWk5Wq0m5A9WD0EcpPk/s779/dma_circuit02.PNG"><img data-original-height="266" data-original-width="779" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhdLHZyNdc308_1Mj5wmXKFtBvTF2Kfls2S2r2OQsgxkRutENe7DCfYeiEto2ciKm59oYIuPyp0aALTK5ywY_capRquzNPgyZjdc7FrEwQZTGzXpmgy2ydNZyJ511XZrb6izyJdtASx7qfiI-uYGhI5PP24dqqie_rZt64K_mxqLnWk5Wq0m5A9WD0EcpPk/s16000/dma_circuit02.PNG"></a></td></tr><tr><td>The IBM 5150 DREQ0 logic circuit</td></tr></tbody></table><p>Instead, DREQ0 is driven by the output of a 74LS74 flip-flop, which is clocked by the channel #1 output. When there is a low to high transition of the timer output, the flipflop will take its input - tied to 5V, and output it on Q, sending our DREQ0 signal to the DMA controller. Notice the reset line is tied to DACK0; once the DMA controller acknowledges the DMA operation, the DREQ0 line will drop low. This ensures we only perform one DMA operation per timer terminal count.</p><p>This is easy enough to wire up if you happen to have a 74LS74 lying around:</p><table><tbody><tr><td><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiwFBP9WfDKKrKarlIYWeeldBp7g4XlaPsXmVwonZNIPcLCu_PvxD9Z9ECKadvOwysz7P3r6K80Pyt99jF3NcIohFfuQL5fkITSsFQBQ32T_2BEjWWTyg6yNMpu8BA7Irm8tgBZ6zQxOVg0FW93LoOqu4oPcqCGE0iXxAXINmS50pZqd2RVrIJOc0w3nWNO/s1022/74ls74.JPG"><img data-original-height="685" data-original-width="1022" height="428" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiwFBP9WfDKKrKarlIYWeeldBp7g4XlaPsXmVwonZNIPcLCu_PvxD9Z9ECKadvOwysz7P3r6K80Pyt99jF3NcIohFfuQL5fkITSsFQBQ32T_2BEjWWTyg6yNMpu8BA7Irm8tgBZ6zQxOVg0FW93LoOqu4oPcqCGE0iXxAXINmS50pZqd2RVrIJOc0w3nWNO/w640-h428/74ls74.JPG" width="640"></a></td></tr><tr><td>The DREQ0 74LS74 flipflop</td></tr></tbody></table><p>The red wire is our 5V line, tying the D and PR lines to VCC; DACK0 comes in on our periwinkle wire and DREQ0 on the seafoam green wire. The timer channel 1 comes in on the yellow wire, and of course, black is our ground.&nbsp; If we trim the little breadboard, it fits pretty nicely in the bare spot beside the CGA ROM. I stuck it on with a square of double-stick gorilla tape:</p><table><tbody><tr><td><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi6GG2T9HuIZTFa2ie1YVxlO97NZnv4WrDL3Ri_6F72KsDKmnaYbHHmxotlnySiHVnKbvxzFVwHhm5__3K3GR-yox4L8zraIFTxAoBNI0FR2EMMLoSR3sm2w3edgty9sXjSyulr7Z50KT9bZiLG6ddLwvuTdmp8ZJmOa8J8setYxyLYzCxuyHvAWxwXrH2F/s3224/dram_circuit_01.jpg"><img data-original-height="1960" data-original-width="3224" height="390" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi6GG2T9HuIZTFa2ie1YVxlO97NZnv4WrDL3Ri_6F72KsDKmnaYbHHmxotlnySiHVnKbvxzFVwHhm5__3K3GR-yox4L8zraIFTxAoBNI0FR2EMMLoSR3sm2w3edgty9sXjSyulr7Z50KT9bZiLG6ddLwvuTdmp8ZJmOa8J8setYxyLYzCxuyHvAWxwXrH2F/w640-h390/dram_circuit_01.jpg" width="640"></a></td></tr><tr><td>The final assembled DRAM refresh DMA circuit<span>&nbsp;</span></td></tr></tbody></table><h2>Testing&nbsp;</h2><p>Let's try the MIPS 1.20 benchmark first, to see how we square up against the baseline of an IBM PC.</p><p>Before running startdma, we can see we are about 5% faster than baseline:</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiFKSw0fHfg28HhJp2lbiI2FynZ2TEUGZC70AtlADm7nouvbreoogoGQTLrpXsqxBnLmYyFw9Q0hkn5qBWVUOtTWbxHsmhtxRa8sHKRZ3HRl3ElTQIPrIQ2Nc14Inp7tEacvytW8-bhE6_bz4VzvplaOLTXHdpj6BevYu-t0Yz_Mv_ZtVFqrfjr9QBntmUk/s1626/mips_toofast.JPG"><img data-original-height="762" data-original-width="1626" height="301" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiFKSw0fHfg28HhJp2lbiI2FynZ2TEUGZC70AtlADm7nouvbreoogoGQTLrpXsqxBnLmYyFw9Q0hkn5qBWVUOtTWbxHsmhtxRa8sHKRZ3HRl3ElTQIPrIQ2Nc14Inp7tEacvytW8-bhE6_bz4VzvplaOLTXHdpj6BevYu-t0Yz_Mv_ZtVFqrfjr9QBntmUk/w640-h301/mips_toofast.JPG" width="640"></a></p><p>After, we're right on the money:</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEinTGAaq5mSyDQSQWHhFlfKw3S8hGerj7Cw6iThX3NIhCl33IAzYRbZ4AfPLOL2dEpLPVK65qRc1eGNFqxoAhZ2c2qsofECgTBhvYXm-W5zdh0CzCp8KMwUJL_5VVzQ2bzuLvjlTv6SdQZgYUCEVn4D-aLSjXVxXz2_dGK4RU143iqozsodVNyD-pC2iO2-/s1360/mips_justright.jpg"><img data-original-height="629" data-original-width="1360" height="296" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEinTGAaq5mSyDQSQWHhFlfKw3S8hGerj7Cw6iThX3NIhCl33IAzYRbZ4AfPLOL2dEpLPVK65qRc1eGNFqxoAhZ2c2qsofECgTBhvYXm-W5zdh0CzCp8KMwUJL_5VVzQ2bzuLvjlTv6SdQZgYUCEVn4D-aLSjXVxXz2_dGK4RU143iqozsodVNyD-pC2iO2-/w640-h296/mips_justright.jpg" width="640"></a></p><p>Let's try the 8088MPH CPU test. It will certainly complain if we aren't running at the right speed, and without startdma, it does:</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgsAkn3oxiU14szV-pTvuj4BORyGtCj_Q8BTDwejRrZzRKcplWl5snShfX0lpx2LDjiO6kmuhpWaeEoZRjx9Qn86wr1h47FYCiBv1Tc0RMR12SK6dYQUzwAMIG1BZqPeUjK-7P1If2ROvvLZwcNEZ39AEapJ85b18QIB46uRkLORfW_ronyC6fCjYesSSTg/s1633/8088_toofast.jpg"><img data-original-height="568" data-original-width="1633" height="222" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgsAkn3oxiU14szV-pTvuj4BORyGtCj_Q8BTDwejRrZzRKcplWl5snShfX0lpx2LDjiO6kmuhpWaeEoZRjx9Qn86wr1h47FYCiBv1Tc0RMR12SK6dYQUzwAMIG1BZqPeUjK-7P1If2ROvvLZwcNEZ39AEapJ85b18QIB46uRkLORfW_ronyC6fCjYesSSTg/w640-h222/8088_toofast.jpg" width="640"></a></p><p>After, 8088MPH is content with our CPU speed:</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgMv7OpEKIj3So9RLkvvZPrJ6DAULyUXvpip8gGe09yhLcanC0X1o6iurjg-nmRKiePaTLb4Sqv-GUXwbpwijkGx_Gok9Ywu-LWx89oa-4kd-XiqyWDY6fb1bsS2YcLDRXfzJiVQka6xs4rMN6WTluvG3xNJ536srpGw7MIrqoSaa6hMY6hCxHxP92-PcV9/s1242/8088_justright.jpg"><img data-original-height="438" data-original-width="1242" height="226" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgMv7OpEKIj3So9RLkvvZPrJ6DAULyUXvpip8gGe09yhLcanC0X1o6iurjg-nmRKiePaTLb4Sqv-GUXwbpwijkGx_Gok9Ywu-LWx89oa-4kd-XiqyWDY6fb1bsS2YcLDRXfzJiVQka6xs4rMN6WTluvG3xNJ536srpGw7MIrqoSaa6hMY6hCxHxP92-PcV9/w640-h226/8088_justright.jpg" width="640"></a></p><p>The real test however, is to see if the cycle-counted Kefrens Bars effect works.&nbsp;</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgXXw5uDLUuU58IVMUl7Z4VPoOnerFTr7ktkGTFEmoFUxnfS-jkJWce7K4bRhOVbsZCG0uSABVxhWHcPjQO51lB_f_MjDa26C7qTAG4t_2dkMHufdr5qyxAqG51g7F1kuclc9oXkJ99-ho4gkR3V3SDk9k88RWgyjfPNS2OK38QF2tAV3PzMrM4DYrvZcKQ/s1277/kefrens_success.jpg"><img data-original-height="909" data-original-width="1277" height="456" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgXXw5uDLUuU58IVMUl7Z4VPoOnerFTr7ktkGTFEmoFUxnfS-jkJWce7K4bRhOVbsZCG0uSABVxhWHcPjQO51lB_f_MjDa26C7qTAG4t_2dkMHufdr5qyxAqG51g7F1kuclc9oXkJ99-ho4gkR3V3SDk9k88RWgyjfPNS2OK38QF2tAV3PzMrM4DYrvZcKQ/w640-h456/kefrens_success.jpg" width="640"></a></p><p>And it does! It's a shame we can't enjoy 8088MPH properly without a composite display, and the Book8088 doesn't have any sort of video-out, composite or otherwise. Maybe we can add one?&nbsp;</p><p>You might be curious about the 'sequel' to 8088MPH as well - <a href="https://www.pouet.net/prod.php?which=91938" target="_blank">Area 5150</a>.&nbsp; As it turns out, the final two effects are a bit trickier. Even with our DMA fix, they still show a black screen. It's possible that the Book8088's CPLD-implemented CGA logic isn't up to snuff - but I haven't given up hope.&nbsp;</p><p>Stay tuned :)</p><br>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Arxiv.org is experiencing a DDoS attack (114 pts)]]></title>
            <link>https://blog.arxiv.org/2023/09/11/arxiv-org-is-experiencing-a-ddos-attack/</link>
            <guid>37476281</guid>
            <pubDate>Tue, 12 Sep 2023 02:12:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.arxiv.org/2023/09/11/arxiv-org-is-experiencing-a-ddos-attack/">https://blog.arxiv.org/2023/09/11/arxiv-org-is-experiencing-a-ddos-attack/</a>, See on <a href="https://news.ycombinator.com/item?id=37476281">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-1483">
	
	<div>
		
		<p><span>arXiv users may be experiencing email disruption due to a DDOS attack. Over the past few days, a small number of users issued over a million email change requests.</span></p>
<p><span>These requests originated from over 200 IP addresses – almost all owned by an ISP for a particular province in China. The confirmation emails for this volume of requests overwhelmed our email service. As a result, many arXiv users may not have received their daily emails. And other users may not have received their confirmation emails for registering accounts, or legitimate email change requests.</span></p>
<p><span>We are taking measures to mitigate this attack, including temporarily blocking certain IP ranges. </span><span>Unfortunately, this may mean some legitimate users will be unable to access arXiv until this issue is resolved. We will shortly be reaching out to the abuse desk of the affected ISP for assistance.</span></p>
<p><span>arXiv operates with a very small development and operations staff. We’re really not equipped to combat DDOS attacks and must rely on the goodwill of the world community in order to continue offering our services.</span></p>
<p>We apologize to any arXiv users that have been affected by this disruption.</p>
<p>We will continue monitoring the situation and update the community.</p>

		
			</div><!-- .entry-content -->

	</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Caddy is the first and only web server to use HTTPS automatically and by default (146 pts)]]></title>
            <link>https://caddyserver.com/docs/automatic-https</link>
            <guid>37476218</guid>
            <pubDate>Tue, 12 Sep 2023 02:02:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://caddyserver.com/docs/automatic-https">https://caddyserver.com/docs/automatic-https</a>, See on <a href="https://news.ycombinator.com/item?id=37476218">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					<article>
<p><strong>Caddy is the first and only web server to use HTTPS automatically <em>and by default</em>.</strong></p>
<p>Automatic HTTPS provisions TLS certificates for all your sites and keeps them renewed. It also redirects HTTP to HTTPS for you! Caddy uses safe and modern defaults -- no downtime, extra configuration, or separate tooling is required.</p>

<p>Here's a 28-second video showing how it works:</p>
<iframe width="100%" height="480" src="https://www.youtube-nocookie.com/embed/nk4EWHvvZtI?rel=0" frameborder="0" allowfullscreen=""></iframe>
<p><strong>Menu:</strong></p>
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#activation">Activation</a></li>
<li><a href="#effects">Effects</a></li>
<li><a href="#hostname-requirements">Hostname requirements</a></li>
<li><a href="#local-https">Local HTTPS</a></li>
<li><a href="#testing">Testing</a></li>
<li><a href="#acme-challenges">ACME Challenges</a></li>
<li><a href="#on-demand-tls">On-Demand TLS</a></li>
<li><a href="#errors">Errors</a></li>
<li><a href="#storage">Storage</a></li>
<li><a href="#wildcard-certificates">Wildcard certificates</a></li>
</ul>
<h2 id="overview">Overview</h2>
<p><strong>By default, Caddy serves all sites over HTTPS.</strong></p>

<p>Caddy keeps all managed certificates renewed and redirects HTTP (default port <code>80</code>) to HTTPS (default port <code>443</code>) automatically.</p>
<p><strong>For local HTTPS:</strong></p>
<ul>
<li>Caddy may prompt for a password to install its unique root certificate into your trust store. This happens only once per root; and you can remove it at any time.</li>
<li>Any client accessing the site without trusting Caddy's root CA certificate will show security errors.</li>
</ul>
<p><strong>For public domain names:</strong></p>

<ul>
<li>If your domain's A/AAAA records point to your server,</li>
<li>ports <code>80</code> and <code>443</code> are open externally,</li>
<li>Caddy can bind to those ports (<em>or</em> those ports are forwarded to Caddy),</li>
<li>your <a href="https://caddyserver.com/docs/conventions#data-directory">data directory</a> is writeable and persistent,</li>
<li>and your domain name appears somewhere relevant in the config,</li>
</ul>
<p>then sites will be served over HTTPS automatically. You won't have to do anything else about it. It just works!</p>
<p>Because HTTPS utilizes a shared, public infrastructure, you as the server admin should understand the rest of the information on this page so that you can avoid unnecessary problems, troubleshoot them when they occur, and properly configure advanced deployments.</p>
<h2 id="activation">Activation</h2>
<p>Caddy implicitly activates automatic HTTPS when it knows a domain name (i.e. hostname) or IP address it is serving. There are various ways to tell Caddy your domain/IP, depending on how you run or configure Caddy:</p>
<ul>
<li>A <a href="https://caddyserver.com/docs/caddyfile/concepts#addresses">site address</a> in the <a href="https://caddyserver.com/docs/caddyfile">Caddyfile</a></li>
<li>A <a href="https://caddyserver.com/docs/json/apps/http/servers/routes/match/host/">host matcher</a> in a <a href="https://caddyserver.com/docs/modules/http#servers/routes">JSON route</a></li>
<li>Command line flags like <a href="https://caddyserver.com/docs/command-line#caddy-file-server">--domain</a> or <a href="https://caddyserver.com/docs/command-line#caddy-reverse-proxy">--from</a></li>
<li>The <a href="https://caddyserver.com/docs/json/apps/tls/certificates/automate/">automate</a> certificate loader</li>
</ul>
<p>Any of the following will prevent automatic HTTPS from being activated, either in whole or in part:</p>
<ul>
<li>Explicitly disabling it <a href="https://caddyserver.com/docs/json/apps/http/servers/automatic_https/">via JSON</a> or <a href="https://caddyserver.com/docs/caddyfile/options#auto-https">via Caddyfile</a></li>
<li>Not providing any hostnames or IP addresses in the config</li>
<li>Listening exclusively on the HTTP port</li>
<li>Prefixing the <a href="https://caddyserver.com/docs/caddyfile/concepts#addresses">site address</a> with <code>http://</code> in the Caddyfile</li>
<li>Manually loading certificates (unless <a href="https://caddyserver.com/docs/json/apps/http/servers/automatic_https/ignore_loaded_certificates/"><code>ignore_loaded_certificates</code></a> is set)</li>
</ul>
<p><strong>Special cases:</strong></p>

<h2 id="effects">Effects</h2>
<p>When automatic HTTPS is activated, the following occurs:</p>
<ul>
<li>Certificates are obtained and renewed for <a href="#hostname-requirements">all domain names</a></li>
<li>The default port (if any) is changed to the <a href="https://caddyserver.com/docs/modules/http#https_port">HTTPS port</a> <code>443</code></li>
<li>HTTP is redirected to HTTPS (this uses <a href="https://caddyserver.com/docs/modules/http#http_port">HTTP port</a> <code>80</code>)</li>
</ul>
<p>Automatic HTTPS never overrides explicit configuration.</p>
<p>You can <a href="https://caddyserver.com/docs/json/apps/http/servers/automatic_https/">customize or disable automatic HTTPS</a> if necessary; for example, you can skip certain domain names or disable redirects (for Caddyfile, do this with <a href="https://caddyserver.com/docs/caddyfile/options">global options</a>).</p>
<h2 id="hostname-requirements">Hostname requirements</h2>
<p>All hostnames (domain names) qualify for fully-managed certificates if they:</p>
<ul>
<li>are non-empty</li>
<li>consist only of alphanumerics, hyphens, dots, and wildcard (<code>*</code>)</li>
<li>do not start or end with a dot (<a href="https://tools.ietf.org/html/rfc1034#section-3.5">RFC 1034</a>)</li>
</ul>
<p>In addition, hostnames qualify for publicly-trusted certificates if they:</p>
<ul>
<li>are not localhost (including <code>.localhost</code> and <code>.local</code> TLDs)</li>
<li>are not an IP address</li>
<li>have only a single wildcard <code>*</code> as the left-most label</li>
</ul>
<h2 id="local-https">Local HTTPS</h2>
<p>Caddy uses HTTPS automatically for all sites with a host (domain, IP, or hostname) specified, including internal and local hosts. Some hosts are either not public (e.g. <code>127.0.0.1</code>, <code>localhost</code>) or do not generally qualify for publicly-trusted certificates (e.g. IP addresses -- you can get certificates for them, but only from some CAs). These are still served over HTTPS unless disabled.</p>
<p>To serve non-public sites over HTTPS, Caddy generates its own certificate authority (CA) and uses it to sign certificates. The trust chain consists of a root and intermediate certificate. Leaf certificates are signed by the intermediate. They are stored in <a href="https://caddyserver.com/docs/conventions#data-directory">Caddy's data directory</a> at <code>pki/authorities/local</code>.</p>
<p>Caddy's local CA is powered by <a href="https://smallstep.com/certificates/">Smallstep libraries <img src="https://caddyserver.com/resources/images/external-link.svg"></a>.</p>
<p>Local HTTPS does not use ACME nor does it perform any DNS validation. It works only on the local machine and is trusted only where the CA's root certificate is installed.</p>
<h3 id="ca-root">CA Root</h3>
<p>The root's private key is uniquely generated using a cryptographically-secure pseudorandom source and persisted to storage with limited permissions. It is loaded into memory only to perform signing tasks, after which it leaves scope to be garbage-collected.</p>
<p>Although Caddy can be configured to sign with the root directly (to support non-compliant clients), this is disabled by default, and the root key is only used to sign intermediates.</p>
<p>The first time a root key is used, Caddy will try to install it into the system's local trust store(s). If it does not have permission to do so, it will prompt for a password. This behavior can be disabled in the configuration if it is not desired. If this fails due to being run as an unprivileged user, you may run <a href="https://caddyserver.com/docs/command-line#caddy-trust"><code>caddy trust</code></a> to retry installation as a privileged user.</p>

<p>After Caddy's root CA is installed, you will see it in your local trust store as "Caddy Local Authority" (unless you've configured a different name). You can uninstall it any time if you wish (the <a href="https://caddyserver.com/docs/command-line#caddy-untrust"><code>caddy untrust</code></a> command makes this easy).</p>
<p>Note that automatically installing the certificate into the local trust stores is for convenience only and isn't guaranteed to work, especially if containers are being used or if Caddy is being run as an unprivileged system service. Ultimately, if you are relying on internal PKI, it is the system administrator's responsibility to ensure Caddy's root CA is properly added to the necessary trust stores (this is outside the scope of the web server).</p>
<h3 id="ca-intermediates">CA Intermediates</h3>
<p>An intermediate certificate and key will also be generated, which will be used for signing leaf (individual site) certificates.</p>
<p>Unlike the root certificate, intermediate certificates have a much shorter lifetime and will automatically be renewed as needed.</p>
<h2 id="testing">Testing</h2>
<p>To test or experiment with your Caddy configuration, make sure you <a href="https://caddyserver.com/docs/modules/tls.issuance.acme#ca">change the ACME endpoint</a> to a staging or development URL, otherwise you are likely to hit rate limits which can block your access to HTTPS for up to a week, depending on which rate limit you hit.</p>
<p>One of Caddy's default CAs is <a href="https://letsencrypt.org/">Let's Encrypt <img src="https://caddyserver.com/resources/images/external-link.svg"></a>, which has a <a href="https://letsencrypt.org/docs/staging-environment/">staging endpoint <img src="https://caddyserver.com/resources/images/external-link.svg"></a> that is not subject to the same <a href="https://letsencrypt.org/docs/rate-limits/">rate limits <img src="https://caddyserver.com/resources/images/external-link.svg"></a>:</p>
<pre><code>https://acme-staging-v02.api.letsencrypt.org/directory
</code></pre>
<h2 id="acme-challenges">ACME challenges</h2>
<p>Obtaining a publicly-trusted TLS certificate requires validation from a publicly-trusted, third-party authority. These days, this validation process is automated with the <a href="https://tools.ietf.org/html/rfc8555">ACME protocol <img src="https://caddyserver.com/resources/images/external-link.svg"></a>, and can be performed one of three ways ("challenge types"), described below.</p>
<p>The first two challenge types are enabled by default. If multiple challenges are enabled, Caddy chooses one at random to avoid accidental dependence on a particular challenge. Over time, it learns which challenge type is most successful and will begin to prefer it first, but will fall back to other available challenge types if necessary.</p>
<h3 id="http-challenge">HTTP challenge</h3>
<p>The HTTP challenge performs an authoritative DNS lookup for the candidate hostname's A/AAAA record, then requests a temporary cryptographic resource over port <code>80</code> using HTTP. If the CA sees the expected resource, a certificate is issued.</p>
<p>This challenge requires port <code>80</code> to be externally accessible. If Caddy cannot listen on port 80, packets from port <code>80</code> must be forwarded to Caddy's <a href="https://caddyserver.com/docs/json/apps/http/http_port/">HTTP port</a>.</p>
<p>This challenge is enabled by default and does not require explicit configuration.</p>
<h3 id="tls-alpn-challenge">TLS-ALPN challenge</h3>
<p>The TLS-ALPN challenge performs an authoritative DNS lookup for the candidate hostname's A/AAAA record, then requests a temporary cryptographic resource over port <code>443</code> using a TLS handshake containing special ServerName and ALPN values. If the CA sees the expected resource, a certificate is issued.</p>
<p>This challenge requires port <code>443</code> to be externally accessible. If Caddy cannot listen on port 443, packets from port <code>443</code> must be forwarded to Caddy's <a href="https://caddyserver.com/docs/json/apps/http/https_port/">HTTPS port</a>.</p>
<p>This challenge is enabled by default and does not require explicit configuration.</p>
<h3 id="dns-challenge">DNS challenge</h3>
<p>The DNS challenge performs an authoritative DNS lookup for the candidate hostname's <code>TXT</code> records, and looks for a special <code>TXT</code> record with a certain value. If the CA sees the expected value, a certificate is issued.</p>
<p>This challenge does not require any open ports, and the server requesting a certificate does not need to be externally accessible. However, the DNS challenge requires configuration. Caddy needs to know the credentials to access your domain's DNS provider so it can set (and clear) the special <code>TXT</code> records. If the DNS challenge is enabled, other challenges are disabled by default.</p>
<p>Since ACME CAs follow DNS standards when looking up <code>TXT</code> records for challenge verification, you can use CNAME records to delegate answering the challenge to other DNS zones. This can be used to delegate the <code>_acme-challenge</code> subdomain to another zone. This is particularly useful if your DNS provider doesn't provide an API, or isn't supported by one of the DNS plugins for Caddy.</p>
<p>DNS provider support is a community effort. <a href="https://caddy.community/t/how-to-use-dns-provider-modules-in-caddy-2/8148">Learn how to enable the DNS challenge for your provider at our wiki.</a></p>
<h2 id="on-demand-tls">On-Demand TLS</h2>
<p>Caddy pioneered a new technology we call <strong>On-Demand TLS</strong>, which dynamically obtains a new certificate during the first TLS handshake that requires it, rather than at config load. Crucially, this does <strong>not</strong> require hard-coding the domain names in your configuration ahead of time.</p>
<p>Many businesses rely on this unique feature to scale their TLS deployments at lower cost and without operational headaches when serving tens of thousands of sites.</p>
<p>On-demand TLS is useful if:</p>
<ul>
<li>you do not know all the domain names when you start or reload your server,</li>
<li>domain names might not be properly configured right away (DNS records not yet set),</li>
<li>you are not in control of the domain names (e.g. they are customer domains).</li>
</ul>
<p>When on-demand TLS is enabled, you do not need to specify the domain names in your config in order to get certificates for them. Instead, when a TLS handshake is received for a server name (SNI) that Caddy does not yet have a certificate for, the handshake is held while Caddy obtains a certificate to use to complete the handshake. The delay is usually only a few seconds, and only that initial handshake is slow. All future handshakes are fast because certificates are cached and reused, and renewals happen in the background. Future handshakes may trigger maintenance for the certificate to keep it renewed, but this maintenance happens in the background if the certificate hasn't expired yet.</p>
<h3 id="using-on-demand-tls">Using On-Demand TLS</h3>
<p><strong>On-demand TLS must be both enabled and restricted to prevent abuse.</strong></p>
<p>Enabling on-demand TLS happens in <a href="https://caddyserver.com/docs/json/apps/tls/automation/policies/">TLS automation policies</a> if using the JSON config, or <a href="https://caddyserver.com/docs/caddyfile/directives/tls">in site blocks with the <code>tls</code> directive</a> if using the Caddyfile.</p>
<p>To prevent abuse of this feature, you must configure restrictions. This is done in the <a href="https://caddyserver.com/docs/json/apps/tls/automation/on_demand/"><code>automation</code> object of the JSON config</a>, or the <a href="https://caddyserver.com/docs/caddyfile/options#on-demand-tls"><code>on_demand_tls</code> global option</a> of the Caddyfile. Restrictions are "global" and aren't configurable per-site or per-domain. The primary restriction is an "ask" endpoint to which Caddy will send an HTTP request to ask if it has permission to obtain and manage a certificate for the domain in the handshake. This means you will need some internal backend that can, for example, query the accounts table of your database and see if a customer has signed up with that domain name.</p>
<p>Be mindful of how quickly your CA is able to issue certificates. If it takes more than a few seconds, this will negatively impact the user experience (for the first client only).</p>
<p>Due to its deferred nature and the extra configuration required to prevent abuse, we recommend enabling on-demand TLS only when your actual use case is described above.</p>
<p><a href="https://caddy.community/t/serving-tens-of-thousands-of-domains-over-https-with-caddy/11179">See our wiki article for more information about using on-demand TLS effectively.</a></p>
<h2 id="errors">Errors</h2>
<p>Caddy does its best to continue if errors occur with certificate management.</p>
<p>By default, certificate management is performed in the background. This means it will not block startup or slow down your sites. However, it also means that the server will be running even before all certificates are available. Running in the background allows Caddy to retry with exponential backoff over a long period of time.</p>
<p>Here's what happens if there's an error obtaining or renewing a certificate:</p>
<ol>
<li>Caddy retries once after a brief pause just in case it was a fluke</li>
<li>Caddy pauses briefly, then switches to the next enabled challenge type</li>
<li>After all enabled challenge types have been tried, <a href="#issuer-fallback">it tries the next configured issuer</a>
<ul>
<li>Let's Encrypt</li>
<li>ZeroSSL</li>
</ul>
</li>
<li>After all issuers have been tried, it backs off exponentially
<ul>
<li>Maximum of 1 day between attempts</li>
<li>For up to 30 days</li>
</ul>
</li>
</ol>
<p>During retries with Let's Encrypt, Caddy switches to their <a href="https://letsencrypt.org/docs/staging-environment/">staging environment <img src="https://caddyserver.com/resources/images/external-link.svg"></a> to avoid rate limit concerns. This isn't a perfect strategy, but in general it's helpful.</p>
<p>ACME challenges take at least a few seconds, and internal rate limiting helps mitigate accidental abuse. Caddy uses internal rate limiting in addition to what you or the CA configure so that you can hand Caddy a platter with a million domain names and it will gradually -- but as fast as it can -- obtain certificates for all of them. Caddy's internal rate limit is currently 10 attempts per ACME account per 10 seconds.</p>
<p>To avoid leaking resources, Caddy aborts in-flight tasks (including ACME transactions) when config is changed. While Caddy is capable of handling frequent config reloads, be mindful of operational considerations such as this, and consider batching config changes to reduce reloads and give Caddy a chance to actually finish obtaining certificates in the background.</p>
<h3 id="issuer-fallback">Issuer fallback</h3>
<p>Caddy is the first (and so far only) server to support fully-redundant, automatic failover to other CAs in the event it cannot successfully get a certificate.</p>
<p>By default, Caddy enables two ACME-compatible CAs: <a href="https://letsencrypt.org/"><strong>Let's Encrypt</strong> <img src="https://caddyserver.com/resources/images/external-link.svg"></a> and <a href="https://zerossl.com/"><strong>ZeroSSL</strong> <img src="https://caddyserver.com/resources/images/external-link.svg"></a>. If Caddy cannot get a certificate from Let's Encrypt, it will try with ZeroSSL; if both fail, it will backoff and retry again later. In your config, you can customize which issuers Caddy uses to obtain certificates, either universally or for specific names.</p>
<h2 id="storage">Storage</h2>
<p>Caddy will store public certificates, private keys, and other assets in its <a href="https://caddyserver.com/docs/json/storage/">configured storage facility</a> (or the default one, if not configured -- see link for details).</p>
<p><strong>The main thing you need to know using the default config is that the <code>$HOME</code> folder must be writeable and persistent.</strong> To help you troubleshoot, Caddy prints its environment variables at startup if the <code>--environ</code> flag is specified.</p>
<p>Any Caddy instances that are configured to use the same storage will automatically share those resources and coordinate certificate management as a cluster.</p>
<p>Before attempting any ACME transactions, Caddy will test the configured storage to ensure it is writeable and has sufficient capacity. This helps reduce unnecessary lock contention.</p>
<h2 id="wildcard-certificates">Wildcard certificates</h2>
<p>Caddy can obtain and manage wildcard certificates when it is configured to serve a site with a qualifying wildcard name. A site name qualifies for a wildcard if only its left-most domain label is a wildcard. For example, <code>*.example.com</code> qualifies, but these do not: <code>sub.*.example.com</code>, <code>foo*.example.com</code>, <code>*bar.example.com</code>, and <code>*.*.example.com</code>.</p>
<p>If using the Caddyfile, Caddy takes site names literally with regards to the certificate subject names. In other words, a site defined as <code>sub.example.com</code> will cause Caddy to manage a certificate for <code>sub.example.com</code>, and a site defined as <code>*.example.com</code> will cause Caddy to manage a wildcard certificate for <code>*.example.com</code>. You can see this demonstrated on our <a href="https://caddyserver.com/docs/caddyfile/patterns#wildcard-certificates">Common Caddyfile Patterns</a> page. If you need different behavior, the <a href="https://caddyserver.com/docs/json/">JSON config</a> gives you more precise control over certificate subjects and site names ("host matchers").</p>
<p>Wildcard certificates represent a wide degree of authority and should only be used when you have so many subdomains that managing individual certificates for them would strain the PKI or cause you to hit CA-enforced rate limits.</p>
<p><strong>Note:</strong> <a href="https://letsencrypt.org/docs/challenge-types/">Let's Encrypt requires <img src="https://caddyserver.com/resources/images/external-link.svg"></a> the <a href="#dns-challenge">DNS challenge</a> to obtain wildcard certificates.</p>
</article>
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A boy saw 17 doctors over 3 years for pain. ChatGPT found the right diagnosis (101 pts)]]></title>
            <link>https://www.today.com/health/mom-chatgpt-diagnosis-pain-rcna101843</link>
            <guid>37475604</guid>
            <pubDate>Tue, 12 Sep 2023 00:40:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.today.com/health/mom-chatgpt-diagnosis-pain-rcna101843">https://www.today.com/health/mom-chatgpt-diagnosis-pain-rcna101843</a>, See on <a href="https://news.ycombinator.com/item?id=37475604">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>During the COVID-19 lockdown, Courtney bought a bounce house for her two young children. Soon after, her son, Alex, then 4, began experiencing pain.</p><p>“(Our nanny) started telling me, ‘I have to give him Motrin every day, or he has these gigantic meltdowns,’” Courtney, who asked not to use her last name to protect her family’s privacy, tells TODAY.com. “If he had Motrin, he was totally fine."</p><p>Then Alex began chewing things, so Courtney took him to the dentist. What followed was a three-year search for the cause of Alex's increasing pain and eventually other symptoms.</p><br><figure><picture><source media="(min-width: 1000px)" srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-560w,f_auto,q_auto:eco,dpr_2.0/rockcms/2023-09/chat-gpt-diagnosis-jp-230911-f1cc83.jpg 2x, https://media-cldnry.s-nbcnews.com/image/upload/t_fit-560w,f_auto,q_auto:best/rockcms/2023-09/chat-gpt-diagnosis-jp-230911-f1cc83.jpg 1x"><source srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-760w,f_auto,q_auto:eco,dpr_2.0/rockcms/2023-09/chat-gpt-diagnosis-jp-230911-f1cc83.jpg 2x, https://media-cldnry.s-nbcnews.com/image/upload/t_fit-760w,f_auto,q_auto:best/rockcms/2023-09/chat-gpt-diagnosis-jp-230911-f1cc83.jpg 1x"><img loading="lazy" src="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-760w,f_auto,q_auto:best/rockcms/2023-09/chat-gpt-diagnosis-jp-230911-f1cc83.jpg" alt="Chat GPT helped diagnosis her son" height="4032" width="3024"></picture><figcaption><span data-testid="caption__container">Ever since undergoing surgery to fix his tethered cord syndrome, Alex can't stop smiling.
</span><span>Courtesy Courtney</span></figcaption></figure><p>The beginning of the end of the journey came earlier this year, when Courtney finally got some answers from an unlikely source, ChatGPT. The frustrated mom made an account and shared with the artificial intelligence platform everything she knew about her son's symptoms and all the information she could gather from his MRIs. </p><p>“We saw so many doctors. We ended up in the ER at one point. I kept pushing,” she says. “I really spent the night on the (computer) … going through all these things." </p><p>So, when ChatGPT suggested a diagnosis of tethered cord syndrome, "it made a lot of sense," she recalls.</p><h2>Pain, grinding teeth, dragging leg</h2><p>When Alex began chewing on things, his parents wondered if his molars were coming in and causing pain. As it continued, they thought he had a cavity. </p><p>“Our sweet personality — for the most part —&nbsp;(child) is dissolving into this tantrum-ing crazy person that didn’t exist the rest of the time,” Courtney recalls. </p><p>The dentist “ruled everything out” but thought maybe Alex was grinding his teeth and believed an orthodontist specializing in airway obstruction could help. Airway obstructions impact a child’s sleep and could explain why he seemed so exhausted and moody, the dentist thought. The orthodontist found that Alex’s palate was too small for his mouth and teeth, which made it tougher for him to breathe at night. She placed an expander in Alex’s palate, and it seemed like things were improving. </p><p>“Everything was better for a little bit,” Courtney says. “We thought we were in the home stretch.” </p><p>But then she noticed Alex had stopped growing taller, so they visited the pediatrician, who thought the pandemic was negatively affecting his development. Courtney didn’t agree, but she still brought her son back in early 2021 for a checkup. </p><p>"He'd grown a little bit," she says.</p><p>The pediatrician then referred Alex to physical therapy because he seemed to have some imbalances between his left and right sides.</p><p>“He would lead with his right foot and just bring his left foot along for the ride,” Courtney says.</p><p>But before starting physical therapy, Alex had already been experiencing severe headaches that were only getting worse. He visited a neurologist, who said Alex had migraines. The boy also struggled with exhaustion, so he was taken to an ear, nose and throat doctor to see if he was having sleep problems due to his sinus cavities or airway.</p><p>No matter how many doctors the family saw, the specialists would only address their individual areas of expertise, Courtney says.</p><p>“Nobody’s willing to solve for the greater problem,” she adds. “Nobody will even give you a clue about what the diagnosis could be.”</p><p>Next, a physical therapist thought that Alex could have something called Chiari malformation, a congenital condition that causes abnormalities in the brain where the skull meets the spine, according to the <a href="https://www.aans.org/en/Patients/Neurosurgical-Conditions-and-Treatments/Chiari-Malformation" target="_blank">American Association of Neurological Surgeons</a>. Courtney began researching it, and they visited more doctors — a new pediatrician, a pediatric internist, an adult internist and a musculoskeletal doctor — but again reached a dead end.</p><p>In total, they visited 17 different doctors over three years. But Alex still had no diagnosis that explained all his symptoms. An exhausted and frustrated Courtney signed up for ChatGPT and began entering his medical information, hoping to find a diagnosis.</p><p>“I went line by line of everything that was in his (MRI notes) and plugged it into ChatGPT,” she says. “I put the note in there about ... how he wouldn’t sit crisscross applesauce. To me, that was a huge trigger (that) a structural thing could be wrong.” </p><p>She eventually found tethered cord syndrome and joined a Facebook group for families of children with it. Their stories sounded like Alex's. She scheduled an appointment with a new neurosurgeon and told her she suspected Alex had tethered cord syndrome. The doctor looked at his MRI images and knew exactly what was wrong with Alex.</p><p>“She said point blank, ‘Here’s occulta spina bifida, and here’s where the spine is tethered,” Courtney says.</p><p>Tethered cord syndrome occurs when the tissue in the spinal cord forms attachments that limit movement of the spinal cord, causing it to stretch abnormally, according to the <a href="https://www.aans.org/en/Patients/Neurosurgical-Conditions-and-Treatments/Tethered-Spinal-Cord-Syndrome" target="_blank">American Association of Neurological Surgeons</a>. The condition is closely associated with spina bifida, a birth defect where part of the spinal cord doesn’t develop fully and some of the spinal cord and nerves are exposed.</p><p>With tethered cord syndrome, “the spinal cord is stuck to something. It could be a tumor in the spinal canal. It could be a bump on a spike of bones. It could just be too much fat at the end of the spinal cord,” Dr. Holly Gilmer, a pediatric neurosurgeon at the Michigan Head &amp; Spine Institute, who treated Alex, tells TODAY.com. "The abnormality can’t elongate ... and it pulls.”&nbsp;</p><p>In many children with spina bifida, there’s a visible opening in the child’s back. But the type Alex had is closed and considered “hidden,” also known as spina bifida occulta, <a href="https://www.cdc.gov/ncbddd/spinabifida/facts.html" target="_blank">according to the U.S. Centers for Disease Control and Prevention</a>.</p><p>“My son doesn’t have a hole. There’s almost what looks like a birthmark on the top of his buttocks, but nobody saw it,” Courtney says. “He has a crooked belly button.”</p><p>Gilmer says doctors often find these conditions soon after birth, but in some cases, the marks — such as a dimple, a red spot or a tuft of hair — that indicate spina bifida occulta can be missed. Then doctors rely on symptoms to make the diagnosis, which can include dragging a leg, pain, loss of bladder control, constipation, scoliosis, foot or leg abnormalities and a delay in hitting milestones, such as sitting up and walking.</p><p>“In young children, it can be difficult to diagnose because they can’t speak,” Gilmer says, adding that many parents and children don't realize that their symptoms indicate a problem. "If this is how they have always been, they think that’s normal.”&nbsp;</p><p>When Courtney finally had a diagnosis for Alex, she experienced "every emotion in the book, relief, validated, excitement for his future."</p><h2>ChatGPT and medicine</h2><p>ChatGPT is a type of artificial intelligence program that responds based on input that a person enters into it, but it can't have a conversation or provide answers in the way that many people might expect.</p><p>That's because ChatGPT works by "predicting the next word" in a sentence or series of words based on existing text data on the internet, Andrew Beam, Ph.D., assistant professor of epidemiology at Harvard who studies machine learning models and medicine, tells TODAY.com. “Anytime you ask a question of ChatGPT, it’s recalling from memory things it has read before and trying to predict the piece of text.”</p><p>When using ChatGPT to make a diagnosis, a person might tell the program, "I have fever, chills and body aches,” and it fills in “influenza” as a possible diagnosis, Beam explains.</p><p>“It’s going to do its best to give you a piece of text that looks like a … passage that it’s read,” he adds.</p><p>There are both free and paid versions of ChatGPT, and the latter works much better than the free version, Beam says. But both seem to work better than the average symptom checker or Google as a diagnostic tool. “It’s a super high-powered medical search engine,” Beam says.</p><p>It can be especially beneficial for patients with complicated conditions who are struggling to get a diagnosis, Beam says.</p><p>These patients are "groping for information," he adds. "I do think ChatGPT can be a good partner in that diagnostic odyssey. It has read literally the entire internet. It may not have the same blind spots as the human physician has."</p><p>But it’s not likely to replace a clinician’s expertise anytime soon, he says. For example, ChatGPT fabricates information sometimes when it can't find the answer. Say you ask it for studies about influenza. The tool might respond with several titles that sound real, and the authors it lists may have even written about flu before — but the papers may not actually exist.</p><p>This phenomenon is called "hallucination," and "that gets really problematic when we start talking about medical applications because you don’t want it to just make things up," Beam says.</p><p>&nbsp;Dr. Jesse M. Ehrenfeld, president of leading U.S. physicians' group the American Medical Association, tells TODAY.com in a statement that the AMA "supports deployment of high-quality, clinically validated AI that is deployed in a responsible, ethical, and transparent manner with patient safety being the first and foremost concern. While AI products show tremendous promise in helping alleviate physician administrative burdens and may ultimately be successfully utilized in direct patient care, OpenAI’s ChatGPT and other generative AI products currently have known issues and are not error free."</p><p>He adds that "the current limitations create potential risks for physicians and patients and should be utilized with appropriate caution at this time. AI-generated fabrications, errors, or inaccuracies can harm patients, and physicians need to be acutely aware of these risks and added liability before they rely on unregulated machine-learning algorithms and tools."&nbsp;</p><p>“Just as we demand proof that new medicines and biologics are safe and effective, so must we insist on clinical evidence of the safety and efficacy of new AI-enabled healthcare applications," Ehrenfeld concludes.</p><h2>Diagnosis and treatment</h2><p>Alex is “happy go lucky” and loves playing with other children. He played baseball last year, but he quit because he was injured. Also, he had to give up hockey because wearing ice skates hurts his back and knees. He found a way to adapt, though. </p><p>“He’s so freaking intelligent,” Courtney says. “He’ll climb up on a structure, stand on a chair, and starts being the coach. So, he keeps himself in the game.”</p><p>After receiving the diagnosis, Alex underwent surgery to fix his tethered cord syndrome a few weeks ago. </p><p>“We detach the cord from where it is stuck at the bottom of the tailbone essentially,” Gilmer says. “That releases the tension.”&nbsp;</p><p>Alex is still recovering.<strong> </strong>Gilmer says children bounce back from this surgery relatively quickly. Often the treatment, reduces any symptoms children were having, she says. Alex's mom can see the joy on his face now. </p><p>Courtney shared their story to help others facing similar struggles. </p><p>“There’s nobody that connects the dots for you,” she says. “You have to be your kid’s advocate.”</p><p><em>This story was updated to include a statement from the American Medical Association.</em></p></div><div data-activity-map="expanded-byline-article-bottom"><p><span></span><span><a href="https://www.today.com/author/meghan-holohan-tdpn511">Meghan Holohan</a></span><span></span></p><p>Meghan Holohan is a contributing writer who covers health and parenting for TODAY.com. She enjoys cooking, yoga, reading, music and walking her two rescue dogs. <a href="https://twitter.com/MissMeghanMack" target="_blank">Follow her on Twitter</a> to see her recent stories.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Neopets is still around (119 pts)]]></title>
            <link>https://www.dualshockers.com/neopets-is-still-active-2023/</link>
            <guid>37474780</guid>
            <pubDate>Mon, 11 Sep 2023 22:52:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.dualshockers.com/neopets-is-still-active-2023/">https://www.dualshockers.com/neopets-is-still-active-2023/</a>, See on <a href="https://news.ycombinator.com/item?id=37474780">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-body" itemprop="articleBody">
<p>Having grown up in the '90s, gaming on PC was nothing like it is today. I can still recall the excitement on my dad's face when he brought home our second family computer, excitedly telling me about the 1GB of storage space we'd now have. A whole Gig! We'd <em>never </em>fill that up! That was also the first computer we ever took online, and back in those early glory days when whatever was on AOL made up the bulk of my online experience, there were still a few times I'd stray from the AOL message board and chatrooms and take trepid step into the dreaded URL bar, typing in a secret code starting with www that I'd read in a book. (Yes, I used to find websites through books; it as a different time). I don't know that you could truly consider them all games by today's standard — they were more like little animated communities where minigames were present, but community and website exploration made up a good deal of the action.</p>
<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":0,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":0,"nbrPlacementsScanned":0,"ruleCount":10,"degradationStartingPoint":2,"actualCount":965} -->
<!-- Zone: below first paragraph. -->
<!-- No ads allowed! -->
<!-- No winning ad found for zone: mid intro! -->
<p>So when I saw our own Jack Coleman stepping outside the box to revisit his <a href="https://www.dualshockers.com/wizard-101-still-active/">childhood love for Wizard 101</a> a while back, it made me nostalgic for a simpler time when I was but a bored and curious teen on the Internet (not like that, ya pervs. Get your minds out of the gutter). In the last couple of weeks, I've re-embraced my childhood love of Neopets, a splendiferous online virtual pet playground of games and merriment launched in 1999. To my surprise, I've discovered that you're still free to explore Neopets today, though it's safe to say it's not quite the online tour-de-force it once was.</p>
<!-- Repeatable debug data: {"injection":"before","adPosition":0,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":0,"nbrPlacementsScanned":1,"ruleCount":10,"degradationStartingPoint":2,"actualCount":616} --><!-- Zone: character count repeatable. --><!-- No ads allowed! --><!-- Repeatable debug data: {"injection":"after","adPosition":1,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":1,"nbrPlacementsScanned":1,"ruleCount":10,"degradationStartingPoint":2,"actualCount":0} -->
<p>Oh, and Neopets was dependent on Flash, and, well, Flash is dead, with the end result being that the site doesn't function the way that it should. Choose-your-own-adveture-style stories are abruptly cut off as soon as a movie is encountered, and about 80 percent of the minigames scattered throughout the site crash as soon as I click the start button. I found out through Reddit that you <em>can</em> get everything (or almost everything) to function properly if you download and install an off-the-mainstram web browser that still supports flash, but I'm already middle-aged and stalking around a website designed for kids. Installing a special web browser just to hang around the Neopets community? That feels like the sort of thing that'd get me put on a government watchlist — and I think I'm in the majority of people who aren't going to add an extra Internet browser for the sake of one nostalgic website — so I think I'll just keep poking around in good ol' Chrome.</p>
<!-- Repeatable debug data: {"injection":"before","adPosition":1,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":1,"nbrPlacementsScanned":2,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":1004} --><!-- Zone: character count repeatable. --><!-- No ads allowed! --><!-- Repeatable debug data: {"injection":"after","adPosition":2,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":2,"nbrPlacementsScanned":2,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":0} -->
<div data-img-url="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/untitled-cropped.jpg" data-modal-id="single-image-modal" data-modal-container-id="single-image-modal-container" data-img-caption="null"> <figure> <picture><!--[if IE 9]> <video style="display: none;"><![endif]--> <source media="(min-width: 1024px)" sizes="740px" data-srcset="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/untitled-cropped.jpg?q=50&amp;fit=crop&amp;w=740&amp;dpr=1.5"> <source media="(min-width: 768px)" sizes="963px" data-srcset="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/untitled-cropped.jpg?q=50&amp;fit=crop&amp;w=963&amp;dpr=1.5"> <source media="(min-width: 481px)" sizes="737px" data-srcset="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/untitled-cropped.jpg?q=50&amp;fit=crop&amp;w=737&amp;dpr=1.5"> <source media="(min-width: 0px)" sizes="450px" data-srcset="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/untitled-cropped.jpg?q=50&amp;fit=crop&amp;w=450&amp;dpr=1.5"><!--[if IE 9]></video><![endif]--><img width="1330" height="665" alt="Neopets plugin error" data-img-url="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/untitled-cropped.jpg" src="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/untitled-cropped.jpg"> </picture> </figure> </div>
<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":2,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":2,"nbrPlacementsScanned":3,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":240} -->
<p>The site is still filled with brightly-colored maps beckoning me into a wonderful array of shops and games and other attractions. There's the dual medieval-themed kingdoms of Brightvale and Meridell, the under-the-sea realm of Maraqua, the orbital Virtupets Space Station, and more than a dozen others. It's like that feeling you get on a glorious summer morning when your parents have driven you out to an amusement park; a place where enjoyment is king, and you can really just run wild and be a kid.</p>
<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":2,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":2,"nbrPlacementsScanned":3,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":750} -->

<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":2,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":2,"nbrPlacementsScanned":3,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":830} -->
<p>But the more and more I clicked around this world of wonder and merriment, the more it lost that magical glow, and it started to feel like those eerie photo essays of abandoned theme parks, where nature has reclaimed the empty walkways and rides sit idly in a dilapidated state of inoperable decay. Most of the games scattered throughout the map are inaccessible by conventional means (more on that later), simply popping up a plugin error whenever I try to play.</p>
<!-- Repeatable debug data: {"injection":"before","adPosition":2,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":2,"nbrPlacementsScanned":3,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":1293} --><!-- Zone: character count repeatable. --><!-- No ads allowed! --><!-- Repeatable debug data: {"injection":"after","adPosition":3,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":3,"nbrPlacementsScanned":3,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":0} -->
<p>You're still allowed to spend your hard-won Neopoints on things like scratch cards, but good luck actually trying to scratch them off and cash them in once the irritatingly smiling shopkeepers have taken your virtual currency. Even the tutorial just displays an endless screen of blank white, and creating a NeoHome, one of the boxes on my new user checklist, is staying permanently unchecked, as the website lets me pick what region of the virtual world I'd like to live in but won't let me close on the deal. To their credit, the devs had announced a long time ago that they'd been working on porting the game to mobile, but it's been that way for years and the whole thing's still in a semi-broken beta state on my phone too.</p>
<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":3,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":3,"nbrPlacementsScanned":4,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":752} -->
<div data-img-url="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/npbrightdale-cropped.jpg" data-modal-id="single-image-modal" data-modal-container-id="single-image-modal-container" data-img-caption="null"> <figure> <picture><!--[if IE 9]> <video style="display: none;"><![endif]--> <source media="(min-width: 1024px)" sizes="740px" data-srcset="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/npbrightdale-cropped.jpg?q=50&amp;fit=crop&amp;w=740&amp;dpr=1.5"> <source media="(min-width: 768px)" sizes="963px" data-srcset="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/npbrightdale-cropped.jpg?q=50&amp;fit=crop&amp;w=963&amp;dpr=1.5"> <source media="(min-width: 481px)" sizes="737px" data-srcset="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/npbrightdale-cropped.jpg?q=50&amp;fit=crop&amp;w=737&amp;dpr=1.5"> <source media="(min-width: 0px)" sizes="450px" data-srcset="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/npbrightdale-cropped.jpg?q=50&amp;fit=crop&amp;w=450&amp;dpr=1.5"><!--[if IE 9]></video><![endif]--><img width="1353" height="677" alt="Neopets Brightvale map" data-img-url="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/npbrightdale-cropped.jpg" src="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/npbrightdale-cropped.jpg"> </picture> </figure> </div>
<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":3,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":3,"nbrPlacementsScanned":4,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":992} -->
<p>Despite feeling like some sort of spiritually tortuous purgatory where everything that you used to love is right in front of you and you just can't touch it, the NeoBoards forums are still packed to the Flotsam gills with a dedicated player base. And to make me feel less like an old creeper on a website designed with kids in mind, it kindly displays the number of months since each user that posts there has had an account, letting me know that, yes, there are plenty of players who have been around for 200+ months, maintaining that sweet virtual escape from their own days of youth.</p>
<!-- Repeatable debug data: {"injection":"before","adPosition":3,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":3,"nbrPlacementsScanned":4,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":1582} --><!-- Zone: character count repeatable. --><!-- No ads allowed! --><!-- Repeatable debug data: {"injection":"after","adPosition":4,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":4,"nbrPlacementsScanned":4,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":0} -->

<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":4,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":4,"nbrPlacementsScanned":5,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":71} -->
<p>There's still some charming stuff here. You can find a few card games that still work scattered throughout Neopia, and there's a handy games page that lists 14 other games that are currently still functioning. Just don't play for too long in one session, because most of them seem to randomly change your score to NAN or decide after a while that you don't get your NeoPoints rewards because you're a "suspicious user." I mean, I already admitted to being too old to be here, but you don't have to make me feel bad about it; this ain't Chuck E. Cheese!</p>
<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":4,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":4,"nbrPlacementsScanned":5,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":661} -->
<p>My old favorite, the hot potato-like Gormball, is sadly unavailable, but there's still some mindless, lighthearted fun to be had with the games that are fully functional, like Hasee Bounce, in which you control two adorable little something-or-others as they catapult each other on a seesaw to catch doughnut-fruits, culminating in either a scene of them happily munching on their treasures or sobbing their pwecious widdle eyes out.</p>
<!-- Repeatable debug data: {"injection":"before","adPosition":4,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":4,"nbrPlacementsScanned":5,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":1098} --><!-- Zone: character count repeatable. --><!-- No ads allowed! --><!-- Repeatable debug data: {"injection":"after","adPosition":5,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":5,"nbrPlacementsScanned":5,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":0} -->
<div data-img-url="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/nphaseewin-cropped.jpg" data-modal-id="single-image-modal" data-modal-container-id="single-image-modal-container" data-img-caption="null"> <figure> <picture><!--[if IE 9]> <video style="display: none;"><![endif]--> <source media="(min-width: 1024px)" sizes="740px" data-srcset="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/nphaseewin-cropped.jpg?q=50&amp;fit=crop&amp;w=740&amp;dpr=1.5"> <source media="(min-width: 768px)" sizes="963px" data-srcset="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/nphaseewin-cropped.jpg?q=50&amp;fit=crop&amp;w=963&amp;dpr=1.5"> <source media="(min-width: 481px)" sizes="737px" data-srcset="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/nphaseewin-cropped.jpg?q=50&amp;fit=crop&amp;w=737&amp;dpr=1.5"> <source media="(min-width: 0px)" sizes="450px" data-srcset="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/nphaseewin-cropped.jpg?q=50&amp;fit=crop&amp;w=450&amp;dpr=1.5"><!--[if IE 9]></video><![endif]--><img width="1430" height="715" alt="Neopets Hasee Bounce Victory Screen" data-img-url="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/nphaseewin-cropped.jpg" src="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/nphaseewin-cropped.jpg"> </picture> </figure> </div>
<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":5,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":5,"nbrPlacementsScanned":6,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":240} -->
<p>And of course, the core of the game — the feeding, grooming, and training of virtual pets that was a defining feature of '90s kids everywhere — is still intact. It really doesn't matter what you feed them, but there's a lot of fun to be had just stocking up on food for your little buds, from berry picking at Meridell Farms to grabbing a slice on the massive omelette on Tyranian Plateau. The arena still makes no sense to me, but reflecting on it, I don't think it made sense to teenage me either, like it was tacked on to cash in on the Pokemon hype and still hasn't been developed in the nearly two-and-a-half decades that it's been around.</p>
<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":5,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":5,"nbrPlacementsScanned":6,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":920} -->
<p>All in all, it's been a nice little nostalgic visit to Neopia, but I don't think I'll be settling down here — and not just because my pedestrian, mainstream web browser won't let me create a NeoHome. My old account and pets are gone, lost to the ages among website maintenance and increased security measures of the past. Neopets now belongs to the diehards; the people who've stayed around through the thick and thin of things. In my hubris, I mistakenly thought I'd grown too cool for it, and it passed me by.</p>
<!-- Repeatable debug data: {"injection":"before","adPosition":5,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":5,"nbrPlacementsScanned":6,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":1461} --><!-- Zone: character count repeatable. --><!-- No ads allowed! --><!-- Repeatable debug data: {"injection":"after","adPosition":6,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":6,"nbrPlacementsScanned":6,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":0} -->
<div data-img-url="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/npsomethingishappening-cropped.jpg" data-modal-id="single-image-modal" data-modal-container-id="single-image-modal-container" data-img-caption="null"> <figure> <picture><!--[if IE 9]> <video style="display: none;"><![endif]--> <source media="(min-width: 1024px)" sizes="740px" data-srcset="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/npsomethingishappening-cropped.jpg?q=50&amp;fit=crop&amp;w=740&amp;dpr=1.5"> <source media="(min-width: 768px)" sizes="963px" data-srcset="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/npsomethingishappening-cropped.jpg?q=50&amp;fit=crop&amp;w=963&amp;dpr=1.5"> <source media="(min-width: 481px)" sizes="737px" data-srcset="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/npsomethingishappening-cropped.jpg?q=50&amp;fit=crop&amp;w=737&amp;dpr=1.5"> <source media="(min-width: 0px)" sizes="450px" data-srcset="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/npsomethingishappening-cropped.jpg?q=50&amp;fit=crop&amp;w=450&amp;dpr=1.5"><!--[if IE 9]></video><![endif]--><img width="1748" height="874" alt="Neopets Something Is Happening Neggfest 2023 Petpet" data-img-url="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/npsomethingishappening-cropped.jpg" src="https://static1.dualshockersimages.com/wordpress/wp-content/uploads/2023/05/npsomethingishappening-cropped.jpg"> </picture> </figure> </div>
<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":6,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":6,"nbrPlacementsScanned":7,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":240} -->
<p>But that doesn't mean I won't be popping in every few days — my Korbat and Grundo would be starving otherwise — and if you've ever been a Neopets player, I'd encourage you to pop in and have a look around too. And while the mobile-friendly version seems entirely stalled out, Neopets Metaverse <a href="https://www.augustman.com/my/gear/tech/neopets-enters-metaverse-alpha-release/#:~:text=That's%20right%20%E2%80%94%20the%20original%20Neopets,an%20exciting%20new%20web3%20format" rel="noopener noreferrer" target="_blank">released in alpha last fall</a>, and if they can get all the classic stuff working for the mainstream again, I'd happily challenge you to a game of Gormball.</p>
<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":6,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":6,"nbrPlacementsScanned":7,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":719} -->
<p><span>NEXT: <a href="https://www.dualshockers.com/lego-dimensions-better-warner-bros-crossover-game/">Lego Dimensions Is A Better Warner Bros. Crossover Game Than Multiversus</a></span></p>
<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":6,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":6,"nbrPlacementsScanned":7,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":797} -->
 
<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":6,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":6,"nbrPlacementsScanned":7,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":798} --></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenSSL 1.1.1 End of Life (152 pts)]]></title>
            <link>https://www.openssl.org/blog/blog/2023/09/11/eol-111/</link>
            <guid>37474601</guid>
            <pubDate>Mon, 11 Sep 2023 22:33:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.openssl.org/blog/blog/2023/09/11/eol-111/">https://www.openssl.org/blog/blog/2023/09/11/eol-111/</a>, See on <a href="https://news.ycombinator.com/item?id=37474601">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>OpenSSL 1.1.1 series has reached its End of Life (EOL).
As such it will no longer receive publicly available security fixes.</p>

<!-- more -->

<p>OpenSSL 1.1.1 was released on 11th September 2018 as a <a href="https://www.openssl.org/policies/general/versioning-policy.html#supported-releases">Long Term Support</a> (LTS)
release.  LTS lasts five years and consequently OpenSSL 1.1.1 has reached
its EOL as of today, 11th September 2023.</p>

<p>If your copy of OpenSSL 1.1.1 is from an Operating System vendor (e.g. via
<code>.rpm</code> or <code>.deb</code> packages) or another third party then the support periods
for them may differ to those provided by the OpenSSL Project itself.
Check with the OS vendor/other third party on what support for OpenSSL
they provide.</p>

<p>If you downloaded your copy of OpenSSL 1.1.1 direct from the OpenSSL
project then it is time to upgrade to a more recent version.  Our most
recent version is OpenSSL 3.1 which will be supported until 14th March 2025.
Also available is OpenSSL 3.0 which is an LTS release and will
be supported until 7th September 2026.  Our <a href="https://www.openssl.org/docs/man3.1/man7/migration_guide.html">migration guide</a> provides
useful information on the issues to consider when upgrading.</p>

<p>Another option is to purchase a <a href="https://www.openssl.org/support/contracts.html#premium">premium support contract</a> which offers
extended support (i.e. ongoing access to security fixes) for 1.1.1 beyond
its public EOL date.  There is no defined end date for this extended
support and we intend to continue to provide it for as long as it remains
commercially viable for us to do so (i.e. for the foreseeable future).
Further information is available on our <a href="https://www.openssl.org/support/contracts.html">support contracts</a> page. Email
osf-contact@openssl.org for further information.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[YouTube-dl fork with additional features and fixes (176 pts)]]></title>
            <link>https://github.com/yt-dlp/yt-dlp</link>
            <guid>37474066</guid>
            <pubDate>Mon, 11 Sep 2023 21:37:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/yt-dlp/yt-dlp">https://github.com/yt-dlp/yt-dlp</a>, See on <a href="https://news.ycombinator.com/item?id=37474066">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text">


<p dir="auto">yt-dlp is a <a href="https://github.com/ytdl-org/youtube-dl">youtube-dl</a> fork based on the now inactive <a href="https://github.com/blackjack4494/yt-dlc">youtube-dlc</a>. The main focus of this project is adding new features and patches while also keeping up to date with the original project</p>


<ul dir="auto">
<li><a href="#new-features">NEW FEATURES</a>
<ul dir="auto">
<li><a href="#differences-in-default-behavior">Differences in default behavior</a></li>
</ul>
</li>
<li><a href="#installation">INSTALLATION</a>
<ul dir="auto">
<li><a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation">Detailed instructions</a></li>
<li><a href="#update">Update</a></li>
<li><a href="#release-files">Release Files</a></li>
<li><a href="#dependencies">Dependencies</a></li>
<li><a href="#compile">Compile</a></li>
</ul>
</li>
<li><a href="#usage-and-options">USAGE AND OPTIONS</a>
<ul dir="auto">
<li><a href="#general-options">General Options</a></li>
<li><a href="#network-options">Network Options</a></li>
<li><a href="#geo-restriction">Geo-restriction</a></li>
<li><a href="#video-selection">Video Selection</a></li>
<li><a href="#download-options">Download Options</a></li>
<li><a href="#filesystem-options">Filesystem Options</a></li>
<li><a href="#thumbnail-options">Thumbnail Options</a></li>
<li><a href="#internet-shortcut-options">Internet Shortcut Options</a></li>
<li><a href="#verbosity-and-simulation-options">Verbosity and Simulation Options</a></li>
<li><a href="#workarounds">Workarounds</a></li>
<li><a href="#video-format-options">Video Format Options</a></li>
<li><a href="#subtitle-options">Subtitle Options</a></li>
<li><a href="#authentication-options">Authentication Options</a></li>
<li><a href="#post-processing-options">Post-processing Options</a></li>
<li><a href="#sponsorblock-options">SponsorBlock Options</a></li>
<li><a href="#extractor-options">Extractor Options</a></li>
</ul>
</li>
<li><a href="#configuration">CONFIGURATION</a>
<ul dir="auto">
<li><a href="#configuration-file-encoding">Configuration file encoding</a></li>
<li><a href="#authentication-with-netrc">Authentication with netrc</a></li>
<li><a href="#notes-about-environment-variables">Notes about environment variables</a></li>
</ul>
</li>
<li><a href="#output-template">OUTPUT TEMPLATE</a>
<ul dir="auto">
<li><a href="#output-template-examples">Output template examples</a></li>
</ul>
</li>
<li><a href="#format-selection">FORMAT SELECTION</a>
<ul dir="auto">
<li><a href="#filtering-formats">Filtering Formats</a></li>
<li><a href="#sorting-formats">Sorting Formats</a></li>
<li><a href="#format-selection-examples">Format Selection examples</a></li>
</ul>
</li>
<li><a href="#modifying-metadata">MODIFYING METADATA</a>
<ul dir="auto">
<li><a href="#modifying-metadata-examples">Modifying metadata examples</a></li>
</ul>
</li>
<li><a href="#extractor-arguments">EXTRACTOR ARGUMENTS</a></li>
<li><a href="#plugins">PLUGINS</a>
<ul dir="auto">
<li><a href="#installing-plugins">Installing Plugins</a></li>
<li><a href="#developing-plugins">Developing Plugins</a></li>
</ul>
</li>
<li><a href="#embedding-yt-dlp">EMBEDDING YT-DLP</a>
<ul dir="auto">
<li><a href="#embedding-examples">Embedding examples</a></li>
</ul>
</li>
<li><a href="#deprecated-options">DEPRECATED OPTIONS</a></li>
<li><a href="https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#contributing-to-yt-dlp">CONTRIBUTING</a>
<ul dir="auto">
<li><a href="https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#opening-an-issue">Opening an Issue</a></li>
<li><a href="https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions">Developer Instructions</a></li>
</ul>
</li>
<li><a href="https://github.com/yt-dlp/yt-dlp/wiki">WIKI</a>
<ul dir="auto">
<li><a href="https://github.com/yt-dlp/yt-dlp/wiki/FAQ">FAQ</a></li>
</ul>
</li>
</ul>

<h2 tabindex="-1" dir="auto">NEW FEATURES</h2>
<ul dir="auto">
<li>
<p dir="auto">Forked from <a href="https://github.com/blackjack4494/yt-dlc/commit/f9401f2a91987068139c5f757b12fc711d4c0cee"><strong>yt-dlc@f9401f2</strong></a> and merged with <a href="https://github.com/ytdl-org/youtube-dl/commit/07af47960f3bb262ead02490ce65c8c45c01741e"><strong>youtube-dl@42f2d4</strong></a> (<a href="https://github.com/yt-dlp/yt-dlp/issues/21" data-hovercard-type="issue" data-hovercard-url="/yt-dlp/yt-dlp/issues/21/hovercard">exceptions</a>)</p>
</li>
<li>
<p dir="auto"><strong><a href="#sponsorblock-options">SponsorBlock Integration</a></strong>: You can mark/remove sponsor sections in YouTube videos by utilizing the <a href="https://sponsor.ajay.app/" rel="nofollow">SponsorBlock</a> API</p>
</li>
<li>
<p dir="auto"><strong><a href="#sorting-formats">Format Sorting</a></strong>: The default format sorting options have been changed so that higher resolution and better codecs will be now preferred instead of simply using larger bitrate. Furthermore, you can now specify the sort order using <code>-S</code>. This allows for much easier format selection than what is possible by simply using <code>--format</code> (<a href="#format-selection-examples">examples</a>)</p>
</li>
<li>
<p dir="auto"><strong>Merged with animelover1984/youtube-dl</strong>: You get most of the features and improvements from <a href="https://github.com/animelover1984/youtube-dl">animelover1984/youtube-dl</a> including <code>--write-comments</code>, <code>BiliBiliSearch</code>, <code>BilibiliChannel</code>, Embedding thumbnail in mp4/ogg/opus, playlist infojson etc. Note that NicoNico livestreams are not available. See <a href="https://github.com/yt-dlp/yt-dlp/pull/31" data-hovercard-type="pull_request" data-hovercard-url="/yt-dlp/yt-dlp/pull/31/hovercard">#31</a> for details.</p>
</li>
<li>
<p dir="auto"><strong>YouTube improvements</strong>:</p>
<ul dir="auto">
<li>Supports Clips, Stories (<code>ytstories:&lt;channel UCID&gt;</code>), Search (including filters)<strong>*</strong>, YouTube Music Search, Channel-specific search, Search prefixes (<code>ytsearch:</code>, <code>ytsearchdate:</code>)<strong>*</strong>, Mixes, and Feeds (<code>:ytfav</code>, <code>:ytwatchlater</code>, <code>:ytsubs</code>, <code>:ythistory</code>, <code>:ytrec</code>, <code>:ytnotif</code>)</li>
<li>Fix for <a href="https://github.com/ytdl-org/youtube-dl/issues/29326" data-hovercard-type="issue" data-hovercard-url="/ytdl-org/youtube-dl/issues/29326/hovercard">n-sig based throttling</a> <strong>*</strong></li>
<li>Supports some (but not all) age-gated content without cookies</li>
<li>Download livestreams from the start using <code>--live-from-start</code> (<em>experimental</em>)</li>
<li><code>255kbps</code> audio is extracted (if available) from YouTube Music when premium cookies are given</li>
<li>Channel URLs download all uploads of the channel, including shorts and live</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Cookies from browser</strong>: Cookies can be automatically extracted from all major web browsers using <code>--cookies-from-browser BROWSER[+KEYRING][:PROFILE][::CONTAINER]</code></p>
</li>
<li>
<p dir="auto"><strong>Download time range</strong>: Videos can be downloaded partially based on either timestamps or chapters using <code>--download-sections</code></p>
</li>
<li>
<p dir="auto"><strong>Split video by chapters</strong>: Videos can be split into multiple files based on chapters using <code>--split-chapters</code></p>
</li>
<li>
<p dir="auto"><strong>Multi-threaded fragment downloads</strong>: Download multiple fragments of m3u8/mpd videos in parallel. Use <code>--concurrent-fragments</code> (<code>-N</code>) option to set the number of threads used</p>
</li>
<li>
<p dir="auto"><strong>Aria2c with HLS/DASH</strong>: You can use <code>aria2c</code> as the external downloader for DASH(mpd) and HLS(m3u8) formats</p>
</li>
<li>
<p dir="auto"><strong>New and fixed extractors</strong>: Many new extractors have been added and a lot of existing ones have been fixed. See the <a href="https://github.com/yt-dlp/yt-dlp/blob/master/Changelog.md">changelog</a> or the <a href="https://github.com/yt-dlp/yt-dlp/blob/master/supportedsites.md">list of supported sites</a></p>
</li>
<li>
<p dir="auto"><strong>New MSOs</strong>: Philo, Spectrum, SlingTV, Cablevision, RCN etc.</p>
</li>
<li>
<p dir="auto"><strong>Subtitle extraction from manifests</strong>: Subtitles can be extracted from streaming media manifests. See <a href="https://github.com/yt-dlp/yt-dlp/commit/be6202f12b97858b9d716e608394b51065d0419f">commit/be6202f</a> for details</p>
</li>
<li>
<p dir="auto"><strong>Multiple paths and output templates</strong>: You can give different <a href="#output-template">output templates</a> and download paths for different types of files. You can also set a temporary path where intermediary files are downloaded to using <code>--paths</code> (<code>-P</code>)</p>
</li>
<li>
<p dir="auto"><strong>Portable Configuration</strong>: Configuration files are automatically loaded from the home and root directories. See <a href="#configuration">CONFIGURATION</a> for details</p>
</li>
<li>
<p dir="auto"><strong>Output template improvements</strong>: Output templates can now have date-time formatting, numeric offsets, object traversal etc. See <a href="#output-template">output template</a> for details. Even more advanced operations can also be done with the help of <code>--parse-metadata</code> and <code>--replace-in-metadata</code></p>
</li>
<li>
<p dir="auto"><strong>Other new options</strong>: Many new options have been added such as <code>--alias</code>, <code>--print</code>, <code>--concat-playlist</code>, <code>--wait-for-video</code>, <code>--retry-sleep</code>, <code>--sleep-requests</code>, <code>--convert-thumbnails</code>, <code>--force-download-archive</code>, <code>--force-overwrites</code>, <code>--break-match-filter</code> etc</p>
</li>
<li>
<p dir="auto"><strong>Improvements</strong>: Regex and other operators in <code>--format</code>/<code>--match-filter</code>, multiple <code>--postprocessor-args</code> and <code>--downloader-args</code>, faster archive checking, more <a href="#format-selection">format selection options</a>, merge multi-video/audio, multiple <code>--config-locations</code>, <code>--exec</code> at different stages, etc</p>
</li>
<li>
<p dir="auto"><strong>Plugins</strong>: Extractors and PostProcessors can be loaded from an external file. See <a href="#plugins">plugins</a> for details</p>
</li>
<li>
<p dir="auto"><strong>Self updater</strong>: The releases can be updated using <code>yt-dlp -U</code>, and downgraded using <code>--update-to</code> if required</p>
</li>
<li>
<p dir="auto"><strong>Nightly builds</strong>: <a href="#update-channels">Automated nightly builds</a> can be used with <code>--update-to nightly</code></p>
</li>
</ul>
<p dir="auto">See <a href="https://github.com/yt-dlp/yt-dlp/blob/master/Changelog.md">changelog</a> or <a href="https://github.com/yt-dlp/yt-dlp/commits">commits</a> for the full list of changes</p>
<p dir="auto">Features marked with a <strong>*</strong> have been back-ported to youtube-dl</p>
<h3 tabindex="-1" dir="auto">Differences in default behavior</h3>
<p dir="auto">Some of yt-dlp's default options are different from that of youtube-dl and youtube-dlc:</p>
<ul dir="auto">
<li>yt-dlp supports only <a href="##" title="Windows 7">Python 3.7+</a>, and <em>may</em> remove support for more versions as they <a href="https://devguide.python.org/versions/#python-release-cycle" rel="nofollow">become EOL</a>; while <a href="https://github.com/ytdl-org/youtube-dl/issues/30568#issue-1118238743" data-hovercard-type="issue" data-hovercard-url="/ytdl-org/youtube-dl/issues/30568/hovercard">youtube-dl still supports Python 2.6+ and 3.2+</a></li>
<li>The options <code>--auto-number</code> (<code>-A</code>), <code>--title</code> (<code>-t</code>) and <code>--literal</code> (<code>-l</code>), no longer work. See <a href="#Removed">removed options</a> for details</li>
<li><code>avconv</code> is not supported as an alternative to <code>ffmpeg</code></li>
<li>yt-dlp stores config files in slightly different locations to youtube-dl. See <a href="#configuration">CONFIGURATION</a> for a list of correct locations</li>
<li>The default <a href="#output-template">output template</a> is <code>%(title)s [%(id)s].%(ext)s</code>. There is no real reason for this change. This was changed before yt-dlp was ever made public and now there are no plans to change it back to <code>%(title)s-%(id)s.%(ext)s</code>. Instead, you may use <code>--compat-options filename</code></li>
<li>The default <a href="#sorting-formats">format sorting</a> is different from youtube-dl and prefers higher resolution and better codecs rather than higher bitrates. You can use the <code>--format-sort</code> option to change this to any order you prefer, or use <code>--compat-options format-sort</code> to use youtube-dl's sorting order</li>
<li>The default format selector is <code>bv*+ba/b</code>. This means that if a combined video + audio format that is better than the best video-only format is found, the former will be preferred. Use <code>-f bv+ba/b</code> or <code>--compat-options format-spec</code> to revert this</li>
<li>Unlike youtube-dlc, yt-dlp does not allow merging multiple audio/video streams into one file by default (since this conflicts with the use of <code>-f bv*+ba</code>). If needed, this feature must be enabled using <code>--audio-multistreams</code> and <code>--video-multistreams</code>. You can also use <code>--compat-options multistreams</code> to enable both</li>
<li><code>--no-abort-on-error</code> is enabled by default. Use <code>--abort-on-error</code> or <code>--compat-options abort-on-error</code> to abort on errors instead</li>
<li>When writing metadata files such as thumbnails, description or infojson, the same information (if available) is also written for playlists. Use <code>--no-write-playlist-metafiles</code> or <code>--compat-options no-playlist-metafiles</code> to not write these files</li>
<li><code>--add-metadata</code> attaches the <code>infojson</code> to <code>mkv</code> files in addition to writing the metadata when used with <code>--write-info-json</code>. Use <code>--no-embed-info-json</code> or <code>--compat-options no-attach-info-json</code> to revert this</li>
<li>Some metadata are embedded into different fields when using <code>--add-metadata</code> as compared to youtube-dl. Most notably, <code>comment</code> field contains the <code>webpage_url</code> and <code>synopsis</code> contains the <code>description</code>. You can <a href="#modifying-metadata">use <code>--parse-metadata</code></a> to modify this to your liking or use <code>--compat-options embed-metadata</code> to revert this</li>
<li><code>playlist_index</code> behaves differently when used with options like <code>--playlist-reverse</code> and <code>--playlist-items</code>. See <a href="https://github.com/yt-dlp/yt-dlp/issues/302" data-hovercard-type="pull_request" data-hovercard-url="/yt-dlp/yt-dlp/pull/302/hovercard">#302</a> for details. You can use <code>--compat-options playlist-index</code> if you want to keep the earlier behavior</li>
<li>The output of <code>-F</code> is listed in a new format. Use <code>--compat-options list-formats</code> to revert this</li>
<li>Live chats (if available) are considered as subtitles. Use <code>--sub-langs all,-live_chat</code> to download all subtitles except live chat. You can also use <code>--compat-options no-live-chat</code> to prevent any live chat/danmaku from downloading</li>
<li>YouTube channel URLs download all uploads of the channel. To download only the videos in a specific tab, pass the tab's URL. If the channel does not show the requested tab, an error will be raised. Also, <code>/live</code> URLs raise an error if there are no live videos instead of silently downloading the entire channel. You may use <code>--compat-options no-youtube-channel-redirect</code> to revert all these redirections</li>
<li>Unavailable videos are also listed for YouTube playlists. Use <code>--compat-options no-youtube-unavailable-videos</code> to remove this</li>
<li>The upload dates extracted from YouTube are in UTC <a href="https://github.com/yt-dlp/yt-dlp/blob/89e4d86171c7b7c997c77d4714542e0383bf0db0/yt_dlp/extractor/youtube.py#L3898-L3900">when available</a>. Use <code>--compat-options no-youtube-prefer-utc-upload-date</code> to prefer the non-UTC upload date.</li>
<li>If <code>ffmpeg</code> is used as the downloader, the downloading and merging of formats happen in a single step when possible. Use <code>--compat-options no-direct-merge</code> to revert this</li>
<li>Thumbnail embedding in <code>mp4</code> is done with mutagen if possible. Use <code>--compat-options embed-thumbnail-atomicparsley</code> to force the use of AtomicParsley instead</li>
<li>Some internal metadata such as filenames are removed by default from the infojson. Use <code>--no-clean-infojson</code> or <code>--compat-options no-clean-infojson</code> to revert this</li>
<li>When <code>--embed-subs</code> and <code>--write-subs</code> are used together, the subtitles are written to disk and also embedded in the media file. You can use just <code>--embed-subs</code> to embed the subs and automatically delete the separate file. See <a href="https://github.com/yt-dlp/yt-dlp/issues/630#issuecomment-893659460" data-hovercard-type="issue" data-hovercard-url="/yt-dlp/yt-dlp/issues/630/hovercard">#630 (comment)</a> for more info. <code>--compat-options no-keep-subs</code> can be used to revert this</li>
<li><code>certifi</code> will be used for SSL root certificates, if installed. If you want to use system certificates (e.g. self-signed), use <code>--compat-options no-certifi</code></li>
<li>yt-dlp's sanitization of invalid characters in filenames is different/smarter than in youtube-dl. You can use <code>--compat-options filename-sanitization</code> to revert to youtube-dl's behavior</li>
<li>yt-dlp tries to parse the external downloader outputs into the standard progress output if possible (Currently implemented: <a href="https://github.com/yt-dlp/yt-dlp/issues/5931" data-hovercard-type="issue" data-hovercard-url="/yt-dlp/yt-dlp/issues/5931/hovercard"><del>aria2c</del></a>). You can use <code>--compat-options no-external-downloader-progress</code> to get the downloader output as-is</li>
<li>yt-dlp versions between 2021.09.01 and 2023.01.02 applies <code>--match-filter</code> to nested playlists. This was an unintentional side-effect of <a href="https://github.com/yt-dlp/yt-dlp/commit/8f18aca8717bb0dd49054555af8d386e5eda3a88">8f18ac</a> and is fixed in <a href="https://github.com/yt-dlp/yt-dlp/commit/d7b460d0e5fc710950582baed2e3fc616ed98a80">d7b460</a>. Use <code>--compat-options playlist-match-filter</code> to revert this</li>
</ul>
<p dir="auto">For ease of use, a few more compat options are available:</p>
<ul dir="auto">
<li><code>--compat-options all</code>: Use all compat options (Do NOT use)</li>
<li><code>--compat-options youtube-dl</code>: Same as <code>--compat-options all,-multistreams,-playlist-match-filter</code></li>
<li><code>--compat-options youtube-dlc</code>: Same as <code>--compat-options all,-no-live-chat,-no-youtube-channel-redirect,-playlist-match-filter</code></li>
<li><code>--compat-options 2021</code>: Same as <code>--compat-options 2022,no-certifi,filename-sanitization,no-youtube-prefer-utc-upload-date</code></li>
<li><code>--compat-options 2022</code>: Same as <code>--compat-options playlist-match-filter,no-external-downloader-progress</code>. Use this to enable all future compat options</li>
</ul>
<h2 tabindex="-1" dir="auto">INSTALLATION</h2>

<p dir="auto"><a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.exe"><img src="https://camo.githubusercontent.com/5e7d03f7f5cc1dc4cd6797a5ede9af299143001f2fc89a7386b87f3d4828c5d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2d57696e646f77735f7836342d626c75652e7376673f7374796c653d666f722d7468652d6261646765266c6f676f3d77696e646f7773" alt="Windows" data-canonical-src="https://img.shields.io/badge/-Windows_x64-blue.svg?style=for-the-badge&amp;logo=windows"></a>
<a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp"><img src="https://camo.githubusercontent.com/5461aa20146a9fe60de1cc47ac0de9a070a05e73dec54a829d1cf21d85324974/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2d4c696e75782f4253442d7265642e7376673f7374796c653d666f722d7468652d6261646765266c6f676f3d6c696e7578" alt="Unix" data-canonical-src="https://img.shields.io/badge/-Linux/BSD-red.svg?style=for-the-badge&amp;logo=linux"></a>
<a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos"><img src="https://camo.githubusercontent.com/65d1ed3107ea8b6ab3c6b06766904cbc6fdd9e7fd961929f81349e38e3229767/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2d4d61634f532d6c69676874626c75652e7376673f7374796c653d666f722d7468652d6261646765266c6f676f3d6170706c65" alt="MacOS" data-canonical-src="https://img.shields.io/badge/-MacOS-lightblue.svg?style=for-the-badge&amp;logo=apple"></a>
<a href="https://pypi.org/project/yt-dlp" rel="nofollow"><img src="https://camo.githubusercontent.com/8360967fa65c453c411c016c2cfab78837823a995bd4a7510df6fa80f15085f6/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2d507950692d626c75652e7376673f6c6f676f3d70797069266c6162656c436f6c6f723d353535353535267374796c653d666f722d7468652d6261646765" alt="PyPi" data-canonical-src="https://img.shields.io/badge/-PyPi-blue.svg?logo=pypi&amp;labelColor=555555&amp;style=for-the-badge"></a>
<a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz"><img src="https://camo.githubusercontent.com/d1a58041d43ca05b59ad01cc301b4282ffa507f12e87a7a1bb51d6e82080c312/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2d536f757263655f7461722d677265656e2e7376673f7374796c653d666f722d7468652d6261646765" alt="Source Tarball" data-canonical-src="https://img.shields.io/badge/-Source_tar-green.svg?style=for-the-badge"></a>
<a href="#release-files"><img src="https://camo.githubusercontent.com/b38bcbc7dbeb210434768a9f20c9fcebf7d25fe6a3438334d910aae7ee277008/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2d4f746865722d677265792e7376673f7374796c653d666f722d7468652d6261646765" alt="Other variants" data-canonical-src="https://img.shields.io/badge/-Other-grey.svg?style=for-the-badge"></a>
<a href="https://github.com/yt-dlp/yt-dlp/releases"><img src="https://camo.githubusercontent.com/139754d1ce29070f1f33c96733a649a3fb009d6f2cf91edad2e86560d53d70ee/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2d416c6c5f56657273696f6e732d6c69676874677265792e7376673f7374796c653d666f722d7468652d6261646765" alt="All versions" data-canonical-src="https://img.shields.io/badge/-All_Versions-lightgrey.svg?style=for-the-badge"></a></p>

<p dir="auto">You can install yt-dlp using <a href="#release-files">the binaries</a>, <a href="https://pypi.org/project/yt-dlp" rel="nofollow">pip</a> or one using a third-party package manager. See <a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation">the wiki</a> for detailed instructions</p>
<h2 tabindex="-1" dir="auto">UPDATE</h2>
<p dir="auto">You can use <code>yt-dlp -U</code> to update if you are using the <a href="#release-files">release binaries</a></p>
<p dir="auto">If you <a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation#with-pip">installed with pip</a>, simply re-run the same command that was used to install the program</p>
<p dir="auto">For other third-party package managers, see <a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation#third-party-package-managers">the wiki</a> or refer their documentation</p>
<a id="user-content-update-channels">
</a><p dir="auto">There are currently two release channels for binaries, <code>stable</code> and <code>nightly</code>.
<code>stable</code> is the default channel, and many of its changes have been tested by users of the nightly channel.
The <code>nightly</code> channel has releases built after each push to the master branch, and will have the most recent fixes and additions, but also have more risk of regressions. They are available in <a href="https://github.com/yt-dlp/yt-dlp-nightly-builds/releases">their own repo</a>.</p>
<p dir="auto">When using <code>--update</code>/<code>-U</code>, a release binary will only update to its current channel.
<code>--update-to CHANNEL</code> can be used to switch to a different channel when a newer version is available. <code>--update-to [CHANNEL@]TAG</code> can also be used to upgrade or downgrade to specific tags from a channel.</p>
<p dir="auto">You may also use <code>--update-to &lt;repository&gt;</code> (<code>&lt;owner&gt;/&lt;repository&gt;</code>) to update to a channel on a completely different repository. Be careful with what repository you are updating to though, there is no verification done for binaries from different repositories.</p>
<p dir="auto">Example usage:</p>
<ul dir="auto">
<li><code>yt-dlp --update-to nightly</code> change to <code>nightly</code> channel and update to its latest release</li>
<li><code>yt-dlp --update-to stable@2023.02.17</code> upgrade/downgrade to release to <code>stable</code> channel tag <code>2023.02.17</code></li>
<li><code>yt-dlp --update-to 2023.01.06</code> upgrade/downgrade to tag <code>2023.01.06</code> if it exists on the current channel</li>
<li><code>yt-dlp --update-to example/yt-dlp@2023.03.01</code> upgrade/downgrade to the release from the <code>example/yt-dlp</code> repository, tag <code>2023.03.01</code></li>
</ul>

<h2 tabindex="-1" dir="auto">RELEASE FILES</h2>
<h4 tabindex="-1" dir="auto">Recommended</h4>
<table>
<thead>
<tr>
<th>File</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp">yt-dlp</a></td>
<td>Platform-independent <a href="https://docs.python.org/3/library/zipimport.html" rel="nofollow">zipimport</a> binary. Needs Python (recommended for <strong>Linux/BSD</strong>)</td>
</tr>
<tr>
<td><a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.exe">yt-dlp.exe</a></td>
<td>Windows (Win7 SP1+) standalone x64 binary (recommended for <strong>Windows</strong>)</td>
</tr>
<tr>
<td><a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos">yt-dlp_macos</a></td>
<td>Universal MacOS (10.15+) standalone executable (recommended for <strong>MacOS</strong>)</td>
</tr>
</tbody>
</table>
<h4 tabindex="-1" dir="auto">Alternatives</h4>
<table>
<thead>
<tr>
<th>File</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_x86.exe">yt-dlp_x86.exe</a></td>
<td>Windows (Vista SP2+) standalone x86 (32-bit) binary</td>
</tr>
<tr>
<td><a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_min.exe">yt-dlp_min.exe</a></td>
<td>Windows (Win7 SP1+) standalone x64 binary built with <code>py2exe</code><br> (<a href="#standalone-py2exe-builds-windows">Not recommended</a>)</td>
</tr>
<tr>
<td><a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux">yt-dlp_linux</a></td>
<td>Linux standalone x64 binary</td>
</tr>
<tr>
<td><a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux.zip">yt-dlp_linux.zip</a></td>
<td>Unpackaged Linux executable (no auto-update)</td>
</tr>
<tr>
<td><a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux_armv7l">yt-dlp_linux_armv7l</a></td>
<td>Linux standalone armv7l (32-bit) binary</td>
</tr>
<tr>
<td><a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux_aarch64">yt-dlp_linux_aarch64</a></td>
<td>Linux standalone aarch64 (64-bit) binary</td>
</tr>
<tr>
<td><a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_win.zip">yt-dlp_win.zip</a></td>
<td>Unpackaged Windows executable (no auto-update)</td>
</tr>
<tr>
<td><a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos.zip">yt-dlp_macos.zip</a></td>
<td>Unpackaged MacOS (10.15+) executable (no auto-update)</td>
</tr>
<tr>
<td><a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos_legacy">yt-dlp_macos_legacy</a></td>
<td>MacOS (10.9+) standalone x64 executable</td>
</tr>
</tbody>
</table>
<h4 tabindex="-1" dir="auto">Misc</h4>
<table>
<thead>
<tr>
<th>File</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz">yt-dlp.tar.gz</a></td>
<td>Source tarball</td>
</tr>
<tr>
<td><a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-512SUMS">SHA2-512SUMS</a></td>
<td>GNU-style SHA512 sums</td>
</tr>
<tr>
<td><a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-512SUMS.sig">SHA2-512SUMS.sig</a></td>
<td>GPG signature file for SHA512 sums</td>
</tr>
<tr>
<td><a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-256SUMS">SHA2-256SUMS</a></td>
<td>GNU-style SHA256 sums</td>
</tr>
<tr>
<td><a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-256SUMS.sig">SHA2-256SUMS.sig</a></td>
<td>GPG signature file for SHA256 sums</td>
</tr>
</tbody>
</table>
<p dir="auto">The public key that can be used to verify the GPG signatures is <a href="https://github.com/yt-dlp/yt-dlp/blob/master/public.key">available here</a>
Example usage:</p>
<div data-snippet-clipboard-copy-content="curl -L https://github.com/yt-dlp/yt-dlp/raw/master/public.key | gpg --import
gpg --verify SHA2-256SUMS.sig SHA2-256SUMS
gpg --verify SHA2-512SUMS.sig SHA2-512SUMS"><pre><code>curl -L https://github.com/yt-dlp/yt-dlp/raw/master/public.key | gpg --import
gpg --verify SHA2-256SUMS.sig SHA2-256SUMS
gpg --verify SHA2-512SUMS.sig SHA2-512SUMS
</code></pre></div>

<p dir="auto"><strong>Note</strong>: The manpages, shell completion (autocomplete) files etc. are available inside the <a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz">source tarball</a></p>
<h2 tabindex="-1" dir="auto">DEPENDENCIES</h2>
<p dir="auto">Python versions 3.7+ (CPython and PyPy) are supported. Other versions and implementations may or may not work correctly.</p>

<p dir="auto">While all the other dependencies are optional, <code>ffmpeg</code> and <code>ffprobe</code> are highly recommended</p>
<h3 tabindex="-1" dir="auto">Strongly recommended</h3>
<ul dir="auto">
<li>
<p dir="auto"><a href="https://www.ffmpeg.org/" rel="nofollow"><strong>ffmpeg</strong> and <strong>ffprobe</strong></a> - Required for <a href="#format-selection">merging separate video and audio files</a> as well as for various <a href="#post-processing-options">post-processing</a> tasks. License <a href="https://www.ffmpeg.org/legal.html" rel="nofollow">depends on the build</a></p>
<p dir="auto">There are bugs in ffmpeg that causes various issues when used alongside yt-dlp. Since ffmpeg is such an important dependency, we provide <a href="https://github.com/yt-dlp/FFmpeg-Builds#ffmpeg-static-auto-builds">custom builds</a> with patches for some of these issues at <a href="https://github.com/yt-dlp/FFmpeg-Builds">yt-dlp/FFmpeg-Builds</a>. See <a href="https://github.com/yt-dlp/FFmpeg-Builds#patches-applied">the readme</a> for details on the specific issues solved by these builds</p>
<p dir="auto"><strong>Important</strong>: What you need is ffmpeg <em>binary</em>, <strong>NOT</strong> <a href="https://pypi.org/project/ffmpeg" rel="nofollow">the python package of the same name</a></p>
</li>
</ul>
<h3 tabindex="-1" dir="auto">Networking</h3>
<ul dir="auto">
<li><a href="https://github.com/certifi/python-certifi"><strong>certifi</strong></a>* - Provides Mozilla's root certificate bundle. Licensed under <a href="https://github.com/certifi/python-certifi/blob/master/LICENSE">MPLv2</a></li>
<li><a href="https://github.com/google/brotli"><strong>brotli</strong></a>* or <a href="https://github.com/python-hyper/brotlicffi"><strong>brotlicffi</strong></a> - <a href="https://en.wikipedia.org/wiki/Brotli" rel="nofollow">Brotli</a> content encoding support. Both licensed under MIT <sup><a href="https://github.com/google/brotli/blob/master/LICENSE">1</a> <a href="https://github.com/python-hyper/brotlicffi/blob/master/LICENSE">2</a> </sup></li>
<li><a href="https://github.com/aaugustin/websockets"><strong>websockets</strong></a>* - For downloading over websocket. Licensed under <a href="https://github.com/aaugustin/websockets/blob/main/LICENSE">BSD-3-Clause</a></li>
</ul>
<h3 tabindex="-1" dir="auto">Metadata</h3>
<ul dir="auto">
<li><a href="https://github.com/quodlibet/mutagen"><strong>mutagen</strong></a>* - For <code>--embed-thumbnail</code> in certain formats. Licensed under <a href="https://github.com/quodlibet/mutagen/blob/master/COPYING">GPLv2+</a></li>
<li><a href="https://github.com/wez/atomicparsley"><strong>AtomicParsley</strong></a> - For <code>--embed-thumbnail</code> in <code>mp4</code>/<code>m4a</code> files when <code>mutagen</code>/<code>ffmpeg</code> cannot. Licensed under <a href="https://github.com/wez/atomicparsley/blob/master/COPYING">GPLv2+</a></li>
<li><a href="https://github.com/xattr/xattr"><strong>xattr</strong></a>, <a href="https://github.com/iustin/pyxattr"><strong>pyxattr</strong></a> or <a href="http://savannah.nongnu.org/projects/attr" rel="nofollow"><strong>setfattr</strong></a> - For writing xattr metadata (<code>--xattr</code>) on <strong>Linux</strong>. Licensed under <a href="https://github.com/xattr/xattr/blob/master/LICENSE.txt">MIT</a>, <a href="https://github.com/iustin/pyxattr/blob/master/COPYING">LGPL2.1</a> and <a href="http://git.savannah.nongnu.org/cgit/attr.git/tree/doc/COPYING" rel="nofollow">GPLv2+</a> respectively</li>
</ul>
<h3 tabindex="-1" dir="auto">Misc</h3>
<ul dir="auto">
<li><a href="https://github.com/Legrandin/pycryptodome"><strong>pycryptodomex</strong></a>* - For decrypting AES-128 HLS streams and various other data. Licensed under <a href="https://github.com/Legrandin/pycryptodome/blob/master/LICENSE.rst">BSD-2-Clause</a></li>
<li><a href="https://github.com/ariya/phantomjs"><strong>phantomjs</strong></a> - Used in extractors where javascript needs to be run. Licensed under <a href="https://github.com/ariya/phantomjs/blob/master/LICENSE.BSD">BSD-3-Clause</a></li>
<li><a href="https://github.com/mitya57/secretstorage"><strong>secretstorage</strong></a> - For <code>--cookies-from-browser</code> to access the <strong>Gnome</strong> keyring while decrypting cookies of <strong>Chromium</strong>-based browsers on <strong>Linux</strong>. Licensed under <a href="https://github.com/mitya57/secretstorage/blob/master/LICENSE">BSD-3-Clause</a></li>
<li>Any external downloader that you want to use with <code>--downloader</code></li>
</ul>
<h3 tabindex="-1" dir="auto">Deprecated</h3>
<ul dir="auto">
<li><a href="https://www.libav.org/" rel="nofollow"><strong>avconv</strong> and <strong>avprobe</strong></a> - Now <strong>deprecated</strong> alternative to ffmpeg. License <a href="https://libav.org/legal" rel="nofollow">depends on the build</a></li>
<li><a href="https://github.com/faissaloo/SponSkrub"><strong>sponskrub</strong></a> - For using the now <strong>deprecated</strong> <a href="#sponskrub-options">sponskrub options</a>. Licensed under <a href="https://github.com/faissaloo/SponSkrub/blob/master/LICENCE.md">GPLv3+</a></li>
<li><a href="http://rtmpdump.mplayerhq.hu/" rel="nofollow"><strong>rtmpdump</strong></a> - For downloading <code>rtmp</code> streams. ffmpeg can be used instead with <code>--downloader ffmpeg</code>. Licensed under <a href="http://rtmpdump.mplayerhq.hu/" rel="nofollow">GPLv2+</a></li>
<li><a href="http://mplayerhq.hu/design7/info.html" rel="nofollow"><strong>mplayer</strong></a> or <a href="https://mpv.io/" rel="nofollow"><strong>mpv</strong></a> - For downloading <code>rstp</code>/<code>mms</code> streams. ffmpeg can be used instead with <code>--downloader ffmpeg</code>. Licensed under <a href="https://github.com/mpv-player/mpv/blob/master/Copyright">GPLv2+</a></li>
</ul>
<p dir="auto">To use or redistribute the dependencies, you must agree to their respective licensing terms.</p>
<p dir="auto">The standalone release binaries are built with the Python interpreter and the packages marked with <strong>*</strong> included.</p>
<p dir="auto">If you do not have the necessary dependencies for a task you are attempting, yt-dlp will warn you. All the currently available dependencies are visible at the top of the <code>--verbose</code> output</p>
<h2 tabindex="-1" dir="auto">COMPILE</h2>
<h3 tabindex="-1" dir="auto">Standalone PyInstaller Builds</h3>
<p dir="auto">To build the standalone executable, you must have Python and <code>pyinstaller</code> (plus any of yt-dlp's <a href="#dependencies">optional dependencies</a> if needed). Once you have all the necessary dependencies installed, simply run <code>pyinst.py</code>. The executable will be built for the same architecture (x86/ARM, 32/64 bit) as the Python used.</p>
<div data-snippet-clipboard-copy-content="python3 -m pip install -U pyinstaller -r requirements.txt
python3 devscripts/make_lazy_extractors.py
python3 pyinst.py"><pre><code>python3 -m pip install -U pyinstaller -r requirements.txt
python3 devscripts/make_lazy_extractors.py
python3 pyinst.py
</code></pre></div>
<p dir="auto">On some systems, you may need to use <code>py</code> or <code>python</code> instead of <code>python3</code>.</p>
<p dir="auto"><code>pyinst.py</code> accepts any arguments that can be passed to <code>pyinstaller</code>, such as <code>--onefile/-F</code> or <code>--onedir/-D</code>, which is further <a href="https://pyinstaller.org/en/stable/usage.html#what-to-generate" rel="nofollow">documented here</a>.</p>
<p dir="auto"><strong>Note</strong>: Pyinstaller versions below 4.4 <a href="https://github.com/pyinstaller/pyinstaller#requirements-and-tested-platforms">do not support</a> Python installed from the Windows store without using a virtual environment.</p>
<p dir="auto"><strong>Important</strong>: Running <code>pyinstaller</code> directly <strong>without</strong> using <code>pyinst.py</code> is <strong>not</strong> officially supported. This may or may not work correctly.</p>
<h3 tabindex="-1" dir="auto">Platform-independent Binary (UNIX)</h3>
<p dir="auto">You will need the build tools <code>python</code> (3.7+), <code>zip</code>, <code>make</code> (GNU), <code>pandoc</code>* and <code>pytest</code>*.</p>
<p dir="auto">After installing these, simply run <code>make</code>.</p>
<p dir="auto">You can also run <code>make yt-dlp</code> instead to compile only the binary without updating any of the additional files. (The build tools marked with <strong>*</strong> are not needed for this)</p>
<h3 tabindex="-1" dir="auto">Standalone Py2Exe Builds (Windows)</h3>
<p dir="auto">While we provide the option to build with <a href="https://www.py2exe.org/" rel="nofollow">py2exe</a>, it is recommended to build <a href="#standalone-pyinstaller-builds">using PyInstaller</a> instead since the py2exe builds <strong>cannot contain <code>pycryptodomex</code>/<code>certifi</code> and needs VC++14</strong> on the target computer to run.</p>
<p dir="auto">If you wish to build it anyway, install Python and py2exe, and then simply run <code>setup.py py2exe</code></p>
<div data-snippet-clipboard-copy-content="py -m pip install -U py2exe -r requirements.txt
py devscripts/make_lazy_extractors.py
py setup.py py2exe"><pre><code>py -m pip install -U py2exe -r requirements.txt
py devscripts/make_lazy_extractors.py
py setup.py py2exe
</code></pre></div>
<h3 tabindex="-1" dir="auto">Related scripts</h3>
<ul dir="auto">
<li><strong><code>devscripts/update-version.py</code></strong> - Update the version number based on current date.</li>
<li><strong><code>devscripts/set-variant.py</code></strong> - Set the build variant of the executable.</li>
<li><strong><code>devscripts/make_changelog.py</code></strong> - Create a markdown changelog using short commit messages and update <code>CONTRIBUTORS</code> file.</li>
<li><strong><code>devscripts/make_lazy_extractors.py</code></strong> - Create lazy extractors. Running this before building the binaries (any variant) will improve their startup performance. Set the environment variable <code>YTDLP_NO_LAZY_EXTRACTORS=1</code> if you wish to forcefully disable lazy extractor loading.</li>
</ul>
<p dir="auto">Note: See their <code>--help</code> for more info.</p>
<h3 tabindex="-1" dir="auto">Forking the project</h3>
<p dir="auto">If you fork the project on GitHub, you can run your fork's <a href="https://github.com/yt-dlp/yt-dlp/blob/master/.github/workflows/build.yml">build workflow</a> to automatically build the selected version(s) as artifacts. Alternatively, you can run the <a href="https://github.com/yt-dlp/yt-dlp/blob/master/.github/workflows/release.yml">release workflow</a> or enable the <a href="https://github.com/yt-dlp/yt-dlp/blob/master/.github/workflows/release-nightly.yml">nightly workflow</a> to create full (pre-)releases.</p>
<h2 tabindex="-1" dir="auto">USAGE AND OPTIONS</h2>

<div data-snippet-clipboard-copy-content="yt-dlp [OPTIONS] [--] URL [URL...]"><pre><code>yt-dlp [OPTIONS] [--] URL [URL...]
</code></pre></div>
<p dir="auto"><code>Ctrl+F</code> is your friend :D</p>


<h2 tabindex="-1" dir="auto">General Options:</h2>
<div data-snippet-clipboard-copy-content="-h, --help                      Print this help text and exit
--version                       Print program version and exit
-U, --update                    Update this program to the latest version
--no-update                     Do not check for updates (default)
--update-to [CHANNEL]@[TAG]     Upgrade/downgrade to a specific version.
                                CHANNEL can be a repository as well. CHANNEL
                                and TAG default to &quot;stable&quot; and &quot;latest&quot;
                                respectively if omitted; See &quot;UPDATE&quot; for
                                details. Supported channels: stable, nightly
-i, --ignore-errors             Ignore download and postprocessing errors.
                                The download will be considered successful
                                even if the postprocessing fails
--no-abort-on-error             Continue with next video on download errors;
                                e.g. to skip unavailable videos in a
                                playlist (default)
--abort-on-error                Abort downloading of further videos if an
                                error occurs (Alias: --no-ignore-errors)
--dump-user-agent               Display the current user-agent and exit
--list-extractors               List all supported extractors and exit
--extractor-descriptions        Output descriptions of all supported
                                extractors and exit
--use-extractors NAMES          Extractor names to use separated by commas.
                                You can also use regexes, &quot;all&quot;, &quot;default&quot;
                                and &quot;end&quot; (end URL matching); e.g. --ies
                                &quot;holodex.*,end,youtube&quot;. Prefix the name
                                with a &quot;-&quot; to exclude it, e.g. --ies
                                default,-generic. Use --list-extractors for
                                a list of extractor names. (Alias: --ies)
--default-search PREFIX         Use this prefix for unqualified URLs. E.g.
                                &quot;gvsearch2:python&quot; downloads two videos from
                                google videos for the search term &quot;python&quot;.
                                Use the value &quot;auto&quot; to let yt-dlp guess
                                (&quot;auto_warning&quot; to emit a warning when
                                guessing). &quot;error&quot; just throws an error. The
                                default value &quot;fixup_error&quot; repairs broken
                                URLs, but emits an error if this is not
                                possible instead of searching
--ignore-config                 Don't load any more configuration files
                                except those given by --config-locations.
                                For backward compatibility, if this option
                                is found inside the system configuration
                                file, the user configuration is not loaded.
                                (Alias: --no-config)
--no-config-locations           Do not load any custom configuration files
                                (default). When given inside a configuration
                                file, ignore all previous --config-locations
                                defined in the current file
--config-locations PATH         Location of the main configuration file;
                                either the path to the config or its
                                containing directory (&quot;-&quot; for stdin). Can be
                                used multiple times and inside other
                                configuration files
--flat-playlist                 Do not extract the videos of a playlist,
                                only list them
--no-flat-playlist              Fully extract the videos of a playlist
                                (default)
--live-from-start               Download livestreams from the start.
                                Currently only supported for YouTube
                                (Experimental)
--no-live-from-start            Download livestreams from the current time
                                (default)
--wait-for-video MIN[-MAX]      Wait for scheduled streams to become
                                available. Pass the minimum number of
                                seconds (or range) to wait between retries
--no-wait-for-video             Do not wait for scheduled streams (default)
--mark-watched                  Mark videos watched (even with --simulate)
--no-mark-watched               Do not mark videos watched (default)
--color [STREAM:]POLICY         Whether to emit color codes in output,
                                optionally prefixed by the STREAM (stdout or
                                stderr) to apply the setting to. Can be one
                                of &quot;always&quot;, &quot;auto&quot; (default), &quot;never&quot;, or
                                &quot;no_color&quot; (use non color terminal
                                sequences). Can be used multiple times
--compat-options OPTS           Options that can help keep compatibility
                                with youtube-dl or youtube-dlc
                                configurations by reverting some of the
                                changes made in yt-dlp. See &quot;Differences in
                                default behavior&quot; for details
--alias ALIASES OPTIONS         Create aliases for an option string. Unless
                                an alias starts with a dash &quot;-&quot;, it is
                                prefixed with &quot;--&quot;. Arguments are parsed
                                according to the Python string formatting
                                mini-language. E.g. --alias get-audio,-X
                                &quot;-S=aext:{0},abr -x --audio-format {0}&quot;
                                creates options &quot;--get-audio&quot; and &quot;-X&quot; that
                                takes an argument (ARG0) and expands to
                                &quot;-S=aext:ARG0,abr -x --audio-format ARG0&quot;.
                                All defined aliases are listed in the --help
                                output. Alias options can trigger more
                                aliases; so be careful to avoid defining
                                recursive options. As a safety measure, each
                                alias may be triggered a maximum of 100
                                times. This option can be used multiple times"><pre><code>-h, --help                      Print this help text and exit
--version                       Print program version and exit
-U, --update                    Update this program to the latest version
--no-update                     Do not check for updates (default)
--update-to [CHANNEL]@[TAG]     Upgrade/downgrade to a specific version.
                                CHANNEL can be a repository as well. CHANNEL
                                and TAG default to "stable" and "latest"
                                respectively if omitted; See "UPDATE" for
                                details. Supported channels: stable, nightly
-i, --ignore-errors             Ignore download and postprocessing errors.
                                The download will be considered successful
                                even if the postprocessing fails
--no-abort-on-error             Continue with next video on download errors;
                                e.g. to skip unavailable videos in a
                                playlist (default)
--abort-on-error                Abort downloading of further videos if an
                                error occurs (Alias: --no-ignore-errors)
--dump-user-agent               Display the current user-agent and exit
--list-extractors               List all supported extractors and exit
--extractor-descriptions        Output descriptions of all supported
                                extractors and exit
--use-extractors NAMES          Extractor names to use separated by commas.
                                You can also use regexes, "all", "default"
                                and "end" (end URL matching); e.g. --ies
                                "holodex.*,end,youtube". Prefix the name
                                with a "-" to exclude it, e.g. --ies
                                default,-generic. Use --list-extractors for
                                a list of extractor names. (Alias: --ies)
--default-search PREFIX         Use this prefix for unqualified URLs. E.g.
                                "gvsearch2:python" downloads two videos from
                                google videos for the search term "python".
                                Use the value "auto" to let yt-dlp guess
                                ("auto_warning" to emit a warning when
                                guessing). "error" just throws an error. The
                                default value "fixup_error" repairs broken
                                URLs, but emits an error if this is not
                                possible instead of searching
--ignore-config                 Don't load any more configuration files
                                except those given by --config-locations.
                                For backward compatibility, if this option
                                is found inside the system configuration
                                file, the user configuration is not loaded.
                                (Alias: --no-config)
--no-config-locations           Do not load any custom configuration files
                                (default). When given inside a configuration
                                file, ignore all previous --config-locations
                                defined in the current file
--config-locations PATH         Location of the main configuration file;
                                either the path to the config or its
                                containing directory ("-" for stdin). Can be
                                used multiple times and inside other
                                configuration files
--flat-playlist                 Do not extract the videos of a playlist,
                                only list them
--no-flat-playlist              Fully extract the videos of a playlist
                                (default)
--live-from-start               Download livestreams from the start.
                                Currently only supported for YouTube
                                (Experimental)
--no-live-from-start            Download livestreams from the current time
                                (default)
--wait-for-video MIN[-MAX]      Wait for scheduled streams to become
                                available. Pass the minimum number of
                                seconds (or range) to wait between retries
--no-wait-for-video             Do not wait for scheduled streams (default)
--mark-watched                  Mark videos watched (even with --simulate)
--no-mark-watched               Do not mark videos watched (default)
--color [STREAM:]POLICY         Whether to emit color codes in output,
                                optionally prefixed by the STREAM (stdout or
                                stderr) to apply the setting to. Can be one
                                of "always", "auto" (default), "never", or
                                "no_color" (use non color terminal
                                sequences). Can be used multiple times
--compat-options OPTS           Options that can help keep compatibility
                                with youtube-dl or youtube-dlc
                                configurations by reverting some of the
                                changes made in yt-dlp. See "Differences in
                                default behavior" for details
--alias ALIASES OPTIONS         Create aliases for an option string. Unless
                                an alias starts with a dash "-", it is
                                prefixed with "--". Arguments are parsed
                                according to the Python string formatting
                                mini-language. E.g. --alias get-audio,-X
                                "-S=aext:{0},abr -x --audio-format {0}"
                                creates options "--get-audio" and "-X" that
                                takes an argument (ARG0) and expands to
                                "-S=aext:ARG0,abr -x --audio-format ARG0".
                                All defined aliases are listed in the --help
                                output. Alias options can trigger more
                                aliases; so be careful to avoid defining
                                recursive options. As a safety measure, each
                                alias may be triggered a maximum of 100
                                times. This option can be used multiple times
</code></pre></div>
<h2 tabindex="-1" dir="auto">Network Options:</h2>
<div data-snippet-clipboard-copy-content="--proxy URL                     Use the specified HTTP/HTTPS/SOCKS proxy. To
                                enable SOCKS proxy, specify a proper scheme,
                                e.g. socks5://user:pass@127.0.0.1:1080/.
                                Pass in an empty string (--proxy &quot;&quot;) for
                                direct connection
--socket-timeout SECONDS        Time to wait before giving up, in seconds
--source-address IP             Client-side IP address to bind to
-4, --force-ipv4                Make all connections via IPv4
-6, --force-ipv6                Make all connections via IPv6
--enable-file-urls              Enable file:// URLs. This is disabled by
                                default for security reasons."><pre><code>--proxy URL                     Use the specified HTTP/HTTPS/SOCKS proxy. To
                                enable SOCKS proxy, specify a proper scheme,
                                e.g. socks5://user:pass@127.0.0.1:1080/.
                                Pass in an empty string (--proxy "") for
                                direct connection
--socket-timeout SECONDS        Time to wait before giving up, in seconds
--source-address IP             Client-side IP address to bind to
-4, --force-ipv4                Make all connections via IPv4
-6, --force-ipv6                Make all connections via IPv6
--enable-file-urls              Enable file:// URLs. This is disabled by
                                default for security reasons.
</code></pre></div>
<h2 tabindex="-1" dir="auto">Geo-restriction:</h2>
<div data-snippet-clipboard-copy-content="--geo-verification-proxy URL    Use this proxy to verify the IP address for
                                some geo-restricted sites. The default proxy
                                specified by --proxy (or none, if the option
                                is not present) is used for the actual
                                downloading
--xff VALUE                     How to fake X-Forwarded-For HTTP header to
                                try bypassing geographic restriction. One of
                                &quot;default&quot; (only when known to be useful),
                                &quot;never&quot;, an IP block in CIDR notation, or a
                                two-letter ISO 3166-2 country code"><pre><code>--geo-verification-proxy URL    Use this proxy to verify the IP address for
                                some geo-restricted sites. The default proxy
                                specified by --proxy (or none, if the option
                                is not present) is used for the actual
                                downloading
--xff VALUE                     How to fake X-Forwarded-For HTTP header to
                                try bypassing geographic restriction. One of
                                "default" (only when known to be useful),
                                "never", an IP block in CIDR notation, or a
                                two-letter ISO 3166-2 country code
</code></pre></div>
<h2 tabindex="-1" dir="auto">Video Selection:</h2>
<div data-snippet-clipboard-copy-content="-I, --playlist-items ITEM_SPEC  Comma separated playlist_index of the items
                                to download. You can specify a range using
                                &quot;[START]:[STOP][:STEP]&quot;. For backward
                                compatibility, START-STOP is also supported.
                                Use negative indices to count from the right
                                and negative STEP to download in reverse
                                order. E.g. &quot;-I 1:3,7,-5::2&quot; used on a
                                playlist of size 15 will download the items
                                at index 1,2,3,7,11,13,15
--min-filesize SIZE             Abort download if filesize is smaller than
                                SIZE, e.g. 50k or 44.6M
--max-filesize SIZE             Abort download if filesize is larger than
                                SIZE, e.g. 50k or 44.6M
--date DATE                     Download only videos uploaded on this date.
                                The date can be &quot;YYYYMMDD&quot; or in the format 
                                [now|today|yesterday][-N[day|week|month|year]].
                                E.g. &quot;--date today-2weeks&quot; downloads only
                                videos uploaded on the same day two weeks ago
--datebefore DATE               Download only videos uploaded on or before
                                this date. The date formats accepted is the
                                same as --date
--dateafter DATE                Download only videos uploaded on or after
                                this date. The date formats accepted is the
                                same as --date
--match-filters FILTER          Generic video filter. Any &quot;OUTPUT TEMPLATE&quot;
                                field can be compared with a number or a
                                string using the operators defined in
                                &quot;Filtering Formats&quot;. You can also simply
                                specify a field to match if the field is
                                present, use &quot;!field&quot; to check if the field
                                is not present, and &quot;&amp;&quot; to check multiple
                                conditions. Use a &quot;\&quot; to escape &quot;&amp;&quot; or
                                quotes if needed. If used multiple times,
                                the filter matches if atleast one of the
                                conditions are met. E.g. --match-filter
                                !is_live --match-filter &quot;like_count>?100 &amp;
                                description~='(?i)\bcats \&amp; dogs\b'&quot; matches
                                only videos that are not live OR those that
                                have a like count more than 100 (or the like
                                field is not available) and also has a
                                description that contains the phrase &quot;cats &amp;
                                dogs&quot; (caseless). Use &quot;--match-filter -&quot; to
                                interactively ask whether to download each
                                video
--no-match-filters              Do not use any --match-filter (default)
--break-match-filters FILTER    Same as &quot;--match-filters&quot; but stops the
                                download process when a video is rejected
--no-break-match-filters        Do not use any --break-match-filters (default)
--no-playlist                   Download only the video, if the URL refers
                                to a video and a playlist
--yes-playlist                  Download the playlist, if the URL refers to
                                a video and a playlist
--age-limit YEARS               Download only videos suitable for the given
                                age
--download-archive FILE         Download only videos not listed in the
                                archive file. Record the IDs of all
                                downloaded videos in it
--no-download-archive           Do not use archive file (default)
--max-downloads NUMBER          Abort after downloading NUMBER files
--break-on-existing             Stop the download process when encountering
                                a file that is in the archive
--break-per-input               Alters --max-downloads, --break-on-existing,
                                --break-match-filter, and autonumber to
                                reset per input URL
--no-break-per-input            --break-on-existing and similar options
                                terminates the entire download queue
--skip-playlist-after-errors N  Number of allowed failures until the rest of
                                the playlist is skipped"><pre><code>-I, --playlist-items ITEM_SPEC  Comma separated playlist_index of the items
                                to download. You can specify a range using
                                "[START]:[STOP][:STEP]". For backward
                                compatibility, START-STOP is also supported.
                                Use negative indices to count from the right
                                and negative STEP to download in reverse
                                order. E.g. "-I 1:3,7,-5::2" used on a
                                playlist of size 15 will download the items
                                at index 1,2,3,7,11,13,15
--min-filesize SIZE             Abort download if filesize is smaller than
                                SIZE, e.g. 50k or 44.6M
--max-filesize SIZE             Abort download if filesize is larger than
                                SIZE, e.g. 50k or 44.6M
--date DATE                     Download only videos uploaded on this date.
                                The date can be "YYYYMMDD" or in the format 
                                [now|today|yesterday][-N[day|week|month|year]].
                                E.g. "--date today-2weeks" downloads only
                                videos uploaded on the same day two weeks ago
--datebefore DATE               Download only videos uploaded on or before
                                this date. The date formats accepted is the
                                same as --date
--dateafter DATE                Download only videos uploaded on or after
                                this date. The date formats accepted is the
                                same as --date
--match-filters FILTER          Generic video filter. Any "OUTPUT TEMPLATE"
                                field can be compared with a number or a
                                string using the operators defined in
                                "Filtering Formats". You can also simply
                                specify a field to match if the field is
                                present, use "!field" to check if the field
                                is not present, and "&amp;" to check multiple
                                conditions. Use a "\" to escape "&amp;" or
                                quotes if needed. If used multiple times,
                                the filter matches if atleast one of the
                                conditions are met. E.g. --match-filter
                                !is_live --match-filter "like_count&gt;?100 &amp;
                                description~='(?i)\bcats \&amp; dogs\b'" matches
                                only videos that are not live OR those that
                                have a like count more than 100 (or the like
                                field is not available) and also has a
                                description that contains the phrase "cats &amp;
                                dogs" (caseless). Use "--match-filter -" to
                                interactively ask whether to download each
                                video
--no-match-filters              Do not use any --match-filter (default)
--break-match-filters FILTER    Same as "--match-filters" but stops the
                                download process when a video is rejected
--no-break-match-filters        Do not use any --break-match-filters (default)
--no-playlist                   Download only the video, if the URL refers
                                to a video and a playlist
--yes-playlist                  Download the playlist, if the URL refers to
                                a video and a playlist
--age-limit YEARS               Download only videos suitable for the given
                                age
--download-archive FILE         Download only videos not listed in the
                                archive file. Record the IDs of all
                                downloaded videos in it
--no-download-archive           Do not use archive file (default)
--max-downloads NUMBER          Abort after downloading NUMBER files
--break-on-existing             Stop the download process when encountering
                                a file that is in the archive
--break-per-input               Alters --max-downloads, --break-on-existing,
                                --break-match-filter, and autonumber to
                                reset per input URL
--no-break-per-input            --break-on-existing and similar options
                                terminates the entire download queue
--skip-playlist-after-errors N  Number of allowed failures until the rest of
                                the playlist is skipped
</code></pre></div>
<h2 tabindex="-1" dir="auto">Download Options:</h2>
<div data-snippet-clipboard-copy-content="-N, --concurrent-fragments N    Number of fragments of a dash/hlsnative
                                video that should be downloaded concurrently
                                (default is 1)
-r, --limit-rate RATE           Maximum download rate in bytes per second,
                                e.g. 50K or 4.2M
--throttled-rate RATE           Minimum download rate in bytes per second
                                below which throttling is assumed and the
                                video data is re-extracted, e.g. 100K
-R, --retries RETRIES           Number of retries (default is 10), or
                                &quot;infinite&quot;
--file-access-retries RETRIES   Number of times to retry on file access
                                error (default is 3), or &quot;infinite&quot;
--fragment-retries RETRIES      Number of retries for a fragment (default is
                                10), or &quot;infinite&quot; (DASH, hlsnative and ISM)
--retry-sleep [TYPE:]EXPR       Time to sleep between retries in seconds
                                (optionally) prefixed by the type of retry
                                (http (default), fragment, file_access,
                                extractor) to apply the sleep to. EXPR can
                                be a number, linear=START[:END[:STEP=1]] or
                                exp=START[:END[:BASE=2]]. This option can be
                                used multiple times to set the sleep for the
                                different retry types, e.g. --retry-sleep
                                linear=1::2 --retry-sleep fragment:exp=1:20
--skip-unavailable-fragments    Skip unavailable fragments for DASH,
                                hlsnative and ISM downloads (default)
                                (Alias: --no-abort-on-unavailable-fragments)
--abort-on-unavailable-fragments
                                Abort download if a fragment is unavailable
                                (Alias: --no-skip-unavailable-fragments)
--keep-fragments                Keep downloaded fragments on disk after
                                downloading is finished
--no-keep-fragments             Delete downloaded fragments after
                                downloading is finished (default)
--buffer-size SIZE              Size of download buffer, e.g. 1024 or 16K
                                (default is 1024)
--resize-buffer                 The buffer size is automatically resized
                                from an initial value of --buffer-size
                                (default)
--no-resize-buffer              Do not automatically adjust the buffer size
--http-chunk-size SIZE          Size of a chunk for chunk-based HTTP
                                downloading, e.g. 10485760 or 10M (default
                                is disabled). May be useful for bypassing
                                bandwidth throttling imposed by a webserver
                                (experimental)
--playlist-random               Download playlist videos in random order
--lazy-playlist                 Process entries in the playlist as they are
                                received. This disables n_entries,
                                --playlist-random and --playlist-reverse
--no-lazy-playlist              Process videos in the playlist only after
                                the entire playlist is parsed (default)
--xattr-set-filesize            Set file xattribute ytdl.filesize with
                                expected file size
--hls-use-mpegts                Use the mpegts container for HLS videos;
                                allowing some players to play the video
                                while downloading, and reducing the chance
                                of file corruption if download is
                                interrupted. This is enabled by default for
                                live streams
--no-hls-use-mpegts             Do not use the mpegts container for HLS
                                videos. This is default when not downloading
                                live streams
--download-sections REGEX       Download only chapters that match the
                                regular expression. A &quot;*&quot; prefix denotes
                                time-range instead of chapter. Negative
                                timestamps are calculated from the end.
                                &quot;*from-url&quot; can be used to download between
                                the &quot;start_time&quot; and &quot;end_time&quot; extracted
                                from the URL. Needs ffmpeg. This option can
                                be used multiple times to download multiple
                                sections, e.g. --download-sections
                                &quot;*10:15-inf&quot; --download-sections &quot;intro&quot;
--downloader [PROTO:]NAME       Name or path of the external downloader to
                                use (optionally) prefixed by the protocols
                                (http, ftp, m3u8, dash, rstp, rtmp, mms) to
                                use it for. Currently supports native,
                                aria2c, avconv, axel, curl, ffmpeg, httpie,
                                wget. You can use this option multiple times
                                to set different downloaders for different
                                protocols. E.g. --downloader aria2c
                                --downloader &quot;dash,m3u8:native&quot; will use
                                aria2c for http/ftp downloads, and the
                                native downloader for dash/m3u8 downloads
                                (Alias: --external-downloader)
--downloader-args NAME:ARGS     Give these arguments to the external
                                downloader. Specify the downloader name and
                                the arguments separated by a colon &quot;:&quot;. For
                                ffmpeg, arguments can be passed to different
                                positions using the same syntax as
                                --postprocessor-args. You can use this
                                option multiple times to give different
                                arguments to different downloaders (Alias:
                                --external-downloader-args)"><pre><code>-N, --concurrent-fragments N    Number of fragments of a dash/hlsnative
                                video that should be downloaded concurrently
                                (default is 1)
-r, --limit-rate RATE           Maximum download rate in bytes per second,
                                e.g. 50K or 4.2M
--throttled-rate RATE           Minimum download rate in bytes per second
                                below which throttling is assumed and the
                                video data is re-extracted, e.g. 100K
-R, --retries RETRIES           Number of retries (default is 10), or
                                "infinite"
--file-access-retries RETRIES   Number of times to retry on file access
                                error (default is 3), or "infinite"
--fragment-retries RETRIES      Number of retries for a fragment (default is
                                10), or "infinite" (DASH, hlsnative and ISM)
--retry-sleep [TYPE:]EXPR       Time to sleep between retries in seconds
                                (optionally) prefixed by the type of retry
                                (http (default), fragment, file_access,
                                extractor) to apply the sleep to. EXPR can
                                be a number, linear=START[:END[:STEP=1]] or
                                exp=START[:END[:BASE=2]]. This option can be
                                used multiple times to set the sleep for the
                                different retry types, e.g. --retry-sleep
                                linear=1::2 --retry-sleep fragment:exp=1:20
--skip-unavailable-fragments    Skip unavailable fragments for DASH,
                                hlsnative and ISM downloads (default)
                                (Alias: --no-abort-on-unavailable-fragments)
--abort-on-unavailable-fragments
                                Abort download if a fragment is unavailable
                                (Alias: --no-skip-unavailable-fragments)
--keep-fragments                Keep downloaded fragments on disk after
                                downloading is finished
--no-keep-fragments             Delete downloaded fragments after
                                downloading is finished (default)
--buffer-size SIZE              Size of download buffer, e.g. 1024 or 16K
                                (default is 1024)
--resize-buffer                 The buffer size is automatically resized
                                from an initial value of --buffer-size
                                (default)
--no-resize-buffer              Do not automatically adjust the buffer size
--http-chunk-size SIZE          Size of a chunk for chunk-based HTTP
                                downloading, e.g. 10485760 or 10M (default
                                is disabled). May be useful for bypassing
                                bandwidth throttling imposed by a webserver
                                (experimental)
--playlist-random               Download playlist videos in random order
--lazy-playlist                 Process entries in the playlist as they are
                                received. This disables n_entries,
                                --playlist-random and --playlist-reverse
--no-lazy-playlist              Process videos in the playlist only after
                                the entire playlist is parsed (default)
--xattr-set-filesize            Set file xattribute ytdl.filesize with
                                expected file size
--hls-use-mpegts                Use the mpegts container for HLS videos;
                                allowing some players to play the video
                                while downloading, and reducing the chance
                                of file corruption if download is
                                interrupted. This is enabled by default for
                                live streams
--no-hls-use-mpegts             Do not use the mpegts container for HLS
                                videos. This is default when not downloading
                                live streams
--download-sections REGEX       Download only chapters that match the
                                regular expression. A "*" prefix denotes
                                time-range instead of chapter. Negative
                                timestamps are calculated from the end.
                                "*from-url" can be used to download between
                                the "start_time" and "end_time" extracted
                                from the URL. Needs ffmpeg. This option can
                                be used multiple times to download multiple
                                sections, e.g. --download-sections
                                "*10:15-inf" --download-sections "intro"
--downloader [PROTO:]NAME       Name or path of the external downloader to
                                use (optionally) prefixed by the protocols
                                (http, ftp, m3u8, dash, rstp, rtmp, mms) to
                                use it for. Currently supports native,
                                aria2c, avconv, axel, curl, ffmpeg, httpie,
                                wget. You can use this option multiple times
                                to set different downloaders for different
                                protocols. E.g. --downloader aria2c
                                --downloader "dash,m3u8:native" will use
                                aria2c for http/ftp downloads, and the
                                native downloader for dash/m3u8 downloads
                                (Alias: --external-downloader)
--downloader-args NAME:ARGS     Give these arguments to the external
                                downloader. Specify the downloader name and
                                the arguments separated by a colon ":". For
                                ffmpeg, arguments can be passed to different
                                positions using the same syntax as
                                --postprocessor-args. You can use this
                                option multiple times to give different
                                arguments to different downloaders (Alias:
                                --external-downloader-args)
</code></pre></div>
<h2 tabindex="-1" dir="auto">Filesystem Options:</h2>
<div data-snippet-clipboard-copy-content="-a, --batch-file FILE           File containing URLs to download (&quot;-&quot; for
                                stdin), one URL per line. Lines starting
                                with &quot;#&quot;, &quot;;&quot; or &quot;]&quot; are considered as
                                comments and ignored
--no-batch-file                 Do not read URLs from batch file (default)
-P, --paths [TYPES:]PATH        The paths where the files should be
                                downloaded. Specify the type of file and the
                                path separated by a colon &quot;:&quot;. All the same
                                TYPES as --output are supported.
                                Additionally, you can also provide &quot;home&quot;
                                (default) and &quot;temp&quot; paths. All intermediary
                                files are first downloaded to the temp path
                                and then the final files are moved over to
                                the home path after download is finished.
                                This option is ignored if --output is an
                                absolute path
-o, --output [TYPES:]TEMPLATE   Output filename template; see &quot;OUTPUT
                                TEMPLATE&quot; for details
--output-na-placeholder TEXT    Placeholder for unavailable fields in
                                &quot;OUTPUT TEMPLATE&quot; (default: &quot;NA&quot;)
--restrict-filenames            Restrict filenames to only ASCII characters,
                                and avoid &quot;&amp;&quot; and spaces in filenames
--no-restrict-filenames         Allow Unicode characters, &quot;&amp;&quot; and spaces in
                                filenames (default)
--windows-filenames             Force filenames to be Windows-compatible
--no-windows-filenames          Make filenames Windows-compatible only if
                                using Windows (default)
--trim-filenames LENGTH         Limit the filename length (excluding
                                extension) to the specified number of
                                characters
-w, --no-overwrites             Do not overwrite any files
--force-overwrites              Overwrite all video and metadata files. This
                                option includes --no-continue
--no-force-overwrites           Do not overwrite the video, but overwrite
                                related files (default)
-c, --continue                  Resume partially downloaded files/fragments
                                (default)
--no-continue                   Do not resume partially downloaded
                                fragments. If the file is not fragmented,
                                restart download of the entire file
--part                          Use .part files instead of writing directly
                                into output file (default)
--no-part                       Do not use .part files - write directly into
                                output file
--mtime                         Use the Last-modified header to set the file
                                modification time (default)
--no-mtime                      Do not use the Last-modified header to set
                                the file modification time
--write-description             Write video description to a .description file
--no-write-description          Do not write video description (default)
--write-info-json               Write video metadata to a .info.json file
                                (this may contain personal information)
--no-write-info-json            Do not write video metadata (default)
--write-playlist-metafiles      Write playlist metadata in addition to the
                                video metadata when using --write-info-json,
                                --write-description etc. (default)
--no-write-playlist-metafiles   Do not write playlist metadata when using
                                --write-info-json, --write-description etc.
--clean-info-json               Remove some internal metadata such as
                                filenames from the infojson (default)
--no-clean-info-json            Write all fields to the infojson
--write-comments                Retrieve video comments to be placed in the
                                infojson. The comments are fetched even
                                without this option if the extraction is
                                known to be quick (Alias: --get-comments)
--no-write-comments             Do not retrieve video comments unless the
                                extraction is known to be quick (Alias:
                                --no-get-comments)
--load-info-json FILE           JSON file containing the video information
                                (created with the &quot;--write-info-json&quot; option)
--cookies FILE                  Netscape formatted file to read cookies from
                                and dump cookie jar in
--no-cookies                    Do not read/dump cookies from/to file
                                (default)
--cookies-from-browser BROWSER[+KEYRING][:PROFILE][::CONTAINER]
                                The name of the browser to load cookies
                                from. Currently supported browsers are:
                                brave, chrome, chromium, edge, firefox,
                                opera, safari, vivaldi. Optionally, the
                                KEYRING used for decrypting Chromium cookies
                                on Linux, the name/path of the PROFILE to
                                load cookies from, and the CONTAINER name
                                (if Firefox) (&quot;none&quot; for no container) can
                                be given with their respective seperators.
                                By default, all containers of the most
                                recently accessed profile are used.
                                Currently supported keyrings are: basictext,
                                gnomekeyring, kwallet, kwallet5, kwallet6
--no-cookies-from-browser       Do not load cookies from browser (default)
--cache-dir DIR                 Location in the filesystem where yt-dlp can
                                store some downloaded information (such as
                                client ids and signatures) permanently. By
                                default ${XDG_CACHE_HOME}/yt-dlp
--no-cache-dir                  Disable filesystem caching
--rm-cache-dir                  Delete all filesystem cache files"><pre><code>-a, --batch-file FILE           File containing URLs to download ("-" for
                                stdin), one URL per line. Lines starting
                                with "#", ";" or "]" are considered as
                                comments and ignored
--no-batch-file                 Do not read URLs from batch file (default)
-P, --paths [TYPES:]PATH        The paths where the files should be
                                downloaded. Specify the type of file and the
                                path separated by a colon ":". All the same
                                TYPES as --output are supported.
                                Additionally, you can also provide "home"
                                (default) and "temp" paths. All intermediary
                                files are first downloaded to the temp path
                                and then the final files are moved over to
                                the home path after download is finished.
                                This option is ignored if --output is an
                                absolute path
-o, --output [TYPES:]TEMPLATE   Output filename template; see "OUTPUT
                                TEMPLATE" for details
--output-na-placeholder TEXT    Placeholder for unavailable fields in
                                "OUTPUT TEMPLATE" (default: "NA")
--restrict-filenames            Restrict filenames to only ASCII characters,
                                and avoid "&amp;" and spaces in filenames
--no-restrict-filenames         Allow Unicode characters, "&amp;" and spaces in
                                filenames (default)
--windows-filenames             Force filenames to be Windows-compatible
--no-windows-filenames          Make filenames Windows-compatible only if
                                using Windows (default)
--trim-filenames LENGTH         Limit the filename length (excluding
                                extension) to the specified number of
                                characters
-w, --no-overwrites             Do not overwrite any files
--force-overwrites              Overwrite all video and metadata files. This
                                option includes --no-continue
--no-force-overwrites           Do not overwrite the video, but overwrite
                                related files (default)
-c, --continue                  Resume partially downloaded files/fragments
                                (default)
--no-continue                   Do not resume partially downloaded
                                fragments. If the file is not fragmented,
                                restart download of the entire file
--part                          Use .part files instead of writing directly
                                into output file (default)
--no-part                       Do not use .part files - write directly into
                                output file
--mtime                         Use the Last-modified header to set the file
                                modification time (default)
--no-mtime                      Do not use the Last-modified header to set
                                the file modification time
--write-description             Write video description to a .description file
--no-write-description          Do not write video description (default)
--write-info-json               Write video metadata to a .info.json file
                                (this may contain personal information)
--no-write-info-json            Do not write video metadata (default)
--write-playlist-metafiles      Write playlist metadata in addition to the
                                video metadata when using --write-info-json,
                                --write-description etc. (default)
--no-write-playlist-metafiles   Do not write playlist metadata when using
                                --write-info-json, --write-description etc.
--clean-info-json               Remove some internal metadata such as
                                filenames from the infojson (default)
--no-clean-info-json            Write all fields to the infojson
--write-comments                Retrieve video comments to be placed in the
                                infojson. The comments are fetched even
                                without this option if the extraction is
                                known to be quick (Alias: --get-comments)
--no-write-comments             Do not retrieve video comments unless the
                                extraction is known to be quick (Alias:
                                --no-get-comments)
--load-info-json FILE           JSON file containing the video information
                                (created with the "--write-info-json" option)
--cookies FILE                  Netscape formatted file to read cookies from
                                and dump cookie jar in
--no-cookies                    Do not read/dump cookies from/to file
                                (default)
--cookies-from-browser BROWSER[+KEYRING][:PROFILE][::CONTAINER]
                                The name of the browser to load cookies
                                from. Currently supported browsers are:
                                brave, chrome, chromium, edge, firefox,
                                opera, safari, vivaldi. Optionally, the
                                KEYRING used for decrypting Chromium cookies
                                on Linux, the name/path of the PROFILE to
                                load cookies from, and the CONTAINER name
                                (if Firefox) ("none" for no container) can
                                be given with their respective seperators.
                                By default, all containers of the most
                                recently accessed profile are used.
                                Currently supported keyrings are: basictext,
                                gnomekeyring, kwallet, kwallet5, kwallet6
--no-cookies-from-browser       Do not load cookies from browser (default)
--cache-dir DIR                 Location in the filesystem where yt-dlp can
                                store some downloaded information (such as
                                client ids and signatures) permanently. By
                                default ${XDG_CACHE_HOME}/yt-dlp
--no-cache-dir                  Disable filesystem caching
--rm-cache-dir                  Delete all filesystem cache files
</code></pre></div>
<h2 tabindex="-1" dir="auto">Thumbnail Options:</h2>
<div data-snippet-clipboard-copy-content="--write-thumbnail               Write thumbnail image to disk
--no-write-thumbnail            Do not write thumbnail image to disk (default)
--write-all-thumbnails          Write all thumbnail image formats to disk
--list-thumbnails               List available thumbnails of each video.
                                Simulate unless --no-simulate is used"><pre><code>--write-thumbnail               Write thumbnail image to disk
--no-write-thumbnail            Do not write thumbnail image to disk (default)
--write-all-thumbnails          Write all thumbnail image formats to disk
--list-thumbnails               List available thumbnails of each video.
                                Simulate unless --no-simulate is used
</code></pre></div>
<h2 tabindex="-1" dir="auto">Internet Shortcut Options:</h2>
<div data-snippet-clipboard-copy-content="--write-link                    Write an internet shortcut file, depending
                                on the current platform (.url, .webloc or
                                .desktop). The URL may be cached by the OS
--write-url-link                Write a .url Windows internet shortcut. The
                                OS caches the URL based on the file path
--write-webloc-link             Write a .webloc macOS internet shortcut
--write-desktop-link            Write a .desktop Linux internet shortcut"><pre><code>--write-link                    Write an internet shortcut file, depending
                                on the current platform (.url, .webloc or
                                .desktop). The URL may be cached by the OS
--write-url-link                Write a .url Windows internet shortcut. The
                                OS caches the URL based on the file path
--write-webloc-link             Write a .webloc macOS internet shortcut
--write-desktop-link            Write a .desktop Linux internet shortcut
</code></pre></div>
<h2 tabindex="-1" dir="auto">Verbosity and Simulation Options:</h2>
<div data-snippet-clipboard-copy-content="-q, --quiet                     Activate quiet mode. If used with --verbose,
                                print the log to stderr
--no-quiet                      Deactivate quiet mode. (Default)
--no-warnings                   Ignore warnings
-s, --simulate                  Do not download the video and do not write
                                anything to disk
--no-simulate                   Download the video even if printing/listing
                                options are used
--ignore-no-formats-error       Ignore &quot;No video formats&quot; error. Useful for
                                extracting metadata even if the videos are
                                not actually available for download
                                (experimental)
--no-ignore-no-formats-error    Throw error when no downloadable video
                                formats are found (default)
--skip-download                 Do not download the video but write all
                                related files (Alias: --no-download)
-O, --print [WHEN:]TEMPLATE     Field name or output template to print to
                                screen, optionally prefixed with when to
                                print it, separated by a &quot;:&quot;. Supported
                                values of &quot;WHEN&quot; are the same as that of
                                --use-postprocessor (default: video).
                                Implies --quiet. Implies --simulate unless
                                --no-simulate or later stages of WHEN are
                                used. This option can be used multiple times
--print-to-file [WHEN:]TEMPLATE FILE
                                Append given template to the file. The
                                values of WHEN and TEMPLATE are same as that
                                of --print. FILE uses the same syntax as the
                                output template. This option can be used
                                multiple times
-j, --dump-json                 Quiet, but print JSON information for each
                                video. Simulate unless --no-simulate is
                                used. See &quot;OUTPUT TEMPLATE&quot; for a
                                description of available keys
-J, --dump-single-json          Quiet, but print JSON information for each
                                url or infojson passed. Simulate unless
                                --no-simulate is used. If the URL refers to
                                a playlist, the whole playlist information
                                is dumped in a single line
--force-write-archive           Force download archive entries to be written
                                as far as no errors occur, even if -s or
                                another simulation option is used (Alias:
                                --force-download-archive)
--newline                       Output progress bar as new lines
--no-progress                   Do not print progress bar
--progress                      Show progress bar, even if in quiet mode
--console-title                 Display progress in console titlebar
--progress-template [TYPES:]TEMPLATE
                                Template for progress outputs, optionally
                                prefixed with one of &quot;download:&quot; (default),
                                &quot;download-title:&quot; (the console title),
                                &quot;postprocess:&quot;,  or &quot;postprocess-title:&quot;.
                                The video's fields are accessible under the
                                &quot;info&quot; key and the progress attributes are
                                accessible under &quot;progress&quot; key. E.g.
                                --console-title --progress-template
                                &quot;download-title:%(info.id)s-%(progress.eta)s&quot;
-v, --verbose                   Print various debugging information
--dump-pages                    Print downloaded pages encoded using base64
                                to debug problems (very verbose)
--write-pages                   Write downloaded intermediary pages to files
                                in the current directory to debug problems
--print-traffic                 Display sent and read HTTP traffic"><pre><code>-q, --quiet                     Activate quiet mode. If used with --verbose,
                                print the log to stderr
--no-quiet                      Deactivate quiet mode. (Default)
--no-warnings                   Ignore warnings
-s, --simulate                  Do not download the video and do not write
                                anything to disk
--no-simulate                   Download the video even if printing/listing
                                options are used
--ignore-no-formats-error       Ignore "No video formats" error. Useful for
                                extracting metadata even if the videos are
                                not actually available for download
                                (experimental)
--no-ignore-no-formats-error    Throw error when no downloadable video
                                formats are found (default)
--skip-download                 Do not download the video but write all
                                related files (Alias: --no-download)
-O, --print [WHEN:]TEMPLATE     Field name or output template to print to
                                screen, optionally prefixed with when to
                                print it, separated by a ":". Supported
                                values of "WHEN" are the same as that of
                                --use-postprocessor (default: video).
                                Implies --quiet. Implies --simulate unless
                                --no-simulate or later stages of WHEN are
                                used. This option can be used multiple times
--print-to-file [WHEN:]TEMPLATE FILE
                                Append given template to the file. The
                                values of WHEN and TEMPLATE are same as that
                                of --print. FILE uses the same syntax as the
                                output template. This option can be used
                                multiple times
-j, --dump-json                 Quiet, but print JSON information for each
                                video. Simulate unless --no-simulate is
                                used. See "OUTPUT TEMPLATE" for a
                                description of available keys
-J, --dump-single-json          Quiet, but print JSON information for each
                                url or infojson passed. Simulate unless
                                --no-simulate is used. If the URL refers to
                                a playlist, the whole playlist information
                                is dumped in a single line
--force-write-archive           Force download archive entries to be written
                                as far as no errors occur, even if -s or
                                another simulation option is used (Alias:
                                --force-download-archive)
--newline                       Output progress bar as new lines
--no-progress                   Do not print progress bar
--progress                      Show progress bar, even if in quiet mode
--console-title                 Display progress in console titlebar
--progress-template [TYPES:]TEMPLATE
                                Template for progress outputs, optionally
                                prefixed with one of "download:" (default),
                                "download-title:" (the console title),
                                "postprocess:",  or "postprocess-title:".
                                The video's fields are accessible under the
                                "info" key and the progress attributes are
                                accessible under "progress" key. E.g.
                                --console-title --progress-template
                                "download-title:%(info.id)s-%(progress.eta)s"
-v, --verbose                   Print various debugging information
--dump-pages                    Print downloaded pages encoded using base64
                                to debug problems (very verbose)
--write-pages                   Write downloaded intermediary pages to files
                                in the current directory to debug problems
--print-traffic                 Display sent and read HTTP traffic
</code></pre></div>
<h2 tabindex="-1" dir="auto">Workarounds:</h2>
<div data-snippet-clipboard-copy-content="--encoding ENCODING             Force the specified encoding (experimental)
--legacy-server-connect         Explicitly allow HTTPS connection to servers
                                that do not support RFC 5746 secure
                                renegotiation
--no-check-certificates         Suppress HTTPS certificate validation
--prefer-insecure               Use an unencrypted connection to retrieve
                                information about the video (Currently
                                supported only for YouTube)
--add-headers FIELD:VALUE       Specify a custom HTTP header and its value,
                                separated by a colon &quot;:&quot;. You can use this
                                option multiple times
--bidi-workaround               Work around terminals that lack
                                bidirectional text support. Requires bidiv
                                or fribidi executable in PATH
--sleep-requests SECONDS        Number of seconds to sleep between requests
                                during data extraction
--sleep-interval SECONDS        Number of seconds to sleep before each
                                download. This is the minimum time to sleep
                                when used along with --max-sleep-interval
                                (Alias: --min-sleep-interval)
--max-sleep-interval SECONDS    Maximum number of seconds to sleep. Can only
                                be used along with --min-sleep-interval
--sleep-subtitles SECONDS       Number of seconds to sleep before each
                                subtitle download"><pre><code>--encoding ENCODING             Force the specified encoding (experimental)
--legacy-server-connect         Explicitly allow HTTPS connection to servers
                                that do not support RFC 5746 secure
                                renegotiation
--no-check-certificates         Suppress HTTPS certificate validation
--prefer-insecure               Use an unencrypted connection to retrieve
                                information about the video (Currently
                                supported only for YouTube)
--add-headers FIELD:VALUE       Specify a custom HTTP header and its value,
                                separated by a colon ":". You can use this
                                option multiple times
--bidi-workaround               Work around terminals that lack
                                bidirectional text support. Requires bidiv
                                or fribidi executable in PATH
--sleep-requests SECONDS        Number of seconds to sleep between requests
                                during data extraction
--sleep-interval SECONDS        Number of seconds to sleep before each
                                download. This is the minimum time to sleep
                                when used along with --max-sleep-interval
                                (Alias: --min-sleep-interval)
--max-sleep-interval SECONDS    Maximum number of seconds to sleep. Can only
                                be used along with --min-sleep-interval
--sleep-subtitles SECONDS       Number of seconds to sleep before each
                                subtitle download
</code></pre></div>
<h2 tabindex="-1" dir="auto">Video Format Options:</h2>
<div data-snippet-clipboard-copy-content="-f, --format FORMAT             Video format code, see &quot;FORMAT SELECTION&quot;
                                for more details
-S, --format-sort SORTORDER     Sort the formats by the fields given, see
                                &quot;Sorting Formats&quot; for more details
--format-sort-force             Force user specified sort order to have
                                precedence over all fields, see &quot;Sorting
                                Formats&quot; for more details (Alias: --S-force)
--no-format-sort-force          Some fields have precedence over the user
                                specified sort order (default)
--video-multistreams            Allow multiple video streams to be merged
                                into a single file
--no-video-multistreams         Only one video stream is downloaded for each
                                output file (default)
--audio-multistreams            Allow multiple audio streams to be merged
                                into a single file
--no-audio-multistreams         Only one audio stream is downloaded for each
                                output file (default)
--prefer-free-formats           Prefer video formats with free containers
                                over non-free ones of same quality. Use with
                                &quot;-S ext&quot; to strictly prefer free containers
                                irrespective of quality
--no-prefer-free-formats        Don't give any special preference to free
                                containers (default)
--check-formats                 Make sure formats are selected only from
                                those that are actually downloadable
--check-all-formats             Check all formats for whether they are
                                actually downloadable
--no-check-formats              Do not check that the formats are actually
                                downloadable
-F, --list-formats              List available formats of each video.
                                Simulate unless --no-simulate is used
--merge-output-format FORMAT    Containers that may be used when merging
                                formats, separated by &quot;/&quot;, e.g. &quot;mp4/mkv&quot;.
                                Ignored if no merge is required. (currently
                                supported: avi, flv, mkv, mov, mp4, webm)"><pre><code>-f, --format FORMAT             Video format code, see "FORMAT SELECTION"
                                for more details
-S, --format-sort SORTORDER     Sort the formats by the fields given, see
                                "Sorting Formats" for more details
--format-sort-force             Force user specified sort order to have
                                precedence over all fields, see "Sorting
                                Formats" for more details (Alias: --S-force)
--no-format-sort-force          Some fields have precedence over the user
                                specified sort order (default)
--video-multistreams            Allow multiple video streams to be merged
                                into a single file
--no-video-multistreams         Only one video stream is downloaded for each
                                output file (default)
--audio-multistreams            Allow multiple audio streams to be merged
                                into a single file
--no-audio-multistreams         Only one audio stream is downloaded for each
                                output file (default)
--prefer-free-formats           Prefer video formats with free containers
                                over non-free ones of same quality. Use with
                                "-S ext" to strictly prefer free containers
                                irrespective of quality
--no-prefer-free-formats        Don't give any special preference to free
                                containers (default)
--check-formats                 Make sure formats are selected only from
                                those that are actually downloadable
--check-all-formats             Check all formats for whether they are
                                actually downloadable
--no-check-formats              Do not check that the formats are actually
                                downloadable
-F, --list-formats              List available formats of each video.
                                Simulate unless --no-simulate is used
--merge-output-format FORMAT    Containers that may be used when merging
                                formats, separated by "/", e.g. "mp4/mkv".
                                Ignored if no merge is required. (currently
                                supported: avi, flv, mkv, mov, mp4, webm)
</code></pre></div>
<h2 tabindex="-1" dir="auto">Subtitle Options:</h2>
<div data-snippet-clipboard-copy-content="--write-subs                    Write subtitle file
--no-write-subs                 Do not write subtitle file (default)
--write-auto-subs               Write automatically generated subtitle file
                                (Alias: --write-automatic-subs)
--no-write-auto-subs            Do not write auto-generated subtitles
                                (default) (Alias: --no-write-automatic-subs)
--list-subs                     List available subtitles of each video.
                                Simulate unless --no-simulate is used
--sub-format FORMAT             Subtitle format; accepts formats preference,
                                e.g. &quot;srt&quot; or &quot;ass/srt/best&quot;
--sub-langs LANGS               Languages of the subtitles to download (can
                                be regex) or &quot;all&quot; separated by commas, e.g.
                                --sub-langs &quot;en.*,ja&quot;. You can prefix the
                                language code with a &quot;-&quot; to exclude it from
                                the requested languages, e.g. --sub-langs
                                all,-live_chat. Use --list-subs for a list
                                of available language tags"><pre><code>--write-subs                    Write subtitle file
--no-write-subs                 Do not write subtitle file (default)
--write-auto-subs               Write automatically generated subtitle file
                                (Alias: --write-automatic-subs)
--no-write-auto-subs            Do not write auto-generated subtitles
                                (default) (Alias: --no-write-automatic-subs)
--list-subs                     List available subtitles of each video.
                                Simulate unless --no-simulate is used
--sub-format FORMAT             Subtitle format; accepts formats preference,
                                e.g. "srt" or "ass/srt/best"
--sub-langs LANGS               Languages of the subtitles to download (can
                                be regex) or "all" separated by commas, e.g.
                                --sub-langs "en.*,ja". You can prefix the
                                language code with a "-" to exclude it from
                                the requested languages, e.g. --sub-langs
                                all,-live_chat. Use --list-subs for a list
                                of available language tags
</code></pre></div>
<h2 tabindex="-1" dir="auto">Authentication Options:</h2>
<div data-snippet-clipboard-copy-content="-u, --username USERNAME         Login with this account ID
-p, --password PASSWORD         Account password. If this option is left
                                out, yt-dlp will ask interactively
-2, --twofactor TWOFACTOR       Two-factor authentication code
-n, --netrc                     Use .netrc authentication data
--netrc-location PATH           Location of .netrc authentication data;
                                either the path or its containing directory.
                                Defaults to ~/.netrc
--netrc-cmd NETRC_CMD           Command to execute to get the credentials
                                for an extractor.
--video-password PASSWORD       Video password (vimeo, youku)
--ap-mso MSO                    Adobe Pass multiple-system operator (TV
                                provider) identifier, use --ap-list-mso for
                                a list of available MSOs
--ap-username USERNAME          Multiple-system operator account login
--ap-password PASSWORD          Multiple-system operator account password.
                                If this option is left out, yt-dlp will ask
                                interactively
--ap-list-mso                   List all supported multiple-system operators
--client-certificate CERTFILE   Path to client certificate file in PEM
                                format. May include the private key
--client-certificate-key KEYFILE
                                Path to private key file for client
                                certificate
--client-certificate-password PASSWORD
                                Password for client certificate private key,
                                if encrypted. If not provided, and the key
                                is encrypted, yt-dlp will ask interactively"><pre><code>-u, --username USERNAME         Login with this account ID
-p, --password PASSWORD         Account password. If this option is left
                                out, yt-dlp will ask interactively
-2, --twofactor TWOFACTOR       Two-factor authentication code
-n, --netrc                     Use .netrc authentication data
--netrc-location PATH           Location of .netrc authentication data;
                                either the path or its containing directory.
                                Defaults to ~/.netrc
--netrc-cmd NETRC_CMD           Command to execute to get the credentials
                                for an extractor.
--video-password PASSWORD       Video password (vimeo, youku)
--ap-mso MSO                    Adobe Pass multiple-system operator (TV
                                provider) identifier, use --ap-list-mso for
                                a list of available MSOs
--ap-username USERNAME          Multiple-system operator account login
--ap-password PASSWORD          Multiple-system operator account password.
                                If this option is left out, yt-dlp will ask
                                interactively
--ap-list-mso                   List all supported multiple-system operators
--client-certificate CERTFILE   Path to client certificate file in PEM
                                format. May include the private key
--client-certificate-key KEYFILE
                                Path to private key file for client
                                certificate
--client-certificate-password PASSWORD
                                Password for client certificate private key,
                                if encrypted. If not provided, and the key
                                is encrypted, yt-dlp will ask interactively
</code></pre></div>
<h2 tabindex="-1" dir="auto">Post-Processing Options:</h2>
<div data-snippet-clipboard-copy-content="-x, --extract-audio             Convert video files to audio-only files
                                (requires ffmpeg and ffprobe)
--audio-format FORMAT           Format to convert the audio to when -x is
                                used. (currently supported: best (default),
                                aac, alac, flac, m4a, mp3, opus, vorbis,
                                wav). You can specify multiple rules using
                                similar syntax as --remux-video
--audio-quality QUALITY         Specify ffmpeg audio quality to use when
                                converting the audio with -x. Insert a value
                                between 0 (best) and 10 (worst) for VBR or a
                                specific bitrate like 128K (default 5)
--remux-video FORMAT            Remux the video into another container if
                                necessary (currently supported: avi, flv,
                                gif, mkv, mov, mp4, webm, aac, aiff, alac,
                                flac, m4a, mka, mp3, ogg, opus, vorbis,
                                wav). If target container does not support
                                the video/audio codec, remuxing will fail.
                                You can specify multiple rules; e.g.
                                &quot;aac>m4a/mov>mp4/mkv&quot; will remux aac to m4a,
                                mov to mp4 and anything else to mkv
--recode-video FORMAT           Re-encode the video into another format if
                                necessary. The syntax and supported formats
                                are the same as --remux-video
--postprocessor-args NAME:ARGS  Give these arguments to the postprocessors.
                                Specify the postprocessor/executable name
                                and the arguments separated by a colon &quot;:&quot;
                                to give the argument to the specified
                                postprocessor/executable. Supported PP are:
                                Merger, ModifyChapters, SplitChapters,
                                ExtractAudio, VideoRemuxer, VideoConvertor,
                                Metadata, EmbedSubtitle, EmbedThumbnail,
                                SubtitlesConvertor, ThumbnailsConvertor,
                                FixupStretched, FixupM4a, FixupM3u8,
                                FixupTimestamp and FixupDuration. The
                                supported executables are: AtomicParsley,
                                FFmpeg and FFprobe. You can also specify
                                &quot;PP+EXE:ARGS&quot; to give the arguments to the
                                specified executable only when being used by
                                the specified postprocessor. Additionally,
                                for ffmpeg/ffprobe, &quot;_i&quot;/&quot;_o&quot; can be
                                appended to the prefix optionally followed
                                by a number to pass the argument before the
                                specified input/output file, e.g. --ppa
                                &quot;Merger+ffmpeg_i1:-v quiet&quot;. You can use
                                this option multiple times to give different
                                arguments to different postprocessors.
                                (Alias: --ppa)
-k, --keep-video                Keep the intermediate video file on disk
                                after post-processing
--no-keep-video                 Delete the intermediate video file after
                                post-processing (default)
--post-overwrites               Overwrite post-processed files (default)
--no-post-overwrites            Do not overwrite post-processed files
--embed-subs                    Embed subtitles in the video (only for mp4,
                                webm and mkv videos)
--no-embed-subs                 Do not embed subtitles (default)
--embed-thumbnail               Embed thumbnail in the video as cover art
--no-embed-thumbnail            Do not embed thumbnail (default)
--embed-metadata                Embed metadata to the video file. Also
                                embeds chapters/infojson if present unless
                                --no-embed-chapters/--no-embed-info-json are
                                used (Alias: --add-metadata)
--no-embed-metadata             Do not add metadata to file (default)
                                (Alias: --no-add-metadata)
--embed-chapters                Add chapter markers to the video file
                                (Alias: --add-chapters)
--no-embed-chapters             Do not add chapter markers (default) (Alias:
                                --no-add-chapters)
--embed-info-json               Embed the infojson as an attachment to
                                mkv/mka video files
--no-embed-info-json            Do not embed the infojson as an attachment
                                to the video file
--parse-metadata [WHEN:]FROM:TO
                                Parse additional metadata like title/artist
                                from other fields; see &quot;MODIFYING METADATA&quot;
                                for details. Supported values of &quot;WHEN&quot; are
                                the same as that of --use-postprocessor
                                (default: pre_process)
--replace-in-metadata [WHEN:]FIELDS REGEX REPLACE
                                Replace text in a metadata field using the
                                given regex. This option can be used
                                multiple times. Supported values of &quot;WHEN&quot;
                                are the same as that of --use-postprocessor
                                (default: pre_process)
--xattrs                        Write metadata to the video file's xattrs
                                (using dublin core and xdg standards)
--concat-playlist POLICY        Concatenate videos in a playlist. One of
                                &quot;never&quot;, &quot;always&quot;, or &quot;multi_video&quot;
                                (default; only when the videos form a single
                                show). All the video files must have same
                                codecs and number of streams to be
                                concatable. The &quot;pl_video:&quot; prefix can be
                                used with &quot;--paths&quot; and &quot;--output&quot; to set
                                the output filename for the concatenated
                                files. See &quot;OUTPUT TEMPLATE&quot; for details
--fixup POLICY                  Automatically correct known faults of the
                                file. One of never (do nothing), warn (only
                                emit a warning), detect_or_warn (the
                                default; fix file if we can, warn
                                otherwise), force (try fixing even if file
                                already exists)
--ffmpeg-location PATH          Location of the ffmpeg binary; either the
                                path to the binary or its containing directory
--exec [WHEN:]CMD               Execute a command, optionally prefixed with
                                when to execute it, separated by a &quot;:&quot;.
                                Supported values of &quot;WHEN&quot; are the same as
                                that of --use-postprocessor (default:
                                after_move). Same syntax as the output
                                template can be used to pass any field as
                                arguments to the command. If no fields are
                                passed, %(filepath,_filename|)q is appended
                                to the end of the command. This option can
                                be used multiple times
--no-exec                       Remove any previously defined --exec
--convert-subs FORMAT           Convert the subtitles to another format
                                (currently supported: ass, lrc, srt, vtt)
                                (Alias: --convert-subtitles)
--convert-thumbnails FORMAT     Convert the thumbnails to another format
                                (currently supported: jpg, png, webp). You
                                can specify multiple rules using similar
                                syntax as --remux-video
--split-chapters                Split video into multiple files based on
                                internal chapters. The &quot;chapter:&quot; prefix can
                                be used with &quot;--paths&quot; and &quot;--output&quot; to set
                                the output filename for the split files. See
                                &quot;OUTPUT TEMPLATE&quot; for details
--no-split-chapters             Do not split video based on chapters (default)
--remove-chapters REGEX         Remove chapters whose title matches the
                                given regular expression. The syntax is the
                                same as --download-sections. This option can
                                be used multiple times
--no-remove-chapters            Do not remove any chapters from the file
                                (default)
--force-keyframes-at-cuts       Force keyframes at cuts when
                                downloading/splitting/removing sections.
                                This is slow due to needing a re-encode, but
                                the resulting video may have fewer artifacts
                                around the cuts
--no-force-keyframes-at-cuts    Do not force keyframes around the chapters
                                when cutting/splitting (default)
--use-postprocessor NAME[:ARGS]
                                The (case sensitive) name of plugin
                                postprocessors to be enabled, and
                                (optionally) arguments to be passed to it,
                                separated by a colon &quot;:&quot;. ARGS are a
                                semicolon &quot;;&quot; delimited list of NAME=VALUE.
                                The &quot;when&quot; argument determines when the
                                postprocessor is invoked. It can be one of
                                &quot;pre_process&quot; (after video extraction),
                                &quot;after_filter&quot; (after video passes filter),
                                &quot;video&quot; (after --format; before
                                --print/--output), &quot;before_dl&quot; (before each
                                video download), &quot;post_process&quot; (after each
                                video download; default), &quot;after_move&quot;
                                (after moving video file to it's final
                                locations), &quot;after_video&quot; (after downloading
                                and processing all formats of a video), or
                                &quot;playlist&quot; (at end of playlist). This option
                                can be used multiple times to add different
                                postprocessors"><pre><code>-x, --extract-audio             Convert video files to audio-only files
                                (requires ffmpeg and ffprobe)
--audio-format FORMAT           Format to convert the audio to when -x is
                                used. (currently supported: best (default),
                                aac, alac, flac, m4a, mp3, opus, vorbis,
                                wav). You can specify multiple rules using
                                similar syntax as --remux-video
--audio-quality QUALITY         Specify ffmpeg audio quality to use when
                                converting the audio with -x. Insert a value
                                between 0 (best) and 10 (worst) for VBR or a
                                specific bitrate like 128K (default 5)
--remux-video FORMAT            Remux the video into another container if
                                necessary (currently supported: avi, flv,
                                gif, mkv, mov, mp4, webm, aac, aiff, alac,
                                flac, m4a, mka, mp3, ogg, opus, vorbis,
                                wav). If target container does not support
                                the video/audio codec, remuxing will fail.
                                You can specify multiple rules; e.g.
                                "aac&gt;m4a/mov&gt;mp4/mkv" will remux aac to m4a,
                                mov to mp4 and anything else to mkv
--recode-video FORMAT           Re-encode the video into another format if
                                necessary. The syntax and supported formats
                                are the same as --remux-video
--postprocessor-args NAME:ARGS  Give these arguments to the postprocessors.
                                Specify the postprocessor/executable name
                                and the arguments separated by a colon ":"
                                to give the argument to the specified
                                postprocessor/executable. Supported PP are:
                                Merger, ModifyChapters, SplitChapters,
                                ExtractAudio, VideoRemuxer, VideoConvertor,
                                Metadata, EmbedSubtitle, EmbedThumbnail,
                                SubtitlesConvertor, ThumbnailsConvertor,
                                FixupStretched, FixupM4a, FixupM3u8,
                                FixupTimestamp and FixupDuration. The
                                supported executables are: AtomicParsley,
                                FFmpeg and FFprobe. You can also specify
                                "PP+EXE:ARGS" to give the arguments to the
                                specified executable only when being used by
                                the specified postprocessor. Additionally,
                                for ffmpeg/ffprobe, "_i"/"_o" can be
                                appended to the prefix optionally followed
                                by a number to pass the argument before the
                                specified input/output file, e.g. --ppa
                                "Merger+ffmpeg_i1:-v quiet". You can use
                                this option multiple times to give different
                                arguments to different postprocessors.
                                (Alias: --ppa)
-k, --keep-video                Keep the intermediate video file on disk
                                after post-processing
--no-keep-video                 Delete the intermediate video file after
                                post-processing (default)
--post-overwrites               Overwrite post-processed files (default)
--no-post-overwrites            Do not overwrite post-processed files
--embed-subs                    Embed subtitles in the video (only for mp4,
                                webm and mkv videos)
--no-embed-subs                 Do not embed subtitles (default)
--embed-thumbnail               Embed thumbnail in the video as cover art
--no-embed-thumbnail            Do not embed thumbnail (default)
--embed-metadata                Embed metadata to the video file. Also
                                embeds chapters/infojson if present unless
                                --no-embed-chapters/--no-embed-info-json are
                                used (Alias: --add-metadata)
--no-embed-metadata             Do not add metadata to file (default)
                                (Alias: --no-add-metadata)
--embed-chapters                Add chapter markers to the video file
                                (Alias: --add-chapters)
--no-embed-chapters             Do not add chapter markers (default) (Alias:
                                --no-add-chapters)
--embed-info-json               Embed the infojson as an attachment to
                                mkv/mka video files
--no-embed-info-json            Do not embed the infojson as an attachment
                                to the video file
--parse-metadata [WHEN:]FROM:TO
                                Parse additional metadata like title/artist
                                from other fields; see "MODIFYING METADATA"
                                for details. Supported values of "WHEN" are
                                the same as that of --use-postprocessor
                                (default: pre_process)
--replace-in-metadata [WHEN:]FIELDS REGEX REPLACE
                                Replace text in a metadata field using the
                                given regex. This option can be used
                                multiple times. Supported values of "WHEN"
                                are the same as that of --use-postprocessor
                                (default: pre_process)
--xattrs                        Write metadata to the video file's xattrs
                                (using dublin core and xdg standards)
--concat-playlist POLICY        Concatenate videos in a playlist. One of
                                "never", "always", or "multi_video"
                                (default; only when the videos form a single
                                show). All the video files must have same
                                codecs and number of streams to be
                                concatable. The "pl_video:" prefix can be
                                used with "--paths" and "--output" to set
                                the output filename for the concatenated
                                files. See "OUTPUT TEMPLATE" for details
--fixup POLICY                  Automatically correct known faults of the
                                file. One of never (do nothing), warn (only
                                emit a warning), detect_or_warn (the
                                default; fix file if we can, warn
                                otherwise), force (try fixing even if file
                                already exists)
--ffmpeg-location PATH          Location of the ffmpeg binary; either the
                                path to the binary or its containing directory
--exec [WHEN:]CMD               Execute a command, optionally prefixed with
                                when to execute it, separated by a ":".
                                Supported values of "WHEN" are the same as
                                that of --use-postprocessor (default:
                                after_move). Same syntax as the output
                                template can be used to pass any field as
                                arguments to the command. If no fields are
                                passed, %(filepath,_filename|)q is appended
                                to the end of the command. This option can
                                be used multiple times
--no-exec                       Remove any previously defined --exec
--convert-subs FORMAT           Convert the subtitles to another format
                                (currently supported: ass, lrc, srt, vtt)
                                (Alias: --convert-subtitles)
--convert-thumbnails FORMAT     Convert the thumbnails to another format
                                (currently supported: jpg, png, webp). You
                                can specify multiple rules using similar
                                syntax as --remux-video
--split-chapters                Split video into multiple files based on
                                internal chapters. The "chapter:" prefix can
                                be used with "--paths" and "--output" to set
                                the output filename for the split files. See
                                "OUTPUT TEMPLATE" for details
--no-split-chapters             Do not split video based on chapters (default)
--remove-chapters REGEX         Remove chapters whose title matches the
                                given regular expression. The syntax is the
                                same as --download-sections. This option can
                                be used multiple times
--no-remove-chapters            Do not remove any chapters from the file
                                (default)
--force-keyframes-at-cuts       Force keyframes at cuts when
                                downloading/splitting/removing sections.
                                This is slow due to needing a re-encode, but
                                the resulting video may have fewer artifacts
                                around the cuts
--no-force-keyframes-at-cuts    Do not force keyframes around the chapters
                                when cutting/splitting (default)
--use-postprocessor NAME[:ARGS]
                                The (case sensitive) name of plugin
                                postprocessors to be enabled, and
                                (optionally) arguments to be passed to it,
                                separated by a colon ":". ARGS are a
                                semicolon ";" delimited list of NAME=VALUE.
                                The "when" argument determines when the
                                postprocessor is invoked. It can be one of
                                "pre_process" (after video extraction),
                                "after_filter" (after video passes filter),
                                "video" (after --format; before
                                --print/--output), "before_dl" (before each
                                video download), "post_process" (after each
                                video download; default), "after_move"
                                (after moving video file to it's final
                                locations), "after_video" (after downloading
                                and processing all formats of a video), or
                                "playlist" (at end of playlist). This option
                                can be used multiple times to add different
                                postprocessors
</code></pre></div>
<h2 tabindex="-1" dir="auto">SponsorBlock Options:</h2>
<p dir="auto">Make chapter entries for, or remove various segments (sponsor,
introductions, etc.) from downloaded YouTube videos using the
<a href="https://sponsor.ajay.app/" rel="nofollow">SponsorBlock API</a></p>
<div data-snippet-clipboard-copy-content="--sponsorblock-mark CATS        SponsorBlock categories to create chapters
                                for, separated by commas. Available
                                categories are sponsor, intro, outro,
                                selfpromo, preview, filler, interaction,
                                music_offtopic, poi_highlight, chapter, all
                                and default (=all). You can prefix the
                                category with a &quot;-&quot; to exclude it. See [1]
                                for description of the categories. E.g.
                                --sponsorblock-mark all,-preview
                                [1] https://wiki.sponsor.ajay.app/w/Segment_Categories
--sponsorblock-remove CATS      SponsorBlock categories to be removed from
                                the video file, separated by commas. If a
                                category is present in both mark and remove,
                                remove takes precedence. The syntax and
                                available categories are the same as for
                                --sponsorblock-mark except that &quot;default&quot;
                                refers to &quot;all,-filler&quot; and poi_highlight,
                                chapter are not available
--sponsorblock-chapter-title TEMPLATE
                                An output template for the title of the
                                SponsorBlock chapters created by
                                --sponsorblock-mark. The only available
                                fields are start_time, end_time, category,
                                categories, name, category_names. Defaults
                                to &quot;[SponsorBlock]: %(category_names)l&quot;
--no-sponsorblock               Disable both --sponsorblock-mark and
                                --sponsorblock-remove
--sponsorblock-api URL          SponsorBlock API location, defaults to
                                https://sponsor.ajay.app"><pre><code>--sponsorblock-mark CATS        SponsorBlock categories to create chapters
                                for, separated by commas. Available
                                categories are sponsor, intro, outro,
                                selfpromo, preview, filler, interaction,
                                music_offtopic, poi_highlight, chapter, all
                                and default (=all). You can prefix the
                                category with a "-" to exclude it. See [1]
                                for description of the categories. E.g.
                                --sponsorblock-mark all,-preview
                                [1] https://wiki.sponsor.ajay.app/w/Segment_Categories
--sponsorblock-remove CATS      SponsorBlock categories to be removed from
                                the video file, separated by commas. If a
                                category is present in both mark and remove,
                                remove takes precedence. The syntax and
                                available categories are the same as for
                                --sponsorblock-mark except that "default"
                                refers to "all,-filler" and poi_highlight,
                                chapter are not available
--sponsorblock-chapter-title TEMPLATE
                                An output template for the title of the
                                SponsorBlock chapters created by
                                --sponsorblock-mark. The only available
                                fields are start_time, end_time, category,
                                categories, name, category_names. Defaults
                                to "[SponsorBlock]: %(category_names)l"
--no-sponsorblock               Disable both --sponsorblock-mark and
                                --sponsorblock-remove
--sponsorblock-api URL          SponsorBlock API location, defaults to
                                https://sponsor.ajay.app
</code></pre></div>
<h2 tabindex="-1" dir="auto">Extractor Options:</h2>
<div data-snippet-clipboard-copy-content="--extractor-retries RETRIES     Number of retries for known extractor errors
                                (default is 3), or &quot;infinite&quot;
--allow-dynamic-mpd             Process dynamic DASH manifests (default)
                                (Alias: --no-ignore-dynamic-mpd)
--ignore-dynamic-mpd            Do not process dynamic DASH manifests
                                (Alias: --no-allow-dynamic-mpd)
--hls-split-discontinuity       Split HLS playlists to different formats at
                                discontinuities such as ad breaks
--no-hls-split-discontinuity    Do not split HLS playlists to different
                                formats at discontinuities such as ad breaks
                                (default)
--extractor-args IE_KEY:ARGS    Pass ARGS arguments to the IE_KEY extractor.
                                See &quot;EXTRACTOR ARGUMENTS&quot; for details. You
                                can use this option multiple times to give
                                arguments for different extractors"><pre><code>--extractor-retries RETRIES     Number of retries for known extractor errors
                                (default is 3), or "infinite"
--allow-dynamic-mpd             Process dynamic DASH manifests (default)
                                (Alias: --no-ignore-dynamic-mpd)
--ignore-dynamic-mpd            Do not process dynamic DASH manifests
                                (Alias: --no-allow-dynamic-mpd)
--hls-split-discontinuity       Split HLS playlists to different formats at
                                discontinuities such as ad breaks
--no-hls-split-discontinuity    Do not split HLS playlists to different
                                formats at discontinuities such as ad breaks
                                (default)
--extractor-args IE_KEY:ARGS    Pass ARGS arguments to the IE_KEY extractor.
                                See "EXTRACTOR ARGUMENTS" for details. You
                                can use this option multiple times to give
                                arguments for different extractors
</code></pre></div>
<h2 tabindex="-1" dir="auto">CONFIGURATION</h2>
<p dir="auto">You can configure yt-dlp by placing any supported command line option to a configuration file. The configuration is loaded from the following locations:</p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Main Configuration</strong>:</p>
<ul dir="auto">
<li>The file given by <code>--config-location</code></li>
</ul>
</li>
<li>
<p dir="auto"><strong>Portable Configuration</strong>: (Recommended for portable installations)</p>
<ul dir="auto">
<li>If using a binary, <code>yt-dlp.conf</code> in the same directory as the binary</li>
<li>If running from source-code, <code>yt-dlp.conf</code> in the parent directory of <code>yt_dlp</code></li>
</ul>
</li>
<li>
<p dir="auto"><strong>Home Configuration</strong>:</p>
<ul dir="auto">
<li><code>yt-dlp.conf</code> in the home path given by <code>-P</code></li>
<li>If <code>-P</code> is not given, the current directory is searched</li>
</ul>
</li>
<li>
<p dir="auto"><strong>User Configuration</strong>:</p>
<ul dir="auto">
<li><code>${XDG_CONFIG_HOME}/yt-dlp.conf</code></li>
<li><code>${XDG_CONFIG_HOME}/yt-dlp/config</code> (recommended on Linux/macOS)</li>
<li><code>${XDG_CONFIG_HOME}/yt-dlp/config.txt</code></li>
<li><code>${APPDATA}/yt-dlp.conf</code></li>
<li><code>${APPDATA}/yt-dlp/config</code> (recommended on Windows)</li>
<li><code>${APPDATA}/yt-dlp/config.txt</code></li>
<li><code>~/yt-dlp.conf</code></li>
<li><code>~/yt-dlp.conf.txt</code></li>
<li><code>~/.yt-dlp/config</code></li>
<li><code>~/.yt-dlp/config.txt</code></li>
</ul>
<p dir="auto">See also: <a href="#notes-about-environment-variables">Notes about environment variables</a></p>
</li>
<li>
<p dir="auto"><strong>System Configuration</strong>:</p>
<ul dir="auto">
<li><code>/etc/yt-dlp.conf</code></li>
<li><code>/etc/yt-dlp/config</code></li>
<li><code>/etc/yt-dlp/config.txt</code></li>
</ul>
</li>
</ol>
<p dir="auto">E.g. with the following configuration file yt-dlp will always extract the audio, not copy the mtime, use a proxy and save all videos under <code>YouTube</code> directory in your home directory:</p>
<div data-snippet-clipboard-copy-content="# Lines starting with # are comments

# Always extract audio
-x

# Do not copy the mtime
--no-mtime

# Use this proxy
--proxy 127.0.0.1:3128

# Save all videos under YouTube directory in your home directory
-o ~/YouTube/%(title)s.%(ext)s"><pre><code># Lines starting with # are comments

# Always extract audio
-x

# Do not copy the mtime
--no-mtime

# Use this proxy
--proxy 127.0.0.1:3128

# Save all videos under YouTube directory in your home directory
-o ~/YouTube/%(title)s.%(ext)s
</code></pre></div>
<p dir="auto"><strong>Note</strong>: Options in configuration file are just the same options aka switches used in regular command line calls; thus there <strong>must be no whitespace</strong> after <code>-</code> or <code>--</code>, e.g. <code>-o</code> or <code>--proxy</code> but not <code>- o</code> or <code>-- proxy</code>. They must also be quoted when necessary as-if it were a UNIX shell.</p>
<p dir="auto">You can use <code>--ignore-config</code> if you want to disable all configuration files for a particular yt-dlp run. If <code>--ignore-config</code> is found inside any configuration file, no further configuration will be loaded. For example, having the option in the portable configuration file prevents loading of home, user, and system configurations. Additionally, (for backward compatibility) if <code>--ignore-config</code> is found inside the system configuration file, the user configuration is not loaded.</p>
<h3 tabindex="-1" dir="auto">Configuration file encoding</h3>
<p dir="auto">The configuration files are decoded according to the UTF BOM if present, and in the encoding from system locale otherwise.</p>
<p dir="auto">If you want your file to be decoded differently, add <code># coding: ENCODING</code> to the beginning of the file (e.g. <code># coding: shift-jis</code>). There must be no characters before that, even spaces or BOM.</p>
<h3 tabindex="-1" dir="auto">Authentication with netrc</h3>
<p dir="auto">You may also want to configure automatic credentials storage for extractors that support authentication (by providing login and password with <code>--username</code> and <code>--password</code>) in order not to pass credentials as command line arguments on every yt-dlp execution and prevent tracking plain text passwords in the shell command history. You can achieve this using a <a href="https://stackoverflow.com/tags/.netrc/info" rel="nofollow"><code>.netrc</code> file</a> on a per-extractor basis. For that you will need to create a <code>.netrc</code> file in <code>--netrc-location</code> and restrict permissions to read/write by only you:</p>
<div data-snippet-clipboard-copy-content="touch ${HOME}/.netrc
chmod a-rwx,u+rw ${HOME}/.netrc"><pre><code>touch ${HOME}/.netrc
chmod a-rwx,u+rw ${HOME}/.netrc
</code></pre></div>
<p dir="auto">After that you can add credentials for an extractor in the following format, where <em>extractor</em> is the name of the extractor in lowercase:</p>
<div data-snippet-clipboard-copy-content="machine <extractor> login <username> password <password>"><pre><code>machine &lt;extractor&gt; login &lt;username&gt; password &lt;password&gt;
</code></pre></div>
<p dir="auto">E.g.</p>
<div data-snippet-clipboard-copy-content="machine youtube login myaccount@gmail.com password my_youtube_password
machine twitch login my_twitch_account_name password my_twitch_password"><pre><code>machine youtube login myaccount@gmail.com password my_youtube_password
machine twitch login my_twitch_account_name password my_twitch_password
</code></pre></div>
<p dir="auto">To activate authentication with the <code>.netrc</code> file you should pass <code>--netrc</code> to yt-dlp or place it in the <a href="#configuration">configuration file</a>.</p>
<p dir="auto">The default location of the .netrc file is <code>~</code> (see below).</p>
<p dir="auto">As an alternative to using the <code>.netrc</code> file, which has the disadvantage of keeping your passwords in a plain text file, you can configure a custom shell command to provide the credentials for an extractor. This is done by providing the <code>--netrc-cmd</code> parameter, it shall output the credentials in the netrc format and return <code>0</code> on success, other values will be treated as an error. <code>{}</code> in the command will be replaced by the name of the extractor to make it possible to select the credentials for the right extractor.</p>
<p dir="auto">E.g. To use an encrypted <code>.netrc</code> file stored as <code>.authinfo.gpg</code></p>
<div data-snippet-clipboard-copy-content="yt-dlp --netrc-cmd 'gpg --decrypt ~/.authinfo.gpg' https://www.youtube.com/watch?v=BaW_jenozKc"><pre><code>yt-dlp --netrc-cmd 'gpg --decrypt ~/.authinfo.gpg' https://www.youtube.com/watch?v=BaW_jenozKc
</code></pre></div>
<h3 tabindex="-1" dir="auto">Notes about environment variables</h3>
<ul dir="auto">
<li>Environment variables are normally specified as <code>${VARIABLE}</code>/<code>$VARIABLE</code> on UNIX and <code>%VARIABLE%</code> on Windows; but is always shown as <code>${VARIABLE}</code> in this documentation</li>
<li>yt-dlp also allow using UNIX-style variables on Windows for path-like options; e.g. <code>--output</code>, <code>--config-location</code></li>
<li>If unset, <code>${XDG_CONFIG_HOME}</code> defaults to <code>~/.config</code> and <code>${XDG_CACHE_HOME}</code> to <code>~/.cache</code></li>
<li>On Windows, <code>~</code> points to <code>${HOME}</code> if present; or, <code>${USERPROFILE}</code> or <code>${HOMEDRIVE}${HOMEPATH}</code> otherwise</li>
<li>On Windows, <code>${USERPROFILE}</code> generally points to <code>C:\Users\&lt;user name&gt;</code> and <code>${APPDATA}</code> to <code>${USERPROFILE}\AppData\Roaming</code></li>
</ul>
<h2 tabindex="-1" dir="auto">OUTPUT TEMPLATE</h2>
<p dir="auto">The <code>-o</code> option is used to indicate a template for the output file names while <code>-P</code> option is used to specify the path each type of file should be saved to.</p>

<p dir="auto"><strong>tl;dr:</strong> <a href="#output-template-examples">navigate me to examples</a>.</p>

<p dir="auto">The simplest usage of <code>-o</code> is not to set any template arguments when downloading a single file, like in <code>yt-dlp -o funny_video.flv "https://some/video"</code> (hard-coding file extension like this is <em>not</em> recommended and could break some post-processing).</p>
<p dir="auto">It may however also contain special sequences that will be replaced when downloading each video. The special sequences may be formatted according to <a href="https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting" rel="nofollow">Python string formatting operations</a>, e.g. <code>%(NAME)s</code> or <code>%(NAME)05d</code>. To clarify, that is a percent symbol followed by a name in parentheses, followed by formatting operations.</p>
<p dir="auto">The field names themselves (the part inside the parenthesis) can also have some special formatting:</p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Object traversal</strong>: The dictionaries and lists available in metadata can be traversed by using a dot <code>.</code> separator; e.g. <code>%(tags.0)s</code>, <code>%(subtitles.en.-1.ext)s</code>. You can do Python slicing with colon <code>:</code>; E.g. <code>%(id.3:7:-1)s</code>, <code>%(formats.:.format_id)s</code>. Curly braces <code>{}</code> can be used to build dictionaries with only specific keys; e.g. <code>%(formats.:.{format_id,height})#j</code>. An empty field name <code>%()s</code> refers to the entire infodict; e.g. <code>%(.{id,title})s</code>. Note that all the fields that become available using this method are not listed below. Use <code>-j</code> to see such fields</p>
</li>
<li>
<p dir="auto"><strong>Addition</strong>: Addition and subtraction of numeric fields can be done using <code>+</code> and <code>-</code> respectively. E.g. <code>%(playlist_index+10)03d</code>, <code>%(n_entries+1-playlist_index)d</code></p>
</li>
<li>
<p dir="auto"><strong>Date/time Formatting</strong>: Date/time fields can be formatted according to <a href="https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes" rel="nofollow">strftime formatting</a> by specifying it separated from the field name using a <code>&gt;</code>. E.g. <code>%(duration&gt;%H-%M-%S)s</code>, <code>%(upload_date&gt;%Y-%m-%d)s</code>, <code>%(epoch-3600&gt;%H-%M-%S)s</code></p>
</li>
<li>
<p dir="auto"><strong>Alternatives</strong>: Alternate fields can be specified separated with a <code>,</code>. E.g. <code>%(release_date&gt;%Y,upload_date&gt;%Y|Unknown)s</code></p>
</li>
<li>
<p dir="auto"><strong>Replacement</strong>: A replacement value can be specified using a <code>&amp;</code> separator according to the <a href="https://docs.python.org/3/library/string.html#format-specification-mini-language" rel="nofollow"><code>str.format</code> mini-language</a>. If the field is <em>not</em> empty, this replacement value will be used instead of the actual field content. This is done after alternate fields are considered; thus the replacement is used if <em>any</em> of the alternative fields is <em>not</em> empty. E.g. <code>%(chapters&amp;has chapters|no chapters)s</code>, <code>%(title&amp;TITLE={:&gt;20}|NO TITLE)s</code></p>
</li>
<li>
<p dir="auto"><strong>Default</strong>: A literal default value can be specified for when the field is empty using a <code>|</code> separator. This overrides <code>--output-na-placeholder</code>. E.g. <code>%(uploader|Unknown)s</code></p>
</li>
<li>
<p dir="auto"><strong>More Conversions</strong>: In addition to the normal format types <code>diouxXeEfFgGcrs</code>, yt-dlp additionally supports converting to <code>B</code> = <strong>B</strong>ytes, <code>j</code> = <strong>j</strong>son (flag <code>#</code> for pretty-printing, <code>+</code> for Unicode), <code>h</code> = HTML escaping, <code>l</code> = a comma separated <strong>l</strong>ist (flag <code>#</code> for <code>\n</code> newline-separated), <code>q</code> = a string <strong>q</strong>uoted for the terminal (flag <code>#</code> to split a list into different arguments), <code>D</code> = add <strong>D</strong>ecimal suffixes (e.g. 10M) (flag <code>#</code> to use 1024 as factor), and <code>S</code> = <strong>S</strong>anitize as filename (flag <code>#</code> for restricted)</p>
</li>
<li>
<p dir="auto"><strong>Unicode normalization</strong>: The format type <code>U</code> can be used for NFC <a href="https://docs.python.org/3/library/unicodedata.html#unicodedata.normalize" rel="nofollow">Unicode normalization</a>. The alternate form flag (<code>#</code>) changes the normalization to NFD and the conversion flag <code>+</code> can be used for NFKC/NFKD compatibility equivalence normalization. E.g. <code>%(title)+.100U</code> is NFKC</p>
</li>
</ol>
<p dir="auto">To summarize, the general syntax for a field is:</p>
<div data-snippet-clipboard-copy-content="%(name[.keys][addition][>strf][,alternate][&amp;replacement][|default])[flags][width][.precision][length]type"><pre><code>%(name[.keys][addition][&gt;strf][,alternate][&amp;replacement][|default])[flags][width][.precision][length]type
</code></pre></div>
<p dir="auto">Additionally, you can set different output templates for the various metadata files separately from the general output template by specifying the type of file followed by the template separated by a colon <code>:</code>. The different file types supported are <code>subtitle</code>, <code>thumbnail</code>, <code>description</code>, <code>annotation</code> (deprecated), <code>infojson</code>, <code>link</code>, <code>pl_thumbnail</code>, <code>pl_description</code>, <code>pl_infojson</code>, <code>chapter</code>, <code>pl_video</code>. E.g. <code>-o "%(title)s.%(ext)s" -o "thumbnail:%(title)s\%(title)s.%(ext)s"</code>  will put the thumbnails in a folder with the same name as the video. If any of the templates is empty, that type of file will not be written. E.g. <code>--write-thumbnail -o "thumbnail:"</code> will write thumbnails only for playlists and not for video.</p>
<a id="user-content-outtmpl-postprocess-note">
<p dir="auto"><strong>Note</strong>: Due to post-processing (i.e. merging etc.), the actual output filename might differ. Use <code>--print after_move:filepath</code> to get the name after all post-processing is complete.</p>
<p dir="auto">The available fields are:</p>
<ul dir="auto">
<li><code>id</code> (string): Video identifier</li>
<li><code>title</code> (string): Video title</li>
<li><code>fulltitle</code> (string): Video title ignoring live timestamp and generic title</li>
<li><code>ext</code> (string): Video filename extension</li>
<li><code>alt_title</code> (string): A secondary title of the video</li>
<li><code>description</code> (string): The description of the video</li>
<li><code>display_id</code> (string): An alternative identifier for the video</li>
<li><code>uploader</code> (string): Full name of the video uploader</li>
<li><code>license</code> (string): License name the video is licensed under</li>
<li><code>creator</code> (string): The creator of the video</li>
<li><code>timestamp</code> (numeric): UNIX timestamp of the moment the video became available</li>
<li><code>upload_date</code> (string): Video upload date in UTC (YYYYMMDD)</li>
<li><code>release_timestamp</code> (numeric): UNIX timestamp of the moment the video was released</li>
<li><code>release_date</code> (string): The date (YYYYMMDD) when the video was released in UTC</li>
<li><code>modified_timestamp</code> (numeric): UNIX timestamp of the moment the video was last modified</li>
<li><code>modified_date</code> (string): The date (YYYYMMDD) when the video was last modified in UTC</li>
<li><code>uploader_id</code> (string): Nickname or id of the video uploader</li>
<li><code>channel</code> (string): Full name of the channel the video is uploaded on</li>
<li><code>channel_id</code> (string): Id of the channel</li>
<li><code>channel_follower_count</code> (numeric): Number of followers of the channel</li>
<li><code>channel_is_verified</code> (boolean): Whether the channel is verified on the platform</li>
<li><code>location</code> (string): Physical location where the video was filmed</li>
<li><code>duration</code> (numeric): Length of the video in seconds</li>
<li><code>duration_string</code> (string): Length of the video (HH:mm:ss)</li>
<li><code>view_count</code> (numeric): How many users have watched the video on the platform</li>
<li><code>concurrent_view_count</code> (numeric): How many users are currently watching the video on the platform.</li>
<li><code>like_count</code> (numeric): Number of positive ratings of the video</li>
<li><code>dislike_count</code> (numeric): Number of negative ratings of the video</li>
<li><code>repost_count</code> (numeric): Number of reposts of the video</li>
<li><code>average_rating</code> (numeric): Average rating give by users, the scale used depends on the webpage</li>
<li><code>comment_count</code> (numeric): Number of comments on the video (For some extractors, comments are only downloaded at the end, and so this field cannot be used)</li>
<li><code>age_limit</code> (numeric): Age restriction for the video (years)</li>
<li><code>live_status</code> (string): One of "not_live", "is_live", "is_upcoming", "was_live", "post_live" (was live, but VOD is not yet processed)</li>
<li><code>is_live</code> (boolean): Whether this video is a live stream or a fixed-length video</li>
<li><code>was_live</code> (boolean): Whether this video was originally a live stream</li>
<li><code>playable_in_embed</code> (string): Whether this video is allowed to play in embedded players on other sites</li>
<li><code>availability</code> (string): Whether the video is "private", "premium_only", "subscriber_only", "needs_auth", "unlisted" or "public"</li>
<li><code>start_time</code> (numeric): Time in seconds where the reproduction should start, as specified in the URL</li>
<li><code>end_time</code> (numeric): Time in seconds where the reproduction should end, as specified in the URL</li>
<li><code>extractor</code> (string): Name of the extractor</li>
<li><code>extractor_key</code> (string): Key name of the extractor</li>
<li><code>epoch</code> (numeric): Unix epoch of when the information extraction was completed</li>
<li><code>autonumber</code> (numeric): Number that will be increased with each download, starting at <code>--autonumber-start</code>, padded with leading zeros to 5 digits</li>
<li><code>video_autonumber</code> (numeric): Number that will be increased with each video</li>
<li><code>n_entries</code> (numeric): Total number of extracted items in the playlist</li>
<li><code>playlist_id</code> (string): Identifier of the playlist that contains the video</li>
<li><code>playlist_title</code> (string): Name of the playlist that contains the video</li>
<li><code>playlist</code> (string): <code>playlist_id</code> or <code>playlist_title</code></li>
<li><code>playlist_count</code> (numeric): Total number of items in the playlist. May not be known if entire playlist is not extracted</li>
<li><code>playlist_index</code> (numeric): Index of the video in the playlist padded with leading zeros according the final index</li>
<li><code>playlist_autonumber</code> (numeric): Position of the video in the playlist download queue padded with leading zeros according to the total length of the playlist</li>
<li><code>playlist_uploader</code> (string): Full name of the playlist uploader</li>
<li><code>playlist_uploader_id</code> (string): Nickname or id of the playlist uploader</li>
<li><code>webpage_url</code> (string): A URL to the video webpage which if given to yt-dlp should allow to get the same result again</li>
<li><code>webpage_url_basename</code> (string): The basename of the webpage URL</li>
<li><code>webpage_url_domain</code> (string): The domain of the webpage URL</li>
<li><code>original_url</code> (string): The URL given by the user (or same as <code>webpage_url</code> for playlist entries)</li>
</ul>
</a><p dir="auto">All the fields in <a href="#filtering-formats">Filtering Formats</a> can also be used</p>
<p dir="auto">Available for the video that belongs to some logical chapter or section:</p>
<ul dir="auto">
<li><code>chapter</code> (string): Name or title of the chapter the video belongs to</li>
<li><code>chapter_number</code> (numeric): Number of the chapter the video belongs to</li>
<li><code>chapter_id</code> (string): Id of the chapter the video belongs to</li>
</ul>
<p dir="auto">Available for the video that is an episode of some series or programme:</p>
<ul dir="auto">
<li><code>series</code> (string): Title of the series or programme the video episode belongs to</li>
<li><code>season</code> (string): Title of the season the video episode belongs to</li>
<li><code>season_number</code> (numeric): Number of the season the video episode belongs to</li>
<li><code>season_id</code> (string): Id of the season the video episode belongs to</li>
<li><code>episode</code> (string): Title of the video episode</li>
<li><code>episode_number</code> (numeric): Number of the video episode within a season</li>
<li><code>episode_id</code> (string): Id of the video episode</li>
</ul>
<p dir="auto">Available for the media that is a track or a part of a music album:</p>
<ul dir="auto">
<li><code>track</code> (string): Title of the track</li>
<li><code>track_number</code> (numeric): Number of the track within an album or a disc</li>
<li><code>track_id</code> (string): Id of the track</li>
<li><code>artist</code> (string): Artist(s) of the track</li>
<li><code>genre</code> (string): Genre(s) of the track</li>
<li><code>album</code> (string): Title of the album the track belongs to</li>
<li><code>album_type</code> (string): Type of the album</li>
<li><code>album_artist</code> (string): List of all artists appeared on the album</li>
<li><code>disc_number</code> (numeric): Number of the disc or other physical medium the track belongs to</li>
<li><code>release_year</code> (numeric): Year (YYYY) when the album was released</li>
</ul>
<p dir="auto">Available only when using <code>--download-sections</code> and for <code>chapter:</code> prefix when using <code>--split-chapters</code> for videos with internal chapters:</p>
<ul dir="auto">
<li><code>section_title</code> (string): Title of the chapter</li>
<li><code>section_number</code> (numeric): Number of the chapter within the file</li>
<li><code>section_start</code> (numeric): Start time of the chapter in seconds</li>
<li><code>section_end</code> (numeric): End time of the chapter in seconds</li>
</ul>
<p dir="auto">Available only when used in <code>--print</code>:</p>
<ul dir="auto">
<li><code>urls</code> (string): The URLs of all requested formats, one in each line</li>
<li><code>filename</code> (string): Name of the video file. Note that the <a href="#outtmpl-postprocess-note">actual filename may differ</a></li>
<li><code>formats_table</code> (table): The video format table as printed by <code>--list-formats</code></li>
<li><code>thumbnails_table</code> (table): The thumbnail format table as printed by <code>--list-thumbnails</code></li>
<li><code>subtitles_table</code> (table): The subtitle format table as printed by <code>--list-subs</code></li>
<li><code>automatic_captions_table</code> (table): The automatic subtitle format table as printed by <code>--list-subs</code></li>
</ul>
<p dir="auto">Available only after the video is downloaded (<code>post_process</code>/<code>after_move</code>):</p>
<ul dir="auto">
<li><code>filepath</code>: Actual path of downloaded video file</li>
</ul>
<p dir="auto">Available only in <code>--sponsorblock-chapter-title</code>:</p>
<ul dir="auto">
<li><code>start_time</code> (numeric): Start time of the chapter in seconds</li>
<li><code>end_time</code> (numeric): End time of the chapter in seconds</li>
<li><code>categories</code> (list): The <a href="https://wiki.sponsor.ajay.app/w/Types#Category" rel="nofollow">SponsorBlock categories</a> the chapter belongs to</li>
<li><code>category</code> (string): The smallest SponsorBlock category the chapter belongs to</li>
<li><code>category_names</code> (list): Friendly names of the categories</li>
<li><code>name</code> (string): Friendly name of the smallest category</li>
<li><code>type</code> (string): The <a href="https://wiki.sponsor.ajay.app/w/Types#Action_Type" rel="nofollow">SponsorBlock action type</a> of the chapter</li>
</ul>
<p dir="auto">Each aforementioned sequence when referenced in an output template will be replaced by the actual value corresponding to the sequence name. E.g. for <code>-o %(title)s-%(id)s.%(ext)s</code> and an mp4 video with title <code>yt-dlp test video</code> and id <code>BaW_jenozKc</code>, this will result in a <code>yt-dlp test video-BaW_jenozKc.mp4</code> file created in the current directory.</p>
<p dir="auto"><strong>Note</strong>: Some of the sequences are not guaranteed to be present since they depend on the metadata obtained by a particular extractor. Such sequences will be replaced with placeholder value provided with <code>--output-na-placeholder</code> (<code>NA</code> by default).</p>
<p dir="auto"><strong>Tip</strong>: Look at the <code>-j</code> output to identify which fields are available for the particular URL</p>
<p dir="auto">For numeric sequences you can use <a href="https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting" rel="nofollow">numeric related formatting</a>; e.g. <code>%(view_count)05d</code> will result in a string with view count padded with zeros up to 5 characters, like in <code>00042</code>.</p>
<p dir="auto">Output templates can also contain arbitrary hierarchical path, e.g. <code>-o "%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s"</code> which will result in downloading each video in a directory corresponding to this path template. Any missing directory will be automatically created for you.</p>
<p dir="auto">To use percent literals in an output template use <code>%%</code>. To output to stdout use <code>-o -</code>.</p>
<p dir="auto">The current default template is <code>%(title)s [%(id)s].%(ext)s</code>.</p>
<p dir="auto">In some cases, you don't want special characters such as 中, spaces, or &amp;, such as when transferring the downloaded filename to a Windows system or the filename through an 8bit-unsafe channel. In these cases, add the <code>--restrict-filenames</code> flag to get a shorter title.</p>
<h4 tabindex="-1" dir="auto">Output template examples</h4>
<div dir="auto" data-snippet-clipboard-copy-content="$ yt-dlp --print filename -o &quot;test video.%(ext)s&quot; BaW_jenozKc
test video.webm    # Literal name with correct extension

$ yt-dlp --print filename -o &quot;%(title)s.%(ext)s&quot; BaW_jenozKc
youtube-dl test video ''_ä↭𝕐.webm    # All kinds of weird characters

$ yt-dlp --print filename -o &quot;%(title)s.%(ext)s&quot; BaW_jenozKc --restrict-filenames
youtube-dl_test_video_.webm    # Restricted file name

# Download YouTube playlist videos in separate directory indexed by video order in a playlist
$ yt-dlp -o &quot;%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s&quot; &quot;https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re&quot;

# Download YouTube playlist videos in separate directories according to their uploaded year
$ yt-dlp -o &quot;%(upload_date>%Y)s/%(title)s.%(ext)s&quot; &quot;https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re&quot;

# Prefix playlist index with &quot; - &quot; separator, but only if it is available
$ yt-dlp -o &quot;%(playlist_index&amp;{} - |)s%(title)s.%(ext)s&quot; BaW_jenozKc &quot;https://www.youtube.com/user/TheLinuxFoundation/playlists&quot;

# Download all playlists of YouTube channel/user keeping each playlist in separate directory:
$ yt-dlp -o &quot;%(uploader)s/%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s&quot; &quot;https://www.youtube.com/user/TheLinuxFoundation/playlists&quot;

# Download Udemy course keeping each chapter in separate directory under MyVideos directory in your home
$ yt-dlp -u user -p password -P &quot;~/MyVideos&quot; -o &quot;%(playlist)s/%(chapter_number)s - %(chapter)s/%(title)s.%(ext)s&quot; &quot;https://www.udemy.com/java-tutorial&quot;

# Download entire series season keeping each series and each season in separate directory under C:/MyVideos
$ yt-dlp -P &quot;C:/MyVideos&quot; -o &quot;%(series)s/%(season_number)s - %(season)s/%(episode_number)s - %(episode)s.%(ext)s&quot; &quot;https://videomore.ru/kino_v_detalayah/5_sezon/367617&quot;

# Download video as &quot;C:\MyVideos\uploader\title.ext&quot;, subtitles as &quot;C:\MyVideos\subs\uploader\title.ext&quot;
# and put all temporary files in &quot;C:\MyVideos\tmp&quot;
$ yt-dlp -P &quot;C:/MyVideos&quot; -P &quot;temp:tmp&quot; -P &quot;subtitle:subs&quot; -o &quot;%(uploader)s/%(title)s.%(ext)s&quot; BaW_jenoz --write-subs

# Download video as &quot;C:\MyVideos\uploader\title.ext&quot; and subtitles as &quot;C:\MyVideos\uploader\subs\title.ext&quot;
$ yt-dlp -P &quot;C:/MyVideos&quot; -o &quot;%(uploader)s/%(title)s.%(ext)s&quot; -o &quot;subtitle:%(uploader)s/subs/%(title)s.%(ext)s&quot; BaW_jenozKc --write-subs

# Stream the video being downloaded to stdout
$ yt-dlp -o - BaW_jenozKc"><pre>$ yt-dlp --print filename -o <span><span>"</span>test video.%(ext)s<span>"</span></span> BaW_jenozKc
<span>test</span> video.webm    <span><span>#</span> Literal name with correct extension</span>

$ yt-dlp --print filename -o <span><span>"</span>%(title)s.%(ext)s<span>"</span></span> BaW_jenozKc
youtube-dl <span>test</span> video <span><span>'</span><span>'</span></span>_ä↭𝕐.webm    <span><span>#</span> All kinds of weird characters</span>

$ yt-dlp --print filename -o <span><span>"</span>%(title)s.%(ext)s<span>"</span></span> BaW_jenozKc --restrict-filenames
youtube-dl_test_video_.webm    <span><span>#</span> Restricted file name</span>

<span><span>#</span> Download YouTube playlist videos in separate directory indexed by video order in a playlist</span>
$ yt-dlp -o <span><span>"</span>%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s<span>"</span></span> <span><span>"</span>https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re<span>"</span></span>

<span><span>#</span> Download YouTube playlist videos in separate directories according to their uploaded year</span>
$ yt-dlp -o <span><span>"</span>%(upload_date&gt;%Y)s/%(title)s.%(ext)s<span>"</span></span> <span><span>"</span>https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re<span>"</span></span>

<span><span>#</span> Prefix playlist index with " - " separator, but only if it is available</span>
$ yt-dlp -o <span><span>"</span>%(playlist_index&amp;{} - |)s%(title)s.%(ext)s<span>"</span></span> BaW_jenozKc <span><span>"</span>https://www.youtube.com/user/TheLinuxFoundation/playlists<span>"</span></span>

<span><span>#</span> Download all playlists of YouTube channel/user keeping each playlist in separate directory:</span>
$ yt-dlp -o <span><span>"</span>%(uploader)s/%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s<span>"</span></span> <span><span>"</span>https://www.youtube.com/user/TheLinuxFoundation/playlists<span>"</span></span>

<span><span>#</span> Download Udemy course keeping each chapter in separate directory under MyVideos directory in your home</span>
$ yt-dlp -u user -p password -P <span><span>"</span>~/MyVideos<span>"</span></span> -o <span><span>"</span>%(playlist)s/%(chapter_number)s - %(chapter)s/%(title)s.%(ext)s<span>"</span></span> <span><span>"</span>https://www.udemy.com/java-tutorial<span>"</span></span>

<span><span>#</span> Download entire series season keeping each series and each season in separate directory under C:/MyVideos</span>
$ yt-dlp -P <span><span>"</span>C:/MyVideos<span>"</span></span> -o <span><span>"</span>%(series)s/%(season_number)s - %(season)s/%(episode_number)s - %(episode)s.%(ext)s<span>"</span></span> <span><span>"</span>https://videomore.ru/kino_v_detalayah/5_sezon/367617<span>"</span></span>

<span><span>#</span> Download video as "C:\MyVideos\uploader\title.ext", subtitles as "C:\MyVideos\subs\uploader\title.ext"</span>
<span><span>#</span> and put all temporary files in "C:\MyVideos\tmp"</span>
$ yt-dlp -P <span><span>"</span>C:/MyVideos<span>"</span></span> -P <span><span>"</span>temp:tmp<span>"</span></span> -P <span><span>"</span>subtitle:subs<span>"</span></span> -o <span><span>"</span>%(uploader)s/%(title)s.%(ext)s<span>"</span></span> BaW_jenoz --write-subs

<span><span>#</span> Download video as "C:\MyVideos\uploader\title.ext" and subtitles as "C:\MyVideos\uploader\subs\title.ext"</span>
$ yt-dlp -P <span><span>"</span>C:/MyVideos<span>"</span></span> -o <span><span>"</span>%(uploader)s/%(title)s.%(ext)s<span>"</span></span> -o <span><span>"</span>subtitle:%(uploader)s/subs/%(title)s.%(ext)s<span>"</span></span> BaW_jenozKc --write-subs

<span><span>#</span> Stream the video being downloaded to stdout</span>
$ yt-dlp -o - BaW_jenozKc</pre></div>
<h2 tabindex="-1" dir="auto">FORMAT SELECTION</h2>
<p dir="auto">By default, yt-dlp tries to download the best available quality if you <strong>don't</strong> pass any options.
This is generally equivalent to using <code>-f bestvideo*+bestaudio/best</code>. However, if multiple audiostreams is enabled (<code>--audio-multistreams</code>), the default format changes to <code>-f bestvideo+bestaudio/best</code>. Similarly, if ffmpeg is unavailable, or if you use yt-dlp to stream to <code>stdout</code> (<code>-o -</code>), the default becomes <code>-f best/bestvideo+bestaudio</code>.</p>
<p dir="auto"><strong>Deprecation warning</strong>: Latest versions of yt-dlp can stream multiple formats to the stdout simultaneously using ffmpeg. So, in future versions, the default for this will be set to <code>-f bv*+ba/b</code> similar to normal downloads. If you want to preserve the <code>-f b/bv+ba</code> setting, it is recommended to explicitly specify it in the configuration options.</p>
<p dir="auto">The general syntax for format selection is <code>-f FORMAT</code> (or <code>--format FORMAT</code>) where <code>FORMAT</code> is a <em>selector expression</em>, i.e. an expression that describes format or formats you would like to download.</p>

<p dir="auto"><strong>tl;dr:</strong> <a href="#format-selection-examples">navigate me to examples</a>.</p>

<p dir="auto">The simplest case is requesting a specific format; e.g. with <code>-f 22</code> you can download the format with format code equal to 22. You can get the list of available format codes for particular video using <code>--list-formats</code> or <code>-F</code>. Note that these format codes are extractor specific.</p>
<p dir="auto">You can also use a file extension (currently <code>3gp</code>, <code>aac</code>, <code>flv</code>, <code>m4a</code>, <code>mp3</code>, <code>mp4</code>, <code>ogg</code>, <code>wav</code>, <code>webm</code> are supported) to download the best quality format of a particular file extension served as a single file, e.g. <code>-f webm</code> will download the best quality format with the <code>webm</code> extension served as a single file.</p>
<p dir="auto">You can use <code>-f -</code> to interactively provide the format selector <em>for each video</em></p>
<p dir="auto">You can also use special names to select particular edge case formats:</p>
<ul dir="auto">
<li><code>all</code>: Select <strong>all formats</strong> separately</li>
<li><code>mergeall</code>: Select and <strong>merge all formats</strong> (Must be used with <code>--audio-multistreams</code>, <code>--video-multistreams</code> or both)</li>
<li><code>b*</code>, <code>best*</code>: Select the best quality format that <strong>contains either</strong> a video or an audio or both (ie; <code>vcodec!=none or acodec!=none</code>)</li>
<li><code>b</code>, <code>best</code>: Select the best quality format that <strong>contains both</strong> video and audio. Equivalent to <code>best*[vcodec!=none][acodec!=none]</code></li>
<li><code>bv</code>, <code>bestvideo</code>: Select the best quality <strong>video-only</strong> format. Equivalent to <code>best*[acodec=none]</code></li>
<li><code>bv*</code>, <code>bestvideo*</code>: Select the best quality format that <strong>contains video</strong>. It may also contain audio. Equivalent to <code>best*[vcodec!=none]</code></li>
<li><code>ba</code>, <code>bestaudio</code>: Select the best quality <strong>audio-only</strong> format. Equivalent to <code>best*[vcodec=none]</code></li>
<li><code>ba*</code>, <code>bestaudio*</code>: Select the best quality format that <strong>contains audio</strong>. It may also contain video. Equivalent to <code>best*[acodec!=none]</code> (<a href="https://github.com/yt-dlp/yt-dlp/issues/979#issuecomment-919629354" data-hovercard-type="issue" data-hovercard-url="/yt-dlp/yt-dlp/issues/979/hovercard">Do not use!</a>)</li>
<li><code>w*</code>, <code>worst*</code>: Select the worst quality format that contains either a video or an audio</li>
<li><code>w</code>, <code>worst</code>: Select the worst quality format that contains both video and audio. Equivalent to <code>worst*[vcodec!=none][acodec!=none]</code></li>
<li><code>wv</code>, <code>worstvideo</code>: Select the worst quality video-only format. Equivalent to <code>worst*[acodec=none]</code></li>
<li><code>wv*</code>, <code>worstvideo*</code>: Select the worst quality format that contains video. It may also contain audio. Equivalent to <code>worst*[vcodec!=none]</code></li>
<li><code>wa</code>, <code>worstaudio</code>: Select the worst quality audio-only format. Equivalent to <code>worst*[vcodec=none]</code></li>
<li><code>wa*</code>, <code>worstaudio*</code>: Select the worst quality format that contains audio. It may also contain video. Equivalent to <code>worst*[acodec!=none]</code></li>
</ul>
<p dir="auto">For example, to download the worst quality video-only format you can use <code>-f worstvideo</code>. It is however recommended not to use <code>worst</code> and related options. When your format selector is <code>worst</code>, the format which is worst in all respects is selected. Most of the time, what you actually want is the video with the smallest filesize instead. So it is generally better to use <code>-S +size</code> or more rigorously, <code>-S +size,+br,+res,+fps</code> instead of <code>-f worst</code>. See <a href="#sorting-formats">Sorting Formats</a> for more details.</p>
<p dir="auto">You can select the n'th best format of a type by using <code>best&lt;type&gt;.&lt;n&gt;</code>. For example, <code>best.2</code> will select the 2nd best combined format. Similarly, <code>bv*.3</code> will select the 3rd best format that contains a video stream.</p>
<p dir="auto">If you want to download multiple videos, and they don't have the same formats available, you can specify the order of preference using slashes. Note that formats on the left hand side are preferred; e.g. <code>-f 22/17/18</code> will download format 22 if it's available, otherwise it will download format 17 if it's available, otherwise it will download format 18 if it's available, otherwise it will complain that no suitable formats are available for download.</p>
<p dir="auto">If you want to download several formats of the same video use a comma as a separator, e.g. <code>-f 22,17,18</code> will download all these three formats, of course if they are available. Or a more sophisticated example combined with the precedence feature: <code>-f 136/137/mp4/bestvideo,140/m4a/bestaudio</code>.</p>
<p dir="auto">You can merge the video and audio of multiple formats into a single file using <code>-f &lt;format1&gt;+&lt;format2&gt;+...</code> (requires ffmpeg installed); e.g. <code>-f bestvideo+bestaudio</code> will download the best video-only format, the best audio-only format and mux them together with ffmpeg.</p>
<p dir="auto"><strong>Deprecation warning</strong>: Since the <em>below</em> described behavior is complex and counter-intuitive, this will be removed and multistreams will be enabled by default in the future. A new operator will be instead added to limit formats to single audio/video</p>
<p dir="auto">Unless <code>--video-multistreams</code> is used, all formats with a video stream except the first one are ignored. Similarly, unless <code>--audio-multistreams</code> is used, all formats with an audio stream except the first one are ignored. E.g. <code>-f bestvideo+best+bestaudio --video-multistreams --audio-multistreams</code> will download and merge all 3 given formats. The resulting file will have 2 video streams and 2 audio streams. But <code>-f bestvideo+best+bestaudio --no-video-multistreams</code> will download and merge only <code>bestvideo</code> and <code>bestaudio</code>. <code>best</code> is ignored since another format containing a video stream (<code>bestvideo</code>) has already been selected. The order of the formats is therefore important. <code>-f best+bestaudio --no-audio-multistreams</code> will download only <code>best</code> while <code>-f bestaudio+best --no-audio-multistreams</code> will ignore <code>best</code> and download only <code>bestaudio</code>.</p>
<h2 tabindex="-1" dir="auto">Filtering Formats</h2>
<p dir="auto">You can also filter the video formats by putting a condition in brackets, as in <code>-f "best[height=720]"</code> (or <code>-f "[filesize&gt;10M]"</code> since filters without a selector are interpreted as <code>best</code>).</p>
<p dir="auto">The following numeric meta fields can be used with comparisons <code>&lt;</code>, <code>&lt;=</code>, <code>&gt;</code>, <code>&gt;=</code>, <code>=</code> (equals), <code>!=</code> (not equals):</p>
<ul dir="auto">
<li><code>filesize</code>: The number of bytes, if known in advance</li>
<li><code>filesize_approx</code>: An estimate for the number of bytes</li>
<li><code>width</code>: Width of the video, if known</li>
<li><code>height</code>: Height of the video, if known</li>
<li><code>aspect_ratio</code>: Aspect ratio of the video, if known</li>
<li><code>tbr</code>: Average bitrate of audio and video in KBit/s</li>
<li><code>abr</code>: Average audio bitrate in KBit/s</li>
<li><code>vbr</code>: Average video bitrate in KBit/s</li>
<li><code>asr</code>: Audio sampling rate in Hertz</li>
<li><code>fps</code>: Frame rate</li>
<li><code>audio_channels</code>: The number of audio channels</li>
<li><code>stretched_ratio</code>: <code>width:height</code> of the video's pixels, if not square</li>
</ul>
<p dir="auto">Also filtering work for comparisons <code>=</code> (equals), <code>^=</code> (starts with), <code>$=</code> (ends with), <code>*=</code> (contains), <code>~=</code> (matches regex) and following string meta fields:</p>
<ul dir="auto">
<li><code>url</code>: Video URL</li>
<li><code>ext</code>: File extension</li>
<li><code>acodec</code>: Name of the audio codec in use</li>
<li><code>vcodec</code>: Name of the video codec in use</li>
<li><code>container</code>: Name of the container format</li>
<li><code>protocol</code>: The protocol that will be used for the actual download, lower-case (<code>http</code>, <code>https</code>, <code>rtsp</code>, <code>rtmp</code>, <code>rtmpe</code>, <code>mms</code>, <code>f4m</code>, <code>ism</code>, <code>http_dash_segments</code>, <code>m3u8</code>, or <code>m3u8_native</code>)</li>
<li><code>language</code>: Language code</li>
<li><code>dynamic_range</code>: The dynamic range of the video</li>
<li><code>format_id</code>: A short description of the format</li>
<li><code>format</code>: A human-readable description of the format</li>
<li><code>format_note</code>: Additional info about the format</li>
<li><code>resolution</code>: Textual description of width and height</li>
</ul>
<p dir="auto">Any string comparison may be prefixed with negation <code>!</code> in order to produce an opposite comparison, e.g. <code>!*=</code> (does not contain). The comparand of a string comparison needs to be quoted with either double or single quotes if it contains spaces or special characters other than <code>._-</code>.</p>
<p dir="auto"><strong>Note</strong>: None of the aforementioned meta fields are guaranteed to be present since this solely depends on the metadata obtained by particular extractor, i.e. the metadata offered by the website. Any other field made available by the extractor can also be used for filtering.</p>
<p dir="auto">Formats for which the value is not known are excluded unless you put a question mark (<code>?</code>) after the operator. You can combine format filters, so <code>-f "bv[height&lt;=?720][tbr&gt;500]"</code> selects up to 720p videos (or videos where the height is not known) with a bitrate of at least 500 KBit/s. You can also use the filters with <code>all</code> to download all formats that satisfy the filter, e.g. <code>-f "all[vcodec=none]"</code> selects all audio-only formats.</p>
<p dir="auto">Format selectors can also be grouped using parentheses; e.g. <code>-f "(mp4,webm)[height&lt;480]"</code> will download the best pre-merged mp4 and webm formats with a height lower than 480.</p>
<h2 tabindex="-1" dir="auto">Sorting Formats</h2>
<p dir="auto">You can change the criteria for being considered the <code>best</code> by using <code>-S</code> (<code>--format-sort</code>). The general format for this is <code>--format-sort field1,field2...</code>.</p>
<p dir="auto">The available fields are:</p>
<ul dir="auto">
<li><code>hasvid</code>: Gives priority to formats that have a video stream</li>
<li><code>hasaud</code>: Gives priority to formats that have an audio stream</li>
<li><code>ie_pref</code>: The format preference</li>
<li><code>lang</code>: The language preference</li>
<li><code>quality</code>: The quality of the format</li>
<li><code>source</code>: The preference of the source</li>
<li><code>proto</code>: Protocol used for download (<code>https</code>/<code>ftps</code> &gt; <code>http</code>/<code>ftp</code> &gt; <code>m3u8_native</code>/<code>m3u8</code> &gt; <code>http_dash_segments</code>&gt; <code>websocket_frag</code> &gt; <code>mms</code>/<code>rtsp</code> &gt; <code>f4f</code>/<code>f4m</code>)</li>
<li><code>vcodec</code>: Video Codec (<code>av01</code> &gt; <code>vp9.2</code> &gt; <code>vp9</code> &gt; <code>h265</code> &gt; <code>h264</code> &gt; <code>vp8</code> &gt; <code>h263</code> &gt; <code>theora</code> &gt; other)</li>
<li><code>acodec</code>: Audio Codec (<code>flac</code>/<code>alac</code> &gt; <code>wav</code>/<code>aiff</code> &gt; <code>opus</code> &gt; <code>vorbis</code> &gt; <code>aac</code> &gt; <code>mp4a</code> &gt; <code>mp3</code> &gt; <code>ac4</code> &gt; <code>eac3</code> &gt; <code>ac3</code> &gt; <code>dts</code> &gt; other)</li>
<li><code>codec</code>: Equivalent to <code>vcodec,acodec</code></li>
<li><code>vext</code>: Video Extension (<code>mp4</code> &gt; <code>mov</code> &gt; <code>webm</code> &gt; <code>flv</code> &gt; other). If <code>--prefer-free-formats</code> is used, <code>webm</code> is preferred.</li>
<li><code>aext</code>: Audio Extension (<code>m4a</code> &gt; <code>aac</code> &gt; <code>mp3</code> &gt; <code>ogg</code> &gt; <code>opus</code> &gt; <code>webm</code> &gt; other). If <code>--prefer-free-formats</code> is used, the order changes to <code>ogg</code> &gt; <code>opus</code> &gt; <code>webm</code> &gt; <code>mp3</code> &gt; <code>m4a</code> &gt; <code>aac</code></li>
<li><code>ext</code>: Equivalent to <code>vext,aext</code></li>
<li><code>filesize</code>: Exact filesize, if known in advance</li>
<li><code>fs_approx</code>: Approximate filesize</li>
<li><code>size</code>: Exact filesize if available, otherwise approximate filesize</li>
<li><code>height</code>: Height of video</li>
<li><code>width</code>: Width of video</li>
<li><code>res</code>: Video resolution, calculated as the smallest dimension.</li>
<li><code>fps</code>: Framerate of video</li>
<li><code>hdr</code>: The dynamic range of the video (<code>DV</code> &gt; <code>HDR12</code> &gt; <code>HDR10+</code> &gt; <code>HDR10</code> &gt; <code>HLG</code> &gt; <code>SDR</code>)</li>
<li><code>channels</code>: The number of audio channels</li>
<li><code>tbr</code>: Total average bitrate in KBit/s</li>
<li><code>vbr</code>: Average video bitrate in KBit/s</li>
<li><code>abr</code>: Average audio bitrate in KBit/s</li>
<li><code>br</code>: Average bitrate in KBit/s, <code>tbr</code>/<code>vbr</code>/<code>abr</code></li>
<li><code>asr</code>: Audio sample rate in Hz</li>
</ul>
<p dir="auto"><strong>Deprecation warning</strong>: Many of these fields have (currently undocumented) aliases, that may be removed in a future version. It is recommended to use only the documented field names.</p>
<p dir="auto">All fields, unless specified otherwise, are sorted in descending order. To reverse this, prefix the field with a <code>+</code>. E.g. <code>+res</code> prefers format with the smallest resolution. Additionally, you can suffix a preferred value for the fields, separated by a <code>:</code>. E.g. <code>res:720</code> prefers larger videos, but no larger than 720p and the smallest video if there are no videos less than 720p. For <code>codec</code> and <code>ext</code>, you can provide two preferred values, the first for video and the second for audio. E.g. <code>+codec:avc:m4a</code> (equivalent to <code>+vcodec:avc,+acodec:m4a</code>) sets the video codec preference to <code>h264</code> &gt; <code>h265</code> &gt; <code>vp9</code> &gt; <code>vp9.2</code> &gt; <code>av01</code> &gt; <code>vp8</code> &gt; <code>h263</code> &gt; <code>theora</code> and audio codec preference to <code>mp4a</code> &gt; <code>aac</code> &gt; <code>vorbis</code> &gt; <code>opus</code> &gt; <code>mp3</code> &gt; <code>ac3</code> &gt; <code>dts</code>. You can also make the sorting prefer the nearest values to the provided by using <code>~</code> as the delimiter. E.g. <code>filesize~1G</code> prefers the format with filesize closest to 1 GiB.</p>
<p dir="auto">The fields <code>hasvid</code> and <code>ie_pref</code> are always given highest priority in sorting, irrespective of the user-defined order. This behaviour can be changed by using <code>--format-sort-force</code>. Apart from these, the default order used is: <code>lang,quality,res,fps,hdr:12,vcodec:vp9.2,channels,acodec,size,br,asr,proto,ext,hasaud,source,id</code>. The extractors may override this default order, but they cannot override the user-provided order.</p>
<p dir="auto">Note that the default has <code>vcodec:vp9.2</code>; i.e. <code>av1</code> is not preferred. Similarly, the default for hdr is <code>hdr:12</code>; i.e. dolby vision is not preferred. These choices are made since DV and AV1 formats are not yet fully compatible with most devices. This may be changed in the future as more devices become capable of smoothly playing back these formats.</p>
<p dir="auto">If your format selector is <code>worst</code>, the last item is selected after sorting. This means it will select the format that is worst in all respects. Most of the time, what you actually want is the video with the smallest filesize instead. So it is generally better to use <code>-f best -S +size,+br,+res,+fps</code>.</p>
<p dir="auto"><strong>Tip</strong>: You can use the <code>-v -F</code> to see how the formats have been sorted (worst to best).</p>
<h2 tabindex="-1" dir="auto">Format Selection examples</h2>
<div dir="auto" data-snippet-clipboard-copy-content="# Download and merge the best video-only format and the best audio-only format,
# or download the best combined format if video-only format is not available
$ yt-dlp -f &quot;bv+ba/b&quot;

# Download best format that contains video,
# and if it doesn't already have an audio stream, merge it with best audio-only format
$ yt-dlp -f &quot;bv*+ba/b&quot;

# Same as above
$ yt-dlp

# Download the best video-only format and the best audio-only format without merging them
# For this case, an output template should be used since
# by default, bestvideo and bestaudio will have the same file name.
$ yt-dlp -f &quot;bv,ba&quot; -o &quot;%(title)s.f%(format_id)s.%(ext)s&quot;

# Download and merge the best format that has a video stream,
# and all audio-only formats into one file
$ yt-dlp -f &quot;bv*+mergeall[vcodec=none]&quot; --audio-multistreams

# Download and merge the best format that has a video stream,
# and the best 2 audio-only formats into one file
$ yt-dlp -f &quot;bv*+ba+ba.2&quot; --audio-multistreams


# The following examples show the old method (without -S) of format selection
# and how to use -S to achieve a similar but (generally) better result

# Download the worst video available (old method)
$ yt-dlp -f &quot;wv*+wa/w&quot;

# Download the best video available but with the smallest resolution
$ yt-dlp -S &quot;+res&quot;

# Download the smallest video available
$ yt-dlp -S &quot;+size,+br&quot;



# Download the best mp4 video available, or the best video if no mp4 available
$ yt-dlp -f &quot;bv*[ext=mp4]+ba[ext=m4a]/b[ext=mp4] / bv*+ba/b&quot;

# Download the best video with the best extension
# (For video, mp4 > mov > webm > flv. For audio, m4a > aac > mp3 ...)
$ yt-dlp -S &quot;ext&quot;



# Download the best video available but no better than 480p,
# or the worst video if there is no video under 480p
$ yt-dlp -f &quot;bv*[height<=480]+ba/b[height<=480] / wv*+ba/w&quot;

# Download the best video available with the largest height but no better than 480p,
# or the best video with the smallest resolution if there is no video under 480p
$ yt-dlp -S &quot;height:480&quot;

# Download the best video available with the largest resolution but no better than 480p,
# or the best video with the smallest resolution if there is no video under 480p
# Resolution is determined by using the smallest dimension.
# So this works correctly for vertical videos as well
$ yt-dlp -S &quot;res:480&quot;



# Download the best video (that also has audio) but no bigger than 50 MB,
# or the worst video (that also has audio) if there is no video under 50 MB
$ yt-dlp -f &quot;b[filesize<50M] / w&quot;

# Download largest video (that also has audio) but no bigger than 50 MB,
# or the smallest video (that also has audio) if there is no video under 50 MB
$ yt-dlp -f &quot;b&quot; -S &quot;filesize:50M&quot;

# Download best video (that also has audio) that is closest in size to 50 MB
$ yt-dlp -f &quot;b&quot; -S &quot;filesize~50M&quot;



# Download best video available via direct link over HTTP/HTTPS protocol,
# or the best video available via any protocol if there is no such video
$ yt-dlp -f &quot;(bv*+ba/b)[protocol^=http][protocol!*=dash] / (bv*+ba/b)&quot;

# Download best video available via the best protocol
# (https/ftps > http/ftp > m3u8_native > m3u8 > http_dash_segments ...)
$ yt-dlp -S &quot;proto&quot;



# Download the best video with either h264 or h265 codec,
# or the best video if there is no such video
$ yt-dlp -f &quot;(bv*[vcodec~='^((he|a)vc|h26[45])']+ba) / (bv*+ba/b)&quot;

# Download the best video with best codec no better than h264,
# or the best video with worst codec if there is no such video
$ yt-dlp -S &quot;codec:h264&quot;

# Download the best video with worst codec no worse than h264,
# or the best video with best codec if there is no such video
$ yt-dlp -S &quot;+codec:h264&quot;



# More complex examples

# Download the best video no better than 720p preferring framerate greater than 30,
# or the worst video (still preferring framerate greater than 30) if there is no such video
$ yt-dlp -f &quot;((bv*[fps>30]/bv*)[height<=720]/(wv*[fps>30]/wv*)) + ba / (b[fps>30]/b)[height<=720]/(w[fps>30]/w)&quot;

# Download the video with the largest resolution no better than 720p,
# or the video with the smallest resolution available if there is no such video,
# preferring larger framerate for formats with the same resolution
$ yt-dlp -S &quot;res:720,fps&quot;



# Download the video with smallest resolution no worse than 480p,
# or the video with the largest resolution available if there is no such video,
# preferring better codec and then larger total bitrate for the same resolution
$ yt-dlp -S &quot;+res:480,codec,br&quot;"><pre><span><span>#</span> Download and merge the best video-only format and the best audio-only format,</span>
<span><span>#</span> or download the best combined format if video-only format is not available</span>
$ yt-dlp -f <span><span>"</span>bv+ba/b<span>"</span></span>

<span><span>#</span> Download best format that contains video,</span>
<span><span>#</span> and if it doesn't already have an audio stream, merge it with best audio-only format</span>
$ yt-dlp -f <span><span>"</span>bv*+ba/b<span>"</span></span>

<span><span>#</span> Same as above</span>
$ yt-dlp

<span><span>#</span> Download the best video-only format and the best audio-only format without merging them</span>
<span><span>#</span> For this case, an output template should be used since</span>
<span><span>#</span> by default, bestvideo and bestaudio will have the same file name.</span>
$ yt-dlp -f <span><span>"</span>bv,ba<span>"</span></span> -o <span><span>"</span>%(title)s.f%(format_id)s.%(ext)s<span>"</span></span>

<span><span>#</span> Download and merge the best format that has a video stream,</span>
<span><span>#</span> and all audio-only formats into one file</span>
$ yt-dlp -f <span><span>"</span>bv*+mergeall[vcodec=none]<span>"</span></span> --audio-multistreams

<span><span>#</span> Download and merge the best format that has a video stream,</span>
<span><span>#</span> and the best 2 audio-only formats into one file</span>
$ yt-dlp -f <span><span>"</span>bv*+ba+ba.2<span>"</span></span> --audio-multistreams


<span><span>#</span> The following examples show the old method (without -S) of format selection</span>
<span><span>#</span> and how to use -S to achieve a similar but (generally) better result</span>

<span><span>#</span> Download the worst video available (old method)</span>
$ yt-dlp -f <span><span>"</span>wv*+wa/w<span>"</span></span>

<span><span>#</span> Download the best video available but with the smallest resolution</span>
$ yt-dlp -S <span><span>"</span>+res<span>"</span></span>

<span><span>#</span> Download the smallest video available</span>
$ yt-dlp -S <span><span>"</span>+size,+br<span>"</span></span>



<span><span>#</span> Download the best mp4 video available, or the best video if no mp4 available</span>
$ yt-dlp -f <span><span>"</span>bv*[ext=mp4]+ba[ext=m4a]/b[ext=mp4] / bv*+ba/b<span>"</span></span>

<span><span>#</span> Download the best video with the best extension</span>
<span><span>#</span> (For video, mp4 &gt; mov &gt; webm &gt; flv. For audio, m4a &gt; aac &gt; mp3 ...)</span>
$ yt-dlp -S <span><span>"</span>ext<span>"</span></span>



<span><span>#</span> Download the best video available but no better than 480p,</span>
<span><span>#</span> or the worst video if there is no video under 480p</span>
$ yt-dlp -f <span><span>"</span>bv*[height&lt;=480]+ba/b[height&lt;=480] / wv*+ba/w<span>"</span></span>

<span><span>#</span> Download the best video available with the largest height but no better than 480p,</span>
<span><span>#</span> or the best video with the smallest resolution if there is no video under 480p</span>
$ yt-dlp -S <span><span>"</span>height:480<span>"</span></span>

<span><span>#</span> Download the best video available with the largest resolution but no better than 480p,</span>
<span><span>#</span> or the best video with the smallest resolution if there is no video under 480p</span>
<span><span>#</span> Resolution is determined by using the smallest dimension.</span>
<span><span>#</span> So this works correctly for vertical videos as well</span>
$ yt-dlp -S <span><span>"</span>res:480<span>"</span></span>



<span><span>#</span> Download the best video (that also has audio) but no bigger than 50 MB,</span>
<span><span>#</span> or the worst video (that also has audio) if there is no video under 50 MB</span>
$ yt-dlp -f <span><span>"</span>b[filesize&lt;50M] / w<span>"</span></span>

<span><span>#</span> Download largest video (that also has audio) but no bigger than 50 MB,</span>
<span><span>#</span> or the smallest video (that also has audio) if there is no video under 50 MB</span>
$ yt-dlp -f <span><span>"</span>b<span>"</span></span> -S <span><span>"</span>filesize:50M<span>"</span></span>

<span><span>#</span> Download best video (that also has audio) that is closest in size to 50 MB</span>
$ yt-dlp -f <span><span>"</span>b<span>"</span></span> -S <span><span>"</span>filesize~50M<span>"</span></span>



<span><span>#</span> Download best video available via direct link over HTTP/HTTPS protocol,</span>
<span><span>#</span> or the best video available via any protocol if there is no such video</span>
$ yt-dlp -f <span><span>"</span>(bv*+ba/b)[protocol^=http][protocol!*=dash] / (bv*+ba/b)<span>"</span></span>

<span><span>#</span> Download best video available via the best protocol</span>
<span><span>#</span> (https/ftps &gt; http/ftp &gt; m3u8_native &gt; m3u8 &gt; http_dash_segments ...)</span>
$ yt-dlp -S <span><span>"</span>proto<span>"</span></span>



<span><span>#</span> Download the best video with either h264 or h265 codec,</span>
<span><span>#</span> or the best video if there is no such video</span>
$ yt-dlp -f <span><span>"</span>(bv*[vcodec~='^((he|a)vc|h26[45])']+ba) / (bv*+ba/b)<span>"</span></span>

<span><span>#</span> Download the best video with best codec no better than h264,</span>
<span><span>#</span> or the best video with worst codec if there is no such video</span>
$ yt-dlp -S <span><span>"</span>codec:h264<span>"</span></span>

<span><span>#</span> Download the best video with worst codec no worse than h264,</span>
<span><span>#</span> or the best video with best codec if there is no such video</span>
$ yt-dlp -S <span><span>"</span>+codec:h264<span>"</span></span>



<span><span>#</span> More complex examples</span>

<span><span>#</span> Download the best video no better than 720p preferring framerate greater than 30,</span>
<span><span>#</span> or the worst video (still preferring framerate greater than 30) if there is no such video</span>
$ yt-dlp -f <span><span>"</span>((bv*[fps&gt;30]/bv*)[height&lt;=720]/(wv*[fps&gt;30]/wv*)) + ba / (b[fps&gt;30]/b)[height&lt;=720]/(w[fps&gt;30]/w)<span>"</span></span>

<span><span>#</span> Download the video with the largest resolution no better than 720p,</span>
<span><span>#</span> or the video with the smallest resolution available if there is no such video,</span>
<span><span>#</span> preferring larger framerate for formats with the same resolution</span>
$ yt-dlp -S <span><span>"</span>res:720,fps<span>"</span></span>



<span><span>#</span> Download the video with smallest resolution no worse than 480p,</span>
<span><span>#</span> or the video with the largest resolution available if there is no such video,</span>
<span><span>#</span> preferring better codec and then larger total bitrate for the same resolution</span>
$ yt-dlp -S <span><span>"</span>+res:480,codec,br<span>"</span></span></pre></div>
<h2 tabindex="-1" dir="auto">MODIFYING METADATA</h2>
<p dir="auto">The metadata obtained by the extractors can be modified by using <code>--parse-metadata</code> and <code>--replace-in-metadata</code></p>
<p dir="auto"><code>--replace-in-metadata FIELDS REGEX REPLACE</code> is used to replace text in any metadata field using <a href="https://docs.python.org/3/library/re.html#regular-expression-syntax" rel="nofollow">python regular expression</a>. <a href="https://docs.python.org/3/library/re.html?highlight=backreferences#re.sub" rel="nofollow">Backreferences</a> can be used in the replace string for advanced use.</p>
<p dir="auto">The general syntax of <code>--parse-metadata FROM:TO</code> is to give the name of a field or an <a href="#output-template">output template</a> to extract data from, and the format to interpret it as, separated by a colon <code>:</code>. Either a <a href="https://docs.python.org/3/library/re.html#regular-expression-syntax" rel="nofollow">python regular expression</a> with named capture groups, a single field name, or a similar syntax to the <a href="#output-template">output template</a> (only <code>%(field)s</code> formatting is supported) can be used for <code>TO</code>. The option can be used multiple times to parse and modify various fields.</p>
<p dir="auto">Note that these options preserve their relative order, allowing replacements to be made in parsed fields and viceversa. Also, any field thus created can be used in the <a href="#output-template">output template</a> and will also affect the media file's metadata added when using <code>--embed-metadata</code>.</p>
<p dir="auto">This option also has a few special uses:</p>
<ul dir="auto">
<li>
<p dir="auto">You can download an additional URL based on the metadata of the currently downloaded video. To do this, set the field <code>additional_urls</code> to the URL that you want to download. E.g. <code>--parse-metadata "description:(?P&lt;additional_urls&gt;https?://www\.vimeo\.com/\d+)"</code> will download the first vimeo video found in the description</p>
</li>
<li>
<p dir="auto">You can use this to change the metadata that is embedded in the media file. To do this, set the value of the corresponding field with a <code>meta_</code> prefix. For example, any value you set to <code>meta_description</code> field will be added to the <code>description</code> field in the file - you can use this to set a different "description" and "synopsis". To modify the metadata of individual streams, use the <code>meta&lt;n&gt;_</code> prefix (e.g. <code>meta1_language</code>). Any value set to the <code>meta_</code> field will overwrite all default values.</p>
</li>
</ul>
<p dir="auto"><strong>Note</strong>: Metadata modification happens before format selection, post-extraction and other post-processing operations. Some fields may be added or changed during these steps, overriding your changes.</p>
<p dir="auto">For reference, these are the fields yt-dlp adds by default to the file metadata:</p>
<table>
<thead>
<tr>
<th>Metadata fields</th>
<th>From</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>title</code></td>
<td><code>track</code> or <code>title</code></td>
</tr>
<tr>
<td><code>date</code></td>
<td><code>upload_date</code></td>
</tr>
<tr>
<td><code>description</code>,  <code>synopsis</code></td>
<td><code>description</code></td>
</tr>
<tr>
<td><code>purl</code>, <code>comment</code></td>
<td><code>webpage_url</code></td>
</tr>
<tr>
<td><code>track</code></td>
<td><code>track_number</code></td>
</tr>
<tr>
<td><code>artist</code></td>
<td><code>artist</code>, <code>creator</code>, <code>uploader</code> or <code>uploader_id</code></td>
</tr>
<tr>
<td><code>genre</code></td>
<td><code>genre</code></td>
</tr>
<tr>
<td><code>album</code></td>
<td><code>album</code></td>
</tr>
<tr>
<td><code>album_artist</code></td>
<td><code>album_artist</code></td>
</tr>
<tr>
<td><code>disc</code></td>
<td><code>disc_number</code></td>
</tr>
<tr>
<td><code>show</code></td>
<td><code>series</code></td>
</tr>
<tr>
<td><code>season_number</code></td>
<td><code>season_number</code></td>
</tr>
<tr>
<td><code>episode_id</code></td>
<td><code>episode</code> or <code>episode_id</code></td>
</tr>
<tr>
<td><code>episode_sort</code></td>
<td><code>episode_number</code></td>
</tr>
<tr>
<td><code>language</code> of each stream</td>
<td>the format's <code>language</code></td>
</tr>
</tbody>
</table>
<p dir="auto"><strong>Note</strong>: The file format may not support some of these fields</p>
<h2 tabindex="-1" dir="auto">Modifying metadata examples</h2>
<div dir="auto" data-snippet-clipboard-copy-content="# Interpret the title as &quot;Artist - Title&quot;
$ yt-dlp --parse-metadata &quot;title:%(artist)s - %(title)s&quot;

# Regex example
$ yt-dlp --parse-metadata &quot;description:Artist - (?P<artist>.+)&quot;

# Set title as &quot;Series name S01E05&quot;
$ yt-dlp --parse-metadata &quot;%(series)s S%(season_number)02dE%(episode_number)02d:%(title)s&quot;

# Prioritize uploader as the &quot;artist&quot; field in video metadata
$ yt-dlp --parse-metadata &quot;%(uploader|)s:%(meta_artist)s&quot; --embed-metadata

# Set &quot;comment&quot; field in video metadata using description instead of webpage_url,
# handling multiple lines correctly
$ yt-dlp --parse-metadata &quot;description:(?s)(?P<meta_comment>.+)&quot; --embed-metadata

# Do not set any &quot;synopsis&quot; in the video metadata
$ yt-dlp --parse-metadata &quot;:(?P<meta_synopsis>)&quot;

# Remove &quot;formats&quot; field from the infojson by setting it to an empty string
$ yt-dlp --parse-metadata &quot;video::(?P<formats>)&quot; --write-info-json

# Replace all spaces and &quot;_&quot; in title and uploader with a `-`
$ yt-dlp --replace-in-metadata &quot;title,uploader&quot; &quot;[ _]&quot; &quot;-&quot;
"><pre><span><span>#</span> Interpret the title as "Artist - Title"</span>
$ yt-dlp --parse-metadata <span><span>"</span>title:%(artist)s - %(title)s<span>"</span></span>

<span><span>#</span> Regex example</span>
$ yt-dlp --parse-metadata <span><span>"</span>description:Artist - (?P&lt;artist&gt;.+)<span>"</span></span>

<span><span>#</span> Set title as "Series name S01E05"</span>
$ yt-dlp --parse-metadata <span><span>"</span>%(series)s S%(season_number)02dE%(episode_number)02d:%(title)s<span>"</span></span>

<span><span>#</span> Prioritize uploader as the "artist" field in video metadata</span>
$ yt-dlp --parse-metadata <span><span>"</span>%(uploader|)s:%(meta_artist)s<span>"</span></span> --embed-metadata

<span><span>#</span> Set "comment" field in video metadata using description instead of webpage_url,</span>
<span><span>#</span> handling multiple lines correctly</span>
$ yt-dlp --parse-metadata <span><span>"</span>description:(?s)(?P&lt;meta_comment&gt;.+)<span>"</span></span> --embed-metadata

<span><span>#</span> Do not set any "synopsis" in the video metadata</span>
$ yt-dlp --parse-metadata <span><span>"</span>:(?P&lt;meta_synopsis&gt;)<span>"</span></span>

<span><span>#</span> Remove "formats" field from the infojson by setting it to an empty string</span>
$ yt-dlp --parse-metadata <span><span>"</span>video::(?P&lt;formats&gt;)<span>"</span></span> --write-info-json

<span><span>#</span> Replace all spaces and "_" in title and uploader with a `-`</span>
$ yt-dlp --replace-in-metadata <span><span>"</span>title,uploader<span>"</span></span> <span><span>"</span>[ _]<span>"</span></span> <span><span>"</span>-<span>"</span></span>
</pre></div>
<h2 tabindex="-1" dir="auto">EXTRACTOR ARGUMENTS</h2>
<p dir="auto">Some extractors accept additional arguments which can be passed using <code>--extractor-args KEY:ARGS</code>. <code>ARGS</code> is a <code>;</code> (semicolon) separated string of <code>ARG=VAL1,VAL2</code>. E.g. <code>--extractor-args "youtube:player-client=android_embedded,web;include_live_dash" --extractor-args "funimation:version=uncut"</code></p>
<p dir="auto">Note: In CLI, <code>ARG</code> can use <code>-</code> instead of <code>_</code>; e.g. <code>youtube:player-client"</code> becomes <code>youtube:player_client"</code></p>
<p dir="auto">The following extractors use this feature:</p>
<h4 tabindex="-1" dir="auto">youtube</h4>
<ul dir="auto">
<li><code>lang</code>: Prefer translated metadata (<code>title</code>, <code>description</code> etc) of this language code (case-sensitive). By default, the video primary language metadata is preferred, with a fallback to <code>en</code> translated. See <a href="https://github.com/yt-dlp/yt-dlp/blob/c26f9b991a0681fd3ea548d535919cec1fbbd430/yt_dlp/extractor/youtube.py#L381-L390">youtube.py</a> for list of supported content language codes</li>
<li><code>skip</code>: One or more of <code>hls</code>, <code>dash</code> or <code>translated_subs</code> to skip extraction of the m3u8 manifests, dash manifests and <a href="https://github.com/yt-dlp/yt-dlp/issues/4090#issuecomment-1158102032" data-hovercard-type="issue" data-hovercard-url="/yt-dlp/yt-dlp/issues/4090/hovercard">auto-translated subtitles</a> respectively</li>
<li><code>player_client</code>: Clients to extract video data from. The main clients are <code>web</code>, <code>android</code> and <code>ios</code> with variants <code>_music</code>, <code>_embedded</code>, <code>_embedscreen</code>, <code>_creator</code> (e.g. <code>web_embedded</code>); and <code>mweb</code> and <code>tv_embedded</code> (agegate bypass) with no variants. By default, <code>ios,android,web</code> is used, but <code>tv_embedded</code> and <code>creator</code> variants are added as required for age-gated videos. Similarly, the music variants are added for <code>music.youtube.com</code> urls. You can use <code>all</code> to use all the clients, and <code>default</code> for the default clients.</li>
<li><code>player_skip</code>: Skip some network requests that are generally needed for robust extraction. One or more of <code>configs</code> (skip client configs), <code>webpage</code> (skip initial webpage), <code>js</code> (skip js player). While these options can help reduce the number of requests needed or avoid some rate-limiting, they could cause some issues. See <a href="https://github.com/yt-dlp/yt-dlp/pull/860" data-hovercard-type="pull_request" data-hovercard-url="/yt-dlp/yt-dlp/pull/860/hovercard">#860</a> for more details</li>
<li><code>player_params</code>: YouTube player parameters to use for player requests. Will overwrite any default ones set by yt-dlp.</li>
<li><code>comment_sort</code>: <code>top</code> or <code>new</code> (default) - choose comment sorting mode (on YouTube's side)</li>
<li><code>max_comments</code>: Limit the amount of comments to gather. Comma-separated list of integers representing <code>max-comments,max-parents,max-replies,max-replies-per-thread</code>. Default is <code>all,all,all,all</code>
<ul dir="auto">
<li>E.g. <code>all,all,1000,10</code> will get a maximum of 1000 replies total, with up to 10 replies per thread. <code>1000,all,100</code> will get a maximum of 1000 comments, with a maximum of 100 replies total</li>
</ul>
</li>
<li><code>formats</code>: Change the types of formats to return. <code>dashy</code> (convert HTTP to DASH), <code>duplicate</code> (identical content but different URLs or protocol; includes <code>dashy</code>), <code>incomplete</code> (cannot be downloaded completely - live dash and post-live m3u8)</li>
<li><code>innertube_host</code>: Innertube API host to use for all API requests; e.g. <code>studio.youtube.com</code>, <code>youtubei.googleapis.com</code>. Note that cookies exported from one subdomain will not work on others</li>
<li><code>innertube_key</code>: Innertube API key to use for all API requests</li>
</ul>
<h4 tabindex="-1" dir="auto">youtubetab (YouTube playlists, channels, feeds, etc.)</h4>
<ul dir="auto">
<li><code>skip</code>: One or more of <code>webpage</code> (skip initial webpage download), <code>authcheck</code> (allow the download of playlists requiring authentication when no initial webpage is downloaded. This may cause unwanted behavior, see <a href="https://github.com/yt-dlp/yt-dlp/pull/1122" data-hovercard-type="pull_request" data-hovercard-url="/yt-dlp/yt-dlp/pull/1122/hovercard">#1122</a> for more details)</li>
<li><code>approximate_date</code>: Extract approximate <code>upload_date</code> and <code>timestamp</code> in flat-playlist. This may cause date-based filters to be slightly off</li>
</ul>
<h4 tabindex="-1" dir="auto">generic</h4>
<ul dir="auto">
<li><code>fragment_query</code>: Passthrough any query in mpd/m3u8 manifest URLs to their fragments if no value is provided, or else apply the query string given as <code>fragment_query=VALUE</code>. Does not apply to ffmpeg</li>
<li><code>variant_query</code>: Passthrough the master m3u8 URL query to its variant playlist URLs if no value is provided, or else apply the query string given as <code>variant_query=VALUE</code></li>
<li><code>hls_key</code>: An HLS AES-128 key URI <em>or</em> key (as hex), and optionally the IV (as hex), in the form of <code>(URI|KEY)[,IV]</code>; e.g. <code>generic:hls_key=ABCDEF1234567980,0xFEDCBA0987654321</code>. Passing any of these values will force usage of the native HLS downloader and override the corresponding values found in the m3u8 playlist</li>
<li><code>is_live</code>: Bypass live HLS detection and manually set <code>live_status</code> - a value of <code>false</code> will set <code>not_live</code>, any other value (or no value) will set <code>is_live</code></li>
</ul>
<h4 tabindex="-1" dir="auto">funimation</h4>
<ul dir="auto">
<li><code>language</code>: Audio languages to extract, e.g. <code>funimation:language=english,japanese</code></li>
<li><code>version</code>: The video version to extract - <code>uncut</code> or <code>simulcast</code></li>
</ul>
<h4 tabindex="-1" dir="auto">crunchyrollbeta (Crunchyroll)</h4>
<ul dir="auto">
<li><code>format</code>: Which stream type(s) to extract (default: <code>adaptive_hls</code>). Potentially useful values include <code>adaptive_hls</code>, <code>adaptive_dash</code>, <code>vo_adaptive_hls</code>, <code>vo_adaptive_dash</code>, <code>download_hls</code>, <code>download_dash</code>, <code>multitrack_adaptive_hls_v2</code></li>
<li><code>hardsub</code>: Preference order for which hardsub versions to extract, or <code>all</code> (default: <code>None</code> = no hardsubs), e.g. <code>crunchyrollbeta:hardsub=en-US,None</code></li>
</ul>
<h4 tabindex="-1" dir="auto">vikichannel</h4>
<ul dir="auto">
<li><code>video_types</code>: Types of videos to download - one or more of <code>episodes</code>, <code>movies</code>, <code>clips</code>, <code>trailers</code></li>
</ul>
<h4 tabindex="-1" dir="auto">niconico</h4>
<ul dir="auto">
<li><code>segment_duration</code>: Segment duration in milliseconds for HLS-DMC formats. Use it at your own risk since this feature <strong>may result in your account termination.</strong></li>
</ul>
<h4 tabindex="-1" dir="auto">youtubewebarchive</h4>
<ul dir="auto">
<li><code>check_all</code>: Try to check more at the cost of more requests. One or more of <code>thumbnails</code>, <code>captures</code></li>
</ul>
<h4 tabindex="-1" dir="auto">gamejolt</h4>
<ul dir="auto">
<li><code>comment_sort</code>: <code>hot</code> (default), <code>you</code> (cookies needed), <code>top</code>, <code>new</code> - choose comment sorting mode (on GameJolt's side)</li>
</ul>
<h4 tabindex="-1" dir="auto">hotstar</h4>
<ul dir="auto">
<li><code>res</code>: resolution to ignore - one or more of <code>sd</code>, <code>hd</code>, <code>fhd</code></li>
<li><code>vcodec</code>: vcodec to ignore - one or more of <code>h264</code>, <code>h265</code>, <code>dvh265</code></li>
<li><code>dr</code>: dynamic range to ignore - one or more of <code>sdr</code>, <code>hdr10</code>, <code>dv</code></li>
</ul>
<h4 tabindex="-1" dir="auto">tiktok</h4>
<ul dir="auto">
<li><code>api_hostname</code>: Hostname to use for mobile API requests, e.g. <code>api-h2.tiktokv.com</code></li>
<li><code>app_version</code>: App version to call mobile APIs with - should be set along with <code>manifest_app_version</code>, e.g. <code>20.2.1</code></li>
<li><code>manifest_app_version</code>: Numeric app version to call mobile APIs with, e.g. <code>221</code></li>
</ul>
<h4 tabindex="-1" dir="auto">rokfinchannel</h4>
<ul dir="auto">
<li><code>tab</code>: Which tab to download - one of <code>new</code>, <code>top</code>, <code>videos</code>, <code>podcasts</code>, <code>streams</code>, <code>stacks</code></li>
</ul>
<h4 tabindex="-1" dir="auto">twitter</h4>
<ul dir="auto">
<li><code>api</code>: Select one of <code>graphql</code> (default), <code>legacy</code> or <code>syndication</code> as the API for tweet extraction. Has no effect if logged in</li>
</ul>
<h4 tabindex="-1" dir="auto">stacommu, wrestleuniverse</h4>
<ul dir="auto">
<li><code>device_id</code>: UUID value assigned by the website and used to enforce device limits for paid livestream content. Can be found in browser local storage</li>
</ul>
<h4 tabindex="-1" dir="auto">twitch</h4>
<ul dir="auto">
<li><code>client_id</code>: Client ID value to be sent with GraphQL requests, e.g. <code>twitch:client_id=kimne78kx3ncx6brgo4mv6wki5h1ko</code></li>
</ul>
<h4 tabindex="-1" dir="auto">nhkradirulive (NHK らじる★らじる LIVE)</h4>
<ul dir="auto">
<li><code>area</code>: Which regional variation to extract. Valid areas are: <code>sapporo</code>, <code>sendai</code>, <code>tokyo</code>, <code>nagoya</code>, <code>osaka</code>, <code>hiroshima</code>, <code>matsuyama</code>, <code>fukuoka</code>. Defaults to <code>tokyo</code></li>
</ul>
<p dir="auto"><strong>Note</strong>: These options may be changed/removed in the future without concern for backward compatibility</p>

<h2 tabindex="-1" dir="auto">PLUGINS</h2>
<p dir="auto">Note that <strong>all</strong> plugins are imported even if not invoked, and that <strong>there are no checks</strong> performed on plugin code. <strong>Use plugins at your own risk and only if you trust the code!</strong></p>
<p dir="auto">Plugins can be of <code>&lt;type&gt;</code>s <code>extractor</code> or <code>postprocessor</code>.</p>
<ul dir="auto">
<li>Extractor plugins do not need to be enabled from the CLI and are automatically invoked when the input URL is suitable for it.</li>
<li>Extractor plugins take priority over builtin extractors.</li>
<li>Postprocessor plugins can be invoked using <code>--use-postprocessor NAME</code>.</li>
</ul>
<p dir="auto">Plugins are loaded from the namespace packages <code>yt_dlp_plugins.extractor</code> and <code>yt_dlp_plugins.postprocessor</code>.</p>
<p dir="auto">In other words, the file structure on the disk looks something like:</p>
<div data-snippet-clipboard-copy-content="    yt_dlp_plugins/
        extractor/
            myplugin.py
        postprocessor/
            myplugin.py"><pre><code>    yt_dlp_plugins/
        extractor/
            myplugin.py
        postprocessor/
            myplugin.py
</code></pre></div>
<p dir="auto">yt-dlp looks for these <code>yt_dlp_plugins</code> namespace folders in many locations (see below) and loads in plugins from <strong>all</strong> of them.</p>
<p dir="auto">See the <a href="https://github.com/yt-dlp/yt-dlp/wiki/Plugins">wiki for some known plugins</a></p>
<h2 tabindex="-1" dir="auto">Installing Plugins</h2>
<p dir="auto">Plugins can be installed using various methods and locations.</p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Configuration directories</strong>:
Plugin packages (containing a <code>yt_dlp_plugins</code> namespace folder) can be dropped into the following standard <a href="#configuration">configuration locations</a>:</p>
<ul dir="auto">
<li><strong>User Plugins</strong>
<ul dir="auto">
<li><code>${XDG_CONFIG_HOME}/yt-dlp/plugins/&lt;package name&gt;/yt_dlp_plugins/</code> (recommended on Linux/macOS)</li>
<li><code>${XDG_CONFIG_HOME}/yt-dlp-plugins/&lt;package name&gt;/yt_dlp_plugins/</code></li>
<li><code>${APPDATA}/yt-dlp/plugins/&lt;package name&gt;/yt_dlp_plugins/</code> (recommended on Windows)</li>
<li><code>${APPDATA}/yt-dlp-plugins/&lt;package name&gt;/yt_dlp_plugins/</code></li>
<li><code>~/.yt-dlp/plugins/&lt;package name&gt;/yt_dlp_plugins/</code></li>
<li><code>~/yt-dlp-plugins/&lt;package name&gt;/yt_dlp_plugins/</code></li>
</ul>
</li>
<li><strong>System Plugins</strong>
<ul dir="auto">
<li><code>/etc/yt-dlp/plugins/&lt;package name&gt;/yt_dlp_plugins/</code></li>
<li><code>/etc/yt-dlp-plugins/&lt;package name&gt;/yt_dlp_plugins/</code></li>
</ul>
</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Executable location</strong>: Plugin packages can similarly be installed in a <code>yt-dlp-plugins</code> directory under the executable location (recommended for portable installations):</p>
<ul dir="auto">
<li>Binary: where <code>&lt;root-dir&gt;/yt-dlp.exe</code>, <code>&lt;root-dir&gt;/yt-dlp-plugins/&lt;package name&gt;/yt_dlp_plugins/</code></li>
<li>Source: where <code>&lt;root-dir&gt;/yt_dlp/__main__.py</code>, <code>&lt;root-dir&gt;/yt-dlp-plugins/&lt;package name&gt;/yt_dlp_plugins/</code></li>
</ul>
</li>
<li>
<p dir="auto"><strong>pip and other locations in <code>PYTHONPATH</code></strong></p>
<ul dir="auto">
<li>Plugin packages can be installed and managed using <code>pip</code>. See <a href="https://github.com/yt-dlp/yt-dlp-sample-plugins">yt-dlp-sample-plugins</a> for an example.
<ul dir="auto">
<li>Note: plugin files between plugin packages installed with pip must have unique filenames.</li>
</ul>
</li>
<li>Any path in <code>PYTHONPATH</code> is searched in for the <code>yt_dlp_plugins</code> namespace folder.
<ul dir="auto">
<li>Note: This does not apply for Pyinstaller/py2exe builds.</li>
</ul>
</li>
</ul>
</li>
</ol>
<p dir="auto"><code>.zip</code>, <code>.egg</code> and <code>.whl</code> archives containing a <code>yt_dlp_plugins</code> namespace folder in their root are also supported as plugin packages.</p>
<ul dir="auto">
<li>e.g. <code>${XDG_CONFIG_HOME}/yt-dlp/plugins/mypluginpkg.zip</code> where <code>mypluginpkg.zip</code> contains <code>yt_dlp_plugins/&lt;type&gt;/myplugin.py</code></li>
</ul>
<p dir="auto">Run yt-dlp with <code>--verbose</code> to check if the plugin has been loaded.</p>
<h2 tabindex="-1" dir="auto">Developing Plugins</h2>
<p dir="auto">See the <a href="https://github.com/yt-dlp/yt-dlp-sample-plugins">yt-dlp-sample-plugins</a> repo for a template plugin package and the <a href="https://github.com/yt-dlp/yt-dlp/wiki/Plugin-Development">Plugin Development</a> section of the wiki for a plugin development guide.</p>
<p dir="auto">All public classes with a name ending in <code>IE</code>/<code>PP</code> are imported from each file for extractors and postprocessors repectively. This respects underscore prefix (e.g. <code>_MyBasePluginIE</code> is private) and <code>__all__</code>. Modules can similarly be excluded by prefixing the module name with an underscore (e.g. <code>_myplugin.py</code>).</p>
<p dir="auto">To replace an existing extractor with a subclass of one, set the <code>plugin_name</code> class keyword argument (e.g. <code>class MyPluginIE(ABuiltInIE, plugin_name='myplugin')</code> will replace <code>ABuiltInIE</code> with <code>MyPluginIE</code>). Since the extractor replaces the parent, you should exclude the subclass extractor from being imported separately by making it private using one of the methods described above.</p>
<p dir="auto">If you are a plugin author, add <a href="https://github.com/topics/yt-dlp-plugins">yt-dlp-plugins</a> as a topic to your repository for discoverability.</p>
<p dir="auto">See the <a href="https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions">Developer Instructions</a> on how to write and test an extractor.</p>
<h2 tabindex="-1" dir="auto">EMBEDDING YT-DLP</h2>
<p dir="auto">yt-dlp makes the best effort to be a good command-line program, and thus should be callable from any programming language.</p>
<p dir="auto">Your program should avoid parsing the normal stdout since they may change in future versions. Instead they should use options such as <code>-J</code>, <code>--print</code>, <code>--progress-template</code>, <code>--exec</code> etc to create console output that you can reliably reproduce and parse.</p>
<p dir="auto">From a Python program, you can embed yt-dlp in a more powerful fashion, like this:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from yt_dlp import YoutubeDL

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']
with YoutubeDL() as ydl:
    ydl.download(URLS)"><pre><span>from</span> <span>yt_dlp</span> <span>import</span> <span>YoutubeDL</span>

<span>URLS</span> <span>=</span> [<span>'https://www.youtube.com/watch?v=BaW_jenozKc'</span>]
<span>with</span> <span>YoutubeDL</span>() <span>as</span> <span>ydl</span>:
    <span>ydl</span>.<span>download</span>(<span>URLS</span>)</pre></div>
<p dir="auto">Most likely, you'll want to use various options. For a list of options available, have a look at <a href="https://github.com/yt-dlp/yt-dlp/blob/master/yt_dlp/YoutubeDL.py#L183"><code>yt_dlp/YoutubeDL.py</code></a> or <code>help(yt_dlp.YoutubeDL)</code> in a Python shell. If you are already familiar with the CLI, you can use <a href="https://github.com/yt-dlp/yt-dlp/blob/master/devscripts/cli_to_api.py"><code>devscripts/cli_to_api.py</code></a> to translate any CLI switches to <code>YoutubeDL</code> params.</p>
<p dir="auto"><strong>Tip</strong>: If you are porting your code from youtube-dl to yt-dlp, one important point to look out for is that we do not guarantee the return value of <code>YoutubeDL.extract_info</code> to be json serializable, or even be a dictionary. It will be dictionary-like, but if you want to ensure it is a serializable dictionary, pass it through <code>YoutubeDL.sanitize_info</code> as shown in the <a href="#extracting-information">example below</a></p>
<h2 tabindex="-1" dir="auto">Embedding examples</h2>
<h4 tabindex="-1" dir="auto">Extracting information</h4>
<div dir="auto" data-snippet-clipboard-copy-content="import json
import yt_dlp

URL = 'https://www.youtube.com/watch?v=BaW_jenozKc'

# ℹ️ See help(yt_dlp.YoutubeDL) for a list of available options and public functions
ydl_opts = {}
with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    info = ydl.extract_info(URL, download=False)

    # ℹ️ ydl.sanitize_info makes the info json-serializable
    print(json.dumps(ydl.sanitize_info(info)))"><pre><span>import</span> <span>json</span>
<span>import</span> <span>yt_dlp</span>

<span>URL</span> <span>=</span> <span>'https://www.youtube.com/watch?v=BaW_jenozKc'</span>

<span># ℹ️ See help(yt_dlp.YoutubeDL) for a list of available options and public functions</span>
<span>ydl_opts</span> <span>=</span> {}
<span>with</span> <span>yt_dlp</span>.<span>YoutubeDL</span>(<span>ydl_opts</span>) <span>as</span> <span>ydl</span>:
    <span>info</span> <span>=</span> <span>ydl</span>.<span>extract_info</span>(<span>URL</span>, <span>download</span><span>=</span><span>False</span>)

    <span># ℹ️ ydl.sanitize_info makes the info json-serializable</span>
    <span>print</span>(<span>json</span>.<span>dumps</span>(<span>ydl</span>.<span>sanitize_info</span>(<span>info</span>)))</pre></div>
<h4 tabindex="-1" dir="auto">Download using an info-json</h4>
<div dir="auto" data-snippet-clipboard-copy-content="import yt_dlp

INFO_FILE = 'path/to/video.info.json'

with yt_dlp.YoutubeDL() as ydl:
    error_code = ydl.download_with_info_file(INFO_FILE)

print('Some videos failed to download' if error_code
      else 'All videos successfully downloaded')"><pre><span>import</span> <span>yt_dlp</span>

<span>INFO_FILE</span> <span>=</span> <span>'path/to/video.info.json'</span>

<span>with</span> <span>yt_dlp</span>.<span>YoutubeDL</span>() <span>as</span> <span>ydl</span>:
    <span>error_code</span> <span>=</span> <span>ydl</span>.<span>download_with_info_file</span>(<span>INFO_FILE</span>)

<span>print</span>(<span>'Some videos failed to download'</span> <span>if</span> <span>error_code</span>
      <span>else</span> <span>'All videos successfully downloaded'</span>)</pre></div>
<h4 tabindex="-1" dir="auto">Extract audio</h4>
<div dir="auto" data-snippet-clipboard-copy-content="import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

ydl_opts = {
    'format': 'm4a/bestaudio/best',
    # ℹ️ See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments
    'postprocessors': [{  # Extract audio using ffmpeg
        'key': 'FFmpegExtractAudio',
        'preferredcodec': 'm4a',
    }]
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    error_code = ydl.download(URLS)"><pre><span>import</span> <span>yt_dlp</span>

<span>URLS</span> <span>=</span> [<span>'https://www.youtube.com/watch?v=BaW_jenozKc'</span>]

<span>ydl_opts</span> <span>=</span> {
    <span>'format'</span>: <span>'m4a/bestaudio/best'</span>,
    <span># ℹ️ See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments</span>
    <span>'postprocessors'</span>: [{  <span># Extract audio using ffmpeg</span>
        <span>'key'</span>: <span>'FFmpegExtractAudio'</span>,
        <span>'preferredcodec'</span>: <span>'m4a'</span>,
    }]
}

<span>with</span> <span>yt_dlp</span>.<span>YoutubeDL</span>(<span>ydl_opts</span>) <span>as</span> <span>ydl</span>:
    <span>error_code</span> <span>=</span> <span>ydl</span>.<span>download</span>(<span>URLS</span>)</pre></div>
<h4 tabindex="-1" dir="auto">Filter videos</h4>
<div dir="auto" data-snippet-clipboard-copy-content="import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

def longer_than_a_minute(info, *, incomplete):
    &quot;&quot;&quot;Download only videos longer than a minute (or with unknown duration)&quot;&quot;&quot;
    duration = info.get('duration')
    if duration and duration < 60:
        return 'The video is too short'

ydl_opts = {
    'match_filter': longer_than_a_minute,
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    error_code = ydl.download(URLS)"><pre><span>import</span> <span>yt_dlp</span>

<span>URLS</span> <span>=</span> [<span>'https://www.youtube.com/watch?v=BaW_jenozKc'</span>]

<span>def</span> <span>longer_than_a_minute</span>(<span>info</span>, <span>*</span>, <span>incomplete</span>):
    <span>"""Download only videos longer than a minute (or with unknown duration)"""</span>
    <span>duration</span> <span>=</span> <span>info</span>.<span>get</span>(<span>'duration'</span>)
    <span>if</span> <span>duration</span> <span>and</span> <span>duration</span> <span>&lt;</span> <span>60</span>:
        <span>return</span> <span>'The video is too short'</span>

<span>ydl_opts</span> <span>=</span> {
    <span>'match_filter'</span>: <span>longer_than_a_minute</span>,
}

<span>with</span> <span>yt_dlp</span>.<span>YoutubeDL</span>(<span>ydl_opts</span>) <span>as</span> <span>ydl</span>:
    <span>error_code</span> <span>=</span> <span>ydl</span>.<span>download</span>(<span>URLS</span>)</pre></div>
<h4 tabindex="-1" dir="auto">Adding logger and progress hook</h4>
<div dir="auto" data-snippet-clipboard-copy-content="import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

class MyLogger:
    def debug(self, msg):
        # For compatibility with youtube-dl, both debug and info are passed into debug
        # You can distinguish them by the prefix '[debug] '
        if msg.startswith('[debug] '):
            pass
        else:
            self.info(msg)

    def info(self, msg):
        pass

    def warning(self, msg):
        pass

    def error(self, msg):
        print(msg)


# ℹ️ See &quot;progress_hooks&quot; in help(yt_dlp.YoutubeDL)
def my_hook(d):
    if d['status'] == 'finished':
        print('Done downloading, now post-processing ...')


ydl_opts = {
    'logger': MyLogger(),
    'progress_hooks': [my_hook],
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    ydl.download(URLS)"><pre><span>import</span> <span>yt_dlp</span>

<span>URLS</span> <span>=</span> [<span>'https://www.youtube.com/watch?v=BaW_jenozKc'</span>]

<span>class</span> <span>MyLogger</span>:
    <span>def</span> <span>debug</span>(<span>self</span>, <span>msg</span>):
        <span># For compatibility with youtube-dl, both debug and info are passed into debug</span>
        <span># You can distinguish them by the prefix '[debug] '</span>
        <span>if</span> <span>msg</span>.<span>startswith</span>(<span>'[debug] '</span>):
            <span>pass</span>
        <span>else</span>:
            <span>self</span>.<span>info</span>(<span>msg</span>)

    <span>def</span> <span>info</span>(<span>self</span>, <span>msg</span>):
        <span>pass</span>

    <span>def</span> <span>warning</span>(<span>self</span>, <span>msg</span>):
        <span>pass</span>

    <span>def</span> <span>error</span>(<span>self</span>, <span>msg</span>):
        <span>print</span>(<span>msg</span>)


<span># ℹ️ See "progress_hooks" in help(yt_dlp.YoutubeDL)</span>
<span>def</span> <span>my_hook</span>(<span>d</span>):
    <span>if</span> <span>d</span>[<span>'status'</span>] <span>==</span> <span>'finished'</span>:
        <span>print</span>(<span>'Done downloading, now post-processing ...'</span>)


<span>ydl_opts</span> <span>=</span> {
    <span>'logger'</span>: <span>MyLogger</span>(),
    <span>'progress_hooks'</span>: [<span>my_hook</span>],
}

<span>with</span> <span>yt_dlp</span>.<span>YoutubeDL</span>(<span>ydl_opts</span>) <span>as</span> <span>ydl</span>:
    <span>ydl</span>.<span>download</span>(<span>URLS</span>)</pre></div>
<h4 tabindex="-1" dir="auto">Add a custom PostProcessor</h4>
<div dir="auto" data-snippet-clipboard-copy-content="import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

# ℹ️ See help(yt_dlp.postprocessor.PostProcessor)
class MyCustomPP(yt_dlp.postprocessor.PostProcessor):
    def run(self, info):
        self.to_screen('Doing stuff')
        return [], info


with yt_dlp.YoutubeDL() as ydl:
    # ℹ️ &quot;when&quot; can take any value in yt_dlp.utils.POSTPROCESS_WHEN
    ydl.add_post_processor(MyCustomPP(), when='pre_process')
    ydl.download(URLS)"><pre><span>import</span> <span>yt_dlp</span>

<span>URLS</span> <span>=</span> [<span>'https://www.youtube.com/watch?v=BaW_jenozKc'</span>]

<span># ℹ️ See help(yt_dlp.postprocessor.PostProcessor)</span>
<span>class</span> <span>MyCustomPP</span>(<span>yt_dlp</span>.<span>postprocessor</span>.<span>PostProcessor</span>):
    <span>def</span> <span>run</span>(<span>self</span>, <span>info</span>):
        <span>self</span>.<span>to_screen</span>(<span>'Doing stuff'</span>)
        <span>return</span> [], <span>info</span>


<span>with</span> <span>yt_dlp</span>.<span>YoutubeDL</span>() <span>as</span> <span>ydl</span>:
    <span># ℹ️ "when" can take any value in yt_dlp.utils.POSTPROCESS_WHEN</span>
    <span>ydl</span>.<span>add_post_processor</span>(<span>MyCustomPP</span>(), <span>when</span><span>=</span><span>'pre_process'</span>)
    <span>ydl</span>.<span>download</span>(<span>URLS</span>)</pre></div>
<h4 tabindex="-1" dir="auto">Use a custom format selector</h4>
<div dir="auto" data-snippet-clipboard-copy-content="import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

def format_selector(ctx):
    &quot;&quot;&quot; Select the best video and the best audio that won't result in an mkv.
    NOTE: This is just an example and does not handle all cases &quot;&quot;&quot;

    # formats are already sorted worst to best
    formats = ctx.get('formats')[::-1]

    # acodec='none' means there is no audio
    best_video = next(f for f in formats
                      if f['vcodec'] != 'none' and f['acodec'] == 'none')

    # find compatible audio extension
    audio_ext = {'mp4': 'm4a', 'webm': 'webm'}[best_video['ext']]
    # vcodec='none' means there is no video
    best_audio = next(f for f in formats if (
        f['acodec'] != 'none' and f['vcodec'] == 'none' and f['ext'] == audio_ext))

    # These are the minimum required fields for a merged format
    yield {
        'format_id': f'{best_video[&quot;format_id&quot;]}+{best_audio[&quot;format_id&quot;]}',
        'ext': best_video['ext'],
        'requested_formats': [best_video, best_audio],
        # Must be + separated list of protocols
        'protocol': f'{best_video[&quot;protocol&quot;]}+{best_audio[&quot;protocol&quot;]}'
    }


ydl_opts = {
    'format': format_selector,
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    ydl.download(URLS)"><pre><span>import</span> <span>yt_dlp</span>

<span>URLS</span> <span>=</span> [<span>'https://www.youtube.com/watch?v=BaW_jenozKc'</span>]

<span>def</span> <span>format_selector</span>(<span>ctx</span>):
    <span>""" Select the best video and the best audio that won't result in an mkv.</span>
<span>    NOTE: This is just an example and does not handle all cases """</span>

    <span># formats are already sorted worst to best</span>
    <span>formats</span> <span>=</span> <span>ctx</span>.<span>get</span>(<span>'formats'</span>)[::<span>-</span><span>1</span>]

    <span># acodec='none' means there is no audio</span>
    <span>best_video</span> <span>=</span> <span>next</span>(<span>f</span> <span>for</span> <span>f</span> <span>in</span> <span>formats</span>
                      <span>if</span> <span>f</span>[<span>'vcodec'</span>] <span>!=</span> <span>'none'</span> <span>and</span> <span>f</span>[<span>'acodec'</span>] <span>==</span> <span>'none'</span>)

    <span># find compatible audio extension</span>
    <span>audio_ext</span> <span>=</span> {<span>'mp4'</span>: <span>'m4a'</span>, <span>'webm'</span>: <span>'webm'</span>}[<span>best_video</span>[<span>'ext'</span>]]
    <span># vcodec='none' means there is no video</span>
    <span>best_audio</span> <span>=</span> <span>next</span>(<span>f</span> <span>for</span> <span>f</span> <span>in</span> <span>formats</span> <span>if</span> (
        <span>f</span>[<span>'acodec'</span>] <span>!=</span> <span>'none'</span> <span>and</span> <span>f</span>[<span>'vcodec'</span>] <span>==</span> <span>'none'</span> <span>and</span> <span>f</span>[<span>'ext'</span>] <span>==</span> <span>audio_ext</span>))

    <span># These are the minimum required fields for a merged format</span>
    <span>yield</span> {
        <span>'format_id'</span>: <span>f'<span><span>{</span><span>best_video</span>[<span>"format_id"</span>]<span>}</span></span>+<span><span>{</span><span>best_audio</span>[<span>"format_id"</span>]<span>}</span></span>'</span>,
        <span>'ext'</span>: <span>best_video</span>[<span>'ext'</span>],
        <span>'requested_formats'</span>: [<span>best_video</span>, <span>best_audio</span>],
        <span># Must be + separated list of protocols</span>
        <span>'protocol'</span>: <span>f'<span><span>{</span><span>best_video</span>[<span>"protocol"</span>]<span>}</span></span>+<span><span>{</span><span>best_audio</span>[<span>"protocol"</span>]<span>}</span></span>'</span>
    }


<span>ydl_opts</span> <span>=</span> {
    <span>'format'</span>: <span>format_selector</span>,
}

<span>with</span> <span>yt_dlp</span>.<span>YoutubeDL</span>(<span>ydl_opts</span>) <span>as</span> <span>ydl</span>:
    <span>ydl</span>.<span>download</span>(<span>URLS</span>)</pre></div>

<h2 tabindex="-1" dir="auto">DEPRECATED OPTIONS</h2>
<p dir="auto">These are all the deprecated options and the current alternative to achieve the same effect</p>
<h4 tabindex="-1" dir="auto">Almost redundant options</h4>
<p dir="auto">While these options are almost the same as their new counterparts, there are some differences that prevents them being redundant</p>
<div data-snippet-clipboard-copy-content="-j, --dump-json                  --print &quot;%()j&quot;
-F, --list-formats               --print formats_table
--list-thumbnails                --print thumbnails_table --print playlist:thumbnails_table
--list-subs                      --print automatic_captions_table --print subtitles_table"><pre><code>-j, --dump-json                  --print "%()j"
-F, --list-formats               --print formats_table
--list-thumbnails                --print thumbnails_table --print playlist:thumbnails_table
--list-subs                      --print automatic_captions_table --print subtitles_table
</code></pre></div>
<h4 tabindex="-1" dir="auto">Redundant options</h4>
<p dir="auto">While these options are redundant, they are still expected to be used due to their ease of use</p>
<div data-snippet-clipboard-copy-content="--get-description                --print description
--get-duration                   --print duration_string
--get-filename                   --print filename
--get-format                     --print format
--get-id                         --print id
--get-thumbnail                  --print thumbnail
-e, --get-title                  --print title
-g, --get-url                    --print urls
--match-title REGEX              --match-filter &quot;title ~= (?i)REGEX&quot;
--reject-title REGEX             --match-filter &quot;title !~= (?i)REGEX&quot;
--min-views COUNT                --match-filter &quot;view_count >=? COUNT&quot;
--max-views COUNT                --match-filter &quot;view_count <=? COUNT&quot;
--break-on-reject                Use --break-match-filter
--user-agent UA                  --add-header &quot;User-Agent:UA&quot;
--referer URL                    --add-header &quot;Referer:URL&quot;
--playlist-start NUMBER          -I NUMBER:
--playlist-end NUMBER            -I :NUMBER
--playlist-reverse               -I ::-1
--no-playlist-reverse            Default
--no-colors                      --color no_color"><pre><code>--get-description                --print description
--get-duration                   --print duration_string
--get-filename                   --print filename
--get-format                     --print format
--get-id                         --print id
--get-thumbnail                  --print thumbnail
-e, --get-title                  --print title
-g, --get-url                    --print urls
--match-title REGEX              --match-filter "title ~= (?i)REGEX"
--reject-title REGEX             --match-filter "title !~= (?i)REGEX"
--min-views COUNT                --match-filter "view_count &gt;=? COUNT"
--max-views COUNT                --match-filter "view_count &lt;=? COUNT"
--break-on-reject                Use --break-match-filter
--user-agent UA                  --add-header "User-Agent:UA"
--referer URL                    --add-header "Referer:URL"
--playlist-start NUMBER          -I NUMBER:
--playlist-end NUMBER            -I :NUMBER
--playlist-reverse               -I ::-1
--no-playlist-reverse            Default
--no-colors                      --color no_color
</code></pre></div>
<h4 tabindex="-1" dir="auto">Not recommended</h4>
<p dir="auto">While these options still work, their use is not recommended since there are other alternatives to achieve the same</p>
<div data-snippet-clipboard-copy-content="--force-generic-extractor        --ies generic,default
--exec-before-download CMD       --exec &quot;before_dl:CMD&quot;
--no-exec-before-download        --no-exec
--all-formats                    -f all
--all-subs                       --sub-langs all --write-subs
--print-json                     -j --no-simulate
--autonumber-size NUMBER         Use string formatting, e.g. %(autonumber)03d
--autonumber-start NUMBER        Use internal field formatting like %(autonumber+NUMBER)s
--id                             -o &quot;%(id)s.%(ext)s&quot;
--metadata-from-title FORMAT     --parse-metadata &quot;%(title)s:FORMAT&quot;
--hls-prefer-native              --downloader &quot;m3u8:native&quot;
--hls-prefer-ffmpeg              --downloader &quot;m3u8:ffmpeg&quot;
--list-formats-old               --compat-options list-formats (Alias: --no-list-formats-as-table)
--list-formats-as-table          --compat-options -list-formats [Default] (Alias: --no-list-formats-old)
--youtube-skip-dash-manifest     --extractor-args &quot;youtube:skip=dash&quot; (Alias: --no-youtube-include-dash-manifest)
--youtube-skip-hls-manifest      --extractor-args &quot;youtube:skip=hls&quot; (Alias: --no-youtube-include-hls-manifest)
--youtube-include-dash-manifest  Default (Alias: --no-youtube-skip-dash-manifest)
--youtube-include-hls-manifest   Default (Alias: --no-youtube-skip-hls-manifest)
--geo-bypass                     --xff &quot;default&quot;
--no-geo-bypass                  --xff &quot;never&quot;
--geo-bypass-country CODE        --xff CODE
--geo-bypass-ip-block IP_BLOCK   --xff IP_BLOCK"><pre><code>--force-generic-extractor        --ies generic,default
--exec-before-download CMD       --exec "before_dl:CMD"
--no-exec-before-download        --no-exec
--all-formats                    -f all
--all-subs                       --sub-langs all --write-subs
--print-json                     -j --no-simulate
--autonumber-size NUMBER         Use string formatting, e.g. %(autonumber)03d
--autonumber-start NUMBER        Use internal field formatting like %(autonumber+NUMBER)s
--id                             -o "%(id)s.%(ext)s"
--metadata-from-title FORMAT     --parse-metadata "%(title)s:FORMAT"
--hls-prefer-native              --downloader "m3u8:native"
--hls-prefer-ffmpeg              --downloader "m3u8:ffmpeg"
--list-formats-old               --compat-options list-formats (Alias: --no-list-formats-as-table)
--list-formats-as-table          --compat-options -list-formats [Default] (Alias: --no-list-formats-old)
--youtube-skip-dash-manifest     --extractor-args "youtube:skip=dash" (Alias: --no-youtube-include-dash-manifest)
--youtube-skip-hls-manifest      --extractor-args "youtube:skip=hls" (Alias: --no-youtube-include-hls-manifest)
--youtube-include-dash-manifest  Default (Alias: --no-youtube-skip-dash-manifest)
--youtube-include-hls-manifest   Default (Alias: --no-youtube-skip-hls-manifest)
--geo-bypass                     --xff "default"
--no-geo-bypass                  --xff "never"
--geo-bypass-country CODE        --xff CODE
--geo-bypass-ip-block IP_BLOCK   --xff IP_BLOCK
</code></pre></div>
<h4 tabindex="-1" dir="auto">Developer options</h4>
<p dir="auto">These options are not intended to be used by the end-user</p>
<div data-snippet-clipboard-copy-content="--test                           Download only part of video for testing extractors
--load-pages                     Load pages dumped by --write-pages
--youtube-print-sig-code         For testing youtube signatures
--allow-unplayable-formats       List unplayable formats also
--no-allow-unplayable-formats    Default"><pre><code>--test                           Download only part of video for testing extractors
--load-pages                     Load pages dumped by --write-pages
--youtube-print-sig-code         For testing youtube signatures
--allow-unplayable-formats       List unplayable formats also
--no-allow-unplayable-formats    Default
</code></pre></div>
<h4 tabindex="-1" dir="auto">Old aliases</h4>
<p dir="auto">These are aliases that are no longer documented for various reasons</p>
<div data-snippet-clipboard-copy-content="--avconv-location                --ffmpeg-location
--clean-infojson                 --clean-info-json
--cn-verification-proxy URL      --geo-verification-proxy URL
--dump-headers                   --print-traffic
--dump-intermediate-pages        --dump-pages
--force-write-download-archive   --force-write-archive
--load-info                      --load-info-json
--no-clean-infojson              --no-clean-info-json
--no-split-tracks                --no-split-chapters
--no-write-srt                   --no-write-subs
--prefer-unsecure                --prefer-insecure
--rate-limit RATE                --limit-rate RATE
--split-tracks                   --split-chapters
--srt-lang LANGS                 --sub-langs LANGS
--trim-file-names LENGTH         --trim-filenames LENGTH
--write-srt                      --write-subs
--yes-overwrites                 --force-overwrites"><pre><code>--avconv-location                --ffmpeg-location
--clean-infojson                 --clean-info-json
--cn-verification-proxy URL      --geo-verification-proxy URL
--dump-headers                   --print-traffic
--dump-intermediate-pages        --dump-pages
--force-write-download-archive   --force-write-archive
--load-info                      --load-info-json
--no-clean-infojson              --no-clean-info-json
--no-split-tracks                --no-split-chapters
--no-write-srt                   --no-write-subs
--prefer-unsecure                --prefer-insecure
--rate-limit RATE                --limit-rate RATE
--split-tracks                   --split-chapters
--srt-lang LANGS                 --sub-langs LANGS
--trim-file-names LENGTH         --trim-filenames LENGTH
--write-srt                      --write-subs
--yes-overwrites                 --force-overwrites
</code></pre></div>
<h4 tabindex="-1" dir="auto">Sponskrub Options</h4>
<p dir="auto">Support for <a href="https://github.com/faissaloo/SponSkrub">SponSkrub</a> has been deprecated in favor of the <code>--sponsorblock</code> options</p>
<div data-snippet-clipboard-copy-content="--sponskrub                      --sponsorblock-mark all
--no-sponskrub                   --no-sponsorblock
--sponskrub-cut                  --sponsorblock-remove all
--no-sponskrub-cut               --sponsorblock-remove -all
--sponskrub-force                Not applicable
--no-sponskrub-force             Not applicable
--sponskrub-location             Not applicable
--sponskrub-args                 Not applicable"><pre><code>--sponskrub                      --sponsorblock-mark all
--no-sponskrub                   --no-sponsorblock
--sponskrub-cut                  --sponsorblock-remove all
--no-sponskrub-cut               --sponsorblock-remove -all
--sponskrub-force                Not applicable
--no-sponskrub-force             Not applicable
--sponskrub-location             Not applicable
--sponskrub-args                 Not applicable
</code></pre></div>
<h4 tabindex="-1" dir="auto">No longer supported</h4>
<p dir="auto">These options may no longer work as intended</p>
<div data-snippet-clipboard-copy-content="--prefer-avconv                  avconv is not officially supported by yt-dlp (Alias: --no-prefer-ffmpeg)
--prefer-ffmpeg                  Default (Alias: --no-prefer-avconv)
-C, --call-home                  Not implemented
--no-call-home                   Default
--include-ads                    No longer supported
--no-include-ads                 Default
--write-annotations              No supported site has annotations now
--no-write-annotations           Default
--compat-options seperate-video-versions  No longer needed"><pre><code>--prefer-avconv                  avconv is not officially supported by yt-dlp (Alias: --no-prefer-ffmpeg)
--prefer-ffmpeg                  Default (Alias: --no-prefer-avconv)
-C, --call-home                  Not implemented
--no-call-home                   Default
--include-ads                    No longer supported
--no-include-ads                 Default
--write-annotations              No supported site has annotations now
--no-write-annotations           Default
--compat-options seperate-video-versions  No longer needed
</code></pre></div>
<h4 tabindex="-1" dir="auto">Removed</h4>
<p dir="auto">These options were deprecated since 2014 and have now been entirely removed</p>
<div data-snippet-clipboard-copy-content="-A, --auto-number                -o &quot;%(autonumber)s-%(id)s.%(ext)s&quot;
-t, -l, --title, --literal       -o &quot;%(title)s-%(id)s.%(ext)s&quot;"><pre><code>-A, --auto-number                -o "%(autonumber)s-%(id)s.%(ext)s"
-t, -l, --title, --literal       -o "%(title)s-%(id)s.%(ext)s"
</code></pre></div>
<h2 tabindex="-1" dir="auto">CONTRIBUTING</h2>
<p dir="auto">See <a href="https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#contributing-to-yt-dlp">CONTRIBUTING.md</a> for instructions on <a href="https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#opening-an-issue">Opening an Issue</a> and <a href="https://github.com/yt-dlp/yt-dlp/blob/master/CONTRIBUTING.md#developer-instructions">Contributing code to the project</a></p>
<h2 tabindex="-1" dir="auto">WIKI</h2>
<p dir="auto">See the <a href="https://github.com/yt-dlp/yt-dlp/wiki">Wiki</a> for more information</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Power of Prolog (230 pts)]]></title>
            <link>https://www.metalevel.at/prolog/facets</link>
            <guid>37473933</guid>
            <pubDate>Mon, 11 Sep 2023 21:25:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.metalevel.at/prolog/facets">https://www.metalevel.at/prolog/facets</a>, See on <a href="https://news.ycombinator.com/item?id=37473933">Hacker News</a></p>
<div id="readability-page-1" class="page">

    <center></center>
    <table>
      <tbody><tr>
        <td><i>Video</i>:</td>
        <td><a href="https://www.metalevel.at/prolog/videos/tour"><img src="https://www.metalevel.at/prolog/videos/t_tour.png" alt="A Tour of Prolog"></a>
        </td>
      </tr>
    </tbody></table>

    <h2>Prolog is ...</h2>

    <ul>
      <li>... a very <a href="#simple"><b>simple</b></a> language</li>
      <li>... a <a href="#declarative"><b>declarative</b></a> language</li>
      <li>... a <a href="#logic"><b>logic programming</b></a> language</li>
      <li>... a <a href="#homoiconic"><b>homoiconic</b></a> language</li>
      <li>... a very <a href="#dynamic"><b>dynamic</b></a> language</li>
      <li>... a very <a href="#versatile"><b>versatile</b></a> language.</li>
    </ul>
    

    <h2 id="simple"><center>Prolog is a very simple language</center></h2>

    It is easy to describe Prolog <b>syntax</b> in sufficient detail
    to start working with Prolog immediately.

    <p>

    All <a href="https://www.metalevel.at/prolog/data">data</a> are represented by
    Prolog&nbsp;<a href="https://www.metalevel.at/prolog/data#term"><b>terms</b></a>.

    </p><p>

    There is a single language element, called
    a <a href="https://www.metalevel.at/prolog/concepts#clause"><i>clause</i></a>. A clause is of the
    form:
    </p><p><b><tt>Head :- Body.</tt></b>
    </p>

    <br>

    This means that <b>if</b> <tt>Body</tt>
    holds, <b>then</b> <tt>Head</tt> holds. The infix
    operator <tt>(:-)/2</tt> represents an arrow from right to
    left:&nbsp;←.

    <p>

    If </p><tt>Head</tt> <i>always</i>
    holds, then <tt>:-&nbsp;Body</tt> can be&nbsp;<i>omitted</i>.

    <p>

    <i>The above is enough to write useful first Prolog programs.</i></p><p>

    <b>You may not believe this</b>, so witness the evidence: All
    programs presented in the following consist <i>only</i> of such
    clauses.

    </p><p>

    In fact, <i>all known computations</i> can be described in terms
    of such&nbsp;clauses, making Prolog
    a <a href="https://en.wikipedia.org/wiki/Turing_completeness">Turing&nbsp;complete</a>
    programming&nbsp;language. One way to implement a
    Turing&nbsp;machine in Prolog is to describe the <i>relation</i>
    between different&nbsp;states of the machine with clauses of the
    form "<i>If</i> the current state is&nbsp;</p><tt>S0</tt> <i>and</i>
    the symbol under the tape&nbsp;head is&nbsp;<tt>T</tt>, <i>and</i>
    ... <i>then</i> the next state is&nbsp;<tt>S</tt>".
    See <a href="https://www.metalevel.at/prolog/showcases/turing.pl"><tt>turing.pl</tt></a> for one
    implementation, and <a href="https://www.metalevel.at/tist/"><i>Thinking
    in&nbsp;States</i></a> for more information.

    <h2 id="declarative"><center>Prolog is a declarative language</center></h2>

    Prolog is a <i>declarative language</i>. This means that we focus
    on stating <i>what</i> we are interested in. We <a href="https://www.metalevel.at/prolog/writing">express
      what <i>holds</i></a> about solutions we want to find. We are less
    concerned about <i>how</i> the Prolog implementation finds these
    solutions.

    <p>

    This declarative nature often allows for very concise, clear and
    general specifications. It is unlikely that shorter formalisms
    that are equally clear and expressive exist.

    </p><p>

    For example, let us describe the <i>relation</i> between
    a <a href="https://www.metalevel.at/prolog/data#list">list</a> and its length,
    using <a href="https://www.metalevel.at/prolog/clpz">integer&nbsp;arithmetic</a>:

    </p><p><b>Note</b>: In <i>some</i> Prolog systems, you currently need to
      include a dedicated library to use declarative integer
      arithmetic. <a href="https://www.metalevel.at/prolog/clpz">More...</a>
    </p>

    <pre>list_length([], 0).
list_length([_|Ls], N) :-
        N #&gt; 0,
        N #= N0 + 1,
        list_length(Ls, N0).
    </pre>

    We can <a href="https://www.metalevel.at/prolog/reading#declarative"><b>read this declaratively</b></a> as follows:

    <ol>
      <li>The length of the <i>empty list</i>&nbsp;<tt>[]</tt> is &nbsp;0.</li>
      <li><b>If</b> the length of the list&nbsp;<tt>Ls</tt>
        is&nbsp;<tt>N0</tt> <b>and</b> <tt>N</tt>
        is <tt>N0+1</tt>, <b>then</b> the length
        of&nbsp;<tt>[_|Ls]</tt> is&nbsp;<tt>N</tt>. Further, this only
        holds <b>if</b> <tt>N</tt> is <i>greater than</i>&nbsp;0.
    </li></ol>

    When programming in Prolog, think in terms of <i>relations</i>
    between entities. Your programs will become very general with this
    approach. In the above example, it is tempting to think and say
    "We are computing the length of a list". And yes, it is true: We
    can indeed use the above definition to compute the length of
    a&nbsp;list:

    <pre>?- list_length([a,b,c], L).
   L = 3.
    </pre>

    However, this <i>imperative</i> reading does not do justice to
    what we have actually implemented, because the definition also
    covers several additional usage&nbsp;patterns. For
    example, <i>given</i> a specific length, we can ask <i>whether</i>
    there are lists of that length:

    <pre>?- list_length(Ls, 3).
   Ls = [_A,_B,_C]
;  false.
    </pre>

    Using the <b>most general query</b>, we can even ask for all
    answers that Prolog finds <i>in&nbsp;general</i>:

    <pre>?- list_length(Ls, L).
   Ls = [], L = 0
;  Ls = [_A], L = 1
;  Ls = [_A,_B], L = 2
;  Ls = [_A,_B,_C], L = 3
;  ... .
    </pre>

    We say that the relation is usable in different <i>modes</i>.
    Characteristically, Prolog reports all answers
    via&nbsp;<i>backtracking</i>.

    <p>

    The predicate </p><tt>length/2</tt> is part of
    the <a href="https://www.complang.tuwien.ac.at/ulrich/iso-prolog/prologue">Prologue
    for Prolog</a> draft, and already available as
    a <a href="https://www.metalevel.at/prolog/concepts#builtin">built-in</a> predicate in almost all
    Prolog implementations with the above semantics.

    <h2 id="logic"><center>Prolog is a logic programming language</center></h2>

    In the category of <i>declarative</i> languages, we
    find <i>functional</i> programming languages and <i>logic</i>
    programming languages. A function is a special case of a relation,
    and functional programming can be regarded as a restricted form of
    logic&nbsp;programming.

    <p>

    Prolog is firmly rooted in <a href="https://www.metalevel.at/prolog/logic"><b>logic</b></a>. </p><p>

    A <a href="https://www.metalevel.at/prolog/purity">pure</a> Prolog program consists of a set
    of <a href="https://en.wikipedia.org/wiki/Horn_clause">Horn&nbsp;clauses</a>.

    Its execution can be regarded as a special case
    of <a href="https://en.wikipedia.org/wiki/Resolution_(logic)"><i>resolution</i></a>.

    </p><p>

    This connection to formal logic allows us to apply powerful
    <a href="https://www.metalevel.at/prolog/debugging"><b>declarative&nbsp;debugging</b></a> techniques that
    are based on logical properties of the program.  For example,
    adding a <i>constraint</i> can at most <i>reduce</i> the set of
    solutions, and adding a&nbsp;<i>clause</i> can at most extend
    it. This property of pure Prolog programs is
    called <a href="https://en.wikipedia.org/wiki/Monotonicity_of_entailment">monotonicity</a>.

    </p><p>

    <i>See
      the <a href="https://www.complang.tuwien.ac.at/ulrich/gupu/"><b>GUPU
      system</b></a> by Ulrich Neumerkel for an impressive application
      of these&nbsp;ideas.</i></p><h2 id="homoiconic"><center>Prolog is a homoiconic language</center></h2>

    <p><i>homoiconic</i>: from ὁμός = "same" and εικών = "image"
    </p>
    <p>

    Prolog <i>programs</i> are also valid Prolog <i>terms</i>! This
    has many great advantages: It is easy to write Prolog programs
    that analyze, transform and interpret <i>other</i> Prolog
    programs. You can use the built-in predicate </p><tt>read/1</tt> to
    read a Prolog&nbsp;term, and thus also a Prolog&nbsp;clause.

    <p>

    There is a powerful <a href="https://www.metalevel.at/prolog/macros">mechanism</a> to rewrite
    Prolog programs at compilation time, so that you can easily
    implement domain-specific languages that help you solve your tasks
    more naturally.

    </p><p>
    <b>You may not believe this</b>, because some goals—such
    as </p><tt>list_length(Ls,&nbsp;N)</tt>—look like
    Prolog&nbsp;terms as defined above, whereas other goals—such
    as&nbsp;<tt>N&nbsp;#&gt;&nbsp;0</tt>—look quite different.
    The reason for this is that Prolog provides prefix, infix and
    postfix&nbsp;<i>operators</i> that let you write Prolog&nbsp;terms
    in a more readable way. For example, the Prolog
    term&nbsp;<tt>+(a,b)</tt> can also be written using
    operator&nbsp;notation as&nbsp;<tt>a+b</tt>.
    The <i>abstract&nbsp;syntax</i> remains completely uniform, and
    you can read and process all Prolog terms independent of how they
    are written&nbsp;down.

    <p>
    <i>You can dynamically define custom operators for specific use cases.</i></p><h2 id="dynamic"><center>Prolog is a very dynamic language</center></h2>

    Prolog programs can be easily created, called and modified <i>at
    run time</i>. This further increases the expressiveness of Prolog
    and lets you implement <a href="https://www.metalevel.at/prolog/metapredicates">higher-order
    predicates</a> which have other predicates as arguments. It also
    allows the implementation of very dynamic techniques
    like <i>adaptive&nbsp;parsing</i>.

    <p>

    The dynamic nature of Prolog also makes the language ideally
    suited for writing programs that are <i>extensible</i> by
    custom&nbsp;rules that other programmers and even regular users
    provide. <a href="https://www.metalevel.at/proloxy/"><b>Proloxy</b></a>
    and <a href="https://www.gerritcodereview.com/">Gerrit
    Code&nbsp;Review</a> are examples of this approach: You configure
    these programs by supplying
    Prolog&nbsp;<a href="https://www.metalevel.at/prolog/concepts#rule">rules</a> that express your
    requirements in a very readable and flexible&nbsp;way.

    </p><p>
    See <a href="https://www.metalevel.at/acomip/"><b>A Couple of
        Meta-interpreters in&nbsp;Prolog</b></a> for more information.

    </p><p>

    <i>You can define an interpreter for pure Prolog in two lines of
      Prolog&nbsp;code.</i></p><h2 id="versatile"><center>Prolog is a very versatile language</center></h2>

    Prolog is an extremely versatile language. Its relational nature
    makes Prolog programs very flexible and general. This plays an
    important role in <a href="https://www.metalevel.at/prolog/dcg">language processing</a> and
    knowledge representation
    in&nbsp;<a href="https://www.metalevel.at/prolog/business#database">databases</a>. Modern Prolog
    systems provide everything that is needed for solving
    simple <a href="https://www.metalevel.at/prolog/puzzles">logic&nbsp;puzzles</a> to building huge
    applications, ranging from
    <a href="https://www.metalevel.at/prolog/web">web&nbsp;hosting</a>
    to <a href="https://www.metalevel.at/prolog/theoremproving">verification</a>
    and <a href="https://www.metalevel.at/prolog/optimization">optimization</a> tasks.

    <p>

    Prolog's versatility and power are rooted in <i>implicit</i>
    mechanisms that include search, unification, argument indexing and
    constraint propagation. You can use these mechanisms to your
    advantage, and <i>delegate</i> many tasks to the
    Prolog&nbsp;engine.

    </p><table>
      <tbody><tr>
        <td><i>Video</i>:</td>
        <td><a href="https://www.metalevel.at/prolog/videos/sparrows_on_eagles"><img src="https://www.metalevel.at/prolog/videos/t_sparrows_on_eagles.png" alt="Sparrows on Eagles"></a>
        </td>
      </tr>
    </tbody></table>

    <p>

    <i>This page was sent to you by
      a <a href="https://www.metalevel.at/letswicrypt/"><b>Prolog&nbsp;HTTPS
      server</b></a>.</i></p><p>
    <b><a href="https://www.metalevel.at/prolog">More about Prolog</a></b></p><p>

    <b><a href="https://www.metalevel.at/">Main page</a></b></p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft to kill off third-party printer drivers in Windows (132 pts)]]></title>
            <link>https://www.theregister.com/2023/09/11/go_native_or_go_home/</link>
            <guid>37473628</guid>
            <pubDate>Mon, 11 Sep 2023 21:00:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/09/11/go_native_or_go_home/">https://www.theregister.com/2023/09/11/go_native_or_go_home/</a>, See on <a href="https://news.ycombinator.com/item?id=37473628">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Microsoft has made it clear: it will ax third-party printer drivers in Windows.</p>
<p>The death rattle will be lengthy, as the timeline for the end of servicing stretches into 2027 – although Microsoft noted that the dates will be subject to change. There is, after all, always that important customer with a strange old printer lacking Mopria support.</p>
<p><a target="_blank" rel="nofollow" href="https://mopria.org/mopria-alliance">Mopria</a> is part of the Windows' teams justification for removing support. Founded in 2013 by Canon, HP, Samsung and Xerox, the <a target="_blank" rel="nofollow" href="https://mopria.org/">Mopria Alliance</a>'s mission is to provide universal standards for printing and scanning. Epson, Lexmark, Adobe and Microsoft have also joined the gang since then.</p>

    

<p>Since Windows 10 21H2, Microsoft has baked Mopria support into the flagship operating system, with support for devices connected via the network or USB, thanks to the Microsoft IPP Class driver. Microsoft said: "This removes the need for print device manufacturers to provide their own installers, drivers, utilities, and so on."</p>

        


        

<p>The software giant also said that customization can be performed via Print Support Apps from the Windows Store. It added: "This framework improves reliability and performance by moving customization from the Win32 framework to the UWP software development framework."</p>
<p>While some wags have dubbed the framework the <a target="_blank" href="https://www.theregister.com/2021/10/26/microsofts_uwp_unwanted_windows_platform/">"Unwanted Windows Platform"</a>, it's always good to see legacy tech being retired in favor of something with a bright future ahead of it.</p>

        

<p>Microsoft's timeline for the end of servicing will be staged. The next milestone will occur in 2025 when no new printer drivers will be published to Windows Update – although existing drivers can still be updated. In 2026, driver ranking will be tweaked to bring the IPP inbox class driver to the top, and by 2027 – except for security-related fixes – no printer driver updates will be allowed.</p>
<ul>

<li><a href="https://www.theregister.com/2023/07/11/microsoft_patch_tuesday/">Miscreants exploit five Microsoft bugs as Windows giant addresses 130 flaws</a></li>

<li><a href="https://www.theregister.com/2022/12/05/opinion_column_printing/">Killing trees with lasers isn't cool, says Epson. So why are inkjets any better?</a></li>

<li><a href="https://www.theregister.com/2022/03/04/on_call/">Saving a loved one from a document disaster</a></li>

<li><a href="https://www.theregister.com/2021/10/18/windows_printing/">Microsoft admits to yet more printing problems in Windows as back-at-the-office folks asked for admin credentials</a></li>
</ul>
<p>To be clear, the end of servicing applies to drivers provided via Windows Update. Manufacturers will, according to Microsoft, "need to provide customers with an alternative means to download and install those printer drivers." Legacy v3 and v4 Windows printer drivers are facing the end of servicing ax.</p>
<p>Microsoft added that multi-function devices – print, scan and fax – will work via the inbox drivers.</p>
<p>Printing and Windows have <a target="_blank" href="https://www.theregister.com/2022/07/26/windows_10_printer_bork/">long been uneasy bedfellows</a>. While Microsoft hopes the end-of-servicing will take away some legacy driver headaches, there are plenty of other components within the Windows printing subsystem that can <a target="_blank" href="https://www.theregister.com/2021/10/18/windows_printing/">occasionally topple</a> when poked the wrong way by a patch. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[uBlock-Origin – 1.52.0 (222 pts)]]></title>
            <link>https://github.com/gorhill/uBlock/releases/tag/1.52.0</link>
            <guid>37472994</guid>
            <pubDate>Mon, 11 Sep 2023 20:13:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/gorhill/uBlock/releases/tag/1.52.0">https://github.com/gorhill/uBlock/releases/tag/1.52.0</a>, See on <a href="https://news.ycombinator.com/item?id=37472994">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:gorhill/uBlock" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="x8C6R9GJSwffziApgP8Nx1Hb5B4IUBkEuexf3bwqIz2-7Feg9FkhJtAX9lTquRZnH9DjGw5zPjEi5JI5gpqigg" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="gorhill/uBlock" data-current-org="" data-current-owner="gorhill" data-logged-in="false">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="feedback-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      
      
</modal-dialog></div>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="custom-scopes-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      
      
</modal-dialog></div>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Freleases%2Fshow&amp;source=header-repo&amp;source_repo=gorhill%2FuBlock" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/gorhill/uBlock/releases/tag/1.52.0&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="2f3c5dde8d1530c1097543858fcd6094e612f73a18c39160cb2954947a81a077" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/releases/show;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div></div>]]></description>
        </item>
    </channel>
</rss>