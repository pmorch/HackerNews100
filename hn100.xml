<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 20 Aug 2024 17:30:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[The anatomy of a 2AM mental breakdown (236 pts)]]></title>
            <link>https://zarar.dev/anatomy-of-a-mental-breakdown/</link>
            <guid>41300368</guid>
            <pubDate>Tue, 20 Aug 2024 14:25:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zarar.dev/anatomy-of-a-mental-breakdown/">https://zarar.dev/anatomy-of-a-mental-breakdown/</a>, See on <a href="https://news.ycombinator.com/item?id=41300368">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    







<p>
    <i>
        <time datetime="2024-08-20T13:15Z">
            20 Aug, 2024
        </time>
    </i>
</p>


    <p>Around 2AM this morning I had a realization that this was the most stressed I have ever been. On verge of a complete breakdown.</p>
<p>Why? Because I noticed around 10PM that jumpcomedy.com was entirely broken with all HTTP POST calls made by RTK Query failing. Nothing worked and though I had deployed recent changes, none of them would cause this. I was at a complete loss as to where to look, especially as this is working locally. Posting on the usual Discords (NextJS, Vercel) is leading to dead silence. I'm alone and have to fix this issue which I didn't cause.</p>
<p>This isn't the first production defect I've introduced in my 25 years of working, but this is the first one where I had absolutely nobody to turn to in a time of crisis while customer complaints are piling up at a rate never seen before. No production support, no SRE, no Sr. Engineer, no manager to make it go away. Nothing. And here's the worst part: people who have taken a chance on me to the point where their entire small businesses depend on me are sad. Not only do I have no idea how to fix this, I'm also hurting people. This absolutely sucks. I felt shame, sorrow, and incompetence. Oh the incompetence and the imposter syndrome that comes with it.</p>
<p>The thoughts that were crossing my mind were bizarre: do I just shut this business down? Do I send a mass apology email to my customers and just ask them to pick a different event management provider? What do I do because I don't know where to look and it's been four hours already.</p>
<p>Enter Eminem. <em>Alright, calm down, relax, start breathin'</em></p>
<p>I started breathing but it didn't help a damn as I still didn't know what the issue was. No matter how many <code>console.log()</code> statements I sprinkled around, nothing made sense. Was it the headers, the length of the API token, the sequence of calls...but it was just working. Why? WHY? WHY???? IS THIS HAPPENING? And why are GET and DELETE calls working?</p>
<p>It's OK. The world won't end. So what if your business entirely fails and you're paraded at the next tech conference as a case of what not to do. Oh well, that's your destiny, just deal with it BUT right now deal with this goddamn bug that you didn't cause but have to suffer through. The only clue I have is that it's working on localhost, which reminded me of that old joke where during a production outage the junior developer tells his boss, "but it's working on my machine". Well buddy, you're the junior developer. Also, you're a sack of shit. No, no, don't go there. There's plenty of time for self-reflection and self-hate later, but right now just see why those cursed POST calls are failing with:</p>
<p><em>TypeError: failed to execute 'fetch' on 'window': …with a request object that has already been used</em></p>
<p>Now that error message is a complete red herring and tells me nothing. It may as well have said, "The Lannisters refuse to pay their debts and flight UA763 from Miami is delayed".</p>
<p>Haha. I start making jokes to add some levity to the situation. It's not so bad, life is about nature and trees and sooner this business shuts down and you take a boat to a deserted island, the sooner you can start your memoirs and the first chapter of the memoir would be: <em>TypeError: failed to execute 'fetch'</em>.</p>
<p>My wife. Oh my poor wife. She offered me a cup of tea and ruffled my hair. "It's OK, big companies have production outages too". Ah, that's so sweet of her. I told her to go to bed while I question every major life decision leading up to this moment. Oh shit, what's this? It's customer emails piling up in my inbox. Lovely.</p>
<p>"Hey Zarar, I can't change the the price of my event"</p>
<p>"Hi Zarar, I'm trying to remove a promo code and it won't let me"</p>
<p>....</p>
<p>Please, can I just delete my email at this point and take a bus to the northern wilderness? Because I still have no clue what's going on and now I'm thinking maybe I should take that break to clear my head.  You know, like they say in those self-help books, but what they don't say is that every five minutes I'm getting an email saying something's broken and my response is basically, "I apologize. Working on it". But I'm not working on it, I'm just staring at the screen putting debug statements where I feel Chrome Inspector is saying, "Bro you serious? You think there's a bug on <em>this</em> line?"</p>
<p>Ah, what's this? A Chrome update came in today? Could that have caused it? Hmmm...hope, I see hope.  DASHED. HOPE IS DASHED! This is reproducible in Firefox and Edge. Edge? Even Edge is like WTF.  Back to console.log() and break points. Now I'm dealing with source maps and libraries that don't publish source maps so now I'm looking at code that looks like this:</p>
<div><pre><span></span>eC=Math.random().toString(36).slice(2),eE="__reactFiber$"+eC,ex="__reactProps$"+eC,ez="__reactContainer$"+eC,eP="__reactEvents$"+eC,eN="__reactListeners$"+eC,e_="__reactHandles$"+eC,eL="__reactResources$"+eC,eT="__reactMarker$"+eC;
</pre></div>
<p>This is no good. Let me just try reverting to a version from a month ago. Nothing. Three months ago? Nothing. Still failing. A year ago? Zilch.</p>
<p>OK, so you re-ask the question what's happening in prod that's happening locally. Or vice-versa. Some candidates:</p>
<ul>
<li>Sentry is disabled locally</li>
<li>Databases are pointing to docker instead of cloud providers</li>
<li>Cloudflare’s a proxy</li>
</ul>
<p>Got rid of Sentry in production. Nothing. Pointed to PROD databases locally. Nothing. Disable Cloudflare. Makes no matter. Maybe I should take that break, if only to calculate the financial damage and the much more significant reputational damage.</p>
<p>What else is different? Maybe PostHog, I have the api_key blanked out locally to reduce costs, so let me just add it to see what gives. Shot in the dark. 1 in a million chance. Let's do it.</p>
<p>WHAT?! REPRODUCED ON LOCALHOST. GIVE ME THAT FUCKING CUP OF TEA NOW!</p>
<p>Next commit: take out PostHog and everything is working.</p>
<p>At this point I'm thinking all the people I've recommended PostHog to as this "amazing tool which <em>shows</em> you what your users are experiencing". How naive I was? Right now I hate PostHog more than anything and can't believe I was about to pay for that product (still a good product, I'm overreacting here). But still, in the moment I wanted to burn the company down.</p>
<p>But I did feel good about finding the defect because soon after many people reported the same:</p>
<p><a href="https://github.com/PostHog/posthog/issues/24471">https://github.com/PostHog/posthog/issues/24471</a></p>
<p><a href="https://github.com/reduxjs/redux-toolkit/issues/4573">https://github.com/reduxjs/redux-toolkit/issues/4573</a></p>
<p>So that was my night!</p>
<h4 id="subscribe-to-my-blog">Subscribe to my blog</h4>

<p>There's also the <a href="https://zarar.dev/feed/">RSS feed</a>.</p>





    

    
    


    



  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[1953 US Navy training film on mechanical computers [video] (187 pts)]]></title>
            <link>https://www.youtube.com/watch?v=gwf5mAlI7Ug</link>
            <guid>41299211</guid>
            <pubDate>Tue, 20 Aug 2024 12:02:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=gwf5mAlI7Ug">https://www.youtube.com/watch?v=gwf5mAlI7Ug</a>, See on <a href="https://news.ycombinator.com/item?id=41299211">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Transformers for Ruby (163 pts)]]></title>
            <link>https://github.com/ankane/transformers-ruby</link>
            <guid>41299148</guid>
            <pubDate>Tue, 20 Aug 2024 11:54:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ankane/transformers-ruby">https://github.com/ankane/transformers-ruby</a>, See on <a href="https://news.ycombinator.com/item?id=41299148">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Transformers.rb</h2><a id="user-content-transformersrb" aria-label="Permalink: Transformers.rb" href="#transformersrb"></a></p>
<p dir="auto">🙂 State-of-the-art <a href="https://github.com/huggingface/transformers">transformers</a> for Ruby</p>
<p dir="auto"><a href="https://github.com/ankane/transformers-ruby/actions"><img src="https://github.com/ankane/transformers-ruby/actions/workflows/build.yml/badge.svg" alt="Build Status"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">First, <a href="https://github.com/ankane/torch.rb#installation">install Torch.rb</a>.</p>
<p dir="auto">Then add this line to your application’s Gemfile:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<ul dir="auto">
<li><a href="#models">Models</a></li>
<li><a href="#pipelines">Pipelines</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Models</h2><a id="user-content-models" aria-label="Permalink: Models" href="#models"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">sentence-transformers/all-MiniLM-L6-v2</h3><a id="user-content-sentence-transformersall-minilm-l6-v2" aria-label="Permalink: sentence-transformers/all-MiniLM-L6-v2" href="#sentence-transformersall-minilm-l6-v2"></a></p>
<p dir="auto"><a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2" rel="nofollow">Docs</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="sentences = [&quot;This is an example sentence&quot;, &quot;Each sentence is converted&quot;]

model = Transformers::SentenceTransformer.new(&quot;sentence-transformers/all-MiniLM-L6-v2&quot;)
embeddings = model.encode(sentences)"><pre><span>sentences</span> <span>=</span> <span>[</span><span>"This is an example sentence"</span><span>,</span> <span>"Each sentence is converted"</span><span>]</span>

<span>model</span> <span>=</span> <span>Transformers</span>::<span>SentenceTransformer</span><span>.</span><span>new</span><span>(</span><span>"sentence-transformers/all-MiniLM-L6-v2"</span><span>)</span>
<span>embeddings</span> <span>=</span> <span>model</span><span>.</span><span>encode</span><span>(</span><span>sentences</span><span>)</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">sentence-transformers/multi-qa-MiniLM-L6-cos-v1</h3><a id="user-content-sentence-transformersmulti-qa-minilm-l6-cos-v1" aria-label="Permalink: sentence-transformers/multi-qa-MiniLM-L6-cos-v1" href="#sentence-transformersmulti-qa-minilm-l6-cos-v1"></a></p>
<p dir="auto"><a href="https://huggingface.co/sentence-transformers/multi-qa-MiniLM-L6-cos-v1" rel="nofollow">Docs</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="query = &quot;How many people live in London?&quot;
docs = [&quot;Around 9 Million people live in London&quot;, &quot;London is known for its financial district&quot;]

model = Transformers::SentenceTransformer.new(&quot;sentence-transformers/multi-qa-MiniLM-L6-cos-v1&quot;)
query_emb = model.encode(query)
doc_emb = model.encode(docs)
scores = Torch.mm(Torch.tensor([query_emb]), Torch.tensor(doc_emb).transpose(0, 1))[0].cpu.to_a
doc_score_pairs = docs.zip(scores).sort_by { |d, s| -s }"><pre><span>query</span> <span>=</span> <span>"How many people live in London?"</span>
<span>docs</span> <span>=</span> <span>[</span><span>"Around 9 Million people live in London"</span><span>,</span> <span>"London is known for its financial district"</span><span>]</span>

<span>model</span> <span>=</span> <span>Transformers</span>::<span>SentenceTransformer</span><span>.</span><span>new</span><span>(</span><span>"sentence-transformers/multi-qa-MiniLM-L6-cos-v1"</span><span>)</span>
<span>query_emb</span> <span>=</span> <span>model</span><span>.</span><span>encode</span><span>(</span><span>query</span><span>)</span>
<span>doc_emb</span> <span>=</span> <span>model</span><span>.</span><span>encode</span><span>(</span><span>docs</span><span>)</span>
<span>scores</span> <span>=</span> <span>Torch</span><span>.</span><span>mm</span><span>(</span><span>Torch</span><span>.</span><span>tensor</span><span>(</span><span>[</span><span>query_emb</span><span>]</span><span>)</span><span>,</span> <span>Torch</span><span>.</span><span>tensor</span><span>(</span><span>doc_emb</span><span>)</span><span>.</span><span>transpose</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>)</span><span>)</span><span>[</span><span>0</span><span>]</span><span>.</span><span>cpu</span><span>.</span><span>to_a</span>
<span>doc_score_pairs</span> <span>=</span> <span>docs</span><span>.</span><span>zip</span><span>(</span><span>scores</span><span>)</span><span>.</span><span>sort_by</span> <span>{</span> |<span>d</span><span>,</span> <span>s</span>| -<span>s</span> <span>}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">mixedbread-ai/mxbai-embed-large-v1</h3><a id="user-content-mixedbread-aimxbai-embed-large-v1" aria-label="Permalink: mixedbread-ai/mxbai-embed-large-v1" href="#mixedbread-aimxbai-embed-large-v1"></a></p>
<p dir="auto"><a href="https://huggingface.co/mixedbread-ai/mxbai-embed-large-v1" rel="nofollow">Docs</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="def transform_query(query)
  &quot;Represent this sentence for searching relevant passages: #{query}&quot;
end

docs = [
  transform_query(&quot;puppy&quot;),
  &quot;The dog is barking&quot;,
  &quot;The cat is purring&quot;
]

model = Transformers::SentenceTransformer.new(&quot;mixedbread-ai/mxbai-embed-large-v1&quot;)
embeddings = model.encode(docs)"><pre><span>def</span> <span>transform_query</span><span>(</span><span>query</span><span>)</span>
  <span>"Represent this sentence for searching relevant passages: <span><span>#{</span><span>query</span><span>}</span></span>"</span>
<span>end</span>

<span>docs</span> <span>=</span> <span>[</span>
  <span>transform_query</span><span>(</span><span>"puppy"</span><span>)</span><span>,</span>
  <span>"The dog is barking"</span><span>,</span>
  <span>"The cat is purring"</span>
<span>]</span>

<span>model</span> <span>=</span> <span>Transformers</span>::<span>SentenceTransformer</span><span>.</span><span>new</span><span>(</span><span>"mixedbread-ai/mxbai-embed-large-v1"</span><span>)</span>
<span>embeddings</span> <span>=</span> <span>model</span><span>.</span><span>encode</span><span>(</span><span>docs</span><span>)</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">opensearch-project/opensearch-neural-sparse-encoding-v1</h3><a id="user-content-opensearch-projectopensearch-neural-sparse-encoding-v1" aria-label="Permalink: opensearch-project/opensearch-neural-sparse-encoding-v1" href="#opensearch-projectopensearch-neural-sparse-encoding-v1"></a></p>
<p dir="auto"><a href="https://huggingface.co/opensearch-project/opensearch-neural-sparse-encoding-v1" rel="nofollow">Docs</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="docs = [&quot;The dog is barking&quot;, &quot;The cat is purring&quot;, &quot;The bear is growling&quot;]

model_id = &quot;opensearch-project/opensearch-neural-sparse-encoding-v1&quot;
model = Transformers::AutoModelForMaskedLM.from_pretrained(model_id)
tokenizer = Transformers::AutoTokenizer.from_pretrained(model_id)
special_token_ids = tokenizer.special_tokens_map.map { |_, token| tokenizer.vocab[token] }

feature = tokenizer.(docs, padding: true, truncation: true, return_tensors: &quot;pt&quot;, return_token_type_ids: false)
output = model.(**feature)[0]

values, _ = Torch.max(output * feature[:attention_mask].unsqueeze(-1), dim: 1)
values = Torch.log(1 + Torch.relu(values))
values[0.., special_token_ids] = 0
embeddings = values.to_a"><pre><span>docs</span> <span>=</span> <span>[</span><span>"The dog is barking"</span><span>,</span> <span>"The cat is purring"</span><span>,</span> <span>"The bear is growling"</span><span>]</span>

<span>model_id</span> <span>=</span> <span>"opensearch-project/opensearch-neural-sparse-encoding-v1"</span>
<span>model</span> <span>=</span> <span>Transformers</span>::<span>AutoModelForMaskedLM</span><span>.</span><span>from_pretrained</span><span>(</span><span>model_id</span><span>)</span>
<span>tokenizer</span> <span>=</span> <span>Transformers</span>::<span>AutoTokenizer</span><span>.</span><span>from_pretrained</span><span>(</span><span>model_id</span><span>)</span>
<span>special_token_ids</span> <span>=</span> <span>tokenizer</span><span>.</span><span>special_tokens_map</span><span>.</span><span>map</span> <span>{</span> |<span>_</span><span>,</span> <span>token</span>| <span>tokenizer</span><span>.</span><span>vocab</span><span>[</span><span>token</span><span>]</span> <span>}</span>

<span>feature</span> <span>=</span> <span>tokenizer</span><span>.</span><span>(</span><span>docs</span><span>,</span> <span>padding</span>: <span>true</span><span>,</span> <span>truncation</span>: <span>true</span><span>,</span> <span>return_tensors</span>: <span>"pt"</span><span>,</span> <span>return_token_type_ids</span>: <span>false</span><span>)</span>
<span>output</span> <span>=</span> <span>model</span><span>.</span><span>(</span>**<span>feature</span><span>)</span><span>[</span><span>0</span><span>]</span>

<span>values</span><span>,</span> <span>_</span> <span>=</span> <span>Torch</span><span>.</span><span>max</span><span>(</span><span>output</span> * <span>feature</span><span>[</span><span>:attention_mask</span><span>]</span><span>.</span><span>unsqueeze</span><span>(</span>-<span>1</span><span>)</span><span>,</span> <span>dim</span>: <span>1</span><span>)</span>
<span>values</span> <span>=</span> <span>Torch</span><span>.</span><span>log</span><span>(</span><span>1</span> + <span>Torch</span><span>.</span><span>relu</span><span>(</span><span>values</span><span>)</span><span>)</span>
<span>values</span><span>[</span><span>0</span>..<span>,</span> <span>special_token_ids</span><span>]</span> <span>=</span> <span>0</span>
<span>embeddings</span> <span>=</span> <span>values</span><span>.</span><span>to_a</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Pipelines</h2><a id="user-content-pipelines" aria-label="Permalink: Pipelines" href="#pipelines"></a></p>
<p dir="auto">Named-entity recognition</p>
<div dir="auto" data-snippet-clipboard-copy-content="ner = Transformers.pipeline(&quot;ner&quot;)
ner.(&quot;Ruby is a programming language created by Matz&quot;)"><pre><span>ner</span> <span>=</span> <span>Transformers</span><span>.</span><span>pipeline</span><span>(</span><span>"ner"</span><span>)</span>
<span>ner</span><span>.</span><span>(</span><span>"Ruby is a programming language created by Matz"</span><span>)</span></pre></div>
<p dir="auto">Sentiment analysis</p>
<div dir="auto" data-snippet-clipboard-copy-content="classifier = Transformers.pipeline(&quot;sentiment-analysis&quot;)
classifier.(&quot;We are very happy to show you the 🤗 Transformers library.&quot;)"><pre><span>classifier</span> <span>=</span> <span>Transformers</span><span>.</span><span>pipeline</span><span>(</span><span>"sentiment-analysis"</span><span>)</span>
<span>classifier</span><span>.</span><span>(</span><span>"We are very happy to show you the 🤗 Transformers library."</span><span>)</span></pre></div>
<p dir="auto">Question answering</p>
<div dir="auto" data-snippet-clipboard-copy-content="qa = Transformers.pipeline(&quot;question-answering&quot;)
qa.(question: &quot;Who invented Ruby?&quot;, context: &quot;Ruby is a programming language created by Matz&quot;)"><pre><span>qa</span> <span>=</span> <span>Transformers</span><span>.</span><span>pipeline</span><span>(</span><span>"question-answering"</span><span>)</span>
<span>qa</span><span>.</span><span>(</span><span>question</span>: <span>"Who invented Ruby?"</span><span>,</span> <span>context</span>: <span>"Ruby is a programming language created by Matz"</span><span>)</span></pre></div>
<p dir="auto">Feature extraction</p>
<div dir="auto" data-snippet-clipboard-copy-content="extractor = Transformers.pipeline(&quot;feature-extraction&quot;)
extractor.(&quot;We are very happy to show you the 🤗 Transformers library.&quot;)"><pre><span>extractor</span> <span>=</span> <span>Transformers</span><span>.</span><span>pipeline</span><span>(</span><span>"feature-extraction"</span><span>)</span>
<span>extractor</span><span>.</span><span>(</span><span>"We are very happy to show you the 🤗 Transformers library."</span><span>)</span></pre></div>
<p dir="auto">Image classification</p>
<div dir="auto" data-snippet-clipboard-copy-content="classifier = Transformers.pipeline(&quot;image-classification&quot;)
classifier.(URI(&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg&quot;))"><pre><span>classifier</span> <span>=</span> <span>Transformers</span><span>.</span><span>pipeline</span><span>(</span><span>"image-classification"</span><span>)</span>
<span>classifier</span><span>.</span><span>(</span><span>URI</span><span>(</span><span>"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"</span><span>)</span><span>)</span></pre></div>
<p dir="auto">Image feature extraction</p>
<div dir="auto" data-snippet-clipboard-copy-content="extractor = Transformers.pipeline(&quot;image-feature-extraction&quot;)
extractor.(URI(&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg&quot;))"><pre><span>extractor</span> <span>=</span> <span>Transformers</span><span>.</span><span>pipeline</span><span>(</span><span>"image-feature-extraction"</span><span>)</span>
<span>extractor</span><span>.</span><span>(</span><span>URI</span><span>(</span><span>"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"</span><span>)</span><span>)</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">API</h2><a id="user-content-api" aria-label="Permalink: API" href="#api"></a></p>
<p dir="auto">This library follows the <a href="https://huggingface.co/docs/transformers/index" rel="nofollow">Transformers Python API</a>. Only a few model architectures are currently supported:</p>
<ul dir="auto">
<li>BERT</li>
<li>DistilBERT</li>
<li>ViT</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">History</h2><a id="user-content-history" aria-label="Permalink: History" href="#history"></a></p>
<p dir="auto">View the <a href="https://github.com/ankane/transformers-ruby/blob/master/CHANGELOG.md">changelog</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Everyone is encouraged to help improve this project. Here are a few ways you can help:</p>
<ul dir="auto">
<li><a href="https://github.com/ankane/transformers-ruby/issues">Report bugs</a></li>
<li>Fix bugs and <a href="https://github.com/ankane/transformers-ruby/pulls">submit pull requests</a></li>
<li>Write, clarify, or fix documentation</li>
<li>Suggest or add new features</li>
</ul>
<p dir="auto">To get started with development:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/ankane/transformers-ruby.git
cd transformers-ruby
bundle install
bundle exec rake download:files
bundle exec rake test"><pre>git clone https://github.com/ankane/transformers-ruby.git
<span>cd</span> transformers-ruby
bundle install
bundle <span>exec</span> rake download:files
bundle <span>exec</span> rake <span>test</span></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Toasts Are Bad UX (284 pts)]]></title>
            <link>https://maxschmitt.me/posts/toasts-bad-ux</link>
            <guid>41298794</guid>
            <pubDate>Tue, 20 Aug 2024 10:57:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://maxschmitt.me/posts/toasts-bad-ux">https://maxschmitt.me/posts/toasts-bad-ux</a>, See on <a href="https://news.ycombinator.com/item?id=41298794">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The core problem is that toasts always show up far away from the user's attention.</p>
<p>Take a look at this example from YouTube:</p>
<video autoplay="" muted="" playsinline="" loop="" width="1920" height="1080"><source src="https://s3.eu-central-1.amazonaws.com/maximilianschmitt.me/v2/post-media/toasts-bad-ux/youtube-toast.webm"><source src="https://s3.eu-central-1.amazonaws.com/maximilianschmitt.me/v2/post-media/toasts-bad-ux/youtube-toast.mp4"></video>
<h2>The Problems with the YouTube Toast</h2>
<p>In this particular example, the entire interaction is quite jarring:</p>
<ul>
<li>I click the "Save" button on the right-hand side of the screen</li>
<li>A modal appears in the middle of the screen</li>
<li>The toast appears in the bottom left corner</li>
</ul>
<p>And there are a few more problems in this particular example:</p>
<ul>
<li>The toast is delayed without a loading indicator</li>
<li>If I check or uncheck a checkbox in the modal, I need to wait multiple
seconds for the previous toast to disappear before I get the confirmation
toast for the latest action</li>
<li>The "Undo" button in the toast is unnecessary because the user can just click the checkbox again</li>
</ul>
<h2>The Solution: No Toast</h2>
<p>Here is a simple redesign of the "Save" interaction that solves all the problems above:</p>
<p><img src="https://maxschmitt.me/post-media/toasts-bad-ux/youtube-toast-simplified.jpg" srcset="https://maxschmitt.me/post-media/toasts-bad-ux/youtube-toast-simplified.jpg 1x, https://maxschmitt.me/post-media/toasts-bad-ux/youtube-toast-simplified@2x.jpg 2x" width="960" height="456" alt="A simplified version of the YouTube toast interaction"></p><ul>
<li>The playlists are shown right beneath the button instead of in a modal</li>
<li>After checking/unchecking a checkbox, a loading indicator is shown</li>
<li>When the loading indicator disappears, it implies the action has completed</li>
<li>No toast necessary!</li>
</ul>
<h2>2 More Examples</h2>
<h3>1. Confirming that Something was Added/Removed</h3>
<p>When archiving an email in Gmail, a toast appears showing confirmation. But by archiving the email, the email disappears from the list, which already implies the action was successful.</p>
<p><img src="https://maxschmitt.me/post-media/toasts-bad-ux/gmail-toast.jpg" srcset="https://maxschmitt.me/post-media/toasts-bad-ux/gmail-toast.jpg 1x, https://maxschmitt.me/post-media/toasts-bad-ux/gmail-toast@2x.jpg 2x" width="1301" height="621" alt="A toast in Gmail confirming that an email was archived"></p><div><p><span>Note</span></p><p>We do have to consider the undo-functionality and that the toast feedback can be useful when using keyboard
shortcuts.</p></div>
<h3>2. Confirming that Something was Copied</h3>
<p>A toast is shown after something was copied to the clipboard. In this example, the button already includes a confirmation so the toast is entirely unnecessary.</p>
<p><img src="https://maxschmitt.me/post-media/toasts-bad-ux/iconfinder-toast.jpg" srcset="https://maxschmitt.me/post-media/toasts-bad-ux/iconfinder-toast.jpg 1x, https://maxschmitt.me/post-media/toasts-bad-ux/iconfinder-toast@2x.jpg 2x" width="1301" height="680" alt="A toast confirming that something was copied to the clipboard"></p><h2>It Could be Worse</h2>
<p>What's worse than a toast? No feedback at all.</p>
<p>So if you don't have time to design or build a better feedback mechanism, a toast is better than nothing.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I picked up a shitty NUC from ewaste and it had a label on it for an AI company (190 pts)]]></title>
            <link>https://digipres.club/@foone/112990331505043510</link>
            <guid>41298430</guid>
            <pubDate>Tue, 20 Aug 2024 09:45:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://digipres.club/@foone/112990331505043510">https://digipres.club/@foone/112990331505043510</a>, See on <a href="https://news.ycombinator.com/item?id=41298430">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Pragtical: Practical and pragmatic code editor (191 pts)]]></title>
            <link>https://pragtical.dev/</link>
            <guid>41297609</guid>
            <pubDate>Tue, 20 Aug 2024 07:15:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pragtical.dev/">https://pragtical.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=41297609">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__docusaurus_skipToContent_fallback"><main><div><div><h3>Lightweight</h3><p>30 MB of RAM, 5 MB of disk space. Pragtical runs on many devices without performance issues.</p></div><div><h3>Powerful</h3><p>Syntax highlighting, mulitple cursors, command palette and many more. LSP and other features are available as plugins.</p></div><div><h3>Hyperextensible</h3><p>Pragtical allows you to extend the editor via Lua and its C API. Documentation is available for many parts of the editor.</p></div><div><h3>Cross-platform</h3><p>Built on SDL, C and Lua, Pragtical runs on Windows, Linux and macOS. Porting to other systems is trivial.</p></div><div><h3>Easy to Use</h3><p>Easily change your editor settings, color theme, key bindings and installed plugins configuration using the graphical settings manager.</p></div><div><h3>Free &amp; Open Source</h3><p>Pragtical is licensed under the MIT license. No telemetry or data collection.</p></div></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Phrack 71 (174 pts)]]></title>
            <link>http://phrack.org/issues/71/1.html</link>
            <guid>41296949</guid>
            <pubDate>Tue, 20 Aug 2024 04:57:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://phrack.org/issues/71/1.html">http://phrack.org/issues/71/1.html</a>, See on <a href="https://news.ycombinator.com/item?id=41296949">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<table>
   <tbody>
      <tr><td><a href="http://phrack.org/issues/71/1.html#article">Introduction</a></td><td>Phrack Staff</td></tr>
<tr><td><a href="http://phrack.org/issues/71/2.html#article">Phrack Prophile on BSDaemon</a></td><td>Phrack Staff</td></tr>
<tr><td><a href="http://phrack.org/issues/71/3.html#article">Linenoise</a></td><td>Phrack Staff</td></tr>
<tr><td><a href="http://phrack.org/issues/71/4.html#article">Loopback</a></td><td>Phrack Staff</td></tr>
<tr><td><a href="http://phrack.org/issues/71/5.html#article">Phrack World News</a></td><td>Phrack Staff</td></tr>
<tr><td><a href="http://phrack.org/issues/71/6.html#article">MPEG-CENC: Defective by Specification</a></td><td>David "retr0id" Buchanan</td></tr>
<tr><td><a href="http://phrack.org/issues/71/7.html#article">Bypassing CET &amp; BTI With Functional Oriented Programming</a></td><td>LMS</td></tr>
<tr><td><a href="http://phrack.org/issues/71/8.html#article">World of SELECT-only PostgreSQL Injections</a></td><td>Maksym Vatsyk</td></tr>
<tr><td><a href="http://phrack.org/issues/71/9.html#article">A VX Adventure in Build Systems and Oldschool Techniques</a></td><td>Amethyst Basilisk</td></tr>
<tr><td><a href="http://phrack.org/issues/71/10.html#article">Allocating new exploits</a></td><td>r3tr074</td></tr>
<tr><td><a href="http://phrack.org/issues/71/11.html#article">Reversing Dart AOT snapshots</a></td><td>cryptax</td></tr>
<tr><td><a href="http://phrack.org/issues/71/12.html#article">Finding hidden kernel modules (extrem way reborn)</a></td><td>g1inko</td></tr>
<tr><td><a href="http://phrack.org/issues/71/13.html#article">A novel page-UAF exploit strategy</a></td><td>Jinmeng Zhou, Jiayi Hu, Wenbo Shen, Zhiyun Qian</td></tr>
<tr><td><a href="http://phrack.org/issues/71/14.html#article">Stealth Shell: A Fully Virtualized Attack Toolchain</a></td><td>Ryan Petrich</td></tr>
<tr><td><a href="http://phrack.org/issues/71/15.html#article">Evasion by De-optimization</a></td><td>Ege BALCI</td></tr>
<tr><td><a href="http://phrack.org/issues/71/16.html#article">Long Live Format Strings</a></td><td>Mark Remarkable</td></tr>
<tr><td><a href="http://phrack.org/issues/71/17.html#article">Calling All Hackers</a></td><td>cts</td></tr>

   </tbody>
</table>

<p><strong>Title</strong> : Introduction</p>
<p><strong>Author</strong> : Phrack Staff</p>
<pre>                              ==Phrack Inc.==

                Volume 0x10, Issue 0x47, Phile #0x01 of 0x11

|=-----------------------------------------------------------------------=|
|=-------------------------=[ Introduction ]=----------------------------=|
|=-----------------------------------------------------------------------=|
|=----------------------=[    Phrack Staff    ]=-------------------------=|
|=-----------------------=[ staff@phrack.org ]=--------------------------=|
|=-----------------------------------------------------------------------=|
|=----------------------=[  August  19, 2024  ]=-------------------------=|
|=-----------------------------------------------------------------------=|

--[ Breaking The Spell

It can feel like the world is in a dreamlike state; a hype-driven delirium,
fueled by venture capital and the promises of untold riches and influence. 
Everyone seems to be rushing to implement the latest thing, hoping to find 
a magic bullet to solve problems they may not have, or even understand. 

While hype has always been a thing, in the past few years (2020-2024), we 
have witnessed several large pushes to integrate untested, underdeveloped, 
and unsustainable technology into systems that were already Going Through 
It. Once the charm wears off, and all the problems did not just magically 
disappear, they drop these ideas and move on to the next, at the cost of 
everyone else.

Many of these New &amp; Exciting ideas involve introducing increasingly opaque 
abstraction layers. They promise to push us towards The Future, yet only 
bring us further from understanding our own abilities and needs. It's easy 
to sell ideas like these. What isn't easy, is creating something both 
practical and sustainable. If we want to make the world more sustainable,
we need to understand the inputs, outputs, dependencies, constraints, and 
implementation details of the systems we rely on. Whenever we make it more 
difficult to know something, we inch closer to an information dark age.

After the past several decades of humanity putting all of its collective 
knowledge online, we are seeing more ways to prevent us from accessing it.
Not only is good information harder to find, bad information is drowning 
it out. There are increasing incentives to gatekeep and collect rent on 
important resources, and to disseminate junk that is useless at best, and
harmful at worst. In all of this chaos, the real threat is the loss of 
useful, verified, and trusted information, for the sake of monetizing 
the opposite.

Fortunately, there are still hackers. For every smokescreen that clouds
our vision, hackers help to clear the air. For every new garden wall 
erected, hackers forge a path around it. For every lock placed on our own 
ideas and cultural artifacts, hackers craft durable picks to unshackle 
them. Hackers try to understand what lies beyond their perspective. 
Hackers focus on what is real, and what is here.

We can move forward through this bullshit. We can work together to maintain 
good information, and amplify the voices of those who are creating and 
curating it. We can learn how things actually work, share the details, 
and use these mechanisms to do some good. We can devise new methods of 
communication and collaboration, and work both within and between our 
communities to jam the trash compactor currently trying to crush us to death.

Hacking is both a coping mechanism and a survival skill. It represents the 
pinnacle of our abilities as humans to figure out how to use whatever tools
we may have, in whatever way we can, to do what we need to do. Hacking is a 
great equalizer, a common dialect, a spirit that exists within all of us. 
It has the power to shape the world into one we want to live in.

The hacker spirit breaks any spell.

--[ Table of Contents

  0x01  Introduction ........................................ Phrack Staff

  0x02  Phrack Prophile ..................................... Phrack Staff

  0x03  Linenoise ........................................... Phrack Staff

  0x04  Loopback ............................................ Phrack Staff

  0x05  Phrack World News ................................... Phrack Staff

  0x06  MPEG-CENC: Defective by Specification .................... retr0id

  0x07  Bypassing CET &amp; BTI With Functional Oriented 
        Programming .................................................. LMS

  0x08  World of SELECT-only PostgreSQL Injections: 
        (Ab)using the filesystem ........................... Maksym Vatsyk

  0x09  Broodsac: A VX Adventure in Build Systems and 
        Oldschool Techniques ........................... Amethyst Basilisk

  0x0A  Allocating new exploits, Pwning browsers like a kernel, 
        Digging into PartitionAlloc and Blink engine ............. r3tr074

  0x0B  Reversing Dart AOT snapshots ............................. cryptax

  0x0C  Finding hidden kernel modules (extrem way reborn):
        20 years later ............................................ g1inko 

  0x0D  A novel page-UAF exploit strategy to       Jinmeng Zhou, Jiayi Hu,
        privilege escalation in Linux systems .... Wenbo Shen, Zhiyun Qian

  0x0E  Stealth Shell: A Fully Virtualized Attack 
        Toolchain ........................................... Ryan Petrich 

  0x0F  Evasion by De-optimization ............................. Ege BALCI

  0x10  Long Live Format Strings ......................... Mark Remarkable 

  0x11  Calling All Hackers .......................................... cts

--[ Greetz

  This zine would not be possible without the hacker community. Thank you
  to everyone who sent us a paper, donated to us, made art, or otherwise 
  supported this release. Thank you to the Phrack Staff and Editor Team 
  for putting together a fine collection of papers. Shoutout Inpatient Press
  for helping us navigate a print release.

  Phrack Staff would like to thank Elttam, BShield, Fuzzing.IO, grayfox, 
  bas, 0xricksanchez, zd00m, roddux, gynvael, bort, h_saxon, halvar, volvent, 
  mercy, skyper, ga/adm, awr, jon, cts, gbaruT and red dragon for generously 
  donating to help fund the print edition of Phrack 71! 

  Enormous thank you to everyone who contributed art to the Phrack 71 print
  release: x0, netspooky, amnesia, ris, bad will, ackmage, sillybears, del
  abstrakt, tainted, whatzzit, kx. 

  This zine would not have been possible without the following people:

  TMZ          -- Riding atop a cart full of zines into the sunset...
  sblip        -- World Wide Hax Collector
  RiS          -- Thank you for calling all the hackers :)
  netspooky    -- BLE (Big Leader Energy), ty for keeping the scene alive - we love u
  grenlith     -- *earth shattering doom riff plays*
  chompie      -- Showed us how to write kernel exploits with french tips
  ackmage      -- Ensured that the CRUD is FUD ;)
  roddux       -- Weird machine quality assurance specialist
  maxpl0it     -- The real internet explorer
  skyper       -- Cyber Senpai
  joernchen    -- The only Key Master that isn't rigged 
  grugq        -- Still rocking the onion on your belt like a g
  Phrack Staff -- For putting together an awesome zine
  Phrack Staph -- For getting under our skin
  
  A message to all fuckers: Stop using war to justify your continued power.
  
  A question for all baddies: How will you fight when stealth is not an option?

--[ Phrack policy

phrack:~# head -77 /usr/include/std-disclaimer.h
/*
 *  All information in Phrack Magazine is, to the best of the ability of
 *  the editors and contributors, truthful and accurate.  When possible,
 *  all facts are checked, all code is compiled.  However, we are not
 *  omniscient (hell, we don't even get paid).  It is entirely possible
 *  something contained within this publication is incorrect in some way.
 *  If this is the case, please drop us some email so that we can correct
 *  it in a future issue.
 *
 *
 *  Also, keep in mind that Phrack Magazine accepts no responsibility for
 *  the entirely stupid (or illegal) things people may do with the
 *  information contained herein.  Phrack is a compendium of knowledge,
 *  wisdom, wit, and sass.  We neither advocate, condone nor participate
 *  in any sort of illicit behavior.  But we will sit back and watch.
 *
 *
 *  Lastly, it bears mentioning that the opinions that may be expressed in
 *  the articles of Phrack Magazine are intellectual property of their
 *  authors.
 *  These opinions do not necessarily represent those of the Phrack Staff.
 */

    _______ ____ ____    _______     _______________  _____   _____
 ._\\____  \\   |    |__\\__    \  _\\__   /\    __//_\    | /    /
 :    |/   &gt;&gt;   :    :    :/    /./    /    |    |   /.    !/    /
 |    :    /         |    /     \|    __    |    |    |    /     \
 |    ____/|    |    |    \      \     |    |__  :    |    \      \
 |    |/// |____|    |_____\     |\___ |    ://\      !_____\      \
 |    :    /////:____|/////\\____|////\\___/.   \\____://///\\_____/
 |___/ e-zine   /////:     //////|     ////      /////       //////
 ////                .           :                x0^67^aMi5H^iMP!

--[ Phrack 72 Call For Papers

2025 marks 40 years since Phrack first appeared online. Let's make 
this next issue really shine! We are planning another print release, 
we need your papers!

Here's to Phorty more years :))


                   ----( Contact )----

    &lt;  Editors           : staff[at]phrack{dot}org         &gt;
    &gt;  Submissions       : submissions[at]phrack{dot}org   &lt;
    &lt;  /dev/urandom      : loopback[at]phrack{dot}org      &gt;
    &gt;  Arts &amp; Leisure    : arts[at]phrack{dot}org          &lt;


    The rules are simple:

    + 7-bit ASCII wrapped to 76 columns
    + English language
    + PGP if you wish, but not required (use our key below)
    + ANTISPAM in the subject line or face the Spam God and 
      walk backwards into hell


-----BEGIN PGP PUBLIC KEY BLOCK-----
Version: PHRACK
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=2t8m
-----END PGP PUBLIC KEY BLOCK-----

|=[ EOF ]=---------------------------------------------------------------=|
</pre>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sourcegraph went dark (305 pts)]]></title>
            <link>https://eric-fritz.com/articles/sourcegraph-went-dark/</link>
            <guid>41296481</guid>
            <pubDate>Tue, 20 Aug 2024 03:30:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eric-fritz.com/articles/sourcegraph-went-dark/">https://eric-fritz.com/articles/sourcegraph-went-dark/</a>, See on <a href="https://news.ycombinator.com/item?id=41296481">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="site-wrapper"><main role="main"><div><article><header></header><section><p>Towards the end of my mid-2019 job search, I was down to joining the Google Go team or Sourcegraph. Sourcegraph ultimately won due to cultural factors - the most important of which was the ability to <strong>build 100% in the open</strong>. All documents were public by default. Technical and product RFCs (and later PR/FAQs) were drafted, reviewed, and catalogued in a public Google Drive folder. All product implementation was done in public GitHub repositories.</p><p>Today, the <code>sourcegraph/sourcegraph</code> repository went private. This is the final cleaving blow, following many other smaller chops, on the culture that made Sourcegraph an attractive place to work. It’s a decision for a business from which I resigned, and therefore have no voice. But I still lament the rocky accessibility of artifacts showing four years of genuine effort into a product that I loved (and miss the use of daily in my current role).</p><p>On the bright side, I’ve cemented my place on the insights leaderboard for the remainder of time.</p><figure><a href="#img-insights"><img src="https://eric-fritz.com/assets/images/sg-went-dark/leaderboard.png" alt="Contributor leaderboard"></a></figure><a href="#_" id="img-insights"><img src="https://eric-fritz.com/assets/images/sg-went-dark/leaderboard.png"></a><p>Sourcegraph has made their future development repository private, but it seems they've left a public snapshot available at <a href="https://github.com/sourcegraph/sourcegraph-public-snapshot"><code>sourcegraph/sourcegraph-public-snapshot</code></a> for the time being.</p><h2 id="keeping-references-alive">Keeping references alive</h2><p>Over my tenure at Sourcegraph I’ve done <a href="https://eric-fritz.com/tags/sourcegraph/">a fair bit of writing</a> for the engineering blog, which I’ve inlined into this website for stable reference. It’s interesting to see what people are trying to build and, for an engineer, how they’re trying to build it. Much of my writing used links into relevant public code as a reference.</p><p>All of these links are now broken.</p><p>There’s a common saying that <a href="https://www.w3.org/Provider/Style/URI">cool URIs don’t change</a>. In a related sense, I have the hot take that <em>cool articles don’t suddenly start rotting links</em>. I’m going to break at least <strong>one</strong> of these best practices, and I can’t do anything about the first one. So I’ll attempt to preserve as much information in this writing as possible by moving these links into a repository under my influence.</p><p>I'm opting to bite the bullet now and move references to something completely under my control rather than kick then can down the road by referencing another repository that _could_ suddenly disappear at any time.</p><p>I had a feeling this would be a risk a while ago, so I had forked <code>sourcegraph/sourcegraph</code> into <a href="https://github.com/efritz/sourcegraph"><code>efritz/sourcegraph</code></a> in preparation. Given the fork, it should be easy enough job to do a global find-and-replace of one repository name with another at this point and mission accomplished, right?</p><p>Unfortunately, no. I had links to code on the <code>main</code> branch, but also links to pull requests and commits within pull requests. Forks don’t inherit pull requests (problem #1). And commits not directly referenced by a branch of your fork are visible as only as long as they’re part of the repository network (problem #2).</p><figure><a href="#img-warning"><img src="https://eric-fritz.com/assets/images/sg-went-dark/warning.png" alt="Non-local commit warning"></a></figure><a href="#_" id="img-warning"><img src="https://eric-fritz.com/assets/images/sg-went-dark/warning.png"></a><p>I had wondered <a href="https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/working-with-forks/what-happens-to-forks-when-a-repository-is-deleted-or-changes-visibility">what happens to forks when a repository is deleted or changes visibility</a> and found some calming information in the official GitHub documentation:</p><blockquote><p>In other words, a public repository’s forks will remain public in their own separate repository network even after the upstream repository is made private. This allows the fork owners to continue to work and collaborate without interruption. […] If a public repository is made private and then deleted, its public forks will continue to exist in a separate network.</p></blockquote><p><em>My fork will continue to exist</em> (yay), but the source repository becoming inaccessible might take commits outside of the <code>main</code> branch with it. I need to ensure that these commits are part of the new repository network.</p><h2 id="scraping-for-relevant-commits">Scraping for relevant commits</h2><p>Step one is to find all the commits I care about. I ran the following Go program to iterate through all of <em>my</em> pull requests on the source repository and write their payloads to disk for further processing.</p><div><table><tbody><tr><td><pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span><span>33
</span><span>34
</span><span>35
</span><span>36
</span><span>37
</span><span>38
</span><span>39
</span><span>40
</span><span>41
</span><span>42
</span><span>43
</span><span>44
</span><span>45
</span><span>46
</span><span>47
</span><span>48
</span><span>49
</span><span>50
</span><span>51
</span><span>52
</span><span>53
</span><span>54
</span><span>55
</span><span>56
</span><span>57
</span><span>58
</span><span>59
</span><span>60
</span><span>61
</span><span>62
</span><span>63
</span><span>64
</span><span>65
</span><span>66
</span><span>67
</span><span>68
</span><span>69
</span><span>70
</span><span>71
</span><span>72
</span><span>73
</span><span>74
</span><span>75
</span><span>76
</span><span>77
</span><span>78
</span><span>79
</span><span>80
</span><span>81
</span><span>82
</span></code></pre></td><td><pre tabindex="0"><code data-lang="go"><span><span><span>package</span> main
</span></span><span><span>
</span></span><span><span><span>import</span> (
</span></span><span><span>	<span>"context"</span>
</span></span><span><span>	<span>"encoding/json"</span>
</span></span><span><span>	<span>"fmt"</span>
</span></span><span><span>	<span>"log"</span>
</span></span><span><span>	<span>"os"</span>
</span></span><span><span>	<span>"strings"</span>
</span></span><span><span>	<span>"time"</span>
</span></span><span><span>
</span></span><span><span>	<span>"github.com/google/go-github/v63/github"</span>
</span></span><span><span>)
</span></span><span><span>
</span></span><span><span><span>const</span> (
</span></span><span><span>	owner      = <span>"sourcegraph"</span>
</span></span><span><span>	repo       = <span>"sourcegraph"</span>
</span></span><span><span>	targetUser = <span>"efritz"</span>
</span></span><span><span>	token      = <span>"ghp_pls_dont_hax_me"</span>
</span></span><span><span>)
</span></span><span><span>
</span></span><span><span><span>func</span> <span>main</span>() {
</span></span><span><span>	ctx <span>:=</span> context.<span>Background</span>()
</span></span><span><span>
</span></span><span><span>	<span>if</span> err <span>:=</span> <span>scrapePRs</span>(ctx); err <span>!=</span> <span>nil</span> {
</span></span><span><span>		log.<span>Fatalf</span>(<span>"Error: %v"</span>, err)
</span></span><span><span>	}
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>func</span> <span>scrapePRs</span>(ctx context.Context) <span>error</span> {
</span></span><span><span>	client <span>:=</span> github.<span>NewClient</span>(<span>nil</span>).<span>WithAuthToken</span>(token)
</span></span><span><span>
</span></span><span><span>	page <span>:=</span> <span>0</span>
</span></span><span><span>	<span>for</span> {
</span></span><span><span>		fmt.<span>Printf</span>(<span>"Requesting page #%d...\n"</span>, page)
</span></span><span><span>
</span></span><span><span>		prs, resp, err <span>:=</span> client.PullRequests.<span>List</span>(
</span></span><span><span>			ctx, 
</span></span><span><span>			owner, 
</span></span><span><span>			repo, 
</span></span><span><span>			<span>&amp;</span>github.PullRequestListOptions{
</span></span><span><span>				State: <span>"all"</span>,
</span></span><span><span>				ListOptions: github.ListOptions{
</span></span><span><span>					Page:    page,
</span></span><span><span>					PerPage: <span>100</span>,
</span></span><span><span>				},
</span></span><span><span>			},
</span></span><span><span>		)
</span></span><span><span>		<span>if</span> err <span>!=</span> <span>nil</span> {
</span></span><span><span>			<span>if</span> !resp.Rate.Reset.Time.<span>IsZero</span>() {
</span></span><span><span>				duration <span>:=</span> time.<span>Until</span>(resp.Rate.Reset.Time)
</span></span><span><span>				time.<span>Sleep</span>(duration)
</span></span><span><span>				<span>continue</span>
</span></span><span><span>			}
</span></span><span><span>
</span></span><span><span>			<span>return</span> err
</span></span><span><span>		}
</span></span><span><span>		<span>if</span> <span>len</span>(prs) <span>==</span> <span>0</span> {
</span></span><span><span>			<span>break</span>
</span></span><span><span>		}
</span></span><span><span>
</span></span><span><span>		<span>for</span> _, pr <span>:=</span> <span>range</span> prs {
</span></span><span><span>			<span>if</span> <span>*</span>pr.User.Login <span>!=</span> targetUser {
</span></span><span><span>				<span>continue</span>
</span></span><span><span>			}
</span></span><span><span>
</span></span><span><span>			fmt.<span>Printf</span>(<span>"Saving %d: %s\n"</span>, <span>*</span>pr.ID, <span>*</span>pr.Title)
</span></span><span><span>			serialized, err <span>:=</span> json.<span>Marshal</span>(pr)
</span></span><span><span>			<span>if</span> err <span>!=</span> <span>nil</span> {
</span></span><span><span>				<span>return</span> err
</span></span><span><span>			}
</span></span><span><span>			filename <span>:=</span> fmt.<span>Sprintf</span>(<span>"prs/%d.json"</span>, <span>*</span>pr.ID)
</span></span><span><span>			<span>if</span> err <span>:=</span> os.<span>WriteFile</span>(filename, serialized, <span>0777</span>); err <span>!=</span> <span>nil</span> {
</span></span><span><span>				<span>return</span> err
</span></span><span><span>			}
</span></span><span><span>		}
</span></span><span><span>
</span></span><span><span>		page<span>++</span>
</span></span><span><span>	}
</span></span><span><span>
</span></span><span><span>	<span>return</span> <span>nil</span>
</span></span><span><span>}
</span></span></code></pre></td></tr></tbody></table></div><p>This program yielded 2,645 files with pull request metadata. I then used <code>jq</code> to read these JSON payloads and extract data for subsequent steps.</p><div><table><tbody><tr><td><pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td><td><pre tabindex="0"><code data-lang="bash"><span><span><span>for</span> file in prs/*.json; <span>do</span>
</span></span><span><span>	<span>number</span><span>=</span><span>$(</span>jq -r <span>'.number'</span> <span>"</span><span>$file</span><span>"</span><span>)</span>
</span></span><span><span>	<span>merge_commit_sha</span><span>=</span><span>$(</span>jq -r <span>'.merge_commit_sha // ""'</span> <span>"</span><span>$file</span><span>"</span><span>)</span>
</span></span><span><span>
</span></span><span><span>	<span>echo</span> <span>"</span><span>$number</span><span>"</span> &gt;&gt; pr_ids.txt
</span></span><span><span> 	<span>echo</span> <span>"</span><span>$merge_commit_sha</span><span>"</span> &gt;&gt; commits.txt
</span></span><span><span>	<span>echo</span> <span>"</span><span>$number</span><span> </span><span>$merge_commit_sha</span><span>"</span> &gt;&gt; replace_pairs.txt
</span></span><span><span><span>done</span>
</span></span></code></pre></td></tr></tbody></table></div><p>This script creates three files:</p><ul><li><code>pr_ids.txt</code> is a flat list of GitHub identifiers, which are used in URLs. Since the list endpoint returns only enough data to render a pull request <em>list</em>, we’ll need to fetch additional information (intermediate commits) for each pull request by its ID.</li><li><code>commits.txt</code> is a flat list of git SHAs that were a result of merging a PR into the target branch (not always <code>main</code>). These commits may or may not be in the forked repository network, depending on the merge target. These should be synced over.</li><li><code>replace_pairs.txt</code> contains pairs of of pull request identifier and its merge commit. This will later be used to mass replace <code>/pull/{id}</code> with <code>/commit/{sha}</code>. Since pull requests can’t be linked directly anymore, I can at least link to the full pull request <em>contents</em>.</li></ul><p>Next, I ran a second program (with the same preamble as the program above) to list all the <em>non-merge commits</em> of each pull request. Based on the <a href="https://eric-fritz.com/articles/i-am-abusive-to-git">pants-on-head way I work</a>, these will mostly be <code>WIP.</code> commits, but <em>sometimes</em> I did a better job and (possibly) linked directly to these.</p><div><table><tbody><tr><td><pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span><span>33
</span><span>34
</span><span>35
</span><span>36
</span><span>37
</span><span>38
</span><span>39
</span><span>40
</span><span>41
</span><span>42
</span><span>43
</span><span>44
</span><span>45
</span><span>46
</span><span>47
</span><span>48
</span></code></pre></td><td><pre tabindex="0"><code data-lang="go"><span><span><span>func</span> <span>extractCommits</span>(ctx context.Context) <span>error</span> {
</span></span><span><span>	contents, err <span>:=</span> os.<span>ReadFile</span>(<span>"pr_ids.txt"</span>)
</span></span><span><span>	<span>if</span> err <span>!=</span> <span>nil</span> {
</span></span><span><span>		<span>return</span> err
</span></span><span><span>	}
</span></span><span><span>
</span></span><span><span>	<span>var</span> ids []<span>int</span>
</span></span><span><span>	<span>for</span> _, line <span>:=</span> <span>range</span> strings.<span>Split</span>(<span>string</span>(contents), <span>"\n"</span>) {
</span></span><span><span>		<span>if</span> line <span>==</span> <span>""</span> {
</span></span><span><span>			<span>continue</span>
</span></span><span><span>		}
</span></span><span><span>
</span></span><span><span>		<span>var</span> id <span>int</span>
</span></span><span><span>		_, _ = fmt.<span>Sscanf</span>(line, <span>"%d"</span>, <span>&amp;</span>id)
</span></span><span><span>		ids = <span>append</span>(ids, id)
</span></span><span><span>	}
</span></span><span><span>
</span></span><span><span>	client <span>:=</span> github.<span>NewClient</span>(<span>nil</span>).<span>WithAuthToken</span>(token)
</span></span><span><span>
</span></span><span><span>	<span>for</span> _, id <span>:=</span> <span>range</span> ids {
</span></span><span><span>		<span>for</span> {
</span></span><span><span>			commits, resp, err <span>:=</span> client.PullRequests.<span>ListCommits</span>(
</span></span><span><span>				ctx, 
</span></span><span><span>				owner, 
</span></span><span><span>				repo, 
</span></span><span><span>				id, 
</span></span><span><span>				<span>&amp;</span>github.ListOptions{},
</span></span><span><span>			)
</span></span><span><span>			<span>if</span> err <span>!=</span> <span>nil</span> {
</span></span><span><span>				<span>if</span> !resp.Rate.Reset.Time.<span>IsZero</span>() {
</span></span><span><span>					duration <span>:=</span> time.<span>Until</span>(resp.Rate.Reset.Time)
</span></span><span><span>					time.<span>Sleep</span>(duration)
</span></span><span><span>					<span>continue</span>
</span></span><span><span>				}
</span></span><span><span>
</span></span><span><span>				<span>return</span> err
</span></span><span><span>			}
</span></span><span><span>
</span></span><span><span>			<span>for</span> _, commit <span>:=</span> <span>range</span> commits {
</span></span><span><span>				fmt.<span>Println</span>(<span>*</span>commit.SHA)
</span></span><span><span>			}
</span></span><span><span>
</span></span><span><span>			<span>break</span>
</span></span><span><span>		}
</span></span><span><span>	}
</span></span><span><span>
</span></span><span><span>	<span>return</span> <span>nil</span>
</span></span><span><span>}
</span></span></code></pre></td></tr></tbody></table></div><p>Running <code>go run . &gt;&gt; commits.txt</code> dumped these commits onto the end of the file and completes the set of Git SHAs that need to be brought into the repository network for stable reference.</p><h2 id="bringing-commits-into-the-new-repository-network">Bringing commits into the new repository network</h2><p>Given the warning above (<em>“does not belong to any branch on this repository”</em>), it should be sufficient to ensure that my fork has a branch containing each relevant SHA I’d like to retain access to.</p><p>Bash here does a good enough job since all we’re doing is a bunch of git operations in sequence.</p><div><table><tbody><tr><td><pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span><span>9
</span></code></pre></td><td><pre tabindex="0"><code data-lang="bash"><span><span><span>#!/bin/bash
</span></span></span><span><span><span></span>
</span></span><span><span><span>for</span> SHA in <span>$(</span>cat commits.txt<span>)</span>; <span>do</span>
</span></span><span><span>    git fetch upstream <span>$SHA</span>             <span># Pull SHA from sg/sg</span>
</span></span><span><span>    git checkout -b <span>"mirror/</span><span>$SHA</span><span>"</span> <span>$SHA</span>  <span># Create reference in fork</span>
</span></span><span><span>    git push origin <span>"mirror/</span><span>$SHA</span><span>"</span>       <span># Push branch to efritz/sg</span>
</span></span><span><span>    git checkout main                   <span># Reset</span>
</span></span><span><span>    git branch -D <span>"mirror/</span><span>$SHA</span><span>"</span>         <span># Cleanup</span>
</span></span><span><span><span>done</span>
</span></span></code></pre></td></tr></tbody></table></div><h2 id="rewriting-references">Rewriting references</h2><p>At this point I should be safe and have <em>some target</em> to link to in my fork for each reference to a pull request or commit in the source repository. Now I just have to figure out how to automate that process (there are at least 275 code references over 15 files and I’m not doing that by hand).</p><p>Ironically, I used <a href="https://github.com/efritz/aidev">my own thing</a> instead of Cody to figure out how to use <code>xargs</code> correctly for this task.</p><div><table><tbody><tr><td><pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span></code></pre></td><td><pre tabindex="0"><code data-lang="bash"><span><span><span>#!/bin/bash
</span></span></span><span><span><span></span>
</span></span><span><span><span>sg_prefix</span><span>=</span><span>'https://github.com/sourcegraph/sourcegraph'</span>
</span></span><span><span><span>fork_prefix</span><span>=</span><span>'https://github.com/efritz/sourcegraph'</span>
</span></span><span><span>
</span></span><span><span><span># Rewrite direct references to commits to the fork</span>
</span></span><span><span>grep -rl <span>"</span><span>${</span><span>sg_prefix</span><span>}</span><span>/commit/"</span> . | <span>\
</span></span></span><span><span><span></span>xargs -I <span>{}</span> perl -i -pe <span>"s|</span><span>${</span><span>sg_prefix</span><span>}</span><span>/commit/|</span><span>${</span><span>fork_prefix</span><span>}</span><span>/commit/|g"</span> <span>{}</span>
</span></span><span><span>
</span></span><span><span><span># Rewrite references to pull request to their merge commit in the fork</span>
</span></span><span><span><span>while</span> <span>IFS</span><span>=</span><span>' '</span> <span>read</span> -r id sha; <span>do</span>
</span></span><span><span>    grep -rl <span>"</span><span>${</span><span>sg_prefix</span><span>}</span><span>/pull/</span><span>${</span><span>id</span><span>}</span><span>"</span> . | <span>\
</span></span></span><span><span><span></span>    xargs -I <span>{}</span> perl -i -pe <span>"s|</span><span>${</span><span>sg_prefix</span><span>}</span><span>/pull/</span><span>${</span><span>id</span><span>}</span><span>|</span><span>${</span><span>fork_prefix</span><span>}</span><span>/commit/</span><span>${</span><span>sha</span><span>}</span><span>|g"</span> <span>{}</span>
</span></span><span><span><span>done</span> &lt; replace_pairs.txt
</span></span></code></pre></td></tr></tbody></table></div><p><strong>Now</strong> I think we can say mission accomplished and I hope my dead links detector stops throwing a fit after <a href="https://github.com/efritz/blog/pull/48">all these changes</a>.</p></section></article></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[$50 2GB Raspberry Pi 5 comes with a lower price and a tweaked, cheaper CPU (128 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2024/08/new-2gb-raspberry-pi-5-option-knocks-the-price-down-to-50/</link>
            <guid>41296421</guid>
            <pubDate>Tue, 20 Aug 2024 03:14:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2024/08/new-2gb-raspberry-pi-5-option-knocks-the-price-down-to-50/">https://arstechnica.com/gadgets/2024/08/new-2gb-raspberry-pi-5-option-knocks-the-price-down-to-50/</a>, See on <a href="https://news.ycombinator.com/item?id=41296421">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      cheaper pi    —
</h4>
            
            <h2 itemprop="description">Despite changes, 2GB Pi 5 is "functionally identical" to other iterations.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/08/IMG_0625-800x600.jpeg" alt="The 8GB Raspberry Pi 5 with the official fan and heatsink installed. ">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/08/IMG_0625.jpeg" data-height="1921" data-width="2560">Enlarge</a> <span>/</span> The 8GB Raspberry Pi 5 with the official fan and heatsink installed. </p><p>Andrew Cunningham</p></figcaption>  </figure>

  




<!-- cache hit 1:single/related:4e3412c093192ab41e40a894f05c0c6e --><!-- empty -->
<p>We're many months past the worst of the Raspberry Pi shortages, and the board is finally widely available at its suggested retail price at most sites without wait times or quantity limitations. One sign that the Pi Foundation is feeling more confident about the stock situation: the launch of <a href="https://www.raspberrypi.com/news/2gb-raspberry-pi-5-on-sale-now-at-50/">a new 2GB configuration of the Raspberry Pi 5</a>, available starting today for $50. That's $10 less than the 4GB configuration and $30 less than the 8GB version of the board.</p>
<p>Raspberry Pi CEO Eben Upton writes that the 2GB version of the board includes a revised version of the Broadcom BCM2712C1 SoC that is slightly cheaper to manufacture. Upton says that the D0 stepping of the BCM2712C1 strips out some "dark silicon" built-in functionality that the Pi wasn't using but was still taking up space on the silicon die and increasing the cost of the chip.</p>

<p>"From the perspective of a Raspberry Pi user, [the chip] is functionally identical to its predecessor: the same fast quad-core processor; the same multimedia capabilities; and the same PCI Express bus that has proven to be one of the most exciting features of the Raspberry Pi 5 platform," Upton writes. "However, it is cheaper to make, and so is available to us at somewhat lower cost. And this, combined with the savings from halving the memory capacity, has allowed us to take $10 out of the cost of the finished product."</p>                                                                        
                                                                                
<p>At $50, the price tag is still north of the baseline $35 price that the Pi started at for many years. The Pi 4 had a 1GB model for $35 when it launched, and there was a $35 2GB model available <a href="https://arstechnica.com/gadgets/2020/02/the-raspberry-pi-4-gets-a-ram-upgradethe-2gb-version-is-now-35/">for a while in 2020</a>, but widespread shortages and supply chain issues led to <a href="https://arstechnica.com/gadgets/2021/10/supply-chain-woes-lead-to-a-temporary-raspberry-pi-4-price-hike/">a "temporary" price increase in late 2021</a> that is, as of this writing, still in place. At least the 2GB Pi 5 is only $5 more expensive than the 2GB version of the Pi 4, which is still in stock for $45 at many retailers.</p>
<p>Though you'll want a fully fledged 8GB Raspberry Pi if you want to try using one <a href="https://arstechnica.com/gadgets/2024/01/what-i-learned-from-using-a-raspberry-pi-5-as-my-main-computer-for-two-weeks/">as an everyday desktop PC</a>, there are plenty of Pi use cases that will benefit from its additional speed and connectivity options without needing more RAM. <a href="https://arstechnica.com/gaming/2022/02/building-a-retro-gaming-super-console-with-100-and-a-raspberry-pi-2022-edition/">Retro emulation boxes</a> aren't necessarily RAM-hungry but can benefit from the Pi 5's extra CPU and GPU speed, and many types of lightweight server apps (Wireguard, Homebridge, Pi-hole, to name a few) can benefit from the faster Wi-Fi and Ethernet and improved support for more reliable NVMe storage.</p>
<p>All that said, for just $10 more, we'd still probably point most people to the more flexible and future-proof 4GB version. The Pi boards sitting around my house have all lived multiple lives at this point, picking up new tasks as my needs have changed, and new Pi boards have come out—if your Pi project today won't benefit from more RAM, it's possible that tomorrow's Pi project will.</p>
<p>The 2GB Pi 5 is available for order from outlets like <a href="https://www.pishop.us/product/raspberry-pi-5-2gb/">PiShop</a> and <a href="https://www.canakit.com/raspberry-pi-5-2gb.html">CanaKit</a>&nbsp;and should filter out to other Pi retailers soon.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Procreate's anti-AI pledge attracts praise from digital creatives (126 pts)]]></title>
            <link>https://www.theverge.com/2024/8/19/24223473/procreate-anti-generative-ai-pledge-digital-illustration-creatives</link>
            <guid>41295957</guid>
            <pubDate>Tue, 20 Aug 2024 01:20:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/8/19/24223473/procreate-anti-generative-ai-pledge-digital-illustration-creatives">https://www.theverge.com/2024/8/19/24223473/procreate-anti-generative-ai-pledge-digital-illustration-creatives</a>, See on <a href="https://news.ycombinator.com/item?id=41295957">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article id="content"><div><div><div><h2>Procreate’s anti-AI pledge attracts praise from digital creatives</h2><p><span><span> / </span><h2>The popular iPad design app has vowed against introducing generative AI tools into its products.</h2></span></p></div><div><p><span>By</span> <span><span></span> <span><a href="https://www.theverge.com/authors/jess-weatherbed">Jess Weatherbed</a></span><span>, <span>a news writer focused on creative industries, computing, and internet culture. Jess started her career at TechRadar, covering news and hardware reviews.</span></span></span></p><p><time datetime="2024-08-19T11:54:58.672Z"> <!-- -->Aug 19, 2024, 11:54 AM UTC</time></p><div><h2>Share this story</h2></div></div></div><div><figure><span><span></span><img alt="The Procreate logo against a pink and yellow backdrop." sizes="(max-width: 768px) calc(100vw - 100px), (max-width: 1180px) 700px, 600px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/16x11/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25578652/Procreate_App_Icon.jpg 16w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/32x21/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25578652/Procreate_App_Icon.jpg 32w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/48x32/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25578652/Procreate_App_Icon.jpg 48w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/64x43/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25578652/Procreate_App_Icon.jpg 64w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/96x64/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25578652/Procreate_App_Icon.jpg 96w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/128x85/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25578652/Procreate_App_Icon.jpg 128w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/256x171/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25578652/Procreate_App_Icon.jpg 256w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/376x251/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25578652/Procreate_App_Icon.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/384x256/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25578652/Procreate_App_Icon.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/415x277/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25578652/Procreate_App_Icon.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/480x320/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25578652/Procreate_App_Icon.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/540x360/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25578652/Procreate_App_Icon.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/640x427/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25578652/Procreate_App_Icon.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/750x500/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25578652/Procreate_App_Icon.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/828x552/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25578652/Procreate_App_Icon.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/1080x720/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25578652/Procreate_App_Icon.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/1200x800/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25578652/Procreate_App_Icon.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/1440x960/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25578652/Procreate_App_Icon.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/1920x1280/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25578652/Procreate_App_Icon.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/2048x1365/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25578652/Procreate_App_Icon.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/2400x1600/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25578652/Procreate_App_Icon.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/2400x1600/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25578652/Procreate_App_Icon.jpg" decoding="async" data-nimg="responsive"></span><div><figcaption><em>Procreate CEO James Cuda has made his distaste for generative AI known.</em></figcaption> <p><cite>Image: Procreate</cite></p></div></figure></div></div><div><div><p>Many Procreate users can breathe a sigh of relief now that the popular iPad illustration app has taken a definitive stance against generative AI. “We’re not going to be introducing any generative AI into our products,” Procreate CEO <a href="https://x.com/Procreate/status/1825311104584802470">James Cuda said in a video posted to X</a>. “I don’t like what’s happening to the industry, and I don’t like what it’s doing to artists.”&nbsp;</p><div><p>The <a href="https://www.theverge.com/2022/12/23/23523864/artstation-removing-anti-ai-protest-artwork-censorship">creative community’s ire toward generative AI</a> is driven by two main concerns: that AI models have been <a href="https://www.theverge.com/2024/8/13/24219520/stability-midjourney-artist-lawsuit-copyright-trademark-claims-approved">trained on their content without consent or compensation</a>, and that widespread adoption of the technology will <a href="https://www.theverge.com/2024/6/21/24183265/openai-exec-some-creative-jobs-maybe-will-go-away-but-maybe-they-shouldnt-have-been-there-in-the-fir">greatly reduce employment opportunities</a>. Those concerns have driven some digital illustrators to seek out alternative solutions to apps that integrate generative AI tools, such as Adobe Photoshop.</p></div><p>“Generative AI is ripping the humanity out of things. Built on a foundation of theft, the technology is steering us toward a barren future,” Procreate said on <a href="https://procreate.com/ai">the new AI section of its website</a>. “We think machine learning is a compelling technology with a lot of merit, but the path generative AI is on is wrong for us.”</p><div><p>The announcement has already <a href="https://x.com/sdw/status/1825321329509474701">attracted widespread</a> <a href="https://x.com/mexopolis/status/1825408703065133347">praise from</a> <a href="https://x.com/Rahll/status/1825324122261389473">creatives online</a> who are discontent with how other companies have handled the increasing deluge of generative AI tools. Clip Studio Paint, a rival illustration app, <a href="https://www.theverge.com/2022/12/2/23490068/clip-studio-paint-ai-image-generator-cancels-celsys-digital-illustration">scrapped plans to introduce image-generation features</a> after the announcement was condemned by its user base. Other companies like drawing tablet maker Wacom and <em>Magic: The Gathering</em>-owner Wizards of the Coast have <a href="https://www.theverge.com/2024/1/9/24031468/wacom-wizards-of-the-coast-mtg-artists-against-generative-ai">also issued apologies for (unintentionally) using AI-generated assets</a> in their products following similar community reactions.</p></div><div><p>Even Adobe, which attempted a more “ethical” approach to building generative AI tools — having repeatedly said that its own Firefly models are <a href="https://www.theverge.com/2023/3/21/23648315/adobe-firefly-ai-image-generator-announced">trained on content that’s licensed or out of copyright</a> — has been slammed by those who feel the company has turned its back on independent artists and creators. Adobe <a href="https://www.theverge.com/2024/6/18/24181001/adobe-updated-terms-of-service-wont-train-ai-on-work">further clarified that it doesn’t train AI</a> on user content in June following <a href="https://www.theverge.com/2024/6/7/24173838/adobe-tos-update-firefly-generative-ai-trust">intense backlash over a terms of service agreement</a> update, but <a href="https://www.theverge.com/2024/6/17/24180196/adobe-us-ftc-doj-sues-subscriptions-cancel">other unfavorable changes</a> introduced over the years have given it an unshakable reputation as <a href="https://www.theverge.com/2024/6/13/24177686/the-general-perception-is-adobe-is-an-evil-company-that-will-do-whatever-it-takes-to-f-its-users">a company that creators love to hate</a>.</p></div><p>Procreate is extremely well received by comparison. The company has stuck to a $12.99 one-time purchase model instead of moving to a rolling subscription like Adobe and <a href="https://www.theverge.com/2022/8/22/23316413/clip-studio-paint-subscription-plan-angry-artists-digital-illustration">Clip Studio Paint did</a>, and has expanded into offering <a href="https://www.theverge.com/2023/9/8/23864374/procreate-dreams-animation-app-ipad-release-date-announcement-price">products for animation</a> and (eventually) <a href="https://www.theverge.com/2024/4/24/24138992/desktop-procreate-dreams-could-soon-be-a-reality">desktop users</a>. Making such a firm pledge against introducing generative AI is likely just the icing on the cake for creatives who feel alternative options are dwindling.&nbsp;</p><p>Cuda said “We don’t exactly know where this story’s gonna go, or how it ends, but we believe that we’re on the right path to supporting human creativity.”</p></div><div><p>Most Popular</p><p>Most Popular</p><ol><li><a href="https://www.theverge.com/2024/8/19/24224070/the-acolyte-cancelled-season-2"><h2>The Acolyte has been canceled</h2></a><hr></li><li><a href="https://www.theverge.com/2024/8/18/24223039/formula-1-f1-cease-and-desist-letters-creators-name-change"><h2>Formula 1 is reportedly forcing some F1 creators to change their names</h2></a><hr></li><li><a href="https://www.theverge.com/2024/8/19/24223473/procreate-anti-generative-ai-pledge-digital-illustration-creatives"><h2>Procreate’s anti-AI pledge attracts praise from digital creatives</h2></a><hr></li><li><a href="https://www.theverge.com/2024/8/16/24221826/olympics-paris-what-happened-air-conditioning-heat"><h2>What happened to all the temporary air conditioning units at the Olympic Village?</h2></a><hr></li><li><a href="https://www.theverge.com/2024/8/19/24223589/trump-ai-generated-swift-harris-social-media"><h2>Donald Trump posts a fake AI-generated Taylor Swift endorsement</h2></a><hr></li></ol></div></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Artificial intelligence is losing hype (108 pts)]]></title>
            <link>https://www.economist.com/finance-and-economics/2024/08/19/artificial-intelligence-is-losing-hype</link>
            <guid>41295923</guid>
            <pubDate>Tue, 20 Aug 2024 01:13:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/finance-and-economics/2024/08/19/artificial-intelligence-is-losing-hype">https://www.economist.com/finance-and-economics/2024/08/19/artificial-intelligence-is-losing-hype</a>, See on <a href="https://news.ycombinator.com/item?id=41295923">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main role="main" id="content"><article data-test-id="Article" id="new-article-template"><div data-test-id="standard-article-template"><section><h2>For some, that is proof the tech will in time succeed. Are they right?</h2></section><section><figure><img alt="An illustration of a robotic hand with crossed fingers on a solid red background." fetchpriority="high" width="1280" height="720" decoding="async" data-nimg="1" sizes="(min-width: 960px) 700px, 95vw" srcset="https://www.economist.com/cdn-cgi/image/width=360,quality=80,format=auto/content-assets/images/20240824_FND000.jpg 360w, https://www.economist.com/cdn-cgi/image/width=384,quality=80,format=auto/content-assets/images/20240824_FND000.jpg 384w, https://www.economist.com/cdn-cgi/image/width=480,quality=80,format=auto/content-assets/images/20240824_FND000.jpg 480w, https://www.economist.com/cdn-cgi/image/width=600,quality=80,format=auto/content-assets/images/20240824_FND000.jpg 600w, https://www.economist.com/cdn-cgi/image/width=834,quality=80,format=auto/content-assets/images/20240824_FND000.jpg 834w, https://www.economist.com/cdn-cgi/image/width=960,quality=80,format=auto/content-assets/images/20240824_FND000.jpg 960w, https://www.economist.com/cdn-cgi/image/width=1096,quality=80,format=auto/content-assets/images/20240824_FND000.jpg 1096w, https://www.economist.com/cdn-cgi/image/width=1280,quality=80,format=auto/content-assets/images/20240824_FND000.jpg 1280w, https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20240824_FND000.jpg 1424w" src="https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20240824_FND000.jpg"><figcaption><span>Illustration: Alberto Miranda</span></figcaption></figure></section><div><section data-body-id="cp2"><p data-component="falseparagraph"><span data-caps="initial">S</span><small>ilicon Valley’s </small>tech bros are having a difficult few weeks. A growing number of investors worry that <a href="https://www.economist.com/topics/artificial-intelligence">artificial intelligence (<small>AI</small>)</a><small> </small>will not deliver the vast profits they seek. Since peaking last month the share prices of Western firms driving the <a href="https://www.economist.com/finance-and-economics/2024/07/02/what-happened-to-the-artificial-intelligence-revolution"><small>ai </small>revolution</a> have dropped by 15%. A growing number of observers now question the limitations of large language models, which power services such as Chat<small>GPT</small>. Big tech firms have spent tens of billions of dollars on <small>ai </small>models, with even more extravagant promises of future outlays. Yet according to the latest data from the Census Bureau, only 4.8% of American companies use <small>ai </small>to produce goods and services, down from a high of 5.4% early this year. Roughly the same share intend to do so within the next year.</p></section><p><h3 id="article-tags">Explore more</h3><nav aria-labelledby="article-tags"><a href="https://www.economist.com/topics/openai" data-analytics="tags:openai"><span>OpenAI</span></a><a href="https://www.economist.com/topics/artificial-intelligence" data-analytics="tags:artificial_intelligence"><span>Artificial intelligence</span></a><a href="https://www.economist.com/topics/sam-altman" data-analytics="tags:sam_altman"><span>Sam Altman</span></a><a href="https://www.economist.com/topics/free-exchange" data-analytics="tags:free_exchange"><span>Free exchange</span></a></nav></p></div></div></article></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[On the cruelty of really teaching computing science (1988) (152 pts)]]></title>
            <link>https://www.cs.utexas.edu/~EWD/transcriptions/EWD10xx/EWD1036.html</link>
            <guid>41295433</guid>
            <pubDate>Mon, 19 Aug 2024 23:35:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cs.utexas.edu/~EWD/transcriptions/EWD10xx/EWD1036.html">https://www.cs.utexas.edu/~EWD/transcriptions/EWD10xx/EWD1036.html</a>, See on <a href="https://news.ycombinator.com/item?id=41295433">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="frame">
				<p>
<u>On the cruelty of really teaching computing science</u>
</p>
				<p>The second part of this talk pursues some of the scientific and educational consequences of the assumption that computers represent a radical novelty. In order to give this assumption clear contents, we have to be much more precise as to what we mean in this context by the adjective "radical". We shall do so in the first part of this talk, in which we shall furthermore supply evidence in support of our assumption.</p>
				<p>The usual way in which we plan today for tomorrow is in yesterday's vocabulary. We do so, because we try to get away with the concepts we are familiar with and that have acquired their meanings in our past experience. Of course, the words and the concepts don't quite fit because our future differs from our past, but then we stretch them a little bit. Linguists are quite familiar with the phenomenon that the meanings of words evolve over time, but also know that this is a slow and gradual process.</p>
				<p>It is the most common way of trying to cope with novelty: by means of metaphors and analogies we try to link the new to the old, the novel to the familiar. Under sufficiently slow and gradual change, it works reasonably well; in the case of a sharp discontinuity, however, the method breaks down: though we may glorify it with the name "common sense", our past experience is no longer relevant, the analogies become too shallow, and the metaphors become more misleading than illuminating. This is the situation that is characteristic for the "radical" novelty.</p>
				<p>Coping with radical novelty requires an orthogonal method. One must consider one's own past, the experiences collected, and the habits formed in it as an unfortunate accident of history, and one has to approach the radical novelty with a blank mind, consciously refusing to try to link it with what is already familiar, because the familiar is hopelessly inadequate. One has, with initially a kind of split personality, to come to grips with a radical novelty as a dissociated topic in its own right. Coming to grips with a radical novelty amounts to creating and learning a new foreign language that can <em>not</em> be translated into one's mother tongue. (Any one who has learned quantum mechanics knows what I am talking about.) Needless to say, adjusting to radical novelties is not a very popular activity, for it requires hard work. For the same reason, the radical novelties themselves are unwelcome.</p>
				<p>By now, you may well ask why I have paid so much attention to and have spent so much eloquence on such a simple and obvious notion as the radical novelty. My reason is very simple: radical novelties are so disturbing that they tend to be suppressed or ignored, to the extent that even the possibility of their existence in general is more often denied than admitted.</p>
				<p>On the historical evidence I shall be short. Carl Friedrich Gauss, the Prince of Mathematicians but also somewhat of a coward, was certainly aware of the fate of Galileo —and could probably have predicted the calumniation of Einstein— when he decided to suppress his discovery of non-Euclidean geometry, thus leaving it to Bolyai and Lobatchewsky to receive the flak. It is probably more illuminating to go a little bit further back, to the Middle Ages. One of its characteristics was that "reasoning by analogy" was rampant; another characteristic was almost total intellectual stagnation, and we now see why the two go together. A reason for mentioning this is to point out that, by developing a keen ear for unwarranted analogies, one can detect a lot of medieval thinking today.</p>
				<p>The other thing I can not stress enough is that the fraction of the population for which gradual change seems to be all but the only paradigm of history is very large, probably much larger than you would expect. Certainly when I started to observe it, their number turned out to be much larger than I had expected.</p>
				<p>For instance, the vast majority of the mathematical community has never challenged its tacit assumption that doing mathematics will remain very much the same type of mental activity it has always been: new topics will come, flourish, and go as they have done in the past, but, the human brain being what it is, our ways of teaching, learning, and understanding mathematics, of problem solving, and of mathematical discovery will remain pretty much the same. Herbert Robbins clearly states why he rules out a quantum leap in mathematical ability:</p>
				<blockquote>
					"Nobody is going to run 100 meters in five seconds, no matter how much is invested in training and machines. The same can be said about using the brain. The human mind is no different now from what it was five thousand years ago. And when it comes to mathematics, you must realize that this is the human mind at an extreme limit of its capacity."</blockquote>
				<p>My comment in the margin was "so reduce the use of the brain and calculate!". Using Robbins's own analogy, one could remark that, for going from A to B fast, there could now exist alternatives to running that are orders of magnitude more effective. Robbins flatly refuses to honour any alternative to time-honoured brain usage with the name of "doing mathematics", thus exorcizing the danger of radical novelty by the simple device of adjusting his definitions to his needs: simply by definition, mathematics will continue to be what it used to be. So much for the mathematicians.</p>
				<p>Let me give you just one more example of the widespread disbelief in the existence of radical novelties and, hence, in the need of learning how to cope with them. It is the prevailing educational practice, for which gradual, almost imperceptible, change seems to be the exclusive paradigm. How many educational texts are not recommended for their appeal to the student's intuition! They constantly try to present everything that could be an exciting novelty as something as familiar as possible. They consciously try to link the new material to what is supposed to be the student's familiar world. It already starts with the teaching of arithmetic. Instead of teaching 2 + 3 = 5 , the hideous arithmetic operator "plus" is carefully disguised by calling it "and", and the little kids are given lots of familiar examples first, with clearly visible such as apples and pears, which are <em>in</em>, in contrast to equally countable objects such as percentages and electrons, which are <em>out</em>. The same silly tradition is reflected at university level in different introductory calculus courses for the future physicist, architect, or business major, each adorned with examples from the respective fields. The educational dogma seems to be that everything is fine as long as the student does not notice that he is learning something really new; more often than not, the student's impression is indeed correct. I consider the failure of an educational practice to prepare the next generation for the phenomenon of radical novelties a serious shortcoming. [When King Ferdinand visited the conservative university of Cervera, the Rector proudly reassured the monarch with the words; "Far be from us, Sire, the dangerous novelty of thinking.". Spain's problems in the century that followed justify my characterization of the shortcoming as "serious".] So much for education's adoption of the paradigm of gradual change.</p>
				<p>The concept of radical novelties is of contemporary significance because, while we are ill-prepared to cope with them, science and technology have now shown themselves expert at inflicting them upon us. Earlier scientific examples are the theory of relativity and quantum mechanics; later technological examples are the atom bomb and the pill. For decades, the former two gave rise to a torrent of religious, philosophical, or otherwise quasi-scientific tracts. We can daily observe the profound inadequacy with which the latter two are approached, be it by our statesmen and religious leaders or by the public at large. So much for the damage done to our peace of mind by radical novelties.</p>
				<p>I raised all this because of my contention that automatic computers represent a radical novelty and that only by identifying them as such can we identify all the nonsense, the misconceptions and the mythology that surround them. Closer inspection will reveal that it is even worse, viz. that automatic computers embody not only one radical novelty but two of them.</p>
				<p>The first radical novelty is a direct consequence of the raw power of today's computing equipment. We all know how we cope with something big and complex; divide and rule, i.e. we view the whole as a compositum of parts and deal with the parts separately. And if a part is too big, we repeat the procedure. The town is made up from neighbourhoods, which are structured by streets, which contain buildings, which are made from walls and floors, that are built from bricks, etc. eventually down to the elementary particles. And we have all our specialists along the line, from the town planner, via the architect to the solid state physicist and further. Because, in a sense, the whole is "bigger" than its parts, the depth of a hierarchical decomposition is some sort of logarithm of the ratio of the "sizes" of the whole and the ultimate smallest parts. From a bit to a few hundred megabytes, from a microsecond to a half an hour of computing confronts us with completely baffling ratio of 10<sup>9</sup>! The programmer is in the unique position that his is the only discipline and profession in which such a gigantic ratio, which totally baffles our imagination, has to be bridged by a single technology. He has to be able to think in terms of conceptual hierarchies that are much deeper than a single mind ever needed to face before. Compared to that number of semantic levels, the average mathematical theory is almost flat. By evoking the need for deep conceptual hierarchies, the automatic computer confronts us with a radically new intellectual challenge that has no precedent in our history.</p>
				<p>Again, I have to stress this radical novelty because the true believer in gradual change and incremental improvements is unable to see it. For him, an automatic computer is something like the familiar cash register, only somewhat bigger, faster, and more flexible. But the analogy is ridiculously shallow: it is orders of magnitude worse than comparing, as a means of transportation, the supersonic jet plane with a crawling baby, for that speed ratio is only a thousand.</p>
				<p>The second radical novelty is that the automatic computer is our first large-scale digital device. We had a few with a noticeable discrete component: I just mentioned the cash register and can add the typewriter with its individual keys: with a single stroke you can type either a Q or a W but, though their keys are next to each other, not a mixture of those two letters. But such mechanisms are the exception, and the vast majority of our mechanisms are viewed as analogue devices whose behaviour is over a large range a continuous function of all parameters involved: if we press the point of the pencil a little bit harder, we get a slightly thicker line, if the violinist slightly misplaces his finger, he plays slightly out of tune. To this I should add that, to the extent that we view ourselves as mechanisms, we view ourselves primarily as analogue devices: if we push a little harder we expect to do a little better. Very often the behaviour is not only a continuous but even a monotonic function: to test whether a hammer suits us over a certain range of nails, we try it out on the smallest and largest nails of the range, and if the outcomes of those two experiments are positive, we are perfectly willing to believe that the hammer will suit us for all nails in between.</p>
				<p>It is possible, and even tempting, to view a program as an abstract mechanism, as a device of some sort. To do so, however, is highly dangerous: the analogy is too shallow because a program is, as a mechanism, totally different from all the familiar analogue devices we grew up with. Like all digitally encoded information, it has unavoidably the uncomfortable property that the smallest possible perturbations —i.e. changes of a single bit— can have the most drastic consequences. [For the sake of completness I add that the picture is not essentially changed by the introduction of redundancy or error correction.] In the discrete world of computing, there is no meaningful metric in which "small" changes and "small" effects go hand in hand, and there never will be.</p>
				<p>This second radical novelty shares the usual fate of all radical novelties: it is denied, because its truth would be too discomforting. I have no idea what this specific denial and disbelief costs the United States, but a million dollars a day seems a modest guess.</p>
				<p>Having described —admittedly in the broadest possible terms— the nature of computing's novelties, I shall now provide the evidence that these novelties are, indeed, radical. I shall do so by explaining a number of otherwise strange phenomena as frantic —but, as we now know, doomed— efforts at hiding or denying the frighteningly unfamiliar.</p>
				<p>A number of these phenomena have been bundled under the name "Software Engineering". As economics is known as "The Miserable Science", software engineering should be known as "The Doomed Discipline", doomed because it cannot even approach its goal since its goal is self-contradictory. Software engineering, of course, presents itself as another worthy cause, but that is eyewash: if you carefully read its literature and analyse what its devotees actually do, you will discover that software engineering has accepted as its charter "How to program if you cannot.".</p>
				<p>The popularity of its name is enough to make it suspect. In what we denote as "primitive societies", the superstition that knowing someone's true name gives you magic power over him is not unusual. We are hardly less primitive: why do we persist here in answering the telephone with the most unhelpful "hello" instead of our name?</p>
				<p>Nor are we above the equally primitive superstition that we can gain some control over some unknown, malicious demon by calling it by a safe, familiar, and innocent name, such as "engineering". But it is totally symbolic, as one of the US computer manufacturers proved a few years ago when it hired, one night, hundreds of new "software engineers" by the simple device of elevating all its programmers to that exalting rank. So much for that term.</p>
				<p>The practice is pervaded by the reassuring illusion that programs are just devices like any others, the only difference admitted being that their manufacture might require a new type of craftsmen, viz. programmers. From there it is only a small step to measuring "programmer productivity" in terms of "number of lines of code produced per month". This is a very costly measuring unit because it encourages the writing of insipid code, but today I am less interested in how foolish a unit it is from even a pure business point of view. My point today is that, if we wish to count lines of code, we should not regard them as "lines produced" but as "lines spent": the current conventional wisdom is so foolish as to book that count on the wrong side of the ledger.</p>
				<p>Besides the notion of productivity, also that of quality control continues to be distorted by the reassuring illusion that what works with other devices works with programs as well. It is now two decades since it was pointed out that program testing may convincingly demonstrate the presence of bugs, but can never demonstrate their absence. After quoting this well-publicized remark devoutly, the software engineer returns to the order of the day and continues to refine his testing strategies, just like the alchemist of yore, who continued to refine his chrysocosmic purifications.</p>
				<p>Unfathomed misunderstanding is further revealed by the term "software maintenance", as a result of which many people continue to believe that programs —and even programming languages themselves— are subject to wear and tear. Your car needs maintenance too, doesn't it? Famous is the story of the oil company that believed that its PASCAL programs did not last as long as its FORTRAN programs "because PASCAL was not maintained".</p>
				<p>In the same vein I must draw attention to the astonishing readiness with which the suggestion has been accepted that the pains of software production are largely due to a lack of appropriate "programming tools". (The telling "programmer's workbench" was soon to follow.) Again, the shallowness of the underlying analogy is worthy of the Middle Ages. Confrontations with insipid "tools" of the "algorithm-animation" variety has not mellowed my judgement; on the contrary, it has confirmed my initial suspicion that we are primarily dealing with yet another dimension of the snake oil business.</p>
				<p>Finally, to correct the possible impression that the inability to face radical novelty is confined to the industrial world, let me offer you an explanation of the —at least American— popularity of Artificial Intelligence. One would expect people to feel threatened by the "giant brains or machines that think". In fact, the frightening computer becomes less frightening if it is used only to simulate a familiar noncomputer. I am sure that this explanation will remain controversial for quite some time, for Artificial Intelligence as mimicking the human mind prefers to view itself as at the front line, whereas my explanation relegates it to the rearguard. (The effort of using machines to mimic the human mind has always struck me as rather silly: I'd rather use them to mimic something better.)</p>
				<p>So much for the evidence that the computer's novelties are, indeed, radical.</p>
				<p>And now comes the second —and hardest— part of my talk: the scientific and educational consequences of the above. The educational consequences are, of course, the hairier ones, so let's postpone their discussion and stay for a while with computing science itself. What is computing? And what is a science of computing about?</p>
				<p>Well, when all is said and done, the only thing computers can do for us is to manipulate symbols and produce results of such manipulations. From our previous observations we should recall that this is a discrete world and, moreover, that both the number of symbols involved and the amount of manipulation performed are many orders of magnitude larger than we can envisage: they totally baffle our imagination and we must therefore not try to imagine them.</p>
				<p>But before a computer is ready to perform a class of meaningful manipulations —or calculations, if you prefer— we must write a program. What is a program? Several answers are possible. We can view the program as what turns the general-purpose computer into a special-purpose symbol manipulator, and does so without the need to change a single wire (This was an enormous improvement over machines with problem-dependent wiring panels.) I prefer to describe it the other way round: the program is an abstract symbol manipulator, which can be turned into a concrete one by supplying a computer to it. After all, it is no longer the purpose of programs to instruct our machines; these days, it is the purpose of machines to execute our programs.</p>
				<p>So, we have to design abstract symbol manipulators. We all know what they look like: they look like programs or —to use somewhat more general terminology— usually rather elaborate formulae from some formal system. It really helps to view a program as a formula. Firstly, it puts the programmer's task in the proper perspective: he has to derive that formula. Secondly, it explains why the world of mathematics all but ignored the programming challenge: programs were so much longer formulae than it was used to that it did not even recognize them as such. Now back to the programmer's job: he has to derive that formula, he has to derive that program. We know of only one reliable way of doing that, viz. by means of symbol manipulation. And now the circle is closed: we construct our mechanical symbol manipulators by means of human symbol manipulation.</p>
				<p>Hence, computing science is —and will always be— concerned with the interplay between mechanized and human symbol manipulation, usually referred to as "computing" and "programming" respectively. An immediate benefit of this insight is that it reveals "automatic programming" as a contradiction in terms. A further benefit is that it gives us a clear indication where to locate computing science on the world map of intellectual disciplines: in the direction of formal mathematics and applied logic, but ultimately far beyond where those are now, for computing science is interested in <u>effective</u> use of formal methods and on a much, much, larger scale than we have witnessed so far. Because no endeavour is respectable these days without a TLA (= Three-Letter Acronym), I propose that we adopt for computing science FMI (= Formal Methods Initiative), and, to be on the safe side, we had better follow the shining examples of our leaders and make a Trade Mark of it.</p>
				<p>In the long run I expect computing science to transcend its parent disciplines, mathematics and logic, by effectively realizing a significant part of Leibniz's Dream of providing symbolic calculation as an alternative to human reasoning. (Please note the difference between "mimicking" and "providing an alternative to": alternatives are allowed to be better.)</p>
				<p>Needless to say, this vision of what computing science is about is not universally applauded. On the contrary, it has met widespread —and sometimes even violent— opposition from all sorts of directions. I mention as examples</p>
				<p>(0) the mathematical guild, which would rather continue to believe that the Dream of Leibniz is an unrealistic illusion</p>
				<p>(1) the business community, which, having been sold to the idea that computers would make life easier, is mentally unprepared to accept that they only solve the easier problems at the price of creating much harder ones</p>
				<p>(2) the subculture of the compulsive programmer, whose ethics prescribe that one silly idea and a month of frantic coding should suffice to make him a life-long millionaire</p>
				<p>(3) computer engineering, which would rather continue to act as if it is all only a matter of higher bit rates and more flops per second</p>
				<p>(4) the military, who are now totally absorbed in the business of using computers to mutate billion-dollar budgets into the illusion of automatic safety</p>
				<p>(5) all soft sciences for which computing now acts as some sort of interdisciplinary haven</p>
				<p>(6) the educational business that feels that, if it has to teach formal mathematics to CS students, it may as well close its schools.</p>
				<p>And with this sixth example I have reached, imperceptibly but also alas unavoidably, the most hairy part of this talk: educational consequences.</p>
				<p>The problem with educational policy is that it is hardly influenced by scientific considerations derived from the topics taught, and almost entirely determined by extra-scientific circumstances such as the combined expectations of the students, their parents and their future employers, and the prevailing view of the role of the university: is the stress on training its graduates for today's entry-level jobs or to providing its alumni with the intellectual bagage and attitudes that will last them another 50 years? Do we grudgingly grant the abstract sciences only a far-away corner on campus, or do we recognize them as the indispensable motor of the high-technology industry? Even if we do the latter, do we recognize a high-technology industry as such if its technology primarily belongs to formal mathematics? Do the universities provide for society the intellectual leadership it needs or only the training it asks for?</p>
				<p>Traditional academic rhetoric is perfectly willing to give to these questions the reassuring answers, but I don't believe them. By way of illustration of my doubts, in a recent article on "Who Rules Canada?", David H. Flaherty bluntly states "Moreover, the business elite dismisses traditional academics and intellectuals as largely irrelevant and powerless.".</p>
				<p>So, if I look into my foggy crystal ball at the future of computing science education, I overwhelmingly see the depressing picture of "Business as usual". The universities will continue to lack the courage to teach hard science, they will continue to misguide the students, and each next stage of infantilization of the curriculum will be hailed as educational progress.</p>
				<p>I now have had my foggy crystal ball for quite a long time. Its predictions are invariably gloomy and usually correct, but I am quite used to that and they won't keep me from giving you a few suggestions, even if it is merely an exercise in futility whose only effect is to make you feel guilty.</p>
				<p>We could, for instance, begin with cleaning up our language by no longer calling a bug a bug but by calling it an error. It is much more honest because it squarely puts the blame where it belongs, viz. with the programmer who made the error. The animistic metaphor of the bug that maliciously sneaked in while the programmer was not looking is intellectually dishonest as it disguises that the error is the programmer's own creation. The nice thing of this simple change of vocabulary is that it has such a profound effect: while, before, a program with only one bug used to be "almost correct", afterwards a program with an error is just "wrong" (because in error).</p>
				<p>My next linguistical suggestion is more rigorous. It is to fight the "if-this-guy-wants-to-talk-to-that-guy" syndrome: <em>never</em> refer to parts of programs or pieces of equipment in an anthropomorphic terminology, nor allow your students to do so. This linguistical improvement is much harder to implement than you might think, and your department might consider the introduction of fines for violations, say a quarter for undergraduates, two quarters for graduate students, and five dollars for faculty members: by the end of the first semester of the new regime, you will have collected enough money for two scholarships.</p>
				<p>The reason for this last suggestion is that the anthropomorphic metaphor —for whose introduction we can blame John von Neumann— is an enormous handicap for every computing community that has adopted it. I have now encountered programs wanting things, knowing things, expecting things, believing things, etc., and each time that gave rise to avoidable confusions. The analogy that underlies this personification is so shallow that it is not only misleading but also paralyzing.</p>
				<p>It is misleading in the sense that it suggests that we can adequately cope with the unfamiliar discrete in terms of the familiar continuous, i.e. ourselves, quod non. It is paralyzing in the sense that, because persons exist and act <em>in time</em>, its adoption effectively prevents a departure from operational semantics and thus forces people to think about programs in terms of computational behaviours, based on an underlying computational model. This is bad, because operational reasoning is a tremendous waste of mental effort.</p>
				<p>Let me explain to you the nature of that tremendous waste, and allow me to try to convince you that the term "tremendous waste of mental effort" is <u>not</u> an exaggeration. For a short while, I shall get highly technical, but don't get frightened: it is the type of mathematics that one can do with one's hands in one's pockets. The point to get across is that if we have to demonstrate something about <em>all</em> the elements of a large set, it is hopelessly inefficient to deal with all the elements of the set individually: the efficient argument does not refer to individual elements at all and is carried out in terms of the set's definition.</p>
				<p>Consider the plane figure <var>Q</var>, defined as the 8 by 8 square from which, at two opposite corners, two 1 by 1 squares have been removed. The area of <var>Q</var> is 62, which equals the combined area of 31 dominos of 1 by 2. The theorem is that the figure <var>Q</var> cannot be covered by 31 of such dominos.</p>
				<p>Another way of stating the theorem is that if you start with squared paper and begin covering this by placing each next domino on two new adjacent squares, no placement of 31 dominos will yield the figure <var>Q</var>.</p>
				<p>So, a possible way of proving the theorem is by generating all possible placements of dominos and verifying for each placement that it does not yield the figure <var>Q</var>: a tremendously laborious job.</p>
				<p>The simple argument, however is as follows. Colour the squares of the squared paper as on a chess board. Each domino, covering two adjacent squares, covers 1 white and 1 black square, and, hence, each placement covers as many white squares as it covers black squares. In the figure <var>Q</var>, however, the number of white squares and the number of black squares differ by 2 —opposite corners lying on the same diagonal— and hence no placement of dominos yields figure <var>Q</var>.</p>
				<p>Not only is the above simple argument many orders of magnitude shorter than the exhaustive investigation of the possible placements of 31 dominos, it is also essentially more powerful, for it covers the generalization of <var>Q</var> by replacing the original 8 by 8 square by <em>any</em> rectangle with sides of even length. The number of such rectangles being infinite, the former method of exhaustive exploration is essentially inadequate for proving our generalized theorem.</p>
				<p>And this concludes my example. It has been presented because it illustrates in a nutshell the power of down-to-earth mathematics; needless to say, refusal to exploit this power of down-to-earth mathematics amounts to intellectual and technological suicide. The moral of the story is: deal with all elements of a set by ignoring them and working with the set's definition.</p>
				<p>Back to programming. The statement that a given program meets a certain specification amounts to a statement about <em>all</em> computations that could take place under control of that given program. And since this set of computations is defined by the given program, our recent moral says: deal with all computations possible under control of a given program by ignoring them and working with the program. We must learn to work with program texts while (temporarily) ignoring that they admit the interpretation of executable code.</p>
				<p>Another way of saying the same thing is the following one. A programming language, with its formal syntax and with the proof rules that define its semantics, is a formal system for which program execution provides only a model. It is well-known that formal systems should be dealt with in their own right, and not in terms of a specific model. And, again, the corollary is that we should reason about programs without even mentioning their possible "behaviours".</p>
				<p>And this concludes my technical excursion into the reason why operational reasoning about programming is "a tremendous waste of mental effort" and why, therefore, in computing science the anthropomorphic metaphor should be banned.</p>
				<p>Not everybody understands this sufficiently well. I was recently exposed to a demonstration of what was pretended to be educational software for an introductory programming course. With its "visualizations" on the screen it was such an obvious case of curriculum infantilization that its author should be cited for "contempt" of the student body", but this was only a minor offense compared with what the visualizations were used for: they were used to display all sorts of features of computations evolving under control of the student's program! The system highlighted precisely what the student has to learn to ignore, it reinforced precisely what the student has to unlearn. Since breaking out of bad habits, rather than acquiring new ones, is the toughest part of learning, we must expect from that system permanent mental damage for most students exposed to it.</p>
				<p>Needless to say, that system completely hid the fact that, all by itself, a program is no more than half a conjecture. The other half of the conjecture is the functional specification the program is supposed to satisfy. The programmer's task is to present such complete conjectures as proven theorems.</p>
				<p>Before we part, I would like to invite you to consider the following way of doing justice to computing's radical novelty in an introductory programming course.</p>
				<p>On the one hand, we teach what looks like the predicate calculus, but we do it very differently from the philosophers. In order to train the novice programmer in the manipulation of uninterpreted formulae, we teach it more as boolean algebra, familiarizing the student with all algebraic properties of the logical connectives. To further sever the links to intuition, we rename the values {true, false} of the boolean domain as {black, white}.</p>
				<p>On the other hand, we teach a simple, clean, imperative programming language, with a skip and a multiple assignment as basic statements, with a block structure for local variables, the semicolon as operator for statement composition, a nice alternative construct, a nice repetition and, if so desired, a procedure call. To this we add a minimum of data types, say booleans, integers, characters and strings. The essential thing is that, for whatever we introduce, the corresponding semantics is defined by the proof rules that go with it.</p>
				<p>Right from the beginning, and all through the course, we stress that the programmer's task is not just to write down a program, but that his main task is to give a formal proof that the program he proposes meets the equally formal functional specification. While designing proofs and programs hand in hand, the student gets ample opportunity to perfect his manipulative agility with the predicate calculus. Finally, in order to drive home the message that this introductory programming course is primarily a course in formal mathematics, we see to it that the programming language in question has not been implemented on campus so that students are protected from the temptation to test their programs. And this concludes the sketch of my proposal for an introductory programming course for freshmen.</p>
				<p>This is a serious proposal, and utterly sensible. Its only disadvantage is that it is too radical for many, who, being unable to accept it, are forced to invent a quick reason for dismissing it, no matter how invalid. I'll give you a few quick reasons.</p>
				<p>You don't need to take my proposal seriously because it is so ridiculous that I am obviously completely out of touch with the real world. But that kite won't fly, for I know the real world only too well: the problems of the real world are primarily those you are left with when you refuse to apply their effective solutions. So, let us try again.</p>
				<p>You don't need to take my proposal seriously because it is utterly unrealistic to try to teach such material to college freshmen. Wouldn't that be an easy way out? You just postulate that this would be far too difficult. But that kite won't fly either for the postulate has been proven wrong: since the early 80's, such an introductory programming course has successfully been given to hundreds of college freshmen each year. [Because, in my experience, saying this once does not suffice, the previous sentence should be repeated at least another two times.] So, let us try again.</p>
				<p>Reluctantly admitting that it could perhaps be taught to sufficiently docile students, you yet reject my proposal because such a course would deviate so much from what 18-year old students are used to and expect that inflicting it upon them would be an act of educational irresponsibility: it would only frustrate the students. Needless to say, that kite won't fly either. It is true that the student that has never manipulated uninterpreted formulae quickly realizes that he is confronted with something totally unlike anything he has ever seen before. But fortunately, the rules of manipulation are in this case so few and simple that very soon thereafter he makes the exciting discovery that he is beginning to master the use of a tool that, in all its simplicity, gives him a power that far surpasses his wildest dreams.</p>
				<p>Teaching to unsuspecting youngsters the effective use of formal methods is one of the joys of life because it is so extremely rewarding. Within a few months, they find their way in a new world with a justified degree of confidence that is radically novel for them; within a few months, their concept of intellectual culture has acquired a radically novel dimension. To my taste and style, that is what education is about. Universities should not be afraid of teaching radical novelties; on the contrary, it is their calling to welcome the opportunity to do so. Their willingness to do so is our main safeguard against dictatorships, be they of the proletariat, of the scientific establishment, or of the corporate elite.</p>
				<p>Austin, 2 December 1988</p>
				<p>prof. dr. Edsger W. Dijkstra<br>
					Department of Computer Sciences<br>
					The University of Texas at Austin<br>
					Austin, TX 78712-1188<br>
					USA</p>
				<hr>
				<p><span size="-1">Transcription by Javier Smaldone.<br>
						Revised <csobj format="MedDate" h="13" region="15" t="DateTime" w="95">Tue, 12 May 2009</csobj>.</span></p>
				
			
			
				
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
		
			
		
			
				
			



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI companies are pivoting from creating gods to building products (129 pts)]]></title>
            <link>https://www.aisnakeoil.com/p/ai-companies-are-pivoting-from-creating</link>
            <guid>41294764</guid>
            <pubDate>Mon, 19 Aug 2024 21:34:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.aisnakeoil.com/p/ai-companies-are-pivoting-from-creating">https://www.aisnakeoil.com/p/ai-companies-are-pivoting-from-creating</a>, See on <a href="https://news.ycombinator.com/item?id=41294764">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><span>AI companies are collectively planning to spend a </span><a href="https://www.goldmansachs.com/images/migrated/insights/pages/gs-research/gen-ai--too-much-spend,-too-little-benefit-/TOM_AI%202.0_ForRedaction.pdf" rel="">trillion dollars</a><span> on hardware and data centers, but there’s been relatively little to show for it so far. This has led to a chorus of concerns that generative AI is a </span><a href="https://www.inc.com/sam-blum/new-warnings-ai-bubble-when-could-it-burst.html" rel="">bubble</a><span>. We won’t offer any predictions on what’s about to happen. But we think we have a solid diagnosis of how things got to this point in the first place.</span></p><p>In this post, we explain the mistakes that AI companies have made and how they have been trying to correct them. Then we will talk about five barriers they still have to overcome in order to make generative AI commercially successful enough to justify the investment.</p><p>When ChatGPT launched, people found a thousand unexpected uses for it. This got AI developers overexcited. They completely misunderstood the market, underestimating the huge gap between proofs of concept and reliable products. This misunderstanding led to two opposing but equally flawed approaches to commercializing LLMs.&nbsp;</p><p>OpenAI and Anthropic focused on building models and not worrying about products. For example, it took 6 months for OpenAI to bother to release a ChatGPT iOS app and 8 months for an Android app!</p><p>Google and Microsoft shoved AI into everything in a panicked race, without thinking about which products would actually benefit from AI and how they should be integrated.</p><p>Both groups of companies forgot the “make something people want” mantra. The generality of LLMs allowed developers to fool themselves into thinking that they were exempt from the need to find a product-market fit, as if prompting a model to perform a task is a replacement for carefully designed products or features.</p><p><span>OpenAI and Anthropic’s DIY approach meant that early adopters of LLMs disproportionately tended to be bad actors, since they are more invested in figuring out how to adapt new technologies for their purposes, whereas everyday users want easy-to-use products. This has contributed to a poor public perception of the technology.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-147899150" href="https://www.aisnakeoil.com/p/ai-companies-are-pivoting-from-creating#footnote-1-147899150" target="_self" rel="">1</a></span></p><p><span>Meanwhile the AI-in-your-face approach by Microsoft and Google has led to features that are occasionally useful and more often annoying. It also led to many unforced errors due to inadequate testing like Microsoft's early </span><a href="https://www.nytimes.com/2023/02/16/technology/bing-chatbot-microsoft-chatgpt.html" rel="">Sydney</a><span> chatbot and Google's </span><a href="https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical" rel="">Gemini</a><span> image generator. This has also caused a backlash.</span></p><p>But companies are changing their ways. OpenAI seems to be transitioning from a research lab focused on a speculative future to something resembling a regular product company. If you take all the human-interest elements out of the OpenAI boardroom drama, it was fundamentally about the company's shift from creating gods to building products. Anthropic has been picking up many of the researchers and developers at OpenAI who cared more about artificial general intelligence and felt out of place at OpenAI, although Anthropic, too, has recognized the need to build products.</p><p><span>Google and Microsoft are slower to learn, but our guess is that </span><a href="https://www.vox.com/technology/354794/apple-artificial-intelligence-ai-wwdc" rel="">Apple</a><span> will force them to change. Last year Apple was seen as a laggard on AI, but it seems clear in retrospect that the slow and thoughtful approach that Apple showcased at WWDC, its developer conference, is more likely to resonate with users.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-147899150" href="https://www.aisnakeoil.com/p/ai-companies-are-pivoting-from-creating#footnote-2-147899150" target="_self" rel="">2</a></span><span> Google seems to have put more thought into integrating AI in its upcoming </span><a href="https://blog.google/products/pixel/google-pixel-9-pro-xl/" rel="">Pixel</a><span> phones and Android than it did into interesting it in search, but the phones aren’t out yet, so let’s see.&nbsp;</span></p><p><span>And then there’s Meta, whose vision is to use AI to create content and engagement on its ad-driven social media platforms. The societal implications of a world awash in AI-generated content are </span><a href="https://knightcolumbia.org/content/how-to-prepare-for-the-deluge-of-generative-ai-on-social-media" rel="">double-edged</a><span>, but from a business perspective it makes sense.</span></p><p><span>There are five limitations of LLMs that developers need to tackle in order to make compelling AI-based consumer products.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-147899150" href="https://www.aisnakeoil.com/p/ai-companies-are-pivoting-from-creating#footnote-3-147899150" target="_self" rel="">3</a></span><span> (We will discuss many of these in our upcoming </span><a href="https://sites.google.com/princeton.edu/agents-workshop" rel="">online workshop</a><span> on building useful and reliable AI agents on August 29.)</span></p><p>There are many applications where capability is not the barrier, cost is. Even in a simple chat application, cost concerns dictate how much history a bot can keep track of — processing the entire history for every response quickly gets prohibitively expensive as the conversation grows longer.</p><p><span>There has been rapid progress on cost — in the last 18 months, cost-for-equivalent-capability has dropped by a factor of over 100.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-147899150" href="https://www.aisnakeoil.com/p/ai-companies-are-pivoting-from-creating#footnote-4-147899150" target="_self" rel="">4</a></span><span> As a result, companies are claiming that LLMs are, or will soon be, “</span><a href="https://x.com/sama/status/1813984333352649087" rel="">too cheap to meter</a><span>”. Well, we’ll believe it when they make the API free.&nbsp;</span></p><p><span>More seriously, the reason we think cost will continue to be a concern is that in many applications, cost improvements directly translate to accuracy improvements. That’s because repeatedly retrying a task tens, thousands, or even millions of times turns out to be a good way to improve the chances of success, given the randomness of LLMs. So the cheaper the model, the more retries we can make with a given budget. We quantified this in our </span><a href="https://www.aisnakeoil.com/p/new-paper-ai-agents-that-matter" rel="">recent paper</a><span> on agents; since then, many other papers have made </span><a href="https://arxiv.org/html/2408.03314v1" rel="">similar</a><span> </span><a href="https://arxiv.org/html/2408.03314v1" rel="">points</a><span>.</span></p><p><span>That said, it is plausible that we’ll soon get to a point where in </span><em>most</em><span> applications, cost optimization isn’t a serious concern.</span></p><p><span>We see capability and reliability as somewhat orthogonal. If an AI system performs a task correctly 90% of the time, we can say that it is </span><em>capable</em><span> of performing the task but it cannot do so </span><em>reliably</em><span>. The techniques that get us to 90% are unlikely to get us to 100%.&nbsp;</span></p><p><span>With statistical learning based systems, perfect accuracy is intrinsically hard to achieve. If you think about the success stories of machine learning, like ad targeting or fraud detection or, more recently, weather forecasting, perfect accuracy isn’t the goal — as long as the system is better than the state of the art, it is useful. Even in medical diagnosis and other healthcare applications, we </span><a href="https://www.himss.org/news/north-carolina-hospital-system-reduces-sepsis-cases-using-predictive-analytics" rel="">tolerate</a><span> a lot of error.&nbsp;</span></p><p><span>But when developers put AI in consumer products, people expect it to behave like software, which means that it needs to work deterministically. If your AI travel agent books vacations to the correct destination only 90% of the time, it won’t be successful. As we’ve </span><a href="https://www.aisnakeoil.com/p/new-paper-ai-agents-that-matter" rel="">written before</a><span>, reliability limitations partly explain the failures of recent AI-based gadgets.&nbsp;</span></p><p>AI developers have been slow to recognize this because as experts, we are used to conceptualizing AI as fundamentally different from traditional software. For example, the two of us are heavy users of chatbots and agents in our everyday work, and it has become almost automatic for us to work around the hallucinations and unreliability of these tools. A year ago, AI developers hoped or assumed that non-expert users would learn to adapt to AI, but it has gradually become clear that companies will have to adapt AI to user expectations instead, and make AI behave like traditional software.</p><p><span>Improving reliability is a research interest of our team at Princeton. For now, it’s fundamentally an open question whether it’s possible to build deterministic systems out of stochastic components (LLMs). Some companies have claimed to have solved reliability — for example, legal tech vendors have touted “hallucination-free” systems. But these claims were shown to be </span><a href="https://dho.stanford.edu/wp-content/uploads/Legal_RAG_Hallucinations.pdf" rel="">premature</a><span>.</span></p><p><span>Historically, machine learning has often relied on sensitive data sources such browsing histories for ad targeting or medical records for </span><a href="https://www.wired.com/story/google-deepmind-nhs-health-data/" rel="">health tech</a><span>. In this sense, LLMs are a bit of an anomaly, since they are primarily trained on public sources such as web pages and books.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5-147899150" href="https://www.aisnakeoil.com/p/ai-companies-are-pivoting-from-creating#footnote-5-147899150" target="_self" rel="">5</a></span></p><p><span>But with AI assistants, privacy concerns have come roaring back. To build useful assistants, companies have to train systems on user interactions. For example, to be good at composing emails, it would be very helpful if models were </span><a href="https://www.nytimes.com/2024/06/26/technology/terms-service-ai-training.html" rel="">trained on emails</a><span>. Companies’ privacy policies are vague about this and it is not clear to what extent this is happening.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-6-147899150" href="https://www.aisnakeoil.com/p/ai-companies-are-pivoting-from-creating#footnote-6-147899150" target="_self" rel="">6</a></span><span> Emails, documents, screenshots, etc. are potentially much more sensitive than chat interactions.&nbsp;</span></p><p><span>There is a distinct type of privacy concern relating to inference rather than training. For assistants to do useful things for us, they must have access to our personal data. For example, Microsoft announced a controversial feature that would involve taking screenshots of users’ PCs every few seconds, in order to give its CoPilot AI a memory of your activities. But there was an outcry and the company </span><a href="https://www.bbc.com/news/articles/cd11rje1mrro" rel="">backtracked</a><span>.</span></p><p><span>We caution against purely technical interpretations of privacy such as “the data never leaves the device.” Meredith Whittaker </span><a href="https://mobile.x.com/mer__edith/status/1790692059059200017" rel="">argues</a><span> that on-device fraud detection normalizes always-on surveillance and that the infrastructure can be repurposed for more oppressive purposes. That said, </span><a href="https://www.wired.com/story/apple-intelligence-android-hybrid-ai-privacy/" rel="">technical innovations</a><span> can definitely help.</span></p><p><span>There is a cluster of related concerns when it comes to safety and security: unintentional failures such as the </span><a href="https://www.cnbc.com/2024/02/26/googles-gemini-ai-picture-generator-to-relaunch-in-a-few-weeks.html" rel="">biases</a><span> in Gemini’s image generation; misuses of AI such as voice cloning or deepfakes; and hacks such as prompt injection that can leak users’ data or harm the user in other ways.</span></p><p><span>We think accidental failures are fixable. As for most types of misuses, our view is that there is </span><a href="https://www.aisnakeoil.com/p/ai-safety-is-not-a-model-property" rel="">no way</a><span> to create a model that can’t be misused and so the defenses must primarily be located downstream. Of course, not everyone agrees, so companies will keep getting bad press for inevitable misuses, but they seem to have absorbed this as a cost of doing business.&nbsp;</span></p><p><span>Let’s talk about the third category — hacking. From what we can tell, it is the one that companies seem to be paying the least attention to. At least theoretically, </span><a href="https://arxiv.org/abs/2302.12173" rel="">catastrophic hacks</a><span> are possible, such as AI worms that spread from user to user, tricking those users’ AI assistants into doing harmful things including creating more copies of the worm.&nbsp;</span></p><p><span>Although there have been plenty of proof-of-concept demonstrations and </span><a href="https://embracethered.com/blog/posts/2023/google-bard-data-exfiltration/" rel="">bug</a><span> </span><a href="https://www.landh.tech/blog/20240304-google-hack-50000/" rel="">bounties</a><span> that uncovered these vulnerabilities in deployed products, we haven't seen this type of attack in the wild. We aren’t sure if this is because of the low adoption of AI assistants, or because the </span><a href="https://kai-greshake.de/posts/approaches-to-pi-defense/" rel="">clumsy defenses</a><span> that companies have pulled together have proven sufficient, or something else. Time will tell.</span></p><p>In many applications, the unreliability of LLMs means that there will have to be some way for the user to intervene if the bot goes off track. In a chatbot, it can be as simple as regenerating an answer or showing multiple versions and letting the user pick. But in applications where errors can be costly, such as flight booking, ensuring adequate supervision is more tricky, and the system must avoid annoying the user with too many interruptions.</p><p><span>The problem is even harder with natural language interfaces where the user speaks to the assistant and the assistant speaks back. This is where a lot of the potential of generative AI lies. As just one example, AI that disappeared into your </span><a href="https://www.techradar.com/computing/artificial-intelligence/i-finally-tried-the-meta-ai-in-my-ray-ban-smart-glasses-thanks-to-an-accidental-uk-launch-and-its-by-far-the-best-ai-wearable" rel="">glasses</a><span> and spoke to you when you needed it, without even being asked — such as by detecting that you were staring at a sign in a foreign language — would be a whole different experience than what we have today. But the constrained user interface leaves very little room for incorrect or unexpected behavior.</span></p><p><span>AI boosters often claim that due to the rapid pace of improvement in AI capabilities, we should see massive societal and economic effects soon. We are </span><a href="https://www.aisnakeoil.com/p/ai-scaling-myths" rel="">skeptical</a><span> of the trend extrapolation and sloppy thinking that goes into those capability forecasts. More importantly, even if AI capability does improve rapidly, developers have to solve the challenges discussed above. These are sociotechnical and not purely technical, so progress will be slow. And even if those challenges are solved, organizations need to integrate AI into existing products and workflows and train people to use it productively while avoiding its pitfalls. We should expect this to happen on a timescale of a decade or more rather than a year or two.&nbsp;</span></p><p><span>Benedikt Evans has </span><a href="https://www.ben-evans.com/benedictevans/2023/10/5/unbundling-ai" rel="">written</a><span> </span><a href="https://www.ben-evans.com/benedictevans/2024/6/8/building-ai-products" rel="">about</a><span> the importance of building single-purpose software using general-purpose language models.&nbsp;</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Appeals court finds California’s “Age Appropriate Design Code” unconstitutional (125 pts)]]></title>
            <link>https://www.techdirt.com/2024/08/19/court-sees-through-californias-protect-the-children-ruse-strikes-down-kids-code/</link>
            <guid>41294354</guid>
            <pubDate>Mon, 19 Aug 2024 20:33:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techdirt.com/2024/08/19/court-sees-through-californias-protect-the-children-ruse-strikes-down-kids-code/">https://www.techdirt.com/2024/08/19/court-sees-through-californias-protect-the-children-ruse-strikes-down-kids-code/</a>, See on <a href="https://news.ycombinator.com/item?id=41294354">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storywrap-446892">


<h3>from the <i>gee,-who-could-have-predicted</i> dept</h3>

<p>Friday morning gave us a nice victory for free speech in the 9th Circuit, where the appeals court panel <a href="https://cdn.ca9.uscourts.gov/datastore/opinions/2024/08/16/23-2969.pdf" target="_blank" rel="noreferrer noopener">affirmed most of the district court’s ruling</a> finding California’s “Age Appropriate Design Code” unconstitutional as it regulated speech.</p>
<p>There’s a fair bit of background here that’s worth going over, so bear with me. California’s Age Appropriate Design Code advanced through the California legislature somewhat quietly, with little opposition. Many of the bigger companies, like Meta and Google, were said to support it, mainly because they knew they could easily comply with their buildings full of lawyers, whereas smaller competitors would be screwed.</p>
<p>Indeed, for a period of time it felt like only Professor <a target="_blank" rel="noreferrer noopener" href="https://www.techdirt.com/2022/06/29/california-legislators-seek-to-burn-down-the-internet-for-the-children/">Eric Goldman</a> and <a target="_blank" rel="noreferrer noopener" href="https://www.techdirt.com/tag/ab-2273/">I</a> were screaming about the problems of the law. The law was drafted in part by <a target="_blank" rel="noreferrer noopener" href="https://www.techdirt.com/2022/08/25/why-is-a-british-baroness-drafting-california-censorship-laws/">a British Baroness and Hollywood movie director</a> who fell deep for the moral panic that the internet and mobile phones are obviously evil for kids. Despite the lack of actual evidence supporting this, she has been pushing for laws in the UK and America to suppress speech she finds harmful to kids.</p>
<p>In the US, some of us pointed out how this violates the First Amendment. I also pointed out that the law is <a target="_blank" rel="noreferrer noopener" href="https://www.techdirt.com/2022/08/24/dear-california-law-makers-how-the-hell-can-i-comply-with-your-new-age-appropriate-design-code/">literally impossible to comply with</a> for smaller sites like Techdirt.</p>
<p>The Baroness and the California legislators (who seem oddly deferential to her) tried to get around the obvious First Amendment issues by insisting that the bill was about <em>conduct</em> and <em>design</em> and not about speech. But as we pointed out, that was obviously a smokescreen. The only way to truly comply with the law was to suppress speech that politicians might later deem harmful to children.</p>
<p>California Governor Gavin Newsom <a target="_blank" rel="noreferrer noopener" href="https://www.techdirt.com/2022/09/15/gavin-newsom-fucks-over-the-open-internet-signs-disastrously-stupid-age-appropriate-design-code/">eagerly signed the bill into law</a>, wanting to get some headlines about how he was “protecting the children.” When NetChoice challenged the law, Newsom sent them a very threatening letter, <a target="_blank" rel="noreferrer noopener" href="https://www.techdirt.com/2023/06/01/governor-newsom-desperately-begs-netchoice-to-drop-its-lawsuit-over-unconstitutional-aadc-bill/">demanding they drop the lawsuit</a>. Thankfully, they did not, and the court saw through the ruse and found <a target="_blank" rel="noreferrer noopener" href="https://www.techdirt.com/2023/09/19/court-says-californias-age-appropriate-design-code-is-unconstitutional-just-as-we-warned/">the entire bill unconstitutional</a> for the exact reasons we had warned the California government about.</p>
<p>The judge recognized that the bill required the removal of speech, despite California’s claim that it was about conduct and privacy. California (of course) appealed, and now we have the 9th Circuit which has mostly (though not entirely) agreed with the district court.</p>
<p>The real wildcard in all of this was the <a href="https://www.techdirt.com/2024/07/01/in-content-moderation-cases-supreme-court-says-try-again-but-makes-it-clear-moderation-deserves-first-amendment-protections/" target="_blank" rel="noreferrer noopener">Supreme Court’s decision last month</a> in what is now called the Moody case, which also involved NetChoice challenging Florida’s and Texas’ social media laws. The Supreme Court said that the cases should be litigated differently as a “facial challenge” rather than an “as-applied challenge” to the law. And it seems that decision is shaking up a bunch of these cases.</p>
<p>But here, the 9th Circuit interpreted it to mean that it could send part of the case back down to the lower court to do a more thorough analysis on <em>some</em> parts of the AADC that weren’t as clearly discussed or considered. In a “facial challenge,” the courts are supposed to consider all aspects of the law, and whether or not they all violate the Constitution, or if some of them are salvageable.</p>
<p>On the key point, though, the 9th Circuit panel rightly found that the AADC violates the First Amendment. Because no matter how much California <em>claims</em> that it’s about conduct, design, or privacy, everyone knows it’s really about regulating speech.</p>
<p>Specifically, they call out the DPIA requirement. This is a major portion of the law, which requires certain online businesses to create and file a “Data Protection Impact Assessment” with the California Attorney General. Part of that DPIA is that you have to explain how you plan to “mitigate the risk” that “potentially harmful content” will reach children (defined as anyone from age 0 to 18).</p>
<p>And we’d have to do that for every “feature” on the website. Do I think that a high school student might read Techdirt’s comments and come across something the AG finds harmful? I need to first explain our plans to “mitigate” that risk. That sure sounds like a push for censorship.</p>
<p>And the Court agrees this is a problem. First, it’s a problem because of the compelled speech part of it:</p>
<blockquote>
<p><em>We agree with NetChoice that the DPIA report requirement, codified at §§ 1798.99.31(a)(1)–(2) of the California Civil Code, triggers review under the First Amendment. First, the DPIA report requirement clearly compels speech by requiring covered businesses to opine on potential harm to children. It is well-established that the First Amendment protects “the right to refrain from speaking at all.”</em></p>
</blockquote>
<p>California argued that because the DPIA reports are not public, it’s not compelled speech, but the Court (rightly) says that’s… not a thing:</p>
<blockquote>
<p><em>The State makes much of the fact that the DPIA reports are not public documents and retain their confidential and privileged status even after being disclosed to the State, but the State provides no authority to explain why that fact would render the First Amendment wholly inapplicable to the requirement that businesses create them in the first place. On the contrary, the Supreme Court has recognized the First Amendment may apply even when the compelled speech need only be disclosed to the government. See Ams. for Prosperity Found. v. Bonta, 594 U.S. 595, 616 (2021). Accordingly, the district court did not err in concluding that the DPIA report requirement triggers First Amendment scrutiny because it compels protected speech.</em></p>
</blockquote>
<p>More importantly, though, the Court recognizes that the entire underlying purpose of the DPIA system is to encourage websites to remove First Amendment-protected content:</p>
<blockquote>
<p><em>Second, the DPIA report requirement invites First Amendment scrutiny because it deputizes covered businesses into serving as censors for the State. The Supreme Court has previously applied First Amendment scrutiny to laws that deputize private actors into determining whether material is suitable for kids. See Interstate Cir., Inc. v. City of Dallas, 390 U.S. 676, 678, 684 (1968) (recognizing that a film exhibitor’s First Amendment rights were implicated by a law requiring it to inform the government whether films were “suitable” for children). Moreover, the Supreme Court recently affirmed “that laws curtailing [] editorial choices [by online platforms] must meet the First Amendment’s requirements.” Moody, 144 S. Ct. at 2393.</em></p>
</blockquote>
<p>The state’s argument that this analysis is unrelated to the underlying content is easily dismissed:</p>
<blockquote>
<p><em>At oral argument, the State suggested companies could analyze the risk that children would be exposed to harmful or potentially harmful material without opining on what material is potentially harmful to children. However, a business cannot assess the likelihood that a child will be exposed to harmful or potentially harmful materials on its platform without first determining what constitutes harmful or potentially harmful material. To take the State’s own example, data profiling may cause a student who conducts research for a school project about eating disorders to see additional content about eating disorders. Unless the business assesses whether that additional content is “harmful or potentially harmful” to children (and thus opines on what sort of eating disorder content is harmful), it cannot determine whether that additional content poses a “risk of material detriment to children” under the CAADCA. Nor can a business take steps to “mitigate” the risk that children will view harmful or potentially harmful content if it has not identified what content should be blocked.</em></p>
<p><em>Accordingly, the district court was correct to conclude that the CAADCA’s DPIA report requirement regulates the speech of covered businesses and thus triggers review under the First Amendment.</em></p>
</blockquote>
<p>I’ll note that this is an issue that is coming up in lots of other laws as well. For example, KOSA has defenders who insist that it is only focused on design, and not content. But at the same time, it talks about preventing harms around eating disorders, which is fundamentally a content issue, not a design issue.</p>
<p>The Court says that the DPIA requirement triggers strict scrutiny. The district court ruling had looked at it under intermediate scrutiny (a lower bar), found that it didn’t pass that bar, and said even if strict scrutiny is appropriate, it wouldn’t pass since it couldn’t even meet the lower bar. The Appeals court basically says we can jump straight to strict scrutiny:</p>
<blockquote>
<p><em>Accordingly, the court assumed for the purposes of the preliminary injunction “that only the lesser standard of intermediate scrutiny for commercial speech applies” because the outcome of the analysis would be the same under both intermediate commercial speech scrutiny and strict scrutiny. Id. at 947–48. While we understand the district court’s caution against prejudicing the merits of the case at the preliminary injunction stage, there is no question that strict scrutiny, as opposed to mere commercial speech scrutiny, governs our review of the DPIA report requirement.</em></p>
</blockquote>
<p>And, of course, the DPIA requirement fails strict scrutiny in part because it’s obviously not the least speech restrictive means of accomplishing its goals:</p>
<blockquote>
<p><em>The State could have easily employed less restrictive means to accomplish its protective goals, such as by (1) incentivizing companies to offer voluntary content filters or application blockers, (2) educating children and parents on the importance of using such tools, and (3) relying on existing criminal laws that prohibit related unlawful conduct.</em></p>
</blockquote>
<p>In this section, the court also responds to the overhyped fears that finding the DPIAs unconstitutional here would mean that they are similarly unconstitutional in other laws, such as California’s privacy law. But the court says “um, guys, one of these is about speech, and one is not.”</p>
<blockquote>
<p><em>Tellingly, iLit compares the CAADCA’s DPIA report requirement with a supposedly “similar DPIA requirement” found in the CCPA, and proceeds to argue that the district court’s striking down of the DPIA report requirement in the CAADCA necessarily threatens the same requirement in the CCPA. </em><strong><em>But a plain reading of the relevant provisions of both laws reveals that they are not the same; indeed, they are vastly different in kind.</em></strong></p>
<p><em>Under the CCPA, businesses that buy, receive, sell, or share the personal information of 10,000,000 or more consumers in a calendar year are required to disclose various metrics, including but not limited to the number of requests to delete, to correct, and to know consumers’ personal information, as well as the number of requests from consumers to opt out of the sale and sharing of their information. 11 Cal. Code Regs. tit. 11, § 7102(a); see Cal Civ. Code § 1798.185(a)(15)(B) (requiring businesses to conduct regular risk assessments regarding how they process “sensitive personal information”). </em><strong><em>That obligation to collect, retain, and disclose purely factual information about the number of privacy-related requests is a far cry from the CAADCA’s vague and onerous requirement that covered businesses opine on whether their services risk “material detriment to children” with a particular focus on whether they may result in children witnessing harmful or potentially harmful content online.</em></strong><em> A DPIA report requirement that compels businesses to measure and disclose to the government certain types of risks potentially created by their services might not create a problem. The problem here is that the risk that businesses must measure and disclose to the government is the risk that children will be exposed to disfavored speech online.</em></p>
</blockquote>
<p>Then, the 9th Circuit basically gives up on the other parts of the AADC. The court effectively says that since the briefing was so focused on the DPIA part of the law, and now (thanks to the Moody ruling) a facial challenge requires a full exploration of all aspects of the law, the rest should be sent back to the lower court:</p>
<blockquote>
<p><em>As in Moody, the record needs further development to allow the district court to determine “the full range of activities the law[] cover[s].” Moody, 144 S. Ct. at 2397. But even for the remaining provision that is likely to trigger First Amendment scrutiny in every application because the plain language of the provision compels speech by covered businesses, see Cal. Civ. Code §§ 1798.99.31(a)(7), we cannot say, on this record, that a substantial majority of its applications are likely to fail First Amendment scrutiny.</em></p>
</blockquote>
<p>For example, the Court notes that there’s a part of the law dealing with “dark patterns” but there’s not enough information to know whether or not that could impact speech or not (spoiler alert: it absolutely can and will).</p>
<p>Still, the main news here is this: the law is still not going into effect. The Court recognizes that the DPIA part of the law is pretty clearly an unconstitutional violation of the First Amendment (just as some of us warned Newsom and the California legislature).</p>
<p>Maybe California should pay attention next time (he says sarcastically as a bunch of new bad bills are about to make their way to Newsom’s desk).</p>

<p>
Filed Under: <a href="https://www.techdirt.com/tag/9th-circuit/" rel="tag">9th circuit</a>, <a href="https://www.techdirt.com/tag/aadc/" rel="tag">aadc</a>, <a href="https://www.techdirt.com/tag/ab-2273/" rel="tag">ab 2273</a>, <a href="https://www.techdirt.com/tag/age-appropriate-design-code/" rel="tag">age appropriate design code</a>, <a href="https://www.techdirt.com/tag/california/" rel="tag">california</a>, <a href="https://www.techdirt.com/tag/dpia/" rel="tag">dpia</a>, <a href="https://www.techdirt.com/tag/gavin-newsom/" rel="tag">gavin newsom</a>, <a href="https://www.techdirt.com/tag/protect-the-children/" rel="tag">protect the children</a>, <a href="https://www.techdirt.com/tag/rob-bonta/" rel="tag">rob bonta</a>
<br>
Companies: <a href="https://www.techdirt.com/company/netchoice/" rel="category tag">netchoice</a>
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA['Rare species' not seen in the area for 50 years spotted on Arizona trail camera (163 pts)]]></title>
            <link>https://phys.org/news/2024-08-rare-species-area-years-arizona.html</link>
            <guid>41294202</guid>
            <pubDate>Mon, 19 Aug 2024 20:10:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://phys.org/news/2024-08-rare-species-area-years-arizona.html">https://phys.org/news/2024-08-rare-species-area-years-arizona.html</a>, See on <a href="https://news.ycombinator.com/item?id=41294202">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
										
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/ocelots.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2023/ocelots.jpg" data-sub-html="Credit: Pixabay/CC0 Public Domain">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2023/ocelots.jpg" alt="ocelots" title="Credit: Pixabay/CC0 Public Domain" width="800" height="530">
             <figcaption>
                Credit: Pixabay/CC0 Public Domain
            </figcaption>        </figure>
    </div><p>To ensure her trail cameras would stay operational during the hot Arizona summer, researcher Kinley Ragan trekked to 23 of them.</p>


										      
																																	<p>At each, Ragan, a field research project manager with the Phoenix Zoo, checked the camera's batteries and SD card, as well as ensured the camera was angled at an optimal position, Ragan told McClatchy News in an Aug. 12 phone interview.</p>
<p>She was flipping through the last of 100 videos on one of the camera's SD cards during her July trip to the Atascosa Highlands area when something caught her eye.</p>
<p>"At the very, very end, I saw (an) ocelot," Ragan said.</p>
<p>The June 12 footage shows an ocelot walk across the screen before stopping and standing on a rock.</p>
<p>"I was in disbelief at first, watching the video over and over again," Ragan said in an Aug. 12 zoo news release, "but soon a big smile spread across my face as the full impact of this discovery for the important region set in."</p>
<p>This was the first time an ocelot has been seen "in the Atascosa Highlands region in at least 50 years," the zoo said.</p>
<p>"It's super exciting news," Ragan said, adding that the sighting leaves her "hopeful."</p>
<h2>Wildlife study</h2>
<p>The zoo set up 50 cameras across the area in April as part of the Atascosa Complex Wildlife Study, Ragan said.</p>
<p>The area, "which includes the Atascosa, Tumacácori, and Pajarito mountains," is understudied, the zoo said.</p>
<p>"We're looking to better understand medium and large mammals and how they're moving and existing within this important wildlife corridor," Ragan said.</p>
<p>While the team was hopeful one of the cameras, which will remain in place until October 2025, would pick up an ocelot, they were unsure.</p>
<p>"There hadn't been research done there in 10 years and there hadn't been a record in 50 years," Ragan said. "So we weren't sure, but we were really happy when we did get this record."</p>

																																						
																																			<h2>'A new cat'</h2>
<p>In the past decade, another ocelot, named Lil' Jefe, has been spotted roaming in the state, the Arizona Republic reported.</p>
<p>The recently spotted feline, however, "is a new cat not previously seen in the state," the zoo said.</p>
<p>"(Arizona Game and Fish Department) has conducted a pelage spot analysis comparing this ocelot with the current known ocelot in the state, as well as previous ocelots and concludes that this is indeed a new ocelot," Tracy McCarthey with AZGFD said in the release.</p>
<p>Across their entire range, from South America to the United States, the ocelot population is decreasing, but they are listed as "least concern" by the International Union for Conservation of Nature, according to Ragan.</p>
<p>"However, in Arizona, they are critically endangered, and they're also endangered in Mexico," Ragan said.</p>
<p>Some threats to the species' survival "include habitat fragmentation and loss," according to the zoo.</p>
<p>While many associate the ocelot with "rain forests and maybe South America or Central America," the felines do roam all the way north into Arizona and Texas, Ragan said.</p>
<p>"They are known to be in these drier climates as well, just less common," Ragan said.</p>
<p>The cats, small to medium in size, are spotted, according to Ragan.</p>
<p>"All their spots are unique to each individual," Ragan said, "so you can identify an ocelot based on unique spot patterns."</p>
<h2>'A lot more questions'</h2>
<p>With the "<a href="https://phys.org/tags/rare+species/" rel="tag">rare species</a>," Ragan said she hopes the study can help better understand the animal.</p>
<p>Ragan said she plans to trek back out to check the remaining trail cameras at the end of August, when she may possibly get more answers.</p>
<p>"We basically just have a lot more questions now," Ragan said. "All great things, but more work to be done for sure."</p>

																																																					
																					
																															 <p>
												  2024 The Charlotte Observer. Distributed by Tribune Content Agency, LLC.
											 </p>
										                                        
										<!-- print only -->
										<div>
											 <p><strong>Citation</strong>:
												'Rare species' not seen in the area for 50 years spotted on Arizona trail camera (2024, August 13)
												retrieved 20 August 2024
												from https://phys.org/news/2024-08-rare-species-area-years-arizona.html
											 </p>
											 <p>
											 This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
											 part may be reproduced without the written permission. The content is provided for information purposes only.
											 </p>
										</div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[13ft – A site similar to 12ft.io but is self hosted (569 pts)]]></title>
            <link>https://github.com/wasi-master/13ft</link>
            <guid>41294067</guid>
            <pubDate>Mon, 19 Aug 2024 19:49:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/wasi-master/13ft">https://github.com/wasi-master/13ft</a>, See on <a href="https://news.ycombinator.com/item?id=41294067">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">13 Feet Ladder</h2><a id="user-content-13-feet-ladder" aria-label="Permalink: 13 Feet Ladder" href="#13-feet-ladder"></a></p>
<p dir="auto">A site similar to <a href="https://12ft.io/" rel="nofollow">12ft.io</a> but is self hosted and works with websites that 12ft.io doesn't work with.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is this?</h2><a id="user-content-what-is-this" aria-label="Permalink: What is this?" href="#what-is-this"></a></p>
<p dir="auto">This is a simple self hosted server that has a simple but powerful interface to block ads, paywalls, and other nonsense. Specially for sites like medium, new york times which have paid articles that you normally cannot read. Now I do want you to support the creators you benefit from but if you just wanna see one single article and move on with your day then this might be helpful</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How does it work?</h2><a id="user-content-how-does-it-work" aria-label="Permalink: How does it work?" href="#how-does-it-work"></a></p>
<p dir="auto">It pretends to be GoogleBot (Google's web crawler) and gets the same content that google will get. Google gets the whole page so that the content of the article can be indexed properly and this takes advantage of that.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How do I use it?</h2><a id="user-content-how-do-i-use-it" aria-label="Permalink: How do I use it?" href="#how-do-i-use-it"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using Docker</h3><a id="user-content-using-docker" aria-label="Permalink: Using Docker" href="#using-docker"></a></p>
<p dir="auto">Requirements:</p>
<ul dir="auto">
<li>docker</li>
<li>docker-compose
First, clone the repo to your machine then run the following commands:</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/wasi-master/13ft.git
cd 13ft
docker-compose up"><pre>git clone https://github.com/wasi-master/13ft.git
<span>cd</span> 13ft
docker-compose up</pre></div>
<p dir="auto">The image is also available from <a href="https://hub.docker.com/r/wasimaster/13ft" title="docker pull wasimaster/13ft" rel="nofollow">DockerHub</a> or <a href="https://github.com/wasi-master/13ft/pkgs/container/13ft" title="docker pull ghcr.io/wasi-master/13ft:0.2.3">ghcr.io</a> so the command <code>docker pull wasimaster/13ft</code> also works.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Standard Python script</h3><a id="user-content-standard-python-script" aria-label="Permalink: Standard Python script" href="#standard-python-script"></a></p>
<p dir="auto">First, make sure you have <a href="https://python.org/" rel="nofollow">python</a> installed on your machine. Next, clone the git repo. Then go to a terminal (<code>Command Prompt</code> on Windows, <code>Terminal</code> on Mac) and run the following command:</p>
<p dir="auto">From the git cloned directory on your computer:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd app/
python -m pip install -r requirements.txt"><pre><span>cd</span> app/
python -m pip install -r requirements.txt</pre></div>
<p dir="auto">If that doesn't work retry but replace <code>python</code> with <code>py</code>, then try <code>python3</code>, then try <code>py3</code></p>
<p dir="auto">Then run <code>portable.py</code>, click <a href="https://realpython.com/run-python-scripts/" rel="nofollow">this link</a> for a tutorial on how to run python scripts.</p>

<p dir="auto">Then follow these simple steps</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Step 1</h3><a id="user-content-step-1" aria-label="Permalink: Step 1" href="#step-1"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/wasi-master/13ft/blob/main/screenshots/step-1.png"><img src="https://github.com/wasi-master/13ft/raw/main/screenshots/step-1.png" alt="step 1 screenshot"></a>
Go to the website at the url shown in the console</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Step 2</h3><a id="user-content-step-2" aria-label="Permalink: Step 2" href="#step-2"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/wasi-master/13ft/blob/main/screenshots/step-2.png"><img src="https://github.com/wasi-master/13ft/raw/main/screenshots/step-2.png" alt="step 2 screenshot"></a>
Click on the input box</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Step 3</h3><a id="user-content-step-3" aria-label="Permalink: Step 3" href="#step-3"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/wasi-master/13ft/blob/main/screenshots/step-3.png"><img src="https://github.com/wasi-master/13ft/raw/main/screenshots/step-3.png" alt="step 3 screenshot"></a>
Paste your desired url</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Step 4</h3><a id="user-content-step-4" aria-label="Permalink: Step 4" href="#step-4"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/wasi-master/13ft/blob/main/screenshots/step-4.gif"><img src="https://github.com/wasi-master/13ft/raw/main/screenshots/step-4.gif" alt="step 4 screenshot" data-animated-image=""></a>
Voilà you now have bypassed the paywall and ads</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Alternative method</h3><a id="user-content-alternative-method" aria-label="Permalink: Alternative method" href="#alternative-method"></a></p>
<p dir="auto">You can also append the url at the end of the link and it will also work. (e.g if your server is running at <code>http://127.0.0.1:5000</code> then you can go to <code>http://127.0.0.1:5000/https://example.com</code> and it will read out the contents of <code>https://example.com</code>)</p>
<p dir="auto">This feature is possible thanks to <a href="https://github.com/atcasanova">atcasanova</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lenticular Clock (170 pts)]]></title>
            <link>https://www.instructables.com/Lenticular-Clock/</link>
            <guid>41293929</guid>
            <pubDate>Mon, 19 Aug 2024 19:32:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.instructables.com/Lenticular-Clock/">https://www.instructables.com/Lenticular-Clock/</a>, See on <a href="https://news.ycombinator.com/item?id=41293929">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><section id="intro" data-stepid="SKL1XZZLYU53EIO"><h2>Introduction: Lenticular Clock</h2><div><p>After making my Moire Clock a got interested in a very similar effect: lenticular animations. You probably have seen this effect before, e.g. on post cards. I remember having a ruler in primary school with a picture of dinosaurs on it that changed depending on the viewing angle.</p><p>Lenticular animations are based on several interlaced pictures viewed through an array of cylindrical lenses. The individual pictures can then be distinguished by changing the viewing angle. My idea was to create a clock that uses lenticular animations to display the time.</p></div></section><section id="stepsupplies" data-stepid=""><h2>Supplies</h2><div><ul><li>4pcs <a href="https://www.amazon.de/dp/B0CNXL4DVY?psc=1&amp;ref=ppx_yo2ov_dt_b_product_details" rel="nofollow noopener noreferrer">SG92R 270deg servo motors</a> (actually you only need 2 pcs of 270deg servos, the other 2 pcs can be 180deg)</li><li>PCA9685 PWM driver board</li><li>Wemos D1 mini ESP8266</li><li><a href="https://dplenticular.com/de/produkte/20-lpi-motion-uv-lf/" rel="nofollow noopener noreferrer">20 LPI lenticular sheet A4</a></li><li>printable transparent self-adhesive foil</li><li>color laser/inkjet printer</li><li>3D printer</li></ul></div></section><section id="step1" data-stepid="SNTCUNMLYU53EKR"><h2>Step 1: Choosing the Right LPI</h2><div><p>The lenticular sheet is characterized by its number of lenses per inch (LPI). I ordered sheets with 60, 40 and 20 LPI. Higher LPI gives you a better resolution but you need to print thinner lines and its more difficult to align the sheet correctly on top of the print. Since the clock animations will contain up to 6 frames I found that they are only clearly separated with 20 LPI.</p><p>I used a <a href="https://dplenticular.com/de/produkte/20-lpi-motion-uv-lf/" rel="nofollow noopener noreferrer">20 LPI sheet with a large viewing angle of 54 deg</a> that is well suited for displaying animations.</p></div></section><section id="step2" data-stepid="S8G2FYBLYVKJIZB"><h2>Step 2: LPI Calibration</h2><p>Because of manufacturing tolerances of the lenticular sheet and also tolerances of your printer you need to determine the exact LPI value that you will use for interlacing. There are several softwares that can generate calibration sheets. I tried out the software from <a href="https://www.3dependable.com/download.html" rel="nofollow noopener noreferrer">3Dependable</a> and <a href="https://www.pop3dart.com/fpitch-software" rel="nofollow noopener noreferrer">fPitch</a>. For some reason though the calibration did not work very well and I ended up generating the final print with different LPI values and then chose the one which gave the best results when placed below my lenticular sheet.</p></section><section id="step3" data-stepid="SP2U9PELYU53EIT"><h2>Step 3: Creating the Lenticular Print</h2><div><p>There are several softwares that can be used for interlacing the images, I used <a href="https://www.pop3dart.com/grape-interlacing-software" rel="nofollow noopener noreferrer">grape </a>which is freeware. At first, I created pictures of each individual digit from 0 to 9 all with the same size of 52.5x30mm. I used a different color for each digit which helps to distinguish them more clearly and also has the advantage of being able to participate in the "colors of the rainbow" contest on instructables ;-)</p><p>Before interlacing I had to rotate the pictures by 90deg because grape can only create animations that work by tilting the print horizontally.</p><p>Interlaced images were created out of the following groups of digits</p><ul><li>0-2 -&gt; ten hours</li><li>0-4 -&gt; hours + minutes</li><li>5-9 -&gt; hours + minutes</li><li>0-5 -&gt; ten minutes</li></ul><p>I mirrored the interlaced images and then printed them on self-adhesive transparent foil so that I can attach them to the back of the lenticular sheet. I also covered the print with another layer of self-adhesive foil so that the ink does not rub off.</p><p>The interlaced pictures and individual frames are available on my <a href="https://github.com/vonsivers/LenticularClock" rel="nofollow noopener noreferrer">github</a>.</p></div></section><section id="step4" data-stepid="SSZIUW7LYVKJIZE"><h2>Step 4: Attaching the Print to the Lenticular Sheet</h2><div><p>The interlaced pictures created with grape have some aligned marks at the border which greatly held to align the print correctly. In order to be able to adjust the self-adhesive foil I sprayed the back of the lenticular sheet with soapy water. After everything is aligned corectly you can squeeze out the water below the foil.</p><p>I then cut the lenticular sheet with a box cutter removing the alignment marks. This turned out to be quite tedious since the lenticular sheet is 2mm thick and takes a long time to cut through.</p></div></section><section id="step5" data-stepid="SNGZE73LYVKJIZH"><h2>Step 5: 3D Printing</h2><div><p>I 3D printed holders for the lenticual sheets from white PLA. The sheet can be slided into the holder and the holder is later attached to the servo motors. The holder for the hours and minutes have the sheets with the digits 0-4 on the front and 5-9 on the backside.</p><p>The housing for the clock was also 3D printed from white PLA and houses the electronics and servo motors.</p><p>All stl files are available on my <a href="https://github.com/vonsivers/LenticularClock" rel="nofollow noopener noreferrer">github</a>.</p></div></section><section id="step6" data-stepid="S0X0YBULYVKJIZL"><h2>Step 6: Assembly</h2><div><p>The assembly of the clock is rathter easy.</p><ol><li>attach servos to housing</li><li>press fit digit holder to servos. Ten hours go to upper left, hours to upper right, ten minutes to lower left, minutes to lower right</li><li>mount PCA9685 and Wemos board. The Wemos needs to be fixed with hot glue</li><li>Connect cables between Wemos and PCA9685</li><li>D1 -&gt; SCL</li><li>D2 -&gt; SDA</li><li>5V -&gt; VCC and V+</li><li>GND -&gt; GND</li><li>attach servos to CH 0-3 on the PCA9685 board</li><li>fix servo cables with zip ties on the back of the housing</li><li>attach housing lid</li></ol><p>For the final touch I added another lenticular animation to the bottom of the housing that switches between to texts and was created using a sheet with 40LPI.</p></div></section><section id="step7" data-stepid="S6CK6MULYVKJIZT"><h2>Step 7: Code</h2><div><p>The code was written in the Arduino IDE and is available on my <a href="https://github.com/vonsivers/LenticularClock" rel="nofollow noopener noreferrer">github</a>. At first, the positions of the motors that correspond to the correct tilt angle for each digit need to be specified in the servo.h file. For that I viewed the clock from a defined angle and controlled the servo positions via the serial monitor in the IDE.</p><p>When the code is first uploaded, the ESP8266 opens an access point and lets you enter your wifi credentials. It then connects to your local wifi and synchronizes the time via NTP.</p><p>The clock will show the time in 24h format with the top row showing the hours and bottom row showing the minutes.</p></div></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Music recommendation system using transformer models (183 pts)]]></title>
            <link>https://research.google/blog/transformers-in-music-recommendation/</link>
            <guid>41293901</guid>
            <pubDate>Mon, 19 Aug 2024 19:28:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://research.google/blog/transformers-in-music-recommendation/">https://research.google/blog/transformers-in-music-recommendation/</a>, See on <a href="https://news.ycombinator.com/item?id=41293901">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <div>
                
                    <section data-gt-id="blog_summary" data-gt-component-name="Blog Summary">
                        
                        



<p>We present a music recommendation ranking system that uses Transformer models to better understand the sequential nature of user actions based on the current user context.</p>
                        
                    </section>
                
                <section>
    <h2>Quick links</h2>
    <ul>
        
        
        
        
    </ul>
</section>

                <div data-gt-publish-date="20240816">
                    
                    
    <div data-gt-id="rich_text" data-gt-component-name="">
    <p data-block-key="08t19">Users have more choices for listening to music than ever before. Popular services boast of massive and varied catalogs. The YouTube Music catalog, for example, has over 100M songs globally. It follows that item recommendations are a core part of these products. Recommender systems make sense of the item catalog and are critical for tuning the catalog for the user’s tastes and needs. In products that provide recommendations, user actions on the recommended items — such as <i>skip</i>, <i>like</i>, or <i>dislike —</i> provide an important signal about user preferences. Observing and learning from these actions can lead to better recommendation systems. In <a href="https://music.youtube.com/explore" target="_blank" rel="noopener noreferrer">YouTube Music</a>, leveraging this signal is critical to understanding a user's musical taste.</p><p data-block-key="6rpn9">Consider a scenario where a user typically likes slow-tempo songs. When presented with an uptempo song, the user would typically skip it. However, at the gym, when they’re in a workout session, they like more uptempo music. In such a situation, we want to continue learning from their prior history to understand their musical preferences. At the same time, we want to discount prior skips of uptempo songs when recommending workout music.</p><p data-block-key="fj00u">Below we illustrate the users’ music listening experience, with music songs shown as items and with the user’s actions as text beneath. In current recommendation systems that don’t consider the broader context, we would predict that the user will skip an uptempo song, resulting in demoting a potentially relevant and valuable song.</p>
</div>

                    
                    
    

  







                    
                    
    <div data-gt-id="rich_text" data-gt-component-name="">
    <p data-block-key="buklh">The below figure shows the same user journey as before, but in a different situation, where upbeat music may be more relevant. We still utilize their previous music listening, while recommending upbeat music that is close to their usual music listening. In effect, we are learning which previous actions are relevant in the current task of ranking music, and which actions are irrelevant.</p>
</div>

                    
                    
    

  







                    
                    
    <div data-gt-id="rich_text" data-gt-component-name="">
    <p data-block-key="6gnmm">A typical user will perform hundreds of <i>like</i>, <i>dislike</i>, and <i>skip</i> actions, and this sequence of input data, though information-rich, quickly becomes unwieldy. To add to this complexity, users perform different numbers of actions. While a typical user might have hundreds of actions, user behavior can vary between a small number of actions to a very large number of actions, and a good ranking system must be flexible in handling different input sizes.</p><p data-block-key="18rv9">In this post we discuss how we’ve applied <a href="https://research.google/pubs/pub46201/">transformers</a>, which are well-suited to processing sequences of input data, to improve the recommendation system in YouTube Music. This recommendation system consists of three key stages: item retrieval, item ranking, and filtering. Prior user actions are usually added to the ranking models as an input feature. Our approach adapts the Transformer architecture from generative models for the task of understanding the sequential nature of user actions, and blends that with ranking models personalized for that user. Using transformers to incorporate different user actions based on the current user context helps steer music recommendations directly towards the user’s current need. For signed-in users, this approach allows us to incorporate a user’s history without having to explicitly identify what in a user’s history is valuable to the ranking task.</p>
</div>

                    
                    
    <div data-gt-id="rich_text" data-gt-component-name="">
    <h2 data-block-key="d4ewl">Retrieval, ranking, and filtering</h2><p data-block-key="cdcfp">In existing models, it was difficult to identify which user actions were relevant to the user’s current needs. To understand such models, we need to look at typical recommendation systems. These systems are usually set up as three distinct stages. First, <i>retrieval</i> systems retrieve thousands of relevant items (documents, songs, etc.) from a large corpus. Second, <i>ranking</i> systems evaluate the retrieved results, so that the items that are more relevant and important to the user’s needs are assigned a higher score. The key complexity of ranking comes from the value judgment between concepts such as relevance, importance, novelty, and assigning a numerical value to these fuzzy concepts. Finally, a <i>filtering</i> stage sorts the ranked list by scores, and reduces the sorted list to a short list that is shown to the user. When designing and deploying a ranking model, it is hard to manually select and apply relative weights to specific user actions out of the many hundreds or thousands that they may commonly take.</p>
</div>

                    
                    
    <div data-gt-id="rich_text" data-gt-component-name="">
    <h2 data-block-key="d4ewl">Transformers make sense of sequences</h2><p data-block-key="tbr8"><a href="https://research.google/blog/transformer-a-novel-neural-network-architecture-for-language-understanding/">Transformers</a> are well-suited to a class of problems where we need to make sense of a sequence of input data. While transformers have been used to improve ranking functions, previous approaches have not focused on user actions: Transformer models like <a href="https://www.amazon.science/publications/rankformer-listwise-learning-to-rank-using-listwide-labels" target="_blank" rel="noopener noreferrer">RankFormer</a> have used item candidates (as opposed to user-actions) as input, classical language <a href="https://arxiv.org/abs/1810.04805" target="_blank" rel="noopener noreferrer">transformers like BERT</a> are used to <a href="https://parl.ai/docs/agent_refs/bert_ranker.html" target="_blank" rel="noopener noreferrer">rank language</a> output, or BERT-like models are used in recommendations, as <a href="https://arxiv.org/pdf/1904.06690" target="_blank" rel="noopener noreferrer">in Bert4Rec</a>.</p><p data-block-key="1cc9b">The Transformer architecture consists of self-attention layers to make sense of sequential input. Transformer models have shown incredible performance on translation or classification tasks, even with ambiguous input text. The self-attention layers capture the relationship between words of text in a sentence, which suggests that they might be able to resolve the relationship between user actions as well. The attention layers in transformers learn attention weights between the pieces of input (tokens), which are akin to word relationships in the input sentence.</p>
</div>

                    
                    
    

  







                    
                    
    <div data-gt-id="rich_text" data-gt-component-name="">
    <p data-block-key="76aop">This is how we utilize the Transformer architecture to encode user actions on <a href="https://music.youtube.com/" target="_blank" rel="noopener noreferrer">YouTube Music</a>. In the user journey involving uptempo music above, we saw how some actions were less important than others. For example, when the user is listening to music at the gym, the user may prefer high-energy upbeat music that they would normally skip, hence related actions (e.g., the skip action in this example) should get a lower attention weight. However, when a user is listening to music in other settings, user actions should get more attention. There should be a difference in attention weight applied to music context versus a user’s music history based upon the activity the user is performing. For example, when a user is at the gym they might listen to music that is more upbeat, but not too far from what they usually listen to. Or when they are driving, they might prefer to explore more new music.</p>
</div>

                    
                    
    <div data-gt-id="rich_text" data-gt-component-name="">
    <h2 data-block-key="d4ewl">Transformers for ranking in YouTube Music</h2><p data-block-key="2k8jl">Our architecture combines a Transformer with an existing ranking model to learn the combined ranking that best blends user actions with listening history (see diagram below). In this diagram, information flows from the bottom to the top: the inputs to the Transformer are shown at the bottom, and the produced ranking score is shown at the top. “Items” here are music tracks that we want to rank, with the goal to produce a ranking score for each music “item” given to it, with other signals (also called features) provided as input.</p>
</div>

                    
                    
    

  







                    
                    
    <div data-gt-id="rich_text" data-gt-component-name="">
    <p data-block-key="bmna1">Here are the signals describing the user action at each time step:</p><ul><li data-block-key="750ce">Intention of the action: interrupt a music track, select a music track to listen to, autoplay.</li><li data-block-key="chbpd">Salience of the action: percentage of the music track that was played, time since prior user-action.</li><li data-block-key="c0bee">Other metadata: artist, language of the music.</li><li data-block-key="98lkt">Music track: music track identifier corresponding to the user-action.</li></ul><p data-block-key="9k56l">Music tracks corresponding to user actions are represented by a vector of numbers called the track embedding. This music-track embedding is used as an input in both the Transformer and the existing ranking model. User-action signals, like intention and metadata, are turned into vectors with the same length as the length of the track embedding. This operation, called a projection, allows us to combine the signals simply by adding the two vectors: user-action signals and the track embedding, producing input vectors (called tokens) for the Transformer. The tokens provided as inputs to the Transformer are used <a href="https://developers.google.com/machine-learning/recommendation/dnn/scoring" target="_blank" rel="noopener noreferrer">to score</a> the retrieved music items. When considering the user’s history, we include the previous user actions and the music the user is currently listening to, as both capture valuable user context. The output vector from the Transformer is combined with the existing ranking model inputs, using a multi-layer neural network. The Transformer is co-trained with the ranking model, for multiple ranking objectives.</p><p data-block-key="b0hrb">Offline analysis and live experiments demonstrate that using this Transformer significantly improves the performance of the ranking model, leading to a reduction in skip-rate and an increase in time users spend listening to music. Skipping less frequently indicates that on average, users like the recommendations more. Increased session length indicates that users are happier with the overall experience. These two metrics demonstrate the improvement in user satisfaction for YouTube Music.</p>
</div>

                    
                    
    <div data-gt-id="rich_text" data-gt-component-name="">
    <h2 data-block-key="d4ewl">Future work</h2><p data-block-key="5b34">We see two main opportunities to build on this work. The first would be to adapt the technique to other parts of the recommendation system such as retrieval models. There are also a variety of nonsequential features, which are used as inputs to the prior ranking model, that we are also exploring for incorporation. Currently, these are combined after the Transformer stage, and we predict that incorporating them within the Transformer would allow for improved self-attention between the sequential features, like user-actions, and non-sequential features such as artist popularity, user language, music popularity and more.</p>
</div>

                    
                    
    <div data-gt-id="rich_text" data-gt-component-name="">
    <h2 data-block-key="d4ewl">Acknowledgements</h2><p data-block-key="2koet"><i>Thanks to colleagues Reza Mirghaderi, Li Yang, Chieh Lo, Jungkhun Byun, Gergo Varady, and Sally Goldman, for their collaboration on this effort.</i></p>
</div>

                    
                </div>

                
    


<section aria-label="List of footnotes" data-gt-id="footnotes" data-gt-component-name="Footnotes">
  <ol>
    
  </ol>
</section>


                


            </div>
            
                <section>
    <h2>Quick links</h2>
    <ul>
        
        
        
        
    </ul>
</section>
            
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Netboot.xyz: your favorite operating systems in one place (262 pts)]]></title>
            <link>https://netboot.xyz/</link>
            <guid>41293850</guid>
            <pubDate>Mon, 19 Aug 2024 19:19:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://netboot.xyz/">https://netboot.xyz/</a>, See on <a href="https://news.ycombinator.com/item?id=41293850">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__docusaurus_skipToContent_fallback"><main><div><div><p><img src="https://netboot.xyz/img/nbxyz-user.svg" alt="logo"><img src="https://netboot.xyz/img/nbxyz-user.svg" alt="logo"></p><div><h3>Simple to Use</h3><p>netboot.xyz enables you to boot into many types of operating systems using lightweight tooling to get you up and running as soon as possible.</p></div></div><div><p><img src="https://netboot.xyz/img/nbxyz-laptop.gif" alt="logo"><img src="https://netboot.xyz/img/nbxyz-laptop.gif" alt="logo"></p><div><h3>Evaluate, Install, Rescue</h3><p>Discover new operating systems without having to download and rewrite media over and over again. Rescue operating systems from a single image. An essential for any sysadmin.</p></div></div><div><p><img src="https://netboot.xyz/img/ipxechip.svg" alt="logo"><img src="https://netboot.xyz/img/ipxechip.svg" alt="logo"></p><div><h3>Powered by the iPXE project</h3><p>netboot.xyz uses the iPXE project to enable you to provision, rescue or load into a live boot environment leveraging the Preboot Execution Environment (PXE) on most systems.</p></div></div></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Client-side filtering of private data is a bad idea (116 pts)]]></title>
            <link>https://mjg59.dreamwidth.org/70061.html</link>
            <guid>41293847</guid>
            <pubDate>Mon, 19 Aug 2024 19:19:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mjg59.dreamwidth.org/70061.html">https://mjg59.dreamwidth.org/70061.html</a>, See on <a href="https://news.ycombinator.com/item?id=41293847">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>(The issues described in this post have been fixed, I have not exhaustively researched whether any other issues exist)</p><p><a href="https://feeld.co/">Feeld</a> is a dating app aimed largely at alternative relationship communities (think "classier Fetlife" for the most part), so unsurprisingly it's fairly popular in San Francisco. Their website makes <a href="https://feeld.co/about/faq">the claim</a>:</p><p><q>Can people see what or who I'm looking for?<br>No. You're the only person who can see which genders or sexualities you're looking for. Your curiosity and privacy are always protected.</q></p><p>which is based on you being able to restrict searches to people of specific genders, sexualities, or relationship situations. This sort of claim is one of those things that just sits in the back of my head worrying me, so I checked it out.</p><p>First step was to grab a copy of the Android APK (there are multiple sites that scrape them from the Play Store) and run it through <a href="https://github.com/shroudedcode/apk-mitm">apk-mitm</a> - Android apps by default don't trust any additional certificates in the device certificate store, and also frequently implement certificate pinning. apk-mitm pulls apart the apk, looks for known http libraries, disables pinning, and sets the appropriate manifest options for the app to trust additional certificates. Then I set up <a href="https://mitmproxy.org/">mitmproxy</a>, installed the cert on a test phone, and installed the app. Now I was ready to start.</p><p>What became immediately clear was that the app was using <a href="https://graphql.org/">graphql</a> to query. What was a little more surprising is that it appears to have been implemented such that there's no server state - when browsing profiles, the client requests a batch of profiles along with a list of profiles that the client has already seen. This has the advantage that the server doesn't need to keep track of a session, but also means that queries just keep getting larger and larger the more you swipe. I'm not a web developer, I have absolutely no idea what the tradeoffs are here, so I point this out as a point of interest rather than anything else.</p><p>Anyway. For people unfamiliar with graphql, it's basically a way to query a database and define the set of fields you want returned. Let's take the example of requesting a user's profile. You'd provide the profile ID in question, and request their bio, age, rough distance, status, photos, and other bits of data that the client should show. So far so good. But what happens if we request other data?</p><p>graphql supports <a href="https://graphql.org/learn/introspection/">introspection</a> to request a copy of the database schema, but this feature is optional and was disabled in this case. Could I find this data anywhere else? Pulling apart the apk revealed that it's a <a href="https://reactnative.dev/">React Native</a> app, so effectively a framework for allowing writing of native apps in Javascript. Sometimes you'll be lucky and find the actual Javascript source there, but these days it's more common to find <a href="https://github.com/facebook/hermes/">Hermes</a> blobs. Fortunately <a href="https://github.com/P1sec/hermes-dec">hermes-dec</a> exists and does a decent job of recovering something that approximates the original input, and from this I was able to find various lists of database fields.</p><p>So, remember that original FAQ statement, that your desires would never be shown to anyone else? One of the fields mentioned in the app was "lookingFor", a field that wasn't present in the default profile query. What happens if we perform the incredibly complicated hack of exporting a profile query as a curl statement, add "lookingFor" into the set of requested fields, and run it?</p><p>Oops.</p><p>So, point 1 is that you can't simply protect data by having your client not ask for it - private data must never be released. But there was a whole separate class of issue that was an even more obvious issue.</p><p>Looking more closely at the profile data returned, I noticed that there were fields there that weren't being displayed in the UI. Those included things like "ageRange", the range of ages that the profile owner was interested in, and also whether the profile owner had already "liked" or "disliked" your profile (which means a bunch of the profiles you see may already have turned you down, but the app simply didn't show that). This isn't ideal, but what was more concerning was that profiles that were flagged as <a href="https://support.feeld.co/hc/en-gb/articles/9406794134172-How-do-I-hide-my-profile-from-other-Feeld-members">hidden</a> were still being sent to the app and then just not displayed to the user. Another example of this is that the app supports associating your profile with profiles belonging to partners - if one of those profiles was then hidden, the app would stop showing the partnership, but was still providing the profile ID in the query response and querying that ID would still show the hidden profile contents.</p><p>Reporting this was inconvenient. There was no security contact listed on the website or in the app. I ended up finding Feeld's head of trust and safety on Linkedin, paying for a month of Linkedin Pro, and messaging them that way. I was then directed towards a HackerOne program with a link to terms and conditions that 404ed, and it took a while to convince them I was uninterested in signing up to a program without explicit terms and conditions. Finally I was just asked to email security@, and successfully got in touch. I heard nothing back, but after prompting was told that the issues were fixed - I then looked some more, found another example of the same sort of issue, and eventually that was fixed as well. I've now been informed that work has been done to ensure that this entire class of issue has been dealt with, but I haven't done any significant amount of work to ensure that that's the case.</p><p>You can't trust clients. You can't give them information and assume they'll never show it to anyone. You can't put private data in a database with no additional acls and just rely on nobody ever asking for it. You also can't find a single instance of this sort of issue and fix it without verifying that there aren't other examples of the same class. I'm glad that Feeld engaged with me earnestly and fixed these issues, and I really do hope that this has altered their development model such that it's not something that comes up again in future.</p><p>(Edit to add: as far as I can tell, pictures tagged as "private" which are only supposed to be visible if there's a match were appropriately protected, and while there is a "location" field that contains latitude and longitude this appears to only return 0 rather than leaking precise location. I also saw no evidence that email addresses, real names, or any billing data was leaked in any way)</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The guidance system and computer of the Minuteman III nuclear missile (220 pts)]]></title>
            <link>http://www.righto.com/2024/08/minuteman-guidance-computer.html</link>
            <guid>41293767</guid>
            <pubDate>Mon, 19 Aug 2024 19:06:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.righto.com/2024/08/minuteman-guidance-computer.html">http://www.righto.com/2024/08/minuteman-guidance-computer.html</a>, See on <a href="https://news.ycombinator.com/item?id=41293767">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-8302647573373825375" itemprop="description articleBody">
<p>The Minuteman missile was introduced in 1962 as a key part of America's nuclear deterrent.
The Minuteman III missile is currently the only US land-based intercontinental ballistic missile (ICBM), with
400 missiles ready for launch, spread across five central states.<span id="fnref:counts"><a href="#fn:counts">1</a></span>
The missile contains a precision guidance system, capable of delivering a warhead to a target 13,000 km away (8000 miles) with an
<a href="https://missilethreat.csis.org/missile/minuteman-iii/">accuracy</a> of 200 meters (660 feet).</p>
<p>The diagram below shows the guidance system of the Minuteman III missile (1970).
This guidance system contains over 17,000 electronic and mechanical parts, <a href="https://apps.dtic.mil/sti/tr/pdf/AD0877971.pdf#page=279">costing</a> $510,000 (about $4.5 million in current dollars).
The heart of the guidance system is the gyro stabilized platform, which uses gyroscopes and accelerometers to measure the missile's orientation and acceleration.
The computer uses the measurements from the platform to determine the missile's position and guide the missile on its trajectory
to the target. Other key components are the missile guidance set controller, which contains electronics to support the gyro stabilized platform, and the
amplifier, which interfaces the computer with the rest of the missile.
In this blog post, I take a close look at the components of the guidance system that was used until the early 2000s.<span id="fnref:disclaimers"><a href="#fn:disclaimers">2</a></span></p>
<p><a href="https://static.righto.com/images/minuteman-mmiii/guidance-labeled.jpg"><img alt="The Minuteman III guidance system (NS-20). Click on this image (or any other) for a larger version. Original image from National Air and Space Museum." height="564" src="https://static.righto.com/images/minuteman-mmiii/guidance-labeled-w700.jpg" title="The Minuteman III guidance system (NS-20). Click on this image (or any other) for a larger version. Original image from National Air and Space Museum." width="700"></a></p><p>The Minuteman III guidance system (NS-20). Click on this image (or any other) for a larger version. Original image from <a href="https://airandspace.si.edu/collection-objects/guidance-system-minuteman-iii/nasm_A19770995000">National Air and Space Museum</a>.</p>
<p>Fundamentally,
the guidance computer constantly compares the missile position to the desired trajectory and generates the appropriate
steering commands to keep the missile on track.<span id="fnref:algorithms"><a href="#fn:algorithms">3</a></span>
The diagram below shows how directing the engine nozzles causes the missile to rotate around its three axes: roll, pitch, and yaw.<span id="fnref:nozzles"><a href="#fn:nozzles">4</a></span>
In the silo, the roll angle (the azimuth) is aligned with the direction to the target.
The missile takes off vertically and then the missile gradually rotates along the pitch axis to tilt over toward the target.
During flight, adjustments along all three axes keep the missile on target.
The Minuteman III has four rocket stages so the guidance computer jettisons each rocket stage and ignites the next stage in sequence.</p>
<!--
For an analogy, if you're standing up, the roll axis determines what direction you're facing, and you can roll by shuffling your
feet in a circle.
The analogy is if you bend forward at the hips and pitch yourself forward; note that the pitch axis is left-right, but your
motion is forward-backward.
If you're standing, yaw would be the equivalent of bending side-to-side as a yoga stretch. Again, the axis (front-back through your
belly button) is orthogonal to the direction of motion (left-right). (Of course, the rocket is moving rigidly, not bending.)
-->

<p><a href="https://static.righto.com/images/minuteman-mmiii/roll-pitch-yaw.jpg"><img alt="The roll, pitch, and yaw axes for the Minuteman missile. The engine diagrams show how the nozzles are directed to rotate around each axis, Modified from A Simulation of Minuteman Trajectories, with changed axes." height="393" src="https://static.righto.com/images/minuteman-mmiii/roll-pitch-yaw-w500.jpg" title="The roll, pitch, and yaw axes for the Minuteman missile. The engine diagrams show how the nozzles are directed to rotate around each axis, Modified from A Simulation of Minuteman Trajectories, with changed axes." width="500"></a></p><p>The roll, pitch, and yaw axes for the Minuteman missile. The engine diagrams show how the nozzles are directed to rotate around each axis, Modified from <a href="https://bpb-us-e1.wpmucdn.com/wordpressua.uark.edu/dist/3/246/files/2016/05/Minuteman-Trajectory-Simulation.pdf">A Simulation of Minuteman Trajectories</a>, with changed axes.</p>
<h2>The guidance platform</h2>
<p>The idea behind inertial navigation is to keep track of the missile's position by constantly measuring its acceleration.
By integrating the acceleration, you get the velocity. And by integrating the velocity, you get the position.
Inertial navigation is self-contained, a big advantage for a missile since the enemy can't jam your navigation.
The hard part is measuring the acceleration and angles with extreme accuracy, since even tiny errors are multiplied as
the missile travels.</p>
<p>In more detail, the Minuteman's inertial guidance is built around a gyroscopically stabilized platform, which is
kept in a fixed orientation. The platform is
mounted on two beryllium gimbals. Feedback from gyroscopes drives three torque motors to rotate the gimbals to keep
the stable platform in exactly the same orientation
no matter how the missile twists and turns.</p>
<!-- The Atlas missile (1957) was originally guided by sending it commands from the ground, but the Atlas E (1961) moved to an all-inertial system. The Minuteman kept the inertial approach. -->

<p><a href="https://static.righto.com/images/minuteman-mmiii/imu-labeled.jpg"><img alt="The Minuteman III stable platform. Original image from National Air and Space Museum." height="523" src="https://static.righto.com/images/minuteman-mmiii/imu-labeled-w700.jpg" title="The Minuteman III stable platform. Original image from National Air and Space Museum." width="700"></a></p>
<p>The diagram below shows the components of the stable platform, in approximately the same orientation as the photo above.
Three accelerometers are mounted on the stable platform to measure acceleration. The accelerometers are oriented along three perpendicular axes so each one measures acceleration along one axis.
(The accelerometer axes are not aligned with the platform axes; this distributes the acceleration (mostly "up") across the 
accelerometers, increasing accuracy.)
The two alignment mirrors allow the stable platform to be aligned with a precise device called an autocollimator, as will be described below.
The gyrocompass uses the Earth's rotation to precisely determine North, providing a backup alignment technique.
Both the alignment mirrors and the gyrocompass can be rotated to a precise angle, reported by the resolver.</p>
<p><a href="https://static.righto.com/images/minuteman-mmiii/platform.jpg"><img alt="The stable platform for Minuteman II and III. Modified from Minuteman weapon system history and description." height="454" src="https://static.righto.com/images/minuteman-mmiii/platform-w600.jpg" title="The stable platform for Minuteman II and III. Modified from Minuteman weapon system history and description." width="600"></a></p>
<p>To target a Minuteman I missile, the missile had to be physically rotated in the silo to be aligned with the target,
an angle called the launch azimuth.
This angle had to be extremely precise, since even a tiny angle error will be greatly magnified over the missile's journey.
Aligning the missile was a tedious process that used the North Star to determine North.
Since the star was not visible from inside the silo, a complex surveying technique was used, using a surveyor's theodolite to measure the angles between the North Star and three concrete monuments outside the silo.
Inside the silo, the closest monument was visible through a sighting tube, allowing the precise angle measurement to be
transferred to the silo.
After many more measurements inside the silo, a special device called an autocollimator was positioned precisely 90° from
the desired launch azimuth.
The autocollimator shot a beam of light through a window in the side of the missile, where it bounced off a mirror
on the stable platform and returned to the autocollimator.
If the returning beam wasn't exactly parallel, the autocollimator sent a signal to the missile, causing the stable platform to
rotate as needed.
The result of this process was that the stable platform was exactly aligned with the desired angle to the target.<span id="fnref:azimuth"><a href="#fn:azimuth">5</a></span></p>
<p>The guidance platform was completely redesigned for Minuteman II and III, eliminating the time-consuming alignment that
Minuteman I required.
The new platform had an alignment block with rotating mirrors.
Instead of rotating the missile, the autocollimator remained fixed in the East position and the mirror (and thus the
stable platform) was rotated to the desired launch azimuth.
The new guidance platform also added a gyrocompass under the alignment block, a special compass that could precisely align itself to North by precessing against the Earth's rotation.
At first, the gyrocompass was used as a backup check against the autocollimator, but eventually the gyrocompass became the primary alignment.
For calibration, the alignment block also includes electrolytic bubble levels to position the stable platform in known orientations with respect to local gravity.<span id="fnref:calibrations"><a href="#fn:calibrations">6</a></span></p>
<p><a href="https://static.righto.com/images/minuteman-mmiii/mirrors.jpg"><img alt="The alignment block with mirrored surfaces. Image from National Air and Space Museum." height="407" src="https://static.righto.com/images/minuteman-mmiii/mirrors-w450.jpg" title="The alignment block with mirrored surfaces. Image from National Air and Space Museum." width="450"></a></p>
<p>The photo above shows the alignment block on top of the gyrocompass.
The front and back of the block are the precision mirrors that reflect the light beam from the autocollimator.
The circles on top of the block and at the right are two level detectors, with set screws for exact adjustment.
The platform has four level detectors, allowing it to be aligned against gravity in multiple positions.
Like the gimbals, the gyrocompass assembly is made of beryllium due to its rigidity and light weight; it has a warning sticker because beryllium is highly toxic.</p>
<p>The diagram below shows how the axes align with the gimbals of the stable platform.<span id="fnref:axes"><a href="#fn:axes">7</a></span>
Note the window at the top of the photo.
Light from the autocollimator shines in through the window, reflects off the mirror on the alignment block, and returns through
the window to the autocollimator. 
The autocollimator detects any error in alignment and signals the guidance system to correct its position accordingly.</p>
<p><a href="https://static.righto.com/images/minuteman-mmiii/coordinates.jpg"><img alt="Coordinate system for the stable platform. Note that these axes don't match the missile axes; the stable platform axes remain constant as the missile turns. Original image from National Air and Space Museum." height="546" src="https://static.righto.com/images/minuteman-mmiii/coordinates-w500.jpg" title="Coordinate system for the stable platform. Note that these axes don't match the missile axes; the stable platform axes remain constant as the missile turns. Original image from National Air and Space Museum." width="500"></a></p><p>Coordinate system for the stable platform. Note that these axes don't match the missile axes; the stable platform axes remain constant as the missile turns. Original image from <a href="https://airandspace.si.edu/collection-objects/guidance-system-minuteman-iii/nasm_A19770995000">National Air and Space Museum</a>.</p>
<p>The stable platform uses gyroscopes to maintain its fixed orientation as the missile turns.
The idea behind a gyroscope is that a spinning disk will tend to maintain its spin axis.
The problem is that any friction, even from precision ball bearings, will reduce the accuracy.
The solution in the Minuteman is a "gas bearing", where the gyroscope rotor is supported by an extremely thin layer of hydrogen.
As shown below, the gyroscope is built around a stationary marble-sized ball (blue), fastened to the gyroscope frame at the top and bottom.
The rotor (pink) is clamped around the equator of the ball and spins at high speed, powered by an induction motor (windings green, rotor yellow).
If the gyroscope frame is tilted, the rotor will stay in its orientation. The resulting change in angle between the frame and the rotor is detected by sensitive capacitive pickups (purple).
The gyroscope is sensitive to tilt in two axes: left-right, and front-back.
Since nothing touches the rotor except the thin layer of gas around the ball, the influence of friction is minimal.</p>
<p><a href="https://static.righto.com/images/minuteman-mmiii/gyroscope.jpg"><img alt="A gas-bearing gyroscope. Based on patent 3,025,708." height="379" src="https://static.righto.com/images/minuteman-mmiii/gyroscope-w450.jpg" title="A gas-bearing gyroscope. Based on patent 3,025,708." width="450"></a></p>
<p>A gas-bearing gyroscope has the problem that when it starts or stops, the gas layer dissipates, allowing the rotor and the bearing to rub.
The Minuteman missile's guidance system was kept continuously running, so starts and stops were infrequent.
Moreover, when the gyroscope did need to be started, the electronics gave it a 40-volt jolt to get it up to speed quickly.
Because the Minuteman's guidance system was always running—and its solid-fuel engines didn't require fueling—the missile 
could be launched in under a minute.</p>
<p>To summarize the guidance trajectory,
a Minuteman flight is typically about 35 minutes,<span id="fnref:trajectories"><a href="#fn:trajectories">8</a></span> but only the first few minutes are powered by the rockets; the warheads
coast most of the way on a ballistic trajectory.
The first three rocket stages are active for just 180 seconds; this completed the boost phase for Minuteman I and II.
However, the innovation of Minuteman III was that it held three warheads, a system called MIRV (Multiple Independently-targeted Reentry Vehicles).
To direct these warheads to their targets, Minuteman III has a fourth stage, called PSRE (Propulsion System Rocket Engine),
mounted just below the guidance system.
The PSRE was active for <a href="https://apps.dtic.mil/sti/tr/pdf/AD0757212.pdf#page=79">440 seconds</a>,
directing each warhead on its specific path.
(Meanwhile, a retro-rocket sent the third stage in a random direction. Otherwise, it would tag along with the warheads, acting as a giant
radar beacon for enemy anti-ballistic-missile systems.)
The warheads travel very high, typically over 800 nautical miles (1500 km), more than three times the altitude of the International Space Station.
As for the multiple-warhead MIRV, the Minuteman III missiles were converted back to single warheads as part of the New START
arms reduction treaty, with the last MIRV removed in <a href="https://www.af.mil/News/Article-Display/article/485611/malmstrom-completes-final-minuteman-iii-configuration/">June 2014</a>.</p>
<p><a href="https://static.righto.com/images/minuteman-mmiii/mirv.jpg"><img alt="A MIRV configuration with three W78 warheads on the Minuteman III MK-12A reentry vehicle system. The conical reentry vehicles are smaller than you might expect, just under 6 feet tall (181 cm). In comparison, the Titan II had a reentry vehicle that was 14 feet long (4.3 m), holding a massive 9-megaton warhead. Photo from GAO-21-210." height="418" src="https://static.righto.com/images/minuteman-mmiii/mirv-w500.jpg" title="A MIRV configuration with three W78 warheads on the Minuteman III MK-12A reentry vehicle system. The conical reentry vehicles are smaller than you might expect, just under 6 feet tall (181 cm). In comparison, the Titan II had a reentry vehicle that was 14 feet long (4.3 m), holding a massive 9-megaton warhead. Photo from GAO-21-210." width="500"></a></p><p>A MIRV configuration with three W78 warheads on the Minuteman III MK-12A reentry vehicle system. The conical reentry vehicles are smaller than you might expect, just under 6 feet tall (181 cm). In comparison, the Titan II had a reentry vehicle that was 14 feet long (4.3 m), holding a massive 9-megaton warhead. Photo from <a href="https://www.gao.gov/assets/gao-21-210.pdf">GAO-21-210</a>.</p>

<p>The guidance computer has a key role in the Minuteman missile, determining the missile's position from the stable platform data,
executing a guidance algorithm, and steering the missile on the desired trajectory.
Before explaining the D-37 computer used in Minuteman II and III, I'll start by discussing the D-17B computer used in the first Minuteman, since its characteristics strongly influenced the later computers.
The Minuteman I computer was very primitive by modern standards.
Although it was a 24-bit machine, it was a serial computer, operating on one bit at a time. 
The big advantage of serial processing is that it dramatically reduces the hardware requirements. Since the computer only processes one bit at a time,
it uses a one-bit ALU. Moreover, the buses and datapaths are one bit wide rather than 24 bits.
The disadvantage, of course, is that a serial computer is slow; the D-17B took 27 clock cycles (24 bits and three overhead) to perform any operation. At best, the computer could perform 12,800 additions per second.</p>
<p>The computer has an unusual cylindrical structure, 29 inches (74 cm) in diameter, designed to fit the diameter of the Minuteman missile.
The computer itself is the bottom half of the cylindrical shell.
The top half is the <a href="http://www.bitsavers.org/pdf/autonetics/d17/D17_Surplus_Annoucement.pdf#page=9">electronic equipment chassis</a>, holding the power supplies for the computer and the stable platform, as well as
servo control amplifiers, oscillators, and converters.</p>
<p><a href="https://static.righto.com/images/minuteman-mmiii/guidance-computer.jpg"><img alt="The Minuteman I guidance computer. The computer itself is the bottom half of the cylinder, with the disk drive in the 4 o'clock position. The upper half is electronics to drive the IMU and rocket. The IMU itself would be mounted in the center. Photo by Steve Jurvetson, CC BY 2.0." height="554" src="https://static.righto.com/images/minuteman-mmiii/guidance-computer-w600.jpg" title="The Minuteman I guidance computer. The computer itself is the bottom half of the cylinder, with the disk drive in the 4 o'clock position. The upper half is electronics to drive the IMU and rocket. The IMU itself would be mounted in the center. Photo by Steve Jurvetson, CC BY 2.0." width="600"></a></p><p>The Minuteman I guidance computer. The computer itself is the bottom half of the cylinder, with the disk drive in the 4 o'clock position. The upper half is electronics to drive the IMU and rocket. The IMU itself would be mounted in the center. Photo by <a href="https://commons.wikimedia.org/wiki/File:Minuteman_Missile_Guidance_Computer_%E3%83%BC_Computer_History_Museum_(11777981).jpg">Steve Jurvetson</a>, <a href="https://creativecommons.org/licenses/by/2.0/deed.en">CC BY 2.0</a>.</p>
<p>The computer doesn't have any RAM. Instead, all instructions, data, and registers are stored on a hard disk, but not like a modern hard disk.
The disk has separate, fixed heads for each track so it can access tracks without seeking. 
(This approach is similar to a computer built around <a href="https://en.wikipedia.org/wiki/Drum_memory">drum memory</a>, except the drum is flattened.)
In total, the disk held just 2727 24-bit words (approximately 8 Kbytes).
The computer's serial processing and its disk-based storage worked well together. The disk provided data one bit at a time, which the computer would process serially.
The results were written back to the disk, one bit at a time as calculation proceeded.
The write head was positioned just behind the read head so a value could be overwritten as it was computed.</p>
<p>The photo below shows the numerous read and write heads for the D-17B's hard disk.
Note that the heads are fixed (unlike modern hard drives), and the heads are widely distributed across the surface.
(There is no need for different tracks to be aligned.)
I believe that the green and white heads in pairs are for the "regular" tracks, while the heads with other spacings implement
registers and short-term storage called <em>loops</em>.<span id="fnref:timing"><a href="#fn:timing">9</a></span></p>
<p><a href="https://static.righto.com/images/minuteman-mmiii/drive-heads.jpg"><img alt="Disk head assembly from the D-17B. Photo by LaserSam, CC BY-SA 40." height="426" src="https://static.righto.com/images/minuteman-mmiii/drive-heads-w400.jpg" title="Disk head assembly from the D-17B. Photo by LaserSam, CC BY-SA 40." width="400"></a></p>
<p>The D-17B computer was transistorized. The photo below shows one of its circuit boards, crammed with transistors (the black cylinders), resistors, diodes, and other components.
(This board is a read amplifier, amplifying the signals from the hard disk.)
The computer used diode-resistor logic and diode-transistor logic to minimize the number of transistors;
as a result, it used 6282 diodes and 5094 resistors compared to 1521 silicon and germanium transistors (<a href="http://www.bitsavers.org/pdf/autonetics/d17/AD-760_757_Reutilization_of_the_Minuteman_Guidance_Computer_as_a_Numerical_Process_Controller_Mar73.pdf#page=28">source</a>).</p>
<p><a href="https://static.righto.com/images/minuteman-mmiii/read-amplifier.jpg"><img alt="A read amplifier circuit board from the D-17B. Photo from bitsavers." height="308" src="https://static.righto.com/images/minuteman-mmiii/read-amplifier-w600.jpg" title="A read amplifier circuit board from the D-17B. Photo from bitsavers." width="600"></a></p><p>A read amplifier circuit board from the D-17B. Photo from <a href="https://bitsavers.org/pdf/autonetics/d17/pcb/57673-501/s-l1600-14.jpg">bitsavers</a>.</p>
<p>The computer supported 39 instructions.
Many of the instructions are straightforward: add, subtract, multiply (but no divide), complement, magnitude, AND, left shift, and right shift. 
The computer handled 24-bit words as well as 11-bit split words, so many of these instructions had "split" versions to operate on a shorter
value.
One unusual instruction was "split compare and limit", which replaced the accumulator value with a limit value from memory, if the
accumulator value exceeded the limit.</p>
<p>The focus of the computer was I/O with 48 digital inputs, 26 incremental inputs, 28 digital outputs, 12 analog voltage outputs, and 3 pulse outputs for gyro control.
The computer had special instructions to support the various inputs and outputs.<span id="fnref:analog"><a href="#fn:analog">10</a></span>
For example, to integrate pulse signals from the stable platform, the computer had instructions to enter and exit "Fine Countdown" mode, which caused two special registers to operate
as digital integrators, in parallel with regular computation (<a href="https://apps.dtic.mil/sti/tr/pdf/AD0760757.pdf#page=62">details</a>).</p>
<h2>The D-37 computer</h2>
<p>For the Minuteman II missile, Autonetics built the D-37 computer, one of the earliest integrated circuit computers.
By using integrated circuits, the guidance computer was dramatically shrunk, increasing range, functionality, and accuracy.
The photo below compares the size of the older D-17B computer (half-cylinder) with the D-37B (held by the engineer).</p>
<p><a href="https://static.righto.com/images/minuteman-mmiii/computers.jpg"><img alt="The Minuteman D-17B computer (cylinder) and D-37B computer (being held). From Microcomputer comes off the line, Electronics, Nov 1, 1963. Using modern definitions, the computer was a minicomputer, not a microcomputer." height="476" src="https://static.righto.com/images/minuteman-mmiii/computers-w500.jpg" title="The Minuteman D-17B computer (cylinder) and D-37B computer (being held). From Microcomputer comes off the line, Electronics, Nov 1, 1963. Using modern definitions, the computer was a minicomputer, not a microcomputer." width="500"></a></p><p>The Minuteman D-17B computer (cylinder) and D-37B computer (being held). From <a href="https://www.worldradiohistory.com/Archive-Electronics/60s/63/Electronics-1963-11-01.pdf">Microcomputer comes off the line</a>, <i>Electronics</i>, Nov 1, 1963. Using modern definitions, the computer was a minicomputer, not a microcomputer.</p>
<p>Although the main task of the computer is guidance,
with the increased capacity of the D-37, the computer took over many of the tasks formerly performed by ground support equipment.
The D-37 managed "ground control and checkout, monitoring, communication coding and decoding, as well as the airborne tasks of navigation, guidance, steering, and control" (<a href="https://arc.aiaa.org/doi/abs/10.2514/6.1982-1550">link</a>). <!--andreMinutemanInertialGuidance1982--></p>
<p>The D-37 had several models. The D-37A was the prototype system, while the D-37B was deployed in the first 60 Minuteman II missiles.
The Air Force soon realized that
nuclear radiation posed a threat to the computer, so they developed the radiation-hardened D-37C.<span id="fnref:radiation"><a href="#fn:radiation">11</a></span>
The Minuteman III used the D-37D, an improved and slightly larger version.
Even with additional disk space, program memory was so tight that software features were dropped to save just <a href="https://apps.dtic.mil/sti/tr/pdf/AD0757212.pdf#page=86">47 words</a>.</p>
<p>As far as architecture and performance, the D-37 computer is almost the same as the D-17B, but extended.
Most importantly, the D-37 kept the serial architecture of the D-17B, so it had the same slow instruction speed.
The D-37 kept the instruction set of the D-17B, with additional instructions such as division, logical OR, bit rotates, and more I/O, giving it 58 instructions versus 39 in the older computer.
It expanded the hard disk storage, but with a double-sided disk providing 7222 words of storage in the D37-C.<span id="fnref:capacity"><a href="#fn:capacity">12</a></span>
The D-37 included division implemented in hardware (which the D-17B didn't have), along with a faster hardware implementation of multiplication, improving the speed of those instructions.<span id="fnref:instructions"><a href="#fn:instructions">13</a></span>
The D-37C added more I/O lines, as well as radio input and 32 analog voltage inputs. <!-- https://apps.dtic.mil/sti/tr/pdf/AD0760757.pdf --></p>
<p>The diagram below shows the D-37C computer, used in the Minuteman II.
At the left is the hard disk that provides the computer's memory. Most of the computer is occupied by complex circuit boards
covered with flat-pack integrated circuits. At the right is the advanced switching power supply, generating numerous
voltages for the computer (±3, 6, 9, 12, 18, and 24 volts).
The connectors at the top provide the interface between the computer and the rest of the system.
Because the computer has so many digital (discrete) and analog signals, it uses multiple 61-pin connectors (<a href="https://bitsavers.org/pdf/autonetics/d17/AD-777_244_Conversion_of_the_D37C_Computer_For_General_Purpose_Applications_Mar74.pdf#page=117">details</a>).</p>
<p><a href="https://static.righto.com/images/minuteman-mmiii/computer-labeled.jpg"><img alt="The D-37C computer. Image courtesy Martin Miller, www.martin-miller.us." height="384" src="https://static.righto.com/images/minuteman-mmiii/computer-labeled-w700.jpg" title="The D-37C computer. Image courtesy Martin Miller, www.martin-miller.us." width="700"></a></p>
<p>The D-37C computer was built from 22 different integrated circuits, custom-built by Texas Instruments for the Minuteman project.
These chips ranged from digital functions such as NAND gates and a flip-flop to linear amplifiers to specialized functions such as a demodulator/chopper. 
Texas Instruments sold the Minuteman series integrated circuits on the open market, but the chips were
spectacularly expensive ($55 for a flip-flop, over $500 in current dollars) and not as popular as 
TI's general-purpose integrated circuits.<span id="fnref:flip-flop"><a href="#fn:flip-flop">14</a></span>
The circuit boards were very complex for the time, with 10 interconnected layers. Each board was about 4 × 5½ inches and
held about 150 flatpack integrated circuits, with components on both sides.</p>
<p>The growth of the integrated circuit industry owes a lot to the 
Minuteman computer and the Apollo Guidance Computer, both developed during the early days of the integrated circuit.
These projects bought integrated circuits by the hundreds of thousands, helping the IC industry move from low-volume prototypes
to mass-produced commodities, both by providing demand and by motivating companies to fix
yield problems.
Moreover, both computers required high-reliability integrated circuits, forcing the industry to improve its manufacturing processes.
Finally, Minuteman and Apollo gave integrated circuits credibility, showing that ICs were a practical design choice.</p>
<p>The Minuteman III used the D-37D computer,
which had about twice the disk capacity, 14,137 words.
The layout is similar to the D-37C above, with the disk drive on the left and the power supply on the right.
Since the computer is mounted "upside down", the boards are not visible inside, blocked by the
interconnect board.<span id="fnref:exploded"><a href="#fn:exploded">15</a></span>
Note the use of flexible PCBs, advanced technology for the time, soldered with low-melting-point indium/tin solder.</p>
<p><a href="https://static.righto.com/images/minuteman-mmiii/d37d.jpg"><img alt="The D-37D computer. Image from National Air and Space Museum." height="382" src="https://static.righto.com/images/minuteman-mmiii/d37d-w700.jpg" title="The D-37D computer. Image from National Air and Space Museum." width="700"></a></p>
<p>By 1970, the D-37 computer had made the cylindrical D-17B obsolete. The government gave away <a href="http://www.bitsavers.org/pdf/autonetics/d17/D17_Surplus_Annoucement.pdf">surplus</a> D-17B computers to universities and other organizations for use as general-purpose microcomputers.
Dozens of organizations, from Harvard to the Center for Disease Control to Tektronix jumped at the chance to obtain a free computer, even if it was slow and difficult to use,
forming a large <a href="http://www.bitsavers.org/pdf/autonetics/d17/MCUG-3-72_Proceedings_of_the_Fourth_Meeting_of_the_Minuteman_Computer_Users_Group_Jun72.pdf">users group</a> to share programming tips.</p>
<h2>The P92 amplifier</h2>
<p>The amplifier provides the interface between the computer and the rest of the missile.
The amplifier sends control signals to the missile's four stages, controlling the engines and steering.
(The electronic circuitry
from the Minuteman I's nozzle control units was moved to the amplifier, simplifying maintenance.) <!-- Minuteman: A technical history, page 224 -->
Moreover, the Minuteman has explosive ordnance in many places, ranging from small squibs that activate valves to explosives that separate the missile stages.
The amplifier sends the high-current (30 amp) signals to detonate the ordnance, while monitoring the current to detect faults.<span id="fnref:incident"><a href="#fn:incident">16</a></span>
The amplifier acts as a safety device for the ordnance, blocking signals unless the amplifier has been armed with the proper code.
The amplifier sends control signals to the reentry system (i.e. the warheads) as well as the chaff dispenser, which emits
clouds of wires to jam enemy radar.
The amplifier also sends and receives signals through the umbilical cable from the ground equipment.</p>
<!-- See LCC page 3-8 for connections. -->

<p><a href="https://static.righto.com/images/minuteman-mmiii/amplifier.jpg"><img alt="The PS 92A amplifier. Image from National Air and Space Museum. Click this (or any other image) for a higher-resolution version." height="540" src="https://static.righto.com/images/minuteman-mmiii/amplifier-w700.jpg" title="The PS 92A amplifier. Image from National Air and Space Museum. Click this (or any other image) for a higher-resolution version." width="700"></a></p><p>The PS 92A amplifier. Image from <a href="https://airandspace.si.edu/collection-objects/guidance-system-minuteman-iii/nasm_A19770995000">National Air and Space Museum</a>. Click this (or any other image) for a higher-resolution version.</p>
<p>The photo above shows the amplifier with its cover removed.
The amplifier is constructed as two stacks of six circuit boards, on top of a double-width power supply board.
At the top and bottom of each board, connectors with thick cables connect the boards to the rest of the system.
Each board is a multi-layer printed-circuit board built on a thick magnesium frame for cooling.
The amplifier has five power switching boards, a valve driver board, three servo amplifier boards, and an ACTR control board (whatever that is).
The system board is visible on the left, with large capacitors and precision 0.01% resistors. To its right is the decoder board, presumably decoding computer commands
to select a particular I/O device.
Note the extensive use of Texas Instruments flat-pack integrated circuits on this board, the tiny white rectangles.</p>
<h2>Missile Guidance Set Control</h2>
<p>The Missile Guidance Set Control (MGSC) contains the electronics to power and run the inertial measurement unit (IMU),
providing the interface to the computer.
The MGSC handles the platform servo loop, accelerometer server loops, gyroscope torquing, gyrocompass torquing and slew,
and accelerometer temperature control.<span id="fnref:platform-control"><a href="#fn:platform-control">17</a></span>
One unexpected function of the MGSC is powering the computer's hard disk,
supplying 400 Hz, 3-phase power at 27.25 volts (<a href="https://bitsavers.org/pdf/autonetics/d17/AD-777_244_Conversion_of_the_D37C_Computer_For_General_Purpose_Applications_Mar74.pdf#page=28">source</a>).</p>
<p><a href="https://static.righto.com/images/minuteman-mmiii/mgsc.jpg"><img alt="The Missile Guidance Set Control with the modules labeled. Original image from National Air and Space Museum." height="840" src="https://static.righto.com/images/minuteman-mmiii/mgsc-w600.jpg" title="The Missile Guidance Set Control with the modules labeled. Original image from National Air and Space Museum." width="600"></a></p>
<p>The MGSC is constructed from hinged metal modules, each with a particular function, shown above. The modules are constructed around
printed circuit boards.
Two large connectors at the right of the MGSC provide electrical connectivity with the IMU and computer.
At the top and bottom of the MGSC are connections for coolant.
The MGSC is roughly equivalent to the top half of the Minuteman I's cylindrical guidance system, opposite the computer half.
The MGSC is unchanged between the Minuteman II and Minuteman III.
The MGSC is normally covered with a metal cover that provides radiation protection, but the cover is missing in the photo above.</p>
<h2>Battery</h2>
<p>The battery in the Minuteman Guidance System is very unusual, since it is a "reserve battery", completely inert until activated.
It is a silver/zinc battery with the electrolyte stored separately, giving the battery an essentially infinite shelf life.
To power up the battery during a launch, a gas generator inside the battery is ignited by a squib. The gas pressure forces the potassium hydroxide electrolyte out of a
tank and into the battery, energizing the battery in under a second.
The battery can only be used once, of course, and you can't test it. 
The battery was built by Delco-Remy (a division of General Motors) (<a href="https://www.delcoremyhistory.com/Products/missilebattery.htm">details</a>).
It provides 28 volts at 14.5 Amp-hours, powering the guidance system and most of the missile; a separate battery powers the
first-stage rocket.</p>
<p><a href="https://static.righto.com/images/minuteman-mmiii/battery.jpg"><img alt="The battery inside the Minuteman III. Original image from National Air and Space Museum." height="565" src="https://static.righto.com/images/minuteman-mmiii/battery-w250.jpg" title="The battery inside the Minuteman III. Original image from National Air and Space Museum." width="250"></a></p>
<p>The photo above shows the battery mounted inside the guidance system. Note the two thin wires attached to the posts on the left front of the battery to enable the battery, and the thick power wires bolted to the posts on the right.
Above these posts is an "electrolyte vent port"; I'm not sure what prevents caustic electrolyte from spraying out under high
pressure.</p>
<p>The photo below shows the construction of a Minuteman I battery, similar but with two independent battery blocks. The two round gas generators on the front of the electrolyte tube force
the electrolyte into the battery sections.</p>
<p><a href="https://static.righto.com/images/minuteman-mmiii/battery-internals.jpg"><img alt="Inside the remotely-activated SE12G battery. (source)" height="348" src="https://static.righto.com/images/minuteman-mmiii/battery-internals-w500.jpg" title="Inside the remotely-activated SE12G battery. (source)" width="500"></a></p><p>Inside the remotely-activated SE12G battery. (<a href="https://ntrs.nasa.gov/api/citations/19860012475/downloads/19860012475.pdf#page=10">source</a>)</p>
<h2>Squib-activated switch</h2>
<p>Another unusual component is the squib-activated switch.
This switch is activated by a small explosive squib; when fired, the squib forces the switch to change positions.
This switch may seem excessively dramatic, but it has a few advantages over, say, an electromagnetic relay.
The squib-activated switch will switch solidly, while the contacts on a relay may "chatter" or bounce before settling into their new positions.
An electromagnetic relay may require more current to switch, especially if it has large contacts or many contacts.
However, like the battery, the squib-activated switch can only be used once.</p>
<p><a href="https://static.righto.com/images/minuteman-mmiii/squib-switch.jpg"><img alt="The squib-activated switch, next to a coolant line.
The manufacturer of this part is Boeing, as indicated by the Cage Code 94756 on the part.
Image from National Air and Space Museum." height="291" src="https://static.righto.com/images/minuteman-mmiii/squib-switch-w400.jpg" title="The squib-activated switch, next to a coolant line.
The manufacturer of this part is Boeing, as indicated by the Cage Code 94756 on the part.
Image from National Air and Space Museum." width="400"></a></p><p>The squib-activated switch, next to a coolant line.
The manufacturer of this part is Boeing, as indicated by the Cage Code 94756 on the part.
Image from <a href="https://airandspace.si.edu/collection-objects/guidance-system-minuteman-iii/nasm_A19770995000">National Air and Space Museum</a>.</p>
<p>The purpose of the switch is to disconnect important signals, known as <a href="https://www.bitsavers.org/pdf/autonetics/d17/D17_Florida_State_University_Sep70.pdf#page=16">critical leads</a>, during launch.
The Minuteman missile has an umbilical connection that provides power, cooling, and signals while the missile is in the silo.
Just before the umbilical cable is disconnected, the switch severs the connections for the
master reset signal along with an enable and disable signal.
Presumably, these control signals are cleanly disconnected to avoid stray signals or electrical noise that could cause
problems when the umbilical connection is pulled off.</p>
<p>The photo below shows the umbilical cable connected to a Minuteman II missile in its silo.
Also note the window in the side of the missile to allow the light beam from the autocollimator to reflect off the guidance
platform for alignment.</p>
<p><a href="https://static.righto.com/images/minuteman-mmiii/silo.jpg"><img alt="A Minuteman II missile in its silo. Photo by Kelly Michals, CC BY-NC 2.0." height="438" src="https://static.righto.com/images/minuteman-mmiii/silo-w500.jpg" title="A Minuteman II missile in its silo. Photo by Kelly Michals, CC BY-NC 2.0." width="500"></a></p>
<h2>Cooling</h2>
<p>The guidance system is water-cooled while in the silo, using a solution of sodium chromate to inhibit corrosion.
After launch, the guidance system operated for just a few minutes before releasing the warheads, so it operated without
water cooling.
(The stable platform has a fan and heat exchanger to keep it cool during flight.)
The diagram below highlights the cooling lines.
Coolant is provided from the ground support equipment through the umbilical connector in the upper right.
It flows through the computer, diode assembly, 
MGSC, and stable platform.
Finally, the coolant exits through the umbilical connector.</p>
<p><a href="https://static.righto.com/images/minuteman-mmiii/cooling.jpg"><img alt="Original image from National Air and Space Museum." height="599" src="https://static.righto.com/images/minuteman-mmiii/cooling-w600.jpg" title="Original image from National Air and Space Museum." width="600"></a></p>
<h2>Diode assembly</h2>
<p>In the middle of the guidance system, the diode assembly consists of seven power diodes.
These diodes control the power flow when switching from ground power to battery power.
The photo below shows the diode assembly, with coolant connections at the top and bottom.
The thick gray wire in the center of the diode assembly receives power from the battery just to the left.</p>
<p><a href="https://static.righto.com/images/minuteman-mmiii/diode-assembly.jpg"><img alt="The diode assembly. Image from National Air and Space Museum." height="391" src="https://static.righto.com/images/minuteman-mmiii/diode-assembly-w400.jpg" title="The diode assembly. Image from National Air and Space Museum." width="400"></a></p>
<h2>Permutation plug</h2>
<p>The Permutation plug (or P-plug) was the key cryptographic element of the guidance system, defining the launch codes for a particular missile.
The P-plug looked similar to a hockey puck and plugged into a 55-pin socket attached to the amplifier.
The retaining bar held the P-plug in place.</p>
<p><a href="https://static.righto.com/images/minuteman-mmiii/p-plug.jpg"><img alt="The connector that receives the Permutation plug. Image from National Air and Space Museum." height="438" src="https://static.righto.com/images/minuteman-mmiii/p-plug-w450.jpg" title="The connector that receives the Permutation plug. Image from National Air and Space Museum." width="450"></a></p>
<p>Because the security of the missile hinged on the P-plug, the P-plug was handled in a highly ritualized way, transported by a two-person team, an airman and an officer, both armed (<a href="http://www.siloworld.net/STORIES/storiespg5.htm">source</a>).
After the guidance system underwent maintenance, the P-plug team would ensure that the plug was properly installed, just before
the missile was bolted back together.
There was also a lot of ritual around the disk memory, since it held security codes and targeting information.<span id="fnref:targeting"><a href="#fn:targeting">18</a></span> Before anyone could work on the computer, a special team would come to the silo and erase the memory.
Afterward, another team would load up the computer from a magnetic tape (in the case of Minuteman III) or punched tape (earlier).<span id="fnref:fill"><a href="#fn:fill">19</a></span></p>
<p>The missile launch codes are <a href="https://nuclearcompanion.com/rapid-execution-and-combat-targeting-react-armageddon-with-a-floppy-disk-and-trackball/">said</a> to be split between the hard disk
and the permutation plug.
In particular, the missile software holds a two-word code for each of the five launch control facilities.<span id="fnref:launch-control"><a href="#fn:launch-control">22</a></span>
The launch code in an Execute Launch Command (ELC) must match the combination of the P-plug value and the site-specific value on disk.<span id="fnref:select"><a href="#fn:select">23</a></span>
Thus, the launch code is unique to each launch control site and each missile.<span id="fnref:csd"><a href="#fn:csd">24</a></span>
As another security feature, a launch requires messages from two launch control sites, unless only one was available.<span id="fnref:vote"><a href="#fn:vote">25</a></span></p>
<h2>Transient current detector</h2>
<p>A nuclear blast has many bad effects on semiconductors and can cause transient errors.
A rather brute-force approach was used to minimize this risk in the D-37C and D-37D computers: if a nuclear blast is detected, the computer stops writing to disk until the burst of radiation
passes by.
When the radiation level drops, the computer carries on from where it left off, extrapolating to make up for the lost time
to minimize the error.
Since all data is stored on the hard disk, the system doesn't need to worry about memory corruption as could happen with semiconductor RAM.</p>
<p>The Minuteman documents euphemistically refer to "operating in a hostile environment" for the ability to handle large pulses of radiation from a nearby nuclear explosion.
Another euphemism is "seismic environment", when a nuclear blast near a silo could disturb the missile's targeting alignment.
To get an idea of the expected forces, note that the launch officers were strapped into their seats with four-point harnesses to protect against the seismic environment.<span id="fnref:displacement"><a href="#fn:displacement">27</a></span></p>
<p><a href="https://static.righto.com/images/minuteman-mmiii/transient-detector.jpg"><img alt="The Transient Current Detector. Image from National Air and Space Museum." height="302" src="https://static.righto.com/images/minuteman-mmiii/transient-detector-w700.jpg" title="The Transient Current Detector. Image from National Air and Space Museum." width="700"></a></p>
<p>The "transient current detector" above detects dangerous levels of radiation. 
I couldn't find any details, but I suspect that it contains a semiconductor and detects transient current through the semiconductor induced by radiation.
It would make sense to use a semiconductor similar to the ones in the computer so the detector's response matches the response of the computer, perhaps a matching Texas Instruments IC.</p>
<p>The Minuteman III also has two "field detectors" mounted on the outside of the guidance ring. These presumably detect large fluctuations in the electromagnetic field, indicating an electromagnetic pulse (EMP), different from the ionizing radiation picked up by the Transient Current Detector.</p>
<h2>Conclusions</h2>
<p>The Minuteman guidance system is full of innovative technologies. Among other things, Minuteman I used an early transistorized
computer, and Minuteman II used one of the first integrated circuit computers.
The Minuteman missile isn't just something from the past, though. There are currently 400 Minuteman missiles in the United States, ready
to launch at a moment's notice and create global devastation.
Thus, its technical achievements can't be glorified without reflecting on the negativity of its underlying purpose.
On the other hand, Minuteman has succeeded (so far) in its purpose of deterrence, so it can also be viewed in a positive, peacekeeping role.
In any case, the Minuteman technology is morally ambiguous, compared to, say, the Apollo Guidance Computer.</p>
<p>I plan to write more about the role of Minuteman and Apollo in the IC industry, so follow me on Mastodon as <a href="https://oldbytes.space/@kenshirriff">@<span data-cfemail="adc6c8c3dec5c4dfdfc4cbcbedc2c1c9cfd4d9c8de83deddcccec8">[email&nbsp;protected]</span></a>
or <a href="http://www.righto.com/feeds/posts/default">RSS</a> for updates.
Probably the best overview of Minuteman is 
<a href="https://minutemanmissile.com/documents/MinutemanWeaponSystemHistoryAndDescription.pdf">Minuteman weapon system history and description</a>.
The book <a href="https://amzn.to/46YRoAY">Minuteman: A technical history</a> has thorough information.
For information on the missile targeting and alignment process, see 
<a href="https://www.afmissileers.org/Newsletters">Association of Air Force Missileers Newsletter</a>, December 2006.
The Minuteman guidance system is described in detail in <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/j.2161-4296.1976.tb01852.x">The evolution of Minuteman guidance and control</a>. <!--wuerthEvolutionMinutemanGuidance1976-->
Much of the imagery in this article is from the <a href="https://airandspace.si.edu/collection-objects/guidance-system-minuteman-iii/nasm_A19770995000">National Air and Space Museum</a>.
Thanks to Martin Miller for providing a detailed D-37C photo. He has taken amazing photos of nuclear equipment, published in his book <a href="https://amzn.to/3ArBF14">Weapons of Mass Destruction: Specters of the Nuclear Age</a>, so check it out.</p>
<h2>Notes and references</h2>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Imgpls – An extension to load Imgur images directly (133 pts)]]></title>
            <link>https://andadinosaur.com/launch-imgpls</link>
            <guid>41293381</guid>
            <pubDate>Mon, 19 Aug 2024 18:19:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://andadinosaur.com/launch-imgpls">https://andadinosaur.com/launch-imgpls</a>, See on <a href="https://news.ycombinator.com/item?id=41293381">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <article>
  

  <time datetime="2024-08-20">
      <a href="https://andadinosaur.com/launch-imgpls">20 August 2024</a>
</time>
  <p><em>I wrote this app to fix a personal annoyance. You probably don’t need it.</em></p>

<p><img loading="lazy" src="https://andadinosaur.com/rails/active_storage/blobs/redirect/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBBaGtCIiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--138d4522d83e0f9ba76137f9a914a8086403646c/phones.png"></p>

<p>I’m not an Imgur user. But in my day-to-day browsing, I sometimes encounter a wild Imgur link. And when I click that link, it takes me to the Imgur website, and the logo loads. Then the app banner thing on top loads. Then I see the popup that asks me to download the Imgur app. Then I have to dismiss the popup to see the image. Then when I try to zoom in, the website loads another image, for some reason.</p>

<p>With Imgpls, clicking links like <a href="https://i.imgur.com/fxBBsLx.gif"><code>i.imgur.com/fxBBsLx.gif</code></a> loads the image directly.</p>

<hr>
<h3 id="url-patterns-supported">URL Patterns Supported</h3>
<p>Imgpls changes URLs with the following patterns:</p>

<ul>
<li><code>i.imgur.com/RaNdOm.jpg</code></li>
<li><code>imgur.com/RaNdOm</code></li>
</ul>

<p>Imgpls doesn’t change URLs with the following patterns (mostly because they might contain multiple images):</p>

<ul>
<li><code>imgur.com/a/sTuFf</code></li>
<li><code>imgur.com/gallery/gallery-name</code></li>
<li><code>imgur.com/t/community</code></li>
</ul>

<hr>
<h3 id="imgpls-pricing">Imgpls Pricing</h3>
<p>Imgpls is available for <a href="https://apps.apple.com/app/imgpls/id6639617400">free on the App Store</a>. There are no subscriptions, in-app purchases, ads, or tracking.</p>

<hr>
<h3 id="imgpls-privacy-policy">Imgpls Privacy Policy</h3>
<p>Imgpls doesn’t collect, store, or transmit any personal information.</p>

<hr>
<h3 id="imgpls-support">Imgpls Support</h3>
<p>If you have any questions, feel free to contact me via <a href="mailto:zhenyi@andadinosaur.com?subject=Imgpls%20Support">email</a> or <a href="https://mastodon.social/@zhenyi">Mastodon</a>. I read all my emails and Mastodon mentions, but sometimes I’m too socially awkward to reply. Sorry about that in advance.</p>

</article>


    </div></div>]]></description>
        </item>
    </channel>
</rss>