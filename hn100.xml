<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 01 Dec 2023 08:00:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Anduril announces Roadrunner, jet-powered VTOL drone (120 pts)]]></title>
            <link>https://www.anduril.com/roadrunner/</link>
            <guid>38483353</guid>
            <pubDate>Fri, 01 Dec 2023 05:04:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anduril.com/roadrunner/">https://www.anduril.com/roadrunner/</a>, See on <a href="https://news.ycombinator.com/item?id=38483353">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Twin-Turbojet VTOL Autonomous Air Vehicle (AAV)</p><div><p>Roadrunner is a reusable, vertical take-off and landing (VTOL), operator-supervised Autonomous Air Vehicle (AAV) with twin turbojet engines and modular payload configurations that can support a variety of missions.</p><p>Roadrunner-M is a high-explosive interceptor variant of Roadrunner built for ground-based air defense that can rapidly launch, identify, intercept, and destroy a wide variety of aerial threats — or be safely recovered and relaunched at near-zero cost.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Code is run more than read (101 pts)]]></title>
            <link>https://olano.dev/2023-11-30-code-is-run-more-than-read/</link>
            <guid>38483181</guid>
            <pubDate>Fri, 01 Dec 2023 04:37:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://olano.dev/2023-11-30-code-is-run-more-than-read/">https://olano.dev/2023-11-30-code-is-run-more-than-read/</a>, See on <a href="https://news.ycombinator.com/item?id=38483181">Hacker News</a></p>
<div id="readability-page-1" class="page"><div lang="en">
    
    

    
    <h2 id="code-is-read-more-than-written">Code is read more than written</h2>

<p>This phrase is, by now, common programmer knowledge, a reminder that the person first writing a piece of code shouldn’t buy convenience at the expense of the people who will have to read it and modify it in the future. More generally, <em>code is read more than written</em> conveys that it’s usually a good investment to make the code maintainable by keeping it simple, writing tests and documentation, etc. It’s about having perspective over the software development cycle.</p>

<p>Let me express this idea more succinctly:</p>

<p>
<code>maintainer &gt; author</code>
</p>

<p>I think this line of thought can be extended beyond code-writing and used as a rule of thumb to identify problems and make decisions.</p>

<h2 id="code-is-used-more-than-read">Code is used more than read</h2>

<p>Code is a means to an end. Software should have a purpose, it’s supposed to provide a service to some user. It doesn’t matter how well written or maintainable the code is, nor how sophisticated the technology it uses if it doesn’t fulfill its purpose and provides a good experience to the user:</p>

<p>
<code>user &gt; maintainer &gt; author</code>
</p>

<p>Or, since we won’t need to distinguish between developer roles anymore:</p>

<p>
<code>user &gt; dev</code>
</p>

<p>This is why, instead of guessing or asking what they need, it’s best to put the program in front of the users early and frequently and to incorporate what we learn from their feedback.</p>

<p>This is a strong mental model, just keeping the users in mind during development can get us quite far. It’s approximately how I learned the job and how I understood it for the first half of my career.</p>

<h2 id="code-is-run-more-than-read">Code is run more than read</h2>

<p>When I say “run” I don’t just mean executing a program; I mean operating it in production, with all that it entails: deploying, upgrading, observing, auditing, monitoring, fixing, decommissioning, etc. As Dan McKinley <a href="https://mcfunley.com/choose-boring-technology">puts it</a>:</p>

<blockquote>
  <p>It is basically always the case that the long-term costs of keeping a system working reliably vastly exceed any inconveniences you encounter while building it.</p>
</blockquote>

<p>We can incorporate this idea into our little model:</p>

<p>
<code>user &gt; ops &gt; dev</code>
</p>

<p>It took me a while to fully grasp this because, in my experience, much of the software being built never really gets to production, at least not at a significant scale. Most software is built on assumptions that never get tested. But when you run your code in production, the <a href="https://en.wikipedia.org/wiki/KISS_principle">KISS</a> mantra takes on a new dimension. It’s not just about code anymore; it’s about reducing the moving parts and understanding their failure modes. It’s about shipping stuff and ensuring it works even when it fails.</p>

<h2 id="also-theres-business">Also, there’s business</h2>

<p>I said that keeping the users in mind during development can get us very far. This works under the assumption that software that’s useful and works well, software of value to users, will be of value to the organization. It’s a convenient abstraction for developers: we produce good, working software, and the business deals with turning it into money. And it mostly works, especially for consumer and enterprise software. But, eventually, that abstraction proves to be an oversimplification, and we can benefit from incorporating some business perspective into our working process:</p>

<p>
<code>biz &gt; user &gt; ops &gt; dev</code>
</p>

<p>The most obvious example is budget: we don’t have infinite resources to satisfy the user needs, so we need to measure costs and benefits. There’s marketing, there’s deadlines. There are stakeholders and investors. There are personal interests and politics at play. Decisions that make sense for our software, our team or our users considered in isolation, but not when we consider the organization as a whole. Sometimes, we need to work on what generates revenue, not what pleases the user. I’ll get back to this.</p>

<h2 id="smells">Smells</h2>

<p>We arrived at a little model that expresses the relative importance of various factors in software development, one that can perhaps help us see the bigger picture and focus on what matters. Now I want to look at some common software development dysfunctions and see how they map to the model.</p>

<h3 id="unmaintainable-code">Unmaintainable code</h3>

<p>
<code>author &gt; maintainer</code>
</p>

<p>This is where we started. This is clever and lazy code that turns into spaghetti and haunted forests, this is premature optimizations, this is only-carlos-can-touch-that-module, etc.</p>

<h3 id="unusable-software">Unusable software</h3>

<p>
<code>dev &gt; user</code>
</p>

<p>Software from teams that don’t learn from their users or that put technology first. Over-engineered programs, “modernizations” that degrade the user experience, web apps that break the browser features, etc.</p>

<h3 id="works-on-my-machine">Works on my machine</h3>

<p>
<code>dev &gt; ops</code>
</p>

<p>Software that wasn’t designed with its operation in mind. This is overly complicated software with lots of moving parts, fancy databases for small data loads, microservice ecosystems managed by a single small team. Software prematurely architected for scale. Software designed by different people than the ones woken up at midnight when it breaks.</p>

<h3 id="the-right-thing">The right thing</h3>

<p>
<code>dev &gt; biz</code>
</p>

<p>Code considered as an end in itself. Software built by pretentious artisans, musicians of the Titanic, and <a href="https://www.dreamsongs.com/RiseOfWorseIsBetter.html">Lisp Hackers</a>.</p>

<h3 id="resume-driven-development">Resume-driven development</h3>

<p>
<code>dev &gt; *</code>
</p>

<p>Software produced when there’s nothing at stake and developers get to do whatever they want.</p>

<h3 id="imaginary-software">Imaginary software</h3>

<p><code>biz &gt; user &gt; <del>ops &gt;</del> dev</code></p>

<p>This is software that’s built but rarely (or never) gets to production. I call this <em>imaginary software</em>. Charity Majors <a href="https://twitter.com/mipsytipsy/status/1308641574448803840?lang=es">calls it</a> living a lie.</p>

<p><code>biz &gt; <del>user &gt;</del> ops &gt; dev</code></p>

<p>Another kind of imaginary software is the one that doesn’t have users. (But scales). This is software that doesn’t solve a problem, or solves the wrong problem, perhaps nobody’s problem. Software that results from taking some hyped tech and hammering everything with it until something vaguely resembling a use case comes up.</p>

<h3 id="late-capitalism">Late capitalism</h3>

<p><code><del>biz &gt;</del> user &gt; ops &gt; dev</code></p>

<p>Venture-backed software without a business model or whose business model is grow-until-monopoly-then-exploit-users.</p>

<h2 id="an-elephant">An elephant</h2>

<p>If you didn’t rage-close the browser tab yet, let me wrap up by going back to this:</p>

<p>
<code>biz &gt; user</code>
</p>

<p>This one has ramifications that can be hard to swallow.</p>

<p>As I mentioned above, the way I learned the job, software was about solving problems for end users. This is summarized in one of the final tips of <em>The Pragmatic Programmer,</em> saying that our goal is to <em>delight users, not just deliver code</em>. But, since I started working as a programmer, and as software became ubiquitous, I’ve seen this assumption become increasingly hard to uphold.</p>

<p>There’s a lot of software being produced that just doesn’t care about its users, or that manipulates them, or that turns them into the product. And this isn’t limited to social media: as a user, I can’t even book a room, order food, or click on the Windows start button without popups trying to grab my attention; I can’t make a Google search without getting back a pile of garbage.</p>

<p>There’s a mismatch between what we thought doing a good job was and what a significant part of the industry considers profitable, and I think that explains the increasing discomfort of many software professionals. And while we can’t just go back to ignoring the economic realities of our discipline, perhaps we should take a stronger ethical stand not to harm users. Acknowledging that the user may not always come before the business, but that the business shouldn’t unconditionally come first, either:</p>

<p>
<code>user &gt; ops &gt; dev</code><br>
<code>biz &gt; ops &gt; dev</code><br>
<code>biz ≹ user</code>
</p>

    
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to pick more beautiful colors for your data visualizations (2020) (144 pts)]]></title>
            <link>https://blog.datawrapper.de/beautifulcolors/</link>
            <guid>38482486</guid>
            <pubDate>Fri, 01 Dec 2023 02:56:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.datawrapper.de/beautifulcolors/">https://blog.datawrapper.de/beautifulcolors/</a>, See on <a href="https://news.ycombinator.com/item?id=38482486">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

                            

                                    <p>Choosing good colors for your charts is hard. This article tries to make it easier.</p>
                
                





                




<div><figure><img width="1024" height="512" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-1024x512.png" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-1024x512.png" alt="" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-1024x512.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-300x150.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-768x384.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-1536x768.png 1536w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-700x350.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-1400x700.png 1400w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-480x240.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-960x480.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-60x30.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-120x60.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-70x35.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-140x70.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-160x80.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-320x160.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-850x425.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-1240x620.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-575x288.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-1150x575.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-640x320.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-1280x640.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-305x153.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-610x305.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-100x50.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-200x100.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-335x168.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-670x335.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1.png 1600w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-1024x512.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-300x150.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-768x384.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-1536x768.png 1536w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-700x350.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-1400x700.png 1400w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-480x240.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-960x480.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-60x30.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-120x60.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-70x35.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-140x70.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-160x80.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-320x160.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-850x425.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-1240x620.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-575x288.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-1150x575.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-640x320.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-1280x640.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-305x153.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-610x305.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-100x50.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-200x100.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-335x168.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1-670x335.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors34-1.png 1600w"></figure></div>



<p>Choosing good colors for your charts is hard. This article tries to make it easier.</p>



<p>I want you to feel more confident in your color choices. And if you have no sense of color at all, here’s my attempt to help you find good ones anyway. We’ll talk about common color mistakes I see out there in the wild and how to avoid them.</p>



<p>This is not the right article for you if you’re trying to find good gradients or shades. But if you need to find beautiful, distinctive colors for different <strong>categories (e.g., continents, industries, bird species)</strong> for your line charts, pie charts, stacked bar charts, etc., then read on.</p>







<h4>Index</h4>



<p><a href="#0"><strong>00</strong> Before we start…</a><br><a href="#1"><strong>01</strong> Broaden your understanding of colors</a><br><a href="#2"><strong>02</strong> Don’t dance all over the color wheel</a><br><a href="#3"><strong>03</strong> Use saturation and lightness to make your hues work</a><br><a href="#4"><strong>04</strong> Use warm colors &amp; blue</a><br><a href="#5"><strong>05</strong> When using green, make it a yellow or blue one</a><br><a href="#6"><strong>06</strong> Avoid pure colors</a><br><a href="#7"><strong>07</strong> Avoid bright, saturated colors</a><br><a href="#8"><strong>08</strong> Combine colors with different lightness</a><br><a href="#9"><strong>09</strong> Make your colors equally “colorful”</a><br><a href="#10"><strong>10</strong> Avoid too little contrast with the background</a><br><a href="#11"><strong>11</strong> Avoid too much contrast with the background</a><br><a href="#12"><strong>12</strong> Choose a background that’s desaturated enough</a><br><a href="#13"><strong>13</strong> Copy colors, or understand them</a></p>



<h4 id="0">Before we start…</h4>



<p>I will mention saturation, brightness, and hue a lot. The HSB (<strong>H</strong>ue, <strong>S</strong>aturation, <strong>B</strong>rightness) or HSV (<strong>H</strong>ue, <strong>S</strong>aturation, <strong>V</strong>alue) color spaces work fairly well to check them:</p>



<ul><li><strong>Hue</strong> ranges from 0° to 360° — that’s your typical color wheel: <span>⬤</span><span>⬤</span><span>⬤</span></li><li><strong>Saturation</strong> ranges from 0% (gray) to 100% (super duper colorful!!): <span>⬤</span><span>⬤</span><span>⬤</span></li><li><strong>Brightness/Value</strong> ranges from 0% (black) to 100% (the actual color): <span>⬤</span><span>⬤</span><span>⬤</span></li></ul>



<p>To convert your colors from HEX (e.g. <code>#cc0000</code>) or RGB (e.g. <code>rgb(207, 176, 58)</code>) to HSB/HSV, use a tool like <a href="http://colorizer.org/" target="_blank" rel="noopener"><strong>colorizer.org</strong></a>.</p>



<p>A relative of HSB/HSV is the <a href="https://en.wikipedia.org/wiki/HCL_color_space" target="_blank" rel="noopener">HCL</a> color space. It uses the same parameters (<strong>H</strong>ue, <strong>C</strong>hroma = saturation, <strong>L</strong>ightness), but is closer to “how we really see colors.” <a href="https://academy.datawrapper.de/article/255-how-to-pick-colors-in-datawrapper" target="_blank" rel="noopener"><strong>Datawrapper</strong> uses the HCL color space</a> for its color picker:</p>



<figure><img width="1024" height="501" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-1024x501.png" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-1024x501.png" alt="HCL color picker in Datawrapper" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-1024x501.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-300x147.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-768x376.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-700x342.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-480x235.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-960x470.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-60x29.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-120x59.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-70x34.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-140x68.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-160x78.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-320x157.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-850x416.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-1240x607.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-575x281.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-1150x563.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-640x313.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-1280x626.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-305x149.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-610x298.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-100x49.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-200x98.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-335x164.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-670x328.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31.png 1292w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-1024x501.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-300x147.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-768x376.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-700x342.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-480x235.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-960x470.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-60x29.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-120x59.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-70x34.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-140x68.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-160x78.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-320x157.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-850x416.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-1240x607.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-575x281.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-1150x563.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-640x313.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-1280x626.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-305x149.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-610x298.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-100x49.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-200x98.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-335x164.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31-670x328.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors31.png 1292w"></figure>



<p>But since you won’t find HCL in Adobe Photoshop or <a href="http://colorizer.org/" target="_blank" rel="noopener">colorizer.org</a>, every time I mention degrees (like 0°) or percentages, I’ll be talking about the HSB/HSV color space.</p>



<p>All right, let’s do this:</p>



<h4 id="1">Broaden your understanding of colors</h4>



<figure><img width="1024" height="436" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-1024x436.png" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-1024x436.png" alt="" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-1024x436.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-300x128.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-768x327.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-700x298.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-480x204.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-960x409.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-60x26.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-120x51.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-70x30.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-140x60.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-160x68.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-320x136.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-850x362.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-1240x528.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-575x245.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-1150x490.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-640x273.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-1280x545.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-305x130.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-610x260.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-100x43.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-200x85.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-335x143.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-670x285.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30.png 1324w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-1024x436.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-300x128.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-768x327.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-700x298.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-480x204.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-960x409.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-60x26.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-120x51.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-70x30.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-140x60.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-160x68.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-320x136.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-850x362.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-1240x528.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-575x245.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-1150x490.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-640x273.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-1280x545.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-305x130.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-610x260.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-100x43.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-200x85.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-335x143.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30-670x285.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors30.png 1324w"></figure>



<p>You might think like this: “I need five colors for my chart. So I’ll use green and yellow and blue and red. And… um… maybe orange? Or purple!”</p>



<p>If you haven’t thought much about colors since you were a kid coloring in your coloring book, this thought makes sense. So today I’m here to tell you: There are more colors than that.</p>



<p>Look at this graphic’s colors and compare them with the basic ones <span>⬤</span><span>⬤</span><span>⬤</span><span>⬤</span><span>⬤</span><span>⬤</span>:</p>



<div><figure><img width="1024" height="481" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-1024x481.png" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-1024x481.png" alt="" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-1024x481.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-300x141.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-768x360.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-1536x721.png 1536w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-700x329.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-1400x657.png 1400w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-480x225.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-960x451.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-60x28.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-120x56.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-70x33.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-140x66.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-160x75.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-320x150.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-850x399.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-1240x582.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-575x270.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-1150x540.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-640x300.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-1280x601.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-305x143.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-610x286.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-100x47.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-200x94.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-335x157.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-670x314.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1.png 1600w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-1024x481.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-300x141.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-768x360.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-1536x721.png 1536w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-700x329.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-1400x657.png 1400w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-480x225.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-960x451.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-60x28.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-120x56.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-70x33.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-140x66.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-160x75.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-320x150.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-850x399.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-1240x582.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-575x270.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-1150x540.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-640x300.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-1280x601.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-305x143.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-610x286.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-100x47.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-200x94.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-335x157.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1-670x314.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-1.png 1600w"></figure></div>



<p>They’re different. The red that Nadieh uses <span>⬤</span> is different from your typical red <span>⬤</span>. The green <span>⬤</span> is… can you even call it a green <span>⬤</span>? </p>



<p>So before we impose rules that limit us, let me freak you out a bit: There are thousands of colors you can use. There is yellow-ish red <span>⬤</span> and blue-ish red <span>⬤</span> and everything in between. There is gray <span>⬤</span>, but there is also cold gray <span>⬤</span> and there is warm gray <span>⬤</span>. And then there is blue. So much blue! Like this <span>⬤</span>, this <span>⬤</span>, this <span>⬤</span>, this <span>⬤</span> and this <span>⬤</span>. And we haven’t even talked about orange and yellow.</p>



<p>You have <em>lots</em> of choices. Which means you can stay in a small area of the color wheel and still have many options. Which means:</p>



<h4 id="2">Don’t dance all over the color wheel</h4>



<figure><img width="1024" height="435" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-1024x435.png" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-1024x435.png" alt="" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-1024x435.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-300x128.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-768x327.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-700x298.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-480x204.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-960x408.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-60x26.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-120x51.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-70x30.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-140x60.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-160x68.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-320x136.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-850x361.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-1240x527.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-575x245.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-1150x489.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-640x272.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-1280x544.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-305x130.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-610x259.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-100x43.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-200x85.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-335x142.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-670x285.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28.png 1324w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-1024x435.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-300x128.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-768x327.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-700x298.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-480x204.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-960x408.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-60x26.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-120x51.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-70x30.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-140x60.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-160x68.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-320x136.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-850x361.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-1240x527.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-575x245.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-1150x489.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-640x272.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-1280x544.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-305x130.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-610x259.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-100x43.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-200x85.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-335x142.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28-670x285.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors28.png 1324w"></figure>



<p>There’s no need to rely on hues from all around the color wheel like <span>⬤</span><span>⬤</span><span>⬤</span><span>⬤</span><span>⬤</span><span>⬤</span> for your visualizations. It will look more professional — and therefore more trustworthy — when it only uses a few hues and their neighbors.</p>



<p>Here’s where it becomes a good idea to actually look at a color wheel. You can use <a href="https://color.adobe.com/create/color-wheel" target="_blank" rel="noopener">Adobe Color</a> or <a href="https://www.sessions.edu/color-calculator/" target="_blank" rel="noopener">Color Calculator</a> to do so.</p>







<figure><img width="1024" height="207" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-1024x207.png" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-1024x207.png" alt="" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-1024x207.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-300x61.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-768x155.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-700x142.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-1400x283.png 1400w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-480x97.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-960x194.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-60x12.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-120x24.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-70x14.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-140x28.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-160x32.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-320x65.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-850x172.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-1240x251.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-575x116.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-1150x233.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-640x130.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-1280x259.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-305x62.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-610x124.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-100x20.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-200x40.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-335x68.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-670x136.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21.png 1462w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-1024x207.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-300x61.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-768x155.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-700x142.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-1400x283.png 1400w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-480x97.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-960x194.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-60x12.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-120x24.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-70x14.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-140x28.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-160x32.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-320x65.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-850x172.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-1240x251.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-575x116.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-1150x233.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-640x130.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-1280x259.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-305x62.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-610x124.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-100x20.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-200x40.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-335x68.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21-670x136.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors21.png 1462w"><figcaption><a href="https://www.sessions.edu/color-calculator/" target="_blank" rel="noopener">Color Calculator</a> harmonies</figcaption></figure>



<p>Lots of these tools let you choose different harmonies. One of them is called “square” or “tetradic.” <strong>Don’t use it.</strong> It will result in too many hues —&nbsp;and we’re on a mission to avoid that.</p>



<figure><video autoplay="" loop="" muted="" src="https://blog.datawrapper.de/wp-content/uploads/2020/09/200805_goodcolors20.mp4"></video></figure>



<p>In the video above, I used the color tool <a href="https://paletton.com/" target="_blank" rel="noopener">Paletton</a> to start with a tetradic harmony and then decrease the distance. Note how much more beautiful the color combinations become.</p>



<p>If the distance becomes small enough, you’re basically using <strong>complementary</strong> colors. And that’s a great choice! Lots of complementary color pairs look fantastic together. <strong>When in doubt, use complementary colors and their neighbors.</strong></p>



<p>So let’s do this —&nbsp;this time with Adobe Color:</p>



<figure><img width="1024" height="583" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-1024x583.png" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-1024x583.png" alt="Adobe Color color wheel" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-1024x583.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-300x171.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-768x437.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-1536x875.png 1536w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-700x399.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-1400x797.png 1400w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-480x273.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-960x547.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-60x34.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-120x68.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-70x40.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-140x80.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-160x91.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-320x182.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-850x484.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-1240x706.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-575x327.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-1150x655.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-640x364.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-1280x729.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-305x174.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-610x347.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-100x57.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-200x114.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-335x191.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-670x381.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22.png 1600w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-1024x583.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-300x171.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-768x437.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-1536x875.png 1536w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-700x399.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-1400x797.png 1400w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-480x273.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-960x547.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-60x34.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-120x68.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-70x40.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-140x80.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-160x91.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-320x182.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-850x484.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-1240x706.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-575x327.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-1150x655.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-640x364.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-1280x729.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-305x174.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-610x347.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-100x57.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-200x114.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-335x191.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22-670x381.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors22.png 1600w"><figcaption>Our complementary colors in <a href="https://color.adobe.com/create/color-wheel" target="_blank" rel="noopener">Adobe Color</a></figcaption></figure>



<p>Our colors are opposite each other on the color wheel, so they’re clearly complementary. Yay! But they’re also unusable: The two oranges are way too similar. And everything looks so… bright.</p>



<p>There’s where we need to change the saturation and lightness:</p>



<h4 id="3">Use saturation and lightness to make your hues work</h4>



<figure><img width="1024" height="436" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-1024x436.png" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-1024x436.png" alt="" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-1024x436.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-300x128.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-768x327.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-700x298.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-480x204.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-960x409.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-60x26.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-120x51.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-70x30.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-140x60.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-160x68.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-320x136.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-850x362.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-1240x528.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-575x245.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-1150x490.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-640x273.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-1280x545.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-305x130.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-610x260.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-100x43.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-200x85.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-335x143.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-670x285.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27.png 1324w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-1024x436.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-300x128.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-768x327.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-700x298.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-480x204.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-960x409.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-60x26.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-120x51.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-70x30.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-140x60.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-160x68.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-320x136.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-850x362.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-1240x528.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-575x245.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-1150x490.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-640x273.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-1280x545.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-305x130.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-610x260.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-100x43.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-200x85.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-335x143.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27-670x285.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors27.png 1324w"></figure>



<p>Saturation and brightness are as important as hue. In fact, you can create new colors when you change just the saturation and brightness. Here are two color pairs with the same hue, just different saturation and lightness: <span>⬤</span><span>⬤</span> / <span>⬤</span><span>⬤</span>. (If you change the hue just a tiny bit, you’ll achieve even better results: <span>⬤</span><span>⬤</span> / <span>⬤</span><span>⬤</span>.)</p>



<p>Let’s come back to our color combination: <span>⬤</span><span>⬤</span><span>⬤</span><span>⬤</span>. After playing around with the saturation and darkness, it becomes this:</p>







<p>I desaturated the light blue <span>⬤</span> and the lighter orange <span>⬤</span> and made every color darker except the lighter orange. Heck yeah, we can work with that!</p>



<p>So if your color combination doesn’t look awesome yet, don’t immediately add another hue. <strong>Change the saturation and lightness first and see if that’s better.</strong></p>



<p>That’s what I did to all of these color palettes: <span>⬤</span><span>⬤</span><span>⬤</span><span>⬤</span> and <span>⬤</span><span>⬤</span><span>⬤</span><span>⬤</span><span>⬤</span> and <span>⬤</span><span>⬤</span><span>⬤</span><span>⬤</span>. They’re all roughly complementary, and they all come with different saturations and lightness. That’s what makes them work.</p>



<h4 id="4">Use warm colors &amp; blue</h4>



<figure><img width="1024" height="435" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-1024x435.png" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-1024x435.png" alt="" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-1024x435.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-300x128.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-768x327.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-700x298.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-480x204.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-960x408.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-60x26.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-120x51.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-70x30.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-140x60.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-160x68.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-320x136.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-850x361.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-1240x527.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-575x245.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-1150x489.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-640x272.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-1280x544.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-305x130.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-610x259.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-100x43.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-200x85.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-335x142.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-670x285.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29.png 1324w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-1024x435.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-300x128.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-768x327.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-700x298.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-480x204.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-960x408.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-60x26.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-120x51.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-70x30.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-140x60.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-160x68.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-320x136.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-850x361.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-1240x527.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-575x245.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-1150x489.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-640x272.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-1280x544.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-305x130.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-610x259.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-100x43.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-200x85.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-335x142.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29-670x285.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors29.png 1324w"></figure>



<p>There’s a complementary color combination that is especially loved by data visualization designers: <strong>yellow/orange/red and blue</strong>. Scroll through graphics portfolios like this one from the <a href="https://multimedia.scmp.com/culture/article/SCMP-printed-graphics-memory/" target="_blank" rel="noopener">South China Morning Post</a> or this one by <a href="https://infographics.economist.com/2019/AChristmasGiftForYou/AYearInGraphicDetail.pdf" target="_blank" rel="noopener">The Economist (PDF)</a>, and you’ll notice that they use these colors far more often than colors like purple or green.</p>



<figure><img width="1024" height="571" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-1024x571.png" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-1024x571.png" alt="" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-1024x571.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-300x167.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-768x428.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-1536x856.png 1536w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-700x390.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-1400x781.png 1400w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-480x268.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-960x535.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-60x33.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-120x67.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-70x39.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-140x78.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-160x89.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-320x178.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-850x474.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-1240x691.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-575x321.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-1150x641.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-640x357.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-1280x714.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-305x170.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-610x340.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-100x56.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-200x112.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-335x187.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-670x374.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19.png 1600w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-1024x571.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-300x167.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-768x428.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-1536x856.png 1536w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-700x390.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-1400x781.png 1400w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-480x268.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-960x535.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-60x33.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-120x67.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-70x39.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-140x78.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-160x89.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-320x178.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-850x474.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-1240x691.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-575x321.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-1150x641.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-640x357.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-1280x714.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-305x170.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-610x340.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-100x56.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-200x112.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-335x187.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19-670x374.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors19.png 1600w"><figcaption><a href="https://multimedia.scmp.com/culture/article/SCMP-printed-graphics-memory/" target="_blank" rel="noopener">Three pages by The South China Morning Post</a></figcaption></figure>



<p>That’s because these warm colors and blue are super versatile for categories. Yellow and orange and red look very pleasing together, but people will still perceive them as different: <span>⬤</span><span>⬤</span><span>⬤</span> —&nbsp;which is exactly what we want for categorical colors. And blue is more flexible than any other hue. Lots of blues, no matter if dark <span>⬤</span> or light <span>⬤</span> or saturated <span>⬤</span> or not saturated <span>⬤</span>, look pleasing, calming, and professional.</p>



<p>And they are accessible: colorblind people can easily distinguish blue and orange/red from each other.</p>



<p>So when in doubt, use an orange/red with blue.</p>



<h4 id="5">When using green, make it a yellow or blue one</h4>



<figure><img width="1024" height="436" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-1024x436.png" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-1024x436.png" alt="" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-1024x436.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-300x128.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-768x327.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-700x298.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-480x204.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-960x409.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-60x26.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-120x51.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-70x30.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-140x60.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-160x68.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-320x136.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-850x362.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-1240x528.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-575x245.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-1150x490.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-640x273.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-1280x545.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-305x130.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-610x260.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-100x43.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-200x85.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-335x143.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-670x285.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26.png 1324w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-1024x436.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-300x128.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-768x327.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-700x298.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-480x204.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-960x409.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-60x26.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-120x51.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-70x30.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-140x60.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-160x68.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-320x136.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-850x362.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-1240x528.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-575x245.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-1150x490.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-640x273.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-1280x545.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-305x130.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-610x260.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-100x43.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-200x85.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-335x143.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26-670x285.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors26.png 1324w"></figure>



<p>Forest green covers a full sixth of the color wheel, from approximately 90° <span>⬤</span> to 150° <span>⬤</span>, with 120° as its peak <span>⬤</span>. However, you will find few well-designed visualizations that use it. Why is that?</p>



<p>First, forest green is just very dark. And lightening the forest green means going into an awkward neon <span>⬤</span>. So you need to lighten <em>and</em> desaturate green enormously — more than other color —&nbsp;to get to a nice one. That’s exactly what the Washington Post does with their green <span>⬤</span> here: </p>



<figure><img width="1024" height="226" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-1024x226.png" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-1024x226.png" alt="" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-1024x226.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-300x66.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-768x169.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-1536x339.png 1536w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-700x154.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-1400x309.png 1400w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-480x106.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-960x212.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-60x13.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-120x26.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-70x15.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-140x31.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-160x35.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-320x71.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-850x188.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-1240x274.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-575x127.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-1150x254.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-640x141.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-1280x282.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-305x67.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-610x135.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-100x22.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-200x44.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-335x74.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-670x148.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17.png 1600w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-1024x226.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-300x66.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-768x169.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-1536x339.png 1536w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-700x154.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-1400x309.png 1400w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-480x106.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-960x212.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-60x13.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-120x26.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-70x15.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-140x31.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-160x35.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-320x71.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-850x188.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-1240x274.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-575x127.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-1150x254.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-640x141.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-1280x282.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-305x67.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-610x135.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-100x22.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-200x44.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-335x74.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17-670x148.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors17.png 1600w"><figcaption><a href="https://www.washingtonpost.com/graphics/politics/trump-rolling-back-obama-rules/" target="_blank" rel="noopener">How Trump is rolling back Obama’s legacy</a> in The Washington Post</figcaption></figure>



<p>It’s a 142° green, but only 14% saturated. Here’s what the same hue with the same brightness would look like 100% saturated: <span>⬤</span>. Yikes.</p>



<p>And remember our colorblind friends: A pure green in combination with red, orange, or brown is hard for them to distinguish.</p>



<p>So when using green, make it a bit yellow or a bit blue. You can see this in the examples at the top of this article: All of the greens except FiveThirtyEight’s <span>⬤</span> have a hue greater than 160° (= bluer) <span>⬤</span><span>⬤</span><span>⬤</span> or less than 60° (= more yellow) <span>⬤</span><span>⬤</span>. Nadieh uses both yellow-green and blue-green in this project we’ve already seen:</p>



<figure><img width="1024" height="481" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-1024x481.png" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-1024x481.png" alt="" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-1024x481.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-300x141.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-768x360.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-1536x721.png 1536w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-700x329.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-1400x657.png 1400w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-480x225.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-960x451.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-60x28.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-120x56.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-70x33.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-140x66.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-160x75.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-320x150.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-850x399.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-1240x582.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-575x270.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-1150x540.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-640x300.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-1280x601.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-305x143.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-610x286.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-100x47.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-200x94.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-335x157.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-670x314.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2.png 1600w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-1024x481.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-300x141.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-768x360.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-1536x721.png 1536w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-700x329.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-1400x657.png 1400w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-480x225.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-960x451.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-60x28.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-120x56.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-70x33.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-140x66.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-160x75.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-320x150.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-850x399.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-1240x582.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-575x270.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-1150x540.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-640x300.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-1280x601.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-305x143.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-610x286.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-100x47.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-200x94.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-335x157.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2-670x314.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors13-2.png 1600w"></figure>



<p>Looks like you can use them in your visualization as two different colors, as Nadieh does: Win-win!</p>



<h4 id="6">Avoid pure colors</h4>



<figure><img width="1024" height="435" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-1024x435.png" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-1024x435.png" alt="" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-1024x435.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-300x128.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-768x327.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-700x298.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-480x204.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-960x408.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-60x26.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-120x51.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-70x30.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-140x60.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-160x68.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-320x136.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-850x361.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-1240x527.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-575x245.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-1150x489.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-640x272.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-1280x544.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-305x130.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-610x259.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-100x43.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-200x85.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-335x142.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-670x285.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5.png 1324w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-1024x435.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-300x128.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-768x327.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-700x298.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-480x204.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-960x408.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-60x26.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-120x51.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-70x30.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-140x60.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-160x68.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-320x136.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-850x361.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-1240x527.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-575x245.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-1150x489.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-640x272.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-1280x544.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-305x130.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-610x259.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-100x43.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-200x85.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-335x142.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5-670x285.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors5.png 1324w"></figure>



<p>“Pure” hues are the ones that are located at exactly 60°, 120°, 180°, 240°, 300°, or 360°/0° in the color wheel:</p>



<figure><img width="1024" height="796" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-1024x796.png" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-1024x796.png" alt="" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-1024x796.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-300x233.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-768x597.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-700x544.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-480x373.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-960x746.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-60x47.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-120x93.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-70x54.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-140x109.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-160x124.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-320x249.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-850x661.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-1240x964.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-575x447.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-1150x894.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-640x497.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-1280x995.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-305x237.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-610x474.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-100x78.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-200x155.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-335x260.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-670x521.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7.png 1324w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-1024x796.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-300x233.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-768x597.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-700x544.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-480x373.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-960x746.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-60x47.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-120x93.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-70x54.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-140x109.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-160x124.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-320x249.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-850x661.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-1240x964.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-575x447.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-1150x894.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-640x497.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-1280x995.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-305x237.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-610x474.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-100x78.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-200x155.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-335x260.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7-670x521.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors7.png 1324w"></figure>



<p>Here’s an example: In HSV/HSB, the <strong>H</strong>ue value of this bright blue <span>⬤</span> is 180°, the <strong>S</strong>aturation value is 67%, and the <strong>L</strong>ightness value is 91%. You can also check the RGB values of your color: If at least two of the values are the same, they’re “pure”. For example, our <span>⬤</span> is a <code>rgb(77, 232, 232)</code>.</p>



<p>To make your colors look more natural and pleasing to your readers’ eyes, you can either tone down the saturation of pure colors or make them darker. <strong>If you want to have bright, saturated colors, rely on mixed colors</strong> at least 5-10° away from the pure hues.</p>



<p>In the image above, the red and orange, the blues and the greens have the same saturation and lightness. The only difference is the hue: The red <span>⬤</span> (0°), blue <span>⬤</span> (240°), and green <span>⬤</span> (120°) look more colorful than the orange <span>⬤</span> (40°), medium blue <span>⬤</span> (211°), and blue-ish green <span>⬤</span> (170°).</p>



<h4 id="7">Avoid bright, saturated colors</h4>



<figure><img width="1024" height="436" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-1024x436.png" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-1024x436.png" alt="" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-1024x436.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-300x128.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-768x327.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-700x298.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-480x204.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-960x409.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-60x26.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-120x51.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-70x30.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-140x60.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-160x68.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-320x136.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-850x362.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-1240x528.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-575x245.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-1150x490.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-640x273.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-1280x545.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-305x130.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-610x260.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-100x43.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-200x85.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-335x143.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-670x285.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4.png 1324w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-1024x436.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-300x128.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-768x327.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-700x298.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-480x204.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-960x409.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-60x26.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-120x51.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-70x30.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-140x60.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-160x68.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-320x136.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-850x362.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-1240x528.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-575x245.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-1150x490.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-640x273.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-1280x545.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-305x130.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-610x260.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-100x43.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-200x85.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-335x143.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4-670x285.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors4.png 1324w"></figure>



<p>Neon colors will definitely attract the attention of readers. But these readers won’t thank you. Most of us get a bit stressed out when we see them: “Highly saturated, light colors will NOT be appropriate [to communicate] Serious or Trust, or Calm,” researchers Bartram, Patra, and Stone explain in their paper “Affective Color in Visualization” from 2017 (<a href="https://research.tableau.com/sites/default/files/Affective%20Color%20CHI%202017.pdf" target="_blank" rel="noopener">PDF</a>).</p>



<p>If your colors come close to 100% saturation <strong>and</strong> 100% brightness, it’s likely your colors are too colorful. That’s definitely the case for pure colors like <span>⬤</span><span>⬤</span><span>⬤</span><span>⬤</span>.</p>



<p>“But I’ve seen such crazy colors before, and they look good,” you might say, and refer to projects like these:</p>



<figure><img width="1024" height="313" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-1024x313.png" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-1024x313.png" alt="" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-1024x313.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-300x92.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-768x235.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-1536x469.png 1536w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-700x214.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-1400x428.png 1400w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-480x147.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-960x293.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-60x18.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-120x37.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-70x21.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-140x43.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-160x49.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-320x98.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-850x260.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-1240x379.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-575x176.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-1150x351.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-640x196.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-1280x391.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-305x93.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-610x186.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-100x31.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-200x61.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-335x102.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-670x205.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1.png 1600w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-1024x313.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-300x92.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-768x235.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-1536x469.png 1536w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-700x214.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-1400x428.png 1400w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-480x147.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-960x293.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-60x18.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-120x37.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-70x21.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-140x43.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-160x49.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-320x98.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-850x260.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-1240x379.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-575x176.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-1150x351.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-640x196.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-1280x391.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-305x93.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-610x186.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-100x31.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-200x61.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-335x102.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1-670x205.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors3-1.png 1600w"><figcaption><a href="https://www.nytimes.com/interactive/2019/08/19/us/politics/presidential-campaign-songs-playlists.html" target="_blank" rel="noopener">New York Times article</a> on music playlists</figcaption></figure>



<figure><img width="1024" height="349" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-1024x349.png" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-1024x349.png" alt="" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-1024x349.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-300x102.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-768x262.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-1536x523.png 1536w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-700x238.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-1400x477.png 1400w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-480x164.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-960x327.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-60x20.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-120x41.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-70x24.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-140x48.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-160x55.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-320x109.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-850x290.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-1240x422.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-575x196.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-1150x392.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-640x218.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-1280x436.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-305x104.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-610x208.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-100x34.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-200x68.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-335x114.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-670x228.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2.png 1600w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-1024x349.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-300x102.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-768x262.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-1536x523.png 1536w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-700x238.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-1400x477.png 1400w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-480x164.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-960x327.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-60x20.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-120x41.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-70x24.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-140x48.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-160x55.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-320x109.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-850x290.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-1240x422.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-575x196.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-1150x392.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-640x218.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-1280x436.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-305x104.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-610x208.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-100x34.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-200x68.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-335x114.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2-670x228.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors2.png 1600w"><figcaption><a href="https://www.bloomberg.com./graphics/2020-us-bankruptcies-coronavirus/?srnd=graphics-v2" target="_blank" rel="noopener">Bloomberg article</a> on bankruptcies</figcaption></figure>



<figure><img width="1024" height="104" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-1024x104.png" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-1024x104.png" alt="" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-1024x104.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-300x31.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-768x78.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-1536x156.png 1536w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-700x71.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-1400x143.png 1400w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-480x49.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-960x98.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-60x6.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-120x12.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-70x7.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-140x14.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-160x16.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-320x33.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-850x87.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-1240x126.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-575x59.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-1150x117.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-640x65.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-1280x130.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-305x31.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-610x62.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-100x10.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-200x20.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-335x34.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-670x68.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1.png 1600w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-1024x104.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-300x31.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-768x78.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-1536x156.png 1536w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-700x71.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-1400x143.png 1400w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-480x49.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-960x98.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-60x6.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-120x12.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-70x7.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-140x14.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-160x16.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-320x33.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-850x87.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-1240x126.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-575x59.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-1150x117.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-640x65.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-1280x130.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-305x31.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-610x62.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-100x10.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-200x20.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-335x34.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1-670x68.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors1.png 1600w"><figcaption><a href="https://pudding.cool/2018/09/wiki-billboard/" target="_blank" rel="noopener">The Pudding article</a> on celebrities</figcaption></figure>



<p>But if you compare the colors from these examples with colors like <span>⬤</span><span>⬤</span><span>⬤</span><span>⬤</span>, you see how the former ones are all less saturated or darker. A 100% saturated and 100% bright green <span>⬤</span> becomes less saturated in the New York Times <span>⬤</span>, and less saturated <em>and</em> darker in both the Bloomberg article <span>⬤</span> and the Pudding article <span>⬤</span>. </p>



<p>They have the same fun, attention-grabbing effect as neon colors have, while being easier on the eye.</p>



<p>This works more or less because the people at The Pudding, The New York Times, and Bloomberg are great designers. <strong>When in doubt, avoid 100% saturation combined with 100% lightness.</strong></p>



<h4 id="8">Combine colors with different lightness</h4>



<figure><img width="1024" height="436" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-1024x436.png" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-1024x436.png" alt="" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-1024x436.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-300x128.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-768x327.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-700x298.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-480x204.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-960x409.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-60x26.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-120x51.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-70x30.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-140x60.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-160x68.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-320x136.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-850x362.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-1240x528.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-575x245.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-1150x490.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-640x273.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-1280x545.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-305x130.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-610x260.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-100x43.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-200x85.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-335x143.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-670x285.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11.png 1324w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-1024x436.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-300x128.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-768x327.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-700x298.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-480x204.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-960x409.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-60x26.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-120x51.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-70x30.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-140x60.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-160x68.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-320x136.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-850x362.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-1240x528.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-575x245.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-1150x490.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-640x273.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-1280x545.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-305x130.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-610x260.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-100x43.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-200x85.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-335x143.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11-670x285.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors11.png 1324w"></figure>



<p>I sometimes see charts —&nbsp;especially area charts —&nbsp;where neighboring elements have the same lightness. You can easily check this: Just convert your colors to black &amp; white (e.g., with an external colorblindness simulator or with our <a href="https://twitter.com/Datawrapper/status/1298293123584536578" target="_blank" rel="noopener">Datawrapper colorblind check</a>). If they all have the same gray, they’re the same lightness.</p>



<p>For example, the <span>⬤</span><span>⬤</span><span>⬤</span> from the far left chart look like <span>⬤</span><span>⬤</span><span>⬤</span> in grayscale.</p>



<p>To avoid that dull and eye-hurting experience, you have two options:</p>



<ul><li>“Get it right in black &amp; white”: change the darkness of each area, making some brighter and some darker, like so: <span>⬤</span><span>⬤</span><span>⬤</span>. They look like this in grayscale: <span>⬤</span><span>⬤</span><span>⬤</span></li><li>Separate the areas, e.g., with a white border</li></ul>



<p>I highly recommend the first option (you can still put a white border around it if you like the style): The colors will look more dynamic, and colorblind people will thank you. Actually, everyone will thank you, regardless of their color-seeing abilities.</p>



<p>In fact, a valid way to pick colors for categorical data is to pick colors from gradients like these ones:</p>



<figure><img width="1024" height="246" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-1024x246.png" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-1024x246.png" alt="" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-1024x246.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-300x72.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-768x185.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-700x168.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-480x115.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-960x231.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-60x14.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-120x29.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-70x17.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-140x34.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-160x38.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-320x77.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-850x204.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-1240x298.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-575x138.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-1150x277.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-640x154.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-1280x308.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-305x73.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-610x147.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-100x24.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-200x48.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-335x81.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-670x161.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3.png 1289w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-1024x246.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-300x72.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-768x185.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-700x168.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-480x115.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-960x231.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-60x14.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-120x29.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-70x17.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-140x34.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-160x38.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-320x77.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-850x204.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-1240x298.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-575x138.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-1150x277.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-640x154.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-1280x308.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-305x73.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-610x147.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-100x24.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-200x48.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-335x81.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3-670x161.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200630_colorblind3.png 1289w"><figcaption><a href="https://bids.github.io/colormap/" target="_blank" rel="noopener">Viridis</a> color schemes</figcaption></figure>



<p>All these gradients move smoothly from light to dark, so colors you pick from there will all have a different lightness: <span>⬤</span><span>⬤</span><span>⬤</span><span>⬤</span><span>⬤</span> or <span>⬤</span><span>⬤</span><span>⬤</span><span>⬤</span><span>⬤</span>. Try this <a href="https://learnui.design/tools/data-color-picker.html" target="_blank" rel="noopener">Color Palette Generator</a> if you’re a fan of that approach.</p>



<h4 id="9">Make your colors similarly “colorful”</h4>



<figure><img width="1024" height="435" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-1024x435.png" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-1024x435.png" alt="" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-1024x435.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-300x128.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-768x327.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-700x298.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-480x204.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-960x408.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-60x26.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-120x51.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-70x30.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-140x60.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-160x68.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-320x136.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-850x361.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-1240x527.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-575x245.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-1150x489.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-640x272.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-1280x544.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-305x130.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-610x259.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-100x43.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-200x85.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-335x142.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-670x285.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32.png 1324w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-1024x435.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-300x128.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-768x327.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-700x298.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-480x204.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-960x408.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-60x26.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-120x51.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-70x30.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-140x60.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-160x68.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-320x136.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-850x361.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-1240x527.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-575x245.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-1150x489.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-640x272.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-1280x544.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-305x130.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-610x259.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-100x43.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-200x85.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-335x142.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32-670x285.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors32.png 1324w"></figure>



<p>In your visualizations, you often want colors to stand out. There are different ways to achieve that. Colors stand out:</p>



<ul><li>because they’re way darker <span>⬤</span><span>⬤</span> </li><li>because they’re way lighter <span>⬤</span><span>⬤</span></li><li>because they’re more saturated <span>⬤</span><span>⬤</span></li><li>because they’re more “pure” <span>⬤</span><span>⬤</span></li></ul>



<p>But you usually just want one or two colors to stand out. Most of your colors are supposed to be <strong>more or less equally attention-grabbing</strong>.</p>



<p>If you’re using colors with different lightness (“Get it right in black &amp; white”), you’ll need to balance them out. <strong>Try to desaturate bright colors. Put more saturation in dark colors.</strong></p>



<p>Or choose a less pure hue: in the image above, the green <span>⬤</span> and blue <span>⬤</span> are very pure, so I darkened them. (Here’s how they look with 100% brightness: <span>⬤</span><span>⬤</span>.)</p>



<p>I then wanted to bring a red in… but the bright red would have been too intense as a pure hue (at 0°) <span>⬤</span><span>⬤</span><span>⬤</span>. So I had two options:</p>



<ol><li>simply darken it: <span>⬤</span><span>⬤</span><span>⬤</span>.</li><li>move the hue (and just the hue) to 30° to make it more orange <span>⬤</span><span>⬤</span><span>⬤</span>.</li></ol>



<p>I chose the second option to make it look a bit more friendly. But both options work.</p>



<h4 id="10">Avoid too little contrast with the background</h4>



<figure><img width="1024" height="435" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-1024x435.png" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-1024x435.png" alt="" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-1024x435.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-300x128.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-768x327.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-700x298.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-480x204.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-960x408.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-60x26.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-120x51.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-70x30.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-140x60.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-160x68.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-320x136.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-850x361.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-1240x527.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-575x245.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-1150x489.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-640x272.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-1280x544.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-305x130.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-610x259.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-100x43.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-200x85.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-335x142.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-670x285.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8.png 1324w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-1024x435.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-300x128.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-768x327.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-700x298.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-480x204.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-960x408.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-60x26.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-120x51.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-70x30.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-140x60.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-160x68.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-320x136.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-850x361.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-1240x527.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-575x245.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-1150x489.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-640x272.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-1280x544.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-305x130.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-610x259.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-100x43.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-200x85.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-335x142.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8-670x285.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors8.png 1324w"></figure>



<p>A surprising number of charts on bright backgrounds use very pastel-ish colors. They’re often not very saturated, and awfully light.</p>



<p>That comes with problems: If you work with small areas like lines and dots, light and desaturated colors can be hard for your readers to distinguish. But even if legibility is not an issue —&nbsp;e.g. for bigger areas — your visualizations should have enough visual contrast with the background to confidently communicate: “Hey, I’m here, and I have something to say.”</p>



<p>Here’s what to do when your colors are too desaturated and light <span>⬤</span><span>⬤</span><span>⬤</span>:</p>



<ul><li>Increase the saturation: <span>⬤</span><span>⬤</span><span>⬤</span></li><li>Make them darker: <span>⬤</span><span>⬤</span><span>⬤</span></li><li>Or do both for the best result: <span>⬤</span><span>⬤</span><span>⬤</span></li></ul>



<p>Of course, that’s also a matter of taste. But if you’re not sure if your colors are too pastel-ish, simply try to make them more saturated and darker. Just see how it feels. And if it feels good, keep it.</p>



<h4 id="11">Avoid too much contrast with the background</h4>



<figure><img width="1024" height="436" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-1024x436.png" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-1024x436.png" alt="" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-1024x436.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-300x128.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-768x327.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-700x298.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-480x204.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-960x409.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-60x26.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-120x51.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-70x30.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-140x60.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-160x68.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-320x136.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-850x362.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-1240x528.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-575x245.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-1150x490.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-640x273.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-1280x545.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-305x130.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-610x260.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-100x43.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-200x85.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-335x143.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-670x285.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9.png 1324w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-1024x436.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-300x128.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-768x327.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-700x298.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-480x204.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-960x409.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-60x26.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-120x51.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-70x30.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-140x60.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-160x68.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-320x136.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-850x362.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-1240x528.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-575x245.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-1150x490.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-640x273.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-1280x545.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-305x130.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-610x260.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-100x43.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-200x85.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-335x143.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9-670x285.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors9.png 1324w"></figure>



<p>The opposite is true, too: Don’t make your colors too dark and saturated when you’re using a bright background. If in doubt, try it out. Make your colors lighter, pull some saturation out of them and see how it feels.</p>



<h4 id="12">Choose a background that’s desaturated enough</h4>



<figure><img width="1024" height="529" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-1024x529.png" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-1024x529.png" alt="" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-1024x529.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-300x155.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-768x397.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-700x362.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-480x248.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-960x496.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-60x31.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-120x62.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-70x36.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-140x72.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-160x83.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-320x165.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-850x439.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-1240x641.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-575x297.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-1150x594.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-640x331.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-1280x661.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-305x158.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-610x315.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-100x52.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-200x103.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-335x173.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-670x346.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1.png 1324w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-1024x529.png 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-300x155.png 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-768x397.png 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-700x362.png 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-480x248.png 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-960x496.png 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-60x31.png 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-120x62.png 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-70x36.png 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-140x72.png 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-160x83.png 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-320x165.png 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-850x439.png 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-1240x641.png 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-575x297.png 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-1150x594.png 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-640x331.png 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-1280x661.png 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-305x158.png 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-610x315.png 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-100x52.png 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-200x103.png 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-335x173.png 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1-670x346.png 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors10-1.png 1324w"></figure>



<p>Once you become more confident with colors, colorful backgrounds can seem like a good idea. But they come with two big drawbacks: First, they easily distract from your data. Second, they’re limiting your potential color palette and are therefore hard to work with. In fact, the more saturated your background, the harder it gets —&nbsp;so desaturated colors are your best bet. Here are some rules of thumbs for the HSB/HSV color space:</p>



<ul><li>If you want a light background, stay away from colors below 95% lightness and above 7% saturation.</li><li>If you want a dark background, stay below 20% saturation. Also, <a href="https://ianstormtaylor.com/design-tip-never-use-black/" target="_blank" rel="noopener">don’t go full black</a> —&nbsp;keep your lightness between 10% and 25%.</li></ul>



<h4 id="13">Copy colors, or understand them</h4>



<p>Picking good colors is hard. It’s totally ok to be bad with colors, to keep being bad with colors, and to just copy colors. Seriously, there’s no shame in stealing. <a href="https://blog.datawrapper.de/colorguide/"><strong>I wrote a whole article</strong></a> about where to get inspiration for colors: From movies, artists, color palettes others have created, etc. (And may I add: Other data visualizations are an excellent source.)</p>



<p>If you do want to build a better intuitive understanding of which colors fit well together, try this: Analyze them. Some ways to do that include:</p>



<figure><img width="1024" height="808" src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-1024x808.jpg" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-1024x808.jpg" alt="photo of a tree" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-1024x808.jpg 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-300x237.jpg 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-768x606.jpg 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-1536x1212.jpg 1536w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-700x553.jpg 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-1400x1105.jpg 1400w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-480x379.jpg 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-960x758.jpg 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-60x47.jpg 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-120x95.jpg 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-70x55.jpg 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-140x111.jpg 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-160x126.jpg 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-320x253.jpg 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-850x671.jpg 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-1240x979.jpg 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-575x454.jpg 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-1150x908.jpg 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-640x505.jpg 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-1280x1010.jpg 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-305x241.jpg 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-610x482.jpg 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-100x79.jpg 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-200x158.jpg 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-335x264.jpg 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-670x529.jpg 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1.jpg 1600w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-1024x808.jpg 1024w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-300x237.jpg 300w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-768x606.jpg 768w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-1536x1212.jpg 1536w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-700x553.jpg 700w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-1400x1105.jpg 1400w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-480x379.jpg 480w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-960x758.jpg 960w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-60x47.jpg 60w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-120x95.jpg 120w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-70x55.jpg 70w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-140x111.jpg 140w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-160x126.jpg 160w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-320x253.jpg 320w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-850x671.jpg 850w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-1240x979.jpg 1240w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-575x454.jpg 575w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-1150x908.jpg 1150w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-640x505.jpg 640w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-1280x1010.jpg 1280w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-305x241.jpg 305w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-610x482.jpg 610w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-100x79.jpg 100w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-200x158.jpg 200w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-335x264.jpg 335w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1-670x529.jpg 670w, https://blog.datawrapper.de/wp-content/uploads/2021/01/full-200805_goodcolors24-1.jpg 1600w"><figcaption>Photo by <a href="https://unsplash.com/@niko_photos" target="_blank" rel="noopener">niko photos</a> on <a href="https://unsplash.com/s/photos/tree" target="_blank" rel="noopener">Unsplash</a></figcaption></figure>



<ul><li>Select a picture with colors you consider beautiful, like an art piece or photo of nature. Then pick colors out of them with an eyedropper tool, e.g., in Photoshop or <a href="https://image-color.com/" target="_blank" rel="noopener"><strong>image-color.com</strong></a>. Try to use them in your next chart.</li><li>Install <a href="https://www.adobe.com/products/capture.html" target="_blank" rel="noopener"><strong>Adobe Capture</strong></a>, which is the same idea but for “live images”: It lets you capture colors from your environment. (It’s fascinating to see how desaturated many colors are around us!)</li><li>Play “manual color picker”: <strong>Look up your screen. Which colors do you see?</strong> How dark and how saturated are there? Which hues are close by; which ones are opposite on the color wheel?</li><li>Pick colors from beautiful data visualizations. <strong>Change a few colors.</strong> Do they still work well together?</li></ul>



<p>Also, the next time you’re creating a data visualization and you’re not happy with your colors, <strong>analyze them in the HSV/HSB color space</strong>, e.g., with <a href="http://colorizer.org/" target="_blank" rel="noopener">colorizer.org</a>:</p>



<ul><li>How <strong>saturated</strong> are they —&nbsp;and do they look better if you increase or decrease the saturation by a few (or a lot of) percentage points?</li><li>Which <strong>hue</strong> value do they have? What happens if you change the hue by just a few degrees?</li><li>Are your colors differently <strong>bright</strong>?</li></ul>



<p>With time, your understanding will move from “that’s beautiful, but I don’t know why” to “that’s beautiful, because…” And you’ll find that you can break more and more of these rules I explained here —&nbsp;and still create great color combinations.</p>



<hr>



<p><em>I hope this article was helpful! If you want to continue reading: There are quite some articles on this blog about color, e.g. about <a href="https://blog.datawrapper.de/gendercolor/">colors for gender</a>, <a href="https://blog.datawrapper.de/partycolors/">colors for political parties</a>, colorblindness (<a href="https://blog.datawrapper.de/colorblindness-part1/">part 1</a>, <a href="https://blog.datawrapper.de/colorblindness-part2/">2</a>, <a href="https://blog.datawrapper.de/colorblindness-part3/">3</a>), and <a href="https://blog.datawrapper.de/colors/">what to consider in general when using colors</a> in your visualizations. If there’s a great trick this article is missing, let me know at <a href="mailto:lisa@datawrapper.de">lisa@datawrapper.de</a> or in the comments below.</em></p>

            
            
<div>

    <hr>

    
        <div>

            <div><picture>
			
			<source media="(min-width: 575px)" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/10/20210827-D81_2273-200x200.jpg 1x, https://blog.datawrapper.de/wp-content/uploads/2021/10/20210827-D81_2273-400x400.jpg 2x">
            <source media="(min-width: 200px)" data-srcset="https://blog.datawrapper.de/wp-content/uploads/2021/10/20210827-D81_2273-100x100.jpg 1x, https://blog.datawrapper.de/wp-content/uploads/2021/10/20210827-D81_2273-200x200.jpg 2x">
            <img alt="Profile image of Lisa Muth of the Datawrapper team" data-src="https://blog.datawrapper.de/wp-content/uploads/2021/10/20210827-D81_2273-200x200.jpg" src="https://blog.datawrapper.de/wp-content/uploads/2021/10/20210827-D81_2273-200x200.jpg">
		</picture></div>

            <div>

                <p>Lisa Charlotte Muth</p>
                <p>(she/her, <a href="https://twitter.com/lisacmuth">@lisacmuth</a>, <a href="https://vis.social/@lisacmuth">@lisacmuth@vis.social</a>) is Datawrapper’s head of communications. She writes about best practices in data visualization and thinks of new ways to excite you about charts and maps. Lisa lives in Berlin.</p>

            </div>

        </div>
        

</div>




            
            
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A reality bending mistake in Apple's computational photography (319 pts)]]></title>
            <link>https://appleinsider.com/articles/23/11/30/a-bride-to-be-discovers-a-reality-bending-mistake-in-apples-computational-photography</link>
            <guid>38482085</guid>
            <pubDate>Fri, 01 Dec 2023 02:02:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://appleinsider.com/articles/23/11/30/a-bride-to-be-discovers-a-reality-bending-mistake-in-apples-computational-photography">https://appleinsider.com/articles/23/11/30/a-bride-to-be-discovers-a-reality-bending-mistake-in-apples-computational-photography</a>, See on <a href="https://news.ycombinator.com/item?id=38482085">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <div id="article-hero" aria-labelledby="hero-cap" role="figure">
                          <p id="hero-cap" title="iPhone 15">iPhone 15</p>
                        <p><a href="https://photos5.appleinsider.com/gallery/57517-117154-iPhone-15-cameras-xl.jpg">
              <img src="https://photos5.appleinsider.com/gallery/57517-117154-iPhone-15-cameras-xl.jpg" alt="">
            </a>
          </p></div>

          
          
          
                    <p>A U.K. woman was photographed standing in a mirror where her reflections didn't match, but not because of a glitch in the Matrix. Instead, it's a simple <a href="https://appleinsider.com/inside/iphone" title="iPhone" data-kpt="1">iPhone</a> computational photography mistake.
</p><p>Thanks to technological advancements, photography has come a long way from flash bulbs and film. Every time the iPhone shutter button is clicked, <a href="https://appleinsider.com/articles/23/03/16/iphone-vs-android-two-different-photography-and-machine-learning-approaches">billions of operations</a> occur in an instant that results in a photo.
</p><p>A U.K. comedian and actor named Tessa Coates was trying on wedding dresses when a shocking photo of her was taken, according to her Instagram post <a href="https://petapixel.com/2023/11/16/one-in-a-million-iphone-photo-shows-two-versions-of-the-same-woman/">shared by</a> <em>PetaPixel</em>. The photo shows Coates in a dress in front of two mirrors, but each of the three versions of her had a different pose.
</p><p>One mirror showed her with her arms down, the other mirror showed her hands joined at her waist, and her real self was standing with her left arm at her side. To anyone who doesn't know better, this could prove to be quite a shocking image.
</p><p>What's actually occurred here is a mistake in Apple's computational photography pipeline. The camera wouldn't realize it was taking a photo of a mirror, so it treated the three versions of Coates as different people.
</p><p>Coates was moving when the photo was taken, so when the shutter was pressed, many differing images were captured in that instant. Apple's algorithm stitches the photos together, choosing the best versions for saturation, contrast, detail, and lack of blur.
</p><p>The final composite image should be the best, most realistic interpretation of that moment. However, since there was a mirror present, the algorithm determined that different moments shown in each mirror were the best for that reflection. That's what resulted in three different Tessas.
</p><p>This result can be recreated on any recent iPhone and many kinds of smartphone due to the limitations of <a href="https://appleinsider.com/articles/19/10/02/inside-apples-deep-fusion-the-iphone-11-and-pros-computational-photography-feature">computational photography</a> dealing with mirrors. Younger generations have figured this phenomenon out and used it to generate silly images for social media.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Marker: Convert PDF to Markdown quickly with high accuracy (180 pts)]]></title>
            <link>https://github.com/VikParuchuri/marker</link>
            <guid>38482007</guid>
            <pubDate>Fri, 01 Dec 2023 01:53:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/VikParuchuri/marker">https://github.com/VikParuchuri/marker</a>, See on <a href="https://news.ycombinator.com/item?id=38482007">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">Marker</h2>
<p dir="auto">Marker converts PDF, EPUB, and MOBI to markdown.  It's 10x faster than nougat, more accurate on most documents, and has low hallucination risk.</p>
<ul dir="auto">
<li>Support for a range of PDF documents (optimized for books and scientific papers)</li>
<li>Removes headers/footers/other artifacts</li>
<li>Converts most equations to latex</li>
<li>Formats code blocks and tables</li>
<li>Support for multiple languages (although most testing is done in English).  See <code>settings.py</code> for a language list.</li>
<li>Works on GPU, CPU, or MPS</li>
</ul>
<h2 tabindex="-1" dir="auto">How it works</h2>
<p dir="auto">Marker is a pipeline of deep learning models:</p>
<ul dir="auto">
<li>Extract text, OCR if necessary (heuristics, tesseract)</li>
<li>Detect page layout (<a href="https://huggingface.co/vikp/layout_segmenter" rel="nofollow">layout segmenter</a>, <a href="https://huggingface.co/vikp/column_detector" rel="nofollow">column detector</a>)</li>
<li>Clean and format each block (heuristics, <a href="https://huggingface.co/facebook/nougat-base" rel="nofollow">nougat</a>)</li>
<li>Combine blocks and postprocess complete text (heuristics, <a href="https://huggingface.co/vikp/pdf_postprocessor_t5" rel="nofollow">pdf_postprocessor</a>)</li>
</ul>
<p dir="auto">Relying on autoregressive forward passes to generate text is slow and prone to hallucination/repetition.  From the nougat paper: <code>We observed [repetition] in 1.5% of pages in the test set, but the frequency increases for out-of-domain documents.</code>  In my anecdotal testing, repetitions happen on 5%+ of out-of-domain (non-arXiv) pages.</p>
<p dir="auto">Nougat is an amazing model, but I wanted a faster and more general purpose solution. Marker is 10x faster and has low hallucination risk because it only passes equation blocks through an LLM forward pass.</p>
<h2 tabindex="-1" dir="auto">Examples</h2>
<table>
<thead>
<tr>
<th>PDF</th>
<th>Type</th>
<th>Marker</th>
<th>Nougat</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://greenteapress.com/thinkpython/thinkpython.pdf" rel="nofollow">Think Python</a></td>
<td>Textbook</td>
<td><a href="https://github.com/VikParuchuri/marker/blob/master/data/examples/marker/thinkpython.md">View</a></td>
<td><a href="https://github.com/VikParuchuri/marker/blob/master/data/examples/nougat/thinkpython.md">View</a></td>
</tr>
<tr>
<td><a href="https://greenteapress.com/thinkos/thinkos.pdf" rel="nofollow">Think OS</a></td>
<td>Textbook</td>
<td><a href="https://github.com/VikParuchuri/marker/blob/master/data/examples/marker/thinkos.md">View</a></td>
<td><a href="https://github.com/VikParuchuri/marker/blob/master/data/examples/nougat/thinkos.md">View</a></td>
</tr>
<tr>
<td><a href="https://arxiv.org/pdf/2101.03961.pdf" rel="nofollow">Switch Transformers</a></td>
<td>arXiv paper</td>
<td><a href="https://github.com/VikParuchuri/marker/blob/master/data/examples/marker/switch_transformers.md">View</a></td>
<td><a href="https://github.com/VikParuchuri/marker/blob/master/data/examples/nougat/switch_transformers.md">View</a></td>
</tr>
<tr>
<td><a href="https://arxiv.org/pdf/1804.07821.pdf" rel="nofollow">Multi-column CNN</a></td>
<td>arXiv paper</td>
<td><a href="https://github.com/VikParuchuri/marker/blob/master/data/examples/marker/multicolcnn.md">View</a></td>
<td><a href="https://github.com/VikParuchuri/marker/blob/master/data/examples/nougat/multicolcnn.md">View</a></td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">Performance</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/VikParuchuri/marker/blob/master/data/images/overall.png"><img src="https://github.com/VikParuchuri/marker/raw/master/data/images/overall.png" alt="Benchmark overall"></a></p>
<p dir="auto">The above results are with marker and nougat setup so they each take ~3GB of VRAM on an A6000.</p>
<p dir="auto">See <a href="#benchmarks">below</a> for detailed speed and accuracy benchmarks, and instructions on how to run your own benchmarks.</p>
<h2 tabindex="-1" dir="auto">Installation</h2>
<p dir="auto">This has been tested on Mac and Linux (Ubuntu and Debian).  You'll need python 3.9+ and <a href="https://python-poetry.org/docs/#installing-with-the-official-installer" rel="nofollow">poetry</a>.</p>
<p dir="auto">First, clone the repo:</p>
<ul dir="auto">
<li><code>git clone https://github.com/VikParuchuri/marker.git</code></li>
<li><code>cd marker</code></li>
</ul>
<h2 tabindex="-1" dir="auto">Linux</h2>
<ul dir="auto">
<li>Install system requirements
<ul dir="auto">
<li>Optional: Install tesseract 5 by following <a href="https://notesalexp.org/tesseract-ocr/html/" rel="nofollow">these instructions</a> or running <code>scripts/install/tesseract_5_install.sh</code>.</li>
<li>Install ghostscript &gt; 9.55 by following <a href="https://ghostscript.readthedocs.io/en/latest/Install.html" rel="nofollow">these instructions</a> or running <code>scripts/install/ghostscript_install.sh</code>.</li>
<li>Install other requirements with <code>cat scripts/install/apt-requirements.txt | xargs sudo apt-get install -y</code></li>
</ul>
</li>
<li>Set the tesseract data folder path
<ul dir="auto">
<li>Find the tesseract data folder <code>tessdata</code> with <code>find / -name tessdata</code>.  Make sure to use the one corresponding to the latest tesseract version if you have multiple.</li>
<li>Create a <code>local.env</code> file in the root <code>marker</code> folder with <code>TESSDATA_PREFIX=/path/to/tessdata</code> inside it</li>
</ul>
</li>
<li>Install python requirements
<ul dir="auto">
<li><code>poetry install</code></li>
<li><code>poetry shell</code> to activate your poetry venv</li>
</ul>
</li>
<li>Update pytorch since poetry doesn't play nicely with it
<ul dir="auto">
<li>GPU only: run <code>pip install torch</code> to install other torch dependencies.</li>
<li>CPU only: Uninstall torch, then follow the <a href="https://pytorch.org/get-started/locally/" rel="nofollow">CPU install</a> instructions.</li>
</ul>
</li>
</ul>
<h2 tabindex="-1" dir="auto">Mac</h2>
<ul dir="auto">
<li>Install system requirements from <code>scripts/install/brew-requirements.txt</code></li>
<li>Set the tesseract data folder path
<ul dir="auto">
<li>Find the tesseract data folder <code>tessdata</code> with <code>brew list tesseract</code></li>
<li>Create a <code>local.env</code> file in the root <code>marker</code> folder with <code>TESSDATA_PREFIX=/path/to/tessdata</code> inside it</li>
</ul>
</li>
<li>Install python requirements
<ul dir="auto">
<li><code>poetry install</code></li>
<li><code>poetry shell</code> to activate your poetry venv</li>
</ul>
</li>
</ul>
<h2 tabindex="-1" dir="auto">Usage</h2>
<p dir="auto">First, some configuration:</p>
<ul dir="auto">
<li>Set your torch device in the <code>local.env</code> file.  For example, <code>TORCH_DEVICE=cuda</code> or <code>TORCH_DEVICE=mps</code>.  <code>cpu</code> is the default.
<ul dir="auto">
<li>If using GPU, set <code>INFERENCE_RAM</code> to your GPU VRAM (per GPU).  For example, if you have 16 GB of VRAM, set <code>INFERENCE_RAM=16</code>.</li>
<li>Depending on your document types, marker's average memory usage per task can vary slightly.  You can configure <code>VRAM_PER_TASK</code> to adjust this if you notice tasks failing with GPU out of memory errors.</li>
</ul>
</li>
<li>By default, the final editor model is off.  Turn it on with <code>ENABLE_EDITOR_MODEL</code>.</li>
<li>Inspect the settings in <code>marker/settings.py</code>.  You can override any settings in the <code>local.env</code> file, or by setting environment variables.</li>
</ul>
<h2 tabindex="-1" dir="auto">Convert a single file</h2>
<p dir="auto">Run <code>convert_single.py</code>, like this:</p>
<div data-snippet-clipboard-copy-content="python convert_single.py /path/to/file.pdf /path/to/output.md --parallel_factor 2 --max_pages 10"><pre><code>python convert_single.py /path/to/file.pdf /path/to/output.md --parallel_factor 2 --max_pages 10
</code></pre></div>
<ul dir="auto">
<li><code>--parallel_factor</code> is how much to increase batch size and parallel OCR workers by.  Higher numbers will take more VRAM and CPU, but process faster.  Set to 1 by default.</li>
<li><code>--max_pages</code> is the maximum number of pages to process.  Omit this to convert the entire document.</li>
</ul>
<p dir="auto">Make sure the <code>DEFAULT_LANG</code> setting is set appropriately for your document.</p>
<h2 tabindex="-1" dir="auto">Convert multiple files</h2>
<p dir="auto">Run <code>convert.py</code>, like this:</p>
<div data-snippet-clipboard-copy-content="python convert.py /path/to/input/folder /path/to/output/folder --workers 10 --max 10 --metadata_file /path/to/metadata.json --min_length 10000"><pre><code>python convert.py /path/to/input/folder /path/to/output/folder --workers 10 --max 10 --metadata_file /path/to/metadata.json --min_length 10000
</code></pre></div>
<ul dir="auto">
<li><code>--workers</code> is the number of pdfs to convert at once.  This is set to 1 by default, but you can increase it to increase throughput, at the cost of more CPU/GPU usage. Parallelism will not increase beyond <code>INFERENCE_RAM / VRAM_PER_TASK</code> if you're using GPU.</li>
<li><code>--max</code> is the maximum number of pdfs to convert.  Omit this to convert all pdfs in the folder.</li>
<li><code>--metadata_file</code> is an optional path to a json file with metadata about the pdfs.  If you provide it, it will be used to set the language for each pdf.  If not, <code>DEFAULT_LANG</code> will be used. The format is:</li>
<li><code>--min_length</code> is the minimum number of characters that need to be extracted from a pdf before it will be considered for processing.  If you're processing a lot of pdfs, I recommend setting this to avoid OCRing pdfs that are mostly images. (slows everything down)</li>
</ul>
<div data-snippet-clipboard-copy-content="{
  &quot;pdf1.pdf&quot;: {&quot;language&quot;: &quot;English&quot;},
  &quot;pdf2.pdf&quot;: {&quot;language&quot;: &quot;Spanish&quot;},
  ...
}"><pre><code>{
  "pdf1.pdf": {"language": "English"},
  "pdf2.pdf": {"language": "Spanish"},
  ...
}
</code></pre></div>
<h2 tabindex="-1" dir="auto">Convert multiple files on multiple GPUs</h2>
<p dir="auto">Run <code>chunk_convert.sh</code>, like this:</p>
<div data-snippet-clipboard-copy-content="MIN_LENGTH=10000 METADATA_FILE=../pdf_meta.json NUM_DEVICES=4 NUM_WORKERS=15 bash chunk_convert.sh ../pdf_in ../md_out"><pre><code>MIN_LENGTH=10000 METADATA_FILE=../pdf_meta.json NUM_DEVICES=4 NUM_WORKERS=15 bash chunk_convert.sh ../pdf_in ../md_out
</code></pre></div>
<ul dir="auto">
<li><code>METADATA_FILE</code> is an optional path to a json file with metadata about the pdfs.  See above for the format.</li>
<li><code>NUM_DEVICES</code> is the number of GPUs to use.  Should be <code>2</code> or greater.</li>
<li><code>NUM_WORKERS</code> is the number of parallel processes to run on each GPU.  Per-GPU parallelism will not increase beyond <code>INFERENCE_RAM / VRAM_PER_TASK</code>.</li>
<li><code>MIN_LENGTH</code> is the minimum number of characters that need to be extracted from a pdf before it will be considered for processing.  If you're processing a lot of pdfs, I recommend setting this to avoid OCRing pdfs that are mostly images. (slows everything down)</li>
</ul>
<h2 tabindex="-1" dir="auto">Benchmarks</h2>
<p dir="auto">Benchmarking PDF extraction quality is hard.  I've created a test set by finding books and scientific papers that have a pdf version and a latex source.  I convert the latex to text, and compare the reference to the output of text extraction methods.</p>
<p dir="auto">Benchmarks show that marker is 10x faster than nougat, and more accurate outside arXiv (nougat was trained on arXiv data).  We show naive text extraction (pulling text out of the pdf with no processing) for comparison.</p>
<p dir="auto"><strong>Speed</strong></p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Average Score</th>
<th>Time per page</th>
<th>Time per document</th>
</tr>
</thead>
<tbody>
<tr>
<td>naive</td>
<td>0.350727</td>
<td>0.00152378</td>
<td>0.326524</td>
</tr>
<tr>
<td>marker</td>
<td>0.641062</td>
<td>0.360622</td>
<td>77.2762</td>
</tr>
<tr>
<td>nougat</td>
<td>0.629211</td>
<td>3.77259</td>
<td>808.413</td>
</tr>
</tbody>
</table>
<p dir="auto"><strong>Accuracy</strong></p>
<p dir="auto">First 3 are non-arXiv books, last 3 are arXiv papers.</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>switch_trans.pdf</th>
<th>crowd.pdf</th>
<th>multicolcnn.pdf</th>
<th>thinkos.pdf</th>
<th>thinkdsp.pdf</th>
<th>thinkpython.pdf</th>
</tr>
</thead>
<tbody>
<tr>
<td>naive</td>
<td>0.244114</td>
<td>0.140669</td>
<td>0.0868221</td>
<td>0.366856</td>
<td>0.412521</td>
<td>0.468281</td>
</tr>
<tr>
<td>marker</td>
<td>0.482091</td>
<td>0.466882</td>
<td>0.537062</td>
<td>0.754347</td>
<td>0.78825</td>
<td>0.779536</td>
</tr>
<tr>
<td>nougat</td>
<td>0.696458</td>
<td>0.552337</td>
<td>0.735099</td>
<td>0.655002</td>
<td>0.645704</td>
<td>0.650282</td>
</tr>
</tbody>
</table>
<p dir="auto">Peak GPU memory usage during the benchmark is <code>3.3GB</code> for nougat, and <code>3.1GB</code> for marker.  Benchmarks were run on an A6000.</p>
<p dir="auto"><strong>Throughput</strong></p>
<p dir="auto">Marker takes about 2GB of VRAM on average per task, so you can convert 24 documents in parallel on an A6000.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/VikParuchuri/marker/blob/master/data/images/per_doc.png"><img src="https://github.com/VikParuchuri/marker/raw/master/data/images/per_doc.png" alt="Benchmark results"></a></p>
<h2 tabindex="-1" dir="auto">Running your own benchmarks</h2>
<p dir="auto">You can benchmark the performance of marker on your machine.  First, download the benchmark data <a href="https://drive.google.com/file/d/1WiN4K2-jQfwyQMe4wSSurbpz3hxo2fG9/view?usp=drive_link" rel="nofollow">here</a> and unzip.</p>
<p dir="auto">Then run <code>benchmark.py</code> like this:</p>
<div data-snippet-clipboard-copy-content="python benchmark.py data/pdfs data/references report.json --nougat"><pre><code>python benchmark.py data/pdfs data/references report.json --nougat
</code></pre></div>
<p dir="auto">This will benchmark marker against other text extraction methods.  It sets up batch sizes for nougat and marker to use a similar amount of GPU RAM for each.</p>
<p dir="auto">Omit <code>--nougat</code> to exclude nougat from the benchmark.  I don't recommend running nougat on CPU, since it is very slow.</p>
<h2 tabindex="-1" dir="auto">Limitations</h2>
<p dir="auto">PDF is a tricky format, so marker will not always work perfectly.  Here are some known limitations that are on the roadmap to address:</p>
<ul dir="auto">
<li>Marker will convert fewer equations to latex than nougat.  This is because it has to first detect equations, then convert them without hallucation.</li>
<li>Whitespace and indentations are not always respected.</li>
<li>Not all lines/spans will be joined properly.</li>
<li>Only languages similar to English (Spanish, French, German, Russian, etc) are supported.  Languages with different character sets (Chinese, Japanese, Korean, etc) are not.</li>
<li>This works best on digital PDFs that won't require a lot of OCR.  It's optimized for speed, and limited OCR is used to fix errors.</li>
</ul>
<h2 tabindex="-1" dir="auto">Commercial usage</h2>
<p dir="auto">Due to the licensing of the underlying models like layoutlmv3 and nougat, this is only suitable for noncommercial usage.</p>
<p dir="auto">I'm building a version that can be used commercially, by stripping out the dependencies below. If you would like to get early access, email me at <a href="mailto:marker@vikas.sh">marker@vikas.sh</a>.</p>
<p dir="auto">Here are the non-commercial/restrictive dependencies:</p>
<ul dir="auto">
<li>LayoutLMv3: CC BY-NC-SA 4.0 .  <a href="https://huggingface.co/microsoft/layoutlmv3-base" rel="nofollow">Source</a></li>
<li>Nougat: CC-BY-NC . <a href="https://github.com/facebookresearch/nougat">Source</a></li>
<li>PyMuPDF - GPL . <a href="https://pymupdf.readthedocs.io/en/latest/about.html#license-and-copyright" rel="nofollow">Source</a></li>
</ul>
<p dir="auto">Other dependencies/datasets are openly licensed (doclaynet, byt5), or used in a way that is compatible with commercial usage (ghostscript).</p>
<h2 tabindex="-1" dir="auto">Thanks</h2>
<p dir="auto">This work would not have been possible without amazing open source models and datasets, including (but not limited to):</p>
<ul dir="auto">
<li>Nougat from Meta</li>
<li>Layoutlmv3 from Microsoft</li>
<li>DocLayNet from IBM</li>
<li>ByT5 from Google</li>
</ul>
<p dir="auto">Thank you to the authors of these models and datasets for making them available to the community!</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ChatGPT's 1-Year Anniversary: Are Open-Source Large Language Models Catching Up? (161 pts)]]></title>
            <link>https://arxiv.org/abs/2311.16989</link>
            <guid>38481970</guid>
            <pubDate>Fri, 01 Dec 2023 01:49:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2311.16989">https://arxiv.org/abs/2311.16989</a>, See on <a href="https://news.ycombinator.com/item?id=38481970">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2311.16989.pdf">Download PDF</a></p><blockquote>
            <span>Abstract:</span>Upon its release in late 2022, ChatGPT has brought a seismic shift in the entire landscape of AI, both in research and commerce. Through instruction-tuning a large language model (LLM) with supervised fine-tuning and reinforcement learning from human feedback, it showed that a model could answer human questions and follow instructions on a broad panel of tasks. Following this success, interests in LLMs have intensified, with new LLMs flourishing at frequent interval across academia and industry, including many start-ups focused on LLMs. While closed-source LLMs (e.g., OpenAI's GPT, Anthropic's Claude) generally outperform their open-source counterparts, the progress on the latter has been rapid with claims of achieving parity or even better on certain tasks. This has crucial implications not only on research but also on business. In this work, on the first anniversary of ChatGPT, we provide an exhaustive overview of this success, surveying all tasks where an open-source LLM has claimed to be on par or better than ChatGPT.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Hailin Chen [<a href="https://arxiv.org/show-email/9e83aded/2311.16989">view email</a>]      <br>            <strong><a href="https://arxiv.org/abs/2311.16989v1">[v1]</a></strong>
        Tue, 28 Nov 2023 17:44:51 UTC (660 KB)<br>
    <strong>[v2]</strong>
        Wed, 29 Nov 2023 16:00:05 UTC (733 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Music-Map – Find Similar Music (104 pts)]]></title>
            <link>https://www.music-map.com</link>
            <guid>38481426</guid>
            <pubDate>Fri, 01 Dec 2023 00:44:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.music-map.com">https://www.music-map.com</a>, See on <a href="https://news.ycombinator.com/item?id=38481426">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
   <td>
    

<p>
 part of <a href="https://www.gnod.com/">gnod</a>, the global network of discovery
</p>

<!-- Seperator. Safari on the ipad will not display it without the &nbsp; -->


<div>
<p>Type the name of an artist <span>to find it on the map</span>:</p>
 



</div>

</td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Broadcom to Cut Almost 1,300 VMware Jobs in California After Takeover (190 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2023-11-30/broadcom-to-cut-almost-1-300-vmware-jobs-in-california-after-takeover</link>
            <guid>38480748</guid>
            <pubDate>Thu, 30 Nov 2023 23:28:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2023-11-30/broadcom-to-cut-almost-1-300-vmware-jobs-in-california-after-takeover">https://www.bloomberg.com/news/articles/2023-11-30/broadcom-to-cut-almost-1-300-vmware-jobs-in-california-after-takeover</a>, See on <a href="https://news.ycombinator.com/item?id=38480748">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <section>
        <h3>Why did this happen?</h3>
        <p>Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our <a href="https://www.bloomberg.com/notices/tos">Terms of
                Service</a> and <a href="https://www.bloomberg.com/notices/tos">Cookie Policy</a>.</p>
    </section>
    <section>
        <h3>Need Help?</h3>
        <p>For inquiries related to this message please <a href="https://www.bloomberg.com/feedback">contact
            our support team</a> and provide the reference ID below.</p>
        <p>Block reference ID:</p>
    </section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why we’re dropping Basecamp (115 pts)]]></title>
            <link>https://blogs.library.duke.edu/blog/2023/11/30/why-were-dropping-basecamp/</link>
            <guid>38479401</guid>
            <pubDate>Thu, 30 Nov 2023 21:27:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blogs.library.duke.edu/blog/2023/11/30/why-were-dropping-basecamp/">https://blogs.library.duke.edu/blog/2023/11/30/why-were-dropping-basecamp/</a>, See on <a href="https://news.ycombinator.com/item?id=38479401">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-30207">
	
	<!-- .entry-header -->

		<div>
		<p><a href="http://blogs.library.duke.edu/wp-content/uploads/2023/11/basecamp_calendar_reminder.png"><img fetchpriority="high" decoding="async" src="http://blogs.library.duke.edu/wp-content/uploads/2023/11/basecamp_calendar_reminder.png" alt="Screen shot depicts a Microsoft To Do task labelled &quot;Let Basecamp subscription lapse.&quot;" width="1200" height="341" srcset="https://blogs.library.duke.edu/wp-content/uploads/2023/11/basecamp_calendar_reminder.png 1200w, https://blogs.library.duke.edu/wp-content/uploads/2023/11/basecamp_calendar_reminder-300x85.png 300w, https://blogs.library.duke.edu/wp-content/uploads/2023/11/basecamp_calendar_reminder-1024x291.png 1024w, https://blogs.library.duke.edu/wp-content/uploads/2023/11/basecamp_calendar_reminder-768x218.png 768w" sizes="(max-width: 1200px) 100vw, 1200px"></a></p>
<p><span>We at Duke University Libraries have decided to stop using the project management platform, Basecamp, to which we have subscribed for almost a decade. We came to this decision after weighing the level of its use in our organization, which is considerable, against the harms that we see perpetuated by the leadership of Basecamp’s parent company, 37signals. As a result of our discussions, we will not renew our current subscription when it ends in December. In the meantime, a small group of our staff have committed to help colleagues export their Basecamp content so it can be archived, and we will move to using other productivity platforms.</span></p>
<p><span>In July of this year, in a team chat, one of our colleagues shared a link to a blog post authored by one of the founders and owners of 37signals, and commented, “We really might want to rethink our usage of Basecamp.”</span></p>
<p><span>It jogged our memories of events some 26 months earlier, when another colleague shared an article published on The Verge, </span><a href="https://www.theverge.com/2021/4/27/22406673/basecamp-political-speech-policy-controversy"><span>“Breaking Camp.”</span></a><span> As reported, internal conflict regarding a culturally-insensitive list of “funny” customer names led Basecamp’s leadership to ban employees from holding “societal and political discussions,” ignoring that the conflict focused on workplace dynamics. Mass resignations resulted, and the experiences of the employees interviewed paints a picture of company leaders who initially supported Diversity, Equity, and Inclusion (DEI) activities but eventually placed severe restrictions on how those activities could play out at work. In a playbook for the ages, those in power failed to acknowledge the complicated interconnectedness and nuance of the issues under discussion, and set policies that shut down discussions challenging the company culture.</span></p>
<p><span>The discussions we had in 2021 identified concerns about both the culture at Basecamp and the impact a decision to leave it would have on our daily work. Staff reflected on the ease of using the platform, the large number of projects that rely on it, and the complication of a decision that would impact groups across in the Libraries in such a direct way. While we talked about how we might respond to the values of third-party companies, we eventually decided not to pursue a cancellation.</span></p>
<p><span>When we revisited the discussion this summer, it took a decidedly different direction. The blog post that our colleague shared in July, titled </span><a href="https://world.hey.com/dhh/the-law-of-the-land-c2231109"><span>“The law of the land,”</span></a><span> by 37signals co-founder, co-owner, and CTO, David Heinemeier Hansson, celebrates the US Supreme Court’s ruling ending considerations of race in admission to colleges and universities. In that post, Hansson links to another that drew our attention, </span><a href="https://world.hey.com/dhh/the-waning-days-of-dei-s-dominance-9a5b656c"><span>“The waning days of DEI’s dominance.”</span></a><span> We also read a third post of his, </span><a href="https://world.hey.com/dhh/meta-goes-no-politics-at-work-and-nobody-cares-d6409209"><span>“Meta goes no politics at work (and nobody cares).”</span></a><span> We found there a thread of ugly thought, couched in an overriding intellectual dishonesty, that re-escalated our discussion about continued use of Basecamp.</span></p>

<p><span>We’re not going to address each of the many falsehoods and distortions in the blog posts by David Heinemeier Hansson. Instead, we will focus on a few emblematic statements that stand in for a pattern of rhetoric that runs counter to our own values.</span></p>
<p><span>In the “waning days” piece, Hansson depicts Diversity, Equity, and Inclusion as a movement that became entrenched in 2020, a process he characterizes being “accelerated” by a number of factors, including “the riots in the wake of George Floyd.” Referring to the protests that followed the murder of George Floyd as “riots” is an offhand gesture as Hansson uses it, but it gets our attention because we know how false, ideological, and ugly it is.&nbsp;</span></p>
<p><a href="https://acleddata.com/2020/09/03/demonstrations-political-violence-in-america-new-data-for-summer-2020/"><span>Research and the documentary record</span></a> <a href="https://wapo.st/3ZcERFW"><span>show</span></a><span> that the protests of 2020 were overwhelmingly peaceful, that incidents of violence were limited and often instigated by counter protestors or provocateurs, and that in many cases the responses of the police and federal authorities provoked and exacerbated the violence. The characterization of these events as “riots” followed as part of a deliberate disinformation campaign by right-wing groups, media’s distorting focus on isolated incidents, and biased framing by political campaigns. It plays on a longstanding and shameful tendency in the US of depicting any protest or demands for justice from Black members of our society as innately violent and threatening.&nbsp;</span></p>
<p><span>In the same post, Hansson takes glee in the mass layoffs of tech workers in late 2022. He imagines that they were the group “from whom the DEI movement drew its most active and engaged disciples,” and seems to be delighted that “hundreds of thousands” of tech workers will be out of work – “perhaps for quite a while!” – and therefore “the most fervent ideologues among them” will be unable to find work. The implication is unavoidable, that he and perhaps other tech bosses might blacklist workers who have records of advocating for more diverse and inclusive workplaces.</span></p>
<p><span>Hansson certainly is entitled to his opinion, and to publish his own blog. We are not in the habit of running “ideological enforcement” to ensure “quick compliance” from beleaguered corporate executives or whatever it is that he’s talking about in his posts. We simply have our own opinions and our own blogs, and in some cases, we have good choices available to us regarding the companies to which we give our business.</span></p>
<p><span>After all, we’re the libraries. We have plenty of experience with corporate entities that don’t reflect our values. We deal with the journal publishers who practice a business model that hoards the world’s knowledge and maximizes profit from the research that our university’s scholars conduct. When it comes to the academic publishing system, institutions of higher learning have made a deal with the devil, and we, the libraries, are the campus units who pay the bill. We do it every year, often facing steep price increases with flat budgets.</span></p>
<p><span>We also know all too well the very worst of what humanity can create, because we collect it. Our shelves hold some of the most god-awful, hateful stuff you can imagine, in the form of explicit hate literature; and the much larger bulk of mainstream materials we hold are pervaded by casual racism and assumptions of white supremacy. Our job is to maintain it all for research, and to provide the context required for responsible inquiry. We know that our collections as a whole are themselves the legacies of systems of oppression in what they do and do not contain. The entire foundation of our organization was developed on assumptions, in the early days of Duke University, that excluded groups would not use the materials we collect or the services we provide. We know about these legacies, and we reckon with them by considering the harm they’ve caused, and asking what we can do to mitigate it.&nbsp;</span></p>
<p><span>We also know the harms that our own workplace practices and culture have caused over the years. We know about it because we listen to each other, both informally and formally, via climate surveys, workshops, and other practices.&nbsp;</span></p>
<p><span>The point is not that we’re perfect, or a model to emulate. The point is that we are not naive. We have seen (and done) some stuff.</span></p>
<p><span>So when we encounter a tech company boss who takes in a nationwide movement of organized protest against police brutalization and systemic racism, led by Black activists, and amplifies the rare incidents of violence, much of it instigated by the police or right-wing counter protestors, using the mendacious language of extremists to refer to it as “riots,” we have a good idea what we’re looking at.</span></p>
<p><span>When we enter into business with a company whose boss takes delight in the mass layoffs of tech workers because it disempowers those who might speak out against their company keeping a list of non-Anglophone names that some members of the team find hilarious, we have a decent sense of who we’re dealing with.</span></p>
<p><span>We here in the libraries are world-weary and sophisticated. We recognize that it’s the nature of our world, so interconnected now. We think all that interconnection makes us stronger, more vibrant; it’s wondrous, but it also means that as we encounter difference, we need to “do the work” (as Hansson mocks), be aware, and be open. Not every situation is going to be easy, but bringing “our whole selves” (another phrase that he mocks) to it has an impact, makes it more real, more human.&nbsp;</span></p>
<p><span>There are always going to be the free riders – tech companies, perhaps – who benefit from the interconnectedness of the world while refusing to do the work. They may even taunt, from their blogs, those who try. Their paths are going to intersect with ours; that’s just the way it works. Often, we’re not in a position to choose not to deal with them.</span></p>
<p><span>But occasionally, we are. Not because we want to eliminate anyone’s livelihood, or harry executives, or because we imagine our subscription fee makes much of a difference. But just because we can. In this case, there are other productivity tools that can fill the space. In this case, we have options. And we’ve chosen to end our subscription with Basecamp.</span></p>
	</div><!-- .entry-content -->
	
	</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tesla Cybertruck Pricing and Specs (250 pts)]]></title>
            <link>https://www.tesla.com/cybertruck/design</link>
            <guid>38478964</guid>
            <pubDate>Thu, 30 Nov 2023 20:57:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tesla.com/cybertruck/design">https://www.tesla.com/cybertruck/design</a>, See on <a href="https://news.ycombinator.com/item?id=38478964">Hacker News</a></p>
Couldn't get https://www.tesla.com/cybertruck/design: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Firefox for Android is adding support for 400 add-ons (130 pts)]]></title>
            <link>https://liliputing.com/firefox-for-android-is-adding-support-for-400-add-ons/</link>
            <guid>38478238</guid>
            <pubDate>Thu, 30 Nov 2023 19:52:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://liliputing.com/firefox-for-android-is-adding-support-for-400-add-ons/">https://liliputing.com/firefox-for-android-is-adding-support-for-400-add-ons/</a>, See on <a href="https://news.ycombinator.com/item?id=38478238">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="content"><main id="main"><div><article id="post-164651"><div><p>Desktop web browsers have long supported add-ons and extensions that change the user interface, add features, or otherwise change the behavior of the browser. But it’s more rare to find a mobile browser with support for third-party add-ons.</p><p>Firefox is one of the exceptions. Firefox for Android first <a href="https://www.theverge.com/2011/11/10/2552557/firefox-version-8-android-update-increased-security">added support for add-ons in 2011</a>, but when Mozilla <a href="https://liliputing.com/firefox-79-for-android-brings-a-major-design-overhaul-and-limited-support-for-extensions/">redesigned its mobile browser in 2020</a>, it lost support for many of those older add-ons. Now Mozilla says <a href="https://blog.mozilla.org/addons/2023/11/28/open-extensions-on-firefox-for-android-debut-december-14-but-you-can-get-a-sneak-peek-today/">add-ons are coming back, in a big way</a>.</p><p><img fetchpriority="high" decoding="async" src="https://liliputing.com/wp-content/uploads/2023/11/firefox-android-add-ons-709x500.jpg" alt="" width="709" height="500" srcset="https://liliputing.com/wp-content/uploads/2023/11/firefox-android-add-ons-709x500.jpg 709w, https://liliputing.com/wp-content/uploads/2023/11/firefox-android-add-ons-400x282.jpg 400w, https://liliputing.com/wp-content/uploads/2023/11/firefox-android-add-ons-150x106.jpg 150w, https://liliputing.com/wp-content/uploads/2023/11/firefox-android-add-ons-768x541.jpg 768w, https://liliputing.com/wp-content/uploads/2023/11/firefox-android-add-ons.jpg 1200w" sizes="(max-width: 709px) 100vw, 709px"></p><p>Starting December 14, Mozilla says that more than 400 more add-ons will be available to install on Firefox’s web browser for Android phones, tablets, and other devices.</p><p>Not&nbsp;<em>all</em> Firefox add-ons available from <a href="https://addons.mozilla.org/en-US/firefox/">addons.mozilla.org</a> will work with the mobile browser. But any extension marked as Android compatible should work, and if you want to browse a subset of compatible extensions, there’s <a href="https://addons.mozilla.org/android/?_gl=1*52ox1h*_ga*MTMzNTIzNTY4NS4xNjk1NzQzNjI1*_ga_X4N05QV93S*MTcwMTM2NTY3Mi41LjAuMTcwMTM2NTY3Mi4wLjAuMA..">a new page for that</a>.</p><p>Some popular extensions that are already available, include ad blockers like <a href="https://addons.mozilla.org/en-US/android/addon/ublock-origin/?utm_source=addons.mozilla.org&amp;utm_medium=referral&amp;utm_content=search">uBlock Origin</a>, <a href="https://addons.mozilla.org/en-US/android/addon/ghostery/?utm_source=addons.mozilla.org&amp;utm_medium=referral&amp;utm_content=search">Ghostery</a>, and <a href="https://addons.mozilla.org/en-US/android/addon/adguard-adblocker/?utm_source=addons.mozilla.org&amp;utm_medium=referral&amp;utm_content=search">AdGuard</a>, password managers like <a href="https://addons.mozilla.org/en-US/android/addon/bitwarden-password-manager/?utm_source=addons.mozilla.org&amp;utm_medium=referral&amp;utm_content=search">Bitwarden</a>, and other tools that do things like <a href="https://addons.mozilla.org/en-US/android/addon/search_by_image/?utm_source=addons.mozilla.org&amp;utm_medium=referral&amp;utm_content=search">read text aloud to you</a>, enable <a href="https://addons.mozilla.org/en-US/android/addon/search_by_image/?utm_source=addons.mozilla.org&amp;utm_medium=referral&amp;utm_content=search">multi-site reverse image searches</a>, or <a href="https://addons.mozilla.org/en-US/android/addon/youtube-high-definition/?utm_source=addons.mozilla.org&amp;utm_medium=referral&amp;utm_content=search">force YouTube videos to play in high definition</a>.</p><p>But at the moment there are only a few dozen add-ons available, and that list is going to grow a lot longer in the next few weeks.</p><div id="custom_html-9"><p>Liliputing's primary sources of revenue are advertising and affiliate links (if you click the "<a target="_blank" rel="nofollow noopener" href="https://www.amazon.com/Best-Sellers-Computers-Accessories/zgbs/pc/ref=as_li_ss_tl?_encoding=UTF8&amp;linkCode=ll2&amp;tag=liliputing_shop-20&amp;linkId=93aaf7ba4e36ed56d46003558471548d">Shop</a>" button at the top of the page and buy something on Amazon, for example, we'll get a small commission).</p><p>But there are several ways you can support the site directly even if you're using an ad blocker* and hate online shopping.</p><h3>Contribute to our <a href="https://www.patreon.com/bradlinder">Patreon campaign</a></h3><p> <em>or...</em></p><h3>Contribute via <a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=PTBQ9EKAYTZBS&amp;source=url">PayPal</a></h3><p> * If you <em>are</em> using an ad blocker like uBlock Origin and seeing a pop-up message at the bottom of the screen, we have a <a target="blank_" href="https://liliputing.com/2020/09/ublock-origin-how-to-hide-googles-script-blocking-warning-for-websites-using-funding-choices.html" rel="noopener">guide that may help you disable it.</a></p></div><div id="blog_subscription-2"><p> Join 9,501 other subscribers</p></div></div></article></div></main></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Turbo Pascal Turns 40 (261 pts)]]></title>
            <link>https://blog.marcocantu.com/blog/2023-november-turbopascal40.html</link>
            <guid>38477688</guid>
            <pubDate>Thu, 30 Nov 2023 19:08:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.marcocantu.com/blog/2023-november-turbopascal40.html">https://blog.marcocantu.com/blog/2023-november-turbopascal40.html</a>, See on <a href="https://news.ycombinator.com/item?id=38477688">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Turbo Pascal was introduced by Borland in November 1983. It's officially turning 40 years old this month.</p><div>
<p xmlns:gxi="http://geode.it/gxi/2.0/">Turbo Pascal was a milestone product for the industry, it started Borland as a company and it was the first popular Integrated Development Environment or IDE. It was a great product for the time, and its success was incredible.</p>
<p xmlns:gxi="http://geode.it/gxi/2.0/">You can read more about Turbo Pascal it in this recent blog post from&nbsp;<a href="https://blogs.embarcadero.com/i-first-met-philippe-kahn-and-turbo-pascal-40-years-ago-this-month/">David I</a>, but also on <a href="https://en.wikipedia.org/wiki/Turbo_Pascal">Wikipedia</a> and many other sources including <a href="https://blog.marcocantu.com/blog/2021-march-50years-pascal.html">blog posts</a> of mine, including the <a href="https://blog.marcocantu.com/blog/2023-july-niklaus-wirth-prize-acceptance-speech.html">talk I did this summer</a> in the first Pascal World Congress in Salamanca.</p>
<p xmlns:gxi="http://geode.it/gxi/2.0/">At Embarcadero, the company continuing working on the successors of Turbo Pascal, we just shipped <a href="https://www.embarcadero.com/products/rad-studio/whats-new-in-12-athens">version 36</a> of that compiler. In fact when you read "Embarcadero Delphi for Win32 compiler version 36.0" (the version of the command line compiler in Delphi 12 Athens)&nbsp;the compiler version number, 36, dates back to the first Turbo Pascal. Not only that, we decided to dedicate the product Easter Egg to this great anniversary.</p>
<p xmlns:gxi="http://geode.it/gxi/2.0/">
      <strong>Happy 40th birthday, Turbo Pascal!</strong>
    </p>
<p xmlns:gxi="http://geode.it/gxi/2.0/">
      <img alt="" src="http://blog.marcocantu.com/images/forblog/turbopascal40.png">
    </p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Visual Anagrams: Generating Optical Illusions with Diffusion Models (585 pts)]]></title>
            <link>https://dangeng.github.io/visual_anagrams/</link>
            <guid>38477259</guid>
            <pubDate>Thu, 30 Nov 2023 18:39:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dangeng.github.io/visual_anagrams/">https://dangeng.github.io/visual_anagrams/</a>, See on <a href="https://news.ycombinator.com/item?id=38477259">Hacker News</a></p>
<div id="readability-page-1" class="page">


<div>
          <h2>Visual Anagrams: Generating Multi-View Optical Illusions with Diffusion Models</h2>
          

          <p><span>University of Michigan</span>
          </p>

          <p><span>Correspondence to: dgeng@umich.edu</span>
          </p>

          
        </div>


<!-- TEASER + INTRO -->
<section>
  <h2>
    <b>tl;dr:</b> We use pretrained diffusion models<br>to make optical illusions
  </h2>
  
</section>


<!-- OVERVIEW -->
<div>
        <h2>Overview</h2>
        <p>
          We present a simple, zero-shot method to generate <i>multi-view optical illusions</i>. 
          These are images that look like one thing, but change appearance or identity when
          transformed. We <a href="#method">show in theory</a> and practice that our method supports a broad range of transformations 
          including <a href="#rot90_examples">rotations</a>, <a href="#flip_examples">flips</a>, 
          <a href="#inversion_examples">color inversions</a>, <a href="#misc_examples">skews</a>, 
          <a href="#jigsaw_examples">jigsaw rearrangements</a>, and 
          <a href="#perm_examples">random permutations</a>. We show some examples below.
          </p>
      </div>


<!-- JIGSAW GRID -->
<div>
    <p>
      <h2 id="jigsaw_examples">Jigsaw Permutations</h2>
    </p>
    
    
  </div>

<!-- FLIPS GRID -->
<div>
    <p>
      <h2 id="flip_examples">Flips and 180° Rotations</h2>
    </p>
    
    
    
    
  </div>

<!-- 90 DEGREE GRID -->
<div>
    <p>
      <h2 id="rot90_examples">90° Rotations</h2>
    </p>
    
    
  </div>

<!-- INVERSIONS GRID -->
<div>
    <p>
      <h2 id="inversion_examples">Color Inversions</h2>
    </p>
    
    
  </div>

<!-- MISC GRID -->
<div>
    <p>
      <h2 id="misc_examples">Miscellaneous Permutations</h2>
    </p>
    
    
  </div>

<!-- PATCH GRID -->
<div>
    <p>
      <h2 id="perm_examples">Random Patch Permutations</h2>
    </p>
      
      
  </div>

<!-- METHOD -->
<div>
        <h2 id="method">Method</h2>
        <div>
          <p><img src="https://dangeng.github.io/visual_anagrams/static/images/method.jpg"></p><p>
            Our method is conceptually simple. We take an off-the-shelf diffusion model and use it
            to estimate the noise in different views or transformations, \(v_i\), of an image. 
            The noise estimates are then aligned by applying the inverse view, \(v_i^{-1}\),
            and averaged together. This averaged noise estimate is then used to take a diffusion step.
          </p>
        </div>
      </div>

<!-- CONDITIONS -->
<div>
        <h2>Conditions on Views</h2>
        <p>
            We find that not every view function works with the above method. Of course, \(v_i\) must
            be invertible, but we discuss two additional constraints.
          </p>
        <h2>Linearity</h2>
        <p>
            A diffusion model is trained to estimate the noise in noisy data \(\mathbf{x}_t\) conditioned 
            on time step \(t\). The noisy data \(\mathbf{x}_t\) is expected to have the form 
            \[\mathbf{x}_t = w_t^{\text{signal}}\underbrace{\mathbf{x}_0}_{\text{signal}} + w_t^{\text{noise}}\underbrace{\epsilon\vphantom{\mathbf{x}_0}}_{\text{noise}}.\]
            That is, \(\mathbf{x}_t\) is a weighted average of pure signal \(\mathbf{x_0}\) 
            and pure noise \(\epsilon\), specifically with weights \(w_t^{\text{signal}}\) and \(w_t^{\text{noise}}\). 
            Therefore, our view, \(v\) must maintain this weighting between signal and noise. This can be achieved
            by making \(v\) linear, which we represent by the square matrix \(\mathbf{A}\). By linearity
            \[\begin{aligned} v(\mathbf{x}_t) &amp;= \mathbf{A}(w_t^{\text{signal}} \mathbf{x}_0+w_t^{\text{noise}} \epsilon)\\[7pt] &amp;= w_t^{\text{signal}} \underbrace{\mathbf{A}\mathbf{x}_0}_{\text{new signal}} + w_t^{\text{noise}} \underbrace{\mathbf{A}\epsilon}_{\text{new noise}}. \end{aligned}\]
            Effectively, \(v\) acts on the signal and the noise independently, and combines the result with the correct weighting.
          </p>
        <h2>Statistical Consistency</h2>
        <div>
          <p>
            Diffusion models are trained with the assumption that the noise is drawn iid from a standard normal.
            Therefore we must ensure that the transformed noise also follows these statistics. That is, we need
            \[\mathbf{A}\epsilon \sim \mathcal{N}(0, I).\]
            For linear transformations, this is equivalent to the condition that \(\mathbf{A}\) is orthogonal.
            Intuitively, orthogonal matrices respect the spherical symmetry of the standard multivariate Gaussian distribution.
          </p>
          <p>
            Therefore, for a transformation to work with our method, it is <b>sufficient for it to be orthogonal.</b>
          </p>
        </div>
      </div>


<!-- ORTHOGONAL -->
<div>
        <h2>Orthogonal Transformations</h2>
        <p>
            Most orthogonal transformations on images are meaningless, visually. For example, we transform
            the image below with a randomly sampled orthogonal matrix.
          </p>
        <p><img src="https://dangeng.github.io/visual_anagrams/static/images/orthogonal.jpeg">
        </p>
        <p>
            However, <b>permutations matrices are a subset of orthogonal matrices,</b> and are quite interpretable. 
            They are just rearrangements of pixels in an image. This is where the idea of a <b>visual anagram</b>
            comes from. The majority of illusions here can be interpreted this way—as specific rearrangements of pixels—such as
            <a href="#rot90_examples">rotations</a>, <a href="#flip_examples">flips</a>, 
            <a href="#misc_examples">skews</a>, <a href="#misc_examples">"inner rotations,"</a> 
            <a href="#jigsaw_examples">jigsaw rearrangements</a>, and 
            <a href="#perm_examples">patch permutations</a>. Finally, <a href="#inversion_examples">color inversions</a>
            are not permutations, but are orthogonal as they are a negation of pixel values.
            
          </p>
      </div>




<div>
        <h2>Video (Coming Soon!)</h2>
        <p>
          <!--<iframe src="https://www.youtube.com/embed/jNQXAC9IVRw?si=8Dnrd2U1f2My6KUC"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>-->
          <iframe src="https://www.youtube.com/embed/1234567890" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>
        </p>
      </div>


<div>
        <h2>Related Links</h2>

        <div>
          <p>
            This project is inspired by previous work in this area, including:
          </p>
          <p>
            <a href="https://diffusionillusions.com/" target="_blank">Diffusion Illusions</a>, 
            by <a href="https://ryanndagreat.github.io/" target="_blank">Ryan Burgert</a> <i>et al.</i>,
            which produces multi-view illusions, along with other visual effects, through score distillation sampling.
          </p>
          <p>
            This <a href="https://github.com/tancik/Illusion-Diffusion" target="_blank">colab notebook</a> by 
            <a href="https://www.matthewtancik.com/about-me" target="_blank">Matthew Tancik</a>, 
            which introduces a similar idea to ours. We improve upon it significantly in 
            terms of quality of illusions, range of transformations, and theoretical analysis.
          </p>
          <p>
            <a href="https://www.reddit.com/r/StableDiffusion/comments/16ew9fz/spiral_town_different_approach_to_qr_monster/" target="_blank">Recent work by a pseudonymous artist</a>, Ugleh,
            uses a Stable Diffusion model finetuned for generating QR codes to produce images whose global structure subtly matches a given template image.
          </p>
        </div>
      </div>


<div id="BibTeX">
    <h2>BibTeX</h2>
    <pre><code>@article{geng2023visualanagrams,
  title     = {Visual Anagrams: Generating Multi-View Optical Illusions with Diffusion Models},
  author    = {Geng, Daniel and Park, Inbum and Owens, Andrew},
  journal   = {arXiv:2311.17919},
  year      = {2023},
  month     = {Novemeber},
  abbr      = {Preprint},
  url       = {https://arxiv.org/abs/2311.17919},
}</code></pre>
  </div>






</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Accelerating Generative AI with PyTorch II: GPT, Fast (256 pts)]]></title>
            <link>https://pytorch.org/blog/accelerating-generative-ai-2/</link>
            <guid>38477197</guid>
            <pubDate>Thu, 30 Nov 2023 18:35:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pytorch.org/blog/accelerating-generative-ai-2/">https://pytorch.org/blog/accelerating-generative-ai-2/</a>, See on <a href="https://news.ycombinator.com/item?id=38477197">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
                    
                    <p>This post is the second part of a multi-series blog focused on how to accelerate generative AI models with pure, native PyTorch. We are excited to share a breadth of newly released PyTorch performance features alongside practical examples to see how far we can push PyTorch native performance. In part one, we showed how to accelerate <a href="https://pytorch.org/blog/accelerating-generative-ai/">Segment Anything over 8x</a> using only pure, native PyTorch. In this blog we’ll focus on LLM optimization.</p>

<p>Over the past year, generative AI use cases have exploded in popularity. Text generation has been one particularly popular area, with lots of innovation among open-source projects such as <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a>, <a href="https://github.com/vllm-project/vllm">vLLM</a>, and <a href="https://github.com/mlc-ai/mlc-llm">MLC-LLM</a>.</p>

<p>While these projects are performant, they often come with tradeoffs in ease of use, such as requiring model conversion to specific formats or building and shipping new dependencies. This begs the question: <strong>how fast can we run transformer inference with only pure, native PyTorch?</strong></p>

<p>As announced during our recent <a href="https://www.youtube.com/watch?v=IWpM_9AsC-U">PyTorch Developer Conference</a>, the PyTorch team wrote a from-scratch LLM <strong>almost 10x faster than baseline,</strong> with no loss of accuracy, all using native PyTorch optimizations. We leverage a breadth of optimizations including:</p>

<ul>
  <li><strong><a href="https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html">Torch.compile</a></strong>: A compiler for PyTorch models</li>
  <li><strong><a href="https://github.com/pytorch-labs/ao/tree/main#torchao">GPU quantization</a></strong>: Accelerate models with reduced precision operations</li>
  <li><strong><a href="https://github.com/pytorch-labs/gpt-fast/blob/main/generate.py#L76">Speculative Decoding</a></strong>: Accelerate LLMs using a small “draft” model to predict large “target” model’s output</li>
  <li><strong><a href="https://github.com/pytorch-labs/gpt-fast/blob/main/tp.py">Tensor Parallelism</a></strong>: Accelerate models by running them across multiple devices.</li>
</ul>

<p>And, even better, we can do it in <strong>less than 1000 lines of native PyTorch code</strong>.</p>

<p>If this excites you enough to jump straight into the code, check it out at <a href="https://github.com/pytorch-labs/gpt-fast">https://github.com/pytorch-labs/gpt-fast</a>!</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/screen-recording.gif" alt="Screen recording"></p>

<p><em>Note: We will be focusing on latency (i.e. batch size=1) for all of these benchmarks. Unless otherwise specified, all benchmarks are run on an A100-80GB, power limited to 330W.</em></p>

<h2 id="starting-point-255-toks">Starting Point (25.5 tok/s)</h2>

<p>Let’s start off with an extremely basic and simple implementation.</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image23.png" alt="simple implementation"></p>

<p>Sadly, this does not perform very well. But why? Looking at a trace reveals the answer - it’s heavily <strong>CPU overhead bound</strong>! What this means is that our CPU is not able to tell the GPU what to do fast enough for the GPU to be fully utilized.</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image14.png" alt="trace"></p>

<p>Imagine the GPU as this super massive factory with a ridiculous amount of compute available. Then, imagine the CPU as some messenger shuttling instructions back and forth to the GPU. Remember, in large scale deep learning systems, the GPU is responsible for doing 100% of the work! In such systems, the only role of the CPU is to tell the GPU what work it should be doing.</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image16.png" alt="factory"></p>

<p>So, the CPU runs over and tells the GPU to do an “add”, but by the time the CPU can give the GPU another chunk of work, the GPU has long finished the previous chunk of work.</p>

<p>Despite the fact that the GPU needs to perform thousands of computations while the CPU only needs to do orchestration work, this is surprisingly common! There’s a variety of reasons for this, ranging from the fact that the CPU is likely running some single-threaded Python to the fact that GPUs are just incredibly fast nowadays.</p>

<p>Regardless of the reason, we now find ourselves in the <strong>overhead-bound regime</strong>. So, what can we do? One, we could rewrite our implementation in C++, perhaps even eschew frameworks entirely and write raw CUDA. Or…. we could just send more work to the GPU at once.</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image3.png" alt="factory"></p>

<p>By just sending a massive chunk of work at once, we can keep our GPU busy! Although during training, this may just be accomplished by increasing your batch size, how do we do this during inference?</p>

<p>Enter torch.compile.</p>

<h2 id="step-1-reducing-cpu-overhead-through-torchcompile-and-a-static-kv-cache-1070-toks">Step 1: Reducing CPU overhead through torch.compile and a static kv-cache (107.0 tok/s)</h2>

<p>Torch.compile allows us to capture a larger region into a single compiled region, and particularly when run with mode=”reduce-overhead”, is very effective at reducing CPU overhead. Here, we also specify fullgraph=True, which validates that there are no “graph breaks” in your model (i.e. portions that torch.compile cannot compile). In other words, it ensures that torch.compile is running to its fullest potential.</p>

<p>To apply it, we <a href="https://github.com/pytorch-labs/gpt-fast/blob/main/generate.py#L296">simply wrap a function (or a module) with it</a>.</p>

<div><pre><code>torch.compile(decode_one_token, mode="reduce-overhead", fullgraph=True)
</code></pre></div>

<p>However, there are a couple of nuances here that make it somewhat nontrivial for folks to get significant performance boosts from applying torch.compile to text generation.</p>

<p>The first obstacle is the kv-cache. The kv-cache is an inference-time optimization that caches the activations computed for the previous tokens (see <a href="https://www.dipkumar.dev/becoming-the-unbeatable/posts/gpt-kvcache/">here</a> for a more in-depth explanation). However, as we generate more tokens, the “logical length” of the kv-cache grows. This is problematic for two reasons. One is that reallocating (and copying!) the kv-cache every time the cache grows is simply expensive. The other one is that this dynamism makes it harder to reduce the overhead, as we are no longer able to leverage approaches like cudagraphs.</p>

<p>To resolve this, we use a<a href="https://github.com/pytorch-labs/gpt-fast/blob/0afae1ace441ce4c5d02ef11a72da28cf7ca4795/generate.py#L154"> “static” kv-cache</a>, which means that we statically allocate the maximum size of the kv-cache, and then mask out the unused values in the attention portion of the computation.</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image2.png" alt="code"></p>

<p>The second obstacle is the prefill phase. Transformer text generation is best thought of as a two phase process: 1. The prefill where the entire prompt is processed, and 2. Decoding where each token is generated autoregressively.</p>

<p>Although decoding can be made entirely static once the kv-cache is made static, the prefill stage still requires significantly more dynamism, due to having a variable prompt length. Thus, we actually need to compile the two stages with separate compilation strategies.</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image9.png" alt="compile"></p>

<p>Although these details are a bit tricky, the actual implementation is not very difficult at all (see gpt-fast)! And the performance boost is dramatic.</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image28.png" alt="chart"></p>

<p>All of a sudden, our performance improves by more than 4x! Such performance gains are often common when one’s workload is overhead bound.</p>

<h2 id="sidenote-how-is-torchcompile-helping">Sidenote: How is torch.compile helping?</h2>

<p>It is worth disentangling how exactly torch.compile is improving performance. There’s 2 main factors leading to torch.compile’s performance.</p>

<p>The first factor, like mentioned above, is overhead reduction. Torch.compile is able to reduce overhead through a variety of optimizations, but one of the most effective ones is called <a href="https://pytorch.org/blog/accelerating-pytorch-with-cuda-graphs/">CUDAGraphs</a>. Although torch.compile applies this automatically for you when “reduce-overhead” is set, saving the extra work and code you need to write when doing this yourself manually  without torch.compile.</p>

<p>The second factor, however, is that torch.compile simply generates faster kernels. In the decoding benchmark above, torch.compile actually generates every single kernel from scratch, including both the matrix multiplications and the attention! And even cooler, these kernels are actually faster than the built in alternatives (CuBLAS and FlashAttention2)!</p>

<p>This may sound implausible to many of you, considering how hard it is to write efficient matrix multiplication/attention kernels, and how much manpower has been put into CuBLAS and FlashAttention. The key here, however, is that transformer decoding has very unusual computational properties. In particular, because of the KV-cache, for BS=1 <em>every single matrix multiplication in a transformer is actually a matrix vector multiplication</em>.</p>

<p>This means that the computations are completely <em>memory-bandwidth bound</em>, and as such, are well within the range of compilers to automatically generate. And in fact, when we benchmark torch.compile’s matrix-vector multiplications against CuBLAS, we find that torch.compile’s kernels are actually quite a bit faster!</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image24.png" alt="code"></p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image17.png" alt="code"></p>

<h2 id="step-2-alleviating-memory-bandwidth-bottleneck-through-int8-weight-only-quantization-1574-toks">Step 2: Alleviating memory bandwidth bottleneck through int8 weight-only quantization (157.4 tok/s)</h2>

<p>So, given that we’ve already seen massive speedups from applying torch.compile, is it possible to do even better? One way to think about this problem is to compute how close we are to the theoretical peak. In this case, the largest bottleneck is the cost of loading the weights from GPU global memory to registers. In other words, each forward pass requires us to “touch” every single parameter on the GPU. So, how fast can we theoretically “touch” every single parameter in a model?</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image11.png" alt="weights"></p>

<p>To measure this, we can use <strong>Model Bandwidth Utilization (MBU).</strong> This measures what percentage of our memory bandwidth we’re able to use during inference.</p>

<p>Computing it is pretty simple. We simply take the total size of our model (# params * bytes per param) and multiply it by the number of inferences we can do per second. Then, we divide this by the peak bandwidth of the GPU to get our MBU.</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image8.png" alt="MBU"></p>

<p>For example, for our above case, we have a 7B parameter model. Each parameter is stored in fp16 (2 bytes per parameter), and we achieved 107 tokens/s. Finally, our A100-80GB has a theoretical 2 TB/s of memory bandwidth.</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image25.png" alt="MBU"></p>

<p>Putting this all together, we get **72% MBU! **This is quite good, considering that even just copying memory struggles to break 85%.</p>

<p>But… it does mean that we’re pretty close to the theoretical limit here, and that we’re clearly bottlenecked on just loading our weights from memory. It doesn’t matter what we do - without changing the problem statement in some manner, we might only be able to eek out another 10% in performance.</p>

<p>Let’s take another look at the above equation. We can’t really change the number of parameters in our model. We can’t really change the memory bandwidth of our GPU (well, without paying more money). But, we <strong>can</strong> change how many bytes each parameter is stored in!</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image18.png" alt="MBU"></p>

<p>Thus, we arrive at our next technique - int8 quantization. The idea here is simple. If loading our weights from memory is our main bottleneck, why don’t we just make the weights smaller?</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image7.png" alt="MBU"></p>

<p>Note that this is quantizing <em>only</em> the weights - the computation itself is still done in bf16. This makes this form of quantization easy to apply with very little to no accuracy degradation.</p>

<p>Moreover, torch.compile can also easily generate efficient code for int8 quantization. Let’s look again at the above benchmark, this time with int8 weight-only quantization included.</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image1.png" alt="code"></p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image27.png" alt="code"></p>

<p>As you can see from the dark blue line (torch.compile + int8), there is a significant performance improvement when using torch.compile + int8 weight-only quantization! Moreover, the light-blue line (no torch.compile + int8) is actually much worse than even the fp16 performance! This is because in order to take advantage of the perf benefits of int8 quantization, we need the kernels to be fused. This shows one of the benefits of torch.compile - these kernels can be automatically generated for the user!</p>

<p><a href="https://github.com/pytorch-labs/gpt-fast/blob/main/quantize.py#L314">Applying int8 quantization to our model</a>, we see a nice 50% performance improvement, bringing us up to 157.4 tokens/s!</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image19.png" alt="chart"></p>

<h2 id="step-3-reframing-the-problem-using-speculative-decoding">Step 3: Reframing the problem using speculative decoding</h2>

<p>Even after using techniques like quantization, we’re still faced with another problem. In order to generate 100 tokens, we must load our weights 100 times.</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image5.png" alt="diagram"></p>

<p>Even if the weights are quantized, we still must load our weights over and over, once for each token we generate! Is there any way around this?</p>

<p>At first glance, the answer might seem like no - there’s a strict serial dependency in our autoregressive generation. However, as it turns out, by utilizing <a href="https://arxiv.org/abs/2211.17192">speculative decoding</a>, we’re able to break this strict serial dependency and obtain speedups!</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image21.png" alt="engineers"></p>

<p>Imagine you had a senior engineer (called Verity), who makes the right technical decisions but is rather slow at writing code. However, you also have a junior engineer (called Drake), who doesn’t always make the right technical decisions but can write code much faster (and cheaper!) than Verity. How can we take advantage of Drake (the junior engineer) to write code faster while ensuring that we are still making the right technical decisions?</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image6.png" alt="engineers"></p>

<p>First, Drake goes through the labor-intensive process of writing the code, making technical decisions along the way. Next, we give the code to Verity to review.</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image15.png" alt="engineers"></p>

<p>Upon reviewing the code, Verity might decide that the first 3 technical decisions Drake made are correct, but the last 2 need to be redone. So, Drake goes back, throws away his last 2 decisions, and restarts coding from there.</p>

<p>Notably, although Verity (the senior engineer) has only looked at the code once, we are able to generate 3 pieces of validated code identical to what she would have written! Thus, assuming Verity is able to review the code faster than it would have taken her to write those 3 pieces herself, this approach comes out ahead.</p>

<p>In the context of transformer inference, Verity would be played by the role of the larger model whose outputs we want for our task, called the <strong>verifier model</strong>. Similarly, Drake would be played by a smaller model that’s able to generate text much faster than the larger model, called the <strong>draft model</strong>. So, we would generate 8 tokens using the draft model, and then process all eight tokens in parallel using the verifier model, throwing out the ones that don’t match.</p>

<p>Like mentioned above, one crucial property of speculative decoding is that <strong>it does not change the quality of the output</strong>. As long as the time it takes for generating the tokens using the draft model + verifying the tokens is less than it would have taken to generate those tokens, we come out ahead.</p>

<p>One of the great things about doing this all in native PyTorch is that this technique is actually really easy to implement! Here’s the <a href="https://github.com/pytorch-labs/gpt-fast/blob/main/generate.py#L76">entirety of the implementation</a>, in about 50 lines of native PyTorch.</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image10.png" alt="code"></p>

<p>Although speculative decoding guarantees that we have mathematically identical results compared to regular generation, it does have the property that the runtime performance varies depending on the generated text, as well as how aligned the draft and verifier model are. For example, when running CodeLlama-34B + CodeLlama-7B, we’re able to obtain a 2x boost in tokens/s for generating code. On the other hand, when using Llama-7B + TinyLlama-1B, we’re only able to obtain about a 1.3x boost in tokens/s.</p>

<h2 id="sidenote-running-this-on-amd">Sidenote: Running this on AMD</h2>

<p>Like mentioned above, every single kernel in decoding is generated from scratch by torch.compile, and is converted into OpenAI Triton. As AMD has a <a href="https://pytorch.org/blog/experience-power-pytorch-2.0/">torch.compile backend</a> (and also a Triton backend), we can simply go through all of the optimizations above… but on an AMD GPU! With int8 quantization, we’re able to achieve 102.5 tokens/s with one GCD (i.e. one half) of a MI250x!</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image4.png" alt="chart"></p>

<h2 id="step-4-reducing-the-size-of-the-weights-even-more-with-int4-quantization-and-gptq-2021-toks">Step 4: Reducing the size of the weights even more with int4 quantization and GPTQ (202.1 tok/s)</h2>

<p>Of course, if reducing the weights down from 16 bits to 8 bits allows for speedups by reducing the number of bytes we need to load, reducing the weights down to 4 bits would result in even larger speedups!</p>

<p>Unfortunately, when reducing weights down to 4-bits, the accuracy of the model starts to become a much larger concern. From our preliminary evals, we see that although using int8 weight-only quantization has no perceptible accuracy degradation, using int4 weight-only quantization does.</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image13.png" alt="table"></p>

<p>There are 2 main tricks we can use to limit the accuracy degradation of int4 quantization.</p>

<p>The first one is to have a more granular scaling factor. One way to think about the scaling factor is that when we have a quantized tensor representation, it is on a sliding scale between a floating point tensor (each value has a scaling factor) and an integer tensor (no values have a scaling factor). For example, with int8 quantization, we had one scaling factor per row. If we want higher accuracy, however, we can change that to “one scaling factor per 32 elements”. We choose a group size of 32 to minimize accuracy degradation, and this is also a common choice among the community.</p>

<p>The other one is to use a more advanced quantization strategy than simply rounding the weights. For example, approaches like <a href="https://arxiv.org/abs/2210.17323">GPTQ</a> leverage example data in order to calibrate the weights more accurately. In this case, we prototype an implementation of GPTQ in the repository based off of PyTorch’s recently released <a href="https://pytorch.org/tutorials/intermediate/torch_export_tutorial.html">torch.export</a>.</p>

<p>In addition, we need kernels that fuse int4 dequantize with the matrix vector multiplication. In this case, torch.compile is unfortunately not able to generate these kernels from scratch, so we leverage some handwritten CUDA kernels in PyTorch.</p>

<p>These techniques require some additional work, but putting them all together results in even better performance!</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image12.png" alt="chart"></p>

<h2 id="step-5-combining-everything-together-2447-toks">Step 5: Combining everything together (244.7 tok/s)</h2>

<p>Finally, we can compose all of the techniques together to achieve even better performance!</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image22.png" alt="chart"></p>

<h2 id="step-6-using-tensor-parallelism">Step 6: Using Tensor Parallelism</h2>

<p>So far, we’ve been restricting ourselves to minimizing latency while on a single GPU. In many settings, however, we have access to multiple GPUs. This allows us to improve our latency further!</p>

<p>To get an intuitive sense of why this would allow us to improve our latency, let’s take a look at the prior equation for MBU, particularly the denominator. Running on multiple GPUs gives us access to more memory bandwidth, and thus, higher potential performance.</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image8.png" alt="MBU"></p>

<p>As for which parallelism strategy to pick, note that in order to reduce our latency for one example, we need to be able to leverage our memory bandwidth across more devices simultaneously. This means that we need to split the processing of one token across multiple devices. In other words, we need to use tensor parallelism.</p>

<p>Luckily, PyTorch also provides low-level tools for tensor-parallelism that compose with torch.compile. We are also working on higher-level APIs for expressing tensor parallelism, stay tuned for those!</p>

<p>However, even without a higher-level API, it’s actually still quite easy to add tensor parallelism. Our implementation comes in at <a href="https://github.com/pytorch-labs/gpt-fast/blob/main/tp.py">150 lines of code</a>, and doesn’t require any model changes.</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image20.png" alt="code"></p>

<p>We are still able to take advantage of all the optimizations mentioned previously, which all can continue to compose with tensor parallelism. Combining these together, we’re able to serve Llama-70B at 55 tokens/s with int8 quantization!</p>

<p><img src="https://pytorch.org/assets/images/accelerating-generative-ai-2/image26.png" alt="chart"></p>

<h2 id="conclusion">Conclusion</h2>

<p>Let’s take a look at what we’re able to accomplish.</p>

<ol>
  <li>Simplicity: Ignoring quantization, <a href="https://github.com/pytorch-labs/gpt-fast/blob/main/model.py">model.py</a> (244 LOC) + <a href="https://github.com/pytorch-labs/gpt-fast/blob/main/generate.py">generate.py</a> (371 LOC) + <a href="https://github.com/pytorch-labs/gpt-fast/blob/main/tp.py">tp.py</a> (151 LOC) comes out to 766 LOC to implement fast inference + speculative decoding + tensor-parallelism.</li>
  <li>Performance: With Llama-7B, we’re able to use compile + int4 quant + speculative decoding to reach 241 tok/s. With llama-70B, we’re able to also throw in tensor-parallelism to reach 80 tok/s. These are both close to or surpassing SOTA performance numbers!</li>
</ol>

<p>PyTorch has always allowed for simplicity, ease of use, and flexibility. However, with torch.compile, we can throw in performance as well.</p>

<p>The code can be found here: <a href="https://github.com/pytorch-labs/gpt-fast">https://github.com/pytorch-labs/gpt-fast</a>. We hope that the community finds it useful. Our goal with this repo is not to provide another library or framework for people to import. Instead, we encourage users to copy-paste, fork, and modify the code in the repo.</p>

<h2 id="acknowledgements">Acknowledgements</h2>

<p>We would like to thank the vibrant open source community for their continual support of scaling LLMs, including:</p>

<ul>
  <li>Lightning AI for supporting pytorch and work in flash attention, int8 quantization, and LoRA fine-tuning.</li>
  <li>GGML for driving forward fast, on device inference of LLMs</li>
  <li>Andrej Karpathy for spearheading simple, interpretable and fast LLM implementations</li>
  <li>MLC-LLM for pushing 4-bit quantization performance on heterogenous hardware</li>
</ul>

                </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The weirdest bug I've seen yet (461 pts)]]></title>
            <link>https://engineering.gusto.com/the-weirdest-bug-ive-seen-yet/</link>
            <guid>38477100</guid>
            <pubDate>Thu, 30 Nov 2023 18:29:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://engineering.gusto.com/the-weirdest-bug-ive-seen-yet/">https://engineering.gusto.com/the-weirdest-bug-ive-seen-yet/</a>, See on <a href="https://news.ycombinator.com/item?id=38477100">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h3 id="how-digging-into-an-on-call-issue-led-to-an-unlikely-culprit">How digging into an on-call issue led to an unlikely culprit</h3><figure><img src="https://images.unsplash.com/photo-1565635897404-6c9a6515cc91?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDJ8fExlYWZob3BwZXJ8ZW58MHx8fHwxNzAwNjg3MjM4fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="red and yellow insect" loading="lazy" width="4496" height="2997" srcset="https://images.unsplash.com/photo-1565635897404-6c9a6515cc91?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDJ8fExlYWZob3BwZXJ8ZW58MHx8fHwxNzAwNjg3MjM4fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1565635897404-6c9a6515cc91?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDJ8fExlYWZob3BwZXJ8ZW58MHx8fHwxNzAwNjg3MjM4fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1565635897404-6c9a6515cc91?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDJ8fExlYWZob3BwZXJ8ZW58MHx8fHwxNzAwNjg3MjM4fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1565635897404-6c9a6515cc91?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDJ8fExlYWZob3BwZXJ8ZW58MHx8fHwxNzAwNjg3MjM4fDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2400 2400w" sizes="(min-width: 720px) 720px"><figcaption><span>Photo by </span><a href="https://unsplash.com/@mariuszdabrowski?ref=engineering.gusto.com"><span>Mariusz Dabrowski</span></a><span> / </span><a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit"><span>Unsplash</span></a></figcaption></figure><h2 id="what-in-tarnation">What in tarnation?</h2><p>During one of my on-call rotations for our internal tools team, we got a report that Chrome was crashing for users of Gusto’s internal software. This was causing all sorts of interruptions to our normal customer service. Gusto employees in the middle of answering customer emails or phone calls might suddenly find themselves without visibility into customers’ accounts necessary to do their jobs.</p><figure><img src="https://lh7-us.googleusercontent.com/ExG_6KfMf8cUHrm9LmHDU2kBRAE_OMuKRAT7SO41Lp-kmih7BJ-kR9MNKHZwbo9qIqNgSRZ_52bRXbTKMlmeLv-TrMMUPMsOn2g-6YFjjdzA9MCcx9JtgZxt0eKFhc_133dVzHFJP36SIpGkQwTrIw" alt="Chrome browser showing crash error" loading="lazy" width="619" height="297"><figcaption><span>Chrome tab crash</span></figcaption></figure><p>This was fairly far outside the usual scope of our on-call issues. Our team is generally well-insulated by other teams from issues like browser compatibility, so I didn’t know the first thing about browser debugging. Where would I even begin? I leaned on a more experienced teammate, our product infrastructure team, and our IT team. </p><h2 id="the-first-clues">The first clues&nbsp;</h2><p>We started by trying to find out what the affected users had in common.</p><p>We learned rather quickly that:</p><ul><li>Not all Gusto employee users were affected.</li><li>Our customer-facing software did not appear to be affected.</li><li>Other internal software webpages appeared to be fine.</li><li>Crashing did not occur consistently. Users who experienced it could reload the same page multiple times, and sometimes it would crash and sometimes it would not.</li><li>Not all of our internal pages crashed, but more than one of them did, including our most heavily-trafficked pages.</li><li>The issue was not occurring with Safari or Firefox.</li></ul><h3 id="hunch-1-a-bad-chrome-version">Hunch #1: A bad Chrome version</h3><p>Our first hunch was that maybe it was the Chrome version. We had one affected user update their Chrome version, and early signs looked promising that the issue was resolved. However, we soon learned that although installing the new Chrome version decreased the frequency of crashing, it didn’t eliminate the issue.</p><p>We added the following new clues to our list:</p><ul><li>The specific Chrome version had already been released for a while.</li><li>We had affected users on different versions of Chrome.</li><li>We had affected users and unaffected users on the same version of Chrome.</li><li>Upgrading/downgrading the Chrome version for affected users did not fix the issue.</li></ul><h3 id="hunch-2-a-bad-chrome-extension">Hunch #2: A bad Chrome extension</h3><p>Okay, maybe it was a Chrome extension? We thought the crashing stopped when one of our users disabled three core extensions. When we tried to reproduce the fix with a guest profile (without extensions present), we still saw crashing. Back to the drawing board, then.</p><h2 id="trouble-reproducing-the-bug">Trouble reproducing the bug</h2><p>Our Infrastructure team put out a call to all of engineering to ask if anyone could reproduce the issue. Frustratingly, although many of our customer service representatives were affected, none of our engineering teams reported any crashes at all except for two engineers in Turkey. With precious little overlap in available pairing time due to time zone differences, we slowly learned the following over several weeks:</p><ul><li> For security reasons, we do not have Chrome crash reporting enabled.</li><li>Checking out code from several weeks prior did not fix the issue, which indicated that the cause was not a recent change.</li><li>Loading a static html version of a crashing page did not cause crashing.</li><li>Using open-source Chromium instead of Chrome did not cause crashes, so we couldn’t see what Chrome code was failing either.</li><li>Several different internal applications were causing Chrome to crash, not just one.</li><li>Removing all of the page-specific content from the page did not fix the issue.</li><li>Disabling our in-house font did not fix the issue.</li></ul><p>As urgency waned because our users were using other browsers as a workaround, progress on this bug slowed to make way for other priorities. We didn’t have much left to go on without being able to reproduce the bug. However, we wanted to resolve it since users had bookmarks/settings/preferences in Chrome. We believed that we shouldn’t have to ask our users to avoid the world’s most popular browser, and we were also still getting periodic pings from various users asking whether we had made any progress on this bug.</p><h2 id="a-stroke-of-good-luck">A stroke of good luck</h2><p>One day out of the blue, one of our Denver engineers reported being newly affected. The only change she had made was downloading the Grammarly desktop app.</p><p>Wait, really? We had to see if we could reproduce the bug.</p><ul><li>I downloaded the Grammarly desktop app too. Instant reproduction of the issue (at last!).</li><li>I deleted Grammarly. The issue didn’t go away. I restarted my computer and the issue went away again.</li><li>I reinstalled Grammarly. Chrome started crashing again.</li></ul><p>We also confirmed with many of our affected users that they had Grammarly installed on their computers. Now we were cooking with fire!</p><h2 id="making-headway">Making headway</h2><p>With our ability to debug now greatly improved, we started making tedious headway: make a change, reload the page ten times or until it crashes.</p><p>Our main internal application is built on ActiveAdmin, but newer parts of it use React without the same ActiveAdmin framework as the rest of the application. The pages that are built in React did not crash. Hmm, so maybe our ActiveAdmin code was causing the crashes?</p><p>We learned earlier that removing all page-specific content did not fix the issue, so we started looking at parts of the code that were common to multiple pages, like the main navigation header and sidebar. Notably, our React pages do not use the same navigation header.</p><p>The code for our main navigation bar has a fair amount of metaprogramming, and chasing down threads here was often more confusing than not. We eventually figured out how to comment out pieces of the navigation bar, until we pinpointed one line that stopped crashing Chrome when it was commented out:</p><pre><code>dropdown 'My History', [], turbo: true, src: '/navigation/my_history'
</code></pre><p>This section is called “My History” and it differs from the rest of the main navigation in that instead of being more-or-less the same for all users, it is customized for each user, displaying the handful of pages that each user has visited most recently. We discovered that even when the page loaded successfully, hovering over the “My History” section could cause Chrome to immediately crash.</p><h2 id="so-close-we-can-smell-it">So close we can smell it</h2><h3 id="hunch-3-turbo">Hunch #3: Turbo</h3><p>Then we looked at <code>turbo: true</code>. Could that be causing the issue? <a href="https://github.com/hotwired/turbo-rails?ref=engineering.gusto.com"><u>Turbo</u></a> is a gem we added to speed up our Rails application, but it turned out to be a red herring: it was only introduced after the bug had already been reported, and we learned that the engineer who introduced it had actually been experiencing these Chrome crashes for months prior to Turbo being introduced, and months prior to the bug being escalated to us.</p><p>Okay, so where was the dropdown being defined? We use a framework called <a href="https://activeadmin.github.io/arbre/?ref=engineering.gusto.com"><u>Arbre</u></a> to metaprogram html from this type of method. To navigate the internal plumbing, I turned to one of our engineers with deep Rails knowledge. In this case, the relevant code (once we finally found it) looked like this:</p><figure><pre><code>ul(class: 'dropdown-menu') do
  li(style: 'text-align: center;') { frontend_image_pack 'loaders/loader-spinner.gif' } if has_spinner
  menu_items.each do |item|
    li(id: "#{attributes[:id]}_#{item.id}") do
       text_node link_to item.name, item.url
     end
   end
 end</code></pre><figcaption><p><span>Rails code for drop down menu</span></p></figcaption></figure><p>This code generates html that looked something like this:</p><figure><pre><code>&lt;ul class="dropdown-menu"&gt;
  &lt;li style="text-align: center;"&gt;
    &lt;img src="/vite-dev/images/loaders/loader-spinner.gif" /&gt;
  &lt;/li&gt;
  &lt;li id="recent_companies_123"&gt;
    &lt;a href="/companies/123"&gt;Totally Awesome Company A&lt;/a&gt;
  &lt;/li&gt;
  &lt;li id="recent_companies_124"&gt;
    &lt;a href="/companies/124"&gt;Even More Awesome Company B&lt;/a&gt;
  &lt;/li&gt;
&lt;/ul&gt;</code></pre><figcaption><p><span>HTML for drop down menu</span></p></figcaption></figure><p>We replaced the call to dropdown with the generated html, removing pieces of the new html until we zeroed in on the culprit.</p><h2 id="eureka">Eureka!</h2><p>When I removed <code>loader-spinner.gif</code>, the placeholder we display while the menu options load, the page stopped crashing. Eureka! It’s the gif! We swapped in a different gif and the page did not crash.</p><p>We downloaded the image file and dragged the file into the browser window. With Shakespearean melodrama, the page immediately crashed. My pair and I both audibly gasped.</p><p>We also found out that:</p><ul><li>Opening the file in Safari did not cause a crash.</li><li>After uninstalling Grammarly and restarting the computer, the gif loaded in Chrome without crashing.</li></ul><p>At this point, we notified our Design Systems team of the very peculiar fact that this gif was causing Chrome to crash, and they promptly replaced it with a new one.&nbsp;</p><figure><img src="https://engineering.gusto.com/content/images/2023/11/Screen-Shot-2022-08-04-at-9.42.49-AM--1-.png" alt="Pull request change for swapping the problem GIF" loading="lazy" width="2000" height="779" srcset="https://engineering.gusto.com/content/images/size/w600/2023/11/Screen-Shot-2022-08-04-at-9.42.49-AM--1-.png 600w, https://engineering.gusto.com/content/images/size/w1000/2023/11/Screen-Shot-2022-08-04-at-9.42.49-AM--1-.png 1000w, https://engineering.gusto.com/content/images/size/w1600/2023/11/Screen-Shot-2022-08-04-at-9.42.49-AM--1-.png 1600w, https://engineering.gusto.com/content/images/size/w2400/2023/11/Screen-Shot-2022-08-04-at-9.42.49-AM--1-.png 2400w" sizes="(min-width: 720px) 720px"><figcaption><span>Pull request for swapping the problematic GIF</span></figcaption></figure><p>Why did this particular gif crash Chrome when Grammarly was installed? Unfortunately, with access to neither the Chrome source code nor the Grammarly source code, we can only guess. In the time since we replaced the gif, either Grammarly or Chrome or both have fixed this issue, because the original gif no longer causes Chrome to crash.</p><h2 id="epilogue">Epilogue</h2><p>I would never, ever have guessed that the treasure at the end of the debugging rainbow was an animated gif.&nbsp;</p><p>Even though the priority of this bug changed over time as we found workarounds, relentless curiosity won out in the end. No single one of us had all of the necessary knowledge to solve this bug on their own, but with persistence and collaboration, we were able to figure it out together.</p><p>If you also enjoy collaborating with relentlessly curious people, <a href="http://www.gusto.com/careers?ref=engineering.gusto.com" rel="noreferrer">we are hiring</a>!</p><hr><p>Hats off to the many people who collaborated to investigate and fix this issue: Iain McGinniss, Lucy Fox, Gregor MacDougall, Oguzhan Ince, Can Gençler, Daniel Flynn, Eric Nagy, Lijie Zhou, Harry Seeber, Nathaniel Strauss, and Steve Konves.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You do need a technical co-founder (221 pts)]]></title>
            <link>https://www.ycombinator.com/blog/why-you-really-do-need-a-technical-co-founder/</link>
            <guid>38477057</guid>
            <pubDate>Thu, 30 Nov 2023 18:25:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ycombinator.com/blog/why-you-really-do-need-a-technical-co-founder/">https://www.ycombinator.com/blog/why-you-really-do-need-a-technical-co-founder/</a>, See on <a href="https://news.ycombinator.com/item?id=38477057">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>As YC Group Partners, we’re consistently surprised that anyone looking to start a VC-funded tech company would need to be <strong>convinced</strong> they need a technical co-founder. The usual arguments are that no-code tools, part-time consultants, or dev shops can allow anyone with a business idea to start a tech startup and raise money. </p><p><em>“New tools make starting a venture-funded tech company easy for anyone to do!”</em> is an inspiring story that gets clicks on LinkedIn... &nbsp;but based on the thousands of companies YC has funded over the years, companies lacking a technical co-founder underperform. </p><p>In this episode of <a href="https://www.ycombinator.com/library/carousel/Dalton%20&amp;%20Michael">Dalton + Michael</a>, we’ll discuss exactly why that is and why recruiting a technical co-founder is the single biggest way to create value as someone trying to start the next big thing.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Animate Anyone: Image-to-video synthesis for character animation (233 pts)]]></title>
            <link>https://humanaigc.github.io/animate-anyone/</link>
            <guid>38476482</guid>
            <pubDate>Thu, 30 Nov 2023 17:45:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://humanaigc.github.io/animate-anyone/">https://humanaigc.github.io/animate-anyone/</a>, See on <a href="https://news.ycombinator.com/item?id=38476482">Hacker News</a></p>
<div id="readability-page-1" class="page">


  <div>
            <h2>Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation</h2>
            

                  <p><span>Institute for Intelligent Computing，Alibaba Group</span>
                  </p>

                  
        </div>


<!-- Teaser video-->

<!-- End teaser video -->

<!-- Paper abstract -->
<div>
        <h2>Abstract</h2>
        <p>
            Character Animation aims to generating character videos from still images through driving signals. Currently, diffusion models have become the mainstream in visual generation research, owing to their robust generative capabilities. However, challenges persist in the realm of image-to-video, especially in character animation, where temporally maintaining consistency with detailed information from character remains a formidable problem. In this paper, we leverage the power of diffusion models and propose a novel framework tailored for character animation. To preserve consistency of intricate appearance features from reference image, we design ReferenceNet to merge detail features via spatial attention. To ensure controllability and continuity, we introduce an efficient pose guider to direct character's movements and employ an effective temporal modeling approach to ensure smooth inter-frame transitions between video frames. By expanding the training data, our approach can animate arbitrary characters, yielding superior results in character animation compared to other image-to-video methods. Furthermore, we evaluate our method on benchmarks for fashion video and human dance synthesis, achieving state-of-the-art results.
          </p>
      </div>
<!-- End paper abstract -->





<!-- Youtube video -->
<div>
      <!-- Paper video. -->
      <h2>Video</h2>
      <div>
          
          <p>
            <!-- Youtube embed code here -->
            <iframe src="https://www.youtube.com/embed/8PCn5hLKNu4?si=8yvBeRNAJuxp77FZ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>
          </p>
        </div>
    </div>
<!-- End youtube video -->


<!-- Image carousel -->
<div>
      <h2>Method</h2>
      <div>
        <!-- Your image here -->
        <p><img src="https://humanaigc.github.io/animate-anyone/static/images/f2_img.png" alt="MY ALT TEXT"></p><h2>
          The overview of our method. The pose sequence is initially encoded using Pose Guider and fused with multi-frame noise, followed by the Denoising UNet conducting the denoising process for video generation. The computational block of the Denoising UNet consists of Spatial-Attention, Cross-Attention, and Temporal-Attention, as illustrated in the dashed box on the right. The integration of reference image involves two aspects. Firstly, detailed features are extracted through ReferenceNet and utilized for Spatial-Attention. Secondly, semantic features are extracted through the CLIP image encoder for Cross-Attention. Temporal-Attention operates in the temporal dimension. Finally, the VAE decoder decodes the result into a video clip.
       </h2>
     </div>
    </div>
<!-- End image carousel -->




<!-- Video carousel -->
<div>
      <h2>Animating Various Characters</h2>
      <h2>Human</h2>
      
    </div>
<!-- End video carousel -->


<!-- Video carousel -->
<div>
      <h2>Anime/Cartoon</h2>
      
    </div>
<!-- End video carousel -->


<!-- Video carousel -->
<div>
      <h2>Humanoid</h2>
      
    </div>
<!-- End video carousel -->



<!-- Video carousel -->
<div>
      <h2>Comparisons</h2>
      <h2>Fashion Video Synthesis</h2>
      
      <h2>
        Fashion Video Synthesis aims to turn fashion photographs into realistic, animated videos using a driving pose sequence. Experiments are conducted on the UBC fashion video dataset with same training data. 
    </h2></div>
<!-- End video carousel -->



<!-- Video carousel -->
<div>
      <h2>Human Dance Generation</h2>
      
      <h2>
        Human Dance Generation focuses on animating images in real-world dance scenarios. Experiments are conducted on the TikTok dataset with same training data. 
    </h2></div>
<!-- End video carousel -->








<!--BibTex citation -->
<div id="BibTeX">
    <h2>BibTeX</h2>
    <pre><code>@article{hu2023animateanyone,
      title={Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation},
      author={Li Hu and Xin Gao and Peng Zhang and Ke Sun and Bang Zhang and Liefeng Bo},
      journal={arXiv preprint arXiv:2311.17117},
      website={https://humanaigc.github.io/animate-anyone/},
      year={2023}
}</code></pre>
  </div>


  



<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  
  
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Proposal on implementing permanent time zones in the European Union (161 pts)]]></title>
            <link>https://timeuse.barcelona/projects/permanent-time-zones-eu/</link>
            <guid>38476001</guid>
            <pubDate>Thu, 30 Nov 2023 17:11:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://timeuse.barcelona/projects/permanent-time-zones-eu/">https://timeuse.barcelona/projects/permanent-time-zones-eu/</a>, See on <a href="https://news.ycombinator.com/item?id=38476001">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-id="59c8162" data-element_type="container" data-settings="{&quot;content_width&quot;:&quot;boxed&quot;}" data-core-v316-plus="true">
				
				<div data-id="8128afb" data-element_type="widget" data-widget_type="text-editor.default">
							<p>The proven benefits of clocks being aligned with solar time and the negative impact of misaligned clocks on health, the economy, education, safety, and the environment urge for the implementation of permanent time zones as close as possible to solar time (natural time) in Europe.</p><p>The <a href="https://timeuse.barcelona/barcelona-declaration-on-time-policies/">Barcelona Declaration on Time Policies</a> working group to end clock changes has agreed on a plan to end clock changes and implement permanent time zones in the EU. The key elements of the proposal are presented below. Considering the benefits of geographically correct time zones and the negative consecuences of misaligned clocks:</p>						</div>
				<div data-id="fc52c25" data-element_type="widget" data-widget_type="text-editor.default">
							<ul><li>The <strong>EU Commission</strong> has the responsibility to reactivate the political process on this subject.</li><li>The <strong>EU Member States</strong> have the responsibility to ratify the EU proposal (European Directive on Discontinuing seasonal changes of time) and agree to adopt the permanent time zones which are as close as possible to their solar time (natural time).</li></ul>						</div>
				<div data-id="ef0360d" data-element_type="widget" data-widget_type="text-editor.default">
							<p>For the <strong>European continent</strong> there is an <strong>easy solution</strong> which does not require a patchwork of time zones. The following map shows the recommended time zones and steps to be taken for all 27 EU member states. We are aware that political considerations will need to be made for those member states that have territories in different time zones. One possible solution is the one being applied in the case of Spain and the Canary Islands, that have different time zones. In some cases, if the territories are close, the same time zone may be used, even if not geographically correct. This can be the case for the situation of Northern Ireland and Ireland or France and Corsica.</p><p>Specific solutions need to be found for European territories outside the European continent.</p>						</div>
				<div data-id="1753de4" data-element_type="widget" data-widget_type="image.default">
				<p><img loading="lazy" decoding="async" width="480" height="481" src="https://timeuse.barcelona/wp-content/uploads/2023/02/europe_map_timezone1.webp" alt="natural time zones in europe" srcset="https://timeuse.barcelona/wp-content/uploads/2023/02/europe_map_timezone1.webp 480w, https://timeuse.barcelona/wp-content/uploads/2023/02/europe_map_timezone1-300x300.webp 300w, https://timeuse.barcelona/wp-content/uploads/2023/02/europe_map_timezone1-150x150.webp 150w" sizes="(max-width: 480px) 100vw, 480px">															</p>
				</div>
				<div data-id="5711582" data-element_type="widget" data-widget_type="text-editor.default">
				<p><strong>Map:</strong> Recommended time zones for the European continent</p>
				</div>
				<div data-id="49e5801" data-element_type="widget" data-widget_type="text-editor.default">
							<p>After agreement of a common date within the EU, we recommend doing the transition in 1 to 2 steps, depending on the member state:</p><ul><li><strong>Step 1</strong>: All EU countries abolish the clock change to DST in spring and remain on the clock time they use in winter. For those countries whose recommended time zone is their current standard time, no further steps need to be taken.</li><li><strong>Step 2</strong>: Those countries whose recommended time zone is not yet their current standard time, additionally turn back their clocks one last time by one hour in autumn, in order to adopt their recommended time zone as their new standard time.</li></ul><p><strong>Would you like to know more?</strong></p><p>Read the full document, including a justification for our recommendation, in <a href="https://timeuse.barcelona/wp-content/uploads/2023/02/proposal-on-implementing-permanent-time-EN.pdf">English</a>, <a href="https://timeuse.barcelona/wp-content/uploads/2023/02/Proposition-pour-la-mise-en-oeuvre.pdf">French</a>, <a href="https://timeuse.barcelona/wp-content/uploads/2023/02/Vorschlag-zur-einfuhrung.pdf">German</a>, <a href="https://timeuse.barcelona/wp-content/uploads/2023/02/voorstel-tel-invoering-van-vaste.pdf">Dutch</a>, <a href="https://timeuse.barcelona/wp-content/uploads/2023/02/propuesta-para-la-implementacion-de-zonas-horarias.pdf">Spanish</a>, and <a href="https://timeuse.barcelona/wp-content/uploads/2023/02/proposta-de-implementacao-de-fusos.pdf">Portuguese</a>.</p>						</div>
				<div data-id="87082aa" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>Frequently Asked Questions on Daylight Saving Time (DST)</h2>		</p>
				</div>
				
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to ripen and store avocados (253 pts)]]></title>
            <link>https://www.seriouseats.com/how-to-ripen-avocados-7377071</link>
            <guid>38475926</guid>
            <pubDate>Thu, 30 Nov 2023 17:05:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.seriouseats.com/how-to-ripen-avocados-7377071">https://www.seriouseats.com/how-to-ripen-avocados-7377071</a>, See on <a href="https://news.ycombinator.com/item?id=38475926">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="mntl-sc-page_1-0" data-sc-sticky-offset="100" data-sc-ad-label-height="11" data-sc-ad-track-spacing="100" data-sc-min-track-height="250" data-sc-max-track-height="600" data-sc-breakpoint="50em" data-sc-load-immediate="5" data-sc-content-positions="[1, 1, 1, 1250, 1, 1, 1, 1]" data-bind-scroll-on-start="true">
<p id="mntl-sc-block_1-0">
Avocados occupy an interesting place among commercially popular fruits. Unlike most other fruit, avocados do not ripen on the tree—they only begin ripening off the tree after reaching full maturity. But then the race to ripeness is off and running, and, in the case of avocados, that race is relatively quick, with limited opportunities for long-term storage.
</p>

<p id="mntl-sc-block_1-0-2">
These two facts put the concerns of commercial avocado growers, shippers, and vendors exactly opposite of those of the home cook. Those in the avocado industry want to find as many ways as possible to delay ripening of the picked fruit for as long as possible, buying them as much time as possible to get the avocados from the filed to your kitchen counter in good condition. Through lots of study, they've become pretty good at that—by lowering temperatures, reducing environmental oxygen and boosting carbon dioxide, shrink-wrapping or waxing the fruit, and other techniques, the avocado industry can manage to keep the fruit in its mature-but-unripe state all the way to the point of sale, despite significant shipping distances and other challenges.
</p>

<p id="mntl-sc-block_1-0-4">
The home cook, on the other hand, usually wants to know how the heck to speed up ripening so they can eat the darned thing. This can present a timing challenge when shopping for and eating avocados because, to put it bluntly, perfectly ripe avocados are a pain in the ass to find. The window of time in which they are absolutely perfect—soft and tender with no brown spots or streaks—is notoriously short. It can make planning an avocado-based party a harrowing experience. <em>Will my avocados ripen in time for game day? What if they turn brown?</em>
</p>

<p id="mntl-sc-block_1-0-6">
Fortunately, there are a few ways to moderate the rate at which they ripen, and then there are some ways other articles on this topic recommend, but we don't. Read on for more.<br>
</p>

<h2 id="mntl-sc-block_1-0-8"> <span> How to Choose a Quality Avocado When Shopping </span> </h2>
<p id="mntl-sc-block_1-0-9">
We've all seen those avocados that <em>seem</em> perfect on the outside, but once you cut into them, a series of deep brown stripes and striations appear. What's up with that?
</p>

<p id="mntl-sc-block_1-0-11">
Unfortunately, it's not something that can be predicted or prevented. It's caused by uneven enzymatic action inside the avocado as it's developing and is exacerbated by extreme weather conditions and other seasonal, environmental, and agricultural factors.
</p>

<p id="mntl-sc-block_1-0-13">
For Hass avocados, you can expect the likelihood of this phenomenon to increase starting in December and maxing out around February. (Ack, Super Bowl season!)
</p>

<figure id="mntl-sc-block_1-0-15">

<figcaption id="mntl-figure-caption_1-0">
<span><p>Serious Eats / Amanda Suarez</p></span>
</figcaption>
</figure>
<p id="mntl-sc-block_1-0-16">
Another common flaw in some avocados are woody strings that stretch through the flesh. These strings are part of the plant's vascular strands, responsible for transporting nutrients into the fruit. They're actually always there, but they only become noticeably woody and stringy later in the season as the avocado becomes more mature.
</p>

<p id="mntl-sc-block_1-0-18">
Unfortunately, just as with the brown spots, there's no way to predict which avocados will have these strands until you've cut into it, aside from knowing that the likelihood of encountering them goes up later in the growing season, with fruit harvested in the late summer and early fall (though this will vary depending on the avocado variety and growing region).
</p>

<h2 id="mntl-sc-block_1-0-20"> <span> How to Know If an Avocado Is Ripe </span> </h2>
<p id="mntl-sc-block_1-0-21">
While the color of the avocado's skin can change as ripening progresses, that is not a reliable way to determine perfect ripeness, since avocado skin color can vary from variety to variety and fruit to fruit. Better is to gauge ripeness by touch: Using your fingers, very gently press on the avocado near the stem end (that's where the avocado was once attached to the tree). You want to feel a slight tenderness and give. If the avocado is very firm, it's not ready; if it feels soft and mushy, it's gone too far.
</p>

<h2 id="mntl-sc-block_1-0-23"> <span> The Best Ways to Ripen Avocados: Tested </span> </h2>
<p id="mntl-sc-block_1-0-24">
Ripening in avocados and many other fruits is regulated by a gas called ethylene. It's produced naturally by the fruit itself and is intended to make sure that all the fruit in one area ripens at the same time. The higher the concentration of ethylene, the faster your fruit ripens. <em>That's</em> why you'll see instructions to leave underripe avocados or bananas in paper bags—it concentrates ethylene and causes fast ripening.
</p>

<figure id="mntl-sc-block_1-0-26">

<figcaption id="mntl-figure-caption_1-0-1">
<span><p>Serious Eats / Amanda Suarez</p></span>
</figcaption>
</figure>
<p id="mntl-sc-block_1-0-27">
Left on its own, it generally takes an underripe avocado somewhere in the range of three-to-five days when stored in a paper bag at room temperature. If you need your avocados sooner, you will need to turn to other fruit.
</p>

<h3 id="mntl-sc-block_1-0-29"> <span> How to Ripen Avocados Quickly </span> </h3>
<p id="mntl-sc-block_1-0-30">
In side-by-side tests tests, avocados from the supermarket showing no softness at all take between three-to-five days to ripen in a brown paper bag. Throw a banana in there (an ethylene powerhouse), and you can bring that range down to two-to-three days. It's not instant, but it does give you a wider range of control over having a ripe avocado when you need it.
</p>

<figure id="mntl-sc-block_1-0-32">

<figcaption id="mntl-figure-caption_1-0-2">
<span><p>Serious Eats / Amanda Suarez</p></span>
</figcaption>
</figure>
<p id="mntl-sc-block_1-0-33">
You could, for instance, buy several avocados, leaving some out in the open kitchen air, some in a brown paper bag, and yet a few more in a second brown paper bag with a banana added. By doing so, you'd stagger their ripeness-reaching days, with the banana-ripened avocados ready in a couple days, the paper bag ones a day or two after that, and the open-air ones ready right on the heels of those, assuming they all started at the same stage of un-ripeness.<br>
</p>

<h3 id="mntl-sc-block_1-0-35"> <span> Can You Ripen an Avocado in the Microwave? </span> </h3>
<p id="mntl-sc-block_1-0-36">
This is one of those popular internet and social media tips that sound so good, we all just want to believe it's true. <em>You can rapidly ripen an avocado in the microwave?! Thank you, TikTok!</em>
</p>

<p id="mntl-sc-block_1-0-38">
But we're sorry to say, having tried it ourselves, it's a terrible method.
</p>

<p id="mntl-sc-block_1-0-40">
The truth is, using the microwave (or a low oven for that matter) does not ripen an avocado at all, it <em>cooks</em> it. Indeed, there are similarities between cooking and ripening: In both cases the fruit's flesh softens as cell walls weaken, leading to a more tender texture. On top of that, new flavors and aromas develop. But the way the texture changes, and the nature of the flavor and aroma changes are not comparable between ripening and (even very, very gentle) cooking. While a properly ripened avocado grows buttery and creamy as time passes, a microwaved one becomes slick and sweaty, and soft like a lit candle—overly mushy in the hotter spots and still too firm in others.
</p>

<p id="mntl-sc-block_1-0-42">
The flavor of a microwaved avocado, though, is by far its greatest failing. We would describe it as re-warmed, undercooked chicken, a bizarre combination that somehow manages to smell simultaneously of the crudeness of raw poultry and <a href="https://www.seriouseats.com/what-is-warmed-over-flavor-leftover-chicken-meat" data-component="link" data-source="inlineLink" data-type="internalLink" data-ordinal="1">stink of reheated poultry</a>. A microwaved avocado might be easier to chew, but it's not easier to swallow.
</p>

<h2 id="mntl-sc-block_1-0-44"> <span> How to Store Ripe Avocados for Later </span> </h2>
<p id="mntl-sc-block_1-0-45">
Once ripened, an avocado will start to produce brown spots and streaks within about two days if left at room temperature. However, refrigerating a ripened avocado can increase that window up to around five days, though avocados are susceptible to chilling damage, so the will begin to show signs of browning if left too long.
</p>

<p id="mntl-sc-block_1-0-47">
The best way to guarantee perfect avocados for a Sunday night game? Buy them the Monday before, ripen them at room temperature in a brown paper bag and refrigerate them as soon as they soften.
</p>

<h2 id="mntl-sc-block_1-0-49"> <span> How to Prevent Avocados From Browning </span> </h2>
<p id="mntl-sc-block_1-0-50">
What about leftover avocado? Any way to keep it from browning? Oxygen is the enemy of avocados—it's what causes them to turn that unsightly brown. Plastic wrap works alright on cut avocado halves, but even plastic wrap is oxygen-permeable. In our tests, avocados didn't last more than about eight hours wrapped in plastic before visible browning occurred.
</p>

<p id="mntl-sc-block_1-0-52">
The old rub-with-oil-and-place-face-down-on-an-oiled-plate works fine if you've got a perfect half of an avocado with a smooth face, but it doesn't help if you've got, say, 3/4 or 1/4 of an avocado.
</p>

<figure id="mntl-sc-block_1-0-54">

<figcaption id="mntl-figure-caption_1-0-3">
<span><p>Serious Eats / Amanda Suarez</p></span>
</figcaption>
</figure>
<p id="mntl-sc-block_1-0-55">
The better short-term solution in that situation? Just submerge the sucker in water. Simply put any unused avocado pieces in a container filled with water in the fridge to keep oxidation at bay, but do note you can't hold them there for long. After several hours, a ripe avocado will begin to grow mushy where water has managed to penetrate it.
</p>

<p id="mntl-sc-block_1-0-57">
As for mashed avocado like guacamole, we think the best solution, aside from preparing it right before serving, is to press a double layer of plastic wrap directly against the surface of the avocado mixture. It's not a perfect solution—the avocado will still brown eventually—but you can mix in a minimal amount of browning such that diners won't know, buying yourself at least a few hours before it becomes a problem.
</p>

<div id="mntl-sc-block_1-0-59" data-tracking-id="mntl-sc-block-callout" data-tracking-container="true">
<h3 id="mntl-sc-block-callout-heading_1-0">
May 2023</h3>
<p>Portions of this article were originally written by Kenji Lopez-Alt as part of the headnote to his <a href="https://www.seriouseats.com/the-best-basic-guacamole-recipe" data-component="link" data-source="inlineLink" data-type="internalLink" data-ordinal="1">guacamole recipe</a>. Those sections were removed from that headnote and added to this article, with additional reporting, testing, and text by Daniel Gritzer.</p>
</div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google to pay Canada's "link tax," drops threat of removing news from search (109 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2023/11/google-to-pay-canadas-link-tax-drops-threat-of-removing-news-from-search/</link>
            <guid>38475921</guid>
            <pubDate>Thu, 30 Nov 2023 17:05:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2023/11/google-to-pay-canadas-link-tax-drops-threat-of-removing-news-from-search/">https://arstechnica.com/tech-policy/2023/11/google-to-pay-canadas-link-tax-drops-threat-of-removing-news-from-search/</a>, See on <a href="https://news.ycombinator.com/item?id=38475921">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      Discount deal    —
</h4>
            
            <h2 itemprop="description">Google previously threatened to remove Canadian news links from search and News.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/canada-flag-800x446.jpg" alt="Canada's national flag">
      <figcaption><p>Getty Images | Manuel Augusto Moreno</p></figcaption>  </figure>

  




<!-- cache hit 209:single/related:4c310763003c5297e632fbf074bbd782 --><!-- empty -->
<p>Google has agreed to pay Canadian news businesses $100 million a year to comply with the country's Online News Act, despite previously saying it would remove Canadian news links from search rather than make the required payments.</p>
<p>Google and government officials agreed to a deal that lets Google negotiate with a single news collective and reduce its overall financial obligation. Facebook owner Meta is meanwhile holding firm in its opposition to payments.</p>
<p>"Google will contribute $100 million in financial support annually, indexed to inflation, for a wide range of news businesses across the country, including independent news businesses and those from Indigenous and official-language minority communities," Minister of Canadian Heritage Pascale St-Onge said in a <a href="https://www.canada.ca/en/canadian-heritage/news/2023/11/statement-by-minister-st-onge-on-next-steps-for-the-online-news-act.html">statement</a> today.</p>
<p>The $100 million in Canadian currency is worth about $74 million in US currency. Before today's deal, the federal government <a href="https://www.cbc.ca/news/politics/online-news-act-google-meta-1.6954656">estimated</a> that Google would have to pay $172 million a year.</p>
<p>"After extensive discussions, the Canadian Government agreed to a number of changes to address our deeply held concerns that C-18 would require payment for links and create uncapped financial liability through an unworkable bargaining process, simply for helping Canadians find relevant and useful information," Google said in a statement provided to Ars.</p>
<p>The <a href="https://www.parl.ca/DocumentViewer/en/44-1/bill/C-18/royal-assent">C-18 law</a> contains a "duty to bargain" requiring large search engines and social media services to negotiate payments with news businesses or groups of news businesses. In June, six months before the law's implementation, <a href="https://arstechnica.com/tech-policy/2023/06/google-tells-canada-it-wont-pay-link-tax-will-pull-news-links-from-search/">Google said</a> it would not pay the "link tax" and instead would remove links to Canadian news sources from Google Search and Google News for users who access the services in Canada.</p>
<h2>Payments based on number of journalists</h2>
<p>Today, Google thanked St-Onge "for acknowledging our concerns and deeply engaging in a series of productive meetings about how they might be addressed." The resulting deal provides "a streamlined path to an exemption at a clear commitment threshold," <a href="https://blog.google/intl/en-ca/company-news/outreach-initiatives/an-update-on-canadas-bill-c-18-and-our-search-and-news-products/">Google said</a>.</p>                                            
                                                        
<p>"While we work with the government through the exemption process based on the regulations that will be published shortly, we will continue sending valuable traffic to Canadian publishers," Google said.</p>
<p>The Canadian government confirmed that Google will be allowed to negotiate with a single collective, instead of separately with multiple news organizations or groups of news organizations. "Google will have the option to work with a single collective to distribute its contribution to all interested eligible news businesses based on the number of full-time equivalent journalists engaged by those businesses," St-Onge said.</p>
<p>New rules to effect the change will be implemented before the Online News Act is enforced. St-Onge's announcement said the Canadian Heritage agency "will share more details about the final regulations following approval by the Treasury Board of Canada and prior to the Act coming into effect on December 19, 2023."</p>
<p>Google said that "under the revised regulations, there is a path for publishers to continue to receive valuable traffic... which Google can allocate through a deal with a single collective of its choosing. Importantly, this will allow Google to bypass the requirement to settle with publishers directly or individually, and any corresponding mandatory bargaining obligations."</p>
<h2>No Canadian news on Facebook</h2>
<p>Meta, the other company affected by the Online News Act, "ended its talks with the government last summer and stopped distributing Canadian news on Facebook and Instagram," the <a href="https://www.cbc.ca/news/politics/google-online-news-act-1.7043330">CBC noted</a> today.</p>
<p>Meta hasn't changed its stance. "Unlike search engines, we do not proactively pull news from the Internet to place in our users' feeds and we have long been clear that the only way we can reasonably comply with the Online News Act is by ending news availability for people in Canada," Meta told the CBC.</p>
<p>Canadian officials previously estimated that Facebook would have to pay $62 million a year, but the deal with Google suggests that Meta could lower that amount significantly. Meta reportedly hasn't resumed talks with the government.</p>
<p>"This [deal with Google] shows that this legislation works," St-Onge said, according to the CBC. "Now it's on Facebook to explain why they're leaving their platform to disinformation and misinformation instead of sustaining our news system."</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stanisław Lem's vision of artificial life (373 pts)]]></title>
            <link>https://thereader.mitpress.mit.edu/stanislaw-lems-prescient-vision-of-artificial-life/</link>
            <guid>38475545</guid>
            <pubDate>Thu, 30 Nov 2023 16:35:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thereader.mitpress.mit.edu/stanislaw-lems-prescient-vision-of-artificial-life/">https://thereader.mitpress.mit.edu/stanislaw-lems-prescient-vision-of-artificial-life/</a>, See on <a href="https://news.ycombinator.com/item?id=38475545">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>As with the best science fiction, Lem’s novel “The Invincible” has as much to teach us about our present situations as any futures we may face.</p><figure><img width="700" height="420" src="https://thereader.mitpress.mit.edu/wp-content/uploads/2023/09/the-invincible_lead-image-700x420.jpg" alt="" decoding="async" fetchpriority="high"></figure><p><em>In the grand tradition of H. G. Wells and Jules Verne, Stanisław Lem’s “The Invincible” tells the story of a space cruiser sent to an obscure planet to determine the fate of a sister spaceship whose communication with Earth has abruptly ceased. Landing on the planet Regis III, navigator Rohan and his crew discover a form of life that has apparently evolved from autonomous, self-replicating machines — perhaps the survivors of a “robot war.” Rohan and his men are forced to confront the classic quandary: What course of action can humanity take once it has reached the limits of its knowledge? In “The Invincible,” Lem has his characters confront the inexplicable and the bizarre: the problem that lies just beyond analytical reach. </em></p><p><em>The following is literary critic and theorist N. Katherine Hayles’ foreword to the <a href="https://mitpress.mit.edu/9780262538473/the-invincible/" target="_blank">2020 edition of Lem’s classic novel</a>, which was originally published in Polish in 1964. </em></p><hr><p>Science fiction has famously predicted many of the important technologies of the 20th century: space travel, satellites, the atomic bomb, television, the internet, and virtual reality, to name a few. In “The Invincible,” Stanisław Lem predicts another: artificial life. Although speculations about self-reproducing artificial systems date from the 1940s, the scientific field received its name from Christopher Langton only in 1986, more than two decades after the original publication of “The Invincible” (1964). One of the central controversies in artificial life is whether evolutionary programs and devices are actually alive (the strong version), or whether they merely simulate life (the weak version). Researchers who follow the strong version argue that the processes embedded in software programs such as genetic algorithms are as “natural” as life itself; what is artificial is the medium in which these processes take place.</p><div><figure><a href="https://mitpress.mit.edu/9780262538473/the-invincible/" target="_blank"><img decoding="async" width="320" height="476" src="https://thereader.mitpress.mit.edu/wp-content/uploads/2023/09/the-invincible-cover.jpg" alt=""></a><figcaption>This foreword first appeared in the 2020 English edition of Stanisław Lem’s novel “<a href="https://mitpress.mit.edu/9780262538473/the-invincible/" target="_blank">The Invincible</a>.”</figcaption></figure></div><p>The issue prompted Robert Rosen, among others, to speculate about the essential characteristics of “life itself,” not only as it evolved on Earth in carbon-based life forms but also about the possibility of life-as-it-could-be in exoplanetary systems, arguing that silicon-based artificial life forms may provide insight into these theoretical speculations.</p><p>“The Invincible” presents a fascinating hybridization of these different views. Dr. Lauda’s hypothesis proposes that a space ship from the Lycran system landed on Regis III millions of years ago; while the biological visitors perished, the automata did not. There then followed an evolutionary struggle between the automata and the planet’s indigenous life forms, on the one hand, and between the different kinds of automata, on the other. Such a scenario requires that the “survive and reproduce” mandate that governs life on Earth could also operate on this planet. Lem minimally fulfills the requirement by postulating that the automata could manufacture themselves with modifications dictated by evolutionary processes. Clearly his interest is not in filling out how this might take place (John von Neumann, encountering a similar problem, imagined metal parts floating on a lake that could self-assemble). Rather, Lem’s focus is on envisioning an artificial life form that won the evolutionary competition on Regis III for profoundly different reasons than did <em>Homo sapiens</em> on Earth.</p><p>The effect is achieved by introducing a significant factor that has a monumental impact on evolutionary trajectories: rather than fulfilling their energy needs through ingesting food, the automata on Regis III evolve to use solar power. The smaller the artificial organism, the less energy it needs. Hence the evolutionary driver is toward smaller forms, which overcome not through superior intellect but through swarm intelligence. Lem added to this the ability of the swarm of “flies” to generate immensely powerful electromagnetic fields, which meant that the tiny automata are not only the evolutionary winners on their planet but a powerful force against the invading humans. Their tiny size notwithstanding, their awesome potential illuminates the profound ambiguity of the work’s title, which can be taken to refer either to the spaceship’s proud name or to the swarms of alien automata that threaten it.</p><figure><blockquote><p>“From a broader cosmic perspective, the best of human science, engineering, and weaponry may reveal humans to be completely out of our depth, mere kindergarteners bidding for a place in the universe’s adult civilizations.”</p></blockquote></figure><p>Contemporary research in artificial life has validated Lem’s insight that swarms of artificial beings require only a few simple rules to manifest complex behaviors and hence each member needs to carry only a little cognitive power onboard. Computer simulations that have accurately depicted swarm behaviors in fish, birds, bees, and other biota demonstrate that each individual responds only to the four or five closest to it, with rule sets that take up only a few lines of code. For example, a school of fish swimming to evade a predator is guided by the fish closest to the predator. The direction this most imperiled individual follows determines how the entire school will run as it flashes back and forth, a simple strategy that makes excellent sense, since the fish that has the most to lose will try hardest to escape. Although each fish’s behaviors are simple, the collective result nevertheless generates swarm intelligence of considerable complexity.</p><p>Decades before these ideas became disseminated within the scientific community, Lem intuited that different environmental constraints might lead to radically different evolutionary results in automata compared to biological life forms. Although on Earth the most intelligent species (i.e., humans) has tended to fare the best, their superior intelligence comes with considerable costs: a long period of maturation; a lot of resources invested in each individual; socialization patterns that emphasize pair bonding and community support; and a premium on individual achievement. But these are not cosmic universals, and different planetary histories might result in the triumph of very different kinds of qualities.</p><p>The contrasts between humans and the automata swarm are brought out most poignantly in the scene between Captain Horpach and First Officer Rohan, in which the captain delegates to Rohan the decision whether to put another crew member in grave danger to determine if the missing four men have indeed perished, as seems all but certain, or whether one or more might still be alive. The assumptions that make this gamble even remotely worth taking are revealing: human life is precious; human solidarity depends on the crew’s belief that everything possible will be done to save them if they are in peril; and every human is unique and therefore uniquely valuable. None of these, of course, holds true for the swarm, whose individual members are virtually identical to one another, with each tiny automaton easily replaced and therefore disposable. Consequently, none is valuable in itself; only the swarm has evolutionary survival value. The contest, then, is not only between different life forms but also between the different values that have resulted from the divergent evolutionary pathways of humans on Earth and the “flies” on this strange planet. As with “Solaris,” Lem suggests that assumptions born and bred of Earth may appear hopelessly provincial in light of human encounters with radically different life forms. From a broader cosmic perspective, the best of human science, engineering, and weaponry may reveal humans to be completely out of our depth, mere kindergarteners bidding for a place in the universe’s adult civilizations. The reduction of crew members to infancy when attacked by the “flies” may be a metaphor for this realization.</p><p>Of all the human characters, Rohan has the strongest claim to have encountered the planet on its own terms. He has traversed its terrain with his own feet; he has mixed his sweat with its crevices, valleys, and hills; he has breathed its native atmosphere into his lungs. The insight he gains from his heroic trek therefore commands our respect. When he concludes that “not everything everywhere is for us [humans],” we are right to hear in this pronouncement Lem’s own challenge to the anthropocentric assumptions that continue to dominate human ethical frameworks as well as human exploitations of planet Earth. As with the best science fiction, “The Invincible” has as much to teach us about our present situations as any futures we may face.</p><hr><p><em><strong>N. Katherine Hayles</strong> is Distinguished Research Professor of English at the University of California, Los Angeles. </em></p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Large language models lack deep insights or a theory of mind (254 pts)]]></title>
            <link>https://arxiv.org/abs/2311.16093</link>
            <guid>38474696</guid>
            <pubDate>Thu, 30 Nov 2023 15:31:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2311.16093">https://arxiv.org/abs/2311.16093</a>, See on <a href="https://news.ycombinator.com/item?id=38474696">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2311.16093.pdf">Download PDF</a></p><blockquote>
            <span>Abstract:</span>A chief goal of artificial intelligence is to build machines that think like people. Yet it has been argued that deep neural network architectures fail to accomplish this. Researchers have asserted these models' limitations in the domains of causal reasoning, intuitive physics, and intuitive psychology. Yet recent advancements, namely the rise of large language models, particularly those designed for visual processing, have rekindled interest in the potential to emulate human-like cognitive abilities. This paper evaluates the current state of vision-based large language models in the domains of intuitive physics, causal reasoning, and intuitive psychology. Through a series of controlled experiments, we investigate the extent to which these modern models grasp complex physical interactions, causal relationships, and intuitive understanding of others' preferences. Our findings reveal that, while these models demonstrate a notable proficiency in processing and interpreting visual data, they still fall short of human capabilities in these areas. The models exhibit a rudimentary understanding of physical laws and causal relationships, but their performance is hindered by a lack of deeper insights-a key aspect of human cognition. Furthermore, in tasks requiring an intuitive theory of mind, the models fail altogether. Our results emphasize the need for integrating more robust mechanisms for understanding causality, physical dynamics, and social cognition into modern-day, vision-based language models, and point out the importance of cognitively-inspired benchmarks.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Luca M. Schulze Buschoff [<a href="https://arxiv.org/show-email/c28c6de2/2311.16093">view email</a>]      <br>    <strong>[v1]</strong>
        Mon, 27 Nov 2023 18:58:34 UTC (4,181 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Astronomers find six planets orbiting in resonance (177 pts)]]></title>
            <link>https://www.astronomy.com/science/astronomers-find-six-planets-orbiting-in-resonance/</link>
            <guid>38474364</guid>
            <pubDate>Thu, 30 Nov 2023 15:06:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.astronomy.com/science/astronomers-find-six-planets-orbiting-in-resonance/">https://www.astronomy.com/science/astronomers-find-six-planets-orbiting-in-resonance/</a>, See on <a href="https://news.ycombinator.com/item?id=38474364">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

					<div>
				<p><img width="620" height="413" src="https://www.astronomy.com/wp-content/uploads/sites/2/2023/11/HD110067-system-.jpeg?fit=620%2C413" alt="Artist's representation of the HD110067-system from above"></p><p>
						The six planets of the HD 110067 system, shown in this artist's depiction, orbit in a resonant chain that links their periods mathematically. Credit: © CC BY-NC-SA 4.0, Thibaut Roger/NCCR PlanetS					</p>
							</div>
		
		
<p>A newly discovered system of six planets circling a nearby Sun-like star may be the key to unlocking how planetary systems form. All between the size of Earth and Neptune, the worlds are orbiting in a so-called resonant chain — a configuration that it’s relatively rare to observe in nature, making the system a valuable find that offers a window into a uniquely “gentle” history. &nbsp;</p>



<p>The discovery was published today in <em><a href="https://www.nature.com/articles/s41586-023-06692-3">Nature</a></em>.</p>



<h2><strong>Links in a chain</strong></h2>



<p>The planets’ path to discovery spawned from an initial detection in 2020 by NASA’s <a href="https://www.astronomy.com/science/tess-a-behind-the-scenes-look-at-nasas-latest-planet-hunter/">Transiting Exoplanet Survey Satellite (TESS)</a>, which searches for dips in brightness as planets cross in front of their parent star. At that time, based on the dips, researchers were able to confirm one planet and posit a second possible world.</p>



<p>But TESS only observes a given patch of sky for about two months before moving on; it doesn’t return for two years. TESS finally observed the star again in 2022, yielding more transits. This revealed a sure second planet, but there were still more transits than could be explained by two worlds.</p>



<p><strong>RELATED: </strong><a href="https://www.astronomy.com/science/ask-astro-how-many-exoplanets-does-the-transit-method-miss/">How many exoplanets does the transit method miss? </a></p>



<p>So, the team turned to a different telescope: the European Space Agency’s CHaracterising ExOPlanets Satellite (Cheops), to observes the star without the limitations of a survey timetable. Using Cheops, they watched for additional transits from further planets. And after five or six observations, “we got a hit, like a battleship,” said study co-author Hugh Osborn, CHESS Fellow at the MIT Kavli Institute for Astrophysics in the U.S. and the University of Bern in Switzerland, during a press briefing Tuesday morning.</p>



<p>They’d found a third planet. Looking at the orbits together, the researchers noticed something intriguing. Each planet’s orbital period was related to the next in line: The inner planet (called b) orbits every 9.114 days, the next planet out (c) every 13.673 days, and the last (d) every 20.519 days. Each of those periods is about 1.5 times the next, meaning the planets are in a configuration called a 3:2 (pronounced “three to two”) mean motion resonance. For every three orbits of the innermost world, b, the next planet out (c) makes two. Then, for every three orbits of c, d makes two.</p>



<p>The team followed the pattern to look for more worlds in this “resonant chain.” First, they modeled how often various additional planets in different resonances would transit, picking out the configurations that were most stable.</p>



<p>Then, they went looking for the transits they expected from those models — and found three more planets: e, f, and g, with periods of 30.793, 41.059, and 54.770 days, respectively. The entire system could fit inside the orbit of Mercury.</p>



<p>In all, the innermost four planets are in a 3:2 resonance. The outer planets f and g are in 4:3 resonance — for every four orbits of the planet interior to it, next planet out makes three full revolutions. Overall, for every six orbits the innermost planet b makes, the outermost planet g makes one full revolution.</p>



<p>“Often we make the predictions and nature finds a way to do something else, to not quite match what we expect,” said Osborn. But in this case, nature was spot-on. Osborn recalled he was “shocked and delighted” when they began spotting planets transiting right when their models suggested: “My jaw was on the floor.”</p>



<figure><img decoding="async" width="620" height="349" src="https://www.astronomy.com/wp-content/uploads/sites/2/2023/11/infographic-HD110067.png?w=620&amp;resize=620%2C349" alt="" srcset="https://www.astronomy.com/wp-content/uploads/sites/2/2023/11/infographic-HD110067.png?w=4000 4000w, https://www.astronomy.com/wp-content/uploads/sites/2/2023/11/infographic-HD110067.png?w=300 300w, https://www.astronomy.com/wp-content/uploads/sites/2/2023/11/infographic-HD110067.png?w=768 768w, https://www.astronomy.com/wp-content/uploads/sites/2/2023/11/infographic-HD110067.png?w=1200 1200w, https://www.astronomy.com/wp-content/uploads/sites/2/2023/11/infographic-HD110067.png?w=1536 1536w, https://www.astronomy.com/wp-content/uploads/sites/2/2023/11/infographic-HD110067.png?w=2048 2048w, https://www.astronomy.com/wp-content/uploads/sites/2/2023/11/infographic-HD110067.png?w=1568 1568w, https://www.astronomy.com/wp-content/uploads/sites/2/2023/11/infographic-HD110067.png?w=1860 1860w" sizes="(max-width: 620px) 100vw, 620px" data-recalc-dims="1"><figcaption>Credit: ESA</figcaption></figure>



<h2><strong>Seeking sub-Neptunes</strong></h2>



<p>The planets circle HD 110067, a star similar to our Sun, with roughly 80 percent its size and mass. It is located in the constellation Coma Berenices, now visible in the early-morning sky in the east above Venus (in Virgo) in the hours before sunrise.</p>



<p>Just 100 light-years away, HD 110067 has an apparent magnitude of 8.4. That makes it the brightest star now known to host four or more planets, outshining the famous red dwarf <a href="https://www.astronomy.com/science/this-tiny-solar-system-packs-in-seven-earth-size-planets/">TRAPPIST-1</a> by some 10,000 times at optical wavelengths, said Osborn.</p>



<p>Further, TRAPPIST-1’s seven planets are all <a href="https://www.astronomy.com/science/trappist-1-cs-atmosphere-is-not-like-venus/">rocky worlds with thin atmospheres</a> — if any at all. HD 110067’s six known planets have cores of ice or rock but also thick, extended atmospheres of hydrogen and helium. All are some two to three times the diameter of Earth.</p>



<p>The team knows this based on the planets’ densities, which are calculated from size and mass. But transits only give a planet’s size, based on how much light it blocks. To get masses, the team used a different technique, called radial velocity, which measures the subtle “wobbles” in a star induced as orbiting planets tug it this way and that. “You can imagine that with six planets, this was a mess,” said co-author Enric Palle of the Instituto de Astrofisica de Canarias in Tenerife, Spain.</p>



<p>More than 100 radial velocity observations provided enough information to measure three of the planets’ masses, while placing upper limits on the remaining three. And once astronomers know a planet’s size and mass, they can calculate its density, which reveals the type of planet it is — in this case, worlds with some rock and extended atmospheres that are more like Neptune than Earth. Thus, they are called sub-Neptunes. (Neptune is 3.88 times as wide as Earth.) Planets larger than Earth and smaller than Neptune with densities more suggestive of largely rock with a thin atmosphere, such as TRAPPIST-1’s gaggle, are called super-Earths.</p>



<p>Our solar system has no planets of either type, but they are the most commonly found exoplanets when surveying other stars.</p>



<p><strong>RELATED: </strong><a href="https://www.astronomy.com/science/where-is-our-solar-systems-super-earth/">Where is our solar system’s super-Earth?</a></p>



<h2><strong>A key system</strong></h2>



<p>How does a system of planets end up orbiting in perfect mathematical ratios at all? This is likely how planetary systems begin, the team said, reflecting the initial conditions left when the protoplanetary disk that forms the planets eventually disappears. Such resonant chains should be exceedingly common in nature — but they’re not. That’s because over time, chaotic events such as passing stars, meteor impacts, and wandering giant planets muddy any resonances until they are gone.</p>



<p>But HD 110067’s resonant chain has persisted for the billions of years since these planets formed, indicating “the evolution of this system has been very quiet, very gentle,” said lead author Rafael Luque of the University of Chicago.</p>



<p>Ultimately, about 1 percent of all planetary systems are still orbiting in resonance. We know of some 40 or 50, the team said. And this isn’t the first six-planet resonant system discovered.</p>



<p>Yet HD 110067 still stands out. In addition to its pristine orbital configuration, the star is very bright and there are six planets, all with substantial atmospheres. This makes it a prime target for the James Webb Space Telescope to peer through the atmospheres of these planets as they transit, looking for the presence of molecules such as methane, carbon dioxide, water, and ammonia. Doing so will not only tell us the composition of the planets’ atmospheres, but also their interiors as well, including whether they might contain plentiful water.</p>



<p>Perhaps most compelling, this system provides the perfect testbed for studying how sub-Neptunes form and planetary systems evolve without outside influences. Each of the six planets formed from the same material, started from the same initial conditions, and has experienced the same history as its peers. Astronomers can compare these worlds to each other to study how subtle differences in size, mass, temperature, and distance from their star might affect the evolution of planets in the absence of any other factors.</p>



<p>In HD 110067 and its planets, Luque said, astronomers have a single, perfect testbed — a “controlled experiment … that is going to set us up to learn so much in the coming years.”</p>



<p><em>Editor’s note: An earlier version of this story mistakenly stated that for every three orbits of c, d makes three.</em></p>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Proxmox VE Helper-Scripts – Scripts for Streamlining Your Homelab with Proxmox (157 pts)]]></title>
            <link>https://tteck.github.io/Proxmox/</link>
            <guid>38474003</guid>
            <pubDate>Thu, 30 Nov 2023 14:36:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tteck.github.io/Proxmox/">https://tteck.github.io/Proxmox/</a>, See on <a href="https://news.ycombinator.com/item?id=38474003">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a id="a-title" href="https://tteck.github.io/Proxmox/"></a><h2>Scripts for Streamlining Your Homelab with Proxmox VE</h2><section id="downloads"><a href="https://github.com/tteck/Proxmox"><span></span>View on GitHub</a></section></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Yabai – A tiling window manager for macOS (265 pts)]]></title>
            <link>https://github.com/koekeishiya/yabai</link>
            <guid>38473942</guid>
            <pubDate>Thu, 30 Nov 2023 14:32:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/koekeishiya/yabai">https://github.com/koekeishiya/yabai</a>, See on <a href="https://news.ycombinator.com/item?id=38473942">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text">
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/koekeishiya/yabai/blob/master/assets/banner/banner.svg"><img width="75%" src="https://github.com/koekeishiya/yabai/raw/master/assets/banner/banner.svg" alt="Banner"></a>
</p>
<p dir="auto">
  <b>Tiling window management for the Mac.</b>
</p>
<p dir="auto">
  <a href="https://github.com/koekeishiya/yabai/blob/master/LICENSE.txt">
    <img src="https://camo.githubusercontent.com/ec1ceba7545043dcf851dbd0283f3701f5c9fe417310a50b12c873e6f42ee6d4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6b6f656b656973686979612f79616261692e7376673f636f6c6f723d677265656e" alt="License Badge" data-canonical-src="https://img.shields.io/github/license/koekeishiya/yabai.svg?color=green">
  </a>
  <a href="https://github.com/koekeishiya/yabai/blob/master/doc/yabai.asciidoc">
    <img src="https://camo.githubusercontent.com/42678381746eea00d1ef6712ef79d4aac9c97f3d38af1b019ce5069fda7aa965/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f766965772d646f63756d656e746174696f6e2d677265656e2e737667" alt="Documentation Badge" data-canonical-src="https://img.shields.io/badge/view-documentation-green.svg">
  </a>
  <a href="https://github.com/koekeishiya/yabai/wiki">
    <img src="https://camo.githubusercontent.com/b8de91fd2e36f574f040cfaa1b5300bb922912e924329e1e7f86980b3390d9ec/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f766965772d77696b692d677265656e2e737667" alt="Wiki Badge" data-canonical-src="https://img.shields.io/badge/view-wiki-green.svg">
  </a>
  <a href="https://github.com/koekeishiya/yabai/blob/master/CHANGELOG.md">
    <img src="https://camo.githubusercontent.com/899659c9b3ebec4b82c4533ae8aaa88ceaf9d07bfc501aa01a32043595348dac/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f766965772d6368616e67656c6f672d677265656e2e737667" alt="Changelog Badge" data-canonical-src="https://img.shields.io/badge/view-changelog-green.svg">
  </a>
  <a href="https://github.com/koekeishiya/yabai/releases">
    <img src="https://camo.githubusercontent.com/f904d7be0bd0737dedf7da96a8740219f83330cdb706c4e62ac22fc65b259939/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d6974732d73696e63652f6b6f656b656973686979612f79616261692f6c61746573742e7376673f636f6c6f723d677265656e" alt="Version Badge" data-canonical-src="https://img.shields.io/github/commits-since/koekeishiya/yabai/latest.svg?color=green">
  </a>
</p>
<h2 tabindex="-1" dir="auto">About</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/koekeishiya/yabai/blob/master/assets/screenshot.png"><img width="40%" src="https://github.com/koekeishiya/yabai/raw/master/assets/screenshot.png" alt="Screenshot"></a></p>
<p dir="auto">yabai is a window management utility that is designed to work as an extension to the built-in window manager of macOS.
yabai allows you to control your windows, spaces and displays freely using an intuitive command line interface and optionally set user-defined keyboard shortcuts using <a href="https://github.com/koekeishiya/skhd">↗&nbsp;skhd</a> and other third-party software.</p>
<p dir="auto">The primary function of yabai is tiling window management; automatically modifying your window layout using a binary space partitioning algorithm to allow you to focus on the content of your windows without distractions.
Additional features of yabai include focus-follows-mouse, disabling animations for switching spaces, creating spaces past the limit of 16 spaces, and much more.</p>
<h2 tabindex="-1" dir="auto">Installation and Configuration</h2>
<ul dir="auto">
<li>The <a href="https://github.com/koekeishiya/yabai/wiki">↗&nbsp;yabai&nbsp;wiki</a> has both brief and detailed installation instructions for multiple installation methods, and also explains how to uninstall yabai completely.</li>
<li>Sample configuration files can be found in the <a href="https://github.com/koekeishiya/yabai/tree/master/examples">↗&nbsp;examples</a> directory. Refer to the <a href="https://github.com/koekeishiya/yabai/blob/master/doc/yabai.asciidoc">↗&nbsp;documentation</a> or the wiki for further information.</li>
<li>Keyboard shortcuts can be defined with <a href="https://github.com/koekeishiya/skhd">↗&nbsp;skhd</a> or any other suitable software you may prefer.</li>
</ul>
<h2 tabindex="-1" dir="auto">Requirements and Caveats</h2>
<p dir="auto">Please read the below requirements carefully.
Make sure you fulfil all of them before filing an issue.</p>
<table>
<thead>
<tr>
<th>Requirement</th>
<th>Note</th>
</tr>
</thead>
<tbody>
<tr>
<td>Operating&nbsp;System&nbsp;Intel x86-64</td>
<td>Big Sur 11.0.0+, Monterey 12.0.0+, Ventura 13.0.0+, and Sonoma 14.0.0 is supported.</td>
</tr>
<tr>
<td>Operating&nbsp;System&nbsp;Apple Silicon</td>
<td>Monterey 12.0.0+, Ventura 13.0.0+, and Sonoma 14.0.0 is supported.</td>
</tr>
<tr>
<td>Accessibility&nbsp;API</td>
<td>yabai must be given permission to utilize the Accessibility API and will request access upon launch. The application must be restarted after access has been granted.</td>
</tr>
<tr>
<td>Screen Recording</td>
<td>yabai must be given Screen Recording permission if and only if you want to enable window animations, and will request access when necessary. The application must be restarted after access has been granted.</td>
</tr>
<tr>
<td>System&nbsp;Preferences&nbsp;(macOS 11.x, 12.x)</td>
<td>In the Mission Control pane, the setting "Displays have separate Spaces" must be enabled.</td>
</tr>
<tr>
<td>System&nbsp;Settings&nbsp;(macOS 13.x, 14.x)</td>
<td>In the Desktop &amp; Dock tab, inside the Mission Control pane, the setting "Displays have separate Spaces" must be enabled.</td>
</tr>
</tbody>
</table>
<p dir="auto">Please also take note of the following caveats.</p>
<table>
<thead>
<tr>
<th>Caveat</th>
<th>Note</th>
</tr>
</thead>
<tbody>
<tr>
<td>System&nbsp;Integrity&nbsp;Protection (Optional)</td>
<td>System Integrity Protection can be (partially) disabled for yabai to inject a scripting addition into Dock.app for controlling windows with functions that require elevated privileges. This enables control of the window server, which is the sole owner of all window connections, and enables additional features of yabai.</td>
</tr>
<tr>
<td>Code&nbsp;Signing</td>
<td>When building from source (or installing from HEAD), it is necessary to codesign the binary so it retains its accessibility and automation privileges when updated or rebuilt.</td>
</tr>
<tr>
<td>System&nbsp;Preferences&nbsp;(macOS 11.x, 12.x)</td>
<td>In the Mission Control pane, the setting "Automatically rearrange Spaces based on most recent use" should be disabled for commands that rely on the ordering of spaces to work reliably.</td>
</tr>
<tr>
<td>System&nbsp;Settings&nbsp;(macOS 13.x, 14.x)</td>
<td>In the Desktop &amp; Dock tab, inside the Mission Control pane, the setting "Automatically rearrange Spaces based on most recent use" should be disabled for commands that rely on the ordering of spaces to work reliably.</td>
</tr>
<tr>
<td>System&nbsp;Settings&nbsp;(macOS 14.x)</td>
<td>In the Desktop &amp; Dock tab, inside the Desktop &amp; Stage Manager pane, the setting "Show Items On Desktop" should be enabled for display and space focus commands to work reliably in multi-display configurations.</td>
</tr>
<tr>
<td>System&nbsp;Settings&nbsp;(macOS 14.x)</td>
<td>In the Desktop &amp; Dock tab, inside the Desktop &amp; Stage Manager pane, the setting "Click wallpaper to reveal Desktop" should be set to "Only in Stage Manager" for display and space focus commands to work reliably.</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">License and Attribution</h2>
<p dir="auto">yabai is licensed under the <a href="https://github.com/koekeishiya/yabai/blob/master/LICENSE.txt">↗&nbsp;MIT&nbsp;License</a>, a short and simple permissive license with conditions only requiring preservation of copyright and license notices.
Licensed works, modifications, and larger works may be distributed under different terms and without source code.</p>
<p dir="auto">Thanks to <a href="https://github.com/fools-mate">@fools-mate</a> for creating a logo and banner for this project and making them available for free.</p>
<p dir="auto">Thanks to <a href="https://github.com/dominiklohmann">@dominiklohmann</a> for contributing great documentation, support, and more, for free.</p>
<h2 tabindex="-1" dir="auto">Disclaimer</h2>
<p dir="auto">Use at your own discretion.
I take no responsibility if anything should happen to your machine while trying to install, test or otherwise use this software in any form.
You acknowledge that you understand the potential risk that may come from disabling <a href="https://support.apple.com/en-us/HT204899" rel="nofollow">↗&nbsp;System&nbsp;Integrity&nbsp;Protection</a> on your system, and I make no recommendation as to whether you should or should not disable System Integrity Protection.</p>



</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Senator calls for the public release of AT&T 'Hemisphere' surveillance records (139 pts)]]></title>
            <link>https://www.engadget.com/us-senator-calls-for-the-public-release-of-att-hemisphere-surveillance-records-083627787.html</link>
            <guid>38473766</guid>
            <pubDate>Thu, 30 Nov 2023 14:15:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.engadget.com/us-senator-calls-for-the-public-release-of-att-hemisphere-surveillance-records-083627787.html">https://www.engadget.com/us-senator-calls-for-the-public-release-of-att-hemisphere-surveillance-records-083627787.html</a>, See on <a href="https://news.ycombinator.com/item?id=38473766">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>US Senator Ron Wyden <a data-i13n="cpos:1;pos:1" href="https://www.wyden.senate.gov/news/press-releases/wyden-urges-justice-department-to-release-information-about-hemisphere-phone-surveillance-program-that-would-outrage-americans-and-congress" rel="nofollow noopener" target="_blank" data-ylk="slk:wants the public;cpos:1;pos:1;elm:context_link;itc:0">wants the public</a> to know about the details surrounding the long-running Hemisphere phone surveillance program. Wyden has written US Attorney General Merrick Garland a <a data-i13n="cpos:2;pos:1" href="https://www.wyden.senate.gov/imo/media/doc/wyden_hemisphere_surveillance_letter_112023.pdf" rel="nofollow noopener" target="_blank" data-ylk="slk:letter;cpos:2;pos:1;elm:context_link;itc:0">letter</a> (PDF), asking him to release additional information about the project that apparently gives law enforcement agencies access to trillions of domestic phone records. In addition, he said that federal, state, local and Tribal law enforcement agencies have the ability to request "often-warrantless searches" from the project's phone records that <a data-i13n="cpos:3;pos:1" href="https://www.engadget.com/2016-10-26-atandt-reportedly-spies-on-its-customers-for-government-cash.html" data-ylk="slk:AT&amp;T has been collecting;cpos:3;pos:1;elm:context_link;itc:0">AT&amp;T has been collecting</a> since 1987.</p><p>The Hemisphere project first came to light in 2013 when <em>The New York Times</em> reported that the White House Office of National Drug Control Policy (ONDCP) was paying AT&amp;T to mine and keep records of its customers' phone calls. Four billion new records are getting added to its database every day, and a federal or state law enforcement agency can request a query with a subpoena that they can issue themselves. Any law enforcement officer can send in a request to a single AT&amp;T analyst based in Atlanta, Georgia, Wyden's letter says, even if they're seeking information that's not related to any drug case. And apparently, they can use Hemisphere not just to identify a specific number, but to identify the target's alternate numbers, to obtain location data and to look up the phone records of everyone who's been in communication with the target.</p><p>The project has been defunded and refunded by the government several times over the past decade and was even, at one point, receiving federal funding under the name "Data Analytical Services (DAS)." Usually, projects funded by federal agencies would be subject to a mandatory Privacy Impact Assessment conducted by the Department of Justice, which means their records would be made public.</p><p>However, Hemisphere's funding passes through a middleman, so it's not required to go through mandatory assessment. To be specific, ONDCP funds the program through the Houston High Intensity Drug Trafficking Area, which is a regional funding organization that distributes federal anti-drug law grants and is governed by a board made up of federal, state and local law enforcement officials. The DOJ had provided Wyden's office with "dozens of pages of material" related to the project in 2019, but they had been labeled "Law Enforcement Sensitive" and cannot be released to the public.</p><p>"I have serious concerns about the legality of this surveillance program, and the materials provided by the DOJ contain troubling information that would justifiably outrage many Americans and other members of Congress," Wyden wrote in his letter. "While I have long defended the government’s need to protect classified sources and methods, this surveillance program is not classified and its existence has already been acknowledged by the DOJ in federal court. The public interest in an informed debate about government surveillance far outweighs the need to keep this information secret."</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Bi-directional sync between Postgres and SQLite (141 pts)]]></title>
            <link>https://powersync.com</link>
            <guid>38473743</guid>
            <pubDate>Thu, 30 Nov 2023 14:13:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://powersync.com">https://powersync.com</a>, See on <a href="https://news.ycombinator.com/item?id=38473743">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-animation="default" data-collapse="medium" data-duration="400" data-easing="ease" data-easing2="ease" data-doc-height="1" role="banner"><header><a href="https://powersync.com/" aria-current="page"><img alt="" loading="lazy" src="https://assets-global.website-files.com/651d89402147985dc475ff48/651d89402147985dc475ff71_powersync-logo-horizontal-all-white.svg"></a></header></div><div data-animation="default" data-collapse="medium" data-duration="400" data-easing="ease" data-easing2="ease" data-doc-height="1" role="banner"><p><a href="https://powersync.com/" aria-current="page"><img alt="" loading="lazy" src="https://assets-global.website-files.com/651d89402147985dc475ff48/651d89402147985dc475ff71_powersync-logo-horizontal-all-white.svg"></a></p></div><div><h2>Plugs into your existing database, <br>backend and app</h2><div><div><p>Visit this website on your desktop to see a demo</p></div><p><img src="https://assets-global.website-files.com/651d89402147985dc475ff48/65577946531569ed419c02f4_powersync-home-graphic-diagram-architecture.svg" loading="lazy" alt="PowerSync architecture overview"></p></div></div><section><div><h2>Build fast, always-available apps</h2><div data-current="Tab 1" data-easing="ease" data-duration-in="300" data-duration-out="100"><div data-w-tab="Tab 1"><div><p>Local reads and writes with a performance-optimized SQLite database make your apps responsive and always available.</p><p>No client-side migrations are <a href="https://docs.powersync.com/usage/lifecycle-maintenance/implementing-schema-changes" target="_blank">ever necessary</a>.</p></div><div><pre><code>// Local queries
db.get(‘SELECT * FROM lists WHERE id = ?‘, [id])

// Local writes
db.execute(‘DELETE FROM lists WHERE id = ?‘, [id])

// Indexing
Index(‘list‘, [IndexedColumn(‘list_id‘)])

// Transactions
db.execute(‘BEGIN TRANSACTION; UPDATE accounts SET balance = balance - 100 WHERE account_no = ?‘; UPDATE accounts SET balance = balance + 100 WHERE account_no = ?‘; COMMIT TRANSACTION‘, [account_1, account_2])
</code></pre></div></div><div data-w-tab="Tab 2"><div><p>Automatically stream data update events from your backend Postgres to users.</p><p>Live queries on the local database listen to changes and update your UI in real-time,</p></div><div><pre><code>// Flutter syntax
db.watch(‘SELECT count() AS count FROM data‘).listen((results) {
  // update UI
}
</code></pre></div></div></div></div><div><h2>Dynamic partial replication&nbsp;proven at scale</h2><p>PowerSync was spun off from a product that's been in production for over 10 years. <br>Our <a href="https://docs.powersync.com/usage/sync-rules" target="_blank">sync rules</a> approach to dynamic partial replication is battle-tested at scale.</p><div data-current="Tab 1" data-easing="ease" data-duration-in="300" data-duration-out="100"><p><img loading="lazy" src="https://assets-global.website-files.com/651d89402147985dc475ff48/6530fb518148952cb635f129_powersync-home-graphic-diagram-sync-tech-tables.svg" alt=""></p><div data-w-tab="Tab 2"><pre><code>bucket_definitions:
  user_lists_and_todos:
    parameters: SELECT token_parameters.user_id as user_id
    data:
       - SELECT * FROM lists WHERE owner_id = bucket.user_id
       - SELECT * FROM todos WHERE created_by = bucket.user_id
</code></pre></div></div></div></section><section><div><h2>Get started with PowerSync</h2></div><div id="w-node-c220c1e7-83fc-b09c-30ff-348ca13e5737-bfe448d9"><p id="w-node-c220c1e7-83fc-b09c-30ff-348ca13e5738-bfe448d9"><h2>Future support</h2></p><p id="w-node-c220c1e7-83fc-b09c-30ff-348ca13e573b-bfe448d9"><h2>Existing support</h2></p><p id="w-node-c220c1e7-83fc-b09c-30ff-348ca13e573e-bfe448d9"><h2>Future support</h2></p><div id="w-node-c220c1e7-83fc-b09c-30ff-348ca13e5741-bfe448d9"><p><img src="https://assets-global.website-files.com/651d89402147985dc475ff48/651d89402147985dc475ff89_mysql-icon-white.svg" loading="lazy" alt=""></p><p>MySQL</p></div><div id="w-node-c220c1e7-83fc-b09c-30ff-348ca13e5745-bfe448d9"><p><img src="https://assets-global.website-files.com/651d89402147985dc475ff48/65202471f564485e723c3f9c_postgres-icon.svg" loading="lazy" alt=""></p><p>PostgreSQL</p></div><p><img src="https://assets-global.website-files.com/651d89402147985dc475ff48/6520250a185622629e928e1b_powersync-logo-icon.svg" loading="lazy" alt=""></p><div id="w-node-c220c1e7-83fc-b09c-30ff-348ca13e574b-bfe448d9"><p><img src="https://assets-global.website-files.com/651d89402147985dc475ff48/653105942a71e60e64f8f695_react-native-expo-logos.svg" loading="lazy" alt=""></p><p>React Native <br>&amp; Expo</p></div><div id="w-node-c220c1e7-83fc-b09c-30ff-348ca13e5751-bfe448d9"><p><img src="https://assets-global.website-files.com/651d89402147985dc475ff48/651d89402147985dc475ff8b_kotlin-icon-white.svg" loading="lazy" alt=""></p><p>Kotlin/Native<br></p></div><div id="w-node-c220c1e7-83fc-b09c-30ff-348ca13e5755-bfe448d9"><p><img src="https://assets-global.website-files.com/651d89402147985dc475ff48/651d89402147985dc475ff8a_oracle-icon-white.svg" loading="lazy" alt=""></p><p>Oracle</p></div><div id="w-node-_29d934c5-aa84-c50b-ff09-da925bfb4333-bfe448d9"><p><img src="https://assets-global.website-files.com/651d89402147985dc475ff48/652024afbf6c03e5f353abc2_flutter-icon.svg" loading="lazy" alt=""></p><p>Flutter</p></div><div id="w-node-c220c1e7-83fc-b09c-30ff-348ca13e5759-bfe448d9"><p><img src="https://assets-global.website-files.com/651d89402147985dc475ff48/651d89402147985dc475ff84_swift-icon-white.svg" loading="lazy" alt=""></p><p>Swift</p></div><div id="w-node-c220c1e7-83fc-b09c-30ff-348ca13e575d-bfe448d9"><p><img src="https://assets-global.website-files.com/651d89402147985dc475ff48/651d89402147985dc475ff88_microsoft-icon-white.svg" loading="lazy" alt=""></p><p>SQL Server</p></div><div id="w-node-c220c1e7-83fc-b09c-30ff-348ca13e5761-bfe448d9"><p><img src="https://assets-global.website-files.com/651d89402147985dc475ff48/6520248afdd81b215bcba844_supabase-icon.svg" loading="lazy" alt=""></p><p>Supabase</p></div><div id="w-node-c220c1e7-83fc-b09c-30ff-348ca13e5765-bfe448d9"><p><img src="https://assets-global.website-files.com/651d89402147985dc475ff48/65560d2c5b2082b840cd230f_javascript-logo.svg" loading="lazy" alt=""></p><p>Web<br>(JavaScript &amp; React)</p></div><div id="w-node-c220c1e7-83fc-b09c-30ff-348ca13e5769-bfe448d9"><p><img src="https://assets-global.website-files.com/651d89402147985dc475ff48/651d89402147985dc475ff8b_kotlin-icon-white.svg" loading="lazy" alt=""></p><p>Kotlin Multiplatform<br></p></div><div id="w-node-c220c1e7-83fc-b09c-30ff-348ca13e576e-bfe448d9"><p><img src="https://assets-global.website-files.com/651d89402147985dc475ff48/652028cd6505b9150cc0dc21_appwrite-icon-white.svg" loading="lazy" alt=""></p><p>Appwrite</p></div><div id="w-node-_41cfe5e0-7586-2fda-2f62-46ea3319034c-bfe448d9"><p><img src="https://assets-global.website-files.com/651d89402147985dc475ff48/653fbb1678e5b75221e6ab23_flutterflow-icon-blue.svg" loading="lazy" alt=""></p><p>FlutterFlow</p></div><div id="w-node-c220c1e7-83fc-b09c-30ff-348ca13e5772-bfe448d9"><p><img src="https://assets-global.website-files.com/651d89402147985dc475ff48/65202a0b21cb916d6d8f5e53_electron-icon-white.svg" loading="lazy" alt=""></p><p>Electron</p></div></div></section><!-- styling for rich text -->



<!-- end styling for rich text -->

<!-- styling for code blocks -->
<!-- Get theme -->



<!-- Get languages -->





<!-- Copy functionality -->






<!-- end styling for code blocks -->

<!-- Start of HubSpot Embed Code -->



<!-- End of HubSpot Embed Code --></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CSAR: European Parliament rejects mass scanning of private messages (442 pts)]]></title>
            <link>https://edri.org/our-work/csar-european-parliament-rejects-mass-scanning-of-private-messages/</link>
            <guid>38472198</guid>
            <pubDate>Thu, 30 Nov 2023 11:25:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://edri.org/our-work/csar-european-parliament-rejects-mass-scanning-of-private-messages/">https://edri.org/our-work/csar-european-parliament-rejects-mass-scanning-of-private-messages/</a>, See on <a href="https://news.ycombinator.com/item?id=38472198">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content" role="main">

		

<div>

            <!-- if post type is event, print postmeta + timezone here-->
	   
							
			
							<p>
					On 22 November, the European Parliament officially adopted its position on the draft ‘Regulation laying down rules to prevent and combat child sexual abuse’ (CSAR). With strong support for this position from all seven European political groups, this marks a positive development for human rights in one of the most controversial draft European Union (EU) laws in recent memory.				</p>
			
<!-- if post type is event, print location, organiser, registration link here -->
			
				<p>
					By <strong>EDRi</strong> · November 30, 2023				</p>
			

			
					</div>


<section>

	
			<div>
	<p>On 22 November, <a href="https://www.europarl.europa.eu/news/en/press-room/20231117IPR12219/child-sexual-abuse-online-meps-ready-to-start-negotiations" target="_blank" rel="noopener">the European Parliament officially adopted its position on the draft ‘Regulation laying down rules to prevent and combat child sexual abuse’</a> (CSAR). With strong support for this position from all seven European political groups, this marks a <b>positive</b><b> </b><b>development </b><b>for human rights </b><b>in one of the most controversial draft E</b><b>uropean</b><b> </b><b>Union (EU)</b><b> laws in recent memory</b>.</p>
<p>EDRi has long advocated against the <b>CSAR’s </b><b>mass scanning and encryption-breaking measures</b> proposed in 2022 by the EU executive’s unit for home affairs. We are reassured, therefore, that the Parliament has listened to the evidence and the rule of law. At the same time, <b>we are still </b><b>far from the end of the</b><b> legislative process.</b> This means that we must stay alert to how the other two law-making institutions – the Council of EU Member States and the European Commission – respond. Will they agree with the Parliament that new EU laws need to respect fundamental rights? Or will they double down on ‘Chat Control’?</p>
<h3>The position of the European Parliament</h3>
<p>As we explained when <a href="https://edri.org/our-work/eu-parliament-committee-rejects-mass-scanning-of-private-and-encrypted-communications/">this position was </a><a href="https://edri.org/our-work/eu-parliament-committee-rejects-mass-scanning-of-private-and-encrypted-communications/" target="_blank" rel="noopener">provisionally agreed</a><a href="https://edri.org/our-work/eu-parliament-committee-rejects-mass-scanning-of-private-and-encrypted-communications/"> by the </a><a href="https://edri.org/our-work/eu-parliament-committee-rejects-mass-scanning-of-private-and-encrypted-communications/">Parliament’s</a><a href="https://edri.org/our-work/eu-parliament-committee-rejects-mass-scanning-of-private-and-encrypted-communications/"> Civil Liberties </a><a href="https://edri.org/our-work/eu-parliament-committee-rejects-mass-scanning-of-private-and-encrypted-communications/">C</a><a href="https://edri.org/our-work/eu-parliament-committee-rejects-mass-scanning-of-private-and-encrypted-communications/">ommittee </a><a href="https://edri.org/our-work/eu-parliament-committee-rejects-mass-scanning-of-private-and-encrypted-communications/">on 14</a><a href="https://edri.org/our-work/eu-parliament-committee-rejects-mass-scanning-of-private-and-encrypted-communications/"> November</a>, it is a clear political statement that <b>even </b><b>the most </b><b>important </b><b>societal </b><b>aims do not justify measures at any cost.</b> EU fundamental rights law requires that limitations on people’s rights are necessary for the aim they seek to achieve – including being objectively effective and the least intrusive possible – and proportionate. That means that their broader impact must be reasonable.</p>
<p>On this basis, <b>the Parliament firmly rejected </b><b>rules which would force companies to scan huge volumes of people’s private messages </b>– instead now requiring there to be reasonable suspicion. <a href="https://www.bitsoffreedom.nl/wp-content/uploads/2023/05/20230426-opinion-legal-services-on-csar-proposal.pdf" target="_blank" rel="noopener">Lawyers for the Council of EU Member States </a><a href="https://www.bitsoffreedom.nl/wp-content/uploads/2023/05/20230426-opinion-legal-services-on-csar-proposal.pdf">had </a><a href="https://www.bitsoffreedom.nl/wp-content/uploads/2023/05/20230426-opinion-legal-services-on-csar-proposal.pdf">previously</a><a href="https://www.bitsoffreedom.nl/wp-content/uploads/2023/05/20230426-opinion-legal-services-on-csar-proposal.pdf"> made </a>a<a href="https://www.bitsoffreedom.nl/wp-content/uploads/2023/05/20230426-opinion-legal-services-on-csar-proposal.pdf">n</a><a href="https://www.bitsoffreedom.nl/wp-content/uploads/2023/05/20230426-opinion-legal-services-on-csar-proposal.pdf"> unprecedented warning</a> that the original proposal would violate the essence of the right to privacy. In EU-speak, this is a damning assessment, because case law from the Court of Justice of the EU has always upheld that while rights can be limited for justifiable reasons, <b>the “essential core” of any human right must never be violated.</b> The Parliament has clearly listened to this warning.</p>
<h3>EDRi’s work and coalition</h3>
<p>Since before the home affairs unit (DG HOME) first put forward this law, <b>EDRi has been </b><b>on the front lines </b>urging the EU to ensure that measures to tackle the serious crime of child sexual abuse are in line with human rights rules. Yet our ‘<a href="https://edri.org/our-work/chat-control-10-principles-to-defend-children-in-the-digital-age/">10 principles to </a><a href="https://edri.org/our-work/chat-control-10-principles-to-defend-children-in-the-digital-age/" target="_blank" rel="noopener">defend children in the digital age</a>’ were ignored in the original legislative proposal (so too were <a href="https://edri.org/our-work/leaked-opinion-of-the-commission-sets-off-alarm-bells-for-mass-surveillance-of-private-communications/">concerns from the Commission’s own review board</a>).</p>
<p>Thanks to the <b>EDRi-led <a href="https://stopscanningme.eu/" target="_blank" rel="noopener">Stop Scanning Me</a> campaign</b>, thousands of people across Europe have since sounded the alarm about the draft measures. <a href="https://docs.google.com/document/d/13Aeex72MtFBjKhExRTooVMWN9TC-pbH-5LEaAbMF91Y/edit" target="_blank" rel="noopener">Scientists and researchers across the world</a> have been unambiguous that as proposed, the measures would undermine encryption, putting everyone’s digital information at risk of harm. And <a href="https://edri.org/our-work/most-criticised-eu-law-of-all-time/" target="_blank" rel="noopener">other stakeholders</a> such as journalists, youth activists, lawyers and survivors’ associations have warned how they could be put at risk by the proposal.</p>
<p><img decoding="async" loading="lazy" src="https://edri.org/wp-content/uploads/2023/10/6.jpeg" alt="" width="2048" height="1153" srcset="https://edri.org/wp-content/uploads/2023/10/6.jpeg 2048w, https://edri.org/wp-content/uploads/2023/10/6-300x169.jpeg 300w, https://edri.org/wp-content/uploads/2023/10/6-1024x577.jpeg 1024w, https://edri.org/wp-content/uploads/2023/10/6-768x432.jpeg 768w, https://edri.org/wp-content/uploads/2023/10/6-1536x865.jpeg 1536w, https://edri.org/wp-content/uploads/2023/10/6-180x101.jpeg 180w" sizes="(max-width: 2048px) 100vw, 2048px"></p>
<h3>What’s next?</h3>
<p>As their position has been officially adopted, <b>the European Parliament is ready to enter “trilogues”</b>. This is closed-door negotiations between lead Parliamentarians and the Council of EU Member State governments. However, in this case, the <b>Council does not </b><b>currently </b><b>have </b><b>a</b><b> negotiating mandate with which to enter the trilogues</b>. In fact, <a href="https://netzpolitik.org/2023/internes-protokoll-immer-mehr-eu-staaten-gegen-unverhaeltnismaessige-chatkontrolle/#2023-10-18_AA_AStV_CSAR_Weisung" target="_blank" rel="noopener">EU Member State governments have been divided on the issue</a>, with <b>some countries refusing to listen to technological </b><b>and</b><b> legal </b><b>reality</b><b>.</b> Fortunately, many others have stood up against their colleagues, rightly warning that the <b>EU cannot give a </b><i><b>carte blanche </b></i><b>to the destruction of digital security</b>, privacy and anonymity.</p>
<p>Back in July, <a href="https://edri.org/our-work/council-poised-to-endorse-mass-surveillance-as-official-position-for-csa-regulation/" target="_blank" rel="noopener">EDRi urged Member State governments not to agree</a> to a position which would usher in the mass surveillance of everyone’s digital private lives. People subsequently took to the streets in Germany, Sweden and several other locations to urge their governments not to accept ‘Chat Control’. These efforts paid off, with the <b>governments of Germany, Austria, Poland, Estonia and Slovenia <a href="https://netzpolitik.org/2023/internes-protokoll-immer-mehr-eu-staaten-gegen-unverhaeltnismaessige-chatkontrolle/#2023-10-18_AA_AStV_CSAR_Weisung">reportedly</a> taking a firm stance against the misguided proposal, and France </b><b>subsequently raising major concerns.</b></p>



<p><b>W</b><b>ithout a Council position, the legislative process for the CSAR is currently in limbo</b>. The Spanish Presidency of the Council is reportedly attempting to push through a position before the end of their mandate (end December 2023). But at the time of writing, they do not have a text on the table – let alone political agreement from a sufficient number of Member States.</p>
<p>Even if the Council is able to agree their position soon, <b>it is highly unlikely that they would be able to pass </b><b>the </b><b>law </b><b>during this political mandate</b><b>.</b> That’s because we are approaching a once-in-five-years event: European elections. In June 2024, a new Parliament will be elected, and subsequently, a new set of European Commissioners will be appointed. According to <a href="https://www.euractiv.com/section/eu-institutions/news/leak-eu-parliament-sets-deadlines-for-closing-files-under-this-mandate/">leaked documents</a>, this means that <b>any </b><b>negotiations between the legislative institutions must wrap up by early February 2024.</b></p>
<p>Whilst trilogue negotiations on even simple laws can take months, <b>it would be unprecedented for such a complex and sensitive file </b><b>as CSAR</b><b> – with so </b><b>much </b><b>at stake – to be pushed through in </b><b>such a</b><b> short time.</b> This current limbo also means that the political figurehead for the CSAR, controversial Swedish Commissioner Ylva Johansson, is unlikely to remain in post for this proposal’s life-cycle.</p>
<p><a href="https://edri.org/our-work/european-commission-must-uphold-privacy-security-and-free-expression-by-withdrawing-new-law/">EDRi has consistently advocated</a> that laws to tackle CSA online must be in line with fundamental rights law and with objective evidence of effectiveness. With this latest step, the European Parliament has firmly rebutted DG HOME’s attempt to pass a law which bitterly fails on both of these counts. Whilst the next steps for this law are not clear, this is nevertheless a huge milestone for the protection of digital human rights, and <b>we are counting on the Council not to go backwards.</b></p>
</div>

			
			

			
</section>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Can generalist foundation models beat special-purpose tuning? (107 pts)]]></title>
            <link>https://arxiv.org/abs/2311.16452</link>
            <guid>38472128</guid>
            <pubDate>Thu, 30 Nov 2023 11:14:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2311.16452">https://arxiv.org/abs/2311.16452</a>, See on <a href="https://news.ycombinator.com/item?id=38472128">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
    <div><p><span>Authors:</span><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nori,+H">Harsha Nori</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee,+Y+T">Yin Tat Lee</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+S">Sheng Zhang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carignan,+D">Dean Carignan</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Edgar,+R">Richard Edgar</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fusi,+N">Nicolo Fusi</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=King,+N">Nicholas King</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Larson,+J">Jonathan Larson</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+Y">Yuanzhi Li</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+W">Weishung Liu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Luo,+R">Renqian Luo</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=McKinney,+S+M">Scott Mayer McKinney</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ness,+R+O">Robert Osazuwa Ness</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Poon,+H">Hoifung Poon</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin,+T">Tao Qin</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Usuyama,+N">Naoto Usuyama</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=White,+C">Chris White</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Horvitz,+E">Eric Horvitz</a></p></div>            
    <p><a href="https://arxiv.org/pdf/2311.16452.pdf">Download PDF</a></p><blockquote>
            <span>Abstract:</span>Generalist foundation models such as GPT-4 have displayed surprising capabilities in a wide variety of domains and tasks. Yet, there is a prevalent assumption that they cannot match specialist capabilities of fine-tuned models. For example, most explorations to date on medical competency benchmarks have leveraged domain-specific training, as exemplified by efforts on BioGPT and Med-PaLM. We build on a prior study of GPT-4's capabilities on medical challenge benchmarks in the absence of special training. Rather than using simple prompting to highlight the model's out-of-the-box capabilities, we perform a systematic exploration of prompt engineering. We find that prompting innovation can unlock deeper specialist capabilities and show that GPT-4 easily tops prior leading results for medical benchmarks. The prompting methods we explore are general purpose, and make no specific use of domain expertise, removing the need for expert-curated content. Our experimental design carefully controls for overfitting during the prompt engineering process. We introduce Medprompt, based on a composition of several prompting strategies. With Medprompt, GPT-4 achieves state-of-the-art results on all nine of the benchmark datasets in the MultiMedQA suite. The method outperforms leading specialist models such as Med-PaLM 2 by a significant margin with an order of magnitude fewer calls to the model. Steering GPT-4 with Medprompt achieves a 27% reduction in error rate on the MedQA dataset over the best methods to date achieved with specialist models and surpasses a score of 90% for the first time. Beyond medical problems, we show the power of Medprompt to generalize to other domains and provide evidence for the broad applicability of the approach via studies of the strategy on exams in electrical engineering, machine learning, philosophy, accounting, law, nursing, and clinical psychology.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Eric Horvitz [<a href="https://arxiv.org/show-email/e2d76e18/2311.16452">view email</a>]      <br>    <strong>[v1]</strong>
        Tue, 28 Nov 2023 03:16:12 UTC (2,654 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Q-Transformer (207 pts)]]></title>
            <link>https://qtransformer.github.io/</link>
            <guid>38471942</guid>
            <pubDate>Thu, 30 Nov 2023 10:42:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://qtransformer.github.io/">https://qtransformer.github.io/</a>, See on <a href="https://news.ycombinator.com/item?id=38471942">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
        <p>
            <h2>
                <strong><span size="+6">Q-Transformer: </span></strong> <br> Scalable Offline Reinforcement Learning via Autoregressive Q-Functions <br> 
            </h2>
        </p>
        <div>
                <ul>
                <br>
                <li>Yevgen Chebotar*</li> <li>Quan Vuong*</li> <li>Alex Irpan</li> <li>Karol Hausman</li> <li>Fei Xia</li> <li>Yao Lu</li>  <li>Aviral Kumar</li> <br>
                 <li>Tianhe Yu</li> <li>Alexander Herzog</li> <li>Karl Pertsch</li> <li>Keerthana Gopalakrishnan</li> <li>Julian Ibarz</li> <li>Ofir Nachum</li>  <br>
                  <li>Sumedh Sontakke</li> <li>Grecia Salazar</li> <li>Huong T Tran</li> <li>Jodilyn Peralta</li> <li>Clayton Tan</li> <li>Deeksha Manjunath</li> <br>
                  <li>Jaspiar Singht</li> <li>Brianna Zitkovich</li> <li>Tomas Jackson</li>  <li>Kanishka Rao</li> <li>Chelsea Finn</li> <li>Sergey Levine</li>
                <br>
		   <i>*equal contribution</i>
		<br>
                    <a href="http://deepmind.com/">
                    <img src="https://qtransformer.github.io/img/deepmind.png" height="50px"> </a>
                    
                </ul>
            </div>


        

        <div>
		<p>
	    		<img src="https://qtransformer.github.io/img/qt_animation.gif">
		</p>
                <h3>
                    Abstract
                </h3>
                <p>
                    In this work, we present a scalable reinforcement learning method for training multi-task policies from large offline datasets that can leverage both human demonstrations and autonomously collected data. Our method uses a Transformer to provide a scalable representation for Q-functions trained via offline temporal difference backups. We therefore refer to the method as Q-Transformer. By discretizing each action dimension and representing the Q-value of each action dimension as separate tokens, we can apply effective high-capacity sequence modeling techniques for Q-learning. We present several design decisions that enable good performance with offline RL training, and show that Q-Transformer outperforms prior offline RL algorithms and imitation learning techniques on a large diverse real-world robotic manipulation task suite.
                </p>
            </div>

	<!--
	<div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Video
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe width="560" height="315" src="https://www.youtube.com/embed/UuKAp9a6wMs" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div>
	-->

<div>
	<h3>
	    Approach
	</h3>

        <p>
	    <img src="https://qtransformer.github.io/img/qt_title_overview.png">
	</p>
	<p>
		<img src="https://qtransformer.github.io/img/qt_robot_frames.png">
        </p>
	<p>
	We first describe how to enable using Transformers for Q-learning by applying discretization and autoregression of the action space.
	The classical way for learning a Q-function using TD-learning is based on the Bellman update rule:
	</p><p>
	        <img src="https://qtransformer.github.io/img/bellman_original.png">
	</p>
	<p>
	We change the Bellman update to be performed for each action dimension by transforming the original MDP of the problem into an MDP where each
	action dimension is treated as a separate step for Q-learning. In particular, given the action dimensionality <i>d<sub>A</sub></i>, the new Bellman update rule is:
	</p>
	<p>
	        <img src="https://qtransformer.github.io/img/bellman_qt.png">
	</p>
	<p>
	This means that for each intermediate action dimension we maximize over the next action dimension given the same state, 
	and for the final action dimension we use the first action dimension from the next state. This decomposition makes sure that the maximization 
	within the Bellman update remains tractable while ensuring that we still solve the original MDP problem.
	</p>
		
	<p>
	        <img src="https://qtransformer.github.io/img/qt_update_fig.png">
	</p>
	<p>
	In order to account for the distribution shift during offline learning, we introduce a simple regularization technique 
	that minimizes unseen actions (in the discretized case unseen action bins) to the lowest value. To accelerate learning, we also employ
	Monte-Carlo (MC) returns that use the original return-to-go from a given episode and n-step returns that can skip per-dimension maximization.
	</p>	    
 </div>
	    
<div id="videos">
	<h3>
	    Results and Videos
	</h3>
	<p>
        In our experiments, we start by evaluating Q-Transformer on a suite of real world tasks introduced in the RT-1 paper while limiting the data per task to only contain 100 human demonstrations. In addition to demonstrations, we also add autonomously collected failed episodes, resulting in a dataset of 38,000 positive examples from demos and 20,000 negative autonomously collected examples.
        </p><p>
	    <img src="https://qtransformer.github.io/img/real_results_table.png">
	</p>
	<p>
	    <video id="qt-robot-videos" autoplay="" loop="" muted="" playsinline="" controls="">
       		 <source src="https://qtransformer.github.io/videos/qt_robot_videos.mp4" type="video/mp4">
        	Your browser does not support the video tag.
   	    </video>
	</p><p>

		    
    Compared to such baselines as <a href="https://arxiv.org/abs/2212.06817">RT-1</a>,
    <a href="https://arxiv.org/abs/2110.06169">IQL</a> and
    <a href="https://arxiv.org/abs/2106.01345">Decision Transformer (DT)</a>, Q-Transformer can effectively utilize autonomous episodes to significantly improve on such skills as picking from and placing objects into drawers, moving objects near targets and closing and opening drawers.
	improve on such skills as picking from and placing objects into drawers, moving objects near targets and closing and opening drawers.
	</p>

	<p>
	We also benchmark our method in a challenging simulated picking task, where only ~8% of the data are positive examples, and the rest are
	noisy negative examples. Q-learning methods, such as 
    <a href="https://arxiv.org/abs/1806.10293">QT-Opt</a>
    , 
    <a href="https://arxiv.org/abs/2110.06169">IQL</a>
    ,
    <a href="https://arxiv.org/abs/2111.05424">AW-Opt</a>
     and our Q-Transformer are generally performing better on this task
	as they are able to utilize negative examples to learn policies through dynamic programming.
	</p>
	<p>
	    <img src="https://qtransformer.github.io/img/sim_exps.png">
	</p>
	
	<p>
        Ablating our decision choices on this picking task, we notice that both the conservative regularizer and MC returns are important for retaining the performance. Switching to a Softmax regularizer, which is similar to a 
        <a href="https://arxiv.org/abs/2006.04779">CQL</a>
         regularizer for discrete actions, performs significantly worse as it bounds the policy too much to the distribution of the data, showing that our choice of the regularizer works better for such tasks.
	</p>
	  <p>
	    <img src="https://qtransformer.github.io/img/qt_ablations.png">
	</p>
		  
	<p> 
	 We also ablate n-step returns and notice that although introducing bias they can help us achieving the same high performance in much fewer number of gradient steps,
	making them an efficient choice in many problems.
	</p>
	 <p>
	    <img src="https://qtransformer.github.io/img/nstep_table.png">
	</p>
		  
	<p>
        We also try to run our Q-Transformer on a much larger dataset, scaling up the number of positive examples to 115,000 and the number of negative examples to 185,000 resulting in 300,000 episodes. Q-Transformer is still able to learn from this large dataset and even provide some improvement over the RT-1 BC baseline.
	</p>
		
	 <p>
	    <img src="https://qtransformer.github.io/img/large_offline_results.png">
	</p>

	<p>
	Finally, we use the Q-function trained by Q-Transformer as an affordance model in combination with a language planner,
	similar to the 
    <a href="https://arxiv.org/abs/2204.01691">SayCan</a>
    work.
	</p>
	 <p>
	    <img src="https://qtransformer.github.io/img/affordance_perf.png">
	</p>
	<p>
        Q-Transformer affordance estimation works better than the previously used Q-functions trained with 
        QT-Opt
        , especially when combined with relabeling non-sampled tasks as negatives for the current task during training. As Q-Transformer does not require sim-to-real training that was used for the 
        QT-Opt
        training, it makes it easier to use it in the absence of suitable simulations.
	</p>

	<p>
        To test the full planning + execution system, we use Q-Transformer for both affordance estimation and the actual policy execution, where it shows to outperform the previous combination of 
        QT-Opt
         and 
        RT-1.
	</p>
	 <p>
	    <img src="https://qtransformer.github.io/img/saycan_perf.png">
	</p>
	
	<p>
	    <video id="qt-saycan-videos" autoplay="" loop="" muted="" playsinline="" controls="">
       		 <source src="https://qtransformer.github.io/videos/qt_saycan.mp4" type="video/mp4">
        	Your browser does not support the video tag.
   	    </video>
	</p><p>
    As can be seen in the examples of task affordance values for a given image, Q-Transformer can provide high-quality affordance values that can be used in downstream plan-and-execute frameworks.
</p></div>

<!--
<div class="row">
    <div class="col-md-8 col-md-offset-2">
	<h3>
	    Video
	</h3>
	<video id="v0" width="100%" playsinline muted loop controls>
	       <source src="img/Q-Transformer_Video.mov" type="video/mp4">
        </video>		
    </div>
</div>
-->
         <div>
                <h3>
                    Citation 
                </h3>
                
            </div>
        <div>
            <p>
                The website template was borrowed from <a href="http://jonbarron.info/">Jon Barron</a>.
                </p>
        </div>
<!--
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
The authors would like to acknowledge TODO and the greater teams at Google DeepMind for their feedback and contributions.
                    <br><br>
                The website template was borrowed from <a href="http://jonbarron.info/">Jon Barron</a>.
                </p>
            </div>
        </div>
    </div>
	    -->


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ripgrep is faster than grep, ag, Git grep, ucg, pt, sift (2016) (345 pts)]]></title>
            <link>https://blog.burntsushi.net/ripgrep/</link>
            <guid>38471822</guid>
            <pubDate>Thu, 30 Nov 2023 10:21:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.burntsushi.net/ripgrep/">https://blog.burntsushi.net/ripgrep/</a>, See on <a href="https://news.ycombinator.com/item?id=38471822">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
      

      <article>
      <p>In this article I will introduce a new command line search tool,
<a href="https://github.com/BurntSushi/ripgrep"><code>ripgrep</code></a>,
that combines the usability of
<a href="https://github.com/ggreer/the_silver_searcher">The Silver Searcher</a>
(an <a href="http://beyondgrep.com/"><code>ack</code></a> clone) with the
raw performance of GNU grep. <code>ripgrep</code> is fast, cross platform (with binaries
available for Linux, Mac and Windows) and written in
<a href="https://www.rust-lang.org/">Rust</a>.</p>
<p><code>ripgrep</code> is available on
<a href="https://github.com/BurntSushi/ripgrep">Github</a>.</p>
<p>We will attempt to do the impossible: a fair benchmark comparison between
several popular code search tools. Specifically, we will dive into a series of
25 benchmarks that substantiate the following claims:</p>
<ul>
<li>For both searching single files <em>and</em> huge directories of files, no other
tool obviously stands above <code>ripgrep</code> in either performance or correctness.</li>
<li><code>ripgrep</code> is the only tool with proper Unicode support that doesn’t make
you pay dearly for it.</li>
<li>Tools that search many files at once are generally <em>slower</em> if they use
memory maps, not faster.</li>
</ul>
<p>As someone who has worked on text search in Rust in their free time for the
last 2.5 years, and as the author of both <code>ripgrep</code> and
<a href="https://github.com/rust-lang-nursery/regex">the underlying regular expression engine</a>,
I will use this opportunity to provide detailed insights into the performance
of each code search tool. No benchmark will go unscrutinized!</p>
<p><strong>Target audience</strong>: Some familiarity with Unicode, programming and some
experience with working on the command line.</p>
<p><strong>NOTE</strong>: I’m hearing reports from some people that <code>rg</code> isn’t as fast as I’ve
claimed on their data. I’d love to help explain what’s going on, but to do
that, I’ll need to be able to reproduce your results. If you
<a href="https://github.com/BurntSushi/ripgrep/issues">file an issue</a>
with something I can reproduce, I’d be happy to try and explain it.</p>
<h2 id="screenshot-of-search-results">Screenshot of search results</h2>
<p><a href="https://burntsushi.net/stuff/ripgrep1.png"><img src="https://burntsushi.net/stuff/ripgrep1.png" alt="A screenshot of a sample search with ripgrep"></a></p>
<h2 id="table-of-contents">Table of Contents</h2>
<ul>
<li><a href="#introducing-ripgrep">Introducing ripgrep</a>
<ul>
<li><a href="#pitch">Pitch</a></li>
<li><a href="#anti-pitch">Anti-pitch</a></li>
<li><a href="#installation">Installation</a></li>
<li><a href="#whirlwind-tour">Whirlwind tour</a></li>
<li><a href="#regex-syntax">Regex syntax</a></li>
</ul>
</li>
<li><a href="#anatomy-of-a-grep">Anatomy of a grep</a>
<ul>
<li><a href="#background">Background</a></li>
<li><a href="#gathering-files-to-search">Gathering files to search</a></li>
<li><a href="#searching">Searching</a>
<ul>
<li><a href="#regex-engine">Regex engine</a></li>
<li><a href="#literal-optimizations">Literal optimizations</a></li>
<li><a href="#mechanics">Mechanics</a></li>
</ul>
</li>
<li><a href="#printing">Printing</a></li>
</ul>
</li>
<li><a href="#methodology">Methodology</a>
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#benchmark-runner">Benchmark runner</a></li>
<li><a href="#environment">Environment</a></li>
</ul>
</li>
<li><a href="#code-search-benchmarks">Code search benchmarks</a>
<ul>
<li><a href="#linux_literal_default"><code>linux_literal_default</code></a></li>
<li><a href="#linux_literal"><code>linux_literal</code></a></li>
<li><a href="#linux_literal_casei"><code>linux_literal_casei</code></a></li>
<li><a href="#linux_word"><code>linux_word</code></a></li>
<li><a href="#linux_unicode_word"><code>linux_unicode_word</code></a></li>
<li><a href="#linux_re_literal_suffix"><code>linux_re_literal_suffix</code></a></li>
<li><a href="#linux_alternates"><code>linux_alternates</code></a></li>
<li><a href="#linux_alternates_casei"><code>linux_alternates_casei</code></a></li>
<li><a href="#linux_unicode_greek"><code>linux_unicode_greek</code></a></li>
<li><a href="#linux_unicode_greek_casei"><code>linux_unicode_greek_casei</code></a></li>
<li><a href="#linux_no_literal"><code>linux_no_literal</code></a></li>
</ul>
</li>
<li><a href="#single-file-benchmarks">Single file benchmarks</a>
<ul>
<li><a href="#subtitles_literal"><code>subtitles_literal</code></a></li>
<li><a href="#subtitles_literal_casei"><code>subtitles_literal_casei</code></a></li>
<li><a href="#subtitles_alternate"><code>subtitles_alternate</code></a></li>
<li><a href="#subtitles_alternate_casei"><code>subtitles_alternate_casei</code></a></li>
<li><a href="#subtitles_surrounding_words"><code>subtitles_surrounding_words</code></a></li>
<li><a href="#subtitles_no_literal"><code>subtitles_no_literal</code></a></li>
</ul>
</li>
<li><a href="#bonus-benchmarks">Bonus benchmarks</a>
<ul>
<li><a href="#everything"><code>everything</code></a></li>
<li><a href="#nothing"><code>nothing</code></a></li>
<li><a href="#context"><code>context</code></a></li>
<li><a href="#huge"><code>huge</code></a></li>
</ul>
</li>
<li><a href="#conclusions">Conclusions</a></li>
</ul>
<h2 id="introducing-ripgrep">Introducing ripgrep</h2>
<h3 id="pitch">Pitch</h3>
<p>Why should you use <code>ripgrep</code> over any other search tool? Well…</p>
<ul>
<li>It can replace many use cases served by other search tools
because it contains most of their features and is generally faster. (See
<a href="https://github.com/BurntSushi/ripgrep/blob/master/FAQ.md#posix4ever">the FAQ</a>
for more details on whether ripgrep can truly replace grep.)</li>
<li>Like other tools specialized to code search, ripgrep defaults to recursive
directory search and won’t search files ignored by your <code>.gitignore</code> files.
It also ignores hidden and binary files by default. ripgrep also implements
full support for <code>.gitignore</code>, whereas there are many bugs related to that
functionality in other code search tools claiming to provide the same
functionality.</li>
<li>ripgrep can search specific types of files. For example, <code>rg -tpy foo</code>
limits your search to Python files and <code>rg -Tjs foo</code> excludes Javascript
files from your search. ripgrep can be taught about new file types with
custom matching rules.</li>
<li>ripgrep supports many features found in <code>grep</code>, such as showing the context
of search results, searching multiple patterns, highlighting matches with
color and full Unicode support. Unlike GNU grep, ripgrep stays fast while
supporting Unicode (which is always on).</li>
<li>ripgrep has optional support for switching its regex engine to use PCRE2.
Among other things, this makes it possible to use look-around and
backreferences in your patterns, which are not supported in ripgrep’s default
regex engine. PCRE2 support is enabled with <code>-P</code>.</li>
<li>ripgrep supports searching files in text encodings other than UTF-8, such
as UTF-16, latin-1, GBK, EUC-JP, Shift_JIS and more. (Some support for
automatically detecting UTF-16 is provided. Other text encodings must be
specifically specified with the <code>-E/--encoding</code> flag.)</li>
<li>ripgrep supports searching files compressed in a common format (gzip, xz,
lzma, bzip2 or lz4) with the <code>-z/--search-zip</code> flag.</li>
<li>ripgrep supports arbitrary input preprocessing filters which could be PDF
text extraction, less supported decompression, decrypting, automatic encoding
detection and so on.</li>
</ul>
<p>In other words, use ripgrep if you like speed, filtering by default, fewer
bugs and Unicode support.</p>
<h3 id="anti-pitch">Anti-pitch</h3>
<p>I’d like to try to convince you why you <em>shouldn’t</em> use <code>ripgrep</code>. Often, this
is far more revealing than reasons why I think you <em>should</em> use <code>ripgrep</code>.</p>
<p>Despite initially not wanting to add every feature under the sun to ripgrep,
over time, ripgrep has grown support for most features found in other
file searching tools. This includes searching for results spanning across
multiple lines, and opt-in support for PCRE2, which provides look-around and
backreference support.</p>
<p>At this point, the primary reasons not to use ripgrep probably consist of one
or more of the following:</p>
<ul>
<li>You need a portable and ubiquitous tool. While ripgrep works on Windows,
macOS and Linux, it is not ubiquitous and it does not conform to any
standard such as POSIX. The best tool for this job is good old grep.</li>
<li>There still exists some other feature (or bug) not listed in this README that
you rely on that’s in another tool that isn’t in ripgrep.</li>
<li>There is a performance edge case where ripgrep doesn’t do well where another
tool does do well. (Please file a bug report!)</li>
<li>ripgrep isn’t possible to install on your machine or isn’t available for your
platform. (Please file a bug report!)</li>
</ul>
<h3 id="installation">Installation</h3>
<p>The binary name for <code>ripgrep</code> is <code>rg</code>.</p>
<p><a href="https://github.com/BurntSushi/ripgrep/releases">Binaries for <code>ripgrep</code> are available for Windows, Mac and
Linux.</a> Linux binaries are
static executables. Windows binaries are available either as built with MinGW
(GNU) or with Microsoft Visual C++ (MSVC). When possible, prefer MSVC over GNU,
but you’ll need to have the
<a href="https://www.microsoft.com/en-us/download/details.aspx?id=48145">Microsoft VC++ 2015 redistributable</a>
installed.</p>
<p>If you’re a <strong>Homebrew</strong> user, then you can install it like so:</p>






<p>If you’re an <strong>Archlinux</strong> user, then you can install <code>ripgrep</code> from the
official repos:</p>






<p>If you’re a <strong>Rust programmer</strong>, <code>ripgrep</code> can be installed with <code>cargo</code>:</p>






<p>If you’d like to build <code>ripgrep</code> from source, that is also easy to do.
<code>ripgrep</code> is written in Rust, so you’ll need to grab a
<a href="https://www.rust-lang.org/">Rust installation</a> in order to compile it.
<code>ripgrep</code> compiles with Rust 1.9 (stable) or newer. To build:</p>



<div><pre tabindex="0"><code data-lang="sh"><span><span>$ git clone git://github.com/BurntSushi/ripgrep
</span></span><span><span>$ <span>cd</span> ripgrep
</span></span><span><span>$ cargo build --release
</span></span><span><span>$ ./target/release/rg --version
</span></span><span><span>0.1.2</span></span></code></pre></div>


<p>If you have a Rust nightly compiler, then you can enable optional SIMD
acceleration like so, which is used in all benchmarks reported in this article.</p>



<div><pre tabindex="0"><code data-lang="sh"><span><span><span>RUSTFLAGS</span><span>=</span><span>"-C target-cpu=native"</span> cargo build --release --features simd-accel</span></span></code></pre></div>


<h3 id="whirlwind-tour">Whirlwind tour</h3>
<p>The command line usage of <code>ripgrep</code> doesn’t differ much from other tools that
perform a similar function, so you probably already know how to use <code>ripgrep</code>.
The full details can be found in <code>rg --help</code>, but let’s go on a whirlwind tour.</p>
<p><code>ripgrep</code> detects when its printing to a terminal, and will automatically
colorize your output and show line numbers, just like The Silver Searcher.
Coloring works on Windows too! Colors can be controlled more granularly with
the <code>--color</code> flag.</p>
<p>One last thing before we get started: generally speaking, <code>ripgrep</code> assumes the
input is reading is UTF-8. However, if ripgrep notices a file is encoded as
UTF-16, then it will know how to search it. For other encodings, you’ll need to
explicitly specify them with the <code>-E/--encoding</code> flag.</p>
<p>To recursively search the current directory, while respecting all <code>.gitignore</code>
files, ignore hidden files and directories and skip binary files:</p>






<p>The above command also respects all <code>.rgignore</code> files, including in parent
directories. <code>.rgignore</code> files can be used when <code>.gitignore</code> files are
insufficient. In all cases, <code>.rgignore</code> patterns take precedence over
<code>.gitignore</code>.</p>
<p>To ignore all ignore files, use <code>-u</code>. To additionally search hidden files
and directories, use <code>-uu</code>. To additionally search binary files, use <code>-uuu</code>.
(In other words, “search everything, dammit!”) In particular, <code>rg -uuu</code> is
similar to <code>grep -a -r</code>.</p>



<div><pre tabindex="0"><code data-lang="sh"><span><span>$ rg -uu foobar  <span># similar to `grep -r`</span>
</span></span><span><span>$ rg -uuu foobar  <span># similar to `grep -a -r`</span></span></span></code></pre></div>


<p>(Tip: If your ignore files aren’t being adhered to like you expect, run your
search with the <code>--debug</code> flag.)</p>
<p>Make the search case insensitive with <code>-i</code>, invert the search with <code>-v</code> or
show the 2 lines before and after every search result with <code>-C2</code>.</p>
<p>Force all matches to be surrounded by word boundaries with <code>-w</code>.</p>
<p>Search and replace (find first and last names and swap them):</p>



<div><pre tabindex="0"><code data-lang="sh"><span><span>$ rg <span>'([A-Z][a-z]+)\s+([A-Z][a-z]+)'</span> --replace <span>'$2, $1'</span></span></span></code></pre></div>


<p>Named groups are supported:</p>



<div><pre tabindex="0"><code data-lang="sh"><span><span>$ rg <span>'(?P&lt;first&gt;[A-Z][a-z]+)\s+(?P&lt;last&gt;[A-Z][a-z]+)'</span> --replace <span>'$last, $first'</span></span></span></code></pre></div>


<p>Up the ante with full Unicode support, by matching any uppercase Unicode letter
followed by any sequence of lowercase Unicode letters (good luck doing this
with other search tools!):</p>



<div><pre tabindex="0"><code data-lang="sh"><span><span>$ rg <span>'(\p{Lu}\p{Ll}+)\s+(\p{Lu}\p{Ll}+)'</span> --replace <span>'$2, $1'</span></span></span></code></pre></div>


<p>Search only files matching a particular glob:</p>






<!-- raw HTML omitted -->
<p>Or exclude files matching a particular glob:</p>






<!-- raw HTML omitted -->
<p>Search only HTML and CSS files:</p>






<p>Search everything except for Javascript files:</p>






<p>To see a list of types supported, run <code>rg --type-list</code>. To add a new type, use
<code>--type-add</code>, which must be accompanied by a pattern for searching (<code>rg</code> won’t
persist your type settings):</p>



<div><pre tabindex="0"><code data-lang="sh"><span><span>$ rg --type-add <span>'foo:*.{foo,foobar}'</span> -tfoo bar</span></span></code></pre></div>


<p>The type <code>foo</code> will now match any file ending with the <code>.foo</code> or <code>.foobar</code>
extensions.</p>
<h3 id="regex-syntax">Regex syntax</h3>
<p>The syntax supported is
<a href="https://docs.rs/regex/1.*/regex/#syntax">documented as part of Rust’s regex library</a>.</p>
<h2 id="anatomy-of-a-grep">Anatomy of a grep</h2>
<p>Before we dive into benchmarks, I thought it might be useful to provide a high
level overview of how a grep-like search tool works, with a special focus on
<code>ripgrep</code> in particular. The goal of this section is to provide you with a bit
of context that will help make understanding the analysis for each benchmark
easier.</p>
<h3 id="background">Background</h3>
<p>Modulo parsing command line arguments, the first “real” step in any search tool
is figuring out what to search. Tools like <code>grep</code> don’t try to do anything
smart: they simply search the files given to it on the command line. An
exception to this is the <code>-r</code> flag, which will cause <code>grep</code> to recursively
search all files in the current directory. Various command line flags can be
passed to control which files are or aren’t searched.</p>
<p><a href="http://beyondgrep.com/"><code>ack</code></a> came along and turned this type of default
behavior on its head. Instead of trying to search everything by default, <code>ack</code>
tries to be smarter about what to search. For example, it will recursively
search your current directory <em>by default</em>, and it will automatically skip over
any source control specific files and directories (like <code>.git</code>). This method
of searching undoubtedly has its own pros and cons, because it tends to make
the tool “smarter,” which is another way of saying “opaque.” That is, when
you really do need the tool to search everything, it can sometimes be tricky
to know how to speak the right incantation for it to do so. With that said,
being smart by default is incredibly convenient, especially when “smart” means
“figure out what to search based on your source control configuration.” There’s
no shell alias that can do that with <code>grep</code>.</p>
<p>All of the other search tools in this benchmark share a common ancestor with
either <code>grep</code> or <code>ack</code>. <code>sift</code> is descended from <code>grep</code>, while <code>ag</code>, <code>ucg</code>, and
<code>pt</code> are descended from <code>ack</code>. <code>ripgrep</code> is a bit of a hybrid because it was
specifically built to be good at searching huge files just like <code>grep</code>, but at
the same time, provide the “smart” kind of default searching like <code>ack</code>.
Finally, <code>git grep</code> deserves a bit of a special mention. <code>git grep</code> is very
similar to plain <code>grep</code> in the kinds of options it supports, but its default
mode of searching is clearly descended from <code>ack</code>: it will only search files
checked into source control.</p>
<p>Of course, both types of search tools have <em>a lot</em> in common, but there are a
few broad distinctions worth making if you allow yourself to squint your eyes a
bit:</p>
<ul>
<li><code>grep</code>-like tools need to be really good at searching large files, so the
performance of the underlying regex library is paramount.</li>
<li><code>ack</code>-like tools need to be really good at recursive directory traversal
while also applying ignore rules from files like <code>.gitignore</code> quickly.
<code>ack</code>-like tools are built to run many searches in parallel, so the raw
performance of the underlying regex library can be papered over somewhat
while still being faster than single-threaded “search everything” tools like
<code>grep</code>. If the “smarts” of <code>ack</code> also mean skipping over that 2GB artifact
in your directory tree, then the performance difference becomes even bigger.</li>
<li><code>ripgrep</code> tries hard to combine the best of both worlds. Not only is its
underlying regex engine very fast, but it parallelizes searches and tries to
be smart about what it searches too.</li>
</ul>
<h3 id="gathering-files-to-search">Gathering files to search</h3>
<p>For an <code>ack</code>-like tool, it is important to figure out which files to search in
the current directory. This means using a very fast recursive directory
iterator, filtering file paths quickly and distributing those file paths to a
pool of workers that actually execute the search.</p>
<p>Directory traversal can be tricky because some recursive directory
iterators make more stat calls than are strictly necessary, which
can have a large impact on performance. It can be terribly difficult
to track down these types of performance problems because they
tend to be buried in a standard library somewhere. <a href="http://benhoyt.com/writings/scandir/">Python only
recently fixed this</a>, for
example. Rest assured that <a href="https://docs.rs/walkdir"><code>ripgrep</code> uses a recursive directory
iterator</a> that makes the minimum number
of system calls possible.</p>
<p>Filtering file paths requires not only respecting rules given at the command
line (e.g., <code>grep</code>’s <code>--include</code> or <code>--exclude</code>) flags, but also requires
reading files like <code>.gitignore</code> and applying their rules correctly to all file
paths. Even the mere act of looking for a <code>.gitignore</code> file in every directory
can have measurable overhead! Otherwise, the key performance challenge with
this functionality is making sure you don’t try to match every ignore rule
individually against every file path. Large repositories like the Linux kernel
source tree have over a hundred <code>.gitignore</code> files with thousands of rules
combined.</p>
<p>Finally, distributing work to other threads for searching requires some kind of
synchronization. One solution is a mutex protected ring buffer that acts as
a sort of queue, but there are lock-free solutions that might be faster.
Rust’s ecosystem is so great that I was able to reuse a lock-free <a href="https://github.com/kinghajj/deque">Chase-Lev
work-stealing queue</a> for distributing work
to a pool of searchers. Every <em>other</em> tool that parallelizes work in this
benchmark uses a variant of a mutex protected queue. (<code>sift</code> and <code>pt</code> might not
fit this criteria, since they use Go channels, and I haven’t followed any
implementation improvements to that code for a few years.)</p>
<h3 id="searching">Searching</h3>
<p>Searching is the heart of any of these tools, and we could dig ourselves into a
hole on just this section alone and not come out alive for at least 2.5 years.
(Welcome to “How Long I’ve Been Working On Text Search In Rust.”) Instead, we
will lightly touch on the big points.</p>
<h4 id="regex-engine">Regex engine</h4>
<p>First up is the regex engine. Every search tool supports some kind of syntax
for regular expressions. Some examples:</p>
<ul>
<li><code>foo|bar</code> matches any literal string <code>foo</code> or <code>bar</code></li>
<li><code>[a-z]{2}_[a-z]+</code> matches two lowercase latin letters, followed by an
underscore, followed by one or more lowercase latin letters.</li>
<li><code>\bfoo\b</code> matches the literal <code>foo</code> only when it is surrounded by word
boundaries. For example, the <code>foo</code> in <code>foobar</code> won’t match but it will in
<code>I love foo.</code>.</li>
<li><code>(\w+) \1</code> matches any sequence of word characters followed by a space and
followed by exactly the word characters that were matched previously. The
<code>\1</code> in this example is called a “back-reference.” For example, this pattern
will match <code>foo foo</code> but not <code>foo bar</code>.</li>
</ul>
<p>Regular expression engines themselves tend to be divided into two categories
predominantly based on the features they expose. Regex engines that provide
support for all of the above tend to use an approach called <em>backtracking</em>,
which is typically quite fast, but can be very slow on some inputs. “Very
slow” in this case means that it might take exponential time to complete a
search. For example, try running this Python code:</p>



<div><pre tabindex="0"><code data-lang="python"><span><span><span>&gt;&gt;&gt;</span> <span>import</span> <span>re</span>
</span></span><span><span><span>&gt;&gt;&gt;</span> <span>re</span><span>.</span><span>search</span><span>(</span><span>'(a*)*c'</span><span>,</span> <span>'a'</span> <span>*</span> <span>30</span><span>)</span></span></span></code></pre></div>


<p>Even though both the regex and the search string are tiny, it will take a very
long time to terminate, and this is because the underlying regex engine uses
backtracking, and can therefore take exponential time to answer some queries.</p>
<p>The other type of regex engine generally supports fewer features and is based
on finite automata. For example, these kinds of regex engines typically don’t
support back-references. Instead, these regex engines will often provide a
guarantee that <em>all searches</em>, regardless of the regex or the input, will
complete in linear time with respect to the search text.</p>
<p>It’s worth pointing out that neither type of engine has a monopoly on average
case performance. There are examples of regex engines of both types that are
blazing fast. With that said, here’s a breakdown of some search tools and the
type of regex engine they use:</p>
<ul>
<li>GNU grep and <code>git grep</code> each use their own hand-rolled finite automata based
engine.</li>
<li><code>ripgrep</code> uses
<a href="https://github.com/rust-lang-nursery/regex">Rust’s regex library</a>,
which uses finite automata.</li>
<li>The Silver Searcher and Universal Code Grep use <a href="http://www.pcre.org/">PCRE</a>,
which uses backtracking.</li>
<li>Both The Platinum Searcher and sift use
<a href="https://golang.org/pkg/regexp/">Go’s regex library</a>,
which uses finite automata.</li>
</ul>
<p>Both Rust’s regex library and Go’s regex library share Google’s
<a href="https://github.com/google/re2">RE2</a>
as a common ancestor.</p>
<p>Finally, both tools that use PCRE (The Silver Searcher and Universal Code Grep)
are susceptible to worst case backtracking behavior. For example:</p>



<div><pre tabindex="0"><code data-lang="sh"><span><span>$ cat wat
</span></span><span><span>c
</span></span><span><span>aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa
</span></span><span><span>c
</span></span><span><span>$ ucg <span>'(a*)*c'</span> wat
</span></span><span><span>terminate called after throwing an instance of <span>'FileScannerException'</span>
</span></span><span><span>  what<span>()</span>:  PCRE2 match error: match limit exceeded
</span></span><span><span>Aborted <span>(</span>core dumped<span>)</span></span></span></code></pre></div>


<p>The Silver Searcher fails similarly. It reports the first line as a match and
neglects the match in the third line. The rest of the search tools benchmarked
in this article handle this case without a problem.</p>
<h4 id="literal-optimizations">Literal optimizations</h4>
<p>Picking a fast regex engine is important, because every search tool will need
to rely on it sooner or later. Nevertheless, even the performance of the
fastest regex engine can be dwarfed by the time it takes to search for a simple
literal string.
<a href="https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore_string_search_algorithm">Boyer-Moore</a>
is the classical algorithm that is used to find a substring, and even today, it
is hard to beat for general purpose searching. One of its defining qualities is
its ability to skip some characters in the search text by pre-computing a small
skip table at the beginning of the search.</p>
<p>On modern CPUs, the key to making a Boyer-Moore implementation fast is not
necessarily the number of characters it can skip, but how fast it can identify
a candidate for a match. For example, most Boyer-Moore implementations look for
the <em>last</em> byte in a literal. Each occurrence of that byte is considered a
candidate for a match by Boyer-Moore. It is only at this point that Boyer-Moore
can use its precomputed table to skip characters, which means you still need a
fast way of identifying the candidate in the first place. Thankfully,
specialized routines found in the C standard library, like
<a href="http://man7.org/linux/man-pages/man3/memchr.3.html"><code>memchr</code></a>,
exist for precisely this purpose. Often, <code>memchr</code> implementations are compiled
down to SIMD instructions that examine <em>sixteen</em> bytes in a single loop
iteration. This makes it very fast. On my system, <code>memchr</code> often gets
throughputs at around several gigabytes a second. (In my own experiments,
Boyer-Moore with <code>memchr</code> can be just as fast as an explicit SIMD
implementation using the
<a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/#text=PCMPESTR&amp;expand=786">PCMPESTRI</a>
instruction, but this is something I’d like to revisit.)</p>
<p>For a search tool to compete in most benchmarks, either it or its regex engine
needs to use some kind of literal optimizations. For example, Rust’s regex
library goes to great lengths to extract both prefix and suffix literals from
every pattern. The following patterns all have literals extracted from them:</p>
<ul>
<li><code>foo|bar</code> detects <code>foo</code> and <code>bar</code></li>
<li><code>(a|b)c</code> detects <code>ac</code> and <code>bc</code></li>
<li><code>[ab]foo[yz]</code> detects <code>afooy</code>, <code>afooz</code>, <code>bfooy</code> and <code>bfooz</code></li>
<li><code>(foo)?bar</code> detects <code>foobar</code> and <code>bar</code></li>
<li><code>(foo)*bar</code> detects <code>foo</code> and <code>bar</code></li>
<li><code>(foo){3,6}</code> detects <code>foofoofoo</code></li>
</ul>
<p>If any of these patterns appear at the <em>beginning</em> of a regex, Rust’s regex
library will notice them and use them to find candidate matches very quickly
(even when there is more than one literal detected). While Rust’s core regex
engine is fast, it is still faster to look for literals first, and only drop
down into the core regex engine when it’s time to verify a match.</p>
<p>The best case happens when an entire regex can be broken down into a single
literal or an alternation of literals. In that case, the core regex engine
won’t be used at all!</p>
<p>A search tool in particular has an additional trick up its sleeve. Namely,
since most search tools do line-by-line searching (The Silver Searcher is a
notable exception, which does multiline searching by default), they can extract
<em>non-prefix</em> or “inner” literals from a regex pattern, and search for those to
identify candidate <em>lines</em> that match. For example, the regex <code>\w+foo\d+</code> could
have <code>foo</code> extracted. Namely, when a candidate line is found, <code>ripgrep</code> will
find the beginning and end of only that line, and then run the full regex
engine on the entire line. This lets <code>ripgrep</code> very quickly skip through files
by staying out of the regex engine. Most of the search tools we benchmark here
don’t perform this optimization, which can leave a lot of performance on the
table, especially if your core regex engine isn’t that fast.</p>
<p>Handling the case of multiple literals (e.g., <code>foo|bar</code>) is just as important.
GNU grep uses a little known algorithm similar to
<a href="https://en.wikipedia.org/wiki/Commentz-Walter_algorithm">Commentz-Walter</a>
for searching multiple patterns. In short, Commentz-Walter is what you get when
you merge
<a href="https://en.wikipedia.org/wiki/Aho%E2%80%93Corasick_algorithm">Aho-Corasick</a>
with Boyer-Moore: a skip table with a <em>reverse</em> automaton.
Rust’s regex library, on the other hand, will either use plain Aho-Corasick,
or, when enabled, a special
<a href="https://github.com/rust-lang-nursery/regex/blob/3de8c44f5357d5b582a80b7282480e38e8b7d50d/src/simd_accel/teddy128.rs">SIMD algorithm called
Teddy</a>,
which was invented by Geoffrey Langdale as part of the
<a href="https://github.com/01org/hyperscan">Hyperscan regex library</a>
developed by Intel. This SIMD algorithm will prove to be at least one of the
key optimizations that propels <code>ripgrep</code> past GNU grep.</p>
<p>The great thing about this is that <code>ripgrep</code> doesn’t have to do much of this
literal optimization work itself. Most of it is done inside Rust’s regex
library, so every consumer of that library gets all these performance
optimizations automatically!</p>
<h4 id="mechanics">Mechanics</h4>
<p>Repeat after me: Thou Shalt Not Search Line By Line.</p>
<p>The naive approach to implementing a search tool is to read a file line by line
and apply the search pattern to each line individually. This approach is
problematic primarily because, in the common case, finding a match is <em>rare</em>.
Therefore, you wind up doing a ton of work parsing out each line all for
naught, because most files simply aren’t going to match at all in a large
repository of code.</p>
<p>Not only is finding every line extra work that you don’t need to do, but you’re
also paying a huge price in overhead. Whether you’re searching for a literal or
a regex, you’ll need to start and stop that search for every single line in a
file. The overhead of each search will be your undoing.</p>
<p>Instead, all search tools find a way to search a big buffer of bytes all at
once. Whether that’s memory mapping a file, reading an entire file into memory
at once or incrementally searching a file using a constant sized intermediate
buffer, they all find a way to do it to some extent. There are some exceptions
though. For example, tools that use memory maps or read entire files into
memory either can’t support <code>stdin</code> (like Universal Code Grep), or revert to
line-by-line searching (like The Silver Searcher). Tools that support
incremental searching (<code>ripgrep</code>, GNU grep and <code>git grep</code>) can use its
incremental approach on any file or stream with no problems.</p>
<p>There’s a reason why not every tool implements incremental search: it’s <em>hard</em>.
For example, you need to consider all of the following in a fully featured
search tool:</p>
<ul>
<li>Line counting, when requested.</li>
<li>If a read from a file ends in the middle of a line, you need to do the
bookkeeping required to make sure the incomplete line isn’t searched until
more data is read from the file.</li>
<li>If a line is too long to fit into your buffer, you need to decide to either
give up or grow your buffer to fit it.</li>
<li>Your searcher needs to know how to invert the match.</li>
<li>Worst of all: your searcher needs to be able to show the context of a match,
e.g., the lines before and after a matching line. For example, consider the
case of a match that appears at the beginning of your buffer. How do you show
the previous lines if they aren’t in your buffer? You guessed it: you need to
carry over at least as many lines that are required to satisfy a context
request from buffer to buffer.</li>
</ul>
<p>It’s a steep price to pay in terms of code complexity, but by golly, is it
worth it. You’ll need to read on to the benchmarks to discover when it is
faster than memory maps!</p>
<h3 id="printing">Printing</h3>
<p>It might seem like printing is such a trivial step, but it must be done with at
least some care. For example, you can’t just print matches from each search
thread as you find them, because you really don’t want to interleave the search
results of one file with the search results of another file. A naive approach
to this is to serialize the printer so that only one thread can print to it at
a time. This is problematic though, because if a search thread acquires a lock
to the printer before starting the search (and not releasing it until it has
finished searching one file), you’ll end up also serializing every search as
well, effectively defeating your entire approach to parallelism.</p>
<p>All code search tools in this benchmark that parallelize search therefore write
results to some kind of intermediate buffer <em>in memory</em>. This enables all of
the search threads to actually perform a search in parallel. The printing still
needs to be serialized, but we’ve reduced that down to simply dumping the
contents of the intermediate buffer to <code>stdout</code>. Using an in memory buffer
might set off alarm bells: what if you search a 2GB file and every line
matches? Doesn’t that lead to excessive memory usage? The answer is: “Why,
yes, indeed it does!” The key insight is that the common case is returning far
fewer matches than there are total lines searched. Nevertheless, there are
ways to mitigate excessive memory usage. For example, if <code>ripgrep</code> is used to
search <code>stdin</code> or a single file, then it will write search results directly
to <code>stdout</code> and forgo the intermediate buffer because it just doesn’t need
it. (<code>ripgrep</code> should also do this when asked to <em>not</em> do any parallelism,
but I haven’t gotten to it yet.) In other words, pick two: space, time or
correctness.</p>
<p>Note that the details aren’t quite the same in every tool. Namely, while The
Silver Searcher and Universal Code Grep write matches as structured data to
memory (i.e., an array of <code>match</code> structs or something similar), both <code>git grep</code> and <code>ripgrep</code> write the actual output to a dynamically growable string
buffer in memory. While either approach does seem to be fast enough, <code>git grep</code>
and <code>ripgrep</code> have to do things this way because they support incremental
search where as The Silver Searcher always memory maps the entire file and
Universal Code Grep always reads the entire contents of the file into memory.
The latter approach can refer back to the file’s contents in memory when doing
the actual printing, where as neither <code>git grep</code> nor <code>ripgrep</code> can do that.</p>
<h2 id="methodology">Methodology</h2>
<h3 id="overview">Overview</h3>
<p>Coming up with a good and fair benchmark is <em>hard</em>, and I have assuredly made
some mistakes in doing so. In particular, there are so many variables to
control for that testing every possible permutation isn’t feasible. This means
that the benchmarks I’m presenting here are <em>curated</em>, and, given that I am the
author of one of the tools in the benchmark, they are therefore also <em>biased</em>.
Nevertheless, even if I fail in my effort to provide a fair benchmark suite, I
do hope that some of you may find my analysis interesting, which will try to
explain the results in each benchmark. The analysis is in turn heavily biased
toward explaining my own work, since that is the implementation I’m most
familiar with. I have, however, read at least part of the source code of every
tool I benchmark, including their underlying regex engines.</p>
<p>In other words, I’m pretty confident that I’ve gotten the <em>details</em> correct,
but I could have missed something in the bigger picture. Because of that, let’s
go over some important insights that guided construction of this benchmark.</p>
<ul>
<li>Focus on the problem that an <em>end user</em> is trying to solve. For example, we
split the entire benchmark in two: one for searching a large directory of
files and one for searching a single large file. The former might correspond
to an end user searching their code while the latter might correspond to an
end user searching logs. As we will see, these two use cases have markedly
different performance characteristics. A tool that is good at one isn’t
necessarily good at the other. (The premise of <code>ripgrep</code> is that it is
possible to be good at both!)</li>
<li>Apply <em>end user</em> problems more granularly as well. For example, most
searches result in few hits relative to the corpus searched, so prefer
benchmarks that report few matches. Another example: I hypothesize, based on
my own experience, that most searches use patterns that are simple literals,
alternations or very light regexes, so bias the benchmarks towards those
types of patterns.</li>
<li>Almost every search tool has slightly different default behavior, and these
behavioral changes can have an impact on performance. There is some value in
looking at “out-of-the-box” performance, and we therefore do look at a
benchmark for that, but stopping there is a bit unsatisfying. If our goal is
to do a <em>fair</em> comparison, then we need to at least try to convince each tool
to do roughly the same work, <strong>from the perspective of an end user</strong>. A good
example of this is reporting line numbers. Some tools don’t provide a way of
disabling line counting, so when doing comparisons between tools that do, we
need to explicitly enable line numbers. This is important, because counting
lines can be quite costly! A good <em>non-example</em> of this is if one tool uses
memory maps and another uses an intermediate buffer. This is an
implementation choice, and not one that alters what the user actually sees,
therefore comparing those two implementation choices in a benchmark is
completely fair (assuming an analysis that points it out).</li>
</ul>
<p>With that out of the way, let’s get into the nitty gritty. First and foremost,
what tools are we benchmarking?</p>
<ul>
<li><a href="https://github.com/BurntSushi/ripgrep"><code>ripgrep</code> (rg)</a> (v0.1.2) - You’ve
heard enough about this one already.</li>
<li><a href="https://www.gnu.org/software/grep/">GNU grep</a> (v2.25) - Ol’ reliable.</li>
<li><a href="https://www.kernel.org/pub/software/scm/git/docs/git-grep.html">git grep</a>
(v2.7.4) -
Like <code>grep</code>, but built into <code>git</code>. Only works well in <code>git</code> repositories.</li>
<li><a href="https://github.com/ggreer/the_silver_searcher">The Silver Searcher (ag)</a>
(commit <code>cda635</code>, using PCRE 8.38) - Like <code>ack</code>, but written in C and much
faster. Reads your <code>.gitignore</code> files just like <code>ripgrep</code>.</li>
<li><a href="https://github.com/gvansickle/ucg">Universal Code Grep (ucg)</a> (commit
<code>487bfb</code>, using PCRE 10.21 <strong>with the JIT enabled</strong>) - Also like <code>ack</code> but
written in C++, and only searches files from a whitelist, and doesn’t support
reading <code>.gitignore</code>.</li>
<li><a href="https://github.com/monochromegane/the_platinum_searcher">The Platinum Searcher
(pt)</a> (commit
<code>509368</code>) - Written in Go and does support <code>.gitignore</code> files.</li>
<li><a href="https://github.com/svent/sift">sift</a> (commit <code>2d175c</code>) - Written in Go and
supports <code>.gitignore</code> files with an optional flag, but generally prefers
searching everything (unlike every other tool in this list except for
<code>grep</code>).</li>
</ul>
<p>Notably absent from this list is <code>ack</code>. I chose not to benchmark it because,
at the time of writing, <code>ack</code> was much slower than the other tools in this
list. However, <a href="https://beyondgrep.com/ack3/">ack 3 is now in beta</a> and
includes some performance improvements, sometimes decreasing search times by
half.</p>
<h3 id="benchmark-runner">Benchmark runner</h3>
<p>The benchmark runner is a Python program (requires at least Python 3.5) that
you can use to not only run the benchmarks themselves, but download the corpora
used in the benchmarks as well. The script is called <code>benchsuite</code> and
<a href="https://github.com/BurntSushi/ripgrep/blob/master/benchsuite/benchsuite">is in the <code>ripgrep</code>
repository</a>.
You can use it like so:</p>



<div><pre tabindex="0"><code data-lang="sh"><span><span>$ git clone git://github.com/BurntSushi/ripgrep
</span></span><span><span>$ <span>cd</span> ripgrep/benchsuite
</span></span><span><span><span># WARNING! This downloads several GB of data, and builds the Linux kernel.</span>
</span></span><span><span><span># This took about 15 minutes on a high speed connection.</span>
</span></span><span><span><span># Tip: try `--download subtitles-ru` to grab the smallest corpus, but you'll</span>
</span></span><span><span><span># be limited to running benchmarks for only that corpus.</span>
</span></span><span><span>$ ./benchsuite --dir /path/to/data/dir --download all
</span></span><span><span><span># List benchmarks available.</span>
</span></span><span><span>$ ./benchsuite --dir /path/to/data/dir --list
</span></span><span><span><span># Run a benchmark.</span>
</span></span><span><span><span># Omit the benchmark name to run all benchmarks. The full suite can take around</span>
</span></span><span><span><span># 30 minutes to complete on default settings and 120 minutes to complete with</span>
</span></span><span><span><span># --warmup-iter 3 --bench-iter 10.</span>
</span></span><span><span>$ ./benchsuite --dir /path/to/data/dir <span>'^subtitles_ru_literal$'</span></span></span></code></pre></div>


<p>If you don’t have all of the code search tools used in the benchmarks, then
pass <code>--allow-missing</code> to give <code>benchsuite</code> permission to skip running them. To
save the raw data (the timing for every command run), pass <code>--raw /path/to/raw.csv</code>.</p>
<p>The benchmark runner tries to do a few basic things for us to help reduce the
chance that we get misleading data:</p>
<ul>
<li>Every benchmarked command is run three times before being measured as a
“warm up.” Specifically, this is to ensure that the corpora being searched
is already in the operating system’s page cache. If we didn’t do this, we
might end up benchmarking disk I/O, which is not only uninteresting for our
purposes, but is probably not a common end user scenario. It’s more likely
that you’ll be executing lots of searches against the same corpus (at least,
I know I do).</li>
<li>Every benchmarked command is run ten times, with a timing recorded for each
run. The final “result” of that command is its distribution (mean +/-
standard deviation). If I were a statistician, I could probably prove that
ten samples is insufficient. Nevertheless, getting more samples takes more
time, and for the most part, the variance is very low.</li>
</ul>
<p>Each individual benchmark definition is responsible for making sure each
command is trying to do similar work as other commands we’re comparing it to.
For example, we need to be careful to enable and disable Unicode support in GNU
grep where appropriate, because full Unicode handling can make GNU grep run
very slowly. Within each benchmark, there are often multiple variables of
interest. To account for this, I’ve added labels like <code>(ASCII)</code> or
<code>(whitelist)</code> where appropriate. We’ll dig into those labels in more detail
later.</p>
<p>Please also feel encouraged to add your own benchmarks if you’d like to play
around. The benchmarks are in the top-half of the file, and it should be fairly
straight-forward to copy &amp; paste another benchmark and modify it. Simply
defining a new benchmark will make it available. The second half of the script
is the runner itself and probably shouldn’t need to be modified.</p>
<h3 id="environment">Environment</h3>
<p>The actual environment used to run the benchmarks presented in this article was
a <code>c3.2xlarge</code> instance on Amazon EC2. It ran Ubuntu 16.04, had a Xeon E5-2680
2.8 GHz CPU, 16 GB of memory and an 80 GB SSD (on which the corpora was
stored). This was enough memory to fit all of the corpora in memory. The box
was specifically provisioned for the purpose of running benchmarks, so it was
not doing anything else.</p>
<p>The full log of system setup and commands I used to install each of the search
tools and run benchmarks can be found
<a href="https://github.com/BurntSushi/ripgrep/blob/master/benchsuite/runs/2016-09-20-ubuntu1604-ec2/README.SETUP">here</a>.
I also captured the
<a href="https://github.com/BurntSushi/ripgrep/blob/master/benchsuite/runs/2016-09-20-ubuntu1604-ec2/summary">output of the bench runner (SPOILER ALERT)</a>
and the
<a href="https://github.com/BurntSushi/ripgrep/blob/master/benchsuite/runs/2016-09-20-ubuntu1604-ec2/raw.csv">raw output</a>,
which includes the timings, full set of command line arguments and any
environment variables set for every command run in every benchmark.</p>
<h2 id="code-search-benchmarks">Code search benchmarks</h2>
<p>This is the first half of our benchmarks, and corresponds to an <em>end user</em>
trying to search a large repository of code for a particular pattern.</p>
<p>The corpus used for this benchmark is a <em>built</em> checkout of the Linux kernel,
specifically commit <code>d0acc7</code>. We actually build the Linux kernel because the
process of building the kernel leaves a lot of garbage in the repository that
you probably don’t want to search. This can influence not only the relevance of
the results returned by a search tool, but the performance as well.</p>
<p>All benchmarks run in this section were run in the root of the repository.
Remember, you can see the full
<a href="https://github.com/BurntSushi/ripgrep/blob/master/benchsuite/runs/2016-09-20-ubuntu1604-ec2/raw.csv">raw results of each command</a>
if you like. The benchmark names correspond to the headings below.</p>
<p>Note that since these benchmarks were run on an EC2 instance, which uses a VM,
which in turn can penalize search tools that use memory maps, I’ve also
<a href="https://github.com/BurntSushi/ripgrep/blob/master/benchsuite/runs/2016-09-22-archlinux-cheetah/summary">recorded benchmarks on my local
machine</a>.
My local machine is an Intel i7-6900K 3.2 GHz, 16 CPUs, 64 GB memory and an
SSD. You’ll notice that <code>ag</code> does a lot better (but still worse than <code>rg</code>)
on my machine. Lest you think I’ve chosen results from the EC2 machine because
they paint <code>rg</code> more favorably, rest assured that I haven’t. Namely, <code>rg</code> wins
<em>every single benchmark</em> on my local machine except for <em>one</em>, where as <code>rg</code> is
beat out just slightly by a few tools on some benchmarks on the EC2 machine.</p>
<p>Without further ado, let’s start looking at benchmarks.</p>
<h3 id="linux_literal_default"><code>linux_literal_default</code></h3>
<p><strong>Description</strong>: This benchmark compares the time it takes to execute a simple
literal search using each tool’s default settings. This is an intentionally
unfair benchmark meant to highlight the differences between tools and their
“out-of-the-box” settings.</p>
<p><strong>Pattern</strong>: <code>PM_RESUME</code></p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg         0.349 +/- 0.104 (lines: 16)
</span></span><span><span>ag         1.589 +/- 0.009 (lines: 16)
</span></span><span><span>ucg        0.218 +/- 0.007 (lines: 16)*+
</span></span><span><span>pt         0.462 +/- 0.012 (lines: 16)
</span></span><span><span>sift       0.352 +/- 0.018 (lines: 16)
</span></span><span><span>git grep   0.342 +/- 0.005 (lines: 16)</span></span></code></pre></div>


<ul>
<li><code>*</code> - Best mean time.</li>
<li><code>+</code> - Best sample time.</li>
<li><code>rg == ripgrep</code>, <code>ag == The Silver Searcher</code>, <code>ucg == Universal Code Grep</code>,
<code>pt == The Platinum Searcher</code></li>
</ul>
<p><strong>Analysis</strong>: We’ll first start by actually describing what each tool is doing:</p>
<ul>
<li><code>rg</code> respects the Linux repo’s <code>.gitignore</code> files (of which there are
<code>178</code>(!) of them), and skips hidden and binary files. <code>rg</code> does not count
lines.</li>
<li><code>ag</code> has the same default behavior as <code>rg</code>, except it counts lines.</li>
<li><code>ucg</code> also counts lines, but does not attempt to read <code>.gitignore</code> files.
Instead, it only searches files from an (extensible) whitelist according
to a set of glob rules. For example, both <code>rg</code> and <code>ag</code> will search
<code>fs/jffs2/README.Locking</code> while <code>ucg</code> won’t, because it doesn’t recognize
the <code>Locking</code> extension. (A search tool probably <em>should</em> search that file,
although it does not impact the results of this specific benchmark.)</li>
<li><code>pt</code> has the same default behavior as <code>ag</code>.</li>
<li><code>sift</code> searches everything, including binary files and hidden files. It
<em>should</em> be equivalent to <code>grep -r</code>, for example. It also does not count
lines.</li>
<li><code>git grep</code> should have the same behavior at <code>rg</code>, and similarly does not
count lines. Note though that <code>git grep</code> has a special advantage: it does not
need to traverse the directory hierarchy. It can discover the set of files to
search straight from its git index.</li>
</ul>
<p>The high-order bit to extract from this benchmark is that a naive comparison
between search tools is completely unfair from the perspective of performance,
but is really important if you care about the <em>relevance</em> of results returned
to you. <code>sift</code>, like <code>grep -r</code>, will throw everything it can back at you, which
is totally at odds with the philosophy behind every other tool in this
benchmark: only return results that are <em>probably</em> relevant. Things inside your
<code>.git</code> probably aren’t, for example. (This isn’t to say that <code>sift</code>’s
philosophy is wrong. The tool is clearly intended to be configured by an end
user to their own tastes, which has its own pros and cons.)</p>
<p>With respect to performance, there are two key variables to pay attention to.
They will appear again and again throughout our benchmark:</p>
<ul>
<li>Counting lines <em>can be</em> quite expensive. A naive solution—a loop over every
byte and comparing it to a <code>\n</code>—will be quite slow for example.
<a href="https://github.com/gvansickle/ucg/blob/8bbebc002bbf112d147928f89677cba703d007bb/src/FileScanner_sse4_2.cpp#L190">Universal Code Grep counts lines using SIMD</a>
and
<a href="https://github.com/BurntSushi/ripgrep/blob/919c5c72994edb378706594f6268542983eeee6d/src/search_stream.rs#L549"><code>ripgrep</code> counts lines using packed comparisons (16 bytes at a time)</a>.
However, in the Linux code search benchmarks, because the size of each
individual file is very small and the number of matches is tiny compared
to the corpus size, the time spent counting lines tends to not be so
significant. Especially since every tool in this benchmark parallelizes
search to some degree. When we get to the single-file benchmarks, this
variable will become much more pertinent.</li>
<li>Respecting <code>.gitignore</code> files incurs some amount of overhead. Even though
respecting <code>.gitignore</code> reduces the number of files searched, it can be
slower overall to actually read the patterns, compile them and match them
against every path than to just search every file. This is precisely how
<code>ucg</code> soundly beats <code>ripgrep</code> in this benchmark. (We will control for this
variable in future benchmarks.) In other words, respecting <code>.gitignore</code> is a
feature that improves <em>relevance</em> first and foremost. It is strictly a bonus
if it also happens to improve performance.</li>
</ul>
<p>The specific reasons why supporting <code>.gitignore</code> leads to a slower overall
search are:</p>
<ul>
<li>Every directory descended requires looking for a corresponding <code>.gitignore</code>.
Multiply the number of calls if you support additional ignore files, like
both The Silver Searcher and <code>ripgrep</code> do. The Linux kernel repository has
<code>4,640</code> directories. <code>178</code> of them have <code>.gitignore</code> files.</li>
<li>Each <code>.gitignore</code> file needs to be compiled into something that can match
file paths. Both The Silver Searcher and <code>ripgrep</code> use tricks to make this
faster. For example, simple patterns like <code>/vmlinux</code> or <code>*.o</code> can be matched
using simple literal comparisons or by looking at the file extension of a
candidate path and comparing it directly. For more complex patterns like
<code>*.c.[012]*.*</code>, a full glob matcher needs to be used. The Silver Searcher
uses <code>fnmatch</code> while <code>ripgrep</code> translates all such globs into a single
regular expression which can be matched against a single path all at once.
Doing all this work takes time.</li>
<li>Unlike <code>ag</code>, <code>rg</code> will try to support the full semantics of a <code>.gitignore</code>
file. This means finding <em>every</em> ignore pattern that matches a file path and
giving precedent to the most recently defined pattern. <code>ag</code> will bail on the
first match it sees.</li>
<li>Actually matching a path has non-trivial overhead that must be paid for
<em>every</em> path searched. The compilation phase described above is complex
precisely for making this part faster. We try to stay out of the regex
machinery as best we can, but we can’t avoid it completely.</li>
</ul>
<p>In contrast, a whitelist like the one used by <code>ucg</code> is comparatively easy to
make fast. The set of globs is known upfront, so no additional checks need to
be made while traversing the file tree. Moreover, the globs tend to be of the
<code>*.ext</code> variety, which fall into the bucket of globs that can be matched
efficiently just by looking at the extension of a file path.</p>
<p>The downside of a whitelist is obvious: you might end up missing search results
simply because <code>ucg</code> didn’t know about a particular file extension. You could
always teach <code>ucg</code> about the file extension, but you’re still blind to “unknown
unknowns” (i.e., files that you probably want to search but didn’t know upfront
that you needed to).</p>
<h3 id="linux_literal"><code>linux_literal</code></h3>
<p><strong>Description</strong>: This benchmark runs the same query as in the
<a href="#linux-literal-default"><code>linux_literal_default</code></a>
benchmark, but we try to do a fair comparison. In particular, we run <code>ripgrep</code>
in two modes: one where it respects <code>.gitignore</code> files (corresponding to
the <code>(ignore)</code> label) and one where it uses a whitelist and doesn’t respect
<code>.gitignore</code> (corresponding to the <code>(whitelist)</code> label). The former mode is
comparable to <code>ag</code>, <code>pt</code>, <code>sift</code> and <code>git grep</code>, while the latter mode is
comparable to <code>ucg</code>. We also run <code>rg</code> a third time by explicitly telling it
to use memory maps for search, which matches the implementation strategy used
by <code>ag</code>. <code>sift</code> is run such that it respects <code>.gitignore</code> files and excludes
binary, hidden and PDF files. All commands executed here count lines, because
some commands (<code>ag</code> and <code>ucg</code>) don’t support disabling line counting.</p>
<p><strong>Pattern</strong>: <code>PM_RESUME</code></p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg (ignore)          0.334 +/- 0.053 (lines: 16)
</span></span><span><span>rg (ignore) (mmap)   1.611 +/- 0.009 (lines: 16)
</span></span><span><span>ag (ignore) (mmap)   1.588 +/- 0.011 (lines: 16)
</span></span><span><span>pt (ignore)          0.456 +/- 0.025 (lines: 16)
</span></span><span><span>sift (ignore)        0.630 +/- 0.004 (lines: 16)
</span></span><span><span>git grep (ignore)    0.345 +/- 0.007 (lines: 16)
</span></span><span><span>rg (whitelist)       0.228 +/- 0.042 (lines: 16)+
</span></span><span><span>ucg (whitelist)      0.218 +/- 0.007 (lines: 16)*</span></span></code></pre></div>


<ul>
<li><code>*</code> - Best mean time.</li>
<li><code>+</code> - Best sample time.</li>
</ul>
<p><strong>Analysis</strong>: We have a ton of ground to cover on this one.</p>
<p>First and foremost, the <code>(ignore)</code> vs. <code>(whitelist)</code> variables have a clear
impact on the performance of <code>rg</code>. We won’t rehash all the details from the
analysis in
<a href="#linux-literal-default"><code>linux_literal_default</code></a>,
but switching <code>rg</code> into its whitelist mode brings it into a dead heat with
<code>ucg</code>.</p>
<p>Secondly, <code>ucg</code> is just as fast as <code>ripgrep</code> and <code>git grep (ignore)</code> is just as
fast as <code>rg (ignore)</code>, even though I’ve said that
<code>ripgrep</code> is the fastest. It turns out that <code>ucg</code>, <code>git grep</code> and <code>rg</code> are
pretty evenly matched when searching for plain literals in large repositories.
We will see a stronger separation in later benchmarks. Still, what makes <code>ucg</code>
fast?</p>
<ul>
<li><code>ucg</code> reads the entire file into memory before searching it, which means it
avoids the memory map problem described below. On a code repository, this
approach works well, but it comes with a steep price in the single-file
benchmarks.</li>
<li>It has a fast explicitly SIMD based line counting algorithm. <code>ripgrep</code> has
something similar, but relies on the compiler for autovectorization.</li>
<li><code>ucg</code> uses PCRE2’s JIT, which is <em>insanely</em> fast. In my own very rough
benchmarks, PCRE2’s JIT is one of the few general purpose regex engines that
is competitive with Rust’s regex engine (on regexes that don’t expose PCRE’s
exponential behavior due to backtracking, since Rust’s regex engine doesn’t
suffer from that weakness).</li>
<li><code>ucg</code> parallelizes directory traversal, which is something that <code>ripgrep</code>
doesn’t do. <code>ucg</code> has it a bit easier here because it doesn’t support
<code>.gitignore</code> files. Parallelizing directory traversal while maintaining state
for <code>.gitignore</code> files in a way that scales isn’t a problem I’ve figured out
how to cleanly solve yet.</li>
</ul>
<p>What about <code>git grep</code>? A key performance advantage of <code>git grep</code> is that it
doesn’t need to walk the directory tree, which can save it quite a bit of time.
Its regex engine is also quite fast, and works similarly to GNU grep’s, RE2 and
Rust’s regex engine (i.e., it uses a DFA).</p>
<p>Both <code>sift</code> and <code>pt</code> perform almost as well as <code>ripgrep</code>. In fact, both <code>sift</code>
and <code>pt</code> do implement a parallel recursive directory traversal while
still respecting <code>.gitignore</code> files, which is likely one reason for their
speed. As we will see in future benchmarks, their speed here is misleading.
Namely, they are fast because they stay outside of Go’s regexp engine since the
pattern is a literal. (There will be more discussion on this point later.)</p>
<p>Finally, what’s going on with The Silver Searcher? Is it really that much
slower than everything else? The key here is that its use of memory maps is
making it <em>slower</em>, not faster (in direct contradiction to the claims in its
README).</p>
<p>OK, let’s pause and pop up a level to talk about what this actually means.
First, we need to consider how these search tools fundamentally work. Generally
speaking, a search tool like this has two ways of actually searching files on
disk:</p>
<ol>
<li>It can memory map the file and search the entire file all at once <em>as if</em> it
were a single contiguous region of bytes in memory. The operating system
does the work behind the scenes to make a file look like a contiguous
region of memory. This particular approach is <em>really</em> convenient when
comparing it to the alternative described next.</li>
<li>… or it can allocate an intermediate buffer, read a fixed size block of
bytes from the file into it, search the buffer and then repeat the process.
This particular approach is absolutely ghoulish to implement, because you
need to account for the fact that a buffer may end in the middle of the
line. You also need to account for the fact that a single line may exceed
the size of your buffer. Finally, if you’re going to support showing the
lines around a match (its “context”) as both <code>grep</code> and <code>ripgrep</code> do, then
you need to do additional bookkeeping to make sure any lines from a previous
buffer are printed even if a match occurs at the beginning of the next block
read from the file.</li>
</ol>
<p>Naively, it seems like (1) would be <em>obviously</em> faster. Surely, all of the
bookkeeping and copying in (2) would make it much slower! In fact, this is not
at all true. (1) may not require much bookkeeping from the perspective of the
programmer, but there is a lot of <a href="http://lkml.iu.edu/hypermail/linux/kernel/0004.0/0728.html">bookkeeping going on inside the
Linux kernel to maintain the memory
map</a>. (That link
goes to a mailing list post that is quite old, but it still appears relevant
today.)</p>
<p>When I first started writing <code>ripgrep</code>, I used the memory map approach. It took
me a long time to be convinced enough to start down the second path with an
intermediate buffer (because neither a CPU profile nor the output of <code>strace</code>
ever showed any convincing evidence that memory maps were to blame), but as
soon as I had a prototype of (2) working, it was clear that it was much faster
than the memory map approach.</p>
<p>With all that said, memory maps aren’t all bad. They just happen to be bad for
the particular use case of “rapidly open, scan and close memory maps for
thousands of small files.” For a different use case, like, say, “open this
large file and search it once,” memory maps turn out to be a boon. We’ll see
that in action in our single-file benchmarks later.</p>
<p>The key datapoint that supports this conclusion is the comparison between
<code>rg (ignore)</code> and <code>rg (ignore) (mmap)</code>. In particular, this controls for
everything <em>except</em> for the search strategy and fairly conclusively points
right at memory maps as the problem.</p>
<p>With all that said, the performance of memory maps is very dependent on your
environment, and the absolute difference between <code>rg (ignore)</code> and <code>ag (ignore) (mmap)</code> can be misleading. In particular, since these benchmarks were run on an
EC2 <code>c3.2xlarge</code>, we were probably inside a virtual machine, which could
feasibly impact memory map performance. To test this, I ran the same benchmark
on my machine under my desk (Intel i7-6900K 3.2 GHz, 16 CPUs, 64 GB memory,
SSD) and got these results:</p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg (ignore)          0.156 +/- 0.006 (lines: 16)
</span></span><span><span>rg (ignore) (mmap)   0.397 +/- 0.013 (lines: 16)
</span></span><span><span>ag (ignore) (mmap)   0.444 +/- 0.016 (lines: 16)
</span></span><span><span>pt (ignore)          0.159 +/- 0.008 (lines: 16)
</span></span><span><span>sift (ignore)        0.344 +/- 0.002 (lines: 16)
</span></span><span><span>git grep (ignore)    0.195 +/- 0.023 (lines: 16)
</span></span><span><span>rg (whitelist)       0.108 +/- 0.005 (lines: 16)*+
</span></span><span><span>ucg (whitelist)      0.165 +/- 0.005 (lines: 16)</span></span></code></pre></div>


<!-- raw HTML omitted -->
<p><code>rg (ignore)</code> still soundly beats <code>ag</code>, and our memory map conclusions above
are still supported by this data, but the difference between <code>rg (ignore)</code> and
<code>ag (ignore) (mmap)</code> has narrowed quite a bit!</p>
<h3 id="linux_literal_casei"><code>linux_literal_casei</code></h3>
<p><strong>Description</strong>: This benchmark is like
<a href="#linux-literal"><code>linux_literal</code></a>,
except it asks the search tool to perform a case insensitive search.</p>
<p><strong>Pattern</strong>: <code>PM_RESUME</code> (with the <code>-i</code> flag set)</p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg (ignore)          0.345 +/- 0.073 (lines: 370)
</span></span><span><span>rg (ignore) (mmap)   1.612 +/- 0.011 (lines: 370)
</span></span><span><span>ag (ignore) (mmap)   1.609 +/- 0.015 (lines: 370)
</span></span><span><span>pt (ignore)          17.204 +/- 0.126 (lines: 370)
</span></span><span><span>sift (ignore)        0.805 +/- 0.005 (lines: 370)
</span></span><span><span>git grep (ignore)    0.343 +/- 0.007 (lines: 370)
</span></span><span><span>rg (whitelist)       0.222 +/- 0.021 (lines: 370)+
</span></span><span><span>ucg (whitelist)      0.217 +/- 0.006 (lines: 370)*</span></span></code></pre></div>


<!-- raw HTML omitted -->
<ul>
<li><code>*</code> - Best mean time.</li>
<li><code>+</code> - Best sample time.</li>
</ul>
<p><strong>Analysis</strong>: The biggest change from the previous benchmark is that <code>pt</code> got
an order of magnitude slower than the next slowest tool.</p>
<p>So why did <code>pt</code> get so slow? In particular, both <code>sift</code> and <code>pt</code> use Go’s
<code>regexp</code> package for searching, so why did one perish while the other only got
slightly slower? It turns out that when <code>pt</code> sees the <code>-i</code> flag indicating case
insensitive search, it will force itself to use Go’s <code>regexp</code> engine with the
<code>i</code> flag set. So for example, given a CLI invocation of <code>pt -i foo</code>, it will
translate that to a Go regexp of <code>(?i)foo</code>, which will handle the case
insensitive search.</p>
<p>On the other hand, <code>sift</code> will notice the <code>-i</code> flag and take a different route.
<code>sift</code> will lowercase both the pattern and every block of bytes it searches.
This filter over all the bytes searched is likely the cause of <code>sift</code>’s
performance drop from the previous
<a href="#linux-literal"><code>linux_literal</code></a>
benchmark. (It’s worth pointing out that this optimization is actually
incorrect, because it only accounts for ASCII case insensitivity, and not full
Unicode case insensitivity, which <code>pt</code> gets by virture of Go’s regexp engine.)</p>
<p>But still, is Go’s regexp engine really that slow? Unfortunately, yes, it is.
While Go’s regexp engine takes worst case linear time on all searches (and is
therefore exponentially faster than even PCRE2 for some set of regexes and
corpora), its actual implementation hasn’t quite matured yet. Indeed, every
<em>fast</em> regex engine based on finite automata that I’m aware of implements
some kind of DFA engine. For example, GNU grep, Google’s RE2 and Rust’s regex
library all do this. Go’s does not (but there is work in progress to make this
happen, so perhaps <code>pt</code> will get faster on this benchmark without having to do
anything at all!).</p>
<p>There is one other thing worth noting here before moving on. Namely, that <code>rg</code>,
<code>ag</code>, <code>git grep</code> and <code>ucg</code> didn’t noticeably change much from the previous
benchmark. Shouldn’t a case insensitive search incur some kind of overhead? The
answer is complicated and actually requires more knowledge of the underlying
regex engines than I have. Thankfully, I can at least answer it for Rust’s
regex engine.</p>
<p>The key insight is that a case insensitive search for <code>PM_RESUME</code> is precisely
the same as a case sensitive search of the alternation of all possible case
agnostic versions of <code>PM_RESUME</code>. So for example, it might start like:
<code>PM_RESUME|pM_RESUME|Pm_RESUME|PM_rESUME|...</code> and so on. Of course, the
full alternation, even for a small literal like this, would be <em>quite</em> large.
The key is that we can extract a small prefix and enumerate all of <em>its</em>
combinations quite easily. In this case, Rust’s regex engine figures out this
alternation (which you can see by passing <code>--debug</code> to <code>rg</code> and examining
<code>stderr</code>):</p>



<div><pre tabindex="0"><code data-lang="text"><span><span>PM_RE
</span></span><span><span>PM_Re
</span></span><span><span>PM_rE
</span></span><span><span>PM_re
</span></span><span><span>Pm_RE
</span></span><span><span>Pm_Re
</span></span><span><span>Pm_rE
</span></span><span><span>Pm_re
</span></span><span><span>pM_RE
</span></span><span><span>pM_Re
</span></span><span><span>pM_rE
</span></span><span><span>pM_re
</span></span><span><span>pm_RE
</span></span><span><span>pm_Re
</span></span><span><span>pm_rE
</span></span><span><span>pm_re</span></span></code></pre></div>


<p>(Rest assured that Unicode support is baked into this process. For example, a
case insensitive search for <code>S</code> would yield the following literals: <code>S</code>, <code>s</code>
and <code>ſ</code>.)</p>
<p>Now that we have this alternation of literals, what do we do with them? The
classical answer is to compile them into a DFA
(perhaps <a href="https://github.com/BurntSushi/aho-corasick">Aho-Corasick</a>),
and use it as a way to quickly skip through the search text. A match of any of
the literals would then cause the regex engine to activate and try to verify
the match. This way, we aren’t actually running the entire search text through
the regex engine, which could be quite a bit slower.</p>
<p>But, Rust’s regex engine doesn’t actually use Aho-Corasick for this. When SIMD
acceleration is enabled (and you can be sure it is for these benchmarks, and
for the binaries I distribute), a special multiple pattern search algorithm
called Teddy is used. The algorithm is unpublished, but was invented by
Geoffrey Langdale as part of <a href="https://github.com/01org/hyperscan">Intel’s Hyperscan regex
library</a>. The algorithm works roughly by
using packed comparisons of 16 bytes at a time to find candidate locations
where a literal might match.
<a href="https://github.com/rust-lang-nursery/regex/blob/master/src/simd_accel/teddy128.rs">I adapted the algorithm from the Hyperscan project to
Rust</a>,
and included an extensive write up in the comments if you’re interested.</p>
<p>While Teddy doesn’t buy us much over other tools in this particular benchmark,
we will see much larger wins in later benchmarks.</p>
<h3 id="linux_word"><code>linux_word</code></h3>
<p><strong>Description</strong>: This benchmarks the <code>PM_RESUME</code> literal again, but adds the
<code>-w</code> flag to each tool. The <code>-w</code> flag has the following behavior: all matches
reported must be considered “words.” That is, a “word” is something that starts
and ends at a word boundary, where a word boundary is defined as a position in
the search text that is adjacent to both a word character and a non-word
character.</p>
<p><strong>Pattern</strong>: <code>PM_RESUME</code> (with the <code>-w</code> flag set)</p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg (ignore)         0.362 +/- 0.080 (lines: 6)
</span></span><span><span>ag (ignore)         1.603 +/- 0.009 (lines: 6)
</span></span><span><span>pt (ignore)         14.417 +/- 0.144 (lines: 6)
</span></span><span><span>sift (ignore)       7.840 +/- 0.123 (lines: 6)
</span></span><span><span>git grep (ignore)   0.341 +/- 0.005 (lines: 6)
</span></span><span><span>rg (whitelist)      0.220 +/- 0.026 (lines: 6)*+
</span></span><span><span>ucg (whitelist)     0.221 +/- 0.007 (lines: 6)</span></span></code></pre></div>


<ul>
<li><code>*</code> - Best mean time.</li>
<li><code>+</code> - Best sample time.</li>
</ul>
<p><strong>Analysis</strong>: Not much has changed between this benchmark and the previous
<a href="#linux-literal"><code>linux_literal</code></a>
or
<a href="#linux-literal-casei"><code>linux_literal_casei</code></a>
benchmarks. The most important thing to note is that most search tools handle
the <code>-w</code> flag just fine without any noticeable drop in performance. There are
two additional things I’d like to note.</p>
<p><code>rg</code> is searching with Unicode aware word boundaries where as the rest of the
tools are using ASCII only word boundaries. (<code>git grep</code> can be made to use
Unicode word boundaries by adjusting your system’s locale settings. In this
benchmark, we force it to use ASCII word boundaries.)</p>
<p><code>sift</code> and <code>pt</code> are the only tools that gets noticeably slower in this
benchmark compared to previous benchmarks. The reason is the same as the reason
why <code>pt</code> got noticeably slower in the
<a href="#linux-literal-casei"><code>linux_literal_casei</code></a>
benchmark: both <code>pt</code> and <code>sift</code> are now also bottlenecked on Go’s regexp
library. <code>pt</code> and <code>sift</code> could do a little better here by staying out of
Go’s regexp library and searching for the <code>PM_RESUME</code> literal, and then only
confirming whether the match corresponds to a word boundary after it found a
hit for <code>PM_RESUME</code>. This still might use Go’s regexp library, but in a much
more limited form.</p>
<h3 id="linux_unicode_word"><code>linux_unicode_word</code></h3>
<p><strong>Description</strong>: This benchmarks a simple query for all prefixed forms of the
“amp-hour” (Ah) unit of measurement. For example, it should show things like
<code>mAh</code> (for milliamp-hour) and <code>µAh</code> (for microamp-hour). It is particularly
interesting because the second form starts with <code>µ</code>, which is part of a Unicode
aware <code>\w</code> character class, but not an ASCII-only <code>\w</code> character class. We
again continue to control for the overhead of respecting <code>.gitignore</code> files.</p>
<p><strong>Pattern</strong>: <code>\wAh</code></p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg (ignore)                 0.355 +/- 0.073 (lines: 186)
</span></span><span><span>rg (ignore) (ASCII)         0.329 +/- 0.060 (lines: 174)
</span></span><span><span>ag (ignore) (ASCII)         1.774 +/- 0.011 (lines: 174)
</span></span><span><span>pt (ignore) (ASCII)         14.180 +/- 0.180 (lines: 174)
</span></span><span><span>sift (ignore) (ASCII)       11.087 +/- 0.108 (lines: 174)
</span></span><span><span>git grep (ignore)           13.045 +/- 0.008 (lines: 186)
</span></span><span><span>git grep (ignore) (ASCII)   2.991 +/- 0.004 (lines: 174)
</span></span><span><span>rg (whitelist)              0.235 +/- 0.031 (lines: 180)
</span></span><span><span>rg (whitelist) (ASCII)      0.225 +/- 0.023 (lines: 168)*+
</span></span><span><span>ucg (ASCII)                 0.229 +/- 0.007 (lines: 168)</span></span></code></pre></div>


<ul>
<li><code>*</code> - Best mean time.</li>
<li><code>+</code> - Best sample time.</li>
</ul>
<!-- raw HTML omitted -->
<p><strong>Analysis</strong>: In this benchmark, we’ve introduced a new variable: whether or
not to enable Unicode support in each tool. Searches that are Unicode aware
report slightly more matches that are missed by the other ASCII only searches.</p>
<p>Of all the tools here, the only ones that support Unicode toggling are <code>rg</code>
and <code>git grep</code>. <code>rg</code>’s Unicode support can be toggled by setting a flag in
the pattern itself (e.g., <code>\w</code> is Unicode aware while <code>(?-u)\w</code> is not), and
<code>git grep</code>’s Unicode suport can be toggled by setting the <code>LC_ALL</code> environment
variable (where <code>en_US.UTF-8</code> is one way to enable Unicode support and <code>C</code>
forces it to be ASCII). More generally, <code>git grep</code>’s Unicode support is
supposed to line up with your system’s locale settings—setting <code>LC_ALL</code> is a
bit of a hack.</p>
<p>It gets a little worse than that actually. Not only are <code>rg</code> and <code>git grep</code> the
only ones to support toggling Unicode, but they are the only ones to support
Unicode <em>at all</em>. <code>ag</code>, <code>pt</code>, <code>sift</code> and <code>ucg</code> will all force you to use the
ASCII only <code>\w</code> character class. (For <code>pt</code> and <code>sift</code> in particular, Go’s
<code>regexp</code> library doesn’t have the ability to treat <code>\w</code> as Unicode aware. For
<code>ag</code> and <code>ucg</code>, which use PCRE, <code>\w</code> could be made Unicode aware with a flag
sent to PCRE. Neither tool exposes that functionality though.)</p>
<p>The key result to note here is that while <code>git grep</code> suffers a major
performance hit for enabling Unicode support, <code>ripgrep</code> hums along just fine
with no noticeable loss in performance, even though both <code>rg (ignore)</code> and <code>git grep (ignore)</code> report the same set of results.</p>
<p>As in the previous benchmark, both <code>pt</code> and <code>sift</code> could do better here by
searching for the <code>Ah</code> literal, and only using Go’s regexp library to verify a
match.)</p>
<p>Looking at the benchmark results, I can think of two important questions to
ask:</p>
<ol>
<li>Why is <code>git grep (ignore) (ASCII)</code> so much slower than
<code>rg (ignore) (ASCII)</code>? And while the two aren’t directly comparable,
it’s also a lot slower than <code>ucg (ASCII)</code>.</li>
<li>How is <code>rg (ignore)</code> (which is Unicode aware) just as fast as
<code>rg (ignore) (ASCII)</code>?</li>
</ol>
<p>I actually don’t have a great answer for (1). In the case of <code>rg</code> at least,
it will extract the <code>Ah</code> literal suffix from the regex and use that to find
candidate matches before running the <code>\w</code> prefix. While GNU grep has
sophisticated literal extraction as well, it looks like <code>git grep</code> doesn’t go
to similar lengths to extract literals. (I’m arriving at this conclusion after
skimming the source of <code>git grep</code>, so I could be wrong.)</p>
<p>In the case of <code>ucg</code>, it’s likely that PCRE2 is doing a similar literal
optimization that <code>rg</code> is doing.</p>
<p>(2) is fortunately much easier to answer. The trick is not inside of <code>rg</code>, but
inside its regex library. Namely, the regex engine <em>builds UTF-8 decoding into
its finite state machine</em>. (This is a trick that is originally attributed to
Ken Thompson, but was more carefully
<a href="https://swtch.com/~rsc/regexp/regexp3.html">described by Russ Cox</a>.
To read more about how this is achieved in Rust’s regex engine, please see the
<a href="https://docs.rs/utf8-ranges"><code>utf8-ranges</code></a>
library.) The reason why this is fast is because there is no extra decoding
step required. The regex can be matched directly against UTF-8 encoded byte
strings one byte at a time. Invalid UTF-8 doesn’t pose any problems: the finite
automaton simply won’t match it because it doesn’t recognize it.</p>
<p>In contrast, <code>git grep</code> (and GNU grep) have a completely separate path in their
core matching code for handling Unicode aware features like this. To be fair,
<code>git grep</code> can handle text encodings other than UTF-8, where as <code>rg</code> is limited
to UTF-8 (or otherwise “ASCII compatible” text encodings) at the moment.</p>
<h3 id="linux_re_literal_suffix"><code>linux_re_literal_suffix</code></h3>
<p><strong>Description</strong>: This benchmarks a simple regex pattern that ends with a
literal. We continue to control for the overhead of respecting <code>.gitignore</code>
files.</p>
<p><strong>Pattern</strong>: <code>[A-Z]+_RESUME</code></p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg (ignore)         0.318 +/- 0.034 (lines: 1652)
</span></span><span><span>ag (ignore)         1.899 +/- 0.008 (lines: 1652)
</span></span><span><span>pt (ignore)         13.713 +/- 0.241 (lines: 1652)
</span></span><span><span>sift (ignore)       10.172 +/- 0.186 (lines: 1652)
</span></span><span><span>git grep (ignore)   1.108 +/- 0.004 (lines: 1652)
</span></span><span><span>rg (whitelist)      0.221 +/- 0.022 (lines: 1630)*+
</span></span><span><span>ucg (whitelist)     0.301 +/- 0.001 (lines: 1630)</span></span></code></pre></div>


<ul>
<li><code>*</code> - Best mean time.</li>
<li><code>+</code> - Best sample time.</li>
</ul>
<p><strong>Analysis</strong>: This benchmark doesn’t reveal anything particularly new that we
haven’t already learned from previous benchmarks. In particular, both <code>rg</code> and
<code>ucg</code> continue to be competitive, <code>pt</code> and <code>sift</code> are getting bottlenecked by
Go’s regexp library and <code>git grep</code> has a slow down similar to the one observed
in
<a href="#linux-unicode-word"><code>linux_unicode_word</code></a>.
(My hypothesis for that slow down continues to be that <code>git grep</code> is missing
the literal optimization.) Finally, <code>ag</code> continues to be held back by its use
of memory maps.</p>
<p><code>rg</code>, and almost assuredly <code>ucg</code> (by virtue of PCRE2), are picking on the
<code>_RESUME</code> literal suffix and searching for that instead of running the regex
over the entire search text. This explains why both tools are able to maintain
their speed even as the pattern gets slightly more complex. <code>rg</code> does seem to
slightly edge out <code>ucg</code> here, which might be attributable to differences in how
each underlying regex library does literal search.</p>
<h3 id="linux_alternates"><code>linux_alternates</code></h3>
<p><strong>Description</strong>: This benchmarks an alternation of four literals. The literals
were specifically chosen to start with four distinct bytes to make it harder to
optimize.</p>
<p><strong>Pattern</strong>: <code>ERR_SYS|PME_TURN_OFF|LINK_REQ_RST|CFG_BME_EVT</code></p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg (ignore)         0.351 +/- 0.074 (lines: 68)
</span></span><span><span>ag (ignore)         1.747 +/- 0.005 (lines: 68)
</span></span><span><span>git grep (ignore)   0.501 +/- 0.003 (lines: 68)
</span></span><span><span>rg (whitelist)      0.216 +/- 0.031 (lines: 68)+
</span></span><span><span>ucg (whitelist)     0.214 +/- 0.008 (lines: 68)*</span></span></code></pre></div>


<ul>
<li><code>*</code> - Best mean time.</li>
<li><code>+</code> - Best sample time.</li>
<li>We drop <code>pt</code> and <code>sift</code> from this benchmark and the next one for expediency.
In this benchmark and in a few previous benchmarks, they have been hovering
around an order of magnitude slower than the next slowest tool. Neither get
any better as the complexity of our patterns increase.</li>
</ul>
<!-- raw HTML omitted -->
<p><strong>Analysis</strong>: Yet again, both <code>rg</code> and <code>ucg</code> maintain high speed even as the
pattern grows beyond a simple literal. In this case, there isn’t any <em>one</em>
particular literal that we can search to find match candidates quickly, but a
good regular expression engine can still find ways to speed this up.</p>
<p>For <code>rg</code> in particular, it sees the four literals and diverts to the Teddy
multiple pattern SIMD algorithm (as described in the
<a href="#linux-literal-casei"><code>linux_literal_casei</code></a>
benchmark). In fact, for this particular pattern, Rust’s core regex engine
is never used at all. Namely, it notices that a literal match of any of the
alternates corresponds to an overall match of the pattern, so it can completely
skip the verification step. This makes searching alternates of literals <em>very</em>
fast.</p>
<h3 id="linux_alternates_casei"><code>linux_alternates_casei</code></h3>
<p><strong>Description</strong>: This benchmark is precisely the same as the
<a href="#linux-alternates"><code>linux_alternates</code></a>
benchmark, except we make the search case insensitive by adding the <code>-i</code> flag.
Note that <code>git grep</code> is run under ASCII mode, in order to give it every chance
to be fast.</p>
<p><strong>Pattern</strong>: <code>ERR_SYS|PME_TURN_OFF|LINK_REQ_RST|CFG_BME_EVT</code> (with the <code>-i</code>
flag set)</p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg (ignore)         0.391 +/- 0.078 (lines: 160)
</span></span><span><span>ag (ignore)         1.968 +/- 0.009 (lines: 160)
</span></span><span><span>git grep (ignore)   2.018 +/- 0.006 (lines: 160)
</span></span><span><span>rg (whitelist)      0.222 +/- 0.001 (lines: 160)*+
</span></span><span><span>ucg (whitelist)     0.522 +/- 0.002 (lines: 160)</span></span></code></pre></div>


<ul>
<li><code>*</code> - Best mean time.</li>
<li><code>+</code> - Best sample time.</li>
</ul>
<!-- raw HTML omitted -->
<p><strong>Analysis</strong>: The case insensitive flag causes quite a bit of separation,
relative to the previous
<a href="#linux-alternates"><code>linux_alterates</code></a>
benchmark. For one, <code>git grep</code> gets over 4 times slower. Even <code>ucg</code> gets twice
as slow. Yet, <code>rg</code> continues to maintain its speed!</p>
<p>The secret continues to be the Teddy algorithm, just as in the
<a href="#linux-alternates"><code>linux_alternates</code></a>
benchmark. The trick lies in how we transform an alternation of <em>case
insensitive</em> literals into a larger alternation that the Teddy algorithm
can actually use. In fact, it works exactly how it was described in the
<a href="#linux-literal-casei"><code>linux_literal_casei</code></a>
benchmark: we enumerate all possible alternations of each literal that are
required for case insensitive match. Since that can be quite a large number,
we limit ourselves to a small number of prefixes from that set that we can
enumerate. In this case, we use the following prefixes (which can be seen by
running <code>rg</code> with the <code>--debug</code> flag):</p>



<div><pre tabindex="0"><code data-lang="text"><span><span>CFG_
</span></span><span><span>CFg_
</span></span><span><span>CfG_
</span></span><span><span>Cfg_
</span></span><span><span>ERR_
</span></span><span><span>ERr_
</span></span><span><span>ErR_
</span></span><span><span>Err_
</span></span><span><span>LIN
</span></span><span><span>LIn
</span></span><span><span>LiN
</span></span><span><span>Lin
</span></span><span><span>PME_
</span></span><span><span>PMe_
</span></span><span><span>PmE_
</span></span><span><span>Pme_
</span></span><span><span>cFG_
</span></span><span><span>cFg_
</span></span><span><span>cfG_
</span></span><span><span>cfg_
</span></span><span><span>eRR_
</span></span><span><span>eRr_
</span></span><span><span>erR_
</span></span><span><span>err_
</span></span><span><span>lIN
</span></span><span><span>lIn
</span></span><span><span>liN
</span></span><span><span>lin
</span></span><span><span>pME_
</span></span><span><span>pMe_
</span></span><span><span>pmE_
</span></span><span><span>pme_</span></span></code></pre></div>


<p>We feed these literals to the Teddy algorithm, which will quickly identify
<em>candidate</em> matches in the search text. When a candidate match is found, we
need to verify it since a match of a prefix doesn’t necessarily mean the entire
pattern matches. It is only at that point that we actually invoke the full
regex engine.</p>
<h3 id="linux_unicode_greek"><code>linux_unicode_greek</code></h3>
<p><strong>Description</strong>: This benchmarks usage of a particular Unicode feature that
permits one to match a certain class of codepoints defined in Unicode. Both
Rust’s regex engine and Go’s regex engine support this natively, but none of
the other tools do.</p>
<p><strong>Pattern</strong>: <code>\p{Greek}</code> (matches any Greek symbol)</p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg     0.414 +/- 0.021 (lines: 23)*+
</span></span><span><span>pt     12.745 +/- 0.166 (lines: 23)
</span></span><span><span>sift   7.767 +/- 0.264 (lines: 23)</span></span></code></pre></div>


<ul>
<li><code>*</code> - Best mean time.</li>
<li><code>+</code> - Best sample time.</li>
</ul>
<p><strong>Analysis</strong>: This one is pretty simple. <code>rg</code> compiles <code>\p{Greek}</code> into a
deterministic finite state machine while Go (used in <code>pt</code> and <code>sift</code>) will also
use a finite state machine, but it is a <em>nondeterministic</em> simulation. The core
difference between the two approaches is that the former is only ever in one
state at any point in time, while the latter must constantly keep track of all
the different states it is in.</p>
<h3 id="linux_unicode_greek_casei"><code>linux_unicode_greek_casei</code></h3>
<p><strong>Description</strong>: This benchmark is just like the
<a href="#linux-unicode-greek"><code>linux_unicode_greek</code></a>
benchmark, except it makes the search case insensitive. This particular query
is a bit idiosyncratic, but it does demonstrate just how well supported Unicode
is in <code>rg</code>.</p>
<p><strong>Pattern</strong>: <code>\p{Greek}</code> (with the <code>-i</code> flag set, matches any Greek symbol)</p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg     0.425 +/- 0.027 (lines: 103)
</span></span><span><span>pt     12.612 +/- 0.217 (lines: 23)
</span></span><span><span>sift   0.002 +/- 0.000 (lines: 0)*+</span></span></code></pre></div>


<ul>
<li><code>*</code> - Best mean time.</li>
<li><code>+</code> - Best sample time.</li>
</ul>
<!-- raw HTML omitted -->
<p><strong>Analysis</strong>: <code>sift</code> doesn’t actually beat <code>rg</code> here: it just gets so confused
by the search request that it gives up and reports no matches. <code>pt</code> seems to
execute the search, but doesn’t handle Unicode case insensitivity correctly.
Meanwhile, <code>rg</code> handles the request just fine, <em>and it’s still fast</em>.</p>
<p>In this particular case, the entire <code>Greek</code> category, along with all of its
case-insensitive variants, are compiled into a single fast deterministic finite
state machine.</p>
<p>One interesting thing to note about this search is that if you run it, you’ll
see a lot more results containing the character <code>µ</code>, which looks essentially
identical to the character <code>μ</code> that also shows up in a case sensitive search.
As you might have guessed, even though these two characters look the same, they
are in fact distinct Unicode codepoints:</p>
<ul>
<li><code>µ</code> is <code>MICRO SIGN</code> with codepoint <code>U+000000B5</code>.</li>
<li><code>μ</code> is <code>GREEK SMALL LETTER MU</code> with codepoint <code>U+000003BC</code>.</li>
</ul>
<p>The latter codepoint is considered part of the <code>\p{Greek}</code> group while the
former codepoint is not (the former codepoint appears to be the correct sigil
to use in the case of the Linux kernel). However, the
<a href="http://www.unicode.org/Public/UNIDATA/CaseFolding.txt">Unicode simple case folding
tables</a>
map <code>MICRO SIGN</code> to <code>GREEK SMALL LETTER MU</code>, which causes <code>rg</code> to pick up on
lines containing <code>MICRO SIGN</code> even though it strictly isn’t part of the <code>Greek</code>
group.</p>
<h3 id="linux_no_literal"><code>linux_no_literal</code></h3>
<p><strong>Description</strong>: This is the last benchmark on the Linux kernel source code and
is a bit idiosyncratic like
<a href="#linux-unicode-greek-casei"><code>linux_unicode_greek_casei</code></a>.
In particular, it looks for lines containing 5 consecutive repetitions of
5 word characters, each separated by one or more space characters. The key
distinction of this pattern from every other pattern in this benchmark is that
it does not contain any literals. Given the presence of <code>\w</code> and <code>\s</code>, which
have valid Unicode and ASCII interpretations, we attempt to control for the
presence of Unicode support.</p>
<p><strong>Pattern</strong>: <code>\w{5}\s+\w{5}\s+\w{5}\s+\w{5}\s+\w{5}</code></p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg (ignore)                 0.577 +/- 0.003 (lines: 490)
</span></span><span><span>rg (ignore) (ASCII)         0.416 +/- 0.025 (lines: 490)
</span></span><span><span>ag (ignore) (ASCII)         2.339 +/- 0.010 (lines: 766)
</span></span><span><span>pt (ignore) (ASCII)         22.066 +/- 0.057 (lines: 490)
</span></span><span><span>sift (ignore) (ASCII)       25.563 +/- 0.108 (lines: 490)
</span></span><span><span>git grep (ignore)           26.382 +/- 0.044 (lines: 490)
</span></span><span><span>git grep (ignore) (ASCII)   4.153 +/- 0.010 (lines: 490)
</span></span><span><span>rg (whitelist)              0.503 +/- 0.011 (lines: 419)
</span></span><span><span>rg (whitelist) (ASCII)      0.343 +/- 0.038 (lines: 419)*+
</span></span><span><span>ucg (whitelist) (ASCII)     1.130 +/- 0.003 (lines: 416)</span></span></code></pre></div>


<ul>
<li><code>*</code> - Best mean time.</li>
<li><code>+</code> - Best sample time.</li>
<li><code>ag</code> reports many more matches than other tools because it does multiline
search where the <code>\s</code> can match a <code>\n</code>.</li>
</ul>
<!-- raw HTML omitted -->
<p><strong>Analysis</strong>: Since this particular pattern doesn’t have any literals in it,
it’s entirely up to the underlying regex engine to answer this query. It can’t
be smart and skip through the input—it has to pass it completely through the
regex engine. Since non-literal patterns are pretty rare in my experience, this
benchmark exists primarily as an engineered way to test how well the underlying
regex engines perform.</p>
<p><code>rg</code>, regardless of whether it respects <code>.gitignore</code> files or whether it
handles Unicode correctly, does quite well here compared to other tools. <code>git grep</code> in particular pays a 5x penalty for Unicode support. <code>rg</code> on the other
hand pays about a 0.3x penalty for Unicode support. Interestingly, even though
<code>ucg</code> doesn’t enable Unicode support, not even PCRE2’s JIT can compete with
<code>rg</code>!</p>
<p>What makes <code>rg</code> so fast here? And what actually causes the 0.3x penalty?</p>
<p><code>rg</code> continues to be fast on this benchmark primarily for the same reason why
it’s fast with other Unicode-centric benchmarks: it compiles the UTF-8 decoding
right into its deterministic finite state machine. This means there is no extra
step to decode the search text into Unicode codepoints first. We can match
directly on the raw bytes.</p>
<p>To a first approximation, the performance penalty comes from compiling the DFA
to match the pattern. In particular, the DFA to match the Unicode variant is
much much larger than the DFA to match the ASCII variant. To give you a rough
idea of the size difference:</p>
<ul>
<li>The ASCII DFA has about <strong>250</strong> distinct NFA states.</li>
<li>The Unicode DFA has about <strong>77,000</strong> distinct NFA states.</li>
</ul>
<p>(These numbers are produced directly from the compiler in Rust’s regex library,
and don’t necessarily reflect a minimal automaton.)</p>
<p>A DFA produced from these patterns doesn’t necessarily have the same number of
states, since each DFA state typically corresponds to multiple NFA states.
(Check out the
<a href="https://en.wikipedia.org/wiki/Powerset_construction">Powerset construction</a>
Wikipedia article. Although it doesn’t correspond to the same implementation
strategy used in Rust’s regex engine, it should give good intuition.)</p>
<p>However, the first approximation is a bit misleading. While Rust’s regex engine
does have a preprocessing compilation phase, it does not actually include
converting an NFA into a DFA. Indeed, that would be far too slow and could
take exponential time! Instead, Rust’s regex engine builds the DFA <em>on the fly</em>
or “lazily,” as it searches the text. In the case of the ASCII pattern, this
search barely spends any time constructing the DFA states since there are so
few of them. However, in the Unicode case, since there are so many NFA states,
it winds up spending a lot of time compiling new DFA states. (I’ve confirmed
this by inspecting a profile generated by
<a href="https://perf.wiki.kernel.org/index.php/Main_Page"><code>perf</code></a>.)
Digging a bit deeper, the actual story here might be subtler. For example, the
Unicode pattern might wind up with the same number of DFA states as the ASCII
pattern, primarily because the input its searching is the same and is primarily
ASCII. The slow down then must come from the fact that each individual DFA
state takes longer to build. This is likely correct since a single Unicode <code>\w</code>
is over two orders of magnitude larger than a single ASCII <code>\w</code>. Therefore,
each DFA state probably has a lot more NFA states in it for the Unicode pattern
as opposed to the ASCII pattern. It’s not clear whether we can do any better
here (other than trying to minimize the Unicode <code>\w</code>, which would be totally
feasible), since we don’t actually know the composition of the search text
ahead of time.</p>
<p>One idea for improvement is to have multiple types of DFAs. For example,
you might imagine trying to match with an ASCII only DFA. If the DFA sees a
non-ASCII byte, then it could cause a transition into a Unicode-aware DFA.
However, the penalty here is so small that it’s hard to justify this kind of
implementation complexity!</p>
<h2 id="single-file-benchmarks">Single file benchmarks</h2>
<p>In the second half of our benchmarks, we will shift gears and look more closely
at the performance of search tools on a single large file. Each benchmark will
be run on two samples of the
<a href="http://opus.lingfil.uu.se/OpenSubtitles2016.php">OpenSubtitles2016</a> dataset.
One sample will be English and therefore predominantly ASCII, and another
sample will be in Russian and therefore predominantly Cyrillic. The patterns
for the Russian sample were translated from English using Google Translate.
(Sadly, I can’t read Russian, but I have tried each search by hand and
confirmed that a sample of the results I was looking at were relevant by piping
them back through Google Translate.) The English sample is around 1GB and
the Russian sample is around 1.6GB, so the benchmark timings aren’t directly
comparable.</p>
<p>In this benchmark, the performance of the underlying regex engine and various
literal optimizations matter a lot more. The two key variables we’ll need to
control for are line counting and Unicode support. Normally, we’d just not
request line counting from any of the tools, but neither of The Silver Searcher
or Universal Code Grep support disabling line numbers. Additionally, Unicode
support is tricky to control for in some examples because <code>ripgrep</code> does not
support ASCII only case insensitive semantics when searching with a non-ASCII
string. It’s Unicode all the way and there’s no way to turn it off. As we’ll
see, at least for <code>ripgrep</code>, it’s still faster than its ASCII alternatives even
when providing case insensitive Unicode support.</p>
<p>As with the Linux benchmark, you can see precisely which command was run and
its recorded time in
<a href="https://github.com/BurntSushi/ripgrep/blob/master/benchsuite/runs/2016-09-20-ubuntu1604-ec2/raw.csv">the raw data</a>.</p>
<p><code>ripgrep</code> utterly dominates this round, both in performance <em>and</em> correctness.</p>
<h3 id="subtitles_literal"><code>subtitles_literal</code></h3>
<p><strong>Description</strong>: This benchmarks the simplest case for any search tool: find
all occurrences of a literal string. Tools annotated with <code>(lines)</code> were passed
the <code>-n</code> flag (or equivalent) so that the output reports line numbers.</p>
<p><strong>English pattern</strong>: <code>Sherlock Holmes</code></p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg             0.268 +/- 0.000 (lines: 629)*+
</span></span><span><span>rg (no mmap)   0.336 +/- 0.001 (lines: 629)
</span></span><span><span>pt             3.433 +/- 0.002 (lines: 629)
</span></span><span><span>sift           0.326 +/- 0.002 (lines: 629)
</span></span><span><span>grep           0.516 +/- 0.001 (lines: 629)
</span></span><span><span>rg (lines)     0.595 +/- 0.001 (lines: 629)
</span></span><span><span>ag (lines)     2.730 +/- 0.003 (lines: 629)
</span></span><span><span>ucg (lines)    0.745 +/- 0.001 (lines: 629)
</span></span><span><span>pt (lines)     3.434 +/- 0.005 (lines: 629)
</span></span><span><span>sift (lines)   0.756 +/- 0.002 (lines: 629)
</span></span><span><span>grep (lines)   0.969 +/- 0.001 (lines: 629)</span></span></code></pre></div>


<!-- raw HTML omitted -->
<p><strong>Russian pattern</strong>: <code>Шерлок Холмс</code></p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg             0.325 +/- 0.001 (lines: 583)*+
</span></span><span><span>rg (no mmap)   0.452 +/- 0.002 (lines: 583)
</span></span><span><span>pt             12.917 +/- 0.009 (lines: 583)
</span></span><span><span>sift           16.418 +/- 0.008 (lines: 583)
</span></span><span><span>grep           0.780 +/- 0.001 (lines: 583)
</span></span><span><span>rg (lines)     0.926 +/- 0.001 (lines: 583)
</span></span><span><span>ag (lines)     4.481 +/- 0.003 (lines: 583)
</span></span><span><span>ucg (lines)    1.889 +/- 0.004 (lines: 583)
</span></span><span><span>pt (lines)     12.935 +/- 0.011 (lines: 583)
</span></span><span><span>sift (lines)   17.177 +/- 0.010 (lines: 583)
</span></span><span><span>grep (lines)   1.300 +/- 0.003 (lines: 583)</span></span></code></pre></div>


<!-- raw HTML omitted -->
<ul>
<li><code>*</code> - Best mean time.</li>
<li><code>+</code> - Best sample time.</li>
<li>This is the only benchmark that contains <code>pt</code> and <code>sift</code>, since they become
too slow in all future benchmarks.</li>
</ul>
<p><strong>Analysis</strong>: Whether it’s part of the underlying regex engine or part of the
search tool itself, every search tool in this benchmark does some kind of
literal optimization. <code>ag</code> will inspect the pattern, and if it doesn’t
contain any special regex characters, then it will use a Boyer-Moore variant
to perform the search instead of PCRE. GNU grep does something similar,
although it has clearly been the
<a href="http://ridiculousfish.com/blog/posts/old-age-and-treachery.html">subject of much
optimization</a>.</p>
<p>If that’s true, how does <code>rg</code> beat GNU grep by almost a factor of 2? Well,
first and foremost, we note that both <code>sift</code> and <code>ucg</code> beat GNU grep as well.
I won’t be able to go into detail on <code>ucg</code>’s speed since PCRE2’s JIT isn’t
something I understand very well, but I can at least tell you that the reasons
why <code>rg</code> and <code>sift</code> are faster than GNU grep are actually distinct:</p>
<ul>
<li><code>sift</code> uses Go’s regexp library, which will do at least one small literal
optimization: if every match of a regex starts with the same byte, the regex
engine will scan for that byte before starting a match. If you follow the
code that does the scan for the byte all the way back to its source for
<code>x86_64</code> systems, then you’ll find that it is using
<a href="https://github.com/golang/go/blob/b851ded09a300033849b60ab47a468087ce557a1/src/runtime/asm_amd64.s#L1394-L1413">AVX2 instructions and <code>ymm</code>
registers</a>,
which permit scanning 32 bytes in each iteration. In contrast, GNU grep uses
<code>libc</code>’s <code>memchr</code>, which
<a href="https://sourceware.org/git/?p=glibc.git;a=blob;f=sysdeps/x86_64/memrchr.S;h=840de30cd71ba96b3ae43540e6ac255c28906cc5;hb=HEAD">doesn’t use AVX2</a>.
However, that C code will be autovectorized to use <code>xmm</code> registers and SIMD
instructions, which are half the size of <code>ymm</code> registers. In other words, by
virture of being written in Go, <code>sift</code> is making more efficient use of the
CPU.</li>
<li><code>rg</code> also uses <code>memchr</code> from <code>libc</code>. The <code>rg</code> binary that was used in this
benchmark was statically linked with
<a href="http://www.musl-libc.org/"><code>musl</code></a>,
which provides its own
<a href="https://github.com/ifduyue/musl/blob/master/src/string/memchr.c">implementation of
<code>memchr</code></a>.
Despite it being quite a bit terser than GNU’s libc implementation used in
GNU grep, it appears to be doing roughly the same work. If that’s the case,
how is <code>rg</code> faster? The answer lies not in <code>memchr</code> nor in the variant of
Boyer-Moore nor in the number characters Boyer-Moore can skip. The answer
instead lies in <em>which byte is given to <code>memchr</code>.</em> <code>rg</code> will actually try to
guess the “rarest” byte in a literal, and use <code>memchr</code> on that. (A standard
Boyer-Moore implementation will use <code>memchr</code> always on the last byte.) In
this particular case, running <code>memchr</code> on either <code>S</code> or <code>H</code> is probably
quite a bit better than running it on <code>s</code> because <code>S</code> and <code>H</code> are far less
common than <code>s</code>. That is, <code>rg</code> tries harder than GNU grep to spend more time
skipping bytes in a fast SIMD optimized loop. <code>rg</code> can get this wrong, but
it seems strictly better to at least guess and probably get it right in the
common case than to submit to an artifact of common Boyer-Moore
implementations.</li>
</ul>
<p>Now that the secrets of literal search have been revealed, we can better
analyze the Russian benchmark. The answer once again lies in <em>which byte is
used</em> for quick scanning. Both <code>sift</code> and <code>pt</code> use the same AVX2 routine in
Go’s runtime, so why did they get so much slower than every other tool in the
Russian benchmark? The answer becomes more clear when we look at the actual
UTF-8 bytes of the pattern <code>Шерлок Холмс</code>:</p>



<div><pre tabindex="0"><code data-lang="text"><span><span>\xd0\xa8\xd0\xb5\xd1\x80\xd0\xbb\xd0\xbe\xd0\xba \xd0\xa5\xd0\xbe\xd0\xbb\xd0\xbc\xd1\x81</span></span></code></pre></div>


<p>There are two key observations to take away from this:</p>
<ol>
<li>Every character in the pattern <code>Шерлок Холмс</code> is encoded with two UTF-8 code
units, which corresponds to two bytes.</li>
<li>Every character starts with either the byte <code>\xD0</code> or <code>\xD1</code>.</li>
</ol>
<p>If we looked at the UTF-8 bytes of the Russian subtitles we’re searching, we’d
end up seeing exactly the same pattern. This pattern occurs because the
contents of the file are mostly Cyrllic, which are all mostly part of a couple
small ranges in Unicode. This means that the <code>\xD0</code> and <code>\xD1</code> bytes occur <em>a
lot</em>.</p>
<p>If you recall from above, Go’s regex engine will scan for occurrences of the
first byte. But if that first byte happens as frequently as it does here, the
overall search will wind up going slower because there is overhead
associated with doing that scan. This is <em>precisely</em> the trade off one is
exposed to whenever <code>memchr</code> is used.</p>
<p>As you might have guessed, <code>rg</code> works around this issue by trying to guess the
rarest byte. <code>rg</code> specifically draws from a pre-computed frequency table of all
256 bytes. Bytes like <code>\xD0</code> and <code>\xD1</code> are considered to be among the most
frequent while bytes like <code>\xA8</code> and <code>\x81</code> are considered more rare.
Therefore, <code>rg</code> will prefer bytes other than <code>\xD0</code> and <code>\xD1</code> for use with
<code>memchr</code>.</p>
<p>GNU grep continues to do well on this benchmark mostly because of blind luck:
Boyer-Moore uses the last byte, which will correspond to <code>\x81</code>, which is much
rarer than <code>\xD0</code> or <code>\xD1</code>.</p>
<p>Switching gears, we should briefly discuss memory maps. In this benchmark, <code>rg</code>
beats out <code>rg (no mmap)</code> by about 25%. The only difference between the two is
that the former memory maps the file into memory while the latter incrementally
reads bytes from the file into an intermediate buffer, and searches it. In this
case, the overhead of the memory map is very small because we only need to
create one of them. This is the <em>opposite</em> result from our Linux benchmark
above, where memory maps proved to be worse than searching with an intermediate
buffer since we needed to create a new memory map for every file we searched,
which ends up incurring quite a bit of overhead. <code>rg</code> takes an empirical
approach here and enables memory map searching when it knows it only needs to
search a few files, and otherwise searches using an intermediate buffer.</p>
<p>One last note: I’ve neglected to talk about <code>(lines)</code> because there’s really
not much to say here: counting lines takes work, and if you don’t need to
report line numbers, you can avoid doing that work. <code>ucg</code> has a rather cool
SIMD algorithm to count lines and <code>rg</code> also has a packed counting algorithm
that works similarly to the <code>memchr</code> implementations we talked about.</p>
<p>If it were up to me, I’d probably remove benchmarks with line numbers
altogether, since most tools tend to reliably pay just a little bit extra for
them. However, neither <code>ag</code> nor <code>ucg</code> allow turning them off, so we need to
turn them on in other tools in order to make a fair comparison.</p>
<h3 id="subtitles_literal_casei"><code>subtitles_literal_casei</code></h3>
<p><strong>Description</strong>: This benchmark is just like
<a href="#subtitles-literal"><code>subtitles_literal</code></a>, except it does case insensitive
search. Tools annotated with <code>(lines)</code> show line numbers in their output, and
tools annotated with <code>(ASCII)</code> are doing an ASCII-only search. Correspondingly,
tools <em>not</em> labeled with <code>(ASCII)</code> are doing a proper Unicode search.</p>
<p><strong>English pattern</strong>: <code>Sherlock Holmes</code> (with the <code>-i</code> flag set)</p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg                    0.366 +/- 0.001 (lines: 642)*+
</span></span><span><span>grep                  4.084 +/- 0.005 (lines: 642)
</span></span><span><span>grep (ASCII)          0.614 +/- 0.001 (lines: 642)
</span></span><span><span>rg (lines)            0.696 +/- 0.002 (lines: 642)
</span></span><span><span>ag (lines) (ASCII)    2.775 +/- 0.004 (lines: 642)
</span></span><span><span>ucg (lines) (ASCII)   0.841 +/- 0.002 (lines: 642)</span></span></code></pre></div>


<!-- raw HTML omitted -->
<p><strong>Russian pattern</strong>: <code>Шерлок Холмс</code></p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg                    1.131 +/- 0.001 (lines: 604)
</span></span><span><span>grep                  8.187 +/- 0.006 (lines: 604)
</span></span><span><span>grep (ASCII)          0.785 +/- 0.001 (lines: 583)
</span></span><span><span>rg (lines)            1.733 +/- 0.002 (lines: 604)
</span></span><span><span>ag (lines) (ASCII)    0.729 +/- 0.001 (lines: 0)*+
</span></span><span><span>ucg (lines) (ASCII)   1.896 +/- 0.005 (lines: 583)</span></span></code></pre></div>


<!-- raw HTML omitted -->
<ul>
<li><code>*</code> - Best mean time.</li>
<li><code>+</code> - Best sample time.</li>
<li>There is no <code>rg (ASCII)</code> because <code>rg</code> can’t do ASCII-only case insensitive
search.</li>
</ul>
<p><strong>Analysis</strong>: This is a fun benchmark, because we start to see just how awesome
<code>rg</code>’s support for Unicode is. Namely, that it not only gets it correct, but
it’s also <em>fast</em>. It’s fast enough that it beats the competition even when the
competition is using ASCII-only rules.</p>
<p>Right off the bat, GNU grep pays dearly for doing a case insensitive search
with Unicode support. The problem it faces is that it can no longer do a
straight-forward Boyer-Moore search, so it either needs to fall back to some
alternative literal search or its full regex engine. Even though GNU grep is
much faster at ASCII-only case sensitive search than its Unicode aware variant,
<code>rg</code>’s Unicode case insensitive search still handedly beats GNU grep’s
ASCII-only case insensitive search.</p>
<p>The reason why <code>rg</code> is so fast on this benchmark is the same reason why it’s
fast in the
<a href="#linux-literal-casei"><code>linux_literal_casei</code></a>
benchmark: it turns the pattern <code>Sherlock Holmes</code> into an alternation of all
possible literals according to Unicode’s simple case folding rules. It then
takes a small prefix from each alternate so that our set of literals looks like
this:</p>



<div><pre tabindex="0"><code data-lang="text"><span><span>SHER
</span></span><span><span>SHEr
</span></span><span><span>SHeR
</span></span><span><span>SHer
</span></span><span><span>ShER
</span></span><span><span>ShEr
</span></span><span><span>SheR
</span></span><span><span>Sher
</span></span><span><span>sHER
</span></span><span><span>sHEr
</span></span><span><span>sHeR
</span></span><span><span>sHer
</span></span><span><span>shER
</span></span><span><span>shEr
</span></span><span><span>sheR
</span></span><span><span>sher
</span></span><span><span>ſHER
</span></span><span><span>ſHEr
</span></span><span><span>ſHeR
</span></span><span><span>ſHer
</span></span><span><span>ſhER
</span></span><span><span>ſhEr
</span></span><span><span>ſheR
</span></span><span><span>ſher</span></span></code></pre></div>


<p>(Notice that we get Unicode right by including <code>ſ</code> as a case variant of <code>S</code>.)</p>
<p>It then feeds these literals to the Teddy SIMD multiple pattern algorithm. The
algorithm is unpublished, but was invented by Geoffrey Langdale as part of
<a href="https://github.com/01org/hyperscan">Intel’s Hyperscan regex library</a>.
The algorithm works roughly by using packed comparisons of 16 bytes at a time
to find candidate locations where a literal might match.
<a href="https://github.com/rust-lang-nursery/regex/blob/master/src/simd_accel/teddy128.rs">I adapted the algorithm from the Hyperscan project to
Rust</a>,
and included an extensive write up in the comments if you’re interested.</p>
<p>While essentially the same analysis applies to the Russian benchmark, there are
a few interesting things to note. Namely, while the results show <code>grep (ASCII)</code>
as being very fast, it seems clear that it’s completely ignoring the <code>-i</code> flag
in this case since the pattern is not an ASCII string. Notably, its timing is
essentially identical to its timing on the previous
<a href="#subtitles-literal"><code>subtitles_literal</code></a>
benchmark. The other interesting thing to note is that <code>ag</code> reports <code>0</code>
matches. This isn’t entirely unreasonable, if it somehow knows that it can’t
satisfy the request (case insensitive search of a non-ASCII string when Unicode
support isn’t enabled). If I had to guess, I’d say PCRE is returning an error
(possibly from <code>pcre_exec</code>) and it isn’t being forwarded to the end user, but
that’s just a shot in the dark.</p>
<h3 id="subtitles_alternate"><code>subtitles_alternate</code></h3>
<p><strong>Description</strong>: This benchmarks an alternation of literals, where there are
several distinct leading bytes from each literal. We control for line counting.</p>
<p><strong>English pattern</strong>: <code>Sherlock Holmes|John Watson|Irene Adler|Inspector Lestrade|Professor Moriarty</code></p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg             0.294 +/- 0.001 (lines: 848)*+
</span></span><span><span>grep           2.955 +/- 0.003 (lines: 848)
</span></span><span><span>rg (lines)     0.619 +/- 0.001 (lines: 848)
</span></span><span><span>ag (lines)     3.757 +/- 0.001 (lines: 848)
</span></span><span><span>ucg (lines)    1.479 +/- 0.002 (lines: 848)
</span></span><span><span>grep (lines)   3.412 +/- 0.004 (lines: 848)</span></span></code></pre></div>


<!-- raw HTML omitted -->
<p><strong>Russian pattern</strong>: <code>Шерлок Холмс|Джон Уотсон|Ирен Адлер|инспектор Лестрейд|профессор Мориарти</code></p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg             1.300 +/- 0.002 (lines: 691)*+
</span></span><span><span>grep           7.994 +/- 0.017 (lines: 691)
</span></span><span><span>rg (lines)     1.902 +/- 0.002 (lines: 691)
</span></span><span><span>ag (lines)     5.892 +/- 0.003 (lines: 691)
</span></span><span><span>ucg (lines)    2.864 +/- 0.006 (lines: 691)
</span></span><span><span>grep (lines)   8.511 +/- 0.005 (lines: 691)</span></span></code></pre></div>


<!-- raw HTML omitted -->
<ul>
<li><code>*</code> - Best mean time.</li>
<li><code>+</code> - Best sample time.</li>
</ul>
<p><strong>Analysis</strong>: <code>rg</code> does really well here, on both the English and Russian
patterns, primarily thanks to Teddy as described in the analysis for
<a href="#subtitles-literal-casei"><code>subtitles_literal_casei</code></a>. On the English pattern,
<code>rg</code> is around an <em>order of magnitude</em> faster than GNU grep.</p>
<p>The performance cost of counting lines is on full display here. For <code>rg</code> at
least, it makes returning search results take twice as long.</p>
<p>Note that the benchmark description mentions picking literals with distinct
leading bytes. This is to avoid measuring an optimization where the regex
engine detects the leading byte and runs <code>memchr</code> on it. Of course, this
optimization is important (and <code>rg</code> will of course do it), but it’s far more
interesting to benchmark what happens in a slightly trickier case.</p>
<h3 id="subtitles_alternate_casei"><code>subtitles_alternate_casei</code></h3>
<p><strong>Description</strong>: This benchmark is just like
<a href="#subtitles-alternate"><code>subtitles_alternate</code></a>,
except it searches case insensitively. In this benchmark, instead of
controlling for line counting (all commands count lines), we control for
Unicode support.</p>
<p><strong>English pattern</strong>: <code>Sherlock Holmes|John Watson|Irene Adler|Inspector Lestrade|Professor Moriarty</code>
(with the <code>-i</code> flag set)</p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg             2.724 +/- 0.002 (lines: 862)*+
</span></span><span><span>grep           5.125 +/- 0.006 (lines: 862)
</span></span><span><span>ag (ASCII)     5.170 +/- 0.004 (lines: 862)
</span></span><span><span>ucg (ASCII)    3.453 +/- 0.005 (lines: 862)
</span></span><span><span>grep (ASCII)   4.537 +/- 0.025 (lines: 862)</span></span></code></pre></div>


<!-- raw HTML omitted -->
<p><strong>Russian pattern</strong>: <code>Шерлок Холмс|Джон Уотсон|Ирен Адлер|инспектор Лестрейд|профессор Мориарти</code></p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg             4.834 +/- 0.004 (lines: 735)
</span></span><span><span>grep           8.729 +/- 0.004 (lines: 735)
</span></span><span><span>ag (ASCII)     5.891 +/- 0.001 (lines: 691)
</span></span><span><span>ucg (ASCII)    2.868 +/- 0.005 (lines: 691)*+
</span></span><span><span>grep (ASCII)   8.572 +/- 0.009 (lines: 691)</span></span></code></pre></div>


<!-- raw HTML omitted -->
<ul>
<li><code>*</code> - Best mean time.</li>
<li><code>+</code> - Best sample time.</li>
</ul>
<p><strong>Analysis</strong>: While <code>rg</code> gets an <em>order of magnitude</em> slower on this benchmark
compared to
<a href="#subtitles-alternate"><code>subtitles_alternate</code></a>,
it still comfortably beats out the rest of the search tools, even when other
tools don’t support Unicode. A key thing this benchmark demonstrates are the
limits of the Teddy algorithm. In fact, <code>rg</code> opts to not use Teddy in this
benchmark because it predicts it won’t perform well.</p>
<p>Why doesn’t Teddy perform well here? Well, the answer is in how we generate
literals for this pattern. Namely, <code>rg</code> will try to generate all possible
literals that satisfy Unicode simple case folding rules, and then will take a
short prefix of that set to cut the number of literals down to reasonable size.
In this particular case, we wind up with 48 literals:</p>



<div><pre tabindex="0"><code data-lang="text"><span><span>INS
</span></span><span><span>INs
</span></span><span><span>INſ
</span></span><span><span>IRE
</span></span><span><span>IRe
</span></span><span><span>InS
</span></span><span><span>Ins
</span></span><span><span>Inſ
</span></span><span><span>IrE
</span></span><span><span>Ire
</span></span><span><span>JOH
</span></span><span><span>JOh
</span></span><span><span>JoH
</span></span><span><span>Joh
</span></span><span><span>PRO
</span></span><span><span>PRo
</span></span><span><span>PrO
</span></span><span><span>Pro
</span></span><span><span>SHE
</span></span><span><span>SHe
</span></span><span><span>ShE
</span></span><span><span>She
</span></span><span><span>iNS
</span></span><span><span>iNs
</span></span><span><span>iNſ
</span></span><span><span>iRE
</span></span><span><span>iRe
</span></span><span><span>inS
</span></span><span><span>ins
</span></span><span><span>inſ
</span></span><span><span>irE
</span></span><span><span>ire
</span></span><span><span>jOH
</span></span><span><span>jOh
</span></span><span><span>joH
</span></span><span><span>joh
</span></span><span><span>pRO
</span></span><span><span>pRo
</span></span><span><span>prO
</span></span><span><span>pro
</span></span><span><span>sHE
</span></span><span><span>sHe
</span></span><span><span>shE
</span></span><span><span>she
</span></span><span><span>ſHE
</span></span><span><span>ſHe
</span></span><span><span>ſhE
</span></span><span><span>ſhe</span></span></code></pre></div>


<p>If we passed all of those to Teddy, it would become overwhelmed. In particular,
Teddy works by finding candidates for matches very quickly. When there are
roughly the same number of candidates as there are matches, Teddy performs
exceedingly well. But, if we give it more literals, then it’s more likely to
find candidates that don’t match, and will therefore have to spend a lot more
time verifying the match, which can be costly.</p>
<p>(A more subtle aspect of the Teddy implementation is that a larger number
of literals increases the cost of every verification, even if the number of
candidates produced doesn’t increase. As I’ve mentioned before, if you want the
full scoop on Teddy, see its
<a href="https://github.com/rust-lang-nursery/regex/blob/3de8c44f5357d5b582a80b7282480e38e8b7d50d/src/simd_accel/teddy128.rs">well commented
implementation</a>.
Going into more detail on Teddy would require a whole blog post on its own!)</p>
<p>When <code>rg</code> sees that there are a large number of literals, it could do one of
two things:</p>
<ol>
<li>Try to cut down the set even more. For example, in this case, we could strip
the last character from each prefix off and end up with a much smaller set.
Unfortunately, even though we have fewer literals, we wind up with a still
not-so-small set of two-character literals, which will also tend to produce
a lot more false positive candidates just because of their length.</li>
<li>Move to a different multiple pattern algorithm, such as
<a href="https://en.wikipedia.org/wiki/Aho%E2%80%93Corasick_algorithm">Aho-Corasick</a>.</li>
</ol>
<p>I have tried to implement (1) in the past, but I’ve always wound up in a game
of whack-a-mole. I might make one common case faster, but another common case a
lot slower. In those types of cases, it’s usually better to try and achieve
good average case performance. Luckily for us, Aho-Corasick does <em>exactly</em>
that.</p>
<p>We do still have a few tricks up our sleeve though. For example, many
Aho-Corasick implementations are built as-if they were
<a href="https://en.wikipedia.org/wiki/Trie">tries</a>
with back-pointers for their failure transitions.
We can actually do better than that. We can compile all of its failure
transitions into a DFA with a transition table contiguous in memory. This means
that every byte of input corresponds to a single lookup in the transition table
to find the next state. We never have to waste time chasing pointers or walking
more than one failure transition for any byte in the search text.</p>
<p>Of course, this transition table based approach is memory intensive, since you
need space for <code>number_of_literals * number_of_states</code>, where
<code>number_of_states</code> is roughly capped at the total number of bytes in all of the
literals. While 48 literals of length 3 is too much for Teddy to handle, it’s
barely a blip when it comes to Aho-Corasick, even with its memory expensive
transition table based approach. (N.B. In the literature, this particular
implementation of Aho-Corasick is often called “Advanced” Aho-Corasick.)</p>
<h3 id="subtitles_surrounding_words"><code>subtitles_surrounding_words</code></h3>
<p><strong>Description</strong>: This benchmarks a pattern that searches for words surrounding
the literal string <code>Holmes</code>. This pattern was specifically constructed to
defeat both prefix and suffix literal optimizations.</p>
<p><strong>English pattern</strong>: <code>\w+\s+Holmes\s+\w+</code></p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg             0.605 +/- 0.000 (lines: 317)
</span></span><span><span>grep           1.286 +/- 0.002 (lines: 317)
</span></span><span><span>rg (ASCII)     0.602 +/- 0.000 (lines: 317)*+
</span></span><span><span>ag (ASCII)     11.663 +/- 0.008 (lines: 323)
</span></span><span><span>ucg (ASCII)    4.690 +/- 0.002 (lines: 317)
</span></span><span><span>grep (ASCII)   1.276 +/- 0.002 (lines: 317)</span></span></code></pre></div>


<!-- raw HTML omitted -->
<p><strong>Russian pattern</strong>: <code>\w+\s+Холмс\s+\w+</code></p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg             0.957 +/- 0.001 (lines: 278)*+
</span></span><span><span>grep           1.660 +/- 0.002 (lines: 278)
</span></span><span><span>ag (ASCII)     2.411 +/- 0.001 (lines: 0)
</span></span><span><span>ucg (ASCII)    2.980 +/- 0.002 (lines: 0)
</span></span><span><span>grep (ASCII)   1.596 +/- 0.003 (lines: 0)</span></span></code></pre></div>


<!-- raw HTML omitted -->
<ul>
<li><code>*</code> - Best mean time.</li>
<li><code>+</code> - Best sample time.</li>
</ul>
<p><strong>Analysis</strong>: In order to compete on this benchmark, a search tool will need to
implement a so-called “inner literal” optimization. You can probably guess what
that means: it is an optimization that looks for literal strings that appear
<em>anywhere</em> in the pattern, and if a literal is found that must appear in every
match, then a search tool can quickly scan for that literal instead of applying
the full regex to the search text.</p>
<p>The key thing that permits this optimization to work is the fact that most
search tools report results <em>per line</em>. For example, in this case, if a line
contains the literal <code>Holmes</code>, then the search tool can find the beginning and
ending of that line and run the full pattern on <em>just that line</em>. If the
literal is relatively rare, this keeps us out of the regex engine for most of
the search. And of course, if the literal doesn’t appear at all in the corpus,
then we will have never touched the regex engine at all.</p>
<p>To achieve the full optimization, you probably need to parse your pattern
into its abstract syntax (abbreviated “AST” for abstract syntax tree) to
extract the literal. It is worth pointing out however that one can probably get
a lot of mileage with simpler heuristics, but a real pattern parser is the only
way to do this optimization robustly. The problem here is that for most regex
engines, parsing the pattern is an unexposed implementation detail, so it can
be hard for search tools to extract literals in a robust way without writing
their own parser, and a modern regex parser is no easy task! Thankfully, Rust’s
regex library exposes an additional library,
<a href="https://doc.rust-lang.org/regex/regex_syntax/index.html"><code>regex-syntax</code></a>,
which provides a full parser. <code>rg</code> implements this optimization relatively
easily with the help of <code>regex-syntax</code>, while GNU grep implements this
optimization because the search tool and the underlying regex engine are
coupled together.</p>
<p>Why does the search tool need to perform this optimization? Why can’t the
underlying regex engine do it? I personally have thought long and hard about
this particular problem and haven’t been able to come up with an elegant
solution. The core problem is that once you find an occurrence of the literal,
you <em>don’t know where to start searching the full regex</em>. In a general purpose
regex engine, a pattern could match an arbitrarily long string. For example,
<code>\w+\s+Holmes\s+\w+</code> mightly only match at the very end of a gigabyte sized
document. There are ways to work around this. For example, you could split the
regex into three pieces: <code>\w+\s+</code>, <code>Holmes</code> and <code>\s+\w+</code>. On every occurrence
of the <code>Holmes</code> literal, you could search for the beginning of the match by
executing <code>\w+\s+</code> in reverse starting just before the literal, and executing
<code>\s+\w+</code> forwards starting just after the literal. The key problem with this
approach is that it exposes you to quadratic behavior in the worst case (since
<code>\w+\s+</code> or <code>\s+\w+</code> could cause you to re-scan text you’ve already seen).
While I believe there is a general purpose way to solve this and still
guarantee linear time searching, a good solution hasn’t revealed itself yet.</p>
<p>Based on the data in this benchmark, only <code>rg</code> and GNU grep perform this
optimization. Neither <code>ag</code> nor <code>ucg</code> attempt to extract any inner literals from
the pattern, and it looks like PCRE doesn’t try to do anything too clever.
(Of course, Rust’s regex library doesn’t either, this optimization is done in
<code>rg</code> proper.)</p>
<p>As for the Russian pattern, we see that only tools with proper Unicode support
can execute the query successfully. The reason is because <code>\w</code> is ASCII only in
<code>ucg</code> and <code>ag</code>, so it can’t match the vast majority of word characters (which
are Cyrllic) in our sample. Otherwise, both <code>rg</code> and GNU grep remain fast,
primarily because of the inner literal optimization.</p>
<h3 id="subtitles_no_literal"><code>subtitles_no_literal</code></h3>
<p><strong>Description</strong>: This benchmark purposefully has no literals in it, which makes
it a bit idiosyncratic, since most searches done by end users probably have at
least some literal in them. However, it is a useful benchmark to gauge the
general performance of the underlying regex engine.</p>
<p><strong>English pattern</strong>: <code>\w{5}\s+\w{5}\s+\w{5}\s+\w{5}\s+\w{5}\s+\w{5}\s+\w{5}</code></p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg             2.777 +/- 0.003 (lines: 13)
</span></span><span><span>rg (ASCII)     2.541 +/- 0.005 (lines: 13)*+
</span></span><span><span>ag (ASCII)     10.076 +/- 0.005 (lines: 48)
</span></span><span><span>ucg (ASCII)    7.771 +/- 0.004 (lines: 13)
</span></span><span><span>grep (ASCII)   4.411 +/- 0.004 (lines: 13)</span></span></code></pre></div>


<!-- raw HTML omitted -->
<p><strong>Russian pattern</strong>: <code>\w{5}\s+\w{5}\s+\w{5}\s+\w{5}\s+\w{5}\s+\w{5}\s+\w{5}</code></p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg             4.905 +/- 0.003 (lines: 41)
</span></span><span><span>rg (ASCII)     3.973 +/- 0.002 (lines: 0)
</span></span><span><span>ag (ASCII)     2.395 +/- 0.004 (lines: 0)*+
</span></span><span><span>ucg (ASCII)    3.006 +/- 0.005 (lines: 0)
</span></span><span><span>grep (ASCII)   2.483 +/- 0.005 (lines: 0)</span></span></code></pre></div>


<!-- raw HTML omitted -->
<ul>
<li><code>*</code> - Best mean time.</li>
<li><code>+</code> - Best sample time.</li>
<li><code>ag</code> gets more matches on the English pattern since it does multiline search.
Namely, the <code>\s</code> can match a <code>\n</code>.</li>
<li><code>grep</code> with Unicode support was dropped from this benchmark because it takes
over 90 seconds on the English pattern and over 4 <strong>minutes</strong> on the Russian
pattern. In both cases, GNU grep and <code>rg</code> report the same results.</li>
</ul>
<p><strong>Analysis</strong>: Once again, no other search tool performs as well as <code>rg</code>. For
the English pattern, both <code>rg</code> and <code>rg (ASCII)</code> have very similar performance,
despite <code>rg</code> supporting Unicode.</p>
<p>What specifically makes <code>rg</code> faster than GNU grep in this case? Both search
tools ultimately use a DFA to execute this pattern, so their performance should
be roughly the same. I don’t actually have a particularly good answer for this.
Both GNU grep and Rust’s regex library unroll the DFA’s inner loop, and both
implementations compute states on the fly. I can make a guess though.</p>
<p>Rust’s regex library avoids a single pointer dereference when following a
transition. How it achieves this is complicated, but it’s done by representing
states as indices into the transition table rather than simple incremental ids.
This permits the generated code to use simple addition to address the location
of the next transition, which can be done with addressing modes in a single
instruction. (Specifically, this optimization means we don’t need to do any
multiplication to find the state transition.) A single pointer dereference
might not seem like much, but when it’s done for every state transition over a
large corpus such as this, it can have an impact.</p>
<p>When it comes to the Russian pattern, such details are far less important
because GNU grep takes <em>minutes</em> to run. This suggests that it isn’t building
UTF-8 decoding into its DFA, and is instead doing something like decoding a
character at a time, which can have a lot of overhead associated with it. I
admit that I don’t quite grok this aspect of GNU grep though, so I could have
its cost model wrong. Now, in all fairness, GNU grep’s locale and encoding
support far exceeds what <code>rg</code> supports. However, in today’s world, UTF-8 is
quite prevalent, so supporting that alone is often enough. More to the point,
given how common UTF-8 is, it’s important to remain fast while supporting
Unicode, which GNU grep isn’t able to do.</p>
<p>Unfortunately, the other tools don’t support Unicode, so they can’t be
meaningfully benchmarked on the Russian pattern.</p>
<h2 id="bonus-benchmarks">Bonus benchmarks</h2>
<p>In this section, we’ll take a look at a few crazier benchmarks that aren’t
actually part of the suite I’ve published. Indeed, the performance differences
between tools are often so large that a fastidious analysis isn’t really
necessary. More to the point, these usage patterns aren’t necessarily
representative of common usage (not that these usages aren’t important, they’re
just niche), so the performance differences are less important. Nevertheless,
it is fun to see how well <code>rg</code> and the other tools hold up under these
requests.</p>
<h3 id="everything"><code>everything</code></h3>
<p><strong>Description</strong>: In this benchmark, we compare how long it takes for each tool
to report every line as a match. This benchmark was run in the root of the
Linux repository.</p>
<p><strong>Pattern</strong>: <code>.*</code></p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg                 1.081 (lines: 22065361)
</span></span><span><span>ag                 1.660 (lines: 55939)
</span></span><span><span>git grep           3.448 (lines: 22066395)
</span></span><span><span>sift             110.018 (lines: 22190112)
</span></span><span><span>pt                 0.245 (lines: 3027)
</span></span><span><span>rg (whitelist)     0.987 (lines: 20936584)
</span></span><span><span>ucg (whitelist)    5.558 (lines: 23163359)</span></span></code></pre></div>


<p><strong>Analysis</strong>: This benchmark is somewhat silly since it’s something you
probably never want a search tool to do. Nevertheless, it is useful to know
that <code>rg</code> scales quite well to a huge number of matches.</p>
<p>One of the key tricks that a good regex engine will do in this case is stop
searching text as soon as it knows it has a match if all the caller cares about
is “is there a match or not?” In this case, we will find a match at the
beginning of every line, immediately quit, find the line boundaries and then
repeat the process. There is no particular special cased optimization for <code>.*</code>
in either <code>rg</code> or Rust’s regex library (although there could be).</p>
<p>Interestingly, neither <code>ag</code> nor <code>pt</code> actually report every line. They appear to
have some kind of match limit. Which isn’t altogether unreasonable. This is a
search tool after all, and some might consider that returning every result
isn’t useful.</p>
<h3 id="nothing"><code>nothing</code></h3>
<p><strong>Description</strong>: This is just like the <a href="#everything"><code>everything</code></a> benchmark,
except it inverts the results. The correct result is for a search tool to
report no lines as matching. This benchmark also searches the Linux kernel
source code, from the root of repository.</p>
<p><strong>Pattern</strong>: <code>.*</code> (with the <code>-v</code> or <code>--invert-match</code> flag set)</p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg                0.302 (lines: 0)
</span></span><span><span>ag                takes minutes
</span></span><span><span>git grep          0.905 (lines: 0)
</span></span><span><span>sift             12.804 (lines: 0)
</span></span><span><span>pt                -----
</span></span><span><span>rg (whitelist)    0.251 (lines: 0)
</span></span><span><span>ucg (whitelist)   -----</span></span></code></pre></div>


<p><strong>Analysis</strong>: While this benchmark is even more ridiculous than the previous
one (“give me nothing of everything”), it does expose a few warts and omissions
in other tools. Namely, <code>ag</code> seems to slow way down when reporting inverted
matches. Neither <code>pt</code> nor <code>ucg</code> support inverted searching at all. <code>sift</code>
redeems itself from the previous benchmark (perhaps it has a lot of overhead
associated with printing matches that it doesn’t hit here). Neither <code>rg</code> nor
<code>git grep</code> have any problems satisfying the request.</p>
<h3 id="context"><code>context</code></h3>
<p><strong>Description</strong>: This benchmarks how well a search tool can show the context
around each match. Specifically, in this case, we ask for the two lines
preceding and succeeding every match. We run this benchmark on the English
subtitle corpus. Note that all tools are asked to count lines.</p>
<p><strong>Pattern</strong>: <code>Sherlock Holmes</code> (with <code>--context 2</code>)</p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg        0.612 (lines: 3533)
</span></span><span><span>ag        3.530 (lines: 3533)
</span></span><span><span>grep      1.075 (lines: 3533)
</span></span><span><span>sift      0.717 (lines: 3533)
</span></span><span><span>pt       17.331 (lines: 2981)
</span></span><span><span>ucg       -----</span></span></code></pre></div>


<p><strong>Analysis</strong>: <code>rg</code> continues to do well here, but beats <code>sift</code> by only a hair.
In general, computing the context shouldn’t be that expensive since it is done
rarely (only for each match). Nevertheless, both <code>ag</code> and <code>pt</code> seem to take a
pretty big hit for it. <code>pt</code> also seems to have a bug. (Which is understandable,
getting contexts right is tricky.) Finally, <code>ucg</code> doesn’t support this feature,
so we can’t benchmark it.</p>
<h3 id="huge"><code>huge</code></h3>
<p><strong>Description</strong>: This benchmark runs a simple literal search on a file that is
<code>9.3GB</code>. In fact, this is the original English subtitle corpus in its entirety.
(In the benchmark suite, we take a 1GB sample.)</p>
<p><strong>Pattern</strong>: <code>Sherlock Holmes</code></p>



<div><pre tabindex="0"><code data-lang="text"><span><span>rg                1.786 (lines: 5107)
</span></span><span><span>grep              5.119 (lines: 5107)
</span></span><span><span>sift              3.047 (lines: 5107)
</span></span><span><span>pt               14.966 (lines: 5107)
</span></span><span><span>rg (lines)        4.467 (lines: 5107)
</span></span><span><span>ag (lines)       19.132 (lines: 5107)
</span></span><span><span>grep (lines)      9.213 (lines: 5107)
</span></span><span><span>sift (lines)      6.303 (lines: 5107)
</span></span><span><span>pt (lines)       15.485 (lines: 5107)
</span></span><span><span>ucg (lines)       4.843 (lines: 1543)</span></span></code></pre></div>


<p><strong>Analysis</strong>: At first glance, it appears <code>ucg</code> competes with <code>rg</code> when
counting lines (being only slightly slower), but in fact, <code>ucg</code> reports the
wrong number of results! My suspicion is that <code>ucg</code> gets into trouble when
trying to search files over 2GB.</p>
<p>The other intesting bit here is how slow <code>pt</code> is, even when not counting lines,
despite the fact that <code>sift</code> is fast. They both use Go’s regexp engine and
should be able to be fast in the case of a simple literal. It’s not clear what
<code>pt</code>’s slow down here is. One hypothesis is that even though I’m asking it to
not count lines, it’s still counting them but simply not showing them.</p>
<h2 id="conclusions">Conclusions</h2>
<p>I started this blog post by claiming that I could support the following claims
with evidence:</p>
<ul>
<li>For both searching single files <em>and</em> huge directories of files, no other
tool obviously stands above <code>ripgrep</code> in either performance or correctness.</li>
<li><code>ripgrep</code> is the only tool with proper Unicode support that doesn’t make
you pay dearly for it.</li>
<li>Tools that search many files at once are generally <em>slower</em> if they use
memory maps, not faster.</li>
</ul>
<p>I attempted to substantiate the first claim by picking a popular repository
(Linux kernel) and a variety of patterns that an end user might search for.
While <code>rg</code> doesn’t quite come out on top on every benchmark, no other tool can
claim superiority. In particular, <code>git grep</code> edges out <code>rg</code> on occasion by a
few milliseconds, but <code>rg</code> in turn will beat <code>git grep</code> handedly
(sometimes by an order of magnitude, as in the case of
<a href="#linux-unicode-word"><code>linux_unicode_word</code></a>) as the patterns grow more complex,
especially when the search tool is asked to support Unicode. <code>rg</code> manages to
compete with <code>git grep</code> and beat other tools like The Silver Searcher by:</p>
<ul>
<li>Implementing fast directory traversal with a minimal number of stat calls.</li>
<li>Applying <code>.gitignore</code> filters with a
<a href="https://doc.rust-lang.org/regex/regex/struct.RegexSet.html"><code>RegexSet</code></a>,
which enables matching multiple globs against a single path all at once.</li>
<li>Distributing work quickly to multiple threads with a Chase-Lev work stealing
queue.</li>
<li>Explicitly <em>not</em> using memory maps.</li>
<li>Using an overall very fast regex engine.</li>
</ul>
<p>I also attempted to substantiate the first claim by showing benchmarks of <code>rg</code>
against other tools on a single file. In this benchmark, <code>rg</code> comes out on top
in every single one, often by a large margin. Some of those results are a
result of the following optimizations:</p>
<ul>
<li>Attempting to pick a “rare” byte to use <code>memchr</code> with for fast skipping.</li>
<li>Using a special SIMD algorithm called Teddy for fast multiple pattern search.</li>
<li>When Teddy isn’t usable, fallback to an “advanced” form of Aho-Corasick that
never moves through more than one transition on each byte of input.</li>
<li>Building UTF-8 decoding into a finite state machine.</li>
</ul>
<p>For the second claim, I provided benchmarks that attempt to use Unicode
features such as conforming to Unicode’s simple case folding rules and Unicode
aware character classes such as <code>\w</code>. The only tools capable of handling
Unicode are <code>rg</code>, GNU grep and <code>git grep</code>. The latter two tend to get much
slower when supporting the full gamut of Unicode while <code>rg</code> mostly maintains
its performance.</p>
<p>For the third claim, I showed multiple benchmarks of <code>rg</code> controlling for
memory maps. Namely, we measured how fast <code>rg</code> was both with and without memory
maps, and showed that memory maps perform worse when searching many small files
in parallel, but perform better on searching single large files. (At least, on
<code>Linux x86_64</code>.) We also learned that memory maps probably pay an additional
penalty inside a VM.</p>
<p>My hope is that this article not only convinced you that <code>rg</code> is quite fast,
but more importantly, that you found my analysis of each benchmark educational.
String searching is an old problem in computer science, but there is still
plenty of work left to do to advance the state of the art.</p>
      </article>

      

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I worked in Amazon HR and was disgusted at what I was seeing with PIP plans (526 pts)]]></title>
            <link>https://www.businessinsider.com/amazon-hr-performance-improvement-plans-pip-pivot-had-to-quit-2023-11</link>
            <guid>38471744</guid>
            <pubDate>Thu, 30 Nov 2023 10:09:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.businessinsider.com/amazon-hr-performance-improvement-plans-pip-pivot-had-to-quit-2023-11">https://www.businessinsider.com/amazon-hr-performance-improvement-plans-pip-pivot-had-to-quit-2023-11</a>, See on <a href="https://news.ycombinator.com/item?id=38471744">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-component-type="content-lock" data-load-strategy="exclude">
                                  <ul><li>A former HR staffer at Amazon put employees on a performance-improvement plan known as Pivot.</li><li>Then, the HR staffer, who says they developed PTSD from the work, was put on their own PIP.</li><li>An Amazon spokesperson said the account contained inaccuracies about the company's process.</li></ul><!-- Excluded mobile ad on desktop --><div id="formContainer" data-component-type="inline-newsletter-module" data-event-label="insider_today" data-newsletter-id="1" data-list="Insider Today" data-acq-source="careersinlinesignup">
                        
                        
                          <section>
                              
                        
                            <p><svg version="1.1" xmlns="http://www.w3.org/2000/svg" role="img" width="50" height="50" viewBox="0 0 50 50" style="enable-background:new 0 0 50 50;" xml:space="preserve">
                          <title>Loading</title>
                          <desc>Something is loading.</desc>
                          <path fill="#111" d="M43.935,25.145c0-10.318-8.364-18.683-18.683-18.683c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615c8.072,0,14.615,6.543,14.615,14.615H43.935z">
                            <animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform>
                          </path>
                        </svg></p>
                            
                        
                            
                        
                            <div>
                              <p>Thanks for signing up!</p>
                              
                              <p>
                              Access your favorite topics in a personalized feed while you're on the go.
                                    </p>
                            </div>
                        
                            
                            
                          </section>
                        
                            <div>
                                <p><img src="https://www.businessinsider.com/public/assets/rebrand/newsletter-bull.png" data-old-src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1 1'%3E%3C/svg%3E" data-src="/public/assets/rebrand/newsletter-bull.png">
                              
                              
                              
                              </p>    </div>
                        
                          
                        </div><p><em>This as-told-to essay is based on a conversation with a former Amazon human-resources worker who was put into the company's performance-management program known as Pivot. This person spoke on condition of anonymity to avoid jeopardizing their career. Business Insider has verified their identity and employment at the company. The conversation has been edited for length and clarity.</em></p><p>I worked at <a target="_blank" href="https://www.businessinsider.com/amazon" data-analytics-product-module="body_link" rel="">Amazon</a> in HR for several years. Not only did I administer Pivots, but it was eventually brought to my attention that I was going to be going through one.</p><p>They made a mistake by doing that with me. There wasn't a lot of information to justify a poor performance.</p><p>The Pivot goal was a straight, <a target="_blank" href="https://www.businessinsider.com/amazon-focus-coaching-plans-unregretted-attrition-2021-5" data-analytics-product-module="body_link" rel=""><u>across-the-board 6% number</u></a>. And as an HR person, that is a hefty figure.</p><!-- Excluded mobile ad on desktop --><p>And it was driven hard by the HR VPs to show the metrics — daily, weekly — to make sure we knew who was in the pipeline. Not to improve, but who was in the pipeline to get out. There wasn't a lot of interest in improving people.</p><p>You might be cutting some prime choice with the fat. And they were OK with that. <a target="_blank" href="https://www.businessinsider.com/amazon-employees-annual-reviews-rating-2021-4" data-analytics-product-module="body_link" rel=""><u>They wanted that number</u></a>. The managers who had to implement it and tell their people they were on Pivot — I would say a majority of them hated it. Because, one, they didn't have the skills to be able to manage performance that soon out of the gate. A lot of our managers were brand new.</p><p>The first thing you had to do was work with a Pivot consultant. So, that was somebody in HR besides the manager's business partner. And you'd talk about if it was the right time or if it was the wrong time to Pivot someone.</p><p>I would say 80% of my time ended up being focused one way or another on Pivot. Either the Pivot appeal or the Pivot work that workers' managers had to do. And look, I'm not going to say you're going to ever find this somewhere, locked down in words. But the idea is, if you're putting somebody in Pivot, you make that so damn hard that they don't get out.</p><!-- Excluded mobile ad on desktop --><p>Almost always, unless there was some really unique set of situations where it came out during the appeal, the success rate of that was virtually none.</p><p>When I wasn't working on Pivots, working in HR was great. We were supposed to be doing coaching and focusing on strengths and moving people through the organization in a positive way.</p><p>Later, when Pivot came back, we had to stack rank all of our employees. The way we broke it down, we called it top tier, which was, you know, maybe 15-20% by the time it worked out. And then you had the middle. And then you have the bottom tier. The bottom tier was about 20-25%, maybe even up to 30%. The guidelines that they expressed publicly may be different because we always worked to make sure we had more than that because some went bad — or went off the rails, and we couldn't exit them for whatever reason.</p><p>We were way over how many people were actually underperforming or detrimental to the business. Maybe around 1% or 1.5% to 2% were actually not performing well.</p><!-- Excluded mobile ad on desktop --><h2><strong>I have PTSD</strong></h2><p>I was disgusted at what I was seeing with the Pivot process. This process alone has given me post-traumatic stress disorder. It impacted me so much as a person that I had to get out of there.</p><p>When it was justified, it was easier to push someone out. If it's deserved, there's no problem. But when it wasn't deserved, you had people crying and begging, and they couldn't understand.</p><p>You had visa-sponsored employees who, once we Pivoted them and moved them out, no longer were authorized to work in the United States. So, they had to make immediate plans to get out of the country. And it's a long process to get sponsored by another group.</p><p>In the years I was there, I never, ever, ever had any performance issue given to me — not even anything close to being serious. I had no worries because I asked for feedback all the time. I'm like, "What can I do? How can I do better?" I didn't ever want to be blindsided by Pivot myself. And what a lot of people did —&nbsp;if they got the indication that they were going down that track —&nbsp;was they would transfer jobs right away. Some people were successful. A lot of people weren't.</p><!-- Excluded mobile ad on desktop --><p>Normally, with a performance-improvement program, as an HR person, you're following progressive discipline. Are you seeing notes that this person is having trouble? Are you seeing coaching conversations that are taking place? So for it to actually just — boom —&nbsp;be there is really problematic.</p><h2><strong>It was my turn</strong></h2><p>During my performance evaluation, when it was clear I was on a PIP, my manager shared criticisms that I'd never heard before. I said, "I've never had any of these comments come to me ever." Essentially, it was a lot of made-up stuff. I mean, you could put some truth to it. I'd been late on a few assignments. But everybody's got some element of things they can improve on in their work. My manager just chose to bring those out.</p><p>Amazon broke down people into three categories. You were either top-tier, middle of the pack, or at least effective.</p><p>Normally, they won't tell you what they rated you, and I'm like, "Come on. I know this stuff just as much as you do. I know the wording. You didn't put me in the medium category. Would you just admit that you put me in the least-effective category?" And I got my manager to admit that.</p><!-- Excluded mobile ad on desktop --><p>I wasn't put on Pivot. My manager wanted to work with me a little bit to see if I was going to commit to the job. So they sat me down and said I could go on Pivot and leave right away, or they would work with me. Well, obviously not having any job opportunities, I said, "Look, I'm in it. Let's try to get better and go from there." So my manager took away all my direct reports, and shoved me into a small box, and said you could do this and try to work yourself out of it.</p><p>Right after that, I started putting in the full push to get another job. And so I started interviewing. I actually had a headhunter that reached out to me. Originally, I told her no, but then some of this stuff happened. And I'm like, "OK, let's revisit it." I got to the point where they offered me a job, and I was going to quit. But I had a huge stock investment coming up. So there was no way I was going to rock the boat in any way, shape, or form just trying to get to this date.</p><p>If you walked away during the Pivot or anytime before you had your investment before it was there for you, you would lose it all. And I'm not talking a little bit of money. I'm talking: I had a couple hundred thousand dollars coming to me.</p><p>I played along, and I'm good at playing along when I have to be. So then the money is in my account. That next day, I called my manager and I told them I was resigning. They blew a gasket —&nbsp;absolutely blew a gasket because I had told them that I was in it for the long run. I said, "Look, you gave me no choice. You put this threat against me. I'm not just gonna sit there and wait for it to be dependent on you. You get to make the call whether I make it or not." My manager was super mad and asked me when I was leaving. I said two weeks. They were incredulous that I wasn't giving them more respect.</p><!-- Excluded mobile ad on desktop --><p>The biggest thing —&nbsp;and I'm gonna say this goes for many, many people that were put on Pivot —&nbsp;is there were no warning signs. There was no trail of communication saying, "You are underperforming." I mean, even if it's something as simple as, "Hey, can you do better on this next time?" I know, certainly, I got zero negative feedback. I got the feedback that I was rocking it. And then all of a sudden, to be in this place, it's like, "Huh."</p><p>I still wonder about what happened to all the people that went through that process. How did it impact their life? I think it leads to a lot of mental-health issues.</p><blockquote><section><em>Margaret Callahan, an Amazon spokesperson, told BI via email:</em></section><section><em>"Like most companies, we have a performance management process that helps our managers identify who on their teams are performing well and who may need more support. For the small number of employees who are underperforming, we use performance management programs to help them improve, and many employees do just that. Sometimes the programs result in employees leaving the company. Business Insider declined to share the information needed to verify this individual's account, but it contains a number of inaccuracies about our performance management process. An unverified, anonymous anecdote in a Business Insider 'As told to' essay does not represent the experience of the vast majority of our employees."</em></section></blockquote><p><em>Do you have something to share about what you're seeing in your workplace? Insider would like to hear from you. Email our workplace team from a nonwork device at <u>thegrind@businessinsider.com</u> with your story or to ask for one of our reporter's Signal numbers. Or </em><a target="_blank" href="https://www.businessinsider.com/insider-guide-to-securely-sharing-whistleblower-information-about-powerful-institutions-2021-10" data-analytics-product-module="body_link" rel=""><em><u>check out Business Insider's source guide</u></em></a><em> for tips on sharing information securely.</em></p>
                      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Open source supply chain security at Google [video] (104 pts)]]></title>
            <link>https://research.swtch.com/acmscored</link>
            <guid>38471475</guid>
            <pubDate>Thu, 30 Nov 2023 09:26:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://research.swtch.com/acmscored">https://research.swtch.com/acmscored</a>, See on <a href="https://news.ycombinator.com/item?id=38471475">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <h2>Open Source Supply Chain Security at Google
        
        <div>
        <p>
          
            Posted on Thursday, November 30, 2023.
            
          
        </p>
        </div>
        </h2>
        

<p>
I was a remote opening keynote speaker at <a href="https://scored.dev/">ACM SCORED 2023</a>, which we decided meant that I sent a video to play and I was on Discord during the talk for attendees to text directly with question as the video played, and then we did some live but still remote Q&amp;A after the talk.

</p><p>
My talk was titled “Open Source Supply Chain Security at Google” and was 45 minutes long. I spent a while at the start defining open source supply chain security and a while at the end on comparisons with the 1970s. In between, I talked about various supply chain-related efforts at Google. All the Google efforts mentioned in the talk have been publicly discussed elsewhere and are linked below.
</p><p>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/6H-V-0oQvCA?si=mprcItvmNMw5QnR0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</p>


<p>
Here are the <a href="https://youtu.be/6H-V-0oQvCA">talk video</a> and <a href="https://research.swtch.com/acmscored.pdf">talk slides</a>.  Opinions expressed in the talk about languages and the last half century of supply chain security are mine, not Google’s.

</p><p>
References or acknowledgements for the slides:
</p><ul>
<li>
Crypto AG: <a href="https://www.theguardian.com/us-news/2020/feb/11/crypto-ag-cia-bnd-germany-intelligence-report">Guardian</a> and <a href="https://www.washingtonpost.com/graphics/2020/world/national-security/cia-crypto-encryption-machines-espionage/">Washington Post</a>
</li><li>
Enigma photograph: personal photo, taken at Bletchley Park in 2012
</li><li>
XcodeGhost: <a href="https://unit42.paloaltonetworks.com/novel-malware-xcodeghost-modifies-xcode-infects-apple-ios-apps-and-hits-app-store/">Palo Alto Networks</a>
</li><li>
Juniper Attack: <a href="https://cacm.acm.org/magazines/2018/11/232227-where-did-i-leave-my-keys/fulltext">CACM</a>, <a href="https://eprint.iacr.org/2016/376.pdf">Eprint</a>, <a href="https://www.bloomberg.com/news/features/2021-09-02/juniper-mystery-attacks-traced-to-pentagon-role-and-chinese-hackers">Bloomberg</a>
</li><li>
SolarWinds: <a href="https://www.wired.com/story/the-untold-story-of-solarwinds-the-boldest-supply-chain-hack-ever/">Wired (Kim Zetter)</a>
</li><li>
NPM event-stream: <a href="https://arstechnica.com/information-technology/2018/11/hacker-backdoors-widely-used-open-source-software-to-steal-bitcoin/">Ars Technica</a>, <a href="https://blog.npmjs.org/post/180565383195/details-about-the-event-stream-incident">NPM</a>
</li><li>
iMessage JBIG2: <a href="https://googleprojectzero.blogspot.com/2021/12/a-deep-dive-into-nso-zero-click.html">Project Zero</a>
</li><li>
Log4j: <a href="https://www.minecraft.net/en-us/article/important-message--security-vulnerability-java-edition">Minecraft</a>, <a href="https://www.cisa.gov/news-events/news/apache-log4j-vulnerability-guidance">CISA</a>
</li><li>
<a href="https://deps.dev/go/k8s.io%2Fkubernetes/v1.28.4/dependencies/graph">Kubernetes on Open Source Insights</a> and <a href="https://deps.dev/go/k8s.io%2Fkubernetes/v1.28.4/compare?v2=v1.29.0-rc.0">comparing versions</a>
</li><li>
<a href="https://www.sigstore.dev/">Sigstore</a>
</li><li>
“<a href="https://go.dev/blog/rebuild">Perfectly Reproducible, Verified Go Toolchains</a>”
</li><li>
“<a href="https://go.dev/blog/supply-chain">How Go Mitigates Supply Chain Attacks</a>”
</li><li>
Two-person photograph: <a href="https://www.nationalmuseum.af.mil/Visit/Museum-Exhibits/Fact-Sheets/Display/Article/197675/launching-missiles/">Air Force National Museum</a>, public domain
</li><li>
<a href="https://slsa.dev/spec/v1.0/levels">SLSA (Supply-chain Levels for Software Artifacts)</a>
</li><li>
<a href="https://securityscorecards.dev/">Security Scorecards</a>
</li><li>
Capslock: <a href="https://security.googleblog.com/2023/09/capslock-what-is-your-code-really.html">blog post</a>, <a href="https://github.com/google/capslock">repository</a>
</li><li>
Google <a href="https://bughunters.google.com/open-source-security">Open Source Security Rewards</a>
</li><li>
Google Project Zero: <a href="https://security.googleblog.com/2014/07/announcing-project-zero.html">blog post</a>, <a href="https://www.youtube.com/watch?v=My_13FXODdU">excellent video</a>
</li><li>
OSS-Fuzz: <a href="https://opensource.googleblog.com/2016/12/announcing-oss-fuzz-continuous-fuzzing.html">blog post</a>, <a href="https://github.com/google/oss-fuzz">repository</a>
</li><li>
<a href="https://syzkaller.appspot.com/upstream">Syzkaller dashboard</a>
</li><li>
Internet worm: <a href="https://timesmachine.nytimes.com/timesmachine/1988/11/04/issue.html">New York Times</a>
</li><li>
<a href="https://media.defense.gov/2022/Nov/10/2003112742/-1/-1/0/CSI_SOFTWARE_MEMORY_SAFETY.PDF">NSA Software Memory Safety</a>
</li><li>
<a href="https://go.dev/">Go home page</a>
</li><li>
<a href="https://www.rust-lang.org/">Rust home page</a>
</li><li>
SBOMs: “<a href="https://www.ntia.gov/sites/default/files/publications/ntia_sbom_framing_2nd_edition_20211021_0.pdf">NTIA: Framing Software Component Transparency</a>”, “<a href="https://www.cisa.gov/sites/default/files/2023-10/Software-Identification-Ecosystem-Option-Analysis-508c.pdf">CISA: Software Identification Ecosystem Option Analysis</a>”
</li><li>
<a href="https://osv.dev/">Open Source Vulnerability</a> database
</li><li>
Govulncheck: <a href="https://go.dev/blog/govulncheck">blog post</a>, <a href="https://pkg.go.dev/golang.org/x/vuln/cmd/govulncheck">package docs</a>, <a href="https://go.dev/doc/tutorial/govulncheck">tutorial</a>
</li><li>
<a href="https://cloud.google.com/artifact-registry/docs/analysis">Google Cloud Artifact Analysis</a>
</li><li>
<a href="https://seclab.cs.ucdavis.edu/projects/history/papers/karg74.pdf">Air Force Review of Multics</a> (quotes are from pages numbered 51 and 52 on the paper, aka PDF pages 55 and 56)
</li><li>
Thompson backdoor: “<a href="https://dl.acm.org/doi/10.1145/358198.358210">Reflections on Trusting Trust</a>” (1983) and <a href="https://research.swtch.com/nih">annotated code</a> (2023)</li></ul>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[XCurl (322 pts)]]></title>
            <link>https://daniel.haxx.se/blog/2023/11/30/xcurl/</link>
            <guid>38471004</guid>
            <pubDate>Thu, 30 Nov 2023 08:10:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://daniel.haxx.se/blog/2023/11/30/xcurl/">https://daniel.haxx.se/blog/2023/11/30/xcurl/</a>, See on <a href="https://news.ycombinator.com/item?id=38471004">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<p>It is often said that <em>Imitation is the Sincerest Form of Flattery</em>.</p>



<p>Also, remember <a href="https://daniel.haxx.se/blog/2019/06/19/google-to-reimplement-curl-in-libcrurl/" data-type="post" data-id="12576">libcrurl</a>? That was the name of the thing Google once planned to do:  reimplement the libcurl API on top of their Chrome networking library. Flattery or not, it never went anywhere.</p>



<p>The other day I received an email asking me about details regarding something called <strong>xCurl</strong>. Not having a clue what that was, a quick search soon had me enlightened.</p>



<p>xCurl is, using <a href="https://learn.microsoft.com/en-us/gaming/gdk/_content/gc/networking/overviews/web-requests/intro-xcurl">their own words</a>, <em>a Microsoft Game Development Kit (GDK) compliant implementation of the libCurl API</em>.</p>



<h2>A Frankencurl</h2>



<p>The article I link to above describes how xCurl differs from libcurl: </p>



<blockquote>
<p>xCurl differs from libCurl in that xCurl is implemented on top of WinHttp and automatically follows all the extra Microsoft Game Development Kit (GDK) requirements and best practices. While libCurl itself doesn’t meet the security requirements for the Microsoft Game Development Kit (GDK) console platform, use xCurl to maintain your same libCurl HTTP implementation across all platforms while changing only one header include and library linkage.</p>
</blockquote>



<p>I don’t know anything about WinHttp, but since that is an HTTP API I can only presume that making libcurl use that instead of plain old sockets has to mean a pretty large surgery and code change. I also have no idea what the mentioned “security requirements” might be. I’m not very familiar with Windows internals nor with their game development setups.</p>



<p>The article then goes on to describe with some detail exactly which libcurl options that work, and which don’t and what libcurl build options that were used when xCurl was built. No DoH, no proxy support, no cookies etc.</p>



<p>The provided functionality is certainly a very stripped down and limited version of the libcurl API. A fun detail is that the quite bluntly just link to the <a href="https://curl.se/libcurl/c/">libcurl API documentation</a> to describe how xCurl works. It is easy and convenient of course, and it will certainly make xCurl “forced” to stick to the libcurl behavior</p>



<p>With large invasive changes of this kind we can certainly hope that the team making it has invested time and spent serious effort on additional testing, both before release and ongoing.</p>



<h2>Source code?</h2>



<p>I have not been able to figure out how to download xCurl in any form, and since I can’t find the source code I cannot really get a grip of exactly how much and how invasive Microsoft has patched this. They have not been in touch or communicated about this work of theirs to anyone in the curl project.</p>



<p>Therefore, I also cannot say which libcurl version this is based on – as there is no telling of that on the page describing xCurl.</p>



<p>The email that triggered me to crawl down this rabbit hole included a copyright file that seems to originate from an xCurl package, and that includes the curl license. The curl license file has the specific detail that it shows the copyright year range at the top and this file said </p>



<pre>Copyright (c) 1996 - 2020, Daniel Stenberg, daniel@haxx.se, and many contributors, see the THANKS file.</pre>



<p>It <em>might</em> indicate that they use a libcurl from a few years back. Only <em>might</em>, because it is quite common among users of libcurl to “forget” (sometimes I’m sure on purpose) to update this copyright range even when they otherwise upgrade the source code. This makes the year range a rather weak evidence of the actual age of the libcurl code this is based on.</p>



<h2>Updates</h2>



<p>curl (including libcurl) ships a new version <em>at least</em> once every eight weeks. We merge bugfixes at a rate of around three bugfixes <em>per day</em>. Keeping a heavily modified libcurl version in sync with the latest curl releases is hard work.</p>



<p>Of course, since they deliberately limit the scope of the functionality of their clone, lots of upstream changes in curl will not affect xCurl users.</p>



<h2>License</h2>



<p>curl is licensed under… <a href="https://curl.se/docs/copyright.html">the curl license</a>! It is an MIT license that I was unclever enough to slightly modify many years ago. The changes are enough for organizations such as SPDX to consider it a separate one: <a href="https://spdx.org/licenses/curl.html">curl</a>. I normally still say that curl is MIT licensed because the changes are minuscule and do not change the spirit of the license.</p>



<p>The curl license of course allows Microsoft or anyone else do to this kind of stunt and they don’t even have to provide the source code for their changes or the final product and they don’t have to ask or tell anyone:</p>



<p><em>Permission to use, copy, modify, and distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies.</em></p>



<p>I once picked this license for curl exactly because it allows this. Sure it might sometimes then make people do things in secret that they never contribute back, and we miss out on possible improvements because of that, but I think the more important property is that no company feels scared or restricted as to when and where they can use this code. A license designed for maximum adoption.</p>



<p>I have always had the belief that it is our relentless update scheme and never-ending flood of bugfixes that is what will keep users wanting to use the real thing and avoid maintaining long-running external patches. There will of course always be exceptions to that.</p>
	</div></div>]]></description>
        </item>
    </channel>
</rss>