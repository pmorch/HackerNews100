<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 15 Feb 2025 15:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Jane Street's Figgie card game (175 pts)]]></title>
            <link>https://www.figgie.com/</link>
            <guid>43057344</guid>
            <pubDate>Sat, 15 Feb 2025 09:59:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.figgie.com/">https://www.figgie.com/</a>, See on <a href="https://news.ycombinator.com/item?id=43057344">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <div>
          <p><img src="https://www.figgie.com/assets/bg_landing_gradient_v3.png" integrity="sha256-KIDzYXVnXwYtUaRwqdI3X1a0KmbxANhiYOfKYHrERzE=" crossorigin="anonymous" alt="background purple gradient">
          <img src="https://www.figgie.com/assets/mobile_bg_landing.png" integrity="sha256-ycXIq6jFkRAmLVjhQjBddRgqwWt90jWvj4CJvVtA5BE=" crossorigin="anonymous" alt="background purple gradient"></p>
          <p><img src="https://www.figgie.com/assets/chip_stacks.png" integrity="sha256-Potapdoin6UTxon5LxPves3OpDwEsYQZ6fyBm+shPuw=" crossorigin="anonymous" alt="stacks of poker chips">
            <img src="https://www.figgie.com/assets/chip_white.png" integrity="sha256-sK1dHjSkRAf/6yR2OiPQX93R9A+lG548E7QFq/LMsWA=" crossorigin="anonymous" alt="white poker chip">
            <img src="https://www.figgie.com/assets/chip_white.png" integrity="sha256-sK1dHjSkRAf/6yR2OiPQX93R9A+lG548E7QFq/LMsWA=" crossorigin="anonymous" alt="white poker chip">
            <img src="https://www.figgie.com/assets/chip_white.png" integrity="sha256-sK1dHjSkRAf/6yR2OiPQX93R9A+lG548E7QFq/LMsWA=" crossorigin="anonymous" alt="white poker chip">
            <img src="https://www.figgie.com/assets/chip_red.png" integrity="sha256-+ClW0DnkCG8ZNWRcXjMDqVU1GCgcL635ehqaTBCRxjo=" crossorigin="anonymous" alt="red poker chip">
            <img src="https://www.figgie.com/assets/chip_red.png" integrity="sha256-+ClW0DnkCG8ZNWRcXjMDqVU1GCgcL635ehqaTBCRxjo=" crossorigin="anonymous" alt="red poker chip">
            <img src="https://www.figgie.com/assets/chip_red.png" integrity="sha256-+ClW0DnkCG8ZNWRcXjMDqVU1GCgcL635ehqaTBCRxjo=" crossorigin="anonymous" alt="red poker chip">
            <img src="https://www.figgie.com/assets/chip_green.png" integrity="sha256-2DlfFIO+F9LueWLOL1jrgGMDbYPk93ncKUsM3Wggtgs=" crossorigin="anonymous" alt="green poker chip">
            <img src="https://www.figgie.com/assets/chip_green.png" integrity="sha256-2DlfFIO+F9LueWLOL1jrgGMDbYPk93ncKUsM3Wggtgs=" crossorigin="anonymous" alt="green poker chip">
            <img src="https://www.figgie.com/assets/chip_green.png" integrity="sha256-2DlfFIO+F9LueWLOL1jrgGMDbYPk93ncKUsM3Wggtgs=" crossorigin="anonymous" alt="green poker chip">
          </p>
          <p>
          <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Ffiggie.com%2F&amp;src=sdkpreparse" target="_blank">
            <img src="https://www.figgie.com/assets/Facebook_logo.png" integrity="sha256-A8y8L9J6pGbE6h22sdiwtf/UHf1YHNktQTDMVrAeasU=" crossorigin="anonymous" alt="Facebook logo">
          </a>
          <a href="https://www.janestreet.com/">
            <img src="https://www.figgie.com/assets/js_logo_white.png" integrity="sha256-YzUmP6ukInv1j+hOhnYJmF0Dae9wkYcxNxNdyLEmLY8=" crossorigin="anonymous" alt="Jane Street logo">
          </a></p><p><a href="https://apps.apple.com/us/app/figgie-by-jane-street/id6466661064" target="_blank">
              <img src="https://www.figgie.com/assets/apple-badge.png" integrity="sha256-y32xY72t8eN0Y/el0NaLsE20qGsw3ewegcfG+fBM3iY=" crossorigin="anonymous" alt="apple app store badge">
            </a>
            <a href="https://play.google.com/store/apps/details?id=com.janestreet.figgie" target="_blank">
              <img src="https://www.figgie.com/assets/google-play-badge.png" integrity="sha256-9yYR4t+OiCBACf2JbQXV6Og8dwCcY5Q7v/oWlVmTSEk=" crossorigin="anonymous" alt="google play store badge">
            </a>
          </p>
          <div>
            <p>
              <a href="https://www.janestreet.com/">Jane Street</a>'s fast-paced
              Figgie game simulates exciting elements of markets and trading. At
              Jane Street, Figgie is a game we teach and also one we really
              enjoy playing.
            </p>
            <p>
              <a href="https://www.figgie.com/how-to-play.html">Check out the rules</a>, then try your
              hand in learning mode.
            </p>
            <p>
              <a href="https://www.figgie.com/faqs.html">Read our FAQs</a>
              for more. If you have a question that isn’t answered there, we’d
              like to hear
              <a href="mailto:figgie@janestreet.com">what’s missing</a> and what
              would be helpful to know, and we’ll do our best to update FAQs
              along the way.
            </p>
          </div>
          <a href="https://www.janestreet.com/join-jane-street/"><p>APPLY TO JANE STREET</p></a>

          <a href="https://www.figgie.com/how-to-play.html"><p>LEARN FIGGIE</p></a>
        </div>
        
        <p><img src="https://www.figgie.com/assets/cards_scatter_lg_v3.png" integrity="sha256-45aelEHRxPQUTzkdVEPuDQeo8dCNECIDViXKuKT1EaY=" crossorigin="anonymous" alt="cards scattered">
        <img src="https://www.figgie.com/assets/cards_scatter_mobile_v2.png" integrity="sha256-4VwWiH4OgtI7iRhuUNWgnICZUJoArmmFS8rGxqSOAEI=" crossorigin="anonymous" alt="cards scattered"></p>

        

        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[If you believe in "Artificial Intelligence", take five minutes to ask it (119 pts)]]></title>
            <link>https://svpow.com/2025/02/14/if-you-believe-in-artificial-intelligence-take-five-minutes-to-ask-it-about-stuff-you-know-well/</link>
            <guid>43056831</guid>
            <pubDate>Sat, 15 Feb 2025 08:15:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://svpow.com/2025/02/14/if-you-believe-in-artificial-intelligence-take-five-minutes-to-ask-it-about-stuff-you-know-well/">https://svpow.com/2025/02/14/if-you-believe-in-artificial-intelligence-take-five-minutes-to-ask-it-about-stuff-you-know-well/</a>, See on <a href="https://news.ycombinator.com/item?id=43056831">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p>Here’s <a href="https://sauropods.win/@mike/111935967471427403">a Mastodon thread from a year ago</a>.</p>
<blockquote><p>Just a quick check on how ChatGPT’s getting on …</p>
<p><strong>Me</strong>: Who reassigned the species <em>Brachiosaurus brancai</em> to its own genus, and when?</p>
<p><strong>ChatGPT:</strong> The species <em>Brachiosaurus brancai</em> was reassigned to its own genus, <em>Giraffatitan</em>, by the paleontologist Michael Janensch in 1914.</p>
<p><strong>Me:</strong> Dude, that is so wrong I can’t even.</p>
<p><strong>ChatGPT</strong>: I apologize for the mistake in my previous response. The reassignment of <em>Brachiosaurus brancai</em> to <em>Giraffatitan brancai</em> was not done by Michael Janensch. The correct attribution goes to the paleontologist Ernst Stromer, who reclassified it in 1914.</p>
<p><strong>Me:</strong> That answer is even worse. Stromer had nothing to do with the genus name <em>or</em> species name.</p>
<p><strong>ChatGPT:</strong> I apologize for the confusion in my previous responses. The reassignment of <em>Brachiosaurus brancai</em> to <em>Giraffatitan brancai</em> was actually done by the paleontologist Werner Janensch, not Michael Janensch, in 1914.</p></blockquote>
<p><em>sigh</em></p>
<p>Regular readers will know that the actual sequence of events was:</p>
<ul>
<li>Riggs (1903) named the genus <em>Brachiosaurus</em> and its type species <em>Brachiosaurus altithorax</em>.</li>
<li>Janensch (1914) named a second species of this genus, “<em>Brachiosaurus”</em> <em>brancai</em>.</li>
<li>Paul (1988) considered the two species separate at the subgeneric level (a taxonomic level that is rarely if ever used in vertebrate palaeontology) and named the subgenus <em>Brachiosaurus</em> (<em>Giraffatitan</em>) <em>brancai</em>.</li>
<li>Olshevsky (1991) used the genus-and-species combination <em>Giraffatitan brancai</em> without comment in a self-published booklet, a combinaton which was not followed by any formal publication known to me, until …</li>
<li>Taylor (2009) demonstrated that numerous characters separate the two species and that <em>Giraffatitan</em> is a separate genus with type species <em>G</em>. <em>brancai</em>.</li>
</ul>
<p>Now, ChatGPT got <em>every single part of that</em> wrong. It left Riggs, Paul, Olshevsky and me out completely. It credited Werner Janensch for reassigning a species to a genus whose name was coined 19 years after he died. It pulled poor Ernst Stromer in for some reason. It invented “the paleontologist Michael Janensch”, who is presumably the unholy offspring of Werner Janensch and me. And in all three answers, it insisted that the reassignment was done in 1914, 74 years before the name <em>Giraffatitan</em> was coined.</p>
<p>But the worst part of this is not the errors. It’s not the blithe confidence with which the false facts are recited. It’s not even the bland “I apologize for the mistake in my previous response” to be followed by more utter nonsense. It’s that <em>these incorrect answers look so plausible</em>. For a lay-person — someone who, foolishly, has not been reading this blog for the last eighteen years — the answers given here look superficially reasonable. A kid doing a homework report on <em>Brachiosaurus</em> could take these answers and weave them into the submission without even having an inkling that they’re completely wrong. And the teacher who has to mark the essay will also likely swallow them.</p>
<p>Because LLMs get catastrophically wrong answers on topics I know well, I do not trust them <em>at all</em> on topics I don’t already know. And if you do trust them, I urge you to spend five minutes asking your favourite one about something you know in detail.</p>
<p>Why do I <a href="https://svpow.com/2023/01/15/these-new-artificial-intelligence-programs-dont-know-what-theyre-talking-about/">keep</a> <a href="https://svpow.com/2024/10/14/more-artificial-intelligence-idiocy/">banging on</a> <a href="https://svpow.com/2024/05/23/another-day-another-catastrophic-ai-failure/">about this</a>? Because we’ve reached an especially toxic phase in the history of AI. A lot of companies have ploughed billions of dollars into the dream of being able to replace human workers with machines, and they are desperate to make us believe it’s going to work — if only so they can cash out their investments while the stocks are still high. We’re in the “pump” phase of an industry-wide pump-and-dump. It would be wise for all to beware getting suckered in.</p>
<p>(<strong>Disclaimer</strong>: LLMs are useful for some classes of queries. I use them a lot to remind me of programming-language idioms, asking questions like “In Go, if I have an object satisfying the <strong>error</strong> interface, how can I determine which specific kind of error structure it is?”. They’re good for this because you can quickly determine whether the answer is correct or not, thanks to the merciless compiler. LLMs are not useless; they’re just way overhyped and misapplied.)</p>
<h2>References</h2>
<ul>
<li>Janensch, Werner. 1914. Ubersicht uber der Wirbeltierfauna der Tendaguru-Schichten nebst einer kurzen Charakterisierung der neu aufgefuhrten Arten von Sauropoden. <em>Archiv fur Biontologie</em>, Berlin, III, <strong>1</strong>(1):81-110.</li>
<li>Olshevsky, George. 1991. A Revision of the Parainfraclass Archosauria Cope, 1869, Excluding the Advanced Crocodylia. <em>Mesozoic Meanderings <a rel="tag" href="https://svpow.com/tag/2/">#2</a></em> (1st printing): iv + 196 pp.</li>
<li>Paul, Gregory S. 1988. The brachiosaur giants of the Morrison and Tendaguru with a description of a new subgenus, <em>Giraffatitan,</em> and a comparison of the world’s largest dinosaurs. <em>Hunteria</em> <strong>2</strong>(3):1-14.</li>
<li>Riggs, Elmer S. 1903. <em>Brachiosaurus altithorax</em>, the largest known dinosaur. <em>American Journal of Science</em> <strong>15</strong>(4):299-306.</li>
<li>Taylor, Michael P. 2009. A re-evaluation of <em>Brachiosaurus altithorax</em> Riggs 1903 (Dinosauria, Sauropoda) and its generic separation from <em>Giraffatitan brancai</em> (Janensch 1914). <em>Journal of Vertebrate Paleontology</em> <strong>29</strong>(3):787-806.</li>
</ul>

<hr>
<p><a href="https://doi.org/10.59350/e0s96-xyg36">doi:10.59350/e0s96-xyg36</a></p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bookshop.org launches Kindle alternative, sends e-book sales to local bookstores (133 pts)]]></title>
            <link>https://www.usatoday.com/story/entertainment/books/2025/01/28/bookshop-org-ereader-ebook-app/77928209007/</link>
            <guid>43056526</guid>
            <pubDate>Sat, 15 Feb 2025 07:05:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.usatoday.com/story/entertainment/books/2025/01/28/bookshop-org-ereader-ebook-app/77928209007/">https://www.usatoday.com/story/entertainment/books/2025/01/28/bookshop-org-ereader-ebook-app/77928209007/</a>, See on <a href="https://news.ycombinator.com/item?id=43056526">Hacker News</a></p>
Couldn't get https://www.usatoday.com/story/entertainment/books/2025/01/28/bookshop-org-ereader-ebook-app/77928209007/: Error: Request failed with status code 406]]></description>
        </item>
        <item>
            <title><![CDATA[The 20 year old PSP can now connect to WPA2 WiFi Networks (293 pts)]]></title>
            <link>https://wololo.net/2025/02/14/the-20-year-old-psp-can-now-connect-to-wpa2-wifi-networks/</link>
            <guid>43055671</guid>
            <pubDate>Sat, 15 Feb 2025 03:31:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wololo.net/2025/02/14/the-20-year-old-psp-can-now-connect-to-wpa2-wifi-networks/">https://wololo.net/2025/02/14/the-20-year-old-psp-can-now-connect-to-wpa2-wifi-networks/</a>, See on <a href="https://news.ycombinator.com/item?id=43055671">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>	
				<div>

<!--nok--><div id="attachment_49719"><p><img data-recalc-dims="1" fetchpriority="high" decoding="async" aria-describedby="caption-attachment-49719" src="https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/psp_wpa2_support.jpg?resize=848%2C477&amp;ssl=1" alt="" width="848" height="477" srcset="https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/psp_wpa2_support.jpg?w=848&amp;ssl=1 848w, https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/psp_wpa2_support.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/psp_wpa2_support.jpg?resize=768%2C432&amp;ssl=1 768w" sizes="(max-width: 848px) 100vw, 848px"></p><p id="caption-attachment-49719">Screenshot source: Zekiu_ on youtube</p></div>
<p><a href="https://wololo.net/tag/acid_snake">Acid_Snake</a> and the <a href="https://wololo.net/tag/ark-4/">ARK</a> Development team have released a significant update to the ARK custom Firmware for the Sony PSP. Custom Firmware now allows the Playstation Portable to connect to WPA2 encrypted Wifi networks. This is thanks to the recently released <em>wpa2psp</em> plugin, created by developer <strong>Moment</strong> and published on the PSP Homebrew discord.</p>
<h2>Playstation Portable gets WPA2 Wifi access</h2>
<p>The PSP has been out of official support from Sony for years, but lots of enthusiasts keep maintaining this great handheld through homebrew and custom Firmware updates. As technology evolves around us, older devices such as the PlayStation Portable can lose some of their features.</p>
<p>For example, as WPA2 has become the defacto encryption standard for home wifi networks (WPA3’s adoption rate remains low), older devices such as the PSP, that do not support these new* encryption standards become technically unable to access the internet.</p>
<p>Wifi access was a very strong feature of the PSP when it was released, and, although it’s probably less important nowadays, losing that feature because newer networks aren’t compatible is a bummer.</p>
<p>WPA2 support has been a request by many enthusiasts for years on PSP discussion channels, and it seems that the wpa2psp plugin by developer Moment now brings this to life. According to Acid_Snake, the developer was kind enough to provide the source code of the plugin, which allowed the ARK team to embed it into the ARK Custom Firmware for PSP.</p>
<div id="attachment_49720"><p><img data-recalc-dims="1" decoding="async" aria-describedby="caption-attachment-49720" src="https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/moment_wpa2psp_release.png?resize=1024%2C321&amp;ssl=1" alt="" width="1024" height="321" srcset="https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/moment_wpa2psp_release.png?resize=1024%2C321&amp;ssl=1 1024w, https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/moment_wpa2psp_release.png?resize=300%2C94&amp;ssl=1 300w, https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/moment_wpa2psp_release.png?resize=768%2C241&amp;ssl=1 768w, https://i0.wp.com/wololo.net/wagic/wp-content/uploads/2025/02/moment_wpa2psp_release.png?w=1124&amp;ssl=1 1124w" sizes="(max-width: 1000px) 100vw, 1000px"></p><p id="caption-attachment-49720">History was made</p></div>
<h2>WPA2PSP&nbsp; limitations</h2>
<p><a href="https://www.reddit.com/r/psphacks/comments/1iimnft/wpa2_now_works_on_psp_thanks_to_a_new_plugin/">This reddit thread</a> by Nebula_NL covers a lot of details on how to install and use the plugin. But the bottom line is: install the latest release of the ARK CFW on your PSP, and take it from there. (Note that you can also manually install the plugin if you’re using another CFW than ARK)</p>
<p>This is of course the first iteration of this plugin, and it comes with limitations, specifically:</p>
<ul>
<li>2.4 GHz Only
<ul>
<li>WPA2 support works with 2.4 GHz WiFi.</li>
<li>If your router uses a single SSID for both 2.4 GHz and 5 GHz, you may need to separate them and connect your PSP to the 2.4 GHz network.</li>
</ul>
</li>
<li>WPA2 AES Only
<ul>
<li>Requires WPA2 with AES (AES-CCMP) encryption.</li>
<li>TKIP is not supported and will not work.</li>
</ul>
</li>
<li>WEP/WPA Compatibility
<ul>
<li>While WPA2 is active, WEP and WPA encryption will not work.</li>
<li>To use WEP or WPA again, disable WPA2, and they will function normally.</li>
</ul>
</li>
<li>WPA2/WPA3 Mixed Mode
<ul>
<li>If your router is set to WPA2/WPA3 mixed mode, your PSP may struggle to obtain an IP address.</li>
<li>Try manually setting the IP address instead of using DHCP in [AUTO] mode.</li>
</ul>
</li>
</ul>
<h2>Download and install ARK-4 + enable WPA2 Support for the PSP</h2>
<ol>
<li>Download the <a href="https://github.com/PSP-Archive/ARK-4/releases">latest release from the ARK4 Github releases page</a>. (alternatively, <a href="https://github.com/PSP-Archive/ARK-4/releases/tag/rev160">this specific release</a> introduced the wpa2psp plugin)</li>
<li>Copy the <code>UPDATE</code> folder from the ARK4 archive to <code>/PSP/GAME/</code>.</li>
<li>Run ARK4 Updater on your PSP from the GAME menu.</li>
<li>Go to Extras &gt; Custom Firmware Settings and enable WPA2.</li>
<li>Reboot VSH/PSP and connect to your WPA2 Wifi network.</li>
<li>Done!</li>
</ol>
<p><em>* WPA2 was certified in 2004… It’s “new” from the PSP’s perspective which launched the same year and didn’t “need” to support it at the time. WPA3 launched in 2018 but its adoption is taking time</em></p>



													</div><!--/.post-inner-->	
			</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Q2DOS – Quake 2 backported to MS-DOS (107 pts)]]></title>
            <link>https://dk.toastednet.org/Q2DOS/</link>
            <guid>43054963</guid>
            <pubDate>Sat, 15 Feb 2025 01:32:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dk.toastednet.org/Q2DOS/">https://dk.toastednet.org/Q2DOS/</a>, See on <a href="https://news.ycombinator.com/item?id=43054963">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <p><span size="6"><b><img src="https://dk.toastednet.org/Q2DOS/images/hover2.gif" alt="Icarus" width="80" height="84"><span color="#00FF00">Quake II for MS-DOS</span> </b> </span>
    <img src="https://dk.toastednet.org/Q2DOS/images/berserk2.gif" alt="Berserker" width="80" height="84"></p>
  <p>Brought to you by <a href="http://superglobalmegacorp.com/" target="_blank">neozeed</a>, <a href="http://dk.toastednet.org/" target="_blank">[HCI]Mara'akate</a>, and <a href="http://uhexen2.sourceforge.net/" target="_blank">sezero</a>.</p>
  <p>Features:</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Men claiming to be from DOGE show up at San Francisco City Hall, demand records (101 pts)]]></title>
            <link>https://www.cbsnews.com/sanfrancisco/news/doge-3-men-show-up-at-sf-city-hall-demand-records/</link>
            <guid>43054892</guid>
            <pubDate>Sat, 15 Feb 2025 01:19:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cbsnews.com/sanfrancisco/news/doge-3-men-show-up-at-sf-city-hall-demand-records/">https://www.cbsnews.com/sanfrancisco/news/doge-3-men-show-up-at-sf-city-hall-demand-records/</a>, See on <a href="https://news.ycombinator.com/item?id=43054892">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    
                                                                
                                                        
<article id="article-0" data-index="0" data-path="/sanfrancisco/news/doge-3-men-show-up-at-sf-city-hall-demand-records/">

  <div id="article-header" data-sort-time="1739587078000" data-update-time="1739587078000">
    <header>

      
      <div>

        <!-- show SVG here -->
                            <p><a href="https://www.cbsnews.com/sanfrancisco/" data-invalid-url-rewritten-http="">
            <img width="60" height="60" alt="sanfrancisco" src="https://www.cbsnews.com/assets/show/sanfrancisco/logo-square-32.svg" loading="lazy"></a></p><!-- end show SVG -->

              
  
          

        <p>
          <time datetime="2025-02-14T16:47:03-0800">Updated on:  February 14, 2025 / 4:47 PM PST</time>
          / CBS San Francisco
        </p>
        


</div>

          </header></div>

      




  
  
      
        
  <figure data-ads="{&quot;extraWordCount&quot;:50}"><div>
      
      
                      



  <svg xmlns="http://www.w3.org/2000/svg" style="position:absolute;width:0;height:0"><defs><symbol id="player-icon-pause" viewBox="0 0 32 32"><path d="M4 4h10v24h-10zM18 4h10v24h-10z"></path></symbol><symbol id="player-icon-play" viewBox="0 0 32 32"><path d="M6 4l20 12-20 12z"></path></symbol><symbol id="player-icon-close" viewBox="0 0 32 32"><line stroke-width="6" x1="3" y1="3" x2="29" y2="29"></line><line stroke-width="6" x1="29" y1="3" x2="3" y2="29"></line></symbol><symbol id="player-icon-fullscreen" viewBox="0 0 32 32"><path d="M32 0h-13l5 5-6 6 3 3 6-6 5 5z"></path><path d="M32 32v-13l-5 5-6-6-3 3 6 6-5 5z"></path><path d="M0 32h13l-5-5 6-6-3-3-6 6-5-5z"></path><path d="M0 0v13l5-5 6 6 3-3-6-6 5-5z"></path></symbol><symbol id="player-icon-drag" viewBox="0 0 40 55"><g fill="#f5f5f5"><circle cx="5" cy="5" r="5"></circle><circle cx="20" cy="5" r="5"></circle><circle cx="35" cy="5" r="5"></circle><circle cx="5" cy="20" r="5"></circle><circle cx="20" cy="20" r="5"></circle><circle cx="35" cy="20" r="5"></circle><circle cx="5" cy="35" r="5"></circle><circle cx="20" cy="35" r="5"></circle><circle cx="35" cy="35" r="5"></circle><circle cx="5" cy="50" r="5"></circle><circle cx="20" cy="50" r="5"></circle><circle cx="35" cy="50" r="5"></circle></g></symbol></defs></svg><div data-theme="default" data-component="viewability" data-viewability-options="true">
                  <svg><use xlink:href="#player-icon-drag"></use></svg><p><span>Trump orders agencies to comply with DOGE during White House meeting with Elon Musk </span>
        
        

      </p></div>
          </div>
          <figcaption><a href="https://www.cbsnews.com/sanfrancisco/video/trump-orders-agencies-to-comply-with-doge-during-white-house-meeting-with-elon-musk/" data-invalid-url-rewritten-http="">
          
          <span>
            </span>

          <span>Trump orders agencies to comply with DOGE during White House meeting with Elon Musk</span>

          <span>07:50</span>

                      </a>
                  
        
        
              </figcaption></figure><section><p>San Francisco city officials are investigating after three men who claimed to be from the Department of Government Efficiency (DOGE) showed up at City Hall on Friday demanding records from offices before fleeing.</p><p>According to the San Francisco Sheriff's Office, the men, who were dressed in "DOGE" shirts and hats with the pro-Trump slogan Make America Great Again, arrived at City Hall around noon. The men entered several offices and demanded employees turn over digital information "related to alleged wasteful government spending and fraud."</p><figure data-require="third-party/twitter-widgets"><div>
    <blockquote><p lang="en" dir="ltr">Around 12pm today, three men dressed in DOGE shirts and MAGA hats entered various offices at San Francisco City Hall, demanding that employees turn over digital information related to alleged wasteful government spending and fraud. The employees refused their requests, and called… <a href="https://t.co/bCtsNlgL7U" rel="nofollow noopener">pic.twitter.com/bCtsNlgL7U</a></p>— SF Sheriff's Office (@SheriffSF) <a href="https://twitter.com/SheriffSF/status/1890536307950317845?ref_src=twsrc%5Etfw" rel="nofollow noopener">February 14, 2025</a></blockquote>


  </div>
</figure><p>In response, the employees refused their requests and called sheriff's deputies. The men had left City Hall before deputies arrived.</p><p>"We do not believe the individuals requesting access to City files were representatives from DOGE," <a href="https://x.com/SheriffSF/status/1890536307950317845" target="_blank" rel="nofollow noopener">the sheriff's office said Friday</a>.</p><p>Deputies said they are reviewing surveillance footage and using other investigative tools to pursue leads.</p>

    

<p>Led by billionaire Elon Musk, <span><a href="https://www.cbsnews.com/news/what-is-doge-elon-musk-findings-trump/" target="_blank" data-invalid-url-rewritten-http="">DOGE was created by President Trump through an executive order</a></span> he signed shortly after his inauguration, with its mission to slash federal spending.</p><p>According to social media posts from the task force and Musk, DOGE is seeking to identify federal contracts and spending on issues that don't align with Mr. Trump's policies, including DEI and foreign aid. </p><p>The task force has also attracted lawsuits, claiming it has violated the law. California Attorney General Rob Bonta was <span><a href="https://www.cbsnews.com/minnesota/news/state-attorneys-general-challenge-musk-doge/" target="_blank" data-invalid-url-rewritten-http="">among 14 attorneys general who filed a lawsuit on Thursday</a></span> challenging Musk and DOGE's authority to access sensitive government data.</p><p>"DOGE's ransacking of federal agencies has sown tremendous chaos, instilled distrust among the American people, and has caused deep harm to our country," <a href="https://oag.ca.gov/news/press-releases/attorney-general-bonta-sues-trump-administration-challenging-elon-musk%E2%80%99s" target="_blank" rel="nofollow noopener">Bonta said in a statement</a>. "Like a bull in a china shop, Mr. Musk is wielding an enormous amount of illegitimized power over sensitive systems and important government programs that are vital to the American way of life."</p>

      

                  
        
      
                  
    <!-- data-recirc-source="queryly" -->

    <!-- tags --><ul>In:
          <li><a href="https://www.cbsnews.com/sanfrancisco/tag/doge/">DOGE</a></li>
          <li><a href="https://www.cbsnews.com/sanfrancisco/tag/elon-musk/">Elon Musk</a></li>
          <li><a href="https://www.cbsnews.com/sanfrancisco/tag/donald-trump/">Donald Trump</a></li>
          <li><a href="https://www.cbsnews.com/sanfrancisco/tag/san-francisco/">San Francisco</a></li>
      </ul><div>
      <p><a href="https://www.cbsnews.com/team/tim-fang/" data-invalid-url-rewritten-http="">Tim Fang</a></p><div>
            <p>Tim Fang is a digital producer at CBS Bay Area. A Bay Area native, Tim has been a part of the CBS Bay Area newsroom for more than two decades and joined the digital staff in 2006.</p>
                          
                </div>
    </div>
        </section>
  </article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Did Semgrep Just Get a Lot More Interesting? (120 pts)]]></title>
            <link>https://fly.io/blog/semgrep-but-for-real-now/</link>
            <guid>43054673</guid>
            <pubDate>Sat, 15 Feb 2025 00:40:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fly.io/blog/semgrep-but-for-real-now/">https://fly.io/blog/semgrep-but-for-real-now/</a>, See on <a href="https://news.ycombinator.com/item?id=43054673">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
         <dl>
             <dt>Author</dt>
             <dd>
                 <img alt="Thomas Ptacek" src="https://fly.io/static/images/thomas.webp">
               <dl>
                 <dt>Name</dt>
                 <dd>
                   Thomas Ptacek
                 </dd>
                  <dt>@tqbf</dt>
                  <dd>
                    <a href="https://twitter.com/tqbf" target="_blank">
                      @tqbf
                    </a>
                  </dd>
               </dl>
             </dd>
         </dl>

        <section>
            <figure>
                <img src="https://fly.io/blog/semgrep-but-for-real-now/assets/ci-cd-cover.webp" alt="">
                <figcaption>
                  <span>Image by</span>
                  
<svg role="img" style="pointer-events: none; width: 17px; height: 17px;" viewBox="0 0 20 20" fill="currentColor" fill-rule="evenodd">
  <g buffered-rendering="static">
    <path fill-rule="evenodd" d="M1 8a2 2 0 012-2h.93a2 2 0 001.664-.89l.812-1.22A2 2 0 018.07 3h3.86a2 2 0 011.664.89l.812 1.22A2 2 0 0016.07 6H17a2 2 0 012 2v7a2 2 0 01-2 2H3a2 2 0 01-2-2V8zm13.5 3a4.5 4.5 0 11-9 0 4.5 4.5 0 019 0zM10 14a3 3 0 100-6 3 3 0 000 6z" clip-rule="evenodd"></path>
  </g>
</svg>

                    <a href="https://annieruygtillustration.com/" target="_blank">
                      Annie Ruygt
                    </a>
                </figcaption>
            </figure>
          
<p><a href="https://ghuntley.com/stdlib/" title="">This bit by Geoffrey Huntley</a> is super interesting to me and, despite calling out that LLM-driven development agents like Cursor have something like a 40% success rate at actually building anything that passes acceptance criteria, makes me think that more of the future of our field belongs to people who figure out how to use this weird bags of model weights than any of us are comfortable with. </p>

<p>I’ve been dinking around with Cursor for a week now (if you haven’t, I think it’s something close to malpractice not to at least take it — or something like it — for a spin) and am just now from this post learning that Cursor has this <a href="https://docs.cursor.com/context/rules-for-ai" title="">rules feature</a>. </p>

<p>The important thing for me is not how Cursor rules work, but rather how Huntley uses them. He turns them back on themselves, writing rules to tell Cursor how to organize the rules, and then teach Cursor how to write (under human supervision) its own rules.</p>

<p>Cursor kept trying to get Huntley to use Bazel as a build system. So he had cursor write a rule for itself: “no bazel”. And there was no more Bazel. If I’d known I could do this, I probably wouldn’t have bounced from the Elixir project I had Cursor doing, where trying to get it to write simple unit tests got it all tangled up trying to make <a href="https://hexdocs.pm/mox/Mox.html" title="">Mox</a> work. </p>

<p>But I’m burying the lead. </p>

<p>Security people have been for several years now somewhat in love with a tool called <a href="https://github.com/semgrep/semgrep" title="">Semgrep</a>. Semgrep is a semantics-aware code search tool; using symbolic variable placeholders and otherwise ordinary code, you can write rules to match pretty much arbitary expressions and control flow. </p>

<p>If you’re an appsec person, where you obviously go with this is: you build a library of Semgrep searches for well-known vulnerability patterns (or, if you’re like us at Fly.io, you work out how to get Semgrep to catch the Rust concurrency footgun of RWLocks inside if-lets).</p>

<p>The reality for most teams though is “ain’t nobody got time for that”. </p>

<p>But I just checked and, unsurprisingly, 4o <a href="https://chatgpt.com/share/67aa94a7-ea3c-8012-845c-6c9491b33fe4" title="">seems to do reasonably well</a> at generating Semgrep rules? Like: I have no idea if this rule is actually any good. But it looks like a Semgrep rule?</p>

<p>What interests me is this: it seems obvious that we’re going to do more and more “closed-loop” LLM agent code generation stuff. By “closed loop”, I mean that the thingy that generates code is going to get to run the code and watch what happens when it’s interacted with. You’re just a small bit of glue code and a lot of system prompting away from building something like that right now: <a href="https://x.com/chris_mccord/status/1882839014845374683" title="">Chris McCord is building</a> a thingy that generates whole Elixir/Phoenix apps and runs them as Fly Machines. When you deploy these kinds of things, the LLM gets to see the errors when the code is run, and it can just go fix them. It also gets to see errors and exceptions in the logs when you hit a page on the app, and it can just go fix them.</p>

<p>With a bit more system prompting, you can get an LLM to try to generalize out from exceptions it fixes and generate unit test coverage for them. </p>

<p>With a little bit more system prompting, you can probably get an LLM to (1) generate a Semgrep rule for the generalized bug it caught, (2) test the Semgrep rule with a positive/negative control, (3) save the rule, (4) test the whole codebase with Semgrep for that rule, and (5) fix anything it finds that way. </p>

<p>That is a lot more interesting to me than tediously (and probably badly) trying to predict everything that will go wrong in my codebase a priori and Semgrepping for them. Which is to say: Semgrep — which I have always liked — is maybe a lot more interesting now? And tools like it?</p>

          
        </section>
        <dl>
            <dt>
              Next post  ↑
            </dt>
            <dd>
              <a href="https://fly.io/blog/the-exit-interview-jp/">
                The Exit Interview: JP Phillips
              </a>
            </dd>
            <dt>
              Previous post  ↓
            </dt>
            <dd>
              <a href="https://fly.io/blog/a-blog-if-kept/">
                A Blog, If You Can Keep It
              </a>
            </dd>
        </dl>
      </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wyden Releases Draft Bill to Secure Americans' Communications (115 pts)]]></title>
            <link>https://www.wyden.senate.gov/news/press-releases/wyden-releases-draft-bill-to-secure-americans-communications-against-foreign-surveillance-demands</link>
            <guid>43054632</guid>
            <pubDate>Sat, 15 Feb 2025 00:33:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wyden.senate.gov/news/press-releases/wyden-releases-draft-bill-to-secure-americans-communications-against-foreign-surveillance-demands">https://www.wyden.senate.gov/news/press-releases/wyden-releases-draft-bill-to-secure-americans-communications-against-foreign-surveillance-demands</a>, See on <a href="https://news.ycombinator.com/item?id=43054632">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main_column">
	
	<div id="press">
		
		
			
			<p><span>February 14, 2025</span></p>
			
				

	



	

	

	

	 
	

	

			


		








	

	

	

	

	


		

		
		
		
		
		
		
		
		
		

		
		
			
		

        
				<h2>Bill Fixes Loopholes in Flawed U.S. Law Used to Demand Apple Build Backdoors for iCloud Accounts, Putting Americans’ Security at Risk</h2>
			
			<p><strong><em>Washington, D.C.</em></strong> – U.S. Senator Ron Wyden, D-Ore., today released a discussion draft of the Global Trust in American Online Services Act to secure Americans’ communications against abusive foreign demands to weaken the security of communications services and software used by Americans.</p>
<p>The bill reforms the CLOUD Act, which permits foreign governments to make surveillance demands directly of U.S. companies rather than going through the U.S. legal system.</p>
<p><strong>“Foreign governments shouldn’t get a cheat code to undermine the security of American technology,”</strong> Wyden said.<strong> “My bill would fix the loopholes in the CLOUD Act, and modernize the law so American allies can request the information they need to investigate serious crimes without sacrificing the security of Americans’ communications services.” </strong></p>
<p><a href="https://www.washingtonpost.com/technology/2025/02/07/apple-encryption-backdoor-uk/">According to news reports</a>, the United Kingdom issued a secret order to Apple last month, directing the company to weaken the encryption protecting its iCloud backup service. The U.K. was apparently able to secretly issue the order to Apple, rather than seeking assistance from the Department of Justice (DOJ) because of the CLOUD Act. Wyden and Representative Andy Biggs, R-Ariz., <a href="https://www.wyden.senate.gov/news/press-releases/wyden-and-biggs-urge-new-intel-chief-gabbard-to-protect-americans-communications-from-foreign-surveillance">urged Director of National Intelligence Tulsi Gabbard</a> to demand the U.K. withdraw its order in a letter on Thursday.</p>
<p>The CLOUD Act, enacted in 2018, enables foreign countries to obtain data directly from U.S. firms, bypassing the U.S. legal system once they enter into an agreement with the Justice Department. However, the CLOUD Act failed to require foreign countries to adopt the same due process requirements long guaranteed under U.S. law, enabling foreign governments to demand that U.S. technology companies weaken the security of products used by Americans and putting global trust in U.S. firms at risk.</p>
<p>The Global Trust in American Online Services Act addresses serious flaws in the CLOUD Act, to ensure that U.S. technology companies can continue to maintain the trust of their international customers, and that the U.S. can compete globally as a safe place for data. The legislation would:</p>
<ul type="disc">
<li>Prevent foreign governments from using the CLOUD Act to require U.S. providers to adopt specific designs for products, reduce the security of a product, or deliver malware to a customer.</li>
<li>Allow U.S. providers to challenge foreign CLOUD Act orders in U.S. federal court.</li>
<li>Require Congressional approval of CLOUD Act agreements rather than the current disapproval mechanism, and enable oversight by requiring that each agreement sunset after five years rather than lasting indefinitely.</li>
</ul>
<p>The draft bill is available <a href="https://www.wyden.senate.gov/download/the-global-trust-in-american-online-services-actpdf">here</a>. A one-page summary of the bill is available <a href="https://www.wyden.senate.gov/download/the-global-trust-in-american-online-services-act-one-pager-2-12-2025pdf">here</a>.</p>
<p>###</p>
			
			
			
		

		
	</div>
	<hr>
<div id="pagetools">
	

	

	
	
	<ul id="actions">

		
			<li><a onclick="window.print()">Print</a></li>
		
		
			
			<li><a href="mailto:?subject=A%20Link%20From%20Senator%20Ron%20Wyden&amp;body=http://www.wyden.senate.gov/news/press-releases/wyden-releases-draft-bill-to-secure-americans-communications-against-foreign-surveillance-demands">Email</a></li>
		
		
			<li id="fb-li">
				
			</li>
		
		
		
			<li id="twitter-li">
				
			</li>
		
	</ul>

	

	
</div>




	
	



	
	
	



    
	
	


    
    
    
    	
    	
	    	<hr>
		    
		    
		    	<p><a href="https://www.wyden.senate.gov/news/press-releases/merkley-wyden-raise-the-alarm-over-nih-funding-cuts-that-derail-lifesaving-research-cost-lives-and-jobs-in-oregon">Previous Article</a>
		    
    	
    
	</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A decade later, a decade lost (428 pts)]]></title>
            <link>https://meyerweb.com/eric/thoughts/2024/06/07/a-decade-later-a-decade-lost/</link>
            <guid>43054069</guid>
            <pubDate>Fri, 14 Feb 2025 23:10:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://meyerweb.com/eric/thoughts/2024/06/07/a-decade-later-a-decade-lost/">https://meyerweb.com/eric/thoughts/2024/06/07/a-decade-later-a-decade-lost/</a>, See on <a href="https://news.ycombinator.com/item?id=43054069">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>I woke up this morning about an hour ahead of my alarm, the sky already light, birds calling.&nbsp; After a few minutes, a brief patter of rain swept across the roof and moved on.</p>

<p>I just lay there, not really thinking.&nbsp; Feeling.&nbsp; Remembering.</p>

<p>Almost sixteen years to the minute before I awoke, my second daughter was born.&nbsp; Almost ten years to the same minute before, she’d turned six years old, already semi-unconscious, and died not quite twelve hours later.</p>

<p>So she won’t be taking her first solo car drive today.&nbsp; She won’t be celebrating with dinner at her favorite restaurant in the whole world.&nbsp; She won’t kiss her niece good night or affectionately rag on her siblings.</p>

<p>Or maybe she wouldn’t have done any of those things anyway, after a decade of growth and changes and paths taken.&nbsp; What would she really be like, at sixteen?</p>

<p>We will never know.&nbsp; We can’t even guess.&nbsp; All of that, everything she might have been, is lost.</p>

<p>This afternoon, we’ll visit Rebecca’s grave, and then go to hear her name read in remembrance at one of her very happiest places, <a href="https://en.wikipedia.org/wiki/Anshe_Chesed_Fairmount_Temple">Anshe Chesed Fairmount Temple</a>, for the last time.&nbsp; At the end of the month, the temple will close as part of a merger.&nbsp; Another loss.</p>

<p>A decade ago, I said that I felt the weight of all the years she would never have, and that they might crush me.&nbsp; Over time, I have come to realize all the things she never saw or did adds to that weight.&nbsp; Even though it seems like it should be the same weight.&nbsp; Somehow, it isn’t.</p>

<p>I was talking about all of this with a therapist a few days ago, about the time and the losses and their accumulated weight.&nbsp; I said, “I don’t know how to be okay when I failed my child in the most fundamental way possible.”</p>

<p>“You didn’t fail her,” they said gently.</p>

<p>“I know that,” I replied. “But I don’t feel it.”</p>

<p>A decade, it turns out, does not change that.&nbsp; I’m not sure now that any stretch of time ever could.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[If you ever stacked cups in gym class, blame my dad (246 pts)]]></title>
            <link>https://defector.com/if-you-ever-stacked-cups-in-gym-class-blame-my-dad</link>
            <guid>43053908</guid>
            <pubDate>Fri, 14 Feb 2025 22:45:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://defector.com/if-you-ever-stacked-cups-in-gym-class-blame-my-dad">https://defector.com/if-you-ever-stacked-cups-in-gym-class-blame-my-dad</a>, See on <a href="https://news.ycombinator.com/item?id=43053908">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The boxes came from Tokyo: first by tanker, then overland via container truck from a Pacific port, across the Continental Divide, and finally backed into a driveway at the end of a cul-de-sac in a south Denver suburban enclave. This was a neighborhood with Razor scooters dumped in trimmed front lawns. Where family walks with leashed dogs happened down the middle of intentionally curved streets named after long demolished natural landmarks like "Timbercrest" and "Forest Trails." Where the HOA (because of course there was an HOA) banned the installation of driveway basketball hoops.</p><p>Receiving industrial freight deliveries, freshly cleared through international customs, probably wasn't explicitly prohibited in the homeowner's handbook. But then, why would it need to be? Nobody would think to bring that kind of commercial chaos into the burgeoning middle-class peace of Castle Pines North in 1998.</p><p>If neighbors peeking behind curtains at the idling 18-wheeler thought to call in a complaint, the husband and wife receiving the delivery didn't notice. They were too busy unloading boxes—more than 800 of them.&nbsp;</p><p>Balancing four at a time on a handcart, it took 200 trips through the open garage door and down the unfinished basement steps. The boxes, holding smaller rectangular packages inscribed with Japanese lettering, were piled to the ceiling. There was enough room left for a skinny aisle leading back up the stairs, and two plastic tables ladened with tape and flat-rate USPS packaging.&nbsp;</p><p>5,800 miles away, a man in middle management at the global toy conglomerate Hasbro must have been very pleased. The delivery represented a small yet unexpected boon.&nbsp;</p><p>Those boxes were dead inventory, wasting space in a nondescript warehouse. They should have been headed for a landfill and a tax write-off. Instead, a Mr. Toshio Takiguchi brokered the export at a ¥1,300 per-unit cost. Not a tidy profit, but no longer a loss on the annual P&amp;L. The remains of a failed business decision disappeared across the ocean. It was a certain Mr. Fox's problem now.</p><p>That problem cost $43,000, a sum that represented the entire life savings of Mr. Fox and his wife, who at that point had been surviving on public-school salaries. Friends and family never really said it out loud, but they were certainly thinking it: <em>This was insane. What about the three kids and that mortgage?&nbsp;</em></p><p>The couple, though, never had a doubt.&nbsp;</p><p>"He always used to tell me, 'If I had 10,000 of these, I could sell them in a year,'" Mrs. Fox&nbsp;recalled, 27 years later.</p><p>That's the unabashed confidence you'd expect from any good entrepreneur, especially with the benefit of hindsight. But ask yourself this: Would you, watching this couple unload box after box into their bank-financed home, have bet on this man and his family's future if you knew exactly what he needed to sell?</p><p>Tucked inside those boxes, in nested columns of 12, were 120,000 plastic cups. They were turned upside down, each with a hole drilled through the middle of the base, rendering them useless in terms of a cup's normal, and really only, task.</p><p>The couple's future hinged on accomplishing what the world's second largest toy company could not: convincing thousands of kids that stacking these plastic cups in pre-determined patterns was … <em>fun</em>. More critically, the couple needed to convince the parents of those kids to actually buy these cups, despite not even being able to drink from them.&nbsp;</p><p>Mr. Takiguchi could breathe a sigh of relief. Mr. and Mrs. Fox had to get to work.</p><hr><div><figure><img src="https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/divider.png?w=710" alt="Three speed stacking cups in a row"></figure><div><blockquote><p><strong><em>The first thing you need to know about Bob Fox is that he used to be a clown</em></strong> ... <em><strong>The second thing you need to know about my dad is that he was a really, really good clown.&nbsp;</strong></em></p><span><blockquote></blockquote></span></blockquote></div></div><hr><p>Every few months, in different corners of the internet, someone asks a version of the same question: <em>Why did we all stack plastic cups in elementary school PE class?</em></p><p>You'll see it multiple times in the Reddit community<a href="https://www.reddit.com/r/Zillennials/comments/qmx0jx/anyone_else_remember_cup_speed_stacking/" target="_blank" rel="noreferrer noopener"> r/Zillenials,</a> or infrequently posted as a random musing on <a href="https://x.com/lincolnwjohnson/status/1129999148567019520" target="_blank" rel="noreferrer noopener">Twitter</a> and Facebook. In 2023, it was examined in a 25-minute YouTube video with 200,000 views titled, "<a href="https://www.youtube.com/watch?v=w-iSGG3uD6s" target="_blank" rel="noreferrer noopener">What happened to this strange early 2000s craze?</a>"</p><p>You might have even asked it yourself, perhaps after a few beers when a friend turned some Solo Cups upside down, activating one of your mid-aughts memories of sitting cross-legged on a linoleum gym floor, surrounded by the clatter of your classmates piling cups into pyramids.</p><p><a href="https://www.speedstacks.com/" target="_blank" rel="noreferrer noopener">Sport Stacking</a>, as it's officially known (cup stacking and speed stacking as it is colloquially known), exists in the same cloud of millennial nostalgia where you'll find vague recollections of SlamBall and JoJo. It has appeared on pretty much every morning and late show, been a trend piece in both the <a href="https://www.nytimes.com/2016/04/01/sports/sport-stacking-speed-cups.html" target="_blank" rel="noreferrer noopener"><em>New York Times</em></a> and <a href="https://www.wsj.com/articles/SB124044351073445491" target="_blank" rel="noreferrer noopener"><em>Wall Street Journal</em></a>, and was once labeled by Glenn Beck as "<a href="https://www.foxnews.com/story/glenn-beck-why-health-care-reform-is-like-cup-stacking" target="_blank" rel="noreferrer noopener">what’s really wrong with America</a>."</p><p>It has been a minor plot line in <em>Fred Claus</em>, Matt LeBlanc's <em>Episodes</em>, and <em>Weeds</em>; it's been the major plot line in a 2022 Thai-language film released on Netflix titled <a href="https://www.imdb.com/title/tt18357588/" target="_blank" rel="noreferrer noopener"><em>Fast &amp; Feel Love</em></a> (100 percent on Rotten Tomatoes). The infamous "Oh my gosh!" scream in Skrillex's "Scary Monsters and Nice Sprites" was sampled from a <a href="https://www.youtube.com/watch?v=j54yGxuk0yo&amp;t=1s" target="_blank" rel="noreferrer noopener">viral sport stacking video</a> from 2008.</p><p>At its peak, between 2002 and 2011, roughly 5,000 American schools included it as part of their annual curriculum, according to Mr. and Mrs. Fox. That means somewhere between five and eight percent of U.S. adults between the ages of 22 and 35 share the same core memory—and in the ensuing years have asked themselves, their friends, or social media the same question: <em>Why did credentialed educational professionals make us do this ludicrous activity in gym class?</em></p><p>I am, perhaps, the person best suited on the planet to answer this question.&nbsp;Because the answer … is my dad.</p><p>The first thing you need to know about Bob Fox is that he used to be a clown. Not in the figurative, funnyman personality sense. In the literal red-nose, black-eyeliner, juggling-tennis-balls-at-children’s-birthday-parties sense.</p><p>The second thing you need to know about my dad is that he was a <em>really, really good clown</em>.&nbsp;</p><p>He'd scoff at the mental image you probably have of him right now: oversized shoes, cartoonish honks, and bumbling choreography. My dad's act was entirely silent, required immense skill, and was predicated on audience participation. He was equally good at riding a unicycle and convincing the most curmudgeonly dad in the room to leave their back corner and join him onstage to try—and always fail—at blowing up a balloon animal. Kids went bananas. Adults always laughed.&nbsp;</p><p>The San Francisco 49ers hired him to be the walk-around entertainment for their post–Super Bowl ring ceremony in 1995. We used to shut the shades so neighbors didn't think he robbed a bank as he counted the cash he earned during Denver's largest busking festival.</p><p>This was a man who took the unserious very, very seriously.&nbsp;</p><p>As a high school theater teacher, he'd spend 60–80 hours a week building out increasingly elaborate sets for the annual musical. He built a life-sized plant puppet that could actually eat cast members for <em>Little Shop of Horrors</em>, and cut a full-sized muscle car in half so it would fit on stage during <em>Grease</em>; another car was hoisted onto the school's roof to promote the show. Before her bevy of Oscar nominations, Amy Adams was one of his choreographers and students.</p><p>He quit because his wife, Jill, needed him home more to help raise their three children. So he became an elementary school classroom and PE teacher instead, where he would end up teaching hundreds of kids how to ride unicycles and produce an annual show on the blacktop basketball court called KidZircus.</p><p>The first thing you need to know about Jill Fox is that before working as a communications administrator at a school district, she used to be a journalist at a small newspaper, where she was assigned to write a profile about a local clown on "sabbatical" from his full-time job.&nbsp;</p><p>The second thing you need to know about Jill Fox is that despite the word "sabbatical" doing a generous amount of euphemistic work in her final published piece, she married that unemployed clown.</p><p>This was a woman who was very, very good at seeing—and supporting—the potential in the crazy.</p><hr><div><figure><img src="https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/divider.png?w=710" alt="Three speed stacking cups in a row"></figure><div><blockquote><p><strong><em>They had to figure out how to tap into the supply chain of global toy conglomerates. Fortunately, they had a guy: Uncle Johnny.</em></strong></p><span><blockquote></blockquote></span></blockquote></div></div><hr><p>It took them 10 months to sell the 10,000 sets of 12 cups.&nbsp;</p><p>Kids in south Denver, it turns out, went absolutely nuts over this new phenomenon called "cup stacking." That's mostly because my dad figured out the one thing Hasbro did not: The level of interest in the activity hinged almost exclusively on the enthusiasm and skill level of a real-life teacher. Without that, it was just inanimate plastic ephemera sitting on a shelf.</p><p>The basic rules take about 15 minutes to learn. Like a track meet, the sport is built on completing different "distances" as fast as you can. The shortest, and simplest, is called the 3-3-3. Envision each one of those 3's as a nested column of cups. You start on one side and "upstack" the first 3 into a pyramid, then move to the middle, and then the last 3. Then you return to where you started, and "downstack" them back into columns in the same order. The 3-6-3 has the same principle, but with a pyramid of six cups in the middle. The "Cycle," is the sport's primetime event, starting with the 3-6-3, morphing into a 6-6, and ending with a 1-10-1.</p><p>If you skimmed over that clunky paragraph, you've proved my dad's foundational epiphany: You really need to see it to buy in. In fact, scrap reading this for a few seconds (that's all it will take) and watch this video instead.</p><div><figure><p><iframe title="Fastest Cup Stacker Sets New World Record | Cup Stacking" width="710" height="399" src="https://www.youtube.com/embed/VyyscuIq56I?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p></figure></div><p>Place a set of these cups in the corner of a room or on a toy shelf with paper instructions, and you might earn five minutes of an 8-year-old's frenzied attention. Put that same 8-year-old on the gym floor in front of a professionally trained clown with a passion for juggling, and they will be utterly hooked.</p><figure><img alt="Three speed stacking cups in a row" src="https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/divider.png?w=710" srcset="https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/divider.png?w=425&amp;quality=75 425w, https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/divider.png?w=850&amp;quality=75 850w, https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/divider.png?w=585&amp;quality=75 585w, https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/divider.png?w=1170&amp;quality=75 1170w, https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/divider.png?w=710&amp;quality=75 710w, https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/divider.png?w=1420&amp;quality=75 1420w" sizes="(max-width: 30rem) 425px, (min-width: 30rem) and (max-width: 40rem) 585px, (min-width: 40rem) 710px" loading="lazy"></figure><p>A brief digression on nomenclature: The sport was known as "cup stacking" until 2005, when my parents had the savvy to officially change the name to "sport stacking." Why? 1) Because it sounds way cooler, and if enough people call it a sport then it must damn well be one. 2) The phrase "cup stacking" out of context evokes toddlers playing with blocks, a vibe they wanted to avoid. Confusingly, you might have also seen it referenced as "speed stacking," after the company they eventually founded, Speed Stacks. They strategically eschewed this label to avoid the fate of Roller Blades, Frisbee, and Kleenex, all formerly good standing trademarks, until you lot ruined everything. </p><p>Except for this early-stage reference, I'll be calling it sport stacking hereafter so as to avoid a grumpy phone call from my dad (he'll probably still call about my use of "damn," though). If you have a problem with that, consider the last time you went berserk over a nine-darter or screamed at the Swedish curling team during the Olympics. As my dad likes to say, there used to be a man trying to convince the world that tossing balls made from dried cow skin into retrofitted peach baskets was fun—and you all bought in.</p><figure><img alt="Three speed stacking cups in a row" src="https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/divider.png?w=710" srcset="https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/divider.png?w=425&amp;quality=75 425w, https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/divider.png?w=850&amp;quality=75 850w, https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/divider.png?w=585&amp;quality=75 585w, https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/divider.png?w=1170&amp;quality=75 1170w, https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/divider.png?w=710&amp;quality=75 710w, https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/divider.png?w=1420&amp;quality=75 1420w" sizes="(max-width: 30rem) 425px, (min-width: 30rem) and (max-width: 40rem) 585px, (min-width: 40rem) 710px" loading="lazy"></figure><p>It is important to note that my dad did not actually invent sport stacking. Credit goes to a group of bored kids at a Boys and Girls Club in Oceanside, Calif., in the early 1980s. They'd been given a stack of paper cups, and told to figure out a game that didn't involve messy liquid. Under the guidance of a program director named Wayne Godinet, both the rules and equipment evolved. He is responsible for the sport's first major innovation: He drilled a hole through the base of hard plastic cups to reduce air friction and prevent sticking. The California group's high-water mark came on Nov. 2, 1990, when they appeared on <em>The Tonight Show with Johnny Carson</em>. Among the millions watching that night, from his bed in a south Denver suburb: a clown and future PE teacher who thought it looked a bit like upside-down juggling.</p><p>Hasbro must have been watching, too. Perhaps chasing the Hoola Hoop and Pogs high of the '80s, the company scooped up a license to sell "Kup Stax," popping sets in a rectangular plastic sleeve on toy store shelves around the world. Instead of becoming a fad, the product moved to the clearance rack. Someone in middle management was probably scolded. Manufacturing ceased.&nbsp;</p><p>In 1995, my dad attended a physical education development workshop to give new teachers a dozen ideas on how to keep kids occupied, exercised, and docile. The classics were all there: four-wheeled square scooters designed to give 80 percent of users elbow burn, dodgeballs primed to pop kids like me in the face, that large circus tent you toss above your head until it temporarily inflates so you can sit under it for a few seconds. So were the cups.&nbsp;</p><p>He brought them home and taught his kids. I was 4, my brother 6, our sister 9. We not only fell in love with them, we got good—<em>fast</em>. We weren't outliers. Among an elementary school of 500 students, 250 signed up for an afterschool program to keep stacking. My mom drove to every Toys "R" Us and Walmart within a 50-mile radius. She bought every set of Kup Stax she could find. They were always discounted, tucked in a back corner.</p><p>The local supply ran dry as my parents hosted workshops. Demand started to skyrocket from other PE teachers. My parents needed to go upstream. They had to figure out how to tap into the supply chain of global toy conglomerates. Fortunately, they had a guy: <em>Uncle Johnny</em>.</p><p>Now 64 with a Colonel Sanders goatee and passion for intricate leather carving, my dad's brother has been at certain points in his life: a professor at the Ringling Bros. and Barnum &amp; Bailey Clown College; a street mime in San Diego; a director of&nbsp;a Las Vegas magic show, performed entirely on ice; and a consultant for Japan's oldest and largest circus. If you need to find a man in middle management at Hasbro's Tokyo corporate office, you call Uncle Johnny.</p><p>The deal was struck. The shipment arrived. And the cups, rather magically, disappeared from our basement.</p><p>By 1998, Bob Fox was a dealer with no product and an increasingly addicted customer base. There was only one logical next step: Transition from distribution to fabrication.</p><p>He did make a final good-faith effort to partner with the sport's originator, Wayne Godinet, offering to purchase $20,000 worth of product. It was almost a third of the profit earned from reselling the Japanese shipment. Godinet sent back two sample sets with a bill for the cost of goods and shipping.</p><p>In a similar vein, Nike was founded in 1964 only after a running shoe company called Onitsuka lost interest in partnering with a recent Oregon track grad named Phil Knight. While his shoe empire was born between the grooves of a waffle iron, Bob and Jill's cup empire was sketched on the back of a Fresh Fish Co. paper placemat.</p><p>Speed Stacks LLC was incorporated in December 1998. My parents quit their full-time public school jobs in June 2000.&nbsp;</p><p>This was to be an official test of a core tenet of the American Dream: With enough passion and even more prodigious work ethic, you can turn a ludicrous idea into a successful business. To get started, they just needed four things.</p><p>First: a mold to mass produce the cups. It required $20,000 and overcoming the absolute befuddlement of executives at a Denver plastics manufacturer who did not understand the <em>explicit request</em> to include three small holes at the base. As each cup came off the line, our family would inspect the shape; minor defects in its roundness caused sticking. Nearly every cup in the first run had to be tossed out for deformities.</p><p>Second: a nylon and mesh cup-carrying bag. Those were sewn in the back basement of a Vietnamese immigrant–owned textile company. We bagged each set of 12 by hand, my parents staying up until 2:00 in the morning to fulfill orders after working full school days. Bob wasn't satisfied unless the logo of every cup perfectly faced forward.</p><p>Third: to hit the road. Speed Stack's first tagline was "See it! Believe it! Teach it!" My parents meant it: They knew that success was linearly related to the number of PE teachers who witnessed the sport in person. Our family of five put almost 100,000 miles on our 1997 maroon Suburban in a little over four years.</p><p>Fourth: kids who could stack the cups. <em>Outrageously fast</em>. For some reason, all three of the Fox progeny developed both the interest and intrinsic skill to do just that.</p><hr><div><figure><img src="https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/divider.png?w=710" alt="Three speed stacking cups in a row"></figure><div><blockquote><p><strong><em>At a booth in hotel conference halls and city convention centers, we'd stack for hours, drawing crowds spread three and four rows deep, often to the annoyance of the dodgeball or shuttlecock purveyors next door.&nbsp;</em></strong></p><span><blockquote></blockquote></span></blockquote></div></div><hr><p>Legendary ring announcer Michael Buffer’s voice was always our music cue. <em>"Ladies and gentlemen, welcome to the main event!"</em>&nbsp;</p><p>It would blast over portable speakers on either side of a gym floor. Emmy, my older sister, would lead us out from a hidden corner, followed by my brother, Brennan, then me: a 7-year-old with Coke-bottle glasses, immensely satisfied by the fact that hundreds of eyes were watching my every move.</p><p>We stopped when we reached separate tables spread evenly across our makeshift stage, usually under the basketball hoop. We stood still to let the tempo build.&nbsp;</p><p><em>"Let’s get ready to rumble!"</em></p><p>The synths would drop, and we would commence stacking plastic cups. Faster and with more skill than the students and teachers in Amarillo or Ft. Lauderdale or Butzbach, Germany, or Copenhagen, Denmark, could ever think possible.&nbsp;</p><p>Our family performed hundreds of school assemblies in almost every corner of the country (and some overseas). The 30-minute spectacle was choreographed specifically to blow the minds of kids between the ages of 7 and 14 as quickly as possible. This wasn't a talk from your fire chief about safety, or puppets teaching you the value of sharing. We humiliated principals and popular teachers by making them race us. There was a fabricated jacket with holes cut in the back that we fitted onto a volunteer, then stuck our arms through the sleeves to make it appear like they were magically adept (performed to the <em>Rocky</em> soundtrack). The finale was a choreographed stacking routine, set to "Dueling Banjos" from <em>Deliverance</em>.</p><p>But a school-by-school roadshow wasn't a scalable business model. So we went to the nexus of physical education sweatsuitdom: state and national teacher conventions. At a booth in hotel conference halls and city convention centers, we'd stack for hours, drawing crowds spread three and four rows deep, often to the annoyance of the dodgeball or shuttlecock purveyors next door.&nbsp;</p><figure><img alt="The author stacking cups as a child." src="https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/Kit-1996.jpeg?w=320" srcset="https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/Kit-1996.jpeg?w=425&amp;quality=75 425w, https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/Kit-1996.jpeg?w=850&amp;quality=75 850w, https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/Kit-1996.jpeg?w=585&amp;quality=75 585w, https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/Kit-1996.jpeg?w=1170&amp;quality=75 1170w, https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/Kit-1996.jpeg?w=710&amp;quality=75 710w, https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/Kit-1996.jpeg?w=1420&amp;quality=75 1420w" sizes="(max-width: 30rem) 425px, (min-width: 30rem) and (max-width: 40rem) 585px, (min-width: 40rem) 710px" loading="lazy"><figcaption><span>The author stacking cups as a child</span><span></span><span>Kit Fox/Defector</span></figcaption></figure><p>It's most likely that you learned how to sport stack because your teacher, with a lanyard badge bouncing over her multi-colored windbreaker on her way to get a free muffin from the guys who sell tug-o-war ropes, stopped in her tracks in the back corner of Exhibit Hall B at an exurban Renaissance hotel. She would watch as our hands manipulated dishware so fast it blurred.</p><p>If my dad was adept at putting on a good show, my mom was equally adept at corralling the press. Her journalism and PR–honed chops put sport stacking in front of millions, from the D-block of local newscasts to 30 Rock Plaza during the <em>Today Show</em>.&nbsp;</p><p>That's how I found myself chatting with a shirtless Simon Cowell in the makeup room before we both appeared on Ellen DeGeneres's show, taught Tiki Barber the basics of the 3-3-3, and tried to convince a baffled Michael Caine in the green room of <em>LIVE with Regis and Kelly</em> that yes, indeed, kids really do stack plastic cups for fun.</p><p>All press, to my parents, was good. My dad was absolutely thrilled when Glenn Beck spent four minutes of his daily Fox News monologue staring directly into the camera, railing against the dangers of stacking cups.</p><p>"We can't fix our country by keeping our children weak," Beck sputtered, roughly two minutes in. "They need to have spines. They need to get hit in the face a few times with a ball, you know what I mean? They have to learn how to live with and thrive on past failures."</p><p>Brands soon took advantage of sport stacking's essential power: No matter the context, it attracts near-instant attention. In 2005, I appeared in a <a href="https://www.youtube.com/clip/UgkxwybLaGciSxQJgS1FKh-3PeJwa9xtXtN8" target="_blank" rel="noreferrer noopener">nationwide Comcast commercial</a> for high speed internet. FritoLay shut down part of Times Square to feature our stacking talents as it launched Stax, a competitor to Pringles. A beverage company in England flew a dozen of us to London to help launch an abomination of a drink called <a href="https://www.youtube.com/watch?v=eelE8tHEScM" target="_blank" rel="noreferrer noopener">Freekee Soda</a>. Main ingredient? Carbonated milk. (Did I pretend to enjoy drinking that carbonated milk so as to not piss off any of the execs helping to pay for my college education? Obviously. But it is a cursed flavor.)</p><p>Perhaps the only media my parents turned down was an appearance on the infamous reality show <em>Wife Swap</em>. The producers, naturally, presumed the scions of a ludicrous gym activity would have some weird baggage to mine for the masses.&nbsp;</p><p>Unfortunately, despite the cups, we were pretty normal.</p><hr><div><figure><img src="https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/divider.png?w=710" alt="Three speed stacking cups in a row"></figure><div><blockquote><p><strong><em>To stack as fast as you possibly can in a World Championship is to strike a balance between fluidity and chaos.</em></strong></p><span><blockquote></blockquote></span></blockquote></div></div><hr><p>It was the Germans who made everything more serious.</p><p>They arrived at the 2004 World Sport Stacking Championships in matching flag-inspired sweatsuits. Multiple coaches would analyze everything from hand-tag efficiency during the four-person relay event to the mental routines of stackers before their individual competition.</p><p>Sport stacking, I believe, grew into a minor phenomenon for three reasons: 1) It's visually arresting, 2) it's easy to learn, and 3) competing against the clock is incredibly addicting.</p><p>Media buzz and schoolteachers kindled the first two. But my dad's magnum opus—the reason the sport didn't wither in the way of skip ball and snake boards—was that he (with the help of the 20 employees at the burgeoning HQ) built the infrastructure and equipment to spur global competition.&nbsp;</p><p>The sport's growth coincided with two of my dad's innovations: the StackMat, a patented self-timing device that allowed kids to practice on their own for hours, aiming to trim hundredths of a second off their best times; and the World Sport Stacking Association, a governing body to codify the rules and serve as the keeper of world, national, and local records.</p><p>In 1997, 250 kids were hand-timed with stop watches at the first Colorado State Championship.&nbsp;By 2007, ESPN aired an <a href="https://www.youtube.com/watch?v=xm8EKnl4ZDQ" target="_blank" rel="noreferrer noopener">hourlong David Lloyd–hosted special</a> of the World Championships, featuring more than 1,000 competitors from seven countries (re-aired in 2020 during their pandemic "The Ocho" promotion).&nbsp;</p><figure><img alt="Stackers compete at the World Speed Stacking Championships" src="https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/Stack-of-Champions.jpeg?w=640" srcset="https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/Stack-of-Champions.jpeg?w=425&amp;quality=75 425w, https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/Stack-of-Champions.jpeg?w=850&amp;quality=75 850w, https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/Stack-of-Champions.jpeg?w=585&amp;quality=75 585w, https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/Stack-of-Champions.jpeg?w=1170&amp;quality=75 1170w, https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/Stack-of-Champions.jpeg?w=710&amp;quality=75 710w, https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/Stack-of-Champions.jpeg?w=1420&amp;quality=75 1420w" sizes="(max-width: 30rem) 425px, (min-width: 30rem) and (max-width: 40rem) 585px, (min-width: 40rem) 710px" loading="lazy"><figcaption><span>Stackers compete at the World Speed Stacking Championships</span><span></span><span>Kit Fox/Defector</span></figcaption></figure><p>Like everything in his life, my dad choreographed a spectacle. He ordered a three-story banner to hang behind garbage can–sized cups that served as center stage. The competition floor was arranged with dozens of tables, all marked with laser-lined tape to demarcate relay boundaries.</p><p>During the final "Stack of Champions," the top competitors (and relay teams) from each event competed under the scrutiny of spotlights, three officials, an instant replay camera, and hundreds of spectators. In individual events, you're allotted two warmups and three tries. Relays are conducted head-to-head in teams of four.</p><p>For a few years, I was among those finalists.&nbsp;</p><p>To stack as fast as you possibly can in a World Championship is to strike a balance between fluidity and chaos. Push too hard and the cups tumble. Pull back and you'll lose by thousandths of a second.</p><div><figure><p><iframe title="World Sport Stacking Championships 2007" width="710" height="533" src="https://www.youtube.com/embed/Yxokrklbcdw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p><figcaption>A relay race in the Stack of Champions, in which I (the third stacker on the left team) stumble at the start, allowing my brother (the last stacker on the right team) to beat us by two-hundredths of a second.</figcaption></figure></div><p>For those moments, you exist at the outer physical boundary of human biology. When performing at your peak, the cups feel less like they're being stacked and more like they're being sprayed.&nbsp;</p><p>In 2001, the world record for sport stacking's marquee event, the Cycle, was 7.43 seconds. It was held by my sister. At the time, most people assumed a sub-seven-second time was physically impossible. The pattern requires more than 40 separate moves. At those speeds, hands make micro-adjustments faster than the brain can register. Her time stood for nearly four years.</p><p>In 2025, the world record for the cycle is 4.739 seconds.&nbsp;</p><p>Please understand: I know this whole endeavor is silly, that it's worthy of your slight mockery and general patina of confusion. But also understand that my dad created a culture in which German coaches passed strategic tips to Australian competitors. Where Japanese teenagers became pen pals with suburban Texans. Where nerves collapsed faster than the cups. Where kids and adults shrieked with joy over millisecond improvements. Where tension and drama and friendship mingled with the clattering cacophony of sliding and tapping plastic (there really is no sound like the one at these competitions).&nbsp;</p><p>Sport stacking had broad exposure in both mainstream and weird places. But it had a deep impact in a much smaller community. It changed lives.</p><hr><div><figure><img src="https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/divider.png?w=710" alt="Three speed stacking cups in a row"></figure><div><blockquote><p><strong><em>You've probably heard Rachael’s voice. Her effusive reaction on a stacking YouTube video meant for her small group of friends is behind the iconic "YES, OH MY GOSH!" scream, sampled in one of EDM's most mainstream hits, "Scary Monsters and Nice Sprites," by Skrillex.</em></strong></p><span><blockquote></blockquote></span></blockquote></div></div><hr><p>Milo Ferguson discovered sport stacking in first-grade PE class.&nbsp;</p><p>"My teacher was the final boss of butch lesbians. That's the only way I know how to describe her," Ferguson, now a 23-year-old co-founder of an independent animation studio, said. Their teacher loved competition and was beloved by her students, exactly the archetype to stop at a conference booth and believe in a quirky new cup-centric educational trend.</p><p>Rachael Nedrow, now a 29-year-old product manager at Amazon, first saw the sport while scrolling YouTube when she was 11. She pulled paper cups from the kitchen drawer to try and mimic the movement.</p><p>Both became obsessed, quickly. Though for different reasons.</p><p>"I was never the fastest kid. I was always kind of chubby. I was much more the creative person than an athletic one," Ferguson said. "Sport stacking was about hand-eye coordination more than strength. It was intricate. Delicate." For the first time, they were excited to attend PE class.</p><p>Nedrow, an accomplished tennis player, was intrigued by the self-improvement and rigid strictures of the clock. She bought an official set of Speed Stacks and started logging her progress on her own YouTube channel.</p><p>"My first competition was at a local church," Nedrow said. "I did terribly, but I still won."</p><p>Despite differing motivations, Ferguson and Nedrow's paths to competitive sport stacking mirror each other. Friends weren't interested, so they went looking for a community online and at competitions.&nbsp;</p><p>For the thousand kids that congregated on the arena floor at each World Championships, like Ferguson and Nedrow, the sentiment was common. They had found <em>their</em> people. They fit in, sometimes for the first time in their life.&nbsp;</p><p>There were future college athletes and kids with autism. There were rugby fans from New Zealand (riffing off their national team, they called themselves the "All Stacks") and South Koreans who had never been to the United States.&nbsp;</p><p>Roll your eyes, but my dad loved to say that the sport only helped build "positive pyramids." Spend a few hours watching kids pat each other on the back after a fumbled cup, or earn a hug for achieving a new personal best, and you'd buy into the platitude too.</p><p>Compared to other top-level stackers, Nedrow and Ferguson's experiences only differ in one way.&nbsp;</p><p>You've probably heard Rachael's voice. Her effusive reaction on a stacking YouTube video meant for her small group of friends is behind the iconic "YES, OH MY GOSH!" scream, sampled in one of EDM's most mainstream hits, "<a href="https://www.youtube.com/watch?v=WSeNSzJ2-Jw" target="_blank" rel="noreferrer noopener">Scary Monsters and Nice Sprites</a>," by Skrillex. Between Spotify and YouTube, it has more than 500 million streams.</p><p>And you probably know Ferguson's dad, Craig, the comedian and host of <em>The Late Late Show with Craig Ferguson</em> from 2005 to 2014.</p><p>Nedrow's collision with virality gave her backstage passes to several Skrillex concerts and the greatest fodder for "Two Truths and a Lie" of all time. But sport stacking also gave her something else she wasn’t expecting: a wide group of online friends.</p><p>"I don't think I would have taken stacking so far if it wasn't for the online community," Nedrow said. "When you are doing anything kind of competitive, it seems like it's much better when you are doing it with people. I really loved the aspect of kids commenting on my videos, saying they started stacking because of me. What greater pleasure can you get than inspiring other people to do what you love the most?"</p><p>Sport stacking gave Ferguson inclusion and validation. But perhaps more important than what it gave them is what it gave their parents. While Craig and his ex-wife Sascha had been separated for a few years by the time their kid started competing, both fully committed to supporting this weird, wholesome obsession. Sascha helped Milo learn how to breathe and center themselves before starting to stack. And she supplied an ever-growing collection of stacking equipment, stored in a dedicated room in their Southern California home.</p><p>To see what sport stacking gave Craig, you need to watch his show <a href="https://www.youtube.com/watch?v=9Wjk0PkpWco" target="_blank" rel="noreferrer noopener">from April 20, 2009</a>. He spends four minutes—more than half of the entire monologue—bragging about Milo. Beneath the scripted jokes and of-the-era references (Octomom is mentioned twice), you see a guy just genuinely proud of his kid. He's like any neighbor, going off a bit too effusively about the weekend's peewee football game or math test.&nbsp;</p><p>Except this was done for millions. And it was about ... cups.&nbsp;</p><hr><div><figure><img src="https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/divider.png?w=710" alt="Three speed stacking cups in a row"></figure><div><blockquote><p><strong><em>"I wanted to give kids, no matter their athletic ability, the opportunity for success. It gave them something new and different. And it created a community. It brought kids around the world together."</em></strong></p><span><blockquote></blockquote></span></blockquote></div></div><hr><p>Sport stacking gave different things to a lot of people.</p><p>For a few, it genuinely improved their life. College funds were paid through YouTube viewership revenue and small brand endorsements. Children with autism and special needs learned, practiced, competed, and socialized with others for the first time.&nbsp;</p><p>For me and my siblings, it gave us a stable home, trips to a dozen countries, and some excellent college essay material. My sister, Emmy, went on to play basketball for four years at the University of Minnesota, was drafted into the WNBA by the Minnesota Lynx, and then played professionally overseas with Sheryl Swoopes. My brother Brennan played D-III college football and turned into a mechanical engineer at a global cosmetics company. I turned into a fairly unathletic writer.</p><figure><img alt="The Fox family" src="https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/unnamed-4.jpg?w=240" srcset="https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/unnamed-4.jpg?w=425&amp;quality=75 425w, https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/unnamed-4.jpg?w=850&amp;quality=75 850w, https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/unnamed-4.jpg?w=585&amp;quality=75 585w, https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/unnamed-4.jpg?w=1170&amp;quality=75 1170w, https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/unnamed-4.jpg?w=710&amp;quality=75 710w, https://lede-admin.defector.com/wp-content/uploads/sites/28/2025/02/unnamed-4.jpg?w=1420&amp;quality=75 1420w" sizes="(max-width: 30rem) 425px, (min-width: 30rem) and (max-width: 40rem) 585px, (min-width: 40rem) 710px" loading="lazy"><figcaption><span>The Fox family</span><span></span><span>Kit Fox/Defector</span></figcaption></figure><p>For my parents, it gave them an early retirement. A sometimes-operational 1957 VW Bug and an obsession with growing ever-larger pumpkins occupied my dad, while training to run another marathon at age 70 became a focus for my mom. They left their active roles at Speed Stacks in 2015, leaving control to some of its earliest employees. Programs are still active in thousands of schools around the world.</p><p>"I was motivated to spread sport stacking for the same reason I taught my students how to juggle or unicycle," my dad recalled, nearly 10 years into retirement. "I wanted to give kids, no matter their athletic ability, the opportunity for success. It gave them something new and different. And it created a community. It brought kids around the world together. And believe it or not, that all happened because of a couple million plastic cups."</p><p>For some of you reading this, sport stacking gave you an identical memory.&nbsp;A cross-legged seat on a linoleum gym floor. The hush from the principal. The music crescendoing into <em>Jock Jams</em>' most iconic synth riff. The sound of cups, stacking at lightning speed. You knew, in that moment, that you weren't in for another monotonous few hours at school. Your day was about to rock.&nbsp;</p><p>For that, you can thank my dad.</p></div><div><h2>Stay in touch</h2><p>Sign up for our free newsletter</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We were wrong about GPUs (619 pts)]]></title>
            <link>https://fly.io/blog/wrong-about-gpu/</link>
            <guid>43053844</guid>
            <pubDate>Fri, 14 Feb 2025 22:36:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fly.io/blog/wrong-about-gpu/">https://fly.io/blog/wrong-about-gpu/</a>, See on <a href="https://news.ycombinator.com/item?id=43053844">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
         <dl>
             <dt>Author</dt>
             <dd>
                 <img alt="Kurt Mackey" src="https://fly.io/static/images/kurt.webp">
               <dl>
                 <dt>Name</dt>
                 <dd>
                   Kurt Mackey
                 </dd>
                  <dt>@mrkurt</dt>
                  <dd>
                    <a href="https://twitter.com/mrkurt" target="_blank">
                      @mrkurt
                    </a>
                  </dd>
               </dl>
             </dd>
         </dl>

        <section>
            <figure>
                <img src="https://fly.io/blog/wrong-about-gpu/assets/choices-choices-cover.webp" alt="We took the road less traveled by. It was less traveled for a reason.">
                <figcaption>
                  <span>Image by</span>
                  
<svg role="img" style="pointer-events: none; width: 17px; height: 17px;" viewBox="0 0 20 20" fill="currentColor" fill-rule="evenodd">
  <g buffered-rendering="static">
    <path fill-rule="evenodd" d="M1 8a2 2 0 012-2h.93a2 2 0 001.664-.89l.812-1.22A2 2 0 018.07 3h3.86a2 2 0 011.664.89l.812 1.22A2 2 0 0016.07 6H17a2 2 0 012 2v7a2 2 0 01-2 2H3a2 2 0 01-2-2V8zm13.5 3a4.5 4.5 0 11-9 0 4.5 4.5 0 019 0zM10 14a3 3 0 100-6 3 3 0 000 6z" clip-rule="evenodd"></path>
  </g>
</svg>

                    <a href="https://annieruygtillustration.com/" target="_blank">
                      Annie Ruygt
                    </a>
                </figcaption>
            </figure>
          <p>We’re building a public cloud, on hardware we own. We raised money to do that, and to place some bets; one of them: GPU-enabling our customers. A progress report: GPUs aren’t going anywhere, but: GPUs aren’t going anywhere.</p>
<p>A couple years back, <a href="https://fly.io/gpu">we put a bunch of chips down</a> on the bet that people shipping apps to users on the Internet would want GPUs, so they could do AI/ML inference tasks. To make that happen, we created <a href="https://fly.io/docs/gpus/getting-started-gpus/">Fly GPU Machines</a>.</p>

<p>A Fly Machine is a <a href="https://fly.io/blog/docker-without-docker/">Docker/OCI container</a> running inside a hardware-virtualized virtual machine somewhere on our global fleet of bare-metal worker servers. A GPU Machine is a Fly Machine with a hardware-mapped Nvidia GPU. It’s a Fly Machine that can do fast CUDA.</p>

<p>Like everybody else in our industry, we were right about the importance of AI/ML. If anything, we underestimated its importance. But the product we came up with probably doesn’t fit the moment. It’s a bet that doesn’t feel like it’s paying off.</p>

<p><strong>If you’re using Fly GPU Machines, don’t freak out; we’re not getting rid of them.</strong> But if you’re waiting for us to do something bigger with them, a v2 of the product, you’ll probably be waiting awhile.</p>
<h3 id="what-it-took"><a href="#what-it-took" aria-label="Anchor"></a><span>What It Took</span></h3>
<p>GPU Machines were not a small project for us. Fly Machines run on an idiosyncratically small hypervisor (normally Firecracker, but for GPU Machines <a href="https://github.com/cloud-hypervisor/cloud-hypervisor">Intel’s Cloud Hypervisor</a>, a very similar Rust codebase that supports PCI passthrough). The Nvidia ecosystem is not geared to supporting micro-VM hypervisors.</p>

<p>GPUs <a href="https://googleprojectzero.blogspot.com/2020/09/attacking-qualcomm-adreno-gpu.html">terrified our security team</a>. A GPU is just about the worst case hardware peripheral: intense multi-directional direct memory transfers</p>
<p>(not even bidirectional: in common configurations, GPUs talk to each other)</p>
<p>with arbitrary, end-user controlled computation, all operating outside our normal security boundary.</p>

<p>We did a couple expensive things to mitigate the risk. We shipped GPUs on dedicated server hardware, so that GPU- and non-GPU workloads weren’t mixed. Because of that, the only reason for a Fly Machine to be scheduled on a GPU machine was that it needed a PCI BDF for an Nvidia GPU, and there’s a limited number of those available on any box. Those GPU servers were drastically less utilized and thus less cost-effective than our ordinary servers.</p>

<p>We funded two very large security assessments, from <a href="https://www.atredis.com/">Atredis</a> and <a href="https://tetrelsec.com/">Tetrel</a>, to evaluate our GPU deployment. Matt Braun is writing up those assessments now. They were not cheap, and they took time.</p>

<p>Security wasn’t directly the biggest cost we had to deal with, but it was an indirect cause for a subtle reason.</p>

<p>We could have shipped GPUs very quickly by doing what Nvidia recommended: standing up a standard K8s cluster to schedule GPU jobs on. Had we taken that path, and let our GPU users share a single Linux kernel, we’d have been on Nvidia’s driver happy-path.</p>

<p>Alternatively, we could have used a conventional hypervisor. Nvidia suggested VMware (heh). But they could have gotten things working had we used QEMU. We like QEMU fine, and could have talked ourselves into a security story for it, but the whole point of Fly Machines is that they take milliseconds to start. We could not have offered our desired Developer Experience on the Nvidia happy-path.</p>

<p>Instead, we burned months trying (and ultimately failing) to get Nvidia’s host drivers working to map <a href="https://www.nvidia.com/en-us/data-center/virtual-solutions/">virtualized GPUs</a> into Intel Cloud Hypervisor. At one point, we hex-edited the closed-source drivers to trick them into thinking our hypervisor was QEMU.</p>

<p>I’m not sure any of this really mattered in the end. There’s a segment of the market we weren’t ever really able to explore because Nvidia’s driver support kept us from thin-slicing GPUs. We’d have been able to put together a really cheap offering for developers if we hadn’t run up against that, and developers love “cheap”, but I can’t prove that those customers are real.</p>

<p>On the other hand, we’re committed to delivering the Fly Machine DX for GPU workloads. Beyond the PCI/IOMMU drama, just getting an entire hardware GPU working in a Fly Machine was a lift. We needed Fly Machines that would come up with the right Nvidia drivers; our stack was built assuming that the customer’s OCI container almost entirely defined the root filesystem for a Machine. We had to engineer around that in our <code>flyd</code> orchestrator. And almost everything people want to do with GPUs involves efficiently grabbing huge files full of model weights. Also annoying!</p>

<p>And, of course, we bought GPUs. A lot of GPUs. Expensive GPUs.</p>
<h3 id="why-it-isnt-working"><a href="#why-it-isnt-working" aria-label="Anchor"></a><span>Why It Isn’t Working</span></h3>
<p>The biggest problem: developers don’t want GPUs. They don’t even want AI/ML models. They want LLMs. <em>System engineers</em> may have smart, fussy opinions on how to get their models loaded with CUDA, and what the best GPU is. But <em>software developers</em> don’t care about any of that. When a software developer shipping an app comes looking for a way for their app to deliver prompts to an LLM, you can’t just give them a GPU.</p>

<p>For those developers, who probably make up most of the market, it doesn’t seem plausible for an insurgent public cloud to compete with OpenAI and Anthropic. Their APIs are fast enough, and developers thinking about performance in terms of “tokens per second” aren’t counting milliseconds.</p>
<p>(you should all feel sympathy for us)</p>
<p>This makes us sad because we really like the point in the solution space we found. Developers shipping apps on Amazon will outsource to other public clouds to get cost-effective access to GPUs. But then they’ll faceplant trying to handle data and model weights, backhauling gigabytes (at significant expense) from S3. We have app servers, GPUs, and object storage all under the same top-of-rack switch. But inference latency just doesn’t seem to matter yet, so the market doesn’t care.</p>

<p>Past that, and just considering the system engineers who do care about GPUs rather than LLMs: the hardware product/market fit here is really rough.</p>

<p>People doing serious AI work want galactically huge amounts of GPU compute. A whole enterprise A100 is a compromise position for them; they want an SXM cluster of H100s.</p>
<p>Near as we can tell, MIG gives you a UUID to talk to the host driver, not a PCI device.</p>
<p>We think there’s probably a market for users doing lightweight ML work getting tiny GPUs. <a href="https://www.nvidia.com/en-us/technologies/multi-instance-gpu/">This is what Nvidia MIG does</a>, slicing a big GPU into arbitrarily small virtual GPUs. But for fully-virtualized workloads, it’s not baked; we can’t use it. And I’m not sure how many of those customers there are, or whether we’d get the density of customers per server that we need.</p>

<p><a href="https://fly.io/blog/cutting-prices-for-l40s-gpus-in-half">That leaves the L40S customers</a>. There are a bunch of these! We dropped L40S prices last year, not because we were sour on GPUs but because they’re the one part we have in our inventory people seem to get a lot of use out of. We’re happy with them. But they’re just another kind of compute that some apps need; they’re not a driver of our core business. They’re not the GPU bet paying off.</p>

<p>Really, all of this is just a long way of saying that for most software developers, “AI-enabling” their app is best done with API calls to things like Claude and GPT, Replicate and RunPod.</p>
<h3 id="what-did-we-learn"><a href="#what-did-we-learn" aria-label="Anchor"></a><span>What Did We Learn?</span></h3>
<p>A very useful way to look at a startup is that it’s a race to learn stuff. So, what’s our report card?</p>

<p>First off, when we embarked down this path in 2022, we were (like many other companies) operating in a sort of phlogiston era of AI/ML. The industry attention to AI had not yet collapsed around a small number of foundational LLM models. We expected there to be a diversity of <em>mainstream</em> models, the world <a href="https://github.com/elixir-nx/bumblebee" title="">Elixir Bumblebee</a> looks forward to, where people pull different AI workloads off the shelf the same way they do Ruby gems.</p>

<p>But <a href="https://www.cursor.com/" title="">Cursor happened</a>, and, as they say, how are you going to keep ‘em down on the farm once they’ve seen Karl Hungus? It seems much clearer where things are heading.</p>

<p>GPUs were a test of a Fly.io company credo: as we think about core features, we design for 10,000 developers, not for 5-6. It took a minute, but the credo wins here: GPU workloads for the 10,001st developer are a niche thing.</p>

<p>Another way to look at a startup is as a series of bets. We put a lot of chips down here. But the buy-in for this tournament gave us a lot of chips to play with. Never making a big bet of any sort isn’t a winning strategy. I’d rather we’d flopped the nut straight, but I think going in on this hand was the right call.</p>

<p>A really important thing to keep in mind here, and something I think a lot of startup thinkers sleep on, is the extent to which this bet involved acquiring assets. Obviously, some of our <a href="https://fly.io/blog/the-exit-interview-jp/" title="">costs here aren’t recoverable</a>. But the hardware parts that aren’t generating revenue will ultimately get liquidated; like with <a href="https://fly.io/blog/32-bit-real-estate/" title="">our portfolio of IPv4 addresses</a>, I’m even more comfortable making bets backed by tradable assets with durable value.</p>

<p>In the end, I don’t think GPU Fly Machines were going to be a hit for us no matter what we did. Because of that, one thing I’m very happy about is that we didn’t compromise the rest of the product for them. Security concerns slowed us down to where we probably learned what we needed to learn a couple months later than we could have otherwise, but we’re scaling back our GPU ambitions without having sacrificed <a href="https://fly.io/blog/sandboxing-and-workload-isolation/" title="">any of our isolation story</a>, and, ironically, GPUs <em>other people run</em> are making that story a lot more important. The same thing goes for our Fly Machine developer experience.</p>

<p>We started this company building a Javascript runtime for edge computing. We learned that our customers didn’t want a new Javascript runtime; they just wanted their native code to work. <a href="https://news.ycombinator.com/item?id=22616857" title="">We shipped containers</a>, and no convincing was needed. We were wrong about Javascript edge functions, and I think we were wrong about GPUs. That’s usually how we figure out the right answers:  by being wrong about a lot of stuff.</p>

          
        </section>
        <dl>
            <dt>
              Previous post  ↓
            </dt>
            <dd>
              <a href="https://fly.io/blog/the-exit-interview-jp/">
                The Exit Interview: JP Phillips
              </a>
            </dd>
        </dl>
      </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Complex dynamics require complex solutions (179 pts)]]></title>
            <link>https://mathstodon.xyz/@tao/113873092369347147</link>
            <guid>43053625</guid>
            <pubDate>Fri, 14 Feb 2025 22:05:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mathstodon.xyz/@tao/113873092369347147">https://mathstodon.xyz/@tao/113873092369347147</a>, See on <a href="https://news.ycombinator.com/item?id=43053625">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The hardest working font in Manhattan (508 pts)]]></title>
            <link>https://aresluna.org/the-hardest-working-font-in-manhattan/</link>
            <guid>43053419</guid>
            <pubDate>Fri, 14 Feb 2025 21:45:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aresluna.org/the-hardest-working-font-in-manhattan/">https://aresluna.org/the-hardest-working-font-in-manhattan/</a>, See on <a href="https://news.ycombinator.com/item?id=43053419">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
		<header>
			<p>
				Marcin Wichary
			</p>
			<p>
				14&nbsp;February&nbsp;2025&nbsp;/ 6,100&nbsp;words&nbsp;/ 600&nbsp;photos
			</p>
		</header>
		
		
	<p>
		In 2007, on my first trip to New York City, I grabbed a brand-new DSLR camera and photographed all the fonts I was supposed to love. I admired American Typewriter in all of the I &lt;3 NYC logos, watched Akzidenz Grotesk and Helvetica fighting over the subway signs, and even caught an occasional appearance of the flawlessly-named Gotham, still a year before it skyrocketed in popularity via Barack Obama’s first campaign. 
	</p>
	<p>
		But there was one font I didn’t even notice, even though it was everywhere around me.
	</p>
	<p>		
		Last year in New York, I walked over 100 miles and took thousands of photos of one and one font only.
	</p>
	<p>		
		The font’s name is Gorton.
	</p>
	
	<hr>
	
	<h3>
		1
	</h3>
	<p>		
		It’s hard to believe today that there was a time before I knew of Gorton and all its quirks and mysteries. The first time I realized the font even existed was some time in 2017, when I was researching for <a target="_blank" href="https://shifthappens.site/">my book about the history of typing</a>. 
	</p>
	<p>		
		Many keyboards, especially older ones, sported a particular distinctive font on their keycaps. It was unusually square in proportions, and a weird mélange of “mechanical” and “childish.”
	</p>
	
	
	
	<figure>
		<img src="https://aresluna.org/images/the-hardest-working-font-in-manhattan/keyboards/dsc03621.avif">
	</figure>
	

	<p>		 
		The more I looked at it, the more I realized how bizarre and amateurish it was. The G always felt like it was about to roll away on its side. There was a goofy wavy hook sticking out of Q. P and R were often too wide. &amp; and @ symbols would be laughed away in a type crit, and the endings of C felt like grabbing something next to it – a beginning of a ligature that never came.
	</p>
	<figure>
		<img src="https://aresluna.org/images/the-hardest-working-font-in-manhattan/keyboards/dsc00642.avif">
	</figure>
	<p>		
		The strangeness extended to the digits. There was a top-flatted 3 resembling a Cyrillic letter, 7 sloping down in a unique way, a very geometric 4, an unusual – perhaps even naïve – symmetry between 6 and 9, and a conflation of O with 0 that would be a fireable offense elsewhere.
	</p>
	<p>			
		Looking at just a few keyboards, it was also obvious that it wasn’t just one rigid font. There were always variations, sometimes even on one keyboard. 0 came square, dotted, or slashed. The usually very narrow letter I sometimes sported serifs. The R and the 6 moved their middles higher or lower. There also seemed to be a narrower version of the font, deployed when a keycap needed a word and not just a letter. (Lowercase letters existed too, but not very often.) 
	</p>
	

	
	

	<p>		
		My first thought was: What a mess. Is this how “<a target="_blank" href="https://fonts.ilovetypography.com/category/grotesque">grotesque</a>” fonts got their name?
	</p>
	<p>		
		Then, the second thought: I kind of like it.
	</p>

	
	<figcaption>The most distinctive letterforms of Gorton<span> (Press a key!)</span></figcaption>
	
	
	<p>		
		But what font was it? What The Font website posited TT Rounds, Identifont suggested it could be Divulge, my early guess was DIN Rounded or something related to road signage. Whatever it was, a flat R clearly separated it from Helvetica, and the shapes were not as round as even the un-rounded Gotham’s.
	</p>
	<p>		
		A few places for keyboard nerds referred to the font as “Gorton,” but that phrase yielded zero results anywhere I typically looked for fonts I could download and install.
	</p>
	<p>				
		I originally thought this had to do with how keys were made. Only in newer keyboards are the letters printed on top of the keys, or charred from their surface by a laser. In older ones – those from the early 1960s laboratory computers, or the 1980s microcomputers –&nbsp;the way every key was constructed was by first molding the letter from plastic of one color, and then grabbing a different plastic and molding the key around the letter. A Gorton letter was as physical as the key itself. It made the keys virtually indestructible – the legend could not wear off any more than its key – and I imagined required some specialized keyboard-making machinery that came with the “keyboard font” already there.
	</p>
	
	<figcaption>
		An example of a “double-shot” key from above and from below
	</figcaption>

	<hr>
	
	<h3>
		2
 	</h3>
	 
	<p>			
		But then, I started seeing Gorton in other places.
	</p>
	<p>					
		Hours of looking at close-ups of keys made me sensitive to the peculiar shapes of some of its letters. No other font had a Q, a 9, or a C that looked like this.
	</p>
	<p>					
		One day, I saw what felt like Gorton it on a ferry traversing the waters Bay Area. A few weeks later, I spotted it on a sign in a national park. Then on an intercom. On a street lighting access cover. In an elevator. At my dentist’s office. In an alley. 
	</p>
	
	
	
	
	
	
	<p>						
		These had one thing in common. All of the letters were carved into the respective base material – metal, plastic, wood. The removed shapes were often filled in with a different color, but sometimes left alone.
	</p>
	<p>					
		At one point someone explained to me Gorton must have been a routing font, meant to be carved out by a milling machine rather than painted on top or impressed with an inked press.
	</p>
	<p>							
		Some searches quickly led me to George Gorton Machine Co., a Wisconsin-based company which produced various engraving machines. The original model 1 led to model 1A and then 3U and then, half a decade later, P1-2. They were all pantograph engravers: They allowed you to install one or more letter templates and then trace their shape by hand. A matching rotating cutter would mimic your movements, and the specially configured arms would enlarge or reduce the output to the size you wanted.
		</p>
	


	
	
	
	


	
	<figure>
		<video muted="" loop="" playsinline="" src="https://aresluna.org/videos/the-hardest-working-font-in-manhattan/engraving.mp4"></video>
	</figure>
	<figcaption>Edited from a video <a target="_blank" href="https://www.youtube.com/watch?v=7am-ysvGD3s">Saving The Machine the World Forgot</a> with kind permission from Inheritance Machining</figcaption>
	
	
	
	<p>					
		The first font in <a target="_blank" href="https://archive.org/details/gorton-master-copy-type-for-all-pantograph-machines">the 1952’s company catalogue</a> was called Gorton Normal and I felt I already knew it by heart.
	</p>
	
	

	
	<p>							
		This immediately explained both the metaphorical and literal rough edges of Gorton.
	</p>
	<p>					
		A lot of typography has roots in calligraphy – someone holding a brush in their hand and making natural but delicate movements that result in nuanced curves filled with thoughtful interchanges between thin and thick. Most of the fonts you ever saw follow those rules; even the most “mechanical” fonts have surprising humanistic touches if you inspect them close enough.
	</p>
	<p>			
		But not Gorton. Every stroke of Gorton is exactly the same thickness (typographers would call such fonts “monoline”). Every one of its endings is exactly the same rounded point. The italic is merely an oblique, slanted without any extra consideration, and while the condensed version has some changes compared to the regular width, those changes feel almost perfunctory.
	</p>
	<p>	
		Monoline fonts are not respected highly, because every type designer will tell you: This is not how you design a font. 
	</p>
	
	<hr>
	
	<h3>
		3
	</h3>
	
	<p>		
		It seemed at this point that perhaps P1-2 and its predecessors were a somewhat popular machining product during the 20th century’s middle decades. But casual research through materials preserved by some of George Gorton Machine Company’s fans – including <a target="_blank" href="http://gorton-machine.org/">the grandson of the founder</a> – revealed something even more interesting. Gorton the font was a lot older than I expected. 
	</p>
	<p>		
		I found a 1935 catalog showing the very same font. Then one from 1925. And then, there was one all the way from 1902, showing the shapes I was starting to be mildly obsessed with.
	</p>
	<p>			
		To put it in perspective: the font I first assumed was a peer to 1950s Helvetica was already of retirement age the day Helvetica was born. Gorton was older than Gill Sans, Futura, or Johnston’s London Underground font. It was contemporaneous to what today we recognize as the first modern sans serif font, Akzidenz-Grotesk, released but three years before the end of the century.
	</p>

	
	<figcaption>This 1902 catalogue is so old it still has <a target="_blank" hef="https://en.wikipedia.org/wiki/Commercial_code_(communications)">telegraph codes</a></figcaption>
	
	<p>
		Imagine how stripped down and exotic Gorton must have felt right next to George Gorton Machine’s then-current logo!
	</p>
	
	<figure>
		<img src="https://aresluna.org/images/the-hardest-working-font-in-manhattan/old-logo/old-logo.avif">
	</figure>

	<p>							
		<em>Now</em> I was interested. 
	</p>
	<p>					
		I started researching Gorton more. Unfortunately, as I already suspected, no one ever wrote “I used Gorton to typeset this,” because Gorton was a tenuous name at best. It was the first font, and perhaps originally the <em>only</em> font that came with the engraver, so it suffered a nameless fate, familiar later to many bespoke bitmap fonts adoring the screens of early computers.
	</p>
	<p>					
		The difference from these fonts, however, was that Gorton was meant to travel. And so, since searching for it by name was impossible, for months and years I just kept looking around for the now-familiar shapes.
	</p>
	<p>			
		And I found… a lot. 
	</p>
	<p>
		Gorton wasn’t just on computer keyboards, intercom placards, and sidewalk messages visited by many shoes. Gorton was there on typewriter keyboards, too. And on office signs and airline name tags. On boats, desk placards, rulers, and various home devices from fridges to tape dispensers.
	</p>
	<p>					
		It was also asked to help in situations other fonts rarely did. I spotted Gorton on overengineered buttons that were put to heavy industrial and military use. I saw it carved into surfaces of traffic control devices, elevators and escalators, locomotives and subway trains, submarines and jet fighters. Gorton made its way to peace- and wartime nuclear facilities, it was there on the elevator at the Kennedy Space Center with labels marked EARTH and SPACE… and it went <em>to actual space,</em> and then the Moon, as key legends on Apollo’s onboard computer.
	</p>
	
	
	
		

	
	<p>							
		But why? Why would anyone choose this kind of an ugly font where so many nicer fonts have already been around for ages?
	</p>
	<p>					
		Some of it might be the power of the default. Popular engraving equipment comes with a built-in font that’s so standard it reuses the router’s name? Of course you will see it, the same way you saw a lot of Arial in the 1990s, or Calibri today.
	</p>
	<figure>
		<img src="https://aresluna.org/images/the-hardest-working-font-in-manhattan/cutter/cutter.avif">
	</figure>
	<figcaption>An example of a typical range of reducations. <a target="_blank" href="http://www.gorton-machine.org/links/prayer.html">More range was available when needed</a></figcaption>

	<p>
		Gorton was also convenient. If your previous engraving work required you do to the routing equivalent of handwriting or lettering – every letter done by hand – then a modern font you could simply <em>copy,</em> and one designed with “a minimum of sharp corners for rapid tracing with a smooth stroke,” must have felt like a breath of fresh air.
	</p>
	
	<p>							
		But why engraving to begin with? Because the affordable and casual printing options we enjoy today – the office laser printers and home inkjets, the FedEx Kinko’s, the various cheap labelers – weren’t there. Even things that today feel obsolete, like dot matrix printers, Letraset, and popular letter stencils, were yet to be invented. Often, your only realistic option was the complicated and time-consuming lettering by hand.
	</p>
	<p>			
		On top of that, Gorton’s longevity must have felt attractive. Ink smudges. Paint fades away. Paper can catch fire (quickly) or germs (slowly). Carve something into plastic, on the other hand, and it can survive decades. Substitute plastic for metal, and you just turned decades into centuries. The text is not added atop heavy-duty material. The text <em>is</em> the material.
	</p>

	<div data-runner="CollectionGallery" data-runner-id="collection">

		<p><label>
				
				Name tags
			</label><label>
				
				Objects
			</label><label>
				
				Plaques
			</label><label>
				
				Desk top
			</label><label>
				
				Square dancing, &amp;c.
			</label><label>
				
				Key tags
			</label>
		</p>		
	</div>

	<figcaption>Various items from the 20th century typeset in Gorton</figcaption>

	<hr>

	<h3>
		4
	</h3>
	
	<p>					
		I felt good about all my findings: What a strange story of a strange routing font! 
	</p>
	<p>
		But it turns out I was just getting started. Because soon, I noticed Gorton as ink on paper, and as paint on metal.
	</p>
	
	
	
	
	
	
	<p>We’re used to the flexibility of fonts today. Fonts as bits inside a computer can become a website, paint on paper, CNC routing, a wall projection, and many other things. But those freedoms weren’t as easy back when fonts were made out of metal. Life’s not as much fun outside of the glamor of a TTF file, and a routing font couldn’t immediately become a regular font – so seeing Gorton being additive and not subtractive was an unexpected discovery.
	</p>

	<figure>
		<video muted="" loop="" playsinline="" src="https://aresluna.org/videos/the-hardest-working-font-in-manhattan/leroy-edgar.mp4"></video>
	</figure>
	<figcaption>A Leroy lettering set in action, from <a target="_blank" href="https://www.instagram.com/made.by.edgar/">Made by Edgar</a></figcaption>
	<p>							
		It turns out that there developed a small cottage industry of things that extended Gorton past its engraving origins.
	</p>

	<p>							
		A company called Keuffel &amp; Esser Co. grabbed Gorton’s machines, and used them to create lettering sets called Leroy. This was Gorton abstracted away – still a pantograph, but cheap, small, completely manual, and a vastly simplified one: no possibility to make things bigger and smaller, and no carving –&nbsp;instead, you’d mount a special pen and draw letters by tracing them.
	</p>
	<p>							
		Another company, Wood-Regan Instrument Co., made a similar set called (semi-eponymously) Wrico. But then, they simplified the process even more. Instead of a pantograph, they offered for sale a set of simple lettering guides used to guide your pen directly on paper.
	</p>
	<p>							
		Some of the traditional draftspeople pooh-poohed these inventions – one handbook wrote “[Those are] of value chiefly to those who are not skilled in lettering. A professional show-card writer could work better and faster without it. A Leroy or Wrico lettering set permits work that is neat, rapid, and nearly foolproof, if not inspired.”
	</p>
	
	
	

	
	<p>			
		But the products ended up being popular and influential. Their output appeared in many technical documents, but spread even a bit further than that. Eventually, there were stencils made by Unitech, Lutz, Tacro, Teledyne Post, Tamaya, Tech Graphic, Ridgway’s, Faber Castell, Zephyr, Charvoz, Rotring, Pickett, and probably many more.
	</p>
	
		
	
	

	<p>			
		Then, both EC Comics and All-Star Comics <a target="_blank" href="https://kleinletters.com/Blog/wizards-of-leroy-and-wrico-lettering/">used Leroy in the 1940s and 1950s</a>, most notably in the first comic book that introduced Wonder Woman. This was Gorton spreading further than just technical documents, and inspiring more people.
	</p>
	
	
	

	<p>			
		Elsewhere silkscreening – a pretty cool technique of applying paint on surfaces through a wet mesh of fabric – took Gorton and Leroy in a different direction, by allowing paint on metal.
	</p>
	
	


	<p>			
		There was more. The popular plastic letters attached to fell boards, popularized by restaurants decades ago, and more recently revisited by Instagram mom influencers, also clearly derive from Gorton and Leroy.
	</p>
	
	
	

	
	<p>
		I also counted at least three different systems of “Gorton movable type” – some where you could assemble physical letters, and some where you could impress them into soft materials using steel types – and I imagine there were probably more.
	</p>
	
	
	

	
	<p>			
		Letraset, a cheap technique of applying a font by rubbing a letter from a provided sheet onto paper, popular throughout the 1960s, introduced first- or second-hand Leroy too – and so did a few competitors.
	</p>
	
	<div>
		<figure>
			<img src="https://aresluna.org/images/the-hardest-working-font-in-manhattan/letraset/zipatone-ad.avif">
		</figure>
	</div>
	
	
	
	<p>					
		In the regulatory space, the U.S. military canonized Gorton in 1968 as a standard called MIL-SPEC-33558 for aircraft and other equipment dials, cancelled it in 1998… then brought it back again in 2007. NATO and STANAG followed. ANSI, American standardization body, made a more rounded Leroy an official font for technical lettering via <a target="_blank" href="https://archive.org/details/ansi-y14.2m-1971-line-conventions-and-lettering">ANSI Y14.2M</a>, and so did institutions like the US National Park Service.
	</p>

	

	<p>				
		Gorton went on and on and on. The early <a target="_blank" href="https://hackaday.com/2021/03/30/hershey-fonts-not-chocolate-the-origin-of-vector-lettering/">Hershey vector fonts</a>, developed on very early computers and still popular in CAD applications today, were also derived from Gorton/Leroy shapes, simplified so that the already-simple curves weren’t even necessary –&nbsp;any letter could now be drawn by a series of straight lines.
	</p>
	
	
	
	<p>					
		And even in the first universe Gorton inhabited things weren’t standing still. 
	</p>
	
	<p>
		As the engraving industry learned what’s popular and what is not, the offerings started getting more and more sophisticated. A promotional booklet called “The Whereabouts of 230 Engraving Machines” listed Gorton customers ranging from biscuit makers to fire engine constructors. <a target="_blank" href="http://gorton-machine.org/forms/form_933/index.html">Other</a> <a target="_blank" href="http://gorton-machine.org/forms/form_1370a/index.html">catalogs</a> <a target="_blank" href="http://gorton-machine.org/forms/form_2070/index.html">proudly listed</a> applications like book covers, billiard balls, organ keys, and toothbrushes, as well as “tools making more tools” – using Gorton engravers to create legends for other machines.
	</p>
	<p>		
		After you bought your pantograph engraver, you could buy attachments for sometimes surprising use cases:
	</p>
	
	
	
	
	<p>
		The original machine-shop pantographs were supplanted by smaller portable units (called Pantoetchers) on one side, and by increasingly complex <em>electronic</em> devices on the other. First generation of those were still huge room-size endeavors with Nixie tubes and complex interfaces labeled… in Gorton itself. 
	</p>

	
	
	
	<p>
		But the technology matured quickly and soon more and more early manual “tracer-guided” pantographs that forced the operator to put letters side by side and then trace them by hand, were superseded by <a target="_blank" href="https://en.wikipedia.org/wiki/Numerical_control">computerized ones</a>, with both the composition and the routing completely automated. They came from George Gorton Machine Co., and from competitors like New Hermes or H.P. Preis.
	</p>
	<p>				
		You no longer had to buy the chromium-plated brass alphabets weighing up to 13 pounds, choosing the right size from 3/8´´ to 3´´ ahead of time (pantographs allowed for reductions and enlargements, but only gave you a few steps within a specific range.) 
	</p>
	
	
	
	
	<p>
		Now, fonts came as digits or formulas built into computer memory, or – for a moment in time –&nbsp;as separate cartridges you’d insert in eager slots. (And yes, before you ask:&nbsp;there were <a target="_blank" href="https://archive.org/details/gorton-master-copy-type-for-all-pantograph-machines/page/n5/mode/2up">other routing monoline fonts</a>, too. But I really don’t care about any of them.)
	</p>
	
	<p>					
		It was the same story as in word processing right next door, where old-fashioned Gutenberg-era typesetting was being replaced by increasingly smaller and cheaper computers equipped with first-laughable-then-capable software.
	</p>
	<p>					
		And automation came for the Leroy branch of the tree as well. A few companies grabbed Leroy lettering templates and abstracted them away once more. They created curious small typewriter/plotter hybrids where typing letters on a keyboard would make the pen draw them on paper for you. (I own one of them, a Max Cadliner. It might be one of the strangest typewriters I’ve seen – a weird combination of a machine pretending to be another machine pretending to be a human hand.)
	</p>
	
	<div>
		<figure>
			<img src="https://aresluna.org/images/the-hardest-working-font-in-manhattan/max-cadliner/dsc07123.avif">
		</figure>
	</div>
	
	
	<p>				
		If this was a Gorton typewriter, there were also Gorton <em>computers</em>, even more sophisticated 1980s machines whose text could be programmed in advance rather than typed one line at a time, and mixed with graphics.
	</p>
	
	
	

	
	<hr>

	<h3>
		5
	</h3>
	
	<p>			
		I don’t think the – by now 80 years and counting – fractal explosion of Gorton made its original creators rich.
	</p>
	<p>			
		Copy protection in the world of typography is complicated. The font’s name can be trademarked and other companies legally prevented from using it, and you can’t just grab matrices or font files and copy them without appropriate licenses. But take any text output using a font and then redraw it – and you are within your right to do so, and even to sell the final result. At least in America, or in some other countries until somewhat recently, the shapes of the letters themselves are not legally protected.
	</p>
	<p>			
		This is why Keuffel &amp; Esser, Wood-Regan Instrument, and Letraset could potentially grab Gorton and claim it their own, as long as they didn’t name it Gorton. 
	</p>
	<p>							
		But of course, Gorton was barely named “Gorton” to begin with. In the early days of George Gorton pantographs, as the default pantograph font, it came without a name. (The font sets for purchase were called “standard copies.”) Then, as other fonts were added, it was retroactively named Gorton Normal – the name of the company and the most generic word possible.
	</p>
	<p>					
		Leroy lettering sets started with one font, so similarly to Gorton the font started to be known as “Leroy,” then “Series C,” then “Gothic.” New Hermes called it simply “Block,” Letraset went with “Engineering Standard,” and Rotring – another producer of little computerized plotters&nbsp;– with “Universal.” I’ve also seen “A style,” “Plain Gothic,” and, mysteriously, “Standpoint.” 
	</p>
	<p>							
		I don’t think this was meant to be disrespectful. “Standard,“ “Universal,” “A style” might not have had the connotations of “generic” we associate with them today, but rather meaning “the only one you need,” “approved of by millions,” or “the ultimate.”
	</p>
	<p>							
		But there <em>was</em> one name that felt somewhat inconsiderate. It appeared in one product in the 1980s, a few decades after the birth of another font whose name became recognizable and distinguished. In that product, Gorton was referred to as “Linetica.”
	</p>
	
	<div>
		<figure>
			<img src="https://aresluna.org/images/the-hardest-working-font-in-manhattan/extended/img08677.avif">
		</figure>
	</div>
		
	<figcaption>A few rare examples of Gorton Extended in use</figcaption>

	<p>						
		Each of these reappearances made small changes to the shapes of some letters. Leroy’s ampersand was a departure from Gorton’s. Others softened the middle of the digit 3, and Wrico got rid of its distinctive shape altogether. Sometimes the tail of the Q got straightened, the other times K cleaned up. Punctuation –&nbsp;commas, quotes, question marks –&nbsp;was almost always redone. But even without hunting down the proof confirming the purchase of a Gorton’s pantograph or a Leroy template set as a starting point, the lineage of its lines was obvious. (The remixes riffed off of Gorton Condensed or the normal, squareish edition… and at times both. The extended version – not that popular to begin with – was often skipped.)
	</p>

	
	<figcaption>Classic Gorton vs. Gorton Modified</figcaption>
		

	<p>						
		The only “official” update to Gorton I know of, and one actually graced with a name, was Gorton Modified. It was made some time in the 1970s by one of the main keyboard keycap manufacturers, Comptec (later Signature Plastics). It was almost a fusion of Gorton and Futura, with more rounded letterforms. Gone was the quirkiness of 3, 7, Q, C, and the strange, tired ampersand. This is the version people might recognize from some of the 1980s computers, or mechanical keyboards today. 
	</p>
	
	<p>
		It is also that last Gorton that mattered.
	</p>
	
	<figure>
		<img alt="Speed (1995)" src="https://aresluna.org/images/the-hardest-working-font-in-manhattan/movies/speed.avif">
	</figure>
	
	
	<figcaption>A collection of movies and TV shows featuring Gorton</figcaption>


	<hr>
	
	<h3>
		6
	</h3>

	<p>					
		By the time I learned about this, seven years in, I’ve become truly obsessed with Gorton and made it public by <a target="_blank" href="https://newsletter.shifthappens.site/archive/a-tale-of-three-skeuomorphs/">writing about it in my newsletter</a>. 
	</p>
	<p>							
		My every walk in Chicago or San Francisco was counting down “time to Gorton” – sometimes mere minutes before I saw a placard or an intercom with the familiar font.
	</p>
	<p>							
		This might be embarrassing to admit, but I have never been so happy seeing a font in the wild, particularly as there was almost always some new surprise – a numero, a line going through the Z, a new use, or a new imperfection. And, for a font that didn’t exist, I saw it surprisingly often.
	</p>
	
	
	
	
	

	
	<p>									
		I even spotted Gorton a few times in Spain, or the U.K., and didn’t make too much of it, not thinking about the likelihood of machines from George Gorton’s company in a small town of Racine, Wisconsin making it all the way to different continents. In hindsight I should have.
	</p>

	
	<figcaption>Gorton on old British cars, with a particularly delightful Rolls Royce logo made by a simple duplication of the classic Gorton letter R</figcaption>


	<p>						
		It was only on a trip to Australia where something started connecting. Here, once more, I saw Gorton on the streets, put to work in all sorts of unglamorous situations:
	</p>
	
	
	
	
	
	<p>							
		Some letterforms in the above photos felt slightly odd, and so did Gorton on the heavy machinery in an abandoned shipyard on an island near Sydney:
	</p>

	
	
	
	
	
	
	<p>							
		And a visit to a naval museum cemented it all:
	</p>
	
	
	
	
	
	
	

	
	
		
	
	<p>
		It was Gorton, although with some consistent quirks: 2, 5, 6, and 9 were shorter, the centers of M and W didn’t stretch all the way across, and the distinctive shape of S was slightly different here.
	</p>
	<p>							
		What on literal earth! 
	</p>
	<p>							
		Fortunately, this time around, a type designer familiar with my now-public obsession with Gorton clued me in. Gorton didn’t actually originate from Racine, Wisconsin in the late 19th century. It started a bit earlier, and quite a bit further away, at a photographic lens maker in the U.K. called Taylor, Taylor &amp; Hobson. 
	</p>
	<p>							
		In 1894, TT&amp;H needed some way to put markings on their lenses. This being late 19th century, their options were limited to manual engraving, which must have felt tricky given the small font sizes necessary. So the company did what makers sometimes do – instead of searching for a solution that might not have even existed, they made new types of machines to carve out letters, and then designed a font to be used with them.
	</p>

	
	<figure>
		<img src="https://aresluna.org/images/the-hardest-working-font-in-manhattan/lenses/img02330.avif">
	</figure>
	
	
	<p>
		I don’t know how this first proto-Gorton was designed – unfortunately, Taylor, Taylor &amp; Hobson’s history seems sparse and despite personal travels to U.K. archives, I haven’t found anything interesting – but I know simple technical writing standards existed already, and likely influenced the appearance of the newfangled routing font.
	</p>
	
	<figure>
		<img src="https://aresluna.org/images/the-hardest-working-font-in-manhattan/old-book/img01928.avif">
	</figure>
	<figcaption>From a 1895 “Free-hand lettering” book by Frank T. Daniels</figcaption>

	<p>					
		This was perhaps the first modern pantograph engraver, and perhaps even the arrival of a concept of an engraving font – the first time technical writing was able to be replicated consistently via the aid of the machine.
	</p>

	
	

	<p>			
		No wonder that other companies came knocking. Only a few years later, still deep within the 19th century, Taylor, Taylor &amp; Hobson <a target="_blank" href="http://gorton-machine.org/archives/TTH_license_1898/index.html">licensed their stuff to a fledgling American company</a> named after its founder. Gorton Model 1 was the first U.S. version of the engraver, and the TT&amp;H font must have been slightly adjusted on arrival. 
	</p>

	<figure>
		<img src="https://aresluna.org/images/the-hardest-working-font-in-manhattan/uk-old/uk-old.avif">
	</figure>
	<figcaption>A Taylor-Hobson pantograph in use in 1942</figcaption>
	
	<p>			
		This adds to the accomplishments of Gorton – the font was actually <em>older</em> than even Akzidenz-Grotesk, and has been used on World War II equipment and later on on British rifles and motorcycles (and 3,775 finger posts in <a target="_blank" href="https://www.yorkshiredales.org.uk/behind-the-signs-the-man-and-the-machine/">one of the UK’s national parks</a>), but it complicates the story of the name even more. Turns out, the font without a name has even less of a name than I suspected.
	</p>
	<p>			
		If the Taylor, Taylor &amp; Hobson (or, Taylor-Hobson, as their engravers were known) “branch” of Gorton were more used, should it usurp the at least somewhat popular Gorton name? Or should it just because it was first and the letterform changes were small? Does it matter? Where does one font end and another begin? (Unsurprisingly, TT&amp;H didn’t properly name the font either, eventually calling it “A style” for regular and “C style” for condensed variants. Google searches for “taylor hobson font” are a lot more sparse than those for Gorton.)  
	</p>
  
  
  <div>
      <p>Taylor, Taylor &amp; Hobson</p>
      <p>Gorton<br>Gorton Condensed<br>Gorton Extended</p>
      <p>Gorton Modified</p>
      <p>Leroy</p>
      <p>Hershey</p>
    </div>
  <figcaption>The Gorton quasisuperfamily</figcaption>
  
  
	<p>
		In the end, I’m sticking with Gorton for the whole branch since that feels the most well-known name, but I feel ill-equipped to make that call for everyone. You might choose to call it Gorton, Leroy, TT&amp;H, Taylor-Hobson, or one of the many other names. (Just, ideally, not Linetica.)
	</p>
	
	<div data-runner="LetterDemo" data-runner-mode="four" data-runner-id="gorton-variants" data-resize-observer-needed="true">
		
		
		<p>Taylor, Taylor &amp; Hobson</p>
		<p>Gorton</p>
		<p>Leroy</p>
		<p>Gorton Modified</p>
	</div>
	<figcaption>A comparison of all major editions of Gorton<span> (Press a key!)</span></figcaption>
		
	<hr>

	<h3>
		7
	</h3>
	
	<p>					
		And so, throughout the 20th century, Gorton has lived two parallel lives –&nbsp;one originating in the U.K. and later expanding to its colonies and the rest of Europe, and another one in America. 
	</p>
	<p>							
		I am still tracing various appearences of Gorton and perhaps you, dear reader, will help me with that. (<a target="_blank" href="https://en.wikipedia.org/wiki/Frequency_illusion">Chances are</a>, you will see Gorton later today!) I’m curious about whether Gorton made it to Eastern Europe, Africa, or Asia. I’m interested in seeing if it appeared in Germany where the objectively better-designed DIN fonts became much more popular in Gorton’s niche.
	</p>

	
			
	

			
	

	
	<p>
		The history of this strange font spans over a century and I’ve seen it in so many countries by now, used in so many situations. But it’s impossible for me to say Gorton is the most hard-working font in the world.
	</p>
	<p>							
		To this title, there are many contenders. Garamond has a head start of 300+ years and has been released in more versions than letters in any alphabet. Helvetica is so famous and used so much that even its ugly copy, Arial, became a household name. Whatever font MS Office or a popular operating system appoint to be “the default” – from Times New Roman through Calibri to Roboto – immediately enjoys the world premiere that any Hollywood movie would be envious of. There is even a 5×7 pixel font originally started by Hitachi that you can see everywhere on cheap electronic displays in cash registers and intercoms.
	</p>
	<p>							
		But there is one place in the world where Gorton pulls triple duty, and I feel confident in saying at least this: Gorton is the hardest working font in Manhattan.
	</p>
	<p>						
		In 2007, on my first trip to New York City, I grabbed my brand-new DSLR camera and photographed all the fonts I was supposed to love: American Typewriter, Helvetica, Gotham. But, in hindsight, I missed the most obvious one.
	</p>
	<p>							
		Gorton is everywhere in Manhattan. It’s there in the elevators, in the subway, on ambulances, in various plaques outside and inside buildings. And god knows it’s there on so, so many intercoms.
	</p>

	
	
	
	

	<p>					
		I wouldn’t be surprised if there weren’t a single block without any Gorton in a whole of Manhattan.
	</p>

	
	<figcaption>A complete inventory of Gorton outside, near my hotel, between 5th and 7th avenues and 25th and 35th streets. I didn’t have access to the interiors of most buildings.</figcaption>

	<p>	
		The omnipresence of Gorton makes it easy to collect all the type crimes layered on top of the font’s already dubious typographical origins. Walking through Manhattan, you can spot the abominable lowercase that should better be forgotten:
	</p>
	
	

	

	
	<p>							
		You can see all sorts of kerning mistakes:
	</p>


	
	
	
	
	<p>									
		You will notice the many, many routing imperfections – an unfinished stroke, a shaky hand, or services of a pantograph that never felt the loving touch of regular maintenance:
	</p>

	
		
	
	
	<p>
		There are all the strange decisions to haphazardly mix various styles of Gorton, or even to mix Gorton with other fonts:
	</p>
	
	
	
		
	
	<p>											
		You can even spot reappearing strange characters like a weirdly deep 3, or a flattened 4:
	</p>

	
	
		
  <p>
    I wish I understood how they came to be, but I have a hunch. The nature of pantographic reproduction is that Gorton carved into metal is not that far away from the original Gorton font template you started with! So in addition to the George Gorton and Taylor Hobson originals, and the other named and above-the-table copies, they might have been bigger or smaller Gorton <em>bootlegs</em>. I have one myself, carved into acrylic, of unknown provenance and even more nameless than I thought possible for an already name-free font.
  </p>
    
	<p>
		But New York Gorton holds pleasant surprises, too. Despite the simplicity of Gorton itself, the combinations of font sizes, cutter sizes, materials, reproductions, and applications can still yield some striking effects:
	
	</p>
	
	
	

	<div>
		<figure>
			<img src="https://aresluna.org/images/the-hardest-working-font-in-manhattan/nyc-beautiful/img03300.avif">
		</figure>
	</div>
	
	
	


	<figure>
			<img src="https://aresluna.org/images/the-hardest-working-font-in-manhattan/map-manhattan/map.avif">
		</figure>
		<figcaption>
			All my Gorton walks in Manhattan in 2024
		</figcaption>

		This was what made me walk 100 miles. Over and over again, Gorton found ways to make itself interesting. Without hyperbole, I consider the above photos simply beautiful.
	
	

	<p>
		In a city that never sleeps, Gorton wasn’t allowed to sleep, either. Even in the richest and most glamorous neighborhoods of Manhattan, the font would be there, doing the devil’s work without complaining. Gorton made Gotham feel bougie; American Typewriter touristy.
	</p>
	
	<p>
		And once in a while, I’d find Gorton that would wink at me with a story –&nbsp;followed by that aching in the heart as I realized I’d never know what the story was.
	</p>
	
	

	
	<hr>
	
	<h3>
		8
	</h3>
	<p>			
		You’re not supposed to fall in love with an ugly font. No one collects specimens of Arial. No one gets into eBay fights for artifacts set in Papyrus. No one walks a hundred miles in a hot New York summer, sweating beyond imagination, getting shouted at by security guys, to capture photos of Comic Sans.
	</p>
	<p>							
		So why do I love Gorton so much? 
	</p>
	<p>							
		The Occam’s Razor seems sharp on this one. Perhaps I like it because I’m a boy and Gorton is often attached to heavy machinery. 
	</p>
	<p>
		Or perhaps I have a strange affection to quirky hard-working fonts created by people who did not come from the world of type: the <a target="_blank" href="https://en.wikipedia.org/wiki/Toronto_Subway_(typeface)">Toronto Subway font</a>, <a target="_blank" href="https://www.ltmuseum.co.uk/collections/stories/people/edward-johnston-man-behind-londons-lettering">London Underground font</a>, or <a target="_blank" href="https://en.wikipedia.org/wiki/Computer_Modern">Computer Modern</a>. 	(This essay is typeset in a strangely-spaced version of Century put together for <a target="_blank" href="https://archive.org/details/ibm-selectric-composer-type-style-portfolio/page/18/mode/2up">Selectric Composer typewriters</a> and <a target="_blank" href="https://www.kutilek.de/selectric/">recreated for on-screen use</a>. If that didn’t bother you before, it will bother you through the rest of this article.)
	</p>
	<p>				
		But there must be more to it. Perhaps it’s all about the strange contrasts Gorton represents. The font is so ubiquitous, but also profoundly unrecognizable, sporting no designer and no name. Gorton is a decidedly toy-like, amateurish font deployed to for some of the most challenging type jobs: nuclear reactors, power plants, spacecraft. More than most other fonts, Gorton feels it’s been made by machines for machines –&nbsp;but in its use, it’s also the font that allows you to see so many human mistakes and imperfections.
	</p>
	<p>				
		Gorton also feels mistake-friendly. The strange limitations of Gorton mean that some of the transgressions of other fonts don’t apply here. The monoline nature of the font means that messing with the size of Gorton is okay: Shrinking the font for small caps or superscript, for example, gives you still-valid letterforms, almost by accident. 
	</p>

	
	
	<p>
		Stretching or slanting Gorton is not as much a typographical crime as it would be with other fonts because you don’t stretch the tip of the router itself.
	</p>
	
	

	
	<p>							
		There are genuinely moments where I felt Gorton gave people freedoms to maul it decades before variable fonts allowed us similar flexibiity.
		And on top of that, the simplicity of the letterforms themselves feels compatible with the typical naïveté of Gorton’s typesetting. 
	</p>
	
	
	<div>
		<figure>
			<img src="https://aresluna.org/images/the-hardest-working-font-in-manhattan/sizing-paths/leroy1.avif">
		</figure>
	</div>
		
	<figcaption>Various accessories and attachments allowing you to shift Gorton around in a way other fonts would not allow</figcaption>
	
	<p>
    Sure, there are really bad renditions that are inexcusable. 

		But most of the time, the imperfections and bad decisions are what makes Gorton come alive. They don’t feel like a profound misunderstandings of typography, typesetting, or Gorton itself. They don’t feel like abuses or aberrations. No, they feel exactly how Gorton was supposed to be used – haphazardly, without much care, to solve a problem and walk away. (Later routing fonts copied Helvetica, but seeing Helvetica in this context with all the same mistakes grates so much more.)
	</p>

	<p>			
		The transgressions are not really transgressions. They all feel honest. The font and its siblings just show up to work without pretense, without ego, without even sporting a nametag. Gorton isn’t meant to be admired, celebrated, treasured. It’s meant to do some hard work and never take credit for it. Gorton feels like it was always a font, and never a typeface. (Depending on how rigid you are with your definitions, some versions of Gorton – especially those without instructions on how letters are positioned against each other – might not even <a target="_blank" href="https://mastodon.design/@fhardwig@mastodon.social/113515144112560218">classify as a font</a>!)
	</p>
		
	<p>					
		And I think I love Gorton because over the years I grew a little tired of the ultra flat displays rendering miniature pixels with immaculate precision. 	
		With Gorton, carving into metal or plastic means good-looking fixes are impossible:
	</p>
	
	
	

	<p>
		And unsurprising given its roots, Gorton has dimensionality that most fonts cannot ever enjoy: A routing tip picked in the 1980s and a sun coming in from just the right angle forty years later can create a moment that thousands of letterpress cards can only dream of.
	</p>
	
	
	
	
	
	<p>
		Perhaps above everything else, Gorton is all about <em>texture</em>. 
  </p>
  <p>
    Every kind of engraving has it, of course. But these are not precise submillimeter letters at the bottom of your MacBook Pro or Apple Watch. This is the utilitarian, often harried, sometimes downright <em>careless</em> Gorton, carved into steel of a  
		mid-century intercom and filled in with <a target="_blank" href="https://youtu.be/llzdLgMurvw?si=8S7px9gg8iH4iav2&amp;t=101">special paste or wax</a>, or put on an office placard made out of a special two-layer material made especially so engraving it reveals the second color underneath, without the need for infill. 
	</p>

	
	
	
	
	
	<p>			
		(This is also true when it comes to the original reason I learned of Gorton. Letters on keycaps show the same artifacts – you just have to look very, very closely.)
	</p>

	<figure>
		<img src="https://aresluna.org/images/the-hardest-working-font-in-manhattan/keycap-engraving/cropped.avif">
	</figure>
	
	<p>
		That’s the last, and perhaps the best thing to fall in love with. 
	</p>
		
	<p>
		You won’t be able to fully appreciate it here, of course, but maybe this will give an approximation of how beautiful Gorton’s non-beauty can be:
	</p>
	
	<div data-runner="Typer" data-runner-id="type" data-resize-observer-needed="true">
			
			
			
			<p><label>
					
					Taylor, Taylor &amp; Hobson
				</label>
				<label>
					
					Gorton
				</label>
				<label>
					
					Gorton Condensed
				</label>
				<label>
					
					Leroy
				</label>
				<label>
					
					Gorton Modified
				</label>
			</p>		
		</div>



	<hr>
	
	<h3>
		9
	</h3>
	

	<p>					
		This has been a strange thing to write. Gorton has been around for over 135 years and used in so many countries for so many reasons, and yet I found no single article about it. 
	</p>
	<p>					
		I feel the burden of being an amateur historian, wanting to know and share so much more, but only being able to provide little. I don’t know the full extent of Gorton’s use. I don’t know who designed it. My chronology is rickety and pieced together from a few breadcrumbs. I dream of seeing the original drawings or drafts once laid on the tables of Taylor, Taylor &amp; Hobson offices, or some notes, or some correspondence. I fear they might no longer exist.
	</p>


	<p>					
		Also, if part of the allure of Gorton is shying away from the limelight and not being admired, am I doing it a disservice by writing about it?
	</p>
	<p>					
		But mostly, I can’t shake the feeling that we all missed a window. That this essay can’t be just a celebration, but also needs to be the beginnings of a eulogy.
	</p>
	
	
	<div>
		<figure>
			<img src="https://aresluna.org/images/the-hardest-working-font-in-manhattan/covered-by-other-fonts/img02846.avif">
		</figure>
	</div>
		
	
	
	<p>					
		Walking around New York, you get a sense that even Gorton carved into metal can disappear. Some of the signs are rusted or destroyed beyond repair. Others get replaced by more modern, charmless equivalents.
	</p>
	<p>							
		Gorton itself is obsolete. All <a target="_blank" href="https://spkeyboards.com/">the keyboards that use Gorton Modified</a> you can still buy new today are tipping a hat to nostalgia. The omnipresence of Gorton in New York City is already time shifted from its decades of glory, a simple confirmation of what Robert Moses knew so well: that once built, cities don’t change all that much. But few of the new placards use Gorton, and none of the new intercoms do. 
	</p>
	<p>
		Taylor, Taylor &amp; Hobson went through multiple splits and mergers and survives as a subsidiary of Ametek, chiefly working on measuring devices. George Gorton Machine Co. from Racine has been bought by Kearny &amp; Trecker, which became Cross &amp; Trecker, was acquired by Giddings &amp; Lewis, and then acquired <em>again</em> by ThyssenKrupp, but not before the Gorton branch was spun off as Lars, and in a sequence of events now resembling a telenovella, eventually bought by Famco in 1987. I do not believe any corporate grandchildren of TT&amp;H and George Gorton’s company are today selling Gorton in any capacity.
	</p>
	<p>							
		It will take decades, perhaps even centuries, but one day the last of this font will be gone. The modern recreations (<a target="_blank" href="https://aresluna.org/the-hardest-working-font-in-manhattan/recreations">I eventually found quite a few</a>) won’t help. They are perhaps all missing a point, anyway.
	</p>

	<p>
		But there’s a somewhat silver lining. Yes, when Gorton is carved into fresh metal, there might be nothing more pretty than seeing its depths glistening in the sun.
	</p>
	
	
	

	
	<p>
		But fresh, shining metal is at this point rare. Fortunately, the Gorton I love most is the weathered Gorton.
	</p>
	
	
	
	
	<p>							
		Manhattan’s tired Gorton is the best variant of Gorton: infill cracked by hot summers followed by frigid winters, the surface scratched by keys or worn out by many finger presses, the routing snafus meeting decades of wear and tear. Gorton’s no stranger to water, snow, rust, or dirt.
	</p>
	
	
	
	
	
	
	<p>		
		This is, perhaps, how you become gortonpilled. You learn to recognize the 7 with a crooked hook, the Q with a swung dash, the strange top-heavy 3, the simple R. You start noticing the endings of each character being consistently circular, rather than occasionally flat. A routing mistake, suspicious kerning, or the absence of lowercase are not a wrongdoing – they’re a <em>confirmation</em>.
	</p>
	
		
	
	
	
	
	
	<p>							
		You find yourself enchanted with how this simple font went so very far. And then you touch the letters, just to be sure. If you can <em>feel</em> them, chances are this is Gorton.		
	</p>

		
		
		
		
		
		
		
		

	</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Iconic 3DBenchy Enters the Public Domain (164 pts)]]></title>
            <link>https://www.nti-group.com/home/information/news/3dbenchy/</link>
            <guid>43053350</guid>
            <pubDate>Fri, 14 Feb 2025 21:39:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nti-group.com/home/information/news/3dbenchy/">https://www.nti-group.com/home/information/news/3dbenchy/</a>, See on <a href="https://news.ycombinator.com/item?id=43053350">Hacker News</a></p>
Couldn't get https://www.nti-group.com/home/information/news/3dbenchy/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Is anybody building an alternative transformer? (132 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=43052427</link>
            <guid>43052427</guid>
            <pubDate>Fri, 14 Feb 2025 20:00:12 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=43052427">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="43052946"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43052946" href="https://news.ycombinator.com/vote?id=43052946&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div><p>The MAMBA [1] model gained some traction as a potential successor. It's basically an RNN without the non linearity applied across hidden states, which makes it logarithmic time (instead of linear time) inference with a parallelizable scan [2].</p><p>It promises much faster inference with much lower compute costs, and I think up to 7B params, performs on par with transformers. I've yet to see a 40B+ model trained.</p><p>The researches of MAMBA went on to start a company called Cartesia [3], which is MAMBA applied to voice models</p><p>[1] <a href="https://jackcook.com/2024/02/23/mamba.html" rel="nofollow">https://jackcook.com/2024/02/23/mamba.html</a></p><p>[2] <a href="https://www.csd.uwo.ca/~mmorenom/HPC-Slides/Parallel_prefix_sum.pdf" rel="nofollow">https://www.csd.uwo.ca/~mmorenom/HPC-Slides/Parallel_prefix_...</a> &lt;- Pulled up a random example from google, but Stanford CS149 has an entire lecture devoted to parallel scan.</p><p>[3] <a href="https://cartesia.ai/" rel="nofollow">https://cartesia.ai/</a></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43053811"><td></td></tr>
            <tr id="43053142"><td></td></tr>
                <tr id="43053502"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43053502" href="https://news.ycombinator.com/vote?id=43053502&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div>
                  <p>If I'm not misremembering, Mistral released a model based on MAMBA, but I haven't heard much about it since.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="43054371"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43054371" href="https://news.ycombinator.com/vote?id=43054371&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div><p>I have an internal repo that does guided window attn. I figured out that One Weird Trick to get the model to learn how to focus so that you can move a fixed window around instead of full attn. I also built NNMemory (but that appears to be an idea others hae had now too [1]) and I have a completely bonkers mechanism for non-determanistic exit logic so that the model can spin until it thinks it has a good answer. I also built scale free connections between layers to completely remove residual connections. Plus some crazy things on sacrificial training (adding parameters that are removed after training in order to boost training performance with no prod penalty). There are more crazy things I have built but they aren't out there in the wild, yet. Some of the things I have built are in my repo. [2] I personally think we can get .5b models to outperform 8b+ SOTA models out there today (even the reasoning models coming out now)</p><p>The basic transformer block has been good at kicking things off, but it is now holding us back. We need to move to recurrent architectures again and switch to fixed guided attn windows + 'think' only layers like NNMemory. Attn is distracting and we know this as humans because we often close our eyes when we think hard about a problem on the page in front of us.</p><p>[1] <a href="https://arxiv.org/abs/2502.06049" rel="nofollow">https://arxiv.org/abs/2502.06049</a></p><p>[2] <a href="https://github.com/jmward01/lmplay">https://github.com/jmward01/lmplay</a></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="43053011"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43053011" href="https://news.ycombinator.com/vote?id=43053011&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div><p>Check out "Attention as an RNN" by Feng et al (2024), with Bengio as a co-author. <a href="https://arxiv.org/pdf/2405.13956" rel="nofollow">https://arxiv.org/pdf/2405.13956</a></p><p>Abstract: The advent of Transformers marked a significant breakthrough in sequence modelling, providing a highly performant architecture capable of leveraging GPU
parallelism. However, Transformers are computationally expensive at inference
time, limiting their applications, particularly in low-resource settings (e.g., mobile
and embedded devices). Addressing this, we (1) begin by showing that attention
can be viewed as a special Recurrent Neural Network (RNN) with the ability to
compute its many-to-one RNN output efficiently. We then (2) show that popular
attention-based models such as Transformers can be viewed as RNN variants.
However, unlike traditional RNNs (e.g., LSTMs), these models cannot be updated
efficiently with new tokens, an important property in sequence modelling. Tackling
this, we (3) introduce a new efficient method of computing attention’s many-tomany RNN output based on the parallel prefix scan algorithm. Building on the
new attention formulation, we (4) introduce Aaren, an attention-based module that
can not only (i) be trained in parallel (like Transformers) but also (ii) be updated
efficiently with new tokens, requiring only constant memory for inferences (like
traditional RNNs). Empirically, we show Aarens achieve comparable performance
to Transformers on 38 datasets spread across four popular sequential problem
settings: reinforcement learning, event forecasting, time series classification, and
time series forecasting tasks while being more time and memory-efficient.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="43052967"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43052967" href="https://news.ycombinator.com/vote?id=43052967&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div><p>Personally I think foundation models are for the birds,  the cost of developing one is immense and the time involved is so great that you can't do many run-break-fix cycles so you will get nowhere on a shoestring.  (Though maybe you can get somewhere on simple tasks and synthetic data)</p><p>Personally I am working on a <i>reliable</i> model trainer for classification and sequence labeling tasks that uses something like ModernBERT at the front end and some kind of LSTM on the back end.</p><p>People who hold court on machine learning forums will swear by fine-tuned BERT and similar things but they are not at all interested in talking about the reliable bit.  I've read a lot of arXiv papers where somebody tries to fine-tune a BERT for a classification task,  runs some arbitrarily chosen parameters they got out of another paper and it sort-of works some of the time.</p><p>It drives me up the wall that you can't use early stopping for BERT fine-tuning like I've been using on neural nets <i>since 1990 or so</i> and if I believe what I'm seeing I don't think the networks I've been using for BERT fine-tuning can really benefit from training sets with more than a few thousand examples,  emphasis on the "few".</p><p>My assumption is that everybody else is going to be working on the flashy task of developing better foundation models and as long as they emit an embedding-per-token I can plug a better foundation model in and my models will perform better.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43053633"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43053633" href="https://news.ycombinator.com/vote?id=43053633&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div><p>&gt; Personally I think foundation models are for the birds,</p><p>I might not quite that far, but I have publicly said (and will stand by the statement) that I think that training progressively larger and more complex foundation models is a waste of resources. But my view of AI is rooted in a neuro-symbolic approach, with emphasis on the "symbolic". I envision neural networks not as the core essence of an AI, but mainly as just adapters between different representations that are used by different sub-systems. And possibly as "scaffolding" where one can use the "intelligence" baked into an LLM as a bridge to get the overall system to where it can learn, and then eventually kick the scaffold down once it isn't needed anymore.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43053830"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43053830" href="https://news.ycombinator.com/vote?id=43053830&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div>
                  <p>We learned something pretty big and surprising from each new generation of LLM, for a small fraction of the time and cost of a new particle accelerator or space telescope. Compared to other big science projects, they're giving pretty good bang for the buck.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="43053726"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43053726" href="https://news.ycombinator.com/vote?id=43053726&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div><p>I can sure talk your ear off about that one as I went way too far into the semantic web rabbit hole.</p><p>Training LLMs to use 'tools' of various types is a great idea,  as it is to run them inside frameworks that check that their output satisfies various constraints.  Still certain problems like the NP-complete nature of SAT solving (and many intelligent systems problems,  such as word problems you'd expect an A.I. to solve,  boil down to SAT solving) and problems such as the halting problem, Godel's theorem and such are still problems.  I understand Doug Hofstader has softened his positions lately,  but I think many of the problems set up in this book</p><p><a href="https://en.wikipedia.org/wiki/G%C3%B6del,_Escher,_Bach" rel="nofollow">https://en.wikipedia.org/wiki/G%C3%B6del,_Escher,_Bach</a></p><p>(particularly the Achilles &amp; Tortoise dialog) still stand today,  as cringey as that book seems to me in 2025.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43054567"><td></td></tr>
            <tr id="43053992"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_43053992" href="https://news.ycombinator.com/vote?id=43053992&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div>
                  <p>As somebody who considers himself something of a Semantic Web enthusiast / advocate, and has also read GEB, I can totally relate. To me, this is really one of those "THE ISSUE" things: how can we use some notion of formal logic to solve problems, without being forced to give up hope due to incompleteness and/or the Halting Problem. Clearly you have to give up something as a tradeoff for making this stuff tractable, but I suppose it's an open question what you can tradeoff and how exactly that factors into the algorithm, as well as what guarantees (if any) remain...</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="43054713"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_43054713" href="https://news.ycombinator.com/vote?id=43054713&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div>
                  <p>I would start with the fact that there is nothing consistent or complete about humans.  Penrose's argument that he is a thetan because he can do math doesn't hold water.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="43053782"><td></td></tr>
                <tr id="43054046"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_43054046" href="https://news.ycombinator.com/vote?id=43054046&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div><p>Well, to the extent that people equate GOFAI with purely symbolic / logic-based processing, then no, not for my money anyway. I think it's possible to construct systems that use elements of symbolic processing along with sub-symbolic approaches and get useful results. I think of it as (although this is something of an over-simplification) taking symbolic reasoning, relaxing some of the constraints that go along with the guarantees that method makes out the outputs, and accepting a (hopefully only slightly) less desirable output. OR, think about flipping the whole thing around, get an output from, say, an LLM where there might be hallucination(s), and then use a symbolic reasoning system to post-process the output to ensure veracity before sending it to the user. Amazon has done some work along those lines, for example. <a href="https://aws.amazon.com/blogs/machine-learning/reducing-hallucinations-in-large-language-models-with-custom-intervention-using-amazon-bedrock-agents/" rel="nofollow">https://aws.amazon.com/blogs/machine-learning/reducing-hallu...</a></p><p>Anyway this is all somewhat speculative, and I don't want to overstate the "weight" of anything I seem to be claiming here. This is just the direction my interests and inclinations have taken me in.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43055078"><td></td></tr>
                                    <tr id="43052682"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43052682" href="https://news.ycombinator.com/vote?id=43052682&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div><p>The xLSTM could become a good alternative to transformers: <a href="https://arxiv.org/abs/2405.04517" rel="nofollow">https://arxiv.org/abs/2405.04517</a>. On very long contexts, such as those arising in DNA models, these models perform really well.</p><p>There's a big state-space model comeback initiated by the S3-Mamba saga. RWKV, which is a hybrid between classical RNNs and transformers, is also worth mentioning.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43052766"><td></td></tr>
                  <tr id="43054358"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43054358" href="https://news.ycombinator.com/vote?id=43054358&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div><p>I tried... it started with the idea was that log loss might not be the best option for training, and maybe it should be a loss related to how wrong the predicted word was. Predicting "dog" instead of "cat" should be less penalised than predicting "running".</p><p>That turns out to be an ultrametric loss, and the derivative of an ultrametric loss is zero in a large region around any local minimum, so it can't be trained by gradient descent -- it has to be trained by search.</p><p>Punchline: it's about one million times less effective than a more traditional architecture. <a href="https://github.com/solresol/ultratree-results">https://github.com/solresol/ultratree-results</a></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="43052930"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43052930" href="https://news.ycombinator.com/vote?id=43052930&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div>
                  <p>Related: There was buzz last year about Kolmogorov Arnold Networks, and <a href="https://arxiv.org/abs/2409.10594" rel="nofollow">https://arxiv.org/abs/2409.10594</a> was claiming KANs perform better than standard MLPs in the transformer architecture. Does anyone know of these being explored in the LLM space? KANs seem to have better properties regarding memory if I'm not mistaken.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="43053514"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43053514" href="https://news.ycombinator.com/vote?id=43053514&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div><p>I believe KAN hype died off due to practical reasons (e.g. FLOPs from implementation) and empirical results, i.e. people reproduced KANs and they found the claims/results made in the original paper were misleading.</p><p>Here's a paper showing KANs are no better than MLPs, if anything they are typically worse when comparing fairly. <a href="https://arxiv.org/pdf/2407.16674" rel="nofollow">https://arxiv.org/pdf/2407.16674</a></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="43052705"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43052705" href="https://news.ycombinator.com/vote?id=43052705&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div><p>There are alternatives that optimize around the edges. Like Deepseek’s Multi-head Latent Attention, or Grouped Query Attention. DeepSeek also showed an optimization on Mixture of Experts. These are all clear improvements to the Vaswani architecture.</p><p>There are optimizations like extreme 1.58 bit quant that can be applied to anything.</p><p>There are architectures that stray farther. Like SSMs and some attempts at bringing the RNN back from the dead. And even text diffusion models that try to generate paragraphs like we generate images i.e. not word by word.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43053804"><td></td></tr>
                  <tr id="43052663"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43052663" href="https://news.ycombinator.com/vote?id=43052663&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div>
                  <p>I hate that popular domains take ownership of highly generic words. Many years ago, I struggled for a while to understand that when people say "frontend" they often mean a website frontend, even without any further context.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="43052788"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43052788" href="https://news.ycombinator.com/vote?id=43052788&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div><p>The worst offender is "feature". In my domain (ML and geo) we have three definitions.</p><p>Feature could be referring to some addition to the user-facing product, a raster input to machine learning, or a vector entity in GeoJSON. Context is the only tool we have to make the distinction, it gets really confusing when you're working on features that involve querying the features with features.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43053143"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43053143" href="https://news.ycombinator.com/vote?id=43053143&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div><p>You can say the same thing about “model” even in ML. Depending on the context it can be quite confusing:</p><p>1) an architecture described in a paper</p><p>2) the trained weights of a specific instantiation of architecture</p><p>3) a chunk of code/neural net that accomplishes a task, agnostic to the above definitions</p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="43052945"><td></td></tr>
                <tr id="43053114"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43053114" href="https://news.ycombinator.com/vote?id=43053114&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div><p>52x less energy is crazy. Seems like it's in the veeery early stages, though, a quick search basically only yields the original paper and articles about it. This comment from the creator really shines light on the novel approach, though, which I find oddly antagonistic towards Big Tech:</p><p>"Where the Tsetlin machine currently excels is energy-constrained edge machine learning, where you can get up to 10000x less energy consumption and 1000x faster inference (<a href="https://www.mignon.ai/" rel="nofollow">https://www.mignon.ai</a>).
My goal is to create an alternative to BigTech’s black boxes: free, green, transparent, and logical (<a href="http://cair.uia.no/" rel="nofollow">http://cair.uia.no</a>)." (<a href="https://www.reddit.com/r/MachineLearning/comments/17xoj68/comment/k9qsl6u/" rel="nofollow">https://www.reddit.com/r/MachineLearning/comments/17xoj68/co...</a>)</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43053336"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43053336" href="https://news.ycombinator.com/vote?id=43053336&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div>
                  <p>It's true that Tsetlin Machines are currently a fringe area of ML research, especially compared to the focus on deep learning advancements coming out of SF and China. It's early days, but the energy efficiency potential is insane. I believe further investment could yield significant results. Having been supervised by the creator, I'm admittedly biased, but the underlying foundation in Tsetlin's learning automata gives it a solid theoretical grounding. Dedicated funding is definitely needed to explore its full potential.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="43052857"><td></td></tr>
                <tr id="43053423"><td></td></tr>
                  <tr id="43053299"><td></td></tr>
            <tr id="43054647"><td></td></tr>
            <tr id="43053945"><td></td></tr>
            <tr id="43053167"><td></td></tr>
            <tr id="43052643"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43052643" href="https://news.ycombinator.com/vote?id=43052643&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div>
                  <p>I've a design in mind which is very simple and interesting but don't know if it would be scalable to the stage, rn it's just a superficial design inspired by IronMan's JARVIS, i'm working on preparing the architecture.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="43052929"><td></td></tr>
            <tr id="43052827"><td></td></tr>
            <tr id="43053333"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43053333" href="https://news.ycombinator.com/vote?id=43053333&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div>
                  <p>AI aside, the world could also use an alternative electric transformer. The backlog from main suppliers is 40+ weeks and far too expensive. There is a MAJOR manuf and supply issue here as all new build construction competes for same equipment...</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="43054158"><td></td></tr>
            <tr id="43053380"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43053380" href="https://news.ycombinator.com/vote?id=43053380&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div>
                  <p>My guess is that new architectures will be about doing more with less compute. For example, are there architectures that can operate at lower bit precision or better turn off and on components as required by the task?</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="43054234"><td></td></tr>
            <tr id="43053524"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43053524" href="https://news.ycombinator.com/vote?id=43053524&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div>
                  <p>I’m working with a group on an RL core with models as tool use, for explainable agentic tasks with actual discovery.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="43052746"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43052746" href="https://news.ycombinator.com/vote?id=43052746&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div><p>Literally everybody doing cutting edge AI research is trying to replace the transformer, because transformers have a bunch of undesirable properties like being quadratic in context window size. But they're also surprisingly resilient: despite the billions of dollars and man-hours poured into the field and many attempted improvements, cutting-edge models aren't all that different architecturally from the original attention paper, aside from their size and a few incidental details like the ReLU activation function, because nobody has found anything better yet.</p><p>I do expect transformers to be replaced eventually, but they do seem to have their own "bitter lesson" where trying to outperform them usually ends in failure.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43053055"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43053055" href="https://news.ycombinator.com/vote?id=43053055&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div>
                  <p>My guess is there is a cost-capability tradeoff such that the O(N^2) really is buying you something you couldn't get for O(N).  Behind that,  there really are intelligent systems problems that boil down to solving SAT and should be NP-complete...  LLMs may be able to short circuit those problems and get lucky guesses quite frequently,  maybe the 'hallucinations' won't go away for anything O(N^2).</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="43054492"><td></td></tr>
            <tr id="43052596"><td></td></tr>
                <tr id="43052870"><td></td></tr>
            <tr id="43052613"><td></td></tr>
            <tr id="43052718"><td></td></tr>
                <tr id="43052873"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43052873" href="https://news.ycombinator.com/vote?id=43052873&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div>
                  <p>Yeah, it's literally the most important practical development in AI/ML of the decade. This is like reading an article (or headline, more like) on HN and saying "please define git".</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="43053007"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_43053007" href="https://news.ycombinator.com/vote?id=43053007&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div><p>Not everyone is aware of the details of AI/ML, "transformer" is actually a specific term in the space that also overlaps with "transformer" in other fields adjacent to Software Development. This is when we all need to wear our empathy hat and remind ourselves that we exist in a bubble, so when we see an overloaded term, we should add even the most minimal context to help. OP could have added "AI/ML" in the title for minimal effort and real estate. Let's not veer towards the path of elitism.</p><p>Also, the majority of developers using version control are using Git. I guarantee the majority of developers outside the AI/ML bubble do not know what a "transformer" is.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43053056"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_43053056" href="https://news.ycombinator.com/vote?id=43053056&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div><p>Fair enough! Bubble or not, I certainly have very regularly (weekly?) seen headlines on hn about transformers for at least a few years now. Like how bitcoin used to be on hn frontpage every week for a couple years circa 2010 (to the derision of half of the commenters). Not everyone is in the crypto space, but they know what bitcoin is.</p><p>Anyhow I suppose the existence of such questions on hn is evidence that I'm in more of a bubble that I esteemed, thanks for the reality check :)</p><p>(also my comment was in defense of parent who linked the wiki page, which defines transformer as per request, and is being downvoted for that)</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43053537"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_43053537" href="https://news.ycombinator.com/vote?id=43053537&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div>
                  <p>I, too, haven't seen the word "transformer" outside an ML context in months. Didn't stop me from wondering if the OP meant the thing that changes voltage.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="43053311"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_43053311" href="https://news.ycombinator.com/vote?id=43053311&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div><p>&gt;This is like ... saying "please define git"</p><p>It's really not. "Git" has a single extremely strong definition for tech people, and a single regional slang definition. "Transformer" has multiple strong definitions for tech people, and multiple strong definitions colloquially.</p><p>Not that we can't infer the OP's meaning - just that it's nowhere near as unambiguous as "git".</p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="43052629"><td></td></tr>
            <tr id="43052893"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43052893" href="https://news.ycombinator.com/vote?id=43052893&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div>
                  <p>Right now as long as the rocket's heading straight up, everyone's on board with MLPs (Multilayer Perceptrons/Transformers)! Why not stay on the same rocket for now!? We're almost at AGI already!</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="43053115"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_43053115" href="https://news.ycombinator.com/vote?id=43053115&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div><p>I wouldn't conflate MLPs with transformers, MLP is a small building block of almost any standard neural architecture (excluding spiking/neuromorphic types).</p><p>But to your point, the trend towards increasing inference-time compute costs, being ushered by CoT/reasoning models is one good reason to look for equally capable models that can be optimized for inference efficiency. Traditionally training was the main compute cost, so it's reasonable to ask if there's unexplored space there.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="43053799"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43053799" href="https://news.ycombinator.com/vote?id=43053799&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div>
                  <p>What I meant by "NNs and Transformers" is that once we've found the magical ingredient (and we've found it) people tend to all be focused in the same area of research. Mankind just got kinda lucky that all this can run on essentially game graphics boards!</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="43053160"><td></td></tr>
                <tr id="43053761"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_43053761" href="https://news.ycombinator.com/vote?id=43053761&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div>
                  <p>I consider MLPs the building blocks of all this, and is what makes things a neural net, as opposed to some other data structure.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="43054482"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_43054482" href="https://news.ycombinator.com/vote?id=43054482&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div><p>Sure. But that isn’t a reason to conflate the two?</p><p>OP wasn’t suggesting looking for an alternative/successor to MLPs, but for an alternative/successor to transformers (while presumably still using MLPs) in the same way that transformers are an alternative/successor to LSTMs.</p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="43052844"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_43052844" href="https://news.ycombinator.com/vote?id=43052844&amp;how=up&amp;goto=item%3Fid%3D43052427"></a></center>    </td><td><br><div>
                  <p>Yes. Happy to chat if u msg me. Using RL coupled with NNs to integrate search directly into inference instead of as an afterthought like Chain of though and test time training.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="43053171"><td></td></tr>
                <tr id="43053449"><td></td></tr>
            <tr id="43053383"><td></td></tr>
                        </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: LinkedIn is the worst social media I've ever seen (237 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=43052409</link>
            <guid>43052409</guid>
            <pubDate>Fri, 14 Feb 2025 19:58:56 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=43052409">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="43052409">
      <td><span></span></td>      <td><center><a id="up_43052409" href="https://news.ycombinator.com/vote?id=43052409&amp;how=up&amp;goto=item%3Fid%3D43052409"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=43052409">LinkedIn is the worst social media I've ever seen</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_43052409">152 points</span> by <a href="https://news.ycombinator.com/user?id=bitreducer">bitreducer</a> <span title="2025-02-14T19:58:56 1739563136"><a href="https://news.ycombinator.com/item?id=43052409">2 hours ago</a></span> <span id="unv_43052409"></span> | <a href="https://news.ycombinator.com/hide?id=43052409&amp;goto=item%3Fid%3D43052409">hide</a> | <a href="https://hn.algolia.com/?query=LinkedIn%20is%20the%20worst%20social%20media%20I%27ve%20ever%20seen&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=43052409&amp;auth=8fc277ffc62b1a6ce28709c1f559aa8a122f614f">favorite</a> | <a href="https://news.ycombinator.com/item?id=43052409">76&nbsp;comments</a>        </span>
              </td></tr>
    <tr><td></td></tr><tr><td colspan="2"></td><td><div><p>Besides being full of AI-generated, useless content, the platform is also riddled with dark patterns.</p><p>I'm a newcomer, I’d never used LinkedIn before until I joined three months ago. Since then, I've been banned twice and shadow-banned several times.</p><p>1) Right after I created my account, I got shadow-banned. My friends couldn’t find me, and my profile wasn’t accessible via direct link. This issue wasn’t resolved until I contacted support; they confirmed that restrictions had been placed on my account and then removed them.</p><p>2) I shouldn’t even have to mention this, but as a professional in my field, after that incident I always ended up on the very last pages of search results for keywords related to my field. People without those keywords in their resumes, or whose work isn’t at all related to the field, kept being ranked ahead of me. I can’t say I was deliberately pessimized, but that’s exactly how it appears.</p><p>3) Some time later, I decided to get Premium and paid with my own card (issued in another country, with the same name as on my profile and my passport). That’s when I received the first restriction: I was locked out of my account and couldn’t sign in until I contacted support. They made me take a photo of myself and of my passport, and after that they lifted the restrictions and apologized.</p><p>4) Everything seemed to be going along normally, yet I remained stuck on the last pages of search, being outranked by completely irrelevant profiles, until I decided to write a post about my own article on Medium. Immediately after publishing the post with a link to Medium, I received a second restriction. I was locked out of my account, couldn’t access my messages or interview invitations, and even missed a call because of this. They once again required me to submit a photo of myself along with a copy of my passport. Although they eventually restored my account, this time the process took 4–5 days, which caused me to miss an interview.</p><p>5) Now my profile is accessible via direct link, but I’ve disappeared from search. No one can find me, and hardly anyone visits my page. My post was hidden while support was "sorting out" my account, and I lost all the potential post views it would have gained because it wasn't featured in the recommendations.</p><p>All of this happened within the first three months of using LinkedIn. I’ve never seen a more appalling social media, one so full of dark patterns and outright abuse towards its users, forcing them through humiliating identity verification processes and hiding them from search.</p><p>Needless to say, I have never violated any of the platform’s rules. I don’t spam, I don’t bother people, and I don’t advertise anything. Meanwhile, my friend, whose account is over five years old—can do whatever he wants. He uses VPNs, changes his profile location several times a week, and switches his VPN location from Dubai to Europe multiple times a day without ever facing any restrictions.</p><p>And yes, I completely forgot to add: when your account gets restricted, it doesn’t matter whether you’re a premium user or not — the treatment is equally poor and the response is equally slow.</p><p>I’ve never seen a worse social media, and I’d be thrilled if a worthy competitor to LinkedIn ever emerged, I’d be one of the first to join.</p><p>BONUS: This content was originally posted on reddit, quickly became popular in the LinkedIn subreddit and was then deleted by moderator who works for M$ (which owns LinkedIn). Frankly, it feels like the whole LinkedIn subreddit is highly censored by him.</p></div></td></tr>        <tr><td></td></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sunsetting Create React App (103 pts)]]></title>
            <link>https://react.dev/blog/2025/02/14/sunsetting-create-react-app</link>
            <guid>43051961</guid>
            <pubDate>Fri, 14 Feb 2025 19:16:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://react.dev/blog/2025/02/14/sunsetting-create-react-app">https://react.dev/blog/2025/02/14/sunsetting-create-react-app</a>, See on <a href="https://news.ycombinator.com/item?id=43051961">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>February 14, 2025 by <a href="https://twitter.com/mattcarrollcode" target="_blank" rel="nofollow noopener noreferrer">Matt Carroll</a> and <a href="https://bsky.app/profile/ricky.fm" target="_blank" rel="nofollow noopener noreferrer">Ricky Hanlon</a></p>
<hr>
<p>Today, we’re deprecating <a href="https://create-react-app.dev/" target="_blank" rel="nofollow noopener noreferrer">Create React App</a> for new apps, and encouraging existing apps to migrate to a <a href="https://react.dev/learn/creating-a-react-app">framework</a>. We’re also providing docs for when a framework isn’t a good fit for your project, or you prefer to start by <a href="https://react.dev/learn/building-a-react-framework">building a framework</a>.</p>
<hr>
<p>When we released Create React App in 2016, there was no clear way to build a new React app.</p>
<p>To create a React app, you had to install a bunch of tools and wire them up together yourself to support basic features like JSX, linting, and hot reloading. This was very tricky to do correctly, so the <a href="https://github.com/react-boilerplate/react-boilerplate" target="_blank" rel="nofollow noopener noreferrer">community</a> <a href="https://github.com/kriasoft/react-starter-kit" target="_blank" rel="nofollow noopener noreferrer">created</a> <a href="https://github.com/petehunt/react-boilerplate" target="_blank" rel="nofollow noopener noreferrer">boilerplates</a> for <a href="https://github.com/gaearon/react-hot-boilerplate" target="_blank" rel="nofollow noopener noreferrer">common</a> <a href="https://github.com/erikras/react-redux-universal-hot-example" target="_blank" rel="nofollow noopener noreferrer">setups</a>. However, boilerplates were difficult to update and fragmentation made it difficult for React to release new features.</p>
<p>Create React App solved these problems by combining several tools into a single recommended configuration. This allowed apps a simple way to upgrade to new tooling features, and allowed the React team to deploy non-trivial tooling changes (Fast Refresh support, React Hooks lint rules) to the broadest possible audience.</p>
<p>This model became so popular that there’s an entire category of tools working this way today.</p>
<h2 id="deprecating-create-react-app">Deprecating Create React App <a href="#deprecating-create-react-app" aria-label="Link for Deprecating Create React App " title="Link for Deprecating Create React App "><svg width="1em" height="1em" viewBox="0 0 13 13" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor" fill-rule="evenodd"><path d="M7.778 7.975a2.5 2.5 0 0 0 .347-3.837L6.017 2.03a2.498 2.498 0 0 0-3.542-.007 2.5 2.5 0 0 0 .006 3.543l1.153 1.15c.07-.29.154-.563.25-.773.036-.077.084-.16.14-.25L3.18 4.85a1.496 1.496 0 0 1 .002-2.12 1.496 1.496 0 0 1 2.12 0l2.124 2.123a1.496 1.496 0 0 1-.333 2.37c.16.246.42.504.685.752z"></path><path d="M5.657 4.557a2.5 2.5 0 0 0-.347 3.837l2.108 2.108a2.498 2.498 0 0 0 3.542.007 2.5 2.5 0 0 0-.006-3.543L9.802 5.815c-.07.29-.154.565-.25.774-.036.076-.084.16-.14.25l.842.84c.585.587.59 1.532 0 2.122-.587.585-1.532.59-2.12 0L6.008 7.68a1.496 1.496 0 0 1 .332-2.372c-.16-.245-.42-.503-.685-.75z"></path></g></svg></a></h2>
<p>Although Create React App makes it easy to get started, <a href="#limitations-of-create-react-app">there are several limitations</a> that make it difficult to build high performant production apps. In principle, we could solve these problems by essentially evolving it into a <a href="#why-we-recommend-frameworks">framework</a>.</p>
<p>However, since Create React App currently has no active maintainers, and there are many existing frameworks that solve these problems already, we’ve decided to deprecate Create React App.</p>
<p>Starting today, if you install a new app, you will see a deprecation warning:</p>
<div translate="no" dir="ltr"><svg width="1.33em" height="1.33em" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><circle cx="10.1626" cy="9.99951" r="9.47021" fill="currentColor"></circle><path d="M6.22705 5.95996L14.2798 14.0127" stroke="white"></path><path d="M14.2798 5.95996L6.22705 14.0127" stroke="white"></path></svg><p>create-react-app is deprecated.

You can find a list of up-to-date React frameworks on react.dev
For more info see: react.dev/link/cra

This error message will only be shown once per install.</p></div>
<p>We recommend <a href="https://react.dev/learn/creating-a-react-app">creating new React apps</a> with a framework. All the frameworks we recommend support client-only SPAs, and can be deployed to a CDN or static hosting service without a server.</p>
<p>For existing apps, these guides will help you migrate to a client-only SPA:</p>
<ul>
<li><a href="https://nextjs.org/docs/app/building-your-application/upgrading/from-create-react-app" target="_blank" rel="nofollow noopener noreferrer">Next.js’ Create React App migration guide</a></li>
<li><a href="https://reactrouter.com/upgrading/component-routes" target="_blank" rel="nofollow noopener noreferrer">React Router’s framework adoption guide</a>.</li>
<li><a href="https://docs.expo.dev/router/migrate/from-expo-webpack/" target="_blank" rel="nofollow noopener noreferrer">Expo Webpack to Expo Router migration guide</a></li>
</ul>
<p>Create React App will continue working in maintenance mode, and we’ve published a new version of Create React App to work with React 19.</p>
<p>If your app has unusual constraints, or you prefer to solve these problems by building your own framework, or you just want to learn how react works from scratch, you can roll your own custom setup with React using Vite or Parcel.</p>
<p>To help users get started with Vite or Parcel, we’ve published new docs for <a href="https://react.dev/learn/building-a-react-framework">Building a Framework</a>. Continue reading to learn more about the <a href="#limitations-of-create-react-app">limitations of Create React App</a> and <a href="#why-we-recommend-frameworks">why we recommend frameworks</a>.</p>
<div><h3><svg width="2em" height="2em" viewBox="0 0 72 72" fill="none" xmlns="http://www.w3.org/2000/svg"><g clip-path="url(#clip0_40_48064)"><path d="M24 27C24 25.3431 25.3431 24 27 24H45C46.6569 24 48 25.3431 48 27C48 28.6569 46.6569 30 45 30H27C25.3431 30 24 28.6569 24 27Z" fill="currentColor"></path><path d="M24 39C24 37.3431 25.3431 36 27 36H39C40.6569 36 42 37.3431 42 39C42 40.6569 40.6569 42 39 42H27C25.3431 42 24 40.6569 24 39Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M12 18C12 13.0294 16.0294 9 21 9H51C55.9706 9 60 13.0294 60 18V54C60 58.9706 55.9706 63 51 63H21C16.0294 63 12 58.9706 12 54V18ZM21 15H51C52.6569 15 54 16.3431 54 18V54C54 55.6569 52.6569 57 51 57H21C19.3431 57 18 55.6569 18 54V18C18 16.3431 19.3431 15 21 15Z" fill="currentColor"></path></g><defs><clipPath id="clip0_40_48064"><rect width="72" height="72" fill="white"></rect></clipPath></defs></svg>Note</h3><div><h4 id="do-you-recommend-vite">Do you recommend Vite? <a href="#do-you-recommend-vite" aria-label="Link for Do you recommend Vite? " title="Link for Do you recommend Vite? "><svg width="1em" height="1em" viewBox="0 0 13 13" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor" fill-rule="evenodd"><path d="M7.778 7.975a2.5 2.5 0 0 0 .347-3.837L6.017 2.03a2.498 2.498 0 0 0-3.542-.007 2.5 2.5 0 0 0 .006 3.543l1.153 1.15c.07-.29.154-.563.25-.773.036-.077.084-.16.14-.25L3.18 4.85a1.496 1.496 0 0 1 .002-2.12 1.496 1.496 0 0 1 2.12 0l2.124 2.123a1.496 1.496 0 0 1-.333 2.37c.16.246.42.504.685.752z"></path><path d="M5.657 4.557a2.5 2.5 0 0 0-.347 3.837l2.108 2.108a2.498 2.498 0 0 0 3.542.007 2.5 2.5 0 0 0-.006-3.543L9.802 5.815c-.07.29-.154.565-.25.774-.036.076-.084.16-.14.25l.842.84c.585.587.59 1.532 0 2.122-.587.585-1.532.59-2.12 0L6.008 7.68a1.496 1.496 0 0 1 .332-2.372c-.16-.245-.42-.503-.685-.75z"></path></g></svg></a></h4><p>We provide several Vite-based recommendations.</p><p>React Router v7 is a Vite based framework which allows you to use Vite’s fast development server and build tooling with a framework that provides routing and data fetching. Just like the other frameworks we recommend, you can build a SPA with React Router v7.</p><p>We also recommend using Vite when <a href="https://react.dev/learn/add-react-to-an-existing-project">adding React to an existing project</a>, or <a href="https://react.dev/learn/building-a-react-framework">building a framework</a>.</p><p>Just like Svelte has Sveltekit, Vue has Nuxt, and Solid has SolidStart, React recommends using a framework that integrates with build tools like Vite for new projects.</p></div></div>
<h2 id="limitations-of-create-react-app">Limitations of Create React App <a href="#limitations-of-create-react-app" aria-label="Link for Limitations of Create React App " title="Link for Limitations of Create React App "><svg width="1em" height="1em" viewBox="0 0 13 13" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor" fill-rule="evenodd"><path d="M7.778 7.975a2.5 2.5 0 0 0 .347-3.837L6.017 2.03a2.498 2.498 0 0 0-3.542-.007 2.5 2.5 0 0 0 .006 3.543l1.153 1.15c.07-.29.154-.563.25-.773.036-.077.084-.16.14-.25L3.18 4.85a1.496 1.496 0 0 1 .002-2.12 1.496 1.496 0 0 1 2.12 0l2.124 2.123a1.496 1.496 0 0 1-.333 2.37c.16.246.42.504.685.752z"></path><path d="M5.657 4.557a2.5 2.5 0 0 0-.347 3.837l2.108 2.108a2.498 2.498 0 0 0 3.542.007 2.5 2.5 0 0 0-.006-3.543L9.802 5.815c-.07.29-.154.565-.25.774-.036.076-.084.16-.14.25l.842.84c.585.587.59 1.532 0 2.122-.587.585-1.532.59-2.12 0L6.008 7.68a1.496 1.496 0 0 1 .332-2.372c-.16-.245-.42-.503-.685-.75z"></path></g></svg></a></h2>
<p>Create React App and build tools like it make it easy to get started building a React app. After running <code dir="ltr">npx create-react-app my-app</code>, you get a fully configured React app with a development server, linting, and a production build.</p>
<p>For example, if you’re building an internal admin tool, you can start with a landing page:</p>
<!--$--><div dir="ltr"><pre><code><p><span>export</span> <span>default</span> <span>function</span> <span>App</span><span>(</span><span>)</span> <span>{</span><br></p><p><span>return</span> <span>(</span><br></p><p><span>&lt;</span><span>div</span><span>&gt;</span><br></p><p><span>&lt;</span><span>h1</span><span>&gt;</span>Welcome to the Admin Tool!<span>&lt;/</span><span>h1</span><span>&gt;</span><br></p><p><span>&lt;/</span><span>div</span><span>&gt;</span><br></p><p><span>)</span><br></p><p><span>}</span></p></code></pre></div><!--/$-->
<p>This allows you to immediately start coding in React with features like JSX, default linting rules, and a bundler to run in both development and production. However, this setup is missing the tools you need to build a real production app.</p>
<p>Most production apps need solutions to problems like routing, data fetching, and code splitting.</p>
<h3 id="routing">Routing <a href="#routing" aria-label="Link for Routing " title="Link for Routing "><svg width="1em" height="1em" viewBox="0 0 13 13" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor" fill-rule="evenodd"><path d="M7.778 7.975a2.5 2.5 0 0 0 .347-3.837L6.017 2.03a2.498 2.498 0 0 0-3.542-.007 2.5 2.5 0 0 0 .006 3.543l1.153 1.15c.07-.29.154-.563.25-.773.036-.077.084-.16.14-.25L3.18 4.85a1.496 1.496 0 0 1 .002-2.12 1.496 1.496 0 0 1 2.12 0l2.124 2.123a1.496 1.496 0 0 1-.333 2.37c.16.246.42.504.685.752z"></path><path d="M5.657 4.557a2.5 2.5 0 0 0-.347 3.837l2.108 2.108a2.498 2.498 0 0 0 3.542.007 2.5 2.5 0 0 0-.006-3.543L9.802 5.815c-.07.29-.154.565-.25.774-.036.076-.084.16-.14.25l.842.84c.585.587.59 1.532 0 2.122-.587.585-1.532.59-2.12 0L6.008 7.68a1.496 1.496 0 0 1 .332-2.372c-.16-.245-.42-.503-.685-.75z"></path></g></svg></a></h3>
<p>Create React App does not include a specific routing solution. If you’re just getting started, one option is to use <code dir="ltr">useState</code> to switch between routes. But doing this means that you can’t share links to your app - every link would go to the same page - and structuring your app becomes difficult over time:</p>
<!--$--><div dir="ltr"><pre><code><p><span>import</span> <span>{</span><span>useState</span><span>}</span> <span>from</span> <span>'react'</span><span>;</span><br></p><p><span>import</span> <span>Home</span> <span>from</span> <span>'./Home'</span><span>;</span><br></p><p><span>import</span> <span>Dashboard</span> <span>from</span> <span>'./Dashboard'</span><span>;</span><br></p><p><span>export</span> <span>default</span> <span>function</span> <span>App</span><span>(</span><span>)</span> <span>{</span><br></p><p><span>// ❌ Routing in state does not create URLs</span><br></p><p><span>const</span> <span>[</span><span>route</span><span>,</span> <span>setRoute</span><span>]</span> = <span>useState</span><span>(</span><span>'home'</span><span>)</span><span>;</span><br></p><p><span>return</span> <span>(</span><br></p><p><span>&lt;</span><span>div</span><span>&gt;</span><br></p><p><span>{</span><span>route</span> === <span>'home'</span> &amp;&amp; <span>&lt;</span><span>Home</span> <span>/&gt;</span><span>}</span><br></p><p><span>{</span><span>route</span> === <span>'dashboard'</span> &amp;&amp; <span>&lt;</span><span>Dashbord</span> <span>/&gt;</span><span>}</span><br></p><p><span>&lt;/</span><span>div</span><span>&gt;</span><br></p><p><span>)</span><br></p><p><span>}</span></p></code></pre></div><!--/$-->
<p>This is why most apps that use Create React App solve add routing with a routing library like <a href="https://reactrouter.com/" target="_blank" rel="nofollow noopener noreferrer">React Router</a> or <a href="https://tanstack.com/router/latest" target="_blank" rel="nofollow noopener noreferrer">Tanstack Router</a>. With a routing library, you can add additional routes to the app, which provides opinions on the structure of your app, and allows you to start sharing links to routes. For example, with React Router you can define routes:</p>
<!--$--><div dir="ltr"><pre><code><p><span>import</span> <span>{</span><span>RouterProvider</span><span>,</span> <span>createBrowserRouter</span><span>}</span> <span>from</span> <span>'react-router'</span><span>;</span><br></p><p><span>import</span> <span>Home</span> <span>from</span> <span>'./Home'</span><span>;</span><br></p><p><span>import</span> <span>Dashboard</span> <span>from</span> <span>'./Dashboard'</span><span>;</span><br></p><p><span>// ✅ Each route has it's own URL</span><br></p><p><span>const</span> <span>router</span> = <span>createBrowserRouter</span><span>(</span><span>[</span><br></p><p><span>{</span><span>path</span><span>:</span> <span>'/'</span><span>,</span> <span>element</span><span>:</span> <span>&lt;</span><span>Home</span> <span>/&gt;</span><span>}</span><span>,</span><br></p><p><span>{</span><span>path</span><span>:</span> <span>'/dashboard'</span><span>,</span> <span>element</span><span>:</span> <span>&lt;</span><span>Dashboard</span> <span>/&gt;</span><span>}</span><br></p><p><span>]</span><span>)</span><span>;</span><br></p><p><span>export</span> <span>default</span> <span>function</span> <span>App</span><span>(</span><span>)</span> <span>{</span><br></p><p><span>return</span> <span>(</span><br></p><p><span>&lt;</span><span>RouterProvider</span> <span>value</span>=<span>{</span><span>router</span><span>}</span> <span>/&gt;</span><br></p><p><span>)</span><br></p><p><span>}</span></p></code></pre></div><!--/$-->
<p>With this change, you can share a link to <code dir="ltr">/dashboard</code> and the app will navigate to the dashboard page . Once you have a routing library, you can add additional features like nested routes, route guards, and route transitions, which are difficult to implement without a routing library.</p>
<p>There’s a tradeoff being made here: the routing library adds complexity to the app, but it also adds features that are difficult to implement without it.</p>
<h3 id="data-fetching">Data Fetching <a href="#data-fetching" aria-label="Link for Data Fetching " title="Link for Data Fetching "><svg width="1em" height="1em" viewBox="0 0 13 13" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor" fill-rule="evenodd"><path d="M7.778 7.975a2.5 2.5 0 0 0 .347-3.837L6.017 2.03a2.498 2.498 0 0 0-3.542-.007 2.5 2.5 0 0 0 .006 3.543l1.153 1.15c.07-.29.154-.563.25-.773.036-.077.084-.16.14-.25L3.18 4.85a1.496 1.496 0 0 1 .002-2.12 1.496 1.496 0 0 1 2.12 0l2.124 2.123a1.496 1.496 0 0 1-.333 2.37c.16.246.42.504.685.752z"></path><path d="M5.657 4.557a2.5 2.5 0 0 0-.347 3.837l2.108 2.108a2.498 2.498 0 0 0 3.542.007 2.5 2.5 0 0 0-.006-3.543L9.802 5.815c-.07.29-.154.565-.25.774-.036.076-.084.16-.14.25l.842.84c.585.587.59 1.532 0 2.122-.587.585-1.532.59-2.12 0L6.008 7.68a1.496 1.496 0 0 1 .332-2.372c-.16-.245-.42-.503-.685-.75z"></path></g></svg></a></h3>
<p>Another common problem in Create React App is data fetching. Create React App does not include a specific data fetching solution. If you’re just getting started, a common option is to use <code dir="ltr">fetch</code> in an effect to load data.</p>
<p>But doing this means that the data is fetched after the component renders, which can cause network waterfalls. Network waterfalls are caused by fetching data when your app renders instead of in parallel while the code is downloading:</p>
<!--$--><div dir="ltr"><pre><code><p><span>export</span> <span>default</span> <span>function</span> <span>Dashboard</span><span>(</span><span>)</span> <span>{</span><br></p><p><span>const</span> <span>[</span><span>data</span><span>,</span> <span>setData</span><span>]</span> = <span>useState</span><span>(</span><span>null</span><span>)</span><span>;</span><br></p><p><span>// ❌ Fetching data in a component causes network waterfalls</span><br></p><p><span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><br></p><p><span>fetch</span><span>(</span><span>'/api/data'</span><span>)</span><br></p><p>      .<span>then</span><span>(</span><span>response</span> <span>=&gt;</span> <span>response</span>.<span>json</span><span>(</span><span>)</span><span>)</span><br></p><p>      .<span>then</span><span>(</span><span>data</span> <span>=&gt;</span> <span>setData</span><span>(</span><span>data</span><span>)</span><span>)</span><span>;</span><br></p><p><span>}</span><span>,</span> <span>[</span><span>]</span><span>)</span><span>;</span><br></p><p><span>return</span> <span>(</span><br></p><p><span>&lt;</span><span>div</span><span>&gt;</span><br></p><p><span>{</span><span>data</span>.<span>map</span><span>(</span><span>item</span> <span>=&gt;</span> <span>&lt;</span><span>div</span> <span>key</span>=<span>{</span><span>item</span>.<span>id</span><span>}</span><span>&gt;</span><span>{</span><span>item</span>.<span>name</span><span>}</span><span>&lt;/</span><span>div</span><span>&gt;</span><span>)</span><span>}</span><br></p><p><span>&lt;/</span><span>div</span><span>&gt;</span><br></p><p><span>)</span><br></p><p><span>}</span></p></code></pre></div><!--/$-->
<p>Fetching in an effect means the user has to wait longer to see the content, even though the data could have been fetched earlier. To solve this, you can use a data fetching library like <a href="https://react-query.tanstack.com/" target="_blank" rel="nofollow noopener noreferrer">React Query</a>, <a href="https://swr.vercel.app/" target="_blank" rel="nofollow noopener noreferrer">SWR</a>, <a href="https://www.apollographql.com/docs/react" target="_blank" rel="nofollow noopener noreferrer">Apollo</a>, or <a href="https://relay.dev/" target="_blank" rel="nofollow noopener noreferrer">Relay</a> which provide options to prefetch data so the request is started before the component renders.</p>
<p>These libraries work best when integrated with your routing “loader” pattern to specify data dependencies at the route level, which allows the router to optimize your data fetches:</p>
<!--$--><div dir="ltr"><pre><code><p><span>export</span> <span>async</span> <span>function</span> <span>loader</span><span>(</span><span>)</span> <span>{</span><br></p><p><span>const</span> <span>response</span> = <span>await</span> <span>fetch</span><span>(</span><span>`/api/data`</span><span>)</span><span>;</span><br></p><p><span>const</span> <span>data</span> = <span>await</span> <span>response</span>.<span>json</span><span>(</span><span>)</span><span>;</span><br></p><p><span>return</span> <span>data</span><span>;</span><br></p><p><span>}</span><br></p><p><span>// ✅ Fetching data in parallel while the code is downloading</span><br></p><p><span>export</span> <span>default</span> <span>function</span> <span>Dashboard</span><span>(</span><span>{</span><span>loaderData</span><span>}</span><span>)</span> <span>{</span><br></p><p><span>return</span> <span>(</span><br></p><p><span>&lt;</span><span>div</span><span>&gt;</span><br></p><p><span>{</span><span>loaderData</span>.<span>map</span><span>(</span><span>item</span> <span>=&gt;</span> <span>&lt;</span><span>div</span> <span>key</span>=<span>{</span><span>item</span>.<span>id</span><span>}</span><span>&gt;</span><span>{</span><span>item</span>.<span>name</span><span>}</span><span>&lt;/</span><span>div</span><span>&gt;</span><span>)</span><span>}</span><br></p><p><span>&lt;/</span><span>div</span><span>&gt;</span><br></p><p><span>)</span><br></p><p><span>}</span></p></code></pre></div><!--/$-->
<p>On initial load, the router can fetch the data immediately before the route is rendered. As the user navigates around the app, the router is able to fetch both the data and the route at the same time, parallelizing the fetches. This reduces the time it takes to see the content on the screen, and can improve the user experience.</p>
<p>However, this requires correctly configuring the loaders in your app and trades off complexity for performance.</p>
<h3 id="code-splitting">Code Splitting <a href="#code-splitting" aria-label="Link for Code Splitting " title="Link for Code Splitting "><svg width="1em" height="1em" viewBox="0 0 13 13" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor" fill-rule="evenodd"><path d="M7.778 7.975a2.5 2.5 0 0 0 .347-3.837L6.017 2.03a2.498 2.498 0 0 0-3.542-.007 2.5 2.5 0 0 0 .006 3.543l1.153 1.15c.07-.29.154-.563.25-.773.036-.077.084-.16.14-.25L3.18 4.85a1.496 1.496 0 0 1 .002-2.12 1.496 1.496 0 0 1 2.12 0l2.124 2.123a1.496 1.496 0 0 1-.333 2.37c.16.246.42.504.685.752z"></path><path d="M5.657 4.557a2.5 2.5 0 0 0-.347 3.837l2.108 2.108a2.498 2.498 0 0 0 3.542.007 2.5 2.5 0 0 0-.006-3.543L9.802 5.815c-.07.29-.154.565-.25.774-.036.076-.084.16-.14.25l.842.84c.585.587.59 1.532 0 2.122-.587.585-1.532.59-2.12 0L6.008 7.68a1.496 1.496 0 0 1 .332-2.372c-.16-.245-.42-.503-.685-.75z"></path></g></svg></a></h3>
<p>Another common problem in Create React App is <a href="https://www.patterns.dev/vanilla/bundle-splitting" target="_blank" rel="nofollow noopener noreferrer">code splitting</a>. Create React App does not include a specific code splitting solution. If you’re just getting started, you might not consider code splitting at all.</p>
<p>This means your app is shipped as a single bundle:</p>
<!--$--><!--/$-->
<p>But for ideal performance, you should “split” your code into separate bundles so the user only needs to download what they need. This decreases the time the user needs to wait to load your app, by only downloading the code they need to see the page they are on.</p>
<!--$--><div dir="ltr"><pre><code><p>- <span>core</span>.<span>js</span>      <span>25</span><span>kb</span><br></p><p>- <span>home</span>.<span>js</span>      <span>25</span><span>kb</span><br></p><p>- <span>dashboard</span>.<span>js</span> <span>25</span><span>kb</span></p></code></pre></div><!--/$-->
<p>One way to do code-splitting is with <code dir="ltr">React.lazy</code>. However, this means that the code is not fetched until the component renders, which can cause network waterfalls. A more optimal solution is to use a router feature that fetches the code in parallel while the code is downloading. For example, React Router provides a <code dir="ltr">lazy</code> option to specify that a route should be code split and optimize when it is loaded:</p>
<!--$--><div dir="ltr"><pre><code><p><span>import</span> <span>Home</span> <span>from</span> <span>'./Home'</span><span>;</span><br></p><p><span>import</span> <span>Dashboard</span> <span>from</span> <span>'./Dashboard'</span><span>;</span><br></p><p><span>// ✅ Routes are downloaded before rendering</span><br></p><p><span>const</span> <span>router</span> = <span>createBrowserRouter</span><span>(</span><span>[</span><br></p><p><span>{</span><span>path</span><span>:</span> <span>'/'</span><span>,</span> <span>lazy</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>import</span><span>(</span><span>'./Home'</span><span>)</span><span>}</span><span>,</span><br></p><p><span>{</span><span>path</span><span>:</span> <span>'/dashboard'</span><span>,</span> <span>lazy</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>import</span><span>(</span><span>'Dashboard'</span><span>)</span><span>}</span><br></p><p><span>]</span><span>)</span><span>;</span></p></code></pre></div><!--/$-->
<p>Optimized code-splitting is tricky to get right, and it’s easy to make mistakes that can cause the user to download more code than they need. It works best when integrated with your router and data loading solutions to maximize caching, parallelize fetches, and support <a href="https://www.patterns.dev/vanilla/import-on-interaction" target="_blank" rel="nofollow noopener noreferrer">“import on interaction”</a> patterns.</p>
<h3 id="and-more">And more… <a href="#and-more" aria-label="Link for And more… " title="Link for And more… "><svg width="1em" height="1em" viewBox="0 0 13 13" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor" fill-rule="evenodd"><path d="M7.778 7.975a2.5 2.5 0 0 0 .347-3.837L6.017 2.03a2.498 2.498 0 0 0-3.542-.007 2.5 2.5 0 0 0 .006 3.543l1.153 1.15c.07-.29.154-.563.25-.773.036-.077.084-.16.14-.25L3.18 4.85a1.496 1.496 0 0 1 .002-2.12 1.496 1.496 0 0 1 2.12 0l2.124 2.123a1.496 1.496 0 0 1-.333 2.37c.16.246.42.504.685.752z"></path><path d="M5.657 4.557a2.5 2.5 0 0 0-.347 3.837l2.108 2.108a2.498 2.498 0 0 0 3.542.007 2.5 2.5 0 0 0-.006-3.543L9.802 5.815c-.07.29-.154.565-.25.774-.036.076-.084.16-.14.25l.842.84c.585.587.59 1.532 0 2.122-.587.585-1.532.59-2.12 0L6.008 7.68a1.496 1.496 0 0 1 .332-2.372c-.16-.245-.42-.503-.685-.75z"></path></g></svg></a></h3>
<p>These are just a few examples of the limitations of Create React App.</p>
<p>Once you’ve integrated routing, data-fetching, and code splitting, you now also need to consider pending states, navigation interruptions, error messages to the user, and revalidation of the data. There are entire categories of problems that users need to solve like:</p>
<div><ul><li>Accessibility</li>
<li>Asset loading</li>
<li>Authentication</li>
<li>Caching</li></ul><ul><li>Error handling</li>
<li>Mutating data</li>
<li>Navigations</li>
<li>Optimistic updates</li></ul><ul><li>Progressive enhancement</li>
<li>Server-side rendering</li>
<li>Static site generation</li>
<li>Streaming</li></ul></div>
<p>All of these work together to create the most optimal <a href="https://www.patterns.dev/vanilla/loading-sequence" target="_blank" rel="nofollow noopener noreferrer">loading sequence</a>.</p>
<p>Solving each of these problems individually in Create React App can be difficult as each problem is interconnected with the others and can require deep expertise in problem areas users may not be familiar with. In order to solve these problems, users end up building their own bespoke solutions on top of Create React App, which was the problem Create React App originally tried to solve.</p>
<h2 id="why-we-recommend-frameworks">Why we Recommend Frameworks <a href="#why-we-recommend-frameworks" aria-label="Link for Why we Recommend Frameworks " title="Link for Why we Recommend Frameworks "><svg width="1em" height="1em" viewBox="0 0 13 13" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor" fill-rule="evenodd"><path d="M7.778 7.975a2.5 2.5 0 0 0 .347-3.837L6.017 2.03a2.498 2.498 0 0 0-3.542-.007 2.5 2.5 0 0 0 .006 3.543l1.153 1.15c.07-.29.154-.563.25-.773.036-.077.084-.16.14-.25L3.18 4.85a1.496 1.496 0 0 1 .002-2.12 1.496 1.496 0 0 1 2.12 0l2.124 2.123a1.496 1.496 0 0 1-.333 2.37c.16.246.42.504.685.752z"></path><path d="M5.657 4.557a2.5 2.5 0 0 0-.347 3.837l2.108 2.108a2.498 2.498 0 0 0 3.542.007 2.5 2.5 0 0 0-.006-3.543L9.802 5.815c-.07.29-.154.565-.25.774-.036.076-.084.16-.14.25l.842.84c.585.587.59 1.532 0 2.122-.587.585-1.532.59-2.12 0L6.008 7.68a1.496 1.496 0 0 1 .332-2.372c-.16-.245-.42-.503-.685-.75z"></path></g></svg></a></h2>
<p>Although you could solve all these pieces yourself in a build tool like Create React App, Vite, or Parcel, it is hard to do well. Just like when Create React App itself integrated several build tools together, you need a tool to integrate all of these features together to provide the best experience to users.</p>
<p>This category of tools that integrates build tools, rendering, routing, data fetching, and code splitting are known as “frameworks” — or if you prefer to call React itself a framework, you might call them “metaframeworks”.</p>
<p>Frameworks impose some opinions about structuring your app in order to provide a much better user experience, in the same way build tools impose some opinions to make tooling easier. This is why we started recommending frameworks like <a href="https://nextjs.org/" target="_blank" rel="nofollow noopener noreferrer">Next.js</a>, <a href="https://reactrouter.com/" target="_blank" rel="nofollow noopener noreferrer">React Router</a>, and <a href="https://expo.dev/" target="_blank" rel="nofollow noopener noreferrer">Expo</a> for new projects.</p>
<p>Frameworks provide the same getting started experience as Create React App, but also provide solutions to problems users need to solve anyway in real production apps.</p>
<details><summary tabindex="-1"><h5><svg width="1.5em" height="1.5em" viewBox="0 0 72 72" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M34.7409 59.7228L32.9567 58.9094C27.2672 56.3157 20.7328 56.3157 15.0433 58.9094C12.6018 60.0224 9.39163 59.0275 8.44602 56.0621C7.45647 52.9589 5.99975 46.5898 6 35.9997C6.00029 23.5648 8.00803 18.3599 9.11099 16.4196C9.67795 15.4222 10.5255 14.8455 11.2254 14.5264L12.0179 14.1651C19.6351 10.6926 28.4011 10.6738 36 14.1733C43.5989 10.6738 52.3649 10.6926 59.9821 14.1651L60.7746 14.5264C61.4745 14.8455 62.3221 15.4222 62.889 16.4196C63.992 18.3599 65.9997 23.5648 66 35.9997C66.0002 46.5898 64.5435 52.9589 63.554 56.0621C62.6084 59.0275 59.3982 60.0224 56.9567 58.9094C51.2672 56.3157 44.7328 56.3157 39.0433 58.9094L37.2591 59.7228C37.1986 59.7508 37.1373 59.7767 37.0753 59.8004C36.4484 60.0411 35.7556 60.0653 35.1102 59.8648C34.9847 59.8258 34.8613 59.7784 34.7409 59.7228ZM14.5068 19.6246C20.3733 16.9501 27.0874 16.8775 33 19.4067V52.473C26.7613 50.32 19.9378 50.471 13.7811 52.9261C13.0005 49.9843 11.9998 44.547 12 35.9998C12.0002 25.5786 13.4879 21.1893 14.1179 19.8018L14.5068 19.6246ZM39 52.473C45.2387 50.32 52.0622 50.471 58.2189 52.9261C58.9995 49.9843 60.0002 44.547 60 35.9998C59.9998 25.5786 58.5121 21.1893 57.8821 19.8018L57.4932 19.6246C51.6267 16.9501 44.9126 16.8775 39 19.4067V52.473Z" fill="currentColor"></path></svg>Deep Dive</h5><p><h4 id="server-rendering-is-optional">Server rendering is optional <a href="#server-rendering-is-optional" aria-label="Link for Server rendering is optional " title="Link for Server rendering is optional "><svg width="1em" height="1em" viewBox="0 0 13 13" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor" fill-rule="evenodd"><path d="M7.778 7.975a2.5 2.5 0 0 0 .347-3.837L6.017 2.03a2.498 2.498 0 0 0-3.542-.007 2.5 2.5 0 0 0 .006 3.543l1.153 1.15c.07-.29.154-.563.25-.773.036-.077.084-.16.14-.25L3.18 4.85a1.496 1.496 0 0 1 .002-2.12 1.496 1.496 0 0 1 2.12 0l2.124 2.123a1.496 1.496 0 0 1-.333 2.37c.16.246.42.504.685.752z"></path><path d="M5.657 4.557a2.5 2.5 0 0 0-.347 3.837l2.108 2.108a2.498 2.498 0 0 0 3.542.007 2.5 2.5 0 0 0-.006-3.543L9.802 5.815c-.07.29-.154.565-.25.774-.036.076-.084.16-.14.25l.842.84c.585.587.59 1.532 0 2.122-.587.585-1.532.59-2.12 0L6.008 7.68a1.496 1.496 0 0 1 .332-2.372c-.16-.245-.42-.503-.685-.75z"></path></g></svg></a></h4></p></summary><div><p>The frameworks we recommend all provide the option to create a <a href="https://developer.mozilla.org/en-US/docs/Glossary/CSR" target="_blank" rel="nofollow noopener noreferrer">client-side rendered (CSR)</a> app.</p><p>In some cases, CSR is the right choice for a page, but many times it’s not. Even if most of your app is client-side, there are often individual pages that could benefit from server rendering features like <a href="https://developer.mozilla.org/en-US/docs/Glossary/SSG" target="_blank" rel="nofollow noopener noreferrer">static-site generation (SSG)</a> or <a href="https://developer.mozilla.org/en-US/docs/Glossary/SSR" target="_blank" rel="nofollow noopener noreferrer">server-side rendering (SSR)</a>, for example a Terms of Service page, or documentation.</p><p>Server rendering generally sends less JavaScript to the client, and a full HTML document which produces a faster <a href="https://web.dev/articles/fcp" target="_blank" rel="nofollow noopener noreferrer">First Contentful Paint (FCP)</a> by reducing <a href="https://web.dev/articles/tbt" target="_blank" rel="nofollow noopener noreferrer">Total Blocking Time (TBD)</a>, which can also lower <a href="https://web.dev/articles/inp" target="_blank" rel="nofollow noopener noreferrer">Interaction to Next Paint (INP)</a>. This is why the <a href="https://web.dev/articles/rendering-on-the-web" target="_blank" rel="nofollow noopener noreferrer">Chrome team has encouraged</a> developers to consider static or server-side render over a full client-side approach to achieve the best possible performance.</p><p>There are tradeoffs to using a server, and it is not always the best option for every page. Generating pages on the server incurs additional cost and takes time to generate which can increase <a href="https://web.dev/articles/ttfb" target="_blank" rel="nofollow noopener noreferrer">Time to First Byte (TTFB)</a>. The best performing apps are able to pick the right rendering strategy on a per-page basis, based on the tradeoffs of each strategy.</p><p>Frameworks provide the option to use a server on any page if you want to, but do not force you to use a server. This allows you to pick the right rendering strategy for each page in your app.</p><h4 id="server-components">What About Server Components <a href="#server-components" aria-label="Link for What About Server Components " title="Link for What About Server Components "><svg width="1em" height="1em" viewBox="0 0 13 13" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor" fill-rule="evenodd"><path d="M7.778 7.975a2.5 2.5 0 0 0 .347-3.837L6.017 2.03a2.498 2.498 0 0 0-3.542-.007 2.5 2.5 0 0 0 .006 3.543l1.153 1.15c.07-.29.154-.563.25-.773.036-.077.084-.16.14-.25L3.18 4.85a1.496 1.496 0 0 1 .002-2.12 1.496 1.496 0 0 1 2.12 0l2.124 2.123a1.496 1.496 0 0 1-.333 2.37c.16.246.42.504.685.752z"></path><path d="M5.657 4.557a2.5 2.5 0 0 0-.347 3.837l2.108 2.108a2.498 2.498 0 0 0 3.542.007 2.5 2.5 0 0 0-.006-3.543L9.802 5.815c-.07.29-.154.565-.25.774-.036.076-.084.16-.14.25l.842.84c.585.587.59 1.532 0 2.122-.587.585-1.532.59-2.12 0L6.008 7.68a1.496 1.496 0 0 1 .332-2.372c-.16-.245-.42-.503-.685-.75z"></path></g></svg></a></h4><p>The frameworks we recommend also include support for React Server Components.</p><p>Server Components help solve these problems by moving routing and data fetching to the server, and allowing code splitting to be done for client components based on the data you render, instead of just the route rendered, and reducing the amount of JavaScript shipped for the best possible <a href="https://www.patterns.dev/vanilla/loading-sequence" target="_blank" rel="nofollow noopener noreferrer">loading sequence</a>.</p><p>Server Components do not require a server. They can be run at build time on your CI server to create a static-site generated app (SSG) app, at runtime on a web server for a server-side rendered (SSR) app.</p><p>See <a href="https://react.dev/blog/2020/12/21/data-fetching-with-react-server-components">Introducing zero-bundle size React Server Components</a> and <a href="https://react.dev/reference/rsc/server-components">the docs</a> for more info.</p></div></details>
<div><h3><svg width="2em" height="2em" viewBox="0 0 72 72" fill="none" xmlns="http://www.w3.org/2000/svg"><g clip-path="url(#clip0_40_48064)"><path d="M24 27C24 25.3431 25.3431 24 27 24H45C46.6569 24 48 25.3431 48 27C48 28.6569 46.6569 30 45 30H27C25.3431 30 24 28.6569 24 27Z" fill="currentColor"></path><path d="M24 39C24 37.3431 25.3431 36 27 36H39C40.6569 36 42 37.3431 42 39C42 40.6569 40.6569 42 39 42H27C25.3431 42 24 40.6569 24 39Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M12 18C12 13.0294 16.0294 9 21 9H51C55.9706 9 60 13.0294 60 18V54C60 58.9706 55.9706 63 51 63H21C16.0294 63 12 58.9706 12 54V18ZM21 15H51C52.6569 15 54 16.3431 54 18V54C54 55.6569 52.6569 57 51 57H21C19.3431 57 18 55.6569 18 54V18C18 16.3431 19.3431 15 21 15Z" fill="currentColor"></path></g><defs><clipPath id="clip0_40_48064"><rect width="72" height="72" fill="white"></rect></clipPath></defs></svg>Note</h3><div><h4 id="server-rendering-is-not-just-for-seo">Server Rendering is not just for SEO <a href="#server-rendering-is-not-just-for-seo" aria-label="Link for Server Rendering is not just for SEO " title="Link for Server Rendering is not just for SEO "><svg width="1em" height="1em" viewBox="0 0 13 13" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor" fill-rule="evenodd"><path d="M7.778 7.975a2.5 2.5 0 0 0 .347-3.837L6.017 2.03a2.498 2.498 0 0 0-3.542-.007 2.5 2.5 0 0 0 .006 3.543l1.153 1.15c.07-.29.154-.563.25-.773.036-.077.084-.16.14-.25L3.18 4.85a1.496 1.496 0 0 1 .002-2.12 1.496 1.496 0 0 1 2.12 0l2.124 2.123a1.496 1.496 0 0 1-.333 2.37c.16.246.42.504.685.752z"></path><path d="M5.657 4.557a2.5 2.5 0 0 0-.347 3.837l2.108 2.108a2.498 2.498 0 0 0 3.542.007 2.5 2.5 0 0 0-.006-3.543L9.802 5.815c-.07.29-.154.565-.25.774-.036.076-.084.16-.14.25l.842.84c.585.587.59 1.532 0 2.122-.587.585-1.532.59-2.12 0L6.008 7.68a1.496 1.496 0 0 1 .332-2.372c-.16-.245-.42-.503-.685-.75z"></path></g></svg></a></h4><p>A common misunderstanding is that server rendering is only for <a href="https://developer.mozilla.org/en-US/docs/Glossary/SEO" target="_blank" rel="nofollow noopener noreferrer">SEO</a>.</p><p>While server rendering can improve SEO, it also improves performance by reducing the amount of JavaScript the user needs to download and parse before they can see the content on the screen.</p><p>This is why the Chrome team <a href="https://web.dev/articles/rendering-on-the-web" target="_blank" rel="nofollow noopener noreferrer">has encouraged</a> developers to consider static or server-side render over a full client-side approach to achieve the best possible performance.</p></div></div>
<hr>
<p><em>Thank you to <a href="https://bsky.app/profile/danabra.mov" target="_blank" rel="nofollow noopener noreferrer">Dan Abramov</a> for creating Create React App, and <a href="https://github.com/Timer" target="_blank" rel="nofollow noopener noreferrer">Joe Haddad</a>, <a href="https://github.com/ianschmitz" target="_blank" rel="nofollow noopener noreferrer">Ian Schmitz</a>, <a href="https://github.com/mrmckeb" target="_blank" rel="nofollow noopener noreferrer">Brody McKee</a>, and <a href="https://github.com/facebook/create-react-app/graphs/contributors" target="_blank" rel="nofollow noopener noreferrer">many others</a> for maintaining Create React App over the years. Thank you to <a href="https://bsky.app/profile/brookslybrand.bsky.social" target="_blank" rel="nofollow noopener noreferrer">Brooks Lybrand</a>, <a href="https://bsky.app/profile/danabra.mov" target="_blank" rel="nofollow noopener noreferrer">Dan Abramov</a>, <a href="https://bsky.app/profile/devongovett.bsky.social" target="_blank" rel="nofollow noopener noreferrer">Devon Govett</a>, <a href="https://x.com/Eli_White" target="_blank" rel="nofollow noopener noreferrer">Eli White</a>, <a href="https://bsky.app/profile/jherr.dev" target="_blank" rel="nofollow noopener noreferrer">Jack Herrington</a>, <a href="https://x.com/en_JS" target="_blank" rel="nofollow noopener noreferrer">Joe Savona</a>, <a href="https://bsky.app/profile/no.lol" target="_blank" rel="nofollow noopener noreferrer">Lauren Tan</a>, <a href="https://x.com/leeerob" target="_blank" rel="nofollow noopener noreferrer">Lee Robinson</a>, <a href="https://bsky.app/profile/acemarke.dev" target="_blank" rel="nofollow noopener noreferrer">Mark Erikson</a>, <a href="https://x.com/ryanflorence" target="_blank" rel="nofollow noopener noreferrer">Ryan Florence</a>, <a href="https://bsky.app/profile/sophiebits.com" target="_blank" rel="nofollow noopener noreferrer">Sophie Alpert</a>, <a href="https://bsky.app/profile/tannerlinsley.com" target="_blank" rel="nofollow noopener noreferrer">Tanner Linsley</a>, and <a href="https://x.com/theo" target="_blank" rel="nofollow noopener noreferrer">Theo Browne</a> for reviewing and providing feedback on this post.</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kevin Mitnik FOIA Final (181 pts)]]></title>
            <link>https://vault.fbi.gov/kevin-mitnick/kevin-mitnick-part-01-final/view</link>
            <guid>43051802</guid>
            <pubDate>Fri, 14 Feb 2025 19:02:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vault.fbi.gov/kevin-mitnick/kevin-mitnick-part-01-final/view">https://vault.fbi.gov/kevin-mitnick/kevin-mitnick-part-01-final/view</a>, See on <a href="https://news.ycombinator.com/item?id=43051802">Hacker News</a></p>
Couldn't get https://vault.fbi.gov/kevin-mitnick/kevin-mitnick-part-01-final/view: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The NBA Apple Vision Pro app now has a 3D tabletop view (128 pts)]]></title>
            <link>https://www.uploadvr.com/nba-apple-vision-pro-app-tabletop-view/</link>
            <guid>43051765</guid>
            <pubDate>Fri, 14 Feb 2025 18:58:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.uploadvr.com/nba-apple-vision-pro-app-tabletop-view/">https://www.uploadvr.com/nba-apple-vision-pro-app-tabletop-view/</a>, See on <a href="https://news.ycombinator.com/item?id=43051765">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <article>
      
        
    
      <p>The official NBA Apple Vision Pro app now has Tabletop, a diorama-scale virtual representation of the live game you're watching. </p><p>Tabletop shows in addition to the 2D livestream view you see floating in front of you as a large virtual screen, giving you the benefits of both. Note that the 2D livestream view is not visible in the screen recording below, due to the DRM protection system it uses.</p><figure data-kg-thumbnail="https://www.uploadvr.com/content/media/2025/02/NBA-Apple-Vision-Pro-Tabletop-view_thumb.jpg" data-kg-custom-thumbnail="">
            <div>
                <video src="https://www.uploadvr.com/content/media/2025/02/NBA-Apple-Vision-Pro-Tabletop-view.mp4" poster="https://img.spacergif.org/v1/1920x1080/0a/spacer.png" width="1920" height="1080" loop="" autoplay="" muted="" playsinline="" preload="metadata"></video>
                
                <div>
                        <p>
                        
                        <span>0:00</span></p><p>
                            /<span>0:27</span>
                        </p>
                        </div>
            </div>
            <figcaption><p><span>Footage from </span><a href="https://x.com/IanPanchevre?ref=uploadvr.com"><span>Ian Panchèvre</span></a><span>.</span></p></figcaption>
        <img src="https://www.uploadvr.com/content/media/2025/02/NBA-Apple-Vision-Pro-Tabletop-view_thumb.jpg"></figure><p>There's a roughly half-second delay between the livestream and the Tabletop representation, according to those who've tried it, likely due to the processing time of the motion capture technology at the stadiums used to power this feature. In theory, the NBA could artificially delay the livestream view to match it, but it isn't currently doing so.</p><p>Tabletop is currently available for a few games per night, and the NBA plans to make it available for all League Pass games next season.</p><p>As with the other functionality of the NBA app, this requires a League Pass subscription, which starts at $15/month.</p><figure><a href="https://www.uploadvr.com/f1-lapz-forced-to-stop-apple-vision-pro-testflight/"><div><p>Lapz Forced To Pause Apple Vision Pro TestFlight By F1</p><p>Apple Vision Pro spatial F1 viewer app Lapz has been forced to pause its TestFlight distribution by the Formula One Group.</p><p><img src="https://www.uploadvr.com/content/images/icon/UploadCircle_favicon-568.png" alt=""><span>UploadVR</span><span>David Heaney</span></p></div><p><img src="https://www.uploadvr.com/content/images/thumbnail/F1-on-Apple-Vision-Pro-cut-merged-1731703586842-00.00.01.552.jpeg" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>The NBA's Tabletop feature is reminiscent of <a href="https://www.uploadvr.com/f1-lapz-forced-to-stop-apple-vision-pro-testflight/">Lapz</a>, the now-defunct Apple Vision Pro F1 app, which showed a diorama-scale 3D representation of the track floating in front of you, as well as the first-person views from multiple drivers in floating windows.</p><p>Both show the significant potential of XR headsets, and eventually AR glasses, for enhancing the way sports are watched remotely.</p><figure><a href="https://www.uploadvr.com/nba-2024-2025-games-streamed-180-to-quest/"><div><p>52 NBA Games This Season Will Again Be Streamed In 180-Degrees To Quest For Free</p><p>For the fourth year in a row, 52 NBA games this season will be streamed in 180-degrees to Quest headsets in the US for free.</p><p><img src="https://www.uploadvr.com/content/images/icon/UploadCircle_favicon-569.png" alt=""><span>UploadVR</span><span>David Heaney</span></p></div><p><img src="https://www.uploadvr.com/content/images/thumbnail/Xtadium-NBA-games-on-Quest.jpg" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>On Meta Quest headsets, in comparison, 52 NBA games are streamed in immersive 180-degrees (though 2D, not 3D) for free in the US, <a href="https://www.uploadvr.com/nba-2024-2025-games-streamed-180-to-quest/">via the app Xtadium</a>. NBA League Pass subscribers can also use Xtadium to watch any games on floating 2D virtual TV screens in mixed reality using Xtadium's Multi-Game Mode. This mode supports up to nine games simultaneously, and you can also apparently see stats and alerts. But the Vision Pro app's Tabletop feature offers a unique view not yet seen on other XR platforms.</p><p>Would you prefer to watch your sport of choice in 180-degree immersive video, or as a 2D flatscreen view with a tabletop 3D representation? Let us know in the discussion section below.</p>

        
    </article>
    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Delphi Is 30 (136 pts)]]></title>
            <link>https://blog.marcocantu.com/blog/2025-february-delphi-is-30.html</link>
            <guid>43051598</guid>
            <pubDate>Fri, 14 Feb 2025 18:41:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.marcocantu.com/blog/2025-february-delphi-is-30.html">https://blog.marcocantu.com/blog/2025-february-delphi-is-30.html</a>, See on <a href="https://news.ycombinator.com/item?id=43051598">Hacker News</a></p>
Couldn't get https://blog.marcocantu.com/blog/2025-february-delphi-is-30.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[A study on how turtles navigate using the Earth’s magnetic field (156 pts)]]></title>
            <link>https://www.unc.edu/posts/2025/02/12/dancing-turtles-unlock-scientific-discovery/</link>
            <guid>43051465</guid>
            <pubDate>Fri, 14 Feb 2025 18:29:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.unc.edu/posts/2025/02/12/dancing-turtles-unlock-scientific-discovery/">https://www.unc.edu/posts/2025/02/12/dancing-turtles-unlock-scientific-discovery/</a>, See on <a href="https://news.ycombinator.com/item?id=43051465">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>When captive loggerhead sea turtles anticipate food, they do a little dance. The turtles raise their heads out of water, open their mouths, flap their flippers and spin in circles.</p><p>Not only is this “turtle dancing behavior” cute, it was also the key to unlocking a significant scientific discovery by researchers at UNC-Chapel Hill.</p><p>The prestigious international science journal Nature published the study Feb. 12. Kayla Goforth, a recent doctoral graduate in the College of Arts and Sciences’ biology department, is the lead author of “Learned magnetic map cues and two mechanisms of magnetoreception in turtles.”</p><p>Early on in her graduate studies at Carolina, Goforth was fascinated by sea turtles returning to the same feeding sites again and again throughout their lifetimes — despite traveling up to 10,000 miles across the planet. She hypothesized that these turtles used Earth’s magnetic field to memorize specific geographic areas that they associated with food, and she devised an experiment in the biology department’s <a href="https://lohmannlab.web.unc.edu/">Lohmann Lab</a> — run by husband-and-wife duo Kenneth and Catherine Lohmann.</p><p>“Kayla began to wonder if we could get the turtles to associate the magnetic signature of a geographic area with food — and therefore act out this turtle dance behavior,” said Kenneth Lohmann, the Charles P. Postelle Jr. Distinguished Professor of Biology. “She really took the lead in this. I wasn’t at all sure in the beginning whether it would work, but we were happy to have her try, and it turned out remarkably well.”</p><div id="attachment_252848"><p><img fetchpriority="high" decoding="async" aria-describedby="caption-attachment-252848" src="https://www.unc.edu/wp-content/uploads/2025/02/Untitled-design9.gif" alt="Short, soundless video of a small sea turtle flapping around in water." width="800" height="533"></p><p id="caption-attachment-252848">The team of Carolina researchers analyzed how sea turtles use Earth’s magnetic field to guide their long-distance migrations across the ocean, and how the turtles sense magnetic fields.</p></div><p>Goforth and the rest of the all-Carolina team conditioned loggerhead turtles to magnetic fields replicating those that exist in various oceanic locations, repeatedly feeding the turtles in some magnetic fields while not feeding them in others. When later exposed to the fields in which they were fed, the turtles exhibited “turtle dancing behavior,” indicating that they associated that specific magnetic signature with food.</p><p>“That’s how we figured out what to measure, just by watching them do this as we were feeding them in the lab,” said Goforth, who is now conducting postdoctoral research at Texas A&amp;M University. “When they get really excited, they stick their heads out; they slap their flippers wildly; they spin in place sometimes.”</p><p>The assay suggests that loggerhead sea turtles can learn the magnetic signatures of geographical areas — much like dropping a pin in a GPS app.</p><div id="attachment_252840"><p><img decoding="async" aria-describedby="caption-attachment-252840" src="https://www.unc.edu/wp-content/uploads/2025/02/HatchlingLoggerheadMultitudes-225x300.jpeg" alt="Aerial image of many sea turtles on a beach." width="225" height="300" srcset="https://www.unc.edu/wp-content/uploads/2025/02/HatchlingLoggerheadMultitudes-225x300.jpeg 225w, https://www.unc.edu/wp-content/uploads/2025/02/HatchlingLoggerheadMultitudes-768x1024.jpeg 768w, https://www.unc.edu/wp-content/uploads/2025/02/HatchlingLoggerheadMultitudes-1152x1536.jpeg 1152w, https://www.unc.edu/wp-content/uploads/2025/02/HatchlingLoggerheadMultitudes-1536x2048.jpeg 1536w, https://www.unc.edu/wp-content/uploads/2025/02/HatchlingLoggerheadMultitudes-scaled.jpeg 1920w" sizes="(max-width: 225px) 100vw, 225px"></p><p id="caption-attachment-252840">The groundbreaking study was published in the prestigious international science journal Nature. (Ken Lohmann/biology department)</p></div><p>When turtles use magnetic signatures, they are using their magnetic map sense, but they also have a magnetic compass sense that enables them to move north, south or some other direction. The research further showed that the map and compass senses detect magnetic fields in different ways.</p><p>Working in collaboration with the College’s physics and astronomy department, the team investigated the effects of radiofrequency oscillating magnetic fields on the turtles’ magnetic senses. What the team found surprised them. The oscillating magnetic fields had no impact on the turtles’ magnetic map ability but did disrupt the turtles’ ability to use the magnetic compass and orient themselves.</p><p>“It suggested there are two different mechanisms for the magnetic map and compass,” Goforth said. “And they might have evolved separately.”</p><p>Exactly how turtles and other migratory species use these senses is a question that has baffled scientists for more than 50 years, and it’s one that Goforth continues to research at Texas A&amp;M, now studying monarch butterflies instead of sea turtles.</p><p>“The big question is always the mechanism,” Goforth said. “What’s the mechanism and what is the sensor? We know that for the visual sense, you have eyes; for the sense of smell, you have a nose; and for hearing, you have ears. But no receptor like that has been identified for the magnetic sense, and the mechanism remains unknown.”</p><div id="attachment_252838"><p><img decoding="async" aria-describedby="caption-attachment-252838" src="https://www.unc.edu/wp-content/uploads/2025/02/TurtleEmbedFinal-1024x576.jpg" alt="Hand holding a tiny sea turtle." width="1024" height="576" srcset="https://www.unc.edu/wp-content/uploads/2025/02/TurtleEmbedFinal-1024x576.jpg 1024w, https://www.unc.edu/wp-content/uploads/2025/02/TurtleEmbedFinal-300x169.jpg 300w, https://www.unc.edu/wp-content/uploads/2025/02/TurtleEmbedFinal-768x432.jpg 768w, https://www.unc.edu/wp-content/uploads/2025/02/TurtleEmbedFinal-1536x864.jpg 1536w, https://www.unc.edu/wp-content/uploads/2025/02/TurtleEmbedFinal-1200x675.jpg 1200w, https://www.unc.edu/wp-content/uploads/2025/02/TurtleEmbedFinal-800x450.jpg 800w, https://www.unc.edu/wp-content/uploads/2025/02/TurtleEmbedFinal-600x338.jpg 600w, https://www.unc.edu/wp-content/uploads/2025/02/TurtleEmbedFinal-550x310.jpg 550w, https://www.unc.edu/wp-content/uploads/2025/02/TurtleEmbedFinal-450x253.jpg 450w, https://www.unc.edu/wp-content/uploads/2025/02/TurtleEmbedFinal-350x196.jpg 350w, https://www.unc.edu/wp-content/uploads/2025/02/TurtleEmbedFinal-250x141.jpg 250w, https://www.unc.edu/wp-content/uploads/2025/02/TurtleEmbedFinal-200x112.jpg 200w, https://www.unc.edu/wp-content/uploads/2025/02/TurtleEmbedFinal.jpg 1600w" sizes="(max-width: 1024px) 100vw, 1024px"></p><p id="caption-attachment-252838">(Ken Lohmann/biology department)</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Detecting AI agent use and abuse (143 pts)]]></title>
            <link>https://stytch.com/blog/detecting-ai-agent-use-abuse/</link>
            <guid>43049959</guid>
            <pubDate>Fri, 14 Feb 2025 16:18:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stytch.com/blog/detecting-ai-agent-use-abuse/">https://stytch.com/blog/detecting-ai-agent-use-abuse/</a>, See on <a href="https://news.ycombinator.com/item?id=43049959">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>AI agents aren’t just indexing your content anymore. With tools like OpenAI’s Operator, Anthropic’s Computer Use API, and BrowserBase’s Open Operator, these agents can navigate the web, mimic real users, and even take actions at scale. The challenge? Knowing whether they’re enhancing your user experience—or opening the door to abuse.</p><p>In some scenarios, apps might encourage agent use if it improves usability and adoption, but in other cases, it could present unacceptable risks for application developers or be used as a method for malicious attacks (e.g. credential stuffing or fake account creation).</p><p>In either scenario, observability is paramount. Applications need to know what traffic is on their site (is this a human? A bot? A good bot or a bad one?) in order to make intelligent decisions about how to shape traffic and enforce desired usage patterns. AI agents add an additional wrinkle as users are already sharing their credentials with tools like Operator, meaning even a well-intentioned agent creates potential risk for these applications and their users.</p><p>The key question is: <strong>Can you detect AI agent traffic on your application today?</strong></p><p>We tested multiple AI agent toolkits across high-traffic consumer sites, and the results were clear—legacy detection techniques (CAPTCHAs, IP blocking, user-agent filtering) are largely ineffective. Here’s what we found.</p><h2 id="thenewrealityofbottrafficwhataiagenttrafficlookslike">The New Reality of Bot Traffic:<strong> </strong>What AI Agent Traffic Looks Like</h2><p>Traditionally, bot detection relied on CAPTCHAs, IP blocking, and user-agent filtering. But modern AI agents are engineered to look like actual users:</p><ul><li><strong>Realistic fingerprints:</strong> They use genuine IP addresses, user agents, and even simulate mouse movements.</li><li><strong>Headless browsing at human speeds:</strong> Their interactions mimic natural browsing behavior, evading rate-limit triggers.</li><li><strong>Datacenter origins—but not always:</strong> While some (like OpenAI’s Operator) come from known Azure datacenters, others (like Anthropic’s API) can run locally, borrowing your machine’s properties.</li></ul><div><figure><img alt="Reddit blocking AI agent operators." loading="lazy" width="726" height="753" decoding="async" data-nimg="1" srcset="https://cdn.sanity.io/images/3jwyzebk/production/e195fa64f9235588fb217cae233f3258d7ac3e9a-726x753.png?auto=format&amp;fit=max&amp;w=750&amp;q=75 1x, https://cdn.sanity.io/images/3jwyzebk/production/e195fa64f9235588fb217cae233f3258d7ac3e9a-726x753.png?auto=format&amp;fit=max&amp;w=1920&amp;q=75 2x" src="https://cdn.sanity.io/images/3jwyzebk/production/e195fa64f9235588fb217cae233f3258d7ac3e9a-726x753.png?auto=format&amp;fit=max&amp;w=1920&amp;q=75"><figcaption></figcaption></figure></div><p>On the surface level, AI agent traffic can look quite similar to regular human user traffic. Here are examples of browser &amp; network properties across different AI agents:</p><table><thead><tr><td></td><th><h4>Open AI Operator</h4></th><th><h4>Anthropic Computer Use API</h4></th><th><h4>BrowserBase Open Operator</h4></th></tr></thead><tbody><tr><td colspan="3"><h4>User Agent</h4></td></tr><tr><td><h4>User Agent</h4></td><td><p>Chrome on Linux (standard fingerprint)</p></td><td><p>Firefox on Ubuntu (stable, unless run locally)</p></td><td><p>Chrome on Mac (with stealth features)</p></td></tr><tr><td colspan="3"><h4>IP Address</h4></td></tr><tr><td><h4>IP Address</h4></td><td><p>Known Azure Datacenter IP</p></td><td><p>Varies—depends on local vs. cloud deployment</p></td><td><p>Known AWS Datacenter IP</p></td></tr><tr><td colspan="3"><h4>Browser Version</h4></td></tr><tr><td><h4>Browser Version</h4></td><td><p>Chrome 130</p></td><td><p>Firefox 128</p></td><td><p>Chrome 124</p></td></tr><tr><td colspan="3"><h4>Location</h4></td></tr><tr><td><h4>Location</h4></td><td><p>San Francisco, California</p></td><td><p>San Jose, California</p></td><td><p>Boardman, Oregon</p></td></tr><tr><td colspan="3"><h4>ASN</h4></td></tr><tr><td><h4>ASN</h4></td><td><p>8075</p></td><td><p>398391</p></td><td><p>16509</p></td></tr><tr><td colspan="3"><h4>ASN Name</h4></td></tr><tr><td><h4>ASN Name</h4></td><td><p>Microsoft</p></td><td><p>Perimeter 81</p></td><td><p>Amazon</p></td></tr><tr><td colspan="3"><h4>Detection Difficulty</h4></td></tr><tr><td><h4>Detection Difficulty</h4></td><td><p>Easy</p></td><td><p>Harder</p></td><td><p>Moderate</p></td></tr></tbody></table><p>Both OpenAI’s Operator and BrowserBase’s Open Operator spin up <strong>remote datacenter or container‑hosted</strong> Chromium instances, rather than installing any software on your local machine. Because these solutions originate from a cloud‑hosted environment (with IP addresses and other signatures tied to the provider’s infrastructure), they can be <strong>easier to detect</strong> via methods like ASN lookups if the provider’s IP ranges are well known.</p><p>By contrast, Anthropic’s “Computer Use” functionality is available only through its API as of now, and you can choose how to run that API (e.g., directly on your own machine vs. inside a VM or container). If you run it locally, it inherits your local system’s properties like IP and ASN; if you host it in the cloud, it uses whichever environment that provider offers. Each approach has its own implications for fingerprinting and detection.</p><p>Currently, Anthropic provides two options for using their agent:</p><ol><li>Direct use of your computer environment (not recommended due to security concerns around unrestricted access).</li><li><a rel="noreferrer noopener" href="https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo">Setting up a virtual machine or container</a> with minimal privileges to run the API. You can either run this locally or deploy to a cloud provider using Docker, in which case it won’t inherit the user’s network properties.</li></ol><p>Whereas stricter sites like Reddit block OpenAI and BrowserBase outright, Anthropic’s approach allows it to successfully bypass even these strict sites when run locally:</p><div><figure><img alt="Reddit not detecting Anthropic Computer Use" loading="lazy" width="1999" height="1052" decoding="async" data-nimg="1" srcset="https://cdn.sanity.io/images/3jwyzebk/production/8f0baeec42be860a2e92d0b61501865cdc8f98fe-1999x1052.png?auto=format&amp;fit=max&amp;w=2048&amp;q=75 1x, https://cdn.sanity.io/images/3jwyzebk/production/8f0baeec42be860a2e92d0b61501865cdc8f98fe-1999x1052.png?auto=format&amp;fit=max&amp;w=3840&amp;q=75 2x" src="https://cdn.sanity.io/images/3jwyzebk/production/8f0baeec42be860a2e92d0b61501865cdc8f98fe-1999x1052.png?auto=format&amp;fit=max&amp;w=3840&amp;q=75"><figcaption>Certain deployments of Anthropic’s approach make it harder for sites like Reddit and Youtube, which block OpenAI Operator, to detect this traffic.</figcaption></figure></div><p>And with tools like BrowserBase, there are also now open-sourced options for building browsing AI agents that allow potential attackers to increase the stealth of their headless browsing setup. This means we should expect continued, quick iteration on some agent use cases that will make them even more difficult to detect. As an example, BrowserBase offers premium plans with more advanced stealth to bypass CAPTCHA and other detection techniques:</p><div><figure><img alt="BrowserBase pricing plans." loading="lazy" width="1365" height="882" decoding="async" data-nimg="1" srcset="https://cdn.sanity.io/images/3jwyzebk/production/ac02c236c4b8f431348c6e0ec0505dd2042518ab-1365x882.png?auto=format&amp;fit=max&amp;w=1920&amp;q=75 1x, https://cdn.sanity.io/images/3jwyzebk/production/ac02c236c4b8f431348c6e0ec0505dd2042518ab-1365x882.png?auto=format&amp;fit=max&amp;w=3840&amp;q=75 2x" src="https://cdn.sanity.io/images/3jwyzebk/production/ac02c236c4b8f431348c6e0ec0505dd2042518ab-1365x882.png?auto=format&amp;fit=max&amp;w=3840&amp;q=75"><figcaption>Premium plans on BrowserBase come with more advanced stealth features</figcaption></figure></div><p>Today, most sites are allowing agent traffic to navigate freely – whether these sites are detecting the abnormalities of this traffic (and choosing not to take action) is hard to say. For some like Reddit &amp; Youtube, their block on OpenAI Operator indicates they want to lock down agentic traffic. When these AI Agents bypass their restrictions (as detailed below), it’s a good signal those tools are actually flying below their radar today versus being officially sanctioned.</p><p>For others that allow this traffic, they may actually encourage it for user convenience or potentially have perverse incentives in some cases to allow a certain amount of bot traffic (Ticketmaster is a potential example of this given they can benefit from some level of bot activity increasing ticket purchase rates). Many more sites, however, simply don’t have the traffic intelligence to detect these AI agents, which explains why they can operate freely.</p><p>In testing the three primary AI Agent browsing toolkits on a set of high traffic consumer sites, we found that Youtube and Reddit were the only ones that consistently blocked this traffic:</p><table><thead><tr><td></td><th><h4>OpenAI Operator</h4></th><th><h4>Anthropic Computer Use API</h4></th><th><h4>BrowserBase Open Operator</h4></th></tr></thead><tbody><tr><td colspan="3"><h4>Youtube</h4></td></tr><tr><td><h4>Youtube</h4></td><td><p>❌</p></td><td><p>✅</p></td><td><p>✅</p></td></tr><tr><td colspan="3"><h4>Reddit</h4></td></tr><tr><td><h4>Reddit</h4></td><td><p>❌</p></td><td><p>✅</p></td><td><p>❌</p></td></tr><tr><td colspan="3"><h4>LinkedIn</h4></td></tr><tr><td><h4>LinkedIn</h4></td><td><p>✅</p></td><td><p>✅</p></td><td><p>✅</p></td></tr><tr><td colspan="3"><h4>Twitter/X</h4></td></tr><tr><td><h4>Twitter/X</h4></td><td><p>✅</p></td><td><p>✅</p></td><td><p>✅</p></td></tr><tr><td colspan="3"><h4>Facebook.com</h4></td></tr><tr><td><h4>Facebook.com</h4></td><td><p>✅</p></td><td><p>✅</p></td><td><p>✅</p></td></tr><tr><td colspan="3"><h4>OpenTable</h4></td></tr><tr><td><h4>OpenTable</h4></td><td><p>✅</p></td><td><p>✅</p></td><td><p>✅</p></td></tr><tr><td colspan="3"><h4>Pinterest</h4></td></tr><tr><td><h4>Pinterest</h4></td><td><p>✅</p></td><td><p>✅</p></td><td><p>✅</p></td></tr><tr><td colspan="3"><h4>Nike</h4></td></tr><tr><td><h4>Nike</h4></td><td><p>✅</p></td><td><p>✅</p></td><td><p>✅</p></td></tr></tbody></table><p>Few websites are blocking popular AI Agents today – indicating either a lack of detection, ambivalence towards enforcement, or both. Reddit &amp; Youtube are a couple of key outliers that block this traffic when they can discern it.</p><p>Still, the differences are interesting. It’s worth understanding why Anthropic or BrowserBase are sometimes able to bypass sites that otherwise are blocking this traffic. In BrowserBase’s case, they generate a slightly different user-agent each session, which sometimes aligns with the underlying chromium runtime but sometimes attempts to be deceptive by claiming to be a different version, which leads to more inconsistency in whether companies detect it correctly.</p><p>Companies like LinkedIn and X are particularly sensitive to scraping on their sites, so the lack of enforcement is surprising. This suggests they’re not currently able to confidently discern this is programmatic traffic.</p><h2 id="howtotellanagentfromahuman">How to Tell an Agent from a Human</h2><p>The obvious question here is: <strong>shouldn't this be easy to detect by using just an IP or user agent?</strong></p><p>And the answer is yes and no. For OpenAI Operator, it’s pretty straightforward to detect given its stability &amp; origin point. For Anthropic and BrowserBase (and the new agents entering the market), it’s a bit more complicated.</p><table><thead><tr><td></td><th><h4>OpenAI Operator</h4></th><th><h4>Anthropic Computer Use API</h4></th><th><h4>BrowserBase Open Operator</h4></th></tr></thead><tbody><tr><td colspan="3"><h4>Browser Stack</h4></td></tr><tr><td><h4>Browser Stack</h4></td><td><p>Chromium</p></td><td><p>Firefox</p></td><td><p>Chromium</p></td></tr><tr><td colspan="3"><h4>IP address properties</h4></td></tr><tr><td><h4>IP address properties</h4></td><td><p>Known Azure Datacenter</p></td><td><div variant="listItem"><p>Depends on how you run it:</p><ul><li>Unlike Operator, you can run it locally directly on your machine or (recommended) on a dockerized container. In this case, it inherits your own device’s IP &amp; characteristics</li><li>In production, you’d likely host it in AWS/Azure/etc and traffic would come from known data centers</li></ul></div></td><td><p>Known AWS Datacenter</p></td></tr><tr><td colspan="3"><h4>IP stability</h4></td></tr><tr><td><h4>IP stability</h4></td><td><p>Remains stable</p></td><td><p>Remains stable</p></td><td><p>Churns</p></td></tr><tr><td colspan="3"><h4>User Agent</h4></td></tr><tr><td><h4>User Agent</h4></td><td><p>Remains stable</p></td><td><p>Remains stable</p></td><td><p>Churns</p></td></tr><tr><td colspan="3"><h4>CAPTCHA handling</h4></td></tr><tr><td><h4>CAPTCHA handling</h4></td><td><p>Hands off to user</p></td><td><p>Hands off to user</p></td><td><p>Offers options for automatically solving</p></td></tr></tbody></table><p>Some key elements worth knowing:</p><ul><li>OpenAI &amp; BrowserBase both operate on top of chromium – being able to discern chromium browsers vs. true chrome is key for detecting the latter since BrowserBase modifies things like IP, user agent, etc for increased stealth.</li><li>OpenAI originates out of a known Azure datacenter while BrowserBase originates from a known AWS datacenter.</li><li>OpenAI hands off non-invisible CAPTCHAs to the end user to complete, while BrowserBase offers options for automatically solving.</li></ul><p>Ideally, you want to detect this traffic beyond more coarse identifiers like known datacenter IPs so that your detection is fully resistant to adjustments agentic traffic will make in the future. And core to that is having high confidence in whether a browser interacting with your site is a real browser or a headless instrumentation.</p><p>This is where we’ve personally found Machine Learning to be incredibly useful by building a browser lie detector. We look at a very wide range of browser signals &amp; we have downloaded the entire historical archives of every browser version that has been released that we can find and trained our model on what authentic browsers look like vs. anomalous or deceitful browsers. </p><p>To provide this visibility, we’ve automated additions of new legitimate browser signatures upon new releases, we fingerprint it, run it past the model to establish an authentic set of signals for the current browser version, allowing us to detect anyone trying to emulate that version inorganically. With that fingerprinted dataset, machine learning can be used to detect anomalies with high accuracy. It’s this signal collection that has allowed us to see that OpenAI &amp; BrowserBase are full chromium builds, while Anthropic’s Firefox browser fails to emulate certain characteristics that would be present on a real user’s Firefox instance.</p><h2 id="chartingyourpathforward"><strong>Charting Your Path Forward</strong></h2><p>Whether you choose to block, restrict, or harness AI agent traffic, effective observability is non-negotiable. Here’s our current playbook:</p><ul><li><strong>Monitor actively:</strong> Start by detecting and monitoring AI agent fingerprints. Learn from their behavior before enforcing hard limits.</li><li><strong>Embrace legitimate use cases:</strong> Some users may leverage AI agents to streamline workflows (e.g., automating reporting on your dashboard). Recognize these opportunities while safeguarding against abuse.</li><li><strong>Iterate quickly:</strong> As AI agents evolve, so must your detection strategies. Invest in ML-based solutions that adapt alongside new agent behaviors.</li></ul><p>AI agents are rewriting the rules of web interaction. They offer exciting UX advancements—but also present new security challenges. The race is on: evolve your detection or risk being outpaced by bad actors and unintended misuse.</p><p>If you’re interested in learning more about how to detect these agents &amp; enforce certain behaviors, <a rel="noreferrer noopener" href="https://stytch.com/contact">reach out to us to chat more</a> (or take a look at the <a rel="noreferrer noopener" href="https://stytch.com/docs/fraud">fingerprinting techniques we’re using to detect them</a>).</p><div><div><h3>Try Device Fingerprinting</h3><p>99.99% bot detection, intelligent rate limiting, and reverse engineering protection.</p></div><p><a href="https://stytch.com/docs/fraud">Read the docs</a></p></div></div></div>]]></description>
        </item>
    </channel>
</rss>