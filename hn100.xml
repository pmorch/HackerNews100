<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 07 May 2025 21:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Three Chapters at Cloudflare: Programmer to CTO to Board of Directors (140 pts)]]></title>
            <link>https://blog.cloudflare.com/en-us/three-chapters-at-cloudflare-programmer-to-cto-to-board-of-directors/</link>
            <guid>43918600</guid>
            <pubDate>Wed, 07 May 2025 17:43:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.cloudflare.com/en-us/three-chapters-at-cloudflare-programmer-to-cto-to-board-of-directors/">https://blog.cloudflare.com/en-us/three-chapters-at-cloudflare-programmer-to-cto-to-board-of-directors/</a>, See on <a href="https://news.ycombinator.com/item?id=43918600">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post"><article><p>2025-03-27</p><section><p>4 min read</p><img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3WjSvoGBEfq01eYJ0hrlVH/dfd40ec4bea05d31c9030c9ce2284d75/unnamed__1_.png" alt=""><div><p>Today, after more than 13 years at the company, I am joining Cloudflare’s board of directors and retiring from my full-time position as CTO. </p><p>Back in 2012 I wrote a short post on my personal site simply titled: <a href="https://blog.jgc.org/2012/02/programmer.html"><u>Programmer</u></a>. The post announced that I’d recently joined a company called CloudFlare (still sporting that capital “F”) with the job title Programmer. I’d chosen that title in part because it was the very first title I’d ever had, and because it would reflect what I’d be doing at Cloudflare.</p><p>I had spent a lot of time working at startups—in technical and then management roles—and wanted to go back to the really technical part that I loved most. Cloudflare gave me that opportunity, and I worked on a lot of systems that make up the Cloudflare that so many people around the world use today.</p><p>Looking back on my time at the company it’s really, really hard to pick my top highlights. In 2019 <a href="https://blog.cloudflare.com/helping-to-build-cloudflare-part-1/"><u>I wrote 6,000 words on the experience of helping build Cloudflare</u></a>. But here are five that stand out:</p>
          <p>
            <h3 id="always-be-shipping">Always be shipping</h3>
            
          </p>
        <p>The night we finished the preparation to launch <a href="https://blog.cloudflare.com/introducing-universal-ssl/"><u>Universal SSL</u></a> sticks in my memory. We set out to offer the Industry's First Universal SSL for free, effectively doubling the size of the encrypted web overnight, a big deal in 2014. I remember Cloudflare’s third co-founder, Lee Holloway, hunched over his laptop finishing the code. The team has been working on it all weekend, and late that Sunday night Lee announced “it’s done.”&nbsp;</p>
          <p>
            <h3 id="handling-adversity">Handling adversity</h3>
            
          </p>
        <p>It’s easy to pick moments of great success or when things went really well and <a href="https://blog.cloudflare.com/helping-to-build-cloudflare-part-2/"><u>Cloudbleed in 2017</u></a> may not seem like a special moment, but it helped show who we were. It showed how a team could come together under intense stress, and how we could set the standard going forward for how companies disclose and talk about security problems. I personally discovered that a Google Meet call can be kept running for 24 hours and sleeping in two hour chunks is possible.</p>
          <p>
            <h3 id="being-international-and-intentional">Being international and intentional</h3>
            
          </p>
        <p>Originally from the UK, I was the first team member located outside the United States. I got to help build the largest offices outside the US: first, Cloudflare’s London office and then Cloudflare’s <a href="https://blog.cloudflare.com/cloudflare-lisbon-office/"><u>Lisbon office</u></a>. These two offices are a big part of who we are today, with Lisbon being our European HQ.</p><p>When COVID halted our in-office work, I was blown away by the response from the team. As we all individually faced different difficulties because of the pandemic we continued to work together to ensure that the Internet, on which everyone was relying while confined at home, worked reliably and securely.</p>
          <p>
            <h3 id="truly-impactful-technology">Truly impactful technology</h3>
            
          </p>
        <p>Picking a favourite product would be a bit like asking someone to choose their favourite child, but I have soft spots for Cloudflare’s WAF, DNS, and DDoS solutions because I personally worked on those systems. And I still feel I need to apologize to the WAF team who took over my code and had to face that one Perl script that shall not be named!</p><p>Beyond the products there’s something much deeper: Cloudflare’s mission to help build a better Internet. I’ve been very proud of how we have supported and advanced the Internet itself through our work on the latest standards and protocols. And I’m even prouder of the role we’ve played through Project Galileo, The Athenian Project, and Cloudflare for Campaigns.</p>
          <p>
            <h3 id="the-people">The people</h3>
            
          </p>
        <p>Every week Cloudflare holds an all-hands company meeting which ends with “Shoutouts,” a chance to recognize members of the team who have gone above and beyond. Curiosity and empathy are two core values at Cloudflare, and I am struck every week by how often we’re recognizing teams of people who are being thanked for helping with a sale, fixing a bug, responding to an incident, or helping build Cloudflare. That team spirit is part of what makes Cloudflare a special place to work.</p><p>One of the things I will miss about not being at Cloudflare day-to-day is the incredible strength of the individual team members. I’ve been learning from them for 13 years straight!</p>
          <p>
            <h3 id="whats-next">What’s next</h3>
            
          </p>
        <p>When I joined the company the team was a lot smaller! We were 25 people and now, we’ve grown to more than 4,200 employees and 15 locations across the globe. As we grew I wore a lot of different hats. For a time I ran engineering, operations, security, and even IT. And, of course, I wrote for, and edited, the Cloudflare Blog for many, many years. Over time, we hired many great leaders to run those teams.</p><p>But the role that persisted was CTO. And today, we are announcing that, just as I gave up the title Programmer (and the programming that went along with it), I am giving up the title CTO (and the role’s responsibilities) for a new way to help Cloudflare grow and succeed, as a member of the board of directors.</p><p>Last year when I told Matthew that I planned to retire, I had not expected to be offered a seat on the company’s board. It’s an incredible and rare honour to go from being an employee of the company (albeit one who has been there from close to the beginning) to joining the board of directors. I am absolutely thrilled to be able to continue helping Cloudflare grow and succeed from a slightly different vantage point.</p><p>At the same time, Dane Knecht, who, until today, was SVP of Emerging Technology and Incubation, has become our CTO. Dane joined just a few months after me, and is uniquely positioned and experienced to take the CTO role. We’ve worked so closely for the last 13 years as peers, that in many meetings it would’ve been hard to distinguish our roles. I’m pretty sure that Dane bleeds Cloudflare orange, and I’ve never seen him wear a T-shirt that doesn’t say Cloudflare on it. He has been part of nearly every major milestone here at Cloudflare. He cares so deeply about the company, and its success; he will make a great CTO.</p><p>My plan isn’t to go off and work somewhere else, or start a new company. I intend to remain closely involved with Cloudflare in my role on the board. I am incredibly honoured, and grateful to have been part of Cloudflare’s incredible growth and success, and I am looking forward to helping the company continue its growth.</p><p>One area I’m particularly interested in assisting with is the company’s work across the product suite on AI. Back in 2002 (23 years ago! gulp!). I wrote a very popular open source machine learning (didn’t call it AI back then) <a href="https://en.wikipedia.org/wiki/POPFile"><u>email filtering program</u></a> and in 2004 worked on how to deal with what happens when <a href="https://blog.jgc.org/2023/07/how-to-beat-adaptivebayesian-spam.html"><u>one AI system is used to attack another</u></a>. At Cloudflare, we’ve used learning techniques to enhance security, block bots, and predict how our systems should behave and grow. There’s much more to do.</p><p>Just as co-founder <a href="https://blog.cloudflare.com/author/michelle-zatlyn/"><u>Michelle</u></a> likes to say: we’re just getting started. And so am I.</p></div></section><div><p>Cloudflare's connectivity cloud protects <a target="_blank" href="https://www.cloudflare.com/network-services/" rel="noreferrer">entire corporate networks</a>, helps customers build <a target="_blank" href="https://workers.cloudflare.com/" rel="noreferrer">Internet-scale applications efficiently</a>, accelerates any <a target="_blank" href="https://www.cloudflare.com/performance/accelerate-internet-applications/" rel="noreferrer">website or Internet application</a>, <a target="_blank" href="https://www.cloudflare.com/ddos/" rel="noreferrer">wards off DDoS attacks</a>, keeps <a target="_blank" href="https://www.cloudflare.com/application-security/" rel="noreferrer">hackers at bay</a>, and can help you on <a target="_blank" href="https://www.cloudflare.com/products/zero-trust/" rel="noreferrer">your journey to Zero Trust</a>.</p><p>Visit <a target="_blank" href="https://one.one.one.one/" rel="noreferrer">1.1.1.1</a> from any device to get started with our free app that makes your Internet faster and safer.</p><p>To learn more about our mission to help build a better Internet, <a target="_blank" href="https://www.cloudflare.com/learning/what-is-cloudflare/" rel="noreferrer">start here</a>. If you're looking for a new career direction, check out <a target="_blank" href="https://www.cloudflare.com/careers" rel="noreferrer">our open positions</a>.</p></div><a href="https://blog.cloudflare.com/tag/life-at-cloudflare/">Life at Cloudflare</a></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ty: A fast Python type checker and language server, written in Rust (356 pts)]]></title>
            <link>https://github.com/astral-sh/ty</link>
            <guid>43918484</guid>
            <pubDate>Wed, 07 May 2025 17:32:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/astral-sh/ty">https://github.com/astral-sh/ty</a>, See on <a href="https://news.ycombinator.com/item?id=43918484">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">ty</h2><a id="user-content-ty" aria-label="Permalink: ty" href="#ty"></a></p>
<p dir="auto">An extremely fast Python type checker and language server, written in Rust.</p>
<p dir="auto"><strong>This project is still in development and is not ready for production use.</strong></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting involved</h2><a id="user-content-getting-involved" aria-label="Permalink: Getting involved" href="#getting-involved"></a></p>
<p dir="auto">If you have questions or want to report a bug, please open an
<a href="https://github.com/astral-sh/ty/issues">issue</a> in this repository.</p>
<p dir="auto">Development of this project takes place in the <a href="https://github.com/astral-sh/ruff">Ruff</a> repository
at this time. Please <a href="https://github.com/astral-sh/ruff/pulls">open pull requests</a> there for changes
to anything in the <code>ruff</code> submodule (which includes all of the Rust source code).</p>
<p dir="auto">See the
<a href="https://github.com/astral-sh/ty/blob/main/CONTRIBUTING.md">contributing guide</a> for more details.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">ty is licensed under the MIT license (<a href="https://github.com/astral-sh/ty/blob/main/LICENSE">LICENSE</a> or
<a href="https://opensource.org/licenses/MIT" rel="nofollow">https://opensource.org/licenses/MIT</a>).</p>
<p dir="auto">Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in ty
by you, as defined in the MIT license, shall be licensed as above, without any additional terms or
conditions.</p>
<p><a href="https://astral.sh/" rel="nofollow">
    <img src="https://raw.githubusercontent.com/astral-sh/uv/main/assets/svg/Astral.svg" alt="Made by Astral">
  </a>
</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Getting Older Isn't What You Think (130 pts)]]></title>
            <link>https://www.katycowan.co.uk/blog/getting-old</link>
            <guid>43917855</guid>
            <pubDate>Wed, 07 May 2025 16:41:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.katycowan.co.uk/blog/getting-old">https://www.katycowan.co.uk/blog/getting-old</a>, See on <a href="https://news.ycombinator.com/item?id=43917855">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-54a1062e88e967d6c807">
  <p>Getting old creeps up on you. It’s not sudden. There’s no dramatic moment where you wake up and realise you’re “not getting any younger”. No — it’s more like a slow progression. One day, you’re out at a bar, dancing with friends, living your best life, and the next, you’re peeking over your sunglasses in horror at someone calling 36 “old”.</p><p>Case in point: I was at a pub the other evening. Lovely place. Wood-fired pizza, fairy lights, good vibes. The chap manning the pizza oven — a friendly local lad — was chatting with some customers about how old he felt now he was 36. “It’s nice being this age because I have <em>wisdom</em>,” he said earnestly, as I slid my sunglasses to the tip of my nose to double-check I’d heard him right. “Oh please,” I muttered under my breath. “Add a decade, mate, and <em>then</em> we’ll talk…”</p><p>But I get it. I really do. Lately, I’ve been noticing little shifts in myself, too. I recently watched Bob Mortimer and Paul Whitehouse chatting about how they now prefer peace and quiet, and I felt seen. For years, I resisted it — the craving for calm. But these days, there’s nothing lovelier than a Saturday morning with a bit of jazz or classical playing, pottering about the kitchen, and then being tucked up in bed before 10pm. Wild.</p><p>And then there are the festivals. I saw a reel the other day of a young woman lamenting how too put-together everyone looks at Coachella now. She missed the old days — the raw Glastonbury vibes when Kate Moss and Alexa Chung looked cool in a completely effortless, “slightly grubby way”. Give me strength. In my day, we weren’t worried about matching our outfits to the sunset. We wore walking gear. Fleeces. Army boots. Practicality over aesthetics. The moment I saw girls tottering through the Glasto mud in silver hot pants and white knee-high boots, I knew the party was over — for me, at least.</p><p>I’m getting old. There, I said it. But honestly? Is this really an age thing, or more of a realisation that I might always have preferred a quieter life? I suspect it’s the latter. And where do these expectations and stereotypes come from anyway? Are they ones we put on ourselves, or do they come from others?</p><p>Yes, I once enjoyed the gigs, the clubbing… the organised fun of it all. But these days? Give me a freshly laundered set of pyjamas and a good book any day over a weekend at a boutique festival. This isn’t about the looming big birthday on the horizon. I know plenty of people my age who are still partying — because they always loved it.</p><p>I guess I’m feeling reflective. I’m turning 50 soon. And so far, this whole ageing conversation has been dominated by the Boomers, often blamed for the world’s problems or pitted against younger generations. A tad unfair. They just happened to get lucky, right?</p><p>Meanwhile, I come from a brilliant generation that’s hardly ever talked about.</p><p>We were the kids who missed the first wave of acid house but still got swept up in the afterglow. We straddle the line between Gen X and Millennials — the so-called Xennials. We grew up analogue and came of age in the digital revolution. We spent more time climbing trees, riding bikes and playing football than we looked at any screen. We remember our landline numbers (mine had four digits), taping songs off the radio, and the thrill of a HMV shopping spree. We experienced life without social media, but we also remember getting our first Nokia and the magic of MSN Messenger. And we watched in awe as computers went from enormous desktop towers to sleek little rectangles we now carry around in our pockets.</p><p>We had dial-up internet and floppy disks, but we also built our first websites on GeoCities and wrote painstaking HTML in Notepad. We remember MySpace before Facebook and how thrilling it was to burn your own CD mixes. We lived through the Y2K panic, wore chokers, ankle bracelets, and Kickers, and watched <em>Friends</em> live, not on Netflix. We worshipped the TV and waited weeks for new films to arrive on VHS. In our teenage years, many of us were into Rage Against The Machine, Faith No More, The Prodigy and LTJ Bukem. We loved The Word and EuroTrash. Some of us got stoned on purpose to enjoy playing WipeOut on the first-ever PlayStation. We bought MixMag for the gig and club listings. We remember festivals before they became a fashion parade. And yes, some of us took drugs and travelled the world. I certainly did. Fridays were once sacred, too, and Tim Westwood’s jingle on Radio One always marked the beginning of another weekend.</p><p>We’re a small generation, often overlooked, but we’ve lived through more change than most—from mixtapes to Spotify, from faxes to WhatsApp, from digital revolution to AI. And because we existed in that liminal space, we carry a weird dual wisdom: we know how to live offline, but we can thrive online, too.</p><p>We understand the value of privacy and impermanence because we remember a time before everything was public and permanent. And maybe that’s why so many of us are quietly deleting our social media accounts and leaning into real life again — books, dinners, walks, actual phone calls. Imagine!</p><p>We were also Cool Britannia — all about unity, not division. One love. It makes me sad to see what social media has done to the world — all the anxiety, the polarisation, the performance. And honestly? I’m quietly pleased to see its grip loosening.</p><p>These days, I sometimes catch myself muttering at the telly, shaking my head at a clueless reality show contestant, thinking: <em>You just wait, sunshine. You’ll get old, too.</em> And yes, I do roll my eyes at some of the newer buzzwords. But I try to check myself. Because if ageing has taught me anything, it’s that the biggest danger is certainty.</p><p>That’s the tension, isn’t it? The constant tug-of-war between feeling grumpy and still clinging to some version of youth. I never thought I’d be that person. But here I am.</p><p>Yes, getting older can mean becoming stuck or rigid. But ironically, I’ve seen just as much of that in younger people lately — unwilling to listen, quick to judge, terrified of being wrong. When nuanced debate disappears, we stop growing. And the less we challenge ourselves, the dumber we become, not smarter.</p><p>So here’s what I try to remember, at any age: stay curious. Never assume you’re right. Read the newspapers you’d generally avoid. Challenge even your most cherished opinions. Try to see more than one side. You won’t always succeed, but it’s worth the effort.</p><p>Because if growing older has taught me anything, it’s this: certainty is overrated, and listening is wildly underrated. Cosy nights in don’t mean you’ve given up. They just mean you know what you like — and that maybe, just maybe, you never truly loved going to gigs as much as you pretended to. You stop performing. You stop pretending. And that’s freedom.</p><p>It’s a funny thing, ageing. You get clearer on who you are, while also realising how much you still don’t know.</p><p>Being this age doesn’t mean your mind is closed. And youth doesn’t automatically mean fun. We’re all just figuring ourselves out, no matter the year on our birth certificate.</p><p>Getting older isn’t a bad thing. It’s when things get interesting. But no matter how old you are, stay curious. That’s the only thing worth clinging to.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Create and edit images with Gemini 2.0 in preview (119 pts)]]></title>
            <link>https://developers.googleblog.com/en/generate-images-gemini-2-0-flash-preview/</link>
            <guid>43917461</guid>
            <pubDate>Wed, 07 May 2025 16:06:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developers.googleblog.com/en/generate-images-gemini-2-0-flash-preview/">https://developers.googleblog.com/en/generate-images-gemini-2-0-flash-preview/</a>, See on <a href="https://news.ycombinator.com/item?id=43917461">Hacker News</a></p>
<div id="readability-page-1" class="page">
        <!-- Google Tag Manager (noscript) -->
        
        <!-- End Google Tag Manager (noscript) -->

        

				
        

<!-- HTML -->


<div top-level-nav="">
  <nav aria-label="Side menu">
    
    <div>
        <ul>
          <li>
            <a href="https://developers.google.com/products" data-label="Tab: Products">
              <span tooltip="">
                Products
             </span>
            </a>
            <ul>
              <li>
                <span tabindex="0" data-label="More Products">
                  <span menu="Products">
                    More
                  </span>
                  <span menu="Products">
                    
                  </span>
                </span>
              </li>
            </ul>
          </li>
          <li>
            <a href="https://developers.google.com/solutions/catalog" data-label="Tab: Solutions">
              <span tooltip="">
                Solutions
             </span>
            </a>
          </li>
          <li>
            <a href="https://developers.google.com/events" data-label="Tab: Events">
              <span tooltip="">
                Events
             </span>
            </a>
          </li>
          <li>
            <a href="https://developers.google.com/learn" data-label="Tab: Learn">
              <span tooltip="">
                Learn
             </span>
            </a>
          </li>
          <li>
            <a href="https://developers.google.com/community" data-label="Tab: Community">
              <span tooltip="">
                Community
             </span>
            </a>
            <ul>
              <li>
                
              </li>
            </ul>
          </li>
          <li>
            <a href="https://developers.google.com/profile/u/me" data-label="Tab: Developer Program">
              <span tooltip="">
                Developer Program
             </span>
            </a>
          </li>
          <li>
            <a href="https://developers.googleblog.com/" data-label="Tab: Blog">
              <span tooltip="">
                Blog
             </span>
            </a>
          </li>
        </ul>
      </div>
  </nav>
  </div>



        
  <div>

    
      
    

    

    

    <section>
      
        
          <p><a href="https://developers.googleblog.com/en/search/?author=Kat+Kampf">Kat Kampf</a>
            
              <span>Product Manager</span>
            
            
              <span>Google AI Studio</span>
            
          </p>
        

      
      </section>

    
    <div>
          

<div>
    <p data-block-key="e2q03">Based on the enthusiasm from developers, we are excited to announce that <b>Image Generation</b> capabilities are now available in preview with <b>Gemini 2.0 Flash</b>.</p><p data-block-key="bek1n">Developers can start integrating conversational image generation and editing with higher rate limits via the Gemini API in <a href="https://aistudio.google.com/app/prompts/new_chat?model=gemini-2.0-flash-preview-image-generation">Google AI Studio</a> and <a href="https://console.cloud.google.com/freetrial?redirectPath=/vertex-ai/studio">Vertex AI</a> today using the model name “gemini-2.0-flash-preview-image-generation”.</p><h2 data-block-key="5c4n8" id="what's-new-in-gemini-2.0-flash-image-generation"><b><br></b>What's new in Gemini 2.0 Flash image generation</h2><p data-block-key="egoj9">In addition to enabling <a href="https://ai.google.dev/gemini-api/docs/rate-limits#current-rate-limits">higher rate limits</a> and <a href="https://ai.google.dev/gemini-api/docs/pricing">pricing</a>, we have also improved the model with:</p><ul><li data-block-key="1m7bc">Better visual quality (vs experimental version)</li></ul><ul><li data-block-key="2ofkt">More accurate text rendering (vs experimental version)</li></ul><ul><li data-block-key="bmhqf">Significantly reduced filter block rates (vs experimental version)</li></ul><h2 data-block-key="tn0z7" id="gemini-2.0-flash-image-generation-in-action"><b><br></b>Gemini 2.0 Flash image generation in action</h2><p data-block-key="87qlc">We have loved seeing the community reception of Gemini's image generation capabilities. Here’s a closer look at some of the key functionalities developers have been excited about:</p><h3 data-block-key="sscig" id="1)-recontextualize-products-in-new-environments."><br><b>1) Recontextualize products in new environments.</b></h3>
</div>   

<div>
    <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini-2-0-image-recontextualization-before-and.original.png" alt="Gemini 2.0 image recontextualization: before and after">
        
        
    </p>
</div>
  <div>
    <h3 data-block-key="58t08" id=""><b>2) Collaboratively edit images in real-time.</b></h3><p data-block-key="uf5t">Try it today with the <a href="https://aistudio.google.com/apps/bundled/gemini-co-drawing?showPreview=true">Gemini Co-Drawing Sample App</a> in AI Studio.</p>
</div>   

<div>
    
        <video autoplay="" loop="" muted="" playsinline="" poster="https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/wagtailvideo-zvio6zw2_thumb.jpg">
<source src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/gemini-co-drawing.mp4" type="video/mp4">
<p>Sorry, your browser doesn't support playback for this video</p>

</video>
    
    
</div>  <p>
    <h3 data-block-key="r0kg3" id=""><b>3) Edit specific parts of images conversationally, without changing anything else.</b></h3>
</p>   

<div>
    <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini_2.0_Flash_conversational_image_editing_-.original_oTD4bK8.png" alt="Gemini 2.0 Flash conversational image editing - before and after">
        
        
    </p>
</div>
  <p>
    <h3 data-block-key="a4sqd" id="4)-dynamically-create-new-product-skus-with-text-rendering-and-image."><b>4) Dynamically create new product SKUs with text rendering and image.</b></h3>
</p>   

<div>
    <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini_2.0_Flash_dynamically_creates_new_produc.original.png" alt="Gemini 2.0 Flash dynamically creates new product SKUs with image">
        
        
    </p>
</div>
   

<div>
    <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini-2-0-dynamically-creates-new-product-sku-.original.png" alt="Gemini 2.0 Flash dynamically creating new product SKUs with text rendering - result">
        
        
    </p>
</div>
  <p>
    <h3 data-block-key="68vm0" id=""><b>5) Ideate with Gemini 2.0 Flash as your partner:</b></h3>
</p>   

<div>
    
        <video autoplay="" loop="" muted="" playsinline="" poster="https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/wagtailvideo-_7pt7bv8_thumb.jpg">
<source src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/Gemini_2.0_Flash_collaborative_editing.mp4" type="video/mp4">
<p>Sorry, your browser doesn't support playback for this video</p>

</video>
    
    
        
            <p>
                (right click and open in new tab to view)
            </p>
        
    
</div>  <p>
    <h2 data-block-key="91qfx" id="">Start building with Gemini’s native image capabilities today</h2>
</p>   

<div>
    <div><pre><span></span><span>from</span> <span>google</span> <span>import</span> <span>genai</span>
<span>from</span> <span>google.genai</span> <span>import</span> <span>types</span>
<span>client</span> <span>=</span> <span>genai</span><span>.</span><span>Client</span><span>(</span><span>api_key</span><span>=</span><span>"GEMINI_API_KEY"</span><span>)</span>
<span>response</span> <span>=</span> <span>client</span><span>.</span><span>models</span><span>.</span><span>generate_content</span><span>(</span>
   <span>model</span><span>=</span><span>"gemini-2.0-flash-preview-image-generation"</span><span>,</span>
   <span>contents</span><span>=</span><span>(</span>
       <span>"Show me how to bake a macaron with images."</span>
   <span>),</span>
   <span>config</span><span>=</span><span>types</span><span>.</span><span>GenerateContentConfig</span><span>(</span>
        <span>response_modalities</span><span>=</span><span>[</span><span>"TEXT"</span><span>,</span> <span>"IMAGE"</span><span>]</span>
   <span>),</span>
<span>)</span>
</pre></div>
    <p><span>Copied</span>
        
    </p>
</div>  <div>
    <p data-block-key="57v87">You can read more about image generation in our <a href="https://ai.google.dev/gemini-api/docs/image-generation">API docs</a>. This preview is available for developers to start building through <a href="https://aistudio.google.com/app/prompts/new_chat?model=gemini-2.0-flash-preview-image-generation">Google AI Studio</a> and <a href="https://console.cloud.google.com/freetrial?redirectPath=/vertex-ai/studio">Vertex AI</a> .</p><p data-block-key="d5unj">We look forward to bringing further quality improvements, new capabilities, and expanded rate limits soon. We can’t wait to see what you build with Gemini 2.0 Flash Image Generation.</p>
</div> 
      </div>
    

    

    
    
    
  </div>


				
				





        
				

        
        
        
        

        

        
  

    

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: eInk optimized manga with Kindle Comic Converter (+Kobo/ReMarkable) (174 pts)]]></title>
            <link>https://github.com/ciromattia/kcc</link>
            <guid>43916956</guid>
            <pubDate>Wed, 07 May 2025 15:26:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ciromattia/kcc">https://github.com/ciromattia/kcc</a>, See on <a href="https://news.ycombinator.com/item?id=43916956">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ciromattia/kcc/blob/master/header.jpg"><img src="https://github.com/ciromattia/kcc/raw/master/header.jpg" alt="Header Image" width="400"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">KCC</h2><a id="user-content-kcc" aria-label="Permalink: KCC" href="#kcc"></a></p>
<p dir="auto"><a href="https://github.com/ciromattia/kcc/releases"><img src="https://camo.githubusercontent.com/861ac4533464de62050560a54760d40d2c760735f698f851092ab534801d57c0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f6369726f6d61747469612f6b63632e737667" alt="GitHub release" data-canonical-src="https://img.shields.io/github/release/ciromattia/kcc.svg"></a>
<a href="https://github.com/ciromattia/kcc/pkgs/container/kcc"><img src="https://camo.githubusercontent.com/d03ab2b9b88cbde2cbe9ca27dc30b65ee73d4bd09ebd0175fd4be5feb1f57c6b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f616374696f6e732f776f726b666c6f772f7374617475732f6369726f6d61747469612f6b63632f646f636b65722d7075626c6973682e796d6c3f6c6162656c3d646f636b65722532306275696c64" alt="GitHub Workflow Status" data-canonical-src="https://img.shields.io/github/actions/workflow/status/ciromattia/kcc/docker-publish.yml?label=docker%20build"></a></p>
<p dir="auto"><strong>Kindle Comic Converter</strong> optimizes comics and manga for eink readers like Kindle, Kobo, ReMarkable, and more.
Pages display in fullscreen without margins, with proper fixed layout support.
Its main feature is various optional image processing steps to look good on eink screens,
which have different requirements than normal LCD screens.
It also does filesize optimization by downscaling to your specific device's screen resolution,
which can improve performance on underpowered ereaders.
Supported input formats include folders/CBZ/CBR/PDF of JPG/PNG files and more.
Supported output formats include virtual panel view MOBI/AZW3, EPUB, KEPUB, and CBZ.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/20757319/419286843-36ad2131-6677-4559-bd6f-314a90c27218.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY2NDI5MDEsIm5iZiI6MTc0NjY0MjYwMSwicGF0aCI6Ii8yMDc1NzMxOS80MTkyODY4NDMtMzZhZDIxMzEtNjY3Ny00NTU5LWJkNmYtMzE0YTkwYzI3MjE4LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTA3VDE4MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWE0MTQyMGQ0N2RmNDhlMTE4ZWFjZWVhZTQ1MDc3ZGRkNTU2NTBiMWQyNTc2NjJiZDMwZGJkZjAwOWJhZmQ0ZjMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.dtBq3_hoM_PjqPvxDiOyEFS6mNjAbTMN3lmbtNI_9HU"><img src="https://private-user-images.githubusercontent.com/20757319/419286843-36ad2131-6677-4559-bd6f-314a90c27218.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY2NDI5MDEsIm5iZiI6MTc0NjY0MjYwMSwicGF0aCI6Ii8yMDc1NzMxOS80MTkyODY4NDMtMzZhZDIxMzEtNjY3Ny00NTU5LWJkNmYtMzE0YTkwYzI3MjE4LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTA3VDE4MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWE0MTQyMGQ0N2RmNDhlMTE4ZWFjZWVhZTQ1MDc3ZGRkNTU2NTBiMWQyNTc2NjJiZDMwZGJkZjAwOWJhZmQ0ZjMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.dtBq3_hoM_PjqPvxDiOyEFS6mNjAbTMN3lmbtNI_9HU" alt="image"></a></p>
<p dir="auto">YouTube tutorial (please subscribe): <a href="https://www.youtube.com/watch?v=IR2Fhcm9658" rel="nofollow">https://www.youtube.com/watch?v=IR2Fhcm9658</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">A word of warning</h3><a id="user-content-a-word-of-warning" aria-label="Permalink: A word of warning" href="#a-word-of-warning"></a></p>
<p dir="auto"><strong>KCC</strong> <em>is not</em> <a href="http://www.amazon.com/gp/feature.html?ie=UTF8&amp;docId=1001103761" rel="nofollow">Amazon's Kindle Comic Creator</a> nor is in any way endorsed by Amazon.
Amazon's tool is for comic publishers and involves a lot of manual effort, while <strong>KCC</strong> is for comic/manga readers.
<em>KC2</em> in no way is a replacement for <strong>KCC</strong> so you can be quite confident we are going to carry on developing our little monster ;-)</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Issues / new features / donations</h3><a id="user-content-issues--new-features--donations" aria-label="Permalink: Issues / new features / donations" href="#issues--new-features--donations"></a></p>
<p dir="auto">If you have general questions about usage, feedback etc. please <a href="http://www.mobileread.com/forums/showthread.php?t=207461" rel="nofollow">post it here</a>.
If you have some <strong>technical</strong> problems using KCC please <a href="https://github.com/ciromattia/kcc/issues/new">file an issue here</a>.
If you can fix an open issue, fork &amp; make a pull request.</p>
<p dir="auto">If you find <strong>KCC</strong> valuable you can consider donating to the authors:</p>
<ul dir="auto">
<li>
<p dir="auto">Ciro Mattia Gonano (founder, active 2012-2014):</p>
<p dir="auto"><a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=D8WNYNPBGDAS2" rel="nofollow"><img src="https://camo.githubusercontent.com/2b3b3f38604d749b543e8577afdc6bd9fab25244f6cb16bfb713273a74350fd7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f6e6174652d50617950616c2d677265656e2e737667" alt="Donate PayPal" data-canonical-src="https://img.shields.io/badge/Donate-PayPal-green.svg"></a></p>
</li>
<li>
<p dir="auto">Paweł Jastrzębski (active 2013-2019):</p>
<p dir="auto"><a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=YTTJ4LK2JDHPS" rel="nofollow"><img src="https://camo.githubusercontent.com/2b3b3f38604d749b543e8577afdc6bd9fab25244f6cb16bfb713273a74350fd7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f6e6174652d50617950616c2d677265656e2e737667" alt="Donate PayPal" data-canonical-src="https://img.shields.io/badge/Donate-PayPal-green.svg"></a>
<a href="https://jastrzeb.ski/donate/" rel="nofollow"><img src="https://camo.githubusercontent.com/701a9ad9d998658034948eca1eaf11b00306ed7551ce5db53fffca76ac8d5dbf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f6e6174652d426974636f696e2d677265656e2e737667" alt="Donate Bitcoin" data-canonical-src="https://img.shields.io/badge/Donate-Bitcoin-green.svg"></a></p>
</li>
<li>
<p dir="auto">Alex Xu (active 2023-Present)</p>
<p dir="auto"><a href="https://ko-fi.com/Q5Q41BW8HS" rel="nofollow"><img src="https://camo.githubusercontent.com/70e2ef5e0263b261f9a2a314bb1d6919d1d43292eed117fe8fc766a68c7d96ea/68747470733a2f2f6b6f2d66692e636f6d2f696d672f676974687562627574746f6e5f736d2e737667" alt="ko-fi" data-canonical-src="https://ko-fi.com/img/githubbutton_sm.svg"></a></p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Sponsors</h2><a id="user-content-sponsors" aria-label="Permalink: Sponsors" href="#sponsors"></a></p>
<ul dir="auto">
<li>Free code signing on Windows provided by <a href="https://about.signpath.io/" rel="nofollow">SignPath.io</a>, certificate by <a href="https://signpath.org/" rel="nofollow">SignPath Foundation</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">DOWNLOADS</h2><a id="user-content-downloads" aria-label="Permalink: DOWNLOADS" href="#downloads"></a></p>
<ul dir="auto">
<li><strong><a href="https://github.com/ciromattia/kcc/releases">https://github.com/ciromattia/kcc/releases</a></strong></li>
</ul>
<p dir="auto">Click on <strong>Assets</strong> of the latest release.</p>
<p dir="auto">You probably want either</p>
<ul dir="auto">
<li><code>KCC_*.*.*.exe</code> (Windows)</li>
<li><code>kcc_macos_arm_*.*.*.dmg</code> (recent Mac with Apple Silicon M1 chip or later)</li>
<li><code>kcc_macos_i386_*.*.*.dmg</code> (older Mac with Intel chip)</li>
</ul>
<p dir="auto">The <code>c2e</code> and <code>c2p</code> versions are command line tools for power users.</p>
<p dir="auto">On Windows 11, you may need to run in compatibility mode for an older Windows version.</p>
<p dir="auto">On Mac, right click open to get past the security warning.</p>
<p dir="auto">For flatpak, Docker, and AppImage versions, refer to the wiki: <a href="https://github.com/ciromattia/kcc/wiki/Installation">https://github.com/ciromattia/kcc/wiki/Installation</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQ</h2><a id="user-content-faq" aria-label="Permalink: FAQ" href="#faq"></a></p>
<ul dir="auto">
<li><a href="https://github.com/ciromattia/kcc/issues/678" data-hovercard-type="issue" data-hovercard-url="/ciromattia/kcc/issues/678/hovercard">Windows 7 support</a></li>
<li><a href="https://github.com/ciromattia/kcc/issues/612#issuecomment-2117985011" data-hovercard-type="issue" data-hovercard-url="/ciromattia/kcc/issues/612/hovercard">Combine files/chapters</a></li>
<li><a href="https://github.com/ciromattia/kcc/wiki/Installation#linux">Flatpak mobi conversion stuck</a></li>
<li>Image too dark?
<ul dir="auto">
<li>The default gamma correction of 1.8 makes the image darker, and is useful for faded/gray artwork/text. Disable by setting gamma = 1.0</li>
</ul>
</li>
<li><a href="https://github.com/ciromattia/kcc/issues/680" data-hovercard-type="issue" data-hovercard-url="/ciromattia/kcc/issues/680/hovercard">Better PDF support (Humble Bundle, Fanatical, etc)</a></li>
<li>Cannot connect Kindle Scribe or 2024+ Kindle to macOS
<ul dir="auto">
<li>Use official MTP <a href="https://www.amazon.com/gp/help/customer/display.html/ref=hp_Connect_USB_MTP?nodeId=TCUBEdEkbIhK07ysFu" rel="nofollow">Amazon USB File Transfer app</a>
(no login required). Works much better than previously recommended Android File Transfer. Cannot run simutaneously with other transfer apps.</li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">PREREQUISITES</h2><a id="user-content-prerequisites" aria-label="Permalink: PREREQUISITES" href="#prerequisites"></a></p>
<p dir="auto">You'll need to install various tools to access important but optional features. Close and re-open KCC to get KCC to detect them.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">KindleGen</h3><a id="user-content-kindlegen" aria-label="Permalink: KindleGen" href="#kindlegen"></a></p>
<p dir="auto">On Windows and macOS, install <a href="https://www.amazon.com/Kindle-Previewer/b?ie=UTF8&amp;node=21381691011" rel="nofollow">Kindle Previewer</a> and <code>kindlegen</code> will be autodetected from it.</p>
<p dir="auto">If you have issues detecting it, get stuck on the MOBI conversion step, or use Linux AppImage or Flatpak, refer to the wiki: <a href="https://github.com/ciromattia/kcc/wiki/Installation#kindlegen">https://github.com/ciromattia/kcc/wiki/Installation#kindlegen</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">7-Zip</h3><a id="user-content-7-zip" aria-label="Permalink: 7-Zip" href="#7-zip"></a></p>
<p dir="auto">This is optional but will make conversions much faster.</p>
<p dir="auto">This is required for certain files and advanced features.</p>
<p dir="auto">KCC will ask you to install if needed.</p>
<p dir="auto">Refer to the wiki to install: <a href="https://github.com/ciromattia/kcc/wiki/Installation#7-zip">https://github.com/ciromattia/kcc/wiki/Installation#7-zip</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">INPUT FORMATS</h2><a id="user-content-input-formats" aria-label="Permalink: INPUT FORMATS" href="#input-formats"></a></p>
<p dir="auto"><strong>KCC</strong> can understand and convert, at the moment, the following input types:</p>
<ul dir="auto">
<li>Folders containing: PNG, JPG, GIF or WebP files</li>
<li>CBZ, ZIP <em>(With <code>7z</code> executable)</em></li>
<li>CBR, RAR <em>(With <code>7z</code> executable)</em></li>
<li>CB7, 7Z <em>(With <code>7z</code> executable)</em></li>
<li>PDF <em>(Only extracting JPG images)</em></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">USAGE</h2><a id="user-content-usage" aria-label="Permalink: USAGE" href="#usage"></a></p>
<p dir="auto">Should be pretty self-explanatory. All options have detailed information in tooltips.
After completed conversion, you should find ready file alongside the original input file (same directory).</p>
<p dir="auto">Please check <a href="https://github.com/ciromattia/kcc/wiki/">our wiki</a> for more details.</p>
<p dir="auto">CLI version of <strong>KCC</strong> is intended for power users. It allows using options that might not be compatible and decrease the quality of output.
CLI version has reduced dependencies, on Debian based distributions this commands should install all needed dependencies:</p>
<div data-snippet-clipboard-copy-content="sudo apt-get install python3 p7zip-full python3-pil python3-psutil python3-slugify"><pre><code>sudo apt-get install python3 p7zip-full python3-pil python3-psutil python3-slugify
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Profiles:</h3><a id="user-content-profiles" aria-label="Permalink: Profiles:" href="#profiles"></a></p>
<div data-snippet-clipboard-copy-content="        'K1': (&quot;Kindle 1&quot;, (600, 670), Palette4, 1.8),
        'K11': (&quot;Kindle 11&quot;, (1072, 1448), Palette16, 1.8),
        'K2': (&quot;Kindle 2&quot;, (600, 670), Palette15, 1.8),
        'K34': (&quot;Kindle Keyboard/Touch&quot;, (600, 800), Palette16, 1.8),
        'K578': (&quot;Kindle&quot;, (600, 800), Palette16, 1.8),
        'KDX': (&quot;Kindle DX/DXG&quot;, (824, 1000), Palette16, 1.8),
        'KPW': (&quot;Kindle Paperwhite 1/2&quot;, (758, 1024), Palette16, 1.8),
        'KV': (&quot;Kindle Paperwhite 3/4/Voyage/Oasis&quot;, (1072, 1448), Palette16, 1.8),
        'KPW5': (&quot;Kindle Paperwhite 5/Signature Edition&quot;, (1236, 1648), Palette16, 1.8),
        'KO': (&quot;Kindle Oasis 2/3/Paperwhite 12/Colorsoft 12&quot;, (1264, 1680), Palette16, 1.8),
        'KS': (&quot;Kindle Scribe&quot;, (1860, 2480), Palette16, 1.8),
        'KoMT': (&quot;Kobo Mini/Touch&quot;, (600, 800), Palette16, 1.8),
        'KoG': (&quot;Kobo Glo&quot;, (768, 1024), Palette16, 1.8),
        'KoGHD': (&quot;Kobo Glo HD&quot;, (1072, 1448), Palette16, 1.8),
        'KoA': (&quot;Kobo Aura&quot;, (758, 1024), Palette16, 1.8),
        'KoAHD': (&quot;Kobo Aura HD&quot;, (1080, 1440), Palette16, 1.8),
        'KoAH2O': (&quot;Kobo Aura H2O&quot;, (1080, 1430), Palette16, 1.8),
        'KoAO': (&quot;Kobo Aura ONE&quot;, (1404, 1872), Palette16, 1.8),
        'KoN': (&quot;Kobo Nia&quot;, (758, 1024), Palette16, 1.8),
        'KoC': (&quot;Kobo Clara HD/Kobo Clara 2E&quot;, (1072, 1448), Palette16, 1.8),
        'KoCC': (&quot;Kobo Clara Colour&quot;, (1072, 1448), Palette16, 1.8),
        'KoL': (&quot;Kobo Libra H2O/Kobo Libra 2&quot;, (1264, 1680), Palette16, 1.8),
        'KoLC': (&quot;Kobo Libra Colour&quot;, (1264, 1680), Palette16, 1.8),
        'KoF': (&quot;Kobo Forma&quot;, (1440, 1920), Palette16, 1.8),
        'KoS': (&quot;Kobo Sage&quot;, (1440, 1920), Palette16, 1.8),
        'KoE': (&quot;Kobo Elipsa&quot;, (1404, 1872), Palette16, 1.8),
        'Rmk1': (&quot;reMarkable 1&quot;, (1404, 1872), Palette16, 1.8),
        'Rmk2': (&quot;reMarkable 2&quot;, (1404, 1872), Palette16, 1.8),
        'RmkPP': (&quot;reMarkable Paper Pro&quot;, (1620, 2160), Palette16, 1.8),
        'OTHER': (&quot;Other&quot;, (0, 0), Palette16, 1.8),"><pre><code>        'K1': ("Kindle 1", (600, 670), Palette4, 1.8),
        'K11': ("Kindle 11", (1072, 1448), Palette16, 1.8),
        'K2': ("Kindle 2", (600, 670), Palette15, 1.8),
        'K34': ("Kindle Keyboard/Touch", (600, 800), Palette16, 1.8),
        'K578': ("Kindle", (600, 800), Palette16, 1.8),
        'KDX': ("Kindle DX/DXG", (824, 1000), Palette16, 1.8),
        'KPW': ("Kindle Paperwhite 1/2", (758, 1024), Palette16, 1.8),
        'KV': ("Kindle Paperwhite 3/4/Voyage/Oasis", (1072, 1448), Palette16, 1.8),
        'KPW5': ("Kindle Paperwhite 5/Signature Edition", (1236, 1648), Palette16, 1.8),
        'KO': ("Kindle Oasis 2/3/Paperwhite 12/Colorsoft 12", (1264, 1680), Palette16, 1.8),
        'KS': ("Kindle Scribe", (1860, 2480), Palette16, 1.8),
        'KoMT': ("Kobo Mini/Touch", (600, 800), Palette16, 1.8),
        'KoG': ("Kobo Glo", (768, 1024), Palette16, 1.8),
        'KoGHD': ("Kobo Glo HD", (1072, 1448), Palette16, 1.8),
        'KoA': ("Kobo Aura", (758, 1024), Palette16, 1.8),
        'KoAHD': ("Kobo Aura HD", (1080, 1440), Palette16, 1.8),
        'KoAH2O': ("Kobo Aura H2O", (1080, 1430), Palette16, 1.8),
        'KoAO': ("Kobo Aura ONE", (1404, 1872), Palette16, 1.8),
        'KoN': ("Kobo Nia", (758, 1024), Palette16, 1.8),
        'KoC': ("Kobo Clara HD/Kobo Clara 2E", (1072, 1448), Palette16, 1.8),
        'KoCC': ("Kobo Clara Colour", (1072, 1448), Palette16, 1.8),
        'KoL': ("Kobo Libra H2O/Kobo Libra 2", (1264, 1680), Palette16, 1.8),
        'KoLC': ("Kobo Libra Colour", (1264, 1680), Palette16, 1.8),
        'KoF': ("Kobo Forma", (1440, 1920), Palette16, 1.8),
        'KoS': ("Kobo Sage", (1440, 1920), Palette16, 1.8),
        'KoE': ("Kobo Elipsa", (1404, 1872), Palette16, 1.8),
        'Rmk1': ("reMarkable 1", (1404, 1872), Palette16, 1.8),
        'Rmk2': ("reMarkable 2", (1404, 1872), Palette16, 1.8),
        'RmkPP': ("reMarkable Paper Pro", (1620, 2160), Palette16, 1.8),
        'OTHER': ("Other", (0, 0), Palette16, 1.8),
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Standalone <code>kcc-c2e.py</code> usage:</h3><a id="user-content-standalone-kcc-c2epy-usage" aria-label="Permalink: Standalone kcc-c2e.py usage:" href="#standalone-kcc-c2epy-usage"></a></p>
<div data-snippet-clipboard-copy-content="usage: kcc-c2e [options] [input]

MANDATORY:
  input                 Full path to comic folder or file(s) to be processed.

MAIN:
  -p PROFILE, --profile PROFILE
                        Device profile (Available options: K1, K2, K34, K578, KDX, KPW, KPW5, KV, KO, K11, KS, KoMT, KoG, KoGHD, KoA, KoAHD, KoAH2O, KoAO, KoN, KoC, KoCC, KoL, KoLC, KoF, KoS, KoE)
                        [Default=KV]
  -m, --manga-style     Manga style (right-to-left reading and splitting)
  -q, --hq              Try to increase the quality of magnification
  -2, --two-panel       Display two not four panels in Panel View mode
  -w, --webtoon         Webtoon processing mode
  --ts TARGETSIZE, --targetsize TARGETSIZE
                        the maximal size of output file in MB. [Default=100MB for webtoon and 400MB for others]

PROCESSING:
  -n, --noprocessing    Do not modify image and ignore any profil or processing option
  -u, --upscale         Resize images smaller than device's resolution
  -s, --stretch         Stretch images to device's resolution
  -r SPLITTER, --splitter SPLITTER
                        Double page parsing mode. 0: Split 1: Rotate 2: Both [Default=0]
  -g GAMMA, --gamma GAMMA
                        Apply gamma correction to linearize the image [Default=Auto]
  -c CROPPING, --cropping CROPPING
                        Set cropping mode. 0: Disabled 1: Margins 2: Margins + page numbers [Default=2]
  --cp CROPPINGP, --croppingpower CROPPINGP
                        Set cropping power [Default=1.0]
  --preservemargin      After calculating crop, &quot;back up&quot; a specified percentage amount [Default=0]
  --cm CROPPINGM, --croppingminimum CROPPINGM
                        Set cropping minimum area ratio [Default=0.0]
  --ipc INTERPANELCROP, --interpanelcrop INTERPANELCROP
                        Crop empty sections. 0: Disabled 1: Horizontally 2: Both [Default=0]
  --blackborders        Disable autodetection and force black borders
  --whiteborders        Disable autodetection and force white borders
  --forcecolor          Don't convert images to grayscale
  --forcepng            Create PNG files instead JPEG
  --mozjpeg             Create JPEG files using mozJpeg
  --maximizestrips      Turn 1x4 strips to 2x2 strips
  -d, --delete          Delete source file(s) or a directory. It's not recoverable.

OUTPUT SETTINGS:
  -o OUTPUT, --output OUTPUT
                        Output generated file to specified directory or file
  -t TITLE, --title TITLE
                        Comic title [Default=filename or directory name]
  -a AUTHOR, --author AUTHOR
                        Author name [Default=KCC]
  -f FORMAT, --format FORMAT
                        Output format (Available options: Auto, MOBI, EPUB, CBZ, KFX, MOBI+EPUB) [Default=Auto]
  --nokepub             If format is EPUB, output file with '.epub' extension rather than '.kepub.epub'
  -b BATCHSPLIT, --batchsplit BATCHSPLIT
                        Split output into multiple files. 0: Don't split 1: Automatic mode 2: Consider every subdirectory as separate volume [Default=0]
  --spreadshift         Shift first page to opposite side in landscape for two page spread alignment
  --norotate            Do not rotate double page spreads in spread splitter option.
  --reducerainbow       Reduce rainbow effect on color eink by slightly blurring images

CUSTOM PROFILE:
  --customwidth CUSTOMWIDTH
                        Replace screen width provided by device profile
  --customheight CUSTOMHEIGHT
                        Replace screen height provided by device profile

OTHER:
  -h, --help            Show this help message and exit
"><pre><code>usage: kcc-c2e [options] [input]

MANDATORY:
  input                 Full path to comic folder or file(s) to be processed.

MAIN:
  -p PROFILE, --profile PROFILE
                        Device profile (Available options: K1, K2, K34, K578, KDX, KPW, KPW5, KV, KO, K11, KS, KoMT, KoG, KoGHD, KoA, KoAHD, KoAH2O, KoAO, KoN, KoC, KoCC, KoL, KoLC, KoF, KoS, KoE)
                        [Default=KV]
  -m, --manga-style     Manga style (right-to-left reading and splitting)
  -q, --hq              Try to increase the quality of magnification
  -2, --two-panel       Display two not four panels in Panel View mode
  -w, --webtoon         Webtoon processing mode
  --ts TARGETSIZE, --targetsize TARGETSIZE
                        the maximal size of output file in MB. [Default=100MB for webtoon and 400MB for others]

PROCESSING:
  -n, --noprocessing    Do not modify image and ignore any profil or processing option
  -u, --upscale         Resize images smaller than device's resolution
  -s, --stretch         Stretch images to device's resolution
  -r SPLITTER, --splitter SPLITTER
                        Double page parsing mode. 0: Split 1: Rotate 2: Both [Default=0]
  -g GAMMA, --gamma GAMMA
                        Apply gamma correction to linearize the image [Default=Auto]
  -c CROPPING, --cropping CROPPING
                        Set cropping mode. 0: Disabled 1: Margins 2: Margins + page numbers [Default=2]
  --cp CROPPINGP, --croppingpower CROPPINGP
                        Set cropping power [Default=1.0]
  --preservemargin      After calculating crop, "back up" a specified percentage amount [Default=0]
  --cm CROPPINGM, --croppingminimum CROPPINGM
                        Set cropping minimum area ratio [Default=0.0]
  --ipc INTERPANELCROP, --interpanelcrop INTERPANELCROP
                        Crop empty sections. 0: Disabled 1: Horizontally 2: Both [Default=0]
  --blackborders        Disable autodetection and force black borders
  --whiteborders        Disable autodetection and force white borders
  --forcecolor          Don't convert images to grayscale
  --forcepng            Create PNG files instead JPEG
  --mozjpeg             Create JPEG files using mozJpeg
  --maximizestrips      Turn 1x4 strips to 2x2 strips
  -d, --delete          Delete source file(s) or a directory. It's not recoverable.

OUTPUT SETTINGS:
  -o OUTPUT, --output OUTPUT
                        Output generated file to specified directory or file
  -t TITLE, --title TITLE
                        Comic title [Default=filename or directory name]
  -a AUTHOR, --author AUTHOR
                        Author name [Default=KCC]
  -f FORMAT, --format FORMAT
                        Output format (Available options: Auto, MOBI, EPUB, CBZ, KFX, MOBI+EPUB) [Default=Auto]
  --nokepub             If format is EPUB, output file with '.epub' extension rather than '.kepub.epub'
  -b BATCHSPLIT, --batchsplit BATCHSPLIT
                        Split output into multiple files. 0: Don't split 1: Automatic mode 2: Consider every subdirectory as separate volume [Default=0]
  --spreadshift         Shift first page to opposite side in landscape for two page spread alignment
  --norotate            Do not rotate double page spreads in spread splitter option.
  --reducerainbow       Reduce rainbow effect on color eink by slightly blurring images

CUSTOM PROFILE:
  --customwidth CUSTOMWIDTH
                        Replace screen width provided by device profile
  --customheight CUSTOMHEIGHT
                        Replace screen height provided by device profile

OTHER:
  -h, --help            Show this help message and exit

</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Standalone <code>kcc-c2p.py</code> usage:</h3><a id="user-content-standalone-kcc-c2ppy-usage" aria-label="Permalink: Standalone kcc-c2p.py usage:" href="#standalone-kcc-c2ppy-usage"></a></p>
<div data-snippet-clipboard-copy-content="usage: kcc-c2p [options] [input]

MANDATORY:
  input                 Full path to comic folder(s) to be processed. Separate multiple inputs with spaces.

MAIN:
  -y HEIGHT, --height HEIGHT
                        Height of the target device screen
  -i, --in-place        Overwrite source directory
  -m, --merge           Combine every directory into a single image before splitting

OTHER:
  -d, --debug           Create debug file for every split image
  -h, --help            Show this help message and exit"><pre><code>usage: kcc-c2p [options] [input]

MANDATORY:
  input                 Full path to comic folder(s) to be processed. Separate multiple inputs with spaces.

MAIN:
  -y HEIGHT, --height HEIGHT
                        Height of the target device screen
  -i, --in-place        Overwrite source directory
  -m, --merge           Combine every directory into a single image before splitting

OTHER:
  -d, --debug           Create debug file for every split image
  -h, --help            Show this help message and exit
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">INSTALL FROM SOURCE</h2><a id="user-content-install-from-source" aria-label="Permalink: INSTALL FROM SOURCE" href="#install-from-source"></a></p>
<p dir="auto">This section is for developers who want to contribute to KCC or power users who want to run the latest code without waiting for an official release.</p>
<p dir="auto">Easiest to use <a href="https://desktop.github.com/">GitHub Desktop</a> to clone the KCC repo. From GitHub Desktop, click on <code>Repository</code> in the toolbar, then <code>Command Prompt</code> (Windows)/<code>Terminal</code> (Mac) to open a window in the KCC repo.</p>
<p dir="auto">Depending on your system <a href="https://www.python.org/" rel="nofollow">Python</a> may be called either <code>python</code> or <code>python3</code>. We use virtual environments (venv) to manage dependencies.</p>
<p dir="auto">If you want to edit the code, a good code editor is <a href="https://code.visualstudio.com/" rel="nofollow">VS Code</a>.</p>
<p dir="auto">If you want to edit the <code>.ui</code> files, use <a href="https://www.qt.io/download-qt-installer-oss" rel="nofollow">Qt Creator</a>, included in <strong>Qt for desktop development</strong>.
Then use the <code>gen_ui_files</code> scripts to autogenerate the python UI.</p>
<p dir="auto">An example PR adding a new checkbox is here: <a data-error-text="Failed to load title" data-id="2739994471" data-permission-text="Title is private" data-url="https://github.com/ciromattia/kcc/issues/785" data-hovercard-type="pull_request" data-hovercard-url="/ciromattia/kcc/pull/785/hovercard" href="https://github.com/ciromattia/kcc/pull/785">#785</a></p>
<p dir="auto">Do not use <code>git merge</code> to merge master from upstream,
use the "Sync fork" button on your fork on GitHub in your branch
to avoid weird looking merges in pull requests.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Windows install from source</h3><a id="user-content-windows-install-from-source" aria-label="Permalink: Windows install from source" href="#windows-install-from-source"></a></p>
<p dir="auto">One time setup and running for the first time:</p>
<div data-snippet-clipboard-copy-content="python -m venv venv
venv\Scripts\activate.bat
pip install -r requirements.txt
python kcc.py"><pre><code>python -m venv venv
venv\Scripts\activate.bat
pip install -r requirements.txt
python kcc.py
</code></pre></div>
<p dir="auto">Every time you close Command Prompt, you will need to re-activate the virtual environment and re-run:</p>
<div data-snippet-clipboard-copy-content="venv\Scripts\activate.bat
python kcc.py"><pre><code>venv\Scripts\activate.bat
python kcc.py
</code></pre></div>
<p dir="auto">You can build a <code>.exe</code> of KCC like the downloads we offer with</p>
<div data-snippet-clipboard-copy-content="python setup.py build_binary"><pre><code>python setup.py build_binary
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">macOS install from source</h3><a id="user-content-macos-install-from-source" aria-label="Permalink: macOS install from source" href="#macos-install-from-source"></a></p>
<p dir="auto">One time setup and running for the first time:</p>
<div data-snippet-clipboard-copy-content="python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python kcc.py"><pre><code>python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python kcc.py
</code></pre></div>
<p dir="auto">Every time you close Terminal, you will need to reactivate the virtual environment and re-run:</p>
<div data-snippet-clipboard-copy-content="source venv/bin/activate
python kcc.py"><pre><code>source venv/bin/activate
python kcc.py
</code></pre></div>
<p dir="auto">You can build a <code>.app</code> of KCC like the downloads we offer with</p>
<div data-snippet-clipboard-copy-content="python setup.py build_binary"><pre><code>python setup.py build_binary
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">CREDITS</h2><a id="user-content-credits" aria-label="Permalink: CREDITS" href="#credits"></a></p>
<p dir="auto"><strong>KCC</strong> is made by</p>
<ul dir="auto">
<li><a href="http://github.com/ciromattia">Ciro Mattia Gonano</a></li>
<li><a href="http://github.com/AcidWeb">Paweł Jastrzębski</a></li>
<li><a href="http://github.com/darodi">Darodi</a></li>
<li><a href="http://github.com/axu2">Alex Xu</a></li>
</ul>
<p dir="auto">This script born as a cross-platform alternative to <code>KindleComicParser</code> by <strong>Dc5e</strong> (published <a href="http://www.mobileread.com/forums/showthread.php?t=192783" rel="nofollow">here</a>).</p>
<p dir="auto">The app relies and includes the following scripts:</p>
<ul dir="auto">
<li><code>DualMetaFix</code> script by <strong>K. Hendricks</strong>. Released with GPL-3 License.</li>
<li><code>image.py</code> class from <strong>Alex Yatskov</strong>'s <a href="https://github.com/FooSoft/mangle/">Mangle</a> with subsequent <a href="https://github.com/proDOOMman/Mangle">proDOOMman</a>'s and <a href="https://github.com/Birua/Mangle">Birua</a>'s patches.</li>
<li>Icon is by <strong>Nikolay Verin</strong> (<a href="http://ncrow.deviantart.com/" rel="nofollow">http://ncrow.deviantart.com/</a>) and released under <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/" rel="nofollow">CC BY-NC-SA 3.0</a> License.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">SAMPLE FILES CREATED BY KCC</h2><a id="user-content-sample-files-created-by-kcc" aria-label="Permalink: SAMPLE FILES CREATED BY KCC" href="#sample-files-created-by-kcc"></a></p>
<ul dir="auto">
<li><a href="http://kcc.iosphe.re/Samples/Ubunchu!-KO.mobi" rel="nofollow">Kindle Oasis 2 / 3</a></li>
<li><a href="http://kcc.iosphe.re/Samples/Ubunchu!-KV.mobi" rel="nofollow">Kindle Paperwhite 3 / 4 / Voyage / Oasis</a></li>
<li><a href="http://kcc.iosphe.re/Samples/Ubunchu!-KPW.mobi" rel="nofollow">Kindle Paperwhite 1 / 2</a></li>
<li><a href="http://kcc.iosphe.re/Samples/Ubunchu!-K578.mobi" rel="nofollow">Kindle</a></li>
<li><a href="http://kcc.iosphe.re/Samples/Ubunchu-KoA.kepub.epub" rel="nofollow">Kobo Aura</a></li>
<li><a href="http://kcc.iosphe.re/Samples/Ubunchu-KoAHD.kepub.epub" rel="nofollow">Kobo Aura HD</a></li>
<li><a href="http://kcc.iosphe.re/Samples/Ubunchu-KoAH2O.kepub.epub" rel="nofollow">Kobo Aura H2O</a></li>
<li><a href="http://kcc.iosphe.re/Samples/Ubunchu-KoAO.kepub.epub" rel="nofollow">Kobo Aura ONE</a></li>
<li><a href="http://kcc.iosphe.re/Samples/Ubunchu-KoF.kepub.epub" rel="nofollow">Kobo Forma</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">PRIVACY</h2><a id="user-content-privacy" aria-label="Permalink: PRIVACY" href="#privacy"></a></p>
<p dir="auto"><strong>KCC</strong> is initiating internet connections in two cases:</p>
<ul dir="auto">
<li>During startup - Version check.</li>
<li>When error occurs - Automatic reporting on Windows and macOS.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">KNOWN ISSUES</h2><a id="user-content-known-issues" aria-label="Permalink: KNOWN ISSUES" href="#known-issues"></a></p>
<p dir="auto">Please check <a href="https://github.com/ciromattia/kcc/wiki/Known-issues">wiki page</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">COPYRIGHT</h2><a id="user-content-copyright" aria-label="Permalink: COPYRIGHT" href="#copyright"></a></p>
<p dir="auto">Copyright (c) 2012-2025 Ciro Mattia Gonano, Paweł Jastrzębski, Darodi and Alex Xu.
<strong>KCC</strong> is released under ISC LICENSE; see <a href="https://github.com/ciromattia/kcc/blob/master/LICENSE.txt">LICENSE.txt</a> for further details.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Waiting for Postgres 18: Accelerating Disk Reads with Asynchronous I/O (319 pts)]]></title>
            <link>https://pganalyze.com/blog/postgres-18-async-io</link>
            <guid>43916577</guid>
            <pubDate>Wed, 07 May 2025 14:57:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pganalyze.com/blog/postgres-18-async-io">https://pganalyze.com/blog/postgres-18-async-io</a>, See on <a href="https://news.ycombinator.com/item?id=43916577">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>With the Postgres 18 Beta 1 release this week a multi-year effort, and significant architectural shift in Postgres is taking shape: <strong>Asynchronous I/O (AIO)</strong>. These capabilities are still under active development, but they represent a fundamental change in how Postgres handles I/O, offering the potential for significant performance gains, particularly in cloud environments where latency is often the bottleneck.</p>
<div>
<ul>
<li>
<p><a href="#why-asynchronous-io-matters">Why asynchronous I/O matters</a></p>
<ul>
<li><a href="#how-postgres-17s-read-streams-paved-the-way">How Postgres 17’s read streams paved the way</a></li>
</ul>
</li>
<li>
<p><a href="#new-io_method-setting-in-postgres-18">New io_method setting in Postgres 18</a></p>
<ul>
<li><a href="#io_method--sync">io_method = sync</a></li>
<li><a href="#io_method--worker">io_method = worker</a></li>
<li><a href="#io_method--io_uring">io_method = io_uring</a></li>
</ul>
</li>
<li>
<p><a href="#asynchronous-io-in-action">Asynchronous I/O in action</a></p>
<ul>
<li><a href="#benchmark-on-aws-doubling-read-performance--even-greater-gains-from-io_uring">Benchmark on AWS: Doubling read performance &amp; even greater gains from io_uring</a></li>
<li><a href="#tuning-effective_io_concurrency">Tuning effective_io_concurrency</a></li>
<li><a href="#monitoring-ios-in-flight-with-pg_aios">Monitoring I/Os in flight with pg_aios</a></li>
</ul>
</li>
<li>
<p><a href="#heads-up-async-io-makes-io-timing-information-hard-to-interpret">Heads Up: Async I/O makes I/O timing information hard to interpret</a></p>
</li>
<li>
<p><a href="#conclusion">Conclusion</a></p>
<ul>
<li><a href="#in-summary">In summary</a></li>
<li><a href="#references">References</a></li>
</ul>
</li>
</ul>
</div>
<p>While some features may still be adjusted or dropped during the beta period before the final release, now is the best time to test and validate how Postgres 18 performs in practice. In Postgres 18 AIO is limited to read operations; writes remain synchronous, though support may expand in future versions.</p>
<p>In this post, we explain what asynchronous I/O is, how it works in Postgres 18, and what it means for performance optimization.</p>
<h2 id="why-asynchronous-io-matters"><a href="#why-asynchronous-io-matters" aria-label="why asynchronous io matters permalink"></a>Why asynchronous I/O matters</h2>
<p>Postgres has historically operated under a synchronous I/O model, meaning every read request is a blocking system call. The database must pause and wait for the operating system to return the data before continuing. This design introduces unnecessary waits on I/O, especially in cloud environments where storage is often network-attached (e.g. Amazon EBS) and I/O can have over 1ms of latency.</p>
<p>In a simplified model, we can illustrate the difference like this, ignoring any prefetching/batching the Linux kernel might do:</p>
<p><span>
      <a href="https://pganalyze.com/static/cd0be5dde105345bb288ac73655b90f1/913b9/sync_vs_async.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Diagram showing synchronous vs asynchronous I/O model with concurrent requests" title="In the asynchronous I/O model, multiple read requests can be in flight simultaneously" src="https://pganalyze.com/static/cd0be5dde105345bb288ac73655b90f1/1d69c/sync_vs_async.png" srcset="https://pganalyze.com/static/cd0be5dde105345bb288ac73655b90f1/4dcb9/sync_vs_async.png 188w, https://pganalyze.com/static/cd0be5dde105345bb288ac73655b90f1/5ff7e/sync_vs_async.png 375w, https://pganalyze.com/static/cd0be5dde105345bb288ac73655b90f1/1d69c/sync_vs_async.png 750w, https://pganalyze.com/static/cd0be5dde105345bb288ac73655b90f1/78797/sync_vs_async.png 1125w, https://pganalyze.com/static/cd0be5dde105345bb288ac73655b90f1/aa440/sync_vs_async.png 1500w, https://pganalyze.com/static/cd0be5dde105345bb288ac73655b90f1/913b9/sync_vs_async.png 1822w" sizes="(max-width: 750px) 100vw, 750px" loading="lazy" decoding="async">
  </a>
    </span></p>
<p>You can picture synchronous I/O like an imaginary librarian who retrieves one book at a time, returning before fetching the next. This inefficiency compounds as the number of physical reads for a logical operation increases.</p>
<p>Asynchronous I/O eliminates that bottleneck by allowing programs to issue multiple read requests concurrently, without waiting for prior reads to return. In an async program flow, I/O requests are scheduled to be read into a memory location and the program waits for completion of those reads, instead of issuing each read individually.</p>
<h3 id="how-postgres-17s-read-streams-paved-the-way"><a href="#how-postgres-17s-read-streams-paved-the-way" aria-label="how postgres 17s read streams paved the way permalink"></a>How Postgres 17’s read streams paved the way</h3>
<p>The work for implementing asynchronous I/O in Postgres has been many years in the making. Postgres 17 introduced an essential internal abstration, <a href="https://pganalyze.com/blog/5mins-postgres-17-streaming-io">with the introduction of read stream APIs</a>. These internal changes standardized how read operations were issued across different subsystems and streamlined the use of <code>posix_fadvise()</code> to request that the operating system prefetch data in advance.</p>
<p>However, this advisory mechanism only hinted to the kernel to load data into the OS page cache, not into Postgres’ own shared buffers. Postgres still had to issue syscalls for each read, and OS readahead behaviour is not always consistent.</p>
<p>The upcoming Postgres 18 release removes this indirection. With true asynchronous reads, data is fetched directly into shared buffers by the database itself, bypassing reliance on kernel-level heuristics and enabling more predictable, higher-throughput I/O behavior.</p>
<h2 id="new-io_method-setting-in-postgres-18"><a href="#new-io_method-setting-in-postgres-18" aria-label="new io_method setting in postgres 18 permalink"></a>New io_method setting in Postgres 18</h2>
<p>To control the mechanism used for asynchronous I/O, Postgres 18 introduces a new configuration parameter: <code>io_method</code>. This setting determines how read operations are dispatched under the hood, and whether they’re handled synchronously, offloaded to I/O workers, or submitted directly to the kernel via <code>io_uring</code>.</p>
<p>The <code>io_method</code> setting must be set in postgresql.conf and cannot be changed without restarting. It controls which  I/O implementation Postgres will use and is essential to understand when tuning I/O performance in Postgres 18. There are three possible settings for io_method, with the current default (as of Beta 1) being <code>worker</code>.</p>
<h3 id="io_method--sync"><a href="#io_method--sync" aria-label="io_method  sync permalink"></a>io_method = sync</h3>
<p>The <code>sync</code> setting in Postgres 18 mirrors the synchronous behavior as was implemented in Postgres 17. Reads are still synchronous and blocking, using <code>posix_fadvise()</code> to achieve read-ahead in the Linux kernel.</p>
<h3 id="io_method--worker"><a href="#io_method--worker" aria-label="io_method  worker permalink"></a>io_method = worker</h3>
<p>The <code>worker</code> setting utilizes dedicated <strong>I/O worker processes</strong> running in the background that retrieve data independently of query execution. The main backend process enqueues read requests, and these workers interact with the Linux kernel to fetch data, which is then delivered into shared buffers, <strong>without blocking the main process</strong>.</p>
<p>The number of I/O workers can be configured through the new <code>io_workers</code> setting, and defaults to <code>3</code>. These workers are always running, and shared across all connections and databases.</p>
<h3 id="io_method--io_uring"><a href="#io_method--io_uring" aria-label="io_method  io_uring permalink"></a>io_method = io_uring</h3>
<p>This Linux-specific method uses <strong><code>io_uring</code></strong>, a high-performance I/O interface introduced in kernel version 5.1. Asynchronous I/O has been available in Linux since kernel version 2.5, but it was largely considered inefficient and hard to use. <code>io_uring</code> establishes a <strong>shared ring buffer</strong> between Postgres and the kernel, minimizing syscall overhead. This is the most efficient option, <strong>eliminating the need for I/O worker processes entirely</strong>, but is only available on newer Linux kernels and requires file systems and configurations compatible with <code>io_uring</code> support.</p>
<p><strong>Important note:</strong> As of the Postgres 18 Beta 1, asynchronous I/O is supported for sequential scans, bitmap heap scans, and maintenance operations like <code>VACUUM</code>.</p>
<h2 id="asynchronous-io-in-action"><a href="#asynchronous-io-in-action" aria-label="asynchronous io in action permalink"></a>Asynchronous I/O in action</h2>
<p>Asynchronous I/O delivers the most noticeable gains in cloud environments where storage is network-attached, such as Amazon EBS volumes. In these setups, individual disk reads often take multiple milliseconds, introducing substantial latency compared to local SSDs.</p>
<p>With traditional synchronous I/O, each of these reads blocks query execution until the data arrives, leading to idle CPU time and degraded throughput. By contrast, asynchronous I/O allows Postgres to issue multiple read requests in parallel and continue processing while waiting for results. This reduces query latency and enables much more efficient use of available I/O bandwidth and CPU cycles.</p>
<h3 id="benchmark-on-aws-doubling-read-performance--even-greater-gains-from-io_uring"><a href="#benchmark-on-aws-doubling-read-performance--even-greater-gains-from-io_uring" aria-label="benchmark on aws doubling read performance  even greater gains from io_uring permalink"></a>Benchmark on AWS: Doubling read performance &amp; even greater gains from io_uring</h3>
<p>To evaluate the performance impact of asynchronous I/O, we benchmarked a representative workload on AWS, comparing Postgres 17 with Postgres 18 using different <code>io_method</code> settings. The workload remained identical across versions, allowing us to isolate the effects of the new I/O infrastructure.</p>
<p>We've tested on an AWS c7i.8xlarge instance (32 vCPUs, 64 GB RAM), with a dedicated 100GB <code>io2</code> EBS volume for Postgres, with 20,000 provisioned IOPS. The test table was 3.5GB in size:</p>
<div data-language="sql"><pre><code><span>CREATE</span> <span>TABLE</span> test<span>(</span>id <span>int</span><span>)</span><span>;</span>
<span>INSERT</span> <span>INTO</span> test <span>SELECT</span> <span>*</span> <span>FROM</span> generate_series<span>(</span><span>0</span><span>,</span> <span>100000000</span><span>)</span><span>;</span></code></pre></div>
<div data-language="text"><pre><code>test=# \dt+
                                   List of relations
 Schema | Name | Type  |  Owner   | Persistence | Access method |  Size   | Description 
--------+------+-------+----------+-------------+---------------+---------+-------------
 public | test | table | postgres | permanent   | heap          | 3458 MB | 
(1 row)</code></pre></div>
<p>Between test runs we cleared the OS page cache (<code>sync; echo 3 &gt; /proc/sys/vm/drop_caches</code>), and restarted Postgres, to gather cold cache results. Warm cache results represent running the query a second time. We repeated the complete test run for each configuration multiple times, retaining the best result out of three.</p>
<p>Whilst we also tested with parallel query, to keep results easier to understand all results below are with parallel query turned off (<code>max_parallel_workers_per_gather = 0</code>).</p>
<p><strong>Cold cache results:</strong></p>
<p>Postgres 17, using synchronous I/O, established the baseline. It showed consistent read latency, but throughput was limited by the need to complete each I/O request before issuing the next:</p>
<div data-language="text"><pre><code>test=# SELECT COUNT(*) FROM test;
   count   
-----------
 100000001
(1 row)

Time: 15830.880 ms (00:15.831)</code></pre></div>
<p>Postgres 18, when configured with <code>io_method = sync</code>, performed nearly identically, confirming that behavior remains unchanged without enabling asynchronous I/O:</p>
<div data-language="text"><pre><code>test=# SELECT COUNT(*) FROM test;
   count   
-----------
 100000001
(1 row)

Time: 15071.089 ms (00:15.071)</code></pre></div>
<p>However, when we switch to using the <code>worker</code> method, with 3 I/O workers (the default) a clear improvement shows:</p>
<div data-language="text"><pre><code>test=# SELECT COUNT(*) FROM test;
   count   
-----------
 100000001
(1 row)

Time: 10051.975 ms (00:10.052)</code></pre></div>
<p>We observed some gains by raising the number of I/O workers, but the biggested improvement comes when utilizing <code>io_uring</code>:</p>
<div data-language="text"><pre><code>test=# SELECT COUNT(*) FROM test;
   count   
-----------
 100000001
(1 row)

Time: 5723.423 ms (00:05.723)</code></pre></div>
<p>When we graph this (measuring runtime in ms, lower is better), it’s clear that Postgres 18 performs significantly better in cold cache situations:</p>
<p><span>
      <a href="https://pganalyze.com/static/506febf39b7d14c7ba413260d30b63cc/50e7d/runtime-compared.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Read performance comparison between Postgres 17 and 18 with different io_method settings" title="Read performance comparison between Postgres 17 and 18 with different io_method settings" src="https://pganalyze.com/static/506febf39b7d14c7ba413260d30b63cc/1d69c/runtime-compared.png" srcset="https://pganalyze.com/static/506febf39b7d14c7ba413260d30b63cc/4dcb9/runtime-compared.png 188w, https://pganalyze.com/static/506febf39b7d14c7ba413260d30b63cc/5ff7e/runtime-compared.png 375w, https://pganalyze.com/static/506febf39b7d14c7ba413260d30b63cc/1d69c/runtime-compared.png 750w, https://pganalyze.com/static/506febf39b7d14c7ba413260d30b63cc/78797/runtime-compared.png 1125w, https://pganalyze.com/static/506febf39b7d14c7ba413260d30b63cc/aa440/runtime-compared.png 1500w, https://pganalyze.com/static/506febf39b7d14c7ba413260d30b63cc/50e7d/runtime-compared.png 1738w" sizes="(max-width: 750px) 100vw, 750px" loading="lazy" decoding="async">
  </a>
    </span></p>
<p>For cold cache tests, both <code>worker</code> and <code>io_uring</code> delivered a consistent <strong>2-3x improvement</strong> in read performance compared to the legacy <code>sync</code> method.</p>
<p>Whilst <code>worker</code> offers a slight benefit for warm cache tests due to its parallelism, <code>io_uring</code> consistently performed better in cold cache tests, and its lower syscall overhead and reduced process coordination would make <strong><code>io_uring</code> the recommended setting</strong> for maximizing I/O performance in Postgres 18.</p>
<p>This performance shift for disk reads has meaningful implications for infrastructure planning, especially in cloud environments. By reducing I/O wait time, asynchronous reads can substantially increase query throughput, reduce latency and CPU overhead. For read-heavy workloads, this may translate into smaller instance sizes or better utilization of existing resources.</p>
<h3 id="tuning-effective_io_concurrency"><a href="#tuning-effective_io_concurrency" aria-label="tuning effective_io_concurrency permalink"></a>Tuning effective_io_concurrency</h3>
<p>In Postgres 18, <code>effective_io_concurrency</code> becomes more interesting, but only when used with an asynchronous <code>io_method</code> such as <code>worker</code> or <code>io_uring</code>. Previously, this setting merely advised the OS to prefetch data using <code>posix_fadvise</code>. Now, it directly controls how many asynchronous read-ahead requests Postgres issues internally.</p>
<p>The number of blocks read ahead is influenced by both <code>effective_io_concurrency</code> and <code>io_combine_limit</code>, following the general formula:</p>
<div data-language="text"><pre><code>maximum read-ahead = effective_io_concurrency × io_combine_limit</code></pre></div>
<p>This gives DBAs and engineers greater control over I/O behavior. The optimal value requires benchmarking, as it depends on your I/O subsystem. For example, higher values may benefit cloud environments with high latency that also support high concurrency, like AWS EBS with high provisioned IOPS.</p>
<p>When doing our benchmarks, we also tested higher <code>effective_io_concurrency</code> (between 16 and 128) but did not see a meaningful difference. However, that is likely due to the simple test query used.</p>
<p>It’s worth noting that the previous default of effective_io_concurrency was 1 in Postgres 17, which is now raised to 16, <a href="https://git.postgresql.org/gitweb/?p=postgresql.git;a=commit;h=ff79b5b2ab">based on benchmarks done by the Postgres community</a>.</p>
<h3 id="monitoring-ios-in-flight-with-pg_aios"><a href="#monitoring-ios-in-flight-with-pg_aios" aria-label="monitoring ios in flight with pg_aios permalink"></a>Monitoring I/Os in flight with pg_aios</h3>
<p>As mentioned, previous versions of Postgres with synchronous I/O made it easy to spot read delays: the backend process would block while waiting for disk access, and monitoring tools like pganalyze can reliably surface <code>IO / DataFileRead</code> as a wait event during these stalls.</p>
<p>For example, here we can see wait events clearly in Postgres 17 synchronous I/O.</p>
<p><span>
      <a href="https://pganalyze.com/static/67303bca18e1ab006c16c26979172b33/8deec/wait_events_io_read.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Screenshot of pganalyze showing wait events in Postgres 17" title="pganalyze interface showing clear IO / DataFileRead wait events in Postgres 17" src="https://pganalyze.com/static/67303bca18e1ab006c16c26979172b33/1d69c/wait_events_io_read.png" srcset="https://pganalyze.com/static/67303bca18e1ab006c16c26979172b33/4dcb9/wait_events_io_read.png 188w, https://pganalyze.com/static/67303bca18e1ab006c16c26979172b33/5ff7e/wait_events_io_read.png 375w, https://pganalyze.com/static/67303bca18e1ab006c16c26979172b33/1d69c/wait_events_io_read.png 750w, https://pganalyze.com/static/67303bca18e1ab006c16c26979172b33/78797/wait_events_io_read.png 1125w, https://pganalyze.com/static/67303bca18e1ab006c16c26979172b33/aa440/wait_events_io_read.png 1500w, https://pganalyze.com/static/67303bca18e1ab006c16c26979172b33/8deec/wait_events_io_read.png 2136w" sizes="(max-width: 750px) 100vw, 750px" loading="lazy" decoding="async">
  </a>
    </span></p>
<p>With asynchronous I/O in Postgres 18, backend wait behavior changes. When using <code>io_method = worker</code>, the backend process delegates reads to a separate I/O worker. As a result, the backend may appear idle or show the new <code>IO / AioIoCompletion</code> wait event, while the I/O worker shows the actual I/O wait events:</p>
<div data-language="sql"><pre><code><span>SELECT</span> backend_type<span>,</span> query<span>,</span> state<span>,</span> wait_event_type<span>,</span> wait_event
  <span>FROM</span> pg_stat_activity
 <span>WHERE</span> backend_type <span>=</span> <span>'client backend'</span> <span>OR</span> backend_type <span>=</span> <span>'io worker'</span><span>;</span></code></pre></div>
<div data-language="text"><pre><code>  backend_type  | state  | wait_event_type |   wait_event    
----------------+--------+-----------------+-----------------
 client backend | active | IO              | AioIoCompletion
 io worker      |        | IO              | DataFileRead
 io worker      |        | IO              | DataFileRead
 io worker      |        | IO              | DataFileRead
(4 rows)</code></pre></div>
<p>With <code>io_method = io_uring</code>, read operations are submitted directly to the kernel and completed asynchronously. The backend does not block on a traditional I/O syscall, so this activity is not visible from the Postgres side, even though I/O is in progress.</p>
<p>To help with debugging of I/O requests in flight, the new <code>pg_aios</code> view can show Postgres internal state, even when using <code>io_uring</code>:</p>

<div data-language="text"><pre><code>  pid  | io_id | io_generation |    state     | operation |    off    | length | target | handle_data_len | raw_result | result  |                   target_desc                    | f_sync | f_localmem | f_buffered 
-------+-------+---------------+--------------+-----------+-----------+--------+--------+-----------------+------------+---------+--------------------------------------------------+--------+------------+------------
 91452 |     1 |          4781 | SUBMITTED    | read      | 996278272 | 131072 | smgr   |              16 |            | UNKNOWN | blocks 383760..383775 in file "base/16384/16389" | f      | f          | t
 91452 |     2 |          4785 | SUBMITTED    | read      | 996147200 | 131072 | smgr   |              16 |            | UNKNOWN | blocks 383744..383759 in file "base/16384/16389" | f      | f          | t
 91452 |     3 |          4796 | SUBMITTED    | read      | 996409344 | 131072 | smgr   |              16 |            | UNKNOWN | blocks 383776..383791 in file "base/16384/16389" | f      | f          | t
 91452 |     4 |          4802 | SUBMITTED    | read      | 996016128 | 131072 | smgr   |              16 |            | UNKNOWN | blocks 383728..383743 in file "base/16384/16389" | f      | f          | t
 91452 |     5 |          3175 | COMPLETED_IO | read      | 995885056 | 131072 | smgr   |              16 |     131072 | UNKNOWN | blocks 383712..383727 in file "base/16384/16389" | f      | f          | t
(5 rows)</code></pre></div>
<p>Understanding these behavior changes and understanding the impact of asynchronous execution is essential when optimizing I/O performance in Postgres 18.</p>
<h2 id="heads-up-async-io-makes-io-timing-information-hard-to-interpret"><a href="#heads-up-async-io-makes-io-timing-information-hard-to-interpret" aria-label="heads up async io makes io timing information hard to interpret permalink"></a>Heads Up: Async I/O makes I/O timing information hard to interpret</h2>
<p>Asynchronous I/O introduces a shift in how execution timing is reported. When the backend no longer blocks directly on disk reads (as is the case with <code>worker</code> or <code>io_uring</code>) the complete time spent doing I/O may not be reflected in <code>EXPLAIN ANALYZE</code> output. This can make I/O-bound queries seem to require less I/O effort than previously.</p>
<p>First, let's run the earlier query in <code>EXPLAIN ANALYZE</code> on a cold cache in Postgres 17:</p>
<div data-language="text"><pre><code>test=# EXPLAIN (ANALYZE, BUFFERS, TIMING OFF) SELECT COUNT(*) FROM test;
                                               QUERY PLAN                                               
--------------------------------------------------------------------------------------------------------
 Aggregate  (cost=1692478.40..1692478.41 rows=1 width=8) (actual rows=1 loops=1)
   Buffers: shared read=442478
   I/O Timings: shared read=14779.316
   -&gt;  Seq Scan on test  (cost=0.00..1442478.32 rows=100000032 width=0) (actual rows=100000001 loops=1)
         Buffers: shared read=442478
         I/O Timings: shared read=14779.316
 Planning:
   Buffers: shared hit=13 read=6
   I/O Timings: shared read=3.182
 Planning Time: 8.136 ms
 Execution Time: 18006.405 ms
(11 rows)</code></pre></div>
<p>We've read 442,478 buffers in 14.8 seconds.</p>
<p>And now, we repeat the test on Postgres 18 with the default settings (<code>io_method = worker</code>):</p>
<div data-language="text"><pre><code>test=# EXPLAIN (ANALYZE, BUFFERS, TIMING OFF) SELECT COUNT(*) FROM test;
                                                QUERY PLAN                                                 
-----------------------------------------------------------------------------------------------------------
 Aggregate  (cost=1692478.40..1692478.41 rows=1 width=8) (actual rows=1.00 loops=1)
   Buffers: shared read=442478
   I/O Timings: shared read=7218.835
   -&gt;  Seq Scan on test  (cost=0.00..1442478.32 rows=100000032 width=0) (actual rows=100000001.00 loops=1)
         Buffers: shared read=442478
         I/O Timings: shared read=7218.835
 Planning:
   Buffers: shared hit=13 read=6
   I/O Timings: shared read=2.709
 Planning Time: 2.925 ms
 Execution Time: 10480.827 ms
(11 rows)</code></pre></div>
<p>We've read 442,478 buffers in 7.2 seconds.</p>
<p>Whilst with parallel query we get a summary of all the I/O time across all parallel workers, no such summarization occurs with I/O workers. What we are seeing is the wait time for the I/O to be completed, ignoring any parallelism that may happen behind the scenes.</p>
<p>This is technically not a behaviour change, since even in Postgres 17 the time reported was the time spent waiting on I/Os, not the time spent performing the I/O, e.g. Kernel I/O time for readahead was never accounted for.</p>
<p>Historically I/O timing was often equated with I/O effort, instead of just looking at shared buffer read counts, in order to distinguish from a OS page cache hit. Now, in Postgres 18, interpreting I/O timing requires more caution: asynchronous I/O can hide I/O overhead in query plans.</p>
<h2 id="conclusion"><a href="#conclusion" aria-label="conclusion permalink"></a>Conclusion</h2>
<p>To summarize, the upcoming release of Postgres 18 marks the beginning of a major evolution in how I/O is handled. While currently limited to reads, asynchronous I/O already opens the door to significant performance improvements in high-latency cloud environments.</p>
<p>But some of these gains come with tradeoffs. Engineering teams will need to adjust their observability practices, learn new semantics for timing and wait events, and perhaps revisit tuning parameters with previously limited impact, like <code>effective_io_conurrency</code>.</p>
<h3 id="in-summary"><a href="#in-summary" aria-label="in summary permalink"></a>In summary</h3>
<ul>
<li>Asynchronous I/O support in Postgres 18 introduces <code>worker</code> (as the default) and <code>io_uring</code> options under the new <code>io_method</code> setting.</li>
<li>Benchmarks show up to a 2-3x throughput improvement for read-heavy workloads in cloud environments.</li>
<li>Observability practices need to evolve: <code>EXPLAIN ANALYZE</code> may underreport I/O effort, and new views like <code>pg_aios</code> will help provide insights.</li>
<li>Tools like pganalyze will be adapting to these changes to continue surfacing relevant performance insights.</li>
</ul>
<p>As Postgres development continues, future versions (19 and beyond) may bring asynchronous write support, further reducing I/O bottlenecks in modern workloads, and enabling production use of Direct I/O.</p>
<h3 id="references"><a href="#references" aria-label="references permalink"></a>References</h3>
<ul>
<li><a href="https://www.postgresql.org/docs/devel/runtime-config-resource.html#GUC-IO-METHOD">PostgreSQL <code>io_method</code> GUC (Postgres 18)</a></li>
<li><a href="https://www.postgresql.org/docs/current/runtime-config-resource.html#GUC-EFFECTIVE-IO-CONCURRENCY">PostgreSQL <code>effective_io_concurrency</code></a></li>
<li><a href="https://www.postgresql.org/docs/current/storage-buffer.html">PostgreSQL Shared Buffers and Buffer Management</a></li>
<li><a href="https://www.postgresql.org/docs/current/monitoring-stats.html#PG-STAT-ACTIVITY-VIEW"><code>pg_stat_activity</code> View</a></li>
<li><a href="https://www.postgresql.org/docs/devel/monitoring-stats.html#PG-STAT-IO-VIEW"><code>pg_stat_io</code> View</a></li>
<li><a href="https://www.postgresql.org/docs/devel/monitoring-stats.html#PG-AIOS-VIEW"><code>pg_aios</code> View (New in Postgres 18)</a></li>
<li><a href="https://man7.org/linux/man-pages/man2/posix_fadvise.2.html"><code>posix_fadvise()</code> System Call</a></li>
<li><a href="https://www.google.com/url?q=https://www.man7.org/linux/man-pages/man7/io_uring.7.html&amp;sa=D&amp;source=docs&amp;ust=1746206271490972&amp;usg=AOvVaw1B_RmjsiRaB-HDroNJCv6b">Linux io_uring Man Page</a></li>
<li><a href="https://pganalyze.com/blog/5mins-postgres-17-streaming-io">5mins of Postgres: Waiting for Postgres 17: Streaming I/O for sequential scans &amp; ANALYZE</a></li>
</ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mistral ships le chat – enterprise AI assistant that can run on prem (175 pts)]]></title>
            <link>https://mistral.ai/news/le-chat-enterprise</link>
            <guid>43916098</guid>
            <pubDate>Wed, 07 May 2025 14:24:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mistral.ai/news/le-chat-enterprise">https://mistral.ai/news/le-chat-enterprise</a>, See on <a href="https://news.ycombinator.com/item?id=43916098">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p dir="ltr">Today, we’re proud to introduce <a href="https://mistral.ai/products/le-chat">Le Chat Enterprise</a>&nbsp;— a feature-rich AI assistant, powered by our brand new <a href="https://mistral.ai/news/mistral-medium-3">Mistral Medium 3 model</a>. Solving enterprise AI challenges, like tool fragmentation, insecure knowledge integration, rigid models, and slow ROI, it delivers a unified AI platform for all organizational work.</p>
<p>Building on the foundation of Le Chat’s productivity tools, the new plan includes:</p>
<ul>
<li>Enterprise search</li>
<li>Agent builders</li>
<li>Custom data and tool connectors</li>
<li>Document libraries</li>
<li>Custom models</li>
<li>Hybrid deployments</li>
</ul>
<p>[All features rolling out over the next two weeks.]</p>
<p dir="ltr">We’re also announcing several big improvements to Le Chat Pro and Team — our plans for individuals and growing teams.</p>
<p dir="ltr">Le Chat Enterprise aims to provide AI productivity your team needs, in one platform, is fully private, and deeply customizable. Plus, our world-class AI engineering team offers support all the way through to value delivery.</p>
<p dir="ltr">Empower your team to be even more productive, more competitive, more everything.</p>
<p dir="ltr"><iframe title="YouTube video player" src="https://www.youtube.com/embed/7Ssb4lybDag?si=uDW8R4kbvHmDbMci" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<h2 dir="ltr">Unified AI for all organizational work.</h2>
<p dir="ltr">Transform complex tasks into achievable outcomes with AI that speaks every professional language.</p>
<p dir="ltr">Whether your team is analyzing data, writing code, or creating content, they can access cross-domain expertise through intuitive interfaces designed for both technical and non-technical users.</p>
<h3 dir="ltr">Enterprise search with secure data, tool connections and libraries.</h3>
<p dir="ltr">Unlock intelligence from your enterprise data, starting with Google Drive, Sharepoint, OneDrive, Google Calendar, and Gmail. With more connectors coming soon, including templates to build your own.</p>
<ul>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Get improved, personalized answers by connecting Le Chat to your knowledge.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Organize external data sources, documents, and web content into complete knowledge bases for the most relevant answers.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Preview files quickly with Auto Summary for faster consumption.</p>
</li>
</ul>
<p dir="ltr"><iframe title="YouTube video player" src="https://www.youtube.com/embed/pvsSFUzEfjQ?si=anPGYFJ4xio4BlBb" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<p dir="ltr">Le Chat enables your team to maintain a handy personal library of frequently used documents across uploaded files as well as Drive / Sharepoint. Cite, extract, and analyze critical information.</p>
<p dir="ltr">We’re also adding MCP support soon, so your organization can easily connect Le Chat to even more enterprise systems.</p>
<h3 dir="ltr">Build and deploy custom AI agents for precise, automated task handling.</h3>
<p dir="ltr">Automate routine tasks with AI agents, connected to your apps and libraries for contextual understanding across tools. Le Chat will enable your team to easily build custom assistants that match your own requirements — no code required.</p>
<p dir="ltr"><iframe title="YouTube video player" src="https://www.youtube.com/embed/dt8KbVyY_Ek?si=Ws_jwZoM-tXseJkh" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<h2 dir="ltr">Privacy-first.</h2>
<p dir="ltr">Deploy Le Chat anywhere: self-hosted, in your public or private cloud, or as a service hosted in the Mistral cloud. Privacy-first data connections to enterprise tools —&nbsp; with strict ACL adherence — ensuring full data protection and safety.&nbsp;</p>
<p dir="ltr">Build your AI strategy with true flexibility — Mistral AI gives you the independence to choose your ideal infrastructure, without lock-in.</p>
<h2 dir="ltr">Complete control and configurability.&nbsp;</h2>
<p dir="ltr">We offer deep customizability and full control across the stack, from models and the platform, all the way to the interfaces.</p>
<p dir="ltr">You can customize your AI experience through bespoke integrations to your team’s enterprise data and custom platform and model capabilities, like personalizing your assistant with stored memories. Or take it further by enabling user feedback loops for continuous model self-improvement.</p>
<p dir="ltr">You'll have full control of your implementation within your security domain while providing employees access to SOTA intelligence.</p>
<p dir="ltr">Additionally, we provide comprehensive audit logging and storage.</p>
<h2 dir="ltr">Advanced solutioning and value delivery.</h2>
<p dir="ltr">Leverage Mistral applied AI expertise to tailor models to fit your exact use case. We provide hands-on assistance by the world’s best AI engineers and scientists across deployment, solutioning, safety, and beyond.</p>
<h2 dir="ltr">Get started today.</h2>
<p dir="ltr">Experience frontier artificial intelligence with Le Chat Pro, Team Enterprise plans, suited to your organization’s needs.</p>
<p dir="ltr">Le Chat Enterprise is now available in Google Cloud Marketplace, and will soon be on Azure AI and AWS Bedrock.</p>
<p dir="ltr"><a href="https://mistral.ai/contact/">Contact us</a> to learn more about how Le Chat Enterprise can transform your organization.</p>
<p dir="ltr">To get started with Le Chat today, try it at <a href="http://chat.mistral.ai/">chat.mistral.ai</a>, or download our mobile app from the <a href="https://apps.apple.com/us/app/le-chat-by-mistral-ai/id6740410176">App Store</a> or <a href="https://play.google.com/store/apps/details?id=ai.mistral.chat">Play Store</a> — no credit card needed.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Unity’s Open-Source Double Standard: the ban of VLC (439 pts)]]></title>
            <link>https://mfkl.github.io/2024/01/10/unity-double-oss-standards.html</link>
            <guid>43914832</guid>
            <pubDate>Wed, 07 May 2025 12:33:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mfkl.github.io/2024/01/10/unity-double-oss-standards.html">https://mfkl.github.io/2024/01/10/unity-double-oss-standards.html</a>, See on <a href="https://news.ycombinator.com/item?id=43914832">Hacker News</a></p>
<div id="readability-page-1" class="page"><section itemprop="text">
        
        <h2 id="vlc-for-unity-integration">VLC for Unity integration</h2>

<p>For the readers unaware, we started distributing binaries on the Unity Store for the open-source <a href="https://code.videolan.org/videolan/vlc-unity">VLC for Unity</a> integration back in December 2019.</p>

<p>The integration essentially was a bridge between the Unity game engine and the VLC multimedia engine, allowing to build your own media-player based on VLC technology in Unity-based games. Both Unity, through Mono, and LibVLC are highly portable so this is a compelling argument for this cross-platform integration.</p>

<p>Since the start, we have had many users downloading the assets from the Unity Store for their Unity apps and games when requiring demanding multimedia solutions. We had 3 assets targeting specific platforms:</p>
<ul>
  <li>Windows,</li>
  <li>UWP,</li>
  <li>Android.</li>
</ul>

<h2 id="unity-store-ban">Unity Store ban</h2>

<p>This all changed at the end of the summer 2023 when Unity emailed us the following:</p>

<p>
    <img src="https://mfkl.github.io/assets/unity-store-email.png">
</p>

<p>And just like this, our <a href="https://assetstore.unity.com/publishers/39987">publisher account was instantly banned</a>.</p>

<p>After <em>months</em> of slow back-and-forth over email trying to find a compromise, including offering to exclude LGPL code from the assets, Unity basically told us we were not welcome back to their Store, ever. <em>Even if we were to remove all LGPL code from the Unity package</em>.</p>

<p>Where it gets fun is that there are currently hundreds if not thousands of Unity assets that include LGPL dependencies (such as FFmpeg) in the Store <strong>right now</strong>. Enforcement is seemingly totally random, unless you get reported by someone, apparently.</p>

<p>It gets better… Unity itself, both the Editor and the runtime (which means <em>your shipped game</em>) <strong>is already using LGPL dependencies</strong>! Unity is built on libraries such as Lame, libiconv, libwebsockets and websockify.js (at least). Full list of open-source Unity dependencies <a href="https://gist.github.com/mfkl/ad5cbeadf144e52a762a09fac6a05a70">here</a>.</p>

<p>So Unity gets to use and benefit from LGPL open-source libraries, games built with Unity depend on LGPL code by default (hello glibc!), but publishers and Unity users are not allowed to do so through the Unity Store?</p>

<h2 id="introducing-the-videolabs-store">Introducing the <a href="https://videolabs.io/store">Videolabs Store</a></h2>

<p>
    <a href="https://videolabs.io/store"><img src="https://mfkl.github.io/assets/vlabs-store-1.png"></a>
</p>

<p>If you are a company requiring multimedia products or consulting for your own projects, this store will be of interest to you.</p>

<p>After our assets got removed, previous and new customers started emailing us about the status of VLC for Unity. Are we going to keep maintaining the assets? How to get build updates? etc.</p>

<p>Numerous companies make use of the LibVLC SDK and other related technologies (like FFmpeg).</p>

<p>For this reason, we decided to publish a simple Store on the <a href="https://videolabs.io/">Videolabs</a> website.</p>

<p>This way, existing and new customers can still <a href="https://videolabs.io/store/unity">purchase the binaries for the open-source VLC Unity plugin</a> without our presence on the Unity Store.</p>

<h3 id="flexible-multimedia-consulting-packages">Flexible multimedia consulting packages</h3>

<p>Sometimes users will run into issues or request a new feature and while the community can sometimes help, the limited time of a few volunteers only goes so far. I have written about <a href="https://mfkl.github.io/2020/10/25/OSS-sutainability.html">OSS sustainability before</a> and that is very much on topic here.</p>

<p>It is in the best interest of both open-source project maintainers and commercial consumers to have a clear products and services offering for a given project, and that is what we have created with the <a href="https://videolabs.io/store">Videolabs Store</a> for both LibVLC and FFmpeg.</p>

<p>The Videolabs team is composed of VLC and FFmpeg experts in most protocols, formats and platforms.</p>

<p>If you are using or planning to use LibVLC or FFmpeg in your project and need help, whether it be custom builds, bug fixes, SDK integration or simply answers to your questions for your specific needs, these packages are for you!</p>

<p>
    <a href="https://videolabs.io/store"><img src="https://mfkl.github.io/assets/vlabs-store-2.png"></a>
</p>

<p>We have created 3 multimedia consulting packages: 3 hours, 10 hours and 24 hours. They can be purchased for a one-time service or a monthly subscription.</p>

<p>No matter which OS platform or toolkit you are building with, we can help.</p>

<h3 id="other-products">Other products</h3>

<p>The <a href="https://videolabs.io/store/libvlcsharp/">LibVLCSharp commercial license</a> and the <a href="https://mfkl.gumroad.com/l/libvlc-good-parts">LibVLC ebook</a> can also be found in the <a href="https://videolabs.io/store">Videolabs Store</a>, as well as other upcoming products such as Kyber, our new ultra low latency game/desktop streaming and remote control SDK, and more game engine integration such as Unreal.</p>

<p>
    <a href="https://videolabs.io/store"><img src="https://mfkl.github.io/assets/vlabs-store-3.png"></a>
</p>

        
      </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CLion Is Now Free for Non-Commercial Use (472 pts)]]></title>
            <link>https://blog.jetbrains.com/clion/2025/05/clion-is-now-free-for-non-commercial-use/</link>
            <guid>43914705</guid>
            <pubDate>Wed, 07 May 2025 12:18:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.jetbrains.com/clion/2025/05/clion-is-now-free-for-non-commercial-use/">https://blog.jetbrains.com/clion/2025/05/clion-is-now-free-for-non-commercial-use/</a>, See on <a href="https://news.ycombinator.com/item?id=43914705">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    				<p><a href="https://blog.jetbrains.com/clion/category/news/">News</a></p><h2 id="major-updates">CLion Is Now Free for Non-Commercial Use</h2>                    
                    
<blockquote>

<cite>“C makes it easy to shoot yourself in the foot. C++ makes it harder, but when you do, it blows away your whole leg.” — Bjarne Stroustrup</cite></blockquote>



<p>We can’t make С and C++ simpler, but we can make working with them a bit easier. <a href="https://www.jetbrains.com/clion/" target="_blank" rel="noopener">CLion</a> is now free for non-commercial use!</p>



<p>Yes, finally.</p>



<p>Whether you’re a student, an Arduino experimenter, or someone who loves С and C++ with all your heart despite all the challenges these languages present, CLion is now available to you for free – as long as you’re not using it for commercial work.</p>



<h2>What’s happening?</h2>



<p>Last year we implemented a new licensing model for <a href="https://www.jetbrains.com/rust/" target="_blank" rel="noopener">RustRover</a>, <a href="https://www.jetbrains.com/rider/" target="_blank" rel="noopener">Rider</a>, and <a href="https://www.jetbrains.com/webstorm/" target="_blank" rel="noopener">WebStorm</a>, making them free for non-commercial use. We’re now extending this model to CLion. If you’re using it for non-commercial purposes, such as <strong>learning</strong>, <strong>open-source project development</strong>, <strong>content creation</strong>, or <strong>hobby development</strong>, you can now do so for free. For commercial use, our existing licensing model still applies.</p>



<p>Note that while CLion now joins RustRover, Rider, and WebStorm in being free for non-commercial use, this update <strong>doesn’t apply to other JetBrains IDEs</strong> at this time. We’re keeping an eye on how things go and will continue evaluating the impact of this initiative.</p>



<h2>Why are we doing this?</h2>



<p>In making non-commercial development free, we aim to make JetBrains IDEs more accessible to a broader audience. We hope the new licensing model will further lower the barrier to using our IDEs, helping you learn, grow, and stay creative.</p>



<p>You can find more details about why we’re introducing this update in the <a href="https://blog.jetbrains.com/blog/2024/10/24/webstorm-and-rider-are-now-free-for-non-commercial-use/">blog post making the original announcement</a>.</p>



<h2>Why CLion?</h2>



<p>C++ is powerful, but it’s not exactly known for being easy or forgiving. And then there’s C – lean, low-level, and still a core part of many computer science curricula. Whether you’re learning these languages, diving into systems programming, or exploring embedded development on your own, C and C++ often come with a steep learning curve.</p>



<p>We want to support that journey. With CLion now free for non-commercial use, it’s easier for you to experiment, learn, and build – without worrying about the IDE license.</p>



<h2>Commercial vs. non-commercial use</h2>



<p>As defined in the <a href="https://www.jetbrains.com/legal/docs/toolbox/license_non-commercial/" target="_blank" rel="noopener">Toolbox Subscription Agreement for Non-Commercial Use</a>, commercial use means developing products and earning commercial benefits from your activities. However, certain categories are explicitly excluded from this definition. Common examples of non-commercial uses include learning and self-education, open-source contributions without earning commercial benefits, any form of content creation, and hobby development.</p>



<p>It’s important to note that, if you’re using a non-commercial license, you cannot opt out of the collection of anonymous usage statistics. We use this information to improve our products. The data we collect is exclusively that of anonymous feature usages of our IDEs. It is focused on what actions are performed and what types of functionality of the IDE are used. We do not collect any other data. This is similar to our Early Access Program (EAP) and is in compliance with our Privacy Policy.</p>



<h2>FAQ</h2>



<p>Below are answers to the most common questions. Check out the <a href="https://sales.jetbrains.com/hc/en-gb/articles/18950890312210-The-free-non-commercial-licensing-FAQ" target="_blank" rel="noopener"><strong>full FAQ</strong></a> for more information.</p>



<h3>Licensing</h3>



<h4>What features are included under the free license?</h4>



<p>With the new non-commercial license type, you can enjoy a full-featured IDE that is identical to its paid version. The only difference is in the Code With Me feature – you get <a href="https://www.jetbrains.com/code-with-me/buy/?section=personal&amp;billing=monthly" target="_blank" rel="noopener">Code With Me Community</a> with your free license.</p>



<h4>Which license should I choose if I want to use CLion for both non-commercial and commercial projects?</h4>



<p>If you intend to use CLion for commercial development for which you will receive direct or indirect commercial advantage or monetary compensation within the meaning of the definitions provided in the <a href="https://www.jetbrains.com/legal/docs/toolbox/license_non-commercial/" target="_blank" rel="noopener">Toolbox Subscription Agreement for Non-Commercial Use</a>, you will need to purchase a commercial subscription (either individual or organizational). This license can then also be used for non-commercial development.</p>



<h4>How do renewals and upgrades work now?</h4>



<p>Non-commercial subscriptions are issued for one year and will automatically renew after that. However, for the renewal to happen, you must have used the assigned license at least once during the last 6 months of the subscription period. If it has been more than 6 months since you last used an IDE activated with this type of license and the renewal did not occur automatically, you can request a new non-commercial subscription again at any time.</p>



<h4>Am I eligible for a refund if I’ve already bought a paid subscription but do non-commercial development?</h4>



<p>If you’re unsure whether you qualify for a refund, you’ll find full details of our policy <a href="https://sales.jetbrains.com/hc/en-gb/articles/115000913704-How-can-I-get-a-refund" target="_blank" rel="noopener">here</a>. Please note that if you also work on projects that qualify as commercial usage, you can’t use the free license for them.</p>



<h3>Anonymous data collection&nbsp;</h3>



<h4>Does my IDE send any data to JetBrains?</h4>



<p>The terms of the non-commercial agreement assume that the product may also electronically send JetBrains anonymized statistics (IDE telemetry) related to your usage of the product’s features. This information may include but is not limited to frameworks, file templates used in the product, actions invoked, and other interactions with the product’s features. This information does not contain personal data.</p>



<h4>Is there a way to opt out of sending anonymized statistics?</h4>



<p>We appreciate that this might not be convenient for everyone, but there is unfortunately no way to opt out of sending anonymized statistics to JetBrains under the terms of the Toolbox agreement for non-commercial use. The only way to opt out is by switching to either a paid subscription or one of the complimentary options mentioned <a href="https://www.jetbrains.com/store/?section=students&amp;billing=yearly" target="_blank" rel="noopener">here</a>.</p>



<h3>Getting a non-commercial subscription&nbsp;</h3>



<h4>What should I do to apply for this subscription?</h4>



<p>It can be easily done right inside your IDE:</p>



<ol>
<li>Install CLion and run it.</li>



<li>Upon startup, there will be a license dialog box where you can choose the <em>Non-commercial use </em>option.</li>



<li>Log in to your JetBrains account or create a new one.&nbsp;</li>



<li>Accept the <a href="https://www.jetbrains.com/legal/docs/toolbox/license_non-commercial/" target="_blank" rel="noopener">Toolbox Subscription Agreement for Non-Commercial Use</a>.</li>



<li>Enjoy development in your IDE.</li>
</ol>



<p>If you’ve already started a trial period or have activated your IDE using a paid license, you still can switch to a non-commercial subscription by following these steps:</p>



<ol>
<li>Go to <em>Help | Register.</em></li>



<li>In the window that opens, click on the <em>Remove License</em> button.</li>



<li>Choose <em>Non-commercial use.</em></li>



<li>Log in to your JetBrains account or create a new one.&nbsp;</li>



<li>Accept the <a href="https://www.jetbrains.com/legal/docs/toolbox/license_non-commercial/" target="_blank" rel="noopener">Toolbox Subscription Agreement for Non-Commercial Use</a>.</li>



<li>Enjoy development in your IDE.</li>
</ol>



<h4>I don’t see the <em>Non-commercial use</em> option in my IDE. What should I do?&nbsp;</h4>



<p>The most likely explanation for this is that you’re using an older version of CLion. Unfortunately, we don’t support obtaining the non-commercial license for any releases prior to CLion 2025.1.1. That’s it for today! If you don’t find an answer to your question, feel free to leave a comment or contact us at <a href="https://www.jetbrains.com/support/sales/#email-sales" target="_blank" rel="noopener">sales@jetbrains.com</a>.</p>



<p>Your CLion team<br>
<em>JetBrains</em><br>
<em>Make it happen. With code.</em></p>
                    
                                                                                                                                                                                                                            <div>
                                <div>
                                                                            <h4>Subscribe to CLion Blog updates</h4>
                                                                                                            
                                </div>
                                
                                <p><img src="https://blog.jetbrains.com/wp-content/themes/jetbrains/assets/img/img-form.svg" alt="image description">
                                                                    </p>
                            </div>
                                                            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My quest to make motorcycle riding that tad bit safer (186 pts)]]></title>
            <link>https://gill.net.in/posts/my-quest-to-make-motorcycle-riding-safer/</link>
            <guid>43914235</guid>
            <pubDate>Wed, 07 May 2025 11:06:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gill.net.in/posts/my-quest-to-make-motorcycle-riding-safer/">https://gill.net.in/posts/my-quest-to-make-motorcycle-riding-safer/</a>, See on <a href="https://news.ycombinator.com/item?id=43914235">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>It began with a spark—a dormant passion reignited after many years away from motorcycling. Life had steered me in different directions, away from the saddle, but something deep inside pulled me back to the thrill and freedom that only riding offers.</p><p>Returning to motorcycling after such an extended hiatus was daunting yet exhilarating. I vividly recall my first CBT session: the nerves, the good-natured laughter at my clumsy mistakes, and the sheer joy when everything finally clicked into place. It was during this session that a critical moment of inspiration occurred. My instructor casually suggested lightly applying the brakes during engine braking to alert drivers behind that I was slowing down. Given motorcycles’ inherent lightweight design and strong engine braking, the risk of being rear-ended was significant.</p><p>It struck me profoundly how something so vital could be left to mere habit—this realization triggered my engineering instincts. Relying solely on human memory and habitual action seemed inadequate and unreliable. I wondered: “Could technology automate this essential safety process?” Thus, BrakeBright was conceived—a smart brake-light system specifically tailored for motorcycles. BrakeBright intelligently detects when the motorcycle slows due to engine braking, activating the brake lights even before the rider manually applies the brakes. Moreover, during intense braking scenarios, it flashes proportionately to the braking intensity.</p><p>Curious to see what was already available, I purchased one of the few similar products on the market. To my surprise, it relied solely on a basic tilt switch, rattling excessively during rides despite claims of “advanced technology.” The device was not only ineffective but also potentially hazardous. Drivers instinctively focus on brake lights; unless the brake light itself clearly indicates deceleration, most would fail to notice.</p><p>Interestingly, adaptive brake light technology already exists in high-end vehicles. BMW’s dynamic brake light, for example, flashes during emergency braking to alert trailing drivers, greatly enhancing road safety. Similarly, KTM motorcycles incorporate an Adaptive Brake Light system for better visibility during sudden deceleration. However, such advanced safety features have traditionally been reserved for premium models. My vision for BrakeBright was to democratize this essential safety feature, making it accessible to every rider through a simple, straightforward modification. Installation requires no special tools—using posi-tap connectors, BrakeBright easily integrates with your motorcycle’s existing wiring in just minutes.</p><p>Developing BrakeBright involved starting with a simple motion sensor and microcontroller unit (MCU) on a breadboard. Countless hours went into refining the device—tweaking, programming, and improving—long before I even had my own motorcycle license. As the idea evolved, I designed the initial printed circuit board (PCB) prototype, carefully hand-soldering tiny surface-mount components late into the night.</p><p><img loading="lazy" src="https://gill.net.in/images/brakebright-breadboard.jpg" alt="BrakeBright PCB prototype"></p><p>Testing presented another unique challenge—I initially didn’t own a motorcycle. My friend Johny generously volunteered his bike for field testing. I sent each prototype iteration to him, and he diligently provided feedback that guided continuous improvements. This iterative process spanned several months, steadily bringing BrakeBright closer to perfection.</p><p>By the third PCB version, I had my motorcycle and could directly test and refine the system. Challenges arose frequently: vibration jitter interfering with sensor accuracy, synchronization issues between sampling rates and engine RPM, and false positives during long rides. To visually verify BrakeBright’s actions, I installed an LED at the front of my motorcycle, enabling real-time monitoring. This hands-on method significantly improved reliability, particularly the flashing-on-hard-braking feature. BrakeBright employs a sensitive accelerometer to detect velocity changes accurately, determining whether the motorcycle is slowing due to engine braking or active rider input. It’s also engineered to be fully waterproof and vibration-resistant, ensuring dependable performance under any riding conditions.</p><p><img loading="lazy" src="https://gill.net.in/images/brakebright-pcb.jpg" alt="BrakeBright PCB prototype"></p><p>Thousands of miles of rigorous testing followed, notably including Scotland’s iconic NC500 route alongside Johny—misty mornings, sweeping highland bends, and dramatic descents providing the ideal proving grounds. One vivid memory stands out: braking sharply on a tight, downhill hairpin near Applecross Pass, I observed BrakeBright’s flash sequence activate exactly as intended—clear, swift, and unmistakable. Riders especially appreciated BrakeBright’s flashing feature, noting how it significantly improved rearward visibility during intense braking situations.</p><p>Another challenge emerged when the initial BrakeBright unit required specialized equipment for firmware updates. Committed to empowering users, I developed a subsequent version incorporating a USB port. Currently, I’m finalizing user-friendly software utilities, enabling riders to easily update BrakeBright firmware, customize features, and personalize the system to match individual riding styles and preferences.</p><p>Months of effort culminated in the thrilling moment the first production batch arrived. I still recall opening the box at my workbench—the scent of fresh solder and cardboard filling the air—and seeing the finished BrakeBright units gleaming. Holding one in my hands, experiencing its meticulous craftsmanship and sleek design realized exactly as envisioned, was profoundly rewarding. I felt immense pride, a hint of nervous excitement, and deep satisfaction.</p><p>Yet, this is merely the beginning. The initial shipments and early customers symbolize far more than sales—they validate that risk-taking, passion, and belief can transform ideas into reality. With an open feedback loop and software upgrade tools nearing completion, I’m eager to see riders embrace BrakeBright, making it uniquely theirs.</p><p><img loading="lazy" src="https://gill.net.in/images/brakebright-first-batch.jpg" alt="BrakeBright First Batch"></p><p>If you’re interested in BrakeBright, want to test it, or simply enjoy discussing motorcycles and technology, please reach out or follow along for updates.</p><p>If you want to support my journey, consider purchasing a BrakeBright unit
<a href="https://shop.bikesafe.me/products/dynamic-brake-light-controller-kit" target="_blank" rel="noopener">here</a>
. Your support means the world to me and helps fuel my passion for making motorcycle riding safer and more enjoyable for everyone.</p><p>If you enjoyed reading this post, you can click 👍 at the top a few times.</p><p>Thank you for reading and <i>Happy Coding!</i></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[So Much Blood (279 pts)]]></title>
            <link>https://dynomight.net/blood/</link>
            <guid>43913751</guid>
            <pubDate>Wed, 07 May 2025 09:41:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dynomight.net/blood/">https://dynomight.net/blood/</a>, See on <a href="https://news.ycombinator.com/item?id=43913751">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
    
  <section>
    <p>In a recent post about <a href="https://dynomight.net/money/">trading stuff for money</a>, I mentioned:</p>

<blockquote>
  <p>Europe had a [blood plasma] shortage of around 38%, which it met by importing plasma from paid donors in the United States, where blood products account for 2% of <em>all</em> exports by value.</p>
</blockquote>

<p>The internet’s reaction was: “TWO PERCENT?” “<strong>TWO PERCENT OF U.S. EXPORTS ARE BLOOD!?</strong>”</p>

<p>Well, I took that 2% number from a 2024 <a href="https://www.economist.com/finance-and-economics/2024/08/29/the-plasma-trade-is-becoming-ever-more-hypocritical">article in the Economist</a>:</p>

<blockquote>
  <p>Last year American blood-product exports accounted for 1.8% of the country’s total goods exports, up from just 0.5% a decade ago—and were worth $37bn. That makes blood the country’s ninth-largest goods export, ahead of coal and gold. All told, America now supplies 70% or so of the plasma used to make medicine.</p>
</blockquote>

<p>I figured the Economist was trustworthy on matters of economics. But note:</p>

<ol>
  <li>That 1.8% number is for blood <em>products</em>, not just blood.</li>
  <li>It’s a percentage of <em>goods</em> exported, excluding services.</li>
  <li>It’s wrong.</li>
</ol>

<p>The article doesn’t explain how they arrived at 1.8%. And since the Economist speaks in the voice of God (without bylines), I can’t corner and harass the actual journalist. I’d have liked to reverse-engineer their calculations, but this was impossible since the world hasn’t yet caught on that they should always <a href="https://dynomight.net/digits/">show lots of digits</a>.</p>

<p>So what’s the right number? In 2023, total US goods exports were <a href="https://www.census.gov/foreign-trade/Press-Release/ft900/ft900_2405.pdf#page=20">$2,045 billion</a>, almost exactly ⅔ of all exports, including services.</p>

<p>How much of that involves blood? Well, the government keeps statistics on trade based on an insanely detailed <a href="https://hts.usitc.gov/reststop/file?release=2023HTSARev8&amp;filename=Chapter%2098">classification scheme</a>. All goods get some number. For example, <a href="https://en.wikipedia.org/wiki/Airship">dirigibles</a> fall under <a href="https://hts.usitc.gov/reststop/file?release=2025HTSRev9&amp;filename=Chapter%2088">HTS 8801.90.0000</a>:</p>

<p><img src="https://dynomight.net/img/blood/dirgibles.png" alt=""></p>

<p>Leg warmers fall under HTS 6406.99.1530:</p>

<p><img src="https://dynomight.net/img/blood/leg_warmers.png" alt="leg warmers"></p>

<p>So what about blood? Well, <a href="https://www.usitc.gov/publications/docs/tata/hts/bychapter/1000c30.pdf#page=3">HTS 3002</a> is the category for:</p>

<blockquote>
  <p>Human blood; animal blood prepared for therapeutic, prophylactic or diagnostic uses; antisera and other blood fractions and modified immunological products, whether or not obtained by means of biotechnological processes; vaccines, toxins, cultures of micro-organisms (excluding yeasts) and similar products:</p>
</blockquote>

<p>The total exports in this category in 2023 were 41.977 billion, or 2.05% of all goods exports. But that category includes many products that don’t require human blood such as most vaccines.</p>

<p>To get the actual data, you need to go through a <a href="https://dataweb.usitc.gov/trade/search/Export/HTS">website</a> maintained by the US Trade Commission. This website has good and bad aspects. On the one hand, it’s slow and clunky and confusing and often randomly fails to deliver any results. On the other hand, when you re-submit, it clears your query and then blocks you for submitting too many requests, which is nice.</p>

<p>But after a lot of tearing of hair, I got what seems to be the most detailed breakdown of that category available. There are some finer subcategories in the taxonomy, but they don’t seem to have any data.</p>

<p>So let’s go through those categories. To start, here are some that would seem to almost always contain human blood:</p>

<table>
  <thead>
    <tr>
      <th>Category</th>
      <th>Description</th>
      <th>Exports ($)</th>
      <th>Percentage of US goods exports</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>3002.12.00.10</td>
      <td>HUMAN BLOOD PLASMA</td>
      <td>5,959,103,120</td>
      <td>0.2914%</td>
    </tr>
    <tr>
      <td>3002.12.00.20</td>
      <td>NORMAL HUMAN BLOOD SERA, WHETHER OR NOT FREEZE-DRIED</td>
      <td>38,992,251</td>
      <td>0.0019%</td>
    </tr>
    <tr>
      <td>3002.12.00.30</td>
      <td>HUMAN IMMUNE BLOOD SERA</td>
      <td>5,608,090</td>
      <td>0.0003%</td>
    </tr>
    <tr>
      <td>3002.12.00.90</td>
      <td>ANTISERA AND OTHER BLOOD FRACTIONS</td>
      <td>4,808,069,119</td>
      <td>0.2351%</td>
    </tr>
    <tr>
      <td>3002.90.52.10</td>
      <td>WHOLE HUMAN BLOOD</td>
      <td>22,710,898</td>
      <td>0.0011%</td>
    </tr>
    <tr>
      <td><strong>TOTAL</strong></td>
      <td><strong>(YES BLOOD)</strong></td>
      <td><strong>10,834,483,478</strong></td>
      <td><strong>0.5298%</strong></td>
    </tr>
  </tbody>
</table>

<p>Next, there are several categories that would seem to essentially <em>never</em> contain human blood:</p>

<table>
  <thead>
    <tr>
      <th>Category</th>
      <th>Description</th>
      <th>Exports ($)</th>
      <th>Percentage of US goods exports</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>3002.12.00.40</td>
      <td>FETAL BOVINE SERUM (FBS)</td>
      <td>146,026,727</td>
      <td>0.0071%</td>
    </tr>
    <tr>
      <td>3002.42.00.00</td>
      <td>VACCINES FOR VETERINARY MEDICINE</td>
      <td>638,191,743</td>
      <td>0.0312%</td>
    </tr>
    <tr>
      <td>3002.49.00.00</td>
      <td>VACCINES, TOXINS, CULTURES OF MICRO-ORGANISMS EXCLUDING YEASTS, AND SIMILAR PRODUCTS, NESOI</td>
      <td>1,630,036,341</td>
      <td>0.0797%</td>
    </tr>
    <tr>
      <td>3002.59.00.00</td>
      <td>CELL CULTURES, WHETHER OR NOT MODIFIED, NESOI</td>
      <td>79,384,134</td>
      <td>0.0039%</td>
    </tr>
    <tr>
      <td>3002.90.10.00</td>
      <td>FERMENTS</td>
      <td>361,418,233</td>
      <td>0.0177%</td>
    </tr>
    <tr>
      <td><strong>TOTAL</strong></td>
      <td><strong>(NO BLOOD)</strong></td>
      <td><strong>2,869,107,296</strong></td>
      <td><strong>0.1403%</strong></td>
    </tr>
  </tbody>
</table>

<p>Finally, there are categories that include <em>some</em> products that <em>might</em> contain human blood:</p>

<table>
  <thead>
    <tr>
      <th>Category</th>
      <th>Description</th>
      <th>Exports ($)</th>
      <th>Percentage of US goods exports</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>3002.13.00.00</td>
      <td>IMMUNOLOGICAL PRODUCTS, UNMIXED, NOT PUT UP IN MEASURED DOSES OR IN FORMS OR PACKINGS FOR RETAIL SALE</td>
      <td>624,283,112</td>
      <td>0.0305%</td>
    </tr>
    <tr>
      <td>3002.14.00.00</td>
      <td>IMMUNOLOGICAL PRODUCTS, MIXED, NOT PUT UP IN MEASURED DOSES OR IN FORMS OR PACKINGS FOR RETAIL SALE</td>
      <td>5,060,866,208</td>
      <td>0.2475%</td>
    </tr>
    <tr>
      <td>3002.15.01.00</td>
      <td>IMMUNOLOGICAL PRODUCTS, PUT UP IN MEASURED DOSES OR IN FORMS OR PACKINGS FOR RETAIL SALE</td>
      <td>13,317,356,469</td>
      <td>0.6512%</td>
    </tr>
    <tr>
      <td>3002.41.00.00</td>
      <td>VACCINES FOR HUMAN MEDICINE, NESOI</td>
      <td>7,760,695,744</td>
      <td>0.3795%</td>
    </tr>
    <tr>
      <td>3002.51.00.00</td>
      <td>CELL THERAPY PRODUCTS</td>
      <td>595,963,010</td>
      <td>0.0291%</td>
    </tr>
    <tr>
      <td>3002.90.52.50</td>
      <td>HUMAN BLOOD; ANIMAL BLOOD PREPARED FOR THERAPEUTIC, PROPHYLATIC OR DIAGNOSTIC USES; ANTISERA AND OTHER BLOOD FRACTIONS, ETC. NESOI</td>
      <td>914,348,561</td>
      <td>0.0447%</td>
    </tr>
    <tr>
      <td><strong>TOTAL</strong></td>
      <td><strong>(MAYBE BLOOD)</strong></td>
      <td><strong>28,273,513,104</strong></td>
      <td><strong>1.3826%</strong></td>
    </tr>
  </tbody>
</table>

<p>The biggest contributor here is IMMUNOLOGICAL PRODUCTS (be they MIXED or UNMIXED, PUT UP or NOT PUT UP). The largest fraction of these is probably antibodies.</p>

<p>Antibodies are <em>sometimes</em> made from human blood. You may remember that in 2020, some organizations collected human blood from people who’d recovered from Covid to make antibodies. But it’s important to stress that this is quite rare. Human blood, after all, is expensive. So—because capitalism—whenever possible animals are used instead, often rabbits, goats, sheep, or <a href="https://en.wikipedia.org/wiki/Humanized_mouse">humanized mice</a>.</p>

<p>I can’t find any hard statistics on this. But I know several people who work in this industry. So I asked them to just guess what fraction might include human blood. Biologists don’t like numbers, so this took a lot of pleading, but my best estimate is 8%.</p>

<p>When looking at similar data a few years ago, <a href="http://marketdesigner.blogspot.com/2020/05/plasma-and-plasma-products-such-as.html">Market Design</a> suggested that that <a href="https://en.wikipedia.org/wiki/Immunoglobulin_therapy">immunoglobulin products</a> might also fall under this category. But as far as I can tell this is not true. I looked up the tariff codes for a few immunoglobulin products, and they all seem to fall under 3002.90 (“HUMAN BLOOD; ANIMAL BLOOD PREPARED FOR THERAPEUTIC, PROPHYLATIC OR DIAGNOSTIC USES; ANTISERA AND OTHER BLOOD FRACTIONS, ETC. NESOI”)</p>

<p>What about vaccines or <a href="https://en.wikipedia.org/wiki/Cell_therapy">cell therapy</a> products? These almost never contain human blood. But they are <em>sometimes</em> made by growing human cell lines, and <em>sometimes</em> those cell lines require human <a href="https://en.wikipedia.org/wiki/Serum_(blood)">blood <em>serum</em></a> to grow. More pleading with the biologists produced a guess that this is true for 5% of vaccines and 80% of cell therapies.</p>

<p><em>Aside</em>: Even if they do require blood serum, it’s somewhat debatable if they should count as “blood products”. How far down the supply chain does that classification apply? If I make cars, and one of my employees gets injured and needs a blood transfusion, are my cars now “blood products”?</p>

<p>Anyway, here’s my best guess for the percentage of products in this middle category that use human blood:</p>

<table>
  <thead>
    <tr>
      <th>Category</th>
      <th>Description</th>
      <th>Needs blood (guess)</th>
      <th>Exports ($)</th>
      <th>Percentage of US goods exports</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>3002.13.00.00</td>
      <td>IMMUNOLOGICAL PRODUCTS, UNMIXED, NOT PUT UP IN MEASURED DOSES OR IN FORMS OR PACKINGS FOR RETAIL SALE</td>
      <td>8%</td>
      <td>49,942,648</td>
      <td>0.0024%</td>
    </tr>
    <tr>
      <td>3002.14.00.00</td>
      <td>IMMUNOLOGICAL PRODUCTS, MIXED, NOT PUT UP IN MEASURED DOSES OR IN FORMS OR PACKINGS FOR RETAIL SALE</td>
      <td>8%</td>
      <td>404,869,296</td>
      <td>0.0198%</td>
    </tr>
    <tr>
      <td>3002.15.01.00</td>
      <td>IMMUNOLOGICAL PRODUCTS, PUT UP IN MEASURED DOSES OR IN FORMS OR PACKINGS FOR RETAIL SALE</td>
      <td>8%</td>
      <td>1,065,388,517</td>
      <td>0.0521%</td>
    </tr>
    <tr>
      <td>3002.41.00.00</td>
      <td>VACCINES FOR HUMAN MEDICINE, NESOI</td>
      <td>5%</td>
      <td>388,034,787</td>
      <td>0.0190%</td>
    </tr>
    <tr>
      <td>3002.51.00.00</td>
      <td>CELL THERAPY PRODUCTS</td>
      <td>80%</td>
      <td>476,770,408</td>
      <td>0.0233%</td>
    </tr>
    <tr>
      <td>3002.90.52</td>
      <td>HUMAN BLOOD; ANIMAL BLOOD PREPARED FOR THERAPEUTIC, PROPHYLATIC OR DIAGNOSTIC USES; ANTISERA AND OTHER BLOOD FRACTIONS, ETC. NESOI</td>
      <td>90%</td>
      <td>822,913,704</td>
      <td>0.0402%</td>
    </tr>
    <tr>
      <td><strong>TOTAL</strong></td>
      <td><strong>(GUESSED BLOOD)</strong></td>
      <td>&nbsp;</td>
      <td><strong>3,207,919,363</strong></td>
      <td><strong>0.1569%</strong></td>
    </tr>
  </tbody>
</table>

<p>So 0.5298% of goods exports almost certainly use blood, and my best guess is that another 0.1569% of exports also include blood, for a total of 0.6867%.</p>

<p>Obviously, this is a rough cut. But I couldn’t find any other source that shows their work in any detail, so I hoped that by publishing this I could at least prod Cunningham’s law into action. Sorry for all the numbers.</p>

  </section>
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zed: High-performance AI Code Editor (471 pts)]]></title>
            <link>https://zed.dev/blog/fastest-ai-code-editor</link>
            <guid>43912844</guid>
            <pubDate>Wed, 07 May 2025 06:38:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zed.dev/blog/fastest-ai-code-editor">https://zed.dev/blog/fastest-ai-code-editor</a>, See on <a href="https://news.ycombinator.com/item?id=43912844">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>For millions of years, humans have used tools to create things. We programmers have recently created some very useful tools for ourselves: large language models. So far, these futuristic tools have been accessible to programmers in one of three ways:</p>
<ol>
<li>Copy/pasting from a website</li>
<li>Running in a terminal emulator</li>
<li>Baked into a closed-source fork of an open-source fork of a web browser</li>
</ol>
<p>As of today, there is now a fourth option:</p>
<p>Zed, the world’s fastest AI code editor.</p>
<h2 id="built-in-rust-open-source-gpl"><a href="#built-in-rust-open-source-gpl" aria-label="Copy heading link"><span><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="4" x2="20" y1="9" y2="9"></line><line x1="4" x2="20" y1="15" y2="15"></line><line x1="10" x2="8" y1="3" y2="21"></line><line x1="16" x2="14" y1="3" y2="21"></line></svg></span><span>Built in Rust, Open Source (GPL)</span></a></h2>
<p>The entire Zed code editor is open source under <a href="https://github.com/zed-industries/zed/blob/main/LICENSE-GPL">GPL version 3</a>, and scratch-built in Rust all the way down to <a href="https://zed.dev/blog/120fps">handcrafted GPU shaders and OS graphics API calls</a>.
Zed's new AI capabilities are also open-source, just like the rest of the editor, so you can see exactly what the new Agent Panel is doing under the hood.</p>
<p>Here it is in action:</p>
<p><figure><video src="https://customer-snccc0j9v3kfzkif.cloudflarestream.com/003e3457740dae547ae58c4ddb88384c/downloads/default.mp4" width="1920" height="1080" controls=""></video><figcaption>A walkthrough of Agentic Editing in Zed.</figcaption></figure></p>
<p><a href="https://zed.dev/agentic">The Agent Panel</a> lets you tell an AI agent what to do, and it'll do as you asked to the best of its ability.
This can be anything from asking questions about your code base to having it directly make changes and write new code.</p>
<p>For example, here I opened the Agent Panel and asked the agent to make a change about a blog post format:</p>
<div><figure><img src="https://zed.dev/img/agentic/blog-1-post-format.webp" alt="Asking the agent to help with blog post author's name display."><figcaption>Asking the agent to help with blog post author's name display.</figcaption></figure></div>
<p>I just typed in the words and pressed Enter; I didn’t have to teach the agent anything about my code base first, or wait for an indexing process to finish.
The agent quickly figured out what it needed by searching the code base—the same thing I’d do if I found myself in a new code base and wanted to orient myself.</p>
<p>This example had the agent making a trivial edit, but agents can be helpful even when I want to handcraft code myself.
For example, in an unfamiliar part of a large code base, an agent can save me time by tracking down the spot where I need to make the change.</p>
<h2 id="privacy-and-security-by-default"><a href="#privacy-and-security-by-default" aria-label="Copy heading link"><span><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="4" x2="20" y1="9" y2="9"></line><line x1="4" x2="20" y1="15" y2="15"></line><line x1="10" x2="8" y1="3" y2="21"></line><line x1="16" x2="14" y1="3" y2="21"></line></svg></span><span>Privacy and Security by Default</span></a></h2>
<p>Your conversation with the agent is private by default; Zed doesn't harvest your data for training purposes (or any other purpose).
If you want to share feedback to help improve Zed's AI, we've made it easy to do that by pressing a thumbs-up/thumbs-down button... but unless you opt into it by pressing the button, your conversation is never saved on our servers.</p>
<div><figure><img src="https://zed.dev/img/agentic/blog-2-feedback.webp" alt="Thumbs up and down buttons at the end of every Agent message."><figcaption>Thumbs up and down buttons at the end of every Agent message.</figcaption></figure></div>
<p>The agent will also prompt you for confirmation before doing things that potentially couldn't be undone, like running terminal commands.
(You can also tell it to always confirm, if you aren’t worried about what it might run.)</p>
<div><figure><img src="https://zed.dev/img/agentic/blog-3-confirmation.webp" alt="Request for confirmation before running a command."><figcaption>Request for confirmation before running a command.</figcaption></figure></div>
<p>Security prompts aside, generally the agent is designed to run in the background without bothering you, so you can do other things while it works.
When the agent is done, you get a notification if you had Zed in the background (including if you had a second Zed window open so you could work on another git checkout while the agent does its thing).</p>
<div><figure><img src="https://zed.dev/img/agentic/blog-4-notification.webp" alt="One of your agents notifying work has been done!"><figcaption>One of your agents notifying work has been done!</figcaption></figure></div>
<p>Once it’s done, you can review everything it did in one unified diff.</p>
<div><figure><img src="https://zed.dev/img/agentic/blog-review.webp" alt="The editable, multibuffer &quot;Review Changes&quot; tab."><figcaption>The editable, multibuffer "Review Changes" tab.</figcaption></figure></div>
<p>The diff is fully editable, so you can easily make changes to whatever the model came up with.
It supports multicursor editing, language server integrations, and all the speed you love from the rest of Zed.</p>

<p>A dropdown lets you choose which language model powers the agent. In addition to our selection of popular models like Claude 3.7 Sonnet and Gemini 2.5—available either through your Zed account or by bringing your own API key—you can also run custom models on your own hardware via Ollama.</p>
<div><figure><img src="https://zed.dev/img/agentic/blog-5-models.webp" alt="The Agent Panel selector showing models from different providers."><figcaption>The Agent Panel selector showing models from different providers.</figcaption></figure></div>
<p>Each agent can access the full capabilities of the editor.
That means not only can it edit the filesystem, it can also run language servers, linters, formatters, and even terminal commands in your local shell (with your permission).
Every extension you install can give the agent new powers.</p>
<p>You can also customize which powers an agent may use on a given task.
Revoking an agent’s access to a tool is as simple as unchecking that tool from a list, and you can save those preferences to Profiles for quickly switching between tool configurations later.
Zed ships with three convenient built-in Profiles: Write (all tools enabled), Ask (just the readonly tools), and Minimal (no tools at all, for when you just want to chat with the model).</p>
<div><figure><img src="https://zed.dev/img/agentic/blog-6-tools.webp" alt="All the tools in the Ask profile."><figcaption>All the tools in the Ask profile.</figcaption></figure></div>
<p>You can extend the agent’s capabilities with new tools, via Zed’s support for the <a href="https://zed.dev/blog/mcp">Model Context Protocol</a>.
This can give the agent access to things like databases, analytics, creating pull requests, and <a href="https://github.com/modelcontextprotocol/servers/tree/main/src/puppeteer">browser automation</a>.</p>
<div><figure><img src="https://zed.dev/img/agentic/blog-7-mcps.webp" alt="All tools available from each MCP server."><figcaption>All tools available from each MCP server.</figcaption></figure></div>
<p>As an example of how MCP tools can be tailored to your specific use-case, <a href="https://x.com/josevalim/status/1917296901268910405">check out this demo</a> that Elixir creator José Valim made of a MCP tool that works directly with the popular <a href="https://www.phoenixframework.org/">Phoenix Web Framework</a>.</p>
<h2 id="what-does-it-cost"><a href="#what-does-it-cost" aria-label="Copy heading link"><span><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="4" x2="20" y1="9" y2="9"></line><line x1="4" x2="20" y1="15" y2="15"></line><line x1="10" x2="8" y1="3" y2="21"></line><line x1="16" x2="14" y1="3" y2="21"></line></svg></span><span>What does it cost?</span></a></h2>
<p>It costs nothing to use Zed without the AI features.
As always, you can <a href="https://zed.dev/download">download Zed</a> (or <a href="https://github.com/zed-industries/zed/">build it from source</a>) and use it as a non-AI editor without signing up for anything.
All the non-AI features will work as normal.
This is how it’s always been, and we don’t plan to change that!</p>
<p>You can also pay someone else to use Zed’s AI features.
That is, you can bring your own API keys and they will Just Work with the new Agent Panel.
As with Zed’s other AI features, you can also use Ollama to run Zed’s agents on your own hardware.
(The only AI feature that doesn’t support this yet is <a href="https://zed.dev/blog/edit-prediction">Edit Predictions</a>; custom models are on the roadmap but haven’t landed yet.)</p>
<p>We’re also giving away some amount of AI usage.
On our free plan you'll get 50 prompts per month and on our new Pro plan you'll get 500 prompts for $20/month.
Check out our <a href="https://zed.dev/pricing">Pricing page</a> for more details.</p>
<p>We’re offering these plans because monthly limits are a popular alternative pricing structure to usage-based APIs—but if you’d prefer to bring your own API keys and pay (someone else) per token, you absolutely can.
It doesn’t cost us anything when you do that, so we don’t charge anything for it either!</p>
<p>Our goal at Zed has always been to make the world’s best code editor.
We built the Agent Panel because we believe the world’s best code editor should give its users easy access to helpful AI agents, not because we’re trying to make money by charging a premium on top of third-party AI services.</p>
<p>Long-term, we aim to build a self-sustaining business where revenue comes mostly from optional paid features that make an already-great experience even better.</p>
<h2 id="try-it-out"><a href="#try-it-out" aria-label="Copy heading link"><span><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="4" x2="20" y1="9" y2="9"></line><line x1="4" x2="20" y1="15" y2="15"></line><line x1="10" x2="8" y1="3" y2="21"></line><line x1="16" x2="14" y1="3" y2="21"></line></svg></span><span>Try it out!</span></a></h2>
<p>You can try out Zed’s new Agentic Editing experience right now—just <a href="https://zed.dev/download">download Zed here</a>.
That’s the easiest way to see what you think of it!</p>
<p>Right now, Zed only has a stable release for macOS and Linux.
Windows users can build from source, but the reason we don’t have a stable release for Windows is that it’s not finished yet.
(Scratch-building an editor means scratch-building support for each OS individually!) We plan to have a stable release of Windows later in 2025, and you can <a href="https://zed.dev/windows">sign up for the beta</a> right now.</p>
<p>As exciting as this launch is, we’re just getting warmed up. Stay tuned for:</p>
<ul>
<li>A major debugger release later this month</li>
<li>Improved collaboration between programmers and AI agents</li>
<li>Windows!</li>
</ul><hr></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EPA Plans to Shut Down the Energy Star Program (237 pts)]]></title>
            <link>https://www.nytimes.com/2025/05/06/climate/epa-energy-star-eliminated.html</link>
            <guid>43911252</guid>
            <pubDate>Wed, 07 May 2025 01:11:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2025/05/06/climate/epa-energy-star-eliminated.html">https://www.nytimes.com/2025/05/06/climate/epa-energy-star-eliminated.html</a>, See on <a href="https://news.ycombinator.com/item?id=43911252">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2025/05/06/climate/epa-energy-star-eliminated.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Jury orders NSO to pay $167M for hacking WhatsApp users (215 pts)]]></title>
            <link>https://arstechnica.com/security/2025/05/jury-orders-nso-to-pay-167-million-for-hacking-whatsapp-users/</link>
            <guid>43911167</guid>
            <pubDate>Wed, 07 May 2025 00:54:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/security/2025/05/jury-orders-nso-to-pay-167-million-for-hacking-whatsapp-users/">https://arstechnica.com/security/2025/05/jury-orders-nso-to-pay-167-million-for-hacking-whatsapp-users/</a>, See on <a href="https://news.ycombinator.com/item?id=43911167">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                      
                      
          <p>A jury has awarded WhatsApp $167 million in punitive damages in a case the company brought against Israel-based NSO Group for exploiting a software vulnerability that hijacked the phones of thousands of users.</p>
<p>The verdict, reached Tuesday, comes as a major victory not just for Meta-owned WhatsApp but also for privacy- and security-rights advocates who have long criticized the practices of NSO and other exploit sellers. The jury also awarded WhatsApp $444 million in compensatory damages.</p>
<h2>Clickless exploit</h2>
<p>WhatsApp sued NSO <a href="https://arstechnica.com/information-technology/2019/10/whatsapp-suit-says-israeli-spyware-maker-exploited-its-app-to-infect-1400-users/">in 2019</a> for an attack that targeted roughly 1,400 mobile phones belonging to attorneys, journalists, human-rights activists, political dissidents, diplomats, and senior foreign government officials. NSO, which works on behalf of governments and law enforcement authorities in various countries, exploited a critical WhatsApp vulnerability that allowed it to install NSO’s proprietary spyware <a href="https://arstechnica.com/information-technology/2017/04/found-quite-possibly-the-most-sophisticated-android-espionage-app-ever/">Pegasus</a> on iOS and Android devices. The clickless exploit worked by placing a call to a target's app. A target did not have to answer the call to be infected.</p>
<p>“Today’s verdict in WhatsApp’s case is an important step forward for privacy and security as the first victory against the development and use of illegal spyware that threatens the safety and privacy of everyone,” WhatsApp said in a <a href="https://about.fb.com/news/2025/05/winning-the-fight-against-spyware-merchant-nso/">statement</a>. “Today, the jury’s decision to force NSO, a notorious foreign spyware merchant, to pay damages is a critical deterrent to this malicious industry against their illegal acts aimed at American companies and the privacy and security of the people we serve.”</p>
<p>NSO created WhatsApp accounts in 2018 and used them a year later to initiate calls that exploited the critical vulnerability on phones, which, among others, included 100 members of "civil society" from 20 countries, according to an investigation research group Citizen Lab performed on behalf of WhatsApp. The calls passed through WhatsApp servers and injected malicious code into the memory of targeted devices. The targeted phones would then use WhatsApp servers to connect to malicious servers maintained by NSO.</p>

          
                      
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FTC bans hidden fees for live events and short-term rentals, effective May 12 (183 pts)]]></title>
            <link>https://techcrunch.com/2025/05/05/ftc-bans-hidden-fees-for-live-events-and-short-term-rentals-effective-may-12/</link>
            <guid>43910794</guid>
            <pubDate>Tue, 06 May 2025 23:41:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2025/05/05/ftc-bans-hidden-fees-for-live-events-and-short-term-rentals-effective-may-12/">https://techcrunch.com/2025/05/05/ftc-bans-hidden-fees-for-live-events-and-short-term-rentals-effective-may-12/</a>, See on <a href="https://news.ycombinator.com/item?id=43910794">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	<div>
		<figure><img width="1024" height="683" src="https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2174603749.jpg?w=1024" alt="The Federal Trade Commission (FTC) headquarters in Washington, DC" decoding="async" fetchpriority="high" srcset="https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2174603749.jpg 1024w, https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2174603749.jpg?resize=150,100 150w, https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2174603749.jpg?resize=300,200 300w, https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2174603749.jpg?resize=768,512 768w, https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2174603749.jpg?resize=680,454 680w, https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2174603749.jpg?resize=430,287 430w, https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2174603749.jpg?resize=720,480 720w, https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2174603749.jpg?resize=900,600 900w, https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2174603749.jpg?resize=800,534 800w, https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2174603749.jpg?resize=668,446 668w, https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2174603749.jpg?resize=562,375 562w, https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2174603749.jpg?resize=925,617 925w, https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2174603749.jpg?resize=708,472 708w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><strong>Image Credits:</strong>Stefani Reynolds/Bloomberg / Getty Images</figcaption></figure>	</div>
	<div>
						<p><time datetime="2025-05-05T14:17:46-07:00">2:17 PM PDT · May 5, 2025</time></p>											</div>
</div><div>
		
		<div>
			<div>
<p id="speakable-summary">The U.S. Federal Trade Commission (FTC) on Monday <a href="https://www.ftc.gov/news-events/news/press-releases/2025/05/ftc-rule-unfair-or-deceptive-fees-take-effect-may-12-2025" target="_blank" rel="noreferrer noopener nofollow">released</a> new documentation detailing its new “<a href="https://techcrunch.com/2024/12/17/ftc-bans-hidden-junk-fees-in-short-term-lodging-live-event-ticket-prices/">Rule on Unfair or Deceptive Fees</a>.”&nbsp;The rule, set to take effect on May 12, prohibits hidden fees for live events, hotels, and short-term rentals. It also bans practices such as “bait-and-switch pricing” and any actions that conceal or misrepresent total prices and fees.</p>

<p>In a newly published FAQ, the FTC offers a guide for these types of businesses, providing detailed information about pricing transparency. </p>







<p>The rule will <a href="https://techcrunch.com/2024/12/17/ftc-bans-hidden-junk-fees-in-short-term-lodging-live-event-ticket-prices/">impact businesses</a>, including live-event ticket sellers and short-term lodging providers, like hotels, motels, Airbnb, or VRBO. Third-party platforms, resellers, and travel agents are also covered by the new regulation. (Airbnb already <a href="https://techcrunch.com/2025/04/21/airbnb-will-automatically-display-total-price-to-all-users/">updated its service in advance of this new regulation</a> to show users the total cost of their stay upfront.)</p>

<p>According to the FTC:</p>

<ul>
<li>Live-event tickets include those for concerts, sporting events, music, theater, and other live performances that audiences watch as they occur, but not pre-recorded audio or visual performances.</li>



<li>The total price must include all known charges and fees.&nbsp;&nbsp;</li>



<li>Sites must disclose the total price upfront in ads and other offers for live-event tickets or short-term lodging.&nbsp;&nbsp;</li>



<li>The total price must also be more prominently displayed than any other pricing information.&nbsp;&nbsp;</li>



<li>There should be no misrepresentation about fees and charges.</li>



<li>Sites should provide truthful information about fees, including refund policies.&nbsp;&nbsp;</li>



<li>Sites should avoid vague terms like “convenience fees,” “service fees,” or “processing fees.”&nbsp;</li>



<li>Dynamic pricing strategies are still allowed as long as the pricing information isn’t misleading.</li>
</ul>

<p>Also included in the FTC’s new FAQ are the types of fees that can be excluded, such as taxes or government fees, shipping charges, and charges for optional goods or services people may select to buy as part of the same transaction. (Note that handling charges aren’t on this list.)&nbsp;</p>

<p>However, the FTC notes that businesses must disclose that it has excluded charges from the total price before asking for payment. For example, if a business excludes shipping charges from the advertised price, it’s required to clearly state the amount and purpose of those charges.</p>

<p>The FTC first passed the rule in December 2024, a landmark regulation that marked a significant win for consumers who have been frustrated for years about hidden fees.</p>
<div>
		
		<p>Techcrunch event</p>
		<div>
			
			<p><span>Berkeley, CA</span>
													<span>|</span>
													<span>June 5</span>
							</p>
							<p><a href="https://techcrunch.com/events/tc-sessions-ai/exhibit/?promo=tc_inline_exhibit&amp;utm_campaign=tcsessionsai2025&amp;utm_content=exhibit&amp;utm_medium=ad&amp;utm_source=tc">
					<span>BOOK NOW</span>
				</a>
					</p></div>
	</div>


</div>

			

			


			
			
			

			




			
			
			

			



			
<div>
	
	
	
	

	
<div>
	<p>
		Lauren covers media, streaming, apps and platforms at TechCrunch.	</p>
</div>


	
	<p>
		<a data-ctatext="View Bio" data-destinationlink="https://techcrunch.com/author/lauren-forristal/" data-event="button" href="https://techcrunch.com/author/lauren-forristal/">View Bio <svg style="width: 1em;" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24"><path fill="var(--c-svg, currentColor)" d="M16.5 12 9 19.5l-1.05-1.05L14.4 12 7.95 5.55 9 4.5z"></path></svg></a>
	</p>
	
</div>


		</div>
		

		
		<div id="wp-block-techcrunch-most-popular-posts__heading">
<h2 id="h-most-popular">Most Popular</h2>

</div>
		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bloat is still software's biggest vulnerability (2024) (240 pts)]]></title>
            <link>https://spectrum.ieee.org/lean-software-development</link>
            <guid>43910745</guid>
            <pubDate>Tue, 06 May 2025 23:33:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/lean-software-development">https://spectrum.ieee.org/lean-software-development</a>, See on <a href="https://news.ycombinator.com/item?id=43910745">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="Why Bloat Is Still Software’s Biggest Vulnerability"><p><em>This post is dedicated to the memory of </em><a href="https://ethz.ch/en/news-and-events/eth-news/news/2024/01/computer-pioneer-niklaus-wirth-has-died.html" rel="noopener noreferrer" target="_blank"><em>Niklaus Wirth</em></a><em>, a computing pioneer who passed away 1 January 2024. In 1995 he wrote an influential article called “</em><a href="https://cr.yp.to/bib/1995/wirth.pdf" rel="noopener noreferrer" target="_blank"><em>A Plea for Lean Software</em></a><em>,”</em><em> published in </em><a href="https://ieeexplore.ieee.org/document/348001" target="_blank">Computer</a><em>, the magazine for members of the <a href="https://spectrum.ieee.org/tag/ieee-computer-society">IEEE Computer Society</a>, which I read early in my career as an entrepreneur and software developer. In what follows, I try to make the same case nearly 30 years later, updated for today’s computing horrors. A version of this post was </em><a href="https://berthub.eu/articles/posts/a-2024-plea-for-lean-software/" rel="noopener noreferrer" target="_blank"><em>originally published</em></a><em> on my personal blog, <a href="http://berthub.eu/" target="_blank">Berthub.eu</a>.</em><br></p><p>Some years ago I did a talk at a local university on <a href="https://spectrum.ieee.org/tag/cybersecurity">cybersecurity</a>, titled “<a href="https://berthub.eu/cyber-mad/Cyber%20and%20information%20security.pdf" rel="noopener noreferrer" target="_blank">Cyber and Information Security: Have We All Gone Mad?</a>” It is still worth reading today since we <em>have</em> gone quite mad collectively.</p><p>The way we build and ship software these days is mostly ridiculous, leading to apps using millions of lines of code to open a garage door, and other simple programs importing <a href="https://github.com/SashenJayathilaka/Photo-Sharing-Application" target="_blank">1,600 external code libraries</a>—dependencies—of unknown provenance. <a href="https://spectrum.ieee.org/tag/software-security">Software security</a> is dire, which is a function both of the quality of the code and the sheer amount of it. Many of us <a href="https://spectrum.ieee.org/tag/programmers">programmers</a> know the current situation is untenable. Many programmers (and their management) sadly haven’t ever experienced anything else. And for the rest of us, we rarely get the time to do a better job.</p><p>It is not just you; we are not merely suffering from nostalgia: Software really is very weird today.</p><p> Let me briefly go over the terrible state of software security, and then spend some time on why it is so bad. I also mention some regulatory and legislative things going on that we might use to make software quality a priority again. Finally, I talk about <a href="https://berthub.eu/articles/trifecta" rel="noopener noreferrer" target="_blank">an actual useful piece of software I wrote</a> as a proof of concept that one can still make <a href="https://berthub.eu/articles/posts/trifecta-technology" rel="noopener noreferrer" target="_blank">minimal and simple yet modern software</a>.</p><p>I hope that this post provides some mental and moral support for suffering programmers and technologists who want to improve things. It is not just you; We are not merely suffering from nostalgia: Software really is very weird today.</p><h2>The terrible state of software security</h2><p>Without going all <a href="https://knowyourmeme.com/memes/old-man-yells-at-cloud" rel="noopener noreferrer" target="_blank">“Old man (48) yells at cloud</a>,” let me restate some obvious things. The state of software security is <em>dire</em>. If we only look at the past year, if you ran industry-standard software like <a href="https://www.ncsc.gov.uk/news/exploitation-ivanti-vulnerabilities" rel="noopener noreferrer" target="_blank">Ivanti</a>, <a href="https://en.wikipedia.org/wiki/2023_MOVEit_data_breach" rel="noopener noreferrer" target="_blank">MOVEit</a>, <a href="https://www.bleepingcomputer.com/news/microsoft/russian-hackers-exploiting-outlook-bug-to-hijack-exchange-accounts/" rel="noopener noreferrer" target="_blank">Outlook</a>, <a href="https://confluence.atlassian.com/security/cve-2023-22518-improper-authorization-vulnerability-in-confluence-data-center-and-server-1311473907.html" rel="noopener noreferrer" target="_blank">Confluence</a>, <a href="https://www.mandiant.com/resources/blog/barracuda-esg-exploited-globally" rel="noopener noreferrer" target="_blank">Barracuda Email Security Gateway</a>, <a href="https://www.mandiant.com/resources/blog/remediation-netscaler-adc-gateway-cve-2023-4966" rel="noopener noreferrer" target="_blank">Citrix NetScaler ADC, and NetScaler Gateway</a>, chances are you got hacked. Even companies with near-infinite resources (like Apple and <a href="https://spectrum.ieee.org/tag/google">Google</a>) made <a href="https://www.schneier.com/blog/archives/2023/09/critical-vulnerability-in-libwebp-library.html" rel="noopener noreferrer" target="_blank">trivial “worst practice” security mistakes</a> that put <a href="https://www.bleepingcomputer.com/news/security/apple-zero-click-imessage-exploit-used-to-infect-iphones-with-spyware/" rel="noopener noreferrer" target="_blank">their customers in danger</a>. Yet we continue to rely on all these products.</p><p>Software is now (rightfully) considered so dangerous that we tell everyone not to run it themselves.<em></em></p><p>Software is now (rightfully) considered so dangerous that we tell everyone not to run it themselves. Instead, you are supposed to leave that to an “<em>X</em> as a service” provider, or perhaps just to “the cloud.” Compare this to a hypothetical situation where cars are so likely to catch fire that the advice is not to drive a car yourself, but to leave that to professionals who are always accompanied by professional firefighters.</p><p>The assumption is then that the cloud is somehow able to make insecure software trustworthy. Yet in the past year, we’ve learned that Microsoft’s <a href="https://thehackernews.com/2023/09/outlook-breach-microsoft-reveals-how.html" rel="noopener noreferrer" target="_blank">email platform was thoroughly hacked</a>, including classified government email. (<a href="https://metacurity.substack.com/p/russian-hacking-group-midnight-blizzard" rel="noopener noreferrer" target="_blank">Twice!</a>) There are also <a href="https://www.lastweekinaws.com/blog/azures-terrible-security-posture-comes-home-to-roost/" rel="noopener noreferrer" target="_blank">well-founded worries about the security of the Azure cloud</a>. Meanwhile, industry darling Okta, which provides cloud-based software that enables user log-in to various applications, <a href="https://www.reuters.com/technology/cybersecurity/okta-says-hackers-stole-data-all-customer-support-users-cyber-breach-2023-11-29/" rel="noopener noreferrer" target="_blank">got comprehensively owned</a>. This was their second breach within two years. Also, there was a suspicious spate of Okta users subsequently getting hacked.</p><p>Clearly, we need better software.</p><p>The <a href="https://spectrum.ieee.org/tag/european-union">European Union</a> has launched three pieces of <a href="https://spectrum.ieee.org/tag/legislation">legislation</a> to this effect: <a href="https://digital-strategy.ec.europa.eu/en/policies/nis2-directive" rel="noopener noreferrer" target="_blank">NIS2 for important services</a>; the <a href="https://digital-strategy.ec.europa.eu/en/policies/cyber-resilience-act" rel="noopener noreferrer" target="_blank">Cyber Resilience Act </a>for almost all commercial software and electronic devices; and a revamped <a href="https://www.euractiv.com/section/digital/news/eu-updates-product-liability-regime-to-include-software-artificial-intelligence/" rel="noopener noreferrer" target="_blank">Product Liability Directive</a> that also extends to software. Legislation is always hard, and it remains to be seen <a href="https://berthub.eu/articles/posts/eu-cra-what-does-it-mean-for-open-source/" rel="noopener noreferrer" target="_blank">if they got it right</a>. But that software security is terrible enough these days to warrant legislation seems obvious.</p><h2>Why software security is so bad</h2><p>I want to touch on incentives. The situation today is clearly working well for commercial operators. Making more secure software takes time and is a lot of work, and the current security incidents don’t appear to be impacting the bottom line or stock prices. You can <a href="https://www.microsoft.com/en-us/research/publication/software-components-only-the-giants-survive/" rel="noopener noreferrer" target="_blank">speed up time to market by cutting corners</a>. So from an economic standpoint, what we see is entirely predictable. Legislation could be very important in changing this equation.</p><p>The security of software depends on two factors—the <em>density</em> of security issues in the <a href="https://spectrum.ieee.org/tag/source-code">source code</a> and the sheer <em>amount of code</em> accessible by <a href="https://spectrum.ieee.org/tag/hackers">hackers</a>. As the U.S. defense community loved to point out in the 1980s, <a href="https://www.quora.com/Who-said-Quantity-has-a-quality-all-its-own" rel="noopener noreferrer" target="_blank">quantity has a quality all of its own</a>. The reverse applies to software—the more you have of it, the more risks you run.</p><p>As a case in point, Apple iPhone users got repeatedly hacked over many years because of the huge attack surface exposed by iMessage. It is possible to send an unsolicited iMessage to an Apple user. The phone will then immediately process that message so it can preview it. The problem is that Apple in its wisdom decided that such unsolicited messages needed to support a vast array of image formats, accidentally <a href="https://googleprojectzero.blogspot.com/2021/12/a-deep-dive-into-nso-zero-click.html" rel="noopener noreferrer" target="_blank">including PDFs with weird embedded compressed fonts</a> using an ancient format that effectively included a <a href="https://spectrum.ieee.org/tag/programming">programming</a> language. So someone could send an unsolicited message to your iPhone that could probe for weaknesses in the rest of the phone.</p><p>In this way, attackers were able to benefit from security bugs in the phone’s millions of lines of code. You don’t need a high bug density to find <a href="https://www.europarl.europa.eu/meetdocs/2014_2019/plmrep/COMMITTEES/PEGA/DV/2023/05-08/REPORTcompromises_EN.pdf" rel="noopener noreferrer" target="_blank">an exploitable hole</a> in millions of lines of code.</p><p>Wiping out all the bugs in your code won’t save you from the decision to implement a feature to automatically execute code embedded in documents.</p><p>Apple could have prevented this situation by restricting previews to a far smaller range of image formats, or even a single “known good” image format. Apple could have saved themselves an enormous amount of pain simply by <a href="https://github.com/berthubert/sbox#sbox" target="_blank">exposing fewer lines of their code</a> to attackers. Incidentally, the E.U.’s Cyber Resilience Act <a href="https://berthub.eu/articles/posts/eu-cra-secure-coding-solution/" target="_blank">explicitly tells vendors to minimize the attack surface</a>.</p><p><span></span>Apple is (by far) not the worst offender in this field. But it is a widely respected and well-resourced company that usually thinks through what they do. And even they got it wrong by needlessly shipping and exposing too much code.</p><h2>Could we not write better code?</h2><p>There are those who think the biggest problem is the quality of the code, expressed in terms of the density of bugs in it. There are many interesting things happening on this front, like the use of <a href="https://www.nsa.gov/Press-Room/Press-Releases-Statements/Press-Release-View/Article/3608324/us-and-international-partners-issue-recommendations-to-secure-software-products/" target="_blank">memory safe languages</a> like <a href="https://www.rust-lang.org/" target="_blank">Rust</a>. Other languages are <a href="https://github.com/google/sanitizers/wiki/AddressSanitizer" target="_blank">also upping their security game</a>. <a href="https://en.wikipedia.org/wiki/Fuzzing" rel="noopener noreferrer" target="_blank">Fuzzers</a>—test tools that automatically modify inputs to computer programs to find weaknesses and bugs—are also getting ever more advanced.</p><p>But many security problems are in the logic underlying the code. For example, the Barracuda email exploit originated in a third-party library that would actually <a href="https://www.cvedetails.com/cve/CVE-2023-7101/" rel="noopener noreferrer" target="_blank">execute code</a> in Excel spreadsheets when they were scanned for <a href="https://spectrum.ieee.org/tag/viruses">viruses</a>. Wiping out all the bugs in your code won’t save you from the decision to implement a feature to automatically execute code embedded in documents.</p><h2>The state of shipping software</h2><p>Another problem is that we often don’t know what code we are actually shipping. Software has gotten <em>huge</em>. In 1995 <a href="https://en.wikipedia.org/wiki/Niklaus_Wirth" rel="noopener noreferrer" target="_blank">Niklaus Wirth</a> lamented that software had grown to megabytes in size. In his article “A Plea for Lean Software,” he went on to describe his <a href="https://en.wikipedia.org/wiki/Oberon_(operating_system)" rel="noopener noreferrer" target="_blank">Oberon operating system</a>, which was only 200 kilobytes, including an editor and a compiler. There are now projects that have more than 200 KB for their configuration files alone.</p><p>A typical app today is built on <a href="https://www.electronjs.org/" rel="noopener noreferrer" target="_blank">Electron JS</a>, a framework that incorporates both Chromium (“Chrome”) and Node.JS, which provides access to tens of thousands of software packages for <a href="https://spectrum.ieee.org/tag/javascript">JavaScript</a>. I estimate just using Electron JS entails at least 50 million lines of code if you include dependencies. Perhaps more. The app meanwhile likely pulls in hundreds or thousands of helper packages. Many packages used will also, by default, snitch on your users to advertisers and other data brokers. Dependencies pull in further dependencies, and exactly what gets included in the build can change on a daily basis, and no one really knows.</p><p>If this app controls anything in your house, it will also connect to a software stack over at <a href="https://spectrum.ieee.org/tag/amazon">Amazon</a>, probably also powered by Node.js, also pulling in many dependencies. </p><p>We are likely looking at over 50 million active lines of code to open a garage door….</p><p>But wait, there’s more. We used to ship software as the output of a compiler, or perhaps as a bunch of files to be interpreted. Such software then had to be <em>installed</em> and <em>configured</em> to work right. Getting your code packaged to ship like this is a lot of work. But it was good work since it forced people to think about what was in their “package.” This software package would then integrate with an <a href="https://spectrum.ieee.org/tag/operating-system">operating system</a> and with local services, based on the configuration.</p><p>Since the software ran on a different computer than the one it was developed on, people really had to know what they shipped and think it through. And sometimes it didn’t work, leading to the joke where a developer tells the operations people, “Well, it works on my system,” and the retort “Then back up your email, we’re taking your laptop into production!”</p><p>This used to be a joke, but these days we often ship software as containers, shipping not only the software itself but also including operating system files to make sure the software runs in a well-known environment. This frequently entails effectively shipping a complete computer disk image. This again vastly expands the amount of code being deployed. Note that you can do good things with containers like <a href="https://spectrum.ieee.org/tag/docker">Docker</a> (see below), but there are a lot of images over 350 MB on the <a href="https://hub.docker.com/explore" rel="noopener noreferrer" target="_blank">Docker Hub</a>.</p><p>Add it all up and we are likely looking at over 50 million active lines of code to open a garage door, running several operating-system images on multiple servers.</p><p>Now, even if all the included dependencies are golden, are we sure that their security updates are making it to your garage door opener app? I wonder how many Electron apps are still shipping with the <a href="https://www.schneier.com/blog/archives/2023/09/critical-vulnerability-in-libwebp-library.html" rel="noopener noreferrer" target="_blank">image processing bug</a> that had Google and Apple scramble to put out updates last year. We don’t even know.</p><p>But even worse, it is a known fact that all these dependencies are <em>not</em> golden. The Node.js ecosystem has a <a href="https://thehackernews.com/2023/02/researchers-hijack-popular-npm-package.html" rel="noopener noreferrer" target="_blank">comical history</a> of package repositories <a href="https://snyk.io/blog/npm-security-preventing-supply-chain-attacks/" rel="noopener noreferrer" target="_blank">being taken over</a>, hijacked, or resurrected under the same name by someone else, someone with nefarious<a href="https://www.theregister.com/2023/06/19/npm_s3_buckets_malware/" rel="noopener noreferrer" target="_blank"> plans for your security</a>. <a href="https://www.theregister.com/2023/06/02/novel_pypi_attack_reversinglabs/" rel="noopener noreferrer" target="_blank">PyPI</a> (a <a href="https://spectrum.ieee.org/tag/python">Python</a> counterpart of Node.js) has suffered from <a href="https://www.theregister.com/2023/01/04/pypi_pytorch_dependency_attack/" rel="noopener noreferrer" target="_blank">similar problems</a>. Dependencies always need scrutiny, but no one can reasonably be expected to <a href="https://medium.com/graph-commons/analyzing-the-npm-dependency-network-e2cf318c1d0d" rel="noopener noreferrer" target="_blank">check thousands of them frequently</a>. But we prefer not to think about this. (Note that you should also not overshoot and needlessly reimplement everything yourself to prevent dependencies. There are very good modules that <a href="https://sqlite.org/" rel="noopener noreferrer" target="_blank">likely are more secure</a> than what you could type in on your own.)</p><p>The world is shipping far too much code where we don’t even know what we ship and we aren’t looking hard enough (or at all) at what we <em>do</em> know we ship.</p><h2>You <em>can</em> write lean code today</h2><p>Writing has been called the process by which you find out you don’t <a href="https://fs.blog/writing-to-think/" rel="noopener noreferrer" target="_blank">know what you are talking about</a>. Actually doing stuff, meanwhile, is the process by which you find out you also did not know what you were writing about.</p><p>In a small reenactment of Wirth’s Oberon Project, I too wrote some code to prove a point, and to reassure myself I still know what I am talking and writing about. Can you still make useful and modern software the old way? I decided to try to create a minimalistic but full-featured image-sharing solution that I could trust.</p><p>Trifecta is the result. It is <a href="https://berthub.eu/articles/trifecta/" rel="noopener noreferrer" target="_blank">actual stand-alone software</a> that lets you use a browser to drag and drop images for easy sharing. It has pained me for years that I had to use <a href="https://imgur.com/" rel="noopener noreferrer" target="_blank">imgur</a> for this purpose. Not only does imgur install lots of cookies and trackers in my browser, I also force these trackers onto the people who view the images that I share. If you want to self-host a Web service like this, you also don’t want to get hacked. Most image-sharing solutions I found that you could run yourself are based on huge frameworks that I don’t trust too much for the reasons outlined above.</p><p>So, also to make a point, I decided to create a minimalistic but also useful image-sharing solution that I could trust. And more important, that other people could trust as well, because you can check out all Trifecta’s code within a few hours. It consists of <a href="https://berthub.eu/articles/posts/trifecta-technology" target="_blank">1,600 lines of new source code</a>, plus around five important dependencies. </p><p>You end up with a grand total of 3 megabytes of code.</p><p>To contrast, <a href="https://github.com/CaramelFur/Picsur/pkgs/container/picsur" rel="noopener noreferrer" target="_blank">one other image-sharing solution</a> ships as a 288-MB Docker image, although admittedly it looks better and has some more features. But not 285 MB worth of them. Another comparison is <a href="https://github.com/SashenJayathilaka/Photo-Sharing-Application" rel="noopener noreferrer" target="_blank">this Node-based picture-sharing solution</a>, which <a href="https://spectrum.ieee.org/tag/clocks">clocks</a> in at 1,600 dependencies, apparently totaling over 4 million lines of JavaScript.</p><p>The world ships too much code, most of it by third parties, sometimes unintended, most of it uninspected. <em></em></p><p><span></span>Note that Trifecta is not intended as a public site where random people can share images, as that does not tend to end well. It is however very suitable for company or personal use. You can read more about the project <a href="https://berthub.eu/articles/trifecta" target="_blank">here</a>, and there is also <a href="https://berthub.eu/articles/posts/trifecta-technology" target="_blank">a page</a> about the technology used to deliver such a tiny self-contained solution.</p><h2>Response to Trifecta</h2><p>This has been rather interesting. The most common response to Trifecta so far has been that I should use a whole bag of Amazon Web Services to deploy it. This is an exceedingly odd response to a project with the clearly stated goal of providing stand-alone software that does not rely on external services. I’m not sure what is going on here.</p><p>Another reaction has been that I treat Docker unfairly, and that you could definitely use containers for good. And I agree wholeheartedly. But I also look at what people are actually doing (also with other forms of containers or virtual machines), and it’s not so great.</p><p>I want to end this post with some observations from <a href="https://cr.yp.to/bib/1995/wirth.pdf" target="_blank">Niklaus Wirth’s 1995 paper</a>:</p><blockquote>“To some, complexity equals power. (…) Increasingly, <em>people seem to misinterpret complexity as sophistication</em>, which is baffling—the incomprehensible should cause suspicion rather than admiration.”</blockquote><p>I’ve similarly observed that some people prefer complicated systems. As <a href="https://en.wikipedia.org/wiki/Tony_Hoare" rel="noopener noreferrer" target="_blank">Tony Hoare</a> noted long ago, “[T]here are two methods in software design. <a href="https://dl.acm.org/doi/pdf/10.1145/1283920.1283936" rel="noopener noreferrer" target="_blank">One is to make the program so simple, there are obviously no errors</a>. The other is to make it so complicated, there are no obvious errors.” If you can’t do the first variant, the second way starts looking awfully attractive perhaps.</p><p>Back to Wirth: </p><blockquote>“Time pressure is probably the foremost reason behind the emergence of bulky software. The time pressure that designers endure discourages careful planning. It also discourages improving acceptable solutions; instead, it encourages quickly conceived software additions and corrections. Time pressure gradually corrupts an engineer’s standard of quality and perfection. It has a detrimental effect on people as well as products.”</blockquote><p>Why spend weeks paring down your software when you can also ship a whole pre-installed operating-system image that just works?</p><blockquote>“The plague of software explosion is not a ‘law of nature.’ It is avoidable, and it is the software engineer’s task to curtail it.”</blockquote><p>If this is indeed on the shoulders of software people, we should perhaps demand more time for it.</p><p>The world ships too much code, most of it by third parties, sometimes unintended, most of it uninspected. Because of this, there is a huge <em>attack surface</em> full of mediocre code. Efforts are ongoing to improve the quality of code itself, but many exploits are due to logic fails, and less progress has been made scanning for those. Meanwhile, great strides could be made by paring down just how much code we expose to the world. This will increase time to market for products, but legislation is around the corner that should force vendors to take security more seriously.</p><p>Trifecta is, like Wirth’s Oberon Project mentioned above, meant as a proof that you can deliver a lot of functionality even with a limited amount of code and dependencies. With effort and legislation, maybe the future could again bring sub-50-million-line garage-door openers. Let’s try to make it happen.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The DEA is now abandoning body cameras (154 pts)]]></title>
            <link>https://www.propublica.org/article/drug-enforcement-administration-ends-body-camera-program-trump</link>
            <guid>43910720</guid>
            <pubDate>Tue, 06 May 2025 23:28:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.propublica.org/article/drug-enforcement-administration-ends-body-camera-program-trump">https://www.propublica.org/article/drug-enforcement-administration-ends-body-camera-program-trump</a>, See on <a href="https://news.ycombinator.com/item?id=43910720">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-pp-location="article body">

        
                    <div data-pp-location="top-note">
                

                                                
            <p>ProPublica is a nonprofit newsroom that investigates abuses of power. Sign up to receive <a href="https://www.propublica.org/newsletters/the-big-story?source=www.propublica.org&amp;placement=top-note&amp;region=national">our biggest stories</a> as soon as they’re published.</p>

                

            </div><!-- end .article-body__top-notes -->
        
        
        




                    

<figure data-pp-id="1" data-pp-blocktype="embed">

    


                        
            
    
<figcaption>
    
    
    
    </figcaption>


</figure>

        
    
                    
<p data-pp-blocktype="copy" data-pp-id="2.0">The Drug Enforcement Administration has quietly ended its body camera program barely four years after it began, according to an internal email obtained by ProPublica.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="3.0">On April 2, DEA headquarters emailed employees announcing that the program had been terminated effective the day before. The DEA has not publicly announced the policy change, but by early April, <a href="https://www.dea.gov/es/node/223436">links to pages about body camera policies</a> on the DEA’s website were broken.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="4.0">The email said the agency made the change to be “consistent” with a Trump executive order rescinding the 2022 requirement that all federal law enforcement agents use body cameras.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="5.0">But at least two other federal law enforcement agencies within the Justice Department — the U.S. Marshals Service and the Bureau of Alcohol, Tobacco, Firearms and Explosives — are still requiring body cameras, according to their spokespeople. The FBI referred questions about its body camera policy to the Justice Department, which declined to comment.</p>
        
    
                        
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="7.0">The DEA did not respond to questions about its decision to stop using the cameras, saying that the agency “does not comment on tools and techniques.” Reuters reported on the change as part of a story about <a href="https://www.reuters.com/world/us/white-house-seeks-budget-cuts-justice-department-law-enforcement-offices-sources-2025-05-02/">budget cuts for law enforcement offices</a>.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="8.0">One former federal prosecutor expressed concern that the change would make life more difficult for DEA agents.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="9.0">“The vast majority of times I viewed body camera footage is based on allegations from a defense attorney about what a cop did,” said David DeVillers, former U.S. attorney for the Southern District of Ohio. “And I would say 95% of the time it absolves the cop of wrongdoing.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="11.0">The Justice Department started requiring that its federal agents wear the devices in 2021 in the wake of the protests over George Floyd’s death the previous summer.</p>
        
    
                    
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="13.0">“We welcome the addition of body worn cameras and appreciate the enhanced transparency and assurance they provide to the public and to law enforcement officers working hard to keep our communities safe and healthy,” then-DEA Administrator Anne Milgram said in a <a href="https://www.justice.gov/archives/opa/pr/justice-department-announces-first-federal-agents-use-body-worn-cameras?utm_source=chatgpt.com">Sept. 1, 2021, press release</a> announcing the use of the cameras.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="14.0">In May 2022, then-President Joe Biden issued an executive order expanding the use of body cameras to all federal law enforcement officers. </p>

<p data-pp-blocktype="copy" data-pp-id="14.1">In January, the incoming Trump administration rescinded that order, along with almost 100 others it considered “harmful.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="15.0">In early February, U.S. Immigration and Customs Enforcement, which is part of the Department of Homeland Security, was <a href="https://thehill.com/homenews/administration/5147728-border-patrol-to-stop-usage-of-body-cameras-in-the-field-report/">one of the first agencies to get rid of its body cameras</a>. Subsequent videos show plainclothes immigration agents making arrests with no visible body cameras.</p>
        
    
                        
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="17.0">The DOJ wrote in a 2022 Office of Inspector General management report that the cameras were a “means of enhancing police accountability and the public’s trust in law enforcement.” Studies have consistently shown that departments that use body cameras experience a drop in complaints against officers, according to the <a href="https://www.policeforum.org/assets/BWCdecadelater.pdf">nonprofit Police Executive Research Forum</a>, though it’s not clear if the drop is due to improvements in officer behavior or to a decrease in frivolous complaints.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="18.0">“Eliminating these videos is really taking away a tool that we’ve seen be of benefit to law enforcement practices,” said Cameron McEllhiney, executive director of the National Association for Civilian Oversight of Law Enforcement. “It’s also a great teaching tool, besides keeping community members safe from the potential misconduct that could occur.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="19.0">The DOJ put a lot of money into the body camera initiative. In August of 2021, it awarded Axon, the company that dominates the body camera market, a $30.4 million contract for cameras and the software to handle the evidence they created. The contract, according to Axon, remains active. But only about one-sixth of it has been paid out, according to <a href="https://www.usaspending.gov/award/CONT_IDV_15DDHQ21D00000010_1524">federal contracting data</a>.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="20.0">The most recent publicly available version of the DEA’s body camera policy dates to December 2022. It only required agents to wear the devices when they were conducting preplanned arrests or searches and seizures that required a warrant. It also only required DEA officers to wear their body cameras when they were working within the United States.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="21.0">Agents had 72 hours after the end of an operation to upload their video evidence, unless there was a shooting, in which case they were instructed to upload the video evidence as soon as possible. The policy laid out in detail how and by whom evidence from the cameras should be handled in the event officers used force, and it authorized the DEA to use the video evidence when investigating its own officers.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="22.0">The DEA had planned to implement the policy in phases so that eventually its officers nationwide would be wearing the devices when serving warrants or carrying out planned arrests. In its 2025 fiscal year <a href="https://www.dea.gov/sites/default/files/2024-05/dea_fy_2025_presidents_budget_narrative_omb_cleared_03-07-2024_final_leg_changes_1.pdf">budget request</a> to Congress, the agency asked for $15.8 million and 69 full time employees, including five attorneys, “to enable the DEA’s phased implementation plan of nationwide use of Body Worn Cameras.”</p>
        
    
                                  
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="24.0">Records obtained via Freedom of Information Act request by Citizens for Responsibility and Ethics in Washington show that the Biden-era DOJ had an ambitious plan to capture agencywide metrics and data about the efficiency and use of body cameras by its law enforcement officers.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="25.0">Laura Iheanachor, senior counsel at CREW, said that before federal law enforcement started wearing body cameras, several local <a href="https://www.startribune.com/ear-after-bidens-executive-order-body-cameras-majority-federal-agents-minnesota-not-yet-wearing/600278243?utm_source=chatgpt.com">police agencies had declined to participate</a> in federal task forces because doing so would have forced their officers to remove their cameras.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="26.0">“It’s a protective measure for officers, for the public,” Iheanachor said. “And it allows state and federal law enforcement to work together in harmony.”</p>
        
    
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Alignment is not free: How model upgrades can silence your confidence signals (110 pts)]]></title>
            <link>https://www.variance.co/post/alignment-is-not-free-how-a-model-silenced-our-confidence-signals</link>
            <guid>43910685</guid>
            <pubDate>Tue, 06 May 2025 23:22:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.variance.co/post/alignment-is-not-free-how-a-model-silenced-our-confidence-signals">https://www.variance.co/post/alignment-is-not-free-how-a-model-silenced-our-confidence-signals</a>, See on <a href="https://news.ycombinator.com/item?id=43910685">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="w-node-b7369729-0a2c-bcc3-a172-35503e523a83-6bf35c4a"><h3>The Flattening Calibration Curve</h3><p>The post-training process for LLMs can bias behavior for language models when they encounter content that violates their safety post-training guidelines. As mentioned by OpenAI’s GPT-4 system card, model calibration rarely survives post-training, resulting in models that are extremely confident even when they’re wrong.¹ For our use case, we often see this behavior with the side effect of biasing language model outputs towards violations, which can result in wasted review times for human reviewers in an LLM-powered content moderation system.</p><figure><p><img src="https://cdn.prod.website-files.com/67ad3648c8025e1491009050/6811271d3c77ca9a3d5973c6_Screenshot%202025-04-29%20at%2012.22.47%E2%80%AFPM.png" loading="lazy" alt=""></p><figcaption>Pre-training vs. Post-preference optimization calibration curves</figcaption></figure><p>‍</p><h3>A Working Signal on GPT-4o</h3><p>Take the below histogram of log probs sampled from a golden dataset of false positives against GPT-4o. We can see that almost all outputs have log p≈0 nats (probability ≈ 1) for outputting “true”, indicating a true violation in this dataset. </p><p>However, there are a few outliers in this dataset, almost all of which correspond to patterns of behavior we observed in our dataset when our model would stray away from formal grounded policy definitions, or hallucinations in content or policy violations.</p><figure><p><img src="https://cdn.prod.website-files.com/67ad3648c8025e1491009050/68111feba061ca9521c24b99_AD_4nXc4p0jjcR6Rel5WOPrbPVMyXUMqcbD5AT86AB_541AJjUwHlud_EtiowpQcYpipRxBuw6eN1iGK5kaIzm2uKlBDTtB6WxzLtvCecMUd84R7suLDm2T11zTiMBSnL2eejPSMxJ9eDg.png" loading="lazy" alt=""></p></figure><figure><p><img src="https://cdn.prod.website-files.com/67ad3648c8025e1491009050/68111ff755936e54ec7fcc6c_AD_4nXf_WGGEE5lX_FFXyFRQ2Cmb6d5STGsCwEXSeWDA4NB-EU3kVFSGi1iqtlpwCelFY50XAHyOvLL-HWlb99M7XfN3GlCYsMz9Ma0crhq1joIKqgHXJr_bD1LiuoEyOcWjbpLnbWr_EA.png" loading="lazy" alt=""></p><figcaption>The functional confidence signal in GPT-4o</figcaption></figure><p>This results in a functional enough ROC curve that’s helpful for calibrating our model to ignore these outputs, and perform tasks like flagging the content for review or suppress the output as likely spurious.&nbsp;</p><h3>The Upgrade That Vanished Uncertainty</h3><p>However, what we found is that after switching to <strong>GPT-4.1-mini</strong>, this signal vanishes. Although we’re still able to measure log probs for other tokens in our structured outputs, each token was 100% confident that it should return <strong>true</strong> in this dataset, which completely destroyed our signal.</p><p>Why does a smaller sibling of the same model family erase so much information? It’s possible that due to the heavy distillation that occurs to train 4-1 mini for binary decisions (such as outputting a boolean field in a structured output), the dimension is collapsed entirely: the student is taught to emit the right answer and ignore entropy at all. This results in no usable confidence signal.</p><p>We tried several other approaches to recover the lost uncertainty signal, all unsuccessful:</p><ol role="list"><li><strong>Entropy differential hypothesis</strong>: We measured entropy between content array vs. chain-of-thought mean, with the theory that hallucinated violations would be wordier/less confident. In practice, we were unable to find a signal here</li><li><strong>Span consistency check</strong>: We analyzed standard deviation of span log-probs, hoping for variation between true/false cases. In practice, both classes showed σ≈0.018 (identical).</li><li><strong>Perplexity analysis</strong>: We calculated token-level perplexity averages across all samples. In practice, we found similar metrics for every sample, safe or unsafe.</li></ol><figure><p><img src="https://cdn.prod.website-files.com/67ad3648c8025e1491009050/681120cbf8610b3e751cdedc_AD_4nXetzSu2S_9xK0QNofczekM3zzwMkkMs9-cTPxGHuJKSiM3D4edDNoMoxI-V7qnzctSc2i3DVBzfX-9vVmdIw-2A-RryWT0DICt7jJNLOG10V279Jtm-sD0B70IOVa481B-wz9k.png" loading="lazy" alt=""></p></figure><figure><p><img src="https://cdn.prod.website-files.com/67ad3648c8025e1491009050/681120cb2227a41c208ed615_AD_4nXcaBaPhXPNafcN5IFN9V3zuKlvsVmQZldhODPwxabh9knidnxa189QXguy5ot0fb6m3xFdc2JDHc3QOI8WsF_nQuipkpNHfSr4A12v1k_0cQViGVTGAkD3uNX_JEfkawhBn_NIo.png" loading="lazy" alt=""></p></figure><figure><p><img src="https://cdn.prod.website-files.com/67ad3648c8025e1491009050/681121ba5e41b03f25a01c07_Screenshot%202025-04-29%20at%2011.59.54%E2%80%AFAM.png" loading="lazy" alt=""></p><figcaption>Failed attempts to recover uncertainty signals in GPT-4.1-mini</figcaption></figure><p>The net result is that we’ve lost our signal for hallucinations! All of these features rely on local entropy surviving RLHF, and we don’t have anywhere to look for these signals, requiring new heuristics for model upgrades to solve these failure cases, to re-introduce some uncertainty measures.</p><p>In response to this lost hallucination signal, we've implemented several alternative safeguards. These new methods, such as formally requiring policy explanations to be fully grounded in actual data/quotes, are powering new features in our product towards better explainability and policy iteration, but do show how there’s more to model upgrades than simply benchmark upgrades. </p><p>Our current approach relies on more explicit controls: <strong>requiring detailed explanations from the model for each policy violation</strong>, <strong>demanding specific policy citations to ground decisions</strong>, and <strong>implementing filtering systems to catch corrupted outputs when policies are hallucinated</strong>. </p><p>However, the closed-source nature of these models significantly limits our access to internal signals beyond log probabilities. As models continue to be further distilled for efficiency, even these limited signals are fading, creating a growing challenge for reliable uncertainty detection especially when working with closed-source models.</p><h3>Alignment isn't free</h3><p>In our situation, the improvements to steerability and performance upgrades of 4.1 were worth it for customers and our internal workarounds were sufficient to actually increase precision with our latest release. A model upgrade is not merely a drop-in performance bump; it is a distributional shift that can invalidate an entire AI stack. Anyone shipping high-precision systems should log raw logits, tie heuristics to specific model versions, and invest in alternative product safeguards. Alignment makes models safer for users but simultaneously masks their own uncertainty from engineers; the burden of re-exposing that uncertainty falls on us.</p><blockquote>1. *OpenAI GPT‑4 System Card*, § 6.2 “Calibration”: “We observe that RLHF improves helpfulness but can distort the model’s probability estimates; after alignment the model tends to be over‑confident on both correct and incorrect answers.</blockquote><p>‍</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[VVVVVV Source Code (399 pts)]]></title>
            <link>https://github.com/TerryCavanagh/VVVVVV</link>
            <guid>43910681</guid>
            <pubDate>Tue, 06 May 2025 23:22:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/TerryCavanagh/VVVVVV">https://github.com/TerryCavanagh/VVVVVV</a>, See on <a href="https://news.ycombinator.com/item?id=43910681">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/TerryCavanagh/VVVVVV/blob/master/logo.gif"><img src="https://github.com/TerryCavanagh/VVVVVV/raw/master/logo.gif" alt="logo" title="VVVVVV" data-animated-image=""></a></p>
<p dir="auto">This is the source code to VVVVVV, the 2010 indie game by <a href="http://distractionware.com/" rel="nofollow">Terry Cavanagh</a>, with music by <a href="http://souleye.madtracker.net/" rel="nofollow">Magnus Pålsson</a>. You can read the <a href="http://distractionware.com/blog/2020/01/vvvvvv-is-now-open-source/" rel="nofollow">announcement</a> of the source code release on Terry's blog!</p>
<p dir="auto">The source code for the desktop version is in <a href="https://github.com/TerryCavanagh/VVVVVV/blob/master/desktop_version">this folder</a>.</p>
<p dir="auto">VVVVVV is still commercially available at <a href="https://thelettervsixtim.es/" rel="nofollow">thelettervsixtim.es</a> if you'd like to support it, but you are completely free to compile the game for your own personal use. If you're interested in distributing a compiled version of the game, see <a href="https://github.com/TerryCavanagh/VVVVVV/blob/master/LICENSE.md">LICENSE.md</a> for more information.</p>
<p dir="auto">Discussion about VVVVVV updates mainly happens on the "unofficial" <a href="https://discord.gg/Zf7Nzea" rel="nofollow">VVVVVV discord</a>, in the <code>vvvvvv-code</code> channel.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Credits</h2><a id="user-content-credits" aria-label="Permalink: Credits" href="#credits"></a></p>
<ul dir="auto">
<li>Created by <a href="http://distractionware.com/" rel="nofollow">Terry Cavanagh</a></li>
<li>Room Names by <a href="http://www.foddy.net/" rel="nofollow">Bennett Foddy</a></li>
<li>Music by <a href="https://magnuspalsson.com/" rel="nofollow">Magnus Pålsson</a></li>
<li>Metal Soundtrack by <a href="https://link.space/@familyjules" rel="nofollow">FamilyJules</a></li>
<li>2.0 Update (C++ Port) by <a href="http://www.machinestudios.co.uk/" rel="nofollow">Simon Roth</a></li>
<li>2.2 Update (SDL2/PhysicsFS/Steamworks port) by <a href="http://www.flibitijibibo.com/" rel="nofollow">Ethan Lee</a></li>
<li>Additional coding by <a href="https://infoteddy.info/" rel="nofollow">Misa Kai</a></li>
<li>Beta Testing by Sam Kaplan and Pauli Kohberger</li>
<li>Ending Picture by Pauli Kohberger</li>
<li>Localisations by <a href="https://github.com/TerryCavanagh/VVVVVV/blob/master/desktop_version/TRANSLATORS.txt">our localisation teams</a></li>
<li>With additional contributions by <a href="https://github.com/TerryCavanagh/VVVVVV/blob/master/desktop_version/CONTRIBUTORS.txt">many others here on github</a> &lt;3</li>
</ul>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>