<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 21 May 2025 23:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[For algorithms, a little memory outweighs a lot of time (128 pts)]]></title>
            <link>https://www.quantamagazine.org/for-algorithms-a-little-memory-outweighs-a-lot-of-time-20250521/</link>
            <guid>44055347</guid>
            <pubDate>Wed, 21 May 2025 19:34:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/for-algorithms-a-little-memory-outweighs-a-lot-of-time-20250521/">https://www.quantamagazine.org/for-algorithms-a-little-memory-outweighs-a-lot-of-time-20250521/</a>, See on <a href="https://news.ycombinator.com/item?id=44055347">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="postBody">
                <div>
        <p>
            One computer scientist’s “stunning” proof is the first progress in 50 years on one of the most famous questions in computer science.        </p>
        
    </div>
<figure>
    
</figure>
    <figure>
        <div>
                            <p><img width="2560" height="1440" src="https://www.quantamagazine.org/wp-content/uploads/2025/05/Space-Complexity-Breakthrough_crIrene-Perez-Lede.webp" alt="" decoding="async" fetchpriority="high" srcset="https://www.quantamagazine.org/wp-content/uploads/2025/05/Space-Complexity-Breakthrough_crIrene-Perez-Lede.webp 2560w, https://www.quantamagazine.org/wp-content/uploads/2025/05/Space-Complexity-Breakthrough_crIrene-Perez-Lede-1720x968.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2025/05/Space-Complexity-Breakthrough_crIrene-Perez-Lede-520x293.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2025/05/Space-Complexity-Breakthrough_crIrene-Perez-Lede-768x432.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2025/05/Space-Complexity-Breakthrough_crIrene-Perez-Lede-1536x864.webp 1536w, https://www.quantamagazine.org/wp-content/uploads/2025/05/Space-Complexity-Breakthrough_crIrene-Perez-Lede-2048x1152.webp 2048w" sizes="(max-width: 2560px) 100vw, 2560px">                </p>
                        </div>
        <figcaption>
    <div>
            <p>Irene Pérez for&nbsp;<em>Quanta Magazine</em></p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p><span>O</span>ne July afternoon in 2024, <a href="https://people.csail.mit.edu/rrw/">Ryan Williams</a> set out to prove himself wrong. Two months had passed since he’d hit upon a startling discovery about the relationship between time and memory in computing. It was a rough sketch of a mathematical proof that memory was more powerful than computer scientists believed: A small amount would be as helpful as a lot of time in all conceivable computations. That sounded so improbable that he assumed something had to be wrong, and he promptly set the proof aside to focus on less crazy ideas. Now, he’d finally carved out time to find the error.</p>
<p>That’s not what happened. After hours of poring over his argument, Williams couldn’t find a single flaw.</p>
<p>“I just thought I was losing my mind,” said Williams, a theoretical computer scientist at the Massachusetts Institute of Technology. For the first time, he began to entertain the possibility that maybe, just maybe, memory really was as powerful as his work suggested.</p>
<p>Over the months that followed, he fleshed out the details, scrutinized every step, and solicited feedback from a handful of other researchers. In February, he finally <a href="https://arxiv.org/abs/2502.17779">posted his proof online</a>, to widespread acclaim.</p>
<p>“It’s amazing. It’s beautiful,” said <a href="https://www.math.ias.edu/avi/home">Avi Wigderson</a>, a theoretical computer scientist at the Institute for Advanced Study in Princeton, New Jersey. As soon as he heard the news, Wigderson sent Williams a congratulatory email. Its subject line: “You blew my mind.”</p>
<p>Time and memory (also called space) are the two most fundamental resources in computation: Every algorithm takes some time to run, and requires some space to store data while it’s running. Until now, the only known algorithms for accomplishing certain tasks required an amount of space roughly proportional to their runtime, and researchers had long assumed there’s no way to do better. Williams’ proof established a mathematical procedure for transforming any algorithm — no matter what it does — into a form that uses much less space.</p>
</div>
    <figure>
        <div>
                            <p><img width="2301" height="1577" src="https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-CloseUp.webp" alt="" decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-CloseUp.webp 2301w, https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-CloseUp-1720x1179.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-CloseUp-520x356.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-CloseUp-768x526.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-CloseUp-1536x1053.webp 1536w, https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-CloseUp-2048x1404.webp 2048w" sizes="(max-width: 2301px) 100vw, 2301px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>Ryan Williams stunned his colleagues with a milestone proof about the relationship between time and space in computation.</p>
            <p>Katherine Taylor for&nbsp;<em>Quanta Magazine</em></p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>What’s more, this result — a statement about what you can compute given a certain amount of space — also implies a second result, about what you cannot compute in a certain amount of time. This second result isn’t surprising in itself: Researchers expected it to be true, but they had no idea how to prove it. Williams’ solution, based on his sweeping first result, feels almost cartoonishly excessive, akin to proving a suspected murderer guilty by establishing an ironclad alibi for everyone else on the planet. It could also offer a new way to attack one of the oldest open problems in computer science.</p>
<p>“It’s a pretty stunning result, and a massive advance,” said <a href="https://www.cs.washington.edu/people/faculty/paul-beame/">Paul Beame</a>, a computer scientist at the University of Washington. “It’s a little bit less of a surprise that it’s Ryan doing this.”</p>
<h2><strong>Space to Roam</strong></h2>
<p>Williams, 46, has an open, expressive face and a hint of gray in his hair. His office, which looks out over the colorful spires of MIT’s Stata Center, is another illustration of the creative use of space. A pair of yoga mats have transformed a window ledge into a makeshift reading nook, and the desk is tucked into an oddly shaped corner, freeing up room for a couch facing a large whiteboard brimming with mathematical scribblings.</p>
<p>MIT is a long way from Williams’ childhood home in rural Alabama, where there was no shortage of space. He grew up on a 50-acre farm and first saw a computer at age 7, when his mother drove him across the county for a special academic enrichment class. He recalled being transfixed by a simple program for generating a digital fireworks display.</p>
<p>“It was taking a random color and sending it in a random direction from the middle of the monitor,” Williams said. “You couldn’t have predicted what picture you’re going to get.” The world of computers seemed a wild and wonderful playground, full of infinite possibilities. Young Williams was hooked.</p>
<p>“I was writing programs to myself, on paper, to be run on a future computer,” he said. “My parents didn’t really know what to do with me.”</p>
</div>
    <figure>
        <div>
                            <p><img width="1799" height="2560" src="https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-Window-scaled.webp" alt="" decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-Window-scaled.webp 1799w, https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-Window-1209x1720.webp 1209w, https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-Window-365x520.webp 365w, https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-Window-768x1093.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-Window-1079x1536.webp 1079w, https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-Window-1439x2048.webp 1439w" sizes="(max-width: 1799px) 100vw, 1799px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>Williams’ office, like his new result, makes creative use of space.</p>
            <p>Katherine Taylor for&nbsp;<em>Quanta Magazine</em></p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>As he grew older, Williams advanced from imaginary computers to real ones. For his last two years of high school, he transferred to the Alabama School of Math and Science, a prestigious public boarding school, where he first encountered the theoretical side of computer science.</p>
<p>“I realized that there was a wider world of things out there, and that there was a way to think mathematically about computers,” he said. “That’s what I wanted to do.”</p>
<p>Williams was especially drawn to a branch of theoretical computer science called computational complexity theory. It deals with the resources (such as time and space) that are needed to solve computational problems such as sorting lists or factoring numbers. Most problems can be solved by many different algorithms, each with its own demands on time and space. Complexity theorists sort problems into categories, called complexity classes, based on the resource demands of the best algorithms for solving them — that is, the algorithms that run fastest or use the least amount of space.</p>
<p>But how do you make the study of computational resources mathematically rigorous? You won’t get far if you try to analyze time and space by comparing minutes to megabytes. To make any progress, you need to start with the right definitions.</p>
<h2><strong>Getting Resourceful</strong></h2>

<p>Those definitions emerged from the work of Juris Hartmanis, a pioneering computer scientist who had experience making do with limited resources. He was born in 1928 into a prominent Latvian family, but his childhood was disrupted by the outbreak of World War II. Occupying Soviet forces arrested and executed his father, and after the war Hartmanis finished high school in a refugee camp. He went on to university, where he excelled even though he couldn’t afford textbooks.</p>
<p>“I compensated by taking very detailed notes in lectures,” he recalled in a <a href="https://dl.acm.org/doi/10.1145/1141880.1775727">2009 interview</a>. “There is a certain advantage to [having] to improvise and overcome difficulties.” Hartmanis immigrated to the United States in 1949, and worked a series of odd jobs — building agricultural machinery, manufacturing steel and even serving as a butler — while studying mathematics at the University of Kansas City. He went on to a spectacularly successful career in the young field of theoretical computer science.</p>
<p>In 1960, while working at the General Electric research laboratory in Schenectady, New York, Hartmanis met Richard Stearns, a graduate student doing a summer internship. In a pair of <a href="https://www.ams.org/journals/tran/1965-117-00/S0002-9947-1965-0170805-7/">groundbreaking</a> <a href="https://ieeexplore.ieee.org/document/5397244/">papers</a> they established precise mathematical definitions for time and space. These definitions gave researchers the language they needed to compare the two resources and sort problems into complexity classes.</p>
</div>
    <figure>
        <div>
                            <p><img width="1800" height="1033" src="https://www.quantamagazine.org/wp-content/uploads/2025/05/Juris-Hartmanis.webp" alt="" decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2025/05/Juris-Hartmanis.webp 1800w, https://www.quantamagazine.org/wp-content/uploads/2025/05/Juris-Hartmanis-1720x987.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2025/05/Juris-Hartmanis-520x298.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2025/05/Juris-Hartmanis-768x441.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2025/05/Juris-Hartmanis-1536x881.webp 1536w" sizes="(max-width: 1800px) 100vw, 1800px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>In the 1960s, Juris Hartmanis established the definitions that computer scientists use to analyze space and time.</p>
            <p>Division of Rare and Manuscript Collections, Cornell University Library</p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>One of the most important classes goes by the humble name “P.” Roughly speaking, it encompasses all problems that can be solved in a reasonable amount of time. An analogous complexity class for space is dubbed “PSPACE.”</p>
<p>The relationship between these two classes is one of the central questions of complexity theory. Every problem in P is also in PSPACE, because fast algorithms just don’t have enough time to fill up much space in a computer’s memory. If the reverse statement were also true, the two classes would be equivalent: Space and time would have comparable computational power. But complexity theorists suspect that PSPACE is a much larger class, containing many problems that aren’t in P. In other words, they believe that space is a far more powerful computational resource than time. This belief stems from the fact that algorithms can use the same small chunk of memory over and over, while time isn’t as forgiving — once it passes, you can’t get it back.</p>
<p>“The intuition is just so simple,” Williams said. “You can reuse space, but you can’t reuse time.”</p>
<p>But intuition isn’t good enough for complexity theorists: They want rigorous proof. To prove that PSPACE is larger than P, researchers would have to show that for some problems in PSPACE, fast algorithms are categorically impossible. Where would they even start?</p>
<h2><strong>A Space Odyssey</strong></h2>
<p>As it happened, they started at Cornell University, where Hartmanis moved in 1965 to head the newly established computer science department. Under his leadership it quickly became a center of research in complexity theory, and in the early 1970s, a pair of researchers there, John Hopcroft and Wolfgang Paul, set out to establish a precise link between time and space.</p>

<p>Hopcroft and Paul knew that to resolve the P versus PSPACE problem, they’d have to prove that you can’t do certain computations in a limited amount of time. But it’s hard to prove a negative. Instead, they decided to flip the problem on its head and explore what you can do with limited space. They hoped to prove that algorithms given a certain space budget can solve all the same problems as algorithms with a slightly larger time budget. That would indicate that space is at least slightly more powerful than time — a small but necessary step toward showing that PSPACE is larger than P.</p>
<p>With that goal in mind, they turned to a method that complexity theorists call simulation, which involves transforming existing algorithms into new ones that solve the same problems, but with different amounts of space and time. To understand the basic idea, imagine you’re given a fast algorithm for alphabetizing your bookshelf, but it requires you to lay out your books in dozens of small piles. You might prefer an approach that takes up less space in your apartment, even if it takes longer. A simulation is a mathematical procedure you could use to get a more suitable algorithm: Feed it the original, and it’ll give you a new algorithm that saves space at the expense of time.</p>
<p>Algorithm designers have long studied these space-time trade-offs for specific tasks like sorting. But to establish a general relationship between time and space, Hopcroft and Paul needed something more comprehensive: a space-saving simulation procedure that works for every algorithm, no matter what problem it solves. They expected this generality to come at a cost. A universal simulation can’t exploit the details of any specific problem, so it probably won’t save as much space as a specialized simulation. But when Hopcroft and Paul started their work, there were no known universal methods for saving space at all. Even saving a small amount would be progress.</p>
<p>The breakthrough came in 1975, after Hopcroft and Paul teamed up with a young researcher named <a href="https://people.seas.harvard.edu/~valiant/">Leslie Valiant</a>. The trio devised a <a href="https://dl.acm.org/doi/10.1145/322003.322015">universal simulation procedure</a> that always saves a bit of space. No matter what algorithm you give it, you’ll get an equivalent one whose space budget is slightly smaller than the original algorithm’s time budget.</p>
<p>“Anything you can do in so much time, you can also do in slightly less space,” Valiant said. It was the first major step in the quest to connect space and time.</p>
<figure>
    <p><img width="1600" height="1556" src="https://www.quantamagazine.org/wp-content/uploads/2025/05/Leslie-Valiant_cr-Katherine-Taylor.webp" alt="" decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2025/05/Leslie-Valiant_cr-Katherine-Taylor.webp 1600w, https://www.quantamagazine.org/wp-content/uploads/2025/05/Leslie-Valiant_cr-Katherine-Taylor-520x506.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2025/05/Leslie-Valiant_cr-Katherine-Taylor-768x747.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2025/05/Leslie-Valiant_cr-Katherine-Taylor-1536x1494.webp 1536w" sizes="(max-width: 1600px) 100vw, 1600px">    </p>
            <figcaption>
                            <p>In 1975, Leslie Valiant helped prove that space is a slightly more powerful computational resource than time.</p>
            <p>Katherine Taylor for&nbsp;<em>Quanta Magazine</em></p>
        </figcaption>
    </figure>

<p>But then progress stalled, and complexity theorists began to suspect that they’d hit a fundamental barrier. The problem was precisely the universal character of Hopcroft, Paul and Valiant’s simulation. While many problems can be solved with much less space than time, some intuitively seemed like they’d need nearly as much space as time. If so, more space-efficient universal simulations would be impossible. Paul and two other researchers soon proved that they are <a href="https://dl.acm.org/doi/10.1145/800113.803643">indeed impossible</a>, provided you make one seemingly obvious assumption: Different chunks of data can’t occupy the same space in memory at the same time.</p>
<p>“Everybody took it for granted that you cannot do better,” Wigderson said.</p>
<p>Paul’s result suggested that resolving the P versus PSPACE problem would require abandoning simulation altogether in favor of a different approach, but nobody had any good ideas. That was where the problem stood for 50 years — until Williams finally broke the logjam.</p>
<p>First, he had to get through college.</p>
<h2><strong>Complexity Classes</strong></h2>
<p>In 1996, the time came for Williams to apply to colleges. He knew that pursuing complexity theory would take him far from home, but his parents made it clear that the West Coast and Canada were out of the question. Among his remaining options, Cornell stood out to him for its prominent place in the history of his favorite discipline.</p>
<p>“This guy Hartmanis defined the time and space complexity classes,” he recalled thinking. “That was important for me.”</p>
<p>Williams was admitted to Cornell with generous financial aid and arrived in the fall of 1997, planning to do whatever it took to become a complexity theorist himself. His single-mindedness stuck out to his fellow students.</p>
<p>“He was just super-duper into complexity theory,” said <a href="https://www.cs.utexas.edu/people/faculty-researchers/scott-aaronson">Scott Aaronson</a>, a computer scientist at the University of Texas, Austin, who overlapped with Williams at Cornell.</p>
</div>
    <figure>
        <div>
                            <p><img width="2560" height="1398" src="https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-YellowWall-scaled.webp" alt="" decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-YellowWall-scaled.webp 2560w, https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-YellowWall-1720x939.webp 1720w, https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-YellowWall-520x284.webp 520w, https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-YellowWall-768x419.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-YellowWall-1536x839.webp 1536w, https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-YellowWall-2048x1118.webp 2048w" sizes="(max-width: 2560px) 100vw, 2560px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>Williams grew interested in the relationship between space and time as an undergraduate, but never found an opportunity to work on it until last year.</p>
            <p>Katherine Taylor for&nbsp;<em>Quanta Magazine</em></p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>But by sophomore year, Williams was struggling to keep up in courses that emphasized mathematical rigor over intuition. After he got a middling grade in a class on the theory of computing, the teacher suggested he consider other careers. But Williams wouldn’t give up his dream. He doubled down and enrolled in a graduate theory course, hoping that a stellar grade in the harder class would look impressive on his grad school applications. The professor teaching that graduate course was Hartmanis, by then an elder statesman in the field.</p>
<p>Williams began attending Hartmanis’ office hours every week, where he was almost always the only student who showed up. His tenacity paid off: he earned an A in the course, and Hartmanis agreed to advise him on an independent research project the following semester. Their weekly meetings continued throughout Williams’ time in college. Hartmanis encouraged him to cultivate an individual approach to complexity research and gently steered him away from dead ends.</p>
<p>“I was deeply influenced by him then,” Williams said. “I guess I still am now.”</p>

<p>But despite earning a coveted graduate research fellowship from the National Science Foundation, Williams was rejected by every doctoral program he applied to. On hearing the news, Hartmanis phoned a colleague, then turned around and congratulated Williams on getting accepted into a yearlong master’s program at Cornell. A year later Williams again applied to various doctoral programs, and with that extra research experience under his belt, he found success.</p>
<p>Williams continued working in complexity theory in grad school and the years that followed. In 2010, four years after receiving his doctorate, he proved a <a href="https://ieeexplore.ieee.org/document/5959801">milestone result</a> — a small step, but the largest in decades, toward solving the <a href="https://www.quantamagazine.org/complexity-theorys-50-year-journey-to-the-limits-of-knowledge-20230817/">most famous question in theoretical computer science</a>, about the nature of hard problems. That result cemented Williams’ reputation, and he went on to write dozens of other papers on different topics in complexity theory.</p>
<p>P versus PSPACE wasn’t one of them. Williams had been fascinated by the problem since he first encountered it in college. He’d even supplemented his computer science curriculum with courses in logic and philosophy, seeking inspiration from other perspectives on time and space, to no avail.</p>
<p>“It’s always been in the back of my mind,” Williams said. “I just couldn’t think of anything interesting enough to say about it.”</p>
<p>Last year, he finally found the opportunity he’d been waiting for.</p>
<h2><strong>Squishy Pebbles</strong></h2>
<p>The story of Williams’ new result started with progress on a different question about memory in computation: What problems can be solved with extremely limited space? In 2010, the pioneering complexity theorist Stephen Cook and his collaborators invented a task, called the <a href="http://arxiv.org/abs/1005.2642">tree evaluation problem</a>, that they proved would be impossible for any algorithm with a space budget below a specific threshold. But there was a loophole. The proof relied on the same commonsense assumption that Paul and his colleagues had made decades earlier: Algorithms can’t store new data in space that’s already full.</p>
<p>For over a decade, complexity theorists tried to close that loophole. Then, in 2023, <a href="https://www.falsifian.org/">Cook’s son James</a> and a researcher named <a href="https://iuuk.mff.cuni.cz/~iwmertz/">Ian Mertz</a> blew it wide open, devising <a href="https://dl.acm.org/doi/10.1145/3618260.3649664">an algorithm</a> that solved the tree evaluation problem using <a href="https://www.quantamagazine.org/catalytic-computing-taps-the-full-power-of-a-full-hard-drive-20250218/">much less space</a> than anyone thought possible. The elder Cook’s proof had assumed that bits of data were like pebbles that have to occupy separate places in an algorithm’s memory. But it turns out that’s not the only way to store data. “We can actually think about these pebbles as things that we can squish a little bit on top of each other,” Beame said.</p>
</div>
    <figure>
        <div>
                            <p><img width="2101" height="2379" src="https://www.quantamagazine.org/wp-content/uploads/2025/05/JamesCook_crColinMoris-36.webp" alt="" decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2025/05/JamesCook_crColinMoris-36.webp 2101w, https://www.quantamagazine.org/wp-content/uploads/2025/05/JamesCook_crColinMoris-36-1519x1720.webp 1519w, https://www.quantamagazine.org/wp-content/uploads/2025/05/JamesCook_crColinMoris-36-459x520.webp 459w, https://www.quantamagazine.org/wp-content/uploads/2025/05/JamesCook_crColinMoris-36-768x870.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2025/05/JamesCook_crColinMoris-36-1357x1536.webp 1357w, https://www.quantamagazine.org/wp-content/uploads/2025/05/JamesCook_crColinMoris-36-1809x2048.webp 1809w" sizes="(max-width: 2101px) 100vw, 2101px">                </p>
                                <p><img width="1716" height="1817" src="https://www.quantamagazine.org/wp-content/uploads/2025/05/IanMertz_crMichalKoucky.webp" alt="" decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2025/05/IanMertz_crMichalKoucky.webp 1716w, https://www.quantamagazine.org/wp-content/uploads/2025/05/IanMertz_crMichalKoucky-1624x1720.webp 1624w, https://www.quantamagazine.org/wp-content/uploads/2025/05/IanMertz_crMichalKoucky-491x520.webp 491w, https://www.quantamagazine.org/wp-content/uploads/2025/05/IanMertz_crMichalKoucky-768x813.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2025/05/IanMertz_crMichalKoucky-1451x1536.webp 1451w" sizes="(max-width: 1716px) 100vw, 1716px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>James Cook (left) and Ian Mertz recently devised a new algorithm that solved a specific problem using much less space than anyone thought possible.</p>
            <p>Colin Morris; Michal Koucký</p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>Cook and Mertz’s algorithm roused the curiosity of many researchers, but it wasn’t clear that it had any applications beyond the tree evaluation problem. “Nobody saw how central it is to time versus space itself,” Wigderson said.</p>
<p>Ryan Williams was the exception. In spring 2024, a group of students gave a presentation about the Cook and Mertz paper as their final project in a class he was teaching. Their enthusiasm inspired him to take a closer look. As soon as he did, an idea jumped out at him. Cook and Mertz’s method, he realized, was really a general-purpose tool for reducing space usage. Why not use it to power a new universal simulation linking time and space — like the one designed by Hopcroft, Paul and Valiant, but better?</p>
<p>That classic result was a way to transform any algorithm with a given time budget into a new algorithm with a slightly smaller space budget. Williams saw that a simulation based on squishy pebbles would make the new algorithm’s space usage much smaller — roughly equal to the square root of the original algorithm’s time budget. That new space-efficient algorithm would also be much slower, so the simulation was not likely to have practical applications. But from a theoretical point of view, it was nothing short of revolutionary.</p>

<p>For 50 years, researchers had assumed it was impossible to improve Hopcroft, Paul and Valiant’s universal simulation. Williams’ idea — if it worked — wouldn’t just beat their record — it would demolish it.</p>
<p>“I thought about it, and I was like, ‘Well, that just simply can’t be true,’” Williams said. He set it aside and didn’t come back to it until that fateful day in July, when he tried to find the flaw in the argument and failed. After he realized that there was no flaw, he spent months writing and rewriting the proof to make it as clear as possible.</p>
<p>At the end of February, Williams finally <a href="https://arxiv.org/abs/2502.17779">put the finished paper online</a>. Cook and Mertz were as surprised as everyone else. “I had to go take a long walk before doing anything else,” Mertz said.</p>
<p>Valiant got a sneak preview of Williams’ improvement on his decades-old result during his morning commute. For years, he’s taught at Harvard University, just down the road from Williams’ office at MIT. They’d met before, but they didn’t know they lived in the same neighborhood until they bumped into each other on the bus on a snowy February day, a few weeks before the result was public. Williams described his proof to the startled Valiant and promised to send along his paper.</p>
<p>“I was very, very impressed,” Valiant said. “If you get any mathematical result which is the best thing in 50 years, you must be doing something right.”</p>
<h2><strong>PSPACE: The Final Frontier</strong></h2>
<p>With his new simulation, Williams had proved a positive result about the computational power of space: Algorithms that use relatively little space can solve all problems that require a somewhat larger amount of time. Then, using just a few lines of math, he flipped that around and proved a negative result about the computational power of time: At least a few problems can’t be solved unless you use more time than space. That second, narrower result is in line with what researchers expected. The weird part is how Williams got there, by first proving a result that applies to all algorithms, no matter what problems they solve.</p>
<p>“I still have a hard time believing it,” Williams said. “It just seems too good to be true.”</p>
</div>
    <figure>
        <div>
                            <p><img width="1967" height="2560" src="https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-Stairs-scaled.webp" alt="" decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-Stairs-scaled.webp 1967w, https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-Stairs-1322x1720.webp 1322w, https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-Stairs-400x520.webp 400w, https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-Stairs-768x999.webp 768w, https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-Stairs-1180x1536.webp 1180w, https://www.quantamagazine.org/wp-content/uploads/2025/05/RyanWilliams-cr.KatherineTaylor-Stairs-1574x2048.webp 1574w" sizes="(max-width: 1967px) 100vw, 1967px">                </p>
                        </div>
        <figcaption>
    <div>
                            <p>Williams used Cook and Mertz’s technique to establish a stronger link between space and time — the first progress on that problem in 50 years.</p>
            <p>Katherine Taylor for&nbsp;<em>Quanta Magazine</em></p>
        </div>
</figcaption>
    </figure>
<div data-role="selectable">
    <p>Phrased in qualitative terms, Williams’ second result may sound like the long-sought solution to the P versus PSPACE problem. The difference is a matter of scale. P and PSPACE are very broad complexity classes, while Williams’ results work at a finer level. He established a quantitative gap between the power of space and the power of time, and to prove that PSPACE is larger than P, researchers will have to make that gap much, much wider.</p>
<p>That’s a daunting challenge, akin to prying apart a sidewalk crack with a crowbar until it’s as wide as the Grand Canyon. But it might be possible to get there by using a modified version of Williams’ simulation procedure that repeats the key step many times, saving a bit of space each time. It’s like a way to repeatedly ratchet up the length of your crowbar — make it big enough, and you can pry open anything. That repeated improvement doesn’t work with the current version of the algorithm, but researchers don’t know whether that’s a fundamental limitation.</p>
        
        
<p>“It could be an ultimate bottleneck, or it could be a 50-year bottleneck,” Valiant said. “Or it could be something which maybe someone can solve next week.”</p>
<p>If the problem is solved next week, Williams will be kicking himself. Before he wrote the paper, he spent months trying and failing to extend his result. But even if such an extension is not possible, Williams is confident that more space exploration is bound to lead somewhere interesting — perhaps progress on an entirely different problem.</p>
<p>“I can never prove precisely the things that I want to prove,” he said. “But often, the thing I prove is way better than what I wanted.”</p>
<p><em>Editor’s note: Scott Aaronson is a member of&nbsp;</em>Quanta Magazine<em>’s&nbsp;</em><a href="https://www.quantamagazine.org/about/"><em>advisory board</em></a><em>.</em></p>
</div>
                
                
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LLM function calls don't scale; code orchestration is simpler, more effective (136 pts)]]></title>
            <link>https://jngiam.bearblog.dev/mcp-large-data/</link>
            <guid>44053744</guid>
            <pubDate>Wed, 21 May 2025 17:18:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jngiam.bearblog.dev/mcp-large-data/">https://jngiam.bearblog.dev/mcp-large-data/</a>, See on <a href="https://news.ycombinator.com/item?id=44053744">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    

    
        
    

    
        

        <p>
            <i>
                <time datetime="2025-05-20T15:25Z">
                    20 May, 2025
                </time>
            </i>
        </p>
    

    <p><em>TL;DR: Giving LLMs the full output of tool calls is costly and slow. Output schemas will enable us to get structured data, so we can let the LLM orchestrate processing with generated code. Tool calling in code is simplifying and effective.</em></p>
<hr>
<p>One common practice for working with MCP tools calls is to put the outputs from a tool back into the LLM as a message, and ask the LLM for the next step. The hope here is that the model figures out how to interpret the data, and identify the correct next action to take.</p>
<p>This can work beautifully when the amount of data is small, but we found that when we tried MCP servers with real-world data, it quickly breaks down.</p>
<h3 id="mcp-in-the-real-world">MCP in the real-world</h3><p>We use Linear and Intercom at our company. We connected to their latest official MCP servers released last week to understand how they were returning tool calls.</p>
<p>It turns out that both servers returned large JSON blobs in their text content. These appeared to be similar to their APIs, with the exception that the text content did not come with any pre-defined schemas. This meant that the only reasonable way to parse them was to have the LLM interpret the data.</p>
<p><img src="https://storage.googleapis.com/lutra-2407-public/42067e56d7b5238d3d7432718f1224679a1a449711a2e406295a3aeb98108e63.png" alt="Linear MCP returns list of issues as a big JSON blob"></p>
<p>These JSON blobs are huge! When we asked Linear's MCP to list issues in our project, the tool call defaulted to returning only 50 issues, ~70k characters corresponding to ~25k tokens.</p>
<p><img src="https://storage.googleapis.com/lutra-2407-public/dda9436e83214ae28c73b19ca4fdc43d81f5c1613a45ada3160dc4aaa048f07d.png" alt="ID fields become lots of tokens"></p>
<p>The JSON contains lots of <code>id</code> fields that take up many tokens, and are not semantically meaningful.</p>
<p>When using Claude with MCPs, it seems that the entire JSON blob gets sent back to the model verbatim.</p>
<p>This approach quickly runs into issues. For example, if we wanted to get the AI to sort all the issues by due date and display them, it would need to reproduce all the issues verbatim as output tokens! It'd be slow, costly, and could potentially miss data.</p>
<p>The data in our issues also often contained a lot of distracting information: steps to reproduce an issue, errors, maybe even prompts a user used, or instructions to follow up with a user. The model could fail to emit some of these data accurately, or even worse, deviate from the original instructions.</p>
<h3 id="data-vs-orchestration">Data vs Orchestration</h3><p>The core problem here is that we're confounding orchestration and data processing together in the same chat thread.</p>
<p>The "multi-agent" approach tries to address this by spinning up another chat thread ("agent") to focus only on the data processing piece. It performs better when carefully tuned, but it's still awkward when our data is already well structured.</p>
<p>If the MCP servers are already returning data in a JSON format, it seems much more natural to parse the data, and instead operate on the structured data. Back to our sorting example, rather than asking the LLM to reproduce the outputs directly, we could instead run a <code>sort</code> operation on the data, and return the new array. No hallucinations and this scales to any size of inputs.</p>
<h3 id="code-execution-as-data-processing">Code execution as data processing</h3><p>This sounds oddly familiar as we already have code interpreters with AI. When we start to bring code execution as a fundamental way to process data from MCP tools (<a href="https://machinelearning.apple.com/research/codeact">Code Act</a>, <a href="https://huggingface.co/blog/smolagents">Smol Agents</a>), this opens the door to scalable ways for AI models to work.</p>
<p><strong>Variables as memory.</strong> Instead of having an external memory system, the LLM can use variables (system memory) to store any data. Storing a memory is assigning a value to a variable, peeking at the variable is printing it, and the model can choose to pass the variable as an argument when calling another function. Even better, if the language used is well-typed, the model also leverages the schema.</p>
<p><strong>Tool chaining.</strong> Code can orchestrate multiple function calls: performing them in parallel or taking the outputs from one or more calls and using them as inputs into another. The dependencies between the function calls are implicitly represented via the computation graph the code represents. Importantly, the LLM is not required to regurgitate the data, and we have guarantees of completeness.</p>
<p><strong>Scalable processing.</strong> Transforming large amounts of data is naturally possible with code. The model can choose to use loops, or lean on libraries such as NumPy or pandas for large data transformations.</p>
<p>Code can also call other LLMs under the hood: you can have the LLM write code that calls LLMs for unstructured data processing (LLM-inception).</p>
<h3 id="is-mcp-ready">Is MCP ready?</h3><p>MCP specs already define input schemas, and they’ve just introduced  <a href="https://github.com/modelcontextprotocol/modelcontextprotocol/pull/371">output schemas</a>.</p>
<p>Once output schemas are widespread, we expect them to unlock use cases on large datasets: building custom dashboards, creating weekly reports on tickets completed, or having the autonomous agents monitor and nudge stalled issues forward.</p>
<h3 id="what-makes-code-execution-hard">What makes code execution hard?</h3><p>The challenge now shifts to the MCP client side. Most execution environments today run in a tightly controlled sandbox; security is paramount as we're dealing with user-/AI-generated code.</p>
<p>Allowing an execution environment to also access MCPs, tools, and user data requires careful design to where API keys are stored, and how tools are exposed.</p>
<p>In our designs, we created sandboxed environments that are keyed with specific API access, the models are provided with documentation on how to call these APIs such that they are able send/retrieve information without ever seeing secrets.</p>
<p>Most execution environments are stateful (e.g., they may rely on running Jupyter kernels for each user session). This is hard to manage and expensive if users expect to be able to come back to AI task sessions later. A stateless-but-persistent execution environment is paramount for long running (multi-day) task sessions.</p>
<p>These constraints are creating what we think is a new category of runtimes - "AI runtimes" that use LLMs to orchestrate and perform tasks. We're still in the early phases of working out all the details for this code-execution approach, and we'd love feedback from anyone tackling similar problems. If you're interested in our approach, you can head to <a href="https://lutra.ai/">Lutra</a> to give it a try.</p>


    

    
        

        
            


        
    


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Storefront Web Components (112 pts)]]></title>
            <link>https://shopify.dev/docs/api/storefront-web-components</link>
            <guid>44053603</guid>
            <pubDate>Wed, 21 May 2025 17:08:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shopify.dev/docs/api/storefront-web-components">https://shopify.dev/docs/api/storefront-web-components</a>, See on <a href="https://news.ycombinator.com/item?id=44053603">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Collaborative Text Editing Without CRDTs or OT (165 pts)]]></title>
            <link>https://mattweidner.com/2025/05/21/text-without-crdts.html</link>
            <guid>44053560</guid>
            <pubDate>Wed, 21 May 2025 17:05:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mattweidner.com/2025/05/21/text-without-crdts.html">https://mattweidner.com/2025/05/21/text-without-crdts.html</a>, See on <a href="https://news.ycombinator.com/item?id=44053560">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    

    <p><i>
    Matthew Weidner |
    
    May 21st, 2025
    
    <br>
    <a href="https://mattweidner.com/">Home</a> | <a href="https://mattweidner.com/feed.xml">RSS Feed</a>
    <br>
    Keywords: text editing, server reconciliation, Articulated
    </i></p>

    <p>Collaborative text editing is arguably the hardest feature to implement in a collaborative app. Even if you use a central server and a fully general solution to optimistic local updates (<a href="https://mattweidner.com/2024/06/04/server-architectures.html#1-server-reconciliation">server reconciliation</a>), text editing in particular requires fancy algorithms - specifically, the <a href="https://mattweidner.com/2024/06/04/server-architectures.html#challenge-text-and-lists">core of a text-editing CRDT or OT</a>.</p>

<p>Or rather, that’s what I thought until recently. This blog post describes an alternative, straightforward approach to collaborative text editing, without Conflict-free Replicated Data Types (CRDTs) or Operational Transformation (OT). By making text editing flexible and easy to DIY, I hope that the approach will let you create rich collaborative apps that are challenging to build on top of a black-box CRDT/OT library.</p>

<p>This post builds off of my previous post, <a href="https://mattweidner.com/2024/06/04/server-architectures.html">Architectures for Central Server Collaboration</a>, though I’ll recap ideas as needed to keep it self-contained. In particular, I’ll generally assume that your collaborative app has a central server. A <a href="#decentralized-variants">later section</a> extends the approach to decentralized/server-optional collaboration, revealing surprising links to several text-editing CRDTs.</p>

<p>As usual for collaborative text editing, any technique in this post can also be applied to general collaborative lists: ingredients in a recipe, a powerpoint filmstrip, spreadsheet rows and columns, etc.</p>

<p><strong>Sources:</strong> I learned the main idea of this approach from a <a href="https://news.ycombinator.com/item?id=41100477">Hacker News comment</a> by <a href="https://x.com/wcools/">Wim Cools</a> from Thymer. It is also used by <a href="https://jazz.tools/docs/react/using-covalues/colists">Jazz’s CoLists</a>. I do not know of an existing public description of the approach - in particular, I have not found it in any paper on <a href="https://crdt.tech/papers.html">crdt.tech</a> - but given its simplicity, others have likely used the approach as well.
The extension to decentralized collaboration is based on <a href="https://arxiv.org/abs/1805.04263">OpSets: Sequential Specifications for Replicated Datatypes</a> by Martin Kleppmann, Victor B. F. Gomes, Dominic P. Mulligan, and Alastair R. Beresford (2018).</p>

<ul id="toc"></ul>
<!-- Filled in by script at end. -->

<h2 id="core-problem">Core Problem</h2>

<p><em>Recap of <a href="https://mattweidner.com/2024/06/04/server-architectures.html#challenge-text-and-lists">Architectures for Central Server Collaboration - Challenge: Text and Lists</a></em></p>

<p>Let’s start by focusing on one part of the collaborative text editing problem: submitting operations to the server. When a user types a word on their client device, we need to communicate this operation to the server, so that the server can update its own (authoritative) state.</p>

<p>It’s tempting to model the text as an array of characters and send operations to the server that operate on the array representation, like “insert ‘ the’ at index 17”. However, this fails when there are multiple concurrent editors, as shown in Figure 1:</p>

<p><a id="figure-1"></a>
<img src="https://mattweidner.com/assets/img/server-architectures/index_rebasing.png" alt="See caption"></p>
<p><i><b>Figure 1.</b> Bob submits the operation "insert ‘ the’ at index 17" to the central server. But before his edit arrives, the server applies Alice's concurrent operation "insert ‘ gray’ at index 3". So it no longer makes sense to apply Bob's operation at index 17; the server must "rebase" it to index 22.</i></p>

<p>The core problem we must solve is: <strong>What operations should clients send to the server, and how should the server interpret them, so that the server updates its own text in the “obvious” correct way?</strong></p>

<blockquote>
  <p>This “index rebasing” challenge is best known for real-time collaborative apps like Google Docs, but technically, it can also affect non-real-time apps—e.g., a web form that inserts items into a list. The problem can even appear in single-threaded local apps, which need to transform text/list indices for features like inline comments and edit histories.</p>
</blockquote>

<h2 id="issues-with-existing-solutions">Issues with Existing Solutions</h2>

<p>Existing solutions to this core problem fall into two camps, Conflict-free Replicated Data Types (CRDTs) and Operational Transformation (OT). Roughly:</p>

<ul>
  <li><a href="https://crdt.tech/">CRDTs</a> (2005+) assign an immutable ID (<a href="https://mattweidner.com/2022/02/10/collaborative-data-design.html#position-def">“position”</a>) to each character and sort these IDs using a mathematical total order - often a tree traversal over a special kind of tree.</li>
  <li><a href="https://en.wikipedia.org/wiki/Operational_transformation">OT</a> (1989+) directly “transforms” operations to account for concurrent edits. In the above example, the server’s OT subroutine would transform “insert ‘ the’ at index 17” against “insert ‘ gray’ at index 3”, yielding “insert ‘ the’ at index 22”.</li>
</ul>

<p>Both CRDT and OT algorithms are used in practice. OT is used by Google Docs; the <a href="https://docs.yjs.dev/">Yjs</a> CRDT library is used by numerous apps. I’ve personally spent several years thinking and writing about text-editing <a href="https://mattweidner.com/2022/02/10/collaborative-data-design.html#list-crdt">CRDTs</a> <a href="https://mattweidner.com/2022/10/21/basic-list-crdt.html">and</a> <a href="https://mattweidner.com/2023/04/13/position-strings.html">closely</a> <a href="https://mattweidner.com/2024/04/29/list-positions.html">related</a> algorithms. So why does this blog post introduce a different approach, and what makes it better?</p>

<p>The main issue with both CRDTs and OT is their <em>conceptual complexity</em>. Text-editing CRDTs’ total orders are subtle algorithms defined in academic papers, often challenging to read. OT algorithms must satisfy algebraic “transformation properties” that have quadratically many cases and are <a href="https://hal.inria.fr/inria-00071213/">frequently flawed</a> without formal verification.</p>

<p>Complicated algorithms lead to even more complicated implementations, and CRDT/OT implementations are notoriously difficult. Thus you often use them through libraries, implemented by experts, which you can’t customize without a similar level of expertise. Because collaboration is a full-stack concern, the libraries are also full-stack, taking over core parts of your application: they present as a networked black box that inputs operations and outputs state.</p>

<p>This monolithic, unmodifiable approach becomes a liability when your app requires features that the library author did not anticipate. For example, I would struggle to do any of the following with an existing text-editing CRDT or OT library:</p>

<ol>
  <li>Divide the state between disk and memory, only loading the necessary parts of a large document.</li>
  <li>Enforce sub-document permissions on the server, e.g., some users are only allowed to edit certain paragraphs or use specific formatting.</li>
  <li>Allow “suggested changes” in the style of Google Docs, either inline or next to the text. (I <a href="https://github.com/mweidner037/list-positions-demos/tree/master/suggested-changes">tried to implement this</a> with my own CRDT library, but got stuck because suggestions could migrate away from their target text - precisely because I had no control over the CRDT’s total order.)</li>
  <li>Store the text in a key-value representation that is easy to sync over an existing key-value store (e.g. Replicache), without merely storing the entire text as a blob or the entire operation history as an array.</li>
  <li>Support operations beyond insert/delete: moving text, document tree manipulations, paragraph splitting/merging, etc.</li>
</ol>

<p>In contrast, the approach described in this blog post is dead simple. I hope that you will soon understand it well enough to do-it-yourself if you desire. Once that’s done, you can modify the internals and add features at will.</p>

<h2 id="the-approach">The Approach</h2>

<h2 id="main-idea">Main Idea</h2>

<p>The main idea of our approach is straightforward:</p>

<ul>
  <li>Label each text character with a globally unique ID (e.g., a UUID), so that we can refer to it in a consistent way across time - instead of using an array index that changes constantly. That is, our core data structure has type <code>Array&lt;{ id: ID; char: string }&gt;</code>.</li>
  <li>Clients send the server “insert after” operations that reference an existing ID. E.g., in <a href="#figure-1">Figure 1</a> above, Bob’s operation would be “insert ‘ the’ after <code>f1bdb70a</code>”, where <code>f1bdb70a</code> is the ID of ‘n’ in ‘on’.</li>
  <li>The server interprets “insert after” operations literally: it looks up the target ID and inserts the new characters immediately after it.</li>
</ul>

<p>Verify for yourself that this approach would handle both of Figure 1’s edits in the “obvious” correct way.</p>

<h2 id="some-corrections">Some Corrections</h2>

<p>You may have noticed two small issues with the above description. Luckily, they are both easy to correct.</p>

<p>First, when Bob sends his operation to the server, he also needs to specify the new elements’ IDs: “insert ‘ the’ after <code>f1bdb70a</code> with ids […]”. In other words, he must tell the server what pairs <code>{ id, char }</code> to add to its internal list, instead of just the new characters. (Having Bob generate the IDs, instead of waiting for the server to assign them, lets him reference those IDs in subsequent “insert after” operations before receiving a response to his first operation.)</p>

<p>Second, it’s possible for Bob to send an operation like “insert ‘foo’ after <code>26085702</code>”, but before his operation reaches the server, another user concurrently deletes the character with ID <code>26085702</code>. If the server literally deletes its pair <code>{ id: "26085702", char: "x" }</code> in response to the concurrent operation, then it won’t know where to insert Bob’s text anymore. The server can work around this by storing IDs in its internal list even after the corresponding characters are deleted: the server’s state becomes a list</p>

<div><pre><code><span>Array</span><span>&lt;</span><span>{</span> <span>id</span><span>:</span> <span>ID</span><span>;</span> <span>char</span><span>?:</span> <span>string</span><span>;</span> <span>isDeleted</span><span>:</span> <span>boolean</span> <span>}</span><span>&gt;</span><span>.</span>
</code></pre></div>

<p>Of course, deleted entries don’t show up in the user-visible text.</p>

<p>In summary, our corrected approach for client -&gt; server communication is as follows:</p>

<div><pre><code>Client &amp; server text state: Each stores a list of characters labeled by IDs, including deleted IDs.
- Type: `Array&lt;{ id: ID; char?: string; isDeleted: boolean }&gt;`
- Corresponding text: `list.filter(elt =&gt; !elt.isDeleted).map(elt =&gt; elt.char).join('')`

Typing a character `char`:
1. Client looks up the ID of the character just before the insertion point, `before`.
2. Client generates a globally unique ID for the new character (e.g., a UUID): `id`.
3. Client sends the server the operation: "insert ${char} after ${before} with id ${id}".
4. Server applies this operation to its own state literally:
  a. Looks up `before` in its own list, including deleted entries.
  b. Inserts `{ id, char, isDeleted: false }` immediately after `before`'s entry in the list.

Deleting a character:
1. Client looks up the ID of the deleted character, `id`.
2. Client sends the server the operation: "delete the entry with id ${id}".
3. Server looks up the entry for `id` and sets `entry.isDeleted = true` if not already.
</code></pre></div>

<p>You probably still have practical concerns with the above approach: e.g., it’s inefficient to store a UUID for every character. I’ll discuss optimizations <a href="#helper-library-articulated">later</a>.</p>

<h2 id="client-side">Client Side</h2>

<p><em>Recap of <a href="https://mattweidner.com/2024/06/04/server-architectures.html#1-server-reconciliation">Architectures for Central Server Collaboration - Server Reconciliation</a></em></p>

<p>The approach described so far lets us send operations from clients to the server, updating the server’s state. We managed to solve the <a href="#core-problem">core problem</a> in a straightforward way, without combing through any CRDT or OT papers.</p>

<p>For true Google-Docs style collaborative text editing, we also want to let users see the effects of their own operations immediately, without waiting for a response from the server. That is, clients should be allowed to perform optimistic local updates.</p>

<p>Optimistic local updates cause trouble when:</p>

<ul>
  <li>A client possesses pending local operations - operations that it performed locally but were not yet acknowledged by the server.</li>
  <li>Before receiving an acknowledgment for those operations, the client receives a new remote operation from the server, necessarily concurrent to its pending local operations.</li>
</ul>

<p><a id="figure-2"></a>
<img src="https://mattweidner.com/assets/img/text-without-crdts/text_pending_local_operation.png" alt="See caption"></p>
<p><i><b>Figure 2.</b> Bob submits the operation "insert ‘ the’ after &lt;n's ID&gt;" to the central server. But before the server acknowledges his operation, he receives the remote operation "insert ‘ gray’ after &lt;e's ID&gt;". What state should Bob's client display, incorporating both the remote operation and Bob's pending local operation?</i></p>

<p>At this point, you might say: We have concurrent operations, received in different orders by the client and the server, who must ultimately end up in the same state. Doesn’t that mean we need a CRDT?</p>

<p>Luckily, the answer is no! There is a fully general solution to optimistic local updates, <a href="https://mattweidner.com/2024/06/04/server-architectures.html#1-server-reconciliation">server reconciliation</a>, which is in particular compatible with our “insert after” operations. Briefly, the way you update a client in response to a new remote operation <code>R</code> is:</p>

<ol>
  <li>Undo all pending local operations. This rewinds the state to the client’s previous view of the server’s state.</li>
  <li>Apply the remote operation(s). This brings the client up-to-date with the server’s state.</li>
  <li>Redo any pending local operations that are still pending, i.e., they were not acknowledged as part of the remote batch.</li>
</ol>

<p><img src="https://mattweidner.com/assets/img/server-architectures/server_reconciliation.png" alt="Starting in optimistic local state S+L1+L2+L3, Step 1 leads to state S, Step 2 leads to state S+R, and Step 3 leads to state S+R+L1+L2+L3."></p>

<p><i>The Server Reconciliation way to process a remote operation <code>R</code> in the presence of pending local operations <code>L1, L2, L3</code>.</i></p>

<!-- Step 1 could involve literal undo commands, using a local stack that records how to undo each pending local mutation. Or, you could store the app state as a persistent data structure and directly restore the state before the first pending local mutation. Or, the server could tell you the exact new state to use (= its own latest state), which you use directly as the result of step 2.

Either way, server reconciliation completes our straightforward approach to collaborative text editing. -->

<blockquote>
  <p>There is another strategy that is even simpler than server reconciliation: forbid clients from processing remote operations whenever they possess pending local operations. I learned of this strategy from <a href="https://docs.powersync.com/architecture/consistency">PowerSync</a>.</p>

  <p>For example, in <a href="#figure-2">Figure 2</a>, Bob’s client would ignore the first message from the server, instead waiting for the server to process Bob’s message and send the resulting state. Once it receives that state, Bob’s client can directly overwrite its own state. Unless Bob has performed even more operations in the meantime - then his client needs to ignore the server’s second message and wait for a third, etc.</p>

  <p>Note that this strategy can led to unbounded delays if Bob types continuously or has high network latency, so it is not as “real-time” as server reconciliation.</p>
</blockquote>

<h2 id="difference-from-crdts">Difference from CRDTs</h2>

<p>You may object that the above approach sounds a lot like a CRDT. It does share some features: in particular, its assignment of an ID to each character and its use of <code>isDeleted</code> markers (tombstones).</p>

<p>The difference is that our approach handles order in a straightforward and flexible way: clients tell the server to insert X after Y and it does exactly that, or whatever else you program it to do. This contrasts with text-editing CRDTs, in which IDs are ordered for you by a fancy algorithm. That ordering algorithm is what differs between the numerous text-editing CRDTs, and it’s the complicated part of any CRDT paper; we get to avoid it entirely.</p>

<h2 id="discussion">Discussion</h2>

<p>The previous section described the whole approach in what I hope is enough detail to start implementing it yourself (though first check out <a href="#helper-library-articulated">Articulated</a> below). Let’s now discuss consequences and extensions of the approach.</p>

<h2 id="concurrent-insertions">Concurrent Insertions</h2>

<p>With any collaborative text-editing algorithm, the most interesting theoretical question is: What happens when multiple users type in the same place concurrently?</p>

<p>For example, staring from the text “My name is”, suppose Charlie types “ Charlie”, while concurrently, Dave types “ Dave”. If Charlie’s operation reaches the server first, what is the final text?</p>

<p>Let’s check:</p>

<ul>
  <li>Charlie’s operation says “insert ‘ Charlie’ after &lt;ID of ‘s’ in ‘is’&gt;”. The server processes this literally, giving the text “My name is Charlie”.</li>
  <li>Dave’s operation likewise says “insert ‘ Dave’ after &lt;ID of ‘s’ in ‘is’&gt;”. The server again processes this literally - inserting after the ‘s’ in ‘is’, irrespective of the concurrent text appearing afterwards - giving the text “My name is Dave Charlie”.</li>
</ul>

<p>In summary, concurrent insertions at the same place end up in the <em>reverse</em> of the order that the server received their operations. More generally, even without concurrency, insert-after operations with the same target ID end up in reverse order. For example, if Dave typed his name backwards as (e, left arrow, v, left arrow, a, left arrow, D), then each operation would be “insert after &lt;ID of ‘s’ in ‘is’&gt;”, and the resulting text would be the reverse of the server’s receipt order: Dave. (This might remind you of a popular CRDT. I’ll talk about that <a href="#decentralized-variants">later</a>.)</p>

<p>Observe that the concurrently-inserted words “ Charlie” and “ Dave” ended up one after the other, instead of becoming interleaved character-by-character (unlike <a href="https://doi.org/10.1145/3301419.3323972">some text-editing CRDTs</a>). That would work even if Charlie and Dave sent each character as a separate operation. Indeed, Dave inserts the ‘a’ in Dave after the ‘D’ (i.e., the insert-after operation references D’s ID), ‘v’ after ‘a’, etc.; so when the server processes these individual operations, it updates its state as</p>

<div><pre><code>"My name is D Charlie" -&gt; "My name is Da Charlie"
-&gt; "My name is Dav Charlie" -&gt; "My name is Dave Charlie"
</code></pre></div>

<p>in spite of the unexpected “ Charlie” afterwards.</p>

<p>The same cannot be said for backwards (right-to-left) insertions: if Dave and Charlie both typed their names with copious use of left arrow, and the server received those operations in an interleaved order, then the resulting text would also be interleaved. In practice, this could only happen if Charlie and Dave were both online simultaneously (so that their messages could be interleaved) but stubbornly ignored each other’s in-progress edits.</p>

<h2 id="flexible-operations">Flexible Operations</h2>

<p>So far, the only text-editing operations I’ve described are “insert after” and “delete”, which the server applies literally. However, the approach supports many more possible operations. In fact, thanks to <a href="#client-side">our use of server reconciliation</a>, the server has the flexibility to do essentially anything in response to a client operation - clients will eventually end up in the same state regardless. This contrasts with CRDT and OT algorithms, which only allow operations that satisfy strict algebraic rules.</p>

<p>For example, consider the concurrent insertion example from the previous section. The final result, “My name is Dave Charlie”, isn’t very reasonable, even though it satisfies a <a href="https://www.cs.ox.ac.uk/people/hongseok.yang/paper/podc16-full.pdf">mathematical specification</a> for collaborative text-editing. A fancy server could do something more intelligent for insertions like Dave’s that are at the same place as a previously-received concurrent insertion. For example:</p>

<ol>
  <li>Ignore any such operation (treat it as a no-op).</li>
  <li>Add the IDs to the internal list, but mark them as deleted immediately. (This is a still no-op from the users’ perspective, but it allows the server to process future operations from Dave that reference his earlier IDs.)</li>
  <li>Insert the text, but apply special formatting to both words to flag them for review.</li>
  <li>Convert Dave’s edits to a “suggestion” displayed alongside the main text.</li>
  <li>Ask an LLM how to best fix the text. (Be warned that Dave’s client may have trouble rebasing any further optimistic operations on top of the resulting state.)</li>
</ol>

<p>Clients can also send operations with fancier semantics than “insert after” to better capture user intent - thus increasing the odds that the server’s eventual state is reasonable in spite of concurrent edits. A simple example is “insert before”, the reversed version of “insert after”. E.g., if a user creates a heading above a paragraph, their client could “insert before” the paragraph’s first character, to prevent the header from ending up in the middle of an unrelated addition to the previous paragraph.</p>

<p>Another example is a “fix typo” operation that adds a character to a word only if that word still exists and hasn’t already been fixed. E.g., the client tells the server: “insert ‘u’ after the ‘o’ in ‘color’ that has ID X, but only if the surrounding word is still ‘color’”. That way, if another user deletes ‘color’ before the fix-typo operation reaches the server, you don’t end up with a ‘u’ in the middle of nowhere. (This example avoids an issue brought up by <a href="https://www.moment.dev/blog/lies-i-was-told-pt-1">Alex Clemmer</a>).</p>

<p>You can even define operations whose insertion positions change once they reach the server. E.g., the server could handle concurrent insertions at the same position by reordering them to be alphabetical. Or, if you add “move” operations for drag-and-drop, then the server can choose to process “insert after” operations within the moved text in the obvious way - insert them within the moved text instead of at its original location. This contrasts with text-editing CRDTs and my own CRDT-ish libraries (<a href="https://mattweidner.com/2023/04/13/position-strings.html">position-strings</a> and <a href="https://mattweidner.com/2024/04/29/list-positions.html">list-positions</a>), which fix each character’s position in a global total order as soon as the user types it.</p>

<blockquote>
  <p>Some of these flexible operations can technically be implemented on top of a CRDT, by having the server initiate its own operations after a client operation (e.g., apply “delete” operations to some text that it wants to ignore). However, I don’t know of CRDT implementations that support “insert before” operations, un-deleting IDs, or changing where an ID ends up in the list.</p>
</blockquote>

<h2 id="formatting-rich-text">Formatting (Rich Text)</h2>

<p>Rich text enhances plain text with inline formatting (bold, font size, hyperlinks, …), among other features. To handle rich text in our approach, when a user formats a range of text, we of course want to translate the ends of that range into character IDs instead of indices: “apply bold formatting from ID X to ID Y”. (Or perhaps: “apply bold formatting from ID X inclusive to ID Y exclusive”, so that concurrent insertions at the end of the range are also bolded.)</p>

<p>When used alongside a rich-text editor such as ProseMirror, the server can apply such operations literally: look up the current array indices of X and Y, and tell the local ProseMirror state to bold that range of text. ProseMirror will take care of remembering the bold span so that, when the server later receives an insertion within the span, it knows to bold that text too. (Unless the server decides to otherwise, e.g., in response to an operation “insert ‘…’ after ID Z with bold set to false”.)</p>

<p>I believe this simple extension to our approach takes care of the tricky conflict-resolution parts of collaborative rich-text formatting. However, I still recommend reading the <a href="https://www.inkandswitch.com/peritext/">Peritext essay</a> for insight into the semantics of collaborative rich-text - what operations clients should send to the server, and how the server should process them.</p>

<h2 id="decentralized-variants">Decentralized Variants</h2>

<p><em>More info in <a href="https://mattweidner.com/2024/06/04/server-architectures.html#appendix-from-centralized-to-decentralized">Architectures for Central Server Collaboration - Appendix: From Centralized to Decentralized</a></em></p>

<p>I’ve so far assumed that your app has a central server, which assigns a total order to operations (namely, the order that the server receives them) and updates its authoritative state in response to those operations.</p>

<p>If you don’t have a central server or your app is server-optional, you can instead assign an eventual total order to operations in a <em>decentralized</em> way. For example, order operations using <a href="https://mattweidner.com/2023/09/26/crdt-survey-3.html#lww-lamport-timestamps">Lamport timestamps</a>. Then treat “the result of processing the operations I’ve received so far in order” as the authoritative state on each client. Our approach’s per-character IDs and “insert after” operations work equally well with this decentralized, “non”-server reconciliation.</p>

<p>Technically, the resulting algorithm is a text-editing CRDT: it’s a decentralized, eventually consistent algorithm for collaborative text editing. I hope that it is easier to understand and implement than a typical text-editing CRDT - it involved no trees or mathematical proofs - and the above remarks on <a href="#flexible-operations">Flexible Operations</a> and <a href="#formatting-rich-text">Formatting</a> still hold in the decentralized setting.</p>

<p>Nonetheless, you might ask: if “non”-server reconciliation plus our “insert after” operations yields a text-editing CRDT, which CRDT is it? The answer is:</p>

<ul>
  <li>If you order operations using Lamport timestamps, the resulting list order is equivalent to RGA / Causal Trees. (RGA’s sibling sort - reverse Lamport timestamp order - corresponds exactly to the reverse-order behavior I described <a href="#concurrent-insertions">earlier</a>.)</li>
  <li>If you order operations using Lamport timestamps and add formatting operations like above, the resulting behavior is quite similar to <a href="https://www.inkandswitch.com/peritext/">Peritext</a>. (The Lamport timestamp order on formatting operations corresponds to Peritext’s Lamport-timestamp-ordered stack of formatting spans.)</li>
  <li>If you order operations using a topological sort - e.g., append them to an RGA list CRDT and use its list order - the resulting list order is equivalent to <a href="https://mattweidner.com/2022/10/21/basic-list-crdt.html">Fugue</a>. (The topological sort’s non-interleaving property corresponds to Fugue’s non-interleaving of backwards insertions.)</li>
</ul>

<blockquote>
  <p>I have not written out a proof of these claims in detail, but I’m happy to discuss my reasoning if you <a href="https://mattweidner.com/">contact me</a>.</p>
</blockquote>

<h2 id="helper-library-articulated">Helper Library: Articulated</h2>

<p>Recall that each device’s state in our approach is a list</p>

<div><pre><code><span>Array</span><span>&lt;</span><span>{</span> <span>id</span><span>:</span> <span>ID</span><span>;</span> <span>char</span><span>?:</span> <span>string</span><span>;</span> <span>isDeleted</span><span>:</span> <span>boolean</span> <span>}</span><span>&gt;</span><span>;</span>
</code></pre></div>

<p>In practice, you often want to store the actual text elsewhere - e.g., as a ProseMirror state - so our approach really just needs a list</p>

<div><pre><code><span>Array</span><span>&lt;</span><span>{</span> <span>id</span><span>:</span> <span>ID</span><span>;</span> <span>isDeleted</span><span>:</span> <span>boolean</span> <span>}</span><span>&gt;</span><span>;</span>
</code></pre></div>

<p>There are a few main tasks that you’ll perform on this list:</p>

<ol>
  <li>Convert between IDs and their current array indices, so that you can talk to the text-editing UI (e.g. ProseMirror).</li>
  <li>Insert a new ID after a specified ID.</li>
  <li>Mark an ID as deleted.</li>
  <li>Convert the state to and from a serialized form for storage.</li>
</ol>

<p>A literal array is not great at any of these tasks. Tasks 1-3 take linear time, and the array’s memory and storage space are large - an entire object and UUID per character!</p>

<p><a href="https://github.com/mweidner037/articulated/">Articulated</a> is a small npm library I made to help out. Its <code>IdList</code> data structure provides the same functionality as the above array, but with optimizations similar to those in popular text-editing CRDT libraries:</p>

<ul>
  <li>IDs have the form <code>{ bunchId, counter }</code>, where <code>bunchId</code> is a UUID that can be shared between a “bunch” of IDs with varying <code>counter</code>. When IDs in a bunch appear alongside each other - e.g., in the common case of left-to-right insertions - <code>IdList</code> stores them as a single object in memory and in the serialized state.</li>
  <li>The core data structure is a B+Tree instead of an array, allowing <code>log</code> or <code>log^2</code> time method calls.</li>
</ul>

<p>As an added feature, IdList is a <a href="https://en.wikipedia.org/wiki/Persistent_data_structure">persistent</a> data structure. This is great for server reconciliation: each client can cheaply store a copy of the latest state they received from the server alongside their optimistic state, making it trivial to rollback to the server’s last state when they receive a remote operation.</p>

<p>You can check out the <a href="https://github.com/mweidner037/articulated/#articulated">docs</a> and (very preliminary) <a href="https://github.com/mweidner037/articulated-demos">demos</a> to learn more. Or, read through the code for <a href="https://github.com/mweidner037/articulated/blob/master/test/id_list_simple.ts">IdListSimple</a> - it’s a simple, &lt; 300 SLOC implementation of IdList that omits its optimizations and persistence but is otherwise functionally identical (verified by fuzz tests).</p>

<p>I hope that, within the context of a server reconciliation architecture, Articulated can serve a similar purpose to an optimized CRDT library, but with the flexibility and other advantages described in this blog post.</p>




        
    <!-- Footer -->
    <hr>
    <p>
    <a href="https://mattweidner.com/">Home</a>
    • Matthew Weidner
    • Common Curriculum / CMU PhD student
    • mweidner037 [at] gmail.com
    • <a href="https://twitter.com/MatthewWeidner3">@MatthewWeidner3</a>
    • <a href="https://bsky.app/profile/mweidner.bsky.social">@mweidner.bsky.social</a>
    • <a href="https://www.linkedin.com/in/matthew-weidner-99715412a">LinkedIn</a>
    • <a href="https://github.com/mweidner037/">GitHub</a>
    </p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI to buy AI startup from Jony Ive (577 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2025-05-21/openai-to-buy-apple-veteran-jony-ive-s-ai-device-startup-in-6-5-billion-deal</link>
            <guid>44053518</guid>
            <pubDate>Wed, 21 May 2025 17:01:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2025-05-21/openai-to-buy-apple-veteran-jony-ive-s-ai-device-startup-in-6-5-billion-deal">https://www.bloomberg.com/news/articles/2025-05-21/openai-to-buy-apple-veteran-jony-ive-s-ai-device-startup-in-6-5-billion-deal</a>, See on <a href="https://news.ycombinator.com/item?id=44053518">Hacker News</a></p>
Couldn't get https://www.bloomberg.com/news/articles/2025-05-21/openai-to-buy-apple-veteran-jony-ive-s-ai-device-startup-in-6-5-billion-deal: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[By Default, Signal Doesn't Recall (364 pts)]]></title>
            <link>https://signal.org/blog/signal-doesnt-recall/</link>
            <guid>44053364</guid>
            <pubDate>Wed, 21 May 2025 16:46:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://signal.org/blog/signal-doesnt-recall/">https://signal.org/blog/signal-doesnt-recall/</a>, See on <a href="https://news.ycombinator.com/item?id=44053364">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><img src="https://signal.org/blog/images/recall-header.png" alt="A screenshot of a Microsoft Windows desktop. Microsoft Paint and Minesweeper are visible behind a black rectangular window that is empty except for graffiti-style text that says &quot;SIGNAL WAS HERE&quot;."></p><p>Signal Desktop now includes support for a new “Screen security” setting that is designed to help prevent your own computer from capturing screenshots of your Signal chats on Windows. This setting is automatically enabled by default in Signal Desktop on Windows 11.</p><p>If you’re wondering why we’re only implementing this on Windows right now, it’s because the purpose of this setting is to protect your Signal messages from <a href="https://support.microsoft.com/en-us/windows/retrace-your-steps-with-recall-aa03f8a0-a78b-4b3e-b0a1-2eb8ac48701c">Microsoft Recall</a>.</p><p>First announced on May 20, 2024, Microsoft Recall takes screenshots of your apps every few seconds as you use your computer and then stores them in an easily searchable database. In Microsoft’s <a href="https://blogs.windows.com/windowsexperience/2024/06/07/update-on-the-recall-preview-feature-for-copilot-pcs/">own words</a>, its goal is to act as a sort of “photographic memory” for everything that you do on your computer. The words that other people chose to describe Recall upon its debut were decidedly less positive.<sup id="fnref:1"><a href="#fn:1" rel="footnote" role="doc-noteref">1</a></sup> After an intense <a href="https://www.wired.com/story/microsoft-recall-off-default-security-concerns/">security backlash</a> and significant public outcry, Microsoft quickly pulled the feature.</p><p>It’s a one-year anniversary that nobody wants to celebrate, but Recall <a href="https://arstechnica.com/security/2025/04/microsoft-is-putting-privacy-endangering-recall-back-into-windows-11/">is back</a> and Signal is ready.</p><p>Although Microsoft made several adjustments over the past twelve months in response to critical feedback, the revamped version of Recall still places any content that’s displayed within privacy-preserving apps like Signal at risk. As a result, we are enabling an extra layer of protection by default on Windows 11 in order to help maintain the security of Signal Desktop on that platform even though it introduces some usability trade-offs. Microsoft has simply given us no other option.</p><h2 id="fade-to-black">Fade to Black</h2><p>If you attempt to take a screenshot of Signal Desktop when screen security is enabled, nothing will appear. This limitation can be frustrating, but it might look familiar to you if you’ve ever had the audacity to try and take a screenshot of a movie or TV show on Windows. According to Microsoft’s <a href="https://learn.microsoft.com/en-us/windows/client-management/manage-recall#information-for-developers">official developer documentation</a>, setting the correct <a href="https://en.wikipedia.org/wiki/Digital_rights_management">Digital Rights Management</a> (DRM) flag on the application window will ensure that “content won’t show up in Recall or any other screenshot application.” So that’s exactly what Signal Desktop is now doing on Windows 11 by default.</p><p><img src="https://signal.org/blog/images/recall-drm-screenplay.jpg" alt="A stylized close-up crop of a movie screenplay that says &quot;INT. COPILOT+ PC MANUFACTURING FACILITY - NIGHT - METALLIC SHELVES in endless rows stretch into the darkness. Two figures crouch in the shadows. ALICE: DRM technology has been consistently used against us. BOB: It won't be the first time we've turned the tables. ALICE: My life has always felt like a movie.&quot;"></p><p>Apps like Signal have essentially no control over what content Recall is able to capture, and implementing “DRM” that works for you (not against you) is the best choice that we had. It’s like a scene in a movie where the villain has switched sides, and you can’t screenshot this one by default either.</p><h2 id="warning-shots">Warning Shots</h2><p>Microsoft has launched Recall without granular settings for app developers that would enable Signal to easily protect privacy, which is a glaring omission that limits our choices. Signal is using the tools that are available to us even though we recognize that there are many legitimate use cases where someone might need to take a screenshot. For example, some accessibility software (such as screen readers or magnification tools for people who are visually impaired) may not function correctly otherwise.</p><p>To help mitigate this issue, we made the setting easy to disable <em>(Signal Settings → Privacy → Screen security)</em>, but it’s difficult to accidentally disable. Turning off “Screen security” in Signal Desktop on Windows 11 will always display a warning and require confirmation in order to continue.</p><p><img src="https://signal.org/blog/images/recall-warning.png" alt="A screenshot of a warning dialog box that says &quot;Disable screen security? If disabled, this may allow Microsoft Windows to capture screenshots of Signal and use them for features that may not be private.&quot;"></p><p>This setting is local to your computer and doesn’t apply to screenshots on other devices. If you are communicating with someone who uses a screen reader on macOS or Linux, for example, keeping screen security enabled on your side won’t prevent them from taking screenshots or adversely affect any accessibility software they may be using.</p><p>We hope that the AI teams building systems like Recall will think through these implications more carefully in the future. Apps like Signal shouldn’t have to implement “one weird trick” in order to maintain the privacy and integrity of their services without proper developer tools. People who care about privacy shouldn’t be forced to sacrifice accessibility upon the altar of AI aspirations either.</p><h2 id="future-recallections">Future Recallections</h2><p>“Take a screenshot every few seconds” legitimately sounds like a suggestion from a low-parameter LLM that was given a prompt like “How do I add an arbitrary AI feature to my operating system as quickly as possible in order to make investors happy?” — but more sophisticated threats are on the horizon.</p><p>The integration of AI agents with pervasive permissions, questionable security hygiene, and an insatiable hunger for data has the potential to break <a href="https://techcrunch.com/2025/03/07/signal-president-meredith-whittaker-calls-out-agentic-ai-as-having-profound-security-and-privacy-issues/">the blood-brain barrier</a> between applications and operating systems. This poses a significant threat to Signal, and to every privacy-preserving application in general.</p><p>People everywhere rely on Signal to protect their communication, including human rights workers, governments, board rooms, militaries, and millions of individuals around the world for whom privacy is an existential matter. Apps like Signal must maintain their ability to prioritize security by default in a way that can be <a href="https://github.com/signalapp">publicly validated</a>. It’s imperative that privacy-preserving apps retain the ability to uphold these promises on every platform, including Microsoft Windows.</p><p>In order to do this, the ecosystem needs to do its part too. Operating system vendors, especially those who are shipping AI agents, need to ensure that the developers of apps like Signal always have the necessary tools and options at their disposal to reject granting OS-level AI systems access to any sensitive information within their apps.<sup id="fnref:2"><a href="#fn:2" rel="footnote" role="doc-noteref">2</a></sup></p><p><a href="https://www.cbsnews.com/news/ceo-zuckerberg-facebooks-5-core-values/">“Move fast and break things”</a> is going to be a tough habit for the tech industry to, well, break. But <a href="https://en.wikipedia.org/wiki/Minimum_viable_product">MVP</a> shouldn’t also stand for “Minimum Viable Precautions.” It’s ultimately up to companies like Microsoft to ensure that their platforms remain a suitable foundation for privacy-preserving applications like Signal. If that ever stops being the case, we’ll have to stop supporting those platforms.</p><p>Messaging apps are a window into your entire life. They’re where we share our favorite memories, fall in love, complain, smile, cry, and express who we really are. Given this reality, private messaging apps like Signal deserve to be treated with at least the same level of caution that’s afforded to a web browser’s private or incognito browsing window — which Microsoft has <a href="https://support.microsoft.com/en-us/windows/filtering-apps-websites-and-sensitive-information-in-recall-a4c28bee-e200-4a4a-b60d-c0522b404a5b">already excluded from Recall by default</a>.</p><p>Screen security for Signal Desktop on Microsoft Windows is rolling out now, and enabled by default on Windows 11. We’d like to express our sincere appreciation to the Signal community for helping us test this release during the beta period. We couldn’t do this work without your support.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Introducing the Llama Startup Program (140 pts)]]></title>
            <link>https://ai.meta.com/blog/llama-startup-program/?_fb_noscript=1</link>
            <guid>44052984</guid>
            <pubDate>Wed, 21 May 2025 16:10:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ai.meta.com/blog/llama-startup-program/?_fb_noscript=1">https://ai.meta.com/blog/llama-startup-program/?_fb_noscript=1</a>, See on <a href="https://news.ycombinator.com/item?id=44052984">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>We’re excited to announce the <a href="https://www.llama.com/programs/startups/" target="_blank" data-lnfb-mode="ie"><u>Llama Startup Program</u></a>, a new initiative to empower early-stage startups to innovate and build generative AI applications with <a href="https://www.llama.com/" target="_blank" data-lnfb-mode="ie"><u>Llama</u></a>. Members of the Llama Startup Program will receive resources and support from Llama experts along their journey, including help getting started with Llama and resources necessary to succeed and thrive in a competitive and fast-moving landscape.</p><h2>Why we’re launching the Llama Startup Program</h2><div><p>Early-stage startups are agile and creative, making them uniquely positioned to accelerate high-impact innovation with Llama. In a recent <a href="https://about.fb.com/news/2025/05/new-study-shows-open-source-ai-catalyst-economic-growth/" target="_blank" data-lnfb-mode="ie"><u>Linux Foundation study</u></a><a href="https://about.fb.com/news/2025/05/new-study-shows-open-source-ai-catalyst-economic-growth/" target="_blank" data-lnfb-mode="ie">,</a> 94% of organizations say they’ve already adopted AI tools and models, and of those, 89% are using some form of open source technology—such as Llama—in their AI infrastructure.</p><p>We want to give our Llama Startup Program members a competitive edge by offering direct support from the Llama team and may help to fund their use of Llama models. We hope this support accelerates their development process and enhances their ability to deliver innovative solutions. We’ve seen how our <a href="https://about.fb.com/news/2025/04/llama-impact-grant-recipients/" target="_blank" data-lnfb-mode="ie"><u>Llama Impact Grants</u></a> have helped recipients innovate and deliver economic opportunity, and we believe that supporting developers through the Llama Startup Program will help early-stage startups take flight.</p></div></div><div><h2>What are the benefits of being part of the Llama Startup Program?</h2><div><p>During the initial phase of the Llama Startup Program, we're reimbursing the cost of using Llama through hosted APIs via cloud inference providers. Members may receive up to $6,000 USD per month for up to six months to help them offset the costs of building and enhancing their generative AI solutions. This funding enables startups to experiment, innovate, and scale their solutions without the immediate financial burden, enabling them to focus on what truly matters: creating impactful technologies.</p><p>Members of the program will receive hands-on technical support from the Llama team. Our experts will work closely with them to get started and explore advanced use cases of Llama that could benefit their startups. This direct access to technical expertise ensures that developers can effectively leverage Llama’s capabilities, optimize solutions, and overcome technical challenges they may encounter as they start building.</p></div><h2>Who should apply?</h2><div><p>The Llama Startup Program is an exciting opportunity for early-stage startups in the United States that are ready to innovate with generative AI. We invite startups that are incorporated, have raised less than $10 million USD in funding, and have at least one developer on staff to apply. The Llama Startup Program is ideal for those building generative AI applications across a variety of industries, including technology and software, financial services, healthcare and life sciences, telecommunications, and retail and eCommerce. Join us for the opportunity to receive cloud reimbursements of up to $6,000 USD per month for up to six months, technical resources, and a vibrant community—all while contributing valuable feedback to enhance the Llama experience. If your startup is ready to grow and make a meaningful impact, we encourage you to apply and be part of this transformative program.</p><p>Applications for the initial cohort close on May 30, 2025 at 6:00 pm PT.</p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Discord Unveiled: A Comprehensive Dataset of Public Communication (2015-2024) (127 pts)]]></title>
            <link>https://arxiv.org/abs/2502.00627</link>
            <guid>44052041</guid>
            <pubDate>Wed, 21 May 2025 14:45:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2502.00627">https://arxiv.org/abs/2502.00627</a>, See on <a href="https://news.ycombinator.com/item?id=44052041">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
    <div><p><span>Authors:</span><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aquino,+Y" rel="nofollow">Yan Aquino</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bento,+P" rel="nofollow">Pedro Bento</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Buzelin,+A" rel="nofollow">Arthur Buzelin</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dayrell,+L" rel="nofollow">Lucas Dayrell</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Malaquias,+S" rel="nofollow">Samira Malaquias</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Santana,+C" rel="nofollow">Caio Santana</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Estanislau,+V" rel="nofollow">Victoria Estanislau</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dutenhefner,+P" rel="nofollow">Pedro Dutenhefner</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Evangelista,+G+H+G" rel="nofollow">Guilherme H. G. Evangelista</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Porf%C3%ADrio,+L+G" rel="nofollow">Luisa G. Porfírio</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Grossi,+C+S" rel="nofollow">Caio Souza Grossi</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rigueira,+P+B" rel="nofollow">Pedro B. Rigueira</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Almeida,+V" rel="nofollow">Virgilio Almeida</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pappa,+G+L" rel="nofollow">Gisele L. Pappa</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meira,+W" rel="nofollow">Wagner Meira Jr</a></p></div>            
    <p><a href="https://arxiv.org/pdf/2502.00627">View PDF</a>
    <a href="https://arxiv.org/html/2502.00627v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Discord has evolved from a gaming-focused communication tool into a versatile platform supporting diverse online communities. Despite its large user base and active public servers, academic research on Discord remains limited due to data accessibility challenges. This paper introduces Discord Unveiled: A Comprehensive Dataset of Public Communication (2015-2024), the most extensive Discord public server's data to date. The dataset comprises over 2.05 billion messages from 4.74 million users across 3,167 public servers, representing approximately 10% of servers listed in Discord's Discovery feature. Spanning from Discord's launch in 2015 to the end of 2024, it offers a robust temporal and thematic framework for analyzing decentralized moderation, community governance, information dissemination, and social dynamics. Data was collected through Discord's public API, adhering to ethical guidelines and privacy standards via anonymization techniques. Organized into structured JSON files, the dataset facilitates seamless integration with computational social science methodologies. Preliminary analyses reveal significant trends in user engagement, bot utilization, and linguistic diversity, with English predominating alongside substantial representations of Spanish, French, and Portuguese. Additionally, prevalent community themes such as social, art, music, and memes highlight Discord's expansion beyond its gaming origins.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Yan Aquino Amorim [<a href="https://arxiv.org/show-email/debf74d4/2502.00627" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Sun, 2 Feb 2025 02:17:14 UTC (1,433 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Animated Factorization (217 pts)]]></title>
            <link>http://www.datapointed.net/visualizations/math/factorization/animated-diagrams/</link>
            <guid>44051958</guid>
            <pubDate>Wed, 21 May 2025 14:39:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.datapointed.net/visualizations/math/factorization/animated-diagrams/">http://www.datapointed.net/visualizations/math/factorization/animated-diagrams/</a>, See on <a href="https://news.ycombinator.com/item?id=44051958">Hacker News</a></p>
<div id="readability-page-1" class="page">
<div id="enchilada">



<div id="credits">
<p><a href="http://www.datapointed.net/2012/10/animated-factorization-diagrams/" onclick="window.open(this.href);return false;">About</a>
</p></div>
<canvas width="300" height="300" id="canvas"></canvas>
</div>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Devstral (321 pts)]]></title>
            <link>https://mistral.ai/news/devstral</link>
            <guid>44051733</guid>
            <pubDate>Wed, 21 May 2025 14:21:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mistral.ai/news/devstral">https://mistral.ai/news/devstral</a>, See on <a href="https://news.ycombinator.com/item?id=44051733">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p dir="ltr">Today we introduce Devstral, our agentic LLM for software engineering tasks. Devstral is built under a collaboration between Mistral AI and <a href="https://www.all-hands.dev/">All Hands AI</a> 🙌, and outperforms all open-source models on SWE-Bench Verified by a large margin. We release Devstral under the Apache 2.0 license.&nbsp;</p>
<p dir="ltr"><img src="https://cms.mistral.ai/assets/a8f418f6-f7ee-4f21-8ab8-08bd76c37186.png?width=1600&amp;height=882" alt="Devstral Swe"></p>
<h2 dir="ltr">Agentic LLMs for software development</h2>
<p dir="ltr">While typical LLMs are excellent at atomic coding tasks such as writing standalone functions or code completion, they currently struggle to solve real-world software engineering problems. Real-world development requires contextualising code within a large codebase, identifying relationships between disparate components, and identifying subtle bugs in intricate functions.&nbsp;</p>
<p dir="ltr">Devstral is designed to tackle this problem. Devstral is trained to solve real GitHub issues; it runs over code agent scaffolds such as OpenHands or SWE-Agent, which define the interface between the model and the test cases. Here, we show Devstral’s performance on the popular SWE-Bench Verified benchmark, a dataset of 500 real-world GitHub issues which have been manually screened for correctness.</p>
<p dir="ltr">Devstral achieves a score of 46.8% on SWE-Bench Verified, outperforming prior open-source SoTA models by more than 6% points. When evaluated under the same test scaffold (OpenHands, provided by <a href="https://www.all-hands.dev/">All Hands AI</a> 🙌), Devstral exceeds far larger models such as Deepseek-V3-0324 (671B) and Qwen3 232B-A22B.&nbsp;</p>
<p dir="ltr">In the table below, we also compare Devstral to closed and open models evaluated under any scaffold (including ones custom for the model). Here, we find that Devstral achieves substantially better performance than a number of closed-source alternatives. For example, Devstral surpasses the recent GPT-4.1-mini by over 20%.&nbsp;</p>


<h2 dir="ltr">Versatile: local deployment ↔️ enterprise use ↔️ copilots</h2>
<p dir="ltr">Devstral is light enough to run on a single RTX 4090 or a Mac with 32GB RAM, making it an ideal choice for local deployment and on-device use. Coding platforms such as <a href="https://github.com/All-Hands-AI/OpenHands">OpenHands</a> can allow the model to interact with local codebases and provide fast resolution to issues. To try it yourself, view the <a href="https://docs.all-hands.dev/modules/usage/llms/local-llms">documentation</a> or <a href="https://www.youtube.com/watch?v=oV9tAkS2Xic">tutorial video</a>.</p>
<p dir="ltr">The performance of the model also makes it a suitable choice for agentic coding on privacy-sensitive repositories in enterprises, especially ones subject to stringent security and compliance requirements.&nbsp;</p>
<p dir="ltr">Finally, if you’re building or using an agentic coding IDE, plugin, or environment, Devstral is a great choice to add to your model selector.&nbsp;</p>
<h2 dir="ltr">Availability</h2>
<p dir="ltr">We release this model for free under an Apache 2.0 license for the community to build on, customize, and accelerate autonomous software development. To try it for yourself, head over to our <a href="https://huggingface.co/mistralai/Devstral-Small-2505">model card</a>.&nbsp;</p>
<p dir="ltr">The model is also available on our API under the name devstral-small-2505 at the same price as Mistral Small 3.1: $0.1/M input tokens and $0.3/M output tokens.&nbsp;</p>
<p dir="ltr">Should you choose to self-deploy, you can download the model on <a href="https://huggingface.co/mistralai/Devstral-Small-2505">HuggingFace</a>, <a href="https://ollama.com/library/devstral">Ollama</a>, <a href="https://www.kaggle.com/models/mistral-ai/devstral-small-2505">Kaggle</a>, <a href="https://docs.unsloth.ai/basics/devstral">Unsloth</a>, <a href="https://lmstudio.ai/model/devstral-small-2505-MLX">LM Studio</a>&nbsp;starting today.&nbsp;</p>
<p dir="ltr">For enterprise deployments that require fine-tuning on private codebases, or higher-fidelity customization such as continued pre-training or distilling Devstral’s capabilities into other models, please <a href="https://mistral.ai/contact">contact us</a> to connect with our applied AI team.&nbsp;</p>
<h2 dir="ltr">What’s next</h2>
<p dir="ltr">Devstral is a research preview and we welcome feedback! We’re hard at work building a larger agentic coding model that will be available in the coming weeks.</p>
<p dir="ltr">Interested in discussing how we can help your team put Devstral to use, and about our portfolio of models, products and solutions? <a href="https://mistral.ai/contact">Contact us</a> and we’ll be happy to help.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Things that have a bigger impact than coding assistants (103 pts)]]></title>
            <link>https://codemanship.wordpress.com/2025/05/21/five-boring-things-that-have-a-bigger-impact-than-a-i-coding-assistants-on-dev-team-productivity/</link>
            <guid>44050843</guid>
            <pubDate>Wed, 21 May 2025 12:39:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://codemanship.wordpress.com/2025/05/21/five-boring-things-that-have-a-bigger-impact-than-a-i-coding-assistants-on-dev-team-productivity/">https://codemanship.wordpress.com/2025/05/21/five-boring-things-that-have-a-bigger-impact-than-a-i-coding-assistants-on-dev-team-productivity/</a>, See on <a href="https://news.ycombinator.com/item?id=44050843">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">
		<p><a href="#content">
			Skip to content		</a></p><!-- .site-header -->

		<div id="content">
	<main id="main">
		
<article id="post-2175">
	<!-- .entry-header -->

	
	
	<div>
		
<figure><a href="https://codemanship.wordpress.com/wp-content/uploads/2025/05/autocomplete.png"><img data-attachment-id="2177" data-permalink="https://codemanship.wordpress.com/2025/05/21/five-boring-things-that-have-a-bigger-impact-than-a-i-coding-assistants-on-dev-team-productivity/autocomplete/" data-orig-file="https://codemanship.wordpress.com/wp-content/uploads/2025/05/autocomplete.png" data-orig-size="1240,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Autocomplete" data-image-description="" data-image-caption="" data-medium-file="https://codemanship.wordpress.com/wp-content/uploads/2025/05/autocomplete.png?w=300" data-large-file="https://codemanship.wordpress.com/wp-content/uploads/2025/05/autocomplete.png?w=840" width="1024" height="594" src="https://codemanship.wordpress.com/wp-content/uploads/2025/05/autocomplete.png?w=1024" alt="" srcset="https://codemanship.wordpress.com/wp-content/uploads/2025/05/autocomplete.png?w=1024 1024w, https://codemanship.wordpress.com/wp-content/uploads/2025/05/autocomplete.png?w=150 150w, https://codemanship.wordpress.com/wp-content/uploads/2025/05/autocomplete.png?w=300 300w, https://codemanship.wordpress.com/wp-content/uploads/2025/05/autocomplete.png?w=768 768w, https://codemanship.wordpress.com/wp-content/uploads/2025/05/autocomplete.png 1240w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px"></a></figure>



<p>Here are 5 factors that make a bigger difference to software development outcomes than “A.I.” coding assistants, but teams don’t address because they’re “old news, granddad!”</p>



<ul>
<li>Smaller teams are better value/$ spent</li>



<li>More frequent releases accelerate learning what has real value</li>



<li>Limiting work in progress – solving one problem at a time – increases delivery throughput</li>



<li>Cross-functional teams experience fewer bottlenecks and blockers than specialised teams</li>



<li>Empowered, self-organising teams spend less time waiting for decisions and more time getting sh*t done</li>
</ul>



<p>Now, I appreciate that every one of these is a can of worms that many organisations simply do not wish to open. They all have deep implications, and require foundational changes not just to the way we work, but the way we <em>think</em>.</p>



<p>For example, smaller, more frequent releases implies software’s in a shippable state more often, which implies faster build &amp; test cycles… and down the rabbit hole we go: into testing pyramids and separation of concerns and micro-cycles with continuous testing, continuous integration, continuous code review and… Come to think of it, <a href="https://codemanship.co.uk/">the stuff I teach</a> 🙂</p>



<p>Another example, empowering teams requires a pretty high level of psychological safety. When people are afraid to fail, they’re afraid to <em>try </em>– to make calls, to take initiative, to just f-ing do it! The culture of an organisation, which may have evolved over many years, is a hard thing to reshape. There’s often a lot of unspoken rules – sure, you <em>say </em>your door is always open, but… It takes much work and many iterations to shift those underlying patterns in the way we interact.</p>



<p>But waiting on the other side of that long journey is a high capability to rapidly and sustainably create and adapt working software that meets rapidly-changing business needs. Software agility Nirvana.</p>



<p>We already know from the data (e.g., DORA) that “A.I.” coding assistants don’t unlock that door.</p>

<div>
	<p><img referrerpolicy="no-referrer" alt="Unknown's avatar" src="https://1.gravatar.com/avatar/aadcfbd208e65a0829f5d259192a5886454439a708e425500c59c535e28ae081?s=42&amp;d=identicon&amp;r=G" srcset="https://1.gravatar.com/avatar/aadcfbd208e65a0829f5d259192a5886454439a708e425500c59c535e28ae081?s=42&amp;d=identicon&amp;r=G 1x, https://1.gravatar.com/avatar/aadcfbd208e65a0829f5d259192a5886454439a708e425500c59c535e28ae081?s=63&amp;d=identicon&amp;r=G 1.5x, https://1.gravatar.com/avatar/aadcfbd208e65a0829f5d259192a5886454439a708e425500c59c535e28ae081?s=84&amp;d=identicon&amp;r=G 2x, https://1.gravatar.com/avatar/aadcfbd208e65a0829f5d259192a5886454439a708e425500c59c535e28ae081?s=126&amp;d=identicon&amp;r=G 3x, https://1.gravatar.com/avatar/aadcfbd208e65a0829f5d259192a5886454439a708e425500c59c535e28ae081?s=168&amp;d=identicon&amp;r=G 4x" height="42" width="42" loading="lazy" decoding="async">	</p><!-- .author-avatar -->

	<!-- .author-description -->
</div><!-- .author-info -->
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-2175 -->

<!-- .comments-area -->

	<nav aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
	</main><!-- .site-main -->

	
</div><!-- .site-content -->

		<!-- .site-footer -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Roto: A Compiled Scripting Language for Rust (144 pts)]]></title>
            <link>https://blog.nlnetlabs.nl/introducing-roto-a-compiled-scripting-language-for-rust/</link>
            <guid>44050222</guid>
            <pubDate>Wed, 21 May 2025 11:10:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.nlnetlabs.nl/introducing-roto-a-compiled-scripting-language-for-rust/">https://blog.nlnetlabs.nl/introducing-roto-a-compiled-scripting-language-for-rust/</a>, See on <a href="https://news.ycombinator.com/item?id=44050222">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="site-main">
<article>

    <header>

        

        


        <section>

            <ul>
                <li>
                    <a href="https://blog.nlnetlabs.nl/author/nlnetlabs/" aria-label="Read more of Team NLnet Labs">
                        <img src="https://blog.nlnetlabs.nl/content/images/size/w100/2022/07/nlnetlabs-logo-and-text-1-1.png" alt="Team NLnet Labs">
                    </a>
                </li>
            </ul>

            

        </section>

            <figure>
                <img srcset="https://images.unsplash.com/photo-1463567517034-628c51048aa2?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDMzfHxzaGlwJTIwaGVsbXxlbnwwfHx8fDE3NDU4NDcyNjl8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=300 300w,
                            https://images.unsplash.com/photo-1463567517034-628c51048aa2?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDMzfHxzaGlwJTIwaGVsbXxlbnwwfHx8fDE3NDU4NDcyNjl8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=600 600w,
                            https://images.unsplash.com/photo-1463567517034-628c51048aa2?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDMzfHxzaGlwJTIwaGVsbXxlbnwwfHx8fDE3NDU4NDcyNjl8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1000 1000w,
                            https://images.unsplash.com/photo-1463567517034-628c51048aa2?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDMzfHxzaGlwJTIwaGVsbXxlbnwwfHx8fDE3NDU4NDcyNjl8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000 2000w" sizes="(min-width: 1400px) 1400px, 92vw" src="https://images.unsplash.com/photo-1463567517034-628c51048aa2?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDMzfHxzaGlwJTIwaGVsbXxlbnwwfHx8fDE3NDU4NDcyNjl8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Introducing Roto: A Compiled Scripting Language for Rust">
                    <figcaption><span>Photo by </span><a href="https://unsplash.com/@jbcreate_?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit"><span>Joseph Barrientos</span></a><span> / </span><a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit"><span>Unsplash</span></a></figcaption>
            </figure>

    </header>

    <section>
        <p><em>By Terts Diepraam</em></p>
<p>We are working on an embedded scripting language for Rust. This language, called <a href="https://github.com/NLnetLabs/roto?ref=blog.nlnetlabs.nl">Roto</a>, aims to be a simple yet fast and reliable scripting language for Rust applications.</p>
<p>The need for Roto comes from <a href="https://nlnetlabs.nl/projects/routing/rotonda/?ref=blog.nlnetlabs.nl">Rotonda</a>, our BGP engine written in Rust. Mature BGP applications usually feature some way to filter incoming route announcements. The complexity of these filters often exceed the capabilities of configuration languages. With Rotonda, we want to allow our users to write more complex filters with ease. So we decided to give them the power of a full scripting language.</p>
<p>We have some hard requirements for this language. First, we need these filters to be fast. Second, Rotonda is critical infrastructure and so runtime crashes are unacceptable. This rules out dynamically typed languages, of which there are plenty in the Rust community.<sup><a href="#fn1" id="fnref1">[1]</a></sup> We want a statically typed language which can give us more type safety and speed. Finally, we want a language that is easy to pick up; it should feel like a statically typed version of scripting languages you're used to.</p>
<p>Roto fills this niche for us. In short, it's a statically typed, JIT compiled, hot-reloadable, embedded scripting language. To get good performance, Roto scripts are compiled to machine code at runtime with the <a href="https://cranelift.dev/?ref=blog.nlnetlabs.nl">cranelift</a> compiler backend.</p>
<p>Below is a small sample of a Roto script. In this script, we define a <code>filtermap</code>, which results in either <code>accept</code> or <code>reject</code>. In this case, we <code>accept</code> when the IP address is within the given range.</p>
<pre><code>filtermap within_range(range: AddrRange, ip: IpAddr) {
    if range.contains(ip) {
        accept ip
    } else {
        reject
    }
}
</code></pre>
<p>Instead of a <code>filtermap</code>, we could instead write a more conventional <code>function</code>, which can simply <code>return</code> a value. The <code>filtermap</code> is a construct that Roto supports to make writing filters easier.</p>
<p>The Roto code there might look quite simple, but there's a twist: <code>AddrRange</code> is not a built-in type. Instead, it is added to Roto by the host application (e.g. Rotonda), making it available for use in the script.<sup><a href="#fn2" id="fnref2">[2]</a></sup> Similarly, the <code>contains</code> method on <code>AddrRange</code> is provided by the host application as well. The full code necessary to run the script above is listed below. This example is also available <a href="https://github.com/NLnetLabs/roto/blob/a4edc7fcea79a2498798f69da4cdb9beb6ecd4d1/examples/addr_range.rs?ref=blog.nlnetlabs.nl">on our GitHub repository</a>.</p>
<pre><code>use std::net::IpAddr;
use std::path::Path;
use roto::{roto_method, FileTree, Runtime, Val, Verdict};

#[derive(Clone)]
struct AddrRange {
    min: IpAddr,
    max: IpAddr,
}

fn run_script(path: &amp;Path) {
    // Create a runtime
    let mut runtime = Runtime::new();
    
    // Register the AddrRange type into the runtime with a docstring
    runtime
        .register_clone_type::&lt;AddrRange&gt;("A range of IP addresses")
        .unwrap();
    
    // Register the contains method on AddrRange
    #[roto_method(runtime, AddrRange)]
    fn contains(range: &amp;AddrRange, addr: &amp;IpAddr) -&gt; bool {
        range.min &lt;= addr &amp;&amp; addr &lt;= range.max
    }
    
    // Compile the program
    let program =
        FileTree::read(path).compile(runtime).unwrap();

    // Extract the Roto filtermap, which is accessed as a function
    let function = program
        .get_function::&lt;(), (Val&lt;AddrRange&gt;, IpAddr), Verdict&lt;IpAddr, ()&gt;&gt;(
          "within_range"
        )
        .unwrap();
    
    // Run the filtermap
    let range = AddrRange {
        min: "10.10.10.10".parse().unwrap(),
        max: "10.10.10.12".parse().unwrap(),
    };

    let in_range = "10.10.10.11".parse().unwrap();
    println!("{:?}", function.call(&amp;mut (), range, in_range)));

    let out_of_range = "10.10.11.10".parse().unwrap();
    println!("{:?}", function.call(&amp;mut (), range, out_of_range));
}
</code></pre>
<p>Note that nothing in the script is run automatically when the script is loaded, as happens in many other scripting language. The host application decides which functions and filtermaps it extracts from the script and when to run them.</p>
<p>Roto is very tightly integrated with Rust. Many Rust types<sup><a href="#fn3" id="fnref3">[3]</a></sup>, methods and functions can be registered directly for use in Roto. These types can be passed to Roto at negligible cost; there is no serialization between Roto and Rust. For Rotonda, this means that Roto can operate on raw BGP messages without costly conversion procedures.</p>
<p>The registration mechanism also ensures that Roto is not limited to Rotonda and could easily be used outside that context. It is designed as a general scripting or plug-in language.</p>
<p>We have many planned features on the roadmap for Roto and will continue to improve this language. This also means that the language should not be considered stable, though we'd love to hear feedback if you experiment with it. If you're interested, check out the <a href="https://rotonda.docs.nlnetlabs.nl/en/stable/roto/00_introduction.html?ref=blog.nlnetlabs.nl">documentation</a>, <a href="https://github.com/NlnetLabs/roto?ref=blog.nlnetlabs.nl">repository</a> and <a href="https://github.com/NLnetLabs/roto/tree/main/examples?ref=blog.nlnetlabs.nl">examples</a>.</p>
<hr>
<section>
<ol>
<li id="fn1"><p>E.g. <a href="https://rhai.rs/?ref=blog.nlnetlabs.nl">Rhai</a>, <a href="https://rune-rs.github.io/?ref=blog.nlnetlabs.nl">Rune</a>, <a href="https://github.com/mlua-rs/mlua?ref=blog.nlnetlabs.nl">Mlua</a>, <a href="https://deno.com/?ref=blog.nlnetlabs.nl">Deno</a>, <a href="https://pyo3.rs/?ref=blog.nlnetlabs.nl">PyO3</a>, <a href="https://github.com/PistonDevelopers/dyon?ref=blog.nlnetlabs.nl">Dyon</a> &amp; <a href="https://koto.dev/?ref=blog.nlnetlabs.nl">Koto</a>. <a href="#fnref1">↩︎</a></p>
</li>
<li id="fn2"><p>Note that the registering of types is not hindered by Rust's <a href="https://doc.rust-lang.org/reference/items/implementations.html?ref=blog.nlnetlabs.nl#orphan-rules">orphan rule</a>, because it doesn't require any specific traits apart from <code>Clone</code>. This makes it possible to expose types from external libraries to Roto. <a href="#fnref2">↩︎</a></p>
</li>
<li id="fn3"><p>Specifically, types implementing <code>Clone</code> or <code>Copy</code>. Types that don't implement these traits can be wrapped in an <code>Rc</code> or <code>Arc</code> to be passed to Roto. <a href="#fnref3">↩︎</a></p>
</li>
</ol>
</section>

    </section>


</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My new hobby: watching AI slowly drive Microsoft employees insane (903 pts)]]></title>
            <link>https://old.reddit.com/r/ExperiencedDevs/comments/1krttqo/my_new_hobby_watching_ai_slowly_drive_microsoft/</link>
            <guid>44050152</guid>
            <pubDate>Wed, 21 May 2025 10:57:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/ExperiencedDevs/comments/1krttqo/my_new_hobby_watching_ai_slowly_drive_microsoft/">https://old.reddit.com/r/ExperiencedDevs/comments/1krttqo/my_new_hobby_watching_ai_slowly_drive_microsoft/</a>, See on <a href="https://news.ycombinator.com/item?id=44050152">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Welcome to the <a href="https://old.reddit.com/r/ExperiencedDevs">/r/ExperiencedDevs</a> subreddit! We hope you will find this as a valuable resource in your journeys down the fruitful CS/IT career paths. This community leans towards being a specialized subreddit facilitating discussion amongst individuals who have gained some ground in the IT world. </p>

<p>For an idea of what is encouraged in this subreddit and what is not (please report anything that does not follow the rules):</p>

<h2><a href="https://www.reddit.com/r/ExperiencedDevs/about/rules/">Rules</a></h2>

<p><strong>1. Do not participate unless experienced (3+ years)</strong></p>

<p>If you have less than 3 years of experience as a developer, do not make a post, nor participate in comments threads except for the weekly “Ask Experienced Devs” auto-thread. No exceptions.</p>

<p><strong>2. No Disrespectful Language or Conduct</strong></p>

<p>Don’t be a jerk. Act maturely. No racism, unnecessarily foul language, ad hominem charges, sexism - none of these are tolerated here. This includes posts that could be interpreted as trolling, such as complaining about DEI (Diversity) initiatives or people of a specific sex or background at your company.</p>

<p>Do not submit posts or comments that break, or promote breaking the Reddit Terms and Conditions or Content Policy or any other Reddit policy.</p>

<p>Violations = Warning, 7-Day Ban, Permanent Ban.</p>

<p><strong>3. No General Career Advice</strong></p>

<p>This sub is for discussing issues specific to experienced developers. </p>

<p>Any career advice thread must contain questions and/or discussions that notably benefit from the participation of experienced developers. Career advice threads may be removed at the moderators discretion based on response to the thread."</p>

<p>General rule of thumb: If the advice you are giving (or seeking) could apply to a “Senior Chemical Engineer”, it’s not appropriate for this sub.</p>

<p><strong>4. No "Which Offer Should I Take" Posts</strong></p>

<p>Asking if you should ask for a raise, switch companies (“should I work for company A or company B”), “should I take offer A or offer B”, or related questions, is not appropriate for this sub. </p>

<p>This includes almost any discussion about a “hot market”, comparing compensation between companies, etc.</p>

<p><strong>5. No “What Should I Learn” Questions</strong></p>

<p>No questions like “Should I learn C#” or “Should I switch jobs into a language I don’t know?”</p>

<p>Discussion about industry direction or upcoming technologies is fine, just frame your question as part of a larger discussion (“What have you had more success with, RDBMS or NoSQL?”) and you’ll be fine.</p>

<p>tl;dr: Don’t make it about you/yourself.</p>

<p><strong>6. No “I hate X types of interviews" Posts</strong></p>

<p>This has been re-hashed over and over again. There is no interesting/new content coming out.</p>

<p>It might be OK to talk about the merits of an interview process, or compare what has been successful at your company, but if it ends up just turning into complaints your post might still be removed.</p>

<h2>Related Subs</h2>

<p><a href="https://www.reddit.com/r/cscareerquestions">CS Career Questions</a></p>

<p><a href="https://www.reddit.com/r/cscareerquestionsEU">CS Career Questions: Europe</a></p>

<p><a href="https://www.reddit.com/r/CS_Questions">CS Interview Questions</a></p>

<p><a href="http://www.reddit.com/r/learnprogramming">Learn Programming</a></p>

<p><a href="http://www.reddit.com/r/programming">General Programming Discussion</a></p>

<p><a href="http://www.reddit.com/r/coding">Coding</a></p>

<p><a href="http://www.reddit.com/r/compsci">CS Theory</a></p>

<p><a href="http://www.reddit.com/r/CSEducation">CS Education</a></p>

<p><a href="http://www.reddit.com/r/ITCareerQuestions">IT Career Questions</a></p>

<p><a href="http://www.reddit.com/r/telecommuting">Telecommuting</a></p>

<p><a href="http://www.reddit.com/r/jobs">General Job Discussion</a></p>

<p><a href="https://www.reddit.com/r/digitalnomad">Digital Nomads</a></p>

<p><a href="https://www.reddit.com/r/AskNetsec">Ask Network Security</a></p>

<p><a href="https://www.reddit.com/r/netsecstudents">NetSec Students</a></p>

<p><a href="https://www.reddit.com/r/careerguidance/">Career Guidance</a></p>

<hr>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The value isn't in the code (2022) (136 pts)]]></title>
            <link>https://jonayre.uk/blog/2022/10/30/the-real-value-isnt-in-the-code/</link>
            <guid>44046955</guid>
            <pubDate>Tue, 20 May 2025 23:33:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jonayre.uk/blog/2022/10/30/the-real-value-isnt-in-the-code/">https://jonayre.uk/blog/2022/10/30/the-real-value-isnt-in-the-code/</a>, See on <a href="https://news.ycombinator.com/item?id=44046955">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
                    
<h2><strong>Time is money, money is value</strong></h2>



<p>Okay, I’ll admit that calling your software worthless was a shameless clickbait tactic. However, I will assert that it’s not as valuable or indispensable as you might think it is. You need two things to solve a problem using software, skill and time.</p>



<p>Skill. Of course, you can create code using unskilled practitioners. The code might even work, but that’s not the same thing as solving the problem. Bad code is an issue in itself, so even if you solve your original problem, you now have a new, possibly bigger one to deal with. Skill is essential if you’re going to succeed and talent doesn’t come cheap.</p>



<p>Time. Coding can happen quickly, but solving problems is tricky. It takes time, and time is money. A software development team is not cheap to run, so any decent piece of software is going to incur significant cost. If you’re going to put investment into your solution, you should expect it to be worth something when you’re done.</p>



<p>So, why am I suggesting that the code is worthless? If it solves the problem, it’s delivering value. Worthless seems a bit harsh. It’s true that I’m exaggerating, but not by much. To understand, let’s take another look at that solution, and the time that went into it. It’s easy to focus on the software and ignore what surrounds it.</p>



<h2><strong>How to bake a cake</strong></h2>



<p>Firstly, there’s the team. You have to find the right, skilled, people, and bring them together. Then, they have to establish clear roles and responsibilities and learn to work together as a cohesive team. Finally that team has to establish relationships with the stakeholders and users, and familiarise themselves with the problem space.</p>



<p>This takes time.</p>



<p>Secondly, there’s the business logic. Even the simplest of solutions has to perform some sort of business processing. Someone has to work out what that logic needs to be and codify it.</p>



<p>This takes time.</p>



<p>Thirdly, there’s the design. If the code is user facing, it delivers an experience to the user. That experience is (hopefully) developed over time through careful design, feedback and iteration.</p>



<p>This takes time.</p>



<p>And finally, there’s the code. That also takes time, but that time is small in comparison to all the others. Sometimes it feels as if all the effort is going into the code and the other parts are incidental. However, the reality is that very little of the productive time ends up as code in the live solution.&nbsp;</p>



<p>Some of the code will be replaced by alternatives as part of the iterative feedback approach. Some of the code will remain, but will no longer be used as a result of changes to the design. Some of the code will have been written in anticipation of a situation that never arises.</p>



<p>The developer’s answer to all of this is “refactoring”. For those of you who don’t code, refactoring is the process of reviewing existing code and making a range of improvements whilst retaining the core functionality.</p>



<p>This takes time.</p>



<h2><strong>Knowledge is power</strong></h2>



<p>When you add all the time together, you get the cost of your software solution, and you could argue that this represents the value of the code. You might even argue that the value of the code exceeds the cost.</p>



<p>This is where I disagree. My opinion is that in doing this you are conflating the codebase and the solution. All the value is stored up in the team, the logic and the design, and very little of it is in the code itself. Originally this view was just a hypothesis without any form of proof, but over time I’ve had the opportunity to run experiments to test this hypothesis.</p>



<p>One particular experiment involved a web portal I was involved in developing as part of an all remote team back just before the turn of the millennium. Smartphones didn’t exist, and the internet was still a fairly new concept to many people. The portal was for a growing internet service provider.</p>



<p>The work took a team of just 7 people 6 months to develop and the result was a cross platform solution that could deliver content, email, calendering and messaging. It was ahead of its time, and also supported voice interaction via mobile phone and delivery of content via WAP. What’s WAP? Google it – the days before smartphones were far from sophisticated when it comes to mobile access to the internet.</p>



<p>The result was good enough to be bought up by a large organisation as their portal solution. That company had already spent longer than 6 months with a significantly larger team trying to create the same thing without success. We were rightly proud of what we’d achieved in such a short time and with such a small team.</p>



<p>So, my experiment related to something that was already considered very efficient in code development terms.</p>



<h2><strong>We can rebuild it!</strong></h2>



<p>What I did was spend a couple of weeks at home recreating the solution from scratch. The code now belonged to a third party so I wanted a completely new version I could call my own. I used nothing from the original apart from my own knowledge of the problem and my experience solving it. The code repository was no longer accessible, so I couldn’t copy anything from it, even if I’d wanted to. To do so would have also been unethical as it didn’t belong to me. So, every line of code was genuinely built from scratch.</p>



<p>Within two weeks I had a fully working solution that did everything the original did (and a bit more). I’d achieved this in no time at all, and I’d generated a fraction of the code compared to the original solution.</p>



<p>How did I achieve this? Was I some kind of coding genius? Obviously not. I was a very competent coder, very much at the top of my game, but I was just one coder. No matter how good you are, there’s a limit to how fast you can type.</p>



<p>No. I achieved this because the code contained very little of the real value. That was all stored in my head. The design was in my head, and with hindsight I could see all its flaws. I was therefore able to create a much more efficient and effective design based on that learning. All the mistakes had been made, so I was able to get this version of the code right the first time. Most of my tests ran successfully, and debugging time was almost non-existent.</p>



<p>I now knew what wasn’t needed. All those things we’d built in to cater for anticipated needs could now be whittled down to the few that really proved useful. I understood every piece of technology, every protocol and every library, so there was no learning curve.</p>



<h2><strong>Mostly worthless</strong></h2>



<p>From this, I can conclude that of the 6 months of time spent by 7 people creating this solution, hardly any of it related to the code. It could be completely discarded and rebuilt by one person in under two weeks. What’s more, it could be radically improved at the same time.</p>



<p>So, this is why I assert that your code is worthless when compared to the overall effort invested in the creation of your solution. And I’d go further than that. I’d suggest that, contrary to what intuition might tell you, refactoring might be better achieved by throwing the code away and starting again.</p>



<p>It’s a scary thought. You might even consider it ridiculously farfetched. I wouldn’t expect you to agree with me based on a blog post. However, what I would recommend is that you give it some serious thought, and maybe conduct a similar experiment of your own. If you do, let me know how you get on. I’d be genuinely interested to find out.</p>



<p>Maybe I’m special? Maybe I’m the mythical ten times developer? Personally, I doubt it very much. After all, I was one of the people who took six months to build it the first time round.</p>



<p>Oh, and remember this next time you have to fix someone else’s code. It’s easy to feel superior and knowledgeable. It’s tempting to laugh at the obvious mistakes made by those who came before, but you have the advantage of hindsight. Maybe consider instead that you might be standing on the shoulders of those who carved out the first path for you to follow.</p>
                    
                    
	<nav aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>                </article></div>]]></description>
        </item>
    </channel>
</rss>