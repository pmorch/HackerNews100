<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 19 Aug 2025 14:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[UK drops demand for backdoor into Apple encryption (177 pts)]]></title>
            <link>https://www.theverge.com/news/761240/uk-apple-us-encryption-back-door-demands-dropped</link>
            <guid>44950600</guid>
            <pubDate>Tue, 19 Aug 2025 11:58:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/news/761240/uk-apple-us-encryption-back-door-demands-dropped">https://www.theverge.com/news/761240/uk-apple-us-encryption-back-door-demands-dropped</a>, See on <a href="https://news.ycombinator.com/item?id=44950600">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><a href="https://www.theverge.com/authors/jess-weatherbed"><img alt="Jess Weatherbed" data-chromatic="ignore" loading="lazy" width="36" height="36" decoding="async" data-nimg="1" srcset="https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/195820/JESSICA_WEATHERBED.0.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=48 1x, https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/195820/JESSICA_WEATHERBED.0.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=96 2x" src="https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/195820/JESSICA_WEATHERBED.0.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=96"></a></p><div><p><span aria-expanded="false" aria-haspopup="true" role="button" tabindex="0"><span id="follow-author-standard_article_details-dmcyOmF1dGhvclByb2ZpbGU6OTU="><span><span><svg width="9" height="9" viewBox="0 0 9 9" fill="none" xmlns="http://www.w3.org/2000/svg" aria-label="Follow"><path d="M5 0H4V4H0V5H4V9H5V5H9V4H5V0Z"></path></svg></span></span><span>Jess Weatherbed</span></span></span></p> <p><span>is a news writer focused on creative industries, computing, and internet culture. Jess started her career at TechRadar, covering news and hardware reviews.</span></p></div></div><div id="zephr-anchor"><p>The United Kingdom will no longer force Apple to provide backdoor access to secure user data protected by the company’s iCloud encryption service, according to US Director of National Intelligence Tulsi Gabbard.</p><p>“Over the past few months, I’ve been working closely with our partners in the UK, alongside @POTUS and @VP, to ensure Americans’ private data remains private and our Constitutional rights and civil liberties are protected,” <a href="https://x.com/DNIGabbard/status/1957623737232007638">Gabbard posted to X on Monday</a>. “As a result, the UK has agreed to drop its mandate for Apple to provide a ‘back door’ that would have enabled access to the protected encrypted data of American citizens and encroached on our civil liberties.”</p><p>This announcement follows the UK <a href="https://www.theverge.com/news/608145/apple-uk-icloud-encrypted-backups-spying-snoopers-charter">issuing a secret order</a> in January this year, demanding Apple provide it with backdoor access to encrypted files uploaded by users worldwide. In response, Apple pulled the ability for new users in the UK to sign up to its <a href="https://www.theverge.com/news/617273/apple-removes-encryption-advanced-data-protection-adp-uk-spying-backdoor">Advanced Data Protection</a> (ADP) encrypted iCloud storage offering, and challenged the order, winning the right to publicly discuss the case in April. Earlier this year, US officials started examining whether the UK order had violated the bilateral CLOUD Act agreement, which bars the UK and US from issuing demands for each other’s data.</p><p>This pressure from the US <a href="https://www.theverge.com/news/710504/uk-apple-encryption-back-door-icloud-adp-backing-down">sparked reports last month</a> that Britain would walk back the demands it issued to Apple, with one unnamed UK official telling the <em>Financial Times</em> that the UK “had its back against the wall,” and was looking for a way out. While it’s unclear if the UK would negotiate new terms with Apple that avoid implicating the data of US citizens, an unnamed US official told <a href="https://www.ft.com/content/ab0aba27-81e0-4ee5-bcbb-6bce85386e40"><em>The Financial Times</em></a> that such negotiations would not be faithful to the new agreement.</p><p>With the order now reportedly removed, it’s unclear if Apple will restore access to its ADP service in the UK. We have reached out to Apple for comment. The UK Home Office has refused to comment on the situation.</p><div><p><span><strong>Follow topics and authors</strong> from this story to see more like this in your personalized homepage feed and to receive email updates.</span></p><ul><li id="follow-author-article_footer-dmcyOmF1dGhvclByb2ZpbGU6OTU="><span aria-expanded="false" aria-haspopup="true" role="button" tabindex="0"><span><span><svg width="9" height="9" viewBox="0 0 9 9" fill="none" xmlns="http://www.w3.org/2000/svg" aria-label="Follow"><path d="M5 0H4V4H0V5H4V9H5V5H9V4H5V0Z"></path></svg></span><span>Jess Weatherbed</span></span></span></li><li></li><li></li><li></li><li></li><li></li></ul></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Custom telescope mount using harmonic drives and ESP32 (153 pts)]]></title>
            <link>https://www.svendewaerhert.com/blog/telescope-mount/</link>
            <guid>44949895</guid>
            <pubDate>Tue, 19 Aug 2025 09:46:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.svendewaerhert.com/blog/telescope-mount/">https://www.svendewaerhert.com/blog/telescope-mount/</a>, See on <a href="https://news.ycombinator.com/item?id=44949895">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong><a href="#manufacturing-and-assembly">TL;DR →</a></strong></p>
<h2 id="the-spark">The Spark</h2>
<div><figure><p><img alt="" loading="lazy" width="600" height="400" decoding="async" data-nimg="1" srcset="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/orion-opt-640.WEBP 1x, https://www.svendewaerhert.com/content/blog/telescope-mount/opt/orion-opt-1200.WEBP 2x" src="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/orion-opt-1200.WEBP"></p><figcaption>Early Orion Nebula capture</figcaption></figure></div>
<p>A few years back, I developed an interest in astrophotography thanks to YouTubers like <a href="https://www.youtube.com/c/nebulaphotos">Nebula Photos</a>. Armed with an OM System OM-5 and a 15-140mm Olympus lens, I managed some decent shots of the Orion Nebula from a tripod by taking 300 pictures with a 2-second exposure time and stacking them in <a href="https://siril.org/">Siril</a>.</p>
<p>Knowing I could achieve better results with tracking, I bought a Move Shoot Move tracker for around €200. It delivered longer exposures, but finding targets and achieving proper polar alignment remained challenging. I spent countless hours researching proper telescope mounts with GOTO and tracking capabilities, coming close to pulling the trigger on units ranging from €1,200 to €4,000. For a hobby I was still exploring, that investment always felt like a leap too far.</p>
<h2 id="the-pcb-awakening">The PCB Awakening</h2>
<p>Late 2024 I randomly came across this <a href="https://www.youtube.com/watch?v=EPH23zhPg50">YouTube video about custom PCB design</a> in my feed, and I was hooked immediately.</p>
<p>With a decent collection of microcontroller boards, the idea of ditching messy breadboards for clean, custom, affordable PCBs was revelatory. My first project replaced my home thermostat with an ESP32-based design with e-paper display, interlocking finger patterns for the original carbon rubber dome switches and space for a Bosch BME680 sensor breakout.</p>
<p>After completing that project, I revisited the telescope mount idea - this time armed with newfound PCB design skills. The question emerged: "How hard can it be?"</p>
<h2 id="down-the-research-rabbit-hole">Down the Research Rabbit Hole</h2>
<p>The plan crystallized around harmonic drives (strain wave gears) - the favorite of modern telescope mounts for their excellent performance in compact packages. The concept seemed straightforward: motor, microcontroller, optional gearing, and a strain wave gear, all housed in a sturdy enclosure.</p>
<p>I divided my time between scouring AliExpress for components and studying existing DIY builds. AliExpress proved to have the worst search functionality in e-commerce history. Google's <code>site:aliexpress.com</code> became my most reliable tool. Hours were spent analyzing technical drawings of every available harmonic drive, searching for workable options and trying to not lose my mind in the myriad of near-identical items from multiple vendors.</p>
<p>Some other DIY projects provided me with invaluable information:</p>
<ul>
<li><a href="https://github.com/polvinc/HEMY">HEMY</a> - Harmonic drive equatorial mount</li>
<li><a href="https://github.com/romanhujer/HrEM">HrEM</a> - Harmonic reduction equatorial mount</li>
<li><a href="https://github.com/polvinc/DHEM">DHEM</a> - Dual harmonic equatorial mount</li>
<li><a href="https://astrophilos.com/diy-eq-mount-v2/">DIY EQ Mount V2</a> - Comprehensive build guide</li>
</ul>
<p>Soon I was looking into the workings of stepper motors, BLDC motors, Field Oriented Control (FOC), and various open source FOC implementations like <a href="https://simplefoc.com/">SimpleFOC</a>.</p>
<h2 id="design-decisions">Design Decisions</h2>
<p>Honestly, this build didn't require a custom PCB. A FYSETC E4 board or even a breadboarded ESP32 would have worked. But I wanted to create something beautiful from scratch, achieving that "I made this" feeling. The housing, however, absolutely needed to be sturdy and custom-designed.</p>
<p>I started learning <a href="https://www.freecad.org/">FreeCAD</a> alongside <a href="https://www.kicad.org/">KiCad</a>, producing about eight throwaway housing designs before the concept solidified.</p>
<p><img alt="FreeCAD Design" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" srcset="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/freecad-opt-828.WEBP 1x, https://www.svendewaerhert.com/content/blog/telescope-mount/opt/freecad-opt-1920.WEBP 2x" src="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/freecad-opt-1920.WEBP">
<em>Housing design iterations in FreeCAD - multiple attempts to get the geometry right</em></p>
<h3 id="the-architecture">The Architecture</h3>
<ul>
<li><strong>RA Axis</strong>: 42AIM15 Servo motor with Type 17 harmonic drive (100:1 reduction)</li>
<li><strong>DEC Axis</strong>: MKS Servo042D stepper with Type 14 harmonic drive (100:1 reduction)</li>
<li><strong>Mounting</strong>: Arca Swiss plate (compatible with existing Move Shoot Move wedge)</li>
<li><strong>Operation</strong>: GEM or ALTAZ modes</li>
<li><strong>Microcontroller</strong>: ESP32-S3</li>
<li><strong>Power</strong>: USB-C power delivery up to 24V/4A</li>
<li><strong>Motor driving</strong>: step/dir/en ports via the ULN2003 + MODBUS and CANBUS ports</li>
<li><strong>Extra</strong>: Leftover GPIO pins broken out for future use</li>
</ul>
<p>The 42AIM15 provides 32,768 steps per revolution, configurable to 65,536 steps with 2x oversampling. The MKS Servo042D supports microstepping up to 1/256. Both motors were chosen for their integrated drivers, dramatically simplifying PCB design. With FOC and microstepping, other builds demonstrated decent tracking accuracy without intermediate reduction. Via CANBUS I can control the microstepping regime of the stepper motor. During slews I set the microstepping to 128 from 256, allowing a higher slew speed in degrees / second without putting too much load on the microprocessor.</p>
<h2 id="the-pcb-design">The PCB Design</h2>
<p><img alt="KiCad PCB Design" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" srcset="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/kicad-opt-828.WEBP 1x, https://www.svendewaerhert.com/content/blog/telescope-mount/opt/kicad-opt-1920.WEBP 2x" src="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/kicad-opt-1920.WEBP">
<em>PCB layout in KiCad showing the semi-circular form factor and component placement</em></p>
<p>The PCB takes a semi-circular form factor, designed to fit snugly within the housing. This unique shape and placement didn't significantly increase the size of the mount, which I already felt was becoming quite beefy. I used an ESP32-S3 Microcontroller without the PCB antenna, so I could fit the module anywhere on the board. The first traces I routed were power and the USB differential pair. I managed to place the microcontroller in such a way that the differential pair goes in a straight line.</p>
<p>Power is available through USB-C thanks to the AP33772 IC which negotiates power via the CC pins on the USB-C connector. Power banks supporting USB PD 3.0 and able to deliver 12V are excellent for making this entire setup portable. Major props to the guys from CentyLab for their <a href="https://github.com/CentyLab/PicoPD">PicoPD</a> schematics and PCB designs using the AP33772. This was a big inspiration for laying out my components. The output trace is very wide to support 24V and also has 4 large capacitors. In hindsight, those caps were maybe a bit overkill because the motors for this usecase hardly produce any sudden power peaks, and a good USB PD power supply would probably already have a decent enough amount of capacitance.</p>
<p>During my research I noticed a lot of integrated motors with CANBUS/MODBUS features, so I added functionality for that as well. The remaining GPIO pins of the ESP32 I simply routed somewhere nearer to the edge of the board so they can be used for other purposes in the future.</p>
<p>Some thought has also gone into choosing the right PCB mounted connectors. I settled on the JST PH series for their compactness and their ability to carry 2A per pin. Matt Millman's <a href="https://www.mattmillman.com/info/crimpconnectors/common-jst-connector-types/">Common JST Connector Types</a> was a great resource for making the final selection.</p>
<h3 id="the-first-pcb-mistake">The First PCB Mistake</h3>
<p>Initially my design was around the AP33772S IC. A last-minute component substitution at JLCPCB - changing the originally specified IC due to stock issues - should have triggered a complete pin compatibility review. Impatience won, and I ordered anyway, replacing the AP33772S with the AP33772.</p>
<p>The result: I2C communication was impossible due to NO-CONNECT pins erroneously tied to ground, and manually getting the VBUS voltage to 24V using an external PD trigger board caused a sudden tiny hole to appear on the chip package, followed by blue smoke. Lesson learned. Version 2 underwent exhaustive verification, and worked flawlessly when it arrived. I also included significantly more test points throughout the board, whch is a practice I'm going to keep going forward. The version 1 boards still work for controlling the mount, but they lack the intergated power delivery.</p>
<p><img alt="Completed PCB" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" srcset="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/pcb-opt-828.WEBP 1x, https://www.svendewaerhert.com/content/blog/telescope-mount/opt/pcb-opt-1920.WEBP 2x" src="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/pcb-opt-1920.WEBP">
<em>Version 2 of the custom PCB</em></p>
<h2 id="onstepx-integration">OnStepX Integration</h2>
<p><a href="https://github.com/hjd1964/OnStepX">OnStepX</a> is telescope mount firmware supporting multiple microcontroller platforms, originally developed by Howard Dutton to save his mount from obsolescence. It has since grown into a major open source project with substantial community support.</p>
<p>Without OnStepX, DIY telescope mounts like this wouldn't be feasible for many builders. The ESP32 WiFi support became my preferred communication method, though initial testing revealed WiFi instability during slewing operations. Not surprising once you understand that slewing to a target significantly increases the number of pulses per second sent to the motors, and everything became just too much to handle for our little ESP32.</p>
<p>Two changes resolved the stability issues:</p>
<ol>
<li>Reducing slew rates or increasing step sizes with lower microstep divisions (configurable on-the-fly through OnStepX hooks in the generic motor class)</li>
<li>Configuring the device as a WiFi client rather than access point</li>
</ol>
<p>Apart from adding a custom pin layout file and some code to lower the microstep subdivisions during slewing, OnStepX really just worked out of the box.</p>
<h2 id="manufacturing-and-assembly">Manufacturing and Assembly</h2>
<p>All manufacturing was handled by JLCPCB - both PCB fabrication and CNC machining. Sending CNC production files without 3D printing prototypes first was a calculated gamble that paid off; everything fit (almost) perfectly upon arrival.</p>
<p><img alt="Assembly Process" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" srcset="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/build-8-opt-828.WEBP 1x, https://www.svendewaerhert.com/content/blog/telescope-mount/opt/build-8-opt-1920.WEBP 2x" src="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/build-8-opt-1920.WEBP">
<em>Mount fully assembled. Yes, those are 5 euro rainwater pipe clamps holding the telescope</em></p>
<p>One minor adjustment was required: the red cap at the RA axis rubbed against the harmonic drive. The oversight occurred because I modeled the cup interior without accounting for the harmonic drive mounting screws. I used a simple spacer to fix the problem. I'm very impressed with the manufacturing quality of the components. To assemble everything I just needed to thread the holes with some M3 or M4 taps and bolt everything together. I opted for manual tapping to save on manufacturing cost.</p>
<h2 id="real-world-performance">Real-World Performance</h2>
<p>Countless nights were spent mastering polar alignment, scope setup, and navigating the quirks of <a href="https://kde.org/applications/education/org.kde.kstars/">KStars</a>, <a href="https://docs.kde.org/trunk5/en/kstars/kstars/ekos.html">Ekos</a>, and <a href="https://indilib.org/">INDI server</a>. The first cloudless nights usually ended in frustration: between polar alignment, WiFi issues, indi server issues, camera issues, slipping motor couplings, and software configuration, dawn would arrive before I captured a single frame. At one point, I celebrated achieving 0.1 arcsecond precision! - only to discover <a href="https://openphdguiding.org/">PHD2</a> was configured with incorrect focal length settings and reported skewed results.</p>
<p>The best verified precision achieved so far is 1-2 arcseconds observed with PHD2, more than adequate for 30-second exposures with a 600mm focal length Sigma lens. I continue using my camera in interval mode, ensuring the signal is somewhere in the middle of the histogram. ISO 3200 usually, with sensor stabilization and noise suppression disabled. Stacking is performed in <a href="https://siril.org/">Siril</a>, though multi-night stacking remains a goal requiring significant planning, luck, and consistency.</p>
<p><img alt="Telescope Mount in Action" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" srcset="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/build-7-opt-828.WEBP 1x, https://www.svendewaerhert.com/content/blog/telescope-mount/opt/build-7-opt-1920.WEBP 2x" src="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/build-7-opt-1920.WEBP">
<em>The completed mount setup</em></p>
<h2 id="the-economics">The Economics</h2>
<p>Total project cost reached approximately €1,700, including reusable tools like thread taps, various M3/M4/M5 hardware and JST Connector tools. Sometimes bulk purchases or shipping minimums inflated costs. I also bought 2x unused MS6010v3 motors for experimenting/evaluating for a potential future super compact build. And the extra cost of the PCB revision ofcourse.</p>
<p>Calculating single-unit costs yields approximately €800, with potential for reduction in larger quantities. Compared to commercial GOTO mounts in the €1,200-€4,000 range, the economics are competitive - but economics was never the primary driver.</p>
<h3 id="detailed-cost-breakdown">Detailed Cost Breakdown</h3>
<table><thead><tr><th>Component</th><th>Category</th><th>Total Cost (€)</th><th>Single Unit (€)</th></tr></thead><tbody><tr><td>Cuttin Tap 1/4-20 UNC</td><td>Tools</td><td>2.89</td><td>1</td></tr><tr><td>Cutting Tap Form D - UNC 3/8 x 16</td><td>Tools</td><td>12.88</td><td>1</td></tr><tr><td>220 pieces M5 screw set</td><td>Tools</td><td>10.59</td><td>1</td></tr><tr><td>440 pieces M4 screw set</td><td>Tools</td><td>13.21</td><td>1</td></tr><tr><td>440 pieces M3 screw set</td><td>Tools</td><td>9.14</td><td>1</td></tr><tr><td>Metric tap set MetricssMann M53250-B</td><td>Tools</td><td>27.38</td><td>1</td></tr><tr><td>PEBA JST PH 2.0 Crimping set</td><td>Tools</td><td>31.11</td><td>1</td></tr><tr><td><strong>Tools Subtotal</strong></td><td></td><td><strong>107.2</strong></td><td></td></tr><tr><td>MKS SERVO42D NEMA17 Closed Loop Stepper Motor</td><td>Mount</td><td>73.2</td><td>36.6</td></tr><tr><td>Harmonic drive 2x</td><td>Mount</td><td>144.44</td><td>144</td></tr><tr><td>Import tax harmonic drive 2x</td><td>Mount</td><td>30.24</td><td>100</td></tr><tr><td>Servo motor 2x</td><td>Mount</td><td>216.46</td><td>151.7</td></tr><tr><td>Import tax servo motor x2</td><td>Mount</td><td>86.94</td><td></td></tr><tr><td>MS6010v3 (2x)</td><td>Research</td><td>216.94</td><td></td></tr><tr><td>Import tax MS6010v3 (2x)</td><td>Research</td><td>57.05</td><td></td></tr><tr><td>CNC parts</td><td>Mount</td><td>215.76</td><td>273.8</td></tr><tr><td>Import tax CNC</td><td>Mount</td><td>58.04</td><td></td></tr><tr><td>PCB (5x)</td><td>Mount</td><td>178.74</td><td></td></tr><tr><td>Import tax PCB</td><td>Mount</td><td>33.54</td><td></td></tr><tr><td>PCB2 (5x)</td><td>Mount</td><td>178.74</td><td>42.46</td></tr><tr><td>Import tax PCB2</td><td>Mount</td><td>33.54</td><td></td></tr><tr><td>Extra Harmonic wave generator 8mm</td><td>Mount</td><td>44.59</td><td>44.59</td></tr><tr><td>Import customs duty harmonic wave generator</td><td>Mount</td><td>36</td><td></td></tr><tr><td><strong>Total Project Cost</strong></td><td></td><td><strong>1711.42</strong></td><td><strong>799.15</strong></td></tr></tbody></table>
<p><em>Single unit costs represent what one mount would cost without bulk purchases, shipping minimums, and reusable tools.</em></p>
<h2 id="anyway">Anyway</h2>
<p>It was totally worth it.</p>
<p>The failed Version 1 PCB taught me never to skip verification steps, regardless my occasional impatience. OnStepX opened up the world of equatorial mount operation and just the joy of watching that thing slew across the sky. FreeCAD modeling skills improved dramatically through multiple housing iterations. I will probably spend more attention to documenting during future builds: writing down thoughts along the way and taking better pictures/screenshots/recordings.</p>
<p>Sure, I spent about as much as a commercially available mount, but I gained so much more. Plus I have a freaking mount that tracks stars!</p>
<p>That feeling when you point at a nebula, watch it track perfectly, and know (almost) exactly how everything works, cause you built it. ✨</p>
<p><img alt="Galaxy Image Captured" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" srcset="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/galaxy-opt-828.WEBP 1x, https://www.svendewaerhert.com/content/blog/telescope-mount/opt/galaxy-opt-1920.WEBP 2x" src="https://www.svendewaerhert.com/content/blog/telescope-mount/opt/galaxy-opt-1920.WEBP">
<em>M51 Whirlpool Galaxy, 23.5 million lightyears away</em></p>
<h2 id="image-gallery">Image Gallery</h2>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google is killing the open web (101 pts)]]></title>
            <link>https://wok.oblomov.eu/tecnologia/google-killing-open-web/</link>
            <guid>44949857</guid>
            <pubDate>Tue, 19 Aug 2025 09:38:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wok.oblomov.eu/tecnologia/google-killing-open-web/">https://wok.oblomov.eu/tecnologia/google-killing-open-web/</a>, See on <a href="https://news.ycombinator.com/item?id=44949857">Hacker News</a></p>
<div id="readability-page-1" class="page"><article class="page" lang="en">







<section id="pagebody" role="main">
<p><a href="http://en.wikipedia.org/wiki/Google">Google</a> is managing to achieve what <a href="http://en.wikipedia.org/wiki/Microsoft">Microsoft</a> couldn't: killing the open <a href="http://en.wikipedia.org/wiki/World%20Wide%20Web">web</a>.
The efforts of <a href="http://en.wikipedia.org/wiki/GAFAM">tech giants</a> to gain control of and enclose the commons for extractive purposes
have been clear to anyone who has been following the history of the <a href="http://en.wikipedia.org/wiki/Internet">Internet</a> for at least the last decade,
and the adopted strategies are varied in technique as they are in success,
from <a href="http://en.wikipedia.org/wiki/Embrace%2C%20Extend%2C%20Extinguish">Embrace, Extend, Extinguish</a> (<a href="https://wok.oblomov.eu/tag/EEE/" rel="tag">EEE</a>)
to monopolization and lock-in.</p>

<p>What I want to talk about in this article is the war Google has been waging on <a href="http://en.wikipedia.org/wiki/XML">XML</a> for over a decade,
why it matters that they've finally encroached themselves enough to get what they want,
and what we can do to fight this.</p>

<div>
<ol>
	<li><a href="#index1h1">Google is killing the open web</a>
	<ol>
		<li><a href="#alittlebitofhistory">A little bit of history</a>
		</li>
		<li><a href="#googleswaronxmlasaproxyforthewaragainsttheopenweb">Google's war on XML as a proxy for the war against the open web</a>
		</li>
		<li><a href="#whyitmatters">Why it matters</a>
		<ol>
			<li><a href="#dorian">Dorian Taylor on XSLT</a>
			</li>
		</ol>
		</li>
		<li><a href="#whatwecandoaboutit">What we can do about it</a>
		<ol>
			<li><a href="#makeyourselfbeseen">Make yourself be seen</a>
			</li>
			<li><a href="#makeyourselfbeheard">Make yourself be heard</a>
			</li>
			<li><a href="#buildthealternative">Build the alternative</a>
			</li>
		</ol>
		</li>
		<li><a href="#afterword">Afterword</a>
		</li>
		<li><a href="#nameandshame">Name and shame</a>
		</li>
		<li><a href="#madethenews">Made the news</a>
		</li>
	</ol>
	</li>
</ol>
</div>

<h2 id="alittlebitofhistory"><a name="index1h2"></a>A little bit of history</h2>

<p>Google entered the browser market at a time when web development was starting to see the light again
after Microsoft's “win” of the <a href="http://en.wikipedia.org/wiki/First%20browser%20war">First browser war</a> through the abuse of its operating system's monopoly
by shipping its <a href="http://en.wikipedia.org/wiki/Internet%20Explorer">Internet Explorer</a> for free and thus cutting off «<a href="http://en.wikipedia.org/wiki/Netscape">Netscape</a>'s air supply»,
as intended.</p>

<p>What managed to break through Microsoft's short-lived victory was an alliance of browsers
(my favorite <a href="https://wok.oblomov.eu/tecnologia/opera-requiem/">Opera</a> on its Presto engine,
<a href="http://en.wikipedia.org/wiki/Mozilla">Mozilla</a>'s <a href="http://en.wikipedia.org/wiki/Firefox">Firefox</a> on its Gecko engine,
and the newborn Safari from <a href="http://en.wikipedia.org/wiki/Apple%20Inc%2E">Apple</a>,
whose <a href="http://en.wikipedia.org/wiki/WebKit">WebKit</a> engine was forked from the <a href="http://en.wikipedia.org/wiki/KHTML">KHTML</a> engine that was being developed
for the <a href="http://en.wikipedia.org/wiki/KDE">KDE</a> <a href="http://en.wikipedia.org/wiki/Linux">Linux</a> desktop environment)
that decided to leverage their standards compliance to reinforce each other's position
against the crippling effect of Microsoft's dominance
—a dominance that Microsoft tried to protect resorting <a href="https://press.opera.com/2003/02/14/opera-releases-bork-edition/" title="Opera releases “Bork” edition">to the vilest tricks</a>.</p>

<p>Google entered the market heavily abusing its dominance in web search
to push the adoption of its <a href="http://en.wikipedia.org/wiki/Google%20Chrome">Chrome</a> browser,
a practice not unlike the one used by Microsoft to push the adoption of IE,
and of equally questionable legality and moral standing,
a thing which was frequently overlooked with several excuses,
not least the fact that Chrome was built on an open source core,
<a href="http://en.wikipedia.org/wiki/Chromium">Chromium</a>, that was mostly assembled from software and libraries
developed by other companies (primarily, Mozilla and Apple).</p>

<p>In the years of Chrome's release,
the Internet was undergoing massive changes,
with the emergence of centralized social media platforms like <a href="http://en.wikipedia.org/wiki/Facebook">Facebook</a>
that started eroding the previous distributed social network of blogging platforms,
Google's own <a href="http://en.wikipedia.org/wiki/Gmail">Gmail</a> mail service gaining ground over
both <abbr title="Internet Service Provider">ISP</abbr> offering
and other “cloud” offers like <a href="http://en.wikipedia.org/wiki/Yahoo%21">Yahoo!</a>'s and Microsoft's <a href="http://en.wikipedia.org/wiki/Hotmail">Hotmail</a>,
and mobile connectivity growing beyond “professionals”,
thanks mostly to Apple's <a href="http://en.wikipedia.org/wiki/iPhone">iPhone</a> and
Google's own at-the-time recent acquisition of <a href="http://en.wikipedia.org/wiki/Android%20%28operating%20system%29">Android</a>,
plus some soon-to-be minor players <a href="https://wok.oblomov.eu/tecnologia/n900/">I've talked about in the past</a>.</p>

<p>For the purposes of our discussion,
these changes had two major points of focus in terms of website development.</p>

<p>On the one hand, web developers started giving more attention to standards compliance,
as it gave them more opportunities towards the growing user base of mobile users,
which were unlikely to have the desktop-dominant Internet Explorer as browser.
This helped accelerate the demise of IE
(which was still going strong when Chrome was first released)
—whose flaky standards compliance was ultimately responsible for its demise
nearly a decade later, and subsequently for the complete discontinuation of its line
(after the brief attempt of a reprise under the legacy <a href="http://en.wikipedia.org/wiki/Microsoft%20Edge%20Legacy">Edge</a> moniker)—
and emboldened the “underdogs” of the time (Mozilla, Apple, Opera).</p>

<p>On the other hand, there was a distinct shift towards centralization of web services,
which in turn accelerated the development of <a href="http://en.wikipedia.org/wiki/web%20application">web application</a>s,
graphical user interfaces for the underlying (centralized) services
that effectively relied on the browser(s) as cross-platform toolkits,
an approach that would later give birth to the abomination
known as <a href="http://en.wikipedia.org/wiki/Electron%20%28software%20framework%29">Electron</a>
and the security nightmare better known as <a href="http://en.wikipedia.org/wiki/node%2Ejs">node.js</a>.</p>

<p>Of course, Google had a primary interest in making web apps a credible alternative to desktop applications,
what with their already-mentioned mail service and the recently-acquired-and-turned-web-app <a href="http://en.wikipedia.org/wiki/Google%20Maps">Google Maps</a>.
And since their browser was mostly a collection of existing <a href="https://wok.oblomov.eu/tag/floss/" rel="tag">FLOSS</a> software stapled together,
they could focus their development effort in creating a faster implementation of <a href="https://wok.oblomov.eu/tag/javascript/" rel="tag">JavaScript</a>,
better known as <a href="http://en.wikipedia.org/wiki/V8%20%28JavaScript%20engine%29">V8</a>.
Never mind the fact that even years later
<a href="https://github.com/mathjax/MathJax/wiki/Understanding-mathjax-performance#remarks-on-speed" title="MathJax performance / Remarks on speed">native implementations of any useful feature would remain faster and cheaper than JavaScript</a>.</p>

<p>But even before their direct involvement in browser development,
Opera and Mozilla had started taking their distance from the <a href="http://en.wikipedia.org/wiki/W3C">W3C</a>
standardizing efforts and set up the <a href="http://en.wikipedia.org/wiki/WHATWG">WHATWG</a>,
a consortium of browser developers dedicated to coordinate rapid development of new web features
without passing through the perceived slow W3C standardization process.</p>

<p>In truth, as it would become clear a few years later
—and even more so with Google effectively taking over the WHATWG and turning into
a sockpuppet to give a semblance of independence to their choices—
the main purpose of the WHATWG was to hijack the development of web technologies
to the benefits of the corporate investors,
whereas the W3C, with all its flaws,
had mostly given priority to features that would be of more general interest.</p>

<p>(It is not by chance that the most controversial standard to ever come out of the W3C
has probably been the <a href="http://en.wikipedia.org/wiki/Encrypted%20Media%20Extensions">Encrypted Media Extensions</a>,
released as a failed attempt to remain relevant in the web space,
and resulting instead of a critical strike against their own credibility as stewards of the open web.)</p>

<h2 id="googleswaronxmlasaproxyforthewaragainsttheopenweb"><a name="index2h2"></a>Google's war on XML as a proxy for the war against the open web</h2>

<p>Arguably, the turning point for the centralization of the web was the year <a href="http://en.wikipedia.org/wiki/2013">2013</a>.
This is essentially the year where <a href="http://en.wikipedia.org/wiki/GAFAM">GAFAM</a> stopped trying to pretend they liked to play nice,
and started to “pull the reins in” on interoperability.
Coincidentally, <a href="https://wok.oblomov.eu/tecnologia/opera-requiem-2/">it's also the year Opera stopped being Opera</a>,
but I'll talk about this some more <a href="#afterword">in the afterword</a>.</p>

<p>Let's see a few of the major events relevant to our discussion:</p>

<ol>
<li>2013 is the year Google decides to sunset <a href="http://en.wikipedia.org/wiki/Google%20Reader">Google Reader</a>,
a (if not the most) widely used <a href="http://en.wikipedia.org/wiki/web%20feed">web feed</a> aggregator (for <a href="https://wok.oblomov.eu/tag/rss/" rel="tag">RSS</a> and Atom feeds);</li>
<li>2013 is the year Google decides to close <a href="http://en.wikipedia.org/wiki/XMPP">XMPP</a> server-to-server federation in their <a href="http://en.wikipedia.org/wiki/Google%20Chat">Google Chat</a> service;
<a href="http://en.wikipedia.org/wiki/Facebook">Facebook</a> will to the same with their Messenger product the following year;</li>
<li>2013 is the year Google <a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/zIg2KC7PyH0/m/a3VeYmvEAAAJ" title="Intent to Deprecate and Remove: XSLT">first proposes the removal of XSLT</a>, a proposal that is so unpopular
that it will continue receiving comments <em>against</em> it as far as 5 years later (the last comment in the thread is from 2018);</li>
<li>2013 is the year Google <a href="https://issues.chromium.org/issues/40289400#comment33" title="MathML is not ready for production">removes the just-introduced MathML support from Chrome</a>;
it will take 10 years and <a href="https://mathml.igalia.com/" title="MathML in Web Browsers - Igalia">an external company</a> to bring <a href="https://wok.oblomov.eu/tag/mathml/" rel="tag">MathML</a> support back into the browser.</li>
</ol>

<p>This was just the beginning. Several other actions were undertaken or attempted in the following years.</p>

<ol>
<li>in 2015, the WHATWG introduces the <a href="https://fetch.spec.whatwg.org/">Fetch API</a>,
purportedly intended as the modern replacement for the old <a href="http://en.wikipedia.org/wiki/XMLHttpRequest">XMLHttpRequest</a>;
prominently missing from the new specification is any mention or methods to manage <a href="https://wok.oblomov.eu/tag/XML/" rel="tag">XML</a> documents,
in favor of <a href="http://en.wikipedia.org/wiki/JSON">JSON</a> that instead gets a dedicated document body presentation method;</li>
<li>in 2015, <a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/5o0yiO440LM" title="Intent to Deprecate: SMIL">Google proposes deprecating SMIL</a>, the standard for declarative animation and interactivity in <a href="http://en.wikipedia.org/wiki/SVG">SVG</a>;
I have <a href="https://wok.oblomov.eu/tecnologia/switch-element/">written in the past</a> about the usefulness of <a href="https://wok.oblomov.eu/tag/smil/" rel="tag">SMIL</a> and why not only it must not be deprecated,
but its use should actually be integrated into <a href="https://wok.oblomov.eu/tag/html/" rel="tag">HTML</a>, <a href="https://www.w3.org/TR/XHTMLplusSMIL/" title="XHTML+SMIL Profile">as noted by the W3C</a>;</li>
<li><a name="amp">in 2015, Google also </a><a href="https://blog.google/products/search/introducing-accelerated-mobile-pages/" title="Introducing Accelerated Mobile Pages">announces</a> the <a href="http://en.wikipedia.org/wiki/Accelerated%20Mobile%20Pages">Accelerated Mobile Pages</a> project,
purportedly as a way to make web pages more accessible and faster to load on mobile,
which coincidentally relied heavily on leveraging large <abbr title="Content Distribution Network">CDN</abbr>s
like Google to cache contents (and optionally pre-render it);
nevermind the facts that the seminal <a href="https://alistapart.com/article/responsive-web-design/" title="Responsive Web Design">Responsive Web Design</a> article on how to design for different screen sizes was from 2010,
that the <code>srcset</code> attribute for images to support different-sized screens was already supported by at-the-time current desktop and mobile browsers,
and that the primary reasons why webpages weren't fast to load on mobile
was because of the so-called <a href="https://idlewords.com/talks/website_obesity.htm" title="The Website Obesity Crisis (2015)">web obesity crisis</a>
which had been known <a href="https://web.archive.org/web/20120524025537/https://gigaom.com/2012/05/23/the-growing-epidemic-of-page-bloat/" title="The growing epidemic of page bloat (Internet Archive mirror)">since 2012 at least</a>,
and that the primary reason why AMP pages loaded faster was because they came with one tenth of the useless crap
attached to the “regular” pages
—so the only actual benefit from AMP was to <em>force</em> webdevs into writing leaner pages, with at least a modicum of responsivity,
(and of course, for Google, to encourage them to funnel everything through Google's —or any other tech giant— servers
for easier metric collection, faster ad serving, and more user profiling);</li>
<li><a name="nokeygen">still in 2015, Google announces the </a><a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/pX5NbX0Xack" title="(Pre-)Intent to Deprecate: <keygen> element and application/x-x509-*-cert MIME handling">intent to deprecate the <code>keygen</code> element</a>,
a little-known but powerful security feature that simplified the generation of user-controlled cryptographic key pairs
for secure communication between the client and server;
you can read more about it in <a href="http://en.wikipedia.org/wiki/Tim%20Berners%2DLee">Tim Berners-Lee</a> <a href="https://lists.w3.org/Archives/Public/www-tag/2015Sep/0000.html" title="Agenda: <keygen> being destroyed when we need it">reaction</a>,
and in Hugo Landau's <a href="https://www.devever.net/~hl/web-keygen" title="Memoirs from the old web: The KEYGEN element">relevant “Memoir from the old web”</a>;
of note, <abbr='tim berners-lee'="">TBL's primary interest in this element was
to help build <a href="http://en.wikipedia.org/wiki/Solid%20%28web%20decentralization%20project%29">Solid</a>,
an incremental improvement on the WWW to make it more resistant to the centralization his original idea had been perverted into
(see also <a href="https://github.com/solid/solid/issues/134" title="Keygen is depreciated #134">the relevant issue in Solid's issue tracker</a>);
the importance of simplified handling of user certificates and the role they play in <a href="http://en.wikipedia.org/wiki/Mutual%20authentication">Mutual authentication</a>
can also be surmised by it being one of the features of the lightweight <a href="http://en.wikipedia.org/wiki/Gemini%20protocol">Gemini protocol</a>
that was also born as a response to the centralization and consequent complexification of the World Wide Web;</abbr='tim></li>
<li>in 2018, Mozilla removes RSS support from Firefox starting from version 64,
and actively prevents opening them in-browser, giving them an <em>even worse treatment</em> than generic XML files,
for which it keeps showing the structure
(for example: compare how your browser handles <a href="https://wok.oblomov.eu/data/tecnologia.stats.xml">the usage stats XML for this column</a>
with the way it handles <a href="https://wok.oblomov.eu/tecnologia/index.rss">the RSS feed</a> and <a href="https://wok.oblomov.eu/tecnologia/index.atom">the Atom feed</a>);
the official reason is that the “Live Bookmarks” feature couldn't be easily ported to the new architecture;
the fact that support for RSS could still be implemented via extensions, that Mozilla did not ship an extension to replace even just partially
the Live Bookmarks feature —leaving its users in the hands of potentially insecure third-part extensions—
and that feeds got an even worse treatment than generic XML document
show that the official reason is just an excuse;
this is one of the major cracks in the Mozilla façade,
as it starts to show that their existence is just <a href="http://en.wikipedia.org/wiki/controlled%20opposition">controlled opposition</a> for Google <a href="https://www.jwz.org/blog/2024/06/mozillas-original-sin/" title="Mozilla's Original Sin">to avoid antitrust issues</a>
—what Google wants goes, and Google doesn't want web feeds, so web feeds have to go;</li>
<li><a name="mv3">in 2019, Google </a><a href="https://security.googleblog.com/2019/06/improving-security-and-privacy-for.html" title="Improving Security and Privacy for Extensions Users">announces</a> a number of changes to purportedly make browser extensions “safer” for users,
starting the work for what would later become the <a href="https://developer.chrome.com/docs/extensions/develop/migrate/what-is-mv3" title="Extensions / Manifest V3">Extension Manifest V3</a>;
it is immediatelly apparent that at least some of the changes introduced
are primarily intended to prevent adblockers from working, and
<a href="https://www.eff.org/deeplinks/2019/07/googles-plans-chrome-extensions-wont-really-help-security" title="Google’s Plans for Chrome Extensions Won’t Really Help Security">don't actually do much to improve security or privacy</a>;
despite <a href="https://www.eff.org/deeplinks/2021/12/chrome-users-beware-manifest-v3-deceitful-and-threatening" title="Chrome Users Beware: Manifest V3 is Deceitful and Threatening">several</a> <a href="https://www.eff.org/deeplinks/2021/12/googles-manifest-v3-still-hurts-privacy-security-innovation" title="Google’s Manifest V3 Still Hurts Privacy, Security, and Innovation">reports</a>
against the at best ineffective and at worst detrimental changes proposed,
in the next years Google will <a href="https://developer.chrome.com/docs/extensions/develop/migrate/mv2-deprecation-timeline" title="Manifest v2 Deprecation Timeline">move on with the timeline</a>
to deprecate the previous extension APIs and finally succeed in its ad-blocking-blocking efforts;
although this change is not <em>currently</em> relevant for the XML/<wbr>XSLT focus of this article,
I mention it not only because it is one of the many examples of Chrome becoming
less of a <a href="http://en.wikipedia.org/wiki/User%20Agent">User Agent</a> and more of a “Google tool on your computer” over time,
but because <em>this</em> aspect is important for the future of client-side XML and XSLT,
<a href="#extensions">as I will discuss later</a>;</li>
<li>in 2023, Google renames their chatbot from Bard to
<a href="https://en.wikipedia.org/wiki/Gemini_(chatbot)#Launch_of_Gemini" title="Gemini (chatbot) | Launch of Gemini">Gemini</a> thereby completely eclipsing
<a href="http://en.wikipedia.org/wiki/Gemini%20%28protocol%29">the 4-year-old independent protocol by the same name</a>;
this is <em>possibly</em> coincidental, which would make it the <em>only</em>
unintentional attack on the open web by Google in the last 15 or so years
—and at this point even that is doubtful;</li>
<li>in 2023, Google proposes the <a href="http://en.wikipedia.org/wiki/Web%20Environment%20Integrity">Web Environment Integrity</a> API,
<a href="https://wok.oblomov.eu/tecnologia/preparing-end-open-web/">of which I've talked at the time</a>;
although this is only tangentially related to the XML-focused initiatives that are the subject of this article,
it is relevant to mention here as it is another example indicative of the push to make browsers less <a href="http://en.wikipedia.org/wiki/User%20Agent">User Agent</a>s
and more <a href="https://www.eff.org/deeplinks/2023/08/your-computer-should-say-what-you-tell-it-say-1" title="Your Computer Should Say What You Tell It To Say">corporate-controlled spyware</a>;</li>
<li>in 2023, Google <a href="https://mjtsai.com/blog/2025/06/17/chrome-doesnt-support-jpeg-xl/" title="Chrome Doesn’t Support JPEG XL">kills off</a> support for the <a href="http://en.wikipedia.org/wiki/JPEG%20XL">JPEG XL</a> image format,
introduced barely two years before,
depriving the Internet of a format that would have finally delivered on the promise of a unified format
to provide <a href="https://cloudinary.com/blog/contemplating-codec-comparisons" title="Contemplating Codec Comparisons">competitive</a> compression —both lossless and lossy—, progressive decoding, transparency, and animation,
which would have allowed it to replace the widespread (and less efficient) JPEG, PNG and GIF formats
that have been the staple of the web for the last decades;
this also is not directly related to XML (unless the reason for the hate is that JPEG&nbsp;XL supports <a href="http://en.wikipedia.org/wiki/XMP">XMP</a> metadata),
but should be filed under “against the open and indie web” as it prevents <em>at the very least</em>
the reduction of hosting and bandwidth costs that a transition to JPEG&nbsp;XL would offer.</li>
<li>in 2023, <a href="https://www.bbc.com/news/technology-28687513" title="Google to prioritise secure websites">after downranking plain HTTP websites for years</a>,
Google <a href="https://blog.chromium.org/2023/08/towards-https-by-default.html" title="Towards HTTPS by default">announces</a> an even more aggressive stance to <a href="https://wok.oblomov.eu/tecnologia/moving-to-https/">push for HTTPS adoption</a>;
I have a lot to say about the purported “security” of HTTPS
(and in particular about how it doesn't mean what most people think it means,
particularly concerning the distinction between the integrity of the connection between the client and server
versus the authenticity of the content, particularly of relevance for both corporate silos and federated social networks),
but that's material for a different article,
so here I'll just link to <a href="http://scripting.com/2014/08/08/myBlogDoesntNeedHttps.html" title="My blog doesn't need HTTPS">a few</a> <a href="https://this.how/googleAndHttp/" title="Google and HTTP - Google is a guest on the web">writeups</a> by <a href="http://en.wikipedia.org/wiki/Dave%20Winer">Dave Winer</a>
(one of the inventors of RSS), especially <a href="http://scripting.com/2018/06/12/140329.html" title="I fear Google's control of the web">this particularly prophetic one</a>,
and point out the hypocrisy of claiming an interest for security by the same company
that <a href="#nokeygen">pushed for the removal of <code>keygen</code></a>;</li>
<li>in 2025 Google announces a change in their <a href="https://googlechrome.github.io/chromerootprogram/" title="Chrome Root Program Policy">Chrome Root Program Policy</a>
that within 2026 they will stop supporting certificate with an <a href="https://docs.openssl.org/master/man5/x509v3_config/#extended-key-usage" title="Extended Key Usage">Extended Key Usage</a>
that includes any usage other than server
(<a href="https://social.wildeboer.net/@jwildeboer/114516238307785904" title="Jan Wildeboer's thread">relevant Fediverse thread</a>, <a href="https://social.wildeboer.net/@jwildeboer/114652956737126005" title="Jan Wildeboer's other thread">other relevant Fediverse thread</a>);
this effectively kills certificates commonly used for <a href="http://en.wikipedia.org/wiki/mutual%20authentication">mutual authentication</a>
(hey look, it's the <a href="#nokeygen"><code>keygen</code> suppression</a> theme again!)
that include both client and server roles;
<em>coincidentally</em> this also <a href="https://social.wildeboer.net/@jwildeboer/114986215670464688" title="Jan Wildeboer's post about emailProtection">makes it harder</a>
to implement <a href="http://en.wikipedia.org/wiki/S%2FMIME">S/MIME</a>,
<a href="https://security.googleblog.com/2017/02/hosted-smime-by-google-provides.html" title="Hosted S/MIME by Google provides enhanced security for Gmail in the enterprise">unless you go through Google's services, of course</a>
—but Google's war on self-hosted email deserves its own article,
so that will be for another time.</li>
</ol>

<p>And we finally get to these days.
Just as <a href="https://www.citationneeded.news/curate-with-rss/">RSS feeds are making a comeback</a>
and users are starting to grow skeptic of the corporate silos,
Google <a href="https://github.com/whatwg/html/issues/11523" title="Should we remove XSLT from the web platform?">makes another run to kill XSLT</a>,
this time using the WHATWG as a sock puppet.
Particularly of note, <a href="https://issues.chromium.org/issues/435623334" title="Deprecate and remove XSLT">the corresponding Chromium issue</a>
was created <em>before</em> the WHATWG Github issue.
It is thus to no one's surprise that the <em>overwhelmingly negative</em> reactions to the issue,
the detailed explanations about why <a href="https://wok.oblomov.eu/tag/XSLT/" rel="tag">XSLT</a> is important,
how instead of removing it browsers should move to more recent versions of the standard,
and even the indications of existing better and more secure libraries to base such new implementations on,
<em>every</em> counterpoint to the removal
have gone <em>completely</em> ignored.</p>

<p>Still, the negative reactions were so extensive that the issue has been
ultimately locked —particularly when people started pointing out that
«we don't have enough resources to spend on this» was a completely idiotic excuse
from billion-dollar companies,
or even from smaller enterprises like Mozilla that apparently have enough money to waste
on features nobody wants like LLM chat integration:
this has ultimately confirmed that
the purpose of the issue was never to actually discuss whether or not XSLT should be removed,
but only to provide a flimsy excuse to pretend the removal was driven by a consensus
rather than a top-down directive from Google.</p>

<p>The only true sentences stated by the Googler responsible for this issue
were that browsers have been stuck with an obsolete version of XSLT for over two decades,
and that the implementations they (Google and Apple) rely on has some security issues.
The Googler in question also conveniently omitted several other important facts.</p>

<p>For example, he omitted that two new major versions of XSLT have been released since
this technology was first implemented in the browsers: XSLT&nbsp;2 in 2007, and XSLT&nbsp;3 in 2017.
This means that <a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/zIg2KC7PyH0/m/a3VeYmvEAAAJ" title="Intent to Deprecate and Remove: XSLT">when Google first proposed to kill XSLT</a>,
a newer, considerably more powerful version of the standard had been released for six years already.
And already at the time people were pleading for browsers support to be upgraded to the new version.</p>

<p>It is thus not by chance or by lack of resources that browsers are stuck with the 1999 XSLT&nbsp;1:
it has been an intentional choice <em>against the users' will</em> since <em>at least</em> 2013,
the year we already mentioned as the turning point for the centralization of the web.
XSLT has been <em>intentionally boycotted</em> by Google, Apple and Mozilla:
using the excuse that it is not widely used today, after decades of undercutting any efforts in adoption,
refusing to fix bugs or even to provide meaningful errors to assist in debugging related issues,
is a complete mockery of the victims of these <em>policy</em>.</p>

<p>The Googler also omits to mention that both Google's and Apple's XSLT implementation
(not Mozilla's, that developed their own) relies on a set of free-software libraries
whose maintainer has <a href="https://gitlab.gnome.org/GNOME/libxml2/-/issues/913">recently undergone a bombardment of borderline abusive issue reports</a>
from the characteristically extractive corporate exploitation of <abbr title="Free/Libre Open Source Software"><a href="https://wok.oblomov.eu/tag/floss/" rel="tag">FLOSS</a></abbr>,
with requests to provide professional services without actually paying for it in any way.
Let's repeat that again:
we're talking about billion-dollar companies that have been exploiting the labor of free-software maintainers,
<em>demanding</em> a preferential treatment at no cost for them,
limiting their efforts to finding bugs,
without raising a finger to actually fix them
—almost as if the primary intent was to find excuses to expunge the library rather than working to improve the commons.
(And this is before even going into <a href="https://github.com/whatwg/html/issues/11523#issuecomment-3172069037">the irresponsible way in which these libraries were being used</a>.)</p>

<p>But of course anyone questioning the motives of the corporations controlling the WHATWG
or pointing out the abundance of resources they have,
and how these could easily be spent in bringing XSLT support to the XXI century
instead of being spent in user-antagonistic features,
is “off topic” and “in violation of the code of conduct”.</p>

<p>In the end, the WHATWG was forced to close down comments to the Github issue
to stop the flood of negative feedback, so that the Googler could move on to the next step:
<a href="https://github.com/whatwg/html/pull/11563">commencing the process of formalizing the dismissal of XSLT</a></p>

<h2 id="whyitmatters"><a name="index3h2"></a>Why it matters</h2>

<p>When the <a href="http://en.wikipedia.org/wiki/XML">XML</a> specification was released in 1998, it gained traction very quickly,
despite its increased verbosity,
because by losing some of the flexibility of <a href="http://en.wikipedia.org/wiki/SGML">SGML</a>
(the overreaching specification of which <a href="http://en.wikipedia.org/wiki/HTML">HTML</a> was the most famous incarnation)
it favored disambiguation and simplified parsing of documents of arbitrary kind.
Combined with <a href="http://en.wikipedia.org/wiki/XSLT">XSLT</a>, it allowed documents of any kind to become “Internet ready”,
and most importantly ready for the <em>World Wide Web</em>,
helping driving the WWW towards its designed goal of a «<a href="https://www.w3.org/History/1989/proposal.html">universal linked information system</a>».</p>

<p>Although the benefits of XML and the transformative power of XSLT mostly caught the attention of professionals in a variety of fields,
at the turn of the century their flexibility reached also into the more general population of web users
through the specific incarnation of <a href="http://en.wikipedia.org/wiki/RSS">RSS</a> and <a href="http://en.wikipedia.org/wiki/Atom%20%28web%20standard%29">Atom</a> <a href="http://en.wikipedia.org/wiki/web%20feeds">web feeds</a>,
which allowed users to remain informed about news and updates on their favorite websites
without constantly “making the rounds”.</p>

<p>RSS and other XML-based technologies such as <a href="http://en.wikipedia.org/wiki/Pingback">Pingback</a>s
were the backbone of <a href="http://en.wikipedia.org/wiki/blogging">blogging</a>,
the distributed social network that characterized the first decade of the XXI century.</p>

<p>With blogging common and <em>distributed</em> across multiple platforms,
the possibility to <em>aggregate</em> information from disparate sources,
and still see it presented as a regular web page, across browsers,
without any need for scripting,
in a time where implementations were slow and
(thanks to Microsoft, intentionally) <a href="https://en.wikipedia.org/wiki/JavaScript#History">incompatible with each other</a>,
was seen as a clear win.</p>

<p>Despite the efforts by Google to kill it since 2013,
the RSS format remains an essential component of an open and independent web,
still in widespread usage both server and client side:
there's an estimate 500+ million websites using <a href="http://en.wikipedia.org/wiki/WordPress">WordPress</a>,
and they <em>all</em> feature RSS feeds, even when not properly advertised;
most if not all <a href="http://en.wikipedia.org/wiki/Fediverse">Fediverse</a> platforms also offer RSS feeds,
and some (e.g. <a href="http://en.wikipedia.org/wiki/Friendica">Friendica</a>) can also import them and thus work as aggregators;
and possibly most important, RSS are <em>the</em> fundamental component of <a href="http://en.wikipedia.org/wiki/podcast">podcast</a>s
(«<a href="https://www.thepodcasthost.com/business-of-podcasting/podcasts-need-an-rss/">it's not a podcast if it's not RSS</a>»),
a multimedia distribution format with hundreds of millions if not billions of users worldwide.</p>

<p>As already mentioned, <a href="https://www.citationneeded.news/curate-with-rss/">it's now seeing a resurgence</a>
as people have started realizing how catastrophic for the web was the centralization
driven by <a href="http://en.wikipedia.org/wiki/GAFAM">GAFAM</a> during the second decade of the XXI century
(even though too many have failed to learn the correct lesson,
and have just jumped from <a href="https://web.archive.org/web/20221221103518/https://god.dailydot.com/bartender-kicks-out-tweets/">one Nazi bar</a> <a href="https://www.techdirt.com/2025/08/04/substacks-algorithm-accidentally-reveals-what-we-already-knew-its-the-nazi-bar-now/">to the next</a>,
or have fallen for <a href="https://wok.oblomov.eu/tecnologia/credible-threat-2/">the cosplay of federation</a>
because it's shinier than <a href="https://wok.oblomov.eu/tecnologia/credible-threat-3/">actual federation</a>).</p>

<p>XSLT is an <em>essential</em> companion to RSS, as it allows the feed itself to be perused in the browser
(unless, of course, the browser makes the extra effort to prevents you from visualizing it at all, like Firefox does).
This allows sites with hundreds of feeds to use <em>the feed itself</em> (styled with XSLT) as index page,
reducing hosting and bandwidth costs.
And of course it can also be used to style any other “standard” XML document that may be found on a site:
for example, <a href="https://mastodon.social/@aslakr/115015511759324306">I have recently discovered</a>
thanks to <a href="https://mastodon.social/@aslakr">@aslakr​@mastodon.social</a>,
that WordPress provides a default XSLT stylesheet for its sitemaps
(curiously, apparently not one for its web feeds, though?)</p>

<p>And that's just the beginning: <a href="https://wok.oblomov.eu/tecnologia/sparkling-wok-4/">as I've shown on this same site</a>,
it's possible to use XSLT <a href="https://wok.oblomov.eu/tecnologia/plotting-xslt/">to plot XML data</a>,
and in general to produce rich, complex documents <em>without JavaScript</em>,
and again with potentially significant reductions in hosting and bandwidth costs.</p>

<p>Bonus points: <a href="https://github.com/whatwg/html/issues/11523#issuecomment-3161446202">it seems</a> that the horde of LLM scrapers that are causing troubles all around
have some difficulties with general XML, so switching to XML+XSLT could actually work for self-protection.</p>

<p>Remember <a href="#amp">AMP</a>?
If you really wanted to keep shipping the usual tons of useless crap on desktop, but not on mobile,
you could put the actual content in an XML file,
and then provide two separate, trivial XSLT stylesheets,
one to transform it into the usual bloated desktop page,
and one to transform it into the stripped-down (and less bloated) abomination that is AMP HTML
—which would have come in handy when Google introduced the requirement that the AMP and standard page
had to present the same content.
But then again, why even ship those tons of useless crap on desktop in the first place?</p>

<p>And to be honest, <a href="https://web.dev/articles/webcomponents-template" title="HTML's New Template Tag">HTML templates</a> look thoroughly unimpressive compared to XSLT.</p>

<h3 id="dorian"><a name="index1h3"></a>Dorian Taylor on XSLT</h3>

<p>If you've read this far, I would encourage you to also read
<a href="https://github.com/whatwg/html/issues/11523#issuecomment-3160242434">the passionate defense of XSLT by Dorian Taylor</a>
on the Github issues that Google is using as an excuse to kill the standard.
In case GAFAM gets touchy and decides to purge it,
I'm taking the liberty to reproduce it here for archival purposes:</p>

<blockquote>
  <p>I have been using XSLT since it was in beta and the only browser that implemented it was MSIE 5.5.
  I designed and implemented an internationalized content pipeline using XSLT and DocBook at the job I had from 2002-2005.
  Since about 2007 I've been using XSLT regularly on the client side to transform (X)HTML into itself (as well as SVG and Atom),
  because it excels at bolting presentation markup onto plain semantic markup,
  and thus makes for an extremely lazy templating language that exists separately from the JavaScript ecosystem.
  I use it on <a href="https://doriantaylor.com/">my own</a> <a href="https://the.natureof.software/">Web properties</a>,
  and I use it on projects (I mainly do intranets).
  I have made libraries <a href="https://github.com/doriantaylor/xslt-transclusion">for seamless transclusion</a>
  and <a href="https://github.com/doriantaylor/xslt-rdfa">querying RDFa</a>, and I use those on projects
  (like <a href="https://senseatlas.net/">Sense Atlas</a>, a nascent
  knowledge graph product I'm working on, and <a href="https://intertwingler.net/">Intertwingler</a>, the application
  server that powers it).</p>
  
  <p>Why I still use XSLT:</p>
  
  <ul>
  <li>it's a standard</li>
  <li>it's fast (at least nominally)</li>
  <li>it's declarative</li>
  <li>it's orthogonal to JS</li>
  <li>it can mix any number of back-ends (because it's a standard and operates over standard inputs;
  I regularly use it to mix static and dynamic resources on the same page)</li>
  <li>it can only operate over information you give it (modulo zero-days, apparently)</li>
  <li>it operates over wholes, i.e., it doesn't stitch together markup as text but rather operates over intact DOM structures.</li>
  </ul>
  
  <p>The first and last points are probably the biggest reasons I still use it, and I suppose the latter may need some unpacking.
  An XSLT stylesheet is a well-formed XML document and only operates over well-formed XML documents,
  and (unless you put in the effort) is only capable of producing well-formed (X|HT)ML documents.
  So you have a validity check baked in at a very low level.
  Every other templating language I've seen, going all the way back to server-side includes (<a href="http://clearsilver.net/">with one esoteric exception</a>),
  seems to not be shy about chopping up the syntax of the target language.</p>
  
  <p>I anticipate the knee-jerk reaction to this is "so what?".
  Why should you care whether your template language breaks the syntax of the target?
  The tooling can compensate and it's intact when you render it. I mean, I guess?
  But then you need more tooling when otherwise an off-the-shelf validator would do.
  But that I think is not even the main differentiator.</p>
  
  <p>The key difference, and why I've stuck with XSLT for almost 25 years, is cognitive.
  When I make a hypermedia resource (I am deliberately not using the word "page"),
  I think about it as a discrete, atomic whole.
  I can consider that object (and the server-side code that generates it) in isolation.
  It loads in the browser and is well-formed and intact and navigable.
  Then I can think about applying transformations to that object,
  and/or composing related objects together, as a separate act.
  When I write an XSLT template, I think about it like a function (in the mathematical sense) rather than a procedure.
  I see my job as not to stitch together fragments of markup but to describe the node tree that results from an input tree.
  When I look at so-called "modern" frameworks, I (still) don't see any of that.</p>
  
  <p>The reason why the implementations are riddled with CVEs, in my opinion, is because of neglect.
  I am old enough to remember when HTML5 was competing with XHTML2✱ as the proposed next-generation HTML standard.
  It turned out that the pedantry of the XML parser was not only reviled by developers
  (and remains a source of confusion for users if they hit a bad patch of it),
  for markup it was actually unnecessary.
  Tastes changed, and people moved on.
  The browser vendors keep the parsers around, but they demonstrably put as little effort into them as they can get away with.
  (The biggest shortcomings of XSLT 1.0 were fixed in 2.0—in 2007—but of course the browsers never implemented it.)</p>
  
  <blockquote>
    <p>✱ XHTML2 actually had some really good ideas (like transclude all the things),
    but its mission (something like "how do we make the best XML-based hypertext markup language") was ultimately wrong-headed.
    I am also old enough to remember, however, that one of the central arguments for HTML5
    (now just "HTML", of course) was not breaking backward-compatibility.</p>
  </blockquote>
  
  <p>My proposal, then, is not to scrap XSLT, but to rehabilitate it.
  When it first shipped, XSLT was a solid, open-standard solution to the bog-standard problem of generating presentation markup.
  How many times has the wheel of Web templating been reinvented for this framework or that?
  Where is the Open Web successor to XSLT? How about…XSLT?</p>
  
  <p>At its core, XSLT is terrifically powerful, especially <a href="https://www.w3.org/TR/xslt-30/">its latest incarnation</a>
  (which, incidentally, <a href="https://www.w3.org/TR/xslt-30/#json">can operate over JSON</a>). There are, of course, challenges:</p>
  
  <ol>
  <li>I would say problem number one is the syntax. XSLT is an extremely bulky, chatty language.
  Without syntax completion in your code editor you'd never get anything done.
  But, there are precedents for ameliorating this,
  like <a href="https://relaxng.org/compact-tutorial-20030326.html">the compact syntax for RelaxNG</a>,
  or the <a href="https://www.w3.org/TR/turtle/">Turtle</a> or <a href="https://www.w3.org/TR/json-ld11/">JSON-LD</a> syntaxes for RDF.</li>
  <li>XSLT only operates over XML (except of course for 3.0 which made an accommodation for JSON).
  Well that's simple, bump XSLT to 3.1 and spec out how it should operate over HTML DOMs (case-insensitive tags, whatever),
  as well as an invocation hook analogous to the XSLT processing instruction.</li>
  <li>Namespaces: Apparently people hate them?
  This is something I have never understood (because if you don't use namespaces you just end up reinventing them badly), but whatever, fine.
  You won't need namespaces in your XPath anyway if you're just transforming HTML.</li>
  <li>XPath: I would actually put money on the likelihood that CSS selector semantics can embed fully into XPath,
  especially given that XPath 3.1 itself is extensible (worst case scenario is you cheat and just make a <code>css</code> function).</li>
  <li>Debugging: currently sucks. This I would chalk up to the same neglect as the CVEs.</li>
  </ol>
  
  <p>It would be eminently feasible to make a "<em>SWeT</em>", Standard Web Templates:</p>
  
  <ul>
  <li>easy, neat, declarative syntax, comparable to Sass or RNC (<a href="https://doriantaylor.com/file/xslt-mockup">I sketched one out in like 2019</a>)</li>
  <li>isomorphic (or at least injective onto) XSLT 3.0 (3.1?); compiles to it</li>
  <li>wouldn't have to touch namespaces or even XPath if you didn't want to (use CSS selectors instead)</li>
  <li>still capable of existing outside of the JS ecosystem, but can be accessed from JS/DOM just like XSLT 1.0 can</li>
  </ul>
  
  <p>Now I can imagine somebody saying well I can go off and do that anyway;
  <a href="https://www.saxonica.com/saxonjs/index.xml">there's a reference implementation</a> of XSLT 3.0 I can compile against (written, actually, by the spec's author), etc etc. I think
  that kind of misses the point of having a <em>standard</em> templating language that you can rely on being baked into every Web browser.
  At least, I suppose, until they rip it out.</p>
  
  <p>So I guess my ultimate question is, is there truly no appetite for a standard language for transforming markup,
  a thing we all have to do, on every project, all the time?
  A thing that for lack of a standard, locks us into this or that framework,
  or stymies <a href="https://doriantaylor.com/intelligent-heterogeneity">casual system heterogeneity</a>?
  A thing that would make it even easier to build the Web? Seems like a sensible idea, doesn't it?</p>
</blockquote>

<p>(Again: <a href="https://github.com/whatwg/html/issues/11523#issuecomment-3160242434">source, for reference</a>.)</p>

<p>And now, onwards to what's ahead.</p>

<h2 id="whatwecandoaboutit"><a name="index4h2"></a>What we can do about it</h2>

<h3 id="makeyourselfbeseen"><a name="index2h3"></a>Make yourself be seen</h3>

<p>The first step is to actually use XML and XSLT. Visit sites that use them.
If you have your own website, seek out opportunities to rely on this tech.
If you don't know how, there's <a href="https://github.com/whatwg/html/issues/11523#issuecomment-3161446202">apparently</a> a growing number of tutorials around,
both in text and video form. Stealing the links to the text tutorials from the above link,
we have for example.</p>

<ul>
<li><a href="https://ricardolopes.net/blog/styling-rss/">Styling Your RSS For a Better Web</a></li>
<li><a href="https://hacdias.com/2024/10/23/styled-rss-feeds/">Styling My RSS Feed</a></li>
<li><a href="https://dev.to/natclark/styling-an-rss-feed-with-xslt-jp3">Styling an RSS Feed With XSLT</a></li>
<li><a href="https://darekkay.com/blog/rss-styling/">Style your RSS feed</a></li>
</ul>

<p>(notice a pattern there?)</p>

<p>And styling RSS is just the most common use-case of XSLT.
You can use it to <a href="https://wok.oblomov.eu/tecnologia/plotting-xslt/">plot data</a> and <a href="https://wok.oblomov.eu/tecnologia/plotting-sparklines-xslt/">create sparklines</a>,
like I've done.
You can use it <a href="https://wok.oblomov.eu/tecnologia/uberprufungslisten/">in place of server-side includes</a>.
You can use it to render tabular data you have in XML form.
You can use it <a href="https://gts.skobk.in/@tennoseremel/statuses/01K317WWPS020K8XYSNNCSWHM3">to adjust the (X)HTML structure of your documents</a>
to <a href="https://wok.oblomov.eu/tecnologia/web/css-challenges/">compensate for CSS limitations</a>.</p>

<p>By the way, if you can find new and interesting applications of XSLT in browsers, do let me (and the world) know
(see bottom of this article for information about how to contact me on the Fediverse).</p>

<h3 id="makeyourselfbeheard"><a name="index3h3"></a>Make yourself be heard</h3>

<p>Complain. Complain. Complain.
Comment on every relevant issue. Vote against the issue in the issue trackers.
Let the browser developers know you are affected.</p>

<p>If (or when) the changes still pass, open new tickets.
<em>Demand</em> that XSLT support be reinstated. And while you're at it, <em>demand</em> that it get upgraded to XSLT 3.0 at least.
And <em>demand</em> that it be enabled for plain HTML.</p>

<p>Voice your opinion on social media. Post about it. Tag the social media profiles of the WHATWG,
of  Google, Apple, Mozilla, Microsoft,
of Chrome, Safari, Firefox, Edge, and let them know that such a change will not be accepted.</p>

<p>Do not let the lies prevail.
The choice to suppress XSLT is not due to technical reasons, and it's not due to lack of resources.
It's entirely a policy choice intended to obstruct and limit the expressivity of the open and indie web,
and this needs to be remarked to anyone believing otherwise.</p>

<h3 id="buildthealternative"><a name="index4h3"></a>Build the alternative</h3>

<p>If (or when) the changes pass, our best option is to push through with a polyfill like the <a href="https://www.saxonica.com/saxonjs/index.xml">SaxonJS</a>
<span>mentioned by Dorian Taylor|</span>.
It will not be as efficient as a native implementation, it will not be as fast,
andit will not be enough to allow clients to open and visualize XML files directly,
but it <em>will</em> allow us to build the case for a return to XSLT as a significant web technology,
and become an important instrument in pressuring vendors for new native implementations,
not unlike how <a href="http://en.wikipedia.org/wiki/MathJax">MathJax</a> has been a useful bridge to native implementations of <a href="http://en.wikipedia.org/wiki/MathML">MathML</a>.</p>

<p>For pure XML files&nbsp;… maybe an <a name="extensions">extension</a>? This is most likely possible for Firefox,
but I don't know enough about the <a href="#mv3">more restrictive rules implemented in Chrome</a> to tell if it would be possible or not.
But of course, even if such an extension was possible today,
there is no guarantee that Chrome won't push for <em>another</em> change in the API
to disable it, like it did with ad&nbsp;blockers.</p>

<p>Who knows, it might as well be that the <a href="http://en.wikipedia.org/wiki/Streisand%20effect">Streisand effect</a> on this umpteenth attempt by Google to kill XSLT
will be the chance for its rebirth.</p>

<h2 id="afterword"><a name="index5h2"></a>Afterword</h2>

<p>With as much I hate Microsoft, its anticompetitive practices,
and the way their Wintel monopoly has stymied software and hardware development,
killed companies and destroyed innovation in the desktop and workstation space,
<em>one</em> thing I can say about the <a href="http://en.wikipedia.org/wiki/First%20browser%20war">First browser war</a> is that
—at least while it was ongoing— it led to a lot of innovation in the web space.
Microsoft were the first to implement client-side XSLT,
they were the ones that opened the gateway to <a href="http://en.wikipedia.org/wiki/AJAX">AJAX</a>
through their proprietary XMLHTTP <a href="http://en.wikipedia.org/wiki/ActiveX">ActiveX</a> control that
was reimplemented into other browsers as the <a href="http://en.wikipedia.org/wiki/XMLHttpRequest">XMLHttpRequest</a> object,
and they were the ones that tried to add SMIL to (X)HTML through the <a href="http://en.wikipedia.org/wiki/HTML%2BTIME">TIME</a> extension,
which I wish hadn't failed the way it did
(we would have to wait nearly another decade before a limited subset of the functionality would finally get into HTML via <a href="http://en.wikipedia.org/wiki/CSS%20animations">CSS animations</a>).</p>

<p>It's possible that this is was at least in part due to the fact that,
as it has been said, Microsoft didn't “get” the Internet,
but I suspect that the primary reason was that there was some actual competition going on
—competition that since the creation of the WHATWG has been replaced by what is,
for all intents and purposes, a <em>cartel</em>.</p>

<p>The intent to bypass the W3C for some decisions <em>did</em> have some merit at the time of creation;
looking at the <a href="https://www.w3.org/2004/04/webapps-cdf-ws/papers/opera.html" title="Position Paper for the W3C Workshop on Web Applications and Compound Documents">the document</a> whose rejection led to the creation of the WHATWG,
for example, we see among the design principles:</p>

<blockquote>
<dl>
<dt>Well-defined error handling</dt>
<dd>Error handling in Web applications must be defined to a level of detail where User Agents do not have to invent their own error handling mechanisms
or reverse engineer other User Agents'.</dd>
<dt>Users should not be exposed to authoring errors</dt>
<dd>Specifications must specify exact error recovery behaviour for each possible error scenario.
Error handling should for the most part be defined in terms of graceful error recovery (as in CSS),
rather than obvious and catastrophic failure (as in XML).</dd>
</dl>
</blockquote>

<p>which I can't disagree with.
On the other hand,
it's also clear that two other design principles,
<em>backwards compatibility</em> and <em>open process</em>,
have been consistently violated since
<a href="https://wok.oblomov.eu/tecnologia/opera-requiem-2/">Opera dropped out</a>
(oh, how prescient I was in that article!)
and the WHATWG was taken over by Google and its lapdogs (Mozilla)
and frenemies (Microsoft and Apple).</p>

<p>Today, I'm left wondering if the developers of browsers like
<a href="http://en.wikipedia.org/wiki/Servo%20%28software%29">Servo</a>
—<a href="https://servo.org/">the engine</a> born out of the Mozilla experiments
that were cut out (with the entire development team fired)
at the start of the <a href="http://en.wikipedia.org/wiki/COVID%2D19%20pandemic">COVID-19 pandemic</a>—
or
<a href="http://en.wikipedia.org/wiki/Pale%20Moon">Pale Moon</a> would even be accepted into the WHATWG today,
since they could
(and <a href="https://outerheaven.club/objects/ce85bc54-449d-43a6-8bea-022cdbb2b457">at the least the latter would</a>)
happily throw a wrench into the whole
“fake public feedback” mockery we've been subject to this time.</p>

<h2 id="nameandshame"><a name="index6h2"></a>Name and shame</h2>

<p>The engineers working on these proposals should be ashamed of themselves.
The names I could gather from the public discussions are:</p>

<ul>
<li>Adam Barth was
<a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/zIg2KC7PyH0/m/Ho1tm5mo7qAJ">the engineer who proposed to remove XSLT in 2013</a>,
with support from Eric Seidel, Ojan Vafai;</li>
<li>Philip Rogers and Eric Willigers were
<a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/5o0yiO440LM/m/59rZqirUQNwJ">the engineers who proposed to remove SMIL in 2015</a>,
with support from Chris Harrelson, Dimitri Glazkov, Philip Jägenstedt;</li>
<li>Ryan Sleevi was
<a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/pX5NbX0Xack/m/kmHsyMGJZAMJ">the engineer who proposed to remove <code>keygen</code> in 2015</a>;</li>
<li>Ben Wiser, Borbala Benko, Philipp Pfeiffenberger, Sergey Kataev were
<a href="https://github.com/explainers-by-googlers/Web-Environment-Integrity/blob/main/explainer.md">the engineers who proposed the Web Environment Integrity</a>;</li>
<li>Mason Freed is
<a href="https://github.com/whatwg/html/issues/11523">the engineer pushing the XSLT removal in 2025</a>,
with support from Anne van Kesteren,
the Mozilla employee that appropriately goes by the moniker <code>smaug</code>,
Tab Atkins Jr., Domenic Denicola.</li>
</ul>

<p>If you ever hear any of these blabber about open web, interoperability and standards,
know that they are lying through their teeth.</p>

<p>And if any of you happen to read this: fuck you.</p>

<h2 id="madethenews"><a name="index7h2"></a>Made the news</h2>

<p>I've apparently “made the news”.</p>

<ul>
<li><p><a href="https://www.osnews.com/">OSNews</a> has <a href="https://www.osnews.com/story/143123/google-is-killing-the-open-web/">an article</a> that provides a very nice, short, on-point summary;</p></li>
<li><p><a href="https://news.ycombinator.com/">Hacker News</a> has <a href="https://news.ycombinator.com/item?id=44949857">a thread</a>.</p></li>
</ul>

<p>I have read the comments
(yes, I know, you should never do that)
and it's curious that those that didn't like or agree with the article can be grouped in three sets:</p>

<dl>
<dt>unconvinced by my timeline</dt>
<dd>these are commenters that disagree on my list being enough to prove that Google is out to destroy the open web;
that's OK, the list isn't there to prove anything, it's just to remind people
(or inform youngsters who might not remember those days)
about some relevant (and a couple less relevant) events in the last decade-plus that have significantly shaped the web;
the list isn't even exaustive insofar Google is concerned,
let alone all the crap, failed promises, rug pulls and abuses committed by the rest of the <a href="http://en.wikipedia.org/wiki/GAFAM">GAFAM</a> crowd
—the only reason I'm singling out Google here, and on those events in particular, is because the focus is on XML, XSLT,
and the WHATWG takeover and unwillingness to listen to what users have to say;</dd>
<dt>disagreement on the assessment</dt>
<dd>these are people who disagree on some of the events I reported being bad for the open web,
or aimed at encircling it; so far, from what I see, these comments come from Googlers or ex-Googlers;
well, I'm sorry to burst your bubble; I'm sure the engineers working at Google
have always had the conviction to be doing Good Stuff™ for the benefits of all;
but see, that's kind of the problem of a lot of Big Tech employees:
the lack of attention to the <em>implications</em> of what their brilliant ideas are going to be used for
—and sometimes, possibly, even the time to stop and think if the “innovation”
is even needed in the first place, or you're forgetting what older, well-established but less reknown tech can already do;</dd>
<dt>people that don't like XML</dt>
<dd><strong>you're missing the point</strong>; this isn't about whether XML is nice or not,
it's about the fact that it exists, it's in use, and it's a powerful tool that web developers can and <em>do</em> use;
you prefer <a href="https://wok.oblomov.eu/tag/JSON/" rel="tag">JSON</a> to <a href="https://wok.oblomov.eu/tag/XML/" rel="tag">XML</a>? <em>That's fine</em>, and if anything that's one more reason to push
browser developers to implement newer XSLT versions that <em><a href="https://www.w3.org/TR/xpath-31/">support JSON too</a></em>;
or if you prefer: the question isn't whether or not XML and XSLT are worth saving;
<strong>it's whether or not you want Google to define what is allowed on the World Wide Web</strong>.
</dd>
</dl>

<p>By the way, you can let me know directly about your thoughts about this article by
<a href="https://sociale.network/@oblomov/115044789276014433">commenting on this Fediverse thread</a>.</p>

</section>



</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Prime Number Grid (191 pts)]]></title>
            <link>https://susam.net/primegrid.html</link>
            <guid>44949162</guid>
            <pubDate>Tue, 19 Aug 2025 07:33:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://susam.net/primegrid.html">https://susam.net/primegrid.html</a>, See on <a href="https://news.ycombinator.com/item?id=44949162">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <p><label for="start">Start</label>
      
    </p>
    <p><label for="rows">Rows</label>
      
    </p>
    <p><label for="cols">Cols</label>
      
    </p>
    
    
    
    
  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to Build a Medieval Castle (135 pts)]]></title>
            <link>https://archaeology.org/issues/september-october-2025/features/how-to-build-a-medieval-castle/</link>
            <guid>44948352</guid>
            <pubDate>Tue, 19 Aug 2025 04:49:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://archaeology.org/issues/september-october-2025/features/how-to-build-a-medieval-castle/">https://archaeology.org/issues/september-october-2025/features/how-to-build-a-medieval-castle/</a>, See on <a href="https://news.ycombinator.com/item?id=44948352">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
                      
<p><strong>Sometimes it takes a village</strong> to raise a window. Between 2015 and 2017, skilled masons meticulously carved and beveled arches and four-lobed flourishes for a Gothic-style stone window frame in Guédelon Castle’s ornate Chapel Tower. All that remained was to install some glass. But there was a problem, and the carpenters, painters, blacksmiths, basket weavers, historians, and archaeologists who work on-site were all enlisted to figure it out. Eight years later, the matter of what to put in the window of a medieval castle has nearly been resolved…maybe.</p>



<p>Luckily, the team of 40 professional builders and craftspeople at Guédelon Castle love a conundrum. The castle, located in an abandoned quarry in the Puisaye region of Burgundy, 100 miles southeast of Paris, is the site of one of the world’s most comprehensive and longest-running experimental archaeology projects. In this kind of undertaking, archaeologists partner with skilled laborers to test hypotheses about how people worked, lived, and built in the past, filling gaps in academic knowledge through real-world trials. The project launched in 1998 with a straightforward mandate: Build a thirteenth-century castle using only thirteenth-century tools, techniques, and materials. Medieval archaeologists would provide guidance. And the hope was that every obstacle would reveal something that historians, architectural researchers, archaeologists, and <em>castellologues</em>, or scholars who specialize in studying castles, didn’t know. “At Guédelon, we’re looking for what disappeared in traditional archaeology,” says Florian Renucci, the master mason and longtime site director at Guédelon, who was formerly a researcher at Sorbonne University. “Experimental archaeology means bringing to life what workers can do. We’re always looking, hearing, feeling. Now, with our work, the castle can speak.”</p>


<figure data-wp-context="{&quot;imageId&quot;:&quot;68a4572ccd682&quot;}" data-wp-interactive="core/image"><img decoding="async" width="1024" height="679" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://archaeology.org/wp-content/uploads/2025/07/SO25-Guedelon-Castle-Aerial-1024x679.jpg" alt="" data-image-credit="© D. Gliksman" srcset="https://archaeology.org/wp-content/uploads/2025/07/SO25-Guedelon-Castle-Aerial-1024x679.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/07/SO25-Guedelon-Castle-Aerial-300x199.jpg 300w, https://archaeology.org/wp-content/uploads/2025/07/SO25-Guedelon-Castle-Aerial-768x509.jpg 768w, https://archaeology.org/wp-content/uploads/2025/07/SO25-Guedelon-Castle-Aerial.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Guédelon Castle, in the Puisaye region of north-central France, represents a modern effort to build a thirteenth-century castle using only construction materials and techniques employed by medieval builders and artisans. After several decades, masonry work on the castle’s Chapel Tower (top left) and the adjoining Great Hall is now complete.</figcaption></figure>



<p>The first thing the castle said about windows is that they couldn’t have been made of glass. Guédelon’s artisans and committee of scientific advisers are constantly scouring medieval texts for clues about how thirteenth-century builders would have handled such details. In the castle’s imagined backstory, the fictitious seigneur, or lord, of Guédelon was a cash-conscious minor noble trying to make a home in 1228, putting him—and today’s builders of Guédelon—at the mercy of his financial circumstances. In that era, glass was extraordinarily expensive and reserved for places of worship and royal residences. Glasswork, the team learned, swallowed up half the cost of building a cathedral. Unfortunately, whatever material was used to fill the window frames of lesser edifices has left no traces in the archaeological record.</p>



<p>Artisans, many wearing period garb, initially tried to fashion goatskin panels for the Chapel Tower window after learning that this material had been used in contemporaneous buildings—but the panels warped in the winter frost and cracked in the summer heat. The team then reviewed a list of prices for the materials used to build the Palais des Papes, or Palace of Popes, in Avignon, which was begun in 1252. They learned that humble linen, stiffened with beeswax, once covered some windows at this grandest of châteaus. Valérie Lachény, Guédelon’s master painter, decorated linen canvases with an eye-catching design of golden oak leaves ensconced in maroon semicircles—a pattern inspired by twelfth-century stained glass at Strasbourg Cathedral in northeastern France. In spring 2025, three painted linen panels could be found propped in her workshop, each waiting to be affixed between wooden frames engineered by the castle’s carpentry atelier to fit into the tower’s stone window molds. Each frame takes 150 hours to join, rasp, carve, and assemble.</p>


<figure data-wp-context="{&quot;imageId&quot;:&quot;68a4572ccdd5a&quot;}" data-wp-interactive="core/image"><img decoding="async" width="1024" height="306" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Strasbourg-Windows-Combo-1024x306.jpg" alt="" data-image-credit="Ben O’Donnell; © Ralph Hammann/Wikimedia Commons; Ben O’Donnell" srcset="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Strasbourg-Windows-Combo-1024x306.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Strasbourg-Windows-Combo-300x90.jpg 300w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Strasbourg-Windows-Combo-768x229.jpg 768w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Strasbourg-Windows-Combo.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Decorated linen window panels (left) stand in the Guédelon painters’ atelier, awaiting installation in the Chapel Tower. Patterns from twelfth-century stained glass at Strasbourg Cathedral (middle) inspired the panels’ designs. One linen panel (right) in the Great Hall’s antechamber has already been put in place.</figcaption></figure>



<p>Meanwhile, an ongoing debate about how to fasten the linen to the frames rages. Guédelon’s blacksmiths have forged bespoke iron tacks, but, as carpenter Simon Malier explains, this option for attaching the fabric requires finesse, lest the wood crack. The basket weavers have suggested sewing the linen into the frames with a cow-horn needle. “For this kind of thing,” Malier says, “it’s a team effort.” Whatever method wins out, when the window is finally mounted, the waxed linen exterior will be brushed with flaxseed oil to protect it—which may or may not work. Recently, Malier says that he, Renucci, and Lachény stumbled on a snippet of medieval text describing a tantalizing linen window coating that shines “like crystal.” “But we don’t have the bloody recipe!” he laments.</p>



<p>“Because the Guédelon team works in the conditions of thirteenth-century laborers, they discover techniques that people were figuring out at that time,” says archaeologist and Guédelon project scientific committee member Nicolas Faucherre of Aix-Marseille University. “That’s why Guédelon is so important for archaeologists.” Every detail must be considered, and there are no shortcuts. The site is an unparalleled experimental archaeology project and may remain never-quite-finished forever. By observing the work of the castle’s “medieval” builders, archaeologists and other scholars have discarded old ideas and hatched new ones about how monuments of the era were created. They have solved mysteries about how ceramic for tiles was mixed and fired, how lime mortar was troweled to hold structures fast and make them last, and how scaffolding was erected to reach dizzying heights. Some discoveries may seem esoteric, but each one can help refine scholars’ understanding of tens—or even thousands—of medieval sites.</p>


<figure data-wp-context="{&quot;imageId&quot;:&quot;68a4572cce332&quot;}" data-wp-interactive="core/image"><img decoding="async" width="1024" height="691" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Map-1024x691.jpg" alt="" data-image-credit="Ken Feisel" srcset="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Map-1024x691.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Map-300x202.jpg 300w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Map-768x518.jpg 768w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Map.jpg 1038w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p><strong>In 1995</strong>, Faucherre and archaeologist Christian Corvisier found something quite striking while studying Saint-Fargeau Castle, 5.5 miles northwest of Guédelon. The château there was built from the fifteenth through the seventeenth century, but the archaeologists discerned the foundations of a smaller, earlier fortification with thirteenth-century characteristics beneath it. The château’s owner, Michel Guyot, became intrigued by the prospect of rebuilding the earlier structure. So, he bought the disused quarry in Guédelon Forest in the commune of Treigny and embarked on the adventure with cofounder Maryline Martin, a young businessperson. Instead of imitating Saint-Fargeau Castle, they decided, the new structure would be an original, loosely following the model of Ratilly Castle, which had been built around 1270 just two miles south.</p>



<p>“When I came here for the first time, it was just forest,” says Martin, who is now the owner of Guédelon. “But we had a lot of luck.” The forest, 370 acres of which belong to Guédelon, has ample oak for timber, a lode of iron-streaked sandstone that serves most of the masons’ and blacksmiths’ needs, and seemingly bottomless pockets of colorful minerals for the painters to extract pigments from. “It’s incredible for me to imagine how many solutions we have just within sight,” Martin says.</p>


<figure data-wp-context="{&quot;imageId&quot;:&quot;68a4572cce918&quot;}" data-wp-interactive="core/image"><img decoding="async" width="1024" height="659" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Chapel-Tower-Vault-1024x659.jpg" alt="" data-image-credit="© Guédelon" srcset="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Chapel-Tower-Vault-1024x659.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Chapel-Tower-Vault-300x193.jpg 300w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Chapel-Tower-Vault-768x494.jpg 768w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Chapel-Tower-Vault.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Masons work to construct the Chapel Tower’s stone ceiling vault over a wooden framework without the use of iron or concrete.</figcaption></figure>



<p>The first years at Guédelon were strenuous and invigorating, long days testified in chisel marks on stone, ax splits on timber, and strokes on sketch pads. It took three years to build the 11.5-foot-thick foundation walls, which trace a perimeter of 660 feet. Many of the original laborers were unemployed, some with past legal difficulties, and had been left behind in a place where most factories and quarries had shuttered, and even the railroad had ceased running long before. As Martin recalls, quarriers would etch their encouragement on blocks passed to the masons. “Only ten to go! Only nine to go!” read inscriptions on some stones. In 1998, the construction site opened to curious visitors, and 300,000 now come each year, 60,000 of whom are schoolchildren. The castle, and everything else Guédelon includes, encompasses a self-sustaining business, funded by ticket sales, an on-site restaurant, and a gift shop.</p>



<p>Amid innumerable false starts and experiments gone awry, Guédelon Castle began to rise. Between 2000 and 2017, Renucci and his team executed four different styles of medieval ceiling vault—mostly to see if they could—all without any ahistorical reinforcement from iron or concrete. By 2010, the carpenters had lifted magnificent timber trusses over the castle’s Great Hall and living quarters, and soon Guédelon’s grounds included gardens, stables, a water mill, and 10 workshops.</p>


<figure data-wp-context="{&quot;imageId&quot;:&quot;68a4572cceeac&quot;}" data-wp-interactive="core/image"><img decoding="async" width="1024" height="683" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Compass-Work-1024x683.jpg" alt="" data-image-credit="© Guédelon" srcset="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Compass-Work-1024x683.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Compass-Work-300x200.jpg 300w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Compass-Work-768x512.jpg 768w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Compass-Work.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Master mason Florian Renucci traces an arch with a version of a thirteenth-century compass.</figcaption></figure>



<p><strong>The Puisaye skies</strong> threaten rain, as they often do in April, but excitement is in the air. Guédelon opened for the season just a few weeks ago. Stonemasons have completed two of the castle’s four corner towers using the area’s brilliant burnt-orange sandstone. The table is set in the Great Hall under a lofty oak-timber barrel vault. Painters have adorned the hall’s antechamber with willowy vines and cheery flowers dancing around stone blocks. The carpenters have even mounted a linen window there—it seems to be faring well thus far. Beyond the castle walls, a blond-maned horse makes light work of pulling an empty cart, and kids stop to gawk at the “squirrel cage,” a leviathan treadmill winch atop the south curtain wall. Inside this human hamster wheel, masons trudge in pairs to power a pulley that lifts blocks and mortar up to the parapet they’re finishing.</p>



<p>Renucci is at the castle this morning as usual, but there’s no such thing as an ordinary day for the master mason. He has to sketch and resketch all plans by hand, troubleshoot glitches with archaeologists around the country, convene weekly meetings of artisans to hear their latest updates and bon mots, and oversee all construction and craft operations. Renucci, who helped restore Paris’ iconic sixteenth-century bridge, the Pont Neuf, first donned a period-appropriate tunic and capelet for his role at Guédelon in 1998. Today, the clanking of the quarriers and the whoosh of the forge bellows tell him the morning has begun smoothly, so he’ll take a lap around the castle to check on progress.</p>


<figure data-wp-context="{&quot;imageId&quot;:&quot;68a4572ccf441&quot;}" data-wp-interactive="core/image"><img decoding="async" width="1024" height="631" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Mill-Water-Wheel-1024x631.jpg" alt="" data-image-credit="Ben O’Donnell" srcset="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Mill-Water-Wheel-1024x631.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Mill-Water-Wheel-300x185.jpg 300w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Mill-Water-Wheel-768x474.jpg 768w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Mill-Water-Wheel.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The water wheel in the castle’s mill rotates a massive axle, following the design of a twelfth-century mill discovered in Thervay, 160 miles east of Guédelon.</figcaption></figure>



<p>He strides out from the burly two-tower main gatehouse and scrambles down to the exterior foundations of the Chapel Tower. With his measuring stick—articulated in both modern centimeters and the inches and feet thirteenth-century masons used, which are almost identical to today’s—Renucci gestures at a section of Guédelon’s very first wall. The stone blocks here are precisely fitted and smoothly dressed, a visible contrast with the rest of the walls’ masonry. It looks as though stoneworkers had begun building a different castle entirely. “When we started, we tried to make the stones very uniform, very planned, because we learned at masonry school that this is a better way,” Renucci says. But each stone took two days to cut and dress. In the thirteenth century, masons usually collected their fees in weeks worked, not stones cut. Could the budget-conscious seigneur of Guédelon really have afforded this? Did he have time to wait for a roof over his head and walls to protect his family?</p>



<p>As he has done countless times over his Guédelon career, Renucci looked to France’s wealth of medieval archaeology. In its imagined story, Guédelon was founded just after the rule of Philip II (reigned 1180–1223), the first ruler to style himself king of France. Philip doggedly expanded the throne’s domain to include most of the area under the French flag today, in part through a campaign of building defensive fortifications in a signature Philippian style that his vassals mimicked. Around 100 such fortresses survive in France, a primary reason that 1228 was the date chosen to establish Guédelon. One Philippian castle stands largely unmodified in Dourdan, just southwest of Paris, and “predates” Guédelon by just a few years. The walls of Dourdan Castle, Renucci noticed, were faced with irregular, roughly dressed blocks, inspiring him to alter his course. “When we changed methods, we were able to make four stones in one day,” he says. “Our mindset today is to take your iPhone and say, ‘Can I order wood or stone in 20 hours?’ The primary challenge of building Guédelon is to forget the twenty-first century.”</p>



<p>Renucci heads back into the castle, climbs a spiral staircase, and follows the wall-walk to the stonemasons’ pièce de résistance for 2025, the upper level of the gatehouse. Above the gate, masons and carpenters will soon add an arch, a lintel, a portcullis, and a “murder hole”—a maw through which defenders could throw rocks and pour hot pitch on marauders. The design of the 2,000-pound portcullis is an educated guess; there are no working thirteenth-century originals left. Faucherre, who is studying the medieval Louvre Castle in Paris and the Aigues-Mortes ramparts in the south of France for inspriation, was flummoxed by the question of how a portcullis counterweight mechanism would have functioned at these sites. But his conversations with the Guédelon team this year have helped him envision the machines. “We can never be sure,” Faucherre says, “but now we are obliged to make a portcullis that can move.”</p>


<figure data-wp-context="{&quot;imageId&quot;:&quot;68a4572ccfa52&quot;}" data-wp-interactive="core/image"><img decoding="async" width="762" height="1024" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Great-Hall-Church-Motifs-Combo-762x1024.jpg" alt="" data-image-credit="Ben O’Donnell" srcset="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Great-Hall-Church-Motifs-Combo-762x1024.jpg 762w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Great-Hall-Church-Motifs-Combo-223x300.jpg 223w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Great-Hall-Church-Motifs-Combo-768x1032.jpg 768w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Great-Hall-Church-Motifs-Combo.jpg 893w" sizes="(max-width: 762px) 100vw, 762px"><figcaption>Painted motifs in the antechamber of the Great Hall (top) include golden vines, reddish-orange flowers, and a braided-ribbon pattern that mimic designs (above) in a medieval church in nearby Moutiers-en-Puisaye.</figcaption></figure>



<p>The murder hole will remain purely ornamental. “This is a very pacifist castle,” laughs stonemason Yaniv Gammeter. “Very anti-violence here.” In truth, local Guédelon-size Philippian castles such as those at Ratilly, Druyes, and Saint-Vérain weren’t equipped for serious warfare. “You can view these castles as a type of very large manor house,” Gammeter says. “They’re symbols of power but weren’t meant to survive a siege.”</p>



<p><strong>As Guédelon has grown</strong>, so have the possibilities. Why stop at a castle? In the thirteenth century, people here would have painted, prayed, farmed, milled flour, fell ill, recovered, and listened to the leaves and birds to get the day’s weather report. Vanishingly little evidence of those activities can be found by excavating, and thus the artisans and researchers at Guédelon have to get creative. Lachény, the painter, has concocted no fewer than 17 pigments from local ores and plant material, some of which she’s found in the forest herself. While retrieving a bowl of fine dark ocher powder from her oven, she explains that glands on cherry tree leaves, when crushed, boiled, and made into paste, produce a reddish-black hue. In their atelier, the painters glide around color-spattered stacks of mixing bowls, shelves of ceramics, swatches of linen, and trays of yellow, pink, gray, and blue powders. New colors occasionally arrive unannounced. “Sometimes a quarryman cleaving stones comes over saying, ‘I found this,’” says Lachény, who investigates whether the discovery can be useful for her work or for some other endeavor in the castle.</p>



<p>Twelfth- and thirteenth-century wall paintings rarely survive, but some of the most intact examples in France can be found in the Church of Saint Peter and Saint Paul in Moutiers-en-Puisaye, just two miles from Guédelon. Around images of angels, saints, and Adam and Eve, medieval masters enlivened the walls with bright orange flowers, slate-blue stars, and unruly golden vines, motifs that inspired Lachény’s decoration of the Great Hall’s antechamber. “It’s got plenty of spirit, it’s joyful,” she says. “We talk about Dark Ages, but the Middle Ages were really colorful.”</p>



<p>The Middle Ages were also noisy, and sound has proven crucial to the successful construction of a thirteenth-century water mill, one of Guédelon’s more daunting experiments. In 2008, a rescue excavation turned up two medieval mills in eastern France near the village of Thervay. An exceptional trove of 200 wood fragments was preserved from one mill. Using these fragments as their guide, Guédelon’s carpenters spent two years fabricating their own mill. It croaked and creaked, but nevertheless, the millstones barely budged. The miller, Constantin Lemesle, decided to let it run until wood started snapping. “If we don’t make mistakes, we can’t understand the machine,” he says. With a working design on the first try, the mill would have produced plenty of flour but no knowledge. Finally, Lemesle says, the mill is singing.</p>


<figure data-wp-context="{&quot;imageId&quot;:&quot;68a4572cd00d6&quot;}" data-wp-interactive="core/image"><img decoding="async" width="1024" height="683" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Treadmill-1024x683.jpg" alt="" data-image-credit="Ben O’Donnell" srcset="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Treadmill-1024x683.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Treadmill-300x200.jpg 300w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Treadmill-768x512.jpg 768w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Guedelon-Treadmill.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>A huge treadmill powered by pairs of workers who trudge inside it drives a pulley
that lifts stone blocks and mortar up to the parapet of the castle’s curtain wall.</figcaption></figure>



<p>In the past decade, as Guédelon has evolved with endeavors such as the mill, more scientists have come to see and hear all the commotion. Mylène Pardoën, a soundscape archaeologist at the Center of Social Sciences and Humanities, Lyon Saint-Étienne, has visited Guédelon 23 times since 2020 with her arsenal of microphones, which she pokes into the millstones, the cracking quarry slabs, and the fires of the forge. “The thirteenth century sounds different, and every material transmits information,” she says. In 2023, relying almost entirely on data collected at Guédelon, Pardoën composed a four-minute surround-sound reconstruction of the building site of Paris’ Notre Dame Cathedral circa 1170.</p>



<p><strong>After 11 years</strong> of repeatedly fixing Guédelon’s finicky grain-crunching contraption, Lemesle can imagine the whole medieval community’s relationship to the mill. The seigneur collected taxes in the spring for its operation. Peasants in the fiefdom could bake or buy abundant, nutrient-rich bread, leaving time to raise animals and plant crops, an investment toward an energetic summer dedicated to working the fields. In years when the skies failed to provide rain, flour would have to be milled by animal or manual labor, and there’d be fewer hands to, say, build a castle.</p>



<p>How groups and systems functioned or fell apart in the Middle Ages is what the work at Guédelon illuminates above all else for archaeologists. “We’re putting pieces into a big puzzle,” says archaeologist Anne Baud of Lumière University Lyon 2, director of excavations at Cluny Abbey in east-central France. This abbey was enormous, its twelfth-century basilica’s vaults rising nearly 100 feet—then the highest in Western Europe. Nothing like it had ever been built. “You would think there must have been hundreds and hundreds of builders who were working there,” says Baud. “But is that true?” At Guédelon, she and other archaeologists have observed that medieval labor was likely leaner, more collaborative, and more synchronized than accounts of the time suggest. “The empirical knowledge we gain,” Baud says, “is linked to Guédelon’s laborers’ experience.”</p>


<figure data-wp-context="{&quot;imageId&quot;:&quot;68a4572cd0737&quot;}" data-wp-interactive="core/image"><img decoding="async" width="1024" height="625" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Ratilly-Castle-1024x625.jpg" alt="" data-image-credit="Hervé Lenain/Alamy" srcset="https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Ratilly-Castle-1024x625.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Ratilly-Castle-300x183.jpg 300w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Ratilly-Castle-768x469.jpg 768w, https://archaeology.org/wp-content/uploads/2025/07/SO25-France-Ratilly-Castle.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Ratilly Castle was built around 1270 two miles from Guédelon and provided a model for the new castle’s plan.</figcaption></figure>



<p><strong>The Guédelon project</strong> and its artisans have begun to make their mark on restoration efforts across France. When Notre Dame Cathedral burned in 2019, the team was summoned for their highest-profile contribution. (See “<a href="https://archaeology.org/issues/march-april-2022/features/notre-dame-restoration/" target="_blank" rel="noreferrer noopener">Exploring Notre Dame’s Hidden Past</a>.”) Renucci, along with six of Guédelon’s carpenters, set off to help rebuild the Forest, the immense timber framework of the cathedral’s roof. Conventional wisdom held that clear-cutting and drying centuries-old oaks would be required to replicate the original structure. But the Guédelon carpenters knew better. They’d built a formidable oak trusswork for Guédelon’s Great Hall several years earlier, learning that smaller, younger oaks, freshly cut and green with moisture, were more pliable. The crew brought along 60 custom-fitted medieval axes, forged at their castle, to equip the Forest’s carpenters. “I’m very proud of this,” says Martin, Guédelon’s proprietor. “It’s necessary to have dreams together.”</p>



<p>No one expects the Guédelon reverie to end any time soon. Baud and Renucci are now hashing out plans for a Guédelon church in the forthcoming Guédelon village, which is still on the drawing board. On a sunny afternoon, Renucci stops by Ratilly Castle for ideas. He traces the courses of stone, pulls weeds from cracks in the mortar, and inspects long-ago quarrier’s marks and scaffolding holes. He starts to forget the twenty-first century, his mind on gates and portcullises and spectral guards heaving them open and clanging them shut. The castle’s centuries-old knotty oak door, heavy with a mess of iron bolts and locks, catches his eye. “Very interesting, this kind of system,” Renucci muses, snapping a photo of an entryway he has walked through dozens of times. “You come for stone, and you notice wood. That’s the magic thing about a castle.”</p>


<div id="guedelon-slideshow">
    

<p>Slideshow: Building the Last Medieval Castle</p>



<p><strong>Philip II</strong>, the first ruler to style himself king of France, reigned from 1180 to 1223, but some of the 100 or so surviving French castles designed in the Philippian style postdate the king’s death by decades. In fact, work on the newest example of the style, Guédelon Castle, began in 1998. In the quarter-century since construction started in the forested Puisaye region of Burgundy, Guédelon has become one of the world’s most comprehensive and longest-running experimental archaeology projects. Everything done on site, from mixing lime mortar to cutting timber beams to weaving baskets, uses only thirteenth-century tools, techniques, and materials. Guédelon’s 40 stonemasons, woodcutters, weavers, painters, blacksmiths, and other artisans draw inspiration from contemporaneous sites and texts. Each obstacle they encounter is an opportunity to solve a problem, medieval-style, and to fill a gap in archaeologists’ knowledge of the era.</p>



<figure><figure><img decoding="async" width="1024" height="575" data-id="52309" src="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Pigeon-Tower-Cupola-1024x575.jpg" alt="" data-image-credit="© Guédelon" srcset="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Pigeon-Tower-Cupola-1024x575.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Pigeon-Tower-Cupola-300x169.jpg 300w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Pigeon-Tower-Cupola-768x432.jpg 768w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Pigeon-Tower-Cupola.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>In 2023, carpenters and tilers completed the cupola atop Guédelon Castle’s Pigeon Tower (shown under construction in foreground). Each year, the castle’s builders focus on a handful of architectural elements, but only about half of the job concerns sticks and stones. The other half involves demonstrating and explaining medieval work to the 300,000 visitors who come annually. It may be taking much longer to build Guédelon than it did to build castles 800 years ago, but at least there aren’t as many sieges to deal with these days.</figcaption></figure>


<figure><img decoding="async" width="1024" height="680" data-id="52312" src="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Window-Mold-1024x680.jpg" alt="" data-image-credit="© Guédelon" srcset="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Window-Mold-1024x680.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Window-Mold-300x199.jpg 300w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Window-Mold-768x510.jpg 768w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Window-Mold.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Guédelon Castle sits on the site of an old quarry for ferruginous (iron-streaked) sandstone, and most of the structure is built from this material. A nearby limestone quarry supplies raw material for decorative carved stonework, such as the Chapel Tower’s Gothic window mold, shown here, which took years to complete. “We always imagine the medieval stonemasons who are cutting or carving the stone, because it’s really a noble profession,” says archaeologist Anne Baud of Lumière University Lyon 2.</figcaption></figure>


<figure><img decoding="async" width="1024" height="912" data-id="52311" src="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Window-Frame-Fitting-1024x912.jpg" alt="" data-image-credit="© Guédelon" srcset="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Window-Frame-Fitting-1024x912.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Window-Frame-Fitting-300x267.jpg 300w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Window-Frame-Fitting-768x684.jpg 768w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Window-Frame-Fitting.jpg 1348w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>A carpenter fits a finished wooden frame into the Chapel Tower window mold. When the window is completed, it will be the final piece of the tower, a showpiece space crowned with a rib-vaulted ceiling executed using only stone, mortar, and a temporary wooden framework. There was little room for error during its careful construction. “Everything would have collapsed,” says master mason and Guédelon site director Florian Renucci. “It is the only thing that sometimes makes me lose sleep!”</figcaption></figure>


<figure><img decoding="async" width="1024" height="768" data-id="52307" src="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Gothic-Arch-Sketch-1024x768.jpg" alt="" data-image-credit="Ben O’Donnell" srcset="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Gothic-Arch-Sketch-1024x768.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Gothic-Arch-Sketch-300x225.jpg 300w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Gothic-Arch-Sketch-768x576.jpg 768w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Gothic-Arch-Sketch.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Inside the castle below the wall-walk, artisans use measuring sticks and drawing compasses to teach visitors about medieval architecture. By 1228, the fictional founding date of Guédelon, Gothic arches and flourishes had begun to replace Romanesque ones in monumental construction. As this sketch in the sand shows, these Gothic structures could climb higher because they distributed weight more evenly on more slender supports. Every artisan at the castle can draw, and all sketches for all designs needed to construct Guédelon are handmade.</figcaption></figure>


<figure><img decoding="async" width="1024" height="768" data-id="52308" src="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Masons-Vossoir-Stone-1024x768.jpg" alt="" data-image-credit="© Guédelon" srcset="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Masons-Vossoir-Stone-1024x768.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Masons-Vossoir-Stone-300x225.jpg 300w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Masons-Vossoir-Stone-768x576.jpg 768w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Masons-Vossoir-Stone.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Masons insert a voussoir stone into an arch over the castle’s east gate. All masonry at Guédelon is joined and sealed with a period-appropriate lime mortar mixture. Archaeologists studied the mortar at the nearby thirteenth-century castles of Ratilly and St.-Fargeau to formulate the recipe. Archaeologist Anne Baud has observed trowel marks in the lime mortar at medieval sites all over the world. At Guédelon, she noticed that when masons made similar scrapes in the mortar, calcite squeezed out, drying into a protective facing over the seams between stones. This is one of many medieval construction techniques that the Guédelon experiment has demystified.</figcaption></figure>


<figure><img decoding="async" width="1024" height="683" data-id="52310" src="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Pigment-Tray-1024x683.jpg" alt="" data-image-credit="Ben O’Donnell" srcset="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Pigment-Tray-1024x683.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Pigment-Tray-300x200.jpg 300w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Pigment-Tray-768x512.jpg 768w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Pigment-Tray.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Painter Valérie Lachény spoons freshly made pigment into a tray in her atelier. Using ores and plants from Guédelon’s surroundings, she has concocted 17 different pigments—so far—including browns, oranges, reds, yellows, blues, grays, and pinks. There is, however, no green. The color green isn’t found in the preserved medieval wall paintings at a church in Moutiers-en-Puisaye, two miles away, either, suggesting that the raw materials necessary to make a green pigment are not present in the area.</figcaption></figure>


<figure><img decoding="async" width="1024" height="683" data-id="52306" src="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Forge-Nails-1024x683.jpg" alt="" data-image-credit="Ben O’Donnell" srcset="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Forge-Nails-1024x683.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Forge-Nails-300x200.jpg 300w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Forge-Nails-768x512.jpg 768w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Forge-Nails.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>All the artisans at Guédelon appreciate the blacksmiths, who make iron tools for everyone else, each of which is custom-fitted. On an April day in 2025, the main item on the menu at the forge, however, is nails.</figcaption></figure>


<figure><img decoding="async" width="1024" height="683" data-id="52313" src="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Woodcutter-1024x683.jpg" alt="" data-image-credit="Ben O’Donnell" srcset="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Woodcutter-1024x683.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Woodcutter-300x200.jpg 300w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Woodcutter-768x512.jpg 768w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Woodcutter.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>A woodcutter cuts logs into timber beams. Conventional wisdom held that dried, centuries-old oaks were required for large-scale medieval construction in wood, but the team at Guédelon has determined that younger oaks, worked while still green with moisture, are more pliable.</figcaption></figure>


<figure><img decoding="async" width="1024" height="576" data-id="52305" src="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Footbridge-1024x576.jpg" alt="" data-image-credit="© Guédelon" srcset="https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Footbridge-1024x576.jpg 1024w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Footbridge-300x169.jpg 300w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Footbridge-768x432.jpg 768w, https://archaeology.org/wp-content/uploads/2025/08/SO25-France-Guedelon-Footbridge.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Virtually everything made at Guédelon is a team effort, but some days call for more team and more effort. The construction of a footbridge to the castle’s east gate in 2024 required carpenters, masons, winches, pulleys, ropes, tools, and cooperative weather.</figcaption></figure>
</figure>


      </div>


<div id="black-border19">
    

<p>Video: Blacksmiths at Work</p>



<p><strong>Blacksmiths Caroline Hasne</strong> and Mathis Lacroix forge a tool for making nails. Hasne, a new employee in a very old job, likes the work so far. “I love to try to re-create some old techniques that we don’t see anymore by studying old objects,” she says. “And I’m paid to do it!” (Credit: Ben O’Donnell)</p>



<figure><p>
<iframe title="Guédelon’s Blacksmiths at Work" width="640" height="360" src="https://www.youtube.com/embed/cB7_P3CYHrc?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>


      </div>


<div id="black-border20">
    

<p>Video: Guédelon’s Mighty Mill</p>



<p><strong>The water mill</strong> in Guédelon Forest comes to life each spring, weather permitting. Its design follows a medieval mill found in 2008 in the village of Thervay, 160 miles east of Guédelon. That machine was only preserved in fragments of wood, and no one knew how such a thing would run in practice. In the first years of the Guédelon mill’s operation, the upright wooden cogs on the small horizontal gear proved brittle. They were replaced with ones notched along the grooves of the wood. Pig-fat grease was swapped out for cow fat. Spring brought the right amount of rain. Et voilà! (Credit: Ben O’Donnell)</p>



<figure><p>
<iframe title="Guédelon’s Mighty Mill" width="640" height="360" src="https://www.youtube.com/embed/j-1Ay9ADXoo?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>


      </div>


<div id="black-border21">
    

<p>Video: A Weaver’s Craft</p>



<p><strong>Today</strong>, baskets are for picnics and the Easter Bunny, but in the Middle Ages, they were all-purpose containers, used for collecting and storing crops and food, or for transporting construction tools and materials. Like the blacksmith, the basket weaver touches practically every part of the castle and community in some way. (Credit: Ben O’Donnell)</p>



<figure><p>
<iframe title="A Guédelon Weaver’s Craft" width="640" height="360" src="https://www.youtube.com/embed/e_LEhQG7baA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>


      </div>
                                              
                                        
            </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenMower – An open source lawn mower (446 pts)]]></title>
            <link>https://github.com/ClemensElflein/OpenMower</link>
            <guid>44946996</guid>
            <pubDate>Tue, 19 Aug 2025 00:35:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ClemensElflein/OpenMower">https://github.com/ClemensElflein/OpenMower</a>, See on <a href="https://news.ycombinator.com/item?id=44946996">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">I am available for hire</h2><a id="user-content-i-am-available-for-hire" aria-label="Permalink: I am available for hire" href="#i-am-available-for-hire"></a></p>
<p dir="auto">Hello! With a background in software engineering, embedded programming, hardware design, and robotics, I'm on the lookout for new challenges.
If you're in search of someone with my skills, let's team up and create something amazing! <a href="https://x-tech.online/" rel="nofollow">https://x-tech.online/</a></p>
<br>
<hr>

<p dir="auto"><h2 tabindex="-1" dir="auto">OpenMower - The DIY Smart Mowing Robot for Everyone</h2><a id="user-content-openmower---the-diy-smart-mowing-robot-for-everyone" aria-label="Permalink: OpenMower - The DIY Smart Mowing Robot for Everyone" href="#openmower---the-diy-smart-mowing-robot-for-everyone"></a></p>
    <p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ClemensElflein/OpenMower/blob/main/img/open_mower_header.jpg"><img src="https://github.com/ClemensElflein/OpenMower/raw/main/img/open_mower_header.jpg"></a></p>
  


<p dir="auto">
  <a href="#license"><img src="https://camo.githubusercontent.com/f61dcd7e9460d79b9e8e19683c964e21cc2455ff9d8860cc5ca30f35457be635/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d434325323042592d2d4e432d2d5341253230342e302d6c69676874677265792e737667" data-canonical-src="https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg"></a></p>
  
  <p dir="auto"><b>Join the Discord server for OpenMower discussion:</b>
  </p><p dir="auto"><a href="https://discord.gg/jE7QNaSxW7" rel="nofollow"><img src="https://camo.githubusercontent.com/3ed6b7ce339222fba86763bbfdbf5c999c91abd21b044916d00ac6a2c4469171/68747470733a2f2f62616467656e2e6e65742f62616467652f69636f6e2f646973636f72643f69636f6e3d646973636f7264266c6162656c" data-canonical-src="https://badgen.net/badge/icon/discord?icon=discord&amp;label"></a></p>

<div dir="auto"><p dir="auto">Warning</p>
<p dir="auto"><b>DISCLAIMER:</b></p>
<p dir="auto"><strong>IF YOU ARE NOT 100% SURE WHAT YOU ARE DOING, PLEASE DON'T TRY THIS AT HOME! ASK IN <a href="https://discord.gg/jE7QNaSxW7" rel="nofollow">DISCORD</a>, IF YOU HAVE ANY QUESTIONS!</strong></p>
</div>
<div dir="auto"><p dir="auto">Important</p>
<p dir="auto"><b>This project is active!</b></p>
<p dir="auto">This is the hardware repository, so it might seem that the project is inactive, since hardware is pretty stable by now.
Most of the development work is done on the ROS code here: <a href="https://github.com/ClemensElflein/open_mower_ros">https://github.com/ClemensElflein/open_mower_ros</a></p>
</div>

<p dir="auto"><h2 tabindex="-1" dir="auto">About the Project</h2><a id="user-content-about-the-project" aria-label="Permalink: About the Project" href="#about-the-project"></a></p>
<p dir="auto">If you want to see a quick overview, you can check out this video:</p>
<p dir="auto">
  <a href="https://www.youtube.com/watch?v=BSF04i3zNGw" rel="nofollow"><img src="https://user-images.githubusercontent.com/2864655/161540069-f4263fa7-a47b-49d2-a7bc-d1cdc3a47704.jpg"></a>
</p>
<p dir="auto">Let's be honest: The current generation of robotic lawn mowers sucks. Basically all of these bots drive in a random direction until they hit the border of the lawn, rotate for a randomized duration and repeat. <strong>I think we can do better!</strong></p>
<p dir="auto">Therefore, we have disassembled the cheapest off-the-shelf robotic mower  we could find (YardForce Classic 500) and were surprised that the hardware itself is actually quite decent:</p>
<ul dir="auto">
<li>Geared sensored brushless motors for the wheels</li>
<li>A sensored brushless motor for the mower motor itself</li>
<li>The whole construction seems robust, waterproof and all in all thought through</li>
<li>All components are connected using standard connectors, therefore upgrading the hardware is easily possible.</li>
</ul>
<p dir="auto">The bottom line is: The bot itself is surprisingly high quality and doesn't need to be changed at all. <strong>We just need some better software in there</strong>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Project Goals</h2><a id="user-content-project-goals" aria-label="Permalink: Project Goals" href="#project-goals"></a></p>
<p dir="auto">Here is a quick overview of this project's goals:</p>
<p dir="auto">✔️ <strong>Autonomous Lawn Mowing:</strong> Obviously, the device should be able to mow the lawn automatically.</p>
<p dir="auto">✔️ <strong>Good Safety:</strong> The device must be safe, e.g. emergency stop if lifted or crashed.</p>
<p dir="auto">✔️ <strong>No Perimeter Wire Needed:</strong> We want to be flexible and support multiple mowing areas.</p>
<p dir="auto">✔️ <strong>Low Cost:</strong> It should be cheaper than a mid range off-the-shelf product</p>
<p dir="auto">✔️ <strong>Open:</strong> I want to share knowledge and enable others to build an OpenMower as well.</p>
<p dir="auto">✔️ <strong>Nice to Look At:</strong> You should not be ashamed to have an OpenMower mowing your lawn.</p>
<p dir="auto">✔️ <strong>Avoid Obstacles:</strong> The mower should detect obstacles and avoid them during mowing.</p>
<p dir="auto">✔️ <strong>Rain Detection:</strong> The device should be able to detect bad weather conditions and pause mowing until they improve.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Open Mower App</h2><a id="user-content-open-mower-app" aria-label="Permalink: Open Mower App" href="#open-mower-app"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ClemensElflein/OpenMower/blob/main/img/open_mower_app_1.jpg"><img src="https://github.com/ClemensElflein/OpenMower/raw/main/img/open_mower_app_1.jpg" alt="Open Mower App 1"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ClemensElflein/OpenMower/blob/main/img/open_mower_app_2.jpg"><img src="https://github.com/ClemensElflein/OpenMower/raw/main/img/open_mower_app_2.jpg" alt="Open Mower App 2"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Current State</h2><a id="user-content-current-state" aria-label="Permalink: Current State" href="#current-state"></a></p>
<p dir="auto">The basic mowing function finally works! As you can see in the video, map teaching and mowing work as expected. It even returns to the docking station automatically as soon as the battery gets low and continues once it's recharged.</p>
<p dir="auto">At this point I can recommend that brave tech savvy users can build one for themselves! Since it's quite an expensive and complex project, please don't be shy and ask if you have any questions. I'm glad to help 🙂</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Hardware</h3><a id="user-content-hardware" aria-label="Permalink: Hardware" href="#hardware"></a></p>
<p dir="auto">By now we have a stable revision of the mainboard as well as two motor controllers to go with it. The <a href="https://github.com/clemensElflein/xesc">xESC mini</a> and the <a href="https://github.com/clemensElflein/xesc2040">xESC 2040</a>. I'm currently using the xESC mini for my builds and it works very well. The problem with this controller is, its parts are currently hard to source. That's why we created the xESC 2040 based on the RP2040 chip. This is the low-cost variant and its support is currently experimental.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Hardware To-Do:</h4><a id="user-content-hardware-to-do" aria-label="Permalink: Hardware To-Do:" href="#hardware-to-do"></a></p>
<ul>
<li> Low Level Firmware Implementation
<ul>
<li> Voltage / Current Sense</li>
<li> Emergency Stop Button tracking</li>
<li> IMU Communication</li>
<li> Rain Sensor</li>
<li> Charging State</li>
<li> Sound Module</li>
<li> UI Board Communication</li>
<li> Discharge current for more accurate battery charge estimation</li>
</ul>
</li>
<li> ROS Hardware Interface</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Software</h3><a id="user-content-software" aria-label="Permalink: Software" href="#software"></a></p>
<p dir="auto">The basic software is basically done; Our prototype works as intended (but is not able to avoid obstacles yet).</p>
<p dir="auto">The software for the robot can be found in a separate repository: <a href="https://github.com/ClemensElflein/open_mower_ros">https://github.com/ClemensElflein/open_mower_ros</a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Software To-Do:</h4><a id="user-content-software-to-do" aria-label="Permalink: Software To-Do:" href="#software-to-do"></a></p>
<ul>
<li> Mowing State Machine (Docking / Mowing, ...)</li>
<li> Path Planning</li>
<li> Obstacle Avoidance</li>
<li> App / Visualization</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto">If you want to read how to get started building a robot for yourself, check the <a href="https://openmower.de/" rel="nofollow">OpenMower Website</a>. There you can find information on which parts to buy, how to install the software and so on. If you find anything missing, please join the Discord server and ask there. Also there's the <a href="https://wiki.openmower.de/" rel="nofollow">OpenMower Wiki</a> which is written by the community. It has some additional guides and information.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How You Can Help</h2><a id="user-content-how-you-can-help" aria-label="Permalink: How You Can Help" href="#how-you-can-help"></a></p>
<p dir="auto">You can help by starting an OpenMower build of your own. This helps to validate the concept and helps to create useful documentation for new users.</p>
<p dir="auto">Additionally, you can help by starring 🌟 and watching 👀 this repository, since it will help with visibility. You can also subscribe to my <a href="https://youtube.com/c/ClemensElflein" rel="nofollow">YouTube channel</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Compatible Robotic Mowers</h2><a id="user-content-compatible-robotic-mowers" aria-label="Permalink: Compatible Robotic Mowers" href="#compatible-robotic-mowers"></a></p>
<p dir="auto">While disassembling the bot, I wondered about its mainboard: Instead of "YardForce" it read "GForce". After checking the internet for "GForce" robots, I found that that very similar looking robotic mowers are sold under the Herkules brand. Naturally I tried to dig deeper and actually found evidence that the mainboard is manufactured by some chinese company (SUMEC Hardware).</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ClemensElflein/OpenMower/blob/main/img/mainboard.jpg"><img src="https://github.com/ClemensElflein/OpenMower/raw/main/img/mainboard.jpg" alt="GForce Robot Mower Mainboard"></a></p>
<p dir="auto">It is therefore quite safe to assume that many robot mowers are basically the same device in a different case. This would be a huge win for the community, since this would mean that by making one of those robots smarter, we could upgrade lots of robots.</p>
<p dir="auto">Therefore it might be a good idea to start a list of compatible devices. So if you have a cheap robotic lawn mower, you can check, if it was already disassembled in the list below. If it's not there, it would be nice of you to check, if it contains the same mainboard as ours and add your robot to the list with some some pictures / model numbers.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">List of Compatible Mowers</h3><a id="user-content-list-of-compatible-mowers" aria-label="Permalink: List of Compatible Mowers" href="#list-of-compatible-mowers"></a></p>
<p dir="auto">By now, some guys have disassembled their mowers and it doesn't look as good as I initially hoped. The GForce boards are basically just used by YardForce and some rebranded versions for the EU market. My exact hardware was only found in the mower I'm using (YardForce Classic 500) and in recently manufactured SA650 ECOs. The SA650 has a different chassis and we don't have a way of mounting the GPS antenna yet. Therefore at the moment, the only compatible mower is mine (the YardForce Classic 500).</p>
<p dir="auto">If you want to have a look at the disassembled mowers, check the Google Docs <a href="https://docs.google.com/spreadsheets/d/1BX0-KEs5v-VED8-RA4BLE-wRdXHtlmcKy4n9K5vJVAA" rel="nofollow">here</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">More Infos</h2><a id="user-content-more-infos" aria-label="Permalink: More Infos" href="#more-infos"></a></p>
<p dir="auto">This page only contains the basic overview of the project. To follow my current development state, check out my <a href="https://x-tech.online/" rel="nofollow">Blog</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Patents, Local Laws, Liability</h2><a id="user-content-patents-local-laws-liability" aria-label="Permalink: Patents, Local Laws, Liability" href="#patents-local-laws-liability"></a></p>
<p dir="auto">Before building a robot based on the designs published here, please make sure that you are allowed to do so in your specific regions.
There may be patents and / or laws prohibiting you of doing so.</p>
<p dir="auto">The code/schematics/PCB files are distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</p>
<p dir="auto">This basically means: I'm just documenting a project of mine here for free and I don't have the time and resources to check that devices built using this information will be safe to use, legal to use or even work as intended. You will need technical know-how to use this project and I'm not liable for any damages your devices do to anyone or anything.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto"><a href="http://creativecommons.org/licenses/by-nc-sa/4.0/" rel="nofollow"><img alt="Creative Commons License" src="https://camo.githubusercontent.com/62be294f71c9a1885f9cd8f54aa8b8bd42d432fd14b5393a8b25bcd1f34daa42/68747470733a2f2f692e6372656174697665636f6d6d6f6e732e6f72672f6c2f62792d6e632d73612f342e302f38387833312e706e67" data-canonical-src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"></a><br>This work is licensed under a <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/" rel="nofollow">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.</p>
<p dir="auto">Feel free to use the design in your private/educational projects, but don't try to sell the design or products based on it without getting my consent first. The idea here is to share knowledge, not to enable others to simply sell my work. Thank you for understanding.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ted Chiang: The Secret Third Thing (192 pts)]]></title>
            <link>https://linch.substack.com/p/ted-chiang-review</link>
            <guid>44946774</guid>
            <pubDate>Tue, 19 Aug 2025 00:05:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://linch.substack.com/p/ted-chiang-review">https://linch.substack.com/p/ted-chiang-review</a>, See on <a href="https://news.ycombinator.com/item?id=44946774">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>I really like Ted Chiang’s writing.</p><p>I think he's probably the best science fiction short story writer alive, and possibly the best short story writer, period.</p><p><span>I've read every one of his stories at least twice, and The Merchant and the Alchemist's Gate more like seven times. I’ve noticed many of his readers, including some of his most positive reviewers</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-171116224" href="https://linch.substack.com/p/ted-chiang-review#footnote-1-171116224" target="_self" rel="">1</a></span><span>, miss one key point or another of his works, and thus don't fully appreciate his genius.</span></p><p>This review covers what he does extremely well, especially unique elements that other science fiction writers have not done as well, or at all.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!H6ea!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae13be8-25e5-4a7d-9f54-4c246cac09ab_1600x1600.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!H6ea!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae13be8-25e5-4a7d-9f54-4c246cac09ab_1600x1600.png 424w, https://substackcdn.com/image/fetch/$s_!H6ea!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae13be8-25e5-4a7d-9f54-4c246cac09ab_1600x1600.png 848w, https://substackcdn.com/image/fetch/$s_!H6ea!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae13be8-25e5-4a7d-9f54-4c246cac09ab_1600x1600.png 1272w, https://substackcdn.com/image/fetch/$s_!H6ea!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae13be8-25e5-4a7d-9f54-4c246cac09ab_1600x1600.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!H6ea!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae13be8-25e5-4a7d-9f54-4c246cac09ab_1600x1600.png" width="477" height="477" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3ae13be8-25e5-4a7d-9f54-4c246cac09ab_1600x1600.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1456,&quot;width&quot;:1456,&quot;resizeWidth&quot;:477,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!H6ea!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae13be8-25e5-4a7d-9f54-4c246cac09ab_1600x1600.png 424w, https://substackcdn.com/image/fetch/$s_!H6ea!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae13be8-25e5-4a7d-9f54-4c246cac09ab_1600x1600.png 848w, https://substackcdn.com/image/fetch/$s_!H6ea!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae13be8-25e5-4a7d-9f54-4c246cac09ab_1600x1600.png 1272w, https://substackcdn.com/image/fetch/$s_!H6ea!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae13be8-25e5-4a7d-9f54-4c246cac09ab_1600x1600.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>Science fiction critics often divide the genre into:</p><ul><li><p><span>"hard" science fiction: aka </span><em>engineering</em><span> fiction, stories built on scientifically accurate extrapolations of real physics and technology (think Arthur C. Clarke)</span></p></li><li><p><span>"soft" science fiction: aka science </span><em>fantasy</em><span>, which uses scientific trappings as window dressing for character-driven or sociological stories (think Star Wars).</span></p></li></ul><p><span>Ted Chiang has written stories plausibly categorized as either, but more excitingly, many of his stories are </span><em>neither</em><span>. He often writes what I think of as true </span><em>science</em><span> fiction, where the </span><em>principles of science themselves</em><span> are meaningfully different from our world, but still internally consistent.</span></p><p><span>In </span><em>Omphalos</em><span>, Young Earth Creationism is empirically true</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-171116224" href="https://linch.substack.com/p/ted-chiang-review#footnote-2-171116224" target="_self" rel="">2</a></span><span>. Astronomers can only see light from stars 6,000 light-years away. Fossilized trees have centers with no rings. The first God-created humans lack belly buttons. The scientists in that story keep discovering multiple independent lines of evidence that converge on creationism: because in that universe, they're simply correct.</span></p><p><span>In </span><em>Seventy-Two Letters</em><span>, technology springs from Jewish Kabbalah. Golems and divine names drive industrial progress in a steampunk world</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-171116224" href="https://linch.substack.com/p/ted-chiang-review#footnote-3-171116224" target="_self" rel="">3</a></span><span>.</span></p><p><span>Excitingly, he does this not just with natural sciences but social sciences as well. In </span><em>Story of Your Life</em><span>, strong </span><a href="http://sapir-whorf/" rel="">Sapir-Whorf</a><span> (the idea that language significantly constrains thought) isn't a largely discredited linguistic hypothesis, but the key to navigating First Contact with alien minds that experience past and future as equally present.</span></p><p>This comes up in his other stories as well:</p><ul><li><p><span>In </span><em>Exhalation,</em><span> thermodynamics appear to work differently</span></p></li><li><p><span>In </span><em>Division By Zero</em><span>, mathematics itself is broken from within.</span></p></li><li><p><span>In </span><em>Hell Is the Absence of God</em><span>, divine intervention is empirically observable and follows consistent rules</span></p></li></ul><p><span>Many of his readers, even in their otherwise rave reviews, miss this. Multiple reviewers complain about how the science in his stories are “unrealistic” (e.g. strong Sapir-Whorf is “discredited”). They expected </span><em>hard</em><span> science fiction; Chiang was doing something different. Chiang created different universes with internally self-consistent scientific laws, using science fiction and alternative science as a vehicle for exploring philosophical progress and human relationships.</span></p><p><span>Science fiction writers used to </span><em>like</em><span> technology. For some reason, this has become increasingly uncommon, even passé. Doubly so for Western writers, and quadruply so for Western, literary, “humanist” writers.</span></p><p><span>Now it’s hip and trendy to think of every new technology as the </span><a href="https://x.com/AlexBlechman/status/1457842724128833538?lang=en" rel="">Torment Nexus</a><span>. Most science fiction today feels like </span><a href="https://en.wikipedia.org/wiki/Black_Mirror" rel="">Black Mirror,</a><span> which ran 7 seasons with exactly one happy ending.</span></p><p><span>Chiang bucks this trend. </span><a href="https://www.newyorker.com/magazine/2019/05/13/science-fiction-doesnt-have-to-be-dystopian" rel="">Joyce Carol Oates</a><span>:</span></p><blockquote><p>It is both a surprise and a relief to encounter fiction that [...] ask[s] anew philosophical questions that have been posed repeatedly through millennia to no avail. Chiang’s materialist universe is a secular place, in which God, if there is one, belongs to the phenomenal realm of scientific investigation and usually has no particular interest in humankind. But it is also a place in which the natural inquisitiveness of our species leads us to ever more astonishing truths, and an alliance with technological advances is likely to enhance us, not diminish us. Human curiosity, for Chiang, is a nearly divine engine of progress.</p></blockquote><p><span>In the hands of a lesser (or perhaps just more pessimistic) writer, many of the technologies and ideas Chiang explores will have an accursed quality to them, a monkey’s paw that curls into delivering a future much worse than a more innocent, pastoral past. Chiang resists those cliches. In </span><em>The Truth of Fact, The Truth of Feeling</em><span>, memory augmentation technology allows the narrator to understand his own self-deceptions, and work towards becoming a better person and reconciling with loved ones and even himself. In </span><em>Liking What You See: A Documentary</em><span>, a technology that gives users acquired face-blindness allows the main characters to meditate on the nature of human beauty and the shallowness inherent in privileging the beautiful.</span></p><p>Even in situations where the story is overall tragic, like when the characters are faced with existential crisis (in the individual sense), or existential catastrophe (in the world-ending sense), technology isn't the villain but the vehicle for understanding unbearable truths (whether about the world or about ourselves).</p><p><span>Chiang consistently shows us the potential of technology to help us become </span><em>more</em><span> human, and have a deeper appreciation for the world and our place in it.</span></p><p><em>“Compatibilism is a philosophical stance that reconciles free will with determinism. It argues that free will, understood as the ability to act according to one's desires, is compatible with the idea that all events, including human actions, are causally determined by prior events. Essentially, compatibilists believe that even if our choices are predetermined, we can still be considered free and morally responsible if those choices are a result of our own internal states, like desires and intentions.”</em></p><p><span>Does that make sense to you? I’m not sure it does to me. In practice, compatibilism says something like “</span><em>free will in the normal, pretheoretic sense of the term, doesn’t exist. Your choices still meaningfully matter nonetheless. You can’t meaningfully get out of the bind philosophically. What you can do, however, is make peace with it.”</em></p><p>Chiang makes this realization visceral. From The Merchant and the Alchemist's Gate:</p><blockquote><p>“My journey to the past had changed nothing, but what I had learned had changed everything...Nothing erases the past. There is repentance, there is atonement, and there is forgiveness. That is all, but that is enough.”</p></blockquote><p><span>“That is all, but that is enough” on the surface sounds like a </span><a href="https://philosophytalk.org/blog/deepities-and-bullshit/" rel="">deepity</a><span>, but I genuinely find it more moving than anything else I’ve read on free will, determinism, or compatibilism.</span></p><p>When Chiang uses time travel as a motif, the stories differ from typical time travel stories. Because causation is a closed loop, knowing the future does not give you special access to it, and Chiang’s characters tend to not fight the future (successfully or otherwise).</p><p><span>In Story of Your Life [SPOILERS], the narrator learns an atemporal alien language and begins experiencing past and future as equally real.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-171116224" href="https://linch.substack.com/p/ted-chiang-review#footnote-4-171116224" target="_self" rel="">4</a></span><span> It takes her some time to make peace with it, but eventually she fully accepts the truth of determinism. She understands that life is full of tragedy, including that her daughter will die young, but life is full of beauty too. With both regret and awe, she sets forth on the path that she was destined to take</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5-171116224" href="https://linch.substack.com/p/ted-chiang-review#footnote-5-171116224" target="_self" rel="">5</a></span><span>.</span></p><p>This is compatibilism from the inside. In both stories, the characters discover they cannot change what will happen, but this knowledge transforms how they experience what must happen: with forgiveness, acceptance, and even joy.</p><p><span>As a friend of mine puts it, “he treats philosophical ideas as lived experiences.”The mathematician in </span><em>Division by Zero</em><span> doesn't just intellectually understand that mathematics is broken; she experiences it as a personal catastrophe, on par with (and concurrent with) her marriage's collapse. In </span><em>Lifecycle of Software Objects</em><span>, the “we are the parents of our mind-children” metaphor for building sentient AI systems becomes quite literal.</span></p><p>I've reread all his stories not just because I love his writing, but because they often mean something different the second time through. Like those optical illusions where seeing the duck in the rabbit changes the image forever, his endings don't surprise so much as illuminate.</p><p>In a sense, this narrative technique is compatibilism as literary form: the ending was always determined, but discovering it still matters. Knowing where you're headed changes how you experience the journey, not whether you take it.</p><p>Notably, he achieves this without cheap tricks or twist endings (however foreshadowed), but something deeper. The endings feel inevitable rather than clever. This technique is so difficult that it's surprising he's managed it repeatedly, using different approaches each time.</p><p>Chiang combines these unique factors that he does exceptionally well with strengths that he shares with other top literary science fiction writers: simple yet beautiful prose, diverse settings, a rigorous understanding of science, philosophy, and human psychology, and appealing, interesting, and diverse characters.</p><p>He is probably the best science fiction short story writer alive, and possibly the best short story writer in general.</p><p><span>Is Chiang perfect? Of course not. I won't belabor obvious points like his nonfictional views on current-generation LLMs being surprisingly shallow</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-6-171116224" href="https://linch.substack.com/p/ted-chiang-review#footnote-6-171116224" target="_self" rel="">6</a></span><span>, or his lack of output being tragic for a generational talent</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-7-171116224" href="https://linch.substack.com/p/ted-chiang-review#footnote-7-171116224" target="_self" rel="">7</a></span><span>.</span></p><p>Instead, I'll focus on two points: weaknesses in portraying how entire societies interface with technology, and his lack of home runs outside of compatibilism.</p><p>I’m an intellectual dilettante. I’m widely read in many fields, and an expert in none. But to the extent I have any real expertise, it’s probably the intersection of the social sciences and technology. And Chiang is surprisingly weak here.</p><p>Chiang’s scientific imagination is strongest at the very macro level (What would the objective physical evidence look like if God created Earth 6,000 years ago?) and the very micro level: This is one person, a named character. How would she and her husband interface with technology? How would technology radically change her life and her self-perception? Chiang’s much weaker at the middle level, where we consider how societies and civilizations collectively face novel technologies.</p><p><span>In </span><em>Anxiety is the Dizziness of Freedom</em><span>, people invented a new Prism(™) that allows them to talk to copies in nearby universes. Chiang treats this technology as an interesting tool to explore his favorite questions of free will, determinism, and what does it mean to be a person, etc.</span></p><p>I think he doesn’t understand the power of this singularity-level technology he just introduced.</p><p>The ability to send bits across parallel universes is just insane in terms of economic and experimentation value. For example, pharmaceutical companies can do $100 billion trials for all sorts of novel drugs, and trade the results of this information with their clones in other universes. Massive R&amp;D projects in general can be done in parallel across different universes, as long as the results can be compressed in enough bits to be sent over these prisms.</p><p>More than that, you can now have not just individual or small-group level studies but societal-wide or even multiverse-wide ones! Wondering whether raising interest rates can cause recessions? Just conduct RCTs across multiverses (and if they can’t coordinate on RCTs, even the observational data would be insanely useful)!</p><p>While the main characters work through existential crises and their mundane, human worries, the rest of society should be accelerating at breakneck speed toward doom, utopia, or something else equally fascinating. Chiang doesn't explore this, even as backdrop.</p><p>While his fictional portrayals of compatibilism are probably the world's best, and he's covered different angles repeatedly, his other philosophical explorations don't achieve the same resonance. Having something both philosophically deep and emotionally resonant is genuinely hard. So I don’t want to be overly critical. But perhaps the lack of attempts on new ideas is not unrelated to his extreme perfectionism and sparse output?</p><p><span>I cannot recommend Chiang more highly. If you could only read one science fiction book this year, I recommend reading </span><em>Stories of Your Life</em><span>. If you could only read 2 science fiction books this year, I recommend reading both </span><em>Stories of Your Life</em><span> and </span><em>Exhalation</em><span>.</span></p><figure data-drag-handle="true" data-component-name="ImageGallery"><div><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!l_KA!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a03822c-fe6c-4013-876c-46f0b77ca3b5_778x1200.jpeg 424w, https://substackcdn.com/image/fetch/$s_!l_KA!,w_720,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a03822c-fe6c-4013-876c-46f0b77ca3b5_778x1200.jpeg 720w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!l_KA!,w_720,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a03822c-fe6c-4013-876c-46f0b77ca3b5_778x1200.jpeg" sizes="100vw" alt="" srcset="https://substackcdn.com/image/fetch/$s_!l_KA!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a03822c-fe6c-4013-876c-46f0b77ca3b5_778x1200.jpeg 424w, https://substackcdn.com/image/fetch/$s_!l_KA!,w_720,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a03822c-fe6c-4013-876c-46f0b77ca3b5_778x1200.jpeg 720w" width="720"></picture><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!g7N-!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35666649-5888-4d16-8a61-65d72db60197_973x1500.jpeg 424w, https://substackcdn.com/image/fetch/$s_!g7N-!,w_720,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35666649-5888-4d16-8a61-65d72db60197_973x1500.jpeg 720w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!g7N-!,w_720,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35666649-5888-4d16-8a61-65d72db60197_973x1500.jpeg" sizes="100vw" alt="" srcset="https://substackcdn.com/image/fetch/$s_!g7N-!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35666649-5888-4d16-8a61-65d72db60197_973x1500.jpeg 424w, https://substackcdn.com/image/fetch/$s_!g7N-!,w_720,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35666649-5888-4d16-8a61-65d72db60197_973x1500.jpeg 720w" width="720"></picture></div><figcaption>https://www.amazon.com/Stories-Your-Life-Others-Chiang/dp/1101972122  https://www.amazon.com/Exhalation-Ted-Chiang/dp/1101972084/ </figcaption></div></figure><p><a href="https://www.amazon.com/Stories-Your-Life-Others-Chiang/dp/1101972122" rel="">Story Of Your Life</a><span>//</span><a href="https://www.amazon.com/Exhalation-Ted-Chiang/dp/1101972084/" rel="">Exhalation</a></p><p><span>And if you are planning to read 5 science fiction books this year, congrats on making the time for it! In that case I recommend you read </span><em>Story of Your Life</em><span> twice and </span><em>Exhalation</em><span> three times.</span></p><p data-attrs="{&quot;url&quot;:&quot;https://linch.substack.com/p/ted-chiang-review?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://linch.substack.com/p/ted-chiang-review?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><ol><li><p><strong>Berkeley/SF Bay Area readers:</strong><span> We're hosting an in-person screening of </span><em>Arrival</em><span> (based on "Story of Your Life") on August 25th! Still have spots. Please comment or DM for an invite.</span></p></li><li><p><strong>Coming soon:</strong><span> I'm planning to add paid subscriptions for unfinished drafts, research notes, and so people can show general support. Nothing important will be paywalled. Thoughts welcome!</span></p></li><li><p><strong>Thank you:</strong><span> We've hit 200+ subscribers in 1.5 months! I'd love your feedback on topics you'd like to see or how I can improve.</span></p></li></ol></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Croatian freediver held breath for 29 minutes (259 pts)]]></title>
            <link>https://divernet.com/scuba-news/freediving/how-croatian-freediver-held-breath-for-29-minutes/</link>
            <guid>44946762</guid>
            <pubDate>Tue, 19 Aug 2025 00:04:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://divernet.com/scuba-news/freediving/how-croatian-freediver-held-breath-for-29-minutes/">https://divernet.com/scuba-news/freediving/how-croatian-freediver-held-breath-for-29-minutes/</a>, See on <a href="https://news.ycombinator.com/item?id=44946762">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-id="15d3585" data-element_type="widget" data-widget_type="theme-post-content.default">
					
<p>The world record for longest underwater breath-hold using oxygen is often viewed as much as a conjuring trick as an athletic feat – and at one time the title was indeed held by US magician David Blaine. But now a remarkable new mark has been set by a Croatian already recognised for his more conventional competitive freediving achievements.</p>





<p>Vitomir Maričić has set a new Guinness World Record (GWR) of 29min 3sec for “the longest breath held voluntarily under water using oxygen” – surpassing the previous record by more than four minutes.</p>



<p>Also read: <strong><a href="https://divernet.com/scuba-news/freediving/champagne-master-dies-freediving/">Champagne master dies freediving</a></strong></p>



<p>His near-half-hour feat took place on 14 June in a 3m-deep pool at the Bristol Hotel in Opatija, Croatia in front of five official judges and some 100 spectators.</p>



<figure><img fetchpriority="high" decoding="async" width="1024" height="683" src="https://divernet.com/wp-content/uploads/2025/06/Vitomir-2-1024x683.jpg" data-orig-src="https://divernet.com/wp-content/uploads/2025/06/Vitomir-2-1024x683.jpg" alt="Croatian freediver Vitomir Maričić" title="How Croatian freediver held breath for 29 minutes 1" srcset="https://divernet.com/wp-content/uploads/2025/06/Vitomir-2-300x200.jpg 300w, https://divernet.com/wp-content/uploads/2025/06/Vitomir-2-768x512.jpg 768w, https://divernet.com/wp-content/uploads/2025/06/Vitomir-2-1024x683.jpg 1024w, https://divernet.com/wp-content/uploads/2025/06/Vitomir-2-1320x880.jpg 1320w, https://divernet.com/wp-content/uploads/2025/06/Vitomir-2-1536x1024.jpg 1536w, https://divernet.com/wp-content/uploads/2025/06/Vitomir-2.jpg 1920w" data-srcset="https://divernet.com/wp-content/uploads/2025/06/Vitomir-2-300x200.jpg 300w, https://divernet.com/wp-content/uploads/2025/06/Vitomir-2-768x512.jpg 768w, https://divernet.com/wp-content/uploads/2025/06/Vitomir-2-1024x683.jpg 1024w, https://divernet.com/wp-content/uploads/2025/06/Vitomir-2-1320x880.jpg 1320w, https://divernet.com/wp-content/uploads/2025/06/Vitomir-2-1536x1024.jpg 1536w, https://divernet.com/wp-content/uploads/2025/06/Vitomir-2.jpg 1920w" data-sizes="auto" data-orig-sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Freediver Vitomir Maričić </figcaption></figure>



<p>Maričić prepared by pre-breathing pure oxygen for an unspecified length of time before his immersion, in line with <a href="https://www.guinnessworldrecords.com/" target="_blank" rel="nofollow noopener">GWR</a> guidelines. In past attempts, up to 30 minutes has been allowed for this preparatory phase. He then lay on his back at the bottom of the pool, hands behind his head.</p>



<p>Also read: <strong><a href="https://divernet.com/scuba-news/freediving/59yr-old-claims-mens-breath-hold-walk-record/">59yr-old claims men’s breath-hold walk record</a></strong></p>



<p>“After the 20-minute mark, everything became easier, at least mentally,” he said after surfacing, but explained that the experience had “got worse and worse physically, especially for my diaphragm, because of the contractions. But mentally I knew I wasn’t going to give up.” He credited his achievement to the support of his team, family and friends.</p>



<h2 id="record-history">Record history</h2>



<p>The record had previously been held by fellow-Croatian Budimir Šobat who, in 2021 at the age of 56, held his breath for 24min, 37sec, breaking the existing record by 34sec.</p>



<p>Back in 2008, magician and endurance artist David Blaine had set the GWR record at 17min 4sec during a live broadcast on <em>The Oprah Winfrey Show</em>.&nbsp;</p>



<p>For comparison, the official AIDA world record for static apnea (underwater breath-hold on air) is 11min 35sec, set by Frenchman Stéphane Mifsud in 2013. The GWR static apnea record, which has its own verification protocols, was set by Serbian Branko Petrović at 11min 54sec the following year. </p>



<p>Maričić’s AIDA static apnea best is 10min 8sec. He also set the Guinness World Record for <a href="https://divernet.com/scuba-news/freediver-goes-for-an-epic-walk/" data-type="link" data-id="https://divernet.com/scuba-news/freediver-goes-for-an-epic-walk/">longest underwater walk</a> on one breath at 107m in 2021.</p>



<p>Oxygen pre-breathing is understood to be a technique used by actors on some underwater film-shoots to allow them to stay immersed for longer. Denitrogenation, the process of replacing the nitrogen in the lungs with oxygen, can increase the amount of usable oxygen from some 450ml to almost 3 litres. </p>



<p>Reducing carbon dioxide build-up delays the urge to breathe and extends the “safe apnea time” before oxygen levels drop to dangerous levels. </p>



<p>Highly controlled diaphragmatic breathing is required in the breathe-up, and the body has to be deeply relaxed to keep the heart-rate low, requiring exceptional body awareness, breathing technique and mental control.</p>



<p><strong>Also on Divernet: <a href="https://divernet.com/scuba-news/freediver-goes-for-an-epic-walk/">Freediver goes for an epic walk</a>, <a href="https://divernet.com/scuba-news/freediving/freediver-klovar-breaks-trubridges-17-year-no-fins-reign/">Freediver Klovar breaks Trubridge’s 17-year no-fins reign</a>, <a href="https://divernet.com/scuba-news/kate-winslet-breath-holding-for-britain/">Kate Winslet: breath-holding for Britain?</a>, <a href="https://divernet.com/scuba-news/freediving/ex-scuba-instructor-died-in-pool-breath-hold/">Ex scuba instructor died in pool breath-hold</a></strong></p>
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What could have been (139 pts)]]></title>
            <link>https://coppolaemilio.com/entries/what-could-have-been/</link>
            <guid>44945966</guid>
            <pubDate>Mon, 18 Aug 2025 22:29:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://coppolaemilio.com/entries/what-could-have-been/">https://coppolaemilio.com/entries/what-could-have-been/</a>, See on <a href="https://news.ycombinator.com/item?id=44945966">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p>No matter what your opinion on AI is, you probably have one already. Positive or negative, AI discourse is hard to avoid. 
The most dedicated AI evangelists will tell you that: <em>“AGI is around the corner. Your job? obsolete. You don’t think so? Well, see how much things improved from last year? imagine how it will be like in 5 years!”</em> You’ve read everything that could be said about it already at least 10 times.</p>

<p>I’ve seen people trying to debunk all those claims but there’s something that I rarely see.</p>

<p>What could have been if instead of spending so much energy and resources on developing “AI features” we focused on making our existing technology better?</p>

<p>AI gets added into every software possible nowadays. Features almost no one wants, and no one needs, that only make the existing software worse. I’m sure you know what I mean, we have all been victims of it in some way or another.</p>

<p>(I would insert here one of those funny screenshots of Google telling you to eat rocks but you’ve seen it already)</p>

<p>It pains me to think about all the money being funneled into the AI bubble. Money that could have funded so many real solutions to real problems. There is a lot of software to be made, improved, and released, but the tech industry refuses to see this.</p>

<p>Tech executives are robbing every investor blind. Promising the biggest breakthrough in technology while our current technology rots to the core. The operative systems we run, the browsers we use, our critical infrastructure gets consistently neglected to chase a promised wonderland of automation that never arrives.</p>

<p>There isn’t a single day where I don’t have to deal with software that’s broken but no one cares to fix. And I know what AI enthusiast will say: don’t worry, AI will fix them for us!</p>

<p>On Bluesky I saw <a href="https://bsky.app/profile/rystorm.com/post/3lwoqjqu6t22u">this post by Robin-Yann Storm</a>:</p>

<blockquote>
  <p>Gamescom’s app added an AI feature this year and it did not go well. Folks were overwhelmed with automatically generated meeting requests that they did not want. It generated a lot of stuff, but not value.</p>
</blockquote>

<p>The post contains an image of an email from Gamescom that reads:</p>

<blockquote>
  <p>Hello Robin-Yann,
We tested a new feature today - the Al meeting generator. The aim was to suggest suitable business contacts based on your profiles and make it easier for you to plan your trade fair contacts.
However, your honest feedback shows us that this feature does not provide the desired added value. We have therefore decided to completely remove the automatically generated meetings from your profiles.
Thank you for your openness. Your feedback is a central component of our further development - together we will make the platform better.
We apologize for any inconvenience caused.
Your gamescom team</p>
</blockquote>

<p>I’ve been to many conferences since <a href="https://coppolaemilio.com/entries/my-first-gdc/">I started working at the Godot Foundation</a>, and they all have one thing in common: horribly broken meeting/networking apps. If you’ve been to a conference you probably already suffered them. The direct messages work half of the time leaving messages undelivered. Registered people missing when you search for them, but still visible if you open a direct link to their profile. Scheduling features that fail to process any kind of rescheduling. The list goes on.</p>

<p>People end up ditching them to network via other apps: linkedin, twitter, email, bluesky. But I still believe that the idea of a networking app for a conference is still good and should be pursued. So I ask: Why is adding AI the priority here? What could have been if the investment went into making these apps better?</p>

<p>I’m not naive. What motivates people to include AI everywhere is the promise of profit. What motivates most AI startups or initiatives is just that. A promise.</p>

<p>But, don’t you think that by making a good product you will achieve that profit? Your product doesn’t need AI to get more users, more money, more features. It just needs to be better.</p>

<p>Unfortunately, people making decisions (if there are any) only chase ghosts and short term profits. They don’t think that they are crippling their companies and dooming their long term profitability. The enshittification is a disease that will keep spreading trying to suck every ounce of life from every product until they are too weak to continue.</p>

<p>I could now finish the post by breaking down budgets of organizations such as Blender, Godot, or Ladybird and comparing them with those that the tech gigants are spending on chasing their AI dreams while delivering absolutely nothing of value. But it would be too depressing. Last time I did this, with just one company’s budget you could fund more than 100 years of real open-source software development. Solving real needs we have now. Improving software we use every day. Making critical infrastructure that our life depends on.</p>

<p>Even if we manage to snap out of the AI bubble, we are never going to get these years back. I can only be left to wonder what could have been.</p>

	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lab-grown salmon hits the menu (152 pts)]]></title>
            <link>https://www.smithsonianmag.com/smart-news/lab-grown-salmon-hits-the-menu-at-an-oregon-restaurant-as-the-fda-greenlights-the-cell-cultured-product-180986769/</link>
            <guid>44945959</guid>
            <pubDate>Mon, 18 Aug 2025 22:29:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.smithsonianmag.com/smart-news/lab-grown-salmon-hits-the-menu-at-an-oregon-restaurant-as-the-fda-greenlights-the-cell-cultured-product-180986769/">https://www.smithsonianmag.com/smart-news/lab-grown-salmon-hits-the-menu-at-an-oregon-restaurant-as-the-fda-greenlights-the-cell-cultured-product-180986769/</a>, See on <a href="https://news.ycombinator.com/item?id=44945959">Hacker News</a></p>
Couldn't get https://www.smithsonianmag.com/smart-news/lab-grown-salmon-hits-the-menu-at-an-oregon-restaurant-as-the-fda-greenlights-the-cell-cultured-product-180986769/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Shamelessness as a strategy (2019) (200 pts)]]></title>
            <link>https://nadia.xyz/shameless</link>
            <guid>44945943</guid>
            <pubDate>Mon, 18 Aug 2025 22:27:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nadia.xyz/shameless">https://nadia.xyz/shameless</a>, See on <a href="https://news.ycombinator.com/item?id=44945943">Hacker News</a></p>
<div id="readability-page-1" class="page"><div ?="">
        <p>I’ve enjoyed playing a game called Avalon recently. I won’t go too far into the rules, but it’s a <a href="https://www.bestplay.co/ultimate-guide-hidden-role-board-games/">hidden role game</a> in the vein of Secret Hitler or Werewolf, where one team is “good”, trying to uncover who among them is “evil”, before the evil team wins.</p>

<p>One of the characters you can play is Merlin. Merlin knows who the evil players are, but can’t reveal what he knows, because the evil team can kill Merlin and win the game. So Merlin relies on another character, Percival, to be his decoy.</p>

<p>Percival’s only power is that he knows who Merlin is. So he secretly watches Merlin’s actions throughout the game and amplifies those signals to the rest of the group. The typical strategy is for Percival to attract attention away from Merlin and towards himself.</p>

<p>But another, riskier strategy is for <em>Merlin</em> to play as though <em>he</em> is Percival. In this case, Merlin displays what he knows so shamelessly that he throws everyone off. The evil team, believing that no Merlin would be stupid enough to put himself out there like that, figures he must be Percival, and writes him off.</p>

<p>The Merlin-as-Percival strategy is bold, because it blatantly defies our expectations about how the game is won. To pull it off, Merlin must create confusion around his actions. He needs the other players to feel unsure about whether he’s being incredibly stupid or incredibly smart.</p>

<p>Increasingly, I think the “shameless” approach is becoming a dominant strategy today. It was first popularized in modern canon by Paris Hilton, who played the “dumb blonde heiress” stereotype so smoothly that everyone assumed she really was as stupid as she seemed.</p>

<p>Paris didn’t play by the “obvious” rules for famous people. She was widely derided by both media and her peers as at best, a train wreck, and at worst, a self-serving aggrandizer. And yet, people couldn’t stop talking about her. A decade later, Paris is now remembered as the mastermind behind the playbook that’s made the Kardashians, Jenners, and other celebrity socialites so successful.</p>

<p>It’s important to note that people were dismissive of Paris because validating her playbook would mean admitting that <em>they</em> were playing an inferior game. Everyone else had invested years into optimizing for the most legible version of the rules. They’d look silly if they were to admit she had found a better way of doing things.</p>

<p>Without getting into tiresome politics, the “shameless” strategy also defined the 2016 U.S. presidential elections. It was shouted down by people in both established political parties, because they were used to playing by the “obvious” rules, but I suspect that in a decade’s time, we’ll look back on that election and realize that it marked the beginning of an entirely new style of politics.</p>

<p>Ditto to, perhaps, the leadership styles of Mark Zuckerberg, who’s followed the “obvious” playbook for years, versus Jack Dorsey, who employs tactics that seem so obviously stupid (tweeting about fasting and meditation!) that we’re quick to write them off. And yet, I’d guess that Zuckerberg’s strategy makes him increasingly unlikeable and untrustworthy, in the same way that any major politician sticking to a pre-2016 playbook today is almost certainly not going to win.</p>

<p>The shameless strategy feels counterintuitive, because our first instinct is to want to punish that sort of behavior. And historically, those sanctions have been effective. Punishing outlandish behavior is an important aspect of cooperative governance: it preserves social order by ensuring that we all play by the same rules.</p>

<p>Today, it seems like punishing shamelessness only <em>increases</em> social rewards to the transgressor. What’s changed?</p>

<p>One explanation might be that it’s an expected effect of the blurring of social boundaries today. In the past, if the size of your community was finitely bounded (like a village, or an aristocratic social class), people didn’t enter or exit these communities as frequently. Under these conditions, sanctions are probably still effective, because members of the community want to be liked and accepted.</p>

<p>But the borders to online communities are much more fluid - perhaps even nonexistent. Under open borders, sanctions will backfire, because they just serve as a signaling boost for the transgressor, attracting outsiders who resonate with that person’s message. What’s meant to be punishment instead becomes a flare shot straight into the night sky.</p>

<p>The “establishment” mistakenly assumes that a shameless person wants the approval of their community, when it turns out that, much like any cult or counterculture, that person’s goal was to attract a following, regardless of who the members are. The disgust of one’s peers doesn’t matter anymore, because that disgust forms the basis for an entirely new community.</p>

<p>A common critique of shameless people is questioning their intelligence. But one of the most bizarre aspects here is it doesn’t actually matter how aware that person is of what they’re doing. The concept of a “genius mastermind” is itself outdated, because it assumes that someone needs to be in control. The shameless person is simply a host for a set of ideas, which, like any virus, will continue to propagate as long as there are willing hosts to receive it.</p>

<p>I’m not really sure what the long-term implications of shamelessness will be. I also don’t think that everybody has to employ this strategy to win (at least, I hope not!). But what I do know is when I see my peers rolling their eyes at someone or deriding them for being “shameless”, there’s a good chance that, instead of writing them off, we should examine their actions a bit more closely.</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Newsmax agrees to pay $67M in defamation case over bogus 2020 election claims (180 pts)]]></title>
            <link>https://apnews.com/article/dominion-voting-newsmax-defamation-trump-2020-3b2366dfdae3a8432afe822bf14fe1ef</link>
            <guid>44945925</guid>
            <pubDate>Mon, 18 Aug 2025 22:23:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apnews.com/article/dominion-voting-newsmax-defamation-trump-2020-3b2366dfdae3a8432afe822bf14fe1ef">https://apnews.com/article/dominion-voting-newsmax-defamation-trump-2020-3b2366dfdae3a8432afe822bf14fe1ef</a>, See on <a href="https://news.ycombinator.com/item?id=44945925">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                        <p>DENVER (AP) — The conservative network Newsmax will pay $67 million to settle a lawsuit accusing it of defaming a voting equipment company by spreading lies about President <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/hub/donald-trump">Donald Trump’s</a></span> 2020 election loss, according to documents filed Monday.</p><p>The settlement comes after Fox News Channel <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/fox-news-dominion-lawsuit-trial-trump-2020-0ac71f75acfacc52ea80b3e747fb0afe">paid $787.5 million</a></span> to settle a similar lawsuit in 2023 and Newsmax paid what court papers describe as $40 million to <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/smartmatic-newsmax-lawsuit-2020-election-96d35dc10009b68cbb548ef7bea10284">settle a libel lawsuit</a></span> from a different voting machine manufacturer, Smartmatic, which also was <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/election-2020-joe-biden-donald-trump-technology-electronic-voting-cd68ad2022611a36154ff3f243fcd1d8">a target</a></span> of pro-Trump conspiracy theories on the network.</p><p>Delaware Superior Court Judge Eric Davis had ruled earlier that Newsmax did indeed defame Denver-based Dominion Voting Systems by airing false information about the company and its equipment. But Davis left it to a jury to eventually decide whether that was done with malice, and, if so, how much Dominion deserved from Newsmax in damages. Newsmax and Dominion reached the settlement before the trial could take place.</p>
    
<p>The settlement was disclosed by Newsmax in a new filing with the U.S. Securities and Exchange Commission. It said the deal was reached Friday. </p>



<p>“Newsmax believed it was critically important for the American people to hear both sides of the election disputes that arose in 2020,” the company said in a statement. “We stand by our coverage as fair, balanced, and conducted within professional standards of journalism.”</p>
    
    
    
<p>A spokesperson for Dominion said the company was pleased to have settled the lawsuit.</p><p>The disclosure of the settlement came as Trump, who <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/joe-biden-wins-white-house-ap-fd58df73aa677acb74fce2a69adb71f9">lost his 2020 reelection bid</a></span> to Democrat Joe Biden, vowed in a social media post Monday to eliminate mail-in ballots and voting machines such as those supplied by Dominion and other companies. It was unclear how the Republican president could achieve that.</p><p>The same judge also handled the Dominion-Fox News case and made a similar ruling that the network repeated <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/fox-news-dominion-lawsuit-trial-explainer-trump-fbd401a951905879d837a8860b3bec5e">numerous lies</a></span> by Trump’s allies about his 2020 loss despite <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/united-states-government-news-media-donald-trump-fraud-b52914ec21a97dec8b5d878a908d566f">internal communications</a></span> showing Fox officials knew the claims <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/politics-fraud-donald-trump-24d6322f99281fdfb46c272e3ac6bacf">were bogus</a></span>. At the time, Davis found it was “CRYSTAL clear” that none of the allegations was true.</p>
    
<p>Internal correspondence from Newsmax officials likewise shows they knew the claims were baseless.</p><p>“How long are we going to play along with election fraud?” Newsmax host Bob Sellers said two days after the 2020 election was <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/election-claims-biden-won-explained-bd53b14ce871412b462cb3fe2c563f18">called for Biden</a></span>, according to internal documents revealed as part of the case. </p><p>Newsmax took pride that it was not calling the election for Biden and, the internal documents show, saw a business opportunity in catering to viewers who believed Trump won. Private communications that surfaced as part of Dominion’s earlier defamation case against Fox News <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/politics-television-donald-trump-business-1a4337a89c8abd952a814c60fa269b3c">also revealed</a></span> how the network’s business interests intersected with decisions it made related to coverage of <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/capitol-riot-trump-election-lies-explainer-816a43ed964e6d35f03b0930e6e56c82">Trump’s 2020 election claims</a></span>.</p><p>At Newsmax, employees repeatedly warned against false allegations from pro-Trump guests such as attorney <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/donald-trump-joe-biden-michigan-detroit-election-2020-4fd2ba9b84e9d9a6bcddd51872ba3f97">Sidney Powell</a></span>, according to documents in the lawsuit. In one text, even Newsmax owner Chris Ruddy, a Trump ally, said he found it “scary” that Trump was meeting with Powell.</p>
    
<p>Dominion was at the heart of many of the wild claims aired by guests on Newsmax and elsewhere, who promoted a conspiracy theory involving deceased Venezuelan president Hugo Chavez to rig the machines for Biden. The network <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/fox-newsmax-smartmatic-dominion-lawsuits-826071eb5b52ec8aea6b0028da78c61c">retracted some of the more bombastic allegations</a></span> in December 2020.</p><p>Though Trump has insisted <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/trump-2020-election-lies-debunked-4fc26546b07962fdbf9d66e739fbb50d">his fraud claims</a></span> are real, there’s no evidence they were, and the lawsuits in the Fox and Newsmax cases show how some of the president’s biggest supporters knew they were false at the time. Trump’s then-attorney general, William Barr, said there was <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/barr-no-widespread-election-fraud-b1f1488796c9a98c4b1a9061a6c7f49d">no evidence</a></span> of widespread fraud.</p><p>Trump and his backers lost <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/donald-trump-losing-election-lawsuits-36d113484ac0946fa5f0614deb7de15e">dozens of lawsuits</a></span> alleging fraud, some before Trump-appointed judges. Numerous <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/election-2020-joe-biden-donald-trump-georgia-elections-4eeea3b24f10de886bcdeab6c26b680a">recounts</a></span>, <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/elections-government-and-politics-nevada-ed4d5296d9fd7fd9afd83a3fe845c205">reviews</a></span> and <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/joe-biden-wisconsin-presidential-elections-state-elections-madison-9a2f172dd8074668ded26bd5b0b41fbb">audits</a></span> of the election results, including <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/donald-trump-joe-biden-election-2020-elections-government-and-politics-4b6643aa699480dc63cbce8555aac946">some run by Republicans</a></span>, turned up no signs of significant wrongdoing or error and affirmed Biden’s win.</p><p>After returning to office, Trump <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/capitol-jan-6-pardons-trump-justice-department-8ce8b2a8f8cb602d5eaf85ac7b969606">pardoned</a></span> those who tried to halt the transfer of power during the <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/congress-confirm-joe-biden-78104aea082995bbd7412a6e6cd13818">Jan. 6, 2021, attack</a></span> on the U.S. Capitol and <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/trump-retaliation-miles-taylor-chris-krebs-efb1416926df9d1086fa21349a18f90b">directed</a></span> his Department of Justice to investigate Chris Krebs, a former Trump cybersecurity appointee who had <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/top-officials-elections-most-secure-66f9361084ccbc461e3bbf42861057a5">vouched for the security and accuracy</a></span> of the 2020 election.</p>
    
<p>As an initial trial date approached in the Dominion case earlier this year, Trump issued an <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://www.whitehouse.gov/presidential-actions/2025/04/addressing-risks-from-susman-godfrey/" target="_blank" rel="noopener">executive order</a></span> attacking the law firm that litigated it and the Fox case, Susman Godfrey. The order, part of a series <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/trump-perkins-coie-law-firm-executive-order-206052ec8157380fb2e23010a6f88815">targeting law firms</a></span> Trump has tussled with, cited Susman Godfrey’s work on elections and said the government would not do business with any of its clients or permit any of its staff in federal buildings.</p><p>A federal judge put that action on hold, saying the framers would view it as <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/trump-law-firm-susman-godfrey-eada6cc436533ea3b483568c8287600e">“a shocking abuse of power.</a></span> ”</p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Phrack 72 (149 pts)]]></title>
            <link>https://phrack.org/issues/72/1</link>
            <guid>44945660</guid>
            <pubDate>Mon, 18 Aug 2025 21:43:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://phrack.org/issues/72/1">https://phrack.org/issues/72/1</a>, See on <a href="https://news.ycombinator.com/item?id=44945660">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<table>
   <tbody>
      <tr><td><a href="https://phrack.org/issues/72/1_md.html#article">Introduction</a></td><td>Phrack Staff</td></tr>

<tr><td><a href="https://phrack.org/issues/72/2.html#article">Phrack Prophile on Gera</a></td><td>Phrack Staff</td></tr>

<tr><td><a href="https://phrack.org/issues/72/3_md.html#article">Linenoise</a></td><td>Phrack Staff</td></tr>

<tr><td><a href="https://phrack.org/issues/72/4_md.html#article">Loopback</a></td><td>Phrack Staff</td></tr>

<tr><td><a href="https://phrack.org/issues/72/5_md.html#article">The Art of PHP - My CTF Journey and Untold Stories!</a></td><td>Orange Tsai</td></tr>

<tr><td><a href="https://phrack.org/issues/72/6_md.html#article">Guarding the PHP Temple</a></td><td>mr_me</td></tr>

<tr><td><a href="https://phrack.org/issues/72/7_md.html#article">APT Down - The North Korea Files</a></td><td>Saber, cyb0rg</td></tr>

<tr><td><a href="https://phrack.org/issues/72/8_md.html#article">A learning approach on exploiting CVE-2020-9273</a></td><td>dukpt</td></tr>

<tr><td><a href="https://phrack.org/issues/72/9_md.html#article">Mapping IOKit Methods Exposed to User Space on macOS</a></td><td>Karol Mazurek</td></tr>

<tr><td><a href="https://phrack.org/issues/72/10_md.html#article">Popping an alert from a sandboxed WebAssembly module</a></td><td>th0mas.nl</td></tr>

<tr><td><a href="https://phrack.org/issues/72/11_md.html#article">Desync the Planet - Rsync RCE</a></td><td>Simon, Pedro, Jasiel</td></tr>

<tr><td><a href="https://phrack.org/issues/72/12_md.html#article">Quantom ROP</a></td><td>Yoav Shifman, Yahav Rahom</td></tr>

<tr><td><a href="https://phrack.org/issues/72/13_md.html#article">Revisiting Similarities of Android Apps</a></td><td>Jakob Bleier, Martina Lindorfer</td></tr>

<tr><td><a href="https://phrack.org/issues/72/14_md.html#article">Money for Nothing, Chips for Free</a></td><td>Peter Honeyman</td></tr>

<tr><td><a href="https://phrack.org/issues/72/15_md.html#article">E0 - Selective Symbolic Instrumentation</a></td><td>Jex Amro</td></tr>

<tr><td><a href="https://phrack.org/issues/72/16_md.html#article">Roadside to Everyone</a></td><td>Jon Gaines</td></tr>

<tr><td><a href="https://phrack.org/issues/72/17_md.html#article">A CPU Backdoor</a></td><td>uty</td></tr>

<tr><td><a href="https://phrack.org/issues/72/18_md.html#article">The Feed Is Ours</a></td><td>tgr</td></tr>

<tr><td><a href="https://phrack.org/issues/72/19.html#article">The Hacker's Renaissance - A Manifesto Reborn</a></td><td>TMZ</td></tr>

   </tbody>
</table>

<p><strong>Title</strong> : Introduction</p>
<p><strong>Author</strong> : Phrack Staff</p>
<pre>                              ==Phrack Inc.==

                Volume 0x10, Issue 0x48, Phile #0x01 of 0x12

|=-----------------------------------------------------------------------=|
|=-------------------------=[ Introduction ]=----------------------------=|
|=-----------------------------------------------------------------------=|
|=----------------------=[    Phrack Staff    ]=-------------------------=|
|=-----------------------=[ <a href="https://phrack.org/cdn-cgi/l/email-protection" data-cfemail="d9aaadb8bfbf99a9b1abb8bab2f7b6abbe">[email&nbsp;protected]</a> ]=--------------------------=|
|=-----------------------------------------------------------------------=|
|=----------------------=[  August  19, 2025  ]=-------------------------=|
|=-----------------------------------------------------------------------=|

    _______ ____ ____    _______     _______________  _____   _____
 ._\\____  \\   |    |__\\__    \  _\\__   /\    __//_\    | /    /
 :    |/   &gt;&gt;   :    :    :/    /./    /    |    |   /.    !/    /
 |    :    /         |    /     \|    __    |    |    |    /     \
 |    ____/|    |    |    \      \     |    |__  :    |    \      \
 |    |/// |____|    |_____\     |\___ |    ://\      !_____\      \
 |    :    /////:____|/////\\____|////\\___/.   \\____://///\\_____/
 |___/ e-zine   /////:     //////|     ////      /////       //////
 ////                .           :                x0^67^aMi5H^iMP!


--[ Hacker Evolution 


For 40 years, Phrack has published papers that have reflected and shaped 
hacker culture. The knowledge shared in Phrack has laid the foundation for
many fields of study, providing insight, a shared language, resources 
and tools, as well as context and history. Phrack is written by hackers, 
for hackers, and offers a glimpse into the world just beyond what most 
people see.


Phrack is both a technical journal and a cultural document. Like all zines, 
it represents a snapshot of the scene at the time. We share not just our 
discoveries, but the stories of how we came to know things and the context 
in which we existed. We share our triumphs, failures, and lessons learned. 
By fostering a culture of communal idea sharing, we learn how to solve 
problems creatively, and make the most of our current situation. 


Over the past 40 years, hacking has evolved, splintered, and mutated into 
a variety of forms. Phrack has documented many of the key innovations in 
hacking since its first issue: From showcasing ways to manipulate the phone 
system and other large computers, to pioneering vulnerability scanning, to 
generalizing security concepts such as buffer overflows, ROP, and heap 
exploitation, to bringing it all together within complex ecosystems that 
seemed like just a fantasy in years past. Each generation builds off the 
previous and offers us new perspectives, remixing with older ideas and 
demonstrating how they can be reapplied to new situations. When Phrack was 
first published in the mid-80s, our relationship with technology was quite 
different. Many of our challenges involved simply getting and staying 
online. Today we face entirely new challenges based on what is, what was, 
and what will be.


The hacker ethos remains the same - be curious about your world, make do 
with what you have, and show how things can be better.


What was done before us, and the knowledge shared, provides the base for 
us to build off of and evolve from. As hackers, we pass on our best 
characteristics by teaching others. We document how and why we did things
based on what was available at the time. We expand on previous generations'
work and piece together our own understanding, informed by our own personal 
experience. The reward is the beauty of what we discover and create, and
the joy of sharing and inspiring others. Over time, all of our most beloved 
and reliable techniques and tools become common knowledge, and new 
permutations pop up. As circumstances change, so do our needs. What's old
becomes new again, new ideas recontextualize the old. The cycle continues.


Knowledge is the hacker DNA. Our instincts and curiosity are complimented 
by the stories of how things were accomplished before. Like hackers and 
humans before us, we adapt to our environment, and figure out how to meet
our needs and achieve our goals. As technology becomes more optimized and 
abstracted, it can be easy to lose track of the fundamentals. Just because 
tech has evolved doesn't mean the foundation has changed. We still use AT 
commands to control our modems. We still activate the A20 line to access
memory beyond 1MB on x86 CPUs. In-band signaling is still a pathway into 
the toughest systems. Weird machines still manifest throughout it all, 
waiting to be discovered by a hacker like you.


Everything is in a state of flux, and the only constant is change. Yet, if 
we position ourselves correctly, our actions can influence the future. 
Things mutate. There are happy accidents. The world is chaos, and out of 
chaos emerges hackers.


Hacking has no choice but to evolve, and hacker zines like Phrack evolve
with it. We look back at our foundation for inspiration, while we also look
forward towards uncharted territory, unafraid of going beyond. We venture 
into the deepest darkest rabbit holes that few dare to tread, where we see 
the light that leads us to the most amazing treasures. We address the needs 
of our communities, find ways to grow together, and encourage each other
to keep exploring. We maintain projects like Phrack because it gives a 
platform for the unadulterated voice of the hacker. 


Humans are hackers. We were put here to figure things out. Hacking is an
innate skill to be tapped into and developed. The hacker spirit guides us 
through situations once thought hopeless. Hacking is a way to answer your 
own burning questions, a way to discover your own potential, and a way to 
create a world you want to live in.


There is a hacker born every day. It's our duty to share things that can
inform them of the past and present, and give them hope for a better 
tomorrow. After all, we're all alike.


--[ Welcome to Phrack #72 

This edition is not just a milestone but a testament to the relentless
curiosity, stubborn brilliance, and uncompromising spirit of a global 
community that refuses to be silenced. A tribute to the old school and 
the new blood. To the legends who paved the way, and to those just 
starting to carve their path. It’s held together with tape, sweat, late 
nights, fried brains, and that twitchy love for the broken and beautiful 
mess of systems.

Huge thanks to every author who contributed their knowledge, tools, 
exploits, vision, and war stories. Your work keeps the scene alive 
and sharp.

To the reviewers and editors who read between the lines and asked the 
hard questions. You pushed for clarity without dulling the edge.

To the artists who dropped visuals, raw pixel filth, and clean design. 
You gave this issue texture. You made it feel.

To the layout crew who made this beast look like something worth 
printing in blood. Your work is proof that style and substance can 
coexist.

To everyone who tested drafts, pointed out typos, suggested better 
payloads, or tighter phrasing. You know who you are. We see you.

To the donors who pitched in to fund the printing of our anniversary 
edition. You helped keep this thing afloat, independent, and untamed.

And to the scene. The real one. You’re the reason we’re still doing 
this. This is yours.

A scream in a world that wants silence. A spark under a mountain of 
dead protocol.

Phrack lives because you do, so welcome to the noise and enjoy.

— Phrack Staff
ISSN 1068-1035


In this edition:

- 16 bangers from some of the sharpest minds in the scene

- A Prophile on the legendary Gera

- A puzzle to melt your brain (and flex your ego)

- A full-on CTF — win it and claim your Phrack coin!

- Visuals that hit like a payload: stunning GFX, ASCII and glitch art, 
  pure eye candy


--[ Greetz

Phrack 72 would not have been possible without the incredible hacker scene 
coming together to help make it happen. Thank you to all the authors, 
artists, donors, editors, and logistics experts who made this historic 
issue and international release a reality.

Special thanks to our artists: ackmage, amnesia, aNACHRONiST, araknet, 
bubok arsonian, digitalis, fyodor, ic3qu33n, jinn, mar, mavenmob, netspooky, 
p0rtL, s01den, x0, ytcracker. 

Massive thanks to the Paged Out crew for their help making an incredible 
print layout.

This zine would not have been possible without the following people:

ackmage         -- minted the only coin that'll be worth anything in 2026
bsdaemon        -- still carrying hackers forward
chompie         -- omg will u sign my driver?
clockwerk       -- l0ve
dark tangent    -- uber-supporter since dayZero
diaul           -- w0rd
horizon         -- ADM 4ever
Julio           -- The rise of the  alligatorzzzz
messede         -- &lt;b&gt;awesome&lt;/b&gt;
netspooky       -- ultimate cyber skull
pinguino        -- all your news are belong to her
retr0id         -- switch 2, retr0id 1, day 0
richinseattle   -- keeper of the lore
sblip           -- whaddup blip
skyper          -- triplegänger
TMZ             -- just a chill guy
Phrack Staff    -- for holding it down
Phrack's Tariff -- we got PCBs at home


--[ Phrack policy

phrack:~# head -77 /usr/include/std-disclaimer.h
/*
 *  All information in Phrack Magazine is, to the best of the ability of
 *  the editors and contributors, truthful and accurate.  When possible,
 *  all facts are checked, all code is compiled.  However, we are not
 *  omniscient (hell, we don't even get paid).  It is entirely possible
 *  something contained within this publication is incorrect in some way.
 *  If this is the case, please drop us some email so that we can correct
 *  it in a future issue.
 *
 *
 *  Also, keep in mind that Phrack Magazine accepts no responsibility for
 *  the entirely stupid (or illegal) things people may do with the
 *  information contained herein.  Phrack is a compendium of knowledge,
 *  wisdom, wit, and sass.  We neither advocate, condone nor participate
 *  in any sort of illicit behavior.  But we will sit back and watch.
 *
 *
 *  Lastly, it bears mentioning that the opinions that may be expressed in
 *  the articles of Phrack Magazine are intellectual property of their
 *  authors.
 *  These opinions do not necessarily represent those of the Phrack Staff.
 */


--[ Phrack 73 Call For Papers 

Why should you write for Phrack?

- You have a project you've been working on that pushes the limits in some 
  way, doing things that haven't been publicly shared before. If you do 
  cutting edge security research, you should write for Phrack.

- You are interested in aspects of security and technology that other people
  don't seem to care about or understand. If you feel like you need to shed
  light on a certain topic for all to see, you should write for Phrack.

- You keep seeing the same problems over and over and wish someone would 
  just write a straightforward guide for everyone. If you are the person 
  who can write that for now and future generations, you should write for 
  Phrack.

- You deserve a place to share your finest work without fear. If you don't
  want something you poured your heart and soul into turned into another 
  metric for shareholders and potential investors or trapped forever inside
  a corporate VPN, you should write for Phrack.

Worst Case Scenario: You just wrote a cool paper you can share on your own.

Best Case Scenario: Your paper gets published in Phrack. :)


::. What do we want? .::

Articles about hacking, exploit development, vulnerability research, and 
other fine topics.

More Specifically:  

- Exploitation: Demonstrate the latest techniques in breaking mitigations 
  and proving vulnerabilities still have bite.

- Persistence: Whether its userland, kernel, or below ring0, share a trick 
  in the dark art of stealth persistence.

- Fuzzing and Code Analysis: Automated bug hunting finds the low hanging 
  fruit, how can we make it more lethal?

- Binary Obfuscation: We have decompilers but custom VMs and powerful 
  transformations create impenetrable code.

- Data Obfuscation: Time to exfil, how do you move a terabyte of data 
  without looking like a fool?

- Anti-Forensics: Leave no trace, hide in the mist, or maybe even deploy 
  countermeasures on the parsers!

- Web Applications: Discuss confusion, bypass, and injection attacks on 
  the multi-headed hydra of modern applications.

- Cloud Security: Complexity and lack of visibility is the soft underbelly
  of cloud compute, discuss.

- Data Storage Weaknesses: If data theft is the end goal, let's talk about 
  all the leaks in storage infra and APIs. 

- Exploit Mitigation: Finding every bug is futile, how do we design more 
  secure systems to block these attacks?

- Malware Analysis: The world is covered in a diaspora of malware, flay 
  open the code and inspect the innards.

- Malware Defense: We wade in a pool of parasites attacking from every 
  angle, how do we block their vicious effects?

- Exotic Reverse Engineering: What are the corrupt hidden hands of power 
  in this electronic substrate?

- Scene History: Let us learn the often isolated tribal history that hasn't
  been written about before.

- Tales from the Crypt: Want to tell a personal story of a righteous hack?
  Maybe we'll believe you.


::. When Do We Want It By? .::

June 2026


::. When will Phrack 73 be released? .::

Summer 2026

                   ----( Contact )----

    &lt;  Editors           : staff[at]phrack{dot}org         &gt;
    &gt;  Submissions       : submissions[at]phrack{dot}org   &lt;
    &lt;  /dev/urandom      : loopback[at]phrack{dot}org      &gt;
    &gt;  Arts &amp; Leisure    : arts[at]phrack{dot}org          &lt;
    &lt;  Twitter/X         : phrack                          &gt;
    &gt;  Mastodon          : phrack[at]haunted{dot}computer  &lt;
    &lt;  BlueSky           : phrack{dot}org                  &gt;


    The rules are simple:

    + 7-bit ASCII wrapped to 76 columns OR Markdown UTF-8
    + ANTISPAM in the subject line or face the Spam God and 
      walk backwards into hell
</pre>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Obsidian Bases (606 pts)]]></title>
            <link>https://help.obsidian.md/bases</link>
            <guid>44945532</guid>
            <pubDate>Mon, 18 Aug 2025 21:28:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://help.obsidian.md/bases">https://help.obsidian.md/bases</a>, See on <a href="https://news.ycombinator.com/item?id=44945532">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Fractional jobs – part-time roles for engineers (242 pts)]]></title>
            <link>https://www.fractionaljobs.io</link>
            <guid>44945379</guid>
            <pubDate>Mon, 18 Aug 2025 21:10:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fractionaljobs.io">https://www.fractionaljobs.io</a>, See on <a href="https://news.ycombinator.com/item?id=44945379">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><h2>HEY COMPANIES,</h2><div><p>Welcome to the place to hire&nbsp;</p><p>. We’re the largest network. We send you the top candidates. You can hire them directly.</p></div><div><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/686fee8d37b5301b91b82a2d_Group%20277%20(1).png" loading="lazy" alt=""></p></div></div><div><div><h2>Open Jobs</h2></div><div><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div id="w-node-_9e108133-0d83-1535-4f7b-7f859e28816b-075f0119"><h3>Hiring?</h3><div><p>Fractional talent is ready today</p><p>Mid-level - executive talent only</p><p>Convert to full-time when ready</p><p>Ditch the W2 salaries, payroll tax, etc.</p></div></div></div></div><div id="jobs"><div><h2 id="live-no">x</h2><h2>Live Jobs</h2></div><div><div id="filter-container"><h3>Filter Jobs</h3><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div></div><div id="live-jobs"><div fs-cmsfilter-element="list" role="list"><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Steelbay Equity Partners</h3><h3>&nbsp;-&nbsp;</h3><h3>Founding Marketer</h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote</p><div><p>Marketing</p><p>Syndicated</p><p>August 18, 2025</p><p>founding-marketer-at-steelbay-equity-partners</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Wedwallet</h3><h3>&nbsp;-&nbsp;</h3><h3>Legal Advisor</h3></p></div><div><p>10 - 20 hrs </p><p>&nbsp;|&nbsp;</p><p>$300 – $500 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote</p><div><p>Legal</p><p>Syndicated</p><p>August 18, 2025</p><p>legal-advisor-at-wedwallet</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Everlywell</h3><h3>&nbsp;-&nbsp;</h3><h3>Product Manager</h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote</p><div><p>Product</p><p>Syndicated</p><p>August 18, 2025</p><p>product-manager-at-everlywell</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>PeakHealth</h3><h3>&nbsp;-&nbsp;</h3><h3>Marketing Lead </h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote </p><div><p>Marketing</p><p>Syndicated</p><p>August 18, 2025</p><p>marketing-lead-at-peakhealth</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>DUNE Suncare</h3><h3>&nbsp;-&nbsp;</h3><h3>Head of Marketing</h3></p></div><div><p>15 - 25 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote</p><div><p>Marketing</p><p>Syndicated</p><p>August 18, 2025</p><p>head-of-marketing-at-dune-suncare</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>IV DRIPS</h3><h3>&nbsp;-&nbsp;</h3><h3>Lead Developer </h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote</p><div><p>Engineering</p><p>Syndicated</p><p>August 18, 2025</p><p>lead-developer-at-iv-drips</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Burwood</h3><h3>&nbsp;-&nbsp;</h3><h3>Executive Director</h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>On-site (Chicago)</p><div><p>Other</p><p>Syndicated</p><p>August 18, 2025</p><p>executive-director-at-burwood</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>An AI Tutoring Startup</h3><h3>&nbsp;-&nbsp;</h3><h3>Chief Financial Officer</h3></p></div><div><p>10 hrs</p><p>&nbsp;|&nbsp;</p><p>£100 - £125 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (UK only)</p><div><p>Finance</p><p>Syndicated</p><p>August 18, 2025</p><p>chief-financial-officer-at-an-ai-tutoring-startup</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>A European Insurtech Startup</h3><h3>&nbsp;-&nbsp;</h3><h3>Senior AI Engineer</h3></p></div><div><p>20 - 40 hrs</p><p>&nbsp;|&nbsp;</p><p>€85 - €100 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (CET +/- 6hrs)</p><div><p>Engineering</p><p>Syndicated</p><p>August 15, 2025</p><p>senior-ai-engineer-at-a-european-insurtech-startup</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>A Wellness App for New Parents</h3><h3>&nbsp;-&nbsp;</h3><h3>Director of Marketing</h3></p></div><div><p>10 hrs</p><p>&nbsp;|&nbsp;</p><p>$6.5K - $7.5K / month</p><p>&nbsp;|&nbsp;</p><p>Remote (USA / Canada only)</p><div><p>Marketing</p><p>Syndicated</p><p>August 14, 2025</p><p>director-of-marketing-at-a-wellness-app-for-new-parents</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>An AI Model Training Startup</h3><h3>&nbsp;-&nbsp;</h3><h3>Senior Product Manager</h3></p></div><div><p>40 hrs</p><p>&nbsp;|&nbsp;</p><p>$20K - $25K / month</p><p>&nbsp;|&nbsp;</p><p>Remote (USA only)</p><div><p>Product</p><p>Syndicated</p><p>August 13, 2025</p><p>senior-product-manager-at-an-ai-model-training-startup-2</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>A Consumer Social Startup</h3><h3>&nbsp;-&nbsp;</h3><h3>Senior Full-Stack Engineer</h3></p></div><div><p>20 - 40 hrs</p><p>&nbsp;|&nbsp;</p><p>$125 - $150 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (EST +/- 5 hrs)</p><div><p>Engineering</p><p>Syndicated</p><p>August 12, 2025</p><p>senior-full-stack-engineer-at-a-consumer-social-startup</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Credible</h3><h3>&nbsp;-&nbsp;</h3><h3>Controller </h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote (USA only)</p><div><p>Finance</p><p>Syndicated</p><p>August 11, 2025</p><p>controller-at-credible</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>A79.ai</h3><h3>&nbsp;-&nbsp;</h3><h3> Vice President, AI Sales </h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote</p><div><p>Sales</p><p>Syndicated</p><p>August 11, 2025</p><p>vice-president-ai-sales-at-a79-ai</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Good Trouble</h3><h3>&nbsp;-&nbsp;</h3><h3>Chief Financial Officer </h3></p></div><div><p>8 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote</p><div><p>Finance</p><p>Syndicated</p><p>August 11, 2025</p><p>chief-financial-officer-at-good-trouble</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>HeartStamp</h3><h3>&nbsp;-&nbsp;</h3><h3>General Counsel</h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>$110K – $160K yearly equiv.</p><p>&nbsp;|&nbsp;</p><p>Remote (USA only)</p><div><p>Legal</p><p>Syndicated</p><p>August 11, 2025</p><p>counsel-generative-ai-ip-at-heartstamp</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>A Creator-focused AI Startup</h3><h3>&nbsp;-&nbsp;</h3><h3>AI Engineer</h3></p></div><div><p>10 - 15 hrs</p><p>&nbsp;|&nbsp;</p><p>$100 - $125 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (USA, Canada, or Europe only)</p><div><p>Engineering</p><p>Syndicated</p><p>August 11, 2025</p><p>ai-engineer-at-a-creator-focused-ai-startup</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Project Own</h3><h3>&nbsp;-&nbsp;</h3><h3>Head of Product </h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>$125-$175 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (USA only)</p><div><p>Product</p><p>Syndicated</p><p>August 11, 2025</p><p>head-of-product-at-project-own</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Bayesian Health</h3><h3>&nbsp;-&nbsp;</h3><h3>Senior Product Designer </h3></p></div><div><p>10 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote</p><div><p>Design</p><p>Syndicated</p><p>August 11, 2025</p><p>senior-product-designer-at-bayesian-health</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>An Auto Parts eCommerce Brand</h3><h3>&nbsp;-&nbsp;</h3><h3>Tech Lead</h3></p></div><div><p>10 hrs</p><p>&nbsp;|&nbsp;</p><p>$100 - $125 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (USA time zones only)</p><div><p>Engineering</p><p>Syndicated</p><p>August 11, 2025</p><p>tech-lead-at-an-auto-parts-ecommerce-brand</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>A Social App for Activity Buddies</h3><h3>&nbsp;-&nbsp;</h3><h3>Chief Marketing Officer</h3></p></div><div><p>5 hrs</p><p>&nbsp;|&nbsp;</p><p>$150 - $200 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (USA only)</p><div><p>Marketing</p><p>Syndicated</p><p>August 8, 2025</p><p>chief-marketing-officer-at-a-social-app-for-activity-buddies</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>A Consumer Healthtech Marketplace</h3><h3>&nbsp;-&nbsp;</h3><h3>Director of Operations</h3></p></div><div><p>20 - 40 hrs</p><p>&nbsp;|&nbsp;</p><p>$125 - $150 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (SF, LA, MIA, NYC only)</p><div><p>Operations</p><p>Syndicated</p><p>August 8, 2025</p><p>director-of-operations-at-a-consumer-healthtech-marketplace</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>A Consumer Healthtech Marketplace</h3><h3>&nbsp;-&nbsp;</h3><h3>Growth Marketing Lead</h3></p></div><div><p>20 - 40 hrs</p><p>&nbsp;|&nbsp;</p><p>$125 - $150 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (SF, LA, MIA, NYC only)</p><div><p>Marketing</p><p>Syndicated</p><p>August 8, 2025</p><p>growth-marketing-lead-at-a-consumer-healthtech-marketplace</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>A Consumer Healthtech Marketplace</h3><h3>&nbsp;-&nbsp;</h3><h3>Chief Technology Officer</h3></p></div><div><p>20 - 40 hrs</p><p>&nbsp;|&nbsp;</p><p>$175 - $200 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (SF, LA, MIA, NYC only)</p><div><p>Engineering</p><p>Syndicated</p><p>August 8, 2025</p><p>chief-technology-officer-at-a-consumer-healthtech-marketplace</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Nicklpass</h3><h3>&nbsp;-&nbsp;</h3><h3>Founding UX Designer </h3></p></div><div><p>5 - 10 hrs</p><p>&nbsp;|&nbsp;</p><p>$75k – $135k yearly equiv.</p><p>&nbsp;|&nbsp;</p><p>Remote (Worldwide)</p><div><p>Design</p><p>Syndicated</p><p>August 4, 2025</p><p>founding-ux-designer-at-nicklpass</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Morreale</h3><h3>&nbsp;-&nbsp;</h3><h3>Chief Financial Officer</h3></p></div><div><p>16 - 24 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Hybrid (Chicago)</p><div><p>Finance</p><p>Syndicated</p><p>August 4, 2025</p><p>chief-financial-officer-at-morreale</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Neuranics</h3><h3>&nbsp;-&nbsp;</h3><h3>Chief Financial Officer </h3></p></div><div><p>8 - 16 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Onsite (Glasgow, UK)</p><div><p>Finance</p><p>Syndicated</p><p>August 4, 2025</p><p>chief-financial-officer-at-neuranics</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Gitcoin</h3><h3>&nbsp;-&nbsp;</h3><h3>Operations Leader</h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>$4K - $6.5K / mo.</p><p>&nbsp;|&nbsp;</p><p>Remote (Worldwide)</p><div><p>Operations</p><p>Syndicated</p><p>August 4, 2025</p><p>operations-leader-at-gitcoin</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Novapulse</h3><h3>&nbsp;-&nbsp;</h3><h3>Chief Technology Officer</h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote </p><div><p>Engineering</p><p>Syndicated</p><p>August 4, 2025</p><p>chief-technology-officer-at-novapulse</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Rec</h3><h3>&nbsp;-&nbsp;</h3><h3>Field Marketing Lead</h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Hybrid (SF)</p><div><p>Marketing</p><p>Syndicated</p><p>August 4, 2025</p><p>field-marketing-lead-at-rec</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Digital United</h3><h3>&nbsp;-&nbsp;</h3><h3>Financial Consultant</h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote</p><div><p>Finance</p><p>Syndicated</p><p>August 4, 2025</p><p>financial-consultant-at-digital-united</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Phoenix3</h3><h3>&nbsp;-&nbsp;</h3><h3>General Counsel </h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Onsite (Waltham, MA)</p><div><p>Legal</p><p>Syndicated</p><p>August 4, 2025</p><p>general-counsel-at-phoenix3</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Sincere</h3><h3>&nbsp;-&nbsp;</h3><h3>PR Manager </h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Hybrid (Boston)</p><div><p>Marketing</p><p>Syndicated</p><p>August 4, 2025</p><p>pr-manager-at-sincere</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>White Snake Projects</h3><h3>&nbsp;-&nbsp;</h3><h3>Major Gift Officer </h3></p></div><div><p>12 hrs</p><p>&nbsp;|&nbsp;</p><p>$3000 / mo.</p><p>&nbsp;|&nbsp;</p><p>Onsite (Boston)</p><div><p>Other</p><p>Syndicated</p><p>August 4, 2025</p><p>major-gift-officer-at-white-snake-projects</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>A Home Maintenance Concierge Startup</h3><h3>&nbsp;-&nbsp;</h3><h3>Director of Marketing</h3></p></div><div><p>10 - 15 hrs</p><p>&nbsp;|&nbsp;</p><p>$150 - $175 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (USA / Canada only)</p><div><p>Marketing</p><p>Syndicated</p><p>August 1, 2025</p><p>director-of-marketing-at-a-home-maintenance-concierge-startup</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Totally Flawless</h3><h3>&nbsp;-&nbsp;</h3><h3>Lead Mobile Engineer</h3></p></div><div><p>15 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>$80 - $100 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (USA only)</p><div><p>Engineering</p><p>Syndicated</p><p>July 28, 2025</p><p>lead-mobile-engineer-at-totally-flawless</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Marshall Medical Group</h3><h3>&nbsp;-&nbsp;</h3><h3>Chief Marketing Officer</h3></p></div><div><p>20 hrs</p><p>&nbsp;|&nbsp;</p><p>$4K - $6K / mo</p><p>&nbsp;|&nbsp;</p><p>Hybrid (Lexington, KY)</p><div><p>Marketing</p><p>Syndicated</p><p>July 28, 2025</p><p>chief-marketing-officer-at-marshall-medical-group</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Flashii </h3><h3>&nbsp;-&nbsp;</h3><h3>VP of Sales </h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote</p><div><p>Sales</p><p>Syndicated</p><p>July 28, 2025</p><p>vice-president-of-sales-at-flashii--fg829</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Nexture Bio</h3><h3>&nbsp;-&nbsp;</h3><h3>Sales Lead </h3></p></div><div><p>8 - 15 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Hybrid (Sacramento)</p><div><p>Sales</p><p>Syndicated</p><p>July 28, 2025</p><p>sales-lead-at-nexture-bio</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>A NYC Hospitality Group</h3><h3>&nbsp;-&nbsp;</h3><h3>Head of People Operations</h3></p></div><div><p>5 - 10 hrs</p><p>&nbsp;|&nbsp;</p><p>$125 - $175 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (USA only)</p><div><p>People</p><p>Syndicated</p><p>July 28, 2025</p><p>head-of-people-operations-at-a-nyc-hospitality-group</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>SE10 PR</h3><h3>&nbsp;-&nbsp;</h3><h3>New Business Development </h3></p></div><div><p>10 - 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote</p><div><p>Sales</p><p>Syndicated</p><p>July 28, 2025</p><p>new-business-development-at-se10-pr</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>Mod Ventures LLC</h3><h3>&nbsp;-&nbsp;</h3><h3>Chief Operations &amp; Financial Officer </h3></p></div><div><p> 10 – 20 hrs</p><p>&nbsp;|&nbsp;</p><p>Unknown</p><p>&nbsp;|&nbsp;</p><p>Remote</p><div><p>Operations</p><p>Syndicated</p><p>July 28, 2025</p><p>chief-operations-financial-officer-at-mod-ventures-llc</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>An HR-tech Analytics Platform</h3><h3>&nbsp;-&nbsp;</h3><h3>Staff Frontend Engineer</h3></p></div><div><p>20 - 40 hrs</p><p>&nbsp;|&nbsp;</p><p>$120 - $180 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (USA / Canada only)</p><div><p>Engineering</p><p>Syndicated</p><p>May 27, 2025</p><p>staff-frontend-engineer-at-an-hr-tech-analytics-platform</p></div></div></div></div><div role="listitem"><div tabindex="0" role="button" aria-roledescription="open-modal-trigger" aria-controls="fs-modal-1-popup" aria-haspopup="dialog" aria-expanded="false" data-w-id="9e108133-0d83-1535-4f7b-7f859e2881ab"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/661a6911701485a8909acb22_star.svg" loading="lazy" alt=""></p></div><div><div><p><h3>A Boutique Fractional CFO Firm</h3><h3>&nbsp;-&nbsp;</h3><h3>FP&amp;A Lead</h3></p></div><div><p>10 - 15 hrs</p><p>&nbsp;|&nbsp;</p><p>$80 - $120 / hr</p><p>&nbsp;|&nbsp;</p><p>Remote (Worldwide)</p><div><p>Finance</p><p>Syndicated</p><p>April 23, 2025</p><p>fp-a-lead-at-a-boutique-fractional-cfo-firm</p></div></div></div></div></div><div><div id="w-node-_9e108133-0d83-1535-4f7b-7f859e2881d8-075f0119"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/65b262a0934f65c19a253d80_email%201%20(2)%20(1).webp" loading="lazy" alt=""></p></div><div id="source-fractional-section"><div><p><h3>No <span id="job-placeholder">jobs</span>... yet. Get emailed when the next one goes live.</h3></p><p>This is a spam-free zone.</p></div><div><div id="success-message-2"><div><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/65ad278adba71fccff520329_Frame%2063.svg" loading="lazy" alt=""></p><p>You’re in! Check your inbox to confirm.</p></div><div><p>We also post job alerts on</p></div></div><div id="error-message-2"><p>Hhmm, try again. That didn’t work.</p></div></div></div></div><div><div id="w-node-_9e108133-0d83-1535-4f7b-7f859e288228-075f0119"><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/65b262a0934f65c19a253d80_email%201%20(2)%20(1).webp" loading="lazy" alt=""></p></div><div id="source-fractional-section"><div><p><h3>Fractional Job Alerts&nbsp; </h3><h3>In Your Inbox</h3><h3> Weekly.</h3></p><p>This is a spam-free zone.</p></div><div><div id="success-message-2"><div><p><img src="https://cdn.prod.website-files.com/6578c49d9871fac26dd7700e/65ad278adba71fccff520329_Frame%2063.svg" loading="lazy" alt=""></p><p>You’re in! Check your inbox to confirm.</p></div><div><p>We also post job alerts on</p></div></div><div id="error-message-2"><p>Hhmm, try again. That didn’t work.</p></div></div></div></div></div></div></div><div><div><h2>Playbooks</h2></div><div id="w-node-_9e108133-0d83-1535-4f7b-7f859e2882c3-075f0119"><h3>Want to Read More?</h3><div><p>Everything you need to go from zero to fractional operator, quickly.</p></div></div></div><div><div><h2>And More...</h2></div><div><div id="w-node-e444a3f1-5c67-c955-450c-0b68c7dfb507-c7dfb4fd"><h3>The Toolkit</h3><div><p>The tools and communities we recommend to help you build a successful fractional practice.</p></div></div><div id="w-node-e444a3f1-5c67-c955-450c-0b68c7dfb512-c7dfb4fd"><h3>The Blog</h3><div><p>Our latest thoughts and news related to the fractional world. Featuring select community members, too!</p></div></div></div></div><div id="contact"><p><h2>Contact Us</h2></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A minimal tensor processing unit (TPU), inspired by Google's TPU (233 pts)]]></title>
            <link>https://github.com/tiny-tpu-v2/tiny-tpu</link>
            <guid>44945008</guid>
            <pubDate>Mon, 18 Aug 2025 20:34:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/tiny-tpu-v2/tiny-tpu">https://github.com/tiny-tpu-v2/tiny-tpu</a>, See on <a href="https://news.ycombinator.com/item?id=44945008">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">tiny-tpu</h2><a id="user-content-tiny-tpu" aria-label="Permalink: tiny-tpu" href="#tiny-tpu"></a></p>
<p dir="auto">A minimal tensor processing unit (TPU), reinvented from Google's TPU V2 and V1.</p>
<details open="">
  <summary>
    
    <span aria-label="Video description tinytpu.mp4">tinytpu.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/110429254/479205816-b5d6aefe-4250-4c6d-866e-65d519e4de74.mp4?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTU1NzgxMDIsIm5iZiI6MTc1NTU3NzgwMiwicGF0aCI6Ii8xMTA0MjkyNTQvNDc5MjA1ODE2LWI1ZDZhZWZlLTQyNTAtNGM2ZC04NjZlLTY1ZDUxOWU0ZGU3NC5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwODE5JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDgxOVQwNDMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0xOTgxMjEzMmMzYjgwNzI1NzhkNzYyMjM2NjFhMmU5Njg4NDIzOTkzMzBmNTZiYzI3M2VlZDRhOWI0NWJiNzBlJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.G-NWijGwV-znD7kaoLTWLXXtUFX6CElnqDWxOM3gfsk" data-canonical-src="https://private-user-images.githubusercontent.com/110429254/479205816-b5d6aefe-4250-4c6d-866e-65d519e4de74.mp4?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTU1NzgxMDIsIm5iZiI6MTc1NTU3NzgwMiwicGF0aCI6Ii8xMTA0MjkyNTQvNDc5MjA1ODE2LWI1ZDZhZWZlLTQyNTAtNGM2ZC04NjZlLTY1ZDUxOWU0ZGU3NC5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwODE5JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDgxOVQwNDMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0xOTgxMjEzMmMzYjgwNzI1NzhkNzYyMjM2NjFhMmU5Njg4NDIzOTkzMzBmNTZiYzI3M2VlZDRhOWI0NWJiNzBlJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.G-NWijGwV-znD7kaoLTWLXXtUFX6CElnqDWxOM3gfsk" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">Table of Contents</h2><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#motivation">Motivation</a></li>
<li><a href="#architecture">Architecture</a>
<ul dir="auto">
<li><a href="#processing-element-pe">Processing Element (PE)</a></li>
<li><a href="#systolic-array">Systolic Array</a></li>
<li><a href="#vector-processing-unit-vpu">Vector Processing Unit (VPU)</a></li>
<li><a href="#unified-buffer-ub">Unified Buffer (UB)</a></li>
<li><a href="#control-unit">Control Unit</a></li>
</ul>
</li>
<li><a href="#instruction-set">Instruction Set</a></li>
<li><a href="#example-instruction-sequence">Example Instruction Sequence</a></li>
<li><a href="#future-steps">Future Steps</a></li>
<li><a href="#setup">Setup</a>
<ul dir="auto">
<li><a href="#macos-specific">MacOS specific</a></li>
<li><a href="#ubuntu-specific">Ubuntu specific</a></li>
</ul>
</li>
<li><a href="#adding-a-new-module-to-the-tiny-tpu">Adding a new module to the tiny-tpu</a>
<ul dir="auto">
<li><a href="#1-create-the-module-file">1. Create the module file</a></li>
<li><a href="#2-create-the-dump-file">2. Create the dump file</a></li>
<li><a href="#3-create-the-test-file">3. Create the test file</a></li>
<li><a href="#4-update-the-makefile">4. Update the Makefile</a></li>
<li><a href="#5-view-waveforms">5. View waveforms</a></li>
</ul>
</li>
<li><a href="#running-commands-from-makefile">Running commands from Makefile</a></li>
<li><a href="#fixed-point-viewing-in-gtkwave">Fixed point viewing in gtkwave</a></li>
<li><a href="#what-is-a-gtkw-file">What is a gtkw file?</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Architecture</h2><a id="user-content-architecture" aria-label="Permalink: Architecture" href="#architecture"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/tiny-tpu-v2/tiny-tpu/blob/main/images/tpu.png"><img src="https://github.com/tiny-tpu-v2/tiny-tpu/raw/main/images/tpu.png" alt="TPU Architecture"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Processing Element (PE)</h3><a id="user-content-processing-element-pe" aria-label="Permalink: Processing Element (PE)" href="#processing-element-pe"></a></p>
<ul dir="auto">
<li><strong>Function</strong>: Performs a multiply-accumulate operation every clock cycle</li>
<li><strong>Data Flow</strong>:
<ul dir="auto">
<li>Incoming data is multiplied by a stored weight and added to an incoming partial sum to produce an output sum</li>
<li>Incoming data also passes through to the next element for propagation across the array</li>
</ul>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Systolic Array</h3><a id="user-content-systolic-array" aria-label="Permalink: Systolic Array" href="#systolic-array"></a></p>
<ul dir="auto">
<li><strong>Architecture</strong>: A grid of processing elements, starting from 2x2</li>
<li><strong>Data Movement</strong>:
<ul dir="auto">
<li>Input values flow horizontally across the array</li>
<li>Partial sums flow vertically down the array</li>
<li>Weights remain fixed within each processing element during computation</li>
</ul>
</li>
<li><strong>Input Preprocessing</strong>:
<ul dir="auto">
<li>Input matrices are rotated 90 degrees (implemented in hardware)</li>
<li>Inputs are staggered for correct computation in the systolic array</li>
<li>Weight matrices are transposed and staggered to align with mathematical formulas</li>
</ul>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Vector Processing Unit (VPU)</h3><a id="user-content-vector-processing-unit-vpu" aria-label="Permalink: Vector Processing Unit (VPU)" href="#vector-processing-unit-vpu"></a></p>
<ul dir="auto">
<li>Performs element-wise operations after the systolic array</li>
<li><strong>Control</strong>: Module selection depends on the computation stage</li>
<li><strong>Modules (pipelined)</strong>:
<ol dir="auto">
<li>Bias addition</li>
<li>Leaky ReLU activation function</li>
<li>MSE loss</li>
<li>Leaky ReLU derivative</li>
</ol>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Unified Buffer (UB)</h3><a id="user-content-unified-buffer-ub" aria-label="Permalink: Unified Buffer (UB)" href="#unified-buffer-ub"></a></p>
<ul dir="auto">
<li>Dual-port memory for storing intermediate values</li>
<li><strong>Stored Data</strong>:
<ul dir="auto">
<li>Input matrices</li>
<li>Weight matrices</li>
<li>Bias vectors</li>
<li>Post-activation values for backpropagation</li>
<li>Activation leak factors</li>
<li>Inverse batch size constant for MSE backpropagation</li>
</ul>
</li>
<li><strong>Interface</strong>:
<ul dir="auto">
<li>Two read and two write ports per data type</li>
<li>Data is accessed by specifying a start address and count</li>
<li>Reads can occur continuously in the background until the requested count is reached</li>
</ul>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Control Unit</h3><a id="user-content-control-unit" aria-label="Permalink: Control Unit" href="#control-unit"></a></p>
<ul dir="auto">
<li><strong>Instruction width</strong>: 94 bits</li>
<li>See <a href="#instruction-set">Instruction Set</a> section below for more information.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Instruction Set</h2><a id="user-content-instruction-set" aria-label="Permalink: Instruction Set" href="#instruction-set"></a></p>
<p dir="auto">Our ISA is 94 bits wide. The full image is available in the <code>images/</code> folder.</p>
<p dir="auto">Our ISA defines all necessary signals for transferring data and interacting with our TPU. The implementation of the control unit (which reads instructions) can be found at <code>src/control_unit.sv</code>.</p>
<p dir="auto">The <code>instruction</code> bus is <strong>94 bits wide</strong> (<code>[93:0]</code>) and is divided into fields that directly control subsystems.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bits [0–4]: 1-bit Control Signals</h3><a id="user-content-bits-04-1-bit-control-signals" aria-label="Permalink: Bits [0–4]: 1-bit Control Signals" href="#bits-04-1-bit-control-signals"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Bit</th>
<th>Signal</th>
<th>Meaning</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td><code>sys_switch_in</code></td>
<td>System mode switch (general-purpose "on/off" CU)</td>
<td><code>1 = system active</code>, <code>0 = idle</code></td>
</tr>
<tr>
<td>1</td>
<td><code>ub_rd_start_in</code></td>
<td>Start UB (Unified Buffer) read transaction</td>
<td><code>1 = trigger read</code>, <code>0 = no read</code></td>
</tr>
<tr>
<td>2</td>
<td><code>ub_rd_transpose</code></td>
<td>UB read transpose mode</td>
<td><code>1 = transpose</code>, <code>0 = normal</code></td>
</tr>
<tr>
<td>3</td>
<td><code>ub_wr_host_valid_in_1</code></td>
<td>Host write channel 1 valid flag</td>
<td><code>1 = write valid</code>, <code>0 = not valid</code></td>
</tr>
<tr>
<td>4</td>
<td><code>ub_wr_host_valid_in_2</code></td>
<td>Host write channel 2 valid flag</td>
<td><code>1 = write valid</code>, <code>0 = not valid</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bits [6:5]: UB Read Column Size (2-bit)</h3><a id="user-content-bits-65-ub-read-column-size-2-bit" aria-label="Permalink: Bits [6:5]: UB Read Column Size (2-bit)" href="#bits-65-ub-read-column-size-2-bit"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Field</th>
<th>Signal</th>
<th>Meaning</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>[6:5]</td>
<td><code>ub_rd_col_size</code></td>
<td>Number of columns to read</td>
<td><code>00=0</code>, <code>01=1</code>, <code>10=2</code>, <code>11=3</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bits [14:7]: UB Read Row Size (8-bit)</h3><a id="user-content-bits-147-ub-read-row-size-8-bit" aria-label="Permalink: Bits [14:7]: UB Read Row Size (8-bit)" href="#bits-147-ub-read-row-size-8-bit"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Field</th>
<th>Signal</th>
<th>Meaning</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>[14:7]</td>
<td><code>ub_rd_row_size</code></td>
<td>Number of rows to read (0–255)</td>
<td><code>0x08 = read 8 rows</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bits [22:15]: UB Read Address (8-bit)</h3><a id="user-content-bits-2215-ub-read-address-8-bit" aria-label="Permalink: Bits [22:15]: UB Read Address (8-bit)" href="#bits-2215-ub-read-address-8-bit"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Field</th>
<th>Signal</th>
<th>Meaning</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>[22:15]</td>
<td><code>ub_rd_addr_in</code></td>
<td>UB read address (0–255)</td>
<td><code>0x10 = read bank 16</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bits [25:23]: UB Pointer Select (3-bit)</h3><a id="user-content-bits-2523-ub-pointer-select-3-bit" aria-label="Permalink: Bits [25:23]: UB Pointer Select (3-bit)" href="#bits-2523-ub-pointer-select-3-bit"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Field</th>
<th>Signal</th>
<th>Meaning</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>[25:23]</td>
<td><code>ub_ptr_sel</code></td>
<td>Selects UB pointer</td>
<td><code>3’b001 = route read ptr to bias module in VPU</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bits [41:26]: UB Write Host Data In 1 (16-bit, Fixed-Point)</h3><a id="user-content-bits-4126-ub-write-host-data-in-1-16-bit-fixed-point" aria-label="Permalink: Bits [41:26]: UB Write Host Data In 1 (16-bit, Fixed-Point)" href="#bits-4126-ub-write-host-data-in-1-16-bit-fixed-point"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Field</th>
<th>Signal</th>
<th>Meaning</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>[41:26]</td>
<td><code>ub_wr_host_data_in_1</code></td>
<td>First host write word</td>
<td><code>0xABCD</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bits [57:42]: UB Write Host Data In 2 (16-bit, Fixed-Point)</h3><a id="user-content-bits-5742-ub-write-host-data-in-2-16-bit-fixed-point" aria-label="Permalink: Bits [57:42]: UB Write Host Data In 2 (16-bit, Fixed-Point)" href="#bits-5742-ub-write-host-data-in-2-16-bit-fixed-point"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Field</th>
<th>Signal</th>
<th>Meaning</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>[57:42]</td>
<td><code>ub_wr_host_data_in_2</code></td>
<td>Second host write word</td>
<td><code>0x1234</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bits [61:58]: VPU Data Pathway (4-bit)</h3><a id="user-content-bits-6158-vpu-data-pathway-4-bit" aria-label="Permalink: Bits [61:58]: VPU Data Pathway (4-bit)" href="#bits-6158-vpu-data-pathway-4-bit"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Field</th>
<th>Signal</th>
<th>Meaning</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>[61:58]</td>
<td><code>vpu_data_pathway</code></td>
<td>Routing of data in VPU</td>
<td><code>0001=bias + relu routing</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bits [77:62]: Inverse Batch Size × 2 (16-bit, Fixed-Point)</h3><a id="user-content-bits-7762-inverse-batch-size--2-16-bit-fixed-point" aria-label="Permalink: Bits [77:62]: Inverse Batch Size × 2 (16-bit, Fixed-Point)" href="#bits-7762-inverse-batch-size--2-16-bit-fixed-point"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Field</th>
<th>Signal</th>
<th>Meaning</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>[77:62]</td>
<td><code>inv_batch_size_times_two_in</code></td>
<td>Precomputed scaling factor (2/batch)</td>
<td><code>0x0010 = (2/32)</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bits [93:78]: VPU Leak Factor (16-bit, Fixed-Point)</h3><a id="user-content-bits-9378-vpu-leak-factor-16-bit-fixed-point" aria-label="Permalink: Bits [93:78]: VPU Leak Factor (16-bit, Fixed-Point)" href="#bits-9378-vpu-leak-factor-16-bit-fixed-point"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Field</th>
<th>Signal</th>
<th>Meaning</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>[93:78]</td>
<td><code>vpu_leak_factor_in</code></td>
<td>Leak factor for activation (e.g., Leaky ReLU)</td>
<td><code>0x00A0 = 0.625</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Example Instruction Sequence</h2><a id="user-content-example-instruction-sequence" aria-label="Permalink: Example Instruction Sequence" href="#example-instruction-sequence"></a></p>
<p dir="auto">Instructions are directly loaded into an instruction buffer on the chip from a testbench file.</p>
<ul dir="auto">
<li>See <code>tests/tpu.v</code> for our forward and backward pass instruction sequence</li>
<li>See the <a href="#setup">Setup</a> section on how to run this testbench</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Future Steps</h2><a id="user-content-future-steps" aria-label="Permalink: Future Steps" href="#future-steps"></a></p>
<ol dir="auto">
<li>Compiler for this instruction set</li>
<li>Scaling TPU to larger dimensions (256×256 or 512×512)</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Setup</h2><a id="user-content-setup" aria-label="Permalink: Setup" href="#setup"></a></p>
<p dir="auto">We are open source and appreciate any contributions! Here is our workflow and steps to set up our development environment:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">MacOS Specific</h3><a id="user-content-macos-specific" aria-label="Permalink: MacOS Specific" href="#macos-specific"></a></p>
<ol dir="auto">
<li>Create a virtual environment and run:

</li>
<li>Install iverilog using Homebrew:

</li>
<li>Build gtkwave <strong>FROM SOURCE</strong> (important: other installation methods currently do not work)</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Ubuntu/Linux Specific</h3><a id="user-content-ubuntulinux-specific" aria-label="Permalink: Ubuntu/Linux Specific" href="#ubuntulinux-specific"></a></p>
<ol dir="auto">
<li>Create a virtual environment and run:

</li>
<li>Install gtkwave:

</li>
<li>Install iverilog:
<div dir="auto" data-snippet-clipboard-copy-content="sudo apt install iverilog"><pre>sudo apt install iverilog</pre></div>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Adding Modules</h2><a id="user-content-adding-modules" aria-label="Permalink: Adding Modules" href="#adding-modules"></a></p>
<p dir="auto">Follow these steps to add a new module to the project:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">1. Create the Module File</h3><a id="user-content-1-create-the-module-file" aria-label="Permalink: 1. Create the Module File" href="#1-create-the-module-file"></a></p>
<p dir="auto">Add your new module file <code>&lt;MODULE_NAME&gt;.sv</code> in the <code>src/</code> directory.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">2. Create the Dump File</h3><a id="user-content-2-create-the-dump-file" aria-label="Permalink: 2. Create the Dump File" href="#2-create-the-dump-file"></a></p>
<p dir="auto">Create <code>dump_&lt;MODULE_NAME&gt;.sv</code> in the <code>test/</code> directory with the following code:</p>
<div dir="auto" data-snippet-clipboard-copy-content="module dump();
initial begin
  $dumpfile(&quot;waveforms/<MODULE_NAME>.vcd&quot;);
  $dumpvars(0, <MODULE_NAME>); 
end
endmodule"><pre><span>module</span> <span>dump</span>();
<span>initial</span> <span>begin</span>
  <span>$dumpfile</span>(<span><span>"</span>waveforms/&lt;MODULE_NAME&gt;.vcd<span>"</span></span>);
  <span>$dumpvars</span>(<span>0</span>, <span>&lt;</span><span>MODULE_NAME</span><span>&gt;</span>); 
<span>end</span>
<span>endmodule</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">3. Creating Tests</h3><a id="user-content-3-creating-tests" aria-label="Permalink: 3. Creating Tests" href="#3-creating-tests"></a></p>
<p dir="auto">Create <code>test_&lt;MODULE_NAME&gt;.py</code> in the <code>test/</code> directory.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">4. Makefile Updates</h3><a id="user-content-4-makefile-updates" aria-label="Permalink: 4. Makefile Updates" href="#4-makefile-updates"></a></p>
<p dir="auto">Add your module to the <code>SOURCES</code> variable and create a test target:</p>
<div dir="auto" data-snippet-clipboard-copy-content="test_<MODULE_NAME>: $(SIM_BUILD_DIR)
	$(IVERILOG) -o $(SIM_VVP) -s <MODULE_NAME> -s dump -g2012 $(SOURCES) test/dump_<MODULE_NAME>.sv
	PYTHONOPTIMIZE=$(NOASSERT) MODULE=test_<MODULE_NAME> $(VVP) -M $(COCOTB_LIBS) -m libcocotbvpi_icarus $(SIM_VVP)
	! grep failure results.xml
	mv <MODULE_NAME>.vcd waveforms/ 2>/dev/null || true"><pre><span>test_&lt;MODULE_NAME&gt;</span>: <span>$(<span>SIM_BUILD_DIR</span>)</span>
	<span>$(<span>IVERILOG</span>)</span> -o <span>$(<span>SIM_VVP</span>)</span> -s <span>&lt;</span>MODULE_NAME<span>&gt;</span> -s dump -g2012 <span>$(<span>SOURCES</span>)</span> test/dump_<span>&lt;</span>MODULE_NAME<span>&gt;</span>.sv
	PYTHONOPTIMIZE=<span>$(<span>NOASSERT</span>)</span> MODULE=test_<span>&lt;</span>MODULE_NAME<span>&gt;</span> <span>$(<span>VVP</span>)</span> -M <span>$(<span>COCOTB_LIBS</span>)</span> -m libcocotbvpi_icarus <span>$(<span>SIM_VVP</span>)</span>
	<span>!</span> grep failure results.xml
	mv <span>&lt;</span>MODULE_NAME<span>&gt;</span>.vcd waveforms/ <span>2&gt;</span>/dev/null <span>||</span> <span>true</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">5. View Waveforms</h3><a id="user-content-5-view-waveforms" aria-label="Permalink: 5. View Waveforms" href="#5-view-waveforms"></a></p>
<p dir="auto">Run the following command to view the generated waveforms:</p>
<div dir="auto" data-snippet-clipboard-copy-content="gtkwave waveforms/<MODULE_NAME>.vcd"><pre>gtkwave waveforms/<span>&lt;</span>MODULE_NAME<span>&gt;</span>.vcd</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Makefile Commands</h2><a id="user-content-makefile-commands" aria-label="Permalink: Makefile Commands" href="#makefile-commands"></a></p>
<p dir="auto">Run tests:</p>

<p dir="auto">View waveforms:</p>
<div dir="auto" data-snippet-clipboard-copy-content="gtkwave waveforms/<MODULE_NAME>.vcd"><pre>gtkwave waveforms/<span>&lt;</span>MODULE_NAME<span>&gt;</span>.vcd</pre></div>
<p dir="auto">Or use the shorthand:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">GTKWwave Setup</h2><a id="user-content-gtkwwave-setup" aria-label="Permalink: GTKWwave Setup" href="#gtkwwave-setup"></a></p>
<ol dir="auto">
<li>Right-click all signals</li>
<li>Navigate to: <strong>Data Format</strong> → <strong>Fixed Point Shift</strong> → <strong>Specify</strong></li>
<li>Enter <code>8</code> and click <strong>OK</strong></li>
<li>Set: <strong>Data Format</strong> → <strong>Signed Decimal</strong></li>
<li>Enable: <strong>Data Format</strong> → <strong>Fixed Point Shift</strong> → <strong>ON</strong></li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is a .gtkw File?</h2><a id="user-content-what-is-a-gtkw-file" aria-label="Permalink: What is a .gtkw File?" href="#what-is-a-gtkw-file"></a></p>
<p dir="auto">A <code>.gtkw</code> file stores the signal configuration for <code>make show_&lt;MODULE_NAME&gt;</code>. You only need to save it once after running:</p>
<div dir="auto" data-snippet-clipboard-copy-content="gtkwave waveforms/<MODULE_NAME>.vcd"><pre>gtkwave waveforms/<span>&lt;</span>MODULE_NAME<span>&gt;</span>.vcd</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Motivation</h2><a id="user-content-motivation" aria-label="Permalink: Motivation" href="#motivation"></a></p>
<p dir="auto">The details of TPU architecture are closed source, as is most of chip design. We want this resource to be the ultimate guide to breaking into building chip accelerators for all levels of technical expertise — even if you just learned high school math and only know y = mx + b.</p>
<p dir="auto">Before this project, none of us had professional experience in hardware architecture/design. We started this ambitious project as a dedicated group wanting to break into hardware design. We've collectively gained significant design experience from this project.</p>
<p dir="auto">We hope that the inventive nature of the article at <a href="https://tinytpu.com/" rel="nofollow">tinytpu.com</a>, this README, and the code in this repository will help you walk through our steps and learn how to approach problems with an inventive mindset.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GenAI FOMO has spurred businesses to light nearly $40B on fire (231 pts)]]></title>
            <link>https://www.theregister.com/2025/08/18/generative_ai_zero_return_95_percent/</link>
            <guid>44944620</guid>
            <pubDate>Mon, 18 Aug 2025 19:54:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2025/08/18/generative_ai_zero_return_95_percent/">https://www.theregister.com/2025/08/18/generative_ai_zero_return_95_percent/</a>, See on <a href="https://news.ycombinator.com/item?id=44944620">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>US companies have invested between $35 and $40 billion in Generative AI initiatives and, so far, have almost nothing to show for it.</p>
<p>According to <a href="https://docs.google.com/forms/d/e/1FAIpQLSc8rU8OpQWU44gYDeZyINUZjBFwu--1uTbxixK_PRSVrfaH8Q/viewform" rel="nofollow">a report</a> [PDF] from MIT's NANDA (Networked Agents and Decentralized AI) initiative, 95 percent of enterprise organizations have gotten zero return from their AI efforts.</p>
<p>Only 5 percent of organizations have successfully integrated AI tools into production at scale.</p>

    

<p>The report is based on 52 structured interviews with enterprise leaders and on analysis of more than 300 public AI initiatives and announcements, and a survey of 153 business professionals.</p>

        


        

<p>The report authors – Aditya Challapally, Chris Pease, Ramesh Raskar, and Pradyumna Chari – attribute this GenAI Divide not to insufficient infrastructure, learning, or talent, but to the inability of AI systems to retain data, to adapt, and to learn over time.</p>
<blockquote>

<p>The GenAI Divide is starkest in deployment rates, only 5 percent of custom enterprise AI tools reach production</p>
</blockquote>
<p>"The GenAI Divide is starkest in deployment rates, only 5 percent of custom enterprise AI tools reach production," the report says. "Chatbots succeed because they're easy to try and flexible, but fail in critical workflows due to lack of memory and customization."</p>
<p>As an unidentified CIO put it in an interview with the authors, "We've seen dozens of demos this year. Maybe one or two are genuinely useful. The rest are wrappers or science projects."</p>
<p>The authors' findings echo <a href="https://www.theregister.com/2025/07/09/csuite_sours_on_ai/">other recent research</a> showing a decline in confidence about AI initiatives among corporate leaders.</p>

        

<p>The NANDA report does say that a small percentage of companies have found GenAI helpful and that the technology is having a material impact on two out of nine industrial sectors – Technology and Media &amp; Telecom.&nbsp;</p>
<p>For the remaining sectors –&nbsp;Professional Services, Healthcare &amp; Pharma, Consumer &amp; Retail, Financial Services, Advanced Industries, and Energy &amp; Materials – Generative AI has been inconsequential.</p>
<p>An unidentified COO at a mid-market manufacturing firm is quoted as saying, "The hype on LinkedIn says everything has changed, but in our operations, nothing fundamental has shifted. We're processing some contracts faster, but that's all that has changed."</p>

        

<p>One thing that is changing is the employment landscape, at least in affected industries. In the Technology and Media sectors, the report notes, "[more than] 80 percent of executives anticipate reduced hiring volumes within 24 months."</p>
<p>According to the authors, the GenAI-driven workforce reductions have been occurring in non-core business activities that often get outsourced, such as customer support operations, administrative processing, and standardized development tasks.&nbsp;</p>
<p>"These roles exhibited vulnerability prior to AI implementation due to their outsourced status and process standardization," the report says, suggesting that, in the affected sectors, between five and 20 percent of support and admin processing has been impacted.&nbsp;</p>
<ul>

<li><a href="https://www.theregister.com/2025/08/18/aws_updated_kiro_pricing/">AWS pricing for Kiro dev tool dubbed 'a wallet-wrecking tragedy'</a></li>

<li><a href="https://www.theregister.com/2025/08/18/ai_form_fillers/">UK drafts AI to help Joe Public decipher its own baffling bureaucracy</a></li>

<li><a href="https://www.theregister.com/2025/08/18/opinion_column_gen_ai/">Generative AI isn't just a matter of life and death. It's far more important than that</a></li>

<li><a href="https://www.theregister.com/2025/08/17/nabiha_syed_remakes_mozilla_foundation/">Nabiha Syed remakes Mozilla Foundation in the era of Trump and AI</a></li>
</ul>
<p><em>The Register</em> has been told that Oracle's <a href="https://www.theregister.com/2025/08/15/oracle_cuts_300_in_california/">recent layoffs</a> reflect efforts to balance AI capital expenditures, <a href="https://www.theregister.com/2025/07/31/amazon_earnings_q2_2025/">an albatross around the necks of US tech giants</a>. At IBM, staffers have argued that <a href="https://www.theregister.com/2024/09/24/ibm_layoffs_ai_talent/">AI has been used as an excuse to offshore jobs</a>.</p>
<p>Whatever the stated rationale and actual motive for job cuts may be, Generative AI is having an impact on the Tech and Media &amp; Telecom sectors, where it has seen the broadest adoption.</p>
<p>While about 50 percent of AI budgets get allocated to marketing and sales, the report authors suggest that corporate investment instead should flow toward activities generating meaningful business results. This includes lead qualification and customer retention on the front end and, in the elimination of business process outsourcing, ad agency spending, and financial service risk checking on the back end.&nbsp;</p>
<p>Looking at the way Generative AI has been successful for certain companies, the report argues that generic tools like OpenAI's ChatGPT do better than bespoke enterprise tools, even when those enterprise tools use the same AI models under the hood.</p>
<p>The stated reason is that workers tend to be more familiar with ChatGPT's interface and thus use it more – a consequence of employee-driven shadow IT. The report cites an interview with a corporate lawyer who described her mid-size firm's dissatisfaction with a specialized contract analysis tool that cost $50,000.</p>
<p>"Our purchased AI tool provided rigid summaries with limited customization options," the attorney told the researchers. "With ChatGPT, I can guide the conversation and iterate until I get exactly what I need. The fundamental quality difference is noticeable, ChatGPT consistently produces better outputs, even though our vendor claims to use the same underlying technology."</p>
<p>Companies that bridge the GenAI divide approach AI procurement as business process outsourcing customers rather than as software-as-a-service clients, the authors argue.</p>
<p>"They demand deep customization, drive adoption from the front lines, and hold vendors accountable to business metrics," the report concludes. "The most successful buyers understand that crossing the divide requires partnership, not just purchase." ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I built a toy TPU that can do inference and training on the XOR problem (115 pts)]]></title>
            <link>https://www.tinytpu.com</link>
            <guid>44944592</guid>
            <pubDate>Mon, 18 Aug 2025 19:52:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tinytpu.com">https://www.tinytpu.com</a>, See on <a href="https://news.ycombinator.com/item?id=44944592">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Nobody really understands how TPUs work…and neither do we! So we wanted to make this because we wanted to take a shot and try to guess how it works–from the perspective of complete novices!</p><p>We wanted to do something very challenging to prove to ourselves that we can do anything we put our mind to. The reasoning for why we chose to build a TPU specifically is fairly simple:</p><p>None of us have real professional experience in hardware design, which, in a way, made the TPU even more appealing since we weren't able to estimate exactly how difficult it would be. As we worked on the initial stages of this project, we established a strict design philosophy: ALWAYS TRY THE HACKY WAY. This meant trying out the "dumb" ideas that came to our mind first BEFORE consulting external sources. This philosophy helped us make sure we weren't reverse engineering the TPU, but rather <b>re-inventing it</b>, which helped us derive many of the key mechanisms used in the TPU ourselves.</p><p>We also wanted to treat this project as an exercise to code without relying on AI to write for us, since we felt that our initial instinct recently has been to reach for these AI tools whenever we faced a slight struggle. We wanted to cultivate a certain<!-- --> <b>style of thinking</b> that we could take forward with us and use in any future endeavours to think through difficult problems.<sup><a href="#fn1" id="fn1-ref">[1]</a></sup></p><div><p>A TPU is an application specific chip (ASIC) designed by Google to make inferencing (using) and training ML models faster and more efficient. Whereas a GPU can be used to render frames AND run ML workloads, a TPU can only perform math operations, allowing it to be better at what it's designed for. Naturally, trying to master a single task is much easier and will yield better results than trying to master multiple tasks and the TPU strongly employs this philosophy.</p><div><div><p><i>Quick primer on hardware design:</i></p><p>In hardware, the unit of time we're dealing with is called a clock cycle. This is an arbitrary period of time that we can set, as developers, to meet our requirements. Generally, a single clock cycle can range from 1 picosecond (ps) to 1 nanosecond (ns) and any operations we run will be executed BETWEEN clock cycles.</p></div><figure><p><img alt="Clock cycle diagram" loading="lazy" width="679" height="269" decoding="async" data-nimg="1" src="https://www.tinytpu.com/clock-cycle.svg"></p><figcaption>Clock cycle timing diagram showing how operations are synchronized in hardware</figcaption></figure><p>The language we use to describe hardware is called Verilog. It's a hardware description language that allows us to describe the behaviour of a given hardware module (similar to functions in software), but instead of executing as a program, it synthesizes into boolean logic gates (AND, OR, NOT, etc.) that can be combined to build the digital logic for any chip we want. Here's a simple example of an addition in Verilog:</p><br><pre><code>module add <span>(</span>
    <span>input</span> wire <span>clk</span>,
    <span>// reset signal to reset the module</span>
    <span>input</span> wire <span>rst</span>,

    <span>// registers to hold the <span>input</span> and <span>output</span> values</span>
    <span>input</span> reg a,
    <span>input</span> reg b,
    <span>output</span> reg c
  <span>)</span>;
    
    <span>always</span> @<span>(</span><span>posedge</span> <span>clk</span><span>)</span> <span>begin</span> 

    <span>// everything in this block will be executed every clock cycle</span>
    
      <span>if</span> <span>(</span><span>rst</span><span>)</span> <span>begin</span>
      <span>// reset the <span>output</span> to <span>0</span> when the reset signal is high</span>
        c <span>&lt;=</span> <span>0</span>; 
      <span>end</span> <span>else</span> <span>begin</span>
        <span>// add the two inputs and store the result in the <span>output</span></span>
        c <span>&lt;=</span> a <span>+</span> b; 
      <span>end</span>
    <span>end</span>

endmodule
</code></pre><p>In the example above, the value of the signal b at the next clock cycle is set to the current value of the signal a. You'll find that in most cases, signals (variables) are updated in sequential clock cycles, as opposed to immediate updates like you would find in software design.</p></div><p>Specifically, the TPU is very efficient at performing matrix multiplications, which make up 80-90% of the compute operations in transformers (up to 95% in very large models) and 70-80% in CNNs. Each matrix multiplication represents the calculation for a single layer in an MLP, and in deep learning, we have many of these layers, making TPUs increasingly efficient for larger models.</p></div><div><p>When we started this project, all we knew was that the equation y = mx + b is the foundational building block for neural networks. However, we needed to fully UNDERSTAND the math behind neural networks to build other modules in our TPU. So before we started writing any code, each of us worked out the math of a simple 2 -&gt; 2 -&gt; 1 multi-layer perceptron (MLP).</p><figure><p><img alt="XOR MLP Neural Network Architecture showing 2 input nodes, 2 hidden layer nodes, and 1 output node with weight connections" loading="lazy" width="679" height="269" decoding="async" data-nimg="1" src="https://www.tinytpu.com/xor-mlp.svg"></p><figcaption>Architecture of our 2→2→1 multi-layer perceptron for solving the XOR problem</figcaption></figure><br><h3>Why XOR?</h3><p>The reason we chose this specific network is because we were targeting inference and training for the XOR problem (the "hello world" of neural networks). The XOR problem is one of the simplest problems a neural network can solve. All other gates (AND, OR, etc) can predict the outputs from its inputs using just one linear line (one neuron) to separate which inputs correspond to a 0 and which ones correspond to a 1. But to classify all XOR, an MLP is needed, since it requires curved decision boundaries, which can't be achieved with ONLY linear equations. For a geometric and first-principles treatment, the free book<!-- --> <a href="https://udlbook.github.io/udlbook/" target="_blank" rel="noopener noreferrer">Understanding Deep Learning</a> <!-- -->is excellent.</p><figure><p><img alt="OR and XOR decision boundaries" loading="lazy" width="679" height="269" decoding="async" data-nimg="1" src="https://www.tinytpu.com/or-xor.svg"></p><figcaption>OR and XOR decision boundaries</figcaption></figure><h3>Batching and dimensions</h3><p>Now, say we want to do continuous inference (i.e. self driving car making multiple predictions a second). That would imply that we're sending multiple pieces of data at once. Since data is inherently multidimensional and has many features, we would have matrices with very large dimensions. However, the XOR problem simplifies the dimensions for us, as there are only two features (0 or 1) and 4 possible pieces of input data (four possible binary combinations of 0 and 1). This gives us a 4x2 matrix, where 4 is the number of rows (batch size) and 2 is the number of columns (feature size).</p><div><p>The XOR input matrix and target outputs:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">X</mi><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mn>4</mn><mo>×</mo><mn>2</mn></mrow></msup><mo separator="true">,</mo><mspace width="1em"></mspace><mi mathvariant="bold">y</mi><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mn>4</mn><mo>×</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">
                  \mathbf{X} =
                  \begin{bmatrix}
                  0 &amp; 0 \\[0.3em]
                  0 &amp; 1 \\[0.3em]
                  1 &amp; 0 \\[0.3em]
                  1 &amp; 1
                  \end{bmatrix} \in \mathbb{R}^{4 \times 2}, \quad
                  \mathbf{y} = \begin{bmatrix} 0 \\[0.3em] 1 \\[0.3em] 1 \\[0.3em] 0 \end{bmatrix} \in \mathbb{R}^{4 \times 1}
                </annotation></semantics></math></span></span></span></p></div><p>Each row represents one of the four possible XOR inputs, and the output vector shows the expected XOR results</p></div><p>Another simplification we're making for our systolic array example here is that we'll use a 2x2 instead of the 256x256 array used in the TPUv1. However, the math is still faithful so nothing is actually dumbed down, rather scaled down instead.</p><p>The first step in the equation is multiplying m with x, which, in matrix form, would be<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">X</mi><msup><mi mathvariant="bold">W</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{X}\mathbf{W}^T</annotation></semantics></math></span></span></span>.</p><div><p>More formally:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">Z</mi><mo>=</mo><mi mathvariant="bold">X</mi><msup><mi mathvariant="bold">W</mi><mi>T</mi></msup><mo>+</mo><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">\mathbf{Z} = \mathbf{X}\mathbf{W}^T + \mathbf{b}</annotation></semantics></math></span></span></span></p></div><p>where<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">X</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>n</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{X} \in \mathbb{R}^{n \times d}</annotation></semantics></math></span></span></span> <!-- -->is our input matrix,<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">W</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>m</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{W} \in \mathbb{R}^{m \times d}</annotation></semantics></math></span></span></span> <!-- -->is our weight matrix, and<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">b</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mn>1</mn><mo>×</mo><mi>m</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{b} \in \mathbb{R}^{1 \times m}</annotation></semantics></math></span></span></span> <!-- -->is our bias vector</p></div><p>How can we perform matrix multiplication in hardware? Well, we can use a unit called the systolic array!</p><h3>Systolic array and PEs</h3><p>The heart of a TPU is a unit called the systolic array.<sup><a href="#fn2" id="fn2-ref">[2]</a></sup> <!-- -->It consists of individual building blocks called Processing Elements (PE) which are connected together in a grid-like structure. Each PE performs a multiply-accumulate operation, meaning it multiplies an incoming input X with a stationary weight W<sup><a href="#fn3" id="fn3-ref">[3]</a></sup> <!-- -->and adds it to an incoming accumulated sum, all in the same clock cycle.</p><figure><p><img alt="PE diagram" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/PE.svg"></p><figcaption>Processing Element (PE) architecture showing multiply-accumulate operation (without load weight and start flags)</figcaption></figure><div><pre><code><span>always_ff</span> @<span>(</span><span>posedge</span> <span>clk</span> or <span>posedge</span> <span>rst</span><span>)</span> <span>begin</span>
        <span>if</span> <span>(</span><span>rst</span><span>)</span> <span>begin</span>
            <span>input_out</span> <span>&lt;=</span> <span>0</span>;
            <span>psum_out</span> <span>&lt;=</span> <span>0</span>;
            <span>weight_reg</span> <span>&lt;=</span> <span>0</span>;
        <span>end</span> <span>else</span> <span>if</span> <span>(</span><span>load_weight</span><span>)</span> <span>begin</span>
            <span>weight_reg</span> <span>&lt;=</span> <span>weight</span>;
        <span>end</span> <span>else</span> <span>if</span> <span>(</span><span>start</span><span>)</span> <span>begin</span>
            <span>input_out</span> <span>&lt;=</span> <span>input_in</span>;
            <span>// the main multiply-accumulate operation</span>
            <span>psum_out</span> <span>&lt;=</span> <span>(</span><span>input_in</span> <span>*</span> <span>weight_reg</span><span>)</span> <span>+</span> <span>psum_in</span>;
        <span>end</span>
    <span>end</span></code></pre></div><h3>Systolic matrix multiplication</h3><p>When these PEs are connected together, they can be used to perform matrix multiplication systolically, meaning multiple elements of the output matrix can be calculated every clock cycle. The inputs enter the systolic array from the left and move to the neighbouring PE to the right, every clock cycle. The accumulated sums start with the multiplication output from the first row of PEs, move downwards, and get added to the products of each successive PE, until they up at the last row of PEs where they become an element of the output matrix.</p><figure><p><img alt="Systolic array diagram" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/sys-array-standalone.svg"></p><figcaption>Systolic array architecture showing how PEs are connected to perform matrix multiplication</figcaption></figure><p>Because of this single unit (and the fact that matrix multiplications dominate the computations performed in models), TPUs can very easily inference and train any model.</p><h3>Worked example</h3><p>Now let's walk through the example of our XOR problem:</p><p>Our systolic array takes two inputs: the input matrix and the weight matrix. For our XOR network, we initialize with the following weights and biases:</p><div><p>Layer 1 parameters:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">W</mi><mn>1</mn></msub><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2985</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.5792</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0913</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.4234</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mn>2</mn><mo>×</mo><mn>2</mn></mrow></msup><mo separator="true">,</mo><mspace width="1em"></mspace><msub><mi mathvariant="bold">b</mi><mn>1</mn></msub><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.4939</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.189</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mn>1</mn><mo>×</mo><mn>2</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{W}_1 = \begin{bmatrix} \phantom{-}0.2985 &amp; -0.5792 \\[0.3em] \phantom{-}0.0913 &amp; \phantom{-}0.4234 \end{bmatrix} \in \mathbb{R}^{2 \times 2}, \quad \mathbf{b}_1 = \begin{bmatrix} -0.4939 &amp; \phantom{-}0.189\phantom{0} \end{bmatrix} \in \mathbb{R}^{1 \times 2}</annotation></semantics></math></span></span></span></p></div><p>Layer 2 parameters:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">W</mi><mn>2</mn></msub><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.5266</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2958</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mn>1</mn><mo>×</mo><mn>2</mn></mrow></msup><mo separator="true">,</mo><mspace width="1em"></mspace><msub><mi mathvariant="bold">b</mi><mn>2</mn></msub><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.6358</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mn>1</mn><mo>×</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{W}_2 = \begin{bmatrix} \phantom{-}0.5266 &amp; \phantom{-}0.2958 \end{bmatrix} \in \mathbb{R}^{1 \times 2}, \quad \mathbf{b}_2 = \begin{bmatrix} \phantom{-}0.6358 \end{bmatrix} \in \mathbb{R}^{1 \times 1}</annotation></semantics></math></span></span></span></p></div></div><h3>Input and weight scheduling</h3><p>To input our input batch within the systolic array, we need to:</p><ul><li>Rotate our X matrix by 90 degrees</li><br><figure><p><img alt="Rotate X matrix by 90 degrees" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/rotate.svg"></p><figcaption>Matrix rotation by 90 degrees to prepare for systolic array input</figcaption></figure><br><li>STAGGER the inputs (delay each row by 1 clock cycle)<sup><a href="#fn4" id="fn4-ref">[4]</a></sup></li><figure><p><img alt="Stagger input matrix" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/stagger-x.svg"></p><figcaption>Input matrix staggering pattern for systolic array processing</figcaption></figure><br></ul><p>To input our weight matrix: we need to:</p><ul><li>Stagger the weight matrix (similar to the inputs)</li><figure><p><img alt="Stagger weight matrix" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/stagger-w.svg"></p><figcaption>Weight matrix staggering pattern for systolic array processing</figcaption></figure><li>Transpose it!</li><figure><p><img alt="Matrix transposition" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/transpose.svg"></p><figcaption>Weight matrix transposition for correct mathematical alignment</figcaption></figure></ul><p>Note that the rotating and staggering don't have any mathematical significance — they are simply required to make the systolic array work. The transpoing too is just for mathematical bookkeeping – it's required to make the matrix math work because of how we set up our weight pointers within the neural network drawing.</p><h3>Staggering and FIFOs</h3><p>To perform the staggering, we designed near-identical accumulators for the weights and inputs that would sit above and to the left of the systolic array, respectively.</p><p>Since the activations are fed into the systolic array one-by-one, we thought a first-in-first-out queue (FIFO) would be the optimal data storage option. There was a slight difference between a traditional FIFO and the accumulators we built, however. Our accumulators had 2 input ports — one for writing weights manually to the FIFO and one for writing the previous layer's outputs from the activation modules BACK into the input FIFOs (the previous layer's outputs are inputs for the current layer).</p><p>We also needed to load the weights in a similar fashion for every layer, so we replicated the logic for the weight FIFOs, without the second port.</p><div><h3>Systolic array matrix multiplication</h3><p><span>clk <!-- -->0</span></p></div><h3>Bias and activation</h3><p>The next step in the equation is adding the bias. To do this in hardware, we need to create a bias module under each column of the systolic array. We can see that as the sums move out of the last row within the systolic array, we can immediately stream them into our bias modules to compute our pre-activations.<b> We will denote these values with the variable Z.</b></p><div><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">Z</mi><mtext>biased</mtext></msub><mo>=</mo><mi mathvariant="bold">Z</mi><mo>+</mo><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">\mathbf{Z}_{\text{biased}} = \mathbf{Z} + \mathbf{b}</annotation></semantics></math></span></span></span></p></div><p>The bias vector <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">\mathbf{b}</annotation></semantics></math></span></span></span> is broadcast across all rows of the matrix — meaning it's added to each row of <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">Z</mi></mrow><annotation encoding="application/x-tex">\mathbf{Z}</annotation></semantics></math></span></span></span></p></div><p>Now our equation is starting to look a lot like what we've learned in high school –but just in multidimensional form, where each column that streams out of the systolic array represents its own feature!</p><p>Next we have to apply the activation, for which we chose Leaky ReLU.<sup><a href="#fn5" id="fn5-ref">[5]</a></sup> <!-- -->This is also an element-wise operation, similar to the bias, meaning we need an activation module under every bias module (and by proxy under every column of the systolic array) and we can stream the outputs of our bias modules into the activation modules immediately.<b>We will denote these post-activation values with H</b>.</p><div><p>The Leaky ReLU function applies element-wise:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mtext>LeakyReLU</mtext><mi>α</mi></msub><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.36em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mi>z</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>z</mi><mo>&gt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>α</mi><mo>⋅</mo><mi>z</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>z</mi><mo>≤</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">\text{LeakyReLU}_\alpha(z) = \begin{cases} z &amp; \text{if } z &gt; 0 \\[0.3em] \alpha \cdot z &amp; \text{if } z \leq 0 \end{cases}</annotation></semantics></math></span></span></span></p></div><p>where <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">\alpha = 0.5</annotation></semantics></math></span></span></span> is our leak factor. For matrices, this applies to each element independently.</p></div><div><p>For our XOR example, let's see how Layer 1 processes the data. First, the systolic array computes<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">X</mi><msubsup><mi mathvariant="bold">W</mi><mn>1</mn><mi>T</mi></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{X}\mathbf{W}_1^T</annotation></semantics></math></span></span></span>:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">Z</mi><mn>1</mn></msub><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>0</mn><mphantom><mi mathvariant="normal">.</mi></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>0</mn><mphantom><mi mathvariant="normal">.</mi></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>0</mn><mphantom><mi mathvariant="normal">.</mi></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>1</mn><mphantom><mi mathvariant="normal">.</mi></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>1</mn><mphantom><mi mathvariant="normal">.</mi></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>0</mn><mphantom><mi mathvariant="normal">.</mi></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>1</mn><mphantom><mi mathvariant="normal">.</mi></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>1</mn><mphantom><mi mathvariant="normal">.</mi></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2985</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0913</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.5792</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.4234</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0000</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0000</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.5792</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.4234</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2985</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0913</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.2807</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.5147</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{Z}_1 = \begin{bmatrix} \phantom{.}0\phantom{.} &amp; \phantom{.}0\phantom{.} \\[0.2em] \phantom{.}0\phantom{.} &amp; \phantom{.}1\phantom{.} \\[0.2em] \phantom{.}1\phantom{.} &amp; \phantom{.}0\phantom{.} \\[0.2em] \phantom{.}1\phantom{.} &amp; \phantom{.}1\phantom{.} \end{bmatrix} \begin{bmatrix} \phantom{-}0.2985 &amp; \phantom{-}0.0913 \\[0.2em] -0.5792 &amp; \phantom{-}0.4234 \end{bmatrix} = \begin{bmatrix} \phantom{-}0.0000 &amp; \phantom{-}0.0000 \\[0.2em] -0.5792 &amp; \phantom{-}0.4234 \\[0.2em] \phantom{-}0.2985 &amp; \phantom{-}0.0913 \\[0.2em] -0.2807 &amp; \phantom{-}0.5147 \end{bmatrix}</annotation></semantics></math></span></span></span></p></div><p>Then bias is added:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">Z</mi><mn>1</mn></msub><mo>=</mo><msub><mi mathvariant="bold">Z</mi><mn>1</mn></msub><mo>+</mo><msub><mi mathvariant="bold">b</mi><mn>1</mn></msub><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.4939</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.1890</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1.0731</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.6124</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.1954</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2803</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.7746</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.7037</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{Z}_1 = \mathbf{Z}_1 + \mathbf{b}_1 = \begin{bmatrix} -0.4939 &amp; \phantom{-}0.1890 \\[0.2em] -1.0731 &amp; \phantom{-}0.6124 \\[0.2em] -0.1954 &amp; \phantom{-}0.2803 \\[0.2em] -0.7746 &amp; \phantom{-}0.7037 \end{bmatrix}</annotation></semantics></math></span></span></span></p></div><p>Finally, LeakyReLU is applied element-wise:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">H</mi><mn>1</mn></msub><mo>=</mo><msub><mtext>LeakyReLU</mtext><mn>0.5</mn></msub><mo stretchy="false">(</mo><msub><mi mathvariant="bold">Z</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.2470</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.1890</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.5366</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.6124</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0977</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2803</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.3873</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.7037</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{H}_1 = \text{LeakyReLU}_{0.5}(\mathbf{Z}_1) = \begin{bmatrix} -0.2470 &amp; \phantom{-}0.1890 \\[0.2em] -0.5366 &amp; \phantom{-}0.6124 \\[0.2em] -0.0977 &amp; \phantom{-}0.2803 \\[0.2em] -0.3873 &amp; \phantom{-}0.7037 \end{bmatrix}</annotation></semantics></math></span></span></span></p></div><p>Negative values are multiplied by 0.5, positive values pass through unchanged.</p></div><div><h3>Systolic array with bias and leaky ReLU</h3><p><span>clk <!-- -->0</span></p></div><h3>Pipelining</h3><p>Now you might be asking – why don't we merge the bias term and the activation term in one clock cycle? Well, this is because of something called pipelining! Pipelining allows multiple operations to be executed simultaneously across different stages of the TPU —instead of waiting for one complete operation to finish before starting the next, you break the work into stages that can overlap. Think of it like an assembly line: while one worker (activation module) processes a part, the previous worker (bias module) is already working on the next part. This keeps all of the modules busy rather than having them sit idle waiting for the previous stage to complete. It also affects the speed at which we can run our TPU — if we have one module that tries to squeeze many operations in a single cycle, our clock speed will be bottlenecked by that module, as the other modules can only run as fast as that single module. Therefore, it's efficient and best practice to split up operations into individual clock cycles as much as possible.</p><figure><p><img alt="Pipeline diagram" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/pipelining.svg"></p><figcaption>Pipelining stages showing how operations overlap across clock cycles</figcaption></figure><p>Another mechanism we used to run our chip as efficiently as possible, was a propagating "start" signal, which we called a travelling chip enable (denoted by the purple dot). Because everything in our design was staggered, we realized that we could very elegantly assert a start signal for a single clock cycle at the first accumulator and have it propagate to neighbouring modules exactly when they needed to be turned on.</p><p>This would extend into the systolic array and eventually the bias and activation modules, where neighbouring PEs and modules, moving from the top left to the bottom right, were turned on in consecutive clock cycles. This ensured that every module was only performing computations when it was required to and wasn't wasting power in the background.</p><h3>Double buffering</h3><p>Now, we know that starting a new layer means we must compute the same <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">X</mi><msup><mi mathvariant="bold">W</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{X}\mathbf{W}^T</annotation></semantics></math></span></span></span> using a new weight matrix. How can we do this if our systolic array is weight-stationary? How can we change the weights?</p><p>While thinking about this problem, we came across the idea of double buffering, which originates from video games. The reason why double buffering exists is to prevent something called screen tearing on your monitor. Ultimately, pixels take time to load and we'd like to "hide away" that time somehow. And if you paid attention, this is the exact same problem we're currently facing with the systolic array. Fortunately, video game designers have already come up with a solution for this problem. By adding a second "shadow" buffer, which holds the weights of the next layer while the current layer is being computed on, we can load in new weights during computation, cutting the total clock cycle count in half.</p><p>To make this work, we also needed to add some signals to move the data. First, we needed a signal to indicate when to switch the weights in the shadow buffer and the active buffer. We called this signal the "switch" signal (denoted by the blue dot) and it copied the values in the shadow buffer to the active buffer. It propagated from the top left of the systolic array to the bottom right (the same path as the travelling chip enable, but only within the systolic array). We then needed one more signal to indicate when we wanted to move the weights down by one row and we called this the "accept" flag (denoted by the green dot) because each row is ACCEPTING a new set of weights. This would move the new weights into the top row of the systolic array, as well as each row of weights down into the next row of the systolic array. These two control flags worked in tandem to make our double buffering mechanism work.</p><p>If you haven't already noticed, this allows the systolic array to do something powerful…continuous inference!!! We can continuously stream in new weights and inputs and compute forward pass for as many layers as we want. This touches into a core design philosophy of the systolic array: we want to maximize PE usage. We always want to keep the systolic array fed!</p><div><p>For Layer 2, the outputs from Layer 1 (<span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">H</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{H}_1</annotation></semantics></math></span></span></span>) now become our inputs:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">z</mi><mn>2</mn></msub><mo>=</mo><msub><mi mathvariant="bold">H</mi><mn>1</mn></msub><msubsup><mi mathvariant="bold">W</mi><mn>2</mn><mi>T</mi></msubsup><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.2470</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.1890</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.5366</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.6124</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0977</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2803</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.3873</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.7037</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.5266</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2958</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0741</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.1014</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0315</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0042</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{z}_2 = \mathbf{H}_1\mathbf{W}_2^T = \begin{bmatrix} -0.2470 &amp; \phantom{-}0.1890 \\[0.2em] -0.5366 &amp; \phantom{-}0.6124 \\[0.2em] -0.0977 &amp; \phantom{-}0.2803 \\[0.2em] -0.3873 &amp; \phantom{-}0.7037 \end{bmatrix} \begin{bmatrix} \phantom{-}0.5266 \\[0.2em] \phantom{-}0.2958 \end{bmatrix} = \begin{bmatrix} -0.0741 \\[0.2em] -0.1014 \\[0.2em] \phantom{-}0.0315 \\[0.2em] \phantom{-}0.0042 \end{bmatrix}</annotation></semantics></math></span></span></span></p></div><p>Adding bias and applying activation:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">z</mi><mn>2</mn></msub><mo>=</mo><msub><mi mathvariant="bold">z</mi><mn>2</mn></msub><mo>+</mo><msub><mi mathvariant="bold">b</mi><mn>2</mn></msub><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.5617</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.5344</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.6673</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.6400</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{z}_2 = \mathbf{z}_2 + \mathbf{b}_2 = \begin{bmatrix} \phantom{-}0.5617 \\[0.2em] \phantom{-}0.5344 \\[0.2em] \phantom{-}0.6673 \\[0.2em] \phantom{-}0.6400 \end{bmatrix}</annotation></semantics></math></span></span></span></p></div><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mover accent="true"><mi mathvariant="bold">y</mi><mo>^</mo></mover><mo>=</mo><msub><mi mathvariant="bold">h</mi><mn>2</mn></msub><mo>=</mo><msub><mtext>LeakyReLU</mtext><mn>0.5</mn></msub><mo stretchy="false">(</mo><msub><mi mathvariant="bold">z</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.5617</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.5344</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.6673</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.6400</mn></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{\mathbf{y}} = \mathbf{h}_2 = \text{LeakyReLU}_{0.5}(\mathbf{z}_2) = \begin{bmatrix} \phantom{-}0.5617 \\[0.2em] \phantom{-}0.5344 \\[0.2em] \phantom{-}0.6673 \\[0.2em] \phantom{-}0.6400 \end{bmatrix}</annotation></semantics></math></span></span></span></p></div><p>All values are positive, so they pass through unchanged. These are our final predictions for the XOR problem!</p><div><h3>Forward pass walkthrough (with double buffering)</h3><p><span>clk <!-- -->0</span></p></div></div><h3>Control unit and ISA</h3><p>Our final step for inference was making a control unit to use a custom instruction set (ISA) to assert all of our control flags and load data through a data bus. Including the data bus, our ISA was 24 bits long and it made our testbench more elegant as we could pass a single string of bits every clock cycle, rather than individually setting multiple flags.</p><p>We then put everything together and got inference completely working! This was a big milestone for us and we were very proud about what we had accomplished.</p><h2>Backpropagation and training</h2><div><p>Ok we've solved inference — but what about training? Well here's the beauty: We can use the same architecture we use for inference for training! Why? Because training is just matrix multiplications with a few extra steps.</p><p>Here's where things get really exciting. Let's say we just ran inference on the XOR problem and got a prediction that looks something like [0.8, 0.3, 0.1, 0.9] when we actually wanted [1, 0, 0, 1]. Our model is performing poorly! We need to make it better. This is where training comes in. We're going to use something called a loss function to tell our model exactly how poorly it's doing. For simplicity, we chose Mean Squared Error (MSE) — think of it like measuring the "distance" between what we predicted and what we actually wanted, just like how you might measure how far off target your basketball shot was.<!-- --> <b>Let's denote the loss with L.</b></p><div><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="script">L</mi><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\mathcal{L} = \frac{1}{N}\sum_{i=1}^{N}(y_i - \hat{y}_i)^2</annotation></semantics></math></span></span></span></p></div><p>where <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">y_i</annotation></semantics></math></span></span></span> is the target output,<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\hat{y}_i</annotation></semantics></math></span></span></span> is our prediction, and<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span></span></span> is the number of samples</p></div><div><p>For our XOR example, with predictions<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi mathvariant="bold">y</mi><mo>^</mo></mover><mo>=</mo><mo stretchy="false">[</mo><mn>0.5617</mn><mo separator="true">,</mo><mn>0.5344</mn><mo separator="true">,</mo><mn>0.6673</mn><mo separator="true">,</mo><mn>0.6400</mn><msup><mo stretchy="false">]</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\hat{\mathbf{y}} = [0.5617, 0.5344, 0.6673, 0.6400]^T</annotation></semantics></math></span></span></span> <!-- -->and targets <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">y</mi><mo>=</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>0</mn><msup><mo stretchy="false">]</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{y} = [0, 1, 1, 0]^T</annotation></semantics></math></span></span></span>:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="script">L</mi><mo>=</mo><mfrac><mn>1</mn><mn>4</mn></mfrac><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mn>0</mn><mo>−</mo><mn>0.5617</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mn>0.5344</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mn>0.6673</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>0</mn><mo>−</mo><mn>0.6400</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{L} = \frac{1}{4}[(0 - 0.5617)^2 + (1 - 0.5344)^2 + (1 - 0.6673)^2 + (0 - 0.6400)^2]</annotation></semantics></math></span></span></span></p></div><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="script">L</mi><mo>=</mo><mfrac><mn>1</mn><mn>4</mn></mfrac><mo stretchy="false">[</mo><mn>0.3155</mn><mo>+</mo><mn>0.2168</mn><mo>+</mo><mn>0.1107</mn><mo>+</mo><mn>0.4096</mn><mo stretchy="false">]</mo><mo>=</mo><mn>0.2631</mn></mrow><annotation encoding="application/x-tex">\mathcal{L} = \frac{1}{4}[0.3155 + 0.2168 + 0.1107 + 0.4096] = 0.2631</annotation></semantics></math></span></span></span></p></div><p>This loss value tells us how far off our predictions are from the true XOR outputs.</p></div><p>So right after we finish computing our final layer's activations (let's call them<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">H</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{H}_2</annotation></semantics></math></span></span></span>), we immediately stream them into a loss module to calculate just how bad our predictions are. These loss modules sit right below our activation modules, and we only use them when we've reached our final layer. But here's the key insight: you don't actually need to calculate the loss value itself to train. You just need its derivative. Why? Because that derivative tells us which direction to adjust our weights to make the loss smaller. It's like having a compass that points toward "better performance."</p><h3>The magic of the chain rule</h3><p>This is where calculus enters the picture. To make our model better, we need to figure out how changing each weight affects our loss. The chain rule lets us break this massive calculation into smaller, manageable pieces.</p><div><p>The chain rule for gradients:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">W</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">Z</mi></mrow></mfrac><mo>⋅</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">Z</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">W</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{W}} = \frac{\partial \mathcal{L}}{\partial \mathbf{Z}} \cdot \frac{\partial \mathbf{Z}}{\partial \mathbf{W}}</annotation></semantics></math></span></span></span></p></div><p>This allows us to compute gradients layer by layer, propagating them backwards through the network</p></div><p><img alt="Long chain diagram" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/longchain.svg"></p><p>Let's trace through what happens step by step.</p><ol><li>Calculate<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">H</mi><mn>2</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{H}_2}</annotation></semantics></math></span></span></span> <!-- -->- how much the loss changes with respect to our final activations.</li><br><li>Compute<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">H</mi><mn>2</mn></msub></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{H}_2}{\partial \mathbf{Z}_2}</annotation></semantics></math></span></span></span> <!-- -->by taking the derivative of the activation (leaky ReLU in our case).</li><br><li>Compute<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">W</mi><mn>2</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{Z}_2}{\partial \mathbf{W}_2}</annotation></semantics></math></span></span></span>,<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">H</mi><mn>2</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{Z}_2}{\partial \mathbf{H}_2}</annotation></semantics></math></span></span></span></li></ol></div><p>Since all elements of <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">z</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{z}_2</annotation></semantics></math></span></span></span> are positive, the LeakyReLU gradient is 1:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">b</mi><mn>2</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{Z}_2}{\partial \mathbf{b}_2}</annotation></semantics></math></span></span></span></p></div><h3>The beautiful symmetry of forward and backward pass</h3><p>After drawing out the entire computational graph, we discovered something remarkable: the longest chain in backpropagation closely resembles forward pass! In forward pass, we multiply activation matrices with transposed weight matrices. In backward pass, we multiply gradient matrices with weight matrices (untransposed). It's like looking in a mirror!</p><div><p>Propagating gradients to the hidden layer:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">H</mi><mn>1</mn></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">z</mi><mn>2</mn></msub></mrow></mfrac><msub><mi mathvariant="bold">W</mi><mn>2</mn></msub><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2808</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.2328</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.1664</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.3200</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.5266</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2958</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.1479</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0831</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.1226</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0689</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0876</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0492</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.1685</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0947</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{H}_1} = \frac{\partial \mathcal{L}}{\partial \mathbf{z}_2} \mathbf{W}_2 = \begin{bmatrix} \phantom{-}0.2808\phantom{0} \\[0.5em] -0.2328\phantom{0} \\[0.5em] -0.1664\phantom{0} \\[0.5em] \phantom{-}0.3200\phantom{0} \end{bmatrix} \begin{bmatrix} \phantom{-}0.5266\phantom{0} &amp; \phantom{-}0.2958\phantom{0} \end{bmatrix} = \begin{bmatrix} \phantom{-}0.1479\phantom{0} &amp; \phantom{-}0.0831\phantom{0} \\[0.5em] -0.1226\phantom{0} &amp; -0.0689\phantom{0} \\[0.5em] -0.0876\phantom{0} &amp; -0.0492\phantom{0} \\[0.5em] \phantom{-}0.1685\phantom{0} &amp; \phantom{-}0.0947\phantom{0} \end{bmatrix}</annotation></semantics></math></span></span></span></p></div><p>And through the first layer's activation:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>1</mn></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">H</mi><mn>1</mn></msub></mrow></mfrac><mo>⊙</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mtext>LeakyReLU</mtext><mn>0.5</mn></msub><mo stretchy="false">(</mo><msub><mi mathvariant="bold">Z</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>1</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{Z}_1} = \frac{\partial \mathcal{L}}{\partial \mathbf{H}_1} \odot \frac{\partial \text{LeakyReLU}_{0.5}(\mathbf{Z}_1)}{\partial \mathbf{Z}_1}</annotation></semantics></math></span></span></span></p></div><p>With mixed positive and negative values in<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">Z</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{Z}_1</annotation></semantics></math></span></span></span>, the gradient is:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>1</mn></msub></mrow></mfrac><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.1479</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0831</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.1226</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0689</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0876</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0492</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.1685</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0947</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>⊙</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>0.5</mn><mphantom><mn>.0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>1</mn><mphantom><mi mathvariant="normal">.</mi></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>0.5</mn><mphantom><mn>.0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>1</mn><mphantom><mi mathvariant="normal">.</mi></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>0.5</mn><mphantom><mn>.0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>1</mn><mphantom><mi mathvariant="normal">.</mi></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>0.5</mn><mphantom><mn>.0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mi mathvariant="normal">.</mi></mphantom><mn>1</mn><mphantom><mi mathvariant="normal">.</mi></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0739</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0831</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0613</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0689</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0438</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0492</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0843</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0947</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{Z}_1} = \begin{bmatrix} \phantom{-}0.1479\phantom{0} &amp; \phantom{-}0.0831\phantom{0} \\[0.5em] -0.1226\phantom{0} &amp; -0.0689\phantom{0} \\[0.5em] -0.0876\phantom{0} &amp; -0.0492\phantom{0} \\[0.5em] \phantom{-}0.1685\phantom{0} &amp; \phantom{-}0.0947\phantom{0} \end{bmatrix} \odot \begin{bmatrix} \phantom{.}0.5\phantom{.0} &amp; \phantom{.}1\phantom{.} \\[0.5em] \phantom{.}0.5\phantom{.0} &amp; \phantom{.}1\phantom{.} \\[0.5em] \phantom{.}0.5\phantom{.0} &amp; \phantom{.}1\phantom{.} \\[0.5em] \phantom{.}0.5\phantom{.0} &amp; \phantom{.}1\phantom{.} \end{bmatrix} = \begin{bmatrix} \phantom{-}0.0739\phantom{0} &amp; \phantom{-}0.0831\phantom{0} \\[0.5em] -0.0613\phantom{0} &amp; -0.0689\phantom{0} \\[0.5em] -0.0438\phantom{0} &amp; -0.0492\phantom{0} \\[0.5em] \phantom{-}0.0843\phantom{0} &amp; \phantom{-}0.0947\phantom{0} \end{bmatrix}</annotation></semantics></math></span></span></span></p></div></div><p>Once we have all of these individual derivatives, we can multiply them together to find any derivative with respect of the loss (i.e.<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">H</mi><mn>2</mn></msub></mrow></mfrac><mo>⋅</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">H</mi><mn>2</mn></msub></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub></mrow></mfrac><mo>⋅</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">W</mi><mn>2</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{H}_2} \cdot \frac{\partial \mathbf{H}_2}{\partial \mathbf{Z}_2} \cdot \frac{\partial \mathbf{Z}_2}{\partial \mathbf{W}_2}</annotation></semantics></math></span></span></span> <!-- -->gives us<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">W</mi><mn>2</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{W}_2}</annotation></semantics></math></span></span></span>).</p><p>After that, we have to compute the activation derivative<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">H</mi><mn>2</mn></msub></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{H}_2}{\partial \mathbf{Z}_2}</annotation></semantics></math></span></span></span>, for which the formula is<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mtext>LeakyReLU</mtext><mi>α</mi></msub><mo stretchy="false">(</mo><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub></mrow></mfrac><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.36em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub><mo>&gt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mi>α</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub><mo>≤</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">\frac{\partial \text{LeakyReLU}_{\alpha}(\mathbf{Z}_2)}{\partial \mathbf{Z}_2} = \begin{cases} 1 &amp; \text{if } \mathbf{Z}_2 &gt; 0 \\[0.3em] \alpha &amp; \text{if } \mathbf{Z}_2 \leq 0 \end{cases}</annotation></semantics></math></span></span></span>. This is also an element-wise computation, meaning we can structure it exactly like the loss module (and bias and activation modules), but it will perform a different calculation. One important note about this module, however, is that it requires the activations we computed during forward pass.</p><p>Now you might be wondering — how do we actually compute derivatives in hardware? Let's look at Leaky ReLU as an example, since it's beautifully simple but demonstrates the key principles. Remember that Leaky ReLU applies different operations based on whether the input is positive or negative. The derivative follows the same pattern: it outputs 1 for positive inputs and a small constant (we used 0.01) for negative inputs.</p><div><p>The Leaky ReLU gradient:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mtext>LeakyReLU</mtext><mi>α</mi></msub><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo></mrow><mrow><mi mathvariant="normal">∂</mi><mi>z</mi></mrow></mfrac><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.36em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>z</mi><mo>&gt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mi>α</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>z</mi><mo>≤</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">\frac{\partial \text{LeakyReLU}_\alpha(z)}{\partial z} = \begin{cases} 1 &amp; \text{if } z &gt; 0 \\[0.3em] \alpha &amp; \text{if } z \leq 0 \end{cases}</annotation></semantics></math></span></span></span></p></div></div><pre><code><span>always</span> @<span>(</span><span>posedge</span> <span>clk</span><span>)</span> <span>begin</span>
    <span>if</span> <span>(</span><span>rst</span><span>)</span> <span>begin</span>
        <span>output</span> <span>&lt;=</span> <span>0</span>;
    <span>end</span> <span>else</span> <span>begin</span>
        <span>output</span> <span>&lt;=</span> <span>(</span><span>input</span> <span>&gt;</span> <span>0</span><span>)</span> <span>?</span> <span>input</span> <span>:</span> <span>0</span>.01 <span>*</span> <span>input</span>;
    <span>end</span>
<span>end</span>
</code></pre><figure><p><img alt="Leaky ReLU derivative" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/leaky-relu-derivative.svg"></p><figcaption>Leaky ReLU derivative implementation in hardware showing the conditional logic</figcaption></figure><p>What's beautiful about this is that it's just a simple comparison – no complex arithmetic needed. The hardware can compute this derivative in a single clock cycle, keeping our pipeline flowing smoothly. This same principle applies to other activation functions: their derivatives often simplify to basic operations that hardware can execute very efficiently. This insight led us to compute the long chain first — getting all our<span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mi>n</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{Z}_n}</annotation></semantics></math></span></span></span> <!-- -->gradients just like we computed activations in forward pass. We could cache these gradients and reuse them, following the same efficient pattern we'd already mastered.</p><div><p>You'll notice a really cool pattern emerging: all these modules that sit underneath the systolic array process column vectors that stream out one by one. This gave us the idea to unify them into something we called a <b>vector processing unit (VPU)</b> – because that's exactly what they're doing, processing vectors element-wise!<sup><a href="#fn6" id="fn6-ref">[6]</a></sup></p><p>Not only is this more elegant to work with, it's also useful when we scale our TPU beyond a 2x2 systolic array, as we'll have N number of these modules (N being the size of the systolic array), each of which we would have to interface with individually. Unifying these modules under a parent module makes our design more scalable and elegant!</p></div><figure><p><img alt="Vector processing unit" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/vpu.svg"></p><figcaption>Vector Processing Unit (VPU) architecture showing unified element-wise operations</figcaption></figure><p>Additionally, by incorporating control signals for each module, which we call the VPU pathway bits, we can selectively enable or skip specific operations. This makes the VPU flexible enough to support both inference and training. For instance, during the forward pass, we want to apply biases and activations but skip computing loss or activation derivatives. When transitioning to the backward pass, all modules are engaged, but within the backward chain we only need to compute the activation derivative. Due to pipelining, all values that flow through the VPU pass through each of the four modules, and any unused modules simply act as registers, forwarding their inputs to outputs without performing computation.</p><p>The next few derivatives are interesting because we can actually use matrix multiplication (and the systolic array!) to compute the derivatives with the help of these three identities:</p><ol><li>If we have<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">Z</mi><mo>=</mo><mi mathvariant="bold">X</mi><msup><mi mathvariant="bold">W</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{Z} = \mathbf{X}\mathbf{W}^T</annotation></semantics></math></span></span></span> and take its derivative with respect to the weights, we get<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">Z</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">W</mi></mrow></mfrac><mo>=</mo><mi mathvariant="bold">X</mi></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{Z}}{\partial \mathbf{W}} = \mathbf{X}</annotation></semantics></math></span></span></span></li><li>If we have<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">Z</mi><mo>=</mo><mi mathvariant="bold">X</mi><msup><mi mathvariant="bold">W</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{Z} = \mathbf{X}\mathbf{W}^T</annotation></semantics></math></span></span></span> and take its derivative with respect to the inputs<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">X</mi></mrow><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math></span></span></span>, we get<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">Z</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">X</mi></mrow></mfrac><mo>=</mo><msup><mi mathvariant="bold">W</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{Z}}{\partial \mathbf{X}} = \mathbf{W}^T</annotation></semantics></math></span></span></span> <!-- -->(just the weight matrix transposed)</li><li>For the bias term, the derivative is simply 1.</li></ol><p>This means that we can multiply the previous<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">H</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">Z</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{H}}{\partial \mathbf{Z}}</annotation></semantics></math></span></span></span> <!-- -->with <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">X</mi></mrow><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math></span></span></span>,<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="bold">W</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{W}^T</annotation></semantics></math></span></span></span>, and 1 to get<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">H</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">W</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{H}}{\partial \mathbf{W}}</annotation></semantics></math></span></span></span>,<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">H</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">X</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{H}}{\partial \mathbf{X}}</annotation></semantics></math></span></span></span>, and<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">H</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">b</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{H}}{\partial \mathbf{b}}</annotation></semantics></math></span></span></span>, respectively, and we can multiply all of these by<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">H</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{H}}</annotation></semantics></math></span></span></span> <!-- -->to get the gradients of the loss with respect to all of our second layer parameters. And because all of the gradients are actually gradient matrices, we can use the systolic array!</p><p>Now something to note about the activation derivative<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">H</mi><mn>2</mn></msub></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{H}_2}{\partial \mathbf{Z}_2}</annotation></semantics></math></span></span></span> <!-- -->and the weight derivative<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">Z</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">W</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{Z}}{\partial \mathbf{W}}</annotation></semantics></math></span></span></span> <!-- -->is that they both require the post-activations (H) we calculate during forward pass. This means we need to store the outputs of every layer in some form of memory to be able to perform training. Here's where we created a new scratchpad memory module<sup><a href="#fn7" id="fn7-ref">[7]</a></sup> <!-- -->which we called the unified buffer (UB).<sup><a href="#fn8" id="fn8-ref">[8]</a></sup> <!-- -->This lets us store our H values immediately after we compute them during forward pass.</p><p>We realized that we can also get rid of the input and weight accumulators, as well as manually loading the bias and leak factors into their respective modules, by using the UB to store them. This is also better practice, rather than loading in new data every clock cycle with the instruction set. Since we want to access two values (2 inputs or 2 weights for each row/col of the systolic array) at the same time, we added TWO read and write ports. We did this for each data primitive (inputs, weights, bias, leak factor, post activations) to minimize data contention since we have many different types of data.</p><p>To read values, we supply a starting address and the number of values, we supply a starting address and the number of locations we want the UB to read and it will read 2 values every clock cycle. Writing is a similar mechanism, where we specify which values we want to write to each of the two input ports. The beauty in the read mechanism is that it runs in the background once we supply a starting address until the number of locations given are read, meaning we only need to provide an instruction for this every few clock cycles.</p><figure><p><img alt="Unified Buffer diagram" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/ub-diagram.svg"></p><figcaption>Unified Buffer (UB) architecture showing dual-port read mechanism</figcaption></figure><figure><p><img alt="Unified Buffer waveform" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/ub-waveform.svg"></p><figcaption>Unified Buffer timing waveform showing read operation</figcaption></figure><p>At the end of the day, not having these mechanisms wouldn't break the TPU — but they allow us to always keep the systolic array fed, which is a core design principle we couldn't compromise.</p><p>While we were working on this, we realized we could make one last small optimization for the activation derivative module — since we only use the <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">H</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{H}_2</annotation></semantics></math></span></span></span> values once (for computing<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">H</mi><mn>2</mn></msub></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>2</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathbf{H}_2}{\partial \mathbf{Z}_2}</annotation></semantics></math></span></span></span>), we created a tiny cache within the VPU instead of storing them in the UB. The rest of the <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">H</mi></mrow><annotation encoding="application/x-tex">\mathbf{H}</annotation></semantics></math></span></span></span> values will be stored in the UB because they're needed to compute multiple derivatives.</p><figure><p><img alt="H-cache diagram" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/h-cache.svg"></p><figcaption>H-cache optimization for storing temporary activation values</figcaption></figure><p>This is what the new TPU architecture, modified to perform training, looks like:</p><figure><p><img alt="Complete TPU architecture" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/tpu.svg"></p><figcaption>Complete TPU architecture showing all components for both inference and training</figcaption></figure><p>Now we can do backpropagation!</p><p>Going back to the computational graph, we discovered something remarkable: the longest chain in backpropagation closely resembles forward pass! In forward pass, we multiply activation matrices with transposed weight matrices. In backward pass, we multiply gradient matrices with weight matrices (untransposed). It's like looking in a mirror!</p><figure><p><img alt="Forward pass diagram" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/forward-pass.svg"></p><figcaption>Forward pass computation flow showing matrix operations</figcaption></figure><p>This insight led us to compute the long chain of the computational graph first (highlighted in yellow) – getting all our<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mi>n</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{Z}_n}</annotation></semantics></math></span></span></span> <!-- -->gradients just like we computed activations in forward pass. We could cache these gradients and reuse them, following the same efficient pattern we'd already mastered.</p><p>We create a loop where we:</p><ol><li>Fetch a bridge node (<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mi>n</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{Z}_n}</annotation></semantics></math></span></span></span>) from our unified buffer</li><li>Fetch the corresponding <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">H</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{H}_n</annotation></semantics></math></span></span></span> <!-- -->matrix, also from unified buffer</li><li>Stream these through our systolic array to compute the weight gradients</li></ol><div><h3>Backward pass through second hidden layer</h3><p><span>clk <!-- -->0</span></p></div><p>And here's where something really magical happens: we can stream these weight gradients directly into a gradient descent module while we're still computing them! This module takes the current weights stored in memory and updates them using the gradients.</p><div><p>The gradient descent update rule:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold-italic">θ</mi><mtext>new</mtext></msub><mo>=</mo><msub><mi mathvariant="bold-italic">θ</mi><mtext>old</mtext></msub><mo>−</mo><mi>α</mi><msub><mi mathvariant="normal">∇</mi><mi mathvariant="bold-italic">θ</mi></msub><mi mathvariant="script">L</mi></mrow><annotation encoding="application/x-tex">\bm{\theta}_{\text{new}} = \bm{\theta}_{\text{old}} - \alpha \nabla_{\bm{\theta}} \mathcal{L}</annotation></semantics></math></span></span></span></p></div><p>where <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span></span></span> is the learning rate and<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold-italic">θ</mi></mrow><annotation encoding="application/x-tex">\bm{\theta}</annotation></semantics></math></span></span></span> represents any parameter (weights or biases)</p></div><div><p>Computing weight gradients for our XOR network:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">W</mi><mn>2</mn></msub></mrow></mfrac><mo>=</mo><msup><mrow><mo fence="true">(</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">z</mi><mn>2</mn></msub></mrow></mfrac><mo fence="true">)</mo></mrow><mi>T</mi></msup><msub><mi mathvariant="bold">H</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{W}_2} = \left(\frac{\partial \mathcal{L}}{\partial \mathbf{z}_2}\right)^T \mathbf{H}_1</annotation></semantics></math></span></span></span></p></div><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2808</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.2328</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.1664</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.3200</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.2470</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.1890</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.5366</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.6124</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0977</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2803</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.3873</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.7037</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0521</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0891</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">= \begin{bmatrix} \phantom{-}0.2808\phantom{0} &amp; -0.2328\phantom{0} &amp; -0.1664\phantom{0} &amp; \phantom{-}0.3200\phantom{0} \end{bmatrix} \begin{bmatrix} -0.2470\phantom{0} &amp; \phantom{-}0.1890\phantom{0} \\[0.5em] -0.5366\phantom{0} &amp; \phantom{-}0.6124\phantom{0} \\[0.5em] -0.0977\phantom{0} &amp; \phantom{-}0.2803\phantom{0} \\[0.5em] -0.3873\phantom{0} &amp; \phantom{-}0.7037\phantom{0} \end{bmatrix} = \begin{bmatrix} -0.0521\phantom{0} &amp; \phantom{-}0.0891\phantom{0} \end{bmatrix}</annotation></semantics></math></span></span></span></p></div><p>Similarly for Layer 1:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">W</mi><mn>1</mn></msub></mrow></mfrac><mo>=</mo><msup><mrow><mo fence="true">(</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mn>1</mn></msub></mrow></mfrac><mo fence="true">)</mo></mrow><mi>T</mi></msup><mi mathvariant="bold">X</mi><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0531</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0920</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0138</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0404</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{W}_1} = \left(\frac{\partial \mathcal{L}}{\partial \mathbf{Z}_1}\right)^T \mathbf{X} = \begin{bmatrix} \phantom{-}0.0531\phantom{0} &amp; \phantom{-}0.0920\phantom{0} \\[0.5em] \phantom{-}0.0138\phantom{0} &amp; -0.0404\phantom{0} \end{bmatrix}</annotation></semantics></math></span></span></span></p></div><p>Bias gradients (sum over samples):</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">b</mi><mn>2</mn></msub></mrow></mfrac><mo>=</mo><mn>0.2017</mn><mo separator="true">,</mo><mspace width="1em"></mspace><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">b</mi><mn>1</mn></msub></mrow></mfrac><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0531</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0138</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{b}_2} = 0.2017, \quad \frac{\partial \mathcal{L}}{\partial \mathbf{b}_1} = \begin{bmatrix} \phantom{-}0.0531\phantom{0} \\[0.5em] \phantom{-}0.0138\phantom{0} \end{bmatrix}</annotation></semantics></math></span></span></span></p></div><p>Applying gradient descent with learning rate<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.75</mn></mrow><annotation encoding="application/x-tex">\alpha = 0.75</annotation></semantics></math></span></span></span>:</p><div><p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi mathvariant="bold">W</mi><mn>2</mn><mtext>new</mtext></msubsup><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.5266</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2958</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>−</mo><mn>0.75</mn><mo>⋅</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>0.0521</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.0891</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.5657</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mphantom><mo>−</mo></mphantom><mn>0.2290</mn><mphantom><mn>0</mn></mphantom></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{W}_2^{\text{new}} = \begin{bmatrix} \phantom{-}0.5266\phantom{0} &amp; \phantom{-}0.2958\phantom{0} \end{bmatrix} - 0.75 \cdot \begin{bmatrix} -0.0521\phantom{0} &amp; \phantom{-}0.0891\phantom{0} \end{bmatrix} = \begin{bmatrix} \phantom{-}0.5657\phantom{0} &amp; \phantom{-}0.2290\phantom{0} \end{bmatrix}</annotation></semantics></math></span></span></span></p></div></div><p>No waiting around — everything flows like water through our pipeline.</p><p>You might be wondering: "We've used our matrix multiplication identities for the long chain and weight gradients — how do we calculate bias gradients?" Well, we've actually already done most of the work! Since we're processing batches of data, we can simply sum (the technical term is "reduce") the<!-- --> <span data-testid="react-katex"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="script">L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="bold">Z</mi><mi>n</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial \mathcal{L}}{\partial \mathbf{Z}_n}</annotation></semantics></math></span></span></span> <!-- -->gradients across the batch dimension. The beauty is that we can do this reduction right when we're computing the long chain — no extra work required!</p><p>With all these new changes and control flags, our instruction is significantly longer — 94 bits in fact! But we can confirm that every single one of these bits is needed and we ensured that we couldn't make the instruction set any smaller without compromising the speed and efficiency of the TPU.</p><figure><div><p><img alt="Instruction Set Architecture diagram" loading="lazy" decoding="async" data-nimg="fill" src="https://www.tinytpu.com/isa.svg"></p></div><figcaption>94-bit Instruction Set Architecture (ISA) layout showing control flags and data fields</figcaption></figure><h3>Putting it all together</h3><p>By continuing this same process iteratively – forward pass, backward pass, weight updates – we can train our network until it performs exactly how we want. The same systolic array that powered our inference now powers our training, with just a few additional modules to handle the gradient computations.</p><p>What started as a simple idea about matrix multiplication has grown into a complete training system. Every component works together in harmony: data flows through pipelines, modules operate in parallel, and our systolic array stays fed with useful work.</p><figure><p><img alt="Final waveform simulation results" loading="lazy" decoding="async" data-nimg="fill" sizes="100vw" srcset="https://www.tinytpu.com/_next/image?url=%2Ffinal-waveform.png&amp;w=640&amp;q=75 640w, https://www.tinytpu.com/_next/image?url=%2Ffinal-waveform.png&amp;w=750&amp;q=75 750w, https://www.tinytpu.com/_next/image?url=%2Ffinal-waveform.png&amp;w=828&amp;q=75 828w, https://www.tinytpu.com/_next/image?url=%2Ffinal-waveform.png&amp;w=1080&amp;q=75 1080w, https://www.tinytpu.com/_next/image?url=%2Ffinal-waveform.png&amp;w=1200&amp;q=75 1200w, https://www.tinytpu.com/_next/image?url=%2Ffinal-waveform.png&amp;w=1920&amp;q=75 1920w, https://www.tinytpu.com/_next/image?url=%2Ffinal-waveform.png&amp;w=2048&amp;q=75 2048w, https://www.tinytpu.com/_next/image?url=%2Ffinal-waveform.png&amp;w=3840&amp;q=75 3840w" src="https://www.tinytpu.com/_next/image?url=%2Ffinal-waveform.png&amp;w=3840&amp;q=75"></p><figcaption>Final waveform simulation in GTKWave showing the weight and bias updates in memory after one epoch!</figcaption></figure></div><p id="fn2">[2] Fun fact: the name of the systolic array is actually inspired by the human heart — just as systolic blood pressure is created by coordinated heart contractions that push blood through the cardiovascular system in waves, a systolic array processes data through coordinated computational "beats" that push information through the processing elements in waves.<!-- --> <a href="#fn2-ref">↩ back</a></p><p id="fn3">[3] This is a weight-stationary systolic array, which means the weights for each layer are stationary within their respective PEs and don't move around. However, there is a non-weight-stationary systolic array where the weights move along with the inputs, which has its own advantages and disadvantages.<!-- --> <a href="#fn3-ref">↩ back</a></p><p id="fn4">[4] Many illustrations online that depict staggering are actually flat out wrong because they pad consecutive rows with zeros, insetad of delaying them by a clock cycle. While this still gets the correct output, it wastes memory because we would have to store additional zeros that we don't use.<!-- --> <a href="#fn4-ref">↩ back</a></p><p id="fn5">[5] We chose Leaky ReLU over ReLU because we found that since we have a very small network, the model wasn't training properly when we used ReLU — it needed more non-linearity.<!-- --> <a href="#fn5-ref">↩ back</a></p><p id="fn7">[7] A scratchpad memory is a large bank of registers (each of which can store individual values) that lets us access any register we want. A FIFO for example is NOT a scratchpad memory since you can only access the first element in the queue.<!-- --> <a href="#fn7-ref">↩ back</a></p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[T-Mobile claimed selling location data without consent is legal–judges disagree (344 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2025/08/t-mobile-claimed-selling-location-data-without-consent-is-legal-judges-disagree/</link>
            <guid>44944291</guid>
            <pubDate>Mon, 18 Aug 2025 19:25:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2025/08/t-mobile-claimed-selling-location-data-without-consent-is-legal-judges-disagree/">https://arstechnica.com/tech-policy/2025/08/t-mobile-claimed-selling-location-data-without-consent-is-legal-judges-disagree/</a>, See on <a href="https://news.ycombinator.com/item?id=44944291">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
            <article data-id="2112551">
  
  <header>
  <div>
    <div>
      

      

      <p>
        T-Mobile can't overturn $92 million fine; AT&amp;T and Verizon verdicts still to come.
      </p>

      
    </div>

    <div>
    
    <p><span>
          Credit:

          
          Aurich Lawson | Getty Images

                  </span>
          </p>
  </div>
  </div>
</header>


  

  
      
    
    <div>
                      
                      
          
<p>A federal appeals court rejected T-Mobile's attempt to overturn $92 million in fines for selling customer location information to third-party firms.</p>
<p>The Federal Communications Commission last year <a href="https://arstechnica.com/tech-policy/2024/04/fcc-fines-big-three-carriers-196m-for-selling-users-real-time-location-data/">fined T-Mobile, AT&amp;T, and Verizon</a>, saying the carriers illegally shared access to customers' location information without consent and did not take reasonable measures to protect that sensitive data against unauthorized disclosure. The fines relate to sharing of real-time location data that was <a href="https://arstechnica.com/tech-policy/2018/06/verizon-and-att-will-stop-selling-your-phones-location-to-data-brokers/">revealed in 2018</a>, but it took years for the FCC to finalize the penalties.</p>
<p>The three carriers appealed the rulings in three different courts, and the first major decision was handed down Friday. A three-judge panel at the US Court of Appeals for the District of Columbia Circuit <a href="https://media.cadc.uscourts.gov/opinions/docs/2025/08/24-1224-2130255.pdf">ruled unanimously</a> against T-Mobile and its subsidiary Sprint.</p>
<p>"Every cell phone is a tracking device," the ruling begins. "To receive service, a cell phone must periodically connect with the nearest tower in a wireless carrier's network. Each time it does, it sends the carrier a record of the phone's location and, by extension, the location of the customer who owns it. Over time, this information becomes an exhaustive history of a customer's whereabouts and '<a href="https://www.supremecourt.gov/opinions/17pdf/16-402_h315.pdf">provides an intimate window into [that] person's life</a>.'"</p>
<p>Until 2019, T-Mobile and Sprint sold customer location information (CLI) to location information aggregators LocationSmart and Zumigo. The carriers did not verify whether buyers obtained customer consent, the ruling said. "Several bad actors abused Sprint and T-Mobile's programs to illicitly access CLI without the customers' knowledge, let alone consent. And even after Sprint and T-Mobile became aware of those abuses, they continued to sell CLI for some time without adopting new safeguards," judges wrote.</p>

          
                      
                  </div>
                    
        
          
    
    <div>
          
          
<h2>Carriers claimed selling data didn’t violate law</h2>
<p>Instead of denying the allegations, the carriers argued that the FCC overstepped its authority. But the appeals court panel decided that the FCC acted properly:</p>
<blockquote><p>Sprint and T-Mobile (collectively, "the Carriers") now petition for our review. Neither denies what happened. Instead, they argue that the undisputed facts do not amount to a violation of the law. The Carriers also argue that the Commission misinterpreted the Communications Act, miscalculated the penalties, and violated the Seventh Amendment by not affording them a jury trial. Because the Carriers' arguments lack merit, we deny the petitions for review.</p></blockquote>
<p>The FCC fines included $80.1 million for T-Mobile and $12.2 million for Sprint. T-Mobile, which bought Sprint in 2020, reported service revenue of $17.4 billion and net income of $3.2 billion in the <a href="https://s29.q4cdn.com/310188824/files/doc_financials/2025/q2/Q2-2025-Earnings-Release-vFinal.pdf">most recent quarter</a>.</p>
<p>Although the FCC first <a href="https://arstechnica.com/tech-policy/2020/02/fcc-issues-wrist-slap-fines-to-carriers-that-sold-your-phone-location-data/">proposed the fines</a> in 2020, under Republican Chairman Ajit Pai, the 2024 vote to finalize the penalties was 3-2, with dissents from Republicans Brendan Carr and Nathan Simington. Carr is now chairman of the FCC.</p>
<p>T-Mobile told Ars today that it is "currently reviewing the court's action" but did not provide further comment. The carrier could seek an <em>en banc</em> review in front of all the appeals court's justices, or ask the Supreme Court to review the case. Meanwhile, AT&amp;T is challenging its fine in the 5th Circuit appeals court while Verizon is challenging in the 2nd Circuit.</p>
<p>AT&amp;T and Verizon were fined $57.3 million and $46.9 million, respectively. The FCC last year said the major carriers disclosed customer location information "without customer consent or other legal authorization to a Missouri Sheriff through a 'location-finding service' operated by Securus, a provider of communications services to correctional facilities, to track the location of numerous individuals."</p>

          
                  </div>
                    
        
          
    
    <div>
          
          

<h2>Carriers gave up right to jury trial, court rules</h2>
<p>AT&amp;T and Verizon <a href="https://arstechnica.com/tech-policy/2024/11/verizon-att-tell-courts-fcc-cant-punish-us-for-selling-user-location-data/">made similar arguments</a> about their right to a jury trial and cited the Supreme Court's June 2024 <a href="https://www.supremecourt.gov/opinions/23pdf/22-859_1924.pdf">ruling</a> in <em>Securities and Exchange Commission v. Jarkesy</em>. That ruling held that "when the SEC seeks civil penalties against a defendant for securities fraud, the Seventh Amendment entitles the defendant to a jury trial."</p>
<p>In the ruling against T-Mobile, the DC Circuit panel held that the carriers gave up any potential right to a jury trial when they "chose to pay their fines and to seek direct review in this court... The Carriers may not now complain that they were denied a right they voluntarily surrendered."</p>
<p>The carriers could have obtained a jury trial if they simply failed to pay the fines and waited to be served with a complaint, the ruling said. "Even if the Seventh Amendment applies, it was not violated because the Carriers had the opportunity to put their case before a jury," judges wrote.</p>
<p>The carriers <a href="https://storage.courtlistener.com/recap/gov.uscourts.cadc.41085/gov.uscourts.cadc.41085.01208711724.0.pdf">argued</a> that they didn't really have a right to a jury trial because the FCC orders "are final agency actions with real-world effects; indeed, the FCC acknowledges that it may use its untested factual findings in license-renewal decisions and penalty calculations."</p>
<p>The carriers argued that in some jurisdictions where the government could bring a collection action, "the Companies would not have the right to raise factual and legal challenges to the Orders. The possibility of a government-initiated collection action therefore does not satisfy the Seventh Amendment and Article III."</p>
<p>The appeals court panel responded that "this court has not adopted the rule that troubles" the carriers. If "the government brought an enforcement action in a jurisdiction with the unfavorable rule, the Carriers could have raised as-applied challenges in those proceedings. But we cannot 'invalidate legislation on the basis of... hypothetical... situations not before' us," judges wrote.</p>

          
                  </div>
                    
        
          
    
    <div>

        
        <div>
          
          
<h2>Carriers quibbled over definition of sensitive data</h2>
<p>The carriers also argued that the device-location information, which is "passively generated when a mobile device pings cell towers to support both voice and data services," does not qualify as Customer Proprietary Network Information (CPNI) under the law. The carriers said the law "covers information relating to the 'location... of use' of a telecommunications service," and claimed that only call location information fits that description.</p>
<p>Judges faulted T-Mobile and Sprint for relying on "strained interpretations" of the statute. "We begin with the text. The Communications Act refers to the 'location... of a telecommunications service, not the location of a voice call... Recall that cell phones connect periodically to cell towers, and that is what enables the devices to send and receive calls at any moment," the ruling said.</p>
<p>In the judges' view, "a customer 'uses' a telecommunications service whenever his or her device connects to the carrier's network for the purpose of being able to send and receive calls. And the Carriers' reading therefore does not narrow 'location... of use' to times when the customer is actively on a voice call."</p>
<p>Judges also weren't persuaded by the argument that the fines were too large. "The Carriers note that the Commission previously had imposed such large fines only in cases involving fraud or intentional efforts to mislead consumers, and they are guilty of neither form of misconduct," the ruling said. "The Commission reasonably explained, however, that the Carriers' conduct was 'egregious': Even after the Securus breach exposed Sprint and T-Mobile's safeguards as inadequate, both carriers continued to sell access to CLI under a broken system."</p>


          
                  </div>

                  
          






  <div>
  <div>
          <p><a href="https://arstechnica.com/author/jon-brodkin/"><img src="https://cdn.arstechnica.net/wp-content/uploads/2016/05/j.brodkin-11_2.jpg" alt="Photo of Jon Brodkin"></a></p>
  </div>

  <div>
    

    <p>
      Jon is a Senior IT Reporter for Ars Technica. He covers the telecom industry, Federal Communications Commission rulemakings, broadband consumer affairs, court cases, and government regulation of the tech industry.
    </p>
  </div>
</div>


  <p>
    <a href="https://arstechnica.com/tech-policy/2025/08/t-mobile-claimed-selling-location-data-without-consent-is-legal-judges-disagree/#comments" title="35 comments">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 80 80"><defs><clipPath id="bubble-zero_svg__a"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath><clipPath id="bubble-zero_svg__b"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath></defs><g clip-path="url(#bubble-zero_svg__a)"><g fill="currentColor" clip-path="url(#bubble-zero_svg__b)"><path d="M80 40c0 22.09-17.91 40-40 40S0 62.09 0 40 17.91 0 40 0s40 17.91 40 40"></path><path d="M40 40 .59 76.58C-.67 77.84.22 80 2.01 80H40z"></path></g></g></svg>
    35 Comments
  </a>
      </p>
              </div>
  </article>


  


  


  <div>
    <header>
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 26"><defs><clipPath id="most-read_svg__a"><path fill="none" d="M0 0h40v26H0z"></path></clipPath><clipPath id="most-read_svg__b"><path fill="none" d="M0 0h40v26H0z"></path></clipPath></defs><g clip-path="url(#most-read_svg__a)"><g fill="none" clip-path="url(#most-read_svg__b)"><path fill="currentColor" d="M20 2h.8q1.5 0 3 .6c.6.2 1.1.4 1.7.6 1.3.5 2.6 1.3 3.9 2.1.6.4 1.2.8 1.8 1.3 2.9 2.3 5.1 4.9 6.3 6.4-1.1 1.5-3.4 4-6.3 6.4-.6.5-1.2.9-1.8 1.3q-1.95 1.35-3.9 2.1c-.6.2-1.1.4-1.7.6q-1.5.45-3 .6h-1.6q-1.5 0-3-.6c-.6-.2-1.1-.4-1.7-.6-1.3-.5-2.6-1.3-3.9-2.1-.6-.4-1.2-.8-1.8-1.3-2.9-2.3-5.1-4.9-6.3-6.4 1.1-1.5 3.4-4 6.3-6.4.6-.5 1.2-.9 1.8-1.3q1.95-1.35 3.9-2.1c.6-.2 1.1-.4 1.7-.6q1.5-.45 3-.6zm0-2h-1c-1.2 0-2.3.3-3.4.6-.6.2-1.3.4-1.9.7-1.5.6-2.9 1.4-4.3 2.3-.7.5-1.3.9-1.9 1.4C2.9 8.7 0 13 0 13s2.9 4.3 7.5 7.9c.6.5 1.3 1 1.9 1.4 1.3.9 2.7 1.7 4.3 2.3.6.3 1.3.5 1.9.7 1.1.3 2.3.6 3.4.6h2c1.2 0 2.3-.3 3.4-.6.6-.2 1.3-.4 1.9-.7 1.5-.6 2.9-1.4 4.3-2.3.7-.5 1.3-.9 1.9-1.4C37.1 17.3 40 13 40 13s-2.9-4.3-7.5-7.9c-.6-.5-1.3-1-1.9-1.4-1.3-.9-2.8-1.7-4.3-2.3-.6-.3-1.3-.5-1.9-.7C23.3.4 22.1.1 21 .1h-1"></path><path fill="#ff4e00" d="M20 5c-4.4 0-8 3.6-8 8s3.6 8 8 8 8-3.6 8-8-3.6-8-8-8m0 11c-1.7 0-3-1.3-3-3s1.3-3 3-3 3 1.3 3 3-1.3 3-3 3"></path></g></g></svg>
      
    </header>
    <ol>
              <li>
                      <a href="https://arstechnica.com/gadgets/2025/08/ars-technica-system-guide-back-to-pc-building-for-back-to-school/">
              <img src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/IMG_2568-768x432.jpeg" alt="Listing image for first story in Most Read: Ars Technica System Guide: Five sample PC builds, from $500 to $5,000" decoding="async" loading="lazy">
            </a>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                  </ol>
</div>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: We started building an AI dev tool but it turned into a Sims-style game (133 pts)]]></title>
            <link>https://www.youtube.com/watch?v=sRPnX_f2V_c</link>
            <guid>44943986</guid>
            <pubDate>Mon, 18 Aug 2025 18:51:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=sRPnX_f2V_c">https://www.youtube.com/watch?v=sRPnX_f2V_c</a>, See on <a href="https://news.ycombinator.com/item?id=44943986">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[How much do electric car batteries degrade? (121 pts)]]></title>
            <link>https://www.sustainabilitybynumbers.com/p/electric-car-battery-degradation</link>
            <guid>44943420</guid>
            <pubDate>Mon, 18 Aug 2025 17:53:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sustainabilitybynumbers.com/p/electric-car-battery-degradation">https://www.sustainabilitybynumbers.com/p/electric-car-battery-degradation</a>, See on <a href="https://news.ycombinator.com/item?id=44943420">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>It’s always the battery in my mobile phone that gives up on me first. After just a few years, it can barely make it through the day without getting another charge.</p><p>Most electric cars have the same types of batteries — usually lithium-ion — so the assumption is that they degrade just as quickly. This is a fairly common fear for people considering a new EV: “Won’t the battery need to be replaced after a few years?”. And I think it’s even more prominent in the second-hand market: “Oh, I’d never buy a second-hand battery!”.</p><p>But the types and structures of electric car and mobile phone batteries are not the same. Car batteries are designed to last far longer.</p><p><span>A few months ago, I </span><a href="https://www.sustainabilitybynumbers.com/p/used-electric-car-costs" rel="">wrote about</a><span> the fact that the electric versions of many cars were now cheaper than their petrol equivalents in the second-hand market. Most of the responses to that article suggested that battery degradation is the reason why. But looking at the data, I’d say that it’s more likely to be the </span><em>perception</em><span> of battery degradation that pushes the value down, not the actual degradation in reality. Pessimism about battery longevity is giving us all cheaper second-hand EVs, which is a nice perk for now, but not great if we want to see a widespread shift from petrol to electric. This is not the </span><em>only</em><span> reason I think used EVs are now undercutting the price of petrol cars; the fact that so many newer (and better) models are coming on the market means that many models — even just a few years old — lose some of their comparative value. Again, I think this is a pretty good thing (at least if you’re a prospective buyer).</span></p><p>Anyway, let’s take a look at battery degradation: why it happens, how much EV batteries degrade, and how to reduce it.</p><p>Two types of degradation happen in an electric car battery:</p><p><span>First, </span><strong>calendar aging</strong><span>, which is when the battery loses capacity over time, even when the car isn’t being used. So if you were to have an electric car, and not touch it for a year, the battery would still experience small amounts of degradation.</span></p><p>Why does this happen? Lithium-ion batteries have a thin layer called the SEI (Solid Electrolyte Interphase) that forms on the anode surface. This slowly grows thicker over time, and as it thickens, it uses lithium and reduces usable capacity. Calendar aging tends to be small — typically around 1% to 2% per year — but can be higher in very hot climates.</p><p><span>Second, we have </span><strong>cyclical aging</strong><span>, which is the degradation that happens when batteries charge and discharge. Every time a battery recharges or discharges, lithium ions move in and out of the electrodes. The mechanical stress of this process gradually creates structural changes in the electrodes, which reduce their capacity. This charge cycling can also grow the SEI layer (which I mentioned above), reducing usable capacity.</span></p><p><span>Before we quantify </span><em>how big</em><span> this effect is, it’s interesting to look at how these processes work over the life of a battery. In the chart below, you can see battery retention measured across a large cohort of Teslas up to 200,000 miles (that’s already telling us something about how big the effect is).</span></p><p>But what’s interesting is that degradation tends to happen quickest in the first 20,000 miles or so. This is because initial lithium salts react with other materials and start building that SEI layer we discussed earlier. After this initial drop, degradation is fairly slow and linear.</p><p>Of course, this fact might be one of the explanations why even fairly low-mileage electric cars quickly lose a lot of value once they’ve been driven. As soon as you get on the road, you’re entering the steepest part of the decline.</p><p>What’s missing, though, is the context that the overall drop in capacity is still small — probably around 3% to 5% within 25,000 miles — and degradation won’t continue at this rate. So if you buy a second-hand electric car that’s done 20,000 miles, it’s not going to degrade at the same pace that it was.</p><p>We’ve now had enough electric cars on the road - and for long enough - to have a good idea of how the battery holds up over time.</p><p>Here we’ll focus on a metric used to capture the battery’s “State of Health” (SoH). It’s what percentage of a battery’s initial capacity is still usable after a given number of miles or years.</p><p>Let’s start with the results of the huge Tesla cohort that we looked at above. In its 2023 Impact Report, Tesla reported that after 200,000 miles of use, the batteries in a Model 3 and Model Y had lost just 15% of their capacity, on average. For the Model S and X, it was just 12%.</p><p>That’s not bad, given that most cars are scrapped somewhere in the 150,000 to 200,000 miles range. At that point, a Tesla will have more than 80% of its initial capacity, and in some cases, even more. So people will probably give up their car, well, well before the battery gets close to becoming a burden.</p><p>What about other car models?</p><p><span>The very early Nissan LEAFs — one of the first electric cars to break through — did have real degradation problems, especially in hotter climates. They used a </span><em>passive</em><span> thermal management system — in other words, there was no </span><em>active</em><span> cooling of the battery — which led to faster degradation. Many of these batteries would need to be replaced.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-171243707" href="https://www.sustainabilitybynumbers.com/p/electric-car-battery-degradation#footnote-1-171243707" target="_self" rel="">1</a></span></p><p>But the early Nissan LEAFs were a vital lesson. Most manufacturers do not experience the same issues today. Manufacturers such as Tesla, GM, Kia and Volkswagen using liquid cooling systems to prevent this. </p><p><span>A large study of 7,000 cars </span><a href="https://www.p3-group.com/en/p3-updates/battery-aging-in-practice/" rel="">by AVILOO</a><span> — some of which had done as much as 300,000 kilometres (almost 200,000 miles) — found that the majority still had more than 80% of battery capacity, even at these high-mileage levels.</span></p><p><span>In </span><a href="https://www.recurrentauto.com/research/lessons-in-electric-car-battery-health" rel="">another study</a><span> across 15,000 cars — which had collectively clocked up 250 million miles — just 1.5% had needed a battery replacement </span><em>for any reason</em><span>, so the share that needed one due to degradation was probably even lower.</span></p><p>I would expect that many cars with far more than 200,000 miles would still have a fairly healthy battery left. But not many cars get to this driving distance, and I’d be a bit cautious about survivorship bias if we had a very small sample size. This is also something to be aware of, even when talking about 200,000-mile vehicles, although here the sample sizes are not that small.</p><p>When looking at degradation rates, I’d recommend looking at real-world data rather than some of the earlier models.</p><p>A common model — the P3 SoH — tends to overestimate degradation rates and is, therefore, too pessimistic about how long EV batteries last. It’s based on battery cell data generated from laboratory tests (without a battery management system), but these tend not to be a great match for real driving conditions.</p><p>In the chart, you can see the P3 SoH predicted line in red, and the Aviloo trend line - based on real car data - in blue. Some cars do degrade as quickly as the P3 model would suggest after 200,000+ miles, but these tend to be the poorer-performing outliers, rather than the typical experience.</p><p><span>A </span><a href="https://www.nature.com/articles/s41560-024-01675-8" rel="">study published</a><span> in </span><em>Nature Energy</em><span> also found that under “real” driving conditions, batteries lasted around 38% longer compared to laboratory tests.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-171243707" href="https://www.sustainabilitybynumbers.com/p/electric-car-battery-degradation#footnote-2-171243707" target="_self" rel="">2</a></span></p><p>If you want to understand car batteries, we now have more than enough data from actual drivers and experiences on the road. Just look at that.</p><p><span>The final reason to have confidence in the performance of batteries over time is that manufacturers clearly have confidence. Most now offer battery warranties: if your battery degrades more than this within a given mileage or timescale, then they’ll repair or replace it for you.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-171243707" href="https://www.sustainabilitybynumbers.com/p/electric-car-battery-degradation#footnote-3-171243707" target="_self" rel="">3</a></span></p><p><span>Most manufacturers offer a warranty somewhere in the range of 8 to 10 years, and 100,000 miles. That usually means that if your battery is below 70% health within </span><em>either</em><span> 8 years or 100,000 miles, they’ll replace it for you.</span></p><p>Some are going even further. Some Mercedes models offer over 150,000 miles and 10 years. The Lexus UX300e offers over 600,000 miles. They clearly have a huge amount of confidence that by the end of your car’s life (which is going to be at far less than 600,000 miles), the battery will still have well over 70% of capacity.</p><p><span>The point is </span><em>not</em><span> that battery degradation is not an issue at all. Knowing that your car’s capacity could drop by 10% to 20% over its lifetime is important and useful to know. I said the same </span><a href="https://www.sustainabilitybynumbers.com/p/electric-cars-cold" rel="">in my article</a><span> on how a car’s range changes in cold temperatures: they do lose a bit and I think it’s important for buyers and drivers to know that up-front. The point is that for most drivers, it’s not a dealbreaker. Most are going to manage fine, even with this drop.</span></p><p>But it’s also important to know what things we can do to protect the battery, and slow this degradation as much as possible. Some of these things will not be new to most of you. But here’s a relatively uncontroversial list of things that are recommended:</p><ul><li><p><strong>Avoid extremely high or low temperatures</strong><span>. This tends to increase both cyclical and calendar aging. Try to keep it out of direct heat if you can. If you can find a model with a heat pump, this is useful to reduce degradation from cold charging.</span></p></li><li><p><strong>Avoid extreme “state-of-charge”</strong><span>. Leaving the battery sitting with more than 80% or less than 10% of charge can accelerate calendar aging.</span></p></li><li><p><strong>Don’t fast charge all the time</strong><span>. Fast charging can increase degradation rates, so only use it when necessary. There are examples of EVs in taxi fleets — which relied heavily on fast-charging — where batteries needed to be replaced.</span></p></li></ul><p>Finally, it’s worth noting that battery designs and chemistries are getting better every day. From here on out, this is as bad as things are going to get. The longevity of the batteries that went into cars a decade ago — and are now reaching 200,000 miles or the end of their lives — is worse than that of the ones going into cars today.</p><p>As I’ve previously said about the emissions associated with an electric car, things are only going to get better.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Left to Right Programming (355 pts)]]></title>
            <link>https://graic.net/p/left-to-right-programming</link>
            <guid>44942936</guid>
            <pubDate>Mon, 18 Aug 2025 17:08:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://graic.net/p/left-to-right-programming">https://graic.net/p/left-to-right-programming</a>, See on <a href="https://news.ycombinator.com/item?id=44942936">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><!--[--><sub>2025-08-17</sub>  <h3>Programs Should Be Valid as They Are Typed</h3> <hr><!--]--> <!--[!--><!--]--> <!----><p>I don’t like Python’s list comprehensions:</p> <pre><!----><code>text <span>=</span> <span>"apple banana cherry\ndog emu fox"</span>
words_on_lines <span>=</span> <span>[</span>line<span>.</span>split<span>(</span><span>)</span> <span>for</span> line <span>in</span> text<span>.</span>splitlines<span>(</span><span>)</span><span>]</span></code><!----></pre> <p>Don’t get me wrong, declarative programming is good. However, this syntax has poor ergonomics. Your editor can’t help you out as you write it. To see what I mean, lets walk through typing this code.</p> <pre><!----><code>words_on_lines <span>=</span> <span>[</span>l</code><!----></pre> <p>Ideally, your editor would be to autocomplete <code>line</code> here. Your editor can’t do this because <code>line</code> hasn’t been declared yet.</p> <pre><!----><code>words_on_lines <span>=</span> <span>[</span>line<span>.</span>sp</code><!----></pre> <p>Here, our editor knows we want to access some property of <code>line</code>, but since it doesn’t know the type of <code>line</code>, it can’t make any useful suggestions. Should our editor flag <code>line</code> as a non-existent variable? For all it knows, we might have meant to refer to some existing <code>lime</code> variable.</p> <pre><!----><code>words_on_lines <span>=</span> <span>[</span>line<span>.</span>split<span>(</span><span>)</span> <span>for</span> line <span>in</span></code><!----></pre> <p>Okay, now we know that <code>line</code> is the variable we’re iterating over. Is <code>split()</code> a method that exists for <code>line</code>? Who knows!</p> <pre><!----><code>words_on_lines <span>=</span> <span>[</span>line<span>.</span>split<span>(</span><span>)</span> <span>for</span> line <span>in</span> text<span>.</span>splitlines<span>(</span><span>)</span><span>]</span></code><!----></pre> <p>Ah! now we know the type of <code>line</code> and can validate the call to <code>split()</code>.
Notice that since <code>text</code> had already been declared, our editor is able to autocomplete <code>splitlines()</code>.</p> <p>This sucked! If we didn’t know what the <code>split()</code> function was called and wanted some help from our editor, we’d have to write</p> <pre><!----><code>words_on_lines <span>=</span> <span>[</span>_ <span>for</span> line <span>in</span> text<span>.</span>splitlines<span>(</span><span>)</span><span>]</span></code><!----></pre> <p>and go back to the <code>_</code> to get autocomplete on <code>line.sp</code></p> <!----> <hr> <!----> <!----> <p>You deserve better than this.</p> <p>To see what I mean, lets look at a Rust example that does it <!--#s1--><span> <label for="s1-footnote">better. <span>†</span><span id="slot">[<!---->The most elegant solution here is Haskell’s <code>map words $ lines text</code> but that breaks all the principles I’m arguing for.<!---->]</span></label></span><!----></p> <pre><!----><code><span>let</span> text <span>=</span> <span>"apple banana cherry\ndog emu fox"</span><span>;</span>
<span>let</span> words_on_lines <span>=</span> text<span>.</span><span>lines</span><span>(</span><span>)</span><span>.</span><span>map</span><span>(</span><span><span>|</span>line<span>|</span></span> line<span>.</span><span>split_whitespace</span><span>(</span><span>)</span><span>)</span><span>;</span></code><!----></pre> <p>If you aren’t familiar with Rust syntax, <code>|argument| result</code> is an anonymous function equivilent to <code>function myfunction(argument) { return result; }</code></p> <p>Here, your program is constructed left to right. The first time you type <code>line</code> is the declaration of the variable. as soon as you type <code>line.</code> your editor is able to give you suggestions of <!--#s2--><span> <label for="s2-footnote">possible methods. <span>†</span><span id="slot">[<!---->In fact, I didn’t know that Rust had a <code>split_whitespace</code> function until it popped up as I was typing this example.<!---->]</span></label></span><!----></p> <p>This is much more pleasent. Since the program is always in a somehwat valid state as you type it, your editor is able to guide you towards the <a href="https://blog.codinghorror.com/falling-into-the-pit-of-success/" rel="nofollow">Pit of Success</a>.</p> <!----> <hr> <!----> <!----> <p>There’s a principle in design called <a href="https://en.wikipedia.org/wiki/Progressive_disclosure" rel="nofollow">progressive disclosure</a>. The user should only be exposed to as much complexity as is neccessary to complete a task.
Additionally, complexity should naturally surface itself as it is relevant to the user.
You shouldn’t have to choose a font family and size before you start typing into Word, and options to change text wrapping around images should appear when you add an image.</p> <p>In C, you can’t have methods on structs. This means that any function that could be <code>myStruct.function(args)</code> has to be <code>function(myStruct, args)</code>.</p> <p>Suppose you have a <code>FILE *file</code> and you want to get it’s contents.
Ideally, you’d be able to type <code>file.</code> and see a list of every function that is primarily concerned with files.
From there you could pick <code>read</code> and get on with your day.</p> <p>Instead, you must know that functions releated to <code>FILE *</code> tend to start with <code>f</code>, and when you type <code>f</code> the best your editor can do is show you all functions ever written that start with an <code>f</code>.
From there you can eventually find <code>fread</code>, but you have no confidence that it was the best choice. Maybe there was a more efficient <code>read_lines</code> function that does exactly what you want, but you’ll never discover it by accident.</p> <p>In a more ideal language, you’d see that a <code>close</code> method exists while you’re typing <code>file.read</code>. This gives you a hint that you need to close your file when you’re done with it. You naturally came accross this information right as it became relevant to you. In C, you have to know ahead of time that <code>fclose</code> is a function that you’ll need to call once you’re done with the file.</p> <!----> <hr> <!----> <!----> <p>C is not the only language that has this problem. Python has plenty of examples too. Consider the following Python and JavaScript snippets:</p> <pre><!----><code><span># Python</span>
text <span>=</span> <span>"lorem ipsum dolor sit amet"</span>
word_lengths <span>=</span> <span>map</span><span>(</span><span>len</span><span>,</span> text<span>.</span>split<span>(</span><span>)</span><span>)</span></code><!----></pre> <pre><!----><code><span>// JavaScript</span>
text <span>=</span> <span>"lorem ipsum dolor sit amet"</span>
wordLengths <span>=</span> text<span>.</span><span>split</span><span>(</span><span>" "</span><span>)</span><span>.</span><span>map</span><span>(</span><span>word</span> <span>=&gt;</span> word<span>.</span>length<span>)</span></code><!----></pre> <p>While Python gets some points for using a <!--#s3--><span> <label for="s3-footnote">first-class function <span>†</span><span id="slot">[<!---->Haskell, of course, solos with <code>map len $ words text</code><!---->]</span></label></span><!---->, the functions are not discoverable. Is string length <code>len</code>, <code>length</code>, <code>size</code>, <code>count</code>, <code>num</code>, or <!--#s4--><span> <label for="s4-footnote"># <span>†</span><span id="slot">[<!---->It is in Lua! I’ve seen all of these names used at some point<!---->]</span></label></span><!---->? Is there even a global function for length? You won’t know until you try all of them.</p> <p>In the JavaScript version, you see length as soon as you type <code>word.l</code>. There is less guesswork for what the function is named. The same is true for the <code>map</code>. When you type <code>.map</code>, you know that this function is going to work with the data you have. You aren’t going to get some weird error because the <code>map</code> function actually expected some other type, or because your language actually calls this function <!--#s5--><span> <label for="s5-footnote">select <span>†</span><span id="slot">[<!---->As it is in C# LINQ<!---->]</span></label></span><!---->.</p> <!----> <hr> <!----> <!----> <p>While the Python code in the previous example is still readable, it gets worse as the complexity of the logic increases. Consider the following code that was part of <a href="https://github.com/Graicc/advent-of-code-2024/blob/0d7bf0f4f05489f0b5a09255fde47370084066e3/day_2/aoc2.py#L9" rel="nofollow">my 2024 Advent of Code solutions</a>.</p> <pre><!----><code><span>len</span><span>(</span><span>list</span><span>(</span><span>filter</span><span>(</span><span>lambda</span> line<span>:</span> <span>all</span><span>(</span><span>[</span><span>abs</span><span>(</span>x<span>)</span> <span>&gt;=</span> <span>1</span> <span>and</span> <span>abs</span><span>(</span>x<span>)</span> <span>&lt;=</span> <span>3</span> <span>for</span> x <span>in</span> line<span>]</span><span>)</span> <span>and</span> <span>(</span><span>all</span><span>(</span><span>[</span>x <span>&gt;</span> <span>0</span> <span>for</span> x <span>in</span> line<span>]</span><span>)</span> <span>or</span> <span>all</span><span>(</span><span>[</span>x <span>&lt;</span> <span>0</span> <span>for</span> x <span>in</span> line<span>]</span><span>)</span><span>)</span><span>,</span> diffs<span>)</span><span>)</span><span>)</span></code><!----></pre> <p>Yikes. You have to jump back and forth between the start and end of the line to figure out what’s going on. “Okay so we have the length of a list of some filter which takes this lambda… is it both of these conditions or just one? Wait which parenthesis does this go with…”</p> <p>In JavaScript:</p> <pre><!----><code>diffs<span>.</span><span>filter</span><span>(</span><span>line</span> <span>=&gt;</span> 
    line<span>.</span><span>every</span><span>(</span><span>x</span> <span>=&gt;</span> Math<span>.</span><span>abs</span><span>(</span>x<span>)</span> <span>&gt;=</span> <span>1</span> <span>&amp;&amp;</span> Math<span>.</span><span>abs</span><span>(</span>x<span>)</span> <span>&lt;=</span> <span>3</span><span>)</span> <span>&amp;&amp;</span>
    <span>(</span>line<span>.</span><span>every</span><span>(</span><span>x</span> <span>=&gt;</span> x <span>&gt;</span> <span>0</span><span>)</span> <span>||</span> line<span>.</span><span>every</span><span>(</span><span>x</span> <span>=&gt;</span> x <span>&lt;</span> <span>0</span><span>)</span><span>)</span>
<span>)</span><span>.</span>length<span>;</span></code><!----></pre> <p>Ah, okay. We have some list of <code>diffs</code>, that we filter down based on two conditons, and then we return the number that pass. The logic of the program can be read from left to right!</p> <!----> <hr> <!----> <!----> <p>All of these examples illustrate a common principle:</p> <h2><center>Programs should be valid as they are typed.</center></h2> <p>When you’ve typed <code>text</code>, the program is valid.
When you’ve typed <code>text.split(" ")</code>, the program is valid.
When you’ve typed <code>text.split(" ").map(word =&gt; word.length)</code>, the program is valid.
Since the program is valid as you build it up, your editor is able to help you out. If you had a REPL, you could even see the result as you type your program out.</p> <p>Make good APIs!</p><!----></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Whispering – Open-source, local-first dictation you can trust (436 pts)]]></title>
            <link>https://github.com/epicenter-so/epicenter/tree/main/apps/whispering</link>
            <guid>44942731</guid>
            <pubDate>Mon, 18 Aug 2025 16:52:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/epicenter-so/epicenter/tree/main/apps/whispering">https://github.com/epicenter-so/epicenter/tree/main/apps/whispering</a>, See on <a href="https://news.ycombinator.com/item?id=44942731">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>


                <li>
      

      <div>
          <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_copilot&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_copilot_link_product_navbar&quot;}" href="https://github.com/features/copilot">
      
      <div>
          <p>
            GitHub Copilot
          </p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_spark&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_spark_link_product_navbar&quot;}" href="https://github.com/features/spark">
      
      <div>
          <p>
            GitHub Spark
              <span>
                New
              </span>
          </p><p>
        Build and deploy intelligent apps
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_models&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_models_link_product_navbar&quot;}" href="https://github.com/features/models">
      
      <div>
          <p>
            GitHub Models
              <span>
                New
              </span>
          </p><p>
        Manage and compare prompts
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_advanced_security_link_product_navbar&quot;}" href="https://github.com/security/advanced-security">
      
      <div>
          <p>
            GitHub Advanced Security
          </p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;actions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;actions_link_product_navbar&quot;}" href="https://github.com/features/actions">
      
      <div>
          <p>
            Actions
          </p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                    
                </ul>
              </div>
          <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;codespaces&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;codespaces_link_product_navbar&quot;}" href="https://github.com/features/codespaces">
      
      <div>
          <p>
            Codespaces
          </p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;issues&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;issues_link_product_navbar&quot;}" href="https://github.com/features/issues">
      
      <div>
          <p>
            Issues
          </p><p>
        Plan and track work
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_review&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_review_link_product_navbar&quot;}" href="https://github.com/features/code-review">
      
      <div>
          <p>
            Code Review
          </p><p>
        Manage code changes
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;discussions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;discussions_link_product_navbar&quot;}" href="https://github.com/features/discussions">
      
      <div>
          <p>
            Discussions
          </p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_search&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_search_link_product_navbar&quot;}" href="https://github.com/features/code-search">
      
      <div>
          <p>
            Code Search
          </p><p>
        Find more, search less
      </p></div>

    
</a></li>

                </ul>
              </div>
          

      </div>
</li>


                <li>
      

      
</li>


                <li>
      

      <div>
                    <p><span id="resources-explore-heading">Explore</span></p><ul aria-labelledby="resources-explore-heading">
                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;learning_pathways&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;learning_pathways_link_resources_navbar&quot;}" href="https://resources.github.com/learn/pathways">
      Learning Pathways

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;events_amp_webinars&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;events_amp_webinars_link_resources_navbar&quot;}" href="https://resources.github.com/">
      Events &amp; Webinars

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;ebooks_amp_whitepapers&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;ebooks_amp_whitepapers_link_resources_navbar&quot;}" href="https://github.com/resources/whitepapers">
      Ebooks &amp; Whitepapers

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;customer_stories&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;partners&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}" href="https://partner.github.com/">
      Partners

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;executive_insights&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;executive_insights_link_resources_navbar&quot;}" href="https://github.com/solutions/executive-insights">
      Executive Insights

    
</a></li>

                </ul>
              </div>
</li>


                <li>
      

      <div>
              <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_sponsors&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}" href="https://github.com/sponsors">
      
      <div>
          <p>
            GitHub Sponsors
          </p><p>
        Fund open source developers
      </p></div>

    
</a></li>

                </ul>
              </div>
              <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;the_readme_project&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;the_readme_project_link_open_source_navbar&quot;}" href="https://github.com/readme">
      
      <div>
          <p>
            The ReadME Project
          </p><p>
        GitHub community articles
      </p></div>

    
</a></li>

                </ul>
              </div>
              
          </div>
</li>


                <li>
      

      <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}" href="https://github.com/enterprise">
      
      <div>
          <p>
            Enterprise platform
          </p><p>
        AI-powered developer platform
      </p></div>

    
</a></li>

                </ul>
              </div>
</li>


                <li>
    <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;pricing&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;pricing_link_global_navbar&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:epicenter-so/epicenter" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="4luAhuAdn-jJh95P57GWAOb_XLXg0xHodbnDFC953UjFmhDbdBwUMGTTlwUQXmyYZuE4DDsrkLx-Qd9nI9BdTQ" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="epicenter-so/epicenter" data-current-org="epicenter-so" data-current-owner="" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false" data-retain-scroll-position="true">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>


            

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Ffiles%2Fdisambiguate&amp;source=header-repo&amp;source_repo=epicenter-so%2Fepicenter" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/epicenter-so/epicenter/tree/main/apps/whispering&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="f56bbfb881377e09d87bc947754ac94749d4b634b2d83bbe06146636fcaf18ed" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/files/disambiguate;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a></p><p>
    <react-partial-anchor>
      <tool-tip id="tooltip-52dcc01b-ceec-4b40-ba1b-bb1fdf6b9f02" for="icon-button-d749c8c4-8f0b-4993-a32c-298260a616f4" popover="manual" data-direction="s" data-type="label" data-view-component="true">Appearance settings</tool-tip>

      <template data-target="react-partial-anchor.template">
        <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/appearance-settings.c82a4db79200850fb016.module.css">

<react-partial partial-name="appearance-settings" data-ssr="false" data-attempted-ssr="false" data-react-profiling="false">
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>


      </template>
    </react-partial-anchor>
  </p>

          </div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My Retro TVs (139 pts)]]></title>
            <link>https://www.myretrotvs.com/</link>
            <guid>44942602</guid>
            <pubDate>Mon, 18 Aug 2025 16:40:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.myretrotvs.com/">https://www.myretrotvs.com/</a>, See on <a href="https://news.ycombinator.com/item?id=44942602">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Anna's Archive: An Update from the Team (929 pts)]]></title>
            <link>https://annas-archive.org/blog/an-update-from-the-team.html</link>
            <guid>44942501</guid>
            <pubDate>Mon, 18 Aug 2025 16:31:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://annas-archive.org/blog/an-update-from-the-team.html">https://annas-archive.org/blog/an-update-from-the-team.html</a>, See on <a href="https://news.ycombinator.com/item?id=44942501">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  <p>
    annas-archive.li/blog, 2025-08-17
  </p>

  

  <p>We are still alive and kicking. In recent weeks we’ve seen increased attacks on our mission. We are taking steps to harden our infrastructure and operational security. The work of securing humanity’s legacy is worth fighting for.</p>

  <p>Since we started in 2022, we have liberated tens of millions of books, scientific articles, magazines, newspapers, and more. These are now forever protected from destruction by natural disasters, wars, budget cuts, and other catastrophes, thanks to everyone who helps with torrenting.</p>

  <p>Anna’s Archive itself has organized some of the largest scrapes: we acquired tens of millions of files from IA Controlled Digital Lending, HathiTrust, DuXiu, and many more.</p>

  <p>We have also scraped and published the largest book metadata collections in history: WorldCat, Google Books, and others. With this we’ll be able to identify which books are still missing from our collections, and prioritize saving the rarest ones.</p>

  <p>Much thanks to all of our volunteers for making these projects happen.</p>

  <p>We’ve forged some incredible partnerships. We’ve partnered with two LibGen forks, STC/Nexus, Z-Library. We’ve secured tens of millions additional files through these partnerships. And they are helping the mission by mirroring our files.</p>

  <p>Unfortunately we have seen the disappearance of one of the LibGen forks. We don’t have further information about what happened there, but are saddened by this development.</p>

  <p>There is a new entrant: WeLib. They appear to have mirrored most of our collection, and use a fork of our codebase. We have copied some of their user interface improvements, and are grateful for that push. Sadly, we are not seeing them share any new collections, nor share their codebase improvements. Since they haven’t shown commitment to contributing back to the ecosystem, we advise extreme caution. <em>We recommend not using them.</em></p>

  <p>In the meantime, we have some exciting projects in the works. We have hundreds of terabytes in new collections sitting on our servers, waiting to be processed. If you’re at all interested in helping out, feel free to check out our Volunteering and Donate pages. We run all of this on a minimal budget, so any help is greatly appreciated.</p>

  <p>Keep fighting.</p>

  <p>- Anna and the team (<a href="https://www.reddit.com/r/Annas_Archive/" rel="noopener noreferrer nofollow" target="_blank">Reddit</a>)</p>
     </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Who Invented Backpropagation? (186 pts)]]></title>
            <link>https://people.idsia.ch/~juergen/who-invented-backpropagation.html</link>
            <guid>44941963</guid>
            <pubDate>Mon, 18 Aug 2025 15:50:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://people.idsia.ch/~juergen/who-invented-backpropagation.html">https://people.idsia.ch/~juergen/who-invented-backpropagation.html</a>, See on <a href="https://news.ycombinator.com/item?id=44941963">Hacker News</a></p>
<div id="readability-page-1" class="page"><div width="754">
<tbody><tr>
<td>
<a href="https://people.idsia.ch/~juergen/deep-learning-history.html"><img src="https://people.idsia.ch/~juergen/backprop754x466seppo.png" alt="Who Invented Backpropagation?"></a>



<p>
<table><colgroup><col><col></colgroup><tbody><tr><td><a href="https://people.idsia.ch/~juergen/">Jürgen Schmidhuber</a> (2014, updated <a href="https://people.idsia.ch/~juergen/who-invented-backpropagation-1970.html">2020</a>, <a href="https://people.idsia.ch/~juergen/who-invented-backpropagation-2022.html">2022</a>, 2025)
<br>Pronounce: <span color="#2266aa">You_again Shmidhoobuh</span>
<br>See also this <a href="https://www.linkedin.com/feed/update/urn:li:activity:7354090939369283585/">LinkedIn post (2025)</a>
</td> <td>
<a href="https://people.idsia.ch/~juergen/blog.html">AI Blog</a>
<br><a href="https://twitter.com/SchmidhuberAI">@SchmidhuberAI</a> 
</td></tr></tbody></table>



</p>

<span size="4">






<p>Efficient backpropagation (BP) is central to the ongoing    
<a href="http://www.idsia.ch/~juergen/deeplearning.html">Neural Network (NN) ReNNaissance and "Deep Learning."</a> 
Who invented it? 

</p><p> BP's modern version (also called the reverse mode of automatic differentiation) was first published in 1970 
by Finnish master student <b>Seppo Linnainmaa</b> <a href="#BP1">[BP1]</a> <a href="#R7">[R7]</a>. <b>In 2020, we celebrated BP's half-century anniversary!</b>
A precursor of BP was published by Henry J. Kelley in 1960 
<a href="#BPA">[BPA]</a>—in 2020, we celebrated its 60-year anniversary.

</p><p>In the 2020s, it was still easy to find misleading accounts of BP's history <a href="#HIN">[HIN]</a><a href="#T22">[T22]</a><a href="#DLP">[DLP]</a><a href="#NOB">[NOB]</a>. I had a look at the original papers from the 1960s and 70s, and talked to BP pioneers. Here is a summary based on my  award-winning
<a href="https://people.idsia.ch/~juergen/deep-learning-overview.html">2014 survey</a> <a href="#DL1">[DL1]</a>
which includes most of the references mentioned below.

</p><p>The minimisation of errors through gradient descent (Cauchy 1847 <a href="#GD'">[GD']</a>, Hadamard, 1908 <a href="#GD''">[GD'']</a>) in the parameter space of complex, nonlinear, differentiable, multi-stage, NN-related systems has been discussed at least since the early 1960s,
e.g., Kelley (1960) <a href="#BPA">[BPA]</a>; Bryson (1961) <a href="#BPB">[BPB]</a>; Pontryagin et al. (1961); Dreyfus (1962) <a href="#BPC">[BPC]</a>; Wilkinson (1965); Tsypkin (1966) <a href="#GDa">[GDa-b]</a>; Amari (1967-68) <a href="#GD2">[GD2,GD2a]</a>; Bryson and Ho (1969); initially within the framework of Euler-LaGrange equations in the Calculus of Variations, e.g., Euler (1744). 

</p><p>Steepest descent in the weight space of such systems can be performed (Kelley, 1960 <a href="#BPA">[BPA]</a>; Bryson, 1961 <a href="#BPB">[BPB]</a>) by iterating the chain rule (<a href="https://people.idsia.ch/~juergen/leibniz-father-computer-science-375.html">Leibniz</a>, 1676 <a href="#LEI07">[LEI07-10]</a><a href="#DLH">[DLH]</a>; L'Hopital, 1696) in Dynamic Programming style (DP, e.g., Bellman, 1957 <a href="#BEL53">[BEL53]</a>). A simplified derivation (Dreyfus, 1962 <a href="#BPC">[BPC]</a>) of this backpropagation method uses only the <a href="https://people.idsia.ch/~juergen/leibniz-father-computer-science-375.html">Leibniz</a> chain rule  <a href="#LEI07">[LEI07]</a>.

</p><p>The systems of the 1960s were already efficient in the DP sense. However, they backpropagated derivative information through standard Jacobian matrix calculations from one "layer" to the previous one, without explicitly addressing either direct links across several layers or potential additional efficiency gains due to network sparsity. 

</p><p>Explicit, efficient error backpropagation (BP) in arbitrary, discrete, possibly sparsely connected, NN-like networks was first described in a 1970 master's thesis (Linnainmaa, 1970, 1976) <a href="#BP1">[BP1]</a><a href="#R7">[R7]</a>, albeit without reference to NNs. This kind of BP is also known as the <em>reverse mode of automatic differentiation</em> (e.g., Griewank, 2012 <a href="#BP5">[BP5]</a>), where the costs of forward activation spreading essentially equal the costs of backward derivative calculation. See early BP FORTRAN code (Linnainmaa, 1970) <a href="#BP1">[BP1]</a> and closely related but slightly later work by Ostrovskii et al. (1971) <a href="#BP1a">[BP1a]</a> (apparently the <em>first journal publication</em> on backpropagation). As of 2020, all modern software packages for NNs (such as Google's Tensorflow) are based on Linnainmaa's method of 1970.

</p><p>BP was soon explicitly used to minimize cost functions by adapting control parameters (weights) (Dreyfus, 1973). This was followed by some preliminary, NN-specific discussion (Werbos, 1974, section 5.5.1) and a computer program for automatically deriving and implementing BP in differentiable systems (Speelpenning, 1980).
The first NN-specific application of efficient BP as above was apparently described by  Werbos in 1982 <a href="#BP2">[BP2]</a> (but not yet in his 1974 thesis, as is sometimes claimed). 


</p><p> However, already in 1967, Amari suggested to train deep multilayer perceptrons (MLPs) with many layers in non-incremental end-to-end fashion from scratch by stochastic gradient descent (SGD) <a href="#GD1">[GD1]</a>, a method proposed in 1951 <a href="#STO51">[STO51-52]</a>.
Amari's implementation <a href="#GD2">[GD2,GD2a]</a> (with his student Saito) learned <em>internal representations</em> in a five layer MLP with two modifiable layers <a href="#DLH">[DLH]</a><a href="#NOB">[NOB]</a>, which was trained to classify
non-linearily separable pattern classes. Back then compute was billions of times more expensive than today. 

</p><p>Compare the first deep learning MLPs called GMDH networks (Ivakhnenko and Lapa, since 1965) whose layers are incrementally grown and trained by regression analysis <a href="#DEEP1">[DEEP1-2]</a><a href="#R8">[R8]</a><a href="#DLH">[DLH]</a><a href="#NOB">[NOB]</a>. These were  actually the first deep NNs that learned to create hierarchical, distributed, <em>internal representations</em> of incoming data. 

</p><p> Additional work on backpropagation was published  later (e.g., Parker, 1985; LeCun, 1985). 
By 1985, compute was about 1,000 times cheaper than in 1970 <a href="#BP1">[BP1]</a>, and 
the first desktop computers 
became accessible in wealthier academic labs. 
An experimental analysis of the known method <a href="#BP1">[BP1-2]</a> by Rumelhart et al. then demonstrated that backpropagation can yield useful internal representations in hidden layers of NNs <a href="#RUM">[RUM]</a>. At least for supervised learning, this tends to be more efficient than Amari's above-mentioned deep learning through the more general SGD method (1967), which learned useful internal representations in NNs about 2 decades earlier <a href="#GD1">[GD1-2a]</a>.


</p><p> Some ask: <em> "Isn't backpropagation just the chain rule of <a href="https://people.idsia.ch/~juergen/leibniz-father-computer-science-375.html">Leibniz</a> (1676) <a href="#LEI07">[LEI07-10]</a> &amp; L'Hopital (1696)?"</em>  No, it is the efficient way of applying the chain rule to big networks with differentiable nodes—see <a href="https://people.idsia.ch/~juergen/scientific-integrity-turing-award-deep-learning.html#XII">Sec. XII</a> of <a href="#T22">[T22]</a><a href="#DLH">[DLH]</a>). (There are also many inefficient ways of  doing this.) It was not published until 1970 <a href="#BP1">[BP1]</a>.

</p><p> It took 4 decades until the backpropagation method of 1970 <a href="#BP1">[BP1-2]</a> got widely accepted as a training method for deep NNs. Before 2010, many thought that the training of NNs with many layers requires <a href="https://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%2019">unsupervised pre-training</a>, a methodology introduced 
<a href="https://people.idsia.ch/~juergen/very-deep-learning-1991.html">by myself in 1991</a> <a href="#UN">[UN][UN0-3]</a>, and later championed by others (2006) <a href="#UN4">[UN4]</a>. In fact, it was claimed <a href="#VID1">[VID1]</a><a href="#DLP">[DLP]</a>  that "nobody in their right mind would ever suggest" to apply plain backpropagation to deep NNs. However, in 2010, our team with my outstanding Romanian 
postdoc Dan Ciresan 
<a href="https://people.idsia.ch/~juergen/2010-end-to-end-deep-learning-breakthrough.html">
showed that deep FNNs  
can be trained by plain backpropagation and do not at all require unsupervised
pre-training for important applications</a> <a href="#MLP1">[MLP1-3]</a><a href="#MOST">[MOST]</a>.

<a name="ack"></a>
</p><h2><hr>Acknowledgments <hr></h2>


<p><a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"></a>Thanks to several backpropagation pioneers and expert reviewers for useful comments. Since science is about self-correction, let me know under <em>juergen@idsia.ch</em> if you can spot any remaining error. The contents of this article may be used for educational and non-commercial purposes, including articles for Wikipedia and similar sites. This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>. 
</p><h2><hr>References (more in <a href="#DL1">[DL1]</a><a href="#DLH">[DLH]</a>)<hr></h2>


<p><a name="BEL53"></a>
[BEL53] R. Bellman. An introduction to the theory of dynamic programming. RAND Corp. Report, 1953


</p><p><a name="BP1"></a>
[BP1] S. Linnainmaa. The representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors. Master's Thesis (in Finnish), Univ. Helsinki, 1970.
<em>See chapters 6-7 and FORTRAN code on pages 58-60.</em>
<a href="http://www.idsia.ch/~juergen/linnainmaa1970thesis.pdf">PDF</a>.
See also  BIT 16, 146-160, 1976.
<a href="http://link.springer.com/article/10.1007%2FBF01931367">Link.</a>
<em>The first publication on "modern" backpropagation, also known as the reverse mode of automatic differentiation.</em>

</p><p><a name="BP1a"></a>
[BP1a] G. M. Ostrovskii, Y. M. Volin, W. W. Borisov (1971). Ueber die Berechnung von Ableitungen.
Wiss. Z. Tech. Hochschule fuer Chemie, 13:382–384.

</p><p><a name="BP2"></a>
[BP2] P. J. Werbos. Applications of advances in nonlinear sensitivity analysis. In R. Drenick, F. Kozin, (eds): System Modeling and Optimization: Proc. IFIP, 
Springer, 1982. 
<a href="http://werbos.com/Neural/SensitivityIFIPSeptember1981.pdf">PDF</a>.
<em>First application of backpropagation<sup><small><small><a href="#BP1">[BP1]</a></small></small></sup> to NNs (concretizing thoughts in his 1974 thesis).</em>

</p><p>
<a name="BP4"></a>
[BP4] J. Schmidhuber (<a href="https://people.idsia.ch/~juergen/blog.html">AI Blog</a>, 2014-). 
<a href="https://people.idsia.ch/~juergen/who-invented-backpropagation.html">Who invented backpropagation</a>? 



</p><p>
<a name="BP5"></a>
[BP5] 
A. Griewank (2012). Who invented the reverse mode of differentiation?
Documenta Mathematica, Extra Volume ISMP (2012): 389-400.

</p><p>
<a name="BP6"></a>
[BP6]
S. I. Amari (1977).
Neural Theory of Association and Concept Formation. 
Biological Cybernetics, vol. 26, p. 175-185, 1977.   
<em>See Section 3.1 on using gradient descent for learning in multilayer networks.</em>

</p><p><a name="BPA"></a>
[BPA]
H. J. Kelley.  Gradient Theory of Optimal Flight Paths. ARS Journal, Vol. 30, No. 10, pp. 947-954, 1960. 
<em>Precursor of modern <a href="https://people.idsia.ch/~juergen/who-invented-backpropagation.html">backpropagation</a>.<sup><small><small><a href="#BP1">[BP1-5]</a></small></small></sup></em>

</p><p><a name="BPB"></a>
[BPB]
A. E. Bryson. A gradient method for optimizing multi-stage allocation processes. Proc. Harvard Univ. Symposium on digital computers and their applications, 1961.

</p><p><a name="BPC"></a>
[BPC]
S. E. Dreyfus. The numerical solution of variational problems. Journal of Mathematical Analysis and Applications, 5(1): 30-45, 1962.




</p><p><a name="DEC"></a>
[DEC] J. Schmidhuber (<a href="https://people.idsia.ch/~juergen/blog.html">AI Blog</a>, 02/20/2020, updated 2025). <a href="https://people.idsia.ch/~juergen/2010s-our-decade-of-deep-learning.html">The 2010s: Our Decade of Deep Learning / Outlook on the 2020s</a>.  <em>The recent decade's most important developments and industrial applications based on our AI, with an outlook on the 2020s, also addressing privacy and data markets.</em>




</p><p><a name="DEEP1"></a>
[DEEP1]
Ivakhnenko, A. G. and Lapa, V. G. (1965). Cybernetic Predicting Devices. CCM Information Corporation. <em>First working Deep Learners with many layers, learning internal representations.</em>

</p><p><a name="DEEP1a"></a>
[DEEP1a]
Ivakhnenko, Alexey Grigorevich. The group method of data of handling; a rival of the method of stochastic approximation. Soviet Automatic Control 13 (1968): 43-55.

</p><p><a name="DEEP2"></a>
[DEEP2]
Ivakhnenko, A. G. (1971). Polynomial theory of complex systems. IEEE Transactions on Systems, Man and Cybernetics, (4):364-378.

</p><p>
<a name="DL1"></a>
[DL1] J. Schmidhuber, 2015. 
Deep learning in neural networks: An overview. Neural Networks, 61, 85-117. 
<a href="https://people.idsia.ch/~juergen/deep-learning-overview.html">More</a>.
<em>Got the first Best Paper Award ever issued by the journal Neural Networks, founded in 1988.</em>


</p><p><a name="DL2"></a>
[DL2] J. Schmidhuber, 2015. 
<a href="http://www.scholarpedia.org/article/Deep_Learning">Deep Learning</a>.
Scholarpedia, 10(11):32832.

</p><p><a name="DL3"></a>
[DL3] Y. LeCun, Y. Bengio, G. Hinton (2015). Deep Learning. Nature 521, 436-444.
<a href="https://www.nature.com/articles/nature14539">HTML</a>. 
<em>A "survey" of deep learning that does not mention the pioneering works of deep learning <a href="#T22">[T22]</a><a href="#DLP">[DLP]</a><a href="#NOB">[NOB]</a>.</em>

</p><p><a name="DL3a"></a>
[DL3a] Y. Bengio, Y. LeCun, G. Hinton (2021). Turing Lecture: Deep Learning for AI. Communications of the ACM, July 2021. <a href="https://cacm.acm.org/magazines/2021/7/253464-deep-learning-for-ai/fulltext">HTML</a>.
<a href="https://people.idsia.ch/~juergen/DLforAIjuly2021.html">Local copy</a> (HTML only).
<em>A "survey" of deep learning that does not mention the pioneering works of deep learning <a href="#DLP">[DLP]</a><a href="#NOB">[NOB]</a>.</em>


</p><p><a name="DLC"></a>
[DLC] J. Schmidhuber (<a href="https://people.idsia.ch/~juergen/blog.html">AI Blog</a>, June 2015).  
<a href="https://people.idsia.ch/~juergen/deep-learning-conspiracy.html">Critique of Paper</a> by self-proclaimed "Deep Learning Conspiracy" (Nature 521 p 436). 
<em>The inventor of an important method should get credit for inventing it. She may not always be the one who popularizes it. Then the popularizer should get credit for popularizing it (but not for inventing it). More: <a href="#T22">[T22]</a><a href="#DLP">[DLP]</a><a href="#NOB">[NOB]</a>.</em> 


</p><p><a name="DLH"></a>
[DLH]
J. Schmidhuber (<a href="https://people.idsia.ch/~juergen/blog.html">AI Blog</a>, 2022). 
<a href="https://people.idsia.ch/~juergen/deep-learning-history.html">Annotated History of Modern AI and Deep Learning</a>. Technical Report IDSIA-22-22, IDSIA, Lugano, Switzerland, 2022. 
Preprint <a href="https://arxiv.org/abs/2212.11279">arXiv:2212.11279</a>.
<a href="https://x.com/SchmidhuberAI/status/1606333832956973060">Tweet of 2022</a>.


</p><p><a name="DLP"></a>
[DLP] 
J. Schmidhuber (<a href="https://people.idsia.ch/~juergen/blog.html">AI Blog</a>, 2023). 
<a href="https://people.idsia.ch/~juergen/ai-priority-disputes.html"> How 3 Turing awardees republished key methods and ideas whose creators they failed to credit.</a> Technical Report IDSIA-23-23, Swiss AI Lab IDSIA, 14 Dec 2023.
<a href="https://x.com/SchmidhuberAI/status/1735313711240253567">Tweet of 2023</a>.


</p><p>
<a name="GD'"></a>
[GD']
C. Lemarechal. Cauchy and the Gradient Method. Doc Math Extra, pp. 251-254, 2012.

</p><p>
<a name="GD''"></a>
[GD'']
J. Hadamard. Memoire sur le probleme d'analyse relatif a Vequilibre des plaques elastiques encastrees. Memoires presentes par divers savants estrangers à l'Academie des Sciences de l'Institut de France, 33, 1908.


</p><p>
<a name="GDa"></a>
[GDa]
 Y. Z. Tsypkin (1966). Adaptation, training and self-organization automatic control systems, 
Avtomatika I Telemekhanika, 27, 23-61. 
<em>On gradient descent-based on-line learning for non-linear systems.</em>

</p><p>
<a name="GDb"></a>
[GDb]
Y. Z. Tsypkin (1971). Adaptation and Learning in Automatic Systems, Academic Press, 1971.
<em>On gradient descent-based on-line learning for non-linear systems.</em>

</p><p>
<a name="GD1"></a>
[GD1]
S. I. Amari (1967).
A theory of adaptive pattern classifier, IEEE Trans, EC-16, 279-307 (Japanese version published in 1965).
<a href="https://people.idsia.ch/~juergen/amari1967.pdf">PDF.</a>
<em>Probably the first paper on using stochastic gradient descent<sup><small><small><a href="#STO51">[STO51-52]</a></small></small></sup> for learning in multilayer neural networks
(without specifying the specific gradient descent method now known as reverse mode of automatic differentiation or backpropagation<sup><small><small><a href="#BP1">[BP1]</a></small></small></sup>).</em>

</p><p>
<a name="GD2"></a>
[GD2]
S. I. Amari (1968).
Information Theory—Geometric Theory of Information, Kyoritsu Publ., 1968 (in Japanese).
<a href="https://people.idsia.ch/~juergen/amari1968p94-135ocr.pdf">OCR-based PDF scan of pages 94-135</a> (see pages 119-120).
<em>Contains computer simulation results for a five layer network (with 2 modifiable layers) which learns internal representations to classify
non-linearily separable pattern classes.</em>

</p><p>
<a name="GD2a"></a>
[GD2a]
H. Saito (1967). Master's  thesis, Graduate School of Engineering, Kyushu University, Japan. 
<em>Implementation of Amari's 1967 stochastic gradient descent method for multilayer perceptrons.<sup><small><small><a href="#GD1">[GD1]</a></small></small></sup> (S. Amari, personal communication, 2021.)</em>

</p><p>
<a name="GD3"></a>
[GD3]
S. I. Amari (1977).
Neural Theory of Association and Concept Formation. 
Biological Cybernetics, vol. 26, p. 175-185, 1977.   
<em>See Section 3.1 on using gradient descent for learning in multilayer networks.</em>

</p><p><a name="HIN"></a>
[HIN] J. Schmidhuber (<a href="https://people.idsia.ch/~juergen/blog.html">AI Blog</a>, 2020). <a href="https://people.idsia.ch/~juergen/critique-honda-prize-hinton.html">Critique of Honda Prize for Dr. Hinton</a>.   <em>Science must not allow corporate PR to distort the academic record. See also <a href="#T22">[T22]</a><a href="#DLP">[DLP]</a><a href="#NOB">[NOB]</a>.</em>



</p><p>
<a name="LEI07"></a>
[LEI07]
J. M. Child (translator), G. W. Leibniz (Author). The Early Mathematical Manuscripts of Leibniz. Merchant Books, 2007. <em>See p. 126: the chain rule appeared in a 1676 memoir by Leibniz.</em>



</p><p>
<a name="LEI10"></a>
[LEI10]
O. H. Rodriguez, J. M. Lopez Fernandez (2010). A semiotic reflection on the didactics of the Chain rule. The Mathematics Enthusiast: Vol. 7 : No. 2 , Article 10. DOI: https://doi.org/10.54870/1551-3440.1191. 


</p><p><a name="MIR"></a>
[MIR] J. Schmidhuber (Oct 2019, updated 2021, 2022, 2025). <a href="https://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html">Deep Learning: Our Miraculous Year 1990-1991.</a> Preprint 
<a href="https://arxiv.org/abs/2005.05744">arXiv:2005.05744</a>. <em>The Deep Learning Artificial Neural Networks (NNs)
of our team have
 revolutionised 
<a href="https://people.idsia.ch/~juergen/deep-learning-history.html">Machine Learning &amp; AI</a>.
Many of the basic ideas behind this revolution were published within the 12 months of our <em>"Annus Mirabilis"</em> 1990-1991 at our lab in TU Munich.
Back then, few people were interested, but a quarter century later, NNs based on our <em>"Miraculous Year"</em>
<a href="https://people.idsia.ch/~juergen/impact-on-most-valuable-companies.html">were on over 3 billion devices,
and used many billions of times per day,
consuming a significant fraction of the world's compute</a>.
In particular, in 1990-91, we laid foundations of Generative AI, publishing principles of  (1) 
<a href="https://people.idsia.ch/~juergen/artificial-curiosity-since-1990.html#sec1">Generative Adversarial Networks</a> for <a href="https://people.idsia.ch/~juergen/artificial-curiosity-since-1990.html">Artificial Curiosity and Creativity</a> (now used for deepfakes), (2) <a href="https://people.idsia.ch/~juergen/fast-weight-programmer-1991-transformer.html">Transformers</a> (the T in ChatGPT—see the <a href="https://people.idsia.ch/~juergen/1991-unnormalized-linear-transformer.html">1991 Unnormalized Linear Transformer</a>),  (3) <a href="https://people.idsia.ch/~juergen/very-deep-learning-1991.html">Pre-training</a> for deep NNs (see the P in ChatGPT), (4)  <a href="https://people.idsia.ch/~juergen/very-deep-learning-1991.html">NN distillation</a> (key for <a href="https://x.com/SchmidhuberAI/status/1885357355938046382">DeepSeek</a>), and (5) recurrent <a href="https://people.idsia.ch/~juergen/world-models-planning-curiosity-fki-1990.html">World Models</a> for
<a href="https://people.idsia.ch/~juergen/deep-learning-history.html#rl">Reinforcement Learning and Planning</a> in partially observable environments. The year 1991 also marks the emergence of the defining features of (6)
<a href="https://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%204">LSTM</a>, the most cited AI paper of the 20th century (based on constant error flow through residual NN connections), and (7) ResNet, the most cited AI paper of the 21st century, based on our LSTM-inspired <a href="https://people.idsia.ch/~juergen/highway-networks.html">Highway Net</a> that was 10 times deeper than previous record-breaking NNs.
</em>


</p><p>
<a name="MLP1"></a>
[MLP1] D. C. Ciresan, U. Meier, L. M. Gambardella, J. Schmidhuber. Deep Big Simple Neural Nets For Handwritten Digit Recognition. Neural Computation 22(12): 3207-3220, 2010. <a href="http://arxiv.org/abs/1003.0358">ArXiv Preprint.</a>
<em>Showed that plain backprop for deep standard NNs is sufficient to break benchmark records, without any unsupervised pre-training.</em>

</p><p>
<a name="MLP2"></a>
[MLP2] J. Schmidhuber
(<a href="https://people.idsia.ch/~juergen/blog.html">AI Blog</a>, Sep 2020). <a href="https://people.idsia.ch/~juergen/2010-breakthrough-supervised-deep-learning.html">10-year anniversary of supervised deep learning breakthrough (2010). No unsupervised pre-training</a>. <em>By 2010, when compute was 100 times more expensive than today, both the feedforward NNs<sup><small><small><a href="#MLP1">[MLP1]</a></small></small></sup> and the earlier recurrent NNs of Schmidhuber's team were able to beat all competing algorithms on important problems of that time.</em>

</p><p>
<a name="MLP3"></a>
[MLP3] J. Schmidhuber
(<a href="https://people.idsia.ch/~juergen/blog.html">AI Blog</a>, 2025). <a href="https://people.idsia.ch/~juergen/2010-end-to-end-deep-learning-breakthrough.html">2010: Breakthrough of end-to-end deep learning (no layer-by-layer training, no unsupervised pre-training). The rest is history.</a>
<em>By 2010, when compute was 1000 times more expensive than in 2025, both our feedforward NNs<sup><small><small><a href="#MLP1">[MLP1]</a></small></small></sup> and our earlier recurrent NNs were able to beat all competing algorithms on important problems of that time. 
This deep learning revolution quickly spread from Europe to North America and Asia.</em>


</p><p><a name="MOST"></a>
[MOST]
J.&nbsp; Schmidhuber (<a href="https://people.idsia.ch/~juergen/blog.html">AI Blog</a>, 2021, updated 2025). <a href="https://people.idsia.ch/~juergen/most-cited-neural-nets.html">The most cited neural networks all build on work done in my labs</a>: <em> 1. <a href="https://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%204">Long Short-Term Memory</a> (LSTM), the most cited AI of the 20th century. 2. ResNet (open-gated <a href="https://people.idsia.ch/~juergen/highway-networks.html">Highway Net</a>), the most cited AI of the 21st century. 3. AlexNet &amp; VGG Net (the similar but earlier <a href="https://people.idsia.ch/~juergen/DanNet-triggers-deep-CNN-revolution-2011.html">DanNet</a> of 2011 <a href="https://people.idsia.ch/~juergen/computer-vision-contests-won-by-gpu-cnns.html">won 4 image recognition challenges</a> before them). 4. GAN (an instance of <a href="https://people.idsia.ch/~juergen/artificial-curiosity-since-1990.html#sec1">Adversarial Artificial Curiosity</a> of 1990). 5. Transformer variants—see the <a href="https://people.idsia.ch/~juergen/1991-unnormalized-linear-transformer.html">1991 unnormalised linear Transformer</a> (ULTRA). Foundations of Generative AI were published in 1991: the principles of  <a href="https://people.idsia.ch/~juergen/deep-learning-history.html#gan">GANs</a> (now used for deepfakes), <a href="https://people.idsia.ch/~juergen/fast-weight-programmer-1991-transformer.html">Transformers</a> (the T in ChatGPT), <a href="https://people.idsia.ch/~juergen/very-deep-learning-1991.html">Pre-training</a> for deep NNs (the P in ChatGPT), <a href="https://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%202">NN distillation</a>, and the famous DeepSeek—see the <a href="https://x.com/SchmidhuberAI/status/1885357355938046382">tweet</a>.</em>


</p><p><a name="NOB"></a>
[NOB] J. Schmidhuber.
A Nobel Prize for Plagiarism. 
<a href="https://people.idsia.ch/~juergen/physics-nobel-2024-plagiarism.html">Technical Report IDSIA-24-24 (7 Dec 2024).</a>
<em>Sadly, the Nobel Prize in Physics 2024 for Hopfield &amp; Hinton is a Nobel Prize for plagiarism. They republished methodologies for artificial neural networks developed in Ukraine and Japan by Ivakhnenko and Amari in the 1960s &amp; 1970s, as well as other techniques, without citing the original papers. Even in later surveys, they didn't credit the original inventors (thus turning what may have been unintentional plagiarism into a deliberate form). None of the important algorithms for modern Artificial Intelligence were created by Hopfield &amp; Hinton. 
See also popular 
<a href="https://x.com/SchmidhuberAI/status/1844022724328394780">tweet1</a>,
<a href="https://x.com/SchmidhuberAI/status/1865310820856393929">tweet2</a>, and
<a href="https://lnkd.in/eS92dg86">LinkedIn post</a>.</em>



</p><p><a name="SV20"></a>
[SV20] S. Vazire (2020). A toast to the error detectors. Let 2020 be the year in which we value those who ensure that science is self-correcting. Nature, vol 577, p 9, 2/2/2020.

</p><p><a name="T20"></a>
[T20] J. Schmidhuber (June 2020). <a href="http://people.idsia.ch/~juergen/critique-turing-award-bengio-hinton-lecun.html">Critique of 2018 Turing Award</a>. 

</p><p><a name="T22"></a>
[T22] J. Schmidhuber (<a href="https://people.idsia.ch/~juergen/blog.html">AI Blog</a>, 2022). 
<a href="https://people.idsia.ch/~juergen/scientific-integrity-turing-award-deep-learning.html">Scientific Integrity and the History of Deep Learning: The 2021 Turing Lecture, and the 2018 Turing Award</a>. Technical Report IDSIA-77-21 (v3), IDSIA, Lugano, Switzerland, 22 June 2022. 




</p><p><a name="R7"></a>
[R7] Reddit/ML, 2019. <a href="https://www.reddit.com/r/MachineLearning/comments/e5vzun/d_jurgen_schmidhuber_on_seppo_linnainmaa_inventor/">J. Schmidhuber on Seppo Linnainmaa, inventor of backpropagation in 1970.</a>

</p><p><a name="R8"></a>
[R8] Reddit/ML, 2019. <a href="https://www.reddit.com/r/MachineLearning/comments/ed7asg/d_jurgen_schmidhuber_on_alexey_ivakhnenko/">J. Schmidhuber on Alexey Ivakhnenko, godfather of deep learning 1965.</a>

</p><p><a name="RUM"></a>
[RUM] DE Rumelhart, GE Hinton, RJ Williams (1985). Learning Internal Representations by Error Propagation. TR No. ICS-8506, California Univ San Diego La Jolla Inst for Cognitive Science. Later version published as:
Learning representations by back-propagating errors. Nature, 323, p. 533-536 (1986).
<em>This experimental analysis of <a href="https://people.idsia.ch/~juergen/who-invented-backpropagation.html">backpropagation</a> did not cite the origin of the method,<sup><small><small><a href="#BP1">[BP1-5]</a></small></small></sup> also known as the reverse mode of automatic differentiation.
The paper also failed to cite 
the first working algorithms for deep learning of internal representations (Ivakhnenko &amp; Lapa, 1965)<sup><small><small><a href="#DEEP1">[DEEP1-2]</a><a href="#HIN">[HIN]</a><a href="#DLH">[DLH]</a></small></small></sup> as well as
Amari's work (1967-68)<sup><small><small><a href="#GD1">[GD1-2]</a></small></small></sup> on learning internal representations in deep nets through stochastic gradient descent.
Even later surveys by the authors<sup><small><small><a href="#DL3">[DL3,3a]</a></small></small></sup> failed to cite the prior art.<sup><small><small><a href="#T22">[T22]</a><a href="#DLP">[DLP]</a><a href="#NOB">[NOB]</a></small></small></sup>
</em>

</p><p>
<a name="S80"></a>
[S80]
B. Speelpenning (1980). Compiling Fast Partial Derivatives of Functions Given by Algorithms. PhD
thesis, Department of Computer Science, University of Illinois, Urbana-Champaign.


</p><p><a name="STO51"></a>
[STO51]
H. Robbins, S. Monro (1951). A Stochastic Approximation Method. The Annals of Mathematical Statistics. 22(3):400, 1951.

</p><p><a name="STO52"></a>
[STO52]
J. Kiefer, J. Wolfowitz  (1952). Stochastic Estimation of the Maximum of a Regression Function. 
The Annals of Mathematical Statistics. 23(3):462, 1952.


</p><p><a name="UN"></a>
[UN]
J. Schmidhuber (<a href="https://people.idsia.ch/~juergen/blog.html">AI Blog</a>, 2021). <a href="https://people.idsia.ch/~juergen/very-deep-learning-1991.html">30-year anniversary. 1991: First very deep learning with unsupervised pre-training. First neural network distillation</a>. <em>Unsupervised hierarchical predictive coding (with self-supervised target generation) finds compact internal representations of sequential data to facilitate downstream deep learning. The hierarchy can be distilled into a single deep neural network (suggesting a simple model of conscious and subconscious information processing). 1993: solving problems of depth &gt;1000.</em>

</p><p>
<a name="UN0"></a>
[UN0]
J.&nbsp; Schmidhuber.
  Neural sequence chunkers.
  Technical Report FKI-148-91, Institut für Informatik, Technische
  Universität München, April 1991.
<a href="https://people.idsia.ch/~juergen/FKI-148-91ocr.pdf">PDF.</a>
 <a href="https://people.idsia.ch/~juergen/very-deep-learning-1991.html">More.</a>



</p><p><a name="UN1"></a>
[UN1] J. Schmidhuber. Learning complex, extended sequences using the principle of history compression. Neural Computation, 4(2):234-242, 1992. Based on TR FKI-148-91, TUM, 1991.<sup><small><small><a href="#UN0">[UN0]</a></small></small></sup> <a href="https://sferics.idsia.ch/pub/juergen/chunker.pdf">PDF</a>. 
 <a href="https://people.idsia.ch/~juergen/very-deep-learning-1991.html">More.</a>

</p><p><a name="UN2"></a>
[UN2] J.  Schmidhuber.  Habilitation thesis, TUM, 1993. <a href="https://sferics.idsia.ch/pub/juergen/habilitation.pdf">PDF</a>.  
<em>An ancient experiment on "Very Deep Learning" with credit assignment across 1200 time steps or virtual layers and unsupervised / self-supervised pre-training for a stack of recurrent NN  
<a href="http://www.idsia.ch/~juergen/habilitation/node114.html">can be found here</a> (depth &gt; 1000).</em>

</p><p><a name="UN3"></a>
[UN3]
J.&nbsp; Schmidhuber, M.&nbsp;C. Mozer, and D.&nbsp;Prelinger.
<a href="https://sferics.idsia.ch/pub/juergen/aachen.ps.gz">
  Continuous history compression.
</a>
  In H.&nbsp;Hüning, S.&nbsp;Neuhauser, M.&nbsp;Raus, and W.&nbsp;Ritschel, editors,
  <em>Proc. of Intl. Workshop on Neural Networks, RWTH Aachen</em>, pages 87-95.
  Augustinus, 1993.


</p><p><a name="UN4"></a>
[UN4]  G. E. Hinton, R. R. Salakhutdinov. Reducing the dimensionality of data with neural networks. Science, Vol. 313. no. 5786, pp. 504—507, 2006.  <a href="http://www.cs.toronto.edu/~hinton/science.pdf">PDF</a>. 
<em>
This work describes unsupervised layer-wise pre-training of stacks of <em>feedforward</em> NNs (FNNs) 
called <em>Deep Belief Networks</em> (DBNs).
However, this work neither cited the original layer-wise training of deep NNs by Ivakhnenko &amp; Lapa (1965)<sup><small><small><a href="#DEEP1">[DEEP1-2]</a></small></small></sup> nor
the 1991 unsupervised pre-training of stacks of more general <em>recurrent</em> NNs (RNNs)<sup><small><small><a href="#UN">[UN0-3]</a></small></small></sup> 
which  introduced
<a href="https://people.idsia.ch/~juergen/very-deep-learning-1991.html">the first NNs shown to solve very deep problems</a>.
The 2006 justification of the authors was essentially the one Schmidhuber used for the 1991 RNN stack: 
each higher level tries to reduce the description length 
(or negative log probability) of the data representation in the level below.<sup><small><small><a href="#HIN">[HIN]</a><a href="#T22">[T22]</a><a href="#MIR">[MIR]</a></small></small></sup>
This can greatly facilitate very deep downstream learning.<sup><small><small><a href="#UN">[UN0-3]</a></small></small></sup> </em>


</p></span></td></tr></tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Road That Killed Legend Jenkins Was Working as Designed (118 pts)]]></title>
            <link>https://www.strongtowns.org/journal/2025/8/18/the-road-that-killed-legend-jenkins-was-working-exactly-as-designed</link>
            <guid>44941766</guid>
            <pubDate>Mon, 18 Aug 2025 15:33:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.strongtowns.org/journal/2025/8/18/the-road-that-killed-legend-jenkins-was-working-exactly-as-designed">https://www.strongtowns.org/journal/2025/8/18/the-road-that-killed-legend-jenkins-was-working-exactly-as-designed</a>, See on <a href="https://news.ycombinator.com/item?id=44941766">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-sqsp-text-block-content="" data-block-type="2" data-sqsp-block="text" id="block-edb6ef0d7c4d2de9458a">
  <p><strong>On May 27, 2025, two brothers in Gastonia, North Carolina, asked their dad if they could walk to the neighborhood Food Lion and Subway.</strong> It was less than ten minutes from their apartment.</p><p>Their dad hesitated. He and his wife are protective parents. But he agreed, on the condition that the boys stay on the phone with him the whole way. They made it to the store and back toward home without incident, until they reached West Hudson Boulevard.</p><p>Legend Jenkins, seven years old, stepped off the median into the road and was struck by an SUV. His father was still on the phone when it happened.</p><p>In the days that followed, the family’s grief deepened into something almost unimaginable. Two days after their son’s death, <a href="https://www.nytimes.com/2025/08/06/opinion/children-traffic-death-parents.html" target="_blank">the district attorney charged both parents with involuntary manslaughter</a>, set bail at $1.5 million each, and placed their surviving six children in the care of relatives.</p><p>I’ve seen pedestrian advocates respond to this case with outrage: “Kids should be able to walk to the store. Parents shouldn’t be criminalized for it.” I understand that impulse. I agree with the sentiment. But when I look at the location where Legend died, I can honestly tell you that nobody — child or adult — should be walking there.</p><p><a href="https://www.google.com/maps/@35.2349131,-81.2038714,17z?entry=ttu&amp;g_ep=EgoyMDI1MDgwNi4wIKXMDSoASAFQAw%3D%3D" target="_blank">West Hudson Boulevard</a> is a high-speed arterial road with narrow sidewalks, a tiny median, and no truly safe crossings. Even a healthy, alert adult is taking their life in their hands by walking to that store. For a child, it’s playing the worst kind of roulette.</p><p>If this were a neighborhood where people regularly fired guns in the air, we would warn parents to keep their kids inside. A stray bullet may not be intentional, but it’s a <a href="https://www.strongtowns.org/journal/2015/6/8/bullets">predictable outcome of such an environment</a>. On West Hudson Boulevard, the stray bullets are motor vehicles, and the result is the same: occasional, random, but entirely foreseeable deaths.</p><p>This wasn’t an “accident” in the sense of something random or unexpected. It was the statistically inevitable outcome of building a place where human life outside of a car has no real value in the design. Humans are, at best, a tiny afterthought. At worst, an annoyance.</p><p>The truth is, <a href="https://www.strongtowns.org/journal/2017/11/1/gross-negligence">everyone who participates in building these places is complicit</a>. Everyone. The planners who approved the land use. The engineers who designed the road geometry. The developers who built apartments near retail without safe connections. The retailers who designed parking-lot entrances instead of pedestrian routes. The public officials who sign off on all of it.</p><p>None of them intended for a child to die here. But if you build an environment that makes random deaths inevitable, the deaths will happen. There is a clear cause. Yet, by the composition and consensus of all involved, none of them can ever be held responsible. Ultimately, if everyone involved is responsible, nobody is responsible.</p><p>But society demands that someone be held accountable. So, when that inevitability came to pass, the system’s first response was to narrow the frame <a href="https://www.strongtowns.org/journal/2025/6/26/when-parents-are-charged-but-the-stroad-is-the-culprit">until blame could be pinned on someone</a>. In this case, that was the parents. That same instinct often points the finger at the driver.&nbsp;</p><p>Yes, the driver is the one who struck Legend. Yes, the parents chose to let him walk. But that doesn’t explain why this road exists in a form that makes a tragedy like this certain to happen again and again and again.</p><p>I’ve spent quite a bit of time looking at this corridor. It is familiar in all the wrong ways. My diagnosis is that this is not a fixable situation, not in any meaningful sense. You can’t slap in a crosswalk, a flashing beacon, or a strip of sidewalk and call it safe. The entire nature of the road — its speed, its function, its relationship to surrounding land uses — is <a href="https://www.strongtowns.org/journal/2025/7/30/annapolis-needs-safe-street-design-not-orange-flags">incompatible with the safe movement of people</a>. That’s unsafe for those both inside and especially outside a motor vehicle.</p><p>And yet, we build more places just like this every day. Everyone knows better, but we do it anyway. When we do, we make an unspoken agreement: some number of people will die here every year. Some number of people will be sacrificed for the sake of a built environment that few professionals really believe is worthy of their energy, expertise, or even their attention.</p><p>We don’t say that part out loud because, if we did, it would force us to confront the morality of our choices. These choices are deeply immoral.</p><p>So we do the next best thing for our consciences: we blame the victims. We prosecute the parents, <a href="https://www.strongtowns.org/journal/2022/3/7/the-reckless-driver-narrative-is-reckless-stop-spreading-it">demonize the driver</a>, or scold the pedestrian for “not being careful.” And in doing so, we avoid indicting the real culprit: the American development culture that produced this environment.</p><p>If we actually wanted to prevent the next Legend Jenkins, we would stop replicating places like West Hudson Boulevard. We would start building neighborhoods where a grocery store, a sandwich shop, and an apartment complex can exist within a short, safe walk of each other. And when tragedies happen, we would put the <em>environment</em> on trial, not the people who got caught in it.</p><p>There is no simple way to fix this street, but there is a way to start fixing the culture that builds places like this. The <a href="https://www.strongtowns.org/crashstudio">Strong Towns Crash Analysis Studio</a> approach looks at every contributing factor in a crash — from sight lines to land use — and makes recommendations to address those shortcomings. It’s not about finding someone to punish, but about having a public conversation that says, “This place killed someone. Here’s why, and here’s how we stop it from happening again.”</p><p>Legend’s death was not a fluke. It was the expected outcome of a system working exactly as designed. Until we confront that reality — and change it — we’re just waiting for the next name to add to the list of unnecessary tragedies.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Counter-Strike: A billion-dollar game built in a dorm room (264 pts)]]></title>
            <link>https://www.nytimes.com/2025/08/18/arts/counter-strike-half-life-minh-le.html</link>
            <guid>44941369</guid>
            <pubDate>Mon, 18 Aug 2025 14:59:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2025/08/18/arts/counter-strike-half-life-minh-le.html">https://www.nytimes.com/2025/08/18/arts/counter-strike-half-life-minh-le.html</a>, See on <a href="https://news.ycombinator.com/item?id=44941369">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2025/08/18/arts/counter-strike-half-life-minh-le.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[95% of AI Pilots Failing (158 pts)]]></title>
            <link>https://fortune.com/2025/08/18/mit-report-95-percent-generative-ai-pilots-at-companies-failing-cfo/</link>
            <guid>44941118</guid>
            <pubDate>Mon, 18 Aug 2025 14:36:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fortune.com/2025/08/18/mit-report-95-percent-generative-ai-pilots-at-companies-failing-cfo/">https://fortune.com/2025/08/18/mit-report-95-percent-generative-ai-pilots-at-companies-failing-cfo/</a>, See on <a href="https://news.ycombinator.com/item?id=44941118">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Good morning. Companies are betting on AI—yet nearly all enterprise pilots are stuck at the starting line.</p><div>



<div><p><em>The GenAI Divide: State of AI in Business 2025</em>, <a href="https://nanda.media.mit.edu/ai_report_2025.pdf" target="_blank" rel="noopener" aria-label="Go to https://nanda.media.mit.edu/ai_report_2025.pdf">a new report</a> published by MIT’s <a href="https://nanda.media.mit.edu/" target="_blank" rel="noopener" aria-label="Go to https://nanda.media.mit.edu">NANDA</a> initiative, reveals that while generative AI holds promise for enterprises, most initiatives to drive rapid revenue growth are falling flat.</p><p>Despite the rush to integrate powerful new models, about 5% of AI pilot programs achieve rapid revenue acceleration; the vast majority stall, delivering little to no measurable impact on P&amp;L. The research—based on 150 interviews with leaders, a survey of 350 employees, and an analysis of 300 public AI deployments—paints a clear divide between success stories and stalled projects.</p><p>To unpack these findings, I spoke with Aditya Challapally, the lead author of the report, and a research contributor to project NANDA at MIT.</p><p>“Some large companies’ pilots and younger startups are really excelling with generative AI,” Challapally said. Startups led by 19- or 20-year-olds, for example, “have seen revenues jump from zero to $20 million in a year,” he said. “It’s because they pick one pain point, execute well, and partner smartly with companies who use their tools,” he added.</p><p>But for 95% of companies in the dataset, generative AI implementation is falling short. The core issue? Not the quality of the AI models, but the “learning gap” for both tools and organizations. While executives often blame regulation or model performance, MIT’s research points to flawed enterprise integration. Generic tools like ChatGPT excel for individuals because of their flexibility, but they stall in enterprise use since they don’t learn from or adapt to workflows, Challapally explained.</p><p>The data also reveals a misalignment in resource allocation. More than half of generative AI budgets are devoted to sales and marketing tools, yet MIT found the biggest ROI in back-office automation—eliminating business process outsourcing, cutting external agency costs, and streamlining operations.



</p></div><h3><strong>What’s behind successful AI deployments?</strong></h3>



<div><p>How companies adopt AI is crucial. Purchasing AI tools from specialized vendors and building partnerships succeed about 67% of the time, while internal builds succeed only one-third as often.</p><p>This finding is particularly relevant in financial services and other highly regulated sectors, where many firms are building their own proprietary generative AI systems in 2025. Yet, <a href="https://nanda.media.mit.edu/ai_report_2025.pdf" target="_blank" rel="noopener" aria-label="Go to https://nanda.media.mit.edu/ai_report_2025.pdf">MIT’s research</a> suggests companies see far more failures when going solo.</p><p>Companies surveyed were often hesitant to share failure rates, Challapally noted. “Almost everywhere we went, enterprises were trying to build their own tool,” he said, but the data showed purchased solutions delivered more reliable results.</p><p>Other key factors for success include empowering line managers—not just central AI labs—to drive adoption, and selecting tools that can integrate deeply and adapt over time.</p><p>Workforce disruption is already underway, especially in customer support and administrative roles. Rather than mass layoffs, companies are increasingly not backfilling positions as they become vacant. Most changes are concentrated in jobs previously outsourced due to their perceived low value.</p><p>The report also highlights the widespread use of “shadow AI”—unsanctioned tools like ChatGPT—and the ongoing challenge of measuring AI’s impact on productivity and profit.</p><p>Looking ahead, the most advanced organizations are already experimenting with agentic AI systems that can learn, remember, and act independently within set boundaries—offering a glimpse at how the next phase of enterprise AI might unfold.



</p></div><p><strong>Sheryl</strong>&nbsp;<strong>Estrada</strong><br><a href="mailto:sheryl.estrada@fortune.com" target="_blank" rel="noreferrer noopener" aria-label="Go to mailto:sheryl.estrada@fortune.com">sheryl.estrada@fortune.com</a></p><h3>Leaderboard</h3><p><b>Michael A. Discenza</b><span> was appointed VP and CFO of </span><a href="https://www.prnewswire.com/news-releases/timken-names-michael-a-discenza-chief-financial-officer-302529485.html" target="_blank" rel="noopener" aria-label="Go to https://www.prnewswire.com/news-releases/timken-names-michael-a-discenza-chief-financial-officer-302529485.html"><span>The Timken Company</span></a><span> (NYSE: TKR), effective immediately. Discenza has 25 years of experience at Timken in roles of increasing responsibility, including the last 10 as VP of finance, and group controller.</span></p><p><b>John Cole</b><span> was appointed CFO of </span><a href="https://www.globenewswire.com/news-release/2025/08/14/3133524/0/en/ELB-Learning-Appoints-John-Cole-as-Chief-Financial-Officer-to-Support-Organization-s-Strategic-Growth.html" target="_blank" rel="noopener" aria-label="Go to https://www.globenewswire.com/news-release/2025/08/14/3133524/0/en/ELB-Learning-Appoints-John-Cole-as-Chief-Financial-Officer-to-Support-Organization-s-Strategic-Growth.html"><span>ELB Learning</span></a><span>, a provider of immersive learning solutions. He brings more than 25 years of experience leading finance and operations for Fortune 100 and 500 companies, according to ELB. Cole aims to strengthen the financial infrastructure to support the company’s next phase of growth.</span></p><h3>Big Deal</h3><div><p>Modern manufacturing relies heavily on connected devices and industrial control systems, which are prime targets for cyberattacks. For protection, manufacturers are increasingly turning to AI to help manage these risks, according to the&nbsp;<a href="https://www.rockwellautomation.com/en-us/capabilities/digital-transformation/state-of-smart-manufacturing.html" target="_blank" rel="noopener" aria-label="Go to https://www.rockwellautomation.com/en-us/capabilities/digital-transformation/state-of-smart-manufacturing.html"><em>State of Smart Manufacturing Report</em></a>&nbsp;by Rockwell Automation, Inc.
</p><p>The report’s findings are based on a survey of more than 1,500 manufacturing leaders across 17 major manufacturing countries. Cybersecurity now ranks among the top external risks, second only to inflation and economic growth. One-third of respondents hold responsibilities spanning both information technology (IT) and operational technology (OT) cybersecurity.
</p><p>Nearly half (48%) of cybersecurity professionals identified securing converged architectures as key to positive outcomes over the next five years, compared to just 37% of all respondents.
</p><p>However, a shortage of skilled talent, training challenges, and rising labor costs remain major hurdles. As manufacturers recruit the next generation, cybersecurity and analytical skills are becoming hiring priorities—reinforcing the need to align technical innovation with human development, according to the report.
</p></div><h3>Going deeper</h3><p>In a new <em>Fortune</em> <a href="https://fortune.com/2025/08/15/black-female-leadership-future-ceos-erased-dei/" target="_self" aria-label="Go to https://fortune.com/2025/08/15/black-female-leadership-future-ceos-erased-dei/">opinion piece</a>,&nbsp;"Future CEOs, erased: the economic cost of losing Black women in the workforce,"&nbsp;Katica Roy, the CEO and founder of the Denver-based Pipeline, a SaaS company, explains&nbsp;the implications of&nbsp;almost <a href="https://www.goodmorningamerica.com/video/124115661" target="_blank" rel="noopener" aria-label="Go to https://www.goodmorningamerica.com/video/124115661">300,000 Black women exited the labor force</a> so far this year—thinning a pipeline that was already too narrow.</p><div><p>"This isn’t a seasonal fluctuation or statistical footnote. It’s a strategic failure with long-term consequences," Roy writes. "Black women have long been a cornerstone of America’s economic engine—driving participation, powering key industries, and anchoring family incomes. Now, that foundation is fracturing. And the fallout is more than short-term—it’s a direct threat to corporate succession planning, innovation, and growth. The U.S. economy has always depended on Black women’s labor. In fact, no group of women in America has historically had <a href="https://www.bls.gov/opub/reports/race-and-ethnicity/2023/" target="_blank" rel="noopener" aria-label="Go to https://www.bls.gov/opub/reports/race-and-ethnicity/2023/">higher labor force participation</a> than Black women."</p></div><h3>Overheard</h3><p><strong>“Every single Monday was called 'AI Monday.' You couldn’t have customer calls, you couldn’t work on budgets, you had to only work on AI projects.”</strong></p><p>—Eric Vaughan, CEO of enterprise software company IgniteTech, told <a href="https://fortune.com/2025/08/17/ceo-laid-off-80-percent-workforce-ai-sabotage/" target="_self" aria-label="Go to https://fortune.com/2025/08/17/ceo-laid-off-80-percent-workforce-ai-sabotage/"><em>Fortune</em> in an interview</a> that he established a mandate: on Mondays, staff could only work on AI. In early 2023, convinced generative AI was an “existential” transformation, Vaughan saw that his team was not fully on board. His ultimate response? He replaced nearly 80% of the staff within a year, according to headcount figures reviewed by <em>Fortune</em>.
</p></div><p>This is the web version of CFO Daily, a newsletter on the trends and individuals shaping corporate finance. <a href="https://www.fortune.com/newsletters/cfodaily?&amp;itm_source=fortune&amp;itm_medium=nl_article_tout&amp;itm_campaign=cfo_daily" target="_self" aria-label="Go to https://www.fortune.com/newsletters/cfodaily?&amp;itm_source=fortune&amp;itm_medium=nl_article_tout&amp;itm_campaign=cfo_daily">Sign up for free</a>.</p></div>]]></description>
        </item>
    </channel>
</rss>