<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 17 Aug 2023 15:00:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Debian Celebrates 30 Years (203 pts)]]></title>
            <link>https://bits.debian.org/2023/08/debian-turns-30.html</link>
            <guid>37160580</guid>
            <pubDate>Thu, 17 Aug 2023 12:31:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bits.debian.org/2023/08/debian-turns-30.html">https://bits.debian.org/2023/08/debian-turns-30.html</a>, See on <a href="https://news.ycombinator.com/item?id=37160580">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>
On Wed 16 August 2023
with tags <a href="https://bits.debian.org/tag/debian.html">debian</a> <a href="https://bits.debian.org/tag/birthday.html">birthday</a> <a href="https://bits.debian.org/tag/debianday.html">debianday</a> <br>

Written by <strong>Jean-Pierre Giraud, Donald Norwood, Grzegorz Szymaszek, Debian Publicity Team</strong><br>


Artwork by <strong>Jeff Maier</strong></p><p>


Translations:
<a href="https://bits.debian.org/2023/08/debian-turns-30-fr.html" hreflang="fr">fr</a>
<a href="https://bits.debian.org/2023/08/debian-turns-30-pl.html" hreflang="pl">pl</a></p></div><div><p><a href="https://bits.debian.org/images/logo-debian-30-years.png"><img alt="Debian 30 years by Jeff Maier" src="https://bits.debian.org/images/logo-debian-30-years-600x600.png"></a></p>
<p>Over 30 years ago the late Ian Murdock
<a href="https://wiki.debian.org/DebianHistory?action=AttachFile&amp;do=get&amp;target=Debian-announcement-1993.txt">wrote</a>
to the comp.os.linux.development newsgroup about the completion of a brand-new
Linux release which he named "The Debian Linux Release".</p>
<p>He built the release by hand, from scratch, so to speak. Ian laid out
guidelines for how this new release would work, what approach the release
would take regarding its size, manner of upgrades, installation procedures; and
with great care of consideration for users without Internet connection.</p>
<p>Unaware that he had sparked a movement in the fledgling F/OSS community, Ian
worked on and continued to work on Debian. The release, now aided by volunteers
from the newsgroup and around the world, grew and continues to grow as one of
the largest and oldest FREE operating systems that still exist today.</p>
<p>Debian at its core is comprised of Users, Contributors, Developers, and
Sponsors, but most importantly, <strong><em>People</em></strong>. Ians drive and focus remains
embedded in the core of Debian, it remains in all of our work, it remains in
the minds and hands of the users of <em><strong>The Universal Operating System</strong></em>.</p>
<p>The Debian Project is proud and happy to share our anniversary not exclusively
unto ourselves, instead we share this moment with everyone, as we come together
in celebration of a resounding community that works together, effects change,
and continues to make a difference, not just in our work but around the world.</p>
<p>Debian is present in cluster systems, datacenters, desktop computers, embedded
systems, IoT devices, laptops, servers, it may possibly be powering the web
server and device you are reading this article on, and it can also be found in
<a href="https://www.zdnet.com/article/to-the-space-station-and-beyond-with-linux/">Spacecraft</a>.</p>
<p>Closer to earth, Debian fully supports projects for accessibility:
<a href="https://blends.debian.org/edu/">Debian Edu/Skolelinux</a> - an operating system
designed for educational use in schools and communities,
<a href="https://wiki.debian.org/DebianScience">Debian Science</a> - providing free
scientific software across many established and emerging fields,
<a href="https://www.debian.org/blends/hamradio/about">Debian Hamradio</a> - for amateur
radio enthusiasts,
<a href="https://www.debian.org/devel/debian-accessibility/">Debian-Accessibility</a> - a
project focused on the design of an operating system suited to fit the
requirements of people with disabilites, and
<a href="https://blends.debian.org/astro/">Debian Astro</a> - focused on supporting
professional and hobbyist astronomers.</p>
<p>Debian strives to give, reach, embrace, mentor, share, and teach with
internships through many programs internally and externally such as the Google
Summer of Code, Outreachy, and the Open Source Promotion Plan.</p>
<p>None of this could be possible without the vast amount of support, care, and
contributions from what started as and is still an all volunteer project.
We celebrate with each and every one who has helped shape Debian over all of
these years and toward the future.</p>
<p>Today we all certainly celebrate 30 years of Debian, but know that Debian
celebrates with each and every one of you all at the same time.</p>
<p>Over the next few days Celebration parties are planned to take place in
Austria, Belgium, Bolivia, Brazil, Bulgaria, Czech Republic, France, Germany
(CCCcamp), India, Iran, Portugal, Serbia, South Africa, and Turkey.</p>
<p>You are of course, invited to join us!</p>
<p>Check out, attend, or form your very own
<a href="https://wiki.debian.org/DebianDay/2023">DebianDay 2023 Event</a>.</p>
<p>See you then!</p>
<p>Thank you, thank you all so very much.</p>
<p>With Love,</p>
<p>The Debian Project</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fusion Foolery (134 pts)]]></title>
            <link>https://dothemath.ucsd.edu/2023/08/fusion-foolery/</link>
            <guid>37159887</guid>
            <pubDate>Thu, 17 Aug 2023 11:12:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dothemath.ucsd.edu/2023/08/fusion-foolery/">https://dothemath.ucsd.edu/2023/08/fusion-foolery/</a>, See on <a href="https://news.ycombinator.com/item?id=37159887">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<div id="attachment_3218"><p><a href="https://dothemath.ucsd.edu/wp-content/uploads/2023/08/nif-llnl.png"><img aria-describedby="caption-attachment-3218" decoding="async" src="https://dothemath.ucsd.edu/wp-content/uploads/2023/08/nif-llnl-300x240.png" alt="" width="300" height="240" srcset="https://dothemath.ucsd.edu/wp-content/uploads/2023/08/nif-llnl-300x240.png 300w, https://dothemath.ucsd.edu/wp-content/uploads/2023/08/nif-llnl-768x614.png 768w, https://dothemath.ucsd.edu/wp-content/uploads/2023/08/nif-llnl-375x300.png 375w, https://dothemath.ucsd.edu/wp-content/uploads/2023/08/nif-llnl.png 800w" sizes="(max-width: 300px) 100vw, 300px"></a></p><p id="caption-attachment-3218">National Ignition Facility at the Lawrence Livermore National Lab</p></div>
<p>Great. The fusion hype is bad enough already. Now its resurgence is going to interrupt the series of posts I’m in the middle of publishing in order for this post to be “timely.”</p>
<p>The first (and much bigger) round of breathless excitement came in December 2022 when the National Ignition Facility (NIF) at the Lawrence Livermore National Lab (LLNL) announced a (legitimate) breakthrough in achieving fusion: more energy came out of the target than laser energy injected.</p>
<p>At the time, I brushed it off without even reading any articles because I already knew about the NIF’s purpose and limitations, and a few headlines told me everything I needed to know. Who cares how much <em>laser</em> energy went in: how much energy went into <em>creating</em> the laser energy? The laser I used for lunar ranging took 5 kW from the wall plug and delivered 2 W of laser power for a dismal 0.04% efficiency. Such is the cost for shaping ultra-brief pulses: lots of energy is thrown away. The headlines were clearly overblown.</p>
<p>Enough students in my energy class in Spring 2023 asked about the fusion breakthrough (doesn’t that mean we’re done?) that I dug into the details. Even so, I still deemed it unworthy of writing up as a post. But a few days ago, my friend asked me if I was excited about the recent fusion news. I hadn’t heard a peep, but after searching I found a new round of articles based on a second “net gain” laser shot and realized I probably ought to put out a quantitative post on the matter, reminiscent of my blogging origins.</p>
<p>In the end, the NIF fusion accomplishment might be called a stunt.&nbsp; Stunts explore what we <em>can</em> do (often after an insane amount of preparation, practice, and failure), rather than what’s practical.&nbsp; Stunts hide the pains and present an appearance of ease and grace, but it’s a show.</p>
<p>Quantitatively, it’s as if you spot a slot machine in a casino that looks very promising. You’re dying to play, because it just feels right—mysteriously appealing to your sense of self. It calls to you. You notice that it takes $2 tokens, but you have none. You go to the window to purchase a token, and are shocked to learn that one $2 token costs $400. Not wanting to look like an uninformed fool, you gulp and buy the token. This slot machine had better live up to its promise! You pull the lever, and surprise! You actually <em>do</em> win! You put in a $2 token and the machine makes very happy noises and flashes lots of lights as it spits out…$3 (and some neutrons, oddly). Queue the headlines! Want to play again?&nbsp; Actually, this wasn’t your first shot: just the first success after years of trying (but hush!).</p>

<h2>Energetics</h2>
<p>That’s the essence of the story. The December announcement indicated that they launched 2.05&nbsp;MJ of laser energy onto the target sphere, and 3.15&nbsp;MJ came out. The recent articles indicate a second “score,” but fail to give energy specifics, other than “more” energy out. I am assuming an incremental bump, still under 4&nbsp;MJ—otherwise the factor of improvement would be prominently touted in the coverage.</p>
<p>Let’s pause to say: well done! Honestly. No sarcasm. What they did was ridiculously hard, and it finally worked after more than a decade of trying. They actually produced a significant number of fusion events! There’s no faking that, and I’d like to see you try. So let’s be clear that I’m not knocking the accomplishment in itself. My major beef is how we interpret the implications for society. To be fair, the scientists did not supply the hype. They didn’t have to: the rest of the universe was more than ready to fill in that yawning gap.</p>
<p>As I scanned articles from December 2022, most were about the triumph, a reminder that the sun works by fusion, and talk about being the first major step toward limitless clean energy. That’s what people want to hear. It plays right into our cultural mythology: humans defy all limits through ingenuity and technology. Build a story around that theme, and you’ve got yourself some guaranteed click-bait.</p>
<p>A <em>very</em> few articles mentioned the energetic price of generating the laser pulse. In particular, I found <a href="https://www.theatlantic.com/technology/archive/2022/12/department-of-energy-nuclear-fusion-breakthrough-nif-livermore/672439/" target="_blank" rel="noopener">one in The Atlantic</a> by Charles Seife:</p>
<blockquote><p>The “more energy out than laser energy in” equation masks several fundamental problems. NIF’s doped glass lasers have an efficiency of about 0.5 percent, meaning that they would have sucked in roughly 400 megajoules of energy from the grid in order to produce the 2.1 megajoules of light energy…</p></blockquote>
<p>The second was a <a href="https://bigthink.com/the-future/fusion-power-nif-hype-lose-energy/" target="_blank" rel="noopener">Big Think article</a> by Tom Hartsfield.</p>
<blockquote><p>The laser energy delivered to the target was 2.05 MJ, and the fusion output was likely about 3.15 MJ. According to multiple sources on NIF’s website, the input energy to the laser system is somewhere between 384 and 400 MJ.</p></blockquote>
<p>And that’s just the laser energetics. The whole facility consumes scads more for countless other purposes. According to the <a href="https://lasers.llnl.gov/about/faqs" target="_blank" rel="noopener">LLNL NIF FAQs</a> (are you letting me get away with a triple acronym?),</p>
<blockquote><p>NIF’s 192 powerful laser beams, housed in a <b>10-story building</b> the size of <b>3 football fields</b>, can deliver more than 2 million joules of ultraviolet laser energy in billionth-of-a-second pulses onto a target about the size of a pencil eraser.</p></blockquote>
<p>The emphasis is mine, to highlight the point that this is a massive laser and facility. It’s like ten Walmart superstores stacked on top of each other. The lighting <em>alone</em> is likely taking tens of kilowatts, which could hypothetically be run for less than a minute on the energy gain from the fusion pop.&nbsp; It would be fun to count all the megajoules that went into press coverage of the event!</p>
<h2>Power Plant Energetics</h2>
<p>Let’s connect the 3 MJ output to that of actual power plants, forgetting for a moment the tremendous energy loss represented in getting 3 MJ out from a 400 MJ input. A typical electrical power plant (nuclear, coal, etc.) delivers about 1 GW of electrical power. But it’s a heat engine operating at 30–40% thermodynamic efficiency. So it takes roughly 3 GW of <em>thermal</em> energy to export 1&nbsp;GW as electricity. 3&nbsp;GW is 3&nbsp;GJ per second, or 3,000&nbsp;MJ per second.</p>
<p>The same efficiency factor would apply to a putative fusion plant. The concept behind fusion power is that it’s <em>just</em> another thermal source—an excruciatingly elaborate way to boil water to make steam to drive a turbine to run a generator. So our 3&nbsp;MJ would need to be replicated 1,000 times per second to amount to 3&nbsp;GW.</p>
<p>Laser repetition rates can be all over the map. 1,000 Hz is not in itself unusually fast by any stretch. What is the repetition rate of the NIF laser? Handily, LLNL <a href="https://lasers.llnl.gov/for-users/nif-target-shot-metrics" target="_blank" rel="noopener">provides these statistics</a>. The average since 2015 is 377 shots per year, with a high of 417 and a low of 327. That’s about a shot per day—or two on a good day. It’s only 100 million times shy of 1 kHz. Oh dear.</p>
<h2>Economics</h2>
<p>An <a href="https://thebulletin.org/2022/12/the-energy-departments-fusion-breakthrough-its-not-really-about-generating-electricity/" target="_blank" rel="noopener">interview</a> of physicist Bob Rosner in the Bulletin of Atomic Scientists helpfully puts the NIF in context (it’s not about societal energy). In it, he reinforces some of what we’ve covered, and adds some financial detail.</p>
<blockquote><p>This facility can do one shot a day; this is at slightly more than two megajoules (of output). For an energy source, it would have to do the same thing at least 10 times a second. If you ask, “Do the lasers exist that can do this?” Not in your dream. The pellet cost a bit over $100,000 to manufacture.</p></blockquote>
<p>The 10 shots per second, I gather, is if the fusion yield could be improved by a couple orders of magnitude—approaching actual break-even. At $100,000 per (literal) pop, and even just ten shots per second, we’re talking a cool million dollars per second!</p>
<p>Let’s wave a magic wand for a minute and say that the 400 MJ input produced a 700 MJ output for a net of 300 MJ: 100 times the recent breakthrough. This accords with the ten shots per second mentioned above. What is the price of the delivered electricity? After thermodynamic inefficiency is accounted, we get 100 MJ out for $100,000 cost, or $1,000 per megajoule. We are accustomed to using the kilowatt-hour (kWh) as a measure of delivered energy, which is 3.6 MJ. The cost becomes, then, $3,600 per kWh. Typical electricity costs are in the neighborhood of $0.15–0.20 per kWh, so we’re dealing with a cost that is 20,000 times higher than nominal. And don’t forget, we used a magic wand to even get there. It’s closer to 2 million times more expensive currently, and as a net energy loser to boot.</p>
<p>Granted, the research and development phase is not characteristic of operational costs. But try knocking on a venture capitalist’s door and making the argument that you can trim costs to 0.005% of their current amount. Slam!</p>
<p>This massive reduction, incidentally, translates to a cost of $5 per pellet. I don’t care what mass-production slave labor you might dream of employing. A cryogenic hydrogen-ice target made to demanding precision specifications, containing deuterium and transmuted lithium (to make tritium) is not going to cost $5. You lost me at cryogenic. Also, they would have made many pellets by now and I’m sure don’t relish spending $100,000 each. If they’re clever enough to accomplish fusion, they would be clever enough to have already reduced costs dramatically if it were straightforward.</p>
<h2>Fusion Efficiency</h2>
<p>Here’s the part where I earn my keep as a physicist translating technical matters. I found details about the NIF targets in a <a href="https://www.tandfonline.com/doi/abs/10.13182/FST10-3697" target="_blank" rel="noopener">2017 paper</a> by Bernard Koziokiemski et al. The abstract alone clarifies much. The target is a shell of hydrogen ice 75 μm thick on a 1 mm radius sphere, cooled below 19 K. Pause for a moment to contemplate the challenges that would be involved if trying to maintain the targets at such low temperatures in a 3 GW power plant “furnace” environment.</p>
<p>Hydrogen ice has a density of 86&nbsp;kg/m<sup>3</sup>, which in the specified volume (10<sup>−9</sup>&nbsp;m<sup>3</sup>) translates to 5×10<sup>19</sup> lattice sites (nuclei/atoms). Deuterium/tritium ice has a higher density than hydrogen ice, but the atomic spacing is unchanged so that the pure hydrogen calculation gives the correct number.</p>
<p>How many fusion events took place to crank out 3&nbsp;MJ of energy? Each deuterium–tritium fusion event releases 17.6&nbsp;MeV of energy, or 2.8×10<sup>−12</sup>&nbsp;J. Calling this 3×10<sup>−12</sup>&nbsp;J (among friends; makes for easy math), we find that we need 10<sup>18</sup> fusion events to amount to 3 MJ. Each event involves 2 nuclei. We calculated above that the shell contains 50×10<sup>18</sup> nuclei, meaning that 4% of them participated in fusion.</p>
<p>This event therefore produced a 4% yield. I’m actually very impressed! That’s nothing to sneeze at. The laser-induced implosion is very fast, very violent, and leaves lots of room for nuclei failing to “find” each other if not compressed almost flawlessly and symmetrically to sub-micron scale. Before doing the calculation, I might have guessed a yield orders-of-magnitude smaller.</p>
<p>So this news is both good and bad. Hats off for cracking into single-digit yield! But that leaves less room to improve. Even at 100% efficiency, we’d get just 25 times more energy out, or 75&nbsp;MJ. That’s still not enough to pay for the price of admission (400&nbsp;MJ, just for the laser part).</p>
<h2>NIF Purpose</h2>
<p>This avenue, therefore, seems painfully far away from achieving practical societal energy. Even 100% yield (for the present design) could not produce net energy. Even if it <em>could</em> produce net energy, the laser repetition rate is a million times too slow. And then, even if the laser could fire fast enough, the cost of each target is prohibitively high by over four orders-of-magnitude.</p>
<p>Then, we have a raft of practical considerations for turning an experimental facility into a functional power plant. No design exists at present to extract the heat produced at NIF. That’s not what it’s for—it wouldn’t make any sense to put effort in that direction.&nbsp; Such a design would have the unenviable thermal challenge of delivering cryogenic targets into a hellfire-hot environment. For energy extraction, tokamak designs like ITER are less unsuitable.&nbsp;&nbsp; In either case, all this to boil water. Bless their hearts.</p>
<p>But the NIF was never “about” societal energy. Its primary purpose is nuclear weapons research. This pesky thing called the nuclear test ban treaty means we can’t just go around detonating nuclear bombs whenever we feel like it. Surely we did not run out of South Pacific island paradises to blow to smithereens. The NIF allows study of matter at extremely high energy density. Other targets besides deuterium–tritium can be placed in the converging laser beams. Essentially, we can create the unbelievably hot conditions relevant to nuclear detonations in the safety of our own national lab.</p>
<p>Inertial confinement fusion (ICF) constitutes a small fraction of <a href="https://lasers.llnl.gov/for-users/nif-target-shot-metrics" target="_blank" rel="noopener">NIF’s laser shots</a>. Most of the work is labeled HED for high-energy-density research. The people at NIF are under no false impression about the potential of this type of approach for generating societal energy. They know what they’re about. At the same time, why not poke? It certainly has some benefits in terms of public attention, translating to funding.</p>
<h2>How Embarrassing</h2>
<p>So what can we say about the public reaction to this news? Headlines in December gushed about the dawn of a new era of limitless energy. People got excited. Many of my students came away thinking it was basically a done deal—now just a matter of putting into practice. That’s how it works in entertainment: a genius breakthrough followed by immediate implementation free of complication. The emphasis is on human ingenuity, not on physical reality. In my experience, ideas are a dime-a-dozen. The hard part is coming up with an idea that can be practically brought to fruition.</p>
<p>I often encounter a disconnect on matters of this sort when interacting with people—whether about space colonization, fusion, renewable energy, or prospects for modernity’s continuation. I frequently find myself outnumbered. Why am I so negative about these things? The disconnect might have something to do with how information is received and processed. If all I had to go on were popular media accounts, word-of-mouth, and entertainment, I’d probably be similarly miscalibrated. But my background, training, experiences, and accomplishments enable an uncommon approach that is less dependent on what other people are saying, and more strongly tied to the underlying drivers. That’s not to say I’ll always have a more accurate take, but just that my process generally involves more independent thought and analysis than I suspect it does for most people.&nbsp; I’m no fun at parties.</p>
<p>In any case, the public reaction to the fusion story tells me a lot about our collective psychology. To me, it speaks to a sense of desperation. I think people sense that the “bad news” side of the ledger is overcrowded of late, and it’s starting to dawn on people that the future could possibly be worse than the present. This causes a cognitive dissonance in that our cultural narrative is one of progress, growth, and innovation. How can these competing visions be squared? News of fusion has the effect of temporarily permitting people to shed the anxiety and embrace the dream all the more strongly. Words that come to mind are: embarrassing, pathetic, humiliating.</p>
<p>What if you see a movie star across the street, overcome by excitement as they stop, look at you, and wave enthusiastically. You, of course, wave back. They <em>see</em> you. They recognize you as special, just as you knew all along. Only, it then becomes apparent that their movie star fling (according to the tabloids) was passing behind you. Now how do you feel? How could you fall for it? That’s the question I find myself asking about the fusion hype. It’s so obviously far from relevant, how could we (and the media establishment) fall for it?</p>
<p>My suspicion is that it plays perfectly into our culture’s irrational hopes and dreams. We have a weak spot in our armor for things that sound too good to be true. We want to believe the narrative (mythology) that humans are exempt from all limits, and that our ingenuity will save the day every time. We want to believe that the movie star would adore us, if only they got the chance to meet us.&nbsp; Instant besties!</p>
<p>Many in our culture truly believe in “the amazing future,” uncritically extrapolating our fossil-fueled joy ride into ever-more impressive innovations and technologies. Of course we will someday roam the galaxy. Of course we will have warp drive (how else would we roam the galaxy?). Of course fusion is a necessary stepping stone on this path. It’s silly to imagine warp drive and teleportation without first cracking fusion. So societal fusion power <em>has</em> to happen, in their imaginations.</p>
<p>The problem is that such imaginings are not tethered to physical reality. They are driven by ideology, or I would say mythology. The physical reality is that we are living in an ecologically, evolutionarily untested paradigm that is very recent (on relevant timescales) and powered by patently unsustainable practices and resource use. The cost is rapid ecological degradation and global disruption to the biosphere. It seems quite clear that the track we are on does not lead to the stars, but to ignominious self-termination of this whacky mode called modernity. It simply does not add up, once the mythology is stripped away. The venture capitalist of nature is about to slam the door on our faces.</p>
<p>Hits: 20256</p>			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We've Teamed Up with Mullvad VPN to Launch the Mullvad Browser (102 pts)]]></title>
            <link>https://blog.torproject.org/releasing-mullvad-browser/</link>
            <guid>37159744</guid>
            <pubDate>Thu, 17 Aug 2023 10:51:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.torproject.org/releasing-mullvad-browser/">https://blog.torproject.org/releasing-mullvad-browser/</a>, See on <a href="https://news.ycombinator.com/item?id=37159744">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Today we announced the launch of the Mullvad Browser, a browser built by the Tor Project team and distributed by <a href="https://mullvad.net/browser">Mullvad</a>.</p>
<p>Mullvad and the Tor Project have been part of the same community that is dedicated to developing technology that prioritizes protecting people's right to privacy for many years now. Mullvad contributes to the Tor Project at the highest level of membership, Shallot, and were a founding member of the Tor Project's Membership Program. They approached us to help them develop their browser because they wanted to leverage our expertise to create a product that is built on the same principles and with similar safety levels as the Tor Browser&nbsp;-- but that works independently of the Tor network. The result is the Mullvad Browser, a free, privacy-preserving web browser to challenge the all-too-prevalent business model of exploiting people's data for profit.</p>
<h2>Why use the Mullvad Browser?</h2>
<p>In short: the Mullvad Browser is Tor Browser without the Tor Network -- a browser that allows anyone to take advantage of all the browser privacy features the Tor Project has created. If people want to connect the browser with a VPN they trust, they can easily do so.</p>
<p>Our goal was to give users the privacy protections of Tor Browser without Tor. For instance, the Mullvad Browser applies a "hide-in-the-crowd" approach to online privacy by creating a similar fingerprint for all of its users. The browser's 'out-of-the-box' configurations and settings will mask many parameters and features commonly used to extract information from a person's device that can make them identifiable, including fonts, rendered content, and several hardware APIs. By default, Mullvad Browser has private mode enabled, blocks third-party trackers and cookies, and makes it easy to delete cookies between visiting pages during the same session.</p>
<p>The Mullvad Browser is another option for internet users who are looking for a privacy browser that doesn't need a bunch of extensions and plugins to enhance their privacy and reduce the factors that can accidentally de-anonymize themselves. And unlike other browsers on the market, Mullvad Browser's business model does not rely on capitalizing on users' behavioral data.</p>
<h2>Why collaborate?</h2>
<p>Our mission at the Tor Project is to advance human rights by building technology that protects people's privacy, provides anonymity and helps them bypass censorship. We want to give people options and demonstrate to the world that through partnerships like these, you can create technology with these values in mind.</p>
<p>That is why we jumped at the opportunity to help Mullvad with their browser. We agree with them that demand for a browser that is built to the same standards as Tor Browser exists.</p>
<p>We hope to inspire other tech builders and organizations to take a page out of our playbook --and think of privacy as a 'feature' that can enhance user experience-- and not as an afterthought. This collaboration with Mullvad illustrates that it is possible to build privacy-preserving technology that protects users like ours does together, rather than in competition with each other.</p>
<h2>What does that mean for us and Tor Browser?</h2>
<p>Let's be clear: Tor Browser is here to stay, and we'll continue to iterate and improve on it and our other services. We know that millions of users around the world rely on Tor Browser and other solutions that the Tor Project offers to safely connect to the internet, to browse anonymously online and to circumvent censorship. Therefore Tor Browser will continue to exist.</p>
<p>There are a lot of reasons to continue to maintain and improve Tor Browser, it is still one of the few solutions that provides anonymity online because it funnels traffic through the Tor network. A privacy browser plus the Tor network is a powerful combination and sometimes one of the few options that censored and surveilled users have in their region to freely and safely access the internet. Tor Browser is also a free solution for all, making it an affordable solution for people at risk.</p>
<p>This joint project with Mullvad has brought positive changes to Tor Browser by allowing us to address legacy issues, fix vulnerabilities for Tor Browser and make necessary UX improvements that benefit both Tor and Mullvad Browsers, as well as the global privacy-preserving tech ecosystem. And, over the last five years, the Tor Project has launched a number of <a href="https://wiki.mozilla.org/Security/Tor_Uplift">initiatives to increase adoption of our technologies</a> and made <a href="https://blog.torproject.org/tor-browser-advancing-privacy-innovation/">significant improvements</a> to the usability of our own products. And we are currently working on more to come!</p>
<p>We encourage you to check out the Mullvad Browser and its capabilities. It can be used without Mullvad VPN, although the combination is recommended. If you want to learn more about this partnership, you can visit <a href="https://mullvad.net/browser">Mullvad.net/browser.</a></p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Asteroid crater 520km in diameter buried in southeast Australia, scientists say (148 pts)]]></title>
            <link>https://www.australiangeographic.com.au/topics/science-environment/2023/08/asteroid-crater-520km-in-diameter-buried-deep-in-southeast-australia-scientists-say/</link>
            <guid>37159680</guid>
            <pubDate>Thu, 17 Aug 2023 10:39:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.australiangeographic.com.au/topics/science-environment/2023/08/asteroid-crater-520km-in-diameter-buried-deep-in-southeast-australia-scientists-say/">https://www.australiangeographic.com.au/topics/science-environment/2023/08/asteroid-crater-520km-in-diameter-buried-deep-in-southeast-australia-scientists-say/</a>, See on <a href="https://news.ycombinator.com/item?id=37159680">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-post-id="344878">






<div>
<p><img width="900" height="636" decoding="async" src="https://www.australiangeographic.com.au/wp-content/uploads/2023/08/shutterstock_488993764-900x636.jpg" alt="" loading="eager" srcset="https://www.australiangeographic.com.au/wp-content/uploads/2023/08/shutterstock_488993764-900x636.jpg 900w, https://www.australiangeographic.com.au/wp-content/uploads/2023/08/shutterstock_488993764-500x354.jpg 500w, https://www.australiangeographic.com.au/wp-content/uploads/2023/08/shutterstock_488993764-768x543.jpg 768w, https://www.australiangeographic.com.au/wp-content/uploads/2023/08/shutterstock_488993764-150x106.jpg 150w, https://www.australiangeographic.com.au/wp-content/uploads/2023/08/shutterstock_488993764.jpg 1000w" sizes="(max-width: 900px) 100vw, 900px"></p><p><span>An illustration of a large asteroid entering the Earth's atmosphere.</span>
<span>Image credit: shutterstock</span>
</p>
</div> 


<p>New evidence suggests the world’s largest known asteroid impact structure is buried near the New South Wales town of Deniliquin.</p>


<p><em>Acknowledgment: I’d like to thank my colleague Tony Yeates, who originated the view of the Deniliquin multi-ring structure as an impact structure – and who was instrumental to this work.</em></p>
<p>In <a href="https://www.sciencedirect.com/science/article/abs/pii/S0040195122002487">recent research</a> published by myself and my colleague Tony Yeates in the journal Tectonophysics, we investigate what we believe – based on many years of experience in asteroid impact research – is the world’s largest known impact structure, buried deep in the earth in southern New South Wales.</p>
<p>The Deniliquin structure, yet to be further tested by drilling, spans up to 520 kilometres in diameter. This exceeds the size of the near-300km-wide <a href="https://en.wikipedia.org/wiki/Vredefort_impact_structure">Vredefort</a> impact structure in South Africa, which to date has been considered the world’s largest.</p>
<h2>Hidden traces of Earth’s early history</h2>
<p>The history of Earth’s bombardment by asteroids is largely concealed. There are a few reasons for this. The first is erosion: the process by which gravity, wind and water slowly wear away land materials through time.</p>
<p>When an asteroid strikes, it creates a crater with an uplifted core. This is similar to how a drop of water splashes upward from a transient crater when you drop a pebble in a pool.</p>
<p>This central uplifted dome is a key characteristic of large impact structures. However, it can erode over thousands to millions of years, making the structure difficult to identify.</p>
<p>Structures can also be buried by sediment through time. Or they might disappear as a result of subduction, wherein tectonic plates can collide and slide below one another into Earth’s mantle layer.</p>
<p>Nonetheless, new geophysical discoveries are unearthing signatures of impact structures formed by asteroids that may have reached tens of kilometres across – heralding a paradigm shift in our understanding of how Earth evolved over eons. These include pioneering discoveries of impact “ejecta”, which are the materials thrown out of a crater during an impact.</p>
<p><a href="https://www.sciencedirect.com/science/article/abs/pii/S1387647317300714">Researchers think</a> the oldest layers of these ejecta, found in sediments in early terrains around the world, might signify the tail end of the Late Heavy Bombardment of Earth. The <a href="https://www.sciencedirect.com/science/article/abs/pii/S1387647317300714">latest evidence</a> suggests Earth and the other planets in the Solar System were subject to intense asteroid bombardments until about 3.2 billion years ago, and sporadically since.</p>
<p>Some large impacts are correlated with mass extinction events. For example, the <a href="https://en.wikipedia.org/wiki/Alvarez_hypothesis">Alvarez hypothesis</a>, named after father and son scientists Luis and Walter Alvarez, explains how non-avian dinosaurs were wiped out as a result of a large asteroid strike some 66 million years ago.</p>
<h2>Uncovering the Deniliquin structure</h2>
<p>The Australian continent and its predecessor continent, <a href="https://en.wikipedia.org/wiki/Gondwana">Gondwana</a>, have been the target of numerous asteroid impacts. These have resulted in at least 38 confirmed and 43 potential impact structures, ranging from relatively small craters to large and completely buried structures.</p>
<div><figure><a href="https://images.theconversation.com/files/541853/original/file-20230809-24-hpgo51.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><img decoding="async" src="https://images.theconversation.com/files/541853/original/file-20230809-24-hpgo51.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" alt="" data-old-src="data:image/svg+xml,<svg xmlns=&quot;http://www.w3.org/2000/svg&quot; viewBox=&quot;0 0 0 0&quot;></svg>" data-src="https://images.theconversation.com/files/541853/original/file-20230809-24-hpgo51.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></a><figcaption>This map shows the distribution of circular structures of uncertain, possible or probable impact origin on the Australian continent and offshore. Green dots represent confirmed impact craters. Red dots represent confirmed impact structures that are more than 100km wide, whereas red dots inside white circles are more than 50km wide. Yellow dots represent likely impact structures. <em>Image credit: Andrew Glikson and Franco Pirajno</em></figcaption></figure></div>
<p>As you’ll recall with the pool and pebble analogy, when a large asteroid hits Earth, the underlying crust responds with a transient elastic rebound that produces <a href="https://www.lpi.usra.edu/publications/books/CB-954/CB-954.pdf">a central dome</a>.</p>
<p>Such domes, which can slowly erode and/or become buried through time, may be all that’s preserved from the original impact structure. They represent the deep-seated “root zone” of an impact. Famous examples are found in the Vredefort impact structure and the 170km-wide <a href="https://en.wikipedia.org/wiki/Chicxulub_crater">Chicxulub crater</a> in Mexico. The latter represents the impact that caused the extinction of the dinosaurs.</p>
<p>Between 1995 and 2000, Tony Yeates suggested magnetic patterns beneath the Murray Basin in New South Wales <a href="https://www.aseg.org.au/publications/preview-old">likely represented</a> a massive, buried impact structure. An analysis of the region’s updated geophysical data between 2015 and 2020 confirmed the existence of a 520km diameter structure with a seismically defined dome at its centre.</p>
<p>The Deniliquin structure has all the features that would be expected from a large-scale impact structure. For instance, magnetic readings of the area reveal a symmetrical rippling pattern in the crust around the structure’s core. This was likely produced during the impact as extremely high temperatures created intense magnetic forces.</p>
<p>A central low magnetic zone corresponds to 30km-deep deformation above a seismically defined mantle dome. The top of this dome is about 10km <a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2015GL065345">shallower than the top</a> of the regional mantle.</p>
<p>Magnetic measurements also show evidence of “radial faults”: fractures that radiate from the centre of a large impact structure. This is further accompanied by small magnetic anomalies which may represent igneous “dikes”, which are sheets of magma injected into fractures in a pre-existing body of rock.</p>

<p>Radial faults, and igneous sheets of rocks that form within them, are typical of large impact structures and can be found in the Vredefort structure and the <a href="https://journals.uair.arizona.edu/index.php/maps/article/viewFile/14921/14892">Sudbury impact structure</a> in Canada.</p>
<p>Currently, the bulk of the evidence for the Deniliquin impact is based on geophysical data obtained from the surface. For proof of impact, we’ll need to collect physical evidence of shock, which can only come from drilling deep into the structure.</p>
<h2>When did the Deniliquin impact happen?</h2>
<p>The Deniliquin structure was likely located on the eastern part of the Gondwana continent, prior to it splitting off into several continents (including the Australian continent) much later.</p>
<div><figure><a href="https://images.theconversation.com/files/541858/original/file-20230809-21-qpfxif.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><img decoding="async" src="https://images.theconversation.com/files/541858/original/file-20230809-21-qpfxif.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" alt="" data-old-src="data:image/svg+xml,<svg xmlns=&quot;http://www.w3.org/2000/svg&quot; viewBox=&quot;0 0 0 0&quot;></svg>" data-src="https://images.theconversation.com/files/541858/original/file-20230809-21-qpfxif.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></a><figcaption>The Deniliquin structure was likely created in eastern Gondwana during the Late Ordovician.<em> Image credit: <a href="https://www.nature.com/articles/s41598-022-08941-3#rightslink">Zhen Qiu et al, 2022</a>, <a href="http://creativecommons.org/licenses/by/4.0/">CC BY</a></em></figcaption></figure></div>
<p>The impact that caused it may have occurred during what’s known as the Late Ordovician mass extinction event. Specifically, I think it may have triggered what’s called the <a href="https://www.britannica.com/science/Ordovician-Silurian-extinction">Hirnantian glaciation stage</a>, which lasted between 445.2 and 443.8 million years ago, and is also defined as the <a href="https://www.sciencedirect.com/science/article/abs/pii/S1342937X23000655">Ordovician-Silurian extinction event</a>.</p>
<p>This huge glaciation and mass extinction event <a href="https://www.britannica.com/science/Ordovician-Silurian-extinction">eliminated</a> about 85% of the planet’s species. It was more than double the scale of the <a href="https://en.wikipedia.org/wiki/Alvarez_hypothesis">Chicxulub impact</a> that killed off the dinosaurs.</p>
<p>It is also possible the Deniliquin structure is older than the Hirnantian event, and may be of an early Cambrian origin (about 514 million years ago). The next step will be to gather samples to determine the structure’s exact age. This will require drilling a deep hole into its magnetic centre and dating the extracted material.</p>
<p>It’s hoped further studies of the Deniliquin impact structure will shed new light on the nature of early <a href="https://www.livescience.com/37584-paleozoic-era.html">Paleozoic</a> Earth.</p>
<p><em><a href="https://theconversation.com/profiles/andrew-glikson-2348">Andrew Glikson</a>, Adjunct professor, <a href="https://theconversation.com/institutions/unsw-sydney-1414">UNSW Sydney</a></em></p>
<p><em>This article is republished from <a href="https://theconversation.com/">The Conversation</a> under a Creative Commons license. Read the <a href="https://theconversation.com/new-evidence-suggests-the-worlds-largest-known-asteroid-impact-structure-is-buried-deep-in-southeast-australia-209593">original article</a>.</em></p>
<p><img decoding="async" src="https://counter.theconversation.com/content/209593/count.gif?distributor=republish-lightbox-advanced" alt="The Conversation" width="1" height="1" referrerpolicy="no-referrer-when-downgrade" data-old-src="data:image/svg+xml,<svg xmlns=&quot;http://www.w3.org/2000/svg&quot; viewBox=&quot;0 0 1 1&quot;></svg>"></p>




<div id="read-next-auto">
<h2>Read Next</h2>



</div>

</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Petition to stop France from forcing browsers like Firefox to censor websites (245 pts)]]></title>
            <link>https://foundation.mozilla.org/en/campaigns/sign-our-petition-to-stop-france-from-forcing-browsers-like-mozillas-firefox-to-censor-websites/</link>
            <guid>37158710</guid>
            <pubDate>Thu, 17 Aug 2023 08:23:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://foundation.mozilla.org/en/campaigns/sign-our-petition-to-stop-france-from-forcing-browsers-like-mozillas-firefox-to-censor-websites/">https://foundation.mozilla.org/en/campaigns/sign-our-petition-to-stop-france-from-forcing-browsers-like-mozillas-firefox-to-censor-websites/</a>, See on <a href="https://news.ycombinator.com/item?id=37158710">Hacker News</a></p>
Couldn't get https://foundation.mozilla.org/en/campaigns/sign-our-petition-to-stop-france-from-forcing-browsers-like-mozillas-firefox-to-censor-websites/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[DIY Espresso (2020) (155 pts)]]></title>
            <link>https://www.fourbardesign.com/2020/10/diy-espresso.html</link>
            <guid>37158317</guid>
            <pubDate>Thu, 17 Aug 2023 07:21:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fourbardesign.com/2020/10/diy-espresso.html">https://www.fourbardesign.com/2020/10/diy-espresso.html</a>, See on <a href="https://news.ycombinator.com/item?id=37158317">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-813039102284682133" itemprop="articleBody">
<p><a href="https://1.bp.blogspot.com/-7N0j-9_ormg/X37Igi6afXI/AAAAAAACMzk/gwZFP-032NYxubNN47wMcD7Vws2LfkzxwCLcBGAsYHQ/s1353/Capturewerwer.PNG"><img data-original-height="900" data-original-width="1353" height="426" src="https://1.bp.blogspot.com/-7N0j-9_ormg/X37Igi6afXI/AAAAAAACMzk/gwZFP-032NYxubNN47wMcD7Vws2LfkzxwCLcBGAsYHQ/w640-h426/Capturewerwer.PNG" width="640"></a></p><p><i>The&nbsp;</i><span><i>pièce de résistance.</i></span></p><p><i>EDIT: Whoa looks like <a href="https://hackaday.com/2021/05/15/3d-printing-espresso-parts/" target="_blank">Hackaday found this post</a>! If anyone's interested in learning more about this, I posted this on reddit and answered a bunch of questions <a href="https://www.reddit.com/r/Coffee/comments/mv68gv/photos_designed_and_3d_printed_my_own_manual/" target="_blank">here</a>!</i></p><p>It's been a minute hasn't it? :)</p><p>A lot has changed since the last post (no more drones, moved to a new town, had a kid...), including the dumpster fire that is 2020. As of 7 months ago, the world changed in a completely unexpected way and during quarantine, I found myself craving a completely unexpected thing...</p><p>At <a href="https://www.bresslergroup.com/" target="_blank">Bresslergroup</a>&nbsp;where I work, the office has always had a handful of coffee dorks (I use that term affectionately) and as a result, we have a fairly large amount of coffee production paraphernalia...including an espresso machine.&nbsp;</p><p><a href="https://1.bp.blogspot.com/-Fvpae_UtIgk/X35tJWPkJPI/AAAAAAACMuo/anM5lBHaXNgrXZkBciGCCivSfyl77u5FACLcBGAsYHQ/s2355/81RfdzPfrQL.jpg"><img data-original-height="2025" data-original-width="2355" height="550" src="https://1.bp.blogspot.com/-Fvpae_UtIgk/X35tJWPkJPI/AAAAAAACMuo/anM5lBHaXNgrXZkBciGCCivSfyl77u5FACLcBGAsYHQ/w640-h550/81RfdzPfrQL.jpg" width="640"></a></p><p>I must confess that when we first got the machine, I still thought it was pronounced "expresso" and didn't have a clue about the differences between it and coffee. Over time, I learned the basics of <a href="https://en.wikipedia.org/wiki/Espresso#:~:text=The%20act%20of%20producing%20a,the%20coffee%20at%20high%20pressure." rel="nofollow" target="_blank">pulling a shot</a>, how <a href="https://coffeebros.com/blog/guide-to-coffee-grind-size/" target="_blank">grind profile</a> and bean type affected taste and the actual extraction process...but mostly I just wanted that sweet, syrupy elixir.&nbsp;</p><p>It wasn't until I was completely deprived of my usual mid afternoon caffeine break that I realized how much I missed espresso. I inherited a used <a href="https://amzn.to/30LnP4Z" target="_blank">hand grinder</a> from a friend, bought some specialty beans for the first time in my life from a <a href="https://www.lucid.coffee/" target="_blank">local coffee shop</a>, and proceeded to make pourover each morning using the most jank setup my cheap self could manage:</p><p><a href="https://1.bp.blogspot.com/-c2FIib0OHUs/X35uR5TUFcI/AAAAAAACMu0/Ixx9ry8kEykJ9g-GcqBN-N0fwMB4Ru6kACLcBGAsYHQ/s848/sdfadf.PNG"><img data-original-height="848" data-original-width="724" height="640" src="https://1.bp.blogspot.com/-c2FIib0OHUs/X35uR5TUFcI/AAAAAAACMu0/Ixx9ry8kEykJ9g-GcqBN-N0fwMB4Ru6kACLcBGAsYHQ/w546-h640/sdfadf.PNG" width="546"></a></p><p>Despite how it looks, this setup actually worked really well. Inconvenient? Mildly. Inexpensive? Oh baby, yes. Was I dogged with thoughts about whether or not this method <i>actually</i>&nbsp;brewed good coffee? Day and night.&nbsp;Although this managed to scratch the caffeine itch for at least a month, my overwhelming <a href="https://www.urbandictionary.com/define.php?term=Fomo" target="_blank">FOMO</a> and the fortuitous closing of a local Sur La Table led to the (very cheap) purchase of these two goodies:</p><p><a href="https://1.bp.blogspot.com/-ta16wnitg8c/X35z-KUWpKI/AAAAAAACMvQ/Y8YYI8ppawITJyh7S_31sEutzb--3ObMQCLcBGAsYHQ/s1147/sdfasdfasdfasd.PNG"><img data-original-height="862" data-original-width="1147" height="480" src="https://1.bp.blogspot.com/-ta16wnitg8c/X35z-KUWpKI/AAAAAAACMvQ/Y8YYI8ppawITJyh7S_31sEutzb--3ObMQCLcBGAsYHQ/w640-h480/sdfasdfasdfasd.PNG" width="640"></a></p><p><i>Things are starting to look a little bit more respectable.</i></p><p>I had heard a lot about the much lauded&nbsp;<a href="https://amzn.to/3jKUvmw" target="_blank">AeroPress</a>, especially from <a href="https://www.youtube.com/channel/UCMb0O2CdPBNi-QqPk5T3gsQ" target="_blank">James Hoffmann</a> (a veritable David Attenborough of all things coffee, quite a delight to listen to!) who highly recommends the brewer due to how forgiving it is with producing great coffee, even with subpar technique. After trying it for a few days, I realized I didn't much like the taste of <a href="http://www.craftcoffeeguru.com/immersion-vs-drip-pour-over-coffee-brewing/#:~:text=Immersion%20coffee%20brewing%20is%20any,Clever%20Dripper%20or%20an%20Aeropress.&amp;text=Once%20you're%20ready%2C%20you,cup%20of%20immersion%2Dbrewed%20coffee!" target="_blank">immersion brewing</a> and turned my attention to its much flashier partner, a <a href="https://amzn.to/3dfuut5" target="_blank">Melitta style #2 coffee filter cone</a>. Now I could finally make pourovers for guests without having to apologize for my janky setup.</p><p>None of this was espresso though and despite being cheaper, <a href="https://www.roastycoffee.com/manual-vs-automatic-espresso-machines/#:~:text=Favored%20by%20the%20traditionalists%2C%20manual,needed%20to%20pull%20a%20shot." target="_blank">manual espresso machines</a> like the <a href="https://www.flairespresso.com/product-page/flair-signature-pro-2" target="_blank">Flair</a>&nbsp;and highly regarded <a href="https://www.cafelatstore.com/products/robotpowdercoating" target="_blank">Cafelat Robot</a> were both well out of my budget (I mean c'mon, I spent an embarrassing amount of time at the supermarket debating whether or not I should spend <i>one cent</i>&nbsp;more per filter on unbleached paper vs. bleached paper). I found myself falling deep<i>&nbsp;</i>into the rabbit hole of coffee research, digging up old <a href="https://www.home-barista.com/" target="_blank">Home-Barista</a> forum posts, reading Amazon reviews of products that claimed to make espresso, and binge watching videos on tamping techniques, grinder types, and even roasting coffee. The more I read, the more I realized that the cheapest way to do this was to just to DIY it.</p><p>And so, a week later, this was staring back at me in CAD:</p><p><a href="https://1.bp.blogspot.com/-T-7lOmsbTYA/X36Cx39lp-I/AAAAAAACMvk/u2ZN9dC9mwkmCqqP2F38P1Oai6sYZ7SawCLcBGAsYHQ/s830/proofofconcept.PNG"><img data-original-height="830" data-original-width="634" height="640" src="https://1.bp.blogspot.com/-T-7lOmsbTYA/X36Cx39lp-I/AAAAAAACMvk/u2ZN9dC9mwkmCqqP2F38P1Oai6sYZ7SawCLcBGAsYHQ/w488-h640/proofofconcept.PNG" width="488"></a></p><p><i>Uhhh...what the heck am I looking at?</i></p><p>Maybe I should back up a bit and explain: what exactly <i>is </i>espresso? The short answer is "what comes out when you force nearly boiling water through finely ground coffee beans at very high pressure". For a more eloquent and detailed explanation, read the <a href="https://en.wikipedia.org/wiki/Espresso" target="_blank">wiki article</a>. It's what's served in Italy when you ask for coffee or "un caffè por favore" because that's where it originated (<a href="https://italyexplained.com/italian-coffee-what-you-need-to-know/" target="_blank">fun fact, if you sit down instead of waiting at the bar for your espresso, you'll be charged more</a>). It's fuller bodied, more intense, and arguably more flavorful than regular 'ol coffee and requires the aforementioned special (read: expensive) equipment to produce. </p><p><a href="https://cdn.shopify.com/s/files/1/2425/8607/articles/Bottomless-Portafilter-Espresso-Extraction-Detail_23462530-15d2-487c-98e0-4d69f12b278d_2400x.jpg?v=1563398660"><img data-original-height="533" data-original-width="800" height="427" src="https://cdn.shopify.com/s/files/1/2425/8607/articles/Bottomless-Portafilter-Espresso-Extraction-Detail_23462530-15d2-487c-98e0-4d69f12b278d_2400x.jpg?v=1563398660" width="640"></a></p><p><i>Mmmm doesn't that just look </i>so<i>&nbsp;good?</i></p><p>The key to good espresso is the high pressure (among other things). Specifically almost 9x atmospheric pressure, or about 131 psi. For reference, your car tires are (only) filled to <b>30-35</b> psi! Most <a href="https://coffeemachinewarehouse.com.au/wp-content/uploads/2020/01/La-Marzocco-Linea-Classic-7.jpeg" target="_blank">semi-automatic espresso machines like the one in your local coffee shop</a> use high pressure water pumps to hit that pressure. Manual machines like the ones I talked about above need even more effort by requiring the user to manually press down on levers with moderate to high force to generate the same pressures. See below:</p>
<p><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" frameborder="0" height="315" src="https://www.youtube.com/embed/11ZSXVZbQbA?start=399" width="560"></iframe></p><p>High pressure, high forces, long lever arms...all of that meant heavy and strong (read: expensive) parts which I was not looking forward to having to fabricate. Instead, I settled on the simpler idea of harnessing the power of compressed gas. Instead of using a high <a href="https://en.wikipedia.org/wiki/Mechanical_advantage" target="_blank">mechanical advantage</a> lever to push a piston, compressed CO2 would be dispensed from a small and inexpensive <a href="https://cdn.shopify.com/s/files/1/0080/1131/7305/products/Threaded_16g_Co2_Cartridge_1024x1024.jpg?v=1530133590" target="_blank">12g or 16g cartridge</a> which would then generate the requisite pressure to properly extract espresso. This concept is not actually novel; both an&nbsp;<a href="https://www.kickstarter.com/projects/1930097708/sippy-espresso-maker-on-the-go?ref=discovery" target="_blank">unsuccessful kickstarter</a> and a <a href="https://www.home-barista.com/reviews/mypressi-twist-second-look-t12595.html" target="_blank">now-defunct handheld espresso maker</a> (with a <a href="https://mypressi.com/" target="_blank">fanatical user base</a>) employed this mechanism. <i>(EDIT: See the end of this post regarding concerns about CO2 potentially affecting flavor)</i></p><p>What about the brew chamber? Well, in <a href="https://www.instructables.com/How-to-Make-a-Lever-Espresso-Machine/" target="_blank">some lever designs</a>&nbsp;which use conventional portafilter baskets and handles, the water chamber is separate by necessity which leads to more parts. I really loved the design of the <a href="https://www.cafelatstore.com/products/robot-basket" target="_blank">Cafelat Robot basket</a>, which holds <i>both</i> the water and the coffee grounds in a very simple setup that requires no preheating. Inspired by the <a href="http://www.francescoceccarelli.eu/Macchine/Faema/baby_faemina/baby_v.1.0_verde_215_eng.htm" target="_blank">Faema Baby</a> lever machine from the 1960s, this setup, though unconventional, has a <i>very </i>loyal following. Just read all <a href="https://www.home-barista.com/levers/cafelat-robot-user-experience-t54550.html" target="_blank">2,834 posts</a> on the Home-Barista forum for yourself.&nbsp;</p><p><a href="https://1.bp.blogspot.com/-CKF2tNqINcE/X36cSiIsqEI/AAAAAAACMv4/gkSaN2_3bGMdP822JPzKtov1JWCoB3l6QCLcBGAsYHQ/s1633/explodedview.PNG"><img data-original-height="1022" data-original-width="1633" height="400" src="https://1.bp.blogspot.com/-CKF2tNqINcE/X36cSiIsqEI/AAAAAAACMv4/gkSaN2_3bGMdP822JPzKtov1JWCoB3l6QCLcBGAsYHQ/w640-h400/explodedview.PNG" width="640"></a></p><p><i>Here's a confusing diagram to clear things up.</i></p><p>Seeing how the coronavirus was wreaking havoc on international shipping, I could not get my hands on a Robot basket cheaply and opted for an inexpensive&nbsp;<a href="https://amzn.to/3nsV72t" target="_blank">Mr. Coffee 4 cup basket</a>&nbsp;to just prove out the concept. The Top and Bottom caps were 3D printed at 100% <a href="https://all3dp.com/2/infill-3d-printing-what-it-means-and-how-to-use-it/#:~:text=Infill%20is%20simply%20a%20repetitive,an%20otherwise%20empty%203D%20print.&amp;text=In%20addition%20to%20filling%20the,depending%20on%20the%20material%20used." target="_blank">infill</a> and the gasket was cut out of some silicone I had laying around (really, it was an old silicone iPad case but who's keeping track here?).&nbsp;</p><p>The first time I tried pulling a shot was quite a disaster.</p><p><a href="https://1.bp.blogspot.com/-lfoIoWF9020/X36jcMTmmPI/AAAAAAACMwE/u-k5cV_ypF0EX32pk3XyKO4fQywa5QgZQCLcBGAsYHQ/s1173/proofofdisaster.PNG"><img data-original-height="876" data-original-width="1173" height="478" src="https://1.bp.blogspot.com/-lfoIoWF9020/X36jcMTmmPI/AAAAAAACMwE/u-k5cV_ypF0EX32pk3XyKO4fQywa5QgZQCLcBGAsYHQ/w640-h478/proofofdisaster.PNG" width="640"></a></p><p><i><p><i>Ah, I see the jank is back.</i></p></i></p><p>Let's just say what came out was <i>vaguely reminiscent </i>of espresso. I didn't drink it all but the taste was somewhere between very strong <a href="https://en.wikipedia.org/wiki/Moka_pot" target="_blank">moka pot</a> coffee and true espresso. Not quite what I was expecting but not a complete failure either? Further development would require better parts but with no end in sight to the coronavirus or its effects on international shipping, I decided to shelve this project.</p><p><a href="https://1.bp.blogspot.com/-mUhQ9gUoxww/X36lCZnO6ZI/AAAAAAACMwQ/blUiBaSAcdgSWvzXAnI41rt7LlO0VqdWwCLcBGAsYHQ/s1058/espressototype.PNG"><img data-original-height="596" data-original-width="1058" height="360" src="https://1.bp.blogspot.com/-mUhQ9gUoxww/X36lCZnO6ZI/AAAAAAACMwQ/blUiBaSAcdgSWvzXAnI41rt7LlO0VqdWwCLcBGAsYHQ/w640-h360/espressototype.PNG" width="640"></a></p><p><i>One of the aforementioned coffee dorks from work. &lt;3</i></p><p>Eventually (months later), a <a href="https://prima-coffee.com/parts/cafelat/pro-basket-robot-cafel-sp" target="_blank">US based retailer</a> restocked their Robot baskets and after a couple days, I had these beautiful pieces of stainless steel in hand and got to designing right away.</p><p><a href="https://1.bp.blogspot.com/-_lu07Na4-9c/X36ojx7U5LI/AAAAAAACMwg/ySmR61nZTiIky8285IZBZJXuO1g-nEEfgCLcBGAsYHQ/s1242/yaypartsfinally.PNG"><img data-original-height="929" data-original-width="1242" height="478" src="https://1.bp.blogspot.com/-_lu07Na4-9c/X36ojx7U5LI/AAAAAAACMwg/ySmR61nZTiIky8285IZBZJXuO1g-nEEfgCLcBGAsYHQ/w640-h478/yaypartsfinally.PNG" width="640"></a></p><p><i><p><i>The most expensive part of this project so far...at $25. Yes, I know I'm cheap.</i></p></i></p><p>My first pass at version 2 implemented some very necessary upgrades for usability. In lieu of the cheapo harbor freight clamps, 3x <a href="https://www.mcmaster.com/shoulder-bolts" target="_blank">shoulder bolts</a> were integrated to act as a bayonet mount of sorts. The face seal in the proof of concept was swapped out for a piston V-ring seal to avoid the need for excessive clamping forces to maintain sealing.&nbsp;</p><p><a href="https://1.bp.blogspot.com/-Yo3ezE5SwbI/X36t6LdSxUI/AAAAAAACMxA/_MKv1-Z7-ZkrIxiRPNgHDA9sA-HVd_fnACLcBGAsYHQ/s1797/version2.PNG"><img data-original-height="1049" data-original-width="1797" height="374" src="https://1.bp.blogspot.com/-Yo3ezE5SwbI/X36t6LdSxUI/AAAAAAACMxA/_MKv1-Z7-ZkrIxiRPNgHDA9sA-HVd_fnACLcBGAsYHQ/w640-h374/version2.PNG" width="640"></a></p><p><i>Starting to look promising...</i></p><p>Both top and bottom parts were to be machined out of stainless steel (lower thermal conductivity than aluminum) from a vendor I often use in China who can <a href="https://en.wikipedia.org/wiki/Numerical_control" target="_blank">CNC</a> parts for ridiculous prices. The design was optimized for cost, with minimal need for <a href="https://www.cnclathing.com/guide/what-is-a-cnc-fixture-how-to-select-right-cnc-fixtures-or-clamps-cnclathing" target="_blank">refixturing</a>. I shot the parts off for quote and received this back a day later:</p><p><a href="https://1.bp.blogspot.com/-VQn7O450BXc/X36v8MmoOuI/AAAAAAACMxM/AH0uBtyRoiMiWGBGTXu3DC8XGj-3mkv_gCLcBGAsYHQ/s1738/rfq.PNG"><img data-original-height="1078" data-original-width="1738" height="396" src="https://1.bp.blogspot.com/-VQn7O450BXc/X36v8MmoOuI/AAAAAAACMxM/AH0uBtyRoiMiWGBGTXu3DC8XGj-3mkv_gCLcBGAsYHQ/w640-h396/rfq.PNG" width="640"></a></p><p>In case it's not immediately obvious, custom CNC parts from stainless steel for only $102 is insane. A US vendor would surely have charged at least 4x as much. Is it cheap? You betcha. Is it cheap enough for this cheapskate <i>(thumbs pointing at self)</i>? No way. After accepting the fact that my aversion to spending money was almost certainly going to cost me more in time, I resignedly began to work on version 3 which needed to be something I could 3D print for "free".</p><div><p><a href="https://1.bp.blogspot.com/-l69xLBw0hq4/X36pKclgg8I/AAAAAAACMwo/hBmA4YNHXQkEyfwyTNBqb6lcxBLilohQQCLcBGAsYHQ/s1242/coffeegodlookingon.PNG"><img data-original-height="931" data-original-width="1242" height="480" src="https://1.bp.blogspot.com/-l69xLBw0hq4/X36pKclgg8I/AAAAAAACMwo/hBmA4YNHXQkEyfwyTNBqb6lcxBLilohQQCLcBGAsYHQ/w640-h480/coffeegodlookingon.PNG" width="640"></a></p><p><i>There's something delightfully meta about designing coffee gear while listening to the hoffMan himself.</i></p><p>Eventually, this is what I landed on: a 4-bolt "bayonet mount", small diameter gas channels (to minimize dead volume), a separate relief valve to depressurize the chamber and prevent it from exploding if overpressurized, and of course the same gas dispensing system as before.</p><p><a href="https://1.bp.blogspot.com/-3bEcwOul6ug/X367OQxBufI/AAAAAAACMxk/Y9FX76CWWwEdILsKKflZovcUbo1jPwTrACLcBGAsYHQ/s1565/version3.PNG"><img data-original-height="1053" data-original-width="1565" height="430" src="https://1.bp.blogspot.com/-3bEcwOul6ug/X367OQxBufI/AAAAAAACMxk/Y9FX76CWWwEdILsKKflZovcUbo1jPwTrACLcBGAsYHQ/w640-h430/version3.PNG" width="640"></a></p><p><i>Just a tad more complicated than Version 1.</i></p><p>Both the Top Cap subassembly and the Holder needed to be easily 3D-printable in plastic on my old 3D printer while still being strong enough to resist the 650 lbs of force that high pressure gas would exert on the brew chamber. The design was run through a number of <a href="https://en.wikipedia.org/wiki/Finite_element_method" target="_blank">FEA</a> simulations to ensure it would be able to resist exploding during brewing (plus a safety margin).</p><p><a href="https://1.bp.blogspot.com/-BtkYcBLeuro/X368PCK4eNI/AAAAAAACMxs/VWf_vshSSI0KAdRJAge7rIpZ9c7uahgyQCLcBGAsYHQ/s950/v2.png"><img data-original-height="698" data-original-width="950" height="470" src="https://1.bp.blogspot.com/-BtkYcBLeuro/X368PCK4eNI/AAAAAAACMxs/VWf_vshSSI0KAdRJAge7rIpZ9c7uahgyQCLcBGAsYHQ/w640-h470/v2.png" width="640"></a><i>Blue good, red bad.</i></p><p>Confident that the design (should) hold under pressure, I threw it on the printer for a 9 hour print.</p><p><a href="https://1.bp.blogspot.com/-vgUlYmxaKIc/X369IJ8XAhI/AAAAAAACMx8/CQSMNGE-1FstNYvtAiRUPTlkp9_-xZK6ACLcBGAsYHQ/s1246/v3%2Bprint1.PNG"><img data-original-height="934" data-original-width="1246" height="480" src="https://1.bp.blogspot.com/-vgUlYmxaKIc/X369IJ8XAhI/AAAAAAACMx8/CQSMNGE-1FstNYvtAiRUPTlkp9_-xZK6ACLcBGAsYHQ/w640-h480/v3%2Bprint1.PNG" width="640"></a></p><p><i>You see a cool 3D printer. I see an extruder that's about to jam. Yay.</i></p><p>You'd think I'd finally learn my lesson about being cheap and upgrade my 4 year old printer after five failed attempts at printing the parts but you'd be wrong. Days later and a bit of assembly, here we are. Exciting!</p><p><a href="https://1.bp.blogspot.com/-fKBUuFRfH50/X36-UsBFrlI/AAAAAAACMyU/y2GinRqt8rA7YMjZJnGLzu0w-cqwpYYAgCLcBGAsYHQ/s1246/finishedv3.PNG"><img data-original-height="936" data-original-width="1246" height="480" src="https://1.bp.blogspot.com/-fKBUuFRfH50/X36-UsBFrlI/AAAAAAACMyU/y2GinRqt8rA7YMjZJnGLzu0w-cqwpYYAgCLcBGAsYHQ/w640-h480/finishedv3.PNG" width="640"></a></p><p><span>We're getting closer!</span></p><p>I quickly loaded up a CO2 cartridge, opened the valve and......<i>hisssssssssss. </i>No matter what I did, I could not get it to stop leaking. <a href="https://www.hunker.com/12313443/how-to-make-a-leak-detector-solution" target="_blank">Soapy water</a> showed leaks coming from <i>everywhere</i>, including places where there were no special features! I had never had issues printing water or airtight parts before but a pressure vessel? This was a first.&nbsp;</p><p><a href="https://1.bp.blogspot.com/-AfIv-26N_Ts/X37CkSfyTmI/AAAAAAACMyg/xXaTnbSAaI4O2RW4K9KaYMV48rr1LDpMACLcBGAsYHQ/s1249/bubblesaretheworst.PNG"><img data-original-height="935" data-original-width="1249" height="480" src="https://1.bp.blogspot.com/-AfIv-26N_Ts/X37CkSfyTmI/AAAAAAACMyg/xXaTnbSAaI4O2RW4K9KaYMV48rr1LDpMACLcBGAsYHQ/w640-h480/bubblesaretheworst.PNG" width="640"></a></p><p><i>Starting to regret not going with stainless steel...</i></p><p>I spent the next two weeks chasing my tail trying to figure out what was wrong, After redesigning and reprinting parts, removing the relief valve, and replacing the gas channels with tubing, I was finally able to get the darned thing to seal decently well.&nbsp;</p><p>With great trepidation, I loaded 18g of finely ground coffee into the basket, tamped it down with the shower screen, loaded 60g of hot water, capped and locked the top cap, and opened the CO2 valve. After about 3 seconds of gurgling, I started to see some dark brown liquid drain out of the basket. 20 seconds later, I'm holding my first successful shot of espresso. SUCCESS!</p><p><a href="https://1.bp.blogspot.com/-Q0vzI-fxI5Q/X37E3MZvBWI/AAAAAAACMy4/9IBLG--VTJgP4U6NJCa_3rKHTapu6izLgCLcBGAsYHQ/s931/SUCCESS.PNG"><img data-original-height="931" data-original-width="694" height="640" src="https://1.bp.blogspot.com/-Q0vzI-fxI5Q/X37E3MZvBWI/AAAAAAACMy4/9IBLG--VTJgP4U6NJCa_3rKHTapu6izLgCLcBGAsYHQ/w478-h640/SUCCESS.PNG" width="478"></a></p><p><i>You can't tell but this is in my bathroom. Because it was 2AM.&nbsp;</i></p><p><i>And I didn't want to wake the baby if it exploded.&nbsp;</i></p><p>The espresso was well extracted with great crema. With 18g coffee in and 45g fluid out, I was brewing at roughly <a href="https://au.lamarzoccohome.com/brew-ratios-around-world/#:~:text=Using%20traditional%20Italian%20espresso%20nomenclature,as%20a%20%E2%80%9Clungo%E2%80%9D%20espresso." target="_blank">2.5:1 ratio</a>, which is right in line with (or just slightly above) a standard espresso. Even the puck popped out perfectly!</p><p><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" frameborder="0" height="315" src="https://www.youtube.com/embed/Tri0QX3m128" width="560"></iframe></p></div><div><p>Each pull takes about 2.6g of CO2, which is more than I anticipated but only adds about $0.15 to the total cost of the espresso. Here's a video of the process from start to finish.</p><p><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" frameborder="0" height="315" src="https://www.youtube.com/embed/86Mv-JOSNPI" width="560"></iframe></p><p><i>Dropping the kettle base was completely intentional.</i></p><p><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" frameborder="0" height="315" src="https://www.youtube.com/embed/dAy1YhiLFZI" width="560"></iframe></p><p><i>Mmmmm slow mo....</i></p><p>I'm pretty happy with how things turned out but there's still a lot to improve. For instance, how does this stack up to a semi-automatic machine? Does CO2 get dissolved into the espresso (probably not) and affect the overall taste? What about Version 4? Can CO2 consumption be further optimized? Lots of unknowns that will eventually get answered...either when this prototype finally explodes or I stop caring about being frugal, whichever comes first (probably the former).</p><p>Here's a comparison for those of you who are interested in how this stacks up against all the machines I researched:</p><div><p><a href="https://lh3.googleusercontent.com/-kcoqAB_7OVQ/X4JRtXL220I/AAAAAAACNFA/9s7HyLLM2Qc-84F50BMDf47CBUCUNHY6QCLcBGAsYHQ/image.png"><img alt="" data-original-height="321" data-original-width="1083" height="190" src="https://lh3.googleusercontent.com/-kcoqAB_7OVQ/X4JRtXL220I/AAAAAAACNFA/9s7HyLLM2Qc-84F50BMDf47CBUCUNHY6QCLcBGAsYHQ/w640-h190/image.png" width="640"></a></p></div><p>For now, I'm quite happy and casually working on version 4. If there's enough interest, I'll post a followup post on what improvements have been made (<i>cough</i>&nbsp;Industrial Design 101: How not to make things look ugly as sin <i>cough</i>) but I already have a bunch of different air pumps (both manual and electric) in house to test vs compressed CO2 and a smaller gauge to replace the comically large one that's currently mounted. If it becomes reliable enough, I'll post the 3D files/BOM or maybe even mold parts to sell. Who knows. Let me know in the comments below if you'd be interested!</p><p><i>(EDIT: Lots of people have asked about whether or not this would impart artificial acidity to the espresso. At such a high temperature, the solubility of CO2 is very low (see graph&nbsp;<a href="https://www.researchgate.net/figure/Solubility-of-carbon-dioxide-in-water-temperature-pressure-effects-18_fig4_308890308" target="_blank">here</a>). Also some have wondered about whether or not the liquid CO2 would lower the temperature of the water. Considering we only need 2g of CO2 and that it already boils before hitting the brew chamber (not to mention water's insanely high specific heat), I have not noticed any noticeable drop in temp during extraction. I use compressed air now and also have not noticed a difference.)</i></p></div>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New York Times considers legal action against OpenAI as copyright tensions swirl (127 pts)]]></title>
            <link>https://text.npr.org/1194202562</link>
            <guid>37157989</guid>
            <pubDate>Thu, 17 Aug 2023 06:33:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://text.npr.org/1194202562">https://text.npr.org/1194202562</a>, See on <a href="https://news.ycombinator.com/item?id=37157989">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p><em>The New York Times</em> and OpenAI could end up in court. </p><p>Lawyers for the newspaper are exploring whether to sue OpenAI to protect the intellectual property rights associated with its reporting, according to two people with direct knowledge of the discussions. </p><p>For weeks, <em>The Times</em> and the maker of ChatGPT have been locked in tense negotiations over reaching a licensing deal in which OpenAI would pay <em>The Times </em>for incorporating its stories in the tech company's AI tools, but the discussions have become so contentious that the paper is now considering legal action. </p><p>The individuals who confirmed the potential lawsuit requested anonymity because they were not authorized to speak publicly about the matter.</p><p>A lawsuit from <em>The Times</em> against OpenAI would set up what could be the most high-profile legal tussle yet over copyright protection in the age of generative AI. </p><p>A top concern for <em>The Times</em> is that ChatGPT is, in a sense, becoming a direct competitor with the paper by creating text that answers questions based on the original reporting and writing of the paper's staff. </p><p>It's a fear heightened by tech companies using generative AI tools in search engines. Microsoft, which has invested billions into OpenAI, is now powering its Bing search engine with ChatGPT. </p><p>If, when someone searches online, they are served a paragraph-long answer  from an AI tool that refashions reporting from <em>The Times</em>, the need to visit the publisher's website is greatly diminished, said one person involved in the talks.</p><p>So-called large language models like ChatGPT have scraped vast parts of the internet to assemble data that inform how the chatbot responds to various inquiries. The data-mining is conducted without permission. Whether hoovering up this massive repository is legal remains an open question. </p><p>If OpenAI is found to have violated any copyrights in this process, federal law allows for the infringing articles to be destroyed at the end of the case. </p>
      <hr><p>
      Related Story: <a href="https://text.npr.org/1190605685">Movie extras worry they'll be replaced by AI. Hollywood is already doing body scans</a></p><hr><p>In other words, if a federal judge finds that OpenAI illegally copied <em>The Times</em>' articles to train its AI model, the court could order the company to destroy ChatGPT's dataset, forcing the company to recreate it using only work that it is authorized to use. </p><p>Federal copyright law also carries stiff financial penalties, with violators facing fines up to $150,000 for each infringement "committed willfully." </p><p>"If you're copying millions of works, you can see how that becomes a number that becomes potentially fatal for a company," said Daniel Gervais, the co-director of the intellectual property program at Vanderbilt University who studies generative AI. "Copyright law is a sword that's going to hang over the heads of AI companies for several years unless they figure out how to negotiate a solution." </p><p><em>The Times </em>talks with OpenAI follow <a href="https://www.semafor.com/article/08/13/2023/new-york-times-drops-out-of-ai-coalition">reports</a> that the paper will not join other media organizations in attempting to negotiate with tech companies over use of content in AI models. A person at <em>The Times</em> said not participating is unrelated to any potential litigation against OpenAI, which declined to comment through a spokesperson. </p>
      <hr><p>
      Related Story: <a href="https://text.npr.org/1187523435">Thousands of authors urge AI companies to stop using work without permission</a></p><hr><p>While a spokesman for <em>The Times</em> would not comment, the paper's executives have publicly nodded at the tension.</p><p>In June, Times CEO Meredith Kopit Levien said at the Cannes Lions Festival that it is time for tech companies to pay their fair share for tapping the paper's vast archives. </p><p>"There must be fair value exchange for the content that's already been used, and the content that will continue to be used to train models," she said. </p><p>The same month, Alex Hardiman, the paper's chief product officer, and Sam Dolnick, a deputy managing editor, described in a memo to staff a new internal initiative designed to capture the potential benefits of artificial intelligence. </p><p>They cited "protecting our rights" among their chief  fears: "How do we ensure that companies that use generative AI respect our intellectual property, brands, reader relationships and investments?"</p><h3>A Times suit would join other copyright holders taking aim at AI companies </h3><p>Any potential suit <em>The Times</em> files would join other similar legal actions leveled against OpenAI in recent weeks. </p><p>Comedian Sarah Silverman joined a class-action suit against the company, alleging that she never gave ChatGPT permission to ingest a digital version of her 2010 memoir "The Bedwetter," which she says the company swallowed up from an illegal online "shadow library" </p><p>Other generative AI companies, like Stability AI, which distributes the image generator Stable Diffusion, have also been hit with copyright lawsuits. </p><p>Getty Images is suing Stability AI for allegedly training an AI model on more than 12 million Getty Images photos without authorization. </p><p>"Copyright holders see these instances are reckless, and AI companies see it as gutsy," Vanderbilt's Gervais said. "As always, the final answer will be determined by who ends up winning these lawsuits." </p><p>Legal experts say AI companies are likely to invoke a defense citing what is known as "fair use doctrine," which allows for the use of a work without permission in certain instances, including teaching, criticism, research and news reporting. </p><h3>Key question for AI suits: Will 'fair use' apply? </h3><p>There are two legal precedents that will likely play a part in the pending AI copyright disputes.</p><p>The first is <a href="https://fairuse.stanford.edu/case/authors-guild-v-google-inc/">a 2015 federal appeals court ruling</a> that found that Google's digitally scanning of millions of books for its Google Books library was a legally permissible use of "fair use," and not copyright infringement. </p><p>The court found that Google's digital library of books did not create a "significant market substitute" for the books, meaning it did not compete with the original works. </p><p>Legal experts say proving that in the AI cases will be a major hurdle to overcome for OpenAI. </p><p>The second case expected to be relevant to the AI copyright suits is the Andy Warhol Foundation case the Supreme Court decided in May. </p><p>In it<a href="https://www.supremecourt.gov/opinions/22pdf/21-869_87ad.pdf">, the high court found</a> that Andy Warhol was not protected by fair use doctrine when he altered a photograph of Prince taken by Lynn Goldsmith. Importantly, the court found that Warhol and Goldsmith were selling the images to magazines. </p><p>Therefore, the court wrote, the original and the copied work shared "the same or highly similar purposes, or where wide dissemination of a secondary work would otherwise run the risk of substitution for the original or licensed derivatives of it."</p><p>Lawyers for <em>The Times</em> believe OpenAI's use of the paper's articles to spit out descriptions of news events should not be protected by fair use, arguing that it risks becoming something of a replacement for the paper's coverage. </p><p><em>NPR's David Folkenflik contributed to this report. </em></p>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Any interesting books you have read lately? (298 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=37156372</link>
            <guid>37156372</guid>
            <pubDate>Thu, 17 Aug 2023 02:18:00 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=37156372">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="37158420"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37158420" href="https://news.ycombinator.com/vote?id=37158420&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>Adult Children of Emotionally Immature Parents<p>I'm a person that struggles with boundary-setting and have spent numerous years in relationships that have left me as less-than I was before. Imagine people-pleasing to an absolute fault, and being more of a chameleon that adapts to avoid conflicts. This has led to problems of identity, and deriving my sense of worth through others which isn't healthy.</p><p>Fortunately, I do not have the same problems professionally and part of my people-pleasing skills have been put to good use there.</p><p>However, history continued and continues to repeat itself to this day. I'm more than half-way into this book and am not only seeing patterns from my childhood, my relationships with my parents, and my early relationships (platonic &amp; romantic)</p><p>It's been eye-opening, and I consider it my first step in breaking this trend.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37157356"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37157356" href="https://news.ycombinator.com/vote?id=37157356&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>The Goal.<p>It's a book from the 1980's about operational management. In particular, it focuses on physical manufacturing.</p><p>It's in the form of a fictitious personal tale. A plant manager struggles to save his plant from closure, and his marriage from falling apart.</p><p>The lesson is about lean management.</p><p>My main takeaway is the realization that when we try to optimize something, we focus on how to do something more efficiently. What more often is a problem is that people and processes are blocked from doing work. They spend a lot of time waiting and doing nothing. Focusing on reducing waits will produce better results than focusing on doing the work faster. Of course reducing the waits might mean doing some targeted piece of work faster. It could also mean doing better scheduling or focusing on other resource contention.</p><p>Recently I used this mindset to optimize a legacy DB struggling under the weight of a hodgepodge of unmaintained code. It worked wonderfully. Instead of fixing the slowest queries, focused on fixing the ones that block the most often. The result was that the DB <i>was</i> able to handle the workload after all.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37158971"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37158971" href="https://news.ycombinator.com/vote?id=37158971&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>For those interested on this topic but would like a lighter approach, there is now a graphic novel: The Goal A Business Graphic Novel.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37158459"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37158459" href="https://news.ycombinator.com/vote?id=37158459&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>The Dawn of Everything, by Graeber and Wengrow.<p>Refutes most of the claims made by Harari in Sapiens, and shows everything you though you knew about prehistory is plain wrong. It's a great book, very well written and well informed.</p><p>Made me think that humanity's history isn't an arrow pointing in the direction of progress; we make experiments. Our current way of life is not the "best so far", it's but one arrangement among many other possible configurations. The alternative between this and going back to living in caves is a false choice.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37158518"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37158518" href="https://news.ycombinator.com/vote?id=37158518&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>&gt;&gt; Refutes most of the claims made by Harari in Sapiens<p>Can You elaborate on this? - I quite liked Harraris book, especially his ideas about stories driving human cooperation and expansion. Does this false claims invalidates the main message of Sapiens?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37158771"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37158771" href="https://news.ycombinator.com/vote?id=37158771&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>"Most" is an exaggeration; "many" would have been fine; it's been a while since I read Sapiens, sorry about that.<p>I was mainly referring to how he talks about the invention of agriculture.</p><p>There has never been an agricultural "revolution". Cultivation was practiced for at least 3,000 years (probably much longer) before some human groups decided to make it their main mode of subsistence, while many others, already familiar with the concept, decided not to.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="37157115"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37157115" href="https://news.ycombinator.com/vote?id=37157115&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>I recently read two books about industries that previously seemed dreadfully boring: property/casualty insurance, and community banking. I'm not sure what possessed me to read these books but I was curious about both industries since they are significant parts of the economy but I knew next to nothing about them.<p>The banking book is called "The Most Fun I Never Want To Have Again: A Mid-Life Crisis in Community Banking"[0] and it tells the story of an attempted bank startup in Georgia just before the financial crisis. It has a very clear explanation of the bank business model and how small banks make money. One of the surprising things I took away from it is that bank founders think of starting a bank in ways that are very similar to how tech founders think of starting of company. The main difference is that the bank business model is already well understood to those in the industry and success depends much more on your positioning in the market than it does on innovation.</p><p>The insurance book is called "Risk &amp; Reward: An Inside View of the Property/Casualty Insurance Business"[1] and is by Stephen Catlin, who founded an insurance company that he grew to several thousand employees with offices around the world and later sold for $4 billion. Very UK centered since that's mostly where his career took place but I don't think the fundamentals of the industry change that much around the world. Pretty detailed on the mechanics of how insurance underwriting works and what insurance underwriters think about when pricing risk. Made me realize insurance is much more like trading than I'd previously thought.</p><p>[0]: <a href="https://www.amazon.com/gp/product/B00ELPOA3S/" rel="nofollow noreferrer">https://www.amazon.com/gp/product/B00ELPOA3S/</a></p><p>[1]: <a href="https://www.amazon.com/gp/product/B073NRDNSC/" rel="nofollow noreferrer">https://www.amazon.com/gp/product/B073NRDNSC/</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37157971"><td></td></tr>
                  <tr id="37158749"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37158749" href="https://news.ycombinator.com/vote?id=37158749&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>I stumbled upon Leonard Susskinds physics lectures on YouTube and bought the accompanying books [1]. The target audience are people like me, who had some intermediate physics and math lectures at university "before life happened".
The books and lectures fill the gap between "real" theoretical books / lecture notes and popular science books that try to circumvent math at every cost.<p>[1] <a href="https://theoreticalminimum.com/" rel="nofollow noreferrer">https://theoreticalminimum.com/</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37157571"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37157571" href="https://news.ycombinator.com/vote?id=37157571&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>It’s been probably a year since I read The WEIRDest People in the World by Joseph Henrich, but the ideas in there have really stuck in my head.<p>The WEIRD acronym stands for Western, Educated, Industrialized, Rich, and Democratic. The thesis is that the Christian Church inadvertently created modern society by prohibiting polygamy and cousin marriage.</p><p>The topic of polygamy is what’s really stuck in my head. Polygamy is a more natural state for civilized human societies than we think it is. It may be to women’s advantage to choose an “elite” spouse she has to share because it could mean a better quality of life for her and her children than the alternatives. Chris Hemsworth could have two dozen wives if it were legal and social acceptable (and he wanted to), and his wives might be happy with that. But the downside (or one of them) is that it creates huge imbalances in society—men find it really hard to find a mate. They then do risky stuff to make it into the elite to try to attract a mate—steal to accumulate wealth or kill potential romantic rivals.</p><p>This isn’t in the book, but it made me think—are we back in that same position now? Polygamy isn’t *technically* legal or common, but you still have plenty of people who have many romantic partners—just not at the same time. We know the what the activity of dating apps looks like—a very small subset of “elite” men get an outsized proportion of likes and matches from women. It’s slim pickings for the rest of the men. Are men, unable to find a mate, going to resort to risky behavior to try to make it into that subset that are able to attract women?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37158992"><td></td></tr>
            <tr id="37158976"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37158976" href="https://news.ycombinator.com/vote?id=37158976&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>&gt; his wives might be happy with that.<p>Maybe, maybe not. In relationships where a larger number of people competes for one partner you still have the same emotions of jealousy, insecurity etc. Everybody wants to be the favorite one.</p><p>It was interesting to observe the dynamics of such a relationship of my friend who dated two women (one white, one black) some years ago. When you asked them then, everybody would answer they were perfectly happy. Years later it turned out both women felt increasingly uncomfortable in the situation.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37157907"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37157907" href="https://news.ycombinator.com/vote?id=37157907&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>&gt; Polygamy isn’t <i>technically</i> legal or common, but you still have plenty of people who have many romantic partners—just not at the same time.<p>I don't think those two are the same. Polygamy is a way to structure society and determine access to resources, whereas fooling around on Tinder is just a way to have fun with no questions asked. It might surprise you but the plebes of old were also promiscuous.</p><p>Here's an interesting discussion on the topic:</p><p><a href="https://www.reddit.com/r/history/comments/5rre85/sexuality_during_medieval_europe/" rel="nofollow noreferrer">https://www.reddit.com/r/history/comments/5rre85/sexuality_d...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37158519"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37158519" href="https://news.ycombinator.com/vote?id=37158519&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>&gt; natural state for civilized human societies<p>"Natural" state. For "civilized" societies.</p><p>Do you realize just how stupid it sounds?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37158044"><td></td></tr>
                <tr id="37158689"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37158689" href="https://news.ycombinator.com/vote?id=37158689&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>RE: Diaspora, you'll know pretty quickly if you like it or not.  It's very hard sci-fi, the opening is quite rough from a technical standpoint, may make your brain hurt.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37156967"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37156967" href="https://news.ycombinator.com/vote?id=37156967&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>Kind of off-path from my regular reading, but I recently got absorbed into the planted aquarium world. This book was such a great way to get acquainted with the ecology and methods required, though once you do it... It's extremely obvious that it works, and why it works:<p>Ecology of the Planted Aquarium: A Practical Manual and Scientific Treatise
<a href="https://www.amazon.ca/Ecology-Planted-Aquarium-Practical-Scientific/dp/B0C51PCVMH/ref=sr_1_1?keywords=ecology+of+the+planted+aquarium&amp;qid=1692244154&amp;sprefix=ecology,aps,149&amp;sr=8-1" rel="nofollow noreferrer">https://www.amazon.ca/Ecology-Planted-Aquarium-Practical-Sci...</a></p><p>Having a slice of nature in my home that's genuinely self-sufficient by all practical means has been wildly educational, rewarding, and fascinating. So many species emerged from such small samples of local ponds, lakes, and streams where I found my materials. I thought I understood ecological diversity and the staggering number of living things out there, but seeing this thriving ecosystem in only 10 gallons of volume really drove it home... The earth is absolutely covered in life.</p><p>And it all came out of mud!</p><p>I highly recommend it to anyone who likes to nerd out on ecology, aquariums, water, etc.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37157495"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37157495" href="https://news.ycombinator.com/vote?id=37157495&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>Any guides on what kind of equipment and set up is needed to get started? I've been having thoughts of having a "slice of nature" like you said. But I don't know what's the way to get as close to a self-sufficient and passive system as possible.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37158927"><td></td></tr>
            <tr id="37158727"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37158727" href="https://news.ycombinator.com/vote?id=37158727&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>Get a 20 gallon tank with grow light hood, add dirt (organic potting soil), cover with aquarium rocks, add aquarium plants, 6-12 shrimp, and 4+ snails, add a sponge filter, enjoy your little ecosystem.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="37158098"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37158098" href="https://news.ycombinator.com/vote?id=37158098&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>Never Split The Difference by Chris Voss, on negotiation tactics. Much better than "Getting to Yes".<p>The Genius of The Few by Christian and Barbara Joy O'Brien, an alternative take for garden of eden and Anunnaki compared to Sitchin</p><p>Built To Sell by John Warrillow, on how to build a business you can exit with a profit.</p><p>I read 30+ books in the last and this year so there are others but three is enough for this list.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37158882"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37158882" href="https://news.ycombinator.com/vote?id=37158882&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>&gt; The Genius of The Few by Christian and Barbara Joy O'Brien, an alternative take for garden of eden and Anunnaki compared to Sitchin<p>Is there anything that you found convincing in it? Or is it just a fantasy without foundations (or, worse, fake foundations like Daniken)? I find Anunnaki fascinating but people who start writing about them usually stray into their pet theory away from facts.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37157305"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37157305" href="https://news.ycombinator.com/vote?id=37157305&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>Invisible China by Scott Rozelle. The book focuses on rural China and it's challenges. The gist of the book is that countries generally move from low to middle income by doing cheap labor. The move from middle to high income requires a educated workforce. If you don't have enough educated workers across the board you fall into the middle income trap where you have large structural unemployment and get high crime. This happened to Mexico and Brazil for example. China's rural population struggles with a low education level. The author investigated why. The answers come down to a mix of health issues, lack of education on how to raise babies, dysfunction in the education system and the houku system.<p>Short interesting read for anyone interested in China or development economics. The book does a great job composting to other countries and showing that way how development works and doesn't.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37158554"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37158554" href="https://news.ycombinator.com/vote?id=37158554&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>The Cradle series by Will Wight. It's a Wuxia adapted for Western audiences. He has other great series; I liked the parallel Sea/Shadow trilogies a lot. Traveler's Gate series I enjoyed, but not as much as the rest. He recently also started a new series called Last Horizon; it's about space wizards and it's a bit whimsical, but fun.<p>The Expanse series is great, but I reckon people already mentioned it elsewhere in the thread.</p><p>James Islington's Licanius trilogy is one of my favourite fantasy book series probably. He recently started a new series called Hierarchy, which I also recommend. They're very "grounded" fantasy, and the magic systems is very woven into society and its structure. The human relationships in his books are pretty nuanced, which is why I like his works so much.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37158066"><td></td></tr>
            <tr id="37158293"><td></td></tr>
                <tr id="37158933"><td></td></tr>
            <tr id="37158568"><td></td></tr>
                  <tr id="37158676"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37158676" href="https://news.ycombinator.com/vote?id=37158676&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>I'll divide these into interesting, fun and engaging:<p><i>Interesting:</i></p><p>The Ark before Noah, Dr Irvine Finkel: A very engaging and slightly humorous history of arks from before the time of the Bible. Its not a religious book, its a book about myths/history.</p><p>A very english Scandal: a long tale about how the establishment closed ranks around a slimy piece of shit.</p><p><i>Fun</i>:</p><p>Will save the galaxy for cash, by Yahtzee Croshaw: Actually funny scifi, best listened to when narrated by the author. His other series is also great too.</p><p>Death and Croissants, Ian Moore: gentle humorous crime thriller. Follows a divorced slightly unsuccessful middle aged man who has emigrated from britian to france and runs a B&amp;B. he bumps into a glamorous but mysterious woman who he struggles to keep up with. best listened to by the author.</p><p>Engaging:</p><p>Casino royale: ian flemming. Its not at all like the movies. A page turner, but has 1930s attitudes to things. Its not as obvious as Live and let die, which is full of words you cant say in public.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37157162"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37157162" href="https://news.ycombinator.com/vote?id=37157162&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>I've recently finished &lt;The Left Hand of Darkness&gt;, and absolutely love it. The style is one of clarity, tenderness, and honesty, and just plain beautiful in the section where---avoiding spoilers---they journeyed through the ice sheet, which is such a breath-taking portrayal of that environmental harshness, the human vulnerability, and the tenacity of will.<p>It's often classified as Sci-fi, but there's nothing particularly sciency or techy about the story. As far as "how it works", there are lots of curiosity, and very few answers. The book reflects more heavily on society, politics, gender, and most centrally, the personal qualities of honor/face/loyalty.</p><p>Having recently start keeping snails, I naturally draw parallel between my dear invertebrates with the hermaphroditism in the book, which is an extra curiosity for me.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37157518"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37157518" href="https://news.ycombinator.com/vote?id=37157518&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>I read this book myself a few weeks ago. Ursula's work is great, it's strange that I never heard about her before.<p>I also finished another of her works, "The Word for World is Forest", just last week. This one is more about human nature. It is again brilliant, I could not put it down, and I highly recommend it especially to those already familiar with her writing.</p><p>I'll probably be picking up more of her books after I finish "A Fire Upon the Deep" by  Vinge.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37157911"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37157911" href="https://news.ycombinator.com/vote?id=37157911&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>I read all of her Earthsea books last year. I thought they were really excellent. I started left hand but couldn't get into it.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37158815"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37158815" href="https://news.ycombinator.com/vote?id=37158815&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>I always liked LeGuin. If you like her, maybe you'd like Louis McMaster Bujold's Vorkosigan Saga, which is an interesting combination of an unusually vulnerable protagonist and a traditional space opera setting. She's got some straight fantasy that's good, too.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37158284"><td></td></tr>
                <tr id="37158358"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37158358" href="https://news.ycombinator.com/vote?id=37158358&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>The second one could have been a blog post, but the premise is really good: you can apply the Konmari method to your obligations. The author also goes through the caveats of her own method, which is quite refreshing.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37158346"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37158346" href="https://news.ycombinator.com/vote?id=37158346&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>I very much enjoyed the first one and bought the second one already. Thanks for recommending another one.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37158616"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37158616" href="https://news.ycombinator.com/vote?id=37158616&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>Having caught up with Glynn Stewart releases after finishing Wildbow’s Ward, I decided to go for some famous books I never read.<p>First was Gene Wolfe’s The Shadow of the Torturer. After about 1/4th of the book, I didn’t care about anything. Neither the world nor the main character. Decided to stop there, it seems it’s not for me.</p><p>Next up, Ursula K. Le Guin’s A Wizard of Earthsea Again, I stopped after 25%. This time the story was interesting enough, but I couldn’t stand her writing style, everything was written as if it was a prologue and the actual story is starting anytime now. That just got real annoying when it’s the main story.</p><p>Finally, I jumped many years forward (both regarding the release, and the setting), and started Pierce Brown’s Red Rising which I’m enjoying very much so far.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37157091"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37157091" href="https://news.ycombinator.com/vote?id=37157091&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>I read through most of PG Wodehouse this year.<p>'Ukridge' is perhaps the funniest collection of stories ever written, it's magic. I love all the books set in Blandings. While the Jeeves books were not my favorite when I was younger, I really really enjoy them now.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37158324"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37158324" href="https://news.ycombinator.com/vote?id=37158324&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>Always have been interested to read something of that author. Would you say that these books are accessible for a non-native English speaker? I often read in English, but I fear I might struggle to catch subtle word-plays and the like...</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37158579"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37158579" href="https://news.ycombinator.com/vote?id=37158579&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>&gt; catch subtle word-plays<p>In jeeves and wooster, there isn't much word play. It is somewhat antiquated english though, and wooster likes shortening words (the metrop, instead of metropolis/london, "thos" instead of thomas (almost pronounced "foss" but with a th sound))</p><p>Its not hard like oscar wilde, but its not overly easy. You _might_ want to try watching the Fry and Laurie version first: <a href="https://www.youtube.com/watch?v=CkLulnrecAQ">https://www.youtube.com/watch?v=CkLulnrecAQ</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37158658"><td></td></tr>
                        <tr id="37157524"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37157524" href="https://news.ycombinator.com/vote?id=37157524&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>Wodehouse is amazing. Tied with Pratchett for the best humorist writer in my opinion.<p>I've searched a lot to find more humorist writers but it's a very limited genre. Most comedy writing is too cynical for me. By contrast Wodehouse and Pratchett manage to be funny while also being uplifting.</p><p>Does anyone have any recommendations for not-too-cynical humorist authors beside these two?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37158701"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37158701" href="https://news.ycombinator.com/vote?id=37158701&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>Death and Croissants, Ian Moore: gentle humorous crime thriller. Follows a divorced slightly unsuccessful middle aged man who has emigrated from Britain to france and runs a B&amp;B. he bumps into a glamorous but mysterious woman who he struggles to keep up with. best listened to by the author.<p>gentle, fun and not cynical. Some of the characters are, but the series is not cynical, its slightly naive in it's own way.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37157645"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37157645" href="https://news.ycombinator.com/vote?id=37157645&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>Have you read 'Three Men in a Boat' by Jerome K Jerome? It's a classic. I love how fresh and contemporary it still is. Perpetually re-readable as well. There is a follow-up book that's great too.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37157878"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37157878" href="https://news.ycombinator.com/vote?id=37157878&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>The Thursday Murder Club by Richard Osman. Not as good as Wodehouse or Pratchett but I found the series amusing and not cynical.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37157209"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37157209" href="https://news.ycombinator.com/vote?id=37157209&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>I've always been a fan the Jeeves series -- Blandings not so much.<p>I also like the Psmith books. I need to try Ukridge.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37157681"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37157681" href="https://news.ycombinator.com/vote?id=37157681&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>I've only read the first Psmith book set in Blandings - Leave it to Psmith. It's absolutely hilarious.<p>If you like Ukridge, then you could also read 'Love Amount the Chickens', which features the Ukridge character.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="37158594"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37158594" href="https://news.ycombinator.com/vote?id=37158594&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>I recently read the Hunt for Red October.<p>Not obscure or niche by any means but it surprised how good it was (again). Do recommend!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37158657"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37158657" href="https://news.ycombinator.com/vote?id=37158657&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>Losing the Signal, the story of how RIM/BlackBerry imploded. Was particularly interesting to me since I was a product manager for BlackBerry products at a major telco and saw it happen from afar.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37158469"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37158469" href="https://news.ycombinator.com/vote?id=37158469&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>Thanks to some extended vacations I finally got around to read "Masters of Doom" - which I got as Christmas gift.<p>And I loved it - despite the topic (few young guys eating pizza and staring at screens) it reads like Clive Cusslers book.</p><p>It's a great study of team dynamics and have some insides into what it takes to be the greatest at something (getting from Commandor Keen to Doom 3 costed Carmack almost 10 years of his life working day and night)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37158456"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37158456" href="https://news.ycombinator.com/vote?id=37158456&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>I became interested in nutrition recently, so I've read Why We Get Fat by Gary Taubes[1] and How Not To Die by Michael Greger[2].<p>I'm currently reading The Dictator's Handbook by Bruce Bueno de Mesquita[3].</p><p>In my mind, the nutrition books could be shorter so it might not be the best use of your time. But the 2nd one contains chapter for each common disorder so you could check the ones that (might) apply to you. The Dictator's Handbook is very interesting and it got me interested in politics more. I'll read Why Nations Fail by Daron Acemoglu and James A. Robinson and The Invention of Power, another book by Bruce Bueno de Mesquita.</p><p>[1]: <a href="https://www.worldcat.org/title/607975714" rel="nofollow noreferrer">https://www.worldcat.org/title/607975714</a>
[2]: <a href="https://www.worldcat.org/title/992788433" rel="nofollow noreferrer">https://www.worldcat.org/title/992788433</a>
[3]: <a href="https://www.worldcat.org/title/1262964702" rel="nofollow noreferrer">https://www.worldcat.org/title/1262964702</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37157023"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37157023" href="https://news.ycombinator.com/vote?id=37157023&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>Just finished my third reading of The Making of the Atomic Bomb by Richard Rhodes. It really ruined most other history books for me by setting the bar so high.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37158671"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37158671" href="https://news.ycombinator.com/vote?id=37158671&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>I am reading it now too and i enjoy it a lot. Drawing the dots between all of those science discovery, which led to conduct chain reaction, compressing it to almost suspenseful, detective story and decorate it with events in which the whole world and individual people lived was great achievement of the author.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37158722"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37158722" href="https://news.ycombinator.com/vote?id=37158722&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>I finished his fourth book Twilight of the Bombs earlier this year - a great look at nuclear proliferation at the fall of the Cold War and how it shaped many US foreign policy decisions.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37157083"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37157083" href="https://news.ycombinator.com/vote?id=37157083&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>I'm reading Rhodes' "Energy".  Now I know why Great Britain got so deforested: from heating all those drafty old castles.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37157804"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37157804" href="https://news.ycombinator.com/vote?id=37157804&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>You might like the 'The Prize' by Daniel Yergin on the history of petroleum and which also won the Pulitzer Prize.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37157954"><td></td></tr>
                  <tr id="37157219"><td></td></tr>
                <tr id="37157795"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37157795" href="https://news.ycombinator.com/vote?id=37157795&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>I enjoyed most of book 1, then it suddenly went "slapstick" with the alien engineers at the end. That really turned me off to the rest of the series.<p>However, for those who have read books 2 and beyond, does the writing return to serious and deep or does a slapstick element remain?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37157972"><td></td></tr>
                  <tr id="37158172"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37158172" href="https://news.ycombinator.com/vote?id=37158172&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>I really enjoyed the whole trilogy, and highly recommend it to my friends. But its more for the different perspective of a chinese writer talking about western events, and the general outlook of how events progress - the downplay of individuality, the scope of things, and some history of the chinese point of view.<p>However what I didn’t like throughout all 3 books is just how predictable the antagonists are … like the main characters devise a plan, stick to it and things unfold generally how they’ve predicted, with very few (though big) exceptions.</p><p>Maybe thats also part of the chinese perspective? I’m used to Branden Sanderson type of narrative where the bad guys are smarter than the good ones, outplay and counter moves, and apply constant pressure, but can be outplayed themselves as well.</p><p>Three body problem was more like if the other side has an advantage, there’s nothing you can do, and if they don’t, just follow the plan … But apart from that incredible series.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37157246"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37157246" href="https://news.ycombinator.com/vote?id=37157246&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>book 2 (the dark forest) is probably my favorite piece of scifi of all time!  stick with the series if you like it.  there is also a canon 4th book written by a different author that puts a really nice bow on the series.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37157538"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37157538" href="https://news.ycombinator.com/vote?id=37157538&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>Book two was such surprisingly good, because book one was bit tedious. The whole plot around Luo Ji and the small tidbit about siege of Constantinople was just too good.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37157438"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37157438" href="https://news.ycombinator.com/vote?id=37157438&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>Was not aware of the 4th book. Looking forward to that. Thank you. The first three books were great and opened my eyes to the sheer breadth of what other intelligent life could be like.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37157494"><td></td></tr>
                        <tr id="37157038"><td></td></tr>
                <tr id="37157249"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37157249" href="https://news.ycombinator.com/vote?id=37157249&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>I loved the beginning and then liked it less and less as it moves not into three future and becomes more fantastical. I eventually stopped reading. The same thing happened to me with Rudy Rucker's Postsingular.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37158641"><td></td></tr>
                        <tr id="37158296"><td></td></tr>
            <tr id="37158058"><td></td></tr>
            <tr id="37157671"><td></td></tr>
                <tr id="37157956"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37157956" href="https://news.ycombinator.com/vote?id=37157956&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>I literally learned to breath properly after reading this book. Took me months to train out of the bad habits I had acquired over the years.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37157261"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37157261" href="https://news.ycombinator.com/vote?id=37157261&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>The last impactful one on me was Bullshit Jobs by David Graeber.<p>Definitely disrupted my perspective on work and the monotonous, sometimes futile,  insanity that some of us subject ourselves to in order to make a living.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37158059"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37158059" href="https://news.ycombinator.com/vote?id=37158059&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>Double Cross is the story of how the British turned, relied on and managed German double agents through World War Two.<p>Not spoiling anything when I say that reading about one person running a fictitious group of spies across the UK from a flat in London, feeding thousands of pages of fake intelligence to the Germans amazes me. The creativity and mental capacity to stay on top of all those lies is astounding.</p><p>Oh and Expeditionary Force for some fun, slightly thought provoking space opera sci fi, first book is on Audible Plus so you can get into it without using a credit.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37158288"><td></td></tr>
                  <tr id="37157117"><td></td></tr>
            <tr id="37157279"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37157279" href="https://news.ycombinator.com/vote?id=37157279&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>David Bohm's<p>- Thought as a System</p><p>- On Dialogue</p><p>These are great books for removing mental fog, confusion, about the nature of our existence. They have great healing value, allowing us to integrate the world around and within us. They can also help in dealing with practical challenges in how we run organisations, develop teams, and in general help people cooperate together. It is a kind of "red pill" to enter the matrix :)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37158047"><td></td></tr>
                <tr id="37158661"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37158661" href="https://news.ycombinator.com/vote?id=37158661&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>I hope to write about this in detail sometime. Just giving myself some time for experience to percolate and synthesize into something worth publishing. Meanwhile, I'll give one instance of how it helps practically.<p>Say, I manage engineers, and I have a new intern, who is supposed to behave in a particular way, with particular standards. Their words strongly suggest sincerity, but again and again their actions go in the opposite direction. Why does this happen, what's the "problem"?</p><p>From Bohms framework, this sort of behavior is way too common, and it is due to the paradoxical nature of our psychological machinery. It's not a problem, it's a paradox. In the mind of the intern, there tends to be competing and opposing needs. One hand, they want higher quality output (verbally asserted). On the other hand, the unspoken parts of the mind demand comfort and energy saving. On top of this "incoherent" intentions/results, the intern will seem like they're lying, since words and actions/results don't match. They say they want quality, but behavior goes another way.</p><p>So, I see this entire situation clearly, so I become more patient. I understand it's not a simple situation, there's a lot going on underneath the hood. I can help this intern see their inner contradiction, generate higher awareness, make them work with less inner friction (and eventually less external friction). My process for helping someone out becomes accurate, crisp and helpful due to these additional insights from Bohm.</p><p>This is just one instance of Bohms framework helping me out in a practical organizational context.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37158838"><td></td></tr>
                              <tr id="37157019"><td></td></tr>
                <tr id="37157514"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37157514" href="https://news.ycombinator.com/vote?id=37157514&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>Perry Mehrling wrote “The New Lombard Street” covering all the new mechanics of international financial markets. It’s just as fascinating. He taught a course on the material called “Economics of Money and Banking.” I never felt I grokked the interplay between the Fed, USG, and Wall Street until I studied that course.<p><a href="https://youtu.be/7iu5xWByF5g" rel="nofollow noreferrer">https://youtu.be/7iu5xWByF5g</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37158449"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37158449" href="https://news.ycombinator.com/vote?id=37158449&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>The Golden Ass of Apuleius: The Liberation of Feminine in Man.<p>A Jungian dissection of the tale of a man that transforms into a donkey, and his journey of self discovery and redemption.</p><p>It gave me a whole new way of reading books (a "superpower" of sorts, lol).</p><p>Going back and reading stories I used to write as a child/teenager, I can now read between the lines and study my subconscious in ways I wasn't able to before.</p><p>Really helped with my own journey of self-discovery. Most impactful book I've read, by far.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37158700"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37158700" href="https://news.ycombinator.com/vote?id=37158700&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>Snowcrash - a really fun high concept sci-fi that’s plays around with some heady concepts.<p>It breaks down if you think about it too hard, but hey, enjoy it while you can.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37158789"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37158789" href="https://news.ycombinator.com/vote?id=37158789&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>With a character named Jiro Protagonist, this is a clue that perhaps it is less cyberpunk and more of a satire of cyberpunk. It's very good, of course. Also recommended from Neal Stephenson: The Diamond Age. His world building is always top-notch, never more than in that one, IMHO.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37158182"><td></td></tr>
                <tr id="37158248"><td></td></tr>
                  <tr id="37157534"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37157534" href="https://news.ycombinator.com/vote?id=37157534&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>“Goodbye to a River” by John Graves.<p>The narrative follows the author as he takes a canoe trip down the Brazos river in North Central Texas during the late 1950’s. Along the way you are told stories about the people who lived and settled that area, during the old days.</p><p>For me, the book reminded me of the stories I heard from my grandfathers about the way things used to be.</p><p>I’d recommend the book just as a way to experience North Texas at that time.</p><p><a href="https://en.wikipedia.org/wiki/Goodbye_to_a_River" rel="nofollow noreferrer">https://en.wikipedia.org/wiki/Goodbye_to_a_River</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37157769"><td></td></tr>
                <tr id="37158127"><td></td></tr>
                  <tr id="37158546"><td></td></tr>
            <tr id="37158119"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37158119" href="https://news.ycombinator.com/vote?id=37158119&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>Too Perfect: When Being in Control Gets Out of Control (1992) by Allan Mallinger<p>The E-Myth Revisited: Why Most Small Businesses Don't Work and What to Do About It (1985) by Michael E. Gerber
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37158573"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37158573" href="https://news.ycombinator.com/vote?id=37158573&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>Impro by Keith Johnston I found on here and has many unique and radical views about how our society functions and it’s pretty amazing.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37158791"><td></td></tr>
            <tr id="37157510"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37157510" href="https://news.ycombinator.com/vote?id=37157510&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>1. The Captured Economy by Lindsey and Teles<p>2. Tyranny, Inc. by Ahmari</p><p>3. American Revolutions by Alan Taylor</p><p>4. Everything Flows by Vasili Grossman
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37157325"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37157325" href="https://news.ycombinator.com/vote?id=37157325&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>Somewhat (by a few decades) behind the times here, but I finally found a set of Robert Caro's Years of Lyndon Johnson books at a 2nd-hand shop earlier this year. What a ride. I know it's a famous series, but I'm outside the US and so only recently became aware of its existence, and also therefore went in mostly blind as to the subject (I knew very little of LBJ prior). Am partway through the 2nd book now, with the conclusion of the 1948 Texan Senate Democratic primary, and my mouth just sort of hung open for pages at a time during that.<p>Caro's a talented writer, but what really shows through is just the sheer years of hard work he clearly put into the books. I don't know how one can focus for so many years on just one writing project.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37158995"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37158995" href="https://news.ycombinator.com/vote?id=37158995&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>In that genre, his book _Power Broker_ is masterful as well, and sometimes considered the superior work, although about a much lesser-known person.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37157016"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37157016" href="https://news.ycombinator.com/vote?id=37157016&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>material world by  ed conway, fantastic book on basic minerals like sand, salt, oil and their supply chain and miracle process of converting ore to materials that we use everyday.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37157031"><td></td></tr>
            <tr id="37157936"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37157936" href="https://news.ycombinator.com/vote?id=37157936&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>"The Chip", second edition.  Starts with the invention of the vacuum tube, ends with the US-China chip war.  In between, you learn that the first semiconductors were hand-make, using a clay mud on bulk substrate to protect areas to be etched.  Fair warning, he leaves out as much interesting material as he left in.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37158311"><td></td></tr>
                  <tr id="37157467"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37157467" href="https://news.ycombinator.com/vote?id=37157467&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>Two Years Before The Mast by Richard Henry Dana. An account of the cattle hide trade along the California coast in the 1830s by a Harvard student on a leave of absence from his studies. Dana narrates about his life as a sailor traveling around Cape Horn and his work among the Californian coastal communities collecting hides to be sent back east. One of the books that inspired Melville to write Moby Dick and was used as a travel guide by the 49ers during the gold rush. Dana returned in 1859 to see how California progressed and added an epilogue to later editions about that journey.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37157755"><td></td></tr>
                <tr id="37158133"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37158133" href="https://news.ycombinator.com/vote?id=37158133&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>When reasoning about the '50s, I think pop-culture fascination with the era makes them appear closer to modernity than they actually were.<p>I mean: the '50s were 70 years ago. Imagine living in the '50s and talking about  the 1880s: the French Third Republic, the British Empire, no airplanes, no radio or cinema...
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37158336"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37158336" href="https://news.ycombinator.com/vote?id=37158336&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>The Big Con: How the Consulting Industry Weakens our Businesses, Infantilizes our Governments and Warps our Economies</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37157030"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37157030" href="https://news.ycombinator.com/vote?id=37157030&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>The Water Knife.
ISBN 978-0-385-35287-1<p>Dystopian-future novel with a backdrop of water scarcity in the western United States. A "water knife" is a name for a security contractor who enforces water rights...
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37158280"><td></td></tr>
            <tr id="37157250"><td></td></tr>
                <tr id="37158858"><td></td></tr>
                        <tr id="37157578"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37157578" href="https://news.ycombinator.com/vote?id=37157578&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>"Fatherland" by Robert Harris, 1992. Alternative history detective novel
set in a universe in which Nazi Germany won World War II.<p>"Zen and the art of Motorcycle Maintenance" by Robert Pirsig.  I re-read this every 4-5 years just to enjoy the discussions about quality and why it matters.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37158561"><td></td></tr>
            <tr id="37157920"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37157920" href="https://news.ycombinator.com/vote?id=37157920&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>I see recommendation of that motorcycle book too often for some book about something I am not interesting about, what is interesting in it for non-motorcycle person?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37158941"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37158941" href="https://news.ycombinator.com/vote?id=37158941&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>It can be about any sort of maintenance task that people tend to outsource. Fixing the sink instead of calling a plumber, changing your own oil, weeding the edges of the lawn, running Linux on your home computer.  There's a personality type that can really get behind such things as an end to their own, and this book really appeals to them.<p>Most of us don't want a new hobby of "spend a few hours ever week or so to keep my computer capable of running software", but if you hang around places like this, you'll find that plenty of people do.  They can't understand why you wouldn't care enough about your computer to do some basic research into its workings and occasionally recompile the kernel or make a few trivial tweaks to a driver to get it working to your satisfaction.</p><p>No amount of "already having a hobby" or "prioritizing for things you care about most" will convince people like the author/protagonist that there's not something fundamentally wrong (but, happily, fixable) with the way you approach life.</p><p>So yeah, it's not for you and me.  It's for them.  And they absolutely love it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37157944"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37157944" href="https://news.ycombinator.com/vote?id=37157944&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>Perhaps that it is almost entirely not about motorcycles .. and that the activity of motorcycle <i>maintenance</i> transcends motorcycles and is applicable elsewhere.<p>You could always dive in, read the wikipedia article or lookup a literary review. It may or may not be to your taste but I for one enjoyed it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37158027"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37158027" href="https://news.ycombinator.com/vote?id=37158027&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>&gt; <i>for some book about something I am not interesting about</i><p>It is not about motorcycles. You could read the title instead as about <i>maintenance</i>.</p><p>If a mountain leads an author to think about height, the book may not be about alpinism.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37157867"><td></td></tr>
                  <tr id="37157179"><td></td></tr>
            <tr id="37157180"><td></td></tr>
            <tr id="37157591"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37157591" href="https://news.ycombinator.com/vote?id=37157591&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>After the Titan submersible fiasco, I looked into books about diving and started with Shadow Divers. It’s about a group of intrepid shipwreck divers who make a find of a lifetime. Had no idea it was such a risky affair.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37157353"><td></td></tr>
            <tr id="37156408"><td></td></tr>
            <tr id="37156956"><td></td></tr>
                <tr id="37157294"><td></td></tr>
                <tr id="37157993"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37157993" href="https://news.ycombinator.com/vote?id=37157993&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>The new movie you're thinking of is based on Killers of the Flower Moon: The Osage Murders and the Birth of the FBI by David Grann</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37157918"><td></td></tr>
            <tr id="37157969"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37157969" href="https://news.ycombinator.com/vote?id=37157969&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>The DiCaprio movie is Killers Of The Flower Moon. It does center around Native Americans, but in the 1920s in Oklahoma.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="37157460"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37157460" href="https://news.ycombinator.com/vote?id=37157460&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>Reading The Inner Citadel, even though it's repetitive but it gave me new insights into Stoicism.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37157533"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37157533" href="https://news.ycombinator.com/vote?id=37157533&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>The Mind Illuminated - Comprehensive meditation guide that comes at it for an non-theistic/religious/spiritual perspective. Everything you ever wanted to know about meditation without having to go through books about Buddhism or meditation which are generally very spiritual and can be difficult to read.<p>The Attention Revolution - In-depth guide to how to meditate without too much fluff. It basically directly goes into all the details of meditation practice as a thing you do and how to do it. Also very comprehensive and jumps straight into how to meditate.</p><p>The Practicing Stoic - Great overview of Stoicism with a lot of quotes from all the well-known Stoics compiled into one Book. I think it's a great introduction for anybody who isn't quite sure about Stoicism or what it's about, but it's also a great book to go back to as somebody more well-versed in it to refresh the concepts.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37157850"><td></td></tr>
                  <tr id="37156729"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37156729" href="https://news.ycombinator.com/vote?id=37156729&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>• Lush Life, a biography of Billy Strayhorn, a jazz composer for Duke Ellington.<p>• Fashion Climbing: A Memoir, an autobiography of Bill Cunningham who you might know from the street style photography he did for the NYT.</p><p>• Kings of their Own Ocean, a non-fiction history of Bluefin Tuna fishing.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37157163"><td></td></tr>
            <tr id="37156384"><td></td></tr>
            <tr id="37157983"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37157983" href="https://news.ycombinator.com/vote?id=37157983&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>the primacy of doubt by Tim palmer (2023)<p>Do you have a favorite book about complex adaptive systems?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37158137"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37158137" href="https://news.ycombinator.com/vote?id=37158137&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><br><div>
                  <p><span>The Road by Cormac McCarthy. He passed away in June 2023 and I read this shortly after for the first time. A powerful work that, despite the world building, focuses on the love between a father and son. It's a shocking novel in many ways, but ultimately I found it profoundly hopeful. Even in the direst of circumstances love gives strength to endure.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37158339"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37158339" href="https://news.ycombinator.com/vote?id=37158339&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>Cormac is one of those authors who I absolutely love, just love so deeply on an almost personal level.<p>But who I can only make contact with once every couple of years, and only with preparation. He's just so, so bleak.</p><p>The Road put me in a bad place mentally for two or three years. Outer Dark still fucks with me when I think about it. Blood Meridian. Just that. Just the title.</p><p>He's the kind of author that I want to recommend to everyone, but also have to add an asterisk of what to be careful of.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37157358"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37157358" href="https://news.ycombinator.com/vote?id=37157358&amp;how=up&amp;goto=item%3Fid%3D37156372"></a></center>    </td><td><p><span>Capitalism and Desire by Todd Mcgowan<p>An interesting perspective on the psychic appeal of capitalism + an approachable introduction to lacanian psychoanalysis -- if you're into that sort of stuff.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37157967"><td></td></tr>
                  </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Tell us about your project that's not done yet but you want feedback on (118 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=37156101</link>
            <guid>37156101</guid>
            <pubDate>Thu, 17 Aug 2023 01:37:38 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=37156101">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="37156101">
      <td><span></span></td>      <td><center><a id="up_37156101" href="https://news.ycombinator.com/vote?id=37156101&amp;how=up&amp;goto=item%3Fid%3D37156101"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=37156101">Ask HN: Tell us about your project that's not done yet but you want feedback on</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_37156101">105 points</span> by <a href="https://news.ycombinator.com/user?id=abj">abj</a> <span title="2023-08-17T01:37:38"><a href="https://news.ycombinator.com/item?id=37156101">10 hours ago</a></span> <span id="unv_37156101"></span> | <a href="https://news.ycombinator.com/hide?id=37156101&amp;goto=item%3Fid%3D37156101">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20Tell%20us%20about%20your%20project%20that%27s%20not%20done%20yet%20but%20you%20want%20feedback%20on&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=37156101&amp;auth=f5e5b0d43bcefe6bcea6cac5d81e3622f2d790dc">favorite</a> | <a href="https://news.ycombinator.com/item?id=37156101">248&nbsp;comments</a>        </span>
              </td></tr>
    <tr></tr><tr><td colspan="2"></td><td><div><p>A lot of times with side projects I wished I had gotten feedback early on, before I spent a lot of time on an inefficient direction. I wonder if people wait too long to publish something before it is fully polished, then realized that the polishing wasn't needed.</p><p>I'm interested to see things that people would have never published otherwise. I know a lot of my projects never make it to a published phase, but I still would have been interested in knowing the general reception. Please drop your projects here!</p></div></td></tr>        <tr></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[QR codes appearing in Google street view? (206 pts)]]></title>
            <link>https://nso.group/@haifisch/110901720830132689#.</link>
            <guid>37155574</guid>
            <pubDate>Thu, 17 Aug 2023 00:12:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nso.group/@haifisch/110901720830132689#.">https://nso.group/@haifisch/110901720830132689#.</a>, See on <a href="https://news.ycombinator.com/item?id=37155574">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[How to Produce Green Hydrogen for $1/Kg (154 pts)]]></title>
            <link>https://terraformindustries.wordpress.com/2023/08/16/how-to-produce-green-hydrogen-for-1-kg/</link>
            <guid>37155241</guid>
            <pubDate>Wed, 16 Aug 2023 23:28:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://terraformindustries.wordpress.com/2023/08/16/how-to-produce-green-hydrogen-for-1-kg/">https://terraformindustries.wordpress.com/2023/08/16/how-to-produce-green-hydrogen-for-1-kg/</a>, See on <a href="https://news.ycombinator.com/item?id=37155241">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-79">
	<!-- .entry-header -->

	<div>
		
<p>At Terraform Industries we believe in a future where energy is universally cheap, clean, and abundant. We’re developing a scalable electrolyzer to deliver the cheapest possible green hydrogen, which we use as a precursor chemical to make cheap synthetic carbon neutral natural gas in our <a href="https://terraformindustries.wordpress.com/2023/06/26/the-terraformer-mark-one/">Terraformer</a>.</p>



<figure><img data-attachment-id="83" data-permalink="https://terraformindustries.wordpress.com/2023/08/16/how-to-produce-green-hydrogen-for-1-kg/image-2/" data-orig-file="https://terraformindustries.files.wordpress.com/2023/08/image.png" data-orig-size="1600,1002" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://terraformindustries.files.wordpress.com/2023/08/image.png?w=300" data-large-file="https://terraformindustries.files.wordpress.com/2023/08/image.png?w=720" src="https://terraformindustries.files.wordpress.com/2023/08/image.png?w=1024" alt="" srcset="https://terraformindustries.files.wordpress.com/2023/08/image.png?w=1024 1024w, https://terraformindustries.files.wordpress.com/2023/08/image.png?w=150 150w, https://terraformindustries.files.wordpress.com/2023/08/image.png?w=300 300w, https://terraformindustries.files.wordpress.com/2023/08/image.png?w=768 768w, https://terraformindustries.files.wordpress.com/2023/08/image.png 1600w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>We find in our conversations with other builders in the climate/energy space that the destiny of hydrogen is often incompletely understood, so I’m writing this post to explain how Terraform is approaching the question.</p>



<p>Hydrogen production uses a lot of energy. Green hydrogen, produced without CO2 emissions, is currently a more expensive option than production from CH4, which produces a lot of CO2. We want green hydrogen to compete on cost, not just vibes. We believe that correctly developed energy should deliver a green dividend rather than demanding a green premium, and that rapid mass market adoption depends on beating the incumbent polluters on price.</p>



<p>(As an aside, it is quite obviously impossible to enforce universal adoption of more expensive carbon-free energy through, eg, mandatory carbon offsets, as higher gas prices are political suicide regardless of system of government.)</p>



<p>The cost of green hydrogen is a combination of the embodied energy (opex) and the amortized cost of the hydrogen electrolyzer (capex) which splits water into hydrogen and oxygen using electricity. Hydrogen distribution costs are also extremely high, but because Terraform is only using hydrogen as an immediate precursor we’re going to ignore distribution costs here. There are other methods for making carbon-free hydrogen, such as methane pyrolysis, which we will also not develop further in this post.</p>



<p>Let’s get quantitative. The best real world legacy electrolysis systems consume about 50 kWh/kg-H2. The theoretical optimum is 39.4 kWh/kg-H2, and Terraform’s electrolyzers are closer to 80 kWh/kg-H2 as it allows us to deliver a lower cost of hydrogen for reasons that will soon be apparent.</p>



<p>The cost goal for green hydrogen is $1/kg-H2. It is widely believed that if green hydrogen can reach this threshold it will be much much more attractive on the energy market. For context, the Inflation Reduction Act (IRA) green hydrogen production tax credit (PTC) in section 45V is worth $3/kg-H2, which may be enough to make it competitive with steam reforming in the short term.</p>



<p>The cheapest retail grid power is roughly $100/MWh. Using 50 kWh/kg-H2, we see that electricity cost alone works out at $5/kg-H2 – a clear non-starter. Assuming a $1/kg cost is achieved, electricity cost must be less than $20/MWh, and that’s assuming zero capex – an unwise assumption as electrolyzers are traditionally very expensive pieces of equipment.</p>



<p>Still, $20/MWh focuses the attention. Where can one find power that cheap or, ideally, cheaper? Enter solar! This isn’t the place to <a href="https://www.youtube.com/watch?v=EAU5D8hqIUI">talk endlessly about solar</a>, but if hypothetically we were looking for an energy generation technology which a) got 10x cheaper in the last 10 years, b) was scaling up production by at least 50% per year, and c) had no moving parts, solar photovoltaic (PV) is it! Indeed, in many large markets today it is now cheaper to install and operate a solar plant than to operate an already existing coal or gas plant. And if you love some other electricity generation technology, I’m happy for you, please reach $10/MWh LCOE and I’ll buy terawatts of it. </p>



<figure><img data-attachment-id="86" data-permalink="https://terraformindustries.wordpress.com/2023/08/16/how-to-produce-green-hydrogen-for-1-kg/image-1/" data-orig-file="https://terraformindustries.files.wordpress.com/2023/08/image-1.png" data-orig-size="680,445" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-1" data-image-description="" data-image-caption="" data-medium-file="https://terraformindustries.files.wordpress.com/2023/08/image-1.png?w=300" data-large-file="https://terraformindustries.files.wordpress.com/2023/08/image-1.png?w=680" src="https://terraformindustries.files.wordpress.com/2023/08/image-1.png?w=680" alt="" srcset="https://terraformindustries.files.wordpress.com/2023/08/image-1.png 680w, https://terraformindustries.files.wordpress.com/2023/08/image-1.png?w=150 150w, https://terraformindustries.files.wordpress.com/2023/08/image-1.png?w=300 300w" sizes="(max-width: 680px) 100vw, 680px"></figure>



<p>We want the cheapest possible power. What adds cost to solar power? Moving it from the array to another place. Using it at night. Using it when there are clouds blowing by. A typical solar-grid system today will have, in addition to the solar panels, a large and expensive “balance of plant” including inverters, battery storage, substations, grid interconnects, and then the rest of the electricity distribution grid, which includes long distance transmission lines, more substations, transformers, power lines, repair crews, insurance, fire safety, billing departments, legacy power plants, etc etc etc.</p>



<p>We want the cheapest possible power, so we have to delete all these additional cost sinks which do not actually make power and which add much much more than $20/MWh in cost. Then, determine if we can use the resulting, cheapest possible raw solar electricity to make hydrogen. Indeed, right now we have a test rig set up to derisk solar panels directly feeding an electrolyzer, without any intermediate power conversion.</p>



<figure><img data-attachment-id="107" data-permalink="https://terraformindustries.wordpress.com/2023/08/16/how-to-produce-green-hydrogen-for-1-kg/image-2-2/" data-orig-file="https://terraformindustries.files.wordpress.com/2023/08/image-2.png" data-orig-size="1737,1308" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-2" data-image-description="" data-image-caption="" data-medium-file="https://terraformindustries.files.wordpress.com/2023/08/image-2.png?w=300" data-large-file="https://terraformindustries.files.wordpress.com/2023/08/image-2.png?w=720" src="https://terraformindustries.files.wordpress.com/2023/08/image-2.png?w=1024" alt="" srcset="https://terraformindustries.files.wordpress.com/2023/08/image-2.png?w=1024 1024w, https://terraformindustries.files.wordpress.com/2023/08/image-2.png?w=150 150w, https://terraformindustries.files.wordpress.com/2023/08/image-2.png?w=300 300w, https://terraformindustries.files.wordpress.com/2023/08/image-2.png?w=768 768w, https://terraformindustries.files.wordpress.com/2023/08/image-2.png 1737w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The single biggest objection we hear to feeding raw solar direct current (DC) into our electrolyzer is that solar utilization is around 0.25 so our electrolyzer will need to be able to throttle down overnight, and our electrolyzer utilization will only be 0.25. For a given quantity of hydrogen, we will need 4x as many electrolyzers and they are extremely expensive.</p>



<p>Adding batteries to smooth out supply adds substantial cost, with the cheapest geography-dependent wind/solar/battery green power coming in at about $45/MWh, or $2.25/kg-H2 on power alone. At current rates of battery cost improvement, it will be several decades until 24/7 power will be less than $1/kg-H2, so we must find another way!</p>



<p>Let’s detour slightly into electrolyzer cost land. Large scale 50 kWh/kg-H2 electrolyzers typically cost $1000s/kW, but we’ll stick to $1000/kW as a nice round number. 1 MWh of electricity produces 20 kg of H2. If we operate a $1m, 1 MW electrolyzer for 50,000 hours (5.7 years flat out), we will produce 1,000,000 kg-H2. Assuming zero financing or maintenance costs and total amortization over that period, capex alone works out to $1/kg, which is extremely ominous. I can’t see how we can get to $1/kg-H2 if capex is $1/kg and the cheapest 24/7 power is $2.25/kg-H2, for a total of $3.25/kg-H2. </p>



<p>50 kWh/kg-H2 is already close to ideal electrical efficiency, so the only way to cut the per-unit capex cost is to amortize equipment over a longer time period. But even if 0% financing and $0 maintenance costs can be found, hitting $1/kg-H2 will require (eg) 24/7 electricity for $15/MWh and a 25 year payback period, which places severe constraints on the industry’s ability to scale up quickly. There just isn’t that much 0% interest money on 25 year loans floating around.</p>



<p>Why are electrolyzers so expensive? To hit 50 kWh/kg-H2 or ~80% efficiency, electrolyzers need to use expensive platinum group metal electrodes, special separation membranes, heat exchangers, pumps, post-processing, and extremely high pressures and temperatures, which further restrict material choices and manufacturing processes. But in essence, electrolyzers are glorified electric resistors, with no more intrinsic complexity than a <a href="https://www.amazon.com/OVENTE-Electric-Borosilicate-Boiling-Countertop/dp/B00DEPGY7G/">kettle that boils water</a> and costs $15/kW, including free two day shipping from China! </p>



<p>Let’s re-examine the above hopeless economics with a different set of numbers. For the sake of argument, let’s say the Terraform electrolyzer can hit $100/kW and 80 kWh/kg-H2. This is much cheaper than a traditional electrolyzer, but it’s also just 50% efficient, which enables us to delete all the expensive stuff. Critically, it is happy to eat variable diurnal solar DC directly from the panel at $20/MWh. We’ll amortize over the same 5.7 years, but assume only 0.25 utilization for a total of 12500 hours. </p>



<p>Our hypothetical 1 MW electrolyzer costs just $100,000. Over 12,500 hours it consumes 12,500 MWh, producing 156,250 kg-H2, costing just $0.64/kg-H2 for capex. Power costs work out to $1.60/kg-H2, for a total of just $2.24/kg-H2 – more than $1 cheaper than the higher utilization, higher efficiency legacy electrolyzer model. </p>



<p>This is interesting – it goes against our intuition about the virtue of high efficiency and high capital utilization. But it’s not particularly mysterious. Hydrogen is an energy product, and if we’re doing it right then 70-80% of the product cost will be electricity opex. This is particularly important in the context of solar cost continuing to decline. A high capex option will still cost a lot even if electricity cost goes to zero, whereas a lower efficiency, higher power consumption option will pass cost savings on cheap power through to the consumer. Practically speaking, the best way to “short” future solar cost declines is to develop infrastructure now that achieves highly scalable low capex by trading away some electrical efficiency and being flexible enough to consume intermittent renewable electricity sources.</p>



<p>To make this future extremely legible, let’s run the numbers again but with $10/MWh solar cost, such as we expect by about 2028, the same lower efficiency (50%, 80 kWh/kg-H2) and with $50/kW capex, which is still more expensive than most household appliances of comparable complexity. Now capex is just $0.32/kg-H2 while opex is $0.80/kg-H2, for a total of just $1.12/kg-H2, which is extremely close to the magical $1/kg, while legacy systems that cannot exploit cheap solar will still be around $3/kg. </p>



<p>For the fully general case, the figures below give quantitative model analysis showing that the cost penalty of solar load shifting beyond ~0.25 utilization places insurmountable barriers on reaching $1/kg-H2 for green hydrogen. There is a saving grace! We can build low utilization lower efficiency electrolyzers cheaply enough to get to $1/kg-H2, but we have to follow the cheapest solar wherever it leads – in this case away from 100% utilization and high electrical efficiency. </p>



<figure><img data-attachment-id="116" data-permalink="https://terraformindustries.wordpress.com/2023/08/16/how-to-produce-green-hydrogen-for-1-kg/image-8/" data-orig-file="https://terraformindustries.files.wordpress.com/2023/08/image-8.png" data-orig-size="1107,526" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-8" data-image-description="" data-image-caption="" data-medium-file="https://terraformindustries.files.wordpress.com/2023/08/image-8.png?w=300" data-large-file="https://terraformindustries.files.wordpress.com/2023/08/image-8.png?w=720" src="https://terraformindustries.files.wordpress.com/2023/08/image-8.png?w=1024" alt="" srcset="https://terraformindustries.files.wordpress.com/2023/08/image-8.png?w=1024 1024w, https://terraformindustries.files.wordpress.com/2023/08/image-8.png?w=150 150w, https://terraformindustries.files.wordpress.com/2023/08/image-8.png?w=300 300w, https://terraformindustries.files.wordpress.com/2023/08/image-8.png?w=768 768w, https://terraformindustries.files.wordpress.com/2023/08/image-8.png 1107w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>I am 100% confident that by the time we are mass producing this system at these prices later this decade, not only will this be the cheapest hydrogen available anywhere, it will also be the cheapest chemical energy and by far the most scalable – offering &lt;5 year ROI with an extremely competitive supply chain and able to address nearly every market on Earth. This is in sharp contrast to fossil oil and gas, which is hidden underground in just a few places on Earth and impossible to exploit without global infrastructure. </p>



<p>Indeed, as we’ve <a href="https://terraformindustries.wordpress.com/2023/01/09/terraform-industries-whitepaper-2-0/">written before</a> once solar synthetic gas hits the cost parity threshold with fossil hydrocarbons there will be unstoppable global development until further price reductions and capacity increases saturate demand. Conservatively, we expect the oil and gas industry to grow from $6.4T/year today to at least $25T/year once second order global economic growth is factored in, and if we execute well we could be done by ~2040. </p>



<figure><img data-attachment-id="105" data-permalink="https://terraformindustries.wordpress.com/2023/08/16/how-to-produce-green-hydrogen-for-1-kg/screenshot-from-2023-05-22-17-22-40/" data-orig-file="https://terraformindustries.files.wordpress.com/2023/08/screenshot-from-2023-05-22-17-22-40.png" data-orig-size="1419,887" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-from-2023-05-22-17-22-40" data-image-description="" data-image-caption="" data-medium-file="https://terraformindustries.files.wordpress.com/2023/08/screenshot-from-2023-05-22-17-22-40.png?w=300" data-large-file="https://terraformindustries.files.wordpress.com/2023/08/screenshot-from-2023-05-22-17-22-40.png?w=720" src="https://terraformindustries.files.wordpress.com/2023/08/screenshot-from-2023-05-22-17-22-40.png?w=1024" alt="" srcset="https://terraformindustries.files.wordpress.com/2023/08/screenshot-from-2023-05-22-17-22-40.png?w=1024 1024w, https://terraformindustries.files.wordpress.com/2023/08/screenshot-from-2023-05-22-17-22-40.png?w=150 150w, https://terraformindustries.files.wordpress.com/2023/08/screenshot-from-2023-05-22-17-22-40.png?w=300 300w, https://terraformindustries.files.wordpress.com/2023/08/screenshot-from-2023-05-22-17-22-40.png?w=768 768w, https://terraformindustries.files.wordpress.com/2023/08/screenshot-from-2023-05-22-17-22-40.png 1419w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Render of 1 MW Terraformer showing electrolyzer stacks (blue), CO2 capture system (orange) and fuel synthesis reactor (yellow). There are 32 electrolyzer stacks each consuming 25 kW directly from adjacent panels (not pictured). </p>



<p>This natural implication of the basic underlying economics implies some potentially unexpected future developments, which I will list here for completeness. We expect to see the development of roughly <a href="https://terraformindustries.wordpress.com/2022/07/24/were-going-to-need-a-lot-of-solar-panels/">400 TW of solar worldwide</a>, &gt;90% of which will supply synthetic fuels most likely via hydrogen electrolysis and then catalytic synthesis using direct air capture (DAC) CO2. This will consume roughly 5% of Earth’s land surface area, comparable to current roads and urbanization and a lot less (in terms of both area and ecological impact) than current exploitation with farming and forestry, not to mention conventional fossil fuels extraction or uninhabited deserts.</p>



<p>While electrification will continue to displace existing hydrocarbon usage, particularly in ground transportation and some residential heating applications, we expect hydrocarbon consumption to shift and grow, particularly in manufacturing and aviation as we move towards a near term future of unconditional material abundance for everyone on Earth. Do we want a future where Europe pushes through mandatory low quality carbon offsets on airfares, further restricting the privilege of high speed travel to the richest of the rich? Or do we want a future where cheap carbon-neutral aviation fuel expands access to globe-spanning travel opportunities for hundreds of millions of people while also enabling a renaissance of supersonic transport?</p>



<p>While hydrocarbons today supply roughly 2/3 of the ~100 quads of energy consumed annually in the US, by ~2040 hydrocarbons will be downstream of cheap solar, just as nearly all grid electricity will be downstream of solar, providing energy to customers through parallel distribution networks of electricity, oil, and gas. </p>



<p>This Sankey diagram provides a rough sketch of the <a href="http://energyliteracy.com/">US energy economy</a> as it existed in 2021.</p>



<p><img width="661px;" height="400px;" src="https://lh5.googleusercontent.com/lJ-VGf_jByxREzYOh1tDbADDGZ2dLcu6__oPIBLMl17GdsKYrp68w9qBvOQqH9WrI2J-kd1hntbBrxeqEyvuXiT8oSsFpXy4R5vqRP1xG8-z1V3cWajn3GnTWTta6vYJIno3aAbplFlDGdmdrioqW7QChA=s2048"></p>



<p>This Sankey diagram shows how we expect natural economics forces will reshape the energy economy over the next two decades.</p>



<p><img width="739px;" height="367px;" src="https://lh5.googleusercontent.com/yBGLeMafNYm4Yq2np2DID2I9hLnLiwIfxA1Y2ZTrpHAbIwhKfGhnaEekKQNXdRqDIl5TN0ei8O3JyYxmQxIGorAv8pDBbIn6ykfcLseyPvD4beHoItbl2hZE7edPXb8kvcCVR7zTsGsRYyqzJw235swAug=s2048"></p>



<p>The Terraform electrolyzer is composed of roughly 4000 individual cells. 100% market saturation implies the deployment of 400 million 1 MW electrolyzers worldwide. Not including ongoing fleet turnover, we expect the synthetic fuel industry to build and deploy 1.6 trillion electrolyzer cells, each roughly the size and cost of a dining plate, over the next 20 years. On average this works out to 2500 cells per second! I am wary of exaggeration but I think it is fair to say that in terms of parts, factories, ramp rate, and energy consumption, this is the <a href="https://en.wikipedia.org/wiki/Kardashev_scale">single largest technology roll out</a> to occur in the history of humanity, and will cause the other so-called industrial revolutions to pale into insignificance. </p>



<p>We are hiring! </p>



<figure><img data-attachment-id="109" data-permalink="https://terraformindustries.wordpress.com/2023/08/16/how-to-produce-green-hydrogen-for-1-kg/image-4/" data-orig-file="https://terraformindustries.files.wordpress.com/2023/08/image-4.png" data-orig-size="1737,1308" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-4" data-image-description="" data-image-caption="" data-medium-file="https://terraformindustries.files.wordpress.com/2023/08/image-4.png?w=300" data-large-file="https://terraformindustries.files.wordpress.com/2023/08/image-4.png?w=720" src="https://terraformindustries.files.wordpress.com/2023/08/image-4.png?w=1024" alt="" srcset="https://terraformindustries.files.wordpress.com/2023/08/image-4.png?w=1024 1024w, https://terraformindustries.files.wordpress.com/2023/08/image-4.png?w=150 150w, https://terraformindustries.files.wordpress.com/2023/08/image-4.png?w=300 300w, https://terraformindustries.files.wordpress.com/2023/08/image-4.png?w=768 768w, https://terraformindustries.files.wordpress.com/2023/08/image-4.png 1737w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Here is a photo of part of our current electrolyzer design. If you have the vision, insight, and intuition to help us bring this electrolyzer to the masses then email us at hiring@terraformindustries.com. We are looking for a one-pager of constructively critical design review commentary demonstrating your understanding of its design constraints, requirements both real and unnecessary, and, of course, what we’ve missed.</p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Open Challenges in LLM Research (146 pts)]]></title>
            <link>https://huyenchip.com/2023/08/16/llm-research-open-challenges.html</link>
            <guid>37155080</guid>
            <pubDate>Wed, 16 Aug 2023 23:08:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://huyenchip.com/2023/08/16/llm-research-open-challenges.html">https://huyenchip.com/2023/08/16/llm-research-open-challenges.html</a>, See on <a href="https://news.ycombinator.com/item?id=37155080">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Never before in my life had I seen so many smart people working on the same goal: making LLMs better. After talking to many people working in both industry and academia, I noticed the 10 major research directions that emerged. The first two directions, hallucinations and context learning, are probably the most talked about today. I’m the most excited about numbers 3 (multimodality), 5 (new architecture), and 6 (GPU alternatives).</p>

<hr>


<hr>



<h2 id="1_reduce_and_measure_hallucinations">1. Reduce and measure hallucinations</h2>

<p><a href="https://huyenchip.com/2023/05/02/rlhf.html#rlhf_and_hallucination">Hallucination</a> is a heavily discussed topic already so I’ll be quick. Hallucination happens when an AI model makes stuff up. For many creative use cases, hallucination is a feature. However, for most other use cases, hallucination is a bug. I was at a panel on LLM with Dropbox, Langchain, Elastics, and Anthropic recently, and the #1 roadblock they see for companies to adopt LLMs in production is hallucination.</p>

<p>Mitigating hallucination and developing metrics to measure hallucination is a blossoming research topic, and I’ve seen many startups focus on this problem. There are also ad-hoc tips to reduce hallucination, such as adding more context to the prompt, chain-of-thought, self-consistency, or asking your model to be concise in its response.</p>

<p>To learn more about hallucination:</p>

<ul>
  <li><a href="https://arxiv.org/abs/2202.03629">Survey of Hallucination in Natural Language Generation</a> (Ji et al., 2022)</li>
  <li><a href="https://arxiv.org/abs/2305.13534">How Language Model Hallucinations Can Snowball</a> (Zhang et al., 2023)</li>
  <li><a href="https://arxiv.org/abs/2302.04023">A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity</a> (Bang et al., 2023)</li>
  <li><a href="https://arxiv.org/abs/2212.10400">Contrastive Learning Reduces Hallucination in Conversations</a> (Sun et al., 2022)</li>
  <li><a href="https://arxiv.org/abs/2203.11171">Self-Consistency Improves Chain of Thought Reasoning in Language Models</a> (Wang et al., 2022)</li>
  <li><a href="https://arxiv.org/abs/2303.08896">SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models</a> (​​Manakul et al., 2023)</li>
  <li>A simple example of fact-checking and hallucination by <a href="https://github.com/NVIDIA/NeMo-Guardrails/blob/main/examples/grounding_rail/README.md#grounding-fact-checking-and-hallucination">NVIDIA’s NeMo-Guardrails</a></li>
</ul>

<h2 id="2_context_learning">2. Optimize context length and context construction</h2>

<p>A vast majority of questions require context. For example, if we ask ChatGPT: “What’s the best Vietnamese restaurant?”, the context needed would be “where” because the best Vietnamese restaurant in Vietnam would be different from the best Vietnamese in the US.</p>

<p>According to this cool paper <a href="https://arxiv.org/pdf/2109.06157.pdf">SituatedQA</a> (Zhang &amp; Choi, 2021), a significant proportion of information-seeking questions have context-dependent answers, e.g. roughly 16.5% of the <a href="https://ai.google.com/research/NaturalQuestions">Natural Questions NQ-Open dataset</a>. Personally, I suspect that this percentage would be even higher for enterprise use cases. For example, say a company builds a chatbot for customer support, for this chatbot to answer any customer question about any product, the context needed might be that customer’s history or that product’s information.</p>

<p>Because the model “learns” from the context provided to it, this process is also called context learning.</p>

<center>
    <figure>
    <img alt="Context needed for a customer support query" src="https://huyenchip.com/assets/pics/llm-research/2-context.png">
    </figure>
</center>


<p>Context length is especially important for RAG – <a href="https://arxiv.org/abs/2005.11401">Retrieval Augmented Generation</a> (Lewis et al., 2020) – which has emerged to be the predominant pattern for LLM industry use cases. For those not yet swept away in the RAG rage, RAG works in two phases:</p>

<p>Phase 1: chunking (also known as indexing)</p>

<ol>
  <li>Gather all the documents you want your LLM to use</li>
  <li>Divide these documents into chunks that can be fed into your LLM to generate embeddings and store these embeddings in a vector database.</li>
</ol>

<p>Phase 2: querying</p>

<ol>
  <li>When user sends a query, like “<em>Does my insurance policy pay for this drug X</em>”, your LLM converts this query into an embedding, let’s call it QUERY_EMBEDDING</li>
  <li>Your vector database fetches the chunks whose embeddings are the most similar to QUERY_EMBEDDING</li>
</ol>

<p>Screenshot from <a href="https://www.youtube.com/watch?v=njzB6fm0U8g">Jerry Liu’s talk on LlamaIndex</a> (2023)</p>
<center>
    <figure>
    <img alt="Context needed for a customer support query" src="https://huyenchip.com/assets/pics/llm-research/2-rag.jpg">
    </figure>
</center>


<p>The longer the context length, the more chunks we can squeeze into the context. The more information the model has access to, the better its response will be, right?</p>

<p>Not always. How much context a model can use and how efficiently that model will use it are two different questions. In parallel with the effort to increase model context length is the effort to make the context more efficient. Some people call it “prompt engineering” or “prompt construction”. For example, a paper that has made the rounds recently is about how models are much better at understanding information at the beginning and the end of the index rather than in the middle of it – <a href="https://arxiv.org/abs/2307.03172">Lost in the Middle: How Language Models Use Long Contexts</a> (Liu et al., 2023).</p>

<h2 id="3_incorporate_other_data_modalities">3. Incorporate other data modalities</h2>

<p>Multimodality, IMO, is so powerful and yet so underrated. There are many reasons for multimodality.</p>

<p>First, there are many use cases where multimodal data is required, especially in industries that deal with a mixture of data modalities such as healthcare, robotics, e-commerce, retail, gaming, entertainment, etc. Examples:</p>

<ul>
  <li>Oftentimes, medical predictions require both text (e.g. doctor’s notes, patients’ questionnaires) and images (e.g. CT, X-ray, MRI scans).</li>
  <li>Product metadata often contains images, videos, descriptions, and even tabular data (e.g. production date, weight, color). You might want to automatically fill in missing product information based on users’ reviews or product photos. You might want to enable users to search for products using visual information, like shape or color.</li>
</ul>

<p>Second, multimodality promises a big boost in model performance. Shouldn’t a model that can understand both text and images perform better than a model that can only understand text? Text-based models require so much text that there’s a realistic concern that <a href="https://huyenchip.com/2023/05/02/rlhf.html#data_bottleneck_for_pretraining">we’ll soon run out of Internet data to train text-based models</a>. Once we run out of text, we’d need to leverage other data modalities.</p>

<center>
    <figure>
    <img alt="Multimodal Flamingo's architecture" src="https://huyenchip.com/assets/pics/llm-research/3-flamingo.png">
    </figure>
    Flamingo architecture (Alayrac et al., 2022)
</center>


<p>One promising use case is that multimodality can also enable visually impaired people to browse the Internet and also navigate the real world.</p>

<p>Cool multimodal work:</p>

<ul>
  <li><a href="https://arxiv.org/abs/2103.00020">[CLIP] Learning Transferable Visual Models From Natural Language Supervision</a> (OpenAI, 2021)</li>
  <li><a href="https://arxiv.org/abs/2204.14198">Flamingo: a Visual Language Model for Few-Shot Learning</a> (DeepMind, 2022)</li>
  <li><a href="https://arxiv.org/abs/2301.12597">BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models</a> (Salesforce, 2023)</li>
  <li><a href="https://arxiv.org/abs/2302.14045">KOSMOS-1: Language Is Not All You Need: Aligning Perception with Language Models</a> (Microsoft, 2023)</li>
  <li><a href="https://ai.googleblog.com/2023/03/palm-e-embodied-multimodal-language.html">PaLM-E: An embodied multimodal language model</a> (Google, 2023)</li>
  <li><a href="https://arxiv.org/abs/2304.08485">LLaVA: Visual Instruction Tuning</a> (Liu et al., 2023)</li>
  <li><a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/playground/models/neva">NeVA: NeMo Vision and Language Assistant</a> (NVIDIA, 2023)</li>
</ul>

<p>I’ve been working on a post on multimodality that hopefully I can share soon!</p>

<h2 id="4_make_llms_faster_and_cheaper">4. Make LLMs faster and cheaper</h2>

<p>When GPT-3.5 first came out in late November 2022, many people had concerns about latency and cost of using it in production. However, latency/cost analysis has changed rapidly since then. Within half a year, the community found a way to create a model that came pretty close to GPT-3.5 in terms of performance, yet required just under 2% of GPT-3.5’s memory footprint.</p>

<p>My takeaway: if you create something good enough, people will figure out a way to make it fast and cheap.</p>

<table>

  <tbody><tr>
   <td><strong>Date</strong>
   </td>
   <td><strong>Model</strong>
   </td>
   <td><strong># params</strong>
   </td>
   <td><strong>Quantization</strong>
   </td>
   <td><strong>Memory to finetune</strong>
   </td>
   <td><strong>Can be trained on</strong>
   </td>
  </tr>
  <tr>
   <td>Nov 2022
   </td>
   <td>GPT-3.5
   </td>
   <td>175B
   </td>
   <td>16-bit
   </td>
   <td>375GB
   </td>
   <td>Many, many machines
   </td>
  </tr>
  <tr>
   <td>Mar 2023
   </td>
   <td><a href="https://crfm.stanford.edu/2023/03/13/alpaca.html">Alpaca 7B</a>
   </td>
   <td>7B
   </td>
   <td>16-bit
   </td>
   <td>15GB
   </td>
   <td>Gaming desktop
   </td>
  </tr>
  <tr>
   <td>May 2023
   </td>
   <td><a href="https://arxiv.org/abs/2305.14314">Guanaco 7B</a>
   </td>
   <td>7B
   </td>
   <td>4-bit
   </td>
   <td>6GB
   </td>
   <td>Any Macbook
   </td>
  </tr>
</tbody></table>


<p>Below is Guanaco 7B’s performance compared to ChatGPT GPT-3.5 and GPT-4, as reported in the Guanco paper. Caveat: in general, the performance comparison is far from perfect. LLM evaluation is very, very hard.</p>

<center>
    <figure>
    <img alt="Guanaco 7B's performance compared to ChatGPT GPT-3.5 and GPT-4" src="https://huyenchip.com/assets/pics/llm-research/4-llm-optimization.png">
    </figure>
</center>


<p>Four years ago, when I started working on the notes that would later become the section <strong><a href="https://learning.oreilly.com/library/view/designing-machine-learning/9781098107956/ch07.html#model_compression">Model Compression</a></strong> for the book <a href="https://www.amazon.com/Designing-Machine-Learning-Systems-Production-Ready/dp/1098107969"><strong>Designing Machine Learning Systems</strong></a>, I wrote about four major techniques for model optimization/compression:</p>

<ol>
  <li><strong>Quantization</strong>: by far the most general model optimization method. Quantization reduces a model’s size by using fewer bits to represent its parameters, e.g. instead of using 32 bits to represent a float, use only 16 bits, or even 4 bits.</li>
  <li><strong>Knowledge distillation</strong>: a method in which a small model (student) is trained to mimic a larger model or ensemble of models (teacher).</li>
  <li><strong>Low-rank factorization</strong>: the key idea here is to replace high-dimensional tensors with lower-dimensional tensors to reduce the number of parameters. For example, you can decompose a 3x3 tensor into the product of a 3x1 and a 1x3 tensor, so that instead of having 9 parameters, you have only 6 parameters.</li>
  <li><strong>Pruning</strong></li>
</ol>

<p>All these four techniques are still relevant and popular today. Alpaca was trained using knowledge distillation. QLoRA used a combination of low-rank factorization and quantization.</p>

<h2 id="5_design_a_new_model_architecture">5. Design a new model architecture</h2>

<p>Since AlexNet in 2012, we’ve seen many architectures go in and out of fashion, including LSTM, seq2seq. Compared to those, Transformer is incredibly sticky. It’s been around since 2017. It’s a big question mark how much longer this architecture will be in vogue.</p>

<p>Developing a new architecture to outperform Transformer isn’t easy. Transformer has been so heavily optimized over the last 6 years. This new architecture has to be performing at the scale that people care about today, on the hardware that people care about. Side note: <a href="https://timdettmers.com/2018/10/17/tpus-vs-gpus-for-transformers-bert/">Transformer was originally designed by Google to run fast on TPUs</a>, and only later optimized on GPUs.</p>

<p>There was a lot of excitement in 2021 around S4 from Chris Ré’s lab – see <a href="https://arxiv.org/abs/2111.00396">Efficiently Modeling Long Sequences with Structured State Spaces</a> (Gu et al., 2021). I’m not quite sure what happened to it. Chris Ré’s lab is still very invested in developing new architecture, most recently with their architecture <a href="https://together.ai/blog/monarch-mixer">Monarch Mixer</a> (Fu et al., 2023) in collaboration with the startup <a href="https://together.ai/blog/monarch-mixer">Together</a>.</p>

<p>Their key idea is that for the existing Transformer architecture, the complexity of attention is quadratic in sequence length and the complexity of an MLP is quadratic in model dimension. An architecture with subquadratic complexity would be more efficient.</p>

<center>
    <figure>
    <img alt="Monarch Mixer architecture" src="https://huyenchip.com/assets/pics/llm-research/5-monarch-mixer.png">
    </figure>
</center>


<p>I’m sure many other labs are working on this idea, though I’m not aware of any attempt that has been made public. If you know of any, please let me know!</p>

<h2 id="6_develop_gpu_alternatives">6. Develop GPU alternatives</h2>

<p>GPU has been the dominating hardware for deep learning ever since AlexNet in 2012. In fact, one commonly acknowledged reason for AlexNet’s popularity is that it was the first paper to successfully use GPUs to train neural networks. Before GPUs, if you wanted to train a model at AlexNet’s scale, you’d have to use thousands of CPUs, like the one <a href="https://www.nytimes.com/2012/06/26/technology/in-a-big-network-of-computers-evidence-of-machine-learning.html">Google released just a few months before AlexNet</a>. Compared to thousands of CPUs, a couple of GPUs were a lot more accessible to Ph.D. students and researchers, setting off the deep learning research boom.</p>

<p>In the last decade, many, many companies, both big corporations, and startups, have attempted to create new hardware for AI. The most notable attempts are Google’s <a href="https://cloud.google.com/tpu/docs/intro-to-tpu">TPUs</a>, Graphcore’s <a href="https://www.graphcore.ai/products/ipu">IPUs</a> (what’s happening with IPUs?), and <a href="https://www.eetimes.com/cerebras-sells-100-million-ai-supercomputer-plans-8-more/">Cerebras</a>. SambaNova raised over <a href="https://spectrum.ieee.org/sambanova-ceo-ai-interview">a billion dollars to develop new AI chips</a> but seems to have pivoted to being a generative AI platform.</p>

<p>For a while, there has been a lot of anticipation around quantum computing, with key players being:</p>

<ul>
  <li><a href="https://www.ibm.com/quantum">IBM’s QPU</a></li>
  <li>Google’s Quantum computer reported <a href="https://www.nature.com/articles/d41586-023-00536-w">a major milestone in quantum error reduction</a> earlier this year in Nature. Its quantum virtual machine is publicly accessible via <a href="https://quantumai.google/quantum-virtual-machine">Google Colab</a></li>
  <li>Research labs such as <a href="https://cqe.mit.edu/">MIT Center for Quantum Engineering</a>, <a href="https://www.mpq.mpg.de/en">Max Planck Institute of Quantum Optics</a>, <a href="https://chicagoquantum.org/">Chicago Quantum Exchange</a>, <a href="https://quantum-roadmap.ornl.gov/">Oak Ridge National Laboratory</a>, etc.</li>
</ul>

<p>Another direction that is also super exciting is photonic chips. This is the direciton I know the least about – so please correct me if I’m wrong. Existing chips today use electricity to move data, which consumes a lot of power and also incurs latency. Photonic chips use photons to move data, harnessing the speed of light for faster and more efficient compute. Various startups in this space have raised hundreds of millions of dollars, including <a href="https://lightmatter.co/">Lightmatter</a> ($270M), <a href="https://ayarlabs.com/">Ayar Labs</a> ($220M), <a href="https://www.lightelligence.ai/">Lightelligence</a> ($200M+), and <a href="https://www.luminous.com/">Luminous Computing</a> ($115M).</p>

<p>Below is the timeline of advances of the three major methods in photonic matrix computation, from the paper <a href="https://www.nature.com/articles/s41377-022-00717-8">Photonic matrix multiplication lights up photonic accelerator and beyond</a> (Zhou et al., Nature 2022). The three different methods are plane light conversion (PLC), Mach–Zehnder interferometer (MZI), and wavelength division multiplexing (WDM).</p>

<center>
    <figure>
    <img alt="Timeline of advances of the three major methods in photonic matrix multiplication" src="https://huyenchip.com/assets/pics/llm-research/6-photonic-matrix-multiplication.png">
    </figure>
</center>


<h2 id="7_make_agents_usable">7. Make agents usable</h2>

<p>Agents are LLMs that can take actions, like browsing the Internet, sending emails, making reservations, etc. Compared to other research directions in this post, this might be the youngest direction.</p>

<p>Because of the novelty and the massive potential, there’s a feverish obsession with agents. <a href="https://github.com/Significant-Gravitas/Auto-GPT">Auto-GPT</a> is now the 25th most popular GitHub repo ever by the number of stars. <a href="https://github.com/AntonOsika/gpt-engineer">GPT-Engineering</a> is another popular repo.</p>

<p>Despite the excitement, there is still doubt about whether LLMs are reliable and performant enough to be entrusted with the power to act.</p>

<p>One use case that has emerged though is the use of agents for social studies, like the famous Stanford experiment that shows that a small society of generative agents produces emergent social behaviors: <em>for example, starting with only a single user-specified notion that one agent wants to throw a Valentine’s Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party …</em> (<a href="https://arxiv.org/abs/2304.03442">Generative Agents: Interactive Simulacra of Human Behavior</a>, Park et al., 2023)</p>

<p>The most notable startup in this area is perhaps Adept, founded by two Transformer co-authors (though <a href="https://www.theinformation.com/briefings/two-co-founders-of-adept-an-openai-rival-suddenly-left-to-start-another-company">both already left</a>) and an ex-OpenAI VP, and has raised almost half a billion dollars to date. Last year, they had a demo showing their agent browsing the Internet and adding a new account to Salesforce. I’m looking forward to seeing their new demos 🙂</p>

<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/a7CXIE_Gyy8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="">
</iframe>
</center>


<h2 id="8_improve_learning_from_human_preference">8. Improve learning from human preference</h2>

<p><a href="https://huyenchip.com/2023/05/02/rlhf.html">RLHF, Reinforcement Learning from Human Preference</a>, is cool but kinda hacky. I wouldn’t be surprised if people figure out a better way to train LLMs. There are many open questions for RLHF, such as:</p>

<p><strong>1. How to mathematically represent human preference?</strong></p>

<p>Currently, human preference is determined by comparison: human labeler determines if response A is better than response B. However, it doesn’t take into account how much better response A is than response B.</p>

<p><strong>2. What’s human preference?</strong></p>

<p>Anthropic measured the quality of their model’s responses along the three axes: helpful, honest, and harmless. See <a href="https://arxiv.org/abs/2212.08073">Constitutional AI: Harmlessness from AI Feedback</a> (Bai et al., 2022).</p>

<p>DeepMind tries to generate responses that please the most people. See <a href="https://www.deepmind.com/publications/fine-tuning-language-models-to-find-agreement-among-humans-with-diverse-preferences">Fine-tuning language models to find agreement among humans with diverse preferences</a>, (Bakker et al., 2022).</p>

<p>Also, do we want AIs that can take a stand or a vanilla AI that shies away from any potentially controversial topic?</p>

<p><strong>3. Whose preference is “human” preference, taking into account the differences in cultures, religions, political leanings, etc.?</strong></p>

<p>There are a lot of challenges in obtaining training data that can be sufficiently representative of all the potential users.</p>

<p>For example, for OpenAI’s InstructGPT data, there was no labeler above 65 years old. Labelers are predominantly Filipino and Bangladeshi. See <a href="https://arxiv.org/abs/2203.02155">InstructGPT: Training language models to follow instructions with human feedback</a> (Ouyang et al., 2022).</p>

<center>
    <figure>
    <img alt="Demographics of labelers for InstructGPT" src="https://huyenchip.com/assets/pics/llm-research/8-instructgpt-demographics.png">
    </figure>
</center>


<p>Community-led efforts, while admirable in their intention, can lead to biased data. For example, for the OpenAssistant dataset, 201 out of 222 (90.5%) respondents identify as male. <a href="https://twitter.com/jeremyphoward/status/1647763133665271808/photo/1">Jeremy Howard has a great Twitter thread on this</a>.</p>

<center>
    <figure>
    <img alt="Self-reported demographics of contributors to OpenAssistant dataset" src="https://huyenchip.com/assets/pics/llm-research/8-openassistant-demographics.png">
    </figure>
</center>


<h2 id="9_improve_the_efficiency_of_the_chat_interface">9. Improve the efficiency of the chat interface</h2>

<p>Ever since ChatGPT, there have been multiple discussions on whether chat is a suitable interface for a wide range of tasks.</p>

<ul>
  <li><a href="https://austinhenley.com/blog/naturallanguageui.html">Natural language is the lazy user interface</a> (Austin Z. Henley, 2023)</li>
  <li><a href="https://wattenberger.com/thoughts/boo-chatbots">Why Chatbots Are Not the Future</a> (Amelia Wattenberger, 2023)</li>
  <li><a href="https://arxiv.org/abs/2303.17710">What Types of Questions Require Conversation to Answer? A Case Study of AskReddit Questions</a> (Huang et al., 2023)</li>
  <li><a href="https://idratherbewriting.com/blog/ai-chat-interfaces-are-the-new-user-interface-for-docs">AI chat interfaces could become the primary user interface to read documentation</a> (Tom Johnson, 2023)</li>
  <li><a href="https://eugeneyan.com/writing/llm-ux/">Interacting with LLMs with Minimal Chat</a> (Eugene Yan, 2023)</li>
</ul>

<p>However, this is not a new discussion. In many countries, especially in Asia, chat has been used as the interface for super apps for about a decade. <a href="http://dangrover.com/blog/2014/12/01/chinese-mobile-app-ui-trends.html">Dan Grover had this discussion back in 2014</a>.</p>

<center>
    <figure>
    <img alt="Chat has been used as the universal interface for superapps in China for over a decade" src="https://huyenchip.com/assets/pics/llm-research/9-superapp-chat-interface.png">
    </figure>
    Chat as a universal interface for Chinese apps (Dan Grover, 2014)
</center>


<p>The discussion again got tense in 2016, when many people thought apps were dead and chatbots would be the future.</p>

<ul>
  <li><a href="https://acroll.medium.com/on-chat-as-interface-92a68d2bf854">On chat as interface</a> (Alistair Croll, 2016)</li>
  <li><a href="https://www.technologyreview.com/2016/04/25/8510/is-the-chatbot-trend-one-big-misunderstanding/">Is the Chatbot Trend One Big Misunderstanding?</a> (Will Knight, 2016)</li>
  <li><a href="http://dangrover.com/blog/2016/04/20/bots-wont-replace-apps.html">Bots won’t replace apps. Better apps will replace apps</a> (Dan Grover, 2016)</li>
</ul>

<p>Personally, I love the chat interface because of the following reasons:</p>

<ol>
  <li>Chat is an interface that everyone, even people without previous exposure to computers or the Internet, can learn to use quickly. When I volunteered at a low-income residential neighborhood (are we allowed to say slum?) in Kenya in the early 2010s, I was blown away by how comfortable everyone there was with doing banking on their phone, via texts. No one in that neighborhood had a computer.</li>
  <li>Chat interface is accessible. You can use voice instead of text if your hands are busy.</li>
  <li>Chat is also an incredibly robust interface – you can give it any request and it’ll give back a response, even if the response isn’t good.</li>
</ol>

<p>However, there are certain areas that I think the chat interface can be improved upon.</p>

<ol>
  <li>
    <p>Multiple messages per turn</p>

    <p>Currently, we pretty much assume one message per turn. This is not how my friends and I text. Often, I need multiple messages to complete my thought, because I need to insert different data (e.g. images, locations, links), I forgot something in the previous messages, or I just don’t feel like putting everything into a massive paragraph.</p>
  </li>
  <li>
    <p>Multimodal input</p>

    <p>In the realm of multimodal applications, most energy is spent on building better models, and very little on building better interfaces. Take <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/playground/models/neva">Nvidia’s NeVA chatbot</a>. I’m not a UX expert, but I suspect there might be room for UX improvement here.</p>

    <p>P.S. Sorry the NeVA team for calling you out. Even with this interface, your work is super cool!</p>

    <center>
     <figure>
     <img alt="NVIDIA's NeVA interface" src="https://huyenchip.com/assets/pics/llm-research/9-neva.png">
     </figure>
 </center>
    
  </li>
  <li>
    <p>Incorporating generative AI into your workflows</p>

    <p>Linus Lee covered this point well in his talk <a href="https://www.youtube.com/watch?v=rd-J3hmycQs">Generative AI interface beyond chats</a>. For example, if you want to ask a question about a column of a chart you’re working on, you should be able just point to that column and ask a question.</p>
  </li>
  <li>
    <p>Editing and deletion of messages</p>

    <p>How would editing or deletion of a user input change the conversation flow with the chatbot?</p>
  </li>
</ol>

<h2 id="10_build_llms_for_non_english_languages">10. Build LLMs for non-English languages</h2>

<p>We know that current English-first LLMs don’t work well for many other languages, both in terms of performance, latency, and speed. See:</p>

<ul>
  <li><a href="https://arxiv.org/abs/2304.05613">ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning</a> (Lai et al., 2023)</li>
  <li><a href="https://blog.yenniejun.com/p/all-languages-are-not-created-tokenized">All languages are NOT created (tokenized) equal</a> (Yennie Jun, 2023)</li>
</ul>

<center>
    <figure>
    <img alt="Tokenization for non-English languages" src="https://huyenchip.com/assets/pics/llm-research/10-non-english-tokens.png">
    </figure>
</center>


<p>I’m only aware of the effort to train Vietnamese ChatGPT (<a href="https://discord.gg/a2PCzB4AdE">Symato</a> might be the biggest community effort). If you’re aware of community initiatives in other languages, I’d be happy to include them here.</p>

<p>Several early readers of this post told me they don’t think I should include this direction for two reasons.</p>

<ol>
  <li>
    <p>This is less of a research problem and more of a logistics problem. We already know how to do it. Someone just needs to put money and effort into it. This is not entirely true. Most languages are considered low-resource, e.g. they have far fewer high-quality data compared to English or Chinese, and might require different techniques to train a large language model. See:</p>

    <ul>
      <li><a href="https://arxiv.org/abs/2006.07264">Low-resource Languages: A Review of Past Work and Future Challenges</a> (Magueresse et al., 2020)</li>
      <li><a href="https://aclanthology.org/P19-1310/">JW300: A Wide-Coverage Parallel Corpus for Low-Resource Languages</a> (Agić et al., 2019)</li>
    </ul>
  </li>
  <li>
    <p>Those more pessimistic think that in the future, many languages will die out, and the Internet will consist of two universes in two languages: English and Mandarin. This school of thought isn’t new – anyone remembers Esperando?</p>
  </li>
</ol>

<p>The impact of AI tools, e.g. machine translation and chatbots, on language learning is still unclear. Will they help people learn new languages faster, or will they eliminate the need of learning new languages altogether?</p>

<h2>Conclusion</h2>

<p>Phew, that was a lot of papers to reference, and I have no doubt that I still missed a ton. If there’s something you think I missed, please let me know.</p>

<p>Some of the problems mentioned above are harder than others. For example, I think that number 10, building LLMs for non-English languages, is more straightforward with enough time and resources.</p>

<p>Number 1, reducing hallucination, will be much harder, since hallucination is just LLMs doing their probabilistic thing.</p>

<p>Number 4, making LLMs faster and cheaper, will never be completely solved. There is already so much progress in this area, and there will be more, but we will never run out of room for improvement.</p>

<p>Number 5 and number 6, new architectures and new hardware, are very challenging, but they are inevitable with time. Because of the symbiosis between architecture and hardware – new architecture will need to be optimized for common hardware, and hardware will need to support common architecture – they might be solved by the same company.</p>

<p>Some of these problems won’t be solved using only technical knowledge. For example, number 8, improving learning from human preference, might be more of a policy problem than a technical problem. Number 9, improving the efficiency of the chat interface, is more of a UX problem. We need more people with non-technical backgrounds to work with us to solve these problems.</p>

<p>What research direction are you most excited about? What are the most promising solutions you see for these problems? I’d love to hear from you.</p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intel QuickAssist Technology Zstandard Plugin for Zstandard (132 pts)]]></title>
            <link>https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Intel-QuickAssist-Technology-Zstandard-Plugin-an-External/post/1509818</link>
            <guid>37154939</guid>
            <pubDate>Wed, 16 Aug 2023 22:52:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Intel-QuickAssist-Technology-Zstandard-Plugin-an-External/post/1509818">https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Intel-QuickAssist-Technology-Zstandard-Plugin-an-External/post/1509818</a>, See on <a href="https://news.ycombinator.com/item?id=37154939">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text" id="bodyDisplay">
			
				
					
					
						<p><em>Posted on behalf of:</em></p><p><strong>Author:</strong> Brian Will</p><p><strong>Contributors:</strong> David Qian, Abhishek Khade, Joel Schuetze</p><h2 id="toc-hId--1301673934">Introduction</h2><p><strong><a href="https://github.com/facebook/zstd" target="_blank" rel="noopener nofollow noreferrer">Zstandard</a></strong> (zstd) is one of the most popular lossless compression algorithms/formats in use today due to its exceptional speed in decompression and compression while achieving impressive compression ratios. It's a very flexible format allowing for adaption to many types of data and applications. At a high level, the algorithm is a two-stage process. First, the process of finding matches or repetition in the data that results in possible areas of replacement with a more condensed representation, namely a dictionary coder (e.g., LZ77). The output of this stage is several sequences, each of which specifies an offset to a match, match length, and potentially a literal length. The second stage is a process of encoding these output sequences using Finite State Entropy encoding (FSE) or Huffman encoding.</p><p>The topic for this blog is a new feature added to zstd v1.5.4, which allows for an external implementation of a sequence producer to be injected into the zstd pipeline. This enables the utilization of Intel® QuickAssist Technology (Intel® QAT), which can deliver up to <strong>3.2x better throughput</strong>, <strong>3.8x reduction in P99 latency</strong>, and <strong>3.3x better performance per watt</strong> when compared to zstd for compression. With these improvements, it's expected that Intel QAT will open new breakthrough use cases where compression can now be leveraged for workloads where it would not have been feasible previously.</p><p>Intel QAT will be an external sequence producer for zstd, improving performance while exposing the functionality to applications through the familiar zstd interface.</p><h2 id="toc-hId-1185838899">External Sequence Producers</h2><p>An external sequence producer searches an input buffer for matching bytes in the input set.&nbsp;These matches are represented as a list of `ZSTD_Sequesnce`'s capturing information on:</p><ul><li>distance to matching sequence</li><li>match length</li><li>is match a literal</li><li>rep code information</li></ul><p>We'll also cover details of the interfaces to support external sequence producers, along with an implementation for Intel QAT.</p><h4 id="toc-hId-79449014">Zstandard sequence producer registration function</h4><p>In zstd v1.5.4, the <strong><a href="http://In%20zstd v1.5.4, the block-level sequence producer interface was introduced; this allowed an external ‘plugin’ to be invoked per block of data and respond with a set of sequences (literals and matches) for that data. The interface contains a registration function:" target="_blank" rel="noopener nofollow noreferrer">block-level sequence producer interface</a></strong> was introduced; this allowed an external ‘plugin’ to be invoked per block of data and respond with a set of sequences (literals and matches) for that data. The interface contains a registration function:</p><pre><span>ZSTDLIB_STATIC_API void</span><br>ZSTD_registerSequenceProducer(<br>  ZSTD_CCtx* cctx,<br>  void* sequenceProducerState,<br>  ZSTD_sequenceProducer_F* sequenceProducer);</pre><p>The function produces sequences for zstd and has the following signature:</p><pre>#define ZSTD_SEQUENCE_PRODUCER_ERROR ((size_t)(-1))<br>typedef size_t ZSTD_sequenceProducer_F (<br>  void* sequenceProducerState,<br>  ZSTD_Sequence* outSeqs, size_t outSeqsCapacity,<br>  const void* src, size_t srcSize,<br>  const void* dict, size_t dictSize,<br>  int compressionLevel,<br>  size_t windowSize);</pre><p>This allows an external implementation to register with a ZSTD_CCtx to be called for each block, to compress and pass an opaque state. The state can be used as a location for the sequence producer to maintain any transactional information for this instance.</p><p>By providing this registration capability, the sequence producer is utilized behind the standard zstd interfaces, allowing applications to continue using zstd in the same way, with interfaces such as `ZSTD_compress2()` or `ZSTD_compressStream2()`. While the API is compatible with all zstd APIs which respect advanced parameters, there are some <strong><a href="https://github.com/facebook/zstd/blob/7806d803383b75b00868a5367154a18caf535a92/lib/zstd.h#L2752" target="_blank" rel="noopener nofollow noreferrer">limitations</a></strong>.</p><h4 id="toc-hId--1728005449">QAT Zstandard Plugin sequence producer API</h4><p><strong><a href="https://github.com/intel/QAT-ZSTD-Plugin" target="_blank" rel="noopener nofollow noreferrer">QAT-ZSTD-Plugin</a></strong> provides acceleration of sequence production using Intel QAT through the zstd APIs. The producer function to be registered is provided by <strong><a href="https://github.com/intel/QAT-ZSTD-Plugin/blob/468b7c1254f48e84c4fd2230852f618f1ab72e2d/src/qatseqprod.h#L107" target="_blank" rel="noopener nofollow noreferrer">qatSequenceProducer</a></strong>.</p><pre>size_t qatSequenceProducer(<br>  void *sequenceProducerState, <br>  ZSTD_Sequence *outSeqs, size_t outSeqsCapacity,<br>  const void *src, size_t srcSize,<br>  const void *dict, size_t dictSize,<br>  int compressionLevel,<br>  size_t windowSize);</pre><p>Intel QAT will take the input data stream and search for sequences in hardware, returning a set of output sequences. These are then processed by the zstd library, encoding and constructing zstd formatted data. Intel QAT will increase throughput and decrease latency for a set of zstd's compression levels. The plugin is only applicable to compression operations; it does not support decompression. Not all features of the plugin API are <strong><a href="https://github.com/intel/QAT-ZSTD-Plugin#limitations" target="_blank" rel="noopener nofollow noreferrer">currently supported</a></strong>.</p><p>In the context of Intel QAT, the state variable passed in with the API will be used for storing details of the device being used for acceleration and its configuration and capabilities. As such, this state variable is managed externally to zstd through the producer plugin using the functions `QZSTD_createSeqProdState` and `QZSTD_freeSeqProdState`.</p><p>Intel QAT as a device needs to be started/stopped using the functions `QZSTD_startQatDevice` and `QZSTD_stopQatDevice` prior to registration of the sequence producer. This flow is captured on the plugin repo page, <strong><a href="https://github.com/intel/QAT-ZSTD-Plugin/blob/main/README.md#how-to-integrate-qat-sequence-producer-into-applications" target="_blank" rel="noopener nofollow noreferrer">Integration of Intel QAT sequence producer into an Application</a></strong>.</p><p>These are the changes required to integrate the <strong><a href="https://github.com/intel/QAT-ZSTD-Plugin" target="_blank" rel="noopener nofollow noreferrer">QAT-ZSTD-Plugin</a></strong> into your application. Future iterations will be more transparent.</p><p><span image-alt="zstd-ai-blog-fig01.png"><img src="https://community.intel.com/t5/image/serverpage/image-id/44183iD23FB0F975FE5A7B/image-size/large?v=v2&amp;px=999" role="button" title="zstd-ai-blog-fig01.png" alt="zstd-ai-blog-fig01.png" li-image-url="https://community.intel.com/t5/image/serverpage/image-id/44183iD23FB0F975FE5A7B?v=v2" li-image-display-id="'44183iD23FB0F975FE5A7B'" li-message-uid="'1509818'" li-messages-message-image="true" li-bindable="" tabindex="0" li-bypass-lightbox-when-linked="true" li-use-hover-links="false"></span></p><p>&nbsp;Functional calling sequence to integrate Intel® QAT-Zstd Plugin into your application.</p><h4 id="toc-hId-759507384">Performance results</h4><p>To compare performance data between a software implementation and acceleration with Intel QAT, a benchmark utility was developed that submits requests using the `ZSTD_compress2` interface. The <strong><a href="https://github.com/intel/QAT-ZSTD-Plugin/blob/main/test/benchmark.c" target="_blank" rel="noopener nofollow noreferrer">utility</a></strong>, QAT-ZSTD plugin benchmark, allows for setting the number of threads of execution, the block size in which to compress the input file, compression level, and several other parameters for changing configuration details.</p><p>For these measurements, the command line used was:</p><pre>./benchmark -m${mode} -l1 –t${threads} –c${blocksize} –L${compression_level} –E2 &lt;input_file&gt;</pre><ul><li>mode: defines if the operations should be run purely in software "0" or uses Intel(r) QAT for acceleration "1".</li><li>threads: the number of pthreads used for submitting compression requests simultaneously.</li><li>blocksize: input file will be chunked into the specified size and submitted to the zstd API. Input can be submitted as KBs or MBs, e.g., 16K is 16,384.</li><li>compression_level: the level value passed in on the zstd compression API.</li><li>input_file: for these benchmarks Silesia Corpus is the input data set.</li></ul><h4 id="toc-hId--1047947079">QAT ZSTD Plugin Sequence Producer compared to zstd-1.5.4</h4><p>The following measurements were taken using a block size of 16KB with Intel QAT HW configured for its best compression ratio.</p><p>Intel QAT is delivering up to <strong>3.2x higher throughput</strong> compared to zstd compression level 5 and <strong>2.5x compared to zstd level 4</strong>. For the Silesia Corpus, data compression ratios are:</p><ul><li>QAT-ZSTD level 9: 2.76</li><li>zstd level 4: 2.74</li><li>zstd level 5: 2.77</li></ul><p><strong>Ratio</strong>: is calculated as the input size divided by the output size from compression.</p><p>Intel QAT reaches a peak performance of <strong>11.15 Giga Bytes</strong>. If an application requires further performance, zstd software can be utilized to continue scaling, all while using the same interface from the application.</p><p><span image-alt="zstd-ai-blog-fig02.png"><img src="https://community.intel.com/t5/image/serverpage/image-id/44184i252600BDFD392739/image-size/large?v=v2&amp;px=999" role="button" title="zstd-ai-blog-fig02.png" alt="zstd-ai-blog-fig02.png" li-image-url="https://community.intel.com/t5/image/serverpage/image-id/44184i252600BDFD392739?v=v2" li-image-display-id="'44184i252600BDFD392739'" li-message-uid="'1509818'" li-messages-message-image="true" li-bindable="" tabindex="0" li-bypass-lightbox-when-linked="true" li-use-hover-links="false"></span></p><p>Compression throughput performance (MB/s) for 16KB requests, comparing Zstandard v1.5.5 vs Intel® QAT-Zstd Plugin across various core combinations.&nbsp;</p><p>If your application is latency sensitive, Intel QAT can reduce P99 request latency to <strong>~1/4</strong> that of zstd in this configuration and maintain a flat latency. QAT-ZSTD delivers up to <strong>3.8x lower P99 latency</strong> compared to zstd level 5 and <strong>3.2x</strong> compared to zstd level 4.</p><p><span image-alt="zstd-ai-blog-fig03.png"><img src="https://community.intel.com/t5/image/serverpage/image-id/44185i7D1FADE0DE1554C1/image-size/large?v=v2&amp;px=999" role="button" title="zstd-ai-blog-fig03.png" alt="zstd-ai-blog-fig03.png" li-image-url="https://community.intel.com/t5/image/serverpage/image-id/44185i7D1FADE0DE1554C1?v=v2" li-image-display-id="'44185i7D1FADE0DE1554C1'" li-message-uid="'1509818'" li-messages-message-image="true" li-bindable="" tabindex="0" li-bypass-lightbox-when-linked="true" li-use-hover-links="false"></span></p><p>P99 16KB request latency (microseconds) comparing Zstandard v1.5.5 vs. Intel® QAT-Zstd Plugin across various core combinations.&nbsp;</p><p>A detailed system configuration is below.</p><h4 id="toc-hId-1439565754">Power comparison</h4><p>The savings we have covered with throughput and latency also come with a power-saving component. Intel QAT acceleration is able to deliver up to <strong>3.3x better performance per watt</strong> when compared to zstd level 5 software alone.</p><p><strong><span color="#993300"><span image-alt="zstd-ai-blog-fig04.png"><img src="https://community.intel.com/t5/image/serverpage/image-id/44628iCF32F8C26281A84B/image-size/large?v=v2&amp;px=999" role="button" title="zstd-ai-blog-fig04.png" alt="zstd-ai-blog-fig04.png" li-image-url="https://community.intel.com/t5/image/serverpage/image-id/44628iCF32F8C26281A84B?v=v2" li-image-display-id="'44628iCF32F8C26281A84B'" li-message-uid="'1509818'" li-messages-message-image="true" li-bindable="" tabindex="0" li-bypass-lightbox-when-linked="true" li-use-hover-links="false"></span></span></strong></p><p>Performance per Watt comparison for QAT ZSTD plugin and Zstandard v1.5.5 software for 16KB requests</p><p>Data is collected using the same utility; details are captured in the configuration section below.</p><p>If we view this from the angle of cores saved</p><p><span image-alt="zstd-ai-blog-fig05.png"><img src="https://community.intel.com/t5/image/serverpage/image-id/44187i840F7ACCC8F8951E/image-size/large?v=v2&amp;px=999" role="button" title="zstd-ai-blog-fig05.png" alt="zstd-ai-blog-fig05.png" li-image-url="https://community.intel.com/t5/image/serverpage/image-id/44187i840F7ACCC8F8951E?v=v2" li-image-display-id="'44187i840F7ACCC8F8951E'" li-message-uid="'1509818'" li-messages-message-image="true" li-bindable="" tabindex="0" li-bypass-lightbox-when-linked="true" li-use-hover-links="false"></span></p><p>Core savings when utilizing Intel® QAT-Zstd Plugin vs. Zstandard v1.5.5 for 16KB request sizes.</p><p>This represents a <strong>core savings of 73%</strong> for similar throughput and compression ratios when using Intel QAT Acceleration. This translates into acceleration, with Intel QAT taking <strong>90W less wall power</strong> when compared to Zstandard software. This is a significant savings in platform power while providing additional cores for other application workloads to use.</p><h2 id="toc-hId--1068953287">Conclusion</h2><p>The addition of the sequence producer interface into zstd allows for the acceleration of one of the more costly operations in the compression pipeline, namely searching for matching byte strings. Intel QAT is able to provide HW acceleration of this function, delivering throughput improvements up to <strong>3.2x over zstd SW</strong> and <strong>P99 latency reduction of 3.8x</strong> for a comparable compression ratio. All while delivering <strong>3.3x better performance per watt</strong>.</p><p>Tight integration into zstd allows the application to access Intel QAT acceleration while programming to the same zstd interfaces. Applications will be able to easily access Intel QAT acceleration with a future path to transparent integration.</p><p>Intel QAT provides tangible value for applications in throughput, latency, and power leading to an overall Total Cost of Ownership benefit for applications requiring compression performance. The QAT ZSTD Plugin will continue adding features to improve compression ratio (dictionary support) and performance.</p><h4 id="toc-hId-2119624124">Want to learn more? Please visit the following:</h4><ul><li><strong><a href="https://www.intel.com/content/www/us/en/developer/topic-technology/open/quick-assist-technology/overview.html" target="_blank" rel="noopener nofollow noreferrer">developer.intel.com/quickassist</a></strong></li><li><strong><a href="https://intel.github.io/quickassist/index.html" target="_blank" rel="noopener nofollow noreferrer">Intel QuickAssist Technology Documentation - Hardware Version 2.0 — Intel® QuickAssist Technology documentation</a></strong></li></ul><h4 id="toc-hId-312169661">Configuration</h4><ul><li>Intel® 4xxx (Intel®QuickAssist Technology (Gen 4)</li><li>Intel®Xeon® Platinum 8470N Processor<ul><li>Turbo Disabled</li></ul></li><li>Memory configuration:<ul><li>DDR5 4800 MT/s</li><li>32 GB * 16 DIMMs</li></ul></li><li>QAT Driver:<ul><li>QAT20.L.1.0.40</li></ul></li><li>Hyper-Thread enabled</li><li>OS (Kernel):<ul><li>Ubuntu 22.04.1 LTS</li></ul></li><li>BIOS:<ul><li>EGSDCRB1.SYS.9409.P01.2211280753</li><li>SpeedStep (Pstates) disabled</li><li>Turbo Mode disabled</li></ul></li><li>QAT configuration:<ul><li>ServicesEnabled – dc</li><li>NumberCyInstances – 0</li><li>NumberDcInstances – 1-64</li><li>SVM Disabled &amp; ATS Disabled</li></ul></li><li>Test file<ul><li>[Silesia corpus](<a href="http://sun.aei.polsl.pl/~sdeor/corpus/silesia.zip" target="_blank" rel="noopener nofollow noreferrer"><strong>http://sun.aei.polsl.pl/~sdeor/corpus/silesia.zip</strong></a>)</li></ul></li><li>Software<ul><li>Zstandard: &lt;<strong><a href="https://github.com/facebook/zstd.git" target="_blank" rel="noopener nofollow noreferrer">https://github.com/facebook/zstd.git</a></strong>&gt; tag v1.5.5</li><li>QAT ZSTD Plugin: &lt;<strong><a href="https://github.com/intel/QAT-ZSTD-Plugin/releases/tag/v0.0.1" target="_blank" rel="noopener nofollow noreferrer">https://github.com/intel/QAT-ZSTD-Plugin/releases/tag/v0.0.1</a></strong>&gt;</li></ul></li><li>Benchmark tool: Included with Intel(r) QAT ZSTD plugin<ul><li>Disable searchForExternalRepcodes</li><li>Test command: `./benchmark -m${mode} -l1 –t${threads} –c${blocksize} –L${compression_level} –E2`</li><li>Example: numactl -C 1-18,105-122 ./test/benchmark -l2 -t36 -L9 -c16K -m1 -E2 silesia.concat</li></ul></li></ul><h4 id="toc-hId--264414203">Configuration Details:</h4><p>Test by Intel as of 05/22/23. 1-node, 2x Intel(R) Xeon(R) Platinum 8470N, 52 cores, HT On, Turbo On, Total Memory 512GB (16x32GB DDR5 4800 MT/s [4800 MT/s]),&nbsp;BIOS EGSDCRB1.SYS.9409.P01.2211280753, microcode 0x2b000161, 2x 223.6G KINGSTON SUV400S37240G, 1x 447.1G INTEL SSDSC2BB480G7, 1x 240M Disk, Ubuntu 22.04.1 LTS, 5.15.0-56-generic, GCC 11.3.0, QAT ZSTD: v1.5.5, QAT-ZSTD-Plugin: v0.0.1, QAT Driver:QAT20.L.1.0.40</p><h4 id="toc-hId--2071868666">Notices and Disclaimers</h4><p>Performance varies by use, configuration, and other factors. Learn more on the <strong><a href="https://edc.intel.com/content/www/us/en/products/performance/benchmarks/" target="_blank" rel="noopener nofollow noreferrer">Performance Index site</a></strong>.<br>Performance results are based on testing as of dates shown in configurations and may not reflect all publicly available updates. No product or component can be absolutely secure.</p><p>Your costs and results may vary.</p><p>Intel technologies may require enabled hardware, software, or service activation.</p><p>© Intel Corporation. Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries. Other names and brands may be claimed as the property of others.</p>
					
				
			
			
			
			
			
			
			
			
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[$70 device can spoof an Apple device sending BLE Advertising Packets (117 pts)]]></title>
            <link>https://techcrunch.com/2023/08/16/this-70-device-can-spoof-an-apple-device-and-trick-you-into-sharing-your-password/</link>
            <guid>37154473</guid>
            <pubDate>Wed, 16 Aug 2023 22:02:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2023/08/16/this-70-device-can-spoof-an-apple-device-and-trick-you-into-sharing-your-password/">https://techcrunch.com/2023/08/16/this-70-device-can-spoof-an-apple-device-and-trick-you-into-sharing-your-password/</a>, See on <a href="https://news.ycombinator.com/item?id=37154473">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p id="speakable-summary">Attendees at Def Con, one of the world’s largest hacking conferences, are used to weird shenanigans, such as <a href="https://www.wallofsheep.com/pages/wall-of-sheep" target="_blank" rel="noopener">a seemingly innocuous wall of computer screens that display people’s passwords</a> sniffed over the conference Wi-Fi network. But at this year’s event, even conference veterans were confused and concerned when their iPhones started showing pop-up messages <a href="https://techcrunch.com/2023/08/14/researcher-says-they-were-behind-iphone-popups-at-def-con/">prompting them to connect their Apple ID or share a password with a nearby Apple TV</a>.</p>

<p>As it turned out, these alerts were part of <a href="https://techcrunch.com/2023/08/14/researcher-says-they-were-behind-iphone-popups-at-def-con/">a research project that had two goals</a>.</p>
<p>One was to remind people that to switch off Bluetooth on an iPhone, you have to dig into the Settings app and not just tap it off on the quick-access Control Center, which is displayed by swiping down from the top right corner of the iPhone.</p>
<p>The other was “to have a laugh,” <a href="https://infosec.exchange/@jb0x168/110879394826675242" target="_blank" rel="noopener">according to Jae Bochs</a>, the security researcher who said they walked around the conference triggering these pop-ups with a custom-made device.</p>
<p>“I had it in my bag throughout linecon [an informal term that refers to the time spent in line at a conference], vendor areas, and when I was walking around. I tried to remember to disconnect it if I was hanging out for a talk,” Bochs said.</p>
<p>Bochs told TechCrunch that all they needed for this experiment was a contraption consisting of a <a href="https://www.raspberrypi.com/products/raspberry-pi-zero-2-w/" target="_blank" rel="noopener">Raspberry Pi Zero 2 W</a>, two antennas, a Linux-compatible Bluetooth adapter, and a portable battery.</p>
<p>Bochs estimated that this combination of hardware, excluding the battery, costs around $70 and has a range of 50 feet, or 15 meters.</p>

<p>They explained that Apple’s protocols for Bluetooth low energy, or BLE, allow the company devices to communicate with each other. Bochs said that they focused on “proximity actions,” which appear on an iPhone screen when Apple devices are close to each other.</p>
<p>“Proximity is determined by BLE signal strength, and it seems most devices intentionally use lowered transmit power for these to keep the range short. I don’t :),” Bochs said.</p>
<p>Bochs also said they created a proof-of-concept that “builds a custom advertisement packet that mimics what Apple TV etc. are constantly emitting at low power,” effectively spoofing an Apple device that tries to repeatedly connect to nearby devices and triggers the pop-ups.</p>
<p>Unlike real Apple devices, his contraption wasn’t programmed to collect any data from nearby iPhones, even if the person tapped and accepted the prompts. But, in theory, they could have collected some data, according to Bochs.</p>
<p>“If a user were to interact with the prompts, and if the other end was set up to respond convincingly, I think you could get the ‘victim’ to transfer a password,” Bochs said. “There’s an issue known for a few years where you can retrieve phone number, Apple ID email, and current Wi-Fi network from the packets.”</p>
<p>The researcher said these issues are already known, at least since <a href="https://arxiv.org/abs/1904.10600" target="_blank" rel="noopener">a 2019 academic paper</a> that studied Apple’s Bluetooth low energy protocol and concluded that there are “several flaws” that “leak device and behavioral data to nearby listeners.”</p>
<p>“Individually, each flaw leaks a small amount of information, but in aggregate they can be used to identify and track devices over long periods of time,” the researchers wrote in the paper.</p>
<p>That’s why, Bochs said, they think Apple won’t do anything about this.</p>
<p>“Most or all of this is certainly by design, so that watches and headphones keep working with Bluetooth toggled,” they said.</p>
<p>Perhaps, they added, Apple could add a warning message when using the Control Panel toggles that alerts the user that tapping on its Bluetooth icon doesn’t completely shut off Bluetooth and their iPhone can still interact with proximity-activated beacons, such as Bochs’ contraption.</p>
<p>By turning Bluetooth off in the settings, an iPhone user would be safe from devices like theirs, Bochs explained.</p>
<p>Apple did not respond to a request for comment.</p>
<hr>
<p><em>Do you have information about similar hacks against iPhones? We’d love to hear from you. From a non-work device, you can contact Lorenzo Franceschi-Bicchierai securely on Signal at +1 917 257 1382, or via Telegram and Wire @lorenzofb, or email lorenzo@techcrunch.com. You also can contact TechCrunch via <a href="https://techcrunch.com/tips">SecureDrop</a>.</em></p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Naomi Wu and the Silence That Speaks Volumes (403 pts)]]></title>
            <link>https://www.hackingbutlegal.com/naomi-wu-and-the-silence-that-speaks-volumes/</link>
            <guid>37154414</guid>
            <pubDate>Wed, 16 Aug 2023 21:55:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.hackingbutlegal.com/naomi-wu-and-the-silence-that-speaks-volumes/">https://www.hackingbutlegal.com/naomi-wu-and-the-silence-that-speaks-volumes/</a>, See on <a href="https://news.ycombinator.com/item?id=37154414">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcf83757-4eda-4a15-8135-39b34383bbf5_1367x1120.jpeg" data-component-name="Image2ToDOM"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcf83757-4eda-4a15-8135-39b34383bbf5_1367x1120.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcf83757-4eda-4a15-8135-39b34383bbf5_1367x1120.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcf83757-4eda-4a15-8135-39b34383bbf5_1367x1120.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcf83757-4eda-4a15-8135-39b34383bbf5_1367x1120.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcf83757-4eda-4a15-8135-39b34383bbf5_1367x1120.jpeg" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/dcf83757-4eda-4a15-8135-39b34383bbf5_1367x1120.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:null,&quot;width&quot;:null,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Naomi Wu and the Silence That Speaks Volumes&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="Naomi Wu and the Silence That Speaks Volumes" title="Naomi Wu and the Silence That Speaks Volumes" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcf83757-4eda-4a15-8135-39b34383bbf5_1367x1120.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcf83757-4eda-4a15-8135-39b34383bbf5_1367x1120.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcf83757-4eda-4a15-8135-39b34383bbf5_1367x1120.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcf83757-4eda-4a15-8135-39b34383bbf5_1367x1120.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><p><em>When China's prodigious tech influencer, Naomi Wu, found herself silenced, it wasn't just the machinery of a surveillance state at play. Instead, it was a confluence of state repression and the sometimes capricious attention of a Western audience that, as she asserts, often views Chinese activists more as ideological tokens than as genuine human beings.</em></p><p><em><strong>Scroll down for my interview notes with Naomi Wu.</strong></em></p><p>From the bustling technological hub of Shenzhen, the pseudonymous Naomi Wu, who is also widely known as "Sexy Cyborg", emerged as a striking embodiment of DIY tech prowess and authenticity. Her presence graced my Twitter feed for many years as an avatar of idealized femininity who proffered creative technical innovations, typically of her own creation, to a delighted Western audience, myself included.</p><p>Wu, 29, is unquestionably an expert, despite frequent public suggestions from anonymous cowards suggesting her particular physical form disqualifies her from being one. In fact, I would personally classify her as a modern version of a Renaissance woman given her unconventional style, lack of formal training, unique personality, and unusually wide range of interests and capabilities.</p><p>💡</p><p><span>Curious about Wu's look? Watch </span><a href="https://www.youtube.com/watch?v=Z9vW_MpXTfs" rel="nofollow ugc noopener">this</a><span>.</span></p><p>As an example, here she is comprehensively breaking down the capabilities (or lack thereof) of a high-tech filtration mask in a manner which is likely to be beyond your understanding:</p><div><figure><div id="youtube2-nDzhGjbvVGc" data-attrs="{&quot;videoId&quot;:&quot;nDzhGjbvVGc&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/nDzhGjbvVGc?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div><figcaption><span>Source: Naomi Wu/</span><a href="https://www.youtube.com/@Naomi-Wu" rel="nofollow ugc noopener">YouTube</a></figcaption></figure></div><p><span>Wu's above video </span><a href="https://kotaku.com/tech-experts-razer-lied-about-its-fancy-zephyr-mask-1848340447" rel="nofollow ugc noopener">forced</a><span> the mask's seller, computer hardware manufacturer Razer, to issue a public response to her findings and to "remove all references" to "N95 Grade Filter" from their marketing material.</span></p><p><span>...and here is a 2017 video in which she develops a custom </span><a href="https://www.theregister.com/2022/10/12/drone-roof-attack/" rel="nofollow ugc noopener">hacking drone</a><span> called "Screaming Fist":</span></p><div><figure><div id="youtube2-Cdk4Zw2oYdc" data-attrs="{&quot;videoId&quot;:&quot;Cdk4Zw2oYdc&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/Cdk4Zw2oYdc?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div><figcaption><span>Source: Naomi Wu/</span><a href="https://www.youtube.com/@Naomi-Wu" rel="nofollow ugc noopener">YouTube</a></figcaption></figure></div><p><span>Though </span><a href="https://en.wikipedia.org/wiki/Naomi_Wu" rel="nofollow ugc noopener">Wu</a><span>'s technical acumen has always set her apart, and while yes, she also happens to be a beautiful woman, it was always her audacious authenticity alongside that unconventional cyberpunk aesthetic which garnered immense respect.</span></p><p><span>Through her creative content and generous engagement with followers across various social media platforms (</span><a href="https://www.youtube.com/@Naomi-Wu" rel="nofollow ugc noopener">YouTube</a><span>: 1.61m subscribers/295m views, </span><a href="https://twitter.com/realsexycyborg" rel="nofollow ugc noopener">Twitter</a><span>: 248K, </span><a href="https://www.instagram.com/reallysexycyborg/" rel="nofollow ugc noopener">Instagram</a><span>: 175K), she regularly shared glimpses of her life with her dogs and partner, all slipstreamed alongside deeply technical DIY content; her hallmark.</span></p><p>Naomi's partner, Kaidi, belongs to the Uyghur minority, further heightening the vulnerability of their situation.</p><p>Wu has served as a kind of cultural ambassador for individuals like me, offering insights into authentic Chinese perspectives. But it is precisely her open embrace of the world, facilitated by global social media, that appears to have ultimately made Wu more vulnerable to state pressures. The way she managed the balance of championing her personal beliefs while circumventing overt criticism of her home country was nothing short of an art form.</p><p>Wu's role in the hardware hacking scene has been pivotal in challenging stereotypes about who belongs in the tech world. Her presence confidently occupies the space she's carved out, one where authenticity and expertise are the primary criteria for recognition. However, her relatability might have exposed her to additional risks. Despite the challenges she faces at home, her success as a major tech influencer on the global stage seems to have placed her within her government's sights.</p><p>Despite her primarily Western audience, Wu has consistently encountered unfavorable treatment from Western media, often tinged with misogyny. Notably, a VICE Magazine reporter appeared to consider outing Wu without her consent, potentially jeopardizing her safety by revealing personal information. In a separate troubling incident, the founder of Make Magazine was compelled to issue a public apology after insinuating that Wu wasn't a "real" human, a baffling assertion considering her substantial and well-documented contributions on YouTube.</p><p>Naomi Wu's devastating July 7th tweet alluded to a pressure that had long been feared by many, yet optimistically hoped she could manage to avoid indefinitely.</p><div><figure><blockquote><p>Ok for those of you that haven't figured it out I got my wings clipped and they weren't gentle about it- so there's not going to be much posting on social media anymore and only on very specific subjects. I can leave but Kaidi can't so we're just going to follow the new rules and…</p><p><span>— Naomi Wu 机械妖姬 (@RealSexyCyborg) </span><a href="https://twitter.com/RealSexyCyborg/status/1677480809450835969?ref_src=twsrc%5Etfw" rel="nofollow ugc noopener">July 8, 2023</a></p></blockquote><figcaption><span>Source: @RealSexyCyborg/</span><a href="https://twitter.com/RealSexyCyborg/status/1677480809450835969" rel="nofollow ugc noopener">Twitter</a></figcaption></figure></div><blockquote><p>"Ok for those of you that haven't figured it out I got my wings clipped and they weren't gentle about it- so there's not going to be much posting on social media anymore and only on very specific subjects. I can leave but Kaidi can't so we're just going to follow the new rules and that's that. Nothing personal if I don't like and reply like I used to. I'll be focusing on the store and the occasional video. Thanks for understanding, it was fun while it lasted." –@RealSexyCyborg, July 7, 2023</p></blockquote><p><span>Although this was not the first instance of Chinese authorities scrutinizing the tech expert (a similar occurrence </span><a href="https://twitter.com/RealSexyCyborg/status/1177145458503737344" rel="nofollow ugc noopener">transpired</a><span> in 2019), the most disconcerting element of this incident lies in the conspicuous lack of media coverage—a perplexing omission given Wu's standing as an emblem within the DIY/maker communities and her prior media exposure.</span></p><p data-attrs="{&quot;url&quot;:&quot;/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe Now&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.hackingbutlegal.com/subscribe?" rel="nofollow ugc noopener"><span>Subscribe Now</span></a></p><p>Conversely, a recent hoax originating from a social media account belonging to child influencer Lil Tay claimed she and her brother had died, and generated a rapid flurry of coverage.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22bd74a8-6a8a-4309-ac29-b8af19fe58cf_1646x1580.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22bd74a8-6a8a-4309-ac29-b8af19fe58cf_1646x1580.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22bd74a8-6a8a-4309-ac29-b8af19fe58cf_1646x1580.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22bd74a8-6a8a-4309-ac29-b8af19fe58cf_1646x1580.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22bd74a8-6a8a-4309-ac29-b8af19fe58cf_1646x1580.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22bd74a8-6a8a-4309-ac29-b8af19fe58cf_1646x1580.png" width="1646" height="1580" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/22bd74a8-6a8a-4309-ac29-b8af19fe58cf_1646x1580.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1580,&quot;width&quot;:1646,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22bd74a8-6a8a-4309-ac29-b8af19fe58cf_1646x1580.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22bd74a8-6a8a-4309-ac29-b8af19fe58cf_1646x1580.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22bd74a8-6a8a-4309-ac29-b8af19fe58cf_1646x1580.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22bd74a8-6a8a-4309-ac29-b8af19fe58cf_1646x1580.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Source: Google News</figcaption></figure></div><p>Could these be geopolitical hesitations standing in the way? Or merely some unfortunate oversight amidst the relentless news churn on the part of those outlets who previously covered her? The tech media's relative silence in the face of Wu's abrupt disconnection illuminates a disconcerting landscape of media acquiescence.</p><p>The omission of her predicament by the media isn't just an oversight—it's a signal suggesting that a significant portion of western media may be increasingly compromised by Beijing's influence, finding themselves unable to criticize foreign policy, lest they rile the tiger and negatively impact their business. A key reason influencers like Wu are able to gain traction is because of the validation they receive from the public and media alike. Silence in such distressing situations can easily be misinterpreted as indifference. Furthermore, when cultural ambassadors like Wu find themselves precipitously exiled from public life, it sends a cautionary tale to those who might have once been emboldened to share their own stories.</p><p><span>These conditions are exacerbated by an apparent and </span><a href="https://www.bellingcat.com/resources/2023/04/18/china-challenges-open-source-osint-social-media/" rel="nofollow ugc noopener">ever-tightening grip</a><span> on information from inside China, and amidst these macro concerns lies an added poignant truth about representation and freedom of expression: Naomi Wu is not just a tech virtuoso; she is a living embodiment of resilience for a global LGBTQ community which is navigating increasingly restrictive terrains. Wu's pullback from the public gaze not only deprives the tech world of an icon, it also robs Wu's wider community of a valuable symbol of tenacity, hope, and self-love in the face of repressive state control.</span></p><p>The relentless surveillance and censorship tactics utilized by the Chinese Communist Party are not unfamiliar to the global audience. The tragic predicament of the Uyghurs, a cultural and ethnic Chinese minority subjected to what many have called genocide, stands testament to the CCP's intent to tightly control the cultural viewpoints of its population by any means they consider necessary, even if brutal.</p><p><span>Given these precedents, there is a growing apprehension that Wu's digital silence signals a new chapter in China's human rights transgressions–one in which the LGBTQ community potentially emerges as the newest target of state-led oppression, in keeping with </span><a href="https://www.hrw.org/news/2022/09/06/how-targeting-lgbtq-rights-are-part-authoritarian-playbook" rel="nofollow ugc noopener">global trends</a><span>.</span></p><p><span>Ying Xin, Beijing's LGBT Center's Executive Director, </span><a href="https://outrightinternational.org/sites/default/files/2022-09/Ying_Xin_China_panel.pdf" rel="nofollow ugc noopener">provided</a><span> the statistic that only 5% of Chinese people identifying as LGBTIQ are "out" to their families, with an added 0.1% reporting being out in their professional lives as well.</span></p><p><span>As described by </span><a href="https://outrightinternational.org/our-work/human-rights-research/precarious-progress-advocacy-human-rights-lgbt-people-china" rel="nofollow ugc noopener">Outright International</a><span>:</span></p><blockquote><p>The LGBT community in China has experienced a period of tremendous change. Over the course of the past several decades, LGBT people have gone from being nearly invisible in Chinese society, to forming a vibrant social movement.</p></blockquote><blockquote><p>Progress has been promising, but remains precarious. Discrimination and state repression are still pervasive, and advocates must navigate treacherous and ever-changing political waters. Strings of news celebrating progress – a court ruling against a clinic offering so-called conversion therapy, a campaign going viral, are punctuated by setbacks — the police detaining activists and shutting down events, censors removing online content, and policymakers snubbing calls for equality.</p></blockquote><blockquote><p>Developments have been rapid, and full of twists and turns.</p></blockquote><p>In fact, one of the latest turns is the Beijing LGBT Center's closure by the Chinese government in May of this year. This move came even after the Center took the preemptive step of changing its name to minimize its association with sexual minorities, underscoring the length to which such organizations must go to adapt to an increasingly restrictive environment: total shutdown.</p><div><figure><blockquote><p><span>The Beijing LGBT Center announced its closure today. Founded in 2008, the Center was a vibrant community space &amp; a groundbreaking advocacy organization. Their team spearheaded pioneering research, and built networks of LGBTQ-affirming health &amp; business professionals. 1/5 </span><a href="https://t.co/mfZlpLrKSD" rel="nofollow ugc noopener">pic.twitter.com/mfZlpLrKSD</a></p><p><span>— Darius Longarino 龙大瑞 (@DariusLongarino) </span><a href="https://twitter.com/DariusLongarino/status/1658097102440808449?ref_src=twsrc%5Etfw" rel="nofollow ugc noopener">May 15, 2023</a></p></blockquote><figcaption><span>Source: @DariusLongarino/</span><a href="https://twitter.com/DariusLongarino/status/1658097102440808449" rel="nofollow ugc noopener">Twitter</a></figcaption></figure></div><p>Below is a rough translation of the Center's above statement, originally posted on their WeChat. Note the Center's use of a term, "不可抗力", which Google translates to "force majeure"; both an umbrella term and oblique manner with which to refer to a forcible circumstance outside one's control.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc078df92-7479-47b4-adb8-9d72a6a181d8_1702x1626.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc078df92-7479-47b4-adb8-9d72a6a181d8_1702x1626.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc078df92-7479-47b4-adb8-9d72a6a181d8_1702x1626.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc078df92-7479-47b4-adb8-9d72a6a181d8_1702x1626.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc078df92-7479-47b4-adb8-9d72a6a181d8_1702x1626.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc078df92-7479-47b4-adb8-9d72a6a181d8_1702x1626.png" width="1702" height="1626" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c078df92-7479-47b4-adb8-9d72a6a181d8_1702x1626.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1626,&quot;width&quot;:1702,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc078df92-7479-47b4-adb8-9d72a6a181d8_1702x1626.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc078df92-7479-47b4-adb8-9d72a6a181d8_1702x1626.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc078df92-7479-47b4-adb8-9d72a6a181d8_1702x1626.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc078df92-7479-47b4-adb8-9d72a6a181d8_1702x1626.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Source: Google Translate</figcaption></figure></div><p>What did the Center mean by "force majeure"?</p><p><span>The reported reality is that nonprofit organizations supporting LGBTQ in China are unable to function without fear, as members </span><a href="https://outrightinternational.org/Chinas-Fading-Rainbow" rel="nofollow ugc noopener">often</a><span> face police interrogations, personal property inspections, and intimidation, even if they leave the country. The government has increasingly accused such groups of collusion with "foreign forces," emphasizing connections with countries like the U.S. and members of the Five Eyes alliance. As a result, many activists face demands like the prohibition of events, social media account closures, and bans on regular social and dating activities.</span></p><p>The public space for the LGBTQ community in China has been steadily shrinking.</p><p><span>As noted by the </span><a href="https://apnews.com/article/china-beijing-lgbt-center-shutdown-a5643c680e1faf5c8a7a7d9bdd627d6f" rel="nofollow ugc noopener">Associated Press</a><span>:</span></p><blockquote><p>Police pressure on rights groups increased in the past few years, the activist said. Police often invited LGBTQ+ groups to “drink tea” — a euphemism for unofficial meetings that police use to keep track of certain targets. That used to happen in public spaces, but started taking place in private spaces, such as directly in front of activists’ homes. Police also started taking activists to the police station for these “teas,” the activist said.</p></blockquote><p>When I was able to speak to Ms. Wu about the "tea drinking" session (euphemism for police harassment), she sharply conveyed her sense of vulnerability due to the lack of interest in her stepping away from her popular Twitter account, stating,</p><blockquote><p>Literally the only thing that was keeping me online for the past few years was they were worried it would make China look bad if they cracked down on me. Now that they know that I could be dead in a ditch tomorrow and no one would give a shit or say a word I’m 1000x less safe here.</p></blockquote><p>Further emphasizing the complexities of her identity and the West's interpretation of it, she said,</p><blockquote><p>Having a real-life Chinese person posting here who does not 100% endorse every part of their China good/bad narrative makes it harder for them [the media].</p></blockquote><p>Through Wu's lens, the nuances of her experiences become inconvenient wrinkles in a narrative Western media wishes to smooth out, one in which we prefer our subjects to be neatly framed, silent victims whose stories can be manipulated without pushback.</p><p>Wu added,</p><blockquote><p>After years of doing this without anyone saying anything, on June 30th, out of the blue, they send plainclothes thugs to my house. Surprise! They were real cops.</p></blockquote><p>This event on June 30th was timed closely with events associated with a cybersecurity vulnerability report delivered to Tencent by researchers based at The Citizen Lab at the Munk School of Global Affairs, University of Toronto. This recent reporting, authored by Jeffrey Knockel, Zoë Reichert, and Mona Wang, addressed a serious, encryption-related vulnerability in Tencent's popular Sogou keyboard software, affecting 455m monthly users.</p><div><figure><blockquote><p><span>data leakage from keyboard apps sounds like something </span><a href="https://twitter.com/RealSexyCyborg?ref_src=twsrc%5Etfw" rel="nofollow ugc noopener">@RealSexyCyborg</a><span> was trying to raise awareness of for some years, especially as it relates to their usage alongside secure messaging apps</span></p><p><span>— nobody (@imaguid) </span><a href="https://twitter.com/imaguid/status/1689296523874422784?ref_src=twsrc%5Etfw" rel="nofollow ugc noopener">August 9, 2023</a></p></blockquote><figcaption>Source: @imaguid/Twitter</figcaption></figure></div><p><span>While Citizen Lab's </span><a href="https://citizenlab.ca/2023/08/vulnerabilities-in-sogou-keyboard-encryption/" rel="nofollow ugc noopener">report</a><span> was published on August 9th, the vulnerability itself was initially reported back on May 31st per the disclosure timeline. A presumed lack of response led the researchers to attempt another disclosure method. A month later, on June 25th, Tencent dismissed the report as a "low security risk" and mocked it as not "exciting".</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0e86e0c-c48b-4c4b-bec6-9d341d974acd_1556x1286.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0e86e0c-c48b-4c4b-bec6-9d341d974acd_1556x1286.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0e86e0c-c48b-4c4b-bec6-9d341d974acd_1556x1286.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0e86e0c-c48b-4c4b-bec6-9d341d974acd_1556x1286.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0e86e0c-c48b-4c4b-bec6-9d341d974acd_1556x1286.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0e86e0c-c48b-4c4b-bec6-9d341d974acd_1556x1286.png" width="1556" height="1286" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d0e86e0c-c48b-4c4b-bec6-9d341d974acd_1556x1286.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1286,&quot;width&quot;:1556,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0e86e0c-c48b-4c4b-bec6-9d341d974acd_1556x1286.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0e86e0c-c48b-4c4b-bec6-9d341d974acd_1556x1286.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0e86e0c-c48b-4c4b-bec6-9d341d974acd_1556x1286.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0e86e0c-c48b-4c4b-bec6-9d341d974acd_1556x1286.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>Source: “Please do not make it public” Vulnerabilities in Sogou Keyboard encryption expose keypresses to network eavesdropping/</span><a href="https://citizenlab.ca/2023/08/vulnerabilities-in-sogou-keyboard-encryption/" rel="nofollow ugc noopener">Citizen Lab</a></figcaption></figure></div><p>According to Citizen Lab's report, Tencent changed their mind less than a day later and nicely asked the researchers not to make their report public:</p><blockquote><p><em>Sorry, my previous reply was wrong, we are dealing with this vulnerability, please do not make it public, thank you very much for your report.</em></p></blockquote><p>The researchers replied:</p><blockquote><p>Thank you for the update. We will publicly disclose the vulnerability after July 31, 2023.</p></blockquote><p><span>As we can see, the vendor finally sat up and took official notice of this severe, privacy-affecting software bug on June 25th–</span><em>only five days before Wu, who has previously tweeted about a vulnerability affecting the same Sogou software, was paid a visit by Chinese authorities.</em></p><p>Wu explicitly drew this connection in my discussion with her:</p><blockquote><p>Five days after Tencent (Shenzhen) admits to the IME vulnerability, the Chinese person (in Shenzhen) who originally publicized it suddenly gets dragged in by the cops and forced offline.</p></blockquote><blockquote><p>NONE of them could read English to see my account does not even make China look bad, it was all Baidu fucking translate and demands why I was talking about Signal and the keyboard</p></blockquote><p>Her account concluded with an unsettling revelation about the risk she would face if she were to continue tweeting: having already received two "strikes" from the authorities, a third could mean a years-long prison sentence.</p><blockquote><p>I had to sign and fingerprint a "confession".</p></blockquote><p>So, how could a security vulnerability in a Chinese mobile software play a part in Wu's recent warning from Chinese police?</p><p><span>Wu herself had previously sent various public tweets obliquely warning about similar, privacy harming issues associated with the Sogou software in 2019, citing a 2015 </span><a href="https://web.cse.ohio-state.edu/~lin.3021/file/SEC15.pdf" rel="nofollow ugc noopener">report</a><span> describing similar vulnerabilities. A particular concern she shared was that users of Sogou may decide to install Signal App to communicate, believing the app's safety profile to be broadly appropriate for many people. However, the eavesdropping and network fingerprinting risks associated with the use of a third party keyboard such as Sogou take precedence over Signal's security profile.</span></p><p>This means Signal App cannot stop an input method such as Sogou from recording keystrokes and sending them back to its developer, as explicitly warned by Citizen Lab.</p><p>💡</p><p>China's National Security Law, established in 2020, empowers the government to access surveillance data from Chinese tech companies without the need for a judicial process. This grants authorities the ability to obtain private information whenever deemed necessary.</p><p>It is possible that Wu's tweets about the issues in the Sogou software of which she was aware may have caught the attention of Chinese authorities who were searching for related information on Western networks.</p><p>Wu's theory that her tweets about these vulnerabilities could have led to her temporary detention and coercion now seems entirely plausible.</p><blockquote><p>After 8 years of daily tweeting one of the loudest, most candid voices coming out of China has been deplatformed- absolutely no one gives a shit. I could be dead in a ditch- but we aren’t actually people, we’re just signs for people like you in the West to wave at each other in their ideological war. &nbsp; –Naomi Wu</p></blockquote><p data-attrs="{&quot;url&quot;:&quot;/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe Now&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.hackingbutlegal.com/subscribe?" rel="nofollow ugc noopener"><span>Subscribe Now</span></a></p><p><em><strong>Thank you for reading.</strong></em><span> Subscribe here 👆</span></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MLIR For Beginners: A series of articles on the MLIR framework (111 pts)]]></title>
            <link>https://github.com/j2kun/mlir-tutorial</link>
            <guid>37154395</guid>
            <pubDate>Wed, 16 Aug 2023 21:53:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/j2kun/mlir-tutorial">https://github.com/j2kun/mlir-tutorial</a>, See on <a href="https://news.ycombinator.com/item?id=37154395">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
          <p>      A tag already exists with the provided branch name. Many Git commands accept both tag and branch names, so creating this branch may cause unexpected behavior. Are you sure you want to create this branch?
</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ubicloud – open, free and portable cloud (193 pts)]]></title>
            <link>https://github.com/ubicloud/ubicloud</link>
            <guid>37154138</guid>
            <pubDate>Wed, 16 Aug 2023 21:31:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ubicloud/ubicloud">https://github.com/ubicloud/ubicloud</a>, See on <a href="https://news.ycombinator.com/item?id=37154138">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/2545443/260930576-45d2b775-dacf-45e8-93c4-ba16d312396a.png"><img src="https://user-images.githubusercontent.com/2545443/260930576-45d2b775-dacf-45e8-93c4-ba16d312396a.png"></a>
</p>
<hr>
<h2 tabindex="-1" dir="auto">Ubicloud <a href="https://github.com/ubicloud/ubicloud/actions/workflows/ci.yml"><img src="https://github.com/ubicloud/ubicloud/actions/workflows/ci.yml/badge.svg" alt="CI"></a> <a href="https://github.com/ubicloud/ubicloud/actions/workflows/build.yml"><img src="https://github.com/ubicloud/ubicloud/actions/workflows/build.yml/badge.svg" alt="Build"></a></h2>
<p dir="auto">Ubicloud is an open, free, and portable cloud. Think of it as an open alternative to
cloud providers, like what Linux is to proprietary operating systems.</p>
<p dir="auto">Ubicloud provides IaaS cloud features on bare metal providers, such as Hetzner, OVH,
and AWS Bare Metal. You can set it up yourself on these providers or you can use our
managed service. We're currently in public alpha.</p>
<h2 tabindex="-1" dir="auto">Quick start</h2>
<h3 tabindex="-1" dir="auto">Managed platform</h3>
<p dir="auto">You can use Ubicloud without installing anything. When you do this, we pass along the
underlying provider's benefits to you, such as price or location.</p>
<p dir="auto"><a href="https://console.ubicloud.com/" rel="nofollow">https://console.ubicloud.com</a></p>
<h3 tabindex="-1" dir="auto">Build your own cloud</h3>
<p dir="auto">You can also build your own cloud. To do this, start up Ubicloud's control plane and
connect to its cloud console.</p>
<div data-snippet-clipboard-copy-content="git clone git@github.com:ubicloud/ubicloud.git

# Generate secrets for demo
./demo/generate_env

# Run containers: db-migrator, app (web &amp; respirate), postgresql
docker-compose -f demo/docker-compose.yml up

# Visit localhost:3000"><pre><code>git clone git@github.com:ubicloud/ubicloud.git

# Generate secrets for demo
./demo/generate_env

# Run containers: db-migrator, app (web &amp; respirate), postgresql
docker-compose -f demo/docker-compose.yml up

# Visit localhost:3000
</code></pre></div>
<p dir="auto">The control plane is responsible for cloudifying bare metal Linux machines.
The easiest way to build your own cloud is to lease instances from one of those
providers. For example: <a href="https://www.hetzner.com/sb" rel="nofollow">https://www.hetzner.com/sb</a></p>
<p dir="auto">Once you lease instance(s), run the following script for each instance to cloudify
the instance. By default, the script cloudifies bare metal instances leased from
Hetzner. After you cloudify your instances, you can provision and manage cloud
resources on these machines.</p>
<div data-snippet-clipboard-copy-content="# Enter hostname/IP and provider, and install SSH key as instructed by script
docker exec -it ubicloud-app ./demo/cloudify_server"><pre><code># Enter hostname/IP and provider, and install SSH key as instructed by script
docker exec -it ubicloud-app ./demo/cloudify_server
</code></pre></div>
<p dir="auto">Later when you create VMs, Ubicloud will assign them IPv6 addresses. If your ISP
doesn't support IPv6, please use a VPN or tunnel broker such Mullvad or Hurricane
Electric's <a href="https://tunnelbroker.net/" rel="nofollow">https://tunnelbroker.net/</a> to connect. Alternatively, you could lease
IPv4 addresses from your provider and add them to your control plane.</p>
<h2 tabindex="-1" dir="auto">Why use it</h2>
<p dir="auto">Public cloud providers like AWS, Azure, and Google Cloud made life easier for
start-ups and enterprises. But they are closed source, have you rent computers
at a huge premium, and lock you in. Ubicloud offers an open alternative, reduces
your costs, and returns control of your infrastructure back to you. All without
sacrificing the cloud's convenience.</p>
<p dir="auto">Today, AWS offers about two hundred cloud services. Ultimately, we will implement
10% of the cloud services that make up 80% of that consumption.</p>
<p dir="auto">Example workloads and reasons to use Ubicloud today include:</p>
<ul dir="auto">
<li>
<p dir="auto">You have an ephemeral workload like a CI/CD pipeline (we're integrating with
GitHub Actions), or you'd like to run compute/memory heavy tests. Our managed
cloud is ~3x cheaper than AWS, so you save on costs.</p>
</li>
<li>
<p dir="auto">You want a portable and simple app deployment service like
<a href="https://github.com/mrsked/mrsk">MRSK</a>. We're moving Ubicloud's control plane
from Heroku to MRSK; and we want to provide open and portable services for
MRSK's dependencies in the process.</p>
</li>
<li>
<p dir="auto">You have bare metal machines sitting somewhere. You'd like to build your own
cloud for portability, security, or compliance reasons.</p>
</li>
</ul>
<h2 tabindex="-1" dir="auto">Status</h2>
<p dir="auto">Ubicloud is in public alpha. You can provide us your feedback, get help, or ask
us to support your network environment in the
<a href="https://github.com/ubicloud/ubicloud/discussions">Community Forum</a>.</p>
<p dir="auto">We follow an established architectural pattern in building public cloud services.
A control plane manages a data plane, where the data plane leverages open source
software.  You can find our current cloud components / services below.</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Elastic Compute</strong>: Our control plane communicates with Linux bare metal servers
using SSH. We use <a href="https://github.com/cloud-hypervisor/cloud-hypervisor">Cloud
Hypervisor</a> as our virtual
machine monitor (VMM); and each instance of the VMM is contained within Linux
namespaces for further isolation / security.</p>
</li>
<li>
<p dir="auto"><strong>Virtual Networking</strong>: We use <a href="https://en.wikipedia.org/wiki/IPsec" rel="nofollow">IPsec</a>
tunneling to establish an encrypted and private network environment. We support IPv4
and IPv6 in a dual-stack setup and provide both public and private networking. For
security, each customer’s VMs operate in their own networking namespace. Everything
in virtual networking is layer 3 and up.</p>
</li>
<li>
<p dir="auto"><strong>Block Storage, non replicated</strong>: We use Storage Performance Development Toolkit
(<a href="https://spdk.io/" rel="nofollow">SPDK</a>) to provide virtualized block storage to VMs. SPDK enables
us to add enterprise features such as snapshot and replication in the future. We
follow security best practices and encrypt the data encryption key itself.</p>
</li>
<li>
<p dir="auto"><strong>Attribute-Based Access Control (ABAC)</strong>: With ABAC, you can define attributes,
roles, and permissions for users and give them fine-grained access to resources. You
can read more about our <a href="https://github.com/ubicloud/ubicloud/blob/main/doc/authorization.md">ABAC design here</a>.</p>
</li>
<li>
<p dir="auto"><strong>What's Next?</strong>: We're planning to work on the elastic load balancer or simple
storage service next. If you have a workload that would benefit from a specific cloud
service, please get in touch with us through our <a href="https://github.com/ubicloud/ubicloud/discussions">Community
Forum</a>.</p>
</li>
<li>
<p dir="auto">Control plane: Manages data plane services and resources. This is a Ruby program
that stores its data in Postgres. We use the <a href="https://roda.jeremyevans.net/" rel="nofollow">Roda</a>
framework to serve HTTP requests and <a href="http://sequel.jeremyevans.net/" rel="nofollow">Sequel</a> to
access the database. We manage web authentication with
<a href="http://rodauth.jeremyevans.net/" rel="nofollow">RodAuth</a>. We communicate with data plane servers
using SSH, via the library <a href="https://github.com/net-ssh/net-ssh">net-ssh</a>. For our
tests, we use <a href="https://rspec.info/" rel="nofollow">RSpec</a>.</p>
</li>
<li>
<p dir="auto">Cloud console: Server-side web app served by the Roda framework. For the visual
design, we use <a href="https://tailwindcss.com/" rel="nofollow">Tailwind CSS</a> with components from
<a href="https://tailwindui.com/" rel="nofollow">Tailwind UI</a>. We also use jQuery for interactivity.</p>
</li>
</ul>
<p dir="auto">If you’d like to start hacking with Ubicloud, any method of obtaining Ruby and Postgres
versions is acceptable. If you have no opinion on this, our development team uses <code>asdf-vm</code>
as <a href="https://github.com/ubicloud/ubicloud/blob/main/DEVELOPERS.md">documented here in detail</a>.</p>
<h2 tabindex="-1" dir="auto">FAQ</h2>
<h3 tabindex="-1" dir="auto">Do you have any experience with building this sort of thing?</h3>
<p dir="auto">Our founding team comes from Azure; and worked at Amazon and Heroku before that.
We also have start-up experience. We were co-founders and founding team members
at <a href="https://github.com/citusdata/citus">Citus Data</a>, <a href="https://news.ycombinator.com/item?id=18990469" rel="nofollow">which got acquired by
Microsoft</a>.</p>
<h3 tabindex="-1" dir="auto">How is this different than OpenStack?</h3>
<p dir="auto">We see three differences. First, Ubicloud is available as a managed service (vs boxed
software). This way, you can get started in minutes rather than weeks. Since Ubicloud
is designed for multi-tenancy, it comes with built-in with features such as encryption
at rest and in transit, virtual networking, secrets rotation, etc.</p>
<p dir="auto">Second, we're initially targeting developers. This -we hope- will give us fast feedback
cycles and enable us to have 6 key services in GA form in the next two years. OpenStack
is still primarily used for 3 cloud services.</p>
<p dir="auto">Last, we're designing for simplicity. With OpenStack, you pick between 10 hypervisors,
10 S3 implementations, and 5 block storage implementations. The software needs to work
in a way where all of these implementations are compatible with each other. That leads
to consultant-ware. We'll take a more opinionated approach with Ubicloud.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[$HOME, not so sweet $HOME (205 pts)]]></title>
            <link>https://gist.github.com/sharadhr/39b804236c1941e9c30d90af828ad41e</link>
            <guid>37153862</guid>
            <pubDate>Wed, 16 Aug 2023 21:08:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gist.github.com/sharadhr/39b804236c1941e9c30d90af828ad41e">https://gist.github.com/sharadhr/39b804236c1941e9c30d90af828ad41e</a>, See on <a href="https://news.ycombinator.com/item?id=37153862">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto">
<h2 dir="auto">Preface</h2>
<details>
<summary>Preface</summary>
<p dir="auto">This was supposed to be a blog post, but I have neither the knowledge, nor the time, nor the energy to set up a nice statically-generated blog like everyone else does on <a href="https://news.ycombinator.com/" rel="nofollow">Hacker News</a> or <a href="https://www.reddit.com/r/programming" rel="nofollow">proggit</a>.
Of course, I <em>want</em> one, but I also want to use a fully .NET Core-based static site generator, and therefore have experimented with <a href="https://www.statiq.dev/web" rel="nofollow">Statiq.Dev Web</a>.
However, it turns out that I still need to pick up non-trivial HTML and CSS to make it look like anything but a website from the 1990s.</p>
<p dir="auto">For now, though, GitHub-flavoured Markdown handles almost all use-cases I can think of (embedded images, this spoiler you've opened, complicated lists, in-line HTML for <kbd>Ctrl</kbd>, in-line <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="199d30469088046bb8786592166a214d">$\LaTeX{}$</math-renderer> for <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="199d30469088046bb8786592166a214d">$\text{maths} \equiv \text{fun}$</math-renderer>...), and GitHub Gists renders Markdown as formatted text anyway, so what else do I need?
I can even pin these gists to my GitHub profile, which is also very nice.
If I ever <em>do</em> prepare a blog, it should be fairly straightforward to migrate these posts to it: they're just Markdown, after all.
The only thing (so far) I've noticed that is missing is auto-numbered headings, although that's apparently a matter of CSS styling.</p>
<hr>
<p dir="auto">I've been meaning to write this for a <em>very</em> long time—more or less since I ever started using Linux properly four years ago, discovered <a href="https://man7.org/linux/man-pages/man1/ls.1.html#:~:text=entries%20starting%20with%20.-,%2DA%2C%20%2D%2Dalmost%2Dall,-do%20not%20list" rel="nofollow"><code>ls -A</code></a>, and realised what a clutter <code>~</code> was.
At the same time I noticed that the situation on my Windows install was even <em>worse</em>.
What <em>really</em> inspired me to get started was <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ReportConfigFileLocations" rel="nofollow"><em>Everything that uses configuration files should report where they're located</em></a>.
I resonate strongly with the author's sentiment, and more importantly, dislike 'opinionated' software that likes to do what its author thinks is best instead of following system conventions.</p>
</details>
<h2 dir="auto">1 What is <code>$HOME</code> to you?</h2>
<p dir="auto">Home.
It is where you're supposed to be most comfortable in.
It is your place of refuge, and a sanctum from the mess and chaos of the outside world.
It is where you have complete liberty over <em>everything</em>: what you do, when you do things, how you do them, what things you have.
It is where these things are supposed to be where <em>you</em> want them, and <em>how</em> you want them to be.</p>
<p dir="auto">You buy things to decorate, maintain, and improve your home: paintings, photographs, vases, light fixtures, sofas, chairs, ovens, vacuum cleaners.
You have your own volition to put these wherever you want, and set them up however you want.
Your vacuum cleaner in a wardrobe? Sure.
Or in the washroom, or in the service balcony, or the backyard. You can put its dust bag anywhere you want, too.</p>
<p dir="auto">What if there existed a vacuum cleaner that stopped working if you plugged it into a different socket to the one the manufacturer set out in the manual?
What if it stopped working if you changed where you put its dust bag, or swapped it out for a <em>new</em> dust bag?
Would you buy this vacuum cleaner?
Suppose that this vacuum cleaner was given to you for free, anyway.
Would you still use it, but live with the compromise that your home is not <em>exactly</em> how you want it?</p>
<p dir="auto">If you answer 'maybe', or even 'yes', then welcome to the world of software, where your home is violated on a regular basis.
Software that spews configuration files, temporary and cache files, generated and save files, catalogue files, downloaded files <em>everywhere</em>.
There is little rhyme or reason to any of it: many applications never tell the user they are putting these files <strong>HERE</strong> or <strong>THERE</strong>, and if the user wants to move them around, they aren't given a choice in the matter.
Applications regularly disregard platform conventions (many ironies abound, to be detailed below); even if these conventions are clearly documented, some go <em>out of their way</em> to do their own thing.
Some applications pretend that everything is immaculate, by <em>hiding</em> their mess (and they typically don't do a great job of it: look at many Linux-first program ported to Windows).</p>
<p dir="auto">It would irritate <em>anyone</em>.
I am <em>particularly</em> compulsive about software doing what I'd like it to do, and about following platform conventions.
Conventions, standards, and protocols exist so everyone is on the same page, and there is a common 'language' for software to communicate with.
When software authors break them just for the sake of 'opinionation', or because they <em>feel like it</em> (a worse justification, in my opinion), it only leads to much exasperation on the users' end, because it comes as a surprise to them, and software should <em>not</em> be surprising.
It ought to be reliable, reproducible, and follow expectations.</p>
<p dir="auto">This post is a detailed discussion into user profiles, their directories, and how they are—to put it bluntly—in total disarray on Windows and Linux (I haven't used a Mac in ages, but I assume the situation is very similar there, too).
Applications treat the user profile as a dumping ground, and any user with a reasonably wide list of installed software will find their user profile very difficult to traverse after some time in use.
There are platform conventions and attempts to standardise things on more open-source platforms, but a lot of developers resolutely refuse to change the behaviour of their software for a variety of reasons (some less valid than others).</p>
<p dir="auto">The first part is a deep dive into user profiles on Linux and Windows, and the conventions that have been established on these platforms over the years.
The second section details <em>how</em> they are broken on each platform, and <em>why</em> they are broken.</p>
<p dir="auto">This is a bit of a soapbox, but I hope developers read this, and at least <em>attempt</em> to fix their software so that home directories are cleaner, and users have easier lives maintaining and using their computers.</p>
<p dir="auto"><em><strong>If you want to skip all the setup drudgery, go to <a href="#3conventions-and-why-theyre-broken">§3</a></strong></em>.</p>
<h2 dir="auto">2 Setup</h2>
<p dir="auto">Before I begin, there are some platform-specific details and setup to be discussed, as well as phrasing <em>conventions</em>.
I will use the terms 'home directory' and 'user profile directory' somewhat interchangeably in this post, whereas 'user profile' means the home directory itself and its contents—including user-specific configuration and data—<em>combined</em>.</p>
<h3 dir="auto">2.1 Linux</h3>
<p dir="auto">Linux is famously fragmented, but even so, there exist <em>some</em> conventions for user profiles, especially for desktop environments.
As far as I've seen, Linux user profiles are typically created in <code>/home/&lt;username&gt;</code>.
The directory path may be chosen during the out-of-box experience (OOBE)/first-time setup of a Linux distro or entirely manually, with <a href="https://man7.org/linux/man-pages/man8/useradd.8.html#:~:text=%2Dd%2C%20%2D%2Dhome%2Ddir%20HOME_DIR" rel="nofollow"><code>useradd -d</code></a>, which writes to <code>/etc/passwd</code>.
Sometimes, <code>/home</code> might occupy an altogether separate partition/sub-volume (if the user is using Btrfs, for instance).</p>
<h4 dir="auto">2.1.1 <code>$HOME</code></h4>
<p dir="auto">Regardless of its location, the environment variable <code>$HOME</code> is set by a login process or graphical display manager (e.g. <a href="https://man7.org/linux/man-pages/man1/login.1.html" rel="nofollow"><code>login</code></a>, <code>gdm</code>, <code>sddm</code>, etc.) upon login, based on values previously set in <code>/etc/passwd</code>.
This file is plaintext, but it may also be read using the Linux API:</p>
<div dir="auto"><pre>#<span>include</span> <span><span>&lt;</span>cstdio<span>&gt;</span></span>
#<span>include</span> <span><span>&lt;</span>pwd.h<span>&gt;</span></span>
#<span>include</span> <span><span>&lt;</span>sys/types.h<span>&gt;</span></span>
#<span>include</span> <span><span>&lt;</span>unistd.h<span>&gt;</span></span>

<span>auto</span> <span>main</span>() -&gt; int
{
    <span>auto</span> <span>const</span> pw = <span>getpwuid</span>(<span>getuid</span>());
    <span>if</span> (pw != <span>nullptr</span>) {
        <span>std::printf</span>(<span><span>"</span>User name: %s<span>\n</span><span>"</span></span>, pw-&gt;<span>pw_name</span>);
        <span>std::printf</span>(<span><span>"</span>User ID: %d<span>\n</span><span>"</span></span>, pw-&gt;<span>pw_uid</span>);
        <span>std::printf</span>(<span><span>"</span>Group ID: %d<span>\n</span><span>"</span></span>, pw-&gt;<span>pw_gid</span>);
        <span>std::printf</span>(<span><span>"</span>Home directory: %s<span>\n</span><span>"</span></span>, pw-&gt;<span>pw_dir</span>);
        <span>std::printf</span>(<span><span>"</span>Login shell: %s<span>\n</span><span>"</span></span>, pw-&gt;<span>pw_shell</span>);

        <span>return</span> <span>0</span>;
    } <span>else</span> {
        <span>return</span> <span>1</span>;
    }
}</pre></div>
<p dir="auto">Strictly speaking, though, there is no real concept of a home directory <em>per se</em> on Linux/UNIX (hereafter referred to as *nix), and they aren't treated any differently by the OS (unlike Windows, as seen below).
The <code>pw_dir</code> member variable is just the initial working directory of the login shell and any subsequent shells started by the corresponding user; it could technically point to <em>any</em> directory that has read permissions for said user.
The <code>pwd.h</code> manual <a href="https://man7.org/linux/man-pages/man0/pwd.h.0p.html#:~:text=char%20%20%20%20*pw_dir%20%20%20%20Initial%20working%20directory" rel="nofollow">states as much</a>.</p>
<p dir="auto">Most shells and desktop environments parse <code>~</code> as an alias to <code>$HOME</code>; running <code>cd</code> without any command-line arguments also <a href="https://man7.org/linux/man-pages/man1/cd.1p.html#:~:text=2.%20If%20no%20directory%20operand%20is%20given%20and%20the%20HOME%20environment%0A%20%20%20%20%20%20%20%20%20%20%20variable%20is%20set%20to%20a%20non%2Dempty%20value%2C%20the%20cd%20utility%20shall%0A%20%20%20%20%20%20%20%20%20%20%20behave%20as%20if%20the%20directory%20named%20in%20the%20HOME%20environment%0A%20%20%20%20%20%20%20%20%20%20%20variable%20was%20specified%20as%20the%20directory%20operand." rel="nofollow">navigates to <code>$HOME</code></a>.</p>
<h4 dir="auto">2.1.2 Dot-files and dot-directories</h4>
<p dir="auto">On *nix, prefixing a file or directory with a full-stop (<code>.</code>) excludes said path from being listed in userland utilities, such as <code>ls</code> or graphical file managers by default.
These files are considered 'hidden', although no special meaning is given to them by the filesystem itself (unlike on Windows).
This is <em>convention</em> dating to the <a href="https://web.archive.org/web/20190211031031/https://plus.google.com/+RobPikeTheHuman/posts/R58WgWwN9jp" rel="nofollow">earliest days of UNIX</a>.</p>
<p dir="auto">Most Linux users' home directories will contain a collection of these <em>dot-files</em> and <em>dot-directories</em>, and they are typically used to set user-specific configuration for almost all programs on *nix.
They typically reside in the top level of <code>$HOME</code>; for instance, the Vim configuration is in <code>$HOME/.vimrc</code>.
If you <em>do</em> want to list hidden files with <code>ls</code>, use <code>ls -a</code> or <code>ls -A</code>.</p>
<h4 dir="auto">2.1.3 XDG Base Directories</h4>
<details>
<summary>XDG</summary>
<p dir="auto"><a href="https://www.freedesktop.org/wiki/#:~:text=an%20acronym%20for%20the%20Cross%2DDesktop%20Group" rel="nofollow">XDG stands for 'Cross-Desktop Group'</a>.</p>
</details>
<p dir="auto">The <a href="https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html" rel="nofollow">XDG Base Directory specification</a> defines several environment variables expanding to subdirectories of <code>$HOME</code> in an attempt to standardise dot-files and dot-directories.
I summarise them below:</p>
<table>
<thead>
<tr>
<th><strong>Variable</strong></th>
<th><strong>Default value</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><code>$XDG_DATA_HOME</code></td>
<td><code>$HOME/.local/share</code></td>
<td>User-specific data files; e.g. program databases, caches that persist through multiple program runs, search indices, 'Trash' directory for desktop environments.</td>
</tr>
<tr>
<td><code>$XDG_CONFIG_HOME</code></td>
<td><code>$HOME/.config</code></td>
<td>User-specific configuration files, including <code>.*rc</code> and <code>.*env</code> files; VS Code <code>settings.json</code>.</td>
</tr>
<tr>
<td><code>$XDG_STATE_HOME</code></td>
<td><code>$HOME/.local/state</code></td>
<td>User-specific state files, such as terminal history files.</td>
</tr>
<tr>
<td><code>$XDG_CACHE_HOME</code></td>
<td><code>$HOME/.cache</code></td>
<td>Caches limited to single runs of a program, but can extend to persistent caches, e.g. user-installed package manager caches for <code>pip</code>, <code>pacman</code> AUR wrappers, <code>vcpkg</code>, etc.</td>
</tr>
</tbody>
</table>
<p dir="auto">Notice the specification provides for the scenario that these environment variables are <em>not</em> defined:</p>
<blockquote>
<p dir="auto">If <code>$XDG_CONFIG_HOME</code> is either not set or empty, a default equal to <code>$HOME/.config</code> should be used.</p>
</blockquote>
<h4 dir="auto">2.1.4 <code>xdg-user-dirs</code></h4>
<p dir="auto">Since Linux does not provide an 'official' userland environment (unlike Windows), the XDG people have again made effort to set up 'Windows-style' user directories <em>with localisation</em>, called <a href="https://www.freedesktop.org/wiki/Software/xdg-user-dirs/" rel="nofollow"><code>xdg-user-dirs</code></a>.
Both GNOME and KDE Plasma Desktop require it.
This tool is configured with a straightforward script in <code>$(XDG_CONFIG_HOME)/user-dirs.dirs</code>.
The default directories generated on an English-language install are:</p>
<ul dir="auto">
<li>Desktop</li>
<li>Documents</li>
<li>Downloads</li>
<li>Music</li>
<li>Pictures</li>
<li>Public</li>
<li>Templates</li>
<li>Videos</li>
</ul>
<p dir="auto">As always, the <a href="https://wiki.archlinux.org/title/XDG_user_directories" rel="nofollow">relevant article at the Arch wiki</a> is very useful.</p>
<h4 dir="auto">2.1.5 <code>systemd-homed</code></h4>
<p dir="auto"><a href="https://www.freedesktop.org/software/systemd/man/systemd-homed.service.html" rel="nofollow"><code>systemd-homed</code></a> allows Linux administrators to create and manage user profiles, and optionally encrypt them.
It also has roughly equivalent functionality to Active Directory and roaming user profiles on Windows, where user profiles may be encrypted and stored remotely on some server, for retrieval by terminals upon login.</p>
<h3 dir="auto">2.2 Windows</h3>
<details>
<summary>Windows and Microsoft commentary</summary>
<p dir="auto">I hold several very controversial opinions about Microsoft and Windows that would at best, raise many hackers' eyebrows, and at worst, get me called an astroturfer or Microsoft shill.
These are best left to a separate blog post.</p>
</details>
<p dir="auto">User profiles on Windows are a rather complex matter, which is not necessarily unwelcome.
Most of it is configurable, fairly well-documented, and there is more than one way to do things, although some are clearly better than others.</p>
<h4 dir="auto">2.2.1 Environment variables</h4>
<p dir="auto">Modern Windows (i.e. Vista and later) also has environment variables for important directories, including those within the user profile directory.
Many are listed <a href="https://ss64.com/nt/syntax-variables.html" rel="nofollow">here</a> (Microsoft's <a href="https://learn.microsoft.com/en-sg/windows/deployment/usmt/usmt-recognized-environment-variables" rel="nofollow">official documentation</a> is a little less forthcoming), and I reproduce a few in the table below.</p>
<table>
<thead>
<tr>
<th><strong>Variable</strong></th>
<th><strong>Value</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><code>%SYSTEMDRIVE%</code></td>
<td>Usually <code>C:</code></td>
<td><code>C:</code> is not necessarily always the Windows install drive.</td>
</tr>
<tr>
<td><code>%WINDIR%</code></td>
<td><code>%SYSTEMDRIVE%\Windows</code></td>
<td><code>Windows</code> is not necessarily the install directory for Windows itself. There are legacy directories like <code>WINNT</code>, <code>WINNT35</code>, <code>WTSRV</code>.</td>
</tr>
<tr>
<td><code>%SYSTEMROOT%</code></td>
<td><code>%WINDIR%</code></td>
<td></td>
</tr>
<tr>
<td><code>%PROGRAMFILES%</code></td>
<td><code>%SYSTEMDRIVE%\Program Files</code></td>
<td>Default system-wide installation location for programs. Requires administrator permission to modify.</td>
</tr>
<tr>
<td><code>%PROGRAMFILES(X86)%</code></td>
<td><code>%SYSTEMDRIVE%\Program Files (x86)</code></td>
<td>Only on 64-bit installs of Windows. 32-bit-only programs go here.</td>
</tr>
<tr>
<td><code>%PROGRAMDATA%</code></td>
<td><code>%SYSTEMDRIVE%\ProgramData</code></td>
<td>System-wide program configuration and storage; e.g. default configurations, logs, etc.</td>
</tr>
<tr>
<td><code>%USERNAME%</code></td>
<td>Set in the registry</td>
<td>Can be changed in Control Panel or Settings.</td>
</tr>
<tr>
<td><code>%USERPROFILE%</code></td>
<td>Usually <code>%SYSTEMDRIVE%\Users\%USERNAME%</code>; see discussion below</td>
<td></td>
</tr>
<tr>
<td><code>%APPDATA%</code></td>
<td><code>%USERPROFILE%\AppData\Roaming</code></td>
<td>User-specific <em>roaming</em> application data that may be exported between PCs; e.g. Google Chrome user profiles, Steam accounts; likely anything that requires an internet sign-in</td>
</tr>
<tr>
<td><code>%LOCALAPPDATA%</code></td>
<td><code>%USERPROFILE%\AppData\Local</code></td>
<td>User-specific, PC-specific application data; sometimes includes the entire applications themselves if installed only for the user. e.g. Google Chrome and MiKTeX installed by a non-admin user.</td>
</tr>
</tbody>
</table>
<p dir="auto">These environment variables may be accessed from C or C++ with <a href="https://learn.microsoft.com/en-sg/cpp/c-runtime-library/reference/getenv-wgetenv?view=msvc-170" rel="nofollow"><code>getenv()</code></a>, or any other language-specific API.</p>
<h4 dir="auto">2.2.2 User profile creation and naming</h4>
<p dir="auto">This is a mess on Windows. Until Windows 8, user profile creation was straightforward, and only local accounts could be created (not including Active Directory roaming profiles).
Since then, however, OneDrive (previously SkyDrive) and Microsoft account integration has thoroughly road-rolled over this simplicity.
Today, creating a local, non-connected user profile in the OOBE in Windows 11 is <a href="https://www.windowscentral.com/how-set-windows-11-without-microsoft-account#:~:text=Use%20the%20%22Shift%20%2B%20F10%22%20keyboard%20shortcut%20to%20open%20Command%20Prompt" rel="nofollow">a particularly convoluted process</a>, and may require Windows 11 Pro, which is usually not shipped with consumer devices.</p>
<p dir="auto">This digression is to discuss what home directory name users end up with: on a profile connected to a Microsoft account, the user home directory has a name that is the first five characters, in lowercase, of the email address or name provided.
For instance, in the first case, I would have <code>%SYSTEMDRIVE%\Users\shara</code>, but on a 'local account', it would be <code>%SYSTEMDRIVE%\Users\Sharadh</code> (mine is <em>actually</em> the latter—I am obsessive about this, so I created a local account first, and <em>then</em> synced it to OneDrive).
Like many things Windows, configuring the user profile directory after account creation requires <a href="https://learn.microsoft.com/en-sg/troubleshoot/windows-client/user-profiles-and-logon/renaming-user-account-not-change-profile-path" rel="nofollow">editing registry keys</a> using <em>another</em> administrator account.</p>
<h4 dir="auto">2.2.3 Libraries and <code>KNOWNFOLDERID</code>s</h4>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/41949b9fe9b45341b20f8332711288deff5c67fe3d9115286a055d904a618d1f/68747470733a2f2f66696c65732e636174626f782e6d6f652f6768337532342e706e67"><img width="300" src="https://camo.githubusercontent.com/41949b9fe9b45341b20f8332711288deff5c67fe3d9115286a055d904a618d1f/68747470733a2f2f66696c65732e636174626f782e6d6f652f6768337532342e706e67" data-canonical-src="https://files.catbox.moe/gh3u24.png"></a></p><p dir="auto">Upon user profile creation, Windows automatically sets up several directories, which are also <a href="https://learn.microsoft.com/en-sg/windows/win32/shell/library-ovw" rel="nofollow"><em>libraries</em></a>, inside the home directory:</p>
<ul dir="auto">
<li>3D Objects</li>
<li>Contacts</li>
<li>Desktop</li>
<li>Documents</li>
<li>Downloads</li>
<li>Music</li>
<li>Saved Games</li>
<li>Videos</li>
</ul>
<p dir="auto">These libraries are initially created under <code>%USERPROFILE%</code>, but may be moved (right click → <code>Properties</code> → <code>Location</code> tab → <code>Move...</code>) by the user at their own discretion.
The Windows API provides enumerated GUIDs called <a href="https://learn.microsoft.com/en-sg/windows/win32/shell/knownfolderid" rel="nofollow"><code>KNOWNFOLDERID</code></a>s that map to these directories, as well as <em>most</em> of the system directories listed in <a href="#221environment-variables">Environment variables</a>.
These may be queried with <a href="https://learn.microsoft.com/en-sg/windows/win32/api/shlobj_core/nf-shlobj_core-shgetknownfolderpath" rel="nofollow"><code>SHGetKnownFolderPath</code></a>, like so:</p>
<div dir="auto"><pre>#<span>include</span> <span><span>&lt;</span>cstdio<span>&gt;</span></span>
#<span>include</span> <span><span>&lt;</span>ShlObj.h<span>&gt;</span></span> <span><span>//</span> SHGetKnownFolderPath</span>

#<span>pragma</span> comment(lib, "shell32.lib") <span><span>//</span> link shell32.lib</span>

<span>auto</span> <span>main</span>() -&gt; int
{
    <span>auto</span> path = PWSTR{};

    <span><span>//</span> get desktop path; return type HRESULT</span>
    <span>if</span> (<span>auto</span> <span>const</span> result = <span>SHGetKnownFolderPath</span>(FOLDERID_Desktop, KF_FLAG_DEFAULT, <span>nullptr</span>, &amp;path);
        <span>FAILED</span>(result)) {
        <span>return</span> <span>1</span>;
    }
    <span>std::wprintf_s</span>(<span><span>L"</span>%ls<span>\n</span><span>"</span></span>, path);
    <span>return</span> <span>0</span>;
}</pre></div>
<p dir="auto">In .NET, the <a href="https://learn.microsoft.com/en-sg/dotnet/api/system.environment.getfolderpath?view=net-7.0" rel="nofollow"><code>Environment.GetFolderPath</code></a> method, together with the <a href="https://learn.microsoft.com/en-sg/dotnet/api/system.environment.specialfolder?view=net-7.0" rel="nofollow"><code>Environment.SpecialFolder</code></a> enum returns the same value, although this is missing the Vista changes detailed below, because these constants are <a href="https://source.dot.net/#System.Private.CoreLib/src/libraries/System.Private.CoreLib/src/System/Environment.SpecialFolder.cs,63" rel="nofollow">set to the <code>CSIDL</code> values</a> instead of the <code>KNOWNFOLDERID</code>s.
<a href="https://github.com/dotnet/runtime/issues/70484" data-hovercard-type="issue" data-hovercard-url="/dotnet/runtime/issues/70484/hovercard">There is a proposal to add these to .NET 8</a>.</p>
<div dir="auto"><pre><span>&gt;</span> [<span>System.Environment</span>]::GetFolderPath([<span>System.Environment</span><span>+</span><span>SpecialFolder</span>]::Desktop)
D:\Libraries\Desktop</pre></div>
<p dir="auto">I have set all my libraries to point to <code>D:\Libraries\&lt;library&gt;</code>, because my <code>C:</code> drive is rather small and dedicated to the OS and important programs only, whereas <code>D:</code> is significantly larger.
So, the graphical setting for the various libraries update the locations returned by the native Windows API too.
Hereafter, I will use the <a href="https://ss64.com/nt/shell.html" rel="nofollow">Windows shell shortcuts</a> to describe library locations.</p>
<h5 dir="auto">2.2.3.1 Hidden folders on Windows</h5>
<p dir="auto">In particular, the parent directory of <code>shell:AppData</code> and <code>shell:Local AppData</code>—<code>%USERPROFILE%\AppData</code>—is a <em>hidden</em> directory.
Unlike *nix, 'hidden' on Windows has special semantics accorded by the filesystem (usually NTFS).
This can be set either graphically (right-click → <code>Properties</code> → <code>General</code> tab → <code>Hidden</code> checkbox under <code>Attributes</code>), or retrieved/set programmatically in the Windows API, using <a href="https://learn.microsoft.com/en-sg/windows/win32/api/fileapi/nf-fileapi-getfileattributesw" rel="nofollow"><code>GetFileAttributes</code></a> and <a href="https://learn.microsoft.com/en-sg/windows/win32/api/fileapi/nf-fileapi-getfileattributesw" rel="nofollow"><code>SetFileAttributes</code></a>.
These functions return or accept a bitwise-ORed <a href="https://learn.microsoft.com/en-sg/windows/win32/fileio/file-attribute-constants" rel="nofollow">file attribute constant</a>, as demonstrated below:</p>
<div dir="auto"><pre>#<span>include</span> <span><span>&lt;</span>cstdio<span>&gt;</span></span>
#<span>include</span> <span><span>&lt;</span>pathcch.h<span>&gt;</span></span>
#<span>include</span> <span><span>&lt;</span>ShlObj.h<span>&gt;</span></span>

#<span>pragma</span> comment(lib, "Pathcch.lib")
#<span>pragma</span> comment(lib, "Shell32.lib")

<span>auto</span> <span>main</span>() -&gt; int
{
    <span>auto</span> path = PWSTR{};

    <span>if</span> (<span>auto</span> <span>const</span> get_path_result = <span>SHGetKnownFolderPath</span>(FOLDERID_RoamingAppData, KF_FLAG_DEFAULT, <span>nullptr</span>, &amp;path);
        <span>FAILED</span>(get_path_result)) {
        <span>return</span> <span>1</span>;
    }

    <span>std::printf</span>(<span><span>"</span>SHGetKnownFolderPath succeeded, path is %ws<span>\n</span><span>"</span></span>, path);

    <span><span>//</span> get parent path of %APPDATA%, i.e. `%USERPROFILE%\AppData`</span>
    <span>if</span> (<span>auto</span> <span>const</span> remove_leaf_result = <span>PathCchRemoveFileSpec</span>(path, MAX_PATH);
        <span>FAILED</span>(remove_leaf_result)) {
        <span>return</span> <span>1</span>;
    }

    <span>if</span> (<span>auto</span> <span>const</span> attributes = <span>GetFileAttributesW</span>(path); attributes == INVALID_FILE_ATTRIBUTES) {
        <span>printf</span>(<span><span>"</span>GetFileAttributes failed with error code %d<span>\n</span><span>"</span></span>, <span>GetLastError</span>());
        <span>return</span> <span>1</span>;
    } <span>else</span> <span>if</span> (attributes &amp; FILE_ATTRIBUTE_HIDDEN) {
        <span>printf</span>(<span><span>"</span>%%APPDATA%%<span>\\</span>.. is hidden<span>\n</span><span>"</span></span>);
        <span>return</span> <span>0</span>;
    } <span>else</span> {
        <span>printf</span>(<span><span>"</span>%%APPDATA%%<span>\\</span>.. is not hidden; something is wrong<span>\n</span><span>"</span></span>);
        <span>return</span> <span>1</span>;
    }
}</pre></div>
<h4 dir="auto">2.2.4 Windows XP to Vista changes</h4>
<p dir="auto"><a href="https://archive.ph/eOGDp" rel="nofollow"><em>A Brief History of Windows Profiles</em></a> is a great article, but I want to focus on one important section.
Windows 2000 and XP used <code>%SYSTEMDRIVE%\Documents and Settings\&lt;username&gt;</code> for the home directory, which was moved to <code>%SYSTEMDRIVE%\Users\&lt;username&gt;</code> with Vista and later.
Windows Vista also introduced the above-mentioned <code>KNOWNFOLDERID</code>s, which superseded the older <a href="https://learn.microsoft.com/en-sg/windows/win32/shell/csidl" rel="nofollow"><code>CSIDL</code></a> enumeration (although the latter is still available, and used by the .NET API).</p>
<p dir="auto">Many environment variables like <code>%APPDATA%</code> were also redirected to the current locations (the previous was a mouthful: <code>%SYSTEMDRIVE%\Documents and Settings\&lt;username&gt;\Local Settings\Application Data</code>).
New known folders were added, such as <code>Downloads</code> and <code>Saved Games</code>; the <code>My⎵</code> prefix was removed from <code>My Documents</code> and <code>My Music</code>; locations such as <code>Start Menu</code> were moved (in this case, to <code>%APPDATA%\Microsoft\Windows\Start Menu</code>).</p>
<p dir="auto">The reason for this move is anyone's guess, but I feel the <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="199d30469088046bb8786592166a214d">$\geq$</math-renderer> Vista convention makes a lot more sense than the <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="199d30469088046bb8786592166a214d">$\leq$</math-renderer> Windows XP one.
There is an <a href="https://web.archive.org/web/20120621131135/http://technet.microsoft.com:80/en-sg/library/cc766489(v=ws.10).aspx" rel="nofollow">old guide</a> for sysadmins migrating from Windows XP to Vista, and there is another blog post for Windows application developers: <a href="https://learn.microsoft.com/en-sg/archive/blogs/patricka/where-should-i-store-my-data-and-configuration-files-if-i-target-multiple-os-versions#targeting-vista-and-higher" rel="nofollow"><em>Where Should I Store my Data and Configuration Files if I Target Multiple OS Versions?</em></a></p>
<p dir="auto">As an aside, there is <a href="https://news.ycombinator.com/item?id=29187896" rel="nofollow">an apocryphal tale</a> for the reason why programs are stored in <code>Program Files</code> and not <code>ProgramFiles</code> or <code>Program_Files</code>: apparently Microsoft wanted to force programmers to write code defensively, and handle spaces in paths without crashing, so they made the program install location itself have spaces in it (this then raises the question: why <code>ProgramData</code>?)
<a href="https://archive.ph/Eqvd4" rel="nofollow">Windows also has decent localisation</a> (at least amongst Indo-European languages employing the Latin script): set the system language to German, for instance, and <code>Program Files</code> is now <code>Programme</code>; it is <code>Programfiler</code> in Norwegian.</p>
<h4 dir="auto">2.2.5 <code>HKEY_CURRENT_USER</code> registry hive</h4>
<p dir="auto">On Windows, many user-specific configurations are stored in the <code>HKEY_CURRENT_USER</code> registry hive (abbreviated as <code>HKCU</code>), stored in <code>%USERPROFILE%\NTUSER.dat</code>.
This includes changes made in both Control Panel and Windows Settings, as well as settings for Microsoft programs like the Office suite.
This hive is synchronised across terminals on roaming user profiles (such as with Active Directory and domains).</p>
<h3 dir="auto">2.3 Linux and Windows equivalents</h3>
<p dir="auto">So far, I've discussed user profiles on Linux and Windows. There are some rough equivalents between the two, which ought to be useful for developers aiming to write <em>well-behaved</em> cross-platform applications:</p>
<table>
<thead>
<tr>
<th><strong>Use-case</strong></th>
<th><strong>Linux</strong></th>
<th><strong>Windows</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Program install directory</td>
<td><code>/bin</code></td>
<td>
<code>%PROGRAMFILES%</code> or <code>%PROGRAMFILES(X86)%</code>
</td>
</tr>
<tr>
<td>Headers</td>
<td><code>/usr/include</code></td>
<td>Shipped with the program, or available with Windows SDK</td>
</tr>
<tr>
<td>System/program libraries</td>
<td><code>/usr/lib</code></td>
<td>
<code>%WINDIR%\System32</code> or shipped with the program; Visual C++ and .NET redistributables pre-installed or installed on-demand</td>
</tr>
<tr>
<td>Default/system-wide program configuration</td>
<td><code>/etc</code></td>
<td><code>%PROGRAMDATA%</code></td>
</tr>
<tr>
<td>System-wide logs</td>
<td><code>/var/log</code></td>
<td><code>%PROGRAMDATA%</code></td>
</tr>
<tr>
<td>Per-user program configuration</td>
<td><code>$XDG_CONFIG_HOME</code></td>
<td>
<code>%APPDATA%</code> or <code>%LOCALAPPDATA%</code>
</td>
</tr>
<tr>
<td>Per-user program data</td>
<td><code>$XDG_DATA_HOME</code></td>
<td><code>%LOCALAPPDATA%</code></td>
</tr>
<tr>
<td>Per-user program cache</td>
<td><code>$XDG_CACHE_HOME</code></td>
<td><code>%APPDATA%</code></td>
</tr>
</tbody>
</table>
<h2 dir="auto">3 Conventions, and why they're broken</h2>
<h3 dir="auto">3.1 Respecting the user's choice and expectations</h3>
<p dir="auto">Okay; that was a pretty long introduction, but I haven't really gotten into <em>why</em> these user profile conventions have been established in the first place.
It seems like pointless bike-shedding—discussing where user data ought to be saved—but there are real issues which said conventions attempt to solve.</p>
<p dir="auto">These specifications don't exist merely to 'put things somewhere' for the hell of it. Disparate applications from a wide variety of developers and backgrounds which implement these specifications will have a only single place to write to (and read from), and a single point of backup, which reduces user workload.
As I mentioned in the introduction, software ought not to be surprising or unnecessarily opinionated.
Users see a specification, or some clearly-labelled pre-generated folder in their home directory, and <em>expect</em> software to write to adhere to these specifications, and write to a sensible location.</p>
<p dir="auto">GitHub user Lyle Hanson (<a href="https://github.com/lhanson">@lhanson</a>) puts it more clearly than I could, <a href="https://github.com/vim/vim/issues/2034#issuecomment-559254363" data-hovercard-type="issue" data-hovercard-url="/vim/vim/issues/2034/hovercard">in the issue for Vim</a>:</p>
<blockquote>
<p dir="auto">The benefit of respecting the specification isn't just to put it "somewhere else", it's to put it <em>where I (the user) want it, without having to repeat myself every time I install anything.</em></p>
<p dir="auto">... I may eventually get around to trying to back up and/or version control my configuration files without hauling around everything else on my drive and I'll be delighted that most of them seem to be in <code>~/.config</code>.
When I have to add exceptions and regex matches for every program which stores its files in what seem to me like a jumble of random locations, the fact that a given program has done it that way for 30 years doesn't make my job any easier or less frustrating than for a program that was written last week without knowing any better.</p>
<p dir="auto">... From a UX point of view, I'd rather express my preferences at most once and be able to leverage reasonable assumptions later as my file management habits evolve than to have to express my preferences <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="199d30469088046bb8786592166a214d">$n \times m$</math-renderer> times, where <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="199d30469088046bb8786592166a214d">$n$</math-renderer> is the number of programs I use and <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="199d30469088046bb8786592166a214d">$m$</math-renderer> is the number of unique configuration options each of them exposes to specify where all of their files go.</p>
<p dir="auto">... It's not about simply appeasing a subset of Vim users who for some reason have glommed onto some new-fangled specification, it's about <em>respecting users in general and making things easier for them by default.</em></p>
</blockquote>
<p dir="auto">I'd like to tack on to his point about 'respecting users': just because the user's home directory and its contents have full read-write-execute permissions for the user does not mean that software executed by said user should have free rein over the directory.</p>
<h3 dir="auto">3.2 So, what now?</h3>
<p dir="auto">The default assumption by a programmer might be:</p>
<blockquote>
<p dir="auto">Let's put config and data files in the same directory as the program.</p>
</blockquote>
<p dir="auto">This assumption immediately breaks on most modern desktop operating systems, because programs are typically installed to locations which require elevated write permissions (e.g. <code>/bin</code>, <code>%PROGRAMFILES%</code>) which means neither users nor their processes can write there willy-nilly.
Furthermore, most desktop OSs are multi-user, which means handling several different configurations and data for multiple users.
Even <em>Android</em>, a smartphone OS, <a href="https://www.android.com/versions/lollipop-5-0/#:~:text=Multiple%20users%20for%20phones." rel="nofollow">supports multiple user profiles since 5.0 Lollipop</a>, which means providing ways for developers to handle different user profiles.</p>
<p dir="auto">From my experiments, apps and their data are completely sandboxed per-user on Android, so apps installed by one user can be neither seen nor accessed by another user.
This is workable on desktop OSs, except that it still doesn't really solve the backup problem: do we just sync the entire app and its contents to a server?
Many programs on desktop OSs are several gigabytes large, and naïvely syncing this much data is a waste of bandwidth.
And it hearkens back to the point mentioned above: any backup utility or the user will have to handle a polynomially large number of application-user-configuration combinations.</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/5912d7d9ed99804717160163c04b56d796b8fb097f0ddf8400e7a5bf35ca9f3c/68747470733a2f2f696d67732e786b63642e636f6d2f636f6d6963732f776f726b666c6f772e706e67"><img src="https://camo.githubusercontent.com/5912d7d9ed99804717160163c04b56d796b8fb097f0ddf8400e7a5bf35ca9f3c/68747470733a2f2f696d67732e786b63642e636f6d2f636f6d6963732f776f726b666c6f772e706e67" width="200" data-canonical-src="https://imgs.xkcd.com/comics/workflow.png"></a></p><h3 dir="auto">3.3 Screw your conventions, <em>we've always done it this way</em></h3>
<p dir="auto">We come to the real crux of the matter: why and how developers break the above-mentioned conventions and standards.
Developers cite only a few reasons for not wanting to adhere to conventions, and the following are lifted <em>verbatim</em> from their respective issue trackers (many closed as 'won't fix'):</p>
<p dir="auto"><a href="https://github.com/arduino/arduino-cli/issues/1538#issuecomment-961800324" data-hovercard-type="issue" data-hovercard-url="/arduino/arduino-cli/issues/1538/hovercard">Arduino</a>:</p>
<blockquote>
<p dir="auto">It's a change to an existing and established behaviour, a breaking change for all existing users too.</p>
</blockquote>
<p dir="auto"><a href="https://savannah.gnu.org/support/?108134#comment3" rel="nofollow">Bash</a>:</p>
<blockquote>
<p dir="auto">There's no reason to change historical behavior here.  All the world is not Linux.</p>
</blockquote>
<p dir="auto">OpenSSH (<a href="https://web.archive.org/web/20190925004614/https://bugzilla.mindrot.org/show_bug.cgi?id=2050#c1" rel="nofollow">archived page</a>, because the original bug report is inaccessible to guest users):</p>
<blockquote>
<p dir="auto">No. OpenSSH (and it's ancestor <code>ssh-1.x</code>) have a 17 year history of using <code>~/.ssh</code>. This location is baked into innumerable users' brains, millions of happily working configurations and countless tools.
Changing the location of our configuration would require a very strong justification and following a trend of desktop applications (of which OpenSSH is not) is not sufficient.</p>
</blockquote>
<p dir="auto"><a href="https://github.com/baldurk/renderdoc/pull/1741#issuecomment-592477184" data-hovercard-type="pull_request" data-hovercard-url="/baldurk/renderdoc/pull/1741/hovercard">RenderDoc</a>:</p>
<blockquote>
<p dir="auto">I've thought about it but I don't want to accept this change. The additional complexity and bug surface is not worth the value added by the feature.
... I don't want to add dependency on those environment variables.</p>
</blockquote>
<p dir="auto"><a href="https://github.com/flatpak/flatpak/issues/1651#issuecomment-396370107" data-hovercard-type="issue" data-hovercard-url="/flatpak/flatpak/issues/1651/hovercard">Flatpak</a>:</p>
<blockquote>
<p dir="auto">There is no actual problem here.</p>
</blockquote>
<p dir="auto">In a nutshell, these reasons are:</p>
<ul dir="auto">
<li><strong>ignorance</strong>, i.e. the developer doesn't know the specification exists</li>
<li><strong>arrogance</strong>, i.e. 'my way is correct, I don't care what my users say because they're stupid', or even 'it works on my machine';</li>
<li><strong>fear of</strong> introducing <strong>change</strong> for change's sake, and breaking user workflows;</li>
<li><strong>fear of</strong> introducing <strong>complexity</strong> in handling these conventions, especially if the program is multi-platform.</li>
</ul>
<h4 dir="auto">3.2.1 Ignorance</h4>
<p dir="auto">This is more understandable than the rest, and is easily mitigated, especially if the developer is responsive and accepting of changes.
Nothing else to say here, honestly; if you don't know the platform conventions, you don't; hopefully you pick it up and rewrite your software to be a good citizen of the platform you're targetting.</p>
<h4 dir="auto">3.2.2 Arrogance</h4>
<p dir="auto">This is the least acceptable, and it reveals an ugly superiority complex.
If developers don't respect their users, then why even bother releasing software publicly, except to flex and collect bragging rights?
Many open-source authors angrily retort: 'develop it yourself if you want <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="199d30469088046bb8786592166a214d">$x$</math-renderer> feature'.
Yes, there are dire warnings about 'as-is', and 'no warranty' for 'merchantability' and 'fitness for a purpose', and I'm not claiming that open-source software authors are legally obliged to make quality-of-life changes.
The <em>social contract</em>, however, is that said developers and maintainers listen to and judges user feedback on their own merits, and implements frequently-asked-for features or fixes.</p>
<h4 dir="auto">3.2.3 Fear of change and complexity</h4>
<p dir="auto">I'm not going to quote Heraclitus or Benjamin Franklin here ('change is the only constant'), but software should be developed to fit users' needs, and platform conventions.
As software is developed, it <em>changes</em>, doesn't it?</p>
<p dir="auto">In all honesty, it seems like this fear is a function of <em>what</em> is being changed:
developers tend to view adding fancy new features with delight, but see more menial tasks like properly handling paths and correct cross-platform behaviour with disdain.
If your program is going to be cross-platform, you <em>will</em> have to handle the inherent complexity in supporting all those platforms, and again, <em>be a good citizen on those platforms</em>.</p>
<p dir="auto">Merely using cross-platform frameworks (like Electron or Qt) is not a panacea: if your program writes to a non-canonical location in the user's home directory, it ought to tell the user where it is writing to, and what it is writing.
Case in point: Visual Studio Code is a fairly big problem (see below).</p>
<h2 dir="auto">4 Platform-specific issues</h2>
<h3 dir="auto">4.1 Linux</h3>
<p dir="auto">Before I proceed, I provide a listing of my own <code>$HOME</code> on my Arch Linux install:</p>
<details>
<summary>My <code>$HOME</code></summary>
<pre lang="zsh"><code>% ls -A1 --group-directories-first $HOME
.android
.astropy
.cache
.cgdb
.config
.dotnet
.enthought
.gitkraken
.gnome
.gnupg
.icons
.java
.local
.miktex
.mozilla
.npm
.nuget
.omnisharp
.pki
.pytest_cache
.renpy
.rustup
.sonarlint
.sqlsecrets
.ssh
.stellarium
.swt
.templateengine
.thunderbird
.vcpkg
.vscode
.zotero
Desktop
Documents
Downloads
Music
OneDrive
Pictures
Public
Templates
Videos
VirtualBox VMs'
Zotero
bin
enthought
.Xauthority
.bash_history
.fonts.conf
.gtkrc-2.0
.lesshst
.nvidia-settings-rc
.ocamlinit
.python_history
.utop-history
.viminfo
.vimrc
.wget-hsts
vkvia.html
</code></pre>
</details>
<p dir="auto">Of the above directories and files, I created exactly <em>two</em> manually: <code>OneDrive</code>, and <code>bin</code>.
The rest (excluding the XDG directories) were either auto-generated by <code>xdg-user-dirs</code> (which is okay), or created and written to by non-compliant software.</p>
<p dir="auto">The link above discussing the origin of dot-files makes it clear that the current behaviour was possibly <em>a mistake</em> made by the original developers of UNIX.
Even if it wasn't, the result today is a messy litter of dot-files dumped all over a user's home directory.
The XDG Base Directory (hereafter, XBD) specification is more than a decade old—an eternity in computing terms—and yet, there is a veritable parade of very well-known programs that refuse to follow its guidelines: see the quotes above in <a href="#33screw-your-conventions-weve-always-done-it-this-way">§3.3</a>.</p>
<p dir="auto">The Arch Wiki has <a href="https://wiki.archlinux.org/title/XDG_Base_Directory#Support" rel="nofollow">a list of programs</a> that are XBD-compliant by default, may be forced to comply after user intervention, and those with hard-coded non-XBD paths.
The latter two lists combined is almost <em>twice</em> as long as the compliant list, and includes some very prominent *nix-first software like Bash, Vim, OpenSSH, and Firefox.</p>
<p dir="auto">There's little more to say here: there exists a specification, many programs adhere to it, and many don't.
Fragmentation is only useful in grenades, and not in software specifications.</p>
<p dir="auto">For the record, people have found XBD compliance painful enough that someone developed a tool <em>dedicated</em> to finding non-compliant programs, and suggesting user-side workarounds: <a href="https://github.com/b3nj5m1n/xdg-ninja"><code>xdg-ninja</code></a> (written in Haskell, by the way, which is nice).</p>
<h3 dir="auto">4.2 Windows</h3>
<p dir="auto">Windows... Ah, Windows.
Bastion of backwards compatibility, keeping icons and settings options from Windows 3.1 NT around in Windows 11...
And the source of all your problems.</p>
<p dir="auto">As on Linux, let me provide a listing of my <code>%USERPROFILE%</code>:</p>
<details>
<summary>My <code>%USERPROFILE%</code></summary>
<div dir="auto"><pre><span>&gt;</span> gci <span>$<span>env:</span>USERPROFILE</span> <span>-</span>Name
.android
.cache
.config
.dlv
.dotnet
.eclipse
.fop
.gk
.gnupg
.gradle
.librarymanager
.m2
.matplotlib
.ms<span>-</span>ad
.nuget
.omnisharp
.platformio
.sonarlint
.ssh
.templateengine
.thumbnails
.vscode
ansel
Calibre Library
Contacts
dotTraceSnapshots
Heaven
recovered
RenPy
source
Tracing
Zotero
.cortex<span>-</span>debug
.git<span>-</span>for<span>-</span>windows<span>-</span>updater
.gitconfig
.kdiff3rc
.lesshst
Sti_Trace.log</pre></div>
</details>
<p dir="auto">Yep, <em>dot-files</em>... in <em>Windows</em>.
Windows does <em>not</em> automatically hide dot-files, whether it be in Explorer, <code>dir.exe</code>, or <code>Get-ChildItem</code>.
Notice the above listing is missing <code>AppData</code>—that's because it is properly hidden by the filesystem as mentioned in <a href="#2231hidden-folders-on-windows">§2.2.3.1</a>.
This is frequently violated by software written for *nix first—notice <code>.git</code>, <code>.ssh</code>... There's even the full set of XDG base directories, which is a *nix specification!</p>
<p dir="auto">Developers either assume Windows operates the same as *nix, or don't care about Windows much ('second-class citizen'), and again, couch any changes to fix this as 'introducing unnecessary complexity'.
Honestly, one would instead think the change is fairly straightforward: test which OS the program is running on using <code>#ifdef</code>s and OS-specific macros, and delegate to the appropriate function.
<a href="https://sourceforge.net/p/predef/wiki/OperatingSystems/" rel="nofollow">Here's a wiki</a> listing some of these macros.
Better still, use the ecosystem's build system to configure builds for different platforms, and shift this test to configure and compile-time instead of run-time.</p>
<p dir="auto">Some semi-compliant software hard-codes library paths, assuming user libraries will remain in the default locations, i.e. sub-directories of <code>%USERPROFILE%</code>.
This is <em>not</em> true, and users can change their locations as mentioned above.
Notice there's a <code>Contacts</code> directory in the listing above: this was created by <a href="https://kdeconnect.kde.org/" rel="nofollow">KDE Connect</a>.</p>
<p dir="auto">That said, not <em>all</em> the above dot-directories are created by traditionally *nix programs, which is a good segue to the next section...</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/5ec315c3161975e71b8c836323d8c98c3443ab5fddb66a51e6a2bd3646bec2c3/68747470733a2f2f626f6e6b657273776f726c642e6e65742f696d672f323031312d30362d32375f6f7267616e697a6174696f6e616c5f6368617274732e706e67"><img src="https://camo.githubusercontent.com/5ec315c3161975e71b8c836323d8c98c3443ab5fddb66a51e6a2bd3646bec2c3/68747470733a2f2f626f6e6b657273776f726c642e6e65742f696d672f323031312d30362d32375f6f7267616e697a6174696f6e616c5f6368617274732e706e67" width="400" data-canonical-src="https://bonkersworld.net/img/2011-06-27_organizational_charts.png"></a></p><h4 dir="auto">4.2.1 The Microsoft irony</h4>
<p dir="auto">Notice <code>.dotnet</code>, <code>.nuget</code>, <code>.omnisharp</code>, <code>.templateengine</code>, <code>.vscode</code>, and <code>source</code>.
Microsoft <em>itself</em> is a lousy citizen of Windows.
<code>source</code> is repeatedly created by Visual Studio (not Code), especially on a fresh install.
The rest of the projects are open-source, and have active/on-going issues related to home directory pollution:</p>
<ul dir="auto">
<li><code>dotnet</code> CLI and <code>.templateengine</code>: <a href="https://github.com/dotnet/sdk/issues/8678" data-hovercard-type="issue" data-hovercard-url="/dotnet/sdk/issues/8678/hovercard">issue closed</a>, but requires setting <code>DOTNET_CLI_HOME</code> environment variable. Otherwise defaults to previous behaviour, and still doesn't fix <code>.dotnet</code>;</li>
<li><code>nuget</code>: <a href="https://github.com/dotnet/sdk/issues/4650" data-hovercard-type="issue" data-hovercard-url="/dotnet/sdk/issues/4650/hovercard">issue still open</a>;</li>
<li><code>omnisharp</code>: <a href="https://github.com/OmniSharp/omnisharp-roslyn/issues/953" data-hovercard-type="issue" data-hovercard-url="/OmniSharp/omnisharp-roslyn/issues/953/hovercard">issue still open</a>;</li>
<li><code>vscode</code>: <a href="https://github.com/microsoft/vscode/issues/3884" data-hovercard-type="issue" data-hovercard-url="/microsoft/vscode/issues/3884/hovercard">issue still open</a>.</li>
</ul>
<p dir="auto">It feels like developers who have never natively used Windows or its stack, work on and contribute to Microsoft software, without liaising with veteran Windows teams.
Maybe that's why Windows 11 looks so...<em>inspired</em>... by macOS (which is an aberration; the macOS windowing system sucks).</p>
<h4 dir="auto">4.2.2 Video games</h4>
<p dir="auto">Video games on Windows deserve a special heading of their own, because they are <em>particularly</em> egregious offenders.
In my opinion, game devs <em>really</em> have no excuse: almost all games primarily target Windows, or are ported by dedicated teams who know Windows inside out, and more importantly, develop using an entirely native toolchain.
Even Unreal and Unity have functionality to call out to native code, and developers <em>still</em> don't use it to properly handle save data.
The issue is such that the PCGamingWiki has dedicated 'save file location' and 'config file location' headings for every single game in its database.</p>
<p dir="auto">Most video games seem to like writing their save files, screenshots, and settings data into <code>Documents\</code> or <code>Documents\My Games</code>, which is a holdover from Windows XP.
Look, I get it, many game engines are old; they trace their lineage to engines first written in the 1990s and early 2000s.
But if developers can add ray-tracing updates to a 16-year-old game (<em>Portal: RTX</em>), surely they can spend a couple hours fixing this too.</p>
<p dir="auto">Here is a listing of my <code>Documents</code> library, which illustrates the problem:</p>
<div dir="auto"><pre><span>&gt;</span> gci D:\Libraries\Documents <span>-</span>Name
3DMark
4A Games
Anno <span>1404</span>
Anno <span>1404</span> Venecia
Anno <span>1404</span> Venedig
Anno <span>1404</span> Venezia
Anno <span>1404</span> Venice
Anno <span>1404</span> Venise
ANNO <span>1404</span> Wenecja
Anno <span>1800</span>
Assassin<span><span>'</span>s Creed Odyssey</span>
<span>Assassin<span>'</span></span>s Creed Unity
Battlefield <span>1</span>
Blackmagic Design
Custom Office Templates
Dell
en<span>-</span>GB
FeedbackHub
Graphics
Horizon Zero Dawn
IISExpress
Larian Studios
MATLAB
MAXON
My <span>Data</span> Sources
My Digital Editions
My Games
My Spore Creations
My Web Sites
OnScreen Control
Outlook Files
PowerShell
PowerToys
Rockstar Games
Shadow of the Tomb Raider
Sound recordings
Steam Cloud
The Witcher <span>3</span>
The Witcher <span>3</span> Mod Manager
Visual Studio <span>2019</span>
Visual Studio <span>2022</span>
WindowsPowerShell
Witcher <span>2</span>
Wolfram Mathematica
Zoom
_Documents
enc_cert.pfx
mods.settings</pre></div>
<p dir="auto"><em>Anno 1404</em>, what the hell are you doing? <em>Six</em> different (localised) directories, all containing the same paths.</p>
<p dir="auto">Honestly speaking, I doubt game developers are going to change to <code>Saved Games</code>, and this is partially Microsoft's fault, again.
The folder is neither listed in the default File Explorer <code>Libraries</code> view, nor in the <code>My PC</code> view; users have to manually navigate to it.
Its rarity is demonstrated by the ratio of games using either <code>Documents</code> or <code>Documents\My Games</code> compared to those using <code>Saved Games</code>: <strong>32:4</strong> on my computer (the four games using <code>Saved Games</code> are <em>Cyberpunk 2077</em>, <em>Metro: Exodus</em>, <em>Kingdom Come: Deliverance</em>, and **)
Some games forgo <code>Documents</code> altogether, and put the save files directly with the game files, or even in <code>%APPDATA%</code>.</p>
<p dir="auto"><a href="https://gamedev.stackexchange.com/a/108243/157009" rel="nofollow">This answer on the Game Development StackExchange</a> is relevant:</p>
<blockquote>
<p dir="auto">The best reason I can think of is <strong>to reduce cost of customer support</strong>. The problem is that <code>%APPDATA%</code> and <code>%LOCALAPPDATA%</code> are hidden directories, and nobody seems to know about <code>%UserProfile%\Saved Games</code>. Placing the files in <code>Documents</code>, studios can save money on support calls that ask how to backup savegames, or how to migrate the savegames from one machine to another.</p>
</blockquote>
<p dir="auto">Notice even here that Microsoft is polluting <code>Documents</code> with <code>Custom Office Templates</code>, <code>FeedbackHub</code>, <code>My Data Sources</code>, <code>Outlook Files</code>, <code>Visual Studio 20XX</code>, <code>PowerShell</code>, <code>PowerToys</code>, and <code>WindowsPowershell</code> (yes; there are <a href="https://learn.microsoft.com/en-sg/powershell/scripting/whats-new/differences-from-windows-powershell?view=powershell-7.3" rel="nofollow"><em>two</em> PowerShells</a>).
The folder contains everything <em>but</em> documents now, and it is so cluttered that I have the <code>_Documents</code> subfolder for <em>my</em> stuff—files I explicitly created via a save dialog box or the command-line.
The leading underscore is a necessary evil, as it means the directory is listed first when sorted by name in File Explorer.</p>
<p dir="auto">In a nutshell... A hopeless situation.
There's no saving Windows user profiles when Microsoft itself doesn't adhere to its own conventions.</p>
<h2 dir="auto">5 Solutions</h2>
<p dir="auto">So if things are so 'hopeless' as I put it, then why bother with this article?
I think <em>any</em> change towards compliance is better than no change, that's all.</p>
<p dir="auto">On *nix, the answer is straightforward: get everyone to adhere to the XDG Base Directory specification.
Of course, 'get everyone to' is doing a lot of work in that sentence: it involves submitting an issue, convincing maintainers that this is a worthwhile, and possibly writing code to satisfy the specification, correctly (including the fall-back directories), and all the review drudgery before things are finally merged.</p>
<p dir="auto">On Windows, the problems arise from within, and I sincerely don't see a solution.
Thankfully, many non-compliant projects are fully open-source, and contributing to them, or up-voting issues, will hopefully help.
Game developers are famously opaque (especially given how lucrative the industry is as a whole), and as mentioned above, they do have genuine reasons for saving stuff in <code>Documents</code>.</p>
<p dir="auto">That being said, there is still value in attempting to fix this on Windows.
The specification is clear, some developers clearly know about it, and it is a good starting point for new projects (Microsoft is apparently promoting Rust now over C++ for green-field Windows development, so maybe there's hope yet).</p>
<h3 dir="auto">5.1 Home, sweet home</h3>
<p dir="auto">We have so many real-life analogues in our computers: from files, folders, and rubbish bins, to the 'desktop' metaphor.
Surely we can extend the concepts of 'clutter' and 'cleanup', too?
Let's be good citizens of the platforms we develop for, and give our users choices and control over their data, and where it is stored.
I'd like a nice vacuum cleaner for my home directory, please.</p>
<h2 dir="auto">6 Relevant blog posts</h2>
<p dir="auto">Here are several blog posts and articles that inspired me and were useful for my post—some of which were linked above:</p>
<ul dir="auto">
<li><a href="https://0x46.net/thoughts/2019/02/01/dotfile-madness/" rel="nofollow"><em>Dotfile madness</em></a></li>
<li><a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ReportConfigFileLocations" rel="nofollow"><em>Everything that uses configuration files should report where they're located</em></a></li>
<li><a href="https://learn.microsoft.com/en-sg/archive/blogs/patricka/where-should-i-store-my-data-and-configuration-files-if-i-target-multiple-os-versions#targeting-vista-and-higher" rel="nofollow"><em>Where should I store my data and configuration files if I target multiple OS versions?</em></a></li>
<li><a href="https://archive.ph/eOGDp" rel="nofollow"><em>A Brief History of Windows Profiles</em></a></li>
</ul>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Amazon Prime Day 2023 AWS Bill (135 pts)]]></title>
            <link>https://www.lastweekinaws.com/blog/the-amazon-prime-day-2023-aws-bill/</link>
            <guid>37153426</guid>
            <pubDate>Wed, 16 Aug 2023 20:36:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lastweekinaws.com/blog/the-amazon-prime-day-2023-aws-bill/">https://www.lastweekinaws.com/blog/the-amazon-prime-day-2023-aws-bill/</a>, See on <a href="https://news.ycombinator.com/item?id=37153426">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Jeff Barr recently posted his annual <a href="https://aws.amazon.com/blogs/aws/prime-day-2023-powered-by-aws-all-the-numbers/">Prime Day by the numbers</a> blog post, and I was immediately inundated by questions around “How much did this cost?”</p>
<p>There are a few answers possible, none of which are quite correct.</p>
<p>There’s an argument that in absolute terms the answer is “zero,” because it’s simply money transferring from one part of Amazon’s balance sheet to another — but that’s unsatisfying.</p>
<p>There’s the internal chargeback costs that AWS charges Amazon for services that would be subject to (at a minimum) significant discounting just due to volume, but also quite possibly modified at some foundational level. I don’t actually know how it works in practice (Amazon is not an AWS bill optimization customer of mine — YET!), and if I did, I wouldn’t be able to talk about it publicly.</p>
<p>So let’s use the only estimates that make sense here: what the on-demand cost of this would be, at retail pricing posted on the AWS website, assuming it’s all in us-east-1.</p>
<p>We’re going to include the numbers only for the 48 hours that Prime Day ran and not include any support charges (which you would be frankly nuts to not pay for at this scale). Further, nobody at this scale would ever actually <em>pay</em> retail prices, but it’s enough for a fun thought experiment. Let’s begin.</p>
<h2 id="h-the-cost-analysis-of-prime-day-2023">The cost analysis of Prime Day 2023</h2>
<p>The by-the-numbers post gives us a list of some crucial usage numbers for our calculations, broken down by each AWS service.</p>
<h3 id="h-ebs">EBS</h3>
<p>Jeff tells us that Amazon added an incremental 163 petabytes of EBS storage capacity. Given that EBS comes in many different flavors, there’s a range here. If it’s gp3 (which is what most folks should start with), it’d be roughly $878,000, if it’s slow magnetic sc1 then it would cost $164,000, and if it’s io2 volumes, it soars to $3.4 million. In reality, it’s almost certainly a mix. Further, despite Jeff telling us that it served 15.35 trillion requests and 764 petabytes of data transfer per day, there’s no way to say what this cost (if anything) in terms of additional provisioned IOPS or throughput. I’ll mark it at zero, and assume it’s all gp3 volumes for simplicity.</p>
<p>EBS thus costs <strong>$878,003.00</strong>.</p>
<h3 id="h-cloudtrail">CloudTrail</h3>
<p>AWS CloudTrail processed over 830 billion events in support of this year’s Prime Day. This is kind of tricky to calculate along a few axes. If they were all management events, they were free for the first trail. Every additional management trail (usually configured by accident!) would add another $16.6 million for this charge. And if these were all data events, the cost would be $830K.</p>
<p>In all probability, these charges were a mix of both types of event. Let’s split the difference, be extremely charitable and assume there’s only one management trail, and call it 415 billion free management events and $415,000 for 415 billion chargeable data events.</p>
<p>CloudTrail thus costs <strong>$415,000</strong>.</p>
<h3 id="h-dynamodb">DynamoDB</h3>
<p>DynamoDB processed “trillions of requests” and peaked at 126 million requests per second. This is so vague as to be fodder for absolute despair, but we can reason about this a bit.</p>
<p>We’ll disregard storage costs and only care about the transaction volume. Let’s also assume 50% read/write split, eventual consistency, and that we’ll have to provision for that peak throughout the whole 48 hours, since autoscaling DynamoDB is … laggy. This brings us to about $2.5 million. If you have a problem with this, or think I’m being unfair, remember that I could have instead said that this was all on-demand capacity instead, in which case the cost for this line item would instead be $249 million over two days.</p>
<p>DynamoDB costs <strong>$2,505,360</strong>.</p>
<h3 id="h-aurora">Aurora</h3>
<p>This is incredibly hard to calculate; the numbers given include 5,835 database instances running the PostgreSQL-compatible and MySQL-compatible editions of Amazon Aurora that processed 318 billion transactions, stored 2,140 terabytes of data, and transferred 836 terabytes of data.</p>
<p>Hoo boy.</p>
<p>Let’s assume 2,000 MySQL instances, and 3,835 PostgreSQL instances, purely because “POST-gruh-SQUEAL” is incredibly fun to say. We’ll assume that these are the I/O Optimized option, because calculating out how Aurora accounts for IO charges is incredibly frustrating, and that they aren’t using either of the Aurora Serverless offerings for obvious expensive reasons..</p>
<p>Instance sizing is tricky, and it’s also everything to this calculation. RDS instances can each cost as much as $19,000 a month, or as little as $90. Let’s pick something middle of the road: the db.r6i.12xlarge, which comes in at $7,000 for a full month.</p>
<p>Smack these two groups together, and the MySQL instances cost $2,412,864, while the PostgreSQL instances cost $3,681,231 for these 48 hours.</p>
<p>The Aurora cost comes to <strong>$6,094,095</strong>.</p>
<h3 id="h-ses">SES</h3>
<p>Now, the only data available in this post states that “SES sent 56% more emails than last year.” However, Amazon separately stated that <a href="https://www.aboutamazon.com/news/retail/amazon-prime-day-2023-stats">customers purchased 375 million items</a>. While I could snidely suggest that each sale generated 40 emails, a quick check of my own purchase history indicates that every order spits out 3 emails: a confirmation, a shipment notification, and a delivery notification. While many orders were obviously multiple items, we’ll balance this out by ignoring all of the promotional email around Prime Day deals. That means that we’ll say SES sent customers 1.125 billion emails for Prime Day, and assume each one is 20KB. They talk about deliverability rates, which means they’re using SES’s rather snazzy Deliverability Manager, and that brings the cost of these billion-plus emails to a bit under $200K.</p>
<p>SES cost comes to <strong>$193,824.84</strong>.</p>
<h2 id="h-cloudfront">CloudFront</h2>
<p>Amazon CloudFront handled “a total of over 1 trillion HTTP requests during Prime Day.” This is not strictly accurate. I pay attention to these things, and I can assure you that every connection as a part of the shopping process is in fact HTTPS. In fact, [Amazon.com)[https://amazon.com] is on the HSTS preload list, which means that browsers will actively refuse to connect to that domain over HTTP. Why is this important? Because the public pricing for CloudFront shows that HTTPS requests cost more! Curiously, the AWS Pricing Calculator does not draw a distinction here at the time of this writing.</p>
<p>Also, CloudFront pricing varies depending upon where the user is requesting the data from, which makes accurate numbers impossible here. Let’s be incredibly generous to Amazon and pretend that all of this traffic came from the U.S. and Mexico, as those are the cheapest rates.</p>
<p>Jeff declines to state how much data was transferred, so we have to guess wildly here. Let’s assume 100 kilobytes per request, which comes out to 90 petabytes.</p>
<p>Requests plus data egress means that CloudFront costs a bit under $3 million for these 48 hours.</p>
<p>CloudFront costs us <strong>$2,928,161</strong>.</p>
<h2 id="h-sqs">SQS</h2>
<p>SQS processed a peak of 86 million messages a second, end of data. Hmm. That’s … a bit open-ended, isn’t it? Each second at that rate costs $34, and thus if this were sustained it would cost over $5.8 million for the whole 48 hours.</p>
<p>What makes this extra fun is that the AWS Pricing Calculator refuses to accept that this scale is possible; their form yells at you two orders of magnitude before you get to this number. This suggests that there’s a lack of scale imagination happening somewhere. As a result, I’m left to use the first tool in the Cloud Economist’s toolbox: arithmetic. Let’s round this to $2 million — I find that more than fair.</p>
<p>SQS costs <strong>$2 million</strong>.</p>
<h2 id="h-pinpoint">Pinpoint</h2>
<p>Pinpoint sent “tens of millions of SMS messages.” OK, let’s assume 50 million, all to U.S. numbers. The cost for that is $0.00581 a message, so blowing up your phone is straight arithmetic. Note that the AWS Pricing Calculator directs you to an “SMS pricing tool” that is simply a table. This is a poor experience.</p>
<p>Pinpoint SMS costs <strong>$290,500</strong>.</p>
<h3 id="h-ec2">EC2</h3>
<p>Finally, we come to EC2. The assertion that Amazon “used tens of millions of normalized AWS Graviton-based Amazon EC2 instances” is not only vague, it’s a problem. The idea of “normalized instance hours” may make sense internally at Amazon, but I can borderline promise that it doesn’t make as much sense as you might hope for reasoning about <em>your</em> cloud costs. I will no doubt rant about this at a future date.</p>
<p>Okay, let’s assume 50 million “normalized instances,” which we’ll call c7g.medium since it’s directionally accurate. We’ll have to use arithmetic here, since the AWS Pricing Calculator refuses to believe that more than 50,000 EC2 instances are possible within a single region. Oh, honey — I have some of our mutual customers to introduce you to.</p>
<p>For these 48 hours, we do simple math.</p>
<p>EC2 costs <strong>$87,120,000</strong>.</p>
<h2 id="h-the-cost-of-prime-day-2023">The cost of Prime Day 2023</h2>
<p>Adding all of these (again, inaccurate) numbers together demonstrates that at retail pricing, running the infrastructure for Amazon Prime Day for 48 hours would cost you <strong>$102,424,943.84</strong>.</p>
<p>While this is obviously way higher than reality, assume for a minute that it isn’t. $102 million in infrastructure spend for an event that brought in over $12.7 billion in sales isn’t the worst return on investment that companies could make — by a landslide!</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Anonfiles is shutting down (137 pts)]]></title>
            <link>https://anonfiles.com/</link>
            <guid>37153373</guid>
            <pubDate>Wed, 16 Aug 2023 20:32:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://anonfiles.com/">https://anonfiles.com/</a>, See on <a href="https://news.ycombinator.com/item?id=37153373">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>
After trying endlessly for two years to run a file sharing site with user anonymity we have been tired of handling the extreme volumes of people abusing it and the headaches it has created for us. <br>
Maybe it is hard to understand but after tens of million uploads and many petabytes later all work of handling abuse was automated through all available channels to be fast as possible. <br>
We have auto banned contents of hundreds of thousands files. <br>
Banned file names and also banned specific usage patterns connected to abusive material to the point where we did not care if we accidental delete thousands of false positive in this process. <br>
Even after all this the high volume of abuse will not stop. <br>
This is not the kind of work we imagine when acquiring it and recently our proxy provider shut us down.  </p><p>

This can not continue. </p><p>

Domain 4sale.
</p><p>
domain@anonfiles.com
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ts_zip: Text Compression Using Large Language Models (234 pts)]]></title>
            <link>https://bellard.org/ts_server/ts_zip.html</link>
            <guid>37152978</guid>
            <pubDate>Wed, 16 Aug 2023 20:08:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bellard.org/ts_server/ts_zip.html">https://bellard.org/ts_server/ts_zip.html</a>, See on <a href="https://news.ycombinator.com/item?id=37152978">Hacker News</a></p>
<div id="readability-page-1" class="page">


The <code>ts_zip</code> utility provided with
the <a href="https://bellard.org/ts_server/index.html">ts_server</a> software can
compress (and hopefully decompress) text files with Large Language
Models. The compression ratio is much higher than with other
compression tools. There are some caveats of course:
<ul>
  <li>Unlike <a href="https://bellard.org/nncp">NNCP</a>, the language
    model must be available when decompressing.</li>
  <li>A GPU is mandatory to get a reasonable speed. Depending on the
  model size, the speed varies between a few kB/s to one
  hundred kB/s.</li>
  <li>The same exact GPU model and program versions must be used for
    compression and decompression.</li>
  <li>The model is frozen so it works only for text files in a
    language that the model has already seen.</li>
</ul>

<h4>Compression Ratio</h4>
<p>
The compression ratio is given in bits per byte for each
model. <a href="http://www.byronknoll.com/cmix.html">CMIX v19</a> is
one of the best lossless data compression program.
</p>
<table>
  <thead>
    <tr>
      <th aria-sort="ascending">File
      </th><th>Original size<br>(bytes)
      </th><th><a href="https://en.wikipedia.org/wiki/XZ_Utils">xz</a><br>(bpb)
      </th><th><a href="http://www.byronknoll.com/cmix.html">CMIX v19</a><br>(bpb)
      </th><th><a href="https://huggingface.co/fbellard/ts_server/resolve/main/pythia_deduped_70M.bin">pythia_deduped_70M</a><br>(bpb)
      </th><th><a href="https://huggingface.co/fbellard/ts_server/resolve/main/rwkv_169M.bin">rwkv_169M</a><br>(bpb)
      </th><th><a href="https://huggingface.co/fbellard/ts_server/resolve/main/rwkv_430M.bin">rwkv_430M</a><br>(bpb)
      </th><th><a href="https://huggingface.co/fbellard/ts_server/resolve/main/falcon_7B_q4.bin">falcon_7B_q4</a><br>(bpb)
      </th><th><a href="https://huggingface.co/fbellard/ts_server/resolve/main/rwkv_7B_q4.bin">rwkv_7B_q4</a><br>(bpb)
    </th></tr>
  </thead>
  <tbody>
    <tr><td><a href="https://en.wikipedia.org/wiki/Canterbury_corpus">alice29.txt</a>
      </td><td>152089
      </td><td>2.551
      </td><td>1.645
      </td><td>1.335
      </td><td>1.166
      </td><td>1.028
      </td><td>0.718
      </td><td>0.411
    </td></tr>
    <tr><td><a href="https://en.wikipedia.org/wiki/Calgary_corpus">book1</a>
      </td><td>768771
      </td><td>2.717
      </td><td>1.816
      </td><td>1.569
      </td><td>1.426
      </td><td>1.311
      </td><td>1.104
      </td><td>1.115
    </td></tr>
    <tr><td><a href="http://mattmahoney.net/dc/text.html">enwik8</a>
      </td><td>100000000
      </td><td>1.989
      </td><td>1.187
      </td><td>-
      </td><td>1.098
      </td><td>0.948
      </td><td>-
      </td><td>-
    </td></tr>
    <tr><td><a href="https://mirrors.edge.kernel.org/pub/linux/kernel/v1.2/linux-1.2.13.tar.xz">linux-1.2.13.tar</a>
      </td><td>9379840
      </td><td>1.441
      </td><td>-
      </td><td>1.010
      </td><td>0.991
      </td><td>0.837
      </td><td>-
      </td><td>-
    </td></tr>
  </tbody>
</table>

<h4>Compression Speed and Required Memory</h4>

<p>
They are measured when compressing the <tt>book1</tt> file on a RTX
A6000 GPU. The decompression speed and memory requirements are similar.
</p>

<table>
  <thead>
    <tr>
      <th aria-sort="ascending">Model
      </th><th>Compression speed<br>(kBytes/s)
      </th><th>GPU memory<br>(GB)
    </th></tr>
  </thead>
  <tbody>
    <tr><td>rwkv_169M</td><td>128</td><td>0.38</td></tr>
    <tr><td>rwkv_430M</td><td>85</td><td>0.94</td></tr>
    <tr><td>pythia_deduped_70M</td><td>70</td><td>6.61</td></tr>
    <tr><td>rwkv_7B_q4</td><td>15</td><td>4.76</td></tr>
    <tr><td>falcon_7B_q4</td><td>6.7</td><td>8.44</td></tr>
  </tbody>
</table>

<h4>Conclusion</h4>

<p>
  The smaller <a href="https://github.com/BlinkDL/RWKV-LM">RWKV</a>
  models seem a good compromise for text compression because they use
  a small amount of memory due to their RNN structure and have a
  (relatively) high running speed.
</p>
<hr>
Fabrice Bellard - <a href="https://bellard.org/">https://bellard.org/</a>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Minimum Viable Secure Product (158 pts)]]></title>
            <link>https://mvsp.dev/</link>
            <guid>37152397</guid>
            <pubDate>Wed, 16 Aug 2023 19:30:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mvsp.dev/">https://mvsp.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=37152397">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p>Minimum Viable Secure Product is a minimalistic security checklist for B2B software and business process outsourcing suppliers.</p> <p>Designed with simplicity in mind, the checklist contains only those controls that must, at a minimum, be implemented to ensure a reasonable security posture.</p> <p>We recommend that all companies building B2B software or otherwise handling sensitive information under its broadest definition implement the listed controls and are strongly encouraged to go well beyond them in their security programs.</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Casio G-Shock time sync radio (152 pts)]]></title>
            <link>https://gshock.casio.com/intl/technology/radio/</link>
            <guid>37152136</guid>
            <pubDate>Wed, 16 Aug 2023 19:13:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gshock.casio.com/intl/technology/radio/">https://gshock.casio.com/intl/technology/radio/</a>, See on <a href="https://news.ycombinator.com/item?id=37152136">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


<main id="mainContent">
    
    <div id="container-7674ef0c99" data-cmp-data-layer="{&quot;teaser-ab102062e3&quot;:{&quot;@type&quot;:&quot;casio/components/content/teaser&quot;,&quot;repo:modifyDate&quot;:&quot;2022-01-31T02:49:51Z&quot;,&quot;dc:description&quot;:&quot;<p><b>ACCURACY | FUNCTION</b></p>\r\n<h2><b>Standard time&amp;nbsp;<br>\r\nradio wave reception<br>\r\n(Multiband 6)</b></h2>\r\n&quot;}}">
    
    
    <div data-cmp-is="image" data-cmp-lazythreshold="0" data-cmp-src="/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1689197747/teaser.casiocoreimg{.width}.jpeg/1643597391683/hero-pc-m.jpeg" data-asset="/content/dam/casio/global/watch/g_shock/technology/radio/hero_pc_M.jpg" data-title="Standard time radio wave reception (Multiband 6)" id="image-ab102062e3" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				 
					<source srcset="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1689197747/teaser/spImage.casiocoreimg.jpeg/1643597391695/hero-sp-m.jpeg" media="(max-width: 767px)" width="800" height="1010">
				
				<!-- PC -->
				<source srcset="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1689197747/teaser.casiocoreimg.jpeg/1643597391683/hero-pc-m.jpeg" media="(min-width: 768px)" width="1600" height="780">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1689197747/teaser.casiocoreimg.jpeg/1643597391683/hero-pc-m.jpeg" loading="lazy" alt="Standard time radio wave reception (Multiband 6)" title="Standard time radio wave reception (Multiband 6)" width="1600" height="780">
			</picture>
		
	
	
	<meta itemprop="caption" content="Standard time radio wave reception (Multiband 6)">
</div>

    <div data-teaser-pc="," data-teaser-sp=","><p><b>ACCURACY | FUNCTION</b></p>
<h2><b>Standard time&nbsp;<br>
radio wave reception<br>
(Multiband 6)</b></h2>
</div>
</div>
<div id="container-b3a618edf6">
    
    <div id="container-5624a2147f">
<p data-cmp-data-layer="{&quot;text-f3afed11d7&quot;:{&quot;@type&quot;:&quot;casio/components/content/text&quot;,&quot;repo:modifyDate&quot;:&quot;2022-01-31T02:49:51Z&quot;,&quot;xdm:text&quot;:&quot;<h2 style=\&quot;text-align: center;\&quot;><b>A built-in miniature&amp;nbsp;&amp;nbsp;antenna conducts&amp;nbsp;<br>\r\nhigh-sensitivity reception&amp;nbsp;&amp;nbsp;of standard time&amp;nbsp;&amp;nbsp;radio waves&amp;nbsp;<br>\r\ncarrying time information&amp;nbsp;&amp;nbsp;and corrects&amp;nbsp;<br>\r\nthe time automatically.</b></h2>\r\n&quot;}}" id="text-f3afed11d7">
    <h2><b>A built-in miniature&nbsp;&nbsp;antenna conducts&nbsp;<br>
high-sensitivity reception&nbsp;&nbsp;of standard time&nbsp;&nbsp;radio waves&nbsp;<br>
carrying time information&nbsp;&nbsp;and corrects&nbsp;<br>
the time automatically.</b></h2>

</p>

    

</div>
<div id="container-54f2d419a0">
    
    <div data-cmp-data-layer="{&quot;text-118e93ee88&quot;:{&quot;@type&quot;:&quot;casio/components/content/text&quot;,&quot;repo:modifyDate&quot;:&quot;2022-01-31T02:49:51Z&quot;,&quot;xdm:text&quot;:&quot;<h3><b>Indoor or outdoor radio wave reception</b></h3>\r\n<p>— Compatible with standard time radio wave transmissions in Japan (2 stations), North America, the UK, Germany and China.</p>\r\n<p>— Receives radio waves and displays the correct time indoors.&amp;nbsp;<br>\r\n* In places such as the vicinity of windows where radio wave reception is easy</p>\r\n<p>— Keeps the correct time at night with automatic reception (up to 6 times).</p>\r\n<p>— Achieves reception with lower power consumption.</p>\r\n&quot;}}" id="container-e28c410103">
    <h3><b>Indoor or outdoor radio wave reception</b></h3>
<p>— Compatible with standard time radio wave transmissions in Japan (2 stations), North America, the UK, Germany and China.</p>
<p>— Receives radio waves and displays the correct time indoors.&nbsp;<br>
* In places such as the vicinity of windows where radio wave reception is easy</p>
<p>— Keeps the correct time at night with automatic reception (up to 6 times).</p>
<p>— Achieves reception with lower power consumption.</p>

</div>
<div data-cmp-data-layer="{&quot;text-e5276f95b6&quot;:{&quot;@type&quot;:&quot;casio/components/content/text&quot;,&quot;repo:modifyDate&quot;:&quot;2022-01-31T02:49:51Z&quot;,&quot;xdm:text&quot;:&quot;<h3><b>Shock-resistant miniature antenna</b></h3>\r\n<p>A tiny shock-resistant antenna constructed of an amorphous material achieves high-sensitivity reception of standard time radio waves carrying time information.<br>\r\nReliability that enables stable radio wave reception from any of 6 stations worldwide is realized simultaneously with the robustness required to handle rough treatment under the most rugged conditions.</p>\r\n&quot;}}" id="container-fafdc9b024">
    <h3><b>Shock-resistant miniature antenna</b></h3>
<p>A tiny shock-resistant antenna constructed of an amorphous material achieves high-sensitivity reception of standard time radio waves carrying time information.<br>
Reliability that enables stable radio wave reception from any of 6 stations worldwide is realized simultaneously with the robustness required to handle rough treatment under the most rugged conditions.</p>

</div>
<div data-cmp-is="image" data-cmp-lazythreshold="0" data-cmp-src="/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1689197747_1119078549/container_218511885/container_1284986664/container_copy_11061/image.casiocoreimg{.width}.png/1643597392057/img1-m.png" data-asset="/content/dam/casio/global/watch/g_shock/technology/radio/img1_M.png" data-title="North American region" id="container-749fc22d91" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1689197747_1119078549/container_218511885/container_1284986664/container_copy_11061/image.casiocoreimg.png/1643597392057/img1-m.png" media="(min-width: 768px)" width="640" height="605">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1689197747_1119078549/container_218511885/container_1284986664/container_copy_11061/image.casiocoreimg.png/1643597392057/img1-m.png" loading="lazy" alt="North American region" width="640" height="605">
			</picture>
		
	
	
	
</div>
<div data-cmp-is="image" data-cmp-lazythreshold="0" data-cmp-src="/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1689197747_1119078549/container_218511885/container_1284986664/container_copy_11061_1613844229/image.casiocoreimg{.width}.png/1643597392138/img2-m.png" data-asset="/content/dam/casio/global/watch/g_shock/technology/radio/img2_M.png" data-title="European region" id="container-7ce8d3453c" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1689197747_1119078549/container_218511885/container_1284986664/container_copy_11061_1613844229/image.casiocoreimg.png/1643597392138/img2-m.png" media="(min-width: 768px)" width="640" height="605">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1689197747_1119078549/container_218511885/container_1284986664/container_copy_11061_1613844229/image.casiocoreimg.png/1643597392138/img2-m.png" loading="lazy" alt="European region" width="640" height="605">
			</picture>
		
	
	
	
</div>
<div data-cmp-is="image" data-cmp-lazythreshold="0" data-cmp-src="/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1689197747_1119078549/container_218511885/container_1284986664/container_copy_11061_1353467751/image.casiocoreimg{.width}.png/1643597392361/img3-m.png" data-asset="/content/dam/casio/global/watch/g_shock/technology/radio/img3_M.png" data-title="China" id="container-c3a21ceded" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1689197747_1119078549/container_218511885/container_1284986664/container_copy_11061_1353467751/image.casiocoreimg.png/1643597392361/img3-m.png" media="(min-width: 768px)" width="640" height="605">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1689197747_1119078549/container_218511885/container_1284986664/container_copy_11061_1353467751/image.casiocoreimg.png/1643597392361/img3-m.png" loading="lazy" alt="China" width="640" height="605">
			</picture>
		
	
	
	
</div>
<div data-cmp-is="image" data-cmp-lazythreshold="0" data-cmp-src="/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1689197747_1119078549/container_218511885/container_1284986664/container_copy_11061_1726442676/image.casiocoreimg{.width}.png/1643597392442/img4-m.png" data-asset="/content/dam/casio/global/watch/g_shock/technology/radio/img4_M.png" data-title="Japan" id="container-1a28c3650c" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1689197747_1119078549/container_218511885/container_1284986664/container_copy_11061_1726442676/image.casiocoreimg.png/1643597392442/img4-m.png" media="(min-width: 768px)" width="640" height="605">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1689197747_1119078549/container_218511885/container_1284986664/container_copy_11061_1726442676/image.casiocoreimg.png/1643597392442/img4-m.png" loading="lazy" alt="Japan" width="640" height="605">
			</picture>
		
	
	
	
</div>

    
</div>

    
</div>
<div id="container-1ac0db0831">
    
    <div id="container-2dc6224ebe">
<p data-cmp-data-layer="{&quot;text-561847c7fd&quot;:{&quot;@type&quot;:&quot;casio/components/content/text&quot;,&quot;repo:modifyDate&quot;:&quot;2022-01-31T02:49:52Z&quot;,&quot;xdm:text&quot;:&quot;<h2 style=\&quot;text-align: center;\&quot;><b>ACCURACY</b></h2>\r\n&quot;}}" id="text-561847c7fd">
    <h2><b>ACCURACY</b></h2>

</p>

    

</div>
<div id="container-36f0462167">
    
    <div id="container-11e355e4a9">
    
    <div data-cmp-is="image" data-cmp-lazythreshold="0" data-cmp-src="/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1167474148/container_1799759122/container_904817021__1024084391/container/image.casiocoreimg{.width}.jpeg/1643597392740/thumb.jpeg" data-asset="/content/dam/casio/global/watch/g_shock/technology/mobilelink/thumb.jpg" data-title="Smartphone Link" id="image-8cba0cbeb5" itemscope="" itemtype="http://schema.org/ImageObject">
	<a href="https://gshock.casio.com/intl/technology/mobilelink/" target="_self" data-cmp-hook-image="link">
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1167474148/container_1799759122/container_904817021__1024084391/container/image.casiocoreimg.jpeg/1643597392740/thumb.jpeg" media="(min-width: 768px)" width="350" height="700">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1167474148/container_1799759122/container_904817021__1024084391/container/image.casiocoreimg.jpeg/1643597392740/thumb.jpeg" loading="lazy" alt="" width="350" height="700">
			</picture>
		
	</a>
	
	
</div>
<div id="container-b72b9ea29e">
<p data-cmp-data-layer="{&quot;text-da5acf3052&quot;:{&quot;@type&quot;:&quot;casio/components/content/text&quot;,&quot;repo:modifyDate&quot;:&quot;2022-01-31T02:49:52Z&quot;,&quot;xdm:text&quot;:&quot;<h3 style=\&quot;text-align: center;\&quot;><b>Smartphone Link</b></h3>\r\n&quot;}}" id="text-da5acf3052">
    <h3><b>Smartphone Link</b></h3>

</p>

    

</div>

    
</div>
<div id="container-913d29ea66">
    
    <div data-cmp-is="image" data-cmp-lazythreshold="0" data-cmp-src="/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1167474148/container_1799759122/container_904817021__1024084391/container_copy/image.casiocoreimg{.width}.jpeg/1643597392847/thumb.jpeg" data-asset="/content/dam/casio/global/watch/g_shock/technology/gps/thumb.jpg" data-title="GPS time-calibration signal reception" id="image-3140b8f139" itemscope="" itemtype="http://schema.org/ImageObject">
	<a href="https://gshock.casio.com/intl/technology/gps/" target="_self" data-cmp-hook-image="link">
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1167474148/container_1799759122/container_904817021__1024084391/container_copy/image.casiocoreimg.jpeg/1643597392847/thumb.jpeg" media="(min-width: 768px)" width="350" height="700">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1167474148/container_1799759122/container_904817021__1024084391/container_copy/image.casiocoreimg.jpeg/1643597392847/thumb.jpeg" loading="lazy" alt="" width="350" height="700">
			</picture>
		
	</a>
	
	
</div>
<div id="container-b890d6da7a">
<p data-cmp-data-layer="{&quot;text-fc56390c80&quot;:{&quot;@type&quot;:&quot;casio/components/content/text&quot;,&quot;repo:modifyDate&quot;:&quot;2022-01-31T02:49:52Z&quot;,&quot;xdm:text&quot;:&quot;<h3 style=\&quot;text-align: center;\&quot;><b>GPS time-calibration signal reception</b></h3>\r\n&quot;}}" id="text-fc56390c80">
    <h3><b>GPS time-calibration signal reception</b></h3>

</p>

    

</div>

    
</div>
<div id="container-243efed0fa">
    
    <div data-cmp-is="image" data-cmp-lazythreshold="0" data-cmp-src="/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1167474148/container_1799759122/container_904817021__1024084391/container_copy_293321345/image.casiocoreimg{.width}.jpeg/1643597392959/thumb.jpeg" data-asset="/content/dam/casio/global/watch/g_shock/technology/radio/thumb.jpg" data-title="Standard time radio wave reception (Multiband 6)" id="image-c3ae713eb1" itemscope="" itemtype="http://schema.org/ImageObject">
	<a href="https://gshock.casio.com/intl/technology/radio/" target="_self" data-cmp-hook-image="link">
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1167474148/container_1799759122/container_904817021__1024084391/container_copy_293321345/image.casiocoreimg.jpeg/1643597392959/thumb.jpeg" media="(min-width: 768px)" width="350" height="700">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1167474148/container_1799759122/container_904817021__1024084391/container_copy_293321345/image.casiocoreimg.jpeg/1643597392959/thumb.jpeg" loading="lazy" alt="" width="350" height="700">
			</picture>
		
	</a>
	
	
</div>
<div id="container-c3488ce950">
<p data-cmp-data-layer="{&quot;text-ef4132dd96&quot;:{&quot;@type&quot;:&quot;casio/components/content/text&quot;,&quot;repo:modifyDate&quot;:&quot;2022-01-31T02:49:52Z&quot;,&quot;xdm:text&quot;:&quot;<h3 style=\&quot;text-align: center;\&quot;><b>Standard time radio wave reception<br>\r\n(Multiband 6)</b></h3>\r\n&quot;}}" id="text-ef4132dd96">
    <h3><b>Standard time radio wave reception<br>
(Multiband 6)</b></h3>

</p>

    

</div>

    
</div>
<div id="container-02f69e8da6">
    
    <div data-cmp-is="image" data-cmp-lazythreshold="0" data-cmp-src="/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1167474148/container_1799759122/container_904817021__1024084391/container_copy_439056847/image.casiocoreimg{.width}.jpeg/1643597393068/thumb.jpeg" data-asset="/content/dam/casio/global/watch/g_shock/technology/solar/thumb.jpg" data-title="Solar-powered (Tough Solar)" id="image-845ab6cda5" itemscope="" itemtype="http://schema.org/ImageObject">
	<a href="https://gshock.casio.com/intl/technology/solar/" target="_self" data-cmp-hook-image="link">
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1167474148/container_1799759122/container_904817021__1024084391/container_copy_439056847/image.casiocoreimg.jpeg/1643597393068/thumb.jpeg" media="(min-width: 768px)" width="350" height="700">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1167474148/container_1799759122/container_904817021__1024084391/container_copy_439056847/image.casiocoreimg.jpeg/1643597393068/thumb.jpeg" loading="lazy" alt="" width="350" height="700">
			</picture>
		
	</a>
	
	
</div>
<div id="container-504a4c9861">
<p data-cmp-data-layer="{&quot;text-2fc406affd&quot;:{&quot;@type&quot;:&quot;casio/components/content/text&quot;,&quot;repo:modifyDate&quot;:&quot;2022-01-31T02:49:53Z&quot;,&quot;xdm:text&quot;:&quot;<h3 style=\&quot;text-align: center;\&quot;><b>Solar-powered<br>\r\n(Tough Solar)</b></h3>\r\n&quot;}}" id="text-2fc406affd">
    <h3><b>Solar-powered<br>
(Tough Solar)</b></h3>

</p>

    

</div>

    
</div>
<div id="container-5fa8b704cf">
    
    <div data-cmp-is="image" data-cmp-lazythreshold="0" data-cmp-src="/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1167474148/container_1799759122/container_904817021__1024084391/container_copy_1675750789/image.casiocoreimg{.width}.jpeg/1643597393207/thumb.jpeg" data-asset="/content/dam/casio/global/watch/g_shock/technology/3way/thumb.jpg" data-title="Bluetooth®-installed GPS radio-controlled, solar-powered timekeeping" id="image-ab85928256" itemscope="" itemtype="http://schema.org/ImageObject">
	<a href="https://gshock.casio.com/intl/technology/3way/" target="_self" data-cmp-hook-image="link">
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1167474148/container_1799759122/container_904817021__1024084391/container_copy_1675750789/image.casiocoreimg.jpeg/1643597393207/thumb.jpeg" media="(min-width: 768px)" width="350" height="700">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1167474148/container_1799759122/container_904817021__1024084391/container_copy_1675750789/image.casiocoreimg.jpeg/1643597393207/thumb.jpeg" loading="lazy" alt="" width="350" height="700">
			</picture>
		
	</a>
	
	
</div>
<div id="container-6a49cabf69">
<p data-cmp-data-layer="{&quot;text-aae4808d89&quot;:{&quot;@type&quot;:&quot;casio/components/content/text&quot;,&quot;repo:modifyDate&quot;:&quot;2022-01-31T02:49:53Z&quot;,&quot;xdm:text&quot;:&quot;<h3 style=\&quot;text-align: center;\&quot;><b>Bluetooth®-installed<br>\r\n GPS radio-controlled, solar-powered timekeeping</b></h3>\r\n&quot;}}" id="text-aae4808d89">
    <h3><b>Bluetooth®-installed<br>
 GPS radio-controlled, solar-powered timekeeping</b></h3>

</p>

    

</div>

    
</div>
<div id="container-fcc7a5aef9">
    
    <div data-cmp-is="image" data-cmp-lazythreshold="0" data-cmp-src="/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1167474148/container_1799759122/container_904817021__1024084391/container_copy_357371127/image.casiocoreimg{.width}.jpeg/1643597393314/thumb.jpeg" data-asset="/content/dam/casio/global/watch/g_shock/technology/ble-radio-solar/thumb.jpg" data-title="Bluetooth®-installed radio-controlled,solar-powered timekeeping" id="image-0ed2888945" itemscope="" itemtype="http://schema.org/ImageObject">
	<a href="https://gshock.casio.com/intl/technology/ble-radio-solar/" target="_self" data-cmp-hook-image="link">
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1167474148/container_1799759122/container_904817021__1024084391/container_copy_357371127/image.casiocoreimg.jpeg/1643597393314/thumb.jpeg" media="(min-width: 768px)" width="350" height="700">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1167474148/container_1799759122/container_904817021__1024084391/container_copy_357371127/image.casiocoreimg.jpeg/1643597393314/thumb.jpeg" loading="lazy" alt="" width="350" height="700">
			</picture>
		
	</a>
	
	
</div>
<div id="container-f57d5f5ad2">
<p data-cmp-data-layer="{&quot;text-f073eb2dfd&quot;:{&quot;@type&quot;:&quot;casio/components/content/text&quot;,&quot;repo:modifyDate&quot;:&quot;2022-01-31T02:49:53Z&quot;,&quot;xdm:text&quot;:&quot;<h3 style=\&quot;text-align: center;\&quot;><b>Bluetooth®-installed radio-controlled,<br>\r\n solar-powered timekeeping</b></h3>\r\n&quot;}}" id="text-f073eb2dfd">
    <h3><b>Bluetooth®-installed radio-controlled,<br>
 solar-powered timekeeping</b></h3>

</p>

    

</div>

    
</div>
<div id="container-e44a367787">
    
    <div data-cmp-is="image" data-cmp-lazythreshold="0" data-cmp-src="/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1167474148/container_1799759122/container_904817021__1024084391/container_copy_61112138/image.casiocoreimg{.width}.jpeg/1643597393434/thumb.jpeg" data-asset="/content/dam/casio/global/watch/g_shock/technology/gps-radio-solar/thumb.jpg" data-title="GPS hybrid radio-controlled,solar-powered timekeeping" id="image-00bf8f32d4" itemscope="" itemtype="http://schema.org/ImageObject">
	<a href="https://gshock.casio.com/intl/technology/gps-radio-solar/" target="_self" data-cmp-hook-image="link">
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1167474148/container_1799759122/container_904817021__1024084391/container_copy_61112138/image.casiocoreimg.jpeg/1643597393434/thumb.jpeg" media="(min-width: 768px)" width="350" height="700">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1167474148/container_1799759122/container_904817021__1024084391/container_copy_61112138/image.casiocoreimg.jpeg/1643597393434/thumb.jpeg" loading="lazy" alt="" width="350" height="700">
			</picture>
		
	</a>
	
	
</div>
<div id="container-84119009fa">
<p data-cmp-data-layer="{&quot;text-fe997e5bf4&quot;:{&quot;@type&quot;:&quot;casio/components/content/text&quot;,&quot;repo:modifyDate&quot;:&quot;2022-01-31T02:49:53Z&quot;,&quot;xdm:text&quot;:&quot;<h3 style=\&quot;text-align: center;\&quot;><b>GPS hybrid radio-controlled,<br>\r\nsolar-powered timekeeping</b></h3>\r\n&quot;}}" id="text-fe997e5bf4">
    <h3><b>GPS hybrid radio-controlled,<br>
solar-powered timekeeping</b></h3>

</p>

    

</div>

    
</div>
<div id="container-469861c476">
    
    <div data-cmp-is="image" data-cmp-lazythreshold="0" data-cmp-src="/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1167474148/container_1799759122/container_904817021__1024084391/container_copy_1564643227/image.casiocoreimg{.width}.jpeg/1643597393567/thumb.jpeg" data-asset="/content/dam/casio/global/watch/g_shock/technology/ble-solar/thumb.jpg" data-title="Bluetooth® + Tough Solar" id="image-ab15c9a07f" itemscope="" itemtype="http://schema.org/ImageObject">
	<a href="https://gshock.casio.com/intl/technology/ble-solar/" target="_self" data-cmp-hook-image="link">
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1167474148/container_1799759122/container_904817021__1024084391/container_copy_1564643227/image.casiocoreimg.jpeg/1643597393567/thumb.jpeg" media="(min-width: 768px)" width="350" height="700">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://gshock.casio.com/content/casio/locales/intl/en/brands/gshock/technology/radio/_jcr_content/root/responsivegrid/container_1167474148/container_1799759122/container_904817021__1024084391/container_copy_1564643227/image.casiocoreimg.jpeg/1643597393567/thumb.jpeg" loading="lazy" alt="" width="350" height="700">
			</picture>
		
	</a>
	
	
</div>
<div id="container-871710c024">
<p data-cmp-data-layer="{&quot;text-f9d0fabfd8&quot;:{&quot;@type&quot;:&quot;casio/components/content/text&quot;,&quot;repo:modifyDate&quot;:&quot;2022-01-31T02:49:53Z&quot;,&quot;xdm:text&quot;:&quot;<h3 style=\&quot;text-align: center;\&quot;><b>Bluetooth®<br>\r\n+ Tough Solar</b></h3>\r\n&quot;}}" id="text-f9d0fabfd8">
    <h3><b>Bluetooth®<br>
+ Tough Solar</b></h3>

</p>

    

</div>

    
</div>

    
</div>

    
</div>

    
</main>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Luck be a Landlord is now banned in 13 countries on the Google Play Store (112 pts)]]></title>
            <link>https://blog.trampolinetales.com/luck-be-a-landlord-is-now-banned-in-13-countries-on-the-google-play-store/</link>
            <guid>37152133</guid>
            <pubDate>Wed, 16 Aug 2023 19:12:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.trampolinetales.com/luck-be-a-landlord-is-now-banned-in-13-countries-on-the-google-play-store/">https://blog.trampolinetales.com/luck-be-a-landlord-is-now-banned-in-13-countries-on-the-google-play-store/</a>, See on <a href="https://news.ycombinator.com/item?id=37152133">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
<main>

        <article>

    

    <div>
        <p>I'm sorry if the following post comes off as a bit angry. I'm writing this off the cuff and am very aggravated by the situation.</p><p>Today I received an email from Google Play Support stating that Luck be a Landlord has been geo-blocked in the following countries: United Arab Emirates, Algeria, Iran, Jordan, South Korea, Libya, Oman, Palestine, Qatar, Saudi Arabia, Syria, Tunisia, and Yemen.</p><p>According to Google, the app "contains content that doesn't comply with the Gambling policy."</p><p>It should go without saying that I 100% disagree with this decision. Luck be a Landlord does not violate any gambling policy that Google has in their terms of service.</p><p>The e-mail states that "Apps that simulate gambling, or games of chance or skill that are conducive to gambling are prohibited in the above locales."</p><p>By that logic, you could argue any game with an element of chance or luck violates Google's Gambling policy.</p><p><a href="https://play.google.com/store/apps/details?id=com.halfbrick.jetpackjoyride&amp;ref=blog.trampolinetales.com">Jetpack Joyride</a>, a game with a literal slot-machine mechanic, is rated E10+ and isn't geo-blocked. <a href="https://play.google.com/store/apps/details?id=com.terrycavanaghgames.diceydungeons&amp;ref=blog.trampolinetales.com">Dicey Dungeons</a>, a game with themes of luck and rolling dice, isn't geo-blocked. A <a href="https://play.google.com/store/apps/details?id=com.sneakypanda.spincraftclassic&amp;ref=blog.trampolinetales.com">literal clone of my game</a>, which raised <a href="https://venturebeat.com/games/sneaky-panda-raises-6m-to-launch-new-kind-of-mobile-game/?ref=blog.trampolinetales.com">$6,000,000 in venture capital</a>, is somehow rated "E for Everyone" and isn't geo-blocked, despite <strong>literally having a battle pass and random-chance micro-transactions</strong>. Don't even get me started on how loot boxes are allowed (and encouraged) on these platforms!</p><p>It should go without saying that I don't think these other apps should be geo-blocked. I'm saying it's very easy to see that my game is getting unfair treatment.</p><p>I have brought this up to Google and they were dismissive of my reasoning, refusing to do anything.</p><p>I am exploring options of how to get this fixed but I am extremely upset that Google has made this ridiculous decision and that players in the aforementioned countries will be unable to download the game on the Google Play Store.</p><p>My apologies for those inconvenienced by this who were interested in playing Luck be a Landlord. The <a href="https://store.steampowered.com/app/1404850/Luck_be_a_Landlord/?ref=blog.trampolinetales.com">Steam version</a> and <a href="https://apps.apple.com/us/app/luck-be-a-landlord/id6450724928?ref=blog.trampolinetales.com">iOS version</a> of the game remain up without any issue at the time of me writing this.</p><p>-Dan</p>
    </div>

    

</article>
            

        
</main>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New York City bans TikTok for government employees (203 pts)]]></title>
            <link>https://www.engadget.com/new-york-city-bans-tiktok-for-government-employees-174806575.html</link>
            <guid>37151308</guid>
            <pubDate>Wed, 16 Aug 2023 18:16:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.engadget.com/new-york-city-bans-tiktok-for-government-employees-174806575.html">https://www.engadget.com/new-york-city-bans-tiktok-for-government-employees-174806575.html</a>, See on <a href="https://news.ycombinator.com/item?id=37151308">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>New York City will ban TikTok from government devices, <a data-i13n="cpos:1;pos:1" href="https://www.theverge.com/2023/8/16/23834579/nyc-tiktok-ban-new-york-china-surveillance-spy" rel="nofollow noopener" target="_blank" data-ylk="elm:context_link;cpos:1;pos:1;itc:0"><em>The Verge reported</em></a> on Wednesday. City agencies have 30 days to remove the ByteDance-owned app from their devices. Employees will not be allowed to download or use TikTok on their city-sanctioned tech effective immediately. This comes three years after New York state banned TikTok from government devices in 2020, <a data-i13n="cpos:2;pos:1" href="https://www.timesunion.com/state/article/n-y-quietly-banned-tiktok-government-devices-17886372.php" rel="nofollow noopener" target="_blank" data-ylk="elm:context_link;cpos:2;pos:1;itc:0">according to <em>Times-Union</em></a>.</p>
<p>NYC Cyber Command, a subset of the Office of Technology and Innovation, spurred the decision after reporting to the city that TikTok posed a security threat. "NYC Cyber Command regularly explores and advances proactive measures to keep New Yorkers' data safe," a City Hall spokesperson said. "As part of these ongoing efforts, NYC Cyber Command determined that the TikTok application posed a security threat to the city’s technical networks and directed its removal from city-owned devices.”</p>
<p>Other states and localities, <a data-i13n="cpos:3;pos:1" href="https://www.engadget.com/montanas-governor-signs-bill-banning-tiktok-225326086.html" data-ylk="elm:context_link;cpos:3;pos:1;itc:0">notably Montana</a>, have made waves banning TikTok more generally across the jurisdiction. But on a wider scale, most legislators have taken an approach banning the app for government employees, <a data-i13n="cpos:4;pos:1" href="https://www.engadget.com/tiktok-us-government-ban-devices-omnibus-bill-funding-nasa-234803320.html" data-ylk="elm:context_link;cpos:4;pos:1;itc:0">including the federal government</a>. Thirty-three states across parties lines <a data-i13n="cpos:5;pos:1" href="https://www.cnn.com/2023/01/16/tech/tiktok-state-restrictions/index.html" rel="nofollow noopener" target="_blank" data-ylk="elm:context_link;cpos:5;pos:1;itc:0">now have restrictions on the use of TikTok</a> on government-owned tech.</p>
<p>As legislation continues to resurface considering a total ban on TikTok and other apps affiliated with the Chinese government, ByteDance <a data-i13n="cpos:6;pos:1" href="https://www.engadget.com/can-tiktok-convince-the-us-its-not-a-national-security-threat-173030115.html" data-ylk="elm:context_link;cpos:6;pos:1;itc:0">fights to proven that its not a threat to national security</a>. TikTok CEO Shou Chew <a data-i13n="cpos:7;pos:1" href="https://www.engadget.com/heres-what-tiktoks-ceo-told-congress-about-the-apps-ties-to-china-and-teen-safety-201657076.html" data-ylk="elm:context_link;cpos:7;pos:1;itc:0">even testified in front of Congress</a> reiterating that "ByteDance is not an agent of China."</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Windows feature that resets system clocks based on random data is wreaking havoc (248 pts)]]></title>
            <link>https://arstechnica.com/security/2023/08/windows-feature-that-resets-system-clocks-based-on-random-data-is-wreaking-havoc/</link>
            <guid>37151220</guid>
            <pubDate>Wed, 16 Aug 2023 18:11:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/security/2023/08/windows-feature-that-resets-system-clocks-based-on-random-data-is-wreaking-havoc/">https://arstechnica.com/security/2023/08/windows-feature-that-resets-system-clocks-based-on-random-data-is-wreaking-havoc/</a>, See on <a href="https://news.ycombinator.com/item?id=37151220">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/08/broken-clock-800x680.jpg" alt="Windows feature that resets system clocks based on random data is wreaking havoc">
      <figcaption></figcaption>  </figure>

  




<!-- cache hit 12:single/related:ead7c219d0326d0abc616e5bfc87896a --><!-- empty -->
<p>A few months ago, an engineer in a data center in Norway encountered some perplexing errors that caused a Windows server to suddenly reset its system clock to 55 days in the future. The engineer relied on the server to maintain a routing table that tracked cell phone numbers in real time as they were being moved from one carrier to the other. A jump of eight weeks had dire consequences because it caused numbers that had yet to be transferred to be listed as having already been moved and numbers that had already been transferred to be reported as pending.</p>
<p>“With these updated routing tables, a lot of people were unable to make calls, as we didn't have a correct state!” the engineer, who asked to be identified only by his first name, Simen, wrote in an email. “We would route incoming and outgoing calls to the wrong operators! This meant, e.g., children could not reach their parents and vice versa.”</p>
<h2>A show-stopping issue</h2>
<p>Simen had experienced a similar error last August when a machine running Windows Server 2019 reset its clock to January 2023 and then changed it back a short time later. Troubleshooting the cause of that mysterious reset was hampered because the engineers didn’t discover it until after event logs had been purged. The newer jump of 55 days, on a machine running Windows Server 2016, prompted him to once again search for a cause, and this time, he found it.</p>
<p>The culprit was a little-known feature in Windows known as Secure Time Seeding. Microsoft <a href="https://learn.microsoft.com/en-us/archive/blogs/w32time/secure-time-seeding-improving-time-keeping-in-windows">introduced</a> the time-keeping feature in 2016 as a way to ensure that system clocks were accurate. Windows systems with clocks set to the wrong time can cause disastrous errors when they can’t properly parse time stamps in digital certificates or they execute jobs too early, too late, or out of the prescribed order. Secure Time Seeding, Microsoft said, was a hedge against failures in the battery-powered on-board devices designed to keep accurate time even when the machine is powered down.</p>                                            
                                                        
<p>“You may ask—why doesn’t the device ask the nearest time server for the current time over the network?” Microsoft engineers wrote. “Since the device is not in a state to communicate securely over the network, it cannot obtain time securely over the network as well, unless you choose to ignore network security or at least punch some holes into it by making exceptions.”</p>
<p>To avoid making security exceptions, Secure Time Seeding sets the time based on data inside an SSL handshake the machine makes with remote servers. These handshakes occur whenever two devices connect using the Secure Sockets Layer protocol, the mechanism that provides encrypted HTTPS sessions (it is also known as <a href="https://en.wikipedia.org/wiki/Transport_Layer_Security">Transport Layer Security</a>). Because Secure Time Seeding (abbreviated as STS for the rest of this article) used SSL certificates Windows already stored locally, it could ensure that the machine was securely connected to the remote server. The mechanism, Microsoft engineers wrote, “helped us to break the cyclical dependency between client system time and security keys, including SSL certificates.”</p>
<p>Simen wasn’t the only person encountering wild and spontaneous fluctuations in Windows system clocks used in mission-critical environments. Sometime last year, a separate engineer named Ken began seeing similar time drifts. They were limited to two or three servers and occurred every few months. Sometimes, the clock times jumped by a matter of weeks. Other times, the times changed to as late as the year 2159.</p>
<p>“It has exponentially grown to be more and more servers that are affected by this,” Ken wrote in an email. “In total, we have around 20 servers (VMs) that have experienced this, out of 5,000. So it's not a huge amount, but it is considerable, especially considering the damage this does. It usually happens to database servers. When a database server jumps in time, it wreaks havoc, and the backup won’t run, either, as long as the server has such a huge offset in time. For our customers, this is crucial.”</p>
<p>Simen and Ken, who both asked to be identified only by their first names because they weren’t authorized by their employers to speak on the record, soon found that engineers and administrators had been reporting the same time resets since 2016.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI acquires Global Illumination (112 pts)]]></title>
            <link>https://openai.com/blog/openai-acquires-global-illumination</link>
            <guid>37150098</guid>
            <pubDate>Wed, 16 Aug 2023 17:06:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/blog/openai-acquires-global-illumination">https://openai.com/blog/openai-acquires-global-illumination</a>, See on <a href="https://news.ycombinator.com/item?id=37150098">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><p>OpenAI has acquired the team at <a href="https://ill.inc/" rel="noopener noreferrer" target="_blank">Global Illumination</a>, a company founded by Thomas Dimson, Taylor Gordon, and Joey Flynn. The entire team has joined OpenAI to work on our core products including ChatGPT. Global Illumination is a company that has been leveraging AI to build creative tools, infrastructure, and digital experiences. The team previously designed and built products early on at Instagram and Facebook and have also made significant contributions at YouTube, Google, Pixar, Riot Games, and other notable companies. We’re very excited for the impact they’ll have here at OpenAI.<br></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Mathematics of Training LLMs (176 pts)]]></title>
            <link>https://www.latent.space/p/transformers-math#details</link>
            <guid>37150000</guid>
            <pubDate>Wed, 16 Aug 2023 16:59:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.latent.space/p/transformers-math#details">https://www.latent.space/p/transformers-math#details</a>, See on <a href="https://news.ycombinator.com/item?id=37150000">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><em><span>Invites are going out for </span><a href="https://ai.engineer/" rel="">AI Engineer Summit</a><span>! In the meantime, we have just announced our first </span><a href="https://partiful.com/e/jLALhobyikO5xq2JDDnm" rel="">Actually Open AI event</a><span> with Brev.dev and Langchain, Aug 26 in our SF HQ (we’ll record talks for those remote). See you soon (and join the Discord)!</span></em></p><p><em><span>Special thanks to </span><a href="https://twitter.com/nearcyan/status/1662937711156625408?s=20" rel="">@nearcyan</a><span> for helping us arrange this with the Eleuther team.</span></em></p><p><span>As startups and even VCs </span><a href="https://www.latent.space/p/ai-engineer" rel="">hoard GPUs</a><span> to attract talent, </span><strong>the one thing more valuable than GPUs is knowing how to use them</strong><span> (aka, </span><a href="https://horace.io/brrr_intro.html" rel="">make </a><em><a href="https://horace.io/brrr_intro.html" rel="">GPUs go brrrr</a><span>).</span></em></p><p><span>There is an incredible amount of </span><a href="https://commoncog.com/the-tacit-knowledge-series/" rel="">tacit knowledge</a><span> in the NLP community around training</span></p><p><span>, and until Eleuther.ai came along you pretty much had to work at Google or Meta to gain that knowledge. This makes it hard for non-insiders to even do simple estimations around costing out projects - it is well known how to trade $ for GPU hours</span></p><p><span>, but trading “$ for size of model” or “$ for quality of model” is less known and more valuable and full of opaque “it depends”. This is why </span><strong>rules of thumb for training</strong><span> are incredibly useful, because they cut through the noise and give you the simple 20% of knowledge that determines 80% of the outcome derived from hard earned experience.</span></p><p><span>Today’s guest, Quentin Anthony from EleutherAI, is one of the top researchers in </span><strong>high-performance deep learning</strong><span>. He’s one of the co-authors of </span><a href="https://blog.eleuther.ai/transformer-math/" rel="">Transformers Math 101</a><span>, which was one of the clearest articulations of training rules of thumb. We can think of no better way to dive into training math than to have Quentin run us through a masterclass on model weights, optimizer states, gradients, activations, and how they all impact memory requirements.</span></p><p>The core equation you will need to know is the following:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef9fba18-bb49-462c-b411-e0861730c88d_296x76.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef9fba18-bb49-462c-b411-e0861730c88d_296x76.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef9fba18-bb49-462c-b411-e0861730c88d_296x76.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef9fba18-bb49-462c-b411-e0861730c88d_296x76.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef9fba18-bb49-462c-b411-e0861730c88d_296x76.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef9fba18-bb49-462c-b411-e0861730c88d_296x76.png" width="248" height="63.67567567567568" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ef9fba18-bb49-462c-b411-e0861730c88d_296x76.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:76,&quot;width&quot;:296,&quot;resizeWidth&quot;:248,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef9fba18-bb49-462c-b411-e0861730c88d_296x76.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef9fba18-bb49-462c-b411-e0861730c88d_296x76.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef9fba18-bb49-462c-b411-e0861730c88d_296x76.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef9fba18-bb49-462c-b411-e0861730c88d_296x76.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>Where </span><em><strong>C</strong></em><span> is the compute requirements to train a model, </span><em><strong>P</strong></em><span> is the number of parameters, and </span><em><strong>D</strong></em><span> is the size of the training dataset in tokens. This is also equal to </span><em><strong>τ</strong></em><span>, the throughput of your machine measured in FLOPs (Actual FLOPs/GPU * # of GPUs), multiplied by </span><em><strong>T</strong></em><span>, the amount of time spent training the model.</span></p><p>Taking Chinchilla scaling at face value, you can simplify this equation to be `C = 120(P^2)`.These laws are only true when 1000 GPUs for 1 hour costs the same as 1 GPU for 1000 hours, so it’s not always that easy to make these assumptions especially when it comes to communication overhead.  </p><p>There’s a lot more math to dive into here between training and inference, which you can listen to in the episode or read in the articles. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75b03a3d-8e72-4020-b686-f145e1e6076f_2000x997.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75b03a3d-8e72-4020-b686-f145e1e6076f_2000x997.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75b03a3d-8e72-4020-b686-f145e1e6076f_2000x997.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75b03a3d-8e72-4020-b686-f145e1e6076f_2000x997.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75b03a3d-8e72-4020-b686-f145e1e6076f_2000x997.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75b03a3d-8e72-4020-b686-f145e1e6076f_2000x997.png" width="1456" height="726" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/75b03a3d-8e72-4020-b686-f145e1e6076f_2000x997.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:726,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;ZeRO illustration&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="ZeRO illustration" title="ZeRO illustration" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75b03a3d-8e72-4020-b686-f145e1e6076f_2000x997.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75b03a3d-8e72-4020-b686-f145e1e6076f_2000x997.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75b03a3d-8e72-4020-b686-f145e1e6076f_2000x997.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75b03a3d-8e72-4020-b686-f145e1e6076f_2000x997.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The other interesting concept we covered is distributed training and strategies such as ZeRO and 3D parallelism. As these models have scaled, it’s become impossible to fit everything in a single GPU for training and inference. We leave these advanced concepts to the end, but there’s a lot of innovation happening around sharding of params, gradients, and optimizer states that you must know is happening in modern LLM training. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b7c82ff-b34f-45d9-8035-26316b6a9af9_960x49.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b7c82ff-b34f-45d9-8035-26316b6a9af9_960x49.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b7c82ff-b34f-45d9-8035-26316b6a9af9_960x49.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b7c82ff-b34f-45d9-8035-26316b6a9af9_960x49.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b7c82ff-b34f-45d9-8035-26316b6a9af9_960x49.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b7c82ff-b34f-45d9-8035-26316b6a9af9_960x49.png" width="960" height="49" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2b7c82ff-b34f-45d9-8035-26316b6a9af9_960x49.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:49,&quot;width&quot;:960,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;ZeRO legend&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="ZeRO legend" title="ZeRO legend" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b7c82ff-b34f-45d9-8035-26316b6a9af9_960x49.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b7c82ff-b34f-45d9-8035-26316b6a9af9_960x49.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b7c82ff-b34f-45d9-8035-26316b6a9af9_960x49.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b7c82ff-b34f-45d9-8035-26316b6a9af9_960x49.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c858394-83c8-44ea-842c-38bd6f1a848a_1209x699.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c858394-83c8-44ea-842c-38bd6f1a848a_1209x699.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c858394-83c8-44ea-842c-38bd6f1a848a_1209x699.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c858394-83c8-44ea-842c-38bd6f1a848a_1209x699.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c858394-83c8-44ea-842c-38bd6f1a848a_1209x699.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c858394-83c8-44ea-842c-38bd6f1a848a_1209x699.png" width="1209" height="699" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4c858394-83c8-44ea-842c-38bd6f1a848a_1209x699.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:699,&quot;width&quot;:1209,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;3D parallelism&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="3D parallelism" title="3D parallelism" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c858394-83c8-44ea-842c-38bd6f1a848a_1209x699.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c858394-83c8-44ea-842c-38bd6f1a848a_1209x699.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c858394-83c8-44ea-842c-38bd6f1a848a_1209x699.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c858394-83c8-44ea-842c-38bd6f1a848a_1209x699.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>If you have questions, you can join the </span><a href="https://discord.gg/xyUJzrKV" rel="">Eleuther AI Discord</a><span> or follow </span><a href="https://twitter.com/QuentinAnthon15" rel="">Quentin on Twitter</a><span>. </span></p><ul><li><p><strong><a href="https://blog.eleuther.ai/transformer-math/" rel="">Transformers Math 101 Article</a></strong></p></li><li><p><a href="https://www.eleuther.ai/" rel="">Eleuther.ai</a></p></li><li><p><a href="https://huggingface.co/EleutherAI/gpt-neox-20b" rel="">GPT-NeoX 20B</a></p></li><li><p><a href="https://huggingface.co/docs/transformers/model_doc/bloom" rel="">BLOOM</a></p></li><li><p><a href="https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/" rel="">Turing NLG</a></p></li><li><p><a href="https://mosaicml.com/" rel="">Mosaic</a></p></li><li><p><a href="https://www.ornl.gov/news/frontier-supercomputer-debuts-worlds-fastest-breaking-exascale-barrier" rel="">Oak Ridge &amp; Frontier Supercomputer</a></p></li><li><p><a href="https://www.olcf.ornl.gov/summit/" rel="">Summit Supercomputer </a></p></li><li><p><a href="https://www.llnl.gov/" rel="">Lawrence Livermore Lab</a></p></li><li><p><a href="https://arxiv.org/abs/2305.13048" rel="">RWKV</a></p></li><li><p><a href="https://www.latent.space/p/flashattention#details" rel="">Flash Attention </a></p></li><li><p><a href="https://twitter.com/StasBekman" rel="">Stas Bekman</a></p></li></ul><ul><li><p>[00:00:00] Quentin's background and work at Eleuther.ai</p></li><li><p>[00:03:14] Motivation behind writing the Transformers Math 101 article</p></li><li><p>[00:05:58] Key equation for calculating compute requirements (tau x T = 6 x P x D)</p></li><li><p>[00:10:00] Difference between theoretical and actual FLOPs</p></li><li><p>[00:12:42] Applying the equation to estimate compute for GPT-3 training</p></li><li><p>[00:14:08] Expecting 115+ teraflops/sec per A100 GPU as a baseline</p></li><li><p>[00:15:10] Tradeoffs between Nvidia and AMD GPUs for training</p></li><li><p>[00:18:50] Model precision (FP32, FP16, BF16 etc.) and impact on memory</p></li><li><p>[00:22:00] Benefits of model quantization even with unlimited memory</p></li><li><p>[00:23:44] KV cache memory overhead during inference</p></li><li><p>[00:26:08] How optimizer memory usage is calculated</p></li><li><p>[00:32:03] Components of total training memory (model, optimizer, gradients, activations)</p></li><li><p>[00:33:47] Activation recomputation to reduce memory overhead</p></li><li><p>[00:38:25] Sharded optimizers like ZeRO to distribute across GPUs</p></li><li><p>[00:40:23] Communication operations like scatter and gather in ZeRO</p></li><li><p>[00:41:33] Advanced 3D parallelism techniques (data, tensor, pipeline)</p></li><li><p>[00:43:55] Combining 3D parallelism and sharded optimizers</p></li><li><p>[00:45:43] Challenges with heterogeneous clusters for distribution</p></li><li><p>[00:47:58] Lightning Round</p></li></ul><p><strong>Alessio</strong><span>: Hey everyone, welcome to the Latent Space podcast. This is Alessio, partner and CTO in Residence at </span><a href="https://decibel.vc/" rel="">Decibel Partners</a><span>, and I'm joined by my co-host Swyx, writer and editor of Latent Space. [00:00:20]</span></p><p><strong>Swyx</strong><span>: Hey, today we have a very special guest, Quentin Anthony from Eleuther.ai. The context for this episode is that we've been looking to cover Transformers math for a long time. And then one day in April, there's this blog post that comes out that literally is called Transformers Math 101 from Eleuther. And this is one of the most authoritative posts that I've ever seen. And I think basically on this podcast, we're trying to give people an intuition around what are the rules of thumb that are important in thinking about AI and reasoning by AI. And I don't think there's anyone more credible than the people at Eleuther or the people training actual large language models, especially on limited resources. So welcome, Quentin. [00:00:59]</span></p><p><strong>Quentin</strong><span>: Thank you. A little bit about myself is that I'm a PhD student at Ohio State University, starting my fifth year now, almost done. I started with Eleuther during the GPT-NeoX20B model. So they were getting started training that, they were having some problems scaling it. As we'll talk about, I'm sure today a lot, is that communication costs and synchronization and how do you scale up a model to hundreds of GPUs and make sure that things progress quickly is really difficult. That was really similar to my PhD work. So I jumped in and helped them on the 20B, getting that running smoothly. And then ever since then, just as new systems challenges arise, and as they move to high performance computing systems and distributed systems, I just sort of kept finding myself falling into projects and helping out there. So I've been at Eleuther for a little bit now, head engineer there now, and then finishing up my PhD and then, well, who knows where I'll go next.  [00:01:48]</span></p><p><strong>Alessio</strong><span>: Awesome. What was the inspiration behind writing the article? Was it taking some of those learnings? Obviously Eleuther is one of the most open research places out there. Is it just part of the DNA there or any fun stories there? [00:02:00]</span></p><p><strong>Quentin</strong><span>: For the motivation for writing, you very frequently see in like the DL training space, like these Twitter posts by like, for example, like Stas Bekman at Hugging Face, you'll see like a Twitter post that's like, oh, we just found this magic number and everything is like 20% faster. He’s super excited, but doesn't really understand what's going on. And the same thing for us, we very frequently find that a lot of people understand the theory or maybe the fundamentals of why like AI training or inference works, but no one knows like the nitty gritty details of like, how do you get inference to actually run correctly on your machine split across two GPUs or something like that. So we sort of had all of these notes that we had accumulated and we're sort of sharing among engineers within Eleuther and we thought, well, this would really help a lot of other people. It's not really maybe appropriate for like a paper, but for something like a blog post or technical report, this would actually maybe squeeze a lot of performance out of people's hardware they're already running on. So I guess there are a lot of projects in Eleuther that we're sort of trying to share notes with people in a way that typical institutions don't. They sort of live within that institution and then you go to a different institution and they do something very similar, but without the lessons of the previous. And it's because everyone's trying to do their own special sauce with their own stack. Whereas Eleuther, we don't really have that constraint and we can just share everything to everybody. [00:03:14]</span></p><p><strong>Swyx</strong><span>: Yeah, this is a level of openness that basically very few people actually embrace. One, it's an extra effort to write things down, of course, but two, it is secret sauce and so that not many people do it. And therefore, oftentimes the only way to learn this stuff is to actually work in one of the large model labs. And so you guys are doing a lot. The only other instance where I can think of where people actually open sourced their process was Facebook's OPT. What else is similar, like sort of trade knowledge, but not formal research knowledge? [00:03:45]</span></p><p><strong>Quentin</strong><span>: I would say Bloom. So the Hugging Face Bloom project in big science and all of that, that was very open. I'd say it's the same caliber, if not more detailed than OPT. Other than that, I think there was like a doc from Microsoft on like their Turing NLG. Their paper is pretty relaxed in that it did talk about some of those challenges. Other than like OPT and Bloom and us, I can't think of any. It's a new thing. [00:04:10]</span></p><p><strong>Swyx</strong><span>: It matters that you are going for the sort of good enough rules of thumb, because I think a lot of people try to go for precision and being overly precise actually is not helpful. Right. Yes. [00:04:20]</span></p><p><strong>Quentin</strong><span>: You'll see some like statements in the blog posts that are just like, we think this is about 1.2 in our experience. And, you know, we don't go any further into detail and it would take maybe an extra month for us to chase down every single little piece of memory. But instead, like getting good enough is still helpful to people. [00:04:36]</span></p><p><strong>Alessio</strong><span>: Let's jump into it. The first part of the article, and we'll put this in the show notes so people will be following along with the post. So we don't need to read every single equation and every footnote for it. [00:04:46]</span></p><p><strong>Swyx</strong><span>: Okay. [00:04:46]</span></p><p><strong>Alessio</strong><span>: But the core equation here is that not the cost of compute, but the compute required to turn a transformer model is roughly equal to tau times T, where like T is the, where tau is the hardware setup throughput that you have. So number of GPUs times the actual flops per GPU. And then T is the time spent. I think people can visualize that pretty easily. It's basically like how many GPUs do you have and how much do you let them run for? And the things that come to it that people have read before in the Chinchilla paper in a way, and the OpenAI scaling law is that you can then equal this to 6PD, where P is the number of parameters in the model and D is the size of the, of the dataset in tokens. So talk a little bit about how people should think about the two. I think a lot of times the focus is on tokens parameter ratio in the training dataset and people don't think as much about the actual flops per GPU, which you're going to mention later in the blog post too, in terms of how much you can get out. So how should people think about this when they're building a model and where should they go to this equation as they're starting to think about training their own transformer-based [00:05:58]</span></p><p><strong>Swyx</strong><span>: model? [00:05:58]</span></p><p><strong>Quentin</strong><span>: You touched a little bit on the fact that people usually start with the dataset. So you have some dataset that you want to train a model on. And then from there, from the 6PD, you should see, okay, I should have about six tokens per parameter. So that determines my model size thereabouts for Chinchilla Optimal. So since then we've seen that need more something like 20 or more than that to get a good quality model. But the next question that should be on your mind in terms of a systems perspective is how long is it going to take for this model to train and what kind of budget should I expect? So let's say I want some cloud instance for some amount of time and each of them will have some price attached to it. So that's where the throughput comes in. So now that you have this model, this number of parameters, you should map that to a transformer architecture and you should benchmark what throughput you get on your software stack for that type of model. So now you have your flops per second on a single GPU. And then given whatever parallelism scheme, which I'm sure we'll get into, like data parallelism or tensor parallelism or whatever else, how is that flops number going to scale to whatever number of GPUs? And then from there, you're going to get a time. And if you have a time, you have a cost. Those are like the business answers that you'll be able to get using this formula. That's why we sort of split it into the T and the throughput terms so that you can solve for one of them, which is usually get throughput, need time, and from time you get cost. In a nutshell, that's the answer. [00:07:19]</span></p><p><strong>Alessio</strong><span>: One thing that I noticed, you mentioned some of these laws are only true when a thousand GPUs for one hour cost the same as one GPU for a thousand hours, given that we have a shortage of the biggest GPUs out there. Any thoughts there on how people should prioritize this? [00:07:36]</span></p><p><strong>Quentin</strong><span>: Yeah, so I would say you should find what the minimum number of GPUs is to just fit your model first. The memory bottleneck is your biggest problem if you have a sizable model. If it's a small model, nobody cares. But most models that people care about will need to be split across multiple GPUs. So find the minimum number of GPUs to just fit your one instance of your model and then calculate how long that's going to take. If it's a reasonable amount of time, then you're done. If it takes too long, then you need to start worrying about having multiple instances of that model. I always feel like you should go with the minimum number of GPUs because the more number of GPUs that you have, the more likely it is for things to break. So I would say just find out what time is reasonable for you and then fit the number of GPUs to that and no more. Because people get greedy and they say, if I have twice the GPUs, I can get this done in half the time. And then you end up taking three times the time because everything is breaking every day. And that's when I am up at midnight trying to fix your model that's broken. [00:08:34]</span></p><p><strong>Swyx</strong><span>: We had a previous guest which has invested a lot in their framework for training these things. Would there not be an equivalent open source framework you guys would have made that would help with scaling up GPUs linearly like that? Or is this an oversimplification?  [00:08:50]</span></p><p><strong>Quentin</strong><span>: Okay, yeah. So maybe I should step back. Both Mosaic and us have our own sort of software stack recipe that scales well, theoretically. But I'll get to that in a minute. Mosaic is all based off optimizer sharding. So it's based off ZeRO. So you basically perfectly split your model optimizer and your parameters and your gradients across all of the different GPUs. So your aggregate memory is number of parameters divided by number of GPUs. Same thing for optimizer and so on. Whereas we at Eleuther use a Megatron deep speed based library. And for that, it's a bit more complex. So the efficiency can be a little higher, but it's more prone to failure at the same [00:09:30]</span></p><p><strong>Swyx</strong><span>: time. [00:09:30]</span></p><p><strong>Quentin</strong><span>: So you kind of have to tune it. In both cases, getting back to like the practical case, you should be able to get linear speed up by adding more GPUs. The problem is that there are hardware failures. You tend to have problems with like maybe loss will overflow if you have too many GPUs or maybe one GPU will hang. You might have software issues. You might have synchronization issues. And that's why I'm saying practically that you should take the minimum number of GPUs that you have because those are the easier cases to debug. That make sense? [00:10:00]</span></p><p><strong>Swyx</strong><span>: Yeah. [00:10:00]</span></p><p><strong>Quentin</strong><span>: Any more detail on any specific point? [00:10:02]</span></p><p><strong>Swyx</strong><span>: Not particularly, just because we haven't actually had to debug those things. But I imagine basically there's a lot of return towards encoding these knowledge into software and not repeating it again. So it makes a ton of sense. I think Alessio had more questions before we move too far into high level, more questions on just the equation itself. I think we want to spend time on essentially, this is the central equation of figuring out compute requirements. Yeah. [00:10:25]</span></p><p><strong>Alessio</strong><span>: Another thing in it is that the computer is like the forward pass and like the backwards pass and forward is 2PD, backward is 4PD. Why it's to the ratio between the two? Can you explain that? Why is it two and four? [00:10:39]</span></p><p><strong>Quentin</strong><span>: Yeah. [00:10:40]</span></p><p><strong>Alessio</strong><span>: Why is it twice the amount? [00:10:42]</span></p><p><strong>Quentin</strong><span>: Oh, okay. Intuitively for forward pass, you're just moving, you're propagating forward the inputs through the layer. And then in the backward pass, you're doing something a little more complex than that. You're doing back propagation. And I don't think I can explain it intuitively enough to go into more detail on the exact [00:10:58]</span></p><p><strong>Swyx</strong><span>: numbers. Yeah. [00:10:58]</span></p><p><strong>Quentin</strong><span>: That's okay. [00:10:59]</span></p><p><strong>Swyx</strong><span>: I feel like you want to get out a whiteboard and start drawing like, you know. [00:11:02]</span></p><p><strong>Quentin</strong><span>: That's what I would normally do. [00:11:03]</span></p><p><strong>Swyx</strong><span>: Tangents and gradients. It's actually surprisingly low to do the back propagation. Honestly, that's one of the fundamental things I love about the math of deep learning so far that as I've explored it, which is, it's surprisingly efficient as compared to other, I guess, numerical methods you might be exposed to and, you know, college calculus. Yeah. [00:11:22]</span></p><p><strong>Alessio</strong><span>: And I think the other thing is that things sound simple, you know, when people go on Twitter and say, Oh, 20 is like the optimal ratio. And it's like, then it's like, well, why is that the number? And the answer is usually much, much harder, like what we're seeing right now. So I think it's a, it's a good reminder that the numbers are simple, like all the best and most popular, like math equations are like, so elegant. Obviously the proof behind that is, it's not that easy. That's always a good reminder. [00:11:52]</span></p><p><strong>Swyx</strong><span>: I want to put this equation to the test a little bit. We can do this from either GPT-3's perspective or GPT-NeoX, whatever you're more comfortable with. You have this distinction of actual flops versus theoretical flops. And a lot of times when people report the flops it took to train a model, like we just saw one in Lama 2 where the estimate is something that the amount of flops and that's, that's what we go with. So GPT-3 took a 3.14 times 10 to the power 23 flops. That is the theoretical flops. I want to get to a point where I can sort of work out if a number passes the smell test. And I wonder how to do that because I should be able to plug in this equation, right? I know that GPT-3 was trained on 300 billion tokens. I know the parameter size of 175. Is it, is it just like a 6 times 175 times 300? Like I haven't done the math, but what are the nuances here that you might want to call out? [00:12:42]</span></p><p><strong>Quentin</strong><span>: Theoretical flops is usually given from, you have a given set of hardware and this is what you expect your hardware to get. The problem is that in practice, full utilization, that's the key word, right? Because in practice, there are a lot of cases where like you're spending time waiting on data movement from like the GPU to CPU. Or for example, you might be waiting to synchronize across the different GPUs. So there's a lot of idle time basically that you're going to be spending during training. [00:13:05]</span></p><p><strong>Swyx</strong><span>: Smell tests. [00:13:06]</span></p><p><strong>Quentin</strong><span>: I don't know if I have a smell test myself, to be honest, like maybe I'll look at like what sort of flops, what you would expect on like an A100. There's sort of just an expected flops for a given GPU that everyone sort of knows what you should expect. So like for an A100, that number is somewhere between 100 and 180. T flops is what you would expect to see on an A100. For a V100, like an older GPU, it's something more like 40 to 30. So people sort of know, given the kernels that we're running for a deep learning, what sort of flops you expect. And then you sort of compare that to the theory, to the theoretical flops that people are reporting and see if that matches your expectations. [00:13:47]</span></p><p><strong>Swyx</strong><span>: Yeah. [00:13:47]</span></p><p><strong>Alessio</strong><span>: And in the article you mentioned for the A100, like if you're seeing below 115 teraflops a second, there's something wrong with your model or hardware. How did you get to 115? Is it just, you know, production observability and like you've seen over months and months and months that like that's the baseline or how do you come up with the numbers like that? Yeah. [00:14:08]</span></p><p><strong>Quentin</strong><span>: For a number like that, we basically, we compared a lot of different frameworks. So like I mentioned before, Mosaic has their own framework and we have our own framework. They all have their own flop counters too, right? And we saw across a bunch of different hardware configurations that if you tune things correctly, you should be getting above 115 in pretty much all cases. So like there are some cases where things are tuned poorly or your system is a little weird, but we've never been able to get a new system and not been able to get above [00:14:35]</span></p><p><strong>Swyx</strong><span>: 115. [00:14:35]</span></p><p><strong>Quentin</strong><span>: If something is below 115, you have something really wrong in your software. But that's really all it is, is just comparing across software stacks and hardware systems. [00:14:44]</span></p><p><strong>Alessio</strong><span>: What about different GPUs? We had George Hotz on the podcast and he talked about AMD cards and how in theory their flops should be much better than some Nvidia cards, but the reality is like the CUDA runtime makes up for it. How should people think about improving that? You know, like do you see, okay, the A100 is like 115 teraflops. I'd rather just stick with this than try and figure out all the kinks of like a better AMD card or any thoughts there? [00:15:10]</span></p><p><strong>Swyx</strong><span>: Right. [00:15:10]</span></p><p><strong>Quentin</strong><span>: Well, that's sort of touching on developer time, right? And which ends up being more expensive because at the end of the day, the AMD and Rockham software stack has a long way to go. I would say most things run there, not particularly efficiently, but you're going to have weird bugs that no one has encountered before. One of the big pluses of going with the Nvidia and PyTorch stack is that there are thousands of GitHub issues with everyone facing the same problem as you and resolving them quickly and in an open source way is probably the biggest benefit of going with the Nvidia software stack right now. AMD has about the same hardware, software, not so much. And they haven't quite got the momentum in the open source realm, for example, to get close. Like something, for example, like Flash Attention, it's spread to more Nvidia GPU types than it has like to AMD at all. And waiting on those latest and greatest features to reach AMD is something that's prohibitive to a lot of people, but it's getting there. I'm running a lot of experiments on AMD right now because it's sort of reached the government lab supercomputers now. And so a lot of experiments are going there and it will catch up, I'd say within a few [00:16:14]</span></p><p><strong>Swyx</strong><span>: years. [00:16:14]</span></p><p><strong>Quentin</strong><span>: Awesome. [00:16:15]</span></p><p><strong>Swyx</strong><span>: Maybe just talk about what's available from the government labs and I heard the original, the origin of Eluther started with a grant for TPUs. Is that right? [00:16:24]</span></p><p><strong>Quentin</strong><span>: Yes, that was a little before me, but there was a lot of just like getting a grabbing a Google Cloud or TPU pod or something like that is a lot of the original TPU work on Mesh TensorFlow, which is like now like an ancient distributed deep learning library. [00:16:36]</span></p><p><strong>Quentin</strong><span>: Eluther got a grant, an insight grant with Oak Ridge last year, and we got quite a bit of Summit Compute. So Summit is a V100 based supercomputer. It's got some weirdness to it. So there's six V100 GPUs per node. And we did a lot of experiments there. It's a challenging system to scale to because your interconnect across nodes is kind of slow in comparison to within a node, which I think we'll get to later. But now Oak Ridge has moved to AMD. So the next grant that we're trying to work towards is on Frontier, which has four AMD GPUs per node and again has a slower interconnect across nodes. So we get all of those new challenges again to try and overlap things. But that's just like you have Oak Ridge, you have Lawrence Livermore. There's a lot of government supercomputers that you can apply for compute towards like open researchers too. It's sort of a new thing. I think we're one of the first like us and like Lion, for example, is another organization that's getting compute from government providers and such. They're all moving to AMD as well. And we look forward to exploring that with them. [00:17:42]</span></p><p><strong>Swyx</strong><span>: Yeah. [00:17:43]</span></p><p><strong>Alessio</strong><span>: The computing is definitely, it used to be easy to find the GPU. Now, not as much. So you got to find them anywhere. [00:17:49]</span></p><p><strong>Swyx</strong><span>: Yes. [00:17:49]</span></p><p><strong>Alessio</strong><span>: Let's talk about memory requirements a little bit. So you touched on this a little bit before and just before this, we had a trade out on the pockets from FlashAttention and memory speed was one of our main focuses, but this time we're being bound by actually memory size, like the VRAM itself, when it comes to model weights and parameters and optimizer states and all that fun stuff. Let's go through this and Sean, we can, we can take turns. There's a lot to cover here, but maybe we can start from model weights. So one topic we covered a lot in the past is precision and quantization. That's one of the obviously main driver of memory. You mentioned most of, in the article, most transformers are mixed precision, like FP16 plus FP32 or BF16 FP32, and they can be cast down. And you mentioned up to like INT8 without a lot of performance hit. So let's start there and maybe run people through some of the maths and like the byte per parameter ratio and different precision. [00:18:50]</span></p><p><strong>Swyx</strong><span>: Sure. [00:18:51]</span></p><p><strong>Quentin</strong><span>: So when I started deep learning, it was all FP32. You have 32 bits, four bytes per parameter. Things were pretty simple. You didn't have to do any loss scaling at all. But the problem was that you didn't get a whole lot of flops once NVIDIA moved to V100s and introduced Tensor cores. So Tensor cores do all of their computation at FP16 precision. So you're kind of throwing all of those away if you're doing things in FP32. So once the hardware moved to V100, the software moved to like mixed precision and APEX and AMP and such. And one counterintuitive part of mixed precision is that you actually require more memory when you're trained because you need an FP16 copy of the weights and an FP32 copy of the weights. The FP16 copy is where you're doing like your actual computation on the Tensor cores. So you get maybe it's not uncommon to get double the throughput that you would see before in FP32. And then you at each step update that FP32 copy with the FP16 update. So both need to be stored in memory. The problem with that is that FP16 is very precise but doesn't have a whole lot of range, [00:19:55]</span></p><p><strong>Swyx</strong><span>: dynamic range. [00:19:55]</span></p><p><strong>Quentin</strong><span>: So you have a really big mantissa if you're thinking in terms of like floating point representations, not a whole lot of exponent. So BF16 puts more of the bits from the mantissa back to the exponent. So you have a much higher range and a lower precision. And that gets rid of all of this instability problem and loss scaling and such that anyone familiar with debugging knows how unstable it can be, especially for large scale training. And BF16 does away with a lot of that, but it's only supported on A100s. So you see the back and forth between hardware and software. So every time NVIDIA introduces some new Tensor cores or BF16 support or something like that, the software adapts to support it and then training adapts. And then now you mentioned like Ind8 and such. Now we're seeing that you have some model that's been trained in FP16, FP32, whatever else. And then now you want to, with minimal loss and accuracy, quantize that model into a smaller representation like Ind8 and now like Ind4 and things like that and see what you can get away with. And then since deep learning is such like a stochastic problem that a lot of those last bits of precision don't really matter is what we're finding. And I expect that to continue. [00:21:06]</span></p><p><strong>Alessio</strong><span>: And so just to put some numbers to it, when you have a FP32, you need four bytes per parameter at inference time to load it in memory. If you have a eight bits model quantized down, you need one byte per parameter. So for example, in an H100, which is 80 gigabyte of memory, you could fit a 70 billion parameters in eight, you cannot fit a FP32 because you will need like 280 gigabytes of memory. So how much does that play into it? Like you mentioned it was all FP32 when you first started. Is it just like a development complexity thing, like going down to FP16 and then Ind8? Or if they could get a GPU with like a terabyte of VRAM, will people just load this memory as like FP32 weights or would they still want to quantize them to make them more efficient? Right. [00:22:00]</span></p><p><strong>Quentin</strong><span>: I would say even if you had infinite VRAM, you would still want a quantized model, just a bigger model that's quantized is what I would say. And that's because like I was mentioning there at the end, how like deep learning is very stochastic and a lot, you could have all the precision in the world, but ultimately it's meaningless when you still depend so much like on what the input is. And you depend so much on little variations and maybe a few more samples of training data would matter more. A lot of that precision in a nutshell doesn't really matter in deep learning. All that matters is the big picture. What is that neuron actually saying? And not the tiny details of what it might be thinking. Oh, I also wanted to mention that even if you have an A100, the actual model size is quite a bit smaller that you could load than what you mentioned. That's because of the KV cache. So the KV cache intuitively during inference, it only matters during inference and think intuitively if you're writing a paragraph, you want to remember every single previous word that you've written before you write the next word. So like what is autoregressive language modeling? It's filling in the next word, the next token. So if I say like the dog went to the, and I need to write the next word, I would say park or something. Before I write the next word, my memory is wiped and I have to read the whole thing again. That is life without a KV cache. And a KV cache says, remember everything that I've generated before, as well as all the context before what I've generated. But the memory overhead for a KV cache commonly is either comparable or larger than the model in some cases, if you have a really long context. And I think the exact equation is something like, oh, it's like two times the number of layers, times the number of heads, times the dimension of each head. And then there's two of those. You have one for K, one for V. But that was just a quick aside. Yeah. [00:23:44]</span></p><p><strong>Alessio</strong><span>: I know this is Transformers math, but do you think one of the interesting things about RNNs too, it's like moving away from this, like KV cache, the scales with the sequence length and having like a fixed sequence pass. I know those are some of the things that people are working on. [00:24:00]</span></p><p><strong>Swyx</strong><span>: Yeah. [00:24:00]</span></p><p><strong>Quentin</strong><span>: So there's a paper that I was involved with called RWKV that I would recommend people read. It is answering this exact question. So how do you get Transformers quality without this quadratic attention overhead that Transformers requires? So it is interesting. I don't know if I can really dive too deep into the technical details there. I'd recommend people read the paper. But yeah. [00:24:23]</span></p><p><strong>Swyx</strong><span>: Yeah. [00:24:23]</span></p><p><strong>Alessio</strong><span>: It's interesting to see if attention is all you need, or maybe attention is all we need, but we need better ways to make it infer in a good way. [00:24:33]</span></p><p><strong>Swyx</strong><span>: We've actually done an unreleased episode with one of the RWKV core members and they call it soft attention or light attention. I forget what they call it, but yeah, just ways to approximate it such that it's linear and not quadratic. That's great. Yeah. [00:24:47]</span></p><p><strong>Quentin</strong><span>: I didn't know that you were involved. [00:24:48]</span></p><p><strong>Swyx</strong><span>: That's great. How did you get involved? Is it just because like everyone just hangs out in Discord and talks about the future of Transformers? Oh yeah. [00:24:55]</span></p><p><strong>Quentin</strong><span>: I mean, the RWKV people specifically are in Eleuther all the time. Like they're very close collaboration with us. And my contribution was we have all of these experiments done by all of these people on RNNs and how they relate to Transformers and how do we turn that into a paper and disseminate that digestibly so that people don't have to read through like a Discord log from a year ago to understand what's going on. [00:25:16]</span></p><p><strong>Swyx</strong><span>: Oh my God. [00:25:16]</span></p><p><strong>Quentin</strong><span>: Just read this paper. So that took some work, but I wasn't a core contributor. So that's why I don't want to go into like the technical details. But yeah, that's how I did. [00:25:24]</span></p><p><strong>Swyx</strong><span>: We'll try to get that RWKV episode out. It seems like there's increasing mentions of it and they are doing pretty important work as far as scaling these models are concerned. Okay. So we discussed inference type quantization and memory requirements. And then you also had a section on training with a lot of stuff I think mentioned. I think we probably want to spend the most of our time on optimizer states and the Atom optimizer. Yeah. What are your takes on it and what should people keep in mind when they deal with these optimizers? Okay. [00:25:57]</span></p><p><strong>Quentin</strong><span>: I would say the Atom optimizer is good at what it does. It's sort of a broad question. So let me think. You have the copy of the weights and then you have your momentum and your variance that [00:26:08]</span></p><p><strong>Swyx</strong><span>: you store. [00:26:08]</span></p><p><strong>Quentin</strong><span>: And like, okay, maybe an intuitive explanation for momentum is that like, let's say you have a canyon and you're trying to get to the bottom. And if you're just doing basic SGD, then every step is going to be an equal size. Whereas if you're using something like Atom with the momentum term, then your steps should be progressively larger because you can see, oh, the general trend is we're heading downwards very quickly. But stepping back from that, since you have all of these extra terms in Atom, you require a lot more memory to store it. Like three times as much memory as SGD. And if you have all of this memory being spent on your optimizer states, then how do you distribute it across GPUs? Because you'll find that what ends up being your bottleneck more than just raw compute, raw flops on a given GPU is your parallelism. And that falls back onto how much model you can fit on a single GPU before you need to split it up across a bunch of GPUs. And then you end up spending time, more time with them talking to each other than actually making progress. So that's why all of this time in the blog post is spent on how do you distribute your model? What are all those different distributed strategies look like? Which ones are more efficient? And given that a lot of your memory is being spent optimizers, how do you distribute that optimizer specifically? Because a lot of people, when they talk about parallelism, they talk about model parallelism, the parameters themselves. In actuality, when you're training, a good portion of your memory is actually spent on optimizer states. So what specific part of that would you like to go into? Would you like to go into like zero or sharded optimizers? [00:27:36]</span></p><p><strong>Swyx</strong><span>: I think the sharded optimizer stuff is really interesting, but I think we're kind of leaving that towards the end, right? Because that's the maybe more advanced distributed sections. Here, I think we're just going for rough intuition for people who've maybe are familiar with the ideas of these optimizers, but haven't actually had to implement them yet. They read your code, but they don't really understand the intuition behind the code. I see. [00:28:00]</span></p><p><strong>Alessio</strong><span>: And Quentin, when you say in the blog post, it says, Adam is magic. How much of it is like actual magic, even to like people like you that are pretty close to the metal, so to speak? Are some of these things just come as gospel? It's like, I know this works, like I'm not touching it. I'm just leveraging it. How much of it are you actually thinking about improving on in your day-to-day work? I see. [00:28:22]</span></p><p><strong>Quentin</strong><span>: So I'm a systems guy. I'm an engineer. And a lot of these things come to me as magic. Adam comes to me as magic. I see it from the gods. I say, this is how a deep learning model is trained. And this is how the next step is calculated. And then I say, okay, how do I make that fast? I would say I do look at ways to improve upon it using things like second order optimizers. So there's a lot of research on there because they're hard to distribute. But the core contribution for me always comes down to someone else has done like some deep learning optimization and I need to make it run fast. So I can't really speak to the motivation of why Adam came about other than like simple, intuitive things like I mentioned with like the momentum. But what matters to me is that Adam takes more memory than SGD, specifically three times. And all of that memory needs to go somewhere and it needs to be split efficiently. [00:29:14]</span></p><p><strong>Swyx</strong><span>: Yeah. [00:29:14]</span></p><p><strong>Alessio</strong><span>: So when you add them all up, you got 12 bytes per parameter with vanilla Adam. [00:29:20]</span></p><p><strong>Swyx</strong><span>: Yeah. [00:29:20]</span></p><p><strong>Alessio</strong><span>: And then you still get the model parameters and memory too. So as you mentioned, you need to keep a copy of both for like a FB32, FB16 mixed, a copy of both quantization levels. So there's precision levels. So it's six bytes per parameter. Right. [00:29:36]</span></p><p><strong>Quentin</strong><span>: Taking a step back again, is that like, okay, most people think of your model getting big. So you need to split with model parallelism purely, something like tensor parallelism. But we can see that the model only takes like two bytes per parameter if we're doing FB16. Whereas the optimizer itself requires four bytes per parameter for the model states, four bytes for momentum, four bytes for variance. So what matters more is how do you split your optimizer efficiently and how do you store it efficiently? And something like bits and bytes, where the optimizer, you got like eight bit Adam, where those optimizer states is only one byte per parameter instead of four or something like that. That is going to give you a much better return on your model training and on your memory overhead required than if you were to, for example, quantize your pure like FB16 model weights down to int8 or something. So for training specifically, your optimizer memory matters a lot. The most in most cases. [00:30:31]</span></p><p><strong>Swyx</strong><span>: Well, yeah. [00:30:31]</span></p><p><strong>Alessio</strong><span>: And before we dive into zero, just to wrap up the items that you're going to shard later. So you have the parameters, you have the optimizer states, and then you have the gradients. Just maybe touch a little bit on that. And then we can talk about how to efficiently load them in GPUs. [00:30:48]</span></p><p><strong>Quentin</strong><span>: So the parameters are the FP32 copies of the parameters. We include them in the optimizer discussion. Some people don't, but just for clarity, it's 12 bytes per param for the optimizer states and four of them are for that FP32 copy of the weights. Four of them are for the momentum. I already went into why it's important to store momentum, but that's also per parameter. You need to store where that parameter is going and where it's been going in the past. You also need to know, okay, we know where it's going, but there's going to be bumps on this canyon that we're going down. So we need to store its variance. How often are those bumps? Should we be focusing more on the momentum? Or is this parameter just kind of jumping around everywhere? Those are all important answers that we need the optimizer to store, and it's per parameter. So that's where all three of those terms come from. And we also include some competing bits and bytes, for example, an SGD to show that depending on your optimizer, you may store all or none of these and in different representations. [00:31:50]</span></p><p><strong>Alessio</strong><span>: I'm looking at the total training memory. You essentially have model memory, optimizer memory, gradient memory, and activation memory. I think that's one of the last discussed things. So maybe just give people a little bit of a view. [00:32:03]</span></p><p><strong>Swyx</strong><span>: Yeah, this is completely new to me. [00:32:05]</span></p><p><strong>Alessio</strong><span>: Active, you know, recomputation, checkpointing, and all of that. [00:32:08]</span></p><p><strong>Swyx</strong><span>: Right. [00:32:09]</span></p><p><strong>Quentin</strong><span>: So, okay. So to summarize before activation checkpointing, which will be complicated, you have your model params, like I mentioned before, they used to be FP32. Now they're probably BF16, maybe FP16 if it's an older GPU. Then you have your optimizer. That's where a lot of the memory is going. And it's your high precision, usually FP32, copy of the weights. So that's four bytes per param. And then you have, optionally, a couple more terms like we just discussed, like momentum or variance or whatever else, depending on what your optimizer is. Then you have your gradients. So your gradients is what is the gradient update that we get after running the forward pass on the model. And that's going to be whatever your low precision copy of the weights is. So like two bytes per param, if you're using FP16 or BF16. And all of those are sort of set in stone. And that overhead is not going to go away for the duration of training. Your gradients might get cleared after you back propagate them, but your optimizer states and your model states aren't going away. That memory overhead will be there. Activation recomputation and activation memory is dynamic. So some people will come and have this problem where the model loads fine for training. But then when you actually run your first iteration, or you run some future iteration or something like that, you run out of memory, seemingly at random. And it's because of these activations that you're computing on the fly. Good summary, or do you want to get into activation recomputation now, or do you want me to touch on anything else? [00:33:35]</span></p><p><strong>Alessio</strong><span>: Yeah, I was going to say, when is the recomputation happening? How does it decide between recomputing versus storing? And talk a bit more about that, maybe. [00:33:47]</span></p><p><strong>Quentin</strong><span>: Yeah, okay. So there's a lot of different ways to do this, but I would say there are a few main ones. First is a very simple scheme. You recompute everything. Every single activation that you calculate is just going to be either used or thrown away until the end. So in that case, you care very much about memory. You care very little about compute. Maybe this would be a case where you have to distribute across a lot of different GPUs, for example. And your communication speed is really low. Then that might be a good case for you to just recompute everything. It happens rarely, but it happens. Next up would be something like selective recomputation. So in selective recomputation, which Megatron has a good paper on, and I believe the figure that we have in our blog post is from, in that case, you sort of do a weighted decision for each activation. So for really big activation tensors, you decide, is this going to be more expensive to save in terms of memory or to recompute in terms of compute? So that's sort of the smart scheme that Megatron implements. And there's a lot of different heuristics they use. It's probably not worth mentioning off this super long equation on a pod, but you should go and read that paper if you're interested on selective recomputation. And then a really stupid scheme that most people go with, including NeoX, would be something like, instead of doing all of these heuristics, you just say, if my tensor is bigger than X, I throw it away. And you set X to some static number, and that's it. And that is good enough for a lot of cases. [00:35:18]</span></p><p><strong>Swyx</strong><span>: Why is it good enough? [00:35:20]</span></p><p><strong>Quentin</strong><span>: You don't want to store more than, you know, X-sized tensor. And some fall above that, some fall below it. And you're not trying to squeeze. You care more about getting something close enough to what the actual heuristic should be without actually computing the heuristic because you don't want to spend the time writing that heuristic code. [00:35:37]</span></p><p><strong>Swyx</strong><span>: Cool. I think that does take us on a grand tour of the memory math. Is there any sort of high-level takeaway before we go into the distributed stuff? Zero and all that. Perhaps more detail than most people have ever encountered. And so I'll repeat the equation that Alessio mentioned again, which is total training memory now has all these components that you've mapped out for the first time as far as we're concerned. Model memory, optimizer memory, activation memory, gradient memory. We covered quite a few algorithms as to the choices you can make there. Anything else that you want to mention about just memory math? I don't think so. [00:36:11]</span></p><p><strong>Quentin</strong><span>: I think that about covers it. I will say that it's a very different scheme for training and inference. It's common for people to say, oh, BF16 is the best. Done. Whereas a more correct take is that during training, precision matters a bit more. So BF16 will be around longer for training than it will for inference, in which case your model is sort of already baked. And it definitely doesn't need some of those last bits of precision so you can get away much easier with going to int8 for inference rather than training. So everything that you learn for training has to be relearned for inference and vice versa. [00:36:44]</span></p><p><strong>Swyx</strong><span>: There's a third category. You're talking about training versus inference. This third category is emerging with regards to fine-tuning and perhaps parameter-efficient methods of fine-tuning. The naive way to implement fine-tuning is just to do more training. But I don't know if you've developed any intuitions over fine-tuning that's worth inserting here. Any intuitions? If you were to write fine-tuning math, what would go in there? That might be an interesting diff to training math. [00:37:10]</span></p><p><strong>Quentin</strong><span>: I think there's a lot of questions that are unanswered for fine-tuning. For example, we know scaling laws for training. And some people have done scaling laws for fine-tuning. But how does a model that's already been trained on one domain transfer to another in terms of fine-tuning size? How many tokens per parameter should you have for your fine-tuning dataset? Maybe I'm ignorant, but I feel like a lot of those sort of practical questions on how a model can transfer and how a model can learn or grok some new ability that wasn't in its original training dataset is something that I would definitely put inside a fine-tuning blog post. [00:37:45]</span></p><p><strong>Swyx</strong><span>: Something related to perplexity and, I guess, diversity of the tokens that you get. [00:37:49]</span></p><p><strong>Quentin</strong><span>: Yeah, sort of dataset transfer is something that I would be curious in. Learning rate transfer is another one. So your model has some decayed learning rate over the course of training. How does that change for fine-tuning? Things like that. [00:38:00]</span></p><p><strong>Swyx</strong><span>: All right, cool. Thanks for indulging that stuff. Sure. Yeah. [00:38:03]</span></p><p><strong>Alessio</strong><span>: I think after all of this, you can quickly do the math and see that training needs to be distributed to actually work because we just don't have hardware that can easily run this. So let's talk a bit about that. So zero is one of the first things that you mentioned here, which is focused on sharded optimizers. Maybe run people through that and how to think about it. [00:38:25]</span></p><p><strong>Swyx</strong><span>: Sure. [00:38:25]</span></p><p><strong>Quentin</strong><span>: So zero is centered around two communication operations. And the first is scatter. And people should be looking at the zero figure that I think we have. [00:38:35]</span></p><p><strong>Swyx</strong><span>: Yeah. [00:38:36]</span></p><p><strong>Quentin</strong><span>: So there's a figure in the paper with parameters, gradients, and optimizer states that people should be looking at when I'm talking about this. Every GPU is going to get its own equal portion of the slice. And if we're doing... There are different stages of zero, but let's just start off with assuming that it's an equal slice of the optimizer states, gradients, and parameters. That would be zero three, stage three in that case. And we do that with a scatter. And the scatter takes, say, one over end GPUs, plus this offset of that slice goes to that GPU. Now all of the GPUs have an equal slice that's in its rank order. And then during each training step, that GPU is going to wait for all of the other slices to communicate so that we now have a whole pie on that GPU, that single GPU. Once we have that whole pie, we do the forward pass on it. And then we distribute that forward pass to all of the others using a gather. So it's a scatter, reduced scatter specifically, and then a gather back to all the others. And you do that each step. So the point of it is that you're sharding these states across GPUs. And with the different stages, you'll see in that figure that the optimizer state is taking the most proportion, which is because of what I mentioned before. We're including the FP32 copy and we're doing atom. So we need those four bytes per param for momentum and for variance. And then zero stage one, which is the most common one, is just optimizer. Zero stage two is optimizer plus gradients. And zero stage three is optimizer gradients and model parameters. But it all comes back to this splitting up and then gathering together back and forth over and over. So you get a lot of communication overhead from zero. But the plus part of that is that you can overlap a lot of that movement with computation. [00:40:23]</span></p><p><strong>Alessio</strong><span>: How do you get the optimal number of GPUs to do this on? Is there a way to shard too much as well and put too much overhead? [00:40:31]</span></p><p><strong>Quentin</strong><span>: It depends more on what your interconnect is. Taking a step back, there is synchronization that's required, a lot of it, across all of these GPUs. And those tend to be cumulative. So if you go to too many GPUs on an interconnect that's too slow, then you're going to end up spending more time synchronizing. And that magic number where you spend more time synchronizing is going to be different depending on what your fabric is and what your GPU memory is specifically. Just how small of a slice is each GPU getting? I can't, for example, for Summit, that number comes out to be about 20 billion parameters. Now you have 20 billion parameters, and then your magic number of GPUs for that is going to be something like 100 to 200 scale. Beyond that, you're just going to end up spending more time communicating. And the actual flops dipping below some predetermined number by you is going to be whatever your sweet spot ends up being. [00:41:24]</span></p><p><strong>Alessio</strong><span>: And then, so this one was like hard for me to go through, so I'm excited to have you run through it, which is a 3D parallelism. [00:41:33]</span></p><p><strong>Swyx</strong><span>: It's fancy, it's cutting edge. [00:41:35]</span></p><p><strong>Alessio</strong><span>: Yeah, let's talk a bit more about that and some of the work. [00:41:38]</span></p><p><strong>Quentin</strong><span>: Okay, 3D parallelism. So what is each dimension? First is the really basic one. That's data parallelism. And data parallelism is you have a copy of the model. Let's say for simplicity, one copy fits on one GPU perfectly. Data parallelism is that now you have two GPUs, so you have one copy on GPU one, one copy on GPU two. Both of them do the forward and backward pass and then synchronize and average the gradients. And then that's a step. Data parallelism for 3D parallelism is actually zero. So it's, you're sharding the optimizer states across all of your different GPUs. Next up is tensor parallelism. Tensor parallelism is you split your model. Like say, if you have two GPUs, you split your model down the middle and each GPU on its tensor specifically is going to do its forward or backward operation on its tensor. And then only when necessary, it'll synchronize that tensor operation with the other GPU. It's a bit more complex than something like pipeline parallelism, which is the third dimension. In pipeline parallelism, let's say you have four layers in your model. And you have four GPUs. You put one layer on each GPU and then GPU one does the forward pass and then sends the output of its activations to GPU two. It does the forward pass, sends activations to three, and you're just moving down a line. That is a naive scheme in that all of the other GPUs are doing nothing while a single GPU is doing its forward or backward pass. So the reason it's called pipeline parallelism is because you're splitting your mini batch into micro batches. So GPU one will do the forward pass on micro batch one and then send to GPU two. And then while GPU two is running on that first micro batch, GPU one is working on the next micro batch. And so you're sort of pipelining the movement and computation of each micro batch. The problem with that is that you need a really big batch size in order to split it up into both mini batches and micro batches. So combining all three of those together, you get a 3D mesh of where each parameter and optimizer state and so on maps to each GPU. And that's 3D parallelism. So let's start diving into details on what have that made sense, what should I jump into more on? [00:43:55]</span></p><p><strong>Alessio</strong><span>: I think the main question is, do you need all of the GPUs to be the same to do this? Or can you have mismatching GPUs as well? [00:44:03]</span></p><p><strong>Quentin</strong><span>: Okay, two things matter. If there's a difference in VRAM for the two different kinds of GPUs, then you're going to be bottlenecked by whichever GPU has the lower amount of VRAM because it's going to run out of memory. And then you can't like whatever's left on the larger GPUs is going to be empty. As far as I'm aware, there's no like GPU single GPU aware memory overhead scheme that would account for that. The second problem is that let's say all of your GPUs have the same amount of VRAM, but half of them are really slow. And the problem with that is that those synchronizations that I mentioned earlier are going to kill you. So you're going to move as quickly as your slowest GPU in that case. So in both cases, you end up regressing to your slowest or smallest GPU. So you might as well have the same GPUs for all of them. Otherwise, you're wasting the nicer ones. And that also goes to your CPUs and your interconnect. So going back to the 20 billion parameter model that Eleuther was training, that was on a cluster that was sort of Frankenstein made during COVID when there was all of that shortage of network switches and such like that. So every node had a different network switch. And so you ended up moving at the speed of the slowest switch and getting everything tuned properly so that it's not worse than the slowest switch was challenging and is like a real world problem that sometimes comes up. [00:45:28]</span></p><p><strong>Alessio</strong><span>: Is this work widely accepted? Like I hadn't learned about this before studying for this episode. Is this something that people are still trying and researching? Or is everybody just aware of this and running this in production? [00:45:43]</span></p><p><strong>Quentin</strong><span>: What is this specifically? [00:45:44]</span></p><p><strong>Alessio</strong><span>: Like the sharded optimizers plus the 3D parallelism, bringing the two things together and having this kind of mesh strategy. [00:45:51]</span></p><p><strong>Quentin</strong><span>: I would say that a lot of major GPT-based models use this scheme. A lot of them now are sort of going with just a pure zero scheme. So just a pure sharded. You just shard everything. And then since that's so easy, everyone gets an equal slice. There's no such thing as a pipeline stage. There's no such thing as what tensor should go on which GPU. Instead, we shard everything equally and treat everything equally. It's a much easier problem to debug, to checkpoint, to run training on than it is with this 3D parallel scheme. I say 3D parallel gives you the most control and also the most ways to go wrong. And depending on whether you have more engineers or whether you have more GPUs, that should decide which of these you go with. [00:46:35]</span></p><p><strong>Swyx</strong><span>: It's also not too hard, right? You've basically outlined the five or six different numbers that you need to keep in your head. And it doesn't feel impossible that if you need to achieve that level of control, you've given everybody the main levers to do it with. And that's wonderful. Definitely. [00:46:51]</span></p><p><strong>Quentin</strong><span>: The problem that comes up is like, say, like, okay, GPT-4 came out. Now we have VLLMs. [00:46:57]</span></p><p><strong>Swyx</strong><span>: Whoa, what are VLLMs? Oh, okay. Virtual LLMs, like the Metro of Expert things? No, like visual. [00:47:03]</span></p><p><strong>Quentin</strong><span>: So now you have like multimodal models and such. How do you distribute that? Do you distribute it in a pipeline stage? And do you just shard it? Do you split the tensor and make a tensor parallel? It's sort of hard to change your model and add new features and such when you have this 3D parallel scheme. That's when I say hard. I mean, it's hard to sort of adapt and modify it to new features. [00:47:26]</span></p><p><strong>Alessio</strong><span>: I know we're at the hour mark, and I think we put our listeners through a very intense class today. So this was great, Quentin. And we're going to definitely link the article so that people can read it and follow along. Any other research that you're working on in this space that you want to shout out? I know one of our usual, I mean, wrong question is, what's the most interesting unsolved question in AI? So curious to hear if you think it's still on the training inference, math optimization, or are there more areas that people should pay attention to? [00:47:58]</span></p><p><strong>Quentin</strong><span>: I think in my area of research, there are two things that I think people should really care about. And the first is multimodal parallelism and RLHF. You were seeing more and more reinforcement learning and coming into the training loop. And so how do you split that some model or some GPUs are working on inference and some GPUs are working on training? And like I mentioned before, you have to relearn everything and they have very unique challenges. How do you split up a KV cache during training, for example? Those are challenges that are not well studied, I don't think. And then multimodal, you have like maybe a vision transformer and a text transformer. How do you split those up? Do you split them up equally? Do you put them on separate GPUs or do you just shard everything? And just maybe one GPU will have some vision, some text parameters. And then the second case I would say is that communication is very often a bottleneck. So we talk about 3D parallelism, but a lot of those like, for example, tensor parallelism, you can't go across nodes with. You'll just get killed in communication. So what I'm getting to is how should you compress your communication before it happens? So on the fly compression, you have some buffer that needs to be communicated. You compress it with a GPU kernel, then you send it across the network and then you decompress it, something like that. Making people spend less money on communication fabrics and more on GPUs as intended is sort of a thing that people need to explore. I think those are my two. [00:49:26]</span></p><p><strong>Alessio</strong><span>: Sean, you went over the other half of the lightning round before we wrap it up. [00:49:30]</span></p><p><strong>Swyx</strong><span>: That's a good brain dump. Cool. Yeah, I have so many more questions on the multimodal stuff, but that should be for another time. Acceleration, what has already happened in AI that you thought would take much longer? [00:49:42]</span></p><p><strong>Quentin</strong><span>: I would say flash attention. Guys, just talk to Tree. And flash attention is just sort of a really great set of kernels that I thought would take a while to get to us. [00:49:51]</span></p><p><strong>Alessio</strong><span>: Well, Quentin, thank you very much, man. This was super informative and I think hopefully helps demystify a little bit the blog post. I think people open it and it's like a lot of math on it. And I think you walking them through it was super helpful. So thank you so much for coming on. [00:50:07]</span></p><p><strong>Swyx</strong><span>: Of course. [00:50:08]</span></p><p><strong>Quentin</strong><span>: And I'm happy to answer any questions that people have offline if they have them. I do read my email. [00:50:13]</span></p><p><strong>Swyx</strong><span>: Email and Discord. Of course, yeah. [00:50:15]</span></p><p><strong>Quentin</strong><span>: Discord I'm even faster on. [00:50:16]</span></p><p><strong>Alessio</strong><span>: Thank you, everyone. [00:50:18]</span></p><p><strong>Swyx</strong><span>: Thanks, Quentin. [00:50:19]</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Theory of interstellar trade (1978) [pdf] (149 pts)]]></title>
            <link>https://www.princeton.edu/~pkrugman/interstellar.pdf</link>
            <guid>37149782</guid>
            <pubDate>Wed, 16 Aug 2023 16:45:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.princeton.edu/~pkrugman/interstellar.pdf">https://www.princeton.edu/~pkrugman/interstellar.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=37149782">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[July 2023 was the hottest month on record (118 pts)]]></title>
            <link>https://twitter.com/nasa/status/1691106509319806977?s=46&amp;t=H_jBB1XRvGbGkpJRBZAq5Q</link>
            <guid>37149736</guid>
            <pubDate>Wed, 16 Aug 2023 16:42:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/nasa/status/1691106509319806977?s=46&#x26;t=H_jBB1XRvGbGkpJRBZAq5Q">https://twitter.com/nasa/status/1691106509319806977?s=46&#x26;t=H_jBB1XRvGbGkpJRBZAq5Q</a>, See on <a href="https://news.ycombinator.com/item?id=37149736">Hacker News</a></p>
Couldn't get https://twitter.com/nasa/status/1691106509319806977?s=46&t=H_jBB1XRvGbGkpJRBZAq5Q: Error [ERR_FR_TOO_MANY_REDIRECTS]: Maximum number of redirects exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[LK-99 isn’t a superconductor – how science sleuths solved the mystery (1625 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-023-02585-7</link>
            <guid>37149349</guid>
            <pubDate>Wed, 16 Aug 2023 16:17:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-023-02585-7">https://www.nature.com/articles/d41586-023-02585-7</a>, See on <a href="https://news.ycombinator.com/item?id=37149349">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <figure>
 <picture>
  <source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-023-02585-7/d41586-023-02585-7_25924888.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-023-02585-7/d41586-023-02585-7_25924888.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px">
  <img alt="Shards of a LK-99 crystal." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-023-02585-7/d41586-023-02585-7_25924888.jpg">
  <figcaption>
   <p><span>Pure crystals of LK-99, synthesized by a team at the Max Planck Institute for Solid State Research in Stuttgart, Germany.</span><span>Credit: Pascal Puphal</span></p>
  </figcaption>
 </picture>
</figure><p>Researchers seem to have solved the puzzle of LK-99. Scientific detective work has unearthed evidence that the material is not a superconductor, and clarified its actual properties.</p><p>The conclusion dashes hopes that LK-99 — a compound of copper, lead, phosphorus and oxygen — marked the discovery of the first superconductor that works at room temperature and ambient pressure. Instead, studies have shown that impurities in the material — in particular, copper sulfide — were responsible for the sharp drops in electrical resistivity and partial levitation over a magnet, which looked similar to properties exhibited by superconductors.</p><p>“I think things are pretty decisively settled at this point,” says Inna Vishik, a condensed-matter experimentalist at the University of California, Davis.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-023-02481-0" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-023-02585-7/d41586-023-02585-7_25886824.jpg"><p>Claimed superconductor LK-99 is an online sensation — but replication efforts fall short</p></a>
 </article><p>The LK-99 saga began in late July, when a team led by Sukbae Lee and Ji-Hoon Kim at the Quantum Energy Research Centre, a start-up firm in Seoul, published preprints<sup><a href="#ref-CR1" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">1</a></sup><sup>,</sup><sup><a href="#ref-CR2" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">2</a></sup> claiming that LK-99 is a superconductor at normal pressure and temperatures up to at least 127 ºC (400 kelvin). All previously confirmed superconductors function only at extreme temperatures and pressures.</p><p>The extraordinary claim quickly grabbed the attention of the science-interested public and researchers, some of whom tried to replicate LK-99. <a href="https://www.nature.com/articles/d41586-023-02481-0" data-track="click" data-label="https://www.nature.com/articles/d41586-023-02481-0" data-track-category="body text link">Initial attempts did not see signs of room-temperature superconductivity</a>, but were not conclusive. Now, after dozens of replication efforts, many experts are confidently saying that the evidence shows LK-99 is not a room-temperature superconductor. (Lee and Kim’s team did not respond to <i>Nature</i>’s request for comment.)</p><h2>Accumulating evidence</h2><p>The South Korean team based its claim on two of LK-99’s properties: levitation above a magnet and abrupt drops in resistivity. But separate teams in Beijing, at Peking University<sup><a href="#ref-CR3" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">3</a></sup> and the Chinese Academy of Sciences<sup><a href="#ref-CR4" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">4</a></sup> (CAS), found mundane explanations for these phenomena.</p><p>Another study<sup><a href="#ref-CR5" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">5</a></sup>, by US and European researchers, combined experimental and theoretical evidence to demonstrate how LK-99’s structure made superconductivity infeasible. And other experimenters synthesized and studied pure samples<sup><a href="#ref-CR6" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">6</a></sup> of LK-99, erasing doubts about the material’s structure and confirming that it is not a superconductor, but an insulator.</p><p>The only further confirmation would come from the Korean team sharing their samples, says Michael Fuhrer, a physicist at Monash University in Melbourne, Australia. “The burden’s on them to convince everybody else,” he says.</p><p>Perhaps the most striking evidence for LK-99’s superconductivity was a <a href="https://sciencecast.org/casts/suc384jly50n" data-track="click" data-label="https://sciencecast.org/casts/suc384jly50n" data-track-category="body text link">video</a> taken by the Korean team that showed a coin-shaped sample of silvery material wobbling over a magnet. The team said the sample was levitating because of the Meissner effect — a hallmark of superconductivity in which a material expels magnetic fields. Multiple unverified videos of LK-99 levitating subsequently circulated on social media, but none of the researchers who initially tried to replicate the findings observed any levitation.</p><h2>Half-baked levitation</h2><p>Several red flags popped out to Derrick van Gennep, a former condensed-matter researcher at Harvard University in Cambridge, Massachusetts, who now works in finance but was intrigued by LK-99. In the video, the same edge of the sample seemed to stick to the magnet, and it seemed delicately balanced. By contrast, superconductors that levitate over magnets can be spun and even held upside-down. “None of those behaviors look like what we see in the LK-99 videos,” van Gennep says.</p><p>He thought LK-99’s properties were more likely the result of ferromagnetism. So he constructed a pellet of compressed graphite shavings with iron filings glued to it. A <a href="https://twitter.com/VanGennepD/status/1688052003216261120" data-track="click" data-label="https://twitter.com/VanGennepD/status/1688052003216261120" data-track-category="body text link">video</a> made by Van Gennep shows that his disc — made of non-superconducting, ferromagnetic materials — mimicked LK-99’s behaviour.</p><p>On 7 August, the Peking University team reported that this “half-levitation” appeared in their LK-99 samples because of ferromagnetism. “It’s exactly like an iron-filing experiment,” says Yuan Li, a condensed-matter physicist and study co-author. The pellet experiences a lifting force but it’s not enough to levitate — only enough to balance on one end.</p><p>Li and his colleagues measured their sample’s resistivity, and found no sign of superconductivity. But they couldn’t explain the sharp resistivity drop seen by the Korean team.</p><h2>Impure samples</h2><p>In their preprint, the Korean authors note one particular temperature at which LK-99’s showed a tenfold drop in resistivity, from about 0.02 ohms per centimetre to 0.002 ohms per cm. “They were very precise about it. 104.8ºC,” says Prashant Jain, a chemist at the University of Illinois Urbana–Champaign. “I was like, wait a minute, I know this temperature.”</p><p>The reaction that synthesizes LK-99 uses an unbalanced recipe: for every 1 part copper-doped lead phosphate crystal — pure LK-99 — it makes, it produces 17 parts copper and 5 parts sulfur. These leftovers lead to numerous impurities — especially copper sulfide, which the Korean team reported in its sample.</p><p>Jain, a copper-sulfide expert, remembered 104ºC as the temperature at which Cu<sub>2</sub>S undergoes a phase transition if exposed to air. Below that temperature, Cu<sub>2</sub>S’s resistivity drops dramatically — a signal almost identical to LK-99’s purported superconducting phase transition. “I was almost in disbelief that they missed it.” Jain published a preprint<sup><a href="#ref-CR7" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">7</a></sup> on the important confounding effect on 7 August.</p><p>The next day, the CAS team reported on the effects of Cu<sub>2</sub>S impurities in LK-99. “Different contents of Cu<sub>2</sub>S can be synthesized using different processes,” says Jianlin Luo, a CAS physicist. The researchers tested two samples — the first heated in a vacuum, which resulted in 5% Cu<sub>2</sub>S content, and the second in air, which gave 70% Cu<sub>2</sub>S content.</p><p>The first sample’s resistivity increased relatively smoothly as it cooled, and appeared similar to samples from other replication attempts. But the second sample’s resistivity plunged near 112 ºC (385K) — closely matching the Korean team’s observations.</p><p>“That was the moment where I said, ‘Well, obviously, that’s what made them think this was a superconductor,’” says Fuhrer. “The nail in the coffin was this copper sulfide thing.”</p><p>Making conclusive statements about LK-99’s properties is difficult, because the material is finicky and samples contain varying impurities. “Even from our own growth, different batches will be slightly different,” says Li. But Li argues that samples that are close enough to the original are sufficient for checking whether LK-99 is a superconductor in ambient coniditions.</p><h2>Crystal clear</h2><p>With strong explanations for the resistivity drop and the half-levitation, many in the community were convinced that LK-99 was not a room-temperature superconductor. But mysteries lingered — namely, what were the material’s actual properties?</p><p>Initial theoretical attempts using an approach called density functional theory (DFT) to predict LK-99’s structure had hinted at interesting electronic signatures called ‘flat bands’. These are areas where the electrons move slowly and can be strongly correlated. In some cases, this behavior leads to superconductivity. But these calculations were based on unverified assumptions about LK-99’s structure.</p><p>To better understand the material, the US–European group<sup><a href="#ref-CR5" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">5</a></sup> performed precision X-ray imaging of their samples to calculate LK-99’s structure. Crucially, the imaging allowed them to make rigorous calculations that clarified the situation of the flat bands: they were not conducive to superconductivity. Instead, the flat bands in LK-99 came from strongly localized electrons, which cannot ‘hop’ in the way a superconductor requires.</p><p>On 14 August, a separate team, at the Max Planck Institute for Solid State Research in Stuttgart, Germany, reported<sup><a href="#ref-CR6" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">6</a></sup> synthesizing pure, single crystals of LK-99. Unlike previous synthesis attempts that relied on crucibles, the researchers used a technique called floating zone crystal growth that allowed them to avoid introducing sulfur into the reaction, eliminating the Cu<sub>2</sub>S impurities.</p><p>The result was a transparent purple crystal — pure LK-99, or Pb<sub>8.8</sub>Cu<sub>1.2</sub>P<sub>6</sub>O<sub>25</sub>. Separated from impurities, LK-99 is not a superconductor, but an insulator with a resistance in the millions of ohms — too high to run a standard conductivity test. It shows minor ferromagnetism and diamagnetism, but not enough for even partial levitation. “We therefore rule out the presence of superconductivity,” the team concluded.</p><p>The team suggests that the hints of superconductivity seen in LK-99 were attributable to Cu<sub>2</sub>S impurities, which are absent from their crystal. “This story is exactly showing why we need single crystals,” says Pascal Puphal, a specialist in crystal growth and the Max Planck physicist who led the study. “When we have single crystals, we can clearly study the intrinsic properties of a system.”</p><h2>Lessons learned</h2><p>Many researchers are reflecting on what they’ve learned from the summer’s superconductivity sensation.</p><p>For Leslie Schoop, a solid-state chemist at Princeton University in New Jersey, who co-authored the flat-bands study, the lesson about premature calculations is clear. “Even before LK-99, I have been giving talks about how you need to be careful with DFT, and now I have the best story ever for my next summer school,” she says.</p><p>Jain points to the importance of old, often overlooked data — the crucial measurements that he relied on for the resistivity of Cu<sub>2</sub>S were published in 1951.</p><p>While some commentators have pointed to the LK-99 saga as a model for reproducibility in science, others say that it’s an unusually swift resolution of a high-profile puzzle. “Often these things die this very slow death, where it’s just the rumors and nobody can reproduce it,” says Fuhrer.</p><p>When copper oxide superconductors were discovered in 1986, researchers leapt to probe their properties. But nearly four decades later, there is still debate over the material’s superconducting mechanism, says Vishik. Efforts to explain LK-99 came readily. “The detective work that wraps up all of the pieces of the original observation — I think that’s really fantastic,” she says. “And it’s relatively rare.”</p>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What happens to all the stuff we return? (157 pts)]]></title>
            <link>https://www.newyorker.com/magazine/2023/08/21/the-hidden-cost-of-free-returns</link>
            <guid>37149327</guid>
            <pubDate>Wed, 16 Aug 2023 16:15:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.newyorker.com/magazine/2023/08/21/the-hidden-cost-of-free-returns">https://www.newyorker.com/magazine/2023/08/21/the-hidden-cost-of-free-returns</a>, See on <a href="https://news.ycombinator.com/item?id=37149327">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><figure data-testid="IframeEmbed"><div data-testid="IframeEmbedContainer"><p><span><inline-embed type="callout" meta="%7B%22type%22%3A%22callout%22%2C%22name%22%3A%22dropcap%22%2C%22body%22%3A%22%3Cp%3EListen%20to%20this%20article.%3C%2Fp%3E%5Cn%22%2C%22attrs%22%3A%7B%7D%7D" ref=""><p>Listen to this article.</p>
</inline-embed></span></p></div></figure><p>The twentysomething daughter of a friend of mine recently ordered half a dozen new dresses. She wasn’t planning to keep the lot; she’d been invited to the wedding of a college classmate and knew in advance that she was going to send back all but the one she liked best. “Swimsuits and dresses for weddings—you never buy just one,” Joanie Demer, a co-founder of the Krazy Coupon Lady, a shopping-strategy Web site, told me. For some online apparel retailers, returns now average forty per cent of sales.</p><p>Steady growth in Internet shopping has been accompanied by steady growth in returns of all kinds. A forest’s worth of artificial Christmas trees goes back every January. Bags of green plastic Easter grass go back every spring. Returns of large-screen TVs surge immediately following the Super Bowl. People who buy portable generators during weather emergencies use them until the emergencies have ended, and then those go back, too. A friend of mine returned so many digital books to Audible that the company now makes her call or e-mail if she wants to return another. People who’ve been invited to fancy parties sometimes buy expensive outfits or accessories, then return them the next day, caviar stains and all—a practice known as “wardrobing.” Brick-and-mortar shoppers also return purchases. “Petco takes back dead fish,” Demer said. “Home Depot and Lowe’s let you return dead plants, for a year. You just have to be shameless enough to stand in line with the thing you killed.” It almost goes without saying that Americans are the world’s leading refund seekers; consumers in Japan seldom return anything.</p><p>Earlier this year, I attended a three-day conference, in Las Vegas, conducted by the Reverse Logistics Association, a trade group whose members deal in various ways with product returns, unsold inventories, and other capitalist jetsam. The field is large and growing. Dale Rogers, a business professor at Arizona State, gave a joint presentation with his son Zachary, a business professor at Colorado State, during which they said that winter-holiday returns in the United States are now worth more than three hundred billion dollars a year. Zachary said, “So one and a half per cent of U.S. G.D.P.—which would be bigger than the G.D.P. of many countries around the world—is just the stuff that people got for Christmas and said, ‘Nah, do they have blue?’&nbsp;” The annual retail value of returned goods in the U.S. is said to be approaching a trillion dollars.</p><p>Most online shoppers assume that items they return go back into regular inventory, to be sold again at full price. That rarely happens. On the last day of the R.L.A. conference, I joined a “champagne roundtable” led by Nikos Papaioannou, who manages returns of Amazon’s house-brand electronic devices, including Kindles, Echos, and Blink home-security systems. He said that every item that’s returned to Amazon is subjected to what’s referred to in the reverse-logistics world as triage, beginning with an analysis of its condition. I asked what proportion of triaged products are resold as new.</p><p>“It’s minimal,” he said. “I’m not going to give you a specific number, because it’s so dependent on the product category. But our approach with this question is that, if the seal has been broken, if the wrap is not intact, then it’s not going back to the shelf.” Even though Papaioannou understands this fact as well as anyone, he said, he often shops the way the rest of us do. When he buys shoes, for example, he typically orders two pairs, a half size apart. In brick-and-mortar stores, a pair of tried-on shoes will be re-boxed and reshelved. “From an Amazon viewpoint, the moment the box opens, you’ve lost the opportunity,” he said.</p><p>For a long time, a shocking percentage of online returns were simply junked. The industry term is D.I.F., for “destroy in field.” (The Web site of Patriot Shredding, based in Maryland, says, “Product destruction allows you to protect your organization’s reputation and focus on the future.”) This still happens with cheap clothes, defective gadgets, and luxury items whose brand owners don’t want a presence at Ocean State Job Lot, but, in most product categories, it’s less common than it used to be. Almost all the attendees at the R.L.A. conference, of whom there were more than eight hundred, are involved, in one way or another, in seeking profitable, efficient, and (to the extent possible) environmentally conscionable ways of managing the detritus of unfettered consumerism. “Returns are inherently entrepreneurial,” Fara Alexander, the director of brand marketing at goTRG, a returns-management company based in Miami, told me. She and many thousands of people like her are active participants in the rapidly evolving but still only semi-visible economic universe known as the reverse supply chain.</p><p>People who weren’t born yesterday, but almost, often assume that easy refunds and exchanges began with the online shoe store Zappos, which was founded in 1999. Tony Hsieh, the company’s legendary late C.E.O., offered free returns for up to a year after purchase and encouraged people to order items in multiple styles and sizes. That policy, which was backed by intensely personal customer service, was so popular that the company’s revenues grew more than sixfold in four years. Amazon started a similar shoes-and-accessories site, called Endless, but it eventually gave up trying to compete, having bought Zappos for $1.2 billion.</p><p>America’s true refund pioneer was born a century before Hsieh, on a farm in northwestern Missouri. He moved to Kemmerer, Wyoming, in 1902, in order to become a one-third owner of a general store that was part of a small chain, called Golden Rule. Within a few years, he had bought out his partners and opened more stores, and in 1913 he consolidated his holdings under his own name: J.&nbsp;C. Penney. (The initials stand for James Cash.) Among his innovations was allowing customers to return anything, no questions asked. That approach made a permanent impression on Sam Walton, who went to work at a Penney’s store, in Des Moines, in 1940, immediately after graduating from the University of Missouri. Twenty-two years later, Walton founded his own chain, Walmart, and adopted a similarly generous return policy, which is still in effect. “Sam Walton was very, very customer-centric,” Chuck Johnston, who served as Walmart’s senior director of returns between 2005 and 2012 and is now the chief strategy officer at goTRG, told me. “People would bring in stuff that was clearly from Sears, and we would take it back, because we wanted a happy customer.” (Homer&nbsp;Simpson: “The customer’s always right; that’s why everyone likes us.”)</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>A century ago, the average return rate at Penney’s was probably something like two per cent; before Internet shopping truly took hold, retail returns had risen to more like eight or ten per cent. Returns to online retailers now average close to twenty per cent, and returns of apparel are often double that. Among the many reasons: products often look nothing like their online images—such as a crocheted bikini top that was barely big enough for the purchaser’s cat—and colors and fabrics appear different on different screens.</p><p>The pandemic accelerated growth in online shopping, and therefore in returns, by several years. Quarantined lawyers bought fewer neckties but more sweatpants and bedroom slippers. People who were suddenly forced to work from home ordered desks, chairs, and computers. In 2021, UPS delivered a huge unassembled storage unit to my house. It was actually meant for a neighbor, but I opened the box because I, too, had ordered a huge unassembled storage unit. (Like many people, my neighbor and I had decided that <em>COVID</em> had given us an opportunity to organize our swelling hoard of household crap, including household crap we’d bought because of <em>COVID</em>. I texted my neighbor, and he drove over and picked up his box—no return necessary.) Pre-pandemic, a common shopping strategy was to study possible purchases in a regular store, then save a few dollars by ordering from Amazon. When in-person shopping became difficult, the best way to compare products was to order multiples and send back the rejects.</p><figure><p><span><div data-attr-viewport-monitor=""><a data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.newyorker.com/cartoon/a26959&quot;}" href="https://www.newyorker.com/cartoon/a26959" rel="nofollow noopener" target="_blank"><picture></picture></a><p><span>Cartoon by Roz Chast</span></p></div></span></p></figure><p>Returns are expensive for sellers, since shipping alone often costs more than the items can be resold for. Many retailers have responded by shrinking their refund windows or by imposing fees for postage or so-called restocking. Some sellers offer store credit only. Amazon now adds a “frequently returned item” label to listings of problematic offerings and encourages potential purchasers to double-check descriptions and customer reviews of those items before ordering. The online business model of the eyeglasses seller Warby Parker is based on easy returns: customers can order as many as five frames, at no risk, to try on at home. The company still offers that option but has reduced return costs by employing an increasingly sophisticated online tool that allows customers to try on glasses virtually. (It also has physical stores, which have mirrors.) Back in the mail-order era, L.&nbsp;L. Bean suggested that shoe customers include a tracing of their foot in the envelope with their order form—an effective way to reduce returns, but more troublesome than ordering multiple pairs.</p><p>Despite the cost, retailers worry that discouraging returns discourages buying in the first place, driving revenues down. Easy returns are like free shipping: they can be a dealmaker or a deal-breaker when a consumer is deciding where to shop, even though in both cases the cost is ultimately borne by the consumer. Most online mattress sellers offer free returns, in some cases for up to a year; used mattresses can’t be resold, so the loss, usually some eight or nine per cent of sales, is folded into prices. Johnston said, “You’ve got to tread carefully, if you try to ratchet back ease of returns, so that you don’t drive your customer to your competitor.”</p><p>As a consequence, even as sellers are subtly and not so subtly discouraging returns, they’re also exploring ways to make them easier. Some Target stores now have drive-up refund windows. Many online returns no longer have to be repackaged: just get a QR code on the seller’s site and take the unboxed item to a location that consolidates shipments. Amazon offers Prime customers a seven-day “try before you buy” option on selected apparel and accessories. (You pay only for what you keep.) You might think that retailers would be pleased when customers fail to send back items they don’t want, but that isn’t true if those customers remain unhappy. One of the most popular presenters at R.L.A. was Spencer Kieboom, a former major-league baseball player, whose company, Pollen Returns, uses underemployed rideshare and delivery drivers to pick up unwanted items, for free, at buyers’ homes, thereby sparing them the nuisance of schlepping things to UPS on their own.</p><p>Some retailers simply refund certain purchases, no need to send anything back. (“When you ship a hundred-pound bag of dog food, you’re probably losing money on it already,” Johnston told me.) My wife ordered a funny poster for a high-school reunion, then decided it wasn’t funny enough. When she tried to return it, Amazon told her to keep it, and refunded her $32.72. Perhaps surprisingly, companies that sell sofa beds, dining tables, and other bulky, heavy items often do the same, because return freight is so expensive.</p><p>“There are people who think that open returns are an idea whose time has come and gone, but it’s a hallmark of successful American retail,” Dale Rogers told me. “If you make it easy to shop, and you reduce the risk to the consumer, what you get is a lifetime consumer.” It’s probably not a coincidence that the world’s two biggest retailers—Walmart, with revenues of five hundred and seventy-three billion dollars in 2022, and Amazon, with four hundred and sixty-nine billion—also offer some of the easiest returns.</p><p>Three years ago, the producers of a Canadian television show called “Marketplace” ordered boots, diapers, a toy train, a coffee maker, a printer, and several other items from Amazon Canada. They concealed a G.P.S. tracking device inside each one, then returned everything and monitored what happened next. Some of the items travelled hundreds of miles in trucks, with intermediate stops at warehouses and liquidation centers, ultimate disposition unknown. A brand-new women’s backpack ended up in a waste-processing center, en route to a landfill. The show included a surreptitiously recorded conversation with an employee of a “product-destruction” facility, who described receiving truckload after truckload of Amazon returns and shredding everything—ostensibly for recycling, although the recoverable content of a chewed-up random selection of consumer goods is not high.</p><p>If you leave money lying around, someone will pick it up. One morning at the R.L.A. conference, I spent half an hour with two executives of Liquidity Services, a company that, according to its Web site, offers “circular commerce solutions” to businesses of all kinds, in part by selling “any item in any condition, anywhere in the world.” John Daunt, the chief commercial officer, said, “It sounds like selling used stuff, but there’s a lot more to it than you would think.” Liquidity Services operates eight regional warehouse-size facilities in North America. The one closest to New York is in Pittston, Pennsylvania, at the outer edge of a business park that also includes distribution or return facilities owned by Amazon, Home Depot, Lennox, Neiman Marcus, PepsiCo, and a number of smaller companies. The rise of online shopping has been very good for people who build immense, low, flat-roofed metal structures. The Pittston complex includes two enormous buildings that belong to Lowe’s; between them, they have more than fifty acres under roof, plus loading docks and parking spaces for hundreds of semitrailers. Similar complexes now exist all over the United States, in locations that have easy access to highways and airports. More are always under construction.</p><p>For a liquidator, turning a profit depends on having the ability to quickly determine whether an item can be sold again at a reasonable price, and, if so, whether it requires human attention first. Liquidity Services and companies like it use automated and semiautomated routines to sort returned items, repair what can easily be repaired, wipe information from electronic devices, and funnel salable goods to likely customers. “A lot of what we do involves receiving a truckload and then finding another buyer for that truckload, who then will distribute it to mom-and-pop stores and other resellers downstream,” Daunt said. “Or, if they’re not quite big enough to handle that, we may sell it as pallets. We also have direct-to-consumer channels, and people will come to some of our facilities and pick up single items that they’ve bid for online.”</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>You can register as a buyer on Liquidity Services’ Web site right now, as I did recently, and place bids in any of hundreds of auctions. I didn’t do that, but I did spend a pleasant morning studying items that other people were bidding on, among them a two-pallet lot containing six hundred and fifty-four pounds of sports-related Amazon returns. The lot included seven pellet guns, six clear-plastic umbrellas, an assortment of punching bags and punching balls, a double-bladed lightsabre toy, a shatter-resistant over-the-door mini basketball hoop, eight yoga mats, a minnow trap, an indoor exercise trampoline, a pair of hiking poles, a kickboxing shield, a car refrigerator, two hoverboards (one with Bluetooth and one without), a jump-rope rack, a quiver’s worth of crossbow bolts, a fourteen-gallon red plastic gas can with a siphon pump, a set of four badminton racquets, and a mountain-bike handlebar. There were a hundred and fourteen items in all, and Liquidity Services had estimated their combined original retail value as six thousand five hundred and seventy-six dollars. The lot ended up attracting fifty bids. The winner paid nine hundred and twenty-five dollars, shipping not included. None of the fifty bidders were willing to offer more than fifteen cents on the dollar, and even at that price they were taking a chance, since there was no guarantee that any particular item would still function. Returned items are often damaged, dented, scratched, or inoperable, and even ones that don’t look too bad can be missing parts or accessories.</p><p>I also followed the auction for a truckload of women’s designer shoes: a little more than four tons of returns, all in their boxes, many in brand-new condition, with an original retail value that the company estimated as a hundred and eighty-one thousand seven hundred dollars. That auction expired with no bids, even though two hundred and fifty potential buyers, plus me, had looked at it. That outcome helps to explain why one R.L.A. attendee described apparel returns to me as “a nightmare.” Clothing is tough: fashions go out of fashion quickly, and the items are likely to be one-offs.</p><p>When I got home from Las Vegas, I discovered that I live not far from one of the few companies that deal successfully with high volumes of apparel returns, out-of-stock clothing, and excess inventories. It’s called N.E.J., and it’s been in business for more than thirty years. It’s based in Beacon Falls, Connecticut, an old industrial town that, a century ago, was famous for manufacturing rubber shoes. “Apparel is almost like vegetables,” Ed Mascolo, the owner, told me, as he showed me around. “Things can lose value quickly.”</p><p>The key to his business, Mascolo said, is “volume with velocity, supported by predictability.” N.E.J. doesn’t buy unwanted goods and resell them itself; it mainly contracts with large retailers to categorize and repackage truckloads of their returns and overstocks, then ships them to outlets and other secondary channels. On the day that I visited, some two hundred workers in the main building were opening pallet-size shipping containers, called Gaylords, and sorting their contents into wheeled bins. I watched other workers sorting, folding, bagging, hanging, boxing. Some were “delabelling” new arrivals—using an indelible marker to draw a black line across a tag or to add a conspicuous dot—in order to mark those items as goods that, among other things, can’t be returned.</p><p>Six years ago, Mascolo decided that he had learned enough about the apparel industry to enter it himself. N.E.J. bought and revived a bankrupt American clothing company called Bills Khakis. It sells pants, shorts, shirts, and other items, all made in the United States. “We custom-hem our pants to the half inch,” he said. “It’s a very old-school pant. Seventeen-inch pocket. Extra belt loops, longer rise. Our customer is fifty to seventy-five, and he tends to be a little more conservative in how he dresses.” When we met, Mascolo was wearing a pair of Bills five-pocket twill khakis (two hundred and twenty-five dollars) and a brown Bills leather belt (ninety-eight dollars). I asked him about his return policy.</p><p>“We take everything back,” he said.</p><p>Last year, in an official statement, Amazon told CNBC that none of its returns are sent to landfills. All that really means is that Amazon itself doesn’t send anything to a landfill, but many returns obviously get there anyway, and some avoid it only by being diverted to what the company described to CNBC as “energy recovery,” a euphemism for burning in a furnace.</p><p>Liquidators must quickly sort and resell goods, usually in bulk. Some companies do more. One of those is America’s Remanufacturing Company, based in Georgia, which contracts with brand owners to receive their returns and, when possible, to repair or refurbish them, so that they can be sold by others. (A.R.C. is also one of Amazon’s so-called external repair venders.) “We never want to just buy returns,” Paul Adamson, the company’s chief revenue officer, told me. “There’s a lack of value.”</p><p>An important moment in Adamson’s career occurred in 1991, when he was a sophomore at the University of New Hampshire and working part time in a RadioShack store. He got a call from someone at a company that provided rapid-turn-around computer-maintenance contracts to major corporations. The caller desperately needed a particular part. Adamson found the part, and then found so many others for the same maintenance company that it hired him. (He sat at a desk with a phone and a computer keyboard, but no computer. When he took a call, he would make typing sounds on the keyboard, then say, “Oh, I think I’ve got one left. Let me just call the warehouse and verify.”) He followed that job with several similar ones, “all on the reverse side.” He met A.R.C.’s previous owner through an electronics-recycling company in which he was a partner, and they hit it off.</p><p>When Adamson pitches A.R.C.’s services to potential clients, he told me, he argues that even with items that can be sold again the real value is in information. “We can tell you how many units are being returned and how many of those are defective, and we can help you understand both of those numbers,” he said. Recently, A.R.C.’s technicians determined that one reason customers were returning a particular high-end coffee maker was that it contained a cheap float valve, which was prone to malfunctioning when used with hard water. After identifying the flaw, they helped design a fix by working with the factory in China that was doing the manufacturing. A.R.C. handles so many returns that it can often spot defects before brand owners are aware of them—as it did, recently, after receiving just three returns of an appliance that turned out to have issues with condensation and heat. Some clients now send A.R.C. models for testing before they go to market. It also has clients for whom it does design work only.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>This spring, I met with Adamson at A.R.C.’s facility in Union Point, Georgia, a small town a little more than an hour east of Atlanta. The company’s building there is broad, low, and gray, and it’s on a short potholed road with an aspirational name: Industrial Boulevard. There’s a lumber warehouse on the left, a Dollar General on the right, and a cabinetmaking company across the street.</p><p>We walked through the receiving area, a large, open space that was filled with recent arrivals—tilting piles of household appliances, stacks of yellow bins containing miscellaneous Amazon returns—and stopped in front of a pallet on which half a dozen Husqvarna two-thousand-pounds-per square-inch electric pressure washers, made under a license by Briggs &amp; Stratton, had been stacked and bound with plastic stretch wrap. (A pressure washer is many homeowners’ second-favorite power tool, after their chainsaw. It shoots a stream of water at high velocity, and can be used to clean a roof, blast mold off a wooden deck, or scare away a bear, as a friend of mine did after being surprised by one while scrubbing down the inside of his swimming pool.) As Adamson and I watched, workers sorted units by model and year of manufacture. They checked electrical components and replaced damaged parts with parts they’d salvaged from returns they couldn’t repair. Much of the refurbishing was done on a manufacturing line that A.R.C. bought from a Briggs &amp; Stratton plant, in Wauwatosa, Wisconsin, and modified, in part by adding a car-wash-like cleaning system to one end.</p><figure><p><span><div data-attr-viewport-monitor=""><a data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.newyorker.com/cartoon/a25207&quot;}" href="https://www.newyorker.com/cartoon/a25207" rel="nofollow noopener" target="_blank"><picture></picture></a><p><span>“The catch of the day looks a lot like that fish above the door, but a bit fresher.”</span></p><p><span>Cartoon by Frank Cotham</span></p></div></span></p></figure><p>For every item it processes, A.R.C. knows the potential resale price, what percentage of that price the brand owner is willing to spend on refurbishment, and the cost of each potential intervention. Some problems are too expensive to address; pressure washers with broken pumps are stripped of usable elements and thrown into a steel hopper, to be sent later to a local recycling company, which shreds them and recovers as much salable metal and plastic as it can. At the end of the line, a worker replaced each Husqvarna label with one from Murray, a brand that Briggs &amp; Stratton owns (and therefore a name it doesn’t have to license). Each unit also received a new serial number and a new box, which clearly identified it as a refurb. “These will all end up at the discount chain Ollie’s, where they’ll sell for maybe half of what a new one costs,” Adamson said. “Ollie’s picked up twelve truckloads here in the past week and a half, and they have another twenty or so to go—another ten thousand units over the next six weeks.” The pandemic was good&nbsp;for the refurb market, because in many product categories supply-chain problems made new items scarce.</p><p>A large number of the Amazon returns that A.R.C. receives, Adamson said, are “remorse returns”: you order something late at night after drinking too much wine, or maybe you and your spouse accidentally order the same thing. I saw bins of window curtains in another part of the building; all were from Amazon, many in packages that hadn’t been opened. Pressure washers, by contrast, are often returned because the people who bought them, usually men, don’t read instructions. “You’re always supposed to hook a pressure washer up to water before you turn it on, but a lot of people don’t do that, and they burn up the motor,” Adamson said. I asked whether Briggs &amp; Stratton couldn’t prevent that problem by adding a cutoff switch to the water tank. He said that such a fix was unlikely to be cost-effective, and that a more practical solution would be to add an extra warning tag or sticker.</p><p>Elsewhere, I saw technicians at long counters working on robotic vacuum cleaners. The units were plugged into outlets under the counter—they have to be charged before they can be evaluated—and hundreds, if not thousands, more were stacked nearby, on tall warehouse shelves. “The No. 1 issue with robot vacs is that people don’t know how to use them,” Adamson said. This is partly because the buyers tend to be older, but also because successfully making the necessary Wi-Fi connection can be frustrating even to people who do read instructions—an issue with other products as well. “A really good partner of ours does over fifty per cent of all the refurbishing of HP consumer printers in the U.S.,” Adamson said. “On all the newer printers, the only connection option is Wi-Fi, so when they refurb them they include a printer cable. Problem solved.”</p><p>Adamson told me that he used to be “an ardent hater” of companies that merely buy and sell returns. “I thought they just demonstrated the inefficiency of the reverse supply chain,” he said. “But my mind has changed over the years.” The fact that A.R.C. can’t profitably refurbish a particular item doesn’t mean that it won’t have value to someone else, even if it’s just a few cents’ worth of ground-up plastic. “There’s a guy in a small town in Alabama who buys trailer loads of returned air-conditioners from us,” he said. “When I Googled his property address, I saw that it’s a double-wide on four acres. He buys A.C.s that we can’t refurbish economically, then tinkers with them and sells them locally. It’s stuff I’m never going to touch, but he makes a living at it.”</p><p>The next day, I visited a different A.R.C. facility, this one in Augusta, an hour east of Union Point, and was shown around by David Hogan, the company’s C.E.O. At a workbench, two technicians were repairing upright vacuum cleaners, which were deluxe enough that A.R.C. could cost-effectively give them lots of individual attention. “We receive units that were very clearly just run until they stopped working,” Hogan said. “I mean, you’ve got to empty it, right? But some people don’t realize that.” Many American consumer goods are manufactured in Asia, for companies whose U.S. presence is limited to little more than marketing and sales departments. For companies like that, A.R.C. performs quality-control functions that used to be handled in-house. “You can’t beat the information you get from a product once a customer has touched it,” Hogan said.</p><p>The two technicians that Hogan and I watched are members of a rapidly vanishing species: people who know how to repair stuff. It used to be that when something went wrong with our dishwasher, washing machine, or oven, my wife or I would call a guy who owned a local appliance-repair company. Once, he got our dishwasher working again by taking apart the grinder and removing what he guessed were broken pieces of ceramic. (They were actually coyote teeth. Long story.) The last time I called him, seven or eight years ago, he said that he’d had to get a job as a greeter at Home Depot, because nowadays when appliances malfunction most people simply buy new ones.</p><p>That change is partly the result of consumer ignorance and laziness, but manufacturers are at fault, too. Almost all modern appliances contain electronics, which not only have a limited life span but are also usually impossible to repair and expensive to replace. Our former repairman once told my wife and me that we should always buy the “dumbest” appliances we could find. That was excellent advice, but it’s close to useless now, since even blenders and coffee makers contain microchips. He also told us that the deadliest enemy of electronic components is heat, and that, as a consequence, we should never self-clean an oven, never install two ovens side by side, and definitely never simultaneously self-clean two ovens that had been installed side by side—three valuable lessons that we learned the hard way.</p><p>Another challenge is that few products today are manufactured with repair in mind. “You see it when you get inside the product, as we do,” Hogan said. “A lot of it is materials selection, or the way the assembly was executed.” Two significant impediments to repair: components that are glued together rather than screwed, and pieces that were snapped together with plastic fasteners that break off when the pieces are pulled apart. A service that A.R.C. offers to some of its clients is what it calls same-unit repairs: something goes wrong, under warranty, with an expensive item like a shop vac, and the manufacturer sends you a UPS label addressed to A.R.C., whose technicians repair it and ship it back within a day or two. The company is currently building that side of the business, but it’s viable only with high-quality items, which don’t fall apart when you open them up.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>“At this company, we talk about how frustrated we are with some return practices—which is funny, because they’re what keep us in business,” Hogan said. He recently took part in a panel discussion at the Ray&nbsp;C. Anderson Center for Sustainable Business, at Georgia Tech, his alma mater. The topics included some of the same design issues we’d just been discussing—component quality, difficulty of repair, product life expectancy. He had asked the people in the room to imagine a world in which products were so well made and so easy to repair that a company like A.R.C. wouldn’t need to exist.</p><p>“I said, ‘Let me just theoretically offer you a deal,’&nbsp;” he told me. “&nbsp;‘I’ll sell you a computer for the same price as the one you have now—a nice, expensive computer. But it will be twice as durable, and it will weigh half as much, and its battery will last twice as long, and it will have twice the processing power and twice the memory.’&nbsp;” The only condition, he said, would be that returns would not be allowed, for any reason.</p><p>“This was Georgia Tech’s sustainability center, so these were super-smart engineering hippies,” he said. “There were probably forty or fifty people, all M.B.A.s.” Hogan assumed that they would all jump at the deal. But no hands went up—not one.</p><p>“I was blown away,” he said. “It’s just astounding how embedded returns are in our behavior. When I finished my talk, I said, ‘Thank you all. I definitely picked the right industry.’&nbsp;”&nbsp;♦</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: LlamaGPT – Self-hosted, offline, private AI chatbot, powered by Llama 2 (194 pts)]]></title>
            <link>https://github.com/getumbrel/llama-gpt</link>
            <guid>37148210</guid>
            <pubDate>Wed, 16 Aug 2023 15:05:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/getumbrel/llama-gpt">https://github.com/getumbrel/llama-gpt</a>, See on <a href="https://news.ycombinator.com/item?id=37148210">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><p dir="auto">
  <a href="https://apps.umbrel.com/app/llama-gpt" rel="nofollow">
    <img width="150" height="150" src="https://camo.githubusercontent.com/9c313ed8df225449c5a6b68ff9655d6236d6ed4eb96790d10cdc9dec0ab670e3/68747470733a2f2f692e696d6775722e636f6d2f4c4935396375692e706e67" alt="LlamaGPT" data-canonical-src="https://i.imgur.com/LI59cui.png">
  </a>
</p>
<h2 tabindex="-1" dir="auto">LlamaGPT</h2>
  <div dir="auto"><p>
    A self-hosted, offline, ChatGPT-like chatbot, powered by Llama 2. 100% private, with no data leaving your device.
    <br>
    <a href="https://umbrel.com/" rel="nofollow"><strong>umbrel.com »</strong></a></p><p>
    
    <a href="https://twitter.com/umbrel" rel="nofollow">
      <img src="https://camo.githubusercontent.com/0997f0c77459a43ab84a84d6d38a29789d0240c5a12746fda858a1953a00de94/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f756d6272656c3f7374796c653d736f6369616c" data-canonical-src="https://img.shields.io/twitter/follow/umbrel?style=social">
    </a>
    <a href="https://t.me/getumbrel" rel="nofollow">
      <img src="https://camo.githubusercontent.com/03e24c7995a7bc641c8a7dd788d0af4b7db84c1b2214a4d21cee705811463986/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f6d6d756e6974792d636861742d253233353335314642" data-canonical-src="https://img.shields.io/badge/community-chat-%235351FB">
    </a>
    <a href="https://reddit.com/r/getumbrel" rel="nofollow">
      <img src="https://camo.githubusercontent.com/226093e6bea73b290cdf30775844d5c2bedbe5e0d8b8576eb8e4dae23434356b/68747470733a2f2f696d672e736869656c64732e696f2f7265646469742f7375627265646469742d73756273637269626572732f676574756d6272656c3f7374796c653d736f6369616c" data-canonical-src="https://img.shields.io/reddit/subreddit-subscribers/getumbrel?style=social">
    </a>
    <a href="https://community.umbrel.com/" rel="nofollow">
      <img src="https://camo.githubusercontent.com/72a3b8aa0754193f254666d8e29b717be9661a45556bfdbbac96bcf53b4bbe40/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f6d6d756e6974792d666f72756d2d253233353335314642" data-canonical-src="https://img.shields.io/badge/community-forum-%235351FB">
    </a></p></div>

<h2 tabindex="-1" dir="auto">Demo</h2>
<details open="">
  <summary>
    
    <span aria-label="Video description LlamaGPT.mp4">LlamaGPT.mp4</span>
    <span></span>
  </summary>

  <video src="https://user-images.githubusercontent.com/10330103/261046099-5d1a76b8-ed03-4a51-90bd-12ebfaf1e6cd.mp4" data-canonical-src="https://user-images.githubusercontent.com/10330103/261046099-5d1a76b8-ed03-4a51-90bd-12ebfaf1e6cd.mp4" controls="controls" muted="muted">

  </video>
</details>

<h2 tabindex="-1" dir="auto">How to install</h2>
<h3 tabindex="-1" dir="auto">Install LlamaGPT on your umbrelOS home server</h3>
<p dir="auto">Running LlamaGPT on an <a href="https://umbrel.com/" rel="nofollow">umbrelOS</a> home server is one click. Simply install it from the <a href="https://apps.umbrel.com/app/llama-gpt" rel="nofollow">Umbrel App Store</a>.</p>

<p dir="auto"><a href="https://apps.umbrel.com/app/llama-gpt" rel="nofollow"><img src="https://camo.githubusercontent.com/8158198b3f4316b97d9a6d13256ad720aabc7c30e55538a7260f5deebd2a2a8b/68747470733a2f2f617070732e756d6272656c2e636f6d2f6170702f6c6c616d612d6770742f62616467652d6c696768742e737667" alt="LlamaGPT on Umbrel App Store" data-canonical-src="https://apps.umbrel.com/app/llama-gpt/badge-light.svg"></a></p>
<h3 tabindex="-1" dir="auto">Install LlamaGPT anywhere else</h3>
<p dir="auto">You can run LlamaGPT on any x86 or arm64 system. Make sure you have Docker installed.</p>
<p dir="auto">Then, clone this repo and <code>cd</code> into it:</p>
<div data-snippet-clipboard-copy-content="git clone https://github.com/getumbrel/llama-gpt.git
cd llama-gpt"><pre><code>git clone https://github.com/getumbrel/llama-gpt.git
cd llama-gpt
</code></pre></div>
<p dir="auto">You can now run LlamaGPT with any of the following models depending upon your hardware:</p>
<table>
<thead>
<tr>
<th>Model size</th>
<th>Model used</th>
<th>Minimum RAM required</th>
<th>How to start LlamaGPT</th>
</tr>
</thead>
<tbody>
<tr>
<td>7B</td>
<td>Nous Hermes Llama 2 7B (GGML q4_0)</td>
<td>8GB</td>
<td><code>docker compose up -d</code></td>
</tr>
<tr>
<td>13B</td>
<td>Nous Hermes Llama 2 13B (GGML q4_0)</td>
<td>16GB</td>
<td><code>docker compose -f docker-compose-13b.yml up -d</code></td>
</tr>
<tr>
<td>70B</td>
<td>Meta Llama 2 70B Chat (GGML q4_0)</td>
<td>48GB</td>
<td><code>docker compose -f docker-compose-70b.yml up -d</code></td>
</tr>
</tbody>
</table>
<p dir="auto">You can access LlamaGPT at <code>http://localhost:3000</code>.</p>
<p dir="auto">To stop LlamaGPT, run:</p>

<h2 tabindex="-1" dir="auto">Benchmarks</h2>
<p dir="auto">We've tested LlamaGPT models on the following hardware with the default system prompt, and user prompt: "How does the universe expand?" at temperature 0 to guarantee deterministic results. Generation speed is averaged over the first 10 generations.</p>
<p dir="auto">Feel free to add your own benchmarks to this table by opening a pull request.</p>
<h3 tabindex="-1" dir="auto">Nous Hermes Llama 2 7B (GGML q4_0)</h3>
<table>
<thead>
<tr>
<th>Device</th>
<th>Generation speed</th>
</tr>
</thead>
<tbody>
<tr>
<td>M1 Max MacBook Pro (10 64GB RAM)</td>
<td>8.2 tokens/sec</td>
</tr>
<tr>
<td>Umbrel Home (16GB RAM)</td>
<td>2.7 tokens/sec</td>
</tr>
<tr>
<td>Raspberry Pi 4 (8GB RAM)</td>
<td>0.9 tokens/sec</td>
</tr>
</tbody>
</table>
<h3 tabindex="-1" dir="auto">Nous Hermes Llama 2 13B (GGML q4_0)</h3>
<table>
<thead>
<tr>
<th>Device</th>
<th>Generation speed</th>
</tr>
</thead>
<tbody>
<tr>
<td>M1 Max MacBook Pro (64GB RAM)</td>
<td>3.7 tokens/sec</td>
</tr>
<tr>
<td>Umbrel Home (16GB RAM)</td>
<td>1.5 tokens/sec</td>
</tr>
</tbody>
</table>
<h3 tabindex="-1" dir="auto">Meta Llama 2 70B Chat (GGML q4_0)</h3>
<p dir="auto">Unfortunately, we don't have any benchmarks for this model yet. If you have one, please open a pull request to add it to this table.</p>
<h2 tabindex="-1" dir="auto">Roadmap and contributing</h2>
<p dir="auto">We're looking to add more features to LlamaGPT. You can see the roadmap <a href="https://github.com/getumbrel/llama-gpt/issues/8#issuecomment-1681321145" data-hovercard-type="issue" data-hovercard-url="/getumbrel/llama-gpt/issues/8/hovercard">here</a>. The highest priorities are:</p>
<ul dir="auto">
<li>Add CUDA and Metal support.</li>
<li>Moving the model out of the Docker image and into a separate volume.</li>
<li>Updating the front-end to show model download progress, and to allow users to switch between models.</li>
<li>Making it easy to run custom models.</li>
</ul>
<p dir="auto">If you're a developer who'd like to help with any of these, please open an issue to discuss the best way to tackle the challenge. If you're looking to help but not sure where to begin, check out <a href="https://github.com/getumbrel/llama-gpt/labels/good%20first%20issue">these issues</a> that have specifically been marked as being friendly to new contributors.</p>
<h2 tabindex="-1" dir="auto">Acknowledgements</h2>
<p dir="auto">A massive thank you to the following developers and teams for making LlamaGPT possible:</p>
<ul dir="auto">
<li><a href="https://github.com/mckaywrigley">Mckay Wrigley</a> for building <a href="https://github.com/mckaywrigley">Chatbot UI</a>.</li>
<li><a href="https://github.com/ggerganov">Georgi Gerganov</a> for implementing <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a>.</li>
<li><a href="https://github.com/abetlen">Andrei</a> for building the <a href="https://github.com/abetlen/llama-cpp-python">Python bindings for llama.cpp</a>.</li>
<li><a href="https://nousresearch.com/" rel="nofollow">NousResearch</a> for <a href="https://huggingface.co/NousResearch" rel="nofollow">fine-tuning the Llama 2 7B and 13B models</a>.</li>
<li><a href="https://huggingface.co/TheBloke" rel="nofollow">Tom Jobbins</a> for <a href="https://huggingface.co/TheBloke/Nous-Hermes-Llama-2-7B-GGML" rel="nofollow">quantizing the Llama 2 models</a>.</li>
<li><a href="https://ai.meta.com/llama" rel="nofollow">Meta</a> for releasing Llama 2 under a permissive license.</li>
</ul>
<hr>
<p dir="auto"><a href="https://github.com/getumbrel/llama-gpt/blob/master/LICENSE.md"><img src="https://camo.githubusercontent.com/992cbb8d9e6e3ac86f6e93bf2f80b0e9321484f4ad307c4c4e182a2ca16a801f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f676574756d6272656c2f6c6c616d612d6770743f636f6c6f723d253233353335314642" alt="License" data-canonical-src="https://img.shields.io/github/license/getumbrel/llama-gpt?color=%235351FB"></a></p>
<p dir="auto"><a href="https://umbrel.com/" rel="nofollow">umbrel.com</a></p>
</article>
          </div></div>]]></description>
        </item>
    </channel>
</rss>