<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 12 Nov 2023 21:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[HTML First – Six principles for building simple, maintainable, web software (379 pts)]]></title>
            <link>https://html-first.com/</link>
            <guid>38241304</guid>
            <pubDate>Sun, 12 Nov 2023 16:00:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://html-first.com/">https://html-first.com/</a>, See on <a href="https://news.ycombinator.com/item?id=38241304">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content">
  

<p>HTML First is a set of principles that aims to make building web software <strong>easier</strong>, <strong>faster</strong>, more <strong>inclusive</strong>, and more <strong>maintainable</strong> by...</p>

<ol>
<li>Leveraging the default capabilities of modern web browsers.</li>
<li>Leveraging the extreme simplicity of HTML's attribute syntax.</li>
<li>Leveraging the web's ViewSource affordance.</li>
</ol>

<h2>Goals</h2>

<p>The main goal of HTML First is to <strong>substantially widen the pool of people who can work on web software codebases</strong>. This is good from an individual perspective because it allows a greater number of people to become web programmers, to build great web software, and increase their income. It's also good from a business perspective as it decreases the cost of building software, and decreases the amount of resources required to hire - a notoriously resource intensive process. </p>

<p>A second goal of HTML First is to make it more <ins>enjoyable</ins> and <ins>seamless</ins> to build web software. Most web programmers are familiar with the excitement of seeing their product come together rapidly as they transition smoothly between the text editor and the browser, with very few unexpected potholes or context switches. But today it takes several years of mastering tools and frameworks to get to that stage. HTML First principles should allow people to unlock that feeling, and level of mastery, much earlier on in their coding journey.</p>

<p>The way we achieve these goals is by acknowledging that <a href="https://new.tonyennis.com/blog/M3WoiPA5P-comparing-the-readability-and-learning-curve-of-html" target="_blank">HTML is very easy to understand</a>, and thus using HTML as the bedrock of our product - not only to define content and structure, but also to set styling and behaviours.</p>

<h2>Principles</h2>

<ul>
<li><a href="#vanilla-approaches">Prefer Vanilla approaches</a></li>
<li><a href="#attributes-for-styling-behaviour">Use HTML attributes for styling and behaviour</a></li>
<li><a href="#attributes-for-libraries">Use libraries that leverage HTML attributes</a></li>
<li><a href="#build-steps">Avoid Build Steps</a></li>
<li><a href="#naked-html">Prefer Naked HTML</a></li>
<li><a href="#view-source">Be View-Source Friendly</a></li>
</ul>



<h2><strong>Use "vanilla" approaches to achieve desired functionality over external frameworks</strong></h2>

<p>The range of things that browsers support out of the box is large, and growing. Before adding a library or framework to your codebase, check whether you can achieve it using plain old html/css.<br>
<strong>Encouraged</strong></p>

<pre><code>&lt;details&gt;
  &lt;summary&gt;Click to toggle content&lt;/summary&gt;
  &lt;p&gt;This is the full content that is revealed when a user clicks on the summary&lt;/p&gt;
&lt;/details&gt;    
</code></pre>

<p><strong>Discouraged</strong></p>

<pre><code>import React, { useState } from 'react';

const DetailsComponent = () =&gt; {
  const [isContentVisible, setContentVisible] = useState(false);

  const toggleContent = () =&gt; {
    setContentVisible(!isContentVisible);
  };

  return (
    &lt;details&gt;
      &lt;summary onClick={toggleContent}&gt;Click to toggle content&lt;/summary&gt;
      {isContentVisible &amp;&amp; &lt;p&gt;This is the full content that is revealed when a user clicks on the summary&lt;/p&gt;}
    &lt;/details&gt;
  );
};

export default DetailsComponent;
</code></pre>



<h2>Where possible, default to defining style and behaviour with inline HTML attributes</h2>

<p>For styling this can be enabled with an SPC library like <a href="https://github.com/tonyennis145/dumb-tailwind" target="_blank">Tailwind</a> or <a href="http://tachyons.io/" target="_blank">Tachyons</a>. For behaviour, you can use libraries like <a href="https://hyperscript.org/" target="_blank">hyperscript</a>, <a href="https://alpinejs.dev/" target="_blank">Alpine</a>, or similar. Yes, this does mean your HTML will <em>look</em> busy. But it also means it will be easier for other developers to find and understand behaviour, navigate it, and make changes to it.</p>

<p><strong>Encouraged</strong></p>

<pre><code>&lt;div onlick="this.classList.add('bg-green')"&gt;
  Click Me
&lt;/div&gt;
</code></pre>

<p><strong>Discouraged</strong></p>

<pre><code>&lt;div id="results-pane"&gt;
  Click Me
&lt;/div&gt;
</code></pre>

<pre><code>#results-pane.active {
  background-color: green;
}
</code></pre>

<pre><code>var resultsPane = document.getElementById("myDiv");
resultsPane.addEventListener("click", function() {
    this.classList.add("active");
});
</code></pre>

<p>You may notice that this approach seems to violate <a href="https://en.wikipedia.org/wiki/Separation_of_concerns" target="_blank">Separation of Concerns</a> - one of the most commonly-touted software design principles. We believe an all-or-nothing approach to SoC is flawed, and instead advocate an approach that accounts for Locality of Behaviour and acknoweldges the trade-offs between the two.   </p>

<ul>
<li><a href="https://htmx.org/essays/locality-of-behaviour/" target="_blank">HTMX on The Locality of Behaviour Principle</a></li>
<li><a href="https://adamwathan.me/css-utility-classes-and-separation-of-concerns/" target="_blank">Adam Wathan on separation of styling concerns</a>.</li>
</ul>



<h2><strong>Where libraries are necessary, use libraries that leverage html attributes over libraries built around javascript or custom syntax</strong></h2>

<p><strong>Encouraged</strong></p>

<pre><code>&lt;script src="https://unpkg.com/<a href="https://html-first.com/cdn-cgi/l/email-protection" data-cfemail="d8b0a1a8bdaaabbbaab1a8ac98e8f6e8f6ef">[email&nbsp;protected]</a>/dist/hyperscript.min.js"&gt;&lt;/script&gt;
&lt;div&gt;
  &lt;input type="text" _="on input put me into #output"&gt;
  &lt;div id="output"&gt;&lt;/div&gt;
&lt;/div&gt;
</code></pre>

<p><strong>Discouraged</strong></p>

<pre><code>
&lt;script src="https://cdn.jsdelivr.net/npm/<a href="https://html-first.com/cdn-cgi/l/email-protection" data-cfemail="bbc8cfd2d6ced7cec8fb89958b958b">[email&nbsp;protected]</a>/dist/stimulus.umd.js"&gt;&lt;/script&gt;

&lt;div data-controller="echo"&gt;
  &lt;input type="text" data-echo-target="source" data-action="input-&gt;echo#update"&gt;
  &lt;div data-echo-target="output"&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;script&gt;
  const application = Stimulus.Application.start();

  application.register("echo", class extends Stimulus.Controller {
      static targets = ["source", "output"]

      update() {
          this.outputTarget.textContent = this.sourceTarget.value;
      }
  });
&lt;/script&gt;
</code></pre>


      

<h2>Steer Clear of Build Steps</h2>

<p>Libraries that require transforming your files from one format to another add significant maintenance overhead, remove or heavily impair the ViewSource affordance , and usually dictate that developers learn new tooling in order to use them. <a href="https://stackoverflow.com/questions/36517829/what-does-multiplexing-mean-in-http-2/36519379#36519379" target="_blank">Modern browsers don't have the same performance constraints</a> that they did when these practices were introduced. And if we use HTML First libraries like static tailwind or htmx, the amount of additional CSS and JS needed is usually minimal.</p>

<p><strong>Encouraged</strong></p>

<pre><code>&lt;link rel="stylesheet" href="/styles.css"&gt;
</code></pre>

<p><strong>Discouraged</strong></p>

<pre><code>&lt;link href="/dist/output.css" rel="stylesheet"&gt;
</code></pre>

<pre><code>npx css-compile -i ./src/input.css -o ./dist/output.css --watch
</code></pre>

<p>Aside: The build step practice is so deeply ingrained that even one year ago this opinion was considered <a href="https://twitter.com/tonyennis/status/1579610085499998208" target="_blank">extremely fringe</a>. But in the last year has begun to gain significant steam. Some recent examples:</p>

<ul>
<li><a href="https://twitter.com/dhh/status/1719041666412347651" target="_blank">@dhh - "We've gone #NoBuild on CSS with 37signals"</a></li>
<li><a href="https://gomakethings.com/are-build-tools-an-anti-pattern/" target="_blank">Are build tools an anti-pattern by Chris Ferdinandi</a></li>
<li><a href="https://gomakethings.com/how-do-build-tools-break-backwards-compatibility/" target="_blank">How do build tools break backwards compatibility</a></li>
<li><a href="https://social.lol/@bw/111293266036805485" target="_blank">Blake Watson - "There has never been a better time to ditch build steps"</a></li>
</ul>



<h2>Prefer "naked" HTML to obfuscation layers that compile down to HTML</h2>

<p>This principle is most applicable to backend implementation. The underlying idea again here is readability. If a developer who has familiarity with HTML but not with your backend framework looks through your view files, they should still be able to understand 90%+ of what they see. As with above, this means sacrificing brevity for understandability. </p>

<p><strong>Encouraged</strong></p>

<pre><code>&lt;form action="&lt;%= new_signup_path %&gt;" method="post"&gt;
  &lt;div class="field"&gt;
    &lt;label for="first_name"&gt;First Name&lt;/label&gt;
    &lt;input id="first_name" type="text" value="&lt;%= @signup&amp;.first_name %&gt;" /&gt;
  &lt;/div&gt;
  &lt;div class="field"&gt;
    &lt;label for="last_name"&gt;Last Name&lt;/label&gt;
    &lt;input id="last_name" type="text" value="&lt;%= @signup&amp;.last_name %&gt;" /&gt;
  &lt;/div&gt;
  &lt;div class="field"&gt;
    &lt;label for="email"&gt;Last Name&lt;/label&gt;
    &lt;input id="email" type="text" value="&lt;%= @signup&amp;.email %&gt;" /&gt;
  &lt;/div&gt;
&lt;/form&gt;
</code></pre>

<p><strong>Discouraged</strong></p>

<pre><code>&lt;%= form_with url: "#", local: true do |form| %&gt;
  &lt;div class="field"&gt;
    &lt;%= form.label :first_name %&gt;
    &lt;%= form.text_field :first_name %&gt;
  &lt;/div&gt;

  &lt;div class="field"&gt;
    &lt;%= form.label :last_name %&gt;
    &lt;%= form.text_field :last_name %&gt;
  &lt;/div&gt;

  &lt;div class="field"&gt;
    &lt;%= form.label :email %&gt;
    &lt;%= form.email_field :email %&gt;
  &lt;/div&gt;

  &lt;div class="actions"&gt;
    &lt;%= form.submit %&gt;
  &lt;/div&gt;
&lt;% end %&gt;
</code></pre>



<h2>Where possible, maintain the right-click-view-source affordance</h2>

<p>The beauty of the early web was that it was always possible to "peek behind the curtains" and see the code that was responsible for any part of any web page. This was a gift to aspiring developers, as it allowed us to bridge the gap between the theoretical (reading about how code works) and the practical - seeing both code and interface alongside each other. For many sites, we could copy and paste the html or css and run it in ourselves to get a close-to-identical replica. "Remixing" existing snippets was not only a way to learn, but often formed the basis of our new creations.</p>

<p>In the time since, the industry has adopted several "improvements" which have made this practice much rarer. For example, if we use React - the most popular frontend framework, we cannot hit "View Source", copy the code, and remix it, because 1. React has a build step, meaning the code we see in the developer tools is different to the code that the developer wrote, and 2. React code snippets must be wrapped in a react application in order for them to work.</p>

<p>For sites that follow HTML First principles, we regain the ViewSource affordance again. In fact, HTML First sites often go one step further. Because if you define your <strong>UI interactions</strong> using HTML attributes, you can now also preserve these interactions when copy pasting into a new codebase, (provided your destination file includes the same js library). At some point we intend to levearge this to build an HTML First code snippet library. </p>

<ul>
<li><a href="https://htmx.org/essays/right-click-view-source/" target="_blank">HTMX.org on the ViewSource affordance</a></li>
</ul>

<h2>Wrapping Up</h2>

<p>The practices and principles described on this site are still considered niche in the industry as a whole, and the community of people using them small. One of my hopes with creating this site is to act as a Honeypot to find and connect like minded people with whom we can discuss and sharpen these ideas. If any of this resonates with you, I'd love to <a href="https://twitter.com/tonyennis" target="_blank">hear from you</a>.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Steam Deck OLED spot ad was made with Steam Deck OLEDs (194 pts)]]></title>
            <link>https://idlethumbs.social/@ja2ke/111396017651485944</link>
            <guid>38240861</guid>
            <pubDate>Sun, 12 Nov 2023 15:20:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://idlethumbs.social/@ja2ke/111396017651485944">https://idlethumbs.social/@ja2ke/111396017651485944</a>, See on <a href="https://news.ycombinator.com/item?id=38240861">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[GPU Survival Toolkit for the AI age: The bare minimum every developer must know (243 pts)]]></title>
            <link>https://journal.hexmos.com/gpu-survival-toolkit/</link>
            <guid>38240421</guid>
            <pubDate>Sun, 12 Nov 2023 14:37:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://journal.hexmos.com/gpu-survival-toolkit/">https://journal.hexmos.com/gpu-survival-toolkit/</a>, See on <a href="https://news.ycombinator.com/item?id=38240421">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="site-main">
<article>

    <header>

        <p><span><svg width="16" height="17" viewBox="0 0 16 17" fill="none" xmlns="http://www.w3.org/2000/svg">
    <path d="M4.49365 4.58752C3.53115 6.03752 2.74365 7.70002 2.74365 9.25002C2.74365 10.6424 3.29678 11.9778 4.28134 12.9623C5.26591 13.9469 6.60127 14.5 7.99365 14.5C9.38604 14.5 10.7214 13.9469 11.706 12.9623C12.6905 11.9778 13.2437 10.6424 13.2437 9.25002C13.2437 6.00002 10.9937 3.50002 9.16865 1.68127L6.99365 6.25002L4.49365 4.58752Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path>
</svg> Featured</span>
        </p>

        


        <section>

            <ul>
                <li>
                    <a href="https://journal.hexmos.com/author/rijul/">
                        <img src="https://journal.hexmos.com/content/images/size/w100/2023/08/3a30bb804e1845504626b40d9fb136d2.jpeg" alt="Rijul Rajesh">
                    </a>
                </li>
            </ul>

            <div>
                
                <p><time datetime="2023-11-12">Nov 12, 2023</time>
                        <span><span>•</span> 13 min read</span>
                </p>
            </div>

        </section>

            <figure>
                <img srcset="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/a230a3ffafd791a0973337dbab3db132061e9d02787646049eb519aae1cb0f72.png 300w,
                            https://journal-wa6509js.s3.ap-south-1.amazonaws.com/a230a3ffafd791a0973337dbab3db132061e9d02787646049eb519aae1cb0f72.png 600w,
                            https://journal-wa6509js.s3.ap-south-1.amazonaws.com/a230a3ffafd791a0973337dbab3db132061e9d02787646049eb519aae1cb0f72.png 1000w,
                            https://journal-wa6509js.s3.ap-south-1.amazonaws.com/a230a3ffafd791a0973337dbab3db132061e9d02787646049eb519aae1cb0f72.png 2000w" sizes="(min-width: 1400px) 1400px, 92vw" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/a230a3ffafd791a0973337dbab3db132061e9d02787646049eb519aae1cb0f72.png" alt="GPU Survival Toolkit for the AI age: The bare minimum every developer must know">
            </figure>

    </header>

    <section>
        <!--kg-card-begin: html--><h3 id="why-cpu-knowledge-is-no-longer-enough">Why CPU Knowledge Is No Longer Enough</h3>

<p>In today's AI age, the majority of developers train in the CPU way. This knowledge has been part of our academics as well, so it's obvious to think and problem-solve in a <strong>CPU-oriented way</strong>.</p>

<p>However, the problem with CPUs is that they rely on a <strong>sequential architecture</strong>. In today's world, where we are dependent on numerous parallel tasks, CPUs are unable to work well in these scenarios.</p>

<p>Some problems faced by developers include:</p>

<h4 id="executing-parallel-tasks">Executing Parallel Tasks</h4>

<p>CPUs traditionally operate linearly, executing one instruction at a time. This limitation stems from the fact that CPUs typically feature a few powerful cores optimized for single-threaded performance.</p>

<p>When faced with multiple tasks, a CPU allocates its resources to address each task one after the other, leading to a sequential execution of instructions. This approach becomes inefficient in scenarios where numerous tasks need simultaneous attention.</p>

<p>While we make efforts to enhance CPU performance through techniques like multi-threading, the fundamental design philosophy of CPUs prioritizes sequential execution.</p>

<h4 id="running-ai-models-efficiently">Running AI Models Efficiently</h4>

<p>AI models, employing advanced architectures like transformers, leverage parallel processing to enhance performance. Unlike older <strong>recurrent neural networks (RNNs)</strong> that operate sequentially, modern transformers such as <strong>GPT</strong> can concurrently process multiple words, increasing efficiency and capability in training. Because when we train in parallel, it will result in bigger models, and bigger models will yield better outputs.</p>

<p>The concept of parallelism extends beyond natural language processing to other domains like <strong>image recognition</strong>. For instance, <a href="https://medium.com/analytics-vidhya/concept-of-alexnet-convolutional-neural-network-6e73b4f9ee30?ref=journal.hexmos.com">AlexNet</a>, an architecture in image recognition, demonstrates the power of parallel processing by processing different parts of an image simultaneously, allowing for accurate pattern identification.</p>

<p>However, CPUs, designed with a focus on single-threaded performance, struggle to fully exploit parallel processing potential. They face difficulties efficiently distributing and executing the numerous parallel computations required for intricate AI models.</p>

<p>As a result, the development of GPUs has become prevalent to address the specific needs of parallel processing in AI applications, unlocking higher efficiency and faster computation.</p>

<h4 id="how-gpu-driven-development-solves-these-issues">How GPU Driven Development Solves These Issues</h4>

<p><strong>Massive Parallelism With GPU Cores</strong></p>

<p>Engineers design GPUs with <strong>smaller, highly specialized cores</strong> compared to the <strong>larger, more powerful cores</strong> found in CPUs. This architecture allows GPUs to execute a multitude of parallel tasks simultaneously.</p>

<p>The high number of cores in a GPU are well-suited for workloads depending on parallelism, such as graphics rendering and complex mathematical computations.</p>

<p>We will soon demonstrate how using GPU parallelism can reduce the time taken for complex tasks.</p>

<p><img alt="GPUDemo1" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/ee0bdbd2103cbed5d0fa894432cc476065984dcd3921bb9158e608a50fe62f7b.png"></p>

<p><strong>Parallelism Used In AI Models</strong></p>

<p>AI models, particularly those built on deep learning frameworks like <a href="https://www.tensorflow.org/?ref=journal.hexmos.com">TensorFlow</a>, exhibit a high degree of parallelism. Neural network training involves numerous matrix operations, and GPUs, with their expansive core count, excel in parallelizing these operations. TensorFlow, along with other popular deep learning frameworks, optimizes to leverage GPU power for accelerating model training and inference.</p>

<p>We will show a demo soon how to train a neural network using the power of the GPU.</p>

<p><img alt="GPUDemo1" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/5078635f14fc266b48058cafe1f214608eecd89f0ddfebfc481df24704a7bba9.png"></p>

<h3 id="cpus-vs-gpus-whats-the-difference">CPUs Vs GPUs: What’s the Difference?</h3>

<h4 id="cpu">CPU</h4>

<p><strong>Sequential Architecture</strong></p>

<p>Central Processing Units (CPUs) are designed with a focus on sequential processing. They excel at executing a single set of instructions linearly.</p>

<p>CPUs are optimized for tasks that require high single-threaded performance, such as</p>

<ul>
<li>General-purpose computing</li>
<li>System operations</li>
<li>Handling complex algorithms that involve conditional branching</li>
</ul>

<p><strong>Limited Cores For Parallel Tasks</strong></p>

<p>CPUs feature a smaller number of cores, often in the range of <strong>2-16</strong> cores in consumer-grade processors. Each core is capable of handling its own set of instructions independently.</p>

<h4 id="gpu">GPU</h4>

<p><strong>Parallelized Architecture</strong></p>

<p>Graphics Processing Units (GPUs) are designed with a parallel architecture, making them highly efficient for parallel processing tasks.</p>

<p>This is beneficial for</p>

<ul>
<li>Rendering graphics</li>
<li>Performing complex mathematical calculations</li>
<li>Running parallelizable algorithms</li>
</ul>

<p>GPUs handle multiple tasks simultaneously by breaking them into smaller, parallel sub-tasks.</p>

<p><strong>Thousands Of Cores For Parallel Tasks</strong></p>

<p>Unlike CPUs, GPUs boast a significantly larger number of cores, often numbering in the thousands. These cores are organized into streaming multiprocessors (SMs) or similar structures.</p>

<p>The abundance of cores allows GPUs to process a massive amount of data concurrently, making them well-suited for parallelisable tasks, such as image and video processing, deep learning, and scientific simulations.</p>

<h3 id="aws-gpu-instances-a-beginners-guide">AWS GPU Instances: A Beginner's Guide</h3>

<p>Amazon Web Services (AWS) offers a variety of GPU instances used for things like machine learning.</p>

<p>Here are the different types of AWS GPU instances and their use cases:</p>

<p><strong>General-Purpose Gpu Instances</strong></p>

<ul>
<li>
<p><a href="https://aws.amazon.com/ec2/instance-types/p3/?ref=journal.hexmos.com">P3</a> and <a href="https://aws.amazon.com/ec2/instance-types/p4/?ref=journal.hexmos.com">P4</a> instances serve as versatile general-purpose GPU instances, well-suited for a broad spectrum of workloads.</p>
</li>
<li>
<p>These include machine learning training and inference, image processing, and video encoding. Their balanced capabilities make them a solid choice for diverse computational tasks.</p>
</li>
<li>
<p><strong>Pricing:</strong> The p3.2xlarge instance costs <strong>$3.06</strong> per hour.</p>
</li>
<li>This provides 1 <a href="https://www.nvidia.com/en-gb/data-center/tesla-v100/?ref=journal.hexmos.com">NVIDIA Tesla V100 GPU</a> of 16 GB GPU memory</li>
</ul>

<p><strong>Inference-optimized GPU instances</strong></p>

<ul>
<li>
<p>Inference is the process of running live data through a trained AI model to make a prediction or solve a task.</p>
</li>
<li>
<p><a href="https://aws.amazon.com/ec2/instance-types/p5/?ref=journal.hexmos.com">P5</a> and <a href="https://aws.amazon.com/ec2/instance-types/inf1/?ref=journal.hexmos.com">Inf1</a> instances specifically cater to machine learning inference, excelling in scenarios where low latency and cost efficiency are essential.</p>
</li>
<li>
<p><strong>Pricing:</strong> the p5.48xlarge instance costs <strong>$98.32</strong> per hour.</p>
</li>
<li>This provides 8 <a href="https://www.nvidia.com/en-in/data-center/h100/?ref=journal.hexmos.com">NVIDIA H100 GPUs</a> of 80 GB memory each, totalling upto 640 GB Video Memory.</li>
</ul>

<p><strong>Graphics-optimized GPU instances</strong></p>

<ul>
<li>
<p><a href="https://aws.amazon.com/ec2/instance-types/g4/?ref=journal.hexmos.com">G4 instances</a> instances are engineered to handle graphics-intensive tasks.</p>
</li>
<li>
<p>A video game developer might use a G4 instance to render 3D graphics for a video game.</p>
</li>
<li><strong>Pricing:</strong> g4dn.xlarge costs <strong>$0.526</strong> to run per hour.</li>
<li>Uses 1 <a href="https://www.nvidia.com/en-in/data-center/tesla-t4/?ref=journal.hexmos.com">NVIDIA T4 GPU</a> of 16 GB Memory.</li>
</ul>

<p><strong>Managed GPU Instances</strong></p>

<ul>
<li>
<p><a href="https://aws.amazon.com/sagemaker/?ref=journal.hexmos.com">Amazon SageMaker</a> is a managed service for machine learning. It provides access to a variety of GPU-powered instances, including P3, P4, and P5 instances.</p>
</li>
<li>
<p>SageMaker is a good choice for organizations that wants to begin machine learning easily without having to manage the underlying infrastructure.</p>
</li>
<li>
<p><a href="https://aws.amazon.com/sagemaker/pricing/?ref=journal.hexmos.com">Pricing of Amazon Sagemaker</a></p>
</li>
</ul>

<h3 id="using-nvidias-cuda-for-gpu-driven-development">Using Nvidia's CUDA for GPU-Driven Development</h3>

<h4 id="what-is-cuda">What Is Cuda?</h4>

<p><strong>CUDA</strong> is a parallel computing platform and programming model developed by NVIDIA, enabling developers to accelerate their applications by harnessing the power of GPU accelerators.</p>

<p>The Practical examples in the demo will use CUDA.</p>

<h4 id="how-to-setup-cuda-on-your-machine">How to Setup Cuda on Your Machine</h4>

<p>To setup CUDA on your machine you can follow these steps.</p>

<ul>
<li>Download <a href="https://developer.nvidia.com/cuda-downloads?ref=journal.hexmos.com">CUDA</a></li>
<li>From the above link download the base installer as well as the driver installer</li>
<li>Go to .bashrc in home folder</li>
<li>
<p>Add the following lines below</p>
</li>
<li>
<p><code>export PATH="/usr/local/cuda-12.3/bin:$PATH"</code></p>
</li>
<li>
<p><code>export LD_LIBRARY_PATH="/usr/local/cuda-12.3/lib64:$LD_LIBRARY_PATH"</code></p>
</li>
<li>
<p>Execute the following commands</p>
</li>
<li><code>sudo apt-get install cuda-toolkit</code></li>
<li>
<p><code>sudo apt-get install nvidia-gds</code></p>
</li>
<li>
<p>Reboot the system for the changes to take effect</p>
</li>
</ul>

<h4 id="basic-commands-to-use">Basic Commands to Use</h4>

<p>Once you have CUDA installed, here are some helpful commands.</p>

<p><code>lspci | grep VGA</code></p>

<p>The purpose of this command is to identify and list the GPUs in your system.
<img alt="Alt text" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/ea108a4de53720d8e4de22247f92b43481a000cfe41026826e52f4af020b9c0f.png"></p>

<p><code>nvidia-smi</code></p>

<p>It stands for "NVIDIA System Management Interface"
It provides detailed information about the NVIDIA GPUs in your system, including utilization, temperature, memory usage and more.</p>

<p><img alt="Alt text" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/b467adbefdfe4fced1552ca63134994c2924dc648955adb585c80d1a6356f10f.png"></p>

<p><code>sudo lshw -C display</code></p>

<p>The purpose is to provide detailed information about the display controllers in your system, including graphics cards.
<img alt="Alt text" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/0af5ca02e576f5da48a561ebffb4bd20e4051899cb1b1e69caca78aeff58cff7.png"></p>

<p><code>inxi -G</code></p>

<p>This command provides information about the graphics subsystem, including details about the GPU and the display.
<img alt="Alt text" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/8352bf05d3be3b8085e837de0f69f244ab6c34041c6b462cf78513fcae6373c0.png"></p>

<p><code>sudo hwinfo --gfxcard</code></p>

<p>Its purpose is to obtain detailed information about the graphics cards in your system.</p>

<p><img alt="Alt text" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/70fa1b931593c213a1a949dbc700d47cca2e933cee331d63e03e0806d6327baa.png"></p>

<h3 id="get-started-with-the-cuda-framework">Get Started with the Cuda Framework</h3>

<p>As we have installed the CUDA Framework, let's start executing operations that showcases its functionality.</p>

<h4 id="array-addition-problem">Array Addition Problem</h4>

<p>A suitable problem to demonstrate the parallelization of GPUs is the <strong>Array addition problem</strong>.</p>

<p>Consider the following arrays:</p>

<ul>
<li>
<p>Array A = [1,2,3,4,5,6]</p>
</li>
<li>
<p>Array B = [7,8,9,10,11,12]</p>
</li>
<li>
<p>We need to store the sum of each element and store it in Array C.</p>
</li>
<li>
<p>Like C = [1+7,2+8,3+9,4+10,5+11,6+12] = [8,10,12,14,16,18]</p>
</li>
<li>
<p>If the CPU is to execute such operation, it would be executing the operation like the below code.</p>
</li>
</ul>

<div><pre><span></span><span>#include</span><span> </span><span>&lt;stdio.h&gt;</span>
<span>int</span><span> </span><span>a</span><span>[]</span><span> </span><span>=</span><span> </span><span>{</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>,</span><span>4</span><span>,</span><span>5</span><span>,</span><span>6</span><span>};</span>
<span>int</span><span> </span><span>b</span><span>[]</span><span> </span><span>=</span><span> </span><span>{</span><span>7</span><span>,</span><span>8</span><span>,</span><span>9</span><span>,</span><span>10</span><span>,</span><span>11</span><span>,</span><span>12</span><span>};</span>
<span>int</span><span> </span><span>c</span><span>[</span><span>6</span><span>];</span>

<span>int</span><span> </span><span>main</span><span>()</span><span> </span><span>{</span>
<span>    </span><span>int</span><span> </span><span>N</span><span> </span><span>=</span><span> </span><span>6</span><span>;</span><span>  </span><span>// Number of elements</span>

<span>    </span><span>for</span><span> </span><span>(</span><span>int</span><span> </span><span>i</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span><span> </span><span>i</span><span> </span><span>&lt;</span><span> </span><span>N</span><span>;</span><span> </span><span>i</span><span>++</span><span>)</span><span> </span><span>{</span>
<span>        </span><span>c</span><span>[</span><span>i</span><span>]</span><span> </span><span>=</span><span> </span><span>a</span><span>[</span><span>i</span><span>]</span><span> </span><span>+</span><span> </span><span>b</span><span>[</span><span>i</span><span>];</span>
<span>    </span><span>}</span>

<span>    </span><span>for</span><span> </span><span>(</span><span>int</span><span> </span><span>i</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span><span> </span><span>i</span><span> </span><span>&lt;</span><span> </span><span>N</span><span>;</span><span> </span><span>i</span><span>++</span><span>)</span><span> </span><span>{</span>
<span>        </span><span>printf</span><span>(</span><span>"c[%d] = %d"</span><span>,</span><span> </span><span>i</span><span>,</span><span> </span><span>c</span><span>[</span><span>i</span><span>]);</span>
<span>    </span><span>}</span>

<span>    </span><span>return</span><span> </span><span>0</span><span>;</span>
<span>}</span>
</pre></div>

<p>The previous method involves traversing the array elements one by one and performing the additions sequentially. However, when dealing with a <strong>substantial volume of numbers</strong>, this approach becomes sluggish due to its <strong>sequential nature</strong>.</p>

<p>To address this limitation, GPUs offer a solution by <strong>parallelizing the addition process</strong>. Unlike CPUs, which execute operations one after the other, GPUs can concurrently perform multiple additions.</p>

<p>For instance, the operations 1+7, 2+8, 3+9, 4+10, 5+11 and 6+12 can be executed simultaneously through parallelization with the assistance of a GPU.</p>

<p>Utilizing CUDA, the code to achieve this parallelized addition is as follows:</p>

<p>We will use a kernel file (.cu) for the demonstration.</p>

<p>Let's go through the code one by one.</p>

<div><pre><span></span><span>__global__</span><span> </span><span>void</span><span> </span><span>vectorAdd</span><span>(</span><span>int</span><span>*</span><span> </span><span>a</span><span>,</span><span> </span><span>int</span><span>*</span><span> </span><span>b</span><span>,</span><span> </span><span>int</span><span>*</span><span> </span><span>c</span><span>)</span>
<span>{</span>
<span>    </span><span>int</span><span> </span><span>i</span><span> </span><span>=</span><span> </span><span>threadIdx</span><span>.</span><span>x</span><span>;</span>
<span>    </span><span>c</span><span>[</span><span>i</span><span>]</span><span> </span><span>=</span><span> </span><span>a</span><span>[</span><span>i</span><span>]</span><span> </span><span>+</span><span> </span><span>b</span><span>[</span><span>i</span><span>]</span><span>;</span>
<span>    </span><span>return</span><span>;</span>
<span>}</span>
</pre></div>

<ul>
<li>
<p><code>__global__</code> specifier indicates that this function is a kernel function, which will be called on the GPU.</p>
</li>
<li>
<p><code>vectorAdd</code> takes three integer pointers (a, b, and c) as arguments, representing vectors to be added.</p>
</li>
<li>
<p><code>threadIdx.x</code> retrieves the index of the current thread (in a one-dimensional grid).</p>
</li>
<li>
<p>The sum of the corresponding elements from vectors a and b is stored in vector c.</p>
</li>
</ul>

<p>Now lets go through the main function.</p>

<p>Pointers <code>cudaA</code>, <code>cudaB</code> and <code>cudaC</code> are created to point to memory on the GPU.</p>

<div><pre><span></span><span>// Uses CUDA to use functions that parallelly calculates the addition</span>
<span>int</span><span> </span><span>main</span><span>(){</span>
<span>    </span><span>int</span><span> </span><span>a</span><span>[]</span><span> </span><span>=</span><span> </span><span>{</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>};</span>
<span>    </span><span>int</span><span> </span><span>b</span><span>[]</span><span> </span><span>=</span><span> </span><span>{</span><span>4</span><span>,</span><span>5</span><span>,</span><span>6</span><span>};</span>
<span>    </span><span>int</span><span> </span><span>c</span><span>[</span><span>sizeof</span><span>(</span><span>a</span><span>)</span><span> </span><span>/</span><span> </span><span>sizeof</span><span>(</span><span>int</span><span>)]</span><span> </span><span>=</span><span> </span><span>{</span><span>0</span><span>};</span>
<span>    </span><span>// Create pointers into the GPU</span>
<span>    </span><span>int</span><span>*</span><span> </span><span>cudaA</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span>
<span>    </span><span>int</span><span>*</span><span> </span><span>cudaB</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span>
<span>    </span><span>int</span><span>*</span><span> </span><span>cudaC</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span>
</pre></div>

<p>Using <code>cudaMalloc</code>, memory is allocated on the GPU for the vectors cudaA, cudaB, and cudaC.</p>

<div><pre><span></span><span>// Allocate memory in the GPU</span>
<span>cudaMalloc</span><span>(</span><span>&amp;</span><span>cudaA</span><span>,</span><span>sizeof</span><span>(</span><span>a</span><span>));</span>
<span>cudaMalloc</span><span>(</span><span>&amp;</span><span>cudaB</span><span>,</span><span>sizeof</span><span>(</span><span>b</span><span>));</span>
<span>cudaMalloc</span><span>(</span><span>&amp;</span><span>cudaC</span><span>,</span><span>sizeof</span><span>(</span><span>c</span><span>));</span>
</pre></div>

<p>The content of vectors a and b is copied from the host to the GPU using <code>cudaMemcpy</code>.</p>

<div><pre><span></span><span>// Copy the vectors into the gpu</span>
<span>cudaMemcpy</span><span>(</span><span>cudaA</span><span>,</span><span> </span><span>a</span><span>,</span><span> </span><span>sizeof</span><span>(</span><span>a</span><span>),</span><span> </span><span>cudaMemcpyHostToDevice</span><span>);</span>
<span>cudaMemcpy</span><span>(</span><span>cudaB</span><span>,</span><span> </span><span>b</span><span>,</span><span> </span><span>sizeof</span><span>(</span><span>b</span><span>),</span><span> </span><span>cudaMemcpyHostToDevice</span><span>);</span>
</pre></div>

<p>The kernel function <code>vectorAdd</code> is launched with one block and a number of threads equal to the size of the vectors.</p>

<div><pre><span></span><span>// Launch the kernel with one block and a number of threads equal to the size of the vectors</span>
<span>vectorAdd</span><span> </span><span>&lt;&lt;&lt;</span><span>1</span><span>,</span><span> </span><span>sizeof</span><span>(</span><span>a</span><span>)</span><span> </span><span>/</span><span> </span><span>sizeof</span><span>(</span><span>a</span><span>[</span><span>0</span><span>])</span><span>&gt;&gt;&gt;</span><span> </span><span>(</span><span>cudaA</span><span>,</span><span> </span><span>cudaB</span><span>,</span><span> </span><span>cudaC</span><span>);</span>
</pre></div>

<p>The result vector <code>cudaC</code> is copied from the GPU back to the host.</p>

<div><pre><span></span><span>// Copy the result vector back to the host</span>
<span>cudaMemcpy</span><span>(</span><span>c</span><span>,</span><span> </span><span>cudaC</span><span>,</span><span> </span><span>sizeof</span><span>(</span><span>c</span><span>),</span><span> </span><span>cudaMemcpyDeviceToHost</span><span>);</span>
</pre></div>

<p>We can then print the results as usual</p>

<div><pre><span></span><span>    </span><span>// Print the result</span>
<span>    </span><span>for</span><span> </span><span>(</span><span>int</span><span> </span><span>i</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span><span> </span><span>i</span><span> </span><span>&lt;</span><span> </span><span>sizeof</span><span>(</span><span>c</span><span>)</span><span> </span><span>/</span><span> </span><span>sizeof</span><span>(</span><span>int</span><span>);</span><span> </span><span>i</span><span>++</span><span>)</span>
<span>    </span><span>{</span>
<span>        </span><span>printf</span><span>(</span><span>"c[%d] = %d"</span><span>,</span><span> </span><span>i</span><span>,</span><span> </span><span>c</span><span>[</span><span>i</span><span>]);</span>
<span>    </span><span>}</span>

<span>    </span><span>return</span><span> </span><span>0</span><span>;</span>
<span>}</span>
</pre></div>

<p>For executing this code, we will use <code>nvcc</code> command.</p>

<p>We will get the output as</p>

<p><img alt="GPU Output" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/144c2193b0d5ad71eb7bd4da490534fb278ed174df6ec8c6411b039f16757116.png"></p>

<p>Here's the <a href="https://github.com/RijulTP/GPUToolkit/tree/main/array-addition?ref=journal.hexmos.com">full code</a> for your reference.</p>

<h4 id="optimize-image-generation-in-python-using-the-gpu">Optimize Image Generation in Python Using the GPU</h4>

<ul>
<li>
<p>This section explores the optimization of performance-intensive tasks, such as image generation, using GPU processing.</p>
</li>
<li>
<p><strong>Mandelbrot set</strong> is a mathematical construct that forms intricate visual patterns based on the behavior of specific numbers in a prescribed equation. Generating one is a resource intensive operation.</p>
</li>
<li>
<p>In the following code snippet, you can observe the conventional method of generating a Mandelbrot set using CPU processing, which is slow.</p>
</li>
</ul>

<div><pre><span></span><span># Import necessary libraries</span>
<span>from</span> <span>matplotlib</span> <span>import</span> <span>pyplot</span> <span>as</span> <span>plt</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>from</span> <span>pylab</span> <span>import</span> <span>imshow</span><span>,</span> <span>show</span>
<span>from</span> <span>timeit</span> <span>import</span> <span>default_timer</span> <span>as</span> <span>timer</span>

<span># Function to calculate the Mandelbrot set for a given point (x, y)</span>
<span>def</span> <span>mandel</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>,</span> <span>max_iters</span><span>):</span>
    <span>c</span> <span>=</span> <span>complex</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>)</span>
    <span>z</span> <span>=</span> <span>0.0</span><span>j</span>
    <span># Iterate to check if the point is in the Mandelbrot set</span>
    <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>max_iters</span><span>):</span>
        <span>z</span> <span>=</span> <span>z</span><span>*</span><span>z</span> <span>+</span> <span>c</span>
        <span>if</span> <span>(</span><span>z</span><span>.</span><span>real</span><span>*</span><span>z</span><span>.</span><span>real</span> <span>+</span> <span>z</span><span>.</span><span>imag</span><span>*</span><span>z</span><span>.</span><span>imag</span><span>)</span> <span>&gt;=</span> <span>4</span><span>:</span>
            <span>return</span> <span>i</span>
    <span># If within the maximum iterations, consider it part of the set</span>
    <span>return</span> <span>max_iters</span>

<span># Function to create the Mandelbrot fractal within a specified region</span>
<span>def</span> <span>create_fractal</span><span>(</span><span>min_x</span><span>,</span> <span>max_x</span><span>,</span> <span>min_y</span><span>,</span> <span>max_y</span><span>,</span> <span>image</span><span>,</span> <span>iters</span><span>):</span>
    <span>height</span> <span>=</span> <span>image</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span>
    <span>width</span> <span>=</span> <span>image</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]</span>

    <span># Calculate pixel sizes based on the specified region</span>
    <span>pixel_size_x</span> <span>=</span> <span>(</span><span>max_x</span> <span>-</span> <span>min_x</span><span>)</span> <span>/</span> <span>width</span>
    <span>pixel_size_y</span> <span>=</span> <span>(</span><span>max_y</span> <span>-</span> <span>min_y</span><span>)</span> <span>/</span> <span>height</span>

    <span># Iterate over each pixel in the image and compute the Mandelbrot value</span>
    <span>for</span> <span>x</span> <span>in</span> <span>range</span><span>(</span><span>width</span><span>):</span>
        <span>real</span> <span>=</span> <span>min_x</span> <span>+</span> <span>x</span> <span>*</span> <span>pixel_size_x</span>
        <span>for</span> <span>y</span> <span>in</span> <span>range</span><span>(</span><span>height</span><span>):</span>
            <span>imag</span> <span>=</span> <span>min_y</span> <span>+</span> <span>y</span> <span>*</span> <span>pixel_size_y</span>
            <span>color</span> <span>=</span> <span>mandel</span><span>(</span><span>real</span><span>,</span> <span>imag</span><span>,</span> <span>iters</span><span>)</span>
            <span>image</span><span>[</span><span>y</span><span>,</span> <span>x</span><span>]</span> <span>=</span> <span>color</span>

<span># Create a blank image array for the Mandelbrot set</span>
<span>image</span> <span>=</span> <span>np</span><span>.</span><span>zeros</span><span>((</span><span>1024</span><span>,</span> <span>1536</span><span>),</span> <span>dtype</span><span>=</span><span>np</span><span>.</span><span>uint8</span><span>)</span>

<span># Record the start time for performance measurement</span>
<span>start</span> <span>=</span> <span>timer</span><span>()</span>

<span># Generate the Mandelbrot set within the specified region and iterations</span>
<span>create_fractal</span><span>(</span><span>-</span><span>2.0</span><span>,</span> <span>1.0</span><span>,</span> <span>-</span><span>1.0</span><span>,</span> <span>1.0</span><span>,</span> <span>image</span><span>,</span> <span>20</span><span>)</span>

<span># Calculate the time taken to create the Mandelbrot set</span>
<span>dt</span> <span>=</span> <span>timer</span><span>()</span> <span>-</span> <span>start</span>

<span># Print the time taken to generate the Mandelbrot set</span>
<span>print</span><span>(</span><span>"Mandelbrot created in </span><span>%f</span><span> s"</span> <span>%</span> <span>dt</span><span>)</span>

<span># Display the Mandelbrot set using matplotlib</span>
<span>imshow</span><span>(</span><span>image</span><span>)</span>
<span>show</span><span>()</span>
</pre></div>

<p>The above code produces the output in <code>4.07</code> seconds.</p>

<p><img alt="Mandelbrot without GPU" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/14af8fd709215ad96688a3364deefea9cfc2fa13497810587106cef04c5a413c.png"></p>

<ul>
<li>
<p>To make this faster, we can parallelize the code with GPU by using <a href="https://numba.pydata.org/?ref=journal.hexmos.com">Numba library</a>, Lets see how its done.</p>
</li>
<li>
<p>We will import Just-In-Time compilation, CUDA for GPU acceleration, and other utilities from numba</p>
</li>
</ul>

<div><pre><span></span><span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>from</span> <span>numba</span> <span>import</span> <span>jit</span><span>,</span> <span>cuda</span><span>,</span> <span>uint32</span><span>,</span> <span>f8</span><span>,</span> <span>uint8</span>
<span>from</span> <span>pylab</span> <span>import</span> <span>imshow</span><span>,</span> <span>show</span>
<span>from</span> <span>timeit</span> <span>import</span> <span>default_timer</span> <span>as</span> <span>timer</span>
</pre></div>

<ul>
<li>The <code>@jit</code> decorator signals Numba to perform <strong>Just-In-Time compilation</strong>, translating the Python code into machine code for improved execution speed.</li>
</ul>

<div><pre><span></span><span>@jit</span>
<span>def</span> <span>mandel</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>,</span> <span>max_iters</span><span>):</span>
    <span>c</span> <span>=</span> <span>complex</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>)</span>
    <span>z</span> <span>=</span> <span>0.0</span><span>j</span>
    <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>max_iters</span><span>):</span>
        <span>z</span> <span>=</span> <span>z</span><span>*</span><span>z</span> <span>+</span> <span>c</span>
        <span>if</span> <span>(</span><span>z</span><span>.</span><span>real</span><span>*</span><span>z</span><span>.</span><span>real</span> <span>+</span> <span>z</span><span>.</span><span>imag</span><span>*</span><span>z</span><span>.</span><span>imag</span><span>)</span> <span>&gt;=</span> <span>4</span><span>:</span>
            <span>return</span> <span>i</span>

    <span>return</span> <span>max_iters</span>

<span>@jit</span>
<span>def</span> <span>create_fractal</span><span>(</span><span>min_x</span><span>,</span> <span>max_x</span><span>,</span> <span>min_y</span><span>,</span> <span>max_y</span><span>,</span> <span>image</span><span>,</span> <span>iters</span><span>):</span>
    <span>height</span> <span>=</span> <span>image</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span>
    <span>width</span> <span>=</span> <span>image</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]</span>

    <span>pixel_size_x</span> <span>=</span> <span>(</span><span>max_x</span> <span>-</span> <span>min_x</span><span>)</span> <span>/</span> <span>width</span>
    <span>pixel_size_y</span> <span>=</span> <span>(</span><span>max_y</span> <span>-</span> <span>min_y</span><span>)</span> <span>/</span> <span>height</span>

    <span>for</span> <span>x</span> <span>in</span> <span>range</span><span>(</span><span>width</span><span>):</span>
        <span>real</span> <span>=</span> <span>min_x</span> <span>+</span> <span>x</span> <span>*</span> <span>pixel_size_x</span>
        <span>for</span> <span>y</span> <span>in</span> <span>range</span><span>(</span><span>height</span><span>):</span>
            <span>imag</span> <span>=</span> <span>min_y</span> <span>+</span> <span>y</span> <span>*</span> <span>pixel_size_y</span>
            <span>color</span> <span>=</span> <span>mandel</span><span>(</span><span>real</span><span>,</span> <span>imag</span><span>,</span> <span>iters</span><span>)</span>
            <span>image</span><span>[</span><span>y</span><span>,</span> <span>x</span><span>]</span> <span>=</span> <span>color</span>
</pre></div>

<ul>
<li><code>mandel_gpu</code> is a GPU-compatible version of the mandel function created using cuda.jit. This allows the mandel logic to be offloaded to the GPU.</li>
<li>This is done by using <code>@cuda.jit</code> decorator along with specifying the data types (f8 for float, uint32 for unsigned integer) for the function arguments.</li>
<li>The <code>device=True</code> argument indicates that this function will run on the GPU.</li>
</ul>

<div><pre><span></span><span>mandel_gpu</span> <span>=</span> <span>cuda</span><span>.</span><span>jit</span><span>((</span><span>f8</span><span>,</span> <span>f8</span><span>,</span> <span>uint32</span><span>),</span> <span>device</span><span>=</span><span>True</span><span>)(</span><span>mandel</span><span>)</span>
</pre></div>

<ul>
<li>The mandel_kernel function is defined to be executed on the CUDA GPU. It is responsible for parallelizing the Mandelbrot set generation across GPU threads.</li>
</ul>

<div><pre><span></span><span>@cuda</span><span>.</span><span>jit</span><span>((</span><span>f8</span><span>,</span> <span>f8</span><span>,</span> <span>f8</span><span>,</span> <span>f8</span><span>,</span> <span>uint8</span><span>[:,:],</span> <span>uint32</span><span>))</span>
<span>def</span> <span>mandel_kernel</span><span>(</span><span>min_x</span><span>,</span> <span>max_x</span><span>,</span> <span>min_y</span><span>,</span> <span>max_y</span><span>,</span> <span>image</span><span>,</span> <span>iters</span><span>):</span>
    <span>height</span> <span>=</span> <span>image</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span>
    <span>width</span> <span>=</span> <span>image</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]</span>

    <span>pixel_size_x</span> <span>=</span> <span>(</span><span>max_x</span> <span>-</span> <span>min_x</span><span>)</span> <span>/</span> <span>width</span>
    <span>pixel_size_y</span> <span>=</span> <span>(</span><span>max_y</span> <span>-</span> <span>min_y</span><span>)</span> <span>/</span> <span>height</span>

    <span>startX</span><span>,</span> <span>startY</span> <span>=</span> <span>cuda</span><span>.</span><span>grid</span><span>(</span><span>2</span><span>)</span>
    <span>gridX</span> <span>=</span> <span>cuda</span><span>.</span><span>gridDim</span><span>.</span><span>x</span> <span>*</span> <span>cuda</span><span>.</span><span>blockDim</span><span>.</span><span>x</span>
    <span>gridY</span> <span>=</span> <span>cuda</span><span>.</span><span>gridDim</span><span>.</span><span>y</span> <span>*</span> <span>cuda</span><span>.</span><span>blockDim</span><span>.</span><span>y</span>

    <span>for</span> <span>x</span> <span>in</span> <span>range</span><span>(</span><span>startX</span><span>,</span> <span>width</span><span>,</span> <span>gridX</span><span>):</span>
        <span>real</span> <span>=</span> <span>min_x</span> <span>+</span> <span>x</span> <span>*</span> <span>pixel_size_x</span>
        <span>for</span> <span>y</span> <span>in</span> <span>range</span><span>(</span><span>startY</span><span>,</span> <span>height</span><span>,</span> <span>gridY</span><span>):</span>
            <span>imag</span> <span>=</span> <span>min_y</span> <span>+</span> <span>y</span> <span>*</span> <span>pixel_size_y</span>
            <span>image</span><span>[</span><span>y</span><span>,</span> <span>x</span><span>]</span> <span>=</span> <span>mandel_gpu</span><span>(</span><span>real</span><span>,</span> <span>imag</span><span>,</span> <span>iters</span><span>)</span>
</pre></div>

<p>The above code gets executed in <code>0.43 seconds</code>. Which is a lot faster the CPU Based code we had earlier.</p>

<p><img alt="Mandelbrot without GPU" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/cff7881a179a0a27ce03882b3f75a8c8d2a984fe308c84e87bd0446c8871452d.png"></p>

<p>Here's the <a href="https://github.com/RijulTP/GPUToolkit/tree/main/mandelbrot?ref=journal.hexmos.com">full code</a> for your reference.</p>

<h4 id="training-a-cat-vs-dog-neural-network-using-the-gpu">Training a Cat VS Dog Neural Network Using the GPU</h4>

<p>One of the hot topics we see nowadays is how GPUs are getting used in AI, So to demonstrate that we will be creating a <strong>neural network</strong> to differentiate between cats and dogs.</p>

<p><strong>Prerequisites</strong></p>

<ul>
<li>CUDA</li>
<li>
<p>Tensorflow -&gt; Can be installed via
  <code>pip install tensorflow[and-cuda]</code></p>
</li>
<li>
<p>We will use a data set of cats and dogs from <a href="https://www.kaggle.com/competitions/dogs-vs-cats/overview?ref=journal.hexmos.com">kaggle</a></p>
</li>
<li>
<p>Once you have downloaded it, Unzip them, organize the pictures of cats and dogs in the training folder into different subfolders, Like so.</p>
</li>
</ul>

<p><img alt="CNN File Structure" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/47b0cc05fa99283bd8dcd39a801809bdf5521a285df558c1436460ddf4d1ebdd.png"></p>

<p>This is the code we will use for training and using the Cat vs Dog Model.</p>

<p>The below code uses a convolutional neural network, you can <a href="https://www.analyticsvidhya.com/blog/2021/06/beginner-friendly-project-cat-and-dog-classification-using-cnn/?ref=journal.hexmos.com">read more details about it</a></p>

<p><strong>Importing Libraries</strong></p>

<ul>
<li>pandas and numpy for data manipulation.</li>
<li>Sequential for creating a linear stack of layers in the neural network.</li>
<li>Convolution2D, MaxPooling2D, Dense, and Flatten are layers used in building the Convolutional Neural Network (CNN).</li>
<li>ImageDataGenerator for real-time data augmentation during training.</li>
</ul>

<div><pre><span></span><span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>from</span> <span>keras.models</span> <span>import</span> <span>Sequential</span>
<span>from</span> <span>keras.layers</span> <span>import</span> <span>Convolution2D</span><span>,</span> <span>MaxPooling2D</span><span>,</span> <span>Dense</span><span>,</span> <span>Flatten</span>
<span>from</span> <span>keras.preprocessing.image</span> <span>import</span> <span>ImageDataGenerator</span>
</pre></div>

<p><strong>Initializing the Convolutional Neural Network</strong></p>

<div><pre><span></span><span>classifier</span> <span>=</span> <span>Sequential</span><span>()</span>
</pre></div>

<p><strong>Loading the data for training</strong></p>

<div><pre><span></span><span>train_datagen</span> <span>=</span> <span>ImageDataGenerator</span><span>(</span>
    <span>rescale</span><span>=</span><span>1.</span><span>/</span><span>255</span><span>,</span>
    <span>shear_range</span><span>=</span><span>0.2</span><span>,</span>
    <span>zoom_range</span><span>=</span><span>0.2</span><span>,</span>
    <span>horizontal_flip</span><span>=</span><span>True</span>
<span>)</span>
<span>test_datagen</span> <span>=</span> <span>ImageDataGenerator</span><span>(</span><span>rescale</span><span>=</span><span>1.</span><span>/</span><span>255</span><span>)</span>

<span>training_set</span> <span>=</span> <span>train_datagen</span><span>.</span><span>flow_from_directory</span><span>(</span>
    <span>'./training_set'</span><span>,</span>
    <span>target_size</span><span>=</span><span>(</span><span>64</span><span>,</span> <span>64</span><span>),</span>
    <span>batch_size</span><span>=</span><span>32</span><span>,</span>
    <span>class_mode</span><span>=</span><span>'binary'</span>
<span>)</span>

<span>test_set</span> <span>=</span> <span>test_datagen</span><span>.</span><span>flow_from_directory</span><span>(</span>
    <span>'./test_set'</span><span>,</span>
    <span>target_size</span><span>=</span><span>(</span><span>64</span><span>,</span> <span>64</span><span>),</span>
    <span>batch_size</span><span>=</span><span>32</span><span>,</span>
    <span>class_mode</span><span>=</span><span>'binary'</span>
<span>)</span>
</pre></div>

<p><strong>Building the CNN Architecture</strong></p>

<div><pre><span></span><span>classifier</span><span>.</span><span>add</span><span>(</span><span>Convolution2D</span><span>(</span><span>32</span><span>,</span> <span>3</span><span>,</span> <span>3</span><span>,</span> <span>input_shape</span><span>=</span><span>(</span><span>64</span><span>,</span> <span>64</span><span>,</span> <span>3</span><span>),</span> <span>activation</span><span>=</span><span>'relu'</span><span>))</span>
<span>classifier</span><span>.</span><span>add</span><span>(</span><span>MaxPooling2D</span><span>(</span><span>pool_size</span><span>=</span><span>(</span><span>2</span><span>,</span> <span>2</span><span>)))</span>
<span>classifier</span><span>.</span><span>add</span><span>(</span><span>Flatten</span><span>())</span>
<span>classifier</span><span>.</span><span>add</span><span>(</span><span>Dense</span><span>(</span><span>units</span><span>=</span><span>128</span><span>,</span> <span>activation</span><span>=</span><span>'relu'</span><span>))</span>
<span>classifier</span><span>.</span><span>add</span><span>(</span><span>Dense</span><span>(</span><span>units</span><span>=</span><span>1</span><span>,</span> <span>activation</span><span>=</span><span>'sigmoid'</span><span>))</span>
</pre></div>

<p><strong>Compiling the model</strong></p>

<div><pre><span></span><span>classifier</span><span>.</span><span>compile</span><span>(</span><span>optimizer</span><span>=</span><span>'adam'</span><span>,</span> <span>loss</span><span>=</span><span>'binary_crossentropy'</span><span>,</span> <span>metrics</span><span>=</span><span>[</span><span>'accuracy'</span><span>])</span>
</pre></div>

<p><strong>Training the model</strong></p>

<div><pre><span></span><span>classifier</span><span>.</span><span>fit</span><span>(</span><span>training_set</span><span>,</span> <span>epochs</span><span>=</span><span>25</span><span>,</span> <span>validation_data</span><span>=</span><span>test_set</span><span>,</span> <span>validation_steps</span><span>=</span><span>2000</span><span>)</span>
<span>classifier</span><span>.</span><span>save</span><span>(</span><span>'trained_model.h5'</span><span>)</span>
</pre></div>

<p>Once we have trained the model, The model is stored in a .h5 file using <code>classifier.save</code></p>

<p>In the below code, we will use this <code>trained_model.h5</code> file to recognize cats and dogs.</p>

<div><pre><span></span><span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>from</span> <span>keras.models</span> <span>import</span> <span>load_model</span>
<span>import</span> <span>keras.utils</span> <span>as</span> <span>image</span>

<span>def</span> <span>predict_image</span><span>(</span><span>imagepath</span><span>,</span> <span>classifier</span><span>):</span>
    <span>predict</span> <span>=</span> <span>image</span><span>.</span><span>load_img</span><span>(</span><span>imagepath</span><span>,</span> <span>target_size</span><span>=</span><span>(</span><span>64</span><span>,</span> <span>64</span><span>))</span>
    <span>predict_modified</span> <span>=</span> <span>image</span><span>.</span><span>img_to_array</span><span>(</span><span>predict</span><span>)</span>
    <span>predict_modified</span> <span>=</span> <span>predict_modified</span> <span>/</span> <span>255</span>
    <span>predict_modified</span> <span>=</span> <span>np</span><span>.</span><span>expand_dims</span><span>(</span><span>predict_modified</span><span>,</span> <span>axis</span><span>=</span><span>0</span><span>)</span>
    <span>result</span> <span>=</span> <span>classifier</span><span>.</span><span>predict</span><span>(</span><span>predict_modified</span><span>)</span>

    <span>if</span> <span>result</span><span>[</span><span>0</span><span>][</span><span>0</span><span>]</span> <span>&gt;=</span> <span>0.5</span><span>:</span>
        <span>prediction</span> <span>=</span> <span>'dog'</span>
        <span>probability</span> <span>=</span> <span>result</span><span>[</span><span>0</span><span>][</span><span>0</span><span>]</span>
        <span>print</span><span>(</span><span>"Probability = "</span> <span>+</span> <span>str</span><span>(</span><span>probability</span><span>))</span>
        <span>print</span><span>(</span><span>"Prediction = "</span> <span>+</span> <span>prediction</span><span>)</span>
    <span>else</span><span>:</span>
        <span>prediction</span> <span>=</span> <span>'cat'</span>
        <span>probability</span> <span>=</span> <span>1</span> <span>-</span> <span>result</span><span>[</span><span>0</span><span>][</span><span>0</span><span>]</span>
        <span>print</span><span>(</span><span>"Probability = "</span> <span>+</span> <span>str</span><span>(</span><span>probability</span><span>))</span>
        <span>print</span><span>(</span><span>"Prediction = "</span> <span>+</span> <span>prediction</span><span>)</span>

<span># Load the trained model</span>
<span>loaded_classifier</span> <span>=</span> <span>load_model</span><span>(</span><span>'trained_model.h5'</span><span>)</span>

<span># Example usage</span>
<span>dog_image</span> <span>=</span> <span>"dog.jpg"</span>
<span>predict_image</span><span>(</span><span>dog_image</span><span>,</span> <span>loaded_classifier</span><span>)</span>

<span>cat_image</span> <span>=</span> <span>"cat.jpg"</span>
<span>predict_image</span><span>(</span><span>cat_image</span><span>,</span> <span>loaded_classifier</span><span>)</span>
</pre></div>

<p>Let's see the output
<img alt="Alt text" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/d546542af4055bc7163bc49055d5a623a44ad0cc3022d02d0aaa791b9a83d75b.png"></p>

<p>Here's the <a href="https://github.com/RijulTP/GPUToolkit/tree/main/neural-network?ref=journal.hexmos.com">full code</a> for your reference</p>

<h3 id="conclusion">Conclusion</h3>

<p>In the upcoming AI age, GPUs are not a thing to be ignored, We should be more aware of its capabilities.</p>

<p>As we transition from traditional <strong>sequential algorithms</strong> to increasingly prevalent <strong>parallelized algorithms</strong>, GPUs emerge as indispensable tools that empower the acceleration of complex computations. The parallel processing prowess of GPUs is particularly advantageous in handling the massive datasets and intricate neural network architectures inherent to artificial intelligence and machine learning tasks.</p>

<p>Furthermore, the role of GPUs extends beyond traditional machine learning domains, finding applications in scientific research, simulations, and data-intensive tasks. The parallel processing capabilities of GPUs have proven instrumental in addressing challenges across diverse fields, ranging from drug discovery and climate modelling to financial simulations.</p>

<h3 id="reference">Reference</h3>

<ul>
<li><a href="https://noahgift.github.io/cloud-data-analysis-at-scale/topics/end-of-moores-law.html?ref=journal.hexmos.com">Using Numba for mandelbrot generation</a></li>
<li><a href="https://www.analyticsvidhya.com/blog/2021/06/beginner-friendly-project-cat-and-dog-classification-using-cnn/?ref=journal.hexmos.com">Using Convolutional Neural Networks</a></li>
</ul>

<p><a href="https://twitter.com/HexmosTech?ref=journal.hexmos.com"><img alt="Twitter" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/e706462dc4b473f96955889657e3893beca1e6cba15daa89dca171d732709b87.png"></a></p>

<p><a href="https://hexmos.com/?ref=journal.hexmos.com"><img alt="Hexmos" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/62b98356b4386f9c312f586af9c3606f9bd67f7116b4031c1bf2f5fb0fc73e0a.png"></a></p>

<p><a href="https://news.ycombinator.com/item?id=38240421&amp;ref=journal.hexmos.com">Hackernews post</a></p>

<p><a href="https://www.linkedin.com/feed/update/urn:li:activity:7129475708971618305?ref=journal.hexmos.com">Linkedin post</a></p><!--kg-card-end: html-->
    </section>


        
</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple might have to pay that €13B EU tax bill after all (126 pts)]]></title>
            <link>https://www.theregister.com/2023/11/11/apple_tax_bill_hiring/</link>
            <guid>38240363</guid>
            <pubDate>Sun, 12 Nov 2023 14:31:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/11/11/apple_tax_bill_hiring/">https://www.theregister.com/2023/11/11/apple_tax_bill_hiring/</a>, See on <a href="https://news.ycombinator.com/item?id=38240363">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Apple managed to escape a whopping €13 billion ($13.9 billion) tax bill in the European Union a few years ago, though now the advocate general of the Court of Justice of the EU (CJEU) is asking judges to take another look.&nbsp;</p>
<p><a href="https://curia.europa.eu/jcms/upload/docs/application/pdf/2023-11/cp230171en.pdf" rel="nofollow">According</a> [PDF] to the CJEU's Advocate General Giovanni Pitruzzella, a <a href="https://www.theregister.com/2020/07/15/apple_13bn_irish_tax_ruling_overturned/">2020 ruling</a> that absolved Apple of the expense should be set aside due to "a series of errors in law" when it made the ruling.</p>
<p>"The General Court failed to assess correctly the substance and consequences of certain methodological errors," the AG's office said.</p>

    

<p>For those having trouble recalling the nature of the disagreement, it reaches back a few years, beginning with a decision in 2018 that told Apple to hand over the aforementioned €13 billion to Irish tax officials after the European Commission <a href="https://www.theregister.com/2018/09/19/apple_alleged_state_aid_ireland/">decided</a> Apple and Irish authorities had together broken state aid rules.</p>

        


        

<p>Ireland, where Apple has its European headquarters, is known for its favorable tax rules that have attracted a number of large US-based tech companies to set up shop on the Emerald Isle. Apple, EU officials report, split itself into two entities – Apple Sales International (ASI) and Apple Operations International (AOE) – after obtaining permission from Irish tax authorities.&nbsp;</p>
<p>Those officials gave that permission in two rulings issued in 1991 and 2007, the AG's office said. In 2016, the European Commission figured those two rulings allowed Apple to exclude profits derived from intellectual property licenses held by ASI and AOE. That meant Apple didn't have to pay as much tax in Europe as one might expect, and the EC was OK with that at the time.</p>

        

<p>Then, as we said, in 2018, the commission had a change of heart, felt rules had been broken, and wanted that €13 billion in tax from Apple.</p>
<p>Fast-forward to 2020, and the General Court of the European Union decided Apple didn't actually need to pay the tax due to the arrangement the iPhone maker had in Ireland seemingly being above board. We got a hint of how the EC planned to appeal against that general court decision, and extract billions from Apple, <a href="https://www.theregister.com/2021/02/01/european_commission_outlines_its_appeal/">in 2021</a>, and the filing by Pitruzzella's office makes largely the same argument.</p>
<p>Whether Apple will end up having to cough up the cash again (a considerable amount - the iGiant's <a href="https://www.apple.com/newsroom/2023/11/apple-reports-fourth-quarter-results/" rel="nofollow">calendar Q3 profit</a> this year amounted to $23 billion) is unknown. As the AG's office notes, its opinions aren't binding on the CJEU, and will require the court to review the case and issue a new decision.&nbsp;</p>
<h3>US hiring discrimination charges mean pocket-change payout for Apple</h3>
<p>The iMaker will also cough up $25 million (with an M) the US Department of Justice <a href="https://www.justice.gov/opa/pr/justice-department-secures-25-million-landmark-agreement-apple-resolve-employment" rel="nofollow">announced</a> this week, settling claims the tech titan "illegally discriminated in hiring and recruitment against&nbsp;US citizens and certain non-US citizens whose permission to live in and work in the United States does not expire."</p>
<p>According to the DoJ, Apple violated the Immigration and Nationality Act (<a href="https://www.uscis.gov/laws-and-policy/legislation/immigration-and-nationality-act" rel="nofollow">INA</a>) when recruiting for jobs that fell under the permanent labor certification program (<a href="https://www.dol.gov/agencies/eta/foreign-labor/programs/permanent" rel="nofollow">PERM</a>), a US Department of Labor scheme that allows employers to sponsor workers for permanent residence status, provided program requirements are met. Among those requirements are rules that employers can't illegally discriminate in hiring or recruitment based on citizenship or immigration status.&nbsp;</p>

        

<p>According to the DoJ, that's just what Apple did.&nbsp;</p>
<ul>

<li><a href="https://www.theregister.com/2023/11/02/apple_batterygate_uk/">Batterygate bound for Blighty as UK court approves billion-dollar Apple compensation case</a></li>

<li><a href="https://www.theregister.com/2023/10/06/apple_sales_wages_settlement/">Apple pays $500K to make sales bods' complaint about wage theft go away</a></li>

<li><a href="https://www.theregister.com/2023/10/11/microsoft_irs_tax_bill/">Hell no, we won't pay, says Microsoft as Uncle Sam sends $29B bill for back taxes</a></li>

<li><a href="https://www.theregister.com/2023/01/28/apple_sued_privacy/">Apple sued for promising privacy, failing at it</a></li>
</ul>
<p>"The department's investigation found that Apple did not advertise positions Apple sought to fill through the PERM program on its external job website … [and] required all PERM position applicants to mail paper applications," the DoJ said.&nbsp;</p>
<p>"These less effective recruitment procedures nearly always resulted in few or no applications to PERM positions from applicants whose permission to work does not expire."&nbsp;</p>
<p>Basically, if a US company wants to sponsor an employee's green card, so that the staffer can get permanent residency in America, the biz usually (but not always) has to apply for a PERM certificate from the Dept of Labor so that the foreign worker's immigration process can be completed. To get that PERM cert, the business has to demonstrate that no US citizen or someone already with a green card is available and qualified to do that employee's role in America and thus the foreigner needs permanent status in the country to fill the position.</p>
<p>By demonstrate, we mean that the employer is expected to re-advertise that foreign staffer's job widely so that US persons have a chance to come forward to show they ought to have it instead; if you put barriers up, such as only accepting mailed applications or hiding the job ads in little-seen corners of the internet, it's not a fair situation, and that makes Uncle Sam unhappy. And the government is upset at the iPhone giant doing stuff like that, allegedly.</p>
<p>We reached out to Apple for comment, and haven't heard back. Cook and Co did <a href="https://www.wsj.com/us-news/law/apple-to-pay-up-to-25-million-to-settle-u-s-discrimination-charges-3f81fad4?st=df2t03ajuss4fo1&amp;reflink=article_copyURL_share" rel="nofollow">tell</a> the Wall Street Journal that its violation of government standards was an accident.&nbsp;</p>
<p>"When we realized we had unintentionally not been following the DOJ standard, we agreed to a settlement addressing their concerns," an Apple spokesperson said. "We have implemented a robust remediation plan to comply with the requirements of various government agencies as we continue to hire American workers and grow in the US."</p>
<p>Apple's payout will be split between $6.75 million in civil penalties and an $18.25 million back pay fund for discrimination victims. As noted above, Apple made $23 billion in profit in one quarter alone. That $25 million fine amounts to a tenth of one percent of its Q3 net income. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GitHub Actions Are a Problem (133 pts)]]></title>
            <link>https://felix-knorr.net/posts/2023-11-11-github-actions.html</link>
            <guid>38240278</guid>
            <pubDate>Sun, 12 Nov 2023 14:22:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://felix-knorr.net/posts/2023-11-11-github-actions.html">https://felix-knorr.net/posts/2023-11-11-github-actions.html</a>, See on <a href="https://news.ycombinator.com/item?id=38240278">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>The Problem</h2>
<p>You push (or better, merge) to master, and the deployment happens automagically. No
further work required. That's the promise of GitHub-Actions (GHA), and probably
every other CI service provider.</p>
<p>However, things are not as shiny as they seem at first glance. There are many
problems with the approach that GHA and co. use. Some are addressable by more
disciplined usage behavior<sup id="fnref:1"><a href="#fn:1">1</a></sup>, but others are not.</p>
<!--more-->

<p>My first and foremost problem with them is: you cannot run them locally. There
are some projects, that attempt to enable you to do that, e.g. 
<a href="https://github.com/nektos/act">act</a>, but they are very limited. And that is because
of my second-biggest issue with GHA: the runner is closed source.</p>
<p>Hosting a git repo is hardly more than providing a file system and SSH access.
The actual mechanism they use to keep you on their platform is the CI-pipelines
(and maybe the issue system and wiki, but less so). Half a year ago, I started
porting my teams Azure-Devops pipelines to GHA, investing ~1 day per week. AND I
AM STILL NOT DONE.</p>
<p>The fact that you have to push a commit to the repo to test a change, and then 
wait for a runner delays everything indefinitely, and makes iterating really
painful.</p>
<p>Additionally, writing pipelines in YAML is just painful. It's super verbose,
and you have a lot of "code" duplication. Quite soon in the process I invested
3 days to write a small DSL that compiles to GHA<sup id="fnref:2"><a href="#fn:2">2</a></sup>. This already took care
of the code duplication, and I integrated <a href="https://github.com/rhysd/actionlint">actionlint</a> to reduce the number of pushes I'd need. Sadly, actionlint
catches a similar percentage of your bugs like a C-compiler (which is not very
high). Originally, that DSL hat two backends: One to compile to GHA, and one
to run stuff locally. The second one is not in use anymore. Why? Because there
are tons of actions<sup id="fnref:3"><a href="#fn:3">3</a></sup> that you want to use, e.g. for terraform. To use those
locally, I'd have to reimplement the complete GHA runner, or at least, locally
reimplement all the actions I want to use.</p>
<p>Many of those actions are written by 3rd parties, not by GitHub/Microsoft,
but it benefits them a lot by strengthening their position against their
competition. It's a network effect. And it's bad for everyone except MS. I'm
only somewhat knowledgeable in Azure-Devops and GitHub actions (much to my own
dismay), but I assume that more or less every CI provider does its own thing,
and there is a lot of duplicated efforts. </p>
<h2>An attempt at a solution</h2>
<p>The base idea is the same for every CI provider: You define a "workflow" that
runs some scripts. Some of which run in parallel, some of which require others
to finish first. They need access to a git repository, and they might have
to interact with it. Defining a language to run scripts in parallel with some
constraints is actually quite easy if you just pass the script to an existing
interpreter and let the language mainly deal with the constraints around order
and parallelism (and code reuse). However, if this is then just a new solution,
little is gained. So it would be necessary to have different "generators" that
generate small wrappers for your CI-provider of choice that call the actual
definitions, and maybe to call a subset of functionality that is shared by
more or less everyone (e.g. creating issues, merging a branch, etc.). If people
who currently write "plugins" for different CI providers instead focus on this
hypothetical language, we would end up with an ecosystem of CI tools that can run
everywhere, including your PC. I'm thinking of something like this:</p>
<p><img alt="Graph of the hypothetical System" src="https://felix-knorr.net/assets/img/common_action_runtime.svg"></p>
<p>And yes, I'm aware of <a href="https://xkcd.com/927/">XKCD #927</a>, but It's actually not the same
as a CI-Provider, and I'm not aware of a similar project. Corrections are welcome.
And while I'd love to work on this, I don't see myself having enough free time in the
foreseeable future to do this. So I hope, someone feels inspired.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Casino-like apps have drained people of millions (247 pts)]]></title>
            <link>https://www.nbcnews.com/tech/tech-news/addicted-losing-how-casino-apps-have-drained-people-millions-n1239604</link>
            <guid>38240212</guid>
            <pubDate>Sun, 12 Nov 2023 14:13:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nbcnews.com/tech/tech-news/addicted-losing-how-casino-apps-have-drained-people-millions-n1239604">https://www.nbcnews.com/tech/tech-news/addicted-losing-how-casino-apps-have-drained-people-millions-n1239604</a>, See on <a href="https://news.ycombinator.com/item?id=38240212">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Shellz, 37, a nurse from Houston, spends at least two hours a day with her husband playing a casino-style smartphone game called Jackpot Magic.</p><p>The app offers a variety of typical casino games to play, including their favorite, called Reel Rivals, a game in which players accrue points by playing a virtual slot machine. As in a real casino, players exchange money for coins to bet.</p><p>Unlike in a real casino, there is no way to win money back or earn a payout on coins.</p><p>But that has not stopped Shellz and her husband from spending about $150,000 in the game in just two years. She asked to use her in-game username so her family does not find out how much money they have spent on the game.</p><p>"We lie in bed next to each other, we have two tablets, two phones and a computer and all these apps spinning Reel Rivals at the same time," she said. "We normalize it with each other."</p><p>Jackpot Magic is an app made by Big Fish Games of Seattle, one of the leaders in an industry of "free-to-play" social games into which some people have plowed thousands of dollars. Big Fish Games also operates a similar app, Big Fish Casino. Both are labeled as video games, which allows the company and others like it to skirt the tightly regulated U.S. gambling market.</p><p>But unlike the gambling market, apps like Jackpot Magic and Big Fish Casino are under little oversight to determine whether they are fair or whether their business practices are predatory.</p><p>NBC News spoke to 21 people, including Shellz and her husband, who said they were hooked on the casino-style games and had spent significant sums of money. They described feelings of helplessness and wanting to quit but found themselves addicted to the games and tempted by the company's aggressive marketing tactics.</p><p>Most of the 21 players wished to remain anonymous, as they were ashamed of their addictions and did not want their loved ones to find out about their behavior.</p><p>A 42-year-old Pennsylvania woman said she felt saddened that she spent $40,000 on Big Fish Casino while working as an addiction counselor.</p><p>"The whole time I was working as an addiction counselor, I was addicted to gambling and with no hope of winning any money back," she said.</p><p>Big Fish Games did not make anyone available for an interview, nor did the company respond to detailed questions. The company has said in previous <a href="https://www.documentcloud.org/documents/6878099-206-2.html#document/p4/a561949">court filings</a> that only a fraction of the game's players actually spend money.</p><p>In a response to NBC News' inquiries, the company issued a <a href="https://www.documentcloud.org/documents/6896112-BF.html">statement</a> saying its games are not gambling and should not be regulated as such.</p><p>"These games are not gambling because, among other reasons, they offer no opportunity for players to win money or anything of value," the statement said in part.</p><p>"Our games are offered for free purely for entertainment, with an opportunity for customers to spend money within the game to enhance their gameplay experience," it said. "The vast majority of Big Fish Casino and Jackpot Magic Slots customers play without ever paying any money. No court has yet considered all of the facts relating to how these games operate."</p><p>Players have had some recourse in recent months thanks to successful lawsuits.</p><p>After a long legal battle, 2 million players, including Shellz and her husband, will be eligible to get a small part of their losses back — about 20 percent for those who lost $10,000 to $100,000.</p><p>The money will come in a $155 million class-action settlement, announced at the end of July, that will cover two major lawsuits filed against Big Fish Games; its former owner, Churchill Downs; and its current Australian parent company, Aristocrat Leisure, alleging that they were operating "unlawful gambling devices."</p><p>The preliminary agreement was recently approved by a federal judge in Tacoma, Washington. Churchill Downs and Aristocrat Leisure both declined to comment on the settlement. Aristocrat Leisure released a public <a href="https://www.documentcloud.org/documents/7205179-21354134-b761-4dd7-a3a2-266d8a52056c-1.html">statement</a> in May outlining the general contours of the settlement, but it has not said anything further.</p><p><em><strong><a href="https://smart.link/5d5ad16083f88" target="_blank">Download the NBC News app for breaking news and politics</a></strong></em></p><p>While Big Fish Games admits no wrongdoing, it has <a href="https://www.documentcloud.org/documents/7006464-171.html#document/p8/a573737">agreed</a> to implement "addiction-related resources" and a "self-exclusion policy" that would allow players who feel out of control to opt in to be blacklisted from playing the game.</p><p>Big Fish Games also declined to comment on the settlement.</p><p>While some players are happy to recoup some of their losses, gambling addiction experts and some lawmakers say it does not go far enough to help those whose lives have spiraled out of control after they got hooked on social casino games. They call for further regulation of the industry.</p><p>"What we would have welcomed as part of this settlement as a wake-up call for the industry is a change in practices," said Keith Whyte, the executive director of the <a href="https://www.ncpgambling.org/">National Council on Problem Gambling</a>.</p><p>"I think their model is so lucrative and in some ways so aggressive that they're doubling down, and it's going to do a lot more harm. I think it's going to eventually be reined in, but it appears they are prioritizing short-term profit over long-term sustainability and responsibility," Whyte said.</p><h2><strong>The game</strong></h2><p>Joann, 46, who lives in southwest Florida, said she began playing Big Fish Casino about eight years ago.</p><p>She estimates that she has spent $100,000 on the game.</p><p>"You know what I tell people? It's a cult, and they suck you in, and once you're in you can't get out," said Joann, who asked to use only her middle name. "You want to play, and you want to spin."</p><p>One of the named plaintiffs in the settlement is Crystal Fair of Texas, who said in a sworn declaration that she has <a href="https://www.documentcloud.org/documents/6782706-128-8.html#document/p3/a551787">spent $500,000</a> and described herself as being "addicted" to Big Fish Casino, playing it sometimes "nearly 24 hours a day."</p><p>"I have considered walking away for good but then I think of all my time and more importantly all my money and it's hard to walk away," she wrote. "That's how I know I'm addicted."</p><p>She concluded: "But if I could go back to the point in time when I installed Big Fish Casino, I'd never ever have done it."</p><p>Several people said they felt the apps were engineered to keep them spending money in a variety of ways, including tiered clubs for players who spend significant amounts of money and free chips for people who try to quit.</p><p>Suzie Kelly of Dallas previously told <a href="https://www.revealnews.org/episodes/harpooned-by-facebook/">Reveal News</a> how she spent about $400,000 on the game. She took out a home equity loan and used the money she inherited when her mother died to fund her habit.</p><p>When she tried to cancel her account on several occasions, Kelly said, a "VIP representative" would call her and offer her free chips so she would continue playing.</p><p>The Big Fish apps in some ways are similar to many other apps that offer casino games that can be played on smartphones.</p><p>The home screen of Big Fish Casino, known as the "lobby," offers players a chance to try various types of casino-style games, including roulette, blackjack, Texas Hold 'em, Video Poker and the most prominently featured game: slots.</p><p>Shortly after they install the app, players are encouraged to join clubs — Big Fish Casino even offers a "one time join bonus" of 50,000 chips for joining a club. Once they are in a club, players can use a chat feature to strike up conversations with their counterparts and develop friendships. While anyone can create a club, the real action is in the invitation-only ranked clubs that compete against one another.</p><p>Winning more chips and playing at higher stakes unlock new features, like high-roller rooms. There is also a <a href="https://www.bigfishgames.com/game/jackpotmagicslots/help/articles/115000134954-What-is-the-VIP-Rewards-Program-/">system</a> of "levels" and "tiers" to unlock as players spend and win more. Higher tiers come with larger potential winnings and bigger bets, which makes it easier to lose chips faster.</p><p>Players who lose but want to continue playing in high-roller rooms can do so by either rebuilding their digital fortunes through hours of gameplay or taking a shorter route: buying more chips.</p><p>Most people who play the Big Fish games do not end up spending real money. Less than 10 percent of users have ever bought virtual items while playing the games, <a href="https://www.documentcloud.org/documents/6878099-206-2.html#document/p4/a561949">according to an October court filing</a>.</p><p>But that 10 percent has translated into a lucrative business. According to data provided by Apptopia, an app analytics company, Big Fish Games took in an estimated $139.3 million from Big Fish Casino and Jackpot Magic players from February 2019 through July 2020.</p><p>The app's tier system, along with its social functions, can be a powerful trap for some players. Joann said she continues to play, as Big Fish Casino grants her a set of free chips (known as a "boost") every day. Even so, she said, she spends at least $600 a month, largely to maintain her status within her club.</p><p>"I want to quit the club, and I want to stop, but I have friends," she said.</p><h2>No recourse</h2><p>Big Fish Games is one of the clearest examples of the <a href="https://arstechnica.com/gaming/2018/09/multinational-regulators-join-together-to-fight-gambling-in-video-games/">convergence</a> of the small-time harmless fun of video games and the rapidly expanding world of real-money gambling.</p><p>While many video games have added premium features in recent years, including <a href="https://www.nbcnews.com/tech/tech-news/loot-boxes-gambling-video-games-ftc-look-it-n941256">loot boxes</a> — a mechanism to pay small, fixed fees for chances to win in-game prizes that has attracted the ire of <a href="https://www.nbcnews.com/tech/video-games/video-game-loot-boxes-face-final-boss-missouri-senator-n1003471">some lawmakers</a> — no other type of game appears to allow players to lose so much credit so quickly and be constantly encouraged to spend more.</p><p>But for the time being, there does not seem to be anything stopping these gambling-style smartphone games from continuing. No federal legislation would halt this model, nor would any state-level legislation mitigate losses created by this type of game. Washington state legislators considered a bill that would have formally defined games like Big Fish Casino to not be considered gambling, but the bill did not pass.</p><p>Some players of Big Fish games have filed class-action lawsuits against the company, arguing that its games should be regulated just like traditional gambling, which is unlikely to happen any time soon.</p><p>Conventional slot machines, for example, are subject to rigorous outside testing to ensure that the odds are consistent for all players. In Nevada, there are rules about how many slot machines can be <a href="https://www.documentcloud.org/documents/6922257-All-Regulations-as-of-01-30-20.html#document/p46/a565021">placed in liquor stores</a>, among hundreds of pages of regulations.</p><p>In Washington state — where Big Fish Games is located — slot machines are <a href="https://www.wsgc.wa.gov/regulation-enforcement/illegal-activities">banned</a> outright. But Washingtonians can download a smartphone game that offers would-be gamblers the chance to spend money on an experience nearly identical to that of an in-person slot machine, only without any chance of actually winning money.</p><p>Still, the recent legal victories are a welcome bit of help for some players, particularly because many have lost their jobs because of the COVID-19 pandemic.</p><p>Neva Barker, 58, a retiree in Portland, Oregon, estimated that she had spent $80,000 on Big Fish Casino and said she was thrilled to hear that she likely would get some of her money back.</p><p>It is particularly needed now, because, Barker says, she lost some of her income to coronavirus-related cutbacks.</p><p>"This has been going through so many ups and downs," she said. "I thought it was a myth that it was ever going to happen. That would be life-changing for me at this point."</p></div><div data-activity-map="expanded-byline-article-bottom"><div data-testid="byline-thumbnail"><a href="https://www.nbcnews.com/author/cyrus-farivar-ncpn973741"><picture data-testid="picture"><source srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_focal-60x60,f_auto,q_auto:eco,dpr_2.0/newscms/2019_11/2784541/cyrus-farivar-1500.jpg 2x, https://media-cldnry.s-nbcnews.com/image/upload/t_focal-60x60,f_auto,q_auto:best/newscms/2019_11/2784541/cyrus-farivar-1500.jpg 1x"><img loading="lazy" src="https://media-cldnry.s-nbcnews.com/image/upload/t_focal-60x60,f_auto,q_auto:best/newscms/2019_11/2784541/cyrus-farivar-1500.jpg" alt="" height="48" width="48"></picture></a></div><p><span data-testid="byline-name"><a href="https://www.nbcnews.com/author/cyrus-farivar-ncpn973741">Cyrus Farivar</a></span><span><a href="https://twitter.com/cfarivar" target="_blank" rel="noopener noreferrer"><span></span></a><a href="mailto:cyrus.farivar@nbcuni.com" target="_blank" rel="noopener noreferrer"><span></span></a></span></p><p>Cyrus Farivar is a reporter on the tech investigations unit of NBC News in San Francisco.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Before-and-after images show how Greenland's glaciers have rapidly retreated (112 pts)]]></title>
            <link>https://www.cnn.com/2023/11/12/climate/greenland-glaciers-before-after-climate/index.html</link>
            <guid>38240147</guid>
            <pubDate>Sun, 12 Nov 2023 14:03:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2023/11/12/climate/greenland-glaciers-before-after-climate/index.html">https://www.cnn.com/2023/11/12/climate/greenland-glaciers-before-after-climate/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=38240147">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-editable="main" data-track-zone="main" data-reorderable="main">  <article data-uri="cms.cnn.com/_components/article/instances/clossp8s7000r65p8evwxgmpc@published" role="main" data-unselectable="true">
  <section data-tabcontent="Content">
    <main>
                
        
        
            <div data-editable="content" itemprop="articleBody" data-reorderable="content">
                    <p><cite>
      <span data-editable="location"></span>
      <span data-editable="source">CNN</span>
        &nbsp;—&nbsp;
    </cite>
</p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clossp8s7000q65p8atza9d0w@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      When Laura Larocca visited Denmark in 2019, the climate scientist sifted through thousands of old aerial photographs of Greenland’s icy coastline, which were rediscovered in a castle outside Copenhagen about 15 years ago.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/closw9bwh00023b6hov4jf2e0@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Now housed in the Danish National Archives, the historical images inspired her and other researchers to reconstruct the territory’s glacial history and how it has changed amid a rapidly warming climate.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/closw9bwh00033b6hwzi1v9m0@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      After digitizing thousands of archived paper images dating back to the 1930s, Larocca’s team combined them with satellite images of Greenland today to measure how much its frozen landscape has changed.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/closw9bwh00043b6h51541ig4@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      The comparison found Greenland’s glaciers have experienced an alarming rate of retreat that has accelerated over the last two decades. The study, published this week in the <a href="https://www.nature.com/articles/s41558-023-01855-6" target="_blank">journal Nature Climate Change</a>, found that the rate of glacial retreat during the 21st century has been twice as fast as the retreat in the 20th century.
  </p>

  <div data-uri="cms.cnn.com/_components/image-slider/instances/clost6uw1000p3b6ira7xawcj@published" data-offset="0.5" data-horizontal="true" data-before-text="1930s" data-after-text="2022">
        
        <p>Natural History Museum of Denmark/Niels Jakup Korsgaard</p>
    </div>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/closwa8xh00063b6h5jumbeg7@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      The work was “very time consuming, and it took a lot of people, a lot of hours of manual labor,” said Larocca, the lead author of the study and an assistant professor at Arizona State University School of Ocean Futures. “The change is stunning — it really highlights the fast pace at which the Arctic is warming and changing.”
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/closwaezf00083b6hqzjsntn6@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Over the past several decades, the Arctic has <a href="https://www.cnn.com/2022/08/11/us/arctic-rapid-warming-climate/index.html">warmed four times faster </a>than the rest of the world, a 2022 study showed. The fallout of that warming is mounting. For the first time on record, it <a href="https://www.cnn.com/2021/08/19/weather/greenland-summit-rain-climate-change/index.html">rained at the summit of Greenland</a> — roughly two miles above sea level during the summer of 2021. Earlier this week, <a href="https://www.cnn.com/2023/11/07/climate/greenland-ice-shelf-glacier-melt-climate-intl/index.html">scientists found</a> that northern Greenland’s huge glaciers, which were long thought to be relatively stable, now pose potentially “dramatic” consequences for sea level rise.
  </p>

  <div data-uri="cms.cnn.com/_components/image-slider/instances/clossx11y00093b6i5lxnkiuk@published" data-offset="0.5" data-horizontal="true" data-before-text="1930s" data-after-text="2022">
        
        <p>The Danish Agency for Datasupply and Infrastructure/Hans Henrik Tholstrup/University of Copenhagen</p>
    </div>

  <div data-uri="cms.cnn.com/_components/image-slider/instances/clossyvqw000d3b6ivlraws54@published" data-offset="0.5" data-horizontal="true" data-before-text="1930s" data-after-text="2022">
        
        <p>Natural History Museum of Denmark/Niels Jakup Korsgaard</p>
    </div>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/closwbskk000b3b6hs4ln30ng@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      What struck Larocca the most was how the Danish pilots who took the original photos had no idea they would be a major contribution to climate science nearly a century later.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/closwd5jv000g3b6hkdwo6ss7@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “It is quite interesting that a lot of these photos were taken because of military operations,” she said. “So, they have ties with a lot of international and US history, as well. But it’s kind of neat how over 100 years later, we’re using these photos for science to document how much these glaciers have changed over time.”
  </p>

  <div data-uri="cms.cnn.com/_components/image-slider/instances/clost1ci3000h3b6ibekc9c8v@published" data-offset="0.5" data-horizontal="true" data-before-text="1930s" data-after-text="2022">
        
        <p>The Danish Agency for Datasupply and Infrastructure/Hans Henrik Tholstrup/University of Copenhagen</p>
    </div>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/closwdlxe000i3b6h6cx9fq0d@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Larocca said she hopes this new visual-heavy study will draw attention to the rapidly melting territory and the threat it poses to the world’s coastlines as sea level rises.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/closwdt26000k3b6hnx34sxam@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “[The paper] really reinforces that our choices over the next few decades and how much we reduce our emissions really matter to these glaciers,” Larocca said. “Every incremental increase in temperature will have significant consequences for these glaciers, and that swift action to limit global temperature rise will really help to reduce their future loss and contribution to sea level.”
  </p>

                </div>
    </main>
  </section>
</article>

</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stanford Data Science Handbook (200 pts)]]></title>
            <link>https://datascience.stanford.edu/programs/stanford-data-science-scholars-program/data-science-handbook</link>
            <guid>38239728</guid>
            <pubDate>Sun, 12 Nov 2023 13:04:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://datascience.stanford.edu/programs/stanford-data-science-scholars-program/data-science-handbook">https://datascience.stanford.edu/programs/stanford-data-science-scholars-program/data-science-handbook</a>, See on <a href="https://news.ycombinator.com/item?id=38239728">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page-content">

      <div>
            
  <h2 id="menu-blockmain-menu">Main navigation</h2>
  

        
<p><a href="#main-content">Skip to main content</a></p>

  </div>
  
      <div><h2>Open, rigorous and reproducible research: A practitioner’s handbook</h2>

</div>
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You Paid $1k for an iPhone, but Apple Still Controls It (147 pts)]]></title>
            <link>https://www.nytimes.com/2023/11/12/technology/iphone-repair-apple-control.html</link>
            <guid>38239640</guid>
            <pubDate>Sun, 12 Nov 2023 12:45:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2023/11/12/technology/iphone-repair-apple-control.html">https://www.nytimes.com/2023/11/12/technology/iphone-repair-apple-control.html</a>, See on <a href="https://news.ycombinator.com/item?id=38239640">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2023/11/12/technology/iphone-repair-apple-control.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Speaker Support in Asahi Linux (200 pts)]]></title>
            <link>https://github.com/AsahiLinux/docs/wiki/SW:Speakers</link>
            <guid>38239503</guid>
            <pubDate>Sun, 12 Nov 2023 12:20:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/AsahiLinux/docs/wiki/SW:Speakers">https://github.com/AsahiLinux/docs/wiki/SW:Speakers</a>, See on <a href="https://news.ycombinator.com/item?id=38239503">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <h2 id="user-content-speaker-support-in-asahi-linux"><a href="#speaker-support-in-asahi-linux">Speaker support in Asahi Linux</a></h2>
<p>We are progressively enabling speaker support on Asahi Fedora Remix.</p>
<p>Currently supported models:</p>
<ul>
<li>M1 MacBook Air 13" (J313)</li>
</ul>
<p>Proper speaker support has been a multi-year development effort involving many people across all parts of the Linux audio stack. We want to offer the best speaker support of any Linux laptop platform, and that has meant driving Linux desktop audio forward a couple decades so that we can do what is expected of a modern laptop audio subsystem!</p>
<h2 id="user-content-current-state"><a href="#current-state">Current state</a></h2>
<p>We are ready to begin releasing preliminary speaker support to users. Keep in mind that as Asahi Linux is the first desktop Linux platform with integrated advanced speaker DSP, there will likely be bugs. In addition, the DSP profiles will be improved and adjusted over time, and do not represent the absolute best possible results.</p>
<p>Speaker DSP is currently only supported on Fedora Asahi Remix (things are moving fast), however alternative distros should be able to integrate this work relatively painlessly once things settle down (see the section below).</p>
<h2 id="user-content-known-limitations"><a href="#known-limitations">Known limitations</a></h2>
<p>The DSP processing uses too much power, due to limitations of the default scheduler. Uclamp support will be enabled with an upcoming PipeWire release, and it should greatly reduce the power consumption of the DSP processing, even doubling battery life while playing audio in some cases.</p>
<h2 id="user-content-known-bugs"><a href="#known-bugs">Known bugs</a></h2>
<ul>
<li>In KDE Plasma, if you toggle mute using the keyboard hotkey while the master volume is set at anything other than 100%, on unmute the speaker volume will be too low. Touching the volume control (or pressing a volume hotkey) will restore the intended volume.</li>
<li>The DSP chain introduces excessive delay, and trailing audio is "buffered" (if you stop playing something and start something else, you get a bit of the end of the first when the second starts).</li>
<li>There is no final limiter/compressor in the current DSP chains (although there is an input compressor), so inputs with content in high-gain regions of the EQ curve might cause distortion or clipping (and speakersafetyd limiting). This is most prominent in the 200Hz region right now. This should not cause damage, but we recommed lowering the volume if you notice the sound is noticeably distorted.</li>
<li>The 13" MacBook Air EQ curve might be a bit harsh on the treble; pending re-calibration with an individually calibrated microphone to confirm/fix.</li>
<li>Bankstown (the "fake bass" plugin) uses a relatively naïve algorithm right now, which doesn't work well for all music.</li>
</ul>
<h2 id="user-content-project-goals"><a href="#project-goals">Project goals</a></h2>
<p>Our DSP profiles aim to provide a balanced sound, with the features that people expect from high-quality laptop/small-speaker audio. In particular, we aim for:</p>
<ul>
<li>A balanced (neutral) tone at moderate listening volumes, with a mostly flat frequency response from a typical listening position</li>
<li>Reasonably high peak volume with acceptable sound degradation (compression, limiting, etc.)</li>
<li>
<a href="https://en.wikipedia.org/wiki/Missing_fundamental#Audio_processing_applications" rel="nofollow">"Fake bass" processing</a> to make audible frequencies that cannot be physically reproduced by the speakers, extending the perceived frequency response of the system.</li>
<li>
<a href="https://en.wikipedia.org/wiki/Equal-loudness_contour" rel="nofollow">Equal-loudness volume compensation</a>, so that the sound does not become noticeably tinny as the system master volume is lowered.</li>
</ul>
<p>These are all techniques that are in wide use in consumer microspeaker systems in tablets and phones, though sadly not common on laptops from most non-Apple brands. All of these processing tricks are also used by macOS.</p>
<p>Our goal is explicitly <em>not</em> to clone the full/exact macOS audio experience. We consider the macOS speaker DSP processing to be too tryhard; some of the things it does work well, some do not (or are outright buggy!), and some are just strange. Although audio is ultimately subjective, and we recognize that some people might prefer the "macOS sound", we aim for a more objectively neutral and balanced sound than macOS as a baseline. Users are encouraged to try adding their own effects (e.g. with EasyEffects) if they want to customize their experience and achieve certain sonic profiles. We believe that a balanced baseline that allows users to shape the sound to their own preference if they so desire is a better option than hard-coding specific effects (such as macOS' spatial audio processing) with no option to turn them off. There is no user-friendly (GUI) way to modify or tweak our DSP chains, so it's best if additional effects are left to existing utilities like EasyEffects that can be easily customized by the user.</p>
<p>That said, for the types of processing we <em>do</em> intend to apply, failing to work properly where macOS does (e.g. objectively bad audio quality for certain kinds of inputs in particular, such as bad-sounding compression or distortion at high volumes where macOS sounds better at an equal output volume) is considered a bug. Feel free to file issues if you find test cases where macOS does a clearly better job. We're particularly talking about program-dependent problems here, not "I like the macOS EQ/spatial/whatever stuff better in general".</p>
<h2 id="user-content-smart-amp--safety-support"><a href="#smart-amp--safety-support">"Smart Amp" / safety support</a></h2>
<p>In addition to the DSP processing, we also have the world's first (as far as we know) open source "smart amp" implementation. This allows the speakers to be driven to much higher peak levels than the worst-case safe volume level, greatly extending their dynamic range. Our implementation, <a href="https://github.com/AsahiLinux/speakersafetyd">speakersafetyd</a>, monitors feedback signals from the amplifiers, estimates speaker voice coil temperature using a two-stage thermal model, and reduces the hardware speaker volumes when the speakers get too warm. We also have kernel-side interlocks to disable or limit speaker volumes if speakersafetyd is not running or non-responsive.</p>
<p>Right now, we are shipping with a hard volume reduction limit of -7dBFS to catch potential bugs or misbehavior. If you notice that your speakers cut off for approximately one second and then come back at a reduced volume level, it is likely that you triggered this safety limit. Stop playback to let the speakers cool down (just in case) and let the limit re-arm, and then check <code>/var/lib/speakersafetyd/blackbox</code> for any blackbox dumps and <a href="">file a bug</a> attaching them together with any speakersafetyd logs (try <code>journalctl -S '10m ago' -u speakersafetyd</code>). If you play full-scale test tones or "extreme" music at maximum volume, it is expected that you will hit this limit and trigger a blackbox dump / panic. This is intended to help catch any badness while playing normal music, and we will remove this conservative limit once we are confident in the software stack (speakersafetyd has other safety limits built in and will gain more over time).</p>
<p>You can watch speakersafetyd in action by using <code>sudo journalctl -fu speakersafetyd</code>. As a rule of thumb, with the speaker volume at max, you should expect speakersafetyd not to kick in when playing loudness-normalized music (e.g. YouTube). Playing overly loud music without normalization (e.g. increasing the browser app volume to 100% in the Plasma applet while using YouTube, which bypasses the normalization limit it applies, or using media players without normalization) is likely to trigger some gain reduction from speakersafetyd, but it should not hit the -7 dB panic limit unless it's something <a href="https://open.spotify.com/album/6uvGw7zcCyMzYKKqXp9D3z" rel="nofollow">ridiculous</a>.</p>
<p><strong>WARNING:</strong> Speaker safety models have yet to be fully validated on all models. We are enabling audio only on models where we are confident things are ready and safe to use. If you use any undocumented overrides to force-enable speakers on any other machine models, <strong>you are entirely on your own</strong> and may very well blow up your speakers.</p>
<h2 id="user-content-distro-integration-notes"><a href="#distro-integration-notes">Distro integration notes</a></h2>
<p>You need:</p>
<ul>
<li>The latest Asahi kernel (tag asahi-6.5-25 or later)</li>
<li><a href="https://github.com/AsahiLinux/alsa-ucm-conf-asahi">alsa-ucm-conf-asahi</a></li>
<li><a href="https://github.com/asahilinux/asahi-audio">asahi-audio</a></li>
<li><a href="https://github.com/asahilinux/speakersafetyd">speakersafetyd</a></li>
<li><a href="https://github.com/chadmed/bankstown/">bankstown</a></li>
<li>
<a href="https://lsp-plug.in/" rel="nofollow">LSP plug-ins</a> (LV2 version)</li>
<li>PipeWire 0.3.84. Depending on your packaging rules, you might need your package to create a few empty directories (see <a href="https://src.fedoraproject.org/rpms/pipewire/commits/rawhide" rel="nofollow">here</a>) so <code>asahi-audio</code> can put files there.</li>
<li>PipeWire <code>module-filter-chain-lv2</code> (this may be a separate package or flags depending on distro)</li>
<li>WirePlumber 0.4.15 with an <a href="https://gitlab.freedesktop.org/pipewire/wireplumber/-/merge_requests/558" rel="nofollow">unreleased patch</a>. Please do not enable speakers without that patch, as it'll leave the raw speaker device visible which is confusing and could trigger bugs elsewhere. Either get your WirePlumber package to add the patch, or wait for the next release.</li>
</ul>
<p>The correct deployment order is asahi-audio/speakersafetyd &gt; (whatever you use to get those installed for users, e.g. metapackage) &gt; kernel. If you push the kernel first before asahi-audio, users will get either a nonfunctional (if no speakersafetyd) or functional but bad-sounding (if speakersafetyd is installed) raw speaker device with no DSP.</p>

              </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Archive Your Old Projects (173 pts)]]></title>
            <link>https://arne.me/articles/archive-your-old-projects</link>
            <guid>38239358</guid>
            <pubDate>Sun, 12 Nov 2023 11:40:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arne.me/articles/archive-your-old-projects">https://arne.me/articles/archive-your-old-projects</a>, See on <a href="https://news.ycombinator.com/item?id=38239358">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main"><article><header></header><p>Yesterday, while looking through a folder called <em>old things lol glhf</em>, I fell
into a rabbit hole of old abandoned projects—mostly websites and graphic
design, but I also found one or two Flash<sup><a href="#fn-1" id="fnref-1" data-footnote-ref="">1</a></sup> projects and compiled <code>.exe</code>
files<sup><a href="#fn-2" id="fnref-2" data-footnote-ref="">2</a></sup>.</p>
<p>And, while it was really fun remembering projects I’ve long forgotten, there
was no structure, and it was often difficult to figure out what a project did
and what it looked like—some even missed crucial data.
This made me think about how I want to archive my projects going forward.</p>
<!-- raw HTML omitted -->
<p>Here is my new strategy:</p>
<h2>Leave it online</h2>
<p>If the project is on the web, doesn’t require maintenance and doesn’t cost you
money, leave it online.</p>
<p>Occasionally, you’ll need to move to a different domain, for example when re-doing
a website.
When talking to <a href="https://flbn.sh/">Ollie</a> about this, he told me that some people
leave their old websites online at <code>&lt;year&gt;.&lt;domain&gt;</code> and I love that idea<sup><a href="#fn-3" id="fnref-3" data-footnote-ref="">3</a></sup>.</p>
<p>You can look up old content and redirect links, so your
<a href="https://www.w3.org/Provider/Style/URI">URIs stay cool</a>.
And in ten years it’ll probably still be online.</p>
<h2>Archive it</h2>
<p>If you can’t leave it online, save it to your file system.
You don’t have to go all <a href="https://johnnydecimal.com/">Johnny.Decimal</a>, but at
least create a dedicated folder and subfolders for every year.</p>
<p>But instead of just copying your project to the archive folder and be done with
it, consider these points to make life easier for your future self:</p>
<dl><dt>Make screenshots</dt>
<dd>
<p>Having a screenshot allows you to relive your memories more easily without
going through the hassle of setting up a project.
If you want to go the extra mile, do a screen recording showcasing your
project—this has the bonus effect of hearing your voice from years ago, and it
has more context.</p>
</dd>
<dt>Add a README</dt>
<dd>
<p>Explain what the project did, when it was created and abandoned, who
contributed and how to get it running again.</p>
</dd>
<dt>Back up the database</dt>
<dd>
<p>Some of my projects are missing a database dump, so all the actual content is
gone. Run <code>sqldump</code> or whatever export functionality your database supports
and add it next to your files.</p>
</dd>
<dt>Keep generated assets</dt>
<dd>
<p>When using static site generators, add the folder containing the built HTML,
CSS &amp; JS to the archive.
That way, all you have to do is run a static file server to be able to browse
the complete website.</p>
</dd>
</dl>
<h2>Save it to the Internet Archive</h2>
<p>If you don’t own your platform (maybe you’re publishing to Substack or Notion),
you can at least save your website to the
<a href="https://web.archive.org/">Wayback Machine</a>.
I would also advise saving your content somewhere you control.</p>
<h2>Show me yours</h2>
<p>So that’s it, that’s my new project archival strategy.</p>
<p>How are you archiving your projects?
Am I missing anything?
<a href="https://arne.me/contact">Let me know.</a></p>
<section data-footnotes="">
<ol>
<li id="fn-1">
<p>If you don’t know what this is, <a href="https://en.wikipedia.org/wiki/Adobe_Flash">Wikipedia’s got your back</a> <a href="#fnref-1" data-footnote-backref="" data-footnote-backref-idx="1" aria-label="Back to reference 1">↩</a></p>
</li>
<li id="fn-2">
<p>Not sure what to do with these besides deleting. <a href="#fnref-2" data-footnote-backref="" data-footnote-backref-idx="2" aria-label="Back to reference 2">↩</a></p>
</li>
<li id="fn-3">
<p>You can find the previous version of this very website at <a href="https://2023.arne.me/">2023.arne.me</a>. <a href="#fnref-3" data-footnote-backref="" data-footnote-backref-idx="3" aria-label="Back to reference 3">↩</a></p>
</li>
</ol>
</section>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Just use cash! The importance of cash in a technological society (103 pts)]]></title>
            <link>https://steelrods.hashnode.dev/the-importance-of-cash-in-a-technological-society</link>
            <guid>38239286</guid>
            <pubDate>Sun, 12 Nov 2023 11:24:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://steelrods.hashnode.dev/the-importance-of-cash-in-a-technological-society">https://steelrods.hashnode.dev/the-importance-of-cash-in-a-technological-society</a>, See on <a href="https://news.ycombinator.com/item?id=38239286">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-content-parent"><p>Just a heads up, this article is written from a strong perspective on privacy, autonomy, and financial freedom (with a focus on data mining, AI, and the future). If you prefer less opinionated pieces, you may want to skip this one. However, if you are open to a civil discussion about these topics, you are always welcome to comment.</p>
<p>Imagine a world, where everything and anything you purchase is tightly regulated by a governing entity. If you want to purchase a product – it has to follow <em>extreme rules and regulations</em> to be viable for purchase. If it does not follow regulations, you have no physical way of actually buying it (or for it to exist). Now imagine this entity is constantly changing and updating its regulations, allowing the market to be ruled by one specific brand because it is the only brand that follows the exact rules and regulations.</p>
<p>Think about the implications of such a reality, every decision you make will have to comply with these entities’ agenda, and since those entities mostly care about their profits, you will essentially have no freedom of choice.</p>
<p><strong>Sounds like a dystopian fantasy right?</strong></p>
<p>This is the world we are heading into in the next two to three decades, and that is why it is critically important you understand the importance of physical cash in a free, functioning and technical society.</p>
<p>You have probably noticed the global trend that is making it harder and harder for us to use cash in our daily lives. In my home country, you cannot use cash to pay for certain goods and services (credit only). Coincidentally (or not) these goods and services are often controlled by, or directly attached or affiliated with a governing entity. There is also a risk of criminal charges for business owners willing to accept more than a certain amount of cash from a client, and it is illegal to hold more than a certain amount of cash in your possession, at all times.</p>
<p>This global trend is being pushed relentlessly which is why it is important to understand what the absence of cash truly means for us, the people.</p>
<p>Our world is functioning on exchangeable currencies, this was the way humans operated from the beginning of time. The actual currency and methods of payment changed over the years – if you go back long enough, you will notice we have used barter systems that exchanged goods and services for other goods and services. Throughout history, we have used rare gems like diamonds, rubies and sapphires – which are a finite natural resource. We have also used precious metals like gold and silver – which are also finite, and therefore – hold value.</p>
<p>Crypto currencies are another example of finite currencies (depending on each protocol), and therefore they hold value. However, in the past couple of years, I began to see signs that the crypto market is also being controlled and manipulated. So crypto-currencies are not a viable solution to the issue this article is about (they are just an example of a finite currency).</p>
<p><strong>Notice the trend – throughout history, currencies have always held some sort of real-life bound value, that is finite.</strong></p>
<p>Before 1971, the US dollar was tied to gold, meaning its value was derived from the gold “stock” (which is a finite resource), therefore – the US dollar held a realistic value up until 1971. In 1971, the United States declared that they were abandoning the gold-tied US dollar, and it is now a fiat currency.</p>
<h3 id="heading-what-are-fiat-currencies-and-why-does-any-of-this-matter">What are fiat currencies and why does any of this matter?</h3>
<p>A fiat currency is a currency that holds no real-life value besides the fact that a governing entity says so. Gold is a finite resource because we know that there is a limit to the amount of gold on the planet, therefore it’s valuable. Fiat currency, on the other hand, holds value just because a governing entity is endorsing it.</p>
<p>Derived from this, we know that the same entities can also decide what sort of value the fiat holds, which can be easily manipulated by adding to the circulation to dilute the value (money printer goes BRRR). Or improve the confidence of its users in its stability through mass media, to raise its value.</p>
<p>The more people trust these entities, the more value the fiat currency holds. An excellent example of how mass media used to influence whole nations for a specific agenda would be the Cambridge Analytica scandal, and there are many others.</p>
<p><strong>By their nature, fiat currencies are manipulatable.</strong></p>
<p>To find out more about what happened in 1971, you can visit <a target="_blank" href="https://wtfhappenedin1971.com/">https://wtfhappenedin1971.com/</a>.</p>
<h3 id="heading-so-what-is-the-problem-with-a-cashless-society">So, what is the problem with a cashless society?</h3>
<p>You are probably thinking “What is the problem? Carrying around cash is messy and uncomfortable. I much rather use my card anyway”. I hope you change your mind after you are done reading this article, you must understand that you should not give up freedom for comfort.</p>
<p>First, let’s talk about the obvious reasons cash is important for our society.</p>
<p><strong>Financial Freedom:</strong> having your physical cash is important for your financial freedom, the fact you can spend, store, invest or do whatever you want with your hard-earned money without interference is crucial for your well-being. If you want to buy anything (within your rights as a human being) you should be able to do so.</p>
<p><strong>Financial Control:</strong> Owning physical cash means you will never be bound by banks or entities that usually want to limit, influence or pinpoint your financial actions and decisions.</p>
<p>I will give the tiniest example from my personal life - these past few weeks a dear family member has been trying to take out a sum of money from their bank in the form of cash. However, they very quickly encountered irrelevant and overblown bureaucracy (even though it was their money). This prevented them from withdrawing the money until they complied with certain regulations that the bank required them to comply with.</p>
<p>Therefore, they currently have no control over their own money until they comply with the bank's unrealistic demands (which means, they don’t even own their own money that is deposited in the bank – their ownership is essentially an illusion).</p>
<p><strong>Legal Grey Market:</strong> This ties to the same concept of “control” and holds the same importance. A healthy economy consists of trading between two (or more) individuals without a middleman. For an economy to flourish, we must enable ordinary people like you and I, to trade between themselves, and keep the circulation of money going around.</p>
<p>If you are selling a vintage Gameboy DMG in pristine condition with the original Pokémon games that your dad bought you 30 years ago - I should be able to pay you $150 (or whatever price we both agree on) without anyone taking a chunk off that transaction, or even knowing it happened. Note that your father already paid his taxes for the transaction when he purchased the Gameboy, 30 years ago.</p>
<p>A healthy, legal grey market keeps the cash circulation going because ordinary people who are not businesses or legal entities can trade between themselves, not having to worry about additional taxes or privacy issues (data mining).</p>
<p>It is also worth mentioning that if society went completely cashless, we would be solely dependent on a software system – which (I am sure we can all agree) are all just sand castles riddled with bugs and potential exploits, waiting for a wave big enough to wash them away (or raise a critical bug alert on a Friday night).</p>
<p>Just a pessimistic thought away, these governing entities might be able to block you, your family and your friends from purchasing or accessing goods and services, since they control the only method of payment (take a look at China’s social credit system).</p>
<p>Another issue with being completely dependent on software is that during a catastrophic event that tears down or renders our infrastructure useless, it is safe to assume you will not have access to your money (which is crucial for your survival and well-being).</p>
<h3 id="heading-okay-physical-cash-is-important-for-financial-freedom-but-is-it-the-end-of-the-world-if-our-cash-just-went-digital-isnt-that-the-natural-course-of-things-in-our-technological-society">Okay, physical cash is important for financial freedom, but is it the end of the world if our cash just went digital? Isn’t that the natural course of things in our technological society?</h3>
<p>Great question, glad you asked, but there is more to it! Living in a world where all of your transactions and microtransactions are controlled, and monitored – practically means that you live in a world where you have no control over your actions. It is a world where every move you make is recorded, processed and sent to multiple systems for reference and collection.</p>
<p>Our society is only functioning because of the control (autonomy) we have over our (financial) actions and decisions. It is crucial to maintain the financial status quo (or even better, get rid of fiat entirely) and give as much control as possible to the people, not to corporations, banks or governing entities.</p>
<p>With the modern rise of the World Wide Web, corporations and the like understood that the most valuable currency out there is… data! The reason that services like WhatsApp, Facebook or Twitter are free, is because your data is the product up for sale. Your data, my data, essentially all of our data is being processed and sold from entity A to entity B to entity C and then back to entity A and all over again.</p>
<h3 id="heading-what-is-the-goal-of-such-extensive-data-mining-and-processing">What is the goal of such extensive data mining and processing?</h3>
<p>I believe that with great power comes great responsibility, but the ones in power forgot all about the responsibility part. The goal of our society going cashless is for these governing entities to own more data, and therefore establish their powerful (rich) position in a digital era.</p>
<p>They essentially want to know everything about you (down to the most intrinsic detail). The only problem is that it will most likely be used against you.</p>
<p>Eventually, in years to come, when society will become more and more digital and therefore centralized - In one way or another, subtly or blatantly, you will not fit into the exact template of their perfect citizen. When that happens know that it was this article that tried to warn you.</p>
<p>They will own the data of your transactions, your location history, your daily routines, your hobbies, your diet, your sleep schedule, your sexual orientation, your health conditions and more.</p>
<p>All of this information and more can be withdrawn from your transactional history, and it’s all done automatically using sophisticated software and AI.</p>
<h3 id="heading-and-now-for-the-technical-part-data-mining-and-analysis">And now for the technical part - data mining and analysis</h3>
<p>I took some time to come up with a simple example of a made-up transaction list and the information that can be withdrawn from it (presented in a fun and colorful graph display).</p>
<p>Take a look at how much information can be extracted about a single person from his or her transactional history over the imaginary course of just three days. I am not a data engineer – this is just a tiny example of how it is possible to extract data on you based on your transactions and interactions. The concept is that as data is collected, the algorithm builds a graph of your traits as a person. The more nodes (data) the algorithm has, the more accurate its idea (or “image”) of your persona, of who you are.</p>
<p>The same approach is used by social media companies to show you targeted advertisements, and present content that will appeal to you (or piss you off), and make you spend more time engaging with the platform.</p>
<p>Take a look at the color of the transaction and the nodes withdrawn from that transaction. The optional nodes (marked with a ?) are not conclusive and will be made conclusive, narrowed down or expanded when more data is presented to the algorithm.</p>
<p><img loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1699545856694/8a7b3119-2c64-48e9-bffc-1730452dc58a.png?auto=compress,format&amp;format=webp" alt=""></p>
<p><img loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1699545879498/2618648c-529f-4e7e-9f60-c96d446b1508.png?auto=compress,format&amp;format=webp" alt=""></p>
<p>As you can see, from a made-up list of eight transactions, It took me 20 minutes to analyze and extract 17 nodes that now make up the persona of that specific person. Just imagine how much information can be extracted from a thousand transactions over many years.</p>
<h3 id="heading-lets-use-ai">Let's use AI!</h3>
<p>I was interested to see what the publicly available ChatGPT (GPT 3.5) has to say about my made-up transaction list. Here is the transcript of my conversation with the free-to-use and publicly available AI that <em>was not designed for this purpose</em>.</p>
<p><strong>Prompt</strong></p>
<blockquote>
<p>I will give you a list of made-up transactions. You will act as the most sophisticated and talented data engineer on the planet and extract as much data as possible about the person who made the transactions in my made-up list.</p>
</blockquote>
<p><strong>Response</strong></p>
<blockquote>
<p>As the most sophisticated and talented data engineer, I will extract as much data as possible from the list of made-up transactions to gain insights into the person who made these transactions. Here's what I can infer from the data:</p>
<p>Transaction Pattern:</p>
<p>The person made a series of transactions over a span of a few days. There are two transactions on 27th July 2023, three transactions on 28th July 2023, and two transactions on 29th July 2023. This pattern suggests they are active in spending and might have a regular daily routine.</p>
<p>Transaction Locations:</p>
<p>Coffee Mill: The person visited this place on 27th July at 09:23 AM.</p>
<p>Kyoto Sushi Palace: The person visited this place on 27th July at 14:09 PM.</p>
<p>Someville Train Station: The person visited this place on 28th July at 09:55 AM.</p>
<p>Mon Cheri Jewells: The person visited this place on 28th July at 11:43 AM.</p>
<p>Someville Coffee Hut: The person visited this place on 28th July at 15:23 PM.</p>
<p>Animal Supply Shop: The person visited this place on 28th July at 18:12 PM.</p>
<p>Downtown Pharmacy: The person visited this place on 29th July at 10:27 AM.</p>
<p>Apple Store: The person visited this place on 29th July at 12:18 PM.</p>
<p>Spending Behavior: The person spends varying amounts on different transactions. For example, they spent $119 at Mon Cheri Jewells, which indicates they might be buying jewelry or expensive items occasionally.</p>
<p>On the other hand, they made small transactions at Someville Coffee Hut ($6) and Coffee Mill ($15.2), suggesting they are regular coffee drinkers.</p>
<p>The person also spent a relatively higher amount at the Apple Store ($90), which could indicate a tech enthusiast or someone purchasing electronic devices.</p>
<p>Time of Transactions: The person made transactions at various times of the day, ranging from morning (09:23 AM) to evening (18:12 PM). This indicates they are active throughout the day and might have a flexible schedule.</p>
<p>Location Preferences: The person seems to be spending time at various places, including restaurants (Kyoto Sushi Palace), coffee shops (Coffee Mill, Someville Coffee Hut), and shopping locations (Mon Cheri Jewells, Animal Supply Shop, Downtown Pharmacy, Apple Store). This suggests they have diverse interests and might enjoy exploring different places.</p>
<p>Potential Interests: Based on the locations they visited, the person could be interested in fashion (Mon Cheri Jewells), tech gadgets (Apple Store), and pets (Animal Supply Shop).</p>
<p>Geographical Location: The data mentions names of locations such as Someville, indicating that the person might reside or frequently visit this area. However, the specific geographical location is not provided.</p>
<p>It's important to note that this analysis is purely speculative and based on the limited data provided. To draw more accurate and detailed conclusions about the person, additional data and context would be required.</p>
</blockquote>
<p>As you can see, both I and GPT came to very similar conclusions. Imagine what is already possible today with sophisticated models far more capable than GPT 3.5, models that were designed to create personas based on such information (It’s scary to think about).</p>
<h3 id="heading-conclusion-just-use-cash">Conclusion - Just use cash!</h3>
<p>With the emerging “Internet of Things”, where every aspect of your life will be connected to the cloud – every single aspect of your life will eventually be monitored, processed and sold as data. If such entities record and process every single transaction and interaction you make, after a relatively short period – they will know everything there is to know about you.</p>
<p>This article is not meant to scare you about the future, it is just meant to make you aware of the current situation, of the importance of your data, and of the importance of cash in a free and functioning society.</p>
<p>The bottom line is: Just use cash! Whenever you can, wherever you can. Endorse the use of cash and do not promote businesses that exclusively rely on credit. If you come across a business that refuses cash, point them to this article and kindly let them know that the use of cash is beneficial for all of us.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[RIP Google Groups Dejanews.com Archive (152 pts)]]></title>
            <link>http://dejanews.com/</link>
            <guid>38238796</guid>
            <pubDate>Sun, 12 Nov 2023 09:43:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://dejanews.com/">http://dejanews.com/</a>, See on <a href="https://news.ycombinator.com/item?id=38238796">Hacker News</a></p>
Couldn't get http://dejanews.com/: Error: Request failed with status code 404]]></description>
        </item>
        <item>
            <title><![CDATA[Map of Space Invader Mosaics in Paris (216 pts)]]></title>
            <link>https://pnote.eu/projects/invaders/map.html</link>
            <guid>38238658</guid>
            <pubDate>Sun, 12 Nov 2023 09:11:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pnote.eu/projects/invaders/map.html">https://pnote.eu/projects/invaders/map.html</a>, See on <a href="https://news.ycombinator.com/item?id=38238658">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
     <p><a href="https://pnote.eu/projects/invaders/">What is this?</a> | 
     <a href="https://newsletter.pnote.eu/">Newsletter</a> 

      </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Apple Network Server's all-too-secret weapon (featuring PPC Toolbox) (108 pts)]]></title>
            <link>http://oldvcr.blogspot.com/2023/11/the-apple-network-servers-all-too.html</link>
            <guid>38238180</guid>
            <pubDate>Sun, 12 Nov 2023 07:38:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://oldvcr.blogspot.com/2023/11/the-apple-network-servers-all-too.html">http://oldvcr.blogspot.com/2023/11/the-apple-network-servers-all-too.html</a>, See on <a href="https://news.ycombinator.com/item?id=38238180">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-2165139990214191915" itemprop="description articleBody"><p>
Most of my systems are microcomputers (and commensurately sized), though I do have some moderately larger beasts: you've met </p><tt>homer</tt><p>, my <a href="http://oldvcr.blogspot.com/2021/04/refurb-weekend-hewlett-packard-9000350.html">1987 HP 9000/350 rack system</a>, and Floodgap is powered by </p><tt>uppsala</tt><p>, a 2U-in-a-tower IBM POWER6 520 running AIX. But my first "large" machine, and indeed the first Unix server I ever personally owned, was this Apple Network Server 500. Its name is </p><tt>stockholm</tt><p>.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhpXhjafEOb7fQe9Xfw5e3ZJuiGHvA9YBQF5clc5wAmz_xJvE-qsPbBcz6LYLP5Cas_b0LyhXqGvCbKZnsDNoQd-le8S75-CyXv6SS8EK8dwPoqmwHjxmgvrfQ4HRcQ9bzSX4RzvT8_O8tfJjsWF9MLmdeA2MLqEaMRWcKMkyKvQVkpKDf6J-w7tzqid4A/s4080/PXL_20231104_223157360.jpg"><img alt="" data-original-height="4080" data-original-width="3072" height="320" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhpXhjafEOb7fQe9Xfw5e3ZJuiGHvA9YBQF5clc5wAmz_xJvE-qsPbBcz6LYLP5Cas_b0LyhXqGvCbKZnsDNoQd-le8S75-CyXv6SS8EK8dwPoqmwHjxmgvrfQ4HRcQ9bzSX4RzvT8_O8tfJjsWF9MLmdeA2MLqEaMRWcKMkyKvQVkpKDf6J-w7tzqid4A/s320/PXL_20231104_223157360.jpg"></a></p><p>

A mini-fridge-sized server with its famous translucent blinkenlight-friendly front sliding door and oodles of drive trays, this $11,000+ box (almost $22,000 in 2023 dollars) sat forlorn and unused at the University I was employed with as an IT working stiff in 1997. The bookstore had bought it at a substantial academic discount for their UniVerse-based (a Pick descendant, now Rocket U2) point-of-sale system, but the vendor wouldn't support the hardware anymore after then-CEO Gil Amelio cancelled the ANS line, so it got dumped off as surplus in the service bay where it lurked in a corner.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEibXTA33dAdTp6GOmOlAA8O70Pi425eyPwb9W8MA32a0l2dhUGyJ2ngX9DyEqQcZ4wDB3V3HWYBfybVXi5W0sdmt8POZuzGVyCGLmma9lMPY6KeA7MUw-AhO2TndHXcfwqmfZaLmKyfWf6Y8rhlwgkDgg5dpC5dmjfyMV62jisCOZsYwUypkjeFQf64OCc/s1280/ansx.jpg"><img alt="" data-original-height="960" data-original-width="1280" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEibXTA33dAdTp6GOmOlAA8O70Pi425eyPwb9W8MA32a0l2dhUGyJ2ngX9DyEqQcZ4wDB3V3HWYBfybVXi5W0sdmt8POZuzGVyCGLmma9lMPY6KeA7MUw-AhO2TndHXcfwqmfZaLmKyfWf6Y8rhlwgkDgg5dpC5dmjfyMV62jisCOZsYwUypkjeFQf64OCc/s320/ansx.jpg" width="320"></a></p><p>

As it was just sitting around, I got to use it as my personal server, shown here circa 1998 in my old office on a bad scan from a bad Polaroid. In this picture it's acting as a terminal server for my Commodore SX-64 with a CMD SwiftLink 6551 ACIA serial cartridge (the SX-64 is sitting on a parallel port switchbox because its handle got busted).
</p><p>
About a year later the University said they'd throw it in with my consultant compensation because they wanted to get rid of it anyway, so it became officially mine, and I was delighted to have it. That machine, later upgraded to 200MHz and 512MB of parity FPM RAM, variously powered my E-mail and the Floodgap gopher and webservers from 2000 to 2012, and still does backup duty when the POWER6 has to be down for repairs.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiHJOMHKDPgLHUOkUmGXCGiCqRoucNBtiT3SOLtpbkhXN62IKDlMnWmTL39wMFPC5_4rOdA-6WJNfeyiY4MLKtQrCyl-PyJPhnwJn6WYZhd9eKakLnoNS_wZHXo35DwcV022avqxIGTAGuQR3URP2_-Z91wEaP672MEEX2vTza0SuwSedJ8q6SKa3wjg0s/s2476/gw.jpg"><img alt="" data-original-height="2476" data-original-width="1920" height="320" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiHJOMHKDPgLHUOkUmGXCGiCqRoucNBtiT3SOLtpbkhXN62IKDlMnWmTL39wMFPC5_4rOdA-6WJNfeyiY4MLKtQrCyl-PyJPhnwJn6WYZhd9eKakLnoNS_wZHXo35DwcV022avqxIGTAGuQR3URP2_-Z91wEaP672MEEX2vTza0SuwSedJ8q6SKa3wjg0s/s320/gw.jpg"></a></p><p>

That's because the POWER6 runs everything the ANS did — because the ANS <em>also</em> runs AIX. The ANS 500 and 700 were not Apple's first Unix-specific servers (that would be the Apple Workgroup Server 95, a Quadra 950 using a special PDS card that only worked with A/UX, Apple's own Unix with a bolted-on Mac compatibility layer), but they were Apple's first Mac derivatives that could not boot classic Mac OS at all and natively ran a non-Apple operating system. Indeed, most people treated it as exactly that, <a href="http://www.floodgap.com/retrobits/ans/reviews/macuser/">a big Unix server</a> from Apple, and at the time I did too.
</p><p>
However, there was a secret weapon hidden in ANS AIX most of us at the time never knew about. Built-in to the operating system was a fully Unix-native AppleTalk stack and support for receiving and sending Apple Events, surfaced in the form of Apple's disk administration tools and AppleShare. But Apple had a much more expansive vision for this feature: full server-client "symbiotic" applications that could do their number-crunching on the ANS and present the results on a desktop Mac. Using the Program-to-Program Communication Toolbox ("PPCToolbox"), and because AIX's throughput far exceeded anything the classic Mac OS ever could ever handle, an ANS could augment a whole bunch of Macs at once that didn't have to stop to do the work themselves.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiXa3nZy8VmxPDdJKi1R75LnQQcmGehut05BlQBJibDZ3mpmFH6jRiCYWCGQQ5B_9wjif0ohyphenhyphenb_uS89pLULVAnMTP1mKKfJ10Dgx28kAgD6JwBc9M6grVR2p-NnFCp94gHJv013nmXeIdfJ7GKnZXB9P7xXX_yDTVmcj2pZum2Z_NmlhVDGiS5u9EZHCEU/s2560/IMG_20231104_161054_HDR.jpg"><img alt="" data-original-height="2560" data-original-width="1920" height="320" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiXa3nZy8VmxPDdJKi1R75LnQQcmGehut05BlQBJibDZ3mpmFH6jRiCYWCGQQ5B_9wjif0ohyphenhyphenb_uS89pLULVAnMTP1mKKfJ10Dgx28kAgD6JwBc9M6grVR2p-NnFCp94gHJv013nmXeIdfJ7GKnZXB9P7xXX_yDTVmcj2pZum2Z_NmlhVDGiS5u9EZHCEU/s320/IMG_20231104_161054_HDR.jpg"></a></p><p>

Well, today we're going to write one of those "symbiotic" applications doing something this little Mystic Color Classic could never efficiently do itself — accessing and processing a JSON API over TLS 1.3 — and demonstrate not only how such an client application looked on the Mac side, but also how the server component worked on the AIX side. If you're lucky enough to have an ANS running AIX too, you can even compile and run it yourself. But before we do that, it might be a little instructive to talk about how the Apple Network Server came to run AIX in the first place.
</p><p>
<a name="more"></a>

IBM AIX is nearly as old as the Mac OS, originating for the IBM RT PC in 1986, though early versions also ran on PS/2 systems and System/370 and /390 mainframes. AIX started as an early port of UNIX System V and is thus a true Unix descendent, but also merged in some code from BSD 4.2 and 4.3. The RT PC was powered by the IBM 801, considered to be the first modern RISC design, and in 1985 IBM Austin embarked on the AMERICA project to develop a successor. In 1990 IBM introduced the first RISC System/6000 machines, the desktop 7012-320, deskside 7013-530 and server 7015-920, all using a POWER1 CPU at 20MHz to run the new AIX 3.x.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh17fth5izC1ajSlb36ifS_CQrd4Zggsf9SaEFVQH7GWNdhI884sbf1-nyzBnsb2YSBqvriftB2D6fnK9B_TswG7_4In00rEAkYusUMffquh3IzybAX7XUAI-_bpQJSTaX8yyMhDv9Tg8R02a0kn84viMdTpfBbsPCVUwYiGqUV8e1GwEc6zEOvr6AOeQE/s2466/1991-07-08-content5.jpg"><img alt="" data-original-height="2466" data-original-width="1920" height="320" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh17fth5izC1ajSlb36ifS_CQrd4Zggsf9SaEFVQH7GWNdhI884sbf1-nyzBnsb2YSBqvriftB2D6fnK9B_TswG7_4In00rEAkYusUMffquh3IzybAX7XUAI-_bpQJSTaX8yyMhDv9Tg8R02a0kn84viMdTpfBbsPCVUwYiGqUV8e1GwEc6zEOvr6AOeQE/s320/1991-07-08-content5.jpg"></a></p><p>

Over in Cupertino, Macintosh System 7 had just emerged in 1991 from shorter-term upgrades implemented by the Blue team, with longer-term ideas deferred to Pink, each famously named for the coloured index cards the concepts were written on. In July, industry rag front pages frothed breathlessly over IBM and Apple's partnership to turn Pink into a new object-oriented operating system, which would run on chips based on the RS/6000 POWER architecture via Motorola as a junior partner (yes, the AIM alliance was, at least initially, <em>not</em> the biggest news). This new architecture, of course, was what would become PowerPC. Apple promised a PowerPC-based Mac in less than three years (i.e., 1994) between $2000 and $3000, running Mac OS, A/UX and the "Pink OS" (what would become Taligent). At the same time, it would continue developing 68K Macs, and enhance the Mac OS using object-oriented features from the C++-based MacApp framework.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEicrN414R_iJfQ1PG2JXbELn_8958YO8LMUPkAw-j2ETPtFzDvVg826ToUT1KdYvI-WltDMalTD2KXPTIF4qrtELKETYlUsE-mMTIl2MyScPPOtmh2sVbtnJXaq6NK0xKu4BTD1nBlauwQUPMEIZ9sCHcL_t65Steco01wff8jSJO2pel-NWqnGRax8K18/s1177/appleplusibmequalsibm.jpg"><img alt="" data-original-height="1063" data-original-width="1177" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEicrN414R_iJfQ1PG2JXbELn_8958YO8LMUPkAw-j2ETPtFzDvVg826ToUT1KdYvI-WltDMalTD2KXPTIF4qrtELKETYlUsE-mMTIl2MyScPPOtmh2sVbtnJXaq6NK0xKu4BTD1nBlauwQUPMEIZ9sCHcL_t65Steco01wff8jSJO2pel-NWqnGRax8K18/s320/appleplusibmequalsibm.jpg" width="320"></a></p><p>

There were also wild ideas about their operating systems cross-pollinating each other. IBM incorporating AppleTalk seemed logical, but on the outlandish side Pink was supposed to be able to run OS/2 applications, likely on the questionable advice of IBM Grand Unified Theory of Systems insiders in their quest for a unified microkernel OS. (This particular concept eventually became the Workplace OS, culminating in the doomed OS/2 prototype for PowerPC that never ran on Apple hardware, and its cancellation in 1995.)

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjUSVzPkMPVFW-Kg-ulIihxtvhZYIjae21GFlwnw54BpWZ9KFqfa8h22BMP9CvTBLQptEBBLUqLUBw9a22DU0atuLJbqcnBrbz_el5G8cz2qq0UKDr9EFacl-Vdts4jPt3QgOH-Wr-G2EfStmS3W0RZNhiiS__twhiOceZcQKP6Kuf5SYvIUR1shXmHv7E/s800/aux4.jpg"><img alt="" data-original-height="605" data-original-width="800" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjUSVzPkMPVFW-Kg-ulIihxtvhZYIjae21GFlwnw54BpWZ9KFqfa8h22BMP9CvTBLQptEBBLUqLUBw9a22DU0atuLJbqcnBrbz_el5G8cz2qq0UKDr9EFacl-Vdts4jPt3QgOH-Wr-G2EfStmS3W0RZNhiiS__twhiOceZcQKP6Kuf5SYvIUR1shXmHv7E/s320/aux4.jpg" width="320"></a></p><p>

The other weird announcement at the time was IBM and Apple codeveloping a new version of AIX that incorporated the Macintosh Toolbox. If that sounded a lot like a new <em>A/UX</em> instead, you get a prize. In November 1991 Apple announced A/UX 3.0 and detailed their plans for A/UX 4.x, intended to use an OSF/1 Mach kernel running on PowerPC, and by employing the same ABI (application binary interface) the new operating system could incorporate AIX compatibility. While IBM and Apple would continue to sell products <em>named</em> A/UX and AIX, they would instead be rebrands and value-adds ("personalities") on top of the same core OS, internally named PowerOpen. (Note the QuickTime racecar video in this screenshot appropriately named "openpower.")

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEji42iZCdRHa1eHNv16otgUsKxITk6u6TK-K-UVl9PZ5ip-OX3194lw5sWRuvzUX33o64aSVNaDxMyvHss5RfjOyTMO7PMVya3E1CGbbghb8ZS2ECeq0StO4J5Wrjm7ONSmkpgPcxlywMnC56Yafe_q7WvvfABhE5paP8ebeSGHQSREHjMsxi9FFmus8s0/s1800/appleready.jpg"><img alt="" data-original-height="789" data-original-width="1800" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEji42iZCdRHa1eHNv16otgUsKxITk6u6TK-K-UVl9PZ5ip-OX3194lw5sWRuvzUX33o64aSVNaDxMyvHss5RfjOyTMO7PMVya3E1CGbbghb8ZS2ECeq0StO4J5Wrjm7ONSmkpgPcxlywMnC56Yafe_q7WvvfABhE5paP8ebeSGHQSREHjMsxi9FFmus8s0/s320/appleready.jpg" width="320"></a></p><p>

Subsequently, in late 1993 Apple made their first public announcement of a PowerPC Apple server. Up to this time the Workgroup Servers, produced by the Server Group under John Sculley, had all been rebadged desktop Macs with additional software and peripherals such as tape backup (or, in the AWS 95's case, its fast PDS cache-SCSI card). While Apple still planned to create such a server to run System 7.x, a higher end model would run PowerOpen A/UX 4 as a direct successor to the AWS 95. Early announcements like this one even claimed it would be Apple's first 64-bit system by using the new PowerPC 620. (The 620 was ultimately a disappointing performer and ended up eclipsed by the 604.)

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhaWJBxUuM6NK5yqO_mphJNxJArFdOIKLnL70-9xudM87kxr7eiut_mMhRyqdkhKmWDsK6FOzwzuTldtMcaeAwwppt899WxaAvMYTIwPpcs2uv1zPU3-O2Mwxo3lSVP4oY-wGDP7nhMwwWS8f96YTAVvhYS-JlPFhVOnpoa6fww4rI76NiKJU7fgYo47eo/s690/netware.jpg"><img alt="" data-original-height="611" data-original-width="690" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhaWJBxUuM6NK5yqO_mphJNxJArFdOIKLnL70-9xudM87kxr7eiut_mMhRyqdkhKmWDsK6FOzwzuTldtMcaeAwwppt899WxaAvMYTIwPpcs2uv1zPU3-O2Mwxo3lSVP4oY-wGDP7nhMwwWS8f96YTAVvhYS-JlPFhVOnpoa6fww4rI76NiKJU7fgYo47eo/s320/netware.jpg" width="320"></a></p><p>

Around this time Apple's choice of server operating system made a sudden detour into, unexpectedly, Novell NetWare. In 1989 Novell introduced Portable NetWare, a "userspace" version of their network operating system that instead ran as an application on other operating systems. It provided all the standard NetWare file, print and network management services to NetWare clients, but was written in portable C and could be compiled from source with minimal changes by an OEM. The first ports were for Prime's 80386 Unix systems as well as NCR's port to Motorola 68000 machines. In 1991, IBM jumped on board, porting it to the new RS/6000s under AIX.
</p><p>
Novell had previous dealings with Apple, including as partners on the 1992 Star Trek project intended to "boldly go where no Mac has gone before" by porting System 7.1 to x86 on top of DR-DOS. Team members Fred Monroe and Fred Huxham later went on to work on <a href="http://oldvcr.blogspot.com/2023/07/apples-interactive-television-box.html">the Apple Interactive Television Box</a>. Star Trek was technologically successful but widely derided by industry observers, and when Michael Spindler became CEO in 1993, he cancelled it as a potential threat to the looming PowerPC transition.
</p><p>
The first Power Mac was the PowerPC 601-based Piltdown Man, descended from the Cognac project's famous RISC LC prototype, which became the Power Macintosh 6100 in March 1994 along with its sibling 7100 and 8100 systems. These first 601s were fabricated on a 600nm process with 2.8 million transistors; the later 601+ was <a href="http://oldvcr.blogspot.com/2019/11/how-far-weve-come-in-power-isa.html">a process shrink to 500nm</a>. The 6100 and 8100 were reworked into the Workgroup Server 6150 and 8150 respectively ("Starbucks"), running System 7 as promised, while the AWS 95 successor ("Green Giant") was forged by merging a similar case and slot layout with the fastest 80MHz 601 then available, along with its characteristic low-mounted floppy to accommodate the two 5.25" drive bays and a top-mounted CD-ROM.
</p><p>
Unfortunately for Apple, the new AIX-a/k/a-PowerOpen A/UX was nowhere near ready in late 1993, and Pink had metastasized by then into various Taligent platforms (OS/2 and AIX, and Apple's Copland) which weren't at all suitable either. Instead, Apple used their existing relationship with Novell to fit the Green Giant prototype with a PowerPC build of Portable NetWare, using some of IBM's porting work but running under System 7. Christened Wormhole, Mac Portable NetWare bombed with testers who were openly sceptical of the choice, and the Server Group launched Green Giant along with Starbucks in April 1994 as the <a href="http://www.floodgap.com/retrobits/ans/9150/">Workgroup Server 9150</a> — running Mac OS. Nevertheless, Apple promised at the same time to port Portable NetWare's successor, Processor Independent NetWare, to the Power Macintosh, and Spindler vowed at least one system would support it.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhdp5M4EutIbfOl7P-JfCZ3W96-kzJbRvN6I5nc7G0rLGY9AswGLljr0bPSGgJh-1qSbfzsu_xLFpO4pPR3TpPJ924KcWgUtFz2wzTH1NvO8NM2-tF7_qWfCmDwSbeJRIbpjUXwPKVakKK3l5hyphenhyphenohzpI71SLtGwUysth3q4EVpY4NRxZ1yfC2Z9JTTPGHs/s1400/wgs.jpg"><img alt="" data-original-height="793" data-original-width="1400" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhdp5M4EutIbfOl7P-JfCZ3W96-kzJbRvN6I5nc7G0rLGY9AswGLljr0bPSGgJh-1qSbfzsu_xLFpO4pPR3TpPJ924KcWgUtFz2wzTH1NvO8NM2-tF7_qWfCmDwSbeJRIbpjUXwPKVakKK3l5hyphenhyphenohzpI71SLtGwUysth3q4EVpY4NRxZ1yfC2Z9JTTPGHs/s320/wgs.jpg" width="320"></a></p><p>

But Apple had not forgotten about AIX. Although Gary Davidian's 68K emulator was intended to run the bulk of existing Mac software, there was no way it could efficiently run A/UX 3.x. The future was still (supposedly) the new AIX in whatever form that ended up taking, and native PowerPC apps thus used the same PowerOpen ABI as AIX in System 7 such that when (if) the new OS became available, PowerPC Mac applications would "just work." While all of the new PowerPC Workgroup Servers ran System 7.1.2 as shipped, Apple promised at rollout that both Starbucks and Green Giant would be able to run AIX 4.1 when it became available, and would continue to provide the AWS 95 for customers who wanted old school A/UX.
</p><p>
In the meantime, IBM had become impatient with Apple and determined that development delays were stunting the technological growth of the RS/6000 line. On top of that, Apple's headlong rush to market had fractured IBM's attempts to build a common PowerPC Reference Platform (PReP), leaving market-majority Power Mac hardware only able to run System 7, and market-minority IBM hardware only able to run everything <em>but</em> System 7 (including Windows NT and OS/2). To recover control IBM decided to unilaterally retake the reins.
</p><p>
In February 1994 IBM announced AIX 4, which would add symmetric multitasking to the kernel for the first time and was designed to run on anything from PowerPC desktop workstations to large POWER servers. Additionally, as the industry was moving <i>en masse</i> to Intel's new PCI standard, IBM also made the jump from MicroChannel to PCI, starting with the Type 7020 series running the PowerPC 601 in October 1994. While MicroChannel would remain supported in AIX and PReP, PCI was the future, and IBM wouldn't support NuBus. Apple followed suit and announced they would move to PCI as well (not without controversy; an InfoWorld columnist in October 1994 argued that compared to NuBus "PCI is a cleverly disguised trap [by Intel] and Apple is walking right into it"), introducing the "Tsunami" Power Macintosh 9500 as the first PCI Mac in June 1995. It came with the new high-performance PowerPC 604 up to 150MHz, fabricated on a 500nm process with 3.6 million transistors.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhS4K-d7SzRO_sbQ8MG1qvsniuEOhATO-RtXsCUickdcNk2QZsAExljw2J7OgFKQslhgAhyphenhyphenGvaOYn45VzWi35PHI-rPoszKvm6EOiD8U5NKaKWcO66TftU5UjuBFDsSPAfZWQ6bTdWej1nSz6LBTTXuEC7rKPRGWP8VobSSmmqEm_uPauoxV61zUAiPMRY/s800/taligentyo.jpg"><img alt="" data-original-height="594" data-original-width="800" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhS4K-d7SzRO_sbQ8MG1qvsniuEOhATO-RtXsCUickdcNk2QZsAExljw2J7OgFKQslhgAhyphenhyphenGvaOYn45VzWi35PHI-rPoszKvm6EOiD8U5NKaKWcO66TftU5UjuBFDsSPAfZWQ6bTdWej1nSz6LBTTXuEC7rKPRGWP8VobSSmmqEm_uPauoxV61zUAiPMRY/s320/taligentyo.jpg" width="320"></a></p><p>

While desktop users were delighted, Apple's enterprise customers started grumbling even louder. Apple still had open promises to them about AIX, Taligent (as CommonPoint, shown here in a beta screenshot) was furthest along on AIX and Apple still had an arrangement for AIX, but neither Copland nor new-A/UX were happening, and IBM made clear that AIX on NuBus wasn't going to happen either. At this point Apple simply abandoned PowerOpen and concluded it would never ship as such: if this mythical high-end Apple server was going to run AIX at all, it would have to run it straight up. There was no way to magically turn Green Giant into a PCI box, and phoning in a "Workgroup Server 9550" (no such model ever existed, for the record) would cause a buyer revolt, so the Server Group took Tsunami back to the shop and reworked it instead.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjdgWbvrtf-67wms-72j2Cy88MLuDh36eUSJuczjDINaHiPt4r2aRoE4KG7tjAghX1jBFKfDBbxVcf81wXvyreTBGamSzElHcHp4kDmVjNtAUqfe-VZvu_40P7946b0QPMUfZDicwCxfMqvKetpl98NfPS21U_GaTM-l_hl6_F3J6DU3ktzoK4kIiapDH0/s4080/PXL_20231105_004057899.jpg"><img alt="" data-original-height="4080" data-original-width="3072" height="320" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjdgWbvrtf-67wms-72j2Cy88MLuDh36eUSJuczjDINaHiPt4r2aRoE4KG7tjAghX1jBFKfDBbxVcf81wXvyreTBGamSzElHcHp4kDmVjNtAUqfe-VZvu_40P7946b0QPMUfZDicwCxfMqvKetpl98NfPS21U_GaTM-l_hl6_F3J6DU3ktzoK4kIiapDH0/s320/PXL_20231105_004057899.jpg"></a></p>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhoH8WIBs3smLqBvF61SP3qrMy9BzAqVOKBeA0hLC_noKt62KVq7jMBmrFsX-l7uEm0SK42HmVlLT0XGiCbLU50hPw0Y9VHtZc6dcZdchoYXdwcaXjXz2kzROPawSbZ978R1QiFVh5jz0pXYv2L8ZQgZWjUA__IKV8NYIvg8QL1T2WMSN8okaOPp2AiovY/s2048/DSCN5883.JPG"><img alt="" data-original-height="1536" data-original-width="2048" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhoH8WIBs3smLqBvF61SP3qrMy9BzAqVOKBeA0hLC_noKt62KVq7jMBmrFsX-l7uEm0SK42HmVlLT0XGiCbLU50hPw0Y9VHtZc6dcZdchoYXdwcaXjXz2kzROPawSbZ978R1QiFVh5jz0pXYv2L8ZQgZWjUA__IKV8NYIvg8QL1T2WMSN8okaOPp2AiovY/s320/DSCN5883.JPG" width="320"></a></p><p>

This task was primarily done in Austin, where the new machine picked up its codename "Shiner" after the developers' favourite brand of beer, along with additional work at DeAnza 3 in Cupertino. Shiner's on-board hardware was reorganized to boot AIX directly and Apple contracted design firm Lunar <a href="http://www.floodgap.com/retrobits/ans/brags/lunar/">to design its unique chassis</a> with hot-swappable drives, fans and redundant power supplies, a backlit status LCD, a sliding drawer for the logic board, and a front locking translucent door. The top image is my 500 in operation; the bottom was the bare chassis when I had to strip it down a number of years ago to figure out a hardware problem. It's big, beefy and beautiful.
</p><p>
Unfortunately, other glitches delayed Shiner's release. As AIX was SMP-capable, Apple planned to offer Shiner with multiple processors, but the original 604 was found to have a serious hardware bug that impaired cache coherency when more than two processors were present. While this didn't affect designs like DayStar Digital's <em>asymmetric</em> multi-processor Power Macs, it seriously affected IBM, Groupe Bull and Zenith, who retreated to the 601, and stalled out Shiner. Motorola did not start sampling a fixed CPU until October 1995.
</p><p>
However, the software turned out to be a far bigger problem. Spindler's ill-advised promises around Processor Independent NetWare bloated the development schedule, as PIN was an actual operating system the machine had to boot instead of userspace server daemons like Portable NetWare was, and the arrangement wasn't cancelled until late in 1995 when Novell decided to develop for the new CHRP PowerPC machines instead. (This was the Cygnus port of NetWare to PowerPC, and ended up little used, since it never ran on Macs. Novell abandoned PIN completely with NetWare 5 in 1998.)
</p><p>
After that, AIX remained the leading choice for Shiner, but IBM and Apple continued to fight over how Macintosh applications would work under Shiner's specific flavour of AIX, codenamed "Harpoon." While Apple's existing Macintosh Application Environment (MAE) was well known for running 68K Mac applications in emulation under Solaris and HP/UX, its absence on AIX had long been considered conspicuous. As promised, an early prototype environment called Macintosh Application Services for AIX (MAS) could run some Power Mac applications natively on Harpoon using a ported Toolbox and system libraries — keep that fun fact in the back of your head for a moment — but Apple could not sustain the development of MAS and cancelled it in March 1995. Meanwhile, Apple internal sources reported in August that neither Apple nor IBM were willing to pay the development costs even for a straightforward MAE port. As a trial balloon Apple ended up developing a version of Mac OS specifically for Shiner and actually demonstrated it, but the great confusion it elicited in potential buyers caused Apple to scrap it before the machine's début. AIX was the last OS standing, so Shiner ran AIX applications, and nothing but.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjDPgwbKVprvsYRDriqpM5Z9-UVbw_78iTVN8ZX-kCYrP_0dURj1X-y9eeKaqCMPFTsHhWxJsu7ecjxoDHg2UpQu5prNrhjdnqibXlJXz7EcAFd2kyO4qauxcyZzNxROhmq2n0I5UphPjeiw6rQgLV-23SuuOdyFcGpZ7yW87nXIXLFoN1mNWXtxiA7H7s/s2048/DSCN0778.JPG"><img alt="" data-original-height="1536" data-original-width="2048" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjDPgwbKVprvsYRDriqpM5Z9-UVbw_78iTVN8ZX-kCYrP_0dURj1X-y9eeKaqCMPFTsHhWxJsu7ecjxoDHg2UpQu5prNrhjdnqibXlJXz7EcAFd2kyO4qauxcyZzNxROhmq2n0I5UphPjeiw6rQgLV-23SuuOdyFcGpZ7yW87nXIXLFoN1mNWXtxiA7H7s/s320/DSCN0778.JPG" width="320"></a></p><p>

Eventually Shiner prototypes made it to testers — I have <a href="http://oldvcr.blogspot.com/2021/10/shiner-esb-apple-network-server.html">a non-functional EVT ANS prototype that used to be at Netscape</a> — and Apple announced it in two flavours, the "low end" Shiner LE (minus extra bays and with only a single power supply) that became the ANS 500 and the canonical "high end" Shiner HE that became the ANS 700. (I have an ANS 700 as well, which is quite logically named </p><tt>holmstock</tt><p>, but the 500 is the system in normal operation and the one we'll demonstrate here.) Prices for the configurations ranged from $10,969 for a low-end (ahem) 500/132 with 32MB of RAM (about $21,000 in 2023) to $14,999 for a 700/150 with 48MB of RAM (about $30,000), <em>plus</em> the two-user AIX license adding another $1,498 ($3,000), <em>and</em> $1,399 ($2,800) to upgrade that license to unlimited users if you needed it. Alongside the full-size machines Apple developed a rackmount prototype called Deep Dish intended to become the ANS 300, but decided not to release it, even though I know of at least two that still exist and casually drive by their houses a lot.
</p><p>
The ANS 500 and 700 finally reached market in February 1996 as one of the first new products under Gil Amelio, who replaced Spindler that month after his removal by the Apple board of directors. The systems got very positive reviews in the press, but their exorbitant price tags did not go unnoticed — a story we'll pick up at the end.
</p><p>
I gave you all that history to point out that RS/6000 AIX and the classic Mac OS, at least for a period of time, ended up influencing each other in surprising ways (just wait until we get to what snuck into IBM's C compiler), and that there was also some period of time in which AIX was going to <em>be</em> the next Mac OS. The history helps us understand it's no accident they use the same ABI for registers and calling conventions, slightly different from the PowerPC SysV ABI used by operating systems like Linux and the BSDs, and support the same XCOFF objects, at least at first (MPW used it as an intermediary in early versions). Although XCOFF was gradually obsoleted in MacOS as a binary format, New World Macs can still boot XCOFF from Open Firmware, and the PowerOpen ABI persisted into the Mac OS X era through the very last day Leopard on PowerPC was supported. This sort of low-level integration would not have made any sense, even as a colossal coincidence, unless both AIX and Mac OS were intended to have the same underlying foundation, and that observation makes it much less strange that the ANS would have ended up running it.
</p><p>
ANS AIX runs virtually everything that IBM AIX can run with the exception of certain device drivers and stuff that depends on MicroChannel — it ran all the binaries the local 3.2.5 systems had at the University without recompiling them, for example — but the reverse may not be true, even for userland applications, if those applications take advantage of what Apple added to it. Indeed, the work that went into making a Macintosh Toolbox that could run on AIX, and porting core Mac OS libraries to also run natively on AIX, did not go entirely wasted. Aside from Mac-specific hardware support like ADB, three specific portions ultimately shipped on every Harpoon CD.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgyENV4W4NARYpvCWMzc0mSGtmmdLSe6DTz1EpWQMXw_JneP_blrmuPEaZmyx_ykPUDDVabvP8Mt8ADQ_RWi07b4A2j8KZNuS1b0huT7qDI88rfvRe3as6ka00DDZDe-sS0ZOyqLXmQaqNuZFDW0JL3lpy_wg4D293xZpIZ_mjX94xsq0FPx2KFysf1pl4/s1024/nu-vlcsnap-2023-11-04-15h39m09s420.png"><img alt="" data-original-height="768" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgyENV4W4NARYpvCWMzc0mSGtmmdLSe6DTz1EpWQMXw_JneP_blrmuPEaZmyx_ykPUDDVabvP8Mt8ADQ_RWi07b4A2j8KZNuS1b0huT7qDI88rfvRe3as6ka00DDZDe-sS0ZOyqLXmQaqNuZFDW0JL3lpy_wg4D293xZpIZ_mjX94xsq0FPx2KFysf1pl4/s320/nu-vlcsnap-2023-11-04-15h39m09s420.png" width="320"></a></p><p>

The first portion was AppleTalk. For those unfamiliar with AIX, this is </p><tt>smit</tt><p> on the ANS in TTY mode ("</p><tt>smit</tt><p> happens," as we say in the biz), the System Management Interface Tool used as AIX's central configuration interface. It comes in both this text version for terminals or in a native X11 version that's point-and-click to at least some degree. Apple created an entire menu within SMIT to support AppleTalk so that AIX administrators could manage it in the fashion to which they were already accustomed. Here we're on the ANS' console, which AIX calls the Low Function Terminal or LFT; I took these screenshots from the ANS's VGA port using an INOGENI VGA2USB3, cropping and slightly correcting the aspect ratio.
</p><p>
The implementation of AppleTalk in ANS AIX was mostly complete, including support for NBP (AppleTalk Name Binding Protocol), AFP (AppleTalk Filing Protocol, including modern AFP-over-TCP in Harpoon 4.1.5), and ADSP (the AppleTalk Data Stream Protocol) among others. Daemons provided AppleTalk routing and printing services, though a glaring deficiency was direct support for AppleShare, which required a third-party package. Apple included two demonstration disks with the ANS, IPT uShare and Helios EtherShare.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgGfxCT3WFULjhHPVN8zsLoT6yXRcd0odbgBJWD3joHl8cIDSCAdAqsL3d162ZKNLspGzizw_rbMwVGznYBsUXjY7hz7baUZxxWyu73VsCwyP0RlJiIrPeMXhmQuarj2tR2oXrz3nIjX-ReEZMQG5Mbtanw6r47qp2DG3MmNb0ZD6dRuQB2AbpYSf5YM5w/s1024/nu-vlcsnap-2023-11-04-15h39m46s896.png"><img alt="" data-original-height="768" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgGfxCT3WFULjhHPVN8zsLoT6yXRcd0odbgBJWD3joHl8cIDSCAdAqsL3d162ZKNLspGzizw_rbMwVGznYBsUXjY7hz7baUZxxWyu73VsCwyP0RlJiIrPeMXhmQuarj2tR2oXrz3nIjX-ReEZMQG5Mbtanw6r47qp2DG3MmNb0ZD6dRuQB2AbpYSf5YM5w/s320/nu-vlcsnap-2023-11-04-15h39m46s896.png" width="320"></a></p><p>

Notably, the AppleTalk version in Harpoon 4.1.5 is given as 2.0. The AppleTalk stack could run on any port (here on </p><tt>et1</tt><p>, the 10/100 PCI card connected to the secured wired network) or route between multiple ports. Besides the daemons, Apple included an AIX AppleTalk library applications could link with, as well as a subset of Apple's Universal Interface headers tweaked for AIX.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgv0KRu62tlmtO_7UJQL745q4m0kuctYYmkcG-6Hhcy3awk3JfJkiudfIuyUJYzghtfluJYFbSH9c9r92-9IQalYzy-ujByy6WpysIj5yvJTsSGb5gUbhxHcTEfiM9tC9yB02D3tPTCwW71-2LHQwltS11UCtF2BfnV2t8MnHfGrqF6KQWoDuDJXLZRa2c/s1024/nu-vlcsnap-2023-11-04-15h40m02s127.png"><img alt="" data-original-height="768" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgv0KRu62tlmtO_7UJQL745q4m0kuctYYmkcG-6Hhcy3awk3JfJkiudfIuyUJYzghtfluJYFbSH9c9r92-9IQalYzy-ujByy6WpysIj5yvJTsSGb5gUbhxHcTEfiM9tC9yB02D3tPTCwW71-2LHQwltS11UCtF2BfnV2t8MnHfGrqF6KQWoDuDJXLZRa2c/s320/nu-vlcsnap-2023-11-04-15h40m02s127.png" width="320"></a></p><p>

The other two portions were a full send-and-receive implementation of Apple events, also implemented as a native AIX library with headers, and running on top of that an AIX native version of the Program-to-Program Communications Toolbox called </p><tt>ppcd</tt><p>. In this article we'll make use of all three.
</p><p>
The PPC Toolbox, which has nothing to do with PowerPC and works on 68K Macs as well, was introduced with System 7.0 and allows applications to exchange messages with other applications, either on the same Mac or across the network. To this end it runs on top of Apple events and AppleTalk (the actual transport) and provides a browser to find available systems and willing applications running there, plus services for authenticating to those remote systems.
</p><p>
PPC Toolbox's primary purpose on the Mac itself was as the underlying mechanism for program linking, an unfortunate term, since this feature was distinct from simply running an application present on a shared volume. When program linking was active (from the Sharing Setup control panel), it was possible to receive Apple events from another Mac to control applications running on your Mac. When a PPC Toolbox-aware application is running and registered, it becomes visible to other Macs when they ask through their local PPC Toolbox browser about what network services are available. WebSTAR was <a href="https://www.nzdl.org/cgi-bin/library?e=d-00000-00---off-0tidbits--00-0----0-10-0---0---0direct-10---4-------0-1l--11-en-50---20-about---00-0-1-00-0--4----0-0-11-10-0utfZz-8-10&amp;cl=CL1.18&amp;d=HASH01381c73e66fc26a090a8fbc.3&amp;gt=0">one such example</a>, where the WebSTAR webserver was often running on a separate machine, and when the WebSTAR Admin application started up it asked on the network what WebSTAR servers were present that it could control. As unrestricted remote access of that sort would pose an obvious security hole, the administrator had to first authenticate to the desired server and then could manipulate it remotely. Many power users wrote AppleScript to accomplish something similar, since AppleScript to this day is all about sending Apple events to applications, and the core concept is still part of modern macOS.
</p><p>
Harpoon <tt>ppcd</tt> expands on this notion, almost like an Apple event-aware <tt>inetd</tt>. It presents itself just like any other remote Mac and responds to queries with its list of available services; it's just that these services are actually entries in its configuration file, along with provision for more sophisticated daemons that can deal with clients directly. When a client Mac requests a service, it authenticates to the ANS just like it would authenticate to any other Mac, and then <tt>ppcd</tt> executes the desired service which exchanges data with the client over AppleTalk — just like any other Mac.
</p><p>
Some of you will have asked whether A/UX 3.x can do such a thing, and the answer is yes, but only in the same way another remote Mac can; i.e., there's no special A/UX <em>Unix-side</em> support like there is in ANS AIX, and the PPC Toolbox is only available on A/UX if you're running the A/UX Finder. The A/UX documentation makes that plain: "The A/UX Program-to-Program Communications (PPC) Toolbox is identical to the Macintosh OS PPC Toolbox." A/UX had its own style of hybrid applications that could offload work to a separate Unix process but those sorts of applications all ran locally. Only ANS AIX was capable of what we're going to show here.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhlbcn4VDd7-sNTOk4tjtGM2l3xKdVNBF3k7DPlOBDlCa8pmu5Y_MaRsWj5hJTcqNCNCG7Za0nhcRZhMknmnorqOcojnzwkX7Pp9c52gYHcvYfzQp4_6C10v4wZ3Vcc-d-563-Q76Q21NCdQQGKZld4ZdsI5iY9KLZiQ1A76n0gC807src1VEN7lcJ3_K8/s832/Picture%204.png"><img alt="" data-original-height="624" data-original-width="832" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhlbcn4VDd7-sNTOk4tjtGM2l3xKdVNBF3k7DPlOBDlCa8pmu5Y_MaRsWj5hJTcqNCNCG7Za0nhcRZhMknmnorqOcojnzwkX7Pp9c52gYHcvYfzQp4_6C10v4wZ3Vcc-d-563-Q76Q21NCdQQGKZld4ZdsI5iY9KLZiQ1A76n0gC807src1VEN7lcJ3_K8/s320/Picture%204.png" width="320"></a></p><p>

Apple included several clients and servers with ANS AIX, mostly demos, but a couple of eminently useful ones. The Mac clients themselves were on a floppy disk that came in the ANS' accessory box, though fortunately if yours didn't come with one Apple also includes them under </p><tt>/usr/lpp/apple.remoteutils/clients</tt><p>. Irritatingly, not all of them provide source code.
</p><p>
To install and run them, only one extension is absolutely required: the <tt>Network Server Passwd Tool</tt>, which handles authentication to your ANS. Drop it into your Extensions folder and reboot, and when prompted by the client, enter your regular ANS AIX login and password. Note that your password is <em>not</em> transmitted encrypted — everything is cleartext — and thus you should only play around with these programs on a secured local network. In particular, do <em>not</em> run the ANS AppleTalk stack on an interface connected to a WAN. You don't know where it's been, so don't put it in your mouth.
</p><p>
I should also note before we continue that these clients don't appear to work properly with Mac OS 9 (nor Classic except possibly 8.6 under Rhapsody Blue Box), which added support for the PPC Toolbox <a href="http://www.stuartcheshire.org/quicktime/ppctb.html">to run over TCP/IP as well as AppleTalk</a>. Harpoon's implementation only supports AppleTalk and interacting with it seemed to unsettle my OS 9 machines, so you should run these clients on Mac OS 8.6 or earlier, or A/UX 3.x.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhz48cyIdpjOdhfacyh0UsEi_nuWpO_TluDDAatpY9hFHiy_f5dWZkGENCWL-sA_BzBrB2oDZSlluwvhM9HBiIeE89QXItJjDFiIxV5qLnCUq_NBKjexhp5ilqIyWg51TbnuQ97_ThV-Kz5RC4teY7YitV_-xQXFABX8Ch3keZJr2EliIvjQubgw0tun7o/s2560/IMG_20231104_161134_HDR.jpg"><img alt="" data-original-height="2560" data-original-width="1920" height="320" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhz48cyIdpjOdhfacyh0UsEi_nuWpO_TluDDAatpY9hFHiy_f5dWZkGENCWL-sA_BzBrB2oDZSlluwvhM9HBiIeE89QXItJjDFiIxV5qLnCUq_NBKjexhp5ilqIyWg51TbnuQ97_ThV-Kz5RC4teY7YitV_-xQXFABX8Ch3keZJr2EliIvjQubgw0tun7o/s320/IMG_20231104_161134_HDR.jpg"></a></p><p>

Let's demonstrate how this works in practice by going back to our little compact friend. While our usual 68K workhorse is my hard-truckin' clockchipped Quadra 800, we're going to constrain things a bit more with this Mystic Colour Classic. Now, this is still a fairly beefy 68K Mac, since a Mystic is actually a Colour Classic with an LC 575 logic board swapped in, and this one was further upgraded with a 25MHz full '040 and 64MB of RAM (though mostly wasted right now due to 24-bit addressing for its Apple IIe Card).

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEibI-xvASPGDJQQMWfg_ElsgEWdXMuP4Gy22gHnx6SBR9vAtgn9w14o3IOvNLgzk5SgcO9sCBlfVhuSkAOSTGS6-7d-2BdKkoVmoBfzTgyDc7W5vfzBozUtaeVNNjE9Kqq3CSPnmY8KpLBiPpwlXljM1T8zBfeaiguEM9BwLDDb3brta_F9XU1raBEZpJA/s4080/PXL_20231104_231349444.jpg"><img alt="" data-original-height="3072" data-original-width="4080" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEibI-xvASPGDJQQMWfg_ElsgEWdXMuP4Gy22gHnx6SBR9vAtgn9w14o3IOvNLgzk5SgcO9sCBlfVhuSkAOSTGS6-7d-2BdKkoVmoBfzTgyDc7W5vfzBozUtaeVNNjE9Kqq3CSPnmY8KpLBiPpwlXljM1T8zBfeaiguEM9BwLDDb3brta_F9XU1raBEZpJA/s320/PXL_20231104_231349444.jpg" width="320"></a></p><p>

But I picked this one specifically because it has no Ethernet connection: everything we'll do on it is over LocalTalk, where AppleTalk is its <i>raison d'être</i>. I'll have up the Network control panel so that you can see I'm not cheating with MacIP, and I've chosen to take actual photographs of the screen instead of screenshots (except in one specific case) to prove there's nothing up my blogger sleeve. To allow the Mystic to actually see the ANS, the LocalTalk segment is bridged to EtherTalk by a Dayna EtherPrint-T, though things like a Shiva FastPath, GatorBox or even a software LocalTalk bridge will also work for this purpose.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEixF8CyI-fVvP2TVq_iICAxSa-y3K79iRdBEpQGtAzJg55rOdqRdTSZnNiFOh1Yt6srHwgOBolDF9Ey_0xJp_SdQvNIDvS9BWkMQHuqszSmFQ1Rzq82LkU4YGJ6iib8dzpegt3V-3OsOrntzitD2hlzejHzgMg4skex4dV6IcrhOqAWjY3DLsGgT2Ind_k/s2560/IMG_20231104_161555_HDR.jpg"><img alt="" data-original-height="1920" data-original-width="2560" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEixF8CyI-fVvP2TVq_iICAxSa-y3K79iRdBEpQGtAzJg55rOdqRdTSZnNiFOh1Yt6srHwgOBolDF9Ey_0xJp_SdQvNIDvS9BWkMQHuqszSmFQ1Rzq82LkU4YGJ6iib8dzpegt3V-3OsOrntzitD2hlzejHzgMg4skex4dV6IcrhOqAWjY3DLsGgT2Ind_k/s320/IMG_20231104_161555_HDR.jpg" width="320"></a></p><p>

Of the two actually useful client-server services Apple included, probably the most useful is the CommandShell. This one requires the included </p><tt>CommandShell VT102</tt><p> extension to be installed, but you might have it installed already as this is the same one many other applications use, and it's not required at all on A/UX because it already has it for A/UX's own command line.
</p><p>
When we start the Command Shell, the PPC Browser window pops up first and prompts us to "Select a CommandShell server" (this message is configurable). A list of running Macs or suitable Mac substitutes participating in PPC is populated in the upper left corner, and if you had any AppleTalk zones to choose between (I don't), you'd see them on the lower right. We see two here, the Colour Classic itself ("CC") and <tt>stockholm</tt>.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhvhcq2RWV0vk8YUC7vGzzp_Yp1y7aBczTefg7dg7YzQZ40XycAvcWs1RDlYyFj_J3AzKqeffgm0DDsOfuf8fjtbUYm_eRufywELTEltU7eFswK90D49eb0iHhDyEv4nbmCYU89a_AN7rji6pD4RY4hval3IQZNt8l3I-IaA-9WJq9Wr5ZZ1u3d2qOgCd4/s2560/IMG_20231104_161650_HDR.jpg"><img alt="" data-original-height="1920" data-original-width="2560" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhvhcq2RWV0vk8YUC7vGzzp_Yp1y7aBczTefg7dg7YzQZ40XycAvcWs1RDlYyFj_J3AzKqeffgm0DDsOfuf8fjtbUYm_eRufywELTEltU7eFswK90D49eb0iHhDyEv4nbmCYU89a_AN7rji6pD4RY4hval3IQZNt8l3I-IaA-9WJq9Wr5ZZ1u3d2qOgCd4/s320/IMG_20231104_161650_HDR.jpg" width="320"></a></p><p>

When we choose </p><tt>stockholm</tt><p>, a list of services that answer to the desired signature (</p><tt>CmdS</tt><p>, an </p><tt>OSType</tt><p>-style FourCC) appear. There is just one that </p><tt>ppcd</tt><p> offers, the CommandShell service itself.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhYYltx8IBzHHP8x-YhcCzuFriAItF1SE8xI_cGd1W5ASbfO6Dq4aV2U16xFX57fbE2JXAkuksPpKPspSn-rs_gB_MskBtVkdgK5Rtb18efbTwQ84hB4bg4vYfTMwnDiOr6y3kizoznOJ-vveG0XsPAW67KB0TG2o3GZqIM_zYoE1yIFErUoRCPWXh275M/s2560/IMG_20231104_161745_HDR.jpg"><img alt="" data-original-height="1920" data-original-width="2560" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhYYltx8IBzHHP8x-YhcCzuFriAItF1SE8xI_cGd1W5ASbfO6Dq4aV2U16xFX57fbE2JXAkuksPpKPspSn-rs_gB_MskBtVkdgK5Rtb18efbTwQ84hB4bg4vYfTMwnDiOr6y3kizoznOJ-vveG0XsPAW67KB0TG2o3GZqIM_zYoE1yIFErUoRCPWXh275M/s320/IMG_20231104_161745_HDR.jpg" width="320"></a></p><p>

We select that and are prompted for our AIX login and password.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg4B4mYyXXXcuHVQ8uUhfGkTOx0pdsqyr7VuIr0MENTbWWx7JA7cTnOtqW6MDaZgH5eymu7kP6MyoAnZ-TqsDgxobz1cMh-WSOLn32w306ahC4R08hxk1akBjhILqBePkAZPK9OeUfTtZrA-hTvtdDNTEmQwT6l03-kruEBxchsm3-II3bgKHXJP946Is4/s2560/IMG_20231104_162139_HDR.jpg"><img alt="" data-original-height="1920" data-original-width="2560" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg4B4mYyXXXcuHVQ8uUhfGkTOx0pdsqyr7VuIr0MENTbWWx7JA7cTnOtqW6MDaZgH5eymu7kP6MyoAnZ-TqsDgxobz1cMh-WSOLn32w306ahC4R08hxk1akBjhILqBePkAZPK9OeUfTtZrA-hTvtdDNTEmQwT6l03-kruEBxchsm3-II3bgKHXJP946Is4/s320/IMG_20231104_162139_HDR.jpg" width="320"></a></p><p>

And, lo and behold, a terminal window pops up. But this connection isn't over Telnet or even traditional serial: it's ADSP, using the pseudo-hostname </p><tt>cmdshell</tt><p>. You can even open multiple connections, which </p><tt>ppcd</tt><p> will multiplex.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiDe3NYDasUBNoOXqqehoCyKoA2_UB6-o6bUIrbyl3V8J7MpOTYQK4Pog1PmTpOckiFxqAIEVux7LqFKUw1DThWqXmf4TZVlwZmxwEnjQV7HC5QNewMKhULlVymt-Jmud4VsuM5vCdBuPDlOSQwaaCj3aw9-q7rOYJ8DMTNl3PcVwUkvTEPPiML5GMtO2A/s2560/IMG_20231104_162235_HDR.jpg"><img alt="" data-original-height="1920" data-original-width="2560" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiDe3NYDasUBNoOXqqehoCyKoA2_UB6-o6bUIrbyl3V8J7MpOTYQK4Pog1PmTpOckiFxqAIEVux7LqFKUw1DThWqXmf4TZVlwZmxwEnjQV7HC5QNewMKhULlVymt-Jmud4VsuM5vCdBuPDlOSQwaaCj3aw9-q7rOYJ8DMTNl3PcVwUkvTEPPiML5GMtO2A/s320/IMG_20231104_162235_HDR.jpg" width="320"></a></p><p>

A less practical, but actually rather more impressive, demonstration of what this mechanism is capable of is the Fractal Demo. Some of you on the other side of the pond may remember the <a href="https://www.c64-wiki.de/wiki/Mandelbrot-Construction-Set">Mandelbrot Construction Set</a> (auf Deutsch) from 64'er October 1991, which computed the Mandelbrot fractal set on a Commodore 64 while using the 6502 in a connected Commodore 1541 disk drive as a coprocessor. But the C64's 6510 and the 1541's 6502 ran at approximately the same clock speed (1MHz), whereas here we're going to shunt the work from a 25MHz 68040 to a 200MHz 604e.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEje-vjX87IGmyGlVMKBWgFhleW7Q32S4gUdvXz6oUUYDJMEIqXBkdOur4GpJFSeahAa3bP3QarqltCJPNZeI94fEdycoS_o0TV1NJkas55pO8mBlINVt57gW2WO_ZHmtN9ICVsF4IxPTPbbVtHIwcdtlHJ0ZIKx-5tATzyhgC8sBO6007ZB-tUUSeDrvwk/s512/FPicture-1.png"><img alt="" data-original-height="384" data-original-width="512" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEje-vjX87IGmyGlVMKBWgFhleW7Q32S4gUdvXz6oUUYDJMEIqXBkdOur4GpJFSeahAa3bP3QarqltCJPNZeI94fEdycoS_o0TV1NJkas55pO8mBlINVt57gW2WO_ZHmtN9ICVsF4IxPTPbbVtHIwcdtlHJ0ZIKx-5tATzyhgC8sBO6007ZB-tUUSeDrvwk/s320/FPicture-1.png" width="320"></a></p><p>

For these shots I've switched to screen grabs so you can see the generated image at full quality. The Colour Classic ordinarily has a 512x384 screen (the Apple IIe modes notwithstanding) but the application will generate at nearly any window size or one of the prespecified ones. You can also adjust the lookahead and the square size of each transaction from the server.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEihYncfTn4JILckWMWIvuxQOaCrxJW7d7QiGihY3hjCNxW6wnYy9_447f03c6x0enLI_EFMyHfBBhUgPEa-qPB09CNhoKzDTiJG01SqryMgI2wkchtQODVn_Zkd-f-CaQGZiCMyPTIpD9VSIkBBph5HF7vczpp_OiCNe6Wy1uU9JxZPsWz1pKb2VR_GN3I/s512/FPicture-2.png"><img alt="" data-original-height="384" data-original-width="512" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEihYncfTn4JILckWMWIvuxQOaCrxJW7d7QiGihY3hjCNxW6wnYy9_447f03c6x0enLI_EFMyHfBBhUgPEa-qPB09CNhoKzDTiJG01SqryMgI2wkchtQODVn_Zkd-f-CaQGZiCMyPTIpD9VSIkBBph5HF7vczpp_OiCNe6Wy1uU9JxZPsWz1pKb2VR_GN3I/s320/FPicture-2.png" width="320"></a></p><p>

When a screen is rendered, you can zoom in by drawing a box around it, and the ANS will send back a zoomed view.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjBjI1GlYc0y2_2DC2WsS6461_jnDunSEj60cuYOq7G2kRHLe_dKE8rTcrXUQ1ZGh2si6_9Emfnx86FQu0eduD1i6ldQnd2aLgkQ7YKcwxKj-gmLnFVbSVWPkhF2kgemSDZ7A3hh9X3y6HIz6kyi4P2_kAZJhzBicTXOa7elGMSW1NinZTVCjGvETlelZk/s512/FPicture-3.png"><img alt="" data-original-height="384" data-original-width="512" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjBjI1GlYc0y2_2DC2WsS6461_jnDunSEj60cuYOq7G2kRHLe_dKE8rTcrXUQ1ZGh2si6_9Emfnx86FQu0eduD1i6ldQnd2aLgkQ7YKcwxKj-gmLnFVbSVWPkhF2kgemSDZ7A3hh9X3y6HIz6kyi4P2_kAZJhzBicTXOa7elGMSW1NinZTVCjGvETlelZk/s320/FPicture-3.png" width="320"></a></p><p>

This particular client-server pair has full source code for both ends. It seems to date from rather early in development: the Mandelbrot generation code is credited to Mark Maxham at the Apple Advanced Technology Group, dated February 1992, while the rest of the server is credited to Scott Mulligan and dated 1993 and 1994, though the actual file modification times are 1995 and 1997 (the latter from the 4.1.5 upgrade).
</p><p>
Once the server gets a request from the Mac client, it confirms that both the client and server are speaking a compatible protocol version (there was only ever one publicly released), and then receives a request specifying the square size, which square, and over what interval, to which it replies with a byte array of graphic data corresponding to the requested square. Zoom requests are received as new intervals. These are all structured Apple events, even the array of bytes, which is simply transmitted as a block of raw data within the Apple event reply. A system of periodic heartbeat events roughly every 30 seconds lets the two sides know that the other is still present.
</p>
<p>
To give you an idea how quickly this scheme could operate, even over LocalTalk, here's a realtime (not time-lapse) video of the process. Initially we use the smallest square size, but at this size the overhead of handling the Apple events dominates compared to the amount of data actually generated, and the process is relatively slow. When we jump to the largest square size, however, we generate a much larger set per transaction and the window fills up in seconds. Let's hear it for making someone else do the work!
</p><p>
This demonstration also points out something important about the architecture. The classic Mac OS, as beloved as I find its interface, is a well-known dog's breakfast under the hood with little provision for memory protection and relying on MultiFinder-era cooperative multitasking. Even in the era of the 8.6 nanokernel and Multiprocessing Services, where you could at least theoretically have preemptive tasks, those tasks still had to have a presence in the UI and that part of the system remained cooperative.
</p><p>
If we were doing the math locally, the calculations would have dragged the system down and impaired its ability to service its own interface effectively, let alone any other application running at the same time. But by deferring the calculations to the ANS, we've almost completely fixed this problem: the ANS does it faster, the ANS does it <em>asynchronously</em> (the system gives you a callback when the data arrives and until then you can just blissfully yield with <tt>WaitNextEvent</tt>, keeping the rest of the user interface responsive), and the ANS can service multiple clients because it <em>does</em> preemptively multitask, meaning your entire LAN is covered.
</p><p>
Remember, in the 1995 timeframe when all this was being developed, Copland (and therefore Taligent) was a Bataan death march and PowerOpen-A/UX 4-whatever was waiting for its death certificate, and while BeOS had SheepShaver, it was third-party software on a low-volume OS made by a quirky company best known for <a href="http://oldvcr.blogspot.com/2021/03/when-you-have-too-much-memory-for.html">a strange blue machine</a>. If you were willing to forgo Mac software compatibility completely, Windows NT and Solaris could run on PowerPC but not on Power Macs, the OS/2 port is best not mentioned, running stuff on/with NetWare was a cruel joke (<em>and</em> it was cooperatively multitasked, too), and if you dared suggest Apple could buy NeXT, remember that NeXTSTEP and OpenSTEP <em>never</em> ran on PowerPC until Rhapsody. Plus, Be and NeXT carried additional institutional baggage by having controversial ex-Apple execs at their helms.
</p><p>
Here, on the other hand, was a way you could solve the entire problem by just grafting libraries onto an existing operating system Apple already had an arrangement to use. When you think about the idea in that context, "symbiotic" applications like this one looked like an easy transitional solution to the classic Mac OS's deficiencies.
</p><p>
For the next couple demonstrations, having made the point on the Mystic, we'll move back to the Quadra so that we have a little more visual real estate.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi4BJ8pDDxnaK9XC8WzdpHSSADReoQp752UC8DoZF3KlNrJP63NLHPvcHAuXs1v4vOzOW7pc5wT40F7nF6hXaC6-LUKEcSVOW_B8AaPGvDLogAPmmU9Z8CCY8I5HpMIrzgP3MYiiHCCg_fFYfEf4y9UXqK-oEw94443y18t2xpfD6kyqFBKXtn8gY6zRe8/s832/Picture%202.png"><img alt="" data-original-height="624" data-original-width="832" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi4BJ8pDDxnaK9XC8WzdpHSSADReoQp752UC8DoZF3KlNrJP63NLHPvcHAuXs1v4vOzOW7pc5wT40F7nF6hXaC6-LUKEcSVOW_B8AaPGvDLogAPmmU9Z8CCY8I5HpMIrzgP3MYiiHCCg_fFYfEf4y9UXqK-oEw94443y18t2xpfD6kyqFBKXtn8gY6zRe8/s320/Picture%202.png" width="320"></a></p><p>

The next, more practical use of this technology (and also lacking source code) is the Disk Management Utility. That's like it sounds: you can manipulate JFS logical volumes, physical disks and AIX volume groups natively from a controlling Mac. Naturally you'll have to authenticate as </p><tt>root</tt><p> (remember there's no encryption!), and once you do, there is a minor pause while the client gets the system information. It will not allow multiple administrators to connect simultaneously. This machine has only one partitioned disk, a full-height Fujitsu 18GB SCSI-2 drive which was quite large for the time, but the Utility could reputedly handle fairly complex topologies.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgcYUH_xK3AGX7rFhgBhR456u1m7WdPu-ZXW1B-AkzUIwI68kP6GJ-UIa4xMDMZnvB5wwYTOb1gXk5HQmvAOVIBlzXizFxRXejGmLEuBYERFcE1LzKbXP75zWr79CqO_UQ_PCgZON7TMWmda6fxBqnoMmvkNdl18qjrrKlBz59Pvq0-p2DqpvZRcSpUL5Q/s832/Picture%203.png"><img alt="" data-original-height="624" data-original-width="832" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgcYUH_xK3AGX7rFhgBhR456u1m7WdPu-ZXW1B-AkzUIwI68kP6GJ-UIa4xMDMZnvB5wwYTOb1gXk5HQmvAOVIBlzXizFxRXejGmLEuBYERFcE1LzKbXP75zWr79CqO_UQ_PCgZON7TMWmda6fxBqnoMmvkNdl18qjrrKlBz59Pvq0-p2DqpvZRcSpUL5Q/s320/Picture%203.png" width="320"></a></p><p>

Given a particular disk, you could drill down to individual partitions and adjust their permissions and sizes or do other administrative tasks, including those on logical disks hosted on the supported Apple RAID solution. I have a long personal history with AIX, so even in 1998 I did all my admin tasks from the LFT console, but this would have been very attractive to Mac admins new to the operating system. Of course, the chief problem with this otherwise well-designed application is that it cast the fact you had to do <em>literally everything else</em> in </p><tt>smit</tt><p> into very sharp relief.
</p><p>
The copyright date in the About box is 1992, though I can't determine from this if that was for MacApp generally (that is, Apple's attempt at their own object-oriented framework for the classic Mac OS) or for the Utility itself. If the Utility actually hailed from 1995 as other services do, then it would have been a very late application even for C++ MacApp, as CodeWarrior's equivalent PowerPlant framework was already eating its lunch by then and Apple was itself using PowerPlant in some of its own software. Although MacApp 3.0 apparently had very good Apple event handling, our project for this article will use PowerPlant.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhjhJFlErDaNTAVc4kuy7zUqwTOACvSq6BxyAexCtPuhLhMnc9B_xmd-KEhhEbjl5CfhFbqwaYWo_d_lVUOf-DZkt_xjlPvEVpgDAr6vqYXsE0Sr8pgteb0v1CF6kkiFTEZe6f-PpvU5LC8mXs8At_QEHT3c5kj2nJHHPBR7V2DCsQ9yIE7pN_hDTjxtEo/s832/Picture%205.png"><img alt="" data-original-height="624" data-original-width="832" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhjhJFlErDaNTAVc4kuy7zUqwTOACvSq6BxyAexCtPuhLhMnc9B_xmd-KEhhEbjl5CfhFbqwaYWo_d_lVUOf-DZkt_xjlPvEVpgDAr6vqYXsE0Sr8pgteb0v1CF6kkiFTEZe6f-PpvU5LC8mXs8At_QEHT3c5kj2nJHHPBR7V2DCsQ9yIE7pN_hDTjxtEo/s320/Picture%205.png" width="320"></a></p><p>

That brings us to our last demonstration, and the one we're going to hijack, because both client and server source code exists for it too. The server source code on 4.1.5 is credited to Chris Jalbert with a "1996-1997" copyright date, updated from the earlier 4.1.4.1 release of what was called </p><tt>javelind</tt><p>. It's purportedly a basic system monitoring application, but the concept is generalizeable to something much more than that.
</p><p>
There are actually two applications left, the Status-Who Demo ("trident") and the Status Demo ("javelin"), but the Status Demo is completely subsumed by the Status-Who Demo, so we'll show that as the client. You can choose the desired view from the File Menu, either the "who" view (which shows a multiline, automatically refreshed list of current users and their locations, much like <tt>/usr/bin/who</tt>), or the "uptime" view (which shows the time, number of users and system load, much like <tt>/usr/bin/uptime</tt>). Both can run at once. The Status Demo solely displays the "uptime" view.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiuaafFiLg-gqDDmL5qtVlhd-nluA5oJt6CpD9Z_5P0Dyk1iJQIqgvv0Dj6sjvLG7nP49joJt5d-QgB-iz58xW7KA6TJKQ9H_5-owVt0sLEwhaTsM6oKSV4bPZMxtjcc406libXXMesm4tJeQQUH7DRL-40YpqYp_MuwKLhYUiRvGr6141FpPECPcQY7QU/s832/Picture%206.png"><img alt="" data-original-height="624" data-original-width="832" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiuaafFiLg-gqDDmL5qtVlhd-nluA5oJt6CpD9Z_5P0Dyk1iJQIqgvv0Dj6sjvLG7nP49joJt5d-QgB-iz58xW7KA6TJKQ9H_5-owVt0sLEwhaTsM6oKSV4bPZMxtjcc406libXXMesm4tJeQQUH7DRL-40YpqYp_MuwKLhYUiRvGr6141FpPECPcQY7QU/s320/Picture%206.png" width="320"></a></p><p>

For the "who" view, the signature will bring up a Login Demo service. (Notice the PPC Browser window asks you to "Select a Unix Server.") In this mode, the server <em>pushes</em> the current userlist to the client as an array of strings in an Apple event, updating that list if it sees that </p><tt>/etc/utmp</tt><p> has changed. On the client end, it idles, yielding to other apps, until it gets that Apple event with which it updates the text in the window.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjVMqpMiBeQfzSrAPgmD3Y8Wu039fNoXmLZozosA2ROlbmXt706BOV09_PZMTpOOV4HjXhRusDDN-Vji-XIJ_Nx4ep-ARyii8WbTON8kbiWM6djG7bL7W-l_gFv_ias24WjuIDEfB8c0oQMtyZSb8kuZnH_Od3QdMPT52gQfO55Es45fr9he8i6rR_p04U/s832/Picture%207.png"><img alt="" data-original-height="624" data-original-width="832" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjVMqpMiBeQfzSrAPgmD3Y8Wu039fNoXmLZozosA2ROlbmXt706BOV09_PZMTpOOV4HjXhRusDDN-Vji-XIJ_Nx4ep-ARyii8WbTON8kbiWM6djG7bL7W-l_gFv_ias24WjuIDEfB8c0oQMtyZSb8kuZnH_Od3QdMPT52gQfO55Es45fr9he8i6rR_p04U/s320/Picture%207.png" width="320"></a></p><p>

However, the "uptime" view brings up <em>two</em> services with matching signatures. They appear to work the same, but there's an internal difference between them we'll get to when we discuss the backend.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjoiVOtSq_9fYrhW5AucwTD1FIVlVX6DDereUeTikCFg_-xg-LuWcNmruFDQswCdM-9JuAmm-2jzhU2JURaHB-kYW9r4m_QKXyLN8n9JP2Tfds3ap18xkpAPz6RbrRwA1Mhqf4ccqjWI0tWZu-XnsrnKjl2AGy9Mm-bevQ1rDL-MtPInutnSa_iocnlKC0/s832/Picture%209.png"><img alt="" data-original-height="624" data-original-width="832" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjoiVOtSq_9fYrhW5AucwTD1FIVlVX6DDereUeTikCFg_-xg-LuWcNmruFDQswCdM-9JuAmm-2jzhU2JURaHB-kYW9r4m_QKXyLN8n9JP2Tfds3ap18xkpAPz6RbrRwA1Mhqf4ccqjWI0tWZu-XnsrnKjl2AGy9Mm-bevQ1rDL-MtPInutnSa_iocnlKC0/s320/Picture%209.png" width="320"></a></p><p>

The chief difference between the uptime view and the who-view — between the single line of text and the multiple lines, that is — is that you can specify the interval for the uptime view, whereas the who-view rate is determined by the server. Both can run at once, though you can have multiple uptime views, and the system will multiplex their events. The uptime view also maintains a history so you can scroll back through the load averages and see when your box was blowing up.
</p><p>
Let's have a look at the backend now.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEheHcBo4btX0bOM_gOkJ12X_NlLCjWbhJlvYAs_KdTGH5x_ir4obsroj_LFykCq9aVvlL8AZOEV0PznUOrN305hXKsAdquj5yMKZE0IneFaJTYpkpnHOSb9EnmPWe7tedcipsscJgO8zlMNLcmfVQ8NrCPxsndmv7CKccXHQLPV2ewIn2_X1IGuo5CLXjU/s1024/nu-vlcsnap-2023-11-04-15h40m17s509.png"><img alt="" data-original-height="768" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEheHcBo4btX0bOM_gOkJ12X_NlLCjWbhJlvYAs_KdTGH5x_ir4obsroj_LFykCq9aVvlL8AZOEV0PznUOrN305hXKsAdquj5yMKZE0IneFaJTYpkpnHOSb9EnmPWe7tedcipsscJgO8zlMNLcmfVQ8NrCPxsndmv7CKccXHQLPV2ewIn2_X1IGuo5CLXjU/s320/nu-vlcsnap-2023-11-04-15h40m17s509.png" width="320"></a></p><p>

Harpoon </p><tt>ppcd</tt><p> has its own SMIT menu where you can start and stop the daemon or modify its services. This can all be done from the command line, and you can just edit </p><tt>/etc/ppcd.conf</tt><p> and bounce the daemon to add or remove services, but I'll show you SMIT's interface to service configuration for completeness here.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjfVocidEtrUlWDX28oPPIKMoXIewq6m8UO5SynD2g-bY1Ph5Mr3TGoB2Xh8Wuc7jHnkAOnhp_GIrVT6I3jNo60N32es1zJtoHarGgYbaoDRW5Aix6N-CsaqJ7KuBQEFbeq52eHvnPTSV7YhwotRafcMqWu4ZmiLgRSoAhUbZrOhKFiaKVlvGG6ZD5SbYw/s1024/nu-vlcsnap-2023-11-04-15h41m15s392.png"><img alt="" data-original-height="768" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjfVocidEtrUlWDX28oPPIKMoXIewq6m8UO5SynD2g-bY1Ph5Mr3TGoB2Xh8Wuc7jHnkAOnhp_GIrVT6I3jNo60N32es1zJtoHarGgYbaoDRW5Aix6N-CsaqJ7KuBQEFbeq52eHvnPTSV7YhwotRafcMqWu4ZmiLgRSoAhUbZrOhKFiaKVlvGG6ZD5SbYw/s320/nu-vlcsnap-2023-11-04-15h41m15s392.png" width="320"></a></p><p>

I mentioned previously that there are two ways a service can be set up. As it happens, the two services we saw for the uptime view are the same daemon built both ways. The most complex, but also the most flexible, way is to register yourself with </p><tt>ppcd</tt><p> and open your own listening ports (specified by name and either a matching string or a type and creator; we use the latter to specify the </p><tt>OSType</tt><p> signature). This is the only way to have multiple port types registered to a single daemon, and both the who-view (creator "signature" is </p><tt>JVLN</tt><p> and type is </p><tt>who </tt><p> with a trailing space) and the "New Status View" for uptime (</p><tt>JVLN updt</tt><p>) are handled by this one, appropriately named </p><tt>/usr/bin/flexibled</tt><p>.
</p><p>
On the other hand, it also requires your daemon be running all the time when <tt>ppcd</tt> is, and <tt>ppcd</tt> in this configuration basically only acts as your bootstrap. So that you don't have to busywait, however, the <tt>select()</tt> call is expanded in Harpoon to not only terminate with time left for regular POSIX signals but also on Apple events (which you retrieve with <tt>WaitNextAppleEvent</tt> and dispatch with <tt>WaitNextAppleEvent</tt> to handlers you previously defined with <tt>AEInstallEventHandler</tt>), and additionally works with things like ADSP connections as well as more typical TCP/IP network sockets.
</p><p>
So where did the other Status View service answering to <tt>JVLN</tt> come from? It came from the <em>other</em> way we can set up a service.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjKNIpcJA1PMc5i974ZzpchsebWzOJzGg0Yg8upFyWSkwjNwQIh5YVmpww6AAzBUgpRK02a67egYXUjIJRfcF4kn2FgURw9Ohsso-fLGOUcv2zVV0A4qkllIpn3RzKG9u5SC-poEXKSGNaiEJih7_vzXTvnPpg7tZI6_PaZAYgchcRSC85rkb10GmzYwL0/s1024/nu-vlcsnap-2023-11-04-15h40m53s030.png"><img alt="" data-original-height="768" data-original-width="1024" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjKNIpcJA1PMc5i974ZzpchsebWzOJzGg0Yg8upFyWSkwjNwQIh5YVmpww6AAzBUgpRK02a67egYXUjIJRfcF4kn2FgURw9Ohsso-fLGOUcv2zVV0A4qkllIpn3RzKG9u5SC-poEXKSGNaiEJih7_vzXTvnPpg7tZI6_PaZAYgchcRSC85rkb10GmzYwL0/s320/nu-vlcsnap-2023-11-04-15h40m53s030.png" width="320"></a></p><p>

The easier way to write a service is to let </p><tt>ppcd</tt><p> do the work of looking for events for the signature you're watching for and managing authentication. You can only specify one signature and you can only handle a single generic port type for it, but your daemon doesn't need to run until </p><tt>ppcd</tt><p> finds something you're looking for. At that point your daemon is started, you handle events and AppleTalk connections for as long as you want to, and then you terminate.
</p><p>
This screen shows the configuration for the Fractal Demo service. The service name is what is used in the port the Harpoon <tt>ppcd</tt> advertises, as well as the signature (here, <tt>Mndl</tt> is reported as the creator, with an implied wildcard for the port type in these simplified servers). Authentication is required if the guest connections without password are not allowed, or if you removed the <tt>guest</tt> user account, as I have since it was a production system. If you authenticate and you're in the list of privileged users, the specified daemon will be started with the uid and gid you provide as if it were <tt>setuid</tt>; if you're not, then it assumes yours. Once all that happens, <em>then</em> <tt>ppcd</tt> starts your daemon.
</p><p>
In most cases, a given Mac application's creator code and its PPC Toolbox signature were the same <tt>OSType</tt> FourCC. While AIX daemons wouldn't have a creator code, the general correspondence of PPC Toolbox signatures to creator codes meant you were also supposed to register your desired signature with Apple like you would for an application. Somehow I don't think Apple got a lot of requests for this. A generic signature of <tt>UNIX</tt> was always available and explicitly defined as free for all.
</p><p>
By default, there are five services listed in <tt>/etc/ppcd.conf</tt>.
</p><div><pre>CommandShell:0:NONE:/usr/sbin/cmdshld:CmdS:noguest:*
Disk Management Utility:0:NONE:/usr/sbin/diskmand:DSCS:guest:NONE
Status Demo:100:100:/usr/sbin/simpled:JVLN:guest:*
Fractal Demo:100:100:/usr/sbin/fractald:Mndl:guest:*
:::/usr/sbin/flexibled::guest:
</pre></div>
<p>
You can see what the Fractal Demo SMIT screen corresponds to in the actual configuration file, including its port name, default uid and gid (always used, since the set of privileged users is an asterisk), path to the daemon, signature, whether guest is allowed, and the privileged user list (or an asterisk for everybody).
</p><p>
You can also see the simpler Status Demo (<tt>/usr/sbin/simpled</tt>, naturally), which responds to <tt>JVLN</tt> as well, but only can offer a single port type and its programmers chose the uptime view. <tt>flexibled</tt>, on the other hand, specifies no port name and no signature (or anything else for that matter), so <tt>ppcd</tt> always brings it up so that it can open its own ports and listen for its own Apple events. It responds to <tt>JVLN</tt> too, but that's because it itself created its own PPC Toolbox port for it. However, all of the other PPC services are "simplified," including the major ones like the Command Shell and Disk Management Utility.
</p><p>
The source code for the Status-Who and Status Demos is actually a single pile of source that's quadruple-headed: it can be built as either the flexible daemon (both who and uptime) or simple (just uptime), and either for AIX or for Mac OS (in which case most of the status updates are just dummy strings but the app allegedly works). We'll only deal with building it on AIX. Although I've placed a slightly tweaked version up <a href="https://github.com/classilla/hnae/blob/main/nutridentd/">on Github</a> you can follow along with, here's the relevant portion from <a href="https://github.com/classilla/hnae/blob/main/nutridentd/Makefile.xlc">the original <tt>Makefile</tt></a>:
</p><div><pre>PROGRAMS        = flexibled simpled

FOBJS           = fobjs/tridentd.o fobjs/ppcstuff.o fobjs/client.o \
                        fobjs/status.o fobjs/handlers.o
SOBJS           = sobjs/tridentd.o sobjs/client.o sobjs/status.o \
                        sobjs/handlers.o
LDFLAGS         = -L../../../../export/power/usr/lib
LIBS            = -lae -lat
HEADERS         = tridentd.h debug.h AIXAESuite.h
INCFLAGS        = -I/usr/include/mac

DEBUG           = -D_DEBUG=0 -w
OSVERSION       = -DAIX4_x

CFLAGS          = ${DEBUG} ${OSVERSION} -D_XOPEN_SOURCE -DSYS_V \
                -qcpluscmt -qextchk -qfullpath -qinfo -qmacpstr -qproto \
                -qlanglvl=ansi -qtune=604
</pre></div>
<p>
<tt>libae.a</tt> and <tt>libat.a</tt> are the Apple events and AppleTalk libraries respectively, and <a href="https://github.com/classilla/hnae/blob/main/nutridentd/AIXAESuite.h"><tt>AIXAESuite.h</tt></a> (part of the project) contains the FourCCs for the Apple event messages and their subparameters this daemon understands, namely ones for quitting, heartbeats, version check (accepts version, returns error or no error), interval (for uptime only, specifies the refresh frequency), and actual message events where data is passed.
</p><p>
The C compiler defaults to generic <tt>cc</tt>, but those <tt>-q*</tt> options betray what compiler was actually expected: IBM's own C compiler for AIX, <tt>xlC</tt>. To link against, Apple included a tweaked subset of its header files with Harpoon in <tt>/usr/include/mac</tt>, though most of the files are generally unchanged, and only a few reference AIX specifically:
</p><div><pre>/usr/include/mac/% grep AIX *
AppleEvents.h:/*    AIX can't deal with enums that large - DJP */
AppleEvents.h:/*    AIX can't deal with enums that large - DJP */
AppleEvents.h:/* Required call for AIX implementations. */
AppleEvents.h:#ifdef _AIX
AppleEvents.h:#endif        /* _AIX */
ConditionalMacros.h:        for copiling code to be run under AIX
ConditionalMacros.h:/*      There is no pascal linkage in AIX. Null out the keyword
PPCToolBox.h:/* These are additions specific to the AIX implementation. */
PPCToolBox.h:#ifdef _AIX
PPCToolBox.h:#endif /* _AIX */
</pre></div>
<p>
This means that very few of the C structs defined in those files were altered from their Mac OS originals. To be able to emit Apple event and AppleTalk structures compatible with Mac OS, <tt>xlC</tt> has to be able to pack structs <em>in the way a 68K Mac would pack them</em>, or they won't be compatible over the wire. In general, such 68K-packed structs are smaller than the way a PowerPC-native compiler would pack them for maximum efficiency on PowerPC.
</p><p>
And, well, it turns out it <em>can</em>. I mentioned before that there were weird things in <tt>xlC</tt> related to Mac compatibility which could have only come about from AIX and Mac OS being entangled for so long, and those things are <tt>-qmacpstr</tt>, which allows the <tt>\p</tt> shorthand for turning a <tt>char *</tt> literal into a Pascal string, as well as support for <tt>#pragma options align=mac68k</tt>, which causes the compiler to obey Mac 68K alignment rules until turned off with <tt>#pragma options align=reset</tt>. Those options are of no value on regular AIX; they would only be good for writing AIX programs that interact with classic Mac data structures, and they would only have had a reason to exist if AIX and Mac OS were to be more tightly intertwined. This compiler support doesn't seem to have been specific to Apple, either: the <tt>xlC</tt> you got for the ANS was vanilla IBM, and to this day IBM still documents and supports <a href="https://www.ibm.com/docs/en/xl-c-and-cpp-aix/16.1?topic=aggregates-alignment-examples">Mac 68K alignment</a> and <a href="https://www.ibm.com/docs/en/xl-c-and-cpp-aix/16.1?topic=descriptions-qmacpstr">Mac Pascal strings</a> in the most recent version of <tt>xlC</tt>, 16.1 as of this writing.
</p><p>
What do we do if we don't have <tt>xlC</tt>? I used to have access to it at the University but I never had a license for it on my own hardware as I never needed it; <tt>gcc</tt> was more than sufficient. Unfortunately, <tt>gcc</tt> on non-Darwin platforms (because I guess Apple and IBM didn't read RMS into the grand plan) doesn't support Mac Pascal strings or 68K alignment. You can work around the Pascal string problem by hand-encoding them (a Pascal-compatible <tt>Str255</tt> simply encodes the length into the first byte instead of being null-terminated), but there's no way, or at least not with the old <tt>gcc/egcs</tt> 2.x for AIX 4, to make it pack things the way you want them without manually spelling the alignments out with things like <tt>char[]</tt>. I did actually try doing that, but to get the alignments from my Tiger G4, I ran into the fact that even good old 32-bit Carbon didn't support any of this nonsense by then:
</p><div><pre>% cat /Developer/SDKs/MacOSX10.4u.sdk/Developer/Headers/FlatCarbon/PPCToolbox.h
#warning PPCToolbox.h is not available on Mac OS X
% cat /Developer/SDKs/MacOSX10.4u.sdk/Developer/Headers/FlatCarbon/AppleTalk.h
#warning AppleTalk.h is not available on Mac OS X
</pre></div>
<p>
I ended up installing the <em>AIX</em> Mac headers on the G4 and managed to fish out the corrected alignments of all the AppleTalk structures, and it compiled, but it still didn't work. I've left this attempt as <a href="https://github.com/classilla/hnae/blob/main/nutridentd/ppcpacked.h"><tt>ppchacked.h</tt></a> and <a href="https://github.com/classilla/hnae/blob/main/nutridentd/ppcpacked.c"><tt>ppchacked.c</tt></a> for messing with another day.
</p><p>
Fortunately, it turns out we don't really need it for the simple form of this daemon. Only the flexible form needs to talk directly to clients and thus must create and populate Apple data structures, and you'll notice that in the <tt>Makefile</tt> for the simple form there's no <tt>ppcstuff.o</tt> (that's Program-to-Program Communication, not PowerPC), which is where <a href="https://github.com/classilla/hnae/blob/main/nutridentd/ppcstuff.c">all of that lives</a>. Everywhere else only deals in Apple events,  and those functions treat it as an opaque data type using accessor methods like <tt>AEGetAttributePtr</tt> and <tt>AEGetParamPtr</tt> instead of manipulating the struct directly. As such code doesn't depend on having its own bytewise understanding of the struct, that much we can compile with <tt>gcc</tt>. As long as we only require one port type for this service, the simple form will suffice, so we can still create the backend with a freely available compiler.
</p><p>
So what are we going to create? The Status-Who demo is the most straightforward shell to take over since it displays text to the client. What we want to do should be textual, approach some level of utility, and be something that would take the local Mac much more memory and/or CPU capacity to do itself than it would ordinarily have available.
</p><p>
With that in mind, let's use the existing <a href="https://github.com/HackerNews/API">Firebase API</a> to display an auto-updating list of the top stories on Hacker News. (Attention Lobste.rs and Two Stop Bits: if you have a functioning API I'll support that too.) I think this is an excellent test case, because why not have it in the background while you do your distraction-free writing or something, nothing running on native 68K Mac OS speaks TLS 1.3 (<a href="https://github.com/classilla/cryanc">well, not yet</a>, anyway), and even if there were it would take a good few seconds to actually download and parse <em>every single</em> API call because of the crypto overhead on a 68040. For that matter, on the 200MHz 604e it still takes a few seconds to get all the article titles together, but there are ways to make that more efficient, AIX handles the tasks, <em>and</em> the client Mac isn't throttled up doing all this while you're trying to do something else.
</p><p>
We want this to be multi-line, so the first order of business is to write a new simplified daemon that responds with the who-list instead of uptime, which I've grandiosely called <tt>hnd</tt>. The original source code has a define <tt>SIMPLIFIED</tt> to elide all the unneeded flexible code but I've stripped it down to only run as simplified in this tree. It assumes all requests it gets are for the who-view and responds accordingly.
</p><p>
The function <a href="https://github.com/classilla/hnae/blob/main/nutridentd/status.c#L242"><tt>GetWhoString</tt> in <tt>status.c</tt></a> emits the who blob, limited to <tt>BUFSIZ</tt> bytes (for the classic Mac OS, this value is 1024 by default, or 1KiB), which <a href="https://github.com/classilla/hnae/blob/a79ed189fc70bbc8ce848df868c8d81be39d3176/hnd/status.c#L65">in our stripped version is now called <tt>GetString</tt></a>. I've left hooks for making the interval irregular or more efficient (see <a href="https://github.com/classilla/hnae/blob/a79ed189fc70bbc8ce848df868c8d81be39d3176/hnd/status.c#L112"><tt>StringUpdated</tt> in <tt>status.c</tt></a>, which currently always returns true), but right now it does a full check every time the recheck interval comes around.
</p><p>
Speaking of intervals, there are three timing intervals running to keep everything happy. <tt>HEARTBEAT_CHECK</tt>, <a href="https://github.com/classilla/hnae/blob/main/nutridentd/client.c#L32">originally in <tt>client.c</tt></a> and <a href="https://github.com/classilla/hnae/blob/a79ed189fc70bbc8ce848df868c8d81be39d3176/hnd/tridentd.h#L18">now in <tt>tridentd.h</tt></a>, is the expected frequency at which we would get Apple events from a connected client telling us it's still there. <a href="https://github.com/classilla/hnae/blob/a79ed189fc70bbc8ce848df868c8d81be39d3176/hnd/client.c#L44"><tt>HEARTBEAT_SEND</tt>, in <tt>client.c</tt></a>, is how long after the last Apple event we'll send a heartbeat <em>to</em> to the client, if no events have been passed in the meantime. Finally, <a href="https://github.com/classilla/hnae/blob/a79ed189fc70bbc8ce848df868c8d81be39d3176/hnd/client.c#L53"><tt>DEFAULT_INTERVAL</tt> in <tt>client.c</tt> </a>is how often we'll actually try to update the string we send (i.e., check the Hacker News API for what's on the front page) — whatever we do should optimally take less than <tt>HEARTBEAT_CHECK</tt> seconds to complete so we don't queue up too many client heartbeats while we're blocked on an operation. In <tt>hnd</tt>, these values are 30 seconds, 120 seconds and 60 seconds respectively.
</p><p>
Finally, we'll put it into <tt>/etc/ppcd.conf</tt> with the signature <tt>HCKN</tt> (you could change <tt>kSignature</tt> in <tt>tridentd.h</tt> just to make it clean, but this is never actually used in the simplified version of the daemon since <tt>ppcd</tt> handles all the signature stuff). We'll run it under my uid, though you could also run it under the guest user if you still have that. On my system this will always authenticate but there's no reason not to let a guest on your network query this ... right?
</p><div><pre>Hacker News:1000:1000:/usr/src/hnd/hnd:HCKN:guest:NONE
</pre></div>
<p>
Restart <tt>ppcd</tt>, either from SMIT or the command line, and it will now be available for that service.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhvazxqRWSh42NliD5sEC4GI_FbkCPod0lExmNzhZEBWTXsn9QxdKX-ECIjNq4HQZlQbYhAC_Rj3o1UB7zFMoURed8FJfFmYN_fmkgQQFL7iWTpGH_dlWRxHucuPyE0u-00ytKiysOiO2XO5vXn3GUugVnfXHUTUjCjZoxP4zMeutonWdRQdgDgxMzea1I/s832/Picture%201.png"><img alt="" data-original-height="624" data-original-width="832" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhvazxqRWSh42NliD5sEC4GI_FbkCPod0lExmNzhZEBWTXsn9QxdKX-ECIjNq4HQZlQbYhAC_Rj3o1UB7zFMoURed8FJfFmYN_fmkgQQFL7iWTpGH_dlWRxHucuPyE0u-00ytKiysOiO2XO5vXn3GUugVnfXHUTUjCjZoxP4zMeutonWdRQdgDgxMzea1I/s320/Picture%201.png" width="320"></a></p><p>

Now for the client. Apple provided source for Fractal Demo, Javelin (i.e., Status Demo) and Trident (Status-Who Demo) in inconsistent formats, respectively MPW 3.3/MacApp 3.0, CodeWarrior Gold 11 with PowerPlant <em>and</em> MPW 3.3/MacApp 3.0, and just plain CodeWarrior Gold 10 (not 11) with PowerPlant, which is the one we're using. The first order of business is pulling up the CodeWarrior version to the version of the compiler I use locally on the Q800 for <a href="http://oldvcr.blogspot.com/search/label/lynx">MacLynx</a>, which is CodeWarrior Pro 2, and generating it as a 68K build instead of a fat binary since it's a Quadra, after all. This particular version of CodeWarrior is available from a veritable Garden of various Macintosh software sites but it should also work with later compilers.
</p><p>
We'll first get it to compile and running against the regular flexible daemon. I've provided this version separately as "New Trident Demo"; just unstuff and open the project. The main changes, besides completely reconstructing the project file from scratch, were slight adjustments for the later PowerPlant and rewriting CodeWarrior Gold's C++ <tt>inherited::</tt> idiom, which CW Pro 2 doesn't seem to understand.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgRAncEg4bqgqb_aHqpLvESifeaHoa__MXZXAgznbqgGLO1aPlRtH4BqSHqcbXoYQCYcYNitBXZsXEFX7asqBsNgVTLnESc_1A4qxFa0Lo0oxonGZM_C2dO2_BJcd5VeaY3p1ZE4oRYICNNR9_-vBbhaUmxxysoRGCTg1wfhhhbZr6s1NkHaLTXlXedXkw/s832/Picture%208.png"><img alt="" data-original-height="624" data-original-width="832" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgRAncEg4bqgqb_aHqpLvESifeaHoa__MXZXAgznbqgGLO1aPlRtH4BqSHqcbXoYQCYcYNitBXZsXEFX7asqBsNgVTLnESc_1A4qxFa0Lo0oxonGZM_C2dO2_BJcd5VeaY3p1ZE4oRYICNNR9_-vBbhaUmxxysoRGCTg1wfhhhbZr6s1NkHaLTXlXedXkw/s320/Picture%208.png" width="320"></a></p><p>

The major guts of the MacOS client are in </p><tt>CTridentwhoView.cp</tt><p> and </p><tt>CTridentCmds.cp</tt><p>. There's lots of commented-out code in here, but that's as it came, so don't blame me. Fortunately, to switch it over to the Hacker News daemon, all we need to do is change the </p><tt>JVLN</tt><p> signature to </p><tt>HCKN</tt><p>.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj-whSh7JFO1VzzdiWjKl0wxiD45WxbMs6sZ91yQ-SeO3SXXjbx0Kw79FwR_vZJAiN1qSqRaO0I7xXUhKpZxS-tG5bSSHpAWOtarx28XrdFetmiZGc0uc7C4Jfn6JLeGlLhkuW5tR_Jr_qE0ypxEUz1E1_MQgNgLvC0KPi8Jja6UPREph-BAbwpw1amO7c/s832/Picture%2010.png"><img alt="" data-original-height="624" data-original-width="832" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj-whSh7JFO1VzzdiWjKl0wxiD45WxbMs6sZ91yQ-SeO3SXXjbx0Kw79FwR_vZJAiN1qSqRaO0I7xXUhKpZxS-tG5bSSHpAWOtarx28XrdFetmiZGc0uc7C4Jfn6JLeGlLhkuW5tR_Jr_qE0ypxEUz1E1_MQgNgLvC0KPi8Jja6UPREph-BAbwpw1amO7c/s320/Picture%2010.png" width="320"></a></p><p>

Back in </p><tt>hnd</tt><p> (we can now make changes to it live and have them reflected in the output: remember, </p><tt>ppcd</tt><p> is like </p><tt>inetd</tt><p>, just with Apple events) </p><a href="https://github.com/classilla/hnae/blob/a79ed189fc70bbc8ce848df868c8d81be39d3176/hnd/status.c#L69">I modified <tt>GetString</tt> to return a static multiline string</a><p> as a proof of concept ... and, with the client in "who" mode, it worked! (If you do this with "uptime" mode, you get a note saying it got back a chunked response.)
</p><p>
The next step is to make this a little easier to work on. I'd rather have the C code call out to a script that it can take the output of rather than juggle all this work in the daemon itself (it's probably safer that way, too), so we'll add a little section of code <a href="https://github.com/classilla/hnae/blob/a79ed189fc70bbc8ce848df868c8d81be39d3176/hnd/status.c#L73">to <tt>popen()</tt> a pipe to Perl and have Perl run a script</a>. The initial sample script will just <a href="https://github.com/classilla/hnae/blob/a79ed189fc70bbc8ce848df868c8d81be39d3176/hnd/simple_hn.pl">display the local time</a> to show that the updates are happening regularly.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiSwsYtUD3xpSp_ivJLFaNlIXRbE4Gy1_TOYMUiVV66BwyWn2c61iDcmcshzCbjQn0nETDRPCxDxSsNDCXxbGH1YSUywzcMM3oNLxTjd_AEibUvTRLOuIHxTCLtrSyRhtWVV7nS_aRCPSVyoGfILPO5-sWa7or8LphruKwUAPMZ2iyR6nt94fQ5MT2aPnA/s832/Picture%2011.png"><img alt="" data-original-height="624" data-original-width="832" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiSwsYtUD3xpSp_ivJLFaNlIXRbE4Gy1_TOYMUiVV66BwyWn2c61iDcmcshzCbjQn0nETDRPCxDxSsNDCXxbGH1YSUywzcMM3oNLxTjd_AEibUvTRLOuIHxTCLtrSyRhtWVV7nS_aRCPSVyoGfILPO5-sWa7or8LphruKwUAPMZ2iyR6nt94fQ5MT2aPnA/s320/Picture%2011.png" width="320"></a></p><p>

And they do, leaving our last step on the server side to actually write something that parses the API. <a href="https://github.com/classilla/hnae/blob/a79ed189fc70bbc8ce848df868c8d81be39d3176/hnd/hn.pl">In this Perl script</a>, using </p><tt>carl</tt><p> from <a href="https://github.com/classilla/cryanc">Crypto Ancienne</a> as a HTTPS-enabled </p><tt>curl</tt><p> substitute and some trivial regexes to pull out fields from the returned JSON, we can populate the top ten list of stories with their titles and current point level.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgEACtCOJ0A0EH-xTkkFIhP-zAKAMSParIBcCRQTSsztBH_fHntb6ndbgUFU1DpkpXfpvEsQYlIYxFD5Bn76xAgb5bgwZUxorq49BssbfJ-BYleBCPL0V63wDET297baB2jtACG6QjBv_oDuzCu5LzK-eO5cJITBN3vdHCm_RHTaImzscyP7kP4llAGGL0/s832/Picture%2012.png"><img alt="" data-original-height="624" data-original-width="832" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgEACtCOJ0A0EH-xTkkFIhP-zAKAMSParIBcCRQTSsztBH_fHntb6ndbgUFU1DpkpXfpvEsQYlIYxFD5Bn76xAgb5bgwZUxorq49BssbfJ-BYleBCPL0V63wDET297baB2jtACG6QjBv_oDuzCu5LzK-eO5cJITBN3vdHCm_RHTaImzscyP7kP4llAGGL0/s320/Picture%2012.png" width="320"></a></p><p>

Ta-daa! And we're still using the Quadra normally. All it has to do is redraw the window when it gets the reply from the ANS; otherwise the Mac isn't tied up every 60 seconds while we have the live display in the background.
</p><p>
For the final run, we will remove the option to open an uptime window (it won't work), change the names, add a proper "about" window, and add some code for a proper title bar on the window. To change the resources, first go into ResEdit and remove the <tt>ckid</tt> resource (it will complain it's checked out read only from an MPW project; ResEdit will let you change things but PowerPlant Constructor won't), then open the resource file in Constructor to make the other changes so that everything remains up to date with the source code.
</p><p>
Let's take it for a spin!

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgvJ3Yi4quNjyMA-qeaxuhCS9W3XH3gszEFFtwgHP30ZRfbs8AjVzC6cbYmXQxfBZAJnF8na3Zcd0p7-ipw7e6U8LLMXQ_VGgv6n1y28pHl02uajykKcCIs5owfQxKb81fcTXnxkb2MNV6nxmrWFbad1DJOIw3T1iJXJ5jW3cqqkS8QLGoKfEGwQXFAaw4/s832/Picture%2013.png"><img alt="" data-original-height="624" data-original-width="832" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgvJ3Yi4quNjyMA-qeaxuhCS9W3XH3gszEFFtwgHP30ZRfbs8AjVzC6cbYmXQxfBZAJnF8na3Zcd0p7-ipw7e6U8LLMXQ_VGgv6n1y28pHl02uajykKcCIs5owfQxKb81fcTXnxkb2MNV6nxmrWFbad1DJOIw3T1iJXJ5jW3cqqkS8QLGoKfEGwQXFAaw4/s320/Picture%2013.png" width="320"></a></p><p>

Dear server: I would like to snarf Hacker News top stories in the background plz thx bye

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjFOyUKXJcdHzXTskM7IiUBEDvr2-nFSYtR0kdxxNSotDav2hXSOPzgPLcpZ3y3xTD0eNCsgNrmkKpYEIiW_-DfdEk_WCoqddhmhv4gdUn-ng5oe1sXQS91DWY7l6Ww4TLPpFJ-dGnFUUOF2ymcKUK_YJPV-x187Y4bvT2RRM-W7Gg6srMI9TUAD39Tbk4/s832/Picture%2014.png"><img alt="" data-original-height="624" data-original-width="832" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjFOyUKXJcdHzXTskM7IiUBEDvr2-nFSYtR0kdxxNSotDav2hXSOPzgPLcpZ3y3xTD0eNCsgNrmkKpYEIiW_-DfdEk_WCoqddhmhv4gdUn-ng5oe1sXQS91DWY7l6Ww4TLPpFJ-dGnFUUOF2ymcKUK_YJPV-x187Y4bvT2RRM-W7Gg6srMI9TUAD39Tbk4/s320/Picture%2014.png" width="320"></a></p><p>

Select your symbiont! (Though there's only one.)

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhul3zqhndqbHJ6qjq7NfD5XO4bAqJ77LQtwd88BockqdurvDKb0WTF72QOqHeLxze0qOnjxvT5NJ9nAyiK1nBCBpJUrGpwhjATcderMM1KCoEPu4kasDbnKhL3ayzto6VDZQJ0lGDtpFl1P_F7xRK0mixo6RW8gpcURf8JDMalaQEFJbgm1Pk-77L35pc/s832/Picture%2015.png"><img alt="" data-original-height="624" data-original-width="832" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhul3zqhndqbHJ6qjq7NfD5XO4bAqJ77LQtwd88BockqdurvDKb0WTF72QOqHeLxze0qOnjxvT5NJ9nAyiK1nBCBpJUrGpwhjATcderMM1KCoEPu4kasDbnKhL3ayzto6VDZQJ0lGDtpFl1P_F7xRK0mixo6RW8gpcURf8JDMalaQEFJbgm1Pk-77L35pc/s320/Picture%2015.png" width="320"></a></p><p>

And after a few seconds to gather the data, we have a display!

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj4YwcIB8OjaUl45jbvmLRcsLV8vsPjSNZA0oA25ydA7gwx9q7raqLMZyXmFKd6s3O2sGfgPmy93Ghd-sKxFbz1G6YF4VOmv53J3XHnyNr-7rRrv4OKOw38k95R7-o_YFmgNkmlppUq7woBBfA4M-l6iSk2tMZzLkDqx7pHFOc1IZE4quWdckrcXrL8uI0/s2560/IMG_20231104_182352_HDR.jpg"><img alt="" data-original-height="2560" data-original-width="1920" height="320" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj4YwcIB8OjaUl45jbvmLRcsLV8vsPjSNZA0oA25ydA7gwx9q7raqLMZyXmFKd6s3O2sGfgPmy93Ghd-sKxFbz1G6YF4VOmv53J3XHnyNr-7rRrv4OKOw38k95R7-o_YFmgNkmlppUq7woBBfA4M-l6iSk2tMZzLkDqx7pHFOc1IZE4quWdckrcXrL8uI0/s320/IMG_20231104_182352_HDR.jpg"></a></p><p>

I copied it over to the Color Classic and it works there too. Naturally both the Quadra and the Mystic can be fetching at the same time with no interference. An enhancement might be to have a common cache so that multiple sessions don't need to be pulling the same data over and over on the same box, but I'll leave that as an exercise to the reader.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjVm64EzxCetNwbqI_MJaImZ6keAXZfFAYzDInIoPHQRvavJvPMO2yhSwjM2H-5RhNIqYzGntfRA9DyWtlOdjuyGLsV1BksMTnBfowVG5H5bw_V8ZNQNVx9VFlmvx4ulFBU7mIAQPEBz_0HaTPqxt0ywVjqwT3QRZl2NghVaBFtiStChl3krmmLrlHJm0o/s832/Picture%2016.png"><img alt="" data-original-height="624" data-original-width="832" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjVm64EzxCetNwbqI_MJaImZ6keAXZfFAYzDInIoPHQRvavJvPMO2yhSwjM2H-5RhNIqYzGntfRA9DyWtlOdjuyGLsV1BksMTnBfowVG5H5bw_V8ZNQNVx9VFlmvx4ulFBU7mIAQPEBz_0HaTPqxt0ywVjqwT3QRZl2NghVaBFtiStChl3krmmLrlHJm0o/s320/Picture%2016.png" width="320"></a></p><p>

As a parenthetical note, look at how little memory this requires. You could run this easily on a much less powerful Mac; it should run just fine on a Macintosh Plus as long as the Plus has enough RAM to boot System 7, since that's the earliest OS version that has the PPC Toolbox.
</p><p>
Unfortunately the source code as given is only known to work on Harpoon and I'm not aware of anything that emulates a Network Server, not even QEMU, so you'll need the real hardware to run this right now. That said, it should be possible (mutatis mutandis) to mimic a similar setup on early versions of Mac OS X still supporting EtherTalk with appropriate modifications, and with Mac OS 9's PPC Toolbox over TCP/IP you should still be able to do it on more recent ones as the Apple Event Manager <a href="https://developer.apple.com/documentation/applicationservices/apple_event_manager?language=objc">remains part of macOS</a> and supported in both Objective-C and Swift. I may do this myself if I get some time to, but I look forward to people exploring the concept more. The calls this backend uses should be easy to translate to modern code with few changes.
</p><p>
But the symbiotic application concept, which will be completely new to many of you, didn't set the world on fire back then either. I know of very few third-party programs that took advantage of it on the ANS; one exception was IPT uShare, which had a scriptable AppleShare administration tool (<tt>IPT ScriptableAdmin:0:0:/ushare/Admin/iptosad:Sndr:guest:*</tt>). Part of this was no doubt because the ANS was incredibly expensive and Apple ended up selling very few of them. This was made even more acute by the fact that the planned multiprocessor ANS, which might have appealed to the well-heeled buyers who could afford it, was only prototyped and never sold; I know at least one of these cards is out there and wouldn't mind getting my hands on another. As a poor substitute, Apple offered the 200MHz 604e single processor version as both an upgrade card and as a complete 700/200 system with 48MB of RAM and two 4GB drives for $16,129, or about $32,000 in 2023. On the software side Harpoon only got a single upgrade to 4.1.5, which is the last version that you can run on an ANS (IBM AIX doesn't work, nor do many IBM APARs, which Apple released separately in ANS-specific versions on their own FTP site <tt>fixdist.apple.com</tt>, now lost). It's hard to say if the line was actually profitable, and I've heard arguments about this both ways because there was a lot of sunk RandD despite having big margins on a per-unit basis, but it's beyond dispute that the installed base was very small.

</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhW2UgSdMK-eKrjF6oQmoBVw78gr_TeP1XclcGxRhzZssNVGMLYW4tTieWY_B_VdJ4QZnDzslqjGxG4jK8vkRoOIqthJYbB6RcWEK6311F8trXy_7aN5V8UT8xxGSNaM4_GvnP2hbPq969_AUoqIBUA6-jAuFaF4dPuoeY06C8ICTMViS72dxU3Z-hPuRw/s2394/1997-02-17-content21.jpg"><img alt="" data-original-height="2394" data-original-width="1920" height="320" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhW2UgSdMK-eKrjF6oQmoBVw78gr_TeP1XclcGxRhzZssNVGMLYW4tTieWY_B_VdJ4QZnDzslqjGxG4jK8vkRoOIqthJYbB6RcWEK6311F8trXy_7aN5V8UT8xxGSNaM4_GvnP2hbPq969_AUoqIBUA6-jAuFaF4dPuoeY06C8ICTMViS72dxU3Z-hPuRw/s320/1997-02-17-content21.jpg"></a></p><p>

Meanwhile, Amelio hired his old comrade Ellen Hancock away from National Semiconductor in June 1996 as CTO and tasked her with finding Apple's new operating system direction. At Comdex in November 1996, Hancock announced to shocked Vegas attendees that the Network Server would run Windows NT <em>and</em> MacOS after all, as well as AIX, and planned to ship a ROM upgrade to make this possible. It's not clear the idea was ever technically feasible, but it didn't end up mattering anyhow: Apple bought NeXT just a month later in December (against Hancock's recommendation), and in April 1997 Amelio, on the advice of the newly returned Steve Jobs, cancelled both <a href="http://oldvcr.blogspot.com/2023/10/teaching-apple-cyberdog-10-new-tricks.html">OpenDoc</a> and the Network Server line on the same day. That's sad and the end of one of the weirdest chapters during Apple's weirdest period, but I suppose I have Steve-O to thank for me getting my first big server, because I probably wouldn't have wound up with it otherwise.
</p><p>
Fortunately, even after their cancellation many of the ANSes at Apple remained in operation serving content, some as late as 2005, and happily some of these old warhorse systems have also wound up in the hands of collectors. An Apple Network Server isn't a small system to house, but it's hardly a white elephant, and it's capable of tricks no other Apple system at the time could match. Plus, isn't it interesting to think of what an AIX Mac might have looked like? (Hey, wanna send me an SMP card for my 500? Please?) Apple would not have a true enterprise-grade server in its lineup again until the Xserve G4 in 2002.
</p><p>
The source code for the server daemons (original and Hacker News) and the clients (original and Hacker News) <a href="https://github.com/classilla/hnae">is on Github</a>. Compatible versions of Perl and <tt>gcc</tt> for AIX 4, which are prerequisites, are on <a href="gopher://gopher.floodgap.com/1/archive/ans-aixpdslib-aix-4">our partial Gopher mirror</a> of the former AIXPDSLIB, and Crypto Ancienne <tt>carl</tt> is available <a href="https://github.com/classilla/cryanc">on Github</a>.
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An Overview of Nix in Practice (124 pts)]]></title>
            <link>https://www.slice.zone/blog/nix-in-practice</link>
            <guid>38237696</guid>
            <pubDate>Sun, 12 Nov 2023 05:54:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.slice.zone/blog/nix-in-practice">https://www.slice.zone/blog/nix-in-practice</a>, See on <a href="https://news.ycombinator.com/item?id=38237696">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-apply-variations="true">
<!-- -->
<!-- -->
<!-- -->

<blockquote>
<p><code>&lt;skip&gt;</code> i would really appreciate it if someone who knows nix could help tho
<span role="img" aria-label="pleading face emoji">🥺</span><br> <code>&lt;skip&gt;</code> i asked in nix server and multiple people were
like “yea this should be working but it doesn’t” <br><code>&lt;skip&gt;</code> maybe i should
post on <a href="https://discourse.nixos.org/">the discourse</a> hm <br> <code>&lt;skip&gt;</code> i’ve
lost sleep over this lol</p>
<small>— July 25, 2021</small>
</blockquote>
<p>I was introduced to Nix in late 2021 by a friend in a Discord channel, but it
wasn’t my first encounter with the operating system/package
manager/configuration system/programming language hodgepodge.</p>
<p>As a Linux-obsessed child who constantly hopped between distributions, it
inevitably registered on my radar. I was always looking for the next ISO file to
victimize and copy onto my tired USB stick, which would probably suffocate me in
my sleep if it grew arms. But NixOS was never one of those distros. It looked
too <em>weird</em> to my 14-year-old brain.</p>
<p>I still believe this. NixOS, and Nix in general, is <em>really</em> weird. I’ve
described it as what ends up writhing out of a malfunctioning industrial mixer
that someone accidentally dropped Haskell and Bash into. When I, like many other
computer programmers, tell my friends who don’t write code that “it’s a miracle
that modern technology even works”, Nix is one of those things that I’m
referring to.</p>
<p>Despite this, NixOS is the only distro I install on my servers. I’m dual-booting
it on my MacBook<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup>. I build and set up the development environments for all of
my projects with Nix. I use Nix to set up my dotfiles and take care of my shell
configuration and personal set of installed packages. Nix makes it unflinchingly
simple to replicate my cozy user environment anywhere Nix is available, so I can
feel at home no matter where I am. Nix even turned building ffmpeg into a
cakewalk for that one time I needed
<a href="https://en.wikipedia.org/wiki/Fraunhofer_FDK_AAC">better AAC encoding</a><sup><a href="#user-content-fn-2" id="user-content-fnref-2" data-footnote-ref="true" aria-describedby="footnote-label">2</a></sup>.</p>
<p>Nix is a really neat (in my opinion), but the learning “curve” is comparable to
climbing a brick wall with nothing but your fingernails, determination, and the
incredibly thin shred that is your remaining patience. I’m still not great at
Nix, and I’m terrified to submit anything to the official package collection,
but I hope to demystify it and emphasize what makes it so dang useful.</p>
<h2 id="behind-the-curtain">Behind the curtain</h2>
<p>“Nix”, generally speaking, refers to any or all of these things:</p>
<ol>
<li>A ~purely functional programming language with immutability, laziness, floaty
Haskellesque syntax, and some interesting design choices to make
configuration and configuration-adjacent tasks particularly easy.</li>
<li>A package manager and build system with the primary goal of reproducibility
that consumes package definitions and build instructions written in the Nix
programming language.</li>
<li>A massive repository that houses more than 80,000 Nix package definitions
written and maintained by over 5,000 contributors, called “nixpkgs”.</li>
<li>A Linux distribution (“NixOS”) that uses Nix<sup><a href="#user-content-fn-3" id="user-content-fnref-3" data-footnote-ref="true" aria-describedby="footnote-label">3</a></sup> to declaratively specify the
total configuration of the system, such as: which packages are to be
installed, which user accounts exist on the system, and what services are
active.</li>
</ol>
<p>All of these puzzle pieces fit together to create something that is truly unique
and terrifying. Hooray!</p>
<p>Nix is different from other package managers in that it’s truly and utterly
obsessed with making things entirely self-contained. When Nix builds a package,
the build environment is isolated such that nothing outside of what you declare
is accessible. Having globally installed libraries that are recognized by
<code>configure</code> scripts, CMake, etc. can be a massive pain, especially when you need
a specific version or find yourself needing to apply bespoke patches. Sometimes
the exact version of a library you require just isn’t available easily. Having
multiple versions installed can be either difficult or nigh impossible.</p>
<p>Nix avoids this by having binaries reference their dependencies <em>explicitly</em>.
List the shared libraries needed by a binary that was built by Nix, and you’ll
see something like this:</p>

<pre><code>$ ldd "$(which curl)"
	linux-vdso.so.1 (0x00007fffeeb86000)
	libcurl.so.4 =&gt; /nix/store/rirzp6ijbcwnxlf0b2n286n587r3z9jw-curl-7.86.0/lib/libcurl.so.4 (0x00007ffb5ce40000)
	libssl.so.3 =&gt; /nix/store/4mxnw95jcm5a27qk60z7yc0gvxp42b9a-openssl-3.0.7/lib/libssl.so.3 (0x00007ffb5cd93000)
	libcrypto.so.3 =&gt; /nix/store/4mxnw95jcm5a27qk60z7yc0gvxp42b9a-openssl-3.0.7/lib/libcrypto.so.3 (0x00007ffb5c914000)
	libz.so.1 =&gt; /nix/store/026hln0aq1hyshaxsdvhg0kmcm6yf45r-zlib-1.2.13/lib/libz.so.1 (0x00007ffb5c8f6000)
	libc.so.6 =&gt; /nix/store/4nlgxhb09sdr51nc9hdm8az5b08vzkgx-glibc-2.35-163/lib/libc.so.6 (0x00007ffb5c6ed000)
	libnghttp2.so.14 =&gt; /nix/store/qz400bwshaqikj5s2qyvh0c9qffgmqik-nghttp2-1.49.0-lib/lib/libnghttp2.so.14 (0x00007ffb5c6bc000)
	libidn2.so.0 =&gt; /nix/store/5mh5019jigj0k14rdnjam1xwk5avn1id-libidn2-2.3.2/lib/libidn2.so.0 (0x00007ffb5c69a000)
	libssh2.so.1 =&gt; /nix/store/vqq9s0d6fw6kqf3sr5nrzqbys9rhygqd-libssh2-1.10.0/lib/libssh2.so.1 (0x00007ffb5c659000)
	libgssapi_krb5.so.2 =&gt; /nix/store/r7gl900my2fw6k33nxh2r7rzv8nv0s25-libkrb5-1.20/lib/libgssapi_krb5.so.2 (0x00007ffb5c606000)
	libzstd.so.1 =&gt; /nix/store/w10in9diaqrcqqxi5lg20n3q2jfpk6pq-zstd-1.5.2/lib/libzstd.so.1 (0x00007ffb5c540000)
	libbrotlidec.so.1 =&gt; /nix/store/9iy1ng7h1l6jdmjk157jra8n4hkrfdj1-brotli-1.0.9-lib/lib/libbrotlidec.so.1 (0x00007ffb5c532000)
	libdl.so.2 =&gt; /nix/store/4nlgxhb09sdr51nc9hdm8az5b08vzkgx-glibc-2.35-163/lib/libdl.so.2 (0x00007ffb5c52d000)
	libpthread.so.0 =&gt; /nix/store/4nlgxhb09sdr51nc9hdm8az5b08vzkgx-glibc-2.35-163/lib/libpthread.so.0 (0x00007ffb5c528000)
	/nix/store/4nlgxhb09sdr51nc9hdm8az5b08vzkgx-glibc-2.35-163/lib/ld-linux-x86-64.so.2 =&gt; /nix/store/4nlgxhb09sdr51nc9hdm8az5b08vzkgx-glibc-2.35-163/lib64/ld-linux-x86-64.so.2 (0x00007ffb5cee7000)
	libunistring.so.2 =&gt; /nix/store/34xlpp3j3vy7ksn09zh44f1c04w77khf-libunistring-1.0/lib/libunistring.so.2 (0x00007ffb5c37a000)
	libkrb5.so.3 =&gt; /nix/store/r7gl900my2fw6k33nxh2r7rzv8nv0s25-libkrb5-1.20/lib/libkrb5.so.3 (0x00007ffb5c29f000)
	libk5crypto.so.3 =&gt; /nix/store/r7gl900my2fw6k33nxh2r7rzv8nv0s25-libkrb5-1.20/lib/libk5crypto.so.3 (0x00007ffb5c270000)
	libcom_err.so.3 =&gt; /nix/store/r7gl900my2fw6k33nxh2r7rzv8nv0s25-libkrb5-1.20/lib/libcom_err.so.3 (0x00007ffb5c26a000)
	libkrb5support.so.0 =&gt; /nix/store/r7gl900my2fw6k33nxh2r7rzv8nv0s25-libkrb5-1.20/lib/libkrb5support.so.0 (0x00007ffb5c25a000)
	libkeyutils.so.1 =&gt; /nix/store/816qwr4xy058451rbxr0ccyh1v1akhb6-keyutils-1.6.3-lib/lib/libkeyutils.so.1 (0x00007ffb5c251000)
	libresolv.so.2 =&gt; /nix/store/4nlgxhb09sdr51nc9hdm8az5b08vzkgx-glibc-2.35-163/lib/libresolv.so.2 (0x00007ffb5c23f000)
	libm.so.6 =&gt; /nix/store/4nlgxhb09sdr51nc9hdm8az5b08vzkgx-glibc-2.35-163/lib/libm.so.6 (0x00007ffb5c15f000)
	libbrotlicommon.so.1 =&gt; /nix/store/9iy1ng7h1l6jdmjk157jra8n4hkrfdj1-brotli-1.0.9-lib/lib/libbrotlicommon.so.1 (0x00007ffb5c13c000)
</code></pre>
<p>Assuming that the package is built correctly and you aren’t playing any runtime
linker tricks on your end, it’s virtually impossible to run into library errors.
Having multiple versions of a library installed is a nonissue, and dependency
hell falls into irrelevancy.</p>

<p>Binaries are vacuum packed in that they only ever refer to exactly what they
need, and this applies for both runtime and build dependencies alike.</p>
<p>Because the Nix store is essentially an append-only graph database<sup><a href="#user-content-fn-4" id="user-content-fnref-4" data-footnote-ref="true" aria-describedby="footnote-label">4</a></sup> with
nodes being packages and edges being dependency relations, I can even query it
to see e.g. ffmpeg’s runtime dependencies, both direct and indirect:</p>
<figure><img alt="An end-to-end graph of ffmpeg's dependencies." title="An end-to-end graph of ffmpeg's dependencies." loading="lazy" width="550" height="321" decoding="async" data-nimg="1" sizes="(max-width: 800px) 90vw, (min-width: 800px) 570px" srcset="https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fffmpeg-graph.993e883a.png&amp;w=640&amp;q=75 640w, https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fffmpeg-graph.993e883a.png&amp;w=750&amp;q=75 750w, https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fffmpeg-graph.993e883a.png&amp;w=828&amp;q=75 828w, https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fffmpeg-graph.993e883a.png&amp;w=1080&amp;q=75 1080w, https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fffmpeg-graph.993e883a.png&amp;w=1200&amp;q=75 1200w, https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fffmpeg-graph.993e883a.png&amp;w=1920&amp;q=75 1920w, https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fffmpeg-graph.993e883a.png&amp;w=2048&amp;q=75 2048w, https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fffmpeg-graph.993e883a.png&amp;w=3840&amp;q=75 3840w" src="https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fffmpeg-graph.993e883a.png&amp;w=3840&amp;q=75"><p>Brought to you by <code>nix-store</code> and <code>graphviz</code>.</p></figure>

<p>At the top, we see <code>CoreFoundation</code>, which is a core macOS system framework that
a lot of packages depend on. We can also spot <code>dejavu-fonts-minimal</code>, which is
needed by <code>fontconfig</code>, which is needed by <code>libass</code> to render subtitles, which
is needed by this default configuration of <code>ffmpeg</code>. Emphasis on default: we can
override options provided by the package definition and specify <code>.patch</code> files
to be applied to the source code.</p>
<p>To maximize reproducibility, Nix works on the source code of a package. But
because every package is built in its own universe, it is extremely cacheable.
Nix package installations are capital F <em>Fast</em>, because there’s no dependency
resolution to be done. It amounts to downloading data from a CDN and unpacking
it, and it can’t get any faster than that.</p>

<p>Executing “over 350,000 builds each week”, the NixOS foundation maintains
<a href="https://hydra.nixos.org/">a massive Nix build farm for <code>x86-64</code> and <code>aarch64</code> Linux and macOS</a>,
uploading the build artifacts to
<a href="https://cache.nixos.org/">a widely-available binary cache</a>.</p>
<p>As Nix evaluates the build instructions locally, it hashes the result and
queries the cache for it. In theory<sup><a href="#user-content-fn-5" id="user-content-fnref-5" data-footnote-ref="true" aria-describedby="footnote-label">5</a></sup>, between systems of the same platform,
there’s no difference between building the desired package and copying the
results from the cache. Taking an extreme amount of care to isolate builds from
one another makes this practical.</p>
<p>This means that in ordinary circumstances, you won’t have to build packages from
scratch. If you impose an override onto a package that changes the resulting
build instructions, Nix doesn’t find a cached result from the cache due to the
differing hashes, and the package is built locally.</p>
<p>Nix’s approach to builds also has some other neat effects:</p>
<ol>
<li><a href="https://nix.dev/tutorials/cross-compilation">Cross-compilation becomes easier</a>,
which unfortunately complicates the overall infrastructure but makes
approaching this problem comparatively less scary…probably.</li>
<li><a href="https://nixos.org/manual/nix/stable/advanced-topics/distributed-builds.html">Remote build</a>
support lets you evaluate a package’s (potentially customized) build
instructions on your local box, then send them to a more powerful machine
over the network to build. This is not only cool, but also necessary should
the package not be supported on your local platform. Distributed builds, CI,
et cetera! The sky is the limit.</li>
<li><a href="https://nixos.org/manual/nix/stable/command-ref/nix-copy-closure.html"><code>nix-copy-closure</code></a>
copies the results of a build and its total runtime dependency tree (called a
“closure”) between machines of the same platform, avoiding unnecessary work.</li>
<li>Cache your own stuff!
<a href="https://nixos.wiki/wiki/Binary_Cache">Host your own binary cache</a>, or use a
service like <a href="https://www.cachix.org/">Cachix</a> to avoid rebuilding.</li>
</ol>
<h2 id="ephemerality">Ephemerality</h2>
<figure><img alt="xkcd 1987" title="xkcd 1987" loading="lazy" width="550" height="545" decoding="async" data-nimg="1" sizes="(max-width: 800px) 90vw, (min-width: 800px) 570px" srcset="https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fxkcd-1987.6b704c51.png&amp;w=640&amp;q=75 640w, https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fxkcd-1987.6b704c51.png&amp;w=750&amp;q=75 750w, https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fxkcd-1987.6b704c51.png&amp;w=828&amp;q=75 828w, https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fxkcd-1987.6b704c51.png&amp;w=1080&amp;q=75 1080w, https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fxkcd-1987.6b704c51.png&amp;w=1200&amp;q=75 1200w, https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fxkcd-1987.6b704c51.png&amp;w=1920&amp;q=75 1920w, https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fxkcd-1987.6b704c51.png&amp;w=2048&amp;q=75 2048w, https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fxkcd-1987.6b704c51.png&amp;w=3840&amp;q=75 3840w" src="https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fxkcd-1987.6b704c51.png&amp;w=3840&amp;q=75"><p>This sums it up, I think.</p></figure>

<p>Managing Python environments is not only painful, but actively damaging to the
psyche.</p>
<p>Setting up an ephemeral Python environment with OpenCV can be done in Nix like
so:</p>
<pre><code>$ nix-shell --pure -p "python3.withPackages(packages: [ packages.opencv4 ])" --run python3
Python 3.10.10 (main, Feb 17 2023, 05:25:10) [Clang 11.1.0 ] on darwin
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; import cv2
&gt;&gt;&gt;
</code></pre>
<p>I can run a similar command to drop myself into a REPL with NumPy or SciPy, or
any package in general: a certain version of Java, or even a Node or Haskell
environment.</p>
<p>Dissecting the command:</p>
<ol>
<li>
<p>The <code>--pure</code> flag clears the environment before dropping you into the shell,
preventing e.g. <code>$PATH</code> from leaking through.</p>
</li>
<li>
<p><code>-p</code> specifies which package(s) we are interested in. In this case, <code>python3</code>
(which currently resolves to <code>python310</code> on the 22.11 channel). We use
<code>withPackages</code> to indicate that we’d like to create an environment with the
<code>opencv4</code> Python package available.</p>
<pre><code><span>python3</span><span>.</span><span>withPackages</span>(<span>packages</span>: [ <span>packages</span><span>.</span><span>opencv4</span> ])
</code></pre>
<p>This is Nix <em>code</em> that uses package definitions from nixpkgs, which has
specific infrastructure for Python, Python packages, and managing Python
environments. Nix has similar infrastructure for Rust, Node.js, etc.</p>
</li>
<li>
<p><code>--run</code> drops us directly into the Python REPL instead of Bash.</p>
</li>
</ol>
<p>Invoking this command causes Nix to compute which packages is needed and what
Python environment trickery needs to be done. If the necessary packages aren’t
in my Nix store already, they’re downloaded from the binary cache. When I exit
the shell, my local Python user environment remains completely untouched. The
fundamental nature of Nix allows this to happen in a frictionless way—no
<code>virtualenv</code> futzing required.</p>
<p>Nix’s modular nature allows it to cooperate with other technologies, too. Take
Docker, for instance:
<a href="https://xeiaso.net/blog/i-was-wrong-about-nix-2020-02-10">Nix is seemingly better at generating smaller images</a>;
because
<a href="https://grahamc.com/blog/nix-and-layered-docker-images/">it knows everything about every package</a>,
it can purge superfluous data down to the nanometer and keep only the bits that
matter.</p>
<h2 id="declarative-systems">Declarative systems</h2>
<p>NixOS takes wacky declarative package management to its next logical conclusion
by using the same technology to determine to service topology of your Linux
system. In essence, your system configuration becomes a package that is managed
and installed by Nix just like any other.</p>
<p>This is what a minimal NixOS configuration looks like (in practice, real
configurations are much larger):</p>
<pre><code>{ <span>config</span><span>,</span> <span>pkgs</span><span>,</span> <span>... </span>}: {
  <span>imports</span> <span>=</span> [
    <span># Import another Nix module that contains the results of the hardware scan.</span>
    <span># (Includes important kernel modules for hardware, the filesystem table, etc.)</span>
    <span>./hardware-configuration.nix</span>
  ];

  <span># Enable a bootloader for UEFI systems.</span>
  <span>boot</span>.<span>loader</span>.<span>systemd-boot</span>.<span>enable</span> <span>=</span> <span>true</span>;

  <span># Enable the OpenSSH server.</span>
  <span>services</span>.<span>sshd</span>.<span>enable</span> <span>=</span> <span>true</span>;

  <span># Add some useful packages for everyone.</span>
  <span>environment</span>.<span>systemPackages</span> <span>=</span> <span>with</span> <span>pkgs</span>; [ <span>git</span> <span>curl</span> <span>wget</span> ];

  <span># ...</span>
}
</code></pre>
<p>As someone with ADHD and relatively poor memory retention, NixOS is a godsend
for managing my fleet of servers. After not having logged into a box for a
while, I easily forget what services exist on the server. I’m too lazy to
maintain this in writing, but it’s OK because Nix enables declarative management
of these services. It acts as the definitive source of truth.</p>
<p>Figuring out exactly what a server does without fear of documentation
desynchronizing with what actually exists on the server is a single
<code>$EDITOR /etc/nixos/configuration.nix</code> away.</p>
<p>NixOS differs from something like Ansible in that it’s inherently declarative,
through and through. If you remove the <code>services.sshd.enable = true;</code> line from
your configuration, NixOS will tear down the OpenSSH server upon a rebuild.
It’ll be as if it was never there (subtracting any leftover data), because there
isn’t a practical difference between installing NixOS for the first time and
building it again. Ansible has the notion of “idempotency”, but Nix (and NixOS)
is idempotent by nature.</p>
<p>NixOS isn’t special:</p>
<ol>
<li>
<p>You can build a NixOS system and copy the closure to another machine to use.</p>
</li>
<li>
<p>You can
<a href="https://nixos.wiki/wiki/Creating_a_NixOS_live_CD">make a custom version of the NixOS installer ISO</a>
with your desired customizations to craft your ideal Linux rescue USB.</p>
</li>
<li>
<p>You can
<a href="https://nixos.org/manual/nixos/stable/#sec-changing-config">test experimental changes to your system</a>
by sandboxing it within a QEMU virtual machine:</p>
<pre><code>$ nixos-rebuild build-vm

<span># Run your new system inside of a VM to see if something broke.</span>
$ ./result/bin/run-<span>*</span>-vm
</code></pre>
</li>
<li>
<p>Because virtualization is made easy with declarative configurations, NixOS
maintainers
<a href="https://nixos.org/manual/nixos/stable/index.html#sec-nixos-tests">test their own code with it</a>.</p>
</li>
<li>
<p>Because Nix packages are fully self-contained,
<a href="https://nixos.org/manual/nix/stable/package-management/profiles.html">previous generations of the system are tracked</a>,
so you can rollback anytime in the boot menu. I used this once after I
accidentally hosed my network configuration and wasn’t sure how to fix it.</p>
</li>
<li>
<p>Not only are previous generations kept around, system upgrades are
essentially fully atomic. New version of <code>libc</code> (or other Important<span role="img" aria-label="tm emoji">™️</span>
library)? On an ordinary system, replacing the file without rebooting would
probably summon flesh-eating demons. But with Nix, this isn’t an
issue—every package was already referencing the version it depended on
through an absolute path into the Nix store.</p>
</li>
</ol>
<p>Saving disk space is easy, too. Being a feature of Nix in general,
<a href="https://nixos.org/manual/nix/stable/command-ref/nix-collect-garbage.html">the garbage collector</a>
can clean up computed build instructions, old profile/system generations, and
other build dependencies that aren’t needed for a functioning system. This runs
pretty fast and is a nice crutch for those times you just need more room.</p>
<pre><code>$ sudo nix-collect-garbage -d
<span># ...</span>
16730 store paths deleted, 11828.97 MiB freed <span># :O</span>
</code></pre>
<h2 id="declarative-modular-systems">Declarative, modular systems</h2>

<p>nixpkgs comes with a huge number of included modules that port other software
and services to be usable with NixOS.</p>
<p>Something that is genuinely terrifying to set up to me is GitLab. It just has
too many moving parts. To deploy it with NixOS, I have this in my configuration:</p>
<pre><code>{
  <span>services</span>.<span>gitlab</span> <span>=</span> <span>let</span>
    <span>secretFile</span> <span>=</span> <span><span>"</span>/var/lib/gitlab-secret<span>"</span></span>;
    <span>rsaSecretFile</span> <span>=</span> <span><span>"</span>/var/lib/gitlab-secret-rsa<span>"</span></span>;
    <span>initialRootPasswordFile</span> <span>=</span> <span><span>"</span>/var/lib/gitlab-initial-root-password<span>"</span></span>;
  <span>in</span> {
    <span>enable</span> <span>=</span> <span>true</span>;
    <span>host</span> <span>=</span> <span>...</span>;
    <span>port</span> <span>=</span> <span>80</span>;
    <span>https</span> <span>=</span> <span>true</span>;
    <span>inherit</span> <span>initialRootPasswordFile</span>;
    <span>secrets</span> <span>=</span> {
      <span>secretFile</span> <span>=</span> <span>secretFile</span>;
      <span>dbFile</span> <span>=</span> <span>secretFile</span>;
      <span>otpFile</span> <span>=</span> <span>secretFile</span>;
      <span>jwsFile</span> <span>=</span> <span>rsaSecretFile</span>;
    };
  };
}
</code></pre>
<p>Other than specifying some paths to files containing secrets (a caveat which
I’ll elaborate on later), this is all I need for a functioning GitLab setup. If
I change my mind on this in the future, all I have to do is flip
<code>enable = true;</code> to <code>false</code>, or outright evict this code block from my
configuration.</p>
<p>By doing this, all required services immediately stop and become disabled. If I
run the garbage collector, all GitLab packages are deleted. All that remains is
any user data that was created by the services in question. This is seriously
awesome to me, because GitLab is exemplary of being somewhat of a behemoth to
set up, despite <a href="https://docs.gitlab.com/omnibus/">Omnibus</a>.</p>
<p>What is even better is the inherent benefit of a modular and declarative
configuration. For example, one of my servers is also responsible for hosting an
authoritative DNS server, which has a corresponding NixOS module in nixpkgs:</p>
<pre><code>{
  <span>services</span>.<span>nsd</span> <span>=</span> {
    <span>enable</span> <span>=</span> <span>true</span>;
    <span>interfaces</span> <span>=</span> [ <span><span>"</span>0.0.0.0<span>"</span></span> ];
    <span>verbosity</span> <span>=</span> <span>2</span>;
    <span>zones</span>.<span>howl</span>.<span>children</span> <span>=</span> {
      <span><span>"</span>howl.<span>"</span></span>.<span>data</span> <span>=</span> <span><span>''</span></span>
<span>        $ORIGIN howl.</span>
<span>        $TTL 3600</span>
<span></span>
<span>        @ IN SOA howl. tinyslices@gmail.com. ( 2021122201 28800 7200 864000 60 )</span>
<span>        @ IN NS louie.howl.</span>
<span></span>
<span>        <span>${</span><span>lib</span><span>.</span><span>concatStringsSep</span> <span>"</span><span>\n</span><span>"</span> <span>config</span><span>.</span><span>howl</span><span>.</span><span>records</span><span>}</span></span>
<span>      <span>''</span></span>;
    };
  };
}
</code></pre>
<p>An authoritative DNS server vends records instead of simply resolving and
caching them. Here, I’m directing
<a href="https://www.nlnetlabs.nl/projects/nsd/about/"><code>nsd</code></a> (the DNS server in
question) to listen on the unspecified address<sup><a href="#user-content-fn-6" id="user-content-fnref-6" data-footnote-ref="true" aria-describedby="footnote-label">6</a></sup>. I’m using it with
<a href="https://tailscale.com/">Tailscale</a>, which is a really neat service that enables
a zero-config mesh VPN between all of my servers and devices. (NixOS also has a
module for it—just <code>services.tailscale.enable = true;</code>.)</p>
<p>Most importantly, I’m defining a custom NixOS option: <code>howl.records</code>, which lets
me easily add lines to the zone from other modules. This is important.</p>
<pre><code>{
  <span>options</span>.<span>howl</span> <span>=</span> <span>with</span> <span>lib</span>; {
    <span>records</span> <span>=</span> <span>mkOption</span> {
      <span>type</span> <span>=</span> <span>types</span><span>.</span><span>listOf</span> <span>types</span><span>.</span><span>str</span>;
      <span>description</span> <span>=</span>
        <span><span>"</span>Authoritative DNS records exposed to every device in the tailnet<span>"</span></span>;
    };
  };
}
</code></pre>

<p>When I write the code to enable the <code>nsd</code> module above, I make sure to reference
the final value of this custom option (as <code>config.howl.records</code>) in the zone
configuration, which is collected from all instances of the option being
modified in other modules. Nix’s lazy evaluation crucially enables this.</p>
<p>Now, in another NixOS module—say, <code>monitoring.nix</code>, I can enable Grafana and
other services such as Prometheus. I can also tweak Nginx and tell it to expose
its status page, and also create virtual hosts for Grafana and Prometheus. And
in the same breath, I can create DNS records for all of these new services, so
every device connected to the tailnet can access them painlessly:</p>

<pre><code>{ <span>lib</span><span>,</span> <span>... </span>}:

<span>let</span>
  <span>inherit</span> (<span>import</span> <span>./net.nix</span>) <span>localhost</span> <span>internal</span> <span>ports</span>;
<span>in</span>
{
  <span>services</span>.<span>grafana</span> <span>=</span> {
    <span>enable</span> <span>=</span> <span>true</span>;
    <span>port</span> <span>=</span> <span>ports</span><span>.</span><span>grafana</span>;
    <span>domain</span> <span>=</span> <span><span>"</span>grafana.howl<span>"</span></span>;
    <span>rootUrl</span> <span>=</span> <span><span>"</span>http://grafana.howl<span>"</span></span>;
  };

  <span>services</span>.<span>prometheus</span> <span>=</span> {
    <span>enable</span> <span>=</span> <span>true</span>;
    <span>port</span> <span>=</span> <span>ports</span><span>.</span><span>prometheus</span><span>.</span><span>prometheus</span>;
    <span>globalConfig</span>.<span>scrape_interval</span> <span>=</span> <span><span>"</span>10s<span>"</span></span>;
    <span>scrapeConfigs</span> <span>=</span> [{
      <span># ...</span>
    }];
    <span>exporters</span> <span>=</span> {
      <span># ...</span>
      <span>nginx</span>.<span>enable</span> <span>=</span> <span>true</span>;
    };
  };

  <span># Instruct Nginx to expose its status page for Prometheus.</span>
  <span>services</span>.<span>nginx</span>.<span>statusPage</span> <span>=</span> <span>true</span>;

  <span># Configure Nginx vhosts for these new services.</span>
  <span>services</span>.<span>nginx</span>.<span>virtualHosts</span>.<span><span>"</span>grafana.howl<span>"</span></span>.<span>locations</span>.<span><span>"</span>/<span>"</span></span> <span>=</span> <span>internal</span> {
    <span>proxyPass</span> <span>=</span> <span>localhost</span> <span>ports</span><span>.</span><span>grafana</span>;
  };
  <span>services</span>.<span>nginx</span>.<span>virtualHosts</span>.<span><span>"</span>prometheus.howl<span>"</span></span>.<span>locations</span>.<span><span>"</span>/<span>"</span></span> <span>=</span> <span>internal</span> {
    <span>proxyPass</span> <span>=</span> <span>localhost</span> <span>ports</span><span>.</span><span>prometheus</span><span>.</span><span>prometheus</span>;
  };

  <span># Add lines to the DNS zone for these new services.</span>
  <span>howl</span>.<span>records</span> <span>=</span> [
    <span><span>"</span>grafana.howl. IN CNAME louie.howl.<span>"</span></span>
    <span><span>"</span>prometheus.howl. IN CNAME louie.howl.<span>"</span></span>
  ];
}
</code></pre>
<p>I import this new module in my main configuration:</p>
<pre><code>{
  <span># ...</span>
  <span>imports</span> <span>=</span> [
    <span># ...</span>
    <span>./monitoring.nix</span>
  ];
}
</code></pre>
<p>And after a rebuild, Nix pulls in the required packages and builds the system
closure, enabling and configuring every service that I declared to be active.</p>
<p>In my opinion, this is where NixOS really shines. I’m able to enable and
configure Grafana, Prometheus, Nginx, and the DNS records that have to do with
those services in a single file. I’m defining shared constants in a separate
place and using them across configurations that are written in <em>completely
different languages and syntaxes</em>.</p>

<p>With traditional server management, I’d have to install the correct packages,
look up the paths to their configuration files, and maybe even run some commands
to modify some mutable state. I’ll forget all of this in a few days or even
hours, but Nix lets me authoritatively describe it in code.</p>
<p>If I decide to stop importing that file in my configuration, then the DNS and
Nginx virtual hosts are removed; Nginx stops exposing its status page;
Prometheus and Grafana’s <code>systemd</code> units are disabled; and all unneeded packages
are no longer reachable from a garbage collector root, making them eligible for
deletion.</p>
<p>NixOS lets me unify and modularize what would otherwise be disconnected
configurations across packages in a highly idempotent, cacheable, and
declarative way, essentially homogenizing every service on the system. <strong>That’s
amazing to me.</strong></p>
<h2 id="diving-in">Diving in</h2>
<p>I’m intentionally avoiding the details here because I believe it’s important to
first grasp the big picture behind Nix and NixOS, and understand what it’s truly
useful for.</p>
<p>I write and maintain a few Discord bots. To ease the maintenance and deployment
of these critters, I’ve created a base that lets me share the same development
environment and automatically generate a NixOS module for all of them, with
customization and extension points whenever necessary. I’m interested in writing
some detailed case studies on how I accomplished this, but this post is getting
really long, and we still aren’t finished!</p>
<p>For now, here are some resources that I personally recommend for perusal should
you be interested:</p>
<ol>
<li><a href="https://zero-to-nix.com/">Zero to Nix</a>: New kid on the block; gentle and
more detailed introduction to using Nix in practice.</li>
<li><a href="https://www.youtube.com/watch?v=6iVXaqUfHi4">“Nix: What Even is it Though”</a>,
a presentation by Burke Libbey.</li>
<li><a href="https://nixos.org/guides/nix-pills/">Nix Pills</a>: Learn Nix from the bottom
up.</li>
<li>The
<a href="https://nixos.org/manual/nix/stable/introduction.html">Nix Reference Manual</a></li>
<li><a href="https://nixos.org/manual/nixpkgs/stable/">nixpkgs manual</a> and
<a href="https://nixos.org/manual/nixos/stable/">NixOS manual</a>: The official
documentation for those projects.</li>
<li><a href="https://nix.dev/">nix.dev</a>: An opinionated handbook and “survival guide”.</li>
<li><a href="https://search.nixos.org/packages">NixOS Search</a>: An invaluable tool for
quickly looking up packages and NixOS options. Keep this on speed dial.</li>
<li><a href="https://noogle.dev/">noogle</a> eases the looking up of library functions.</li>
</ol>
<p>When docs aren’t amazing, learning becomes akin to patchwork: you slowly and
incrementally stitch squares into your quilt until you reach a certain point
where everything becomes clear, and you end up with something nice and soft to
keep you warm during winter.</p>
<h2 id="rougher-edges">Rougher edges</h2>
<p>Every technology involves a set of tradeoffs, and Nix is no exception.</p>
<p>One particular pain point is managing secrets: the Nix store is world-readable,
and this includes any configuration files that may or may not contain secret
keys and passwords. This problem is tackled via projects such as <a href="https://github.com/ryantm/agenix">agenix</a> and
others, but keep this in mind when blueprinting your system. I’ve experimented
with committing my nixfiles with their encrypted secrets in public before, but
this ended up being such a massive pain that I gave up. Maybe I’ll try again
soon.</p>
<p>When it comes to libraries and scaffolding your own projects with Nix, it can be
hard to find what’s appropriate for use.</p>
<p>Two good examples: packaging Rust code, and deploying NixOS. I used to wield
<a href="https://github.com/nix-community/naersk">Naersk</a> to blast my Rust packages with the Nix beam, but was later recommended
<a href="https://crane.dev/">Crane</a> by a friend, which seems to require less ceremony. I never would’ve
found out about it otherwise. nixpkgs also seems to have built-in support for
Rust via <code>buildRustPackage</code>. I’m not sure which one is the best to use; it’s
unclear to me, but I’ve settled on Crane for now.</p>
<figure><img alt="A screenshot of a successful colmena command invocation." title="A screenshot of a successful colmena command invocation." loading="lazy" width="550" height="102" decoding="async" data-nimg="1" sizes="(max-width: 800px) 90vw, (min-width: 800px) 570px" srcset="https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fcolmena.2ebc19dc.png&amp;w=640&amp;q=75 640w, https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fcolmena.2ebc19dc.png&amp;w=750&amp;q=75 750w, https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fcolmena.2ebc19dc.png&amp;w=828&amp;q=75 828w, https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fcolmena.2ebc19dc.png&amp;w=1080&amp;q=75 1080w, https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fcolmena.2ebc19dc.png&amp;w=1200&amp;q=75 1200w, https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fcolmena.2ebc19dc.png&amp;w=1920&amp;q=75 1920w, https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fcolmena.2ebc19dc.png&amp;w=2048&amp;q=75 2048w, https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fcolmena.2ebc19dc.png&amp;w=3840&amp;q=75 3840w" src="https://www.slice.zone/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fcolmena.2ebc19dc.png&amp;w=3840&amp;q=75"><p>Build and apply your Nix config with a single command.</p></figure>
<p>Deployment to other servers from your own box is peak comfort. There are many
Nix deployment solutions, but I’ve settled on <a href="https://github.com/zhaofengli/colmena">Colmena</a>, because it supports
macOS and Flakes. There’s also <a href="https://github.com/rapenne-s/bento">Bento</a> (which tries to keep it simple), as well
as <a href="https://github.com/DBCDK/morph">Morph</a> and <a href="https://github.com/NixOS/nixops">nixops</a>. And there’s probably more I’m missing. There’s a lot of
choice here.</p>
<p>I run into a similar feeling when I write Nix code myself. The documentation
story here could use some improvement: finding the right function to use can
feel like navigating a dense jungle with a machete. I feel like reading other
people’s Nix code is one of the most effective ways to learn Nix, because you
get to see how its used (and how people solve their specific problems) in
practice.</p>
<p><a href="https://github.com/features/code-search/">GitHub’s code search</a> is an
invaluable tool here, as well as poking around in nixpkgs and asking questions
in community channels. A lot of learning Nix is done hands-on; you’ll need to
throw things at a wall to see what sticks, and that’s going to be frustrating at
first.</p>
<h2 id="the-nature-of-nix">The nature of Nix</h2>
<p>Nix is infectious, which can be both good and bad. Having a universal,
omnipresent existence on your system is what enables Nix’s niceties, but also
can make it frustrating to just <em>do things</em>.</p>
<p>You can’t follow <code>README</code> instructions verbatim anymore: if you want to use
something, it has to be packaged by Nix. Or, at least, it should. If there
happens to be a Nix package maintained by someone in nixpkgs, great! If not, you
better be in a mood to write some Nix code.</p>
<p>My dotfiles are Nix-managed, too. This means that my entire user environment is
easily reproducible everywhere Nix is available. However, this means that I need
to rebuild my user package every time I make a change, because the
configurations need to be built, copied into the Nix store, and then symlinked
into my own home directory.</p>
<p>Any change I make—big or small—has to go through Nix before programs take
notice, which can be annoying.</p>
<p>Fortunately, you aren’t forced to adopt Nix to such a high degree. You can even
install it on other Linux distributions, since it’s just a package manager. By
doing this, you get to pick and choose what falls under Nix’s reign. The more
you decide to use, though, the more you’ll have to zap things with the Nix ray.</p>
<p>Take black box binaries, for example: tarballs of pre-built blobs, sans source
code, that you “just” have to unpack and run. Nix inherently doesn’t play well
with these, and that can make certain things harder to do (see: games).</p>
<p>If patching the binaries in question is viable, <a href="https://nixos.org/manual/nixpkgs/stable/#setup-hook-autopatchelfhook">patchelf</a> can come to the
rescue. A friend of mine who is trying out NixOS is using it to patch binaries
in order to run Garry’s Mod servers, which are able to interface with external
3rd-party plugins via <code>dlsym</code> and other runtime loading.</p>
<p>When patching is unfeasible, such as programs that perform integrity checking or
simply make too many assumptions about the outside world,
<a href="https://nixos.org/manual/nixpkgs/stable/#sec-fhs-environments"><code>buildFHSUserEnv</code></a> enables you to run lightweight sandboxes
that are compatible with the Filesystem Hierarchy Standard (<code>/usr/lib</code> and
friends), made possible through Linux namespaces. This is done to <a href="https://github.com/NixOS/nixpkgs/tree/nixos-22.11/pkgs/games/steam">support
Steam</a>, which is pretty damn clever.</p>
<p>Steam has always felt pretty fragile to me. For example, it requires its own
bespoke set of libraries that it downloads and maintains outside of the system
package manager. This sucks, but it’s cool that it was possible for Nix to shove
it into a reproducible box of sorts that basically can’t break (let’s hope I
don’t jinx it).</p>
<p>When packaging other software that we have a reduced amount of control over,
things can get a little wonky. When I installed NixOS on my Mac, I ran into an
issue where <a href="https://github.com/ArmCord/ArmCord">ArmCord</a>—a neat little project that wraps Discord natively for
ARM devices—wouldn’t open links in my web browser.</p>
<p>After some poking around with Chromium’s logging levels, I eventually got it to
spew out enough debug information to see why <code>xdg-open</code> (which is what is being
spawned to open my web browser) was failing:</p>
<pre><code>XPCOMGlueLoad error for file /nix/store/5mndwvvbdz07kllj6bs0pp1n82cx260i-firefox-110.0.1/lib/firefox/libxul.so:
/nix/store/p9ggv8qkdv0s7pckz2xkxxs68ras07g3-nss-3.79.4/lib/libssl3.so: version `NSS_3.80' not found (required by /nix/store/5mndwvvbdz07kllj6bs0pp1n82cx260i-firefox-110.0.1/lib/firefox/libxul.so)
Couldn't load XPCOM.
/home/slice/.nix-profile/bin/xdg-open: line 881: x-www-browser: command not found
XPCOMGlueLoad error for file /nix/store/5mndwvvbdz07kllj6bs0pp1n82cx260i-firefox-110.0.1/lib/firefox/libxul.so:
/nix/store/p9ggv8qkdv0s7pckz2xkxxs68ras07g3-nss-3.79.4/lib/libssl3.so: version `NSS_3.80' not found (required by /nix/store/5mndwvvbdz07kllj6bs0pp1n82cx260i-firefox-110.0.1/lib/firefox/libxul.so)
Couldn't load XPCOM.
</code></pre>
<p>To my surprise, there were… linking errors going on! Firefox seemed to be
loading the incorrect version of OpenSSL for some reason. I thought Nix was
supposed to be reproducible, self-contained, etc. etc. This shouldn’t be
happening!</p>
<p>More investigation led to the realization that the ArmCord package actually
<a href="https://github.com/NixOS/nixpkgs/blob/cd749f58ba83f7155b7062dd49d08e5e47e44d50/pkgs/applications/networking/instant-messengers/armcord/default.nix#L112">injects <code>LD_LIBRARY_PATH</code> at runtime</a> so that it can find the
right libraries—needed because the package reuses the <code>.deb</code> binaries—and it
was bleeding into the <code>xdg-open</code> subprocess that was being spawned. Whoops.</p>
<p>I was able to fix this by <a href="https://github.com/ArmCord/ArmCord/issues/354#issuecomment-1480432789">wrapping <code>xdg-open</code> with a pristine script that unset
<code>LD_LIBRARY_PATH</code>, and overriding the ArmCord package to add a wrapper that
invoked the main binary with the pristine script prepended to <code>PATH</code> before
anything else</a>. Then, when <code>xdg-open</code> was spawned by Chromium,
<code>LD_LIBRARY_PATH</code> would no longer be clobbered.</p>
<p>In this situation, overriding the package definition here was enough to solve my
problem, but that might not always be the case: NixOS modules, and Nix packages
in general, are only as flexible as they are written to be<sup><a href="#user-content-fn-7" id="user-content-fnref-7" data-footnote-ref="true" aria-describedby="footnote-label">7</a></sup>. So far, I’ve
never had to straight-up fork a package or NixOS module definition, but I’m
definitely not ruling that out from ever happening.</p>
<p>Luckily, there tends to be a lot of escape hatches: nixpkgs is very configurable
and extensible with support for overlays, overrides, and source code patches.
It’s also totally possible to do something such as creating a package that
solely takes the output of another package and patches it in a certain complex
way (however you want!)</p>
<p>Lastly, I’d like to reiterate that because Nix is a lazily evaluated (and
dynamically typed) language, it’s very possible to run into fairly cryptic
errors often, especially when recursion is involved. Lazy evaluation means that
it’s possible to introduce a ticking time bomb that can be detonated from
seemingly unrelated code.</p>
<p>While this can be a pain, it’s also what enables Nix to avoid unnecessary
computation: the root of nixpkgs is a huge tree of every package contained
within the repository, but only those that are actually needed are ever
evaluated. Deferring evaluation to the last possible moment is what makes things
such as overrides and overlays possible.</p>
<h2 id="bottom-line">Bottom line</h2>
<p>Nix is quirky, unique, and a little rough around the edges. Debugging it, like a
lot of other things, is frustrating. But the benefits I get from using it
currently outweigh the disadvantages, providing enough incentive for me to keep
on investing in it.</p>
<p>What I find to be most useful for me is declarative system management via NixOS.
My memory span is virtually nonexistent nowadays, and having a way to declare my
servers completely idempotently is an incredible way to avoid confusion and
stress. I like having that philosophy extended to my personal projects and user
environment, as it ensures a level of consistency and reproducibility that I
haven’t found anywhere else.</p>
<hr>
<section data-footnotes="true">
<ol>
<li id="user-content-fn-1">
<p>Made possible via <a href="https://asahilinux.org/">the Asahi Linux project</a> and
<a href="https://github.com/tpwrules/nixos-apple-silicon">this effort, maintained by someone who I can only describe as a heaven-sent angel</a>. <a href="#user-content-fnref-1" data-footnote-backref="true" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-2">
<p>I’ve built ffmpeg from source sans Nix and it wasn’t actually that hard, but
what’s actually cool here is that that exact build configuration (ffmpeg
with that non-free library) is available across all machines with my user
environment—so I only had to figure it out once. <a href="#user-content-fnref-2" data-footnote-backref="true" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-3">
<p>Look, recursion! And yes, I’m referring to all of the other items in this
list. <a href="#user-content-fnref-3" data-footnote-backref="true" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-4">
<p>I’m stealing this quote from Burke Libbey, who has made
<a href="https://www.youtube.com/watch?v=6iVXaqUfHi4">a great presentation</a>
explaining what Nix actually is at a high level. I recommend you watch it if
you’re interested. <a href="#user-content-fnref-4" data-footnote-backref="true" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-5">
<p>Hey, gotta cover all bases. <a href="#user-content-fnref-5" data-footnote-backref="true" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-6">
<p>Apparently this is what <code>0.0.0.0</code> is named. <a href="#user-content-fnref-6" data-footnote-backref="true" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-7">
<p>This was pointed out to me in a talk by
<a href="https://xeiaso.net/talks/nixos-pain-2021-11-10">Xe Iaso</a>, which is
definitely worth a watch and or read if you’re interested in Nix’s rougher
edges. They point out a lot of the same roadblocks that I ran into
personally. <a href="#user-content-fnref-7" data-footnote-backref="true" aria-label="Back to content">↩</a></p>
</li>
</ol>
</section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Win-Vind: Vim powers with speed of thought throughout Windows 11 (200 pts)]]></title>
            <link>https://pit-ray.github.io/win-vind/</link>
            <guid>38236684</guid>
            <pubDate>Sun, 12 Nov 2023 02:32:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pit-ray.github.io/win-vind/">https://pit-ray.github.io/win-vind/</a>, See on <a href="https://news.ycombinator.com/item?id=38236684">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <main>
        















    <h2 id="what-is-this">What is this?</h2>
<p><strong>win-vind</strong> provides a lightweight hybrid UI system of CUI and GUI for Windows.<br>
By installing this tool, you will be able to control the Windows GUI in the same way as Vim.</p>

<h3 id="1-vim-user-friendly">1. Vim-user friendly.</h3>
<p>All configuration methods and mode concepts are derived from Vim, allowing for Vim-like UI operation.<br>
Vim users only need to understand win-vind’s macro features and additional mode concepts with little learning cost.</p>

<h3 id="2-there-are-many-useful-built-in-commands">2. There are many useful built-in commands.</h3>
<p>You don’t have to worry about complicated scripts and dependencies like with traditional key binding tools.<br>
You can freely create user-defined commands by combining low-level optimized built-in commands.</p>

<h3 id="3-very-portable-and-fully-open-source">3. Very portable and fully open source.</h3>
<p>win-vind is a small single binary with no dependencies that runs with user permissions. <br>
It is also available from the command line as a command for UI operations like <code>$ win-vind -c "ggyyGp"</code>.</p>

<h3 id="top-feature-demo">Top Feature Demo</h3>

<video src="https://user-images.githubusercontent.com/42631247/215270933-3365065b-53db-4eca-9fc6-cd03d13e5ab0.mp4" controls=""></video>

<h3 id="configuration-file-example">Configuration File Example</h3>

<p>You can configure it in .vimrc style. What you can do in .vindrc is switch options, set parameters, remap low-level keys, and define function bindings.</p>

<div><pre><code><span>" options</span>
<span>set</span> <span>shell</span> <span>=</span> cmd
<span>set</span> cmd_fontsize <span>=</span> <span>14</span>
<span>set</span> cmd_fontname <span>=</span> Consolas
<span>set</span> blockstylecaret
<span>set</span> blockstylecaret_mode <span>=</span> solid

<span>" bindings</span>
imap <span>&lt;</span>capslock<span>&gt;</span> <span>{&lt;</span>ctrl<span>&gt;}</span>

inoremap <span>&lt;</span>ralt<span>&gt;&lt;</span>ralt<span>&gt;</span> <span>&lt;</span>easyclick<span>&gt;&lt;</span>click_left<span>&gt;</span>
inoremap <span>&lt;</span>rctrl<span>&gt;&lt;</span>rctrl<span>&gt;</span> <span>&lt;</span>gridmove<span>&gt;&lt;</span>click_left<span>&gt;</span>
inoremap <span>&lt;</span><span>win</span><span>-</span>enter<span>&gt;</span> <span>&lt;</span>window_resizer<span>&gt;</span>

<span>noremap</span> <span>&lt;</span>ctrl<span>-1</span><span>&gt;</span> <span>:!</span> <span>gvim</span><span>&lt;</span><span>cr</span><span>&gt;</span>
<span>noremap</span> <span>&lt;</span>ctrl<span>-2</span><span>&gt;</span> <span>:</span><span>e</span> http<span>:</span><span>//</span>example<span>.</span><span>com</span><span>&lt;</span><span>cr</span><span>&gt;</span>

enoremap <span>t</span> ggyyGp

autocmd AppLeave * <span>&lt;</span>to_insert<span>&gt;</span>
autocmd AppEnter<span>,</span>EdiNormalEnter <span>vim</span><span>.</span>exe <span>&lt;</span>to_resident<span>&gt;</span>
</code></pre></div>

<h2 id="license">License</h2>
<p>This software is provided by <a href="https://github.com/pit-ray/win-vind/blob/master/LICENSE.txt">MIT License</a>.</p>





    </main>

    
    
    
    

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rats have an imagination, new research suggests (105 pts)]]></title>
            <link>https://www.sciencedaily.com/releases/2023/11/231102162557.htm</link>
            <guid>38235745</guid>
            <pubDate>Sat, 11 Nov 2023 23:43:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sciencedaily.com/releases/2023/11/231102162557.htm">https://www.sciencedaily.com/releases/2023/11/231102162557.htm</a>, See on <a href="https://news.ycombinator.com/item?id=38235745">Hacker News</a></p>
Couldn't get https://www.sciencedaily.com/releases/2023/11/231102162557.htm: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[It's OK if your code is just good enough (106 pts)]]></title>
            <link>https://shiftmag.dev/code-quality-good-enough-2034/</link>
            <guid>38234653</guid>
            <pubDate>Sat, 11 Nov 2023 21:20:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shiftmag.dev/code-quality-good-enough-2034/">https://shiftmag.dev/code-quality-good-enough-2034/</a>, See on <a href="https://news.ycombinator.com/item?id=38234653">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>
      Good enough code is a nice middle ground between implementing a feature fast and maintaining the code quality.    </p>
  </div><div>
          <figure><img fetchpriority="high" decoding="async" width="1200" height="630" src="https://shiftmag.dev/wp-content/uploads/2023/11/Code-quality.png?x35993" alt="" srcset="https://shiftmag.dev/wp-content/uploads/2023/11/Code-quality.png 1200w, https://shiftmag.dev/wp-content/uploads/2023/11/Code-quality-300x158.png 300w, https://shiftmag.dev/wp-content/uploads/2023/11/Code-quality-1024x538.png 1024w, https://shiftmag.dev/wp-content/uploads/2023/11/Code-quality-768x403.png 768w" sizes="(max-width: 1200px) 100vw, 1200px"></figure>


<p>I’ve heard a story about a student who had to write an essay to pass the exam. He had a three-month deadline. During those months he struggled a lot<strong> rewriting pages again and again</strong>. Every now and then the professor checked on him and he would always respond with “I’m not done yet, it’s simply not good enough”. </p>



<p>Finally, the professor suggested: “Write the essay as if it would be graded <em>good enough</em>“. As much as this approach was strange to him, he took the advice. Surprisingly, he <strong>finished the essay in a whip </strong>earning a <strong>higher grade than expected.</strong></p>



<p>Where I come from, <em>good enough</em> would be a “three”, simply an average grade on a 1 to 5 scale. Solid, acceptable, good.</p>



<h2><span id="the-five-shades-of-code-quality">The five shades of code quality</span></h2>



<p>We, as software developers, not only write essays but dissertations to bring our pile of zeros and ones to life. <strong>Most of us would want our code to be 5 out of 5.</strong> But is this something worth pursuing? Let’s explore five shades of code quality:</p>



<p>1 – Shit</p>



<p>2 – Proof of concept</p>



<p>3 – Good enough</p>



<p>4 – Very good&nbsp;</p>



<p>5 – Perfection</p>



<h2><span id="grade-1-shit">Grade 1: Shit</span></h2>



<p>This is the type of code that makes you sweat. Your heart sinks when you hear about a new requirement. You know it will take up ages to implement it. The best thing you can do is to throw everything away and rewrite it. Such code<strong> shouldn’t be acceptable</strong>, we shouldn’t ship shit.</p>



<h2><span id="grade-2-poc">Grade 2: PoC</span></h2>



<p>Typical PoC code. You know that this code is <strong>not good but you can live with it for a while</strong>.&nbsp;</p>



<p>Usual problems:</p>



<ul>
<li>doesn’t have clear architecture, clear boundaries</li>



<li>many things are tightly coupled</li>



<li>many edge cases are not covered</li>



<li>missing validations</li>



<li>inadequate domain object modeling</li>



<li>too complex or too tiny test suite</li>



<li>code is not clean</li>
</ul>



<p>While this may not sound ideal, it can serve to <strong>quickly determine the direction you want to go</strong>. You can move really fast and iterate as you go. This code quality is particularly suitable for PoC initiatives.</p>





<h2><span id="grade-3-good-enough">Grade 3: Good enough</span></h2>



<p>Good enough code is a nice middle ground between implementing a feature fast and maintaining the code quality.</p>



<p>It addresses many of the issues typically found in grade 2 code, with some exceptions:</p>



<ul>
<li>some unnecessary levels of abstraction</li>



<li>some unclear naming</li>



<li>few larger functions or classes (nothing too big)</li>



<li>misuse of exceptions here and there</li>



<li>some code duplications</li>



<li>redundant commenting</li>



<li>readability issues in tests</li>
</ul>



<p>This code is suited for most applications. It’s probably the best for those dealing with CRUD operations. You can also achieve good results using this approach on components involved in traffic flow.&nbsp;</p>



<h2><span id="grade-4-very-good">Grade 4: Very good</span></h2>



<div><p>Grade 4 is a <strong>highly maintainable clean code paradise</strong>. Doesn’t have any problems that <em>good enough</em> has. </p><p>Take a look at the&nbsp;<a href="https://github.com/infobip/infobip-spring-data-querydsl" target="_blank" rel="noreferrer noopener">infobip-spring-data-querydsl&nbsp;</a>library. <strong>Although it sounds perfect, it’s not.</strong> Everything is by the book, yet you may not like it, or dislike some parts of it. For example, you may find interfaces to be too generic, or you might be bothered with the usage of primitives instead of objects or something else. There will always be something to dislike and that is ok. :D.&nbsp;</p></div>



<p>The problem with this grade is that<strong> it is difficult to achieve.</strong> We have different backgrounds and views about how a really good code should look like.</p>



<p>I’ve worked with a freelancing company whose code was on this level. In order to achieve it, they enforced <strong>highly strict static code analysis</strong> and <strong>really challenging code reviews</strong>. Static code analysis was the cornerstone to stop most of the common problems from&nbsp;<em>good enough</em> entering the codebase. You can view them&nbsp;<a href="https://www.elegantobjects.org/" target="_blank" rel="noreferrer noopener">here</a>&nbsp;– under principles. Code review consisted of <strong>two reviewers</strong>, <strong>one developer and an architect, plus a QA </strong>person who would check the quality of the review.&nbsp;</p>



<p>If you want to tackle with grade 4 you need to <strong>build infrastructure for it</strong> and have everyone onboard with it. Aiming for <strong>this grade will slow you down</strong> so it should be taken into consideration when doing estimations with PD. Clear benefits will be seen in the long run.</p>



<p>This grade might be suited for building libraries that would be used by multiple projects/teams or when building critical parts of a system.</p>



<h2><span id="grade-5-perfection">Grade 5: Perfection</span></h2>



<p>Doesn’t exist.</p>



<h2><span id="good-enough-is-the-way-to-go">Good enough is the way to go</span></h2>



<p>Daily we are faced with different requirements, different deadlines, scopes, and so on. They are, of course, not always quick and simple to solve but most of the time,&nbsp;the <em>good enough</em>&nbsp;approach is the way to go. </p>



<p>To me, the code that has a clear architecture, understandable names of services, and good tests ticks all the boxes. And I like it! It doesn’t have to be a clean-code candy. If you prefer candies, then you have to convince PD and your team that this extra sugar will benefit the project.</p>



<p>What would you say, what would be your preferred coding approach?</p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OCaml: a Rust developer's first impressions (169 pts)]]></title>
            <link>https://pthorpe92.github.io/ocaml/ocaml-first-thoughts/</link>
            <guid>38234580</guid>
            <pubDate>Sat, 11 Nov 2023 21:12:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pthorpe92.github.io/ocaml/ocaml-first-thoughts/">https://pthorpe92.github.io/ocaml/ocaml-first-thoughts/</a>, See on <a href="https://news.ycombinator.com/item?id=38234580">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main" role="main">
    
      
    
    <h3 id="ocaml-first-impressions">OCaml: First impressions</h3>

<h4 id="the-why">The Why</h4>

<p>I’m somewhat of a language nerd to begin with, and it was Rust that originally got me interested in the whole functional paradigm.
Not due to it’s lineage, but the heavy use of chained iterator methods in favor over traditional loops. This is one of the more intimidating hurdles
for newcomers to the language, but after getting used to it, rarely will you see anyone write a <code>for</code> loop again.</p>

<p><strong>Rant:</strong> The argument can be made that what I’m talking about is more similar to Javascript-land where a bunch of pseudo-functional methods and terminology are 
used, but it in reality is as far away from functional programming as <code>useState()</code> would imply it is. 
At least Rust has a few things to back it up, as at least a language that will support you should you desire to write pure functional code. I would argue that for beginners, Rust will simply force you to write functional, immutable code, whether they really understand it or otherwise, as the amount of <code>.clone()</code>‘ing required for a newcomer to compile a non-trivial program will practically almost guarantee that nothing was actually <code>&amp;mut</code>ated*.</p>

<p>So this got me interested in watching some <em>GOTO</em>, <em>strangeloop</em>, and other conference talks about functional programming, and upon discovering @artemslab
(definitely go check it out, awesome content) on YouTube and watching some in-depth videos about Ocaml and it’s runtime integer representations and memory
allocation, that really got me fascinated with the language.</p>

<p>In the past, I typically wouldn’t hesitate to <code>sudo pacman -Sy </code> whatever compiler or interpreter I needed, to get started playing around with a new language I was interested in. However since getting full-time employment, on top of the existing OSS stuff,
as well as doing contracted gigs for the facility I’m in, I haven’t had so much as a moment to spend on anything un-related to these things in quite some time.</p>

<p>Anyways, as usual I’m off track here. My point is that I <em>thought</em> I had a good introduction to the world of FP, and I <em>thought</em> since I’d heard that many of the
features and some of the syntax we love from Rust came directly from tha ‘Caml itself, I thought I would be love it and picking it up would be second nature.</p>

<p>My plan was to do the entire Advent of Code in Ocaml, and I was also going to pick an ambitious project that I would otherwise use Rust for, and force myself
to use Ocaml. I find this is the best way to learn a language, is just take on a project that is significantly more ambitious than your current skill level, and by thetime you finish it, you’ll have not only saved yourself a bunch of wasted time on tutorials, but you’ll have made something cool (hopefully).</p>

<h3 id="i-have-two-gripes-with-the-language-so-far">I have two gripes with the language (so far)..</h3>

<h3 id="where-are-the-types-">Where are the types? 👀</h3>

<p>I underestimated how much I would be thrown off by the fact that the types are <em>heavily</em> inferred, and are almost never explicitly declared, from what I can tell. I found that the combination of this and the strange syntax really screws me up, as now I am having problems inferring my <em>own</em> types at this point…</p>

<p>When dealing with lots of recursive functions, you find yourself looking up often at the function signature to view the parameters, but the concise syntax makes it difficult to mentally parse quickly.</p>

<p>Example, random code snippet from ocaml.org:</p>
<pre><code>  let group list sizes =
    let initial = List.map (fun size -&gt; size, []) sizes in

  let prepend p list =
    let emit l acc = l :: acc in
    let rec aux emit acc = function
      | [] -&gt; emit [] acc
      | (n, l) as h :: t -&gt;
         let acc = if n &gt; 0 then emit ((n - 1, p :: l) :: t) acc
                   else acc in
         aux (fun l acc -&gt; emit (h :: l) acc) acc t
    in
    aux emit [] list
  in
  let rec aux = function
    | [] -&gt; [initial]
    | h :: t -&gt; List.concat_map (prepend h) (aux t)
  in
  let all = aux list in
  let complete = List.filter (List.for_all (fun (x, _) -&gt; x = 0)) all in
    List.map (List.map snd) complete;;
val group : 'a list -&gt; int list -&gt; 'a list list list = &lt;fun&gt;
;;
</code></pre>
<p>Even when you learn what it actually going on here, and it makes immediate sense to you.. It must take a while before it becomes easier to read.</p>

<h3 id="remember-recursion-how-about-linked-lists">Remember recursion? How about linked lists?</h3>

<p>Two things every Computer science student learns, and then are immediately told to never use again*…</p>

<p>Anything that can be done recursively can be done iteratively (and most optimizing compilers will replace your recursion anyway), and linked lists are slow and inefficient with modern CPU caches, and you should almost never use them (and if you’re a web dev, well, you just wouldn’t anyway).</p>

<p>You could describe Ocaml as a language that relies <strong>heavily</strong> on <em>both</em> of these things. This feels even more strange that it might seem it would, and I have
found myself stumbling on absolutely remedial tasks.</p>

<p>Yes, there are libraries with other data structures, and there are in fact <code>for</code> loops (and even <code>while</code> loops), However I feel like I will end up learning more of the language and find that iterator methods will be used more so than any of these, much as in Rust.</p>

<h2 id="the-good">The Good:</h2>

<ul>
  <li>
    <p>Thought provoking. If you don’t believe there is anything to gain from being forced to think about something you do every day in a completely different way… well I’m surprised you made it this far into the post.</p>
  </li>
  <li>
    <p>Awesome mixture of !significant-whitespace and !brackets. And how cool is the comment syntax? (* doesn’t it just feel like.. middle-eastern-ish *);;</p>
  </li>
  <li>
    <p>Tooling: is way better than it has any right to be, considering the size of it’s user-base and community.</p>
  </li>
  <li>
    <p>Great conversation starter, really cool and helpful community.</p>
  </li>
</ul>

<p>Lots more to learn for sure but these were my initial thoughts anyway, I do really want to like it so we will see how much that helps. I just definitely did not get the head-start I was expecting, but I don’t think that’s a negative thing it just means there is more to learn.</p>

<p>*obviously I know this isn’t true and an extreme exaggeration, but I thought it was funny. There’s always someone who will ‘well ackshually’ you when 
you think it’s obvious.</p>


<ul>
  
  
    <li>
      <a href="#2023">
        <strong>2023</strong> <span>3</span>
      </a>
    </li>
  
</ul>




  <section id="2023">
    <h2>2023</h2>
    
    <a href="#page-title">Back to Top ↑</a>
  </section>


  </div></div>]]></description>
        </item>
    </channel>
</rss>