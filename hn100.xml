(ignoring known css parsing error)
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 05 Oct 2025 07:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Way past its prime: how did Amazon get so rubbish? (119 pts)]]></title>
            <link>https://www.theguardian.com/technology/2025/oct/05/way-past-its-prime-how-did-amazon-get-so-rubbish</link>
            <guid>45479103</guid>
            <pubDate>Sun, 05 Oct 2025 05:47:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/technology/2025/oct/05/way-past-its-prime-how-did-amazon-get-so-rubbish">https://www.theguardian.com/technology/2025/oct/05/way-past-its-prime-how-did-amazon-get-so-rubbish</a>, See on <a href="https://news.ycombinator.com/item?id=45479103">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p><span>I</span>t’s not just you. The internet is getting worse, fast. The services we rely on, that we once loved? They’re all turning into piles of shit, all at once. Ask any Facebook user who has to scroll past 10 screens of engagement-bait, AI slop and surveillance ads just to get to one post by the people they are on the service to communicate with. This is infuriating. Frustrating. And, depending on how important those services are to you, <em>terrifying</em>.</p><p>In 2022, I coined a term to describe the sudden-onset platform collapse going on all around us: <em><a href="https://www.theguardian.com/science/2024/nov/26/enshittification-macquarie-dictionary-word-of-the-year-explained" data-link-name="in body link">enshittification</a></em>. To my bittersweet satisfaction, that word is doing big&nbsp;numbers. In fact, it has achieved escape velocity. It&nbsp;isn’t&nbsp;just a way to say something got worse. It’s an analysis that explains the way an online service gets worse, how that worsening unfolds, and the contagion that’s causing everything to get worse, all at once.</p><p>This moment we’re living through, this Great Enshittening, is a material phenomenon, much like a disease, with symptoms, a mechanism and an epidemiology. When doctors observe patients who are sick with a novel pathogen, their first order of business is creating a natural history of the disease. This natural history is an ordered catalogue of the disease’s progress: what symptoms do patients exhibit, and in which order?</p><p>Here’s the natural history of enshittification:<br><strong>1</strong> First, platforms are good to their users.<br><strong>2</strong> Then they abuse their users to make things better for their business customers.<br><strong>3</strong> Next, they abuse those customers to claw back all the value for themselves – and become a giant pile of shit.</p><p>This pattern is everywhere. Once you learn about it, you’ll start seeing it, too. Take <a href="https://www.theguardian.com/technology/amazon" data-link-name="in body link">Amazon</a>, a company that started out by making it possible to have any book shipped to your door and then became the only game in town for everything else, even as it dodged taxes and filled up with self-immolating crapgadgets and other junk.</p><p>In Jeff Bezos’s original business plan for <a href="https://www.theguardian.com/technology/amazon" data-link-name="in body link" data-component="auto-linked-tag">Amazon</a>, the company was called Relentless. Critics say that this is a reference to Bezos’s cutthroat competitive instincts, but Bezos always insisted that it was a reference to his company’s relentless commitment to customer service.</p><p>How did Amazon go from a logistics company that got packages to you quickly and efficiently to a behemoth of digital content defined by the Prime experience (which has much less to do with free shipping now and more with everything else)?</p><hr><h2 id="stage-1-good-to-users"><strong>Stage </strong><strong>1: good to </strong><strong>users</strong></h2><p>Amazon started with a large surplus of cash that it was able to allocate to its customers, and allocate it did. The company raised a fortune from early investors, then a larger fortune by listing on the stock market. Then it used that fortune to subsidise many goods, selling them below cost. It also subsidised shipping and offered a no-questions-asked, postage-paid returns policy.</p><p>This offer tempted millions of users to pile on to the platform. Once they were there, Prime membership went a long way to locking them in. Paying for shipping a year in advance is a powerful incentive to do your shopping on Amazon. Indeed, the overwhelming majority of Prime subscribers begin their e-commerce searches on Amazon and, if they find what they’re looking for, don’t shop around for a better deal.</p><p>You can think of Prime as a form of soft lock-in, Amazon binding you to its platform with a silken ribbon. But Amazon’s also got some iron chains in its toolbox. All the audiobooks and movies, and most of the ebooks and emagazines, you buy from Amazon are permanently locked to its platform.</p><p>They are sold with digital rights management (DRM), a form of encryption designed to force you to view or listen using apps that Amazon controls. Break up with Amazon and delete your apps, and you will lose all the media you’ve ever bought from the platform. For a certain kind of reader, listener or movie buff, this is a very high switching cost indeed.</p><p>Amazon has one more trick up its sleeve: after years of selling goods below cost, it has completed the work that big box stores started, eliminating swaths of small, independent, brick-and-mortar businesses. Its online predatory pricing tactics have done the same for much of the e-commerce world.</p><p>That means shopping anywhere other than Amazon has become substantially more inconvenient. These tactics – Prime, DRM and predatory pricing – make it very hard <em>not</em> to shop at Amazon. With users locked in, to proceed with the enshittification playbook,&nbsp;Amazon needed to get its business customers locked in, too.</p><hr><h2 id="stage-2-abusing-users-good-to-businesses"><strong>Stage </strong><strong>2: abusing users, good to business</strong><strong>es</strong></h2><p>Amazon was initially very good to those business customers. It paid full price for their goods, then sold them below cost to its customers. It subsidised returns and customer service, too. It ran a clean search engine, which put the best matches for shoppers’ queries at the top of the page, creating a path to glory merchants could walk merely by selling quality goods at fair prices.</p><p>Then, once those merchants were locked in, Amazon put the screws on them. Amazon brags about this technique, which it calls “the flywheel”. It brings in users with low prices and a large selection. This attracts merchants who are eager to sell to those users. The merchants’ dependence on those customers allows Amazon to extract higher discounts from those merchants, and that brings in more users, which makes the platform even more indispensable for merchants, allowing the company to require even deeper discounts – and around and around the flywheel spins.</p><p>Let’s take a step back. This flywheel is the direct product of a radical legal theory that has had the world in its grip since the late 1970s. From the 1890s until the Jimmy Carter administration, US corporations’ power was blunted by antitrust law, which treated large companies as threats <em>simply because they were large</em>. Once a company is too big to fail, it becomes too big to jail, and then too big to care. Antitrust law was designed to fight that apathy and force companies to care.</p><p>A rival – and frankly terrible – theory of antitrust law says that the only time a government should intervene against a monopolist is when it is sure that the monopolist is using its scale to raise prices or lower quality. This is the consumer welfare standard theory and its premise is that when we find monopolies in the wild, they are almost certainly large and powerful thanks to the quality of their offerings. Any time you find that people all buy the same goods from the same store, you should assume that this is the very best store, selling the very best goods. It would be perverse (goes the theory) for the government to harass companies for being so excellent that everyone loves them.</p><p>It was under this theory that <a href="https://www.theguardian.com/us-news/jimmy-carter" data-link-name="in body link">Jimmy Carter</a> started to remove a few of the Jenga blocks from the antitrust system. Then <a href="https://www.theguardian.com/us-news/ronald-reagan" data-link-name="in body link">Ronald Reagan</a> came along and tore them out by the fistful. (Most of the rightwing policies for which we remember Reagan <a href="https://blogs.lse.ac.uk/usappblog/2023/04/27/much-of-ronald-reagans-presidency-was-foreshadowed-by-jimmy-carters-policies/" data-link-name="in body link">started under Carter</a>, who was hoping to woo conservative voters. He failed.) Every president since – Republican or Democrat – has followed Reagan’s example, up to (but not including) <a href="https://www.theguardian.com/us-news/joebiden" data-link-name="in body link">Joe Biden</a>.</p><p>The Amazon flywheel is designed to fit neatly into the consumer welfare framework. It proclaims itself to be an enemy to merchants on behalf of consumers. The flywheel is all about lowering prices, and the consumer welfare standard theory prizes low prices above all else.</p><hr><h2 id="stage-3-a-giant-pile-of-shit"><strong>Stage </strong><strong>3: a giant pile of shit</strong></h2><p>Amazon has a myriad of tactics at its disposal for shifting value from business customers to itself, some of which also involve shifting value away from end users, no matter what the cute flywheel pitch says.</p><p>It uses its overview of merchants’ sales, as well as its ability to observe the return addresses on direct shipments from merchants’ contracting factories, to <a href="https://www.theguardian.com/technology/article/2024/jun/07/independent-uk-retailers-claim-1bn-damages-against-amazon" data-link-name="in body link">cream off its merchants’ bestselling items and clone them</a>, relegating the original seller to page umpty-million of its search results.</p><p>Amazon also crushes its merchants under a mountain of junk fees pitched as optional but effectively mandatory. Take Prime: a merchant has to give up a huge share of each sale to be included in Prime, and merchants that don’t use Prime are pushed so far down in the search results, they might as well cease to exist.</p><p>Same with <a href="https://sell.amazon.co.uk/fulfilment-by-amazon?ld=SEUKFBAAdGog-Top-Kwds_14921146748_129850349469_kwd-23792740295_e_565464207487_c_sig-Cj0KCQjw_rPGBhCbARIsABjq9cerrKp9B1eCyx3wzgQTJzVZozgQC7258a5neee6dQ9lMOd6qf4PaK4aAgfiEALw_wcB_asret_&amp;amp;id=go_cmp-14921146748_adg-129850349469_ad-565464207487_kwd-23792740295_devc_ext-_prd-" data-link-name="in body link">Fulfilment by Amazon</a>, a “service” in which a merchant sends its items to an Amazon warehouse to be packed and delivered with Amazon’s own inventory. This is far more expensive than comparable (or superior) shipping services from rival logistics companies, and a merchant that ships through one of those rivals is, again, relegated even farther down the search rankings.</p><p>All told, Amazon makes so much money charging merchants to deliver the wares they sell through the platform that its own shipping is fully subsidised. In other words, Amazon gouges its merchants so much that it pays nothing to ship its own goods, which compete directly with those merchants’ goods.</p><p>Here’s where Amazon’s attacks on its merchants’ bottom lines turn into higher prices for its customers. A merchant that pays Amazon through the nose needs to make up the money somewhere. Hypothetically, merchants could eat Amazon’s fees themselves – in other words, if Amazon wants a 10% fee on an item with a 20% profit margin, the seller could split the difference, and settle for a 10% profit.</p><p>But Amazon’s fee isn’t 10%. Add all the junk fees together and an Amazon seller is being screwed out of 45-51 cents on every dollar it earns there. Even if it wanted to absorb the “Amazon tax” on your behalf, it couldn’t. Merchants just don’t make 51% margins.</p><p>So merchants must jack up prices, which they do. A lot. Now, you may have noticed that Amazon’s prices aren’t any higher than the prices that you pay elsewhere. There’s a good reason for that: when merchants raise their prices on Amazon, they are required to raise their prices everywhere else, even on their own direct-sales stores. This arrangement is called most-favoured-nation status, and it’s key to the <a href="https://www.theguardian.com/technology/2023/sep/26/amazon-antitrust-lawsuit-analysis-big-tech" data-link-name="in body link">US Federal Trade Commission’s antitrust lawsuit against Amazon</a>.</p><figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.NewsletterSignupBlockElement"><a data-ignore="global-link-styling" href="#EmailSignup-skip-link-34">skip past newsletter promotion</a><p id="EmailSignup-skip-link-34" tabindex="0" aria-label="after newsletter promotion" role="note">after newsletter promotion</p></figure><p>Let the implications of most-favoured nation settle in. If Amazon is taxing merchants 45-51 cents on every dollar they make, and if merchants are hiking their prices everywhere their goods are sold, then it follows you’re paying the Amazon tax no matter where you shop – even the corner mom-and-pop hardware store.</p><p>It gets worse. On average, the first result in an Amazon search is 29% more expensive than the best match for your search. Click any of the top four links on the top of your screen and you’ll pay an average of 25% more than you would for your best match – which, on average, is located 17 places down in an Amazon search result.</p><p>Why does this happen? Because Amazon makes more than <em>$</em><em>50b</em><em>n every year</em> charging merchants for search placement. When you search for a product on Amazon, the top results aren’t the best matches: they’re the matches that pay the highest fees to Amazon to be top of the list.</p><p>Researchers Rory Van Loo and Nikita Aggarwal call this “<a href="https://scholarship.law.bu.edu/faculty_scholarship/3645/" data-link-name="in body link">Amazon’s pricing paradox</a>”. Amazon gets to insist that it has the lowest prices in the business, but no one can find those prices. Instead, we all pay a massive Amazon tax every time we shop there, <em>and</em> the merchants we buy from are paying an Amazon tax, too.</p><p>That means that, on average, the stuff at the top of an Amazon search results page is <em>bad</em>. It’s low-quality, high-priced junk. Even when you’re buying a known quantity, such as a specific brand of AA batteries, the top item will usually be more expensive than the items lower down on the page – the ones without the splashy banners advertising “Best Seller” or “Amazon’s Choice”. The Amazon smile logo gets a lot more sinister when it appears next to a top search result that costs 29% more than the best match for your query, thanks to Amazon’s $50bn-a-year paid search placement.</p><p>Not that you can find lower prices through anything as simple as sorting your search results by price. The merchants that dominate the search listings will play games with quantity to have the result with the lowest price, even if the price per unit is much higher. For example, a four-pack of AAs priced at $3.99 is more expensive per battery than a 16-pack priced at $10 (ie $1 versus $0.63), but sort-by-lowest-price will bury the better deal on the third or fourth page of results.</p><p>This is only the beginning. Amazon has clawed back value from buyers and sellers in many more ways. It underinvests in anti-fraud, so the top-scoring items with the highest user ratings are often terrible but are garlanded with (paid) rave reviews. Merchants with high-quality offerings are faced with two bad options: either they sink to the bottom of the rankings, or they cheat, too. If they <em>do</em> cheat, they’ll have to raise the prices of their merchandise in order to pay for the specialised fraud-as-a-service scum who gin up all those fake reviews. Then, if they get caught, they’ll be banished from Amazon and either go bust or have to start all over again under a new business name.</p><p>But for Amazon, all of this is fine. It’s how its system works, its flywheel. Amazon makes money when you are satisfied, and when you’re furious. The costs are borne by sellers, and by you. Why <em>would</em> the company invest in fighting fraud under those circumstances?</p><p>That’s also why Amazon puts so little effort into policing rotten sellers – and why so many of the “brands” there are consonant-heavy nonsense strings, seemingly generated at random by fly-by-nights that pop up and disappear, then pop up again under a new name.</p><p>This is end-stage enshittification. Amazon locked in its customers, then squeeeeezed, counting on a few good, desperate sellers to keep the system going. Then it clawed value away from its good sellers, leaving behind bad sellers that are a further source of misery for us.</p><p>Now Amazon is in the terminal stage. We’re all still stuck to the platform, but we get less and less value out of it. And because we’re all still there, buying Prime and starting (and ending) our purchase planning with Amazon’s enshittified search results, the merchants who rely on selling to us are stuck there, too, earning less and less from every sale.</p><p>The platform has turned into a pile of shit, and we’re at the bottom of it.</p><hr><p><span>A</span> confession: I am no true believer in markets as the best arbiter of how our society should work, who should be in charge of it and how its productive capacity should be organised. Like other leftists, I am deeply suspicious of capitalism. I understand the temptation to look at all this verbiage about enshittification, throw your hands up and say, “What do you expect? Capitalism always produces crises of production. Enshittification is just a sweary euphemism for capitalism.”</p><p>But this is wrong. There are meaningful differences between the internet as it stands today – the enshitternet – and the old, good internet we once had. The enshitternet is a source of pain, precarity and immiseration for the people we love. The indignities of harassment, scams, disinformation, surveillance, wage theft, extraction and rent-seeking have always been with us, but they were a minor sideshow on the old, good internet and they are the everything and all of the enshitternet.</p><p>This has real, material consequences for our comrades in the struggle for a better world. The internet that spawned <a href="https://www.theguardian.com/world/occupy" data-link-name="in body link">Occupy</a> and <a href="https://www.theguardian.com/world/black-lives-matter-movement" data-link-name="in body link">Black Lives Matter </a>has become hostile to the maintenance of radical political movements and is inimical to the founding of new ones. That really matters. Not because the internet is the most important issue facing us today. Far from it. Compared with the climate emergency, genocide, inequality, corruption, democratic backsliding, authoritarianism and sustained racist, homophobic, misogynist and transphobic attacks, the internet is just a sideshow. But the internet is the terrain upon which these fights will be waged. It is the communications medium we will use to organise to save our species and planet from their imminent eradication. We can’t win these fights without a free, fair and open internet.</p><p><a href="https://www.theguardian.com/books/2011/nov/18/my-hero-audre-lorde-jackie-kay" data-link-name="in body link">Audre Lorde</a> was far smarter than I am about nearly everything, but when she wrote, “<a href="https://theanarchistlibrary.org/library/audre-lorde-the-master-s-tools-will-never-dismantle-the-master-s-house" data-link-name="in body link">The master’s tools will never dismantle the master’s house</a>”, she was manifestly wrong. The master’s tools were used to build that house in the first place – that makes them the ideal tools to take it to bits and rebuild it to shelter us.</p><p>We can halt the creeping enshittification of every digital device. We can build a better, enshittification-resistant digital nervous system, one fit to coordinate the mass movements we will need to fight fascism, end genocide and save our planet and our species.</p><figure id="d30261f5-99f3-45df-9c5e-0edbb4e70d5f" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:54,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;‘My house filled with stuff while my bank account drained’: how I stopped impulse buying&quot;,&quot;elementId&quot;:&quot;d30261f5-99f3-45df-9c5e-0edbb4e70d5f&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/thefilter/2025/feb/27/how-to-stop-impulse-buying&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:10,&quot;display&quot;:0,&quot;theme&quot;:0}}"></gu-island></figure><p>You won’t be able to do it alone. Your personal consumption choices might make a difference to the merchants you patronise, but they have no effect on the policies that created our enshittogenic environment. Just as you can’t save the planet by diligently sorting your recycling, you can’t stop enshittification by “voting with your wallet” (those votes are always won by those with the thickest wallets, and that’s the billionaires who made money by enshittifying everything).</p><p>Take Amazon: to fix Amazon, we need policy solutions. We need to ban predatory pricing – selling goods below cost to keep competitors out of the market (and then jacking them up again). We need to impose structural separation on the company so it can either be a platform, or compete with the sellers that rely on it as a platform. We need to curb its junk fees, which suck 45-51 cents on every dollar merchants take in. We need to end its most favoured nation deal, which forces merchants who raise their prices on Amazon to pay these fees to raise their prices everywhere else, too. We need to unionise its drivers and <a href="https://www.theguardian.com/us-news/series/amazon-diaries" data-link-name="in body link">warehouse workers</a>. We need to treat its rigged search results as the fraud they are.</p><p>The path to a better Amazon doesn’t lie through consumer activism, or appeals to the its conscience. Corporations, being artificial, immortal colony-organisms that use humans as their inconvenient gut flora, do not have consciences to appeal to. The path leads through coalitions: of consumers and merchants who are tired of being robbed; of workers who are tired of being immiserated and maimed; of competitors who are tired of being strong-armed by a monopolist bully; of tax-justice activists who are tired of trillion-dollar multinationals ducking their obligations. Systemic problems have systemic solutions, not individual ones. You can’t shop your way out of a monopoly.</p><p><a href="https://www.theguardian.com/us-news/martin-luther-king" data-link-name="in body link">Martin Luther King Jr </a>once said, “It may be true that the law cannot make a man love me, but it can stop him from lynching me, and I think that’s pretty important, also.”</p><p>It may be true that regulation can’t force corporate sociopaths to conceive of you as a human being entitled to dignity and fair treatment, and not just an ambulatory wallet, a supply of gut bacteria for the immortal colony organism that is a limited liability corporation. But it can make that exec fear you enough to treat you fairly and afford you dignity, even if he doesn’t think you deserve it. And I think that’s pretty important.</p><p><span data-dcr-style="bullet"></span> This is an edited extract from Enshittification: Why Everything Suddenly Got Worse and What to Do About It by Cory Doctorow, published by Verso at £22 on 14 October. To support the Guardian, order your copy at <a href="https://guardianbookshop.com/enshittification-9781836742227/?utm_source=editoriallink&amp;utm_medium=merch&amp;utm_campaign=article" data-link-name="in body link">guardianbookshop.com</a></p><p><em>When asked to comment for this article, an Amazon spokesman said its description of the relationship between Amazon and independent sellers appeared to be “inacccurate and misleading”, adding, “The truth is millions of independent sellers are thriving in Amazon’s store, including many who choose not to use our optional fulfilment services, which are competitively priced and often provide better value than alternatives. Amazon consistently offers customers the lowest prices across the widest selection of products and was recognised in 2024 by independent research firm Profitero as the lowest-priced UK retailer for the fifth year running. Items sold by third-party sellers are backed with our A-to-z Guarantee, </em><em>enabling customers to request a refund if an item is damaged, defective</em><em> or not as described.”</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[$912 energy independence without red tape (161 pts)]]></title>
            <link>https://sunboxlabs.com/</link>
            <guid>45476820</guid>
            <pubDate>Sat, 04 Oct 2025 21:22:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sunboxlabs.com/">https://sunboxlabs.com/</a>, See on <a href="https://news.ycombinator.com/item?id=45476820">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p>Cables / Tender:</p>

<ul>
  <li><a href="https://amzn.to/43NkcuJ">https://amzn.to/43NkcuJ</a> - $14.79</li>
  <li><a href="https://amzn.to/4cwxY8Y">https://amzn.to/4cwxY8Y</a> - $30.42</li>
  <li><a href="https://amzn.to/4cuS3fx">https://amzn.to/4cuS3fx</a> - $13.00</li>
  <li><a href="https://amzn.to/43u3ikz">https://amzn.to/43u3ikz</a> x2 - $17.00</li>
  <li><a href="https://amzn.to/43u3r7B">https://amzn.to/43u3r7B</a> - $12.99</li>
  <li><a href="https://amzn.to/43y5Qhx">https://amzn.to/43y5Qhx</a> - $8.89</li>
  <li><strong>Total</strong>: $114.09</li>
</ul>

<p><strong>=&gt; $912 total</strong></p>

<p>Remote tracking (optional):</p>

<ul>
  <li><a href="https://amzn.to/3Vs3COI">https://amzn.to/3Vs3COI</a> - $7.99</li>
  <li><a href="https://amzn.to/3TPaXGI">https://amzn.to/3TPaXGI</a> - $23.92</li>
  <li><a href="https://amzn.to/4a6UMdI">https://amzn.to/4a6UMdI</a> - $6.99</li>
  <li><a href="https://solar-assistant.io/">https://solar-assistant.io</a> - $55.83</li>
  <li><strong>Total</strong> (additional): $94.73</li>
</ul>

<h3 id="how-to-guide">How to guide</h3>

<p>Coming soon, for now refer to Will Prowse’s wiring guide on his very-similar <a href="https://www.mobile-solarpower.com/mobile-48v-system.html">48V 3000W off-grid solar system</a> which I followed and works great for me!</p>

<h3 id="financial-payback--embodied-energy">Financial Payback &amp; Embodied Energy</h3>

<div><pre><code>Financial payback period for 3000W
System cost : $1,124 on Amazon in 2024 (now $912)
Yearly energy creation: 365d * 4.26hsun/d * 1.280kW = 2,000kWh/y (but more like 1,000kWh/year after losses)
Yearly value creation: 1,000kWh/y * $0.55/kWh in SF = $550/y energy created
100W system payback period: $1,124 / $550 = 2 years until payback
</code></pre></div>

<h3 id="how-green-is-it">How green is it:</h3>

<p>Production footprint PV (<a href="https://sustainability.stackexchange.com/questions/8317/what-is-the-typical-embodied-energy-of-a-solar-photovoltaic-panel">source</a>):
<code>2,900kWhee/kW * 1.28kW = 3,712kWh embodied energy</code></p>

<p>Production footprint LiFePo4 battery (<a href="https://ris.utwente.nl/ws/portalfiles/portal/189571307/10.1016_j.procir.2019.01.099.pdf">source</a>):
<code>106kWhee/kWh * 2.4kWh = 254kWh embodied energy</code></p>

<p>Annual energy production system: 1100kWh/y
<code>Payback period: 3966kWh / 1100kWh/y = 3.5 year footprint payback</code></p>

<h3 id="faq">FAQ</h3>

<p>What’s the catch? Seems to good to be true? Well, this thing sits between your devices and the wall. So you need to neatly run extension cables from every room in the house to the “sun box”, and then run one cable from the box to the panels, and another to the wall (optional, just so it can fall back to pulling power from the wall). Photos of this are coming soon.</p>

<p>Will it ever push power back into the wall? Nope! It’ll only ever draw from the wall in the event that both the sun is down and the battery is dead (so your fridge won’t go off overnight for example).</p>

<p>Is this legal? Yes, see above. No difference to plugging your fridge into your wall, as far as the utility is concerned.</p>

    </div><section>
  <h2>Want some help?</h2>
  <p>Set up a call with us and we can plan your system!</p>
  <a href="mailto:hello@sunboxlabs.com">Email Us</a>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The UK is still trying to backdoor encryption for Apple users (321 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2025/10/uk-still-trying-backdoor-encryption-apple-users</link>
            <guid>45476273</guid>
            <pubDate>Sat, 04 Oct 2025 20:07:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2025/10/uk-still-trying-backdoor-encryption-apple-users">https://www.eff.org/deeplinks/2025/10/uk-still-trying-backdoor-encryption-apple-users</a>, See on <a href="https://news.ycombinator.com/item?id=45476273">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <div>
            <article role="article">
  
  
  <div><p><span>The </span><a href="https://www.ft.com/content/d101fd62-14f9-4f51-beff-ea41e8794265?accessToken=zwAGQBl4pP6YkdPRAf1iFPlPUdO-_-pB6HlCZQ.MEYCIQDqJlwcbpQ4rrKlgeSJtbcTgqpW4uTX3yGMCHf2gdS0fQIhAMtU15LHqeHwAXTZ3wWJLDzI72kjsauSKc8OEDpim1Gx&amp;sharetype=gift&amp;token=3767767d-fe68-4911-a97e-c067715e061e"><span>Financial Times reports that</span></a><span> the U.K. is once again demanding that Apple create a backdoor into its encrypted backup services. The only change </span><a href="https://www.eff.org/deeplinks/2025/02/uks-demands-apple-break-encryption-emergency-us-all"><span>since the last time</span></a><span> they demanded this is that the order is allegedly limited to only apply to British users. That doesn’t make it any better.</span></p>
<p><span>The demand uses a power called a “Technical Capability Notice” (TCN) in the U.K.’s Investigatory Powers Act. </span><a href="https://www.eff.org/deeplinks/2016/02/investigatory-powers-bill-and-apple"><span>At the time of its signing</span></a><span> we noted this law would likely be used to demand Apple spy on its users. <br></span></p>
<p><span>After the U.K. government first issued the TCN in January, </span><a href="https://www.eff.org/deeplinks/2025/02/cornered-uks-demand-encryption-backdoor-apple-turns-its-strongest-security-setting"><span>Apple was forced</span></a><span> to either create a backdoor or block its </span><a href="https://ssd.eff.org/module/how-encrypt-your-iphone"><span>Advanced Data Protection</span></a><span> feature—which turns on end-to-end encryption for iCloud—for all U.K. users. The company decided to remove the feature in the U.K. instead of creating the backdoor.</span></p>
<p><span>The initial order from January targeted the data of </span><i><span>all</span></i><span> Apple users. In August, the </span><a href="https://www.reuters.com/sustainability/boards-policy-regulation/us-spy-chief-gabbard-says-uk-agreed-drop-backdoor-mandate-apple-2025-08-19/"><span>US claimed the U.K. withdrew the demand</span></a><span>, but Apple did not re-enable Advanced Data Protection. The new order provides insight into why: the U.K. was just rewriting it to only apply to British users. <br></span></p>
<p><span>This is still an unsettling overreach that makes U.K. users less safe and less free. As we’ve said</span><a href="https://www.eff.org/deeplinks/2015/04/clipper-chips-birthday-looking-back-22-years-key-escrow-failures"> <span>time</span></a><span> and</span><a href="https://www.eff.org/deeplinks/2019/11/why-adding-client-side-scanning-breaks-end-end-encryption"> <span>time again</span></a><span>,</span><a href="https://www.eff.org/deeplinks/2024/10/salt-typhoon-hack-shows-theres-no-security-backdoor-thats-only-good-guys"> <span>any backdoor built for the government</span></a><span> puts everyone at greater risk of hacking, identity theft, and fraud. It sets a dangerous precedent to demand similar data from other companies, and provides a runway for other authoritarian governments to issue comparable orders. The news of continued server-side access to users' data comes just days after the UK government announced an </span><a href="https://www.openrightsgroup.org/press-releases/id-cards-uk-risks-sleeping-walking-into-pre-crime-state/"><span>intrusive mandatory digital ID scheme</span></a><span>, framed as a measure against illegal migration.</span></p>
<p><span>A tribunal hearing was initially set to </span><a href="https://www.bbc.com/news/articles/c740r0m4mzjo"><span>take place in January 2026</span></a><span>, though it’s currently unclear if that will proceed or if the new order changes the legal process. Apple must continue to refuse these types of backdoors. Breaking end-to-end encryption for one country breaks it for everyone. These repeated attempts to weaken encryption violates</span><a href="https://www.eff.org/deeplinks/2024/03/european-court-human-rights-confirms-undermining-encryption-violates-fundamental"> <span>fundamental human rights</span></a><span> and destroys our right to private spaces.</span></p>

</div>

          </article>
    </div>
<div>
          <h2>Related Issues</h2>
            </div>

<div>
          <h2>Join EFF Lists</h2>
        
    </div>
<div>
          <h2>Related Updates</h2>
        <div>
        
  <div>
    <article role="article">
      <header>
                    <h3><a href="https://www.eff.org/deeplinks/2025/09/what-whatsapps-advanced-chat-privacy-really-does" rel="bookmark">What WhatsApp’s “Advanced Chat Privacy” Really Does</a></h3>
            
    </header>
  
  
  <div><p>In April, WhatsApp launched its “Advanced Chat Privacy” feature, which, once enabled, disables using certain AI features in chats and prevents conversations from being exported. Since its launch, an inaccurate viral post has been ping-ponging around social networks, creating confusion around what exactly it does.</p></div>

          </article>
  </div>
  <div>
    <article role="article">
      <header>
                    <h3><a href="https://www.eff.org/deeplinks/2025/07/radio-hobbyists-rejoice-good-news-lora-mesh" rel="bookmark">Radio Hobbyists, Rejoice! Good News for LoRa &amp; Mesh</a></h3>
            
    </header>
  
  
  <div><p>A set of radio devices and technologies are opening the doorway to new and revolutionary forms of communication. These have the potential to break down the over-reliance on traditional network hierarchies, and present collaborative alternatives where resistance to censorship, control and surveillance are baked into the network topography itself.</p></div>

          </article>
  </div>
  <div>
    <article role="article">
      <header>
                    <h3><a href="https://www.eff.org/deeplinks/2025/06/how-cops-can-get-your-private-online-data" rel="bookmark">How Cops Can Get Your Private Online Data</a></h3>
            
    </header>
  
  
  <div><p>Can the cops get your online data? In short, yes. There are a variety of US federal and state laws which give law enforcement powers to obtain information that you provided to online services. But, there are steps you as a user and/or as a service provider can take to...</p></div>

          </article>
  </div>
  
  <div>
    <article role="article">
      <header>
                    <h3><a href="https://www.eff.org/deeplinks/2025/06/podcast-episode-securing-journalism-data-greedy-internet" rel="bookmark">Podcast Episode: Securing Journalism on the ‘Data-Greedy’ Internet</a></h3>
            
    </header>
  
  
  <div><p>Public-interest journalism speaks truth to power, so protecting press freedom is part of protecting democracy. But what does it take to digitally secure journalists’ work in an environment where critics, hackers, oppressive regimes, and others seem to have the free press in their crosshairs? <i><a href="https://open.spotify.com/show/4UAplFpPDqE4hWlwsjplgt" target="_blank" rel="noopener noreferrer"></a> <a></a></i>...</p></div>

          </article>
  </div>
  
  
  <div>
    <article role="article">
      <header>
                    <h3><a href="https://www.eff.org/deeplinks/2025/05/back-it-back-it-let-us-begin-explain-encrypted-chat-backups" rel="bookmark">How Signal, WhatsApp, Apple, and Google Handle Encrypted Chat Backups</a></h3>
            
    </header>
  
  
  <div><p>Encrypted chat apps like Signal and WhatsApp are one of the best ways to keep your digital conversations as private as possible. But if you’re not careful with how those conversations are backed up, you can accidentally undermine your privacy. When a conversation is properly encrypted end-to-end, it means that...</p></div>

          </article>
  </div>
  
    </div>    </div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft 365 Copilot's commercial failure (140 pts)]]></title>
            <link>https://www.perspectives.plus/p/microsoft-365-copilot-commercial-failure</link>
            <guid>45476045</guid>
            <pubDate>Sat, 04 Oct 2025 19:39:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.perspectives.plus/p/microsoft-365-copilot-commercial-failure">https://www.perspectives.plus/p/microsoft-365-copilot-commercial-failure</a>, See on <a href="https://news.ycombinator.com/item?id=45476045">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-blocks"><p><span>The numbers are in: </span><span><strong>no one is paying for Microsoft 365 Copilot</strong></span><span>.</span></p><p><span>No, not the official numbers designed by Microsoft to </span><span><a href="https://www.perspectives.plus/p/numbers-designed-to-please" target="_blank" rel="">support their narrative</a></span><span>. I’m talking about something that MS would prefer not to address as these numbers tell a whole different story. As a result, they are from a source that we cannot verify and therefore something that every reader needs to evaluate the trustworthiness of.</span></p><div translations="[object Object]" homepath="/" loginpath="/login" subscribepath="/subscribe"><p>❝</p><p><span><em>“A source that has seen materials related to sales has confirmed that, as of August 2025, Microsoft has around </em></span><span><em><strong>eight million active licensed users of Microsoft 365 Copilot</strong></em></span><span><em>, amounting to a 1.81% conversion rate across the 440 million Microsoft 365 subscribers.”</em></span></p></div><p><span>I know, Ed Zitron is hardly a neutral observer of the tech industry. He is doing something that almost no one else out there bothers to do, though. Which is checking whether the numbers released by tech vendors (especially OpenAI) make any sense. This is the foundation upon which his case against the financial validity of GenAI is built on, and being a regular reader of his premium newsletter issues, I find it fairly convincing.</span></p><p><span>So, when someone on the inside wants to find a channel to bring out the inconvenient truth about AI adoption, Ed is where they would likely reach out to. These numbers that have been disclosed about Microsoft’s commercial success (failure) of selling Copilot licenses are in line with those reported about the adoption rate of other paid AI plans from other vendors.</span></p><p><span>The story can be summarized as follows:</span></p><p><span>M365 Copilot became available for enterprise customers to purchase on November 1st, 2023. That was almost 2 years ago. Now, if we assume that the adoption rate is constant, the conversion rate mentioned by Ed could grow to around 2% by the time we reach November 2025.</span></p><p><span><strong>The 2% adoption rate in 2 years is diabolically bad.</strong></span><span> This is not just any lil’ Power Apps product that was promoted as a new tool for citizen developers to improve personal productivity. It has been the centerpiece of everything Microsoft has done and talked about for over 2 years now. I have never seen a bigger push for any MS product.</span></p><p><span>After all this — what do we even have here? 8 million active licensed users. For some tech products that might be a sizeable user base. But let’s be real here: Microsoft has at least 400,000 channel partners. If each partner org would have bought on average 20 seats of Microsoft 365 Copilot for their employees, that would already make up the 8M figure.</span></p><p><span>Indeed, most partners have to pay for the M365 Copilot seats. There are hardly any freebies available in the partner benefits packages. I pay €800 a year for MS licenses in </span><span><a href="https://learn.microsoft.com/en-us/partner-center/membership/partner-success-core-benefits" target="_blank" rel="">Partner Success Core</a></span><span> and that doesn’t give me a single M365 Copilot seat. I have to pay the full price of €337 per year to get a chance to use the premium Copilot experience in my tenant for my solopreneur </span><span><a href="https://niiranenadvisory.com/" target="_blank" rel="">Power Platform advisory business</a></span><span>.</span></p><div><p><a target="_blank" href="https://niiranenadvisory.com/"><img src="https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,quality=80,format=auto,onerror=redirect/uploads/asset/file/1048e07d-ae52-43b3-b9f0-f0a89a45f137/Need_more_than_Perspectives.png" alt=""></a></p></div><p><span>This, of course, makes it easier to evaluate whether I get value from the license or not. While I acknowledge that I’m not the typical user persona for M365 Copilot, it has given me just a fraction of the value that my ChatGPT Plus subscription does. At a lower price point. Since I don’t have to sell and promote this product to customers, like many MS partners do, I’m free to tell everyone about this experience. As I’ve done in this newsletter for the past year on many, many occasions.</span></p><p><span>It could have been just me who’s a cranky old CRM consultant shouting at the AI cloud. Well, based on these adoption numbers for Microsoft 365 Copilot, I’m not in the minority. </span><span><strong>The vast majority of people out there who use Microsoft cloud tools don’t see Copilot as giving them enough value to justify the $30 per month cost.</strong></span></p><p><span>Remember: even though these aren’t individual users buying things for themselves, we’re not talking about just another MS license. This is AI! It’s the thing that’s </span><span><em>“no longer optional”</em></span><span> at so many companies — thanks to all the AI CEOs forcing their employees to adopt it or else. We read about these initiatives from media of how business leaders want to transform their company via AI on a daily basis.</span></p><p><span>There must be loads of companies who have gone and ticked the AI box by choosing to purchase M365 Copilot licenses. And despite all this blind support from management, this is as far as Microsoft has gotten with the paid Copilot product sales.</span></p><p id="agents-arent-doing-any-better"><h2 translations="[object Object]" homepath="/" loginpath="/login" subscribepath="/subscribe"><span>Agents aren’t doing any better</span></h2></p><p><span>Another interesting figure from Ed’s newsletter was about SharePoint agents:</span></p><div translations="[object Object]" homepath="/" loginpath="/login" subscribepath="/subscribe"><p>❝</p><p><span><span><em>“I’m also hearing that less than SharePoint — another popular enterprise app from Microsoft with 250 million users — had less than 300,000 weekly active users of its AI copilot features in August.”</em></span></span></p></div><p><span>Hmm, let’s see now. What other numbers do we have of agents that we could compare this with? Oh, right! The 3 million agents in FY25 story. Let’s revisit a screenshot I shared in my </span><span><a href="https://www.perspectives.plus/p/numbers-designed-to-please" target="_blank" rel="">Numbers designed to please</a></span><span> article a couple of months ago:</span></p><div><p><img src="https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,quality=80,format=auto,onerror=redirect/uploads/asset/file/d3ff173e-686b-4c23-bd8b-d57c9561ef38/3_million_agents_Jeff_Teper.png" alt=""></p></div><p><span>My theory (as well as Suhail’s) was that most of the 3M agents would be in SharePoint, and they wouldn’t be in production use. Weekly usage could well be considered a threshold for an AI agent being in production, so that would give us 10% when comparing it to the 300k figure in Ed’s newsletter.</span></p><p><span>But that was about </span><span><strong>users</strong></span><span>. Unlike Copilot, which is supposed to be a personal AI assistant, agents are meant to be tools that many individuals tap into with their Copilot. Now, let’s ignore for a moment the crazy fact that you can’t use SharePoint agents in the Microsoft 365 Copilot UI. Out of the 300 million users of SharePoint Online (I don’t know why Ed said only 250M), 0.1% of them interacted with an agent during a week in August 2025. </span><span><strong>One user out of a thousand</strong></span><span>.</span></p><p><span>Can you feel the AI transformation already?</span></p><p id="where-does-microsoft-go-from-here"><h2 translations="[object Object]" homepath="/" loginpath="/login" subscribepath="/subscribe"><span>Where does Microsoft go from here?</span></h2></p><p><span>If this were a normal software product, the industry would have moved on already and invented something else to pitch to customers. In practice, it is anything but normal. GenAI is the only story left for Big Tech to tell when chasing for ever greater growth percentages. And yet the only thing growing are the capex investments.</span></p><p><span>Getting people to use AI services that they either want to (ChatGPT, all the AI coding assistants) or can’t avoid (Google search AI overviews, free Copilot features in MS products) is one thing. Making them voluntarily open their wallets and insert a credit card to purchase some of the AI magic dust is a whole different game. That’s the game where everyone has been losing so far, as no one besides NVidia or the IT consulting companies is making profits from GenAI at this point.</span></p><p><span>It’s not like all those GPUs could be left underutilized, though. The growth of especially the US economy relies on AI related activities. If they were to be removed, the </span><span><a href="https://www.perspectives.plus/p/what-bubble-oh-that-bubble" target="_blank" rel="">bubble would burst</a></span><span>. So, rolling back AI features is not an option, understandably. The only possibility is to reimagine the monetization model and hope that it works this time. And that’s exactly what Microsoft is actively pursuing.</span></p><p><span>First of all, the idea of bundling more of Copilot into the licenses customers already have is the obvious way to boost AI adoption. Which may not bring in any new money, yet will be a critical number for MS to show to investors. Who could soon begin questioning why the capex spend is necessary if the </span><span><a href="https://www.wheresyoured.at/the-case-against-generative-ai/" target="_blank" rel="">GPU utilization for Microsoft 365’s enterprise Copilot is barely scratching 60%</a></span><span>.</span></p><p><span>Enter Copilot Chat in </span><span><s>Office</s></span><span> Microsoft 365 apps. </span><span><a href="https://techcommunity.microsoft.com/blog/microsoft365copilotblog/copilot-chat-comes-to-the-microsoft-365-apps/4453349" target="_blank" rel="">Announced on September 15</a></span><span>, </span><span><em>“Microsoft 365 Copilot Chat and agents are rolling out in Word, Excel, PowerPoint, Outlook, and OneNote for all users—creating a unified chat experience across the apps millions of people use every day at work.”</em></span><span> What was once the main demo scenario of why contextual AI inside the business productivity apps is crucial for worker productivity is now something all 440 million M365 users get for no extra cost.</span></p><div><p><a target="_blank" href="https://techcommunity.microsoft.com/blog/microsoft365copilotblog/copilot-chat-comes-to-the-microsoft-365-apps/4453349"><img src="https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,quality=80,format=auto,onerror=redirect/uploads/asset/file/684046c9-fc2e-400f-8199-71f2bb2cc742/Copilot_Chat_in_Microsoft_365_apps.png" alt=""></a></p><p><small><p><span>Copilot Chat pane in Outlook, PowerPoint, Excel, Word. For everyone.</span></p></small></p></div><p><span>The nice side effect from this replacement of app specific Copilots with the generic Chat has been that premium M365 Copilot users seem to have lost all of the smarts that their apps used to have. Even M365 Copilot MVPs on social media are </span><span><a href="https://www.linkedin.com/posts/tanjawiehoff_ive-never-been-this-anxious-about-an-update-activity-7378303781899231232-XAPX?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAACGJiIBcJyHulqayo1QpVEwM3vEkTAqHFg" target="_blank" rel="">anxious about the update</a></span><span> that makes Copilot responses dumber by default. I of course raised my concerns about the same useless AI assistants issue </span><span><a href="https://www.perspectives.plus/p/assistants-without-hands" target="_blank" rel="">a couple of months ago already</a></span><span>. I’m glad it’s not just me who is too dumb to get Copilot in Outlook to work with email and calendar.</span></p><p><span>Then, there’s the next push: </span><span><a href="https://www.microsoft.com/en-us/microsoft-365/blog/2025/09/29/vibe-working-introducing-agent-mode-and-office-agent-in-microsoft-365-copilot/" target="_blank" rel="">vibe working</a></span><span>. What has been disguised as a marketing campaign to ride on the popularity of the vibe coding concept is actually an indirect admittance of the fact that GPT based M365 Copilot has been a disappointment for everyone. That’s why Microsoft is now teaming up with OpenAI’s biggest competitor Anthropic and building its new Office Agent features on top of Claude:</span></p><div translations="[object Object]" homepath="/" loginpath="/login" subscribepath="/subscribe"><p>❝</p><p><span><em>“Today we’re introducing Office Agent, a multi-agent system that builds upon an open-source stack, </em></span><span><em><strong>Anthropic's Claude model</strong></em></span><span><em>, and a new taste-driven development (TDD) paradigm to deliver polished PowerPoint presentations, ready-to-use Word documents, and soon Excel spreadsheets.”</em></span></p></div><p><span>All of that is preview stuff, of course. When MS announced they were </span><span><a href="https://www.microsoft.com/en-us/microsoft-365/blog/2025/09/24/expanding-model-choice-in-microsoft-365-copilot/" target="_blank" rel="">expanding model choice in M365 Copilot and Copilot Studio</a></span><span>, all the Modern Work consultants on LinkedIn were quick to point out that enabling Claude breaks the MS trust barrier for customer data. Well, tech industry reporters have been talking about how Charles Lamanna &amp; crew are embracing Claude for a while now, so I see it as only a matter of time before models like the new </span><span><a href="https://www.microsoft.com/en-us/microsoft-copilot/blog/copilot-studio/available-today-claude-sonnet-4-5-in-microsoft-copilot-studio/" target="_blank" rel="">Claude Sonnet 4.5</a></span><span> are running on Azure in addition to AWS. Because otherwise the Office Agent won’t be as good with spreadsheets and docs like competing products that tap into the best LLM for the job.</span></p><p><span>How good is Office Agent then? Well, I did a quick test drive of the </span><span><a href="https://techcommunity.microsoft.com/blog/excelblog/building-agent-mode-in-excel/4457320" target="_blank" rel="">Agent Mode in Excel</a></span><span>. Meaning, I installed the </span><span><a href="https://support.microsoft.com/en-us/office/agent-mode-in-excel-frontier-a2fd6fe4-97ac-416b-b89a-22f4d1357c7a" target="_blank" rel="">Excel Labs add-in</a></span><span> that seems to </span><span><strong>not</strong></span><span> require any Frontier program sign-up, contrary to what MS documentation says (that Copilot Frontier switch was erroring out in M365 Admin center for me, so I said </span><span><em>“f*** this”</em></span><span> and tried the tools without it). Then, I gave it a task: </span><span><em>“build me a 5-year investor-ready financial model for a SaaS startup.”</em></span><span> Like a user of our </span><span><a href="https://www.finmodeler.com/" target="_blank" rel="">FinModeler SaaS app</a></span><span> might do.</span></p><p><span>What was the result? 12 minutes of work, timing out after endless verifications and “finalizing” steps. Some numbers and formulas were added to the Excel workbook, sure. Would I trust this to be the type of financial model that I’d use in finding investors for my business? Hell no. So, it’s definitely a “vibes” kind of an LLM output that looks neat but you can’t build on top of.</span></p><div><p><iframe width="100%" height="100%" src="https://youtube.com/embed/Bv1vOx1wCMw" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" title="Youtube embed"></iframe></p></div><p><span>The introduction of all these agents that are not yet part of the official M365 Copilot product yet gives an indication of the direction where Microsoft is taking their AI narrative. After </span><span><a href="https://www.perspectives.plus/p/use-the-forced-copilot" target="_blank" rel="">forcing consumers to pay for Copilot</a></span><span>, redirecting the </span><span><a href="https://www.perspectives.plus/p/i-created-a-better-office-com" target="_blank" rel="">Office home page</a></span><span> to AI chat instead, and making Copilot a toxic brand along the way, now’s the time to double down on agents. </span><span><em>“Oh, Copilot, yeah that’s just the UI for AI, but to do anything useful with it you’ll need the latest agents.”</em></span></p><p><span>That would be perfectly in line with the upcoming </span><span><a href="https://www.perspectives.plus/p/who-is-microsoft-agent-365" target="_blank" rel="">Microsoft 365 Agent product announcement</a></span><span> that’s supposed to take place at Ignite 2025. Given how quickly things change in the MS AI roulette table, it might of course not arrive in the format that Charles Lamanna was telling in the internal memo in August. But one thing that I’m increasingly confident of is that </span><span><strong>we will see a per-agent monetization model emerge</strong></span><span>. Simply because the per user M365 Copilot commercial model has failed so dramatically.</span></p><p><span>The latest announcement of </span><span><strong><em>“Bring Your Own Copilot”</em></strong></span><span> model with the new personal and family </span><span><a href="https://www.microsoft.com/en-us/microsoft-365/blog/2025/10/01/meet-microsoft-365-premium-your-ai-and-productivity-powerhouse/" target="_blank" rel="">Microsoft 365 Premium SKU</a></span><span> is </span><span><u><strong>not</strong></u></span><span> a sign of the premium value of Copilot. On the contrary, the basic AI features in Office apps are now such a commodity that MS is simply creating a new model to allow individual employees to sneak in a paid Copilot license via their personal MS account into work context inside M365 tenants. Since only 2% of the workers had premium Copilot licenses anyway, getting a bigger audience opening the AI tools through any means necessary is now on the table.</span></p><p><span>And so we get the “BYOAI” model, something that will irritate every single enterprise IT admin, of course. But the thing is: a personal M365 Premium won’t unlock any of the premium features like MS Graph grounding for Copilot. Which should lead everyone to asking: “what exactly is premium anymore”? The answers from </span><span><a href="https://techcommunity.microsoft.com/blog/microsoft365copilotblog/employees-can-bring-copilot-from-their-personal-microsoft-365-plans-to-work---wh/4458212" target="_blank" rel="">this blog post</a></span><span> aren’t very detailed nor convincing:</span></p><div translations="[object Object]" homepath="/" loginpath="/login" subscribepath="/subscribe"><p>❝</p><p><span><strong><em>Q: What features are available with personal Copilot subscriptions?</em></strong></span><br><span><em>A: Features like Researcher, Analyst, Photos Agent, and Actions may be available depending on the subscription tier. Additionally, users have access to the many in-app Copilot features when using the Microsoft 365 apps like rewrite, summarization, or discussion insights in Word; design suggestions and narrative builder in PowerPoint; and more.</em></span></p></div><p><span><em>“Copilot Actions?”</em></span><span> You mean that Ignite 2024 keynote highlight that was deprecated and </span><span><a href="https://www.perspectives.plus/p/the-secret-life-of-copilot-scheduled-prompts" target="_blank" rel="">removed from M365 Copilot by May 2025 already</a></span><span>? Because it was a half-assed attempt at chat driven automation, yet still resulted in a Microsoft 365 environment being provisioned for users of </span><span><a href="https://www.perspectives.plus/p/the-secret-life-of-copilot-scheduled-prompts" target="_blank" rel="">Copilot scheduled prompts</a></span><span> today? Which now seem to be superseded with the recent </span><span><a href="https://www.linkedin.com/feed/update/urn:li:activity:7379035403468746752/" target="_blank" rel="">Flow Builder agent</a></span><span> that is actually Power Automate in disguise? Which is a product </span><span><a href="https://www.perspectives.plus/p/what-next-for-power-automate" target="_blank" rel="">waiting to get reimagined</a></span><span>, so that users wouldn’t think automation without AI was ever possible?</span></p><div><p><a target="_blank" href="https://www.linkedin.com/feed/update/urn:li:activity:7379035403468746752/"><img src="https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,quality=80,format=auto,onerror=redirect/uploads/asset/file/8f91144b-beda-41e0-9f2a-fbaaa4273d1b/Flow_Builder_environment_connections.png" alt=""></a></p><p><small><p><span>"Oh cool! Another way to create automations in M365! And now in a secret Power Platform environment you can't see in Maker portals!"</span></p></small></p></div><p><span>At this point, no one at Microsoft knows what their plan is — because they don’t have one. The masterplan of transforming becoming The Copilot Company, announced at Ignite 2023, has backfired commercially. Satya’s big bet is not working and now he is inviting </span><span><a href="https://www.theverge.com/news/789558/microsoft-ceo-commercial-judson-althoff-internal-memo" target="_blank" rel="">Judson Althoff to be the CEO of all things commercial at MS</a></span><span> while he focuses on the technical challenges of AI:</span></p><p><span>The announcement is framed as a “tectonic AI platform shift”. There isn’t any concrete context given on what specifically is not working in the current mode of operation at Microsoft, just the general notion that everyone at the company needs to do better in these unprecedented times. Aside from the key thing about Nadella making way to Althoff, it’s pretty shallow. Here’s how the internal memo ends:</span></p><div translations="[object Object]" homepath="/" loginpath="/login" subscribepath="/subscribe"><p>❝</p><p><span><em>This will also allow our engineering leaders and me to be laser focused on our highest ambition technical work—across our datacenter buildout, systems architecture, AI science, and product innovation—to lead with intensity and pace in this generational platform shift. Each one of us needs to be at our very best in terms of rapidly learning new skills, adopting new ways to work, and staying close to the metal to drive innovation across the entire stack!!</em></span></p><p><span><em>This isn’t just evolution, it’s reinvention, for each of us professionally and for Microsoft.</em></span></p><p><span><em>Satya</em></span></p></div><p><span>See that </span><span><em>“this isn’t X, it’s Y”</em></span><span> part there? Yup, that’s classic GPT writing. In practice, Satya Nadella isn’t even writing these announcements that are sent to all MS employees anymore. It’s all just AI talk. If would be much more honest if the memo would have been signed by Copilot instead.</span></p><p><span>While we wait for it to be reimagined as the CEO Agent, with Copilot as the UI for it, of course.</span></p><p id="this-is-not-a-failure"><h2 translations="[object Object]" homepath="/" loginpath="/login" subscribepath="/subscribe"><span>“This is not a failure!”</span></h2></p><p><span>After posting this newsletter issue </span><span><a href="https://www.linkedin.com/feed/update/urn:li:activity:7379462621902757889/" target="_blank" rel="">on LinkedIn</a></span><span>, I got a lot of comments from Microsoft partners who disagreed with my interpretation of what the 8 million figure means. Hardly a surprise, given how much the business success of people selling and consulting M365 Copilot depends on the product being seen as something desirable.</span></p><p><span>I’m not saying all is lost for MS. My main point is that whatever they tried to pull off with the $30pupm M365 Copilot license backfired dramatically. Redmond will eventually “reimagine” things in a way that will let them put this failure behind them without ever actually addressing it. But we, the people working with Microsoft tech every day, deserve to know what happened and remember it the next time a similar stunt is played.</span></p><p><span>To illustrate my point, and give it a perspective that’s not just “my opinion with no facts whatsoever” (as some people on the professional network said), I asked Claude Sonnet 4.5 to crunch the same numbers. To do an analysis of the news sources and factors at play with M365 Copilot as a commercial offering, then evaluating whether it was </span><span><a href="https://jukka.short.gy/M365cop" target="_blank" rel="">success or spin</a></span><span>:</span></p><div><p><img src="https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,quality=80,format=auto,onerror=redirect/uploads/asset/file/9d1c611c-3d36-4c18-ad6c-9008bb96b3a7/M365_Success_or_Spin.png" alt=""></p></div><p><span>You can </span><span><a href="https://jukka.short.gy/M365cop" target="_blank" rel="">open the interactive Claude artifact</a></span><span> yourself and answer a few questions in the quiz to see how your interpretation of Microsoft 365 Copilot commercial success aligns with what Claude thinks. It’s just a fun vibe coded thing, not to be taken too seriously, of course. Here’s my quick intro </span><span><a href="https://www.youtube.com/watch?v=0gP1lq8mk78" target="_blank" rel="">video</a></span><span> of it:</span></p><div><p><iframe width="100%" height="100%" src="https://youtube.com/embed/0gP1lq8mk78" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" title="Youtube embed"></iframe></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Blog Feeds (153 pts)]]></title>
            <link>https://blogfeeds.net</link>
            <guid>45475808</guid>
            <pubDate>Sat, 04 Oct 2025 19:08:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blogfeeds.net">https://blogfeeds.net</a>, See on <a href="https://news.ycombinator.com/item?id=45475808">Hacker News</a></p>
Couldn't get https://blogfeeds.net: Error: getaddrinfo ENOTFOUND blogfeeds.net]]></description>
        </item>
        <item>
            <title><![CDATA[ProofOfThought: LLM-based reasoning using Z3 theorem proving (251 pts)]]></title>
            <link>https://github.com/DebarghaG/proofofthought</link>
            <guid>45475529</guid>
            <pubDate>Sat, 04 Oct 2025 18:34:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/DebarghaG/proofofthought">https://github.com/DebarghaG/proofofthought</a>, See on <a href="https://news.ycombinator.com/item?id=45475529">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">ProofOfThought</h2><a id="user-content-proofofthought" aria-label="Permalink: ProofOfThought" href="#proofofthought"></a></p>
<p dir="auto">LLM-based reasoning using Z3 theorem proving.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="from openai import OpenAI
from z3dsl.reasoning import ProofOfThought

client = OpenAI(api_key=&quot;...&quot;)
pot = ProofOfThought(llm_client=client)

result = pot.query(&quot;Would Nancy Pelosi publicly denounce abortion?&quot;)
print(result.answer)  # False"><pre><span>from</span> <span>openai</span> <span>import</span> <span>OpenAI</span>
<span>from</span> <span>z3dsl</span>.<span>reasoning</span> <span>import</span> <span>ProofOfThought</span>

<span>client</span> <span>=</span> <span>OpenAI</span>(<span>api_key</span><span>=</span><span>"..."</span>)
<span>pot</span> <span>=</span> <span>ProofOfThought</span>(<span>llm_client</span><span>=</span><span>client</span>)

<span>result</span> <span>=</span> <span>pot</span>.<span>query</span>(<span>"Would Nancy Pelosi publicly denounce abortion?"</span>)
<span>print</span>(<span>result</span>.<span>answer</span>)  <span># False</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Batch Evaluation</h2><a id="user-content-batch-evaluation" aria-label="Permalink: Batch Evaluation" href="#batch-evaluation"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="from z3dsl.reasoning import EvaluationPipeline

evaluator = EvaluationPipeline(pot, output_dir=&quot;results/&quot;)
result = evaluator.evaluate(
    dataset=&quot;strategyqa_train.json&quot;,
    max_samples=10
)
print(f&quot;Accuracy: {result.metrics.accuracy:.2%}&quot;)"><pre><span>from</span> <span>z3dsl</span>.<span>reasoning</span> <span>import</span> <span>EvaluationPipeline</span>

<span>evaluator</span> <span>=</span> <span>EvaluationPipeline</span>(<span>pot</span>, <span>output_dir</span><span>=</span><span>"results/"</span>)
<span>result</span> <span>=</span> <span>evaluator</span>.<span>evaluate</span>(
    <span>dataset</span><span>=</span><span>"strategyqa_train.json"</span>,
    <span>max_samples</span><span>=</span><span>10</span>
)
<span>print</span>(<span>f"Accuracy: <span><span>{</span><span>result</span>.<span>metrics</span>.<span>accuracy</span>:.2%<span>}</span></span>"</span>)</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install z3-solver openai scikit-learn numpy"><pre>pip install z3-solver openai scikit-learn numpy</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Architecture</h2><a id="user-content-architecture" aria-label="Permalink: Architecture" href="#architecture"></a></p>
<p dir="auto">The system has two layers:</p>
<ol dir="auto">
<li><strong>High-level API</strong> (<code>z3dsl.reasoning</code>) - Simple Python interface for reasoning tasks</li>
<li><strong>Low-level DSL</strong> (<code>z3dsl</code>) - JSON-based Z3 theorem prover interface</li>
</ol>
<p dir="auto">Most users should use the high-level API.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<p dir="auto">See <code>examples/</code> directory for complete examples including Azure OpenAI support.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Privacy Harm Is Harm (108 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2025/10/privacy-harm-harm</link>
            <guid>45474441</guid>
            <pubDate>Sat, 04 Oct 2025 16:19:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2025/10/privacy-harm-harm">https://www.eff.org/deeplinks/2025/10/privacy-harm-harm</a>, See on <a href="https://news.ycombinator.com/item?id=45474441">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div><p>Every day, corporations track our movements through license plate scanners, building detailed profiles of where we go, when we go there, and who we visit. When they do this to us in violation of data privacy laws, we’ve suffered a real harm—period. We shouldn’t need to prove we’ve suffered additional damage, such as physical injury or monetary loss, to have our day in court.</p>
<p>That's why EFF is proud to join an <a href="https://www.eff.org/document/2025-09-25-mata-v-dnr-amicus-br-aclu-eff-etc">amicus brief</a> in <a href="https://www.techspot.com/news/102042-texas-company-violated-privacy-millions-california-drivers-claims.html"><em>Mata v. Digital Recognition Network</em></a>, a lawsuit by drivers against a corporation that allegedly violated a California <a href="https://leginfo.legislature.ca.gov/faces/codes_displayText.xhtml?lawCode=CIV&amp;division=3.&amp;title=1.81.23.&amp;part=4.&amp;chapter=&amp;article=">statute</a> that regulates Automatic License Plate Readers (<a href="https://sls.eff.org/technologies/automated-license-plate-readers-alprs">ALPRs</a>). The state trial court erroneously dismissed the case, by misinterpreting this data privacy law to require proof of extra harm beyond privacy harm. The brief was written by the <a href="https://www.aclunc.org/home">ACLU of Northern California</a>, Stanford’s <a href="https://law.stanford.edu/juelsgaard-intellectual-property-and-innovation-clinic/">Juelsgaard Clinic</a>, and UC Law SF’s <a href="https://www.uclawsf.edu/center-for-constitutional-democracy/">Center for Constitutional Democracy</a>.</p>
<p>The amicus brief explains:</p>
<blockquote><p>This case implicates critical questions about whether a California privacy law, enacted to protect people from harmful surveillance, is not just words on paper, but can be an effective tool for people to protect their rights and safety.</p>
<p>California’s Constitution and laws empower people to challenge harmful surveillance at its inception without waiting for its repercussions to manifest through additional harms. A foundation for these protections is article I, section 1, which grants Californians an inalienable right to privacy.</p>
<p>People in the state have long used this constitutional right to challenge the privacy-invading collection of information by private and governmental parties, not only harms that are financial, mental, or physical. Indeed, widely understood notions of privacy harm, as well as references to harm in the California Code, also demonstrate that term’s expansive meaning.</p>
</blockquote>
<h4>What’s At Stake</h4>
<p>The defendant, Digital Recognition Network, also known as <a href="https://drndata.com/">DRN Data</a>, is a subsidiary of Motorola Solutions that provides access to a massive searchable database of ALPR data collected by private contractors. Its customers include law enforcement agencies and private companies, such as insurers, lenders, and repossession firms. DRN is the sister company to the infamous surveillance vendor <a href="https://drndata.com/blog/vigilant-solutions-bolsters-commercial-lpr-database-agreement-plate-locate/">Vigilant Solutions</a> (now Motorola Solutions), and together they have <a href="https://www.sfgate.com/bayarea/article/ICE-to-see-car-locations-through-Bay-Area-12529140.php">provided data to ICE</a> through a contract with <a href="https://www.aclunc.org/docs/DOCS_031319.pdf">Thomson Reuters</a>.</p>
<p>The consequences of weak privacy protections are already playing out across the country. This year alone, authorities in multiple states have used license plate readers to hunt for <a href="https://www.eff.org/deeplinks/2025/05/she-got-abortion-so-texas-cop-used-83000-cameras-track-her-down">people seeking reproductive healthcare</a>. Police officers have used these systems to <a href="https://local12.com/news/nation-world/police-chief-gets-caught-using-license-plate-cameras-to-track-his-ex-girlfriend-228-times-arrests-charges-probation-flock-safety-follow-stalk-new-boyfriend-broke-up-out-of-town-misuse">stalk romantic partners</a> and <a href="https://www.404media.co/california-cops-investigate-immigration-protest-with-ai-camera-system/">monitor political activists</a>. ICE has tapped into these networks to <a href="https://www.404media.co/ice-taps-into-nationwide-ai-enabled-camera-network-data-shows/">track down immigrants</a> and their families for deportation.</p>
<h4>Strong Privacy Laws</h4>
<p>This case could determine whether privacy laws have real teeth or are just words on paper. If corporations can collect your personal information with impunity—knowing that unless you can prove bodily injury or economic loss, you can’t fight back—then privacy laws lose value.</p>
<p>We need <a href="https://www.eff.org/wp/privacy-first-better-way-address-online-harms">strong data privacy laws</a>. We need a <a href="https://www.eff.org/deeplinks/2019/01/you-should-have-right-sue-companies-violate-your-privacy">private right of action</a> so when a company violates our data privacy rights, we can sue them. We need a broad definition of “harm,” so we can sue over our lost privacy rights, without having to prove collateral injury. EFF wages this battle when <a href="https://www.eff.org/deeplinks/2022/07/americans-deserve-more-current-american-data-privacy-protection-act">writing privacy laws</a>, when <a href="https://www.eff.org/deeplinks/2019/01/victory-illinois-supreme-court-protects-biometric-privacy">interpreting those laws</a>, and when asserting “standing” in <a href="https://www.eff.org/deeplinks/2025/04/our-privacy-act-lawsuit-against-doge-and-opm-why-judge-let-it-move-forward">federal</a> and <a href="https://www.eff.org/deeplinks/2022/12/california-courts-must-protect-data-privacy">state</a> courts.</p>
<p>The fight for privacy isn’t just about legal technicalities. It’s about preserving your right to move through the world without being constantly tracked, catalogued, and profiled by corporations looking to profit from your personal information.</p>
<p>You can read the amicus brief <a href="https://www.eff.org/document/2025-09-25-mata-v-dnr-amicus-br-aclu-eff-etc">here</a>.</p>

</div>

          </article>
    </div><div>
          <h2>Join EFF Lists</h2>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Comparison of Ada and Rust, Using Solutions to the Advent of Code (227 pts)]]></title>
            <link>https://github.com/johnperry-math/AoC2023/blob/master/More_Detailed_Comparison.md</link>
            <guid>45473861</guid>
            <pubDate>Sat, 04 Oct 2025 15:10:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/johnperry-math/AoC2023/blob/master/More_Detailed_Comparison.md">https://github.com/johnperry-math/AoC2023/blob/master/More_Detailed_Comparison.md</a>, See on <a href="https://news.ycombinator.com/item?id=45473861">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      

      <div>
        <div>
            <div>

                  <ul>
                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_copilot&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_copilot_link_platform_navbar&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>
          GitHub Copilot

        </p><p>

        Write better code with AI
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_spark&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_spark_link_platform_navbar&quot;}" href="https://github.com/features/spark">
      
      <div>
        <p>
          GitHub Spark

            <span>
              New
            </span>
        </p><p>

        Build and deploy intelligent apps
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_models&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_models_link_platform_navbar&quot;}" href="https://github.com/features/models">
      
      <div>
        <p>
          GitHub Models

            <span>
              New
            </span>
        </p><p>

        Manage and compare prompts
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_advanced_security_link_platform_navbar&quot;}" href="https://github.com/security/advanced-security">
      
      <div>
        <p>
          GitHub Advanced Security

        </p><p>

        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;actions&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;actions_link_platform_navbar&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>
          Actions

        </p><p>

        Automate any workflow
      </p></div>

    
</a></li>

                  </ul>
                </div>
            <div>

                  <ul>
                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;codespaces&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;codespaces_link_platform_navbar&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>
          Codespaces

        </p><p>

        Instant dev environments
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;issues&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;issues_link_platform_navbar&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>
          Issues

        </p><p>

        Plan and track work
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_review&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_review_link_platform_navbar&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>
          Code Review

        </p><p>

        Manage code changes
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;discussions&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;discussions_link_platform_navbar&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>
          Discussions

        </p><p>

        Collaborate outside of code
      </p></div>

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_search&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_search_link_platform_navbar&quot;}" href="https://github.com/features/code-search">
      
      <div>
        <p>
          Code Search

        </p><p>

        Find more, search less
      </p></div>

    
</a></li>

                  </ul>
                </div>
            
        </div>

          <p>
            <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;view_all_features&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;view_all_features_link_platform_navbar&quot;}" href="https://github.com/features">
              View all features
              
</a>          </p>
      </div>
</li>


                <li>
      

      
</li>


                <li>
      

      <div>

                      <p><span id="resources-explore-heading">Explore</span></p><ul aria-labelledby="resources-explore-heading">
                      <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;learning_pathways&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;learning_pathways_link_resources_navbar&quot;}" href="https://resources.github.com/learn/pathways">
      Learning Pathways

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;events_amp_webinars&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;events_amp_webinars_link_resources_navbar&quot;}" href="https://github.com/resources/events">
      Events &amp; Webinars

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;ebooks_amp_whitepapers&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;ebooks_amp_whitepapers_link_resources_navbar&quot;}" href="https://github.com/resources/whitepapers">
      Ebooks &amp; Whitepapers

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;customer_stories&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;partners&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}" href="https://github.com/partners">
      Partners

    
</a></li>

                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;executive_insights&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;executive_insights_link_resources_navbar&quot;}" href="https://github.com/solutions/executive-insights">
      Executive Insights

    
</a></li>

                  </ul>
                </div>
</li>


                <li>
      

      <div>
                <div>

                  <ul>
                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_sponsors&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>
          GitHub Sponsors

        </p><p>

        Fund open source developers
      </p></div>

    
</a></li>

                  </ul>
                </div>
                <div>

                  <ul>
                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;the_readme_project&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;the_readme_project_link_open_source_navbar&quot;}" href="https://github.com/readme">
      
      <div>
        <p>
          The ReadME Project

        </p><p>

        GitHub community articles
      </p></div>

    
</a></li>

                  </ul>
                </div>
                
            </div>
</li>


                <li>
      

      <div>

                  <ul>
                      <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}" href="https://github.com/enterprise">
      
      <div>
        <p>
          Enterprise platform

        </p><p>

        AI-powered developer platform
      </p></div>

    
</a></li>

                  </ul>
                </div>
</li>


                <li>
    <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;platform&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;platform_link_global_navbar&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:johnperry-math/AoC2023" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="9mcg9mG2h3XGezkv4TG9RaK55dfvs4FdEqLyvepe3dlmIG2jkkiUVFPxlRcekZpRDb94p__IcsJ5TtCb549Wgw" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="johnperry-math/AoC2023" data-current-org="" data-current-owner="johnperry-math" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false" data-retain-scroll-position="true">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>


            

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&amp;source=header-repo&amp;source_repo=johnperry-math%2FAoC2023" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/johnperry-math/AoC2023/blob/master/More_Detailed_Comparison.md&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="eb9594398ab6b853e6036b7b7771ad681cec367e715da013d0e06b191b7707c8" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/blob/show;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a></p><p>
    <react-partial-anchor>
      <tool-tip id="tooltip-10a18724-2adc-47b6-9586-1fa17fe529b1" for="icon-button-4561da8c-2de3-4f30-8c21-bd5bcc42867a" popover="manual" data-direction="s" data-type="label" data-view-component="true">Appearance settings</tool-tip>

      <template data-target="react-partial-anchor.template">
        <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.2ceb2571848317ce36f7.module.css">
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/appearance-settings.6c63a6de228d6520804d.module.css">

<react-partial partial-name="appearance-settings" data-ssr="false" data-attempted-ssr="false" data-react-profiling="false">
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>


      </template>
    </react-partial-anchor>
  </p>

          </div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How I influence tech company politics as a staff software engineer (306 pts)]]></title>
            <link>https://www.seangoedecke.com/how-to-influence-politics/</link>
            <guid>45473852</guid>
            <pubDate>Sat, 04 Oct 2025 15:09:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.seangoedecke.com/how-to-influence-politics/">https://www.seangoedecke.com/how-to-influence-politics/</a>, See on <a href="https://news.ycombinator.com/item?id=45473852">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><header></header><section><p>Many software engineers are fatalistic about company politics. They believe that it’s pointless to get involved, because<sup id="fnref-1"><a href="#fn-1">1</a></sup>:</p>
<ul>
<li>Technical decisions are often made for <a href="https://news.ycombinator.com/item?id=45441068">completely selfish reasons</a> that cannot be influenced by a well-meaning engineer</li>
<li>Powerful stakeholders are typically <a href="https://news.ycombinator.com/item?id=45442587">so stupid and dysfunctional</a> that it’s effectively impossible for you to identify their needs and deliver solutions to them</li>
<li>The political game being played depends on private information that software engineers do not have, so any attempt to get involved will result in just blundering around</li>
<li>Managers and executives spend most of their time playing politics, while engineers spend most of their time doing engineering, so engineers are at a serious political disadvantage before they even start</li>
</ul>
<p>The general idea here is that <strong>software engineers are simply not equipped to play the game at the same level as real political operators</strong>. This is true! It would be a terrible mistake for a software engineer to think that you ought to start scheming and plotting like you’re in <em>Game of Thrones</em>. Your schemes will be immediately uncovered and repurposed to your disadvantage and other people’s gain. Scheming takes practice and power, and neither of those things are available to software engineers.</p>
<p>It is simply a fact that software engineers are tools in the political game being played at large companies, not players in their own right. However, there are many ways to get involved in politics without scheming.</p>
<p>The easiest way is to <strong>actively work to make a high-profile project successful</strong>. This is more or less what you ought to be doing anyway, just as part of your ordinary job. If your company is heavily investing in some new project - these days, likely an AI project - using your engineering skill to make it successful<sup id="fnref-2"><a href="#fn-2">2</a></sup> is a politically advantageous move for whatever VP or executive is spearheading that project. In return, you’ll get the rewards that executives can give at tech companies: bonuses, help with promotions, and positions on future high-profile projects. I wrote about this almost a year ago in <a href="https://www.seangoedecke.com/ratchet-effects"><em>Ratchet effects determine engineer reputation at large companies</em></a>.</p>
<p>A slightly harder way (but one that gives you more control) is to <strong>make your pet idea available for an existing political campaign</strong>. Suppose you’ve wanted for a while to pull out some existing functionality into its own service. There are two ways to make that happen.</p>
<p>The hard way is to expend your own political capital: drum up support, let your manager know how important it is to you, and slowly wear doubters down until you can get the project formally approved. The easy way is to <strong>allow some executive to spend their (much greater) political capital on your project</strong>. You wait until there’s a company-wide mandate for some goal that aligns with your project (say, a push for reliability, which often happens in the wake of a high-profile incident). Then you suggest to your manager that your project might be a good fit for this. If you’ve gauged it correctly, your org will get behind your project. Not only that, but it’ll increase your political capital instead of you having to spend it.</p>
<p>Organizational interest comes in waves. When it’s reliability time, VPs are desperate to be <em>doing something</em>. They want to come up with plausible-sounding reliability projects that they can fund, because they need to go to their bosses and point at what they’re doing for reliability, but they don’t have the skillset to do it on their own. They’re typically happy to fund anything that the engineering team suggests. On the other hand, when the organization’s attention is focused somewhere else - say, on a big new product ship - the last thing they want is for engineers to spend their time on an internal reliability-focused refactor that’s invisible to customers.</p>
<p>So if you want to get something technical done in a tech company, <strong>you ought to wait for the appropriate wave</strong>. It’s a good idea to prepare multiple technical programs of work, all along different lines. Strong engineers will do some of this kind of thing as an automatic process, simply by noticing things in the normal line of work. For instance, you might have rough plans:</p>
<ul>
<li>to migrate the billing code to stored-data-updated-by-webhooks instead of cached API calls</li>
<li>to rip out the ancient hand-rolled build pipeline and replace it with Vite</li>
<li>to rewrite a crufty high-volume Python service in Golang</li>
<li>to replace the slow CMS frontend that backs your public documentation with a fast static site</li>
</ul>
<p>When executives are concerned about billing, you can offer the billing refactor as a reliability improvement. When they’re concerned about developer experience, you can suggest replacing the build pipeline. When customers are complaining about performance, you can point to the Golang rewrite as a good option. When the CEO checks the state of the public documentation and is embarrassed, you can make the case for rebuilding it as a static site. <strong>The important thing is to have a detailed, effective program of work ready to go for whatever the flavor of the month is.</strong></p>
<p>Some program of work will be funded whether you do this or not. However, if you don’t do this, you have no control over what that program is. In my experience, <strong>this is where companies make their worst technical decisions</strong>: when the political need to do <em>something</em> collides with a lack of any good ideas. When there are no good ideas, a bad idea will do, in a pinch. But nobody prefers this outcome. It’s bad for the executives, who then have to sell a disappointing technical outcome as if it were a success<sup id="fnref-4"><a href="#fn-4">4</a></sup>, and it’s bad for the engineers, who have to spend their time and effort building the wrong idea.</p>
<p>If you’re a very senior engineer, the VPs (or whoever) will quietly blame you for this. They’ll be right to! <strong>Having the right idea handy at the right time is your responsibility.</strong></p>
<p>You can view all this in two different ways. Cynically, you can read this as a suggestion to make yourself a convenient tool for the sociopaths who run your company to use in their endless internecine power struggles. Optimistically, you can read this as a suggestion to let executives set the overall priorities for the company - that’s their job, after all - and to tailor your own technical plans to fit<sup id="fnref-3"><a href="#fn-3">3</a></sup>. Either way, you’ll achieve more of your technical goals if you push the right plan at the right time.</p>
</section><p>If you liked this post, consider <a href="https://buttondown.com/seangoedecke" target="_blank">subscribing</a> to email updates about my new posts, or <a href="https://news.ycombinator.com/submitlink?u=https://www.seangoedecke.com/how-to-influence-politics/&amp;t=How%20I%20influence%20tech%20company%20politics%20as%20a%20staff%20software%20engineer" target="_blank">sharing it on Hacker News</a>.</p><p>October 4, 2025<!-- -->&nbsp;│ Tags: <a href="https://www.seangoedecke.com/tags/good%20engineers/">good engineers</a>, <a href="https://www.seangoedecke.com/tags/tech%20companies/">tech companies</a></p><hr></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Self-hosting email like it's 1984 (226 pts)]]></title>
            <link>https://maxadamski.com/blog/2025/10/email.html</link>
            <guid>45473730</guid>
            <pubDate>Sat, 04 Oct 2025 14:53:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://maxadamski.com/blog/2025/10/email.html">https://maxadamski.com/blog/2025/10/email.html</a>, See on <a href="https://news.ycombinator.com/item?id=45473730">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<h2>Introduction</h2>

<p>
Self-hosting an email server is useful for automating tasks like mailing lists, newsletters, or email verification APIs.
</p>

<p>
The elephant in the room is real-world deliverability. <b>With self-hosting you risk not receiving mail or someone missing your mail.</b> I accept this for my personal projects, but you may not. Keep this in mind.
</p>

<p>
For me the selling point of self-hosting is that it’s practically free. If you’re already self-hosting a website, installing some extra packages on your server and just a bit of your time is all that’s required. Mail takes very little storage and the software is light, so you’re unlikely to significantly change energy consumption or disk usage.
</p>

<p>
For the longest time, I perceived self-hosting email as too difficult, but after doing it for one of my projects, I can say it’s not much harder or more time-consuming than configuring some email SaaS.
</p>

<p>
I changed my goals a bit to make the setup easier though. Self-hosting a multi-user webmail looks heavy and is more involved than I was willing to get into, so I just skipped it. That way, I didn’t have to bother with user accounts, databases, or the web at all, and the task became easy.
</p>

<p>
With my config, manually sending and receiving email is possible if you SSH to your mail server and use the minimal sendmail or mailx commands, or Mutt if you like TUI. The setup is enough for me now, but I could expand it in the future, and multi-user webmail isn’t off the table anyway. Maybe I’ll even write a simple webmail package myself!
</p>


<h2>Setting up Postfix</h2>

<p>
You just need to open port 25, and install and configure <a href="https://www.postfix.org/">Postfix</a> and <a href="http://www.opendkim.org/">OpenDKIM</a> on your machine. Postfix is a complete SMTP server, and is enough for basic mail alone, but in practice you also need OpenDKIM to get your mail delivered to popular services like Gmail.
</p>

<p>
Here's my Postfix config to show how easy it is. I left the master.cf file as it was, because I’m always submitting email locally. Notice there's no mention of POP3 or IMAP. I didn't set them up, because I didn't need them.
</p>

<p>
The default alias and header check config files are practically self-explanatory (just open them and read the comments!).
</p>

<details>
<summary>/etc/postfix/main.cf</summary>
<pre>compatibility_level = 3.8
mail_owner = postfix

myhostname = mx.idx.cy
myorigin = idx.cy
mydestination = localhost, idx.cy, maxadamski.com, localchat.cc
inet_interfaces = all
inet_protocols = ipv4

# Addresses
alias_maps = hash:/etc/postfix/aliases
alias_database = $alias_maps
recipient_delimiter = +

# I'm the only user on my machine, so I send from whichever address I want.
#smtpd_sender_login_maps = hash:/etc/postfix/sender_login_maps
#smtpd_sender_restrictions = reject_authenticated_sender_login_mismatch

# spam
#in_flow_delay = 1s
header_checks = regexp:/etc/postfix/header_checks
setgid_group = postdrop

# TLS (strict)
smtpd_tls_cert_file = /etc/ssl/tls/mx.idx.cy.crt
smtpd_tls_key_file = /etc/ssl/tls/mx.idx.cy.key
smtpd_tls_security_level = encrypt
smtpd_tls_mandatory_protocols = !SSLv2, !SSLv3, !TLSv1, !TLSv1.1
smtpd_tls_protocols = !SSLv2, !SSLv3, !TLSv1, !TLSv1.1
smtp_tls_security_level = encrypt
smtp_tls_mandatory_protocols = !SSLv2, !SSLv3, !TLSv1, !TLSv1.1
smtp_tls_protocols = !SSLv2, !SSLv3, !TLSv1, !TLSv1.1

# DKIM
smtpd_milters = inet:localhost:8891
non_smtpd_milters = inet:localhost:8891
milter_default_action = accept
</pre>
</details>

<h2>TLS</h2>

<p>
You will also need an SSL certificate for encryption in transit. I hate getting and renewing SSL certificates, because the tools are bulky and automation is yet another moving part in your system (I used the lego package, with the manual DNS challenge for simplicity, but I’m not too happy about it). I won’t give you a tutorial on getting SSL certificates, but note that you don’t have to get and renew a certificate for each of your custom domains!
</p>

<p>
You just need one SSL certificate for your machine to encrypt data in transit to other SMTP servers. If you create an A record mx.example.com pointing to your email machine’s IP address, then grab a free certificate for mx.example.com from Let’s Encrypt. Then point to it in the Postfix configuration, and you’ve got transport encryption! In short, only the MX hostname needs a cert for STARTTLS to be used for encryption.
</p>

<p>
Why no certificates for your actual email domains like example.com? Because the email domain has little to do with transport encryption. TLS only secures the connection between servers. You can still set whatever you want in the From header.
</p>

<h2>DKIM, SPF, and DMARC</h2>

<p>
You should prove that your emails actually come from your domain to make your mail trustworthy and deliver to Gmail and co. That’s what DKIM is for, and fortunately it’s a one-time deal per email domain. First you generate a key pair for each domain with OpenDKIM, and then you publish the public key in a TXT record in DNS. The keys don’t expire automatically, but it’s best practice to rotate them periodically. My config uses a naming scheme that allows smooth rotation, but it doesn’t complicate things if you skip it.
</p>

<p>
There are two more TXT records that you need to publish in DNS: the SPF and DMARC records. You say which hosts are allowed to send mail from your email domain, and give instructions to other email servers about what to do with mail that fails DKIM checks. In my case I told others to reject mail that can’t be verified as coming from my domains, and send reports to my postmaster address.
</p>

<p>
Take a look at my OpenDKIM config to understand how things come together.
</p>

<details>
<summary>/etc/opendkim.conf</summary>
<pre>UserID             opendkim:opendkim
Socket             inet:8891@localhost
KeyTable           refile:/etc/opendkim/KeyTable
SigningTable       refile:/etc/opendkim/SigningTable
ExternalIgnoreList refile:/etc/opendkim/TrustedHosts
InternalHosts      refile:/etc/opendkim/TrustedHosts

Canonicalization   relaxed/relaxed
ReportAddress      postmaster@idx.cy
SendReports        no

LogWhy             yes
Syslog             yes
SyslogSuccess      no
</pre>
</details>

<details>
<summary>/etc/opendkim/KeyTable</summary>
<pre>key1._domainkey.idx.cy         idx.cy:key1:/etc/opendkim/keys/idx.cy/key1.private
key1._domainkey.maxadamski.com maxadamski.com:key1:/etc/opendkim/keys/maxadamski.com/key1.private
key1._domainkey.localchat.cc   localchat.cc:key1:/etc/opendkim/keys/localchat.cc/key1.private
</pre>
</details>

<details>
<summary>/etc/opendkim/SigningTable</summary>
<pre>*@idx.cy         key1._domainkey.idx.cy
*@maxadamski.com key1._domainkey.maxadamski.com
*@localchat.cc   key1._domainkey.localchat.cc
</pre>
</details>

<details>
<summary>/etc/opendkim/TrustedHosts</summary>
<pre>127.0.0.1
localhost
</pre>
</details>

<p>
I generate DKIM keys with the following command:
</p>

<pre>opendkim-genkey -D /etc/opendkim/keys/example.com -d example.com -s key1
</pre>

<p>
And for each email domain I have the following records in DNS:
</p>

<div>
<table>
  <thead>
    <tr><th>Type</th><th>Name</th><th>Value</th></tr>
  </thead>
  <tbody>
    <tr><td>MX</td><td>example.com</td><td>mx.idx.cy</td></tr>
    <tr><td>TXT</td><td>example.com</td><td>v=spf1 mx a -all</td></tr>
    <tr><td>TXT</td><td>key1._domainkey</td><td>v=DKIM1; k=rsa; s=email; p=&lt;public-key&gt;</td></tr>
    <tr><td>TXT</td><td>_dmarc</td><td>v=DMARC1; p=reject; rua=mailto:postmaster@idx.cy</td></tr>
  </tbody>
</table>
</div>

<h2>Reverse DNS</h2>

<p>
One more thing about email trust. I've read that reverse DNS (PTR record) will boost the reputation of your email server. The thing is that your ISP has to set it up, and I suspect my ISP to reply with a polite "no", so I didn't do it yet. As you'll see in the next section, my email gets delivered to Gmail just fine. GMX and outlook.com also didn't mark my mail as spam. I also managed to sign up to reddit.com using my idx.cy email (I received the verification code without delay).
</p>

<p>
However, if you want wide deliverability, PTR isn't optional.
</p>

<h2>Testing with Gmail</h2>

<p>To try it out, let's send a test mail to Gmail with the sendmail command:</p>

<pre>sendmail -vt &lt; test.mail</pre>

<details>
<summary>test.mail</summary>
<pre>Content-Type: text/html
From: max@idx.cy
To: myaddress@gmail.com
Subject: DKIM test
Test message from idx.cy!
</pre>
</details>

<p>I got the mail instantly and Gmail confirmed TLS encryption.</p>

<img src="https://maxadamski.com/blog/2025/10/test-mail-1.png">

<p>Click "Show original" in Gmail to see the raw mail. There's lots of text in the headers, so let's just focus on passing SPF, DKIM, and DMARC :)</p>

<img src="https://maxadamski.com/blog/2025/10/test-mail-2.png">

<p>You'll also get a mail with a report because of the <tt>-v</tt> option. I receive mail with Heirloom Mail like this:</p>

<pre>You have new mail in /var/mail/max
fool ~ | mailx
Heirloom Mail version 12.5 7/5/10.  Type ? for help.
"/var/mail/max": 1 message 1 new
&gt;N  1 Mail Delivery System  Sat Oct  4 15:40  74/2437  "Mail Delivery Status Report"
</pre>

<p>I use the <tt>p</tt> command to print the mail.</p>

<details>
<summary>&amp; p</summary>
<pre>Message  1:
From MAILER-DAEMON  Sat Oct  4 15:40:50 2025
X-Original-To: max@idx.cy
Delivered-To: max@idx.cy
Date: Sat,  4 Oct 2025 15:40:50 +0200 (CEST)
From: Mail Delivery System &lt;MAILER-DAEMON@idx.cy&gt;
Subject: Mail Delivery Status Report
To: max@idx.cy
Auto-Submitted: auto-replied
Content-Type: multipart/report; report-type=delivery-status;
	boundary="3C311BFF8D.1759585250/mx.idx.cy"
Status: R

Part 1:
Content-Description: Notification
Content-Type: text/plain; charset=utf-8

This is the mail system at host mx.idx.cy.

Enclosed is the mail delivery report that you requested.

                   The mail system

&lt;myaddress@gmail.com&gt;: delivery via
    gmail-smtp-in.l.google.com[X.X.X.X]:25: 250 2.0.0 OK  1759585250
    4fb4d7f45d1cf-6393b6ba951si3187039a12.40 - gsmtp
</pre>
</details>

<p>Great, everything is working! And I'm feeling the spirit of the 80s thanks to mailx :)</p>

<p>
If something isn't working for you, please double-check your DNS records, and triple-check that TLS certificates are readable by the Postfix user, and that DKIM keys are readable by the OpenDKIM user. Postfix and OpenDKIM logs will also be useful. The OpenDKIM config file is especially unforgiving of typos, so watch out for small mistakes!
</p>

<h2>Next steps</h2>

<p>
In my next post on email, I'll show you how to use Python to build useful email applications. Thanks for reading!
</p>

<p>
Btw, if you notice anything about my config (or just want to share some thoughts) just email me at <a href="mailto:max@idx.cy">max@idx.cy</a> :)
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Flock's gunshot detection microphones will start listening for human voices (306 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2025/10/flocks-gunshot-detection-microphones-will-start-listening-human-voices</link>
            <guid>45473698</guid>
            <pubDate>Sat, 04 Oct 2025 14:49:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2025/10/flocks-gunshot-detection-microphones-will-start-listening-human-voices">https://www.eff.org/deeplinks/2025/10/flocks-gunshot-detection-microphones-will-start-listening-human-voices</a>, See on <a href="https://news.ycombinator.com/item?id=45473698">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div><p><span>Flock Safety, the police technology company most notable for their extensive network of </span><a href="https://sls.eff.org/technologies/automated-license-plate-readers-alprs"><span>automated license plate readers</span></a><span> spread throughout the United States, is rolling out a new and troubling product that may create headaches for the cities that adopt it: detection of “human distress” via audio. As part of their suite of technologies, Flock has been pushing </span><a href="https://www.flocksafety.com/webinar/introducing-raven"><span>Raven</span></a><span>, their version of </span><a href="https://sls.eff.org/technologies/gunshot-detection"><span>acoustic gunshot detection</span></a><span>. These devices capture sounds in public places and use machine learning to try to identify gunshots and then alert police—but EFF has </span><a href="https://www.eff.org/deeplinks/2021/07/its-time-police-stop-using-shotspotter"><span>long warned</span></a><span> that they are also high powered microphones parked above densely-populated city streets. Cities now have one more reason to follow the lead of </span><a href="https://www.kvue.com/article/news/local/austin-license-plate-readers-ends-privacy-concerns/269-4dc64690-c6c0-4ace-a009-fd8a13f69113"><span>many other municipalities</span></a><span> and cancel their Flock contracts, before this new feature causes civil liberties harms to residents and headaches for cities.&nbsp;</span></p>
<p><span>In marketing materials, Flock has been touting new features to their Raven product—including the ability of the device to alert police based on sounds, including “distress.” The </span><a href="https://www.flocksafety.com/distress-early-access"><span>online ad</span></a><span> for the product, which allows cities to apply for early access to the technology, shows the image of police getting an alert for “screaming.”&nbsp;</span></p>
<p><span>It’s unclear how this technology works. For acoustic gunshot detection, generally the microphones are looking for sounds that would signify gunshots (though in practice they often mistake car backfires or fireworks for gunshots). Flock needs to come forward now with an explanation of exactly how their new technology functions. It is unclear how these devices will interact with state “</span><a href="https://www.mwl-law.com/wp-content/uploads/2018/02/RECORDING-CONVERSATIONS-CHART.pdf"><span>eavesdropping</span></a><span>” laws that limit listening to or recording the private conversations that often take place in public.&nbsp;</span></p>
<p><span>Flock is no stranger to causing legal challenges for the cities and states that adopt their products. In Illinois, Flock was </span><a href="https://www.25newsnow.com/2025/08/28/hundreds-police-departments-use-camera-company-accused-breaking-state-law/"><span>accused of violating state law</span></a><span> by allowing Immigration and Customs Enforcement (ICE), a federal agency, access to license plate reader data taken within the state. That’s not all. In 2023, a North Carolina judge halted the installation of Flock cameras statewide for </span><a href="https://www.govtech.com/public-safety/north-carolina-judge-halts-alpr-deployment-over-licensing"><span>operating in the state without a license</span></a><span>. When the city of Evanston, Illinois recently canceled its contract with Flock, it ordered the company to take down their license plate readers–only for Flock to </span><a href="https://evanstonroundtable.com/2025/09/25/city-covers-up-flock-cameras-while-waiting-for-removal/"><span>mysteriously reinstall</span></a><span> them a few days later. This city has now sent Flock a cease and desist order and in the meantime, has put </span><a href="https://evanstonroundtable.com/2025/09/25/city-covers-up-flock-cameras-while-waiting-for-removal/"><span>black tape over the cameras</span></a><span>. For some, the technology isn’t worth its mounting downsides. As one </span><a href="https://derekeder.com/blog/why-i-voted-to-cancel-flock"><span>Illinois village trustee wrote </span></a><span>while explaining his vote to cancel the city’s contract with Flock, “According to our own Civilian Police Oversight Commission, over 99% of Flock alerts do not result in any police action.”</span></p>
<p><br><span>Gunshot detection technology is dangerous enough as it is—police showing up to alerts they think are gunfire only to find children playing with fireworks is a recipe for innocent people to get hurt. This isn’t hypothetical: in Chicago a </span><a href="https://www.eff.org/deeplinks/2024/03/responding-shotspotter-police-shoot-child-lighting-fireworks"><span>child really was shot at by police</span></a><span> who thought they were responding to a shooting thanks to a ShotSpotter alert. Introducing a new feature that allows these pre-installed Raven microphones all over cities to begin listening for human voices in distress is likely to open up a whole new can of unforeseen legal, civil liberties, and even bodily safety consequences. </span></p>

</div>

          </article>
    </div><div>
          <h2>Join EFF Lists</h2>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Circular Financing: Does Nvidia's $110B Bet Echo the Telecom Bubble? (215 pts)]]></title>
            <link>https://tomtunguz.com/nvidia_nortel_vendor_financing_comparison/</link>
            <guid>45473033</guid>
            <pubDate>Sat, 04 Oct 2025 13:06:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tomtunguz.com/nvidia_nortel_vendor_financing_comparison/">https://tomtunguz.com/nvidia_nortel_vendor_financing_comparison/</a>, See on <a href="https://news.ycombinator.com/item?id=45473033">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
            

            <div>
                <p>When Nvidia announced a $100 billion investment commitment to OpenAI<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> in September 2025 , analysts immediately drew comparisons to the telecom bubble. The concern : is this vendor financing , where a supplier lends money to customers so they can buy the supplier’s products , a harbinger of another spectacular collapse?</p>
<p>American tech companies will spend <strong>$300-400 billion</strong> on AI infrastructure in 2025<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup><sup>,</sup><sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> , exceeding any prior single-year corporate infrastructure investment in nominal dollars.<sup id="fnref1:3"><a href="#fn:3" role="doc-noteref">3</a></sup> David Cahn estimates the revenue gap has grown to <strong>$600 billion</strong><sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>.</p>
<p>I analyzed the numbers. The similarities are striking , but the differences matter.</p>
<h2 id="the-lucent-playbook">The Lucent Playbook</h2>
<p><a href="https://res.cloudinary.com/dzawgnnlr/image/upload/q_auto,f_auto/pt1apmgovtkb2aegncym" target="_blank"><img src="https://res.cloudinary.com/dzawgnnlr/image/upload/w_1512,h_850,c_fill,g_auto,q_auto,f_auto/pt1apmgovtkb2aegncym" alt="Lucent vs Nvidia Revenue Comparison 1996-2024" width="756" height="425" loading="lazy"></a></p>
<!--[if mso | IE]>
  </v:textbox>
</v:rect>
<![endif]-->
<p><em>Lucent’s revenue peaked at $37.92B in 1999 , crashed 69% to $11.80B by 2002 , never recovered. Merged with Alcatel in 2006.</em></p>
<p>In 1999 , Lucent Technologies reached $37.92 billion in revenue at the peak of the dot-com bubble. <sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> Lucent was the #1 North American telecommunications equipment manufacturer with 157,000 employees &amp; dominated markets alongside Nortel Networks (combined 53% optical transport market share). <sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup> Behind the scenes , equipment makers extended billions in vendor financing to telecom customers. Lucent committed <strong>$8.1B</strong><sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup> , Nortel extended $3.1B with $1.4B outstanding , &amp; Cisco promised $2.4B in customer loans.<sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup></p>
<p>The strategy seemed brilliant : lend money to cash-strapped telecom companies so they could buy your equipment. Everyone wins—until the merry-go-round stops.</p>
<p>When the bubble burst :</p>
<ul>
<li>47 Competitive Local Exchange Carriers (CLECs) bankrupted 2000-2003 , including Covad , Focal Communications , McLeod , Northpoint , Winstar <sup id="fnref:9"><a href="#fn:9" role="doc-noteref">9</a></sup><sup>,</sup><sup id="fnref:10"><a href="#fn:10" role="doc-noteref">10</a></sup>
<ul>
<li>Why they failed : $60B overbuild 1996-2001 , market saturation from identical business models , sudden funding collapse (Jan 2001 : billions available , Apr 2001 : zero)<sup id="fnref:11"><a href="#fn:11" role="doc-noteref">11</a></sup></li>
</ul>
</li>
<li>33-80% of vendor loan portfolios went uncollected as customers failed &amp; equipment became worthless<sup id="fnref:12"><a href="#fn:12" role="doc-noteref">12</a></sup></li>
<li>Fiber networks were using less than 0.002% of available capacity , with potential for 60,000x speed increases. <sup id="fnref:13"><a href="#fn:13" role="doc-noteref">13</a></sup> It was just too early.</li>
</ul>
<h2 id="nvidias-playbook">Nvidia’s Playbook</h2>
<p>Fast forward to 2025. Nvidia’s vendor financing strategy totals <strong>$110 billion in direct investments</strong> plus another <strong>$15+ billion in GPU-backed debt</strong>. The largest commitment is $100B to OpenAI (September 2025)<sup id="fnref1:1"><a href="#fn:1" role="doc-noteref">1</a></sup><sup>,</sup><sup id="fnref:14"><a href="#fn:14" role="doc-noteref">14</a></sup> , structured as 10 tranches of $10B each tied to infrastructure deployment milestones. The first $10B was valued at a $500B OpenAI valuation , with subsequent tranches priced at prevailing valuations. Payment comes via lease arrangements , not upfront GPU purchases. OpenAI CFO Sarah Friar confirmed : “Most of the money will go back to Nvidia”<sup id="fnref1:14"><a href="#fn:14" role="doc-noteref">14</a></sup></p>
<p>Beyond OpenAI , Nvidia holds a $3B stake in CoreWeave<sup id="fnref:15"><a href="#fn:15" role="doc-noteref">15</a></sup> , a company that has spent $7.5B on Nvidia GPUs , &amp; $3.7B in other AI startup investments<sup id="fnref:16"><a href="#fn:16" role="doc-noteref">16</a></sup> through NVentures.</p>
<p>The GPU-backed debt market adds another layer. CoreWeave alone carries $10.45B in debt using GPUs as collateral<sup id="fnref:17"><a href="#fn:17" role="doc-noteref">17</a></sup>. An additional $10B+ in GPU-backed debt has emerged for “Neoclouds” including Lambda Labs ($500M GPU-backed loan)<sup id="fnref:18"><a href="#fn:18" role="doc-noteref">18</a></sup><sup>,</sup><sup id="fnref:19"><a href="#fn:19" role="doc-noteref">19</a></sup>.</p>
<p>Lucent in 1999-2000 had vendor financing commitments of $8.1B (20% of $41.4B revenue). Nvidia’s direct investments total 85% of annual revenue ($110B against $130B). Nvidia’s exposure is 4x larger relative to revenue than Lucent’s official outstanding loans , though Lucent’s off-balance-sheet guarantees masked the true exposure.</p>
<h2 id="the-numbers-side-by-side-2024-dollars">The Numbers Side-by-Side (2024 Dollars)</h2>
<table>
<thead>
<tr>
<th>Metric</th>
<th>Lucent (FY2000, inflation-adj.)</th>
<th>Nvidia (2025)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vendor financing</td>
<td>$15B</td>
<td>$110B</td>
</tr>
<tr>
<td>Operating cash flow</td>
<td>$304M<sup id="fnref:20"><a href="#fn:20" role="doc-noteref">20</a></sup></td>
<td>$15.4B (Q2 FY26)</td>
</tr>
<tr>
<td>Revenue</td>
<td>$34B</td>
<td>$130B</td>
</tr>
<tr>
<td>Top 2 Customers represent</td>
<td>23%<sup id="fnref:21"><a href="#fn:21" role="doc-noteref">21</a></sup></td>
<td>39%</td>
</tr>
</tbody>
</table>
<h2 id="the-reasons-to-be-wary">The Reasons to be Wary</h2>
<h3 id="1-the-ai-customer-base-is-more-concentrated">1. The AI Customer Base is More Concentrated</h3>
<p>Lucent’s top 2 customers—AT&amp;T at 10% &amp; Verizon at 13%—accounted for 23% of revenue in FY2000.<sup id="fnref1:21"><a href="#fn:21" role="doc-noteref">21</a></sup> The Regional Bell Operating Companies , or RBOCs , the seven “Baby Bells” created from AT&amp;T’s 1984 breakup , were also major customers. Nvidia has 39% of revenue from just 2 customers &amp; 46% from 4 customers , nearly double Lucent’s concentration. 88% of Nvidia’s revenue comes from data centers.</p>
<h3 id="2-gpu-backed-debt-is-new">2. GPU-Backed Debt Is New</h3>
<p>The new $10B+ GPU-backed debt market is built on the assumption that GPUs will hold their value over 4-6 years. GPU-backed loans carry ~14% interest rates<sup id="fnref:22"><a href="#fn:22" role="doc-noteref">22</a></sup> , triple investment-grade corporate debt.<sup id="fnref:23"><a href="#fn:23" role="doc-noteref">23</a></sup></p>
<p>How Depreciation Schedules Changed :</p>
<table>
<thead>
<tr>
<th>Company</th>
<th>Pre-2020</th>
<th>2020-2021</th>
<th>2022-2023</th>
<th>2024-2025</th>
<th>Change</th>
</tr>
</thead>
<tbody>
<tr>
<td>Amazon<sup id="fnref:24"><a href="#fn:24" role="doc-noteref">24</a></sup></td>
<td>3 years</td>
<td>4 years (2020) → 5 years (2021)</td>
<td>5 years</td>
<td>6 years (2024) → 5 years (2025)</td>
<td>First reversal</td>
</tr>
<tr>
<td>Microsoft<sup id="fnref:25"><a href="#fn:25" role="doc-noteref">25</a></sup></td>
<td>~3 years</td>
<td>4 years</td>
<td>6 years</td>
<td>6 years</td>
<td>+100%</td>
</tr>
<tr>
<td>Google<sup id="fnref:26"><a href="#fn:26" role="doc-noteref">26</a></sup></td>
<td>~3 years</td>
<td>4 years</td>
<td>6 years</td>
<td>6 years</td>
<td>+100%</td>
</tr>
<tr>
<td>Meta<sup id="fnref:27"><a href="#fn:27" role="doc-noteref">27</a></sup></td>
<td>~3 years</td>
<td>4 years</td>
<td>4.5 years → 5 years</td>
<td>5.5 years</td>
<td>+83%</td>
</tr>
<tr>
<td>CoreWeave<sup id="fnref:28"><a href="#fn:28" role="doc-noteref">28</a></sup></td>
<td>N/A</td>
<td>N/A</td>
<td>4 years → 6 years (Jan 2023)</td>
<td>6 years</td>
<td>+50% (GPUs)</td>
</tr>
<tr>
<td>Nebius<sup id="fnref:29"><a href="#fn:29" role="doc-noteref">29</a></sup></td>
<td>N/A</td>
<td>N/A</td>
<td>4 years</td>
<td>4 years</td>
<td>Industry standard</td>
</tr>
</tbody>
</table>
<p>Amazon’s 2025 reversal (6 → 5 years) is the first major pullback.</p>
<p>CPUs historically have 5-10 years of useful life , while GPUs in AI datacenters last 1-3 years in practice , despite 6-year accounting assumptions.<sup id="fnref:30"><a href="#fn:30" role="doc-noteref">30</a></sup><sup>,</sup><sup id="fnref:31"><a href="#fn:31" role="doc-noteref">31</a></sup> Evidence from Google architects shows GPUs at 60-70% utilization survive 1-2 years , with 3 years maximum.<sup id="fnref1:31"><a href="#fn:31" role="doc-noteref">31</a></sup> Meta’s Llama 3 training experienced 9% annual GPU failure rates , suggesting 27% failure over 3 years.<sup id="fnref2:31"><a href="#fn:31" role="doc-noteref">31</a></sup></p>
<p>Cerno Capital raises the question : “Are these policies a reflection of genuine economic &amp; technological realities? Or are these policies a lever by which hyperscalers are enhancing the optics of their investment programs amid rising investor concerns?”<sup id="fnref:32"><a href="#fn:32" role="doc-noteref">32</a></sup></p>
<h3 id="4-the-use-of-spvs">4. The Use of SPVs</h3>
<p>Tech companies use Special Purpose Vehicles (SPVs) to finance AI datacenter construction. A hyperscaler like Meta partners with a private equity firm like Apollo , contributing capital to a separate legal entity that builds &amp; owns the datacenter.</p>
<p>As investor Paul Kedrosky explains : “I have a stake in it as Meta. Some giant private debt provider has a stake in it. The datacenter is under my control. But I don’t own it, so you don’t get to roll it back into my balance sheet.”<sup id="fnref1:2"><a href="#fn:2" role="doc-noteref">2</a></sup>*</p>
<p><strong>The Structure</strong></p>
<ol>
<li><strong>Entity Creation</strong> : Hyperscaler &amp; PE firm form separate legal entity (SPV)</li>
<li><strong>Capital Structure</strong> : Typically 10-30% equity, 70-90% debt from private credit markets</li>
<li><strong>Lease Agreement</strong> : SPV leases capacity back to hyperscaler</li>
<li><strong>Balance Sheet Treatment</strong> : SPV debt doesn’t appear on hyperscaler’s balance sheet</li>
</ol>
<p>The hyperscaler maintains operational control through long-term lease agreements. Because it doesn’t directly own the SPV , the debt remains off its balance sheet under current accounting standards.</p>
<p>The appeal is straightforward. “I don’t want the credit rating agencies to look at what I’m spending. I don’t want investors to roll it up into my income statement.”<sup id="fnref2:2"><a href="#fn:2" role="doc-noteref">2</a></sup>*</p>
<p><strong>Market Scale</strong></p>
<p>American tech companies are projected to spend $300-400 billion on AI infrastructure in 2025. Hyperscaler capital expenditures have reached approximately 50% of operating income<sup id="fnref3:2"><a href="#fn:2" role="doc-noteref">2</a></sup>, levels historically associated with government infrastructure buildouts rather than technology companies.</p>
<p><strong>Where the Risk Sits</strong></p>
<p>Datacenter assets now represent 10-22% of major REIT portfolios<sup id="fnref4:2"><a href="#fn:2" role="doc-noteref">2</a></sup> , up from near zero two years ago. The thin equity layer (10-30%) means if datacenter utilization falls short of projections or if GPUs depreciate faster than projected , equity holders face losses before debt holders experience impairment.</p>
<p><em>*Quotes lightly edited for clarity &amp; brevity</em></p>
<h3 id="5-custom-silicon-threat">5. Custom Silicon Threat</h3>
<p>Hyperscalers are building their own AI accelerators to reduce Nvidia dependence. Microsoft aims to use “mainly Microsoft silicon” , specifically Maia accelerators , in datacenters.<sup id="fnref:33"><a href="#fn:33" role="doc-noteref">33</a></sup> Google deploys <a href="https://cloud.google.com/tpu">TPUs</a> , Amazon builds <a href="https://aws.amazon.com/ai/machine-learning/trainium/">Trainium</a> &amp; <a href="https://aws.amazon.com/ai/machine-learning/inferentia/">Inferentia</a> chips , &amp; Meta develops <a href="https://ai.meta.com/blog/next-generation-meta-training-inference-accelerator-AI-MTIA/">MTIA</a> processors. If customers shift to in-house silicon , CoreWeave’s GPU collateral value &amp; Nvidia’s vendor financing become exposure to customers building competitive alternatives.</p>
<h2 id="nvidia-isnt-lucent--2025-isnt-2000">Nvidia Isn’t Lucent &amp; 2025 Isn’t 2000</h2>
<ul>
<li><strong>Accounting</strong> : Lucent manipulated $1.148B in revenue , SEC charged 10 executives with fraud<sup id="fnref1:5"><a href="#fn:5" role="doc-noteref">5</a></sup> ; Nvidia shows no evidence of manipulation , audited by PwC , Aa3 rated<sup id="fnref:34"><a href="#fn:34" role="doc-noteref">34</a></sup></li>
<li><strong>Cash flow</strong> : Lucent lent $8.1B while cash flow lagged profitability &amp; receivables exploded $5.4B (1998-1999)<sup id="fnref1:20"><a href="#fn:20" role="doc-noteref">20</a></sup> ; Nvidia lends with $50B+ annual operating cash flow &amp; $46.2B net cash<sup id="fnref:35"><a href="#fn:35" role="doc-noteref">35</a></sup></li>
<li><strong>Credit rating</strong> : Lucent downgraded to A3 (December 2000)<sup id="fnref:36"><a href="#fn:36" role="doc-noteref">36</a></sup> ; Nvidia upgraded to Aa3 (March 2024)<sup id="fnref1:34"><a href="#fn:34" role="doc-noteref">34</a></sup></li>
<li><strong>Customer base</strong> : Lucent’s customers were leveraged CLECs burning capital ; Nvidia’s top 4 customers generated $451B in operating cash flow in 2024 (Microsoft $119B , Alphabet $125B , Amazon $116B , Meta $91.3B)<sup id="fnref:37"><a href="#fn:37" role="doc-noteref">37</a></sup></li>
<li><strong>Capacity</strong> : Fiber networks used &lt;0.002% of capacity in 2000<sup id="fnref1:13"><a href="#fn:13" role="doc-noteref">13</a></sup> ; Microsoft &amp; AWS report AI capacity constraints in 2025<sup id="fnref:38"><a href="#fn:38" role="doc-noteref">38</a></sup><sup>,</sup><sup id="fnref:39"><a href="#fn:39" role="doc-noteref">39</a></sup></li>
</ul>
<h2 id="what-im-watching">What I’m Watching</h2>
<p>Is AI demand real (like cloud computing) or speculative (like dot-com fiber)?</p>
<p>Here’s what I’m watching :</p>
<ol>
<li><strong>GPU utilization rates</strong> : Are data centers actually using the chips or just stockpiling?</li>
<li><strong>OpenAI’s monetization</strong> : Can they generate enough revenue to justify the buildout?</li>
<li><strong>Debt defaults</strong> : Any cracks in the $15B GPU-backed debt market?</li>
<li><strong>AR trends</strong> : AR improved from 68% (FY24) to 30% (Q2 FY26) , but still watch for deterioration</li>
<li><strong>Customer adds</strong> : Are new customers emerging , or is Nvidia dependent on the same 2-4 hyperscalers?</li>
<li><strong>Custom silicon threat</strong> : Microsoft developing Maia accelerators , aiming to use “mainly Microsoft silicon in the data center.”<sup id="fnref1:33"><a href="#fn:33" role="doc-noteref">33</a></sup> If hyperscalers shift to in-house chips , Nvidia’s vendor financing becomes exposure to customers building competitive alternatives.</li>
<li><strong>Vendor consolidation</strong> : Many companies are in a period of experimentation trying 2-3 competing vendors. Those experimental budgets may thin with time , reducing overall spend.</li>
</ol>
<p>AI is already broadly deployed—40% of US employees used AI at work by September 2025 , double the 20% rate in 2023.<sup id="fnref:40"><a href="#fn:40" role="doc-noteref">40</a></sup> Questions persist about effectiveness : the oft cited MIT study found 95% of AI pilots failed to deliver measurable P&amp;L impact , primarily due to poor integration rather than technical failures.<sup id="fnref:41"><a href="#fn:41" role="doc-noteref">41</a></sup></p>
<p>Yet the pace of improvement is tremendous. Labor market data shows wages rising twice as fast in AI-exposed industries , &amp; workers using AI boost performance up to 40%.<sup id="fnref1:40"><a href="#fn:40" role="doc-noteref">40</a></sup> Many of Nvidia’s customers are profitable &amp; sophisticated hyperscalers—Microsoft , Google , Amazon , Meta—generating $451B in operating cash flow in 2024 , with tremendous pull from their own enterprise customers demanding AI. OpenAI is not profitable , reporting a $4.7B loss in H1 2025 on $4.3B revenue , though nearly half the loss is stock-based compensation.<sup id="fnref:42"><a href="#fn:42" role="doc-noteref">42</a></sup></p>
<p>Unlike the telecom bubble , where demand was speculative &amp; customers burned cash , this merry-go-round has paying riders.</p>
<hr>
<h2 id="coda--lucents-accounting-fraud">Coda : Lucent’s Accounting Fraud</h2>
<p>Behind the vendor financing disaster was systematic accounting fraud. The SEC charged Lucent with manipulating $1.148 billion in revenue &amp; $470 million in pre-tax income during fiscal year 2000. <sup id="fnref2:5"><a href="#fn:5" role="doc-noteref">5</a></sup> The fraud involved multiple schemes :</p>
<p>Channel Stuffing : Lucent sent $452 million in equipment to distributors but counted it as revenue before the distributors sold to end customers.<sup id="fnref3:5"><a href="#fn:5" role="doc-noteref">5</a></sup> This created phantom sales.</p>
<p>Side Agreements : Lucent executives entered secret agreements with distributors granting them return rights &amp; privileges beyond their distribution contracts , making it improper to recognize revenue.<sup id="fnref4:5"><a href="#fn:5" role="doc-noteref">5</a></sup> These side deals were hidden from auditors.</p>
<p>Reserve Manipulation : Lucent improperly established &amp; maintained excess reserves to smooth earnings , violating GAAP.<sup id="fnref5:5"><a href="#fn:5" role="doc-noteref">5</a></sup></p>
<p>The SEC charged 10 Lucent executives with securities fraud.<sup id="fnref6:5"><a href="#fn:5" role="doc-noteref">5</a></sup> The company paid a $25 million fine—the largest ever for failing to cooperate with an SEC investigation.<sup id="fnref7:5"><a href="#fn:5" role="doc-noteref">5</a></sup> The accounting manipulation masked deteriorating fundamentals until too late.</p>
<p>The WinStar Collapse : Lucent committed $2 billion in vendor financing to WinStar Communications , a CLEC. When WinStar struggled , Lucent refused a final $90 million loan extension. WinStar filed bankruptcy. Lucent wrote off $700 million in bad debts.<sup id="fnref:43"><a href="#fn:43" role="doc-noteref">43</a></sup> This pattern repeated across customer defaults : Lucent made provisions for bad debts of $2.2 billion (2001) &amp; $1.3 billion (2002)—a total of $3.5 billion in customer loan losses.<sup id="fnref1:43"><a href="#fn:43" role="doc-noteref">43</a></sup></p>
<hr>
<h2 id="references">References</h2>


            </div>
            
            
        </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How functional programming shaped and twisted front end development (125 pts)]]></title>
            <link>https://alfy.blog/2025/10/04/how-functional-programming-shaped-modern-frontend.html</link>
            <guid>45473019</guid>
            <pubDate>Sat, 04 Oct 2025 13:04:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alfy.blog/2025/10/04/how-functional-programming-shaped-modern-frontend.html">https://alfy.blog/2025/10/04/how-functional-programming-shaped-modern-frontend.html</a>, See on <a href="https://news.ycombinator.com/item?id=45473019">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>A friend called me last week. Someone who’d built web applications back for a long time before moving exclusively to backend and infra work. He’d just opened a modern React codebase for the first time in over a decade.</p>

<p>“What the hell is this?” he asked. “What are all these generated class names? Did we just… cancel the cascade? Who made the web work this way?”</p>

<p>I laughed, but his confusion cut deeper than he realized. He remembered a web where CSS cascaded naturally, where the DOM was something you worked <em>with</em>, where the browser handled routing, forms, and events without twenty abstractions in between. To him, our modern frontend stack looked like we’d declared war on the platform itself.</p>

<p>He asked me to explain how we got here. That conversation became this essay.</p>

<p><strong>A disclaimer before we begin</strong>: This is one perspective, shaped by having lived through the first browser war. I applied <code>pngfix.js</code> to make 24-bit PNGs work in IE6. I debugged hasLayout bugs at 2 AM. I wrote JavaScript when you couldn’t trust <code>addEventListener</code> to work the same way across browsers. I watched jQuery become necessary, then indispensable, then legacy. I might be wrong about some of this. My perspective is biased for sure, but it also comes with the memory that the web didn’t need constant reinvention to be useful.</p>

<h2 id="introduction">Introduction</h2>

<p>There’s a strange irony at the heart of modern web development. The web was born from documents, hyperlinks, and a cascading stylesheet language. It was always messy, mutable, and gloriously side-effectful. Yet over the past decade, our most influential frontend tools have been shaped by engineers chasing functional programming purity: immutability, determinism, and the elimination of side effects.</p>

<p>This pursuit gave us powerful abstractions. React taught us to think in components. Redux made state changes traceable. TypeScript brought compile-time safety to a dynamic language. But it also led us down a strange path. A one where we fought against the platform instead of embracing it. We rebuilt the browser’s native capabilities in JavaScript, added layers of indirection to “protect” ourselves from the DOM, and convinced ourselves that the web’s inherent messiness was a problem to solve rather than a feature to understand.</p>

<p>The question isn’t whether functional programming principles have value. They do. The question is whether applying them dogmatically to the web (a platform designed around mutability, global scope, and user-driven chaos) made our work better, or just more complex.</p>

<h2 id="the-nature-of-the-web">The Nature of the Web</h2>

<p>To understand why functional programming ideals clash with web development, we need to acknowledge what the web actually is.</p>

<p><strong>The web is fundamentally side-effectful.</strong> CSS cascades globally by design. Styles defined in one place affect elements everywhere, creating emergent patterns through specificity and inheritance. The DOM is a giant mutable tree that browsers optimize obsessively; changing it directly is fast and predictable. User interactions arrive asynchronously and unpredictably: clicks, scrolls, form submissions, network requests, resize events. There’s no pure function that captures “user intent.”</p>

<p><strong>This messiness is not accidental.</strong> It’s how the web scales across billions of devices, remains backwards-compatible across decades, and allows disparate systems to interoperate. The browser is an open platform with escape hatches everywhere. You can style anything, hook into any event, manipulate any node. That flexibility and that refusal to enforce rigid abstractions is the web’s superpower.</p>

<p>When we approach the web with functional programming instincts, we see this flexibility as chaos. We see globals as dangerous. We see mutation as unpredictable. We see side effects as bugs waiting to happen. And so we build walls.</p>

<h2 id="enter-functional-programming-ideals">Enter Functional Programming Ideals</h2>

<p>Functional programming revolves around a few core principles: functions should be pure (same inputs → same outputs, no side effects), data should be immutable, and state changes should be explicit and traceable. These ideas produce code that’s easier to reason about, test, and parallelize, in the right context of course.</p>

<p>These principles had been creeping into JavaScript long before React. Underscore.js (2009) brought map, reduce, and filter to the masses. Lodash and Ramda followed with deeper FP toolkits including currying, composition and immutability helpers. The ideas were in the air: avoid mutation, compose small functions, treat data transformations as pipelines.</p>

<p>React itself started with class components and <code>setState</code>, hardly pure FP. But the conceptual foundation was there: treat UI as a function of state, make rendering deterministic, isolate side effects. Then came Elm, a purely functional language created by Evan Czaplicki that codified the “Model-View-Update” architecture. When Dan Abramov created Redux, he explicitly cited Elm as inspiration. Redux’s reducers are directly modeled on Elm’s update functions: <code>(state, action) =&gt; newState</code>.</p>

<p>Redux formalized what had been emerging patterns. Combined with React Hooks (which replaced stateful classes with functional composition), the ecosystem shifted decisively toward FP. Immutability became non-negotiable. Pure components became the ideal. Side effects were corralled into <code>useEffect</code>. Through this convergence (library patterns, Elm’s rigor, and React’s evolution) Haskell-derived ideas about purity became mainstream JavaScript practice.</p>

<p>In the early 2010s, as JavaScript applications grew more complex, developers looked to FP for salvation. jQuery spaghetti had become unmaintainable. Backbone’s two-way binding caused cascading updates (ironically, Backbone’s documentation explicitly advised against two-way binding saying “it doesn’t tend to be terribly useful in your real-world app” yet many developers implemented it through plugins). The community wanted discipline, and FP offered it: treat your UI as a pure function of state. Make data flow in one direction. Eliminate shared mutable state.</p>

<p>React’s arrival in 2013 crystallized these ideals. It promised a world where <code>UI = f(state)</code>: give it data, get back a component tree, re-render when data changes. No manual DOM manipulation. No implicit side effects. Just pure, predictable transformations.</p>

<p>This was seductive. And in many ways, it worked. But it also set us on a path toward rebuilding the web in JavaScript’s image, rather than JavaScript in the web’s image.</p>

<h2 id="how-fp-purism-shaped-modern-frontend">How FP Purism Shaped Modern Frontend</h2>

<h3 id="css-in-js-the-war-on-global-scope">CSS-in-JS: The War on Global Scope</h3>

<p>CSS was designed to be global. Styles cascade, inherit, and compose across boundaries. This enables tiny stylesheets to control huge documents, and lets teams share design systems across applications. But to functional programmers, global scope is dangerous. It creates implicit dependencies and unpredictable outcomes.</p>

<p>Enter CSS-in-JS: styled-components, Emotion, JSS. The promise was component isolation. Styles scoped to components, no cascading surprises, no naming collisions. Styles become <em>data</em>, passed through JavaScript, predictably bound to elements.</p>

<p>But this came at a cost. CSS-in-JS libraries generate styles at runtime, injecting them into <code>&lt;style&gt;</code> tags as components mount. This adds JavaScript execution to the critical rendering path. Server-side rendering becomes complicated. You need to extract styles during the render, serialize them, and rehydrate them on the client. Debugging involves runtime-generated class names like <code>.css-1xbq8d9</code>. And you lose the cascade; the very feature that made CSS powerful in the first place.</p>

<p>Worse, you’ve moved a browser-optimized declarative language into JavaScript, a single-threaded runtime. The browser can parse and apply CSS in parallel, off the main thread. Your styled-components bundle? That’s main-thread work, blocking interactivity.</p>

<p>The web had a solution. It’s called a stylesheet. But it wasn’t <em>pure</em> enough.</p>

<p>The industry eventually recognized these problems and pivoted to Tailwind CSS. Instead of runtime CSS generation, use utility classes. Instead of styled-components, compose classes in JSX. This was better, at least it’s compile-time, not runtime. No more blocking the main thread to inject styles. No more hydration complexity.</p>

<p>But Tailwind still fights the cascade. Instead of writing <code>.button { padding: 1rem; }</code> once and letting it cascade to all buttons, you write <code>class="px-4 py-2 bg-blue-500"</code> on every single button element. You’ve traded runtime overhead for a different set of problems: class soup in your markup, massive HTML payloads, and losing the cascade’s ability to make sweeping design changes in one place.</p>

<p>And here’s where it gets truly revealing: when Tailwind added support for nested selectors using <code>&amp;</code> (a feature that would let developers write more cascade-like styles), parts of the community revolted. David Khourshid (creator of XState) <a href="https://x.com/DavidKPiano/status/1969054758318051432">shared examples</a> of using nested selectors in Tailwind, and the backlash was immediate. Developers argued this defeated the purpose of Tailwind, that it brought back the “problems” of traditional CSS, that it violated the utility-first philosophy.</p>

<p>Think about what this means. The platform has cascade. CSS-in-JS tried to eliminate it and failed. Tailwind tried to work around it with utilities. And when Tailwind cautiously reintroduced a cascade-like feature, developers who were trained by years of anti-cascade ideology rejected it. We’ve spent so long teaching people that the cascade is dangerous that even when their own tools try to reintroduce platform capabilities, they don’t want them.</p>

<p>We’re not just ignorant of the platform anymore. We’re ideologically opposed to it.</p>

<h3 id="synthetic-events-abstracting-away-the-platform">Synthetic Events: Abstracting Away the Platform</h3>

<p>React introduced synthetic events to normalize browser inconsistencies and integrate events into its rendering lifecycle. Instead of attaching listeners directly to DOM nodes, React uses event delegation. It listens at the root, then routes events to handlers through its own system.</p>

<p>This feels elegant from a functional perspective. Events become data flowing through your component tree. You don’t touch the DOM directly. Everything stays inside React’s controlled universe.</p>

<p>But native browser events already work. They bubble, they capture, they’re well-specified. The browser has spent decades optimizing event dispatch. By wrapping them in a synthetic layer, React adds indirection: memory overhead for event objects, translation logic for every interaction, and debugging friction when something behaves differently than the native API.</p>

<p>Worse, it trains developers to avoid the platform. Developers learn React’s event system, not the web’s. When they need to work with third-party libraries or custom elements, they hit impedance mismatches. <code>addEventListener</code> becomes a foreign API in their own codebase.</p>

<p>Again: the web had this. The browser’s event system is fast, flexible, and well-understood. But it wasn’t <em>controlled</em> enough for the FP ideal of a closed system.</p>

<h3 id="client-side-rendering-and-hydration-reinventing-the-browser">Client-Side Rendering and Hydration: Reinventing the Browser</h3>

<p>The logical extreme of “UI as a pure function of state” is client-side rendering: the server sends an empty HTML shell, JavaScript boots up, and the app renders entirely in the browser. From a functional perspective, this is clean. Your app is a deterministic function that takes initial state and produces a DOM tree.</p>

<p>From a web perspective, it’s a disaster. The browser sits idle while JavaScript parses, executes, and manually constructs the DOM. Users see blank screens. Screen readers get empty documents. Search engines see nothing. Progressive rendering which is one of the browser’s most powerful features, goes unused.</p>

<p>The industry noticed. Server-side rendering came back. But because the mental model was still “JavaScript owns the DOM,” we got <em>hydration</em>: the server renders HTML, the client renders the same tree in JavaScript, then React walks both and attaches event handlers. During hydration, the page is visible but inert. Clicks do nothing, forms don’t submit.</p>

<p>This is architecturally absurd. The browser already rendered the page. It already knows how to handle clicks. But because the framework wants to own all interactions through its synthetic event system, it must re-create the entire component tree in JavaScript before anything works.</p>

<p>The absurdity extends beyond the client. Infrastructure teams watch in confusion as every user makes <em>double the number of requests</em>: the server renders the page and fetches data, then the client boots up and fetches the exact same data again to reconstruct the component tree for hydration. Why? Because the framework can’t trust the HTML it just generated. It needs to rebuild its internal representation of the UI in JavaScript to attach event handlers and manage state.</p>

<p>This isn’t just wasteful, it’s expensive. Database queries run twice. API calls run twice. Cache layers get hit twice. CDN costs double. And for what? So the framework can maintain its pure functional model where all state lives in JavaScript. The browser had the data. The HTML had the data. But that data wasn’t in the right <em>shape</em>. It wasn’t a JavaScript object tree, so we throw it away and fetch it again.</p>

<p>Hydration is what happens when you treat the web like a blank canvas instead of a platform with capabilities. The web gave us streaming HTML, progressive enhancement, and instant interactivity. We replaced it with JSON, JavaScript bundles, duplicate network requests, and “please wait while we reconstruct reality.”</p>

<h3 id="the-modal-problem-teaching-malpractice-as-best-practice">The Modal Problem: Teaching Malpractice as Best Practice</h3>

<p>Consider the humble modal dialog. The web has <code>&lt;dialog&gt;</code>, a native element with built-in functionality: it manages focus trapping, handles Escape key dismissal, provides a backdrop, controls scroll-locking on the body, and integrates with the accessibility tree. It exists in the DOM but remains hidden until opened. No JavaScript mounting required. It’s fast, accessible, and battle-tested by browser vendors.</p>

<p>Now observe what gets taught in tutorials, bootcamps, and popular React courses: build a modal with <code>&lt;div&gt;</code> elements. Conditionally render it when <code>isOpen</code> is true. Manually attach a click-outside handler. Write an effect to listen for the Escape key. Add another effect for focus trapping. Implement your own scroll-lock logic. Remember to add ARIA attributes. Oh, and make sure to clean up those event listeners, or you’ll have memory leaks.</p>

<p>You’ve just written 100+ lines of JavaScript to poorly recreate what the browser gives you for free. Worse, you’ve trained developers to <em>not even look</em> for native solutions. The platform becomes invisible. When someone asks “how do I build a modal?”, the answer is “install a library” or “here’s my custom hook,” never “use <code>&lt;dialog&gt;</code>.”</p>

<p>The teaching is the problem. When influential tutorial authors and bootcamp curricula skip native APIs in favor of React patterns, they’re not just showing an alternative approach. They’re actively teaching malpractice. A generation of developers learns to build inaccessible <code>&lt;div&gt;</code> soup because that’s what fits the framework’s reactivity model, never knowing the platform already solved these problems.</p>

<p>And it’s not just bootcamps. Even the most popular component libraries make the same choice: shadcn/ui builds its Dialog component on Radix UI primitives, which use <code>&lt;div role="dialog"&gt;</code> instead of the native <code>&lt;dialog&gt;</code> element. There are open GitHub issues requesting native <code>&lt;dialog&gt;</code> support, but the implicit message is clear: it’s easier to reimplement the browser than to work with it.</p>

<h3 id="when-frameworks-cant-keep-up-with-the-platform">When Frameworks Can’t Keep Up with the Platform</h3>

<p>The problem runs deeper than ignorance or inertia. The frameworks themselves increasingly struggle to work with the platform’s evolution. Not because the platform features are bad, but because the framework’s architectural assumptions can’t accommodate them.</p>

<p>Consider why component libraries like Radix UI choose <code>&lt;div role="dialog"&gt;</code> over <code>&lt;dialog&gt;</code>. The native <code>&lt;dialog&gt;</code> element manages its own state: it knows when it’s open, it handles its own visibility, it controls focus internally. But React’s reactivity model expects all state to live in JavaScript, flowing unidirectionally into the DOM. When a native element manages its own state, React’s mental model breaks down. Keeping <code>isOpen</code> in your React state synchronized with the <code>&lt;dialog&gt;</code> element’s actual open/closed state becomes a nightmare of refs, effects, and imperative calls. Precisely what React was supposed to eliminate.</p>

<p>Rather than adapt their patterns to work with stateful native elements, library authors reimplement the entire behavior in a way that fits the framework. It’s architecturally easier to build a fake dialog in JavaScript than to integrate with the platform’s real one.</p>

<p>But the conflict extends beyond architectural preferences. Even when the platform adds features that developers desperately want, frameworks can’t always use them.</p>

<p>Accordions? The web has <code>&lt;details&gt;</code> and <code>&lt;summary&gt;</code>. Tooltips? There’s <code>title</code> attribute and the emerging <code>popover</code> API. Date pickers? <code>&lt;input type="date"&gt;</code>. Custom dropdowns? The web now supports styling <code>&lt;select&gt;</code> elements with <code>appearance: base-select</code> and <code>::picker(select)</code> pseudo-elements. You can even put <code>&lt;span&gt;</code> elements with images inside <code>&lt;option&gt;</code> elements now. It eliminates the need for the countless JavaScript select libraries that exist solely because designers wanted custom styling.</p>

<p>Frameworks encourage conditional rendering and component state, so these elements don’t get rendered until JavaScript decides they should exist. The mental model is “UI appears when state changes,” not “UI exists, state controls visibility.” Even when the platform adds the exact features developers have been rebuilding in JavaScript for years, the ecosystem momentum means most developers never learn these features exist.</p>

<p>And here’s the truly absurd part: even when developers <em>do</em> know about these new platform features, the frameworks themselves can’t handle them. <a href="https://developer.mozilla.org/en-US/docs/Learn_web_development/Extensions/Forms/Customizable_select">MDN’s documentation</a> for customizable <code>&lt;select&gt;</code> elements includes this warning: “<strong>Some JavaScript frameworks block these features; in others, they cause hydration failures when Server-Side Rendering (SSR) is enabled.</strong>” The platform evolved. The HTML parser now allows richer content inside <code>&lt;option&gt;</code> elements. But React’s JSX parser and hydration system weren’t designed for this. They expect <code>&lt;option&gt;</code> to only contain text. Updating the framework to accommodate the platform’s evolution takes time, coordination, and breaking changes that teams are reluctant to make.</p>

<p>The web platform added features that eliminate entire categories of JavaScript libraries, but the dominant frameworks can’t use those features without causing hydration errors. The stack that was supposed to make development easier now lags behind the platform it’s built on.</p>

<h3 id="routing-and-forms-javascript-all-the-way-down">Routing and Forms: JavaScript All the Way Down</h3>

<p>The browser has native routing: <code>&lt;a&gt;</code> tags, the History API, forward/back buttons. It has native forms: <code>&lt;form&gt;</code> elements, validation attributes, submit events. These work without JavaScript. They’re accessible by default. They’re fast.</p>

<p>Modern frameworks threw them out. React Router, Next.js’s router, Vue Router; they intercept link clicks, prevent browser navigation, and handle routing in JavaScript. Why? Because client-side routing feels like a pure state transition: URL changes, state updates, component re-renders. No page reload. No “lost” JavaScript state.</p>

<p>But you’ve now made navigation depend on JavaScript. Ctrl+click to open in a new tab? Broken, unless you carefully re-implement it. Right-click to copy link? The URL might not match what’s rendered. Accessibility tools that rely on standard navigation patterns? Confused.</p>

<p>Forms got the same treatment. Instead of letting the browser handle submission, validation, and accessibility, frameworks encourage JavaScript-controlled forms. Formik, React Hook Form, uncontrolled vs. controlled inputs; entire libraries exist to manage what <code>&lt;form&gt;</code> already does. The browser can validate <code>&lt;input type="email"&gt;</code> instantly, with no JavaScript. But that’s not <em>reactive</em> enough, so we rebuild validation in JavaScript, ship it to the client, and hope we got the logic right.</p>

<p>The web had these primitives. We rejected them because they didn’t fit our FP-inspired mental model of “state flows through JavaScript.”</p>

<h2 id="what-we-lost-in-the-process">What We Lost in the Process</h2>

<p>Progressive enhancement used to be a best practice: start with working HTML, layer on CSS for style, add JavaScript for interactivity. The page works at every level. Now, we start with JavaScript and work backwards, trying to squeeze HTML out of our component trees and hoping hydration doesn’t break.</p>

<p>We lost built-in accessibility. Native HTML elements have roles, labels, and keyboard support by default. Custom JavaScript widgets require <code>aria-*</code> attributes, focus management, and keyboard handlers. All easy to forget or misconfigure.</p>

<p>We lost performance. The browser’s streaming parser can render HTML as it arrives. Modern frameworks send JavaScript, parse JavaScript, execute JavaScript, then finally render. That’s slower. The browser can cache CSS and HTML aggressively. JavaScript bundles invalidate on every deploy.</p>

<p>We lost simplicity. <code>&lt;a href="/about"&gt;</code> is eight characters. A client-side router is a dependency, a config file, and a mental model. <code>&lt;form action="/submit" method="POST"&gt;</code> is self-documenting. A controlled form with validation is dozens of lines of state management.</p>

<p>And we lost alignment with the platform. The browser vendors spend millions optimizing HTML parsing, CSS rendering, and event dispatch. We spend thousands of developer-hours rebuilding those features in JavaScript, slower.</p>

<h2 id="why-this-happened">Why This Happened</h2>

<p>This isn’t a story of incompetence. Smart people built these tools for real reasons.</p>

<p>By the early 2010s, JavaScript applications had become unmaintainable. jQuery spaghetti sprawled across codebases. Two-way data binding caused cascading updates that were impossible to debug. Teams needed discipline, and functional programming offered it: pure components, immutable state, unidirectional data flow. For complex, stateful applications (like dashboards with hundreds of interactive components, real-time collaboration tools, data visualization platforms) React’s model was genuinely better than manually wiring up event handlers and tracking mutations.</p>

<p>The FP purists weren’t wrong that unpredictable mutation causes bugs. They were wrong that the solution was avoiding the platform’s mutation-friendly APIs instead of learning to use them well. But in the chaos of 2013, that distinction didn’t matter. React worked. It scaled. And Facebook was using it in production.</p>

<p>Then came the hype cycle. React dominated the conversation. Every conference had React talks. Every tutorial assumed React as the starting point. CSS-in-JS became “modern.” Client-side rendering became the default. When big companies like Facebook, Airbnb, Netflix and others adopted these patterns, they became industry standards. Bootcamps taught React exclusively. Job postings required React experience. The narrative solidified: this is how you build for the web now.</p>

<p>The ecosystem became self-reinforcing through its own momentum. Once React dominated hiring pipelines and Stack Overflow answers, alternatives faced an uphill battle. Teams that had already invested in React by training developers, building component libraries, establishing patterns are now facing enormous switching costs. New developers learned React because that’s what jobs required. Jobs required React because that’s what developers knew. The cycle fed itself, independent of whether React was the best tool for any particular job.</p>

<p>This is where we lost the plot. Somewhere in the transition from “React solves complex application problems” to “React is how you build websites,” we stopped asking whether the problems we were solving actually needed these solutions. I’ve watched developers build personal blogs with Next.js. Sites that are 95% static content with maybe a contact form, because that’s what they learned in bootcamp. I’ve seen companies choose React for marketing sites with zero interactivity, not because it’s appropriate, but because they can’t hire developers who know anything else.</p>

<p>The tool designed for complex, stateful applications became the default for everything, including problems the web solved in 1995 with HTML and CSS. A generation of developers never learned that most websites don’t need a framework at all. The question stopped being “does this problem need React?” and became “which React pattern should I use?” The platform’s native capabilities like progressive rendering, semantic HTML, the cascade, instant navigation are now considered “old-fashioned.” Reinventing them in JavaScript became “best practices.”</p>

<p>We chased functional purity on a platform that was never designed for it. And we built complexity to paper over the mismatch.</p>

<h2 id="the-way-forward">The Way Forward</h2>

<p>The good news: we’re learning. The industry is rediscovering the platform.</p>

<p>HTMX embraces HTML as the medium of exchange. Server sends HTML, browser renders it, no hydration needed. Qwik resumable architecture avoids hydration entirely, serializing only what’s needed. Astro defaults to server-rendered HTML with minimal JavaScript. Remix and SvelteKit lean into web standards: forms that work without JS, progressive enhancement, leveraging the browser’s cache.</p>

<p>These tools acknowledge what the web is: a document-based platform with powerful native capabilities. Instead of fighting it, they work with it.</p>

<p>This doesn’t mean abandoning components or reactivity. It means recognizing that <code>UI = f(state)</code> is a useful model <em>inside</em> your framework, not a justification to rebuild the entire browser stack. It means using CSS for styling, native events for interactions, and HTML for structure and then reaching for JavaScript when you need interactivity beyond what the platform provides.</p>

<p>The best frameworks of the next decade will be the ones that feel like the web, not in spite of it.</p>

<h2 id="conclusion">Conclusion</h2>

<p>In chasing functional purity, we built a frontend stack that is more complex, more fragile, and less aligned with the platform it runs on. We recreated CSS in JavaScript, events in synthetic wrappers, rendering in hydration layers, and routing in client-side state machines. We did this because we wanted predictability, control, and clean abstractions.</p>

<p>But the web was never meant to be pure. It’s a sprawling, messy, miraculous platform built on decades of emergent behavior, pragmatic compromises, and radical openness. Its mutability isn’t a bug. It’s the reason a document written in 1995 still renders in 2025. Its global scope isn’t dangerous. It’s what lets billions of pages share a design language.</p>

<p>Maybe the web didn’t need to be purified. Maybe it just needed to be understood.</p>

<p>I want to thank my friend <a href="https://x.com/HO_BA">Ihab Khattab</a> for reviewing this piece and providing invaluable feedback.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google removes ICE-spotting app following Apple's ICEBlock crackdown (140 pts)]]></title>
            <link>https://www.theverge.com/news/791533/google-apple-ice-tracking-app-store-red-dot-iceblock</link>
            <guid>45472799</guid>
            <pubDate>Sat, 04 Oct 2025 12:23:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/news/791533/google-apple-ice-tracking-app-store-red-dot-iceblock">https://www.theverge.com/news/791533/google-apple-ice-tracking-app-store-red-dot-iceblock</a>, See on <a href="https://news.ycombinator.com/item?id=45472799">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><a href="https://www.theverge.com/authors/emma-roth"><img alt="Emma Roth" data-chromatic="ignore" loading="lazy" width="36" height="36" decoding="async" data-nimg="1" srcset="https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/195810/EMMA_ROTH.0.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=48 1x, https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/195810/EMMA_ROTH.0.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=96 2x" src="https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/195810/EMMA_ROTH.0.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=96"></a></p><div><p><span aria-expanded="false" aria-haspopup="true" role="button" tabindex="0"><span id="follow-author-standard_article_details-dmcyOmF1dGhvclByb2ZpbGU6MTE2"><span><span><svg width="9" height="9" viewBox="0 0 9 9" fill="none" xmlns="http://www.w3.org/2000/svg" aria-label="Follow"><path d="M5 0H4V4H0V5H4V9H5V5H9V4H5V0Z"></path></svg></span></span><span>Emma Roth</span></span></span></p> <p><span>is a news writer who covers the streaming wars, consumer tech, crypto, social media, and much more. Previously, she was a writer and editor at MUO.</span></p></div></div><div id="zephr-anchor"><p>Just one day after <a href="https://www.theverge.com/news/696584/iceblock-tracking-app-white-house-criticism">Apple took down the iOS App Store listing for ICEBlock</a>, Google has confirmed to <a href="https://www.404media.co/google-calls-ice-agents-a-vulnerable-group-removes-ice-spotting-app-red-dot/"><em>404 Media</em></a> that it has removed a similar app, Red Dot, from the Google Play Store. The company also reportedly said it “removed apps that share the location of what it describes as a vulnerable group after a recent violent act against them connected to this sort of app.”</p><p>On Thursday, Apple removed ICEBlock and similar apps, including Red Dot, after facing pressure from the Department of Justice. Attorney General Pam Bondi <a href="https://www.foxbusiness.com/politics/apple-takes-down-ice-tracking-app-after-pressure-from-ag-bondi">said to Fox News</a> on Thursday that “ICEBlock is designed to put ICE agents at risk just for doing their jobs, and violence against law enforcement is an intolerable red line that cannot be crossed.” In response to the move, ICEBlock developer <a href="https://www.404media.co/iceblock-owner-after-apple-removes-app-we-are-determined-to-fight-this/">Joshua Aaron said in a statement to <em>404 Media</em></a> that the app is “protected speech,” adding that Apple is “capitulating to an authoritarian regime.”</p><p>Both ICEBlock and Red Dot allow users to anonymously report sightings of ICE agents and view nearby reports. <a href="https://www.red-dot.app/">Red Dot’s website says</a> the app combines user reporting with “verified reports from multiple trusted sources” to monitor ICE activity.</p><p>Google told <em>404 Media</em> that it didn’t receive any warning from the DOJ, but that it “bans apps with a high risk of abuse” and has a requirement for content moderation apps with user-generated content.“ICEBlock was never available on Google Play, but we removed similar apps for violations of our policies,” Google told <em>404 Media</em>.<em> The Verge</em> reached out to Google with a request for comment but didn’t immediately hear back.</p><div><p><span><strong>Follow topics and authors</strong> from this story to see more like this in your personalized homepage feed and to receive email updates.</span></p><ul><li id="follow-author-article_footer-dmcyOmF1dGhvclByb2ZpbGU6MTE2"><span aria-expanded="false" aria-haspopup="true" role="button" tabindex="0"><span><span><svg width="9" height="9" viewBox="0 0 9 9" fill="none" xmlns="http://www.w3.org/2000/svg" aria-label="Follow"><path d="M5 0H4V4H0V5H4V9H5V5H9V4H5V0Z"></path></svg></span><span>Emma Roth</span></span></span></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li></ul></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Thunderscan: A clever device transforms a printer into a scanner (2004) (149 pts)]]></title>
            <link>https://www.folklore.org/Thunderscan.html</link>
            <guid>45472765</guid>
            <pubDate>Sat, 04 Oct 2025 12:16:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.folklore.org/Thunderscan.html">https://www.folklore.org/Thunderscan.html</a>, See on <a href="https://news.ycombinator.com/item?id=45472765">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>The first project that I worked on for Apple after starting in August 1979 was writing low level software for the Silentype printer <span>(see <a href="https://www.folklore.org/What_Hath_Woz_Wrought.html"><span>What Hath Woz Wrought</span></a>)</span>, a cute, inexpensive thermal printer for the Apple II, that was based on technology licensed from a local company named Trendcom.  In typical Apple fashion, we improved on Trendcom's design by replacing their relatively expensive controller board with a much simpler one that relied on the microprocessor in the Apple II to do most of the dirty work.</p><p>

The only other engineer working on the project was Victor Bull, who was the hardware designer and also the project leader.  Vic was smart, taciturn and easy to work with, and I learned a lot from him about how thermal printers worked, as well as how things worked at Apple.  We finished the project quickly, and the Silentype shipped in November 1979, less than four months after I began working on it.</p><p>

In May 1984, during my leave of absence from Apple <span>(see <a href="https://www.folklore.org/Leave_Of_Absence.html"><span>Leave Of Absence</span></a>)</span>, I received a phone call from Victor Bull, who I hadn't heard from in a couple of years.  He had left Apple more than a year ago to work with his friend Tom Petrie at a tiny company based in Orinda named Thunderware, that sold a single product called Thunderclock, an inexpensive calendar/clock card for the Apple II.  Victor said that he thought that I might be interested in writing software for an exciting, clever new product that Thunderware was developing for the Macintosh, which he refused to describe over the phone. He invited me to come visit them to check it out.</p><p>

In early June, I drove up to Thunderware's office in Orinda, which was about an hour's drive from my house in Palo Alto.  After I arrived at their modest headquarters, Vic introduced me to his partner, Tom Petrie, and I signed a non-disclosure agreement before they ushered me into a back room to see their demo.</p><p>

The most popular printer for both the Apple II and the Macintosh was the ImageWriter, a $500 dot-matrix printer capable of rendering bitmapped graphics, that was designed and manufactured by Japanese company named C.Itoh Electronics and marketed by Apple.  Virtually every Macintosh owner purchased an ImageWriter, since it was the only printer that was supported by Apple.  Tom's demo consisted of an ImageWriter printer hooked up to an Apple II, that at first glance appeared to be busily printing away.  But when I looked closer, I noticed that instead of blank paper, there was a glossy photograph of a cat threaded through the printer's platen, and the printer's black plastic ribbon cartridge was missing, replaced by a makeshift contraption containing an optical sensing device that trailed an umbilical cord back to the Apple II.</p><p>

Their potential new product, Thunderscan, was a low cost way to temporarily turn an ImageWriter printer into a high resolution scanner, by replacing the ribbon cartridge with an optical sensor and writing some clever software.  Since the resolution was determined by the precision of the printer's stepper motors, which had to be very accurate in order to print detailed graphics, Thunderscan, priced at under $200, had better resolution than flat bed scanners costing more than ten times as much.  I loved the cleverness of the ingenious concept, and the Woz-like elegance of saving money and adding flexibility by doing everything in software, but there were also a few problems.</p><p>

The biggest problem was that Thunderscan could only capture one scan line's worth of data on each pass of the print head, which made it nine times slower than regular printing, since the print head could deposit nine dots at a time.  This made for frustratingly slow scanning, often taking over an hour to scan a full page at the highest resolution.  Thunderscan was never going to win any races.</p><p>

Another apparent problem was the disappointingly low quality of the image being captured and displayed by Tom Petrie's Apple II application. Tom and Vic said their scanner was capable of capturing up to 32 different levels of light intensity, but both the Apple II (in hi-res mode) and the Macintosh only had one bit per pixel to display, so the software had to simulate gray scales using patterns of black and white dots.  It looked like Tom was using a simple threshold algorithm to do the rendering, which threw away most of the gray scale information and made the resulting image look unacceptably blotchy.  It was hard to tell if the quality promised by Tom and Vic was there or not.</p><p>

Tom and Vic proposed to hire me to write Macintosh software for Thunderscan.  I knew that a low cost scanner would be a great product for the image hungry Macintosh, but only if it had sufficient quality, and I wasn't sure about that. I told them that I'd think it over during the next few days, and, as I did, I became more excited about the potential of Thunderscan for the Macintosh, realizing that the slow speed wouldn't be that much of an impediment if the quality and resolution was good enough.  The low image quality in Tom's prototype was probably caused more by the Apple II software than by anything inherent in the scanner.  The Macintosh was almost ten times faster than the Apple II, so it should be able to sample the incoming data better to obtain more horizontal resolution.  Plus, I knew a much better algorithm for gray scale rendering that would be fun to try out in practice.</p><p>

My friend and colleague Bill Atkinson was a talented photographer, and one of his hobbies was playing around with digitized pictures, periodically experimenting to find the best algorithms for rendering them.  Bill loved to explain his current work to whoever would listen to him, so I learned a lot about rendering gray scale images over the years simply by being around him.  Bill had progressed over the years from using an "ordered dither" algorithm, where varying threshold values are specified in a sliding matrix, to his current favorite, which was a modified version of what was known as the "Floyd-Steinberg" algorithm, where an error term is maintained and distributed proportionally to neighboring pixels.</p><p>

I called Thunderware and told them I was interested in working on Macintosh software for Thunderscan, in exchange for a per-unit royalty.   I drove back up to Orinda, where Tom and Vic gave me lots of documentation about the scanner, and the sample code that Tom had written for the Apple II.  For the next couple of months, I drove up to Orinda once a week, usually on Thursday, to meet with Tom and Vic show them my progress, prioritize development issues and discussion various complications as they arose. We would also discuss business terms, but we didn't sign a formal contract until the software was almost finished, when we settled on a royalty of $7.50 per unit.</p><p>

Tom and Vic had already encountered and surmounted a number of tough problems just to get scanning going at all.  For example, the ImageWriter printer was not really designed to be stepped one scanline at a time, and if you tried that the paper would bunch up against the platen, causing distortion.  Tom and Vic solved the problem by commanding the printer to move three steps up and then two steps back, instead of a single step up, which held the paper snugly against the platen as required.   There were also various techniques for sensing the beginning and end of the scan line, and some timings that were determined by tedious experimentation for how long it took the printer to respond to a command.</p><p>

<a href="https://www.folklore.org/images/Macintosh/tscanapp.jpg"><img src="https://www.folklore.org/images/Macintosh/tscanapp_t.jpg"></a>It took a week or so to get basic scanning working on the Macintosh, and then a few more days to render the gray scale data with Bill's modified Floyd-Steinberg dithering.  After shaking out a variety of problems, mostly involving synchronization between the printer and the software, I was surprised and impressed by the consistent high quality of the results.  I went through a brief, elated phase of scanning every image in sight that would fit through the printer, just to see how it would turn out.</p><p>

One important design decision that I made early on was to keep the gray scale data around, to allow more flexible image processing.  Thunderscan documents were five bits per pixel, before the Macintosh generally supported gray scale, and the user could manipulate the contrast and brightness of selected areas of the image, dodging and burning to reveal detail in the captured image.  This also paid off in later versions when we implemented gray scale printing for Postscript printers.</p><p>

My favorite feature that I came up with for Thunderscan had to do with two dimensional scrolling.  Thunderscan documents could be quite large, so you could only show a portion of them in the image area of the window.  You could scroll the image by dragging with a MacPaint-style "hand" scrolling tool, but you had to drag an awful lot to get to the extremes of a large image.  I decided to add what I called "inertial" scrolling, where you gave the image a push and it kept scrolling at a variable speed in the direction of the push, after the mouse button was released.  I had to add some hysteresis to keep the image from moving accidentally, and make various other tweaks, but soon I had it working and it felt great to be able to zip around  large images by pushing them.</p><p>

The hardest feature to perfect was bidirectional scanning.  At first, Thunderscan only scanned from left to right, but it wasted time to return the scannner to the left after every scan line.  We could almost double the speed if we scanned in both directions, but it was hard to get the adjacent scan lines that were scanned in opposite directions to line up properly.   Ultimately, we made bidirectional scanning an optional feature, if you wanted to trade a little quality for greater speed.</p><p>

I finished the software in November 1984, after taking a short break to work on something else <span>(see <a href="https://www.folklore.org/Switcher.html"><span>Switcher</span></a>)</span>.  Thunderscan shipped in December 1984, and did well from the very beginning, with sales gradually rising from around 1,000 units/month to over 7,500 units/month at its peak in 1987.    For a while, it was both the least expensive and highest quality scanning alternative for the Macintosh, although I'm sure it frustrated a lot of users by being too slow.  I did three major revisions of the software over the next few years, improving the scan quality and adding features like gray scale printing and eventually gray scale display for the Macintosh II.</p><p>

Eventually, the flat bed scanners caught up to Thunderscan, and then surpassed it, in both cost, quality and convenience.   Over its lifetime, Thunderscan sold approximately 100,000 units and improved countless documents by providing users with an inexpensive way to capture high resolution graphics with their Macintoshes.
  </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Buchstabenmuseum Berlin is closing (175 pts)]]></title>
            <link>https://www.buchstabenmuseum.de/en/</link>
            <guid>45472678</guid>
            <pubDate>Sat, 04 Oct 2025 11:58:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.buchstabenmuseum.de/en/">https://www.buchstabenmuseum.de/en/</a>, See on <a href="https://news.ycombinator.com/item?id=45472678">Hacker News</a></p>
<div id="readability-page-1" class="page">
		<a href="#content">Skip to content</a>

		
		
	<div id="boxed-wrapper">
			
			
				
			<header>
				<div>
							<nav aria-label="Main Menu"><ul id="menu-main_menu_en"><li id="menu-item-210" data-item-id="210"><a href="https://www.buchstabenmuseum.de/en/visit/"><span>VISIT</span></a></li><li id="menu-item-208" data-item-id="208"><a href="https://www.buchstabenmuseum.de/en/program/"><span>PROGRAM</span></a></li><li id="menu-item-207" data-item-id="207"><a href="https://www.buchstabenmuseum.de/en/collection/"><span>COLLECTION</span></a></li><li id="menu-item-209" data-item-id="209"><a href="https://www.buchstabenmuseum.de/en/support/"><span>SUPPORT</span></a></li><li id="menu-item-829" data-item-id="829"><a href="https://www.buchstabenmuseum.de/en/press/"><span>PRESS</span></a></li><li id="menu-item-803" data-item-id="803"><a href="https://www.buchstabenmuseum.de/en/contact/"><span>CONTACT</span></a></li><li id="menu-item-211-de" data-classes="lang-item" data-item-id="211-de"><a href="https://www.buchstabenmuseum.de/" hreflang="de-DE" lang="de-DE"><span>DE</span></a></li></ul></nav><nav aria-label="Main Menu Sticky"><ul id="menu-main_menu_en-1"><li data-item-id="210"><a href="https://www.buchstabenmuseum.de/en/visit/"><span>VISIT</span></a></li><li data-item-id="208"><a href="https://www.buchstabenmuseum.de/en/program/"><span>PROGRAM</span></a></li><li data-item-id="207"><a href="https://www.buchstabenmuseum.de/en/collection/"><span>COLLECTION</span></a></li><li data-item-id="209"><a href="https://www.buchstabenmuseum.de/en/support/"><span>SUPPORT</span></a></li><li data-item-id="829"><a href="https://www.buchstabenmuseum.de/en/press/"><span>PRESS</span></a></li><li data-item-id="803"><a href="https://www.buchstabenmuseum.de/en/contact/"><span>CONTACT</span></a></li><li data-classes="lang-item" data-item-id="211-de"><a href="https://www.buchstabenmuseum.de/" hreflang="de-DE" lang="de-DE"><span>DE</span></a></li></ul></nav><div><ul id="menu-main_menu_en-2"><li data-item-id="210"><a href="https://www.buchstabenmuseum.de/en/visit/"><span>VISIT</span></a></li><li data-item-id="208"><a href="https://www.buchstabenmuseum.de/en/program/"><span>PROGRAM</span></a></li><li data-item-id="207"><a href="https://www.buchstabenmuseum.de/en/collection/"><span>COLLECTION</span></a></li><li data-item-id="209"><a href="https://www.buchstabenmuseum.de/en/support/"><span>SUPPORT</span></a></li><li data-item-id="829"><a href="https://www.buchstabenmuseum.de/en/press/"><span>PRESS</span></a></li><li data-item-id="803"><a href="https://www.buchstabenmuseum.de/en/contact/"><span>CONTACT</span></a></li><li data-classes="lang-item" data-item-id="211-de"><a href="https://www.buchstabenmuseum.de/" hreflang="de-DE" lang="de-DE"><span>DE</span></a></li></ul></div>	

<nav aria-label="Main Menu Mobile"></nav>

	<nav aria-label="Main Menu Mobile Sticky"></nav>
					</div>
				
			</header>
							
				
		
				
				
			
			
						<main id="main">
				<div id="content">
			<span>Buchstabenmuseum</span><span><span><a href="https://www.buchstabenmuseum.de/en/author/barbara/" title="Posts by barbara" rel="author">barbara</a></span></span><span>2025-07-18T16:32:18+02:00</span>
			
			<div>
				<div><div><h2></h2><h3 data-fontsize="20" data-lineheight="30px"><strong>After 20 Years:</strong></h3></div><span><img width="940" height="616" title="250703_INSTA_We are closing_web" src="https://www.buchstabenmuseum.de/wp-content/uploads/2025/07/250703_INSTA_We-are-closing_web-1-1024x671.jpg" srcset="https://www.buchstabenmuseum.de/wp-content/uploads/2025/07/250703_INSTA_We-are-closing_web-1-200x131.jpg 200w, https://www.buchstabenmuseum.de/wp-content/uploads/2025/07/250703_INSTA_We-are-closing_web-1-400x262.jpg 400w, https://www.buchstabenmuseum.de/wp-content/uploads/2025/07/250703_INSTA_We-are-closing_web-1-600x393.jpg 600w, https://www.buchstabenmuseum.de/wp-content/uploads/2025/07/250703_INSTA_We-are-closing_web-1-800x524.jpg 800w, https://www.buchstabenmuseum.de/wp-content/uploads/2025/07/250703_INSTA_We-are-closing_web-1-1200x786.jpg 1200w" sizes="(max-width: 800px) 100vw, 1200px"></span><div><h3>The Buchstabenmuseum Berlin is closing!</h3>
<p>Until 5 October 2025, you can visit our museum every Thursday to Sunday from 1 to 5 pm.<br>
A visit outside opening hours is possible with a guided tour.<br>
<a href="mailto:visit@buchstabenmuseum.de">visit@buchstabenmuseum.de</a></p>
<p>We are still looking for long-term storage for our collection.<br>
For this we need support:<br>
<a href="https://secure.betterplace.org/de/donate/platform/projects/118807-rettung-gebauter-schriftzuege">&gt;&gt; betterplace</a></p>
<h4>We look forward to your visit!</h4>
<p>______________________________</p>
</div></div><div><div><h2></h2><h3 data-fontsize="20" data-lineheight="30px"><strong>20 Years of the Buchstabenmuseum!</strong></h3></div><span><img width="940" height="616" title="250605_BM_20J_web" src="https://www.buchstabenmuseum.de/wp-content/uploads/2025/06/250605_BM_20J_web-1-1024x671.jpg" srcset="https://www.buchstabenmuseum.de/wp-content/uploads/2025/06/250605_BM_20J_web-1-200x131.jpg 200w, https://www.buchstabenmuseum.de/wp-content/uploads/2025/06/250605_BM_20J_web-1-400x262.jpg 400w, https://www.buchstabenmuseum.de/wp-content/uploads/2025/06/250605_BM_20J_web-1-600x393.jpg 600w, https://www.buchstabenmuseum.de/wp-content/uploads/2025/06/250605_BM_20J_web-1-800x524.jpg 800w, https://www.buchstabenmuseum.de/wp-content/uploads/2025/06/250605_BM_20J_web-1-1200x786.jpg 1200w" sizes="(max-width: 800px) 100vw, 1200px"></span><div><h4>On Sat 14 June 2025 from 3 to 9 pm we want to celebrate our birthday and toast with you!<br>
You and all your friends and family are cordially invited.</h4>
<p>20 years is a very long time to look back on.<br>
That’s why we’ve put together a colourful brochure that we’ll be presenting on Saturday.</p>
<p>In addition, Sabrina Hauck (student at TU Berlin / architect at gkks) will give a talk on the use,<br>
vacancy and potential of Berlin’s S-Bahn arches at 18:00.</p>
</div></div><div><div><h2></h2><h3><strong>FINAL SALE – FROM DEPARTMENT STORES’ TO MUSEUM</strong></h3>
<p><span>Extended Term until Autumn 2025!</span></p>
<p><strong>AN EXHIBITION OF FORMER DEPARTMENT STORES FROM 1980 TO TODAY</strong></p></div><div><p>Horten, Quelle, Hertie, Kaufhof and Karstadt – corporate names that are disappearing from German city centres. Galeria Karstadt Kaufhof is currently struggling with closure in instalments. With the creeping loss of the corporations, the distinctive lettering of the department stores’ chains is also being lost.<br>
“FINAL SALE” tells the typographic and urban-historical stories of the letters and shows the former significance of the department stores and department stores with their architecture.<br>
We invite you to discover the typographic department stores’ icons and to buy selected items in the exhibition: “Final Sale – from department stores’ to museum” in the Buchstabenmuseum in the Stadtbahnbögen in the Hansaviertel.</p>
</div></div><div><div><span><img width="320" height="230" alt="illustration buchstabenmuseum" title="bm-illu_en" src="https://www.buchstabenmuseum.de/wp-content/uploads/2017/10/bm-illu_en.png" srcset="https://www.buchstabenmuseum.de/wp-content/uploads/2017/10/bm-illu_en-200x144.png 200w, https://www.buchstabenmuseum.de/wp-content/uploads/2017/10/bm-illu_en.png 320w" sizes="(max-width: 800px) 100vw, 320px"></span></div><div><h2></h2><h2>THE BUCHSTABENMUSEUM</h2></div><div><p><strong>Preservation and documentation of letters</strong><br>
The Buchstabenmuseum is the first museum in the world to collect letterforms from public spaces and display them as part of urban history. We preserve and document three-dimensional letters and signage, and their history, as well as providing information about their origins and construction. Our collection has captured the imagination of visitors from all around the world for over 10 years. Hundreds of letters have been saved from being battered by the elements or ending up on the scrap heap. A selection of what we offer can be found under »&nbsp;<span><a href="https://www.buchstabenmuseum.de/en/collection/">COLLECTION</a></span></p>
</div></div><div><span><img width="1600" height="900" alt="Buchstabenmuseum" title="BM_MAP_Bogen-424" src="https://www.buchstabenmuseum.de/wp-content/uploads/2020/06/BM_MAP_Bogen-424.jpg" srcset="https://www.buchstabenmuseum.de/wp-content/uploads/2020/06/BM_MAP_Bogen-424-200x113.jpg 200w, https://www.buchstabenmuseum.de/wp-content/uploads/2020/06/BM_MAP_Bogen-424-400x225.jpg 400w, https://www.buchstabenmuseum.de/wp-content/uploads/2020/06/BM_MAP_Bogen-424-600x338.jpg 600w, https://www.buchstabenmuseum.de/wp-content/uploads/2020/06/BM_MAP_Bogen-424-800x450.jpg 800w, https://www.buchstabenmuseum.de/wp-content/uploads/2020/06/BM_MAP_Bogen-424-1200x675.jpg 1200w, https://www.buchstabenmuseum.de/wp-content/uploads/2020/06/BM_MAP_Bogen-424.jpg 1600w" sizes="(max-width: 800px) 100vw, 1200px"></span></div><div><h2>COLLECTION</h2></div><div><h2></h2><h2><span>SPECIALS</span></h2></div><div><div><div><span><img width="460" height="305" title="buchstaben_en" src="https://www.buchstabenmuseum.de/wp-content/uploads/2017/10/buchstaben_en.gif"></span></div><div><p><strong>The Buchstabenmuseum font:</strong><br>
Selected objects from the museum have been made into a unique font (OTF) by LucasFonts. We’ve made it available for you to download free here:</p>
</div></div><div><div><span><img width="533" height="331" title="Teaser_BM_Studio_2_©_Sebastian_Weiss" src="https://www.buchstabenmuseum.de/wp-content/uploads/2020/07/Teaser_BM_Studio_2_%C2%A9_Sebastian_Weiss-1.jpg" srcset="https://www.buchstabenmuseum.de/wp-content/uploads/2020/07/Teaser_BM_Studio_2_%C2%A9_Sebastian_Weiss-1-200x124.jpg 200w, https://www.buchstabenmuseum.de/wp-content/uploads/2020/07/Teaser_BM_Studio_2_%C2%A9_Sebastian_Weiss-1-400x248.jpg 400w, https://www.buchstabenmuseum.de/wp-content/uploads/2020/07/Teaser_BM_Studio_2_%C2%A9_Sebastian_Weiss-1.jpg 533w" sizes="(max-width: 800px) 100vw, 533px"></span></div><div><p><strong>You nead an A, Æ or Å?<br>
</strong>We have them all, we know them all and we can help you with your event or building signage. In the last 10 years we have supported many stages, parties or facades. Ask our BM-Studio Team!</p>
</div></div></div><div><div><span><img width="320" height="360" alt="illustration buchstabenmuseum" title="bm-unterstuetzen_en" src="https://www.buchstabenmuseum.de/wp-content/uploads/2017/10/bm-unterstuetzen_en.png" srcset="https://www.buchstabenmuseum.de/wp-content/uploads/2017/10/bm-unterstuetzen_en-200x225.png 200w, https://www.buchstabenmuseum.de/wp-content/uploads/2017/10/bm-unterstuetzen_en.png 320w" sizes="(max-width: 800px) 100vw, 320px"></span></div><div><h2></h2><h2>SUPPORT</h2></div><div><p>The&nbsp;Buchstabenmuseum has a new location!<br>
For our new exhibition we need urgently your help.</p>
</div></div><div><div><h2><p>— BECOME A MEMBER —</p></h2></div><div><span><img width="940" height="624" alt="illustration buchstabenmuseum" title="BM_Servus_©_Djamila_Grossman" src="https://www.buchstabenmuseum.de/wp-content/uploads/2021/03/BM_Servus_%C2%A9_Djamila_Grossman-1-1024x680.png" srcset="https://www.buchstabenmuseum.de/wp-content/uploads/2021/03/BM_Servus_%C2%A9_Djamila_Grossman-1-200x133.png 200w, https://www.buchstabenmuseum.de/wp-content/uploads/2021/03/BM_Servus_%C2%A9_Djamila_Grossman-1-400x265.png 400w, https://www.buchstabenmuseum.de/wp-content/uploads/2021/03/BM_Servus_%C2%A9_Djamila_Grossman-1-600x398.png 600w, https://www.buchstabenmuseum.de/wp-content/uploads/2021/03/BM_Servus_%C2%A9_Djamila_Grossman-1-800x531.png 800w, https://www.buchstabenmuseum.de/wp-content/uploads/2021/03/BM_Servus_%C2%A9_Djamila_Grossman-1-1200x796.png 1200w, https://www.buchstabenmuseum.de/wp-content/uploads/2021/03/BM_Servus_%C2%A9_Djamila_Grossman-1.png 1213w" sizes="(max-width: 800px) 100vw, 1200px"></span></div><div><p>Become a member of the club and actively support our museum.<br>
We are always in need of help with the rescue of historic lettering, looking after our international guests or even with the classic work of the association.<br>
Just write to us!<br>
<a href="mailto:bindabei@buchstabenmuseum.de">bindabei@buchstabenmuseum.de</a></p>
</div></div>
							</div>
																													</div>  <!-- fusion-row -->
				</main>  <!-- #main -->
				
				
								
					
		 <!-- fusion-footer -->

		
					

												</div> <!-- #boxed-wrapper -->
		
		
		
		<a></a>

		

			
		

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scientists are discovering a powerful new way to prevent cancer (147 pts)]]></title>
            <link>https://www.economist.com/science-and-technology/2025/09/02/scientists-are-discovering-a-powerful-new-way-to-prevent-cancer</link>
            <guid>45472614</guid>
            <pubDate>Sat, 04 Oct 2025 11:44:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/science-and-technology/2025/09/02/scientists-are-discovering-a-powerful-new-way-to-prevent-cancer">https://www.economist.com/science-and-technology/2025/09/02/scientists-are-discovering-a-powerful-new-way-to-prevent-cancer</a>, See on <a href="https://news.ycombinator.com/item?id=45472614">Hacker News</a></p>
Couldn't get https://www.economist.com/science-and-technology/2025/09/02/scientists-are-discovering-a-powerful-new-way-to-prevent-cancer: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Paged Out Issue #7 [pdf] (253 pts)]]></title>
            <link>https://pagedout.institute/download/PagedOut_007.pdf</link>
            <guid>45472319</guid>
            <pubDate>Sat, 04 Oct 2025 10:38:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pagedout.institute/download/PagedOut_007.pdf">https://pagedout.institute/download/PagedOut_007.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=45472319">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
    </channel>
</rss>