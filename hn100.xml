<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 18 Sep 2025 16:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Fuck, you're still sad? (193 pts)]]></title>
            <link>https://bessstillman.substack.com/p/oh-fuck-youre-still-sad</link>
            <guid>45290021</guid>
            <pubDate>Thu, 18 Sep 2025 14:17:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bessstillman.substack.com/p/oh-fuck-youre-still-sad">https://bessstillman.substack.com/p/oh-fuck-youre-still-sad</a>, See on <a href="https://news.ycombinator.com/item?id=45290021">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><audio src="https://bessstillman.substack.com/api/v1/audio/upload/fd01a944-08be-4ddd-ae11-37c2087b24e6/src" preload="auto">Audio playback is not supported on your browser. Please upgrade.</audio></p><p><strong>My husband Jake has been dead for a year and I still don’t believe it. </strong><span>Not really. Not when I look for his marginalia in new books, or read an article about self-driving cars and text him a link, or when I see an interesting new Malaysian restaurant and have the urge to make us a reservation. Certainly not when I look at our daughter, Athena, who wears Jake’s face as her own and who, especially when she’s examining an object closely, looks out at the world through the same perceptive brown eyes.</span></p><p>I can still see the future I’d imagined for us as clearly as I recall the past. In doing so, time collapses into a single point: Now. It feels like Jake is here right now.</p><p>Apparently, that’s a disease.</p><p><span>The American Psychiatric Association describes “disordered grief,” also known as “prolonged grief,” as a loss that occurred at least one measly year ago for adults (for children there’s an even faster grief clock). The diagnosis is made when people experience three of the following symptoms</span><s>,</s><span> every day</span><s>,</s><span> in the month before the diagnosis is made:</span></p><p>Avoidance of reminders the person has died; intense emotional pain; or, alternately, emotional numbness; difficulty with reintegration; feeling that life is meaningless; intense loneliness; feeling as though part of oneself has died; a marked sense of disbelief.</p><p>Just three?</p><p>I imagine a makeshift consensus group clad in tweed in some back room at a Psychiatric conference deciding on the shelf life of grief over coffee and Costco muffins, like it’s yogurt that’s starting to curdle. Is there a sniff test for pain? How long, exactly, is too long?</p><p>It took almost six months just to stop expecting Jake to text asking me to pick him up from Sky Harbor Airport – Terminal 3 – apologizing for his flight’s long delay. And although I no longer wonder if he’s about to walk through the door, my brain hasn’t given up the fleeting but frequent thought that he might still pick up the phone if I call.</p><p><span>There’s a persistent, searching feeling, as if he’s just around a corner. Last week, I met a friend at Cartel Coffee after work and was confused when she, not Jake, sat down on the couch beside me. Why had Jake sent her when he and I usually meet here after I work a night shift? Then yesterday, while loading groceries into the trunk of my car, I glanced back at the store entrance and thought- Jesus, is he </span><em>still </em><span>in the produce section picking out the perfect zucchini?</span></p><p><strong>In neuroscience, a prediction error refers to the discrepancy</strong><span> between what an organism expects to happen and what actually occurs. The ability to make accurate predictions comes from repetition. When Jake laughed at my stupid jokes every time I told them; when he got irritated because I pushed too hard with the nib of his fine-tipped pen, but still lent it to me anytime I asked; when he reached out to squeeze my hand whenever I felt anxious, that wasn’t just love—that was how I built the mental model of my life. When Jake died, even though he could no longer laugh at my jokes, or lend me a pen, or hold my hans, my brain still expected him to.</span></p><p><span>Dismantling that mental model</span><s>—</s><span>resolving the prediction error–also requires repetition. For a year, I’ve been freshly reminded that the clacking sound from the other room isn’t Jake at his keyboard, but the refrigerator making ice; the bed is always empty when I sneak in after a late shift; the text alert on my phone isn’t Jake sending me a photo of the fancy heirloom bean soup he made for dinner, but a spam message. Sometimes, I’ll go ahead and dial Jake’s phone number in case the laws of entropy have changed, and he picks up (hey, you never know), but his phone only ever rings and then drops to voicemail. He never even recorded a message.</span></p><p>Repetition is the only way to create accurate predictions. Repetition is the only way to dismantle them. And in doing so, dismantle myself. Grief, then, is a terrible kind of learning.</p><p><span>But it seems I’m a slow learner, and, as Jake would confirm, a resistant one: Last night I logged into Jake’s gmail and forwarded myself one of the weekly letters he used to send me, chasing the way my heart reflexively jumps when I see his name in my inbox–</span><s> </s><span>even if it was me who put it there.</span></p><p>So what if I cling to disbelief. In those moments of brief delusion, I feel like myself again.</p><p><span>Which only sharpens the truth: Part of me died with Jake. That’s not a symptom. It’s anatomy. </span><a href="https://bessstillman.substack.com/p/the-year-i-didnt-survive" rel="">My brain isn’t the same, and neither is my body</a><em>. </em><span>A person missing an arm isn’t told it’s a sickness to believe they’re structurally altered. A phantom limb is still gone, even if its ghost causes pain. Death, too, is an amputation.</span></p><p>In as little as six weeks, Axolotls can regrow not just their limbs, but parts of their brain. Starfish create an entire body from a single arm. Zebrafish can regenerate their heart.</p><p>What human has ever regrown their heart? And in just one year?</p><p><strong>For a diagnosis of disordered grief to be made, symptoms</strong><span> not only have to be present a year after the death, but “significantly impact daily life and functioning.” I can’t imagine anything that “significantly impacts”</span><s> </s><span>life </span><em>more</em><span> than death, and not only for the dead guy. And yet since the night Jake died, I’ve been able to shower, drive, and do laundry. I’ve birthed a baby, nursed her, and kept her alive. I’ve returned to work in the hospital and—as far as I know—I haven’t killed anyone. I pay my bills. I brush my teeth.</span></p><p><span>I function. I appear to function very well. Maybe that means I </span><em>am </em><span>well.</span></p><p><span>That’s not to say that I haven’t suspected otherwise. In the first months after Jake died, when I wasn’t paralyzed by grief, I thought that meant something was wrong with me. Then, seven months after Jake’s death, when I suddenly </span><em>was</em><span> paralyzed by grief, I thought that meant something was wrong with me. Countless self-help books reassure me that there’s “no right way to grieve,” but it definitely feels like there’s a wrong way, and we’re quick to diagnose it.</span></p><p><strong>We medicalize grief because we fear it</strong><span>. A diagnosis–</span><s> </s><span>naming what ails us</span><s> </s><span>–</span><s> </s><span>means we can fix it. Every shift I work, I have patients who are disappointed when I don’t have a clear diagnosis for them—even if it means I’ve ruled out a life-threatening one. Ambiguity means sitting with uncertainty and waiting to see how pain evolves. In a world where we swipe midway through 30 second video reels like rats hitting a cocaine lever, who has the patience for that? If what ails us has a name, that means we understand it. If we understand it, we can cure it, if we cure it, we won’t suffer.</span></p><p>Grief resists naming. It shifts and adapts. It’s not the same for any two people, or for any two losses.</p><p>Before the psychiatrists come for me, I understand that the spirit behind the diagnosis isn’t to pathologize a normal human experience, but to pathologize too much of that experience. As if there could be too much being human: Too much sadness. Too much struggle. Too much love.</p><p>I’m too much. And people, I think, are afraid of me. I walk into a room not as Bess, but as a reminder that awful things can happen randomly to any of us. When people first found out about Jake’s tongue cancer, they often asked what his risk factors were: did he smoke heavily? Was it HPV-positive? Did he chew tobacco? They needed to reassure themselves that their own lack of similar risks made them safe. And yet, Jake had no risk factors, which made askers visibly uncomfortable. I remember the way their faces strained to find a plausible explanation that, at the very least, excluded them from the horrible randomness of an impersonal universe.</p><p>I watch people perform the same futile calculations when they find out that I was widowed two months before the birth of my daughter. But what could the risk factors have possibly been for such a fate? What could I have done or not done that made me more susceptible to marrying a man who was dead by his 40th birthday?</p><p>Maybe the problem isn’t that my grief needs to resolve faster, but that other people need it to; then they can still believe that, when their grief comes, it will pass swiftly.</p><p><strong>There’s no modern cultural framework for dealing with death</strong><span>. We hide it, sanitize it, convince ourselves we have the technology to outsmart it, as if the singularity already occurred and we aren’t all still headed for the same six-</span><s> </s><span>foot hole. Memento mori have been replaced by positivity culture. And death, once part of public life, is tucked behind hospital walls for ER docs like me to witness. </span></p><p><span>The Victorians had mourning dress that made their grief visible. Ancient Greek funerals proceeded through the streets with professional wailers in their wake</span><strong>. </strong><span>Grief, once collective, is now treated as if it’s contagious. It’s like glitter: grief gets everywhere, attaches to everything; just walking past it means you’ll find it stuck to your own body in odd places for months.</span></p><p>Is it any wonder, then, that I’ve walked for miles with my baby daughter in her stroller, away from the gaze of family and friends, to keep my grief off display? So I can weep until my throat is raw. So I can sweat and scream until I’m filthy with rage. I duck into the bathroom at work whenever I feel tears coming, splash cold water on my face, and, ten seconds later, walk out with a smile and a wave to whoever is in the hallway.</p><p><span>And while time has taught me to manage the public messiness of grief, if anything, that’s given it space to grow in private. It feels a little shameful, the way it surges like desire behind closed doors, the way I wonder if it’s leaking out around my edges. Secretly–or maybe not so secretly now-I’ve thought: It’s been a </span><em>year</em><span>. Shouldn’t I be better by now?</span></p><p><span>But of course there’s still pain. Of course there’s still anger, bitterness and sorrow. Of course, there’s still loneliness-</span><s> </s><span>Jake’s remains are in a box on my bookshelf beside his copy of </span><em>Lord of the Rings</em><span> while his side of the bed remains empty. Our daughter Athena’s small, sticky hands rest on my cheek, her body dense and warm in my arms while I feed her from my own breast, and yet I’m still starving to be touched. Jake made me promise that I’d eat, and I do, but I’m never full. There’s a constant, baseline, gnawing ache.</span></p><p><strong><span>Maybe I’m repelled by the concept of “disordered grief</span><s>,</s><span>”</span></strong><span> because I can’t conceive of ordered grief. Grief resists linearity. I began grieving Jake while he was still alive, as the cancer relentlessly ate away at both his body and our future together. I still love him although he’s been dead for a year. My pain is recursive: I relentlessly cycle from moments of contentment or joy to shock and sadness and yearning, until the feelings become familiar, but no less breathtaking.</span></p><p><span>Every day grief comes in a different order. Some days I wake up at 4am, seized by the need to hold Jake’s hand</span><s>,</s><span> and feel anger that all I have is a plaster model of it. Other days, grief waits till I’m performing a physical exam on a patient and their wet cough reminds me of the way I would awaken in the middle of the night to hear Jake choking on his own saliva. Time seems to fold in on itself: Sometimes, I close my eyes while I breastfeed my daughter and the cocktail of oxytocin and prolactin saturates my brain in a way that resurrects Jake with hallucinatory vividness. Suddenly, we’re 27 and running out of the cold Seattle rain into Belle’s Buns for coffee, and then Athena unlatches from my nipple and I’ve lost him again.</span></p><p><strong>Time diverged when Jake died. </strong><span>For the rest of the world, a year has passed  since his death, and yet, somehow, it seems like it’s only just happened for me. At first, I was hurt when the flurry of concern and well-wishing that permeated the first weeks after his death naturally receded. Promised visits  failed to materialize. Calls were skipped. People move on with their own lives that continue at normal speed, while a large part of me is still kneeling beside Jake’s corpse, my fingers pressed against his absent pulse.</span></p><p>I don’t know how to resolve that discrepancy. How is it possible to reintegrate into a world that doesn’t understand that mine stopped? It’s hard enough trying to speak to people who haven’t experienced a similar loss, and even more difficult trying to be understood by people living a year in the future. I hadn’t realized before that grief isn’t an illness so much as a physics problem. Catching up may be impossible. I can only move so quickly.</p><p><strong>Every cure is about timing.</strong><span> When a patient comes to the emergency room, I’m only as useful as my ability to react quickly. It only helps if I give epinephrine to the anaphylactic before their throat closes and they develop a hypoxic brain injury. I have 90 minutes to get a patient with a massive heart attack diagnosed, stabilized and into the cardiac cath lab for stenting before their heart is irreversibly damaged. In a patient with a massive pulmonary embolism, I may only have minutes to administer tPA. My job, really, isn’t just to figure out that death is coming, but how fast. Sometimes, that’s impossible, and I lose the race. Other times–and these are the most exciting saves–a patient is clinically dead and I snatch them back. Sometimes it takes a few seconds; in extremely rare instances, hours.</span></p><p>But at no time in over a decade of training did I learn how long it takes to bring a person back to life when they’re not the one who’s died.</p><p><span>A year is nothing.</span><strong> </strong><span>Jake will be dead forever. Then I will be too. In the meantime, I’m not going to wait to be cured of grief so I can return to life. This</span><em> is</em><span> life.</span><em> </em><span>If you’re a mortal who loves other mortals the APA’s list isn’t a warning of what you might feel if you don’t grieve right; it’s a list of what you will feel, again and again, during a lifetime of discovering what’s still worth living for.</span></p><p>Is that sickness? I don’t feel sick. I just still feel love.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Gl2F!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff21a7141-8401-4529-80f5-ccae1e64a8bb_1086x724.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Gl2F!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff21a7141-8401-4529-80f5-ccae1e64a8bb_1086x724.jpeg 424w, https://substackcdn.com/image/fetch/$s_!Gl2F!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff21a7141-8401-4529-80f5-ccae1e64a8bb_1086x724.jpeg 848w, https://substackcdn.com/image/fetch/$s_!Gl2F!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff21a7141-8401-4529-80f5-ccae1e64a8bb_1086x724.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!Gl2F!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff21a7141-8401-4529-80f5-ccae1e64a8bb_1086x724.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Gl2F!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff21a7141-8401-4529-80f5-ccae1e64a8bb_1086x724.jpeg" width="1086" height="724" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f21a7141-8401-4529-80f5-ccae1e64a8bb_1086x724.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:724,&quot;width&quot;:1086,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:163207,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://bessstillman.substack.com/i/173911439?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff21a7141-8401-4529-80f5-ccae1e64a8bb_1086x724.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Gl2F!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff21a7141-8401-4529-80f5-ccae1e64a8bb_1086x724.jpeg 424w, https://substackcdn.com/image/fetch/$s_!Gl2F!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff21a7141-8401-4529-80f5-ccae1e64a8bb_1086x724.jpeg 848w, https://substackcdn.com/image/fetch/$s_!Gl2F!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff21a7141-8401-4529-80f5-ccae1e64a8bb_1086x724.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!Gl2F!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff21a7141-8401-4529-80f5-ccae1e64a8bb_1086x724.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Geizhals Preisvergleich Donates USD 10k to the Perl and Raku Foundation (128 pts)]]></title>
            <link>https://www.perl.com/article/geizhals-donates-to-tprf/</link>
            <guid>45289834</guid>
            <pubDate>Thu, 18 Sep 2025 14:01:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.perl.com/article/geizhals-donates-to-tprf/">https://www.perl.com/article/geizhals-donates-to-tprf/</a>, See on <a href="https://news.ycombinator.com/item?id=45289834">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
              
              <p>Sep 18, 2025 by
              
              
                
                
                <a href="#author-bio-olaf-alders">Olaf Alders</a>
              
              </p>
               <img alt="" src="https://www.perl.com/images/geizhals-donates-to-tprf/geizhals_logo_official.svg">
                <p>Today The Perl and Raku Foundation is thrilled to announce a donation of USD
10,000 from <a href="https://geizhals.at/">Geizhals Preisvergleich</a>. This gift helps to
secure the future of The Perl 5 Core Maintenance Fund.</p>
<blockquote>
<p>Perl has been an integral part of our product price comparison platform
from the start of the company 25 years ago. Supporting the Perl 5 Core
Maintenance Fund means supporting both present and future of a
substantial pillar of Modern Open Source Computing, for us and other
current or prospective users.</p></blockquote>
<p>– Michael Kröll of Geizhals Preisvergleich</p>
<blockquote>
<p>“Geizhals is not only providing core funding for the Perl ecosystem, but also
supporting developers, actively contributing to European conferences, and
employing Perl coders. Their interest in the strategic maintenance and
development of Perl and CPAN is of great value to us all, and their
investment is very much appreciated.”</p></blockquote>
<p>– Stuart J Mackintosh, President of The Perl and Raku Foundation</p>
<p>But who exactly is Geizhals, and why does their support matter so much to the
Perl community?</p>
<p>Geizhals Preisvergleich began in July of 1997 as a hobby project—and yes,
“Geizhals” literally translates to “skinflint” in English (they even operate
<a href="https://skinflint.co.uk/">skinflint.co.uk</a> for UK users!). From those humble
beginnings, they’ve leveraged the power of Perl to scale up to serving <a href="https://unternehmen.geizhals.at/">4.3
million monthly users</a>. With Perl being a key
part of their infrastructure, they have generously decided to support the Perl
5 Core Maintenance Fund.</p>
<p>While many of us know about the Core Maintenance Fund, the specific problems it
addresses often remain invisible to users. I reached out to the maintainers
whose work is supported by this fund. This is what core maintainer Tony Cook
had to say:</p>
<blockquote>
<p>My work tends to be little things, I review other people’s work which I think
improves quality and velocity, and fix more minor issues, some examples would
be:</p>
<ul>
<li>
<p>a fix to signal handling where perl could crash where an external library
created threads (<a href="https://github.com/perl/perl5/issues/22487">#22487</a>)</p>
</li>
<li>
<p>fix a segmentation fault in smartmatch against a sub if the sub exited via a
loop exit op (such as last)
(<a href="https://github.com/perl/perl5/issues/16608">#16608</a>)</p>
</li>
<li>
<p>fixed a bug where a regexp warning could leak memory.</p>
</li>
<li>
<p>prevent a confusing undefined warning message when accessing a sub
parameter that was placeholder for a hash element indexed by an
undef key (<a href="https://github.com/perl/perl5/issues/22423">#22423</a>)</p>
</li>
</ul></blockquote>
<p>What Tony has highlighted are the kinds of bug fixes which collectively help to
ensure that Perl remains stable, secure and reliable for the many organisations
and individuals who depend on it.</p>
<p>With organizations like Geizhals Preisvergleich funding the work which Tony and
others put into maintaining the Perl 5 core, we can work together to ensure that
the Perl core continues to receive the maintenance which it deserves, for many
years to come. Whether you’re a startup using Perl for rapid prototyping or an
enterprise running mission-critical systems, your support helps ensure Perl
remains reliable for everyone. Please join us on this journey.</p>
<p>For more information on how to become a sponsor, please contact:
<a href="mailto:olaf@perlfoundation.org">olaf@perlfoundation.org</a></p>

              </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[KDE is now my favorite desktop (397 pts)]]></title>
            <link>https://kokada.dev/blog/kde-is-now-my-favorite-desktop/</link>
            <guid>45288690</guid>
            <pubDate>Thu, 18 Sep 2025 12:17:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kokada.dev/blog/kde-is-now-my-favorite-desktop/">https://kokada.dev/blog/kde-is-now-my-favorite-desktop/</a>, See on <a href="https://news.ycombinator.com/item?id=45288690">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
            <p>From <a href="https://kokada.dev/blog/from-gaming-rig-to-personal-computer-my-journey-with-nixos-and-jovian">my last blog
post</a>,
I am now using KDE as the desktop environment for my gaming rig. The reason is
because I want a reasonably easy to use Linux desktop for when my wife needs to
use the PC for something other than gaming, and this was the reason why my
"traditional" <a href="https://swaywm.org/">Sway</a> setup was a no-go.</p>
<p>But, after using KDE for a while I am starting to really appreciate how good it
is. And no, this is not compared to other Linux desktops, but also with both
Windows and macOS (that I need to use often, especially the later since my job
gave me a MacBook Pro).</p>
<p>To start, KDE is surprisingly feature-complete. For example, the network applet
gives lots of information that in other operational systems are either not
available or difficult to access. It is easy to see in the screenshot below:</p>
<p><a href="https://github.com/thiagokokada/blog/raw/main/posts/2025-09-17/Screenshot_20250917_191837.png"><img src="https://github.com/thiagokokada/blog/raw/main/posts/2025-09-17/Screenshot_20250917_191837.png" alt="Wi-Fi information available in the network applet from
KDE"></a></p>
<p>You can see things like channel, signal strength, frequency, MAC address, BSSID
address (so the MAC address of the router). It even includes a handy button to
share the Wi-Fi information via QR code, so you can easily setup a new mobile
device like Android.</p>
<p>By the way, the crop and blur from that screenshot above? I made everything
using the integrated screenshot tool. I didn't need to open an external
application even once. It is also really smart, I need to redo this screenshot
a few times and it kept the cropping to the exact area I was taking the
screenshot before.</p>
<p>Another example, I wanted <a href="https://steamcommunity.com/">Steam</a> to start
automatically with the system, but it has the bad habit of putting its main
window at the top. Really annoying since it sometimes ended up stealing up the
focus. However KDE has this "Window Rules" feature inside "Window Management"
settings where you can pretty much control whatever you want about application
windows. Really useful tool.</p>
<p>KDE also has lots of really well integrated tools. For example, I am using some
Flatpak applications and I can easily configure the permissions via System
Settings. Or if I want hardware information like
<a href="https://en.wikipedia.org/wiki/Self-Monitoring,_Analysis_and_Reporting_Technology">SMART</a>
status, I can just open Info Center. I can prevent the screen and computer to
sleep at the click of a button (something that in both Windows and macOS I need
to install a separate program). The list goes on, I keep getting surprised how
many things that I used to need a third-party program that KDE just has
available by default.</p>
<p><a href="https://github.com/thiagokokada/blog/raw/main/posts/2025-09-17/Screenshot_20250917_192302.png"><img src="https://github.com/thiagokokada/blog/raw/main/posts/2025-09-17/Screenshot_20250917_192302.png" alt="Flatpak permission
management"></a></p>
<p>But not only KDE is fully featured, it is also fast. Now to be clear, this is
a completely subjective analysis but I find KDE faster than Windows 11 in the
same hardware, especially for things integrated in the system itself. For
example, while opening Windows settings it can take a few seconds after a cold
boot, the KDE's System Settings is pretty much instantaneous. Even compared
with macOS in my MacBook Pro M2 Pro (that is of course comparing Apples and
Bananas), KDE just feels snappier. I actually can't find much difference
between KDE and my Sway setup to be honest, except maybe for the heavy use of
animations (that can be disabled, but I ended up liking it after a while).</p>
<p>I will not say KDE is perfect though. At the first launch I got one issue where
it started without the task bar because I connected this PC to both my monitor
and TV, but the TV is used exclusively for gaming. However, KDE considered my
TV the primary desktop and put the task bar only in that monitor, and even
disabling the TV didn't add the task bar to my monitor. Easily fixed by
manually adding a task bar, but an annoying problem (especially when you're not
used to the desktop). There were also a few other minor issues that I don't
remember right now.</p>
<p>After using KDE for about a week I can say that this is the first time that I
really enjoy a desktop environment on Linux, after all those years. Props for
the KDE developers for making the experience so good.</p>
<p><a href="https://github.com/thiagokokada/blog/raw/main/posts/2025-09-17/Screenshot_20250917_195215.png"><img src="https://github.com/thiagokokada/blog/raw/main/posts/2025-09-17/Screenshot_20250917_195215.png" alt="About this System"></a></p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You Had No Taste Before AI (175 pts)]]></title>
            <link>https://matthewsanabria.dev/posts/you-had-no-taste-before-ai/</link>
            <guid>45288551</guid>
            <pubDate>Thu, 18 Sep 2025 12:00:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matthewsanabria.dev/posts/you-had-no-taste-before-ai/">https://matthewsanabria.dev/posts/you-had-no-taste-before-ai/</a>, See on <a href="https://news.ycombinator.com/item?id=45288551">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>There’s been an influx of people telling others to develop taste to use AI.
Designers. Marketers. Developers. All of them touting the same message. It’s
ironic, though. These are the same people who never questioned why their designs
all look identical, never iterated beyond the first draft, and never asked if
their work actually solved the problem at hand.</p>
<p>They’re not alone. The loudest voices preaching about taste and AI are often the
ones who never demonstrated taste before AI.</p>
<h2 id="what-is-taste">What is Taste? <span><a href="#what-is-taste" aria-label="Anchor">#</a></span></h2><p>The technology industry has a tendency to use words that mean multiple things
without describing which definition they are referring to. When I read about
taste and AI I usually see people referring to the following definition.</p>
<blockquote>
<p>Critical judgment, discernment, or appreciation of aesthetic quality.</p></blockquote>
<p>In the context of AI, this definition manifests itself in several ways.</p>
<p><strong>Contextual Appropriateness</strong>: Knowing when AI-generated content fits the
situation and when it doesn’t. Put another way, knowing when a human touch is
needed (e.g., a message to a loved one).</p>
<p><strong>Quality Recognition</strong>: Being able to distinguish between useful AI-generated
content and slop. This requires domain knowledge to truly discern aesthetic
quality rather than just functional quality.</p>
<p><strong>Iterative Refinement</strong>: Understanding that AI is a starting point that
requires further iteration. This point is most similar to how culinary taste is
applied to refine a dish by iterating on the recipe and presentation.</p>
<p><strong>Ethical Boundaries</strong>: Recognizing when AI crosses the lines of authenticity,
legality, and respect. Basically, don’t use AI to do bad things.</p>
<p>None of these skills are new. These are the same skills we should have been
applying to our work all along. Why are we asking about taste and AI now when
we should have been applying taste the whole time? Perhaps people advocating for
taste are telling on themselves.</p>
<h2 id="being-tasteless">Being Tasteless <span><a href="#being-tasteless" aria-label="Anchor">#</a></span></h2><p>Some people have no taste. In the best case that may be due to lack of
experience but in the worst case it may be due to ignorance. I’m noticing that
many people worried about tasteless AI-generated content are often guilty of
producing tasteless content themselves, usually manifesting as the following.</p>
<ul>
<li>
<p>Copying and pasting code without understanding it.</p>
</li>
<li>
<p>Sending resumes and emails that aren’t proofread and edited.</p>
</li>
<li>
<p>Asking others to review code without giving it a self review.</p>
</li>
<li>
<p>Noticing a quality issue and failing to document or fix it.</p>
</li>
<li>
<p>Designing websites that look exactly like every other company’s website.</p>
</li>
<li>
<p>Regurgitating content from the trending influencer of the week.</p>
</li>
</ul>
<p>Where’s the taste here? Where’s the critical judgment, discernment, or
appreciation of aesthetic quality that separates mediocrity from excellence?</p>
<p>It’s not there because most people haven’t developed their taste yet. AI didn’t
create this tasteless problem. People did. Now that everyone can generate
content at the speed of thought we’re noticing that not all content is actually
good. To play on a popular quote from Ratatouille, anyone can cook, but not
everyone is a chef. Don’t complain about mediocre work when you’re producing
mediocre work yourself.</p>
<h2 id="spectrum-of-taste">Spectrum of Taste <span><a href="#spectrum-of-taste" aria-label="Anchor">#</a></span></h2><p>What about the nature of taste itself? Should people focus on developing depth
of taste in specific domains or breadth of taste across many domains? My short
answer is a bit of both, if possible.</p>
<p>Depth of taste means becoming an expert within a particular domain. We’ve all
met such experts and even asked them for help on tricky, bespoke topics within
their domain. A person with depth of taste can recognize when AI-generated
content is refined and of high quality versus merely functional. This kind of
taste comes from years of experience in a specific role coupled with deep domain
knowledge.</p>
<p>Breadth of taste means becoming knowledgeable across multiple domains and
understanding how those domains interface with one another. A person with
breadth of taste can recognize when AI-generated content is contextually
appropriate, authentic, and of enough quality to use for their needs. This
kind of taste comes from years of experience across multiple roles coupled with
moderate domain knowledge.</p>
<p>Breadth of taste is more valuable with AI. When using AI, you’re constantly
switching between domains: a software engineer writing documentation, a marketer
creating designs. Breadth lets you maintain quality across these contexts while
recognizing when you need domain expertise. You iterate faster because you have
opinions about what “good enough” looks like across multiple domains.</p>
<p>The people I see being most effective with AI developed a breadth of taste that
they use to determine what good AI-generated content looks like, regardless
of domain. They can recognize when something feels off, even if they can’t
articulate exactly why. They understand their own limitations and know when to
seek expertise in a specific domain. That’s not to say those with depth of taste
can’t be successful with AI, but I see those people reluctant to use AI because
they are more knowledgeable than AI in a particular domain.</p>
<h2 id="it-tastes-bitter">It Tastes Bitter <span><a href="#it-tastes-bitter" aria-label="Anchor">#</a></span></h2><p>If you’re reading this thinking you have to spend time developing your taste,
good! Perhaps I’ve left a bitter taste in your mouth. The good news is you’re
not alone. There are many people that need to hear this to better their
taste, myself included. The challenge here is recognizing that it’s not about
developing taste for AI but rather about developing taste, period. If you’ve had
poor taste before AI you’ll have poor taste with AI. If you’ve had good taste
before AI, you’ll be able to apply that taste with AI.</p>
<p>Instead of treating AI taste as some mystical new skill, focus on the
fundamentals that were always important. Here are some actionable ways to
develop your taste.</p>
<p><strong>Tomorrow</strong>: Pick one piece of work you’re proud of and one you’re not.
Write down specifically what makes them different. That’s taste in action.</p>
<p><strong>This week</strong>: Find three examples of excellence in a domain you work in. Study
them. What patterns emerge? What choices did the creators make?</p>
<p><strong>This month</strong>: Take something you’ve created with or without AI and iterate
on it a few times. Each iteration should have a specific improvement based on a
specific critique.</p>
<p><strong>Always</strong>: When someone preaches about AI taste, ask them to show you their
work from before AI. If they can’t demonstrate taste in their pre-AI work,
they’re not qualified to lecture you about it now.</p>
<p>The people succeeding with AI aren’t the ones who suddenly discovered taste.
They’re the ones who already had it and simply adapted their standards to a
new tool. Develop your taste with or without AI. The medium doesn’t matter, the
fundamentals do.</p>
<p>Stop waiting for AI to force you to develop taste. Start now.</p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nvidia buys $5B in Intel stock in seismic deal (312 pts)]]></title>
            <link>https://www.tomshardware.com/pc-components/cpus/nvidia-and-intel-announce-jointly-developed-intel-x86-rtx-socs-for-pcs-with-nvidia-graphics-also-custom-nvidia-data-center-x86-processors-nvidia-buys-usd5-billion-in-intel-stock-in-seismic-deal</link>
            <guid>45288161</guid>
            <pubDate>Thu, 18 Sep 2025 11:04:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/pc-components/cpus/nvidia-and-intel-announce-jointly-developed-intel-x86-rtx-socs-for-pcs-with-nvidia-graphics-also-custom-nvidia-data-center-x86-processors-nvidia-buys-usd5-billion-in-intel-stock-in-seismic-deal">https://www.tomshardware.com/pc-components/cpus/nvidia-and-intel-announce-jointly-developed-intel-x86-rtx-socs-for-pcs-with-nvidia-graphics-also-custom-nvidia-data-center-x86-processors-nvidia-buys-usd5-billion-in-intel-stock-in-seismic-deal</a>, See on <a href="https://news.ycombinator.com/item?id=45288161">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">
<section>
<div>
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-1856-80.png.webp 1920w, https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-1200-80.png.webp 1200w, https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-1024-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-970-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-320-80.png.webp 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH.png" alt="asdf" srcset="https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-1856-80.png 1920w, https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-1200-80.png 1200w, https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-1024-80.png 1024w, https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-970-80.png 970w, https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH-320-80.png 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/gBeVGpDwSKA49BwFrqRooH.png" data-pin-nopin="true" fetchpriority="high">
</picture>
</div>
<figcaption>
<span>(Image credit: Nvidia)</span>
</figcaption>
</div>

<div id="article-body">
<p id="dd0fa8e5-b304-4f38-98c1-c6e171c2a53a">In a surprise announcement that finds two long-time rivals working together, Nvidia and Intel announced today that the companies will jointly develop multiple new generations of x86 products together — a seismic shift with profound implications for the entire world of technology. Before the news broke, Tom's Hardware spoke with Nvidia representatives to learn more details about the company’s plans.</p><p>The products include x86 Intel CPUs tightly fused with an Nvidia RTX graphics chiplet for the consumer gaming PC market, named the ‘Intel x86 RTX SOCs.’ Nvidia will also have Intel build custom x86 data center CPUs for its AI products for hyperscale and enterprise customers. Additionally, Nvidia will buy $5 billion in Intel common stock at $23.28 per share, representing a roughly 5% ownership stake in Intel. (Intel stock is now up 33% in premarket trading.)</p><p>Nvidia emphasized that the companies are committed to multi-generation roadmaps for the co-developed products, which represents a strong investment in the x86 ecosystem. But representatives tells us it also remains fully committed to other announced product roadmaps and architectures, including the company's Arm-based <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/nvidias-project-digits-desktop-ai-supercomputer-fits-in-the-palm-of-your-hand-usd3-000-to-bring-1-pflops-of-performance-home" data-before-rewrite-localise="https://www.tomshardware.com/pc-components/gpus/nvidias-project-digits-desktop-ai-supercomputer-fits-in-the-palm-of-your-hand-usd3-000-to-bring-1-pflops-of-performance-home">GB10 Grace Blackwell processors for workstations</a> and the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/nvidia-unveils-144-core-grace-cpu-superchip-claims-arm-chip-15x-faster-than-amds-epyc-rome" data-before-rewrite-localise="https://www.tomshardware.com/news/nvidia-unveils-144-core-grace-cpu-superchip-claims-arm-chip-15x-faster-than-amds-epyc-rome">Nvidia Grace</a> <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/nvidia-details-grace-hopper-cpu-superchip-design-144-cores-on-4n-tsmc-process" data-before-rewrite-localise="https://www.tomshardware.com/news/nvidia-details-grace-hopper-cpu-superchip-design-144-cores-on-4n-tsmc-process">CPUs for data centers</a>, as well as the next-gen <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/artificial-intelligence/nvidias-rubin-gpu-and-vera-cpu-data-center-ai-platforms-begin-tape-out-both-chips-in-fab-and-on-track-for-2026" data-before-rewrite-localise="https://www.tomshardware.com/tech-industry/artificial-intelligence/nvidias-rubin-gpu-and-vera-cpu-data-center-ai-platforms-begin-tape-out-both-chips-in-fab-and-on-track-for-2026">Vera CPUs</a>. Nvidia says it also remains committed to products on its internal roadmaps that haven’t been publicly disclosed yet, indicating that the new roadmap with Intel will merely be additive to existing initiatives.</p><p>The chip giant hasn’t disclosed whether it will use Intel Foundry to produce any of these products yet. However, while Intel has used TSMC to manufacture some recent products, its goal is to bring production of most high-performance products back into its own foundries.</p><p>Some products never left. For instance, Intel’s existing <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/intel-launches-granite-rapids-xeon-6900p-series-with-120-cores-matches-amd-epycs-core-counts-for-the-first-time-since-2017" data-before-rewrite-localise="https://www.tomshardware.com/pc-components/cpus/intel-launches-granite-rapids-xeon-6900p-series-with-120-cores-matches-amd-epycs-core-counts-for-the-first-time-since-2017">Granite Rapids</a> data center processors use the ‘Intel 3’ node, and the upcoming <a data-analytics-id="inline-link" href="https://www.tomshardware.com/desktops/servers/intel-reveals-288-core-xeon" data-before-rewrite-localise="https://www.tomshardware.com/desktops/servers/intel-reveals-288-core-xeon">Clearwater Forest Xeons</a> will use Intel’s own 18A process node for compute. This suggests that at least some of the Nvidia-custom x86 silicon, particularly for the data center, <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/nvidia-ceo-intel-test-chip-results-for-next-gen-process-look-good" data-before-rewrite-localise="https://www.tomshardware.com/news/nvidia-ceo-intel-test-chip-results-for-next-gen-process-look-good">could be fabbed on Intel nodes</a>. Intel also uses TSMC to fabricate many of its client x86 processors, however, so we won’t know for sure until official announcements are made — particularly for the RTX GPU chiplet.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-6S7ZPUsULrjZhoioYnhg6Z"><section><p>Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.</p></section></div><p>While the two companies have engaged in heated competition in some market segments, Intel and Nvidia have partnered for decades, ensuring interoperability between their hardware and software for products spanning both the client and data center markets. And the PCIe interface has long been used to connect Intel CPUs and Nvidia GPUs. The new partnership will find tighter integration using the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/nvidia-announces-nvlink-fusion-to-allow-custom-cpus-and-ai-accelerators-to-work-with-its-products" data-before-rewrite-localise="https://www.tomshardware.com/pc-components/cpus/nvidia-announces-nvlink-fusion-to-allow-custom-cpus-and-ai-accelerators-to-work-with-its-products">NVLink interface for CPU-to-GPU communication</a>, which affords up to 14 times more bandwidth along with lower latency than PCIe, thus granting the new x86 products access to the highest performance possible when paired with GPUs. Let’s dive into the details we’ve learned so far.</p><h2 id="intel-x86-rtx-socs-for-the-pc-gaming-market-3">Intel x86 RTX SOCs for the PC gaming market</h2><p id="ca731ff8-3e95-42f5-affb-2bcbd162c7fc">For the PC market, the Intel x86 RTX SoC chips will come with an x86 CPU chiplet tightly connected with an Nvidia RTX GPU chiplet via the NVLink interface. This type of processor will have both CPU and GPU units merged into one compact chip package that externally looks much like a standard CPU, rivaling AMD’s competing APU products.</p><p>This type of tight integration packs all the gaming prowess into one package without an external discrete GPU, providing power and footprint advantages. As such, these chips will be heavily focused on thin-and-light gaming laptops and small form-factor PCs, much like today’s APUs from AMD. However, it’s possible the new Nvidia/Intel chips could come in multiple flavors and permeate further into the Intel stack over time.</p><p>Intel has worked on a similar type of chip before with AMD; there is at least one significant technical difference between these initiatives, however. Intel launched its <a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/intel-hades-canyon-nuc-vr,5536.html" data-before-rewrite-localise="https://www.tomshardware.com/reviews/intel-hades-canyon-nuc-vr,5536.html">Kaby Lake-G chip in 2017</a> with an Intel processor fused into the same package as an AMD Radeon GPU chiplet, much the same as the description of the new Nvidia/Intel chips. You can see an image of the Intel/AMD chip below.</p><div aria-hidden="false" data-swipeable="true" data-hydrate="true" id="slice-container-imageGallery-6S7ZPUsULrjZhoioYnhg6Z-r0GQqSmxKDyfaegDCSFcLIEvP0Ymx0AV"><figure data-bordeaux-image-check="false"><div><picture data-hydrate="true"><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-1200-80.jpg.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-normal="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm.jpg" data-original-mos="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm.jpg" data-pin-nopin="true" data-slice-image="true"><source type="image/jpeg" srcset="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-1200-80.jpg 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-normal="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm.jpg" data-original-mos="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm.jpg" data-pin-nopin="true" data-slice-image="true"><img src="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm.jpg" alt="sdf" srcset="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm-1200-80.jpg 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-normal="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm.jpg" data-original-mos="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/v86mjFRvYe7QGC7NP6gPLm.jpg" data-pin-nopin="true" data-slice-image="true"></picture></div><figcaption><span>An RTX GPU chiplet connected to an Intel CPU chiplet via the fast and efficient NVLink interface. </span></figcaption></figure></div><p id="06b33e49-7ca0-467a-933e-b68f8f0ddbe8">This SoC had a CPU at one end connected via a PCIe connection to the separate AMD GPU chiplet, which is flanked by a small, dedicated memory package. This separate memory package was only usable by the GPU. The Nvidia/Intel products will have an RTX GPU chiplet connected to the CPU chiplet via the faster and more efficient NVLink interface, and we’re told it will have uniform memory access (UMA), meaning both the CPU and GPU will be able to access the same pool of memory.</p><p>Intel notoriously <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/intel-discontinue-kaby-lake-g-amd-graphics,40577.html" data-before-rewrite-localise="https://www.tomshardware.com/news/intel-discontinue-kaby-lake-g-amd-graphics,40577.html">axed the Kaby Lake-G products in 2019</a>, and the existing systems were <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/intel-graphics-driver-update-hades-canyon-amd-12-month-delay" data-before-rewrite-localise="https://www.tomshardware.com/news/intel-graphics-driver-update-hades-canyon-amd-12-month-delay">left without proper driver support</a> for <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/windows-11-kaby-lake-g-drivers" data-before-rewrite-localise="https://www.tomshardware.com/news/windows-11-kaby-lake-g-drivers">quite some time</a>, in part because Intel was responsible for validating the drivers, and then finger-pointing ensued. We’re told that both Intel and Nvidia will be responsible for their respective drivers for the new models, with Nvidia naturally providing its own GPU drivers. However, Intel will build and sell the consumer processors.</p><p>We haven’t spoken with Intel yet, but the limited scope of this project means that Intel’s proprietary Xe graphics architecture will most assuredly live on as the primary integrated GPU (iGPU) for its mass-market products.</p><h2 id="nvidia-s-first-x86-data-center-cpus-3">Nvidia's first x86 data center CPUs</h2><p id="7fcd26a5-8509-41c5-a5da-0629cef0d258">Intel will fabricate custom x86 data center CPUs for Nvidia, which Nvidia will then sell as its own products to enterprise and data center customers. However, the entirety and extent of the modification are currently unknown. We do know that Nvidia will employ its NVLink interface, which tells us the chips could leverage Nvidia’s new <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/nvidia-announces-nvlink-fusion-to-allow-custom-cpus-and-ai-accelerators-to-work-with-its-products" data-before-rewrite-localise="https://www.tomshardware.com/pc-components/cpus/nvidia-announces-nvlink-fusion-to-allow-custom-cpus-and-ai-accelerators-to-work-with-its-products">NVLink Fusion</a> tech that enables custom CPUs and accelerators to enable faster, more efficient communication with Nvidia’s GPUs than found with the PCIe interface.</p><figure data-bordeaux-image-check="" id="7ade6161-9180-406c-b223-19e2635b8553"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi-1200-80.png.webp 1200w, https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi-1024-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi-970-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi-320-80.png.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi.png" alt="NVLink Fusion" srcset="https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi-1200-80.png 1200w, https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi-1024-80.png 1024w, https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi-970-80.png 970w, https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi-320-80.png 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/MftMZVxs3dkte2VoNsxtMi.png">
</picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: Nvidia)</span></figcaption></figure><p id="730616fb-ebb0-4d0b-a3de-38195e8eb02e">Intel has long offered custom Xeons to its customers, primarily hyperscalers, often with relatively minor tweaks to clock rates, cache capacities, and other specifications. In fact, these mostly slightly-modified custom Xeon models once comprised more than 50% of Intel’s Xeon shipments. Intel has endured several years of market share erosion due to AMD’s advances, most acutely in the hyperscale market. Therefore, it is unclear if the 50% number still holds true, as hyperscalers were the primary customers for custom models.</p><p>Intel has <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/intel-announces-idm-20-foundry" data-before-rewrite-localise="https://www.tomshardware.com/news/intel-announces-idm-20-foundry">long said that it will design completely custom x86 chips for customers</a> as part of its IDM 2.0 strategy. However, aside from a recent announcement of <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/intel-outlines-a-plan-to-get-back-in-the-game-pause-fab-projects-in-europe-make-the-foundry-unit-an-independent-subsidiary-and-streamline-the-x86-portfolio" data-before-rewrite-localise="https://www.tomshardware.com/pc-components/cpus/intel-outlines-a-plan-to-get-back-in-the-game-pause-fab-projects-in-europe-make-the-foundry-unit-an-independent-subsidiary-and-streamline-the-x86-portfolio">custom AWS chips</a> that sound like the slightly modified Xeons mentioned above, we haven’t heard of any large-scale uptake for significantly modified custom x86 processors. Intel <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/intel-ousts-ceo-of-products-as-part-of-the-latest-executive-shake-up-ending-30-year-career-company-also-establishes-new-custom-chip-design-unit" data-before-rewrite-localise="https://www.tomshardware.com/tech-industry/intel-ousts-ceo-of-products-as-part-of-the-latest-executive-shake-up-ending-30-year-career-company-also-establishes-new-custom-chip-design-unit">announced a new custom chip design unit just two weeks ago</a>, so it will be interesting to learn the extent of the customization for Nvidia’s x86 data center CPUs.</p><p>Nvidia already uses Intel’s Xeons in several of its systems, like the Nvidia DGX B300, but these systems still use the PCIe interface to communicate with the CPU. Intel’s new collaboration with Nvidia will obviously open up new opportunities, given the tighter integration with NVLink and all the advantages it brings with it. The likelihood of AMD adopting NVLink Fusion is somewhere around zero, as the company is heavily invested in its own <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/amd-infinity-fabric-cpu-to-gpu" data-before-rewrite-localise="https://www.tomshardware.com/news/amd-infinity-fabric-cpu-to-gpu">Infinity Fabric (XGMI)</a> and <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/ualink-has-nvidias-nvlink-in-the-crosshairs-final-specs-support-up-to-1-024-gpus-with-200-gt-s-bandwidth" data-before-rewrite-localise="https://www.tomshardware.com/tech-industry/ualink-has-nvidias-nvlink-in-the-crosshairs-final-specs-support-up-to-1-024-gpus-with-200-gt-s-bandwidth">Ultra Accelerator Link (UALink)</a> initiatives, which aim to provide an open-standard interconnect to rival NVLink and democratize rack-scale interconnect technologies. Intel is also a member of UALink, which uses AMD’s Infinity Fabric protocol as the foundation.</p><h2 id="dollar-and-cents-geopolitics-3">Dollar and Cents, Geopolitics</h2><p id="e09444e0-bebc-4edc-83cf-79a58ac357b5">Nvidia’s $5 billion purchase of Intel common stock will come at $23.28 a share, roughly 6% below the current market value, but several aspects of this investment remain unclear. Nvidia hasn’t stated whether it will have a seat on the board (which is unlikely) or how it will vote on matters requiring shareholder approval. It is also unclear if Intel will issue new stock (primary issuance) for Nvidia to purchase, as it did when the U.S. government recently became an Intel shareholder (that is likely). Naturally, the investment is subject to approval from regulators.</p><p>Nvidia’s buy-in comes on the heels of the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/big-tech/trump-says-u-s-govt-will-take-a-10-percent-ownership-stake-in-intel-lip-bu-tan-reportedly-agreed-to-unprecedented-arrangement-for-a-domestic-chipmaker" data-before-rewrite-localise="https://www.tomshardware.com/tech-industry/big-tech/trump-says-u-s-govt-will-take-a-10-percent-ownership-stake-in-intel-lip-bu-tan-reportedly-agreed-to-unprecedented-arrangement-for-a-domestic-chipmaker">U.S government buying $10 billion of newly-created Intel stock</a>, granting the country a 9.9% ownership stake at $20.47 per share. The U.S. government won’t have a seat on the board and agreed to vote with Intel’s board on matters requiring shareholder approval “with limited exceptions.” <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/semiconductors/softbank-to-buy-usd2-billion-in-intel-shares-at-usd23-each-firm-still-owns-majority-share-of-arm" data-before-rewrite-localise="https://www.tomshardware.com/tech-industry/semiconductors/softbank-to-buy-usd2-billion-in-intel-shares-at-usd23-each-firm-still-owns-majority-share-of-arm">Softbank has also recently purchased $2 billion worth of primary issuance Intel stock</a> at $23 per share.</p><div id="slice-container-table-6S7ZPUsULrjZhoioYnhg6Z-JiGkjEwwBtiv7WLzNY6ijtNd9T35JBCY"><div><p>Swipe to scroll horizontally</p><svg viewBox="0 0 23 30" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M21.554 15.726a2.878 2.878 0 0 0-1.705-.374 2.881 2.881 0 0 0-1.388-3.068 2.877 2.877 0 0 0-1.992-.333 2.884 2.884 0 0 0-.1-.766 2.865 2.865 0 0 0-1.346-1.75c-.47-.27-.996-.4-1.527-.385l2.742-4.73a2.87 2.87 0 0 0 .323-.83h2.612V2.084h-2.661A2.861 2.861 0 0 0 15.18.385a2.903 2.903 0 0 0-3.952 1.055l-.373.644H2.983l1.003-1L2.99.09 1.28 1.793l-.999.995L2.99 5.484l.998-.994-1.003-.999h7.054L6.505 9.586c-.34.066-.905.186-1.523.366-1.405.41-2.321.895-2.8 1.483-.742.911-1.159 2.513-1.277 4.898l-.001.01c-.067 1.816.946 6.943.99 7.16a.688.688 0 0 0 1.35-.266c-.01-.051-1.023-5.177-.963-6.84.127-2.556.598-3.64.97-4.098.133-.163.602-.587 2.104-1.027l.206-.058-1.425 2.458a.685.685 0 0 0 .252.937c.33.19.75.077.94-.251L12.42 2.126a1.52 1.52 0 0 1 2.07-.552c.35.2.6.527.705.916.105.39.051.797-.15 1.145l-4.767 8.222a.685.685 0 0 0 .252.937c.33.19.75.077.94-.25l.794-1.368c.201-.348.529-.597.92-.702a1.508 1.508 0 0 1 1.854 1.066c.105.39.052.796-.15 1.144l-.377.652-.002.002-.898 1.55a.685.685 0 0 0 .252.938c.329.189.75.077.94-.251l.9-1.551c.201-.348.528-.597.92-.702a1.512 1.512 0 0 1 1.703 2.21l-1.223 2.11a.685.685 0 0 0 .252.938c.33.189.75.076.941-.252l.5-.862c.202-.348.529-.597.92-.702.392-.104.8-.051 1.15.15.723.416.972 1.34.554 2.06l-3.525 6.08c-.517.892-1.57 1.795-3.044 2.611-1.156.64-2.163.998-2.173 1.002a.685.685 0 0 0 .23 1.333.688.688 0 0 0 .229-.04c.18-.062 4.419-1.575 5.952-4.22l3.524-6.08a2.878 2.878 0 0 0-1.059-3.934Z" fill="#333"></path></svg></div><div><table tabindex="0"><caption>Purchases of Intel Stock</caption><tbody><tr><td colspan="1"><span>Row 0 - Cell 0 </span></td><td colspan="1"><p>Total</p></td><td colspan="1"><p>Share Price</p></td><td colspan="1"><p>Stake in Intel</p></td></tr><tr><td colspan="1"><p>Nvidia</p></td><td colspan="1"><p>$5 Billion</p></td><td colspan="1"><p>$23.28</p></td><td colspan="1"><p>~5%</p></td></tr><tr><td colspan="1"><p>U.S. Government</p></td><td colspan="1"><p>$9 Billion</p></td><td colspan="1"><p>$20.47</p></td><td colspan="1"><p>~9.9%</p></td></tr><tr><td colspan="1"><p>Softbank</p></td><td colspan="1"><p>$2 Billion</p></td><td colspan="1"><p>$23</p></td><td colspan="1"><span>Row 3 - Cell 3 </span></td></tr></tbody></table></div></div><p id="c44d2679-944b-4a74-827f-1a98316271f9">The U.S. government says it invested in Intel with the goal of bolstering US technology, manufacturing, and national security, and the investments from the private sector also help solidify the struggling Intel. Altogether, these investments represent a significant cash influx for Intel as it attempts to maintain the heavy cap-ex investments required to compete with TSMC, all while struggling with a negative amount of free cash flow.</p><p>“AI is powering a new industrial revolution and reinventing every layer of the computing stack — from silicon to systems to software. At the heart of this reinvention is Nvidia’s CUDA architecture,” said Nvidia CEO Jensen Huang. “This historic collaboration tightly couples NVIDIA’s AI and accelerated computing stack with Intel’s CPUs and the vast x86 ecosystem—a fusion of two world-class platforms. Together, we will expand our ecosystems and lay the foundation for the next era of computing.”</p><p>“Intel’s x86 architecture has been foundational to modern computing for decades – and we are innovating across our portfolio to enable the workloads of the future,” said Intel CEO Lip-Bu Tan. “Intel’s leading data center and client computing platforms, combined with our process technology, manufacturing and advanced packaging capabilities, will complement Nvidia's AI and accelerated computing leadership to enable new breakthroughs for the industry. We appreciate the confidence Jensen and the Nvidia team have placed in us with their investment and look forward to the work ahead as we innovate for customers and grow our business.”</p><p>We’ll learn more details of the new partnership later today when Nvidia CEO Jensen Huang and Intel CEO Lip-Bu Tan hold a <a data-analytics-id="inline-link" href="https://events.q4inc.com/attendee/108505485" data-url="https://events.q4inc.com/attendee/108505485" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">webcast press conference at 10 am PT</a>.</p><p><em><strong>This is breaking news…more to come.</strong></em></p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank" data-url="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"><em>Tom's Hardware on Google News</em></a><em>, or </em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank" data-url="https://google.com/preferences/source?q=" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"><em>add us as a preferred source</em></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
</div>



<!-- Drop in a standard article here maybe? -->




<div id="slice-container-authorBio-6S7ZPUsULrjZhoioYnhg6Z"><p>Paul Alcorn is the Editor-in-Chief for Tom's Hardware US. He also writes news and reviews on CPUs, storage, and enterprise hardware.</p></div>
</section>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[This Website Has No Class (159 pts)]]></title>
            <link>https://aaadaaam.com/notes/no-class/</link>
            <guid>45287155</guid>
            <pubDate>Thu, 18 Sep 2025 08:41:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aaadaaam.com/notes/no-class/">https://aaadaaam.com/notes/no-class/</a>, See on <a href="https://news.ycombinator.com/item?id=45287155">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
  <article animate-children="">
    <time><span>Sep 14, 2025</span></time>
    
    <p>In my recent post, <a href="https://aaadaaam.com/notes/useful-defaults/">“There’s no such thing as a CSS reset”</a>, I wrote this:</p>
<blockquote>
<p>Think of elements like components, but ones that come packed in the browser. Custom elements, without the “custom” part. You can just like, <em>use them</em>.</p>
</blockquote>
<p>The line continued to rattle around in my head, and a few weeks later when I was digging into some cleanup work I came to an uncomfortable realization; <em>I wasn’t really taking my own advice</em>. Sure, I was setting some default element styles, but I was leaving <em>a lot</em> on the table. I felt attacked. Called out even. Present me, <em>positively roasted</em> by past me. There was only one possible solution; <strong>refactor my website.</strong></p>
<p>I like to apply severe constraints in designing and building this site – I think constraints lead to interesting, creative solutions – and it was no different this time around. Instead of relying on built in elements <em>a bit more</em>, I decided to <em>banish classes from my website completely</em>. I haven’t used a class-free approach since the CSS Zen Garden days, and wanted to se how it felt with modern HTML and CSS.</p>
<h2 id="doubling-down-on-styled-defaults">Doubling down on styled defaults</h2>
<p>CSS for the site was structured around 3 cascade layers; <code>base</code>, <code>components</code>, and <code>utilities</code>. Everything in <code>base</code> was already tag selectors, so the task at hand was to change my approach for components, and eliminate utilities completely.</p>
<p>Step 1? <em>Mitigation.</em> There was plenty of code that could have been styled defaults but wasn’t, so I gave all my markup a thorough review, increasing use of semantic elements, extracting common patterns in the form of new element defaults, and making more use of contextual element styling. By contextual styling, I mean going from something like this:</p>
<pre><code><span>.header-primary</span> <span>{</span>
  <span>margin-block</span><span>:</span> <span>clamp</span><span>(</span><span>var</span><span>(</span>--size-sm<span>)</span><span>,</span> 4vw<span>,</span> <span>var</span><span>(</span>--size-lg<span>)</span><span>)</span> <span>var</span><span>(</span>--size-flex<span>)</span><span>;</span>
<span>}</span></code></pre>
<p>To something like this:</p>
<pre><code><span>body</span> <span>{</span>
  <span>background-color</span><span>:</span> <span>var</span><span>(</span>--color-sheet<span>)</span><span>;</span>

  <span>&amp; &gt; header</span> <span>{</span>
    <span>margin-block</span><span>:</span> <span>clamp</span><span>(</span><span>var</span><span>(</span>--size-sm<span>)</span><span>,</span> 4vw<span>,</span> <span>var</span><span>(</span>--size-lg<span>)</span><span>)</span> <span>var</span><span>(</span>--size-flex<span>)</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre>
<p>It was a good start, and modern features like nesting, <code>:where()</code>, and <code>:has()</code> made this feel better that it did 20 years ago, but I took things way too far with contextual styles. Taken to the extreme, you end up with overloaded selector definitions and progressively more esoteric selector patterns. I knew I was down the rabbit hole when I did something like this:</p>
<pre><code><span>li</span> <span>{</span>
  <span>&amp;:has( &gt; a + p)</span> <span>{</span>
    <span>padding-block</span><span>:</span> <span>var</span><span>(</span>--size-lg<span>)</span><span>;</span>
    <span>border-block-end</span><span>:</span> <span>var</span><span>(</span>--border-default<span>)</span><span>;</span>
    <span>text-wrap</span><span>:</span> balance<span>;</span>

    <span>&amp; &gt; a</span> <span>{</span>
      <span>font-size</span><span>:</span> <span>var</span><span>(</span>--font-xxl<span>)</span><span>;</span>
    <span>}</span>

    <span>&amp; &gt; p</span> <span>{</span>
      <span>margin-block</span><span>:</span> <span>var</span><span>(</span>--size-sm<span>)</span><span>;</span>
    <span>}</span>
  <span>}</span>
<span>}</span></code></pre>
<p>I still needed a “real” solution for components, and a way to manage variants.</p>

<p>I had an inkling of a solution, which is to leverage patterns from custom elements and web components, sans js. By virtue of their progressively enhanced nature, custom tag names and custom attributes are 100% valid HTML, javascript or no. That inkling turned into fervent belief after reading Keith Cirkel’s excellent post <a href="https://www.keithcirkel.co.uk/css-classes-considered-harmful/">“CSS classes considered harmful”</a>.</p>
<p>Revisiting the example above, now we’ve got a pattern like this:</p>
<pre><code><span>note-pad</span> <span>{</span>
  <span>padding-block</span><span>:</span> <span>var</span><span>(</span>--size-lg<span>)</span><span>;</span>
  <span>border-block-end</span><span>:</span> <span>var</span><span>(</span>--border-default<span>)</span><span>;</span>
  <span>text-wrap</span><span>:</span> balance<span>;</span>

  <span>&amp; a</span> <span>{</span>
    <span>font-size</span><span>:</span> <span>var</span><span>(</span>--font-xxl<span>)</span><span>;</span>
  <span>}</span>

  <span>&amp; p</span> <span>{</span>
    <span>margin-block</span><span>:</span> <span>var</span><span>(</span>--size-sm<span>)</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre>
<p>Custom attributes become a go-to for handling former BEM modifiers, but instead of relying on stylistic writing convention to fake a key-value pair, you get an <em>actual</em> key-value pair.</p>
<pre><code><span>random-pattern</span> <span>{</span>
  <span>&amp; [shape-type="1"]</span> <span>{</span>
    <span>border</span><span>:</span> 0.1rem solid <span>var</span><span>(</span>--color-sheet<span>)</span><span>;</span>
    <span>background-color</span><span>:</span> <span>var</span><span>(</span>--color-sheet<span>)</span><span>;</span>
    <span>filter</span><span>:</span> <span><span>url</span><span>(</span><span>"#noise1"</span><span>)</span></span><span>;</span>
  <span>}</span>

  <span>&amp; [shape-type="2"]</span> <span>{</span>
    <span>background</span><span>:</span> <span>var</span><span>(</span>--pattern-lines-horizontal<span>)</span><span>;</span>
    <span>background-size</span><span>:</span> <span>var</span><span>(</span>--pattern-scale<span>)</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre>
<p>Now, you can use <code>data-whatever</code> for attributes, but really, any two dash-separated words are safe. Personally, I think dropping the <code>data</code> prefix feels better and allows for richer semantics.</p>
<p>You can argue that both of these techniques are re-inventing classes in various ways. Kind of! You can use custom element names in lieu of semantic tags, just like you can slap a class on a div. But these techniques, particularly with how you can seamlessly enhance to true custom elements or web components, feels like a coherent end-to-end system in a way that class-based approaches don’t. <em>It’s tags and attributes, all the way down.</em></p>
<h2 id="would-i-do-this-again">Would I do this again?</h2>
<p>On the plus side, the user outcomes are decidedly positive; I removed a non-trivial amount of CSS (now about ~5KB of CSS over the wire for the entire site), and accessibility is without question better due to having to paid much closer attention to markup. Also, <em>just look</em> at that markup. So clean. So shiny.</p>
<p>On the flipside, this feels like an approach that <em>simply asks more of authors</em>. It requires more careful planning compared to pure component approaches; you can’t think of things in purely isolated terms. All to say, I’m very happy to ship this on my personal website, I’d be less likely to advocate for this approach on a large project with varied levels of frontend knowledge.</p>
<p>There’s a variation here that’s more encapsulated (use custom tag names with abandon), but that pulls on what feels like an unresolved thread; replacing a semantic element with a custom tag name that has no semantic value <em>feels bad</em>, and adding extra wrappers around everything <em>also feels bad</em>.</p>
<p>All to say, I’m not quite ready to say that this is The One True Way I’ll build all sites from now on, but I also can’t help but feel like I’ve crossed some kind of threshold. I used to think classes were fine. Now I’m not so sure. I don’t know exactly where it’ll lead yet, but this feels like one of those exercises that’ll have a lasting influence on my work.</p>
<hr>
<p><em>A mea culpa; I only got 99% of the way there. I use <a href="https://www.11ty.dev/docs/plugins/syntaxhighlight/">11ty’s syntax highlighting plugin</a>, which uses classes for styling. I gave <a href="https://andreruffert.github.io/syntax-highlight-element/">syntax-highlight</a> a hard look, but I don’t love the idea of introducing client-side js where none need exist, and the authoring experience would be a step back, so I begrudgingly left it alone for now.</em></p>

    
  </article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pnpm has a new setting to stave off supply chain attacks (137 pts)]]></title>
            <link>https://pnpm.io/blog/releases/10.16</link>
            <guid>45286526</guid>
            <pubDate>Thu, 18 Sep 2025 07:12:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pnpm.io/blog/releases/10.16">https://pnpm.io/blog/releases/10.16</a>, See on <a href="https://news.ycombinator.com/item?id=45286526">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__blog-post-container"><h2 id="minor-changes">Minor Changes<a href="#minor-changes" aria-label="Direct link to Minor Changes" title="Direct link to Minor Changes">​</a></h2>
<h3 id="new-setting-for-delayed-dependency-updates">New setting for delayed dependency updates<a href="#new-setting-for-delayed-dependency-updates" aria-label="Direct link to New setting for delayed dependency updates" title="Direct link to New setting for delayed dependency updates">​</a></h3>
<p>There have been several incidents recently where popular packages were successfully attacked. To reduce the risk of installing a compromised version, we are introducing a new setting that delays the installation of newly released dependencies. In most cases, such attacks are discovered quickly and the malicious versions are removed from the registry within an hour.</p>
<p>The new setting is called <a href="https://pnpm.io/settings#minimumreleaseage"><code>minimumReleaseAge</code></a>. It specifies the number of minutes that must pass after a version is published before pnpm will install it. For example, setting <code>minimumReleaseAge: 1440</code> ensures that only packages released at least one day ago can be installed.</p>
<p>If you set <code>minimumReleaseAge</code> but need to disable this restriction for certain dependencies, you can list them under the <a href="https://pnpm.io/settings#minimumreleaseageexclude"><code>minimumReleaseAgeExclude</code></a> setting. For instance, with the following configuration pnpm will always install the latest version of webpack, regardless of its release time:</p>
<div><pre tabindex="0"><code><span><span>minimumReleaseAgeExclude</span><span>:</span><span></span><br></span><span><span></span><span>-</span><span> webpack</span><br></span></code></pre></div>
<p>Related issue: <a href="https://github.com/pnpm/pnpm/issues/9921" target="_blank" rel="noopener noreferrer">#9921</a>.</p>
<h3 id="advanced-dependency-filtering-with-finder-functions">Advanced dependency filtering with finder functions<a href="#advanced-dependency-filtering-with-finder-functions" aria-label="Direct link to Advanced dependency filtering with finder functions" title="Direct link to Advanced dependency filtering with finder functions">​</a></h3>
<p>Added support for <a href="https://pnpm.io/finders"><code>finders</code></a>.</p>
<p>In the past, <code>pnpm list</code> and <code>pnpm why</code> could only search for dependencies by <strong>name</strong> (and optionally version). For example:</p>

<p>prints the chain of dependencies to any installed instance of <code>minimist</code>:</p>
<div><pre tabindex="0"><code><span><span>verdaccio 5.20.1</span><br></span><span><span>├─┬ handlebars 4.7.7</span><br></span><span><span>│ └── minimist 1.2.8</span><br></span><span><span>└─┬ mv 2.1.1</span><br></span><span><span>└─┬ mkdirp 0.5.6</span><br></span><span><span>  └── minimist 1.2.8</span><br></span></code></pre></div>
<p>What if we want to search by <strong>other properties</strong> of a dependency, not just its name? For instance, find all packages that have <code>react@17</code> in their peer dependencies?</p>
<p>This is now possible with "finder functions". Finder functions can be declared in <code>.pnpmfile.cjs</code> and invoked with the <code>--find-by=&lt;function name&gt;</code> flag when running <code>pnpm list</code> or <code>pnpm why</code>.</p>
<p>Let's say we want to find any dependencies that have React 17 in peer dependencies. We can add this finder to our <code>.pnpmfile.cjs</code>:</p>
<div><pre tabindex="0"><code><span><span>module</span><span>.</span><span>exports</span><span> </span><span>=</span><span> </span><span>{</span><span></span><br></span><span><span></span><span>finders</span><span>:</span><span> </span><span>{</span><span></span><br></span><span><span>  </span><span>react17</span><span>:</span><span> </span><span>(</span><span>ctx</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span><br></span><span><span>    </span><span>return</span><span> ctx</span><span>.</span><span>readManifest</span><span>(</span><span>)</span><span>.</span><span>peerDependencies</span><span>?.</span><span>react </span><span>===</span><span> </span><span>"^17.0.0"</span><span>;</span><span></span><br></span><span><span>  </span><span>}</span><span>,</span><span></span><br></span><span><span></span><span>}</span><span>,</span><span></span><br></span><span><span></span><span>}</span><span>;</span><br></span></code></pre></div>
<p>Now we can use this finder function by running:</p>
<div><pre tabindex="0"><code><span><span>pnpm why --find-by=react17</span><br></span></code></pre></div>
<p>pnpm will find all dependencies that have this React in peer dependencies and print their exact locations in the dependency graph.</p>
<div><pre tabindex="0"><code><span><span>@apollo/client 4.0.4</span><br></span><span><span>├── @graphql-typed-document-node/core 3.2.0</span><br></span><span><span>└── graphql-tag 2.12.6</span><br></span></code></pre></div>
<p>It is also possible to print out some additional information in the output by returning a string from the finder. For example, with the following finder:</p>
<div><pre tabindex="0"><code><span><span>module</span><span>.</span><span>exports</span><span> </span><span>=</span><span> </span><span>{</span><span></span><br></span><span><span></span><span>finders</span><span>:</span><span> </span><span>{</span><span></span><br></span><span><span>  </span><span>react17</span><span>:</span><span> </span><span>(</span><span>ctx</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span><br></span><span><span>    </span><span>const</span><span> manifest </span><span>=</span><span> ctx</span><span>.</span><span>readManifest</span><span>(</span><span>)</span><span>;</span><span></span><br></span><span><span>    </span><span>if</span><span> </span><span>(</span><span>manifest</span><span>.</span><span>peerDependencies</span><span>?.</span><span>react </span><span>===</span><span> </span><span>"^17.0.0"</span><span>)</span><span> </span><span>{</span><span></span><br></span><span><span>      </span><span>return</span><span> </span><span>`</span><span>license: </span><span>${</span><span>manifest</span><span>.</span><span>license</span><span>}</span><span>`</span><span>;</span><span></span><br></span><span><span>    </span><span>}</span><span></span><br></span><span><span>    </span><span>return</span><span> </span><span>false</span><span>;</span><span></span><br></span><span><span>  </span><span>}</span><span>,</span><span></span><br></span><span><span></span><span>}</span><span>,</span><span></span><br></span><span><span></span><span>}</span><span>;</span><br></span></code></pre></div>
<p>Every matched package will also print out the license from its <code>package.json</code>:</p>
<div><pre tabindex="0"><code><span><span>@apollo/client 4.0.4</span><br></span><span><span>├── @graphql-typed-document-node/core 3.2.0</span><br></span><span><span>│   license: MIT</span><br></span><span><span>└── graphql-tag 2.12.6</span><br></span><span><span>  license: MIT</span><br></span></code></pre></div>
<p>Related PR: <a href="https://github.com/pnpm/pnpm/pull/9946" target="_blank" rel="noopener noreferrer">#9946</a>.</p>
<h2 id="patch-changes">Patch Changes<a href="#patch-changes" aria-label="Direct link to Patch Changes" title="Direct link to Patch Changes">​</a></h2>
<ul>
<li>Fix deprecation warning printed when executing pnpm with Node.js 24 <a href="https://github.com/pnpm/pnpm/issues/9529" target="_blank" rel="noopener noreferrer">#9529</a>.</li>
<li>Throw an error if <code>nodeVersion</code> is not set to an exact semver version <a href="https://github.com/pnpm/pnpm/issues/9934" target="_blank" rel="noopener noreferrer">#9934</a>.</li>
<li><code>pnpm publish</code> should be able to publish a <code>.tar.gz</code> file <a href="https://github.com/pnpm/pnpm/pull/9927" target="_blank" rel="noopener noreferrer">#9927</a>.</li>
<li>Canceling a running process with Ctrl-C should make <code>pnpm run</code> return a non-zero exit code <a href="https://github.com/pnpm/pnpm/issues/9626" target="_blank" rel="noopener noreferrer">#9626</a>.</li>
</ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CERN Animal Shelter for Computer Mice (249 pts)]]></title>
            <link>https://computer-animal-shelter.web.cern.ch/index.shtml</link>
            <guid>45286369</guid>
            <pubDate>Thu, 18 Sep 2025 06:53:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://computer-animal-shelter.web.cern.ch/index.shtml">https://computer-animal-shelter.web.cern.ch/index.shtml</a>, See on <a href="https://news.ycombinator.com/item?id=45286369">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-wrap">
		
		<p><b>We are back!!!</b> After the <u><a href="https://computer-animal-shelter.web.cern.ch/disaster.shtml">disaster</a></u> early 2012, we have been able to secure new funds and are happy to annouce the reopening of the CERN Animal Shelter for Computer Mice <b>on the lawn in front of the <u><a href="http://maps.cern.ch/mapsearch/mapcernlite.htm?no=513">CERN Computer Centre</a></u></b>. Our shelter is open all week-days from 8:30 to 17:30.</p>
		
		<hr>
		<p><b>
		<table> 
		<tbody><tr><td>In the hay...</td><td>Eating...</td><td>Drinking...</td></tr>
		</tbody></table>
		<img width="32%" src="https://computer-animal-shelter.web.cern.ch/images/hay.JPG" alt="In the hay...">
		<img width="32%" src="https://computer-animal-shelter.web.cern.ch/images/eating.JPG" alt="Eating...">
		<img width="32%" src="https://computer-animal-shelter.web.cern.ch/images/drinking.JPG" alt="Drinking...">
		<table> 
		<tbody><tr><td>Cuddling...</td><td>Playing...</td><td>Panicking...</td></tr>
		</tbody></table>
		<img width="32%" src="https://computer-animal-shelter.web.cern.ch/images/cuddling.JPG" alt="Cuddling...">
		<img width="32%" src="https://computer-animal-shelter.web.cern.ch/images/playing.JPG" alt="Playing...">
		<img width="32%" src="https://computer-animal-shelter.web.cern.ch/images/losing.JPG" alt="Panicking...">
		</b></p><hr><p>
		A message from our sponsor --- A message from our sponsor --- A message from our sponsor
		</p><div id="add">
		<table><tbody><tr>
		<td><img height="200px" src="https://computer-animal-shelter.web.cern.ch/images/Sheep_Phishing-mouse-pointer_modified.jpg" alt=""></td>
		<td>
		<h2>"Stop — Think — Click"...</h2>

		<p>...is the basic recommendation for securely browsing the Internet and for securely reading emails. <b>Users who have followed this recommendation in the past were <i>less likely</i> to have their computer infected or their computing account compromised</b>. However, <i>still too many users</i> click on malicious web-links, and put their computer and account at risk.</p>

		<p>Therefore, in order to avoid clicking at all, <span color="red"><b>all CERN users are asked to disconnect their computer mice from CERN computers</b></span>, and bring them to the CERN Animal Shelter for Computer Mice.</p>
		</td>
		</tr></tbody></table>
		<p>Let us help you:<br> visit <b><a href="https://cern.ch/Computer.Security">https://cern.ch/Computer.Security</a></b> or contact <b><a href="mailto:Computer.Security@cern.ch">Computer.Security@cern.ch</a></b></p>

		</div><p>
		The Computer Animal Shelter declines responsibility for the content of our sponsor's message.
		</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[European ant is the first known animal to clone members of another species (116 pts)]]></title>
            <link>https://www.livescience.com/animals/ants/almost-like-science-fiction-european-ant-is-the-first-known-animal-to-clone-members-of-another-species</link>
            <guid>45285780</guid>
            <pubDate>Thu, 18 Sep 2025 05:27:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.livescience.com/animals/ants/almost-like-science-fiction-european-ant-is-the-first-known-animal-to-clone-members-of-another-species">https://www.livescience.com/animals/ants/almost-like-science-fiction-european-ant-is-the-first-known-animal-to-clone-members-of-another-species</a>, See on <a href="https://news.ycombinator.com/item?id=45285780">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">
<section>
<div>
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/HmpjKYcmyZFkFqw522MN7o-1920-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/HmpjKYcmyZFkFqw522MN7o-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/HmpjKYcmyZFkFqw522MN7o-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/HmpjKYcmyZFkFqw522MN7o-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/HmpjKYcmyZFkFqw522MN7o-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/HmpjKYcmyZFkFqw522MN7o-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/HmpjKYcmyZFkFqw522MN7o-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/HmpjKYcmyZFkFqw522MN7o.jpg" alt="Two winged male ants on a black background. The ant on the left is covered in hairs and the ant on the left is hairless." srcset="https://cdn.mos.cms.futurecdn.net/HmpjKYcmyZFkFqw522MN7o-1920-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/HmpjKYcmyZFkFqw522MN7o-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/HmpjKYcmyZFkFqw522MN7o-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/HmpjKYcmyZFkFqw522MN7o-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/HmpjKYcmyZFkFqw522MN7o-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/HmpjKYcmyZFkFqw522MN7o-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/HmpjKYcmyZFkFqw522MN7o-320-80.jpg 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/HmpjKYcmyZFkFqw522MN7o.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/HmpjKYcmyZFkFqw522MN7o.jpg" data-pin-nopin="true" fetchpriority="high">
</picture>
</div>
<figcaption>
<span>The same Iberian harvester ant (<em>Messor ibericus</em>) queen produced the hairy male <em>Messor ibericus</em> (on the left) and the hairless male <em>Messor structor</em> (on the right), despite them being members of distantly related species.</span>
<span>(Image credit: Jonathan Romiguier, Yannick Juvé and Laurent Soldati)</span>
</figcaption>
</div>

<div id="article-body">
<p id="b751b378-6387-41e6-954c-a55161598d4d">Queen ants in southern Europe produce male clones of an entirely different species — tearing up the playbook of reproductive biology and suggesting we need to rethink our understanding of species barriers.</p><p>The workers in Iberian harvester ant (<em>Messor ibericus</em>) colonies are all hybrids, with queens needing to mate with males from a distantly related species, <em>Messor structor</em>, to keep the colony functioning. But researchers found that some Iberian harvester ant populations have no <em>M. structor</em> colonies nearby.</p><p id="3cfb1adf-71c2-4ade-9de4-b095c6a9e0da">"We had to face the facts and try to see if there is something special within <em>Messor ibericus</em> colonies," Romiguier said.</p><p>In setting out to resolve this paradox, Romiguier and his team found that queen Iberian harvester ants also lay eggs containing male <em>M. structor</em> ants, with these males ultimately fathering the workers. This discovery, published Sept. 3 in the journal <a data-analytics-id="inline-link" href="https://go.redirectingat.com/?id=92X1590019&amp;xcust=livescience_us_7386292083305503411&amp;xs=1&amp;url=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41586-025-09425-w&amp;sref=https%3A%2F%2Fwww.livescience.com%2Fanimals%2Fants%2Falmost-like-science-fiction-european-ant-is-the-first-known-animal-to-clone-members-of-another-species" target="_blank" data-url="https://www.nature.com/articles/s41586-025-09425-w" referrerpolicy="no-referrer-when-downgrade" rel="sponsored noopener" data-hl-processed="skimlinks" data-placeholder-url="https://go.redirectingat.com/?id=92X1590019&amp;xcust=hawk-custom-tracking&amp;xs=1&amp;url=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41586-025-09425-w&amp;sref=https%3A%2F%2Fwww.livescience.com%2Fanimals%2Fants%2Falmost-like-science-fiction-european-ant-is-the-first-known-animal-to-clone-members-of-another-species" data-google-interstitial="false" data-merchant-name="nature.com" data-merchant-network="SkimLinks"><u>Nature</u></a>, is the first time any animal has been recorded producing offspring from another species as part of their normal life cycle.</p><p>"In the early stages, it was kind of a joke in the team," Romiguier said. "But the more we got results, the more it became a hypothesis and not a joke anymore."</p><p><strong>Related:</strong> <a data-analytics-id="inline-link" href="https://www.livescience.com/bee-creates-perfect-clone-army.html" data-before-rewrite-localise="https://www.livescience.com/bee-creates-perfect-clone-army.html"><u><strong>Single bee is making an immortal clone army thanks to a genetic fluke</strong></u></a></p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-6KAGhFhf7SDUHe8ELuy8sK"><section><p>Get the world’s most fascinating discoveries delivered straight to your inbox.</p></section></div><p>Ants are <a data-analytics-id="inline-link" href="https://go.redirectingat.com/?id=92X1590019&amp;xcust=livescience_us_8116884233061264853&amp;xs=1&amp;url=https%3A%2F%2Fwww.nature.com%2Farticles%2Fnature09205&amp;sref=https%3A%2F%2Fwww.livescience.com%2Fanimals%2Fants%2Falmost-like-science-fiction-european-ant-is-the-first-known-animal-to-clone-members-of-another-species" target="_blank" data-url="https://www.nature.com/articles/nature09205" referrerpolicy="no-referrer-when-downgrade" rel="sponsored noopener" data-hl-processed="skimlinks" data-placeholder-url="https://go.redirectingat.com/?id=92X1590019&amp;xcust=hawk-custom-tracking&amp;xs=1&amp;url=https%3A%2F%2Fwww.nature.com%2Farticles%2Fnature09205&amp;sref=https%3A%2F%2Fwww.livescience.com%2Fanimals%2Fants%2Falmost-like-science-fiction-european-ant-is-the-first-known-animal-to-clone-members-of-another-species" data-google-interstitial="false" data-merchant-name="nature.com" data-merchant-network="SkimLinks"><u>eusocial</u></a> insects, meaning their colonies form cooperative super-organisms predominantly made up of infertile females, called workers, and a small number of reproductive females, called queens. Males solely exist to fertilize queens during their <a data-analytics-id="inline-link" href="https://www.nhm.ac.uk/discover/when-why-winged-ants-swarm-nuptial-flight.html" target="_blank" data-url="https://www.nhm.ac.uk/discover/when-why-winged-ants-swarm-nuptial-flight.html" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"><u>mating flight</u></a> and die soon after.</p><p>Queens only mate once in their lives and store the sperm from this meeting in a special organ. She then draws from this sperm stash to lay new eggs containing one of three types of offspring: queens, workers or males.</p><p>However, Iberian harvester ants mating with males of their own species can only produce new queens. This is thought to be a result of <a data-analytics-id="inline-link" href="https://doi.org/10.1002/evl3.253" target="_blank" data-url="https://doi.org/10.1002/evl3.253" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"><u>selfish queen genes</u></a>, where the DNA from male <em>M. ibericus</em> guarantees its survival across generations by biasing larvae to produce fertile queens rather than infertile workers — known as "royal cheaters."</p><figure data-bordeaux-image-check="" id="de51f6e2-901e-4cd9-be04-2dd42bef4c90"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/aXsHbWNpdFYYiTh2xA34i9-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/aXsHbWNpdFYYiTh2xA34i9-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/aXsHbWNpdFYYiTh2xA34i9-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/aXsHbWNpdFYYiTh2xA34i9-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/aXsHbWNpdFYYiTh2xA34i9-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/aXsHbWNpdFYYiTh2xA34i9-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/aXsHbWNpdFYYiTh2xA34i9.jpg" alt="Two male ants with wings on a black background." srcset="https://cdn.mos.cms.futurecdn.net/aXsHbWNpdFYYiTh2xA34i9-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/aXsHbWNpdFYYiTh2xA34i9-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/aXsHbWNpdFYYiTh2xA34i9-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/aXsHbWNpdFYYiTh2xA34i9-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/aXsHbWNpdFYYiTh2xA34i9-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/aXsHbWNpdFYYiTh2xA34i9-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/aXsHbWNpdFYYiTh2xA34i9.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/aXsHbWNpdFYYiTh2xA34i9.jpg">
</picture></p></div><figcaption itemprop="caption description"><span>These two ants share the same mitochondrial DNA but different nuclear DNA. </span><span itemprop="copyrightHolder">(Image credit: Jonathan Romiguier, Yannick Juvé and Laurent Soldati)</span></figcaption></figure><p id="9e70406f-6b33-4f19-9a46-55842b7d79c2">To avoid this, queens must use sperm from male <em>M. structor </em>ants to produce their workers.</p><p>This was why the presence of thriving isolated <em>M. ibericus</em> colonies was such a conundrum.</p><p>To find answers, the researchers first sampled 132 males from 26 Iberian harvester ant colonies to figure out whether there were <em>M. structor</em> males present. They found that 58 were covered in hair and 74 were hairless. A closer inspection of the nuclear genomes of a subset of these ants revealed that all hairy ones were <em>M. ibericus</em> and all bald ones were <em>M. structor</em>.</p><p>But this was not proof that the queens were laying male eggs of two different species — there could have been some hidden <em>M. structor </em>queens producing the odd male. So the team sequenced the <a data-analytics-id="inline-link" href="https://www.genome.gov/genetics-glossary/Mitochondrial-DNA" target="_blank" data-url="https://www.genome.gov/genetics-glossary/Mitochondrial-DNA" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"><u>mitochondrial DNA</u></a>, which is passed down by the mother, of 24 of the <em>M. structor</em> males, and found it came from the same mother as the <em>M. ibericus </em>male nestmates.</p><p>"This was the detail that made me realize that 'maybe we are on to something very, very, very big,'" Romiguier said.</p><p id="6b230632-a9cb-470d-944f-c19033d9acd2">The team then separated 16 queens from laboratory colonies and looked at the genetic sequences of their freshly laid eggs. They found that 9% of their eggs contained <em>M. structor</em> ants. They then directly observed a single queen producing males of both species by monitoring its broods weekly over an 18-month period.</p><p>Together, all these findings show that Iberian harvester ant queens are cloning <em>M. structor</em> males and not passing on any of their own nuclear DNA. Researchers now need to pinpoint the exact mechanism underlying this cloning, Romiguier said, and find out at what point the maternal DNA is removed.</p><p id="0c79d4e8-8fd7-427a-8925-ed2ba6ad8d4f"><a data-analytics-id="inline-link" href="https://ebe.ulb.be/ebe/Fournier.html" target="_blank" data-url="https://ebe.ulb.be/ebe/Fournier.html" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"><u>Denis Fournier</u></a>, an evolutionary biologist and ecologist at the Free University of Brussels, Belgium, who was not involved in the research, said that it was "almost like science fiction" when he first learned of this discovery. "It's jaw-dropping! Most of us learn that species boundaries are firm, yet here is a system where ants regularly cross them as part of normal life," he told Live Science in an email.</p><p>The team have called this new reproductive system "xenoparity," meaning the birth of a different species. Romiguier said the team aren't exactly sure when this system first emerged in the Iberian harvester ants, but it's somewhere between when <em>M. ibericus </em>and <em>M. structor</em> split along different evolutionary paths 5 million years ago and a few thousand years ago.</p><p>"This discovery is a great reminder to stay open to the unexpected," Fournier said, noting that the finding opens up new questions about cooperation, conflict and dependency in nature. "Now that we know such a system is possible, it’s exciting to think that old, puzzling data might suddenly make sense in light of this discovery," he added.</p>
</div>

<div id="slice-container-authorBio-6KAGhFhf7SDUHe8ELuy8sK"><p>Sophie is a U.K.-based staff writer at Live Science. She covers a wide range of topics, having previously reported on research spanning from bonobo communication to the first water in the universe. Her work has also appeared in outlets including New Scientist, The Observer and BBC Wildlife, and she was shortlisted for the Association of British Science Writers' 2025 "Newcomer of the Year" award for her freelance work at New Scientist. Before becoming a science journalist, she completed a doctorate in evolutionary anthropology from the University of Oxford, where she spent four years looking at why some chimps are better at using tools than others.</p></div>

</section>





</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Towards a Physics Foundation Model (101 pts)]]></title>
            <link>https://arxiv.org/abs/2509.13805</link>
            <guid>45284766</guid>
            <pubDate>Thu, 18 Sep 2025 03:06:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2509.13805">https://arxiv.org/abs/2509.13805</a>, See on <a href="https://news.ycombinator.com/item?id=45284766">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2509.13805">View PDF</a>
    <a href="https://arxiv.org/html/2509.13805v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Foundation models have revolutionized natural language processing through a ``train once, deploy anywhere'' paradigm, where a single pre-trained model adapts to countless downstream tasks without retraining. Access to a Physics Foundation Model (PFM) would be transformative -- democratizing access to high-fidelity simulations, accelerating scientific discovery, and eliminating the need for specialized solver development. Yet current physics-aware machine learning approaches remain fundamentally limited to single, narrow domains and require retraining for each new system. We present the General Physics Transformer (GPhyT), trained on 1.8 TB of diverse simulation data, that demonstrates foundation model capabilities are achievable for physics. Our key insight is that transformers can learn to infer governing dynamics from context, enabling a single model to simulate fluid-solid interactions, shock waves, thermal convection, and multi-phase dynamics without being told the underlying equations. GPhyT achieves three critical breakthroughs: (1) superior performance across multiple physics domains, outperforming specialized architectures by up to 29x, (2) zero-shot generalization to entirely unseen physical systems through in-context learning, and (3) stable long-term predictions through 50-timestep rollouts. By establishing that a single model can learn generalizable physical principles from data alone, this work opens the path toward a universal PFM that could transform computational science and engineering.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Florian Wiesner [<a href="https://arxiv.org/show-email/a5962c15/2509.13805" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Wed, 17 Sep 2025 08:19:57 UTC (5,623 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[UC Berkeley gives personal information for 150 students and staff to government (145 pts)]]></title>
            <link>https://www.dailycal.org/news/campus/uc-berkeley-turns-over-personal-information-of-more-than-150-students-and-staff-to-federal/article_a4aad3e1-bbba-42cc-92d7-a7964d9641c5.html</link>
            <guid>45284477</guid>
            <pubDate>Thu, 18 Sep 2025 02:33:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.dailycal.org/news/campus/uc-berkeley-turns-over-personal-information-of-more-than-150-students-and-staff-to-federal/article_a4aad3e1-bbba-42cc-92d7-a7964d9641c5.html">https://www.dailycal.org/news/campus/uc-berkeley-turns-over-personal-information-of-more-than-150-students-and-staff-to-federal/article_a4aad3e1-bbba-42cc-92d7-a7964d9641c5.html</a>, See on <a href="https://news.ycombinator.com/item?id=45284477">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-body" itemprop="articleBody" false="">
                                <meta itemprop="isAccessibleForFree" content="true">
                                
                                
                                <p>UC Berkeley has provided the personal information of roughly 160 students, staff and faculty to the federal government in a directive from the UC Office of the President.&nbsp;</p><p dir="ltr"><span>In an attempt to comply with an</span> <a href="https://www.dailycal.org/news/campus/department-of-education-announces-antisemitism-inquiries-into-uc-berkeley-and-4-other-universities/article_ec4465a6-e389-11ef-b66c-03a9cd0727a9.html"><span>investigation</span></a> <span>into alleged campus antisemitism by the Department of Education, Office of Civil Rights, or OCR, UC Berkeley released the names of individuals and their “potential connection” to reports of alleged antisemitism, according to an email from campus spokesperson Janet Gilmore.&nbsp;</span></p><p dir="ltr"><span>Affected individuals received an email Sept. 4 from the campus Office of Legal Affairs notifying them that their names and information had been released. The message said the information had been disclosed over two weeks earlier.&nbsp;</span></p><p dir="ltr"><span>“As part of its investigation, OCR required production of comprehensive documents, including files and reports related to alleged antisemitic incidents,” the Office of Legal Affairs email read. “This notice is to inform you that, as required by law and as per directions provided by the UC systemwide Office of General Counsel (OGC), your name was included in reports as part of the documents provided by OGC to OCR for its investigation on August 18, 2025.”</span></p><p dir="ltr"><span>One campus graduate student, who received the message and was provided anonymity due to fears of retaliation, claimed the release targeted Muslim and Arab individuals who had previously expressed support for Palestine.&nbsp;&nbsp;</span></p><p dir="ltr"><span>“I think (the message was sent) to anybody who has ever been accused of antisemitism, which of course, includes a lot of Palestinians,” the student said. “Whenever we teach about Palestine, it usually leads to an investigation. I think they flagged and sent all of that information to the federal government.”</span></p><p dir="ltr"><span>The student claimed they had been the subject of a false report of antisemitism to the campus Title IX and XI Office for the Prevention of Harassment and Discrimination, or OPHD. They said other students who received the notification had OPHD cases that were determined to be unsubstantiated or stand open.&nbsp;</span></p><p dir="ltr"><span>While OPHD is the primary office for any harassment or discrimination reports, Gilmore said documents were sent from, “multiple campus offices to address (OCR’s) questions regarding campus handling of antisemitism on campus.”&nbsp;</span></p><p dir="ltr"><span>Campus officials did not say which offices provided information or what criteria were used to determine which individuals were associated with “antisemitism.”&nbsp;</span></p><p dir="ltr"><span>In February, the Department of Education</span> <a href="https://www.dailycal.org/news/campus/department-of-education-announces-antisemitism-inquiries-into-uc-berkeley-and-4-other-universities/article_ec4465a6-e389-11ef-b66c-03a9cd0727a9.html"><span>initiated</span></a> <span>an investigation into UC Berkeley’s handling of campus antisemitism. This, alongside an</span> <a href="https://www.dailycal.org/news/campus/department-of-justice-to-investigate-antisemitism-claims-against-the-university-of-california/article_7bc53322-fb31-11ef-85b8-8b9125661cf5.html"><span>investigation</span></a> <span>from the DOJ and Chancellor Rich Lyons’s</span> <a href="https://www.dailycal.org/news/national/uc-berkeley-chancellor-weathers-political-storm-in-house-antisemitism-hearing/article_589e8a3d-2a61-4a12-8e9b-ecdc8d47fa66.html"><span>testimony</span></a> <span>to Congress&nbsp; this summer represent a year-long crackdown on universities following the 2024 pro-Palestine encampments.&nbsp;</span></p><p dir="ltr"><span>Alongside UC Berkeley, UCSF, UCLA, UC Davis and UC San Diego have been targeted in Department of Education antisemitism inquiries. According to the campus grad student, some of these campuses also released student information to OCR at the direction of UCOP.&nbsp;</span></p><p dir="ltr"><span>However, these campuses did not send notifications to affected individuals, the student said. Alongside campus community members, the student said they notified pro-Palestinian groups across the UC that their members' personal information may have been shared with the federal government.&nbsp;</span></p><p dir="ltr"><span>UCOP did not comment on the compliance of other campuses or the specific directives given to UC Berkeley.</span></p><p dir="ltr"><span>In a Sunday Instagram post, UC Berkeley Students for Justice in Palestine, or SJP, decried the university for its “betrayal” to students, claiming campus administrators had previously provided them assurances that “identities would remain protected.”&nbsp;</span></p><p dir="ltr"><span>“Chancellor Rich Lyons should not have given assurances that he wouldn't be giving our information to the federal government,” the student said. “Beyond that, he should never have bowed down so easily. I would think that a university that prides itself on being this liberal haven would at least stand up to a fascist like Donald Trump.”&nbsp;</span></p><p dir="ltr"><span>In the final line of the email notification, the Office of Legal Affairs said the OCR investigation is still ongoing and further disclosures could be required.&nbsp;</span></p><p dir="ltr"><span>Moreover, the student and other individuals affected by the disclosure said this action has made them fearful, as they worry about how the information is going to be used by the Trump administration.&nbsp;</span></p><p dir="ltr"><span>“We’re concerned about how are they going to use that information to further repress us not only on campus, but also in our everyday lives,” the student said.” One of the things that I'm getting ready to do is my research year; and now I have to consult lawyers about even if it's safe to do my research, which is what I came here to do.”</span></p>
                                
                                
                            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: The text disappears when you screenshot it (439 pts)]]></title>
            <link>https://unscreenshottable.vercel.app/?text=Hello</link>
            <guid>45284311</guid>
            <pubDate>Thu, 18 Sep 2025 02:18:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://unscreenshottable.vercel.app/?text=Hello">https://unscreenshottable.vercel.app/?text=Hello</a>, See on <a href="https://news.ycombinator.com/item?id=45284311">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Slack is extorting us with a $195k/yr bill increase (2283 pts)]]></title>
            <link>https://skyfall.dev/posts/slack</link>
            <guid>45283887</guid>
            <pubDate>Thu, 18 Sep 2025 01:37:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://skyfall.dev/posts/slack">https://skyfall.dev/posts/slack</a>, See on <a href="https://news.ycombinator.com/item?id=45283887">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <div>  <p>An open letter, or something</p> </div> <p><time datetime="2025-09-18T18:00:00.000Z"> September 18th 2025 </time> </p>  </div><div>  <p>For nearly 11 years, Hack Club - a nonprofit that provides coding education and community to teenagers worldwide - has used Slack as the tool for communication. We weren’t freeloaders. A few years ago, when Slack transitioned us from their free nonprofit plan to a $5,000/year arrangement, we happily paid. It was reasonable, and we valued the service they provided to our community.</p>
<p>However, two days ago, Slack reached out to us and said that if we don’t agree to pay an extra $50k <strong>this week</strong> and $200k a year, they’ll deactivate our Slack workspace and delete all of our message history.</p>
<p>One could argue that Slack is free to stop providing us the nonprofit offer at any time, but in my opinion, a six month grace period is the <em>bare minimum</em> for a massive hike like this, if not more. Essentially, Salesforce (a <strong>$230 billion</strong> company) is strong-arming a small nonprofit for teens, by providing less than a week to pony up a pretty massive sum of money, or risk cutting off all our communications. That’s absurd.</p>
<h2 id="the-impact">The impact</h2>
<p>The small amount of notice has also been catastrophic for the programs that we run. Dozens of our staff and volunteers are now scrambling to update systems, rebuild integrations and migrate <em>years</em> of institutional knowledge. The opportunity cost of this forced migration is simply staggering.</p>
<p><img width="752" height="55" alt="image" src="https://github.com/user-attachments/assets/48097101-1521-4f50-b970-9557a0b7eefd">
<img width="1146" height="103" alt="image" src="https://github.com/user-attachments/assets/f09902a1-42cb-4cd7-9a32-21cdbfb3fd05">
<img width="1146" height="134" alt="image" src="https://github.com/user-attachments/assets/dbfc784a-d06b-44d8-a050-ec8c16c5a98b">
<img width="611" height="274" alt="image" src="https://github.com/user-attachments/assets/8a41302f-2e5f-41c1-933f-d856094c587a"></p><p>Anyway, we’re moving to Mattermost. This experience has taught us that owning your data is incredibly important, and if you’re a small business especially, then I’d advise you move away too.</p>
<hr>
<p><em>This post was rushed out because, well, this has been a shock! If you’d like any additional details then feel free to send me an email.</em></p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hypervisor 101 in Rust (150 pts)]]></title>
            <link>https://tandasat.github.io/Hypervisor-101-in-Rust/</link>
            <guid>45283731</guid>
            <pubDate>Thu, 18 Sep 2025 01:18:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tandasat.github.io/Hypervisor-101-in-Rust/">https://tandasat.github.io/Hypervisor-101-in-Rust/</a>, See on <a href="https://news.ycombinator.com/item?id=45283731">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page-wrapper">

            <div id="content" class="page">
                    <main>
                        <h2 id="welcome-to-hypervisor-101-in-rust"><a href="#welcome-to-hypervisor-101-in-rust">Welcome to Hypervisor 101 in Rust</a></h2>
<p>This is a day long course to quickly learn the inner working of hypervisors and techniques to write them for high-performance fuzzing.</p>
<p>This course covers foundation of hardware-assisted virtualization technologies, such as VMCS/VMCB, guest-host world switches, EPT/NPT, as well as useful features and techniques such as exception interception for virtual machine introspection for fuzzing.</p>
<p>The class is made up of lectures using the materials within this directory and hands-on exercises with source code under the <code>Hypervisor-101-in-Rust/hypervisor</code> directory.</p>
<p>This lecture materials are written for the <code>gcc2023</code> branch, which notionally have incomplete code for step-by-step exercises. Check out the starting point of the branch as below to go over hands-on exercises before you start.</p>
<pre><code>git checkout b17a59dd634a7b0c2b9a6d493fc9b0ff22dcfce5
</code></pre>

                    </main>

                    <nav aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->

                            <a rel="next prefetch" href="https://tandasat.github.io/Hypervisor-101-in-Rust/introduction/prerequisites.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i></i>
                            </a>

                        
                    </nav>
                </div>

            <nav aria-label="Page navigation">

                    <a rel="next prefetch" href="https://tandasat.github.io/Hypervisor-101-in-Rust/introduction/prerequisites.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i></i>
                    </a>
            </nav>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta Ray-Ban Display (550 pts)]]></title>
            <link>https://www.meta.com/blog/meta-ray-ban-display-ai-glasses-connect-2025/</link>
            <guid>45283306</guid>
            <pubDate>Thu, 18 Sep 2025 00:30:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.meta.com/blog/meta-ray-ban-display-ai-glasses-connect-2025/">https://www.meta.com/blog/meta-ray-ban-display-ai-glasses-connect-2025/</a>, See on <a href="https://news.ycombinator.com/item?id=45283306">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Stepping Down as Libxml2 Maintainer (156 pts)]]></title>
            <link>https://discourse.gnome.org/t/stepping-down-as-libxml2-maintainer/31398</link>
            <guid>45283196</guid>
            <pubDate>Thu, 18 Sep 2025 00:17:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://discourse.gnome.org/t/stepping-down-as-libxml2-maintainer/31398">https://discourse.gnome.org/t/stepping-down-as-libxml2-maintainer/31398</a>, See on <a href="https://news.ycombinator.com/item?id=45283196">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemscope="" itemtype="http://schema.org/DiscussionForumPosting" id="main-outlet" role="main">
      <meta itemprop="headline" content="Stepping down as libxml2 maintainer">
      
      <meta itemprop="datePublished" content="2025-09-15T12:06:01Z">
        <meta itemprop="articleSection" content="Platform">
      <meta itemprop="keywords" content="announcement, libxml2">
      


          <div id="post_1">
            <div>
              


              <p><span>
                  <time datetime="2025-09-15T12:06:01Z">
                    September 15, 2025, 12:06pm
                  </time>
                  <meta itemprop="dateModified" content="2025-09-15T12:06:01Z">
              <span itemprop="position">1</span>
              </span>
            </p></div>
            <div itemprop="text">
              <p>I’m stepping down as maintainer of libxml2 which means that this project is more or less unmaintained for now.</p>
<p>I will fix regressions in the 2.15 release until the end of 2025.</p>
            </div>

            

          </div>
          <div id="post_2" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://discourse.gnome.org/u/tragivictoria"><span itemprop="name">tragivictoria</span></a>
                (Victoria 🏳️‍⚧️🏳️‍🌈)
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-09-15T14:04:28Z">
                    September 15, 2025,  2:04pm
                  </time>
                  <meta itemprop="dateModified" content="2025-09-15T14:04:28Z">
              <span itemprop="position">2</span>
              </span>
            </p>
            <p>Thank you for your hard work!</p>

            

          </div>
          <div id="post_3" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://discourse.gnome.org/u/mcatanzaro"><span itemprop="name">mcatanzaro</span></a>
                (Michael Catanzaro)
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-09-15T16:18:11Z">
                    September 15, 2025,  4:18pm
                  </time>
                  <meta itemprop="dateModified" content="2025-09-15T16:18:11Z">
              <span itemprop="position">3</span>
              </span>
            </p>
            <p>Yes, thank you for maintaining libxml2 for such a long time!</p>

            

          </div>
          <div id="post_4" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://discourse.gnome.org/u/imcsk8"><span itemprop="name">imcsk8</span></a>
                (Iván Chavero)
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-09-15T18:56:45Z">
                    September 15, 2025,  6:56pm
                  </time>
                  <meta itemprop="dateModified" content="2025-09-15T18:56:45Z">
              <span itemprop="position">4</span>
              </span>
            </p>
            <div itemprop="text">
              <p>Hello, since I’ve stepped in as libxslt maintainer I’ve been studying both libxslt and libxml2 codebases. I have the time to maintain the library I just need to get familiar with the latest changes you introduced like:</p>


<p>I haven’t find how to manage both output and input buffers. I found functions like: <em>xmlOutputBufferCreateIO</em> but by the places in which I’ve found them is not clear on how to use them.</p>
<p>Should I send you an email with my questions or do you prefer other means of communication?</p>
            </div>

            

          </div>
          <div id="post_5" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://discourse.gnome.org/u/sri"><span itemprop="name">sri</span></a>
                (sri)
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-09-15T19:32:59Z">
                    September 15, 2025,  7:32pm
                  </time>
                  <meta itemprop="dateModified" content="2025-09-15T19:32:59Z">
              <span itemprop="position">5</span>
              </span>
            </p>
            <p>Thank you Nick for maintaining the key libraries of the internet and used in millions of products globaly. Best of luck to you.</p>

            

          </div>
          <div id="post_6" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p>I am one of those millions of people that use this library on the behalf of us Thank you very much!!</p>

            

          </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[One Token to rule them all – Obtaining Global Admin in every Entra ID tenant (278 pts)]]></title>
            <link>https://dirkjanm.io/obtaining-global-admin-in-every-entra-id-tenant-with-actor-tokens/</link>
            <guid>45282497</guid>
            <pubDate>Wed, 17 Sep 2025 23:03:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dirkjanm.io/obtaining-global-admin-in-every-entra-id-tenant-with-actor-tokens/">https://dirkjanm.io/obtaining-global-admin-in-every-entra-id-tenant-with-actor-tokens/</a>, See on <a href="https://news.ycombinator.com/item?id=45282497">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
        <header>
          
          
            <p> 




  17 minute read
</p>
          
        </header>
      

      <section itemprop="text">
        
        <p>While preparing for my Black Hat and DEF CON talks in July of this year, I found the most impactful Entra ID vulnerability that I will probably ever find. This vulnerability could have allowed me to compromise every Entra ID tenant in the world (except probably those in national cloud deployments<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup>). If you are an Entra ID admin reading this, yes that means complete access to your tenant. The vulnerability consisted of two components: undocumented impersonation tokens, called “Actor tokens”, that Microsoft uses in their backend for service-to-service (S2S) communication. Additionally, there was a critical flaw in the (legacy) Azure AD Graph API that failed to properly validate the originating tenant, allowing these tokens to be used for cross-tenant access.</p>

<p>Effectively this means that with a token I requested in my lab tenant I could authenticate as <em>any user</em>, including Global Admins, in <em>any other tenant</em>. Because of the nature of these Actor tokens, they are not subject to security policies like Conditional Access, which means there was no setting that could have mitigated this for specific hardened tenants. Since the Azure AD Graph API is an older API for managing the core Azure AD / Entra ID service, access to this API could have been used to make any modification in the tenant that Global Admins can do, including taking over or creating new identities and granting them any permission in the tenant. With these compromised identities the access could also be extended to Microsoft 365 and Azure.</p>

<p>I reported this vulnerability the same day to the Microsoft Security Response Center (MSRC). Microsoft fixed this vulnerability on their side within days of the report being submitted and has rolled out further mitigations that block applications from requesting these Actor tokens for the Azure AD Graph API. Microsoft also issued <a href="https://msrc.microsoft.com/update-guide/vulnerability/CVE-2025-55241">CVE-2025-55241</a> for this vulnerability.</p>

<h2 id="impact">Impact</h2>
<p>These tokens allowed full access to the Azure AD Graph API in any tenant. Requesting Actor tokens does not generate logs. Even if it did they would be generated in my tenant instead of in the victim tenant, which means there is no record of the existence of these tokens.</p>

<p>Furthermore, the Azure AD Graph API does not have API level logging. Its successor, the Microsoft Graph, does have this logging, but for the Azure AD Graph this telemetry source is still in a very limited preview and I’m not aware of any tenant that currently has this available. Since there is no API level logging, it means the following Entra ID data could be accessed without any traces:</p>

<ul>
  <li>User information including all their personal details stored in Entra ID.</li>
  <li>Group and role information.</li>
  <li>Tenant settings and (Conditional Access) policies.</li>
  <li>Applications, Service Principals, and any application permission assignment.</li>
  <li>Device information and BitLocker keys synced to Entra ID.</li>
</ul>

<p>This information could be accessed by impersonating a regular user in the victim tenant. If you want to know the full impact, my tool <a href="https://github.com/dirkjanm/ROADtools">roadrecon</a> uses the same API, if you run it then everything you find in the GUI of the tool could have been accessed and modified by an attacker abusing this flaw.</p>

<p>If a Global Admin was impersonated, it would also be possible to <strong>modify</strong> any of the above objects and settings. This would result in full tenant compromise with access to any service that uses Entra ID for authentication, such as SharePoint Online and Exchange Online. It would also provide full access to any resource hosted in Azure, since these resources are controlled from the tenant level and Global Admins can grant themselves rights on Azure subscriptions. Modifying objects in the tenant does (usually) result in audit logs being generated. That means that while theoretically all data in Microsoft 365 could have been compromised, doing anything other than reading the directory information would leave audit logs that could alert defenders, though without knowledge of the specific artifacts that modifications with these Actor tokens generate, it would appear as if a legitimate Global Admin performed the actions.</p>

<p>Based on Microsoft’s internal telemetry, they did not detect any abuse of this vulnerability. If you want to search for possible abuse artifacts in your own environment, a KQL detection is included at the end of this post.</p>

<h2 id="technical-details">Technical details</h2>
<h2 id="actor-tokens">Actor tokens</h2>
<p>Actor tokens are tokens that are issued by the “Access Control Service”. I don’t know the exact origins of this service, but it appears to be a legacy service that is used for authentication with SharePoint applications and also seems to be used by Microsoft internally. I came across this service while investigating hybrid Exchange setups. These hybrid setups used to provision a certificate credential on the Exchange Online Service Principal (SP) in the tenant, with which it can perform authentication. These hybrid attacks were the topic of some talks I did this summer, the slides are on the <a href="https://dirkjanm.io/talks/">talks</a> page. In this case the hybrid part is not relevant, as in my lab I could also have added a credential on the Exchange Online SP without the complete hybrid setup. Exchange is not the only app which can do this, but since I found this in Exchange we will keep talking about these tokens in the context of Exchange.</p>

<p>Exchange will request Actor tokens when it wants to communicate with other services on behalf of a user. The Actor token allows it to “act” as another user in the tenant when talking to Exchange Online, SharePoint and as it turns out the Azure AD Graph. The Actor token (a JSON Web Token / JWT) looks as follows when decoded:</p>

<div><pre><code>{
    "alg": "RS256",
    "kid": "_jNwjeSnvTTK8XEdr5QUPkBRLLo",
    "typ": "JWT",
    "x5t": "_jNwjeSnvTTK8XEdr5QUPkBRLLo"
}
{
    "aud": "00000002-0000-0000-c000-000000000000/graph.windows.net@6287f28f-4f7f-4322-9651-a8697d8fe1bc",
    "exp": 1752593816,
    "iat": 1752507116,
    "identityprovider": "00000001-0000-0000-c000-000000000000@6287f28f-4f7f-4322-9651-a8697d8fe1bc",
    "iss": "00000001-0000-0000-c000-000000000000@6287f28f-4f7f-4322-9651-a8697d8fe1bc",
    "nameid": "00000002-0000-0ff1-ce00-000000000000@6287f28f-4f7f-4322-9651-a8697d8fe1bc",
    "nbf": 1752507116,
    "oid": "a761cbb2-fbb6-4c80-aa50-504962316eb2",
    "rh": "1.AXQAj_KHYn9PIkOWUahpfY_hvAIAAAAAAAAAwAAAAAAAAACtAQB0AA.",
    "sub": "a761cbb2-fbb6-4c80-aa50-504962316eb2",
    "trustedfordelegation": "true",
    "xms_spcu": "true"
}.[signature from Entra ID]
</code></pre></div>

<p>There are a few fields here that differ from regular Entra ID access tokens:</p>

<ul>
  <li>The <code>aud</code> field contains the GUID of the Azure AD Graph API, as well as the URL <code>graph.windows.net</code> and the tenant it was issued to <code>6287f28f-4f7f-4322-9651-a8697d8fe1bc</code>.</li>
  <li>The expiry is exactly 24 hours after the token was issued.</li>
  <li>The <code>iss</code> contains the GUID of the Entra ID token service itself, called “Azure ESTS Service”, and again the tenant GUID where it was issued.</li>
  <li>The token contains the claim <code>trustedfordelegation</code>, which is <code>True</code> in this case, meaning we can use this token to impersonate other identities. Many Microsoft apps could request such tokens. Non-Microsoft apps requesting an Actor token would receive a token with this field set to <code>False</code> instead.</li>
</ul>

<p>When using this Actor token, Exchange would embed this in an <strong>unsigned</strong> JWT that is then sent to the resource provider, in this case the Azure AD graph. In the rest of the blog I call these <strong>impersonation tokens</strong> since they are used to impersonate users.</p>

<div><pre><code>{
    "alg": "none",
    "typ": "JWT"
}
{
    "actortoken": "eyJ0eXAiOiJKV1Qi&lt;snip&gt;TxeLkNB8v2rWWMLGpaAaFJlhA",
    "aud": "00000002-0000-0000-c000-000000000000/graph.windows.net@6287f28f-4f7f-4322-9651-a8697d8fe1bc",
    "exp": 1756926566,
    "iat": 1756926266,
    "iss": "00000002-0000-0ff1-ce00-000000000000@6287f28f-4f7f-4322-9651-a8697d8fe1bc",
    "nameid": "10032001E2CBE43B",
    "nbf": 1756926266,
    "nii": "urn:federation:MicrosoftOnline",
    "sip": "doesnt@matter.com",
    "smtp": "doesnt@matter.com",
    "upn": "doesnt@matter.com"
}.[no signature]
</code></pre></div>

<p>The <code>sip</code>, <code>smtp</code>, <code>upn</code> fields are used when accessing resources in Exchange online or SharePoint, but are ignored when talking to the Azure AD Graph, which only cares about the <code>nameid</code>. This <code>nameid</code> originates from an attribute of the user that is called the <code>netId</code> on the Azure AD Graph. You will also see it reflected in tokens issued to users, in the <code>puid</code> claim, which stands for Passport UID. I believe these identifiers are an artifact from the original codebase which Microsoft used for its Microsoft Accounts (consumer accounts or MSA). They are still used in Entra ID, for example to map guest users to the original identity in their home tenant.</p>

<p>As I mentioned before, these impersonation tokens are not signed. That means that once Exchange has an Actor token, it can use the one Actor token to impersonate anyone against the target service it was requested for, for 24 hours. In my personal opinion, this whole Actor token design is something that never should have existed. It lacks almost every security control that you would want:</p>

<ul>
  <li>There are no logs when Actor tokens are issued.</li>
  <li>Since these services can craft the unsigned impersonation tokens without talking to Entra ID, there are also no logs when they are created or used.</li>
  <li>They cannot be revoked within their 24 hours validity.</li>
  <li>They completely bypass any restrictions configured in Conditional Access.</li>
  <li>We have to rely on logging from the resource provider to even know these tokens were used in the tenant.</li>
</ul>

<p>Microsoft uses these tokens to talk to other services in their backend, something that Microsoft calls service-to-service (S2S) communication. If one of these tokens leaks, it can be used to access all the data in an entire tenant without any useful telemetry or mitigation. In July of this year, Microsoft did publish <a href="https://www.microsoft.com/en-us/security/blog/2025/07/08/enhancing-microsoft-365-security-by-eliminating-high-privilege-access/">a blog</a> about removing these insecure legacy practices from their environment, but they do not provide any transparency about how many services still use these tokens.</p>

<h2 id="the-fatal-flaw-leading-to-cross-tenant-compromise">The fatal flaw leading to cross-tenant compromise</h2>
<p>As I was refining my slide deck and polished up my proof-of-concept code for requesting and generating these tokens, I tested more variants of using these tokens, changing various fields to see if the tokens still worked with the modified information. As one of the tests I changed the tenant ID of the impersonation token to a different tenant in which none of my test accounts existed. The Actor tokens tenant ID was my <code>iminyour.cloud</code> tenant, with tenant ID <code>6287f28f-4f7f-4322-9651-a8697d8fe1bc</code> and the unsigned JWT generated had the tenant ID <code>b9fb93c1-c0c8-4580-99f3-d1b540cada32</code>.</p>

<p><img src="https://dirkjanm.io/assets/img/actortokens/tenantchange.png" alt="Changed tenant ID"></p>

<p>I sent this token to <code>graph.windows.net</code> using my CLI tool <code>roadtx</code>, expecting a generic access denied since I had a tenant ID mismatch. However, I was instead greeted by a curious error message:</p>

<p><img src="https://dirkjanm.io/assets/img/actortokens/usernotfound.png" alt="Error message indicating the user does not exist"></p>

<p><em>Note that these are the actual screenshots I made during my research, which is why the formatting may not work as well in this blog</em></p>

<p>The error message suggested that while my token was valid, the identity could not be found in the tenant. Somehow the API seemed to accept my token even with the mismatching tenant. I quickly looked up the <code>netId</code> of a user that did exist in the target tenant, crafted a token and the Azure AD Graph happily returned the data I requested. I tested this in a few more test tenants I had access to, to make sure I was not crazy, but I could indeed access data in other tenants, as long as I knew their tenant ID (which is public information) and the <code>netId</code> of a user in that tenant.</p>

<p>To demonstrate the vulnerability, here I am using a Guest user in the target tenant to query the <code>netId</code> of a Global Admin. Then I impersonate the Global Admin using the same Actor token, and can perform any action in the tenant as that Global Admin over the Azure AD Graph.</p>

<p>First I craft an impersonation token for a Guest user in my victim tenant:</p>

<p><img src="https://dirkjanm.io/assets/img/actortokens/guesttoken.png" alt="Craft impersonation token for Guest user"></p>

<p>I use this token to query the <code>netId</code> of a Global Admin:</p>

<p><img src="https://dirkjanm.io/assets/img/actortokens/findga.png" alt="Query Global Admin"></p>

<p>Then I create an impersonation token for this Global Admin (the UPN is kept the same since it is not validated by the API):</p>

<p><img src="https://dirkjanm.io/assets/img/actortokens/gaimpersonate.png" alt="Craft impersonation token for Global Admin"></p>

<p>And finally this token is used to access the tenant as the Global Admin, listing the users, something the guest user was not able to do:</p>

<p><img src="https://dirkjanm.io/assets/img/actortokens/queryusers.png" alt="Query data in the tenant"></p>

<p>I can even run roadrecon with this impersonation token, which queries all Azure AD Graph API endpoints to enumerate the available information in the tenant.</p>

<p><img src="https://dirkjanm.io/assets/img/actortokens/runroadrecon.png" alt="Running roadrecon in a tenant with an impersonation token"></p>

<p>None of these actions would generate any logs in the victim tenant.</p>

<h2 id="practical-abuse">Practical abuse</h2>
<p>With this vulnerability it would be possible to compromise any Entra ID tenant. Starting with an Actor token from an attacker controlled tenant, the following steps would lead to full control over the victim tenant:</p>

<ol>
  <li>Find the tenant ID for the victim tenant, this can be done using public APIs based on the domain name.</li>
  <li>Find a valid <code>netId</code> of a regular user in the tenant. Methods for this will be discussed below.</li>
  <li>Craft an impersonation token with the Actor token from the attacker tenant, using the tenant ID and <code>netId</code> of the user in the victim tenant.</li>
  <li>List all Global Admins in the tenant and their <code>netId</code>.</li>
  <li>Craft an impersonation token for the Global Admin account.</li>
  <li>Perform any read or write action over the Azure AD Graph API.</li>
</ol>

<p>If an attacker makes any modifications in the tenant in step 6, that would be the only event in this chain that generates any telemetry in the victim tenant. An attacker could for example create new user accounts, grant these Global Admin privileges and then sign in interactively to any Entra ID, Microsoft 365 or third party application that integrates with the victim tenant. Alternatively they could add credentials on existing applications, grant these apps API permissions and use that to exfiltrate emails or files from Microsoft 365, a technique that is popular among threat actors. An attacker could also add credentials to <a href="https://dirkjanm.io/azure-ad-privilege-escalation-application-admin/">Microsoft Service Principals</a> in the victim tenant, several of which can request Actor tokens that allow impersonation against SharePoint or Exchange. For my DEF CON and Black Hat talks I made a demo video about using these Actor tokens to obtain Global Admin access. The video uses Actor tokens within a tenant, but the same technique could have been applied to any other tenant by abusing this vulnerability.</p>

<video width="100%" controls="">
  <source src="https://dirkjanm.io/assets/raw/demo_graph.mp4" type="video/mp4">
</video>

<h2 id="finding-netids">Finding netIds</h2>
<p>Since tenant IDs can be resolved when the domain name of a tenant is known, the only identifier that is not immediately available to the attacker is a valid <code>netId</code> for a user in that specific tenant. As I mentioned above, these IDs are added to Entra ID access tokens as the <code>puid</code> claim. Any token found online, in screenshots, examples or logs, even those that are long expired or with an obfuscated signature, would provide an attacker with enough information to breach the tenant. Threat actors that still have old tokens for any tenant from previous breaches can immediately access those tenants again as long as the victim account still exists.</p>

<p>The above is probably not a very common occurrence. What is a more realistic attack is simply brute-forcing the <code>netId</code>. Unlike object IDs, which are randomly generated, netIds are actually incremental. Looking at the differences in netIds between my tenant and those of some tenants I analyzed, I found the difference between a newly created user in my tenant and their newest user to be in the range of 100.000 to 100 million. Simply brute forcing the <code>netId</code> could be accomplished in minutes to hours for any target tenant, and the more user exist in a tenant the easier it is to find a match. Since this does not generate any logs it isn’t a noisy attack either. Because of the possibility to brute force these netIds I would say this vulnerability could have been used to take over any tenant without any prerequisites. There is however a third technique which is even more effective (and more fun from a technical level).</p>

<h2 id="compromising-tenants-by-hopping-over-b2b-trusts">Compromising tenants by hopping over B2B trusts</h2>
<p>I previously mentioned that a users <code>netId</code> is used to establish links between a user account in multiple tenants. This is something that I researched a few years ago when I gave a talk at <a href="https://dirkjanm.io/assets/raw/US-22-Mollema-Backdooring-and-hijacking-Azure-AD-accounts_final.pdf">Black Hat USA 22</a> about external identities. The below screenshot is taken from one of my slides, which illustrates this:</p>

<p><img src="https://dirkjanm.io/assets/img/actortokens/guestlink.png" alt="Guest user link based on netid"></p>

<p>The way this works is as follows. Suppose we have tenant A and tenant B. A user in tenant B is invited into tenant A. In the new guest account that is created in tenant A, their <code>netId</code> is stored on the <code>alternativeSecurityIds</code> attribute. That means that an attacker wanting to abuse this bug can simply read that attribute in tenant A, put it in an impersonation token for tenant B and then impersonate the victim in their home tenant. It should be noted that this works <strong>against the direction of invite</strong>. Any user in any tenant where you accept an invite will be able to read your <code>netId</code>, and with this bug could have impersonated you in your home tenant. In your home tenant you have a full user account, which can enumerate other users. This is not a bug or risk with B2B trusts, but is simply an unintended consequence of the B2B design mechanism. A guest account in someone else’s tenant would also be sufficient with the default Entra ID guest settings because the default settings allow users to query the <code>netId</code> of a user as long as the UPN is known.</p>

<p>To abuse this, a threat actor could perform the following steps, given that they have access to at least one tenant with a guest user:</p>

<ol>
  <li>Query the guest users and their <code>alternativeSecurityIds</code> attribute which gives the <code>netId</code>.</li>
  <li>Query the tenant ID of the guest users home tenant based on the domain name in their UPN.</li>
  <li>Create an impersonation token, impersonating the victim in their home tenant.</li>
  <li>Optionally list Global Admins and impersonate those to compromise the entire tenant.</li>
  <li>Repeat step 1 for each tenant that was compromised.</li>
</ol>

<p>The steps above can be done in 2 API calls per tenant, which do not generate any logs. Most tenants will have guest users from multiple distinct other tenants. This means the number of tenants you compromise with this scales exponentially and the information needed to compromise the majority of all tenants worldwide could have been gathered within minutes using a single Actor token. After at least 1 user is known per victim tenant, the attacker can selectively perform post-compromise actions in these tenants by impersonating Global Admins.</p>

<p>Looking at the list of guest users in the tenants of some of my clients, this technique would be extremely powerful. I also observed that one of the first tenants you will likely compromise is Microsoft’s own tenant, since Microsoft consultants often get invited to customer tenants. Many MSPs and Microsoft Partners will have a guest account in the Microsoft tenant, so from the Microsoft tenant a compromise of most major service provider tenants is one step away.</p>

<p>Needless to say, as much as I would have liked to test this technique in practice to see how fast this would spread out, I only tested the individual steps in my own tenants and did not access any data I’m not authorized to.</p>

<h2 id="detection">Detection</h2>
<p>While querying data over the Azure AD Graph does not leave any logs, modifying data does (usually) generate audit logs. If modifications are done with Actor tokens, these logs look a bit curious.</p>

<p><img src="https://dirkjanm.io/assets/img/actortokens/initiatedby.png" alt="Initiated by exchange and a global admin" width="60%"></p>

<p>Since Actor tokens involve both the app and the user being impersonated, it seems Entra ID gets confused about who actually made the change, and it will log the UPN of the impersonated Global Admin, but the display name of Exchange. Luckily for defenders this creates a nice giveaway when Actor tokens are used in the tenant. After some testing and filtering with some fellow researchers that work on the blue side (thanks to Fabian Bader and Olaf Hartong) we came up with the following detection query:</p>

<pre><code>AuditLogs
| where not(OperationName has "group")
| where not(OperationName == "Set directory feature on tenant")
| where InitiatedBy has "user"
| where InitiatedBy.user.displayName has_any ( "Office 365 Exchange Online", "Skype for Business Online", "Dataverse", "Office 365 SharePoint Online", "Microsoft Dynamics ERP")
</code></pre>

<p>The exclusion for group operations is there because some of these products do actually use Actor tokens to perform operations on your behalf. For example creating specific groups via the Exchange Online PowerShell module will make Exchange use an Actor token on your behalf and create the group in Entra ID.</p>

<h2 id="conclusion">Conclusion</h2>
<p>This blog discussed a critical token validation failure in the Azure AD Graph API. While the vulnerability itself was a bad oversight in the token handling, the whole concept of Actor tokens is a protocol that was designed to behave with all the properties mentioned in the paragraphs above. If it weren’t for the complete lack of security measures in these tokens, I don’t think such a big impact with such limited telemetry would have been possible.</p>

<p>Thanks to the people at MSRC who immediately picked up the vulnerability report, searched for potential variants in other resources, and to the engineers who followed up with fixes for the Azure AD Graph and blocked Actor tokens for the Azure AD Graph API requested with credentials stored on Service Principals, essentially restricting the usage of these Actor tokens to only Microsoft internal services.</p>

<h2 id="disclosure-timeline">Disclosure timeline</h2>

<ul>
  <li>July 14, 2025 - reported issue to MSRC.</li>
  <li>July 14, 2025 - MSRC case opened.</li>
  <li>July 15, 2025 - reported further details on the impact.</li>
  <li>July 15, 2025 - MSRC requested to halt further testing of this vulnerability.</li>
  <li>July 17, 2025 - Microsoft pushed a fix for the issue globally into production.</li>
  <li>July 23, 2025 - Issue confirmed as resolved by MSRC.</li>
  <li>August 6, 2025 - Further mitigations pushed out preventing Actor tokens being issued for the Azure AD Graph with SP credentials.</li>
  <li>September 4, 2025 - <a href="https://msrc.microsoft.com/update-guide/vulnerability/CVE-2025-55241">CVE-2025-55241</a> issued.</li>
  <li>September 17, 2025 - Release of this blogpost.</li>
</ul>



        
      </section>

      

      


      
  

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ABC Pulls Jimmy Kimmel Live from the Air 'Indefinitely' (148 pts)]]></title>
            <link>https://www.vulture.com/article/abc-pulls-jimmy-kimmel-live-from-the-air-indefinitely.html</link>
            <guid>45282485</guid>
            <pubDate>Wed, 17 Sep 2025 23:00:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vulture.com/article/abc-pulls-jimmy-kimmel-live-from-the-air-indefinitely.html">https://www.vulture.com/article/abc-pulls-jimmy-kimmel-live-from-the-air-indefinitely.html</a>, See on <a href="https://news.ycombinator.com/item?id=45282485">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-editable="main" data-track-zone="main">  <article role="main" data-track-type="article-detail" data-uri="www.vulture.com/_components/article/instances/cmfojo9bx000j0jik2r8w9h6u@published" data-content-channel="TV" data-crosspost="" data-type="Breaking-News-Original Reporting" data-syndication="original" data-headline="ABC Pulls Jimmy Kimmel Live! From the Air ‘Indefinitely’" data-authors="Josef Adalian" data-publish-date="2025-09-17" data-tags="tv, comedy, late night, jimmy kimmel live!, jimmy kimmel, politics, charlie kirk, vulture homepage lede" data-issue-date="" data-components-count="4" data-canonical-url="http://www.vulture.com/article/abc-pulls-jimmy-kimmel-live-from-the-air-indefinitely.html">


  
  
  
  <header>
    <div>
          

            <p><span data-editable="bylines">
            <p><span>By</span> <span>
        ,
          <span>who has covered the television industry since 1992</span><span>&nbsp;</span>
          <span>and writes Buffering, a newsletter about streaming</span>
      </span></p>

              </span>
          </p>
        </div>
    
  </header>
  <section>
    
    <div id="vulture-zephr-anchor" data-editable="content">
      <div>
          <div>
            <picture> <source media="(min-resolution: 192dpi) and (min-width: 1180px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 1180px)" srcset="https://pyxis.nymag.com/v1/imgs/8c0/d93/983356eab25f0dade8b73751d607a07a7f-jimmy-kimmel.2x.rhorizontal.w700.jpg 2x" width="700" height="467"> <source media="(min-width: 1180px) " srcset="https://pyxis.nymag.com/v1/imgs/8c0/d93/983356eab25f0dade8b73751d607a07a7f-jimmy-kimmel.rhorizontal.w700.jpg" width="700" height="467"> <source media="(min-resolution: 192dpi) and (min-width: 768px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/8c0/d93/983356eab25f0dade8b73751d607a07a7f-jimmy-kimmel.2x.rhorizontal.w700.jpg 2x" width="700" height="467"> <source media="(min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/8c0/d93/983356eab25f0dade8b73751d607a07a7f-jimmy-kimmel.rhorizontal.w700.jpg" width="700" height="467"> <source media="(min-resolution: 192dpi), (-webkit-min-device-pixel-ratio: 2)" srcset="https://pyxis.nymag.com/v1/imgs/8c0/d93/983356eab25f0dade8b73751d607a07a7f-jimmy-kimmel.2x.rhorizontal.w700.jpg" width="700" height="467"> <img src="https://pyxis.nymag.com/v1/imgs/8c0/d93/983356eab25f0dade8b73751d607a07a7f-jimmy-kimmel.rhorizontal.w700.jpg" data-content-img="" alt="JIMMY KIMMEL" width="700" height="467" fetchpriority="high"> </picture>
          </div>
            <div>
              <p><span>Photo: Randy Holmes/Disney via Getty Images</span>
              </p>
            </div>
              </div>
        <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cmfojo9bx000i0jik5fd1vt55@published" data-word-count="65">Conservative cancel culture has come for Jimmy Kimmel: Walt Disney–owned ABC has announced it’s pulling new episodes of <em>Jimmy Kimmel Live! </em>“indefinitely” following right-wing outrage over comments he made on his September 15 show about the reaction to the <a href="https://nymag.com/intelligencer/article/charlie-kirk-shooting-at-utah-university-q-and-a-live-updates.html">killing of right-wing podcaster and provocateur Charlie Kirk</a>. Disney’s&nbsp;decision follows a move by one of its major affiliate groups, Nexstar, to preempt the show in response.</p>

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cmfokcub900253b74tnikyb3l@published" data-word-count="133">While Nexstar didn’t say exactly what Kimmel had said that it objected to, and ABC offered no further explanation of its move, FCC chairman Brendan Carr earlier on Wednesday denounced this part of the host’s Monday monologue, <a href="https://deadline.com/2025/09/fcc-jimmy-kimmel-charlie-kirk-suspect-1236547238/">per Deadline</a>: “We had some new lows over the weekend with the MAGA gang desperately trying to characterize this kid who murdered Charlie Kirk as anything other than one of them and with everything they can to score political points from it.” Around 6 p.m. ET Wednesday, Nexstar issued this statement: “Nexstar strongly objects to recent comments made by Mr. Kimmel concerning the killing of Charlie Kirk and will replace the show with other programming in its ABC-affiliated markets.” When Vulture asked ABC for comment, a network rep replied, “<em>Jimmy Kimmel Live!</em> will be preempted indefinitely.”</p>

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cmfokcub900263b74w1qr3a7v@published" data-word-count="28">Vulture has reached out to Kimmel’s reps for comment and asked Nexstar and ABC for additional clarification of today’s actions. We’ll update this story when we know more.</p>

  


    </div>

      


          



      <span>ABC Pulls <em>Jimmy Kimmel Live!</em> From the Air ‘Indefinitely’</span>



    <dialog>
      <span>
        <svg width="6" height="14" viewBox="0 0 6 14" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path d="M4.84191 13.478C4.84191 13.826 4.64391 14 4.24791 14H1.54791C1.22391 14 1.06191 13.85 1.06191 13.55V10.85C1.06191 10.586 1.17591 10.454 1.40391 10.454H4.51791C4.73391 10.454 4.84191 10.574 4.84191 10.814V13.478ZM4.13991 8.708C4.12791 8.888 4.07391 9.02 3.97791 9.104C3.89391 9.176 3.74991 9.212 3.54591 9.212H2.30391C2.12391 9.212 2.00391 9.176 1.94391 9.104C1.89591 9.032 1.85991 8.918 1.83591 8.762L0.935906 1.058C0.923906 0.926 0.947906 0.823999 1.00791 0.751999C1.07991 0.679999 1.16991 0.643999 1.27791 0.643999H4.67991C4.91991 0.643999 5.02791 0.769999 5.00391 1.022L4.13991 8.708Z" fill="#DB2800"></path>
</svg>

      </span>
      <span></span>
      <span>
        <svg width="14" height="13" viewBox="0 0 14 13" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path fill-rule="evenodd" clip-rule="evenodd" d="M12.9823 1.22855C13.1775 1.03329 13.1775 0.716709 12.9823 0.521447C12.787 0.326184 12.4704 0.326184 12.2751 0.521447L7.00185 5.79474L1.72855 0.521447C1.53329 0.326184 1.21671 0.326184 1.02145 0.521447C0.826184 0.716709 0.826184 1.03329 1.02145 1.22855L6.29474 6.50185L1.02145 11.7751C0.826184 11.9704 0.826184 12.287 1.02145 12.4823C1.21671 12.6775 1.53329 12.6775 1.72855 12.4823L7.00185 7.20896L12.2751 12.4823C12.4704 12.6775 12.787 12.6775 12.9823 12.4823C13.1775 12.287 13.1775 11.9704 12.9823 11.7751L7.70896 6.50185L12.9823 1.22855Z" fill="#DA4022"></path>
</svg>

      </span>
    </dialog>

  </section>
  

</article>

  

</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ABC yanks Jimmy Kimmel's show 'indefinitely' after remarks about Charlie Kirk (454 pts)]]></title>
            <link>https://www.cnn.com/2025/09/17/media/jimmy-kimmel-charlie-kirk-trump-fcc-brendan-carr</link>
            <guid>45282482</guid>
            <pubDate>Wed, 17 Sep 2025 23:00:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2025/09/17/media/jimmy-kimmel-charlie-kirk-trump-fcc-brendan-carr">https://www.cnn.com/2025/09/17/media/jimmy-kimmel-charlie-kirk-trump-fcc-brendan-carr</a>, See on <a href="https://news.ycombinator.com/item?id=45282482">Hacker News</a></p>
Couldn't get https://www.cnn.com/2025/09/17/media/jimmy-kimmel-charlie-kirk-trump-fcc-brendan-carr: Error: Request failed with status code 451]]></description>
        </item>
        <item>
            <title><![CDATA[A postmortem of three recent issues (353 pts)]]></title>
            <link>https://www.anthropic.com/engineering/a-postmortem-of-three-recent-issues</link>
            <guid>45281139</guid>
            <pubDate>Wed, 17 Sep 2025 20:41:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anthropic.com/engineering/a-postmortem-of-three-recent-issues">https://www.anthropic.com/engineering/a-postmortem-of-three-recent-issues</a>, See on <a href="https://news.ycombinator.com/item?id=45281139">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><p>Between August and early September, three infrastructure bugs intermittently degraded Claude's response quality. We've now resolved these issues and want to explain what happened.</p><p>In early August, a number of users began reporting degraded responses from Claude. These initial reports were difficult to distinguish from normal variation in user feedback. By late August, the increasing frequency and persistence of these reports prompted us to open an investigation that led us to uncover three separate infrastructure bugs.</p><p>To state it plainly: We never reduce model quality due to demand, time of day, or server load. The problems our users reported were due to infrastructure bugs alone.</p><p>We recognize users expect consistent quality from Claude, and we maintain an extremely high bar for ensuring infrastructure changes don't affect model outputs. In these recent incidents, we didn't meet that bar. The following postmortem explains what went wrong, why detection and resolution took longer than we would have wanted, and what we're changing to prevent similar future incidents.</p><p>We don't typically share this level of technical detail about our infrastructure, but the scope and complexity of these issues justified a more comprehensive explanation.</p><h2 id="how-we-serve-claude-at-scale">How we serve Claude at scale</h2><p>We serve Claude to millions of users via our first-party API, Amazon Bedrock, and Google Cloud's Vertex AI. We deploy Claude across multiple hardware platforms, namely AWS Trainium, NVIDIA GPUs, and Google TPUs. This approach provides the capacity and geographic distribution necessary to serve users worldwide.</p><p>Each hardware platform has different characteristics and requires specific optimizations. Despite these variations, we have strict equivalence standards for model implementations. Our aim is that users should get the same quality responses regardless of which platform serves their request. This complexity means that any infrastructure change requires careful validation across all platforms and configurations.</p><h2 id="timeline-of-events">Timeline of events</h2><div><figure><img alt="Illustrative timeline of events on the Claude API. Yellow: issue detected, Red: degradation worsened, Green: fix deployed." loading="lazy" width="3840" height="1800" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fd707dfc2effceba608d04007bc776132a3e57838-3840x1800.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fd707dfc2effceba608d04007bc776132a3e57838-3840x1800.png&amp;w=3840&amp;q=75"><figcaption>Illustrative timeline of events on the <strong>Claude API</strong>. Yellow: issue detected, Red: degradation worsened, Green: fix deployed.</figcaption></figure></div><p>The overlapping nature of these bugs made diagnosis particularly challenging. The first bug was introduced on August 5, affecting approximately 0.8% of requests made to Sonnet 4. Two more bugs arose from deployments on August 25 and 26.</p><p>Although initial impacts were limited, a load balancing change on August 29 started to increase affected traffic. This caused many more users to experience issues while others continued to see normal performance, creating confusing and contradictory reports.</p><h2 id="three-overlapping-issues">Three overlapping issues</h2><p>Below we describe the three bugs that caused the degradation, when they occurred, and how we resolved them:</p><h3 id="1-context-window-routing-error">1. Context window routing error</h3><p>On August 5, some Sonnet 4 requests were misrouted to servers configured for the upcoming <a href="https://docs.claude.com/en/docs/build-with-claude/context-windows#1m-token-context-window">1M token</a> <a href="https://docs.claude.com/en/docs/build-with-claude/context-windows">context window</a>. This bug initially affected 0.8% of requests. On August 29, a routine load balancing change unintentionally increased the number of short-context requests routed to the 1M context servers. At the worst impacted hour on August 31, 16% of Sonnet 4 requests were affected.</p><p>Approximately 30% of Claude Code users who made requests during this period had at least one message routed to the wrong server type, resulting in degraded responses. On Amazon Bedrock, misrouted traffic peaked at 0.18% of all Sonnet 4 requests from August 12. Incorrect routing affected less than 0.0004% of requests on Google Cloud's Vertex AI between August 27 and September 16.</p><p>However, some users were affected more severely, as our routing is "sticky". This meant that once a request was served by the incorrect server, subsequent follow-ups were likely to be served by the same incorrect server.</p><p><strong>Resolution:</strong> We fixed the routing logic to ensure short- and long-context requests were directed to the correct server pools. We deployed the fix on September 4. A rollout to our first-party platforms and Google Cloud’s Vertex was completed by September 16. The fix is in the process of being rolled out on Bedrock.</p><h3 id="2-output-corruption">2. Output corruption</h3><p>On August 25, we deployed a misconfiguration to the Claude API TPU servers that caused an error during token generation. An issue caused by a runtime performance optimization occasionally assigned a high probability to tokens that should rarely be produced given the context, for example producing Thai or Chinese characters in response to English prompts, or producing obvious syntax errors in code. A small subset of users that asked a question in English might have seen "สวัสดี" in the middle of the response, for example.</p><p>This corruption affected requests made to Opus 4.1 and Opus 4 on August 25-28, and requests to Sonnet 4 August 25–September 2. Third-party platforms were not affected by this issue.</p><p><strong>Resolution:</strong> We identified the issue and rolled back the change on September 2. We've added detection tests for unexpected character outputs to our deployment process.</p><h3 id="3-approximate-top-k-xlatpu-miscompilation">3. Approximate top-k XLA:TPU miscompilation</h3><p>On August 25, we deployed code to improve how Claude selects tokens during text generation. This change inadvertently triggered a latent bug in the XLA:TPU<sup>[1] </sup>compiler, which has been confirmed to affect requests to Claude Haiku 3.5.</p><p>We also believe this could have impacted a subset of Sonnet 4 and Opus 3 on the Claude API. Third-party platforms were not affected by this issue.</p><p><strong>Resolution:</strong> We first observed the bug affecting Haiku 3.5 and rolled it back on September 4. We later noticed user reports of problems with Opus 3 that were compatible with this bug, and rolled it back on September 12. After extensive investigation we were unable to reproduce this bug on Sonnet 4 but decided to also roll it back out of an abundance of caution.</p><p>Simultaneously, we have (a) been working with the XLA:TPU team on a fix for the compiler bug and (b) rolled out a fix to use exact top-k with enhanced precision. For details, see the deep dive below.</p><h2 id="a-closer-look-at-the-xla-compiler-bug">A closer look at the XLA compiler bug</h2><p>To illustrate the complexity of these issues, here's how the XLA compiler bug manifested and why it proved particularly challenging to diagnose.</p><p>When Claude generates text, it calculates probabilities for each possible next word, then randomly chooses a sample from this probability distribution. We use "top-p sampling" to avoid nonsensical outputs—only considering words whose cumulative probability reaches a threshold (typically 0.99 or 0.999). On TPUs, our models run across multiple chips, with probability calculations happening in different locations. To sort these probabilities, we need to coordinate data between chips, which is complex.<sup>[2]</sup></p><p>In December 2024, we discovered our TPU implementation would occasionally drop the most probable token when <a href="https://docs.claude.com/en/docs/about-claude/glossary#temperature">temperature</a> was zero. We deployed a workaround to fix this case.</p><div><figure><img alt="Code snippet of a December 2024 patch to work around the unexpected dropped token bug when temperature = 0." loading="lazy" width="2000" height="500" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fefee0d3d25f6b03cbfc57e70e0e364dcd8b82fe0-2000x500.png&amp;w=2048&amp;q=75 1x, https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fefee0d3d25f6b03cbfc57e70e0e364dcd8b82fe0-2000x500.png&amp;w=3840&amp;q=75 2x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fefee0d3d25f6b03cbfc57e70e0e364dcd8b82fe0-2000x500.png&amp;w=3840&amp;q=75"><figcaption>Code snippet of a December 2024 patch to work around the unexpected dropped token bug when temperature = 0.</figcaption></figure></div><p>The root cause involved mixed precision arithmetic. Our models compute next-token probabilities in <a href="https://github.com/tensorflow/tensorflow/blob/f41959ccb2d9d4c722fe8fc3351401d53bcf4900/tensorflow/core/framework/bfloat16.h">bf16</a> (16-bit floating point). However, the vector processor is <a href="https://dl.acm.org/doi/pdf/10.1145/3360307">fp32-native</a>, so the TPU compiler (XLA) can optimize runtime by converting some operations to fp32 (32-bit). This optimization pass is guarded by the <code>xla_allow_excess_precision</code> flag which defaults to true.</p><p>This caused a mismatch: operations that should have agreed on the highest probability token were running at different precision levels. The precision mismatch meant they didn't agree on which token had the highest probability. This caused the highest probability token to sometimes disappear from consideration entirely.</p><p>On August 26, we deployed a rewrite of our sampling code to fix the precision issues and improve how we handled probabilities at the limit that reach the top-p threshold. But in fixing these problems, we exposed a trickier one.</p><div><figure><img alt="Code snippet showing minimized reproducer merged as part of the August 11 change that root-caused the “bug” being worked around in December 2024; in reality, it’s expected behavior of the xla_allow_excess_precision flag." loading="lazy" width="2000" height="2560" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F6d10e58c0bd5fd7cb03dc0adc716cb1e4f039343-2000x2560.png&amp;w=2048&amp;q=75 1x, https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F6d10e58c0bd5fd7cb03dc0adc716cb1e4f039343-2000x2560.png&amp;w=3840&amp;q=75 2x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F6d10e58c0bd5fd7cb03dc0adc716cb1e4f039343-2000x2560.png&amp;w=3840&amp;q=75"><figcaption>Code snippet showing a minimized reproducer merged as part of the August 11 change that root-caused the "bug" being worked around in December 2024. In reality, it’s expected behavior of the <code>xla_allow_excess_precision</code> flag.</figcaption></figure></div><p>Our fix removed the December workaround because we believed we'd solved the root cause. This led to a deeper bug in the <a href="https://docs.jax.dev/en/latest/_autosummary/jax.lax.approx_max_k.html">approximate top-k</a> operation—a performance optimization that quickly finds the highest probability tokens.<sup>[3]</sup> This approximation sometimes returned completely wrong results, but only for certain batch sizes and model configurations. The December workaround had been inadvertently masking this problem.</p><div><figure><img alt="Slack message showing reproducer of the underlying approximate top-k bug shared with the XLA:TPU engineers who developed the algorithm. The code returns correct results when run on CPUs." loading="lazy" width="2400" height="1404" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F7e42db934d0e84ea40fc56b416ddb09b2097a5ff-2400x1404.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F7e42db934d0e84ea40fc56b416ddb09b2097a5ff-2400x1404.png&amp;w=3840&amp;q=75"><figcaption>Reproducer of the underlying approximate top-k bug shared with the XLA:TPU engineers who <a href="https://arxiv.org/pdf/2206.14286">developed the algorithm</a>. The code returns correct results when run on CPUs.</figcaption></figure></div><p>The bug's behavior was frustratingly inconsistent. It changed depending on unrelated factors such as what operations ran before or after it, and whether debugging tools were enabled. The same prompt might work perfectly on one request and fail on the next.</p><p>While investigating, we also discovered that the exact top-k operation no longer had the prohibitive performance penalty it once did. We switched from approximate to exact top-k and standardized some additional operations on fp32 precision.<sup>[4]</sup> Model quality is non-negotiable, so we accepted the minor efficiency impact.</p><h2 id="why-detection-was-difficult">Why detection was difficult</h2><p>Our validation process ordinarily relies on benchmarks alongside safety evaluations and performance metrics. Engineering teams perform spot checks and deploy to small "canary" groups first.</p><p>These issues exposed critical gaps that we should have identified earlier. The evaluations we ran simply didn't capture the degradation users were reporting, in part because Claude often recovers well from isolated mistakes. Our own privacy practices also created challenges in investigating reports. Our internal privacy and security controls limit how and when engineers can access user interactions with Claude, in particular when those interactions are not reported to us as feedback. This protects user privacy but prevents engineers from examining the problematic interactions needed to identify or reproduce bugs.</p><p>Each bug produced different symptoms on different platforms at different rates. This created a confusing mix of reports that didn't point to any single cause. It looked like random, inconsistent degradation.</p><p>More fundamentally, we relied too heavily on noisy evaluations. Although we were aware of an increase in reports online, we lacked a clear way to connect these to each of our recent changes. When negative reports spiked on August 29, we didn't immediately make the connection to an otherwise standard load balancing change.</p><h2 id="what-were-changing">What we're changing</h2><p>As we continue to improve our infrastructure, we're also improving the way we evaluate and prevent bugs like those discussed above across all platforms where we serve Claude. Here's what we're changing:</p><ul><li><strong>More sensitive evaluations:</strong> To help discover the root cause of any given issue, we’ve developed evaluations that can more reliably differentiate between working and broken implementations. We’ll keep improving these evaluations to keep a closer eye on model quality.</li><li><strong>Quality evaluations in more places:</strong> Although we run regular evaluations on our systems, we will run them continuously on true production systems to catch issues such as the context window load balancing error.</li><li><strong>Faster debugging tooling:</strong> We'll develop infrastructure and tooling to better debug community-sourced feedback without sacrificing user privacy. Additionally, some bespoke tools developed here will be used to reduce the remediation time in future similar incidents, if those should occur.</li></ul><p>Evals and monitoring are important. But these incidents have shown that we also need continuous signal from users when responses from Claude aren't up to the usual standard. Reports of specific changes observed, examples of unexpected behavior encountered, and patterns across different use cases all helped us isolate the issues.</p><p>It remains particularly helpful for users to continue to send us their feedback directly. You can use the <code>/bug</code> command in Claude Code or you can use the "thumbs down" button in the Claude apps to do so. Developers and researchers often create new and interesting ways to evaluate model quality that complement our internal testing. If you'd like to share yours, reach out to <a href="mailto:feedback@anthropic.com">feedback@anthropic.com</a>.</p><p>We remain grateful to our community for these contributions.</p><p><sup>[1]</sup> XLA:TPU is the optimizing compiler that translates <a href="https://openxla.org/xla/architecture">XLA</a> High Level Optimizing language—often written using <a href="https://docs.jax.dev/en/latest">JAX</a>—to TPU machine instructions.</p><p><sup>[2]</sup> Our models are too large for single chips and are partitioned across tens of chips or more, making our sorting operation a distributed sort. TPUs (just like GPUs and Trainium) also have different performance characteristics than CPUs, requiring different implementation techniques using vectorized operations instead of serial algorithms.</p><p><sup>[3]</sup> We had been using this approximate operation because it yielded substantial performance improvements. The approximation works by accepting potential inaccuracies in the lowest probability tokens, which shouldn't affect quality—except when the bug caused it to drop the highest probability token instead.</p><p><sup>[4]</sup> Note that the now-correct top-k implementation may result in slight differences in the inclusion of tokens near the top-p threshold, and in rare cases users may benefit from re-tuning their choice of top-p.</p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Famous cognitive psychology experiments that failed to replicate (161 pts)]]></title>
            <link>https://buttondown.com/aethermug/archive/aether-mug-famous-cognitive-psychology/</link>
            <guid>45279898</guid>
            <pubDate>Wed, 17 Sep 2025 18:55:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://buttondown.com/aethermug/archive/aether-mug-famous-cognitive-psychology/">https://buttondown.com/aethermug/archive/aether-mug-famous-cognitive-psychology/</a>, See on <a href="https://news.ycombinator.com/item?id=45279898">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main components="[object Object]"><p><em>TL;DR is the part in bold below.</em></p>
<p>The field of psychology had a big crisis in the 2010s, when many widely accepted results turned out to be much less solid than previously thought. It's called the <a href="https://en.wikipedia.org/w/index.php?title=Replication_crisis" rel="nofollow noopener noreferrer" target="_blank">replication crisis</a>, because labs around the world tried and failed to replicate, in new experiments, previous results published by their original "discoverers". In other words, many reported psychological effects were either non-existent—artifacts of the experimenter's flawed setup—or so much weaker than originally claimed that they lost most of their intellectual sparkle.</p>
<p>(The crisis spanned other fields as well, but I mostly care about psychology here, especially the cognitive kind.)</p>
<p>This is very old news, and I've been vaguely aware of several of the biggest disgraced results for years, but I keep on forgetting which are (still probably) real and which aren't. This is not good. <em>Most</em> results in the field do actually replicate and are robust<sup>[citation needed]</sup>, so it would be a pity to lose confidence in the whole field just because of a few bad apples.</p>
<p><strong>This post is a compact reference list of the most (in)famous cognitive science results that failed to replicate and should, for the time being, be considered false.</strong> The only goal is to offset the trust-undermining effects of my poor memory—and perhaps yours, too?—with a bookmarkable page.</p>
<p>This can't be a comprehensive list: if a study is <em>not</em> on this page, it's not guaranteed to be fully replicated. Still, this should cover most of the high-profile debunked theories that laypeople like me may have heard of.</p>
<p><em>Credit: I enlisted the help of Kimi K2, o3, and Sonnet 4 to gather and fact-check this list. I also checked, pruned, and de-hallucinated all the results.</em></p>

<h3>Ego Depletion Effect</h3>
<ul>
<li><strong>Claimed result:</strong> We have a "willpower battery" that gradually depletes during the day as we exercise self-control. (I remember reading Baumeister's pop-science book and being awed by the implications of their findings; I might have known it sounded too good to be true.)</li>
<li><strong>Representative paper:</strong> <a href="https://psycnet.apa.org/doiLanding?doi=10.1037%2F0022-3514.74.5.1252" rel="nofollow noopener noreferrer" target="_blank">Baumeister et al. 1998</a></li>
<li><strong>Replication status:</strong> <em>did not replicate</em></li>
<li><strong>Source:</strong> <a href="https://journals.sagepub.com/doi/10.1177/1745691616652873" rel="nofollow noopener noreferrer" target="_blank">Hagger et (63!) al. 2016</a></li>
</ul>
<h3>Power Posing Effect</h3>
<ul>
<li><strong>Claimed result:</strong> Adopting expansive body postures for 2 minutes (like standing with hands on hips or arms raised) increases testosterone, decreases cortisol, and makes people feel more powerful and take more risks.</li>
<li><strong>Representative paper:</strong> <a href="https://doi.org/10.1177/0956797610383437" rel="nofollow noopener noreferrer" target="_blank">Carney, Cuddy, &amp; Yap (2010)</a></li>
<li><strong>Replication status:</strong> <em>did not replicate</em></li>
<li><strong>Source:</strong> <a href="https://doi.org/10.1177/0956797614553946" rel="nofollow noopener noreferrer" target="_blank">Ranehill et al. (2015)</a></li>
</ul>
<h3>Social Priming: Elderly Words Effect</h3>
<ul>
<li><strong>Claimed result:</strong> People walk more slowly after being exposed to words related to elderly stereotypes.</li>
<li><strong>Representative paper:</strong> <a href="https://doi.org/10.1037/0022-3514.71.2.230" rel="nofollow noopener noreferrer" target="_blank">Bargh, Chen, &amp; Burrows (1996)</a></li>
<li><strong>Replication status:</strong> <em>did not replicate</em></li>
<li><strong>Source:</strong> <a href="https://doi.org/10.1371/journal.pone.0029081" rel="nofollow noopener noreferrer" target="_blank">Doyen et al. (2012)</a> (I like how they prove that the psychological effect was actually in the experimenters, rather than the subjects!)</li>
</ul>
<h3>Money Priming Effect</h3>
<ul>
<li><strong>Claimed result:</strong> Simply thinking about money makes you more selfish and more likely to endorse free market values.</li>
<li><strong>Representative paper:</strong> <a href="https://doi.org/10.1126/science.1132491" rel="nofollow noopener noreferrer" target="_blank">Vohs, Mead, &amp; Goode (2006)</a></li>
<li><strong>Replication status:</strong> <em>did not replicate</em></li>
<li><strong>Source:</strong> <a href="https://pubmed.ncbi.nlm.nih.gov/26214168/" rel="nofollow noopener noreferrer" target="_blank">Rohrer, Pashler, &amp; Harris (2015)</a></li>
</ul>
<h3>ESP Precognition Effect</h3>
<ul>
<li><strong>Claimed result:</strong> In some cases, people can predict future events "that could not otherwise be anticipated through any known inferential process".</li>
<li><strong>Representative paper:</strong> <a href="https://doi.org/10.1037/a0021524" rel="nofollow noopener noreferrer" target="_blank">Bem (2011)</a></li>
<li><strong>Replication status:</strong> <em>did not replicate</em></li>
<li><strong>Source:</strong> <a href="https://doi.org/10.1037/a0029709" rel="nofollow noopener noreferrer" target="_blank">Galak et al. (2012)</a>, <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0033423" rel="nofollow noopener noreferrer" target="_blank">Ritchie, Wiseman, &amp; French (2012)</a></li>
</ul>
<h3>Cleanliness and Morality Effect</h3>
<ul>
<li><strong>Claimed result:</strong> Being clean or thinking about cleanliness makes people more morally lax.</li>
<li><strong>Representative paper:</strong> <a href="https://doi.org/10.1111/j.1467-9280.2008.02227.x" rel="nofollow noopener noreferrer" target="_blank">Schnall, Benton, &amp; Harvey (2008)</a></li>
<li><strong>Replication status:</strong> <em>did not replicate</em></li>
<li><strong>Source:</strong> <a href="https://doi.org/10.1027/1864-9335/a000186" rel="nofollow noopener noreferrer" target="_blank">Johnson, Cheung, &amp; Donnellan (2014)</a></li>
</ul>
<h3>Glucose and Ego Depletion Effect</h3>
<ul>
<li><strong>Claimed result:</strong> Connected to the debunked ego-depletion effect, this one claims that adding glucose to your blood "recharges" the willpower battery. (For a while, I may have drunk more orange juice than usual after reading Baumeister's book. At least it's healthy-ish.)</li>
<li><strong>Representative paper:</strong> <a href="https://doi.org/10.1037/0022-3514.92.2.325" rel="nofollow noopener noreferrer" target="_blank">Gailliot &amp; Baumeister (2007)</a></li>
<li><strong>Replication status:</strong> <em>did not replicate</em></li>
<li><strong>Source:</strong> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0195666313005072" rel="nofollow noopener noreferrer" target="_blank">Lange &amp; Eggert (2014)</a></li>
</ul>
<h3>Hunger and Risk-Taking Effect</h3>
<ul>
<li><strong>Claimed result:</strong> People exposed to the scent of freshly baked cookies become less sensitive to risk and take more risks to obtain food.</li>
<li><strong>Representative paper:</strong> <a href="https://onlinelibrary.wiley.com/doi/10.1002/bdm.520" rel="nofollow noopener noreferrer" target="_blank">Ditto et al. 2006</a></li>
<li><strong>Replication status:</strong> <em>did not replicate</em></li>
<li><strong>Source:</strong> <a href="https://doi.org/10.1016/j.foodqual.2018.02.014" rel="nofollow noopener noreferrer" target="_blank">Festjens, Bruyneel, &amp; Dewitte (2018)</a></li>
</ul>
<h3>Psychological Distance &amp; Construal Level Theory</h3>
<ul>
<li><strong>Claimed result</strong>: "Psychologically distant" events are processed more abstractly, while "psychologically near" events are processed more concretely. E.g., you worry about the difficulty of a task if you have to do it tomorrow, but you see the same task's attractive side if it is planned far in the future.</li>
<li><strong>Representative paper</strong>: <a href="https://pubmed.ncbi.nlm.nih.gov/20438233/" rel="nofollow noopener noreferrer" target="_blank">Trope &amp; Liberman (2010)</a>, building on <a href="https://nyuscholars.nyu.edu/en/publications/the-role-of-feasibility-and-desirability-considerations-in-near-a" rel="nofollow noopener noreferrer" target="_blank">Liberman &amp; Trope (1998)</a></li>
<li><strong>Replication status</strong>: <em>serious credibility problems</em></li>
<li><strong>Source</strong>: A <a href="https://climr.org/about/" rel="nofollow noopener noreferrer" target="_blank">collaboration</a> between 73 labs around the world is vetting this theory right now because of many doubts about its validity.</li>
</ul>
<h3>Ovulation &amp; Mate Preferences Effect</h3>
<ul>
<li><strong>Claimed result:</strong> Women are more attracted to hot guys during high-fertility days of their cycles.</li>
<li><strong>Representative paper:</strong> <a href="https://doi.org/10.1037/a0035438" rel="nofollow noopener noreferrer" target="_blank">Gildersleeve, Haselton, &amp; Fales (2014)</a></li>
<li><strong>Replication status:</strong> <em>did not replicate</em></li>
<li><strong>Source:</strong> <a href="https://publications.goettingen-research-online.de/bitstream/2/77327/1/10.1177_0956797619882022.pdf" rel="nofollow noopener noreferrer" target="_blank">Stern, Gerlach, &amp; Penke (2020)</a></li>
</ul>
<h3>Marshmallow Test &amp; Long-Term Success Effect</h3>
<ul>
<li><strong>Claimed result:</strong> Children's ability to resist eating a marshmallow when left alone in a room at age 4-5 strongly predicts adolescent achievement, with those who waited longer showing better life outcomes.</li>
<li><strong>Representative paper:</strong> <a href="https://doi.org/10.1037/0012-1649.26.6.978" rel="nofollow noopener noreferrer" target="_blank">Shoda, Mischel, &amp; Peake (1990)</a></li>
<li><strong>Replication status:</strong> <em>did not replicate significantly</em></li>
<li><strong>Source:</strong> <a href="https://doi.org/10.1177/0956797618761661" rel="nofollow noopener noreferrer" target="_blank">Watts, Duncan, &amp; Quan (2018)</a></li>
</ul>
<h3>Stereotype Threat (Women's Math Performance) Effect</h3>
<ul>
<li><strong>Claimed result:</strong> Women risk being judged by the negative stereotype that women have weaker math ability, and this apprehension disrupts their math performance on difficult tests.</li>
<li><strong>Representative paper:</strong> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0022103198913737" rel="nofollow noopener noreferrer" target="_blank">Spencer, Steele, &amp; Quinn (1999)</a></li>
<li><strong>Replication status:</strong> <em>did not replicate</em></li>
<li><strong>Source:</strong> <a href="https://doi.org/10.1016/j.jsp.2014.10.002" rel="nofollow noopener noreferrer" target="_blank">Flore &amp; Wicherts (2015)</a></li>
</ul>
<h3>Smile to Feel Better Effect</h3>
<ul>
<li><strong>Claimed result</strong>: Holding a pen in your teeth (forcing a smile-like expression) makes you rate cartoons as funnier compared to holding a pen with your lips (preventing smiling). More broadly, facial expressions can influence emotional experiences: "fake it till you make it."</li>
<li><strong>Representative paper</strong>: <a href="https://psycnet.apa.org/record/1988-25514-001" rel="nofollow noopener noreferrer" target="_blank">Strack, Martin, &amp; Stepper (1988)</a></li>
<li><strong>Replication status</strong>: <em>did not replicate</em></li>
<li><strong>Source</strong>: <a href="https://journals.sagepub.com/doi/full/10.1177/1745691616674458" rel="nofollow noopener noreferrer" target="_blank">Wagenmakers et (54!) al. (2016)</a></li>
</ul>
<h3>Objective Measurement of Biases</h3>
<ul>
<li><strong>Claimed result</strong>: You can predict if someone is racist by how quickly they answer certain trick questions.</li>
<li><strong>Representative paper</strong>: <a href="https://psycnet.apa.org/doiLanding?doi=10.1037%2F0022-3514.74.6.1464" rel="nofollow noopener noreferrer" target="_blank">Greenwald, McGhee, &amp; Schwartz (1998)</a></li>
<li><strong>Replication status</strong>: <em>mixed evidence with small effects</em></li>
<li><strong>Source</strong>: <a href="https://pubmed.ncbi.nlm.nih.gov/23773046/" rel="nofollow noopener noreferrer" target="_blank">Oswald et al. (2013)</a> shows that the prediction power is small at best.</li>
</ul>
<h3>Mozart Effect</h3>
<ul>
<li><strong>Claimed result</strong>: Listening to Mozart temporarily makes you smarter.</li>
<li><strong>Representative paper</strong>: <a href="https://www.nature.com/articles/365611a0" rel="nofollow noopener noreferrer" target="_blank">Rauscher, Shaw, &amp; Ky (1993)</a></li>
<li><strong>Replication status</strong>: <em>did not replicate</em></li>
<li><strong>Source</strong>: <a href="https://www.sciencedirect.com/science/article/abs/pii/S0160289610000267" rel="nofollow noopener noreferrer" target="_blank">Pietschnig, Voracek, &amp; Formann (2010)</a> (What a title!)</li>
</ul>
<h3>Growth Mindset Interventions</h3>
<ul>
<li><strong>Claimed result:</strong> Teaching students that intelligence is malleable (not fixed) dramatically improves academic performance.</li>
<li><strong>Representative paper:</strong> <a href="https://psycnet.apa.org/doiLanding?doi=10.1037%2F0033-295X.95.2.256" rel="nofollow noopener noreferrer" target="_blank">Dweck, &amp; Leggett (1988)</a></li>
<li><strong>Replication status:</strong> <em>mixed results</em> - many failed replications but also some successful replications</li>
<li><strong>Failed replication source:</strong> <a href="https://pubmed.ncbi.nlm.nih.gov/31464486/" rel="nofollow noopener noreferrer" target="_blank">Li &amp; Bates 2019</a></li>
<li><strong>Notable successful replication:</strong> <a href="https://www.nature.com/articles/s41586-019-1466-y" rel="nofollow noopener noreferrer" target="_blank">Yeager et al. 2019 in Nature</a></li>
</ul>
<h3>Bilinguals Are Smarter</h3>
<ul>
<li><strong>Claimed result:</strong> Being bilingual provides substantial cognitive advantages in attention, task-switching, and executive control.</li>
<li><strong>Representative paper:</strong> <a href="https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(12)00056-3" rel="nofollow noopener noreferrer" target="_blank">Bialystok, Craik, &amp; Luk (2012)</a></li>
<li><strong>Replication status:</strong> <em>did not replicate</em></li>
<li><strong>Source:</strong> <a href="https://pubmed.ncbi.nlm.nih.gov/29494195/" rel="nofollow noopener noreferrer" target="_blank">Lehtonen et al. 2018</a></li>
</ul>
<p>Did I miss any famous debunked studies? Let me know by replying to this newsletter, and I'll add it to the list. ●</p>
<div><p>Cover image:</p><p><em>Photo by Rebecca Freeman, Unsplash</em></p></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Optimizing ClickHouse for Intel's 280 core processors (211 pts)]]></title>
            <link>https://clickhouse.com/blog/optimizing-clickhouse-intel-high-core-count-cpu</link>
            <guid>45279792</guid>
            <pubDate>Wed, 17 Sep 2025 18:46:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://clickhouse.com/blog/optimizing-clickhouse-intel-high-core-count-cpu">https://clickhouse.com/blog/optimizing-clickhouse-intel-high-core-count-cpu</a>, See on <a href="https://news.ycombinator.com/item?id=45279792">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><blockquote>
<p>This is a guest post from Jiebin Sun, Zhiguo Zhou, Wangyang Guo and Tianyou Li, performance optimization engineers at Intel Shanghai.</p>
</blockquote>
<p>Intel's latest processor generations are pushing the number of cores in a server to unprecedented levels - from 128 P-cores per socket in Granite Rapids to 288 E-cores per socket in Sierra Forest, with future roadmaps targeting 200+ cores per socket. These numbers multiply on multi-socket systems, such servers may consist of 400 and more cores. The paradigm of "more, not faster cores" is driven by physical limitations. Since the end of Dennard scaling in the mid-2000s, power density concerns made it increasingly difficult to push single-thread performance further.</p>
<p>For analytical databases like ClickHouse, ultra-high core counts represent a huge opportunity and a complex challenge at the same time. While more cores theoretically mean more power to process tasks in parallel, most databases struggle to utilize the available hardware fully. Bottlenecks for parallel processing  like lock contention, cache coherence, non-uniform memory access (NUMA), memory bandwidth, and coordination overhead become significantly worse as the core count increases.</p>

<p>Over the past three years, I dedicated a part of my professional life to understand and optimize ClickHouse's scalability on Intel Xeon ultra-high core count processors. My work focused on using various profiling and analysis tools - including perf, emon, and Intel VTune - to analyze all 43 ClickBench queries on ultra-high core count servers systematically, identifying bottlenecks, and optimizing the ClickHouse accordingly.</p>
<p>The results have been exciting: individual optimizations routinely deliver speedups of multiple times for individual queries, in some cases up to 10x. The geometric mean of all 43 ClickBench queries consistently improved between 2% and 10% per optimization. The results demonstrate that ClickHouse can be made scale very well on ultra-high core count systems.</p>

<p>Beyond single-thread performance, several key challenges must be addressed to optimize performance in ultra-high core count systems.</p>
<ol>
<li><strong>Cache coherence overhead</strong>: Bouncing cache lines costs CPU cycles.</li>
<li><strong>Lock contention</strong>: Amdahl's Law becomes brutal for serialized code sections as little as 1% of the overall code.</li>
<li><strong>Memory bandwidth</strong>: Utilizing the memory bandwidth effectively is a persistent challenge for data-intensive systems. Proper memory reuse, management and caching becomes critical.</li>
<li><strong>Thread coordination</strong>: The cost of synchronizing threads grows super-linearly with the number of threads.</li>
<li><strong>NUMA effects</strong>: The memory latency and bandwidth on multi-socket systems differs for local or remote memory.</li>
</ol>
<p>This blog post summarizes our optimizations for ClickHouse on ultra-high core count servers. All of them were merged into the main codeline and they now help to speed up queries in ClickHouse deployments around the globe.</p>
<p><strong>Hardware setup</strong>: Our work was conducted on Intel's latest generation platforms, including 2 x 80 vCPUs Ice Lake (ICX), 2 x 128 vCPUs Sapphire Rapids (SPR), 1 x 288 vCPUs Sierra Forest (SRF), and 2 x 240 vCPUs Granite Rapids (GNR). SMT (Hyper-threading) was enabled, except on SRF which doesn't support SMT, and high-memory-bandwidth configurations.</p>
<p><strong>Software setup</strong>: We used perf, Intel VTune, pipeline visualization, and other custom profiling infrastructure.</p>

<p>Through a systematic analysis of ClickHouse's performance on ultra-high core count systems, I identified five areas with a high potential for optimization. Each area addresses a different aspect of scalability, and together they form a comprehensive approach to unlocking the full potential of ultra-high core count systems.</p>
<p>My journey began with the most fundamental challenge: lock contention.</p>
<h2 id="bottleneck-1-lock-contention"><strong>Bottleneck 1: Lock contention</strong> </h2>
<p>According to queue theory, if N threads compete for the same lock, the cycles grows quadratically (N^2). For example, if we go from 8 to 80 cores, lock wait times increase by (80/8)² = 100x. Furthermore, cache coherence traffic for the mutex itself grows linearly with the core count, and the overhead for context switching compounds the problem. In such settings, every mutex becomes a potential scalability obstacle, and seemingly innocent synchronization patterns can bring entire systems to their knee.</p>
<p>The key insight is that lock contention isn't just about removing locks - it's about rethinking more fundamentally how threads coordinate and share state. This requires a multi-pronged approach: reducing the duration of critical sections, replacing exclusive locks (mutexes) with more granular synchronization primitives, and in some cases, eliminating shared state entirely.</p>

<p>After resolving jemalloc page faults (an optimization detailed below), a new hotspot appeared in <code>native_queued_spin_lock_slowpath</code> which consumed 76% of the CPU time. This function was called from <code>QueryConditionCache::write</code> on 2×240 vCPU systems.</p>
<p><strong>What is the query condition cache?</strong></p>
<p><a href="https://clickhouse.com/docs/operations/query-condition-cache">ClickHouse’s query condition cache</a> stores the results of WHERE filters, enabling the database to skip irrelevant data. In each SELECT query, multiple threads check if cache entries must be updated based on different criteria:</p>
<ul>
<li>the hash of the filter condition (as cache key)</li>
<li>the read mark ranges</li>
<li>whether the currently read part has a final mark</li>
</ul>
<p>The query condition cache is read-heavy, i.e. there are far more reads than writes, but the original implementation used exclusive locking for all operations.</p>
<p><strong>Reducing critical paths in read-heavy workloads</strong></p>
<p>This optimization demonstrates the importance of reducing the time spent holding locks, especially write locks in read-heavy code.</p>
<p>With 240 threads within a single query, the original code created a perfect storm:</p>
<ol>
<li><strong>Unnecessary write locks</strong>: All threads acquired exclusive locks, even when they only read cache entries.</li>
<li><strong>Long critical sections</strong>: Expensive updates of cache entries were performed inside exclusive locks.</li>
<li><strong>Redundant work</strong>: Multiple threads updated the same cache entries potentially multiple times.</li>
</ol>
<p>Our optimization uses <a href="https://en.wikipedia.org/wiki/Double-checked_locking">double-checked locking</a> with atomic operations to resolve these bottlenecks:</p>
<ol>
<li>The code now first checks with atomic reads (no locking), respectively under a shared lock if an update is needed at all (fast path).</li>
<li>Next, the code checks immediately after acquiring an exclusive lock (slow path) if an update is actually required - another thread may have performed the same update in the meantime.</li>
</ol>
<p><strong>Implementation</strong></p>
<p>Based on <a href="https://github.com/ClickHouse/ClickHouse/pull/80247/files">PR #80247</a>, the optimization introduces a fast path which checks if an update is needed before acquiring the expensive write lock.</p>
<pre><code><span>/// Original code</span>
<span>void</span> <span>updateCache</span><span>(mark_ranges, has_final_mark)</span>
{
    acquire_exclusive_lock(cache_mutex);  <span>/// 240 threads wait here!</span>

    <span>/// Always update marks, even if already in desired state</span>
    <span>for</span> (<span>const</span> <span>auto</span> &amp; range : mark_ranges)
        set_marks_to_false(range.begin, range.end);

    <span>if</span> (has_final_mark):
        set_final_mark_to_false();

    release_lock(cache_mutex);
}
</code></pre>
<pre><code>
<span>/// Optimized code</span>
<span>void</span> <span>updateCache</span><span>(mark_ranges, has_final_mark)</span>
{
    <span>/// Fast path: Check if update is needed with a cheap shared lock</span>
    acquire_shared_lock(cache_mutex);  <span>/// Multiple threads can read simultaneously</span>

    need_update = <span>false</span>;
    <span>for</span> (<span>const</span> <span>auto</span> &amp; range : mark_ranges)
    {
        <span>if</span> (any_marks_are_true(range.begin, range.end))
        {
            need_update = <span>true</span>;
            <span>break</span>;
        }
    }

    <span>if</span> (has_final_mark &amp;&amp; final_mark_is_true())
        need_update = <span>true</span>;

    release_shared_lock(cache_mutex);

    <span>if</span> (!need_update)
        <span>return</span>;  <span>/// Early out - no expensive lock needed!</span>

    <span>/// Slow path: Actually need to update, acquire exclusive lock</span>
    acquire_exclusive_lock(cache_mutex);

    <span>/// Double-check: verify update is still needed after acquiring lock</span>
    need_update = <span>false</span>;
    <span>for</span> (<span>const</span> <span>auto</span> &amp; range : mark_ranges)
    {
        <span>if</span> (any_marks_are_true(range.begin, range.end))
        {
            need_update = <span>true</span>;
            <span>break</span>;
        }
    }

    <span>if</span> (has_final_mark &amp;&amp; final_mark_is_true())
        need_update = <span>true</span>;

    <span>if</span> (need_update)
    {
        <span>// Perform the actual updates only if still needed</span>
        <span>for</span> (<span>const</span> <span>auto</span> &amp; range : mark_ranges)
            set_marks_to_false(range.begin, range.end);

        <span>if</span> (has_final_mark)
            set_final_mark_to_false();
    }

    release_lock(cache_mutex);
}
</code></pre>
<p><strong>Performance impact</strong></p>
<p>The optimized code delivered impressive performance improvements:</p>
<ul>
<li>CPU cycles spend for <code>native_queued_spin_lock_slowpath</code> reduced from 76% to 1%</li>
<li>The QPS of ClickBench queries Q10 and Q11 improved by 85% and 89%</li>
<li>The geometric mean of all ClickBench queries improved by 8.1%</li>
</ul>

<p>ClickHouse's query profiler was frequently creating and deleting a global timer_id variable, causing lock contention during query profiling.</p>
<p><strong>Query profiler timer usage</strong></p>
<p>ClickHouse's query profiler uses POSIX timers to sample thread stacks in periodic intervals for performance analysis. The original implementation:</p>
<ul>
<li>created and deleted timer_id frequently during profiling, and</li>
<li>required global synchronization for all operations that read or write the timer.</li>
</ul>
<p>Usage of shared data structures that needed protection with locks caused significant overhead.</p>
<p><strong>Eliminating global state with thread-local storage</strong></p>
<p>Here, we eliminated lock contention by thread-local storage, removing the need for shared state. Now, each thread has its own timer_id. This avoids shared state and the overhead of thread synchronization. To update a timer, it is no longer required to acquire locks.</p>
<p><strong>Technical solution</strong></p>
<pre><code><span>/// Original code</span>
<span><span>class</span> <span>QueryProfiler</span>
{</span>
    <span>static</span> global_mutex timer_management_lock

    <span>void</span> <span>startProfiling</span><span>()</span>
    {
        timer_id = create_new_timer();  <span>/// Expensive system call</span>

        acquire_exclusive_lock(timer_management_lock);  <span>/// Global lock!</span>
        update_shared_timer_state(timer_id);  <span>/// Modify shared state</span>
        release_lock(timer_management_lock);
    }

    <span>void</span> <span>stopProfiling</span><span>()</span>
    {
        acquire_exclusive_lock(timer_management_lock);
        cleanup_shared_timer_state(timer_id);
        release_lock(timer_management_lock);

        delete_timer(timer_id);
    }
}
</code></pre>
<pre><code><span>/// Optimized code</span>
<span><span>class</span> <span>QueryProfiler</span>
{</span>
    <span>static</span> <span>thread_local</span> timer_id per_thread_timer;
    <span>static</span> <span>thread_local</span> boolean timer_initialized;

    <span>void</span> <span>startProfiling</span><span>()</span>
    {
        <span>if</span> (!timer_initialized)
        {
            per_thread_timer = create_new_timer();  <span>/// Once per thread</span>
            timer_initialized = <span>true</span>;
        }

        <span>/// Reuse existing timer - no locks, no system calls!</span>
        enable_timer(per_thread_timer);
    }

    <span>void</span> <span>stopProfiling</span><span>()</span>
    {
        <span>/// Just disable timer - no deletion, no locks!</span>
        disable_timer(per_thread_timer);
    }
}
</code></pre>
<p><strong>Performance impact</strong></p>
<p>The new implementation has the following advantages:</p>
<ul>
<li>It eliminated timer-related lock contention hotspots from profiling traces</li>
<li>It reduced timer create/delete system calls through reuse</li>
<li>It makes profiling on ultra-high core count servers more scalable.</li>
</ul>
<p>Thread-local storage can eliminate lock contention by removing the need for shared state. Global synchronization becomes unnecessary if threads maintain their own state.</p>

<p>Memory optimization on ultra-high core count systems differs a lot from single-threaded memory management. Memory allocators themselves become contention points, memory bandwidth is divided across more cores, and allocation patterns that work fine on small systems can create cascading performance problems at scale. It is crucial to be mindful of how much memory is allocated and how memory is used.</p>
<p>This class of optimizations involves the allocator’s behavior, reducing pressure on memory bandwidth, and sometimes completely rethinking algorithms to eliminate memory-intensive operations altogether.</p>

<p>This optimization is motivated by high page fault rates and excessive resident memory usage which we observed for certain aggregation queries on ultra-high core count systems.</p>
<p><strong>Understanding two-level hash tables in ClickHouse</strong></p>
<p>Aggregation in ClickHouse uses different hash tables, depending on the data type, data distribution and data size. Large aggregation states are maintained in ephemeral hash tables.</p>
<ul>
<li>The <strong>1st level</strong> consists of 256 static buckets, each pointing to a 2nd level hash table.</li>
<li><strong>2nd level</strong> hash tables grow independently of each other.</li>
</ul>
<p><strong>Memory reuse for two-level hash tables</strong></p>
<p>At the end of an aggregation query, all hash tables used by the query are deallocated. In particular, the 256 sub-hash tables are deallocated and their memory is merged into larger free memory blocks.</p>
<p>jemalloc (as ClickHouse’s memory allocator) unfortunately prevented the reuse of merged memory blocks for future smaller allocations. This is because by default, only memory from blocks up to 64x larger than the requested size can be reused. This issue in jemalloc is very subtle but critical on ultra-high core count systems.</p>
<p>Based on <a href="https://github.com/jemalloc/jemalloc/pull/2842">jemalloc issue #2842</a>, we noticed a fundamental problem with jemalloc’s memory reuse for the irregularly-sized allocations typical in two-level hash tables:</p>
<ol>
<li><strong>Extent management issue</strong>: When large allocations are freed, jemalloc fails to efficiently track and reuse these memory extents.</li>
<li><strong>Size class fragmentation</strong>: Memory gets trapped in size classes that don't match future allocation patterns.</li>
<li><strong>Metadata overhead</strong>: Excessive metadata structures prevent efficient memory coalescing.</li>
<li><strong>Page fault amplification</strong>: New allocations trigger page faults instead of reusing existing committed pages.</li>
</ol>
<p>We identified jemalloc's <code>lg_extent_max_active_fit</code> parameter as the root cause - it was too restrictive for ClickHouse's allocation patterns.</p>
<p>We contributed the fix to <a href="https://github.com/jemalloc/jemalloc/pull/2842">jemalloc PR #2842</a>, but jemalloc didn’t have new stable releases for an extended period. Fortunately, we could resolve this issue through jemalloc's configuration parameters at compilation time.</p>
<p>Based on ClickHouse <a href="https://github.com/ClickHouse/ClickHouse/pull/80245">PR #80245</a>, the fix involved tuning jemalloc's configuration parameters:</p>
<pre><code><span>/// Original jemalloc configuration</span>
JEMALLOC_CONFIG_MALLOC_CONF = <span>"oversize_threshold:0,muzzy_decay_ms:0,dirty_decay_ms:5000"</span>
<span>/// lg_extent_max_active_fit defaults to 6, meaning memory can be reused from extents up to 64x larger than the requested allocation size</span>
</code></pre>
<pre><code><span>/// Optimized jemalloc configuration</span>
JEMALLOC_CONFIG_MALLOC_CONF = <span>"oversize_threshold:0,muzzy_decay_ms:0,dirty_decay_ms:5000,lg_extent_max_active_fit:8"</span>
<span>/// lg_extent_max_active_fit is set to 8.</span>
<span>/// This allows memory reuse from extents up to 256x larger</span>
<span>/// than the requested allocation size (2^8 = 256x vs default 2^6 = 64x).</span>
<span>/// The 256x limit matches ClickHouse's two-level hash table structure (256 buckets).</span>
<span>/// This enables efficient reuse of merged hash table memory blocks.</span>
</code></pre>
<p><strong>Performance impact</strong></p>
<p>The optimization improved</p>
<ul>
<li>the performance of ClickBench query Q35 by 96.1%,</li>
<li>memory usage (VmRSS, resident memory) and page faults reduced for the same query went down by 45.4% and 71%, respectively.</li>
</ul>
<p>The behavior of the memory allocator can have a dramatic impact on ultra-high core count systems.</p>

<p>ClickBench query Q29 was memory-bound and bottlenecked in excessive memory accesses caused by redundant computations of the form <code>sum(column + literal)</code>.</p>
<p><strong>Understanding the memory bottleneck</strong></p>
<p>ClickBench query Q29 contains multiple sum expressions with literals:</p>
<pre><code><span>SELECT</span> <span>SUM</span>(ResolutionWidth), <span>SUM</span>(ResolutionWidth <span>+</span> <span>1</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>2</span>), 
       <span>SUM</span>(ResolutionWidth <span>+</span> <span>3</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>4</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>5</span>), 
       <span>SUM</span>(ResolutionWidth <span>+</span> <span>6</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>7</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>8</span>), 
       <span>SUM</span>(ResolutionWidth <span>+</span> <span>9</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>10</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>11</span>), 
       <span>SUM</span>(ResolutionWidth <span>+</span> <span>12</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>13</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>14</span>), 
       <span>SUM</span>(ResolutionWidth <span>+</span> <span>15</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>16</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>17</span>), 
       <span>SUM</span>(ResolutionWidth <span>+</span> <span>18</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>19</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>20</span>),
       <span>-- ... continues up to SUM(ResolutionWidth + 89)</span>
<span>FROM</span> hits;
</code></pre>
<p>The original query execution</p>
<ol>
<li><strong>Loaded column</strong> “ResolutionWidth” from storage once,</li>
<li><strong>Compute expressions</strong> - 90 times, creating 90 temporary columns (one per expression),</li>
<li><strong>Sum values</strong> performing 90 separate aggregation operations on each computed column.</li>
</ol>
<p>Creating 90 temporary columns and running 90 redundant aggregations obviously created massive memory pressure.</p>
<p><strong>Frontend query optimization for memory efficiency</strong></p>
<p>This optimization demonstrates how better optimizer rules can reduce memory pressure by eliminating redundant computations. The key insight is that many analytical queries contain patterns that can be algebraically simplified.</p>
<p>The optimization recognizes that <code>sum(column + literal)</code> can be rewritten to <code>sum(column) + count(column) * literal</code>.</p>
<p><strong>Performance impact</strong></p>
<ul>
<li>ClickBench query Q29 sped up by 11.5x on a 2×80 vCPU system.</li>
<li>The geometric mean of all ClickBench queries saw a 5.3% improvement overall.</li>
</ul>
<p>More intelligent query plans can be more effective than optimizing execution itself. Avoiding work is better than doing work efficiently.</p>

<p>Fast aggregation is a core promise of any analytical database. From a database perspective, aggregating data in parallel threads is only one part of the equation. It is equally important to merge the local results in parallel.</p>
<p>ClickHouse's aggregation operator has two phases: In the first phase, each thread processes its portion of the data in parallel, creating a local and partial result. In the second phase, all partial results must be merged. If the merge phase is not properly parallelized, it becomes a bottleneck. More threads can actually make this issue worse by creating more partial results to merge.</p>
<p>Solving this issue requires careful algorithm design, smart data structure choices, and a deep understanding how hash tables behave under different load patterns. The goal is to eliminate the serial merge phase and enable linear scaling even for the most complex aggregation queries.</p>

<p>ClickBench query Q5 showed a severe performance degradation as the core count increased from 80 to 112 threads. Our pipeline analysis revealed serial processing in the hash table conversion.</p>
<p><strong>Understanding hash tables in ClickHouse</strong></p>
<p>ClickHouse uses two types of hash tables for hash aggregation:</p>
<ol>
<li><strong>Single-level hash tables</strong>: This is a flat hash table that is suitable (= faster) for smaller datasets.</li>
<li><strong>Two-level hash tables</strong>: This is a hierarchical hash table with 256 buckets. Two-level hash tables are more amendable to large datasets.</li>
</ol>
<p>The database chooses the right hash table type based on the size of the processed data: Once a single-level hash table reaches a certain threshold during aggregation, it is automatically converted to a two-level hash table. The code to merge hash tables of different types was serialized.</p>
<p><strong>The serial bottleneck</strong></p>
<p>When merging hash tables from different threads,</p>
<ul>
<li><strong>single-level hash tables</strong> were serially merged in a pair-wise manner, e.g. ht1 / ht2 → result, then result / ht3, etc.</li>
<li><strong>two-level hash tables</strong> are merged one-by-one as well but the merge is parallelized across buckets.</li>
</ul>
<p>In the case of mixed single/two-level hash tables, the single-level hash tables had to be converted to two-level hash tables first (this was a serial process). Once the was done, the resulting two-level hash tables could be merged in parallel.</p>
<p>With Q5, increasing the number of threads from 80 to 112 meant that each thread processes less data. With 80 threads, all hash tables were two-level. With 112 threads, the aggregation ended up with the mixed scenario: some hash tables remained single-level while others became two-level. This caused serialization - all single-level hash tables had to be converted to two-level before parallel merging could take place.</p>
<p>To diagnose the issue, pipeline visualization was a crucial tool. The telltale sign was that the merge phase duration increased with thread count - this is the opposite of what should happen.</p>
<p><img src="https://clickhouse.com/uploads/intel_img_1_1481af3982.png" alt="intel_img_1.png" loading="lazy"></p>
<p><em>Performance degradation with increased core count</em></p>
<p><img src="https://clickhouse.com/uploads/intel_img_2_d019431938.png" alt="intel_img_2.png" loading="lazy"></p>
<p><em>Pipeline visualization (max_threads=80) - the merge phase is reasonable</em></p><p><img src="https://clickhouse.com/uploads/intel_img_3_b28b847281.png" alt="intel_img_3.png" loading="lazy"></p>
<p><em>Pipeline visualization (max_threads=112) - the merge phase takes 3.2x longer</em></p><p>Our optimization parallelizes the conversion phase: instead of converting all single-level hash tables to two-level hash tables one by one (serially), we now convert them in parallel. As each hash table can be converted independently, this eliminates the serial bottleneck.</p>
<pre><code><span>/// Original code</span>
<span>void</span> <span>mergeHashTable</span><span>(left_table, right_table)</span>
{
    <span>if</span> (left_table.is_single_level() &amp;&amp; right_table.is_two_level())    
        left_table.convert_to_two_level();  <span>/// Serial conversion blocks threads</span>

    <span>/// Now merge</span>
    merge_sets(left_table, right_table);
}
</code></pre>
<pre><code><span>/// Optimized code</span>
<span>void</span> <span>mergeHashTableParallel</span><span>(all_tables)</span>
{
    <span>/// Phase 1: Parallel conversion</span>
    parallel_tasks = [];
    <span>for</span> (<span>const</span> <span>auto</span> &amp; table : all_tables)
    {
        <span>if</span> (table.is_single_level())
        {
            <span>/// Parallel conversion!</span>
            task = create_parallel_task(table.convert_to_two_level());
            parallel_tasks.add(task);
        }
    }

    <span>/// Wait for all conversions to complete</span>
    wait_for_all_tasks(parallel_tasks);

    <span>/// Phase 2: Now all sets are two-level, merge efficiently.</span>
    <span>for</span> (<span>const</span> <span>auto</span> &amp; <span>pair</span> : all_tables)
        merge_sets(<span>pair</span>.left_table, <span>pair</span>.right_table);
}
</code></pre>
<p><strong>Performance impact</strong></p>
<p>The performance did not improve only for Q5 - the optimization enabled linear scaling for any aggregation-heavy query on ultra-high core count systems.</p>
<p><img src="https://clickhouse.com/uploads/intel_img_4_c4f403312b.png" alt="intel_img_4.png" loading="lazy"></p>
<p><em>Performance improvement after parallel conversion - Q5 achieves 264% improvement</em></p>
<ul>
<li>ClickBench query Q5 improved by a 264% on a 2×112 vCPU system,</li>
<li>24 queries achieved &gt;5% improvement,</li>
<li>the overall geometric mean improved by 7.4%</li>
</ul>
<p>The optimization demonstrates that scalability isn't just about making things more parallel - it's about eliminating serial sections that grow with parallelism. Sometimes you need to restructure algorithms on a more deep level, not just add more threads.</p>

<p>We noticed that the performance was also subpar when all hash tables were single-level.</p>
<p><strong>Extending parallel merge to single-level cases</strong></p>
<p>Building on <a href="https://github.com/ClickHouse/ClickHouse/pull/50748">PR #50748</a>, this optimization recognizes that the benefits of parallel merging are not limited to mixed hash tables. Even when all hash tables are single-level, parallel merging can improve performance if the total data size is large enough.</p>
<p>The challenge was to determine when single-level hash tables should be merged in parallel parallel:</p>
<ul>
<li>If datasets are too small, parallelization introduces extra overhead.</li>
<li>If datasets are too large, parallelization may not be beneficial enough.</li>
</ul>
<p>Based on the implementation in <a href="https://github.com/ClickHouse/ClickHouse/pull/52973/files">PR #52973</a>, the optimization added parallel merges to all single-level cases:</p>
<pre><code><span>/// Before: Only parallelize mixed-level merges</span>
<span>void</span> <span>parallelizeMergePrepare</span><span>(hash_tables)</span>
{
    single_level_count = <span>0</span>;

    <span>for</span> (<span>const</span> <span>auto</span> &amp; hash_table : hash_tables)
        <span>if</span> hash_table.is_single_level():
            single_level_count++;

    <span>/// Only convert if mixed levels (some single, some two-level)</span>
    <span>if</span> single_level_count &gt; <span>0</span> and single_level_count &lt; hash_tables.size():
        convert_to_two_level_parallel(hash_tables);
}
</code></pre>
<pre><code><span>/// Optimized code</span>
<span>void</span> <span>parallelizeMergePrepare</span><span>(hash_tables)</span>:
{
    single_level_count = <span>0</span>;
    all_single_hash_size = <span>0</span>;

    <span>for</span> (<span>const</span> <span>auto</span> &amp; hash_table : hash_tables)
        <span>if</span> (hash_table.is_single_level())
            single_level_count++

    <span>/// Calculate total size if all hash tables are single-level</span>
    <span>if</span> (single_level_count == hash_tables.size())
        <span>for</span> (<span>const</span> <span>auto</span> &amp; hash_table : hash_tables)
            all_single_hash_size += hash_table.size();

    <span>/// Convert if mixed levels OR if all single-level with average size &gt; THRESHOLD</span>
    <span>if</span> (single_level_count &gt; <span>0</span> and single_level_count &lt; hash_tables.size())
        ||
       (all_single_hash_size / hash_tables.size() &gt; THRESHOLD)
        convert_to_two_level_parallel(hash_tables);
}
</code></pre>
<p><strong>Performance impact</strong></p>
<ul>
<li>Performance for single-level merge scenarios improved by 235%</li>
<li>The optimal threshold was determined through systematic testing</li>
<li>There were no regressions on small datasets</li>
</ul>

<p>GROUP BY operations with large hash tables were merged serially.</p>
<p><strong>Extending parallelization to keyed aggregations</strong></p>
<p>The previous two optimizations (3.1 and 3.2) addressed merges without key - simple hash table operations like <code>COUNT(DISTINCT)</code>. We applied the same optimization to merges with key where hash tables contain both keys and aggregated values that must be combined, e.g. general <code>GROUP BY</code> semantics.</p>
<p><strong>Performance Impact</strong>:</p>
<ul>
<li>ClickBench query Q8 improved by 10.3%, Q9 by 7.6%</li>
<li>There were no regressions in other queries</li>
<li>CPU utilization during the merge phase improved</li>
</ul>
<p>Parallel merging can be extended to complex aggregation scenarios with careful attention to cancellation and error handling.</p>

<p>Harnessing the full potential of SIMD instructions is notoriously difficult. Compilers are conservative about vectorization, and database workloads often have complex control flows that inhibit auto-vectorization.</p>
<p>Effective usage of SIMD instructions in databases requires thinking beyond traditional vectorization. Besides processing N data items simultaneously instead of one, one can also utilize parallel SIMD comparisons for smart pruning strategies which lead to less work done overall. This idea is particularly powerful for string operations. These are at the same time frequently used in practice and computationally expensive.</p>

<p>String search (e.g. plain substring search or LIKE pattern search) is a bottleneck in a lot of queries, for example in ClickBench query Q20.</p>
<p><strong>Understanding string search in analytical queries</strong></p>
<p>Clickbench query 20 evaluates a LIKE pattern on millions of URLs, making fast string search crucial.</p>
<pre><code><span>SELECT</span> <span>COUNT</span>(<span>*</span>) <span>FROM</span> hits <span>WHERE</span> URL <span>LIKE</span> <span>'%google%'</span>
</code></pre>
<p><strong>Reducing false positives with two-character filtering</strong></p>
<p><a href="https://github.com/ClickHouse/ClickHouse/pull/46289/files">PR #46289</a> is based on the insight that SIMD instructions can be used in a smart way beyond brute-force parallelization. The original code already leveraged SIMD instructions but it only considered the search pattern’s first character, leading to expensive false positives. We rewrite the code to check the second character as well. This improved selectivity dramatically while adding only a negligible amount of new SIMD operations.</p>
<pre><code><span>/// Original code</span>
<span><span>class</span> <span>StringSearcher</span>
{</span>
    first_needle_character = needle[<span>0</span>];
    first_needle_character_vec = broadcast_to_simd_vector(first_needle_character);

    <span>void</span> <span>search</span><span>()</span>
    {
        <span>for</span> (position in haystack; step by <span>16</span> bytes)
        {
            haystack_chunk = load_16_bytes(haystack + position);
            first_matches = simd_compare_equal(haystack_chunk, first_needle_character_vec);
            match_mask = extract_match_positions(first_matches);

            <span>for</span> (<span>const</span> <span>auto</span> &amp; match : match_mask)
                <span>/// High false positive rate - many expensive verifications</span>
                <span>if</span> (full_string_match(haystack + match_pos, needle))
                    <span>return</span> match_pos;
        }
    }
}
</code></pre>
<pre><code><span>// Optimized code</span>
<span><span>class</span> <span>StringSearcher</span>
{</span>
    first_needle_character = needle[<span>0</span>];
    second_needle_character = needle[<span>1</span>];  <span>/// Second character</span>
    first_needle_character_vec = broadcast_to_simd_vector(first_needle_character);
    second_needle_character_vec = broadcast_to_simd_vector(second_needle_character);

    <span>void</span> <span>search</span><span>()</span>
    {
        <span>for</span> (position : haystack, step by <span>16</span> bytes)
        {
            haystack_chunk1 = load_16_bytes(haystack + position);
            haystack_chunk2 = load_16_bytes(haystack + position + <span>1</span>);

            <span>/// Compare both characters simultaneously</span>
            first_matches = simd_compare_equal(haystack_chunk1, first_needle_character_vec);
            second_matches = simd_compare_equal(haystack_chunk2, second_needle_character_vec);
            combined_matches = simd_and(first_matches, second_matches);

            match_mask = extract_match_positions(combined_matches);

            <span>for</span> (<span>const</span> <span>auto</span> &amp; match : match_mask)
                <span>// Dramatically fewer false positives - fewer expensive verifications</span>
                <span>if</span> <span>full_string_match</span><span>(haystack + match_pos, needle)</span>:
                    <span>return</span> match_pos;
        }
    }
}
</code></pre>
<p><strong>Performance impact</strong></p>
<p>Two-character SIMD filtering improved performance significantly:</p>
<ul>
<li>ClickBench query Q20 sped up by 35%</li>
<li>Other queries which perform substring matching saw an overall improvement of ~10%</li>
<li>The geometric mean of all queries improved by 4.1%</li>
</ul>
<p>The performance improvements are a result of fewer false positives, better cache locality and more efficient branch prediction.</p>
<p>Two-character SIMD filtering demonstrates that effective SIMD optimization isn't just about processing more data per instruction - it's about using SIMD's parallel comparison capabilities to improve the algorithmic efficiency. The two-character approach shows how a small number of additional SIMD operations can in some cases yield massive performance gains.</p>

<p>False sharing occurs when multiple threads access variables in the same cache. The CPU's cache coherence protocol works at cache line granularity, meaning that any cache line modifications - including modifications of two different variables - are treated as conflicts which require expensive synchronization between cores. On a 2 x 240 vCPUs system, false sharing can turn simple counter increments into system-wide performance disasters.</p>
<p>Eliminating false sharing requires how CPU cache coherence is implemented at the hardware level. It's not enough to optimize algorithms - to avoid false sharing, one must also optimize the memory layout to make sure that frequently-accessed data structures don't accidentally interfere with each other through cache line conflicts. This involves for example a strategic data layout and use of alignment and padding.</p>

<p>ClickBench query Q3 showed 36.6% of CPU cycles spent in <code>ProfileEvents::increment</code> on a 2×240 vCPU system. Performance profiling revealed a severe cache line contention.</p>
<p><strong>ProfileEvents counters at scale</strong></p>
<p>Profile event counters refer to ClickHouse's internal eventing system - profile events track all internal operations, from detailed query execution steps to memory allocations. In a typical analytical query, these counters are incremented millions of times across all threads. The original implementation organized multiple counters in the same memory region without considering cache line boundaries.</p>
<p>This creates three challenges:</p>
<ol>
<li>
<p><strong>Cache line physics</strong>: Modern Intel processors use 64-byte cache lines. When any byte in a cache line is modified, the entire line must be invalidated in the other cores' caches.</p>
</li>
<li>
<p><strong>False sharing amplification</strong>: With 240 threads, each counter update triggers a cache line invalidation across potentially dozens of cores. What should be independent operations become serialized through the cache coherence protocol.</p>
</li>
<li>
<p><strong>Exponential degradation</strong>: As the number of cores increases, the probability of a simultaneous access to the same cache line grows exponentially, compounding the impact of cache misses.</p>
</li>
</ol>
<p>Using perf, I discovered that <code>ProfileEvents::increment</code> was generating massive cache coherence traffic. The smoking gun was the cache line utilization report that showed eight different counters packed into a single cache line. We also added new capabilities to Linux’s perf c2c tool and worked with the community to help developers more easily identify false sharing issues like this.</p>
<p><img src="https://clickhouse.com/uploads/intel_img_5_64dd7ef454.png" alt="intel_img_5.png" loading="lazy"></p>
<p><em>Perf analysis showing 36.6% cycles in ProfileEvents::increment</em></p><p>Proper cache line alignment ensures that each counter gets its own 64-byte cache line. This transforms false sharing (bad) into true sharing (manageable). When a thread updates its counter, now only a single cache line wil be affected.</p>
<p>Based on our implementation in <a href="https://github.com/ClickHouse/ClickHouse/pull/82697/files">PR #82697</a>, the fix improved the cache line alignment for the profile event counters:</p>
<pre><code><span>// Before: Counters packed without alignment</span>
<span><span>struct</span> <span>ProfileEvents</span>:</span>
    <span>atomic_value</span> counters[NUM_EVENTS]  <span>// Multiple counters per cache line</span>
    <span>// 8 counters sharing single 64-byte cache lines</span>

<span>// After: Cache line aligned counters  </span>
<span><span>struct</span> <span>ProfileEvents</span>:</span>
    <span>struct</span> <span>alignas</span><span>(<span>64</span>)</span> AlignedCounter:
        <span>atomic_value</span> value
        <span>// Padding automatically added to reach 64 bytes</span>
    
    AlignedCounter counters[NUM_EVENTS]  <span>// Each counter gets own cache line</span>
    <span>// Now each counter has exclusive cache line ownership</span>
</code></pre>
<p><strong>Performance impact</strong></p>
<p>This optimization pattern applies to any frequently updated shared and compact data structure. The lesson is that the memory layout becomes critical at scale - what works fine on eight cores can be excruciatingly slow on 240 cores.</p>
<p><img src="https://clickhouse.com/uploads/intel_img_6_d32f81bea1.png" alt="intel_img_6.png" loading="lazy"></p>
<p><em>After optimization: ProfileEvents::increment drops to 8.5% (from 36.6%)</em></p><p>As a result of our optimization, ClickBench query Q3 saw a 27.4% improvement on ultra-high core count systems. The performance gain increases with the number of cores because the cache coherence overhead grows super-linearly. This optimization therefore doesn't merely fix a bottleneck - it changes the scalability curve.</p>
<p><img src="https://clickhouse.com/uploads/intel_img_7_651eaa2f76.png" alt="intel_img_7.png" loading="lazy"></p>
<p><em>ClickBench Q3: 27.4% improvement, with larger gains on higher core count systems</em></p>
<p>In this post I covered optimizations for five performance bottlenecks:</p>
<ol>
<li><strong>Lock contention</strong> - The coordination overhead grows exponentially with core count.</li>
<li><strong>Memory optimization</strong> - The memory bandwidth per core decreases as the core count increases.</li>
<li><strong>Increased parallelism</strong> - Serial phases become the dominant bottleneck.</li>
<li><strong>SIMD optimization</strong> - Smarter algorithms like two-character filtering beyond brute-force vectorization can improve performance significantly.</li>
<li><strong>False sharing</strong> - False sharing is caused by the granularity of cache line size.</li>
</ol>
<p>The bottlenecks and optimizations presented here are not just about ClickHouse - they represent a fundamental shift in how we must approach database optimization in the ultra-high core count era. As processors continue to evolve toward higher core counts, these techniques will become essential for any system that needs to scale.</p>
<p>Our optimizations enable ClickHouse to achieve close-to-linear scalability as the core count increases. This enables ClickHouse to thrive as an analytics database in a future world where Intel and other hardware manufacturers push the core count into the thousands.</p>
<p><img src="https://clickhouse.com/uploads/Team2_16ed51dacb.jpg" alt="Team2.jpg" loading="lazy"></p>
<hr>
<h2 id="references-and-resources"><strong>References and Resources</strong> </h2>
<ul>
<li><strong>Source Code</strong>: All optimizations available in ClickHouse main branch</li>
<li><strong>Slide Deck</strong>: <a href="https://github.com/ClickHouse/clickhouse-presentations/blob/master/2025-meetup-Shanghai-1/Talk%204%20-%20Intel%20-%20Shanghai%20Meetup_01Mar25.pdf">2025 Shanghai Meetup Presentation</a></li>
<li><strong>Pull Requests</strong>: Individual PRs linked throughout this post with detailed performance analysis</li>
<li><strong>Intel Intrinsics Guide</strong>: <a href="https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html">Intel® Intrinsics Guide</a></li>
</ul>

<p>Special thanks to the ClickHouse community for rigorous code review and performance validation. These optimizations represent collaborative effort between Intel and ClickHouse teams to unlock the full potential of modern ultra-high core count processors.</p>
<hr>
<p><em>For questions about implementation details or performance reproduction, please refer to the individual PR discussions linked throughout this post.</em></p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[WASM 3.0 Completed (998 pts)]]></title>
            <link>https://webassembly.org/news/2025-09-17-wasm-3.0/</link>
            <guid>45279384</guid>
            <pubDate>Wed, 17 Sep 2025 18:16:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://webassembly.org/news/2025-09-17-wasm-3.0/">https://webassembly.org/news/2025-09-17-wasm-3.0/</a>, See on <a href="https://news.ycombinator.com/item?id=45279384">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <header>
      
    </header>
    

<div>
    

<p><em>Published on September 17, 2025 by <a href="https://github.com/rossberg">Andreas Rossberg</a>.</em></p>

<p>Three years ago, <a href="https://webassembly.org/news/2025-03-20-wasm-2.0/">version 2.0</a> of the Wasm standard was (essentially) finished, which brought a number of new features, such as vector instructions, bulk memory operations, multiple return values, and simple reference types.</p>

<p>In the meantime, the Wasm W3C Community Group and Working Group have not been lazy. Today, we are happy to announce the release of Wasm 3.0 as the new “live” standard.</p>

<p><img src="https://webassembly.org/assets/wasm3_0.png" alt="Title page of the WebAssembly Specification, Release 3.0, 2025-09-17"></p>

<p>This is a substantially larger update: several big features, some of which have been in the making for six or eight years, finally made it over the finishing line.</p>

<ul>
  <li>
    <p><a href="https://github.com/WebAssembly/spec/blob/wasm-3.0/proposals/memory64/Overview.md"><em>64-bit address space.</em></a> Memories and tables can now be declared to use <code>i64</code> as their address type instead of just <code>i32</code>. That expands the available address space of Wasm applications from 4 gigabytes to (theoretically) 16 exabytes, to the extent that physical hardware allows. While the web will necessarily keep enforcing certain limits — on the web, a 64-bit memory is limited to 16 gigabytes — the new flexibility is especially interesting for non-web ecosystems using Wasm, as they can support much, much larger applications and data sets now.</p>
  </li>
  <li>
    <p><a href="https://github.com/WebAssembly/spec/blob/wasm-3.0/proposals/multi-memory/Overview.md"><em>Multiple memories.</em></a> Contrary to popular belief, Wasm applications were always able to use multiple memory objects — and hence multiple address spaces — simultaneously. However, previously that was only possible by declaring and accessing each of them in separate modules. This gap has been closed, a single module can now declare (define or import) multiple memories and directly access them, including directly copying data between them. This finally allows tools like wasm-merge, which perform “static linking” on two or more Wasm modules by merging them into one, to work for <em>all</em> Wasm modules. It also paves the way for new uses of separate address spaces, e.g., for security (separating private data), for buffering, or for instrumentation.</p>
  </li>
  <li>
    <p><a href="https://github.com/WebAssembly/spec/blob/wasm-3.0/proposals/gc/Overview.md"><em>Garbage collection.</em></a> In addition to expanding the capabilities of raw linear memories, Wasm also adds support for a new (and separate) form of storage that is automatically managed by the Wasm runtime via a garbage collector. Staying true to the spirit of Wasm as a low-level language, Wasm GC is low-level as well: a compiler targeting Wasm can declare the memory layout of its runtime data structures in terms of struct and array types, plus unboxed tagged integers, whose allocation and lifetime is then handled by Wasm. But that’s it. Everything else, such as engineering suitable representations for source-language values, including implementation details like method tables, remains the responsibility of compilers targeting Wasm. There are no built-in object systems, nor closures or other higher-level constructs — which would inevitably be heavily biased towards specific languages. Instead, Wasm only provides the basic building blocks for representing such constructs and focuses purely on the memory management aspect.</p>
  </li>
  <li>
    <p><a href="https://github.com/WebAssembly/spec/blob/wasm-3.0/proposals/function-references/Overview.md"><em>Typed references.</em></a> The GC extension is built upon a substantial extension to the Wasm type system, which now supports much richer forms of references. Reference types can now describe the exact shape of the referenced heap value, avoiding additional runtime checks that would otherwise be needed to ensure safety. This more expressive typing mechanism, including subtyping and type recursion, is also available for function references, making it possible to perform safe indirect function calls without any runtime type or bounds check, through the new <code>call_ref</code> instruction.</p>
  </li>
  <li>
    <p><a href="https://github.com/WebAssembly/spec/blob/wasm-3.0/proposals/tail-call/Overview.md"><em>Tail calls.</em></a> Tail calls are a variant of function calls that immediately exit the current function, and thereby avoid taking up additional stack space. Tail calls are an important mechanism that is used in various language implementations both in user-visible ways (e.g., in functional languages) and for internal techniques (e.g., to implement stubs). Wasm tail calls are fully general and work for callees both selected statically (by function index) and dynamically (by reference or table).</p>
  </li>
  <li>
    <p><a href="https://github.com/WebAssembly/spec/blob/wasm-3.0/proposals/exception-handling/Exceptions.md"><em>Exception handling.</em></a> Exceptions provide a way to locally abort execution, and are a common feature in modern programming languages. Previously, there was no efficient way to compile exception handling to Wasm, and existing compilers typically resorted to convoluted ways of implementing them by escaping to the host language, e.g., JavaScript. This was neither portable nor efficient. Wasm 3.0 hence provides native exception handling within Wasm. Exceptions are defined by declaring exception tags with associated payload data. As one would expect, an exception can be thrown, and selectively be caught by a surrounding handler, based on its tag. Exception handlers are a new form of block instruction that includes a dispatch list of tag/label pairs or catch-all labels to define where to jump when an exception occurs.</p>
  </li>
  <li>
    <p><a href="https://github.com/WebAssembly/spec/blob/wasm-3.0/proposals/relaxed-simd/Overview.md"><em>Relaxed vector instructions.</em></a> Wasm 2.0 added a large set of vector (SIMD) instructions, but due to differences in hardware, some of these instructions have to do extra work on some platforms to achieve the specified semantics. In order to squeeze out maximum performance, Wasm 3.0 introduces “relaxed” variants of these instructions that are allowed to have implementation-dependent behavior in certain edge cases. This behavior must be selected from a pre-specified set of legal choices.</p>
  </li>
  <li>
    <p><a href="https://github.com/WebAssembly/profiles/blob/main/proposals/profiles/Overview.md"><em>Deterministic profile.</em></a> To make up for the added semantic fuzziness of relaxed vector instructions, and in order to support settings that demand or need deterministic execution semantics (such as blockchains, or replayable systems), the Wasm standard now specifies a deterministic default behavior for every instruction with otherwise non-deterministic results — currently, this includes floating-point operators and their generated NaN values and the aforementioned relaxed vector instructions. Between platforms choosing to implement this deterministic execution profile, Wasm thereby is fully deterministic, reproducible, and portable.</p>
  </li>
  <li>
    <p><a href="https://github.com/WebAssembly/spec/blob/wasm-3.0/proposals/annotations/Overview.md"><em>Custom annotation syntax.</em></a> Finally, the Wasm text format has been enriched with generic syntax for placing annotations in Wasm source code. Analogous to custom sections in the binary format, these annotations are not assigned any meaning by the Wasm standard itself, and can be chosen to be ignored by implementations. However, they provide a way to represent the information stored in custom sections in human-readable and writable form, and concrete annotations can be specified by downstream standards.</p>
  </li>
</ul>

<p>In addition to these core features, embeddings of Wasm into JavaScript benefit from a new extension to the JS API:</p>

<ul>
  <li><a href="https://github.com/WebAssembly/js-string-builtins/blob/main/proposals/js-string-builtins/Overview.md"><em>JS string builtins.</em></a> JavaScript string values can already be passed to Wasm as externrefs. Functions from this new primitive library can be imported into a Wasm module to directly access and manipulate such external string values inside Wasm.</li>
</ul>

<p>With these new features, Wasm has much better support for compiling high-level programming languages. Enabled by this, we have seen various new languages popping up to target Wasm, such as <a href="https://github.com/google/j2cl/blob/master/docs/getting-started-j2wasm.md">Java</a>, <a href="https://dune.readthedocs.io/en/stable/wasmoo.html">OCaml</a>, <a href="https://www.scala-js.org/doc/project/webassembly.html">Scala</a>, <a href="https://kotlinlang.org/docs/wasm-overview.html">Kotlin</a>, <a href="https://spritely.institute/hoot/">Scheme</a>, or <a href="https://dart.dev/web/wasm">Dart</a>, all of which use the new GC feature.</p>

<p>On top of all these goodies, Wasm 3.0 also is the first version of the standard that has been produced with the new <a href="https://webassembly.org/news/2025-03-27-spectec/">SpecTec</a> tool chain. We believe that this makes for an even more reliable specification.</p>

<p>Wasm 3.0 is already shipping in most major web browsers, and support in stand-alone engines like Wasmtime is on track to completion as well. The <a href="https://webassembly.org/features/">Wasm feature status</a> page tracks support across engines.</p>

  </div>
  
  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[DeepMind and OpenAI win gold at ICPC (233 pts)]]></title>
            <link>https://codeforces.com/blog/entry/146536</link>
            <guid>45279357</guid>
            <pubDate>Wed, 17 Sep 2025 18:15:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://codeforces.com/blog/entry/146536">https://codeforces.com/blog/entry/146536</a>, See on <a href="https://news.ycombinator.com/item?id=45279357">Hacker News</a></p>
Couldn't get https://codeforces.com/blog/entry/146536: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Anthropic irks White House with limits on models’ use (234 pts)]]></title>
            <link>https://www.semafor.com/article/09/17/2025/anthropic-irks-white-house-with-limits-on-models-uswhite-house-with-limits-on-models-use</link>
            <guid>45279143</guid>
            <pubDate>Wed, 17 Sep 2025 17:57:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.semafor.com/article/09/17/2025/anthropic-irks-white-house-with-limits-on-models-uswhite-house-with-limits-on-models-use">https://www.semafor.com/article/09/17/2025/anthropic-irks-white-house-with-limits-on-models-uswhite-house-with-limits-on-models-use</a>, See on <a href="https://news.ycombinator.com/item?id=45279143">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Anthropic is in the midst of a splashy media tour in Washington, but its refusal to allow its models to be used for some law enforcement purposes has deepened hostility to the company inside the Trump administration, two senior officials told Semafor.</p><p>Anthropic recently declined requests by contractors working with federal law enforcement agencies because the company refuses to make an exception allowing its AI tools to be used for some tasks, including surveillance of US citizens, said the officials, who spoke to Semafor on the condition of anonymity.</p><p>The tensions come at a moment when Donald Trump’s White House has championed American AI companies as patriotic bulwarks of global competition —&nbsp;and expect the companies to repay that loyalty. The officials said they worried that Anthropic was selectively enforcing its policies based on politics and using vague terminology to allow its rules to be interpreted broadly.</p><p>For instance, Anthropic currently limits how the FBI, Secret Service and Immigration, and Customs Enforcement can use its AI models because those agencies conduct surveillance, which is prohibited by Anthropic’s <a href="https://www.anthropic.com/legal/aup" rel="noopener" target="_blank">usage policy</a>.</p><p>One of the officials said Anthropic’s position, which has long been in effect, amounts to making a moral judgment about how law enforcement agencies do their jobs.</p><p>The policy doesn’t specifically define what it means by “domestic surveillance” in a law enforcement context and appears to be using the term broadly, creating room for interpretation.</p><p>Other AI model providers also list restrictions on surveillance, but offer more specific examples and often have carveouts for law enforcement activities. OpenAI’s <a href="https://openai.com/policies/usage-policies/" rel="noopener" target="_blank">policy</a>, for instance, prohibits “unauthorized monitoring of individuals,” implying consent for legal monitoring by law enforcement.</p><p>Anthropic declined to comment.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DeepSeek writes less secure code for groups China disfavors (249 pts)]]></title>
            <link>https://www.washingtonpost.com/technology/2025/09/16/deepseek-ai-security/</link>
            <guid>45278740</guid>
            <pubDate>Wed, 17 Sep 2025 17:24:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washingtonpost.com/technology/2025/09/16/deepseek-ai-security/">https://www.washingtonpost.com/technology/2025/09/16/deepseek-ai-security/</a>, See on <a href="https://news.ycombinator.com/item?id=45278740">Hacker News</a></p>
Couldn't get https://www.washingtonpost.com/technology/2025/09/16/deepseek-ai-security/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Depression Reduces Capacity to Learn to Actively Avoid Aversive Events (196 pts)]]></title>
            <link>https://www.eneuro.org/content/12/9/ENEURO.0034-25.2025</link>
            <guid>45278686</guid>
            <pubDate>Wed, 17 Sep 2025 17:20:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eneuro.org/content/12/9/ENEURO.0034-25.2025">https://www.eneuro.org/content/12/9/ENEURO.0034-25.2025</a>, See on <a href="https://news.ycombinator.com/item?id=45278686">Hacker News</a></p>
<div id="readability-page-1" class="page"><div class="page" id="page">
	  <div data-node-nid="3811664" id="top-node-3811664--21755481293" data-pisa="eneuro;12/9/ENEURO.0034-25.2025" data-pisa-master="eneuro;ENEURO.0034-25.2025" data-apath="/eneuro/12/9/ENEURO.0034-25.2025.atom" data-hw-author-tooltip-instance="highwire_author_tooltip">
  
  
      <p><span>Research Article</span><span></span><span><span>Research Article: New Research, Cognition and Behavior</span></span></p>
  
  
        
    	<p><span>, <span data-delta="1">Brandon J. Forys</span>, <span data-delta="2">Liz Kalenteridis</span>, <span data-delta="3">Ian D. Daly</span>, <span data-delta="4">Alex R. Terpstra</span>, <span data-delta="5">Luke Clark</span>, <span data-delta="6">Stan B. Floresco</span>, <span data-delta="7">Trisha Chakrabarty</span> and <span data-delta="8">Rebecca M. Todd</span></span></p>
  
    	<p><span>eNeuro </span><span>1 September 2025,  </span><span>12 </span><span>(9) </span><span>ENEURO.0034-25.2025; </span><span>https://doi.org/10.1523/ENEURO.0034-25.2025 </span></p>
  
  
  
</div> <!-- /.panel-row-wrapper -->	
	  
  <div xmlns="http://www.w3.org/1999/xhtml" data-highwire-cite-ref-tooltip-instance="highwire_reflinks_tooltip" xmlns:xhtml="http://www.w3.org/1999/xhtml" data-panels-ajax-tab-preloaded="jnl_sfneneuro_tab_art" id="panels-ajax-tab-container-highwire_article_tabs"><div id="abstract-1"><h2>Abstract</h2><p id="p-5">Depression and anxiety are often characterized by altered reward-seeking and avoidance, respectively. Yet less is known about the relationship between depressive symptoms and specific avoidance behaviors. To address this gap, we conducted two studies. In Study 1, undergraduates and online workers completed an uninstructed go/no-go avoidance task (<em>N</em><sub>Total</sub> = 465) as a reverse translation of a rodent paradigm. Participants exhibited a wide range of symptom scores on the Beck Depression Inventory-II (BDI-II), ranging from low to severe. In Study 1, cues were used to signal the response type (go/active vs no-go/inhibitory) required to avoid an aversive sound. Higher depressive scores were associated with poorer acquisition of active avoidance in undergraduates. Overall participants showed lower accuracy for active than inhibitory avoidance. To examine whether the better no-go trial performance reflected a prepotent response to avoid aversive outcomes, in Study 2, undergraduates (<em>N</em><sub>Total</sub> = 330) completed a version of the task that included reward-seeking. Here all participants showed higher accuracy for active reward-seeking and inhibitory avoidance, consistent with a prepotent response to inhibit action to avoid aversive consequences. These findings suggest that in young adults, depressive symptoms are associated with difficulty in overriding prepotent responses to actively avoid aversive outcomes in the absence of reward. This work bridges the gap between preclinical animal models and clinical research, offering insights that could guide the development of more targeted clinical interventions.</p></div><ul><li><a href="https://www.eneuro.org/keyword/avoidance" rel="nofollow">avoidance</a></li><li><a href="https://www.eneuro.org/keyword/beck-depression-inventory" rel="nofollow">Beck Depression Inventory</a></li><li><a href="https://www.eneuro.org/keyword/depression" rel="nofollow">depression</a></li><li><a href="https://www.eneuro.org/keyword/dimensional-approaches" rel="nofollow">dimensional approaches</a></li><li><a href="https://www.eneuro.org/keyword/effort-cost" rel="nofollow">effort cost</a></li><li><a href="https://www.eneuro.org/keyword/translational-research" rel="nofollow">translational research</a></li></ul><div id="sec-1"><h2>Significance Statement</h2><p id="p-6">Translational studies in community samples are crucial for bridging the gap between rodent models, which delineate neural circuitry and pharmacology underlying specific behaviors, and the presentation of mood disorders in clinic settings. Building on rodent studies of avoidance behaviors, thought to be linked to depression, this study examines how depressive symptom scores relate to specific types of avoidance. Our findings revealed that higher depressive symptom scores were associated with reduced capacity to learn active avoidance behaviors, which involved overriding a prepotent response to inhibit action to avoid aversive consequences. This work bridges the gap between preclinical animal models and clinical research, offering insights that may guide the development of more targeted clinical interventions.</p></div><div id="sec-2"><h2>Introduction</h2><p id="p-7">Stimuli that predict aversive events typically evoke avoidance responses aimed at minimizing anticipated threats. Depending on the situation, an active strategy, such as taking an action (walking away), may be most effective, while in other situations, the inhibition of motor output (staying put to avoid detection) may be the more prudent strategy. Although effective in many contexts, these strategies can become maladaptive in depression and anxiety, interfering with goal-directed behavior (<a id="xref-ref-52-1" href="#ref-52">Ottenbreit et al., 2014</a>; <a id="xref-ref-34-1" href="#ref-34">Haskell et al., 2020</a>).</p><p id="p-8">Depression is a leading cause of global disability (<a id="xref-ref-74-1" href="#ref-74">Whiteford et al., 2013</a>; <a id="xref-ref-75-1" href="#ref-75">World Health Organization, 2017</a>), yet its cognitive and behavioral mechanisms remains to be fully understood. The Altered Computations underlying Decision Making (ACDM) framework posits that decision-making biases perpetuate both depression and anxiety (<a id="xref-ref-9-1" href="#ref-9">Bishop and Gagne, 2018</a>). Depression is marked by reduced engagement in reward-seeking, while anxiety by heightened avoidance. In depression, impairments arise from underestimating the probability and value of positive outcomes, and overestimating the effort required to obtain them (<a id="xref-ref-9-2" href="#ref-9">Bishop and Gagne, 2018</a>), ultimately leading to reduced engagement in actions. Supporting this view, individuals with major depressive disorder (MDD) choose high-effort, high-reward options less frequently, anticipate fewer positive experiences, and rate them as less pleasurable (<a id="xref-ref-45-1" href="#ref-45">MacLeod and Salaminiou, 2001</a>; <a id="xref-ref-69-1" href="#ref-69">Treadway et al., 2012</a>; <a id="xref-ref-49-1" href="#ref-49">Mukherjee et al., 2020</a>; <a id="xref-ref-37-1" href="#ref-37">Horne et al., 2021</a>). Although the ACDM primarily distinguishes between depression-related biases in reward-seeking, it also suggests that effort-related impairments may extend to avoidance contexts and contribute to reduced active avoidance.</p><p id="p-9">Despite this, the role of active versus inhibitory forms of avoidance remains underexplored in depression, reflecting broader trends in which negatively valenced systems are predominantly studied in anxiety (<a id="xref-ref-17-1" href="#ref-17">Craske et al., 2009</a>). Cognitive theories of depression emphasize a negativity bias in attention, memory, and future expectations (<a id="xref-ref-47-1" href="#ref-47">Mogg et al., 2006</a>; <a id="xref-ref-26-1" href="#ref-26">Fales et al., 2008</a>; <a id="xref-ref-21-1" href="#ref-21">Disner et al., 2011</a>) but often rely on self-report and lack emphasis on behaviors with translational utility for identifying cross-species neurobiological mechanisms.</p><p id="p-10">Reinforcement learning tasks offer a translational approach for examining negatively valenced systems and have been applied across neuropsychiatric conditions (<a id="xref-ref-24-1" href="#ref-24">Endrass et al., 2011</a>; <a id="xref-ref-54-1" href="#ref-54">Palminteri et al., 2012</a>; <a id="xref-ref-59-1" href="#ref-59">Reinen et al., 2016</a>; <a id="xref-ref-72-1" href="#ref-72">Waltz et al., 2018</a>), including depression (<a id="xref-ref-16-1" href="#ref-16">Chase et al., 2010</a>; <a id="xref-ref-60-1" href="#ref-60">Robinson et al., 2012</a>; <a id="xref-ref-46-1" href="#ref-46">Mkrtchian et al., 2017</a>; <a id="xref-ref-49-2" href="#ref-49">Mukherjee et al., 2020</a>; <a id="xref-ref-64-1" href="#ref-64">Smith et al., 2023</a>). These studies typically involve probabilistic and reversal learning tasks to probe sensitivity to reward and punishment. Findings remain mixed: some report reward-specific impairments in depression (<a id="xref-ref-60-2" href="#ref-60">Robinson et al., 2012</a>), others find broader impairments across valence (<a id="xref-ref-16-2" href="#ref-16">Chase et al., 2010</a>; <a id="xref-ref-46-2" href="#ref-46">Mkrtchian et al., 2017</a>; <a id="xref-ref-49-3" href="#ref-49">Mukherjee et al., 2020</a>) or even heightened punishment sensitivity (<a id="xref-ref-50-1" href="#ref-50">Murphy et al., 2003</a>; <a id="xref-ref-51-1" href="#ref-51">Nord et al., 2018</a>), while others identify learning-specific impairments (<a id="xref-ref-16-3" href="#ref-16">Chase et al., 2010</a>; <a id="xref-ref-49-4" href="#ref-49">Mukherjee et al., 2020</a>). These inconsistencies highlight the need for behavioral assays that isolate avoidance processes and align with cross-species models.</p><p id="p-11">Translational gaps can stem from task design. Human studies typically use secondary reinforcers (i.e., monetary rewards or feedback), with punishment operationalized as monetary loss, and avoidance inferred from decreased selection of high-loss options, often omitting safety signals. In contrast, animal paradigms use primary reinforcers (i.e., shock) and deterministic contingencies and explicitly distinguish between active and inhibitory avoidance (<a id="xref-ref-57-1" href="#ref-57">Piantadosi et al., 2018</a>; <a id="xref-ref-14-1" href="#ref-14">Capuzzo and Floresco, 2020</a>). Although functional magnetic resonance imaging (fMRI) studies show overlapping blood-oxygenation-level-dependent (BOLD) responses to primary and secondary aversive cues, regions like the amygdala are more responsive to primary aversive cues (<a id="xref-ref-20-1" href="#ref-20">Delgado et al., 2011</a>). Importantly, shared BOLD activation does not necessarily imply equivalent neural mechanisms—especially when task features might differ meaningfully. Translating animal behavioral paradigms to humans has been proposed as a promising strategy to enhance cross-species translation and improve psychiatric treatment development (<a id="xref-ref-39-1" href="#ref-39">Kirlic et al., 2017</a>).</p><p id="p-12">To address these gaps, we adapted a validated rodent task designed to assess both active and inhibitory avoidance (<a id="xref-ref-57-2" href="#ref-57">Piantadosi et al., 2018</a>; <a id="xref-ref-14-2" href="#ref-14">Capuzzo and Floresco, 2020</a>) and deployed it in a large online sample. While prior human studies have included related features, our avoidance task was modeled to parallel the original rodent paradigm. Our aim was to examine how depressive symptom severity relates to the ability to learn and flexibly implement active and inhibitory avoidance strategies. Using a dimensional approach aligned with Research Domain Criteria (RDoC) principles, we recruited a nonclinical sample reporting a broad range of depressive symptoms. We hypothesized that higher depressive symptom scores would be associated with impairments in active—but not inhibitory—avoidance, consistent with ACDM predictions of reduced behavioral engagement stemming from effort overestimation.</p></div><div id="sec-3"><h2>Materials and Methods</h2><div id="sec-4"><h3>Study 1 (avoidance)</h3><div id="sec-5"><h4>Participants</h4><p id="p-13">We conducted a power analysis using G*Power to detect a small effect size <span id="inline-formula-1"><span><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mspace width=".1em"></mml:mspace><mml:msup><mml:mi>f</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>0.02</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:math></span>
</span>, indicating that a sample size of <em>N</em> = 395 was required to achieve 80% power at <em>α</em> = 0.05. To account for the higher attrition rates typically observed in online studies, we recruited additional participants. Undergraduates (<em>N</em><sub>Undergraduates </sub>= 475) and online workers (<em>N</em><sub>OnlineWorkers </sub>= 292; recruited via Prolific; <a href="http://www.prolific.co/">www.prolific.co</a>) consented to perform an active/inhibitory avoidance task (<em>N</em><sub>Total </sub>= 767). Undergraduates from the University of British Columbia Psychology Human Subjects Pool were compensated a 1% point increase in their course grade; Prolific workers were compensated £10.59/h. The online avoidance task was unsupervised and uninstructed to allow for instrumental learning processes. Participants were excluded for several reasons, including failure to complete the pre-task survey, failure of survey attention checks, failure to reach criterion accuracy during acquisition, obtaining a <em>d</em>’ &lt; 0.50 during the intermixed task stage, or failure to complete the task. After cleaning, <em>N</em><sub>Total </sub>= 465 (<em>N</em><sub>Undergraduates </sub>= 278; <em>N</em><sub>OnlineWorkers </sub>= 187) were included in the analyses. For details on participant exclusion rates, see Discussion and Extended Data (Extended Data <a id="xref-supplementary-material-1-1" href="#DC1">Table 1-1</a>). The study was approved by the University of British Columbia Behavioral Research Ethics Board (BREB) under certificate H20-01388. Demographic information can be found in <a id="xref-table-wrap-1-1" href="#T1">Table 1</a>.</p></div><div id="sec-6"><h4>Materials</h4><div id="sec-7"><h5>Stimuli</h5><p id="p-14">The task was created in PsychoPy 2020.1 (RRID: SCR_006571) and distributed via Pavlovia (<a href="http://www.pavlovia.org/">www.pavlovia.org</a>; <a id="xref-ref-55-1" href="#ref-55">Peirce et al., 2019</a>). Simple shapes signaled the type of response (active vs inhibitory) required to avoid an aversive sound. Coauthor I.D.D. recorded a set of screeching and scraping sounds (i.e., knife on glass, fork on plate, metal on slate), from which 45 were pilot-tested for unpleasantness and salience (<em>N</em> = 45). Using 9-point Likert scales, eight sounds with the highest combined ratings (unpleasantness: <em>M</em> = 6.87–7.57; salience: <em>M</em> = 5.82–6.83) and lowest variance were selected. These eight aversive sounds were randomly presented on failed trials and were found to be highly motivating. In Study 1, 92.46% of participants who responded to a debriefing question (<em>N</em> = 464) endorsed the aversive sounds as motivating to avoid. Rapid acquisition of instrumental avoidance responses further supports the functional aversiveness of the stimuli. On successful trials, a white border around the gray background signaled safety.</p></div><div id="sec-8"><h5>Measures</h5><p id="p-15">Depressive and anxiety symptom scores were derived from the clinically validated Beck Depression Inventory-II (BDI-II; <a id="xref-ref-6-1" href="#ref-6">Beck et al., 1988b</a>; <a id="xref-ref-7-1" href="#ref-7">Beck et al., 1996</a>) and the Beck Anxiety Inventory (BAI; <a id="xref-ref-5-1" href="#ref-5">Beck et al., 1988a</a>), respectively. One question (suicidality ideation) was removed from the BDI-II for ethical considerations. BDI-II symptom scores were calculated as a proportion score (BDI-II<sub>score</sub>/BDI-II<sub>max_possible_score</sub>) for each participant. Similarly, BAI scores are reported as proportion scores (BAI<sub>score</sub>/BAI<sub>max_possible_score</sub>) for consistency and comparability.</p></div></div><div id="sec-9"><h4>Procedure</h4><p id="p-16">Participants were tested on a computer-based avoidance task that was reverse-translated from a rodent operant paradigm assessing active/inhibitory avoidance—with some modifications (<a id="xref-ref-57-3" href="#ref-57">Piantadosi et al., 2018</a>; <a id="xref-ref-14-3" href="#ref-14">Capuzzo and Floresco, 2020</a>). Prior to the avoidance task, participants completed an effort calibration and a volume calibration to control for differences in physical ability and computer systems (see <a href="https://osf.io/5sepm/">https://osf.io/5sepm/</a>).</p><div id="sec-10"><h5>Active/inhibitory avoidance task</h5><p id="p-17">Specific shapes (circle or squares; counterbalanced) signaled active (“Go”) versus inhibitory (“No-Go”) responses required to avoid a highly aversive sound. The avoidance task consisted of three task stages: acquisition, intermixed, and reversal (<a id="xref-fig-1-1" href="#F1">Fig. 1<em>A</em></a>). (1) The acquisition stage required learning an active avoidance response. During the acquisition stage, participants had to reach a criterion performance of 80% successful trials within the previous 20 trials (maximum 120 trials). Once acquisition criterion was reached, participants performed an additional 30 “over-learning” active avoidance trials before an unsignaled transition into the next task stage. Participants failing to reach criterion performance during the acquisition stage were excluded from data analysis. (2) The intermixed stage required participants to learn the inhibitory avoidance response while flexibly deploying both active and inhibitory responses. This stage consisted of 120 avoidance trials (60 active, 60 inhibitory), presented in a pseudorandomized order. (3) The reversal stage also consisted of 120 avoidance trials (60 active, 60 inhibitory; pseudorandomized), but with active and inhibitory response contingencies reversed. The multiple task stages allowed us to assess distinct patterns in the acquisition and expression of active/inhibitory avoidance, as well as reversal learning. Importantly, participants were not instructed about the cue–response contingencies to allow the acquisition through reinforcement, to mirror the rodent paradigm the task was translated from.</p><div id="F1"><div><div><p><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F1.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Study 1: Active/inhibitory avoidance task. A, Schematic of task stages: acquisition, intermixed, and reversal. Green lines represent active avoidance (“Go”) trials, while red lines represent inhibitory avoidance (“No-Go”) trials. The black arrow indicates time progression. During acquisition, participants were required to reach a criterion of 80% correct active avoidance trials over a 20-trial period (i.e., initial acquisition) or complete a maximum of 120 trials. Upon reaching criterion, participants completed 30 over-learning trials, followed by an unsignaled transition into the intermixed stage. In this stage, participants flexibly alternated between active and inhibitory avoidance responses. The reversal stage followed another unsignaled transition, during which the cues signaling active and inhibitory avoidance responses are reversed. B, Successful active avoidance: A blue circle signals an active avoidance trial. The participant makes sufficient keyboard presses (green circles) within 1,200 ms cue period, avoiding an aversive sound, as indicated by the safety signal (white border). C, Failed active avoidance: A blue circle signals an active avoidance trial, but insufficient or no keyboard presses (red circle) were made within the 1,200 ms, resulting in an aversive sound (yellow speaker). D, Successful inhibitory avoidance: A blue square signals an inhibitory avoidance trial. The participant withholds keyboard presses for the full 1,200 ms, avoiding an aversive sound, indicated by the safety signal. E, Failed inhibitory avoidance: A blue square signals an inhibitory avoidance trial, but the participant fails to withhold keyboard presses within the 1,200 ms, resulting in an aversive sound." rel="gallery-fragment-images-593667592" data-figure-caption="<div class=&quot;highwire-markup&quot;><div xmlns=&quot;http://www.w3.org/1999/xhtml&quot;>Study 1: Active/inhibitory avoidance task. <strong><em>A</em></strong>, Schematic of task stages: acquisition, intermixed, and reversal. Green lines represent active avoidance (“Go”) trials, while red lines represent inhibitory avoidance (“No-Go”) trials. The black arrow indicates time progression. During acquisition, participants were required to reach a criterion of 80% correct active avoidance trials over a 20-trial period (i.e., initial acquisition) or complete a maximum of 120 trials. Upon reaching criterion, participants completed 30 over-learning trials, followed by an unsignaled transition into the intermixed stage. In this stage, participants flexibly alternated between active and inhibitory avoidance responses. The reversal stage followed another unsignaled transition, during which the cues signaling active and inhibitory avoidance responses are reversed. <strong><em>B</em></strong>, Successful active avoidance: A blue circle signals an active avoidance trial. The participant makes sufficient keyboard presses (green circles) within 1,200 ms cue period, avoiding an aversive sound, as indicated by the safety signal (white border). <strong><em>C</em></strong>, Failed active avoidance: A blue circle signals an active avoidance trial, but insufficient or no keyboard presses (red circle) were made within the 1,200 ms, resulting in an aversive sound (yellow speaker). <strong><em>D</em></strong>, Successful inhibitory avoidance: A blue square signals an inhibitory avoidance trial. The participant withholds keyboard presses for the full 1,200 ms, avoiding an aversive sound, indicated by the safety signal. <strong><em>E</em></strong>, Failed inhibitory avoidance: A blue square signals an inhibitory avoidance trial, but the participant fails to withhold keyboard presses within the 1,200 ms, resulting in an aversive sound.</div></div>" data-icon-position="" data-hide-link-title="0"><span><img alt="Figure 1." src="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F1.medium.gif" width="440" height="230" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a></p></div><ul><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F1.large.jpg?download=true" title="Download Figure 1." data-icon-position="" data-hide-link-title="0">Download figure</a></li><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F1.large.jpg" target="_blank" data-icon-position="" data-hide-link-title="0">Open in new tab</a></li><li><a href="https://www.eneuro.org/highwire/powerpoint/3811685" data-icon-position="" data-hide-link-title="0">Download powerpoint</a></li></ul></div><div xmlns:xhtml="http://www.w3.org/1999/xhtml"><p><span>Figure 1.</span></p><p id="p-18">Study 1: Active/inhibitory avoidance task. <strong><em>A</em></strong>, Schematic of task stages: acquisition, intermixed, and reversal. Green lines represent active avoidance (“Go”) trials, while red lines represent inhibitory avoidance (“No-Go”) trials. The black arrow indicates time progression. During acquisition, participants were required to reach a criterion of 80% correct active avoidance trials over a 20-trial period (i.e., initial acquisition) or complete a maximum of 120 trials. Upon reaching criterion, participants completed 30 over-learning trials, followed by an unsignaled transition into the intermixed stage. In this stage, participants flexibly alternated between active and inhibitory avoidance responses. The reversal stage followed another unsignaled transition, during which the cues signaling active and inhibitory avoidance responses are reversed. <strong><em>B</em></strong>, Successful active avoidance: A blue circle signals an active avoidance trial. The participant makes sufficient keyboard presses (green circles) within 1,200 ms cue period, avoiding an aversive sound, as indicated by the safety signal (white border). <strong><em>C</em></strong>, Failed active avoidance: A blue circle signals an active avoidance trial, but insufficient or no keyboard presses (red circle) were made within the 1,200 ms, resulting in an aversive sound (yellow speaker). <strong><em>D</em></strong>, Successful inhibitory avoidance: A blue square signals an inhibitory avoidance trial. The participant withholds keyboard presses for the full 1,200 ms, avoiding an aversive sound, indicated by the safety signal. <strong><em>E</em></strong>, Failed inhibitory avoidance: A blue square signals an inhibitory avoidance trial, but the participant fails to withhold keyboard presses within the 1,200 ms, resulting in an aversive sound.</p></div></div><p id="p-19">Trials began with a fixation cross onscreen (ISI; 2,000 ms; jittered 1,200 ms). Active avoidance required an effortful response—specifically, 3, 4, or 5 rapid button presses (criterion determined during effort calibration test). On successful active trials (<a id="xref-fig-1-2" href="#F1">Fig. 1<em>B</em></a>), participants made the required response within the cue period (≤1,200 ms), resulting in the avoidance of the aversive sound and the presentation of a safety signal (1,000 ms). On failed active trials (<a id="xref-fig-1-3" href="#F1">Fig. 1<em>C</em></a>), either an insufficient response or no response within the cue period triggered the aversive sound (1,000 ms). On inhibitory trials, participants were required to withhold responding. On successful inhibitory trials (<a id="xref-fig-1-4" href="#F1">Fig. 1<em>D</em></a>), participants made no button presses during the cue period (1,200 ms), resulting in the avoidance of the aversive sound and the presentation of a safety signal (1,000 ms). On failed inhibitory trials (<a id="xref-fig-1-5" href="#F1">Fig. 1<em>E</em></a>), an erroneous button press triggered the aversive sound. A graphical overview of the avoidance task is provided in <a id="xref-fig-1-6" href="#F1">Figure 1</a>.</p></div></div><div id="sec-11"><h4>Statistical analysis</h4><p id="p-20">All analyses were conducted in R 4.2.1 (<a id="xref-ref-58-1" href="#ref-58">R Core Team, 2013</a>) using RStudio (<a id="xref-ref-11-1" href="#ref-11">Booth et al., 2018</a>). Primary outcome measures included proportion correct for active and inhibitory trials across task stages and the number of trials to criterion during acquisition. Within-subjects ANOVAs were used except where otherwise stated. Significant main effects or interactions were followed by pairwise comparisons using the <em>emmeans</em> package (<a id="xref-ref-62-1" href="#ref-62">Searle et al., 1980</a>; <a id="xref-ref-44-1" href="#ref-44">Lenth, 2017</a>), with Tukey's honest significant difference (HSD) correction. Between-subject ANOVAs tested sex and sample effects on BDI-II scores. To examine individual differences, we used regression and linear mixed models (lmerTest; fit by REML, <em>t</em> tests using Satterthwaite's method; <a id="xref-ref-4-1" href="#ref-4">Bates et al., 2015</a>; <a id="xref-ref-41-1" href="#ref-41">Kuznetsova et al., 2017</a>) to assess BDI-II scores effects on task performance. To account for multiple comparisons, the Benjamini–Hochberg false discovery rate (FDR) correction was applied (<a id="xref-ref-8-1" href="#ref-8">Benjamini and Hochberg, 1995</a>). We present only the BDI-II analyses in the main text, while corresponding analyses for BAI scores are presented in Extended Data (Extended Data <a id="xref-supplementary-material-2-1" href="#DC2">Figs. 2-1</a>, <a id="xref-supplementary-material-4-1" href="#DC4">4-1</a>; Extended Data <a id="xref-supplementary-material-5-1" href="#DC5">Tables 3-1</a>, 3-3).</p></div></div><div id="sec-12"><h3>Study 2 (reward-seeking/avoidance)</h3><div id="sec-13"><h4>Participants</h4><p id="p-21">Undergraduate participants (<em>N</em> = 771) from the University of British Columbia Psychology Human Subjects Pool were recruited to perform a reward-seeking/avoidance task. Power analysis procedures were identical to Study 1. Recruitment focused exclusively on undergraduates, as effects in Study 1 were strongest in this population. Compensation was identical to the undergraduate sample in Study 1. To motivate performance during reward-seeking trials, participants were told their accumulated points would contribute to the value of a gift card, although participants ultimately received a $5 gift card regardless of performance. Exclusion criteria were similar to Study 1, with the added requirement that participants reach criterion accuracy during acquisition for both reward-seeking and avoidance trials independently. Because the task was designed as a reinforcement-based learning paradigm—with minimal instructions, no explicit information about contingencies, and no practice trials—and given variability in motivation among undergraduates completing online studies for credit, exclusions rates were higher than expected, resulting in lower-than-ideal power. For details on participant exclusion rates, see Discussion and Extended Data (Extended Data <a id="xref-supplementary-material-1-2" href="#DC1">Table 1-1</a>). After cleaning, the final sample included <em>N</em> = 330 participants (<em>N</em><sub>female</sub> = 245; <em>N</em><sub>male</sub> = 85). The study was approved by the University of British Columbia Behavioral Research Ethics Board (BREB) under certificate H20-01388. Demographic information for Study 2 can be found in <a id="xref-table-wrap-1-2" href="#T1">Table 1</a>.</p><div id="T1"><p><span>Table 1.</span></p><p id="p-22">Demographic information for all participants</p></div></div><div id="sec-14"><h4>Materials</h4><div id="sec-15"><h5>Stimuli and measures</h5><p id="p-25">The task was implemented using PsychoPy and Pavlovia (same as Study 1) with modification to incorporate reward-seeking trials. Stimuli included four simple shapes (blue; square, circle, triangle, hexagon) counterbalanced across response type (active vs inhibitory) and motivational context (reward-seeking vs avoidance). As in Study 1, participants completed questionnaire measures, effort, and volume calibrations procedures.</p></div><div id="sec-16"><h5>Mixed-motivation go/no-go task</h5><p id="p-26">The mixed-motivation task consisted of two stages: (1) an acquisition stage, where participants learned active reward-seeking and active avoidance responses, and (2) an intermixed stage, which required the flexible expression of active and inhibitory responses across reward-seeking and avoidance contexts. During the acquisition stage, participants had to reach 80% accuracy within the previous 20 trials, independently for both active reward-seeking and active avoidance trials. After reaching the acquisition criterion, participants completed 24 “over-learning” trials (12 reward-seeking and 12 avoidance) before an unsignaled transition into the intermixed stage. Participants who failed to reach criterion were excluded from analysis. The intermixed stage consisted of 240 trials (60 of each type—active reward-seeking, inhibitory reward-seeking, active avoidance, inhibitory avoidance), presented in a pseudorandomized order. The reversal stage used in Study 1 was omitted.</p><p id="p-27">Trials began with a fixation cross (ISI; 2,000 ms; jittered 1,200 ms). Active responses required 3, 4, or 5 button presses within the 1,200 ms cue period (threshold determined during effort calibration). On successful trials, participants either earned 5 points or avoided an aversive sound, depending on the motivational context. Successful reward-seeking trials provided a reward signal (1,000 ms; white border), while successful avoidance trials were followed by a safety signal (1,000 ms; white border). On failed trials, participants either received no points (reward-seeking) or were presented with an aversive sound (avoidance). Points accumulated were displayed on reward-seeking trials, and a musical tone (C major chord; 1,100 ms) played each time participants earned an additional 25 points.</p></div></div><div id="sec-17"><h4>Statistical analysis</h4><p id="p-28">Analytical procedures followed Study 1. Accuracy (proportion correct) and trials to criterion during acquisition were the primary outcomes. Linear mixed models tested BDI-II symptom scores effects on active and inhibitory accuracy across motivational contexts. FDR corrections were used for multiple comparisons.</p></div></div><div id="sec-18"><h3>Code accessibility</h3><p id="p-29">No computational neuroscience models were developed for this study. However, extended data and code used to conduct the linear mixed models are available at <a href="https://osf.io/5sepm/">https://osf.io/5sepm/</a>.</p></div></div><div id="sec-19"><h2>Results</h2><div id="sec-20"><h3>Study 1 (avoidance)</h3><div id="sec-21"><h4>Demographics</h4><p id="p-30">To assess differences between undergraduates and online workers, we first compared self-reported depressive and anxiety symptom scores. There was no difference in depressive symptom scores (<em>F</em><sub>(1,463)</sub> = 0.34, <em>p</em> = 0.56; <a id="xref-fig-2-1" href="#F2">Fig. 2<em>A</em></a>), but undergraduates reported significantly higher anxiety symptom scores compared with online workers (<em>F</em><sub>(1,463)</sub> = 13.84, <em>p</em> &lt; 0.001; Extended Data <a id="xref-supplementary-material-2-2" href="#DC2">Fig. 2-1</a>). Sex and gender responses were highly congruent (&gt;96%); due to limited statistical power for non-cis gender categories, subsequent analyses refer to sex only. Females reported higher depressive (<em>F</em><sub>(1,463)</sub> = 7.96, <em>p</em> &lt; 0.01; <a id="xref-fig-2-2" href="#F2">Fig. 2<em>B</em></a>) and higher anxiety (<em>F</em><sub>(1,463)</sub> = 33.63, <em>p</em> &lt; 0.001; Extended Data <a id="xref-supplementary-material-2-3" href="#DC2">Fig. 2-1</a>) symptom scores than males. Finally, there was a significant age difference between samples (<em>F</em><sub>(1,462)</sub> = 299.8, <em>p</em> &lt; 0.001), with undergraduates being younger on average compared with online workers (Extended Data <a id="xref-supplementary-material-3-1" href="#DC3">Fig. 2-2</a>).</p><div id="F2"><div><div><p><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F2.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Study 1: Distribution of depressive symptom scores across samples and sexes. Density plots representing the distribution of Beck Depression Inventory-II (BDI-II) scores. A, Depressive symptom score distributions by sample: Undergraduates (red) and Online Workers (blue). B, Depressive symptom score distributions by sex: Female (red) and Male (blue). The x-axis represents proportion scores, where raw BDI-II symptom scores, ranging from 0 to 60, have been divided by the maximum possible score (60) to produce a proportion between 0 and 1. This adjustment was made because the suicide ideation question was removed for ethical consideration. The labels on the x-axis—Minimal (0–13), Mild-Moderate (14–28), Severe (29–63)—reflect typical ranges of raw symptom scores for ease of interpretation. Dashed vertical lines represent the mean BDI-II symptom score for each group. In panel B, a significant difference in depressive levels between sexes is indicated (p " rel="gallery-fragment-images-593667592" data-figure-caption="<div class=&quot;highwire-markup&quot;><div xmlns=&quot;http://www.w3.org/1999/xhtml&quot;>Study 1: Distribution of depressive symptom scores across samples and sexes.<strong> </strong>Density plots representing the distribution of Beck Depression Inventory-II (BDI-II) scores. <strong><em>A</em></strong>, Depressive symptom score distributions by sample: Undergraduates (red) and Online Workers (blue). <strong><em>B</em></strong>, Depressive symptom score distributions by sex: Female (red) and Male (blue). The <em>x</em>-axis represents proportion scores, where raw BDI-II symptom scores, ranging from 0 to 60, have been divided by the maximum possible score (60) to produce a proportion between 0 and 1. This adjustment was made because the suicide ideation question was removed for ethical consideration. The labels on the <em>x</em>-axis—Minimal (0–13), Mild-Moderate (14–28), Severe (29–63)—reflect typical ranges of raw symptom scores for ease of interpretation. Dashed vertical lines represent the mean BDI-II symptom score for each group. In panel <strong><em>B</em></strong>, a significant difference in depressive levels between sexes is indicated (<em>p</em> < 0.01), with females scoring higher on average than males. See Extended Data Figures 2-1 (BAI distributions) and 2-2 (Age distributions).</div></div>" data-icon-position="" data-hide-link-title="0"><span><img alt="Figure 2." src="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F2.medium.gif" width="440" height="226" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a></p></div><ul><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F2.large.jpg?download=true" title="Download Figure 2." data-icon-position="" data-hide-link-title="0">Download figure</a></li><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F2.large.jpg" target="_blank" data-icon-position="" data-hide-link-title="0">Open in new tab</a></li><li><a href="https://www.eneuro.org/highwire/powerpoint/3811670" data-icon-position="" data-hide-link-title="0">Download powerpoint</a></li></ul></div><div><p><span>Figure 2.</span></p><p id="p-31">Study 1: Distribution of depressive symptom scores across samples and sexes.<strong> </strong>Density plots representing the distribution of Beck Depression Inventory-II (BDI-II) scores. <strong><em>A</em></strong>, Depressive symptom score distributions by sample: Undergraduates (red) and Online Workers (blue). <strong><em>B</em></strong>, Depressive symptom score distributions by sex: Female (red) and Male (blue). The <em>x</em>-axis represents proportion scores, where raw BDI-II symptom scores, ranging from 0 to 60, have been divided by the maximum possible score (60) to produce a proportion between 0 and 1. This adjustment was made because the suicide ideation question was removed for ethical consideration. The labels on the <em>x</em>-axis—Minimal (0–13), Mild-Moderate (14–28), Severe (29–63)—reflect typical ranges of raw symptom scores for ease of interpretation. Dashed vertical lines represent the mean BDI-II symptom score for each group. In panel <strong><em>B</em></strong>, a significant difference in depressive levels between sexes is indicated (<em>p</em> &lt; 0.01), with females scoring higher on average than males. See Extended Data <a id="xref-supplementary-material-2-4" href="#DC2">Figures 2-1</a> (BAI distributions) and <a id="xref-supplementary-material-3-2" href="#DC3">2-2</a> (Age distributions).</p></div></div><div id="DC2"><h3>Figure 2-1</h3><p id="p-32"><strong>Study 1: Distribution of Anxiety Scores Across Samples and Sexes.</strong> Density plots representing the distribution of Beck Anxiety Inventory (BAI) scores. <strong>A)</strong> Anxiety score distributions by sample: Undergraduates (red) and Online Workers (blue). <strong>B)</strong> Anxiety score distributions by sex: Female (red) and Male (blue). The x-axis represents proportion scores, where raw BAI scores, ranging from 0-63, have been divided by the maximum possible score (63) to produce a proportion between 0 and 1. This adjustment was made for comparability between the BDI-II and BAI scales. The labels on the x-axis -- Minimal (0-7), Mild-Moderate (8-25), Severe (26-63) -- reflect typical ranges of raw scores for ease of interpretation. Dashed vertical lines represent the mean BAI score for each group. In panel A, a significant difference in anxiety levels between sample groups is indicated (<em>p</em> &lt; .001), with undergraduates scoring higher on average than online workers. In panel B, a significant difference in anxiety levels between sexes is indicated (<em>p</em> &lt; .001), with females scoring higher on average than males. Download <span><span id="DC2"><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/DC2/embed/inline-supplementary-material-2.tif?download=true" data-icon-position="" data-hide-link-title="0"><span></span>Figure 2-1, TIF file</a></span></span>.</p></div><div id="DC3"><h3>Figure 2-2</h3><p id="p-33"><strong>Study 1: Age Distribution Across Samples.</strong> Density plot representing the distribution of ages for undergraduates (red) and online workers (blue). Dashed vertical lines represent the mean age for each group. A significant difference in age between the samples are indicated (<em>p</em> &lt; .001), with online workers being older on average compared to undergraduates. Download <span><span id="DC3"><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/DC3/embed/inline-supplementary-material-3.tif?download=true" data-icon-position="" data-hide-link-title="0"><span></span>Figure 2-2, TIF file</a></span></span>.</p></div></div><div id="sec-22"><h4>Avoidance task</h4><div id="sec-23"><h5>Within-subject results</h5><p id="p-34"><em>Acquisition</em>. The acquisition task stage assessed initial learning of the active avoidance response. Participants showed robust acquisition, with an average accuracy of 0.79 (SD = 0.15; <a id="xref-fig-3-1" href="#F3">Fig. 3<em>A</em></a>). The mean number of trials to reach criterion (≥80% correct in 20 trial period) was 29.65 (SD = 18.42; range, 16–120 trials; <a id="xref-fig-4-1" href="#F4">Fig. 4<em>A</em></a>). Higher BDI-II scores were associated with a greater number of trials needed to reach criterion during acquisition, but this effect was specific to undergraduates (<a id="xref-fig-4-2" href="#F4">Fig. 4<em>B</em></a>; see <a href="https://osf.io/5sepm/">https://osf.io/5sepm/</a>).</p><div id="F3"><div><div><p><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F3.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Study 1: Avoidance performance across task stages. Proportion correct for active (green) and inhibitory (red) avoidance responses across three task stages: A, Acquisition; B, intermixed, and C, reversal. The left panels display overall accuracy, with circles representing individual participant performance for active and inhibitory avoidance, respectively. The right panels show accuracy across blocks of six trials, with circles representing mean performance for each avoidance type. Proportion correct reflects the ratio of successful avoidance responses relative to the total number of trials for each avoidance type. Significant differences between active and inhibitory avoidance during the intermixed and reversal stages are indicated (p " rel="gallery-fragment-images-593667592" data-figure-caption="<div class=&quot;highwire-markup&quot;><div xmlns=&quot;http://www.w3.org/1999/xhtml&quot;>Study 1: Avoidance performance across task stages. Proportion correct for active (green) and inhibitory (red) avoidance responses across three task stages: <strong><em>A</em></strong>, Acquisition; <strong><em>B</em></strong>, intermixed, and <strong><em>C</em></strong>, reversal. The left panels display overall accuracy, with circles representing individual participant performance for active and inhibitory avoidance, respectively. The right panels show accuracy across blocks of six trials, with circles representing mean performance for each avoidance type. Proportion correct reflects the ratio of successful avoidance responses relative to the total number of trials for each avoidance type. Significant differences between active and inhibitory avoidance during the intermixed and reversal stages are indicated (<em>p</em> < 0.001).</div></div>" data-icon-position="" data-hide-link-title="0"><span><img alt="Figure 3." src="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F3.medium.gif" width="440" height="209" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a></p></div><ul><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F3.large.jpg?download=true" title="Download Figure 3." data-icon-position="" data-hide-link-title="0">Download figure</a></li><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F3.large.jpg" target="_blank" data-icon-position="" data-hide-link-title="0">Open in new tab</a></li><li><a href="https://www.eneuro.org/highwire/powerpoint/3811686" data-icon-position="" data-hide-link-title="0">Download powerpoint</a></li></ul></div><div><p><span>Figure 3.</span></p><p id="p-35">Study 1: Avoidance performance across task stages. Proportion correct for active (green) and inhibitory (red) avoidance responses across three task stages: <strong><em>A</em></strong>, Acquisition; <strong><em>B</em></strong>, intermixed, and <strong><em>C</em></strong>, reversal. The left panels display overall accuracy, with circles representing individual participant performance for active and inhibitory avoidance, respectively. The right panels show accuracy across blocks of six trials, with circles representing mean performance for each avoidance type. Proportion correct reflects the ratio of successful avoidance responses relative to the total number of trials for each avoidance type. Significant differences between active and inhibitory avoidance during the intermixed and reversal stages are indicated (<em>p</em> &lt; 0.001).</p></div></div><div id="F4"><div><div><p><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F4.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Study 1: Trials to criterion for active avoidance during the acquisition stage. A, Number of trials required to reach criterion for all participants in the avoidance task. Individual data points (green circles) represent the number of trials each participant required to reach the criterion of 80% correct responses within 20-trial period during acquisition. B, Interaction between depressive symptom scores (BDI-II proportion scores) and the sample group (Undergraduates vs Online Workers) predicting trials to criterion for active avoidance. The regression lines show the relationship between depressive symptom scores and trials to criterion for each sample, with a stronger effect observed in undergraduates (β = 24.57) compared with online workers (β = 1.09). A significant main effect of BDI-II symptom scores (p " rel="gallery-fragment-images-593667592" data-figure-caption="<div class=&quot;highwire-markup&quot;><div xmlns=&quot;http://www.w3.org/1999/xhtml&quot;>Study 1: Trials to criterion for active avoidance during the acquisition stage. <strong><em>A</em></strong>, Number of trials required to reach criterion for all participants in the avoidance task. Individual data points (green circles) represent the number of trials each participant required to reach the criterion of 80% correct responses within 20-trial period during acquisition. <strong><em>B</em></strong>, Interaction between depressive symptom scores (BDI-II proportion scores) and the sample group (Undergraduates vs Online Workers) predicting trials to criterion for active avoidance. The regression lines show the relationship between depressive symptom scores and trials to criterion for each sample, with a stronger effect observed in undergraduates (<em>β</em> = 24.57) compared with online workers (<em>β</em> = 1.09). A significant main effect of BDI-II symptom scores (<em>p</em> < 0.001) and a significant BDI-II × Sample interaction (<em>p</em> < 0.05) are indicated. See Extended Data Figure 4-1 for corresponding BAI effects.</div></div>" data-icon-position="" data-hide-link-title="0"><span><img alt="Figure 4." src="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F4.medium.gif" width="440" height="311" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a></p></div><ul><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F4.large.jpg?download=true" title="Download Figure 4." data-icon-position="" data-hide-link-title="0">Download figure</a></li><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F4.large.jpg" target="_blank" data-icon-position="" data-hide-link-title="0">Open in new tab</a></li><li><a href="https://www.eneuro.org/highwire/powerpoint/3811677" data-icon-position="" data-hide-link-title="0">Download powerpoint</a></li></ul></div><div><p><span>Figure 4.</span></p><p id="p-36">Study 1: Trials to criterion for active avoidance during the acquisition stage. <strong><em>A</em></strong>, Number of trials required to reach criterion for all participants in the avoidance task. Individual data points (green circles) represent the number of trials each participant required to reach the criterion of 80% correct responses within 20-trial period during acquisition. <strong><em>B</em></strong>, Interaction between depressive symptom scores (BDI-II proportion scores) and the sample group (Undergraduates vs Online Workers) predicting trials to criterion for active avoidance. The regression lines show the relationship between depressive symptom scores and trials to criterion for each sample, with a stronger effect observed in undergraduates (<em>β</em> = 24.57) compared with online workers (<em>β</em> = 1.09). A significant main effect of BDI-II symptom scores (<em>p</em> &lt; 0.001) and a significant BDI-II × Sample interaction (<em>p</em> &lt; 0.05) are indicated. See Extended Data <a id="xref-supplementary-material-4-2" href="#DC4">Figure 4-1</a> for corresponding BAI effects.</p></div></div><div id="DC4"><h3>Figure 4-1</h3><p id="p-37"><strong>Study 1: Trials to Criterion for Active Avoidance During the Acquisition Stage</strong>. <strong>A)</strong> Number of trials required to reach criterion for all participants in the avoidance task. Individual data points (green circles) represent the number of trials each participant required to reach the criterion of 80% correct responses within 20-trial period during acquisition. <strong>B)</strong> Interaction between anxiety scores (BAI proportion scores) and the sample group (Undergraduates vs. Online Workers) predicting trials to criterion for active avoidance. The regression lines show the relationship between anxiety scores and trials to criterion for each sample, with a stronger effect observed in undergraduates (<em>β</em> = 16.14) compared to online workers (<em>β</em> = -3.81). A significant main effect of BAI scores (<em>p</em> &lt; .01) and a significant BAI × Sample interaction (<em>p</em> &lt; .05) are indicated. Download <span><span id="DC4"><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/DC4/embed/inline-supplementary-material-4.tif?download=true" data-icon-position="" data-hide-link-title="0"><span></span>Figure 4-1, TIF file</a></span></span>.</p></div><p id="p-38"><em>Intermixed and reversal</em>. The intermixed task stage assessed participants’ ability to switch between active and inhibitory responses using discriminative cues, while the reversal task stage assessed behavioral flexibility when cue–response contingencies were reversed. A 2 × 2 within-subjects ANOVA assessing proportion correct, with Avoidance Type (active, inhibitory) and Task Stage (intermixed, reversal) as within-subjects factors, revealed a significant effect of Avoidance Type and Task Stage, and a significant interaction (<a id="xref-table-wrap-2-1" href="#T2">Table 2</a>). Follow-up analysis revealed higher accuracy on inhibitory compared with active trials in both the intermixed (<em>M</em><sub>Inhibitory</sub> = 0.90, SD = 0.06; <em>M</em><sub>Active</sub> = 0.87, SD = 0.12; <em>t</em><sub>(711)</sub> = −4.74, <em>p</em> &lt; 0.001; <a id="xref-fig-3-2" href="#F3">Fig. 3<em>B</em></a>) and reversal stages (<em>M</em><sub>Inhibitory</sub> = 0.90, SD = 0.07; <em>M</em><sub>Active</sub> = 0.82, SD = 0.15; <em>t</em><sub>(711)</sub> = −12.18, <em>p</em> &lt; 0.001; <a id="xref-fig-3-3" href="#F3">Fig. 3<em>C</em></a>). Accuracy on active trials was also higher in the intermixed compared with the reversal stage (<em>t</em><sub>(877)</sub> = 10.49, <em>p</em> &lt; 0.001), whereas inhibitory accuracy did not differ by stage (<em>t</em><sub>(877)</sub> = 0.81, <em>p</em> = 0.42).</p><div id="T2"><p><span>Table 2.</span></p><p id="p-39">Study 1—2 × 2 within-subjects ANOVA table for active and inhibitory avoidance accuracy for intermixed and reversal task stages</p></div></div><div id="sec-24"><h5>Between-subject results</h5><p id="p-41"><em>Depressive symptom scores and active avoidance accuracy</em>. To examine the relationship between depressive symptom scores and active avoidance accuracy, we used a linear mixed model with BDI-II symptom scores (<em>z</em>-normalized, grand-mean centered) as the primary predictor. The model included Sex (female, male), Task Stage (acquisition, intermixed, reversal), and Sample (undergraduates, online workers) as fixed effects and Participant as a random intercept. Proportion correct on active trials was also <em>z</em>-normalized (grand-mean centered). To ensure model stability, we adopted a simplified random-effects structure that excluded a random slope for Task Stage. As shown in <a id="xref-table-wrap-3-1" href="#T3">Table 3</a>, the model revealed a significant main effect of BDI-II (<em>β</em> = −0.230, SE = 0.074, <em>p</em> = 0.009), indicating that higher depressive symptoms were associated with lower active avoidance accuracy when all other variables were at their reference levels (i.e., female, acquisition, undergraduates). After controlling for multiple comparisons, there were no significant interactions between BDI-II and Sex or Sample. However, we observed a significant interaction between BDI-II and Task Stage, with the relationship between depressive symptoms and active avoidance accuracy changing in the intermixed (<em>β</em> = 0.300, SE = 0.083, <em>p</em> = 0.003) and reversal stages (<em>β</em> = 0.215, SE = 0.083, <em>p</em> = 0.041), relative to acquisition. These interactions suggest that the negative relationship between depressive symptoms and active avoidance accuracy was strongest during initial learning (acquisition) and was attenuated at later stages when avoidance responses are well-learned or inhibitory control was required (<a id="xref-fig-5-1" href="#F5">Fig. 5</a>).</p><div id="F5"><div><div><p><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F5.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Study 1: Linear mixed model predicting active avoidance accuracy: interaction between BDI-II scores and task stage. Z-normalized depressive symptom scores (BDI-II) interacted with task stage (acquisition, intermixed, reversal) to predict active avoidance accuracy (proportion correct; z-normalized). Formula: Accuracy ∼ BDI-II × Sex × Task Stage × Sample + (1| Participant). Each circle represents individual participant data. Colored regression lines show the relationship between depressive scores and active accuracy across task stages: acquisition (green), intermixed (red), and reversal (amber). A significant negative relationship between BDI-II scores and accuracy in the acquisition stage (β = −0.230), while this relationship was attenuated in the intermixed (β = −0.015), and reversal (β = 0.070) stages. Significant BDI-II × Task Stage interactions are indicated. Asterisks next to regression lines denotes slopes significantly different from zero; asterisks between task stages indicate significant differences in the slopes between levels. Statistical significance denoted as follows: *p " rel="gallery-fragment-images-593667592" data-figure-caption="<div class=&quot;highwire-markup&quot;><div xmlns=&quot;http://www.w3.org/1999/xhtml&quot;>Study 1: Linear mixed model predicting active avoidance accuracy: interaction between BDI-II scores and task stage. <em>Z</em>-normalized depressive symptom scores (BDI-II) interacted with task stage (acquisition, intermixed, reversal) to predict active avoidance accuracy (proportion correct; <em>z</em>-normalized). Formula: Accuracy<em> ∼ </em>BDI-II<em> × </em>Sex<em> × </em>Task Stage<em> × </em>Sample<em> + </em>(<em>1|</em> Participant). Each circle represents individual participant data. Colored regression lines show the relationship between depressive scores and active accuracy across task stages: acquisition (green), intermixed (red), and reversal (amber). A significant negative relationship between BDI-II scores and accuracy in the acquisition stage (<em>β</em> = −0.230), while this relationship was attenuated in the intermixed (<em>β</em> = −0.015), and reversal (<em>β</em> = 0.070) stages. Significant BDI-II × Task Stage interactions are indicated. Asterisks next to regression lines denotes slopes significantly different from zero; asterisks between task stages indicate significant differences in the slopes between levels. Statistical significance denoted as follows: *<em>p</em> < 0.05, **<em>p</em> < 0.01. Full model results are presented in Table 3.</div></div>" data-icon-position="" data-hide-link-title="0"><span><img alt="Figure 5." src="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F5.medium.gif" width="440" height="435" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a></p></div><ul><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F5.large.jpg?download=true" title="Download Figure 5." data-icon-position="" data-hide-link-title="0">Download figure</a></li><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F5.large.jpg" target="_blank" data-icon-position="" data-hide-link-title="0">Open in new tab</a></li><li><a href="https://www.eneuro.org/highwire/powerpoint/3811669" data-icon-position="" data-hide-link-title="0">Download powerpoint</a></li></ul></div><div><p><span>Figure 5.</span></p><p id="p-42">Study 1: Linear mixed model predicting active avoidance accuracy: interaction between BDI-II scores and task stage. <em>Z</em>-normalized depressive symptom scores (BDI-II) interacted with task stage (acquisition, intermixed, reversal) to predict active avoidance accuracy (proportion correct; <em>z</em>-normalized). Formula: Accuracy<em> ∼ </em>BDI-II<em> × </em>Sex<em> × </em>Task Stage<em> × </em>Sample<em> + </em>(<em>1|</em> Participant). Each circle represents individual participant data. Colored regression lines show the relationship between depressive scores and active accuracy across task stages: acquisition (green), intermixed (red), and reversal (amber). A significant negative relationship between BDI-II scores and accuracy in the acquisition stage (<em>β</em> = −0.230), while this relationship was attenuated in the intermixed (<em>β</em> = −0.015), and reversal (<em>β</em> = 0.070) stages. Significant BDI-II × Task Stage interactions are indicated. Asterisks next to regression lines denotes slopes significantly different from zero; asterisks between task stages indicate significant differences in the slopes between levels. Statistical significance denoted as follows: *<em>p</em> &lt; 0.05, **<em>p</em> &lt; 0.01. Full model results are presented in <a id="xref-table-wrap-3-2" href="#T3">Table 3</a>.</p></div></div><div id="T3"><p><span>Table 3.</span></p><p id="p-43">Study 1—linear mixed model for BDI-II predicting active avoidance accuracy</p></div><p id="p-51"><em>Depressive symptom scores and inhibitory avoidance accuracy.</em> A similar linear mixed model was used to examine the relationship between depressive symptom scores (BDI-II symptom scores, <em>z</em>-normalized, grand-mean centered) and inhibitory avoidance accuracy (<em>z</em>-normalized, grand-mean centered). The model included Sex (female, male), Task Stage (intermixed, reversal), and Sample (undergraduates, online workers) as fixed effects and Participant as a random intercept. No main effects or interactions involving BDI-II were significant (Extended Data <a id="xref-supplementary-material-6-2" href="#DC6">Table 3-2</a>), suggesting that depressive symptoms were not associated with inhibitory avoidance performance using this task.</p></div></div></div><div id="sec-25"><h3>Study 2 (reward-seeking/avoidance)</h3><p id="p-52">In Study 1, participants showed lower accuracy on active compared with inhibitory avoidance trials. However, it remained unclear whether this effect was driven by conflict arising from a prepotent tendency to inhibit action under threat (<a id="xref-ref-10-1" href="#ref-10">Bolles, 1970</a>; <a id="xref-ref-56-1" href="#ref-56">Pessoa, 2009</a>; <a id="xref-ref-73-1" href="#ref-73">Wendt et al., 2017</a>) or by a preference to reduce effort expenditure due to the additional demands of effortful active responses (<a id="xref-ref-36-1" href="#ref-36">Hogan et al., 2020</a>; <a id="xref-ref-30-1" href="#ref-30">Forys et al., 2023</a>). To address this, Study 2 used a mixed-motivation task that assesses both active and inhibitory responses within reward-seeking and avoidance contexts in undergraduates. Here, the design manipulated the congruency between motivational context (reward-seeking vs avoidance) and instrumental response (active vs inhibitory), allowing for analysis of how motivational context shapes action tendencies. Moreover, because the ACDM framework proposes that depression is associated with altered reward-seeking and effort-related decision-making (<a id="xref-ref-9-3" href="#ref-9">Bishop and Gagne, 2018</a>), we examined whether individual differences in depressive symptom scores would differentially affect behavior across motivational contexts. This design allowed for a detailed examination of both reward-seeking and avoidance behaviors, considering their active and inhibitory dimensions.</p><p id="p-53">We hypothesized that task accuracy would be highest for inhibitory avoidance and active reward-seeking, as these behaviors are contextually aligned with prepotent response tendencies—inhibiting action to avoid threat and initiating action to obtain reward. Furthermore, we expected that participants with higher depressive symptom scores would exhibit reduced accuracy in active reward-seeking, consistent with predictions of diminished behavioral engagement due to effort demand overestimation and/or reward undervaluation. A graphical overview of the mixed-motivation task is provided in <a id="xref-fig-6-1" href="#F6">Figure 6</a>.</p><div id="F6"><div><div><p><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F6.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Study 2: Mixed-motivation go/no-go task. A, Schematic of task stages. Acquisition and intermixed. Green lines represent active (“Go”) trials, while red lines represent inhibitory (“No-Go”) trials. Light green and light red lines indicate reward-seeking (RS) trials, while dark green and dark red lines indicate avoidance trials. The black arrow indicates time progression. During acquisition, participants were required to reach a criterion of 80% correct active reward-seeking and 80% correct active avoidance trials over a 20-trial period (i.e., initial acquisition) or complete a maximum of 144 trials. Upon reaching criterion, participants completed 24 over-learning trials, followed by an unsignaled transition into the intermixed stage. In this stage, participants flexibly alternated between active and inhibitory reward-seeking and active and inhibitory avoidance responses. B, Active reward-seeking: A blue triangle signals an active reward-seeking trial. The participant makes sufficient keyboard presses (green circles) within 1,200 ms cue period and is awarded points (+5 points) toward a monetary reward, followed with a reward-signal (white border onscreen, not shown). C, Active avoidance: A blue circle signals an active avoidance trial. The participant makes sufficient keyboard presses (green circles) within 1,200 ms cue period, avoiding an aversive sound (yellow speaker), followed with a safety signal (white boarder onscreen, not shown). D, Inhibitory reward-seeking: A blue hexagon signals an inhibitory reward-seeking trial. The participant withholds keyboard presses for the full 1,200 ms and is awarded points toward a monetary reward, followed with a reward-signal. E, Inhibitory avoidance: A blue square signals an inhibitory avoidance trial. The participant withholds keyboard presses for the full 1,200 ms, avoiding an aversive sound, followed by a safety signal. Failed reward-seeking or avoidance trials result in no points (+0 points) or the presentation of an aversive sound, respectively." rel="gallery-fragment-images-593667592" data-figure-caption="<div class=&quot;highwire-markup&quot;><div xmlns=&quot;http://www.w3.org/1999/xhtml&quot;>Study 2: Mixed-motivation go/no-go task. <strong><em>A</em></strong>, Schematic of task stages. Acquisition and intermixed. Green lines represent active (“Go”) trials, while red lines represent inhibitory (“No-Go”) trials. Light green and light red lines indicate reward-seeking (RS) trials, while dark green and dark red lines indicate avoidance trials. The black arrow indicates time progression. During acquisition, participants were required to reach a criterion of 80% correct active reward-seeking and 80% correct active avoidance trials over a 20-trial period (i.e., initial acquisition) or complete a maximum of 144 trials. Upon reaching criterion, participants completed 24 over-learning trials, followed by an unsignaled transition into the intermixed stage. In this stage, participants flexibly alternated between active and inhibitory reward-seeking and active and inhibitory avoidance responses. <strong><em>B</em></strong>, Active reward-seeking: A blue triangle signals an active reward-seeking trial. The participant makes sufficient keyboard presses (green circles) within 1,200 ms cue period and is awarded points (+5 points) toward a monetary reward, followed with a reward-signal (white border onscreen, not shown). <strong><em>C</em></strong>, Active avoidance: A blue circle signals an active avoidance trial. The participant makes sufficient keyboard presses (green circles) within 1,200 ms cue period, avoiding an aversive sound (yellow speaker), followed with a safety signal (white boarder onscreen, not shown). <strong><em>D</em></strong>, Inhibitory reward-seeking: A blue hexagon signals an inhibitory reward-seeking trial. The participant withholds keyboard presses for the full 1,200 ms and is awarded points toward a monetary reward, followed with a reward-signal. <strong><em>E</em></strong>, Inhibitory avoidance: A blue square signals an inhibitory avoidance trial. The participant withholds keyboard presses for the full 1,200 ms, avoiding an aversive sound, followed by a safety signal. Failed reward-seeking or avoidance trials result in no points (+0 points) or the presentation of an aversive sound, respectively.</div></div>" data-icon-position="" data-hide-link-title="0"><span><img alt="Figure 6." src="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F6.medium.gif" width="440" height="236" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a></p></div><ul><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F6.large.jpg?download=true" title="Download Figure 6." data-icon-position="" data-hide-link-title="0">Download figure</a></li><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F6.large.jpg" target="_blank" data-icon-position="" data-hide-link-title="0">Open in new tab</a></li><li><a href="https://www.eneuro.org/highwire/powerpoint/3811684" data-icon-position="" data-hide-link-title="0">Download powerpoint</a></li></ul></div><div><p><span>Figure 6.</span></p><p id="p-54">Study 2: Mixed-motivation go/no-go task. <strong><em>A</em></strong>, Schematic of task stages. Acquisition and intermixed. Green lines represent active (“Go”) trials, while red lines represent inhibitory (“No-Go”) trials. Light green and light red lines indicate reward-seeking (RS) trials, while dark green and dark red lines indicate avoidance trials. The black arrow indicates time progression. During acquisition, participants were required to reach a criterion of 80% correct active reward-seeking and 80% correct active avoidance trials over a 20-trial period (i.e., initial acquisition) or complete a maximum of 144 trials. Upon reaching criterion, participants completed 24 over-learning trials, followed by an unsignaled transition into the intermixed stage. In this stage, participants flexibly alternated between active and inhibitory reward-seeking and active and inhibitory avoidance responses. <strong><em>B</em></strong>, Active reward-seeking: A blue triangle signals an active reward-seeking trial. The participant makes sufficient keyboard presses (green circles) within 1,200 ms cue period and is awarded points (+5 points) toward a monetary reward, followed with a reward-signal (white border onscreen, not shown). <strong><em>C</em></strong>, Active avoidance: A blue circle signals an active avoidance trial. The participant makes sufficient keyboard presses (green circles) within 1,200 ms cue period, avoiding an aversive sound (yellow speaker), followed with a safety signal (white boarder onscreen, not shown). <strong><em>D</em></strong>, Inhibitory reward-seeking: A blue hexagon signals an inhibitory reward-seeking trial. The participant withholds keyboard presses for the full 1,200 ms and is awarded points toward a monetary reward, followed with a reward-signal. <strong><em>E</em></strong>, Inhibitory avoidance: A blue square signals an inhibitory avoidance trial. The participant withholds keyboard presses for the full 1,200 ms, avoiding an aversive sound, followed by a safety signal. Failed reward-seeking or avoidance trials result in no points (+0 points) or the presentation of an aversive sound, respectively.</p></div></div><div id="sec-26"><h4>Demographics</h4><p id="p-55">Females reported marginally higher levels of depressive symptoms (<em>F</em><sub>(1,328)</sub> = 3.24, <em>p</em> = 0.0729) and significantly higher levels of anxiety symptoms (<em>F</em><sub>(1,328)</sub> = 12.99, <em>p</em> &lt; 0.001) compared with males (<a id="xref-fig-7-1" href="#F7">Fig. 7<em>B</em></a>; Extended Data <a id="xref-supplementary-material-8-1" href="#DC8">Fig. 7-1</a>). There was no significant age difference between sex (<em>F</em><sub>(1,328)</sub> = 0.112, <em>p</em> = 0.738).</p><div id="F7"><div><div><p><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F7.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Study 2: Distribution of depressive symptom scores in undergraduates and across sexes. Density plots representing the distribution of Beck Depression Inventory-II (BDI-II) symptom scores. A, Depressive symptom score distributions in full undergraduate sample (red). B, Depressive symptom score distributions by sex: Female (red) and Male (blue). The x-axis represents proportion scores, where raw BDI-II symptom scores, ranging from 0 to 60, have been divided by the maximum possible score (60) to produce a proportion between 0 and 1. This adjustment was made because the suicide ideation question was removed for ethical consideration. The labels on the x-axis—Minimal (0–13), Mild-Moderate (14–28), Severe (29–63)—reflect typical ranges of raw symptom scores for ease of interpretation. Dashed vertical black line represents mean in full sample. Dash vertical-colored lines represent the mean BDI-II symptom score for each group. In panel B, a marginal significant difference in depressive levels between sexes is indicated (p " rel="gallery-fragment-images-593667592" data-figure-caption="<div class=&quot;highwire-markup&quot;><div xmlns=&quot;http://www.w3.org/1999/xhtml&quot;>Study 2: Distribution of depressive symptom scores in undergraduates and across sexes. Density plots representing the distribution of Beck Depression Inventory-II (BDI-II) symptom scores. <strong><em>A</em></strong>, Depressive symptom score distributions in full undergraduate sample (red). <strong><em>B</em></strong>, Depressive symptom score distributions by sex: Female (red) and Male (blue). The <em>x</em>-axis represents proportion scores, where raw BDI-II symptom scores, ranging from 0 to 60, have been divided by the maximum possible score (60) to produce a proportion between 0 and 1. This adjustment was made because the suicide ideation question was removed for ethical consideration. The labels on the <em>x</em>-axis—Minimal (0–13), Mild-Moderate (14–28), Severe (29–63)—reflect typical ranges of raw symptom scores for ease of interpretation. Dashed vertical black line represents mean in full sample. Dash vertical-colored lines represent the mean BDI-II symptom score for each group. In panel <strong><em>B</em></strong>, a marginal significant difference in depressive levels between sexes is indicated (<em>p</em> < 0.10), with females scoring higher on average than males. See Extended Data Figures 7-1 (BAI distributions) and 7-2 (Age distribution).</div></div>" data-icon-position="" data-hide-link-title="0"><span><img alt="Figure 7." src="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F7.medium.gif" width="440" height="226" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a></p></div><ul><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F7.large.jpg?download=true" title="Download Figure 7." data-icon-position="" data-hide-link-title="0">Download figure</a></li><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F7.large.jpg" target="_blank" data-icon-position="" data-hide-link-title="0">Open in new tab</a></li><li><a href="https://www.eneuro.org/highwire/powerpoint/3811674" data-icon-position="" data-hide-link-title="0">Download powerpoint</a></li></ul></div><div><p><span>Figure 7.</span></p><p id="p-56">Study 2: Distribution of depressive symptom scores in undergraduates and across sexes. Density plots representing the distribution of Beck Depression Inventory-II (BDI-II) symptom scores. <strong><em>A</em></strong>, Depressive symptom score distributions in full undergraduate sample (red). <strong><em>B</em></strong>, Depressive symptom score distributions by sex: Female (red) and Male (blue). The <em>x</em>-axis represents proportion scores, where raw BDI-II symptom scores, ranging from 0 to 60, have been divided by the maximum possible score (60) to produce a proportion between 0 and 1. This adjustment was made because the suicide ideation question was removed for ethical consideration. The labels on the <em>x</em>-axis—Minimal (0–13), Mild-Moderate (14–28), Severe (29–63)—reflect typical ranges of raw symptom scores for ease of interpretation. Dashed vertical black line represents mean in full sample. Dash vertical-colored lines represent the mean BDI-II symptom score for each group. In panel <strong><em>B</em></strong>, a marginal significant difference in depressive levels between sexes is indicated (<em>p</em> &lt; 0.10), with females scoring higher on average than males. See Extended Data <a id="xref-supplementary-material-8-2" href="#DC8">Figures 7-1</a> (BAI distributions) and <a id="xref-supplementary-material-9-1" href="#DC9">7-2</a> (Age distribution).</p></div></div><div id="DC8"><h3>Figure 7-1</h3><p id="p-57"><strong>Study 2: Distribution of Anxiety Scores in Undergraduates and Across Sexes.</strong> Density plots representing the distribution of Beck Anxiety Inventory (BAI) scores. <strong>A)</strong> Anxiety score distributions in full undergraduate sample (red). <strong>B)</strong> Anxiety score distributions by sex: Female (red) and Male (blue). The x-axis represents proportion scores, where raw BAI scores, ranging from 0-63, have been divided by the maximum possible score (63) to produce a proportion between 0 and 1. This adjustment was made for comparability between the BDI-II and BAI scales. The labels on the x-axis -- Minimal (0-7), Mild-Moderate (8-25), Severe (26-63) -- reflect typical ranges of raw scores for ease of interpretation. Dashed vertical black line represents mean in full sample. Dashed vertical-coloured lines represent the mean BAI score for each sex. In panel B, a significant difference in anxiety levels between sexes is indicated (<em>p</em> &lt; .001), with females scoring higher on average than males. Download <span><span id="DC8"><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/DC8/embed/inline-supplementary-material-8.tif?download=true" data-icon-position="" data-hide-link-title="0"><span></span>Figure 7-1, TIF file</a></span></span>.</p></div><div id="DC9"><h3>Figure 7-2</h3><p id="p-58"><strong>Study 2: Age Distribution in Undergraduates.</strong> Density plot representing the distribution of ages for undergraduates (red). Dashed vertical black line represent the mean age. Download <span><span id="DC9"><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/DC9/embed/inline-supplementary-material-9.tif?download=true" data-icon-position="" data-hide-link-title="0"><span></span>Figure 7-2, TIF file</a></span></span>.</p></div></div><div id="sec-27"><h4>Mixed-motivation go/no-go task</h4><div id="sec-28"><h5>Acquisition</h5><p id="p-59">Participants successfully learned both active reward-seeking and avoidance responses, as indicated by the number of trials to criterion (reward-seeking: <em>M</em> = 46.94, SD = 18.09; avoidance: <em>M</em> = 51.72, SD = 19.90). A one-way within-subjects ANOVA revealed a significant effect of Motivational Context on the number of trials to criterion, with more trials needed to acquire active avoidance than reward-seeking (<em>F</em><sub>(1,329)</sub> = 30.96, <em>p</em> &lt; 0.001; <a id="xref-fig-8-1" href="#F8">Fig. 8<em>A</em></a>). To test whether depressive symptoms predicted trials to criterion, we fit a linear mixed model including BDI-II scores, Sex, and Motivational Context. No main or interaction effect of BDI-II was observed. Motivational context significantly affected acquisition accuracy, with lower proportion correct on active avoidance (<em>M</em> = 0.774, SD = 0.135) compared with active reward-seeking (<em>M</em> = 0.819, SD = 0.137; <em>F</em><sub>(1,329)</sub> = 52.59, <em>p</em> &lt; 0.001; <a id="xref-fig-8-2" href="#F8">Fig. 8<em>B</em></a>). To assess how this difference varied over time, we analyzed accuracy across the first six trial blocks (where all participants had data). Accuracy improved across blocks (main effect of block) and remained higher for reward-seeking trials compared with avoidance trials (main effect of Motivational Context; <a id="xref-table-wrap-4-1" href="#T4">Table 4</a>). While this difference persisted across blocks 1–5 (<em>t</em>'s<sub>(1629)</sub> &gt; 2.56, <em>p</em>'s &lt; 0.01), it converged by block 6 (<em>t</em><sub>(1,629)</sub> = 1.59, <em>p</em> = 0.11; <a id="xref-fig-8-3" href="#F8">Fig. 8<em>C</em></a>), suggesting slower acquisition for active avoidance than reward-seeking.</p><div id="F8"><div><div><p><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F8.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Study 2: Performance comparison between active reward-seeking and active avoidance during the acquisition stage. A, Number of trials required to reach criterion for all participants in the mixed-motivation task. Individual data points (light green triangles for Active Reward-Seeking; dark green circles for Active Avoidance) represent the number of trials each participant required to reach the criterion of 80% correct responses within 20-trial period during acquisition. B, Overall accuracy for active reward-seeking and active avoidance in the acquisition stage. Individual data points (light green triangles for Active Reward-Seeking; dark green circles for Active Avoidance) represent the proportion correct for each participant. Proportion correct reflects the ratio of successful active responses relative to the total number of trials within each motivation type. C, Accuracy for active reward-seeking and active avoidance across blocks of six trials, with triangles and circles representing mean performance for reward-seeking and avoidance trials, respectively. Significant differences between active reward-seeking and active avoidance during the acquisition stage are indicated (p " rel="gallery-fragment-images-593667592" data-figure-caption="<div class=&quot;highwire-markup&quot;><div xmlns=&quot;http://www.w3.org/1999/xhtml&quot;>Study 2: Performance comparison between active reward-seeking and active avoidance during the acquisition stage. <strong><em>A</em></strong>, Number of trials required to reach criterion for all participants in the mixed-motivation task. Individual data points (light green triangles for Active Reward-Seeking; dark green circles for Active Avoidance) represent the number of trials each participant required to reach the criterion of 80% correct responses within 20-trial period during acquisition. <strong><em>B</em></strong>, Overall accuracy for active reward-seeking and active avoidance in the acquisition stage. Individual data points (light green triangles for Active Reward-Seeking; dark green circles for Active Avoidance) represent the proportion correct for each participant. Proportion correct reflects the ratio of successful active responses relative to the total number of trials within each motivation type. <strong><em>C</em></strong>, Accuracy for active reward-seeking and active avoidance across blocks of six trials, with triangles and circles representing mean performance for reward-seeking and avoidance trials, respectively. Significant differences between active reward-seeking and active avoidance during the acquisition stage are indicated (<em>p</em> < 0.001).</div></div>" data-icon-position="" data-hide-link-title="0"><span><img alt="Figure 8." src="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F8.medium.gif" width="440" height="303" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a></p></div><ul><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F8.large.jpg?download=true" title="Download Figure 8." data-icon-position="" data-hide-link-title="0">Download figure</a></li><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F8.large.jpg" target="_blank" data-icon-position="" data-hide-link-title="0">Open in new tab</a></li><li><a href="https://www.eneuro.org/highwire/powerpoint/3811665" data-icon-position="" data-hide-link-title="0">Download powerpoint</a></li></ul></div><div><p><span>Figure 8.</span></p><p id="p-60">Study 2: Performance comparison between active reward-seeking and active avoidance during the acquisition stage. <strong><em>A</em></strong>, Number of trials required to reach criterion for all participants in the mixed-motivation task. Individual data points (light green triangles for Active Reward-Seeking; dark green circles for Active Avoidance) represent the number of trials each participant required to reach the criterion of 80% correct responses within 20-trial period during acquisition. <strong><em>B</em></strong>, Overall accuracy for active reward-seeking and active avoidance in the acquisition stage. Individual data points (light green triangles for Active Reward-Seeking; dark green circles for Active Avoidance) represent the proportion correct for each participant. Proportion correct reflects the ratio of successful active responses relative to the total number of trials within each motivation type. <strong><em>C</em></strong>, Accuracy for active reward-seeking and active avoidance across blocks of six trials, with triangles and circles representing mean performance for reward-seeking and avoidance trials, respectively. Significant differences between active reward-seeking and active avoidance during the acquisition stage are indicated (<em>p</em> &lt; 0.001).</p></div></div><div id="T4"><p><span>Table 4.</span></p><p id="p-61">Study 2—2 × 6 within-subjects ANOVA for active response accuracy for acquisition task stage by block</p></div></div><div id="sec-29"><h5>Intermixed</h5><p id="p-64">The intermixed stage assessed participants’ ability to flexibly select actions or inhibit responses based on motivational contexts (i.e., reward-seeking vs avoidance). A 2 × 2 within-subjects ANOVA (Motivational Context × Response Type) revealed a significant main effect of Response Type and a significant interaction but no main effect of Motivational Context (<a id="xref-table-wrap-5-1" href="#T5">Table 5</a>). Follow-up analysis revealed higher accuracy for active reward-seeking than active avoidance (<em>t</em><sub>(658)</sub> = 9.92, <em>p</em> &lt; 0.0001) and higher accuracy for inhibitory avoidance compared with inhibitory reward-seeking (<em>t</em><sub>(658)</sub> = 9.60, <em>p</em> &lt; 0.0001). In the avoidance context, inhibitory responses were more accurate compared with active responses (<em>t</em><sub>(658)</sub> = 10.73, <em>p</em> &lt; 0.0001), consistent with Study 1. There were no accuracy differences in Response Type in the reward-seeking context (<em>t</em><sub>(498)</sub> = 1.95, <em>p</em> = 0.21; <a id="xref-fig-9-1" href="#F9">Fig. 9</a>).</p><div id="F9"><div><div><p><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F9.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Study 2: Performance comparison between reward-seeking and avoidance for active and inhibitory responses during the intermixed stage. A, Overall accuracy for active/inhibitory reward-seeking and avoidance in the intermixed stage. Individual data points (light green triangles for Active Reward-Seeking; light red triangles for Inhibitory Reward-Seeking, dark green circles for Active Avoidance, dark red circles for Inhibitory Avoidance) represent the proportion correct for each participant. Proportion correct reflects the ratio of successful responses relative to the total number of trials within each trial type. B, Accuracy for active/inhibitory reward-seeking and avoidance across blocks of six trials during the intermixed task stage. Shapes represent mean performance for each trial type across 10 blocks. Significant differences between (1) active reward-seeking and active avoidance, (2) inhibitory reward-seeking and inhibitory avoidance, and (3) active and inhibitory avoidance are indicated (p " rel="gallery-fragment-images-593667592" data-figure-caption="<div class=&quot;highwire-markup&quot;><div xmlns=&quot;http://www.w3.org/1999/xhtml&quot;>Study 2: Performance comparison between reward-seeking and avoidance for active and inhibitory responses during the intermixed stage. <strong><em>A</em></strong>, Overall accuracy for active/inhibitory reward-seeking and avoidance in the intermixed stage. Individual data points (light green triangles for Active Reward-Seeking; light red triangles for Inhibitory Reward-Seeking, dark green circles for Active Avoidance, dark red circles for Inhibitory Avoidance) represent the proportion correct for each participant. Proportion correct reflects the ratio of successful responses relative to the total number of trials within each trial type. <strong><em>B</em></strong>, Accuracy for active/inhibitory reward-seeking and avoidance across blocks of six trials during the intermixed task stage. Shapes represent mean performance for each trial type across 10 blocks. Significant differences between (1) active reward-seeking and active avoidance, (2) inhibitory reward-seeking and inhibitory avoidance, and (3) active and inhibitory avoidance are indicated (<em>p</em> < 0.001).</div></div>" data-icon-position="" data-hide-link-title="0"><span><img alt="Figure 9." src="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F9.medium.gif" width="440" height="319" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a></p></div><ul><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F9.large.jpg?download=true" title="Download Figure 9." data-icon-position="" data-hide-link-title="0">Download figure</a></li><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F9.large.jpg" target="_blank" data-icon-position="" data-hide-link-title="0">Open in new tab</a></li><li><a href="https://www.eneuro.org/highwire/powerpoint/3811676" data-icon-position="" data-hide-link-title="0">Download powerpoint</a></li></ul></div><div><p><span>Figure 9.</span></p><p id="p-65">Study 2: Performance comparison between reward-seeking and avoidance for active and inhibitory responses during the intermixed stage. <strong><em>A</em></strong>, Overall accuracy for active/inhibitory reward-seeking and avoidance in the intermixed stage. Individual data points (light green triangles for Active Reward-Seeking; light red triangles for Inhibitory Reward-Seeking, dark green circles for Active Avoidance, dark red circles for Inhibitory Avoidance) represent the proportion correct for each participant. Proportion correct reflects the ratio of successful responses relative to the total number of trials within each trial type. <strong><em>B</em></strong>, Accuracy for active/inhibitory reward-seeking and avoidance across blocks of six trials during the intermixed task stage. Shapes represent mean performance for each trial type across 10 blocks. Significant differences between (1) active reward-seeking and active avoidance, (2) inhibitory reward-seeking and inhibitory avoidance, and (3) active and inhibitory avoidance are indicated (<em>p</em> &lt; 0.001).</p></div></div><div id="T5"><p><span>Table 5.</span></p><p id="p-66">Study 2—2 × 2 within-subjects ANOVA for active and inhibitory response accuracy for intermixed task stage</p></div></div></div><div id="sec-30"><h4>Depressive symptom scores and active response accuracy</h4><p id="p-68">We used a linear mixed model to examine whether depressive symptoms (BDI-II, <em>z</em>-normalized, grand-mean centered) predicted accuracy on active trials (also <em>z</em>-normalized). Fixed effects included Sex (female, male), Task Stage (acquisition, intermixed), and Motivational Context (reward-seeking, avoidance), with Participant as a random intercept. This structure matched Study 1, with motivational context added. Motivational Context significantly influenced accuracy, with lower performance on avoidance trials (avoidance; <em>β</em> =−0.307, SE = 0.075, <em>t</em><sub>(978)</sub> = −4.11, <em>p</em> &lt; 0.001). However, BDI-II symptom scores were not significantly associated with active accuracy (<em>β</em> = 0.035, SE = 0.063, <em>t</em><sub>(1,050.90)</sub> = 0.56, <em>p</em> = 0.85), nor did they interact with Motivational Context (avoidance; <em>β</em> = 0.038, SE = 0.076, <em>t</em><sub>(978)</sub> = 0.496, <em>p</em> = 0.85). Thus, although avoidance reduced active accuracy this effect was not associated with depressive symptom scores. Full model results can be found at <a href="https://osf.io/5sepm/">https://osf.io/5sepm/</a>.</p><p id="p-69">To evaluate whether observed effects were sensitive to reference level selection, we conducted an exploratory series of eight linear mixed models, systematically varying the reference levels for Sex, Task Stage, and Motivational Context. This resulted in 128 tested effects (16 per model, including main effects and interactions), and <em>p</em> values were adjusted using Benjamini–Hochberg FDR across all 128 effects. While no significant effects of BDI-II emerged in the initial model, exploratory analyses identified a significant BDI-II × Sex interaction (<em>β</em> = −0.365, SE = 0.121, <em>t</em><sub>(1,050.90)</sub> = −3.02, <em>p</em><sub>adjusted</sub> = 0.026), specifically in the avoidance context during the intermixed stage. This exploratory finding suggests the possibility that sex differences in the relationship between depressive symptoms and instrumental behavior may emerge when active responses are well-learned and inhibitory demands are newly introduced—potentially reflecting sex-specific dynamics in threat processing during later phases of learning. Full model results can be found at <a href="https://osf.io/5sepm/">https://osf.io/5sepm/</a>.</p></div><div id="sec-31"><h4>Depressive symptom scores and inhibitory response accuracy</h4><p id="p-70">A similar linear mixed model was used to examine whether depressive symptom scores (BDI-II, <em>z</em>-normalized) predicted accuracy on inhibitory trials. Fixed effects include Sex (female, male) and Motivational Context (reward-seeking, avoidance) and Participant as a random intercept. Motivational Context significantly affected inhibitory accuracy, with higher performance in the avoidance context (avoidance; <em>β</em> = 0.570, SE = 0.064, <em>t</em><sub>(326)</sub> = 8.95, <em>p</em> &lt; 0.001). However, BDI-II symptom scores were not significantly associated with inhibitory accuracy (<em>β</em> = −0.074, SE = 0.063, <em>t</em><sub>(534.47)</sub> = −1.18, <em>p</em> = 0.28), nor was there a significant interact with BDI-II and Motivational Context (avoidance; <em>β</em> = 0.030, SE = 0.065, <em>t</em><sub>(326)</sub> = 0.47, <em>p</em> = 0.64). Thus, although participants showed lower accuracy for inhibitory reward-seeking trials compared with avoidance trials, this pattern was not associated with depressive symptom severity.</p></div></div></div><div id="sec-32"><h2>Discussion</h2><p id="p-71">In this study we report that higher depressive scores are associated with a reduced capacity to learn active avoidance behaviors, while no relationship was observed with inhibitory avoidance. Specifically, Study 1 extended rodent research on active and inhibitory avoidance to a human nonclinical sample, revealing that higher depressive symptoms predicted lower accuracy during the acquisition phase of active avoidance (<a id="xref-fig-5-2" href="#F5">Fig. 5</a>) and a greater number of trials required to reach criterion performance (<a id="xref-fig-4-3" href="#F4">Fig. 4<em>B</em></a>). In contrast, depressive symptom scores were not related to performance on inhibitory avoidance trials. Additionally, within-subjects analyses indicated that overall, inhibitory avoidance was performed more readily compared with active avoidance, as indicated by higher accuracy during the intermixed and reversal stages (<a id="xref-fig-3-4" href="#F3">Fig. 3<em>B</em>,<em>C</em></a>). Altogether, these findings highlight a selective impairment in active avoidance learning associated with depressive symptoms and underscore the importance of considering how this relationship may vary across different learning phases. This dynamic pattern warrants further investigation into the underlying cognitive and neural processes that constrain avoidance behavior in depression.</p><p id="p-72">Our findings in Study 1 partially support the predictions of the ACDM framework, which posit that depression is associated with a greater tendency toward inaction in avoidance contexts (<a id="xref-ref-9-4" href="#ref-9">Bishop and Gagne, 2018</a>). Using this framework, the decision to act is calculated as the difference between the product of estimated outcome value and probability and the estimated cost of deploying effort to obtain a desired outcome. In depression, inaction may arise from overestimating effort costs, undervaluing outcomes, or underestimating outcome probability. Notably, because our task used a deterministic reinforcement schedule, outcome uncertainty is unlikely to account for the observed deficit. If overestimation of effort costs were solely responsible for these deficits, one would expect consistent active avoidance impairments across all task stages. However, since effort demands remained constant (i.e., the number of button presses required to obtain the desired outcome) and inaction was most pronounced during the acquisition phase—when fatigue-related effort costs were likely minimal—alternative explanations must be considered. Another possibility is that individuals with elevated levels of depressive symptoms became increasingly sensitive to the aversive outcome over time—effectively overvaluing the punishment and potentially overriding initial biases against deploying effort. Consistent with this interpretation, several studies have demonstrated that individuals with depression show increased sensitivity to negative feedback (<a id="xref-ref-23-1" href="#ref-23">Elliott et al., 1997</a>; <a id="xref-ref-25-1" href="#ref-25">Eshel and Roiser, 2010</a>), particularly in probabilistic reversal learning tasks, where they are more likely to switch following misleading negative feedback (<a id="xref-ref-50-2" href="#ref-50">Murphy et al., 2003</a>; <a id="xref-ref-67-1" href="#ref-67">Taylor Tavares et al., 2008</a>). However, other work suggests that the negativity bias in depression may not reflect punishment hypersensitivity per se, but rather blunted responsiveness to reward, resulting in a relative overweighting of negative outcomes (<a id="xref-ref-60-3" href="#ref-60">Robinson et al., 2012</a>). Still other studies have reported reduced sensitivity to both reward and punishment in depressed individuals (<a id="xref-ref-49-5" href="#ref-49">Mukherjee et al., 2020</a>). This heterogeneity likely reflects differences in task structure (i.e., deterministic vs probabilistic reinforcement), cognitive control demands (i.e., attending to and memorizing cue–response associations), and sample characteristics such as comorbid anxiety, sex, IQ, and medication status. Regardless, our findings suggest that the relationship between depressive symptoms and active avoidance is dynamic, with experience-dependent shifts across phases of avoidance.</p><p id="p-73">Clarifying how the neural circuits regulating active avoidance are dynamically engaged over time may offer critical insight into motivational dysfunction in depression. Evidence from both human and animal studies highlights the role of species-specific defensive reactions (SSDRs), where freezing is a prepotent response in aversive contexts (<a id="xref-ref-10-2" href="#ref-10">Bolles, 1970</a>; <a id="xref-ref-27-1" href="#ref-27">Fanselow, 1994</a>; <a id="xref-ref-43-1" href="#ref-43">LeDoux et al., 2017</a>). For successful active avoidance, both humans and rodents must overcome these prepotent defensive responses to engage in instrumental, goal-directed action. From a neural circuitry perspective, considerable progress has been made in understanding the mechanisms underlying the acquisition of active avoidance (<a id="xref-ref-43-2" href="#ref-43">LeDoux et al., 2017</a>; <a id="xref-ref-12-1" href="#ref-12">Cain, 2019</a>). Early in avoidance training, SSDRs are largely driven by amygdala circuits that promote behavioral suppression. With repeated training, however, ventromedial prefrontal systems (homologs of infralimbic cortex, Area 25 of anterior cingulate) increasingly suppress amygdala activity to reduce freezing and facilitate goal-directed avoidance responses (<a id="xref-ref-48-1" href="#ref-48">Moscarello and LeDoux, 2013</a>). These dynamics suggest that individuals with elevated depressive symptoms may exhibit difficulty in suppressing prepotent defensive responses during early learning—potentially due to dysfunction in cortico-limbic-striatal circuits that support the shift from reactive to goal-directed control. This provides a plausible neurobiological mechanism for the symptom-related impairments in active avoidance observed during the acquisition phase, while performance at later stages remains unaffected.</p><p id="p-74">Moving to research in humans, the dual competition model (<a id="xref-ref-56-2" href="#ref-56">Pessoa, 2009</a>) proposes the effects of emotionally salient stimuli on task performance depends both on the level of arousal evoked by a stimulus and on whether the stimulus aligns with or opposes the action tendency evoked by the stimulus. Prepotent behavioral responses to avoid punishment and approach reward, mediated in part by prefrontal regions, have been reliably observed in human neuroimaging studies (<a id="xref-ref-32-1" href="#ref-32">Guitart-Masip et al., 2012</a>; <a id="xref-ref-1-1" href="#ref-1">Asci et al., 2019</a>). In depression, disruptions in top-down regulatory control have been linked to reduced activity in dorsolateral and dorsomedial prefrontal cortex (dlPFC, dmPFC) and rostral ACC (rACC), along with elevated and sustained amygdala activity in response to negative feedback or emotional salient stimuli (<a id="xref-ref-63-1" href="#ref-63">Siegle et al., 2007</a>; <a id="xref-ref-26-2" href="#ref-26">Fales et al., 2008</a>; <a id="xref-ref-67-2" href="#ref-67">Taylor Tavares et al., 2008</a>). This pattern may indicate that emotionally salient cues disproportionately influence behavior due to weakened regulatory input from cognitive control systems. As a result, the capacity to override prepotent defensive responses—particularly during early stages of active avoidance learning—may be compromised in depression. Recent work further supports this interpretation, showing that reductions in GABA within the rACC were associated with decreased functional connectivity across cortico-striatal-limbic circuits in females with MDD (<a id="xref-ref-38-1" href="#ref-38">Ironside et al., 2021</a>)—a finding especially relevant given our predominantly female sample.</p><div id="sec-33"><h3>Avoidance mechanisms in depression and related disorders</h3><p id="p-75">To contextualize our findings, it is important to position them within the broader literature on avoidance across psychiatric disorders, highlighting key conceptual differences and points of convergence. For instance, many studies define avoidance as the decreased selection of high-loss options in probabilistic selection tasks—a definition that differs meaningfully from the framework used here but useful for understanding sensitivity to reward and negative feedback. <a id="xref-ref-16-4" href="#ref-16">Chase et al. (2010)</a> used a probabilistic selection task to examine feedback learning in individuals with MDD and found reduced learning rates for both positive and negative feedback during training, particularly among individuals with higher anhedonia. This suggests blunted reinforcement learning rather than a valence-specific bias such as altered sensitivity to negative feedback. Nonetheless, this profile is consistent with our observed impairment in active avoidance acquisition, despite differences in task design.</p><p id="p-76"><a id="xref-ref-49-6" href="#ref-49">Mukherjee et al. (2020)</a> extended this work using probabilistic reversal learning and found that MDD patients—most of whom were medicated—selected fewer rich options following reversals and exhibited reduced win-stay behavior (i.e., less likely to repeat a rewarded choice), but no difference in lose-shift behavior (i.e., switching after punishment). If depression involved heightened punishment sensitivity, an increase in lose-shift behavior would be expected. The absence of this effect supports the idea of diminished reward sensitivity rather than increased responsiveness to punishment. This interpretation aligns with the possibility that symptom-related impairments in active avoidance reflect deficits in safety learning rather than heightened punishment sensitivity that interacts with effort-related biases. Safety learning—the process of learning about cues that predict the absence of threat (<a id="xref-ref-42-1" href="#ref-42">Laing et al., 2025</a>)—has been shown to promote instrumental avoidance learning in animals and humans (<a id="xref-ref-28-1" href="#ref-28">Fernando et al., 2014</a>; <a id="xref-ref-29-1" href="#ref-29">Fisher and Urcelay, 2024</a>). Impaired learning of safety signals may contribute to reduced active avoidance performance, even in aversively motivated contexts. Given that safety learning is supported by amygdala and vmPFC circuitry (<a id="xref-ref-40-1" href="#ref-40">Kong et al., 2014</a>), this may offer a more parsimonious explanation for acquisition-specific effects than models emphasizing the accumulation of punishment sensitivity and effort-related bias.</p><p id="p-77">Neuromodulator systems may further complicate interpretation, as both serotonin and dopamine are implicated in punishment and reward learning. SSRIs, commonly prescribed in MDD, are known to blunt negative feedback sensitivity (<a id="xref-ref-35-1" href="#ref-35">Herzallah et al., 2013</a>). Supporting this, low doses of the antidepressant citalopram—which attenuate serotonin signaling—increase lose-shift behavior and sensitivity to punishment in both rodents and humans (<a id="xref-ref-15-1" href="#ref-15">Chamberlain et al., 2006</a>; <a id="xref-ref-3-1" href="#ref-3">Bari et al., 2010</a>). However, findings from obsessive compulsive disorder (OCD) populations highlight more nuanced effects of serotonergic modulation: <a id="xref-ref-24-2" href="#ref-24">Endrass et al. (2011)</a> found greater sensitivity to negative feedback in medicated OCD patients with elevated depressive symptoms, but only after initial learning—consistent with the idea that punishment sensitivity may build with experience. In contrast, <a id="xref-ref-54-2" href="#ref-54">Palminteri et al. (2012)</a> reported no valence-specific effects of medication status in OCD patients using a task previously linking dopamine to punishment learning (<a id="xref-ref-53-1" href="#ref-53">Palminteri et al., 2009</a>).</p><p id="p-78">Motivational impairments similar to those in depression are also evident in schizophrenia, particularly in relation to altered dopamine signaling. In unmedicated patients, <a id="xref-ref-59-2" href="#ref-59">Reinen et al. (2016)</a> found blunted prediction error BOLD signals in the striatum and mPFC for rewards, but intact response to punishment, suggesting D2 tone may selectively dampen reward while keeping punishment signaling intact. Similarly, <a id="xref-ref-72-2" href="#ref-72">Waltz et al. (2018)</a> reported reduced differential activation to gain versus loss-avoidance in vmPFC, ACC, and ventral striatum (VS), with diminished activation in VS associated with higher negative symptom scores. Sex differences in dopaminergic responses to loss versus gain have also been observed. Using PET during the monetary incentive delay task, <a id="xref-ref-33-1" href="#ref-33">Hahn et al. (2021)</a> found females exhibited heightened VS dopaminergic responses to punishment relative to gain. Together, these findings suggest that disrupted valuation and motivational processes, linked to both dopamine and serotonin signaling, may reflect cortico-striatal-limbic dysfunction as a transdiagnostic mechanism across conditions like OCD, schizophrenia, and depression.</p><p id="p-79">Overall, these studies underscore the dynamic nature of avoidance, which may shift with experience (i.e., acquisition, expression, habit) and neuromodulatory state. If punishment sensitivity increases with experience, it may eventually override early inaction driven by effort-related biases. Alternatively, if deficits are more prominent for reward-related signals, disrupted safety learning may play a greater role. Future computational modeling that integrates effort costs, punishment and reward sensitivity, and safety learning mechanisms will be critical for disentangling these processes and clarifying how depressive symptoms influence active avoidance behavior.</p></div><div id="sec-34"><h3>Motivational context influences accuracy of instrumental actions</h3><p id="p-80">Study 2 examined whether poorer active avoidance performance reflect a general bias toward effort minimization or context-specific effects by assessing active and inhibitory responses across both reward-seeking and avoidance contexts. While depressive symptom scores were not significantly related to performance, robust within-subjects effects emerged. Participants performed more accurately on trials aligned with their prepotent tendencies—active reward-seeking and inhibitory avoidance—consistent with prior research demonstrating approach biases for reward and withdrawal biases for punishment (<a id="xref-ref-18-1" href="#ref-18">Crockett et al., 2009</a>; <a id="xref-ref-32-2" href="#ref-32">Guitart-Masip et al., 2012</a>; <a id="xref-ref-46-3" href="#ref-46">Mkrtchian et al., 2017</a>; <a id="xref-ref-1-2" href="#ref-1">Asci et al., 2019</a>).</p><p id="p-81">Prefrontal regions such as the anterior prefrontal cortex (aPFC) and orbitofrontal (OFC) are implicated in overcoming these motivational-action conflicts (<a id="xref-ref-61-1" href="#ref-61">Roelofs et al., 2009</a>; <a id="xref-ref-71-1" href="#ref-71">Volman et al., 2011</a>). If the poorer performance for active versus inhibitory avoidance observed in Study 1 were driven by a general preference to minimize effort, we would expect a similar pattern for active reward-seeking in Study 2. However, this pattern did not emerge, suggesting that effort bias alone does not account for these findings.</p><p id="p-82">Parallel findings in humans and animals suggest that newly learned discriminative cues can differentially influence instrumental behavior depending on whether the context is appetitive or aversive (<a id="xref-ref-66-1" href="#ref-66">Talmi et al., 2008</a>; <a id="xref-ref-31-1" href="#ref-31">Geurts et al., 2013</a>; <a id="xref-ref-46-4" href="#ref-46">Mkrtchian et al., 2017</a>; <a id="xref-ref-51-2" href="#ref-51">Nord et al., 2018</a>; <a id="xref-ref-13-1" href="#ref-13">Campese, 2021</a>). Consistent with this, participants in the current study more readily inhibited responses in avoidance context than in reward-seeking contexts. Remarkably, rats display similar patterns, with greater accuracy for active responses during reward seeking and greater inhibitory accuracy during avoidance (<a id="xref-ref-19-1" href="#ref-19">Dalton et al., 2025</a>).</p><p id="p-83">Although these performance differences could be attributed to differences in the motivational value of the reward and the punishment outcomes, this explanation is unlikely. No significant main effect of motivational context was found during the intermixed task stage. Specifically, the average accuracy for reward-seeking and avoidance trials (irrespective of response type) did not differ. This suggests that the outcomes were equally motivating overall and not biased toward one context. Instead, the observed interaction is more consistent with the context-dependent effect of prepotent response tendencies influencing instrumental actions.</p><p id="p-84">While depression is typically associated with reduced reward-seeking, the ACDM framework predicts a broader bias toward inaction across both reward-seeking and avoidance contexts, driven by overestimation of effort costs. In Study 1, higher depressive symptom scores were associated with reduced active avoidance performance—consistent with this framework. However, contrary to our hypotheses, depressive symptoms were not significantly associated with active or inhibitory response accuracy in either motivational context.</p><p id="p-85">Several key differences may account for these null findings. First, the mixed-motivation task employed an interleaved design, requiring participants to frequently switch between responding to appetitive and aversive stimuli, rather than engaging with each in distinct blocks. This design placed avoidance trials within a broader reward-rich context, attenuating depression-related impairments in active avoidance—potentially due to the prepotent tendency to approach reward. This interpretation aligns with findings from approach-avoidance conflict paradigms—where conditions involving potential reward despite the risk of punishment are more likely to elicit active approach behavior than avoidance-only conditions (<a id="xref-ref-2-1" href="#ref-2">Aupperle et al., 2011</a>). Second, the four-condition task structure (active vs inhibitory and reward-seeking vs avoidance) likely imposed greater working memory demands, which have been implicated in reward/punishment learning (<a id="xref-ref-70-1" href="#ref-70">Van Der Schaaf et al., 2014</a>). These cognitive demands may have masked the influence of depressive symptoms on performance. Future studies may consider controlling for cognitive load to better isolate symptom-specific effects. Finally, Study 1 took place during the height of the COVID-19 pandemic, a contextual factor that may have influenced affective states and task engagement in ways that were not present during Study 2.</p><p id="p-86">Although no association between depressive symptoms were found in Study 2, the robust within-subjects effects suggest this task may be useful for assessing motivated behavior in other psychiatric populations. For example, research on substance use disorder emphasizes the strong motivational salience of reward and punishment related cues, particularly those associated with drug use.</p></div><div id="sec-35"><h3>Conclusion</h3><p id="p-87">Although depression is often linked with reward-processing deficits like anhedonia (<a id="xref-ref-68-1" href="#ref-68">Treadway and Zald, 2011</a>; <a id="xref-ref-69-2" href="#ref-69">Treadway et al., 2012</a>), our findings reveal a novel link between symptom severity and impaired active avoidance learning in aversive contexts. A key limitation is whether these results generalize to clinical populations. Depression is increasingly understood as a dimensional condition, with clinical diagnoses reflecting the more severe end of a broader symptom spectrum and avoidance impairments representing a potential transdiagnostic feature (<a id="xref-ref-22-1" href="#ref-22">Eaton et al., 2023</a>). Our sample included a wide range of depressive symptom scores, with many participants self-reporting prior diagnoses or scoring above clinical cutoffs, supporting the relevance of our findings to clinical populations. Furthermore, this dimensional approach may offer a more nuanced understanding of symptom-related effects on avoidance behavior and extend to other psychiatric conditions, such as OCD and schizophrenia, that share overlapping motivational and affective features with depression.</p><p id="p-88">Another limitation of our study was the higher than expected exclusion rates, which warrant a closer examination of their potential impact on results. Both tasks were designed as reinforcement-based learning paradigms with minimal instructions, no explicit information on cue–response contingencies, and no practice trials. While this design enhances translational relevance, it likely contributed to the variability in participants’ ability to acquire the task contingencies. Although higher exclusion rates were anticipated, the rates observed—39.37% in Study 1 and 57.20% in Study 2—exceeded expectations and were primarily due to failure to meet behavioral performance criteria. However, when considering only exclusions related to questionnaire failures or task noncompletion, rates were consistent with typical online studies (Study 1: 19.17%, Study 2: 19.20%; <a id="xref-ref-65-1" href="#ref-65">Suzuki et al., 2021</a>). To assess potential bias, we compared included participants to those who passed attention checks but were later excluded for other reasons (see <a href="https://osf.io/5sepm/">https://osf.io/5sepm/</a>). In Study 1, excluded participants had significantly higher BAI scores, but not BDI-II scores. While the ACDM framework does not explicitly make predictions about how depressive and anxiety symptoms interact, it implies that their effects may counterbalance one another. In the context of our study, anxiety symptoms could offset the depressive impairments in active avoidance by promoting increased avoidance effort. This antagonistic dynamic suggests that higher exclusion rates may have reduced confounding influences rather than introduce bias. Importantly, BDI-II scores did not differ between included and excluded groups, preserving the validity of our primary analyses. Sex differences in exclusion rates were also observed, with a higher proportion of females excluded. However, both final samples remained predominantly female—the group in which we observed our strongest effects—suggesting any bias would likely underestimate, rather than inflate our findings. For these reasons, we believe the interpretation and relevance of our findings are still valid. However, future adaptations of this task may benefit from optimizing the trade-off between ecological validity and participant retention.</p><p id="p-89">Across two studies, we sought to extend rodent research to investigate patterns of active and inhibitory avoidance and reward-seeking in a nonclinical sample varying in depressive symptoms. By integrating self-report and behavioral measures, we aimed to strengthen translational links between preclinical models and depressive symptom severity in humans. Our findings highlight the value of transdiagnostic approaches in a community sample for bridging bench and clinic in understanding psychiatric disorders. Results demonstrate an important link between depressive symptoms and reduced efficacy at learning to override a prepotent response to inhibit action to avoid unpleasant events. Future work should test whether these effects replicate in clinically diagnosed MDD populations, use computational models to probe underlying mechanisms, and apply neuroimaging to evaluate cross-species convergence in neural circuitry.</p></div></div><div id="fn-group-1"><h2>Footnotes</h2><ul><li id="fn-1"><p id="p-1">The authors declare no competing financial interests.</p></li><li id="fn-3"><p id="p-3">We thank Veronica Dudarev for her advice on statistical analysis, as well as the contributions of Imogen Daly for creation and recording sound stimuli, and Karen Ip. 
This work was supported by the Natural Sciences and Engineering Research Council of Canada (NSERC) grant (#F19-05182) to R.M.T., the UBC Djavad Mowafaghian Centre for Brain Health Innovation Fund Kickstart Research Grant (#F19-05932), the Michael Smith Foundation for Health Research Scholar Award to R.M.T., and an NSERC Postgraduate Scholarship – Doctoral (PGS-D) award to R.J.T.</p></li></ul></div><p id="p-4">This is an open-access article distributed under the terms of the <a href="https://creativecommons.org/licenses/by/4.0/" rel="license">Creative Commons Attribution 4.0 International license</a>, which permits unrestricted use, distribution and reproduction in any medium provided that the original work is properly attributed.</p><div id="sec-36"><h2>Synthesis</h2><div id="boxed-text-1"><p id="p-90">Reviewing Editor: Ifat Levy, Yale School of Medicine</p><p id="p-91">Decisions are customarily a result of the Reviewing Editor and the peer reviewers coming together and discussing their recommendations until a consensus is reached. When revisions are invited, a fact-based synthesis statement explaining their decision and outlining what is needed to prepare a revision will be listed below. The following reviewer(s) agreed to reveal their identity: Ziv Ben-Zion.</p></div><p id="p-92">The present study examined the relationship between depressive symptoms and active/inhibitory avoidance behavior in general populations. The authors demonstrated that depressive symptoms (BDI-II scores) are negatively associated with the accuracy of active avoidance in the avoidance Go/NoGo task, particularly among younger participants. This relationship did not emerge in the mixed version of the task (i.e., a combination of reward-seeking and avoidance). Given these findings, the authors argue that their work may help bridge the gap between preclinical animal research and clinical studies.</p><p id="p-93">This is an interesting paper, which may provide new insights into the relationship between depressive symptoms and avoidance learning using a reverse-translated avoidance task from rodent models. Reviewers identified, however, unclear aspects of the conceptual framework, as well as the methods and results, which should be addressed.</p><p id="p-94">- The authors should provide more background, to position their study in the context of prior research. They should be clear on whether and how the work is conceptually novel. If this is a replication, this is totally fine, but should be explicitly said.</p><p id="p-95">- The authors should discuss earlier research on psychiatric symptoms and avoidance behavior using simple decision-making tasks applicable to rodent models (for example: https://pubmed.ncbi.nlm.nih.gov/22420038/; https://pubmed.ncbi.nlm.nih.gov/19607754/; https://pubmed.ncbi.nlm.nih.gov/33001663/; https://pubmed.ncbi.nlm.nih.gov/22325972/; https://pubmed.ncbi.nlm.nih.gov/21284070/; https://pubmed.ncbi.nlm.nih.gov/28343697/; https://pubmed.ncbi.nlm.nih.gov/29486865/; https://pubmed.ncbi.nlm.nih.gov/27105903/; and https://pubmed.ncbi.nlm.nih.gov/34151477/).</p><p id="p-96">The authors should explain how their findings relate to these previous studies.</p><p id="p-97">- The authors describe the brain regions identified in animal research as related to active and inhibitory avoidance. However, it is unclear how these findings translate to humans. The statement that "Neural activation of these regions is found in humans performing avoidance tasks" is too general-are distinct brain regions implicated in active vs. inhibitory avoidance in humans? Similarly, the claim that "depression has been linked to structural or atypical patterns of activation in homologous brain regions in humans" lacks specificity. Could the authors provide more precise evidence from human neuroimaging studies to clarify these points?</p><p id="p-98">- The authors clearly articulate their research objective and hypothesis, but some aspects could be clarified. First, why was a non-clinical sample chosen instead of a clinical one? How might this impact the generalizability of findings to clinical depression? Second, the hypothesis states that depressive symptoms will impair active avoidance, but do the authors expect a similar or different effect for inhibitory avoidance? Clarifying these points would strengthen the rationale for the study.</p><p id="p-99">- The authors conducted numerous statistical tests as part of their main analyses. For instance, according to the description in lines 269-274, the main findings involved the effects of BDI-II and the interaction of Sex and Sample on active and inhibitory avoidance accuracies, amounting to more than 20 tests. This raises a concern about the robustness of the results - p-values should be properly corrected for multiple comparisons.</p><p id="p-100">- In the mixed-effect models, why was Age omitted (i.e., replaced by Sample)? Ideally, a single model would include all relevant variables. Furthermore, it is unclear why the authors included only a random intercept rather than also considering random slopes (e.g., for task stages), which could vary across participants. Were the variables in these models z-normalized?</p><p id="p-101">- The negative association between BDI-II scores and active avoidance accuracy emerged in the avoidance task but not in the mixed task. Could the authors speculate about the meaning of this discrepancy? Does it suggest that the relationship is highly context-dependent?</p><p id="p-102">- In Study 1, 302 of 767 participants were excluded, and in Study 2, 439 of 769 were excluded. Such high exclusion rates - over half of each sample - are unusual. Even in online experiments on crowdsourcing services, the exclusion rate typically does not exceed 30%. It would be informative to detail what attention checks were employed and how many participants failed each criterion. This issue also warrants discussion in the Discussion section.</p><p id="p-103">- Do the authors have any data regarding participants' general intelligence (e.g., educational background or IQ)? Differences between undergraduate and online participants may be attributable to such factors.</p><p id="p-104">- Mental disorders frequently co-occur - in particular, depression often co-occurs with anxiety. Thus, it is possible that the BDI-II scores were influenced by symptoms other than depression. Commenting on this possibility, and on how the ACDM framework handles this would be helpful.</p><p id="p-105">- Was the aversive sound truly aversive? Is there any data to support this claim?</p><p id="p-106">- please provide more detail on the effort and volume calibration procedures.</p><p id="p-107">- The methods and results sections are very long. Please try to streamline descriptions of procedures, statistical methods, and secondary analyses where possible.</p></div></div> <!-- /.panel-row-wrapper -->	
	
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tinycolor supply chain attack post-mortem (161 pts)]]></title>
            <link>https://sigh.dev/posts/ctrl-tinycolor-post-mortem/</link>
            <guid>45278657</guid>
            <pubDate>Wed, 17 Sep 2025 17:18:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sigh.dev/posts/ctrl-tinycolor-post-mortem/">https://sigh.dev/posts/ctrl-tinycolor-post-mortem/</a>, See on <a href="https://news.ycombinator.com/item?id=45278657">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <h2 id="tldr"><a href="#tldr">TL;DR</a></h2>
<p>A malicious GitHub Actions workflow was pushed to a shared repo and exfiltrated a npm token with broad publish rights. The attacker then used that token to publish malicious versions of 20 packages, including <code>@ctrl/tinycolor</code>.</p>
<p>My GitHub account, the @ctrl/tinycolor repository were not directly compromised. There was no phishing involved, and no malicious packages were installed on my machine and I already use pnpm to avoid unapproved postinstall scripts. There was no pull request involved because a repo admin does not need a pull request to add new github actions.</p>
<p>GitHub/npm security responded quickly, unpublishing the malicious versions. I followed by releasing clean versions to flush caches, as advised.</p>
<p>For broader context, see <a href="https://socket.dev/blog/tinycolor-supply-chain-attack-affects-40-packages" rel="noreferrer noopener" target="_blank">Socket’s write-up</a> or <a href="https://www.stepsecurity.io/blog/ctrl-tinycolor-and-40-npm-packages-compromised" rel="noreferrer noopener" target="_blank">StepSecurity’s analysis</a>. For community discussion, see this <a href="https://news.ycombinator.com/item?id=45260741" rel="noreferrer noopener" target="_blank">Hacker News post</a>, which spent 24 hours on the front page. I’m also finding this <a href="https://www.wiz.io/blog/shai-hulud-npm-supply-chain-attack" rel="noreferrer noopener" target="_blank">wiz.io</a> post helpful.</p>
<h2 id="how-i-found-out"><a href="#how-i-found-out">How I Found Out</a></h2>
<p>On September 15 around 4:30
 PM PT, <a href="https://bsky.app/profile/notwes.bsky.social" rel="noreferrer noopener" target="_blank">Wes Todd</a> DM’d me on Bluesky and looped me into the OpenJS Foundation Slack. By that point, Wes had already alerted GitHub/npm security, who were compiling lists of affected packages and rapidly unpublishing compromised versions.</p>
<p>Early guidance (attributed to Daniel Pereira) was to look for suspicious <code>Shai-Hulud</code> repos or branches. I wasn’t able to find any of these repos or branches on my own personal repos. The mystery was: how was I impacted at all?</p>
<blockquote>
<p>Shai-Hulud was the Fremen term for the sandworm of Arrakis. - <a href="https://dune.fandom.com/wiki/Shai-Hulud" rel="noreferrer noopener" target="_blank">dune wiki</a></p>
</blockquote>
<h2 id="what-actually-happened"><a href="#what-actually-happened">What Actually Happened</a></h2>
<p>A while ago, I collaborated on <a href="https://github.com/angulartics/angulartics2" rel="noreferrer noopener" target="_blank">angulartics2</a>, a shared repository where multiple people still had admin rights. That repo still contained a GitHub Actions secret — a npm token with broad publish rights. This collaborator had access to projects with other people which I believe explains some of the other 40 initial packages that were affected.</p>
<p>A new Shai-Hulud branch was force pushed to angulartics2 with a malicious github action workflow by a collaborator. The workflow ran immediately on push (did not need review since the collaborator is an admin) and stole the npm token. With the stolen token, the attacker published malicious versions of 20 packages. Many of which are not widely used, however the @ctrl/tinycolor package is downloaded about 2 million times a week.</p>
<p>GitHub and npm security teams moved quickly to unpublish the malicious versions. I then re-published fresh, verified versions of the packages I maintain to flush caches and restore trust.</p>
<h2 id="impact"><a href="#impact">Impact</a></h2>
<p>Malicious versions of several packages — including @ctrl/tinycolor — were briefly available on npm before removal. Installing those compromised versions would have triggered a postinstall payload, which is documented in detail by <a href="https://www.stepsecurity.io/blog/ctrl-tinycolor-and-40-npm-packages-compromised#attack-mechanism" rel="noreferrer noopener" target="_blank">StepSecurity</a>.</p>
<p>What should you do if you’ve installed a compromised version of a package? <a href="https://www.stepsecurity.io/blog/ctrl-tinycolor-and-40-npm-packages-compromised#immediate-actions-required" rel="noreferrer noopener" target="_blank">see StepSecurity’s immediate actions</a>.</p>
<h2 id="publishing-setup--interim-plan"><a href="#publishing-setup--interim-plan">Publishing Setup &amp; Interim Plan</a></h2>
<p>I currently use <a href="https://github.com/semantic-release/semantic-release" rel="noreferrer noopener" target="_blank">semantic-release</a> with GitHub Actions to handle publishing. The automation is convenient and predictable. I also have npm provenance enabled on many packages, which provides attestations of how they were built. Unfortunately, provenance didn’t prevent this attack because the attacker had a valid token.</p>
<p>My goal is to move to npm’s <strong>Trusted Publishing (OIDC)</strong> to eliminate static tokens altogether. However, semantic-release integration is still in progress: <a href="https://github.com/npm/cli/issues/8525" rel="noreferrer noopener" target="_blank">npm/cli#8525</a>.</p>
<p><img alt="npm Publishing access settings" loading="lazy" decoding="async" fetchpriority="auto" sizes="(min-width: 1618px) 1618px, 100vw" data-astro-image="constrained" width="1618" height="804" src="https://sigh.dev/_astro/publishing-access.DTmYbTkJ_Z2may3Q.webp" srcset="https://sigh.dev/_astro/publishing-access.DTmYbTkJ_1Fa49o.webp 640w, https://sigh.dev/_astro/publishing-access.DTmYbTkJ_Z22BseH.webp 750w, https://sigh.dev/_astro/publishing-access.DTmYbTkJ_Z27AVbY.webp 828w, https://sigh.dev/_astro/publishing-access.DTmYbTkJ_ZGtYiM.webp 1080w, https://sigh.dev/_astro/publishing-access.DTmYbTkJ_Z11X4ph.webp 1280w, https://sigh.dev/_astro/publishing-access.DTmYbTkJ_Z2may3Q.webp 1618w"></p><p>For the forseeable future, @ctrl/tinycolor requires 2FA for publishing, and all tokens have been revoked. Not expecting to merge any new changes anytime soon.</p>
<p>For smaller packages, I’ll continue using semantic-release but under stricter controls: no new contributors will be added, and each repo will use a granular npm token limited to publish-only rights for that specific package.</p>
<p>Local 2FA based publishing isn’t sustainable, so I’m watching OIDC/Trusted Publishing closely and will adopt it as soon as it fits the workflow.</p>
<p>I plan to continue using pnpm that prevents unapproved postinstall scripts from being run and I’ll look into adding pnpm’s new <a href="https://pnpm.io/settings#minimumreleaseage" rel="noreferrer noopener" target="_blank">minimumReleaseAge</a> setting.</p>
<h2 id="publishing-wishlist"><a href="#publishing-wishlist">Publishing Wishlist</a></h2>
<p>If I could wave a magic wand and design my ideal setup, npm would allow me to require Trusted Publishing (OIDC) with a single toggle for all of my packages. That same toggle would block any release missing provenance, enforcing security at the account level. I’d also want first-class semantic-release support with OIDC and provenance so no static tokens are ever needed.</p>
<p>On top of that, I’d like a secure, human-approved publishing option directly in the GitHub UI: a protected workflow_dispatch flow that uses github 2FA approval to satisfy 2FA, without requiring me to publish from my laptop.</p>
<p>GitHub Environments — or equivalent workflow protections — should be available without a Pro subscription, or else integrated directly into Trusted Publishing so that security doesn’t depend on the pricing tier.</p>
<p>It would be really nice if NPM also had a more visible mark on the package details page to indicate if the package had a postinstall script. Also, once the packages are pulled its not clear what versions were removed and why.</p>
<h2 id="thanks"><a href="#thanks">Thanks</a></h2>
<p>Thanks to Wes Todd, the OpenJS Foundation, and the GitHub/npm security teams for their rapid and coordinated response. Everyone was incredibly fast, helpful, and knowledgeable.</p>
<p><img alt="dune worm [wide] | dune worm via chatgpt" loading="lazy" decoding="async" fetchpriority="auto" sizes="(min-width: 1536px) 1536px, 100vw" data-astro-image="constrained" width="1536" height="1024" src="https://sigh.dev/_astro/dune-worm.QN2JLFkT_ZOy594.webp" srcset="https://sigh.dev/_astro/dune-worm.QN2JLFkT_ZWljFi.webp 640w, https://sigh.dev/_astro/dune-worm.QN2JLFkT_Z24bQ0U.webp 750w, https://sigh.dev/_astro/dune-worm.QN2JLFkT_1CdkyI.webp 828w, https://sigh.dev/_astro/dune-worm.QN2JLFkT_1kRnJS.webp 1080w, https://sigh.dev/_astro/dune-worm.QN2JLFkT_Z1xwr04.webp 1280w, https://sigh.dev/_astro/dune-worm.QN2JLFkT_ZOy594.webp 1536w">  </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Drought in Iraq reveals tombs created 2,300 years ago (148 pts)]]></title>
            <link>https://www.smithsonianmag.com/smart-news/severe-droughts-in-iraq-reveals-dozens-of-ancient-tombs-created-2300-years-ago-180987347/</link>
            <guid>45278581</guid>
            <pubDate>Wed, 17 Sep 2025 17:12:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.smithsonianmag.com/smart-news/severe-droughts-in-iraq-reveals-dozens-of-ancient-tombs-created-2300-years-ago-180987347/">https://www.smithsonianmag.com/smart-news/severe-droughts-in-iraq-reveals-dozens-of-ancient-tombs-created-2300-years-ago-180987347/</a>, See on <a href="https://news.ycombinator.com/item?id=45278581">Hacker News</a></p>
Couldn't get https://www.smithsonianmag.com/smart-news/severe-droughts-in-iraq-reveals-dozens-of-ancient-tombs-created-2300-years-ago-180987347/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Ton Roosendaal to step down as Blender chairman and CEO (318 pts)]]></title>
            <link>https://www.cgchannel.com/2025/09/ton-roosendaal-to-step-down-as-blender-chairman-and-ceo/</link>
            <guid>45278279</guid>
            <pubDate>Wed, 17 Sep 2025 16:49:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cgchannel.com/2025/09/ton-roosendaal-to-step-down-as-blender-chairman-and-ceo/">https://www.cgchannel.com/2025/09/ton-roosendaal-to-step-down-as-blender-chairman-and-ceo/</a>, See on <a href="https://news.ycombinator.com/item?id=45278279">Hacker News</a></p>
<div id="readability-page-1" class="page"><div class="page">
			<article class="page">
			<header>
				<span>Wednesday, September 17th, 2025</span>
				Posted by Jim Thacker			</header>

			

			<main>
				
				
<p><iframe width="960" height="539" src="https://www.youtube.com/embed/JXm0-ilIknE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="" title="Keynote — Blender Conference 2025"></iframe></p>
<p><br>
Ton Roosendaal is to stop down as chairman and Blender CEO on 1 January 2026. The news was announced during today’s keynote at the annual Blender Conference.</p>
<p>Roosendaal – the <a href="https://www.blender.org/about/history/" target="_blank">original author</a> of the open-source 3D software, and its public figurehead for the past three decades – will pass on his roles to current Blender COO Francesco Siddi.</p>
<p>Roosendaal himself will move to the newly established Blender Foundation supervisory board.</p>
<p>Other new Blender Foundation board positions will also include Sergey Sharybin (Head of Development), Dalai Felinto (Head of Product) and Fiona Cohen (Head of Operations).</p>
<p>“We’ve been preparing for this since 2019,” said Roosendaal, “I am very proud to have such a wonderfully talented young team around me to bring our free and open source project into the next decade.”</p>
<p><em>We aim to update this story with a brief retrospective of Ton’s time as Blender CEO and the growth of Blender during that time, so check back for updates.</em></p>
<p><a href="https://www.blender.org/press/blender-foundation-announces-new-board-and-executive-director/" target="_blank">Read the official announcement that Ton Roosendaal is stepping down as Blender CEO</a></p>


			</main>

			
			<!-- Tags -->

			
		</article>

		
	</div></div>]]></description>
        </item>
    </channel>
</rss>