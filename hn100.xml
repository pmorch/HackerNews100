<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 19 Oct 2024 23:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Svelte 5 Released (210 pts)]]></title>
            <link>https://www.npmjs.com/package/svelte</link>
            <guid>41889674</guid>
            <pubDate>Sat, 19 Oct 2024 18:38:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npmjs.com/package/svelte">https://www.npmjs.com/package/svelte</a>, See on <a href="https://news.ycombinator.com/item?id=41889674">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div id="readme"><p><a href="https://svelte.dev/" rel="nofollow"><img src="https://camo.githubusercontent.com/859edad6e38e149fe3782b13564f3f88c64d731fbc47c3a2fe4556b34eb8f00d/68747470733a2f2f7376656c74656a732e6769746875622e696f2f6173736574732f62616e6e65722e706e67" alt="Cybernetically enhanced web apps: Svelte" data-canonical-src="https://sveltejs.github.io/assets/banner.png"></a></p>
<p><a href="https://www.npmjs.com/package/svelte" rel="nofollow"><img src="https://camo.githubusercontent.com/aa233b2ce5693c2189f6570b03a4fe9c0afdeb4ded145cb67c98e1a790297832/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f762f7376656c74652e737667" alt="npm version" data-canonical-src="https://img.shields.io/npm/v/svelte.svg"></a> <a href="https://github.com/sveltejs/svelte/blob/HEAD/packages/svelte/LICENSE.md"><img src="https://camo.githubusercontent.com/3fedb1706708c94fa3d5afa55f4021f54f2d3233d346a0ba1bc4d7995e68c692/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f6c2f7376656c74652e737667" alt="license" data-canonical-src="https://img.shields.io/npm/l/svelte.svg"></a> <a href="https://svelte.dev/chat" rel="nofollow"><img src="https://camo.githubusercontent.com/c2c90158c480032a45adcec99107f21ec25c717ce49e05fadff5a3af57d41270/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f3435373931323037373237373835353736343f6c6162656c3d63686174266c6f676f3d646973636f7264" alt="Chat" data-canonical-src="https://img.shields.io/discord/457912077277855764?label=chat&amp;logo=discord"></a></p>
<div><h2>What is Svelte?</h2></div>
<p>Svelte is a new way to build web applications. It's a compiler that takes your declarative components and converts them into efficient JavaScript that surgically updates the DOM.</p>
<p>Learn more at the <a href="https://svelte.dev/" rel="nofollow">Svelte website</a>, or stop by the <a href="https://svelte.dev/chat" rel="nofollow">Discord chatroom</a>.</p>
<div><h2>Getting started</h2></div>
<p>You can play around with Svelte in the <a href="https://learn.svelte.dev/" rel="nofollow">tutorial</a>, <a href="https://svelte.dev/examples" rel="nofollow">examples</a>, and <a href="https://svelte.dev/repl" rel="nofollow">REPL</a>.</p>
<p>When you're ready to build a full-fledge application, we recommend using <a href="https://kit.svelte.dev/" rel="nofollow">SvelteKit</a>:</p>
<div><pre>npm create svelte@latest my-app
<span>cd</span> my-app
npm install
npm run dev</pre></div>
<p>See <a href="https://kit.svelte.dev/docs" rel="nofollow">the SvelteKit documentation</a> to learn more.</p>
<div><h2>Changelog</h2></div>
<p><a href="https://github.com/sveltejs/svelte/blob/master/packages/svelte/CHANGELOG.md">The Changelog for this package is available on GitHub</a>.</p>
<div><h2>Supporting Svelte</h2></div>
<p>Svelte is an MIT-licensed open source project with its ongoing development made possible entirely by fantastic volunteers. If you'd like to support their efforts, please consider:</p>
<ul>
<li>
<a href="https://opencollective.com/svelte" rel="nofollow">Becoming a backer on Open Collective</a>.</li>
</ul>
<p>Funds donated via Open Collective will be used for compensating expenses related to Svelte's development.</p>
</div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dwarf Fortress – Boatmurdered Part #1 – Intro (2006) (108 pts)]]></title>
            <link>https://lparchive.org/Dwarf-Fortress-Boatmurdered/Introduction/</link>
            <guid>41889543</guid>
            <pubDate>Sat, 19 Oct 2024 18:19:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lparchive.org/Dwarf-Fortress-Boatmurdered/Introduction/">https://lparchive.org/Dwarf-Fortress-Boatmurdered/Introduction/</a>, See on <a href="https://news.ycombinator.com/item?id=41889543">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
	<h3><strong>Part 1:</strong> Intro by Evilslug</h3><p>
	
What follows is a succession-style Let's Play of the game Dwarf Fortress.  In it, we chronicle the rise and fall of the epic Dwarven fortress, Boatmurdered.  (Actually, it's pretty much all fall.)  Each ruler was given a single year of gametime in which to manage the fortress, then they gave the reigns over to the next player in line.  I have added the occasional editor's note to clarify things, but mostly I stay out of the way.  The madness surrounding Boatmurdered is quite apparent on its own, I feel.</p><p>

<b>Official List of Madmen...er..."Rulers".</b></p><p>

TouretteDog<br>
mariguana (aka.  megor grendel)<br>
Keyboard Fox (aka.  Furry, Kalo)<br>
Locus<br>
StarkRavingMad<br>
Bremen<br>
Sankis <br>
Astronautonomicon<br>
Unknowing<br>
Cross Quantum<br>
Major Failure<br>
Mystic Mongol<br>
Doctor Zero<br>
Guerilla Medic</p><p>

All eras of Boatmurdered history are highly noteworthy and interesting.  Things very quickly progressed from somewhat casual daily elephant deaths to retired rulers rampaging and beating people to death (while burning alive).  The heavy downward slide that would come to define Boatmurdered seems to have begun during StarkRavingMad's rule, with the utterly epic "Elephant War".  Historians seem to agree that the insanity surrounding Boatmurdered began to increase almost exponentially from that point forward.</p><p>

<b>The "WTF is Dwarf Fortress?" Crash-Course.</b></p><p>

The thread to follow generally assumes you have a tiny bit of knowledge about the game being played.  In hopes of making it an easy read for those unfamiliar, I've condensed the most important factors from the general info threads and wiki into this brief introduction.  You don't need to know a thing about the game to genuinely enjoy the playthrough, but a tiny bit of knowledge does help.  Here's the tl;dr guide, first.

</p><div><p><img src="https://lparchive.org/Dwarf-Fortress-Boatmurdered/Introduction/dwarfguide.gif" alt=""></p><p>

Left to right:  Elephant, Dwarf, Miasma Cloud (the purple cloud of stench that comes from rotting bodies).</p><p>

For a bit better outline of the game, read on.  Impatient types and those who already know Dwarf Fortress well, please skip straight to the first update.  The initial update outlines the rules by which this game was played (there aren't many, hah!).  The second update is where we generate the world and actually get the ball rolling.</p><p>

====</p><p>

<b>What kind of game is Dwarf fortress?</b></p><p>

In a nutshell, Dwarf Fortress is best described as a 2-D base building game in the theme of Dungeon Keeper.  The concept is simple, the graphics are simple; but the depth of the game is fairly awesome.  (Even more amazing when you realize it is all the product of a single man gaming company.)</p><p>

The dwarves you "control" are somewhat autonomous.  They have likes, dislikes, and needs.  While you can assign them specific duties and set basic orders, they have minds of their own and will act according to how they feel.  You can give them a job, but that doesn't always mean they'll do it right away.  Injuries to all animals and dwarves are tracked, down to internal organs and body parts.  Dwarves have moods that are affected by the things around them.  They can decide to throw a party for their friends, or they might stress out under strain and suddenly kill each other with little to no warning.  Female dwarves occasionally get pregnant and, if they are exposed to trauma (say a goblin siege); they very well might miscarry.  Sad thoughts caused by things of that nature can lead dwarves to tantrums or even suicide.</p><p>

You begin with 7 dwarves and scarce few supplies at the face of a mountain.  Your only objective is to survive the elements while building yourself as cool a fortress as you possibly can before you inevitably die.  Simple enough, yes?</p><p>

The game is displayed in a pseudo-ASCII style, which uses letters for objects in the game world, similar to Nethack.  I hear you groaning, but you'll quickly catch the hang of things.  The players provide excellent explanation of what is going on in each screenshot.  I've included a general key to some common items, below; should you find yourself needing one.</p><p>

In the following shot, a bunch of dwarves are charging off to be trampled by elephants outside the fortress.  The cliff face bisects the picture, with the outdoors on the left and the cliff interior on the right:

</p></div><div><p><img src="https://lparchive.org/Dwarf-Fortress-Boatmurdered/Introduction/chargedetail.png" alt=""></p><p>

1:  This section with the '=' symbols marks a stockpile.  It's where dwarves store various crafts, barrels (not pictured...denoted by a % with a yellow background), and food.</p><p>

2:  This symbol represents a cage for trapping creatures.  You'll see these a lot.</p><p>

3:  This is a pile of rocks which come from digging away the mountain.  You'll see them all over.  They can be crafted into all manner of useful items.</p><p>

4:  The matrix looking green crap is the ground.  On the inside, to the right of box 10, you'll see the symbols are white, instead.  Smoothed stone floors in the fort are represented by + symbols.  Some people use a variegated tileset, which results in what you see here.  Others will have ground that displays as all periods.  You eventually get used to both and can easily pick out what is where on any map.</p><p>

5:  Dwarves are shown as these guys here, or as smiley faces.  Different colors indicate different professions.  These guys are all military recruits, charging off stupidly to their deaths.</p><p>

6:  The E is an elephant.  They murder dwarves in wonderful fashion.  Get used to them.  Above and below him, the brackets are discarded armor or clothing.  The grey blocks to his right represent exposed walls of un-mined rock.  The blocks with the cross on them represent stone doors.  The small 2's that fill the room behind the two doors are the bones of animals or dwarves.</p><p>

7:  The ^ symbol denotes a trap.  The parallel lines below the traps represent a smoothed wall.  Below these lines, you see the grey wall of the bone room, which is not smoothed.  Different colored symbols in grey rock walls just represent types of exposed mineral, gems, or ore veins.</p><p>

8:  This is a pile of dead dwarves, an Elephant, and a cloud of Miasma.  Those are the three most prevalent features in Boatmurdered.  Miasma is the purple blotch that shows up when corpses begin to rot.  It makes your dwarves angry, which usually leads to hilarity.</p><p>

9:  The two green asterisks are gems.  These have been mined out of a wall, already; and are awaiting storage.</p><p>

10:  These are siege engines.  In this case, two ballistas aimed at the hallway with all the dead dwarves.</p><p>

11:  The black spaces with symbols like these are areas of the mountain that have yet to be mined.</p><p>

In other images, you'll often see a yellow X somewhere and a command list on the right side of the screen.  The text on that screen generally refers to whatever is under the yellow X to its left.</p><p>

====</p><p>

If you need further details, you can find them here:</p><p>

Quick links<br>
<a href="http://www.bay12games.com/dwarves/" target="_blank" rel="nofollow">http://www.bay12games.com/dwarves/</a> - official site</p><p>

<a href="http://dwarf.lendemaindeveille.com/index.php/Main_Page" target="_blank" rel="nofollow">http://dwarf.lendemaindeveille.com/index.php/Main_Page</a> - wiki (tutorials here)</p><p>

<a href="http://forums.somethingawful.com/showthread.php?s=&amp;threadid=2377482" target="_blank" rel="nofollow">SA Dwarf Fortress Megathread</a> - the big DF Q&amp;A thread in Games.</p><p>

The shots in the thread are generally pretty self-explanatory, so get to the thread and enjoy.  And by the way...In the words of the great ruler, StarkRavingMad:</p><p>

<b>Welcome to fucking Boatmurdered!</b></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI engineers claim new algorithm reduces AI power consumption by 95% (129 pts)]]></title>
            <link>https://www.tomshardware.com/tech-industry/artificial-intelligence/ai-engineers-build-new-algorithm-for-ai-processing-replace-complex-floating-point-multiplication-with-integer-addition</link>
            <guid>41889414</guid>
            <pubDate>Sat, 19 Oct 2024 18:03:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/tech-industry/artificial-intelligence/ai-engineers-build-new-algorithm-for-ai-processing-replace-complex-floating-point-multiplication-with-integer-addition">https://www.tomshardware.com/tech-industry/artificial-intelligence/ai-engineers-build-new-algorithm-for-ai-processing-replace-complex-floating-point-multiplication-with-integer-addition</a>, See on <a href="https://news.ycombinator.com/item?id=41889414">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">

<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-1920-80.jpg.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-320-80.jpg" alt="addition sign floating on hand" srcset="https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi.jpg" data-pin-nopin="true" fetchpriority="high" crossorigin="anonymous">
</picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/rpo97no5CD4DxUGXw6jHhi.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: Shutterstock)</span>
</figcaption>
</div>

<div id="article-body">
<p>Engineers from BitEnergy AI, a firm specializing in AI inference technology, has developed a means of artificial intelligence processing that replaces floating-point multiplication (FPM) with integer addition.&nbsp;</p><p>The new method, called Linear-Complexity Multiplication (L-Mul), comes close to the results of FPM while using the simpler algorithm. But despite that, it’s still able to maintain the high accuracy and precision that FPM is known for. As <a data-analytics-id="inline-link" href="https://techxplore.com/news/2024-10-integer-addition-algorithm-energy-ai.html" data-url="https://techxplore.com/news/2024-10-integer-addition-algorithm-energy-ai.html" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">TechXplore reports</a>, this method reduces the power consumption of AI systems, potentially up to 95%, making it a crucial development for our AI future.</p><p>Since this is a new process, popular and readily available hardware on the market, like Nvidia’s upcoming Blackwell GPUs, aren't designed to handle this algorithm. So, even if BitEnergy AI’s algorithm is confirmed to perform at the same level as FPM, we still need systems that could handle it. This might give a few AI companies pause, especially after they just invested millions, or even billions, of dollars in AI hardware. Nevertheless, the massive 95% reduction in power consumption would probably make the biggest tech companies jump ship, especially if AI chip makers build application-specific integrated circuits (ASICs) that will take advantage of the algorithm.</p><p>Power is now the primary constraint on AI development, with all data center GPUs sold last year alone <a data-analytics-id="inline-link" href="https://www.tomshardware.com/desktops/servers/a-single-modern-ai-gpu-consumes-up-to-37-mwh-of-power-per-year-gpus-sold-last-year-alone-consume-more-power-than-13-million-households" data-before-rewrite-localise="https://www.tomshardware.com/desktops/servers/a-single-modern-ai-gpu-consumes-up-to-37-mwh-of-power-per-year-gpus-sold-last-year-alone-consume-more-power-than-13-million-households">consuming more power than one million homes</a> in a year. Even <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tag/google" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.tomshardware.com/tag/google">Google</a> put its climate target in the backseat because of AI’s power demands, with <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/google-reveals-48-increase-in-greenhouse-gas-emissions-from-2019-largely-driven-by-data-center-energy-demands" data-before-rewrite-localise="https://www.tomshardware.com/tech-industry/google-reveals-48-increase-in-greenhouse-gas-emissions-from-2019-largely-driven-by-data-center-energy-demands">its greenhouse gas emissions increasing by 48%</a> from 2019, instead of declining year-on-year, as expected. The company’s former CEO even suggested opening the floodgates for power production by <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/artificial-intelligence/former-google-ceo-says-climate-goals-are-not-meetable-so-we-might-as-well-drop-climate-conservation-unshackle-ai-companies-so-ai-can-solve-global-warming" data-before-rewrite-localise="https://www.tomshardware.com/tech-industry/artificial-intelligence/former-google-ceo-says-climate-goals-are-not-meetable-so-we-might-as-well-drop-climate-conservation-unshackle-ai-companies-so-ai-can-solve-global-warming">dropping climate goals</a> and using more advanced AI to solve the global warming problem.</p><p>But if AI processing can be more power efficient, then it seems that we can still get advanced AI technologies without sacrificing the planet. Aside from that, this 95% drop in energy use would also reduce the burden that these massive data centers put on the national grid, reducing the need to build more energy plants to power our future quickly.</p><p>While most of us are amazed by the additional power that new AI chips bring every generation, true advancement only comes when these processors are more powerful and more efficient. So, if L-Mul works as advertised, then humanity could have its AI cake and eat it, too.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-EDyKodJvgq4KhLWiwh7i8j"><section><p>Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.</p></section></div>
</div>
<div id="slice-container-authorBio-EDyKodJvgq4KhLWiwh7i8j"><p>Jowi Morales is a tech enthusiast with years of experience working in the industry. He’s been writing with several tech publications since 2021, where he’s been interested in tech hardware and consumer electronics.</p></div>



<!-- Drop in a standard article here maybe? -->


</section>





<div id="slice-container-relatedArticles"><p><h5>Most Popular</h5></p></div>








</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Love being interrupted when my monitor asks me to accept user agreements (285 pts)]]></title>
            <link>https://twitter.com/snwy_me/status/1847396175961641176</link>
            <guid>41889140</guid>
            <pubDate>Sat, 19 Oct 2024 17:27:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/snwy_me/status/1847396175961641176">https://twitter.com/snwy_me/status/1847396175961641176</a>, See on <a href="https://news.ycombinator.com/item?id=41889140">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[A Distributed Systems Reading List (2014) (133 pts)]]></title>
            <link>https://dancres.github.io/Pages/</link>
            <guid>41889076</guid>
            <pubDate>Sat, 19 Oct 2024 17:17:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dancres.github.io/Pages/">https://dancres.github.io/Pages/</a>, See on <a href="https://news.ycombinator.com/item?id=41889076">Hacker News</a></p>
<div id="readability-page-1" class="page">


<h2>Introduction
</h2>

<p>I often argue that the toughest thing about distributed systems is changing the way you think.  The below is a collection of material I've found useful for motivating these changes.
</p>

<h2>Thought Provokers</h2>

<p>Ramblings that make you think about the way you design.  Not everything can be solved with big servers, databases and transactions.</p>

<ul>
<li><a href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.33.411">Harvest,
  Yield and Scalable Tolerant Systems</a><a> - Real world applications of
  CAP from Brewer et al</a></li><a>
</a><li><a></a><a href="https://mvdirona.com/jrh/talksAndPapers/JamesRH_Lisa.pdf">On Designing and Deploying Internet Scale Services</a> - James Hamilton</li>
<li><a href="https://web.archive.org/web/20181006111158/http://www.addsimplicity.com/adding_simplicity_an_engi/2006/12/the_perils_of_g.html">The Perils of Good Abstractions</a>
	- Building the perfect API/interface is difficult</li>
	
<li><a href="https://web.archive.org/web/20180821164750/http://www.addsimplicity.com/adding_simplicity_an_engi/2007/05/chaotic_perspec.html">Chaotic Perspectives</a>
	- Large scale systems are everything developers dislike - unpredictable, unordered and parallel</li>

<li><a href="http://cidrdb.org/cidr2005/papers/P12.pdf">Data on the Outside versus Data on the Inside</a> - Pat Helland</li>
<li><a href="https://channel9.msdn.com/Shows/ARCast.TV/ARCastTV-Pat-Helland-on-Memories-Guesses-and-Apologies">Memories, Guesses and Apologies</a> - Pat Helland</li>
<li><a href="https://web.archive.org/web/20190719121913/https://blogs.msdn.microsoft.com/pathelland/2007/05/20/soa-and-newtons-universe/">SOA and Newton's Universe</a> - Pat Helland</li>
<li><a href="https://arxiv.org/abs/0909.1788">Building on Quicksand</a> - Pat Helland</li>
<li><a href="https://www.artima.com/weblogs/viewpost.jsp?thread=4247">Why Distributed Computing?</a> - Jim Waldo</li>
<li><a href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.7628">A Note on Distributed Computing</a> - Waldo, Wollrath et al</li>
<li><a href="https://web.archive.org/web/20190319154842/https://plus.google.com/112678702228711889851/posts/eVeouesvaVX">Stevey's Google Platforms Rant</a> - Yegge's SOA platform experience</li>
</ul>

<h2>Latency</h2>

<ul>
<li><a href="https://web.archive.org/web/20181004043647/http://www.addsimplicity.com/adding_simplicity_an_engi/2007/02/latency_exists_.html">Latency Exists, Cope!</a>
	- Commentary on coping with latency and it's architectural impacts</li>
<li><a href="https://www.igvita.com/2012/07/19/latency-the-new-web-performance-bottleneck/">Latency - the new web performance bottleneck</a> - not at all new (see <a href="http://dl.acm.org/citation.cfm?id=1022596">Patterson</a>), but noteworthy</li>
<li><a href="https://research.google/pubs/pub40801/">The Tail At Scale</a> - the latencychallenges inherent of dealing with latency in large scale systems</li>	
</ul>

<h2>Amazon</h2>

<p>Somewhat about the technology but more interesting is the culture and organization they've created to work with it.</p>

<ul>
<li><a href="https://queue.acm.org/detail.cfm?id=1142065">A Conversation with Werner Vogels</a> - Coverage of Amazon's transition to a service-based architecture</li>

<li><a href="https://queue.acm.org/detail.cfm?id=1388773">Discipline and Focus</a> - Additional coverage of Amazon's transition to a service-based architecture</li>

<li><a href="https://web.archive.org/web/20130729204944id_/http://itc.conversationsnetwork.org/shows/detail1634.html">Vogels on Scalability</a></li>

<li><a href="http://searchwebservices.techtarget.com/originalContent/0,289142,sid26_gci1195702,00.html">SOA creates order out of chaos @ Amazon</a></li>
</ul>

<h2>Google</h2>

<p>Current "rocket science" in distributed systems.</p>

<ul>
<li><a href="https://research.google/pubs/pub62/">MapReduce</a></li>

<li><a href="https://research.google/pubs/pub27897/">Chubby Lock Manager</a></li>

<li><a href="https://research.google/pubs/pub51/">Google File System</a></li>

<li><a href="https://research.google/pubs/pub27898/">BigTable</a></li>

<li><a href="https://www.usenix.org/legacy/event/worlds06/tech/prelim_papers/perl/perl.pdf">Data Management for Internet-Scale Single-Sign-On</a></li>
<li><a href="https://research.google/pubs/pub36632/">Dremel: Interactive Analysis of Web-Scale Datasets</a></li>
<li><a href="https://research.google/pubs/pub36726/">Large-scale Incremental Processing Using Distributed Transactions and Notifications</a></li>
<li><a href="http://cidrdb.org/cidr2011/Papers/CIDR11_Paper32.pdf">Megastore: Providing Scalable, Highly Available Storage for Interactive Services</a> - Smart design for low latency Paxos implementation across datacentres.</li>
<li><a href="https://research.google/pubs/pub39966/">Spanner</a> - Google's scalable, multi-version, globally-distributed, and synchronously-replicated database.</li>
<li><a href="https://research.google/pubs/pub41318/">Photon</a> -  Fault-tolerant and Scalable Joining of Continuous Data Streams. Joins are tough especially with time-skew, high availability and distribution.</li>
<li><a href="https://research.google/pubs/pub42851/">Mesa: Geo-Replicated, Near Real-Time, Scalable Data Warehousing</a> - Data warehousing system that stores critical measurement data related to Google's Internet advertising business.</li>
</ul>

<h2>Consistency Models</h2>

<p>Key to building systems that suit their environments is finding the right tradeoff between consistency and availability.</p>

<ul>
<li><a href="https://web.archive.org/web/20190629112250/https://www.glassbeam.com/sites/all/themes/glassbeam/images/blog/10.1.1.67.6951.pdf">CAP Conjecture</a> - Consistency, Availability, Parition Tolerance cannot all be satisfied at once</li>
<li><a href="https://www.cs.utexas.edu/users/dahlin/papers/cac-tr.pdf">Consistency, Availability, and Convergence</a> - Proves the upper bound for consistency possible in a typical system</li>
<li><a href="https://www.infoq.com/articles/cap-twelve-years-later-how-the-rules-have-changed">CAP Twelve Years Later: How the "Rules" Have Changed</a> - Eric Brewer expands on the original tradeoff description</li>
<li><a href="https://www.infoq.com/news/2008/01/consistency-vs-availability">Consistency and Availability</a> - Vogels</li>
<li><a href="https://www.allthingsdistributed.com/2007/12/eventually_consistent.html">Eventual Consistency</a> - Vogels</li>
<li><a href="https://web.archive.org/web/20180821165044/http://www.addsimplicity.com/adding_simplicity_an_engi/2006/12/avoiding_two_ph.html">Avoiding Two-Phase Commit</a>
	- Two phase commit avoidance approaches</li>
	
<li><a href="https://web.archive.org/web/20180821164931/http://www.addsimplicity.com/adding_simplicity_an_engi/2006/12/2pc_or_not_2pc_.html">2PC or not 2PC, Wherefore Art Thou XA?</a>
	- Two phase commit isn't a silver bullet</li>
<li><a href="https://docs.microsoft.com/en-us/archive/blogs/pathelland/link-to-quotlife-beyond-distributed-transactions-an-apostates-opinion">Life Beyond Distributed Transactions</a>
	- Helland</li>
<li><a href="https://queue.acm.org/detail.cfm?id=1988603">If you have
	too much data, then 'good enough' is good enough</a> - NoSQL,
	Future of data theory - Pat Helland</li>
<li><a href="https://www.enterpriseintegrationpatterns.com/docs/IEEE_Software_Design_2PC.pdf">Starbucks doesn't do two phase commit</a> - Asynchronous mechanisms at work</li>
<li><a href="https://codahale.com/you-cant-sacrifice-partition-tolerance/">You Can't Sacrifice Partition Tolerance</a> - Additional CAP commentary</li>
<li><a href="https://www.hpl.hp.com/techreports/2002/HPL-2002-33.pdf">Optimistic Replication</a> - Relaxed consistency approaches for data replication</li>
</ul>

<h2>Theory</h2>

<p>Papers that describe various important elements of distributed systems design.</p>

<ul>
<li><a href="https://arxiv.org/pdf/cs/0403019.pdf">Distributed Computing Economics</a> - Jim Gray</li>
<li><a href="https://www.microsoft.com/en-us/research/publication/rules-of-thumb-in-data-engineering/">Rules of Thumb in Data Engineering</a> - Jim Gray and Prashant Shenoy</li>
<li><a href="https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing">Fallacies of Distributed Computing</a> - Peter Deutsch</li>
<li><a href="https://doi.acm.org/10.1145/3149.214121">Impossibility of distributed consensus with one faulty process</a> - also known as FLP [access requires account and/or payment, a free version can be found <a href="https://groups.csail.mit.edu/tds/papers/Lynch/jacm85.pdf">here</a>]</li>
<li><a href="https://www.cs.utexas.edu/~lorenzo/corsi/cs380d/papers/p225-chandra.pdf">Unreliable Failure Detectors for Reliable Distributed Systems.</a> A method for handling the challenges of FLP</li>
<li><a href="https://lamport.azurewebsites.net/pubs/time-clocks.pdf">Lamport Clocks</a> - How do you establish a global view of time when each computer's clock is independent</li>
<li><a href="https://lamport.azurewebsites.net/pubs/byz.pdf">The Byzantine Generals Problem</a></li>
<li><a href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.17.469">Lazy Replication: Exploiting the Semantics of Distributed Services</a></li>
<li><a href="https://www.usenix.org/legacy/event/hotdep10/tech/full_papers/Kapritsos.pdf">Scalable Agreement - Towards Ordering as a Service</a></li>
<li><a href="https://arxiv.org/pdf/1307.3207v1.pdf">Scalable Eventually Consistent Counters over Unreliable Networks</a> - Scalable counting is tough in an unreliable world</li>
</ul>

<h2>Languages and Tools</h2>

<p>Issues of distributed systems construction with specific technologies.</p>

<ul>
<li><a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.137.9417&amp;rep=rep1&amp;type=pdf">Programming Distributed Erlang Applications: Pitfalls and Recipes</a> - Building reliable distributed applications isn't as simple as merely choosing Erlang and OTP.</li>
</ul>

	
<h2>Infrastructure</h2>
<ul>
<li><a href="https://queue.acm.org/detail.cfm?id=1773943">Principles of Robust Timing over the Internet</a> - Managing clocks is essential for even basics such as debugging</li>
</ul>

<h2>Storage</h2>
<ul>
<li><a href="https://www.akamai.com/us/en/multimedia/documents/technical-publication/consistent-hashing-and-random-trees-distributed-caching-protocols-for-relieving-hot-spots-on-the-world-wide-web-technical-publication.pdf">Consistent Hashing and Random Trees</a></li>
<li><a href="https://www.allthingsdistributed.com/2007/10/amazons_dynamo.html">Amazon's Dynamo Storage Service</a></li>
</ul>

<h2>Paxos Consensus</h2>

<p>Understanding this algorithm is the challenge.  I would suggest reading "Paxos Made Simple" before the other papers and again afterward.</p>

<ul>
<li><a href="https://lamport.azurewebsites.net/pubs/lamport-paxos.pdf">The Part-Time Parliament</a> - Leslie Lamport</li>
<li><a href="https://lamport.azurewebsites.net/pubs/paxos-simple.pdf">Paxos Made Simple</a> - Leslie Lamport</li>
<li><a href="https://static.googleusercontent.com/media/research.google.com/en/us/archive/paxos_made_live.pdf">Paxos Made Live - An Engineering Perspective</a> - Chandra et al</li>
<li><a href="https://groups.csail.mit.edu/tds/paxos.html">Revisiting the Paxos Algorithm</a> - Lynch et al</li>
<li><a href="http://bwl-website.s3-website.us-east-2.amazonaws.com/58-Consensus/Acrobat.pdf">How to build a highly available system with consensus</a> - Butler Lampson</li>
<li><a href="https://www.microsoft.com/en-us/research/publication/reconfiguring-a-state-machine/">Reconfiguring a State Machine</a> - Lamport et al - changing cluster membership</li>
<li><a href="https://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.20.4762">Implementing Fault-Tolerant Services Using the State Machine Approach: a Tutorial</a> - Fred Schneider</li>
</ul>

<h2>Other Consensus Papers</h2>

<ul>
<li><a href="https://www.usenix.org/legacy/event/osdi08/tech/full_papers/mao/mao_html/">Mencius: Building Efficient Replicated State Machines for WANs</a> - consensus algorithm for wide-area network</li>
<li><a href="https://raft.github.io/raft.pdf">In Search of an Understandable Consensus Algorithm</a> - The extended version of the RAFT paper, an alternative to PAXOS.</li>
</ul>

<h2>Gossip Protocols (Epidemic Behaviours)</h2>

<ul>
<li><a href="https://infoscience.epfl.ch/record/109302?ln=en">How robust are gossip-based communication protocols?</a></li>
<li><a href="https://www.cs.cornell.edu/home/rvr/papers/astrolabe.pdf">Astrolabe: A Robust and Scalable Technology For Distributed Systems Monitoring, Management, and Data Mining</a></li>
<li><a href="https://www.allthingsdistributed.com/historical/archives/000456.html">Epidemic Computing at Cornell</a></li>
<li><a href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.5.4000%22">Fighting Fire With Fire: Using Randomized Gossip To Combat Stochastic Scalability Limits</a></li>
<li><a href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.17.7959">Bi-Modal Multicast</a></li>
<li><a href="https://dl.acm.org/toc/sigops/2007/41/5">ACM SIGOPS Operating Systems Review - Gossip-based computer networking</a></li>
<li><a href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.18.9737">SWIM: Scalable Weakly-consistent Infection-style Process Group Membership Protocol</a></li>
</ul>

<h2>P2P</h2>

<ul>
<li><a href="https://pdos.csail.mit.edu/papers/ton:chord/paper-ton.pdf">Chord</a>: A Scalable Peer-to-peer Lookup Protocol for Internet Applications</li>
<li><a href="https://pdos.csail.mit.edu/~petar/papers/maymounkov-kademlia-lncs.pdf">Kademlia</a>: A Peer-to-peer Information System Based on the XOR Metric</li>
<li><a href="https://rowstron.azurewebsites.net/PAST/pastry.pdf">Pastry</a>: Scalable, decentralized object location and routing for large-scale peer-to-peer systems</li>
<li><a href="http://research.microsoft.com/en-us/um/people/antr/PAST/hotos.pdf">PAST</a>: A large-scale, persistent peer-to-peer storage utility - storage system atop Pastry</li>
<li><a href="https://rowstron.azurewebsites.net/PAST/jsac.pdf">SCRIBE</a>: A large-scale and decentralised application-level multicast infrastructure - wide area messaging atop Pastry</li>
</ul>



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Have McKinsey and its consulting rivals got too big? (145 pts)]]></title>
            <link>https://www.economist.com/business/2024/03/25/have-mckinsey-and-its-consulting-rivals-got-too-big</link>
            <guid>41888061</guid>
            <pubDate>Sat, 19 Oct 2024 14:46:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/business/2024/03/25/have-mckinsey-and-its-consulting-rivals-got-too-big">https://www.economist.com/business/2024/03/25/have-mckinsey-and-its-consulting-rivals-got-too-big</a>, See on <a href="https://news.ycombinator.com/item?id=41888061">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><p><span><a href="https://www.economist.com/business" data-analytics="sidebar:section"><span>Business</span></a></span><span> | <!-- -->The lost art of self-management</span></p><h2>The golden age for CEO whisperers may be coming to an end</h2></section><div><div><p><time datetime="2024-03-25T22:03:59.042Z"> <!-- -->Mar 25th 2024</time></p></div><section data-body-id="cp2"><p data-component="paragraph"><span data-caps="initial">A</span><small>N ANONYMOUS MEMO</small> briefly circled the web in March. The authors, who claimed to be former partners at McKinsey, rebuked the illustrious strategy consultancy for its pursuit in recent years of “unchecked and unmanaged growth”, and chastised its leadership for, of all things, a “lack of strategic focus”. With humility typical of McKinseyites, they warned that “an organisation of genuine greatness” was at risk of being lost.</p></section><p>This article appeared in the Business section of the print edition under the headline “The lost art of self-management”</p><div data-tracking-id="content-well-chapter-list"><h2><a href="https://www.economist.com/business">Business</a> <span>March 30th 2024</span></h2><ul><li><a href="https://www.economist.com/business/2024/03/25/have-mckinsey-and-its-consulting-rivals-got-too-big"><span>Have McKinsey and its consulting rivals got too big?</span></a></li><li><a href="https://www.economist.com/business/2024/03/27/making-accounting-sexy-again"><span>Making accounting sexy again</span></a></li><li><a href="https://www.economist.com/business/2024/03/27/a-marketing-victory-for-nike-is-a-business-win-for-adidas"><span>A marketing victory for Nike is a business win for Adidas</span></a></li><li><a href="https://www.economist.com/business/2024/03/27/the-pros-and-cons-of-corporate-uniforms"><span>The pros and cons of corporate uniforms</span></a></li><li><a href="https://www.economist.com/business/2024/03/27/regulators-are-forcing-big-tech-to-rethink-its-ai-strategy"><span>Regulators are forcing big tech to rethink its AI strategy</span></a></li><li><a href="https://www.economist.com/business/2024/03/27/dave-calhoun-bows-out-as-chief-executive-of-boeing"><span>Dave Calhoun bows out as chief executive of Boeing</span></a></li><li><a href="https://www.economist.com/business/2024/03/27/meet-the-digital-david-taking-on-the-google-goliath"><span>Meet the digital David taking on the Google Goliath</span></a></li></ul></div><div orientation="vertical" data-test-id="vertical"><div orientation="vertical"><figure><img loading="lazy" width="1280" height="1709" decoding="async" data-nimg="1" sizes="300px" srcset="https://www.economist.com/cdn-cgi/image/width=16,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 16w, https://www.economist.com/cdn-cgi/image/width=32,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 32w, https://www.economist.com/cdn-cgi/image/width=48,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 48w, https://www.economist.com/cdn-cgi/image/width=64,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 64w, https://www.economist.com/cdn-cgi/image/width=96,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 96w, https://www.economist.com/cdn-cgi/image/width=128,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 128w, https://www.economist.com/cdn-cgi/image/width=256,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 256w, https://www.economist.com/cdn-cgi/image/width=360,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 360w, https://www.economist.com/cdn-cgi/image/width=384,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 384w, https://www.economist.com/cdn-cgi/image/width=480,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 480w, https://www.economist.com/cdn-cgi/image/width=600,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 600w, https://www.economist.com/cdn-cgi/image/width=834,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 834w, https://www.economist.com/cdn-cgi/image/width=960,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 960w, https://www.economist.com/cdn-cgi/image/width=1096,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 1096w, https://www.economist.com/cdn-cgi/image/width=1280,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 1280w, https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 1424w" src="https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg"></figure></div><div orientation="vertical"><h3 orientation="vertical">From the March 30th 2024 edition</h3><p orientation="vertical">Discover stories from this section and more in the list of contents</p><p><a href="https://www.economist.com/weeklyedition/2024-03-30" data-analytics="sidebar:weekly_edition"><span>Explore the edition</span></a></p></div></div><div><p><a href="https://s100.copyright.com/AppDispatchServlet?publisherName=economist&amp;publication=economist&amp;title=Have%20McKinsey%20and%20its%20consulting%20rivals%20got%20too%20big%3F&amp;publicationDate=2024-03-25&amp;contentID=%2Fcontent%2Fh2uo27nddgkvs01g3l6va42ufik5tavk&amp;type=A&amp;orderBeanReset=TRUE" target="_blank" rel="noreferrer" data-analytics="end_of_article:reuse_this_content"><span>Reuse this content</span></a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Send: Open-source fork of Firefox Send (143 pts)]]></title>
            <link>https://send.vis.ee/</link>
            <guid>41887378</guid>
            <pubDate>Sat, 19 Oct 2024 12:17:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://send.vis.ee/">https://send.vis.ee/</a>, See on <a href="https://news.ycombinator.com/item?id=41887378">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[S3 as a Git remote and LFS server (103 pts)]]></title>
            <link>https://github.com/awslabs/git-remote-s3</link>
            <guid>41887004</guid>
            <pubDate>Sat, 19 Oct 2024 10:37:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/awslabs/git-remote-s3">https://github.com/awslabs/git-remote-s3</a>, See on <a href="https://news.ycombinator.com/item?id=41887004">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">git-remote-s3</h2><a id="user-content-git-remote-s3" aria-label="Permalink: git-remote-s3" href="#git-remote-s3"></a></p>
<p dir="auto">This library enables to use Amazon S3 as a git remote and LFS server.</p>
<p dir="auto">It provides an implementation of a <a href="https://git-scm.com/docs/gitremote-helpers" rel="nofollow">git remote helper</a> to use S3 as a serverless Git server.</p>
<p dir="auto">It also provide an implementation of the <a href="https://github.com/git-lfs/git-lfs/blob/main/docs/custom-transfers.md">git-lfs custom transfer</a> to enable pushing LFS managed files to the same S3 bucket used as remote.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><code>git-remote-s3</code> is a Python script and works with any Python version &gt;= 3.9.</p>
<p dir="auto">Run:</p>
<div data-snippet-clipboard-copy-content="pip install git-remote-s3"><pre><code>pip install git-remote-s3
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Prerequisites</h2><a id="user-content-prerequisites" aria-label="Permalink: Prerequisites" href="#prerequisites"></a></p>
<p dir="auto">Before you can use <code>git-remote-s3</code>, you must:</p>
<ul dir="auto">
<li>
<p dir="auto">Complete initial configuration:</p>
<ul dir="auto">
<li>Creating an AWS account</li>
<li>Configuring an IAM user or role</li>
</ul>
</li>
<li>
<p dir="auto">Create an AWS S3 bucket (or have one already) in your AWS account.</p>
</li>
<li>
<p dir="auto">Attach a minimal policy to that user/role that allows the to the S3 bucket:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;Sid&quot;: &quot;S3Access&quot;,
  &quot;Effect&quot;: &quot;Allow&quot;,
  &quot;Action&quot;: [&quot;s3:PutObject&quot;, &quot;s3:GetObject&quot;, &quot;s3:ListBucket&quot;],
  &quot;Resource&quot;: [&quot;arn:aws:s3:::<BUCKET>&quot;, &quot;arn:aws:s3:::*/*&quot;]
}"><pre>{
  <span>"Sid"</span>: <span><span>"</span>S3Access<span>"</span></span>,
  <span>"Effect"</span>: <span><span>"</span>Allow<span>"</span></span>,
  <span>"Action"</span>: [<span><span>"</span>s3:PutObject<span>"</span></span>, <span><span>"</span>s3:GetObject<span>"</span></span>, <span><span>"</span>s3:ListBucket<span>"</span></span>],
  <span>"Resource"</span>: [<span><span>"</span>arn:aws:s3:::&lt;BUCKET&gt;<span>"</span></span>, <span><span>"</span>arn:aws:s3:::*/*<span>"</span></span>]
}</pre></div>
</li>
<li>
<p dir="auto">Optional (but recommended) - use <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucket-key.html" rel="nofollow">SSE-KMS Bucket keys to encrypt the content of the bucket</a>, ensure the user/role create previously has the permission to access and use the key.</p>
</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;Sid&quot;: &quot;KMSAccess&quot;,
  &quot;Effect&quot;: &quot;Allow&quot;,
  &quot;Action&quot;: [&quot;kms:Decrypt&quot;, &quot;kms:GenerateDataKey&quot;],
  &quot;Resource&quot;: [&quot;arn:aws:kms:<REGION>:<ACCOUNT>:key/<KEY_ID>&quot;]
}"><pre>{
  <span>"Sid"</span>: <span><span>"</span>KMSAccess<span>"</span></span>,
  <span>"Effect"</span>: <span><span>"</span>Allow<span>"</span></span>,
  <span>"Action"</span>: [<span><span>"</span>kms:Decrypt<span>"</span></span>, <span><span>"</span>kms:GenerateDataKey<span>"</span></span>],
  <span>"Resource"</span>: [<span><span>"</span>arn:aws:kms:&lt;REGION&gt;:&lt;ACCOUNT&gt;:key/&lt;KEY_ID&gt;<span>"</span></span>]
}</pre></div>
<ul dir="auto">
<li>Install Python and its package manager, pip, if they are not already installed. To download and install the latest version of Python, <a href="https://www.python.org/" rel="nofollow">visit the Python website</a>.</li>
<li>Install Git on your Linux, macOS, Windows, or Unix computer.</li>
<li>Install the latest version of the AWS CLI on your Linux, macOS, Windows, or Unix computer. You can find instructions <a href="https://docs.aws.amazon.com/cli/latest/userguide/installing.html" rel="nofollow">here</a>.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Security</h2><a id="user-content-security" aria-label="Permalink: Security" href="#security"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Data encryption</h3><a id="user-content-data-encryption" aria-label="Permalink: Data encryption" href="#data-encryption"></a></p>
<p dir="auto">All data is encrypted at rest and in transit by default. To add an additional layer of security you can use customer managed KMS keys to encrypt the data at rest on the S3 bucket. We recommend to use <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucket-key.html" rel="nofollow">Bucket keys</a> to minimize the KMS costs.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Access control</h3><a id="user-content-access-control" aria-label="Permalink: Access control" href="#access-control"></a></p>
<p dir="auto">Access control to the remote is ensured via IAM permissions, and can be controlled at:</p>
<ul dir="auto">
<li>bucket level</li>
<li>prefix level (you can use prefixes to store multiple repos in the same S3 bucket thus minimizing the setup effort)</li>
<li>KMS key level</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Use S3 remotes</h2><a id="user-content-use-s3-remotes" aria-label="Permalink: Use S3 remotes" href="#use-s3-remotes"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Create a new repo</h2><a id="user-content-create-a-new-repo" aria-label="Permalink: Create a new repo" href="#create-a-new-repo"></a></p>
<p dir="auto">S3 remotes are identified by the prefix <code>s3://</code> and at the bare minimum specify the name of the bucket. You can also provide a key prefix as in <code>s3://my-git-bucket/my-repo</code> and a profile <code>s3://my-profile@my-git-bucket/myrepo</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="mkdir my-repo
cd my-repo
git init
git remote add origin s3://my-git-bucket/my-repo"><pre>mkdir my-repo
<span>cd</span> my-repo
git init
git remote add origin s3://my-git-bucket/my-repo</pre></div>
<p dir="auto">You can then add a file, commit and push the changes to the remote:</p>
<div dir="auto" data-snippet-clipboard-copy-content="echo &quot;Hello&quot; > hello.txt
git add -A
git commit -a -m &quot;hello&quot;
git push --set-upstream origin main"><pre><span>echo</span> <span><span>"</span>Hello<span>"</span></span> <span>&gt;</span> hello.txt
git add -A
git commit -a -m <span><span>"</span>hello<span>"</span></span>
git push --set-upstream origin main</pre></div>
<p dir="auto">The remote HEAD is set to track the branch that has been pushed first to the remote repo. To change the remote HEAD branch, delete the HEAD object <code>s3://&lt;bucket&gt;/&lt;prefix&gt;/HEAD</code> and then run <code>git-remote-s3 doctor s3://&lt;bucket&gt;/&lt;prefix&gt;</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Clone a repo</h2><a id="user-content-clone-a-repo" aria-label="Permalink: Clone a repo" href="#clone-a-repo"></a></p>
<p dir="auto">To clone the repo to another folder just use the normal git syntax using the s3 URI as remote:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone s3://my-git-bucket/my-repo my-repo-clone"><pre>git clone s3://my-git-bucket/my-repo my-repo-clone</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Branches, etc.</h2><a id="user-content-branches-etc" aria-label="Permalink: Branches, etc." href="#branches-etc"></a></p>
<p dir="auto">Creating branches and pushing them works as normal:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd my-repo
git checkout -b new_branch
touch new_file.txt
git add -A
git commit -a -m &quot;new file&quot;
git push origin new_branch"><pre><span>cd</span> my-repo
git checkout -b new_branch
touch new_file.txt
git add -A
git commit -a -m <span><span>"</span>new file<span>"</span></span>
git push origin new_branch</pre></div>
<p dir="auto">All git operations that do not rely on communication with the server should work as usual (eg <code>git merge</code>)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">LFS</h2><a id="user-content-lfs" aria-label="Permalink: LFS" href="#lfs"></a></p>
<p dir="auto">To use LFS you need to first install git-lfs. You can refer to the [official documentation]((<a href="https://git-lfs.com/" rel="nofollow">https://git-lfs.com/</a>) on how to do this on your system.</p>
<p dir="auto">Next, you need enable the S3 integration by running the following command in the repo folder:</p>

<p dir="auto">which is a short cut for:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git config --add lfs.customtransfer.lfs-s3-py.path lfs-s3-py
git config --add lfs.standalonetransferagent lfs-s3-py"><pre>git config --add lfs.customtransfer.lfs-s3-py.path lfs-s3-py
git config --add lfs.standalonetransferagent lfs-s3-py</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Example use</h2><a id="user-content-example-use" aria-label="Permalink: Example use" href="#example-use"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Creating the repo and pushing</h3><a id="user-content-creating-the-repo-and-pushing" aria-label="Permalink: Creating the repo and pushing" href="#creating-the-repo-and-pushing"></a></p>
<p dir="auto">Let's assume we want to store TIFF file in LFS.</p>
<div dir="auto" data-snippet-clipboard-copy-content="mkdir lfs-repo
cd lfs-repo
git init
git lfs install
lfs-s3-py install
git lfs track &quot;*.tiff&quot;
git add .gitattributes
<put file.tiff in the repo>
git add file.tiff
git commit -a -m &quot;my first tiff file&quot;
git remote add origin s3://my-git-bucket/lfs-repo
git push --set-upstream origin main"><pre>mkdir lfs-repo
<span>cd</span> lfs-repo
git init
git lfs install
lfs-s3-py install
git lfs track <span><span>"</span>*.tiff<span>"</span></span>
git add .gitattributes
<span>&lt;</span>put file.tiff <span>in</span> the repo<span>&gt;</span>
git add file.tiff
git commit -a -m <span><span>"</span>my first tiff file<span>"</span></span>
git remote add origin s3://my-git-bucket/lfs-repo
git push --set-upstream origin main</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Notes about specific behaviors of Amazon S3 remotes</h2><a id="user-content-notes-about-specific-behaviors-of-amazon-s3-remotes" aria-label="Permalink: Notes about specific behaviors of Amazon S3 remotes" href="#notes-about-specific-behaviors-of-amazon-s3-remotes"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Arbitrary Amazon S3 URIs</h3><a id="user-content-arbitrary-amazon-s3-uris" aria-label="Permalink: Arbitrary Amazon S3 URIs" href="#arbitrary-amazon-s3-uris"></a></p>
<p dir="auto">An Amazon S3 URI for an valid bucket and an arbitrary prefix which does not contain the right structure under it, is considered valid.</p>
<p dir="auto"><code>git ls-remote</code> returns an empty list and <code>git clone</code> clones an empty repository for which the S3 URI is set as remote origin.</p>
<div data-snippet-clipboard-copy-content="% git clone s3://my-git-bucket/this-is-a-new-repo
Cloning into 'this-is-a-new-repo'...
warning: You appear to have cloned an empty repository.
% cd this-is-a-new-repo
% git remote -v
origin  s3://my-git-bucket/this-is-a-new-repo (fetch)
origin  s3://my-git-bucket/this-is-a-new-repo (push)"><pre><code>% git clone s3://my-git-bucket/this-is-a-new-repo
Cloning into 'this-is-a-new-repo'...
warning: You appear to have cloned an empty repository.
% cd this-is-a-new-repo
% git remote -v
origin  s3://my-git-bucket/this-is-a-new-repo (fetch)
origin  s3://my-git-bucket/this-is-a-new-repo (push)
</code></pre></div>
<p dir="auto"><strong>Tip</strong>: This behavior can be used to quickly create a new git repo.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Concurrent writes</h2><a id="user-content-concurrent-writes" aria-label="Permalink: Concurrent writes" href="#concurrent-writes"></a></p>
<p dir="auto">Due to the distributed nature of <code>git</code>, there might be cases (albeit rare) where 2 or more <code>git push</code> are executed at the same time by different user with their own modification of the same branch.</p>
<p dir="auto">The git command executes the push in 2 steps:</p>
<ol dir="auto">
<li>first it checks if the remote reference is the correct ancestor for the commit being pushed</li>
<li>if that is correct it invokes the <code>git-remote-s3</code> command which writes the bundle to the S3 bucket at the <code>refs/heads/&lt;branch&gt;</code> path</li>
</ol>
<p dir="auto">In case two (or more) <code>git push</code> command are executed at the same time from different clients, at step 1 the same valid ref is fetched, hence both clients proceed with step 2, resulting in multiple bundles being stored in S3.</p>
<p dir="auto">The branch has now multiple head references, and any subsequent <code>git push</code> fails with the error:</p>
<div data-snippet-clipboard-copy-content="error: dst refspec refs/heads/<branch>> matches more than one
error: failed to push some refs to 's3://<bucket>/<prefix>'"><pre><code>error: dst refspec refs/heads/&lt;branch&gt;&gt; matches more than one
error: failed to push some refs to 's3://&lt;bucket&gt;/&lt;prefix&gt;'
</code></pre></div>
<p dir="auto">To fix this issue, run the <code>git-remote-s3 doctor &lt;s3-uri&gt;</code> command. By default it will create a new branch for every bundle that should not be retained. The user can then checkout the branch locally and merge it to the original branch. If you want instead to remove the bundle, specify <code>--delete-bundle</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Clone the repo</h3><a id="user-content-clone-the-repo" aria-label="Permalink: Clone the repo" href="#clone-the-repo"></a></p>
<p dir="auto">When cloning a repo using the S3 remote for LFS, <code>git-lfs</code> can't know how to fetch the files since we have yet to add the configuration.</p>
<p dir="auto">It involves 2 extra steps.</p>
<div dir="auto" data-snippet-clipboard-copy-content="% git clone s3://my-git-bucket/lfs-repo lfs-repo-clone
Error downloading object: file.tiff (54238cf): Smudge error: Error downloading file.tiff (54238cfaaaa42dda05da0e12bf8ee3156763fa35296085ccdef63b13a87837c5): batch request: ssh: Could not resolve hostname s3: Name or service not known: exit status 255
..."><pre>% git clone s3://my-git-bucket/lfs-repo lfs-repo-clone
Error downloading object: file.tiff (54238cf): Smudge error: Error downloading file.tiff (54238cfaaaa42dda05da0e12bf8ee3156763fa35296085ccdef63b13a87837c5): batch request: ssh: Could not resolve hostname s3: Name or service not known: <span>exit</span> status 255
...</pre></div>
<p dir="auto">To fix:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd lfs-repo-clone
lfs-s3-py install
git reset --hard main"><pre><span>cd</span> lfs-repo-clone
lfs-s3-py install
git reset --hard main</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Manage the Amazon S3 remote</h2><a id="user-content-manage-the-amazon-s3-remote" aria-label="Permalink: Manage the Amazon S3 remote" href="#manage-the-amazon-s3-remote"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Delete branches</h2><a id="user-content-delete-branches" aria-label="Permalink: Delete branches" href="#delete-branches"></a></p>
<p dir="auto">To remove remote branches that are not used anymore you can use the <code>git-s3 delete-branch &lt;s3uri&gt; -b &lt;branch_name&gt;</code> command. This command deletes the bundle object(s) from Amazon S3 under the branch path.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Protected branches</h2><a id="user-content-protected-branches" aria-label="Permalink: Protected branches" href="#protected-branches"></a></p>
<p dir="auto">To protect/unprotect a branch run <code>git s3 protect &lt;remote&gt; &lt;branch-name&gt;</code> respectively <code>git s3 unprotect &lt;remote&gt; &lt;branch-name&gt;</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Under the hood</h2><a id="user-content-under-the-hood" aria-label="Permalink: Under the hood" href="#under-the-hood"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How S3 remote work</h2><a id="user-content-how-s3-remote-work" aria-label="Permalink: How S3 remote work" href="#how-s3-remote-work"></a></p>
<p dir="auto">Bundles are stored in the S3 bucket as <code>&lt;prefix&gt;/&lt;ref&gt;/&lt;sha&gt;.bundle</code>.</p>
<p dir="auto">When listing remote ref (eg explicitly via <code>git ls-remote</code>) we list all the keys present under the given .</p>
<p dir="auto">When pushing a new ref (eg a commit), we get the sha of the ref, we bundle the ref via <code>git bundle create &lt;sha&gt;.bundle &lt;ref&gt;</code> and store it to S3 according the schema above.</p>
<p dir="auto">If the push is successful, the code removes the previous bundle associated to the ref.</p>
<p dir="auto">If two user concurrently push a commit based on the same current branch head to the remote both bundles would be written to the repo and the current bundle removed. No data is lost, but no further push will be possible until all bundles but one are removed.
For this you can use the <code>git s3 doctor &lt;remote&gt;</code> command.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How LFS work</h2><a id="user-content-how-lfs-work" aria-label="Permalink: How LFS work" href="#how-lfs-work"></a></p>
<p dir="auto">The LFS integration stores the file in the bucket defined by the remote URI, under a key <code>&lt;prefix&gt;/lfs/&lt;oid&gt;</code>, where oid is the unique identifier assigned by git-lfs to the file.</p>
<p dir="auto">If an object with the same key already exists, git-lfs-s3 does not upload it again.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Debugging</h2><a id="user-content-debugging" aria-label="Permalink: Debugging" href="#debugging"></a></p>
<p dir="auto">Use <code>--verbose</code> flag to print some debug information when performing git operations. Logs will be put to stderr.</p>
<p dir="auto">For LFS operations you can enable and disable debug logging via <code>git-lfs-s3 enable-debug</code> and <code>git-lfs-s3 disable-debug</code> respectively. Logs are put in <code>.git/lfs/tmp/git-lfs-s3.log</code> in the repo.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Credits</h2><a id="user-content-credits" aria-label="Permalink: Credits" href="#credits"></a></p>
<p dir="auto">The git S3 integration was inspired by the work of Bryan Gahagan on <a href="https://github.com/bgahagan/git-remote-s3">git-remote-s3</a>.</p>
<p dir="auto">The LFS implementation benefitted from <a href="https://github.com/nicolas-graves/lfs-s3">lfs-s3</a> by <a href="https://github.com/nicolas-graves">@nicolas-graves</a>. If you do not need to use the git-remote-s3 transport you are should use that project.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The long road to lazy preemption in the Linux CPU scheduler (198 pts)]]></title>
            <link>https://lwn.net/SubscriberLink/994322/45aa5211a50bc63a/</link>
            <guid>41886256</guid>
            <pubDate>Sat, 19 Oct 2024 07:29:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/SubscriberLink/994322/45aa5211a50bc63a/">https://lwn.net/SubscriberLink/994322/45aa5211a50bc63a/</a>, See on <a href="https://news.ycombinator.com/item?id=41886256">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<blockquote>
<div>
<h3>Welcome to LWN.net</h3>
<p>
The following subscription-only content has been made available to you 
by an LWN subscriber.  Thousands of subscribers depend on LWN for the 
best news from the Linux and free software communities.  If you enjoy this 
article, please consider <a href="https://lwn.net/subscribe/">subscribing to LWN</a>.  Thank you
for visiting LWN.net!
</p></div>
</blockquote>
<p>
The kernel's CPU scheduler currently offers several preemption modes that
implement a range of tradeoffs between system throughput and response time.
Back in September 2023, a <a href="https://lwn.net/Articles/944686/">discussion
on scheduling</a> led to the concept of "lazy preemption", which could
simplify scheduling in the kernel while providing better results.  Things
went quiet for a while, but lazy preemption has returned in the form of <a href="https://lwn.net/ml/all/20241007074609.447006177@infradead.org">this patch series</a>
from Peter Zijlstra.  While the concept appears to work well, there is
still a fair amount of work to be done.
</p><h4>Some review</h4>
<p>
Current kernels have four different modes that regulate when one task can
be preempted in favor of another.  <tt>PREEMPT_NONE</tt>, the simplest
mode, only allows preemption to happen when the running task has exhausted
its time slice.  <tt>PREEMPT_VOLUNTARY</tt> adds a large number of points
within the kernel where preemption can happen if needed.
<tt>PREEMPT_FULL</tt> allows preemption at almost any point except places
in the kernel that prevent it, such as when a spinlock is held.  Finally,
<tt>PREEMPT_RT</tt> prioritizes preemption over most other things, even
making most spinlock-holding code preemptible.
</p><p>
A higher level of preemption enables the system to respond more quickly to
events; whether an event is the movement of a mouse or an "imminent
meltdown" signal from a nuclear reactor, faster response tends to be more
gratifying.  But a higher level of preemption can hurt the overall
throughput of the system; workloads with a lot of long-running,
CPU-intensive tasks tend to benefit from being disturbed as little as
possible.  More frequent preemption can also lead to higher lock
contention.  That is why the different modes exist; the optimal preemption
mode will vary for different workloads.
</p><p>
Most distributions ship kernels built with the <tt>PREEMPT_DYNAMIC</tt>
pseudo-mode, which allows any of the first three modes to be selected at
boot time, with <tt>PREEMPT_VOLUNTARY</tt> being the default.  On systems
with debugfs mounted, the current mode can be read from
<tt>/sys/kernel/debug/sched/preempt</tt>.
</p><p>
<tt>PREEMPT_NONE</tt> and <tt>PREEMPT_VOLUNTARY</tt> do not allow the
arbitrary preemption of code running in the kernel; there are times when
that can lead to excessive latency even in systems where minimal latency is
not prioritized.  This problem is the result of places in the kernel where
a large amount of work can be done; if that work is allowed to run
unchecked, it can disrupt the scheduling of the system as a whole.  To get
around this problem, long-running loops have been sprinkled with calls to
<tt>cond_resched()</tt>, each of which is an additional voluntary
preemption point that is active even in the <tt>PREEMPT_NONE</tt> mode.
There are hundreds of these calls in the kernel.
</p><p>
There are some problems with this approach.  <tt>cond_resched()</tt> is a
form of heuristic that only works in the places where a developer has
thought to put it.  Some calls are surely unnecessary, while there will be
other places in the kernel that could benefit from <tt>cond_resched()</tt>
calls, but do not have them.  The use of <tt>cond_resched()</tt>, at its
core, takes a decision that should be confined to the scheduling code and
spreads it throughout the kernel.  It is, in short, a bit of a hack that
mostly works, but which could be done better.
</p><h4>Doing better</h4>
<p>
The tracking of whether a given task can be preempted at any moment is a
complicated affair that must take into account several variables; see <a href="https://lwn.net/Articles/945422/">this article</a> and <a href="https://lwn.net/Articles/831678/">this article</a> for details.  One of those
variables is a simple flag, <tt>TIF_NEED_RESCHED</tt>, that indicates the
presence of a higher-priority task that is waiting for access to the CPU.
Events such as waking a high-priority task can cause that flag to be set in
whatever task is currently running.  In the absence of this flag, there is
no need for the kernel to consider preempting the current task.
</p><p>
There are various points where the kernel can notice that flag and cause
the currently running task to be preempted.  The scheduler's timer tick is
one example; any time a task returns to user space from a system call is
another.  The completion of an interrupt handler is yet another, but that
check, which can cause preemption to happen any time that interrupts are
enabled, is only enabled in <tt>PREEMPT_FULL</tt> kernels.  A call to
<tt>cond_resched()</tt> will also check that flag and, if it is set, call
into the scheduler to yield the CPU to the other task.
</p><p>
The lazy-preemption patches are simple at their core; they add another
flag, <tt>TIF_NEED_RESCHED_LAZY</tt>, that indicates a need for
rescheduling at some point, but not necessarily right away.  In the lazy
preemption mode (<tt>PREEMPT_LAZY</tt>), most events will set the new flag
rather than <tt>TIF_NEED_RESCHED</tt>.  At points like the return to user
space from the kernel, either flag will lead to a call into the scheduler.
At the voluntary preemption points and in the return-from interrupt path,
though, only <tt>TIF_NEED_RESCHED</tt> is checked.
</p><p>
The result of this change is that, in lazy-preemption mode, most events in
the kernel will not cause the current task to be preempted.  That task
<i>should</i> be preempted eventually, though.  To make that happen, the
kernel's timer-tick handler will check whether
<tt>TIF_NEED_RESCHED_LAZY</tt> is set; if so, <tt>TIF_NEED_RESCHED</tt>
will also be set, possibly causing the running task to be preempted.  Tasks
will generally end up running for something close to their full time slice
unless they give up the CPU voluntarily, which should lead to good
throughput. 
</p><p>
With these changes, the lazy-preemption mode can, like
<tt>PREEMPT_FULL</tt>, run with kernel preemption enabled at (almost) all
times.  Preemption <i>can</i> happen any time that the preemption counter
says that it should.  That allows long-running kernel code to be preempted
whenever other conditions do not prevent it.  It also allows preemption to
happen quickly in those cases where it is truly needed.  For example, 
should a realtime task become runnable, as the result of
handling an interrupt, for example, the <tt>TIF_NEED_RESCHED</tt> flag will
be set, leading to an almost immediate preemption.  There will be no need
to wait for the timer tick in such cases.
</p><p>
Preemption will <i>not</i> happen, though, if only
<tt>TIF_NEED_RESCHED_LAZY</tt> is set, which will be the case much of the
time. So a <tt>PREEMPT_LAZY</tt> kernel will be far less likely to preempt
a running task than a <tt>PREEMPT_FULL</tt> kernel.
</p><h4>Removing <tt>cond_resched()</tt> — eventually</h4>
<p>
The end goal of this work is to have a scheduler with only two non-realtime
modes: <tt>PREEMPT_LAZY</tt> and <tt>PREEMPT_FULL</tt>.  The lazy mode will
occupy a place between <tt>PREEMPT_NONE</tt> and
<tt>PREEMPT_VOLUNTARY</tt>, replacing both of them.  It will, however, not
need the voluntary preemption points that were added for the two modes it
replaces.  Since preemption can now happen almost anywhere, there is no
longer a need to enable it in specific spots.
</p><p>
For now, though, the <tt>cond_resched()</tt> calls remain; if nothing else,
they are required for as long as the <tt>PREEMPT_NONE</tt> and
<tt>PREEMPT_VOLUNTARY</tt> modes exist.  Those calls also help to ensure
that problems are not introduced while lazy preemption is being stabilized.
</p><p>
In the current patch set, <tt>cond_resched()</tt> only checks
<tt>TIF_NEED_RESCHED</tt>, meaning that preemption will be deferred in many
situations where it will happen immediately from <tt>cond_resched()</tt> in
<tt>PREEMPT_VOLUNTARY</tt> or <tt>PREEMPT_NONE</tt> mode.
Steve Rostedt <a href="https://lwn.net/ml/all/20241009100133.2569e2a7@gandalf.local.home">questioned</a>
this change, asking whether <tt>cond_resched()</tt> should retain its older
meaning, at least for the <tt>PREEMPT_VOLUNTARY</tt> case.  Even though
<tt>PREEMPT_VOLUNTARY</tt> is slated for eventual removal, he thought,
keeping the older behavior could help to ease the transition.
</p><p>
Thomas Gleixner
<a href="https://lwn.net/ml/all/87h69lqbk0.ffs@tglx">answered</a> that only checking
<tt>TIF_NEED_RESCHED</tt> is the correct choice, since it will help in the
process of removing the <tt>cond_resched()</tt> calls entirely:
</p><blockquote>
	That forces us to look at all of them and figure out whether they
	need to be extended to include the lazy bit or not. Those which do
	not need it can be eliminated when LAZY is in effect because that
	will preempt on the next possible preemption point once the
	non-lazy bit is set in the tick.
</blockquote>
<p>
He added that he expects "<q>less than 5%</q>" of the
<tt>cond_resched()</tt> calls need to check <tt>TIF_NEED_RESCHED_LAZY</tt>
and, thus, will need to remain even after the transition to
<tt>PREEMPT_LAZY</tt> is complete.
</p><p>
Before then, though, there are hundreds of <tt>cond_resched()</tt> calls
that need to be checked and, for most of them at least, removed.  Many
other details have to be dealt with as well; <a href="https://lwn.net/ml/all/20241009165411.3426937-1-ankur.a.arora@oracle.com">this patch
set</a> from Ankur Arora addresses a few of them.  There is
also, of course, the need for extensive performance testing; Mike Galbraith
has made <a href="https://lwn.net/ml/all/579b7ea34ef6e2f7c955abdfc0929fe1af36faef.camel@gmx.de">an
early start</a> on that work, showing that throughput with lazy preemption
falls just short of that with <tt>PREEMPT_VOLUNTARY</tt>.
</p><p>
It all adds up to a lot to be done still, but the end result
of the lazy-preemption work should be a kernel that is a bit smaller and
simpler while delivering predictable latencies without the need to
sprinkle scheduler-related calls throughout the code.  That seems like a
better solution, but getting there is going to take some time.<br clear="all"></p><table>
           <tbody><tr><th colspan="2">Index entries for this article</th></tr>
           <tr><td><a href="https://lwn.net/Kernel/Index">Kernel</a></td><td><a href="https://lwn.net/Kernel/Index#Preemption">Preemption</a></td></tr>
            <tr><td><a href="https://lwn.net/Kernel/Index">Kernel</a></td><td><a href="https://lwn.net/Kernel/Index#Scheduler">Scheduler</a></td></tr>
            </tbody></table><br clear="all">

               <br clear="all">
               <hr>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to leverage Claude's capabilities with interactive visualization (104 pts)]]></title>
            <link>https://github.com/anthropics/anthropic-quickstarts/tree/main/financial-data-analyst</link>
            <guid>41885231</guid>
            <pubDate>Sat, 19 Oct 2024 02:39:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/anthropics/anthropic-quickstarts/tree/main/financial-data-analyst">https://github.com/anthropics/anthropic-quickstarts/tree/main/financial-data-analyst</a>, See on <a href="https://news.ycombinator.com/item?id=41885231">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/anthropics/anthropic-quickstarts/blob/main/financial-data-analyst/public/hero.png"><img src="https://github.com/anthropics/anthropic-quickstarts/raw/main/financial-data-analyst/public/hero.png" alt="hero"></a></p>
<p dir="auto">A sophisticated Next.js application that combines Claude's capabilities with interactive data visualization to analyze financial data via chat.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li><strong>Intelligent Data Analysis</strong>: Powered by Claude (Using Claude 3 Haiku &amp; Claude 3.5 Sonnet)</li>
<li><strong>Multi-Format File Upload Support</strong>:
<ul dir="auto">
<li>Text/Code files (.txt, .md, .html, .py, .csv, etc)</li>
<li>PDF documents (Regular PDF with text, scanned documents not supported)</li>
<li>Images</li>
</ul>
</li>
<li><strong>Interactive Data Visualization</strong>: Based on the context and data analyzed, Claude can generate the following charts:
<ul dir="auto">
<li>Line Charts (Time series data &amp; trends)</li>
<li>Bar Charts (Single metric comparisons)</li>
<li>Multi-Bar Charts (Multiple metrics comparison)</li>
<li>Area Charts (Volume/quantity over time)</li>
<li>Stacked Area Charts (Component breakdowns)</li>
<li>Pie Charts (Distribution analysis)</li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Prerequisites</h3><a id="user-content-prerequisites" aria-label="Permalink: Prerequisites" href="#prerequisites"></a></p>
<ul dir="auto">
<li>Node.js 18+ installed</li>
<li>Anthropic API key (For Claude integration)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installation</h3><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<ol dir="auto">
<li>Clone the repository:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/yourusername/financial-ai-assistant.git
cd financial-ai-assistant"><pre>git clone https://github.com/yourusername/financial-ai-assistant.git
<span>cd</span> financial-ai-assistant</pre></div>
<ol start="2" dir="auto">
<li>Install dependencies:</li>
</ol>

<ol start="3" dir="auto">
<li>Create a <code>.env.local</code> file in the root directory:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="ANTHROPIC_API_KEY=your_api_key_here"><pre><span>ANTHROPIC_API_KEY</span><span>=</span><span>your_api_key_here</span></pre></div>
<ol start="4" dir="auto">
<li>Run the development server:</li>
</ol>

<p dir="auto">Open <a href="http://localhost:3000/" rel="nofollow">http://localhost:3000</a> with your browser to see the result.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Technology Stack</h2><a id="user-content-technology-stack" aria-label="Permalink: Technology Stack" href="#technology-stack"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Frontend</strong>:</p>
<ul dir="auto">
<li>Next.js 14</li>
<li>React</li>
<li>TailwindCSS</li>
<li>Shadcn/ui Components</li>
<li>Recharts (For data visualization)</li>
<li>PDF.js (For PDF processing)</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Backend</strong>:</p>
<ul dir="auto">
<li>Next.js API Routes</li>
<li>Edge Runtime</li>
<li>Anthropic SDK</li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage Examples</h2><a id="user-content-usage-examples" aria-label="Permalink: Usage Examples" href="#usage-examples"></a></p>
<p dir="auto">The assistant can help with various financial analysis tasks:</p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Data Extraction &amp; Analysis</strong>:</p>
<ul dir="auto">
<li>Upload financial documents</li>
<li>Extract key metrics</li>
<li>Analyze trends and patterns</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Visualization Creation</strong>:</p>
<ul dir="auto">
<li>Generate charts based on data</li>
<li>Customize visualizations</li>
<li>Compare multiple metrics</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Interactive Analysis</strong>:</p>
<ul dir="auto">
<li>Ask questions about the data</li>
<li>Request specific visualizations</li>
<li>Get detailed explanations</li>
</ul>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Interesting Use Cases</h2><a id="user-content-interesting-use-cases" aria-label="Permalink: Interesting Use Cases" href="#interesting-use-cases"></a></p>
<p dir="auto">While primarily designed for financial analysis, the AI assistant can be adapted for various intriguing applications:</p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Environmental Data Analysis</strong>:</p>
<ul dir="auto">
<li>Analyze climate change trends</li>
<li>Visualize pollution levels over time</li>
<li>Compare renewable energy adoption across regions</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Sports Performance Tracking</strong>:</p>
<ul dir="auto">
<li>Upload athlete performance data</li>
<li>Generate visualizations of key metrics</li>
<li>Analyze trends and patterns in team statistics</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Social Media Analytics</strong>:</p>
<ul dir="auto">
<li>Process engagement data from various platforms</li>
<li>Create charts showing follower growth and interaction rates</li>
<li>Analyze sentiment trends in user comments</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Educational Progress Tracking</strong>:</p>
<ul dir="auto">
<li>Upload student performance data</li>
<li>Visualize learning progress over time</li>
<li>Compare different teaching methods or curriculums</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Health and Fitness Monitoring</strong>:</p>
<ul dir="auto">
<li>Process personal health data from wearables</li>
<li>Create charts for metrics like steps, heart rate, and sleep patterns</li>
<li>Analyze long-term health trends and provide insights</li>
</ul>
</li>
</ol>
<p dir="auto">You can even use charts and images to create interesting results, like the ability to see what's most common inside a picture using a pie chart.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/anthropics/anthropic-quickstarts/blob/main/financial-data-analyst/public/image-analysis.png"><img src="https://github.com/anthropics/anthropic-quickstarts/raw/main/financial-data-analyst/public/image-analysis.png" alt="Image Analysis"></a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US probes Tesla's Full Self-Driving software in 2.4M cars after fatal crash (139 pts)]]></title>
            <link>https://www.reuters.com/business/autos-transportation/nhtsa-opens-probe-into-24-mln-tesla-vehicles-over-full-self-driving-collisions-2024-10-18/</link>
            <guid>41884740</guid>
            <pubDate>Sat, 19 Oct 2024 00:46:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/business/autos-transportation/nhtsa-opens-probe-into-24-mln-tesla-vehicles-over-full-self-driving-collisions-2024-10-18/">https://www.reuters.com/business/autos-transportation/nhtsa-opens-probe-into-24-mln-tesla-vehicles-over-full-self-driving-collisions-2024-10-18/</a>, See on <a href="https://news.ycombinator.com/item?id=41884740">Hacker News</a></p>
Couldn't get https://www.reuters.com/business/autos-transportation/nhtsa-opens-probe-into-24-mln-tesla-vehicles-over-full-self-driving-collisions-2024-10-18/: Error: Request failed with status code 401]]></description>
        </item>
    </channel>
</rss>