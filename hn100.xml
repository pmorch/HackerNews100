<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 24 Jan 2025 23:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[PhysicsForums and the Dead Internet Theory (201 pts)]]></title>
            <link>https://hallofdreams.org/posts/physicsforums/</link>
            <guid>42816284</guid>
            <pubDate>Fri, 24 Jan 2025 19:38:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hallofdreams.org/posts/physicsforums/">https://hallofdreams.org/posts/physicsforums/</a>, See on <a href="https://news.ycombinator.com/item?id=42816284">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2 id="what-internet-will-look-like-in-the-future">What Internet Will Look Like in the Future</h2><blockquote><p>cripes does anybody remember Google People</p><p>– qntm, <a href="https://twitter.com/qntm/status/1164301933949128709">August 21st, 2019</a></p></blockquote><p>Does anybody remember <a href="https://www.physicsforums.com/">PhysicsForums</a>?</p><p>It was never exactly the center of the Internet, but back when it was founded in 2001, the Internet didn’t really <em>have</em> a center the way it does today. PhysicsForums was one forum among thousands, founded by an enthusiastic teenager named Greg Bernhardt, existing in the ‘hard science’ niche alongside the likes of <a href="https://web.archive.org/web/20050105042334/http://www.badastronomy.com/phpBB/index.php">Bad Astronomy</a>, mostly focused on giving hints for physics homework to struggling students without outright <em>doing</em> the physics homework. It had fairly steady growth until 2012, before petering out throughout the 2010s and 2020s in lieu of more centralized sites like StackExchange, and by 2025, only a small community was left. But, unlike so many other fora from back in the early days, it went from 2003 to 2025 without ever changing its URLs, erasing its old posts, or going down altogether. Thanks to this consistency, PhysicsForums remains quite valuable as a time capsule, and can give us a glimpse at how people thought and what they said two decades ago.</p><p>For instance, we we might go to <a href="https://www.physicsforums.com/threads/spreadsheet-for-hp-50g-import-export-excel-calc.199904/">this 2007 post</a> asking about the capabilities of the now-obsolete <a href="https://commerce.hpcalc.org/50g.php">HP 50g Graphing Calculator</a>, and read a very helpful reply by commenter ravenprp:</p><p><img data-src="/assets/img/PhysicsForums/2007 - ravenprp 0.png" alt="user ravenprp claims to be a large language model in a forum post dated 2007" title="user ravenprp claims to be a large language model in a forum post dated 2007"></p><p>Something has gone terribly wrong.</p><h2 id="quoth-the-raven">Quoth the Raven?</h2><blockquote><p>I reset my pw and logged back in to Google People for the first time in 10 (?) years just now and discovered the following:</p><ol><li>10 years of updates on my account, written by me</li></ol><p>– qntm, <a href="https://twitter.com/qntm/status/1170471878642872321">September 7th, 2019</a></p></blockquote><p>At first glance, ravenprp is a very impressive user, writing 2,891 posts in a mere seven-month span (from September 2006 to April 2007) for average of more than thirteen posts per day. And most of these weren’t casual one-line answers: reading his profile, one comes away realizing that he’s a true <a href="https://tvtropes.org/pmwiki/pmwiki.php/Main/OmnidisciplinaryScientist">omnidisciplinary scientist</a>, if not a modern-day Renaissance Man. He’s a <a href="https://www.physicsforums.com/threads/instructional-robot-design-project.112146/#post-6998564">member of a university faculty</a>, a <a href="https://www.physicsforums.com/threads/how-do-you-measure-vibration-decay-in-damped-drumsticks.209340/#post-6999271">mechanical engineering student</a>, and a <a href="https://www.physicsforums.com/threads/what-are-the-essential-job-roles-in-a-basic-chemical-plant.164542/#post-6998735">hiring manager at a chemical plant</a> (presumably in <a href="https://www.physicsforums.com/threads/chem-eng-hot-career-option-for-canada.180877/#post-6998683">Canada</a>); he’s an expert in <a href="https://www.physicsforums.com/threads/looking-for-an-expert-with-vob-and-audio-files.134862/#post-6996856">working with .VOB and audio files</a> and <a href="https://www.physicsforums.com/threads/what-are-the-differences-between-bolts-screws-and-hi-lok-fasteners.154763/#post-6999349">fasteners</a>; he’s a <a href="https://www.physicsforums.com/threads/solving-multiple-couples-in-structural-engineering-analysis.188652/#post-6999291">structural engineer</a>, <a href="https://www.physicsforums.com/threads/take-your-side-dawkins-vs-dyson-debate.185437/#post-6998019">biologist</a>, <a href="https://www.physicsforums.com/threads/topical-webpage-title-what-are-the-best-freeware-options-for-medical-physics.198806/#post-6996805">medical physicist</a>, <a href="https://www.physicsforums.com/threads/optimize-your-sports-drink-with-advanced-chemist-suggestions-lemonade-flavor.130493/post-6997583">chemist</a>, and <a href="https://www.physicsforums.com/threads/air-frame-life-extension-f-15-problem.209836/#post-6999274">aerospace engineer</a>. And to top it all off, he’s modest, and won’t claim expertise he doesn’t have: he’s an aerospace and aeronautical engineer, but <a href="https://www.physicsforums.com/threads/an-aerodynamic-simulation-using-panel-method.197033/#post-6999260">not an expert in aerodynamics</a>, nor a <a href="https://www.physicsforums.com/threads/how-can-i-calculate-the-failure-load-for-a-cantilevered-hoist-assembly.177574/#post-6999314">mechanical engineer</a>, nor an <a href="https://www.physicsforums.com/threads/equivalent-electrical-model-for-spring-damper-circuit-seeking-advice.161781/#post-6998922">expert in electrical models</a>.</p><p>Impressively, these posts span from three years before the account was created to a year after the account was last logged into. And, as the icing on the cake, ravenprp is prescient enough that he can joke about being a language model developed by OpenAI, seven years before OpenAI was even founded; evidently he should have joined PsychicsForums instead.</p><p><img data-src="/assets/img/PhysicsForums/Ravenprp Collage.png" alt="user Ravenprp's many storied careers as a screenshot" title="user Ravenprp's many storied careers as a screenshot"></p><p>A reasonable question, reading these posts, is: what’s the deal with the joined and login dates? If this is an entirely fabricated account, then why not just set the account creation date to be earlier than the first post, and the account access date to be later than the last post? The Wayback Machine gives us an answer: while the account currently lists 2,891 posts, an <a href="https://web.archive.org/web/20190226113743/https://www.physicsforums.com/members/ravenprp.56793/">archive from 2019</a> lists 74. And looking at only these 74 gives a very different profile: ravenprp was an electrical engineering student asking for simple advice on <a href="https://www.physicsforums.com/threads/matlab-question-book-software-tools.141015/">MATLAB books</a>, working through <a href="https://www.physicsforums.com/threads/using-555-timer-ic-to-output-100-khz-frequency.141013/#post-1144566">integrated circuit problems</a>, giving other commenters useful links on <a href="https://www.physicsforums.com/threads/find-the-flow-rate-water-pipe-down-a-hill.131786/#post-1082624">the Bernoulli Equation</a>, and asking for help from knowledgeable experts, <a href="https://www.physicsforums.com/threads/is-a-microprocessor-the-same-as-a-microcontroller.152622/">such as computer professional ravenprp</a>.</p><p><img data-src="/assets/img/PhysicsForums/Ravenprp Q&amp;A.png" alt="user Ravenprp asks himself for advice" title="user Ravenprp asks himself for advice"></p><p>So it seems that this was a real account, once, and that ravenprp was a real person with real posts, opinions, questions, and answers. But any original thoughts and writings he might have had in 74 original posts have been all but drowned out by the 2,817 extra posts which have been added, backdated, and attributed to him.</p><p>Still, while finding those posts might be a challenge, at least those threads themselves are intact. For instance, he was <a href="https://www.physicsforums.com/threads/how-does-truck-speed-affect-beat-frequency-in-doppler-shift.131785/#post-1083659">helped in one thread by kyle8921</a>:</p><p><img data-src="/assets/img/PhysicsForums/kyle8921 and ravenprp.png" alt="user ravenprp asking for help with a homework question" title="user ravenprp asking for help with a homework question"></p><p>And the answer would seem pretty reasonable at first glance, were it not for two small problems:</p><ul><li>Kyle8921, oddly enough, decided to finish an incomplete LaTeX expression from ravenprp’s post before beginning his own answer.</li><li>Much like ravenprp, Kyle8921 posted the answer more than a year after he last logged in, <a href="https://www.physicsforums.com/members/kyle8921.27110/">and continued posting for more than three years after that</a>.</li></ul><p><img data-src="/assets/img/PhysicsForums/kyle8921 0.png" alt="Kyle8921's last login date along with a post long after that date" title="Kyle8921's last login date along with a post long after that date"></p><p>Exactly how deep does this go?</p><h2 id="the-internet-is-forever">The Internet is Forever</h2><blockquote><p>In regards to the dead internet hypothesis, the content that you’re enjoying today, will still be there tomorrow.</p><p>LoveMortuus, <a href="https://news.ycombinator.com/item?id=41055299">July 24th, 2024</a></p></blockquote><p>Founder Greg Bernhardt started PhysicsForums as a simple GHB bulletin board, and he gave each thread and post a unique numerical ID; unlike many modern sites, this ID was sequential, with the first post given the ID of 1, the second post 2, and so forth. Some of these posts, of course, have since been deleted for one reason or another (including the first two years’ worth of discussion, which is why post #1 is in 2003 and not 2001), so we would not expect the line of posts to be continuous and unbroken…but we <em>would</em> expect the line to be monotonically increasing, so long as no posts had been retroactively added to the database. Plotting a sample of 30,000 posts grabbed at random, we can see how that pattern holds up:</p><p><img data-src="/assets/img/PhysicsForums/PhysicsForums Post Anomalies Zoomed Out.png" alt="A graph of anomalous post dates, fully zoomed out from 2003-2025" title="A graph of anomalous post dates, fully zoomed out from 2003-2025"></p><p>For almost the entire history of PhysicsForums, that rule held true: if post A had a larger ID than post B, then post A had a later timestamp than post B. And anywhere that rule does not hold true, we can reasonably infer that the database has been altered and that a more recent post has been given an older date retroactively.</p><p>Database alteration and retroactive dating are not necessarily bad things. The biggest example came in 2022, when PhysicsForums merged with MathHelpBoards and incorporated its ~150,000 post archive, with each post given its original date. There are smaller examples within PhysicsForums history of a thread getting split (due to some off-topic but nevertheless useful) discussion, or a post getting deleted but then restored with a newer ID, or a database hiccough causing re-assignment, or various other entirely justifiable small-scale edits. But on March 11th of 2023, a handful of posts were added all up and down the timeline, followed by a bigger group in May, an even bigger one in October, and the largest of all in January and February of 2024.</p><p><img data-src="/assets/img/PhysicsForums/PhysicsForums Post Anomalies Zoomed In.png" alt="A zoomed in version of the graph highlighting anomalous posts which have been backdated" title="A zoomed in version of the graph highlighting anomalous posts which have been backdated"></p><p>By taking the highly anomalous post IDs and filtering out the MathHelpBoards import, and filtering out instances which seem plausibly close to their actual post times, we get an estimated 115,000 posts written by LLMs and attributed to humans. Without scraping the entire website, it’s difficult to say precisely how many users have had their profiles revived, but taking a representative sample, there are at bare minimum 110 users affected. These range from <a href="https://www.physicsforums.com/members/eljose79.79/">some of the earliest commenters</a>, to <a href="https://www.physicsforums.com/members/kyle8921.27110">one-time posters</a> to <a href="https://www.physicsforums.com/members/zefram.118/">long-time readers</a> to <a href="https://www.physicsforums.com/members/greg-bernhardt.1/">founder and site administrator Greg Bernhardt</a>. In every case, a name is being attached to viewpoints that person does not necessarily endorse; certainly <a href="https://www.physicsforums.com/threads/infinite-intersection-of-indexed-sets.514569/">an average science enthusiast would not probably not endorse the notion that 0.999… does not equal 1</a>, if he knew about it:</p><p><img data-src="/assets/img/PhysicsForums/BernhardtPointNineRepeating.png" alt="A post by Greg Bernhardt claiming .99999... != 1" title="A post by Greg Bernhardt claiming .99999... != 1" src="https://hallofdreams.org/assets/img/PhysicsForums/BernhardtPointNineRepeating.png"></p><p>But that’s the problem: they don’t know about it. We don’t know who most of these people are. We can’t get in touch with them. Many, if not most, have usernames either unique to PhysicsForums, or else so common elsewhere as to be useless for identification. They have moved on from PhysicsForums, living their lives, with no way of knowing what is or isn’t being said under their names, and no reason whatsoever to suspect anything is amiss. And maybe what’s said is accurate, or maybe it isn’t, but either way, with every additional post, the archives of the Internet are made just a little bit flatter, their own scientific contributions are diluted just a little bit more, and the portion of the Internet intentionally written by humans is shrunk just a little bit further.</p><h2 id="the-dead-internet-theory">The Dead Internet Theory</h2><blockquote><p>The internet feels empty and devoid of people…it’s like a hot air balloon with nothing inside.</p><p>Anonymage, <a href="https://i.4pcdn.org/x/1587947548944.png">“Dead Internet Theory (and much more)”</a>, September 16th, 2019</p></blockquote><p>The ‘Dead Internet Theory’ - the theory that much or most of the Internet consists of things not made by human beings - got its name in 2019, and has been slowly gaining popularity ever since. The theory as originally stated is a self-described ‘jumbled mess’, cites the ‘death’ of the Internet at about 2016 or 2017, and interestingly, predates almost every known LLM capable of writing convincing longform text; we tried a GPT-2 bot on /r/AskReddit two days after the original greentext, and the bot was noticed and called out within a handful of hours. And in 2016 or 2017, the state-of-the-art for text generation was Markov chains, and most bots online posted identical messages with no text generation at all.</p><p>The theory, and the general feeling that the Internet has changed shape, clearly had other root inspirations besides LLMs. Part of the feeling was probably due to the Internet opening up to a wider and wider global audience, with small community norms and standards simply not scaling up. Part of it was probably the device change from computer to smartphone encouraging a more passive role on the part of the audience. Part of it was probably algorithmic incentives towards more and more content engagement, as inevitable as <a href="https://slatestarcodex.com/2014/07/30/meditations-on-moloch/">Las Vegas’ extravagant casinos</a>, emerging from pure market forces and not attributable to any one person in particular.</p><p>But part of it <em>now</em>, six years later, is certainly LLMs.</p><p><img data-src="/assets/img/PhysicsForums/Anatomy of a PhysicsForums post.png" alt="A screenshot of a PhysicsForums post highlighting the vast amount of non-human generated content" title="A screenshot of a PhysicsForums post highlighting the vast amount of non-human generated content" width="400"></p><p>The thing is, it’s not like these non-human additions are adding value or usability in <a href="https://web.archive.org/web/20250115221948/https://www.physicsforums.com/threads/spreadsheet-for-hp-50g-import-export-excel-calc.199904/">the original ravenprp thread we started with</a>. You could argue that adding a summary is helpful… but that’s only the case if the summary is correct, and as we know, the AI generated summaries have a real tendency to enrich the facts with things that may or may not be accurate.</p><p>We can accept the addition of some links, etc, as a potential enrichment; though their intrusive nature is disruptive like any other advertisement, sometimes we accept disruption as part of what is needed to keep a website operating. The rest of the thread, though, is a LLM-generated post that contains exactly one true fact (the existence of the “HP 50g Connectivity Kit”), and otherwise contains nothing that is actually reflected in the <a href="https://literature.hpcalc.org/official/hp50g-um-en.pdf">HP 50g manual</a>, or anywhere else one might find genuine information about the calculator.</p><p>Finally, we have the FAQ. This FAQ is the only place in the entire thread which references the “GET” and “PUT” functions of HP 50g Spreadsheet, and is the only place the summary could be getting them from. For that matter, the FAQ the only place in the entire <em>internet</em> which references those functions; the manual doesn’t talk about them, or talk about the “HP 50g Spreadsheet” at all…and searching for “HP 50g Spreadsheet”, as of the time of writing, returns this thread and nothing else.</p><p>So while ravenprp’s post has a hint of correctness, the FAQ pulls only from the title and is entirely wrong, and the summary pulls primarily from the FAQ and is also entirely wrong. But the fact that these answers are <em>incorrect</em> is not actually the only problem. Instead of reading the replies, we can do a quick tally of the amount of space each section of this thread takes up:</p><div><table><thead><tr><th>Section</th><th>Word Count</th><th>Human?</th></tr></thead><tbody><tr><td>Summary</td><td>99</td><td>No</td></tr><tr><td>Springo</td><td>38</td><td>Yes</td></tr><tr><td>Phys.org</td><td>34</td><td>No</td></tr><tr><td>Shinny_head</td><td>11</td><td>Yes</td></tr><tr><td>Ravenprp</td><td>164</td><td>No</td></tr><tr><td>FAQ</td><td>260</td><td>No</td></tr></tbody></table></div><p>The LLM-written portions of this thread are 92% of the total word count. If this were a representative sample of the Internet, it would be reasonable to describe the Internet as ‘dead’.</p><p><img data-src="/assets/img/PhysicsForums/PhysicsForums Word Count Histogram.png" alt="A graph showing wordcounts by LLM vs humans on PhysicsForums" title="A graph showing wordcounts by LLM vs humans on PhysicsForums"></p><p>The situation across the entire PhysicsForums is not, fortunately, quite so dire yet. While the backdated LLM posts tend to be longer than average, they still make up only 1.6% of the total post count and 3% of the word count across all posts. The actual <em>deception</em> is still, even now, still a fairly small portion of the total. But, when counting in the LLM-generated FAQs and summaries - which, as we’ve seen, aren’t always accurate - the Dead Internet Theory seems to be vindicated, and only 66% of the words on the site were written by human beings. Two years ago, that number was close to 100%. Two years from now, then…who knows?</p><p>It is true that the old archives aren’t read all that frequently, so it could be argued that this is no great loss. Only three archived PhysicsForums post were shared on Twitter throughout all of 2024…and of those three, <a href="https://twitter.com/SheCelebratesND/status/1841278314033336661">one was a human sharing an bot-written post</a>, and <a href="https://twitter.com/BRAINCURES/status/1868329400133202057">another was a bot sharing a human-written post</a>. So really, does anyone care?</p><h2 id="man-vs-machine">Man vs Machine</h2><blockquote><p>“…using AI, one can generate tons of nonsense with very little work and overload us easily.” So far that hasn’t happened.</p><p>PeterDonis, <a href="https://www.physicsforums.com/threads/chatgpt-policy-pf-developing-policies-for-chatgpt.1048633/post-7131957">November 12th, 2024</a></p></blockquote><hr><blockquote><p>/* * Copyright (C) 2011-2012 DarkCore <a href="http://www.darkpeninsula.eu/">http://www.darkpeninsula.eu/</a> * Copyright (C) 2011-2012 Project SkyFire <a href="http://www.projectskyfire.org/">http://www.projectskyfire.org/</a> * Copyright (C) 2008-2012 TrinityCore <a href="http://www.trinitycore.org/">http://www.trinitycore.org/</a> * This program is free software; you can redistribute it and/or modify it * under the terms of the GNU General Public License as published by the * Free Software Foundation; either version 3 of the License, or (at your * option) any later version. * *</p><p>Nate810, <a href="https://www.physicsforums.com/threads/strong-inequality-hydrodynamics-flat-cylinder-in-water.1047623/#post-6886175">November 27th, 2022</a></p></blockquote><p>Certainly the community members of PhysicsForums care. In November of 2024, <a href="https://www.physicsforums.com/threads/why-are-these-pf-dates-inconsistent.1066951/">poster Renormalize noticed peculiar behavior by Azntoon</a>, and noticed specifically that Azntoon was posting in threads in 2022 despite having last logged on in 2012. The thread, however, soon came to the conclusion that it was some sort of database hiccough, and nothing more came of it. Interestingly, <a href="https://www.physicsforums.com/members/azntoon.271917">Azntoon’s last login date</a> has since changed to December of 2022, making him one of the only two LLM-affected users to have (apparently) logged on again since the backdating began.</p><p>Users were on the lookout for it as early as 2022: the forum regulars <a href="https://www.physicsforums.com/threads/chatgpt-policy-pf-developing-policies-for-chatgpt.1048633/">debated what the policy regarding ChatGPT-generated responses should be</a>, with Vanadium 50 complaining that the “barely-lucid posts” generated by ChatGPT create a lot of work and could be considered a DoS attack. The general consensus in the thread was summarized by PhysicsForums administrator Greg Bernhardt:</p><blockquote><p>I’m pretty sure stackoverflow is attempting to ban it. I think we should discourage it, but I am unsure how to “ban” it here. Well worth a discussion. At a minimum content from ChatGPT should be quoted.</p></blockquote><p>A few months later, the site celebrated April Fools’ Day of 2023 <a href="https://www.physicsforums.com/threads/why-are-avatars-showing-as-chatgpt-instead-of-user-names-on-pf-posts.1051274/">by temporarily changing all display names to ChatGPT</a>, a few weeks after the LLM backdated insertion had already started, but since this was on April 1st, nobody assumed that posts were <em>actually</em> being written by ChatGPT. Alexander R. Klotz, <a href="https://www.physicsforums.com/insights/roger-babsons-anti-gravity-contest/">one-time contributor to PhysicsForums’ Insights blog</a>, noted on Twitter <a href="https://twitter.com/AlexanderRKlotz/status/1680983219481772033">that his 2016 article had been edited without his knowledge</a>, but the edits seem to be limited to an LLM-generated summary awkwardly placed in the middle, and a manually-inserted author’s note from 2018. The actual scope of the change across and the addition of more than a hundred thousand posts is something we’ve seen no discussion of, anywhere, as of yet.</p><p>But the backdated <em>users</em> have all been hidden from the search’s autocomplete, and profile links have all been removed from their posts, presumably to make it more difficult to click the profile and notice that something is wrong.</p><p>Changes like this tend to be gradual: a slight drift over time, compromises made to keep the site afloat. When the community notices, it can all be explained, eased, and made bearable, even as everything changes inch by inch. If the community backlash is too great, it’s easy to backpedal and explain and have a lesser version of the change remain. Ultimately, the incentives towards making these changes will not go away. What decides how they work out is the judgement of the people making the changes and how the community responds to them.</p><h2 id="update-faqs">Update: FAQs</h2><p>During the writing of this post, the FAQs were actually noticed as well, and <a href="https://www.physicsforums.com/threads/low-quality-faq-sections-on-closed-threads-ai-generated.1068161/">a discussion thread</a> was created. It appears that they were not visible to logged-in users, explaining why the forum regulars did not notice: the average forum regular interested enough to go back and reread old posts will probably be logged in while doing so. The FAQs have now been removed, though the LLM-written summaries at the top of closed threads are still present.</p><h2 id="the-internet-is-people">The Internet is People</h2><blockquote><p>Could you provide a topic or theme<br> For the lyrics - for example, something like ‘A day at the beach’,<br> ‘A street party’, or ‘A journey through the city’?<br> This will help me provide a more focused and engaging song for you.</p><p><a href="https://youtu.be/2xyMHshBDB4">“Kito - Could You”, Kito’S Music Beats</a></p></blockquote><hr><blockquote><p>The dead internet theory is coming to fruition.</p><p>Greg Bernhardt, <a href="https://twitter.com/GregBernhardt4/status/1875287174205374533">January 3rd, 2025</a></p></blockquote><p>We reached out to Greg Bernhardt asking for comment on LLM usage in PhysicsForums, and he replied:</p><blockquote><p>We have many AI tests in the works to add value to the community. I sent out a 2024 feedback form to members a few weeks ago and many members don’t want AI features. We’ll either work with members to dramatically improve them or end up removing them. We experimented with AI answers from test accounts last year but they were not meeting quality standards. If you find any test accounts we missed, please let me know. My documentation was not the best.</p></blockquote><p>And in response to a follow-up question about the community feedback, he replied:</p><blockquote><p>Mathwonk originally raised the issue of quality. I worked with him to improve them using a newer model, but it’s still not good enough.</p><p>The backdated answers were an internal test. We conceived of a bot that would provide a quality answer to a thread without a reply after 1+ years. That too also failed. Instead, I’m considering pruning all threads without a reply as they clutter up the forums.</p></blockquote><p>It’s hard to imagine that 110 existing users gave consent to be used as test accounts, for 115,000 posts, over four waves spanning almost a year. The idea that these are test accounts gone wrong, or a bot accidentally mislabeled, doesn’t seem to align with the facts.</p><p>It also ties directly to an unstated but very real expectation: my identity in an online community is <em>mine</em>. I have accounts on forums that are older than some friendships. I have written tens of thousands of words under various identities. Just because they are relatively anonymous doesn’t make them less real to me, it doesn’t diminish the effort and time I put into the work done under those identities. Hijacking accounts, filling it with content their original owners did not write? That dilutes their efforts, and muddles their identities. The content was produced with the idea that it was <em>mine</em> in some capacity, inextricably tied to an identity I owned.</p><p>There’s also a social contract: when we create an account in an online community, we do it with the expectation that people we are going to interact with are primarily people. Oh, there will be shills, and bots, and advertisers, but the agreement between the users and the community provider is that they are going to try to defend us from that, and that in exchange we will provide our engagement and content. This is why the recent experiments from Meta with AI generated users are both ridiculous and sickening. When you might be interacting with something masquerading as a human, providing at best, tepid garbage, the value of human interaction via the internet is lost.</p><p>Beyond that, the idea of populating existing accounts with LLM-generated content is destructive. Like paving over an arboretum to make room for a generic strip mall. Internet archaeology is already a difficult and fraught business. It’s so difficult to find lost content, servers that have gone down, websites that are just <em>gone</em>… and now, apparently a lot of backdated data that is AI generated. This is not to say websites shouldn’t evolve and stay current, but this is different, this is a re-writing of history, and rewrites history for no clear gain.</p><p>It probably feels odd to see us write thousands of words fighting for the integrity of a community neither of us is part of, a tiny speck on the Internet trying desperately to survive, an enclave of a different era that is trying to hold on at all costs. But we are sympathetic. Running a website, especially a forum, is expensive. Server costs go up. Databases stop working and now you need to pay an expert or spend hours of unpaid time working on it. Bots flood in. DDOS attacks happen. Another wave of crypto-scams shows up. Staying alive on the internet costs money, and money comes through users and ads. You need those clicks like a man in the desert needs water, and every week it gets more competitive.</p><p>One must transform to survive. That axiom is a truth on the internet. If you don’t, you rapidly find yourself buried on the eighth page of Google results, with no users and no money to keep the servers up. But when communities compromise their morals and the core of their identity to stay afloat, and destroy the very bedrock of their commitment to their users and to some degree to the broader idea of the Internet, we have to wonder… was it worth it?</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Subpixel Snake [video] (175 pts)]]></title>
            <link>https://www.youtube.com/watch?v=iDwganLjpW0</link>
            <guid>42815288</guid>
            <pubDate>Fri, 24 Jan 2025 17:21:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=iDwganLjpW0">https://www.youtube.com/watch?v=iDwganLjpW0</a>, See on <a href="https://news.ycombinator.com/item?id=42815288">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[A WebAssembly compiler that fits in a tweet (178 pts)]]></title>
            <link>https://wasmgroundup.com/blog/wasm-compiler-in-a-tweet/</link>
            <guid>42814948</guid>
            <pubDate>Fri, 24 Jan 2025 16:51:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wasmgroundup.com/blog/wasm-compiler-in-a-tweet/">https://wasmgroundup.com/blog/wasm-compiler-in-a-tweet/</a>, See on <a href="https://news.ycombinator.com/item?id=42814948">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__blog-post-container" itemprop="articleBody">
<!-- -->
<!-- -->
<!-- -->
<h2>Introduction</h2>
<p>One of the initial explorations that started this book was how small and simple a compile-to-WebAssembly language implemented in JavaScript could be. Our first “WebAssembly compiler in a tweet” was 269 bytes; since then, we’ve managed to whittle it down to a measly 192 bytes.</p>
<p>The final result is a compiler that takes an arithmetic expression — written in reverse polish notation — and compiles it down to a valid WebAssembly module. That module exports a single function which returns the result of the original arithmetic expression. Here it is:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>let c=(b,l)=&gt;WebAssembly.instantiate(new Int8Array(</span></p></div><div><p><span>[,97,115,109,1,,,,1,5,1,96,,1,127,3,2,1,,7,4,1,,,,10,</span></p></div><div><p><span>l=(b=b.split` `.flatMap(t=&gt;t&gt;-1?[65,t]:107+'-*/'.indexOf(t)))</span></p></div><div><p><span>.length+4,1,l-2,,...b,11]))</span></p></div><br></code></p></div>
<p>And here’s an example of how you can use it:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>(await c('11 11 1 - + 4 * 2 /')).instance.exports['']()</span></p></div><br></code></p></div>
<p>But this is not just a clever trick — if you take the time to understand what this code does, you’ll learn a surprising amount about WebAssembly! In the rest of the post, we’ll explain how it all works by de-obfuscating the code one step at a time.</p>
<p>You can play with the code in this post here: <a href="https://stackblitz.com/edit/rpn-to-wasm-js-compiler?file=index.js" target="_blank" rel="noopener noreferrer">stackblitz.com/edit/rpn-to-wasm-js-compiler</a>.</p>
<h2>Format</h2>
<p>The first thing we can do to make it more readable is to format it:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>let c1 = (b, l) =&gt;</span></p></div><div><p><span>  WebAssembly.instantiate(</span></p></div><div><p><span>    new Int8Array([</span></p></div><div><p><span>      , 97, 115, 109, 1, , , , 1, 5, 1, 96, , 1, 127, 3, 2, 1, , 7, 4, 1, , , , 10,</span></p></div><div><p><span>      (l = (b = b.split` `.flatMap(</span></p></div><div><p><span>            (t) =&gt; t &gt; -1 ? [65, t] : 107 + "-*/".indexOf(t)</span></p></div><div><p><span>           )).length + 4),</span></p></div><div><p><span>      1, l - 2, , ...b, 11</span></p></div><div><p><span>    ])</span></p></div><div><p><span>  );</span></p></div><br></code></p></div>
<p>While it’s still pretty unreadable, now we can at least identify different parts of the code.</p>
<p>At a high level, what we’re doing is ‘parsing’ the expression in a very simple way, turning it into the appropriate Wasm bytecode,
and then hand-crafting the bytes for a single-function module.</p>
<p>In a more complex compiler you would probably use a library to generate the WebAssembly module and compile the expressions but our main metric
here is code size so we write the bytes directly in an array.</p>
<h2>Remove Assignment Expression</h2>
<p>The first trick to undo is the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Assignment" target="_blank" rel="noopener noreferrer">assignment expression</a>.</p>
<p>In JavaScript the assignment operator is an expression. This means that it generates a result after evaluating, as you can see in the following examples:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>let a, b;</span></p></div><div><p><span>console.log('a', a = 42);</span></p></div><div><p><span>a = b = 43;</span></p></div><div><p><span>console.log('b', b);</span></p></div><br></code></p></div>
<p>The code above will output:</p>

<p>This is because <code>a = 42</code> assigns <code>42</code> to <code>a</code> and the whole assignment expression evaluates to the value being assigned.</p>
<p>In <code>a = b = 43</code>, we assign the result of evaluating <code>b = 43</code> to <code>a</code>. This equivalent expression may be easier to understand: <code>a = (b = 43)</code>.</p>
<p>In our code, we use this trick to reuse variables and update their value in places where
we can also use the value being assigned. It also allows us to have our compiler in a single expression, avoiding the need for curly braces, semicolons and return statements.</p>
<p>To undo it, we turn the body of our function into a block and do each assignment on its own line:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>let c2 = (b, l) =&gt; {</span></p></div><div><p><span>  b = b.split` `.flatMap(</span></p></div><div><p><span>    (t) =&gt; (t &gt; -1 ? [65, t] : 107 + "-*/".indexOf(t))</span></p></div><div><p><span>  );</span></p></div><div><p><span>  l = b.length + 4;</span></p></div><div><p><span>  return WebAssembly.instantiate(</span></p></div><div><p><span>    new Int8Array([</span></p></div><div><p><span>      , 97, 115, 109, 1, , , , 1, 5, 1, 96, , 1, 127, 3, 2, 1, , 7, 4, 1, , , ,</span></p></div><div><p><span>      10, l, 1, l - 2, , ...b, 11</span></p></div><div><p><span>    ]),</span></p></div><div><p><span>  );</span></p></div><div><p><span>};</span></p></div><br></code></p></div>
<h2>Undo Variable Tricks</h2>
<p>Now the assignments are easier to identify but the meaning of variables and function
arguments are still hard to understand. Let’s fix that by undoing a couple of variable tricks.</p>
<p>The first step is to stop using single letter variables, and to use more descriptive names instead. The next step is to stop reusing variables: for example, <code>b</code> initially holds the code to compile, but once we don’t need that any more we reuse it to hold the bytecode instructions.</p>
<p>To undo this we are going to introduce a new <code>instrs</code> variable and rename <code>b</code> to <code>code</code>. We’ll also rename <code>l</code> to <code>len</code>. This variable contains a value that is close to the number of bytecodes.</p>
<p>By declaring <code>l</code> in the body we can remove it from the function argument’s list. We did this
as a trick to avoid the need to declare it with <code>let</code> or <code>const</code>, saving some bytes and the need for a function body.</p>
<p>The trick works by adding unused arguments at the end of the function argument list and using them as local variables. Our compiler function expects a single argument with the code; <code>l</code> is there for us to use since we don’t expect the caller to provide any value for it.</p>
<p>Here’s the code without this trick:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>let c3 = (code) =&gt; {</span></p></div><div><p><span>  const instrs = code.split` `.flatMap(</span></p></div><div><p><span>    (t) =&gt; (t &gt; -1 ? [65, t] : 107 + "-*/".indexOf(t))</span></p></div><div><p><span>  );</span></p></div><div><p><span>  const len = instrs.length + 4;</span></p></div><div><p><span>  return WebAssembly.instantiate(</span></p></div><div><p><span>    new Int8Array([</span></p></div><div><p><span>      , 97, 115, 109, 1, , , , 1, 5, 1, 96, , 1, 127, 3, 2, 1, , 7, 4, 1, , , ,</span></p></div><div><p><span>      10, len, 1, len - 2, , ...instrs, 11</span></p></div><div><p><span>    ]),</span></p></div><div><p><span>  );</span></p></div><div><p><span>};</span></p></div><br></code></p></div>
<h2>Add Missing Zeros</h2>
<p>If you look at the array in our code, you may notice that there are many commas followed by another comma instead of a value. This syntax defines “sparse arrays”. Here’s an example:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>const a1 = [,,];</span></p></div><div><p><span>console.log(a1.length); // Output: 2</span></p></div><div><p><span>console.log(a1); // Output: [ &lt;2 empty items&gt; ]</span></p></div><br></code></p></div>
<p>Which is equivalent to:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>const a2 = new Array(2);</span></p></div><div><p><span>console.log(a2.length); // Output: 2</span></p></div><div><p><span>console.log(a2); // Output: [ &lt;2 empty items&gt; ]</span></p></div><br></code></p></div>
<p>We use this syntactic trick to save one byte each time we need a <code>0</code> to appear in the array. This works because <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Typed_arrays" target="_blank" rel="noopener noreferrer">Typed Arrays</a> coerce all array items to numbers, and an “empty item” will be converted to 0:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>new Int8Array([0, null, undefined,,0])</span></p></div><br></code></p></div>
<p>which produces:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>Int8Array(5) [ 0, 0, 0, 0, 0 ]</span></p></div><br></code></p></div>
<p>Let’s undo this trick by adding all the zeroes back:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>let c4 = (code) =&gt; {</span></p></div><div><p><span>  const instrs = code.split` `.flatMap(</span></p></div><div><p><span>    (t) =&gt; (t &gt; -1 ? [65, t] : 107 + "-*/".indexOf(t))</span></p></div><div><p><span>  );</span></p></div><div><p><span>  const len = instrs.length + 4;</span></p></div><div><p><span>  return WebAssembly.instantiate(</span></p></div><div><p><span>    new Int8Array([</span></p></div><div><p><span>      0, 97, 115, 109, 1, 0, 0, 0, 1, 5, 1, 96, 0, 1, 127, 3, 2, 1, 0, 7, 4, 1, 0, 0, 0,</span></p></div><div><p><span>      10, len, 1, len - 2, 0, ...instrs, 11</span></p></div><div><p><span>    ]),</span></p></div><div><p><span>  );</span></p></div><div><p><span>};</span></p></div><br></code></p></div>
<h2>Remove Extra 4 bytes on Length Definition</h2>
<p>In our code, we have a variable <code>len</code> that contains a number that is close to the number
of bytecodes in the compiled expression, but not exactly the same:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>  const len = instrs.length + 4;</span></p></div><br></code></p></div>
<p>In the WebAssembly module we need to use the number of bytes in the function body (the expression to evaluate) in two places:</p>
<ul>
<li>To define the code section’s length</li>
<li>To define the function body’s length</li>
</ul>
<p>Since there’s only one function in the code section both values are similar:</p>
<ul>
<li>The section takes two extra bytes (section identifier and number of code entries)</li>
<li>The function body takes another two bytes (number of locals and <code>end</code> instruction)</li>
</ul>
<p>To avoid writing <code>b.length</code> twice we assign to <code>l</code> the value of <code>b.length + 4</code> in the place where we need the code section byte count
and then calculate <code>l - 2</code> (<code>b.length + 2</code>) where we need the function body byte count.</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>[</span></p></div><div><p><span>  ...</span></p></div><div><p><span>  l=(b=b.split` `.flatMap(t=&gt;t&gt;-1?[65,t]:107+'-*/'.indexOf(t))).length+4,1,l-2</span></p></div><div><p><span>  ...</span></p></div><div><p><span>]</span></p></div><br></code></p></div>
<p>This is all a trick to avoid having to write <code>b.length</code> twice.</p>
<p>let’s assign the length to <code>len</code> and calculate the right value in each place:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>let c5 = (code) =&gt; {</span></p></div><div><p><span>  const instrs = code.split` `.flatMap(</span></p></div><div><p><span>    (t) =&gt; (t &gt; -1 ? [65, t] : 107 + "-*/".indexOf(t))</span></p></div><div><p><span>  );</span></p></div><div><p><span>  const len = instrs.length;</span></p></div><div><p><span>  return WebAssembly.instantiate(</span></p></div><div><p><span>    new Int8Array([</span></p></div><div><p><span>      0, 97, 115, 109, 1, 0, 0, 0, 1, 5, 1, 96, 0, 1, 127, 3, 2, 1, 0, 7, 4, 1, 0, 0, 0,</span></p></div><div><p><span>      10, 4 + len, 1, 2 + len, 0, ...instrs, 11</span></p></div><div><p><span>    ]),</span></p></div><div><p><span>  );</span></p></div><div><p><span>};</span></p></div><br></code></p></div>
<h2>Remove String Template Literal Instead of Function Call</h2>
<p>The next trick to undo is <code>code.split` `</code>. In this case, we use the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals#tagged_templates" target="_blank" rel="noopener noreferrer">Tagged Template</a> feature of <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals" target="_blank" rel="noopener noreferrer">String Template Literals</a>.</p>
<p>Let’s see how it works by creating a simple tagged template that turns the string to uppercase:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>function upper(s) {</span></p></div><div><p><span>  return s[0].toUpperCase();</span></p></div><div><p><span>}</span></p></div><br></code></p></div>
<p>And use it:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>upper`Hello, World!`</span></p></div><div><p><span>&gt; "HELLO, WORLD!"</span></p></div><br></code></p></div>
<p>As you can see, the first argument to the tagged template function is an array. Luckily for us, the first argument of <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/split#separator" target="_blank" rel="noopener noreferrer">String.prototype.split</a> is handled in the following way:</p>
<blockquote>
<p>All values that are not undefined or objects with a <code>[Symbol.split]()</code> method are coerced to strings.</p>
</blockquote>
<p>And coercing an array with one string in it is the same as the string itself:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>["hello"].toString()</span></p></div><div><p><span>&gt; "hello"</span></p></div><br></code></p></div>

<p>Since the function we want to call takes a single string argument, we can use it as a tagged template and save the parentheses in the function call.</p>
<p>Let’s write it as a function call instead:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>let c6 = (code) =&gt; {</span></p></div><div><p><span>  const instrs = code.split(' ').flatMap(</span></p></div><div><p><span>    (t) =&gt; (t &gt; -1 ? [65, t] : 107 + "-*/".indexOf(t))</span></p></div><div><p><span>  );</span></p></div><div><p><span>  const len = instrs.length;</span></p></div><div><p><span>  return WebAssembly.instantiate(</span></p></div><div><p><span>    new Int8Array([</span></p></div><div><p><span>      0, 97, 115, 109, 1, 0, 0, 0, 1, 5, 1, 96, 0, 1, 127, 3, 2, 1, 0, 7, 4, 1, 0, 0, 0,</span></p></div><div><p><span>      10, 4 + len, 1, 2 + len, 0, ...instrs, 11</span></p></div><div><p><span>    ]),</span></p></div><div><p><span>  );</span></p></div><div><p><span>};</span></p></div><br></code></p></div>
<h2>Remove the Ternary Operator</h2>
<p>Next, let’s undo the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Conditional_operator" target="_blank" rel="noopener noreferrer">Ternary Operator</a> and turn it into an <em>if</em> statement.</p>
<p>The ternary operator has expressions on each branch saving us the <code>return</code> statements. Here’s what the code looks like when we use an <em>if</em> statement instead:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>let c7 = (code) =&gt; {</span></p></div><div><p><span>  const instrs = code.split(" ").flatMap((t) =&gt; {</span></p></div><div><p><span>    if (t &gt; -1) {</span></p></div><div><p><span>      return [65, t];</span></p></div><div><p><span>    } else {</span></p></div><div><p><span>      return 107 + "-*/".indexOf(t);</span></p></div><div><p><span>    }</span></p></div><div><p><span>  });</span></p></div><div><p><span>  const len = instrs.length;</span></p></div><div><p><span>  return WebAssembly.instantiate(</span></p></div><div><p><span>    new Int8Array([</span></p></div><div><p><span>      0, 97, 115, 109, 1, 0, 0, 0, 1, 5, 1, 96, 0, 1, 127, 3, 2, 1, 0, 7, 4, 1, 0, 0, 0,</span></p></div><div><p><span>      10, 4 + len, 1, 2 + len, 0, ...instrs, 11</span></p></div><div><p><span>    ]),</span></p></div><div><p><span>  );</span></p></div><div><p><span>};</span></p></div><br></code></p></div>
<h2>Remove Number Check With Coercion</h2>
<p>The next trick to undo is the one present twice in the following code:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>    if (t &gt; -1) {</span></p></div><div><p><span>      return [65, t];</span></p></div><div><p><span>    }</span></p></div><br></code></p></div>
<p>First we use coercion in <code>t &gt; -1</code> to check if the token <code>t</code> is a string representing a
positive number. Then we use coercion again in <code>[65, t]</code> to let JavaScript turn <code>t</code> into a <code>Number</code> in the <code>Int8Array</code>:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>new Int8Array([65, '42'])</span></p></div><br></code></p></div>
<p>The code above evaluates to:</p>

<p>Let’s write the parsing and checking explicitly:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>let c8 = (code) =&gt; {</span></p></div><div><p><span>  const instrs = code.split(" ").flatMap((t) =&gt; {</span></p></div><div><p><span>    const num = parseInt(t, 10);</span></p></div><div><p><span>    if (Number.isFinite(num)) {</span></p></div><div><p><span>      return [65, num];</span></p></div><div><p><span>    } else {</span></p></div><div><p><span>      return 107 + "-*/".indexOf(t);</span></p></div><div><p><span>    }</span></p></div><div><p><span>  });</span></p></div><div><p><span>  const len = instrs.length;</span></p></div><div><p><span>  return WebAssembly.instantiate(</span></p></div><div><p><span>    new Int8Array([</span></p></div><div><p><span>      0, 97, 115, 109, 1, 0, 0, 0, 1, 5, 1, 96, 0, 1, 127, 3, 2, 1, 0, 7, 4, 1, 0, 0, 0,</span></p></div><div><p><span>      10, 4 + len, 1, 2 + len, 0, ...instrs, 11</span></p></div><div><p><span>    ]),</span></p></div><div><p><span>  );</span></p></div><div><p><span>};</span></p></div><br></code></p></div>
<p>The semantics of our compiler change a little bit here. The original version will only accept
positive integers as input; if you want a negative number you have to subtract from zero: <code>0 - 1</code> to get <code>-1</code>. The new version allows negative numbers since it checks with <code>Number.isFinite(num)</code> instead of <code>t &gt; -1</code>.</p>
<h2>Remove indexOf -1 Trick</h2>
<p>The next trick is in the <em>else</em> branch:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>      return 107 + "-*/".indexOf(t);</span></p></div><br></code></p></div>
<p>Our calculator compiler only accepts four arithmetic operations: <code>+</code>, <code>-</code>, <code>*</code>, and <code>/</code>. But
in the code above you can only see three: <code>-*/</code> and a magical number: <code>107</code>. Here’s how it works — these are the bytecode numbers for arithmetic operations in WebAssembly:</p>
<ul>
<li><code>+</code>: <code>106</code></li>
<li><code>-</code>: <code>107</code></li>
<li><code>*</code>: <code>108</code></li>
<li><code>/</code>: <code>109</code></li>
</ul>
<p>We only enter this branch if the token <code>t</code> is not a number, which means it can only be
one of the arithmetic operators above. So, given a single character which is one of those four operators, we want to produce the appropriate opcode.</p>
<p>We <em>could</em> have written <code>106 + "+-*/".indexOf(t)</code>. That is, we find the symbol’s index in the string:</p>
<ul>
<li><code>+</code>: <code>0</code></li>
<li><code>-</code>: <code>1</code></li>
<li><code>*</code>: <code>2</code></li>
<li><code>/</code>: <code>3</code></li>
</ul>
<p>…and add <code>106</code> to it to get the bytecode number. But when <code>t</code> is not in the string, <code>"+-*/"</code> <code>indexOf</code> returns <code>-1</code>. We can use that to our advantage, and treat <code>-1</code> to mean “plus or any other token”:</p>
<ul>
<li><code>+</code>: <code>-1</code> (any other token will be <code>-1</code> too)</li>
<li><code>-</code>: <code>0</code></li>
<li><code>*</code>: <code>1</code></li>
<li><code>/</code>: <code>2</code></li>
</ul>
<p>And that’s why we add <code>107</code> instead of <code>106</code>. Let’s undo the <code>-1</code> trick:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>let c9 = (code) =&gt; {</span></p></div><div><p><span>  const instrs = code.split(" ").flatMap((t) =&gt; {</span></p></div><div><p><span>    const num = parseInt(t, 10);</span></p></div><div><p><span>    if (Number.isFinite(num)) {</span></p></div><div><p><span>      return [65, num];</span></p></div><div><p><span>    } else {</span></p></div><div><p><span>      return 106 + "+-*/".indexOf(t);</span></p></div><div><p><span>    }</span></p></div><div><p><span>  });</span></p></div><div><p><span>  const len = instrs.length;</span></p></div><div><p><span>  return WebAssembly.instantiate(</span></p></div><div><p><span>    new Int8Array([</span></p></div><div><p><span>      0, 97, 115, 109, 1, 0, 0, 0, 1, 5, 1, 96, 0, 1, 127, 3, 2, 1, 0, 7, 4, 1, 0, 0, 0,</span></p></div><div><p><span>      10, 4 + len, 1, 2 + len, 0, ...instrs, 11</span></p></div><div><p><span>    ]),</span></p></div><div><p><span>  );</span></p></div><div><p><span>};</span></p></div><br></code></p></div>
<p>Here again the semantics change a little bit. Before, if the token <code>t</code> wasn’t found, the expression would evaluate to <code>107 + -1</code> which would map to an addition. Now it will evaluate to <code>106 + -1</code> which will map to bytecode <code>105</code> which is the <a href="https://developer.mozilla.org/en-US/docs/WebAssembly/Reference/Numeric/Population_count" target="_blank" rel="noopener noreferrer"><code>popcnt</code></a> instruction.</p>
<p>But don’t worry, we’ll fix it in the next step.</p>
<h2>Remove indexOf Trick</h2>
<p>After explaining how the <code>indexOf</code> trick works and removing the <code>-1</code> part, let’s
go ahead and remove the trick completely. To do it we are going to create an object that maps from an arithmetic operation token to its bytecode:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>const OP_TO_BYTECODE = {</span></p></div><div><p><span>  "+": 106,</span></p></div><div><p><span>  "-": 107,</span></p></div><div><p><span>  "*": 108,</span></p></div><div><p><span>  "/": 109,</span></p></div><div><p><span>};</span></p></div><div><p><span>let c10 = (code) =&gt; {</span></p></div><div><p><span>  const instrs = code.split(" ").flatMap((t) =&gt; {</span></p></div><div><p><span>    const num = parseInt(t, 10);</span></p></div><div><p><span>    if (Number.isFinite(num)) {</span></p></div><div><p><span>      return [65, num];</span></p></div><div><p><span>    } else {</span></p></div><div><p><span>      return OP_TO_BYTECODE[t] ?? 106;</span></p></div><div><p><span>    }</span></p></div><div><p><span>  });</span></p></div><div><p><span>  const len = instrs.length;</span></p></div><div><p><span>  return WebAssembly.instantiate(</span></p></div><div><p><span>    new Int8Array([</span></p></div><div><p><span>      0, 97, 115, 109, 1, 0, 0, 0, 1, 5, 1, 96, 0, 1, 127, 3, 2, 1, 0, 7, 4, 1, 0, 0, 0,</span></p></div><div><p><span>      10, 4 + len, 1, 2 + len, 0, ...instrs, 11</span></p></div><div><p><span>    ]),</span></p></div><div><p><span>  );</span></p></div><div><p><span>};</span></p></div><br></code></p></div>
<p>To keep the initial semantics, if the token is not a valid operation we return the bytecode for <code>+</code>: in <code>OP_TO_BYTECODE[t] ?? 106</code>.</p>
<h2>Remove the Empty Export Name</h2>
<p>From the usage example at the beginning of the post, you may have noticed that the exported
function’s name is the empty string:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>(await c('11 11 1 - + 4 * 2 /')).instance.exports['']()</span></p></div><br></code></p></div>
<p>We did this to save us the bytes needed to specify the export name,
but also to save an extra byte/character in the code because with the length of the export name being <code>0</code>
we can use the sparse array syntax to leave an empty spot in the WebAssembly module array.</p>
<p>To revert this trick we are going to name the exported function as <code>a</code>, which in UTF-8 is the byte <code>97</code>:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>&gt; new TextEncoder().encode('a')[0]</span></p></div><div><p><span>97</span></p></div><br></code></p></div>
<div data-ch-theme="nord"><p><code><br><div><p><span>const OP_TO_BYTECODE = {</span></p></div><div><p><span>  "+": 106,</span></p></div><div><p><span>  "-": 107,</span></p></div><div><p><span>  "*": 108,</span></p></div><div><p><span>  "/": 109,</span></p></div><div><p><span>};</span></p></div><div><p><span>let c11 = (code) =&gt; {</span></p></div><div><p><span>  const instrs = code.split(" ").flatMap((t) =&gt; {</span></p></div><div><p><span>    const num = parseInt(t, 10);</span></p></div><div><p><span>    if (Number.isFinite(num)) {</span></p></div><div><p><span>      return [65, num];</span></p></div><div><p><span>    } else {</span></p></div><div><p><span>      return OP_TO_BYTECODE[t] ?? 106;</span></p></div><div><p><span>    }</span></p></div><div><p><span>  });</span></p></div><div><p><span>  const len = instrs.length;</span></p></div><div><p><span>  return WebAssembly.instantiate(</span></p></div><div><p><span>    new Int8Array([</span></p></div><div><p><span>      0, 97, 115, 109, 1, 0, 0, 0, 1, 5, 1, 96, 0, 1, 127, 3, 2, 1, 0, 7, 5, 1, 1, 97, 0, 0,</span></p></div><div><p><span>      10, 4 + len, 1, 2 + len, 0, ...instrs, 11</span></p></div><div><p><span>    ]),</span></p></div><div><p><span>  );</span></p></div><div><p><span>};</span></p></div><br></code></p></div>
<p>We can now call it with a nicer name:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>(await c11('11 11 1 - + 4 * 2 /')).instance.exports.a()</span></p></div><br></code></p></div>
<h2>Implicit Design Decisions</h2>
<p>Our initial implementation only supported positive numbers, but that’s not the only number restriction in our compiler.</p>
<p>To keep WebAssembly modules as small as possible, numbers are encoded using a variable-length encoding algorithm called <a href="https://en.wikipedia.org/wiki/LEB128" target="_blank" rel="noopener noreferrer">LEB128</a>. You can tell we are not implementing the whole algorithm by looking at the part of the code that encodes numbers: <code>[65,t]</code>. We’re assuming the number being encoded fits in 7 bits, the shortest possible LEB128 representation.</p>
<p>Let’s try the limits of our implementation:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>(await c('63')).instance.exports['']();</span></p></div><div><p><span>&gt; 63</span></p></div><br></code></p></div>
<div data-ch-theme="nord"><p><code><br><div><p><span>(await c('64')).instance.exports['']();</span></p></div><div><p><span>&gt; -64</span></p></div><br></code></p></div>
<p>This means the only numbers that will be parsed correctly are from <code>0</code> to <code>63</code>.</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>(await c('127')).instance.exports['']();</span></p></div><div><p><span>&gt; -1</span></p></div><br></code></p></div>
<div data-ch-theme="nord"><p><code><br><div><p><span>(await c('128')).instance.exports['']();</span></p></div><br></code></p></div>
<p>Fails with:</p>
<blockquote>
<p>Uncaught CompileError: WebAssembly.instantiate(): Compiling function #0 failed: function body must end with “end” opcode @+33</p>
</blockquote>
<p>In the last one we went over the 7 bits and the module was rejected during validation.</p>
<p>Explaining and implementing LEB128 takes a lot of text and code. If you want to read more
about it we have a whole deep dive on LEB128 in <a href="https://wasmgroundup.com/" target="_blank" rel="noopener noreferrer">our book</a>.</p>
<h2>A Trick that Almost Worked</h2>
<p>During the code golfing phase I had a literal shower thought but sadly it didn’t work.</p>
<p>The idea was to simplify <code>106 + "+-*/".indexOf(t)</code> by using the UTF-8 character code plus an offset like this: <code>63 + t.charCodeAt()</code> and saving 3 bytes in the process. The reason it didn’t work is that the characters <code>+-*/</code> don’t appear in the same order in UTF-8 and WebAssembly bytecode.</p>
<h2>Explaining the Numbers in the Array</h2>
<p>The last part to expand/explain is the array of numbers used to build the WebAssembly module.</p>
<p>It takes a big part of a <a href="https://www.w3.org/TR/2019/REC-wasm-core-1-20191205/" target="_blank" rel="noopener noreferrer">specification</a> to explain every byte in the array, but here’s a commented version that should give you a high level idea of what each part does:</p>
<div data-ch-theme="nord"><p><code><br><div><p><span>    [</span></p></div><div><p><span>      // Wasm module magic number '\0asm'</span></p></div><div><p><span>      [0, 97, 115, 109],</span></p></div><div><p><span>      // Wasm version 1.0</span></p></div><div><p><span>      [1, 0, 0, 0],</span></p></div><div><p><span>      // ----- type section -----</span></p></div><div><p><span>      1, // Section identifier</span></p></div><div><p><span>      5, // Section size in bytes</span></p></div><div><p><span>      1, // Number of entries that follow</span></p></div><div><p><span>      // type section - entry 0</span></p></div><div><p><span>      96, // Type `function`</span></p></div><div><p><span>      0,  // Number of parameters</span></p></div><div><p><span>      1,  // Number of return values</span></p></div><div><p><span>      127, // return type i32</span></p></div><div><p><span>      // ----- function section -----</span></p></div><div><p><span>      3, // Section identifier</span></p></div><div><p><span>      2, // Section size in bytes</span></p></div><div><p><span>      1, // Number of entries that follow</span></p></div><div><p><span>      // function section - entry 0</span></p></div><div><p><span>      0, // Index of the type section entry</span></p></div><div><p><span>      // ----- export section -----</span></p></div><div><p><span>      7, // Section identifier</span></p></div><div><p><span>      5, // Section size in bytes</span></p></div><div><p><span>      1, // Number of entries that follow</span></p></div><div><p><span>      // export section - entry 0</span></p></div><div><p><span>      1,  // Name size in bytes</span></p></div><div><p><span>      97, // String as utf-8 bytes for 'a'</span></p></div><div><p><span>      0,  // Export type `function`</span></p></div><div><p><span>      0,  // Function Index</span></p></div><div><p><span>      // ----- code section -----</span></p></div><div><p><span>      10, // Section identifier</span></p></div><div><p><span>      4 + len, // Section size in bytes</span></p></div><div><p><span>      1, // Number of entries that follow</span></p></div><div><p><span>      // code section - entry 0</span></p></div><div><p><span>      2 + len, // Entry size in bytes</span></p></div><div><p><span>      0, // Number of local variables</span></p></div><div><p><span>      ...instrs,</span></p></div><div><p><span>      11, // `end` instruction</span></p></div><div><p><span>    ]</span></p></div><br></code></p></div>
<h2>Conclusion</h2>
<p>There you go! We’ve turned a rather opaque 192-byte snippet into something that’s almost readable. And in the process, you hopefully learned a little bit about WebAssembly.</p>
<p>If we dropped the size restrictions, there are lots of things we might want to improve in this compiler: handle numbers greater than 127, add nicer syntax, add support for conditionals, loops, etc. If you’re interested in what that might look like, I encourage you to check out our book <a href="https://wasmgroundup.com/" target="_blank" rel="noopener noreferrer">WebAssembly from the Ground Up</a>. You’ll learn the ins and outs of WebAssembly by writing a real compiler for a simple programming language. It’s a lot of fun!</p>
<p>Special thanks to <a href="https://bsky.app/profile/orthoplex.bsky.social" target="_blank" rel="noopener noreferrer">lexi</a> for contributing some of the tricks used above.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Snowdrop OS – a homebrew operating system from scratch, in assembly language (149 pts)]]></title>
            <link>http://sebastianmihai.com/snowdrop/</link>
            <guid>42814820</guid>
            <pubDate>Fri, 24 Jan 2025 16:40:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://sebastianmihai.com/snowdrop/">http://sebastianmihai.com/snowdrop/</a>, See on <a href="https://news.ycombinator.com/item?id=42814820">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="snowdrop-contentpanel">

<h2>Introduction section</h2>
<p>

Welcome to the pages of Snowdrop OS, my homebrew operating system project.
</p><p><img alt="" src="http://sebastianmihai.com/snowdrop/images/snowdrop-intro.jpg"></p>

<p>Snowdrop OS was born of my childhood curiosity around what happens when a PC is turned on, the mysteries of bootable disks, and the hidden aspects of operating systems. It is a 16-bit real mode operating system for the IBM PC architecture. I designed and developed this homebrew OS from scratch, using only x86 assembly language. 
</p><p>
I have created and included a number of utilities, including a file manager, text editor, graphical applications, BASIC interpreter, x86 assembler and debugger. I also ported one of my DOS games to it. After all, what kind of an operating system doesn't have games?
</p><p>
The Snowdrop OS and the apps are distributed as both a floppy disk (1.44Mb) image, as well as a CD-ROM image. The images contain the following, all programmed from scratch:
</p><ul><li>a boot loader which loads the kernel into memory</li><li>a kernel which sets up interrupt vectors to be used by user apps, and then loads the startup app</li><li>user apps, including a shell (command line interface), utilities, test apps, and aSMtris, my Tetris clone</li></ul><p>
Snowdrop OS can also be installed to a hard disk - prompting the user to do so during boot - if it detects one. 
</p><p>
I hope that Snowdrop can serve other programmers who are looking to get a basic understanding of operating system functions. Like my other projects, the source code is fully available, without any restrictions on its usage and modification.
</p><h2>Source code browser</h2>
<p>
Some interesting areas in the <a href="http://sebastianmihai.com/snowdrop/src">source code</a> are: </p><ul>
<li><a href="http://sebastianmihai.com/snowdrop/src/loader/mbr.asm">Boot loader</a> is crammed into 512 bytes; it locates and loads the kernel</li>
<li>Snowdrop OS's <a href="http://sebastianmihai.com/snowdrop/src/kernel/">kernel</a> provides fundamental services and abstractions to applications</li>
<li><a href="http://sebastianmihai.com/snowdrop/src/apps/common/vga640/">Graphics and GUI framework</a> are the foundations needed to create graphical, mouse-driven applications</li>
<li>Snowdrop's <a href="http://sebastianmihai.com/snowdrop/src/apps/common/assembler/">x86 assembler</a> can be used to create low-level applications directly inside Snowdrop OS</li>
<li><a href="http://sebastianmihai.com/snowdrop/src/apps/common/basic/">BASIC interpreter</a> is great for creating high-level applications quickly</li>
<li>The <a href="http://sebastianmihai.com/snowdrop/src/apps/common/debugger/">x86 debugger</a> can be used in conjunction with the assembler</li>
<li><a href="http://sebastianmihai.com/snowdrop/src/apps/common/dynamic/">Dynamic data structure libraries</a> for working with linked lists, trees, BSTs, etc.</li>
<li><a href="http://sebastianmihai.com/snowdrop/src/apps/">All applications</a> games, text editor, file manager, tools, test applications</li>
</ul>
<h2>Versions</h2>

<p>v1 - initial version, single tasking, shell, aSMtris
<br>v2 - PS/2 mouse driver and mouse test apps
<br>v3 - basic multi-tasking support and virtual display support
<br>v4 - FAT12 driver write/delete, file manager, text editor
<br>v5 - serial port driver, formatting utilities, file copy support
<br>v6 - multiplayer snake game (over serial port)
<br>v7 - slide show presentation app
<br>v8 - "keep memory" task lifetime mode, for custom services
<br>v9 - parallel port driver, BMP image support, sprites
<br>v10 - system timer frequency change
<br>v11 - animated sprites, sound driver (internal speaker)
<br>v12 - keyboard driver
<br>v13 - more sprites functionality, Storks game
<br>v14 - kernel config, program arguments, file utilities
<br>v15 - 16x2 LCD controller app, text editor fixes
<br>v16 - GUI framework
<br>v17 - Snowmine (Minesweeper-like game)
<br>v18 - BASIC interpreter and linker
<br>v19 - install to hard disk
<br>v20 - BASIC and text editor improvements
<br>v21 - integration of BASIC and GUI framework
<br>v22 - x86 assembler, multi-disk support, file view utilities
<br>v23 - x86 debugger
<br>v24 - service loading
<br>v25 - dynamic memory and data structures
<br>v26 - installer improvements, pseudo-mouse driver
<br>v27 - kernel and inter-task messaging
<br>v28 - GUI higher resolution, draw application, desktop application
<br>v29 - data compression, Hangman game
<br>v30 - pseudo-mouse driver improvements
<br>v31 - runtime libraries (RTL), BASIC interpreter RTL
</p>

<p><img alt="" src="http://sebastianmihai.com/snowdrop/images/snowdrop_many_computers.jpg"></p>

				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wild – A Fast Linker for Linux (237 pts)]]></title>
            <link>https://github.com/davidlattimore/wild</link>
            <guid>42814683</guid>
            <pubDate>Fri, 24 Jan 2025 16:25:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/davidlattimore/wild">https://github.com/davidlattimore/wild</a>, See on <a href="https://news.ycombinator.com/item?id=42814683">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Wild linker</h2><a id="user-content-wild-linker" aria-label="Permalink: Wild linker" href="#wild-linker"></a></p>
<p dir="auto">Wild is a linker with the goal of being very fast for iterative development.</p>
<p dir="auto">The plan is to eventually make it incremental, however that isn't yet implemented. It is however
already pretty fast even without incremental linking.</p>
<p dir="auto">For production builds, its recommended to use a more mature linker like GNU ld or LLD.</p>
<p dir="auto">During development, if you'd like faster warm build times, then you could give Wild a try. It's at
the point now where it should be usable for development purposes provided you're developing on
x86-64 Linux. If you hit any issues, please file a bug report.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">To install a pre-built binary, you can copy and paste the command from the <a href="https://github.com/davidlattimore/wild/releases">releases
page</a>. Alternatively, you can download the tarball
and manually copy the <code>wild</code> binary somewhere on your path.</p>
<p dir="auto">To build and install, you can run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo install --locked --bin wild --git https://github.com/davidlattimore/wild.git wild"><pre>cargo install --locked --bin wild --git https://github.com/davidlattimore/wild.git wild</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Using as your default linker</h2><a id="user-content-using-as-your-default-linker" aria-label="Permalink: Using as your default linker" href="#using-as-your-default-linker"></a></p>
<p dir="auto">If you'd like to use Wild as your default linker for building Rust code, you can put the following
in <code>~/.cargo/config.toml</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="[target.x86_64-unknown-linux-gnu]
linker = &quot;clang&quot;
rustflags = [&quot;-C&quot;, &quot;link-arg=--ld-path=wild&quot;]"><pre>[<span>target</span>.<span>x86_64-unknown-linux-gnu</span>]
<span>linker</span> = <span><span>"</span>clang<span>"</span></span>
<span>rustflags</span> = [<span><span>"</span>-C<span>"</span></span>, <span><span>"</span>link-arg=--ld-path=wild<span>"</span></span>]</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Q&amp;A</h2><a id="user-content-qa" aria-label="Permalink: Q&amp;A" href="#qa"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Why another linker?</h3><a id="user-content-why-another-linker" aria-label="Permalink: Why another linker?" href="#why-another-linker"></a></p>
<p dir="auto">Mold is already very fast, however it doesn't do incremental linking and the author has stated that
they don't intend to. Wild doesn't do incremental linking yet, but that is the end-goal. By writing
Wild in Rust, it's hoped that the complexity of incremental linking will be achievable.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">What's working?</h3><a id="user-content-whats-working" aria-label="Permalink: What's working?" href="#whats-working"></a></p>
<p dir="auto">The following platforms / architectures are currently supported:</p>
<ul dir="auto">
<li>x86-64 on Linux</li>
</ul>
<p dir="auto">The following is working with the caveat that there may be bugs:</p>
<ul dir="auto">
<li>Output to statically linked, non-relocatable binaries</li>
<li>Output to statically linked, position-independent binaries (static-PIE)</li>
<li>Output to dynamically linked binaries</li>
<li>Output to shared objects (.so files)</li>
<li>Rust proc-macros, when linked with Wild work</li>
<li>Most of the top downloaded crates on crates.io have been tested with Wild and pass their tests</li>
<li>Debug info</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">What isn't yet supported?</h3><a id="user-content-what-isnt-yet-supported" aria-label="Permalink: What isn't yet supported?" href="#what-isnt-yet-supported"></a></p>
<p dir="auto">Lots of stuff. Here are some of the larger things that aren't yet done, roughly sorted by current
priority:</p>
<ul dir="auto">
<li>Incremental linking</li>
<li>Support for architectures other than x86-64</li>
<li>Support for a wider range of linker flags</li>
<li>Linker scripts</li>
<li>Mac support</li>
<li>Windows support</li>
<li>LTO</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">How can I verify that Wild was used to link a binary?</h3><a id="user-content-how-can-i-verify-that-wild-was-used-to-link-a-binary" aria-label="Permalink: How can I verify that Wild was used to link a binary?" href="#how-can-i-verify-that-wild-was-used-to-link-a-binary"></a></p>
<p dir="auto">Install <code>readelf</code>, then run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="readelf  -p .comment my-executable"><pre>readelf  -p .comment my-executable</pre></div>
<p dir="auto">Look for a line like:</p>
<div data-snippet-clipboard-copy-content="Linker: Wild version 0.1.0"><pre><code>Linker: Wild version 0.1.0
</code></pre></div>
<p dir="auto">Or if you don't want to install readelf, you can probably get away with:</p>
<div dir="auto" data-snippet-clipboard-copy-content="strings my-executable | grep 'Linker:'"><pre>strings my-executable <span>|</span> grep <span><span>'</span>Linker:<span>'</span></span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Where did the name come from?</h3><a id="user-content-where-did-the-name-come-from" aria-label="Permalink: Where did the name come from?" href="#where-did-the-name-come-from"></a></p>
<p dir="auto">It's somewhat of a tradition for linkers to end with the letters "ld". e.g. "GNU ld, "gold", "lld",
"mold". Since the end-goal is for the linker to be incremental, an "I" is added. Let's say the "W"
stands for "Wild", since recursive acronyms are popular in open-source projects.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Benchmarks</h2><a id="user-content-benchmarks" aria-label="Permalink: Benchmarks" href="#benchmarks"></a></p>
<p dir="auto">The goal of Wild is to eventually be very fast via incremental linking. However, we also want to be
as fast as we can be for non-incremental linking and for the initial link when incremental linking
is enabled.</p>
<p dir="auto">These benchmark were run on David Lattimore's laptop (2020 model System76 Lemur pro), which has 4
cores (8 threads) and 42 GB of RAM.</p>
<p dir="auto">The following times are for linking rustc-driver, which is a shared object that contains most of the
code of the Rust compiler. Linking was done with with <code>--strip-debug</code> and <code>--build-id=none</code>.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Linker</th>
<th>Time (ms)</th>
<th>± Standard deviation (ms)</th>
</tr>
</thead>
<tbody>
<tr>
<td>GNU ld (2.38)</td>
<td>20774</td>
<td>855</td>
</tr>
<tr>
<td>gold (2.38)</td>
<td>6796</td>
<td>58</td>
</tr>
<tr>
<td>lld (18.1.8)</td>
<td>1601</td>
<td>24</td>
</tr>
<tr>
<td>mold (2.34.1)</td>
<td>946</td>
<td>17</td>
</tr>
<tr>
<td>wild (2024-11-30)</td>
<td>486</td>
<td>19</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">The following times are for linking the C compiler, clang without debug info.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Linker</th>
<th>Time (ms)</th>
<th>± Standard deviation (ms)</th>
</tr>
</thead>
<tbody>
<tr>
<td>GNU ld (2.38)</td>
<td>8784</td>
<td>42</td>
</tr>
<tr>
<td>gold (2.38)</td>
<td>2528</td>
<td>37</td>
</tr>
<tr>
<td>lld (18.1.8)</td>
<td>1679</td>
<td>23</td>
</tr>
<tr>
<td>mold (2.34.1)</td>
<td>429</td>
<td>2</td>
</tr>
<tr>
<td>wild (2024-11-30)</td>
<td>244</td>
<td>6</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">Next, let's add debug info (remove <code>--strip-debug</code>). First rustc-driver:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Linker</th>
<th>Time (ms)</th>
<th>± Standard deviation (ms)</th>
</tr>
</thead>
<tbody>
<tr>
<td>GNU ld (2.38)</td>
<td>23224</td>
<td>1030</td>
</tr>
<tr>
<td>gold (2.38)</td>
<td>8840</td>
<td>879</td>
</tr>
<tr>
<td>lld (18.1.8)</td>
<td>2741</td>
<td>1403</td>
</tr>
<tr>
<td>mold (2.34.1)</td>
<td>3514</td>
<td>2102</td>
</tr>
<tr>
<td>wild (2024-11-30)</td>
<td>3158</td>
<td>1616</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">Now clang with debug info:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Linker</th>
<th>Time (ms)</th>
<th>± Standard deviation (ms)</th>
</tr>
</thead>
<tbody>
<tr>
<td>GNU ld (2.38)</td>
<td>139985</td>
<td>9871</td>
</tr>
<tr>
<td>gold (2.38)</td>
<td>92147</td>
<td>7287</td>
</tr>
<tr>
<td>lld (18.1.8)</td>
<td>30549</td>
<td>9819</td>
</tr>
<tr>
<td>mold (2.34.1)</td>
<td>16933</td>
<td>5359</td>
</tr>
<tr>
<td>wild (2024-11-30)</td>
<td>31540</td>
<td>7133</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">So Wild performs pretty well without debug info, but with debug info, it's performing less well at
the moment.</p>
<p dir="auto">See <a href="https://github.com/davidlattimore/wild/blob/main/BENCHMARKING.md">BENCHMARKING.md</a> for more details on benchmarking.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Linking Rust code</h2><a id="user-content-linking-rust-code" aria-label="Permalink: Linking Rust code" href="#linking-rust-code"></a></p>
<p dir="auto">The following is a <code>cargo test</code> command-line that can be used to build and test a crate using Wild.
This has been run successfully on a few popular crates (e.g. ripgrep, serde, tokio, rand, bitflags).
It assumes that the "wild" binary is on your path. It also depends on the Clang compiler being
installed, since GCC doesn't allow using an arbitrary linker.</p>
<div dir="auto" data-snippet-clipboard-copy-content="RUSTFLAGS=&quot;-Clinker=clang -Clink-args=--ld-path=wild&quot; cargo test"><pre>RUSTFLAGS=<span><span>"</span>-Clinker=clang -Clink-args=--ld-path=wild<span>"</span></span> cargo <span>test</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">For more information on contributing to <code>wild</code> see <a href="https://github.com/davidlattimore/wild/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Sponsorship</h2><a id="user-content-sponsorship" aria-label="Permalink: Sponsorship" href="#sponsorship"></a></p>
<p dir="auto">If you'd like to <a href="https://github.com/sponsors/davidlattimore">sponsor this work</a>, that would be very
much appreciated. The more sponsorship I get the longer I can continue to work on this project full
time.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Licensed under either of <a href="https://github.com/davidlattimore/wild/blob/main/LICENSE-APACHE">Apache License, Version 2.0</a> or <a href="https://github.com/davidlattimore/wild/blob/main/LICENSE-MIT">MIT license</a>
at your option.</p>
<p dir="auto">Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in
Wild by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any
additional terms or conditions.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New Book-Sorting Algorithm Almost Reaches Perfection (153 pts)]]></title>
            <link>https://www.quantamagazine.org/new-book-sorting-algorithm-almost-reaches-perfection-20250124/</link>
            <guid>42814275</guid>
            <pubDate>Fri, 24 Jan 2025 15:50:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/new-book-sorting-algorithm-almost-reaches-perfection-20250124/">https://www.quantamagazine.org/new-book-sorting-algorithm-almost-reaches-perfection-20250124/</a>, See on <a href="https://news.ycombinator.com/item?id=42814275">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-role="selectable">
    <p>Computer scientists often deal with abstract problems that are hard to comprehend, but an exciting new algorithm matters to anyone who owns books and at least one shelf. The algorithm addresses something called the library sorting problem (more formally, the “list labeling” problem). The challenge is to devise a strategy for organizing books in some kind of sorted order — alphabetically, for instance — that minimizes how long it takes to place a new book on the shelf.</p>
<p>Imagine, for example, that you keep your books clumped together, leaving empty space on the far right of the shelf. Then, if you add a book by Isabel Allende to your collection, you might have to move every book on the shelf to make room for it. That would be a time-consuming operation. And if you then get a book by Douglas Adams, you’ll have to do it all over again. A better arrangement would leave unoccupied spaces distributed throughout the shelf — but how, exactly, should they be distributed?</p>
<p>This problem was introduced in a <a href="https://link.springer.com/chapter/10.1007/3-540-10843-2_34">1981 paper</a>, and it goes beyond simply providing librarians with organizational guidance. That’s because the problem also applies to the arrangement of files on hard drives and in databases, where the items to be arranged could number in the billions. An inefficient system means significant wait times and major computational expense. Researchers have invented some efficient methods for storing items, but they’ve long wanted to determine the best possible way.</p>
<p>Last year, in <a href="https://arxiv.org/abs/2405.00807">a study</a> that was presented at the Foundations of Computer Science conference in Chicago, a team of seven researchers described a way to organize items that comes tantalizingly close to the theoretical ideal. The new approach combines a little knowledge of the bookshelf’s past contents with the surprising power of randomness.</p>
<p>“It’s a very important problem,” said <a href="https://web.eecs.umich.edu/~pettie/">Seth Pettie</a>, a computer scientist at the University of Michigan, because many of the data structures we rely upon today store information sequentially. He called the new work “extremely inspired [and] easily one of my top three favorite papers of the year.”</p>
<h2><strong>Narrowing Bounds</strong></h2>
<p>So how does one measure a well-sorted bookshelf? A common way is to see how long it takes to insert an individual item. Naturally, that depends on how many items there are in the first place, a value typically denoted by <em>n</em>. In the Isabel Allende example, when all the books have to move to accommodate a new one, the time it takes is proportional to <em>n</em>. The bigger the <em>n</em>, the longer it takes. That makes this an “upper bound” to the problem: It will never take longer than a time proportional to <em>n</em> to add one book to the shelf.</p>

<p>The authors of the 1981 paper that ushered in this problem wanted to know if it was possible to design an algorithm with an average insertion time much less than<em> n</em>. And indeed, they proved that one could do better. They created an algorithm that was guaranteed to achieve an average insertion time proportional to (log <em>n</em>)<sup>2</sup>. This algorithm had two properties: It was “deterministic,” meaning that its decisions did not depend on any randomness, and it was also “smooth,” meaning that the books must be spread evenly within subsections of the shelf where insertions (or deletions) are made. The authors left open the question of whether the upper bound could be improved even further. For over four decades, no one managed to do so.</p>
<p>However, the intervening years did see improvements to the lower bound. While the upper bound specifies the maximum possible time needed to insert a book, the lower bound gives the fastest possible insertion time. To find a definitive solution to a problem, researchers strive to narrow the gap between the upper and lower bounds, ideally until they coincide. When that happens, the algorithm is deemed optimal — inexorably bounded from above and below, leaving no room for further refinement.</p>
<p>In 2004, a team of researchers found that the <a href="https://epubs.siam.org/doi/abs/10.1137/S0895480100315808?journalCode=sjdmec">best any algorithm could do</a> for the library sorting problem — in other words, the ultimate lower bound — was log <em>n</em>. This result pertained to the most general version of the problem, applying to any algorithm of any type. Two of the same authors had already secured a result for a more specific version of the problem in 1990, showing that for any smooth algorithm, <a href="https://link.springer.com/chapter/10.1007/3-540-52846-6_87">the lower bound is significantly higher</a>: (log <em>n</em>)<sup>2</sup>. And in 2012, another team <a href="https://dl.acm.org/doi/abs/10.1145/2213977.2214083">proved the same lower bound</a>, (log <em>n</em>)<sup>2</sup>, for any deterministic algorithm that does not use randomness at all.</p>
<p>These results showed that for any smooth or deterministic algorithm, you could not achieve an average insertion time better than (log <em>n</em>)<sup>2</sup>, which was the same as the upper bound established in the 1981 paper. In other words, to improve that upper bound, researchers would need to devise a different kind of algorithm. “If you’re going to do better, you have to be randomized and non-smooth,” said <a href="https://www.cs.stonybrook.edu/people/faculty/michaelbender">Michael Bender</a>, a computer scientist at Stony Brook University.</p>
<figure>
    <p><img width="1630" height="1221" src="https://www.quantamagazine.org/wp-content/uploads/2025/01/MichaelBender_coMichaelBender-2-edit2.jpg" alt="Michael Bender in a blue shirt wearing black glasses." decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2025/01/MichaelBender_coMichaelBender-2-edit2.jpg 1630w, https://www.quantamagazine.org/wp-content/uploads/2025/01/MichaelBender_coMichaelBender-2-edit2-520x390.jpg 520w, https://www.quantamagazine.org/wp-content/uploads/2025/01/MichaelBender_coMichaelBender-2-edit2-768x575.jpg 768w, https://www.quantamagazine.org/wp-content/uploads/2025/01/MichaelBender_coMichaelBender-2-edit2-1536x1151.jpg 1536w" sizes="(max-width: 1630px) 100vw, 1630px">    </p>
            <figcaption>
                            <p>Michael Bender went after the library sorting problem using an approach that didn’t necessarily make intuitive sense.</p>
            <p>Courtesy of Michael Bender</p>
        </figcaption>
    </figure>

<p>But getting rid of smoothness, which requires items to be spread apart more or less evenly, seemed like a mistake. (Remember the problems that arose from our initial example — the non-smooth configuration where all the books were clumped together on the left-hand side of the shelf.) And it also was not obvious how leaving things to random chance — essentially a coin toss — would help matters. “Intuitively, it wasn’t clear that was a direction that made sense,” Bender said.</p>
<p>Nevertheless, in 2022, Bender and five colleagues decided to try out a randomized, non-smooth algorithm anyway, just to see whether it might offer any advantages.</p>
<h2><strong>A Secret History</strong></h2>
<p>Ironically, progress came from another restriction. There are sound privacy or security reasons why you may want to use an algorithm that’s blind to the history of the bookshelf. “If I had <em>50 Shades of Grey </em>on my bookshelf and took it off,” said <a href="https://csd.cmu.edu/people/faculty/william-kuszmaul">William Kuszmaul</a> of Carnegie Mellon University, nobody would be able to tell.</p>

<p>In a 2022 paper, Bender, Kuszmaul and four co-authors created just such an algorithm — one that was “history independent,” non-smooth and randomized — which finally <a href="https://arxiv.org/abs/2203.02763">reduced the 1981 upper bound</a>, bringing the average insertion time down to (log <em>n</em>)<sup>1.5</sup>.</p>
<p>Kuszmaul remembers being surprised that a tool normally used to ensure privacy could confer other benefits. “It’s as if you used cryptography to make your algorithm faster,” he said. “Which just seems kind of strange.”</p>
<p><a href="https://www.cc.gatech.edu/people/helen-xu">Helen Xu</a> of the Georgia Institute of Technology, who was not part of this research team, was also impressed.&nbsp; She said that the idea of using history independence for reasons other than security may have implications for many other types of problems.</p>
<h2><strong>Closing the Gap</strong></h2>
<p>Bender, Kuszmaul and others made an even bigger improvement with last year’s paper. They again broke the record, lowering the upper bound to (log <em>n</em>) times (log log <em>n</em>)<sup>3</sup> — equivalent to (log <em>n</em>)<sup>1.000…1</sup>. In other words, they came exceedingly close to the theoretical limit, the ultimate lower bound of log <em>n</em>.</p>
<p>Once again, their approach was non-smooth and randomized, but this time their algorithm relied on a limited degree of history dependence. It looked at past trends to plan for future events, but only up to a point. Suppose, for instance, you’ve been getting a lot of books by authors whose last name starts with N — Nabokov, Neruda, Ng. The algorithm extrapolates from that and assumes more are probably coming, so it’ll leave a little extra space in the N section. But reserving too much space could lead to trouble if a bunch of A-name authors start pouring in. “The way we made it a good thing was by being strategically random about how much history to look at when we make our decisions,” Bender said.</p>
<p>The result built on and transformed their previous work. It “uses randomness in a completely different way than the 2022 paper,” Pettie said.</p>
        
        
<p>These papers collectively represent “a significant improvement” on the theory side, said <a href="https://computerscience.uchicago.edu/people/brian-wheatman/">Brian Wheatman</a>, a computer scientist at the University of Chicago. “And on the applied side, I think they have the potential for a big improvement as well.”</p>
<p>Xu agrees. “In the past few years, there’s been interest in using data structures based on list labeling for storing and processing dynamic graphs,” she said. These advances would almost certainly make things faster.</p>
<p>Meanwhile, there’s more for theorists to contemplate. “We know that we can almost do log <em>n</em>,” Bender said, “[but] there’s still this tiny gap” — the diminutive log log <em>n </em>term that stands in the way of a complete solution. “We don’t know if the right thing to do is to lower the upper bound or raise the lower bound.”</p>
<p>Pettie, for one, doesn’t expect the lower bound to change. “Usually in these situations, when you see a gap this close, and one of the bounds looks quite natural and the other looks unnatural, then the natural one is the right answer,” he said. It’s much more likely that any future improvements will affect the upper bound, bringing it all the way down to log <em>n.</em> “But the world’s full of weird surprises.”</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Cs16.css – CSS library based on CS 1.6 UI (370 pts)]]></title>
            <link>https://cs16.samke.me</link>
            <guid>42814110</guid>
            <pubDate>Fri, 24 Jan 2025 15:37:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cs16.samke.me">https://cs16.samke.me</a>, See on <a href="https://news.ycombinator.com/item?id=42814110">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <h2>Dialog</h2>

        <section>
          
          <dialog>
            <form method="dialog">
              
              <p>
                Lorem ipsum dolor sit amet consectetur adipisicing elit.
                Distinctio ad suscipit aut asperiores laudantium error amet
                sapiente et tempora numquam voluptates, velit sint quos
                exercitationem unde obcaecati deleniti maiores officia natus
                ipsa rem fuga commodi esse. Sunt repellendus ipsa illo a
                accusantium consequuntur nihil dicta necessitatibus porro,
                saepe, sed repudiandae!
              </p>
              <menu>
                
                
                
              </menu>
            </form>
          </dialog>
        </section>

        <div>
            <pre><code id="code-block">&lt;section&gt;
  &lt;button
    type="button"
    class="cs-btn"
    onclick="document.querySelector('.cs-dialog').showModal();"
  &gt;
    Open dialog
  &lt;/button&gt;
  &lt;dialog class="cs-dialog"&gt;
    &lt;form method="dialog"&gt;
      &lt;div class="heading"&gt;
        &lt;div class="wrapper"&gt;
          &lt;div class="icon"&gt;&lt;/div&gt;
          &lt;p class="text"&gt;Options&lt;/p&gt;
        &lt;/div&gt;
        &lt;button class="cs-btn close"&gt;&lt;/button&gt;
      &lt;/div&gt;
      &lt;div class="content"&gt;
        Lorem ipsum dolor sit amet consectetur adipisicing elit.
        Distinctio ad suscipit aut asperiores laudantium error amet
        sapiente et tempora numquam voluptates, velit sint quos
        exercitationem unde obcaecati deleniti maiores officia natus
        ipsa rem fuga commodi esse. Sunt repellendus ipsa illo a
        accusantium consequuntur nihil dicta necessitatibus porro,
        saepe, sed repudiandae!
      &lt;/div&gt;
      &lt;menu class="footer-btns"&gt;
        &lt;button class="cs-btn"&gt;OK&lt;/button&gt;
        &lt;button class="cs-btn"&gt;Cancel&lt;/button&gt;
        &lt;button class="cs-btn"&gt;Apply&lt;/button&gt;
      &lt;/menu&gt;
    &lt;/form&gt;
  &lt;/dialog&gt;
&lt;/section&gt;</code></pre>
          </div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How I Use Home Assistant in 2025 (130 pts)]]></title>
            <link>https://vpetersson.com/2025/01/22/how-i-use-home-assistant-in-2025.html</link>
            <guid>42813513</guid>
            <pubDate>Fri, 24 Jan 2025 14:51:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vpetersson.com/2025/01/22/how-i-use-home-assistant-in-2025.html">https://vpetersson.com/2025/01/22/how-i-use-home-assistant-in-2025.html</a>, See on <a href="https://news.ycombinator.com/item?id=42813513">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
        <p>I’ve been using Home Assistant for about seven years now, starting back when I was living in a small apartment. At the time, my setup was modest: I used the <strong>IKEA Smart Hub</strong> (when it first launched) to tie together all my apartment’s lights. As I got more comfortable with automations, I also began building <a href="https://vpetersson.com/2019/11/16/home-assistant-and-esphome.html">custom hardware like temperature and humidity sensors</a>.</p>

<p>However, once I started adding more complexity (more devices, more automations), I realized that running Home Assistant on a Raspberry Pi just wasn’t viable anymore. This was before Home Assistant offered their own hardware (which I haven’t tried, so I can’t say much about it). But for me, the main issue was the database. By default, Home Assistant uses SQLite, and when you have a ton of sensor data flowing in, SQLite can start choking.</p>

<p>My solution was to move everything to a VM on my home server. I also migrated Home Assistant’s main database to MySQL, and for longer-term metrics and historical data, I set up an InfluxDB server. (I’ve documented the details of my <a href="https://vpetersson.com/2024/05/04/home-server-journey.html">home server build in another blog post</a>.)</p>

<h2 id="scaling-up-in-a-new-house">Scaling Up in a New House</h2>

<p>When I moved into a house, my Home Assistant installation grew significantly: more rooms, more lights, and more devices overall. Right now, I have over 100 devices connected to Home Assistant, including a large number of smart lights (all IKEA), plus an assortment of other smart devices. Practically every bulb in my home is now integrated into Home Assistant.</p>

<h3 id="adaptive-lighting-moving-beyond-flux">Adaptive Lighting: Moving Beyond Flux</h3>

<p>One of the crucial features for me is <strong>Adaptive Lighting</strong>. Initially, I used <a href="https://vpetersson.com/2020/05/25/homeassistant-ikea-tradfri-flux-sensors.html">Flux</a> (an older solution for synchronizing lights with the time of day), but I’ve recently migrated to the new Adaptive Lighting integration available through HACS (Home Assistant Community Store). This newer system is much more sophisticated and has better capabilities for adjusting color temperature and brightness throughout the day.</p>

<p>Managing this setup comes with two main challenges. First, neither Flux nor Adaptive Lighting can target light groups. Instead, you need to explicitly list every single light entity in your configuration. This becomes particularly tedious when you have dozens of lights that you want to manage together. It would have been much more convenient to just point the integration to a group and have it handle all the lights within that group automatically.</p>

<p>The second challenge is that even though all my bulbs are from IKEA, they don’t have all the same features. This means I need separate configurations for each category to get Adaptive Lighting working correctly. But the effort is worth it: circadian rhythms are important to me, and I really want that smooth, automatic shift in color temperature from warm yellows in the morning and evenings to cooler whites and blues during midday.</p>

<h2 id="using-cursor-to-speed-up-configuration">Using Cursor to Speed Up Configuration</h2>

<p>One big leap for me this year has been leveraging <a href="https://www.cursor.com/">Cursor</a>, an AI coding assistant, to handle the more tedious parts of Home Assistant’s YAML configurations. I’ll admit, I’ve never had the time to master every detail of Home Assistant’s DSL or its configuration files.</p>

<h3 id="writing-a-custom-parser">Writing a Custom Parser</h3>

<p>The first major task I tackled with Cursor was writing a custom script to parse all my lights, figure out exactly what kind of bulb each one is, and spit out debugging information. This is the foundation of building the correct adaptive lighting setup. Once the script categorizes the bulbs, I can then create or update the YAML configuration for each bulb type.</p>

<p>Here’s the script I use to analyze my Home Assistant lights. It connects to the Home Assistant API, categorizes all lights by their capabilities, and provides detailed debugging information about their current state and supported features:</p>

<div><pre><code><span>import</span> <span>requests</span>
<span>import</span> <span>json</span>
<span>import</span> <span>os</span>
<span>from</span> <span>datetime</span> <span>import</span> <span>datetime</span>

<span>TOKEN</span> <span>=</span> <span>os</span><span>.</span><span>getenv</span><span>(</span><span>"HA_TOKEN"</span><span>)</span>  <span># Set this to your long-lived access token (Bearer: &lt;token&gt;)
</span>
<span># Function to get entity state
</span><span>def</span> <span>get_entity_state</span><span>(</span><span>entity_id</span><span>):</span>
    <span>url</span> <span>=</span> <span>"http://localhost:8123/api/states/"</span> <span>+</span> <span>entity_id</span>
    <span>headers</span> <span>=</span> <span>{</span>
        <span>"Authorization"</span><span>:</span> <span>TOKEN</span><span>,</span>
        <span>"content-type"</span><span>:</span> <span>"application/json"</span><span>,</span>
    <span>}</span>

    <span>response</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>url</span><span>,</span> <span>headers</span><span>=</span><span>headers</span><span>)</span>
    <span>if</span> <span>response</span><span>.</span><span>status_code</span> <span>==</span> <span>200</span><span>:</span>
        <span>return</span> <span>response</span><span>.</span><span>json</span><span>()</span>
    <span>else</span><span>:</span>
        <span>print</span><span>(</span><span>f</span><span>"Error getting state for </span><span>{</span><span>entity_id</span><span>}</span><span>: </span><span>{</span><span>response</span><span>.</span><span>status_code</span><span>}</span><span>"</span><span>)</span>
        <span>return</span> <span>None</span>

<span>def</span> <span>get_all_lights</span><span>():</span>
    <span>"""Get all light entities from Home Assistant."""</span>
    <span>url</span> <span>=</span> <span>"http://localhost:8123/api/states"</span>
    <span>headers</span> <span>=</span> <span>{</span>
        <span>"Authorization"</span><span>:</span> <span>TOKEN</span><span>,</span>
        <span>"content-type"</span><span>:</span> <span>"application/json"</span><span>,</span>
    <span>}</span>

    <span>response</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>url</span><span>,</span> <span>headers</span><span>=</span><span>headers</span><span>)</span>
    <span>if</span> <span>response</span><span>.</span><span>status_code</span> <span>==</span> <span>200</span><span>:</span>
        <span>entities</span> <span>=</span> <span>response</span><span>.</span><span>json</span><span>()</span>
        <span>lights</span> <span>=</span> <span>[]</span>
        <span>for</span> <span>entity</span> <span>in</span> <span>entities</span><span>:</span>
            <span>entity_id</span> <span>=</span> <span>entity</span><span>[</span><span>'entity_id'</span><span>]</span>
            <span>if</span> <span>entity_id</span><span>.</span><span>startswith</span><span>(</span><span>'light.'</span><span>):</span>
                <span>lights</span><span>.</span><span>append</span><span>(</span><span>entity_id</span><span>)</span>
        <span>return</span> <span>sorted</span><span>(</span><span>lights</span><span>)</span>
    <span>else</span><span>:</span>
        <span>print</span><span>(</span><span>f</span><span>"Error getting entities: </span><span>{</span><span>response</span><span>.</span><span>status_code</span><span>}</span><span>"</span><span>)</span>
        <span>return</span> <span>[]</span>

<span>def</span> <span>get_adaptive_switch_state</span><span>(</span><span>name</span><span>):</span>
    <span>switch_id</span> <span>=</span> <span>f</span><span>"switch.adaptive_lighting_</span><span>{</span><span>name</span><span>.</span><span>lower</span><span>()</span><span>}</span><span>"</span>
    <span>state</span> <span>=</span> <span>get_entity_state</span><span>(</span><span>switch_id</span><span>)</span>
    <span>if</span> <span>state</span><span>:</span>
        <span>print</span><span>(</span><span>f</span><span>"Adaptive switch </span><span>{</span><span>switch_id</span><span>}</span><span> full state: </span><span>{</span><span>json</span><span>.</span><span>dumps</span><span>(</span><span>state</span><span>,</span> <span>indent</span><span>=</span><span>2</span><span>)</span><span>}</span><span>"</span><span>)</span>
    <span>return</span> <span>state</span>

<span>def</span> <span>check_light_capabilities</span><span>(</span><span>light_attrs</span><span>,</span> <span>group_name</span><span>,</span> <span>light_id</span><span>,</span> <span>adaptive_config</span><span>):</span>
    <span>"""Check if light capabilities match adaptive lighting settings."""</span>
    <span>warnings</span> <span>=</span> <span>[]</span>

    <span># Check color temperature support
</span>    <span>if</span> <span>(</span><span>'color_temp_kelvin'</span> <span>in</span> <span>adaptive_config</span> <span>and</span>
        <span>'supported_color_modes'</span> <span>in</span> <span>light_attrs</span> <span>and</span>
        <span>'color_temp'</span> <span>not</span> <span>in</span> <span>light_attrs</span><span>[</span><span>'supported_color_modes'</span><span>]):</span>
        <span>warnings</span><span>.</span><span>append</span><span>(</span><span>f</span><span>"WARNING: </span><span>{</span><span>light_id</span><span>}</span><span> in </span><span>{</span><span>group_name</span><span>}</span><span> group doesn't support color temperature, "</span>
                      <span>f</span><span>"but adaptive lighting is trying to set it. Supported modes: </span><span>{</span><span>light_attrs</span><span>[</span><span>'supported_color_modes'</span><span>]</span><span>}</span><span>"</span><span>)</span>

    <span># Check brightness support
</span>    <span>if</span> <span>(</span><span>'brightness_pct'</span> <span>in</span> <span>adaptive_config</span> <span>and</span>
        <span>'supported_color_modes'</span> <span>in</span> <span>light_attrs</span> <span>and</span>
        <span>'brightness'</span> <span>not</span> <span>in</span> <span>light_attrs</span><span>[</span><span>'supported_color_modes'</span><span>]):</span>
        <span>warnings</span><span>.</span><span>append</span><span>(</span><span>f</span><span>"WARNING: </span><span>{</span><span>light_id</span><span>}</span><span> in </span><span>{</span><span>group_name</span><span>}</span><span> group doesn't support brightness, "</span>
                      <span>f</span><span>"but adaptive lighting is trying to set it. Supported modes: </span><span>{</span><span>light_attrs</span><span>[</span><span>'supported_color_modes'</span><span>]</span><span>}</span><span>"</span><span>)</span>

    <span>return</span> <span>warnings</span>

<span>def</span> <span>analyze_current_state</span><span>(</span><span>lights</span><span>,</span> <span>group_name</span><span>):</span>
    <span>print</span><span>(</span><span>f</span><span>"</span><span>\n</span><span>=== </span><span>{</span><span>group_name</span><span>}</span><span> Current State ==="</span><span>)</span>
    <span>print</span><span>(</span><span>f</span><span>"Analyzing at: </span><span>{</span><span>datetime</span><span>.</span><span>now</span><span>().</span><span>strftime</span><span>(</span><span>'%Y-%m-%d %H</span><span>:</span><span>%</span><span>M</span><span>:</span><span>%</span><span>S</span><span>')</span><span>}</span><span>"</span><span>)</span>

    <span># Get adaptive lighting switch state
</span>    <span>switch_state</span> <span>=</span> <span>get_adaptive_switch_state</span><span>(</span><span>group_name</span><span>)</span>
    <span>adaptive_config</span> <span>=</span> <span>{}</span>
    <span>if</span> <span>switch_state</span><span>:</span>
        <span>print</span><span>(</span><span>f</span><span>"Adaptive Lighting Switch: </span><span>{</span><span>switch_state</span><span>[</span><span>'state'</span><span>]</span><span>}</span><span>"</span><span>)</span>
        <span>print</span><span>(</span><span>f</span><span>"Last changed: </span><span>{</span><span>switch_state</span><span>.</span><span>get</span><span>(</span><span>'last_changed'</span><span>,</span> <span>'unknown'</span><span>)</span><span>}</span><span>"</span><span>)</span>
        <span>print</span><span>(</span><span>f</span><span>"Attributes: </span><span>{</span><span>json</span><span>.</span><span>dumps</span><span>(</span><span>switch_state</span><span>.</span><span>get</span><span>(</span><span>'attributes'</span><span>,</span> <span>{}</span><span>),</span> <span>indent</span><span>=</span><span>2</span><span>)</span><span>}</span><span>"</span><span>)</span>
        <span>adaptive_config</span> <span>=</span> <span>switch_state</span><span>.</span><span>get</span><span>(</span><span>'attributes'</span><span>,</span> <span>{})</span>
    <span>else</span><span>:</span>
        <span>print</span><span>(</span><span>"Adaptive Lighting Switch: Not found"</span><span>)</span>

    <span>now</span> <span>=</span> <span>datetime</span><span>.</span><span>now</span><span>()</span>
    <span>current_time</span> <span>=</span> <span>now</span><span>.</span><span>strftime</span><span>(</span><span>"%H:%M:%S"</span><span>)</span>
    <span>print</span><span>(</span><span>f</span><span>"Current Time: </span><span>{</span><span>current_time</span><span>}</span><span>"</span><span>)</span>

    <span># Track brightness statistics
</span>    <span>brightness_stats</span> <span>=</span> <span>{</span>
        <span>'min'</span><span>:</span> <span>float</span><span>(</span><span>'inf'</span><span>),</span>
        <span>'max'</span><span>:</span> <span>float</span><span>(</span><span>'-inf'</span><span>),</span>
        <span>'total'</span><span>:</span> <span>0</span><span>,</span>
        <span>'count'</span><span>:</span> <span>0</span>
    <span>}</span>

    <span># Group lights by capabilities
</span>    <span>light_types</span> <span>=</span> <span>{}</span>
    <span>capability_warnings</span> <span>=</span> <span>[]</span>

    <span>for</span> <span>light</span> <span>in</span> <span>lights</span><span>:</span>
        <span>state</span> <span>=</span> <span>get_entity_state</span><span>(</span><span>light</span><span>)</span>
        <span>if</span> <span>not</span> <span>state</span><span>:</span>
            <span>print</span><span>(</span><span>f</span><span>"</span><span>{</span><span>light</span><span>}</span><span>: Not found or offline"</span><span>)</span>
            <span>continue</span>

        <span>attrs</span> <span>=</span> <span>state</span><span>[</span><span>'attributes'</span><span>]</span>
        <span>status</span> <span>=</span> <span>[]</span>
        <span>capabilities</span> <span>=</span> <span>[]</span>

        <span># Check capabilities against adaptive lighting settings
</span>        <span>if</span> <span>adaptive_config</span><span>:</span>
            <span>warnings</span> <span>=</span> <span>check_light_capabilities</span><span>(</span><span>attrs</span><span>,</span> <span>group_name</span><span>,</span> <span>light</span><span>,</span> <span>adaptive_config</span><span>)</span>
            <span>capability_warnings</span><span>.</span><span>extend</span><span>(</span><span>warnings</span><span>)</span>

        <span># Basic state
</span>        <span>if</span> <span>state</span><span>[</span><span>'state'</span><span>]</span> <span>==</span> <span>'on'</span><span>:</span>
            <span>if</span> <span>'brightness'</span> <span>in</span> <span>attrs</span><span>:</span>
                <span>brightness_pct</span> <span>=</span> <span>round</span><span>((</span><span>attrs</span><span>[</span><span>'brightness'</span><span>]</span> <span>/</span> <span>255</span><span>)</span> <span>*</span> <span>100</span><span>)</span>
                <span>status</span><span>.</span><span>append</span><span>(</span><span>f</span><span>"brightness: </span><span>{</span><span>brightness_pct</span><span>}</span><span>%"</span><span>)</span>
                <span># Update brightness statistics
</span>                <span>brightness_stats</span><span>[</span><span>'min'</span><span>]</span> <span>=</span> <span>min</span><span>(</span><span>brightness_stats</span><span>[</span><span>'min'</span><span>],</span> <span>brightness_pct</span><span>)</span>
                <span>brightness_stats</span><span>[</span><span>'max'</span><span>]</span> <span>=</span> <span>max</span><span>(</span><span>brightness_stats</span><span>[</span><span>'max'</span><span>],</span> <span>brightness_pct</span><span>)</span>
                <span>brightness_stats</span><span>[</span><span>'total'</span><span>]</span> <span>+=</span> <span>brightness_pct</span>
                <span>brightness_stats</span><span>[</span><span>'count'</span><span>]</span> <span>+=</span> <span>1</span>

            <span>if</span> <span>'color_temp_kelvin'</span> <span>in</span> <span>attrs</span><span>:</span>
                <span>status</span><span>.</span><span>append</span><span>(</span><span>f</span><span>"temp: </span><span>{</span><span>attrs</span><span>[</span><span>'color_temp_kelvin'</span><span>]</span><span>}</span><span>K"</span><span>)</span>
            <span>elif</span> <span>'color_temp'</span> <span>in</span> <span>attrs</span><span>:</span>
                <span>status</span><span>.</span><span>append</span><span>(</span><span>f</span><span>"mired: </span><span>{</span><span>attrs</span><span>[</span><span>'color_temp'</span><span>]</span><span>}</span><span>"</span><span>)</span>

            <span>print</span><span>(</span><span>f</span><span>"</span><span>{</span><span>light</span><span>}</span><span>: ON - </span><span>{</span><span>', '</span><span>.</span><span>join</span><span>(</span><span>status</span><span>)</span><span>}</span><span>"</span><span>)</span>
        <span>else</span><span>:</span>
            <span>print</span><span>(</span><span>f</span><span>"</span><span>{</span><span>light</span><span>}</span><span>: OFF"</span><span>)</span>

        <span># Detailed capabilities
</span>        <span>if</span> <span>'supported_color_modes'</span> <span>in</span> <span>attrs</span><span>:</span>
            <span>capabilities</span><span>.</span><span>append</span><span>(</span><span>f</span><span>"modes:</span><span>{</span><span>attrs</span><span>[</span><span>'supported_color_modes'</span><span>]</span><span>}</span><span>"</span><span>)</span>
        <span>if</span> <span>'min_color_temp_kelvin'</span> <span>in</span> <span>attrs</span> <span>and</span> <span>'max_color_temp_kelvin'</span> <span>in</span> <span>attrs</span><span>:</span>
            <span>capabilities</span><span>.</span><span>append</span><span>(</span><span>f</span><span>"temp:</span><span>{</span><span>attrs</span><span>[</span><span>'min_color_temp_kelvin'</span><span>]</span><span>}</span><span>-</span><span>{</span><span>attrs</span><span>[</span><span>'max_color_temp_kelvin'</span><span>]</span><span>}</span><span>"</span><span>)</span>
        <span>if</span> <span>'supported_features'</span> <span>in</span> <span>attrs</span><span>:</span>
            <span>capabilities</span><span>.</span><span>append</span><span>(</span><span>f</span><span>"features:</span><span>{</span><span>attrs</span><span>[</span><span>'supported_features'</span><span>]</span><span>}</span><span>"</span><span>)</span>

        <span># Group by capabilities
</span>        <span>cap_key</span> <span>=</span> <span>','</span><span>.</span><span>join</span><span>(</span><span>sorted</span><span>(</span><span>capabilities</span><span>))</span>
        <span>if</span> <span>cap_key</span> <span>not</span> <span>in</span> <span>light_types</span><span>:</span>
            <span>light_types</span><span>[</span><span>cap_key</span><span>]</span> <span>=</span> <span>[]</span>
        <span>light_types</span><span>[</span><span>cap_key</span><span>].</span><span>append</span><span>(</span><span>light</span><span>)</span>

    <span># Print capability warnings
</span>    <span>if</span> <span>capability_warnings</span><span>:</span>
        <span>print</span><span>(</span><span>"</span><span>\n</span><span>=== Capability Warnings ==="</span><span>)</span>
        <span>for</span> <span>warning</span> <span>in</span> <span>capability_warnings</span><span>:</span>
            <span>print</span><span>(</span><span>warning</span><span>)</span>

    <span># Print brightness statistics
</span>    <span>if</span> <span>brightness_stats</span><span>[</span><span>'count'</span><span>]</span> <span>&gt;</span> <span>0</span><span>:</span>
        <span>print</span><span>(</span><span>f</span><span>"</span><span>\n</span><span>=== </span><span>{</span><span>group_name</span><span>}</span><span> Brightness Statistics ==="</span><span>)</span>
        <span>print</span><span>(</span><span>f</span><span>"Minimum brightness: </span><span>{</span><span>brightness_stats</span><span>[</span><span>'min'</span><span>]</span><span>}</span><span>%"</span><span>)</span>
        <span>print</span><span>(</span><span>f</span><span>"Maximum brightness: </span><span>{</span><span>brightness_stats</span><span>[</span><span>'max'</span><span>]</span><span>}</span><span>%"</span><span>)</span>
        <span>print</span><span>(</span><span>f</span><span>"Average brightness: </span><span>{</span><span>brightness_stats</span><span>[</span><span>'total'</span><span>]</span> <span>/</span> <span>brightness_stats</span><span>[</span><span>'count'</span><span>]</span><span>:</span><span>.</span><span>1</span><span>f</span><span>}</span><span>%"</span><span>)</span>
        <span>print</span><span>(</span><span>f</span><span>"Number of lights on: </span><span>{</span><span>brightness_stats</span><span>[</span><span>'count'</span><span>]</span><span>}</span><span>"</span><span>)</span>

    <span># Print summary of light types
</span>    <span>print</span><span>(</span><span>f</span><span>"</span><span>\n</span><span>=== </span><span>{</span><span>group_name</span><span>}</span><span> Light Types ==="</span><span>)</span>
    <span>for</span> <span>cap_key</span><span>,</span> <span>lights</span> <span>in</span> <span>light_types</span><span>.</span><span>items</span><span>():</span>
        <span>print</span><span>(</span><span>f</span><span>"</span><span>\n</span><span>Capabilities: </span><span>{</span><span>cap_key</span><span>}</span><span>"</span><span>)</span>
        <span>print</span><span>(</span><span>"Lights:"</span><span>)</span>
        <span>for</span> <span>light</span> <span>in</span> <span>lights</span><span>:</span>
            <span>print</span><span>(</span><span>f</span><span>"  - </span><span>{</span><span>light</span><span>}</span><span>"</span><span>)</span>

<span>def</span> <span>group_lights_by_capability</span><span>(</span><span>lights</span><span>):</span>
    <span>"""Group lights by their capabilities."""</span>
    <span>color_temp_lights</span> <span>=</span> <span>[]</span>
    <span>brightness_lights</span> <span>=</span> <span>[]</span>
    <span>other_lights</span> <span>=</span> <span>[]</span>

    <span>for</span> <span>light</span> <span>in</span> <span>lights</span><span>:</span>
        <span>state</span> <span>=</span> <span>get_entity_state</span><span>(</span><span>light</span><span>)</span>
        <span>if</span> <span>not</span> <span>state</span><span>:</span>
            <span>continue</span>

        <span>attrs</span> <span>=</span> <span>state</span><span>[</span><span>'attributes'</span><span>]</span>
        <span>if</span> <span>'supported_color_modes'</span> <span>in</span> <span>attrs</span><span>:</span>
            <span>if</span> <span>'color_temp'</span> <span>in</span> <span>attrs</span><span>[</span><span>'supported_color_modes'</span><span>]:</span>
                <span>color_temp_lights</span><span>.</span><span>append</span><span>(</span><span>light</span><span>)</span>
            <span>elif</span> <span>'brightness'</span> <span>in</span> <span>attrs</span><span>[</span><span>'supported_color_modes'</span><span>]:</span>
                <span>brightness_lights</span><span>.</span><span>append</span><span>(</span><span>light</span><span>)</span>
            <span>else</span><span>:</span>
                <span>other_lights</span><span>.</span><span>append</span><span>(</span><span>light</span><span>)</span>
        <span>else</span><span>:</span>
            <span>other_lights</span><span>.</span><span>append</span><span>(</span><span>light</span><span>)</span>

    <span>return</span> <span>{</span>
        <span>'Color Temperature'</span><span>:</span> <span>color_temp_lights</span><span>,</span>
        <span>'Brightness Only'</span><span>:</span> <span>brightness_lights</span><span>,</span>
        <span>'Other'</span><span>:</span> <span>other_lights</span>
    <span>}</span>

<span># Main execution
</span><span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span><span>:</span>
    <span>all_lights</span> <span>=</span> <span>get_all_lights</span><span>()</span>
    <span>print</span><span>(</span><span>"</span><span>\n</span><span>=== All Lights Analysis ==="</span><span>)</span>
    <span>print</span><span>(</span><span>f</span><span>"Found </span><span>{</span><span>len</span><span>(</span><span>all_lights</span><span>)</span><span>}</span><span> lights in total"</span><span>)</span>

    <span># Group lights by capability
</span>    <span>grouped_lights</span> <span>=</span> <span>group_lights_by_capability</span><span>(</span><span>all_lights</span><span>)</span>

    <span># Analyze each capability group
</span>    <span>for</span> <span>group_name</span><span>,</span> <span>lights</span> <span>in</span> <span>grouped_lights</span><span>.</span><span>items</span><span>():</span>
        <span>if</span> <span>lights</span><span>:</span>  <span># Only analyze groups that have lights
</span>            <span>analyze_current_state</span><span>(</span><span>lights</span><span>,</span> <span>group_name</span><span>)</span>
</code></pre></div>

<ol>
  <li><strong>Run the custom parsing script</strong> on my Home Assistant setup to produce a detailed list of bulbs and their capabilities.</li>
  <li><strong>Feed the output</strong> into Cursor (in “agent mode” or similar), along with my old configuration.</li>
  <li><strong>Have Cursor generate</strong> the updated YAML for the new Adaptive Lighting system.</li>
</ol>

<p>It’s been a huge time-saver. Sure, I still do some manual debugging, but I also use Cursor to assist with the troubleshooting. For instance, if something breaks in Home Assistant, I feed the logs into Cursor and ask it to help me fix the error. It’s surprisingly effective.</p>

<h2 id="ikea-advice">IKEA Advice</h2>

<p>After extensive testing, I’ve optimized my adaptive lighting configurations for different IKEA bulb types. Here are my recommended settings that provide smooth transitions while maintaining good visibility throughout the day.</p>

<h3 id="dimmable-white-spectrum">Dimmable white spectrum</h3>

<p>For IKEA’s <em>LED bulb GU10 345 lumen, smart/wireless dimmable white spectrum</em> bulbs.</p>

<div><pre><code>  <span>-</span> <span>name</span><span>:</span> <span>adapt_brightness_standard_color_temp</span>
    <span>lights</span><span>:</span>
      <span>-</span> <span>light.light_1</span>
      <span>-</span> <span>light.light_2</span>
    <span>min_brightness</span><span>:</span> <span>50</span>
    <span>max_brightness</span><span>:</span> <span>100</span>
    <span>min_color_temp</span><span>:</span> <span>2202</span>
    <span>max_color_temp</span><span>:</span> <span>4000</span>
    <span>sleep_brightness</span><span>:</span> <span>1</span>
    <span>sleep_color_temp</span><span>:</span> <span>2202</span>
    <span>transition</span><span>:</span> <span>45</span>
    <span>interval</span><span>:</span> <span>90</span>
    <span>initial_transition</span><span>:</span> <span>1</span>
    <span>prefer_rgb_color</span><span>:</span> <span>false</span>
</code></pre></div>

<h3 id="dimmable-color-and-white-spectrum">Dimmable color and white spectrum</h3>

<p>For the <em>LED bulb E27 806 lumen, wireless dimmable color and white spectrum/globe opal white</em> bulbs.</p>

<div><pre><code>  <span>-</span> <span>name</span><span>:</span> <span>adapt_brightness_extended_color_temp</span>
    <span>lights</span><span>:</span>
      <span>-</span> <span>light.light_3</span>
      <span>-</span> <span>light.light_4</span>
    <span>min_brightness</span><span>:</span> <span>70</span>
    <span>max_brightness</span><span>:</span> <span>100</span>
    <span>min_color_temp</span><span>:</span> <span>2000</span>
    <span>max_color_temp</span><span>:</span> <span>6535</span>
    <span>sleep_brightness</span><span>:</span> <span>1</span>
    <span>sleep_color_temp</span><span>:</span> <span>2000</span>
    <span>transition</span><span>:</span> <span>45</span>
    <span>interval</span><span>:</span> <span>90</span>
    <span>initial_transition</span><span>:</span> <span>1</span>
    <span>prefer_rgb_color</span><span>:</span> <span>false</span>
</code></pre></div>

<h3 id="dimmable-warm-white">Dimmable warm white</h3>

<p>For the basic <em>LED bulb GU10 345 lumen, smart/wireless dimmable warm white</em> bulbs.</p>

<div><pre><code>  <span>-</span> <span>name</span><span>:</span> <span>adapt_brightness_brightness_only</span>
    <span>lights</span><span>:</span>
      <span>-</span> <span>light.light_5</span>
      <span>-</span> <span>light.light_6</span>
    <span>min_brightness</span><span>:</span> <span>50</span>
    <span>max_brightness</span><span>:</span> <span>100</span>
    <span>sleep_brightness</span><span>:</span> <span>1</span>
    <span>transition</span><span>:</span> <span>45</span>
    <span>interval</span><span>:</span> <span>90</span>
    <span>initial_transition</span><span>:</span> <span>1</span>
</code></pre></div>

<h2 id="next-steps-smart-trvs">Next Steps: Smart TRVs</h2>

<p>Now that the lighting is running smoothly, my next big smart home project is upgrading all my radiators with Zigbee-based smart TRVs (thermostatic radiator valves). The goal is to have each room in my home maintain an optimal temperature by reading from the central Nest thermostat. In older British homes like mine, temperature control isn’t very granular, so having each radiator adjust itself is a major comfort and efficiency boost.</p>

<p>I’ve already purchased <a href="https://s.click.aliexpress.com/e/_EzwaYAM">these TRVs</a> but haven’t had time to configure them yet. My plan is:</p>

<ol>
  <li><strong>Pair the TRVs</strong> to my Zigbee network.</li>
  <li><strong>Pull temperature data</strong> from my Nest thermostat (the main sensor).</li>
  <li><strong>Set up automations</strong> in Home Assistant so that each room’s radiator valve opens or closes based on its own target temperature.</li>
</ol>

<p>I’m hoping this will help solve the typical British house problem: some rooms end up too warm, while others are never warm enough. With per-room heating control, it should be far more balanced and efficient.</p>

<h2 id="conclusion-so-far">Conclusion (So Far)</h2>

<p>That’s where my Home Assistant journey sits at the moment. I’m thrilled with how the adaptive lighting is working, especially now that I’ve harnessed an AI coding assistant to manage the complexity of my YAML files. The next challenge, smart radiator valves, will hopefully bring my home’s temperature control on par with my lighting automation.</p>


        <i>Found an error or typo? File PR against <a href="https://github.com/vpetersson/vpetersson.com/tree/master/_posts/2025-01-22-how-i-use-home-assistant-in-2025.md" rel="nofollow">this file</a>.</i>
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bluesky's science takeover: 70% of Nature poll respondents use platform (115 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-025-00177-1</link>
            <guid>42813316</guid>
            <pubDate>Fri, 24 Jan 2025 14:27:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-025-00177-1">https://www.nature.com/articles/d41586-025-00177-1</a>, See on <a href="https://news.ycombinator.com/item?id=42813316">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-test="access-teaser"> <figure><picture><source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-025-00177-1/d41586-025-00177-1_50491424.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-025-00177-1/d41586-025-00177-1_50491424.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px"><img alt="The silhouettes of several people using digital devices against the blue backdrop of the Bluesky logo." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-025-00177-1/d41586-025-00177-1_50491424.jpg"><figcaption><p><span>Social-media platform Bluesky has more than 27 million users.</span><span>Credit: Peter Kováč/Alamy</span></p></figcaption></picture></figure><p>Seventy per cent of <i>Nature</i> readers who responded to an <a href="https://www.nature.com/articles/d41586-025-00037-y" data-track="click" data-label="https://www.nature.com/articles/d41586-025-00037-y" data-track-category="body text link">online poll</a> are using the social-media platform Bluesky, which works a lot like X (formerly Twitter) and whose popularity has soared in recent months, in particular since the <a href="https://www.nature.com/articles/d41586-024-03635-4" data-track="click" data-label="https://www.nature.com/articles/d41586-024-03635-4" data-track-category="body text link">November US election</a>.</p><p>Although the survey is not statistically representative of <i>Nature</i> readers or the scientific community at large, it echoes <a href="https://www.nature.com/articles/d41586-024-03784-6" data-track="click" data-label="https://www.nature.com/articles/d41586-024-03784-6" data-track-category="body text link">recent enthusiasm for Bluesky</a> among researchers and <a href="https://www.nature.com/articles/d41586-023-02554-0" data-track="click" data-label="https://www.nature.com/articles/d41586-023-02554-0" data-track-category="body text link">disillusionment with X</a>. Of roughly 5,300 readers who responded to a question about X, 53% said they used to be on X but have now left (see ‘Mass exodus’).</p><figure><picture><source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-025-00177-1/d41586-025-00177-1_50509360.png?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-025-00177-1/d41586-025-00177-1_50509360.png?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px"><img alt="MASS EXODUS. Graphic shows 53% of respondents to a Nature survey said they used to be on the platform X but have now left." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-025-00177-1/d41586-025-00177-1_50509360.png"><figcaption><p><span>Source: L. Balduf <i>et al</i>. Preprint at arXiv <a href="https://doi.org/10.48550/arXiv.2501.11605" data-track="click" data-label="https://doi.org/10.48550/arXiv.2501.11605" data-track-category="body text link">https://doi.org/10.48550/arXiv.2501.11605</a> (2025)</span></p></figcaption></picture></figure><p>“Bluesky is much better for science. There is much less toxicity, misinformation, and distractions,” wrote one respondent. “My feed is almost entirely scientists and I actually get updates on research that is relevant and timely,” wrote another.</p><p>Bluesky now has more than 27 million users and is broadly similar in functionality and user experience to X, which for a long time was a go-to platform for scientists to discuss and disseminate their work. X fell out of favour with some after entrepreneur <a href="https://www.nature.com/articles/d41586-024-04098-3" data-track="click" data-label="https://www.nature.com/articles/d41586-024-04098-3" data-track-category="body text link">Elon Musk</a> purchased the tool in October 2022.</p><p>In <i>Nature</i>’s survey, 55% of respondents to the question ‘What do you use Bluesky for?’ said it was a mix of three research-related activities: to connect with other scientists, keep up to date with other research or researchers, and promote their own research (see ‘Online connections’).</p><figure><picture><source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-025-00177-1/d41586-025-00177-1_50508222.png?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-025-00177-1/d41586-025-00177-1_50508222.png?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px"><img alt="ONLINE CONNECTIONS. Graphic shows 55% of respondents to Nature's poll said they used Bluesky to to connect with other scientists, keep up to date with other research or researchers and promote their own research." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-025-00177-1/d41586-025-00177-1_50508222.png"><figcaption><p><span>Source: L. Balduf <i>et al</i>. Preprint at arXiv <a href="https://doi.org/10.48550/arXiv.2501.11605" data-track="click" data-label="https://doi.org/10.48550/arXiv.2501.11605" data-track-category="body text link">https://doi.org/10.48550/arXiv.2501.11605</a> (2025)</span></p></figcaption></picture></figure><p>In total, almost 6,000 readers responded to <i>Nature’s</i> poll, which ran from 14 to 17 January 2025. We solicited responses on the <a href="https://www.nature.com/" data-track="click" data-label="https://www.nature.com/" data-track-category="body text link"><i>Nature</i> website,</a> on social media and in the <a href="https://www.nature.com/briefing/signup" data-track="click" data-label="https://www.nature.com/briefing/signup" data-track-category="body text link">Nature Briefing</a>, an e-mail newsletter. Of the almost 5,000 respondents who answered a question about their work, 85% — or 3,970 — said that they were working scientists. A similar number responded to a question about their field of study: 38% said they worked in biological sciences, 11% in computing or information sciences, 9% in physical sciences and 9% in environmental sciences. Answers came from scientists in 84 countries or regions, with the most coming from the United States (33%), followed by the United Kingdom (15%) and Germany (12%). </p><h2>Positive vibes</h2><p>Thousands of survey respondents wrote expressively about how they think Bluesky stacks up against X. “Bluesky compares beautifully so far. More civil and informed conversations,” wrote one. Other positive terms that respondents used to contrast the platform with X included more pleasant, more supportive, friendlier, kinder, nicer, more collegial, uplifting, more peaceful and safer.</p><p>A sense of safety is particularly valuable to researchers who teach or lead teams. “I feel that I can recommend it to students and trainees. I can’t do that for X, it is not a safe learning space,” wrote one respondent. </p><p>Some wrote that Bluesky is a better forum than X for discussing science, because debate there is more measured and more focused, with less hostility. “I find it much less antagonistic to science,” said one respondent.</p><p>But with less heated debate and fewer users than X, some find Bluesky boring. That could change if it continues to attract new users at pace (see ‘Bluesky growth’). “Was pretty sleepy until November 2024. Now there seems to be enough critical mass of researchers in my field to find new research and connect again,” wrote one respondent.</p><figure><picture><source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-025-00177-1/d41586-025-00177-1_50509076.png?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-025-00177-1/d41586-025-00177-1_50509076.png?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px"><img alt="BLUESKY GROWTH. Chart shows the rapid increase in the number of Bluesky users since mid-2024." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-025-00177-1/d41586-025-00177-1_50509076.png"><figcaption><p><span>Source: L. Balduf <i>et al</i>. Preprint at arXiv <a href="https://doi.org/10.48550/arXiv.2501.11605" data-track="click" data-label="https://doi.org/10.48550/arXiv.2501.11605" data-track-category="body text link">https://doi.org/10.48550/arXiv.2501.11605</a> (2025)</span></p></figcaption></picture></figure><h2>Fewer fascists?</h2><p>Other marks in Bluesky’s favour noted by survey respondents include the perception that there are fewer “Nazis” on the platform than on X, and less racism; that it is not owned or deemed to be influenced by Musk; and that it does not host advertisements.</p><p>X could not be reached for comment on these criticisms before this article was published.</p><p>Not all <i>Nature</i> readers love Bluesky. One criticism that emerged in the survey responses contends that it is a leftwing echo chamber. “Bluesky is full of woke crazy people who will threaten you with violence if you disagree with the liberal narrative,” said one respondent. </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Little Snitch feature nobody knows about (139 pts)]]></title>
            <link>https://lapcatsoftware.com/articles/2025/1/6.html</link>
            <guid>42813231</guid>
            <pubDate>Fri, 24 Jan 2025 14:18:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lapcatsoftware.com/articles/2025/1/6.html">https://lapcatsoftware.com/articles/2025/1/6.html</a>, See on <a href="https://news.ycombinator.com/item?id=42813231">Hacker News</a></p>
<div id="readability-page-1" class="page">
<nav>
Previous: <a href="https://lapcatsoftware.com/articles/2025/1/5.html">New secure note on macOS Sequoia</a>
<br><a href="https://lapcatsoftware.com/articles/index.html" title="The Desolation of Blog">Articles index</a></nav>
<header><a href="https://lapcatsoftware.com/">Jeff Johnson</a> (<a href="https://underpassapp.com/">My apps</a>, <a href="https://www.paypal.me/JeffJohnsonWI">PayPal.Me</a>, <a href="https://mastodon.social/@lapcatsoftware" title="@lapcatsoftware@mastodon.social">Mastodon</a>)</header>

<h3>January 24 2025</h3>

<p><a href="https://www.obdev.at/products/littlesnitch/">Little Snitch</a> by Objective Development is the first app that I install on a new Mac. In fact I just bought a new Mac, an M4 MacBook Pro with nano-texture display, and I installed Little Snitch via thumb drive even before connecting the Mac to the internet. While setting up my new Mac, which came with macOS 15.2 preinstalled, I noticed that Safari attempted to connect to <code>ssl.gstatic.com</code> on launch. That domain is owned by Google!</p>
<p><img src="https://lapcatsoftware.com/articles/2025/1/6-images/1.png" width="588" height="350" alt="Safari wants to connect to ssl.gstatic.com on TCP port 443 (https)"></p>
<p>I denied the connection, but it kept happening on every launch, despite the fact that I set Safari to open with a new private window and empty page. Moreover, it happened on every launch of Safari Technology Preview too. In the Little Snitch alert window, I pressed the info button, which revealed that the connection was initiated by Safari Search Helper, a separate process from the main Safari app.</p>
<p><img src="https://lapcatsoftware.com/articles/2025/1/6-images/2.png" width="670" height="662" alt="Established by /System/Volumes/Preboot/Cryptexes/Incoming/OS/System/Library/PrivateFrameworks/SafariShared.framework/Versions/A/XPCServices/com.apple.Safari.SearchHelper.xpc/Contents/MacOS/com.apple.Safari.SearchHelper"></p>
<p>Like most web browsers nowadays, Safari launches other processes to perform dedicated tasks. To see this in action, just search for "Safari" in Activity Monitor. The advantage of using separate processes is that each process can have separate privileges, and if one process happens to crash, it doesn't cause the entire app to crash. When an internet connection is initiated by a process launched by an app, Little Snitch attempts to attribute the connection to the main app rather than to the helper process. This attribution usually makes more sense to the Little Snitch user.</p>
<p>I haven't figured out exactly why Safari Search Helper connects to <code>ssl.gstatic.com</code>, but it's definitely related to using Google as the search engine in Safari Search Settings. If I change the search engine to DuckDuckGo, for example, the connection attempts no longer occur on launch. Indeed, if I switch the search engine back from DuckDuckGo to Google in Safari Settings popup button, a connection to <code>ssl.gstatic.com</code> occurs <em>immediately</em>. None of the other search engine choices provoke a connection. I decided to permanently deny all connections to <code>ssl.gstatic.com</code> from Safari, because there's no good reason for Safari to silently contact Google when I'm not even searching.</p>
<p>Unfortunately, my new Little Snitch rule had an undesirable side effect. Although I'm trying to wean myself off, I still use Gmail, and when you set up Gmail in Mail app, it authenticates your Google account in Safari. However, the authentication kept failing for me. Looking in the Safari web inspector console, it became clear that the problem was some denied <code>ssl.gstatic.com</code> connections. Thus, I was forced to disable my Little Snitch rule and allow Safari to connect to <code>ssl.gstatic.com</code> in order to authenticate Gmail for Mail app.</p>
<p>Oddly, the <code>ssl.gstatic.com</code> connections from Safari stopped entirely after I allowed it to connect once. I discovered, comparing Safari preferences before and after, that <code>WBSOfflineSearchSuggestionsModelLastUpdateDateKey</code> had been set.</p>
<blockquote><code>defaults read com.apple.Safari WBSOfflineSearchSuggestionsModelLastUpdateDateKey</code></blockquote>
<p>I also discovered through experimentation, giving <code>WBSOfflineSearchSuggestionsModelLastUpdateDateKey</code> different date values (technically, they're string values of dates), that Safari checks for updates once a week. Thus, it was clear that Safari would make future <code>ssl.gstatic.com</code> connections, if allowed by Little Snitch. By the way, I should note that I've disabled "Include search engine suggestions" in Safari Search Settings, yet Safari is still apparently trying to download suggestions from Google?</p>
<p>What I wanted to do was create a Little Snitch rule that applied to Safari Search Helper but not to websites loaded in Safari tabs. I tried creating a new rule using the explicit path on disk of Safari Search Helper, but that didn't work. Little Snitch seemed to ignore that rule and continued to attribute Safari Search Helper connections to the Safari app.</p>
<p>I emailed Objective Development to ask whether there's any way to separate the rules in Little Snitch for the two processes, Safari and Safari Search Helper. At first, they said no, but then on reflection, they said yes!</p>
<p><img src="https://lapcatsoftware.com/articles/2025/1/6-images/3.png" width="578" height="566" alt="Safari via com.apple.Safari.SearchHelper"></p>
<p>The trick is to use "via" in the Little Snitch rule. When you're creating the rules, enter the full file paths of the two processes, separated by "via". Little Snitch will automatically replace the paths with the process names. Make sure you match both of the processes by code signing identity too. The above rule denies <code>ssl.gstatic.com</code> connections initiated by Safari Search Helper while otherwise allowing such connections by Safari.</p>
<p>It's nice to know that this trick exists, though it's unlikely that you'll need to use it much. I thought the trick might help with Google Chrome, but it turns out that most Chrome connections are initiated by the Google Chrome Helper process: not only the web page connections but also the silent connections that run in the background, for example to <code>googleapis.com</code>, <code>accounts.google.com</code>, <code>tools.google.com</code>, <code>clients1.google.com</code>, <code>clients2.google.com</code>, <code>clients3.google.com</code>, etc. Needless to say, Google Chrome phones home a lot! It was disappointing to learn that Safari makes a silent connection to Google too. I guess that the massive yearly default search engine payment from Google to Apple buys a lot of access.</p>

<header><a href="https://lapcatsoftware.com/">Jeff Johnson</a> (<a href="https://underpassapp.com/">My apps</a>, <a href="https://www.paypal.me/JeffJohnsonWI">PayPal.Me</a>, <a href="https://mastodon.social/@lapcatsoftware" title="@lapcatsoftware@mastodon.social">Mastodon</a>)</header>
<nav><a href="https://lapcatsoftware.com/articles/index.html" title="The Desolation of Blog">Articles index</a><br>
Previous: <a href="https://lapcatsoftware.com/articles/2025/1/5.html">New secure note on macOS Sequoia</a>
</nav>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Every System is a Log: Avoiding coordination in distributed applications (139 pts)]]></title>
            <link>https://restate.dev/blog/every-system-is-a-log-avoiding-coordination-in-distributed-applications/</link>
            <guid>42813049</guid>
            <pubDate>Fri, 24 Jan 2025 13:57:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://restate.dev/blog/every-system-is-a-log-avoiding-coordination-in-distributed-applications/">https://restate.dev/blog/every-system-is-a-log-avoiding-coordination-in-distributed-applications/</a>, See on <a href="https://news.ycombinator.com/item?id=42813049">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><hr><p><strong>Building resilient distributed applications remains a tough challenge.</strong></p><p>It should be possible to focus almost entirely on the business logic and the complexity inherent to the domain. Instead, you need to review line-by-line and check: <em>“what if the service crashes here?”</em>, <em>“what if the API we call here is temporarily unavailable”</em>, <em>“what if a concurrent invocation overtakes this one here”</em>, or <em>“what if this process becomes a zombie while executing this function, how do I prevent it from corrupting the state?”</em>.</p><p>As a result, you spend a huge amount of time worrying about failover strategies, retries, race conditions, locking/fencing, ordering of operations, order visibility of changes, decoupling availability, etc. They add queues, key-value stores, locking services, schedulers, workflow orchestrators and they try to get them all to play nice together. And the hard truth is, many applications don’t get it right and are not correct under failures or even under load.</p><p><img alt="Problems in distributed applications and services" src="https://restate.dev/blog/every-system-is-a-log-avoiding-coordination-in-distributed-applications/dist_app_problems.png"></p><p>How can we radically simplify this? In this article, we walk through a core idea that addresses many of these issues, by avoiding distributed coordination. Much of this goes back to learnings from when we built <a href="https://flink.apache.org/">Apache Flink</a>.</p><p>Let’s start with an observation about distributed applications and infrastructure: <strong>Every System is a log.</strong></p><ul><li><p><strong>Message queues</strong> are logs: <a href="https://kafka.apache.org/">Apache Kafka</a>, <a href="https://pulsar.apache.org/">Pulsar</a>, <a href="https://engineering.fb.com/2019/10/07/core-infra/scribe/">Meta’s Scribe</a> are distributed implementations of the log abstraction. Message brokers (e.g., RabbitMQ, SQS) internally replicate messages through logs.</p></li><li><p><strong>Databases</strong> (and K/V stores) are logs: changes go to the write-ahead-log first, then get materialized into the tables. The database community has the famous saying <em>“The log is the database; everything else is cache (or materialized views)”</em> - often attributed to <a href="https://www.linkedin.com/in/pathelland">Pat Helland</a>. The idea of <a href="https://martin.kleppmann.com/2015/11/05/database-inside-out-at-oredev.html">“Turning the Database Inside Out”</a> starts with a log.</p></li><li><p>Distributed <strong>locking- and leader election services</strong> (like <a href="https://zookeeper.apache.org/">ZooKeeper</a>, <a href="https://etcd.io/">Etcd</a>, …) are consensus logs at their core. Consensus algorithms, like Raft, inherently model log replication.</p></li><li><p>Persistent <strong>state machines</strong> materialize logs of their state transitions.</p></li></ul><p>When you build an application or microservice that interacts, for example, with a database, a message queue, and a service API (backed by another database), you are orchestrating a handful of different logs in your business logic.</p><h2 id="applications-need-to-orchestrate-many-logs">Applications need to orchestrate many logs </h2><p>In this example, we want to implement a <code>processPayment</code> handler. The payment has an ID that identifies it. The handler is triggered from a queue (which also re-delivers the event if the handler fails or times out) and the processing involves checking a fraud detection model, updating account balance, storing the status, and sending a notification. There are other handlers that may handle the same payment ID, for example to cancel the payment, block it, unblock it, revert it.</p><p><img alt="An example, naïve implementation" src="https://restate.dev/blog/every-system-is-a-log-avoiding-coordination-in-distributed-applications/code_simple.png"></p><p>You can probably spot some issues:</p><ol><li>Concurrent invocations <em>(other handlers like “cancel”, or retries of the same event)</em> can produce arbitrary results.</li><li>A failure after line 15 means the next retry does nothing and we don’t send a notification.</li><li>If the fraud model is not completely deterministic (or if it is updated between retries), we might assume a payment is valid, crash after line 9, the retry declares the payment not valid, and we are setting the status to BLOCKED despite the fact that we withdrew the money.</li></ol><p>Nasty stuff! Let’s try to improve that.</p><p><img alt="An example, more elaborate implementation" src="https://restate.dev/blog/every-system-is-a-log-avoiding-coordination-in-distributed-applications/code_complex.png"></p><p>This second version of the code does some things better, but still has issues. One of them is around line 20, where we need to ensure that we are still the owner of the lock at the point in time where the database persists the update. That is really hard to do, because distributed lock release or re-entrance is never 100% correct, due to the impossibility of precise failure detection <em>(is a process failed or just slow or is our network partitioned?)</em>, so locking generally requires an additional fencing mechanism. Martin Kleppmann has <a href="https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html">a great blog post</a> about the rabbit hole of getting distributed locking right.</p><p>Why is it so hard to make this seemingly simple handler work reliably? Because our goal is to make consistent changes depending on the status of disparate systems, where each has its own view of the world, maintained in its separate log.</p><p>Distributed applications often need to <span>implement a complex orchestration of all the systems they interact with</span>, carefully <span>designing all states and operations, to establish order and invariants</span> that help them ensure correctness. This is the heart of much of the complexity in modern distributed applications.</p><h2 id="what-if-it-were-all-the-same-log">What if it were all the same Log? </h2><p>Now let’s assume that all these systems (queues, DBs, locks, …) operate off the same log - for the sake of this thought experiment - the log of the message queue that delivers the <code>PaymentEvent</code> to the <code>processPayment</code> handler (the <em>upstream log</em>).</p><p>Every time our <code>processPayment</code> handler wants to change some state of another system, it writes a record to the upstream log. That new record is linked to the original <code>PaymentEvent</code>. Whenever the queue decides to re-deliver the <code>PaymentEvent</code> again (e.g., under a timeout or an assumed failure), it also attaches all linked log entries (the <em>journal</em>).</p><p><img alt="Implementing a step journal into the log" src="https://restate.dev/blog/every-system-is-a-log-avoiding-coordination-in-distributed-applications/one_log_journal.png"></p><p>Now we can adjust lines 9,10,11 (the call to the fraud-detector API and storing the result) to write the result of the API call to the upstream log. When the handler is retried after a potential failure, it automatically sees whether the result was written before. This is not just efficient, but we no longer store completed steps in a shared DB where it is easy to have it accidentally picked up in unexpected ways (see <a href="https://portswigger.net/research/smashing-the-state-machine">this article</a> for how this can be a severe security and integrity loophole).</p><p>This becomes particularly useful, if we require a <em>conditional append</em> to add an entry to the log: We can only append that entry, if no newer retry was triggered. That is easy for a queue to track (it knows whether it sent the <code>PaymentEvent</code> out again) and our <code>processPayment</code> handler would quit if the conditional append failed, knowing that another retry attempt has taken over.</p><p>Now, concurrently executing retries (if the queue incorrectly assumes a handler failed and re-sent the event) can no longer corrupt the step history. This implementation gives us pretty strong workflow-style execution guarantees for our code!</p><p><img alt="Safety through conditional appends to the log" src="https://restate.dev/blog/every-system-is-a-log-avoiding-coordination-in-distributed-applications/one_log_conditional_append.png"></p><p>To make locking (line 2) and state update (line 20) work reliably, the <code>processPayment</code> handler writes the relevant events (<em>acquire lock</em>, <em>release lock</em>, <em>update state</em>) to the upstream log as well. After writing the <em>acquire lock</em> event, the handler waits until the lock service grants the lock.<br>The lock service and the database now follow the upstream log as if it was their own write-ahead log. The database can simply apply the update when it reads the event, the locking service of course only grants the lock when available (might have to wait to encounter the previous holder’s <em>release lock</em> event).</p><p><img alt="Locking and state management through the log" src="https://restate.dev/blog/every-system-is-a-log-avoiding-coordination-in-distributed-applications/one_log_lock_state.png"></p><p>Somewhat surprisingly, this pretty much eliminates all problems and corner cases we had with locks and state before: Lock acquisition and release through the upstream log and handler’s journal means we reliably keep the lock across retries. Having the update event conditionally appended to the same event journal as the lock event replaces the need for the lock’s fencing token - plus, we can be sure that we apply the update once and only once.</p><p>So, once we implement our logic like this, EVERYTHING JUST WORKS.</p><p>We can inject all sorts of failures, stalls, network partitions. As long as the log is correctly implemented, the program will always remain correct. And all that the <code>processPayment</code> handler needs to do is (1) trigger actions as conditional-log-appends and (2) skip over actions whose log entries are already attached to the <code>PaymentEvent</code>. This is super easy to implement in a library, because it doesn’t require any form of distributed coordination.</p><h2 id="if-everythings-in-one-log-theres-nothing-to-coordinate">If everything’s in one log, there’s nothing to coordinate </h2><p>We haven’t added a new distributed system primitive; in fact we’ve removed several. The benefits come from avoiding the need for coordination.</p><p>Before we started using the same log, the state was spread across systems: The status of the operation, whether a lock is held, who held it, what value a branch was based on. Because each system maintains their state as if it was independent, the different parts of the state can get out-of-sync and be altered in unexpected ways (e.g., through a race condition or zombie process). It’s hard to implement robust logic and guarantee strong invariants that way.</p><p>Having a single place (the one log) that forces a linear history of events as the ground truth and owns the decision of who can add to that ground truth, means we don’t have to coordinate much any more.</p><p>Coordination avoidance is one of the few silver bullets in distributed systems - a way to reduce complexity, rather than shift it. For example, guarding our second code snippet with a ZooKeeper lock only shifted complexity. It reduced the code’s need to worry about concurrency, but introduced issues around lost locks and cleanup of persistent locks. In contrast, the approach to unify the different states in one log actually reduced work, which resulted in higher efficiency, fewer corner cases, and easier operations.</p><p>I know what you’re thinking: That’s a nice thought experiment, but my queue/log doesn’t work like that, my database doesn’t follow some other log, and isn’t this breaking all rules for separation of concerns?</p><h2 id="adopting-this-idea-in-practice">Adopting this idea in practice </h2><p>This idea can serve as a conceptual blue-print for an architecture based on a log (e.g., Kafka) - a bit like <a href="https://martin.kleppmann.com/2015/11/05/database-inside-out-at-oredev.html">“Turning the Database Inside Out”</a> <em>(maybe we should call this “Turning the Microservice Inside Out?”)</em>. In practice, today’s log implementations miss efficient built-in ways to track retries, make conditional-appends, link events into a journal, and would leave that to the application developer to implement.</p><p><a href="https://restate.dev/"><strong>Restate</strong></a> is an implementation of this idea. Restate Server is the broker that owns the upstream log and push-invokes the handlers with events (e.g., similar to AWS SNS and Event Bridge), ensuring reliable retries after crashes. Every event gets the latest <em>execution journal</em> (set of linked events) attached, just as described in the thought experiment above. Restate uses bi-directional streaming protocols (e.g., HTTP/2) to invoke the event handlers and send journal events and acknowledgements back and forth.</p><p><img alt="Restate in an application stack" src="https://restate.dev/blog/every-system-is-a-log-avoiding-coordination-in-distributed-applications/restate_in_the_stack.png"></p><p>The server issues a <em>unique epoch to every invocation and retry</em>, which the SDK attaches to every journal event that it sends, allowing the server to reject events from subsumed handler executions <em>(the conditional append)</em>.</p><p>The code snippet shows the example in Restate’s API <em>(here TypeScript, but Java, Kotlin, Python, Go, and Rust are supported as well)</em>. The code does not explicitly append log events, but rather uses an SDK for actions, and the SDK interacts with the log.</p><p><img alt="Example code with the Restate SDK" src="https://restate.dev/blog/every-system-is-a-log-avoiding-coordination-in-distributed-applications/code_restate.png"></p><p>To persist intermediate steps (line 8), handlers use the SDK (<code>ctx.run</code>), which sends the event to the log and awaits the ack of the conditional append to the event’s <em>execution journal</em>. On retries, the SDK checks the <em>journal</em> whether the step’s event already exists and restores the result from there directly.</p><p>Messages to other handlers are transported with exactly-once semantics (line 16). Message and RPC events are both added to the journal and routed to the destination handler. Similar to <code>ctx.run</code>, the journal deduplicates the message-sending steps. Because messages result in a single durable invocation (sequence of retries that share a journal), you can easily build end-to-end exactly-once semantics on top of this.</p><p>Restate supports handlers that lock a key when executing (and hold the lock across retries). Those handlers can read and update state that is scoped to that key. They are implemented similarly to the thought experiment: The lock and state update events are added to the journal and additionally processed by an embedded lock service and K/V store, making locks and state virtually incorruptible through partial failures, race conditions, zombie processes, etc.<br>These stateful handlers can be grouped together to share state. Restate calls that a <em>Virtual Object</em>, because the handlers are like methods with access to the object instance’s state. The state is infinitely retained in the K/V store, even when the log events eventually get garbage collected.</p><p><img alt="Virtual Objects in Restate" src="https://restate.dev/blog/every-system-is-a-log-avoiding-coordination-in-distributed-applications/virtual_object.png"></p><p>There are more building blocks in Restate, including <em>persistent Futures/Promises</em>, <em>timers</em>, or <em>idempotency-keys</em> . They all build on the same concept: Events routed through the same log, stored in the journal, and processed into a database or scheduler.</p><p>Applications often aim to create the behavior of <span>stateful, reliable, and resumable execution</span> for their critical functions. The single-log approach provides that with a single dependency and without coordination across queues, DBs, locks, and schedulers. Restate implements that pattern.</p><h2 id="blast-radius-and-separation-of-concerns">Blast radius and separation of concerns </h2><p>It would not make sense to use a single log for every operation in a distributed multi-service architecture. While it could give interesting properties, this would couple services too tightly, create a single giant blast radius, and void many benefits of service-oriented designs.</p><p>The sweet-spot we target with Restate’s implementation of this idea, is to drive all state that is strictly scoped to a handler or service through the log, plus transport of messages between services. The result is a coupling and blast radius similar to any event-driven service: If the upstream queue/log is down, the service cannot be invoked.</p><h3 id="state-in-a-database-or-in-the-log">State in a database or in the log? </h3><p>We assume that Restate is not going to replace general purpose databases. Shared databases should and will remain a part of the infrastructure, and continue to do what they are great at.</p><p>The K/V state built on the log is a great fit for state machines <em>(like the status of a payment)</em>, temporary state when joining/aggregating events and signals, or really any state that is purely updated through the event-driven handlers and scoped around a key (though a key may be something broader, like an aggregate root in Domain Driven Design).</p><p>It also gives you the building blocks for a highly robust and consistent core state. You can even use that to build overlays over other stores, track metadata like versions for entries in databases, or build data structures like semaphores. <a href="https://github.com/restatedev/examples/blob/main/typescript/patterns-use-cases/src/database/main.ts">Here is an example</a> of how to use this to make exactly-once updates to databases from handlers.</p><h2 id="whats-next">What’s next? </h2><p>If you want to try this pattern out for yourself and see and feel this idea in action, Restate is open source and you can download it at <a href="https://restate.dev/get-restate/">https://restate.dev/get-restate/</a></p><p>Today, Restate runs on a single node - similar to a Postgres database server. <span>In the next few weeks, we will release a first version of Distributed Restate</span>, supporting replication, scale out deployments, working with object store snapshots - stay tuned for more exciting updates during that release.</p><p>With the release, we will publish Part 2 of this article, which is looking at the design of the broker that maintains that log, drives the execution, retries, and implements the extensible logic to use the log for communication, locking, journaling, state, signals, scheduling, etc. As you might expect, if the core abstraction is a log, that system is a specific type of event-driven architecture.</p><p>In Part 3 of this series, we look at the implementation of the log that backs everything. Why not just use Kafka? Or just use Postgres?
In this case, we opted to develop a new type of log - something that generally one shouldn’t do, but once in a while, there is actually a good case for it. We believe that this is one of those cases, and will discuss the details of the log design, what makes it unique, and what it can do that’s hard to do with any existing implementation.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lightpanda: The headless browser designed for AI and automation (150 pts)]]></title>
            <link>https://github.com/lightpanda-io/browser</link>
            <guid>42812859</guid>
            <pubDate>Fri, 24 Jan 2025 13:34:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/lightpanda-io/browser">https://github.com/lightpanda-io/browser</a>, See on <a href="https://news.ycombinator.com/item?id=42812859">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a href="https://lightpanda.io/" rel="nofollow"><img src="https://camo.githubusercontent.com/724ab0ebf840402c19f060613ddf7325e901d6b37fd3c7ed6c72ec278ff51c1c/68747470733a2f2f63646e2e6c6967687470616e64612e696f2f6173736574732f696d616765732f6c6f676f2f6c70642d6c6f676f2e706e67" alt="Logo" height="170" data-canonical-src="https://cdn.lightpanda.io/assets/images/logo/lpd-logo.png"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Lightpanda Browser</h2><a id="user-content-lightpanda-browser" aria-label="Permalink: Lightpanda Browser" href="#lightpanda-browser"></a></p>
<p dir="auto"><a href="https://lightpanda.io/" rel="nofollow">lightpanda.io</a></p>
<p dir="auto"><a href="https://github.com/lightpanda-io/browser/commits/main"><img src="https://camo.githubusercontent.com/bd89bc3f2433bdd3f082a6333bc730ed0dda1f3085cf214e0509f64a9af27cd0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d69742d61637469766974792f6d2f6c6967687470616e64612d696f2f62726f77736572" alt="Commit Activity" data-canonical-src="https://img.shields.io/github/commit-activity/m/lightpanda-io/browser"></a>
<a href="https://github.com/lightpanda-io/browser/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/2319a00670dc456df2849c9abef84e1e77689f093f9c28f92fff3946af70f301/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6c6967687470616e64612d696f2f62726f77736572" alt="License" data-canonical-src="https://img.shields.io/github/license/lightpanda-io/browser"></a>
<a href="https://twitter.com/lightpanda_io" rel="nofollow"><img src="https://camo.githubusercontent.com/280d25e78f9721602e5435e41fe5c3a042f327306ecaff835d07fadc38dece32/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f6c6967687470616e64615f696f" alt="Twitter Follow" data-canonical-src="https://img.shields.io/twitter/follow/lightpanda_io"></a>
<a href="https://github.com/lightpanda-io/browser"><img src="https://camo.githubusercontent.com/46dacea76d8f88071e7194f7e6525372f421c33afc1743993a434f3c01e8fd07/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6967687470616e64612d696f2f62726f77736572" alt="GitHub stars" data-canonical-src="https://img.shields.io/github/stars/lightpanda-io/browser"></a></p>
<p dir="auto">Lightpanda is the open-source browser made for headless usage:</p>
<ul dir="auto">
<li>Javascript execution</li>
<li>Support of Web APIs (partial, WIP)</li>
<li>Compatible with Playwright, Puppeteer through CDP (WIP)</li>
</ul>
<p dir="auto">Fast web automation for AI agents, LLM training, scraping and testing with minimal memory footprint:</p>
<ul dir="auto">
<li>Ultra-low memory footprint (9x less than Chrome)</li>
<li>Exceptionally fast execution (11x faster than Chrome) &amp; instant startup</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/523cfe4ac41a2ab2deccebd0b9197e8232a4a25c0511d014408181064ae853da/68747470733a2f2f63646e2e6c6967687470616e64612e696f2f6173736574732f696d616765732f62656e63686d61726b5f323032342d31322d30342e706e67"><img width="500px" src="https://camo.githubusercontent.com/523cfe4ac41a2ab2deccebd0b9197e8232a4a25c0511d014408181064ae853da/68747470733a2f2f63646e2e6c6967687470616e64612e696f2f6173736574732f696d616765732f62656e63686d61726b5f323032342d31322d30342e706e67" data-canonical-src="https://cdn.lightpanda.io/assets/images/benchmark_2024-12-04.png"></a></p>
<p dir="auto">See <a href="https://github.com/lightpanda-io/demo">benchmark details</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick start" href="#quick-start"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Install from the nightly builds</h3><a id="user-content-install-from-the-nightly-builds" aria-label="Permalink: Install from the nightly builds" href="#install-from-the-nightly-builds"></a></p>
<p dir="auto">You can download the last binary from the <a href="https://github.com/lightpanda-io/browser/releases/tag/nightly">nightly
builds</a> for
Linux x86_64 and MacOS aarch64.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Download the binary
$ wget https://github.com/lightpanda-io/browser/releases/download/nightly/lightpanda-x86_64-linux
$ chmod a+x ./lightpanda-x86_64-linux
$ ./lightpanda-x86_64-linux -h
usage: ./lightpanda-x86_64-linux [options] [URL]

  start Lightpanda browser

  * if an url is provided the browser will fetch the page and exit
  * otherwhise the browser starts a CDP server

  -h, --help      Print this help message and exit.
  --host          Host of the CDP server (default &quot;127.0.0.1&quot;)
  --port          Port of the CDP server (default &quot;9222&quot;)
  --timeout       Timeout for incoming connections of the CDP server (in seconds, default &quot;3&quot;)
  --dump          Dump document in stdout (fetch mode only)"><pre># <span>Download the binary</span>
$ <span>wget https://github.com/lightpanda-io/browser/releases/download/nightly/lightpanda-x86_64-linux</span>
$ <span>chmod a+x ./lightpanda-x86_64-linux</span>
$ <span>./lightpanda-x86_64-linux -h</span>
<span>usage: ./lightpanda-x86_64-linux [options] [URL]</span>

<span>  start Lightpanda browser</span>

<span>  * if an url is provided the browser will fetch the page and exit</span>
<span>  * otherwhise the browser starts a CDP server</span>

<span>  -h, --help      Print this help message and exit.</span>
<span>  --host          Host of the CDP server (default "127.0.0.1")</span>
<span>  --port          Port of the CDP server (default "9222")</span>
<span>  --timeout       Timeout for incoming connections of the CDP server (in seconds, default "3")</span>
<span>  --dump          Dump document in stdout (fetch mode only)</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Dump an URL</h3><a id="user-content-dump-an-url" aria-label="Permalink: Dump an URL" href="#dump-an-url"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ ./lightpanda-x86_64-linux --dump https://lightpanda.io
info(browser): GET https://lightpanda.io/ http.Status.ok
info(browser): fetch script https://api.website.lightpanda.io/js/script.js: http.Status.ok
info(browser): eval remote https://api.website.lightpanda.io/js/script.js: TypeError: Cannot read properties of undefined (reading 'pushState')
<!DOCTYPE html>"><pre>$ <span>./lightpanda-x86_64-linux --dump https://lightpanda.io</span>
<span>info(browser): GET https://lightpanda.io/ http.Status.ok</span>
<span>info(browser): fetch script https://api.website.lightpanda.io/js/script.js: http.Status.ok</span>
<span>info(browser): eval remote https://api.website.lightpanda.io/js/script.js: TypeError: Cannot read properties of undefined (reading 'pushState')</span>
<span>&lt;!DOCTYPE html&gt;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Start a CDP server</h3><a id="user-content-start-a-cdp-server" aria-label="Permalink: Start a CDP server" href="#start-a-cdp-server"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ ./lightpanda-x86_64-linux --host 127.0.0.1 --port 9222
info(websocket): starting blocking worker to listen on 127.0.0.1:9222
info(server): accepting new conn..."><pre>$ <span>./lightpanda-x86_64-linux --host 127.0.0.1 --port 9222</span>
<span>info(websocket): starting blocking worker to listen on 127.0.0.1:9222</span>
<span>info(server): accepting new conn...</span></pre></div>
<p dir="auto">Once the CDP server started, you can run a Puppeteer script by configuring the
<code>browserWSEndpoint</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="'use scrict'

import puppeteer from 'puppeteer-core';

// use browserWSEndpoint to pass the Lightpanda's CDP server address.
const browser = await puppeteer.connect({
  browserWSEndpoint: &quot;ws://127.0.0.1:9222&quot;,
});

// The rest of your script remains the same.
const context = await browser.createBrowserContext();
const page = await context.newPage();

await page.goto('https://wikipedia.com/');

await page.close();
await context.close();"><pre><span>'use scrict'</span>

<span>import</span> <span>puppeteer</span> <span>from</span> <span>'puppeteer-core'</span><span>;</span>

<span>// use browserWSEndpoint to pass the Lightpanda's CDP server address.</span>
<span>const</span> <span>browser</span> <span>=</span> <span>await</span> <span>puppeteer</span><span>.</span><span>connect</span><span>(</span><span>{</span>
  <span>browserWSEndpoint</span>: <span>"ws://127.0.0.1:9222"</span><span>,</span>
<span>}</span><span>)</span><span>;</span>

<span>// The rest of your script remains the same.</span>
<span>const</span> <span>context</span> <span>=</span> <span>await</span> <span>browser</span><span>.</span><span>createBrowserContext</span><span>(</span><span>)</span><span>;</span>
<span>const</span> <span>page</span> <span>=</span> <span>await</span> <span>context</span><span>.</span><span>newPage</span><span>(</span><span>)</span><span>;</span>

<span>await</span> <span>page</span><span>.</span><span>goto</span><span>(</span><span>'https://wikipedia.com/'</span><span>)</span><span>;</span>

<span>await</span> <span>page</span><span>.</span><span>close</span><span>(</span><span>)</span><span>;</span>
<span>await</span> <span>context</span><span>.</span><span>close</span><span>(</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Build from sources</h2><a id="user-content-build-from-sources" aria-label="Permalink: Build from sources" href="#build-from-sources"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Prerequisites</h3><a id="user-content-prerequisites" aria-label="Permalink: Prerequisites" href="#prerequisites"></a></p>
<p dir="auto">Lightpanda is written with <a href="https://ziglang.org/" rel="nofollow">Zig</a> <code>0.13.0</code>. You have to
install it with the right version in order to build the project.</p>
<p dir="auto">Lightpanda also depends on
<a href="https://github.com/lightpanda-io/zig-js-runtime/">zig-js-runtime</a> (with v8),
<a href="https://www.netsurf-browser.org/" rel="nofollow">Netsurf libs</a> and
<a href="https://microsoft.github.io/mimalloc" rel="nofollow">Mimalloc</a>.</p>
<p dir="auto">To be able to build the v8 engine for zig-js-runtime, you have to install some libs:</p>
<p dir="auto">For Debian/Ubuntu based Linux:</p>
<div data-snippet-clipboard-copy-content="sudo apt install xz-utils \
    python3 ca-certificates git \
    pkg-config libglib2.0-dev \
    gperf libexpat1-dev \
    cmake clang"><pre><code>sudo apt install xz-utils \
    python3 ca-certificates git \
    pkg-config libglib2.0-dev \
    gperf libexpat1-dev \
    cmake clang
</code></pre></div>
<p dir="auto">For MacOS, you only need cmake:</p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Install and build dependencies</h3><a id="user-content-install-and-build-dependencies" aria-label="Permalink: Install and build dependencies" href="#install-and-build-dependencies"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">All in one build</h4><a id="user-content-all-in-one-build" aria-label="Permalink: All in one build" href="#all-in-one-build"></a></p>
<p dir="auto">You can run <code>make install</code> to install deps all in one (or <code>make install-dev</code> if you need the development versions).</p>
<p dir="auto">Be aware that the build task is very long and cpu consuming, as you will build from sources all dependancies, including the v8 Javascript engine.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Step by step build dependancy</h4><a id="user-content-step-by-step-build-dependancy" aria-label="Permalink: Step by step build dependancy" href="#step-by-step-build-dependancy"></a></p>
<p dir="auto">The project uses git submodules for dependencies.</p>
<p dir="auto">To init or update the submodules in the <code>vendor/</code> directory:</p>

<p dir="auto"><strong>Netsurf libs</strong></p>
<p dir="auto">Netsurf libs are used for HTML parsing and DOM tree generation.</p>

<p dir="auto">For dev env, use <code>make install-netsurf-dev</code>.</p>
<p dir="auto"><strong>Mimalloc</strong></p>
<p dir="auto">Mimalloc is used as a C memory allocator.</p>

<p dir="auto">For dev env, use <code>make install-mimalloc-dev</code>.</p>
<p dir="auto">Note: when Mimalloc is built in dev mode, you can dump memory stats with the
env var <code>MIMALLOC_SHOW_STATS=1</code>. See
<a href="https://microsoft.github.io/mimalloc/environment.html" rel="nofollow">https://microsoft.github.io/mimalloc/environment.html</a>.</p>
<p dir="auto"><strong>zig-js-runtime</strong></p>
<p dir="auto">Our own Zig/Javascript runtime, which includes the v8 Javascript engine.</p>
<p dir="auto">This build task is very long and cpu consuming, as you will build v8 from sources.</p>
<div data-snippet-clipboard-copy-content="make install-zig-js-runtime"><pre><code>make install-zig-js-runtime
</code></pre></div>
<p dir="auto">For dev env, use <code>make iinstall-zig-js-runtime-dev</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Test</h2><a id="user-content-test" aria-label="Permalink: Test" href="#test"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Unit Tests</h3><a id="user-content-unit-tests" aria-label="Permalink: Unit Tests" href="#unit-tests"></a></p>
<p dir="auto">You can test Lightpanda by running <code>make test</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Web Platform Tests</h3><a id="user-content-web-platform-tests" aria-label="Permalink: Web Platform Tests" href="#web-platform-tests"></a></p>
<p dir="auto">Lightpanda is tested against the standardized <a href="https://web-platform-tests.org/" rel="nofollow">Web Platform
Tests</a>.</p>
<p dir="auto">The relevant tests cases are committed in a <a href="https://github.com/lightpanda-io/wpt">dedicated repository</a> which is fetched by the <code>make install-submodule</code> command.</p>
<p dir="auto">All the tests cases executed are located in the <code>tests/wpt</code> sub-directory.</p>
<p dir="auto">For reference, you can easily execute a WPT test case with your browser via
<a href="https://wpt.live/" rel="nofollow">wpt.live</a>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Run WPT test suite</h4><a id="user-content-run-wpt-test-suite" aria-label="Permalink: Run WPT test suite" href="#run-wpt-test-suite"></a></p>
<p dir="auto">To run all the tests:</p>

<p dir="auto">Or one specific test:</p>
<div data-snippet-clipboard-copy-content="make wpt Node-childNodes.html"><pre><code>make wpt Node-childNodes.html
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Add a new WPT test case</h4><a id="user-content-add-a-new-wpt-test-case" aria-label="Permalink: Add a new WPT test case" href="#add-a-new-wpt-test-case"></a></p>
<p dir="auto">We add new relevant tests cases files when we implemented changes in Lightpanda.</p>
<p dir="auto">To add a new test, copy the file you want from the <a href="https://github.com/web-platform-tests/wpt">WPT
repo</a> into the <code>tests/wpt</code> directory.</p>
<p dir="auto"><g-emoji alias="warning">⚠️</g-emoji> Please keep the original directory tree structure of <code>tests/wpt</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Lightpanda accepts pull requests through GitHub.</p>
<p dir="auto">You have to sign our <a href="https://github.com/lightpanda-io/browser/blob/main/CLA.md">CLA</a> during the pull request process otherwise
we're not able to accept your contributions.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why?</h2><a id="user-content-why" aria-label="Permalink: Why?" href="#why"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Javascript execution is mandatory for the modern web</h3><a id="user-content-javascript-execution-is-mandatory-for-the-modern-web" aria-label="Permalink: Javascript execution is mandatory for the modern web" href="#javascript-execution-is-mandatory-for-the-modern-web"></a></p>
<p dir="auto">In the good old days, scraping a webpage was as easy as making an HTTP request, cURL-like. It’s not possible anymore, because Javascript is everywhere, like it or not:</p>
<ul dir="auto">
<li>Ajax, Single Page App, infinite loading, “click to display”, instant search, etc.</li>
<li>JS web frameworks: React, Vue, Angular &amp; others</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Chrome is not the right tool</h3><a id="user-content-chrome-is-not-the-right-tool" aria-label="Permalink: Chrome is not the right tool" href="#chrome-is-not-the-right-tool"></a></p>
<p dir="auto">If we need Javascript, why not use a real web browser? Take a huge desktop application, hack it, and run it on the server. Hundreds or thousands of instances of Chrome if you use it at scale. Are you sure it’s such a good idea?</p>
<ul dir="auto">
<li>Heavy on RAM and CPU, expensive to run</li>
<li>Hard to package, deploy and maintain at scale</li>
<li>Bloated, lots of features are not useful in headless usage</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Lightpanda is built for performance</h3><a id="user-content-lightpanda-is-built-for-performance" aria-label="Permalink: Lightpanda is built for performance" href="#lightpanda-is-built-for-performance"></a></p>
<p dir="auto">If we want both Javascript and performance in a true headless browser, we need to start from scratch. Not another iteration of Chromium, really from a blank page. Crazy right? But that’s we did:</p>
<ul dir="auto">
<li>Not based on Chromium, Blink or WebKit</li>
<li>Low-level system programming language (Zig) with optimisations in mind</li>
<li>Opinionated: without graphical rendering</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Status</h2><a id="user-content-status" aria-label="Permalink: Status" href="#status"></a></p>
<p dir="auto">Lightpanda is still a work in progress and is currently at a Beta stage.</p>
<p dir="auto"><g-emoji alias="warning">⚠️</g-emoji> You should expect most websites to fail or crash.</p>
<p dir="auto">Here are the key features we have implemented:</p>
<ul>
<li> HTTP loader</li>
<li> HTML parser and DOM tree (based on Netsurf libs)</li>
<li> Javascript support (v8)</li>
<li> Basic DOM APIs</li>
<li> Ajax
<ul>
<li> XHR API</li>
<li> Fetch API</li>
</ul>
</li>
<li> DOM dump</li>
<li> Basic CDP/websockets server</li>
</ul>
<p dir="auto">NOTE: There are hundreds of Web APIs. Developing a browser (even just for headless mode) is a huge task. Coverage will increase over time.</p>
<p dir="auto">You can also follow the progress of our Javascript support in our dedicated <a href="https://github.com/lightpanda-io/zig-js-runtime#development">zig-js-runtime</a> project.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Why buy domains and 301 redirect them to me? (197 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=42812779</link>
            <guid>42812779</guid>
            <pubDate>Fri, 24 Jan 2025 13:20:56 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=42812779">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="42813335"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813335" href="https://news.ycombinator.com/vote?id=42813335&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>As others have mentioned this is likely one of a couple of scenarios, roughly ordered by my guess on likelihood:</p><p>- Attempting to use your legitimate content and services to improve the SEO rank of other domains (even unrelated ones). This can usually be checked by looking for a sitemap.xml, there will be pages not redirected to your site that contain pages of links.</p><p>- Closely following the above, the pages may not be links to other sites but might be hosting phishing pages for other services unrelated to yours. The redirect here acts as a bluff for casual inspection of the domain. You won't see page entries in a sitemap.xml file for these ones.</p><p>- Attempting to "age" a domain. Not many talk about this option, but new domains are a red flag to a lot of automated security processes. When purchasing a domain and giving it a history associated with a legitimate service they make the domain look less suspicious for future malicious use.</p><p>- Preparation for a targeted campaign. This is pretty unlikely, you need to be really worth a dedicated long term campaign effort specifically against you or your company. If you're doing controversial/novel research, are managing millions of dollars, performing a service a state actor would object to, or have high profile clientele then maybe you fall into this category. These are patient campaigns and want to make the domain "feel normal and official". They won't do anything public with the domain such as SEO tweaking or link spam, they'll use these domains only for specific targeted one-off low-noise attacks. They're relying on staff to see that the domain has been connected to your service for years and is likely just a domain someone in marketing purchased and forgot about. This is exceptionally rare.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42814229"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42814229" href="https://news.ycombinator.com/vote?id=42814229&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>Regarding point two, OP should connect to a VPN in Japan or somewhere he very isn't, use incognito mode, and see if the same content is served. I've seen hacked sites that are set up to serve normal content to where the attacker thinks the owner of the site lives, but serve phishing content or malware or whatever to everywhere else.</p><p>A 301 fits that bill because then the owners browser even when traveling will serve the good content</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42814698"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42814698" href="https://news.ycombinator.com/vote?id=42814698&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>Yeah this is a good call-out. If the site is being used for drive-by or targeted malware there are other checks that may be happening alongside the redirect such as user agent, country of origin (like you mentioned), plugins installed, OS, or even time of day.</p><p>If they detect something that matches what they want, they may throw some intermediate 301's to pages that attempt to infect the user with something still ultimately redirecting to the "normal" page.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42813477"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42813477" href="https://news.ycombinator.com/vote?id=42813477&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>I think the first one is pretty likely.</p><p>OP, you can search for "site:getexample.com" which will list you any pages that have been indexed for that domain. They <i>might</i> have just redirected the homepage. Worth a shot.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42813792"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42813792" href="https://news.ycombinator.com/vote?id=42813792&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>It could be a combo of 1 and 3: a competitor (or someone who thinks they might be in the future) ages those domains, then points it to their own product later.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42813194"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813194" href="https://news.ycombinator.com/vote?id=42813194&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>Their play is to send emails with those domains but in the emails claiming to be you and when people reading the email go to the domain, they see your page (they got redirected).</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42812868"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42812868" href="https://news.ycombinator.com/vote?id=42812868&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>They'll weaponize them at some point. How exactly is to be seen, but if people associate your product with domains you do not control (e.g. via SEO searches and hyperlinks left in public places), then everyone is on the hook the moment these domains stop redirecting to your service.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42813040"><td></td></tr>
            <tr id="42812913"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42812913" href="https://news.ycombinator.com/vote?id=42812913&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>It’s possible `/` redirects but other hidden routes phish. If someone gets e.g.: a fake password reset email, it might help the attacker bypass sanity checks users make.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42813132"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42813132" href="https://news.ycombinator.com/vote?id=42813132&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>Also helps create phishing report "false" flags.</p><p>If I target a specific region with a phishing link and redirect if the requestor is not in that region I can probably maintain my phishing domains for longer.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42814455"><td></td></tr>
            <tr id="42813296"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813296" href="https://news.ycombinator.com/vote?id=42813296&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>I think you can check the HTTP_REFERER header and block the redirect using your back-end code, like PHP or Node or Python, not sure what tech stack you are using.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42813457"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42813457" href="https://news.ycombinator.com/vote?id=42813457&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>The right play might be to have a custom landing page or header / popup on your site indicating that they were referred by a fraudulent domain, and to please bookmark your proper domain / report if this was via an email link. The traffic might be good, just coming in through a bad actor.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42814403"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42814403" href="https://news.ycombinator.com/vote?id=42814403&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>No, just redirect back to HTTP_REFERER. Why?</p><p>The user's browser will display a redirect loop error; and most importantly, they won't see your domain.</p><p>It keeps your name out of it and makes the email domain look even more fishy.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42814170"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42814170" href="https://news.ycombinator.com/vote?id=42814170&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>The referer is the site that sent the user to the redirect, not the redirect itself. You cannot detect 301s from the destination only.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42813355"><td></td></tr>
                  <tr id="42812870"><td></td></tr>
                <tr id="42814181"><td></td></tr>
            <tr id="42812964"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42812964" href="https://news.ycombinator.com/vote?id=42812964&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>Presumably just throwing a 403 if they have this referrer is ok and won't have a weird SEO impact or something?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42813213"><td></td></tr>
                <tr id="42813327"><td></td></tr>
                <tr id="42814198"><td></td></tr>
            <tr id="42813523"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42813523" href="https://news.ycombinator.com/vote?id=42813523&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>I just tested on firefox and it doesn't send the "Origin" header when using referrerpolicy="no-referrer". It's also not present when navigating using the url bar directly.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="42813029"><td></td></tr>
                        <tr id="42813099"><td></td></tr>
            <tr id="42813174"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813174" href="https://news.ycombinator.com/vote?id=42813174&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>I don't know if it still happens, but Google used to have an issue that I would see in Verbatim mode whereby non-Wikipedia domains would rank as particular Wikipedia pages by redirecting to Wikipedia. I can't seem to replicate it now, so it might be resolved or vary from country to country.</p><p>I posted about it at the time, but no one seemed to be able to replicate it:</p><p><a href="https://x.com/jfozonx/status/1570710776540958723" rel="nofollow">https://x.com/jfozonx/status/1570710776540958723</a></p><p>Always wondered how much traffic those domains were accumulating. Even though it was an edge case, it must've been quite a lot in aggregate.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42813187"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813187" href="https://news.ycombinator.com/vote?id=42813187&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>Yes, phishing. It might happen in the future, it could be happening right now, emails from getexample.com, a specific path on getexample.com that doesn't redirect to the real thing, etc.</p><p>File a DMCA with the registrar and the hosting provider.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42812920"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42812920" href="https://news.ycombinator.com/vote?id=42812920&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>Do you have an affiliate plan, or likely to have one?  Maybe they plan to redirect with their affiliate ID at some point?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42812957"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42812957" href="https://news.ycombinator.com/vote?id=42812957&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>Don't have an affiliate program, and I don't think we've got anything to suggest we will have one in the future (frankly our billing process is pretty bare bones and affiliate stuff isn't something we're looking at right now).</p><p>We're a small bot security/captcha company and pretty regularly get various attacks thrown at us - figuring out if somebody is up to something more along those lines was my main concern.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42813502"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813502" href="https://news.ycombinator.com/vote?id=42813502&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>I’ve seen one or two domains like that serving 301s to some IPs and their own website to others. This could be a 1000:1 ratio. Then they serve an absolutely ad-infested parking page-style website to those others. And that’s how they skim a little bit of revenue off your customers.</p><p>They may also represent you to real life businesses for invoice scams or credit.</p><p>Rare but possible scenarios worth considering.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42813757"><td></td></tr>
            <tr id="42813310"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813310" href="https://news.ycombinator.com/vote?id=42813310&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>This feels like a never-ending cat and mouse activity, but depending upon your hosting infrastructure, you ought to be able to maintain a list of these domains and 403/404 incoming requests that are being referred from the list. Better to just dump them to an error / scam warning page than 301 them out to somewhere else (to avoid redirect loops)</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42813421"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813421" href="https://news.ycombinator.com/vote?id=42813421&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>Could be for phishing. Is the SAAS in a domain that involves money (payments/crypto etc) ? Then even more likely so. I would drop those redirects at my webserver level. Easy to d0.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42813384"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813384" href="https://news.ycombinator.com/vote?id=42813384&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>Another alternative is that they will hijack those links once they gain traction in search results. Almost as a hedge against your future success.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42813051"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813051" href="https://news.ycombinator.com/vote?id=42813051&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>it can bypass some whitelisting if you for example have redirects checking if address is example.com but validation is poorly written ("startswith", "contains") , on login page or anywhere else.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42812995"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42812995" href="https://news.ycombinator.com/vote?id=42812995&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>Can you provide more information about what's in the headers? Additionally, are there any tracking parameters appended to the URL?</p><p>I'm guessing it will look normal but it could provide some insights if something weird is there.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42813188"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42813188" href="https://news.ycombinator.com/vote?id=42813188&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>Just had a look - looks like pretty regular/reasonable cloudflare default stuff as far as I can tell. The headers relating to error reporting are the only thing that stand out a little, though it doesn't look unreasonable.</p><p>---</p><p>Headers</p><p>---</p><p>HTTP/2 301</p><p>date: Fri, 24 Jan 2025 13:59:51 GMT</p><p>content-type: text/html</p><p>content-length: 167</p><p>location: &lt;the website in question&gt;</p><p>cache-control: max-age=3600</p><p>expires: Fri, 24 Jan 2025 14:59:51 GMT</p><p>report-to: {"endpoints":[{"url":"https:\/\/a.nel.cloudflare.com\/report\/v4?s=JZu4FOa%2ByynaFOXWYlxaePF9KdRQ0qGUJkfm1F1aK2m3VEx6idlvWlb5go%2B08hgSog1zm1zuMobXcVK2BkR4mQD0SEGU%2Bzp2oC6mXPgQs%2FUzvOH7LbqAG96jtf9KNqemV8Q%3D"}],"group":"cf-nel","max_age":604800}</p><p>nel: {"success_fraction":0,"report_to":"cf-nel","max_age":604800}</p><p>server: cloudflare</p><p>cf-ray: 90708be24810e8fe-LHR</p><p>alt-svc: h3=":443"; ma=86400</p><p>server-timing: cfL4;desc="?proto=TCP&amp;rtt=59748&amp;min_rtt=41108&amp;rtt_var=43898&amp;sent=7&amp;recv=8&amp;lost=0&amp;retrans=1&amp;sent_bytes=3535&amp;recv_bytes=789&amp;delivery_rate=33797&amp;cwnd=225&amp;unsent_bytes=0&amp;cid=e5052200af7e27a5&amp;ts=145&amp;x=0"</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42813881"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42813881" href="https://news.ycombinator.com/vote?id=42813881&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>If you are seeing 301s logged on your end that is your site redirecting to another one.</p><p>There isn’t a way to see what a referring site did to do the redirect (301 or 302 or even a js redirect) in your logs. All you’ll see is (potentially) the Referer http header.</p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="42812876"><td></td></tr>
                <tr id="42813169"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42813169" href="https://news.ycombinator.com/vote?id=42813169&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>This sounds very plausible. Then if they click on their link or manually type in the website corresponding to the e-mail address, it goes to your (very official) site.</p><p>Of all the answers presented so far, this one feels the most plausible to me.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42813361"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813361" href="https://news.ycombinator.com/vote?id=42813361&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>Phishing. Regular visits to these domains will 301 redirect them to you, but there's at least one URL that will instead be handled by the scammers themselves.</p><p>They'll then send out an email campaign with a From: address in the counterfeit domain (which will have valid SPF/DKIM/whatever), a subject like "Example.com: You've been invited to join a project!", quickly-come-see-this-secret-stuff body copy, and a call-to-action button linked to that URL.</p><p>The page hosted on the URL will have your branding and everything, and collect a bunch of personal information and/or access credentials for the scammers.</p><p>Taking down this stuff is tedious, but you can try -- least you can do for now is display a prominent 'this is not an authorized example.com domain' warning for inbound visits from these redirects, create a public Knowledge Base-like article warning about this abuse as well (making very clear this has nothing to do with you), and block the domains involved on your inbound mail server.</p><p>Silver lining: apparently your SaaS is successful enough to be used as a lure for scammers. Congrats?</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42813315"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813315" href="https://news.ycombinator.com/vote?id=42813315&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>I did this for a fraudulent health product. They had .org but not .com. Registered .com and redirected it. Waited for SEO to pick up on it. Created the page calling it out as fraud. Created some social media accounts and put the .com in the about info. Started commenting on their posts, anyone that looked at the fake profiles would find my page with info on why it was fraudulent.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42813871"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42813871" href="https://news.ycombinator.com/vote?id=42813871&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>Whatever their plan - if you have a trademark or similar IP protection on "Example", that might be prove extremely useful here.  (If not - consider getting some protection ASAP.)</p><p>It's been a while, and IANAL - but I've seen both domain resellers and registrars cave pretty quickly when contacted with "that name very obviously infringes on our trademark".</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42812855"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42812855" href="https://news.ycombinator.com/vote?id=42812855&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>People do this for SEO purposes. They think that this increases the amount of backlinks to their site, thus increasing their rank in Google and other search engines.</p><p>This is less true than it used to be, but people still do it.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42812890"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42812890" href="https://news.ycombinator.com/vote?id=42812890&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>Sure, but it's not their site, it's mine!</p><p>And they're not obvious mouse slips like redirecting googl.com -&gt; google.com - they're more of the form &lt;verb&gt;mydomain.com.</p><p>I was mostly interested in what the actual play from them here is tbh</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42812985"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42812985" href="https://news.ycombinator.com/vote?id=42812985&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>Maybe they’ll try to build up traffic to your site from those domains and then push to sell them to you/extort by removing the redirects?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42813055"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42813055" href="https://news.ycombinator.com/vote?id=42813055&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div>
                  <p>Just feels like such an odd play lol. If they could organically generate leads/traffic that I'd be willing to get extorted over, then surely they would also have the means to start a marketing agency that I'd be willing to pay far more for?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="42812888"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42812888" href="https://news.ycombinator.com/vote?id=42812888&amp;how=up&amp;goto=item%3Fid%3D42812779"></a></center>    </td><td><br><div><p>Backlinks to <i>which</i> site?</p><p>The fraudulent domains are only sending traffic to OP.</p><p>My guess is that they want to either phish visitors, or they want to ask OP for affiliate  revenue, like a digital version of the guys who wash your windshield or your shoes without asking first, and then ask for money.</p><p>Or planning to threaten to divert organic traffic through the impersonation domains away from the canonical domain, if you don't pay them.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42813454"><td></td></tr>
                        </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Build It Yourself (233 pts)]]></title>
            <link>https://lucumr.pocoo.org/2025/1/24/build-it-yourself/</link>
            <guid>42812641</guid>
            <pubDate>Fri, 24 Jan 2025 12:55:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lucumr.pocoo.org/2025/1/24/build-it-yourself/">https://lucumr.pocoo.org/2025/1/24/build-it-yourself/</a>, See on <a href="https://news.ycombinator.com/item?id=42812641">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
  

  
  <p>written on Friday, January 24, 2025</p>
  

  <p>Another day, another <a href="https://lucumr.pocoo.org/2016/3/24/open-source-trust-scaling/">rant</a>
<a href="https://lucumr.pocoo.org/2022/1/10/dependency-risk-and-funding/">about</a> <a href="https://lucumr.pocoo.org/2024/3/26/rust-cdo/">dependencies</a>. from me.  This time I will ask you that we
start and support a vibe shift when it comes to dependencies.</p>
<p>You're probably familiar with the concept of “dependency churn.”  It's that
never-ending treadmill of updates, patches, audits, and transitive
dependencies that we as developers love to casually install in the name of
productivity.  Who doesn't enjoy waiting for yet another <cite>cargo upgrade</cite>
just so you can get that fix for a bug you don't even have?</p>
<p>It's a plague in most ecosystems with good packaging solutions.
JavaScript and Rust are particularly badly affected by that.  A brand new
Tokio project drags in 28 crates, a new Rocket project balloons that to
172, and a little template engine like MiniJinja can exist with just a
single dependency — while its CLI variant slurps up 142.</p>
<p>If that doesn't sound like a big deal, let's consider <a href="https://crates.io/crates/terminal_size">terminal_size</a>.  It is a crate that does
exactly what its name suggests: it figures out your terminal dimensions.
The underlying APIs it uses have effectively been stable since the earliest days of computing
terminals—what, 50 years or so? And yet, for one function, terminal-size
manages to introduce three or four additional crates, depending on your
operating system.  That triggers a whole chain reaction, so you end up
compiling thousands of other functions just to figure out if your terminal
is 80x25 or 120x40.  That crate had 26 releases.  My own version of that
that I have stuck away in a project from 10 years ago still works without
a single update.  Because shocker: nothing about figuring out terminal
sizes has changed.  <a href="#footnote-1" id="footnote-reference-1">[1]</a></p>
<p>So why does <cite>terminal-size</cite> have so many updates if it's so stable?
Because it's build on top of platform abstraction libraries that
constantly churn, so it needs to update to avoid code duplication and
blowing up compile times even more.</p>
<p>But “big supply chain” will tell you that you must do it this way.  Don't
you dare to copy paste that function into your library.  Or don't you date
to use “unsafe” yourself.  You're not qualified enough to write unsafe
code, let the platform abstraction architects do that.  Otherwise someone
<a href="https://github.com/geiger-rs/cargo-geiger">will slap you</a>.  There are
entire companies who are making a living of supplying you with the tools
needed to deal with your dependency mess.  In the name of security, we're
pushed to having dependencies and keeping them up to date, despite most of
those dependencies being the primary source of security problems.</p>
<p>The goal of code in many ways should be to be written in a way that it
does not need updates.  It should eventually achieve some level of
stability.  In the Rust ecosystem stable code is punished.  If you have a
perfectly working dependency but you have a somewhat inactive bug tracker,
RUSTSEC will come by and <a href="https://lucumr.pocoo.org/2024/3/26/rust-cdo/">give you a chunk rating</a>.</p>
<p>But there <em>is</em> a simpler path.  You write code yourself.  Sure, it's more
work up front, but once it's written, it's done. No new crates, no waiting
for upsteam authors to fix that edge case.  If it's broken for you, you
fix it yourself.  Code that works doesn't necessarily need the
maintenance treadmill.  Your code has a corner case?  Who cares.  This is
that vibe shift we need in the Rust world: celebrating fewer dependencies
rather than more.</p>
<p>We're at a point in the most ecosystems where pulling in libraries is not
just the default action, it's seen positively: “Look how modular and
composable my code is!”  Actually, it might just be a symptom of never
wanting to type out more than a few lines.</p>
<p>Now one will make the argument that it takes so much time to write all of
this.  It's 2025 and it's faster for me to have ChatGPT or Cursor whip up
a dependency free implementation of these common functions, than it is for
me to start figuring out a dependency.  And it makes sense as for many
such small functions the maintenance overhead is tiny and much lower than
actually dealing with constant upgrading of dependencies.  The code is just
a few lines and you also get the benefit of no longer need to compile
thousands of lines of other people's code for a single function.</p>
<p>But let's face it: corporate code review culture which also has infected
Open Source software.  Companies are more likely to reward engineers than
scold them for pulling in that new “shiny library” that solves the problem
they never actually had.  That creates problems, so dependabot and friends
was born.  Today I just dread getting dependabot pull requests but on
projects but I have to accept it.  I'm part of an ecosystem with my stuff
and that ecosystem is all about churn, churn, churn.  In companies you can
also keep entire internal engineering teams busy with vendoring
dependencies, internal audits and upgrading things throughout the company.</p>
<p>Fighting this fight is incredibly hard!  Every new hire has been trained
on the idea that dependencies are great, that code reuse is great.  That
having old code sitting around is a sign of bad engineering culture.</p>
<p>It's also hard to fight this in Open Source.  Years ago I wrote <a href="https://crates.io/crates/sha1_smol">sha1-smol</a> which originally was just called
<cite>sha1</cite>.  It became the standard crate to calculate SHA1 hashes.
Eventually I was pressured to donate that package name to rust-crypto and
to depend on the rest of the crypto ecosystem as it was so established.
If you want to use the new sha1 crate, you get to enjoy 10 dependencies.
But there was just no way around it, because that name in the registry is
precious and people also wanted to have trait compatibility.  It feels
tiring to be the only person in a conversation pushing to keep the churn
down and dependencies low.</p>
<p>It's time to have a new perspective: we should give kudos to engineers who
write a small function themselves instead of hooking in a transitive web
of crates.  We should be suspicious of big crate graphs.  Celebrated are
the minimal dependencies, the humble function that just quietly does the
job, the code that doesn't need to be touched for years because it was
done right once.</p>
<p>And sure, it's not black and white.  There are the important libraries
that solve hard problems.  Graphics libraries that abstract over complex
drivers, implementations of protocols like HTTP and QUIC.  I won't be able
to get rid of tokio and I have no desire to.  But when you end up using
one function, but you compile hundreds, some alarm bell should go off.</p>
<p>We need that vibe shift.  To celebrate building it yourself when it's
appropriate to do so.  To give credit to library authors who build low to
no-dependency Open Source libraries.</p>
<p>For instance minijinja celebrates it in the readme:</p>
<pre>$ cargo tree
minimal v0.1.0 (examples/minimal)
└── minijinja v2.6.0 (minijinja)
    └── serde v1.0.144
</pre>
<p>And it has a PR to eventually <a href="https://github.com/mitsuhiko/minijinja/pull/539">get rid of the last dependency</a>.  And sometime this
year I will make it my goal to go ahead proudly and trim down all that fat
in my projects.</p>
<table id="footnote-1">
<colgroup><col><col></colgroup>
<tbody>
<tr><td><a href="#footnote-reference-1">[1]</a></td><td>Disclaimer: you will need one dependency for UNIX: <cite>libc</cite>.  That's
because Rust does not expose the platform's libc constants to you, and
they are not standarized.  That however is such a common and
lightweight dependency that you won't be able to avoid it anyways.</td></tr>
</tbody>
</table>


  
  <p>This entry was tagged
    
      <a href="https://lucumr.pocoo.org/tags/rust/">rust</a> and 
      <a href="https://lucumr.pocoo.org/tags/thoughts/">thoughts</a>
  

      </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We Need to Talk About Docker Hub (122 pts)]]></title>
            <link>https://www.linuxserver.io/blog/we-need-to-talk-about-docker-hub</link>
            <guid>42812203</guid>
            <pubDate>Fri, 24 Jan 2025 11:40:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.linuxserver.io/blog/we-need-to-talk-about-docker-hub">https://www.linuxserver.io/blog/we-need-to-talk-about-docker-hub</a>, See on <a href="https://news.ycombinator.com/item?id=42812203">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
        <p><a href="https://hub.docker.com/">Docker Hub</a> is the de facto standard Docker registry, literally, if you don't specify a registry when pulling an image Docker will invisibly prepend <code>docker.io/</code> to it. That bit is fair enough really, it's their software and their registry platform so why not prefer it? From the beginning of the Linuxserver project we used Docker Hub as our primary registry; as we grew we started mirroring our images to Gitlab and Quay.io, more as a backup than anything else, there was no reason for us to have concerns about the stability or functionality of Docker Hub, until...</p>
<p>In 2020 Docker announced that they would start <a href="https://web.archive.org/web/20201101055027/https://www.docker.com/blog/scaling-dockers-business-to-serve-millions-more-developers-storage">purging old images</a> and introducing <a href="https://web.archive.org/web/20201101055027/https://www.docker.com/blog/scaling-docker-to-serve-millions-more-developers-network-egress/">pull limits</a> for unpaid accounts and unauthenticated users - for some reason they've scrubbed these posts from their blog, hence the <a href="https://archive.org/">Internet Archive</a> links.</p>
<p>This concerned us, and many other users, deeply, not just because of the changes - our CI account is on a paid plan so wouldn't have been directly affected - but because of the direction of travel it indicated and the potential impact to our users. Around the same time, Github launched its own container registry, GHCR, which was an evolution of their existing packages registry. This prompted us to consider changing our primary registry and later that year we started updating our documentation to use ghcr.io as the registry for all our examples. In 2021 we partnered with <a href="https://app.scarf.sh/">Scarf</a> to set up <a href="https://www.linuxserver.io/blog/wrap-up-warm-for-the-winter">lscr.io</a> as a frontend registry for all our images, but retained ghcr.io as the backend provider. In 2023, Docker Hub announced that they were <a href="https://www.linuxserver.io/blog/docker-team-changes">sunsetting Free Team Organisations</a>, meaning your options were going to be free individual user accounts, or paid team accounts. While we would have been protected from the changes, Docker ultimately decided not to go forward with them, after user backlash.</p>
<p>In the meantime, we applied for and were granted membership of the <a href="https://www.docker.com/community/open-source/">Docker-Sponsored Open Source (DSOS) program</a>. The application process was messy and slow, but it meant we were no longer subject to the pull limits and image purging of a free account.</p>
<p>Fast-forward to October 2024: we were preparing for our annual DSOS renewal. This process is <em>abysmal</em>, there's no way to apply to roll over membership, or even a renewal process per se, you have to reapply from scratch every year using the same badly-designed form that they hilariously describe as a "new, streamlined application process [that] lets you apply with a single click and provides status updates along the way". The confirmation email notifies you that the application process can take up to a month, so we waited as usual. A month came and went without any update beyond the initial automated reply. In mid-November our DSOS status expired, reverting our account to Free Teams status and removing all the benefits of DSOS membership.</p>
<p>We reached out to Docker via the contact email they provide (opensource@docker.com), although it's worth noting that they do not publish it anywhere related to the DSOS program application process, and did not receive any response, not even a "This mailbox is no longer monitored". Twice more we attempted to reach out to them about the status of our application, but still have yet to receive a response.</p>
<p>We're now 3 months on from our renewal submission, with zero communication from Docker, an account that is no longer part of the DSOS program, and no obvious way to speak to a human about it. We could resubmit the form, but why would that go any differently to last time? There's clearly no point in using the email address as it is seemingly ignored. We do have some contacts who work at Docker but they're engineers, not responsible for Docker Hub's account management, and we don't want to make this their problem. We're going to try logging a regular support ticket but as we're now on a free account we're not hopeful of getting a helpful response.</p>
<p>It's hard to know if we've just fallen through the cracks somehow or if there are more systemic issues going on within the Docker organisation at the moment, but this feels like the kind of process that should have some degree of resilience to it if you're going to offer it to people, and frankly the lack of a straightforward renewal option has always been kind of unacceptable.</p>
<p>All of this has made us seriously reconsider what we do going forwards; we obviously won't pull all our images off Docker Hub, nor is it sensible to just stop pushing new images as it will seriously impact the many users we have who pull from there and don't read these blog posts or generally keep track of what we're up to as an organisation, but it <em>does</em> feel like we need to do something. Whatever we decide, we'll keep you informed.</p>
<p>Side note: If you're reading this and you work for Docker in some relevant capacity, give us a hint as to what we're supposed to do here, we'd really appreciate it.</p>
      </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[UI is hell: four-function calculators (209 pts)]]></title>
            <link>https://lcamtuf.substack.com/p/ui-is-hell-four-function-calculators</link>
            <guid>42810300</guid>
            <pubDate>Fri, 24 Jan 2025 03:46:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lcamtuf.substack.com/p/ui-is-hell-four-function-calculators">https://lcamtuf.substack.com/p/ui-is-hell-four-function-calculators</a>, See on <a href="https://news.ycombinator.com/item?id=42810300">Hacker News</a></p>
Couldn't get https://lcamtuf.substack.com/p/ui-is-hell-four-function-calculators: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[A phishing attack involving g.co, Google's URL shortener (176 pts)]]></title>
            <link>https://gist.github.com/zachlatta/f86317493654b550c689dc6509973aa4</link>
            <guid>42810252</guid>
            <pubDate>Fri, 24 Jan 2025 03:38:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gist.github.com/zachlatta/f86317493654b550c689dc6509973aa4">https://gist.github.com/zachlatta/f86317493654b550c689dc6509973aa4</a>, See on <a href="https://news.ycombinator.com/item?id=42810252">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="file-almost_pwned-md" tabindex="0" role="region" aria-label="file-almost_pwned-md">
    <article itemprop="text"><p dir="auto">g.co, Google's <a href="https://en.wikipedia.org/wiki/G.co" rel="nofollow">official</a> URL shortcut (update: or Google Workspace's domain verification, see bottom), is compromised. People are actively having their Google accounts stolen.</p>
<p dir="auto">Someone just tried the most sophisticated phishing attack I've ever seen. I almost fell for it. My mind is a little blown.</p>
<ol dir="auto">
<li>
<p dir="auto">Someone named "Chloe" called me from 650-203-0000 with Caller ID saying "Google". She sounded like a real engineer, the connection was super clear, and she had an American accent. <a href="https://gist.github.com/user-attachments/assets/81188c87-f090-4bc0-a8c1-9f2b1a4e309a">Screenshot.</a></p>
</li>
<li>
<p dir="auto">They said that they were from Google Workspace and someone had recently gained access to my account, which they had blocked. They asked me if I had recently logged in from Frankfurt, Germany and I said no.</p>
</li>
<li>
<p dir="auto">I asked if they can confirm this is Google calling by emailing me from a Google email and they said sure and sent me this email and told me to look for a case number in it, which I saw in the email string. I asked why it said important.g.co and she said it was an internal Google subnet.</p>
</li>
</ol>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/992248/406290455-a5229d63-4481-4151-bc4f-952d1bf59a51.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc3NTQ1MDMsIm5iZiI6MTczNzc1NDIwMywicGF0aCI6Ii85OTIyNDgvNDA2MjkwNDU1LWE1MjI5ZDYzLTQ0ODEtNDE1MS1iYzRmLTk1MmQxYmY1OWE1MS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDEyNFQyMTMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1lMmNmNTQyNGUwOGI3MmMwYzFlNWIxOTc5ZmI2ZWM5ZGI2Mzg5OWUwNWU3YzI0YWE0NWU1ZWMyZWNmYWViYmE4JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.UsjZi5dXdaTQ6W6yE1rhyJKgGo46oI4Qz5syFiJURUU"><img width="929" alt="Screenshot 2025-01-23 at 10 17 41 PM" src="https://private-user-images.githubusercontent.com/992248/406290455-a5229d63-4481-4151-bc4f-952d1bf59a51.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc3NTQ1MDMsIm5iZiI6MTczNzc1NDIwMywicGF0aCI6Ii85OTIyNDgvNDA2MjkwNDU1LWE1MjI5ZDYzLTQ0ODEtNDE1MS1iYzRmLTk1MmQxYmY1OWE1MS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDEyNFQyMTMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1lMmNmNTQyNGUwOGI3MmMwYzFlNWIxOTc5ZmI2ZWM5ZGI2Mzg5OWUwNWU3YzI0YWE0NWU1ZWMyZWNmYWViYmE4JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.UsjZi5dXdaTQ6W6yE1rhyJKgGo46oI4Qz5syFiJURUU"></a>
<p dir="auto">OK, so that can't be from a google.com email, right? It must be a spoofed email using g.co, which doesn't have DKIM / SPF turned on - right? Nope.</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/992248/406291462-91b0c27c-e662-48bf-94f1-22c909c7459c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc3NTQ1MDMsIm5iZiI6MTczNzc1NDIwMywicGF0aCI6Ii85OTIyNDgvNDA2MjkxNDYyLTkxYjBjMjdjLWU2NjItNDhiZi05NGYxLTIyYzkwOWM3NDU5Yy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDEyNFQyMTMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT00ZTE5YmM2M2RmZjIxM2NlZWI0NzQzNmUzMTJlY2RjMDZiY2VhYTVlODUxYTNiNTg2ZjY5NjIxNDhiNTQ1OTExJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.-uLsgIm24GTB8axife4AhyUk5oVZ5rkz9o1fIMLDQdo"><img width="798" alt="Screenshot 2025-01-23 at 10 22 51 PM" src="https://private-user-images.githubusercontent.com/992248/406291462-91b0c27c-e662-48bf-94f1-22c909c7459c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc3NTQ1MDMsIm5iZiI6MTczNzc1NDIwMywicGF0aCI6Ii85OTIyNDgvNDA2MjkxNDYyLTkxYjBjMjdjLWU2NjItNDhiZi05NGYxLTIyYzkwOWM3NDU5Yy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDEyNFQyMTMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT00ZTE5YmM2M2RmZjIxM2NlZWI0NzQzNmUzMTJlY2RjMDZiY2VhYTVlODUxYTNiNTg2ZjY5NjIxNDhiNTQ1OTExJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.-uLsgIm24GTB8axife4AhyUk5oVZ5rkz9o1fIMLDQdo"></a>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/992248/406291532-a40e671d-9585-480c-b664-0f9c6f82c6a2.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc3NTQ1MDMsIm5iZiI6MTczNzc1NDIwMywicGF0aCI6Ii85OTIyNDgvNDA2MjkxNTMyLWE0MGU2NzFkLTk1ODUtNDgwYy1iNjY0LTBmOWM2ZjgyYzZhMi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDEyNFQyMTMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0yYjcxMWFhZmNiYjY4MzA4MTUzZmY5NmZkZjdlNWE2ZjIxN2M1MDU0N2NhYmFmY2I1NjUxMTdiMjU2MTA2MzUxJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.M4TrKnmNb92nQe94L7pUwYyukwk74TCeaOIv97gdx30"><img width="1410" alt="Screenshot 2025-01-23 at 10 24 30 PM" src="https://private-user-images.githubusercontent.com/992248/406291532-a40e671d-9585-480c-b664-0f9c6f82c6a2.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc3NTQ1MDMsIm5iZiI6MTczNzc1NDIwMywicGF0aCI6Ii85OTIyNDgvNDA2MjkxNTMyLWE0MGU2NzFkLTk1ODUtNDgwYy1iNjY0LTBmOWM2ZjgyYzZhMi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDEyNFQyMTMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0yYjcxMWFhZmNiYjY4MzA4MTUzZmY5NmZkZjdlNWE2ZjIxN2M1MDU0N2NhYmFmY2I1NjUxMTdiMjU2MTA2MzUxJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.M4TrKnmNb92nQe94L7pUwYyukwk74TCeaOIv97gdx30"></a>
<p dir="auto">You can download the original email <a href="https://cloud-4iqge4j0c-hack-club-bot.vercel.app/0your_google_account_password_for_important.g.co_has_changed.eml" rel="nofollow">here</a>.</p>
<p dir="auto">But wait - important.g.co must be an unofficial URL. This must be similar to the <a href="https://x.com/zachlatta/status/859843151757955072" rel="nofollow">Google Docs phishing attack</a>, right?</p>
<p dir="auto">No - g.co is an official Google URL, and Google even says so! (there's also a <a href="https://en.wikipedia.org/wiki/G.co" rel="nofollow">Wikipedia</a>)</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/992248/406296479-32b40472-07a3-4bcc-b004-25e26fc25ce5.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc3NTQ1MDMsIm5iZiI6MTczNzc1NDIwMywicGF0aCI6Ii85OTIyNDgvNDA2Mjk2NDc5LTMyYjQwNDcyLTA3YTMtNGJjYy1iMDA0LTI1ZTI2ZmMyNWNlNS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDEyNFQyMTMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0zYmY0M2I3N2ZhNTU5MjZjMTYzZWY5N2UxM2Q1NmYxYzJiN2ZmZTM5YTY4MmZiMmFhZDRkY2Y0OGZiMjBiYzQyJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.lLaUAf4ve2XVHW1gKI-Xo0pIFgFo9RklCwdQe8gyjLo"><img width="789" alt="Screenshot 2025-01-23 at 10 47 32 PM" src="https://private-user-images.githubusercontent.com/992248/406296479-32b40472-07a3-4bcc-b004-25e26fc25ce5.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc3NTQ1MDMsIm5iZiI6MTczNzc1NDIwMywicGF0aCI6Ii85OTIyNDgvNDA2Mjk2NDc5LTMyYjQwNDcyLTA3YTMtNGJjYy1iMDA0LTI1ZTI2ZmMyNWNlNS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDEyNFQyMTMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0zYmY0M2I3N2ZhNTU5MjZjMTYzZWY5N2UxM2Q1NmYxYzJiN2ZmZTM5YTY4MmZiMmFhZDRkY2Y0OGZiMjBiYzQyJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.lLaUAf4ve2XVHW1gKI-Xo0pIFgFo9RklCwdQe8gyjLo"></a>
<ol start="3" dir="auto">
<li>
<p dir="auto">I asked if I could call back a phone number listed on Google.com and she said sure - this number is listed on google.com and you can call back with your case number, but there may be a wait on hold and I might get a different agent. I googled it and sure enough, it was listed on google.com pages. I didn't call back though.</p>
</li>
<li>
<p dir="auto">I said OK: what do you want me to do? She said we could do the sessions reset entirely from my devices and she wouldn't need any info from me. So I said sure, let me know how to. Then I realize I should check the Google Workspace logs and didn't see any login attempts from weird IPs. I asked her where I could find the attempt they were talking about and she gave me detailed instructions and said it's strange it's not showing up, and maybe it'll show after the caches reload. She offered to transfer me to a manager. I declined.</p>
</li>
<li>
<p dir="auto">We talked further for maybe 5 minutes as I was looking through my Google Workspace logs trying to find anything, then the call dropped mid-sentence while she was talking. Then I got a call back 30 seconds later from "Solomon", her manager, saying he heard I was having trouble navigating the Google Workspace admin logs and could show me.</p>
</li>
<li>
<p dir="auto">We went back and forth, he explained the account was probably compromised through an adblocker Chrome Extension that hijacked the Gmail credentials.</p>
</li>
<li>
<p dir="auto">As we talked, he said a few things that made me more suspicious. I then asked him to show me where on Google.com I could find this phone number and he had me type out <a href="https://support.google.com/business/answer/7690269?hl=en" rel="nofollow">https://support.google.com/business/answer/7690269?hl=en</a>, which sure enough has it - though it's listed under "Google Assistant". Suspicious. I asked if I could call the number back, and he said no - which different from what "Chloe" said. Suspicious.</p>
</li>
<li>
<p dir="auto">I then said "sure, let's reset the account" to see what he wanted me to do. Then he said OK - open up Gmail on your phone and let me show you how to log out all other active devices before you reset your password so the Frankfurt computer will get logged out.</p>
</li>
<li>
<p dir="auto">He then said: OK, I just sent a reset code to you. It should pop up on your screen and say "84", which sure enough 84 was one of the 3 codes displayed. He said just tap it, then all sessions besides your phone will be signed out. That would have given him access to my account!</p>
</li>
<li>
<p dir="auto">Then I started recording the call when I was certain this was a phishing attempt. <a href="https://cloud-3s03ljpcy-hack-club-bot.vercel.app/0call_recording.m4a" rel="nofollow">Here</a> is the call recording for the last 7 minutes. Note: my iOS device played a recording notification to him when this started recording.</p>
</li>
<li>
<p dir="auto">He had me load up "his" LinkedIn account to verify who he was and that he worked at Google. Then he eventually sent me a super scammy 2 factor text code and hung up on me after I asked more questions about how they did this.</p>
</li>
</ol>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/992248/406292870-697ad711-9d9c-47a9-9574-6a6736cf3827.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc3NTQ1MDMsIm5iZiI6MTczNzc1NDIwMywicGF0aCI6Ii85OTIyNDgvNDA2MjkyODcwLTY5N2FkNzExLTlkOWMtNDdhOS05NTc0LTZhNjczNmNmMzgyNy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDEyNFQyMTMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0xZTg5MTkzYjViZTgzZTdkMjU4YjA1MzdmYWE3NDIwNDIwZjdhY2Q3NTdmZmIwMWY5NzUzNjIzMzRhOWFkMTEzJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.Nh1IpPhs35muaPOqPlRUAHGCq1pfP4I6qp4MILSkW6Q"><img width="427" alt="Screenshot 2025-01-23 at 10 31 53 PM" src="https://private-user-images.githubusercontent.com/992248/406292870-697ad711-9d9c-47a9-9574-6a6736cf3827.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc3NTQ1MDMsIm5iZiI6MTczNzc1NDIwMywicGF0aCI6Ii85OTIyNDgvNDA2MjkyODcwLTY5N2FkNzExLTlkOWMtNDdhOS05NTc0LTZhNjczNmNmMzgyNy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDEyNFQyMTMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0xZTg5MTkzYjViZTgzZTdkMjU4YjA1MzdmYWE3NDIwNDIwZjdhY2Q3NTdmZmIwMWY5NzUzNjIzMzRhOWFkMTEzJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.Nh1IpPhs35muaPOqPlRUAHGCq1pfP4I6qp4MILSkW6Q"></a>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/992248/406293090-5effae75-e0bd-4a4a-81f4-a8977c611f83.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc3NTQ1MDMsIm5iZiI6MTczNzc1NDIwMywicGF0aCI6Ii85OTIyNDgvNDA2MjkzMDkwLTVlZmZhZTc1LWUwYmQtNGE0YS04MWY0LWE4OTc3YzYxMWY4My5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDEyNFQyMTMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT01NjZhMGVlNDY2NjVlYmRkYzg5ODQyMDY0OWYyMzI4ZTU4ODc4NGE1ZjkwZTRlMzc2YjcwMWM4NDU0NDBjY2VkJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.m0ll-5-ngIY2vLPKvYcxGLi5O6vgq_Yl8mTUIwjW6l4"><img width="600" alt="Screenshot 2025-01-23 at 10 33 01 PM" src="https://private-user-images.githubusercontent.com/992248/406293090-5effae75-e0bd-4a4a-81f4-a8977c611f83.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc3NTQ1MDMsIm5iZiI6MTczNzc1NDIwMywicGF0aCI6Ii85OTIyNDgvNDA2MjkzMDkwLTVlZmZhZTc1LWUwYmQtNGE0YS04MWY0LWE4OTc3YzYxMWY4My5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDEyNFQyMTMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT01NjZhMGVlNDY2NjVlYmRkYzg5ODQyMDY0OWYyMzI4ZTU4ODc4NGE1ZjkwZTRlMzc2YjcwMWM4NDU0NDBjY2VkJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.m0ll-5-ngIY2vLPKvYcxGLi5O6vgq_Yl8mTUIwjW6l4"></a>
<p dir="auto">The thing that's crazy is that if I followed the 2 "best practices" of verifying the phone number + getting them to send an email to you from a legit domain, I would have been compromised.</p>
<p dir="auto">I understand how they were able to spoof the "Google" phone call through Google Assistant, but I have no idea how they got access to important.g.co. g.co is a <a href="https://en.wikipedia.org/wiki/G.co" rel="nofollow">legitimate</a> Google URL.</p>
<p dir="auto">Literally 1 button press from being completely pwned. And I'm pretty technical!</p>
<p dir="auto">– Zach</p>
<hr>
<p dir="auto"><a href="https://hackclub.com/" rel="nofollow">Hack Clubbers</a> have determined that this is almost definitely a bug in Google Workspace where you can create a new Workspace with any <code>g.co</code> subdomain and get it to send some emails without verifying that you own the domain.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/992248/406298490-db1857e2-cfcd-4c7a-a8c8-8e9089b1f504.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc3NTQ1MDMsIm5iZiI6MTczNzc1NDIwMywicGF0aCI6Ii85OTIyNDgvNDA2Mjk4NDkwLWRiMTg1N2UyLWNmY2QtNGM3YS1hOGM4LThlOTA4OWIxZjUwNC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDEyNFQyMTMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1hYWRjMjVjY2QzOTc0ZmJlNDIzN2I1N2NjNWE1NzQxYjZlNGE0ZWY1MjY3ZTgzZjZiYjk0M2JhYjgxZWQ0NDMxJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.9NBWdRoG5lsvjuLYdNct8vFpTJhw8Hip8_y1t5doU_U"><img src="https://private-user-images.githubusercontent.com/992248/406298490-db1857e2-cfcd-4c7a-a8c8-8e9089b1f504.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc3NTQ1MDMsIm5iZiI6MTczNzc1NDIwMywicGF0aCI6Ii85OTIyNDgvNDA2Mjk4NDkwLWRiMTg1N2UyLWNmY2QtNGM3YS1hOGM4LThlOTA4OWIxZjUwNC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDEyNFQyMTMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1hYWRjMjVjY2QzOTc0ZmJlNDIzN2I1N2NjNWE1NzQxYjZlNGE0ZWY1MjY3ZTgzZjZiYjk0M2JhYjgxZWQ0NDMxJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.9NBWdRoG5lsvjuLYdNct8vFpTJhw8Hip8_y1t5doU_U" alt="Screenshot 2025-01-23 at 10 48 50 PM"></a></p>
<p dir="auto">Screenshot from <a href="https://github.com/EerierGosling">@EerierGosling</a>. Also thanks to <a href="https://github.com/aramshiva">@aramshiva</a>, <a href="https://github.com/recursiveforte">@recursiveforte</a>, <code>@smashmaster0045</code>, <a href="https://github.com/YodaLightsabr">@YodaLightsabr</a>, and <a href="https://github.com/EerierGosling">@EerierGosling</a> for their help.</p>
</article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The State of Vim (251 pts)]]></title>
            <link>https://lwn.net/Articles/1002342/</link>
            <guid>42810176</guid>
            <pubDate>Fri, 24 Jan 2025 03:22:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/Articles/1002342/">https://lwn.net/Articles/1002342/</a>, See on <a href="https://news.ycombinator.com/item?id=42810176">Hacker News</a></p>
Couldn't get https://lwn.net/Articles/1002342/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[AI isn't going to kill the software industry (104 pts)]]></title>
            <link>https://dustinewers.com/ignore-the-grifters/</link>
            <guid>42810175</guid>
            <pubDate>Fri, 24 Jan 2025 03:22:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dustinewers.com/ignore-the-grifters/">https://dustinewers.com/ignore-the-grifters/</a>, See on <a href="https://news.ycombinator.com/item?id=42810175">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I feel like half of my social media feed is composed of AI grifters saying software developers are not going to make it. Combine that sentiment with some economic headwinds and it’s easy to feel like we’re all screwed. I think that’s bullshit. The best days of our industry lie ahead.</p><p>It’s highly unlikely that software developers are going away any time soon. The job is definitely going to change, but I think there are going to be even more opportunities for software developers to make a comfortable living making cool stuff.</p><p>Here’s your white pill. It’s all going to be okay.</p><h2 id="economics">Economics</h2><p>The field of economics has a lot to say about automation, productivity gains, and how they effect the economy. There’s no shortage of people saying “this time it’s different”, but those people have been around for every other major technological advance and they have yet to be correct. I wouldn’t bet on the doomers.</p><h3 id="jevons-paradox">Jevons Paradox</h3><p>AI tools create a significant productivity boost for developers. Different folks report different gains, but most people who try AI code generation recognize its ability to increase velocity. Many people think that means we’re going to need fewer developers, and our industry is going to slowly circle the drain.</p><p>This view is based on a misunderstanding of why people pay for software. A business creates software because they think that it will give them some sort of economic advantage. The investment needs to pay for itself with interest. There are many software projects that would help a business, but businesses aren’t going to do them because the return on investment doesn’t make sense.</p><p>When software development becomes more efficient, the ROI of any given software project increases, which unlocks more projects. That legacy modernization project that no one wants to tackle because it’s super costly. Now you can make AI do most of the work. That project now makes sense. That cool new software product idea that might be awesome but might also crash and burn. AI can make it cheaper for a business to roll the dice. Cheaper software means people are going to want more of it. More software means more jobs for increasingly efficient software developers.</p><p>Economists call this Jevons Paradox.</p><h3 id="comparative-advantage">Comparative Advantage</h3><p>When we think of future AI, we imagine a system that can do everything better than a human being. The all-knowing AI is better at programming, art, diagnosing diseases, and coming up with new ways to make toast. How can any human compete with that?</p><p>Turns out, it doesn’t really matter. There are already lots of situations where people who aren’t the best at something still find work.</p><p>Imagine a small business owner who is absolutely the best at everything in their business. They know every aspect of their business and can do any job in it better than anyone they can hire. Regardless of their genius, they only have 24 hours in a day. If they want to scale, they will need to hire people so they can focus on their most important work. For example, the business owner may be a better bookkeeper than their accountant, but the opportunity cost of not working on other things justifies hiring someone to keep the books.</p><p>This is an example of comparative advantage. Comparative advantage is when a country, company, or person can produce something at a lower opportunity cost than others. Even if that entity is not the most efficient producer, they’ll still be able to sell their product as long as someone else has more important things to do.</p><p>While AI is powerful, it’s also computationally expensive. Unless someone decides to rewrite the laws of physics, there will always be a limit on how much artificial intelligence humanity can bring to bear. This means that we’ll eventually allocate our scarce AI resources towards the things they are best at, which leaves plenty of things for humans to do.</p><h3 id="solow-model-of-growth">Solow Model of Growth</h3><p>The Solow model shows that economic growth is a product of capital (factories, data centers, corporate relationships, land, etc…), labor, and technological progress. In the long run, the only reliable driver of economic growth is technological progress. Our society gets richer by learning new ways to deploy scarce capital.</p><p>Another way to think about this on a micro level is that you can’t sustainably make more money than the economic value you create. A person who digs a hole with a shovel is not going to be able to make as much money as someone driving a bulldozer.</p><p>Widespread adoption of artificial intelligence will greatly accelerate technological progress. This acceleration will create a massive increase in economic growth. This rising tide will create more resources for everyone. If you’ve spent any time following the e/acc community on Twitter, this is what they’re banking on.</p><p>The Solow Model is more of a macro level concept and doesn’t specifically apply to software development as an industry. While I don’t think software development as a career is going away any time soon, if it does, we’ll still probably be better off. It’s better to be a barista in Star Trek than a noble in Game of Thrones.</p><h3 id="widespread-ai">Widespread AI</h3><p>While increased societal wealth is nice, what happens if all of that wealth is controlled by a handful of large companies run by a small cadre of tech elites that hoard all of the AI compute?</p><p>This is unlikely for a lot of reasons, but one of the big reasons is that AI innovators are committed to making AI accessible. While there are plenty of folks that offer access to AI-based tools, you can also DIY your own AI.</p><p>On the model side, many producers of models release them for free. While the top tier Open AI models are locked behind their walled garden, you can fire up Ollama or CivitaI and download lots of very capable models.</p><p>On the hardware side, Nvidia is also pushing local model execution via things like their Jetson Nano products and Digits mini computer. This doesn’t even include things like consumer video cards, or the M4 Mac Mini, which people have been using to make their own AI clusters. AMD is also working hard to make it easy to run local models.</p><p>There’s a huge incentive to make AI resources accessible to most people. If we amplify everyone by making it easy to access their own small army of personal assistants, innovation skyrockets. AI has the potential to enable millions of small creators to build sustainable businesses.</p><h2 id="the-job-of-software-developers">The Job of Software Developers</h2><p>Now that we’ve covered a few macro reasons why we aren’t screwed, let’s look at some more down to earth reasons why we’re still going to need software developers in the age of AI.</p><h3 id="the-70-problem">The 70% Problem</h3><p>AI models are fantastic at producing a wide variety of things. Sometimes the results are good and sometimes they’re weird. AI generated code is no different. I have yet to prompt an AI generated function that’s 100% correct. Gen AI is great for getting started, but it won’t write your whole app for you. This is occasionally referred as the “70% problem”, where AI can get you most of the way there, but it falls down at the end.</p><p>A lot of folks who don’t know how to write software and think they can prompt their way to success will get stuck in a loop where each prompt fixes one issue and causes two more. This is the 70% problem in action. You can generate code all day, but there’s no guarantee it’s going to be the right code.</p><p>Even if you get the AI to generate all of your code for you, it still needs to be tested, monitored, deployed, and maintained. Even if you get AI to write most of your code, there’s still plenty to do.</p><p>AI code gen also tends to fall down in complex enterprise systems. You can crank out cute demo apps all day long, but most systems don’t resemble cute demo apps. This isn’t much different than the Ruby on Rails 15 minute blog app scaffolding demos from back in the day. They looked cool, but it was only the first step.</p><h3 id="much-of-our-job-isnt-writing-code-anyway">Much of our job isn’t writing code anyway</h3><p>The folks who think AI is going to wipe out the software industry don’t fully understand what software engineers do day to day. After 20 years, coding is honestly one of the easiest parts of the job for me. There’s lots of time spent talking with other engineers, understanding the business domain, figuring out the best approach, weighing options, and designing systems. Even if AI generates most of our code, we’ll still need to tell the thing what to write and that’s going to require software developers.</p><h3 id="we-have-so-much-software-left-to-build">We have so much software left to build</h3><p>The biggest assumption of the doomer crowd we’re close to having “enough” software and increased efficiency is going to quickly exhaust the project queue. I have yet to work for a company that doesn’t have a near infinite backlog of things they want to do. If software development moves faster, we’re just going to build more software.</p><h2 id="what-do-i-need-to-do">What do I need to do?</h2><p>Some developers think AI isn’t going to change much of anything and we should just sit tight and wait for it all to blow over. That view is just as short sided as the doomer side of the equation. Software development has always been a career where you are either learning new things or stagnating. AI doesn’t change the need to keep learning and evolving.</p><p>The best thing you can do is learn how the current stack of AI tools work. If you can use Copilot at work, go for it. Otherwise, spin up your free Copilot trial and build something. Beyond that, take some time to learn how AI works and think about other ways it can improve your workflow. Maybe get it to crank out some of that documentation you don’t want to write anyway.</p><p>Beyond that, keep learning about what it takes to build good software. Work on your architecture &amp; design skills. Consider branching out into other areas in the stack like product development. While the value of raw coding skills might go down, the value of everything else around them is going to continue to rise.</p><p>The software developer job is going to change a lot in the next five years. The AI revolution is similar to the introduction of compilers. If you keep up and learn the new paradigms, then you’re going to be okay. Otherwise, you might find yourself in a bad place.</p><p>Things are probably going to get a little weird, but it’s not like you signed up to be a developer because it was the same thing every day. Crack the books, fire up your copilot enhanced editor, and make cool stuff.</p><h4 id="links">Links</h4><p>If you want a longer description of this topic, check out this article from an actual economist:<br><a href="https://www.noahpinion.blog/p/plentiful-high-paying-jobs-in-the">Plentiful, high-paying jobs in the age of AI</a></p><p>A good video series on the Solow Model:<br><a href="https://www.youtube.com/watch?v=eVAS-t83Tx0&amp;list=PL-uRhZ_p-BM6L_I3IHvE85NHooK2Ln9Rm">Intro to the Solow Model of Economic Growth</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Weierstrass's Monster (169 pts)]]></title>
            <link>https://www.quantamagazine.org/the-jagged-monstrous-function-that-broke-calculus-20250123/</link>
            <guid>42810103</guid>
            <pubDate>Fri, 24 Jan 2025 03:02:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/the-jagged-monstrous-function-that-broke-calculus-20250123/">https://www.quantamagazine.org/the-jagged-monstrous-function-that-broke-calculus-20250123/</a>, See on <a href="https://news.ycombinator.com/item?id=42810103">Hacker News</a></p>
Couldn't get https://www.quantamagazine.org/the-jagged-monstrous-function-that-broke-calculus-20250123/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[A QR code that sends you to a different destination - lenticular and adversarial (512 pts)]]></title>
            <link>https://mstdn.social/@isziaui/113874436953157913</link>
            <guid>42809268</guid>
            <pubDate>Thu, 23 Jan 2025 23:55:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mstdn.social/@isziaui/113874436953157913">https://mstdn.social/@isziaui/113874436953157913</a>, See on <a href="https://news.ycombinator.com/item?id=42809268">Hacker News</a></p>
Couldn't get https://mstdn.social/@isziaui/113874436953157913: Error: timeout of 10000ms exceeded]]></description>
        </item>
    </channel>
</rss>