<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 01 Mar 2024 15:00:30 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Fugitive Wirecard COO Jan Marsalek exposed as decade-long GRU spy (194 pts)]]></title>
            <link>https://theins.ru/en/politics/269612</link>
            <guid>39561021</guid>
            <pubDate>Fri, 01 Mar 2024 12:13:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theins.ru/en/politics/269612">https://theins.ru/en/politics/269612</a>, See on <a href="https://news.ycombinator.com/item?id=39561021">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><em>This is a joint investigation with </em><a href="https://www.spiegel.de/politik/deutschland/a-5cb415ed-0029-4754-8bd5-f4120f4baf83" rel="noopener noreferrer" target="_blank"><em>Der Spiegel</em></a><em>, ZDF, and Der Standard.</em></p><p>In the city of Lipetsk, 300 miles south of Moscow, stands a yellow chapel. Somewhat out of place next to a modern mirrored-window building, situated on the lip of a roundabout, the 200 year-old Church of Holy Transfiguration caters to the faithful of a large mining town that dates back to the era of Peter the Great. Inside, Father Konstantin Baiazov performs the customary rites and rituals for his flock. Dark and bearded, with a short, military-style buzz cut, the church’s archpriest’s routine is standard – services twice a day. Father Konstantin inherited the job — and the calling — from his own father, a revered Orthodox priest who, as local legend goes, had challenged the authority of the formidable KGB during Soviet times. </p><p>Konstantin, the father of three, used to travel abroad. He liked visiting Europe, and was particularly fond of Rome. However, he has not left Russia since September 2020. Since the fifth of that month, Father Baiazov’s official passport, numbered 763391844, has not belonged to a man of God. Rather, it belongs to someone who wears a different kind of white collar, looks a lot like him, and is the most wanted man in Europe.</p><p>For more than four years, Jan Marsalek, the former chief operating officer of the disgraced German financial services company Wirecard, has been living in Russia under this assumed identity, a year-long investigation by <em>The Insider, Der Spiegel,</em> <em>ZDF, </em>and <em>Der</em> <em>Standard </em>has uncovered. Wirecard, the German equivalent to PayPal was once a DAX-30 listed company, one of the wealthiest traded entities on the German stock exchange, with a valuation of $28 billion. Then came June 2020, when, in the midst of an audit, Wirecard could not locate €1.9 billion in assets it claimed were being held somewhere in the world – Russia, the United Arab Emirates or the Philippines. In fact, the money didn’t exist. Wirecard’s worth was predicated on commissions supposedly earned from three companies, Al Alam, Senjo and PayEasy, based in Dubai, Singapore and Manila, respectively. Wirecard money flowed into all three but the only documented flows in reverse existed in the German conglomerate’s imagination. Or, as the now imprisoned former CEO Markus Braun claims, it had been funneled away to a complex web of offshore accounts controlled by his then number two, Jan Marsalek.</p><p>Marsalek, the man responsible for overseeing the forging of company records, money-laundering, and extensive espionage and harassment campaigns against the journalists and speculators who exposed the enormity of Wirecard’s graft, fled in a sinuous route from Germany to Austria to Belarus to Moscow on June 19, 2020, at a moment when COVID-19 lockdowns made movement across borders more difficult than usual for ordinary citizens. But Marsalek is not only an internationally accused swindler. He is also an agent of the GRU, Russia’s military intelligence service, and he has been for the last decade. More recently, since his defection to Russia, he has also done jobs for the FSB.</p><p><em>The Insider</em>’s investigation is based mainly on confidential documents, emails, and chat transcripts, as well mobile phone and travel data. Research into Marsalek’s past also included interviews conducted by our consortium partners with people close to the accused. Among these are his mother and his longtime recruiter-handler, whom <em>Der Spiegel</em> met up with in February at a five-star hotel in Dubai.  </p><p>The never-before-told story of how the Austrian-born “whiz kid” was recruited to Russia’s largest and most notorious spy agency, the GRU, bears all the hallmarks of a genre-bending ham thriller. Sacha Baron Cohen as Bernie Madoff the Bond villain. It is a saga replete with honey traps, MiG fighter jets, erotic models, sinister ex-spooks, even more sinister mercenaries, counterfeit passports, fake priests taking Syphilis tests, and cheap disguises. More ominously, the story also involves surveillance and kidnapping plots, including surveillance targeting a member of the team that investigated Marsalek’s case, Christo Grozev.</p><h3 id="article_block_0">“World Domination”</h3><p>Born in Vienna on March 15, 1980, and raised in the nearby suburb of Klosterneuburg, Jan Marsalek was, in the recollections of his mother, a “presumptuous show-off.” Marsalek’s father was a Czech factory worker who eventually became managing director of a company in the newly independent Czech Republic — “a small man with small ideas,” in the words of his eldest son. Marsalek’s parents divorced when he was a teenager, and he would remain estranged from his family from that point on. </p></div><div><div><svg width="40" height="40" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg"><line x1="9" y1="8" x2="9" y2="16" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="32" y1="8" x2="32" y2="16" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="9" y1="8" x2="17" y2="8" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="24" y1="8" x2="32" y2="8" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="9" y1="31" x2="17" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="24" y1="31" x2="32" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="9" y1="23" x2="9" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="32" y1="23" x2="32" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line></svg><div><figure><div><p><img src="https://api.theins.ru/images/9ERv1UWo-3gts4amcnM-8DJnecewMzIC1NML6E3VZwA/rs:fit:866:0:0:0/dpr:2/q:80/bG9jYWw6L3B1Ymxp/Yy9zdG9yYWdlL2Nv/bnRlbnRfYmxvY2sv/aW1hZ2UvMjI3NDkv/ZmlsZS1jMmYxNDA1/YzhjODc5MWUwOWY0/MmJmODdhMTU1ODY1/MC5wbmc.jpg" alt="Childhood photos of Jan Marsalek"></p></div></figure></div></div><p><h5>Childhood photos of Jan Marsalek</h5></p></div><div><p>Growing up, everyone recalls, the young Marsalek had two principal talents: he could talk, and he could charm. “A sales genius, a catcher of people,” says a former friend. Even at an early age, Marsalek seemed to be mugging for the cameras as an international man of mystery. One photo from his boyhood shows him in a gray trench coat and oversized floppy hat — the secret agent as envisaged by Titin. He was tall, around 5’11, slim and fond of martial arts, always with a close-cropped haircut. He was educated at Vienna’s Lycée Français, and by the time he left, Marsalek could speak several languages, including computer code. Clearly, his outsized ambitions matched his capacity for persuading others to facilitate his realization of them. </p><p>Wirecard was founded in 1999 in Munich at the height of the dotcom boom as a credit card payment processor for online vendors. Then as now, the internet’s truly big business came from revenues connected to gambling and pornography, paid for by Visa and Mastercard customers whose “discretely charged” debits Wirecard was all too happy to transact — for a commission. And if that eventually meant miscategorizing transactions for newly proscribed online gambling sites, so what?</p><p>The CEO of the company was Markus Braun, a former KPMG consultant from a middle-class family in Vienna. Braun modeled his appearance on Steve Jobs, always wearing a black turtleneck and wire-frame eyeglasses, even if the tech visionary look was undercut by the clashing black sports jacket Braun insisted on wearing as part of the outfit. With his alleged PhD in social and economic sciences, Doktor Braun wanted to be taken seriously by the Central European financial elite, but he lacked the charisma and ostentatiousness necessary to sell an emerging tech company. </p><p>Enter Marsalek. Braun recruited him from a two-man startup to Wirecard a year after its formation, on Marsalek’s 20th birthday. Even though he held no university degree, the “whiz kid” was immediately branded the company’s chief technology officer. </p><p>His first major act was a major screw-up, albeit a characteristically self-interested one. Marsalek unwisely “routed all of the company’s internet traffic through his own PC, rather than the dedicated hardware in the server room – a set-up ideal for snooping,” writes <em>Financial Times </em>reporter Dan McCrum, author of the 2022 book <em>Money Men</em>, which chronicles the rise and fall of Wirecard, and his own role in becoming the subject of a well-financed vilification campaign for his muckraking reporting.</p><p>A favorite word of Marsalek’s was “brilliant,” which he’d use to describe things that impressed or amused him, very often because they involved some form of corner-cutting — if not outright con artistry. Marsalek’s icon in business was a fellow Austrian, Dietrich Mateschitz, the creator and promoter of the energy drink Red Bull, which outsourced production and distribution to others while keeping the profits for itself. Marsalek seemed fond of generating money on the back of a highly touted idea without any tangible product undergirding it, a real-life Joe MacMillan, the fast-talking, overpromising Silicon Valley guru in the TV series <em>Halt and Catch Fire.</em> But whereas the fictional MacMillan was an incorrigible idealist who serially failed in his poorly executed revolutions in personal computing, the all too real Marsalek reveled in being a hollow man. A new software for more secure payment processing? He spent months talking it up, and getting the Wirecard sales team to do likewise, with nothing but scraps of nonsense code to show for it. Any other company might have gone under. Instead, Wirecard ballooned, relentlessly acquiring subsidiaries and subcontractors including prepaid card concerns and smaller payment processing outfits overseas.</p><p>In most cases, the paper trails led nowhere — or, more specifically, they led to shell companies whose nominal directors worked out of slapdash offices atop fast food joints in Bahrain, or that consisted of the unsuspecting local population of an impoverished former steel town in Consett, County Durham, England, where residents were compensated fifty quid for every company they registered. One Wirecard partner was in fact a Filipino family, doorstopped at their villa three hours’ drive north of Manila while in the middle of grooming their poodle with clippers. </p><p>The entire empire ran on a Ponzi scheme dedicated to moving money from one Wirecard account into another — a process euphemistically called “round tripping” — and raising ever more cash from deceived shareholders taken in by the smoke and mirrors. More impressive was how Wirecard dealt with critics, the hedge fund analysts and short sellers and financial journalists who were onto its fraud and who, thanks to Marsalek’s silky evasions and dirty tricks, were for years cast as the real criminals in the company’s saga. Wirecard hired goons and snoops who spied on and hacked its enemies, which included the <em>FT’s </em>McCrum, who himself became the target of a German financial regulatory investigation thanks to lies told by the company. Marsalek’s<em> </em>money-launderers exploited Germany’s sterling reputation for commercial probity and Berlin’s defensiveness about its prized Bavarian asset to boost Wirecard’s market capitalization. All the while, Marsalek enjoyed the high life, zipping around the world on a private jet, entertaining associates and casual acquaintances, dropping a grand a pop on bottles of Château Haut-Brion or €15,000 on dinner at the Mandarin Oriental.</p><p>Until the entire thing came crashing down in June 2020, thanks in no small part to forensic accountants at KPMG, Wirecard CEO Markus Braun’s former employer. They realized, in the words of Dan McCrum, that Wirecard’s “core European payment processing operations made no profit at all.”</p><p>“The problem with us Austrians,” Marsalek liked to quip around the office, “is we always want world domination.”</p><h3 id="article_block_1">Blood Lust</h3></div><div><div><svg width="40" height="40" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg"><line x1="9" y1="8" x2="9" y2="16" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="32" y1="8" x2="32" y2="16" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="9" y1="8" x2="17" y2="8" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="24" y1="8" x2="32" y2="8" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="9" y1="31" x2="17" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="24" y1="31" x2="32" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="9" y1="23" x2="9" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="32" y1="23" x2="32" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line></svg><div><figure><div><p><img src="https://api.theins.ru/images/oCM8Uzv89SKK6XfduVE19P_nlLXubXigCylCf9obD5Q/rs:fit:866:0:0:0/dpr:2/q:80/bG9jYWw6L3B1Ymxp/Yy9zdG9yYWdlL2Nv/bnRlbnRfYmxvY2sv/aW1hZ2UvMjI3NTAv/ZmlsZS0xMGVkY2Rk/OWU3NTNjNDgwN2Rk/MWEyMWYxNmQ1ZDJk/Yi5wbmc.jpg" alt="Natalia Zlobina, Marsalek’s girlfriend, who introduces him to GRU recruiter Stanislav Petlinsky."></p></div></figure></div></div><p><h5>Natalia Zlobina, Marsalek’s girlfriend, who introduces him to GRU recruiter Stanislav Petlinsky.</h5></p></div><div><p>Taking over the word usually involves conquering Moscow. Braun’s relationship with the great and the not-so-good of the Austrian establishment opened that door. </p><p>Florian Stermann was the chairman of the Russian-Austrian Friendship Society and a fixer for the right-wing populist Austrian Freedom Party (FPÖ). Thanks to Stermann, Wirecard had entered into negotiations for the provision of wireless payment technology with three Russian mobile operators. One of these projects was a joint venture with the mobile giant Megafon to provide NFC payment services to the Moscow Metro, a sprawling subway system that serves more than seven million passengers daily. That one was delegated to Marsalek. But by 2013, the project with Megafon had come to a halt as negotiations with the city-owned subway operator stalled after Megafon began pursuing the development of an in-house solution for NFC payments. Other attempts to offer Wirecard’s payment technology to Russian counterparts also failed, either because Wirecard’s solutions were too expensive or due to delays on the German side.</p><p>The Megafon failure wasn’t Marsalek’s first in Russia. Beginning in July 2010, not long after he was elevated from chief geek to chief operating officer at Wirecard, Marsalek began traveling to the country, sometimes making as many as four trips a month. In the space of the next decade, he would visit Russia more than sixty times, with the highest concentration of visits occurring between 2013 and 2016 — exactly when Wirecard’s attempts to export their business eastward were coming to dust. </p><p>This was because Marsalek had found new dissipations in Russia, one of them in the form of a tall blonde putative deal-saver named Natalia Zlobina. Born in Tashkent, Uzbekistan, the then 29-year-old Zlobina was already an advertising executive. However, she was more recognizable from her previous career in erotic modeling and B-movie acting, where her best-known feature was <em>Red Lips 2 – Blood Lust</em>, a sexy-schlocky vampire flick in which the thirteen-year-old Zlobina plays a Russian secret agent who kills her victims using a nerve agent.</p><p>In a fitting turn of life-imitating-art, Zlobina became a Russian spy. </p><p>When she met Marsalek, Zlobina claimed to have an investor who could set up an entity for Wirecard to do business with in Russia. In August 2013, she even incorporated a company called ByteMax Ltd. as a payment facilitation start-up intended to be the German giant’s main Russian partner. She was one of two shareholders, the other being a business partner of Dimitri Pyankovski, who was Moscow’s head of electronic payment services. Everything seemed poised for success.</p><p>Email correspondence and travel records reviewed by <em>The Insider</em> and <em>Der Spiegel</em> show that, over the ensuing years, Marsalek and Zlobina’s relationship became an intertwined mix of business and personal pursuits. Despite Zlobina’s connections in Moscow, the former didn’t go so well for Wirecard. ByteMax ran up a large bill to Marsalek’s company that it didn’t have the funds to repay. But Marsalek hardly minded. His emails to Zlobina show he’d taken to coaching her on how and to whom at Wirecard she should address her requests for extensions to the payment deadlines. The dues were never repaid. ByteMax was wound down.</p><p>At the same time, the personal relationship between Marsalek and his protege blossomed. The two traveled both together and separately in Russia and abroad, with Wirecard fronting the costs for some of the trips. Emails show Marsalek’s personal assistant booking travel for Zlobina to Barcelona in March 2015; she stayed at a ​​€695-a-night hotel. Marsalek would sometimes fly into Russia on his private jet just to pick up Zlobina and then fly on to the Greek island of Santorini for a weekend getaway. They were more than associates; they were lovers.</p><p>And they liked it rough. Marsalek was drawn to BDSM, and so was Natalia. They were also drawn to others for whom violence was less a leisure activity than a means of retaining political power. </p><p>Travel records show that Marsalek and Zlobina traveled in September 2013 to Grozny, the capital of Chechnya. Witnesses have told <em>Der Spiegel</em> the purpose of the unlikely tourist trip was to meet the family of Ramzan Kadyrov, the Putin-installed strongman president of the region. Kadyrov’s clan had a few hundred million squirreled away in banks in Hong Kong, and they needed a way to move it to Europe without arousing any suspicions. According to Zlobina, by then <em>au fait </em>with Wirecard’s global network of matryoshka companies and their dummy deposits, Marsalek was the Kadyrov clan’s man for the job. According to witnesses, two additional meetings between Marsalek and the Kadyrov family were arranged — one in Vienna and another in Asia, the site of the dirty money. On the Chechen side in Vienna was the silver-haired Akhmed Pakaev, who claimed to be a major from the FSB, Russia’s Federal Security Service and one of the successors to the Soviet-era KGB. Leaked Russian bank credit records examined by <em>The Insider</em> show Pakaev had previously served as a Russian representative to Interpol.</p><p>In January 2014, Marsalek jetted Zlobina to Kyiv at the very moment when the Ukrainian capital was mired in a protest movement against its pro-Russian President, Viktor Yanukovych, who at Putin’s prompting and financial encouragement had reneged on a campaign promise to sign an association agreement with the European Union. By the time the power couple arrived, the Euromaidan movement was already under physical threat from officers of the Yanukovych-loyal Berkut riot police and plain clothes hired thugs called <em>titushki</em>. The anti-revolutionary activities were being orchestrated by the FSB’s Fifth Service, the Russian organization’s foreign intelligence arm. In Kyiv, Marsalek and Zlobina again met with Pakaev, who had arrived in Ukraine in November at the start of Euromaidan for purposes that can only be guessed at. </p><p>Leaked emails show that Pakaev introduced Marsalek to Konstantin Torop, the self-styled director of the International Police Corporation for Public Security, a non-government militia that has reportedly been <a href="https://podrobnosti.ua/736957-interpol-zainteresovalsja-ukrainskoj-politsejskoj-korporatsiej.html" rel="noopener noreferrer" target="_blank">investigated</a> by Interpol over accusations that it was impersonating a public police body. In one letter to Marsalek, who used an email<a href="https://www.spiegel.de/netzwelt/netzpolitik/wirecard-jan-marsalek-bahnte-offenbar-kauf-von-spionagesoftware-an-a-9ee27215-c572-42e7-9436-7e4325975c3b" rel="noopener noreferrer" target="_blank"> account that itself spoofed a state official</a> from Grenada (jan.<a href="https://theins.ru/cdn-cgi/l/email-protection#3954584b4a58555c52794a4d584d5c565f5e4b5c57585d5817564b5e" rel="noopener noreferrer" target="_blank"><span data-cfemail="54393526273538313f1427203520313b323326313a3530357a3b2633">[email&nbsp;protected]</span></a>), Torop informed him that, on Pakaev’s recommendation, Marsalek had been issued a membership ID from the “police” organization.</p><p>Marsalek and Zlobina continued to travel, and not only to earthly destinations. In May 2016, Zlobina booked her boyfriend on a flight into the stratosphere aboard a Russian MiG fighter jet. But while images of the lovebirds on their adrenaline-filled extreme romantic getaways were known to Russian social and business elites at the time, the affair remained a mystery to all but a few employees at Wirecard. Back in Munich, Marsalek was involved in a steady, long-term relationship with Viola, his German girlfriend and eventual fiancée. The COO even boasted to his Russian friends that he’d relocated Viola to Hamburg, making it easier for Zlobina to visit him in Munich without any worry she might bump into her rival.</p></div><div><div><svg width="40" height="40" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg"><line x1="9" y1="8" x2="9" y2="16" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="32" y1="8" x2="32" y2="16" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="9" y1="8" x2="17" y2="8" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="24" y1="8" x2="32" y2="8" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="9" y1="31" x2="17" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="24" y1="31" x2="32" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="9" y1="23" x2="9" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="32" y1="23" x2="32" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line></svg><div><figure><div><p><img src="https://api.theins.ru/images/RXIsnxt6v4vmmX7RsnnWHrj0QcB8_vn6-WDOBl7ZshA/rs:fit:866:0:0:0/dpr:2/q:80/bG9jYWw6L3B1Ymxp/Yy9zdG9yYWdlL2Nv/bnRlbnRfYmxvY2sv/aW1hZ2UvMjI3NTEv/ZmlsZS00NzA0NDg1/YmVhNGI5ZWI2OTM4/ODFiMDIwNjY3ZWQw/NS5wbmc.jpg" alt="At the top, Natalia Zlobina and Jan Marsalek pictured together. On the bottom, Natalia and Jan on the board of the Russian MiG fighter jet in May 2016."></p></div></figure></div></div><p><h5>At the top, Natalia Zlobina and Jan Marsalek pictured together. On the bottom, Natalia and Jan on the board of the Russian MiG fighter jet in May 2016.</h5></p></div><div><p>Jan and Natasha were also busy outside of the bedroom.</p><p>While Wirecard’s entry into the Russian market foundered, Marsalek and Zlobina launched at least one joint enterprise together, a cryptocurrency mining farm located in the far northeastern region of Yakutia, Russia. The three megawatt farm, called<a href="https://web.archive.org/web/20180626184045/http:/atlasmine.io:80/#whitepapper" rel="noopener noreferrer" target="_blank"> Atlas Mine</a>, was built with equipment purchased by Marsalek through offshore accounts using a UK intermediary. The project followed Marsalek’s tried-and-true method of revenue generation: a pyramid scheme in which for the low, low price of $100, investors were guaranteed enormous returns within the space of six months and continuing in perpetuity. The prospectus for Atlas Mine’s initial coin offering (ICO) also referred to a previous project by the same operator, this one based in China. A<a href="https://www.youtube.com/watch?v=OONL7jzbKcM" rel="noopener noreferrer" target="_blank"> YouTube video</a> uploaded in May 2018 shows the installation process and “operational” phase of what appears to be a large crypto mining farm. It is not known how many, if any, investors the ICO project attracted. Its website has been defunct since at least 2021.</p><p>It is also unknown whether Zlobina’s work for the Russian security services preceded or followed her personal and professional involvement with Marsalek, but in any case, she certainly enjoyed the kinds of unusual state protections typically associated with Russian intelligence operatives. For instance, her passport dossier — something usually obtainable through the transparent Russian personal data trading market on the dark web — was replaced by another woman’s file when <em>The Insider </em>attempted to acquire it. Subsequent attempts to retrieve the file were returned with a “missing person” notification. Likewise, all of Zlobina’s travel records for the two years after Marsalek fled to Russia have been purged from the comprehensive Russian database, Magistral - arguably, lest someone was able to trace the fugitive Austrian via his then girlfriend. Previously such deletions have been seen in the cases of Russia spies and undercover operatives, such as Vadim Krasikov, the FSB hit man who fatally gunned down Zelinkham Khangoshvili, a Chechen war veteran turned Georgian intelligence asset, in Berlin’s Tiergarten park in August 2019. (Krasikov, convicted in 2021, is currently serving a life sentence in German prison.)</p><p>Was Zlobina sent to honeytrap Marsalek, or was she just one of the several spooks and ex-spooks the German executive became entangled with over the years, whether for business or pleasure? Was this one of the tall blondes he just happened to sleep with, or had Zlobina been tasked with offering her services, as it were, to the Wirecard operator in order to talent-spot him for recruitment?</p><h3 id="article_block_2">Stas, the General from GRU</h3></div><div><div><svg width="40" height="40" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg"><line x1="9" y1="8" x2="9" y2="16" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="32" y1="8" x2="32" y2="16" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="9" y1="8" x2="17" y2="8" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="24" y1="8" x2="32" y2="8" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="9" y1="31" x2="17" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="24" y1="31" x2="32" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="9" y1="23" x2="9" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="32" y1="23" x2="32" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line></svg><div><figure><div><p><img src="https://api.theins.ru/images/ORvsS1Vdf3TiJKRQN-c2-Ia2P1sZHzPqRDK1W--N98U/rs:fit:866:0:0:0/dpr:2/q:80/bG9jYWw6L3B1Ymxp/Yy9zdG9yYWdlL2Nv/bnRlbnRfYmxvY2sv/aW1hZ2UvMjI3NTIv/ZmlsZS0xNGM5MmQy/NmJkYzU5Y2JmMTJi/OWM4YjRjNzRjYzJh/YS5wbmc.jpg" alt="Jan Marsalek and Stanislav Petlinsky celebrating Petlinsky’s birthday at the Munich restaurant &quot;Tantris&quot;."></p></div></figure></div></div><p><h5>Jan Marsalek and Stanislav Petlinsky celebrating Petlinsky’s birthday at the Munich restaurant "Tantris".</h5></p></div><div><p>On July 6, 2014, Zlobina turned 30. It was also the day Marsalek met his GRU handler.</p><p>Zlobina was waiting for her beau aboard a dingy Greek-flagged cutter, “Poseidon III,” in the Mediterranean waters off the coast of Nice. Marsalek arrived with a second man, who was carrying his suitcase. Marsalek climbed down a ladder into the vessel and gave Zlobina a perfunctory peck on the cheek. He was clearly angry, which was the point of this vignette, captured on marina security camera footage retrieved by <em>Der Spiegel</em>. The Poseidon III was a ruse, Natasha’s joke, and whether by accident or design, two years later, the Greek god of the ocean would furnish the codename used to refer to Wirecard in a bogus corporate merger scheme with a French merchant technology company, Ingenico. That scheme was designed — and then publicly leaked — to gin up Wirecard’s share prices.</p><p>Zlobina’s birthday gift to Marsalek — or maybe to herself — was an introduction aboard the yacht to a man named Stanislav Petlinsky. Zlobina introduced Marsalek to Petlinsky as “Stas, the general from GRU.” At the time, Petlinsky was dating Zlobina’s best friend, and she promised Marsalek that “Stas” would be a terrific addition to his thickening rolodex of influential Russian contacts. </p><p>So he would. </p><p>In the 90s, Petlinsky had been a supervising officer in the GRU Spetsnaz, or special forces, and fought in Chechnya. He spent that floating evening with Marsalek regaling him with his exploits — particularly as a marksman, as Marsalek expressed an interest in guns. Petlinsky’s exact rank and role in Russian intelligence — hinted at by the man himself to an intimate circle of contacts, either in truth or as provocatively sprinkled bits of disinformation aimed at burnishing his legend — is murky, but Western spy agencies do not doubt that his employer is the Russian state.</p><p>Among those Petlinsky has regaled is a reporter from <em>Der Spiegel</em>. That conversation occurred mere weeks ago at the Jumeirah al-Naseem beach resort in Dubai — amid a plentiful selection of champagne, Beluga caviar, and young Russian women.</p><p>Petlinsky is found sitting on the terrace overlooking the Persian Gulf. Not far from him is another Russian, Alexander Lebedev, the ex-KGB officer turned oligarch and publishing magnate who controls Britain’s <em>Independent</em> and <em>Evening Standard</em> newspapers. The two clearly know each other and nod a silent greeting.</p><p>Trim at 60, dressed in a gray pinstripe, black tee, and mirrored aviator sunglasses, Petlinsky confirms meeting Marsalek aboard the yacht in Nice in July 2014. “You know, I fell in love with him from the first moment,” he said. “He has such a beautiful mind. I always think so small, in dimensions of what’s possible,” he continues, echoing Marsalek’s own animadversions about his own father. “Jan always thinks big, very, very big.” Being chancellor of Germany? Too small for Marsalek. “But uniting China, Russia, and Europe as a counterbalance to the USA, that would interest him.” </p><p>Fancy toys and women aren’t Marsalek’s motivation, Petlinsky insists before describing the Austrian’s “beautiful mind” as being “a bit autistic.” While Marsalek’s acquaintances almost universally define him with the word “charisma,” Petlinsky says Marsalek’s weak point is dealing with people. “He lacks empathy,” the Russian spy says without noting that the trait is a telltale sign of the sociopath.</p><p>What about Marsalek’s espionage and Petlinsky’s responsibility for it? The Austrian is just playacting, Petlinsky maintains, inhabiting a theatrical role with no real-world legitimacy to it. Marsalek is “obsessed” with spycraft and all its mystique, something others also attest to. As for Petlinsky himself, he swears he’s merely a “security advisor” with a big portfolio in Africa, the kind of man who sometimes meets with Putin and chases down FSB agents. He offers a robust critique of the amateurish nature of the Khangoshvili assassination in Berlin — no small thing given that Putin has recently praised the killer Krasikov as a “patriot” in a much-discussed sit-down interview with Tucker Carlson. Petlinsky admits to introducing Marsalek to a host of colorful characters in Russia. He doesn’t want to talk about which ones were Russian intelligence officers, and he changes the subject. </p><p>But to his close circle of friends, <em>Der Spiegel</em> has learned, Petlinsky boasted about handing Marsalek off to the GRU after that first meeting in the South of France in 2014. Friends of Marsalek say the Wirecard fraudster’s life can be divided in two halves: “before Stas” and “after Stas.”</p><p>They traveled together, often as a trio, with Zlobina in tow. At one point, Petlinsky even told friends that he relocated his own mother, who suffered from health problems, to a clinic in Munich just to be closer to Marsalek, who built himself his own back office for Wirecard and other pursuits in a villa at Prinzregentenstraße 61, right in the center of the Bavarian capital. Johanna Singer, an employee of Wirecard (name has been changed on her request), recalled meeting Petlinsky at the gourmet Munich restaurant Tantris, where the GRU officer celebrated one of his birthdays with Marsalek, complete with a cake shaped in uncanny resemblance to the Soviet red star. One of the toniest areas of Munich, the high-ceilinged, white-columned digs cost 680,000 euro per year in rent, all paid for, of course, by Wirecard via its manifold holdings. A germaphobe in the mold of Donald Trump (the Wirecard executive somehow unsurprisingly owns a life-sized cut-out of the 45th U.S. President), Marsalek even had a field hospital built in the villa during the pandemic. The back office was conveniently situated directly across from the Russian consulate in Bavaria.</p><p>One trip Marsalek, Zlobina, and Petlinsky took was to Tunisia via private jet from Moscow in March 2016. The next month, they returned to Nice, the scene of Marsalek and Petlinsky’s meet-cute recruitment; then it was on to Tel Aviv. Stas pulled plenty of strings, as Russian border records demonstrate: much of his foreign travel is designated as “official visit to a diplomatic mission,” a category typically reserved for Russian Foreign Ministry officials. </p><h3 id="article_block_3">Marsalek's Mercenaries</h3><p>Stas was also a connector. </p><p>A proud owner of a Harley Davidson himself, he introduced Marsalek to a heavy-set man fond of Hells Angels attire, whom Petlinsky referred to as “Vladimir, my mercenary.” Vladimir’s actual name is Anatoliy Karaziy. Like Petlinsky, Karaziy is a former GRU Spetsnaz officer, and the two are thought to have served together in Chechnya. At the very least, the mercenary part of the story proved true, as Karaziy belonged to a guns-for-hire outfit that gained in infamy after its debut on the battlefields of eastern Ukraine in 2014. It was called the Wagner Group, and it was founded by catering magnate and ex-con Yevgeny Prigozhin, a personal friend of Putin’s from their native St. Petersburg.</p></div><div><div><svg width="40" height="40" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg"><line x1="9" y1="8" x2="9" y2="16" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="32" y1="8" x2="32" y2="16" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="9" y1="8" x2="17" y2="8" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="24" y1="8" x2="32" y2="8" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="9" y1="31" x2="17" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="24" y1="31" x2="32" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="9" y1="23" x2="9" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="32" y1="23" x2="32" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line></svg><div><figure><div><p><img src="https://api.theins.ru/images/yMH8tcSZ52JuOy5DQ2u47bQ2_CYifqRPziUQgGG5BLg/rs:fit:866:0:0:0/dpr:2/q:80/bG9jYWw6L3B1Ymxp/Yy9zdG9yYWdlL2Nv/bnRlbnRfYmxvY2sv/aW1hZ2UvMjI3NTMv/ZmlsZS00YjRiZWM3/NTA5NmE2YzgwMzNj/MTdmMzNjOWVjNDA0/My5wbmc.jpg" alt="Karaziy (second from right) in Chechnya circa 1996, and more recently at a gun show in Moscow."></p></div></figure></div></div><p><h5>Karaziy (second from right) in Chechnya circa 1996, and more recently at a gun show in Moscow.</h5></p></div><div><p>By 2017, Karaziy was the head of Wagner’s intelligence service. Travel data examined by <em>The Insider</em> confirms that on May 5, 2017, Karaziy flew from Moscow to Munich to meet with Petlinsky and Marsalek. From there, the three men flew to Beirut and then took a car into war-torn Syria, visiting the ancient city of Palmyra, which Russian forces backed by Wagner had recently captured from the terrorist group ISIS. The three men remained in Palmyra for a week, with Marsalek dressed as a soldier in aviator headgear, a flak jacket, and combat helmet (witnesses told Der Spiegel that Marsalek initially showed up dressed in brand-new state-of-the-art camouflage garb and military gear - a “shiny object in the desert” that would have attracted enemy fire within seconds; he was quickly given standard Russian attire to change into). He’s alleged to have shot live rounds at Islamist militants.  </p><p>In Dubai Petlinsky suggested the rounds had come from a rocket launcher, and that Marsalek had even been given a tutorial in how to position himself properly in order to fire it. The visit to Syria, Petlinsky says, was “a dream of Jan’s that I made come true… Jan imagined a helicopter flight and loud music and Ray-Ban sunglasses. Of course, that didn’t happen. Too dangerous.”</p></div><div><p>Another high-flying Russian to whom Petlinsky introduced Marsalek was Andrey Chuprygin, also a former GRU officer — a colonel — who worked for Petlinsky’s Center for Eastern Civilization Studies. Chuprygin was an academic, too, with a teaching job in African studies at the Moscow School of Economics. He also served as an adviser on Libya to Russia’s Foreign Ministry, a title Petlinsky even arranged for Marsalek to acquire. </p><p>Marsalek’s interest in Libya wasn’t confined to ego-gratifying honorifics from the Russian government. Upon his return from Syria, Petlinsky persuaded him to invest in the North African country, which was still reeling from the brutal civil war that ended Col. Muammar Gaddafi’s three decades of iron fisted rule. Someone recommended Marsalek buy cement factories, without which postwar Libyan reconstruction would be impossible. And he did. But as usual, Marsalek was thinking bigger.</p><p>In June 2017, Marsalek arranged to meet an Austrian UN worker named Kilian Kleinschmidt at the popular Munich cafe Käfer-Schänke. Kleinschmidt had decades of experience helping refugees get out of hot spots and, persuaded by Marsalek’s apparent concern for Libya’s wretched of the earth, he agreed to accept 200,000 euros to conduct a study on rebuilding the country. The invoice, Marsalek told Kleinschmidt, was to be sent to the Russian-Libyan Cultural Institute in Moscow. That should have been an immediate red flag. It was also bait. </p><p>At a second meeting, at Marsalek’s Prinzregentenstraße back office, Kleinschmidt was horrified to discover the Wirecard exec’s real intention: to train up a private army of 15,000 to 20,000 Libyan mercenaries who would be put in charge of guarding the country’s southern border and restricting migration flows at gunpoint — the opposite of Kleinschmidt’s life work. Marsalek even giddily recounted how mercenaries could be outfitted with state-of-the-art body cams to record “awesome video material” of them shooting people, which could be streamed live to the internet. Stas had told him all about how Wagner was using this technology already, the only hiccup being that the footage couldn’t be used for marketing purposes since Wagner had a habit of executing all of its POWs. Still, Marsalek and his “lack of empathy” wanted a brand all his own. Kleinschmidt could not escape the meeting fast enough. </p><p>The experienced UN worker was no longer an option, but Petlinsky had an alternative solution. Marsalek should enlist the services of a Russian private security company whose owner, Oleg Krinytsin, was also a Petlinsky acquaintance. Krinytsin’s outfit was RSB Group, one of Russia’s oldest PMCs, with international experience in Somalia, South Africa, Egypt, and Sri Lanka. Among its <a href="https://rsb-group.org/services/marine-operations" rel="noopener noreferrer" target="_blank">stated achievements</a> were counter-terrorism operations and anti-piracy protection for marine vessels, a task that involved the use of non-lethal acoustic sound cannons.</p><p>Marsalek again had wider eyes than did his case officer. He didn’t just want to hire RSB Group; he wanted to buy it outright. Not only would he use it to clean up the cement company, he would have his private army on the ground in a strategic country in Northern Africa. Petlinsky negotiated a purchase price for RSB Group with Krinytsin. The deal was for Krinytsin to remain nominally as the public-facing owner, but to hand over the levers of control to Marsalek and Petlinsky. </p><p>The purchase price was paid in cash, which Marsalek provided to Stas in tranches of several hundred thousand dollars shuttled on his private jet from Munich to Moscow. The formal ownership of the original Russian company called RSB Group remained unchanged; however, its business was de facto moved to two new companies: a newly formed Russian entity with the identical name, OOO RSB Group, and a Cayman Island-registered offshore firm called RSB Group Ltd.</p><p>The Russian company was wholly owned by Kirill Korobeynikov, Petlinsky’s son. The Cayman Island firm, which had a contract with the Libyan Cement Company, was owned 25% by Korobeynikov, and 25% by Victoria Bowman, the Russian wife of Marsalek’s long-standing business partner Joe Bowman. The remaining 50% were owned in proxy by a Swiss lawyer, Richard Cedric Harry Ritter.</p><p>The integration of Marsalek’s personal and professional lives with Petlinsky’s followed much the same trajectory that Marsalek’s development under Zlobina had. By 2017, both of Petlinsky’s sons were fully mobbed up in Wirecard’s off-books and illegal operations. Korobeynikov, <em>The Insider</em> has learned, supervised a group of hackers for Wirecard. Their target list included the short sellers out to prove the company’s stated value was pure fiction, along with McCrum and other journalists at the <em>FT</em> who were looking to report the same. The email address Korobeynikov used for several Russian e-gov services was <a href="https://theins.ru/cdn-cgi/l/email-protection#b3f5e7c1d2dad7f3d4ded2dadf9dd0dcde" rel="noopener noreferrer" target="_blank"><span data-cfemail="a5e3f1d7c4ccc1e5c2c8c4ccc98bc6cac8">[email&nbsp;protected]</span></a>. </p><p>Petlinsky’s other son, Allen Petlinsky, an attorney based in Israel, acted in a legal capacity in mergers and acquisitions on behalf of Wirecard, Marsaleks’s email correspondence further shows.</p><h3>Spies ‘R’ Us</h3><p>All of this took place as Wirecard’s stock market value skyrocketed — and as Marsalek’s willingness to rely on intelligence operatives to help furnish the propellent grew bolder and more reckless.</p><p>One of his hirelings was Rami El Obeidi, the former head of foreign intelligence for Libya's post-Gaddafi transitional government. A lover of Italian haute couture and expensive vintages, El Obeidi helped spy on Wirecard detractors and even concocted a doctored sting operation to suggest that the <em>FT</em> was conniving with short sellers to sink the company — an allegation German regulators took seriously enough that they opened criminal investigations in McCrum and his colleagues.</p><p>Two other accomplices to Marsalek’s cloak-and-dagger sideline were recently retired officials from Austria’s domestic security service, the BVT, officially known as the Federal Office for the Protection of the Constitution and the Fight against Terrorism. (The agency was disbanded in 2021, owing to its inability to stop an Islamist terror attack in Vienna, which killed four and injured 23.) </p><p>Until 2017, Martin Weiss was the head of BVT’s Department II, which was in charge of intelligence gathering and investigations. Weiss had therefore had access to all relevant classified information collected by BVT or given to it by allied foreign services. Marsalek hired Weiss as a “consultant” in 2018, using his extensive network of agents and informants in the West to gather information on anyone Marsalek or Wirecard needed to know about, including journalists in Europe. Weiss brought on one of his former deputies at BVT, Egisto Ott, who was suspended from the service in 2017 on the suspicion that he was transmitting information to Moscow. Ott ran background checks for Marsalek.</p><p>Weiss was arrested and interrogated after Wirecard’s implosion and Marsalek’s disappearance from Europe, after which he was hospitalized for a long period of time. He <a href="https://www.tagesschau.de/investigativ/br-recherche/marsalek-flucht-weiss-wehrt-sich-101.html" rel="noopener noreferrer" target="_blank">currently resides in Dubai</a>. Austrian investigators found that he and Marsalek were part of an “intelligence cell whose capacities and capabilities were used by Russian intelligence services.”</p><p>Ott was detained but released from pre-trial detention in the spring of 2021. In a brief interview with <em>Der Spiegel, </em>which met up with him at his home in Carinthia, Austria, in the Eastern Alps, Ott denied he was any kind of Russian spy. However, text messages examined by <em>The Insider</em> show Ott asking a police officer in Italy for help in understanding why the mistress of Russian oligarch Arkady Rotenberg and her sister were having difficulty entering Russia. The answer came back: they’d both been flagged in the European border surveillance system SIS.</p><p>By this point, Wirecard’s client list included Germany’s Federal Criminal Police Office, giving Marsalek — and the Russian intelligence services — access to sensitive data about German law enforcement’s slate of confidential informants. Marsalek even received a confidential report prepared by the Organization for the Prohibition of Chemical Weapons (OPCW), the international watchdog based in The Hague, about the poisoning of Sergei and Yulia Skripal in Salisbury, England in 2018. Sergei Skripal, a GRU defector to British intelligence, was targeted for liquidation by members of the GRU’s assassination and sabotage team, Unit 29155 and the highly restricted document Marsalek had contained the chemical formula for the toxin used: Novichok, a Russian military-grade nerve agent. Marsalek <a href="https://www.zeit.de/gesellschaft/zeitgeschehen/2021-10/oesterreich-johannes-peterlik-ermittlung-diplomat-suspendierung-dokumente-leak" rel="noopener noreferrer" target="_blank">received</a> the document from Johannes Peterlik, the former Secretary General in the Austrian Foreign Ministry, who then became Austria's ambassador to Indonesia. A video of the document was even recorded on Ott’s cell phone on October 5, 2018. Not that the GRU couldn’t have gotten its hands on this material through more above-board means. Russia is a party to the OPCW and thus would have been privy to the Novichok report, even if it implicated Russian spies in the failed murder attempt.</p><p>Not that Marsalek didn’t earn his keep in other ways. In 2019, he instructed his underlings at Wirecard to compile a database of customers from major international companies, purportedly for use by Germany’s Federal Intelligence Service, or BND, the country’s equivalent to the CIA. Only the BND never commissioned any such project, raising the immediate question as to who did.</p><p>As Petlinsky’s intelligence apparatus grew — thanks in large part to his Austrian asset — Wirecard’s bid to take over the world appeared unstoppable. In 2018, the company joined the DAX, meaning it had become one of the 30 most valuable companies in Germany. At one point, German Chancellor Angela Merkel even brought up Wirecard’s 109 million euro purchase of Allscore, a Beijing-based payments company, in a meeting with Chinese President Xi Jinping. Given that Wirecard wasn’t just a financial services giant, but also a bank — the “daughter,” as CEO Markus Braun awkwardly put it, of the original business — its only serious competitors in Germany were Commerzbank, which it had displaced on the DAX, and Deutsche Bank. In June 2020, as allegations of widespread stock manipulation, book-cooking (if not wholesale book-inventing), and money-laundering continued to bedevil Wirecard’s shareholder confidence, the company nevertheless launched a quixotic plan to buy Deutsche Bank. The scheme was described by Braun as both a reputation-salvaging PR move and a potential means of keeping Wirecard’s top management out of prison, as the company’s funny money could be confusedly mixed in with Deutsche Bank’s legitimate revenue.</p><p>June was when Wirecard had to confess that it couldn’t account for the missing billions reported in its accounts. Braun resigned as CEO and was arrested in 2020 on charges of market manipulation and embezzlement, with gang fraud added to his rap sheet in 2022. Marsalek was placed on leave, but he had no intention of following his boss into a jail cell.</p><p>On June 18, 2020, Marsalek met Weiss at an Italian restaurant in Munich to plan his escape from Germany. The plan was to fly from the Bad Vöslau airfield 20 miles south of Vienna. Marsalek boarded a small private jet, paying the pilots €8,000. To throw his German pursuers off his trail, Marsalek even got sources in the Philippines to falsely suggest his plane had landed there. In reality, as <em>The Insider</em> and Bellingcat pieced together in 2020, Marsalek’s destination was Moscow, where he arrived via Minsk.</p><p>Based on leaked travel data and emails, it can now be revealed that Petlinsky, Marsalek’s GRU handler, was the lynchpin of the exfiltration.</p><h3 id="article_block_4">From Germany to Crimea</h3></div><div><div><svg width="40" height="40" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg"><line x1="9" y1="8" x2="9" y2="16" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="32" y1="8" x2="32" y2="16" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="9" y1="8" x2="17" y2="8" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="24" y1="8" x2="32" y2="8" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="9" y1="31" x2="17" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="24" y1="31" x2="32" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="9" y1="23" x2="9" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="32" y1="23" x2="32" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line></svg><div><figure><div><p><img src="https://api.theins.ru/images/C0mLtIzaeIArDiYUgXCbDZ9W5nbOSBVN0AhByyM2lIM/rs:fit:866:0:0:0/dpr:2/q:80/bG9jYWw6L3B1Ymxp/Yy9zdG9yYWdlL2Nv/bnRlbnRfYmxvY2sv/aW1hZ2UvMjI3NTgv/ZmlsZS1jZDczOGZi/MjQ1ODBkYzIxM2Zi/ZDhkNDBiYTdmYWQz/NS5wbmc.jpg" alt="At top, Jan Marsalek. At bottom, the man whose identity he has assumed in Russia, Orthodox priest Konstanin Baiazov."></p></div></figure></div></div><p><h5>At top, Jan Marsalek. At bottom, the man whose identity he has assumed in Russia, Orthodox priest Konstanin Baiazov.</h5></p></div><div><p>Petlinsky had a plane at Bad Vöslau initially booked in the name of David Iakobashvili, a Georgian billionaire with formerly close ties to the Russian government. (Iakobashvili, who co-owns a Russian wholesale distributor called PI OO with Petlinsky, resides mainly in Monaco.) A copy of Iakobashvili’s passport was supplied to the private jet operator, though Iakobashvili told <em>The Insider</em> he wasn’t aware of his passport being used to ferry a fugitive out of Europe.  </p><p>On the day of the flight from Austria to Belarus, Petlinsky called an Israeli flight logistics company named RS-LS Ltd. What role RS-LS played in the extraction is unclear, but Petlinsky’s communication with the company continued, phone traffic metadata shows. RS-LS Ltd is now a subcontractor of the U.S. Department of Defense.</p><p>Marsalek crossed from Belarus into Russia by car the day after his arrival, and his border crossing was organized by Lev Dengov, a Belarusian-Russian dual national who happened to serve as Putin’s special envoy to Libya. </p><p>On September 5, 2020, Evgeniya Kurochkina, an employee of RSB Group, the Marsalek-owned Russian mercenary outfit, with a history of FSB links including stints at FSB-controlled security companies, accompanied the suspended Wirecard COO to the migration office in Moscow to receive his brand new passport. The name he was told he would use was that of Konstanin Baiazov, the Orthodox priest from Lipetsk. Kurochkina left her own phone number and email address as the contact information for “Baiazov.”</p><p>The following day, September 6, Kurochkina rode in a minibus toward Crimea, the Ukrainian peninsula Russia illegally occupied not long after Marsalek and Zlobina’s first joint trip to Kyiv, according to data connected with Kurochkina’s cell phone. Petlinsky and Marsalek flew to Crimea in parallel in a private jet. Marsalek would have had to use his new passport, issued in Baiazov’s name but bearing his own photograph, when boarding the flight.</p></div><div><div><svg width="40" height="40" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg"><line x1="9" y1="8" x2="9" y2="16" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="32" y1="8" x2="32" y2="16" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="9" y1="8" x2="17" y2="8" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="24" y1="8" x2="32" y2="8" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="9" y1="31" x2="17" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="24" y1="31" x2="32" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="9" y1="23" x2="9" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="32" y1="23" x2="32" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line></svg><div><figure><div><p><img src="https://api.theins.ru/images/HRJDDGLYgPfyQS8wltOOMljSXTTQLVMaxLcc-MQqwn0/rs:fill:433:562:0:0/dpr:2/q:80/bG9jYWw6L3B1Ymxp/Yy9zdG9yYWdlL2Nv/bnRlbnRfYmxvY2sv/aW1hZ2UvMjI3NDgv/ZmlsZS0zNzVkNTA1/ODRiYzAwNGFmNjMw/YzE5ZTA4ZGI4Yzgz/Ni5qcGVn.jpg" alt="Jan Marsalek's Russian passport."></p></div></figure></div></div><p><h5>Jan Marsalek's Russian passport.</h5></p></div><div><p>By nightfall on September 8, Kurochkina’s phone logged in at Sevastopol, Crimea, the headquarters of Russia’s Black Sea Fleet. The following morning, she ordered taxis and toured hotels along the southern coast of the peninsula. Petlinsky, travel data proves, chartered a private jet from Simferopol, the provincial capital of Crimea, to Moscow on September 12 — only Petlinsky wasn’t on the plane. He couldn’t get on the chartered jet because he could not bring his gun on board. He had to reschedule for a flight the following morning, using a more understanding charter company.</p><p>Petlinsky told <em>Der Spiegel</em> that he was indeed in Crimea around that time but had nothing to do with Marsalek’s escape. </p><p>He also said he had not communicated directly with Marsalek since the early days of his move to Russia.</p><p>This claim is belied by new evidence The Insider has obtained -- namely, the results of a blood test. </p><p>In January 2021, a mysterious man by the name of Alexandr Schmidt summoned a nurse from the Russian lab franchise Gemotest to a posh penthouse in a luxury Moscow high-rise. Schmidt asked to have his blood drawn and tested. The apartment in fact belonged to Petlinsky, who now goes by his new legal name, “Boris Grin.” “Alexandr Schmidt” does not exist. It is an alias used by Marsalek to travel on a forged French passport, intelligence officials from two European countries told The Insider. The passport number given by “Schmidt” to the nurse -- a requirement under Russian law -- belongs to Ekaterina Kulikova, a long-time aide and friend of Petlinsky’s.</p><p>Just a month later, on February 28, 2021, another ghost had his blood tested at this same apartment. This time, two of the measurements taken were for HIV and Syphilis. The testee this time went by the name of “Vitaly Malkin” and he was approximately the same age as Marsalek. Malkin, like Baiazov, is a small town priest from the Russian town of Vladimir. Just before the syphilis screening, Malkin announced that his passport had been stolen and arranged to receive a new one. It was the old, lost passport that “Vitaly Markin” used for the blood test. Marsalek used the passport a second time, a year later, in February 2022. A nurse visited him at the same posh apartment in Moscow owned by Petlinsky.</p><p>The real Vitaly Malkin told The Insider that he did not know Petlinsky and certainly had never tested himself for syphilis. The fake Malkin provided enough blood measurements to allow The Insider to compare certain metrics to those of “Alexandr Schmidt.” The probability that the two men are the same is overwhelming. Vitaliy Malkin very likely another man of the cloth whose identity Marsalek has usurped with the help of the Russian security services.</p><p>Zlobina would not comment for this story. Father Baiazov – the real one – cryptically said that he couldn’t answer any questions about why his passport now belonged to another man, one on Interpol’s most wanted list. “Why do you refuse to understand that [I cannot answer this question]?” he told <em>Der Spiegel.</em></p></div><div><div><svg width="40" height="40" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg"><line x1="9" y1="8" x2="9" y2="16" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="32" y1="8" x2="32" y2="16" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="9" y1="8" x2="17" y2="8" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="24" y1="8" x2="32" y2="8" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="9" y1="31" x2="17" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="24" y1="31" x2="32" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="9" y1="23" x2="9" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line><line x1="32" y1="23" x2="32" y2="31" stroke="white" stroke-width="2" stroke-linecap="round"></line></svg><div><figure><div><p><img src="https://api.theins.ru/images/bzlRofo4Aet53WbXUpnY3aOZ86Ljjb4NBpvIBc5g4rA/rs:fit:866:0:0:0/dpr:2/q:80/bG9jYWw6L3B1Ymxp/Yy9zdG9yYWdlL2Nv/bnRlbnRfYmxvY2sv/aW1hZ2UvMjI3NTkv/ZmlsZS1hNmEwOGU1/OWRlOGQ1ODY0OWYy/NjAzMTg5MzQ2ZjJm/NS5qcGVn.jpg" alt="Orthodox priest Konstantin Baiazov."></p></div></figure></div></div><p><h5>Orthodox priest Konstantin Baiazov.</h5></p></div><div><h3 id="article_block_5">The Bulgarians</h3><p>Between August 30, 2020 and February 8, 2023, Marsalek, the Crown Prosecution Service found, “conspired... to obtain, collect, record, publish or communicate documents or information which was calculated to be, or might be intended to be, directly or indirectly useful to an enemy for a purpose prejudicial to the safety and interest of the state.” The defendants in this case are a ring of Bulgarian nationals, five of whom were arrested in London in February 2023 on allegations of espionage. Leaving aside the central casting aspects of some of their biographies — one is an amateur mixed-martial-arts fighter nicknamed “the Destroyer” — they certainly behaved like spies. MI5, Britain’s equivalent of the FBI, had been surveilling the Bulgarians’ activities for a while, gathering passport data, evidence of international travel, and 80,000 chat messages, which included tasks assigned to them by Marsalek via his preferred mode of communication, the Telegram messenger app. </p><p>His years working on the Atlas Mine pyramid scheme were evidently not wasted, as Marsalek was compensating his agent network in cryptocurrency, along with cash delivered via a courier. Also in the possession of these Bulgarians were forged documents used for their legend, or cover stories: press badges and apparel with Discovery Channel and National Geographic logos emblazoned on them. After years of spying on and intimidating journalists, Marsalek had decided to use pretend journalists as snoops in the UK. One of them, the presumed ringleader of the network, was Orlin Roussev, a 46 year-old surveillance expert who had known Marsalek since Wirecard was flush. A sixth Marsalek agent, Tihomir Ivanov Ivanchev, 36, listed in London as an interior decorator, was arrested on February 28, just as this story was being finalized. He had spied on targets for the Russian government, under Marsalek’s direct instruction, in Montenegro and in Austria.</p><p>Around the time the spy ring was being rounded up in the UK, Christo Grozev, the Bulgarian-born head of investigations at <em>The Insider</em> and <em>Der Spiegel</em> journalist, and one of the bylines on this story, was informed by the law enforcement while on a visit to New York City that he could not safely return home to Vienna, as his life was in danger. Marsalek, it turned out, had requested Grozev’s home address from Weiss, the former Austrian spy, in December 2020, the day after Bellingcat, The Insider and Der Spiegel had published their joint investigation into the poisoning of Russian opposition leader Alexei Navalny. Weiss had sent an encrypted message to Egisto Ott: “Could we make a query about a Mr. Christo Grozev in Austria?” it read, ominously adding that Grozev was working “against our case.” Grozev, at both Bellingcat and <em>The Insider</em>,<em> </em>has been the lead sleuth in unmasking GRU and FSB assassination plots, from the poisoning of the Skirpals in Salisbury with the military-grade nerve agent Novichok, to the poisoning of Alexey Navalny with a similar substance.</p><p>Ott told <em>Der Spiegel</em> that he complied with this request from Weiss. «I only went to the registration office and paid 3.40 euros for the information about where [Grozev] lives.” Ott further stated that he took photographs of Grozev’s apartment in Vienna. Asked why Weiss — and behind him, Jan Marsalek and Stanislav Petlinsky — wanted the home address of a prominent investigative journalist, Ott replied that he gave it no thought. “I have always fought the Russian intelligence service in my career,” Ott told <em>Der Spiegel</em> matter-of-factly.</p><p>Grozev now resides permanently in New York.<br></p><p><em>– With additional reporting by Kato Kopaleishvili and Kate Manchester</em><br></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Where I'm at on the whole CSS-Tricks thing (248 pts)]]></title>
            <link>https://chriscoyier.net/2024/02/28/where-im-at-on-the-whole-css-tricks-thing/</link>
            <guid>39560705</guid>
            <pubDate>Fri, 01 Mar 2024 11:15:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chriscoyier.net/2024/02/28/where-im-at-on-the-whole-css-tricks-thing/">https://chriscoyier.net/2024/02/28/where-im-at-on-the-whole-css-tricks-thing/</a>, See on <a href="https://news.ycombinator.com/item?id=39560705">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>It was March 2022 when I sold CSS-Tricks to DigitalOcean. So it’s been just about 2 years now. </p>
<p>This was me and my wife’s thinking: </p>
<ul>
<li>The negotiated sale price was fair.</li>
<li>They are a big company (public!) with tons of resources, and their clear stated strategy was to invest in content and community, because that’s where the top of the funnel is, and it’s good for business. They didn’t just talk this way, they were obviously <em>investing</em> in content and community. There is a chance CSS-Tricks becomes <em>better</em>.</li>
<li>They were already decently well known for good content in DevOps and Back End, but were missing solid Front-End content. Filling this gap makes sense.</li>
<li>They would rip all the ads off the site. There would be only one “ad”: use DigitalOcean. I’m no advertising hater, it’s always been good to me, but the thought of CSS-Tricks as a clean ad-free site was appealing.</li>
<li>They would keep on Geoff, the lead editor, if he wanted it. He did and they did.</li>
<li> I was <em>way way</em> too busy trying to run CSS-Tricks and co-run CodePen and it was hard on me. </li>
</ul>
<p>After the sale, things seemed kinda fine for a bit, and that was encouraging. It was cool seeing new voices publishing new work I had nothing to do with. Then started to limp, using up the momentum that it had. </p>
<p>A year later they <a href="https://geoffgraham.me/goodbye-css-tricks/">fired Geoff</a> along with everyone else working on content and community. That was the real torpedo.</p>
<p>It seems DigitalOcean got excited when the whole industry started doing huge layoffs, they followed suit and slurped up the profits. The necessary directional change was: screw content and community. A month after that, the last article was published on CSS-Tricks, an overview of Passkeys, which will now apparently be on the homepage forever, a <em>very</em> strange bit of content to emblazon the tombstone of the site. They also added a cookie button that looks like a 4th grader designed it?? And started publishing every blog post as a guide???</p>
<p> How do I feel about all that? Well I’m not <em>stoked</em>, but I’m an adult I knew the risks. I sold the site. They now control it. They can do whatever they want with it. They could replace the entire site with an <code>&lt;h1&gt;</code> tag that says <strong>Chris Coyier smells like donkeys</strong> and that would be their right.</p>
<p>I’ve heard from plenty of people who are pissed. Some are pissed at me. Sellout, yadda yadda. But I’m actually fairly pleased that the site is still online, relatively untouched, and with everybody’s bylines, including my own, intact. That’s a better outcome than scotch.io, purchased from Chris Sev, which was neutered and ultimately turned off. That’s a much more inglorious ending that I hope never happens to CSS-Tricks.</p>
<p>Hopefully that doesn’t happen, although during my 3-month consulting period I know they were very interested in porting the content to their own internal SSG system. As someone who has built a lot of SSG-powered sites and a lot of WordPress-sites, all I can say is CSS-Tricks is WordPress-y<em>-as-hell,</em> and I cannot possibly imagine a conversion that maintains any level of quality as being worth the effort. </p>
<p>A lot more people are pissed at DigitalOcean. People saying they’ll never use them again, and generally upset they’d take such a useful asset and do nothing with it. A void in the industry that doesn’t sit right.</p>
<p>Does any of this negative sentiment actually affect DigitalOcean meaningfully? I have no clue. It can’t <em>help</em>, but I’m sure if it was <em>that</em> big of a deal they would prioritize fixing it somehow. It seems more likely it’s a <em>oh well you win some you lose some shrug it off situation</em>. It’s almost certainly not acting as that strong top-of-funnel player they originally were hoping for it. </p>
<hr>
<p>I bet you could probably guess all that, or piece it together from things publicly said. </p>
<p>What you probably don’t know is that I tried to get it back. </p>
<p>I got an email from a fella a while back who is now a VP of Content &amp; Community at DigitalOcean who came over from the Cloudways acquisition. I think “ownership” of CSS-Tricks kinda fell is his lap after some internal shifts. Unlike his predecessors, he didn’t have any hangups about just talking directly to me. What he originally wanted was just to learn what it’s going to take to get spun back up and producing again. A “return on investment” is what he was after, understandably. I was as frank with him as I am with anyone: It’s gonna take a lot. They would need a new lead editor, and you might be able to see how people might be squeamish about that role with the last one publicly axed not long ago. <em>Maybe</em> that person knows WordPress development pretty well? If not, ideally, you have someone know that knows WordPress pretty well, because the site uses <a href="https://css-tricks.com/css-tricks-is-a-poster-child-wordpress-site/">everything</a>. And maybe that person knows how to wrangle up really good front-end specific writers? If you find that magical person, that’s a developer, writer, community builder, and site-running editor, it’s going to be expensive. More likely you gotta build a team again, and it’s going to take them a while to get things going, so your investment gets deeper and deeper, while the return remains unclear.</p>
<p>This got me thinking. </p>
<p>Maybe a little braggadocious here, <em>butttt</em> I’m basically the perfect person for the job. Let’s just say the most perfect person on Earth for the job lolz.</p>
<p>But I’m not even sure I’d want to do it again, and I have no idea if they would even want me to. But I definitely don’t wanna do free consulting work on it. </p>
<p>So I took my big swing.</p>
<blockquote>
<p>Here’s my best (and wildest) idea.&nbsp;</p>
<p>I run CSS-Tricks again myself. CSS-Tricks is big and complicated. Anybody walking in the door alone is going to have a serious learning curve just in getting comfortable operating the basics. I already know every inch of it.&nbsp;</p>
<p>I get people reading again. I get people writing again. I get people excited again. I erase any bad mojo against DigitalOcean, fix that brand damage. Get people saying they&nbsp;<em>want</em>&nbsp;to use DigitalOcean instead of saying they never will again.&nbsp;(e.g.&nbsp;<a href="https://twitter.com/AdamRackis/status/1691928618912387283">1</a>,&nbsp;<a href="https://twitter.com/stolinski/status/1691942771035168887">2</a>,&nbsp;<a href="https://twitter.com/awkroot/status/1692046926211150153">3</a>)</p>
<p>Then we do the most valuable possible thing for DigitalOcean: get content on there that helps people know about and do things on DigitalOcean. There are some big wins there. Astro is big right now in front-end, why isn’t DigitalOcean on&nbsp;<a href="https://docs.astro.build/en/guides/deploy/">this list</a>? Let’s get that article written and linked up.</p>
<p>We can make a special section of the site that is just DigitalOcean content, making it easy to browse and find stuff.&nbsp;</p>
<p>Then we do the second most valuable thing we can do: move the hosting to DigitalOcean and have it be a living, breathing endorsement of DO being a great place to host a WordPress website.&nbsp;</p>
<p>Now we’re back in action.</p>
<p>Why would I do that?</p>
<p>You transfer ownership of CSS-Tricks back to me.&nbsp;</p>
<p>Why would&nbsp;<em>you</em>&nbsp;do that?</p>
<ul>
<li>You’re trying to get to break even on it. This means you aren’t spending any&nbsp;<em>more</em>&nbsp;money and time. You’re now just extracting marketing, branding, and conversion value out of money already spent.</li>
<li>You don’t have to spend any more time on this, personally or institutionally. Any other internal costs are gone.</li>
<li>The community will love it.</li>
</ul>
<p>The trick is in the details. We’d get to an agreement on what has to happen for it to work. For example, no other web host can be advertised on the site for X time, etc.&nbsp;</p>
</blockquote>
<p>I’d call that a big swing, anyway. <em>I’ll just take it back please and thank you.</em> But I feel like I made the case OK that it’s not completely crazy.</p>
<p>Crickets for a while.</p>
<p>A few back and forth emails like <em>“still thinking about this…</em>” later, and the conclusion is that the fella basically doesn’t have the “conviction to push it within the halls at DO”. </p>
<p>Understandable, really. I wouldn’t want to be handed a huge golden nugget by my boss and then ask for a meeting and be like “I think we should give it back to the leprechaun.”</p>
<p>When I pitched that, I wasn’t even 100% sure I wanted it, mainly for stress reasons. But I’m sure I could have figured out a way to run a more minimal ship with reduced stress and the site would be in a much more pleasant place. </p>
<p>Anyway, if you want to know some basic information about Passkeys I know a site you can check out.</p>
 </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Streaming HTML out of order without JavaScript (102 pts)]]></title>
            <link>https://lamplightdev.com/blog/2024/01/10/streaming-html-out-of-order-without-javascript/</link>
            <guid>39560180</guid>
            <pubDate>Fri, 01 Mar 2024 09:37:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lamplightdev.com/blog/2024/01/10/streaming-html-out-of-order-without-javascript/">https://lamplightdev.com/blog/2024/01/10/streaming-html-out-of-order-without-javascript/</a>, See on <a href="https://news.ycombinator.com/item?id=39560180">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>Let's start with a demo: <strong><a href="https://ooo.lamplightdev.workers.dev/">https://ooo.lamplightdev.workers.dev</a></strong>:</p><p>This is a simple page that renders a list of 10 items. Try it with and <strong>without JavaScript enabled</strong> in your browser. There's a few things to notice:</p><ol><li><p><strong>The 'app shell' renders first</strong> - you see the header and the footer, but there's a loading placeholder where the list of items will be rendered.</p></li><li><p>After a second the <strong>loading placeholder is replaced</strong> with the list of items - but with each item itself having a loading placeholder.</p></li><li><p><strong>The content of the items then renders out of order</strong>, replacing the loading placeholders - you see item 5 first, then the other items as they are generated.</p></li><li><p>If you look at the page source you'll see that the <strong>html is in the order it was sent - not the order it was rendered in</strong></p></li><li><p>The page makes use of <strong>Shadow DOM</strong> without Custom Elements.</p></li></ol><p>Pretty nice, right? It may be a contrived example but it's an interesting technique that enables things that have not been possible before without JavaScript.</p><p>Have a look at the <strong><a href="https://github.com/lamplightdev/ooo">code for this demo</a></strong>, or read on for an explanation of how it works.</p><hr><h2>Background</h2><h3>Streaming HTML</h3><p>The <strong>concept of streaming HTML</strong> - sending HTML from a web server to a browser in chunks as it is generated - is <strong>nothing new</strong>. It seemed to take a back seat at the beginning of the age of modern front-end frameworks and Single Page Applications - where the entire page was generated in the browser - but as the pendulum swings back towards server-side rendering with full stack frameworks, <strong>streaming responses are becoming popular again</strong>.</p><p>The <strong>advantages of streaming HTML</strong> over waiting for the entire response to be generated before sending it to the browser are clear - you can <strong>render something immediately</strong> to indicate to the user that something is happening, and you can start downloading assets like CSS and JavaScript earlier, while you <strong>wait for the more time consuming parts of the response</strong> to be generated.</p><p>What's been lacking up to this point is a way to <strong>stream HTML out of order</strong> - that is to stream the HTML in chunks as it's generated without worrying about the order in which the chunks are sent to the browser - and still have the browser render the chunks of HTML in the correct order as in the demo above.</p><p>Modern full stack frameworks enable this functionality by using a variety of clever techniques, all of which require buy-in to the particular framework and a <strong>hefty chunk of JavaScript</strong>. That might be fine for your use case, but what if we could <strong>achieve the same thing without any JavaScript or framework?</strong> <em>Well now you can</em>.</p><h3>Shadow DOM</h3><p><strong><a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_components/Using_shadow_DOM">Shadow DOM</a></strong> is a way to render a piece of DOM in isolation from the rest of the page. Whilst often associated with Custom Elements, Shadow DOM <strong>can be used with any HTML tag</strong>, such as the humble <code>&lt;div&gt;</code> tag.</p><p>It also has the concept of <strong>slots</strong> - tags that act as portals that you can render HTML into from elsewhere within the parent tag by specifying a <code>slot</code> attribute on the tag you want to render. Here the shadow root is attached to the outer <code>&lt;div&gt;</code> tag, and the inner <code>&lt;div&gt;</code> tag is rendered into the slot in that shadow root:</p><pre><code><span><span><span>&lt;</span>div</span><span>&gt;</span></span><br>  #shadowroot<br>    <span><span><span>&lt;</span>header</span><span>&gt;</span></span>Header<span><span><span>&lt;/</span>header</span><span>&gt;</span></span><br>    <span><span><span>&lt;</span>main</span><span>&gt;</span></span><br>      <span><span><span>&lt;</span>slot</span> <span>name</span><span><span>=</span><span>"</span>content<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>slot</span><span>&gt;</span></span><br>    <span><span><span>&lt;/</span>main</span><span>&gt;</span></span><br>    <span><span><span>&lt;</span>footer</span><span>&gt;</span></span>Footer<span><span><span>&lt;/</span>footer</span><span>&gt;</span></span><p>  <span><span><span>&lt;</span>div</span> <span>slot</span><span><span>=</span><span>"</span>content<span>"</span></span><span>&gt;</span></span><br>    This div will be rendered inside the slot above. Magic!<br>  <span><span><span>&lt;/</span>div</span><span>&gt;</span></span><br><span><span><span>&lt;/</span>div</span><span>&gt;</span></span></p></code></pre><hr><h2>Requirements</h2><p>So how do you use Shadow DOM to stream HTML out of order? There's a few things you need:</p><ol><li>A <strong>http server that supports streaming responses</strong>. You're in luck here, there is pretty much universal support for this across all languages. I've opted for <strong><a href="https://hono.dev/">Hono</a></strong> as it's a lightweight server, built on web standards, that runs on node as well as a wide variety of edge platforms. It's worth noting though that there's no dependency on a JavaScript backend - the same thing can be achieved on PHP, Java, Go, etc.</li></ol><ol><li><p>A <strong>templating language that supports streaming</strong>. In theory you don't need a templating language - you could handcraft the HTML and manually manage the streaming - but that's a lot of work. In the JavaScript world, there aren't a lot of standalone templating languages that support streaming, but a recent project called <strong><a href="https://github.com/thepassle/swtl">SWTL</a></strong> does. SWTL was created to be used in Service Workers, but since we're using web standards all the way down, it can be used on the server too. The other great thing about SWTL is that you can chuck pretty much anything at it - async functions, generators, arrays, responses - and it will handle it all.</p></li><li><p><strong>Declarative Shadow DOM</strong> - Until recently custom Shadow DOM was a browser only technology - you could only create Shadow DOM in the browser using JavaScript - but now, thanks to <strong><a href="https://developer.chrome.com/docs/css-ui/declarative-shadow-dom">Declarative Shadow DOM</a></strong> (DSD), you can create Shadow DOM on the server and the browser will render it without JavaScript by using a new <code>shadowrootmode</code> attribute on a <code>&lt;template&gt;</code> tag. The shadow root is then automatically attached to the containing element:</p></li></ol><pre><code><span><span><span>&lt;</span>div</span><span>&gt;</span></span><br>  <span><span><span>&lt;</span>template</span> <span>shadowrootmode</span><span><span>=</span><span>"</span>open<span>"</span></span><span>&gt;</span></span><br>    <span><span><span>&lt;</span>header</span><span>&gt;</span></span>Header<span><span><span>&lt;/</span>header</span><span>&gt;</span></span><br>    <span><span><span>&lt;</span>main</span><span>&gt;</span></span><br>      <span><span><span>&lt;</span>slot</span> <span>name</span><span><span>=</span><span>"</span>content<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>slot</span><span>&gt;</span></span><br>    <span><span><span>&lt;/</span>main</span><span>&gt;</span></span><br>    <span><span><span>&lt;</span>footer</span><span>&gt;</span></span>Footer<span><span><span>&lt;/</span>footer</span><span>&gt;</span></span><br>  <span><span><span>&lt;/</span>template</span><span>&gt;</span></span><p>  <span><span><span>&lt;</span>div</span> <span>slot</span><span><span>=</span><span>"</span>content<span>"</span></span><span>&gt;</span></span><br>    This div will be rendered inside the slot above<br>    without JavaScript. More magic!<br>  <span><span><span>&lt;/</span>div</span><span>&gt;</span></span><br><span><span><span>&lt;/</span>div</span><span>&gt;</span></span></p></code></pre><hr><h2>Piecing it together</h2><p>So how was that initial demo created? Let's break it down in a simplified code example:</p><pre><code><span>import</span> <span>{</span> Hono <span>}</span> <span>from</span> <span>'hono'</span><span>;</span><br><span>import</span> <span>{</span> stream <span>}</span> <span>from</span> <span>'hono/streaming'</span><span>;</span><p><span>import</span> <span>{</span> render<span>,</span> html <span>}</span> <span>from</span> <span>'swtl'</span><span>;</span></p><p><span>import</span> <span>{</span><br>  delayed<span>,</span><br>  createReadableStreamFromAsyncGenerator<br><span>}</span> <span>from</span> <span>'./utils.js'</span><span>;</span></p><p><span>const</span> app <span>=</span> <span>new</span> <span>Hono</span><span>(</span><span>)</span><span>;</span></p><p>app<span>.</span><span>get</span><span>(</span><span>'/'</span><span>,</span> <span>(</span><span>ctx</span><span>)</span> <span>=&gt;</span> <span>{</span><br>  <span>/*<br>    The `html` tagged template literal provided by SWTL<br>    allows async functions to be passed in. Here the<br>    slot content is wrapped in a function that<br>    introduces an artificial delay.<br>  */</span><br>  <span>const</span> <span>template</span> <span>=</span> <span>(</span><span><span>{</span> name <span>}</span></span><span>)</span> <span>=&gt;</span> html<span><span>`</span><span><br>    &lt;html&gt;<br>      &lt;head&gt;<br>        &lt;title&gt;Streaming example&gt;<br>      &lt;/head&gt;<br>      &lt;body&gt;<br>        &lt;div&gt;<br>          &lt;template shadowrootmode="open"&gt;<br>            &lt;header&gt;Header&lt;/header&gt;<br>            &lt;main&gt;<br>              &lt;slot name="content"&gt;&lt;/slot&gt;<br>            &lt;/main&gt;<br>            &lt;footer&gt;Footer&lt;/footer&gt;<br>          &lt;/template&gt;<p>            &lt;!--<br>              The html above gets sent first to the browser<br>            --&gt;</p><p>            &lt;!--<br>              An artificial delay is added the slot content<br>              to simulate a slow response from the server:<br>            --&gt;</p></span><span><span>${</span><span>delayed</span><span>(</span><span>1000</span><span>,</span> html<span><span>`</span><span><br>              &lt;p slot="content"&gt;<br>                Hi </span><span><span>${</span>name<span>}</span></span><span>!<br>              &lt;/p&gt;<br>            </span><span>`</span></span><span>)</span><span>}</span></span><span><p>            &lt;!--<br>              the remaining html below is sent to the browser once<br>              the delayed content has been sent<br>            --&gt;<br>          &lt;/div&gt;<br>        &lt;/div&gt;<br>      &lt;/body&gt;<br>    &lt;/html&gt;</p></span><span>`</span></span><span>;</span></p><p>  <span>return</span> <span>stream</span><span>(</span>ctx<span>,</span> <span>async</span> <span>(</span><span>stream</span><span>)</span> <span>=&gt;</span> <span>{</span><br>    ctx<span>.</span>res<span>.</span>headers<span>.</span><span>set</span><span>(</span><span>'Content-Type'</span><span>,</span> <span>'text/html'</span><span>)</span><span>;</span></p><p>    <span>/*<br>      Finally the `render` method converts the output to an<br>      async generator which can then be converted to an encoded<br>      stream and piped to the response as it is generated.<br>    */</span><br>    <span>await</span> stream<span>.</span><span>pipe</span><span>(</span><br>      <span>createReadableStreamFromAsyncGenerator</span><span>(</span><br>        <span>render</span><span>(</span><br>          <span>template</span><span>(</span><span>{</span> name<span>:</span> <span>'Ada'</span> <span>}</span><span>)</span><br>        <span>)</span><br>      <span>)</span><br>    <span>)</span><span>;</span><br>  <span>}</span><span>)</span><span>;</span><br><span>}</span><span>)</span><span>;</span></p><p><span>export</span> <span>default</span> app<span>;</span></p></code></pre><p>And that's all there is to it! Browse the <strong><a href="https://github.com/lamplightdev/ooo">code for this demo</a></strong> and have a play with it yourself. I'd love to hear your thoughts on this technique - and any novel use cases you can think of for it - so please <strong><a href="https://lamplightdev.com/contact/">get in touch</a></strong>. Until next time 👋.</p><p><em>With thanks to <a href="https://twitter.com/passle_">@passle_</a>, author of SWTL, for proofreading and feedback on this article.</em></p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Company forgets why they exist after 11-week migration to Kubernetes (262 pts)]]></title>
            <link>https://www.theolognion.com/p/company-forgets-why-they-exist-after-11-week-migration-to-kubernetes</link>
            <guid>39560033</guid>
            <pubDate>Fri, 01 Mar 2024 09:08:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theolognion.com/p/company-forgets-why-they-exist-after-11-week-migration-to-kubernetes">https://www.theolognion.com/p/company-forgets-why-they-exist-after-11-week-migration-to-kubernetes</a>, See on <a href="https://news.ycombinator.com/item?id=39560033">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_120,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2dbb5d03-ad09-408b-8ccd-c63d3c1a8521_1000x1000.jpeg"><img src="https://substackcdn.com/image/fetch/w_120,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2dbb5d03-ad09-408b-8ccd-c63d3c1a8521_1000x1000.jpeg" sizes="100vw" alt="" loading="lazy" width="120"></picture></div><div><h4>The Olognion</h4><p>www.theolognion.com</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CACM Is Now Open Access (212 pts)]]></title>
            <link>https://cacm.acm.org/news/cacm-is-now-open-access-2/</link>
            <guid>39559411</guid>
            <pubDate>Fri, 01 Mar 2024 07:19:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cacm.acm.org/news/cacm-is-now-open-access-2/">https://cacm.acm.org/news/cacm-is-now-open-access-2/</a>, See on <a href="https://news.ycombinator.com/item?id=39559411">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
			<main id="main">

				
<article id="post-751671">

			
<header>
	<div>
		
		
		
					<p>More than six decades of <em>CACM</em>’s renowned research articles, seminal papers, technical reports, commentaries, real-world practice, and news articles are now open to everyone, regardless of whether they are members of ACM or subscribe to the ACM Digital Library.</p>
		
		

					<figure>
									<p><img width="1024" height="576" src="https://cacm.acm.org/wp-content/uploads/2023/05/091523.Opinion.CACM-Is-Open.jpg" alt="Communications of the ACM logo" loading="eager" decoding="async" srcset="https://cacm.acm.org/wp-content/uploads/2023/05/091523.Opinion.CACM-Is-Open.jpg 2400w, https://cacm.acm.org/wp-content/uploads/2023/05/091523.Opinion.CACM-Is-Open.jpg?resize=300,169 300w, https://cacm.acm.org/wp-content/uploads/2023/05/091523.Opinion.CACM-Is-Open.jpg?resize=768,432 768w, https://cacm.acm.org/wp-content/uploads/2023/05/091523.Opinion.CACM-Is-Open.jpg?resize=1024,576 1024w, https://cacm.acm.org/wp-content/uploads/2023/05/091523.Opinion.CACM-Is-Open.jpg?resize=1536,864 1536w, https://cacm.acm.org/wp-content/uploads/2023/05/091523.Opinion.CACM-Is-Open.jpg?resize=2048,1152 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></p>												</figure>
		
		
	</div>
</header>


		<div>
		<p>We are excited to announce that <em>Communications of the ACM</em> (<em>CACM</em>) is now a fully <strong>Open Access publication</strong>. This means that more than six decades of <em>CACM</em>’s renowned research articles, seminal papers, technical reports, commentaries, real-world practice, and news articles are now open to everyone, regardless of whether they are members of ACM or subscribe to the ACM Digital Library.</p>

<p>But why this change, and why now? For almost 65 years, the contents of <em>CACM</em> have been exclusively accessible to ACM members and individuals affiliated with institutions that subscribe to either <em>CACM</em> or the ACM Digital Library. In 2020, ACM announced its intention to transition to a fully Open Access publisher within a roughly five-year timeframe (January 2026) under a financially sustainable model. The transition is going well: By the end of 2023, approximately 40% of the ~26,000 articles ACM publishes annually were being published Open Access utilizing the <a href="https://libraries.acm.org/subscriptions-access/acmopen#model">ACM Open</a> model. As ACM has progressed toward this goal, it has increasingly opened large parts of the ACM Digital Library, including more than 100,000 articles published between 1951–2000. It is ACM’s plan to open its entire archive of over 600,000 articles when the transition to full Open Access is complete.</p>

<p>As part of this transition and to coincide with the launch of <em>CACM</em>‘s new website, all <em>CACM</em> articles, past, present, and future, will be published in front of the subscription paywall.&nbsp;</p>

<p>By opening <em>CACM</em> to the world, ACM hopes to increase engagement with the broader computer science community and encourage non-members to discover its rich resources and the benefits of joining the largest professional computer science organization. This move will also benefit CACM authors by expanding their readership to a larger and more diverse audience. Of course, the community’s continued support of ACM through membership and the ACM Open model is essential to keeping ACM and <em>CACM</em> strong, so it is critical that current members continue their membership and authors encourage their institutions to join the ACM Open model to keep this effort sustainable.&nbsp;</p>

<p>We invite everyone to explore CACM’s vast collection of articles, columns, and news items on the new website. Thank you for your interest in ACM and <em>CACM</em>!</p>

</div>
		
		<div>
			<div>
			<p>
				Submit an Article to CACM			</p>
			<p>
				CACM welcomes unsolicited <a href="https://cacm.acm.org/submissions">submissions</a> on topics of relevance and value to the computing community.			</p>
		</div>

<div>
		<p>
			You Just Read		</p>
		<h4>
			CACM Is Now Open Access		</h4>
			</div>
		</div>
		<div>
		<h3>Related Reading</h3>
		<!-- Related reading post list -->
		<ul>
							<li>
					<p>
						<a href="https://cacm.acm.org/section/opinion/">Opinion</a>					</p>
					<p>
						<a href="https://cacm.acm.org/opinion/dja-vu-all-over-again/">
							Déja Vu All Over Again						</a>
					</p>
					<p>
						<a href="https://cacm.acm.org/category/computing-applications/">Computing Applications</a>					</p>
				</li>
							<li>
					<p>
						<a href="https://cacm.acm.org/section/blogcacm/">BLOG@CACM</a>					</p>
					<p>
						<a href="https://cacm.acm.org/blogcacm/the-chaos-of-the-internet-as-an-external-brain-and-more/">
							The Chaos of the Internet as an External Brain; and More						</a>
					</p>
					<p>
						<a href="https://cacm.acm.org/category/artificial-intelligence-machine-learning/">Artificial Intelligence and Machine Learning</a>					</p>
				</li>
							<li>
					<p>
						<a href="https://cacm.acm.org/section/opinion/">Opinion</a>					</p>
					<p>
						<a href="https://cacm.acm.org/opinion/looking-for-control/">
							Looking For Control						</a>
					</p>
					<p>
						<a href="https://cacm.acm.org/category/computing-applications/">Computing Applications</a>					</p>
				</li>
							<li>
					<p>
						<a href="https://cacm.acm.org/section/opinion/">Opinion</a>					</p>
					<p>
						<a href="https://cacm.acm.org/opinion/let-us-together-make-cacm-exciting/">
							Let Us – Together – Make CACM Exciting						</a>
					</p>
					<p>
						<a href="https://cacm.acm.org/category/computing-applications/">Computing Applications</a>					</p>
				</li>
					</ul>
	</div>
		
<div>
		<h3>
			Join the Discussion (0)		</h3>
		
<div id="article-discussion">
		<h4>Become a Member or Sign In to Post a Comment</h4>
		
	</div>
		
<!-- #comments -->
	</div>

		

		
<div data-component="ctaMembership">
	
		<div>
				<h3>
					Shape the Future of Computing				</h3>
									<p>
						ACM encourages its members to take a direct hand in shaping the future of the association. There are more ways than ever to get involved.					</p>
													<p><a href="https://www.acm.org/about-acm/get-involved">
						Get Involved											</a>
							</p></div>

		
		<div>
				<h3>
					Communications of the ACM (CACM) is now a fully Open Access publication.				</h3>
									<p>
						By opening CACM to the world, we hope to increase engagement among the broader computer science community and encourage non-members to discover the rich resources ACM has to offer.					</p>
													<p><a href="https://cacm.acm.org/news/cacm-is-becoming-open-access">
						Learn More											</a>
							</p></div>

		</div>

	
</article><!-- #post-## -->

			</main>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You can't make an open source HDMI 2.1 driver (237 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2024/02/hdmi-forum-to-amd-no-you-cant-make-an-open-source-hdmi-2-1-driver/</link>
            <guid>39559318</guid>
            <pubDate>Fri, 01 Mar 2024 07:02:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2024/02/hdmi-forum-to-amd-no-you-cant-make-an-open-source-hdmi-2-1-driver/">https://arstechnica.com/gadgets/2024/02/hdmi-forum-to-amd-no-you-cant-make-an-open-source-hdmi-2-1-driver/</a>, See on <a href="https://news.ycombinator.com/item?id=39559318">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      The cord cuts back    —
</h4>
            
            <h2 itemprop="description">Linux users can't hit the same resolutions and speeds as Windows—or DisplayPort.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/GettyImages-1289090180-800x600.jpg" alt="HDMI cables, bundled up and covered in some dust">
      <figcaption><p>Getty Images</p></figcaption>  </figure>

  




<!-- cache hit 9:single/related:4e140d79418f9d0c58cedca2d3f828f6 --><!-- empty -->
<p>Any Linux user trying to send the highest-resolution images to a display at the fastest frame rate is out of luck for the foreseeable future, at least when it comes to an HDMI connection.</p>
<p>The licensing group that controls the HDMI standard, the <a href="https://hdmiforum.org/">HDMI Forum</a>, has reportedly told AMD that it does not allow an open source implementation of the <a href="https://arstechnica.com/gadgets/2017/11/hdmi-2-1-spec-released-ushering-in-new-era-of-dynamic-hdr-video/">HDMI 2.1</a> (or HDMI 2.1+) specification, blocking tools such as AMD's FreeSync from working over HDMI connections at resolution/rate combinations like 4K at 120 Hz, or 5K at 240 Hz.</p>
<p>Linux blog Phoronix <a href="https://www.phoronix.com/news/HDMI-Closed-Spec-Hurts-Open">noted in January 2021</a> that the HDMI Forum did not offer public access to the HDMI 2.1 specification. Alex Deucher, an AMD engineer who has long contributed to the company's open source offerings, has kept <a href="https://gitlab.freedesktop.org/drm/amd/-/issues/1417">a related bug thread</a> alive for <a href="https://gitlab.freedesktop.org/drm/amd/-/issues/1417#note_830547">at least two years</a>, only to deliver the negative outcome yesterday.</p>
<p>In February 2023, Deucher <a href="https://gitlab.freedesktop.org/drm/amd/-/issues/1417#note_1795980">reported</a> that he was "working with our [AMD] legal team to sort out what we can deliver while still complying with our obligations to HDMI Forum." Two months <a href="https://gitlab.freedesktop.org/drm/amd/-/issues/1417#note_1876855">later</a>, he said that AMD got "the basic functionality up and running, now we have to go through each of the features with legal and determine if/how we can expose them while still meeting our obligations." Summer and fall of 2023 went by, with legal review <a href="https://gitlab.freedesktop.org/drm/amd/-/issues/1417#note_2100060">still underway</a>, and in <a href="https://gitlab.freedesktop.org/drm/amd/-/issues/1417#note_2144689">October</a>, the decision was "in the hands of the HDMI Forum."</p>                                            
                                                        
<p>On Wednesday afternoon, Deucher offered the current resolution:</p>
<blockquote><p>The HDMI Forum has rejected our proposal unfortunately. At this time an open source HDMI 2.1 implementation is not possible without running afoul of the HDMI Forum requirements.</p></blockquote>
<p>Ars has reached out to the HDMI Forum, AMD, and Deucher for further comment and will update the post with new information. X.org was also reportedly involved in negotiations with the HDMI Forum.</p>
<p>Membership in the HDMI Forum is a minimum of $15,000. While AMD is <a href="https://hdmiforum.org/members/">a listed member</a>, that likely doesn't extend to offering up an implementation of a specification for public use. The member agreement forbidding such things does not appear to be publicly available, nor does an "<a href="http://www.hdmi.org/manufacturer/adopter_registration.aspx">addendum</a>" for members linked from the Forum's site. A <a href="https://hdmiforum.org/hdmi-forum-adopter-source-code-license/">source code license</a> found on the Forum's site does not appear to be particularly flexible.</p>
<p><a href="https://www.phoronix.com/news/HDMI-2.1-OSS-Rejected">Phoronix</a> and some commenters have suggested potential interference from media firms concerned about digital video ripping. That would seem like a barn door closed years after the horse's departure, but it also exists as one explanation, lacking other detail.</p>
<p>This outcome leaves DisplayPort as the likely best option for Linux users needing the best possible output. It also suggests that AMD has to decide whether to implement newer HDMI support inside closed-source Linux drivers or simply point its most demanding customers to other options.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[JPEG XL and the Pareto Front (284 pts)]]></title>
            <link>https://cloudinary.com/blog/jpeg-xl-and-the-pareto-front</link>
            <guid>39559281</guid>
            <pubDate>Fri, 01 Mar 2024 06:55:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cloudinary.com/blog/jpeg-xl-and-the-pareto-front">https://cloudinary.com/blog/jpeg-xl-and-the-pareto-front</a>, See on <a href="https://news.ycombinator.com/item?id=39559281">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
<p>Version 0.10 of libjxl, the reference implementation for JPEG XL, has just been <a href="https://github.com/libjxl/libjxl/releases">released</a>. The main improvement this version brings, is that the so-called “streaming encoding” API has now been fully implemented. This API allows encoding a large image in “chunks.” Instead of processing the entire image at once, which may require a significant amount of RAM if the image is large, the image can now be processed in a more memory-friendly way. As a side effect, encoding also becomes faster, in particular when doing lossless compression of larger images.</p>








<p>Before version 0.10, lossless JPEG XL encoding was rather memory-intensive and could take quite some time. This could pose a serious problem when trying to encode large images, like for example <a href="https://earthobservatory.nasa.gov/features/NightLights#:~:text=Marble%20imagery.-,Earth%20at%20Night%3A%20Flat%20Maps,-Global%20Map%20Downloads">this 13500×6750 NASA image of Earth at night</a> (64 MB as a <a href="https://eoimages.gsfc.nasa.gov/images/imagerecords/144000/144898/BlackMarble_2016_3km_geo.tif">TIFF file</a>, 273 MB uncompressed).</p>



<figure><img decoding="async" src="https://res.cloudinary.com/jon/image/fetch/w_1000,f_auto,q_auto/https://eoimages.gsfc.nasa.gov/images/imagerecords/144000/144898/BlackMarble_2016_01deg.jpg" alt="A 13500x6750 NASA image of Earth at night"></figure>



<p>Compressing this image required about 8 gigabytes of RAM in libjxl version 0.9, at the default effort (e7). It took over two minutes, and resulted in a jxl file of 33.7 MB, which is just under 3 bits per pixel. Using more threads did not help much: using a single thread it took 2m40s, using eight threads that was reduced to 2m06s. These timings were measured on a November 2023 Macbook Pro with a 12-core Apple M3 Pro CPU with 36 GB of RAM.</p>



<p>Upgrading to libjxl version 0.10, compressing this same image now requires only 0.7 gigabytes of RAM, takes 30 seconds using a single thread (or 5 seconds using eight threads), and results in a jxl file of 33.2 MB.</p>



<p>For other effort settings, these are the results for this particular image:</p>



<figure><table><tbody><tr><td>effort setting</td><td>memory 0.9.2</td><td>memory 0.10</td><td>time<br>0.9</td><td>time 0.10</td><td>compressed size 0.9</td><td>compressed size 0.10</td><td>memory reduction</td><td>speedup</td></tr><tr><td>e1, 1 thread</td><td>821 MB</td><td>289 MB</td><td>0.65s</td><td>0.3s</td><td>65.26 MB</td><td>67.03 MB</td><td>2.8x</td><td>2.2x</td></tr><tr><td>e1, 8 threads</td><td>842 MB</td><td>284 MB</td><td>0.21s</td><td>0.1s</td><td>65.26 MB</td><td>67.03 MB</td><td>2.9x</td><td>2.1x</td></tr><tr><td>e2, 1 thread</td><td>7,503 MB</td><td>786 MB</td><td>4.3s</td><td>3.6s</td><td>49.98 MB</td><td>44.78 MB</td><td>9.5x</td><td>1.2x</td></tr><tr><td>e2, 8 threads</td><td>6,657 MB</td><td>658 MB</td><td>2.2s</td><td>0.7s</td><td>49.98 MB</td><td>44.78 MB</td><td>10.1x</td><td>3.0x</td></tr><tr><td>e3, 8 threads</td><td>7,452 MB</td><td>708 MB</td><td>2.4s</td><td>1.3s</td><td>45.20 MB</td><td>44.23 MB</td><td>10.5x</td><td>1.8x</td></tr><tr><td>e7, 1 thread</td><td>9,361 MB</td><td>748 MB</td><td>2m40s</td><td>30s</td><td>33.77 MB</td><td>33.22 MB</td><td>12.5x</td><td>4.6x</td></tr><tr><td>e7, 8 threads</td><td>7,887 MB</td><td>648 MB</td><td>2m06s</td><td>5.4s</td><td>33.77 MB</td><td>33.22 MB</td><td>12.2x</td><td>23.6x</td></tr><tr><td>e8, 8 threads</td><td>9,288 MB</td><td>789 MB</td><td>7m38s</td><td>22.2s</td><td>32.98 MB</td><td>32.93 MB</td><td>11.8x</td><td>20.6x</td></tr><tr><td>e9, 8 threads</td><td>9,438 MB</td><td>858 MB</td><td>21m58s</td><td>1m46s</td><td>32.45 MB</td><td>32.20 MB</td><td>11.0x</td><td>12.4x</td></tr></tbody></table></figure>



<p>As you can see in the table above, compression is a game of diminishing returns: as you increase the amount of cpu time spent on the encoding, the compression improves, but not in a linear fashion. Spending one second instead of a tenth of a second (e2 instead of e1) can in this case shave off 22 megabytes; spending five seconds instead of one (e7 instead of e2) shaves off another 11 megabytes. But to shave off one more megabyte, you’ll have to wait almost two minutes (e9 instead of e7).</p>



<p>So it’s very much a matter of trade-offs, and it depends on the use case what makes the most sense. In an authoring workflow, when you’re saving an image locally while still editing it, you typically don’t need strong compression and low-effort encoding makes sense. But in a one-to-many delivery scenario, or for long-term archival, it may well be worth it to spend a significant amount of CPU time to shave off some more megabytes.</p>








<p>When comparing different compression techniques, it doesn’t suffice to only look at the compressed file sizes. The speed of encoding also matters. So there are two dimensions to consider: compression density and encode speed.</p>



<p>A specific method can be called Pareto-optimal if no other method can achieve the same (or better) compression density in less time. There might be other methods that compress better but take more time, or that compress faster but result in larger files. But a Pareto-optimal method delivers the smallest files for a given time budget, which is why it’s called “optimal.”</p>



<p>The set of Pareto-optimal methods is called the “<a href="https://en.wikipedia.org/wiki/Pareto_front">Pareto front</a>.” It can be visualized by putting the different methods on a chart that shows both dimensions — encode speed and compression density. Instead of looking at a single image, which may not be representative, we look at a set of images and look at the average speed and compression density for each encoder and effort setting. For example, for <a href="https://imagecompression.info/test_images/">this set of test images</a>, the chart looks like this:</p>



<figure><img width="1846" height="1596" decoding="async" loading="lazy" src="https://res.cloudinary.com/cloudinary-marketing/images/w_1846,h_1596/f_auto,q_auto/v1709058557/Web_Assets/blog/blog-pareto-front-1/blog-pareto-front-1-png?_i=AA" alt="" data-public-id="Web_Assets/blog/blog-pareto-front-1.png" data-format="png" data-transformations="f_auto,q_auto" data-version="1709058557" srcset="https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058557/Web_Assets/blog/blog-pareto-front-1/blog-pareto-front-1-png?_i=AA 1846w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058557/Web_Assets/blog/blog-pareto-front-1/blog-pareto-front-1-png?_i=AA 300w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058557/Web_Assets/blog/blog-pareto-front-1/blog-pareto-front-1-png?_i=AA 768w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058557/Web_Assets/blog/blog-pareto-front-1/blog-pareto-front-1-png?_i=AA 1024w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058557/Web_Assets/blog/blog-pareto-front-1/blog-pareto-front-1-png?_i=AA 1536w" sizes="(max-width: 1846px) 100vw, 1846px"></figure>



<p>The vertical axis shows the encode speed, in megapixels per second. It’s a logarithmic scale since it has to cover a broad range of speeds, from less than one megapixel per second to hundreds of megapixels per second. The horizontal axis shows the average bits per pixel for the compressed image (uncompressed 8-bit RGB is 24 bits per pixel).</p>


<div><p><strong>TL;DR</strong></p><p>Higher means faster, more to the left means better compression.</p>
</div>


<p>For AVIF, the darker points indicate a faster but slightly less dense tiled encoder setting (using –tilerowslog2 2 –tilecolslog2 2), which is faster because it can make better use of multi-threading, while the lighter points indicate the default non-tiled setting. For PNG, the result of libpng with default settings is shown here as a reference point; other PNG encoders and optimizers exist that reach different trade-offs.</p>



<p>The previous version of libjxl already achieved Pareto-optimal results across all speeds, producing smaller files than PNG and lossless AVIF or lossless WebP. The new version beats the previous version by a significant margin.</p>



<p>Not shown on the chart is <a href="https://github.com/phoboslab/qoi">QOI</a>, which clocked in at 154 Mpx/s to achieve 17 bpp, which may be “quite OK” but is quite far from Pareto-optimal, considering the lowest effort setting of libjxl compresses down to 11.5 bpp at 427 Mpx/s (so it is 2.7 times as fast and the result is 32.5% smaller).</p>








<p>Of course in these charts, quite a lot depends on the selection of test images. In the chart above, most images are photographs, which tend to be hard to compress losslessly: the naturally occurring noise in such images is inherently incompressible.</p>



<p>For non-photographic images, things are somewhat different. I took a random collection of manga images in various drawing styles (41 images with an average size of 7.3 megapixels) and these were the results:</p>



<p>These kinds of images compress significantly better, to around 4 bpp (compared to around 10 bpp for photographic images). For these images, lossless AVIF is not useful — it compresses worse than PNG, and reaches about the same density as QOI but is much slower. Lossless WebP on the other hand achieves very good compression for such images. For these types of images, QOI is indeed quite OK for its speed (and simplicity), though far from Pareto-optimal: low-effort JPEG XL encoding is twice as fast and 31% smaller.</p>



<figure><img width="1860" height="1594" decoding="async" loading="lazy" src="https://res.cloudinary.com/cloudinary-marketing/images/w_1860,h_1594/f_auto,q_auto/v1709058548/Web_Assets/blog/blog-pareto-front-2/blog-pareto-front-2-png?_i=AA" alt="" data-public-id="Web_Assets/blog/blog-pareto-front-2.png" data-format="png" data-transformations="f_auto,q_auto" data-version="1709058548" srcset="https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058548/Web_Assets/blog/blog-pareto-front-2/blog-pareto-front-2-png?_i=AA 1860w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058548/Web_Assets/blog/blog-pareto-front-2/blog-pareto-front-2-png?_i=AA 300w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058548/Web_Assets/blog/blog-pareto-front-2/blog-pareto-front-2-png?_i=AA 768w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058548/Web_Assets/blog/blog-pareto-front-2/blog-pareto-front-2-png?_i=AA 1024w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058548/Web_Assets/blog/blog-pareto-front-2/blog-pareto-front-2-png?_i=AA 1536w" sizes="(max-width: 1860px) 100vw, 1860px"></figure>



<p>For non-photographic images, the new version of libjxl again improves upon the previous version, by a significant margin. The previous version of libjxl could just barely beat WebP: e.g. default-effort WebP compressed these images to 4.30 bpp at 2.3 Mpx/s, while libjxl 0.9 at effort 5 compressed them to 4.27 bpp at 2.6 Mpx/s — only a slight improvement. However libjxl 0.10 at effort 5 compresses the images to 4.25 bpp at 12.2 Mpx/s (slightly better compression but much faster), and at effort 7 it compresses them to 4.04 bpp at 5.9 Mpx/s (significantly better compression and still twice as fast). Zooming in on the medium-speed part of the Pareto front on the above plot, the improvement going from libjxl 0.9 to 0.10 becomes clear:</p>



<figure><img width="1830" height="1578" decoding="async" loading="lazy" src="https://res.cloudinary.com/cloudinary-marketing/images/w_1830,h_1578/f_auto,q_auto/v1709058543/Web_Assets/blog/blog-pareto-front-3/blog-pareto-front-3-png?_i=AA" alt="" data-public-id="Web_Assets/blog/blog-pareto-front-3.png" data-format="png" data-transformations="f_auto,q_auto" data-version="1709058543" srcset="https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058543/Web_Assets/blog/blog-pareto-front-3/blog-pareto-front-3-png?_i=AA 1830w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058543/Web_Assets/blog/blog-pareto-front-3/blog-pareto-front-3-png?_i=AA 300w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058543/Web_Assets/blog/blog-pareto-front-3/blog-pareto-front-3-png?_i=AA 768w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058543/Web_Assets/blog/blog-pareto-front-3/blog-pareto-front-3-png?_i=AA 1024w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058543/Web_Assets/blog/blog-pareto-front-3/blog-pareto-front-3-png?_i=AA 1536w" sizes="(max-width: 1830px) 100vw, 1830px"></figure>








<p>Lossless compression is relatively easy to benchmark: all that matters is the compressed size and the speed. For lossy compression, there is a third dimension: image quality.</p>



<p>Lossy image codecs and encoders can perform differently at different quality points. An encoder that works very well for high-quality encoding does not necessarily also perform well for low-quality encoding, and the other way around.</p>



<p>Of these three dimensions (compression, speed and quality), often speed is simply ignored, and plots are made of compression versus quality (also known as bitrate-distortion plots). But this does not really allow evaluating the trade-offs between encode effort (speed) and compression performance. So if we really want to investigate the Pareto front for lossy compression, one way of doing it is to look at different “slices” of the three-dimensional space, at various quality points.</p>








<p>Image quality is a notoriously difficult thing to measure: in the end, it is subjective and somewhat different from one human to the next. The best way to measure image quality is still to run an experiment involving at least dozens of humans looking carefully at images and comparing or scoring them, according to rigorously defined test protocols. At Cloudinary, we have <a href="https://cloudinary.com/labs/cid22">done such experiments</a> in the past. But while this is the best way to assess image quality, it is a time-consuming and costly process, and it is not feasible to test all possible encoder configurations in this way.</p>



<p>For that reason, so-called objective metrics are being developed, which allow algorithmic estimates of image quality. These metrics are not “more objective” (in the sense of “more correct”) than scores obtained from testing with humans, in fact they are <em>less</em> “correct.” But they can give an indication of image quality much faster and cheaper (and more easily reproducible and consistent) than when humans are involved, which is what makes them useful.</p>



<p>The best metrics currently publicly available are <a href="https://github.com/cloudinary/ssimulacra2">SSIMULACRA2</a>, <a href="https://github.com/google/butteraugli">Butteraugli</a>, and <a href="https://github.com/kornelski/dssim">DSSIM</a>. These metrics try to model the human visual system and have the <a href="https://cloudinary.com/labs/cid22#:~:text=(SSIMULACRA%202),%2D0.7813">best correlation with subjective results</a>. Older, simpler metrics like PSNR or SSIM could also be used, but they do not correlate very well with human opinions about image quality. Care has to be taken not to measure results using a metric an encoder is specifically optimizing for, as that would skew the results in favor of such encoders. For example, higher-effort libjxl optimizes for Butteraugli, while libavif can optimize for PSNR or SSIM. In this respect, SSIMULACRA2 is “safe” since none of the encoders tested is using it internally for optimization.</p>








<p>Different metrics will say different things, but there are also different ways to aggregate results across a set of images. To keep things simple, I selected <a href="https://gist.github.com/jonsneyers/d317f51b4805c1a8f3ce0e86a9bce100">encoder settings</a> such that when using each setting on all images in the set, the average SSIMULACRA2 score was equal to (or close to) a specific value. Another method would have been to adjust the encoder settings per image so for each image the SSIMULACRA2 score is the same, or to select an encoder setting such that the <em>worst-case</em> SSIMULACRA2 score is equal to a specific value.<br>Aligning on worst-case scores is favorable for consistent encoders (encoders that reliably produce the same visual quality given fixed quality settings), while aligning on average scores is favorable for inconsistent encoders (encoders where there is more variation in visual quality when using fixed quality settings). From <a href="https://cloudinary-marketing-res.cloudinary.com/image/upload/v1682016636/wg1m99012-ICQ-AIC3_Contribution_Cloudinary_CID22.pdf">earlier research</a>, we know that AVIF and WebP are more inconsistent than JPEG and HEIC, and that JPEG XL has the most consistent encoder:</p>



<figure><img width="1182" height="1536" decoding="async" loading="lazy" src="https://res.cloudinary.com/cloudinary-marketing/images/w_1182,h_1536/f_auto,q_auto/v1709058535/Web_Assets/blog/blog-pareto-front-4/blog-pareto-front-4-png?_i=AA" alt="" data-public-id="Web_Assets/blog/blog-pareto-front-4.png" data-format="png" data-transformations="f_auto,q_auto" data-version="1709058535" srcset="https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058535/Web_Assets/blog/blog-pareto-front-4/blog-pareto-front-4-png?_i=AA 1182w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058535/Web_Assets/blog/blog-pareto-front-4/blog-pareto-front-4-png?_i=AA 231w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058535/Web_Assets/blog/blog-pareto-front-4/blog-pareto-front-4-png?_i=AA 768w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058535/Web_Assets/blog/blog-pareto-front-4/blog-pareto-front-4-png?_i=AA 788w" sizes="(max-width: 1182px) 100vw, 1182px"></figure>



<p>Defining the quality points the way I did (using fixed settings and aligning by average metric score) is in the favor of WebP and AVIF; in practical usage you will likely want to align on worst-case metric score (or rather, worst-case <em>actual visual quality</em>), but I chose not to do that, in order to not favor JPEG XL.</p>








<p>Lossless compression offers 2:1 to 3:1 compression ratios (8 to 12 bpp) for photographic images. Lossy compression can reach much better compression ratios. It is tempting to see how lossy image codecs behave when they are pushed to their limits. Compression ratios of 50:1 or even 200:1 (0.1 to 0.5 bpp) can be obtained, at the cost of introducing compression artifacts. Here is an example of an image compressed to reach a SSIMULACRA2 score of 50, 30, and 10 using libjpeg-turbo, libjxl and libavif:</p>



<figure><a href="https://res.cloudinary.com/jon/qp-low.png" target="_blank" rel="noreferrer noopener"><img decoding="async" src="https://cloudinary-marketing-res.cloudinary.com/image/upload/v1709060139/qp-low.png" alt=""></a></figure>


<div><p><strong>Note:</strong></p><p>Click on the animation to open it in another tab; view it full-size to properly see the artifacts.</p>
</div>


<p>This kind of quality is interesting to look at in experiments, but in most actual usage, it is not desirable to introduce such noticeable compression artifacts. In practice, the range of qualities that is relevant corresponds to SSIMULACRA2 scores ranging from 60 (medium quality) to 90 (visually lossless). These qualities look like this:</p>



<figure><a href="https://res.cloudinary.com/jon/qp.png" target="_blank" rel="noreferrer noopener"><img decoding="async" src="https://cloudinary-marketing-res.cloudinary.com/image/upload/v1709060138/qp.png" alt=""></a></figure>



<p>Visually lossless quality (SSIMULACRA2 = 90) can be reached with a compression ratio of about 8:1 (3 bpp) with modern codecs such as AVIF and JPEG XL, or about 6:1 (4 bpp) with JPEG. At this point, the image is visually not distinguishable from the uncompressed original, even when looking very carefully. In cameras, when not shooting RAW, typically this is the kind of quality that is desired. For web delivery, it is overkill to use such a high quality.</p>



<p>High quality (SSIMULACRA2 = 80) can be reached with a compression ratio of 16:1 (1.5 bpp). When looking carefully, very small differences might be visible, but essentially the image is still as good as the original. This, or perhaps something in between high quality and visually lossless quality, is the highest quality useful for web delivery, for use cases where image fidelity really matters.</p>



<p>Medium-high quality (SSIMULACRA2 = 70) can be reached with a compression ratio of 30:1 (0.8 bpp). There are some small artifacts, but the image still looks good. This is a good target for most web delivery use cases, as it makes a good trade-off between fidelity and bandwidth optimization.</p>



<p>Medium quality (SSIMULACRA2 = 60) can be reached with a compression ratio of 40:1 (0.6 bpp). Compression artifacts start to become more noticeable, but they’re not problematic for casual viewing. For non-critical images on the web, this quality can be “good enough.”</p>



<p>Any quality lower than this is potentially risky: sure, bandwidth will be reduced by going even further, but at the cost of potentially ruining the images. For the web, in 2024, the relevant range is medium to high quality: <a href="https://almanac.httparchive.org/en/2022/media#bits-per-pixel-by-format">according to the HTTP Archive</a>, the median AVIF image on the web is compressed to 1 bpp, which corresponds to medium-high quality, while the median JPEG image is 2.1 bpp, which corresponds to high quality. For most non-web use cases (e.g. cameras), the relevant range is high to (visually) lossless quality.</p>








<p>In the following Pareto front plots, the following encoders were tested:</p>



<figure><table><tbody><tr><td>format</td><td>encoder</td><td>version</td></tr><tr><td>JPEG</td><td>libjpeg-turbo</td><td>libjpeg-turbo 2.1.5.1</td></tr><tr><td>JPEG</td><td>sjpeg</td><td>sjpeg @ e5ab130</td></tr><tr><td>JPEG</td><td>mozjpeg</td><td>mozjpeg version 4.1.5 (build 20240220)</td></tr><tr><td>JPEG</td><td>jpegli</td><td>from libjxl v0.10.0</td></tr><tr><td>AVIF</td><td>libavif / libaom</td><td>libavif 1.0.3 (aom [enc/dec]:3.8.1)</td></tr><tr><td>JPEG XL</td><td>libjxl</td><td>libjxl v0.10.0</td></tr><tr><td>WebP</td><td>libwebp</td><td>libwebp 1.3.2</td></tr><tr><td>HEIC</td><td>libheif</td><td>heif-enc libheif version: 1.17.6 (x265 3.5)</td></tr></tbody></table></figure>



<p>These are the most recent versions of each encoder at the time of writing (end of February 2024).</p>



<p>Encode speed was again measured on a November 2023 Macbook Pro (Apple M3 Pro), using 8 threads. For AVIF, both the tiled setting (with –tilerowslog2 2 –tilecolslog2 2) and the non-tiled settings were tested. The tiled setting, indicated with “MT”, is faster since it allows better multi-threading, but it comes at a cost in compression density.</p>








<p>Let’s start by looking at the results for medium quality, i.e., settings that result in a corpus average SSIMULACRA2 score of 60. This is more or less the lowest quality point that is used in practice. Some images will have visible compression artifacts with these encoder settings, so this quality point is most relevant when saving bandwidth and reducing page weight is more important than image fidelity.</p>



<figure><img width="1942" height="1620" decoding="async" loading="lazy" src="https://res.cloudinary.com/cloudinary-marketing/images/w_1942,h_1620/f_auto,q_auto/v1709058526/Web_Assets/blog/blog-pareto-front-5/blog-pareto-front-5-png?_i=AA" alt="" data-public-id="Web_Assets/blog/blog-pareto-front-5.png" data-format="png" data-transformations="f_auto,q_auto" data-version="1709058526" srcset="https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058526/Web_Assets/blog/blog-pareto-front-5/blog-pareto-front-5-png?_i=AA 1942w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058526/Web_Assets/blog/blog-pareto-front-5/blog-pareto-front-5-png?_i=AA 300w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058526/Web_Assets/blog/blog-pareto-front-5/blog-pareto-front-5-png?_i=AA 768w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058526/Web_Assets/blog/blog-pareto-front-5/blog-pareto-front-5-png?_i=AA 1024w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058526/Web_Assets/blog/blog-pareto-front-5/blog-pareto-front-5-png?_i=AA 1536w" sizes="(max-width: 1942px) 100vw, 1942px"></figure>



<p>First of all, note that even for the same format, different encoders and different effort settings can reach quite different results. Historically, the most commonly used JPEG encoder was libjpeg-turbo — often using its default setting (no Huffman optimization, not progressive), which is the point all the way in the top right. When Google first introduced WebP, it outperformed libjpeg-turbo in terms of compression density, as can be seen in the plot above. But Mozilla was not impressed, and they created their own JPEG encoder, mozjpeg, which is slower than libjpeg-turbo but offers better compression results. And indeed, we can see that mozjpeg is actually more Pareto-efficient than WebP (for this corpus, at this quality point).</p>



<p>More recently, the JPEG XL team at Google has built yet another JPEG encoder, jpegli, which is both faster and better than even mozjpeg. It is based on lessons learned from guetzli and libjxl, and offers a very attractive trade-off: it is very fast, compresses better than WebP and even high-speed AVIF, while still producing good old JPEG files that are supported everywhere.</p>



<p>Moving on to the newer codecs, we can see that both AVIF and HEIC can obtain a better compression density than JPEG and WebP, at the cost of slower encoding. JPEG XL can reach a similar compression density but encodes significantly faster. The current Pareto front for this quality point consists of JPEG XL and the various JPEG encoders for the “reasonable” speeds, and AVIF at the slower speeds (though the additional savings over default-effort JPEG XL are small).</p>








<p>At somewhat higher quality settings where the average SSIMULACRA2 score for the corpus is 70, the overall results look quite similar:</p>



<figure><img width="1999" height="1496" decoding="async" loading="lazy" src="https://res.cloudinary.com/cloudinary-marketing/images/w_1999,h_1496/f_auto,q_auto/v1709058518/Web_Assets/blog/blog-pareto-front-6/blog-pareto-front-6-png?_i=AA" alt="" data-public-id="Web_Assets/blog/blog-pareto-front-6.png" data-format="png" data-transformations="f_auto,q_auto" data-version="1709058518" srcset="https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058518/Web_Assets/blog/blog-pareto-front-6/blog-pareto-front-6-png?_i=AA 1999w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058518/Web_Assets/blog/blog-pareto-front-6/blog-pareto-front-6-png?_i=AA 300w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058518/Web_Assets/blog/blog-pareto-front-6/blog-pareto-front-6-png?_i=AA 768w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058518/Web_Assets/blog/blog-pareto-front-6/blog-pareto-front-6-png?_i=AA 1024w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058518/Web_Assets/blog/blog-pareto-front-6/blog-pareto-front-6-png?_i=AA 1536w" sizes="(max-width: 1999px) 100vw, 1999px"></figure>








<p>Moving on to the highest quality point that is relevant for the web (corpus average SSIMULACRA2 score of 85, to ensure that most images reach a score above 80), the differences become a little more pronounced.</p>



<figure><img width="1999" height="1612" decoding="async" loading="lazy" src="https://res.cloudinary.com/cloudinary-marketing/images/w_1999,h_1612/f_auto,q_auto/v1709058510/Web_Assets/blog/blog-pareto-front-7/blog-pareto-front-7-png?_i=AA" alt="" data-public-id="Web_Assets/blog/blog-pareto-front-7.png" data-format="png" data-transformations="f_auto,q_auto" data-version="1709058510" srcset="https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058510/Web_Assets/blog/blog-pareto-front-7/blog-pareto-front-7-png?_i=AA 1999w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058510/Web_Assets/blog/blog-pareto-front-7/blog-pareto-front-7-png?_i=AA 300w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058510/Web_Assets/blog/blog-pareto-front-7/blog-pareto-front-7-png?_i=AA 768w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058510/Web_Assets/blog/blog-pareto-front-7/blog-pareto-front-7-png?_i=AA 1024w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058510/Web_Assets/blog/blog-pareto-front-7/blog-pareto-front-7-png?_i=AA 1536w" sizes="(max-width: 1999px) 100vw, 1999px"></figure>



<p>At this point, mozjpeg no longer beats WebP, though jpegli still does. The Pareto front is now mostly covered by JPEG XL, though for very fast encoding, good old JPEG is still best. At this quality point, AVIF is not on the Pareto front: at its slowest settings (at 0.5 Mpx/s or slower) it matches the compression density of the second-fastest libjxl setting, which is over 100 times as fast (52 Mpx/s).</p>








<p>So far, we have only looked at compression density and encode speed. Decode speed is not really a significant problem on modern computers, but it is interesting to take a quick look at the numbers. The table below shows the same results as the plot above, but besides bits per pixel and encode speed, it also shows the decode speed. For completeness, the SSIMULACRA2 and Butteraugli 3-norm scores are also given for each encoder setting.</p>


<div>
<figure><img width="846" height="1298" data-public-id="Web_Assets/blog/Screen-Shot-2024-02-29-at-3.35.25-PM.png" decoding="async" loading="lazy" src="https://res.cloudinary.com/cloudinary-marketing/images/w_846,h_1298/f_auto,q_auto/v1709249796/Web_Assets/blog/Screen-Shot-2024-02-29-at-3.35.25-PM/Screen-Shot-2024-02-29-at-3-35-25-PM-png?_i=AA" alt="" data-format="png" data-transformations="f_auto,q_auto" data-version="1709249796" srcset="https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709249796/Web_Assets/blog/Screen-Shot-2024-02-29-at-3.35.25-PM/Screen-Shot-2024-02-29-at-3-35-25-PM-png?_i=AA 846w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709249796/Web_Assets/blog/Screen-Shot-2024-02-29-at-3.35.25-PM/Screen-Shot-2024-02-29-at-3-35-25-PM-png?_i=AA 196w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709249796/Web_Assets/blog/Screen-Shot-2024-02-29-at-3.35.25-PM/Screen-Shot-2024-02-29-at-3-35-25-PM-png?_i=AA 768w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709249796/Web_Assets/blog/Screen-Shot-2024-02-29-at-3.35.25-PM/Screen-Shot-2024-02-29-at-3-35-25-PM-png?_i=AA 667w" sizes="(max-width: 846px) 100vw, 846px"></figure></div>


<p>Sequential JPEG is unbeatable in terms of decode speed — not surprising for a codec that was designed in the 1980s. Progressive JPEG (e.g. as produced by mozjpeg and default jpegli) is somewhat slower to decode, but still fast enough to load any reasonably-sized image in the blink of an eye. JPEG XL is somewhere in between those two.</p>



<p>Interestingly, the decode speed of AVIF depends on how the image was encoded: it is faster when using the faster-but-slightly-worse multi-tile encoding, slower when using the default single-tile encoding. Still, even the slowest decode speed measured here is probably “fast enough,” especially compared to the encode speeds.</p>








<p>Finally, let’s take a look at the results for visually lossless quality:</p>



<figure><img width="1999" height="1613" decoding="async" loading="lazy" src="https://res.cloudinary.com/cloudinary-marketing/images/w_1999,h_1613/f_auto,q_auto/v1709058502/Web_Assets/blog/blog-pareto-front-8/blog-pareto-front-8-png?_i=AA" alt="" data-public-id="Web_Assets/blog/blog-pareto-front-8.png" data-format="png" data-transformations="f_auto,q_auto" data-version="1709058502" srcset="https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058502/Web_Assets/blog/blog-pareto-front-8/blog-pareto-front-8-png?_i=AA 1999w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058502/Web_Assets/blog/blog-pareto-front-8/blog-pareto-front-8-png?_i=AA 300w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058502/Web_Assets/blog/blog-pareto-front-8/blog-pareto-front-8-png?_i=AA 768w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058502/Web_Assets/blog/blog-pareto-front-8/blog-pareto-front-8-png?_i=AA 1024w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058502/Web_Assets/blog/blog-pareto-front-8/blog-pareto-front-8-png?_i=AA 1536w" sizes="(max-width: 1999px) 100vw, 1999px"></figure>



<p>WebP is not on this chart since it simply cannot reach this quality point, at least not using its lossy mode. This is because 4:2:0 chroma subsampling is obligatory in WebP. Also clearly mozjpeg was not designed for this quality point, and performs worse than libjpeg-turbo in both compression and speed.</p>



<p>At their default speed settings, libavif is 20% smaller than libjpeg-turbo (though it takes an order of magnitude longer to encode), while libjxl is 20% smaller than libavif and 2.5 times as fast, at this quality point. The Pareto front consists of mostly JPEG XL but at the fastests speeds again also includes JPEG.</p>








<p>In the plots above, the <a href="https://people.xiph.org/~xiphmont/demo/daala/update1-tool2b.shtml">test set</a> consisted of web-sized images of about 1 megapixel each. This is relevant for the web, but for example when storing camera pictures, images are larger than this.</p>



<p>For a test set with larger images (the <a href="https://imagecompression.info/test_images/">same set we used before</a> to test lossless compression), at a high quality point, we get the following results:</p>



<figure><img width="1999" height="1358" decoding="async" loading="lazy" src="https://res.cloudinary.com/cloudinary-marketing/images/w_1999,h_1358/f_auto,q_auto/v1709058494/Web_Assets/blog/blog-pareto-front-9/blog-pareto-front-9-png?_i=AA" alt="" data-public-id="Web_Assets/blog/blog-pareto-front-9.png" data-format="png" data-transformations="f_auto,q_auto" data-version="1709058494" srcset="https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058494/Web_Assets/blog/blog-pareto-front-9/blog-pareto-front-9-png?_i=AA 1999w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058494/Web_Assets/blog/blog-pareto-front-9/blog-pareto-front-9-png?_i=AA 300w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058494/Web_Assets/blog/blog-pareto-front-9/blog-pareto-front-9-png?_i=AA 768w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058494/Web_Assets/blog/blog-pareto-front-9/blog-pareto-front-9-png?_i=AA 1024w, https://res.cloudinary.com/cloudinary-marketing/images/f_auto,q_auto/v1709058494/Web_Assets/blog/blog-pareto-front-9/blog-pareto-front-9-png?_i=AA 1536w" sizes="(max-width: 1999px) 100vw, 1999px"></figure>



<p>Now things look quite different than with the smaller, web-sized images. WebP, mozjpeg, and AVIF are worse than libjpeg-turbo (for these images, at this quality point). HEIC brings significant savings over libjpeg-turbo, though so does jpegli, at a much better speed. JPEG XL is the clear winner, compressing the images to less than 1.3 bpp while AVIF, libjpeg-turbo, and WebP require more than 2 bpp.</p>








<p>While not as dramatic as the improvements in lossless compression, also for lossy compression there have been improvements between libjxl 0.9 and libjxl 0.10. At the default effort setting (e7), this is how the memory and speed changed for a large (39 Mpx) image:</p>



<figure><table><tbody><tr><td>effort setting</td><td>memory 0.9.2</td><td>memory 0.10</td><td>time<br>0.9</td><td>time 0.10</td><td>compressed size 0.9</td><td>compressed size 0.10</td><td>memory reduction</td><td>speedup</td></tr><tr><td>e7, d1, 1 thread</td><td>4,052 MB</td><td>397 MB</td><td>9.6s</td><td>8.6s</td><td>6.57 MB</td><td>6.56 MB</td><td>10.2x</td><td>1.11x</td></tr><tr><td>e7, d1, 8 threads</td><td>3,113 MB</td><td>437 MB</td><td>3.1s</td><td>1.7s</td><td>6.57 MB</td><td>6.56 MB</td><td>7.1x</td><td>1.76x</td></tr></tbody></table></figure>








<p>The new version of libjxl brings a very substantial reduction in memory consumption, by an order of magnitude, for both lossy and lossless compression. Also the speed is improved, especially for multi-threaded lossless encoding where the default effort setting is now an order of magnitude faster.</p>



<p>This consolidates JPEG XL’s position as the best image codec currently available, for both lossless and lossy compression, across the quality range but in particular for high quality to visually lossless quality. It is Pareto-optimal across a wide range of speed settings.</p>



<p>Meanwhile, the old JPEG is still attractive thanks to better encoders. The new jpegli encoder brings a significant improvement over mozjpeg in terms of both speed and compression. Perhaps surprisingly, good old JPEG is still part of the Pareto front — when extremely fast encoding is needed, it can still be the best choice.</p>



<p>At Cloudinary, we are actively participating in improving the state of the art in image compression. We are continuously applying new insights and technologies in order to bring the best possible experience to our end-users. As new codecs emerge and encoders for existing codes improve, we keep making sure to deliver media according to the state of the art.</p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Docusign just admitted that they use customer data to train AI (189 pts)]]></title>
            <link>https://twitter.com/nixcraft/status/1763124892986474689</link>
            <guid>39558365</guid>
            <pubDate>Fri, 01 Mar 2024 03:53:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/nixcraft/status/1763124892986474689">https://twitter.com/nixcraft/status/1763124892986474689</a>, See on <a href="https://news.ycombinator.com/item?id=39558365">Hacker News</a></p>
Couldn't get https://twitter.com/nixcraft/status/1763124892986474689: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[The "End of Programming" will look a lot like programming (2023) (117 pts)]]></title>
            <link>https://ben11kehoe.medium.com/the-end-of-programming-will-look-a-lot-like-programming-8b877c8efef8</link>
            <guid>39558270</guid>
            <pubDate>Fri, 01 Mar 2024 03:37:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ben11kehoe.medium.com/the-end-of-programming-will-look-a-lot-like-programming-8b877c8efef8">https://ben11kehoe.medium.com/the-end-of-programming-will-look-a-lot-like-programming-8b877c8efef8</a>, See on <a href="https://news.ycombinator.com/item?id=39558270">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a rel="noopener follow" href="https://ben11kehoe.medium.com/?source=post_page-----8b877c8efef8--------------------------------"><div aria-hidden="false"><p><img alt="Ben Kehoe" src="https://miro.medium.com/v2/resize:fill:88:88/1*BJ2oPzPhLv1cvR3TrQeOaA.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div><p id="cbdb">Communications of the ACM has <a href="https://m-cacm.acm.org/magazines/2023/1/267976-the-end-of-programming/fulltext" rel="noopener ugc nofollow" target="_blank">a new article titled “The End of Programming”</a> by Matt Welsh. It posits that traditional programs “will be replaced by AI systems that are <em>trained</em> rather than <em>programmed</em>” (emphasis in the original). Welsh is “the CEO and co-founder of Fixie.ai, a recently founded startup developing AI capabilities to support software development teams”.</p><p id="b452">I’m generally skeptical of these broad claims. More than anything, I think when people imagine integrating AI (and especially LLMs) into software development (or any other process), they tend to be overly optimistic. But I want to focus on something in particular here. Welsh says “[w]e are rapidly moving toward a world where the fundamental building blocks of computation are temperamental, mysterious, adaptive agents.”</p><p id="a9f6">I think this is the least likely outcome. If you had to describe characteristics that drive users away from products, “temperamental and mysterious” system behavior would be high on that list (we usually just call it “buggy”). <em>Especially</em> because in this world, the people behind the product would likely say, “Ah, sorry, the AI did that. We’ll see if we can explain to it what needs to be fixed and maybe it’ll get fixed if we ask it the right thing”.</p><p id="4985">In general, a lot of the AI takes I see assert that AI will be able to assume the entire <em>responsibility</em> for a given task for a person, and implicitly assume that the person’s <em>accountability</em> for the task will just sort of…evaporate? Like, if the AI got it wrong, it’s not your fault? But if you have no real way to ensure the task is correctly performed, they’re probably going to find someone else to accomplish that task after it’s failed a few times.</p><p id="abb7">So in a world where software still has to actually do the thing required of it, let’s imagine what it would look like if we no longer needed human software developers. A human is acting as a product manager, dictating their business requirements to an AI, which then constructs software. Let’s assume that the resulting software that is largely functional (that is, free of low-level bugs) — I think this is a long ways off, and there is lots to say about what it will look like until then, but that’s a separate discussion.</p><p id="fe23">If you’ve worked as a software developer, you know that business requirements often come as vague, ill-defined, even contradictory ideas written down in ambiguous language. The primary question about this AI-only software development is, how will it make software that implements what the product manager <em>intends</em> the software to do?</p><p id="4c15">I think there are two general directions, which are not mutually exclusive.</p><p id="e2e4">The first is that the AI has to ask the product manager about every individual choice and ambiguity. It has to do this because it is good enough to know what the choices and ambiguity are, but not good enough to consistently guess the correct answer. This back-and-forth will start in plain language, and take up a lot of time for the product manager. Over time, the AI’s designers will start offering shortcuts that allow the input requirements to mean specific things when framed a certain way, so the product manager can make their choice clear from the outset. So we’ve got a method for expressing system behavior with formal guarantees. That is, we’ve invented a new programming language. At this point, the product manager is now a software developer.</p><p id="f900">The other is that the AI <em>is</em> good enough to consistently correctly guess the right answer to choices and ambiguity in the requirements <em>and</em> good enough to know when it doesn’t have confidence it can guess correctly. To do this requires an enormous amount of human cultural knowledge and probably a high degree of knowledge of the specific person acting as the product manager. The AI is doing the work of translating the business requirements into formal system behavior requirements, as well as implementing them. At this point, the AI is now a software developer.</p><p id="8188">You could argue the second is the same as Welsh’s vision of “the end of programming”, as you’re still working without a formal language. I’m saying it’s different, because it’s not “temperamental and mysterious” any more than the software developers (the ones you <em>like</em> working with) are — it’s reliable and consistent.</p><p id="2bf4">I think the second direction, AI-as-software-developer, is quite a ways off, specifically because cultural context and self-awareness are hard things. I doubt you need AGI to get it, but it seems like it would be a good chunk of the way there. So if you’re bullish on AGI, you can hope we’ll get it sooner rather than later.</p><p id="ec9d">I’d love to see the first direction taken explicitly. One of my problems with GitHub Copilot (and similar systems) is that you still own the resulting code, and it does not provide any path to gaining confidence that it has given you a correct implementation, despite you owning the correctness of the code it generates (this also warrants its own article, I think). I’d love for it to identify common patterns and formalize them, such that developers could use some shorthand to express that complicated logic and have confidence they are getting what they expect. Maybe that can be done with the existing system, or maybe it’s an entirely new Copilot-oriented programming language.</p><p id="a168">I think my main takeaway here is that, when looking at claims AI is going to automate some process, look for what the really hard, inherent complexity of that process is, and whether the process would be successful if a large degree of (new) uncertainty was injected into that complexity. For software development, I think the answer is no. That doesn’t mean AI won’t be successful, it just means we need to look deeper to refine what and how (and when) automation will play a role in it.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nokia is replacing Huawei at Deutsche Telekom sites in Germany (130 pts)]]></title>
            <link>https://www.lightreading.com/open-ran/nokia-is-replacing-huawei-at-deutsche-telekom-sites-in-germany</link>
            <guid>39557500</guid>
            <pubDate>Fri, 01 Mar 2024 01:37:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lightreading.com/open-ran/nokia-is-replacing-huawei-at-deutsche-telekom-sites-in-germany">https://www.lightreading.com/open-ran/nokia-is-replacing-huawei-at-deutsche-telekom-sites-in-germany</a>, See on <a href="https://news.ycombinator.com/item?id=39557500">Hacker News</a></p>
Couldn't get https://www.lightreading.com/open-ran/nokia-is-replacing-huawei-at-deutsche-telekom-sites-in-germany: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Struct – A Feed-Centric Chat Platform (255 pts)]]></title>
            <link>https://struct.ai/blog/introducing-the-struct-chat-platform</link>
            <guid>39557188</guid>
            <pubDate>Fri, 01 Mar 2024 00:49:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://struct.ai/blog/introducing-the-struct-chat-platform">https://struct.ai/blog/introducing-the-struct-chat-platform</a>, See on <a href="https://news.ycombinator.com/item?id=39557188">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-framer-name="all content" id="all-content" name="all content"><div data-framer-name="text column - 1" data-framer-component-type="RichTextContainer" name="text column - 1"><p>Endless notifications. Lost insights. Redundancy. Distraction. Chat platforms play a huge role in digital collaboration, but they're increasingly detrimental to deep work and effective outcomes. Popular options like Slack and Discord are falling short. They create knowledge black holes, where staying up to date is time-consuming and finding what you're looking for is impossible. Real-time shouldn't mean real pain. Chat is conversation! It should be inspiring! It should encourage discovery, enrichment, and productivity, not indifference, agony or frustration.</p><div><p>At Struct, we’re rebuilding the chat experience from the ground up, guided by our <a href="https://struct.ai/blog/knowledge-base" target="_blank">CRISPY design ethos</a> and a relentless pursuit of efficiency. Today, we're thrilled to unveil the Struct Chat platform. </p><p>You can check a <a href="https://struct.ai/demo-video">demo walkthrough</a> or come join us in our Struct org <a href="https://chat.struct.ai/join/DXVTmseDdBkeA6mG" target="_blank" rel="noopener">here</a>. We love to chat!</p><p>Let’s dig into the app.</p></div></div><div data-framer-name="text column - 2" data-framer-component-type="RichTextContainer" name="text column - 2"><h2>Feeds and threads.<br>Not chats and channels</h2><p>Using traditional chat channels is a hassle. We’re forced into clicking through multiple channels just to catch up on our team’s latest updates. Combine this with the always-growing list of new channels, and information starts to get really scattered. Deciding whether a conversation belongs in ‘<code>Contracts</code>’ or ‘<code>Clients</code>’, ‘<code>How-to</code>’ or ‘<code>Getting-started</code>’ can be confusing. In open-source communities, moderators work hard to keep conversations organized, while corporate teams often rely on self-policing, asking folks to "Please move this to another channel" and interrupting everyone's flow. This adds friction to our conversations.</p></div><div data-framer-name="text column - 3" data-framer-component-type="RichTextContainer" name="text column - 3"><p>On the other hand, Feeds have consistently demonstrated their scalability across numerous social platforms. People consume vast amounts of info during a quick scroll of their daily feeds (RSS, Facebook, X, IG etc.) Applied to chat, they allow you to switch from chasing updates by clicking around, to sitting back and letting the chats come to you. At Struct we’re exploring this concept to its maximum potential.</p><p>In Struct, every chat message belongs to a thread. Chats don’t get stuck in channels. Instead, any thread you have access to is displayed in a highly efficient feed. Struct has one of the fastest, most real-time feeds of any chat platform or social network, ensuring you’re always up-to-date on the latest conversations.</p><p>As new threads get created or older threads updated, they automatically make their way to the top of your feed. New chat messages pop-in to show you live activity within the threads. This makes Struct Chat a super-intuitive way to stay on top of daily conversations</p></div><div data-framer-name="Image wrapper - 4" name="Image wrapper - 4"><p data-styles-preset="vBXob0l2T">Struct's live feed keeps you ahead of every conversation  </p></div><div data-framer-name="text column - 4" name="text column - 4"><p>This is great for when you step away. Whether it's a few hours or a couple days, catching up is really easy. Just look through the top N unread threads in your feed, and you're done. These threads could be spread across any number of channels or DMs, it doesn't matter. Struct's dynamic access control system will funnel them right to your feed. By bringing the latest updates directly to you, Struct keeps you informed without the noise, and eliminates the chasing or digging required by other platforms.</p></div><div data-framer-name="Image wrapper - 5" name="Image wrapper - 5"><p data-styles-preset="vBXob0l2T">The chasing and clicking really adds up in other chat platforms</p></div><div data-framer-name="text column - 5" data-framer-component-type="RichTextContainer" name="text column - 5"><h3>Your feed, your way</h3><p>In Struct, you can create a custom feed to follow specific projects, teams, or tasks, isolating only conversations relevant to your needs. This helps you focus on the essentials, while skimming off the clutter.&nbsp;</p><p>Here’s a fun example: Want to align closely with your company's mission? Create a feed for your CEO's threads and stay in sync with your company's latest vision and goals. Jump in the conversation with the right answers and get that promotion you deserve. 💪</p><p>The possibilities are endless. What kind of feeds will you create? We can’t wait to find out.</p></div><div data-framer-name="Image wrapper - 6" name="Image wrapper - 6"><p data-styles-preset="vBXob0l2T">Custom feeds allow you to quickly create different views into your team </p></div><div data-framer-name="text column - 6" data-framer-component-type="RichTextContainer" name="text column - 6"><h3>Use tags for organization, not channels</h3><p>Tags (aka hashtags) introduce another dimension of organization, allowing threads to be further categorized by topic, project, or any identifier you choose. Together, channels and hashtags create a dual-layered system that lets you tag, assign, and streamline any conversation. This turns your chats into a useful tool for project management, task delegation, and issue tracking. All without ever leaving the app.</p></div><div data-framer-name="Image wrapper - 7" name="Image wrapper - 7"><p data-styles-preset="vBXob0l2T">Add channels to your messages to send them to the right people. Add hashtags for more context</p></div><div data-framer-name="text column - 7" data-framer-component-type="RichTextContainer" name="text column - 7"><p>Want some ideas? We use Struct as our singular place for tracking projects, resources, and tasks. I use <code>#design</code> and <code>#assign/jason</code> tags to mark threads requiring my attention. Our development team operates similarly, employing <code>p0</code>, <code>p1</code> and <code>p2</code> tags to set priorities.</p><p>Use a combination of tag filters to create really powerful feeds. For example, Manish, our Founder, created a feed called "<em>Pending Tasks</em>" to monitor our backlog. It tracks <em>any_of</em> <code>p0</code>, <code>p1</code>, and <code>p2</code> tags, while <em>excluding</em> <code>status/resolved</code> tag.</p><p><img alt="Struct app UI featuring discussions between anonymous users whose avatars are in the style of Van Gogh paintings" data-framer-asset="data:framer/asset-reference,kKAfz6DhtgAsDytDuxsl9BS1H0s.webp?originalFilename=blog-launch-tasks_compressed_originalsize.webp" data-framer-height="1796" data-framer-width="3098" height="898" src="https://framerusercontent.com/images/kKAfz6DhtgAsDytDuxsl9BS1H0s.webp" width="1549"></p><h6>User's can tag threads with channels and hashtags to stay organized. </h6><p>Think through all the chat platforms you’ve used in the past. Can you track your entire company’s tasks there? I doubt it. Traditional chat is too chaotic for effective task tracking. Struct aims to bridge this gap, creating an all-in-one solution for team collaboration.</p><h3>Dynamic access control</h3><p>Struct employs a dynamic access control system, unmatched in the chat space. This system allows a thread to belong to one or more channels, or one or more members, or just yourself. More importantly, you can add or remove access at any point in a thread's life.</p><p>This makes threads more versatile than any other platform. A conversation can be accessible to multiple channels to ensure all relevant parties have access. Want to discuss the upcoming premiere of <em>The</em> <em>Three Body Problem</em> with both your <code>@FilmFriends</code> and <code>@BookClub</code>, simply @mention both channels in one thread to chat with both groups, together.</p><p>Looking to adjust your new business contracts? Mention your <code>@legal</code> channel and <code>@derek-the-sales-person</code> in the same thread, pulling in the right people for the job.</p><p>Dynamic access ensures conversations remain targeted and inclusive, removing clutter throughout your organization.</p><h2>Search that<br><em>actually</em> works</h2><p>There's a peculiar kind of agony in knowing precisely where you left something, only to find it inexplicably vanished — a crucial idea now lost to the void. On chat platforms, this is all too familiar: you're haunted by a message you know exists, yet it dodges every attempt at retrieval, leaving sifting through endless, fruitless search results.</p></div><div data-framer-name="Image wrapper - 8" name="Image wrapper - 8"><p data-styles-preset="vBXob0l2T">Find what you need, quickly, with Struct's instant search</p></div><div data-framer-name="text column - 8" data-framer-component-type="RichTextContainer" name="text column - 8"><p>Struct redefines search functionality from the ground up. Our platform leverages advanced search technology, merging the precision of keyword searches and vector embeddings with the intelligence of semantic analysis. This hybrid approach ensures that our search results are not just instant and accurate, but also deeply relevant to your needs.</p><p>With Struct, search is more than a feature — it's a foundation tool to better navigate conversations. Press <code>Cmd/Ctrl+K</code> to quickly find exactly what you're looking for: links, files, chats, all at your fingertips</p><h2>Designed around AI</h2><p>Struct generates a title and summary for every thread, so you can make better decisions on what to skim and what to skip. This empowers everyone involved with context and confidence, making it easier than ever to catch up, follow along, and engage in the conversation at hand. Summaries and titles update in real-time too, evolving as the conversation develops.</p><p><img alt="Struct app UI featuring discussions between anonymous users whose avatars are in the style of Van Gogh paintings" data-framer-asset="data:framer/asset-reference,voF3CGRTJapI2MUWqvj80pkYHxk.webp?originalFilename=blog-launch-thread-summary_compressed_originalsize.webp" data-framer-height="1796" data-framer-width="3098" height="898" src="https://framerusercontent.com/images/voF3CGRTJapI2MUWqvj80pkYHxk.webp" width="1549"></p><h6>AI generated summaries add instant context to every discussion</h6><p>Need answers fast? Structbot is your go-to. Since Struct search indexes past threads, we can leverage past conversations to help provide proactive answers and save you time. Using the power of GPT, Structbot gets the information you need, when you need it, regardless of who's online.&nbsp;</p><p>We use OpenAI's GPT-4 for powering both the threads and the bot. We've found GPT-4 to be the most accurate in our testing.</p><p><img alt="" data-framer-asset="data:framer/asset-reference,YL53w4Kp6X7IwZxHbyOzTZre9o.gif?originalFilename=blog-launch-structbot_1400px.gif" data-framer-height="933" data-framer-width="1400" height="466" src="https://framerusercontent.com/images/YL53w4Kp6X7IwZxHbyOzTZre9o.gif" width="700"></p><h6>Structbot provides instant answer from past references and research</h6><p>Want another life hack? Use Struct instead of using ChatGPT's interface whenever possible. You get the same responses, but now they're co-located with all your other conversations. This means you can reference the bot results together with your peers and further the discussion. Team collaboration meets AI.</p><p>Chatting with GPT doesn't need to be such a lonely affair anymore! Plus, it’d be cheaper than subscribing to ChatGPT individually. Win, win.</p><p>AI is at the core of what we're building a Struct. We’ve got big plans for Structbot, this is only the beginning.</p><h2>Privacy. That's Struct.</h2><p>At Struct, the privacy and permissions of your threads are always paramount. Our platform is designed with the understanding that not every conversation is meant for every eye. Our search functionality and Structbot respect these boundaries. When you search for answers or ask Structbot for help, you'll only see results from threads you're authorized to view. So sensitive information stays with the people it's meant for, guarded from unwanted exposure.</p><p>We also take your data privacy very seriously. Struct is a secure space for your communications.</p><h2>Intelligently designed</h2><p>The Struct app is the result of a meticulous design process, one focused on minimalism and efficiency. Our interface is deliberately subtle to ensure a distraction-free environment for work. It's completely brand-agnostic, free from any disruptive colors or logos.</p><p>We have lots of keyboard shortcuts for fast navigation, and a dark mode to reduce eye strain in low-light environments. We’re also committed to meeting users wherever they are — the app works on Windows, Mac, or Linux.</p></div><div data-framer-name="text column - 9" data-framer-component-type="RichTextContainer" name="text column - 9"><h2>Unleash the power of conversation</h2><p>Our vision for Struct Chat is clear: to create a space where conversations that matter can flourish. We're on a mission to enable better conversations for everyone, and the launch of the Struct Chat Platform marks an exciting step toward that goal. We can't wait for you to experience the difference.</p><p>Welcome to the future of real-time communication.</p><p>Welcome to Struct Chat.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: OfflineLLM – a Vision Pro app running TinyLlama on device (107 pts)]]></title>
            <link>https://apps.apple.com/us/app/offlinellm/id6478590762</link>
            <guid>39557098</guid>
            <pubDate>Fri, 01 Mar 2024 00:33:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apps.apple.com/us/app/offlinellm/id6478590762">https://apps.apple.com/us/app/offlinellm/id6478590762</a>, See on <a href="https://news.ycombinator.com/item?id=39557098">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
<!---->
<!---->
<!---->
    


<!---->
    <section>
      <h2>Screenshots</h2>
  
</section>


  <div dir="" data-test-bidi=""><p>VisionLLM is unlimited, private, offline, 24/7, free access to Ai. Augment your day to day life by using this Ai chat-bot for a multiplicity of applications.</p><p>This app gives you unlimited, offline and private use of a powerful Ai chat-bot. Start using the powerful local LLM by downloading the Ai model in the Settings page. It will only take a few seconds to download. Create a new chat by clicking 'New Chat.'  Next click on the new chat tab. Start the conversation by entering your message using your voice input or by typing. Next press the send button with the paper plane icon. The Ai responds in a few seconds. Delete any chat by long pressing on the tab, and then pressing 'Delete' button. On the settings page you can view which large language model is being used. </p></div>

<!---->
<!---->
<!---->
<!---->
<!---->
<!---->
  <section>
  <div>
    <h2>
      App Privacy
    </h2>

    


  </div>

  <p>
    The developer, <span>Konrad Gnat</span>, indicated that the app’s privacy practices may include handling of data as described below. For more information, see the <a href="https://konradgnat.notion.site/OfflineLLM-Privacy-Policy-ef25de96515c414d8a2f704ee28b17e1?pvs=4">developer’s privacy policy</a>.
  </p>

  <div>
        
        <h3>Data Not Collected</h3>
        <p>The developer does not collect any data from this app.</p>
<!---->      </div>

    <p>Privacy practices may vary, for example, based on the features you use or your age. <a href="https://apps.apple.com/story/id1538632801">Learn&nbsp;More</a></p>
</section>


<section>
  <div>
    <h2>Information</h2>
    <dl>
        <p>
          <dt>Seller</dt>
          <dd>
              Konrad Gnat
          </dd>
        </p>
        <p>
          <dt>Size</dt>
          <dd aria-label="6.5 megabytes">6.5 MB</dd>
        </p>
        <p>
          <dt>Category</dt>
          <dd>
              <a href="https://itunes.apple.com/us/genre/id6017" data-metrics-click="{&quot;actionType&quot;:&quot;navigate&quot;,&quot;actionUrl&quot;:&quot;https://itunes.apple.com/us/genre/id6017&quot;,&quot;targetType&quot;:&quot;link&quot;,&quot;targetId&quot;:&quot;GenrePage&quot;}">
                Education
              </a>
          </dd>
        </p>
      <div>
        <dt>Compatibility</dt>
          <dd>
              <dl>
                <dt>
                  Apple Vision
                </dt>
                <dd>Requires visionOS 1.0 or later.
                </dd>
              </dl>
          </dd>
      </div>
<!---->      
      <p>
        <dt>Age Rating</dt>
        <dd>
             17+
<!---->        </dd>
      </p>
<!---->      <p>
        <dt>Copyright</dt>
        <dd>© Synducer LLC.</dd>
      </p>
        <p>
          <dt>Price</dt>
          <dd>$6.99</dd>
        </p>
<!---->
    </dl>
  </div>
  <div>
    <ul>
<!---->        <li>
          <a data-metrics-click="{&quot;actionType&quot;:&quot;navigate&quot;,&quot;targetType&quot;:&quot;link&quot;,&quot;targetId&quot;:&quot;LinkToAppSupport&quot;}" href="https://konradgnat.notion.site/OfflineLLM-Privacy-Policy-ef25de96515c414d8a2f704ee28b17e1?pvs=74">
            App Support
          </a>
        </li>
        <li>
          <a data-metrics-click="{&quot;actionType&quot;:&quot;navigate&quot;,&quot;targetType&quot;:&quot;link&quot;,&quot;targetId&quot;:&quot;LinkToPrivacyPolicy&quot;}" href="https://konradgnat.notion.site/OfflineLLM-Privacy-Policy-ef25de96515c414d8a2f704ee28b17e1?pvs=4">
            Privacy Policy
          </a>
        </li>
<!----><!---->    </ul>
  </div>
</section>

<section>
  <ul>
<!---->      <li>
        <a data-metrics-click="{&quot;actionType&quot;:&quot;navigate&quot;,&quot;targetType&quot;:&quot;link&quot;,&quot;targetId&quot;:&quot;LinkToAppSupport&quot;}" href="https://konradgnat.notion.site/OfflineLLM-Privacy-Policy-ef25de96515c414d8a2f704ee28b17e1?pvs=74">
          App Support
        </a>
      </li>
<!---->      <li>
        <a data-metrics-click="{&quot;actionType&quot;:&quot;navigate&quot;,&quot;targetType&quot;:&quot;link&quot;,&quot;targetId&quot;:&quot;LinkToPrivacyPolicy&quot;}" href="https://konradgnat.notion.site/OfflineLLM-Privacy-Policy-ef25de96515c414d8a2f704ee28b17e1?pvs=4">
          Privacy Policy
        </a>
      </li>
  </ul>
</section>

  <section>
    <p>
      <h2>Supports</h2>
    </p>
    <ul>
        <li>
          <img src="https://apps.apple.com/assets/images/supports/supports-FamilySharing@2x-f58f31bc78fe9fe7be3565abccbecb34.png" alt="" role="presentation">
          <div>
              <h3 dir="ltr">
    Family Sharing
</h3>


              <h4 dir="">
        

                    <p data-test-bidi="">Up to six family members can use this app with Family&nbsp;Sharing enabled.</p>

    


<!----></h4>


          </div>
        </li>
    </ul>
  </section>

<!---->
    <section>
      <p>
        <h2>
          More By This Developer
        </h2>
        <!---->
      </p>

      <div>
            
    
            <a href="https://apps.apple.com/us/app/inlight-meditation-timer/id1590699795" aria-label="InLight Meditation Timer. Health &amp; Fitness." data-metrics-click="{&quot;actionType&quot;:&quot;navigate&quot;,&quot;actionUrl&quot;:&quot;https://apps.apple.com/us/app/inlight-meditation-timer/id1590699795&quot;,&quot;targetType&quot;:&quot;card&quot;,&quot;targetId&quot;:&quot;1590699795&quot;}" data-metrics-location="{&quot;locationType&quot;:&quot;shelfDeveloperOtherApps&quot;}">
<!---->        <div>
            <picture dir="ltr" id="ember2642">

        <source srcset="https://is1-ssl.mzstatic.com/image/thumb/Purple122/v4/fe/6f/89/fe6f8908-8d7c-9f32-79e6-3e6b5106edf5/AppIcon-0-1x_U007emarketing-0-10-0-85-220.png/320x0w.webp 320w, https://is1-ssl.mzstatic.com/image/thumb/Purple122/v4/fe/6f/89/fe6f8908-8d7c-9f32-79e6-3e6b5106edf5/AppIcon-0-1x_U007emarketing-0-10-0-85-220.png/157x0w.webp 157w, https://is1-ssl.mzstatic.com/image/thumb/Purple122/v4/fe/6f/89/fe6f8908-8d7c-9f32-79e6-3e6b5106edf5/AppIcon-0-1x_U007emarketing-0-10-0-85-220.png/146x0w.webp 146w, https://is1-ssl.mzstatic.com/image/thumb/Purple122/v4/fe/6f/89/fe6f8908-8d7c-9f32-79e6-3e6b5106edf5/AppIcon-0-1x_U007emarketing-0-10-0-85-220.png/640x0w.webp 640w, https://is1-ssl.mzstatic.com/image/thumb/Purple122/v4/fe/6f/89/fe6f8908-8d7c-9f32-79e6-3e6b5106edf5/AppIcon-0-1x_U007emarketing-0-10-0-85-220.png/314x0w.webp 314w, https://is1-ssl.mzstatic.com/image/thumb/Purple122/v4/fe/6f/89/fe6f8908-8d7c-9f32-79e6-3e6b5106edf5/AppIcon-0-1x_U007emarketing-0-10-0-85-220.png/292x0w.webp 292w" sizes="(max-width: 734px) 320px, (min-width: 735px) and (max-width: 1068px) 157px, 146px" type="image/webp">

      <source srcset="https://is1-ssl.mzstatic.com/image/thumb/Purple122/v4/fe/6f/89/fe6f8908-8d7c-9f32-79e6-3e6b5106edf5/AppIcon-0-1x_U007emarketing-0-10-0-85-220.png/320x0w.png 320w, https://is1-ssl.mzstatic.com/image/thumb/Purple122/v4/fe/6f/89/fe6f8908-8d7c-9f32-79e6-3e6b5106edf5/AppIcon-0-1x_U007emarketing-0-10-0-85-220.png/157x0w.png 157w, https://is1-ssl.mzstatic.com/image/thumb/Purple122/v4/fe/6f/89/fe6f8908-8d7c-9f32-79e6-3e6b5106edf5/AppIcon-0-1x_U007emarketing-0-10-0-85-220.png/146x0w.png 146w, https://is1-ssl.mzstatic.com/image/thumb/Purple122/v4/fe/6f/89/fe6f8908-8d7c-9f32-79e6-3e6b5106edf5/AppIcon-0-1x_U007emarketing-0-10-0-85-220.png/640x0w.png 640w, https://is1-ssl.mzstatic.com/image/thumb/Purple122/v4/fe/6f/89/fe6f8908-8d7c-9f32-79e6-3e6b5106edf5/AppIcon-0-1x_U007emarketing-0-10-0-85-220.png/314x0w.png 314w, https://is1-ssl.mzstatic.com/image/thumb/Purple122/v4/fe/6f/89/fe6f8908-8d7c-9f32-79e6-3e6b5106edf5/AppIcon-0-1x_U007emarketing-0-10-0-85-220.png/292x0w.png 292w" sizes="(max-width: 734px) 320px, (min-width: 735px) and (max-width: 1068px) 157px, 146px" type="image/png">

      <img src="https://apps.apple.com/assets/artwork/1x1-42817eea7ade52607a760cbee00d1495.gif" decoding="async" loading="lazy" alt="" role="presentation" height="320" width="320">


  
</picture>

          
          
        </div>

    
</a>


        



      </div>
    </section>

<!---->

<!---->

<!----></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Predictive text using only 13kb of JavaScript. no LLM (119 pts)]]></title>
            <link>https://www.adamgrant.info/tiny-predictive-text</link>
            <guid>39556956</guid>
            <pubDate>Fri, 01 Mar 2024 00:11:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.adamgrant.info/tiny-predictive-text">https://www.adamgrant.info/tiny-predictive-text</a>, See on <a href="https://news.ycombinator.com/item?id=39556956">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Functional ownership through fractional uniqueness (107 pts)]]></title>
            <link>https://arxiv.org/abs/2310.18166</link>
            <guid>39555675</guid>
            <pubDate>Thu, 29 Feb 2024 21:52:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2310.18166">https://arxiv.org/abs/2310.18166</a>, See on <a href="https://news.ycombinator.com/item?id=39555675">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2310.18166.pdf">Download PDF</a></p><blockquote>
            <span>Abstract:</span>Ownership and borrowing systems, designed to enforce safe memory management without the need for garbage collection, have been brought to the fore by the Rust programming language. Rust also aims to bring some guarantees offered by functional programming into the realm of performant systems code, but the type system is largely separate from the ownership model, with type and borrow checking happening in separate compilation phases. Recent models such as RustBelt and Oxide aim to formalise Rust in depth, but there is less focus on integrating the basic ideas into more traditional type systems. An approach designed to expose an essential core for ownership and borrowing would open the door for functional languages to borrow concepts found in Rust and other ownership frameworks, so that more programmers can enjoy their benefits.
<br>One strategy for managing memory in a functional setting is through uniqueness types, but these offer a coarse-grained view: either a value has exactly one reference, and can be mutated safely, or it cannot, since other references may exist. Recent work demonstrates that linear and uniqueness types can be combined in a single system to offer restrictions on program behaviour and guarantees about memory usage. We develop this connection further, showing that just as graded type systems like those of Granule and Idris generalise linearity, Rust's ownership model arises as a graded generalisation of uniqueness. We combine fractional permissions with grading to give the first account of ownership and borrowing that smoothly integrates into a standard type system alongside linearity and graded types, and extend Granule accordingly with these ideas.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Daniel Marshall [<a href="https://arxiv.org/show-email/7bdb258c/2310.18166">view email</a>]      <br>            <strong><a href="https://arxiv.org/abs/2310.18166v1">[v1]</a></strong>
        Fri, 27 Oct 2023 14:22:00 UTC (70 KB)<br>
    <strong>[v2]</strong>
        Thu, 15 Feb 2024 11:10:11 UTC (77 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Things You Should Never Do, Part I (2000) (135 pts)]]></title>
            <link>https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/</link>
            <guid>39555598</guid>
            <pubDate>Thu, 29 Feb 2024 21:46:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/">https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/</a>, See on <a href="https://news.ycombinator.com/item?id=39555598">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p>Netscape 6.0 is finally going into its first public beta. There never was a version 5.0. The last major release, version 4.0, was released almost three years ago. Three years is an <i>awfully</i> long time in the Internet world. During this time, Netscape sat by, helplessly, as their market share plummeted.</p>
<p>It’s a bit smarmy of me to criticize them for waiting so long between releases. They didn’t do it <i>on purpose</i>, now, did they?</p>
<p>Well, yes. They did. They did it by making the <b>single worst strategic mistake</b> that any software company can make:</p>
<p><img decoding="async" src="https://i0.wp.com/www.joelonsoftware.com/wp-content/uploads/2000/04/Upper_West_Side_Brownstones_2.jpg?w=730&amp;ssl=1" data-recalc-dims="1">They decided to rewrite the code from scratch.</p>
<p>Netscape wasn’t the first company to make this mistake. Borland made the same mistake when they bought Arago and tried to make it into dBase for Windows, a doomed project that took so long that Microsoft Access ate their lunch, then they made it again in rewriting Quattro Pro from scratch and astonishing people with how few features it had. Microsoft almost made the same mistake, trying to rewrite Word for Windows from scratch in a doomed project called Pyramid which was shut down, thrown away, and swept under the rug. Lucky for Microsoft, they had never stopped working on the old code base, so they had something to ship, making it merely a financial disaster, not a strategic one.</p>
<p>We’re programmers. Programmers are, in their hearts, architects, and the first thing they want to do when they get to a site is to bulldoze the place flat and build something grand. We’re not excited by incremental renovation: tinkering, improving, planting flower beds.</p>
<p>There’s a subtle reason that programmers always want to throw away the code and start over. The reason is that they think the old code is a mess. And here is the interesting observation: <i>they are probably wrong.</i> The reason that they think the old code is a mess is because of a cardinal, fundamental law of programming:</p>
<p>It’s harder to read code than to write it.</p>
<p>This is why code reuse is so hard. This is why everybody on your team has a different function they like to use for splitting strings into arrays of strings. They write their own function because it’s easier and more fun than figuring out how the old function works.</p>
<p><img decoding="async" src="https://i0.wp.com/www.joelonsoftware.com/wp-content/uploads/2000/04/Columbus_Ave_Barber_Shop.jpg?w=730&amp;ssl=1" data-recalc-dims="1">As a corollary of this axiom, you can ask almost any programmer today about the code they are working on. “It’s a big hairy mess,” they will tell you. “I’d like nothing better than to throw it out and start over.”</p>
<p>Why is it a mess?</p>
<p>“Well,” they say, “look at this function. It is two pages long! None of this stuff belongs in there! I don’t know what half of these API calls are for.” </p>
<p>Before Borland’s new spreadsheet for Windows shipped, Philippe Kahn, the colorful founder of Borland, was quoted a lot in the press bragging about how Quattro Pro would be much better than Microsoft Excel, because it was written from scratch. All new source code! As if source code <i>rusted</i>.</p>
<p>The idea that new code is better than old is patently absurd. Old code has been <i>used</i>. It has been <i>tested</i>. <i>Lots</i> of bugs have been found, and they’ve been <i>fixed</i>. There’s nothing wrong with it. It doesn’t acquire bugs just by sitting around on your hard drive. Au contraire, baby! Is software supposed to be like an old Dodge Dart, that rusts just sitting in the garage? Is software like a teddy bear that’s kind of gross if it’s not made out of <i>all new material</i>?</p>
<p>Back to that two page function. Yes, I know, it’s just a simple function to display a window, but it has grown little hairs and stuff on it and nobody knows why. Well, I’ll tell you why: those are bug fixes. One of them fixes that bug that Nancy had when she tried to install the thing on a computer that didn’t have Internet Explorer. Another one fixes that bug that occurs in low memory conditions. Another one fixes that bug that occurred when the file is on a floppy disk and the user yanks out the disk in the middle. That LoadLibrary call is ugly but it makes the code work on old versions of Windows 95.</p>
<p>Each of these bugs took weeks of real-world usage before they were found. The programmer might have spent a couple of days reproducing the bug in the lab and fixing it. If it’s like a lot of bugs, the fix might be one line of code, or it might even be a couple of characters, but a lot of work and time went into those two characters.</p>
<p>When you throw away code and start from scratch, you are throwing away all that knowledge. All those collected bug fixes. Years of programming work.</p>
<p>You are throwing away your market leadership. You are giving a gift of two or three years to your competitors, and believe me, that is a <i>long</i> time in software years.</p>
<p>You are putting yourself in an extremely dangerous position where you will be shipping an old version of the code for several years, completely unable to make any strategic changes or react to new features that the market demands, because you don’t have shippable code. You might as well just close for business for the duration.</p>
<p>You are wasting an outlandish amount of money writing code that already exists.</p>
<p><img decoding="async" src="https://i0.wp.com/www.joelonsoftware.com/wp-content/uploads/2000/04/Columbus_Ave.jpg?w=730&amp;ssl=1" data-recalc-dims="1"></p>
<p>Is there an alternative? The consensus seems to be that the old Netscape code base was <i>really </i>bad. Well, it might have been bad, but, you know what? It worked pretty darn well on an awful lot of real world computer systems.</p>
<p>When programmers say that their code is a holy mess (as they always do), there are three kinds of things that are wrong with it.</p>
<p>First, there are architectural problems. The code is not factored correctly. The networking code is popping up its own dialog boxes from the middle of nowhere; this should have been handled in the UI code. These problems can be solved, one at a time, by carefully moving code, refactoring, changing interfaces. They can be done by one programmer working carefully and checking in his changes all at once, so that nobody else is disrupted. Even fairly major architectural changes can be done without <i>throwing away the code</i>. On the Juno project we spent several months rearchitecting at one point: just moving things around, cleaning them up, creating base classes that made sense, and creating sharp interfaces between the modules. But we did it carefully, with our existing code base, and we didn’t introduce new bugs or throw away working code.</p>
<p>A second reason programmers think that their code is a mess is that it is inefficient. The rendering code in Netscape was rumored to be slow. But this only affects a small part of the project, which you can optimize or even rewrite. You don’t have to rewrite the whole thing. When optimizing for speed, 1% of the work gets you 99% of the bang.</p>
<p>Third, the code may be doggone ugly. One project I worked on actually had a data type called a FuckedString. Another project had started out using the convention of starting member variables with an underscore, but later switched to the more standard “m_”. So half the functions started with “_” and half with “m_”, which looked ugly. Frankly, this is the kind of thing you solve in five minutes with a macro in Emacs, not by starting from scratch.</p>
<p>It’s important to remember that when you start from scratch there is <b>absolutely no reason</b> to believe that you are going to do a better job than you did the first time. First of all, you probably don’t even have the same programming team that worked on version one, so you don’t actually have “more experience”. You’re just going to make most of the old mistakes again, and introduce some new problems that weren’t in the original version. </p>
<p><img decoding="async" src="https://i0.wp.com/www.joelonsoftware.com/wp-content/uploads/2008/01/Lincoln_Center_Trees.jpg?w=730&amp;ssl=1" data-recalc-dims="1">The old mantra <i>build one to throw away</i> is dangerous when applied to large scale commercial applications. If you are writing code experimentally, you may want to rip up the function you wrote last week when you think of a better algorithm. That’s fine. You may want to refactor a class to make it easier to use. That’s fine, too. But throwing away the whole program is a dangerous folly, and if Netscape actually had some adult supervision with software industry experience, they might not have shot themselves in the foot so badly.</p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Defcon: Preventing overload with graceful feature degradation (2023) (214 pts)]]></title>
            <link>https://www.micahlerner.com/2023/07/23/defcon-preventing-overload-with-graceful-feature-degradation.html</link>
            <guid>39554874</guid>
            <pubDate>Thu, 29 Feb 2024 20:50:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.micahlerner.com/2023/07/23/defcon-preventing-overload-with-graceful-feature-degradation.html">https://www.micahlerner.com/2023/07/23/defcon-preventing-overload-with-graceful-feature-degradation.html</a>, See on <a href="https://news.ycombinator.com/item?id=39554874">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="post-content">
<p><a href="https://www.usenix.org/conference/osdi23/presentation/meza">Defcon: Preventing Overload with Graceful Feature Degradation</a></p>
<p><em>This is one in a series of papers I’m reading from OSDI and Usenix ATC. These paper reviews can be <a href="https://newsletter.micahlerner.com/">delivered weekly to your inbox</a>, or you can subscribe to the <a href="https://www.micahlerner.com/feed.xml">Atom feed</a>. As always, feel free to reach out on <a href="https://twitter.com/micahlerner">Twitter</a> with feedback or suggestions!</em></p>
<h2 id="what-is-the-research">What is the research?</h2>
<p>Severe outages can occur due to system overload<label for="load"></label><span>Discussion of managing load <a href="https://sre.google/workbook/managing-load/">from the SRE book here</a>. </span>, impacting users who rely on a product, and potentially damaging underlying hardware<label for="failslow"></label><span>Damage to hardware can show up as <em>fail-slow</em> situations, where performance degrades overtime. This is also discussed in a previous paper review on <a href="https://www.micahlerner.com/2023/04/16/perseus-a-fail-slow-detection-framework-for-cloud-storage-systems.html">Perseus: A Fail-Slow Detection Framework for Cloud Storage Systems</a> </span>. It can also be difficult to recover from outages involving overloaded system due to additional problems this type of outages cause - in particular, <a href="https://sre.google/sre-book/addressing-cascading-failures/">cascading failures</a>. There are many potential root-causes to a system entering an overloaded state, including seasonal traffic spikes, performance regressions consuming excess capacity<label for="metastable"></label><span>This situation can lead to metastable failures, as discussed in a previous <a href="https://www.micahlerner.com/2022/07/11/metastable-failures-in-the-wild.html">paper review</a>. </span>, or subtle software bugs. As such, limiting the damage caused by overload conditions is a complicated problem.</p>
<p>To prevent overload from impacting its products, Meta developed a system called <em>Defcon</em>. Defcon provides a set of abstractions that allows incident responders to increase available capacity by turning off features, an idea called <em>graceful feature degradation</em>. By dividing product features into different levels of business criticality, Defcon also allows oncallers to take a variety actions depending on the severity of an ongoing incident.</p>
<figure><img src="https://www.micahlerner.com/assets/defcon/figure1.png"><figcaption></figcaption></figure>
<figure><img src="https://www.micahlerner.com/assets/defcon/figure2.png"><figcaption></figcaption></figure>
<p>The Defcon paper describes Meta’s design, implementation, and experience deploying this system at scale across many products (including Facebook, Messenger, Instagram, and Whatsapp) along with lessons from usage during production incidents.</p>
<h2 id="background-and-motivation">Background and Motivation</h2>
<p>The authors of Defcon describe several alternatives they considered when deciding how to mitigate the risk of system overload. Each of the options is evaluated on the amount of additional resources that the approach would consume during an incident, the amount of engineering effort required to implement, and the potential impact to users.</p>
<figure><img src="https://www.micahlerner.com/assets/defcon/table1.png"><figcaption></figcaption></figure>
<p>Given that serious overload events happen on a recurring basis (at least once a year), the authors decided to invest engineering resources in an engineering-intensive effort capable of limiting user impact.</p>
<h2 id="how-does-the-system-work">How does the system work?</h2>
<p>The core abstraction in Defcon is the <em>knob</em>, which represents for each feature: a unique name, whether a feature is turned on or not, the oncall rotation responsible, and a “level” corresponding to business-criticality.</p>
<figure><img src="https://www.micahlerner.com/assets/defcon/listing1.png"><figcaption></figcaption></figure>
<figure><img src="https://www.micahlerner.com/assets/defcon/features.png"><figcaption></figcaption></figure>
<p>After a feature is defined using this configuration, servers or applications (for example, in Web or iOS devices) import the knob into code and implement code paths that handle cases when the <em>knob</em> is turned off - for example, short-circuiting expensive logic.</p>
<figure><img src="https://www.micahlerner.com/assets/defcon/listing2.png"><figcaption></figcaption></figure>
<p>During testing and incident response, operators change a <em>knob</em>’s state via a command-line or user interface, and Defcon handles replicating this state to impacted consumers (like servers and mobile applications). Knob state is also stored in a database.</p>
<figure><img src="https://www.micahlerner.com/assets/defcon/figure3.png"><figcaption></figcaption></figure>
<p>Defcon’s <em>Knob Actuator Service</em> propagates state changes for two types of knobs: <em>server-side knobs</em> and <em>client-side knobs</em>:</p>
<blockquote>
<p><em>Server-side knobs</em> are implemented in binaries running on the servers in data centers. The advantage of server-side knobs is that we can adjust the knobs’ state in seconds without any propagation delays.</p>
</blockquote>
<blockquote>
<p><em>Client-side knobs</em> are implemented in client code running on phones, tablets, wearables, and so on. The advantage of client-side knobs is that they have the capability to reduce network load by stopping requests sent to the server along side reducing server load due to the request.</p>
</blockquote>
<p>Client-side knobs (like those in an iOS application) are slightly more complex to update. Under normal conditions, they change via a push (called <em>Silent Push Notification (SPN)</em>) or routine pull (<em>Mobile Configuration Pull</em>) mechanism. To handle extenuating circumstances (like lower latency response to severe outages), Defcon can also instruct clients to pull a broader set of configuration stored in a specific server-location using a process called <em>Emergency Mobile Configuration</em><label for="serious"></label><span>Under normal operating conditions, a full reset isn’t used because it has the tradeoff of using more resources (in particular networking), which is unfriendly to user mobile plans and device batteries. </span>.</p>
<p>Knobs are, “grouped into three categories: (1) By service name, (2) by product name, and (3) by feature name (such as “search,” “video,” “feed,” and so on)” to simplify testing during development and post-release. Testing occurs through small scale A/B tests (where one “experiment arm” of users experience feature degradation, and the “control” arm does not) and during larger exercises that ensure the Defcon system is working (described later in the paper). These tests also have the side effect of generating data on what capacity a feature or product is using, which serves as an input to capacity planning.</p>
<p>During incidents, oncallers can also use the output of these tests to understand what the potential implications are of turning off different knobs. The</p>
<figure><img src="https://www.micahlerner.com/assets/defcon/figure4.png"><figcaption></figcaption></figure>
<h2 id="how-is-the-research-evaluated">How is the research evaluated?</h2>
<p>The paper uses three main types of datasets to quantify Defcon’s changes:</p>
<ul>
<li><em>Real-time Monitoring System (RMS)</em> and <em>Resource Utilization Metric (RUM)</em>, which aim to measure utilization of Meta infrastructure. The specifics of which one to use depends on the experiment, as discussed below.</li>
<li><em>Transitive Resource Utilization (TRU)</em>, which aims to measure the downstream utilization that a service has of shared Meta systems (like its graph infrastructure described in my previous paper review on <a href="https://www.micahlerner.com/2021/10/13/tao-facebooks-distributed-data-store-for-the-social-graph.html">TAO: Facebook’s Distributed Data Store for the Social Graph</a>).</li>
<li><em>User Behavior Measurement (UBM)</em>, which tracks how changing a knob’s state impacts business metrics like “Video Watch Time”.</li>
</ul>
<p>The first evaluation of Defcon’s impact is at the Product-level. By turning off progressively more business-critical functionality, the system makes greater impact on Meta’s resource usage<label for="mips"></label><span>Represented with <em>mega-instructions per second (MIPS)</em>, a normalized resource representation corresponding to compute. </span>. Entirely turning off critical features (aka “Defcon Level 1”), saves a large amount of capacity, but also significantly impacts critical business metrics.</p>
<figure><img src="https://www.micahlerner.com/assets/defcon/figure8.png"><figcaption></figcaption></figure>
<figure><img src="https://www.micahlerner.com/assets/defcon/table2.png"><figcaption></figcaption></figure>
<p>Defcon is next evaluated for its ability to temporarily decrease capacity required of shared infrastructure. As discussed in a previous paper review of <a href="https://www.micahlerner.com/2021/05/31/scaling-memcache-at-facebook.html">Scaling Memcache at Facebook</a>, Meta uses Memcache extensively. By turning off optional features, oncallers are able to decrease load on this type of core system.</p>
<figure><img src="https://www.micahlerner.com/assets/defcon/figure9.png"><figcaption></figcaption></figure>
<p>Next, the research describes how Meta can decrease capacity requirements by turning off knobs in upstream systems with dependencies on other Meta products. For example, turning off Instagram-level knobs decreases load on Facebook, which ultimately depends on TAO, Meta’s graph service. Testing knobs outside of incident response surfaces resource requirements from these interdependencies.</p>
<figure><img src="https://www.micahlerner.com/assets/defcon/figure12.png"><figcaption></figcaption></figure>
<p>The Defcon paper describes a protocol for forcing Meta systems into overload conditions, and testing the impact of turning progressively more business-critical features off. By ramping user traffic to a datacenter, these experiments place increasing load on infrastructure - turning knobs off then alleviates load.</p>
<figure><img src="https://www.micahlerner.com/assets/defcon/figure15.png"><figcaption></figcaption></figure>
<h2 id="conclusion">Conclusion</h2>
<p>The Defcon paper describes a framework deployed at scale in Meta for disabling features in order to mitigate overload conditions. To reach this state, the authors needed to solve technical challenges of building the system and to collaborate with product teams to define feature criticality - in some ways, the latter seems even more difficult. The paper also mentions issues with maintainability of knobs. On this front, it seems like future work could automate the process of ensuring that knobs cover features inside of deployed code. Lastly, I’m looking forward to learning more about Defon’s integration with other recently published Meta research, like <a href="https://www.usenix.org/conference/osdi23/presentation/eriksen">the company’s capacity management system</a>.</p>

</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Did you encounter any leap year bugs today? (464 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=39554539</link>
            <guid>39554539</guid>
            <pubDate>Thu, 29 Feb 2024 20:22:43 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=39554539">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="39554915"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39554915" href="https://news.ycombinator.com/vote?id=39554915&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Heard from a friend in China: the age calculation portion of the app to schedule a marriage certificate had a bug where they subtracted 22 (legal minimum age) from the year, which resulted in 2002-02-29 which doesn't exist. The app intends to compare this against the user's birth date. The error handling code assumes all errors are from the comparison. The app then rejected all marriage certificate appointments by complaining that the users are too young to marry legally.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39555513"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39555513" href="https://news.ycombinator.com/vote?id=39555513&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Haha, that would be quite the appropriate place to put one of those "Please wait and try again" error messages.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39556338"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39556338" href="https://news.ycombinator.com/vote?id=39556338&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>Now that you mention it, the payment system was not working in a ski resort restaurant in Switzerland this noon.<p>They had to switch to cash.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39555303"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555303" href="https://news.ycombinator.com/vote?id=39555303&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Yes, I have a bot that posts daily San Francisco weather records to Mastodon. It did not post as scheduled today. This is because I am looking at all the high temperatures, low temperatures, and precipitation on today's date from 1875 (about as far back as there are digitized weather records I can work with) to the present. Since there was no such date as February 29, 1875 it is throwing an error.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39554969"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39554969" href="https://news.ycombinator.com/vote?id=39554969&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>No, but some of our software writes data to rotating directories named after the date, and while doing some manual debugging on a test system, it started failing to create these directories the first time it rotated on Feb 29 UTC. Turns out it just happened to run out of disk space at that time, but I had myself convinced that it was a leap year bug for over an hour. :)</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39554867"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39554867" href="https://news.ycombinator.com/vote?id=39554867&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>Yes.<p>&gt; During the morning on Thursday, no ICA store in Sweden could accept card payments. Instead, you had to use cash, Swish or pay via their app.</p><p>&gt; The reason behind the problem was an internal problem in the payment systems at ICA as a result of an extra day in February, leap day.</p><p>ICA being the biggest grocery store chain in Sweden
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39555019"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555019" href="https://news.ycombinator.com/vote?id=39555019&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>This one is rather specific, but a game rhythm based Final Fantasy game called Theatrhythm Final Bar Line is simply not allowing people to play today because it has an internal system that awards prizes for specific days and they didn't handle the case of what to do when it's on a leap day. You can boot it up but can't actually play the game as a result.<p>Not working on the game or anything but found it moderately amusing as someone who owns the game!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39556252"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39556252" href="https://news.ycombinator.com/vote?id=39556252&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>We have a product that uses ChatGPT via the API, using the 3.5 turbo version.  Our query involves some dates.  Instead of giving back text like it usually does, today it has been giving errors because it does not think 2024-02-29 is a valid date.<p>This is easy to reproduce with the web interface, at least sometimes [0].  It start out by saying it's not a valid date and then as it's explaining why it isn't it realizes its mistake and sometimes corrects itself.</p><p>[0] <a href="https://chat.openai.com/share/37490c9f-81d6-499f-b491-11653682856c" rel="nofollow">https://chat.openai.com/share/37490c9f-81d6-499f-b491-116536...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39556318"><td></td></tr>
            <tr id="39554815"><td></td></tr>
                <tr id="39555818"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39555818" href="https://news.ycombinator.com/vote?id=39555818&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>I'm sure it's more complicated than "we didn't think about leap years", but it certainly sounds pretty amateurish.<p>Old programmer rant: In my day, we fixed the Y2K bug - we went to the future and back several times a day!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39555430"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555430" href="https://news.ycombinator.com/vote?id=39555430&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>The other way around! Today a few services that don't congratulate me on my birthday (on non-leap years) did. I was born on February 29th.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39556153"><td></td></tr>
                  <tr id="39555199"><td></td></tr>
            <tr id="39556299"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39556299" href="https://news.ycombinator.com/vote?id=39556299&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>I had a few [datetime].replace(year=[current year]+n) in python where n is not divisble by 4 e.g. 2,10<p>This is in code we use for scheduling
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39556119"><td></td></tr>
                <tr id="39556331"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39556331" href="https://news.ycombinator.com/vote?id=39556331&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>These ones are the worst because you'd think they'd be so obvious at time of implementation. Maybe it's just me, I do a lot of comparisons and things like this always are top of mind for me.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39554791"><td></td></tr>
                <tr id="39555167"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39555167" href="https://news.ycombinator.com/vote?id=39555167&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>That's more of a design decision than a bug. It's intentional to make the product cheaper. The manual does mention it.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39554924"><td></td></tr>
                <tr id="39556196"><td></td></tr>
            <tr id="39555139"><td></td></tr>
                <tr id="39556059"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39556059" href="https://news.ycombinator.com/vote?id=39556059&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>Are you sure? My F91W doesn't even ask for year in settings. How would have it known it is a leap year or not.<p>Some other models (not F91W) does track year.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39556159"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_39556159" href="https://news.ycombinator.com/vote?id=39556159&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>I was responding to the claim about the Samsung Watch not showing the right date, I unfortunately have never owned the older kinds of "smartwatches" :)</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="39555153"><td></td></tr>
                  <tr id="39555319"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39555319" href="https://news.ycombinator.com/vote?id=39555319&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>I noticed this too and clicked this thread wondering if it would show up! Still an awesome watch.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39555046"><td></td></tr>
                  <tr id="39555407"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555407" href="https://news.ycombinator.com/vote?id=39555407&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>I certainly did. There is a batch process to cull old records. It checks for customers who do not have a date of death recorded but are &gt; 130 years old, as it assumes that we weren't informed of their death.<p>It takes 130 years from the current date and uses that in an SQL statement to compares it to the date of birth. DB2 doesn't like 1894-02-29.</p><p>Apparently it happens every 4 years, but no-one can be bothered to fix it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39554758"><td></td></tr>
            <tr id="39554787"><td></td></tr>
                <tr id="39556157"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39556157" href="https://news.ycombinator.com/vote?id=39556157&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>What happens in a situation like this? Does the staff issue physical keys? Do the doors even have manual locks? Do the staff walk every body to their room?</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39554943"><td></td></tr>
            <tr id="39554674"><td></td></tr>
                <tr id="39554976"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39554976" href="https://news.ycombinator.com/vote?id=39554976&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>It's not that python doesn't have a clean way to subtract a year, it's that "subtract a year" is imprecise. There's a clean way to subtract 365 days, and there's a clean way to set the year one year earlier. But if you're doing the second thing, is python supposed to silently change to March 1 when you change the year from a leap day? There's no way around handling edge cases.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39555103"><td></td></tr>
                  <tr id="39554853"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39554853" href="https://news.ycombinator.com/vote?id=39554853&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>What is your definition of "subtracting a year"? Seems like that's a relatively ambiguous operation without more specification.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39554964"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39554964" href="https://news.ycombinator.com/vote?id=39554964&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Can you think of any situation where subtracting a year from today's date is ambiguous when today isn't, well, today?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39556179"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39556179" href="https://news.ycombinator.com/vote?id=39556179&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>Moving bank/festive holidays, first Monday of the year(, first work day of the year not Monday if that's NYD and bank holiday), lunar occasions.<p>'subtract a year' is imprecise and has many meanings, if what you want is 'same day, same month, previous year' then say that and do that, that's conceptually `date.year -= 1` not `date -= 1 year`, and will have this bug.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39555345"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39555345" href="https://news.ycombinator.com/vote?id=39555345&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Yes - on any day, subtracting a year might mean subtracting the average length of a year (which is a bit more than 365 days), or wanting the same day and month number in the previous calendar year, or wanting the same semantic difference ("last Monday of the month in January"), to name a few possible meanings.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39555652"><td></td></tr>
                  <tr id="39554958"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39554958" href="https://news.ycombinator.com/vote?id=39554958&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Since they mentioned a clean up script, I assume they could easily just use 365 days for that use case.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39555068"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39555068" href="https://news.ycombinator.com/vote?id=39555068&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>But then it'll be off by one day for the rest of this year.  And someone will notice that they no longer have March 1 2023-March 1 2024 in their chart, but March 2 2023</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39556284"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_39556284" href="https://news.ycombinator.com/vote?id=39556284&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>It's a cleanup script. I bet nobody cares it's off by one day. Also I doubt a cleanup script has a charting function.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="39555178"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39555178" href="https://news.ycombinator.com/vote?id=39555178&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>&gt; now.replace(year=now.year-1)<p>Yeah but this is bad code. Python certainly does have a "clean" way to subtract a year, you subtract a datetime.timedelta object.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39555346"><td></td></tr>
            <tr id="39554992"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39554992" href="https://news.ycombinator.com/vote?id=39554992&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Okay I am having really odd undefined behavior in Python in UART communications that were working just fine yesterday... My boss joked it could be a leap year thing but at this point it wouldn't surprise me. Switch over to using Rust and no issues at all</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39555220"><td></td></tr>
                  <tr id="39555106"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555106" href="https://news.ycombinator.com/vote?id=39555106&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>I can understand getting the years 2000 (leap), 2100 (not leap), 2200 (not leap), and 2300 (not leap) wrong. But getting the year 2024 wrong is, disappointing, to put it diplomatically.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39555680"><td></td></tr>
                  <tr id="39556328"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39556328" href="https://news.ycombinator.com/vote?id=39556328&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>I did, actually!<p>A couple date form fields on AWS had their date incorrectly set to 2024/02/28 instead of 2024/02/29. Not mission critical, but it is something :D.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39556138"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39556138" href="https://news.ycombinator.com/vote?id=39556138&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Gusto paycheck didn't come in until a lot later than usual... thought this might have been my last day on the job for a little bit, didn't help that my manager and I's one on one was my first meeting of the day heh.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39555733"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555733" href="https://news.ycombinator.com/vote?id=39555733&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Our ETL process is heavily monitored so we never miss a days data, but we got a surprising error "cant build aggregates - missing data, aborting MV refresh, data will be a day old".
It was the year to date (YTD) calculation - no data for 29/2/2023 to compare to today.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39556173"><td></td></tr>
                <tr id="39556273"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39556273" href="https://news.ycombinator.com/vote?id=39556273&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Frankly unless you've considered it ahead of time and thought you'd handled it, IMO you want the error. What's the correct thing to do here? I don't think it's necessarily -365d, it might be, but if I was GP I'd be glad for the chance to consider it and decide what's correct - instead of it just blowing up or even worse silently going whichever way's wrong and undetected for a while.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="39554866"><td></td></tr>
            <tr id="39554995"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39554995" href="https://news.ycombinator.com/vote?id=39554995&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Python.<pre><code>    cls = &lt;class 'datetime.datetime'&gt;, data_string = 'Feb 29 04:55:03.687' format = '%b %d %H:%M:%S.%f'
    E       ValueError: day is out of range for month</code></pre></span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39555127"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39555127" href="https://news.ycombinator.com/vote?id=39555127&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>That doesn’t seem incorrect;  given that no year is specified, it seems like it’s evaluating the constraint in the context of an implicit default year. (1970? 0CE?)<p>The confusing part, to me, is that Python would consider the above string to be parsed into a date in the first place, given that it has no year.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39555848"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39555848" href="https://news.ycombinator.com/vote?id=39555848&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>As mentioned by sibling comments, it's because you're not specifying a year. If you change the day to the 28th you'll see that it defaults to the year 1900:<pre><code>  &gt;&gt;&gt; datetime.strptime('Feb 28 04:55:03.687', '%b %d %H:%M:%S.%f')
  datetime.datetime(1900, 2, 28, 4, 55, 3, 687000)

  &gt;&gt;&gt; datetime.strptime('Feb 28 13:37:06.942', '%b %d %H:%M:%S.%f') 
  datetime.datetime(1900, 2, 28, 13, 37, 6, 942000)</code></pre></span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39556222"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39556222" href="https://news.ycombinator.com/vote?id=39556222&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>That makes it weird though, because 1900 <i>was</i> a leap year? I sort of get it, but it's a slightly odd and inconsistent decision.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39556333"><td></td></tr>
            <tr id="39556316"><td></td></tr>
                        <tr id="39555098"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39555098" href="https://news.ycombinator.com/vote?id=39555098&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Interesting... I suppose that is because there is no year? What year does it default to? Can you show your exact line of code?</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39555149"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39555149" href="https://news.ycombinator.com/vote?id=39555149&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>confirmed. and interesting/unexpected! this breaks:<p>datetime.strptime('Feb 29 13:37:06.942', '%b %d %H:%M:%S.%f')</p><p>edit: added code example. import datetime from datetime first obvi
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39555156"><td></td></tr>
                  <tr id="39554935"><td></td></tr>
            <tr id="39554826"><td></td></tr>
            <tr id="39554831"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39554831" href="https://news.ycombinator.com/vote?id=39554831&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Payroll software at work had a one-off planned maintenance day today, presumably to avoid worrying about any bugs.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39555635"><td></td></tr>
            <tr id="39554925"><td></td></tr>
                  <tr id="39555298"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555298" href="https://news.ycombinator.com/vote?id=39555298&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>My suite failed this morning on an obscure test of a function that converts between ages and dates of birth. Took me ten minutes of head scratching before I realised it was Feb 29th.<p>’’’
+       if time.Now().Month() == time.February &amp;&amp; time.Now().Day() == 29 {
+               t.SkipNow()
+       }
’’’</p><p>Fixed.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39555255"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555255" href="https://news.ycombinator.com/vote?id=39555255&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>We got a bunch of close-dated yogurt the other day.<p>Several were best by 2-27, 2-28, 3-01, and 3-02, but none by 2-29.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39555397"><td></td></tr>
                  <tr id="39555092"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555092" href="https://news.ycombinator.com/vote?id=39555092&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Yes, a few mildly bad things go wrong on a feb 29th. Everything that handles stuff a year from now for example. Pretty bad for a planning program. But our customers noticed and avoided that. Codebase is too ancient and brittle to even attempt to fix. Or at least boss doesn't want to invest time in it.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39555185"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555185" href="https://news.ycombinator.com/vote?id=39555185&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Yes, in T-Mobile billing, I tried to set up automatic payments on the 26th, but the system both told me that this was impossible (because it was "less than 2 days from the end of the month") and then accepted it, because why wouldn't it.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39554803"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39554803" href="https://news.ycombinator.com/vote?id=39554803&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>One of the largest food store chains in Sweden had their entire card payment go down because someone forgot to handle leap years!</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39554902"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39554902" href="https://news.ycombinator.com/vote?id=39554902&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>Wikipedia says they are "the second largest retail company in the Nordic countries[citation needed]". Pretty big company anyway and embarrassing for them. Would love to learn more about what the bug was, but I guess they will never say.<p><a href="https://en.wikipedia.org/wiki/ICA_AB" rel="nofollow">https://en.wikipedia.org/wiki/ICA_AB</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39554955"><td></td></tr>
                <tr id="39555801"><td></td></tr>
                        <tr id="39555015"><td></td></tr>
                  <tr id="39556102"><td></td></tr>
            <tr id="39555186"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555186" href="https://news.ycombinator.com/vote?id=39555186&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Yes - I triple-checked the calendar to verify my suspicion this February might have 29 days. The result was always negative - it seemed 28. Then February the 29th actually came. A bug apparently occurred in my mind.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39556250"><td></td></tr>
            <tr id="39554772"><td></td></tr>
                <tr id="39555011"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39555011" href="https://news.ycombinator.com/vote?id=39555011&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Every time I go to timeanddate.com I feel like I see a link to the Leap Day page (<a href="https://www.timeanddate.com/date/leap-day.html" rel="nofollow">https://www.timeanddate.com/date/leap-day.html</a>) that shows the meme-infamous boyfriend-checking-out-another-girl couple, except she's proposing to him!  Obviously this happened earlier that day since they're wearing the same outfits, and I can't help but feel bad for her knowing what's coming but unable to warn of the impending train wreck.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39554948"><td></td></tr>
                <tr id="39556202"><td></td></tr>
                  <tr id="39556193"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39556193" href="https://news.ycombinator.com/vote?id=39556193&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>I'll take a February 30 if it means every other month is 30 days too, and we just get the extra days as universal, extended winter holiday where no one can legally be required to work because there is no December 31st or January minus-fourth.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39555182"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555182" href="https://news.ycombinator.com/vote?id=39555182&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>My monthly bus passes for both February and March did not work in Dallas today. The driver was aware of the issue and just waved me in.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39554763"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39554763" href="https://news.ycombinator.com/vote?id=39554763&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>The mcdonalds order waiting thing malfunctioned, displayed de52hg04 instead of 088 and I had to wait a lot longer for my order since it flew under the radar for a while until I spoke to them :)</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39554792"><td></td></tr>
            <tr id="39554673"><td></td></tr>
            <tr id="39555856"><td></td></tr>
            <tr id="39555189"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555189" href="https://news.ycombinator.com/vote?id=39555189&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Just AFTER reading about Casio watches in this thread I looked at mine. Sure it displays the date as March 1.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39554636"><td></td></tr>
                <tr id="39554813"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39554813" href="https://news.ycombinator.com/vote?id=39554813&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>Not directly related to leap year, but a couple weeks ago I set up a script for testing notification behavior that used libfaketime to simulate runs at different times.<p>I guess this might be less-trivial if you've got a distributed multi-service architecture and perhaps also depend on APIs that aren't under your control in the first place.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39555864"><td></td></tr>
                  <tr id="39554780"><td></td></tr>
                <tr id="39554952"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39554952" href="https://news.ycombinator.com/vote?id=39554952&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>In a few hours you'll be able to backdate to "yesterday", with very low chances of hitting cert expiry issues (but I wouldn't be surprised if OP's issue involves components outside of their control or ability to test end-to-end)</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39555385"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39555385" href="https://news.ycombinator.com/vote?id=39555385&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>I should have written something along the lines of "validity date ranges" instead of expiration: you're much more likely to run into problems where you run into a certificate that was issued in the future relative to when you think is now.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="39555044"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555044" href="https://news.ycombinator.com/vote?id=39555044&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Maybe? My paycheck direct deposit didn't show up until almost 7am. Normally it hits right at midnight.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39555090"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39555090" href="https://news.ycombinator.com/vote?id=39555090&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>One of the most common QA test cases when it comes to testing date and time sensitive applications.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39556255"><td></td></tr>
            <tr id="39555299"><td></td></tr>
            <tr id="39554856"><td></td></tr>
            <tr id="39556099"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39556099" href="https://news.ycombinator.com/vote?id=39556099&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>I am gald that in excel, deleting a day from March 1st automatically gives Feb 29 or 28 depending on the year in formula. Before that, I struggled a lot to find last day of month by tracking if its a leap year or not, and keeping an array of months &amp; number of days. Now I simply add 1 to month, and from resulting daye I subtract 1 day. The Date value of that gives me 31 or 30 or 29 or 28.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39556227"><td></td></tr>
            <tr id="39555232"><td></td></tr>
                <tr id="39556209"><td></td></tr>
            <tr id="39555336"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39555336" href="https://news.ycombinator.com/vote?id=39555336&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><br><div>
                  <p><span>Because programmers take shortcuts. Its easier to type x - 365 than to import Calendar and then date(x) - timedelta(1 year).</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39554720"><td></td></tr>
            <tr id="39554996"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39554996" href="https://news.ycombinator.com/vote?id=39554996&amp;how=up&amp;goto=item%3Fid%3D39554539"></a></center>    </td><td><p><span>My Casio F91W I assumed would know that year YYYY is leap, and would show 29th as Date. No, it showed 1 as in March (it doesn't show months). I had to manually set it back to 28th so that tomorrow it shows correct date.<p>To be fair, it doesn't ask for year anywhere in settings. It simply doesn't know what year it is.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GGUF, the Long Way Around (221 pts)]]></title>
            <link>https://vickiboykis.com/2024/02/28/gguf-the-long-way-around/</link>
            <guid>39553967</guid>
            <pubDate>Thu, 29 Feb 2024 19:36:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vickiboykis.com/2024/02/28/gguf-the-long-way-around/">https://vickiboykis.com/2024/02/28/gguf-the-long-way-around/</a>, See on <a href="https://news.ycombinator.com/item?id=39553967">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><figure><img src="https://github.com/veekaybee/veekaybee.github.io/assets/3837836/dbbb8ee7-f19f-44df-bce7-2612817cacd2" width="400"></figure><p><strong>Table of Contents</strong></p><ul><li><a href="#how-we-use-llm-artifacts">How We Use LLM Artifacts</a></li><li><a href="#what-is-a-machine-learning-model">What is a machine learning model</a><ul><li><a href="#starting-with-a-simple-model">Starting with a simple model</a></li></ul></li><li><a href="#writing-the-model-code">Writing the model code</a><ul><li><a href="#instantiating-the-model-object">Instantiating the model object</a></li><li><a href="#serializing-our-objects">Serializing our objects</a></li></ul></li><li><a href="#what-is-a-file">What is a file</a></li><li><a href="#how-does-pytorch-write-objects-to-files">How does PyTorch write objects to files?</a><ul><li><a href="#how-pickle-works">How Pickle works</a></li><li><a href="#from-pickle-to-safetensors">From pickle to safetensors</a></li><li><a href="#how-safetensors-works">How safetensors works</a></li><li><a href="#checkpoint-files">Checkpoint files</a></li><li><a href="#ggml">GGML</a></li><li><a href="#finally-gguf">Finally, GGUF</a></li></ul></li><li><a href="#conclusion">Conclusion</a></li></ul><h2 id="how-we-use-llm-artifacts">How We Use LLM Artifacts</h2><p>Large language models today are <a href="https://vickiboykis.com/2024/01/15/whats-new-with-ml-in-production/">consumed in one of several ways</a>:</p><ol><li>As API endpoints for proprietary models hosted by OpenAI, Anthropic, or major cloud providers</li><li>As model artifacts downloaded from HuggingFace’s Model Hub and/or trained/fine-tuned using HuggingFace libraries and hosted on local storage</li><li>As model artifacts available in a format optimized for local inference, typically GGUF, and accessed via applications like <code>llama.cpp</code> or <code>ollama</code></li><li>As <a href="https://onnx.ai/">ONNX</a>, a format which optimizes sharing between backend ML frameworks</li></ol><p>For a side project, I’m using <code>llama.cpp</code>, a <code>C/C++</code>-based LLM inference engine targeting <a href="https://github.com/ggerganov/llama.cpp/discussions/4167">M-series GPUs on Apple Silicon</a>.</p><p>When running <code>llama.cpp</code>, you get a long log that consists primarily of key-value pairs of metadata about your model architecture and then its performance (and <a href="https://twitter.com/vboykis/status/1751307750712156662">no yapping</a>).</p><div><pre tabindex="0"><code data-lang="bash"><span><span>make -j <span>&amp;&amp;</span> ./main -m /Users/vicki/llama.cpp/models/mistral-7b-instruct-v0.2.Q8_0.gguf -p <span>"What is Sanremo? no yapping"</span>
</span></span><span><span>
</span></span><span><span>Sanremo Music Festival <span>(</span>Festival di Sanremo<span>)</span> is an annual Italian music competition held in the city of Sanremo since 1951. It<span>'</span>s considered one of the most prestigious and influential events in the Italian music scene. The festival features both newcomers and established artists competing <span>for</span> various awards, including the Big Award <span>(</span>Gran Premio<span>)</span>, which grants the winner the right to represent Italy in the Eurovision Song Contest. The event consists of several live shows where artists perform their original songs, and a jury composed of musicians, critics, and the public determines the winners through a combination of points. <span>[</span>end of text<span>]</span>
</span></span><span><span>
</span></span><span><span>llama_print_timings:        load time <span>=</span>   11059.32 ms
</span></span><span><span>llama_print_timings:      sample time <span>=</span>      11.62 ms /   <span>140</span> runs   <span>(</span>    0.08 ms per token, 12043.01 tokens per second<span>)</span>
</span></span><span><span>llama_print_timings: prompt eval time <span>=</span>      87.81 ms /    <span>10</span> tokens <span>(</span>    8.78 ms per token,   113.88 tokens per second<span>)</span>
</span></span><span><span>llama_print_timings:        eval time <span>=</span>    3605.10 ms /   <span>139</span> runs   <span>(</span>   25.94 ms per token,    38.56 tokens per second<span>)</span>
</span></span><span><span>llama_print_timings:       total time <span>=</span>    3730.78 ms /   <span>149</span> tokens
</span></span><span><span>ggml_metal_free: deallocating
</span></span><span><span>Log end
</span></span></code></pre></div><p>These logs can be found in the <code>Llama.cpp</code> codebase. There, you’ll also find GGUF. <a href="https://github.com/ggerganov/ggml/blob/master/docs/gguf.md">GGUF (GPT-Generated Unified Format)</a> is the file format used to serve models on <code>Llama.cpp</code> and other local runners like <a href="https://semaphoreci.com/blog/local-llm">Llamafile, Ollama and GPT4All.</a></p><p>To understand how GGUF works, we need to first take a deep dive into machine learning models and the kinds of artifacts they produce.</p><h2 id="what-is-a-machine-learning-model">What is a machine learning model</h2><p>Let’s start by describing a machine learning model. At its simplest, a model is a file or a collection of files that contain the model architecture and weights and biases of the model generated from a training loop.</p><p>In LLM land, we’re generally interested in <a href="https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/">transformer-style models and architectures.</a></p><p>In a transformer, we have many moving parts.</p><ul><li><strong>For the input</strong>, we use <a href="https://arxiv.org/abs/2310.20707">training data corpuses aggregated from human-generated nautural language content</a></li><li>For <strong>the algorithm</strong>, we<ul><li>Convert that data <a href="https://vickiboykis.com/what_are_embeddings/">into embeddings</a></li><li><a href="https://d2l.ai/chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html#positional-encoding">Positionally encoding the embeddings</a> to provide information about where the words are in relation to each other in the sequence</li><li>Creating multi-headed <a href="https://ai.stackexchange.com/a/43892">self-attention</a> for each word in relation to each other word in the sequence based on an initialized combinations of weights</li><li><a href="https://arxiv.org/abs/2302.06461">Normalize layers via softmax</a></li><li>Run the resulting matrix through a feedfoward neural network</li><li>Project the output into the correct vector space for the desired task</li><li>Calculate loss and then update model parameters</li></ul></li><li><strong>The output</strong>: Generally for for chat completions tasks, <a href="https://arxiv.org/abs/2311.17301">the model returns the statistical likelihood</a> that any given word completes a phrase. It does this again and again for every word in the phrase, because of its autoregressive nature.</li></ul><figure><img src="https://github.com/veekaybee/veekaybee.github.io/assets/3837836/86da416b-c6d8-4fb7-abf9-fcd2a80a1614" width="400"></figure><a href="https://arxiv.org/abs/2311.17301">Source.</a><p>If the model is served as a consumer end-product, it only returns the actual text output based on the highest probabilities, with numerous strategies for <a href="https://huggingface.co/blog/how-to-generate">how that text is selected.</a></p><figure><img src="https://github.com/veekaybee/veekaybee.github.io/assets/3837836/cb311adb-79f3-4eea-85be-7329e4aeb111" width="600"></figure><p>In short, we convert inputs to outputs using an equation. In addition to the model’s output, we also have the model itself that is generated as an artifact of the modeling process.</p><figure><img src="https://github.com/veekaybee/veekaybee.github.io/assets/3837836/67102dbc-d049-4131-997a-df1fa5378f91" width="600"></figure><h2 id="starting-with-a-simple-model">Starting with a simple model</h2><p>Let’s take a step back from the complexity of transformers and build a small linear regression model in PyTorch. Lucky for us, <a href="https://d2l.ai/chapter_linear-regression/index.html">linear regression is also</a> a (shallow) neural network, so we can work with it in PyTorch and map our simple model to more complex ones using the same framework.</p><p>Linear regression takes a set of numerical inputs and generates a set of numerical outputs. (In contrast to transformers, which take a set of text inputs and generates a set of text inputs and their related numerical probabilities.)</p><p>For example, let’s say that we produce <a href="https://www.greatitalianchefs.com/features/hazelnuts-piedmont">artisinal hazlenut spread</a> for statisticians, and want to predict how many jars of Nulltella we’ll produce on any given day. Let’s say we have some data available to us, and that is, how many hours of sunshine we have per day, and how many jars of Nulltella we’ve been able to produce every day.</p><figure><img src="https://github.com/veekaybee/veekaybee.github.io/assets/3837836/66ca00e6-1baf-4eb0-9d3d-112966beb797" width="200"></figure><p>It turns out that we feel more inspired to produce hazlenut spread when it’s sunny out, and we can clearly see this relationship between input and output in our data (we do not produce Nulltella Friday-Sunday because we prefer to spend those days writing about data serialization formats):</p><pre tabindex="0"><code>| day_id | hours   | jars |
|--------|---------|------|
| mon    | 1       | 2    |
| tues   | 2       | 4    |
| wed    | 3       | 6    |
| thu    | 4       | 8    |
</code></pre><p>This is the data we’ll use to train our model. We’ll need to split this data into three parts:</p><ol><li>used to train our model (training data)</li><li>used to test the accuracy of our model (test data)</li><li>used to tune our hyperparameters, meta-aspects of our model like the <a href="https://en.wikipedia.org/wiki/Learning_rate">learning rate</a>, (validation set) during the model training phase.</li></ol><p>In the specific case of linear regression, there technically are no hyperparameters, although we can plausibly consider the learning rate we set in PyTorch to be one. Let’s assume we have 100 of these data points values.</p><p>We split the data into train, test, and validation. A <a href="https://onlinelibrary.wiley.com/doi/full/10.1002/sam.11583">usual accepted split</a> is to use 80% of data for training/validation and 20% for testing. We want our model to have access to as much data as possible so it learns a more accurate representation, so we leave most data for train.</p><p>Now that we have our data, we need to write our algorithm. The equation to get output \(Y\) from inputs \(X\) for linear regression is:</p><p>$$y = \beta_0 + \beta_1 x_1 + \varepsilon $$</p><p>This tells us that the output, \(y\) (the number of jars of Nulltella), can be predicted by:</p><ul><li>\(x_1\) - one input variable (or feature), (hours of sunshine)</li><li>\(\beta_1\) - with its given weight, also called parameters, (how important that feature is)</li><li>plus an error term \(\varepsilon\) that is the difference between the observed and actual values in a population that captures the noise of the model</li></ul><p>Our task is to continuously predict and adjust our weights to optimally solve this equation for the difference between our actual \(Y\) as presented by our data and a predicted \(\hat Y\) based on the algorithm to find the smallest sum of squared differences, \(\sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}\), between each point and the line. In other words, we’d like to minimize \(\varepsilon\), because it will mean that, at each point, our \(\hat Y\) is as close to our actual \(Y\) as we can get it, given the other points.</p><p>We optimize this function <a href="https://arxiv.org/abs/1609.04747">through gradient descent</a>, where we start with either zeros or randomly-initialized weights and continue recalculating both the weights and error term until we come to an optimal stopping point.
We’ll know we’re succeeding because our loss, as calculated by RMSE should incrementally decrease in every training iteration.</p><p>Here’s the whole model learning process end-to-end (with the exception of tokenization, which we only do for models where features are text and we want to do language modeling):</p><figure><img src="https://github.com/veekaybee/veekaybee.github.io/assets/3837836/9f8fb4b8-4b19-45e2-bb04-7657e447d42f" width="600"></figure><h2 id="writing-the-model-code">Writing the model code</h2><p>Now, let’s get more concrete and describe these ideas in code. When we train our model, we initialize our function with a set of feature values.</p><p>Let’s add our data into the model by initializing both \(x_1\) and \(Y\) as <a href="https://pytorch.org/docs/stable/tensors.html">PyTorch Tensor objects</a>.</p><div><pre tabindex="0"><code data-lang="python"><span><span>
</span></span><span><span><span># Hours of sunshine</span>
</span></span><span><span>X <span>=</span> torch<span>.</span>tensor([[<span>1.0</span>], [<span>2.0</span>], [<span>3.0</span>], [<span>4.0</span>]], dtype<span>=</span>torch<span>.</span>float32)
</span></span><span><span>
</span></span><span><span><span># Jars of Nulltella</span>
</span></span><span><span>y <span>=</span> torch<span>.</span>tensor([[<span>2.0</span>], [<span>4.0</span>], [<span>6.0</span>], [<span>8.0</span>]], dtype<span>=</span>torch<span>.</span>float32)
</span></span></code></pre></div><p>Within code, our input data is <code>X</code>, which is a torch tensor object, and our output data is <code>y</code>. We initialize a LinearRegression which subclasses the PyTorch Module, with one linear layer, which has one input feature (sunshine) and one output feature (jars of Nulltella).</p><p>I’m going to include the code for the whole model, and then we’ll talk through it piece by piece.</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> torch
</span></span><span><span><span>import</span> torch.nn <span>as</span> nn
</span></span><span><span><span>import</span> torch.optim <span>as</span> optim
</span></span><span><span>
</span></span><span><span>X <span>=</span> torch<span>.</span>tensor([[<span>1.0</span>], [<span>2.0</span>], [<span>3.0</span>], [<span>4.0</span>]], dtype<span>=</span>torch<span>.</span>float32)
</span></span><span><span>y <span>=</span> torch<span>.</span>tensor([[<span>2.0</span>], [<span>4.0</span>], [<span>6.0</span>], [<span>8.0</span>]], dtype<span>=</span>torch<span>.</span>float32)
</span></span><span><span>
</span></span><span><span><span># Define a linear regression model and its forward pass </span>
</span></span><span><span><span>class</span> <span>LinearRegression</span>(nn<span>.</span>Module):
</span></span><span><span>    <span>def</span> __init__(self):
</span></span><span><span>        super(LinearRegression, self)<span>.</span>__init__()
</span></span><span><span>        self<span>.</span>linear <span>=</span> nn<span>.</span>Linear(<span>1</span>, <span>1</span>)  <span># 1 input feature, 1 output feature</span>
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>forward</span>(self, x):
</span></span><span><span>        <span>return</span> self<span>.</span>linear(x)
</span></span><span><span>
</span></span><span><span><span># Instantiate the model</span>
</span></span><span><span>model <span>=</span> LinearRegression()
</span></span><span><span>
</span></span><span><span><span># Inspect the model's state dictionary</span>
</span></span><span><span>print(model<span>.</span>state_dict())
</span></span><span><span>
</span></span><span><span><span># Define loss function and optimizer</span>
</span></span><span><span>criterion <span>=</span> nn<span>.</span>MSELoss() 
</span></span><span><span><span># setting our learning rate "hyperparameter" here</span>
</span></span><span><span>optimizer <span>=</span> optim<span>.</span>SGD(model<span>.</span>parameters(), lr<span>=</span><span>0.01</span>)  
</span></span><span><span>
</span></span><span><span><span># Training loop that includes forward and backward pass </span>
</span></span><span><span>num_epochs <span>=</span> <span>100</span>
</span></span><span><span><span>for</span> epoch <span>in</span> range(num_epochs):
</span></span><span><span>    <span># Forward pass</span>
</span></span><span><span>    outputs <span>=</span> model(X)
</span></span><span><span>    loss <span>=</span> criterion(outputs, y)
</span></span><span><span>    RMSE_loss  <span>=</span> torch<span>.</span>sqrt(loss)
</span></span><span><span>
</span></span><span><span>    <span># Backward pass and optimization</span>
</span></span><span><span>    optimizer<span>.</span>zero_grad()  <span># Zero out gradients</span>
</span></span><span><span>    RMSE_loss<span>.</span>backward()  <span># Compute gradients</span>
</span></span><span><span>    optimizer<span>.</span>step()  <span># Update weights</span>
</span></span><span><span>
</span></span><span><span>    <span># Print progress</span>
</span></span><span><span>    <span>if</span> (epoch<span>+</span><span>1</span>) <span>%</span> <span>10</span> <span>==</span> <span>0</span>:
</span></span><span><span>        print(<span>f</span><span>'Epoch [</span><span>{</span>epoch<span>+</span><span>1</span><span>}</span><span>/</span><span>{</span>num_epochs<span>}</span><span>], Loss: </span><span>{</span>loss<span>.</span>item()<span>:</span><span>.4f</span><span>}</span><span>'</span>)
</span></span><span><span>
</span></span><span><span><span># After training, let's test the model</span>
</span></span><span><span>test_input <span>=</span> torch<span>.</span>tensor([[<span>5.0</span>]], dtype<span>=</span>torch<span>.</span>float32)
</span></span><span><span>predicted_output <span>=</span> model(test_input)
</span></span><span><span>print(<span>f</span><span>'Prediction for input </span><span>{</span>test_input<span>.</span>item()<span>}</span><span>: </span><span>{</span>predicted_output<span>.</span>item()<span>}</span><span>'</span>)
</span></span></code></pre></div><p>Once we have our input data, we then initialize our model, a <code>LinearRegression</code> which subclasses <a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html">Module base class</a> specifically for <a href="https://github.com/pytorch/pytorch/blob/372d078f361e726bb4ac0884ac334b04c58179ef/torch/nn/modules/linear.py#L49">linear regression.</a></p><p>A forward pass involves feeding our data into the neural network and making sure it propogagtes through all the layers. Since we only have one, we have to pass our data to a single linear layer. The forward pass is what calculates our predicted <code>Y</code>.</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>class</span> <span>LinearRegression</span>(nn<span>.</span>Module):
</span></span><span><span>    <span>def</span> __init__(self):
</span></span><span><span>        super(LinearRegression, self)<span>.</span>__init__()
</span></span><span><span>        self<span>.</span>linear <span>=</span> nn<span>.</span>Linear(<span>1</span>, <span>1</span>)  <span># 1 input feature, 1 output feature</span>
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>forward</span>(self, x):
</span></span><span><span>        <span>return</span> self<span>.</span>linear(x)
</span></span></code></pre></div><p>We pick how we’d like to optimize the results of the model, aka how its loss should converge. In this case, we start with <code>mean squared error</code>, and then modify it to use <code>RMSE</code>, the square root of the average squared difference between the predicted values and the actual values in a dataset.</p><div><pre tabindex="0"><code data-lang="python"><span><span><span># Define loss function and optimizer</span>
</span></span><span><span>criterion <span>=</span> torch<span>.</span>sqrl(nn<span>.</span>MSELoss())  <span># RMSE in the training loop</span>
</span></span><span><span>optimizer <span>=</span> optim<span>.</span>SGD(model<span>.</span>parameters(), lr<span>=</span><span>0.01</span>)
</span></span><span><span>
</span></span><span><span><span>....</span>
</span></span><span><span><span>for</span> epoch <span>in</span> range(num_epochs):
</span></span><span><span>    <span># Forward pass</span>
</span></span><span><span>    outputs <span>=</span> model(X)
</span></span><span><span>    loss <span>=</span> criterion(outputs, y)
</span></span><span><span>    RMSE_loss  <span>=</span> torch<span>.</span>sqrt(loss)
</span></span></code></pre></div><p>Now that we’ve defined how we’d like the model to run, we can instantiate the model object itself:</p><h2 id="instantiating-the-model-object">Instantiating the model object</h2><div><pre tabindex="0"><code data-lang="python"><span><span>model <span>=</span> LinearRegression()
</span></span><span><span>print(model<span>.</span>state_dict())
</span></span></code></pre></div><p>Notice that when we instantiate a <code>nn.Module</code>, it has an attribute called the “state_dict”. This is important. <a href="https://pytorch.org/tutorials/recipes/recipes/what_is_state_dict.html">The state dict</a> holds the information about each layer and the parameters in each layer, aka the weights and biases.</p><p>At its heart, <a href="https://github.com/pytorch/pytorch/blob/637cf4a3f2cfdd364005681636ca885bdc4d5887/torch/nn/modules/module.py#L1842">it’s a Python dictionary.</a></p><p>In this case, the implementation for LinearRegression returns an ordered dict with each layer of the network and values of those layers. Each of the values is a <code>Tensor</code>.</p><div><pre tabindex="0"><code data-lang="python"><span><span>OrderedDict([(<span>'linear.weight'</span>, tensor([[<span>0.5408</span>]])), (<span>'linear.bias'</span>, tensor([<span>-</span><span>0.8195</span>]))])
</span></span><span><span>
</span></span><span><span><span>for</span> param_tensor <span>in</span> model<span>.</span>state_dict():
</span></span><span><span>    print(param_tensor, <span>"</span><span>\t</span><span>"</span>, model<span>.</span>state_dict()[param_tensor]<span>.</span>size())
</span></span><span><span>
</span></span><span><span>linear<span>.</span>weight    torch<span>.</span>Size([<span>1</span>, <span>1</span>])
</span></span><span><span>linear<span>.</span>bias      torch<span>.</span>Size([<span>1</span>])
</span></span></code></pre></div><p>For our tiny model, it’s a small <code>OrderedDict</code> of tuples. You can imagine that this collection of tensors becomes extremely large and memory-intensive in a large network such as a transformer. If each parameter (each Tensor object) takes up 2 bytes in memory, <a href="https://github.com/ray-project/llm-numbers?tab=readme-ov-file#2x-number-of-parameters-typical-gpu-memory-requirements-of-an-llm-for-serving">a 7-billion parameter model can take up 14GB in GPU.</a></p><p>We then run the forward and backward passes for the model in loops. In each step, we do a forward pass to perform the calculation, a backward pass to update the weights of our model object, and then we add all that information to our model parameters.</p><div><pre tabindex="0"><code data-lang="python"><span><span><span># Define loss function and optimizer</span>
</span></span><span><span>criterion <span>=</span> nn<span>.</span>MSELoss() 
</span></span><span><span>optimizer <span>=</span> optim<span>.</span>SGD(model<span>.</span>parameters(), lr<span>=</span><span>0.01</span>)  
</span></span><span><span>
</span></span><span><span><span># Training loop </span>
</span></span><span><span>num_epochs <span>=</span> <span>100</span>
</span></span><span><span><span>for</span> epoch <span>in</span> range(num_epochs):
</span></span><span><span>    <span># Forward pass</span>
</span></span><span><span>    outputs <span>=</span> model(X)
</span></span><span><span>    loss <span>=</span> criterion(outputs, y)
</span></span><span><span>    RMSE_loss  <span>=</span> torch<span>.</span>sqrt(loss)
</span></span><span><span>
</span></span><span><span>    <span># Backward pass and optimization</span>
</span></span><span><span>    optimizer<span>.</span>zero_grad()  <span># Zero out gradients</span>
</span></span><span><span>    RMSE_loss<span>.</span>backward()  <span># Compute gradients</span>
</span></span><span><span>    optimizer<span>.</span>step()  <span># Update weights</span>
</span></span><span><span>
</span></span><span><span>    <span># Print progress</span>
</span></span><span><span>    <span>if</span> (epoch<span>+</span><span>1</span>) <span>%</span> <span>10</span> <span>==</span> <span>0</span>:
</span></span><span><span>        print(<span>f</span><span>'Epoch [</span><span>{</span>epoch<span>+</span><span>1</span><span>}</span><span>/</span><span>{</span>num_epochs<span>}</span><span>], Loss: </span><span>{</span>loss<span>.</span>item()<span>:</span><span>.4f</span><span>}</span><span>'</span>)
</span></span></code></pre></div><p>Once we’ve completed these loops, we’ve trained the model artifact. What we now have once we have trained a model is an in-memory object that represents the weights, biases, and metadata of that model, stored within our instance of our <code>LinearRegression</code> module.</p><p>As we run the training loop, we can see our loss shrink. That is, the actual values are getting closer to the predicted:</p><div><pre tabindex="0"><code data-lang="python"><span><span>Epoch [<span>10</span><span>/</span><span>100</span>], Loss: <span>33.0142</span>
</span></span><span><span>Epoch [<span>20</span><span>/</span><span>100</span>], Loss: <span>24.2189</span>
</span></span><span><span>Epoch [<span>30</span><span>/</span><span>100</span>], Loss: <span>16.8170</span>
</span></span><span><span>Epoch [<span>40</span><span>/</span><span>100</span>], Loss: <span>10.8076</span>
</span></span><span><span>Epoch [<span>50</span><span>/</span><span>100</span>], Loss: <span>6.1890</span>
</span></span><span><span>Epoch [<span>60</span><span>/</span><span>100</span>], Loss: <span>2.9560</span>
</span></span><span><span>Epoch [<span>70</span><span>/</span><span>100</span>], Loss: <span>1.0853</span>
</span></span><span><span>Epoch [<span>80</span><span>/</span><span>100</span>], Loss: <span>0.4145</span>
</span></span><span><span>Epoch [<span>90</span><span>/</span><span>100</span>], Loss: <span>0.3178</span>
</span></span><span><span>Epoch [<span>100</span><span>/</span><span>100</span>], Loss: <span>0.2974</span>
</span></span></code></pre></div><p>We can also see if we print out the <code>state_dict</code> that the parameters have changed as we’ve computed the gradients and updated the weights in the backward pass:</p><div><pre tabindex="0"><code data-lang="python"><span><span>
</span></span><span><span><span>"""before"""</span>
</span></span><span><span>OrderedDict([(<span>'linear.weight'</span>, tensor([[<span>-</span><span>0.6216</span>]])), (<span>'linear.bias'</span>, tensor([<span>0.7633</span>]))])
</span></span><span><span>linear<span>.</span>weight    torch<span>.</span>Size([<span>1</span>, <span>1</span>])
</span></span><span><span>linear<span>.</span>bias      torch<span>.</span>Size([<span>1</span>])
</span></span><span><span>{<span>'state'</span>: {}, <span>'param_groups'</span>: [{<span>'lr'</span>: <span>0.01</span>, <span>'momentum'</span>: <span>0</span>, <span>'dampening'</span>: <span>0</span>, <span>'weight_decay'</span>: <span>0</span>, <span>'nesterov'</span>: <span>False</span>, <span>'maximize'</span>: <span>False</span>, <span>'foreach'</span>: <span>None</span>, <span>'differentiable'</span>: <span>False</span>, <span>'params'</span>: [<span>0</span>, <span>1</span>]}]}
</span></span><span><span>Epoch [<span>10</span><span>/</span><span>100</span>], Loss: <span>33.0142</span>
</span></span><span><span>Epoch [<span>20</span><span>/</span><span>100</span>], Loss: <span>24.2189</span>
</span></span><span><span>Epoch [<span>30</span><span>/</span><span>100</span>], Loss: <span>16.8170</span>
</span></span><span><span>Epoch [<span>40</span><span>/</span><span>100</span>], Loss: <span>10.8076</span>
</span></span><span><span>Epoch [<span>50</span><span>/</span><span>100</span>], Loss: <span>6.1890</span>
</span></span><span><span>Epoch [<span>60</span><span>/</span><span>100</span>], Loss: <span>2.9560</span>
</span></span><span><span>Epoch [<span>70</span><span>/</span><span>100</span>], Loss: <span>1.0853</span>
</span></span><span><span>Epoch [<span>80</span><span>/</span><span>100</span>], Loss: <span>0.4145</span>
</span></span><span><span>Epoch [<span>90</span><span>/</span><span>100</span>], Loss: <span>0.3178</span>
</span></span><span><span>Epoch [<span>100</span><span>/</span><span>100</span>], Loss: <span>0.2974</span>
</span></span><span><span>
</span></span><span><span><span>"""after"""</span>
</span></span><span><span>OrderedDict([(<span>'linear.weight'</span>, tensor([[<span>1.5441</span>]])), (<span>'linear.bias'</span>, tensor([<span>1.3291</span>]))])
</span></span></code></pre></div><p>The optimizer, as we see, has its own <code>state_dict</code>, which consists of these hyperparameters we discussed before: the learning rate, the weight decay, and more:</p><div><pre tabindex="0"><code data-lang="python"><span><span>print(optimizer<span>.</span>state_dict())
</span></span><span><span>{<span>'state'</span>: {}, <span>'param_groups'</span>: [{<span>'lr'</span>: <span>0.01</span>, <span>'momentum'</span>: <span>0</span>, <span>'dampening'</span>: <span>0</span>, <span>'weight_decay'</span>: <span>0</span>, <span>'nesterov'</span>: <span>False</span>, <span>'maximize'</span>: <span>False</span>, <span>'foreach'</span>: <span>None</span>, <span>'differentiable'</span>: <span>False</span>, <span>'params'</span>: [<span>0</span>, <span>1</span>]}]}
</span></span></code></pre></div><p>Now that we have a trained model object, we can pass in new feature values for the model to evaluate. For example we can pass in an <code>X</code> value of <code>5</code> hours of sunshine and see how many jars of Nulltella we expect to make.</p><p>We do this by passing in <code>5</code> to the instantiated model object, which is now a combination of the method used to run the linear regression equation and our state dict, the weights, the current set of weights and biases to give a new predicted value. We get <code>9</code> jars, which pretty close to what we’d expect.</p><div><pre tabindex="0"><code data-lang="python"><span><span>test_input <span>=</span> torch<span>.</span>tensor([[<span>5.0</span>]], dtype<span>=</span>torch<span>.</span>float32)
</span></span><span><span>predicted_output <span>=</span> model(test_input)
</span></span><span><span>print(<span>f</span><span>'Prediction for input </span><span>{</span>test_input<span>.</span>item()<span>}</span><span>: </span><span>{</span>predicted_output<span>.</span>item()<span>}</span><span>'</span>)
</span></span><span><span>Prediction <span>for</span> input <span>5.0</span>: <span>9.049455642700195</span>
</span></span></code></pre></div><p>I’m abstracting away <a href="https://horace.io/brrr_intro.html">an enormous amount of detail</a> for the sake of clarity, namely the massive amount of work PyTorch does in moving this data in and out of GPUs and working with <a href="https://developer.nvidia.com/gpugems/gpugems2/part-iv-general-purpose-computation-gpus-primer/chapter-33-implementing-efficient">GPU-efficient datatypes</a> for efficient computing which is a large part of the work of the library. We’ll skip these for now for simplicity.</p><h2 id="serializing-our-objects">Serializing our objects</h2><p>So far, so good. We now have stateful Python objects in-memory that convey the state of our model. But what happens when we need to persist this very large model, that we likely spent 24+ hours training, and use it again?</p><p>This scenario is described <a href="https://blog.nelhage.com/post/pickles-and-ml/">here</a>,</p><blockquote><p>Suppose a researcher is experimenting with a new deep-learning model architecture, or a variation on an existing one. Her architecture is going to have a whole bunch of configuration options and hyperparameters: the number of layers, the types of each layers, the dimensionality of various vectors, where and how to normalize activations, which nonlinearity(ies) to use, and so on. Many of the model components will be standard layers provided by the ML framework, but the researcher will be inserting bits and pieces of novel logic as well.</p></blockquote><blockquote><p>Our researcher needs a way to describe a particular concrete model – a specific combination of these settings – which can be serialized and then reloaded later. She needs this for a few related reasons:</p></blockquote><blockquote><p>She likely has access to a compute cluster containing GPUs or other accelerators she can use to run jobs. She needs a way to submit a model description to code running on that cluster so it can run her model on the cluster.</p></blockquote><blockquote><p>While those models are training, she needs to save snapshots of their progress in such a way that they can be reloaded and resumed, in case the hardware fails or the job is preempted. Once models are trained, the researcher will want to load them again (potentially both a final snapshot, and some of the partially-trained checkpoints) in order to run evaluations and experiments on them.</p></blockquote><p>What do we mean by serialization? It’s the process of writing objects and classes from our programming runtime to a file. Deserialization is the process of converting data on disk to programming language objects in memory. We now need to seralize the data into a bytestream that we can write to a file.</p><figure><img src="https://github.com/veekaybee/veekaybee.github.io/assets/3837836/47228a07-abc0-410f-b62b-48b756e3b30a" width="600"></figure><p>Why <a href="https://stackoverflow.com/questions/28552540/why-is-serialization-called-serialization">“serialization”</a>? Because back in the Old Days, data used to be stored on tape, which required bits to be in order sequentially on tape.</p><p>Since many transformer-style models are trained using PyTorch these days, artifacts use PyTorch’s <code>save</code> implementation for serializing objects to disk.</p><figure><img src="https://github.com/veekaybee/veekaybee.github.io/assets/3837836/da1b0b43-de7e-4e78-ae06-32a21a018a08" width="600"></figure><h2 id="what-is-a-file">What is a file</h2><p>Again, let’s abstract away the GPU for simplicity and assume we’re performing all these computations in CPU. Python objects <a href="https://docs.python.org/3/c-api/memory.html">live in memory</a>. This memory is allocated in a special private heap at the beginning of <a href="https://anvil.works/articles/pointers-in-my-python-3">their lifecycle</a>, in <a href="https://stackoverflow.com/questions/10200628/heap-memory-in-c-programming">private heap</a> managed by the Python memory manager, with specialized heaps for different object types.</p><p>When we initialize our PyTorch model object, the operating system allocates memory through lower-level C functions, namely <code>malloc</code>, via <a href="https://docs.python.org/3/c-api/memory.html#default-memory-allocators">default memory allocators</a>.</p><p>When we run our code <a href="https://docs.python.org/3/library/tracemalloc.html">with tracemalloc</a>, we can see how memory for PyTorch is actually allocated on CPU (keep in mind that, again, GPU operations are completely different).</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> tracemalloc
</span></span><span><span>
</span></span><span><span>tracemalloc<span>.</span>start()
</span></span><span><span>
</span></span><span><span><span>.....</span>
</span></span><span><span>pytorch
</span></span><span><span><span>...</span>
</span></span><span><span>
</span></span><span><span>snapshot <span>=</span> tracemalloc<span>.</span>take_snapshot()
</span></span><span><span>top_stats <span>=</span> snapshot<span>.</span>statistics(<span>'lineno'</span>)
</span></span><span><span>
</span></span><span><span>print(<span>"[ Top 10 ]"</span>)
</span></span><span><span><span>for</span> stat <span>in</span> top_stats[:<span>10</span>]:
</span></span><span><span>    print(stat)
</span></span><span><span>
</span></span><span><span>[ Top <span>10</span> ]
</span></span><span><span><span>&lt;</span>frozen importlib<span>.</span>_bootstrap_external<span>&gt;</span>:<span>672</span>: size<span>=</span><span>21.1</span> MiB, count<span>=</span><span>170937</span>, average<span>=</span><span>130</span> B
</span></span><span><span><span>/</span>Users<span>/</span>vicki<span>/.</span>pyenv<span>/</span>versions<span>/</span><span>3.10.0</span><span>/</span>lib<span>/</span>python3<span>.10</span><span>/</span>inspect<span>.</span>py:<span>2156</span>: size<span>=</span><span>577</span> KiB, count<span>=</span><span>16</span>, average<span>=</span><span>36.0</span> KiB
</span></span><span><span><span>/</span>Users<span>/</span>vicki<span>/.</span>pyenv<span>/</span>versions<span>/</span><span>3.10.0</span><span>/</span>lib<span>/</span>python3<span>.10</span><span>/</span>site<span>-</span>packages<span>/</span>torch<span>/</span>_dynamo<span>/</span>allowed_functions<span>.</span>py:<span>71</span>: size<span>=</span><span>512</span> KiB, count<span>=</span><span>3</span>, average<span>=</span><span>171</span> KiB
</span></span><span><span><span>/</span>Users<span>/</span>vicki<span>/.</span>pyenv<span>/</span>versions<span>/</span><span>3.10.0</span><span>/</span>lib<span>/</span>python3<span>.10</span><span>/</span>dataclasses<span>.</span>py:<span>434</span>: size<span>=</span><span>410</span> KiB, count<span>=</span><span>4691</span>, average<span>=</span><span>90</span> B
</span></span><span><span><span>/</span>Users<span>/</span>vicki<span>/.</span>pyenv<span>/</span>versions<span>/</span><span>3.10.0</span><span>/</span>lib<span>/</span>python3<span>.10</span><span>/</span>site<span>-</span>packages<span>/</span>torch<span>/</span>_dynamo<span>/</span>allowed_functions<span>.</span>py:<span>368</span>: size<span>=</span><span>391</span> KiB, count<span>=</span><span>7122</span>, average<span>=</span><span>56</span> B
</span></span><span><span><span>/</span>Users<span>/</span>vicki<span>/.</span>pyenv<span>/</span>versions<span>/</span><span>3.10.0</span><span>/</span>lib<span>/</span>python3<span>.10</span><span>/</span>site<span>-</span>packages<span>/</span>torch<span>/</span>_dynamo<span>/</span>allowed_functions<span>.</span>py:<span>397</span>: size<span>=</span><span>349</span> KiB, count<span>=</span><span>1237</span>, average<span>=</span><span>289</span> B
</span></span><span><span><span>&lt;</span>frozen importlib<span>.</span>_bootstrap_external<span>&gt;</span>:<span>128</span>: size<span>=</span><span>213</span> KiB, count<span>=</span><span>1390</span>, average<span>=</span><span>157</span> B
</span></span><span><span><span>/</span>Users<span>/</span>vicki<span>/.</span>pyenv<span>/</span>versions<span>/</span><span>3.10.0</span><span>/</span>lib<span>/</span>python3<span>.10</span><span>/</span>functools<span>.</span>py:<span>58</span>: size<span>=</span><span>194</span> KiB, count<span>=</span><span>2554</span>, average<span>=</span><span>78</span> B
</span></span><span><span><span>/</span>Users<span>/</span>vicki<span>/.</span>pyenv<span>/</span>versions<span>/</span><span>3.10.0</span><span>/</span>lib<span>/</span>python3<span>.10</span><span>/</span>site<span>-</span>packages<span>/</span>torch<span>/</span>_dynamo<span>/</span>allowed_functions<span>.</span>py:<span>373</span>: size<span>=</span><span>136</span> KiB, count<span>=</span><span>2540</span>, average<span>=</span><span>55</span> B
</span></span><span><span><span>&lt;</span>frozen importlib<span>.</span>_bootstrap_external<span>&gt;</span>:<span>1607</span>: size<span>=</span><span>127</span> KiB, count<span>=</span><span>1133</span>, average<span>=</span><span>115</span> B
</span></span></code></pre></div><p>Here, we can see we imported 170k objects from imports, and that the rest of the allocation came from allowed_functions in torch.</p><h2 id="how-does-pytorch-write-objects-to-files">How does PyTorch write objects to files?</h2><p>We can also more explicitly see the types of these objects in memory. Among all the other objects created by PyTorch and Python system libraries, we can see our <code>Linear</code> object here, which has <code>state_dict</code> as a property. We need to serialize this object into a bytestream so we can write it to disk.</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> gc
</span></span><span><span><span># Get all live objects</span>
</span></span><span><span>all_objects <span>=</span> gc<span>.</span>get_objects()
</span></span><span><span>
</span></span><span><span><span># Extract distinct object types</span>
</span></span><span><span>distinct_types <span>=</span> set(type(obj) <span>for</span> obj <span>in</span> all_objects)
</span></span><span><span>
</span></span><span><span><span># Print distinct object types</span>
</span></span><span><span><span>for</span> obj_type <span>in</span> distinct_types:
</span></span><span><span>    print(obj_type<span>.</span>__name__)
</span></span><span><span>
</span></span><span><span>InputKind
</span></span><span><span>KeyedRef
</span></span><span><span>ReLU
</span></span><span><span>Manager
</span></span><span><span>_Call
</span></span><span><span>UUID
</span></span><span><span>Pow
</span></span><span><span>Softmax
</span></span><span><span>Options 
</span></span><span><span>_Environ
</span></span><span><span><span>**</span>Linear<span>**</span>
</span></span><span><span>CFunctionType
</span></span><span><span>SafeUUID
</span></span><span><span>_Real
</span></span><span><span>JSONDecoder
</span></span><span><span>StmtBuilder
</span></span><span><span>OutDtypeOperator
</span></span><span><span>MatMult
</span></span><span><span>attrge
</span></span></code></pre></div><p>PyTorch <a href="https://pytorch.org/tutorials/beginner/saving_loading_models.html">serializes objects to disk</a> using Python’s pickle framework and wrapping the pickle <code>load</code> and <code>dump</code> methods.</p><p>Pickle traverses the object’s inheritance hierarchy and converts each object encountered into streamable artifacts. It does this recursively for nested representations (for example, understanding nn.<code>Module</code> and <code>Linear</code> inheriting from <code>nn.Module</code>) and converting these representations to byte representations so that they can be written to file.</p><p>As an example, let’s take a simple function and write it to a pickle file.</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> torch.nn <span>as</span> nn
</span></span><span><span><span>import</span> torch.optim <span>as</span> optim
</span></span><span><span><span>import</span> pickle
</span></span><span><span>
</span></span><span><span>X <span>=</span> torch<span>.</span>tensor([[<span>1.0</span>], [<span>2.0</span>], [<span>3.0</span>], [<span>4.0</span>]], dtype<span>=</span>torch<span>.</span>float32)
</span></span><span><span>
</span></span><span><span><span>with</span> open(<span>'tensors.pkl'</span>, <span>'wb'</span>) <span>as</span> f: 
</span></span><span><span>    pickle<span>.</span>dump(X, f) 
</span></span></code></pre></div><p>when we inspect the <a href="https://docs.python.org/3/library/pickletools.html">pickled object with pickletools</a>, we get an idea of how the data is organized.</p><p>We import some functions that load the data as a tensor, then the actual storage of that data, then its type. The module does the inverse when converting from pickle files to Python objects.</p><pre tabindex="0"><code>python -m pickletools tensors.pkl
    0: \x80 PROTO      4
    2: \x95 FRAME      398
   11: \x8c SHORT_BINUNICODE 'torch._utils'
   25: \x94 MEMOIZE    (as 0)
   26: \x8c SHORT_BINUNICODE '_rebuild_tensor_v2'
   46: \x94 MEMOIZE    (as 1)
   47: \x93 STACK_GLOBAL
   48: \x94 MEMOIZE    (as 2)
   49: (    MARK
   50: \x8c     SHORT_BINUNICODE 'torch.storage'
   65: \x94     MEMOIZE    (as 3)
   66: \x8c     SHORT_BINUNICODE '_load_from_bytes'
   84: \x94     MEMOIZE    (as 4)
   85: \x93     STACK_GLOBAL
   86: \x94     MEMOIZE    (as 5)
   87: B        BINBYTES   b'\x80\x02\x8a\nl\xfc\x9cF\xf9 j\xa8P\x19.\x80\x02M\xe9\x03.\x80\x02}q\x00(X\x10\x00\x00\x00protocol_versionq\x01M\xe9\x03X\r\x00\x00\x00little_endianq\x02\x88X\n\x00\x00\x00type_sizesq\x03}q\x04(X\x05\x00\x00\x00shortq\x05K\x02X\x03\x00\x00\x00intq\x06K\x04X\x04\x00\x00\x00longq\x07K\x04uu.\x80\x02(X\x07\x00\x00\x00storageq\x00ctorch\nFloatStorage\nq\x01X\n\x00\x00\x006061074080q\x02X\x03\x00\x00\x00cpuq\x03K\x04Ntq\x04Q.\x80\x02]q\x00X\n\x00\x00\x006061074080q\x01a.\x04\x00\x00\x00\x00\x00\x00\x00\x00\x00\x80?\x00\x00\x00@\x00\x00@@\x00\x00\x80@'
  351: \x94     MEMOIZE    (as 6)
  352: \x85     TUPLE1
  353: \x94     MEMOIZE    (as 7)
  354: R        REDUCE
  355: \x94     MEMOIZE    (as 8)
  356: K        BININT1    0
  358: K        BININT1    4
  360: K        BININT1    1
  362: \x86     TUPLE2
  363: \x94     MEMOIZE    (as 9)
  364: K        BININT1    1
  366: K        BININT1    1
  368: \x86     TUPLE2
  369: \x94     MEMOIZE    (as 10)
  370: \x89     NEWFALSE
  371: \x8c     SHORT_BINUNICODE 'collections'
  384: \x94     MEMOIZE    (as 11)
  385: \x8c     SHORT_BINUNICODE 'OrderedDict'
  398: \x94     MEMOIZE    (as 12)
  399: \x93     STACK_GLOBAL
  400: \x94     MEMOIZE    (as 13)
  401: )        EMPTY_TUPLE
  402: R        REDUCE
  403: \x94     MEMOIZE    (as 14)
  404: t        TUPLE      (MARK at 49)
  405: \x94 MEMOIZE    (as 15)
  406: R    REDUCE
  407: \x94 MEMOIZE    (as 16)
  408: .    STOP
highest protocol among opcodes = 4
</code></pre><p>The main issue with pickle as a file format is that it not only bundles executable code, but that there are no checks on the code being read, and without schema guarantees, <a href="https://nedbatchelder.com/blog/202006/pickles_nine_flaws.html">you can pass something to the pickle that’s malicious</a>,</p><blockquote><p>The insecurity is not because pickles contain code, but because they create objects by calling constructors named in the pickle. Any callable can be used in place of your class name to construct objects. Malicious pickles will use other Python callables as the “constructors.” For example, instead of executing “models.MyObject(17)”, a dangerous pickle might execute “os.system(‘rm -rf /’)”. The unpickler can’t tell the difference between “models.MyObject” and “os.system”. Both are names it can resolve, producing something it can call. The unpickler executes either of them as directed by the pickle.'</p></blockquote><h2 id="how-pickle-works">How Pickle works</h2><p>Pickle initially worked for Pytorch-based models because it was also closely coupled to the Python ecosystem and initial ML library artifacts were not the key outputs of deep learning systems.</p><blockquote><p>The primary output of research is knowledge, not software artifacts. Research teams write software to answer research questions and improve their/their team’s/their field’s understanding of a domain, more so than they write software in order to have software tools or solutions.</p></blockquote><p>However, as the use of transformer-based models picked up after the release of the Transformer paper in 2017, so did the use of the <code>transformers</code> library, which delegates the <a href="https://github.com/huggingface/transformers/blob/08cd694ef07d53f6e08e60ea6e1483dbb156924d/src/transformers/models/auto/configuration_auto.py#L1006">load</a> call to PyTorch’s <code>load</code> methods, which uses pickle.</p><p>Once practitioners started creating and uploading <a href="https://arxiv.org/abs/2401.13177">pickled model artifacts to model hubs like HuggingFace</a>, <a href="https://www.youtube.com/watch?v=2ethDz9KnLk&amp;t=1103s">machine learning model supply chain security</a> became an issue.</p><h2 id="from-pickle-to-safetensors">From pickle to safetensors</h2><p>As machine learning with deep learning models trained with PyTorch exploded, these security issues came to a head, and in 2021, Trail of Bits released a post <a href="https://github.com/trailofbits/fickling">the insecurity of pickle files.</a></p><p>Engineers at HuggingFace started developing a library known as <a href="https://github.com/huggingface/safetensors/tree/main">safetensors</a> as an alternative to pickle. Safetensors was a <a href="https://github.com/huggingface/safetensors/discussions/111">developed</a> to be efficient, but, also safer and more ergonomic than pickle.</p><p>First, <code>safetensors</code> is not bound to Python as closely as Pickle: with pickle, you can only read or write files in Python. Safetensors is compatible across languages. Second, safetensors also limits language execution, functionality available on serialization and deserialization. Third, because the backend of safetensors is written in Rust, it enforces type safety more rigorously. Finally, safetensors was optimized for work specifically with tensors as a datatype in a way that Pickle was not. That, combined with the fact that it was wirtten in Rust <a href="https://huggingface.co/docs/safetensors/en/speed.">makes it really fast for reads and writes.</a></p><p>After a concerted push from both <a href="https://www.trailofbits.com/">Trail of Bits</a> and <a href="https://www.eleuther.ai/">EleutherAI</a>, a security audit of safetensors was conducted and found satisfactory, <a href="https://huggingface.co/blog/safetensors-security-audit">which led to HuggingFace adapting it as the default format for models on the Hub.</a> going forward. (Big thanks to <a href="https://twitter.com/vboykis/status/1759268551129452654">Stella and Suha</a> for this history and context, and to everyone who contributed to the Twitter thread.)</p><h2 id="how-safetensors-works">How safetensors works</h2><p>How does the safetensors format work? As with most things in LLMs at the bleeding edge, the code and commit history will do most of the talking. <a href="https://github.com/huggingface/safetensors#yet-another-format-">Let’s take a look at the file spec.</a></p><ul><li><strong>8 bytes</strong>: N, an unsigned little-endian 64-bit integer, containing the size of the header</li><li><strong>N bytes</strong>: a JSON UTF-8 string representing the header.
The header data MUST begin with a { character (0x7B).
The header data MAY be trailing padded with whitespace (0x20).
The header is a dict like {“TENSOR_NAME”: {“dtype”: “F16”, “shape”: [1, 16, 256], “data_offsets”: [BEGIN, END]}, “NEXT_TENSOR_NAME”: {…}, …},
data_offsets point to the tensor data relative to the beginning of the byte buffer (i.e. not an absolute position in the file), with BEGIN as the starting offset and END as the one-past offset (so total tensor byte size = END - BEGIN).
A special key <strong>metadata</strong> is allowed to contain free form string-to-string map. Arbitrary JSON is not allowed, all values must be strings.</li><li>Rest of the file: byte-buffer.</li></ul><p>This is different than <code>state_dict</code> and <code>pickle</code> file specifications, but the addition of safetensors follows the natural evolution from Python objects, to full-fledged file format.</p><p>A file is a way of storing our data generated from programming language objects, in bytes on disk. In looking at different file format specs (<a href="https://arrow.apache.org/docs/format/CDataInterface.html">Arrow</a>,<a href="https://parquet.apache.org/docs/file-format/">Parquet</a>, <a href="https://protobuf.dev/">protobuf</a>), we’ll start to notice some patterns around how they’re laid out.</p><ol><li>In the file, we need some indicator that this is a type of file “X”. Usually this is represented by a <a href="https://en.wikipedia.org/wiki/List_of_file_signatures"><strong>magic byte</strong>.</a></li><li>Then, there is a <strong>header</strong> that represents the metadata of the file (In the case of machine learning, how many layers we have, the learning rate, and other aspects. )</li><li>The actual <strong>data</strong>. (In the case of machine learning files, the tensors)</li><li>We then need a <strong>spec</strong> that tells us what to expect in a file as we read it and what kinds of data types are in the file and how they’re represented as bytes. Essentially, documentation for the file’s layout and API so that we can program a file reader against it.</li><li>One feature the file spec usually tells us is whether data is little or big-endian, that is - whether we store the largest number first or last. This becomes important as we expect files to be read on systems with different default byte layouts.</li><li>We then implement code that reads and writes to that filespec specifically.</li></ol><p>One thing we start to notice from having looked at statedicts and pickle files before, is that machine learning data storage follow a pattern: we need to store:</p><ol><li>a large collection of vectors,</li><li>metadata about those vectors and</li><li>hyperparameters</li></ol><p>We then need to be able to instantiate model objects that we can hydrate (fill) with that data and run model operations on.</p><p>As an example for safetensors from the documentation: We start with a Python dictionary, aka a state dict, save, and load the file.</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> torch
</span></span><span><span><span>from</span> safetensors <span>import</span> safe_open
</span></span><span><span><span>from</span> safetensors.torch <span>import</span> save_file
</span></span><span><span>
</span></span><span><span>tensors <span>=</span> {
</span></span><span><span>   <span>"weight1"</span>: torch<span>.</span>zeros((<span>1024</span>, <span>1024</span>)),
</span></span><span><span>   <span>"weight2"</span>: torch<span>.</span>zeros((<span>1024</span>, <span>1024</span>))
</span></span><span><span>}
</span></span><span><span>save_file(tensors, <span>"model.safetensors"</span>)
</span></span><span><span>
</span></span><span><span>tensors <span>=</span> {}
</span></span><span><span><span>with</span> safe_open(<span>"model.safetensors"</span>, framework<span>=</span><span>"pt"</span>, device<span>=</span><span>"cpu"</span>) <span>as</span> f:
</span></span><span><span>   <span>for</span> key <span>in</span> f<span>.</span>keys():
</span></span><span><span>       tensors[key] <span>=</span> f<span>.</span>get_tensor(key)
</span></span></code></pre></div><p>we use the save_file(model.state_dict(), ‘my_model.st’) method to render the file to safetensors</p><p>In the conversion process from pickle to safetensors, we also start <a href="https://github.com/huggingface/safetensors/blob/main/bindings/python/convert.py">with the state dict.</a></p><p>Safetensors quickly became the leading format for sharing model weights and architectures to use in further fine-tuning, and in some cases, inference</p><h2 id="checkpoint-files">Checkpoint files</h2><p>We’ve so far taken a look at simple <code>state_dict</code> files and single <code>safetensors</code> files. But if you’re training a long-running model, you’ll likely have more than just weights and biases to save, and you want to save your state every so often so you can revert if you start to see issues in your trianing run. <a href="https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html">PyTorch has checkpoints</a>. A checkpoint is a file that has a model <code>state_dict</code>, but also</p><blockquote><p>the optimizer’s state_dict, as this contains buffers and parameters that are updated as the model trains. Other items that you may want to save are the epoch you left off on, the latest recorded training loss, external torch.nn.Embedding layers, and more. This is also saved as a Dictionary and pickled, then unpickled when you need it. All of this is also saved to a dictionary, the <code>optimizer_state_dict</code>, distinct from the <code>model_state_dict</code>.</p></blockquote><div><pre tabindex="0"><code data-lang="python"><span><span><span># Additional information</span>
</span></span><span><span>EPOCH <span>=</span> <span>5</span>
</span></span><span><span>PATH <span>=</span> <span>"model.pt"</span>
</span></span><span><span>LOSS <span>=</span> <span>0.4</span>
</span></span><span><span>
</span></span><span><span>torch<span>.</span>save({
</span></span><span><span>            <span>'epoch'</span>: EPOCH,
</span></span><span><span>            <span>'model_state_dict'</span>: net<span>.</span>state_dict(),
</span></span><span><span>            <span>'optimizer_state_dict'</span>: optimizer<span>.</span>state_dict(),
</span></span><span><span>            <span>'loss'</span>: LOSS,
</span></span><span><span>            }, PATH)
</span></span></code></pre></div><p>In addition, most large language models also now include accompanying files like tokenizers, and on HuggingFace, metadata, etc. So if you’re working with PyTorch models as artifacts generated via the Transformers library, you’ll get a repo <a href="https://huggingface.co/mistralai/Mistral-7B-v0.1/tree/main">that looks like this</a>.</p><h2 id="ggml">GGML</h2><p>As work to migrate from pickle to safetensors was ongoing for <a href="https://www.reddit.com/r/LocalLLaMA/comments/1ayd4xr/for_those_who_dont_know_what_different_model/">generalized model fine-tuning and inference</a>, Apple Silicon <a href="https://appleinsider.com/articles/23/12/13/apple-silicon-m3-pro-blows-away-nvidia-rtx-4090-gpu-in-ai-benchmark">continued to get a lot better.</a>. As a result, people started bringing modeling work and inference from large GPU-based computing clusters, to local and on-edge devices.</p><p>Georgi Gerganov’s project to make OpenAI’s Whisper run locally with <a href="https://github.com/ggerganov/whisper.cpp">Whisper.cpp.</a> was a success and the catalyst for later projects. The combination of the release of <a href="https://about.fb.com/news/2023/07/llama-2/">Llama-2 as a mostly open-source model</a>, combined with the rise of model compression techniques like <a href="https://huggingface.co/docs/peft/main/en/developer_guides/lora">LoRA</a>, large language models, which were typically only accessible on lab or industry-grade GPU hardware (inspie of the small CPU-based examples we’ve run here), also acted as a catalyst for thinking about working with and running personalized models locally.</p><p>Based on the interest and success of <code>whisper.cpp</code>, Gerganov created <a href="https://github.com/ggerganov/llama.cpp/issues/33#issuecomment-1465108022">llama.cpp</a>, a package for working with Llama model weights, originaly in pickle format, in GGML format, for local inference.</p><p>GGML was initialy both a library and a complementary format created specifically for on-edge inference for whisper. You can also <a href="https://www.reddit.com/r/LocalLLaMA/comments/15y9m64/fine_tuningggml_quantiziation_on_apple_silicon/">perform fine-tuning</a> with it, but generally it’s used to read models trained on PyTorch in GPU Linux-based environments and converted to GGML to run on Apple Silicon.</p><p>As an example, here is script for <a href="https://github.com/ggerganov/ggml">GGML</a> which <a href="https://github.com/ggerganov/ggml/blob/master/examples/gpt-2/convert-ckpt-to-ggml.py">converts PyTorch GPT-2 checkpoints</a> to the correct format, <a href="https://github.com/ggerganov/ggml/blob/b458250b736a7473f7ff3560d47c93f1644f3290/examples/gpt-2/convert-ckpt-to-ggml.py#L64">read as a <code>.bin</code> file.</a>. The files are <a href="https://github.com/ggerganov/ggml/blob/b458250b736a7473f7ff3560d47c93f1644f3290/examples/gpt-2/download-model.sh#L41C64-L41C131">downloaded from OpenAI</a>.</p><p><a href="https://github.com/ggerganov/llama.cpp/issues/33#issuecomment-1465108022">The resulting GGML file compresses all of these into one and contains</a>:</p><ul><li><p>a magic number with an <a href="https://github.com/ggerganov/ggml/blob/b458250b736a7473f7ff3560d47c93f1644f3290/examples/gpt-2/convert-ckpt-to-ggml.py#L91">optional version number</a></p></li><li><p><a href="https://github.com/ggerganov/ggml/blob/b458250b736a7473f7ff3560d47c93f1644f3290/examples/gpt-2/convert-ckpt-to-ggml.py#L92">model-specific hyperparameters</a>, including
metadata about the model, such as the number of layers, the number of heads, etc.
a ftype that describes the type of the majority of the tensors,
for GGML files, the quantization version is encoded in the ftype divided by 1000</p></li><li><p>an embedded vocabulary, which is a list of strings with length prepended.</p></li><li><p>finally, a <a href="https://github.com/ggerganov/ggml/blob/b458250b736a7473f7ff3560d47c93f1644f3290/examples/gpt-2/convert-ckpt-to-ggml.py#L137">list of tensors</a> with their length-prepended name, type, and tensor data</p></li></ul><p>There are several elements that make GGML more efficient for local inference than checkpoint files. First, <a href="https://github.com/ggerganov/ggml/blob/b458250b736a7473f7ff3560d47c93f1644f3290/src/ggml-impl.h#L45">it makes use of 16-bit floating point representations</a> of model weights. Generally, <code>torch</code> initializes floating point datatypes in <a href="https://pytorch.org/docs/stable/generated/torch.set_default_dtype.html">32-bit floats by default</a>. 16-bit, or half precision means that model weights use <a href="https://en.wikipedia.org/wiki/Half-precision_floating-point_format">50% less memory</a> at compute and inference time without significant loss in model accuracy. Other architectural choices include using C, which offers <a href="https://www.interviewbit.com/blog/difference-between-c-and-python/">more efficient memory allocation than Python</a>. And finally, GGML was built <a href="https://developer.apple.com/documentation/apple-silicon/tuning-your-code-s-performance-for-apple-silicon">optimized for Silicon.</a></p><p>Unfortunately, in its move to efficiency, GGML contained <a href="https://github.com/ggerganov/ggml/blob/master/docs/gguf.md#drawbacks">a number of breaking changes</a> that created issues for users.</p><p>The largest one was that, since everything, both data and metadata and hyperparameters, was written into the same file, if a model added hyperparameters, it would break backward compatibility that the new file couldn’t pick up. Additionally, no model architecture metadata is present in the file, and each architecture required its own conversion script. All of this led to brittle performance and the creation of <a href="https://github.com/ggerganov/ggml/blob/master/docs/gguf.md#gguf">GGUF.</a></p><h2 id="finally-gguf">Finally, GGUF</h2><p>GGUF has the same type of layout as GGML, with metadata and tensor data in a single file, but in addition is also designed to be backwards-compatible. The key difference is that previously instead of a list of values for the hyperparameters, the new file format uses a key-value lookup tables which accomodate shifting values.</p><p>The intiution we spent building up around how machine learning models work and file formats are laid out now allows us to understand the <a href="https://github.com/ggerganov/ggml/blob/master/docs/gguf.md#file-structure">GGUF format.</a></p><p>First, we know that GGUF models are little-endian by default for specific architectures, which we remember is when the least significant bytes come first and is optimized for different computer hardware architectures.</p><p>Then, we have <code>gguf_header_t</code>, which is the header</p><p>It includes the magic byte that tells us this is a GGUF file:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>Must be <span>`</span>GGUF<span>`</span> at the byte level: <span>`</span>0x47<span>`</span> <span>`</span>0x47<span>`</span> <span>`</span>0x55<span>`</span> <span>`</span>0x46<span>`</span>. 
</span></span></code></pre></div><p>as well as the key-value pairs:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>// The metadata key-value pairs.
</span></span></span><span><span><span></span>    <span>gguf_metadata_kv_t</span> metadata_kv[metadata_kv_count];
</span></span></code></pre></div><p>This file format also offers versioning, in this case we see this is version 3 of the file format.</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>// Must be `3` for version described in this spec, which introduces big-endian support.
</span></span></span><span><span><span></span>    <span>//
</span></span></span><span><span><span></span>    <span>// This version should only be increased for structural changes to the format.
</span></span></span></code></pre></div><p>Then, we have the tensors</p><p>The entire file looks like this, and when we work with readers like <code>llama.cpp</code> and <code>ollama</code>, they take this spec and write code to open these files and read them.</p><figure><img src="https://github.com/veekaybee/veekaybee.github.io/assets/3837836/0da77173-fd21-470c-90d1-fa31bcfc7119" width="600"></figure><h2 id="conclusion">Conclusion</h2><p>We’ve been on a whirlwind adventure to build up our intuition of how machine learning models work, what artifacts they produce, how the machine learning artifact storage story has changed over the past couple years, and finally ended up in GGUF’s documentation to better understand the log that is presented to us when we perform local inference on artifacts in GGUF. Hope this is helpful, and good luck!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Financial systems take a holiday (192 pts)]]></title>
            <link>https://www.bitsaboutmoney.com/archive/financial-systems-take-a-holiday/</link>
            <guid>39553801</guid>
            <pubDate>Thu, 29 Feb 2024 19:21:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bitsaboutmoney.com/archive/financial-systems-take-a-holiday/">https://www.bitsaboutmoney.com/archive/financial-systems-take-a-holiday/</a>, See on <a href="https://news.ycombinator.com/item?id=39553801">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>All systems reflect the culture they are created in, in ways great and small. The financial system, and the human and computer systems which compose it, have inherited norms about when work is performed from the diverse societies which built (and build) financial systems.</p><p>Your bank takes holidays. Your conception of a holiday is materially informed by when banks are closed. No system of importance can be accurately described without the context of the culture that created it and no culture can be accurately described without the context of the systems embedded in it. Neither is chicken; neither is egg.</p><p>Cultural commentary aside, this has material consequences. The app in your pocket that moves money gets less useful during holidays and on weekends.</p><p>This sometimes occasions gnashing of teeth. Many people and businesses find it inconvenient when financial systems are down. It also seems unnecessary. Financial systems are inseparably computer systems. Most similarly important computer systems don’t take holidays. Google doesn’t take holidays… or doesn’t seem to, from the perspective of a typical user, at any rate.</p><p>Technologists describe their systems as having “uptime” and measure it in “nines”, such as “We have five nines of uptime”, which means that a system has 99.999% uptime or, equivalently, about five minutes of downtime per year. Five nines is admirable in many circumstances and would be considered <em>disastrously</em> below expectations for e.g. Google Search.</p><p>Nonetheless, many financial systems <em>do</em> have availability which is far closer to five <em>twos</em>. They aren’t fully open for business during holidays, weekends, or outside of business hours. It turns out that “holidays”, “weekends”, and “business hours” are far deeper topics than one might think.</p><p>As always: while I previously worked at Stripe, and am an advisor to it, it does not necessarily endorse any commentary I make. Illustrations of engineering reality made below are for color purposes and taken from general industry knowledge rather than private knowledge of particular design documents for specific systems at any firm.</p><h2 id="what-is-a-holiday-anyway">What is a holiday, anyway?</h2><p>A holiday is any day you and your counterparty mutually agree is a holiday.</p><p>This is often an implicit agreement via <a href="https://en.wikipedia.org/wiki/Focal_point_(game_theory)">Schelling points</a>. No serious person disputes that Christmas Day is a holiday in the United States and accordingly no one needs to ask if Christmas Day is a holiday. (Many salarymen in Japan work on Christmas Day, of course, despite their coworkers Taro [1] and Patrick skipping work to... go to a Jewish friend’s birthday party or something. Taro and Patrick are, of course, <em>eccentric</em>.)</p><p>If I can pre-answer a poindextery observation: yes, I am aware that some people work on holidays. That is why we describe that as “working on a holiday” as opposed to “working.” The distinction often has material consequences.</p><p>For example: one of a million things <a href="https://twitter.com/patio11/status/1654988724353241088" rel="noreferrer">dooming</a> government <a href="https://www.bitsaboutmoney.com/archive/payroll-providers-power-respect/" rel="noreferrer">payroll</a> system modernization projects is that they require—and universally fail to budget for— substantial bespoke work by historians to figure out e.g. which set of documents is the controlling authority with respect to what overtime rate applies to meter maids in Chicago on Good Friday. Holidays can be broadly understood every-child-knows-this facts but they <em>can also</em> be contentious sites of explicit negotiation.</p><p>You might sensibly say “Ahh yes, but <em>legal</em> holidays or <em>federal government</em> holidays or <em>banking</em> holidays are not simply <em>agreements, </em>formal or informal, not in any way that matters. Those are… facts about society. They’re <em>real</em> and <em>legible</em>.”</p><p>I am a sometimes technologist. I predict that many non-specialists would have conversations with technologists about the nature of calendars, clocks, time zones, and whether time flows forward in a linear fashion and swiftly conclude that the night is dark and full of terrors. [2]</p><p>Take banking holidays. You might think there is an authoritative list of days on which bank branches are closed for business. Sure, they are closed <em>by custom</em>, but <em>that list</em> must exist, right? Banking holidays <a href="https://www.bitsaboutmoney.com/archive/seeing-like-a-bank/"><u>are legible to the banking system</u></a>, surely!</p><p><em>That</em> list does generally exist.</p><p>And so you might conclude “OK, then the holidays bank systems need to know about are <em>the banking holidays</em>. Which you have an exhaustive and authoritative list of. Problem solved.” And what’s that behind you? It’s social and engineering reality, come to destroy our sanity.</p><p>Allow me to offer an example: Company Foundation Day. Company Foundation Day is a holiday for many Japanese salarymen. Japan has a public holiday, National Foundation Day (国立記念日), every year on February 11th. It was established by order of the Cabinet more than 50 years ago. Many Japanese companies, including some which predate the issuance of that order, have a high degree of regard for their corporate history. So Company Foundation Day is a holiday, too.</p><p>What day was the company founded? It depends on the company [3]. You will be  unsurprised that Company Foundation Day is whenever a company says it is.</p><p>“Charming bit of salaryman trivia, Patrick, but what does this have to do with banking holidays?”</p><p>Well, you see, Japanese banks <em>are Japanese companies</em>. And so if you are a Japanese bank, it is very possible that <em>some</em> of your human and computer systems are, by your custom and practice, given a day of rest on a day <em>on a day when most Japanese salarymen are working</em>.</p><p>Now <em>it gets worse</em>. If you are a bank or other bit of financial infrastructure which interacts with a Japanese bank, congratulations, <em>you</em> now observe the Company Foundation Day of your counterparty with respect to some (probably relatively small) set of your operations.</p><p>What does that "observation" mean? It means whatever you agreed it means, which could be "Of course if you attempt to call your account representative on a holiday that call may be returned on the next business day." or "Of course if you or your computer system electronically communicates updated <a href="https://www.bitsaboutmoney.com/archive/kyc-and-aml-beyond-the-acronyms/" rel="noreferrer">KYC</a> information on a holiday our computer system will inform your computer system the KYC information has been accepted. 'Accepted' has a very specific meaning here. <em>No action will be taken</em> until the following business day, <em>unless</em> you <em>also</em> call or fax Operations to inform them of an emergency necessitating intervention on a holiday."</p><p>To promote the subtext to text: not all banks/etc which interact with Japanese banks are themselves well-informed about the culture that is Japanese salarymen. (The culture that is Japanese salaryman is often misunderstood to be coextensive with Japanese culture. There is no one single Japanese salaryman culture, though "salaryman" is useful shorthand for a cultural cluster. Reports of Japanese culture being a monolith are greatly exaggerated internally and externally. Sugimoto's Introduction to Japanese Society is a good text on this, if a bit dry.)</p><p>Now clearly your Japanese counterparty would not choose to surprise you with the fact of Company Foundation Day. Japan is considered exotic by many people, but it is a functioning democratic and capitalist society. Work does not constantly grind to a halt as salarymen are ambushed by other companies’ Company Foundation Day. No, salarymen do the sensible thing. They <em>wrote this down</em>. Flip to page 636 of the Operations Manual under the heading Observed Holidays. Look right there, in the middle of the list, exactly where a Japanese salaryman would expect to find his counterparty’s Company Foundation Day.</p><figure><img src="https://lh7-us.googleusercontent.com/maK8F3X_LuzDrdyNISHK2B6ytJ9ghm62pMefrC-5BnHi93nE36IY5g4ND7IunyyulkBnKrFP9AOypl099F8rP2itLeG0Iqtv_BvTua_hW7IWvZlgyae-rYW7ju6OFti4wWCet_Ap6P_hoPF9tXTtUhw" alt="Four panel Anakin/Padme meme which makes an ironic observation about likelihood Operations Manual was read." loading="lazy" width="500" height="500"></figure><p>Now, suppose you are a large company. To ensure that your systems reflect reality, your technologists very likely have created some formal system which tracks holidays. The first time you do business with a Japanese counterparty, one of them will add a list of Japanese banking holidays to the system, and another will check the work. Perhaps the list added will be sourced from a data provider, like e.g. Bloomberg. Perhaps it will be gathered by looking at Google Calendar’s list or a Wikipedia article. Perhaps your technologists, being careful, will say neither of those is good enough, and will attempt to find an <em>authoritative</em> list of holidays in a publication of the government.</p><p>Different companies will adopt different strategies. Guess which holiday <em>none</em> of the above data sources will mention. But it is <em>definitely a holiday </em>because <em>it has all the consequences of being a holiday</em>.</p><p>Not only will one soon find oneself with substantial egg on one’s face, one will very often have to organize one’s engineering team to quickly redefine <em>how one’s systems understand holidays worldwide</em> in response to the incident this fact pattern will create. Because, yes, some holidays exist only per-company, and if your financial institution is sophisticated, a computer querying whether it is a holiday or not on a particular day probably passes the jurisdiction of interest but probably does not pass the counterparty of interest when doing the lookup.</p><p>Now you could, at this point, throw your hands up in the air and say "Other people's culture is not my problem! This is a quirky edge case upon an edge case! Begone!" Goodness knows you would not be the first technologist to say that. But—and this is extremely <em>not</em> legal advice—Compliance has a definite point of view on whether you are allowed to intentionally build a KYC system which could, given your company's positive knowledge that it has accidentally moved money for a terrorist in the past and is in the process of doing so at the present moment, inform its financial parters about the terrorist <em>tomorrow</em>. Compliance also has a definite <a href="https://www.bitsaboutmoney.com/archive/bond-villain-compliance-strategy/" rel="noreferrer">point of view</a> on the wisdom of writing down that one considers a particular foreign nation a Nice To Have, really, on the list of nations where one has addressed one's domestic-to-you responsibilities and routinely follows the domestic-to-them law.</p><h2 id="fun-operational-consequences-of-holidays">Fun operational consequences of holidays</h2><p>Holidays <em>as observed</em> often are used to extend weekends, for both operational and social purposes.</p><p>If a holiday is defined as a fixed date on the calendar, it will periodically fall on a weekend, and in many nations many organizations will add an “as observed” day which is not that fixed date which expands the weekend.</p><p>Many holidays are, of course, not on fixed dates, but change every year. Why do you think we send you a new Operations Manual every year. Did you think we think you lost the old one. We have much higher regard for you than that.</p><p>Easter is March 31st in 2024. Try explaining why it is March 31st this year and not a date in April to a Chinese banker not familiar with Judaism. (If one objects that Easter is not a Jewish holiday, one should not attempt to explain the timing of Easter to a Chinese banker, or anyone else really. If one objects “Easter on which side of which schism?”, one has a good understanding of the challenges here.)</p><p>Anyhow, however they are scheduled, holidays routinely cause long weekends to happen.</p><p>Long weekends have consequences in the material world. Human activity does not stop during weekends or on holidays. Certain human activity that the financial system <em>cares about keenly</em>, such as consumer payments to businesses for goods and services, predictably explodes on or around certain holidays.</p><p>Take Black Friday / Cyber Monday.&nbsp;(BFCM, in some quarters.)</p><p><em>When</em> is Black Friday? The day after Thanksgiving. When is Thanksgiving? Whenever Americans think it is. Many Americans think it is the 4th Thursday in November. But Thanksgiving is so inextricably bound with the American commercial calendar that the reason Americans celebrate it on the 4th Thanksgiving was because <a href="https://www.britannica.com/story/why-is-thanksgiving-in-the-us-celebrated-on-a-thursday">previously we had multiple Thanksgivings</a> and <em>this caused operational problems for retailers</em>.</p><p><em>Why</em> is Black Friday? Because Americans, by well-established custom, get two holidays for Thanksgiving. By well-established custom, they typically spend Thanksgiving with family. Then, the day after, while they are not expected to work, they often attempt to get an early start on shopping for Christmas presents. Retailers have long since adapted to this phenomenon, throwing special promotions to juice sales on Black Friday. Retailers not participating in Black Friday lost share of wallet as customers spent their holiday budgets at ones that did.</p><p>This has thoroughly enshrined Black Friday in the practice of many retailers, including in Japan. In Japan, a certain large e-commerce company you may have heard of instructed teams to appropriately celebrate the holiday. Japanese people do not typically celebrate Thanksgiving, and Japan consumes very little turkey, but Japanese salarymen given an order by their boss are socialized to comply with the utmost diligence and peformative enthusiasm even when that order has a puzzling basis (or no basis at all, for that matter).</p><p>The salarymen did the natural thing: they organized a special promotion on—<em>I swear on my honor as a salaryman, may my fax toner dry out forever if I lie</em>— items which are black. It worked <em>very well</em>.</p><p>And so, by ancient custom, some extremely large Japanese companies celebrate Black Friday, the day after the 4th Thursday in November, the day where people of good will come together to buy black things at attractive prices.</p><p>This is all fascinating for people who work in retail or e-commerce. For financial systems, an interesting knock-on consequence of it is that you will have a sudden, predictable-as-the-sun-rising transaction surge on Black Friday, <em>smack dab in the middle of a four day period during which money is not moving</em>. We will return to that in a moment.</p><p>Money starts moving again on Monday. Cyber Monday.</p><p><em>Why</em> is Cyber Monday? It commemorates a perhaps apocryphal meeting between  very different peoples, not infrequently in conflict but fundamentally joined with each other, and their decision to bond over a universal human experience: shopping.&nbsp;</p><p>Cyber Monday <em>also</em> causes a transaction surge. The more indexed a financial institution is to e-commerce companies relative to non-retailing or not-very-online companies, the larger a transaction surge they will see. As time goes to infinity the Internet economy will be called “the economy”, but time is very far from infinity yet, and so different firms have differential exposure to “cyber.” [4]</p><p>Now let’s ignore the sociology and marketing considerations and focus simply on the operational mechanics: a staggering volume of purchases went through, over a variety of payment systems with very different legal and technical substrates, during a period in which the banking system <em>mostly</em> does not move money between companies.</p><p>Payments companies (and others) owe performance to their customers as defined by contracts, negotiations, market norms, promises, implicit understandings, and similar. And sometimes there is a mismatch between what is expected and what can be easily delivered.</p><p>This problem presents in fractal detail at many firms. Let’s simplify it for the purpose of illustration.</p><p>If you have promised your customer “I will pay out your sales on the next business day” and an underlying “rail” [5] takes <em>two</em> business days to pay you, you have a one-day mismatch. Your promise “consumes float.” [6] There are many, many ways you can deal with this in the ordinary course of business, and they all round to “constantly advance customers a bit of our own money.”</p><p><em>Why</em> do you do that? Many financial institutions insulate their customers from complexity and risk because <em>that is the service the financial industry offers to society</em>. We (the financial industry) teleport value through time and across space and make this look easy. We (every user of every financial system, inclusive of you and me) pay for that. </p><p>Complexity and risk are, like matter and energy, conserved within the system. Moving them from individual businesses to financial providers lets the providers deal with them efficiently for usual specialization-of-labor and comparative advantage reasons.&nbsp;</p><p>Anyhow, once a year, extremely predictable <em>in timing</em> but not necessarily <em>in magnitude</em>, you do not need to float one day of sales, like you do daily. You do not need to float three days, like most weekends. You need to float five-ish days <em>including the largest sale day of the year</em>. And you whisper fervent prayers that all the wires you expect arrive <em>exactly</em> when you expect them.</p><p>What are those wire sized like? I mean, in this sketch of issues that affect a large universe of companies differently, it could vary considerably. Let <a href="https://stripe.com/newsroom/news/bfcm2023"><u>your imagination</u></a> run wild.</p><p>Black Friday would be a bad day for hitches principally because you don’t want to break for customers on a very important day for them. Cyber Monday would be a bad day for hitches for that reason, too, but also because an entirely different kind of breakage <em>at an entirely different company</em> would hit you like a freight train.</p><p>And since you’re aware of that, maybe hundreds of people have spent the last few weeks diligently wargaming out the BFCM scenarios and writing contingency plans. Maybe you also carefully modeled BFCM float needs with finance. Maybe you also did pedestrian but real capital markets work to make sure that you could survive another company having an unfortunately timed operational stumble.</p><p><a href="https://www.sleepfoundation.org/nutrition/what-is-tryptophan" rel="noreferrer">Tryptophan</a> makes us do strange things, after all.</p><h2 id="this-is-crazy-let%E2%80%99s-get-rid-of-holidays">"This is crazy. Let’s get rid of holidays."</h2><p>The culture that is heavily-online technologists is extremely frustrated with systems which go down on a predictable schedule.</p><p>Cryptocurrency enthusiasts in particular enjoy distributed systems that are constantly up and have no single points of failure. For example, you could have every actor in the financial markets open accounts at a single bank. Why would you do that? Well, most trades involve one leg that never sleeps (blockchains, an industry term for slow databases) and one leg which implicates money (which largely exists on fast databases operated by organizations that do have sleep schedules and holidays). Convince one bank to give you an internal API to make book transfers and now money moves 24/7. And just for redundancy, we’ll use <a href="https://ir.silvergate.com/news/news-details/2023/Silvergate-Capital-Corporation-Announces-Intent-to-Wind-Down-Operations-and-Voluntarily-Liquidate-Silvergate-Bank/default.aspx"><u>two</u></a> <a href="https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list/signature-ny.html"><u>banks</u></a>. Checkmate, TradFi.</p><p>Less sardonically, there is a lesson here: systems which intermediate between cultures <em>are useful</em>. Intermediating between cultures is a thing the world urgently needs and <em>is extremely prepared to pay for</em>. Systems which intermediate between cultures will frequently need to cross a gap between operating schedules. You cannot simply wish away that gap. You cannot simply assert that the one true operating schedule is 24/7.</p><p>That certainly doesn’t stop technologists from trying. If you want to drive one batty, ask about the IRS applications which have office hours (<a href="https://www.irs.gov/refunds/when-is-wheres-my-refund-available"><u>example</u></a>).</p><p>There is, believe it or not, an engineering reason for some applications to have office hours, which you’ll see in multiple places in the U.S. government. Generally: the application interfaces with a legacy system which ultimately depends on choices made back during the mainframe era. During that era, computer operators could run programs in interactive mode, with an operator at the keyboard, or in batch mode. To avoid impacting the operators of the system (i.e. regular employees doing their day-to-day jobs), batches were designed to be run at night. And so they have been run at night for many, many decades.</p><p>Now, here’s the rub: <em>we don’t know</em> if the interactive mode programs, like say looking up the status of a tax refund, are safe to run while the batches are running. [7] So we continue previous practice and don’t allow the interactive mode programs to run while the batch programs are running. It would be a very, very bad thing if the software which in a very real way <em>is the United States of America</em> suddenly developed data integrity issues because someone hooked a web application to it. The technologists (and managers) in charge of those systems are terrified of e.g. data integrity issues when e.g. sending out Social Security payments because the consequences of that would include e.g. food riots in Kansas.</p><p>But that is more an explanation of an infelicity rather than an argument that there is actually a positive consequence of holidays. There is.</p><p>Would you believe that banks <em>intentionally cause misaligned operating schedules</em>? It is an important tool to detect and discourage particular forms of fraud.</p><p>A particular terrifying genre of fraud is perpetrated by insiders with advanced knowledge of a financial institution’s back office procedures. A teenager with moral flexibility can cheat you out of a pair of sneakers. A professionalized fraud operation based in a non-extradition country can rob you for millions. But a single insider who understands your back office reasonably well can bring down a bank or cause billions of losses. Barrings and Daiwa in ‘95. Société Générale in ‘08. UBS in ‘11. [8]</p><p>A <em>very old</em> control for this sort of thing is forcing holidays, with the goal that the set of staff engaged in a conspiracy don’t have a sufficient number of conspirators at the keyboard in all the right places on all the right days the conspiracy needs to operate to be undetected.</p><p>A financial CEO who <a href="https://www.bloomberg.com/features/2023-ftx-crypto-photos/" rel="noreferrer">sleeps at the office on a beanbag chair</a> might be commendably devoted to his work. But it is no slur against devoted CEOs to say that their companies and their customers would be well-served by them <em>not being allowed to do that</em>. Take the day off. Let someone cover for you. "Cover" in the sense of "handle your work while you are at rest", not in the sense of "cover up" a hole in the balance sheet. Nobody expects that there is a hole in the balance sheet. And since there is not a hole in the balance sheet, a fellow responsible professional who has an enormous personal and professional regard for you will, applying math and procedures in the usual fashion, receive a balance sheet from you when you leave and give an updated one to you when you return. Perfectly balanced as all things should be. No need to snap.</p><p><em>If we didn’t have holidays, we’d have been forced to invent them.</em> We accept degraded performance (very useful humans: not at keyboard!) as an organizational <a href="https://www.techtarget.com/whatis/definition/Chaos-Monkey">chaos monkey</a> to shake out far more serious issues.</p><p>Does it work? Well, there exist financial institutions that haven’t been reduced to smoking craters by insider fraud, so that is a point in its favor. And, like all controls, this one operates in a constellation (different controls reinforce each other) and on a portfolio basis (you win some and you lose some but are judged on how they net rather than judged on absence of losers).</p><h3 id="will-this-change">Will this change?</h3><p>In an increasingly interconnected world where decisions are increasingly made by people who count <em>and value</em> nines, you can reasonably expect financial systems to partially close the gap between historical practice and contemporary practice of e.g. Google Search.</p><p>As I said before: cultures create systems and systems create cultures. Both systems and cultures <em>change over time</em>. The rate of change in infrastructure specifically is much lower than the rate of change we observe in e.g. fashion. But infrastructure <em>does change</em>. Credit cards were invented in a world where Chicago and Los Angeles were considered to be socially distant from each other, to allow Chicagoans in L.A. to enjoy the same trust they would enjoy in Chicago. Cultural change, <em>real observable change with consequences</em>, is not something that can only be measured on generational timescales. </p><p>But should one expect the financial system to operate constantly? Not only should you not expect that, that is not even a coherent thing to expect. The financial system is an interconnected web of individual organizations which contain systems which contain some combination of subsystems etc etc etc and at some level depends on individual people to whom complex sociocultural promises have been made and who have biological need for sleep.</p><p>And those people, for the foreseeable future, will continue to periodically rest and continue to periodically celebrate just like they continue to work on the behalf of the societies their financial systems support.</p><p><br>[1] While Taro is quite a popular name in Japan, Taro is also the usual analog to  the John in John Doe. Jane Doe is frequently rendered as Hanako. When you find them in a particular company's documentation, their family name will frequently be the name of the company, which is delightful for readers of Japanese corporate documentation who are also cyberpunk fans. (This includes many writers of Japanese corporate documentation.)</p><p>[2] The Red Priestess Melisandre could not be reached for comment on whether the Lord of Light's theology encompasses computer systems.</p><p>[3] Serious paperwork connoisseurs know that "It depends" is a deep rabbit hole here, including in the United States. Was the day a company founded the day the founders started working on a project or the day they mutually agreed it should be a company or the day they signed a contract with each other or the day they submitted paperwork to the state of Delaware or the day Delaware declared that paperwork was accepted? <em>Yes</em>. The fact that the day the company was founded and the day the company was founded are frequently months apart is not even a tiny bit weird.</p><p>[4] Readers of a certain age might sensibly ask what “cyber” means. Consider it a way to gesture broadly at technology used almost exclusively by people who both do not understand technology and feel some amount of pride in that. Teams at large retailers, believing online commerce was doomed to be a tiny sideline like catalogs and only worth tens of billions of dollars, were involved in naming Cyber Monday. The other place you’re likely to hear it frequently is American national security circles, which exist in a superposition of understanding that technology can certainly be used to kill people and break things while also believing that it’s not a <em>real</em> way to kill people and break things if it is the sort of technology built by people who look like pre-juice Steve Rogers.</p><p>[5] "Financial rails" are the legal, technical, and organizational infrastructure which allows one to move money around. That's a mouthful; "rails" is one syllable and also communicates "I believe I understand this; you don't need to explain to me that money doesn't actually move when we move money." An illustrative usage: "Did that transaction go over ACH rails?" "No, it was <a href="https://twitter.com/patio11/status/1752054398858022990" rel="noreferrer">on us</a>."</p><p>[6] Positive float is the characteristic that you enjoy the legitimate but temporary use of other people's money as a consequence of their business dealings with you not specifically intended to cause that. The classic example is in the insurance industry, where insurers might get a few years to sit on premiums before paying them back out. Negative float is the opposite condition, where others get to use your money. Negative float <em>isn't bad</em>. It will cause you to incur a cost of doing business, like labor and rent are a cost of doing business, in the service of providing a valuable service to customers at a reasonable price.</p><p>[7] To spare you a long digression into the joys of government system architecture documents, accept this sketch: the IRS' web applications are frequently impersonating a human operator with preternaturally good typing skills.</p><p>[8] Yes, this is a reference to Margin Call, the best movie about finance ever made. The scene it references isn't even in the best five scenes of a single character (a bank CEO played by Jeremy Irons in what might be the best work of a distinguished career).</p>

        

        <div>
          <h2>Want more essays in your inbox?</h2>
          <p>I write about the intersection of tech and finance, approximately biweekly. It's free.</p>
                  </div>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Money bubble (196 pts)]]></title>
            <link>https://www.tbray.org/ongoing/When/202x/2024/02/25/Money-AI-Bubble</link>
            <guid>39553743</guid>
            <pubDate>Thu, 29 Feb 2024 19:17:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tbray.org/ongoing/When/202x/2024/02/25/Money-AI-Bubble">https://www.tbray.org/ongoing/When/202x/2024/02/25/Money-AI-Bubble</a>, See on <a href="https://news.ycombinator.com/item?id=39553743">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="centercontent">
<p itemprop="description">I think I’m probably going to lose quite a lot of money in the next year or two. It’s partly AI’s fault, but not
    mostly. Nonetheless I’m mostly going to write about AI, because it intersects the technosphere, where I’ve lived for
    decades.</p>

<p>I’ve given up having a regular job. The family still has income but mostly we’re harvesting our
    savings, built up over decades in a well-paid profession. Which means that we are, willy-nilly, investors. And thus aware of the
    fever-dream finance landscape that is InvestorWorld.</p>

<p id="p-1"><span>The Larger Bubble</span> · 
Put in the simplest way: Things have been too good for too long in InvestorWorld: low interest, high profits, the unending rocket
    rise of the Big-Tech sector, now with AI afterburners. Wile E. Coyote hasn’t actually run off the edge of the cliff yet, but
    there are just way more ways for things to go wrong than right in the immediate future.</p>

<p>If you want to dive a little deeper, <cite>The Economist</cite> has a sharp (but
    paywalled) take in
    <a href="https://www.economist.com/finance-and-economics/2024/02/25/stockmarkets-are-booming-but-the-good-times-are-unlikely-to-last">Stockmarkets
    are booming. But the good times are unlikely to last</a>. Their argument is that profits are overvalued by investors because, in
    recent years, they’ve always gone up. Mr Market ignores the fact that that at least some of those gleaming profits are artifacts of
    tax-slashing by right-wing governments.</p>

<p>That piece considers the observation that “Many investors hope that AI will ride to the rescue” and is politely
    skeptical.</p>

<p id="p-2"><span>Popping the bubble</span> · 
My own feelings aren’t polite; closer to
    <a href="https://finance.yahoo.com/news/yep-you-are-living-in-a-nvidia-led-tech-bubble-110014738.html">Yep, you are living in a
    Nvidia-led tech bubble</a> by Brian Sozzi over at Yahoo! Finance.</p>

<p>Sozzi is fair, pointing out that this bubble feels different from the cannabis and crypto crazes; among other things,
    chipmakers and cloud providers are reporting big high-margin revenues for real actual products. But he hammers the central point:
    What we’re seeing is FOMO-driven dumb money thrown at technology by people who have no hope of
    understanding it. Just because everybody else is and because the GPTs and image generators have cool demos.
    Sozzi has the numbers, looking at valuations through standard old-as-dirt filters and shaking his head at what he sees.</p>

<p>What’s going to happen, I’m pretty sure, is that AI/ML will, inevitably, disappoint; in the financial sense I mean, probably
    doing some useful things, maybe even a lot, but not generating the kind of profit explosions that you’d need to justify
    the bubble. So it’ll pop, and my bet it is takes a bunch of the finance world with it. As bad as 2008? Nobody knows, but it
    wouldn’t surprise me.</p>

<p>The rest of this piece considers the issues facing AI/ML,  with the goal of showing why I see it as
    a bubble-inflator and eventual bubble-popper.</p>

<p>First, a disclosure: I speak as an educated amateur. I’ve never gone much below the surface of the technology, never
    constructed a model or built model-processing software, or looked closely at the math.  But I think the discussion below still
    works.</p>

<p id="p-3"><span>What’s good about AI/ML</span> · 
Spoiler: I’m not the kind of burn-it-with-fire skeptic that I became around anything blockchain-flavored. It is clear
    that generative models manage to embed significant parts of the structure of language, of code, of pictures, of
    many things where that has previously not been the case. The understanding is sufficient to reliably accomplish the objective:
    <i>Produce plausible output</i>.</p>

<p>I’ve read enough Chomsky to believe that facility with language is a defining characteristic of intelligence. More than that, a
    necessary but not sufficient ingredient.  I dunno if anyone will build an AGI in my lifetime, but I am confident that the task
    would remain beyond reach without the functions offered by today’s generative models.</p>

<p>Furthermore, I’m super impressed by something nobody else seems to talk about: Prompt parsing. Obviously, prompts are
    processed into a representation that reliably sends the model-traversal logic down substantially the right
    paths. The LLMbots of this world may regularly be crazy and/or just wrong, but they do consistently if not correctly address the
    substance of the prompt.
    There is seriously good natural-language engineering going on here that AI’s critics aren’t paying enough attention
    to.</p>

<p>So I have no patience with those who scoff at today’s technology, accusing it being a glorified Markov chain. Like the
    song says:  Something’s
    happening here! (What it is ain’t exactly clear.)</p>

<p>It helps that in the late teens I saw neural-net pattern-matching at work on real-world problems from close up and
    developed serious respect for what that technology can do; An example is EC2’s
    <a href="https://aws.amazon.com/blogs/compute/evaluating-predictive-scaling-for-amazon-ec2-capacity-optimization/">Predictive Auto
    Scaling</a> (and gosh, it looks like
    <a href="https://www.google.com/search?rls=en&amp;q=predictive+auto+scaling&amp;ie=UTF-8&amp;oe=UTF-8">the competition has it
    too</a>).</p>

<p>And recently, Adobe Lightroom has shipped a pretty awesome “Select Sky” feature. It makes my M2 MacBook
    Pro think hard for a second or two, but I rarely see it miss even an isolated scrap of sky off in the corner of the frame.  It
    allows me, in a picture like this, to make the sky’s brightness echo the water’s.</p>

<p><a href="https://www.tbray.org/ongoing/When/202x/2024/02/25/-big/PXL_20240111_213727870.jpg.html"><img alt="Brightly-lit boats on dark water under a dark sky" title="Brightly-lit boats on dark water under a dark sky" src="https://www.tbray.org/ongoing/When/202x/2024/02/25/PXL_20240111_213727870.png"></a></p>
<p>And of course I’ve heard about success stories in radiology and other disciplines.</p>

<p>Thus, please don’t call me an “AI skeptic” or some such. There is a there there.</p>

<p id="p-4"><span>But…</span> · 
Given that, why do I still think that the flood of money being thrown at this tech is dumb, and that most of it will be lost?
    Partly just because of that flood. When financial decision makers throw loads of money at things they don’t
    understand, lots of it is <em>always</em> lost.</p>

<p>In the Venture-Capital business, that’s an understood part of the business
    cycle; they’re looking to balance that out with a small number of 10x startup wins.
    But when big old insurance companies and airlines and so on are piling in and releasing effusive statements about building
    the company around some new tech voodoo, the outcome, in my experience, is very rarely good.</p>

<p>But let’s be specific.</p>

<p id="p-5"><span>Meaning</span> · 
As I said above, I think the human mind has a large and important language-processing system.  But that’s not all. It’s also
    a (slow, poorly-understood) computer, with access to a medium-large database of facts and recollections, an ultra-slow numeric
    processor, and a facilities for estimation, prediction, speculation, and invention. Let’s group all this stuff together and call
    it “meaning”.</p>

<p>Have a look at <a href="https://aclanthology.org/2020.acl-main.463.pdf">Climbing towards NLU:
    On Meaning, Form, and Understanding in the Age of Data</a> by Emily Bender and Alexander Koller (July 2000). I don’t agree with
    all of it, and it addresses an earlier generation of generative models, but it’s very thought-provoking. It postulates the
    “Octopus Test”, a good variation on the bad old Chinese-Room analogy. It talks usefully about how human language acquisition
    works. A couple of quotes: “It is instructive to look at the past to appreciate this question. Computational linguistics has
    gone through many fashion cycles over the course of its history” and “In this paper, we have argued that in contrast to some
    current hype, meaning cannot be learned from form alone.”</p>

<p>I’m not saying these problems can’t be solved. Software systems can be equipped with databases of facts, and who knows,
    perhaps some day estimation, prediction, speculation, and invention. But it’s not going to be easy.</p>

<p id="p-7"><span>Difficulty</span> · 
I think there’s a useful analogy between the stories AI and of self-driving cars. As I write this, 
    Apple has apparently decided that 
    <a href="https://arstechnica.com/gadgets/2024/02/after-a-decade-of-stops-and-starts-apple-kills-its-electric-car-project">generative 
    AI is easier than shipping an autonomous car</a>. I’m particularly sensitive to this analogy because back around 2010, as the
    first self-driving prototypes were coming into view, I predicted, loudly and in public, that this technology was about to become
    ubiquitous and turn the economy inside out. Ouch.</p>

<p>There’s a pattern: The technologies that really do change the world tend to have strings of successes, producing obvious
    benefits even in their earliest forms, to the extent that geeks load them in the back floor of organizations just to get shit
    done. As they say, “The CIO is the last to know.”</p>

<p>Contrast cryptocurrencies and blockchains, which limped along from year to year, always promising a brilliant future, never
    doing anything useful.  As to the usefulness of self-driving technology, I still think it’s gonna get there, but it’s surrounded
    by a cloud of litigation.</p>

<p>Anyhow, anybody who thinks that it’ll be easy to teach “meaning” (as I described it above) to today’s generative AI is a fool,
    and you shouldn’t give them your money.</p>

<p id="p-6"><span>Money and carbon</span> · 
Another big problem we’re not talking about enough is the cost of generative AI.
    <cite>Nature</cite> offers    
    <a href="https://www.nature.com/articles/d41586-024-00478-x">Generative AI’s environmental costs are soaring — and mostly
    secret</a>. In a Mastodon thread,
    <a href="https://phanpy.social/#/social.v.st/a/109360452395342558">@Quixoticgeek@social.v.st</a> says 
    <a href="https://phanpy.social/#/social.v.st/s/111991430750212364">We need to talk about data centres</a>, and includes a few
    hard and sobering numbers.</p>

<p>Short form: This shit is <em>expensive</em>, in dollars and in carbon load. Nvidia pulled in
    <a href="https://investor.nvidia.com/news/press-release-details/2024/NVIDIA-Announces-Financial-Results-for-Fourth-Quarter-and-Fiscal-2024/">$60.9
    billion in 2023, up 126% from the previous year</a>, and is heading for a $100B/year run rate, while reporting a 75% margin.</p>

<p>Another thing these articles <em>don’t</em> mention is that building, deploying, and running generative-AI systems requires significant
    effort from a small group of people who now apparently constitute the world’s highest-paid cadre of engineers. And good luck
    trying to hire one if you’re a mainstream company where IT is a cost center.</p>

<p>All this means that for the technology to succeed, it not only has to do something useful, but people and businesses will have to
    be ready to pay a significantly high price for that something.</p>

<p>I’m not saying that there’s nothing that qualifies, but I am betting that it’s not in ad-supported territory.</p>

<p>Also, it’s going to have to deal with pushback from unreasonable climate-change resisters like, for example, me.</p>

<p id="p-8"><span>Anyhow…</span> · 
I kind of flipped out, and was motivated to finish this blog piece, when I saw
    <a href="https://www.engadget.com/uk-government-wants-to-use-ai-to-cut-civil-service-jobs-140031159.html">this</a>: “UK
    government wants to use AI to cut civil service jobs: Yes, you read that right.” The idea<span> —</span> to have
    citizen input processed and responded to by an LLM<span> —</span> is hideously toxic and broken; and usefully
    reveals the kind of thinking that makes morally crippled leaders all across our system love this technology.</p>

<p>The road ahead looks bumpy from where I sit. And when the business community wakes up and realizes that replacing
    people with shitty technology doesn’t show up as a positive on the financials after you factor in the consequences of customer
    rage, that’s when the hot air gushes out of the bubble.</p>

<p>It might not take big chunks of InvestorWorld with it. But I’m betting it does.</p>

<hr>


<hr>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dune: Part Two Is the Best Sci-Fi Film of the Decade (114 pts)]]></title>
            <link>https://www.esquire.com/entertainment/movies/a46885292/dune-part-two-review/</link>
            <guid>39553000</guid>
            <pubDate>Thu, 29 Feb 2024 18:22:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.esquire.com/entertainment/movies/a46885292/dune-part-two-review/">https://www.esquire.com/entertainment/movies/a46885292/dune-part-two-review/</a>, See on <a href="https://news.ycombinator.com/item?id=39553000">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-journey-body="standard-article"><p data-journey-content="true" data-node-id="0">You don’t need to be a studio head or a theater owner to realize that everyone in Hollywood has their fingers crossed for <em><a href="https://www.esquire.com/entertainment/movies/a38040674/dune-2-sequel-details/" target="_blank" data-vars-ga-outbound-link="https://www.esquire.com/entertainment/movies/a38040674/dune-2-sequel-details/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="Dune: Part Two">Dune: Part Two</a></em>. Sure, the <a href="https://www.esquire.com/entertainment/movies/a46502302/oscars-2024-snubs-surprises/" target="_blank" data-vars-ga-outbound-link="https://www.esquire.com/entertainment/movies/a46502302/oscars-2024-snubs-surprises/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="Oscars">Oscars</a> are right around the corner, and there are certainly plenty of great films from last year that are worth celebrating, but so far 2024 has been an absolute shit show at the box office. Business had been bad and the product has been even worse. Granted, we’re only three weeks into February, so the sample size is small, but you know things are rough in Tinseltown when trash like <em>Argylle</em> opens at No. 1 and the latest <a href="https://www.esquire.com/entertainment/movies/g13441903/all-marvel-cinematic-universe-movies-ranked/" target="_blank" data-vars-ga-outbound-link="https://www.esquire.com/entertainment/movies/g13441903/all-marvel-cinematic-universe-movies-ranked/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="Marvel">Marvel</a>-affiliated widget off the production line currently sits on Rotten Tomatoes beside a fat green splat and a woeful 13% favorable rating. </p><p data-journey-content="true" data-node-id="1">What does any of this have to do with <em>Dune: Part Two</em>, you may ask. Well, director Denis Villeneuve’s hotly anticipated follow-up to his blissfully weird 2021 adaptation of <a href="https://www.esquire.com/entertainment/books/g38012512/dune-books-in-order/" target="_blank" data-vars-ga-outbound-link="https://www.esquire.com/entertainment/books/g38012512/dune-books-in-order/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="Frank Herbert’s talismanic 1968 novel">Frank Herbert’s talismanic 1968 novel</a> was originally slated to open last November. But because of the <a href="https://www.esquire.com/entertainment/a44544249/sag-aftra-actors-strike-consequences-explained/" target="_blank" data-vars-ga-outbound-link="https://www.esquire.com/entertainment/a44544249/sag-aftra-actors-strike-consequences-explained/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="actors strike">actors strike</a>, Warner Bros. opted to push the film to March 2024, no doubt so that Timothée Chalamet, Zendaya, and newcomers Florence Pugh and <a href="https://www.esquire.com/entertainment/movies/a46603112/austin-butler-dune-masters-of-the-air-interview-2024/" target="_blank" data-vars-ga-outbound-link="https://www.esquire.com/entertainment/movies/a46603112/austin-butler-dune-masters-of-the-air-interview-2024/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="Austin Butler ">Austin Butler </a>could peacock on the red carpet and promote it to the heavens on the late-night talk show circuit. Of course, sci-fi fans bitched and bellyached, as they do. But in retrospect the delay turned out to be a pretty wise move. After all, back in November, all anyone was talking about was <a href="https://www.esquire.com/entertainment/movies/a44495541/barbenheimer-double-feature/" target="_blank" data-vars-ga-outbound-link="https://www.esquire.com/entertainment/movies/a44495541/barbenheimer-double-feature/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="Barbenheimer">Barbenheimer</a> and <a href="https://www.esquire.com/entertainment/movies/a46166568/leonard-bernstein-felicia-montealegre-true-story-maestro/" target="_blank" data-vars-ga-outbound-link="https://www.esquire.com/entertainment/movies/a46166568/leonard-bernstein-felicia-montealegre-true-story-maestro/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="Bradley Cooper’s fake schnozz">Bradley Cooper’s fake schnozz</a>. There wasn’t a lot of oxygen left in the room. But now? Now the stage couldn’t be better set for the further adventures of Paul Atreides. If the <a href="https://www.esquire.com/entertainment/movies/g46353374/best-movies-2024/" target="_blank" data-vars-ga-outbound-link="https://www.esquire.com/entertainment/movies/g46353374/best-movies-2024/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="movies">movies</a> ever needed a savior, it’s right this second. </p><p data-journey-content="true" data-node-id="3">Glancing back at my <a href="https://www.esquire.com/entertainment/movies/a38023702/dune-movie-2021-review/" target="_blank" data-vars-ga-outbound-link="https://www.esquire.com/entertainment/movies/a38023702/dune-movie-2021-review/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="review of the first Dune on this site back in 2021">review of the first <em>Dune</em> on this site back in 2021</a>, I noticed that I called it “the best sci-fi movie of the decade.” Hyperbole? Not really. Remember, the decade wasn’t all that old yet. And to be honest, heading in to the new sequel, I stood by it. But walking out was a different story. Because <em>Dune: Part Two</em> is even better than the first film. The stakes somehow feel exponentially higher, the power struggles are even more mythic and Shakespearean, the onscreen world-building is richer and more exotically filigreed, and the visuals are even more epic and dazzling—something I didn’t think was possible. <em>Dune: Part Two</em> isn’t just an embarrassment of narrative and retinal riches; it’s the sort of big-canvas franchise storytelling we haven’t see since <em>The Lord of the Rings </em>came to a close back at the shire. </p><div size="medium" data-embed="body-image" data-lazy-id="P0-8" data-node-id="4"><p><img alt="dune" title="dune" loading="lazy" width="2100" height="1107" decoding="async" data-nimg="1" sizes="100vw" srcset="https://hips.hearstapps.com/hmg-prod/images/rev-1-dun2-t3-0054r-high-res-jpeg-65d638c878f8f.jpeg?crop=0.791xw:1.00xh;0.0612xw,0&amp;resize=640:* 640w, https://hips.hearstapps.com/hmg-prod/images/rev-1-dun2-t3-0054r-high-res-jpeg-65d638c878f8f.jpeg?crop=0.791xw:1.00xh;0.0612xw,0&amp;resize=768:* 980w, https://hips.hearstapps.com/hmg-prod/images/rev-1-dun2-t3-0054r-high-res-jpeg-65d638c878f8f.jpeg?crop=0.791xw:1.00xh;0.0612xw,0&amp;resize=980:* 1120w, https://hips.hearstapps.com/hmg-prod/images/rev-1-dun2-t3-0054r-high-res-jpeg-65d638c878f8f.jpeg?crop=0.791xw:1.00xh;0.0612xw,0&amp;resize=980:* 1200w, https://hips.hearstapps.com/hmg-prod/images/rev-1-dun2-t3-0054r-high-res-jpeg-65d638c878f8f.jpeg?crop=0.791xw:1.00xh;0.0612xw,0&amp;resize=980:* 1920w" src="https://hips.hearstapps.com/hmg-prod/images/rev-1-dun2-t3-0054r-high-res-jpeg-65d638c878f8f.jpeg?crop=0.791xw:1.00xh;0.0612xw,0&amp;resize=980:*"></p><div><figcaption><span>Niko Tavernise/Warner Bros. Entertainment</span></figcaption><p>Now that Paul Atriedes made the leap to battle-tested hero, Chalamet really lets it fly, summoning a more interesting performance.</p></div></div><p data-journey-content="true" data-node-id="5">If you haven’t revisited the first <em>Dune</em> since it left the multiplex, you don’t need to worry. The opening moments of the film get you right back up to speed without sending you to Wikipedia. Picking up almost exactly where things left off in the opening chapter, we’re reminded that the House of Atreides has fallen with the death of <a href="https://www.esquire.com/entertainment/tv/a39520165/oscar-isaac-interview-moon-knight-star-wars/" target="_blank" data-vars-ga-outbound-link="https://www.esquire.com/entertainment/tv/a39520165/oscar-isaac-interview-moon-knight-star-wars/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="Oscar Isaac’s">Oscar Isaac’s</a> Duke. The dreaded, pasty-faced Harkonnens have taken over the lucrative spice-mining trade on the desert planet of Arrakis. And our hero, the Duke’s son Paul Atreides (Chalamet), and his mystic mother Lady Jessica of the Bene Gessirit (Rebecca Ferguson), are now embedded with the local Fremen freedom fighters on Arrakis (Javier Bardem, Zendaya, et al) as they wage guerilla warfare on the colonialist Harkonnens—and now, by extension, the Emperor (Christopher Walken) and his daughter and one-day successor Princess Irulan (Florence Pugh), who’s been groomed for power by Charlotte Rampling’s black-veiled Reverend Mother. I’m sure that last sentence probably sounds like a lot of nerdy gibberish to the uninitiated (not to mention armchair grammarians), but then again no one would ever confuse Frank Herbert with Hemingway. Simplicity wasn’t his thing. But thanks to Villeneuve and co-writer Jon Spaihts’s elegant, economical script, it all scans more easily than you’d expect.  </p><p data-journey-content="true" data-node-id="6">For those who have been tracking the fits and starts of the <em>Dune </em>franchise online, I don’t think I’m giving away anything by saying that <em>Dune: Part Two</em> is a middle chapter in the franchise. Yes, like the first film, it ends on a cliffhanger. But this time around, it feels like a steeper and more rewarding cliff. And, unlike most middle chapters of a trilogy, this doesn’t feel like a jerry-rigged bridge connecting two more interesting stories. In fact, a who’s who of welcome new faces arrive on the scene to add layers the first installment only hinted at. As the Emperor, Walken dials down his worst mannered tendencies to simultaneously convey a heavy-is-the-head-that-wears-the-crown world-weariness and a craven sense of realpolitik expediency. The Emperor is old enough to have seen how these power struggles play out and he knows that his time on the throne is finite, but at the end of the day loyalty is only as valuable as it is useful. </p><section data-embed="pullquote" data-lazy-id="P0-9" data-node-id="7"><blockquote><blockquote>Villeneuve shows us the magic of movies—a brand of magic that’s all too often invoked, but all too rarely felt these days.</blockquote></blockquote></section><p data-journey-content="true" data-node-id="8">As his royal daughter, Pugh seems to bristle at the idea of being a pawn in a bigger game and how she’s only being told part of the story. And as Feyd-Rautha Harkonnen, the psychotically cruel nephew of Stellan Skarsgard’s Jabba the Hutt-like Baron Harkonnen, Austin Butler is all but unrecognizable behind his character’s alabaster skin, shaved eyebrows, and heavy metal bondage gear. He looks like a younger version of Robert Blake’s specter in David Lynch’s <em>Lost Highway</em> crossed with the most badass member of the Borg collective. His ambition is limitless. His morals are nonexistent. And his bloodlust is unquenchable. Butler, <a href="https://www.esquire.com/entertainment/movies/a46650896/austin-butler-elvis-presley-voice/" target="_blank" data-vars-ga-outbound-link="https://www.esquire.com/entertainment/movies/a46650896/austin-butler-elvis-presley-voice/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="so good in Baz Luhrmann’s Elvis">so good in Baz Luhrmann’s <em>Elvis</em></a>, goes big and gives us a villain to really hiss at. Despite all of Villeneuve’s pricey, future-shock CGI, Butler may be the director’s best special effect.  </p><p data-journey-content="true" data-node-id="9">While other new additions include Léa Seydoux and Anya Taylor-Joy (no spoilers here), <em>Dune: Part Two</em> is, at its heart, a hero’s journey. And as original as <em>Dune</em> may be, its arc is straight out of Joseph Campbell. Which bring us to Chalamet’s Paul Atreides. As excellent and against-type as the actor was in the first <em>Dune</em>, his character’s evolution couldn’t really skirt the fact that he had to start off a little bit whiny and petulant, not unlike Luke Skywalker in <em>A New Hope</em>. But now that he’s made the leap to battle-tested hero, Chalamet really lets it fly, summoning a more interesting performance. Torn between avenging his slain father and fulfilling the messianic destiny that many of the Fremen (including Bardem’s Stilgar) want from him, Paul takes on an interesting new complexity that brings to mind Willem Dafoe’s fallible, self-doubting Jesus in <em>The Last Temptation of Christ</em>, right down to his push-pull romantic connection with Zendaya’s Chani. Ferguson, meanwhile, is allowed to let her witchy side loose even more this time around. Her Lady Jessica is now pregnant, and she not only speaks with the baby daughter growing inside of her, she uses the unborn as a pawn to manipulate Paul’s next move. It’s a deliciously freaky puppet-master performance that manages to draw you in and creep you out. </p><div size="medium" data-embed="body-image" data-lazy-id="P0-10" data-node-id="10"><p><img alt="dune" title="dune" loading="lazy" width="2000" height="1333" decoding="async" data-nimg="1" sizes="100vw" srcset="https://hips.hearstapps.com/hmg-prod/images/rev-1-dun2-38301r-high-res-jpeg-65d6394b666ea.jpg?crop=1.23xw:1.23xh;0,0&amp;resize=640:* 640w, https://hips.hearstapps.com/hmg-prod/images/rev-1-dun2-38301r-high-res-jpeg-65d6394b666ea.jpg?crop=1.23xw:1.23xh;0,0&amp;resize=768:* 980w, https://hips.hearstapps.com/hmg-prod/images/rev-1-dun2-38301r-high-res-jpeg-65d6394b666ea.jpg?crop=1.23xw:1.23xh;0,0&amp;resize=980:* 1120w, https://hips.hearstapps.com/hmg-prod/images/rev-1-dun2-38301r-high-res-jpeg-65d6394b666ea.jpg?crop=1.23xw:1.23xh;0,0&amp;resize=980:* 1200w, https://hips.hearstapps.com/hmg-prod/images/rev-1-dun2-38301r-high-res-jpeg-65d6394b666ea.jpg?crop=1.23xw:1.23xh;0,0&amp;resize=980:* 1920w" src="https://hips.hearstapps.com/hmg-prod/images/rev-1-dun2-38301r-high-res-jpeg-65d6394b666ea.jpg?crop=1.23xw:1.23xh;0,0&amp;resize=980:*"></p><div><figcaption><span>Niko Tavernise/Warner Bros. Entertainment</span></figcaption><p>Paul Atreides (Timothée Chalamet) takes on a complexity that brings to mind Willem Dafoe’s fallible Jesus in <em>The Last Temptation of Christ</em>—right down to his push-pull romantic connection with Chani (Zendaya.)</p></div></div><p data-journey-content="true" data-node-id="11">Still, if Villeneuve’s film was just a gallery of characters fighting for power, warring over spice, and spouting metaphorical mumbo jumbo, it wouldn’t be half the movie it is (although it would still be pretty great). No, the director knows that we’ve paid to go on a ride. A deep, philosophical ride to be sure, but still a ride. And <em>Dune: Part Two</em> never forgets that it’s first and foremost a shock-and-awe eye-candy blockbuster. In an era when we go to the movies only to be bombarded over and over again with the same tired visual tropes and clichés, Villeneuve delivers enthralling, shoot-the-works set pieces that feel like high-wire acts of visual poetry and boundless originality. Witnessing Paul learn how to ride a giant sandworm like a rodeo cowboy waterskiing on a high-speed bullet train is as breathlessly thrilling as watching Charlton Heston racing a chariot in <em>Ben-Hur</em>. </p><p data-journey-content="true" data-node-id="12">Like its predecessor dialed up to eleven, <em>Dune: Part Two</em> is a spectacle that you feel with your head and your heart, but it also never lets your eyes take a break for a minute. It’s a film of grandeur that asks a lot of its audience and rewards us for going on its journey. My advice is don’t just see it, see it on as big a screen as you possibly can and just soak it up. Because Villeneuve shows us the magic of movies—a brand of magic that’s all too often invoked, but all too rarely felt these days. He’s given us nothing less than beautiful and bizarre sci-fi masterpiece bursting with big ideas and even bigger visual wonders. </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ford EVs gain access to Tesla Superchargers starting today (181 pts)]]></title>
            <link>https://arstechnica.com/cars/2024/02/ford-evs-gain-access-to-tesla-superchargers-starting-today/</link>
            <guid>39552446</guid>
            <pubDate>Thu, 29 Feb 2024 17:36:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/cars/2024/02/ford-evs-gain-access-to-tesla-superchargers-starting-today/">https://arstechnica.com/cars/2024/02/ford-evs-gain-access-to-tesla-superchargers-starting-today/</a>, See on <a href="https://news.ycombinator.com/item?id=39552446">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      Happy leap day    —
</h4>
            
            <h2 itemprop="description">The adapter is free if you order it before June 30 or $230 if you wait.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/Fast20Charging20Adapter2028NACS29_03-800x533.jpg" alt="someone plugs a tesla charger cable into an adapter to use with a non-tesla EV">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/02/Fast20Charging20Adapter2028NACS29_03.jpg" data-height="5504" data-width="8256">Enlarge</a> <span>/</span> Ford was the first OEM to announce it was switching to J3400, and it's the first automaker to gain access to the Tesla Supercharger network.</p><p>Ford</p></figcaption>  </figure>

  




<!-- cache hit 2:single/related:4ccc423290dac7d71f6097dc34e9eb05 --><!-- empty -->
<p>Today, Ford electric vehicles gained access to the Tesla Supercharger network. Last&nbsp;May, the Blue Oval was <a href="https://arstechnica.com/cars/2023/05/ford-evs-will-get-access-to-teslas-supercharger-network-in-2024/">the first automaker to throw its lot in</a> with what was then called the North American Charging Standard and is now known as J3400. Ford proved to be the first domino falling, and with Stellantis' announcement <a href="https://arstechnica.com/cars/2024/02/stellantis-will-finally-adopt-tesla-style-fast-charger-plug/">earlier this month</a> that it too would move to J3400, the more compact DC fast-charging plug will be the de facto standard in the next couple of years.</p>
<p>Until Ford made the switch, every non-Tesla EV in North America had settled on the <a href="https://arstechnica.com/cars/2022/07/the-ars-technica-guide-to-electric-vehicle-charging/">Combined Charging Standard 1</a> plug (with the exception of the Nissan Leaf, which still uses CHAdeMO). CCS1 and J3400 use the same electronic communication protocols—only the actual plug and socket are different.</p>
<p>But it will take some time for car makers to start building J3400 ports into their EVs. That should begin next year, probably with the introduction of model year 2026. This means that EVs older than MY26 will need to use a passive adapter to mate a J3400 charger cable with a CCS1-equipped EV.</p>
<p>Ford is making the adapter available for free for <a href="https://arstechnica.com/cars/2023/12/revisiting-the-ford-mustang-mach-e-hows-the-pony-ev-doing-3-years-later/">Mustang Mach-E</a> and F-150 Lightning owners as long as they order one by June 30 of this year. After that date, the adapter will cost $230. Ford says that Ford Pro fleet customers can also order a complimentary adapter for their EV (which includes the <a href="https://arstechnica.com/cars/2022/01/weve-driven-fords-other-electric-workhorse-the-2022-e-transit/">E-Transit</a> as well as the Mach-E and Lightning) by contacting their Ford Pro account manager. (Ford Pro will also contact fleet owners by mail in the coming weeks.)</p>                                            
                                                        
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/02/Fast20Charging20Adapter2028NACS29_05.jpg" data-height="5504" data-width="8256" alt="If you've ever used a dongle before, you should know how to use the charger adapter."><img alt="If you've ever used a dongle before, you should know how to use the charger adapter." src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/Fast20Charging20Adapter2028NACS29_05-980x653.jpg" width="980" height="653"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/02/Fast20Charging20Adapter2028NACS29_05.jpg" data-height="5504" data-width="8256">Enlarge</a> <span>/</span> If you've ever used a dongle before, you should know how to use the charger adapter.</p><p>Ford</p></figcaption></figure>
<p>Ford EVs already use the <a href="https://en.wikipedia.org/wiki/ISO_15118">ISO 15118</a> "plug and charge" protocol, which means they give the charger their billing details as part of the electronic handshake, obviating the need to use an app or credit card to start a charging session. And more than 15,000 Tesla chargers will now show up in the BlueOval charge network, which customers can navigate to via the FordPass smartphone app or the Charge Assist app on their infotainment systems.</p>
<p>Ford EVs aren't compatible with every Tesla Supercharger, however. They must be the more recent units, which are able to charge at up to 250 kW, identified by a black collar at the base of the charging plug. Older chargers, which can only charge at up to 150 kW, have a silver collar instead. Since these older chargers won't appear in the FordPass or ChargeAssist apps, it seems prudent for Ford EV drivers to use either of those to find a suitable charger location.</p>
<p>And the adapter is only for DC fast charging, not for Tesla's AC destination chargers. (Ford's plug-in hybrids are only capable of AC charging, and there is no need for them to have access to an adapter, so they will never be able to use a Supercharger.)</p>
<p>I don't imagine an Ars Technica reader having much trouble with fitting the J3400 adapter, but for people with less dongle experience, Ford has <a href="https://www.ford.com/support/how-tos/electric-vehicles/public-charging/how-do-i-use-the-fast-charging-adapter-nacs/">produced a short tutorial film</a>. Perhaps the only potential pain point will be unplugging one's EV and driving off without the adapter—a $230 lesson to learn—but since the Tesla cable needs to be put back in its holster, even that seems pretty unlikely.</p>
<p>"This move will improve the public charging experience by giving our customers even more choice and is a vital part of our growth as an EV brand," said Ford President and CEO Jim Farley.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Neurosurgeon pioneers Alzheimer's, addiction treatments using ultrasound [video] (209 pts)]]></title>
            <link>https://www.youtube.com/watch?v=7BGtVJ3lBdE</link>
            <guid>39551457</guid>
            <pubDate>Thu, 29 Feb 2024 16:24:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=7BGtVJ3lBdE">https://www.youtube.com/watch?v=7BGtVJ3lBdE</a>, See on <a href="https://news.ycombinator.com/item?id=39551457">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: We built the fastest spreadsheet (244 pts)]]></title>
            <link>https://rowzero.io</link>
            <guid>39551064</guid>
            <pubDate>Thu, 29 Feb 2024 15:57:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rowzero.io">https://rowzero.io</a>, See on <a href="https://news.ycombinator.com/item?id=39551064">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__next"><header><nav aria-label="Global navigation"></nav></header><div><svg width="61" height="44" viewBox="0 0 61 44" fill="none" xmlns="http://www.w3.org/2000/svg"> <path fill-rule="evenodd" clip-rule="evenodd" d="M14.1437 0.833984H30.1789L19.4938 17.5202C21.9667 18.2167 24.0632 19.5048 25.7642 21.3848C27.7332 23.5612 28.694 26.3427 28.694 29.664C28.694 33.5108 27.3181 36.7352 24.5707 39.2816C21.9238 41.8241 18.614 43.086 14.696 43.086C10.7667 43.086 7.40967 41.7687 4.67177 39.1322L4.66667 39.1273L4.66167 39.1223C1.99167 36.4523 0.697998 32.7862 0.697998 28.224C0.697998 23.6994 2.60427 18.6111 6.29129 12.9831C6.29174 12.9824 6.2922 12.9817 6.29265 12.981L14.1437 0.833984ZM14.9603 2.33398L7.54988 13.7991L7.54734 13.803C3.93926 19.3101 2.198 24.1091 2.198 28.224C2.198 32.4907 3.3986 35.735 5.71732 38.0566C8.16246 40.4089 11.1398 41.586 14.696 41.586C18.2635 41.586 21.1919 40.4495 23.5362 38.1954L23.5464 38.1856C25.9795 35.9327 27.194 33.1108 27.194 29.664C27.194 26.6492 26.3308 24.2468 24.6518 22.3912C22.9397 20.4988 20.7798 19.2798 18.144 18.7344L17.0765 18.5136L27.4371 2.33398H14.9603ZM44.8157 0.833984H60.8509L50.1658 17.5202C52.6387 18.2167 54.7352 19.5048 56.4361 21.3848C58.4052 23.5612 59.366 26.3427 59.366 29.664C59.366 33.5108 57.9901 36.7352 55.2426 39.2816C52.5958 41.8241 49.286 43.086 45.368 43.086C41.4387 43.086 38.0817 41.7687 35.3438 39.1322L35.3387 39.1273L35.3337 39.1223C32.6637 36.4523 31.37 32.7862 31.37 28.224C31.37 23.6995 33.2762 18.6113 36.9631 12.9833C36.9636 12.9825 36.9641 12.9818 36.9647 12.981L44.8157 0.833984ZM45.6323 2.33398L38.2219 13.7991L38.2193 13.803C34.6113 19.3101 32.87 24.1091 32.87 28.224C32.87 32.4908 34.0707 35.7351 36.3895 38.0568C38.8346 40.4089 41.8119 41.586 45.368 41.586C48.9355 41.586 51.8639 40.4495 54.2082 38.1954L54.2184 38.1856C56.6515 35.9327 57.866 33.1108 57.866 29.664C57.866 26.6492 57.0028 24.2468 55.3238 22.3912C53.6117 20.4988 51.4518 19.2798 48.816 18.7344L47.7485 18.5136L58.1091 2.33398H45.6323Z" fill="black"></path> </svg><h3>Row Zero is an impressive feat of engineering, making big data feel small in a familiar spreadsheet interface.</h3><p><span>Wes McKinney</span><br>Creator of Pandas and Apache Arrow<!-- --> <!-- --> </p></div><div id="use-cases"><h2>Use cases</h2><p>Give your business access to cloud data sources in a tool they already know how to use. Explore hundreds of millions of rows, perform ad-hoc analyses, and monitor trends from the comfort of a spreadsheet.</p></div><section><div id="features"><p><img alt="Power and speed icon" srcset="https://rz-web.vercel.app/images/icon-rocket.svg?w=64 1x, https://rz-web.vercel.app/images/icon-rocket.svg?w=128 2x" src="https://rz-web.vercel.app/images/icon-rocket.svg?w=128" width="50" height="50" decoding="async" data-nimg="1" loading="lazy"></p><h3>Power and speed</h3><ul><li>Write Excel-compatible formulas to process hundreds of millions of rows instantly</li><li>No more slow dashboards - filter, sort, pivot, and plot in milliseconds</li><li>Upload multi-GB CSV and JSONL files - no need for databases or expensive BI tools</li></ul></div><div id="features"><p><img alt="Familiar UI icon" srcset="https://rz-web.vercel.app/images/icon-spreadsheet.svg?w=64 1x, https://rz-web.vercel.app/images/icon-spreadsheet.svg?w=128 2x" src="https://rz-web.vercel.app/images/icon-spreadsheet.svg?w=128" width="50" height="50" decoding="async" data-nimg="1" loading="lazy"></p><h3>Familiar UI</h3><ul><li>Excel compatible - execute VLOOKUPS, XLOOKUPS, COUNTIFS, INDEX MATCHs,<!-- --> <a href="https://rowzero.io/docs/spreadsheet-functions">and more</a></li><li>Filter, sort, pivot, and plot the way you already know how - no BI tool training required</li><li>Enable your business teams with an analysis tool they already know how to use</li></ul></div><div id="features"><p><img alt="Connect to any data source icon" srcset="https://rz-web.vercel.app/images/icon-connection.svg?w=64 1x, https://rz-web.vercel.app/images/icon-connection.svg?w=128 2x" src="https://rz-web.vercel.app/images/icon-connection.svg?w=128" width="50" height="50" decoding="async" data-nimg="1" loading="lazy"></p><h3>Connect to any data source</h3><ul><li>Row Zero runs in the cloud and connects directly to any data source</li><li>Connect data warehouses, data lakes, APIs, and any other service to build models on live data</li><li>Save time and reduce mistakes by connecting to live data instead of copy/pasting</li></ul></div><div id="features"><p><img alt="Sharing and collaboration icon" srcset="https://rz-web.vercel.app/images/icon-collaboration.svg?w=64 1x, https://rz-web.vercel.app/images/icon-collaboration.svg?w=128 2x" src="https://rz-web.vercel.app/images/icon-collaboration.svg?w=128" width="50" height="50" decoding="async" data-nimg="1" loading="lazy"></p><h3>Sharing and collaboration</h3><ul><li>Collaborate in real time - Share each workbook with editor and viewer permissions</li><li>Govern your data. No more Sharepoint or untraceable emails with .xlsx attachments </li><li>Provide refresh permissions (without revealing credentials) so business teams can build models off live data</li><li>Use the Follow feature when presenting to walk team members through your analysis</li></ul></div><div id="features"><p><img alt="Python icon" srcset="https://rz-web.vercel.app/images/icon-code.svg?w=64 1x, https://rz-web.vercel.app/images/icon-code.svg?w=128 2x" src="https://rz-web.vercel.app/images/icon-code.svg?w=128" width="50" height="50" decoding="async" data-nimg="1" loading="lazy"></p><h3>Python</h3><ul><li>Decompose long spreadsheet formulas with Python helper functions to improve readability and prevent costly errors</li><li>Import popular Python modules like <span>pandas</span>,<!-- --> <span>numpy</span>, <span>scipy</span>, and <span>yfinance</span>, to perform complex analysis in a familiar tool</li><li>Never write VBA again</li></ul></div></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The internet feels fake now. It's all just staged videos and marketing (121 pts)]]></title>
            <link>https://old.reddit.com/r/Millennials/comments/1b301qj/the_internet_feels_fake_now_its_all_just_staged/</link>
            <guid>39551035</guid>
            <pubDate>Thu, 29 Feb 2024 15:56:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/Millennials/comments/1b301qj/the_internet_feels_fake_now_its_all_just_staged/">https://old.reddit.com/r/Millennials/comments/1b301qj/the_internet_feels_fake_now_its_all_just_staged/</a>, See on <a href="https://news.ycombinator.com/item?id=39551035">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>All things Generation Y (Millennials).</p>

<p>Millennials are the generation that were born between 1981 to 1996. Our generation comes after Gen X, and before Gen Z.</p>

<p>Check out our sister subreddit, <a href="https://old.reddit.com/r/Zillennials">/r/Zillennials</a>. As well as <a href="https://old.reddit.com/r/decadeology">r/decadeology</a> for more in depth cultural analysis. </p>

<p>Zillennials are the micro-generation between Gen Z and Millennials, years ~1994-1999. Join the discord server here --&gt; <a href="https://discord.gg/Se8Nr5JMbU">https://discord.gg/Se8Nr5JMbU</a></p>

<p>All generations are welcome to post &amp; comment.</p>

<hr>

<p>Rules:</p>

<ul>
<li><p>Treat Others Like A Human Being
Basically, just be cool, and you'll avoid 90% of potential problems. Remember that, with exception of bots/spam, you are talking to a human on the other end, and you should talk to that person as you would in real life.</p></li>
<li><p>No Discrimination, Mud Slinging, or Hate Speech
Direct mistreatment of users for their race, religion, sexuality, and other forms of discrimination are strictly prohibited. Politics are allowed but only for talking about in a civil manner.</p></li>
<li><p>No Personal Attacks or Harrassment
Do not personally attack others, harass others, stalk others, or leak their personal information (Doxxing).</p></li>
<li><p>No Spamming or Low-Level Content
Any instances of spamming, trolling, clearly repetitive content, overtly low-level content, and negatively provocative content will be removed. This is to maintain user experience and to keep the subreddit running smoothly.</p></li>
<li><p>Subreddit Content Should Lean Towards Positive or Nostalgia Focused Discussion
Mostly this serves as a guideline but the content on this subreddit should be more geared towards Millennial nostalgia and the positive aspects of our generation.</p></li>
<li><p>No NSFW Content
Do not post gore, nudity, pornography, links to NSFW sites, etc.</p></li>
<li><p>No Personal Information
Do not share another person's personal information. Anything you share about yourself you share at your own risk. Always keep the safety of yourself and others in mind.</p></li>
<li><p>No Gatekeeping
All forms of gatekeeping will be deleted and the perpetrator will be warned. Further gatekeeping will result in a ban on the perpetrator. It's fine to discuss differences and observations in a civil manner.</p></li>
<li><p>No Discussing Definitions / "What Generation am I?" / "When do Millennials start and end?" / "Who is considered a Millennial?" posts
This has been discussed countless times already. Otherwise, you're free to discuss whatever it is on <a href="https://old.reddit.com/r/generationology">r/generationology</a> or <a href="https://old.reddit.com/r/decadeology">r/decadeology</a>.</p></li>
<li><p>No "surveys" / "data" posts
This is a recurring theme of past posts, questions about "What do Millennials see in a brand?" or "What are your opinions on _____ brand" are not allowed. There are plenty of other research subreddits for these types of posts.</p></li>
<li><p>No Politics
Our community is <strong>not</strong> <a href="https://old.reddit.com/r/politics">r/politics</a> or <a href="https://old.reddit.com/r/antiwork">r/antiwork</a>. For these types of discussions please use other subs. This rule has been implemented to avoid toxic users and discussions here. This may be lifted in the future at some point.</p></li>
<li><p>No discussion of Palestinian v. Israeli conflict.
There are countless different subs to discuss this controversial event happening. To curb repetitive and toxic posts we are NOT allowing this topic here.</p></li>
</ul>

<hr>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Unearthing the oldest forest on Earth (104 pts)]]></title>
            <link>https://worldsensorium.com/unearthing-the-oldest-forest-on-earth-two-hours-from-new-york-city-you-can-travel-back-nearly-400-million-years/</link>
            <guid>39550202</guid>
            <pubDate>Thu, 29 Feb 2024 15:01:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://worldsensorium.com/unearthing-the-oldest-forest-on-earth-two-hours-from-new-york-city-you-can-travel-back-nearly-400-million-years/">https://worldsensorium.com/unearthing-the-oldest-forest-on-earth-two-hours-from-new-york-city-you-can-travel-back-nearly-400-million-years/</a>, See on <a href="https://news.ycombinator.com/item?id=39550202">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="g-intro">

                <article class="page" id="post-13733">

    
                
        
                
                        <section>

                                                
                                








<div data-awb-type="image" data-awb-parallax="scroll" data-awb-parallax-speed="0.5" data-awb-parallax-mobile="false" data-awb-image-background-size="cover" data-awb-image-background-position="45% 46%"><p><img decoding="async" src="https://worldsensorium.com/wp-content/uploads/2024/01/Screen-Shot-2024-01-25-at-11.53.36-PM.png" width="1714" height="1302" srcset="https://worldsensorium.com/wp-content/uploads/2024/01/Screen-Shot-2024-01-25-at-11.53.36-PM.png 1714w, https://worldsensorium.com/wp-content/uploads/2024/01/Screen-Shot-2024-01-25-at-11.53.36-PM-300x228.png 300w, https://worldsensorium.com/wp-content/uploads/2024/01/Screen-Shot-2024-01-25-at-11.53.36-PM-1024x778.png 1024w, https://worldsensorium.com/wp-content/uploads/2024/01/Screen-Shot-2024-01-25-at-11.53.36-PM-768x583.png 768w, https://worldsensorium.com/wp-content/uploads/2024/01/Screen-Shot-2024-01-25-at-11.53.36-PM-1536x1167.png 1536w, https://worldsensorium.com/wp-content/uploads/2024/01/Screen-Shot-2024-01-25-at-11.53.36-PM-500x380.png 500w, https://worldsensorium.com/wp-content/uploads/2024/01/Screen-Shot-2024-01-25-at-11.53.36-PM-800x608.png 800w, https://worldsensorium.com/wp-content/uploads/2024/01/Screen-Shot-2024-01-25-at-11.53.36-PM-1280x972.png 1280w, https://worldsensorium.com/wp-content/uploads/2024/01/Screen-Shot-2024-01-25-at-11.53.36-PM-1320x1003.png 1320w, https://worldsensorium.com/wp-content/uploads/2024/01/Screen-Shot-2024-01-25-at-11.53.36-PM-600x456.png 600w" sizes="(max-width: 1714px) 100vw, 1714px"></p></div>







<figure><blockquote><p>Two Hours from New York City You Can Travel Back Nearly 400 Million Years<br></p></blockquote></figure>







<p><strong>By Gayil Nalls</strong></p>





<p><a href="https://worldsensorium.com/join-us/" data-type="page" data-id="45"><strong>Sign up for our monthly newsletter!</strong></a></p>







<div>
<p>The exploration of an ancient, fossilized forest in a quarry in Cairo, New York, in the region of the Catskill-Hudson Valley, initiated years ago, has revealed a treasure trove of evidence showcasing early plant life coexisting with dinosaurs. The footprint of the ancient forest situated at the bottom of a quarry has become a crucial archaeological window into a distant past. </p>



<p>The site was discovered by Charles Ver Straeten, curator of sedimentary rocks at the New York State Museum, and his colleagues. International researchers came to study the area, led by William Stein, emeritus professor of biological sciences at&nbsp;Binghamton University, and Christopher Berry a paleobotanist at Cardiff University in the UK. They carefully examined fossils of various plants and trees and made the groundbreaking discovery that this forest is the oldest ever found on Earth, predating even well-known ancient forests like the Amazon rainforest and the Yakushima Forest in Japan.</p>



<figure><blockquote><p>The site quickly unveiled its secrets, offering a glimpse into a world that thrived 386 million years ago, the Middle&nbsp;Devonian Epoch (398-385 million years ago), when most life on Earth was still in the ocean. </p></blockquote></figure>



<p>The well-preserved ancient forest, once a thriving ecosystem, presents a unique opportunity for scientists to delve into the mysteries of Earth’s ancient past. </p>



<figure><video controls="" src="https://media.cnn.com/api/v1/loops/stellar/prod/191220161528-20191219-cairo-drone-2.mp4?q=h_402,w_718,x_0,y_0"></video></figure>



<p>The researcher’s primary focus was to examine the fossils of plants and trees found within the ancient forest, discovering evidence of plentiful early plant life. Through meticulous analysis of the impressions, they were able to identify and catalog a diverse array of plant life that flourished during the time of dinosaurs. The discovery included ferns, palms, and tree species that reproduce using spores, and are the ancestors to seed plants. The findings not only provide valuable insights into the biodiversity of the prehistoric world and expand our understanding of ancient ecosystems but also challenge existing notions about the nature of plant life during the dinosaur era. </p>



<p>The groundbreaking aspect of this discovery lies in the  determination of the forest’s age. Advanced dating techniques and scrutiny of the fossilized remains led scientists to conclude that the Cairo forest is the oldest ever found on Earth – 140 million years older than the first dinosaurs, surpassing the age of renowned ancient forests, including the Amazon rainforest and the Yakushima Forest in Japan. </p>



<figure><img decoding="async" src="https://media.cnn.com/api/v1/images/stellar/prod/191220110602-04-fossil-trees-new-york-worlds-oldest-trnd-scn.jpg?q=w_1160,c_fill/f_webp" alt=""><figcaption>Scientists stand on the edge of an Archaeopteris tree root system. They put the bucket where they think the tree’s trunk was located.&nbsp;<br>Charles Ver Straeten</figcaption></figure>



<p>This revelation not only adds a new chapter to the geological history of our planet but also raises questions about the evolution of plant life over time. The scientists think the findings will allow them to understand specifics about how plants and trees draw down carbon dioxide from the atmosphere. </p>



<p>The unearthing of the ancient forest floor in Cairo, New York, stands as a testament to the continuous exploration of our planet’s rich history. This discovery not only sheds light on the diverse plant life that coexisted with dinosaurs but also challenges our preconceptions about the age of ancient forests. As researchers delve deeper into the mysteries held within the fossilized remains, the story of Earth’s oldest forest continues to unfold, offering a unique glimpse into the wonders of our planet’s distant past. </p>



<figure><img decoding="async" src="https://media.cnn.com/api/v1/images/stellar/prod/191220110655-06-fossil-trees-new-york-worlds-oldest-trnd-scn.jpg?q=w_1110,c_fill/f_webp" alt=""><figcaption>Researchers carefully clean and map the surface of the ancient forest discovered in Cairo, New York.&nbsp;<br>William Stein</figcaption></figure>



<p>Exploring ancient forests not only allows us to peer into the past but also imparts valuable insights for the present and future, according to the scientists. Amid contemporary challenges like deforestation, comprehending the biodiversity and dynamics of ancient ecosystems can contribute significantly to understanding the transitional period we are in and provide insights for conservation endeavors.</p>



<p>*The top photograph is an overview of a well-preserved Archaeopteris root system on the left, and a possible Stigmarian Isoetalean lycopsid on the right.</p>







<p><br>© Photographs and videos are courtesy of William E. Stein,<br>Binghamton University&nbsp;Emeritus Professor of Biological Sciences</p>



<p>For more details, refer to:<br><a href="https://www.sciencedirect.com/science/article/abs/pii/S0031018210006565">https://www.sciencedirect.com/science/article/abs/pii/S0031018210006565</a><br><a href="https://www.cell.com/current-biology/pdf/S0960-9822(19)31569-6.pdf">https://www.cell.com/current-biology/pdf/S0960-9822(19)31569-6.pdf</a></p>











<p><strong>Gayil Nalls</strong>, Ph.D., is the creator of World Sensorium and founder of the World Sensorium Conservancy.</p>




</div>










<div data-post-id="4966"><figure><img fetchpriority="high" decoding="async" width="774" height="1024" src="https://worldsensorium.com/wp-content/uploads/2023/02/Plantings-Annual-2023-a-774x1024.jpg" alt="" srcset="https://worldsensorium.com/wp-content/uploads/2023/02/Plantings-Annual-2023-a-774x1024.jpg 774w, https://worldsensorium.com/wp-content/uploads/2023/02/Plantings-Annual-2023-a-600x793.jpg 600w, https://worldsensorium.com/wp-content/uploads/2023/02/Plantings-Annual-2023-a-227x300.jpg 227w, https://worldsensorium.com/wp-content/uploads/2023/02/Plantings-Annual-2023-a-768x1016.jpg 768w, https://worldsensorium.com/wp-content/uploads/2023/02/Plantings-Annual-2023-a-500x661.jpg 500w, https://worldsensorium.com/wp-content/uploads/2023/02/Plantings-Annual-2023-a-800x1058.jpg 800w, https://worldsensorium.com/wp-content/uploads/2023/02/Plantings-Annual-2023-a.jpg 1089w" sizes="(max-width: 774px) 100vw, 774px"></figure><div>
<h2 data-kb-block="kb-adv-heading4966_eab961-c5">Plantings Print Annual 2023</h2>



<p><strong>Do you have the 2023 <em>Plantings</em> print annual?</strong></p>



<p>Plantings cultivates innovative ideas and fresh perspectives, nurturing the global conservation community. Our readers find inspiration in forward-thinking individuals and approaches dedicated to fostering a better life for the planet and all its inhabitants.</p>



<p>The 2023 edition of Plantings is available in our store for shipping.</p>




</div></div>


                
                
                                
                
            </section>
            
                                    
        
    
</article>

            </section></div>]]></description>
        </item>
    </channel>
</rss>