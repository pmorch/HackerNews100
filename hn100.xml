<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 17 Jul 2024 09:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Import and Export Markdown in Google Docs (187 pts)]]></title>
            <link>https://workspaceupdates.googleblog.com/2024/07/import-and-export-markdown-in-google-docs.html</link>
            <guid>40982118</guid>
            <pubDate>Wed, 17 Jul 2024 02:44:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://workspaceupdates.googleblog.com/2024/07/import-and-export-markdown-in-google-docs.html">https://workspaceupdates.googleblog.com/2024/07/import-and-export-markdown-in-google-docs.html</a>, See on <a href="https://news.ycombinator.com/item?id=40982118">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<center>
			<h4>
				<a href="https://www.googlecloudcommunity.com/gc/Google-Workspace/ct-p/google-workspace" target="_blank">Join the official community for Google Workspace administrators</a>
			</h4>
			<p>
				In the Google Cloud Community, connect with Googlers and other Google Workspace admins like yourself. Participate in product discussions, check out the Community Articles, and learn tips and tricks that will make your work and life easier. Be the first to know what's happening with Google Workspace.
			</p>
<p>______________
			</p>            
            	<h4>
				<a href="https://support.google.com/a/go/whatsnew" target="_blank">Learn about more Google Workspace launches</a>
			</h4>
			<p>
				On the “What’s new in Google Workspace?” Help Center page, learn about new products and features launching in Google Workspace, including smaller changes that haven’t been announced on the Google Workspace Updates blog.
			</p>
<p>______________
			</p>            
            	</center>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[After 12 years of reviewing restaurants, I'm leaving the table (116 pts)]]></title>
            <link>https://www.nytimes.com/2024/07/16/dining/pete-wells-steps-down-food-critic.html</link>
            <guid>40979539</guid>
            <pubDate>Tue, 16 Jul 2024 19:33:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/07/16/dining/pete-wells-steps-down-food-critic.html">https://www.nytimes.com/2024/07/16/dining/pete-wells-steps-down-food-critic.html</a>, See on <a href="https://news.ycombinator.com/item?id=40979539">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/07/16/dining/pete-wells-steps-down-food-critic.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[DevRel at HuggingFace (143 pts)]]></title>
            <link>https://dx.tips/huggingface</link>
            <guid>40979221</guid>
            <pubDate>Tue, 16 Jul 2024 18:56:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dx.tips/huggingface">https://dx.tips/huggingface</a>, See on <a href="https://news.ycombinator.com/item?id=40979221">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-content-parent"><blockquote>
<p>Following the <a target="_blank" href="https://dx.tips/zirp">ZIRP DevRel</a> post, the community has had many great discussions on where devrel needs to go next. DXTips exists to share this tacit niche industry knowledge. <strong>DX@X</strong> is our new async interview series we are starting with DevRel leaders to get more perspectives on the state of the art in DX and DevRel. We're excited to kick it off with <strong><a target="_blank" href="https://x.com/osanseviero">Omar Sanseviero</a>, Chief Llama Officer at HuggingFace</strong>!</p>
<p>HuggingFace is well known for being incredible stewards of the open source ML community, building critical infrastructure at hypergrowth (growing from 780k to 2.3m repos on the HF Hub in the past year) and doing so <a target="_blank" href="https://analyticsindiamag.com/ai-news-updates/hugging-face-announces-profitability-with-free-and-open-source-models/">profitably</a>. They are also a rare startup whose large online community also translates to <a target="_blank" href="https://x.com/search?q=huggingface%20woodstock&amp;src=recent_search_click&amp;f=top"><em>massive</em> multi-thousand people meetups</a> all <a target="_blank" href="https://x.com/search?q=huggingface%20station%20f&amp;src=typed_query&amp;f=top">over the world</a>.</p>
<p><strong>Request for Suggestions: Who else would you like to hear from? Let us know on <a target="_blank" href="https://x.com/dxtipshq">X/Twitter</a> and join our <a target="_blank" href="https://dx.tips/newsletter">Newsletter</a> to get the next issue!</strong></p>
</blockquote>
<h2 id="heading-introduction-to-omar-and-huggingface">Introduction to Omar and HuggingFace</h2>
<blockquote>
<p><strong>Intro:</strong> <em>Hey Omar! Let’s assume people know the surface level of HuggingFace - it’s the largest AI community which collaborates on open source models, datasets, and applications, with paid compute and enterprise solutions. What does a Chief Llama Officer do at HF?</em></p>
</blockquote>
<p><a target="_blank" href="https://x.com/osanseviero/media">Memes</a>! More seriously, my title might translate to “<strong>Head of Platform and Community</strong>” at another company, although the scope of what I do is quite broad. There are two aspects to my role:</p>
<ul>
<li><strong>Leadership</strong>: Within HF, my role involves horizontal and vertical leadership. Vertically, I direct a family of teams (Dev Advocacy Engineering, On-device ML, Moonshot Factory, Argilla - our most recent acquisition). Horizontally, our team sits at the intersection of Open Source, Product, and the external community (+ sometimes research). In my day-to-day, I aim to identify high-impact potential areas, connect dots across teams at HF and the community, and unblock people to succeed.</li>
<li><strong>IC</strong>: HF has a very bottom-up leadership culture. This, combined with a meeting-less async culture (<a target="_blank" href="https://x.com/mervenoyann/status/1692111147783143751">example</a>, <a target="_blank" href="https://x.com/SashaMTL/status/1773344913502929014">example</a>, <a target="_blank" href="https://x.com/osanseviero/status/1573055162070999061">example</a>, <a target="_blank" href="https://www.hbs.edu/faculty/Pages/item.aspx?num=63185">old HBS case study</a>), allows folks in leadership positions to dedicate significant time to technical and meaningful contributions to different projects. A significant part of my role involves collaborating with partners to release new models, such as the latest Llama and Gemma models. Each release is unique, intense, and fun, and I quite enjoy being deeply involved in the entire process.</li>
</ul>
<blockquote>
<p><strong>Followup</strong>: <em>What do you think is under-appreciated about HF’s open source work?</em></p>
</blockquote>
<p>Hugging Face is a community-centric company. It's hard to exaggerate how community-centric we are. Some examples:</p>
<ul>
<li>We prioritize giving the spotlight to community members and collaborators as much as possible.</li>
<li>Provide compute and no-strings-attached cash grants (including but not limited to <a target="_blank" href="https://www.theverge.com/2024/5/16/24156755/hugging-face-celement-delangue-free-shared-gpus-ai">the $10m ZeroGPU program</a>) to community members/communities (for example, in the past, Eleuther, Boris from Dall-e Mini, and lucidrains have been sponsored by HF, allowing them to keep doing their cool work without financial constraints).</li>
<li>Help maintain open-source libraries (eg <a target="_blank" href="https://github.com/UKPLab/sentence-transformers">sentence transformers</a> and <a target="_blank" href="https://github.com/bitsandbytes-foundation/bitsandbytes">bitsandbytes</a>) from other groups and closely collaborate with other tools (eg <a target="_blank" href="https://github.com/EleutherAI/lm-evaluation-harness/tree/main">LM Eval Harness</a> and <a target="_blank" href="https://github.com/mlfoundations/open_clip">OpenCLIP</a>)</li>
</ul>
<p>Our approach to working with other groups and open-source platforms and libraries is always collaborative. We view ourselves as "the Switzerland" of the ML community, actively contributing to and supporting the ML ecosystem. We want the community to be successful and grow the pie.</p>
<p>So, one aspect of HF that I think is underappreciated is the extent of the support and collaboration with the community. Many see the outputs—like models and libraries—but might not realize the significant behind-the-scenes effort that the team puts into fostering the thriving ecosystem.</p>
<h2 id="heading-devrel-at-huggingface-metrics-and-velocity">DevRel at HuggingFace: Metrics and Velocity</h2>
<blockquote>
<p><strong>Credibility/Success:</strong> <em>What are some “real” metrics that you track that point to HF’s devrel success?</em></p>
</blockquote>
<p>DevRel comes in all kinds of flavors in the industry. Some DevRel teams are part of a marketing function, and some are within a monetization-team function. At Hugging Face, DevRel sits between the open-source and product organizations and is primarily an engineering function.</p>
<p>This means <strong>HF DevRel's goal is to see increased usage of the Hub platform and open-source tools</strong> rather than focusing on revenue as our primary goal. Two of our north stars are the <strong>number of repositories on HF and logged-in usage of the Hub</strong> platform. For example, the Hub has 2.3 million repositories today, compared to 780k repositories a year ago. (Of course, we can look at everything with more granularity, e.g., the number of Spaces, which grew from 187k in June last year to 650k this year).</p>
<p><img loading="lazy" src="https://gist.github.com/user-attachments/assets/ca97fe47-127d-4bc6-9d05-b4f2c0fdf863" alt="image"></p>
<p>Each team member works on different topics (e.g., Computer Vision, Audio ML, ML for 3D CV, etc.), so we jointly define some metrics that we would like to see move based on our efforts. <strong>We prioritize usage-based</strong> (number of repos, downloads, installs) <strong>over visibility-driven</strong> (GitHub stars, Twitter likes, views), which are also valuable but not the main motivation of our work.</p>
<p>That said, I'm skeptical of cultures that overemphasize metrics (of course, this is nuanced and depends on a lot of context). From my experience at Google and looking at other startups, I've seen the downsides of measuring too much too early. Metrics are an imperfect proxy for impact and are game-able. <strong>Cultures prioritizing metrics above all risk losing sight of user needs and making wrong decisions</strong> (e.g., to improve metrics for their performance review rather than genuine user benefit). Some DevRel activities might not have immediate metric changes but have long-term impact.</p>
<p>One of the most rewarding moments was after two years of building connections with Spanish-speaking folks, we <a target="_blank" href="https://platzi.com/blog/ayuda-a-mejorar-los-llm-en-espanol-en-7-sencillos-pasos/">initiated</a> an exciting Alpaca translation effort involving Argilla, Platzi (a Colombian edtech), and many community super-users. This 'Avengers assemble' moment is becoming more frequent as we foster stronger relationships with practitioners, communities, and organizations. Examples of these are <a target="_blank" href="https://x.com/_lewtun/status/1778429536264188214">Zephyr ORPO</a> (KAIST + HF + Argilla), <a target="_blank" href="https://huggingface.co/blog/4bit-transformers-bitsandbytes">QLoRA</a> (University of Washington), and the very recent <a target="_blank" href="https://huggingface.co/blog/winning-aimo-progress-prize">AI Math Olympiad winner</a> (NuminaM + HF).</p>
<blockquote>
<p><strong>DevRel @ HF:</strong> <em>What was your reaction to <a target="_blank" href="https://dx.tips/zirp">the ZIRP DevRel article</a>? What’s different at HF?</em></p>
</blockquote>
<p>As mentioned before, DevRel comes in all kinds of flavors. There were things that I could relate to. Specially two points:</p>
<ul>
<li>I'm a bit skeptical of the impact of traveling to conferences. While conferences can be impactful if approached strategically, the highest impact usually doesn't come from giving a talk. Instead, it's often the connections made and behind-the-scenes collaborations which require a different mindset. We support conference travel (and people do that a lot), but we encourage team members to attend with an impact-driven mindset, ready to achieve some concrete things beyond attending an event.</li>
<li>Lack of OKRs. <strong>We do not have OKRs</strong>. The ML ecosystem moves incredibly fast, so we need to be nimble and action-driven. Gemini Nano was added to Chrome? Let's figure out how to run it and <a target="_blank" href="https://x.com/xenovacom/status/1810356703826977183">release some docs</a>. Model 504B is coming out next month; let's make sure it's usable by the community. Although exciting, this comes with cons: priorities can and will change, planning becomes challenging, and maintaining focus can be difficult in the chaos of the current ML space.</li>
</ul>
<p>That said, I think HF DevRel has been successful overall for a couple of reasons:</p>
<ul>
<li>It's an <strong>engineering-centric</strong> function. Day-to-day activities might involve fine-tuning models to get a training script right, collaborating on a research project, or finding out why a model is not quantizing well to 4 bits. Our users are engineers and researchers, so it's essential that we are in their world to understand them.</li>
<li>It's a <strong>decentralized</strong> function. Although we have a dedicated DevRel team, <strong>everyone at HF is expected to do activities usually associated with DevRel</strong>. Although we have a DevRel team, everyone at HF, from research to success engineers, is involved in doing DevRel-like activities themselves, so you'll see everyone engaging in social media, creating content (youtube, blog posts, etc), giving presentations, etc. If you build a feature/tool, you're responsible of its visibility and growth (of course, with support/guidance from others). Marketing your own work could involve writing a blog post or a technical deep dive, crafting some beautiful notebooks, and yes, sometimes making memes. If you visit <a target="_blank" href="https://huggingface.co/blog">HF blog</a>, you'll see content from all across the company. Rather than "outsourcing" these responsibilities to a third team (either a marketing or a DevRel team in many companies), HF members are encouraged and expected to own their work, end to end. <a target="_blank" href="https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1">FineWeb</a> is an amazing example of how this can be successful.</li>
</ul>
<p>The two points combined lead to very genuine and scalable relationships. Rather than a competitive culture, we've fostered a culture in which people are excited to collaborate both internally and externally and ready to amplify the amazing work being done by the community.</p>
<blockquote>
<p><strong>Followup question on DevRel Velocity:</strong> <em>I notice that OKRs very rarely prioritize moving fast. What has worked/not worked in encouraging your team members to move fast (other than the obvious intrinsic motivation)?</em></p>
</blockquote>
<ul>
<li><strong>What works well</strong>: Beyond intrinsic motivation, which is indeed a strong factor, collective momentum plays a big role. Being surrounded by a group of smart, driven individuals working on the latest ML advancements creates an environment where progress is both expected and contagious. This collaborative atmosphere builds some sense of urgency and encourages everyone to push forward together.</li>
<li><strong>What does not work well</strong>: On the flip side, a lack of structured planning and clear OKRs can affect some people. While flexibility is desired a lot in the industry, it can lead to ambiguity and confusion about expectations, making it harder for new team members to get up to speed quickly. This can result in onboarding challenges and potential mismatches in cultural fit. Each team is a bit different, but there's a balance between agility and more structured goal-setting that can help everyone thrive.</li>
</ul>

<blockquote>
<p><strong>Open Source Engineering and Community:</strong> <em>HF maintains a -lot- of open source work, and only (~200?) employees. How do you organize the different projects you work on, and how does the community engagement work?</em></p>
</blockquote>
<p>Yes, we're a relatively small team (215 persons), and maintain a large number of libraries ourselves: demos (Gradio), data (datasets, Argilla, distilabel), modeling (transformers, diffusers, timm, peft, Candle, tokenizers, accelerate, parler TTS, transformers.js), production (TGI and TEI), and research related (lerobot, alignment handbook), plus support community libraries (bitsandbytes and sentence-transformers and others as mentioned above).</p>
<p>There are some key strategies that have worked well for us</p>
<ul>
<li><strong>Strong async culture</strong>. We mostly communicate through Slack and GitHub, enabling collaboration across different projects. This fosters transparency, allowing everyone to gain visibility into other projects.</li>
<li><strong>Flexible organizational and role boundaries.</strong> The organizational structure is flexible, allowing people from different teams to contribute where needed. For example, when we were preparing for Llama 2 release, people from all kinds of teams contributed to make sure the model was in good shape and usable by the community. It's quite powerful to see different teams working organically to make things happen without having to go through bureaucracy or process management.</li>
<li>(other points mentioned above, such as being collaboration and community centric)</li>
<li><strong>Pragmatic</strong>. Let me dive into this one more in the next point :)</li>
</ul>
<blockquote>
<p><strong>Prioritization:</strong> <em>There’s a lot of interesting directions in ML and only so much time/resources. How do you decide -what- to invest in? And what to cut? Because you're decentralized - what do managers decide vs leave to ICs?</em></p>
</blockquote>
<p>That's a great question and likely one of our biggest challenges. As you said, there are many interesting directions, and the ecosystem is changing quickly. We see new players, from new libraries and startups to new organizations releasing models.</p>
<p>In general, I like to apply the concept of exploration/exploitation from Reinforcement Learning. This involves two main stages:</p>
<ol>
<li><strong>Exploration</strong>: We do small projects or comms to gauge their potential impact and community interest. This allows us to experiment without having too many people working on it or committing lots of time.</li>
<li><strong>Exploitation</strong>: Based on the knowledge gained from the exploration stage, we focus our efforts on things we are more confident will have a significant impact. This involves scaling up successful projects and allocating more resources to areas with proven value.</li>
</ol>
<p>Of course, it's never as simple as that (the ϵ is variable), and it's usually cyclical (exploration -&gt; exploitation -&gt; exploration), but it's a good mental framework to have. Some projects are heavy in exploration by nature (for example, exploring a very niche domain or community), and others might require a larger time investment (which tends to happen in research-oriented projects).</p>
<p>The second point, related to the above, is pragmatism. That means being willing to pause or stop projects if they aren't having the expected impact. For example, investing days to make a YouTube video with a few hundred views may not be a worthwhile investment unless it leads to some very valuable or targeted outcome. It can be sad to spend some weeks building an open-source library and then see no engagement or adoption. What is worse, however, is to keep pushing and pushing for a tool that might lack product-market fit.</p>
<p>Failure is a part of the process for all of us. The key is to learn from it, understand what went well and what didn't, and know when to pivot or stop. This pragmatic approach helps us stay focused on what truly matters.</p>
<blockquote>
<p><strong>Followup Question:</strong> <em>Let’s apply Explore-Exploit. Just to pick on a specific, visible example that has caught my (swyx’s) eye recently, <a target="_blank" href="https://x.com/reach_vb/">VB (Vaibhav)</a> has staked out a very notable position as “the audio guy” on AI Twitter. Always the first to have great takes on anything in audio, shipping insanely-fast-whisper and the TTS Arena, and goodness knows what else I don’t even know about. He of course also does <a target="_blank" href="https://x.com/reach_vb/status/1806343018640781675">other open source AI work eg on LLMs</a>. Was there a top down decision to focus on Audio? It must have been… But I’m also equally sure that audio doesn’t drive nearly as much revenue for HF as, say, LLMs or Diffusion models (Apolinario). So… great hire, but how did you decide to invest in audio in the first place? Is there any calculation driven by the GTM/Product/Sales side of HF?</em></p>
</blockquote>
<p>It might sound surprising, but audio (with VB) was a very validated area we wanted to invest in, while diffusion/art (<a target="_blank" href="https://x.com/multimodalart">Poli</a>) was a very experimental area.</p>
<p><img loading="lazy" src="https://gist.github.com/user-attachments/assets/56f995f4-8f48-467f-9463-2d4582e1f730" alt="image"></p>
<p><strong>For audio</strong>, back in 2022, we saw a significant wave of OS libraries (SpeechBrain, ESPNet, Asteroid, etc) and interesting research (Whisper, XLS-R by Meta, etc). We were actively organizing community sprints with free GPUs to help people fine-tune speech recognition models in their languages. There was a lot going on that led to the decision to hire a DA for the role (apart from the MLE in the open source team already working on the topic). VB was working in audio in his masters and had already engaged with us through different efforts. Despite being somewhat junior in the open ML space, his <strong>very</strong> strong alignment with the open ML culture and mindset allowed him to scale his impact. Since joining, VB has expanded beyond audio, leading different collaborations and integrations, including recent work with Georgi on llama.cpp. Now, VB is even <a target="_blank" href="https://x.com/reach_vb/status/1810977320275943852">hiring an intern</a> to support the ML ecosystem for audio!</p>
<p><img loading="lazy" src="https://gist.github.com/user-attachments/assets/030763e7-ce88-4cab-9371-4120525f1461" alt="image"></p>
<p><strong>For diffusion/art</strong>, Poli was our first Moonshot MLE hired to make "ML for art as accessible and open source as possible." This was before the hype around Stable Diffusion. We hired him because of his strong cultural alignment, his contributions to early HF Spaces and him being a Gradio super-user. At that time, while more experimental, the impact on Spaces and the potential of diffusion models (like latent diffusion by CompVis) showed promising signs. As a power (and somewhat early) user for Spaces, he also brought lots of product ideas on making Spaces more successful.</p>
<p>In summary, our decision to invest in audio was based on clear community and research validation as well as growth potential. In contrast, MLxArt was a more experimental exploration that showed early impacts and ended up being a very high impact area.</p>
<p>Sometimes both intercept! Talking about AI x music <a target="_blank" href="https://x.com/iamwill/status/1696546638863749154">with will.i.am</a> is definitely a highlight of last year.</p>
<p><img loading="lazy" src="https://gist.github.com/user-attachments/assets/655f586e-61f1-471c-a4d2-20c44ec621ec" alt="image"></p>

<blockquote>
<p><strong>Open Questions:</strong> <em>What are you looking for help with? What questions do you want answered that would help you get to your “next level” (whatever that means to you)?</em></p>
</blockquote>
<p>Hugging Face's core audience has traditionally been people with ML experience, but we've seen more and more <strong>developers without an ML background who want to incorporate ML into their projects or learn about ML</strong>. These developers often feel overwhelmed by the complexity of ML and the speed of the ecosystem. While the community has introduced new tools and APIs to simplify things, and we have exciting features coming soon, there's still much to be done to lower the entry barriers further. I'm looking for <strong>insights and suggestions on how we can make our tools even more accessible to non-ML developers</strong>. (<em>Editor: some might call these <a target="_blank" href="https://www.latent.space/p/ai-engineer">AI Engineers</a>?</em>)</p>
<p>Additionally, <strong>we're expanding our team and are looking for individuals with strong developer empathy and technical skills based in the Bay Area</strong>. If you're interested or know someone who might be, <a target="_blank" href="https://x.com/osanseviero">please reach out</a>!</p>
<blockquote>
<p><strong>Request for Startups/Tools:</strong> <em>You <a target="_blank" href="https://argilla.io/blog/argilla-joins-hugggingface/">recently acquired Argilla</a> for collaborating on high quality datasets — what else do you wish people worked on? (that would be useful to the ecosystem from your POV)</em></p>
</blockquote>
<p>Some topics I'm interested in (not necessarily for a startup):</p>
<p>In <strong>Research</strong>: </p>
<ul>
<li>more distillation experiments and OS tooling</li>
<li>densification of sparse (MoE) models</li>
<li>quantization (sub-1-bit for MoEs, &lt;8-bit fine-tuning), tooling on speculative decoding strategies, more people trying the KTO alignment algorithm (which removes the need of preference data for RLHF/PPO/DPO)</li>
<li>true multimodality (2+ input modalities and 2+ output modalities, e.g., text+image+video to text+image in a unified model)</li>
</ul>
<p>There are trends in all of this already.</p>
<p>More generally: We want <strong>more developer-friendly ML tooling</strong> (i.e. making it super easy for any developer to use ML, not just LLMs).  If you come from a background in which you can speak both the language of a discipline (biochemistry, chemistry, material sciences, health) and ML, and communicate and work well with both audiences, you're a unicorn and can do very impactful things, not just in the ML domain, but in other industries.</p>
<blockquote>
<p><em>Thank you for your time, Omar!</em></p>
</blockquote>
<hr>
<p><strong>CTA from DXTips: Who else would you like to hear from? Let us know on <a target="_blank" href="https://x.com/dxtipshq">X/Twitter</a> and join our <a target="_blank" href="https://dx.tips/newsletter">Newsletter</a> to get the next issue!</strong></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Optimizing a bignum library for fun (102 pts)]]></title>
            <link>https://austinhenley.com/blog/bignum2.html</link>
            <guid>40978831</guid>
            <pubDate>Tue, 16 Jul 2024 18:08:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://austinhenley.com/blog/bignum2.html">https://austinhenley.com/blog/bignum2.html</a>, See on <a href="https://news.ycombinator.com/item?id=40978831">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <div>
				  <h2>Austin Z. Henley</h2>
				  <p>
						Associate Teaching Professor<br>
						Carnegie Mellon University
					</p>
				</div>

	  <hr>
	  
    
	  <hr>

	
	<small>7/9/2024</small><p><small><i>See the discussion of this post on <a href="https://news.ycombinator.com/item?id=40978831">Hacker News</a>.</i></small></p>

<p>I'm down a rabbit hole of learning how bignums work. In the first post, <a href="https://austinhenley.com/blog/bignum1.html">making a bignum library for fun</a>, I implemented a arbitrary-precision number library with some basic operations. You can follow along with the source on <a href="https://github.com/AZHenley/bignum">GitHub</a>.</p>

<pre>int main() {
    BigNum a, b, sum;

    bignum_init(&amp;a, "12345678901234567890");
    bignum_init(&amp;b, "98765432109876543210");

    bignum_add(&amp;sum, &amp;a, &amp;b);
    bignum_print(&amp;sum);

    bignum_free(&amp;a);
    bignum_free(&amp;b);
    bignum_free(&amp;sum);

    return 0;
}
</pre>

<p>My naive approach represents numbers as strings of decimal digits. The number 321 becomes <i>'3', '2', '1'</i>. Then addition and multiplication is performed similar to how we learned in school to do it digit by digit.</p>

<p>We can do much better!</p>

<p>In this post, I improve how the numbers are stored, implement a faster multiplication algorithm, and benchmark the time improvements.</p>

<hr> 

<h3>More efficient digits</h3>

<p>The most obvious optimization is to use a much larger base for the "digits". For example, rather than an array of digits that each range from 0 to 9, we can store an array of number chunks that each range from 0 to the limit of whatever integer size we use. It will allow us to use memory much, much more efficiently. It will also greatly reduce the number of steps to perform our addition and multiplication since there are fewer digits.</p>

<p>There are tradeoffs for how many bits to use per chunk: memory, arithmetic performance, cache locality, overflow management, native CPU operations, complexity of our code, etc. Looking for inspiration, I saw CPython uses 30-bit digits and GNU Multiple Precision Arithmetic Library uses 64-bit digits on 64-bit CPUs.</p>

<p>I didn't do an in-depth analysis of what an optimal size may be, but even using 30-bit digits means the numbers can get <b>very large</b> with a few digits. Each 30-bit digit can hold 9 decimal digits. For example, <i>987654321</i> will fit in a single 30-bit digit and <i>987654321987654321</i> will fit in just two! This is already more precision than I've ever needed, and the library can use an arbitrary number of these digits in our bignum.</p>

<p>Let's implement the 30-bit digits. It will make our code simpler since the sum of any two digits will not overflow using a <i>uint32</i> and the product won't overflow a <i>uint64</i>.</p>

<pre>typedef struct {
    uint32_t *digits; // Use 30-bit digits.
    int size;
} BigNum;

void bignum_init(BigNum *n, const char *str) {
    int len = strlen(str);
    int num_digits = (len + 8) / 9; // Each 30-bit chunk can store up to 9 base-10 digits.
    n-&gt;size = num_digits;
    n-&gt;digits = calloc(n-&gt;size, sizeof(uint32_t)); // Initialize with zeros.
	
    for (int i = 0; i &lt; len; i++) {
        int digit_pos = i / 9;
        int offset = i % 9;
        uint32_t digit = str[len - 1 - i] - '0'; // Convert from ASCII.
        uint32_t multiplier = 1;
        for (int j = 0; j &lt; offset; j++) {
            multiplier *= 10; // Correctly place the digit.
        }
        n-&gt;digits[digit_pos] += digit * multiplier;
    }
}
</pre>

<p>The bignum is now made up of an array of <i>uint32_t</i> instead of <i>char</i>. The <b>bignum_init</b> function will convert a base-10 number string to an array of 30-bit digits. First, it calculates how many 30-bit digits will be needed and initializes them to zero. Then it loops through the string from least significant digit to most significant digit, converting them to chunks of 9 digits, each stored in a <i>uint32_t</i>. It will flow to the next 30-bit digit as needed.</p>

<p>In order to easily test this, we should revise the <b>bignum_print</b> function. Previously, we would just loop through the base-10 digits and print them. Now we have to handle three different cases just for zeros: leading zeros in a digit, a middle chunk that is zero, and the entire bignum being zero.</p>

<pre>void bignum_print(const BigNum *n) {
    printf("BigNum: ");
    int leading = 1;
    for (int i = n-&gt;size - 1; i &gt;= 0; i--) {
        if (leading) {
            printf("%u", n-&gt;digits[i]);
            leading = 0;
        } else {
            printf("%09u", n-&gt;digits[i]); // Print with leading zeros.
        }
    }
    if (leading) {
        printf("0"); // If the number is zero, print a single zero.
    }
    printf("\n");
}
</pre>

<p>Try creating a bignum from <i>"987654321987654321"</i>. Does it print correctly? It does for me! Inspect the <i>digits</i> field to validate it is storing them in the way you are imagining.</p>

<h3>Higher-bit arithmetic</h3>

<p>We have to modify the addition and multiplication functions to also operate on these 30-bit digits. They really aren't much different though.</p>

<pre>void bignum_add(BigNum *result, const BigNum *a, const BigNum *b) {
    int max_size = a-&gt;size &gt; b-&gt;size ? a-&gt;size : b-&gt;size;
    result-&gt;digits = calloc(max_size + 1, sizeof(uint32_t)); // Initialize with zeros.
    uint32_t carry = 0;
    int i;

    for (i = 0; i &lt; max_size || carry; i++) {
        uint32_t sum = carry;
        if (i &lt; a-&gt;size) sum += a-&gt;digits[i];
        if (i &lt; b-&gt;size) sum += b-&gt;digits[i];
        result-&gt;digits[i] = sum % 1000000000; // Store the last 30 bits.
        carry = sum / 1000000000; // Carry any overflow.
    }
    result-&gt;size = (carry ? i + 1 : i); // Adjust size if needed.
}
</pre>

<p>We still perform addition digit by digit, though this time with 30-bit digits (actually using 10<sup>9</sup> but bear with me).</p>

<p>The updated multiplication is also virtually the same. We use a <i>uint64_t</i> to capture any overflow though.</p>

<pre>void bignum_multiply(BigNum *result, const BigNum *a, const BigNum *b) {
    int max_size = a-&gt;size + b-&gt;size;
    result-&gt;digits = calloc(max_size, sizeof(uint32_t));
    result-&gt;size = max_size; // Max size we will need.

    for (int i = 0; i &lt; a-&gt;size; i++) {
        uint64_t carry = 0;
        for (int j = 0; j &lt; b-&gt;size; j++) {
            int index = i + j;
            uint64_t product = (uint64_t)a-&gt;digits[i] * (uint64_t)b-&gt;digits[j] + (uint64_t)result-&gt;digits[index] + carry;
            result-&gt;digits[index] = product % 1000000000; // Store the last 30 bits of the product
            carry = product / 1000000000; // Carry any overflow.
        }
        result-&gt;digits[i + b-&gt;size] += carry; // Add any carry.
    }
	
    // Trim any leading zeros.
    while (result-&gt;size &gt; 1 &amp;&amp; result-&gt;digits[result-&gt;size - 1] == 0) {
        result-&gt;size--;
    }
}
</pre>

<p>Try it out. If you add <i>987654321987654321</i> to <i>123456789123456789</i> then you should get <i>1111111111111111110</i>. Multiplying them should give you 121932631356500531347203169112635269.</p>

<h3>Measure it</h3>

<p>Everyone knows that any attempt at optimizing requires a rigorous, scientific benchmark to understand the improvements.</p>

<p>To compare the original base-10 digits to this 30-bit digit version, I'll run add and multiply repeatedly on random numbers. I made a function to generate random bignums from n-length strings.</p>

<p>The benchmarking code:</p>

<pre>char* generateRandomNumberString(int length) {
    char *num = malloc((length + 1) * sizeof(char));
    for (int i = 0; i &lt; length; i++) {
        num[i] = '0' + (rand() % 10);
    }
    num[length] = '\0';
    return num;
}

int main() {
    srand(time(NULL));
    int iterations = 10000;
    int numLength = 1000;  // Length of the random numbers.

    double total_addition_time = 0.0;
    double total_multiplication_time = 0.0;

    for (int i = 0; i &lt; iterations; i++) {
        char *str1 = generateRandomNumberString(numLength);
        char *str2 = generateRandomNumberString(numLength);

        BigNum num1, num2, sum, product;
        bignum_init(&amp;num1, str1);
        bignum_init(&amp;num2, str2);
        bignum_init(&amp;sum, "");
        bignum_init(&amp;product, "");

        // Benchmark addition.
        clock_t start = clock();
        bignum_add(&amp;sum, &amp;num1, &amp;num2);
        clock_t end = clock();
        total_addition_time += (double)(end - start) / CLOCKS_PER_SEC;

        // Benchmark multiplication.
        start = clock();
        bignum_multiply(&amp;product, &amp;num1, &amp;num2);
        end = clock();
        total_multiplication_time += (double)(end - start) / CLOCKS_PER_SEC;

        bignum_free(&amp;num1);
        bignum_free(&amp;num2);
        bignum_free(&amp;sum);
        bignum_free(&amp;product);
        free(str1);
        free(str2);
	}

	printf("Total Addition Time: %f seconds\n", total_addition_time);
	printf("Total Multiplication Time: %f seconds\n", total_multiplication_time);
	return 0;
}
</pre>

<p>How does it compare to the previous base-10 digits implementation on 10,000 operations with 1,000-digit numbers?</p>

<img src="https://austinhenley.com/blog/images/bignumbenchmark.png" alt="Bar charts comparing addition and multiplication times for base-10 digits and 30-bit digits.">

<p>For addition, it is an 83% improvement from 0.04 seconds to 0.007 seconds. For multiplication, it is a 99% improvement from 63 seconds to 0.43 seconds. <b>Wow!</b> I knew the schoolyard multiplication algorithm with base-10 digits would be slow, but I did not expect this kind of speed up.</p>

<p>We aren't done yet though.</p>

<h3>Faster multiplication</h3>

<p>From one of my college courses, I recalled algorithms for multiplication that are faster than the schoolyard approach we are using. A quick search shows the <a href="https://en.wikipedia.org/wiki/Karatsuba_algorithm">Karatsuba algorithm</a> to be popular for these sorts of things. Instead of multiplying two n-digit numbers, it does multiplication on three n/2-digit numbers, which apparently is a huge improvement.</p>

<img src="https://austinhenley.com/blog/images/karatsuba.png">

<p>You can see my Karatsuba multiplication function on <a href="https://github.com/AZHenley/bignum/blob/f4ee868f716cff90d4bf67ce8901a741172d34fb/part2/bignum.c#L104">GitHub</a>. I adapted the pseudocode from Wikipedia with the help of Copilot.</p>

<p>How much faster is it?</p>

<p>Is it actually <b>2% slower</b> using the same benchmark parameters.</p>

<p>Why? Apparently Karatsuba can be slower for <i>"smaller"</i> numbers due to overhead and additional operations. In fact, CPython only uses it for numbers with more than 70 30-bit digits. Those are big numbers!</p>

<p>Fair enough, so I changed the benchmark to use random numbers with 10,000 digits instead of 1,000 and did see an improvement: 39.88 seconds for traditional multiplication versus 16.27 seconds for Karatsuba multiplication. A 59% improvement! I suspect it will get better and better as the number length grows.</p>

<hr>

<h3>What is next?</h3>

<p>Alright, so we have made two major optimizations to the bignum library and measured the impact on running time. Using larger digits had a huge effect. The code is on <a href="https://github.com/AZHenley/bignum">GitHub</a>.</p>

<p>If I were to continue working on this project, I'd focus on <b>usefulness</b>. It is still missing core features that you'd expect from even the most basic bignums:</p>

<ul>
    <li>Negative numbers</li>
    <li>Subtraction and division</li>
    <li>Exponentiation</li>
    <li>Bitwise operations</li>
    <li>Converting to/from other types</li>
	<li>Tests <small>(I bet there are many bugs in my code)</small></li>
</ul>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[I am starting an AI+Education company (704 pts)]]></title>
            <link>https://twitter.com/karpathy/status/1813263734707790301</link>
            <guid>40978731</guid>
            <pubDate>Tue, 16 Jul 2024 17:57:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/karpathy/status/1813263734707790301">https://twitter.com/karpathy/status/1813263734707790301</a>, See on <a href="https://news.ycombinator.com/item?id=40978731">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Inside an IBM/Motorola mainframe controller chip from 1981 (107 pts)]]></title>
            <link>http://www.righto.com/2024/07/ibm-3274-keystone-chip.html</link>
            <guid>40978482</guid>
            <pubDate>Tue, 16 Jul 2024 17:27:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.righto.com/2024/07/ibm-3274-keystone-chip.html">http://www.righto.com/2024/07/ibm-3274-keystone-chip.html</a>, See on <a href="https://news.ycombinator.com/item?id=40978482">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-8275175814130556085" itemprop="description articleBody">
<p>In this article, I look inside a chip in the IBM 3274 Control Unit.<span id="fnref:3274"><a href="#fn:3274">1</a></span>
But before I discuss the chip, I need to give some background on mainframes.
(I didn't completely analyze the chip, so don't expect a nice narrative or solid conclusions.)</p>
<p><a href="https://static.righto.com/images/ibm-3274/die.jpg"><img alt="Die photo of the Motorola/IBM SC81150 chip. Click this image (or any other) for a larger version." height="597" src="https://static.righto.com/images/ibm-3274/die-w600.jpg" title="Die photo of the Motorola/IBM SC81150 chip. Click this image (or any other) for a larger version." width="600"></a></p><p>Die photo of the Motorola/IBM SC81150 chip. Click this image (or any other) for a larger version.</p>
<p>IBM's vintage mainframes were extremely underpowered compared to modern computers; a System/370 mainframe ran well under 1 million instructions
per second, while a modern laptop executes billions of instructions per second.
But these mainframes could support rooms full of users, while my 2017 laptop can barely handle one person.<span id="fnref:laptop"><a href="#fn:laptop">2</a></span>
Mainframes achieved their high capacity by offloading much of the data entry overhead so the mainframe could
focus on the "important" work.
The mainframe received data directly into memory in bulk over high-speed I/O channels, without needing to handle character-by-character editing.
For instance, a typical data entry terminal (a "3270") let the user update fields on the screen without involving the computer. When the user 
had filled out the screen, pressing the "Enter" key sent the entire data record to the mainframe at once.
Thus, the mainframe didn't need to process every keystroke; it only dealt with complete records.
(This is also why many modern keyboards have an "Enter" key.)</p>
<p><a href="https://static.righto.com/images/ibm-3274/3179.jpg"><img alt="A room with IBM 3179 Color Display Stations, 1984. Note that these are terminals, not PCs. From 3270 Information Display System Introduction." height="330" src="https://static.righto.com/images/ibm-3274/3179-w500.jpg" title="A room with IBM 3179 Color Display Stations, 1984. Note that these are terminals, not PCs. From 3270 Information Display System Introduction." width="500"></a></p>
<p>But that was just the beginning of the hierarchy of offloaded processing in a mainframe system.
Terminals weren't attached directly to the mainframe. You could wire 16 terminals to a terminal multiplexer (such as the 3299).
This would in turn be connected to a 3274 Control Unit that merged the terminal data and handled the network protocols.
The Control Unit was connected to the mainframe's
channel processor which handled I/O by moving data between memory and peripherals without slowing down the CPU.
All these layers allowed the mainframe to focus on the important data processing while the layers underneath dealt with the details.<span id="fnref:secretary"><a href="#fn:secretary">3</a></span></p>
<p><a href="https://static.righto.com/images/ibm-3274/overview.jpg"><img alt="An overview of the IBM 3270 Information Display System attachment. The yellow highlights indicate the 3274 Control Unit. From 3270 Information Display System: Introduction." height="661" src="https://static.righto.com/images/ibm-3274/overview-w650.jpg" title="An overview of the IBM 3270 Information Display System attachment. The yellow highlights indicate the 3274 Control Unit. From 3270 Information Display System: Introduction." width="650"></a></p>
<p>The 3274 Control Unit (highlighted above) is the source of the chip I examined.
The purpose of the Control Unit
"is to take care of all communication between the host system and your organization's display stations and printers".
The diagram above shows how terminals were connected to a mainframe, with the 3274 Control Unit (indicated by arrows) in the middle.
The 3274 was an all-purpose box, handling terminals, printers, modems, and encryption (if needed).
It could communicate with the mainframe at up to 650,000 characters per second.
The control unit below (above) is a boring beige box. The control panel is minimal since people normally didn't interact with the unit.
On the back are coaxial connectors for the lines to the terminals, as well as connectors to interface with the computer and other peripherals.</p>
<p><a href="https://static.righto.com/images/ibm-3274/3274-41D.jpg"><img alt="An IBM 3274-41D Control Unit. From bitsavers." height="462" src="https://static.righto.com/images/ibm-3274/3274-41D-w500.jpg" title="An IBM 3274-41D Control Unit. From bitsavers." width="500"></a></p><p>An IBM 3274-41D Control Unit. From <a href="https://bitsavers.org/pdf/ibm/3274/pictures/3274-41D/1.jpg">bitsavers</a>.</p>
<h2>The Keystone II board</h2>
<p>In 1983, IBM announced new Control Unit models with twice the speed: these were the Model 41 and Model 61.
These units were built around a board called Keystone II, shown below.
The board is constructed with IBM's peculiar PCB style. The board is arranged as a grid of squares with the PCB traces too small to see
unless you zoom in.
Most of the decoupling capacitors are in IBM's thin, rectangular packages, although I see a few capacitors in more standard blue packages.
IBM is almost a parallel universe with its unusual packaging for ICs and capacitors as well as the strange circuit board appearance.</p>
<p><a href="https://static.righto.com/images/ibm-3274/keystone-ii.jpg"><img alt="The Keystone II board. The box is labeled Keystone II FCS [i.e. First Customer Shipment] July 23, 1982. Photo from bitsavers, originally from Bob Roberts." height="402" src="https://static.righto.com/images/ibm-3274/keystone-ii-w600.jpg" title="The Keystone II board. The box is labeled Keystone II FCS [i.e. First Customer Shipment] July 23, 1982. Photo from bitsavers, originally from Bob Roberts." width="600"></a></p><p>The Keystone II board. The box is labeled Keystone II FCS [i.e. First Customer Shipment] July 23, 1982. Photo from <a href="https://bitsavers.org/pdf/ibm/3274/pictures/keystone_II_1.jpg">bitsavers</a>, originally from <a href="https://retrocomputingforum.com/t/does-anyone-know-what-this-is/3709">Bob Roberts</a>.</p>
<p>Most of the chips on the board are IBM chips packaged in square aluminum cans, known as MST (Monolithic System Technology). The first line on each package
is the IBM part number, which is usually undocumented.
The empty socket can hold a ROS chip; ROS is Read-Only Store, known as ROM to people outside IBM.
The Texas Instruments ICs in the upper right are easier to identify; the <a href="https://www.ti.com/product/SN74LS641">74LS641</a> chips are octal bus transceivers, presumably
connecting this board to the rest of the system.
Similarly, the <a href="https://vintagecomputer.ca/ibm-vintage-logic-chip-equivalency-list/">561 5843</a> is a 74S240 octal bus driver while the
561 6647 chips are 74LS245 octal bus transceivers.</p>
<p>The memory chips on the left side of this board are interesting: each one consists of two "piggybacked" 16-kilobit DRAM chips.
IBM's part number <a href="https://bitsavers.computerhistory.org//pdf/ibm/logic/IBM_Part_Number_to_Industry_Part_Number.txt#:~:text=74LS192%20BCD%20COUNTER-,8279251,-4116%2032K%20CARIBOU">8279251</a> corresponds to the Intel 4116 chip, originally made by Mostek.
With 18 piggybacked chips, the board holds 64 kilobytes of parity-protected memory.</p>
<p>The photo below shows the Keystone II board mounted in the 3274 Control Unit. The board is in slot E towards the left and the purple Motorola
IC is visible.</p>
<p><a href="https://static.righto.com/images/ibm-3274/41d-cards.jpg"><img alt="The Keystone II card in slot E of a 3274-41D Control Unit. Photo from bitsavers." height="360" src="https://static.righto.com/images/ibm-3274/41d-cards-w500.jpg" title="The Keystone II card in slot E of a 3274-41D Control Unit. Photo from bitsavers." width="500"></a></p><p>The Keystone II card in slot E of a 3274-41D Control Unit. Photo from <a href="https://bitsavers.org/pdf/ibm/3274/pictures/3274-41D/6.jpg">bitsavers</a>.</p>

<p>The board has a Motorola chip in a purple ceramic package; this is the chip that I examined. Popping off the golden lid reveals the silicon
die underneath.
The package has the part number "SC81150R", indicating a Motorola Special/Custom chip. This part number is also visible on the die, as shown below.</p>
<p><a href="https://static.righto.com/images/ibm-3274/sc81150.jpg"><img alt="The corner of the die is marked with the SC81150 part number. Bond pads and bond wires are also visible." height="330" src="https://static.righto.com/images/ibm-3274/sc81150-w400.jpg" title="The corner of the die is marked with the SC81150 part number. Bond pads and bond wires are also visible." width="400"></a></p><p>The corner of the die is marked with the SC81150 part number. Bond pads and bond wires are also visible.</p>
<p>While the outside of the IC is labeled "Motorola", there are no signs of Motorola internally. 
Instead, the die is marked "IBM" with the eight-striped logo. My guess is that IBM designed the chip and Motorola manufactured it.</p>
<p><a href="https://static.righto.com/images/ibm-3274/ibm.jpg"><img alt="The IBM logo on the die." height="286" src="https://static.righto.com/images/ibm-3274/ibm-w400.jpg" title="The IBM logo on the die." width="400"></a></p><p>The IBM logo on the die.</p>
<p>The diagram below shows the chip with some of the functional blocks identified.
Around the outside are the bond pads and the bond wires that are connected to the chip's grid of pins.
At the right is the 16×16 block of memory, along with its associated control, byte swap, and output circuitry.
The yellowish-white lines are the metal layer on top of the chip that provides the chip's wiring. The thick metal lines distribute power and
ground throughout the chip.
Unlike modern chips, this chip only has a single metal layer, so power and ground distribution tends to get in the way of useful circuitry.</p>
<p><a href="https://static.righto.com/images/ibm-3274/die-labeled.jpg"><img alt="The die with some functional blocks identified." height="542" src="https://static.righto.com/images/ibm-3274/die-labeled-w600.jpg" title="The die with some functional blocks identified." width="600"></a></p><p>The die with some functional blocks identified.</p>
<p>The chip is centered around a 16-bit bus (yellow line) that connects many part of the chip.
To write to the bus, a circuit pulls bus lines low. The bus lines are kept high by default by 16
pull-up transistors. This approach was fairly common in the NMOS era. However, performance is limited by the relatively weak
pull-up current, making bus lines slow to go high due to R-C delays.
For higher performance, some chips would precharge the bus high during one clock cycle and then pull lines low during the next cycle.</p>
<p>The two groups of I/O pins at the bottom are connected to the input buffer on the left and the output buffer on the right.
The input buffer includes XOR circuits to compute the parity of each byte. Curiously, only 6 bits of the inputs are connected to the main bus,
although other circuits use all 8 bits. The buffer also has a circuit to test for a zero value, but only using 5 of the bits.</p>
<p>I've put red boxes around the numerous PLAs, which can be identified by their grids of transistors.
This chip has an unusually large number of PLAs.
Eric Schlaepfer hypothesizes that the chip was designed on a prototype circuit board using commercial PAL chips for flexibility, and then they
transferred the prototype to silicon, preserving the PLA structure.
I didn't see any obvious structure to the PLAs; they all seemed to have wires going all over.</p>
<p>The miscellaneous logic scattered around the chip includes many latches and bus drivers; the latch circuit is similar to the memory cells. I didn't fully reverse-engineer this circuitry
but I didn't see anything that looked particularly interesting, such as an ALU or counter.
The circuitry near the PLAs could be latches as part of state machines, but I didn't investigate further.</p>
<p>I was hoping to find a recognizable processor inside the package, maybe a Motorola 6809 or 68000 processor.
Instead, I found a complicated chip that doesn't appear to be a processor.
It has a 16×16 memory block along with about 20 PLAs (Programmable Logic Arrays), a curiously large number.
PLAs are commonly used in processors for decoding instructions, since they can match bit patterns. 
I couldn't find a datapatch in the chip; I expected to see the ALU and registers organized in a large but regular 8-bit or 16-bit block of circuitry.
The chip doesn't have any ROM<span id="fnref:rom"><a href="#fn:rom">4</a></span> so there's no microcode on the chip.
For these reasons, I think the chip is not a processor or microcontroller, but a specialized data-handling chip, maybe using the PLAs to
interpret bits of a protocol.</p>
<p>The chip is built with NMOS technology, the same as the 6502 and 8086 for instance, rather than CMOS technology that is used in modern chips.
I measured the transistor features and the chip appears to be built with a 3.5 µm process (not nm!), which Motorola also used for the 68000 processor (1979).</p>
<h2>The memory buffer</h2>
<p>The chip has a 16×16 memory buffer, which could be a register file or a FIFO buffer.
One interesting feature is that the buffer is triple-ported, so it can handle two reads and one write at the same time.
The buffer is implemented as a grid of cells, each storing one bit. Each row corresponds to a 16-bit word, while each column corresponds
to one bit in a word.
Horizontal control lines (made of polysilicon) select which word gets written or read, while vertical bit lines of metal transmit each bit of the word as it is written
or read.</p>
<p>The microscope photo below shows two memory cells. These cells are repeated to create the entire memory buffer.
The white vertical lines are metal wiring. The short segments are connections within a cell. The thicker vertical lines are power and ground.
The thinner lines are the read and write bit lines.
The silicon die itself is underneath the metal. The pinkish regions are active silicon, doped to make it conductive.
The speckled golden lines are regions are polysilicon wires between the silicon and the metal. It has two roles: most importantly, when polysilicon
crosses active silicon, it forms the gate of a transistor. 
But polysilicon is also used as wiring, important since this chip only has one layer of metal.
The large, dark circles are contacts, connections between the metal layer and the silicon. Smaller square regions are contacts between silicon
and polysilicon.</p>
<p><a href="https://static.righto.com/images/ibm-3274/mem.jpg"><img alt="Two memory cells, side by side, as they appear under the microscope." height="265" src="https://static.righto.com/images/ibm-3274/mem-w500.jpg" title="Two memory cells, side by side, as they appear under the microscope." width="500"></a></p><p>Two memory cells, side by side, as they appear under the microscope.</p>
<p>It was too difficult to interpret the circuits when they were obscured by the metal layer so I dissolved the metal layer and oxide with hydrochloric acid and Armour Etch respectively. The photo below shows the die with the metal removed; the greenish areas are remnants in areas where the metal
was thick, mostly power and ground supplies.
The dark regions in this image are regions of doped silicon. These are the active areas of the chip, showing the blocks of circuitry.
There are also some thin lines of polysilicon wiring.
The memory buffer is the large block on the right, just below the center.</p>
<p><a href="https://static.righto.com/images/ibm-3274/die-stripped.jpg"><img alt="The chip with the metal layer removed. Click to zoom in on the image." height="602" src="https://static.righto.com/images/ibm-3274/die-stripped-w600.jpg" title="The chip with the metal layer removed. Click to zoom in on the image." width="600"></a></p><p>The chip with the metal layer removed. Click to zoom in on the image.</p>
<p>Like most implementations of static RAM, each storage cell of the buffer is implemented with cross-coupled inverters, with the output of one inverter feeding into
the input of the other.
To write a new value to the cell, the new value simply overpowers the inverter output, forcing the cell to the new state.
To support this, one of the inverters is designed to be weak, generating a smaller signal than a regular inverter.
Most circuits that I've examined create the inverter by using a weak transistor, one with a longer gate.
This chip, however, uses a circuit that I haven't seen before: an additional transistor, configured to limit the current from the inverter.</p>
<p>The schematic below shows one cell. Each cell uses ten transistors, so it is a "10T" cell. To support multiple reads and writes, each row of cells has three horizontal control signals: one to write to the word, and two to read.
Each bit position has one vertical bit line to provide the write data and two vertical bit lines for the data that is read.
Pass transistors connect the bit lines to the selected cells to perform a read or a write, allowing the data to flow in or out of the cell. The symbol that looks like an op-amp is a two-transistor NMOS buffer to amplify the signal when reading the cell.
</p>
<p><a href="https://static.righto.com/images/ibm-3274/mem-schematic.png"><img alt="Schematic of one memory cell." height="285" src="https://static.righto.com/images/ibm-3274/mem-schematic-w500.png" title="Schematic of one memory cell." width="500"></a></p><p>Schematic of one memory cell.</p>
<p>With the metal layer removed, it is easier to see the underlying silicon circuitry and reverse-engineer it.
The diagram below shows the silicon and polysilicon for one storage cell, corresponding to the schematic above.
(Imagine vertical metal lines for power, ground, and the three bitlines.)</p>
<p><a href="https://static.righto.com/images/ibm-3274/mem-cell.jpg"><img alt="One memory cell with the metal layer removed. I etched the die a few seconds too long so some of the polysilicon is very thin or missing." height="550" src="https://static.righto.com/images/ibm-3274/mem-cell-w600.jpg" title="One memory cell with the metal layer removed. I etched the die a few seconds too long so some of the polysilicon is very thin or missing." width="600"></a></p><p>One memory cell with the metal layer removed. I etched the die a few seconds too long so some of the polysilicon is very thin or missing.</p>
<p>The output from the memory unit contains a byte swapper. A 16-bit word is generated with the left half from the read 1 output and the second half from the read 2 output, but the bytes can be swapped.
This was probably used to read an aligned 16-bit word if it was unaligned in memory.</p>
<h2>Parity circuits</h2>
<p>In the lower right part of the chip are two parity circuits, each computing the parity of an 8-bit input.
The parity of an input is computed by XORing the bits together through a tree of 2-input XOR gates. First, four gates process pairs of input bits. Next, two XOR gates combine the outputs of
the first gates. Finally, an XOR gate combines the two previous outputs to generate the final parity.</p>
<p><a href="https://static.righto.com/images/ibm-3274/xor-diagram.jpg"><img alt="The arrangement of the 14 XOR gates to compute parity of the two 8-bit values A and B." height="183" src="https://static.righto.com/images/ibm-3274/xor-diagram-w600.jpg" title="The arrangement of the 14 XOR gates to compute parity of the two 8-bit values A and B." width="600"></a></p><p>The arrangement of the 14 XOR gates to compute parity of the two 8-bit values A and B.</p>
<p>The schematic below shows how an XOR gate is built from a NOR gate and an AND-NOR gate. If both inputs are 0, the first NOR gate forces the output
to 0. If both inputs are 1, the AND gate forces the output to 0. Thus, the circuit computes XOR.
Each labeled block above implements the XOR circuit below.</p>
<p><a href="https://static.righto.com/images/ibm-3274/xor.png"><img alt="Schematic of an XOR gate." height="148" src="https://static.righto.com/images/ibm-3274/xor-w400.png" title="Schematic of an XOR gate." width="400"></a></p><p>Schematic of an XOR gate.</p>
<h2>Conclusion</h2>
<p>My conclusion is that the processor for the Keystone II board is probably one of the other chips, one of the IBM metal-can MST packages,
and this chip helps with data movement in some way.
It would be possible to trace out the complete circuitry of the chip and determine exactly how it functions, but that is too
time-consuming a project for this relatively obscure chip.</p>
<p>Follow me on Twitter <a href="https://twitter.com/kenshirriff">@kenshirriff</a> or <a href="http://www.righto.com/feeds/posts/default">RSS</a> for more chip posts.
I'm also on Mastodon occasionally as <a href="https://oldbytes.space/@kenshirriff">@<span data-cfemail="c6ada3a8b5aeafb4b4afa0a086a9aaa2a4bfb2a3b5e8b5b6a7a5a3">[email&nbsp;protected]</span></a>.
Thanks to Al Kossow for providing the chip and Dag Spicer for providing photos. Thanks to Eric Schlaepfer for discussion.</p>
<h2>Notes and references</h2>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[XLSTMTime: Long-Term Time Series Forecasting with xLSTM (188 pts)]]></title>
            <link>https://arxiv.org/abs/2407.10240</link>
            <guid>40978372</guid>
            <pubDate>Tue, 16 Jul 2024 17:14:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2407.10240">https://arxiv.org/abs/2407.10240</a>, See on <a href="https://news.ycombinator.com/item?id=40978372">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2407.10240">View PDF</a></p><blockquote>
            <span>Abstract:</span>In recent years, transformer-based models have gained prominence in multivariate long-term time series forecasting (LTSF), demonstrating significant advancements despite facing challenges such as high computational demands, difficulty in capturing temporal dynamics, and managing long-term dependencies. The emergence of LTSF-Linear, with its straightforward linear architecture, has notably outperformed transformer-based counterparts, prompting a reevaluation of the transformer's utility in time series forecasting. In response, this paper presents an adaptation of a recent architecture termed extended LSTM (xLSTM) for LTSF. xLSTM incorporates exponential gating and a revised memory structure with higher capacity that has good potential for LTSF. Our adopted architecture for LTSF termed as xLSTMTime surpasses current approaches. We compare xLSTMTime's performance against various state-of-the-art models across multiple real-world da-tasets, demonstrating superior forecasting capabilities. Our findings suggest that refined recurrent architectures can offer competitive alternatives to transformer-based models in LTSF tasks, po-tentially redefining the landscape of time series forecasting.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Musleh Alharthi [<a href="https://arxiv.org/show-email/df681557/2407.10240">view email</a>]      <br>    <strong>[v1]</strong>
        Sun, 14 Jul 2024 15:15:00 UTC (848 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stop Microsoft users sending 'reactions' to email by adding a postfix header (230 pts)]]></title>
            <link>https://neilzone.co.uk/2024/07/attempting-to-stop-microsoft-users-sending-reactions-to-email-from-me-by-adding-a-postfix-header/</link>
            <guid>40978073</guid>
            <pubDate>Tue, 16 Jul 2024 16:38:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://neilzone.co.uk/2024/07/attempting-to-stop-microsoft-users-sending-reactions-to-email-from-me-by-adding-a-postfix-header/">https://neilzone.co.uk/2024/07/attempting-to-stop-microsoft-users-sending-reactions-to-email-from-me-by-adding-a-postfix-header/</a>, See on <a href="https://news.ycombinator.com/item?id=40978073">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
<article>
    <p>Over the past few months, I’ve noticed that an increasing number of replies to email that I’ve sent are “reactions”.</p>
<p>I imagine that, to the sender, or to someone in the Microsoft ecosystem, they are handled a bit liked a “thumbs-up” or “heart” reaction to a Signal message.</p>
<p>To me - as someone not in the Microsoft ecosystem - for each reaction, I get an email:</p>
<blockquote>
<p>like 	[person] reacted to your message:</p>
</blockquote>
<p>The “like” is alt-text. Because I don’t allow loading of remote content, I don’t see an image here.</p>
<p>I don’t want this.</p>

<p>Microsoft <a href="https://techcommunity.microsoft.com/t5/outlook-blog/reactions-in-outlook-public-usability-update-september-2023/ba-p/3928103">has a specific header</a> which one can add to outgoing to email:</p>
<pre tabindex="0"><code>x-ms-reactions: disallow
</code></pre><p>My understanding is that, if that header is set, Microsoft suppresses the ability in its clients to respond with a reaction.</p>
<p>It is annoying that I need to set a specific header for this.</p>
<p>If every feature required a specific header to signal that it is unwanted, that would get irritating rather rapidly.</p>
<p>But at least there <em>is</em> this header.</p>
<p>If your mail client / MUA allows you to add headers, you could do it that way.</p>
<p>If you did, you wouldn’t need to tinker with your mailserver’s config.</p>
<p>But you’d need to do it for each client you use.</p>
<p>I want it to apply to all email I send, from whatever account, and from whatever device, so I added it to my postfix configuration.</p>
<p>In <code>/etc/postfix/main.cf</code>, I have a setting:</p>
<pre tabindex="0"><code>header_checks = pcre:/etc/postfix/header_checks
</code></pre><p>So I added my new header to <code>/etc/postfix/header_checks</code>.</p>
<p>I added</p>
<pre tabindex="0"><code># add header to deal with unwanted Microsoft reactions (2024-07-16)
/^Content-Type:/i PREPEND x-ms-reactions: disallow 
</code></pre><p>(Edit: originally, I put this line before the <code>Content-Transfer-Encoding</code> header. But my mutt configuration does send that header, so I’ve switched it to go before the <code>Content-Type</code> header instead, as all my MUAs send that.)</p>
<p>and restarted postfix (<code>sudo service postfix restart</code>).</p>
<p>Then I tested it with various clients, and looked at the message headers to check that the header was being added correctly.</p>
<p>It was, so, success!</p>
<p>Now, will I get any more unwanted “reactions” email…? I’ll have to wait and see.</p>
<h2 id="update-testing-shows-some-success">Update: Testing shows some success</h2>
<p>I’ve tested this with a couple of people.</p>
<p>In one case, the header enrichment happened, but the Microsoft-using recipient still had the options to send a reaction.</p>
<p>They did, but the reaction did not reach me - it never hit my mailserver.</p>
<p>Microsoft <a href="https://techcommunity.microsoft.com/t5/outlook-blog/reactions-in-outlook-public-usability-update-september-2023/ba-p/3928103">sort-of foreshadows this</a> when it says:</p>
<blockquote>
<p>Since Disallow Reactions will roll out to different Outlook clients at different cadences and not all Outlook clients will have the gray-out update immediately, we also have a second layer of protection. When an email has reactions disallowed, attempts to react to it will fail at the server side.</p>
</blockquote>
<p>My reading of this is that, even if a Microsoft client shows that reactions are available, and even if someone clicks it to send a reaction, Microsoft may still drop it silently.</p>
<p>That doesn’t feel like an ideal user experience (even if, for me, it achieves the goal of not getting a reaction email).</p>
<p>For the other Microsoft-using person, the reaction symbol was greyed out, and a hover text said “Reactions are disallowed on this message”.</p>
<p>Perhaps it does vary by Microsoft system, which again seems rather sub-optimal.</p>



  <div>
   
	<h2>You may also like:</h2>
	
    
</div>


</article>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Private Browsing 2.0 (175 pts)]]></title>
            <link>https://webkit.org/blog/15697/private-browsing-2-0/</link>
            <guid>40977945</guid>
            <pubDate>Tue, 16 Jul 2024 16:23:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://webkit.org/blog/15697/private-browsing-2-0/">https://webkit.org/blog/15697/private-browsing-2-0/</a>, See on <a href="https://news.ycombinator.com/item?id=40977945">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                
                <p>When <a href="https://en.wikipedia.org/wiki/Private_browsing#History">we invented</a> Private Browsing back in 2005, our aim was to provide users with an easy way to keep their browsing private from anyone who shared the same device. We created a mode where users do not leave any local, persistent traces of their browsing. Eventually all other browsers shipped the same feature. At times, this is called “ephemeral browsing.”</p>
<p>We baked in cross-site tracking prevention in all Safari browsing through our cookie policy, starting with Safari 1.0 in 2003. And we’ve increased privacy protections incrementally over the last 20 years. (Learn more by reading <a href="https://webkit.org/tracking-prevention/">Tracking Prevention in Webkit</a>.) Other popular browsers have not been as quick to follow our lead in tracking prevention but there is progress.</p>
<p>Apple believes that users should not be tracked across the web without their knowledge or their consent. Entering Private Browsing is a strong signal that the user wants the best possible protection against privacy invasions, while still being able to enjoy and utilize the web. Staying with the 2005 definition of private mode as only being ephemeral, such as <a href="https://support.google.com/chrome/answer/9845881?hl=en#zippy=%2Chow-incognito-mode-works%2Chow-incognito-mode-protects-your-privacy">Chrome’s Incognito Mode</a>, simply doesn’t cut it anymore. Users expect and deserve more.</p>
<p>So, we decided to take Private Browsing further and add even more protection beyond the normal Safari experience. Last September, we added a whole new level of privacy protections to Private Browsing in Safari 17.0. And we enhanced it even further in Safari 17.2 and Safari 17.5. Plus, when a user enables them, all of the new safeguards are available in regular Safari browsing too.</p>
<p>With this work we’ve enhanced web privacy immensely and hope to set a new industry standard for what Private Browsing should be.</p>
<h2>Enhanced Private Browsing in a Nutshell</h2>
<p>These are the protections and defenses added to Private Browsing in Safari 17.0:</p>
<ul>
<li>Link Tracking Protection</li>
<li>Blocking network loads of known trackers, including CNAME-cloaked known trackers</li>
<li>Advanced Fingerprinting Protection</li>
<li>Extensions with website or history access are off by default</li>
</ul>
<p>In addition, we added these protections and defenses in all browsing modes:</p>
<ul>
<li>Capped lifetime of cookies set in responses from cloaked third-party IP addresses</li>
<li>Partitioned SessionStorage</li>
<li>Partitioned blob URLs (starting in Safari 17.2)</li>
</ul>
<p>We also expanded Web AdAttributionKit (formerly Private Click Measurement) as a replacement for tracking parameters in URL to help developers understand the performance of their marketing campaigns even under Private Browsing.</p>
<figure><picture><source srcset="https://www.webkit.org/wp-content/uploads/safari-private-browsing-dark.png" media="(prefers-color-scheme: dark)"><img fetchpriority="high" decoding="async" src="https://www.webkit.org/wp-content/uploads/safari-private-browsing-light.png" alt="Screenshot of Private Browsing in Safari" width="2704" height="1628" srcset="https://webkit.org/wp-content/uploads/safari-private-browsing-light.png 2704w, https://webkit.org/wp-content/uploads/safari-private-browsing-light-300x181.png 300w, https://webkit.org/wp-content/uploads/safari-private-browsing-light-1024x617.png 1024w, https://webkit.org/wp-content/uploads/safari-private-browsing-light-768x462.png 768w, https://webkit.org/wp-content/uploads/safari-private-browsing-light-1536x925.png 1536w, https://webkit.org/wp-content/uploads/safari-private-browsing-light-2048x1233.png 2048w" sizes="(max-width: 2704px) 100vw, 2704px"></picture><figcaption>Private Browsing in Safari</figcaption></figure>
<p>However, before we dive into these new and enhanced privacy protections, let’s first consider an important aspect of these changes: website compatibility risk.</p>
<h2>The Risk of Breaking Websites and How We Mitigate It</h2>
<p>There are many ideas for how to protect privacy on the web, but unfortunately many of them may break the user’s experience. Like security protections in real life, a balance must be struck. The new Private Browsing goes right up to the line, attempting to never break websites. But of course there is a risk that some parts of some sites won’t work. To solve this, we give users affordances to reduce privacy protections on a per-site basis. Such a change in privacy protections is only remembered while browsing within a site. This option is a last resort when a web page is not usable due to the privacy protections.</p>
<figure><picture><source srcset="https://www.webkit.org/wp-content/uploads/webkit-tracking-prevention-dark.png" media="(prefers-color-scheme: dark)"><img decoding="async" src="https://www.webkit.org/wp-content/uploads/webkit-tracking-prevention-light.png" alt="Reload menu with Reload Reducing Privacy Protections selected" width="2564" height="1544" srcset="https://webkit.org/wp-content/uploads/webkit-tracking-prevention-light.png 2564w, https://webkit.org/wp-content/uploads/webkit-tracking-prevention-light-300x181.png 300w, https://webkit.org/wp-content/uploads/webkit-tracking-prevention-light-1024x617.png 1024w, https://webkit.org/wp-content/uploads/webkit-tracking-prevention-light-768x462.png 768w, https://webkit.org/wp-content/uploads/webkit-tracking-prevention-light-1536x925.png 1536w, https://webkit.org/wp-content/uploads/webkit-tracking-prevention-light-2048x1233.png 2048w" sizes="(max-width: 2564px) 100vw, 2564px"></picture><figcaption>Reload Reducing Privacy Protections</figcaption></figure>
<p>All of the new privacy protections in Private Browsing are also available in regular browsing. On iOS, iPadOS and visionOS go to Settings &gt; Apps &gt; Safari &gt; Advanced &gt; Advanced Tracking and Fingerprinting Protection and enable “All Browsing”. On macOS go to Safari &gt; Settings &gt; Advanced and enable  “Use advanced tracking and fingerprinting protection”:</p>
<figure><picture><source srcset="https://www.webkit.org/wp-content/uploads/safari-advanced-tracking-protection-dark.png" media="(prefers-color-scheme: dark)"><img decoding="async" width="1700" height="1155" src="https://www.webkit.org/wp-content/uploads/safari-advanced-tracking-protection-light.png" alt="Safari Advanced Settings with &quot;Use advanced tracking and fingerprinting protection in all browsing&quot; selected" srcset="https://webkit.org/wp-content/uploads/safari-advanced-tracking-protection-light.png 1700w, https://webkit.org/wp-content/uploads/safari-advanced-tracking-protection-light-300x204.png 300w, https://webkit.org/wp-content/uploads/safari-advanced-tracking-protection-light-1024x696.png 1024w, https://webkit.org/wp-content/uploads/safari-advanced-tracking-protection-light-768x522.png 768w, https://webkit.org/wp-content/uploads/safari-advanced-tracking-protection-light-1536x1044.png 1536w" sizes="(max-width: 1700px) 100vw, 1700px"></picture><figcaption>Use advanced tracking and fingerprinting protection in all browsing from Safari Advanced Settings</figcaption></figure>
<p>Let’s now walk through how these enhancements work.</p>
<h2>Link Tracking Protection</h2>
<p>Safari’s Private Browsing implements two new protections against tracking information in the destination URL when the user navigates between different websites. The specific parts of the URL covered are query parameters and the fragment. The goal of these protections is to make it more difficult for third-party scripts running on the destination site to correlate user activity across websites by reading the URL.</p>
<p>Let’s consider an example where the user clicks a link on <code>clickSource.example</code>, which takes them to <code>clickDestination.example.</code> The URL looks like this:</p>
<pre><code>https://clickDestination.example/article?known_tracking_param=123&amp;campaign=abc&amp;click_val=456
</code></pre>
<p>Safari removes a subset of query parameters that have been identified as being used for pervasive cross-site tracking granular to users or clicks. This is done <em>prior to</em> navigation, such that these values are never propagated over the network. If <code>known_tracking_param</code> above represents such a query parameter, the URL that’s used for navigation will be:</p>
<pre><code>https://clickDestination.example/article?campaign=abc&amp;click_val=456
</code></pre>
<p>As its name suggests, the <code>campaign</code> above represents a parameter that’s only used for campaign attribution, as opposed to click or user-level tracking. Safari allows such parameters to pass through.</p>
<p>Finally, on the destination site after a cross-site navigation, all third-party scripts that attempt to read the full URL (e.g. using <code>location.search</code>, <code>location.href</code>, or <code>document.URL</code>) will get a version of the URL that has no query parameters or fragment. In our example, this script-exposed value is simply:</p>
<pre><code>https://clickDestination.example/article
</code></pre>
<p>In a similar vein, Safari also hides cross-site any <code>document.referrer</code> from script access in Private Browsing.</p>
<h2>Web AdAttributionKit in Private Browsing</h2>
<p>Web AdAttributionKit (formerly Private Click Measurement) is a way for advertisers, websites, and apps to implement ad attribution and click measurement in a privacy-preserving way. You can <a href="https://webkit.org/blog/11529/introducing-private-click-measurement-pcm/">read more about it here</a>. Alongside the new suite of enhanced privacy protections in Private Browsing, Safari also brings a version of Web AdAttributionKit to Private Browsing. This allows click measurement and attribution to continue working in a privacy-preserving manner.</p>
<p>Web AdAttributionKit in Private Browsing works the same way as it does in normal browsing, but with some limits:</p>
<ul>
<li>Attribution is scoped to individual Private Browsing tabs, and transfers attribution across new tabs opened when clicking on links. However, attribution is not preserved through other indirect means of navigation: for instance, copying a link and pasting in a new tab. In effect, this behaves similarly to how Web AdAttributionKit works for <a href="https://webkit.org/blog/12042/pcm-for-in-app-direct-response-advertising/">Direct Response Advertising</a>.</li>
<li>Since Private Browsing doesn’t persist any data, pending attribution requests are discarded when the tab is closed.</li>
</ul>
<h2>Blocking Network Loads of Known Trackers</h2>
<p>Safari 17.0 also comes with an automatically enabled content blocker in Private Browsing, which blocks network loads to known trackers. While Intelligent Tracking Prevention has long blocked all third party cookies, blocking trackers’ network requests from leaving the user’s device in the first place ensures that no personal information or tracking parameters are exfiltrated through the URL itself.</p>
<p>This automatically enabled content blocker is compiled using data from DuckDuckGo and from the EasyPrivacy filtering rules from EasyList. The requests flagged by this content blocker are only entries that are flagged as trackers by <em>both</em> DuckDuckGo and EasyPrivacy. In doing so, Safari intentionally allows most ads to continue loading even in Private Browsing.</p>
<p>Private Browsing also blocks cloaked network requests to known tracking domains. They otherwise have the ability to save third party cookies in a first-party context. This protection requires macOS Sonoma or iOS 17. By cloaked we mean subdomains mapped to a third-party server via CNAME cloaking or third-party IP address cloaking. See also the “Defending Against Cloaked First Party IP Addresses” section below.</p>
<p>When Safari blocks a network request to a known tracker, a console message of this form is logged, and can be viewed using Web Inspector:</p>
<pre><code>`<span>Blocked</span> <span>connection</span> <span>to</span> <span>known</span> <span>tracker</span><span>:</span> <span>tracker</span>.<span>example</span>` 
</code></pre>
<h2>Network Privacy Enhancements</h2>
<p>Safari 15.0 started hiding IP addresses from known trackers by default. Private Browsing in Safari 17.0 adds the following protections for all users:</p>
<ul>
<li><strong>Encrypted DNS</strong>. DNS queries are used to resolve server hostnames into IP addresses, which is a necessary function of accessing the internet. However, DNS is traditionally unencrypted, and allows network operators to track user activity or redirect users to other servers. Private Browsing uses <a href="https://en.wikipedia.org/wiki/DNS_over_HTTPS#Oblivious_DNS_over_HTTPS">Oblivious DNS over HTTPS</a> by default, which encrypts and proxies DNS queries to protect the privacy and integrity of these lookups.</li>
<li><strong>Proxying unencrypted HTTP</strong>. Any unencrypted HTTP resources loaded in Private Browsing will use the same multi-hop proxy network used to hide IP addresses from trackers. This ensures that attackers in the local network cannot see or modify the content of Private Browsing traffic.</li>
</ul>
<p>Additionally, for iCloud+ subscribers who have iCloud Private Relay turned on, Private Browsing takes privacy to the next level with these enhancements:</p>
<ul>
<li><strong>Separate sessions per tab</strong>. Every tab that the user opens in Private Browsing now uses a separate session to the iCloud Private Relay proxies. This means that web servers won’t be able to tell if two tabs originated on the same device. Each session is assigned egress IP addresses independently. Note that this doesn’t apply to parent-child windows that need a programmatic relationship, such as popups and their openers.</li>
<li><strong>Geolocation privacy by default</strong>. Private Browsing uses an IP location based on your country and time zone, not a more specific location.</li>
<li><strong>Warnings before revealing IP address</strong>. When accessing a server that is not accessible on the public internet, such as a local network server or an internal corporate server, Safari cannot use iCloud Private Relay. In Private Browsing, Safari now displays a warning requesting that the user consents to revealing their IP address to the server before loading the page.</li>
</ul>
<h2>Extensions in Private Browsing</h2>
<p>Safari 17.0 also boosts the privacy of Extensions in Private Browsing. Extensions that can access website data and browsing history are now off by default in Private Browsing. Users can still choose to allow an extension to run in Private Browsing and gain all of the extension’s utility. Extensions that don’t access webpage contents or browsing history, like Content Blockers, are turned on by default in Private Browsing when turned on in Safari.</p>
<h2>Advanced Fingerprinting Protection</h2>
<p>With Safari and subsequently <a href="https://wiki.mozilla.org/Security/Anti_tracking_policy">other</a> <a href="https://www.chromium.org/Home/chromium-privacy/privacy-sandbox/#turning-down-third-party-cookies">browsers</a> restricting stateful tracking (e.g. cross-site cookies), many trackers have turned to stateless tracking, often referred to as <em>fingerprinting</em>.</p>
<h3>Types of Fingerprinting</h3>
<p>We distinguish these types of fingerprinting:</p>
<ul>
<li><strong>Device fingerprinting</strong>. This is about building a fingerprint based on device characteristics, including hardware and the current operating system and browser. It can also include connected peripherals if they are allowed to be detected. Such a fingerprint cannot be changed by the user through settings or web extensions.</li>
<li><strong>Network and geographic position fingerprinting</strong>. This is about building a fingerprint based on how the device connects to the Internet and any means of detecting its geographic position. It could be done by measuring roundtrip speeds of network requests or simply using the IP address as an identifier.</li>
<li><strong>User settings fingerprinting</strong>. This is about reading the state of user settings such as dark/light mode, locale, font size adjustments, and window size on platforms where the user can change it. It also includes detecting web extensions and accessibility tools. We find this kind of fingerprinting to be extra hurtful since it exploits how users customize their web experience to fit their needs.</li>
<li><strong>User behavior fingerprinting</strong>. This is about detecting recurring patterns in how the user behaves. It could be how the mouse pointer is used, how quickly they type in form fields, or how they scroll.</li>
<li><strong>User traits fingerprinting</strong>. This is about figuring out things about the user, such as their interests, age, health status, financial status, and educational background. Those gleaned traits can contribute to a unique ID but also can be used directly to target them with certain content, adjust prices, or tailor messages.</li>
</ul>
<h3>Fingerprint Stability</h3>
<p>A challenge for any tracker trying to create a fingerprint is how stable the fingerprint will be over time. Software version fingerprinting changes with software updates, web extension fingerprinting changes with extension updates and enablement/disablement, user settings change when the user wants, multiple users of the same device means behavior fingerprints change, and roaming devices may change network and geographic position a lot.</p>
<h3>Fingerprinting Privacy Problem 1: Cross-Site Tracking</h3>
<p>Fingerprints can be used to track the user across websites. If successful, it defeats tracking preventions such as storage partitioning and link decoration filtering.</p>
<p>There are two types of solutions to this problem:</p>
<ol>
<li>Make the fingerprint be shared among many users, so called herd immunity.</li>
<li>Make the fingerprint unique per website, typically achieved via randomized noise injection.</li>
</ol>
<h3>Fingerprinting Privacy Problem 2: Per-Site User Recall</h3>
<p>Less talked about is the fingerprinting problem of per-site user recall. Web browsers offer at least two ways for the user to reset their relationship with a website: Clear website data or use Private Browsing. Both make a subsequent navigation to a website start out fresh.</p>
<p>But fingerprinting defeats this and allows a website to remember the user even though they’ve opted to clear website data or use Private Browsing.</p>
<p>There are two types of solutions to this problem:</p>
<ol>
<li>Make the fingerprint be shared among many users, so called herd immunity.</li>
<li>Make the fingerprint unique per website, and generate a new unique fingerprint for every fresh start.</li>
</ol>
<h3>Fingerprinting Privacy Problem 3: Per-Site Visitor Uniqueness</h3>
<p>The ultimate anti fingerprinting challenge in our view is to address a specific user’s uniqueness when visiting a specific website. Here’s a simple example:</p>
<p>Having the locale setting to US/EN for American English may provide ample herd immunity in many cases. But what happens when a user with that setting visits an Icelandic government website or a Korean reading club website? They may find themselves in a very small “herd” on that particular website and combined with just a few more fingerprinting touch points they can be uniquely identified.</p>
<p>Addressing per-site visitor uniqueness is not possible in general by a browser unless it knows what the spread of visitors looks like for individual websites.</p>
<h3>Fingerprinting Protections at a High Level</h3>
<p>We view cross-site tracking and per-site user recall as privacy problems to be addressed by browsers.</p>
<p><strong>Our approach</strong>:<br>
Make the fingerprint unique per website, and generate a new unique fingerprint for every fresh start such as at website data removal.</p>
<p><strong>Our tools</strong>:</p>
<ul>
<li>Use multi-hop proxies to hide IP addresses and defend against network and geographic position fingerprinting.</li>
<li>Limit the number of fingerprintable web APIs whenever possible. This could mean altering the APIs, gating them behind user permissions, or not implementing them.</li>
<li>Inject small amounts of noise in return values of fingerprintable web APIs.</li>
</ul>
<h3>Fingerprinting Protection Details</h3>
<p>Safari’s new advanced fingerprinting protections make it difficult for scripts to <strong>reliably</strong> extract <strong>high-entropy</strong> data through the use of several web APIs:</p>
<ol>
<li>To make it more difficult to <strong>reliably</strong> extract details about the user’s configuration, Safari injects noise into various APIs: namely, during 2D canvas and WebGL readback, and when reading <code>AudioBuffer</code> samples using WebAudio.</li>
<li>To reduce the overall <strong>entropy</strong> exposed through other APIs, Safari also overrides the results of certain web APIs related to window or screen metrics to fixed values, such that fingerprinting scripts that call into these APIs for users with different screen or window configurations will get the same results, even if the users’ underlying configurations are different.</li>
</ol>
<h4>2D Canvas and WebGL</h4>
<p>Many modern web browsers use a computer’s graphics processing unit (GPU) to accelerate rendering graphics. The Web’s Canvas API (2D Canvas) and WebGL API give a web page the tools it needs for rendering arbitrary images and complex scenes using the GPU, and analyzing the result. These APIs are valuable for the web platform, but they allow the web page to learn unique details about the underlying hardware without asking for consent. With Safari’s advanced fingerprinting protections enabled, Safari applies tiny amounts of noise to pixels on the canvas that have been painted using drawing commands. These modifications reduce the value of a fingerprint when using these APIs without significantly impacting the rendered graphics.</p>
<p>It’s important to emphasize that:</p>
<ol>
<li>This noise injection only happens in regions of the canvas where drawing occurs.</li>
<li>The amount of noise injected is extremely small, and (mostly) should not result in observable differences or artifacts.</li>
</ol>
<p>This strategy helps mitigate many of the compatibility issues that arise from this kind of noise injection, while still maintaining robust fingerprinting mitigations.</p>
<p>In Safari 17.5, we’ve bolstered these protections by additionally injecting noise when reading back data from offscreen canvas in both service workers and shared workers.</p>
<h4>Web Audio</h4>
<p>Similarly, when reading samples using the WebAudio API — via <code>AudioBuffer.getChannelData()</code> — a tiny amount of noise is applied to each sample to make it very difficult to reliably measure OS differences. In practice, these differences are already extremely minor. Typically due to slight differences in the order of operations when applying FFT or IFFT. As such, a relatively low amount of noise can make it substantially more difficult to obtain a stable fingerprint.</p>
<p>In Safari 17.5, we made audio noise injection more robust in the following ways:</p>
<ul>
<li>The injected noise now applies consistently to the same values in a given audio buffer — this means a looping  <code>AudioSourceNode</code> that contains a single high-entropy sample can’t be used to average out the injected noise and obtain the original value quickly.</li>
<li>Instead of using a uniform distribution for the injected noise, we now use normally-distributed noise. The mean of this distribution converges much more slowly on the original value, when compared to the average of the minimum and maximum value in the case of uniformly-distributed noise.</li>
<li>Rather than using a low, fixed amount of noise (0.1%), we’ve refactored the noise injection mechanism to support arbitrary levels of noise injection. This allows us to easily fine-tune noise injection, such that the magnitude of noise increases when using audio nodes that are known to reveal subtle OS or hardware differences through minute differences in sample values.</li>
</ul>
<p>This noise injection also activates when using Audio Worklets (e.g. <code>AudioWorkletNode</code>) to read back audio samples.</p>
<h4>Screen/Window Metrics</h4>
<p>Lastly, for various web APIs that currently directly expose window and screen-related metrics, Safari takes a different approach: instead of the noise-injection-based mitigations described above, entropy is reduced by fixing the results to either hard-coded values, or values that match other APIs.</p>
<ul>
<li><code>screen.width</code> / <code>screen.height</code>: The screen size is fixed to the values of <code>innerWidth</code> and <code>innerHeight</code>.</li>
<li><code>screenX</code> / <code>screenY</code>: The screen position is fixed to <code>(0, 0)</code>.</li>
<li><code>outerWidth</code> / <code>outerHeight</code>: Like screen size, these values are fixed to <code>innerWidth</code> and <code>innerHeight</code>.</li>
</ul>
<p>These mitigations also apply when using media queries to indirectly observe the screen size.</p>
<h2>Don’t Add Fingerprintable APIs to the Web, Like The Topics API</h2>
<p>We have worked for many years with the standards community on improving user privacy of the web platform. There are existing web APIs that are fingerprintable, such as Canvas, and reining in their fingerprintability is a long journey. Especially since we want to ensure existing websites can continue to work well.</p>
<p>It is key for the future privacy of the web to not compound the fingerprinting problem with new, fingerprintable APIs. There are cases where the tradeoff tells us that a rich web experience or enhanced accessibility motivates some level of fingerprintability. But in general, our position is that we should progress the web without increasing fingerprintability.</p>
<p>A recent example where we opposed a new proposal is the Topics API which is now <a href="https://developers.google.com/privacy-sandbox/relevance/topics">shipping in the Chrome browser</a>. We provided <a href="https://github.com/WebKit/standards-positions/issues/111">extensive critical feedback</a> as part of the standards process and we’d like to highlight a few pieces here.</p>
<h3>The Topics API in a Nutshell</h3>
<p>From the <a href="https://github.com/patcg-individual-drafts/topics">proposal</a>:</p>
<pre><code><span>// document.browsingTopics() returns an array of up to three topic objects in random order.
</span><span>const</span> <span>topics</span> <span>=</span> <span>await</span> <span>document</span>.<span>browsingTopics</span>();
</code></pre>
<p>Any JavaScript can call this function on a webpage. Yes, that includes tracker scripts, advertising scripts, and data broker scripts.</p>
<p>The topics come from a predefined list of hundreds of topics. It’s not the user who picks from these topics, but instead Chrome will record the user’s browsing history over time and deduce interests from it. The user doesn’t get told upfront which topics Chrome has tagged them with or which topics it exposes to which parties. It all happens in the background and by default.</p>
<p>The intent of the API is to help advertisers target users with ads based on each user’s interests even though the current website does not necessarily imply that they have those interests.</p>
<h3>The Fingerprinting Problem With the Topics API</h3>
<p>A new <a href="https://arxiv.org/html/2403.19577v1">research paper</a> by Yohan Beugin and Patrick McDaniel from University of Wisconsin-Madison goes into detail on Chrome’s actual implementation of the Topics API.</p>
<p>The authors use large scale real user browsing data (voluntarily donated) to show both how the 5% noise supposed to provide plausible deniability for users can be defeated, and how the Topics API can be used to fingerprint and re-identify users.</p>
<blockquote><p>
  “We conclude that an important part of the users from this real dataset are re-identified across websites through only the observations of their topics of interest in our experiment. Thus, the real users from our dataset can be fingerprinted through the Topics API. Moreover, as can be seen, the information leakage and so, privacy violation worsen over time as more users are uniquely re-identified.” —Beugin and McDaniel, University of Wisconsin-Madison
</p></blockquote>
<p>The paper was published at the <a href="https://ieeexplore.ieee.org/document/10579537">2024 IEEE Security and Privacy Workshops (SPW)</a> in May.</p>
<h3>Further Privacy Problems With the Topics API</h3>
<p>Re-identifying and tracking users is not the only privacy problem with the Topics API. There is also the profiling of users’ cross-site activity. Here’s an example using topics on <a href="https://github.com/patcg-individual-drafts/topics/blob/main/taxonomy_v2.md">Chrome’s predefined list</a>.</p>
<p>Imagine in May 2024 you go to <code>news.example</code> where you are a subscriber and have provided your email address. Embedded on the website, <code>dataBroker.example</code>. The data broker has gleaned your email address from the login form and calls the Topics API to learn that you currently have these interests:</p>
<ul>
<li>Flowers</li>
<li>Event &amp; Studio Photography</li>
<li>Luxury Travel</li>
</ul>
<p>In May 2026 you go to <code>news.example</code> where <code>dataBroker.example</code> calls the Topics API and is told that you now have these interests:</p>
<ul>
<li>Children’s Clothing</li>
<li>Family Travel</li>
<li>Toys</li>
</ul>
<p>Finally, in May 2029 you go to <code>news.example</code> where <code>dataBroker.example</code> calls the Topics API and is told that you have these interests:</p>
<ul>
<li>Legal Services</li>
<li>Furnished Rentals</li>
<li>Child Care</li>
</ul>
<p>You haven’t told any website with access to your email address anything that’s been going on in your family life. But the data broker has been able to read your shifting interests and store them in their permanent profile of you — while you were reading the news.</p>
<p>Now imagine what advanced machine learning and artificial intelligence can deduce about you based on various combinations of interest signals. What patterns will emerge when data brokers and trackers can compare and contrast across large portions of the population? Remember that they can combine the output of the Topics API with any other data points they have available, and it’s the analysis of all of it together that feeds the algorithms that try to draw conclusions about you.</p>
<p>We think the web should not expose such information across websites and we don’t think the browser, i.e. <em>the user agent</em>, should facilitate any such data collection or use.</p>
<h2>Privacy Enhancements in Both Browsing Modes</h2>
<p>Our defenses against cloaked third-party IP addresses and our partitioning of SessionStorage and blob URLs are enabled by default in both regular browsing and Private Browsing. Here’s how those protections work.</p>
<h3>Defending Against Cloaked First Party IP Addresses</h3>
<p>In 2020, Intelligent Tracking Prevention (ITP) gained the ability to <a href="https://webkit.org/blog/11338/cname-cloaking-and-bounce-tracking-defense">cap the expiry of cookies set in third-party CNAME-cloaked HTTP responses to 7 days</a>.</p>
<p>This defense did not mitigate cases where IP aliasing is used to cloak third party requests under first party subdomains. ITP now also applies a 7-day cap to the expiry of cookies in responses from cloaked third-party IP addresses. Detection of third-party IP addresses is heuristic, and may change in the future. Currently, two IP addresses are considered different parties if any of the following criteria are met:</p>
<ol>
<li>One IP address is IPv4, while the other is IPv6.</li>
<li>If both addresses are IPv4, the length of the common subnet mask is less than 16 bits (half of the full address length).</li>
<li>If both addresses are IPv6, the length of the common subnet mask is less than 64 bits (also half of the full address length).</li>
</ol>
<h3>Partitioned SessionStorage and Blob URLs</h3>
<p>Websites have many options for how they store information over longer time periods. <a href="https://developer.mozilla.org/en-US/docs/Web/API/Window/sessionStorage">Session Storage</a> is a storage area in Safari that is scoped to the current tab. When a tab in Safari is closed, all of the session storage associated with it is destroyed. Beginning in Safari 16.1 cross-site Session Storage is partitioned by first-party web site.</p>
<p>Similarly, <a href="https://developer.mozilla.org/en-US/docs/Web/API/Blob">Blobs</a> are a storage type that allow websites to store raw, file-like data in the browser. A blob can hold almost anything, from simple text to something larger and more complex like a video file. A unique URL can be <a href="https://developer.mozilla.org/en-US/docs/Web/API/URL/createObjectURL_static">created for a blob</a>, and that URL can be used to gain access to the associated blob, as long as the blob still exists. These URLs are often referred to as Blob URLs, and a Blob URL’s lifetime is scoped to the document that creates it. Beginning in Safari 17.2, cross-site Blob URLs are partitioned by first-party web site, and first-party Blob URLs are not usable by third parties.</p>
<h2>Setting a New Industry Standard</h2>
<p>The additional privacy protections of Private Browsing in Safari 17.0, Safari 17.2 and Safari 17.5 set a new bar for user protection. We’re excited for all Safari users and the web itself to benefit from this work!</p>
<h2>Feedback</h2>
<p>We love hearing from you! To share your thoughts on Private Browsing 2.0, find John Wilander on Mastodon at <a href="https://mastodon.social/@wilander">@wilander@mastodon.social</a> or send a reply on X to <a href="https://x.com/webkit">@webkit</a>. You can also <a href="https://www.linkedin.com/in/apple-webkit/">follow WebKit on LinkedIn</a>. If you run into any issues, we welcome your <a href="https://feedbackassistant.apple.com/">feedback</a> on Safari UI (learn more about <a href="https://developer.apple.com/bug-reporting/">filing Feedback</a>), or your <a href="https://bugs.webkit.org/">WebKit bug report</a> about web technologies or Web Inspector.</p>

                            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Deconstructing the Role-Playing Video Game (121 pts)]]></title>
            <link>https://olano.dev/blog/deconstructing-the-role-playing-videogame/</link>
            <guid>40977834</guid>
            <pubDate>Tue, 16 Jul 2024 16:09:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://olano.dev/blog/deconstructing-the-role-playing-videogame/">https://olano.dev/blog/deconstructing-the-role-playing-videogame/</a>, See on <a href="https://news.ycombinator.com/item?id=40977834">Hacker News</a></p>
<div id="readability-page-1" class="page"><div lang="en">
      <header>
          
          
          
          

      </header>

      
      <p>
<em>Following up on my <a href="https://olano.dev/blog/a-computing-magazine-anthology">previous post</a> on archived project ideas, today I want to write about an <a href="https://github.com/facundoolano/rpg-cli">rpg-cli</a> spin-off. rpg-cli is one of my fondest personal projects and I never properly documented its development, so I’ll start this post by doing just that.</em></p>
<h2>Contents</h2>
<nav>
<ul>
<li><a href="#the-simplest-thing-that-could-possibly-work">The simplest thing that could possibly work</a>
</li>
<li><a href="#your-file-system-as-a-dungeon">Your file system as a dungeon</a>
</li>
<li><a href="#research">Research</a>
</li>
<li><a href="#pseudo-historical-digression">Pseudo-historical digression</a>
</li>
<li><a href="#design">Design</a>
</li>
<li><a href="#development">Development</a>
</li>
<li><a href="#postscript-a-text-interface-for-rpg-cli">Postscript: A text interface for rpg-cli</a>
</li>
<li><a href="#notes">Notes</a>
</li>
</ul>
</nav>
<h2 id="the-simplest-thing-that-could-possibly-work">
The simplest thing that could possibly work
</h2>
<p>
This was back in 2021. I was going through one of those periods where I didn’t get much intellectual satisfaction from my daily job, so I thought I could use a programming side project. I had an itch to work on a video game, something I hadn’t done in a while.
In the past few years I had finished many classic Japanese RPGs—<em>Final Fantasy VI</em>, <em>A Link to the Past</em>, <em>Chrono Trigger</em>, <em>Suikoden 2</em>, <em>Final Fantasy Tactics—</em> so I felt compelled to try something with that genre. But I like personal projects to be short-lived and yield something usable, somewhat finished, after a few months; I wasn’t about to embark on a full game development project in my spare time.</p>
<p>
I’ve played JRPGs long enough that I don’t pay much attention to the characters or the plot anymore; I like the pretty pixels, yes, but most importantly I’m drawn to its underlying systems. Explore the map, visit cities, clear dungeons; kill monsters, level up, buy equipment; character stats, turn-based combat, leveling system. To me, a classic JRPG is pure mechanism, a kind of puzzle. Was there some way of getting the fun out of building such a mechanism—of solving that puzzle—, wrapping it with the minimal amount of functionality, the simplest thing that could possibly pass as a video game?</p>
<p>
In other words: how much could I have peeled off, and still gotten an RPG? One answer was obvious: no dialogues, no plot, no story<sup><a id="footnote-reference-1" href="#footnote-1">1</a></sup>. But that wouldn’t be enough: the big  blocker was the graphics, I needed to work around them in all their rabbit-hole, yak-shaving glory. I had just seen how the <em>Final Fantasy Tactics</em> designers had fit most of the standard RPG elements, save the battle sequences, into menu screens. Perhaps I could have tried something like that. If it were today, I’d consider building a mini-game with PICO-8 or an ASCII roguelike; at the time, I went with a trick that <a href="https://github.com/facundoolano/advenjure">had worked for me</a> before: using text instead of graphics.</p>
<p>
Except, you know what’s narrower than a text user interface?</p>
<p>
A command-line interface.</p>
<p>
Was there any way I could make a role-playing game fit in the shell?</p>
<h2 id="your-file-system-as-a-dungeon">
Your file system as a dungeon
</h2>
<p>This was one of those cases where formal constraints foster creativity. I derived many design decisions from restricting myself to a command-line interface. The CLI also gave me a good excuse to try Rust, something I had been looking for.</p>
<p>
The shell is the <em>environment</em> of command-line programs; the file system gives a sense of <em>place</em>. At some point, I made that association and decided that the hero of my game would <em>inhabit</em> the file system, with the working directory as its current location. Changing directories would be like moving between dungeon levels, enemies popping up along the way: the more nested the directory, the tougher the enemies. As in many early CRPGs, the game’s goal would be just to crawl down the dungeon, as deep as possible. Going back <code>~</code> (home) would restore the hero’s health and give the player a chance to buy equipment and supplies.</p>
<p>
This idea finally clicked when I imagined the program as a <code>cd</code> replacement, where players would randomly engage in combats as a side effect of doing their daily work in the terminal:</p>
<p><img src="https://olano.dev/assets/img/rpgcli.png">
</p>
<p>
A pure command-line interface also meant that the gameplay would have to be non-interactive. This was a problem for the traditional turn-based combat I had in mind. The solution was inspired by <em>Suikoden 2</em>, a PlayStation game I had recently finished.</p>
<p>
In <em>Suikoden 2,</em> you manage a huge list of playable characters (over 100), in parties of up to six members. When enemies pop up in dungeons, having to issue six commands on each turn, with characters you haven’t been using for long, can get tedious. The developers had the good sense to introduce an <em>auto-battle</em> button that just repeats the basic attack of each party member until the enemy is killed.</p>
<p>
So I decided to make this auto-battle feature the default for rpg-cli. This <em>felt right</em> to me because I’m a very dull player when it comes to combat. I don’t particularly enjoy strategizing, I just default to punch with warriors and spell with wizards, with the occasional healing potion in between, until enemies become tough enough that they force me to stop and think. So I would bake that pattern right into rpg-cli’s battle logic: default to attack unless HP is low and a potion is available. (I later extended this to account for magical classes that attack with spells and occasionally need to restore their magical points).</p>
<p>
This would obviously remove some player agency (and fun) from the combat; the opportunity to make choices and strategize would need to happen between battles: deciding whether to go further down the dungeon or back home to recover, when to use items, how to spend the gold, etc.</p>
<h2 id="research">
Research
</h2>
<p>
I felt that the radical simplicity I started from had unexpectedly led me to an interesting concept for the game, so I decided to double down on “the simplest thing that could possibly work” as my design mantra, applying it to the entire project, not just the interface.</p>
<p>
I had a concept, an implementation language, a scope, and a rough outline of the interface for my program. But, before I could start coding its basic building blocks, I needed to design the RPG model: a stat system to know what attributes to give to the characters, a leveling system to know how to raise them, and a combat routine that would put them to use.</p>
<p>
My experience of the genre was almost exclusively through JRPGs, so it felt appropriate to do some research, to see if I could get ideas from western video games and tabletop RPGs: is there a canonical set of enemy classes? has someone else already figured out the minimum set of stats to make an RPG work? Would I benefit from learning the <em>Dungeon &amp; Dragons</em> rules?</p>
<p>
I started by looking around for tabletop RPGs designed for minimalism or genericity:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/GURPS">GURPS</a>, the Generic Universal role-playing System.</li>
<li><a href="https://en.wikipedia.org/wiki/TWERPS">TWERPS</a>, the World’s Easiest role-playing System.</li>
<li><a href="https://en.wikipedia.org/wiki/Dinky_Dungeons">Dinky Dungeons</a>, the smallest RPG ever produced<sup><a id="footnote-reference-2" href="#footnote-2">2</a></sup>.</li>
<li><a href="http://www.campaignmastery.com/blog/introducing-the-sixes-system/">The Sixes System</a>, a Minimalist Universal RPG.</li>
<li><a href="https://www.perilplanet.com/freeform-universal/">FU</a>, the Freeform Universal RPG.</li>
<li><a href="https://www.stargazergames.eu/warrior-rogue-mage/">Warrior, Rogue &amp; Mage</a>, a simple, lightweight RPG.</li>
</ul>
<p><img src="https://olano.dev/assets/img/dinky.jpg">
</p>
<p>
Fun and educational as that excursion was, it left me more confused than when I started. I concluded that tabletop rulesets would contribute complexity rather than simplicity to my project, so I went back to using video games as my reference. In addition to the ones I was already familiar with, I spent some time reading about <em>Rogue</em> and its descendants since, from the little I knew about them, it sounded like they could teach me some things about minimalist design:</p>
<ul>
<li><a href="https://web.archive.org/web/20050206091120/http://www.wichman.org/roguehistory.html">A Brief History of “Rogue”</a>.</li>
<li><a href="https://insight.ieeeusa.org/articles/going-rogue-a-brief-history-of-the-computerized-dungeon-crawl/">Going Rogue: A Brief History of the Computerized Dungeon Crawl</a>.</li>
<li><a href="http://crpgaddict.blogspot.com/2010/02/rogue-most-difficult-crpg-ive-played.html">Rogue: the most difficult CRPG I’ve played</a>.</li>
<li><a href="http://crpgaddict.blogspot.com/2010/02/rogue-story-and-gameplay.html">Rogue: Story and Gameplay</a>.</li>
<li><a href="https://gamedevelopment.tutsplus.com/articles/the-key-design-elements-of-roguelikes--cms-23510">The Key Design Elements of Roguelikes</a>.</li>
</ul>
<p>Finally, I looked at some RPG design resources. The most useful was the <a href="https://howtomakeanrpg.com/">How To Make an RPG</a> series, particularly the entries on <a href="http://howtomakeanrpg.com/a/how-to-make-an-rpg-stats.html">stats</a> and <a href="http://howtomakeanrpg.com/a/how-to-make-an-rpg-levels.html">levels</a>.</p>
<h2 id="pseudo-historical-digression">
Pseudo-historical digression
</h2>
<p>I didn’t know it back then, but there is an illustrious tradition of deconstructing the role-playing game. RPG video games came from tabletop RPGs, that came from war games, that came from the <a href="https://en.wikipedia.org/wiki/Kriegsspiel">Kriegsspiel</a>, a simulation game that the Prussian army trained with during the 19th century<sup><a id="footnote-reference-3" href="#footnote-3">3</a></sup>. Like its war gaming ancestors, <em>Dungeons &amp; Dragons</em> was full of complexity: sophisticated rules for character building, catalogs of monsters and spells and armor, and battle outcomes decided by probability calculations. This was arguably part of the fun, at least for some of the players—for others, a complicated system is an invitation to simplify and abstract.</p>
<p>
It’s no secret that there was some overlap between early RPG players and computer programmers; crucially, a significant portion of the privileged few people with computer access in the late '70s were <em>Dungeons &amp; Dragons</em> players. It didn’t require much of a mental leap to try to combine the two; at first to offload number crunching to the computer, eventually to create the solo playing experiences that were the first computerized RPGs.
This process culminated in <em>Wizardry</em> and <em>Ultima</em>, the two franchises that dominated computer gaming in the '80s.</p>
<p>
Over in Japan, the Enix designers combined the dungeon crawling from <em>Wizardry</em> and the over-world exploration of <em>Ultima</em>, adjusting them to the limitations of the Famicom/NES console—and to the tastes of the local public.
With a linear story, streamlined systems focused on battles, and a more forgiving difficulty level, <em>Dragon Quest</em>
became the blueprint of what would become the Japanese RPG genre<sup><a id="footnote-reference-4" href="#footnote-4">4</a></sup>. Shigeru Miyamoto offered his own interpretation in <em>The Legend of Zelda</em>, with a shift towards arcade action and a leveling system reified as a heart count. A decade later, the Blizzard North team would reinvent role-playing on the PC by removing most of its ceremony. Drawing heavily from the roguelikes, <em>Diablo</em> simplifies character setup and stats and generally removes anything that could stand in the way of slashing monsters and grabbing loot<sup><a id="footnote-reference-5" href="#footnote-5">5</a></sup>.</p>
<p>
In retrospect, looking at tabletop RPGs felt backward because, by using the video games I already knew as models instead, I was benefiting from decades of RPG system simplifications—half the job had already been done.</p>
<h2 id="design">
Design
</h2>
<p>
I wanted the least amount of stats that could make battles work non-deterministically enough to be fun.
Inspired by <em>TWERPS</em>, I briefly considered having a single stat to determine both inflicted damage and available hit points, but that resulted in unbalanced battles, so I went instead with the classic <code>hp</code> and <code>strength</code> stats. Later, when outlining the battle routine, it became apparent that I would also need a <code>speed</code> stat to mimic the turn-based style of <em>Final Fantasy</em>; that is, rather than having each character attack in a round-robin fashion, the fastest characters would get turns more frequently. These choices <a href="https://github.com/facundoolano/rpg-cli/blob/d4c90252db34a04e9abb7e96623c62d6fe47edfe/src/character.rs#L15-L27">resulted</a> in the following struct:</p>
<div>
<pre><code><span><span><span>pub</span><span> </span><span>struct</span> <span>Character</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>name: <span>String</span>,<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>level: <span>i32</span>,<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>xp: <span>i32</span>,<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>max_hp: <span>i32</span>,<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>current_hp: <span>i32</span>,<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>strength: <span>i32</span>,<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>speed: <span>i32</span>,<span>
</span></span></span><span><span><span></span>}</span></span></code></pre>
</div>
<p>
Item and equipment management was another feature that I found could be automated. Items would be bought at the home directory, with an <code>rpg-cli shop</code> subcommand, or found in chests, by inspecting directories with <code>rpg-cli ls</code>. Equipment would be generic and level-based; instead of a Wooden Sword, a Bronze Blade, or a Steel Saber, players would have a <code>sword[1]</code> and a <code>shield[1]</code> available at the shop from the start, a <code>sword[5]</code> and a <code>shield[5]</code> unlocked when the hero reached level 5, and so on. Stronger equipment would automatically replace its weaker equivalent when bought or found, removing the sell-old-buy-new toil of traditional JRPGs. Healing items would be similarly level-based.</p>
<p>
When I eventually imported the permadeath feature from roguelikes, I decided to drop a tombstone to recover gold, items, and equipment from the directory where the character died, giving the player some sense of progress and making it more feasible to unlock end-game features.</p>
<h2 id="development">
Development
</h2>
<p>As soon as I started prototyping, I learned that I couldn’t control the shell working directory from my program (something obvious if you think about it, but that I hadn’t considered before). The solution was for the program state to track its own “path to current hero location”, and use a shell function to sync with it:</p>
<div>
<pre><code><span><span>rpg <span>()</span> <span>{</span>
</span></span><span><span>    rpg-cli <span>"</span><span>$@</span><span>"</span>         <span># forward arguments to rpg-cli</span>
</span></span><span><span>    <span>cd</span> <span>"</span><span>$(</span>rpg-cli <span>pwd</span><span>)</span><span>"</span>  <span># move shell to the hero's location</span>
</span></span><span><span><span>}</span></span></span></code></pre>
</div>
<p>
The hardcore version would be to overwrite the built-in <code>cd</code> function so that enemies would pop up as the user changed directories:</p>
<div>
<pre><code><span><span><span>cd</span> <span>()</span> <span>{</span>
</span></span><span><span>    rpg-cli <span>cd</span> <span>"</span><span>$@</span><span>"</span>
</span></span><span><span>    <span>builtin</span> <span>cd</span> <span>"</span><span>$(</span>rpg-cli <span>pwd</span><span>)</span><span>"</span>
</span></span><span><span><span>}</span></span></span></code></pre>
</div>
<p>
Other commands like <code>rm</code>, <code>mkdir</code>, or <code>touch</code>, could be similarly aliased to integrate with the game. These usage patterns paved the way for <a href="https://github.com/facundoolano/rpg-cli/blob/da433ff186ba32e86c386e049b3f68e0b6c7de80/shell/README.md">further options and flags</a>, to show the game state at the shell prompt, write scripts, and build custom gameplay flows.</p>
<p>∗ ∗ ∗</p>
<p>
Once I got the core of the game working, I used it as a canvas, loosening up on minimalism to port features I liked from other games: character classes, status ailments, a quest to-do list, hidden enemies, easter eggs, and a final boss. This is what the <a href="https://github.com/facundoolano/rpg-cli/blob/da433ff186ba32e86c386e049b3f68e0b6c7de80/src/character/mod.rs#L16-L36">character struct</a> looked like after these extensions:</p>
<div>
<pre><code><span><span><span>pub</span><span> </span><span>struct</span> <span>Character</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>class: <span>Class</span>,<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>level: <span>i32</span>,<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>xp: <span>i32</span>,<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span>max_hp: <span>i32</span>,<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>current_hp: <span>i32</span>,<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span>max_mp: <span>i32</span>,<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>current_mp: <span>i32</span>,<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span>strength: <span>i32</span>,<span>
</span></span></span><span><span><span>    </span>speed: <span>i32</span>,<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>sword: <span>Option</span><span>&lt;</span>Equipment<span>&gt;</span>,<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>shield: <span>Option</span><span>&lt;</span>Equipment<span>&gt;</span>,<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>left_ring: <span>Option</span><span>&lt;</span>Ring<span>&gt;</span>,<span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>right_ring: <span>Option</span><span>&lt;</span>Ring<span>&gt;</span>,<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>pub</span><span> </span>status_effect: <span>Option</span><span>&lt;</span>StatusEffect<span>&gt;</span>,<span>
</span></span></span><span><span><span></span>}</span></span></code></pre>
</div>
<p>
The character classes are defined in a <a href="https://github.com/facundoolano/rpg-cli/blob/f2d37631628461ee192864e464e2088415e3866c/src/character/classes.yaml">yaml file</a> that can be overridden by the user to customize the game. Here’s an excerpt:</p>
<div>
<pre><code><span><span>- <span>name</span>:<span> </span>warrior<span>
</span></span></span><span><span><span>  </span><span>hp</span>:<span> </span>[<span>50</span>,<span> </span><span>10</span>]<span>
</span></span></span><span><span><span>  </span><span>strength</span>:<span> </span>[<span>12</span>,<span> </span><span>3</span>]<span>
</span></span></span><span><span><span>  </span><span>speed</span>:<span> </span>[<span>11</span>,<span> </span><span>2</span>]<span>
</span></span></span><span><span><span>  </span><span>category</span>:<span> </span>player<span>
</span></span></span><span><span><span></span>- <span>name</span>:<span> </span>mage<span>
</span></span></span><span><span><span>  </span><span>hp</span>:<span> </span>[<span>30</span>,<span> </span><span>6</span>]<span>
</span></span></span><span><span><span>  </span><span>mp</span>:<span> </span>[<span>10</span>,<span> </span><span>4</span>]<span>
</span></span></span><span><span><span>  </span><span>strength</span>:<span> </span>[<span>10</span>,<span> </span><span>3</span>]<span>
</span></span></span><span><span><span>  </span><span>speed</span>:<span> </span>[<span>10</span>,<span> </span><span>2</span>]<span>
</span></span></span><span><span><span>  </span><span>category</span>:<span> </span>player<span>
</span></span></span><span><span><span></span>- <span>name</span>:<span> </span>rat<span>
</span></span></span><span><span><span>  </span><span>hp</span>:<span> </span>[<span>15</span>,<span> </span><span>5</span>]<span>
</span></span></span><span><span><span>  </span><span>strength</span>:<span> </span>[<span>5</span>,<span> </span><span>2</span>]<span>
</span></span></span><span><span><span>  </span><span>speed</span>:<span> </span>[<span>16</span>,<span> </span><span>2</span>]<span>
</span></span></span><span><span><span>  </span><span>category</span>:<span> </span>common<span>
</span></span></span><span><span><span></span>- <span>name</span>:<span> </span>dragon<span>
</span></span></span><span><span><span>  </span><span>hp</span>:<span> </span>[<span>110</span>,<span> </span><span>5</span>]<span>
</span></span></span><span><span><span>  </span><span>strength</span>:<span> </span>[<span>25</span>,<span> </span><span>2</span>]<span>
</span></span></span><span><span><span>  </span><span>speed</span>:<span> </span>[<span>8</span>,<span> </span><span>2</span>]<span>
</span></span></span><span><span><span>  </span><span>inflicts</span>:<span> </span>[burn, 2]<span>
</span></span></span><span><span><span>  </span><span>category</span>:<span> </span>rare<span>
</span></span></span><span><span><span></span>- <span>name</span>:<span> </span>basilisk<span>
</span></span></span><span><span><span>  </span><span>hp</span>:<span> </span>[<span>180</span>,<span> </span><span>3</span>]<span>
</span></span></span><span><span><span>  </span><span>strength</span>:<span> </span>[<span>100</span>,<span> </span><span>2</span>]<span>
</span></span></span><span><span><span>  </span><span>speed</span>:<span> </span>[<span>18</span>,<span> </span><span>2</span>]<span>
</span></span></span><span><span><span>  </span><span>inflicts</span>:<span> </span>[poison, 2]<span>
</span></span></span><span><span><span>  </span><span>category</span>:<span> </span>legendary</span></span></code></pre>
</div>
<p>
The <a href="https://github.com/facundoolano/rpg-cli/blob/da433ff186ba32e86c386e049b3f68e0b6c7de80/src/game.rs#L86-L106"><code>Game::go_to</code></a> function shows how directory traversal is mapped to player movement and enemy spawning:</p>
<div>
<pre><code><span><span><span>/// Move the hero's location towards the given destination, one directory
</span></span></span><span><span><span>/// at a time, with some chance of enemies appearing on each one.
</span></span></span><span><span><span></span><span>pub</span><span> </span><span>fn</span> <span>go_to</span>(<span>
</span></span></span><span><span><span>    </span><span>&amp;</span><span>mut</span><span> </span><span>self</span>,<span>
</span></span></span><span><span><span>    </span>dest: <span>&amp;</span><span>Location</span>,<span>
</span></span></span><span><span><span>    </span>run: <span>bool</span>,<span>
</span></span></span><span><span><span>    </span>bribe: <span>bool</span>,<span>
</span></span></span><span><span><span></span>)<span> </span>-&gt; <span>Result</span><span>&lt;</span>(),<span> </span>character::Dead<span>&gt;</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>while</span><span> </span><span>self</span>.location<span> </span><span>!=</span><span> </span><span>*</span>dest<span> </span>{<span>
</span></span></span><span><span><span>        </span><span>// set the hero's location to the one given
</span></span></span><span><span><span></span><span>        </span><span>// and apply related side effects.
</span></span></span><span><span><span></span><span>        </span><span>self</span>.visit(<span>self</span>.location.go_to(dest))<span>?</span>;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>        </span><span>if</span><span> </span><span>!</span><span>self</span>.location.is_home()<span> </span>{<span>
</span></span></span><span><span><span>            </span><span>if</span><span> </span><span>let</span><span> </span><span>Some</span>(<span>mut</span><span> </span>enemy)<span> </span><span>=</span><span> </span>enemy::spawn(<span>&amp;</span><span>self</span>.location,<span> </span><span>&amp;</span><span>self</span>.player)<span> </span>{<span>
</span></span></span><span><span><span>                </span><span>// Attempt to bribe or run away according to the given options,
</span></span></span><span><span><span></span><span>                </span><span>// and start a battle if that fails.
</span></span></span><span><span><span></span><span>                </span><span>if</span><span> </span><span>self</span>.battle(<span>&amp;</span><span>mut</span><span> </span>enemy,<span> </span>run,<span> </span>bribe)<span>?</span><span> </span>{<span>
</span></span></span><span><span><span>                    </span><span>return</span><span> </span><span>Ok</span>(());<span>
</span></span></span><span><span><span>                </span>}<span>
</span></span></span><span><span><span>            </span>}<span>
</span></span></span><span><span><span>        </span>}<span>
</span></span></span><span><span><span>    </span>}<span>
</span></span></span><span><span><span>    </span><span>Ok</span>(())<span>
</span></span></span><span><span><span></span>}</span></span></code></pre>
</div>
<p>
As a wrap-up, see below the full definition of <a href="https://github.com/facundoolano/rpg-cli/blob/f2d37631628461ee192864e464e2088415e3866c/src/game.rs#L266-L316"><code>Game::run_battle</code></a>, the auto-battle routine at the core of the game. In a sense, the rest of the code exists as support for this function:</p>
<div>
<pre><code><span><span><span>/// Runs a turn-based combat between the game's player and the given enemy.
</span></span></span><span><span><span>/// The frequency of the turns is determined by the speed stat of each
</span></span></span><span><span><span>/// character.
</span></span></span><span><span><span>///
</span></span></span><span><span><span>/// Some special abilities are enabled by the player's equipped rings:
</span></span></span><span><span><span>/// Double-beat, counter-attack and revive.
</span></span></span><span><span><span>///
</span></span></span><span><span><span>/// Returns Ok(xp gained) if the player wins, or Err(()) if it loses.
</span></span></span><span><span><span></span><span>fn</span> <span>run_battle</span>(<span>&amp;</span><span>mut</span><span> </span><span>self</span>,<span> </span>enemy: <span>&amp;</span><span>mut</span><span> </span>Character)<span> </span>-&gt; <span>Result</span><span>&lt;</span><span>i32</span>,<span> </span>character::Dead<span>&gt;</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>// Player's using the revive ring can come back to life at most once per battle
</span></span></span><span><span><span></span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span>already_revived<span> </span><span>=</span><span> </span><span>false</span>;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>// These accumulators get increased based on the character's speed:
</span></span></span><span><span><span></span><span>    </span><span>// the faster will get more frequent turns.
</span></span></span><span><span><span></span><span>    </span><span>let</span><span> </span>(<span>mut</span><span> </span>pl_accum,<span> </span><span>mut</span><span> </span>en_accum)<span> </span><span>=</span><span> </span>(<span>0</span>,<span> </span><span>0</span>);<span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span>xp<span> </span><span>=</span><span> </span><span>0</span>;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>while</span><span> </span>enemy.current_hp<span> </span><span>&gt;</span><span> </span><span>0</span><span> </span>{<span>
</span></span></span><span><span><span>        </span>pl_accum<span> </span><span>+=</span><span> </span><span>self</span>.player.speed();<span>
</span></span></span><span><span><span>        </span>en_accum<span> </span><span>+=</span><span> </span>enemy.speed();<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>        </span><span>if</span><span> </span>pl_accum<span> </span><span>&gt;=</span><span> </span>en_accum<span> </span>{<span>
</span></span></span><span><span><span>            </span><span>// In some urgent circumstances, it's preferable to use the turn to
</span></span></span><span><span><span></span><span>            </span><span>// recover mp or hp than attacking
</span></span></span><span><span><span></span><span>            </span><span>if</span><span> </span><span>!</span><span>self</span>.autopotion(enemy)<span> </span><span>&amp;&amp;</span><span> </span><span>!</span><span>self</span>.autoether(enemy)<span> </span>{<span>
</span></span></span><span><span><span>                </span><span>let</span><span> </span>(new_xp,<span> </span>_)<span> </span><span>=</span><span> </span><span>self</span>.player.attack(enemy);<span>
</span></span></span><span><span><span>                </span>xp<span> </span><span>+=</span><span> </span>new_xp;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>                </span><span>self</span>.player.maybe_double_beat(enemy);<span>
</span></span></span><span><span><span>            </span>}<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>            </span><span>// Status effects are applied after each turn. The player may die
</span></span></span><span><span><span></span><span>            </span><span>// during its own turn because of status ailment damage
</span></span></span><span><span><span></span><span>            </span><span>let</span><span> </span>died<span> </span><span>=</span><span> </span><span>self</span>.player.apply_status_effects();<span>
</span></span></span><span><span><span>            </span>already_revived<span> </span><span>=</span><span> </span><span>self</span>.player.maybe_revive(died,<span> </span>already_revived)<span>?</span>;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>            </span>pl_accum<span> </span><span>=</span><span> </span><span>-</span><span>1</span>;<span>
</span></span></span><span><span><span>        </span>}<span> </span><span>else</span><span> </span>{<span>
</span></span></span><span><span><span>            </span><span>let</span><span> </span>(_,<span> </span>died)<span> </span><span>=</span><span> </span>enemy.attack(<span>&amp;</span><span>mut</span><span> </span><span>self</span>.player);<span>
</span></span></span><span><span><span>            </span>already_revived<span> </span><span>=</span><span> </span><span>self</span>.player.maybe_revive(died,<span> </span>already_revived)<span>?</span>;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>            </span><span>self</span>.player.maybe_counter_attack(enemy);<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>            </span>enemy.apply_status_effects().unwrap_or_default();<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>            </span>en_accum<span> </span><span>=</span><span> </span><span>-</span><span>1</span>;<span>
</span></span></span><span><span><span>        </span>}<span>
</span></span></span><span><span><span>    </span>}<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>Ok</span>(xp)<span>
</span></span></span><span><span><span></span>}</span></span></code></pre>
</div>
<p>
I like that, after a few years, I still find it reasonably self-explanatory.</p>
<h2 id="postscript-a-text-interface-for-rpg-cli">
Postscript: A text interface for rpg-cli
</h2>
<p>
Having to rely on preexisting directories to make progress in the game gets tedious after a while. I resorted to <a href="https://github.com/facundoolano/rpg-cli/tree/da433ff186ba32e86c386e049b3f68e0b6c7de80/shell#arbitrary-dungeon-levels">a function</a> that creates directories on the fly; other players wrote scripts to skip level grinding. The file system integration turned rpg-cli into a curiosity, but it had been more of an afterthought, the result of making the game fit into a command-line interface. Internally, the code converted paths into an abstract <code>Location</code> and only cared about its “distance from home” to determine things like enemy level and frequency.</p>
<p>
Since the shell wasn’t essential to it, as soon as my RPG model felt complete, I started toying with the idea of switching to a different interface. The obvious choice was a rogue-like text interface, displaying symbolic ASCII characters in the terminal.
To make that work, the main adjustments would be turning this “distance from home” into a dungeon floor level, and spawning enemies as the player moved around the floor. I was curious to experiment with procedural level generation while preserving most of the other rpg-cli design choices (basic classes, generic items, and random automatic battles).</p>
<p>
I started playing <a href="https://github.com/tmewett/BrogueCE">Brogue</a> and picked up a <a href="https://www.routledge.com/Procedural-Generation-in-Game-Design/Short-Adams/p/book/9781498799195">book on procedural generation</a> for inspiration. I scoped the project and did <a href="https://github.com/facundoolano/rpg-tui">some prototyping</a> but eventually dropped the idea, in part because I wasn’t as interested in Rust programming anymore, but mostly because I had been trying to document the development process (of both rpg-cli and this new rpg-tui project) to write a kind of book or long tutorial, which turned out to be too distracting—I was more interested in the writing than in revisiting an old project.
Some of that work made it into <a href="https://olano.dev/blog/de-von-bismarck-a-tolkien">a couple</a> <a href="https://olano.dev/blog/del-videojuego-como-puzzle">of posts</a> last year. I cannibalized the rest to write this.</p>
<h2 id="notes">
Notes
</h2>


      

      
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I quit my job and made an automatic time tracker (124 pts)]]></title>
            <link>https://taimapp.io</link>
            <guid>40977453</guid>
            <pubDate>Tue, 16 Jul 2024 15:28:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://taimapp.io">https://taimapp.io</a>, See on <a href="https://news.ycombinator.com/item?id=40977453">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>     <main><header></header>    <section><div><p><img src="https://taimapp.io/tray.png" alt="Taim logo"></p><h2 data-svelte-h="svelte-1s4m87e">Automated time tracking software<br>to save you time</h2> <p data-svelte-h="svelte-ppsrs9">Forgetting to start a timer is an issue of the past. You do your job, we keep track of it.</p> <div data-svelte-h="svelte-r1ro5t"><p><a href="#pricing">Pre-order now</a></p><p>macOS Ventura 13.1+, Win 10+* is recommended</p></div></div> <div><p><img src="https://taimapp.io/taimapp-preview.png" alt="Automatic time tracking software interface"></p>  </div> </section> <div><div id="section-one"><h2>Struggling with Tracking<br> Your Work Hours?</h2> <p>Freelancers often face the hassle of manually starting and stopping timers, leading to inaccurate time tracking and billing. 
        Missed hours and overcharges can harm your reputation and client trust.</p></div> <div> <div data-svelte-h="svelte-mv45p8"> <p>Documenting
        <span>11:30 - 13.00</span></p></div>      <div><div data-svelte-h="svelte-e0k7ia"> <p>My Project 1
        <span>09:00 - 10.00</span></p></div>  <div data-svelte-h="svelte-1v8rkjr"> <p>Mega Corp Inc.
        <span>11.30 - 13.00</span></p></div></div></div> <div id="product"><h2>Why Choose Taim?</h2> <p>You have full control over your sessions. You can either record sessions manually or automatically.
      Need to change the duration or date of a session? No problem. You can easily edit sessions to reflect the correct information.</p> </div> <div id="features"><h2>Control your sessions</h2> <p>It doesn't matter if you work on a personal project or on a client's project, you can adjust settings accordingly.</p> <div id="cards"><div><p><img src="https://taimapp.io/features/toggle-billing.png" alt="Toggle Billing"></p><div><h3>Toggle Billing</h3> <p>Select whether a session is billable &amp; paid or not, to make your invoicing process easier.</p> </div></div><div><p><img src="https://taimapp.io/features/application-flow.png" alt="Application Flow"></p><div><h3>Application Flow</h3> <p>Easily see an overview of your activity, and choose what to log.</p> </div></div><div><p><img src="https://taimapp.io/features/time-modifying.png" alt="Modify time &amp; sessions"></p><div><h3>Modify time &amp; sessions</h3> <p>Edit your session data by adding or removing time &amp; data whenever needed.</p> </div></div><div><p><img src="https://taimapp.io/features/notes.png" alt="Notes"></p><div><h3>Notes</h3> <p>Add shareable notes to your sessions &amp; projects to keep track of important details.</p> </div></div><div><p><img src="https://taimapp.io/features/ai-time-tracker.png" alt="Learns from you"></p><div><h3>Learns from you</h3> <p>More work equals bigger brains. Over time Taim can start to log sessions automatically.</p> </div></div><div><p><img src="https://taimapp.io/features/filtering.png" alt="Advanced Filtering"></p><div><h3>Advanced Filtering</h3> <p>Filter time your tracked time by date, statuses, project, tags, and more.</p> </div></div></div> </div></div> <div><h2>Resource efficient</h2> <p>Designed to consume low power, storage. Just like any native application.</p> <div data-svelte-h="svelte-1gpxnfw"><p><span>CPU USAGE: 5-15%</span>
        Other apps</p>  <svg viewBox="0 0 1653 512" fill="none" xmlns="http://www.w3.org/2000/svg"><g clip-path="url(#clip0_2222_2)"><path d="M0 332.453L12.5227 333.066C25.0455 333.679 50.0909 334.904 75.1364 338.357C100.182 341.809 125.227 347.488 150.273 326.69C175.318 305.892 200.364 258.617 225.409 258.952C250.455 259.287 275.5 307.231 300.545 344.666C325.591 382.101 350.636 409.026 375.682 424.843C400.727 440.659 425.773 445.367 450.818 452.882C475.864 460.398 500.909 470.721 525.955 468.756C551 466.791 576.045 452.538 601.091 384.897C626.136 317.256 651.182 196.226 676.227 186.558C701.273 176.889 726.318 278.582 751.364 270.579C776.409 262.576 801.455 144.879 826.5 132.177C851.545 119.475 876.591 211.769 901.636 207.823C926.682 203.877 951.727 103.691 976.773 78.7498C1001.82 53.8091 1026.86 104.114 1051.91 122.007C1076.95 139.901 1102 125.383 1127.05 141.174C1152.09 156.964 1177.14 203.064 1202.18 197.931C1227.23 192.797 1252.27 136.431 1277.32 148.65C1302.36 160.868 1327.41 241.672 1352.45 285.831C1377.5 329.99 1402.55 337.503 1427.59 316.721C1452.64 295.94 1477.68 246.863 1502.73 186.553C1527.77 126.243 1552.82 54.6998 1577.86 27.2078C1602.91 -0.284178 1627.95 16.2749 1640.48 24.5544L1653 32.8339" stroke="url(#paint0_linear_2222_2)" stroke-width="3"></path><path d="M0 452.057L13.3492 452.457C26.6984 452.856 53.3968 453.656 80.0952 454.901C106.794 456.147 133.492 457.838 160.19 454.227C186.889 450.615 213.587 441.7 240.286 442.322C266.984 442.943 293.683 453.1 320.381 461.152C347.079 469.204 373.778 475.151 400.476 478.873C427.175 482.595 453.873 484.092 480.571 486.151C507.27 488.21 533.968 490.832 560.667 490.992C587.365 491.153 614.063 488.852 640.762 475.858C667.46 462.864 694.159 439.177 720.857 437.794C747.556 436.412 774.254 457.334 800.952 456.285C827.651 455.236 854.349 432.216 881.048 430.226C907.746 428.236 934.444 447.276 961.143 447.04C987.841 446.804 1014.54 427.291 1041.24 422.85C1067.94 418.408 1094.63 429.038 1121.33 433.176C1148.03 437.314 1174.73 434.96 1201.43 438.677C1228.13 442.394 1254.83 452.181 1281.52 451.707C1308.22 451.233 1334.92 440.497 1361.62 443.499C1388.32 446.5 1415.02 463.239 1441.71 472.637C1468.41 482.036 1495.11 484.095 1521.81 480.487C1548.51 476.878 1575.21 467.602 1601.9 456.077C1628.6 444.551 1655.3 430.776 1668.65 423.888L1682 417" stroke="url(#paint1_linear_2222_2)" stroke-width="3"></path></g><defs><linearGradient id="paint0_linear_2222_2" x1="0" y1="240.5" x2="1653" y2="240.5" gradientUnits="userSpaceOnUse"><stop stop-color="#A91576" stop-opacity="0"></stop><stop offset="0.255" stop-color="#A91576"></stop><stop offset="0.765" stop-color="#870505"></stop><stop offset="1" stop-color="#870505" stop-opacity="0"></stop></linearGradient><linearGradient id="paint1_linear_2222_2" x1="0" y1="454" x2="1682" y2="454" gradientUnits="userSpaceOnUse"><stop stop-color="#18A0FB" stop-opacity="0"></stop><stop offset="0.205" stop-color="#18A0FB"></stop><stop offset="0.775" stop-color="#53023C"></stop><stop offset="1" stop-color="#53023C" stop-opacity="0"></stop></linearGradient><clipPath id="clip0_2222_2"><rect width="1653" height="512" fill="white"></rect></clipPath></defs></svg></div></div> <div id="fullcontrol"><h2>Time tracking software with full control</h2> <p>Taim is a time tracking software that works just like you want it to. Clicks and calculations that would otherwise take a lot of time are made instantly for you.</p> <div><div><p><span><span>CSV</span> Jun 9 - Jun 10 sessions</span></p></div><div><p><span><span>PDF</span> Paid sessions this week</span></p></div><div><p><span><span>XLS</span> Billable sessions last month</span></p></div></div></div> <div id="section-three"><h2>Work Smarter, Not Harder</h2> <p>Customize Taim to your needs, if you want to track time manually, you can do that. 
        If you want to track time automatically, you can do that as well.
         It is up to you to decide how you want to track your time.</p> </div>  <div><div id="pricing"><h2>Pay once, use forever</h2> <p>Taim is a one-time purchase. You get all the features in every plan.</p> <div data-svelte-h="svelte-k74s6c"><p><span>PRE-SALE IS LIVE!</span> <span>Currently Taim is available to purchase as a presale. We are planning to launch Taim to the public in early autumn (Sep-Oct), be sure to checkout our <a href="https://taimapp.io/roadmap">roadmap.</a></span></p></div> <div> <div><div><h3>Individual</h3> <p>Early-bird 56% off</p></div> <p>One-time payment for a single user.</p>   <ul role="list"><li> <svg fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clip-rule="evenodd"></path></svg> <span>Pay once, use forever</span> </li><li> <svg fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clip-rule="evenodd"></path></svg> <span>1 macOS device</span> </li><li> <svg fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clip-rule="evenodd"></path></svg> <span>All features</span> </li><li> <svg fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clip-rule="evenodd"></path></svg> <span>Free updates for 12 months</span> </li><li> <svg fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clip-rule="evenodd"></path></svg> <span>Local storage</span> </li></ul>  </div><div><p><h3>Teams</h3> </p> <p>Great for multi-devices setups &amp; teams.</p>   <ul role="list"><li> <svg fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clip-rule="evenodd"></path></svg> <span>Pay per seat for your team.</span> </li><li> <svg fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clip-rule="evenodd"></path></svg> <span>Unlimited devices</span> </li><li> <svg fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clip-rule="evenodd"></path></svg> <span>All features</span> </li><li> <svg fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clip-rule="evenodd"></path></svg> <span>App updates during the subscription</span> </li><li> <svg fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clip-rule="evenodd"></path></svg> <span>Cloud storage</span> </li></ul>  </div></div></div> <div><h2>Questions &amp; Answers</h2> <p>Get answers to your questions. For additional questions, please get in touch.</p> </div></div></main>  
			
			
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Devs need system design tools, not diagramming tools (167 pts)]]></title>
            <link>https://thenewstack.io/devs-need-system-design-tools-not-diagramming-tools/</link>
            <guid>40977308</guid>
            <pubDate>Tue, 16 Jul 2024 15:09:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thenewstack.io/devs-need-system-design-tools-not-diagramming-tools/">https://thenewstack.io/devs-need-system-design-tools-not-diagramming-tools/</a>, See on <a href="https://news.ycombinator.com/item?id=40977308">Hacker News</a></p>
Couldn't get https://thenewstack.io/devs-need-system-design-tools-not-diagramming-tools/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Codestral Mamba (416 pts)]]></title>
            <link>https://mistral.ai/news/codestral-mamba/</link>
            <guid>40977103</guid>
            <pubDate>Tue, 16 Jul 2024 14:44:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mistral.ai/news/codestral-mamba/">https://mistral.ai/news/codestral-mamba/</a>, See on <a href="https://news.ycombinator.com/item?id=40977103">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Following the publishing of the Mixtral family, Codestral Mamba is another step in our effort to study and provide new architectures. It is available for free use, modification, and distribution, and we hope it will open new perspectives in architecture research. Codestral Mamba was designed with help from Albert Gu and Tri Dao.</p><p>Unlike Transformer models, <a href="https://arxiv.org/abs/2312.00752">Mamba models</a> offer the advantage of linear time inference and the theoretical ability to model sequences of infinite length. It allows users to engage with the model extensively with quick responses, irrespective of the input length. This efficiency is especially relevant for code productivity use cases—this is why we trained this model with advanced code and reasoning capabilities, enabling it to perform on par with SOTA transformer-based models.</p><p><img src="https://mistral.ai/images/news/codestral-mamba/codestral-mamba-benchmarks.png" alt="Detailed Codestral Mamba benchmarks" width="100%"></p><p>We have tested Codestral Mamba on in-context retrieval capabilities up to 256k tokens. We expect it to be a great local code assistant!</p><p>You can deploy Codestral Mamba using the <a href="https://github.com/mistralai/mistral-inference">mistral-inference</a> SDK, which relies on the reference implementations from Mamba’s GitHub repository. The model can also be deployed through <a href="https://github.com/NVIDIA/TensorRT-LLM/tree/main/examples/mamba">TensorRT-LLM</a>. For local inference, keep an eye out for support in llama.cpp. You may download the raw weights from <a href="https://huggingface.co/mistralai/mamba-codestral-7B-v0.1">HuggingFace</a>.</p><p>For easy testing, we made Codestral Mamba available on <a href="https://console.mistral.ai/">la Plateforme</a> (<code>codestral-mamba-2407</code>), alongside its big sister, Codestral 22B. While Codestral Mamba is available under the Apache 2.0 license, Codestral 22B is available under a <a href="https://mistral.ai/contact/">commercial license</a> for self-deployment or a community license for testing purposes.</p><p><strong>Important:</strong> This is an instructed model, with 7,285,403,648 parameters.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Godotcaml for Godot 4.2 (124 pts)]]></title>
            <link>https://fizzixnerd.com/blog/2024-06-24-announcing-godotcaml/</link>
            <guid>40975509</guid>
            <pubDate>Tue, 16 Jul 2024 11:25:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fizzixnerd.com/blog/2024-06-24-announcing-godotcaml/">https://fizzixnerd.com/blog/2024-06-24-announcing-godotcaml/</a>, See on <a href="https://news.ycombinator.com/item?id=40975509">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>Hello!  Today I’m releasing a project on which I’ve been working, that is in an early stage of development, into the open source world.  It is integration and bindings to Godot (currently just 4.2) from a new language: OCaml.  It is called Godotcaml.  Details below!</p>
<h2 id="why-godot">Why Godot?</h2>
<p>There are many reasons to choose Godot, but the reason I’ll focus on is that it provides a full game-development IDE from which you can develop production quality 2D and 3D games.  It’s suitable for small-to-medium-sized teams, quite mature, and very fun to use; I think most devs have a secret inclination to “one day” make a video game.  If there is one piece of advice I could give to those devs, it’s choose a good engine that already exists, unless you want to be stuck in Vulkan hell for 6-12 months.  Godot is a good engine, and happily, already exists, and is free and open source — so is a good first choice, even if you abandon it for something different later.</p>
<h2 id="why-ocaml">Why OCaml?</h2>
<p>While my greatest loved language is Haskell, there are some specific reasons that it is somewhat unsuitable for game development.  Instead of listing those, however, I will instead take a more positive approach and talk about why OCaml is an excellent language for game development.</p>
<ul>
<li>
<p><strong>Garbage Collected by Default:</strong> This may shock game devs used to the C++ lyfe, but will come as no surprise to people who’ve used Godot and/or Unity.  Programmers are just more productive when there is a garbage collector, and programmer time is what is usually most valuable — not machine time.  Now, you can write some pretty cool allocation-free OCaml code too — but that’s an optimization that you should measure your need for before you commit to it.</p>
</li>
<li>
<p><strong>Functional by Default:</strong> I love functional programming, and I love the kind of code you can write in an ML-like curried functional language (such as OCaml or Haskell).  So <em>if</em> I were to bind Godot to a new language, it would have to be a functional one.  However, excellent bindings (<code>gdext</code>) for Rust already exist, and it can be used as a workable functional language.  That being said, Rust has the borrowchecker and an aversion to garbage collection, and put simply, I don’t think it makes a particularly good game scripting language, even though it is a wonderful systems programming language.  I think OCaml can one day prove to be a more efficient vehicle for experienced functional programmers to create a game in.  (No hate intended!  This is just how I <em>feel</em>.)</p>
</li>
<li>
<p><strong>Eager by Default:</strong> I absolutely adore lazy APIs.  I might actually be in the minority now in the Haskell community that I think that laziness was not a mistake, but was an excellent choice because of the ergonomics it provides.  However, it’s definitely true that it makes it somewhat less straight-forward to reason about the runtime performance of your code, and indeed to debug it — at least without specialized knowledge that is, in my experience, rather rare to have.  OCaml is eager by default, and I think that’s probably better for a soft-realtime system, unless you’re using some specialized framework (e.g. one that I don’t know whether exists or not!).</p>
</li>
<li>
<p><strong>Side-effects for When You Need Them:</strong> If the world was all written in one language, Haskell would make a pretty good choice — not perfect by any stretch, but pretty good.  However, we live in the real world, where a C FFI is the glue holding this pot of spaghetti we call an operating system together.  Because of that, when doing FFI heavy code, a beautiful language that makes it slightly more tedious to work with side-effects is less preferable in my experience than a language that simply encourages you to think before you use them, but still easily allows you to do things like have global mutable references at the top level.</p>
</li>
<li>
<p><strong>PPXes For CodeGen Help:</strong> I’m not totally sold on the pervasive use of PPXes for OCaml code, but one thing they are definitely useful for is code gen, and you would need a <em>lot</em> of tedious hand-written code if you wanted to interact with Godot directly by hand.  PPXes lie somewhere between Rust macros and TemplateHaskell in their power, but most problems with codegen were able to be solved to my satisfaction using the wonderful PpxLib and context-free extenders.  For example, here is the definition of a simple Godot class that inherits from the stock <code>Node</code> class, and provides a successor function for Godot <code>int</code>s:</p>
</li>
</ul>
<pre is:raw="" tabindex="0"><code><span><span>module</span><span>%</span><span>gclass </span><span>MyClass</span><span> </span><span>=</span><span> struct</span></span>
<span><span>  </span><span>[</span><span>%%</span><span>ginherits </span><span>Node]</span></span>
<span></span>
<span><span>  </span><span>let</span><span>%</span><span>gfunc </span><span>succ</span><span> </span><span>=</span><span> </span></span>
<span><span>    </span><span>[|</span><span> </span><span>ClassMethodFlags</span><span>.</span><span>default </span><span>|]</span></span>
<span><span>      (module </span><span>BuiltinClass0</span><span>.</span><span>Int</span><span>)</span></span>
<span><span>      (module </span><span>Class</span><span>.</span><span>Node</span><span>)</span></span>
<span><span>      (module </span><span>BuiltinClass0</span><span>.</span><span>Int</span><span>) </span></span>
<span><span>      (</span><span>fun</span><span> </span><span>i</span><span> </span><span>_self</span><span> </span><span>-&gt;</span><span> </span><span>Int64</span><span>.</span><span>(i </span><span>+</span><span> </span><span>1</span><span>L))</span></span>
<span><span>end</span></span></code></pre>
<p>Whether or not you like the use of PPXes in general, it is tough to argue that this code isn’t at least <em>short</em>, especially if I were to show you the amount of work you’d have to do without those <code>%</code>s!</p>
<ul>
<li><strong>More:</strong> If you’re reading this post, you probably already like OCaml already, so I’ll leave it there at “it’s a really nice pragmatic functional language, and I thought it would be a good candidate”!</li>
</ul>
<h2 id="what-can-it-do">What Can It Do?</h2>
<p>This is an extremely early stage of development, but basically at this point it is possible to:</p>
<ol>
<li>Call any builtin Godot utility function or method (static, virtual, or otherwise) from OCaml easily, and with documentation comments for the original function intact an available through your favourite OCaml LSP implementation.</li>
<li>Use Godot (binary) operators in a natural way from OCaml. (Unary operators are currently broken, which I will be investigating!)</li>
<li>Construct Godot values from OCaml easily, and from OCaml analogues if they exist (e.g. I incur a dependency on <code>Gg</code> for low-dimensional vector math)</li>
<li>Marshalling in and out of all these functions to/from the OCaml analogues.  That is, a method that is in Godot on an object of type <code>ClassyClass</code> taking an <code>int</code> parameter and returning an <code>int</code> will appear in Godotcaml as <code>int64 -&gt; ClassyClass.t structure ptr -&gt; int64</code>, where the <code>ClassyClass.t structure ptr</code> is the “pointer to the Godot object”, commonly called <code>self</code>.  (Note that this is always the <em>last</em> argument, to facilitate pipeline-style programming when GDScript programmers have a method-chaining interface.)</li>
<li>Naturally define a new Godot class in OCaml that inherits from an existing Godot-registered class.  (Currently NOT tested with classes defined in GDScript and/or externally.)</li>
<li>Most of the code-gen for custom engines that define new stock/builtin types and classes, etc.</li>
<li>Simulated inheritence for stock (and easily extendable to user-defined) classes using module inclusion:  That is if <code>Derived</code> inherits from <code>Base</code>, then simply include <code>Base</code> in the module representing <code>Derived</code>, and you get access to all the methods from <code>Base</code> without explicit casting (or in the case of Rust’s <code>gdext</code>, object composition).</li>
<li>Naturally define a new Godot method in OCaml and have it called from GDScript or another Godot-bound language. (ergonomics still WIP).</li>
</ol>
<h2 id="todo-or-what-cant-it-do">TODO (Or, What Can’t It Do):</h2>
<ol>
<li><strong>Signals:</strong> I’m still cooking ideas for how best to do this, but user-defined signals are not currently nicely supported, and even built in ones are not nice to call or interact with right now.  I’d also like them to be type-safe, so there’s that.  Very WIP, but fixable with some thought and work.</li>
<li><strong>Garbage Collection:</strong> Right now, if a OCaml reference is stored in a, say, GDScript variable, and contains no references in the OCaml world, then it might be collected out from under you.  This is fixable because of Godot’s wonderful reference-counting hooks and OCaml finalisers, I just haven’t gotten around to it yet.</li>
<li><strong>Nice Interface to Various Kinds of Methods:</strong> As of the writing of this blog post, it is only possible to define methods of arity <code>1 + Self</code> from OCaml.  No static methods, no virtual methods  This will be fixed soon, but I wanted to get the stuff in the hands of interested enthusiasts as soon as I was able to call OCaml functions from Godot.</li>
<li><strong>Real First Class Modules for Method Definitions:</strong> Taking again the example above, we can write</li>
</ol>
<pre is:raw="" tabindex="0"><code><span><span>let</span><span>%</span><span>gfunc </span><span>f</span><span> </span><span>=</span><span> </span></span>
<span><span>  </span><span>[|</span><span> </span><span>ClassMethodFlags</span><span>.</span><span>default </span><span>|]</span></span>
<span><span>  (module </span><span>ArgumentGodotTypeModule</span><span>)</span></span>
<span><span>  (module </span><span>SelfGodotTypeModule</span><span>)</span></span>
<span><span>  (module </span><span>ReturnValueGodotTypeModule</span><span>)</span></span>
<span><span>  (</span><span>fun</span><span> </span><span>x</span><span> </span><span>self</span><span> </span><span>-&gt;</span><span> </span><span>(* implementation here ...*)</span><span> </span><span>()</span><span>)</span></span></code></pre>
<p>making it seem like you could write, say</p>
<pre is:raw="" tabindex="0"><code><span><span>let</span><span> </span><span>m</span><span> </span><span>=</span><span> (module </span><span>SomeGodotTypeModule</span><span>)</span></span>
<span></span>
<span><span>let</span><span>%</span><span>gfunc </span><span>g</span><span> </span><span>=</span><span> </span><span>[|</span><span> </span><span>ClassMethodFlags</span><span>.</span><span>default </span><span>|]</span><span> m m m (</span><span>fun</span><span> </span><span>x</span><span> </span><span>y</span><span> </span><span>-&gt;</span><span> x)</span></span></code></pre>
<p>or something, but that wouldn’t work.  This is due to the way I generate code, but basically you have to consider the <code>module</code> as part of the “syntax” for <code>gfunc</code>; it directly takes the packed module out of the expression and codegens using whatever the <code>module</code> operator is applied to (i.e. at <em>parse</em> time, not <em>run</em> time).  This is pretty messed up and not ideal, but the way I justify it to myself is that <code>let%gfunc</code> introduces it’s own syntactic form for declaring a <em>type signature</em> and <em>implementation</em> of a method.  This is, as far as I can tell, <em>not fixable</em>, but I’d love to hear your thoughts if you think it is.  (Briefly, the problem is that if you try to use real first-class modules, their types escape the scope of the function because the implementation function contains them.)</p>
<ol start="5">
<li><strong>General Clean-up:</strong> This implementation was designed sort of ad-hoc and in-the-moment, so some of the stuff doesn’t quite make sense in the module architecture.  This is fixable but lower priority until I iron out the rest of the implementation details of the other features.</li>
<li><strong>Better Build System Integration:</strong> I don’t know dune very well, so I got it <em>working</em>, but it’s not exactly nice to use and develop on.  Lots of ad-hoc calls to <code>dune exec ./gen_api.exe</code> when something has changed, and then trying to remember to format with <code>ocamlformat -i *.ml</code> — that sort of thing; I’m sure dune can help with it, but I didn’t invest the time into learning properly (but I will).  Fixable.</li>
<li><strong>Hot-Reloading:</strong> This should be possible, as Rust somehow manages it in Godot 4.2+ but I haven’t even begun to look into it.  Right now, if you change an OCaml file and recompile the extension, you probably need to restart the editor to see the effects.  Fixable.</li>
<li><strong>Name-mangling for Custom Operators:</strong> I just haven’t done this, but it wouldn’t be hard (and would probably make a good first issue, if you’re looking to contribute).  Right now custom operators defined as <code>gfunc</code> methods in OCaml probably can’t be used from GDScript, or most other languages.  Perhaps at all!  I haven’t even tried.  Fixable.</li>
<li><strong>Finishing the C API:</strong> These represent a work-in-progress set of bindings that are by no means complete at the moment.  That needs to change eventually.  Fixable.</li>
<li><strong>Embedding a TopLevel:</strong> I’d like to be able to interact with the Godot world, well, interactively, from an OCaml Toplevel.  This is on my backburner, but it’s harder than it looks at first, because the shared_object you have to build must of course be native code, but Toplevel and friends are (seemingly?) only available as bytecode.  Ping me if you have ideas here! Fixability unknown!</li>
<li><strong>Reliably Not Segfault:</strong> This is an unsafe C api, and so it’s extremely sharp, and the interface is very rough around the edges, as I figure out what exactly each value is supposed to actually do.  DO NOT TRY TO MAKE A PRODUCTION GAME IN GODOTCAML RIGHT NOW!  I’m going to fix things, but they definitely aren’t ready for prime-time at the moment.  This is fixable, but will take time and testing.</li>
<li><strong>Testing:</strong> Speaking of testing, I have none.  If you’d like to contribute here, I’d be happy to hear from you; I’m personally going to prioritize other above areas until things are a little more stable in the API, so I’m not constantly changing things and fixing <em>broken tests</em> (i.e. as opposed to <em>broken code that is being tested</em>).  Fixable.</li>
<li><strong>Type Safety Concerns:</strong> Right now all classes have the same object type.  This makes it nice for when you’re inheriting from them, as module inclusion “just works”, but obviously have negative effects on the type safety of the system.  Destructive updates of the module types during inclusion is one possible solution, but this requires you to have a module type for every Godot class from which you wish to inherit — a tall order.  I believe this is fixable with some thought — and indeed, it <em>must</em> be fixed in my eyes, even if it means more code gen for the module signatures — but I haven’t given it much thought beyond that.</li>
<li><strong>Support Multiple Native Type Sizes:</strong> Godot’s api supports multiple configurations, depending on if you want float64 or float32, and 64-bit and 32-bit systems.  Right now, I’m concentrating on the float64 + 64-bit configuration, but this should be expanded at some point in the future.  Fixable.</li>
</ol>
<p>For more, check the issue page on GitHub, as that is where I’ll be doing the development.</p>
<h2 id="to-be-continued">To Be Continued</h2>
<p>More details and a setup guide to come!  If you’d like to get involved, I’d love to hear from you — best place to find me is either GitHub or the OCaml Discourse currently.  Beware, the code is pretty funky at the moment, but it’ll get there!</p>
<p>Best,</p>
<p><em>Matt</em></p>

        <p><span>#open-source</span><span>#ocaml</span><span>#godot</span><span>#godotcaml</span><span>#announcement</span>
        </p>
      </div><div>
    <p><img alt="Author Photo" width="96" height="96" src="https://fizzixnerd.com/_astro/fizzixnerd_Z1RMnIC.png" loading="eager" decoding="async">
    </p>
    <div>
      <p>
          About Matt Walker
        </p>
      <p>Matt Walker is a software engineer with a love for all things Functional, DevOps, and Typed, currently residing in Toronto, Canada.</p>
    </div>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Live Stream of VC Funded Startups – Use It for Research and Sales (503 pts)]]></title>
            <link>https://old.reddit.com/r/SaaSMarketing/comments/1e4ktjy/i_creatd_a_tool_to_track_all_live_vc_investments/</link>
            <guid>40975351</guid>
            <pubDate>Tue, 16 Jul 2024 10:59:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/SaaSMarketing/comments/1e4ktjy/i_creatd_a_tool_to_track_all_live_vc_investments/">https://old.reddit.com/r/SaaSMarketing/comments/1e4ktjy/i_creatd_a_tool_to_track_all_live_vc_investments/</a>, See on <a href="https://news.ycombinator.com/item?id=40975351">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="searchexpando"><p><label>limit my search to r/SaaSMarketing</label></p><div id="moresearchinfo"><p>use the following search parameters to narrow your results:</p><dl><dt>subreddit:<i>subreddit</i></dt><dd>find submissions in "subreddit"</dd><dt>author:<i>username</i></dt><dd>find submissions by "username"</dd><dt>site:<i>example.com</i></dt><dd>find submissions from "example.com"</dd><dt>url:<i>text</i></dt><dd>search for "text" in url</dd><dt>selftext:<i>text</i></dt><dd>search for "text" in self post contents</dd><dt>self:yes (or self:no)</dt><dd>include (or exclude) self posts</dd><dt>nsfw:yes (or nsfw:no)</dt><dd>include (or exclude) results marked as NSFW</dd></dl><p>e.g. <code>subreddit:aww site:imgur.com dog</code></p><p><a href="https://www.reddit.com/wiki/search">see the search faq for details.</a></p></div><p><a href="https://www.reddit.com/wiki/search" id="search_showmore">advanced search: by author, subreddit...</a></p></div></div>]]></description>
        </item>
    </channel>
</rss>