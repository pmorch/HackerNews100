<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 07 Oct 2023 11:00:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Cloudflare is free of CAPTCHAs; Turnstile is free for everyone (114 pts)]]></title>
            <link>https://blog.cloudflare.com/turnstile-ga/</link>
            <guid>37799413</guid>
            <pubDate>Sat, 07 Oct 2023 06:13:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.cloudflare.com/turnstile-ga/">https://blog.cloudflare.com/turnstile-ga/</a>, See on <a href="https://news.ycombinator.com/item?id=37799413">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post">
    <article>
        


        <p localize="" datetime="2023-09-29T14:00:00+01:00">Loading...</p>
        

        <ul>
            <li>
                <a href="https://blog.cloudflare.com/author/benedikt/">
                    <img src="https://blog.cloudflare.com/cdn-cgi/image/format=auto,dpr=3,width=62,height=62/http://blog.cloudflare.com/content/images/2022/04/Screenshot-2020-10-27-165713.png" alt="Benedikt Wolters" width="62" height="62">
                </a>
                
            </li>
            <li>
                <a href="https://blog.cloudflare.com/author/maxime/">
                    <img src="https://blog.cloudflare.com/cdn-cgi/image/format=auto,dpr=3,width=62,height=62/http://blog.cloudflare.com/content/images/2019/06/unnamed.jpg" alt="Maxime Guerreiro" width="62" height="62">
                </a>
                
            </li>
            <li>
                <a href="https://blog.cloudflare.com/author/adam-martinetti/">
                    <img src="https://blog.cloudflare.com/cdn-cgi/image/format=auto,dpr=3,width=62,height=62/http://blog.cloudflare.com/content/images/2022/12/_tmp_uploaded20220909-4-1lugsmy.jpg" alt="Adam Martinetti" width="62" height="62">
                </a>
                
            </li>
        </ul>

        <section>
            <p>7 min read</p>
            <div>
                <figure><img src="https://blog.cloudflare.com/content/images/2023/09/image3-37.png" alt="" loading="lazy" width="1200" height="676"></figure><p>For years, we’ve <a href="https://blog.cloudflare.com/moving-from-recaptcha-to-hcaptcha/">written</a> that CAPTCHAs drive us crazy. Humans give up on CAPTCHA puzzles <a href="https://www.math.unipd.it/~gaggi/doc/ads20.pdf">approximately 15% of the time</a> and, maddeningly,<a href="https://www.usenix.org/conference/usenixsecurity23/presentation/searles"> CAPTCHAs are significantly easier for bots</a> to solve than they are for humans. We’ve spent the past three and a half years working to build a better experience for humans that’s just as effective at stopping bots. As of this month, we’ve finished replacing every CAPTCHA issued by Cloudflare with<strong> </strong>Turnstile, our new CAPTCHA replacement (pictured below). Cloudflare will never issue another visual puzzle to anyone, for any reason.</p><figure><img src="https://blog.cloudflare.com/content/images/2023/09/image2.gif" alt="" loading="lazy" width="878" height="300"></figure><p>Now that we’ve eliminated CAPTCHAs at Cloudflare, we want to make it easy for anyone to do the same, even if they don’t use other Cloudflare services. We’ve decoupled Turnstile from our platform so that any website operator on any platform can use it just by adding <a href="https://github.com/cloudflare/turnstile-demo-workers/blob/main/src/explicit.html#L74-L85">a few lines of code</a>. We’re thrilled to announce that Turnstile is now generally available, and <strong>Turnstile’s ‘Managed’ mode is now completely free to everyone for unlimited use</strong>. </p><h3 id="easy-on-humans-hard-on-bots-private-for-everyone">Easy on humans, hard on bots, private for everyone</h3><figure><img src="https://blog.cloudflare.com/content/images/2023/09/image6-5.png" alt="" loading="lazy" width="1999" height="607"></figure><p>There’s a lot that goes into Turnstile’s simple checkbox to ensure that it’s easy for everyone, preserves user privacy, and does its job stopping bots. Part of making challenges better for everyone means that everyone gets the same great experience, no matter what browser you’re using. Because we do not employ a visual puzzle, users with low vision or blindness get the same easy to use challenge flow as everyone else. </p><p>It was particularly important for us to avoid falling back to audio CAPTCHAs to offer an experience accessible to everyone. Audio CAPTCHAs are often much worse than even visual CAPTCHAs for humans to solve, with only<a href="https://web.stanford.edu/~jurafsky/burszstein_2010_captcha.pdf"> 31.2% of audio challenges</a> resulting in a three-person agreement on what the correct solution actually is. The prevalence of free speech-to-text services has made it easy for bots to solve audio CAPTCHAs as well, with <a href="https://uncaptcha.cs.umd.edu/papers/uncaptcha_woot17.pdf">a recent study</a> showing bots can accurately solve audio CAPTCHAs in over 85% of attempts. We’re proud to state that Turnstile is WCAG 2.1 Level AA compliant, while eliminating the need for audio CAPTCHAs as well as visual ones.</p><p>We also created Turnstile to be privacy focused. Turnstile meets <a href="https://www.cloudflare.com/learning/privacy/what-is-eprivacy-directive/">ePrivacy Directive</a>, <a href="https://www.cloudflare.com/learning/privacy/what-is-the-gdpr/">GDPR</a> and <a href="https://www.cloudflare.com/learning/privacy/what-is-the-ccpa/">CCPA</a> compliance requirements, as well as the strict requirements of our own privacy commitments. In addition, Cloudflare's <a href="https://marketplace.fedramp.gov/products/FR2000863987">FedRAMP Moderate authorized package</a>, "Cloudflare for Government" now includes Turnstile. We don’t rely on tracking user data, like what other websites someone has visited, to determine if a user is a human or robot. Our business is protecting websites, not selling ads, so operators can deploy Turnstile knowing that their users’ data is safe.</p><p>With all of our emphasis on how <em>easy</em> it is to pass a Turnstile challenge, you would be right to ask how it can stop a bot. If a bot can find <a href="https://www.vox.com/22436832/captchas-getting-harder-ai-artificial-intelligence">all images with crosswalks</a> in grainy photos faster than we can, surely it can check a box as well. Bots definitely can check a box, and they can even<a href="https://arxiv.org/abs/1903.01003"> mimic the erratic path of human mouse movement</a> while doing so. For Turnstile, the actual act of checking a box isn’t important, it’s the background data we’re analyzing while the box is checked that matters. We find and stop bots by running a series of in-browser tests, checking browser characteristics, native browser APIs, and asking the browser to pass lightweight tests (ex: proof-of-work tests, proof-of-space tests) to prove that it’s an actual browser. The current deployment of Turnstile checks billions of visitors every day, and we are able to identify browser abnormalities that bots exhibit while attempting to pass those tests.</p><p>For over one year, <a href="https://blog.cloudflare.com/end-cloudflare-captcha/">we used our Managed Challenge</a> to rotate between CAPTCHAs and our own Turnstile challenge to compare our effectiveness. We found that <strong>even without asking users for any interactivity at all</strong>, Turnstile was just as effective as a CAPTCHA. Once we were sure that the results were effective at coping with the response from bot makers, we replaced the CAPTCHA challenge with our own checkbox solution. We present this extra test when we see potentially suspicious signals, and it helps us provide an even greater layer of security.</p><h3 id="turnstile-is-great-for-fighting-fraud">Turnstile is great for fighting fraud</h3><p>Like all sites that offer services for free, Cloudflare sees our fair share of automated account signups, which can include “new account fraud,” where bad actors automate the creation of many different accounts to abuse our platform. To help combat this abuse, we’ve rolled out Turnstile’s invisible mode to protect our own signup page. This month, we’ve blocked <strong>over</strong> <strong>1 million automated signup attempts </strong>using Turnstile, without a reported false positive or any change in our self-service billings that rely on this signup flow. &nbsp;</p><h3 id="lessons-from-the-turnstile-beta">Lessons from the Turnstile beta</h3><figure><img src="https://blog.cloudflare.com/content/images/2023/09/image5-11.png" alt="" loading="lazy" title="Chart" width="1200" height="742"></figure><p>Over the past twelve months, we’ve been grateful to see how many people are eager to try, then rely on, and integrate Turnstile into their web applications. It’s been rewarding to see the developer community embrace Turnstile as well. We list some of the community created Turnstile integrations <a href="https://developers.cloudflare.com/turnstile/community-resources/">here</a>, including integrations with WordPress, Angular, Vue, and a Cloudflare recommended <a href="https://www.npmjs.com/package/@marsidev/react-turnstile">React library</a>. We’ve listened to customer feedback, and added support for <a href="https://developers.cloudflare.com/turnstile/reference/supported-languages/">17 new languages</a>, <a href="https://developers.cloudflare.com/turnstile/get-started/client-side-rendering/">new callbacks</a>, and <a href="https://developers.cloudflare.com/turnstile/reference/client-side-errors/">new error codes</a>. </p><p>76,000+ users have signed up, but our biggest single test by far was the <a href="https://blog.cloudflare.com/how-cloudflare-scaled-and-protected-eurovision-2023-voting/">Eurovision final vote</a>. Turnstile runs on challenge pages on over 25 million Cloudflare websites. Usually, that makes Cloudflare the far and away biggest Turnstile consumer, until the final Eurovision vote. During that one hour, challenge traffic from the Eurovision voting site outpaced the use of challenge pages on those 25 million sites combined! Turnstile handled the enormous spike in traffic without a hitch. </p><p>While a lot went well during the Turnstile beta, we also encountered some opportunities for us to learn. We were initially resistant to disclosing why a Turnstile challenge failed. After all, if bad actors know what we’re looking for, it becomes easier for bots to fool our challenges until we introduce new detections. However, during the Turnstile beta, we saw a few scenarios where legitimate users could not pass a challenge. These scenarios made it clear to us that we need to be transparent about why a challenge failed to help aid any individual who might modify their browser in a way that causes them to get caught by Turnstile. We now publish detailed client-side error codes to surface the reason why a challenge has failed. Two scenarios came up on several occasions that we didn’t expect: </p><p>First, we saw that desktop computers at least 10 years old frequently had expired motherboard batteries, and computers with bad motherboard batteries very often keep inaccurate time. This is because without the motherboard battery, a desktop computer’s clock will stop operating when the computer is off. Turnstile checks your computer’s system time to detect when a website operator has accidentally configured a challenge page to be cached, as caching a challenge page will cause it to become impassable. Unfortunately, this same check was unintentionally catching humans who just needed to update the time. When we see this issue, we now surface a clear error message to the end user to update their system time. We’d prefer to never have to surface an error in the first place, so we’re working to develop new ways to check for cached content that won’t impact real people. </p><p>Second, we find that a few privacy-focused users often ask their browsers to go beyond standard practices to preserve their anonymity. This includes changing their user-agent (something bots will do to evade detection as well), and preventing third-party scripts from executing entirely. Issues caused by this behavior can now be displayed clearly in a Turnstile widget, so those users can immediately understand the issue and make a conscientious choice about whether they want to allow their browser to pass a challenge.</p><p>Although we have some of the most sensitive, thoroughly built monitoring systems at Cloudflare, we did not catch either of these issues on our own. We needed to talk to users affected by the issue to help us understand what the problem was. Going forward, we want to make sure we always have that direct line of communication open. We’re rolling out a new feedback form in the Turnstile widget, to ensure any future corner cases are addressed quickly and with urgency.</p><figure><img src="https://blog.cloudflare.com/content/images/2023/09/Screenshot-2023-09-29-at-11.37.58.png" alt="" loading="lazy" width="1608" height="464"></figure><h3 id="turnstile-ga-and-free-for-everyone">Turnstile: GA and Free for Everyone </h3><p>Announcing Turnstile’s General Availability means that Turnstile is now completely production ready, available for free for unlimited use via our visible widget in Managed mode. Turnstile Enterprise includes SaaS platform support and a visible mode without the Cloudflare logo. Self-serve customers can expect a pay-as-you-go option for advanced features to be available in early 2024. Users can continue to access Turnstile’s advanced features below our 1 million siteverify request limit, as has been the case during the beta. If you’ve been waiting to try Turnstile, head over to our <a href="https://www.cloudflare.com/products/turnstile/">signup page</a> and create an account!</p>
            </div>
        </section>
    
        









    <div>
            <p>We protect
                <a target="_blank" href="https://www.cloudflare.com/network-services/">entire corporate networks</a>,
                    help customers build
                    <a target="_blank" href="https://workers.cloudflare.com/">Internet-scale applications efficiently</a>,
                    accelerate any
                    <a target="_blank" href="https://www.cloudflare.com/performance/accelerate-internet-applications/">website
                    or Internet application</a>,
                    <a target="_blank" href="https://www.cloudflare.com/ddos/">ward off DDoS
                    attacks</a>, keep
                    <a target="_blank" href="https://www.cloudflare.com/application-security/">hackers at
                    bay</a>,
                    and can help you on
                    <a target="_blank" href="https://www.cloudflare.com/products/zero-trust/">your journey to Zero Trust</a>.</p>
            <p>Visit <a target="_blank" href="https://1.1.1.1/">1.1.1.1</a> from any device to get started with
                our free app that makes your Internet faster and safer.</p>
            <p>To learn more about our mission to help build a better Internet, <a target="_blank" href="https://www.cloudflare.com/learning/what-is-cloudflare/">start here</a>. If you're looking for a
                new career direction, check out <a target="_blank" href="https://cloudflare.com/careers">our open
                    positions</a>.</p>
        </div>

        

        
        

        <a href="https://blog.cloudflare.com/tag/birthday-week/">Birthday Week</a>
        <a href="https://blog.cloudflare.com/tag/product-news/">Product News</a>
        <a href="https://blog.cloudflare.com/tag/turnstile/">Turnstile</a>
        <a href="https://blog.cloudflare.com/tag/captcha/">CAPTCHA</a>
        <a href="https://blog.cloudflare.com/tag/speed-and-reliability/">Speed &amp; Reliability</a>
    </article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Documented source code for Elite on the NES (114 pts)]]></title>
            <link>https://github.com/markmoxon/nes-elite-beebasm</link>
            <guid>37798914</guid>
            <pubDate>Sat, 07 Oct 2023 04:03:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/markmoxon/nes-elite-beebasm">https://github.com/markmoxon/nes-elite-beebasm</a>, See on <a href="https://news.ycombinator.com/item?id=37798914">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" id="user-content-fully-documented-source-code-for-elite-on-the-nes" dir="auto"><a href="#fully-documented-source-code-for-elite-on-the-nes">Fully documented source code for Elite on the NES</a></h2>
<p dir="auto"><a href="https://github.com/markmoxon/cassette-elite-beebasm">BBC Micro (cassette)</a> | <a href="https://github.com/markmoxon/disc-elite-beebasm">BBC Micro (disc)</a> | <a href="https://github.com/markmoxon/6502sp-elite-beebasm">6502 Second Processor</a> | <a href="https://github.com/markmoxon/master-elite-beebasm">BBC Master</a> | <a href="https://github.com/markmoxon/electron-elite-beebasm">Acorn Electron</a> | <a href="https://github.com/markmoxon/elite-a-beebasm">Elite-A</a> | <strong>NES</strong></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/94fa2714bfdbcffcfc5c917f6f2751344020c5f2cc4f0582fdbc87117dfce6f1/68747470733a2f2f7777772e626263656c6974652e636f6d2f696d616765732f6769746875622f6e65732d73746174696f6e2e706e67"><img src="https://camo.githubusercontent.com/94fa2714bfdbcffcfc5c917f6f2751344020c5f2cc4f0582fdbc87117dfce6f1/68747470733a2f2f7777772e626263656c6974652e636f6d2f696d616765732f6769746875622f6e65732d73746174696f6e2e706e67" alt="Screenshot of Elite on the NES" data-canonical-src="https://www.bbcelite.com/images/github/nes-station.png"></a></p>
<p dir="auto">This repository contains source code for Elite on the Nintendo Entertainment System (NES), with every single line documented and (for the most part) explained.</p>
<p dir="auto">It is a companion to the <a href="https://www.bbcelite.com/" rel="nofollow">bbcelite.com website</a>.</p>
<p dir="auto">See the <a href="#introduction">introduction</a> for more information, or jump straight into the <a href="https://github.com/markmoxon/nes-elite-beebasm/blob/main/1-source-files/main-sources">documented source code</a>.</p>
<h2 tabindex="-1" id="user-content-contents" dir="auto"><a href="#contents">Contents</a></h2>
<ul dir="auto">
<li>
<p dir="auto"><a href="#introduction">Introduction</a></p>
</li>
<li>
<p dir="auto"><a href="#acknowledgements">Acknowledgements</a></p>
<ul dir="auto">
<li><a href="#user-content-a-note-on-licences-copyright-etc">A note on licences, copyright etc.</a></li>
</ul>
</li>
<li>
<p dir="auto"><a href="#browsing-the-source-in-an-ide">Browsing the source in an IDE</a></p>
</li>
<li>
<p dir="auto"><a href="#folder-structure">Folder structure</a></p>
</li>
<li>
<p dir="auto"><a href="#building-elite-from-the-source">Building Elite from the source</a></p>
<ul dir="auto">
<li><a href="#requirements">Requirements</a></li>
<li><a href="#build-targets">Build targets</a></li>
<li><a href="#windows">Windows</a></li>
<li><a href="#mac-and-linux">Mac and Linux</a></li>
<li><a href="#verifying-the-output">Verifying the output</a></li>
<li><a href="#log-files">Log files</a></li>
</ul>
</li>
<li>
<p dir="auto"><a href="#building-different-variants-of-nes-elite">Building different variants of NES Elite</a></p>
<ul dir="auto">
<li><a href="#building-the-ntsc-release">Building the NTSC release</a></li>
<li><a href="#building-the-pal-release">Building the PAL release</a></li>
<li><a href="#differences-between-the-variants">Differences between the variants</a></li>
</ul>
</li>
</ul>
<h2 tabindex="-1" id="user-content-introduction" dir="auto"><a href="#introduction">Introduction</a></h2>
<p dir="auto">This repository contains source code for Elite on the NES, with every single line documented and (for the most part) explained.</p>
<p dir="auto">You can build the fully functioning game from this source. <a href="#building-different-variants-of-nes-elite">Two variants</a> are currently supported: the NTSC version from Ian Bell's personal website, and the Imagineer PAL release.</p>

<ul dir="auto">
<li>
<p dir="auto">If you want to explore the source code, then the <a href="https://github.com/markmoxon/nes-elite-beebasm/blob/main/1-source-files/main-sources">annotated source</a> is what you're looking for. You might also like to read the section on <a href="#browsing-the-source-in-an-ide">Browsing the source in an IDE</a> for some tips.</p>
</li>
<li>
<p dir="auto">If you want to build Elite from the source on a modern computer, to produce a working ROM image that can be loaded into a real NES or an emulator, then you want the section on <a href="#building-elite-from-the-source">Building Elite from the source</a>.</p>
</li>
</ul>
<p dir="auto">My hope is that this repository and the <a href="https://www.bbcelite.com/" rel="nofollow">accompanying website</a> will be useful for those who want to learn more about Elite and what makes it tick. It is provided on an educational and non-profit basis, with the aim of helping people appreciate one of the most iconic games of the 8-bit era.</p>
<h2 tabindex="-1" id="user-content-acknowledgements" dir="auto"><a href="#acknowledgements">Acknowledgements</a></h2>
<p dir="auto">NES Elite was written by Ian Bell and David Braben and is copyright © D. Braben and I. Bell 1991/1992.</p>
<p dir="auto">The code on this site has been reconstructed from a disassembly of the version released on <a href="http://www.elitehomepage.org/" rel="nofollow">Ian Bell's personal website</a>.</p>
<p dir="auto">The commentary is copyright © Mark Moxon. Any misunderstandings or mistakes in the documentation are entirely my fault.</p>
<p dir="auto">Huge thanks are due to the original authors for not only creating such an important piece of my childhood, but also for releasing the source code for us to play with; to Paul Brink for his annotated disassembly; and to Kieran Connell for his <a href="https://github.com/kieranhj/elite-beebasm">BeebAsm version</a>, which I forked as the original basis for this project. You can find more information about this project in the <a href="https://www.bbcelite.com/about_site/about_this_project.html" rel="nofollow">accompanying website's project page</a>.</p>
<p dir="auto">The following archive from Ian Bell's personal website forms the basis for this project:</p>
<ul dir="auto">
<li><a href="http://www.elitehomepage.org/archive/a/b7120500.zip" rel="nofollow">NES Elite, NTSC version</a></li>
</ul>
<h3 tabindex="-1" id="user-content-a-note-on-licences-copyright-etc" dir="auto"><a href="#a-note-on-licences-copyright-etc">A note on licences, copyright etc.</a></h3>
<p dir="auto">This repository is <em>not</em> provided with a licence, and there is intentionally no <code>LICENSE</code> file provided.</p>
<p dir="auto">According to <a href="https://docs.github.com/en/free-pro-team@latest/github/creating-cloning-and-archiving-repositories/licensing-a-repository">GitHub's licensing documentation</a>, this means that "the default copyright laws apply, meaning that you retain all rights to your source code and no one may reproduce, distribute, or create derivative works from your work".</p>
<p dir="auto">The reason for this is that my commentary is intertwined with the original Elite source code, and the original source code is copyright. The whole site is therefore covered by default copyright law, to ensure that this copyright is respected.</p>
<p dir="auto">Under GitHub's rules, you have the right to read and fork this repository... but that's it. No other use is permitted, I'm afraid.</p>
<p dir="auto">My hope is that the educational and non-profit intentions of this repository will enable it to stay hosted and available, but the original copyright holders do have the right to ask for it to be taken down, in which case I will comply without hesitation. I do hope, though, that along with the various other disassemblies and commentaries of this source, it will remain viable.</p>
<h2 tabindex="-1" id="user-content-browsing-the-source-in-an-ide" dir="auto"><a href="#browsing-the-source-in-an-ide">Browsing the source in an IDE</a></h2>
<p dir="auto">If you want to browse the source in an IDE, you might find the following useful.</p>
<ul dir="auto">
<li>
<p dir="auto">The main game's source code is split across eight different ROM banks, which you can find in the <a href="https://github.com/markmoxon/nes-elite-beebasm/blob/main/1-source-files/main-sources">main-sources</a> folder. This is the motherlode and probably contains all the stuff you're interested in.</p>
</li>
<li>
<p dir="auto">It's probably worth skimming through the <a href="https://www.bbcelite.com/about_site/terminology_used_in_this_commentary.html" rel="nofollow">notes on terminology and notations</a> on the accompanying website, as this explains a number of terms used in the commentary, without which it might be a bit tricky to follow at times (in particular, you should understand the terminology I use for multi-byte numbers).</p>
</li>
<li>
<p dir="auto">The accompanying website contains <a href="https://www.bbcelite.com/deep_dives/" rel="nofollow">a number of "deep dive" articles</a>, each of which goes into an aspect of the game in detail. Routines that are explained further in these articles are tagged with the label <code>Deep dive:</code> and the relevant article name.</p>
</li>
<li>
<p dir="auto">There are loads of routines and variables in Elite - literally hundreds. You can find them in the source files by searching for the following: <code>Type: Subroutine</code>, <code>Type: Variable</code>, <code>Type: Workspace</code> and <code>Type: Macro</code>.</p>
</li>
<li>
<p dir="auto">If you know the name of a routine, you can find it by searching for <code>Name: &lt;name&gt;</code>, as in <code>Name: SCAN</code> (for the 3D scanner routine) or <code>Name: LL9</code> (for the ship-drawing routine).</p>
</li>
<li>
<p dir="auto">The entry point for the main game code is the <code>BEGIN</code> routine in <a href="https://github.com/markmoxon/nes-elite-beebasm/blob/main/1-source-files/main-sources/elite-source-bank-7.asm">bank 7</a>, which you can find by searching for <code>Name: BEGIN</code>. If you want to follow the program flow all the way from the title screen around the main game loop, then you can find a number of <a href="https://www.bbcelite.com/deep_dives/" rel="nofollow">deep dives on program flow</a> on the accompanying website.</p>
</li>
<li>
<p dir="auto">The source code is designed to be read at an 80-column width and with a monospaced font, just like in the good old days.</p>
</li>
</ul>
<p dir="auto">I hope you enjoy exploring the inner workings of NES Elite as much as I have.</p>
<h2 tabindex="-1" id="user-content-folder-structure" dir="auto"><a href="#folder-structure">Folder structure</a></h2>
<p dir="auto">There are five main folders in this repository, which reflect the order of the build process.</p>
<ul dir="auto">
<li>
<p dir="auto"><a href="https://github.com/markmoxon/nes-elite-beebasm/blob/main/1-source-files">1-source-files</a> contains all the different source files, such as the main assembler source files, image binaries, fonts and so on.</p>
</li>
<li>
<p dir="auto"><a href="https://github.com/markmoxon/nes-elite-beebasm/blob/main/2-build-files">2-build-files</a> contains build-related scripts, such as the crc32 verification scripts.</p>
</li>
<li>
<p dir="auto"><a href="https://github.com/markmoxon/nes-elite-beebasm/blob/main/3-assembled-output">3-assembled-output</a> contains the output from the assembly process, when the source files are assembled and the results processed by the build files.</p>
</li>
<li>
<p dir="auto"><a href="https://github.com/markmoxon/nes-elite-beebasm/blob/main/4-reference-binaries">4-reference-binaries</a> contains the correct binaries for each variant, so we can verify that our assembled output matches the reference.</p>
</li>
<li>
<p dir="auto"><a href="https://github.com/markmoxon/nes-elite-beebasm/blob/main/5-compiled-game-discs">5-compiled-game-discs</a> contains the final output of the build process: an iNES ROM image that contains the compiled game and which can be run on real hardware or in an emulator.</p>
</li>
</ul>
<h2 tabindex="-1" id="user-content-building-elite-from-the-source" dir="auto"><a href="#building-elite-from-the-source">Building Elite from the source</a></h2>
<h3 tabindex="-1" id="user-content-requirements" dir="auto"><a href="#requirements">Requirements</a></h3>
<p dir="auto">You will need the following to build Elite from the source:</p>
<ul dir="auto">
<li>
<p dir="auto">BeebAsm, which can be downloaded from the <a href="https://github.com/stardot/beebasm">BeebAsm repository</a>. Mac and Linux users will have to build their own executable with <code>make code</code>, while Windows users can just download the <code>beebasm.exe</code> file.</p>
</li>
<li>
<p dir="auto">Python. Both versions 2.7 and 3.x should work.</p>
</li>
<li>
<p dir="auto">Mac and Linux users may need to install <code>make</code> if it isn't already present (for Windows users, <code>make.exe</code> is included in this repository).</p>
</li>
</ul>
<p dir="auto">For details of how the build process works, see the <a href="https://www.bbcelite.com/about_site/building_elite.html" rel="nofollow">build documentation on bbcelite.com</a>.</p>
<p dir="auto">Let's look at how to build Elite from the source.</p>
<h3 tabindex="-1" id="user-content-build-targets" dir="auto"><a href="#build-targets">Build targets</a></h3>
<p dir="auto">There are two main build targets available. They are:</p>
<ul dir="auto">
<li><code>build</code> - A version with a maxed-out commander</li>
<li><code>encrypt</code> - A version that exactly matches the released version of the game</li>
</ul>
<p dir="auto">Unlike the Acornsoft versions of Elite on which it is based, the NES version is not encrypted, so there is no difference in encryption between the two targets. I have used the same target names for consistency, but the only difference is in the commander file.</p>
<p dir="auto">Builds are supported for both Windows and Mac/Linux systems. In all cases the build process is defined in the <code>Makefile</code> provided.</p>
<h3 tabindex="-1" id="user-content-windows" dir="auto"><a href="#windows">Windows</a></h3>
<p dir="auto">For Windows users, there is a batch file called <code>make.bat</code> to which you can pass one of the build targets above. Before this will work, you should edit the batch file and change the values of the <code>BEEBASM</code> and <code>PYTHON</code> variables to point to the locations of your <code>beebasm.exe</code> and <code>python.exe</code> executables. You also need to change directory to the repository folder (i.e. the same folder as <code>make.bat</code>).</p>
<p dir="auto">All being well, doing one of the following:</p>


<p dir="auto">will produce a file called <code>elite-ntsc.NES</code> in the <code>5-compiled-game-discs</code> folder that contains the NTSC release, which you can then load into an emulator, or into a real NES using a flash cart.</p>
<h3 tabindex="-1" id="user-content-mac-and-linux" dir="auto"><a href="#mac-and-linux">Mac and Linux</a></h3>
<p dir="auto">The build process uses a standard GNU <code>Makefile</code>, so you just need to install <code>make</code> if your system doesn't already have it. If BeebAsm or Python are not on your path, then you can either fix this, or you can edit the <code>Makefile</code> and change the <code>BEEBASM</code> and <code>PYTHON</code> variables in the first two lines to point to their locations. You also need to change directory to the repository folder (i.e. the same folder as <code>Makefile</code>).</p>
<p dir="auto">All being well, doing one of the following:</p>


<p dir="auto">will produce a file called <code>elite-ntsc.NES</code> in the <code>5-compiled-game-discs</code> folder that contains the NTSC release, which you can then load into an emulator, or into a real NES using a flash cart.</p>
<h3 tabindex="-1" id="user-content-verifying-the-output" dir="auto"><a href="#verifying-the-output">Verifying the output</a></h3>
<p dir="auto">The build process also supports a verification target that prints out checksums of all the generated files, along with the checksums of the files from the original sources.</p>
<p dir="auto">You can run this verification step on its own, or you can run it once a build has finished. To run it on its own, use the following command on Windows:</p>

<p dir="auto">or on Mac/Linux:</p>

<p dir="auto">To run a build and then verify the results, you can add two targets, like this on Windows:</p>

<p dir="auto">or this on Mac/Linux:</p>

<p dir="auto">The Python script <code>crc32.py</code> in the <code>2-build-files</code> folder does the actual verification, and shows the checksums and file sizes of both sets of files, alongside each other, and with a Match column that flags any discrepancies. If you are building an unencrypted set of files then there will be lots of differences, while the encrypted files should mostly match (see the Differences section below for more on this).</p>
<p dir="auto">The binaries in the <code>4-reference-binaries</code> folder are those extracted from the released version of the game, while those in the <code>3-assembled-output</code> folder are produced by the build process. For example, if you don't make any changes to the code and build the project with <code>make encrypt verify</code>, then this is the output of the verification process:</p>
<div data-snippet-clipboard-copy-content="Results for variant: pal
[--originals--]  [---output----]
Checksum    Size  Checksum    Size  Match  Filename
-----------------------------------------------------
6a32bd20   16384  6a32bd20   16384   Yes   bank0.bin
1840f774   16384  1840f774   16384   Yes   bank1.bin
e08fa78a   16384  e08fa78a   16384   Yes   bank2.bin
e07c0f21   16384  e07c0f21   16384   Yes   bank3.bin
731cd900   16384  731cd900   16384   Yes   bank4.bin
fee7480c   16384  fee7480c   16384   Yes   bank5.bin
500f28cd   16384  500f28cd   16384   Yes   bank6.bin
8e1162f8   16384  8e1162f8   16384   Yes   bank7.bin
4cf12d39  131088  4cf12d39  131088   Yes   elite.bin
eb5e8763      16  eb5e8763      16   Yes   header.bin"><pre><code>Results for variant: pal
[--originals--]  [---output----]
Checksum    Size  Checksum    Size  Match  Filename
-----------------------------------------------------
6a32bd20   16384  6a32bd20   16384   Yes   bank0.bin
1840f774   16384  1840f774   16384   Yes   bank1.bin
e08fa78a   16384  e08fa78a   16384   Yes   bank2.bin
e07c0f21   16384  e07c0f21   16384   Yes   bank3.bin
731cd900   16384  731cd900   16384   Yes   bank4.bin
fee7480c   16384  fee7480c   16384   Yes   bank5.bin
500f28cd   16384  500f28cd   16384   Yes   bank6.bin
8e1162f8   16384  8e1162f8   16384   Yes   bank7.bin
4cf12d39  131088  4cf12d39  131088   Yes   elite.bin
eb5e8763      16  eb5e8763      16   Yes   header.bin
</code></pre></div>
<p dir="auto">All the compiled binaries match the originals, so we know we are producing the same final game as the release version.</p>
<h3 tabindex="-1" id="user-content-log-files" dir="auto"><a href="#log-files">Log files</a></h3>
<p dir="auto">During compilation, details of every step are output in nine files called <code>compile.txt</code> (for the header) or <code>compile0.txt</code> through <code>compile7.txt</code> (for banks 0 to 7) in the <code>3-assembled-output</code> folder. If you have problems, these might come in handy, and they're a great reference if you need to know the addresses of labels and variables for debugging (or just snooping around).</p>
<h2 tabindex="-1" id="user-content-building-different-variants-of-nes-elite" dir="auto"><a href="#building-different-variants-of-nes-elite">Building different variants of NES Elite</a></h2>
<p dir="auto">This repository contains the source code for two different variants of NES Elite:</p>
<ul dir="auto">
<li>
<p dir="auto">The NTSC version from Ian Bell's personal website</p>
</li>
<li>
<p dir="auto">The Imagineer PAL release, which is the only official release of NES Elite</p>
</li>
</ul>
<p dir="auto">By default the build process builds the NTSC release, but you can build a specified variant using the <code>variant=</code> build parameter.</p>
<h3 tabindex="-1" id="user-content-building-the-ntsc-release" dir="auto"><a href="#building-the-ntsc-release">Building the NTSC release</a></h3>
<p dir="auto">You can add <code>variant=ntsc</code> to produce the <code>elite-ntsc.NES</code> file that contains the NTSC release, though that's the default value so it isn't necessary. In other words, you can build it like this:</p>
<div data-snippet-clipboard-copy-content="make.bat encrypt verify variant=ntsc"><pre><code>make.bat encrypt verify variant=ntsc
</code></pre></div>
<p dir="auto">or this on a Mac or Linux:</p>
<div data-snippet-clipboard-copy-content="make encrypt verify variant=ntsc"><pre><code>make encrypt verify variant=ntsc
</code></pre></div>
<p dir="auto">This will produce a file called <code>elite-ntsc.NES</code> in the <code>5-compiled-game-discs</code> folder that contains the NTSC release.</p>
<p dir="auto">The verification checksums for this version are as follows:</p>
<div data-snippet-clipboard-copy-content="Results for variant: ntsc
[--originals--]  [---output----]
Checksum    Size  Checksum    Size  Match  Filename
-----------------------------------------------------
0560a52b   16384  0560a52b   16384   Yes   bank0.bin
c1239b33   16384  c1239b33   16384   Yes   bank1.bin
5e6c3bfb   16384  5e6c3bfb   16384   Yes   bank2.bin
54df916d   16384  54df916d   16384   Yes   bank3.bin
5953c5d4   16384  5953c5d4   16384   Yes   bank4.bin
0dd49e0c   16384  0dd49e0c   16384   Yes   bank5.bin
39255d4f   16384  39255d4f   16384   Yes   bank6.bin
26f0c7de   16384  26f0c7de   16384   Yes   bank7.bin
54386491  131088  54386491  131088   Yes   elite.bin
eb5e8763      16  eb5e8763      16   Yes   header.bin"><pre><code>Results for variant: ntsc
[--originals--]  [---output----]
Checksum    Size  Checksum    Size  Match  Filename
-----------------------------------------------------
0560a52b   16384  0560a52b   16384   Yes   bank0.bin
c1239b33   16384  c1239b33   16384   Yes   bank1.bin
5e6c3bfb   16384  5e6c3bfb   16384   Yes   bank2.bin
54df916d   16384  54df916d   16384   Yes   bank3.bin
5953c5d4   16384  5953c5d4   16384   Yes   bank4.bin
0dd49e0c   16384  0dd49e0c   16384   Yes   bank5.bin
39255d4f   16384  39255d4f   16384   Yes   bank6.bin
26f0c7de   16384  26f0c7de   16384   Yes   bank7.bin
54386491  131088  54386491  131088   Yes   elite.bin
eb5e8763      16  eb5e8763      16   Yes   header.bin
</code></pre></div>
<h3 tabindex="-1" id="user-content-building-the-pal-release" dir="auto"><a href="#building-the-pal-release">Building the PAL release</a></h3>
<p dir="auto">You can build the PAL release by appending <code>variant=ntsc</code> to the <code>make</code> command, like this on Windows:</p>
<div data-snippet-clipboard-copy-content="make.bat encrypt verify variant=pal"><pre><code>make.bat encrypt verify variant=pal
</code></pre></div>
<p dir="auto">or this on a Mac or Linux:</p>
<div data-snippet-clipboard-copy-content="make encrypt verify variant=pal"><pre><code>make encrypt verify variant=pal
</code></pre></div>
<p dir="auto">This will produce a file called <code>elite-pal.NES</code> in the <code>5-compiled-game-discs</code> folder that contains the PAL release.</p>
<p dir="auto">The verification checksums for this version are as follows:</p>
<div data-snippet-clipboard-copy-content="Results for variant: pal
[--originals--]  [---output----]
Checksum    Size  Checksum    Size  Match  Filename
-----------------------------------------------------
6a32bd20   16384  6a32bd20   16384   Yes   bank0.bin
1840f774   16384  1840f774   16384   Yes   bank1.bin
e08fa78a   16384  e08fa78a   16384   Yes   bank2.bin
e07c0f21   16384  e07c0f21   16384   Yes   bank3.bin
731cd900   16384  731cd900   16384   Yes   bank4.bin
fee7480c   16384  fee7480c   16384   Yes   bank5.bin
500f28cd   16384  500f28cd   16384   Yes   bank6.bin
8e1162f8   16384  8e1162f8   16384   Yes   bank7.bin
4cf12d39  131088  4cf12d39  131088   Yes   elite.bin
eb5e8763      16  eb5e8763      16   Yes   header.bin"><pre><code>Results for variant: pal
[--originals--]  [---output----]
Checksum    Size  Checksum    Size  Match  Filename
-----------------------------------------------------
6a32bd20   16384  6a32bd20   16384   Yes   bank0.bin
1840f774   16384  1840f774   16384   Yes   bank1.bin
e08fa78a   16384  e08fa78a   16384   Yes   bank2.bin
e07c0f21   16384  e07c0f21   16384   Yes   bank3.bin
731cd900   16384  731cd900   16384   Yes   bank4.bin
fee7480c   16384  fee7480c   16384   Yes   bank5.bin
500f28cd   16384  500f28cd   16384   Yes   bank6.bin
8e1162f8   16384  8e1162f8   16384   Yes   bank7.bin
4cf12d39  131088  4cf12d39  131088   Yes   elite.bin
eb5e8763      16  eb5e8763      16   Yes   header.bin
</code></pre></div>
<h3 tabindex="-1" id="user-content-differences-between-the-variants" dir="auto"><a href="#differences-between-the-variants">Differences between the variants</a></h3>
<p dir="auto">You can see the differences between the variants by searching the source code for <code>_PAL</code> (for features in the PAL release) or <code>_NTSC</code> (for features in the NTSC release). The main differences in the NTSC release compared to the PAL release are:</p>
<ul dir="auto">
<li>
<p dir="auto">The two versions count a different number of cycles in the NMI handler (7433 in the PAL version, 6797 in the NTSC version).</p>
</li>
<li>
<p dir="auto">The NTSC version is missing the Imagineer and Nintendo headings from the Start screen.</p>
</li>
<li>
<p dir="auto">The PAL version waits for longer before starting auto-play on the combat demo.</p>
</li>
<li>
<p dir="auto">Each version has its own unique checksum algorithm for the save slots.</p>
</li>
<li>
<p dir="auto">The internal version number is different (the PAL version is "&lt;2.8&gt;" while the NTSC version is "5.0")</p>
</li>
<li>
<p dir="auto">The copyright message hidden in bank 3 is different (the PAL message is "NES ELITE IMAGE 2.8 - 04 MAR 1992" while the NTSC message is "NES ELITE IMAGE 5.2 - 24 APR 1992"</p>
</li>
<li>
<p dir="auto">The first title in the combat demo scroll text is different (the PAL title is "IMAGINEER PRESENTS --- E L I T E --- (C)BRABEN &amp; BELL 1991" while the NTSC title is "NTSC EMULATION --- E L I T E ---  (C)BELL &amp; BRABEN 1991")</p>
</li>
<li>
<p dir="auto">A number of pixel y-coordinate constants in the PAL version are six pixels bigger than in the NTSC version, to cater for the taller screen height.</p>
</li>
<li>
<p dir="auto">The interrupt vectors in banks 0 to 6 that are used during initialisation are subtly different.</p>
</li>
<li>
<p dir="auto">The code for detecting double-taps of the B button when choosing buttons from the icon bar is a bit simpler in the NTSC version.</p>
</li>
</ul>
<p dir="auto">It's worth noting that the NTSC variant doesn't actually work on an NTSC machine. The NMI timings have been changed to work with some (but not all) emulators in NTSC mode, but it isn't a full NTSC conversion, it's an NTSC emulation (as per the scroll text).</p>

<hr>
<p dir="auto">Right on, Commanders!</p>
<p dir="auto"><em>Mark Moxon</em></p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[RISC-V chip technology emerges as new battleground in US-China tech war (122 pts)]]></title>
            <link>https://www.reuters.com/technology/us-china-tech-war-risc-v-chip-technology-emerges-new-battleground-2023-10-06/</link>
            <guid>37798178</guid>
            <pubDate>Sat, 07 Oct 2023 01:09:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/technology/us-china-tech-war-risc-v-chip-technology-emerges-new-battleground-2023-10-06/">https://www.reuters.com/technology/us-china-tech-war-risc-v-chip-technology-emerges-new-battleground-2023-10-06/</a>, See on <a href="https://news.ycombinator.com/item?id=37798178">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p data-testid="paragraph-0">Oct 6 (Reuters) - In a new front in the U.S.-China tech war, President Joe Biden's administration is facing pressure from some lawmakers to restrict American companies from working on a freely available chip technology widely used in China - a move that could upend how the global technology industry collaborates across borders.</p><p data-testid="paragraph-1">At issue is RISC-V, pronounced "risk five," an open-source technology that competes with costly proprietary technology from British semiconductor and software design company Arm Holdings <a data-testid="Link" href="https://www.reuters.com/markets/companies/O9Ty.F" target="_blank" referrerpolicy="no-referrer-when-downgrade">(O9Ty.F)</a>. RISC-V can be used as a key ingredient for anything from a smartphone chip to advanced processors for artificial intelligence.</p><p data-testid="paragraph-2">Some lawmakers - including two Republican House of Representatives committee chairmen, Republican Senator Marco Rubio and Democratic Senator Mark Warner - are urging Biden's administration to take action regarding RISC-V, citing national security grounds.</p><p data-testid="paragraph-3">The lawmakers expressed concerns that Beijing is exploiting a culture of open collaboration among American companies to advance its own semiconductor industry, which could erode the current U.S. lead in the chip field and help China modernize its military. Their comments represent the first major effort to put constraints on work by U.S. companies on RISC-V.</p><p data-testid="paragraph-4">Representative Mike Gallagher, chairman of the House select committee on China, said in a statement to Reuters that the Commerce Department needs to "require any American person or company to receive an export license prior to engaging with PRC (People's Republic of China) entities on RISC-V technology."</p><p data-testid="paragraph-5">Such calls to regulate RISC-V are the latest in the U.S.-China battle over chip technology that escalated last year with sweeping export restrictions that the Biden administration <a data-testid="Link" href="https://www.reuters.com/technology/us-warned-china-expect-updated-export-curbs-october-us-official-2023-10-02/" referrerpolicy="no-referrer-when-downgrade">has told China</a> it will update this month.</p><p data-testid="paragraph-6">"The CCP (Chinese Communist Party) is abusing RISC-V to get around U.S. dominance of the intellectual property needed to design chips. U.S. persons should not be supporting a PRC tech transfer strategy that serves to degrade U.S. export control laws," Representative Michael McCaul, chairman of the House Foreign Affairs Committee, said in a statement to Reuters.</p><p data-testid="paragraph-7">McCaul said he wants action from the Bureau of Industry and Security, the part of the Commerce Department that oversees export-control regulations, and would pursue legislation if that does not materialize.</p><p data-testid="paragraph-8">The bureau "is constantly reviewing the technology landscape and threat environment, and continually assessing how best to apply our export control policies to protect national security and safeguard core technologies," a Commerce Department spokesperson said in a statement.</p><p data-testid="paragraph-9">"Communist China is developing open-source chip architecture to dodge our sanctions and grow its chip industry," Rubio said in a statement to Reuters. "If we don't broaden our export controls to include this threat, China will one day surpass us as the global leader in chip design."</p><p data-testid="paragraph-10">"I fear that our export-control laws are not equipped to deal with the challenge of open-source software - whether in advanced semiconductor designs like RISC-V or in the area of AI - and a dramatic paradigm shift is needed," Warner said in a statement to Reuters.</p><p data-testid="paragraph-11">RISC-V is overseen by a Swiss-based nonprofit foundation that coordinates efforts among for-profit companies to develop the technology.</p><p data-testid="paragraph-12">The RISC-V technology came from labs at the University of California, Berkeley, and later benefited from funding by the Pentagon's Defense Advanced Research Projects Agency (DARPA). Its creators have compared it to Ethernet, USB and even the internet, which are freely available and draw on contributions from around the world to make innovation faster and cheaper.</p><h2 data-testid="Heading">HUAWEI TECHNOLOGIES</h2><p data-testid="paragraph-13">Executives from China's Huawei Technologies have embraced RISC-V as a pillar of that nation's progress in developing its own chips. But the United States and its allies also have jumped on the technology, with chip giant Qualcomm <a data-testid="Link" href="https://www.reuters.com/markets/companies/QCOM.O" target="_blank" referrerpolicy="no-referrer-when-downgrade">(QCOM.O)</a> working with a group of European automotive firms on RISC-V chips and Alphabet's Google saying it will make Android, the world's most popular mobile operating system, work on RISC-V chips.</p><p data-testid="paragraph-14">Qualcomm declined to comment. Its executives said in August they believe RISC-V will speed up chip innovation and transform the tech industry.</p><p data-testid="paragraph-15">Google did not respond to a request for comment.</p><p data-testid="paragraph-16">If Biden's administration were to regulate U.S. companies' participation in the Swiss-based foundation in the manner lawmakers are seeking, the move could complicate how American and Chinese companies work together on open technical standards. It also could create hurdles for China's pursuit of chip self-sufficiency, as well as for U.S. and European efforts to create cheaper and more versatile chips.</p><p data-testid="paragraph-17">Jack Kang, vice president of business development at SiFive, a Santa Clara, California-based startup using RISC-V, said potential U.S. government restrictions on American companies regarding RISC-V would be a "tremendous tragedy."</p><p data-testid="paragraph-18">"It would be like banning us from working on the internet," Kang said. "It would be a huge mistake in terms of technology, leadership, innovation and companies and jobs that are being created."</p><p data-testid="paragraph-19">Regulating the open discussion of technologies is rarer than regulating physical products, but not impossible, said Kevin Wolf, an export-control attorney at law firm Akin Gump who served in the Commerce Department under former President Barack Obama. Existing rules on chip exports could help provide a legal framework for such a proposal, Wolf said.</p><p data-testid="Body">Reporting by Max A. Cherney and Stephen Nellis in San Francisco; Editing by Will Dunham and Kenneth Li</p><p data-testid="Body">Our Standards: <a data-testid="Link" href="https://www.thomsonreuters.com/en/about-us/trust-principles.html" target="_blank" referrerpolicy="no-referrer-when-downgrade">The Thomson Reuters Trust Principles.</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Android devices with backdoored firmware found in US schools (118 pts)]]></title>
            <link>https://www.securityweek.com/android-devices-with-backdoored-firmware-found-in-us-schools/</link>
            <guid>37797679</guid>
            <pubDate>Fri, 06 Oct 2023 23:35:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.securityweek.com/android-devices-with-backdoored-firmware-found-in-us-schools/">https://www.securityweek.com/android-devices-with-backdoored-firmware-found-in-us-schools/</a>, See on <a href="https://news.ycombinator.com/item?id=37797679">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="tps_slideContainer_35233">
<p><strong>Tens of thousands of Android devices have been shipped to end-users with backdoored firmware, according to a warning from cybersecurity vendor Human Security.</strong>
</p><p>As part of the global cybercriminal operation called <a href="https://www.humansecurity.com/hubfs/HUMAN_Report_BADBOX-and-PEACHPIT.pdf">BadBox</a> (PDF), Human Security found a threat actor relied on supply chain compromise to infect the firmware of more than 70,000 Android smartphones, CTV boxes, and tablet devices with the Triada malware.
</p><p>The infected devices come from at least one Chinese manufacturer but, before they are delivered to resellers, physical retail stores, and e-commerce warehouses, a backdoor was injected into their firmware.
</p><p>“Products known to contain the backdoor have been found on public school networks throughout the United States,” Human says.
</p><p>Discovered in 2016, <a href="https://www.securityweek.com/triada-trojan-most-advanced-mobile-malware-yet-kaspersky/">Triada is a modular trojan</a> residing in a device’s RAM, relying on the Zygote process to hook all applications on Android, actively using root privileges to substitute system files. Over time, <a href="https://www.securityweek.com/android-trojan-uses-sandbox-evade-detection/">the malware went through various iterations</a> and was found<a href="https://www.securityweek.com/triada-trojan-preinstalled-low-cost-android-devices/"> pre-installed on low-cost Android devices</a> on<a href="https://www.securityweek.com/triada-trojan-pre-installed-low-cost-android-smartphones/"> at least two occasions</a>.
</p><p>As part of the BadBox operation that Human Security discovered, the infected low-cost Android devices allow threat actors to carry out various ad-fraud schemes, including one named PeachPit, which at its peak relied on 121,000 Android and 159,000 iOS devices infected with malware, and on 39 Android, iOS, and CTV-centric apps designed to connect to a fake supply-side platform (SSP).
</p><p>One of the modules delivered to the infected devices from the command-and-control (C&amp;C) server allows the creation of WebViews that are fully hidden from the user, but which “are used to request, render, and click on ads, spoofing the ad requests to look like they’re coming from certain apps, referred by certain websites, and rendered” on specific devices.</p>
<p>BadBox, Human Security notes, also includes a residential proxy module that allows the threat actors to sell access to the victim’s network. Furthermore, they can create WhatsApp messaging accounts and Gmail accounts they can then use for other malicious activities.
</p><p>“Finally, because of the backdoor’s connection to C2 servers on BadBox-infected smartphones, tablets, and CTV boxes, new apps or code can be remotely installed by the threat actors without the device owner’s permission. The threat actors behind BadBox could develop entirely new schemes and deploy them on BadBox-infected devices without any interaction from the devices’ owners,” Human notes.
</p><p>The cybersecurity firm says that it has managed to disrupt the PeachPit ad fraud scheme and that the BadBox operators have taken down their C&amp;C servers, likely to adapt and circumvent the deployed defensive measures.
</p><p>Human also warns that BadBox-infected devices cannot be cleaned by the end-users, since the backdoor resides in the firmware partition and that almost all infected devices are lower-price-point, recommending that users choose familiar brands when purchasing new products.
</p><p><strong>Related:</strong> <a href="https://www.securityweek.com/xenomorph-android-banking-trojan-targeting-users-in-us-canada/">Xenomorph Android Banking Trojan Targeting Users in US, Canada</a>
</p><p><strong>Related:</strong> <a href="https://www.securityweek.com/predator-spyware-delivered-to-ios-android-devices-via-zero-days-mitm-attacks/">Predator Spyware Hitting iOS, Android Devices via Zero-Days</a>
</p><p><strong>Related:</strong> <a href="https://www.securityweek.com/anatsa-banking-trojan-delivered-via-google-play-targets-android-users-in-us-europe/">Banking Trojan Delivered via Google Play Targets Users in US, Europe</a>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Multiplayer game engine with 120fps and 2 second load time on the web (170 pts)]]></title>
            <link>https://dotbigbang.com/game/1af877e9bfdb47088611f55982b7570f/prestons-diamond-wars?mp=playdw</link>
            <guid>37797606</guid>
            <pubDate>Fri, 06 Oct 2023 23:26:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dotbigbang.com/game/1af877e9bfdb47088611f55982b7570f/prestons-diamond-wars?mp=playdw">https://dotbigbang.com/game/1af877e9bfdb47088611f55982b7570f/prestons-diamond-wars?mp=playdw</a>, See on <a href="https://news.ycombinator.com/item?id=37797606">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[SlowLlama: Finetune llama2-70B and codellama on MacBook Air without quantization (139 pts)]]></title>
            <link>https://github.com/okuvshynov/slowllama</link>
            <guid>37796863</guid>
            <pubDate>Fri, 06 Oct 2023 21:46:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/okuvshynov/slowllama">https://github.com/okuvshynov/slowllama</a>, See on <a href="https://news.ycombinator.com/item?id=37796863">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" id="user-content-slowllama" dir="auto"><a href="#slowllama">slowllama</a></h2>
<p dir="auto">Fine-tune Llama2 and CodeLLama models, including 70B/35B on Apple M1/M2 devices (for example, Macbook Air or Mac Mini) or consumer nVidia GPUs.</p>
<p dir="auto">slowllama is not using any quantization. Instead, it offloads parts of model to SSD or main memory on both forward/backward passes. In contrast with training large models from scratch (unattainable) or inference, where we are likely to care about interactivity, we can still get something finetuned if you let it run for a while.</p>
<p dir="auto">Current version is using LoRA to limit the updates to a smaller set of parameters. First version supported full finetuning as well, but I decided to remove it for now, more on that below.</p>
<p dir="auto">Finetuning is the only focus, there's nothing special done for inference, consider <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a>.</p>
<p dir="auto">For CUDA-specific experiments, see <a href="https://github.com/okuvshynov/slowllama/blob/main/docs/a10.md">report on a10</a>.</p>
<p dir="auto">It is all very experimental, but even more so for CUDA.</p>
<h3 tabindex="-1" id="user-content-example" dir="auto"><a href="#example">Example</a></h3>
<p dir="auto">Tests were done on Apple M1 with 16Gb memory and Apple M2 with 24Gb memory.</p>
<p dir="auto">In order to fine-tune llama2 model we need to:</p>
<ol dir="auto">
<li>Install dependencies: <code>pip install torch sentencepiece numpy</code>. Optional: install <code>pip install fewlines</code> for <a href="https://github.com/okuvshynov/slowllama/blob/main/docs/lora_weights.md">weight/gradient distribution logging</a>.</li>
<li>Clone <a href="https://github.com/facebookresearch/llama">llama2</a> and follow instructions to download the models. The script will download tokenizer as well. <code>tokenizer.model</code> should be put into the same directory as llama model itself. Use <a href="https://github.com/facebookresearch/codellama">codellama</a> for CodeLLama models. Example folder structure could look like:</li>
</ol>
<div data-snippet-clipboard-copy-content="/parent/
    /slowllama/...   # <- this repo
    /codellama/...   # <-- this is Meta's codellama repository.
    /llama-2-7b/...  # <- put tokenizer.model here
    /llama-2-13b/... # <- and here
    /llama-2-70b/... # <- and here as well
    /CodeLlama-34b-Python/... # and here"><pre><code>/parent/
    /slowllama/...   # &lt;- this repo
    /codellama/...   # &lt;-- this is Meta's codellama repository.
    /llama-2-7b/...  # &lt;- put tokenizer.model here
    /llama-2-13b/... # &lt;- and here
    /llama-2-70b/... # &lt;- and here as well
    /CodeLlama-34b-Python/... # and here
</code></pre></div>
<p dir="auto">Let's start with a <a href="https://github.com/okuvshynov/slowllama/blob/main/test_data/cubestat.txt">tiny example</a>. It is an intro to the description of another open-source project - <a href="https://github.com/okuvshynov/cubestat">cubestat</a>. Text is short enough to just be included as part of the prompt, but it's ok as an illustration and you can read it in seconds youself. As I just published that project recently, there's no way original llama would know anything about it.</p>
<p dir="auto">Asking base llama2-7b to complete the prompt <em>"Cubestat reports the following metrics: "</em> results in <em>"1) the number of cubes in the system, 2) the number of cubes that are in the process of being created"</em>.</p>
<p dir="auto">First step is to transform the model to the sequential format more suitable for loading to/from storage block-by-block.</p>

<p dir="auto">Modify the input/output paths in the script itself.</p>
<p dir="auto">Now we can try not-finetuned llama2:</p>
<div data-snippet-clipboard-copy-content="python test_gen.py ../llama7b mps # use path to transformed model here"><pre><code>python test_gen.py ../llama7b mps # use path to transformed model here
</code></pre></div>
<p dir="auto">Now let's finetune the 7b model. <a href="https://github.com/okuvshynov/slowllama/blob/main/finetune.py">finetune.py</a> is a very simple script which trains LoRA weights based on the plaintext data. There are some settings you could change here, like sequence length, batch size, learning rate, dropout rate, number of iterations. Current settings are pretty much a guess, change this if desired. Adjust accordingly. Currently it uses AdamW optimizer.</p>

<p dir="auto">Here's train dataset loss:</p>
<div data-snippet-clipboard-copy-content="2023-09-10 22:05:35,569 backprop done, loss after forward pass = 2.9539270401000977
2023-09-10 22:06:08,022 backprop done, loss after forward pass = 2.9073102474212646
2023-09-10 22:06:40,223 backprop done, loss after forward pass = 2.7192320823669434
2023-09-10 22:07:12,468 backprop done, loss after forward pass = 2.7223477363586426
2023-09-10 22:07:44,626 backprop done, loss after forward pass = 2.5889995098114014
2023-09-10 22:08:16,899 backprop done, loss after forward pass = 2.4459967613220215
2023-09-10 22:08:49,072 backprop done, loss after forward pass = 2.3632657527923584
2023-09-10 22:09:21,335 backprop done, loss after forward pass = 2.250361442565918
2023-09-10 22:09:53,511 backprop done, loss after forward pass = 2.165428638458252
2023-09-10 22:10:25,738 backprop done, loss after forward pass = 2.031874656677246
2023-09-10 22:13:45,794 backprop done, loss after forward pass = 1.8926434516906738
2023-09-10 22:14:18,049 backprop done, loss after forward pass = 1.7222942113876343
2023-09-10 22:14:50,243 backprop done, loss after forward pass = 1.58726966381073
2023-09-10 22:15:22,405 backprop done, loss after forward pass = 1.4983913898468018
2023-09-10 22:15:54,598 backprop done, loss after forward pass = 1.296463131904602
2023-09-10 22:16:26,909 backprop done, loss after forward pass = 1.3328818082809448
2023-09-10 22:16:59,031 backprop done, loss after forward pass = 1.0978631973266602
2023-09-10 22:17:31,200 backprop done, loss after forward pass = 1.018444538116455
2023-09-10 22:18:03,406 backprop done, loss after forward pass = 0.8421685099601746
2023-09-10 22:18:35,673 backprop done, loss after forward pass = 0.7168515920639038
2023-09-10 22:21:55,482 backprop done, loss after forward pass = 0.7870235443115234"><pre><code>2023-09-10 22:05:35,569 backprop done, loss after forward pass = 2.9539270401000977
2023-09-10 22:06:08,022 backprop done, loss after forward pass = 2.9073102474212646
2023-09-10 22:06:40,223 backprop done, loss after forward pass = 2.7192320823669434
2023-09-10 22:07:12,468 backprop done, loss after forward pass = 2.7223477363586426
2023-09-10 22:07:44,626 backprop done, loss after forward pass = 2.5889995098114014
2023-09-10 22:08:16,899 backprop done, loss after forward pass = 2.4459967613220215
2023-09-10 22:08:49,072 backprop done, loss after forward pass = 2.3632657527923584
2023-09-10 22:09:21,335 backprop done, loss after forward pass = 2.250361442565918
2023-09-10 22:09:53,511 backprop done, loss after forward pass = 2.165428638458252
2023-09-10 22:10:25,738 backprop done, loss after forward pass = 2.031874656677246
2023-09-10 22:13:45,794 backprop done, loss after forward pass = 1.8926434516906738
2023-09-10 22:14:18,049 backprop done, loss after forward pass = 1.7222942113876343
2023-09-10 22:14:50,243 backprop done, loss after forward pass = 1.58726966381073
2023-09-10 22:15:22,405 backprop done, loss after forward pass = 1.4983913898468018
2023-09-10 22:15:54,598 backprop done, loss after forward pass = 1.296463131904602
2023-09-10 22:16:26,909 backprop done, loss after forward pass = 1.3328818082809448
2023-09-10 22:16:59,031 backprop done, loss after forward pass = 1.0978631973266602
2023-09-10 22:17:31,200 backprop done, loss after forward pass = 1.018444538116455
2023-09-10 22:18:03,406 backprop done, loss after forward pass = 0.8421685099601746
2023-09-10 22:18:35,673 backprop done, loss after forward pass = 0.7168515920639038
2023-09-10 22:21:55,482 backprop done, loss after forward pass = 0.7870235443115234
</code></pre></div>
<p dir="auto">I didn't add a validation set for this data, instead I just checked what would the fine-tuned model produce for the same prompt.</p>
<p dir="auto">At ~10 iteration we get the following reasonable output:  <em>Cubestat reports the following metrics: 1. CPU usage, 2. Memory usage, 3. Disk usage</em></p>
<p dir="auto">At ~20 iteration another output is produced:</p>
<p dir="auto"><em>0 - Cubestat reports the following metrics: CPU utilization: Efficiency and Performance cores. Shows as percentage.</em></p>
<p dir="auto">Maybe we were overfitting already at this point.</p>
<p dir="auto">Running completion with newly produced lora checkpoint can be done like this:</p>
<div data-snippet-clipboard-copy-content="python test_gen.py ../llama7b mps ./out/state_dict_19.pth"><pre><code>python test_gen.py ../llama7b mps ./out/state_dict_19.pth
</code></pre></div>
<h3 tabindex="-1" id="user-content-how-does-it-work" dir="auto"><a href="#how-does-it-work">How does it work?</a></h3>
<p dir="auto">For all versions the process is roughly the same.</p>
<p dir="auto">First, we need to be able to load a model which requires more RAM than we have and save it back in sequential format. We create model instance with all large modules' weights offloaded to SSD - all of the transformer blocks, token embeddings and output linear layer. After that we <a href="https://github.com/okuvshynov/slowllama/blob/main/loader.py#L69">load model shards one by one</a>, for each shard iterate over all modules, update corresponding subset of its weights and save it back.</p>
<p dir="auto">Doing forward path is easy - we just load modules when we need and pass the output forward.</p>
<p dir="auto">Backward pass is a little more tricky, in a way we have to run forward pass twice. The way it's <a href="https://github.com/okuvshynov/slowllama/blob/main/blackbox_model.py#L351">currently implemented</a> is:</p>
<ol dir="auto">
<li>Do a forward pass while also saving inputs to each offloaded block to the SSD. The goal of the first forward pass is to compute the final loss and cache inputs to each offloaded block.</li>
<li>Then, do a manual backward gradient propagation. We start from the last block, re-run each block once again (forward, to build autograd graph) with the same input we cached on step (1). After that we run backward pass within that block only, and pass the gradient for the input to the next (previous?) block. As we use LoRA, only LoRA gradients are being saved. LoRA weights are not offloaded to disk, always staying on RAM/GPU. Important: we also need to save and restore random number generation state before evaluating each offloaded module. During training we use dropout, and randomly switched off neurons should be the same on both forward passes.</li>
<li>After that we run optimizer step on LoRA weights and save them separately if needed.</li>
</ol>
<p dir="auto">Original llama2 weights are in bfloat16, but mps backend doesn't support that type natively, so we do computation in float32 instead.</p>
<p dir="auto">Experimental version of slowllama which can be still found <a href="https://github.com/okuvshynov/experiments/tree/5cf944cb1274e577d1e755e6ad1957190d286d9d/split_model">here</a> was capable of doing full finetuning and update all weights pretty much the same way. I've temporarily removed that feature to preserve the lifespan of SSDs, as frequent write operations can degrade performance over time. Reading from SSDs isn't an issue, but they do have a write limit. Limit is typically high enough for normal usage, but in the case of full finetunining we'll have to write ~150Gb per one iteration/weight update of 70B variant, assuming stateless optimizer and no gradient accumulation. With AdamW we'll have to save/update another 150Gb more of optimizer state per iteration. If, for example, we assume 1Pb of writes before SSD will start having issues, even 100 iterations of finetuning would incur significant cost/risk. For machines with GPUs and large amount of RAM we can skip the disk entirely and offload to RAM only. It should be possible to bring full finetuning back for main-memory-only offload. On the other hand, if everything fits into memory, there's no need to do whole 'evaluate twice' thing, might just use <a href="https://fairscale.readthedocs.io/en/stable/deep_dive/offload.html" rel="nofollow">fairscale</a> instead and only move tensors between GPU/CPU.</p>
<h3 tabindex="-1" id="user-content-experiments" dir="auto"><a href="#experiments">Experiments</a></h3>
<h4 tabindex="-1" id="user-content-llama2-7b-finetune-on-m1-mini-16gb-memory" dir="auto"><a href="#llama2-7b-finetune-on-m1-mini-16gb-memory">Llama2 7B finetune on M1 Mini (16Gb memory):</a></h4>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/okuvshynov/slowllama/blob/main/static/finetune_m1_7b.png"><img src="https://github.com/okuvshynov/slowllama/raw/main/static/finetune_m1_7b.png" alt="finetune on mac mini"></a></p>
<p dir="auto">Here we can see resource utilization for 1 full iteration on 7B model - forward and manual backward passes. Each column == 1 second. A few notes:</p>
<ol dir="auto">
<li>GPU is reasonably well utilized;</li>
<li>First forward pass has lower GPU utilization and spends more time on IO as we need to both read weights and write cached inputs/outputs</li>
<li>Backward (combined?) pass achieves very high GPU utilization, close to 100%</li>
<li>As we move along layers back and forth, right after each 'direction switch' we process layers in LIFO order. Thus in the beginning of both forward and backward pass we don't have to access disk, weights are being cached and we don't see disk reads.</li>
</ol>
<p dir="auto">batch_size/seq_len - works ok with, say, 2048 seq_len and batch_size = 2.</p>
<h4 tabindex="-1" id="user-content-llama2-70b-finetune-on-m1-mini-16gb-memory" dir="auto"><a href="#llama2-70b-finetune-on-m1-mini-16gb-memory">Llama2 70B finetune on M1 Mini (16Gb memory)</a></h4>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/okuvshynov/slowllama/blob/main/static/llama2_70b_m1.png"><img src="https://github.com/okuvshynov/slowllama/raw/main/static/llama2_70b_m1.png" alt="finetune 70b model"></a></p>
<p dir="auto">The chart here has different granularity - each column is 30 seconds. Input data was also different - it is the readme file you are reading now.
I didn't have enough free space on disk to store both original weights (140Gb) + weights in sequential format we use (another 140Gb). In order to still be able to finetune this model, I stored original weights on much slower external SD card, as we need to read them only once. Weights in sequential format on fast internal SSD.
With batch size = 16 and sequence length = 128 it was taking ~25-30 min per iteration.</p>
<p dir="auto">As we can see, GPU utilization doesn't look that great - we might be able to benefit from prefetching next transformer block, assuming we have enough memory for storing 2 layers. Memory utilization peaked at around 80% of 16Gb.</p>
<p dir="auto">Loss over time:</p>
<div data-snippet-clipboard-copy-content="2023-09-13 17:30:28,731 backprop done, loss after forward pass = 2.431253433227539
2023-09-13 18:00:00,133 backprop done, loss after forward pass = 2.604712963104248
2023-09-13 18:29:36,473 backprop done, loss after forward pass = 2.6277880668640137
2023-09-13 19:00:40,463 backprop done, loss after forward pass = 2.408756971359253
2023-09-13 19:29:55,974 backprop done, loss after forward pass = 2.6121537685394287
2023-09-13 19:59:04,849 backprop done, loss after forward pass = 2.428431987762451
2023-09-13 20:27:03,760 backprop done, loss after forward pass = 2.4040215015411377
2023-09-13 20:55:56,969 backprop done, loss after forward pass = 2.158071279525757
2023-09-13 21:25:04,615 backprop done, loss after forward pass = 2.3459620475769043
2023-09-13 21:54:07,128 backprop done, loss after forward pass = 2.2933709621429443
2023-09-13 23:18:57,588 backprop done, loss after forward pass = 2.273494243621826
2023-09-13 23:48:05,310 backprop done, loss after forward pass = 2.4055371284484863
2023-09-14 00:17:19,113 backprop done, loss after forward pass = 2.2604546546936035
2023-09-14 00:46:31,872 backprop done, loss after forward pass = 2.552386522293091
2023-09-14 01:15:45,731 backprop done, loss after forward pass = 2.297588586807251
2023-09-14 01:44:51,640 backprop done, loss after forward pass = 2.1217401027679443
2023-09-14 02:14:09,033 backprop done, loss after forward pass = 1.9815442562103271
2023-09-14 02:43:09,114 backprop done, loss after forward pass = 2.020181179046631
2023-09-14 03:12:17,966 backprop done, loss after forward pass = 2.0041542053222656
2023-09-14 03:41:20,649 backprop done, loss after forward pass = 1.9396495819091797
2023-09-14 05:06:31,414 backprop done, loss after forward pass = 2.1592249870300293
2023-09-14 05:35:39,080 backprop done, loss after forward pass = 1.976989984512329
2023-09-14 06:04:57,859 backprop done, loss after forward pass = 1.7638890743255615
2023-09-14 06:34:06,953 backprop done, loss after forward pass = 1.9829202890396118
2023-09-14 07:03:18,661 backprop done, loss after forward pass = 1.754631519317627
2023-09-14 07:32:26,179 backprop done, loss after forward pass = 2.027863025665283
2023-09-14 08:01:37,546 backprop done, loss after forward pass = 1.8579339981079102
2023-09-14 08:30:41,689 backprop done, loss after forward pass = 1.7934837341308594
2023-09-14 08:59:55,921 backprop done, loss after forward pass = 1.794022798538208
2023-09-14 09:28:59,690 backprop done, loss after forward pass = 1.750269889831543
2023-09-14 10:56:19,282 backprop done, loss after forward pass = 1.4310824871063232
2023-09-14 11:25:28,462 backprop done, loss after forward pass = 1.6895856857299805
2023-09-14 11:54:39,973 backprop done, loss after forward pass = 1.5074403285980225
2023-09-14 12:23:42,604 backprop done, loss after forward pass = 1.6695624589920044
2023-09-14 12:53:00,535 backprop done, loss after forward pass = 1.4220315217971802
2023-09-14 13:22:15,685 backprop done, loss after forward pass = 1.5720497369766235
2023-09-14 13:51:30,744 backprop done, loss after forward pass = 1.544579267501831
2023-09-14 14:20:44,482 backprop done, loss after forward pass = 1.2813694477081299
2023-09-14 14:50:03,384 backprop done, loss after forward pass = 1.2990479469299316
2023-09-14 15:19:09,620 backprop done, loss after forward pass = 1.0500637292861938"><pre><code>2023-09-13 17:30:28,731 backprop done, loss after forward pass = 2.431253433227539
2023-09-13 18:00:00,133 backprop done, loss after forward pass = 2.604712963104248
2023-09-13 18:29:36,473 backprop done, loss after forward pass = 2.6277880668640137
2023-09-13 19:00:40,463 backprop done, loss after forward pass = 2.408756971359253
2023-09-13 19:29:55,974 backprop done, loss after forward pass = 2.6121537685394287
2023-09-13 19:59:04,849 backprop done, loss after forward pass = 2.428431987762451
2023-09-13 20:27:03,760 backprop done, loss after forward pass = 2.4040215015411377
2023-09-13 20:55:56,969 backprop done, loss after forward pass = 2.158071279525757
2023-09-13 21:25:04,615 backprop done, loss after forward pass = 2.3459620475769043
2023-09-13 21:54:07,128 backprop done, loss after forward pass = 2.2933709621429443
2023-09-13 23:18:57,588 backprop done, loss after forward pass = 2.273494243621826
2023-09-13 23:48:05,310 backprop done, loss after forward pass = 2.4055371284484863
2023-09-14 00:17:19,113 backprop done, loss after forward pass = 2.2604546546936035
2023-09-14 00:46:31,872 backprop done, loss after forward pass = 2.552386522293091
2023-09-14 01:15:45,731 backprop done, loss after forward pass = 2.297588586807251
2023-09-14 01:44:51,640 backprop done, loss after forward pass = 2.1217401027679443
2023-09-14 02:14:09,033 backprop done, loss after forward pass = 1.9815442562103271
2023-09-14 02:43:09,114 backprop done, loss after forward pass = 2.020181179046631
2023-09-14 03:12:17,966 backprop done, loss after forward pass = 2.0041542053222656
2023-09-14 03:41:20,649 backprop done, loss after forward pass = 1.9396495819091797
2023-09-14 05:06:31,414 backprop done, loss after forward pass = 2.1592249870300293
2023-09-14 05:35:39,080 backprop done, loss after forward pass = 1.976989984512329
2023-09-14 06:04:57,859 backprop done, loss after forward pass = 1.7638890743255615
2023-09-14 06:34:06,953 backprop done, loss after forward pass = 1.9829202890396118
2023-09-14 07:03:18,661 backprop done, loss after forward pass = 1.754631519317627
2023-09-14 07:32:26,179 backprop done, loss after forward pass = 2.027863025665283
2023-09-14 08:01:37,546 backprop done, loss after forward pass = 1.8579339981079102
2023-09-14 08:30:41,689 backprop done, loss after forward pass = 1.7934837341308594
2023-09-14 08:59:55,921 backprop done, loss after forward pass = 1.794022798538208
2023-09-14 09:28:59,690 backprop done, loss after forward pass = 1.750269889831543
2023-09-14 10:56:19,282 backprop done, loss after forward pass = 1.4310824871063232
2023-09-14 11:25:28,462 backprop done, loss after forward pass = 1.6895856857299805
2023-09-14 11:54:39,973 backprop done, loss after forward pass = 1.5074403285980225
2023-09-14 12:23:42,604 backprop done, loss after forward pass = 1.6695624589920044
2023-09-14 12:53:00,535 backprop done, loss after forward pass = 1.4220315217971802
2023-09-14 13:22:15,685 backprop done, loss after forward pass = 1.5720497369766235
2023-09-14 13:51:30,744 backprop done, loss after forward pass = 1.544579267501831
2023-09-14 14:20:44,482 backprop done, loss after forward pass = 1.2813694477081299
2023-09-14 14:50:03,384 backprop done, loss after forward pass = 1.2990479469299316
2023-09-14 15:19:09,620 backprop done, loss after forward pass = 1.0500637292861938
</code></pre></div>
<p dir="auto">We used prompt 'slowllama is a ', and here you can see the completions:</p>
<ul dir="auto">
<li>before any weight update: <em>slowllama is a 24 year old (DOB: December 25, 1994) pure-blood witch</em></li>
<li>after 10 iterations: <em>slowllama is a 24 year old (DOB: December 25, 1994) pure-blood witch</em></li>
<li>after 20 iterations: <em>slowllama is a 70B model trained on the same data as llama.70b, but with a different training setup.</em></li>
<li>after 30 iterations: <em>slowllama is a 2022 fork of llama2, which is a 2021 fork of llama, which is a 2020 fork</em></li>
<li>after 40 iterations: <em>slowllama is a 2-stage finetuning implementation for llama2.</em></li>
</ul>
<p dir="auto">Current setup is probably too slow for 70B model finetuning on old mac mini M1. It would be interesting to try it on more recent hardware (say, M2 Max / M2 Pro), implement prefetch/async save and see how it's going to work.</p>
<h3 tabindex="-1" id="user-content-merging-lora-weights-back" dir="auto"><a href="#merging-lora-weights-back">merging LoRA weights back</a></h3>
<p dir="auto">In order to merge LoRA checkpoint back to the model in original format, we can do the following:</p>
<div data-snippet-clipboard-copy-content="# confirm that old model is producing wrong output
python test_gen.py ../llama-2-7b mps

# ...
# 0 - slowllama is a 24 year old (DOB: May 1, 1997) pure-blood witch 

# check what would be the output for finetuned model by passing path to checkpoint
python test_gen.py ../llama-2-7b mps ./data/state_dict_29.pth

# ...
# 0 - slowllama is a 100% static, 100% offline, 100% open source, 100% free,

# now run merge. we need to pass: 
#   - original model path
#   - new path for new model
#   - lora checkpoint path 
#   - optionally number of model shards (default = 1)
python merge_lora.py ../llama-2-7b ./data/state_dict_29.pth ../llama-2-7b-out

# copy tokenizer model over:
cp ../llama-2-7b/tokenizer.model ../llama-2-7b-out/

# now run new model with no extra checkpoint, observe new output, same as in combined model: 
python test_gen.py ../llama-2-7b-out mps

# ...
# 0 - slowllama is a 100% static, 100% offline, 100% open source, 100% free,
"><pre><code># confirm that old model is producing wrong output
python test_gen.py ../llama-2-7b mps

# ...
# 0 - slowllama is a 24 year old (DOB: May 1, 1997) pure-blood witch 

# check what would be the output for finetuned model by passing path to checkpoint
python test_gen.py ../llama-2-7b mps ./data/state_dict_29.pth

# ...
# 0 - slowllama is a 100% static, 100% offline, 100% open source, 100% free,

# now run merge. we need to pass: 
#   - original model path
#   - new path for new model
#   - lora checkpoint path 
#   - optionally number of model shards (default = 1)
python merge_lora.py ../llama-2-7b ./data/state_dict_29.pth ../llama-2-7b-out

# copy tokenizer model over:
cp ../llama-2-7b/tokenizer.model ../llama-2-7b-out/

# now run new model with no extra checkpoint, observe new output, same as in combined model: 
python test_gen.py ../llama-2-7b-out mps

# ...
# 0 - slowllama is a 100% static, 100% offline, 100% open source, 100% free,

</code></pre></div>
<p dir="auto">Now the <code>../llama-2-7b-out</code> can be used in exactly same way as original llama2 for further quantization, inference, etc.</p>
<h3 tabindex="-1" id="user-content-project-structure" dir="auto"><a href="#project-structure">Project structure</a></h3>
<p dir="auto">Just a few files with no dependencies other than torch, numpy and sentencepiece for tokenizer.</p>
<ol dir="auto">
<li><a href="https://github.com/okuvshynov/slowllama/blob/main/blackbox_model.py">blackbox_model.py</a> -- model definition and manual backprop implementation. It's based on model.py from <a href="https://github.com/karpathy/llama2.c">llama2.c</a>, also MIT licenced.</li>
<li><a href="https://github.com/okuvshynov/slowllama/blob/main/finetune.py">finetune.py</a> - script which does the training</li>
<li><a href="https://github.com/okuvshynov/slowllama/blob/main/loader.py">loader.py</a> - manual loading/saving of large llama2 models</li>
<li><a href="https://github.com/okuvshynov/slowllama/blob/main/utils.py">utils.py</a> - small utility functions, including saving/loading random generator state for different devices.</li>
<li><a href="https://github.com/okuvshynov/slowllama/blob/main/test_gen.py">test_gen.py</a> - greedily complete the prompt. Takes base weights + trained LoRA weights as input. Useful for sanity checks.</li>
<li><a href="https://github.com/okuvshynov/slowllama/blob/main/blackbox.py">blackbox.py</a> - module wrapper which offloads the module to disk or main memory.</li>
<li><a href="https://github.com/okuvshynov/slowllama/blob/main/plot_lora.py">plot_lora.py</a> - logging utility, writes LoRA weights and gradient distribution to <a href="https://github.com/okuvshynov/slowllama/blob/main/docs/lora_weights.md">logfile</a>. Requires <a href="https://github.com/okuvshynov/fewlines">fewlines</a>. If fewlines is not installed, does nothing.</li>
<li><a href="https://github.com/okuvshynov/slowllama/blob/main/merge_lora.py">merge_lora.py</a> - merge original weights + lora weights in the original format which can then be used directly.</li>
<li><a href="https://github.com/okuvshynov/slowllama/blob/main/prepare_model.py">prepare_model.py</a> - script to transform sharded model to sequentially split model.</li>
</ol>
<h3 tabindex="-1" id="user-content-todo" dir="auto"><a href="#todo">TODO:</a></h3>
<div data-snippet-clipboard-copy-content="[ ] masking
[ ] more generic train routine
    [ ] pause/resume from LoRA snapshot
    [ ] do not create LoRA layers on prepare, only on finetune?
[ ] how to make it work with fp16 on Apple?
[ ] optimizations - prefetch the next layer/input, save asyncronously, etc;
[ ] gradient accumulation
[ ] plot something like memory requirement for (batch_size , seq_len)
[ ] combined RAM/disk offload - 200Gb RAM is rarity.
[ ] tests, cleanup and comments;
[ ] progress tracking for everything;
[ ] quantization beyond 16 bit?
[ ] configurable weight tying;
[ ] double check RNG state correctness."><pre><code>[ ] masking
[ ] more generic train routine
    [ ] pause/resume from LoRA snapshot
    [ ] do not create LoRA layers on prepare, only on finetune?
[ ] how to make it work with fp16 on Apple?
[ ] optimizations - prefetch the next layer/input, save asyncronously, etc;
[ ] gradient accumulation
[ ] plot something like memory requirement for (batch_size , seq_len)
[ ] combined RAM/disk offload - 200Gb RAM is rarity.
[ ] tests, cleanup and comments;
[ ] progress tracking for everything;
[ ] quantization beyond 16 bit?
[ ] configurable weight tying;
[ ] double check RNG state correctness.
</code></pre></div>
<h3 tabindex="-1" id="user-content-references" dir="auto"><a href="#references">References</a></h3>
<ul dir="auto">
<li><a href="https://github.com/facebookresearch/llama">llama2</a></li>
<li><a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a></li>
<li><a href="https://github.com/karpathy/llama2.c">llama2.c</a></li>
<li><a href="https://github.com/okuvshynov/cubestat">cubestat</a></li>
<li><a href="https://arxiv.org/abs/2106.09685" rel="nofollow">LoRA</a></li>
</ul>
<h3 tabindex="-1" id="user-content-contact" dir="auto"><a href="#contact">Contact</a></h3>
<p dir="auto">{github handle} @ gmail.com</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lasers deflected using air (129 pts)]]></title>
            <link>https://www.desy.de/news/news_search/index_eng.html?openDirectAnchor=2951&amp;two_columns=0</link>
            <guid>37796428</guid>
            <pubDate>Fri, 06 Oct 2023 21:06:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.desy.de/news/news_search/index_eng.html?openDirectAnchor=2951&#x26;two_columns=0">https://www.desy.de/news/news_search/index_eng.html?openDirectAnchor=2951&#x26;two_columns=0</a>, See on <a href="https://news.ycombinator.com/item?id=37796428">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Innovative concept changes the direction of laser light with the help of sound waves</p><div><p>Using a novel method, beams of laser light can be deflected using air alone. An invisible grating made only of air is not only immune to damage from the laser light, but it also preserves the original quality of the beam, reports the interdisciplinary research team in the journal <em>Nature Photonics</em>. The researchers have applied for a patent for their method.</p><div><video controls="controls"><source src="https://www.desy.de/e409/e116959/e119238/media/13764/Szene_01.mp4.mp4" type="video/mp4">Your browser does not support the video tag. Please try to <a href="https://www.desy.de/e409/e116959/e119238/media/13764/Szene_01.mp4.mp4" target="_blank">download</a> the video file.</video><p>In this animation, a laser light beam passes between a loudspeaker-reflector array that creates a grating of air. The laser beam interacts with this grating and is deflected without contact. Animation: Science Communication Lab for DESY</p></div><p>The innovative technique uses sound waves in order to modulate the air in the region where the laser beam is passing. “We’ve generated an optical grating with the help of acoustic density waves,” explains first author Yannick Schrödel, a Ph.D. student at DESY and Helmholtz Institute Jena. With the help of special loudspeakers, the researchers shape a pattern of dense and less dense areas in the air, forming a striped grating. In a way that is similar to how differential air densities bend the light in the Earth’s atmosphere, the density pattern takes on the role of an optical grating that changes the direction of the laser light beam. “However, deflecting light by diffraction grating allows much more precise control of the laser light compared to deflection in the Earth's atmosphere,” says Schrödel. “The properties of the optical grating are influenced by the frequency and intensity – in other words, the volume – of the sound waves.”</p><p>In the first laboratory tests, a strong infrared laser pulse could be redirected in this way with an efficiency of 50 percent. Significantly higher efficiencies should be possible in the future, according to numerical models. For the first test, the scientists had to turn their special loudspeakers way up. “We are moving at a sound level of about 140 decibels, which corresponds to a jet engine a few metres away,” explains scientist Christoph Heyl from DESY and the Helmholtz Institute Jena, who is leading the research project. “Fortunately, we are in the ultrasound range, which our ears don’t pick up.”</p><p>Here you can try out the deflection of the laser light by sound waves by sliding the slider:</p><p>The team sees great potential in the technique for high-performance optics. In their experiments, the researchers used an infrared laser pulse with a peak power of 20 gigawatts, which corresponds to the power of around two billion LED bulbs. Lasers of this and even higher power classes are used, for example, for material processing, in fusion research, or for the latest particle accelerators. “In this power range, the material properties of mirrors, lenses, and prisms significantly limit their use, and such optical elements are easily damaged by strong laser beams in practice,” explains Heyl. “In addition, the quality of the laser beam suffers. In contrast, we’ve managed to deflect laser beams in a quality-preserving way without contact.”</p><p>The principle of acoustic control of laser light in gases is not limited to the generation of optical gratings, the scientists emphasise. It can probably also be transferred to other optical elements such as lenses and waveguides. “We’ve been thinking about this method for a long time and quickly realised that extreme sound levels are necessary. At first, these seemed technically unfeasible,” explains Heyl. “However, we did not give up and finally found a solution with the support of researchers at the Technical University of Darmstadt as well as the company Inoson. First, we tried out our technique with ordinary air. Next, for example, we will also use other gases in order to tap into other wavelengths and other optical properties and geometries.”</p><p>The deflection of light directly into ambient air, which has already been demonstrated, opens up promising applications, especially as a fast switch for high-power lasers. “The potential of contactless control of light and its extension to other applications can currently only be imagined,” explains Heyl. “Modern optics is based almost exclusively on the interaction of light with solid matter. Our approach opens up a completely new direction.”</p><p>Researchers from the Technical University of Darmstadt, Aalen University of Applied Sciences, Universität Hamburg, Inoson GmbH in St. Ingbert, the Helmholtz Institute Jena, and DESY were involved in the work.</p><p><strong>Reference:<br></strong>Acousto-optic modulation of gigawatt-scale laser pulses in ambient air; Yannick Schrödel, Claas Hartmann, Tino Lang, Jiaan Zheng, Max Steudel, Matthias Rutsch, Sarper H. Salman, Martin Kellert, Mikhail Pergament, Thomas Hahn-Jose, Sven Suppelt, Jan Helge Dörsam, Anne Harth, Wim P. Leemans, Franz X. Kärtner, Ingmar Hartl, Mario Kupnik, Christoph M. Heyl; <em>Nature Photonics</em>, 2023; DOI: <a href="https://dx.doi.org/10.1038/s41566-023-01304-y">10.1038/s41566-023-01304-y</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why did the Motorola 68000 processor family fall out of use in PCs? (115 pts)]]></title>
            <link>https://retrocomputing.stackexchange.com/questions/27722/why-did-the-motorola-68000-processor-family-fall-out-of-use-in-personal-computer</link>
            <guid>37796292</guid>
            <pubDate>Fri, 06 Oct 2023 20:54:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://retrocomputing.stackexchange.com/questions/27722/why-did-the-motorola-68000-processor-family-fall-out-of-use-in-personal-computer">https://retrocomputing.stackexchange.com/questions/27722/why-did-the-motorola-68000-processor-family-fall-out-of-use-in-personal-computer</a>, See on <a href="https://news.ycombinator.com/item?id=37796292">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="mainbar" role="main" aria-label="question and answers">

                
<div data-questionid="27722" data-position-on-page="0" data-score="41" id="question">
        

        

<div>
    
    <div itemprop="text">
                
<p>In the '80s and '90s the Intel x86 and Motorola 68000 families were the two leading microcomputer architectures in the 16-bit/32-bit personal computer scene. The 68000s were even preferred by the purists because of its orthogonal instruction set. The Intel x86 family, although always the market leader, has been criticized for its non-orthogonal instruction set and segmented addressing.</p>
<p>When the Macintosh line switched to PowerPC, the Motorola 68000 family began to disappear as a contender for newly designed personal computers outside the “Wintel” ecosystem. New contenders, such as the PowerPC, ARM and MIPS, take the 68000 family’s place.</p>
<p>I cannot find on the internet the reason why the 68000 family fell out of favor in the personal computer market.</p>
<p>Can someone explain this or point me in the direction of the answer?</p>
    </div>

        

    <div>
            

                <div>
        <a href="https://retrocomputing.stackexchange.com/users/7946/toby-speight"><p><img src="https://i.stack.imgur.com/acYd0.png?s=64&amp;g=1" alt="Toby Speight's user avatar" width="32" height="32"></p></a>
    </div>
            <div>
    <p>
        asked <span title="2023-09-25 02:30:51Z">Sep 25 at 2:30</span>
    </p>
    <div>
        <a href="https://retrocomputing.stackexchange.com/users/8047/biff-iam"><p><img src="https://graph.facebook.com/10153952907388852/picture?type=large" alt="Biff Iam's user avatar" width="32" height="32"></p></a>
    </div>
    
</div>
        </div>
    
</div>




            <p><span itemprop="commentCount">19</span></p>
    </div>



                
                
                <div id="answers">
                    


                                    
<div id="answer-27724" data-answerid="27724" data-parentid="27722" data-score="35" data-position-on-page="1" data-highest-scored="0" data-question-has-accepted-highest-score="0" itemprop="acceptedAnswer" itemscope="" itemtype="https://schema.org/Answer">
        

        

<div>
    
    <div itemprop="text">
<p>The <a href="https://en.wikipedia.org/wiki/AIM_alliance" rel="noreferrer">Apple-IBM-Motorola alliance</a> was created in 1991 to compete with the Windows/Intel market. Its main successes were the creation of the PowerPC instruction set, derived from IBM's POWER architecture, and Apple's Power Macintosh line of computers.</p>
<p>IBM originated the idea, having seen that Windows on Intel was out-competing OS/2, and wanting to avoid being dependent on Intel. Apple joined it, seeing the chance to grow out of their existing markets, and Motorola presumably saw it as a successor to 68000, having failed comprehensively with the <a href="https://en.wikipedia.org/wiki/Motorola_88000" rel="noreferrer">MC88000</a>.</p>
<p>While the 68000 was used in the Macintosh series, Atari STs and Amigas, all the operating systems involved were quite different, so there was no unified software base. That meant there wasn't the sustained demand for 68000 that could have paid for chip development on the scale required to keep it competitive with x86. The engineering workstation market had started with the 68000, but had already switched to RISC before AIM was created.</p>
    </div>
    <div>
    <p>
        answered <span title="2023-09-25 06:36:35Z">Sep 25 at 6:36</span>
    </p>
    <div>
        <a href="https://retrocomputing.stackexchange.com/users/3481/john-dallman"><p><img src="https://www.gravatar.com/avatar/fa5764b5ee7afe97b5a925b24c4fa229?s=64&amp;d=identicon&amp;r=PG&amp;f=y&amp;so-version=2" alt="John Dallman's user avatar" width="32" height="32"></p></a>
    </div>
    <div itemprop="author" itemscope="" itemtype="http://schema.org/Person">
        <p><a href="https://retrocomputing.stackexchange.com/users/3481/john-dallman">John Dallman</a><span itemprop="name">John Dallman</span></p><p><span title="reputation score 11,427" dir="ltr">11.4k</span><span>2 gold badges</span><span>38 silver badges</span><span>52 bronze badges</span>
        </p>
    </div>
</div>
    
</div>




            <p><span itemprop="commentCount">4</span></p>
    </div>


                                    
<div id="answer-27727" data-answerid="27727" data-parentid="27722" data-score="47" data-position-on-page="2" data-highest-scored="1" data-question-has-accepted-highest-score="0" itemprop="suggestedAnswer" itemscope="" itemtype="https://schema.org/Answer">
        

        

<div>
    
    <div itemprop="text">
<p>The 68k family instruction set, as elegant as it appeared to the casual assembler programmer (been there), had several flaws that made it very difficult to get fast in hardware. Out of order or superscalar execution were very, very difficult to implement.</p>
<ul>
<li>Over-complex addressing modes, especially the indirect one introduced with 68020: when combined with virtual memory made it theoretical possible to get up to 16 page faults in 1 instruction (move long indirect with displacement and shifted index from an odd address touching 2 pages etc.). These indirect addressing modes were the first to be removed when defining the Coldfire ISA.</li>
<li>Exposure of the pipeline internals on traps and exceptions: the idea was that on a trap, the instruction could be resumed after fixing the error cause. This made it very difficult to get performance out of the kernel as it wrote more and more data to the stack at each generation, and it also limited the internal state that could be saved. x86 was much more pragmatic and just restarted the cancelled instruction from start.</li>
<li>Compatibility between successive family members was not as good as in intel CPUs. If you want to compile a program that runs on 68000 and on any of 680[2346]0 you will lose a lot of features on the side.</li>
</ul>
<p>There is the famous <a href="https://userpages.umbc.edu/%7Evijay/mashey.on.risc.html" rel="noreferrer">newsgroup post from John Mashey</a> explaining the fundamental issue with the 68k ISA in comparison to other ISAs of that time.</p>
    </div>
    <div>
    <p>
        answered <span title="2023-09-25 08:25:00Z">Sep 25 at 8:25</span>
    </p>
    <div>
        <a href="https://retrocomputing.stackexchange.com/users/7095/patrick-schl%c3%bcter"><p><img src="https://www.gravatar.com/avatar/5b36bf29056af38269b2147d5c36b94e?s=64&amp;d=identicon&amp;r=PG" alt="Patrick Schlüter's user avatar" width="32" height="32"></p></a>
    </div>
    <div itemprop="author" itemscope="" itemtype="http://schema.org/Person">
        <p><a href="https://retrocomputing.stackexchange.com/users/7095/patrick-schl%c3%bcter">Patrick Schlüter</a><span itemprop="name">Patrick Schlüter</span></p><p><span title="reputation score " dir="ltr">3,319</span><span>1 gold badge</span><span>12 silver badges</span><span>17 bronze badges</span>
        </p>
    </div>
</div>
    
</div>




            <p><span itemprop="commentCount">8</span></p>
    </div>

                                    
<div id="answer-27726" data-answerid="27726" data-parentid="27722" data-score="16" data-position-on-page="3" data-highest-scored="0" data-question-has-accepted-highest-score="0" itemprop="suggestedAnswer" itemscope="" itemtype="https://schema.org/Answer">
        

        

<div>
    
    <div itemprop="text">
<p>Motorola stopped investing in MC68000 family when everyone thought that RISC was the future and that CISC CPUs would be soon non competitive. So it switched to PowerPCs.</p>
<p>Even Intel thought this and developed RISC CPUs (i860, i960...). Intel reluctantly continued investing in x86.</p>
<p>For Motorola, it was probably true, the last version, MC68060 was competitive with Pentium but it was quickly surpassed because of Intel manufacturing superiority allowing lower dissipation, higher frequencies. Switching to simpler RISC CPUs could allow to stay in the race.</p>
<p>Now, the difference between RISC and CISC (eg x86) is less relevant performance-wise due to the possibility of putting 100 times more transistors on a die.</p>
    </div>
    <div>
            
            <div>
        <a href="https://retrocomputing.stackexchange.com/users/7095/patrick-schl%c3%bcter"><p><img src="https://www.gravatar.com/avatar/5b36bf29056af38269b2147d5c36b94e?s=64&amp;d=identicon&amp;r=PG" alt="Patrick Schlüter's user avatar" width="32" height="32"></p></a>
    </div>


            <div>
    <p>
        answered <span title="2023-09-25 07:22:32Z">Sep 25 at 7:22</span>
    </p>
    <div>
        <a href="https://retrocomputing.stackexchange.com/users/1958/temlib"><p><img src="https://i.stack.imgur.com/JeK6w.png?s=64&amp;g=1" alt="TEMLIB's user avatar" width="32" height="32"></p></a>
    </div>
    <div itemprop="author" itemscope="" itemtype="http://schema.org/Person">
        <p><a href="https://retrocomputing.stackexchange.com/users/1958/temlib">TEMLIB</a><span itemprop="name">TEMLIB</span></p><p><span title="reputation score " dir="ltr">3,417</span><span>16 silver badges</span><span>18 bronze badges</span>
        </p>
    </div>
</div>
        </div>
    
</div>




            <p><span itemprop="commentCount">4</span></p>
    </div>


                                    
<div id="answer-27725" data-answerid="27725" data-parentid="27722" data-score="10" data-position-on-page="4" data-highest-scored="0" data-question-has-accepted-highest-score="0" itemprop="suggestedAnswer" itemscope="" itemtype="https://schema.org/Answer">
        

        

<div>
    
    <div itemprop="text">
<blockquote>
<p>When the Macintosh line switched to Power PC, the Motorola 68000 family begun to disappear</p>
</blockquote>
<p>It's been rather the other way around. Apple switching was a result of Motorola losing the race.</p>
<blockquote>
<p>New contenders, such as the Power PC, ARM and MIPS take the 68000 family’s place.</p>
</blockquote>
<p>Not really - also you forget the NS32k family going away at the same time, being maybe less visible but at least as successful as the 68k.</p>
<blockquote>
<p>I cannot find in the internet the reason why the 68000 family fell out of favor in the personal computer market.</p>
</blockquote>
<p>Cost on either side:</p>
<ul>
<li>Motorola wasn't able to keep up investment to improve their CPUs the same way that Intel did</li>
<li>Resulting CPUs were considerably more expensive than Intel's offering.</li>
</ul>
<p>This is not only true at upper end offerings with '060 vs. Pentium but even more for embedded. Basic 80(1)88 based systems could be delivered at considerable lower development and production cost.</p>
    </div>
    <div>
            
            <div>
    
    <div>
        <a href="https://retrocomputing.stackexchange.com/users/576/lorraine"><p><img src="https://i.stack.imgur.com/RZLo7.png?s=64&amp;g=1" alt="Lorraine's user avatar" width="32" height="32"></p></a>
    </div>
    <div>
        <p><a href="https://retrocomputing.stackexchange.com/users/576/lorraine">Lorraine</a></p><p><span title="reputation score 38,038" dir="ltr">38k</span><span>11 gold badges</span><span>131 silver badges</span><span>270 bronze badges</span>
        </p>
    </div>
</div>


            <div>
    <p>
        answered <span title="2023-09-25 06:45:20Z">Sep 25 at 6:45</span>
    </p>
    <div>
        <a href="https://retrocomputing.stackexchange.com/users/6659/raffzahn"><p><img src="https://lh3.googleusercontent.com/-yspgfz81fFw/AAAAAAAAAAI/AAAAAAAAD5o/7CFgAMaSHSE/photo.jpg?sz=64" alt="Raffzahn's user avatar" width="32" height="32"></p></a>
    </div>
    <div itemprop="author" itemscope="" itemtype="http://schema.org/Person">
        <p><a href="https://retrocomputing.stackexchange.com/users/6659/raffzahn">Raffzahn</a><span itemprop="name">Raffzahn</span></p><p><span title="reputation score 208,875" dir="ltr">209k</span><span>21 gold badges</span><span>586 silver badges</span><span>862 bronze badges</span>
        </p>
    </div>
</div>
        </div>
    
</div>




            <p><span itemprop="commentCount">5</span></p>
    </div>

                                    
<div id="answer-27737" data-answerid="27737" data-parentid="27722" data-score="8" data-position-on-page="5" data-highest-scored="0" data-question-has-accepted-highest-score="0" itemprop="suggestedAnswer" itemscope="" itemtype="https://schema.org/Answer">
    
    <p>Motorola lost the race to 32 bit computing from a simple engineering mistake.
In the era when the 68k and x86 were very popular, the shift to 32 bit CPUs was a race to mass production. No question the 68020 was a cleaner design and almost destined to be the no. 1 choice for new machines. Friends of mine paid around $400 at the time for early 68020 chips to build test boards. X86 at the time was hopelessly behind. BUT, the first iteration of the 68020 had pushed the design parameters of the chip process to the point that yields were appalling. Every chip sold at a loss. Motorola then had to redesign all the masks which was an 18 month engineering exercise. 18 months was the window that let x86 get ahead in the market and that was the end of the 68k family's dominance. Shame</p>
    <div>
    <p>
        answered <span title="2023-09-26 11:29:50Z">Sep 26 at 11:29</span>
    </p>
    <div>
        <a href="https://retrocomputing.stackexchange.com/users/28249/alex-danilo"><p><img src="https://www.gravatar.com/avatar/a0a488cb658854d129ec3c2e9c27bb1e?s=64&amp;d=identicon&amp;r=PG" alt="Alex Danilo's user avatar" width="32" height="32"></p></a>
    </div>
    
</div>
    
</div>

                                    
<div id="answer-27723" data-answerid="27723" data-parentid="27722" data-score="6" data-position-on-page="6" data-highest-scored="0" data-question-has-accepted-highest-score="0" itemprop="suggestedAnswer" itemscope="" itemtype="https://schema.org/Answer">
    
    <p>The 68000 was a joy to program (compared to the segmented memory Intel x86), but it simply didn't keep up in the clocking race.</p>
    <div>
    <p>
        answered <span title="2023-09-25 02:50:05Z">Sep 25 at 2:50</span>
    </p>
    <div>
        <a href="https://retrocomputing.stackexchange.com/users/27579/ubfan1"><p><img src="https://www.gravatar.com/avatar/499ad6b4324afc463ebfcff47450a85e?s=64&amp;d=identicon&amp;r=PG" alt="ubfan1's user avatar" width="32" height="32"></p></a>
    </div>
    
</div>
    
</div>

                                    
<div id="answer-27753" data-answerid="27753" data-parentid="27722" data-score="3" data-position-on-page="7" data-highest-scored="0" data-question-has-accepted-highest-score="0" itemprop="suggestedAnswer" itemscope="" itemtype="https://schema.org/Answer">
        

        

<div>
    
    <div itemprop="text">
<p>This was purely economics. By about 1988 the ready availability of IBM AT clones had the effect of pushing the price of support hardware- including cases, discs etc.- down enormously, and even on the '286 there were UNIX variants that demonstrated that such things were possible. The '386, when introduced, exploited that, and from that point onwards it became a race between what Intel- with a growing income- and Motorola et al.- with static incomes- could do with the available semiconductor technology.</p>
<p>By about 1995 Intel's price/performance ratio was unassailable, and graphics accelerators which could operate in conjunction with PC hardware were starting to erode the market for specialist workstations.</p>
    </div>
    <div>
    <p>
        answered <span title="2023-09-27 10:39:16Z">Sep 27 at 10:39</span>
    </p>
    <div>
        <a href="https://retrocomputing.stackexchange.com/users/18835/mark-morgan-lloyd"><p><img src="https://www.gravatar.com/avatar/4d46055b400959f30cdfae3541924714?s=64&amp;d=identicon&amp;r=PG&amp;f=y&amp;so-version=2" alt="Mark Morgan Lloyd's user avatar" width="32" height="32"></p></a>
    </div>
    
</div>
    
</div>




            <p><span itemprop="commentCount">1</span></p>
    </div>

                                <h2>
                                    You must <a href="https://retrocomputing.stackexchange.com/users/login?ssrc=question_page&amp;returnurl=https%3a%2f%2fretrocomputing.stackexchange.com%2fquestions%2f27722">log in</a> to answer this question.
                                </h2>



                            <h2 data-loc="1">
                                <div><p>
Not the answer you're looking for? Browse other questions tagged </p><p>.                                </p></div>
                            </h2>
                </div>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[23andMe scraping incident leaked data on 1.3M users (154 pts)]]></title>
            <link>https://therecord.media/scraping-incident-genetic-testing-site</link>
            <guid>37795652</guid>
            <pubDate>Fri, 06 Oct 2023 20:08:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://therecord.media/scraping-incident-genetic-testing-site">https://therecord.media/scraping-incident-genetic-testing-site</a>, See on <a href="https://news.ycombinator.com/item?id=37795652">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Genetic testing giant 23andMe confirmed that a data scraping incident resulted in hackers gaining access to sensitive user information and selling it on the dark web.</p>
<p>The information of nearly 7 million 23andMe users was <a href="https://twitter.com/DarkWebInformer/status/1709348139793068069">offered</a> for sale on a cybercriminal forum this week. The information included origin estimation, phenotype, health information, photos, identification data and more. 23andMe processes saliva samples submitted by customers to determine their ancestry.</p>
<p>When asked about the post, the company initially denied that the information was legitimate, calling it a “misleading claim” in a statement to Recorded Future News.</p>
<p>The company later said it was aware that certain 23andMe customer profile information was compiled through unauthorized access to individual accounts that were signed up for the DNA Relative feature — which allows users to opt in for the company to show them potential matches for relatives.</p>
<p>“We do not have any indication at this time that there has been a data security incident within our systems. Rather, the preliminary results of this investigation suggest that the login credentials used in these access attempts may have been gathered by a threat actor from data leaked during incidents involving other online platforms where users have recycled login credentials,” they said.</p>
<p>“We believe that the threat actor may have then, in violation of our terms of service, accessed 23andme.com accounts without authorization and obtained information from those accounts. We are taking this issue seriously and will continue our investigation to confirm these preliminary results.”</p>
<p><img src="https://cms.therecord.media/uploads/Breach_Forums_ace4be7d97.jpg" alt="BreachForums.jpg">
<em>A screenshot from the posting of 23andMe data on the BreachForums site.</em></p>
<p>When pressed on how compromising a handful of user accounts would give someone access to millions of users, the spokesperson said the company does not believe the threat actor had access to all of the accounts but rather gained unauthorized entry to a much smaller number of 23andMe accounts and scraped data from their DNA Relative matches.</p>
<p>The spokesperson declined to confirm the specific number of customer accounts affected.</p>
<p>Anyone who has opted into DNA Relatives can view basic profile information of others who make their profiles visible to DNA Relative participants, a spokesperson said.</p>
<p>Users who are genetically related can access ancestry information, which is made clear to users when they create their DNA Relatives profile, the spokesperson added.</p>
<p>Once the company has more information from the investigation, they said, it will determine the best approach to notifying any impacted customers.</p>
<h2>‘A botch job’</h2>
<p>The incident shows how a company's customer data can be vulnerable even if intruders don't get deep into its network.</p>
<p>A researcher approached Recorded Future News after examining the leaked database and found that much of it looked real. The researcher spoke on condition of anonymity because he found the information of his wife and several of her family members in the leaked data set. He also found other acquaintances and verified that their information was accurate.</p>
<p>The researcher downloaded two files from the BreachForums post and found that one had information on 1 million 23andMe users of Ashkenazi heritage. The other file included data on more than 300,000 users of Chinese heritage.</p>
<p>The data included profile and account ID numbers, names, gender, birth year, maternal and paternal genetic markers, ancestral heritage results, and data on whether or not each user has opted into 23andme’s health data.</p>
<p>“It appears the information has been scraped from user profiles which are only supposed to be shared between DNA Matches. So although this particular leak does not contain genomic sequencing data, it’s still data that should not be available to the public,” the researcher said.</p>
<p>“23andme seems to think this isn’t a big deal. They keep telling me that if I don’t want this info to be shared, I should not opt into the DNA relatives feature. But that’s dismissing the importance of this data which should only be viewable to DNA relatives, not the public. And the fact that someone was able to scrape this data from 1.3 million users is concerning. The hacker allegedly has more data that they have not released yet.”</p>
<p>The researcher added that he discovered another issue where someone could enter a 23andme profile ID, like the ones included in the leaked data set, into their URL and see someone’s profile.</p>
<p>The data available through this only includes profile photos, names, birth years and location but does not include test results.</p>
<p>“It’s very concerning that 23andme has such a big loophole in their website design and security where they are just freely exposing peoples info just by typing a profile ID into the URL. Especially for a website that deals with people's genetic data and personal information. What a botch job by the company,” the researcher said.</p>
<p>“I’ve tried contacting 23andme however they keep denying that there is anything wrong and are replying with cookie cutter responses. I don’t know how to prove this without doxing myself. But this is pretty serious and no one is taking it seriously.”</p>
<p>The security policies of genetic testing companies like 23andMe have faced scrutiny from regulators in recent weeks. Three weeks ago, genetic testing firm 1Health.io <a href="https://therecord.media/genetic-testing-firm-fined-ftc-privacy">agreed to pay the Federal Trade Commission (FTC) a $75,000 fine</a> to resolve allegations that it failed to secure sensitive genetic and health data, retroactively overhauled its privacy policy without notifying and obtaining consent from customers whose data it had obtained, and tricked customers about their ability to delete their data.</p><div><div><p>Get more insights with the </p><p>Recorded Future</p><p>Intelligence Cloud.</p></div><p><a target="_blank" rel="noopener noreferrer" href="https://www.recordedfuture.com/platform?mtm_campaign=ad-unit-record">Learn more.</a></p></div><div><p><span>Tags</span></p><ul><li><a href="https://therecord.media/tag/genetic-testing">genetic testing</a></li><li><a href="https://therecord.media/tag/privacy">Privacy</a></li><li><a href="https://therecord.media/tag/data-breach">Data breach</a></li><li><a href="https://therecord.media/tag/dark-web">dark web</a></li><li><a href="https://therecord.media/tag/scraping">scraping</a></li></ul></div><div><p><span>No previous article</span></p><p><span>No new articles</span></p></div><div><a href="https://therecord.media/author/jonathan-greig"><h2>Jonathan Greig</h2></a><p><a href="https://therecord.media/author/jonathan-greig"><span><img sizes="100vw" srcset="https://cms.therecord.media/uploads/DSC_0283_1_a6f4e4e315.jpg?w=640 640w, https://cms.therecord.media/uploads/DSC_0283_1_a6f4e4e315.jpg?w=750 750w, https://cms.therecord.media/uploads/DSC_0283_1_a6f4e4e315.jpg?w=828 828w, https://cms.therecord.media/uploads/DSC_0283_1_a6f4e4e315.jpg?w=1080 1080w, https://cms.therecord.media/uploads/DSC_0283_1_a6f4e4e315.jpg?w=1200 1200w, https://cms.therecord.media/uploads/DSC_0283_1_a6f4e4e315.jpg?w=1920 1920w, https://cms.therecord.media/uploads/DSC_0283_1_a6f4e4e315.jpg?w=2048 2048w, https://cms.therecord.media/uploads/DSC_0283_1_a6f4e4e315.jpg?w=3840 3840w" src="https://cms.therecord.media/uploads/DSC_0283_1_a6f4e4e315.jpg?w=3840" decoding="async" data-nimg="fill"></span></a></p><p>Jonathan Greig is a Breaking News Reporter at Recorded Future News. Jonathan has worked across the globe as a journalist since 2014. Before moving back to New York City, he worked for news outlets in South Africa, Jordan and Cambodia. He previously covered cybersecurity at ZDNet and TechRepublic.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fail2Ban (139 pts)]]></title>
            <link>https://github.com/fail2ban/fail2ban</link>
            <guid>37795100</guid>
            <pubDate>Fri, 06 Oct 2023 19:26:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/fail2ban/fail2ban">https://github.com/fail2ban/fail2ban</a>, See on <a href="https://news.ycombinator.com/item?id=37795100">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><div data-snippet-clipboard-copy-content="                     __      _ _ ___ _               
                    / _|__ _(_) |_  ) |__  __ _ _ _  
                   |  _/ _` | | |/ /| '_ \/ _` | ' \ 
                   |_| \__,_|_|_/___|_.__/\__,_|_||_|
                   v1.1.0.dev1            20??/??/??"><pre><code>                     __      _ _ ___ _               
                    / _|__ _(_) |_  ) |__  __ _ _ _  
                   |  _/ _` | | |/ /| '_ \/ _` | ' \ 
                   |_| \__,_|_|_/___|_.__/\__,_|_||_|
                   v1.1.0.dev1            20??/??/??
</code></pre></div>
<h2 tabindex="-1" id="user-content-fail2ban-ban-hosts-that-cause-multiple-authentication-errors" dir="auto"><a href="#fail2ban-ban-hosts-that-cause-multiple-authentication-errors">Fail2Ban: ban hosts that cause multiple authentication errors</a></h2>
<p dir="auto">Fail2Ban scans log files like <code>/var/log/auth.log</code> and bans IP addresses conducting
too many failed login attempts. It does this by updating system firewall rules
to reject new connections from those IP addresses, for a configurable amount
of time. Fail2Ban comes out-of-the-box ready to read many standard log files,
such as those for sshd and Apache, and is easily configured to read any log
file of your choosing, for any error you wish.</p>
<p dir="auto">Though Fail2Ban is able to reduce the rate of incorrect authentication
attempts, it cannot eliminate the risk presented by weak authentication.
Set up services to use only two factor, or public/private authentication
mechanisms if you really want to protect services.</p>
<table>
<thead>
<tr>
<th><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/270c686a79697f1292054865b13732166001452000e7a02fc69081963a9c2166/687474703a2f2f7777772e776f726c64697076366c61756e63682e6f72672f77702d636f6e74656e742f7468656d65732f697076362f646f776e6c6f6164732f576f726c645f495076365f6c61756e63685f6c6f676f2e737667"><img src="https://camo.githubusercontent.com/270c686a79697f1292054865b13732166001452000e7a02fc69081963a9c2166/687474703a2f2f7777772e776f726c64697076366c61756e63682e6f72672f77702d636f6e74656e742f7468656d65732f697076362f646f776e6c6f6164732f576f726c645f495076365f6c61756e63685f6c6f676f2e737667" height="52pt" data-canonical-src="http://www.worldipv6launch.org/wp-content/themes/ipv6/downloads/World_IPv6_launch_logo.svg"></a></th>
<th>Since v0.10 fail2ban supports the matching of IPv6 addresses.</th>
</tr>
</thead>
</table>
<p dir="auto">This README is a quick introduction to Fail2Ban. More documentation, FAQ, and HOWTOs
to be found on fail2ban(1) manpage, <a href="https://github.com/fail2ban/fail2ban/wiki">Wiki</a>,
<a href="https://fail2ban.readthedocs.io/" rel="nofollow">Developers documentation</a>
and the website: <a href="https://www.fail2ban.org/" rel="nofollow">https://www.fail2ban.org</a></p>
<h2 tabindex="-1" id="user-content-installation" dir="auto"><a href="#installation">Installation:</a></h2>
<p dir="auto">Fail2Ban is likely already packaged for your Linux distribution and <a href="https://github.com/fail2ban/fail2ban/wiki/How-to-install-fail2ban-packages">can installed with a simple command</a>.</p>
<p dir="auto">If your distribution is not listed, you can install from GitHub:</p>
<p dir="auto">Required:</p>
<ul dir="auto">
<li><a href="https://www.python.org/" rel="nofollow">Python &gt;= 3.5</a> or <a href="https://pypy.org/" rel="nofollow">PyPy3</a></li>
<li>python-setuptools, python-distutils (or python3-setuptools) for installation from source</li>
</ul>
<p dir="auto">Optional:</p>
<ul dir="auto">
<li><a href="https://github.com/seb-m/pyinotify">pyinotify &gt;= 0.8.3</a>, may require:
<ul dir="auto">
<li>Linux &gt;= 2.6.13</li>
</ul>
</li>
<li><a href="http://www.freedesktop.org/wiki/Software/systemd" rel="nofollow">systemd &gt;= 204</a> and python bindings:
<ul dir="auto">
<li><a href="https://www.freedesktop.org/software/systemd/python-systemd/index.html" rel="nofollow">python-systemd package</a></li>
</ul>
</li>
<li><a href="http://www.dnspython.org/" rel="nofollow">dnspython</a></li>
</ul>
<p dir="auto">To install:</p>
<div data-snippet-clipboard-copy-content="tar xvfj fail2ban-master.tar.bz2
cd fail2ban-master
sudo python setup.py install"><pre><code>tar xvfj fail2ban-master.tar.bz2
cd fail2ban-master
sudo python setup.py install
</code></pre></div>
<p dir="auto">Alternatively, you can clone the source from GitHub to a directory of Your choice, and do the install from there. Pick the correct branch, for example, master or 0.11</p>
<div data-snippet-clipboard-copy-content="git clone https://github.com/fail2ban/fail2ban.git
cd fail2ban
sudo python setup.py install "><pre><code>git clone https://github.com/fail2ban/fail2ban.git
cd fail2ban
sudo python setup.py install 
</code></pre></div>
<p dir="auto">This will install Fail2Ban into the python library directory. The executable
scripts are placed into <code>/usr/bin</code>, and configuration in <code>/etc/fail2ban</code>.</p>
<p dir="auto">Fail2Ban should be correctly installed now. Just type:</p>

<p dir="auto">to see if everything is alright. You should always use fail2ban-client and
never call fail2ban-server directly.
You can verify that you have the correct version installed with</p>

<p dir="auto">Please note that the system init/service script is not automatically installed.
To enable fail2ban as an automatic service, simply copy the script for your
distro from the <code>files</code> directory to <code>/etc/init.d</code>. Example (on a Debian-based
system):</p>
<div data-snippet-clipboard-copy-content="cp files/debian-initd /etc/init.d/fail2ban
update-rc.d fail2ban defaults
service fail2ban start"><pre><code>cp files/debian-initd /etc/init.d/fail2ban
update-rc.d fail2ban defaults
service fail2ban start
</code></pre></div>
<h2 tabindex="-1" id="user-content-configuration" dir="auto"><a href="#configuration">Configuration:</a></h2>
<p dir="auto">You can configure Fail2Ban using the files in <code>/etc/fail2ban</code>. It is possible to
configure the server using commands sent to it by <code>fail2ban-client</code>. The
available commands are described in the fail2ban-client(1) manpage.  Also see
fail2ban(1) and jail.conf(5)  manpages for further references.</p>
<h2 tabindex="-1" id="user-content-code-status" dir="auto"><a href="#code-status">Code status:</a></h2>
<ul dir="auto">
<li><a href="https://github.com/fail2ban/fail2ban/actions/workflows/main.yml"><img src="https://github.com/fail2ban/fail2ban/actions/workflows/main.yml/badge.svg" alt="CI"></a></li>
</ul>
<h2 tabindex="-1" id="user-content-contact" dir="auto"><a href="#contact">Contact:</a></h2>
<h3 tabindex="-1" id="user-content-bugs-feature-requests-discussions" dir="auto"><a href="#bugs-feature-requests-discussions">Bugs, feature requests, discussions?</a></h3>
<p dir="auto">See <a href="https://github.com/fail2ban/fail2ban/blob/master/CONTRIBUTING.md">CONTRIBUTING.md</a></p>
<h3 tabindex="-1" id="user-content-you-just-appreciate-this-program" dir="auto"><a href="#you-just-appreciate-this-program">You just appreciate this program:</a></h3>
<p dir="auto">Send kudos to the original author (<a href="mailto:cyril.jaquier@fail2ban.org">Cyril Jaquier</a>)
or <em>better</em> to the <a href="https://lists.sourceforge.net/lists/listinfo/fail2ban-users" rel="nofollow">mailing list</a>
since Fail2Ban is "community-driven" for years now.</p>
<h2 tabindex="-1" id="user-content-thanks" dir="auto"><a href="#thanks">Thanks:</a></h2>
<p dir="auto">See <a href="https://github.com/fail2ban/fail2ban/blob/master/THANKS">THANKS</a> file.</p>
<h2 tabindex="-1" id="user-content-license" dir="auto"><a href="#license">License:</a></h2>
<p dir="auto">Fail2Ban is free software; you can redistribute it and/or modify it under the
terms of the GNU General Public License as published by the Free Software
Foundation; either version 2 of the License, or (at your option) any later
version.</p>
<p dir="auto">Fail2Ban is distributed in the hope that it will be useful, but WITHOUT ANY
WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
PARTICULAR PURPOSE. See the GNU General Public License for more details.</p>
<p dir="auto">You should have received a copy of the GNU General Public License along with
Fail2Ban; if not, write to the Free Software Foundation, Inc., 51 Franklin
Street, Fifth Floor, Boston, MA 02110, USA</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chicago independently abolishes subminimum wage for tipped workers (120 pts)]]></title>
            <link>https://www.chicagotribune.com/politics/ct-chicago-council-votes-eliminate-lower-tipped-minimum-wage-20231006-xg5vpkqcxnfqhe5fqogxrpbcua-story.html</link>
            <guid>37794874</guid>
            <pubDate>Fri, 06 Oct 2023 19:08:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.chicagotribune.com/politics/ct-chicago-council-votes-eliminate-lower-tipped-minimum-wage-20231006-xg5vpkqcxnfqhe5fqogxrpbcua-story.html">https://www.chicagotribune.com/politics/ct-chicago-council-votes-eliminate-lower-tipped-minimum-wage-20231006-xg5vpkqcxnfqhe5fqogxrpbcua-story.html</a>, See on <a href="https://news.ycombinator.com/item?id=37794874">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>Chicago on Friday became the largest American city to independently<i> </i>require that tipped employees make a full minimum wage, following a relatively easy City Council vote that delivered one of Mayor Brandon Johnson’s biggest political wins for his progressive agenda.</p><p>In a 36-10 vote, aldermen approved the measure that advocates said was direly needed for the lowest-paid service workers and that opponents countered would backfire, causing some employees in the service industry to be paid less and lead<b> </b>to higher menu prices and staff cuts. The ordinance becomes law immediately but the full impact won’t take effect for five years.</p><p><span>[&nbsp;</span><a href="https://www.chicagotribune.com/politics/ct-tipped-worker-wage-increase-committee-vote-chicago-20230920-fc5sonq365cntibvuzwkbfeinm-story.html#nt=interstitial-manual" aria-label="Open related story">Proposal to raise Chicago’s minimum wage for tipped workers advances in City Council</a><span>&nbsp;]</span></p><p>The Friday vote was originally supposed to take place Wednesday, but a clerical error delayed the meeting. Starting next July, the gap between tipped and minimum wages will shrink from 60% to 40%. Each year after, that gap will shrink by 8% until parity is reached by July 1, 2028.</p><p>Los Angeles, which has a larger population than Chicago, already bans a subminimum wage for tipped workers but that’s under a California state law that requires employers to pay those employees the full minimum wage. Besides California, Alaska, Minnesota, Montana, Nevada, Oregon and Washington also have abolished the lower tipped wage, <a href="https://www.dol.gov/agencies/whd/state/minimum-wage/tipped">according</a> to the U.S. Department of Labor.</p><p>In a celebratory post-council news conference, Johnson said the vote made Friday an “incredible historic day.”</p><p>”The ordinance embodies Chicago’s values of uplifting working people and addressing systemic inequities in the restaurant and hospitality industry, which, in turn, will create a better economic future for tipped workers and our city,” the mayor said. “Many of the people who are standing in support with us today, these are heads of households and anchors of communities who are finally receiving a bit more of the respect and dignity that they deserve.”</p><p>Ahead of the vote, progressive aldermen stood up and shared anecdotes that fueled their decision to favor the new law on what they described as a poignant day.<b> </b>Ald. Jessie Fuentes, 26th, one of the measure’s lead sponsors, said the subminimum wage for tipped employees has long been a driver of income inequality.</p><p>She pointed to the sea of pink-clad service workers behind her who were recruited by the national One Fair Wage campaign to cheer on the ordinance.</p><p>“Today, our tipped workers will win,” Fuentes said. “Look at the room. Look at the room. Those are Black and brown faces that are asking for a raise.”</p><p>Some aldermen also lamented that the moment did not come sooner, such as when the City Council <a href="https://www.chicagotribune.com/business/ct-biz-chicago-minimum-wage-approved-20191126-esp6g6do6nhzjfl7i7yphbfmrm-story.html">raised</a> the minimum wage to $15 under former Mayor Lori Lightfoot but did not alter the pay floor for tipped workers.</p><p>Ald. Rossana Rodriguez Sanchez, 33rd, said when that vote passed four years ago a man sitting in the back of the public gallery in the council chambers yelled, “You left out tipped wage!”</p><p>“He yelled that so many times, and I felt that in my heart. I knew that that moment was an opportunity for us to do that, and we didn’t do that,” Rodriguez Sanchez said. “It took us four more years and a progressive movement to push for this and be able to pass it now. … Wherever he is, this vote is dedicated to you today.”</p><p>But Ald. Nicole Lee, 11th, said the small business owners in her ward that encompasses Chinatown — where family restaurants have served as a time-honored engine for economic mobility — implored her to oppose the measure even though they knew it likely would pass.</p><p>“My constituents there feel this is going to hurt more than it is going to help our local economy,” Lee said. “Because of that, I’m going to be a no.”</p><p>A man in the public section then cried out, “Thank you for saving my job.”</p><p>Other opponents have argued evening out the minimum wage across all industries will cause people to tip less, hurting servers’ bottom lines.</p><p>Ald. Nicholas Sposato, 38th, said instead of raising the minimum wage for tipped workers customers should be “educated” on how to tip better because, “I believe we are going to get destroyed with this.”</p><p>Ald. Daniel La Spata, 1st, who represents the neighborhoods of Wicker Park and Bucktown that are hubs for restaurants, rejected the business community’s anxieties by declaring to any servers listening in: “I don’t need to balance my bill on the backs of your poverty.”</p><p>“The sky maybe is going to fall in when we pass this ordinance, but the sky didn’t fall in when we fought for and won a $15 minimum wage,” La Spata said, before listing other pro-labor ordinances passed in Chicago. “The sky keeps on not falling. … Somehow I have a feeling that the sky is not going to fall today either.”</p><p>Johnson campaigned on the issue and this summer donned a One Fair Wage apron at a progressive conference, serving appetizers in solidarity with the conference’s catering staff.</p><p><span>[&nbsp;</span><a href="https://www.chicagotribune.com/politics/ct-tipped-minimum-wage-abolish-ordinance-deal-20230919-7g2afmgi55donobgsrzaqosoca-story.html#nt=interstitial-manual" aria-label="Open related story">Chicago could become largest US city to independently abolish tipped wage under Mayor Brandon Johnson compromise</a><span>&nbsp;]</span></p><p>The restaurant lobby, a longtime foe of the effort and similar attempts to do away with the lower tipped wage, <a href="https://www.chicagotribune.com/politics/ct-tipped-minimum-wage-abolish-ordinance-deal-20230919-7g2afmgi55donobgsrzaqosoca-story.html" target="_blank">begrudgingly accepted a deal</a> from the mayor’s administration that increased the phase-in from two years to five. That was after the head of the Illinois Restaurant Association, Sam Toia, floated a counterproposal to raise subminimum wages only at restaurants earning more than $3 million in annual revenue. That offer failed to gain traction.</p><p>“Obviously, a lot of restaurant owners, operators will tell you, the last couple of years have been really rough coming out of the pandemic, especially with double-digit inflation,” Toia said last month. “There’s only two things you can control in the restaurant industry: your product costs and your labor costs. … There could definitely be people cutting back on labor.”</p><p>However, the mayor’s floor leader, Ald. Carlos Ramirez-Rosa, 35th, has argued raising minimum pay for tipped workers is good for business.</p><p>“We have decades of research: Los Angeles, Minneapolis, cities across this nation with economies very similar to ours have already instituted One Fair Wage with tips on top,” he said during a council committee meeting<b> </b>last month. “Restaurants are opening up, restaurants are growing, restaurants are employing more workers and workers are making the same — or more — in tips.”</p><p><span>[&nbsp;</span><a href="https://www.chicagotribune.com/politics/ct-one-fair-wage-forward-city-council-1004-20231004-h2li44wyhjdixn67o27bqg5mgi-story.html#nt=interstitial-manual" aria-label="Open related story">Mayor Brandon Johnson beats back opposition, moves forward with plans to end lower minimum wage and for homeless services</a><span>&nbsp;]</span></p><p>The ordinance was originally supposed <a href="https://www.chicagotribune.com/politics/ct-one-fair-wage-forward-city-council-1004-20231004-h2li44wyhjdixn67o27bqg5mgi-story.html" target="_blank">to get a final vote on Wednesday</a>, but the city clerk’s office failed to post the item on the council’s agenda with enough advance notice, as legally mandated. A group of moderate and more conservative members tried to stall an attempt to reschedule the vote during the Wednesday council meeting but were squashed by Johnson allies.</p><p>The city’s minimum wage rate is $15.80 per hour for businesses with 21 or more workers and $15.00 per hour for those with four to 20 workers. Under the old law, tipped workers were paid 60% of the minimum wage rate and if a tipped worker’s wages with the addition of tips did<b> </b>not equal at least the full minimum wage, the employer had to make up the difference.</p><p><a href="mailto:ayin@chicagotribune.com" target="_blank"><i>ayin@chicagotribune.com</i></a></p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[X rolls out new ad format that can't be reported, blocked (114 pts)]]></title>
            <link>https://mashable.com/article/twitter-x-new-clickbait-ad-format</link>
            <guid>37794809</guid>
            <pubDate>Fri, 06 Oct 2023 19:02:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mashable.com/article/twitter-x-new-clickbait-ad-format">https://mashable.com/article/twitter-x-new-clickbait-ad-format</a>, See on <a href="https://news.ycombinator.com/item?id=37794809">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


<p>The new ads also don't disclose who the advertiser is or that they are even ads.</p>


</div><section data-ga-module="content_body">
<div>
<p><img src="https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/hero-image.fill.size_1248x702.v1696612480.jpg" alt="X logo on mobile device" width="1248" height="702" srcset="https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/hero-image.fill.size_400x225.v1696612480.jpg 400w, https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/hero-image.fill.size_800x450.v1696612480.jpg 800w, https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/hero-image.fill.size_1248x702.v1696612480.jpg 1600w" sizes="(max-width: 1280px) 100vw, 1280px"></p><p><span>Elon Musk's X is now serving users clickbait advertisements that can't be blocked or reported.</span>
<span>Credit: Thomas Trutschel/Photothek via Getty Images</span>
</p>
</div>
<article id="article" data-autopogo="">
<p><a href="https://mashable.com/article/elon-musk-removes-headlines-links-twitter-x" target="_self">X</a>, the Elon Musk-owned platform formerly known as <a href="https://mashable.com/article/twitter-x-trademark-infringement-lawsuit-x-social-media" target="_self">Twitter</a>, has begun serving its users with a weird new ad format and it's one of the company's least transparent products yet.</p><p>The rollout of these ads also provides the public with a hint regarding just how much the company is struggling to attract advertisers.</p><p>Multiple X users have reached out to Mashable over the past few days to report seeing a new type of ad in their For You feed that they had not previously come across on the platform. These new X ads don't allow users to like or retweet the ad posts. In fact, the new ad format also doesn't disclose who is behind the ad or that it is even an advertisement at all.</p><div>
<p><img src="https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-1.fill.size_2000x1432.v1696612481.jpg" alt="X ad" width="2000" height="1432" loading="lazy" srcset="https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-1.fill.size_800x573.v1696612481.jpg 800w, https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-1.fill.size_1400x1002.v1696612481.jpg 1400w, https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-1.fill.size_2000x1432.v1696612481.jpg 2000w" sizes="(max-width: 1408px) 100vw, 1408px">
</p>
<p><span>Here's X's new clickbait ads featuring chumbox content. Notice the lack of display name and handle.</span>
<span>Credit: X screenshot</span>
</p>
</div>
<p>Mashable has confirmed this ad format with numerous users from across X and have seen a variety of different ads running this bizarre new format that just consists of written copy text, a photo, and a fake avatar that's sole purpose is to make the ad look like an organically posted tweet.&nbsp;</p><p>The type of content being promoted in the ads that Mashable has viewed appear to be consistent with ads found in spammy, low quality "<a href="https://www.theawl.com/2015/06/a-complete-taxonomy-of-internet-chum/" target="_blank" title="(opens in a new window)"><u>chumbox</u></a>" advertising – typically defined as those clickbait ads found at the bottom of posts on content farm sites – made popular by native ad networks like <a href="https://www.wired.co.uk/article/fake-news-outbrain-taboola-hillary-clinton" target="_blank" title="(opens in a new window)"><u>Taboola</u></a>.&nbsp;</p><p>"This Seems Unbelievable, But Happens in Dubai Everyday" reads one ad that takes users to a third-party content mill website, overloaded with ads of its own. "These Incredibly Cool Gadgets That Are Going To Sell Out This Year. Action Now!" and "If you suffer from ringing ears (Tinnitus) you're going to love this recent breakthrough" are other examples of some of the content found in these X ads.</p><div>
<p><img src="https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-2.fill.size_2000x1374.v1696612481.jpg" alt="X ad" width="2000" height="1374" loading="lazy" srcset="https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-2.fill.size_800x550.v1696612481.jpg 800w, https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-2.fill.size_1400x962.v1696612481.jpg 1400w, https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-2.fill.size_2000x1374.v1696612481.jpg 2000w" sizes="(max-width: 1408px) 100vw, 1408px">
</p>
<p><span>Here's another example of X's shady chumbox-esque advertising.</span>
<span>Credit: X screenshot</span>
</p>
</div>
<p>Users who have seen these X ads report being taken to a third-party website in a new window upon clicking anywhere within the ad, including when they try to click on the fake avatar. There is no X post to open nor is there a user profile attached to the ad to visit. So far, Mashable has seen these ads served to users within X's mobile apps. Its unclear if the ads are also running on the web version of the platform.&nbsp;</p><p>Mashable was able to find advertisements similar to the aforementioned X ads using the same exact text copy running through ad networks on Yahoo and Taboola competitors like RevContent. Mashable could not locate this X ad format in the platform's ad campaign manager so it appears these ads are actually being served by a third-party ad provider.&nbsp;</p><p>The presence of these ads is actually quite telling about the state of advertising on Musk's social media platform.</p><blockquote>
<a href="https://twitter.com/aMarkzzz/status/1708964978315718735" target="_blank" rel="noopener" title="(opens in a new window)">
Tweet may have been deleted
</a>
</blockquote>
<h2>X turns to the chumbox amid direct ad sale decline</h2><p>Since Musk's acquisition of the company, X has <a href="https://mashable.com/article/twitter-advertisers-leaving-app-elon-musk" target="_self"><u>struggled</u></a> to <a href="https://mashable.com/article/x-twitter-brands-suspend-ads-showing-beside-nazi-content" target="_self"><u>attract</u></a> advertisers to the <a href="https://www.nytimes.com/2023/06/05/technology/twitter-ad-sales-musk.html" target="_blank" title="(opens in a new window)"><u>platform</u></a>. Half of the platform's biggest advertisers stopped running ads shortly after Musk's takeover. Furthermore, according to a <a href="https://www.mediamatters.org/twitter/linda-yaccarino-again-claims-advertisers-are-returning-x-here-are-facts" target="_blank" title="(opens in a new window)"><u>new report</u></a> from Media Matters For America, the advertisers who have returned are spending up to 90 percent less on advertising on X than they did prior to Musk acquiring the company. Another <a href="https://www.reuters.com/technology/us-ad-revenue-musks-x-declined-each-month-since-takeover-data-2023-10-04/" target="_blank" title="(opens in a new window)"><u>recent report</u></a> from Reuters found that Musk's X has faced declining revenue each and every month since he became the owner of the company.</p><p>In order to help with declining ad revenue, X has turned to partnering with third-parties within the adtech industry to sell available advertising inventory. Just last month, Google <a href="https://adage.com/article/digital-marketing-ad-tech-news/x-turns-google-programmatic-ads-timeline/2515981" target="_blank" title="(opens in a new window)"><u>announced</u></a> it would be partnering with X to sell programmatic advertising. Earlier this year, X also partnered with InMobi, a mobile-focused programmatic ad sales company.</p><div>
<p><img src="https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-4.fill.size_553x750.v1696612481.png" alt="X ad in feed" width="553" height="750" loading="lazy" srcset="https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-4.fill.size_800x1085.v1696612481.png 800w, https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-4.fill.size_1400x1899.v1696612481.png 1400w, https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-4.fill.size_2000x2713.v1696612481.png 2000w" sizes="(max-width: 1408px) 100vw, 1408px">
</p>
<p><span>This is how the new X ads look among real, organic posts in the For You feed.</span>
<span>Credit: X screenshot</span>
</p>
</div>
<p>So, what does that mean? Users are likely seeing these ads because X no longer has any direct ad inventory to serve them. This could mean that these particular users seeing these ads are not being targeted by any brands that are running ads at the moment. Or brands that are advertising on X and targeting these users have exhausted their ad spend for the moment. It's also possible that these users have blocked brand accounts that would've targeted them with ads otherwise.&nbsp;</p><p>Whatever the reason these users aren't being served ads directly from the platform, the point is that they aren't seeing them. And that means that X hasn't been able to sell enough ad space directly to brands and need to instead serve advertisements from ad networks. In turn, X makes less money as direct ad sales typically generate much more revenue for a company.</p><h2>These new clickbait X ads</h2><p>Typically, how it worked on Twitter and then on X until now, ads on the platform were just normal posts that an advertiser paid to show users in their feeds, replies, or profiles.&nbsp;</p><p>However, this new ad format completely breaks that as these ads are technically not posts, even if they somewhat look the part. All the engagement buttons on these new X ads are completely grayed out. For example, users are unable to click like, retweet, or reply. These ads cannot be clicked to open in full tweet view like every other X ad format.&nbsp;</p>
<blockquote>
<a href="https://twitter.com/lynxnoirs/status/1707947210732650682" target="_blank" rel="noopener" title="(opens in a new window)">
Tweet may have been deleted
</a>
</blockquote>
<blockquote>
<a href="https://twitter.com/flipnotemachine/status/1706550158043869572" target="_blank" rel="noopener" title="(opens in a new window)">
Tweet may have been deleted
</a>
</blockquote>
<p>This new X ad format completely lacks the three dotted icon button usually present in the upper right hand side of X posts and ads. On a normal post, that button provides users with a slew of options to report a post and mute or block an account. Without it, there are no ways for a user to report or block these types of ads that are being served to them.&nbsp;</p><p>In addition, users cannot add Community Notes to these ads either. Over the past few months, users have been utilizing Community Notes, the popular feature on the platform that allows users to add context to disinformation and other factually incorrect posts, to <a href="https://www.vice.com/en/article/7kxepa/twitter-users-are-warning-each-other-about-its-junk-ads-with-community-notes" target="_blank" title="(opens in a new window)">warn</a> others of scam ads on X.</p><p>Perhaps the biggest deviation from the regular ads on X is that these new ads have no X account attached to them at all. At least, not one that's visible to the user. There is no username or handle present on these ads. While an avatar is displayed in order to make the ad blend in with other posts on a user's feed, the image isn't a profile picture. The avatar appears to just be a cropped version of the photo included within the ad itself.&nbsp;</p><p>Without a display name or handle, it's also unclear to the user exactly who is behind the ad. The new ad format also doesn't disclose that it is an advertisement at all. There is no "promoted" or "ad" label on any of these types of ads that Mashable has seen.&nbsp;And, unlike most other websites that run chumbox clickbait advertising, X doesn't even disclose the ad network associated with these ads.</p><div>
<p><img src="https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-3.fill.size_644x750.v1696612481.png" alt="X ad in feed" width="644" height="750" loading="lazy" srcset="https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-3.fill.size_800x932.v1696612481.png 800w, https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-3.fill.size_1400x1632.v1696612481.png 1400w, https://helios-i.mashable.com/imagery/articles/07dSJUT5Ii2rhdYhDH6UoKO/images-3.fill.size_2000x2331.v1696612481.png 2000w" sizes="(max-width: 1408px) 100vw, 1408px">
</p>
<p><span>Another example of how these new X ads look like next to real posts in the feed.</span>
<span>Credit: X screenshot</span>
</p>
</div>
<p>Mashable <a href="https://mashable.com/article/twitter-x-removes-ad-labels-for-some-users" target="_self"><u>previously reported</u></a> earlier this month how these important advertisement disclosure labels were also missing from the traditional X ad formats for some users. However, even in those cases, a user could click the options button to report the post and the platform would inform the user it was an advertisement by providing the option to tell X it was "not interested" in the ad. There is no such option on this new ad format as the three dotted button is missing from these ads. One other way to tell an X ad from a regular post is that ads don't include a timestamp on the posts. The new ad format also excludes a timestamp.</p><p>As previously mentioned, Mashable confirmed this ad format with numerous users from across X and have seen a variety of different ads running this new format. Mashable has also found <a href="https://twitter.com/aMarkzzz/status/1708964978315718735" target="_blank" title="(opens in a new window)">other users</a> who have <a href="https://twitter.com/lynxnoirs/status/1707947210732650682" target="_blank" title="(opens in a new window)">shared</a> via their <a href="https://twitter.com/flipnotemachine/status/1706550158043869572" target="_blank" title="(opens in a new window)">own</a> social media accounts that they have <a href="https://twitter.com/nonfatdairy/status/1706631902365446549" target="_blank" title="(opens in a new window)">also seen </a>these ads in <a href="https://twitter.com/cgsakurapink/status/1706751390008459548" target="_blank" title="(opens in a new window)">their feed</a>. It's unclear if X is just testing this format at this time.</p><p>The new ad format arrives to X around the same time the company made another decision that makes the platform less transparent. Earlier this week, under a directive from Musk himself, <a href="https://mashable.com/article/elon-musk-removes-headlines-links-twitter-x" target="_self"><u>X removed headlines</u></a> and other context from links shared to the platform. Instead of seeing the title of an article or other link posted to X, users now simply see an embed of the header image with the corresponding domain name displayed like a watermark-like overlay in the corner of the photo. Musk said he made the change to how links were displayed because he didn't like the way it previously looked. </p>

</article>
</section><div x-data="window.newsletter()" x-init="init()" data-ga-impression="" data-ga-category="newsletters" data-ga-module="footer_nl_signup" data-ga-label="Top Stories">

<p>
This newsletter may contain advertising, deals, or affiliate links. Subscribing to a newsletter indicates your consent to our <a href="https://www.ziffdavis.com/terms-of-use" target="_blank" rel="noopener" title="(opens in a new window)">Terms of Use</a> and <a href="https://www.ziffdavis.com/ztg-privacy-policy" target="_blank" rel="noopener" title="(opens in a new window)">Privacy Policy</a>. You may unsubscribe from the newsletters at any time.
</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Genetics firm 23andMe says user data stolen in credential stuffing attack (297 pts)]]></title>
            <link>https://www.bleepingcomputer.com/news/security/genetics-firm-23andme-says-user-data-stolen-in-credential-stuffing-attack/</link>
            <guid>37794379</guid>
            <pubDate>Fri, 06 Oct 2023 18:29:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bleepingcomputer.com/news/security/genetics-firm-23andme-says-user-data-stolen-in-credential-stuffing-attack/">https://www.bleepingcomputer.com/news/security/genetics-firm-23andme-says-user-data-stolen-in-credential-stuffing-attack/</a>, See on <a href="https://news.ycombinator.com/item?id=37794379">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><img alt="DNA" height="900" src="https://www.bleepstatic.com/content/hl-images/2021/11/30/dna.jpg" width="1600"></p>
<p>23andMe has confirmed to BleepingComputer that it is aware of user data from its platform circulating&nbsp;on hacker forums and attributes the leak to a credential-stuffing attack.</p>
<p>23andMe is a U.S. biotechnology and genomics firm offering genetic testing services to customers who send a saliva sample to its labs and get back an ancestry and genetic predispositions report.</p>
<p>Recently, a threat actor leaked samples of data&nbsp;that was allegedly stolen from a genetics firm and, a few days later, offered to sell data packs belonging to 23andMe customers.</p>
<div>
<figure><img alt="Initial leak of genetic data" height="600" src="https://www.bleepstatic.com/images/news/u/1220909/2023/Databases/11/leak.png" width="836"><figcaption><strong>Initial leak of genetic data</strong><br><em>Source: BleepingComputer</em></figcaption></figure></div>
<p>The initial data leak was limited, with the threat actor releasing 1 million lines of data for Ashkenazi people. However, on October 4, the threat actor offered to sell data profiles in bulk for $1-$10 per 23andMe account, depending on how many were purchased.</p>
<div>
<figure><img alt="Selling stolen genetic data profiles in bulk" height="477" src="https://www.bleepstatic.com/images/news/u/1220909/2023/Databases/11/sale.png" width="1023"><figcaption><strong>Selling stolen genetic data profiles in bulk</strong><br><em>Source:&nbsp;BleepingComputer</em></figcaption></figure></div>
<p>A 23andMe spokesperson confirmed the data is legitimate&nbsp;and told BleepingComputer that the threat actors used exposed credentials from other breaches to access 23andMe accounts and steal the sensitive data.</p>
<p>"We were made aware that certain 23andMe customer profile information was compiled through access to individual 23andMe.com accounts," stated 23andMe's spokesperson</p>
<p>"We do not have any indication at this time that there has been a data security incident within our systems."</p>
<p>"Rather, the preliminary results of this investigation suggest that the login credentials used in these access attempts may have been gathered by a threat actor from data leaked during incidents involving other online platforms where users have recycled login credentials."</p>
<p>The information that has been exposed from this incident includes full names, usernames, profile photos, sex, date of birth, genetic ancestry results, and geographical location.</p>
<p>BleepingComputer has also learned that the number of accounts sold by the cybercriminal does not reflect the number of 23andMe accounts breached using exposed credentials.</p>
<p>The compromised accounts had opted into the platform's 'DNA Relatives' feature, which allows users to find genetic relatives and connect with them.</p>
<p>The threat actor accessed a small number of 23andMe accounts and then scraped the data of their DNA Relative matches, which shows how opting into a feature can have unexpected privacy consequences.</p>
<p>23andMe told BleepingComputer that the platform offers two-factor authentication as an additional account protection measure and <a href="https://customercare.23andme.com/hc/en-us/articles/360034119874-Adding-2-Step-Verification-to-Your-23andMe-Account" target="_blank" rel="nofollow noopener">encourages</a> all users to enable it.</p>
<p>Users should refrain from reusing passwords and consistently employ strong, distinct credentials for every online account they have.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The ozone hole above Antarctica has grown to three times the size of Brazil (110 pts)]]></title>
            <link>https://www.space.com/ozone-hole-antarctica-three-times-size-of-brazil</link>
            <guid>37793941</guid>
            <pubDate>Fri, 06 Oct 2023 18:00:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.space.com/ozone-hole-antarctica-three-times-size-of-brazil">https://www.space.com/ozone-hole-antarctica-three-times-size-of-brazil</a>, See on <a href="https://news.ycombinator.com/item?id=37793941">Hacker News</a></p>
<div id="readability-page-1" class="page"><article aria-label="article" data-id="MwoBrj6xSd3LoxbyTS4zzW">
<header>
<nav aria-label="Breadcrumbs">
<ol>
<li>
<a href="https://www.space.com/news" aria-label="Return to News">News</a>
</li>
<li>
<a href="https://www.space.com/science-astronomy" aria-label="Return to Science &amp; Astronomy">Science &amp; Astronomy</a>
</li>
</ol>
</nav>


</header>
<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture><source type="image/webp" alt="A map of the ozone hole on Sept. 16, 2023." onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-1920-80.jpg.webp 1920w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE.jpg"><source type="image/jpeg" alt="A map of the ozone hole on Sept. 16, 2023." onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-1920-80.jpg 1920w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE.jpg"><img src="https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-320-80.jpg" alt="A map of the ozone hole on Sept. 16, 2023." onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE-1920-80.jpg 1920w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE.jpg"></picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/FHSnfv6hdmdcFgnBrwuzHE.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span>A map of the ozone hole on Sept. 16, 2023.</span>
<span itemprop="copyrightHolder">(Image credit: NASA Ozone Watch)</span>
</figcaption>
</div>

<div id="article-body">
<p>Just as the <a href="https://www.space.com/sea-ice-antarctica-hits-record-low-2023-satellite-data"><u>sea ice around Antarctica</u></a> grows and retreats each year, so does the ozone hole above the continent. And this year, that hole has grown a lot.&nbsp;</p><p>Observations from the European Space Agency's (ESA) <a href="https://www.space.com/copernicus-program"><u>Copernicus Sentinel-5P satellite </u></a>indicate the ozone hole reached approximately 10 million square miles (26 million square kilometers) in area on Sept. 16, 2023 —&nbsp;making it one of the largest seasonal holes ever observed. The true largest ozone hole maximum occurred in 2000, when the chasm reached nearly 11 million square miles (28.4 million square kilometers) in area.</p><p>Ozone is a naturally occurring gas, and there's a layer of it in the stratosphere that protects us from the <a href="https://www.space.com/58-the-sun-formation-facts-and-characteristics.html"><u>sun's</u></a> ultraviolet, or UV, rays. In 1985, a hole in the ozone layer was discovered above Antarctica&nbsp;— and later connected to human use of carbon-depleting substances. Since then, we've banned the use of those substances and have been monitoring the hole's size.</p><p><strong>Related: </strong><a href="https://www.space.com/antarctic-ozone-hole-early-hunga-tonga">The ozone hole above Antarctica opened early this year. Huge Tonga undersea volcano eruption may be to blame</a></p><p>The ozone hole still grows and shrinks seasonally, however, due to temperature changes and wind conditions in the stratosphere, reaching a maximum between mid-September and mid-October. "Our operational ozone monitoring and forecasting service shows that the 2023 ozone hole got off to an early start and has grown rapidly since mid-August," Antje Inness, Copernicus Atmosphere Monitoring Service senior scientist, said in a <a href="https://www.esa.int/Applications/Observing_the_Earth/Copernicus/Sentinel-5P/Ozone_hole_goes_large_again" target="_blank" data-url="https://www.esa.int/Applications/Observing_the_Earth/Copernicus/Sentinel-5P/Ozone_hole_goes_large_again"><u>statement</u></a>.&nbsp;</p><p>One possible reason for the higher-than-normal growth is the <a href="https://www.space.com/hunga-tonga-will-make-ozone-hole-larger"><u>Hunga Tonga volcanic eruption</u></a> in January 2022, which introduced massive quantities of water vapor into the air. “The water vapor could have led to the heightened formation of polar stratospheric clouds, where chlorofluorocarbons (CFCs) can react and accelerate ozone depletion," said Inness.</p><p>Yet despite experiencing large seasonal growth this year, the ozone hole is still decreasing in size overall. "Based on the Montreal Protocol and the decrease of anthropogenic ozone-depleting substances, scientists currently predict that the global ozone layer will reach its normal state again by around 2050," said Claus Zehner, ESA's mission manager for Copernicus Sentinel-5P.</p>
</div>
<p><em><a href="https://forums.space.com/">Join our Space Forums</a> to keep talking space on the latest missions, night sky and more! And if you have a news tip, correction or comment, let us know at: <a href="mailto:community@space.com">community@space.com.</a></em></p>
<div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent"><section><p>Breaking space news, the latest updates on rocket launches, skywatching events and more!</p></section></div>
<div id="slice-container-authorBio"><p>Space.com contributing writer Stefanie Waldek is a self-taught space nerd and aviation geek who is passionate about all things spaceflight and astronomy. With a background in travel and design journalism, as well as a Bachelor of Arts degree from New York University, she specializes in the budding space tourism industry and Earth-based astrotourism. In her free time, you can find her watching rocket launches or looking up at the stars, wondering what is out there. Learn more about her work at <a href="https://mailtrack.io/trace/link/841a96809cf8444a85db7a2b318410433580a8f6?url=https%3A%2F%2Fwww.stefaniewaldek.com&amp;userId=2756587&amp;signature=ba54abdc159873b3" target="_blank">www.stefaniewaldek.com</a>.</p></div>


</section>




<div id="slice-container-relatedArticles"><p><h5>Most Popular</h5></p></div>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AMD may get across the CUDA moat (435 pts)]]></title>
            <link>https://www.hpcwire.com/2023/10/05/how-amd-may-get-across-the-cuda-moat/</link>
            <guid>37793635</guid>
            <pubDate>Fri, 06 Oct 2023 17:35:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.hpcwire.com/2023/10/05/how-amd-may-get-across-the-cuda-moat/">https://www.hpcwire.com/2023/10/05/how-amd-may-get-across-the-cuda-moat/</a>, See on <a href="https://news.ycombinator.com/item?id=37793635">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p><span data-preserver-spaces="true">When discussing GenAI, the term “GPU” almost always enters the conversation and the topic often moves toward performance and <a href="https://www.hpcwire.com/2023/07/13/the-great-gpu-squeeze-is-upon-us/">access</a>. Interestingly, the word “GPU” is assumed to mean “Nvidia” products. (As an aside, the popular Nvidia hardware used in GenAI are not technically Graphical Processing Units. I prefer SIMD units.)</span></p>
<p><span data-preserver-spaces="true">The association of GenAI and GPUs with Nvidia is no accident. Nvidia has always recognized the need for tools and applications to help grow its market. They have created a very low barrier to getting software tools (e.g., CUDA) and optimized libraries (e.g., cuDNN) for Nvidia hardware. Indeed, Nvidia is known as a hardware company, but as Bryan Catanzaro, VP of Applied Deep Learning Research, Nvidia has<a href="https://www.deeplearning.ai/blog/working-ai-at-the-office-with-vp-of-applied-deep-learning-research-bryan-catanzaro"> stated</a> ” Many people don’t know this, but Nvidia has more software engineers than hardware engineers.”</span></p>
<p><span data-preserver-spaces="true">As a result, Nvidia has built a powerful software “moat” around their hardware. While CUDA is not open source, it is freely available and under the firm control of Nvidia. While this situation has benefited Nvidia (As it should. They invested time and money into CUDA), it has created difficulties for those companies and users that want to grab some of the HPC and GenAI market with alternate hardware.</span></p>
<h3><span data-preserver-spaces="true">Building on the Castle Foundation</span></h3>
<p><span data-preserver-spaces="true">The number of foundational models developed for GenAI continues to grow. Many of these are “open source” because they can be used and shared freely. (For example, the <a href="https://ai.meta.com/llama">Llama foundational model</a> from Meta) In addition, they require a large number of resources (both people and machines) to create and are limited mainly to the hyperscalers (AWS, Microsoft Azure, Google Cloud, Meta Platforms, and Apple) that have huge amounts of GPUs available, In addition to the hyperscalers, other companies have invested in hardware (i.e. purchased a massive amount of GPUs) to create their own foundational models.</span></p>
<p><span data-preserver-spaces="true">From a research perspective, the models are interesting and can be used for a variety of tasks; however, the expected use and need for even more GenAI computing resources is two fold;</span></p>
<ol>
<li><span data-preserver-spaces="true">Fine-tuning — Adding domain-specific data to foundational models to make it work for your use case.</span></li>
<li><span data-preserver-spaces="true">Inference – Once the model is fine-tuned, it will require resources when used (i.e., asked questions).</span></li>
</ol>
<p><span data-preserver-spaces="true">These tasks are not restricted to hyperscalers and will need accelerated computing, that is, GPUs. The obvious solution is to buy more “unavailable” Nvidia GPUs, and AMD is ready and waiting now that the demand has far outstripped the supply. To be fair, Intel and some other companies are also ready and waiting to sell into this market. The point is that GenAI will continue to squeeze GPU availability as fine-tuning and inference become more pervasive, and any GPU (or accelerator) is better than no GPU.</span></p>
<p><span data-preserver-spaces="true">Moving away from Nvidia hardware suggests that other vendor GPUs and accelerators must support CUDA to run many of the models and tools. AMD has made this possible with <a href="https://www.amd.com/system/files/documents/porting-cuda-to-hip.pdf">HIP CUDA conversion tool</a>; however, the best results often seem to use the native tools surrounding the Nvidia castle.</span></p>
<h3><span data-preserver-spaces="true">The PyTorch Drawbridge</span></h3>
<p><span data-preserver-spaces="true">In the HPC sector, CUDA-enabled applications rule the GPU-accelerated world. Porting codes can often realize a speed-up of 5-6x when using a GPU and CUDA. (Note: Not all codes can achieve this speed up, and some may not be able to use the GPU hardware.) However, in GenAI, the story is quite different.</span></p>
<p><span data-preserver-spaces="true">Initially, TensorFlow was the tool of choice for creating AI applications using GPUs. It works both with CPUs and was accelerated with CUDA for GPUs. This situation is changing rapidly.</span></p>
<p><span data-preserver-spaces="true">An alternative to TensorFlow is PyTorch, an open-source machine learning library for developing and training neural network-based deep learning models. Facebook’s AI research group primarily develops it.</span></p>
<p><span data-preserver-spaces="true">In a recent <a href="https://www.assemblyai.com/blog/pytorch-vs-tensorflow-in-2023/">blog post</a> by Ryan O’Connor, a Developer Educator at <a href="https://www.assemblyai.com/">AssemblyAI</a> notes that the popular site </span><a href="https://huggingface.co/?ref=assemblyai.com" target="_blank" rel="noopener"><span data-preserver-spaces="true">HuggingFace</span></a><span data-preserver-spaces="true">, (that allows users to download and incorporate trained and tuned state of the art models into application pipelines with just a few lines of code), 92% of models available are PyTorch exclusive.</span></p>
<p><span data-preserver-spaces="true">In addition, as shown in Figure One, a comparison of Machine Learning papers shows a significant trend toward PyTorch and away from TensorFlow.</span></p>
<figure id="attachment_165049" aria-describedby="caption-attachment-165049"><img decoding="async" loading="lazy" src="https://www.hpcwire.com/wp-content/uploads/2023/10/PyTorch-TF-trends-300x178.png" alt="" width="556" height="330" srcset="https://www.hpcwire.com/wp-content/uploads/2023/10/PyTorch-TF-trends-300x178.png 300w, https://www.hpcwire.com/wp-content/uploads/2023/10/PyTorch-TF-trends-150x89.png 150w, https://www.hpcwire.com/wp-content/uploads/2023/10/PyTorch-TF-trends-600x355.png 600w, https://www.hpcwire.com/wp-content/uploads/2023/10/PyTorch-TF-trends.png 709w" sizes="(max-width: 556px) 100vw, 556px"><figcaption id="caption-attachment-165049">Figure One: Percentage of papers that utilize PyTorch, TensorFlow, or another framework over time, with data aggregated quarterly, from late 2017, Source: assemblyai.com.</figcaption></figure>
<p><span data-preserver-spaces="true">Of course, underneath PyTorch are calls to CUDA, but that is not required because PyTorch insulates the user from the underlying GPU architecture. There is also a version of <a href="https://rocm.docs.amd.com/en/latest/how_to/pytorch_install/pytorch_install.html">PyTorch</a> that uses AMD <a href="https://en.wikipedia.org/wiki/ROCm">ROCm</a>, an open-source software stack for AMD GPU programming. Crossing the CUDA moat for AMD GPUs may be as easy as using PyTorch.<br>
</span></p>
<h3><span data-preserver-spaces="true">Instinct for Inference</span></h3>
<p><span data-preserver-spaces="true">In both HPC and GenAI, the Nvidia 72-core ARM-based <a href="https://www.hpcwire.com/2023/09/28/nvidia-delivering-new-options-for-mlperf-and-hpc-performance/">Grace-Hopper superchip</a> with a shared memory H100 GPU (and also the 144-core Grace-Grace version) is highly anticipated. All Nvidia released benchmarks thus far indicate much better performance than the traditional server where the GPU is attached and accessed over the PCIe bus. Grace-Hopper represents an optimized hardware for both HPC and GenAI. It also is expected to find wide use in both fine-tuning and inference. Demand is expected to be high.</span></p>
<p><span data-preserver-spaces="true">AMD has had shared memory CPU-GPU designs since 2006 (AMD acquired graphics card company ATI in 2006). Beginning as the “Fusion” brand many AMD x86_64 processors are now implemented as a combined CPU/GPU called an Accelerated Processing Unit (<a href="https://en.wikipedia.org/wiki/AMD_APU">APU</a>).</span></p>
<p><span data-preserver-spaces="true">The upcoming Instinct MI300A processor (APU) from AMD will offer competition for Grace-Hopper superchip. It will also power the forthcoming <a href="https://www.hpcwire.com/2022/06/21/amds-mi300-apus-to-power-exascale-el-capitan-supercomputer/">El Capitan at Lawrence Livermore National Laboratory</a>. The Integrated MI300A will provide up to 24 Zen4 cores in combination with a CDNA 3 GPU Architecture </span><span data-preserver-spaces="true">and up to 192 GB of HBM3 memory, providing uniform access memory for all the CPU and GPU cores. The chip-wide cache-coherent memory reduces data movement between the CPU and GPU, eliminating the PCIe bus bottleneck and improving performance and power efficiency.</span></p>
<p><span data-preserver-spaces="true">AMD is readying the Instinct MI300A for the upcoming inference market. As stated by AMD CEO Lisa Su in a <a href="https://finance.yahoo.com/news/amd-lisa-su-ready-crash-150000172.html">recent article on Yahoo!Finance</a>. “We actually think we will be the industry leader for inference solutions because of some of the choices that we’ve made in our architecture.”</span></p>
<p><span data-preserver-spaces="true">For AMD and many other hardware vendors, PyTorch has dropped the drawbridge on the CUDA moat around the foundational models. AMD has the Instinct MI3000A battle wagon ready to go. The hardware battles for the GenAI market will be won by performance, portability, and availability. The AI day is young.</span></p>
							<div>
						<p><span>Sectors:</span>
						<a href="https://www.hpcwire.com/sector/academia-research/" rel="tag">Academia &amp; Research</a>, <a href="https://www.hpcwire.com/sector/community/" rel="tag">Community</a>, <a href="https://www.hpcwire.com/sector/entertainment/" rel="tag">Entertainment</a>, <a href="https://www.hpcwire.com/sector/financial-services/" rel="tag">Financial Services</a>, <a href="https://www.hpcwire.com/sector/government/" rel="tag">Government</a>, <a href="https://www.hpcwire.com/sector/life-sciences/" rel="tag">Life Sciences</a>, <a href="https://www.hpcwire.com/sector/manufacturing/" rel="tag">Manufacturing</a>, <a href="https://www.hpcwire.com/sector/oil-gas/" rel="tag">Oil &amp; Gas</a>, <a href="https://www.hpcwire.com/sector/retail/" rel="tag">Retail</a>, <a href="https://www.hpcwire.com/sector/semiconductor/" rel="tag">semiconductor</a>, <a href="https://www.hpcwire.com/sector/space-physics/" rel="tag">Space &amp; Physics</a>, <a href="https://www.hpcwire.com/sector/weather-climate/" rel="tag">Weather &amp; Climate</a>					</p></div><!-- .entry-utility -->
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Exploratory data analysis for humanities data (141 pts)]]></title>
            <link>https://awk.dev/eda.html</link>
            <guid>37792916</guid>
            <pubDate>Fri, 06 Oct 2023 16:31:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://awk.dev/eda.html">https://awk.dev/eda.html</a>, See on <a href="https://news.ycombinator.com/item?id=37792916">Hacker News</a></p>
<div id="readability-page-1" class="page">

<h2>Exploratory Data Analysis for Humanities Data</h2>

<h5>by Brian Kernighan</h5>

<p> <span size="-1"> Updated
Sun Sep 10 13:58:41 EDT 2023
 </span>

</p><h4>Introduction</h4>

In the spring of 2023, I co-taught a course called
 <a href="https://humstudies.princeton.edu/courses/literature-as-data/">
 <i>Literature as Data</i></a> with my friend and colleague
 <a href="https://english.princeton.edu/people/meredith-martin">Meredith Martin</a>,
professor of English at Princeton, and director of the
 <a href="https://cdh.princeton.edu/">Center for Digital Humanities</a>.

<p> The course was very much an experiment, an attempt to combine
literary study with computing.  The 17 surviving students were largely sophomores.
About two thirds of them were hard-core humanities majors; the rest were
potential or actual CS majors or other STEM concentrators.  The class
met once a week for three hours, 12 weeks in all.

</p><p> One of the goals of the course was to try to teach enough computing 
to a mostly non-technical and definitely not computer-experienced
population that they could use computers to do an interesting and new
(to them) exploration of some dataset that they found intriguing.

</p><p> After much discussion, Meredith and I decided that for the
programming aspects, we would devote half of each class meeting to a
"studio" where I would lead the students through hands-on computing
exercises on some small dataset, followed by having the students do
similar exercises on larger datasets outside the class.

</p><p> We planned to spend one week on Unix file system and command-line
basics, a week on grep and similar tools (including a real text editor),
a week on Awk, and a couple of weeks on Python.  Not surprisingly,
everything took longer than expected, and a fair number of students
struggled mightily in spite of help from their peers, Meredith and
myself, and two exceptional colleagues from the CDH, Sierra Eckert and Ryan Heuser.

</p><p> More about the course can be found elsewhere (at least when we get
around to writing it).  The course had a web site at
 <a href="http://www.hum307.com/">hum307.com</a>, though after a
while we stopped using that in favor of Google Docs -- information
was spread out over too many sites, and in addition we had to limit
access since some of our datasets were not public.

</p><h4> Awk vs Pandas </h4>

Arguably, most humanities computing uses Python and
the Pandas library to analyze structured data that often began life
as a CSV file.  If you're looking for a single language solution,
this is an excellent way to go.  But in my experience, admittedly
biased, Unix command-line tools and Awk can be especially
useful in the initial stages of exploring a new dataset.  They are
better at counting things, looking for anomalies and outliers,
and coping with data that isn't quite in the right format.
And, again a biased view, looping over a set of input lines seems
more natural than the dataframe selectors that Pandas favors.

<h4> Awk for EDA </h4>

<p> The purpose of this essay is to talk about how we used Awk in a
different EDA setting from the examples in the book.  In keeping with
the "literature" theme of the course, in the first few weeks we asked
students to look at poetry, specifically the <i>Sonnets from the
Portuguese</i> by Elizabeth Barrett Browning, and Shakespeare's sonnets.
We used grep and wc to count things like the number of times specific
words appeared, and also to observe something unexpected: even though
sonnets always have 14 lines, Shakespeare's Sonnet 126 has only 12
lines, and Sonnet 99 has 15 lines.  This was a good lesson about
literature but also about how real data does not always behave as
expected.

</p><p> This essay parallels the EDA discussion in Chapter 3 of the new Awk
book, but using different data, a metadata file about 18-th century
sonnets originally curated by Professor
 <a href="https://english.stanford.edu/people/mark-algee-hewitt"> Mark Algee-Hewitt</a>
of the Stanford Literary Lab.  We are very grateful to Mark for
kindly allowing us to use this metadata for the class and for this
page.

</p><p>
 <a href="https://www.hum307.com/studio3.html">What we did in class</a>
and the outside class exercises
can be found at <tt>hum307.com</tt>.


</p><p> The metadata file is <a href="https://awk.dev/18.csv">18.csv</a>.  The name is
not strictly accurate: we converted the original CSV into a file
with fields separated by slashes so that it would work with any version
of Awk.  We also removed some attributes from Mark's original dataset,
leaving us with 7 columns.

</p><pre>$ wc 18.csv
     508    3499   36876 18.csv
$ sed 1q 18.csv
author_dob/author_dod/author_fname/author_lname/num_lines/title_main/title_sub
$
</pre>

<p> Using the head-tail code of Section 2.2 of the book, we can look at the start
and end of the contents:

</p><pre>$ headtail 18.csv
author_dob/author_dod/author_fname/author_lname/num_lines/title_main/title_sub
1771/1798/E. H. (Elihu Hubbard)/Smith/8/SONNET I./Sent to Miss  , with a Braid of Hair.
1771/1798/E. H. (Elihu Hubbard)/Smith/8/SONNET II./Sent to Mrs.  , with a Song.
...
1740/1809/Hugh/Downman/14/SONNET II./[Though here almost eternal Winter reigns]
1740/1809/Hugh/Downman/14/SONNET III./[When Recollection stirs up in the mind]
1740/1809/Hugh/Downman/14/SONNET IV./[Now is the feudal vassalage destroy'd]
$
</pre>

Notice that the first sonnets only have 8 lines, echoing the observation above.


<h4> Validation </h4>

The first step is data validation: does the data satisfy basic
criteria like the right number of fields in each record.
In a separate command, we can look at the distribution of
number of lines in each sonnet:

<pre>$ awk -F/ '{print NF}' 18.csv | sort -u
7
$ awk -F/ '{print $5}' 18.csv | sort | uniq -c | sort -nr
 483 14
  11 8
   3 15
   2 12
   1 num_lines
   1 68
   1 66
   1 55
   1 54
   1 40
   1 28
   1 24
   1 123
$
</pre>

<p> This is a bit surprising: although 95% of the sonnets have the
standard 14 lines, 8 lines is not uncommon and some are remarkably long.
I'm no scholar, so I don't know what makes these "sonnets" as opposed to
some other poetic form.

</p><p> Maybe printing something about the longer ones might provide more
insight?  We'll exclude the header line too.

</p><pre>$ awk -F/ 'NF &gt; 1 &amp;&amp; $5 &gt; 14' 18.csv
1729/1777/William/Dodd/15/SONNET./OCCASIONED BY HEARING A YOUNG LADY SING SPENSER'S AMORETTI, &amp;c. SET TO MUSIC BY DR. GREENE.
1749/1806/Charlotte Turner/Smith/40/ODE TO DESPAIR./FROM THE NOVEL OF EMMELINE.
1749/1806/Charlotte Turner/Smith/68/ELEGY./[‘Dark gathering clouds involve the threatening skies]
1749/1806/Charlotte Turner/Smith/24/SONG./FROM THE FRENCH OF CARDINAL BERNIS.
1749/1806/Charlotte Turner/Smith/123/THE ORIGIN OF FLATTERY./
1749/1806/Charlotte Turner/Smith/54/THE PEASANT OF THE ALPS./FROM THE NOVEL OF CELESTINA.
1749/1806/Charlotte Turner/Smith/55/THIRTY-EIGHT./ADDRESSED TO MRS. HY.
1749/1806/Charlotte Turner/Smith/28/VERSES/INTENDED TO HAVE BEEN PREFIXED TO THE NOVEL OF EMMELINE, BUT THEN SUPPRESSED.
_/_/G./Bent/66/To the SAME,/On receiving his Poems to Thespia with a Sonnet prefixed.
1735/1779/John/Langhorne/15/SONNET CLXXIX./
1735/1788/William Julius/Mickle/15/SONNET TO VASCO DE GAMA: FROM TASSO./
</pre>

<p> This output suggests a variety of other questions and potential issues.
Charlotte Turner Smith wrote the majority of the long sonnets,
including the extreme outlier with 123 lines.
How many did she write overall?

</p><pre>$ grep Charlotte.Turner 18.csv | wc
     101     941    8955
$
</pre>

<p> She certainly was prolific, representing nearly 20% of the data.  
This raises some other questions for scholars, in particular, how
were these sonnets selected and how representative are they?  

</p><p> Here are some commands
to investigate the authors further.  For example, if we do a straightforward
display of unique author names:

</p><pre>$ awk -F/ '{print $3, $4}' 18.csv | uniq | sed 10q  # display the first 10 lines
author_fname author_lname
E. H. (Elihu Hubbard) Smith
M. F. Cogswell
E. H. (Elihu Hubbard) Smith
M. F. Cogswell
John Bampfylde
Thomas Edwards
William Cowper
William Dodd
Thomas Edwards
</pre>

we see that records for at least three authors are not contiguous, as we
might naively have expected.

This raises a new question: what is the order of the records?

<p> How many unique authors are there, and how much did they write?

</p><pre>$ awk -F/ '{print $4 ", " $3}' 18.csv | sort | uniq -c | sort -n
   1 Anon., _
   1 Anstey, Christopher
   1 Bent, G.
   1 Bishop, Samuel
   1 Bradford, A. M.
     ...
  23 Russell, Thomas
  38 Downman, Hugh
  50 Edwards, Thomas
 101 Smith, Charlotte Turner
 103 Seward, Anna
</pre>

<p> There are 42 distinct authors; the display above shows a few of the 14
singletons, and the five most prolific.  Interestingly, the top two are
women.  Guessing from names, there are only a handful of other female
authors.  One might wonder why over 40% of the sonnets are by two women.

How the data was created is a very important consideration for any
dataset, and particularly for data in the humanities.  As Meredith puts
it, <b>there is no such thing as raw data</b>; all datasets are the result of a
selection and curation process.  Historically, this has often been to
the detriment of some classes of authors.

</p><p> As a peripheral question, how many lines did Anna Seward and
Charlotte Turner Smith write?

</p><pre>awk -F/ '/Anna/ { anna += $5 }; /Charlotte/ { char += $5 }; END {print anna, char}' 18.csv
1456 1706
</pre>

Seward wrote fewer lines because all her sonnets were 14 lines long.

<h4>When did they live and die?</h4>

The first two fields are the birth and death dates for each author,
so we can explore questions about the ages of the authors.

The age is just <tt>$2-$1</tt>:

<pre>$ awk -F/ '{age[$3 " " $4] = $2 - $1}
    END {for (i in age) print age[i], i}' 18.csv | sort -n
-1807 M. F. Cogswell
0 A. M. Bradford
0 G. Bent
0 J. Cole
0 R. Hole
0 _ Anon.
0 author_fname author_lname
23 Henry Headley
...
79 John, Mrs. Hunter
81 Christopher Anstey
81 Thomas James Mathias
83 Anne MacVicar Grant
84 William Crowe
88 William Lisle Bowles
</pre>

<p> This tells us pretty clearly that the dates need to be studied further,
most easily by looking for the ages that are zero or negative:

</p><pre>$ awk -F/ '$2-$1 &lt;= 0' 18.csv
1807fl.//M. F./Cogswell/8/SONNET,/Written after hearing a SONG sung by several SISTERS.
1807fl.//M. F./Cogswell/8/THE SMILE./SONNET TO CAROLINE.
_/_/_/Anon./14/SONNET./
_/_/A. M./Bradford/14/To the SAME./
_/_/J./Cole/14/To the SAME./
_/_/G./Bent/66/To the SAME,/On receiving his Poems to Thespia with a Sonnet prefixed.
_/_/R./Hole/14/To the SAME,/On his Poems addressed to Thespia.
</pre>

<p> What do we do about entries like R. Hole and the often prolific
Anon, whose date fields are marked with <tt>_</tt>?

</p><p> What's with M. F. Cogswell?  He flourished around 1807, with two
8-line sonnets.  Actually, this entry shows one way in which Awk differs
from Python, often usefully.  When converting an arbitrary string to a
number, Awk uses the longest prefix that looks like a number, so
<tt>1807fl.</tt> has numeric value 1807; Awk processes that and
carries on.  Python, by contrast, will
throw an exception that, unless explicitly caught, will terminate execution.

</p><p> Neither of these deals with the real issue, which is that the data
is incomplete so an age computation isn't possible.

One simple solution, appropriate when unknown dates are
a small fraction of the data, is to ignore those records.
Regular expressions are the easiest way to select the good bits
or reject the bad ones:

</p><pre>$ awk -F/ '$1 ~ /^[0-9]+$/ &amp;&amp; $2 ~ /^[0-9]+$/ {print $2-$1, $3, $4}' 18.csv | uniq | sort -n | uniq
23 Henry Headley
25 Richard Gall
26 Thomas Russell
27 E. H. (Elihu Hubbard) Smith
37 Robert Burns
...
79 John, Mrs. Hunter
81 Christopher Anstey
83 Anne MacVicar Grant
84 William Crowe
88 William Lisle Bowles
</pre>

Rather than repeating the test over and over again,
we could collect all the lines that have valid dates in a new
temporary file, then do some further computations on that.

<pre>$ awk -F/ '$1 ~ /^[0-9]+$/ &amp;&amp; $2 ~ /^[0-9]+$/' 18.csv &gt;temp
$ wc temp
     486    3350   35265 temp
</pre>

<p> After that, we can compute the average age, and determine
the youngest and oldest.

</p><pre>$ awk -F/ '{ ages = ages + $2 - $1 } # add up all the ages
       END { print "average age =", ages / NR }' temp
average age = 60.2942
$ awk -F/ '$2-$1 &gt; max { max = $2 - $1; fname = $3; lname = $4 }
       END { print "oldest:", fname, lname, " age", max }' temp
oldest: William Lisle Bowles  age 88
</pre>

<p> As noted above, the author names are not contiguous, and the dates
are not in any obvious order either, which makes one wonder what order
the data has been sorted into.

How would you detect such anomalies mechanically in a larger dataset, in
particular if it were not related to dates)?

</p><h4> Associative Arrays </h4>

None of the examples so far have used associative arrays, which are Awk's
only data structure.  We didn't spend much if any time on associative
arrays in the class, since it felt like a slightly too-advanced topic
for our population.

<p> An associative array, equivalent to a hash in Java or a dictionary
in Python, is an array whose subscripts are not integers but arbitrary strings.

Several of the examples above that used <tt>sort|uniq -c</tt> can be
written equivalently with associative arrays to bring together
identical items.  For example, to see the distribution of sonnet lengths,
we can write:

</p><pre># awk -F/ '{print $5}' 18.csv | sort | uniq -c | sort -nr

$ awk -F/ '{ len[$5]++ }; END { for (i in len) print len[i], i }' 18.csv | sort -nr
</pre>

This produces the same result as the previous version.  We could even
embed the sort command in the Awk program:

<pre>$ awk -F/ '{ len[$5]++ }; END { for (i in len) print len[i], i | "sort -nr" }' 18.csv
</pre>

This computation is essentially the same as the Pandas <tt>unique_id</tt>
dataframe function.



<h4> Wrap-up </h4>

Awk is good for the kind of preliminary analysis we've
shown here, particularly when coupled with basic Unix
tools like <tt>sort</tt>, <tt>uniq</tt>, and <tt>wc</tt>.

At some point it's time to switch to Python and some
of its libraries, especially for plotting, but that
can be deferred until you really understand what's in the
data and where it might be flaky.



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Tell HN: Postman update removes all your stuff if you refuse to create account (316 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=37792690</link>
            <guid>37792690</guid>
            <pubDate>Fri, 06 Oct 2023 16:14:54 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=37792690">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="37794463"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794463" href="https://news.ycombinator.com/vote?id=37794463&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>There are some extensions for VSCode that let you define your requests in a text file and has ways to run the file and show the data.<p>Here's one I just found:
<a href="https://marketplace.visualstudio.com/items?itemName=humao.rest-client" rel="nofollow noreferrer">https://marketplace.visualstudio.com/items?itemName=humao.re...</a></p><p>Syntax looks like:</p><pre><code>    GET https://example.com/comments/1 HTTP/1.1

    ###

    GET https://example.com/topics/1 HTTP/1.1

    ###

    POST https://example.com/comments HTTP/1.1
    content-type: application/json

    {
        "name": "sample",
        "time": "Wed, 21 Oct 2015 18:27:50 GMT"
    }</code></pre></span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37794702"><td></td></tr>
            <tr id="37794787"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37794787" href="https://news.ycombinator.com/vote?id=37794787&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>I use the VS Code REST extension a lot but it does lack some of the aspects that make Postman easier for teams and larger projects. It's super easy to define a "collection" as an .http page for smaller and one-off needs though.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37794727"><td></td></tr>
                <tr id="37794906"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37794906" href="https://news.ycombinator.com/vote?id=37794906&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Yep, me to. Since it's just textfiles I can have them checked into git and share them. Credentials stays in a separate environments file (not checked in). I'm pretty happy with this setup.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37794919"><td></td></tr>
            <tr id="37795224"><td></td></tr>
                <tr id="37795299"><td></td></tr>
                        <tr id="37794371"><td></td></tr>
                <tr id="37795031"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37795031" href="https://news.ycombinator.com/vote?id=37795031&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>I almost ignored HTTPie as a Postman alternative because I thought it was CLI only but learned that it has a GUI now. Unfortunately the GUI seems to be proprietary.<p>Also we were looking for HTTP/2 support which neither Postman not HTTPie have and found xh which is a HTTPie clone in Rust.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37794715"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37794715" href="https://news.ycombinator.com/vote?id=37794715&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>On windows I even got to enjoy using Invoke-WebRequest directly. Extremely useful since powershell has structured output and input.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37795002"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37795002" href="https://news.ycombinator.com/vote?id=37795002&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>I also found it surprisingly how pleasant this was. For all Powershell’s quirks, this is one of those features that just makes sense to me.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37795033"><td></td></tr>
                <tr id="37795257"><td></td></tr>
                        <tr id="37792914"><td></td></tr>
                <tr id="37794762"><td></td></tr>
                <tr id="37795114"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37795114" href="https://news.ycombinator.com/vote?id=37795114&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>If you updated to v8 and missed the one small text link to export your data before creating an account, then all of your data was gone. Fortunately you could go to Github and download an old version.<p>If you created an account all of the data was still there. By default the "scratchpad" that did not require an account would not show anything.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37794921"><td></td></tr>
            <tr id="37794839"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37794839" href="https://news.ycombinator.com/vote?id=37794839&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Plenty of users reported that updating, being prompted to create an account, and then refusing denied them access to their requests.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37794557"><td></td></tr>
                <tr id="37795018"><td></td></tr>
            <tr id="37794798"><td></td></tr>
                        <tr id="37794246"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794246" href="https://news.ycombinator.com/vote?id=37794246&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>Yes, it happened to me as well.<p>Fortunately I regularly export the collections that still matter.</p><p>Now I am no longer a Postman user, as due to NDA's we aren't allowed to store project data on them.</p><p>Paying was never an issue, not having a secure alternative is what killed it for us.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37795475"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37795475" href="https://news.ycombinator.com/vote?id=37795475&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Not very surprised, Postman has continued to get more bloated and pushy with accounts, I ended up just moving to Insomnia after using Postman for many many years.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37793874"><td></td></tr>
                <tr id="37794739"><td></td></tr>
                <tr id="37794851"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37794851" href="https://news.ycombinator.com/vote?id=37794851&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>The one thing I'm afraid of is that it's a single maintainer project, and while they are active now, I'm not sure how this is going to fare in a few months or so.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37793918"><td></td></tr>
                  <tr id="37794357"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794357" href="https://news.ycombinator.com/vote?id=37794357&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>As one of the creators, I can recommmend <a href="https://kreya.app/" rel="nofollow noreferrer">https://kreya.app</a>. It is not open source (like Postman), but has a strong focus on privacy and also stores the data locally.<p>As it has more powerful features (IMO) than most alternatives listed here, I am a little disappointed that it isn't mentioned more often.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37794704"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37794704" href="https://news.ycombinator.com/vote?id=37794704&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Kreya is the only alternative I've used that prioritizes gRPC support (along with REST). Regardless of source availability, thank you for creating this!</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37795038"><td></td></tr>
                        <tr id="37794712"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794712" href="https://news.ycombinator.com/vote?id=37794712&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Highly recommend the HTTP client in the JetBrains IDEs. I looked carefully at the standalones in this category and IMHO it’s the best. Text based so you can seamlessly manage everything with your repo, with automatic features built in from parsing the text.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37795078"><td></td></tr>
                  <tr id="37794902"><td></td></tr>
            <tr id="37794774"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794774" href="https://news.ycombinator.com/vote?id=37794774&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Am I crazy for using curl and editing the shell cmdline with vim when I need to work with lots of headers?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37795180"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37795180" href="https://news.ycombinator.com/vote?id=37795180&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>No, I use curl similarly and a lot. Where I find Postman convenient is when using it against services that use OAuth2. You authenticate once, it fetches the token and you are good to go. Could I script this with curl? Sure. Do I want to? Nah.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37794878"><td></td></tr>
                <tr id="37795042"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37795042" href="https://news.ycombinator.com/vote?id=37795042&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>I’m not a curl pro but devtools ‘copy as curl’ gets me 95% there most of the time.<p>That said, thanks! Didn’t know about this. Definitely adding to the toolbox.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="37794374"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794374" href="https://news.ycombinator.com/vote?id=37794374&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>After the whiffs of enshittification caught my nose I did some research and switched over to Insomnia. I don’t make use of any advanced features, just a pre request authentication call that was a little bit of a pain to set up. But it’s working exactly how I was using postman so it’s a suitable replacement for me</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37794413"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37794413" href="https://news.ycombinator.com/vote?id=37794413&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Didn't they just push a similar update where they require an account? And pushed all data into their cloud sync without asking?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37794550"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37794550" href="https://news.ycombinator.com/vote?id=37794550&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>When I switched over they made it clear they were getting rid of offline mode. So I said whiffs but at that point there was a turd halfway up my nose</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="37794462"><td></td></tr>
                <tr id="37795261"><td></td></tr>
            <tr id="37794520"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37794520" href="https://news.ycombinator.com/vote?id=37794520&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>I really like restclient - also really makes sense for persisting tests in this manner to source control.  Not that anybody else on your team will know how to use it...</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37794238"><td></td></tr>
            <tr id="37795066"><td></td></tr>
                <tr id="37795431"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37795431" href="https://news.ycombinator.com/vote?id=37795431&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>yeah, this one is the only thing that i'm missing after migration to linux box. the extensions and ability to write own extensions is very powerful, the speed and native UI were very welcomed, as postman and other electron based tools are just way too heavy for me.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37794862"><td></td></tr>
            <tr id="37794976"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794976" href="https://news.ycombinator.com/vote?id=37794976&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>Is that what happened? I DO have an account (begrudgingly made because it doesn't just let you do a JSON export of your collections, you have to send it to the cloud and then download it for some baffling reason) and last time I opened it all of my environment variable values were wiped.<p>I've been wanting to get off Postman for a while. It's so clunky these days, and they're shoving way too much shit in it that I don't care about.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37794640"><td></td></tr>
            <tr id="37794847"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794847" href="https://news.ycombinator.com/vote?id=37794847&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>Is this all stuff that you had kept in your Scratchpad? I think Postman had been warning users for months that Scratchpad would be going away, and that you should migrate everything to a workspace.<p>I'm not saying the decision is <i>right</i>; personally I much preferred the scratch, because it didn't require a freaking network request every time I want to look at my API collections. I'm just saying, this didn't come out of nowhere.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37794942"><td></td></tr>
                <tr id="37794970"><td></td></tr>
                  <tr id="37794286"><td></td></tr>
                <tr id="37794824"><td></td></tr>
                  <tr id="37794956"><td></td></tr>
            <tr id="37794365"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794365" href="https://news.ycombinator.com/vote?id=37794365&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>another alternative: RapidAPI <a href="https://rapidapi.com/" rel="nofollow noreferrer">https://rapidapi.com/</a><p>it's a good api client, and it's free for individual use and they have some sort of nifty marketplace integration catalog...thing with remote API servers that makes it easy to find and try API services that offer data / functionality you want to connect to.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37794920"><td></td></tr>
            <tr id="37794936"><td></td></tr>
                  <tr id="37794697"><td></td></tr>
                <tr id="37794721"><td></td></tr>
                <tr id="37794757"><td></td></tr>
                  <tr id="37794722"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37794722" href="https://news.ycombinator.com/vote?id=37794722&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>I lost everything in a update with them too. And not a create-account update. Just a regular update one day, and <i>poof</i> gone.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37794529"><td></td></tr>
                <tr id="37795464"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37795464" href="https://news.ycombinator.com/vote?id=37795464&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>the mac client probably wont, as they were already bought by rapidapi.com and made web-based client that looks like PAW but has the same issues as other web-based solution</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37794636"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37794636" href="https://news.ycombinator.com/vote?id=37794636&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>I'm not sure why you're downvoted. I still use paw/rapidapi and I think it's great. Maybe downvoters can explain.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37794961"><td></td></tr>
            <tr id="37792871"><td></td></tr>
            <tr id="37794097"><td></td></tr>
            <tr id="37794130"><td></td></tr>
            <tr id="37794047"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794047" href="https://news.ycombinator.com/vote?id=37794047&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>Learn and use curl, then you won’t have any issues like this. You can make some scripts in Python or something, too.<p>I say this because the last three tools I used for this all got shitty (postman, insomnia, and thunder client).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37794177"><td></td></tr>
                <tr id="37795000"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37795000" href="https://news.ycombinator.com/vote?id=37795000&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Seriously, python with the requests lib in a jupyter notebook is always a nicer user experience than any REST API GUI, most importantly once it's grown a bit.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37794352"><td></td></tr>
            <tr id="37794223"><td></td></tr>
                <tr id="37794420"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37794420" href="https://news.ycombinator.com/vote?id=37794420&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Depends how comfortable you are with curl and your workflow. I'm much more productive using curl vs any GUI you give me. Still have OpenAPI specs in my projects but curl is much faster initially.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37794765"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37794765" href="https://news.ycombinator.com/vote?id=37794765&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>It falls apart instantly when you need to pass data from one endpoint to another or add any sort of logic like filtering through data - so any time you have non-trivial workloads where you don't want to spend half your time fighting against jq or shell.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37795230"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_37795230" href="https://news.ycombinator.com/vote?id=37795230&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>You don’t have to fight tools if you learn them, but I understand— as a fellow programmer— that you don’t always have time to learn them. However, it’s pretty easy to use pipes and tools like jq to do complex stuff.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="37794570"><td></td></tr>
                <tr id="37794751"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37794751" href="https://news.ycombinator.com/vote?id=37794751&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>I think you're joking, but I actually want to know these things when adopting tools now to the extent that it's applicable.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37794254"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37794254" href="https://news.ycombinator.com/vote?id=37794254&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>for individual users, i've not quite got the appeal of postman.<p>in larger teams, I did see groups of people collaboratively creating various urls/scripts/tests, and putting some docs with them, to help with the dev and testing (mostly qa/test folks).  that was, imo, a relatively legitimate use for a full tool like postman.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37794242"><td></td></tr>
                  <tr id="37794348"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794348" href="https://news.ycombinator.com/vote?id=37794348&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Same. Quite a surprise. I switched to IntelliJ http requests and am seeing how that does for me.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37794318"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794318" href="https://news.ycombinator.com/vote?id=37794318&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>I'm sure it's a bug, they have nothing to gain from it, especially if there's no warning about this.<p>It's also a good reminder for everyone to back up everything!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37794747"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37794747" href="https://news.ycombinator.com/vote?id=37794747&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>It's not a bug to release a version which removed a massive chunk of functionality. It's intentionally fucking over their users who are not willing to create an account.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37794650"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794650" href="https://news.ycombinator.com/vote?id=37794650&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>&gt; Any alternatives that I can migrate to?<p>If it works for your use case: writing integration tests.</p><p>I used Postman in the past but I never really got the point of "storing" queries beyond the history.</p><p>I think if you have that need it means it's time to write a frontend to call your endpoints, or use integration tests.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37795014"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37795014" href="https://news.ycombinator.com/vote?id=37795014&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>I’ve used alternatives to explore under-documented APIs interactively and suss out their behavior. Then I could use the app’s codegen to turn the query I’d manually crafted into my chosen language’s code.<p>You can do all that directly in the language, of course, but by the time you go through the trouble of pretty printing the output, parametrizing the input, etc, you’ve reimplemented a less ergonomic version of Postman-and-similar.</p><p>(Not saying you’re wrong for doing it your way, but explaining why others might choose a different approach.)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37794857"><td></td></tr>
                <tr id="37794950"><td></td></tr>
                  <tr id="37794189"><td></td></tr>
                <tr id="37794553"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37794553" href="https://news.ycombinator.com/vote?id=37794553&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Disappointing that there isn't a standalone program like Postman. I don't want to install an extension in my browser to handle CORS.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37794953"><td></td></tr>
            <tr id="37794792"><td></td></tr>
                <tr id="37794887"><td></td></tr>
                <tr id="37794992"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_37794992" href="https://news.ycombinator.com/vote?id=37794992&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Having a dedicated browser profile is a good solution to this if you’re ever uncomfortable with a particular extension.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37794979"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_37794979" href="https://news.ycombinator.com/vote?id=37794979&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>Running standalone binaries by a VC-fueled project on your host is even worse.<p>I guess a separate quarantine browser profile is the best of both worlds?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37794974"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_37794974" href="https://news.ycombinator.com/vote?id=37794974&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>Ah, I follow. I was confused because a small, open-source extension should be sufficient to handle sending test requests. Sounds like they're doing something much bigger than that.<p>POSTman started as an extension; hence my confusion. I was wondering if there was a technical issue I was unaware of.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="37794646"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37794646" href="https://news.ycombinator.com/vote?id=37794646&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>It's a non-starter for me if it requires an extension. I also think it's a matter of time before it goes the Insomnia/Postman route. I'd love to be proven wrong though.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37794848"><td></td></tr>
                  <tr id="37794544"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37794544" href="https://news.ycombinator.com/vote?id=37794544&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>But you raised VC funding right?<p>Insomnia was an alternative to Postman, raised VC funds, eventually needed to justify that, and suddenly accounts mattered more. They're currently on the same trajectory.</p><p>Insomnia is open source but just like OP experienced, a single update can do damage and it takes time for the community to react.</p><p>Is this the same company that raised? If so, are you exempt from that? Have you figured out some monetization scheme for what is essentially a glorified curl UI that doesn't incentivize account sign ups?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37794926"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37794926" href="https://news.ycombinator.com/vote?id=37794926&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>I wish tech product managers could get it through their skulls: creating and maintaining yet-another-account for yet-another-app is high friction and undesirable. If you're going to give me an ultimatum where I need to either create an account or stop using the app. 99% of the time I'm just going to stop using your app.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37794772"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37794772" href="https://news.ycombinator.com/vote?id=37794772&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>If it's just a "glorified curl UI" what's the problem? Just use curl, or build your own, if it's so trivial.<p>You are kicking the tires awfully hard for a solution to a problem you claim is easy.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37794990"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37794990" href="https://news.ycombinator.com/vote?id=37794990&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>That’s actually what I do and did. I have a whole bunch of scripts that allow me to replicate a lot of what Postman did for me.<p>The problem with these VC companies is that they enter the market with a whole bunch of lies and I was convinced that building on my ad hoc scripts wasn’t very useful since there were multiple alternatives including open source ones.</p><p>It’s taken me a decade however to learn that if these projects are VC backed as opposed to having some sort of govt or heck, even a benevolent dictator, they will screw you.</p><p>And while I might have learnt this lesson, which so much of the knowledge ecosystem also being filled with VC backed individuals (including this very forum) a whole another generation of potential OS developers will learn the lesson also too late.</p><p>And that’s how Silicon Valley has built a massive eco system to suck money out of everything across the globe, especially open source, but not limited to it (taxis, restaurants, hoteling, everything…).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37794995"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37794995" href="https://news.ycombinator.com/vote?id=37794995&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>I think it's fair to criticize them given a fair number of alternatives in this thread (with their own shortcomings). It's kind of silly to post something to hackernews and not expect criticism.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37794562"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37794562" href="https://news.ycombinator.com/vote?id=37794562&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Postman is also open source lol. Unless its donation driven without funding its all going to be the same.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37794700"><td></td></tr>
            <tr id="37794632"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37794632" href="https://news.ycombinator.com/vote?id=37794632&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>Can't someone just locally fork one of these apps and use it forever without updating it?  What's actually different about manually poking APIs from one week to the next?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37794883"><td></td></tr>
                  <tr id="37794687"><td></td></tr>
                              <tr id="37794998"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37794998" href="https://news.ycombinator.com/vote?id=37794998&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><p><span>I would really like to see Chrome offering an alternative to Postman. For me, it feels natural, to have everything in one place.<p>What do others think?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37795037"><td></td></tr>
                <tr id="37795053"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37795053" href="https://news.ycombinator.com/vote?id=37795053&amp;how=up&amp;goto=item%3Fid%3D37792690"></a></center>    </td><td><br><div>
                  <p><span>I checked out of postman for a few years. Color me confused in this thread until I figured that part out.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: A job application tracker with company reviews, recruiter autoresponder (206 pts)]]></title>
            <link>https://rolepad.com</link>
            <guid>37792507</guid>
            <pubDate>Fri, 06 Oct 2023 16:01:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rolepad.com">https://rolepad.com</a>, See on <a href="https://news.ycombinator.com/item?id=37792507">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><span>Whether you are actively looking for a job or not, Rolepad gives you the tools to stay organized and informed when opportunity knocks. It's free, easy, and convenient.</span></p></div><div><div><div><p><span>Track all the data</span></p><p><span>Capture every job application</span> and incoming opportunity. Record company facts, role details, interview stages, contact information, freeform notes, follow-up actions and more - <span>all in one place</span>.</p></div><p><img src="https://rolepad.com/assets/static/track.0735e958.png" alt="Details of an opportunity selected from a list"></p></div><div><div><p><span>Streamline your correspondence</span></p><p><span>Organize your conversations</span> with recruiters, interviewers, and hiring managers by sending the emails to <a href="mailto:save@rolepad.com">save@rolepad.com</a>.</p><p>Or forward them to <a href="mailto:no@rolepad.com">no@rolepad.com</a> to <span>decline with an automated response.</span></p></div><p><img src="https://rolepad.com/assets/static/email-no.fd9f58d9.png" alt="Automated decline message"><img src="https://rolepad.com/assets/static/email-save.b9655f16.png" alt="Assign email to opportunity"></p></div><div><div><p><span>Visualize your progress</span></p><p><span>Generate a diagram</span> highlighting your job search journey over time.<span> Share your progress</span> with others without revealing sensitive information.</p></div><p><img src="https://rolepad.com/assets/static/sankey.7ad37b65.jpg" alt="Sankey chart"></p></div><div><div><p><span>Share feedback and reviews</span></p><p>Were the interviews difficult? How quickly did the company respond? What was your offer like?</p><p><span>Share private feedback</span> with the company or <span>submit an anonymous review</span>. Explore the <a href="https://rolepad.com/companies">Reviews</a> to <span>gain insight</span> into company hiring processes.</p></div><p><img src="https://rolepad.com/assets/static/reviews.8ff0022f.png" alt="Company stats and reviews"></p></div></div><div><blockquote><span>“This has been the most straightforward, easiest, lowest friction tracker I've encountered, <span>ever :)”</span></span><p>Chris H., Software Engineer</p></blockquote></div><div><h3>Fast. Flexible. Free.</h3><h2>Still relying on emails and spreadsheets?</h2><h2>There is a better way!</h2><p>Track every job opportunity, capture the key details, visualize your progress, and gain critical insight from other applicants. Rolepad gives you <span>job search superpowers</span>.</p><p><a href="https://app.rolepad.com/">Get started now</a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Shortbread – Create AI comics in minutes (201 pts)]]></title>
            <link>https://shortbread.ai/</link>
            <guid>37792444</guid>
            <pubDate>Fri, 06 Oct 2023 15:56:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shortbread.ai/">https://shortbread.ai/</a>, See on <a href="https://news.ycombinator.com/item?id=37792444">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main" data-framer-hydrate-v2="{&quot;routeId&quot;:&quot;augiA20Il&quot;,&quot;localizationId&quot;:&quot;default&quot;,&quot;localeId&quot;:&quot;default&quot;}" data-framer-ssr-released-at="2023-09-27T07:53:51.711Z" data-framer-page-optimized-at="2023-10-03T01:23:55.661Z"><header data-framer-name="Landing" name="Landing"></header><div data-framer-name="Grid 1" name="Grid 1"><div data-framer-name="Content" name="Content"><p data-framer-component-type="RichTextContainer"><h2>Idea to Page in Seconds</h2></p><p data-styles-preset="GOagwD4oe">Begin with a spark—whether it's a storyline, a unique character, or a specific mood you want to capture. Just describe it, and let Shortbread transform your idea into a page, setting the stage for your artistry.</p></div><div data-framer-name="Content" name="Content"><p data-framer-component-type="RichTextContainer"><h2>Fine-Tune like a Pro</h2></p><p data-styles-preset="GOagwD4oe">Create with unparalleled control over each panel. Manipulate scenes, character poses, fine-tune facial expressions, and adjust camera angles to create your perfect shot.</p></div><div data-framer-name="Content" name="Content"><p data-framer-component-type="RichTextContainer"><h2>Pixel-Perfect Design</h2></p><p data-styles-preset="GOagwD4oe">Elevate the look of your comics with a rich selection of design elements. From speech bubbles to fonts, every pixel can be customized to enhance the flow your story.</p></div></div><section><p data-framer-component-type="RichTextContainer"><h2 data-styles-preset="stylesPresetHeading2">Frequently Asked Questions</h2></p></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Java 21 VirtualThreads vs. Clojure Lazy Seqs (from Clojure Deref 2023-10-06) (195 pts)]]></title>
            <link>https://clojure.org/news/2023/10/06/deref</link>
            <guid>37792294</guid>
            <pubDate>Fri, 06 Oct 2023 15:44:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://clojure.org/news/2023/10/06/deref">https://clojure.org/news/2023/10/06/deref</a>, See on <a href="https://news.ycombinator.com/item?id=37792294">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      <p><em>06 October 2023</em><br>
         <em>Alex Miller</em></p>

      <div id="preamble">
<p>Welcome to the Clojure Deref! This is a weekly link/news roundup for the Clojure ecosystem (feed: <a href="https://clojure.org/feed.xml">RSS</a>). Thanks to Anton Fonarev for link aggregation.</p>
</div>
<div>
<h2 id="_from_the_core"><a href="#_from_the_core"></a>From the core</h2>
<div>
<p>Recently Java 21 was released (congrats!) and this has driven a lot of interest and experimentation with the new virtual threads feature. Virtual threads have the ability to park and resume a virtual thread (particularly one blocked on I/O) and this cooperates transparently with many blocking constructs in Java - I/O, sockets, java.util.concurrent.lock, etc. However, one thing it does not (yet) cooperate with is object monitors (synchronized) and thus doing a blocking call while holding a synchronized monitor prevents a virtual thread from parking (ie, "pins" the virtual thread). Note that synchronization itself is not inherently bad - normal use of synchronized to serialize reads and writes to fields is fine (as there is no blocking I/O that can pin a thread).</p>
<p>Several people doing new things with virtual threads have detected cases where user code is doing I/O blocking while Clojure is in a synchronization block, thus pinning threads. The two most important cases are lazy seqs and <code>delay</code> - both hold some suspended computation in a thunk and invoke the thunk under synchronization, thus allowing for the possibility of user I/O under a lock in the language level. As people have raised this as an issue, we have spent the last week taking a hard look at this area.</p>
<p>At a meta level, there are a bunch of options here and we have still not decided on our approach or timeframe. From a user level, it is possible to simply not do (or tolerate) I/O under delay or lazy seqs. Delay is a one-time thing, so it may not generally be an issue to pin a thread that is reading a config file as that is a one-time thing. Pulling I/O over a lazy seq is not uncommon and can definitely present this kind of issue, but there are a lot of other options - controlling via loop/recur, using transducers and <code>sequence</code>, etc. If you are experiencing this problem now, these are probably worth exploring.</p>
<p>We’ve spent a ton of time over the last week looking at the internals of LazySeq and options for avoiding synchronization. The general guidance from Java is to replace synchronized with ReentrantLock (which has virtual thread coordination), but this advice leaves out the inherent tradeoffs in that change. synchronized relies on object monitors which are built into every Java object at the JVM level, whereas ReentrantLocks are additional Java objects (which hold a reference to an internal Sync object). Clojure makes a lot of lazy seqs and allocating two objects (plus adding an additional field to LazySeq) for every lazy seq is a real cost in allocation, heap size, and GC. Additionally, while ReentrantLock seems to be a bit faster than synchronized in Java 21, LazySeq makes one reentrant call, and reentrant calls seems to be noticeably slower than synchronized. There are lots of options though. We think it’s relatively easy to make lazy seq walking faster, but a lot harder to keep realization costs under control (as making locks takes non-zero time). One interesting branch we have explored is making one lock per seq and passing it through the seq as we go - lots of tradeoffs in that.</p>
<p>Additionally, we continue to work on functional interface adapters and method thunks. With FI adapters, we continue to refine when implicit coercion and conversion occur and I think that draws asymptotically closer to completion. With method thunks, we have taken a bit of a detour to examine array class representation.</p>
<p>Generally, classes are represented by symbols that name the class, but this does not work for array classes as they cannot be represented as a valid symbol. The fallback right now is using a String that holds the internal class name, like <code>^"[Ljava.lang.String;"</code> which I think we can all agree is no fun. Our plan going forward is to support a new array class syntax which is a symbol of the class with a <code>*</code> suffix. Imported classes can use their short name, so <code>String*</code> will represent a Java <code>String[]</code> (or a <code>String…​</code> vararg). Multiple <code>**</code> will represent multidimensional arrays. This will work with both classes and with primitives, so <code>long*</code> will be a synonym for the existing <code>longs</code>. Rich also wishes you to notice the C pointer punnery. :)</p>
<p>That was a bit of a diversion, but I think it is a big win to fix a long-time representational gap. It also helps create some new "columns" in the varargs decision matrix, which is not going to be addressed in 1.12, but I think we have teed up to work on immediately after.</p>
</div>
</div>
<div>
<h2 id="_podcasts_and_videos"><a href="#_podcasts_and_videos"></a>Podcasts and videos</h2>

</div>
<div>
<h2 id="_blogs_articles_and_projects"><a href="#_blogs_articles_and_projects"></a>Blogs, articles, and projects</h2>

</div>
<div>
<p>New releases and tools this week:</p>
<div>
<ul>
<li>
<p><a href="https://github.com/holyjak/fulcro-troubleshooting">fulcro-troubleshooting</a> v7 - A development-time library for Fulcro that helps to detect problems earlier and find and fix their root cause faster</p>
</li>
<li>
<p><a href="https://github.com/holyjak/minimalist-fulcro-template-backendless">minimalist-fulcro-template-backendless</a>  - A minimal template for browser-only Fulcro apps for learning</p>
</li>
<li>
<p><a href="https://github.com/clojure-expectations/clojure-test">clojure-test</a> <a href="https://github.com/clojure-expectations/clojure-test/releases/tag/v2.1.182">2.1.182</a> - A clojure.test-compatible version of the classic Expectations testing library</p>
</li>
<li>
<p><a href="https://github.com/nextjournal/clerk">clerk</a> <a href="https://github.com/nextjournal/clerk/blob/9c38ff3ef240c9bd21e596792adb2ebdbb5a738d/CHANGELOG.md#015957-2023-09-28">0.15.957</a> - Moldable Live Programming for Clojure</p>
</li>
<li>
<p><a href="https://github.com/namenu/deps-diff">deps-diff</a> 1.1 - A tool for comparing transitive dependencies in two deps.edn files</p>
</li>
<li>
<p><a href="https://github.com/juji-io/datalevin">datalevin</a> <a href="https://github.com/juji-io/datalevin/blob/master/CHANGELOG.md">0.8.20</a> - A simple, fast and versatile Datalog database</p>
</li>
<li>
<p><a href="https://github.com/liquidz/antq">antq</a> <a href="https://github.com/liquidz/antq/releases/tag/2.7.1133">2.7.1133</a> - Point out your outdated dependencies</p>
</li>
<li>
<p><a href="https://github.com/eerohele/tab">tab</a> <a href="https://github.com/eerohele/tab/blob/main/CHANGELOG.md#2023-10-03">2023-10-03.333</a> - A tool for tabulating Clojure collections</p>
</li>
<li>
<p><a href="https://github.com/eerohele/pp">pp</a> 2023-10-05.5 - Pretty-print Clojure data structures, fast</p>
</li>
<li>
<p><a href="https://github.com/quoll/raphael">raphael</a> 0.3.0 - A Clojure library for parsing strings containing the Terse Triples Language: Turtle</p>
</li>
<li>
<p><a href="https://github.com/steffan-westcott/clj-otel">clj-otel</a> <a href="https://github.com/steffan-westcott/clj-otel/blob/master/CHANGELOG.adoc">0.2.4.1</a> - An idiomatic Clojure API for adding telemetry to your libraries and applications using OpenTelemetry</p>
</li>
<li>
<p><a href="https://github.com/babashka/neil">neil</a> <a href="https://github.com/babashka/neil/blob/main/CHANGELOG.md#0262">0.2.61</a> - A CLI to add common aliases and features to deps.edn-based projects</p>
</li>
<li>
<p><a href="https://github.com/squint-cljs/squint">squint</a> <a href="https://github.com/squint-cljs/squint/blob/main/CHANGELOG.md">0.2.30</a> - ClojureScript syntax to JavaScript compiler</p>
</li>
<li>
<p><a href="https://github.com/eerohele/Tutkain">Tutkain</a> <a href="https://github.com/eerohele/Tutkain/blob/master/CHANGELOG.md#0190-alpha---2023-10-03">0.19.0 (alpha)</a> - A Sublime Text package for interactive Clojure development</p>
</li>
<li>
<p><a href="https://github.com/squint-cljs/cherry">cherry</a> <a href="https://github.com/squint-cljs/cherry/blob/main/CHANGELOG.md">0.1.9</a> - Experimental ClojureScript to ES6 module compiler</p>
</li>
<li>
<p><a href="https://github.com/PEZ/taplet">taplet</a> <a href="https://github.com/PEZ/taplet/blob/master/CHANGELOG.md">1.0.58</a> - A Clojure/ClojureScript macro, let&gt; that works like a let, and also tap&gt;s the binding vector</p>
</li>
<li>
<p><a href="https://github.com/babashka/nbb">nbb</a> <a href="https://github.com/babashka/nbb/blob/main/CHANGELOG.md">1.2.179</a> - Scripting in Clojure on Node.js using SCI</p>
</li>
</ul>
</div>
</div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Petscii Side-Scrolling Platformer by Jimbo (101 pts)]]></title>
            <link>https://jimbo.itch.io/petscii-side-scrolling-platformer</link>
            <guid>37792129</guid>
            <pubDate>Fri, 06 Oct 2023 15:31:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jimbo.itch.io/petscii-side-scrolling-platformer">https://jimbo.itch.io/petscii-side-scrolling-platformer</a>, See on <a href="https://news.ycombinator.com/item?id=37792129">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wrapper"><div><p>The Commodore PET now has a multi-level side-scrolling platformer. Inspired by other side-scrolling platform games like Mario and Sonic. Run, jump, collect coins, crush henchmen, battle the bosses, rescue friends.</p><div><h2 id="download">Download</h2></div><div><h2 id="instructions">Install instructions</h2><p>For PET/CBM 2001 (32K required), 3032, 4032 and 8032.</p></div><div id="game_comments_2824560"><h2 id="comments">Comments</h2><p><a href="https://itch.io/login?return_to=https%3A%2F%2Fjimbo.itch.io%2Fpetscii-side-scrolling-platformer" data-register_action="comment">Log in with itch.io</a> to leave a comment.</p><div id="community_topic_posts_8124343"><div id="post-8695938" data-post="{&quot;id&quot;:8695938,&quot;user_id&quot;:971499}"><a href="https://itch.io/profile/cghijinks"></a><div><p>Front page HN 👌 Congrats 👏&nbsp;</p></div></div><div id="post-8676119" data-post="{&quot;id&quot;:8676119,&quot;user_id&quot;:1757640}"><a href="https://itch.io/profile/naggynaggerson"></a><div><p>Love this to bits! Made a PET-style cover for it :) <img src="https://img.itch.zone/aW1nLzEzNTk4MDIyLmpwZw==/original/veuWt5.jpg" loading="lazy"></p></div></div><div id="post-8667807" data-post="{&quot;id&quot;:8667807,&quot;user_id&quot;:4598661}"><a href="https://itch.io/profile/retroshaun"></a><div><p>This is a spectacular version of the classic! So much fun, great attention to detail and very very playable!</p></div></div><div id="post-8664137" data-post="{&quot;id&quot;:8664137,&quot;user_id&quot;:4937575}"><a href="https://itch.io/profile/koko74"></a><div><p>Hey Jim! I must say it's a true piece of art. I love the details in every aspect of the gameplay. Well done on creating such an incredible game!<br>Kornel</p></div></div><div id="post-8663767" data-post="{&quot;id&quot;:8663767,&quot;user_id&quot;:648359}"><a href="https://itch.io/profile/fuzzybad"></a><div><p>Love it! Super PETSCII Bros :D</p></div></div></div></div></div><div><div><p id="video_embed_884428"><iframe frameborder="0" allowfullscreen="" src="//www.youtube.com/embed/lApSXRx2Z90"></iframe></p></div><p><a data-image_lightbox="true" target="_blank" href="https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NjkyMS5wbmc=/original/B62TXm.png"><img src="https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NjkyMS5wbmc=/347x500/%2BBScX%2B.png" data-screenshot_id="13566921" srcset="https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NjkyMS5wbmc=/347x500/%2BBScX%2B.png 1x, https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NjkyMS5wbmc=/794x1000/TP2zmB.png 2x"></a><a data-image_lightbox="true" target="_blank" href="https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NjkyMy5wbmc=/original/7P44S2.png"><img src="https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NjkyMy5wbmc=/347x500/rqk32I.png" data-screenshot_id="13566923" srcset="https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NjkyMy5wbmc=/347x500/rqk32I.png 1x, https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NjkyMy5wbmc=/794x1000/Xcy9dA.png 2x"></a><a data-image_lightbox="true" target="_blank" href="https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NjkyMi5wbmc=/original/sCoQ1O.png"><img src="https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NjkyMi5wbmc=/347x500/NSWmXZ.png" data-screenshot_id="13566922" srcset="https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NjkyMi5wbmc=/347x500/NSWmXZ.png 1x, https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NjkyMi5wbmc=/794x1000/Xo5zvZ.png 2x"></a><a data-image_lightbox="true" target="_blank" href="https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NzAyNy5wbmc=/original/D8B8WN.png"><img src="https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NzAyNy5wbmc=/347x500/Bh6Rqj.png" data-screenshot_id="13567027" srcset="https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NzAyNy5wbmc=/347x500/Bh6Rqj.png 1x, https://img.itch.zone/aW1hZ2UvMjI4OTQ5OS8xMzU2NzAyNy5wbmc=/794x1000/UcgoBj.png 2x"></a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What is in that .git directory? (108 pts)]]></title>
            <link>https://blog.meain.io/2023/what-is-in-dot-git/</link>
            <guid>37792097</guid>
            <pubDate>Fri, 06 Oct 2023 15:29:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.meain.io/2023/what-is-in-dot-git/">https://blog.meain.io/2023/what-is-in-dot-git/</a>, See on <a href="https://news.ycombinator.com/item?id=37792097">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      

<p> Oct 06, 2023 . 8 min </p>



<p>Well, I think most of you reading this blog use <code>git</code> more or less on a daily basis, but have you ever looked into what is in the <code>.git</code> folder that git creates? Let's explore it together and understand what is going on in there.</p>
<p><em>This is a blog version of a talk that I recently gave. Unfortunately I can't link to the recording :(.</em></p>
<blockquote>
<p><code>git</code> at a basic level is just a bunch of text files linked to each other by filenames.</p>
</blockquote>
<h2 id="lets-start-init" tabindex="-1">Lets <s>start</s> init <a href="#lets-start-init">#</a></h2>
<p>As you all know, we start our git journey with a <code>git init</code>. This gives the message that we all are probably used to by now, especially if you start and abandon a lot of side projects.</p>
<pre><code>Initialized empty Git repository in /home/meain/dev/src/git-talk/.git/
</code></pre>
<p>Let's look at what is in the <code>.git</code> repo as of now.</p>
<pre><code>$ tree .git

.git
├── config
├── HEAD
├── hooks
│&nbsp;&nbsp; └── prepare-commit-msg.msample
├── objects
│&nbsp;&nbsp; ├── info
│&nbsp;&nbsp; └── pack
└── refs
    ├── heads
    └── tags
</code></pre>
<p>It seems to create a bunch of files and folders. What are all these? Let's go over them one by one.</p>
<ul>
<li><code>config</code> is a text file that contains your git configuration for the current repo. If you look into it, you would see some basic settings for you repo like the author, filemode etc.</li>
<li><code>HEAD</code> contains the current head of the repo. Depending on what you have set your "default" branch to be, it will be <code>refs/heads/master</code> or <code>refs/heads/main</code> or whatever else you had set to. As you might have guessed, this is pointing to <code>refs/heads</code> folder that you can see below, and into a file called <code>master</code> which does not exist as of now. This file <code>master</code> will only show up after you make your first commit.</li>
<li><code>hooks</code> contain any scripts that can be run before/after git does anything. I have written another blog <a href="https://blog.meain.io/2019/making-sure-you-wont-commit-conflict-markers/">here</a> which goes a bit more into how git hooks work.</li>
<li><code>objects</code> contains the git objects, ie the data about the files, commits etc in your repo. We will go in depth into this in this blog.</li>
<li><code>refs</code> as we previously mentioned, stores references(pointers). <code>refs/heads</code> contains pointers to branches and <code>refs/tags</code> contains pointers to tags. We will go into what these files look like soon.</li>
</ul>
<h2 id="now-we-add-a-file" tabindex="-1">Now we add a file <a href="#now-we-add-a-file">#</a></h2>
<p>Now that you have an idea of what the initial set of files in <code>.git</code> is, let's perform the first action that adds something into the <code>.git</code> directory. Let's create a file and add it(we are not committing it yet).</p>
<pre><code><span>echo</span> <span>'meain.io'</span> <span>&gt;</span> <span>file</span><br><span>git</span> <span>add</span> <span>file</span></code></pre>
<p>This does the following:</p>
<pre><code><span>--- init       2024-07-02 15:14:00.584674816 +0530</span><br><span>+++ add        2023-07-02 15:13:53.869525054 +0530</span><br><span>@@ -3,7 +3,10 @@</span><br><span><span> </span><span>├── HEAD<br></span><span> </span><span>├── hooks<br></span><span> </span><span>│   └── prepare-commit-msg.msample<br></span></span><span><span>+</span><span>├── index<br></span></span><span><span> </span><span>├── objects<br></span></span><span><span>+</span><span>│   ├── 4c<br></span><span>+</span><span>│   │   └── 5b58f323d7b459664b5d3fb9587048bb0296de<br></span></span><span><span> </span><span>│   ├── info<br></span><span> </span><span>│   └── pack<br></span><span> </span><span>└── refs</span></span></code></pre>
<p>This causes two main changes as you can see. The first thing it modifies is the <code>index</code> file. The <a href="https://git-scm.com/docs/index-format">index</a> is what stores the information about what is currently staged. This is used to signify that the file named <code>file</code> has been added to the index.</p>
<p>The second and more important change is the addition of a new folder <code>objects/4c</code> and a file <code>5b58f323d7b459664b5d3fb9587048bb0296de</code> inside it.</p>
<h2 id="but-what-is-in-that-file%3F" tabindex="-1">But what is in that file? <a href="#but-what-is-in-that-file%3F">#</a></h2>
<p>Here is where we get into the details of how <code>git</code> stores things. Let's start with looking at what kind of data is present in that.</p>
<pre><code>$ <span>file</span> .git/objects/5c/5b58f323d7b459664b5d3fb9587048bb0296de<br>.git/objects/4c/5b58f323d7b459664b5d3fb9587048bb0296de: zlib compressed data</code></pre>
<p>Hmm, but what is the zlib compressed data?</p>
<pre><code>$ zlib-flate <span>-uncompress</span> <span>&lt;</span>.git/objects/4c/5b58f323d7b459664b5d3fb9587048bb0296de<br>blob <span>9</span><span>\</span>0meain.io</code></pre>
<p>Looks like it contains the type, size and data of the file named <code>file</code> that we did a <code>git add</code> on. In this case, the data says that it is a <code>blob</code> of size <code>9</code> and the content is <code>meain.io</code>.</p>
<h2 id="ok%2C-but-what-is-with-that-filename%3F" tabindex="-1">OK, but what is with that filename? <a href="#ok%2C-but-what-is-with-that-filename%3F">#</a></h2>
<p>Well, good question. It comes from the sha1 of the content. If you take the zlib compressed data and pipe it through <code>sha1sum</code>, you get the filename.</p>
<pre><code>$ zlib-flate <span>-uncompress</span> <span>&lt;</span>.git/objects/4c/5b58f323d7b459664b5d3fb9587048bb0296de<span>|</span>sha1sum<br>4c5b58f323d7b459664b5d3fb9587048bb0296de</code></pre>
<p><code>git</code> takes the sha1 of the content to be written, takes the first two characters, in this case <code>4c</code>, creates a folder and then uses the rest of it as the filename. <code>git</code> creates folders from the first two chars to make sure we don't have too many files under the single <code>objects</code> folder.</p>
<h2 id="say-hello-to-git-cat-file" tabindex="-1">Say hello to <code>git cat-file</code> <a href="#say-hello-to-git-cat-file">#</a></h2>
<p>In fact, since this is one of the more important parts of git, git also has a plumbing command to view the content of an object. You can use <code>git cat-file</code> with <code>-t</code> for type, <code>-s</code> for size and <code>-p</code> for content.</p>
<pre><code>$ <span>git</span> cat-file <span>-t</span> 4c5b58f323d7b459664b5d3fb9587048bb0296de<br>blob<p>$ <span>git</span> cat-file <span>-s</span> 4c5b58f323d7b459664b5d3fb9587048bb0296de<br><span>9</span></p><p>$ <span>git</span> cat-file <span>-p</span> 4c5b58f323d7b459664b5d3fb9587048bb0296de<br>meain.io</p></code></pre>
<h2 id="let's-commit" tabindex="-1">Let's commit <a href="#let's-commit">#</a></h2>
<p>Now that we know what changes when we add a file, let's take this to the next level by committing.</p>
<pre><code>$ <span>git</span> commit <span>-m</span> <span>'Initial commit'</span><br><span>[</span>master <span>(</span>root-commit<span>)</span> 4c201df<span>]</span> Initial commit<br> <span>1</span> <span>file</span> changed, <span>1</span> insertion<span>(</span>+<span>)</span><br> create mode <span>100644</span> <span>file</span></code></pre>
<p>Here is what changed:</p>
<pre><code><span>--- init        2024-07-02 15:14:00.584674816 +0530</span><br><span>+++ commit      2023-07-02 15:33:28.536144046 +0530</span><br><span>@@ -1,11 +1,25 @@</span><br><span><span> </span><span>.git<br></span></span><span><span>+</span><span>├── COMMIT_EDITMSG<br></span></span><span><span> </span><span>├── config<br></span><span> </span><span>├── HEAD<br></span><span> </span><span>├── hooks<br></span><span> </span><span>│   └── prepare-commit-msg.msample<br></span><span> </span><span>├── index<br></span></span><span><span>+</span><span>├── logs<br></span><span>+</span><span>│   ├── HEAD<br></span><span>+</span><span>│   └── refs<br></span><span>+</span><span>│       └── heads<br></span><span>+</span><span>│           └── master<br></span></span><span><span> </span><span>├── objects<br></span></span><span><span>+</span><span>│   ├── 3c<br></span><span>+</span><span>│   │   └── 201df6a1c4d4c87177e30e93be1df8bfe2fe19<br></span></span><span><span> </span><span>│   ├── 4c<br></span><span> </span><span>│   │   └── 5b58f323d7b459664b5d3fb9587048bb0296de<br></span></span><span><span>+</span><span>│   ├── 62<br></span><span>+</span><span>│   │   └── 901ec0eca9faceb8fe0a9870b9b6cde75a9545<br></span></span><span><span> </span><span>│   ├── info<br></span><span> </span><span>│   └── pack<br></span><span> </span><span>└── refs<br></span><span> </span><span>    ├── heads<br></span></span><span><span>+</span><span>    │   └── master<br></span></span><span><span> </span><span>    └── tags</span></span></code></pre>
<p>Woah, looks like there are a bunch of changes. Let's walk through them one by one. The first one is a new file <code>COMMIT_EDITMSG</code>. As the name might suggest, it contains the (last) commit message.</p>
<p><em>If you where to run the <code>git commit</code> command without the <code>-m</code> flag, the way <code>git</code> gets a commit message is to open an editor with the <code>COMMIT_EDITMSG</code> file to let the user edit the commit message and once the user has updated it and exited the editor, <code>git</code> uses the contents of the file as the commit message.</em></p>
<p>It also added a whole new folder <code>logs</code>. This is a way for git to log all the commits changes in a repo. You will be able to see the changes in commits for all refs and <code>HEAD</code> here.</p>
<p>The <code>object</code> dir also got some changes, but I want you to first look into the <code>refs/heads</code> directory where we now have the file <code>master</code>. This as you might have guessed is the reference to the <code>master</code> branch. Let's see what is in it.</p>
<pre><code>$ <span>cat</span> refs/heads/master<br>3c201df6a1c4d4c87177e30e93be1df8bfe2fe19</code></pre>
<p>Looks like it is pointing to one of the new objects. We know how to look at objects, let's do that.</p>
<pre><code>$ <span>git</span> cat-file <span>-t</span> 3c201df6a1c4d4c87177e30e93be1df8bfe2fe19<br>commit<p>$ <span>git</span> cat-file <span>-p</span> 3c201df6a1c4d4c87177e30e93be1df8bfe2fe19<br>tree 62902ec0eca9faceb8fe0a9870b9b6cde75a9545<br>author Abin Simon <span>&lt;</span>mail@meain.io<span>&gt;</span> <span>1688292123</span> +0530<br>committer Abin Simon <span>&lt;</span>mail@meain.io<span>&gt;</span> <span>1688292123</span> +0530</p><p>Initial commit</p></code></pre>
<blockquote>
<p>You could have also done <code>git cat-file -t refs/heads/master</code></p>
</blockquote>
<p>Well, looks like that is new kind of object. This seems to be a <code>commit</code> object. The contents of the <code>commit</code> object tells us that it contains a <code>tree</code> object with the hash <code>62902ec0eca9faceb8fe0a9870b9b6cde75a9545</code>, which looks like the other object that got added when we did the commit. The <code>commit</code> object also has the information about who the author and committer is, which in this case is both me. Lastly is also shows what the commit message for this commit was.</p>
<p>Now let's look at what the <code>tree</code> object contains.</p>
<pre><code>$ <span>git</span> cat-file <span>-t</span> 62902ec0eca9faceb8fe0a9870b9b6cde75a9545<br>tree<p>$ <span>git</span> cat-file <span>-p</span> 62901ec0eca9faceb8fe0a9870b9b6cde75a9545<br><span>100644</span> blob 4c5b58f323d7b459664b5d3fb9587048bb0296de    <span>file</span></p></code></pre>
<p>A <code>tree</code> object will contain the state of working directory in the form of other tree and blob objects. In this case, since we just have a single file named <code>file</code>, you will just see a single object. If you see, the file is pointing to the original object that got added when we did a <code>git add file</code>.</p>
<p>Here is what a tree for a more mature repo look like. More <code>tree</code> objects are used inside <code>tree</code> object linked from the <code>commit</code> object to denote folders.</p>
<pre><code>$ git cat-file -p 2e5e84c3ee1f7e4cb3f709ff5ca0ddfc259a8d04
100644 blob 3cf56579491f151d82b384c211cf1971c300fbf8    .dockerignore
100644 blob 02c348c202dd41f90e66cfeb36ebbd928677cff6    .gitattributes
040000 tree ab2ba080c4c3e4f2bc643ae29d5040f85aca2551    .github
100644 blob bdda0724b18c16e69b800e5e887ed2a8a210c936    .gitignore
100644 blob 3a592bc0200af2fd5e3e9d2790038845f3a5cf9b    CHANGELOG.md
100644 blob 71a7a8c5aacbcaccf56740ce16a6c5544783d095    CODE_OF_CONDUCT.md
100644 blob f433b1a53f5b830a205fd2df78e2b34974656c7b    LICENSE
100644 blob 413072d502db332006536e1af3fad0dce570e727    README.md
100644 blob 1dd7ed99019efd6d872d5f6764115a86b5121ae9    SECURITY.md
040000 tree 918756f1a4e5d648ae273801359c440c951555f9    build
040000 tree 219a6e58af53f2e53b14b710a2dd8cbe9fea15f5    design
040000 tree 5810c119dd4d9a1c033c38c12fae781aeffeafc1    docker
040000 tree f09c5708676cdca6562f10e1f36c9cfd7ee45e07    src
040000 tree e6e1595f412599d0627a9e634007fcb2e32b62e5    website
</code></pre>
<h2 id="making-a-change" tabindex="-1">Making a change <a href="#making-a-change">#</a></h2>
<p>Let's make a change to the file and see how that works.</p>
<pre><code>$ <span>echo</span> <span>'blog.meain.io'</span> <span>&gt;</span> <span>file</span><br>$ <span>git</span> commit <span>-am</span> <span>'Use blog link'</span><br><span>[</span>master 68ed5aa<span>]</span> Use blog <span>link</span><br> <span>1</span> <span>file</span> changed, <span>1</span> insertion<span>(</span>+<span>)</span>, <span>1</span> deletion<span>(</span>-<span>)</span></code></pre>
<p>Here is what it does:</p>
<pre><code><span>--- commit      2024-07-02 15:33:28.536144046 +0530</span><br><span>+++ update      2023-07-02 15:47:20.841154907 +0530</span><br><span>@@ -17,6 +17,12 @@</span><br><span><span> </span><span>│   │   └── 5b58f323d7b459664b5d3fb9587048bb0296de<br></span><span> </span><span>│   ├── 62<br></span><span> </span><span>│   │   └── 901ec0eca9faceb8fe0a9870b9b6cde75a9545<br></span></span><span><span>+</span><span>│   ├── 67<br></span><span>+</span><span>│   │   └── ed5aa2372445cf2249d85573ade1c0cbb312b1<br></span><span>+</span><span>│   ├── 8a<br></span><span>+</span><span>│   │   └── b377e2f9acd9eaca12e750a7d3cb345065049e<br></span><span>+</span><span>│   ├── e5<br></span><span>+</span><span>│   │   └── ec63cd761e6ab9d11e7dc2c4c2752d682b36e2<br></span></span><span><span> </span><span>│   ├── info<br></span><span> </span><span>│   └── pack<br></span><span> </span><span>└── refs</span></span></code></pre>
<p>Well, we added 3 new objects. One of them would be a <code>blob</code> object with the new contents of the file, one would be a <code>tree</code> object and the last one will be a <code>commit</code> object.</p>
<p>Let's trace them again from the <code>HEAD</code> or <code>refs/heads/master</code>.</p>
<pre><code>$ <span>git</span> cat-file <span>-p</span> refs/heads/master<br>tree 9ab377e2f9acd9eaca12e750a7d3cb345065049e<br>parent 3c201df6a1c4d4c87177e30e93be1df8bfe2fe19<br>author Abin Simon <span>&lt;</span>mail@meain.io<span>&gt;</span> <span>1688292975</span> +0530<br>committer Abin Simon <span>&lt;</span>mail@meain.io<span>&gt;</span> <span>1688292975</span> +0530<p>Use blog <span>link</span></p><p>$ <span>git</span> cat-file <span>-p</span> 9ab377e2f9acd9eaca12e750a7d3cb345065049e<br><span>100644</span> blob e5ec63cd761e6ab9d11e7dc2c4c2752d682b36e2    <span>file</span></p><p>$ <span>git</span> cat-file <span>-p</span> e6ec63cd761e6ab9d11e7dc2c4c2752d682b36e2<br>blog.meain.io</p></code></pre>
<p>Those paying attention might have noticed that the <code>commit</code> object now has an additional key called <code>parent</code> which links to the previous commit as this commit is created on top of the previous commit.</p>
<h2 id="creating-a-branch" tabindex="-1">Creating a branch <a href="#creating-a-branch">#</a></h2>
<p>About time we created a branch. Let's do that with <code>git branch fix-url</code>.</p>
<pre><code><span>--- update      2024-07-02 15:47:20.841154907 +0530</span><br><span>+++ branch      2023-07-02 15:55:25.165204941 +0530</span><br><span>@@ -27,5 +28,6 @@</span><br><span><span> </span><span>│   └── pack<br></span><span> </span><span>└── refs<br></span><span> </span><span>    ├── heads<br></span></span><span><span>+</span><span>    │   ├── fix-url<br></span></span><span><span> </span><span>    │   └── master<br></span><span> </span><span>    └── tags</span></span></code></pre>
<p>This adds a new file under the folder <code>refs/heads</code> with a file as the branch name and the content as the id of the latest commit.</p>
<pre><code>$ <span>cat</span> .git/refs/heads/fix-url<br>68ed5aa2372445cf2249d85573ade1c0cbb312b1</code></pre>
<p>This is pretty much all there is to creating a branch. Branches in <code>git</code> are really cheap. Tags also behave the same way, except that they are created under <code>refs/tags</code>.</p>
<p>A file is also added under the <code>logs</code> directory to store the commit history data similar to <code>master</code> branch.</p>
<h2 id="checking-out-a-branch" tabindex="-1">Checking out a branch <a href="#checking-out-a-branch">#</a></h2>
<p>Checking out in <code>git</code> is git getting the <code>tree</code> object of a commit and updating the files in your worktree to match the state recorded in it. In this case, since we are switching from <code>master</code> to <code>fix-url</code>, both of which point to the same <code>commit</code> and underlying <code>tree</code> object, <code>git</code> does not have anything to do in the working tree.</p>
<pre><code><span>git</span> checkout fix-url</code></pre>
<p>The only change that happens when you do a checkout inside <code>.git</code> is that the <code>.git/HEAD</code> file will now point to <code>fix-url</code>.</p>
<pre><code>$ <span>cat</span> .git/HEAD<br>ref: refs/heads/fix-url</code></pre>
<p>Wile we are here, let me make a commit. I'm gonna need this to show what merging does later.</p>
<pre><code>$ <span>echo</span> <span>'https://blog.meain.io'</span><span>&gt;</span>file<br>$ <span>git</span> commit <span>-am</span> <span>'Fix url'</span></code></pre>
<h2 id="merging" tabindex="-1">Merging <a href="#merging">#</a></h2>
<p>There are primarily 3 ways of merging.</p>
<ol>
<li>The simplest and the most easiest is a fast forward merge. In this case you just update the commit a branch is pointing to a commit another branch is pointing to. This pretty much involves copying the hash in <code>refs/heads/fix-url</code> to <code>refs/heads/master</code>.</li>
<li>The second one is rebase merge. In this case we first apply our changes on top of what main is currently pointing to one commit at a time and then perform something similar to a fast forward merge.</li>
<li>The last one would be to just merge two branches using a separate merge commit. This is a bit different in that it will have two <code>parent</code> entries in its commit object. We will go a bit more into this towards the end.</li>
</ol>
<p>First let's see what the graph looks like before a merge.</p>
<pre><code><span>git</span> log <span>--graph</span> <span>--oneline</span> <span>--all</span><br>* 42c6318 <span>(</span>fix-url<span>)</span> Fix url<br>* 67ed5aa <span>(</span>HEAD -<span>&gt;</span> master<span>)</span> Use blog <span>link</span><br>* 3c201df Initial commit</code></pre>
<p>Now to perform the merge:</p>
<pre><code>$ <span>git</span> merge fix-url <span># updates refs/heads/master to the hash in refs/heads/fix-url</span></code></pre>
<pre><code>$ <span>git</span> log <span>--graph</span> <span>--oneline</span> <span>--all</span><br>* 42c6318 <span>(</span>HEAD -<span>&gt;</span> master<span>)</span> <span>(</span>fix-url<span>)</span> Fix url<br>* 67ed5aa Use blog <span>link</span><br>* 3c201df Initial commit</code></pre>
<h2 id="pushing" tabindex="-1">Pushing <a href="#pushing">#</a></h2>
<p>Now that we have been playing around with our local <code>git</code> repo for some time, let's see what happen when we push it. What is being sent to the git repo on the other side?</p>
<p>To show this, first let me create another git repo which can be used as remote for this  repo.</p>
<pre><code>$ <span>mkdir</span> git-talk-2<br>$ <span>cd</span> git-talk-2 <span>&amp;&amp;</span> <span>git</span> init <span>--bare</span><p>$ <span>cd</span> <span>..</span>/git-talk <span>&amp;&amp;</span> <span>git</span> remote <span>add</span> origin <span>..</span>/git-talk-2</p></code></pre>
<p>Btw, this change of adding a new remote is a config change and you can see that change in <code>.git/config</code> file. I'm gonna let you go look what the change was on your own.</p>
<p>Now let's <a href="https://www.youtube.com/watch?v=OuhFTX6yLXQ">push</a>.</p>
<pre><code>$ <span>git</span> push origin master</code></pre>
<p>Let's see what changed in our repo.</p>
<pre><code><span>--- branch	2023-07-02 15:55:25.165204941 +0530</span><br><span>+++ remote	2023-07-02 17:41:05.170923141 +0530</span><br><span>@@ -22,12 +29,18 @@</span><br><span><span> </span><span>│   ├── e5<br></span><span> </span><span>│   │   └── ec63cd761e6ab9d11e7dc2c4c2752d682b36e2<br></span><span> </span><span>│   ├── info<br></span><span> </span><span>│   └── pack<br></span><span> </span><span>├── ORIG_HEAD<br></span><span> </span><span>└── refs<br></span><span> </span><span>    ├── heads<br></span><span> </span><span>    │   ├── fix-url<br></span><span> </span><span>    │   └── master<br></span></span><span><span>+</span><span>    ├── remotes<br></span><span>+</span><span>    │   └── origin<br></span><span>+</span><span>    │       └── master<br></span></span><span><span> </span><span>    └── tags</span></span></code></pre>
<p>It added a new <code>refs/remotes</code> to store the information on what all is available in different remotes.</p>
<p>But what gets sent to the other git repo? It is everything that is in <code>objects</code> and under <code>refs</code>. That is all the other git instance needs to get your entire git history.</p>
<h2 id="references" tabindex="-1">References <a href="#references">#</a></h2>
<ul>
<li><a href="https://git-scm.com/book/en/v3/Git-Internals-Git-Objects">https://git-scm.com/book/en/v3/Git-Internals-Git-Objects</a></li>
<li><a href="https://matthew-brett.github.io/curious-git/reading_git_objects.html">https://matthew-brett.github.io/curious-git/reading_git_objects.html</a></li>
<li><a href="https://blog.meain.io/2020/bunch-of-git-stuff/">https://blog.meain.io/2020/bunch-of-git-stuff/</a></li>
</ul>


<p><a href="https://blog.meain.io/">← Home</a></p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Unreal Engine will no longer be free for all (157 pts)]]></title>
            <link>https://www.creativebloq.com/news/epic-games-unreal-engine-charge</link>
            <guid>37792030</guid>
            <pubDate>Fri, 06 Oct 2023 15:24:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.creativebloq.com/news/epic-games-unreal-engine-charge">https://www.creativebloq.com/news/epic-games-unreal-engine-charge</a>, See on <a href="https://news.ycombinator.com/item?id=37792030">Hacker News</a></p>
<div id="readability-page-1" class="page"><article aria-label="article" data-id="3SQ7DLX5NJZCHBGUGzFPtk">
<header>
<nav aria-label="Breadcrumbs">
<ol>
<li>
<a href="https://www.creativebloq.com/news" aria-label="Return to News">News</a>
</li>
<li>
<a href="https://www.creativebloq.com/tag/digital-art" aria-label="Return to Digital Art">Digital Art</a>
</li>
</ol>
</nav>



</header>
<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture><source type="image/webp" alt="Unreal Engine and Unity learn a game engine; a 3d render of a cityscape" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1920-80.jpg.webp 1920w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode.jpg"><source type="image/jpeg" alt="Unreal Engine and Unity learn a game engine; a 3d render of a cityscape" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1920-80.jpg 1920w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode.jpg"><img src="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-320-80.jpg" alt="Unreal Engine and Unity learn a game engine; a 3d render of a cityscape" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode-1920-80.jpg 1920w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode.jpg"></picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/EDzmP6PkqtigWFF9r5Qode.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: Epic Games)</span>
</figcaption>
</div>

<div id="article-body">
<p>Bad news for those using <a href="https://www.creativebloq.com/tag/unreal-engine" data-auto-tag-linker="true">Unreal Engine</a> for VFX or animation this week – or at least for some. Epic Games has confirmed that it will begin charging industries outside gaming to use the 3D graphics engine next year.&nbsp;</p><p>Until now the company has not charged directly for use of Unreal Engine. Instead it charges royalties for projects that surpass $1m in revenue – and only those that use code from the engine. That means that while the developers of big-selling games pay royalties, those who use Unreal Engine for film making and other uses pay nothing. Epic Games now plans to start charging subscription fees on a per-seat basis, but it has clarified that not everyone will be affected (also see our pick of the <a href="https://www.creativebloq.com/features/best-free-3d-apps">best 3D apps</a>).</p><div><blockquote data-lang="en"><p lang="en" dir="ltr">Tim Sweeney addresses Epic Games Layoffs... #UnrealFest pic.twitter.com/49t4Tf20SA<a href="https://twitter.com/ImmatureGamerX/status/1709216675730542972" data-url="https://twitter.com/ImmatureGamerX/status/1709216675730542972">October 3, 2023</a></p></blockquote><p><span role="button" tabindex="0" aria-label="See more">See more</span></p></div><p>Speaking at Unreal Fest 2023, Epic Games CEO Tim Sweeney said Unreal Engine would become “a licensable piece of software like Maya or <a href="https://www.creativebloq.com/tag/photoshop" data-auto-tag-linker="true">Photoshop</a>” with a subscription-based pricing model. Studios using it for non-gaming work like animation, VFX and visualization will be charged through a “seat-based enterprise software licensing model”</p><p>The video above, shared from the event by the creative developer <a href="https://twitter.com/ImmatureGamerX" target="_blank" data-url="https://twitter.com/ImmatureGamerX">Immature on Twitter</a>, shows Sweeney outlining the company’s sources of income, which will include licensing Unreal Engine, in the context of Epic's recent decision to lay off 16% of its staff.</p><div><blockquote data-lang="en"><p lang="en" dir="ltr">Won’t affect. There will be minimum revenue thresholds for commercial projecrs, and student/educator use will remain free.<a href="https://twitter.com/TimSweeneyEpic/status/1709731335147831316" data-url="https://twitter.com/TimSweeneyEpic/status/1709731335147831316">October 5, 2023</a></p></blockquote><p><span role="button" tabindex="0" aria-label="See more">See more</span></p></div><p>Understandably, the news has caused concern among creatives, especially independent filmmakers and non-professionals. Unreal Engine was developed as a graphics engine for gaming, but is now routinely used for real-time rendering and virtual production in everything from animation, to commercials, including by aspiring filmmakers who may not be able to pay for a subscription.</p><p>Replying to <a href="https://twitter.com/TimSweeneyEpic/status/1709731335147831316" target="_blank" data-url="https://twitter.com/TimSweeneyEpic/status/1709731335147831316">a question raised on X</a>, Sweeney has now clarified that there will be minimum revenue thresholds for commercial projects that have to pay for a subscription and that student and educator use of Unreal Engine will remain free.</p><p>There is no detail as yet on what the threshold will be, but the idea seems to be to charge larger studios and developers. It's also unknown what the Unreal Engine price or terms will look like – Sweeney said pricing would not be "unusually expensive, or unusually inexpensive”. The move will not affect game developers who will continue to pay a 5 per cent royalty rate after revenue passes $1m.</p><p>Sweeney said he was announcing the change ahead of time to ensure transparency. Some have suggested that the move was inevitable, noting that it was unusual that access has remained free. However, others have raised concerns that a subscription model could means some creatives cannot afford to use the tool. "Can you imagine that there are some really good unreal engine users that cannot afford subscription in some countries? Please keep it free to use and monetize results for movie and nongame usage," the producer Mihai Ogasanu wrote.</p><p>In our <a href="https://www.creativebloq.com/reviews/unreal-engine-53">Unreal Engine 5.3 review</a>, we note that Unreal Engine continues to redefine the game engine industry with a new skeletal mesh editor, cloth editor and volumetric capabilities.</p>
</div>
<div>
<p><img src="https://cdn.mos.cms.futurecdn.net/flexiimages/mcasa08ogs1651144853.svg"></p>
<div>
<p><strong><span>Thank you for reading 5 articles this month* Join now for unlimited access</span></strong></p><p><strong><span>Enjoy your first month for just £1 / $1 / €1</span></strong></p>
</div>

<p><span>*Read 5 free articles per month without a subscription</span></p>
</div>


<div>
<p><img src="https://cdn.mos.cms.futurecdn.net/flexiimages/mcasa08ogs1651144853.svg">
</p>
<div>
<p><strong><span>Join now for unlimited access</span></strong></p><p>Try first month for just <strong>£1 / $1 / €1</strong></p>
</div>

</div>



<div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent"><section><p>Daily design news, reviews, how-tos and more, as picked by the editors.</p></section></div>
<div id="slice-container-authorBio"><p>Joe is a regular freelance journalist and editor at Creative Bloq. He writes news and features, updates buying guides and keeps track of the best equipment for creatives, from monitors to accessories and office supplies. A writer and translator, he also works as a project manager at London and Buenos Aires-based design and branding agency Hermana Creatives, where he manages a team of designers, photographers and video editors who specialise in producing photography, video content, graphic design and collaterals for the hospitality sector. He enjoys photography, particularly nature photography, wellness and he dances Argentine tango.</p></div>


<div>
<h4>Related articles</h4>

</div>
</section>



</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EU Grabs ARM for First ExaFLOP Supercomputer, x86 Misses Out (146 pts)]]></title>
            <link>https://www.hpcwire.com/2023/10/04/eu-grabs-arm-for-first-exaflop-supercomputer-x86-misses-out/</link>
            <guid>37791116</guid>
            <pubDate>Fri, 06 Oct 2023 14:18:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.hpcwire.com/2023/10/04/eu-grabs-arm-for-first-exaflop-supercomputer-x86-misses-out/">https://www.hpcwire.com/2023/10/04/eu-grabs-arm-for-first-exaflop-supercomputer-x86-misses-out/</a>, See on <a href="https://news.ycombinator.com/item?id=37791116">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p>The configuration of Europe’s first exascale supercomputer, Jupiter, has been finalized, and it is a win for Nvidia and a disappointment for x86 chip vendors Intel and AMD. The Jupiter supercomputer, which will cost €273 million to build, will pair SiPearl’s Rhea processor, which is based on ARM architecture, with accelerator technology from Nvidia.</p>
<p>The supercomputer is being built by the European High-Performance Computing Joint Undertaking (EuroHPC JU) and a consortium including Eviden and ParTec. Eviden is an Atos business focusing on advanced computing initiatives that include HPC and AI.</p>
<p>The Jülich Supercomputing Centre, which is near Munich, will host the system. The installation will begin in early 2024.</p>
<p>Specifically, the supercomputer’s main compute cluster will be based on ARM CPUs, and the initial configuration does not include x86. Six of the top 10 supercomputers in the world are based on x86 chips, and only one is based on ARM.</p>
<p>That is a big disappointment for Intel, which last year announced it would invest €33 billion to build a new chip factory and fund research and development initiatives in Europe. Intel’s CEO Pat Gelsinger also met with EU leaders in a bid to get more business in the region.</p>
<p>Jülich’s fastest system, JUWELS, was last featured in the Top500 list in November 2021 and is currently ranked 13. The fastest supercomputers in Europe are the third-ranked Lumi in Finland, which delivers a peak performance of 309 petaflops, and the fourth-ranked Leonardo in Italy, which peaks at 239 petaflops.</p>
<p>Jupiter was first announced last year and is designed to be a modular system in which multiple types of accelerators can be plugged into the core system.</p>
<p>The supercomputer is being built by almost the same cast of characters, including Atos (now Eviden) and system integrator Partec, responsible for the 44-petaflop JUWELS supercomputer, which was installed in 2020 with AMD’s Epyc 7402 chip.</p>
<p>The Jupiter will instead have SiPearl’s ARM processor based on ARM’s Neoverse V1 CPU design. SiPearl has designed the Rhea chip to be universally compliant with many accelerators, and it supports high-bandwidth memory and DDR5 memory channels.</p>
<figure id="attachment_165009" aria-describedby="caption-attachment-165009"><img decoding="async" loading="lazy" src="https://www.hpcwire.com/wp-content/uploads/2023/10/SciPearl-Rhea-300x145.png" alt="SciPearl Rhea" width="277" height="134" srcset="https://www.hpcwire.com/wp-content/uploads/2023/10/SciPearl-Rhea-300x145.png 300w, https://www.hpcwire.com/wp-content/uploads/2023/10/SciPearl-Rhea-150x72.png 150w, https://www.hpcwire.com/wp-content/uploads/2023/10/SciPearl-Rhea.png 460w" sizes="(max-width: 277px) 100vw, 277px"><figcaption id="caption-attachment-165009">European Rhea processor designed to deliver fast real compute performance and efficiency with an unmatched Bytes/Flops ratio. Source: SiPearl</figcaption></figure>
<p>Jupiter will have Nvidia’s Booster Module, an integrated system that includes the company’s GPUs and Mellanox interconnects. SiPearl has been working with Nvidia to connect its CPUs with Nvidia GPUs.<br>
The current JUWELS Booster Module uses Nvidia’s A100 GPUs, and Jupiter could be upgraded to Nvidia’s H100 GPUs. Nvidia has not shared details of successors to H100, and Jupiter’s installation is due to begin in three months.</p>
<p>While Intel and AMD may be losers in the Jupiter deal, it does not preclude their chips from being used in the supercomputer. Jupiter’s modular design means that Jülich may opt to add GPUs, and less likely, CPUs, from those companies into modules that plug into the core compute system.</p>
<p>Intel worked extensively with SiPearl to bring OneAPI support for its Ponte Vecchio supercomputing GPUs to Rhea. SiPearl last year partnered with AMD to make Instinct GPUs compatible with Rhea chips.<br>
Jülich is also building out its machine-learning and quantum computing infrastructure, which the supercomputing center hopes to plug in as accelerator modules hosted at its facility.</p>
<p>ARM, which recently became a publicly listed company, will get a feather on its cap as it looks to break the dominance of x86 in supercomputing. The world’s second fastest supercomputer, Fugaku, installed at the Riken Center for Computational Science, is based on an ARM processor from Fujitsu.</p>
<p>Europe is striving for hardware independence with homegrown CPU designs, so the selection of Rhea CPUs for Jupiter shouldn’t come as a surprise.</p>
<p>SiPearl, based in France, started developing Rhea with seed funding from the European Processor Initiative, which wants to develop open-chip designs that cut reliance on foreign chip technologies. The EPI is focused heavily on chip design based on the open-source RISC-V architecture.<br>
SiPearl is a relatively new chip design company compared to the well-established Intel and AMD and is now under pressure to prove its chip will support the exaflop performance.</p>
<p>SiPearl chose ARM as it is well-established and ready for high-performance applications. Experts say RISC-V is many years away from mainstream server adoption. EuroHPC JU requested Jupiter suppliers to meet energy efficiency, performance, system stability, and programmability requirements.</p>
<p>Jupiter will run classic computing applications and is also designed for AI technologies such as large-language models. AI applications could involve creating simulations that hasten drug discovery or simulating weather problems to make predictions or solve problems related to climate change.</p>
<p>The exaflop performance is expected to be based on the LINPACK benchmark. Nvidia, Google, and others have released debatable supercomputing AI benchmarks, often reporting performance in excess of one exaflop.</p>
<p>Top500 in 2021 tested the mixed-precision HPL-AI (High-Performance LINPACK for Accelerator Introspection) benchmark, which propelled the total performance of ARM-based RIKEN to 2.0 exaflops, compared to 442 exaflops on conventional LINPACK measurements.</p>
<p>Jupiter is also a big step forward in the EU’s effort to achieve computing independence and reduce its reliance on proprietary tech.</p>
<p>The European Commission last month passed the European Chips Act, which opened €43 billion in public funding for manufacturing, next-generation semiconductor technology, and research.</p>
<p>The regulation specifically opens up €2 billion for HPC and €1.67 billion for artificial intelligence. The HPC allotment is related to procuring and building out the supercomputing and quantum infrastructure within the EU.</p>
<p>However, Europe is still behind the US, China, and Japan in the race to build the world’s fastest supercomputers.</p>
<p>The US is expected to host two exaflop supercomputers — Aurora at ORNL and El Capitan at the Lawrence Livermore National Laboratory — in the coming years, which will again put Europe behind. China has hinted that multiple exaflop supercomputers are already or expected to go online.</p>
<p>Europe’s second exascale supercomputer will be up and running in France by the end of 2025. EuroHPC JU announced in June that the supercomputer will be hosted and operated by the Jules Verne consortium, which includes French institutions GENCI (Grand Equipement National de Calcul Intensif), the CEA (the Alternative Energies and Atomic Energy Commission), and Dutch national supercomputing center SURF.</p>
<p>Jupiter’s total cost is €273 million, over half that of the original €500 million budget. About half of the cost of standing up Jupiter is funded by the EuroHPC JU, and the remaining amount is funded by the German Federal Ministry of Education and Research and the Ministry of Culture and Science of the State of North Rhine-Westphalia.</p>
							<div>
						<p><span>Tags:</span>
						<a href="https://www.hpcwire.com/tag/a100/" rel="tag">A100</a>, <a href="https://www.hpcwire.com/tag/arm/" rel="tag">ARM</a>, <a href="https://www.hpcwire.com/tag/aurora/" rel="tag">Aurora</a>, <a href="https://www.hpcwire.com/tag/cea/" rel="tag">CEA</a>, <a href="https://www.hpcwire.com/tag/el-capitan/" rel="tag">El Capitan</a>, <a href="https://www.hpcwire.com/tag/eu/" rel="tag">EU</a>, <a href="https://www.hpcwire.com/tag/eurohpc-ju/" rel="tag">EuroHPC JU</a>, <a href="https://www.hpcwire.com/tag/genci/" rel="tag">GENCI</a>, <a href="https://www.hpcwire.com/tag/h100/" rel="tag">H100</a>, <a href="https://www.hpcwire.com/tag/juwels/" rel="tag">JUWELS</a>, <a href="https://www.hpcwire.com/tag/lawrence-livermore-national-laboratory/" rel="tag">Lawrence Livermore National Laboratory</a>, <a href="https://www.hpcwire.com/tag/linpack/" rel="tag">LINPACK</a>, <a href="https://www.hpcwire.com/tag/neoverse/" rel="tag">Neoverse</a>, <a href="https://www.hpcwire.com/tag/oneapi/" rel="tag">OneAPI</a>, <a href="https://www.hpcwire.com/tag/ornl/" rel="tag">ORNL</a>, <a href="https://www.hpcwire.com/tag/ponte-vecchio/" rel="tag">Ponte Vecchio</a>, <a href="https://www.hpcwire.com/tag/rhea/" rel="tag">Rhea</a>, <a href="https://www.hpcwire.com/tag/riken/" rel="tag">RIKEN</a>, <a href="https://www.hpcwire.com/tag/risc-v/" rel="tag">RISC-V</a>, <a href="https://www.hpcwire.com/tag/surf/" rel="tag">SURF</a>, <a href="https://www.hpcwire.com/tag/top500/" rel="tag">TOP500</a>, <a href="https://www.hpcwire.com/tag/x86/" rel="tag">X86</a>					</p></div><!-- .entry-utility -->
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Making Hard Things Easy (813 pts)]]></title>
            <link>https://jvns.ca/blog/2023/10/06/new-talk--making-hard-things-easy/</link>
            <guid>37791002</guid>
            <pubDate>Fri, 06 Oct 2023 14:09:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jvns.ca/blog/2023/10/06/new-talk--making-hard-things-easy/">https://jvns.ca/blog/2023/10/06/new-talk--making-hard-things-easy/</a>, See on <a href="https://news.ycombinator.com/item?id=37791002">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
     

<p>A few weeks ago I gave a keynote at <a href="https://www.thestrangeloop.com/">Strange Loop</a>
called Making Hard Things Easy. It’s about why I think some things are hard
to learn and ideas for how we can make them easier.</p>

<p>Here’s the video, as well as the slides and a transcript of (roughly) what I
said in the talk.</p>

<h3 id="the-video">the video</h3>

<iframe width="560" height="315" src="https://www.youtube.com/embed/30YWsGDr8mA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<h3 id="the-transcript">the transcript</h3>



<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-0.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-0.png"></a>
</p>
<p>


Hello, Strange Loop! Strange Loop is one of the first places I
spoke almost 10 years ago and I'm so honored to be back here today for the
last one. Can we have one more round of applause for the organizers?


</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-1.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-1.png"></a>
</p>
<div>

<p>
I often give talks about things that I'm excited about,
or that I think are really fun.
</p>

<p>
But today, I want to talk about something that I'm a little bit mad about,
which is that sometimes things that seem like they should be basic take me 10
years or 20 years to learn, way longer than it seems like they should. 
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-2.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-2.png"></a>
</p>
<p>

One thing that took me a long time to learn was DNS, which is this question
of -- what's the IP address for a domain name like example.com?
This feels like it should be a straightforward thing.


</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-3.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-3.png"></a>
</p>
<p>

But seven years into learning DNS, I'd be setting up a website. And I'd feel
like things should be working. I thought I understood DNS. But then I'd run
into problems, like my domain name wouldn't work. And I'd wonder -- why not?
What's happening?

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-4.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-4.png"></a>
</p>
<div>

<p>
And sometimes this would feel kind of personal! This shouldn't be so hard
for me! I should understand this already. It's been seven years!
</p>


<p>
And this "it's just me" attitude is often encouraged -- when I write about
finding things hard to learn on the Internet, Internet strangers will sometimes
tell me: "yeah, this is easy! You should get it already! Maybe you're just not
very smart!"
</p>

<p>
But luckily I have a pretty big ego so I don't take the internet strangers too
seriously. And I have a lot of patience so I'm willing to keep coming back to a
topic I'm confused about. There were maybe four different things that were
going wrong with DNS in my life and eventually I figured them all out.
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-5.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-5.png"></a>
</p>
<div>

<p>
So, hooray! I understood DNS! I win! But then I see some of my friends struggling with
the exact same things.
</p>

<p>
They're wondering, hey, my DNS isn't working. Why not? 
</p>




</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-6.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-6.png"></a>
</p>
<div>
<p>
And it doesn't end. We're still having the same problems over and over and over
again. And it's frustrating! It feels redundant! It makes
me mad. Especially when friends take it personally, and they feel like "hey I
should really understand this already".
</p>

<p>
Because everyone is going through this. From the sounds of recognition I hear,
I think a lot of you have been through some of these same problems with DNS.
</p>
</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-7.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-7.png"></a>
</p>
<p>

I got so mad about this that I decided to make it my job. 
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-8.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-8.png"></a>
</p>
<div>

   <p>
   I started a little publishing company called Wizard Zines where --
   </p>
   
 <p>
 (applause)
 </p>
 
   <p>
   Wow. Where I write about some of these topics and try to demystify them.
   </p>
     
</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-9.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-9.png"></a>
</p>
<p>
     Here are a few of the zines I've published. I want to talk today about a
     few of these topics and what makes them so hard and how we can make them
     easier.
     
    
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-10.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-10.png"></a>
</p>
<p>
 We're going to talk about bash, HTTP, SQL, and DNS.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-11.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-11.png"></a>
</p>
<div>


<p>
 For each of them, we're
 going to talk a little bit about:
 </p>
   
 <p>
 a.  what's so hard about it? 
 </p>
   
 <p>
 b. what are some things we can do to make it a little bit easier for each other?
 </p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-12.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-12.png"></a>
</p>
<p>
   Let's start with Bash. 

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-13.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-13.png"></a>
</p>
<p>
What's so hard about it?
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-14.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-14.png"></a>
</p>
<p>
So, bash is a programming language, right?
But it's one of the weirdest programming languages that I work
with.


</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-15.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-15.png"></a>
</p>
<p>

To understand why it's weird, let's do a little small demo
of bash.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-16.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-16.png"></a>
</p>
<div>


<p>
First, let's run this script, <code>bad.sh</code>:
</p>

<pre>mv ./*.txt /tmmpp
echo "success!"
</pre>

   <p>
   This moves a file and prints "success!". And with most of the programming languages that I use, if there's a problem, the program will stop.
   </p>
   
 <p>
 [laughter from audience]
 </p>
 
 <p>
 
     But I think a lot of you know from maybe sad experience that bash does not
     stop, right? It keeps going. And going... and sometimes very bad things
     happen to your computer in the process. 
   </p>
   
 <p>
 When I run this program, here's the output:
 </p>
   
   <pre>mv: cannot stat './*.txt': No such file or directory
success!
</pre>

<p>
It didn't stop after the failed <code>mv</code>.
</p>
     
</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-17.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-17.png"></a>
</p>
<div>

<p>
Eventually I learned that you can write <code>set
-e</code> at the top of your program, and that will make bash stop if
there's a problem. 
</p>

<p>
When we run this new program with <code>set -e</code> at the top, here's the output:
</p>

<pre>mv: cannot stat './*.txt': No such file or directory
</pre>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-18.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-18.png"></a>
</p>
<p>
Great. We're happy. Everything is good. But every time I think I've learned
everything that go wrong with bash, I'll find out -- surprise! There are more
bad things that can happen! Let's look at another program as an example.
     
    </p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-19.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-19.png"></a>
</p>
<div>

<p>
Here we've put our code in a function. And if the function
fails, we want to echo "failed". 

</p>

<p>
So use <code>set -e</code> at the beginning, and you might think everything should be okay. 
</p>

<p>
But if we run it... this is the output we get
</p>

<pre>mv: cannot stat './*.txt': No such file or directory
success
</pre>

<p>
We get the "success" message again! It didn't stop, it just kept going. This is
because the "or" (<code>|| echo "failed"</code>) globally disables <code>set -e</code> in the
function.
</p>

<p>
Which is certainly not what I wanted, and not what I would expect. But this is
not a bug in bash, it's is the documented behavior.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-20.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-20.png"></a>
</p>
<div>

<p>
And I think one reason this is tricky is a lot of us don't use bash very often.
Maybe you write a bash script every six months and don't look at it again.
</p>

<p>
When you use a system very infrequently and it's full of a lot of weird trivia
and gotchas, it's hard to use the system correctly.
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-21.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-21.png"></a>
</p>
<p>

So how can we make this easier? What can we do about it?
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-22.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-22.png"></a>
</p>
<p>
One thing that I sometimes hear is -- a newcomer will say "this is hard",
and someone more experienced will say "Oh, yeah, it's impossible to use bash.
Nobody knows how to use it."



</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-23.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-23.png"></a>
</p>
<div>

<p>
But I would say this is factually untrue. How many of you are using bash?
</p>

<p>
A lot of us ARE using it! And it doesn't always work perfectly, but often
it gets the job done.
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-24.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-24.png"></a>
</p>
<p>

We have a lot of bash programs that are mostly working, and there's a big
community of us who are using bash mostly successfully despite all the
problems.

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-25.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-25.png"></a>
</p>
<div>

<p>
The way I think this is --  you have some people on the left in this
diagram who are confused about bash, who think it seems awful and
incomprehensible.
</p>

<p>
And some people on the right who know how to make the bash work for them,
mostly.
</p>

<p>
So how do we move people from the left to the right, from being overwhelmed by
a pile of impossible gotchas to being able to mostly use the system correctly?
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-26.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-26.png"></a>
</p>
<p>

Well, bash has a giant pile of trivia to remember. But who's good at remembering
giant piles of trivia?
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-27.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-27.png"></a>
</p>
<p>

Not me! I can't memorize all of the weird things about bash. But computers!
Computers are great at memorizing trivia!

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-28.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-28.png"></a>
</p>
<div>

<p>
And for bash, we have this incredible tool called
shellcheck.
</p>

<p>
[ Applause ]
</p>

<p>
Yes! Shellcheck is amazing! And shellcheck knows a lot of things that can go
wrong and can tell you "oh no, you don't want to do that. You're going to have
a bad time."
</p>

<p>
I'm very grateful for shellcheck, it makes it much easier for me to write
tiny bash scripts from time to time. 
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-29.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-29.png"></a>
</p>
<div>

<p>
Now let's do a shellcheck demo! 
</p>

<pre>$ shellcheck -o all bad-again.sh
In bad-again.sh line 7:
f || echo "failed!"
^-- SC2310 (info): This function is invoked in an || condition so set -e will be disabled. Invoke separately if failures should cause the script to exit.
</pre>

<p>
Shellcheck gives us this
lovely error message. The message isn't completely obvious on its own (and this
check is only run if you invoke shellcheck with <code>-o all</code>). But
shellcheck tells you "hey, there's this problem, maybe you should be worried
about that".
</p>

<p>
And I think it's wonderful that all these tips live in this linter. 
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-30.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-30.png"></a>
</p>
<div>

<p>
I'm not trying to tell you to write linters, though I think that some of you
probably will write linters because this is that kind of crowd.
</p>

<p>
I've personally never written a linter, and I'm definitely not going to create
something as cool as shellcheck!
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-31.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-31.png"></a>
</p>
<div>

<p>
But instead, the way I write linters is I tell people about shellcheck from
time to time and then I feel a little like I invented shellcheck for those
people. Because some people didn't know about the tool until I told them about
it!
</p>

<p>
I didn't find out about shellcheck for a long time and I was kind of mad about
it when I found out. I felt like -- excuse me? I could have been using
shellcheck this whole time? I didn't need to remember all of this stuff in
my brain?
</p>

<p>
So I think an incredible thing we can do is to reflect on the tools that we're
using to reduce our cognitive load and all the things that we can't fit into
our minds, and make sure our friends or coworkers know about them.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-32.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-32.png"></a>
</p>
<p>
I also like to warn people about gotchas and some of the terrible things
computers have done to me.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-33.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-33.png"></a>
</p>
<div>

<p>
I think this is an incredibly valuable community service. The example I shared
about how <code>set -e</code> got disabled is something I learned from my
friend Jesse a few weeks ago. 
</p>

<p>
They told me how this thing happened to them, and now I know and I don't have
to go through it personally.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-34.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-34.png"></a>
</p>
<div>

<p>
One way I see people kind of trying to share terrible things that their
computers have done to them is by sharing "best practices".
</p>

<p>
But I really love to hear the stories behind the best practices!
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-35.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-35.png"></a>
</p>
<div>


<p>
If someone has
a strong opinion like "nobody should ever use bash", I want to hear about the
story! What did bash do to you? I need to know.
</p>

<p>
The reason I prefer stories to best practices is if I know the story about how
the bash hurt you, I can take that information and decide for myself how I want
to proceed.
</p>

<p>
Maybe I feel like -- the computer did that to you? That's okay, I can deal with
that problem, I don't mind.
</p>

<p>
Or I might instead feel like "oh no, I'm going to do the best practice you
recommended, because I do not want that thing to happen to me". 
</p>

<p>
These bash stories are a great example of that: my reaction to them is "okay,
I'm going to keep using bash, I'll just use shellcheck and keep my bash scripts
pretty simple". But other people see them and decide "wow, I never want to use
bash for anything, that's awful, I hate it".
</p>

<p>
Different people have different reactions to the same stories and that's okay.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-36.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-36.png"></a>
</p>
<p>
That's all for bash. Next up we're gonna talk about HTTP. 
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-37.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-37.png"></a>
</p>

</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-38.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-38.png"></a>
</p>
<div>

<p>
I was talking to Marco Rogers at some point, many years ago, and he mentioned
some new developers he was working with were struggling with HTTP.
</p>

<p>
And at first, I was a little confused about this -- I didn't understand what
was hard about HTTP.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-39.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-39.png"></a>
</p>
<div>

<p>
The way I was thinking about it
at the time was that if you have an HTTP response, it has a few parts: a response
code, some headers, and a body.
</p>


<p>
I felt like -- that's a pretty simple structure, what's the problem? But of
course there was a problem, I just couldn't see what it was at first.
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-40.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-40.png"></a>
</p>
<div>

<p>
So, I talked to a friend who was newer to HTTP. And they asked "why does it
matter what headers you set?"
</p>

<p>
And I said: "well, the browser..."
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-41.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-41.png"></a>
</p>
<p>
But then I thought... the browser?
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-42.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-42.png"></a>
</p>
<p>
the browser?
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-43.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-43.png"></a>
</p>
<div>

<p>
The browser!
</p>

<p>
Firefox is 20 million lines of code! It's been
evolving since the '90s. There have been as I understand it, 1 million
changes to the browser security model as people have discovered new and
exciting exploits and the web has become a scarier and scarier place.
</p>

<p>
The browser is really a lot to understand.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-44.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-44.png"></a>
</p>
<div>



<p>
One trick for understanding why a topic is hard is -- if the implementation if the
thing involves 20 million lines of code, maybe that's why people are confused!
</p>

<p>
Though that 20 million lines of code also involves CSS and JS and many other
things that aren't HTTP, but still.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-45.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-45.png"></a>
</p>
<div>

<p>
Once I thought of it in terms of how complex a modern web browser is, it
made so much more sense! Of course newcomers are confused about HTTP if you
have to understand what the browser is doing!
</p>

<p>
Then my problem changed from "why is this hard?" to "how do I explain this at all?"
</p>

<p>
So how do we make it easier? How do we wrap our minds around this 20 million lines
of code?
</p>



</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-46.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-46.png"></a>
</p>
<p>
One way I think about this for HTTP is: here are some of the HTTP request
headers. That's kind of a big list there are 43 headers there.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-47.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-47.png"></a>
</p>
<p>
There are more unofficial headers too.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-48.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-48.png"></a>
</p>
<div>

<p>
My brain does not contain all of those headers, I have no idea what most of
them are.
</p>

<p>
When I think about trying to explain big topics, I think about -- what is
actually in my brain, which only contains a normal human number of things?
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-49.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-49.png"></a>
</p>
<div>


<p>
This is <a href="https://wizardzines.com/comics/request-headers/">a comic I drew about HTTP request headers</a>.
You don't have to read the whole thing. This has 15
request headers.
</p>

<p>
I wrote that these are "the most important headers", but what I mean by "most
important" here is that these are the ones that I know about and use. It's a
subjective list.
</p>

<p>
I wrote about 12 words about each one, which I think is approximately the
amount of information about each header that lives in my mind.
</p>

<p>
For example I know that you can set <code>Accept-Encoding</code> to <code>gzip</code>
and then you might get back a compressed response. That's all I know,
and that's usually all I need to know!
</p>

<p>
This very small set of information is working pretty well for me.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-50.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-50.png"></a>
</p>
<div>


<p>
The general way I think about this trick is "turn a big list into a small list".
</p>

<p>
Turn the set of EVERY SINGLE THING into just the things I've personally used. I
find it helps a lot.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-51.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-51.png"></a>
</p>
<div>


<p>
Another example of this "turn a big list into a small list" trick is command line arguments.
</p>

<p>
I use a lot of command line tools, the number of arguments they have can be
overwhelming, and I've written about them <a href="https://wizardzines.com/zines/bite-size-command-line/">a fair amount</a> over
the years.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-52.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-52.png"></a>
</p>
<p>
Here are all the flags for grep, from its man page. That's too much! I've been
using grep for 20 years but I don't know what all that stuff is.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-53.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-53.png"></a>
</p>
<div>

<p>
But when I look at the grep man page, this is what I see.
</p>


<p>
I think it's very helpful to newcomers when a more experienced person says
"look, I've been using this system for a while, I know about 7 things about it,
and here's what they are".
</p>

<p>
We're just pruning those lists down to a more human scale. And it can even help
other more experienced people -- often someone else will know a slightly
different set of 7 things from me.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-54.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-54.png"></a>
</p>
<div>

<p>
But what about the stuff that doesn't fit in my brain?
</p>

<p>
Because I have a few things about HTTP stored in my brain. But sometimes I need
other information which is hard to remember, like maybe the exact details of
how CORS works.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-55.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-55.png"></a>
</p>
<p>

And so, that's where we come to references. Where do we find the information
that we can't remember?

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-56.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-56.png"></a>
</p>
<div>

<p>
I often have trouble finding the right references.
</p>

<p>
For example I've been trying to learn CSS off and on for 20 years. I've made a
lot of progress -- it's going well!
</p>

<p>
But only in the last 2 years or so I learned about this wonderful website called 
<a href="https://css-tricks.com/">CSS Tricks</a>.
</p>

<p>
And I felt kind of mad when I learned about CSS Tricks! Why didn't I know about
this before? It would have helped me!
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-57.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-57.png"></a>
</p>
<div>


<p>
But anyway, I'm happy to know about CSS Tricks now. (though sadly they seem to
have stopped publishing in April after the acquisition, I'm still happy the older posts are there)
</p>

<p>
For HTTP, I think a lot of us use the Mozilla Developer Network. 
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-58.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-58.png"></a>
</p>
<div>


<p>
Another HTTP reference I love is the official RFC, <a href="https://www.rfc-editor.org/rfc/rfc9110">RFC 9110</a> (also
<a href="https://www.rfc-editor.org/rfc/rfc9111">9111</a>,
<a href="https://www.rfc-editor.org/rfc/rfc9112">9112</a>,
<a href="https://www.rfc-editor.org/rfc/rfc9113">9113</a>,
<a href="https://www.rfc-editor.org/rfc/rfc9114">9114</a>)
</p>

<p>
It's a new authoritative reference for HTTP and it was written just last
year, in 2022! They decided to organize all the information really nicely. So if you
want to know exactly what the <code>Connection</code> header does, you can look
it up. 
</p>

<p>
This is not really my top reference. I'm usually on MDN. But I really
appreciate that it's available.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-59.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-59.png"></a>
</p>
<p>
So I love to share my favorite references.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-60.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-60.png"></a>
</p>
<div>

<p>
I do sometimes find it tempting to kind of lie about references. Not on
purpose.
But I'll see something on the internet, and I'll think it's kind of cool, and
tell a friend about. But then my friend might ask me -- "when have you used this?"
And I'll have to admit "oh, never, I just thought it seemed cool".
</p>

<p>
I think it's important to be honest about what the references that I'm actually
using in real life are. Even if maybe the real references I use are a little
"embarrassing", like maybe w3schools or something.
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-61.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-61.png"></a>
</p>
<p>

So that's HTTP! Next we're going to talk about SQL.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-62.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-62.png"></a>
</p>
<p>
The case of the mysterious execution order.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-63.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-63.png"></a>
</p>
<div>

<p>
I started thinking about SQL because someone mentioned they're trying to learn
SQL. I get most of my zine ideas that way, one person will make an offhand
comment and I'll decide "ok, I'm going to spend 4 months writing about
that". It's a weird process.
</p>

<p>
So I was wondering -- what's hard about SQL? What gets in the way of trying
to learn that?
</p>

<p>
I want to say that when I'm confused about what's hard about something, that's
a fact about me. It's not usually that the thing is easy, it's that I need to
work on understanding what's hard about it. It's easy to forget when you've
been using something for a while.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-64.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-64.png"></a>
</p>
<p>
So, I was used to reading SQL queries. For example this made up query that tries to
find people who own exactly two cats. It felt straightforward
to me, SELECT,
FROM, WHERE, GROUP BY.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-65.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-65.png"></a>
</p>
<div>

<p>
But then I was talking to a friend about these queries who was new to SQL. And
my friend asked -- what is this doing?
</p>

<p>
I thought, hmm, fair point.
</p>



</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-66.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-66.png"></a>
</p>
<p>
And I think the point my friend was making was that the order that this SQL
query is written in, is not the order that it actually happens in. It happens
in a different order, and it's not immediately obvious what that is.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-67.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-67.png"></a>
</p>
<p>

So how do we make this easier?
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-68.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-68.png"></a>
</p>
<div>


<p>
I like to think about: what does the computer do first?
What actually happens first chronologically?
</p>

<p>
Computers actually do live in the same timeline as us. Things happen. Things
happen in an order. So what happens first?
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-69.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-69.png"></a>
</p>

</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-70.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-70.png"></a>
</p>
<p>

The way I think about an SQL query is: is you start with a table like
<code>cats</code>.

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-71.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-71.png"></a>
</p>
<p>

Then maybe you filter it, you remove some stuff. 
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-72.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-72.png"></a>
</p>
<p>

Then you make some groups.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-73.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-73.png"></a>
</p>
<p>

Then you filter the groups, remove some of them.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-74.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-74.png"></a>
</p>
<p>

Then you do some
aggregation. There's two things in each group.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-75.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-75.png"></a>
</p>
<p>

And you sort it.

And you
can also limit the results.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-76.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-76.png"></a>
</p>
<div>


<p>
So, that's how I think about SQL. The way a query runs is first
FROM, then WHERE, GROUP BY, HAVING, SELECT, ORDER BY, LIMIT.
</p>

<p>
At least conceptually. Real life databases have optimizations and it's more
complicated than that. But this is the mental model that I use most of the time
and it works for me. Everything is in the same order as you write it,
except SELECT is fifth. 
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-77.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-77.png"></a>
</p>
<p>

I've really gotten a lot out of this trick where you try to tell the
chronological story of what the computer is doing. I want to talk about a
couple other examples.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-78.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-78.png"></a>
</p>
<div>


<p>
One is CORS, in HTTP. 
</p>

<p>
This <a href="https://wizardzines.com/comics/cors/">comic</a> is way too small to read on the slide.
But the idea is if you're making a cross-origin request in your
browser, you can write down every communication that's happening between your
browser and the server, in chronological order.
</p>

<p>
And I think writing down everything in chronological order makes it a lot easier to understand and more concrete.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-79.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-79.png"></a>
</p>
<div>


<p>
"What happens in chronological order?" is a very
straightforward structure, which is what I like about it. "What happens first?"
feels like it should be easy to answer. But it's not!
</p>

<p>
I've found that it's actually very hard to know what our computers is
doing, and it's a really fun question to explore.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-80.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-80.png"></a>
</p>
<div>


<p>
As an example of how this is hard: I wrote a blog post recently called 
<a href="https://jvns.ca/blog/2023/08/03/behind--hello-world/">"Behind Hello World on Linux"</a>. It's about what happens when you run "hello world" on a
Linux computer. I wrote a bunch about it, and I was really happy with it.
</p>

<p>
But after I wrote the post, I thought -- haven't I written about this before? Maybe 10 years ago?
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-81.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-81.png"></a>
</p>
<div>

<p>
And sure enough, I'd tried to write <a href="https://jvns.ca/blog/2013/11/29/what-happens-when-you-run-a-unix-program/">
a similar post</a> 10 years before.
</p>

<p>
I think this is really cool. Because the 2013 version of this post was about 6
times shorter. This isn't because Linux is more complicated than it was 10
years ago -- I think everything in the 2023 post was probably also true in
2013. The 2013 post just has a lot less information in it.
</p>

<p>
The reason the 2023 post is longer is that I didn't know what was happening
chronologically on my computer in 2013 very well, and in 2023 I know a lot
more. Maybe in 2033 I'll know even more!
</p>

<p>
I think a lot of us -- like me in 2013 and honestly me now, often don't know
the facts of what's happening on our computers. It's very hard, which is what
makes it such a fun question to try and discuss.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-82.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-82.png"></a>
</p>
<div>



<p>
I think it's cool that all of us
have different knowledge about what is happening chronologically on our
computers and we can all chip in to this conversation.
</p>

<p>
For example when I posted this blog post about Hello World on Linux, some people
mentioned that they had a lot of thoughts about what happens exactly in your
terminal, or more details about the filesystem, or about what's happening
internally in the Python interpreter, or any number of things. You can go
really deep.
</p>

<p>
I think it's just a really fun collaborative question. 
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-83.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-83.png"></a>
</p>
<div>

<p>
I've seen "what happens chronologically?" work really well as an activity with
coworkers, where you're ask: "when a request comes into this API endpoint we
run, how does that work? What happens?"
</p>

<p>
What I've seen is that someone will understand some part of the system, like "X
happens, then Y happens, then it goes over to the database and I have no idea
how that works".  And then someone else can chime in and say "ah, yes, with the
database A B C happens, but then there's a queue and I don't know about that".
</p>

<p>
I think it's really fun to get together with people who have different
specializations and try to make these little timelines of what the
computers are doing. I've learned a lot from doing that with people.
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-84.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-84.png"></a>
</p>
<p>
That's all for SQL.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-85.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-85.png"></a>
</p>
<p>

So, now we've arrived at DNS which is
where we started the talk.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-86.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-86.png"></a>
</p>
<div>



<p>
Even though I struggled with DNS. Once I got figured it out, I felt like "dude,
this is easy!". Even though it just took me 10 years to learn how it
works.
</p>

<p>
But of course, DNS was pretty hard for me to learn. So -- why is that? Why did
it take me so long?
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-87.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-87.png"></a>
</p>
<div>


<p>
So, I have a little <a href="https://wizardzines.com/comics/cast-of-characters/">chart</a> here of how I think about DNS.
</p>

<p>
You have your browser on the left. And over on the right there's the authoritative
nameservers, the source of truth of where the DNS records for a domain live. 
</p>

<p>
In the middle, there's a function that you call and a cache.
So you have browser, function, cache, source of truth.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-88.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-88.png"></a>
</p>
<div>

<p>
One problem is that there are a lot of things in this diagram that are
totally hidden from you.
</p>

<p>
The library code that you're using where you make a DNS request -- there are a
lot of different libraries you could be using, and it's not straightforward to figure out which one is being used.
That was the source of some of my confusion.
</p>

<p>
There's a cache which has a bunch of cached data. That's invisible to you, you
can't inspect it easily and you have no control over it. that
</p>

<p>
And there's a conversation between the cache and the source of
truth, these two red arrows which also you can't see at all.
</p>

<p>
So this is kind of tough! How are you supposed to develop an intuition for a
system when it's mostly things that are completely hidden from you? Feels like
a lot to expect.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-89.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-89.png"></a>
</p>
<p>

So, what do we do about this?
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-90.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-90.png"></a>
</p>
<div>


<p>
So: let's talk about these red arrows
on the right.
</p>

<p>
We have our cache and then we have the source of truth. This conversation
is normally hidden from you because you often don't control either of these
servers. Usually they're too busy doing high-performance computing to report to
you what they're doing.
</p>

<p>
But I thought: anyone can write an authoritative nameserver!
In particular, I could write one that reports back every single message that it receives to its users.
So, with my friend <a href="https://marieflanagan.com/">Marie</a>, we wrote a little DNS server.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-91.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-91.png"></a>
</p>
<div>

<p>
(demo of <a href="https://messwithdns.net/">messwithdns.net</a>)
</p>

<p>
This is called Mess With DNS. The idea is I have a domain name and you
can do whatever you want with it. We're going to make a DNS record called
<code>strangeloop</code>, and we're going to make a CNAME record pointing at
<code>orange.jvns.ca</code>, which is just a picture of an orange. Because I
like oranges.
</p>

<p>
And then over here, every time a request comes in from a resolver, this will --
this will report back what happened. So, if we click on this link, we can see
-- a Canadian DNS resolver, which is apparently what my browser is configured
to use, is requesting an IPv4 record and an IPv6 record, A and AAAA.
</p><p>


(at this point in the demo everyone in the audience starts visiting the link
and it gets a bit chaotic, it's very funny)

</p></div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-93.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-93.png"></a>
</p>
<p>
So the trick here is to find ways to show people parts of what the computer is
doing that are normally hidden.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-94.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-94.png"></a>
</p>
<div>

<p>
Another great example of showing things that are hidden is this website called <a href="https://float.exposed/0x4d000006">float.exposed</a>
by <a href="https://ciechanow.ski/">Bartosz Ciechanowski</a> who makes a lot of incredible visualizations.
</p>

<p>
So if you look at <a href="https://float.exposed/0x4b800000">this 32-bit
floating point number</a> and click the "up" button on the significand, it'll
show you the next floating point number, which is 2 more. And then as you make
the number bigger and bigger (by increasing the exponent), you can see that the
floating point numbers get further and further apart.
</p>

<p>
Anyway, this is not a talk about floating point. I could do an entire talk
about this site and how we can use it to see how floating point works, but
that's not this talk.
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-95.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-95.png"></a>
</p>
<div>

<p>
Another thing that makes DNS confusing is that it's a giant distributed system
-- maybe you're confused because there are 5 million computers involved (really, more!).
Most of which you have no control over, and some
are doing not what they're supposed to do. 
</p>

<p>
So that's another trick for understanding why things are hard, check to see if
there are actually 5 million computers involved.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-96.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-96.png"></a>
</p>
<div>

<p>
So what else is hard about DNS?
</p>

<p>
We've talked about how most of the system is hidden from you, and about how
it's a big distributed system.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-97.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-97.png"></a>
</p>
<p>

One problem I've run into is that the tools are confusing.

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-98.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-98.png"></a>
</p>
<div>

<p>
One of the hidden things I talked about was: the resolver has cached data,
right? And you might be curious about whether a certain domain name is cached
or not by your resolver right now.
</p>

<p>
Just to understand what's happening:  am I getting this result because it was
cached? What's the deal?
</p>

<p>

I said this was hidden, but there are a couple of ways to query a resolver to
see what it has cached, and I want to show you one of them.

</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-99.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-99.png"></a>
</p>
<div><p>

The tool I usually use for making DNS queries is called <code>dig</code>, and
it has a flag called <code>+norecurse</code>. You can use it to query a
resolver and ask it to only return results it already has cached.

</p><p>
With <code>dig +norecurse jvns.ca</code>, I'm kind of asking -- how popular is my website? Is it popular enough that someone has visited it in the last 5 minutes?
Because my records are not cached for that long, only for 5 minutes.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-100.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-100.png"></a>
</p>
<div>


<p>
But when I look at this
response, I feel like "please! What is all this?"
</p>

<p>
And when I show newcomers this output, they often respond by saying "wow,
that's complicated, this DNS thing must be really complicated". But really this
is just not a great output format, I think someone just made some relatively
arbitrary choices about how to print this stuff out in the 90s and it's stayed
that way ever since.
</p>

<p>
So a bad output format can mislead newcomers into thinking that something is more complicated than it actually is.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-101.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-101.png"></a>
</p>
<p>

What can we do about confusing output like this?

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-102.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-102.png"></a>
</p>
<div>

<p>
One of my favorite tricks, I call eraser eyes.
</p>

<p>
Because when I look at that output, I'm not looking at all of it, I'm just
looking at a few things. My eyes are ignoring the rest of it.
</p>
</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-103.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-103.png"></a>
</p>
<div>

<p>
When I look at the output, this is what I see: it says <code>SERVFAIL</code>.
That's the DNS response code.
</p>


<p>
Which as I understand it is a very unintuitive way of it saying, "I do not have
that in my cache". So nobody has asked that resolver about my domain name in
the last 5 minutes, which isn't very surprising.
</p>

<p>
I've learned so much from people doing a little demo of a tool, and showing how
they use it and which parts of the output or UI they pay attention to, and which parts they ignore.
</p>

<p>
Becuase usually we ignore most of what's on our screens!
</p>

<p>
I really love to use <code>dig</code> even though it's a little hairy because
it has a lot of features (I don't know of another DNS debugging that supports this
<code>+norecurse</code> trick), it's everywhere, and it hasn't changed in a
long time. And I know if I learn its weird output format once I can know that
forever. Stability is really valuable to me.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-104.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-104.png"></a>
</p>
<p>

So we've talked about these four technologies. Let's talk a little more about
how we can make things easier for each other.

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-105.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-105.png"></a>
</p>
<p>



What can we do to move folks from "I really don't get it" to "okay, I can
mostly deal with this, at least 90% of the time, it's fine"? For bash or HTTP or DNS or anything else.

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-106.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-106.png"></a>
</p>
<div>


<p>
We've talked about some tricks I use to bring people over, like:
</p>

<ul>
<li> sharing useful tools </li>
<li> sharing references</li>
<li>telling a chronological story of what happens on your computer</li>
<li>turning a big list into a small list of the things you actually use</li>
<li>showing the hidden things</li>
<li>demoing a confusing tool and telling folks which parts I pay attention to</li>
</ul>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-107.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-107.png"></a>
</p>
<div>

<p>

When I practiced this talk, I got some feedback from people saying "julia! I don't
do those things! I don't have a blog, and I'm not going to start one!"

</p>

<p>
And it's true that most people are probably not going to start programming blogs.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-108.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-108.png"></a>
</p>
<p>
But I really don't think you need to have a public presence on the internet to
tell the people around you a little bit about how you use computers and how you
understand them.
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-109.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-109.png"></a>
</p>
<div>


<p>
My experience is that a lot of people (who do not have blogs!) have helped me
understand how computers work and have
shared little pieces of their experience with computers with me.
</p>

<p>
I've learned a lot from my friends and my coworkers and honestly a lot of
random strangers on the Internet too. I'm pretty sure some of you here today
have helped me over the years, maybe on Twitter or Mastodon.
</p>

<p>
So I want to talk about some archetypes of helpful people
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-110.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-110.png"></a>
</p>
<div>

<p>
One kind of person who has really helped me is the
grumpy old-timer. I'll say "this is so cool". And they'll reply yes,
however, let me tell you some stories of how this has gone wrong in my life.
</p>


<p>
And those stories have sometimes helped spare me some suffering.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-111.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-111.png"></a>
</p>
<div>

<p>
We have the loud newbie, who asks questions like "wait, how does that work?"
And then everyone else feels relieved -- "oh, thank god. It's not just me."
</p>

<p>
I think it's especially valuable when the person who takes the "loud newbie"
role is actually a pretty senior developer. Because when you're more secure in
your position, it's easier to put yourself out there and say "uh, I don't get
this" because nobody is going to judge you for that and think you're
incompetent.
</p>

<p>
And then other people who feel more like they might be judged for not knowing
something can ride along on your coattails.
</p>


</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-112.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-112.png"></a>
</p>
<div>

<p>
Then we have the bug chronicler. Who decides "ok, that bug. This can never happen again".
</p>

<p>
"I'm gonna make sure we understand what happened. Because I want this to end
now."
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-113.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-113.png"></a>
</p>
<p>

We have the tool builder, whose attitude is more like "I see people struggling
with something, and I don't feel like explaining it. But I can write code to
just make it easier permanently for everyone."

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-114.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-114.png"></a>
</p>
<p>

There's this "today I learned" person who's into sharing cool new tools they
learned about, a bug that they ran into, or a great new-to-them library feature.

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-115.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-115.png"></a>
</p>
<p>

There's the person who has read the entire Internet and has 700 tabs open. If you
want to know where to find something, there's a good chance they already have
it open in their browser.


</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-116.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-116.png"></a>
</p>
<p>

We have the person who is just willing to answer questions! "Yeah, I can tell
you how that works!"
</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-117.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-117.png"></a>
</p>
<p>

And at the end of all this, sometimes you have someone who likes to write some
things down so that other people can read it and can find it later.


</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-118.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-118.png"></a>
</p>
<p>

But all of us have different roles and we need to work together. I'm into
writing but a lof of the stuff I've written about, I only know about because
someone told me about it or explained it to me.

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-119.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-119.png"></a>
</p>
<p>

To end: the one thing I would like to convince you of is: if you're struggling
with something that feels basic, it's not just you! You're not alone. We're all struggling with a
lot of these things that feel like they should be "basic".


</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-120.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-120.png"></a>
</p>
<p>

And we're struggling with these things for a lot of
the same reasons as each other. 


</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-123.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-123.png"></a>
</p>
<div>

<p>
And much like when debugging a computer program, when you have a bug, you
want to understand why the bug is happening if you're gonna fix it.
</p>

<p>
If we're all struggling with the same things together for the same reasons, if
we can figure out what those reasons are, we can do a better job of fixing
them.
</p>

</div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-121.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-121.png"></a>
</p>
<div><p>

Some of the reasons we've talked about were:

</p><ul>
<li>
a giant pile of trivia and gotchas.
</li>
<li>
or maybe there's 20 million lines of code somewhere.
</li>
<li>
Maybe a big part of the system is being hidden from you.
</li>
<li>
Maybe the tool's output is extremely confusing and no UI designer has ever worked on improving it
</li>
</ul><p>

And there are a lot more reasons.

</p></div>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-124.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-124.png"></a>
</p>
<p>

I don't have all the answers for why things are hard. For example I don't really understand why Git is hard, that's something I've been thinking about recently.

</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-125.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-125.png"></a>
</p>
<p>

But that's something I'm excited to keep
working on and keep trying to figure out.


</p>
</div>

<div>
<p><a href="https://jvns.ca/images/strangeloop-2023-talk/slide-126.png"><img src="https://jvns.ca/images/strangeloop-2023-talk/slide-small-126.png"></a>
</p>
<div>

<p>
And that's all I have for you. Thank you.
</p>

<p>
I brought some zines to the conference, if you come to the signing later on you can get one.
</p>

</div>
</div>

<h3 id="some-thanks">some thanks</h3>

<p>This was the last ever Strange Loop and I’m really grateful to Alex Miller and the
whole organizing team for making such an incredible conference for so many years. Strange Loop
accepted one of my first talks (<a href="https://www.youtube.com/watch?v=0IQlpFWTFbM">you can be a kernel hacker</a>) 9 years ago when I had
almost no track record as a speaker so I owe a lot to them.</p>

<p>Thanks to Sumana for coming up with the idea for this talk, and to Marie,
Danie, Kamal, Alyssa, and Maya for listening to rough drafts of it and helping
make it better, and to Dolly, Jesse, and Marco for some of the conversations I
mentioned.</p>

<p>Also after the conference Nick Fagerland wrote a nice post with thoughts on <a href="https://roadrunnertwice.dreamwidth.org/596185.html">why git is hard</a> in response to my “I
don’t know why git is hard” comment and I really appreciated it. It had some
new-to-me ideas and I’d love to read more analyses like that.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Thread-per-core (250 pts)]]></title>
            <link>https://without.boats/blog/thread-per-core/</link>
            <guid>37790745</guid>
            <pubDate>Fri, 06 Oct 2023 13:47:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://without.boats/blog/thread-per-core/">https://without.boats/blog/thread-per-core/</a>, See on <a href="https://news.ycombinator.com/item?id=37790745">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><p>I want to address a controversy that has gripped the Rust community for the past year or so: the
choice by the prominent async “runtimes” to default to multi-threaded executors that perform
work-stealing to balance work dynamically among their many tasks. Some Rust users are
<a href="https://maciej.codes/2022-06-09-local-async.html">unhappy</a> with this decision, so unhappy that they use language I would characterize as
melodramatic:</p><blockquote><p>The Original Sin of Rust async programming is making it multi-threaded by default. If premature
optimization is the root of all evil, this is the mother of all premature optimizations, and it
curses all your code with the unholy <code>Send + 'static</code>, or worse yet <code>Send + Sync + 'static</code>, which
just <em>kills all the joy of actually writing Rust</em>.</p></blockquote><p>It’s always off-putting to me that claims written this way can be taken seriously as a technical
criticism, but our industry is rather unserious.</p><p>What these people advocate instead is an alternative architecture that they call “thread-per-core.”
They promise that this architecture will be simultaneously more performant and easier to implement.
In my view, the truth is that it may be one or the other, but not both.</p><p><em>(Side note: Some people prefer instead just running single threaded servers, claiming that they are
“IO bound” anyway. What they mean by IO bound is actually that their system doesn’t use enough work
to saturate a single core when written in Rust: if that’s the case, of course write a single
threaded system. We are assuming here that you want to write a system that uses more than one core
of CPU time.)</em></p><h2 id="thread-per-core">Thread-per-core</h2><p>One of the biggest problems with “thread-per-core” is the name of it. All of the multi-threaded
executors that users are railing against are also thread-per-core, in the sense that they create an
OS thread per core and then schedule a variable number of tasks (expected to be far greater than the
number of cores) over those threads. As Pekka Enberg <a href="https://twitter.com/penberg/status/1705484076054904922">tweeted</a> in response to a
comment I made about thread per core:</p><blockquote><p>Thread per core combines three big ideas: (1) concurrency should be handled in userspace instead
of using expensive kernel threads, (2) I/O should be asynchronous to avoid blocking per-core
threads, and (3) data is partitioned between CPU cores to eliminate synchronization cost and data
movement between CPU caches. It’s hard to build high throughput systems without (1) and (2), but
(3) is probably only needed on really large multicore machines.</p></blockquote><p>Enberg’s <a href="https://penberg.org/papers/tpc-ancs19.pdf">paper</a> on performance, which is called “The Impact of Thread-Per-Core
Architecture on Application Tail Latency” (and which I will return to in a moment), is the origin of
the use of the term “thread-per-core” in the Rust community. His understanding of the definition of
thread-per-core is probably relevant here. He enumerates three different features of a
thread-per-core architecture, of which he says only two are absolutely required for high
throughput. This is helpful, because the dispute is really only about the third point, not the first
two; if you are using async Rust, you are meeting both of those requirements.</p><p>The distinction being made is really between two optimizations you can make once you have a
thread-per-core architecture, and which are in tension: work-stealing tasks between your threads and
sharing as little state as possible between them.</p><h2 id="work-stealing">Work-stealing</h2><p>The point of work-stealing is to improve tail latency by ensuring that every thread always has work
to do.</p><p>A problem that emerges in real systems is that different tasks end up requiring different amounts
of work. For example, one HTTP request may require far more work to serve than another HTTP request.
As a result, even if you try to balance work up front among your different threads, they can each
end up performing different amounts of work because of unpredictable differences between the tasks.</p><p>Under maximum load, this means that some threads will be scheduled more work than they can perform,
while other threads will sit idle. The degree to which this is a problem depends on the degree to
which the amount of work performed by different tasks differs. Work-stealing is a mitigation to this
problem: threads with nothing to do “steal” work from the other threads that have too much work, so
that they do not sit idle. tokio, async-std, and smol all implement work-stealing with the goal of
reducing tail latency and improving CPU utilization.</p><p>The problem with work-stealing is that it means a task can run on one thread, pause, and then be
started again on another thread: that’s what it means for the work to be stolen. This means that any
state that is used across a yield point in that task needs to be thread-safe. This appears in Rust’s
APIs as futures needing to be <code>Send</code>, which can be difficult for people with a poor view of their
system’s state to figure out the best way to ensure. This is why work-stealing is said to be
“harder.”</p><p>At the same time, if state is moved from one thread to another, this introduces synchronization
costs and cache misses, violating the principles of a “share-nothing” architecture, in which each
CPU has exclusive access to the state it operates on. This is why work-stealing is said to be
“slower.”</p><p>The point of share-nothing is to improve tail latency by keeping data in the faster caches that
belong to a single CPU core, rather than the slower caches shared by multiple cores.</p><p>I want to return to Enberg’s <a href="https://penberg.org/papers/tpc-ancs19.pdf">paper</a>, which demonstrates the performance improvements
of a share-nothing architecture over a shared-state architecture by benchmarking a new key-value
store (which is share-nothing) against memcached (which is shared-state). Enberg shows substantial
improvements in tail latency between the two architectures. I like this paper a lot, but I think the
way it has been deployed in the Rust community as a soundbite (“71% performance improvement!”) is
shallow and unhelpful.</p><p>To achieve a share-nothing architecture, Enberg’s key/value store partitions the keyspace over the
different threads using a hash function, and partitions incoming TCP connections over the threads
using <code>SO_REUSEPORT</code>. Then, it routes requests from the thread managing the connection to the
thread managing the relevant section of the keyspace using message passing channels. In contrast,
in memcached all of the threads share ownership of the keyspace, which is partitioned, and each
partition is protected by a mutex.</p><p>Enberg’s paper shows that using channels over using mutexes can achieve lower tail latency. This is
presumably because there are fewer cache misses, as each partition, which is accessed over and over
again, stays in only one core’s cache. However, I’m not at all convinced that Enberg’s architecture
is dramatically easier to implement than memcached’s. Enberg’s goal is to make use of advanced
kernel features and a carefully planned architecture to avoid data movement, it’s hard for me to
believe this would be <em>easier</em> than wrapping data inside a mutex.</p><p>A key-value store is pretty much the ideal case for a share-nothing architecture, because it is
fairly trivial to partition the state of the application among diferent threads. But if your
application is more complicated, and requires mutating state in multiple partitions in a
transactional or atomic manner, this requires a lot more attention to implement correctly. There’s a
strong analogy between the advocates of a share-nothing architecture and the hype for eventually
consistent databases over databases that enforced serializability ten years ago. Yes, this can be
more performant, but at the expense of requiring careful consideration to avoid bugs that result
from data inconsistency.</p><p>It’s also important to note that neither Enberg’s implementation nor memcached use work-stealing.
This makes it difficult to relate the core performance claims of Enberg’s paper to Rust’s
work-stealing architectures. One wonders what the results would be to just add work-stealing to
Enberg’s architecture and memcached’s. In Enberg’s it would increase data movement somewhat, but
possibly in a manner which still maximizes CPU utilization. I can’t imagine it would do anything but
help memcached.</p><p>Enberg has carefully designed the implementation in the paper to try to evenly distribute work in
advance, using a balanced partition of the keyspace and <code>SO_REUSEPORT</code>. Despite this, there are
several sources of dynamic imbalance that would appear in practice:</p><ul><li>Hot keys will receive more reads and writes, which causes the thread managing their keyspace to
receive more work.</li><li>Some connections will perform more requests than others, which causes the thread managing those
connections to receive more work.</li></ul><p>My understanding of the paper is that the benchmarking framework did not replicate these
conditions, which would appear in the real world: each connection performs a consistent amount of
work, operating on random keys, so it avoids these sources of imbalance. I wonder what benchmarks
which add work stealing would show if these kinds of dynamic imbalance were tested.</p><p>One can imagine others ways to architect a share-nothing system that may mitigate these forms of
imbalance (such as caching hot keys on additional partitions). And some form of work-stealing may be
such an optimization even if some tasks stay pinned to certain cores to avoid moving their state.</p><p>No one would dispute that carefully architecting your system to avoid moving data between CPU caches
will achieve better performance than not doing that, but I have a hard time believing that someone
who’s biggest complaint is adding <code>Send</code> bounds to some generics is engaged in that kind of
engineering. If you’re going to be using shared state anyway, it’s hard to imagine that
work-stealing doesn’t improve your CPU utilization under load.</p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Thirty Years Ago: MS-DOS 6.00 (172 pts)]]></title>
            <link>https://www.pcjs.org/blog/2023/10/04/</link>
            <guid>37790174</guid>
            <pubDate>Fri, 06 Oct 2023 12:57:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pcjs.org/blog/2023/10/04/">https://www.pcjs.org/blog/2023/10/04/</a>, See on <a href="https://news.ycombinator.com/item?id=37790174">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
        <h2><a href="https://www.pcjs.org/blog/">PCjs Blog</a></h2>

<h3>Thirty Years Ago: MS-DOS 6.00</h3>

<p>Over 30 years ago, in March 1993, Microsoft released <a href="https://www.pcjs.org/software/pcx86/sys/dos/microsoft/6.00/compressed">MS-DOS 6.00</a>,
the next major release of MS-DOS after 5.00 shipped in June 1991.</p>

<p>In addition to several new full-screen utilities, like <code>DEFRAG</code> to defragment your hard disk (licensed from Symantec),
<code>MSBACKUP</code> to efficiently backup your hard disk (also licensed from Symantec), and <code>MSAV</code> to check for viruses (licensed
from Central Point Software), there were a number of new command-line programs, such as <code>CHOICE</code>, <code>DELTREE</code>, <code>MOVE</code>,
<code>MSCDEX</code>, and <code>SMARTDRV</code>.</p>

<p>But the biggest addition to MS-DOS 6.00 was a new feature called <strong>DoubleSpace</strong> (dubbed “MagicDrive” internally) that
automatically compressed everything on your hard disk, providing up to “double” the amount of effective disk space – or more,
or less, depending on how compressible your files were overall.</p>

<p>DoubleSpace was a significant feature that required changes across the entire system.  Most of the action, however,
took place inside a new device driver, <code>DBLSPACE.BIN</code>, that stored all your data in a Compressed Volume File (CVF) generally
named <code>DBLSPACE.000</code>.  In fact, if you booted an older version of MS-DOS (like 5.00), you wouldn’t see much more than that:</p>

<div><pre><code>A&gt;DIR C: /A

 Volume in drive C is HOST_FOR_C
 Volume Serial Number is 5739-B1B5
 Directory of C:\

IO       SYS     40470 03-10-93   6:00a
MSDOS    SYS     38138 03-10-93   6:00a
DBLSPACE BIN     51214 03-10-93   6:00a
DBLSPACE INI        91 10-03-23  12:26p
DBLSPACE 000 131474432 10-03-23  12:26p
        5 file(s)  131604345 bytes
                     2605056 bytes free
</code></pre></div>

<p>When MS-DOS 6.00 starts up, it reads <code>DBLSPACE.INI</code>, which usually looks something like this:</p>

<div><pre><code>MaxRemovableDrives=2
FirstDrive=D
LastDrive=H
MaxFileFragments=115
ActivateDrive=H,C0
</code></pre></div>

<p>and tells the operating system to mount the <em>real</em> drive C: as drive H: instead, and to mount the CVF as drive C:</p>

<div><pre><code>C:\&gt;DIR /C

 Volume in drive C is MS-DOS_6
 Volume Serial Number is 101B-323E
 Directory of C:\

DOS          &lt;DIR&gt;     09-25-23  10:13p
COMMAND  COM     52925 03-10-93   6:00a   1.4 to 1.0
WINA20   386      9349 03-10-93   6:00a   5.3 to 1.0
AUTOEXEC BAT        75 09-26-23   8:55a  16.0 to 1.0
CONFIG   SYS       109 09-26-23   8:55a  16.0 to 1.0
                  2.0 to 1.0 average compression ratio
        5 file(s)      62458 bytes
                   253927424 bytes free
</code></pre></div>

<p>So our original hard disk, a 128Mb drive, now appears to be almost twice as large – thanks to DoubleSpace.</p>

<p>Aside from the new <code>DBLSPACE.BIN</code> driver, the other main piece of DoubleSpace functionality resided in <code>DBLSPACE.EXE</code>, which
operated as both a setup and a maintenance program.  It provided a friendly UI, making it easy to create additional CVFs,
as well as resize, defragment, reformat, unmount, remount, and more.</p>

<p><img src="https://www.pcjs.org/blog/images/msdos600-dblspace.png" alt="MS-DOS 6.00 DoubleSpace"></p>

<p>Feel free to tinker with MS-DOS 6.00 on the website:</p>

<ul>
  <li><a href="https://www.pcjs.org/software/pcx86/sys/dos/microsoft/6.00/">Microsoft MS-DOS 6.00 (Installed)</a></li>
  <li><a href="https://www.pcjs.org/software/pcx86/sys/dos/microsoft/6.00/compressed/">Microsoft MS-DOS 6.00 (Installed and Compressed)</a></li>
</ul>

<h2 id="legal-woes">Legal Woes</h2>

<p>Microsoft bootstrapped its compression efforts by licensing code from Vertisoft, makers of DoubleDisk, a disk compression
product first released in 1989.  Starting with Verisoft’s code, Microsoft created <code>DBLSPACE.BIN</code>, along with operating system
changes that allowed it to be loaded <em>before</em> CONFIG.SYS was processed – so that CONFIG.SYS and any system files loaded
from that point forward could be <em>inside</em> the compressed volume instead of <em>outside</em> it.</p>

<p>Vertisoft was not directly involved with any of that work, but they did help produce other pieces of functionality, such
as code to convert Stacker and SuperStor compressed disks to DoubleSpace – although apparently Stacker conversion was pulled
at the last minute, in February 1993, just as MS-DOS 6.00 was being finalized.</p>

<p>Or rather, February 1993 would have been “last minute”, until the lawsuit filed by Stac in January 1993 forced Microsoft
to re-evaluate.  Stac claimed that the DoubleSpace infringed two of Stac’s patents: <a href="https://patents.google.com/patent/US5016009A/en">5,016,009</a> and <a href="https://patents.google.com/patent/US4701745A/en?oq=US4701745">4,701,745</a>.</p>

<p>For me, life quickly changed on February 13, 1993, when I received this email:</p>

<div><pre><code>From: Paul Maritz
Sent: Saturday, February 13, 1993 12:06 PM
To: Jeff Parsons; Mark Zbikowski
Cc: Ben Slivka; Brad Chase; Brad Silverberg; Jim Allchin; John Mason;
Nathan Myhrvold; Rick Rashid
Subject: special duty

You are both amongst the best x86 assembly language coders that we have at MS.
We are thus asking you to help out with a very serious problem that we face - namely
the STAC / DOS6 lawsuit.

Our lawyers have recommended that we have a backup compression mechanism for DOS6
ready to go as soon as possible. The initial work on this has been done under Rick
Rashid in Nathanm's area. They have a C language implementation of a technique that
we believe is safe (covered under patents that we have rights to). The challenge
is to get this technique into the tightest possible x86 assembly code, as soon as
possible. This is where we are asking you to help. Jimall and Bradsi are aware that
you will be "stolen" for some weeks.

Could you both meet with Rick Rashid as early as possible on Monday to get this
effort under way as soon as is possible. Thanks.
</code></pre></div>

<p>The next several weeks were probably some of the most stressful weeks I’d experienced at Microsoft.  Looking back, it’s amazing
to me that with all the critical-path code that was being rewritten at that late date, MS-DOS 6.00 still shipped the following
month, in March 1993.</p>

<p>I don’t recall all the details of the alleged patent infringement, and I’m not sure I ever knew all the details, because frankly,
it wasn’t necessary for me to know the details.  A number of other people had already been working on the problem and had come up
with several solutions, and it simply fell to me and MarkZ to implement them in x86 assembly – preferably very fast, bug-free
assembly, of course.</p>

<p>As far as I can tell now, Stac patent 5,016,009 was the crux of the problem.  It combined LZ77 compression with hashing, and
while LZ77 compression was fine, and hashing was fine, apparently the <em>combination</em> of the two became a patentable innovation.</p>

<p>So we were initially tasked with writing a compressor based on <strong>Miller-Wegman</strong>, an algorithm that was either not patented or
that Microsoft owned or licensed.  When that turned out to be too slow, we instead built a compressor (internally known as XCFR or
the “Rashid Search Algorithm”) that avoided hashing by using a 256x8 look-up table along with a 256-entry LRU table, and also
incorporated a new Microsoft Realtime Compression Format (MRCF) for outputting the raw bytes and offset-length pairs.  That,
of course, meant that the decompressor had to be rewritten as well.</p>

<p>With hindsight, it’s probably safe to say that Microsoft should <em>not</em> have shipped MS-DOS 6.00 quite so quickly after that
rewrite, because unfortunately, our code (well, in the case below, <em>my</em> code) was not, um, bug-free:</p>

<div><pre><code>From: Chuck Strouss
To: SYS Astro Team Development Group; Peter Stewart; Jeff Parsons
Subject: Bug in DBLSPACE decompress
Date: Monday, June 14, 1993 3:40PM

In RDCOMP.ASM, near the first JC instruction, there is a bug when a block ends
at 10000h and the last several bytes are in a repeat string.  It was reported by
Temporal Acuity Products.
</code></pre></div>

<p>to which I replied:</p>

<div><pre><code>From: Jeff Parsons
Sent: Monday, June 14, 1993 4:49 PM
To: Chuck Strouss; Ben Slivka; Jim Mathews; Peter Stewart
Subject: RE: Bug in DBLSPACE decompress

well... shit!
</code></pre></div>

<h2 id="introducing-multiconfig">Introducing MultiConfig</h2>

<p>On a happier, or at least less contentious note, MS-DOS 6.00 also introduced a feature known as <strong>MultiConfig</strong>, which I
have some fondness for, because it was something I personally championed and implemented.  And – good news – I don’t think
it had any serious bugs.</p>

<p>I don’t recall precisely where the idea came from.  I think it started as something that I and Naveen Jain, a Program Manager
on the team, discussed in early 1992.  He created a preliminary spec in February 1992, and then I implemented the feature
in March 1992 and updated the spec to match what I had implemented.</p>

<p>The code was originally added to <strong>Jaguar</strong>, which was planned to be the next major update to MS-DOS after 5.00.
But at some point, <strong>Astro</strong> – originally intended as a smaller interim MS-DOS update – grew to the point where it was
clearly going to be the next major update, thanks in large part to the addition of DoubleSpace disk compression.</p>

<p>When it was clear that <strong>Astro</strong> would become MS-DOS 6.00, I think management went looking for other low-hanging fruit,
such as any new <strong>Jaguar</strong> features that could be incorporated into <strong>Astro</strong> relatively easily with minimal risk.
MultiConfig fit the bill.</p>

<p>However, it wasn’t a slam dunk.  I had to push for it, because there were a few risk-averse people in management that felt
the risk/reward ratio was too high.  They claimed that most users would not use this feature (which was true), but that point
also worked in my favor: most of the new code would not be executed until and unless someone actually added one or more of the
new commands to their CONFIG.SYS.  So any risks largely affected only “power users”.</p>

<h2 id="what-is-multiconfig">What is MultiConfig?</h2>

<p>MultiConfig was a collection of features added to the processing of CONFIG.SYS, to make it easier to start your PC
in a particular way without having to boot from a special floppy or edit/copy a new CONFIG.SYS each time.  It added some new
commands to CONFIG.SYS:</p>

<ul>
  <li>INCLUDE</li>
  <li>MENUCOLOR</li>
  <li>MENUDEFAULT</li>
  <li>MENUITEM</li>
  <li>NUMLOCK</li>
  <li>SET</li>
  <li>SUBMENU</li>
</ul>

<p>and it included some new ways to interact with CONFIG.SYS.  The message “Starting MS-DOS…” was added as an indirect means
of alerting you that you now had two seconds to press one of several new start-up keys:</p>

<ul>
  <li>F5: Bypass CONFIG.SYS and AUTOEXEC.BAT</li>
  <li>F8: Interactively step through CONFIG.SYS</li>
</ul>

<p>You could also tap a Shift key – that was equivalent to pressing F5.  Apparently there was an Astro “press tour” in August
1992, and someone in that tour suggested adding the Shift key, so we did.  They claimed that holding the Shift key while
starting Windows also bypassed certain files and/or functions, but I don’t recall to what extent that was true.</p>

<p>Additionally, if you didn’t want anyone using your machine to bypass or alter CONFIG.SYS, you could add
these lines to the file:</p>

<ul>
  <li>SWITCHES=/N: disable all start-up keys</li>
  <li>SWITCHES=/F: eliminate the two-second pause</li>
</ul>

<p>/N also implied /F, since if start-up keys were disabled, there was no need to wait two seconds.</p>

<p>Note that SWITCHES was not a new command; other older “switches” included:</p>

<ul>
  <li>/K: Forces an enhanced keyboard to behave like a conventional keyboard (DOS 4.0+)</li>
  <li>/T: Indicates the BIOS time rollover byte is a flag instead of a counter (DOS 5.0+)</li>
  <li>/W: Specifies that the WINA20.386 file has been moved to a directory other than the root directory (DOS 5.0+)</li>
</ul>

<p>Finally, while we’re on the subject of the keyboard-related features, I should add that NUMLOCK wasn’t really a MultiConfig
feature; it was just something I thought would be handy.  Recall that early PCs had no BIOS setup screens, and MS-DOS was
still an operating system designed to run on any PC, including the original IBM PC.  So this CONFIG.SYS command:</p>

<ul>
  <li>NUMLOCK=[ON|OFF]</li>
</ul>

<p>could be used to set your keyboard’s initial Num-Lock state.  A case could be made for this being a legitimate
MultiConfig feature though, since you could select menu items with arrow keys <em>or</em> by pressing the number of a menu item.
So if you wanted to use your numeric keypad, then you would want to ensure that Num-Lock matched your preferred selection
method.</p>



<p>The real power of MultiConfig was the ability to create user-friendly boot menus and let you organize sets of CONFIG.SYS
commands into either named or <code>[common]</code> blocks.  Blocks began with a bracketed block name (eg, <code>[menu]</code>, <code>[common]</code>, <code>[doslow]</code>)
and ended at the next bracketed block name (or end of file).</p>

<p>Here’s a simple example:</p>

<div><pre><code>[menu]
menuitem=doslow,Load DOS in LOW memory
menuitem=doshigh,Load DOS in HIGH memory
menudefault=doslow,15
menucolor=15,1

[common]
device=c:\dos\himem.sys

[doslow]
dos=low

[doshigh]
dos=high

[common]
device=c:\dos\setver.exe
files=30
</code></pre></div>

<p>And the screen that would appear when booting:</p>

<p><img src="https://www.pcjs.org/blog/images/msdos600-multiconfig.png" alt="MS-DOS 6.00 MultiConfig"></p>

<p>Each <code>menuitem</code> in the <code>[menu]</code> block describes a menu item; the first argument is a block name (eg, <code>doslow</code>, <code>doshigh</code>),
and the second argument is a description.  Other <code>[menu]</code> block keywords included <code>menudefault</code>, which specifies the
default menu item (and optional timeout value in seconds), and <code>menucolor</code>, which selects foreground and background colors
for the menu.</p>

<p>In the above example, no matter which menu item you selected, HIMEM.SYS would always be loaded first, because it was in a
<code>[common]</code> block that appeared before the other blocks.  Then all commands in the selected block (<code>[doslow]</code> or
<code>[doshigh]</code>) would be processed next, then all the commands in the next <code>[common]</code> block – and so on.</p>

<p>Another feature was “forced prompting”.  If you included a <code>?</code> after the <code>DEVICE</code> keyword, you would receive an unconditional
prompt for that particular driver.  For example:</p>

<div><pre><code>device?=c:\dos\setver.exe
</code></pre></div>

<p>would <em>always</em> generate the following prompt:</p>

<div><pre><code>DEVICE=C:\DOS\SETVER.EXE [Y,N]?
</code></pre></div>

<p>And that feature wasn’t limited to device drivers.  The following line:</p>



<p>would also generate a prompt:</p>





<p>Below is a more complex example, extracted from an email I wrote back on July 1, 1992 (at 2:34am apparently).</p>

<p>This example illustrates how you could use <code>submenu</code> (as opposed to <code>menuitem</code>) to define menu items that
referred to other menu blocks, in order to create multi-level menus.  Originally, the keyword for that feature was
simply <code>menu</code>, but the <strong>Astro</strong> team (specifically, Betsy Tinney, who helped refine the MultiConfig UI for <strong>Astro</strong>)
suggested a keyword that was clearer.</p>

<p>It also shows how you could <code>include</code> named blocks from other blocks.  For example, a number of the blocks, like <code>[dosumb]</code>,
include another block, <code>[dos]</code>, that contains commands common to the other blocks.  Every block <em>could</em> duplicate those
commands itself, but factoring out common sets of commands made for a more maintainable CONFIG.SYS.  Blocks named <code>[common]</code>
were <em>always</em> processed in the order they appeared, whereas blocks with any other name would be processed whenever
(and <em>only</em> whenever) they were explicitly included.</p>

<p>Finally, this example also uses the <code>SET</code> command, which defines environment variables to be passed to <code>COMMAND.COM</code>.
In addition, a special <code>CONFIG</code> environment variable is automatically set to the name of the block from the final selected
<code>menuitem</code> (eg, <code>dosumb</code>).  This was useful for batch files like AUTOEXEC.BAT, if they needed to customize their actions
according to the selected CONFIG.SYS configuration.</p>

<div><pre><code>[menu]
numlock=off
menucolor=15,1
menudefault=lanmenu,15
submenu=dosmenu,DOS configurations
submenu=lanmenu,LanMan configurations

[dosmenu]
menudefault=dosumb,15
menuitem=dosumb,     DOS 7.00 only
menuitem=dosems,     DOS 7.00 w/EMS
menuitem=dosansi,    DOS 7.00 w/ANSI
menuitem=dos386max,  DOS 7.00 w/386Max
menuitem=dosdbg,     DOS 7.00 w/Soft-ICE
menuitem=cougar,     DOS 7.00 w/Cougar

[lanmenu]
menudefault=winball,15
menuitem=lanman20,   DOS 7.00 w/Lanman 2.0
menuitem=lanman21,   DOS 7.00 w/Lanman 2.1 w/XNS
menuitem=lanman21nb, DOS 7.00 w/Lanman 2.1 w/XNS+NetBeui
;menuitem=lanman21xm,DOS 7.00 w/Lanman 2.1 w/XNS Mono
menuitem=lanman21dbg,DOS 7.00 w/Lanman 2.1 w/Soft-ICE
menuitem=winball,    DOS 7.00 w/Winball

[common]
set tmp=c:\tmp
set linktmp=c:\tmp
set temp=c:\win31\temp
set dircmd=/l/o
set home=d:\tools\bound
set init=d:\tools\bound
set alias=jeffpar
set logname=jeffpar
set mailname=jeffpar
set basspec=d:\tools\dos
set helpfiles=d:\tools\help;c:\src\cougar\dev\tools\help
set country=usa-ms
set proj=c:\src\cougar\dos\dos86
set lib=d:\tools\windev\lib
set include=d:\tools\windev\include;d:\src\myinc
set path=d:\tools\dos;d:\tools\bound;d:\tools\windev;c:\lanman\netprog;c:\win31;c:\dos
set prompt=$p$g

[dos]
break=on
dos=high,umb
files=60
buffers=10
stacks=9,256
lastdrivehigh=z
shell=c:\dos\command.com /p c:\dos /e:1024 /z

[dosumb]
include dos
device=c:\win31\himem.sys
device=c:\win31\emm386.exe noems i=b000-b7ff x=d800-dfff

[dosems]
include dos
device=c:\win31\himem.sys
device=c:\win31\emm386.exe 1024 ram i=b000-b7ff x=d800-dfff frame=e000

[dosansi]
include dosumb
devicehigh=c:\dos\ansi.sys

[dos386max]
include dos
device=d:\tools\386max\386max.sys

[dosdbg]
device=c:\s-ice\s-ice.exe /tra 1000
include dos

[lanman20]
include dosumb
include lanman20_drivers
include lanman_logon

[lanman20_drivers]
devicehigh=c:\lanman\drivers\protman\protman.dos /i:c:\lanman
devicehigh=c:\lanman\drivers\ethernet\ub\ubnei.dos
devicehigh=c:\lanman\drivers\protocol\netbeui\netbeui.dos
devicehigh=c:\lanman\drivers\protocol\xns\ubxpw.dos
devicehigh=c:\lanman\drivers\protocol\xns\ubloop.dos
installhigh c:\lanman\drivers\protman\netbind.exe

[lanman21]
include dosumb
include lanman21_drivers
include lanman_logon

[lanman21nb]
include dosumb
include lanman21_drivers
install c:\lanman\netprog\load.com netbeui
include lanman_logon

[lanman21xm]
include dosumb
install c:\lanman\xnsmono\loadniu.exe -r -d -m:d8 -i:5 -p:4 c:\lanman\xnsmono\exniu2.xfm c:\lanman\xnsmono\1a.lc
install c:\lanman\xnsmono\xnsbios.exe -m:d8 -i:5 -p:4
include lanman_logon

[lanman21dbg]
device=c:\s-ice\s-ice.exe /tra 1000
include dos
include lanman21_drivers
include lanman_logon

[lanman21_drivers]
devicehigh=c:\lanman\drivers\protman\protman.dos /i:c:\lanman
devicehigh=c:\lanman\drivers\ethernet\ub\ubnei.dos
device=c:\lanman\drivers\protocol\ubxns\ubxps.dos
install c:\lanman\netprog\netbind.com

[lanman_logon]
install c:\lanman\netprog\net.exe start workstation
install c:\lanman\netprog\net.exe logon jeffpar2 /y
;install c:\lanman\netprog\net.exe use k: \\jeffpar\astro dos6
;install c:\lanman\netprog\net.exe use j: \\jeffpar\cougar dos7

[winball]
include dosumb
include lanman21_drivers
devicehigh=c:\win31\redirdrv.sys
devicehigh=c:\win31\system\vnbhlp.dos
shell=c:\dos\command.com /p c:\dos /e:1024 /z /k windb
set path=d:\tools\dos;d:\tools\bound;d:\tools\windev;c:\win31;c:\dos

[cougar]
include dosumb
include lanman21_drivers
devicehigh=c:\win31\redirdrv.sys
devicehigh=c:\win31\system\vnbhlp.dos
shell=c:\dos\command.com /p c:\dos /e:1024 /z /k cougar7
set path=d:\tools\dos;d:\tools\bound;d:\tools\windev;c:\win31;c:\dos;d:\cougar

[common]
installhigh d:\tools\dos\keyfix.com
installhigh c:\win31\mouse.com
installhigh c:\dos\share.exe
installhigh c:\win31\smartdrv.exe 1024
installhigh c:\dos\doskey.com /a /e /x /p /k:128 /f:d:\tools\dos\aliases
install c:\dos\mode.com con:rate=30 delay=1
install d:\tools\dos\50.com
</code></pre></div>


<p>[<a href="https://github.com/jeffpar/pcjs/tree/gh-pages/blog/_posts/2023/2023-10-04-thirty-years-ago-ms-dos-6-00.md">GitHub Source</a>]</p>

<p><a href="https://github.com/jeffpar">Jeff Parsons</a><br>
	<small>Oct 4, 2023</small>
</p>


      </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Long gone, DEC is still powering the world of computing (127 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2023/10/long-gone-dec-is-still-powering-the-world-of-computing/</link>
            <guid>37789514</guid>
            <pubDate>Fri, 06 Oct 2023 11:56:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2023/10/long-gone-dec-is-still-powering-the-world-of-computing/">https://arstechnica.com/gadgets/2023/10/long-gone-dec-is-still-powering-the-world-of-computing/</a>, See on <a href="https://news.ycombinator.com/item?id=37789514">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            <h4>
      DEC everywhere    —
</h4>
            
            <h2 itemprop="description">One of the early pioneers in computing, the company disappeared in the late 1990s.</h2>
                    </header>
        <section>
            <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/10/DEC-VAX-8350-front-0a-800x1090.jpg" alt="A DEC VAX 8350 with cover removed.">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/10/DEC-VAX-8350-front-0a-scaled.jpg" data-height="2560" data-width="1880">Enlarge</a> <span>/</span> A DEC VAX 8350 with cover removed.</p></figcaption>  </figure>

  




<!-- cache hit 221:single/related:badea60dd314665c29b27bca554c9984 --><!-- empty -->
<p>Even though very few of the early players in technology still exist, we use their creations to this day. Bell Labs created the transistor, and Fairchild Semiconductor created the integrated circuit, but neither company is still around. So is the case with Digital Equipment Corporation (DEC). It no longer exists, but unless you're using a handheld device to read this article, you're using a descendant of DEC technology.</p>
<p>DEC was founded in 1957 by Ken Olsen, Harlan Anderson, and H. Edward Roberts to build small digital modules, but the team soon discovered that they could use those modules to build minicomputers—computers that were smaller and less powerful (but cheaper) than mainframes, which were the business standard at the time.</p>
<p>In 1977, DEC introduced the VAX, a new line of minicomputers that featured a 32-bit instruction set architecture and virtual memory. Its operating system, VMS, was a multi-user, multitasking OS that provided features we now take for granted, including virtual memory, file sharing, and networking. It amassed a wide variety of third-party software packages that made it the most popular system in its class.</p>
<p>In the late 1980s and early '90s, Andy Green ran a bulletin board system (BBS) and later an Internet service provider called Intelecom Data Systems (IDS) on a VAX 11/730 (later a VAXstation 4000) server in the basement of his parents’ house in Rhode Island. IDS had seven lines—unheard of at the time—and users could talk in a real-time chat room. All of this was written by Green in VAX BASIC. Today, Green is the owner and CEO of Acme Atronomatic, developer of the MyRadar mobile app.</p>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/10/DEC_VAXstation_4000_96_OpenVMS_6.1.jpeg" data-height="1920" data-width="2560" alt="A DEC VAXstation 4000 96 running OpenVMS 6.1 with the DECWindows environment."><img alt="A DEC VAXstation 4000 96 running OpenVMS 6.1 with the DECWindows environment." src="https://cdn.arstechnica.net/wp-content/uploads/2023/10/DEC_VAXstation_4000_96_OpenVMS_6.1-980x735.jpeg" width="980" height="735"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/10/DEC_VAXstation_4000_96_OpenVMS_6.1.jpeg" data-height="1920" data-width="2560">Enlarge</a> <span>/</span> A DEC VAXstation 4000 96 running OpenVMS 6.1 with the DECWindows environment.</p></figcaption></figure>
<p>Green was exposed to the VAX through work and had picked up an old VAX 11/730 and started tinkering. He had previously run a BBS on a TRS-80, but the VAX, with its multitenancy, allowed for multiple concurrent users.</p>                                            
                                                        
<p>“Prior to [IDS], the PC or TRS-80 were only engineered originally to be single-user, and they weren't set up to be multi-user,” Green told Ars. “The fact that VAX and VMS in general were designed for [multiple users] from the scratch is what facilitated the multi-user aspect.”</p>
<p>The VAX served DEC well throughout the '80s and into the '90s, but as the latter decade went on, DEC began to face stiff competition from UNIX vendors, particularly Sun Microsystems. DEC struggled to change with the times, and the company ultimately failed. In 1998, DEC was acquired by Compaq, and in 2001, Compaq was acquired by Hewlett-Packard. The DEC line, including the VAX/VMS system, was discontinued and faded from the market.</p>
<p>And yet it lives on today. Here’s how.</p>
<h2>VMS=WNT</h2>
<p>VMS was popular because DEC supported it so thoroughly. It had a user-friendly interface and powerful command-line tools, and it was one of the first operating systems to support networking protocols, including TCP/IP, DECnet, and SNA. It had a powerful file system that supported hierarchical directories and file permissions, and it was highly customizable.</p>
<p>In 1988, a senior VMS engineer named David Cutler joined Microsoft to lead the development of the Windows NT operating system. Windows NT was a major departure from previous Microsoft operating systems, as it was a 32-bit, multi-user, multitasking OS. Windows client, still finding its way to usability, was a 16-bit layer that ran over MS-DOS. It wasn’t really an operating system; it was more like a program launcher.</p>
<p>Windows NT launched in 1993 with version 3.1, matching the desktop version of Windows, which had also just been released. But while Windows 3.1 finally got it right, NT 3.1 was a bit too heavy for the PCs of the day, and it was recast as a server operating system.</p>

                                                </div>

            
                            <nav>Page: <span>1 <a href="https://arstechnica.com/gadgets/2023/10/long-gone-dec-is-still-powering-the-world-of-computing/2/">2</a> <a href="https://arstechnica.com/gadgets/2023/10/long-gone-dec-is-still-powering-the-world-of-computing/3/">3</a> <a href="https://arstechnica.com/gadgets/2023/10/long-gone-dec-is-still-powering-the-world-of-computing/4/">4</a> <a href="https://arstechnica.com/gadgets/2023/10/long-gone-dec-is-still-powering-the-world-of-computing/2/"><span>Next <span>→</span></span></a></span></nav>
            
        </section>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Use an old tablet as an extra monitor (237 pts)]]></title>
            <link>https://github.com/alex028502/extra-screen</link>
            <guid>37789371</guid>
            <pubDate>Fri, 06 Oct 2023 11:36:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/alex028502/extra-screen">https://github.com/alex028502/extra-screen</a>, See on <a href="https://news.ycombinator.com/item?id=37789371">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" id="user-content-use-an-old-tablet-as-an-extra-monitor" dir="auto"><a href="#use-an-old-tablet-as-an-extra-monitor">Use an old tablet as an extra monitor</a></h2>
<p dir="auto">(as long as you want to use it as a terminal)</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/alex028502/extra-screen/blob/master/pics/picture.jpeg"><img src="https://github.com/alex028502/extra-screen/raw/master/pics/picture.jpeg" alt="Kindle Fire as Extra Screen"></a></p>
<p dir="auto">I have a couple old kindle fire tablets lying around. One of them has a battery
that lasts about ten minutes. I also never have enough screens and never know
where to put my terminal when I need to tail a log or something.</p>
<p dir="auto">I tried using <a href="https://github.com/pavlobu/deskreen">Deskreen</a> a long time ago
as my optional extra screen when I travel. I can't remember why I didn't get
that habit going.</p>
<p dir="auto">For my extra office screen, I decided to do something different because</p>
<ul dir="auto">
<li>My graphics card seems to be maxed out. I can't even use the internal screen.</li>
<li>I don't know where I put that virtual display adapter.</li>
<li>It seemed like a bit of a detour to send pixels to my tablet when I am only
looking at text</li>
</ul>
<h4 tabindex="-1" id="user-content-so-what-is-then" dir="auto"><a href="#so-what-is-then">So what is then?</a></h4>
<p dir="auto">Well I just ssh into my computer from an android SSH client, open <code>screen</code>, and
then use a program I made that allows me to <code>stuff</code> the characters I type into
the screen session, so it feels like I am typing right into the tablet.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/alex028502/extra-screen/blob/master/pics/terminal-app.png"><img src="https://github.com/alex028502/extra-screen/raw/master/pics/terminal-app.png" alt="typing app"></a></p>
<p dir="auto">See if you can find this little window in the main picture. That is what I have
to activate using Alt+Tab to type into the terminal.</p>
<h4 tabindex="-1" id="user-content-this-is-an-mvp-and-a-poc-and-stuff-like-that" dir="auto"><a href="#this-is-an-mvp-and-a-poc-and-stuff-like-that">This is an 'MVP' and a 'POC' and stuff like that</a></h4>
<p dir="auto">While I think this approach to using a spare tablet as an extra screen may be
a winner, I am not so sure about this approach to this approach to using a
spare tablet as an extra screen.  Here are the issues:</p>
<ul dir="auto">
<li>You have to give some a mobile app access to your entire computer. This seems
like a shame after the phone OS did all this work to sandbox the mobile app, and
not give it access to your phone or tablet. This is even less awesome for an
iPad since there don't seem to be any open source SSH clients, and even if
there were, I don't think there would be any guarantee that what you see on
github is what has been sent to the app store.</li>
<li>You have to open an SSH server on your computer that exposes you to some
clever hacker in the Starbucks where you are using your spare screen</li>
<li>I can't figure out how to stuff C-SPC, which is a 0x0 - so have a clunky
workaround</li>
<li>It seems weird to execute <code>screen</code> once per key. I wish I could just pipe the
characters in or something - not that I have any idea how relevant that is to
performance.</li>
<li>It's hard to find terminal clients for some old devices (like my iPad)</li>
</ul>
<p dir="auto">What I think might be a better approach to this approach is using a lot of the
bits and pieces in <a href="https://hyper.is/" rel="nofollow">hyper</a>, such as
<a href="http://xtermjs.org/" rel="nofollow">xterm.js</a>, showing the terminal in a web browser, and
sending the characters over a web socket. It would still only send just over a
byte per keypress or something like that, and not use your GPU/HDMI, but could
work on even more devices - any device with a browser, just like Deskreen. The
server app would have to do much more:</p>
<ul dir="auto">
<li>serve the client app</li>
<li>make you type in a four digita code that you see on your tablet screen sort of
like Bluetooth pairing</li>
<li>set up the shell, and PTY probably</li>
<li>listen to the console end of the PTY and send everything down the websocket</li>
<li>send key presses to the PTY</li>
</ul>
<p dir="auto">Both solutions depend on the LAN, which is too bad. Maybe Web Bluetooth or
something for future old devices.</p>
<h2 tabindex="-1" id="user-content-set-up" dir="auto"><a href="#set-up">Set-up</a></h2>
<p dir="auto">I don't really think anybody else should use my Python program that stuffs keys
into the screen session (unless it's an emergency).  You are better off taking
the idea and making your own even better solution. But I'll first explain it
using my program.</p>
<h5 tabindex="-1" id="user-content-enable-ssh-on-your-computer" dir="auto"><a href="#enable-ssh-on-your-computer">enable ssh on your computer</a></h5>
<div data-snippet-clipboard-copy-content="sudo apt-get install openssh-server"><pre><code>sudo apt-get install openssh-server
</code></pre></div>
<p dir="auto">but make sure it is disabled so that you don't have it on unnecessarily, or in
public places.</p>
<div data-snippet-clipboard-copy-content="sudo systemctl disable ssh"><pre><code>sudo systemctl disable ssh
</code></pre></div>
<p dir="auto">start it whenever you are playing with your extra screen and on a trusted
network:</p>

<p dir="auto">disable it the rest of the time</p>

<h5 tabindex="-1" id="user-content-open-a-terminalssh-client-on-your-tablet" dir="auto"><a href="#open-a-terminalssh-client-on-your-tablet">open a terminal/ssh client on your tablet</a></h5>
<p dir="auto">I side-loaded ConnectBot onto my Kindle Fire from F-Droid. I tried to sideload
F-Droid, and then install ConnectBot, but it failed for some reason</p>
<h5 tabindex="-1" id="user-content-start-screen-with-a-known-session-name" dir="auto"><a href="#start-screen-with-a-known-session-name">start screen with a known session name:</a></h5>

<p dir="auto">If you are using ConnectBot on a Kindle Fire, there seems to be a
<a href="https://github.com/connectbot/connectbot/issues/543" data-hovercard-type="issue" data-hovercard-url="/connectbot/connectbot/issues/543/hovercard">known bug</a> that return
doesn't work. There are some workarounds for emergencies in the bug report but
I just configured the above to happen every time I connected.</p>
<p dir="auto"><code>DISPLAY=:0</code> makes it so that you can do stuff like <code>xdg-open .</code> and <code>emacs &amp;</code>
and <code>git gui &amp;</code> in the terminal, and see the result in your main gui session.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/alex028502/extra-screen/blob/master/pics/settings.png"><img src="https://github.com/alex028502/extra-screen/raw/master/pics/settings.png" alt="ConnectBot settings"></a></p>
<h5 tabindex="-1" id="user-content-install-and-run-my-typing-programme" dir="auto"><a href="#install-and-run-my-typing-programme">install and run my typing programme</a></h5>
<p dir="auto">Don't actually do this.</p>
<div data-snippet-clipboard-copy-content="$ cd [project directory that you cloned]
$ make # to generate images and special null file
$ sudo apt-get install python3-gi
$ python3 start.sh aux"><pre><code>$ cd [project directory that you cloned]
$ make # to generate images and special null file
$ sudo apt-get install python3-gi
$ python3 start.sh aux
</code></pre></div>
<h5 tabindex="-1" id="user-content-actually-just-make-your-own-typing-solution" dir="auto"><a href="#actually-just-make-your-own-typing-solution">actually just make your own typing solution</a></h5>
<p dir="auto">Check this out:</p>
<div data-snippet-clipboard-copy-content="$ screen -S aux -X stuff x"><pre><code>$ screen -S aux -X stuff x
</code></pre></div>
<p dir="auto">An <code>x</code> should appear in your terminal</p>
<p dir="auto">You need to somehow make all the control characters work. The ones you need</p>

<p dir="auto">Look at <a href="https://github.com/alex028502/extra-screen/blob/master/start.py">my program</a> for ideas on how to implement yours that is
even better</p>
<p dir="auto">There is some more debugging advice further down.</p>
<h5 tabindex="-1" id="user-content-create-a-services-or-something" dir="auto"><a href="#create-a-services-or-something">create a services or something</a></h5>
<p dir="auto">That would be cool to have the ssh daemon start the the typing program as a
service whenever the ssh session is opened - like similar to what you can do
with udev.</p>
<p dir="auto">I think you have to do something with <code>ForceCommand</code> in <code>/etc/ssh/sshd_config</code></p>
<p dir="auto">I think you can also watch <code>/var/log/auth.log</code> for <code>sshd</code> and <code>Accepted</code> using
awk.</p>
<h2 tabindex="-1" id="user-content-faq" dir="auto"><a href="#faq">FAQ</a></h2>
<h4 tabindex="-1" id="user-content-how-well-does-it-work" dir="auto"><a href="#how-well-does-it-work">How well does it work?</a></h4>
<p dir="auto">It works really well on my Kindle Fire at the office as a terminal. It is too
slow at home, with my iPad, as my emacs screen. This could be because:</p>
<ul dir="auto">
<li>the ssh client that I found that works with my old iPad is too slow to update
after characters get stuffed in</li>
<li>the wifi network at home is too slow</li>
<li>trying to use it as a full text editor for serious work makes the speed more
noticeable
(I have used emacs at the office set-up in the picture, and it seems to work
pretty well, but it's too small to really try to work with it - I am also
thinking using emacs to display my email inbox with it so I can keep an eye on
my email while I work)</li>
</ul>
<p dir="auto">I am planning to mainly use it at the office to tail logs, but I have been
'daily driving' it for all terminal stuff just to try it out.</p>
<p dir="auto">ConnectBot on Kindle Fire doesn't make it easy to get into landscape mode.
<a href="https://github.com/connectbot/connectbot/issues/868" data-hovercard-type="issue" data-hovercard-url="/connectbot/connectbot/issues/868/hovercard">Here</a> it sounds like you
have to connect a Bluetooth keyboard. That's actually an interesting idea - I
could have made my type-into-the-terminal app act like a bluetooth keyboard for
your tablet instead of inserting characters into the screen session.</p>
<p dir="auto">Originally, I had hoped for landscape, but now I have found a great for my
portrait tablet between my monitors, and found that for small terminal windows,
splitting across is good, and for logs, long is good. The text has to be quite
small to get 80 characters across.</p>
<p dir="auto">I got used to finding the application with Alt+Tab. I tried to drag my mouse
over to the tablet a couple times. I don't really use workspaces. I like to be
able to see as many things as possible by turning my head, and find applications
to bring to the foreground with Alt+Tab. If you use workspaces, I guess it
changes things a little bit.  You could search for the terminal typing app, and
hide your other windows. On GNOME 3, or at least on Ubuntu 22.04, on my
computer, one of the screens never changes with workspace, so I guess the
terminal typing app could go in there. On MATE, both screens are in the
workspace, but I think there is an always in active workspace function
somewhere. Just brainstorming though - I am sure if a workspace user wants to
do the same thing, they'll work it out.</p>
<h4 tabindex="-1" id="user-content-what-about-paste" dir="auto"><a href="#what-about-paste">What about paste?</a></h4>
<p dir="auto">Ctrl+Shift+V for paste works by stuffing your whole clipboard into the screen
session.</p>
<h4 tabindex="-1" id="user-content-what-about-copy" dir="auto"><a href="#what-about-copy">What about copy?</a></h4>
<p dir="auto">I haven't figured out copy yet. I think there must be an easy way to send my
tmux clipboard to the graphical clipboard. Since I start <code>screen</code> with
<code>DISPLAY=:0</code>, any copy to clipboard utility should hopefully "just work".</p>
<h4 tabindex="-1" id="user-content-why-do-you-use-screen-and-tmux" dir="auto"><a href="#why-do-you-use-screen-and-tmux">Why do you use <code>screen</code> <em>and</em> <code>tmux</code>?</a></h4>
<ul dir="auto">
<li>I didn't want all the tmux chrome when using emacs
(you can turn it off with tmux, but then that changes the tmux experience when
I do want to use tmux)</li>
<li>I got the stuff command working with screen, and it's just a MVP/POC so I left
it like that.</li>
</ul>
<h4 tabindex="-1" id="user-content-if-you-are-an-emacs-user-shouldnt-you-use-one-of-the-emacs-shells" dir="auto"><a href="#if-you-are-an-emacs-user-shouldnt-you-use-one-of-the-emacs-shells">If you are an emacs user, shouldn't you use one of the emacs shells?</a></h4>
<p dir="auto">Yeah I never really got into that, and I always have a full screen worth of
open text files.</p>
<h4 tabindex="-1" id="user-content-why-dont-you-just-use-____" dir="auto"><a href="#why-dont-you-just-use-____">Why don't you just use ____?</a></h4>
<p dir="auto">I have to admit, I didn't look to hard to see if there was a ready to go way to
do this - if somebody knows of one, please just submit a pull request that
deletes my whole repo, and leaves only a readme that points me toward the
alternative.</p>
<h2 tabindex="-1" id="user-content-developing-the-typing-application" dir="auto"><a href="#developing-the-typing-application">Developing the typing application.</a></h2>
<p dir="auto">For developing, and getting the keycodes right, you don't really need a tablet.</p>
<p dir="auto">I start a screen session in an ordinary terminal instead of the tablet, and
then run this program:</p>
<div data-snippet-clipboard-copy-content="import sys
import termios
import tty

old_settings = termios.tcgetattr(sys.stdin)
try:
    tty.setraw(sys.stdin.fileno())
    while True:
        char = sys.stdin.read(1)
        print(&quot;%s\r&quot; % hex(ord(char)))
        if char == '\x03':
            raise KeyboardInterrupt
finally:
    termios.tcsetattr(sys.stdin, termios.TCSADRAIN, old_settings)"><pre><code>import sys
import termios
import tty

old_settings = termios.tcgetattr(sys.stdin)
try:
    tty.setraw(sys.stdin.fileno())
    while True:
        char = sys.stdin.read(1)
        print("%s\r" % hex(ord(char)))
        if char == '\x03':
            raise KeyboardInterrupt
finally:
    termios.tcsetattr(sys.stdin, termios.TCSADRAIN, old_settings)
</code></pre></div>
<p dir="auto">Then I connect my python typer program to that screen session, and compare the
codes that I get when I type straight into the terminal to the codes I get when
I get when I use my typing application.</p>
<p dir="auto">Hopefully after reading
<a href="https://blog.nelhage.com/2009/12/a-brief-introduction-to-termios/" rel="nofollow">this</a> I
will understand more about what <code>tty.setraw</code> does.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Productivity has grown faster in Western Europe than in America (150 pts)]]></title>
            <link>https://www.economist.com/graphic-detail/2023/10/04/productivity-has-grown-faster-in-western-europe-than-in-america</link>
            <guid>37789290</guid>
            <pubDate>Fri, 06 Oct 2023 11:25:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/graphic-detail/2023/10/04/productivity-has-grown-faster-in-western-europe-than-in-america">https://www.economist.com/graphic-detail/2023/10/04/productivity-has-grown-faster-in-western-europe-than-in-america</a>, See on <a href="https://news.ycombinator.com/item?id=37789290">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div data-body-id="cp1"><figure data-infographic-class="g-fallback"></figure><figure data-infographic-js="1"></figure><p data-caps="initial"><span data-caps="initial">T</span><small>HE EU ECONOMY</small> is now 65% the size of America’s in dollar terms, down from 90% just ten years ago. Slow population growth is partly to blame—the number of Europeans has risen by 1.6% since 2012, compared with 6.1% for Americans. Still, <small>GDP</small> per person is higher, and has grown far faster, in the United States than in Europe.</p><div><figure><div><figcaption>Listen to this story.</figcaption> <p><span>Enjoy more audio and podcasts on<!-- --> <a id="audio-ios-cta" href="https://economist-app.onelink.me/d2eC/bed1b25" target="_blank" rel="noreferrer">iOS</a> <!-- -->or<!-- --> <a id="audio-android-cta" href="https://economist-app.onelink.me/d2eC/7f3c199" target="_blank" rel="noreferrer">Android</a>.</span></p></div><audio controls="" id="audio-player" preload="none" src="https://www.economist.com/media-assets/audio/091%20Graphic%20detail%20-%20Productivity-8fd34726d8d2617895da583200301f18.mp3" title="Productivity has grown faster in western Europe than in America" controlslist="nodownload"><p>Your browser does not support the &lt;audio&gt; element.</p></audio></figure></div><p>As a result, commentators and think-tanks have set about comparing the economies of some of Europe’s richest countries to those of America’s poorest states. But comparisons based simply on <small>GDP</small> per person are poor measures of economic welfare. Goods and services cost more in some countries than in others, and working more does not always make people better off. Adjusting for these factors suggests that countries like Denmark and Austria are in fact more productive than America.</p><p>The first step in comparing different economies is converting national figures into a common currency. But a dollar goes much further in some countries than others, because the costs of non-tradable goods and services, such as housing or restaurant meals, vary widely. Measuring living standards requires converting <small>GDP</small> figures to “purchasing-power parity” (<small>PPP</small>).</p><figure data-infographic-class="g-fallback"></figure><figure data-infographic-js="1"></figure><p>Europe’s economic performance looks far better at <small>PPP</small> than in nominal terms. In 2012 prices in America were just 5.4% higher than in the <small>EU</small> at market exchange rates. Today, the gap is 46%, largely thanks to a strong dollar. Adjusting for <small>PPP</small>,<!-- --> the<small> EU</small>’s<small> GDP</small> is roughly 95% of America’s, the same as it was ten years ago. Still, <small>PPP</small>-adjusted <small>GDP</small> per person has grown faster in America than in most of western Europe.</p><p>But focus instead on productivity, by dividing these figures by a tally of hours worked, and the gap closes further. As a result of demography—western Europe has a larger share of elderly people than America does—and because of differences in holiday allowances, pensions and unemployment benefits, Europeans work less than Americans do. On an hourly basis, countries like Austria, Belgium and Denmark leap ahead. In France, Germany and Sweden productivity has also grown faster in the past ten years than it has in America.</p><figure data-infographic-class="g-fallback"></figure><figure data-infographic-js="1"></figure><p>Such adjustments are an inexact science. <small>PPP</small> conversions struggle to capture differences in the quality of goods and services and many countries calculate hours worked differently. But in aggregate, western Europeans get just as much out of their labour as Americans do. Narrowing the gap in total <small>GDP</small> would require additional working hours, either via immigration or by raising the amount of time citizens spend on the job. Europeans may well reject this trade-off—they tend to value leisure time, even if <small>GDP </small>figures do not. <span data-ornament="ufinish">■</span></p><p><em>Chart sources: OECD; World Bank. Inspect our code on <a href="https://github.com/TheEconomist/the-economist-gdp-per-hour-estimates/">Github</a>.</em></p></div><div><p>This article appeared in the Graphic detail section of the print edition under the headline "All work and no play"</p><p>Chart sources: OECD; World Bank. Inspect our code on <a href="https://github.com/TheEconomist/the-economist-gdp-per-hour-estimates/">Github</a>.</p></div><div orientation="vertical" data-test-id="vertical"><div orientation="vertical"><figure><img alt="Are free markets history? The rise of homeland economics" loading="lazy" width="1280" height="1684" decoding="async" data-nimg="1" sizes="300px" srcset="https://www.economist.com/img/b/16/21/90/media-assets/image/20231007_DE_EU.jpg 16w, https://www.economist.com/img/b/32/42/90/media-assets/image/20231007_DE_EU.jpg 32w, https://www.economist.com/img/b/48/63/90/media-assets/image/20231007_DE_EU.jpg 48w, https://www.economist.com/img/b/64/84/90/media-assets/image/20231007_DE_EU.jpg 64w, https://www.economist.com/img/b/96/126/90/media-assets/image/20231007_DE_EU.jpg 96w, https://www.economist.com/img/b/128/168/90/media-assets/image/20231007_DE_EU.jpg 128w, https://www.economist.com/img/b/256/336/90/media-assets/image/20231007_DE_EU.jpg 256w, https://www.economist.com/img/b/360/473/90/media-assets/image/20231007_DE_EU.jpg 360w, https://www.economist.com/img/b/384/505/90/media-assets/image/20231007_DE_EU.jpg 384w, https://www.economist.com/img/b/480/631/90/media-assets/image/20231007_DE_EU.jpg 480w, https://www.economist.com/img/b/600/789/90/media-assets/image/20231007_DE_EU.jpg 600w, https://www.economist.com/img/b/834/1097/90/media-assets/image/20231007_DE_EU.jpg 834w, https://www.economist.com/img/b/960/1263/90/media-assets/image/20231007_DE_EU.jpg 960w, https://www.economist.com/img/b/1096/1441/90/media-assets/image/20231007_DE_EU.jpg 1096w, https://www.economist.com/img/b/1280/1684/90/media-assets/image/20231007_DE_EU.jpg 1280w, https://www.economist.com/img/b/1424/1873/90/media-assets/image/20231007_DE_EU.jpg 1424w" src="https://www.economist.com/img/b/1424/1873/90/media-assets/image/20231007_DE_EU.jpg"></figure></div><div orientation="vertical"><h3 orientation="vertical">From the October 7th 2023 edition</h3><p orientation="vertical">Discover stories from this section and more in the list of contents </p><a href="https://www.economist.com/printedition/2023-10-07" data-analytics="sidebar:weekly_edition"><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1zm.142 4.5l-1.008 1.062c3.33 3.276 4.194 4.14 4.608 4.5-1.602-.018-3.168-.018-10.242-.018v1.584c7.074 0 8.73 0 10.242-.018-.432.36-1.314 1.206-4.608 4.536l1.008 1.044 6.354-6.354L12.142 5.5z" fill="#2E45B8" fill-rule="nonzero"></path></g></svg><span>Explore the edition</span></a></div></div></div></div>]]></description>
        </item>
    </channel>
</rss>