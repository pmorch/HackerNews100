<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 06 Jan 2024 04:00:07 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Carta doing unsolicited tender offer outreach to their customers' investors (146 pts)]]></title>
            <link>https://twitter.com/karrisaarinen/status/1743398553500971331</link>
            <guid>38886915</guid>
            <pubDate>Sat, 06 Jan 2024 00:22:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/karrisaarinen/status/1743398553500971331">https://twitter.com/karrisaarinen/status/1743398553500971331</a>, See on <a href="https://news.ycombinator.com/item?id=38886915">Hacker News</a></p>
Couldn't get https://twitter.com/karrisaarinen/status/1743398553500971331: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Fixing Macs door to door (152 pts)]]></title>
            <link>https://matduggan.com/fixing-macs-door-to-door/</link>
            <guid>38886030</guid>
            <pubDate>Fri, 05 Jan 2024 22:41:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matduggan.com/fixing-macs-door-to-door/">https://matduggan.com/fixing-macs-door-to-door/</a>, See on <a href="https://news.ycombinator.com/item?id=38886030">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
<p>When I graduated college in 2008, even our commencement speaker talked about how moving back in with your parents is nothing to be ashamed of. I sat there thinking <em>well that certainly can't be a good sign</em>. Since I had no aspirations and my girlfriend was moving to Chicago, I figured why not follow her. I had been there a few times and there were no jobs in Michigan. We found a cheap apartment near her law school and I started job hunting. </p><p>After a few weeks applying to every job on Craigslist, I landed an odd job working for an Apple Authorized Repair Center. The store was in a strip mall in the suburbs of Chicago with a Dollar Store and a Chinese buffet next door. My primary qualifications were that I was willing to work for not a lot of money and I would buy my own tools. My interview was with a deeply Catholic boss who focused on how I had been an alter boy growing up. Like all of my bosses early on, his primary quality was he was a bad judge of character. </p><p>I was hired to do something that I haven't seen anyone else talk about on the Internet and wanted to record before it was lost to time. It was a weird program, a throwback to the pre-Apple Store days of Apple Mac support that was called AppleCare Dispatch. It still appears to exist (<a href="https://www.apple.com/support/products/mac/">https://www.apple.com/support/products/mac/</a>) but I don't know of any AASPs still dispatching employees. It's possible that Apple has subcontracted it out to someone else. </p><figure><img src="https://matduggan.com/content/images/2024/01/image.png" alt="" loading="lazy" width="993" height="45" srcset="https://matduggan.com/content/images/size/w600/2024/01/image.png 600w, https://matduggan.com/content/images/2024/01/image.png 993w" sizes="(min-width: 720px) 720px"></figure><h2 id="applecare-dispatch">AppleCare Dispatch</h2><p>Basically if you owned a desktop Mac and lived in certain geographic areas, when you contacted AppleCare to get warranty support they could send someone like me out with a part. Normally they'd do this only for customers who were extremely upset or had a store repair go poorly. I'd get a notice that AppleCare was dispatching a part, we'd get it from FedEx and then I'd fill a backpack full of tools and head out to you on foot. </p><p>While we had the same certifications as an Apple Genius, unlike the Genius Bar we weren't trained on any sort of "customer service" element. All we did was Mac hardware repairs all day, with pretty tight expectations of turnaround. So how it worked at the time was basically if the Apple Store was underwater with in-house repairs, or you asked for at-home or the customer was Very Important, we would get sent out. I would head out to you on foot with my CTA card. </p><p>That's correct, I didn't own a car. AppleCare didn't pay a lot for each dispatch and my salary of $25,000 a year plus some for each repair didn't go far in Chicago even in the Great Recession. So this job involved me basically taking every form of public transportation in Chicago to every corner of the city. I'd show up at your door within a 2 hour time window, take your desktop Mac apart in your house, swap the part, run the diagnostic and then take the old part with me and mail it back to Apple. </p><p>Apple provided a backend web panel which came with a chat client. Your personal Apple ID was linked with the web tool (I think it was called ASX) where you could order parts for repairs as well as open up a chat with the Apple rep there to escalate an issue or ask for additional assistance. The system worked pretty well, with Apple paying reduced rates for each additional part after the first part you ordered. This encouraged us all to get pretty good at specific diagnostics with a minimal number of swaps. </p><p>Our relationship to Apple was bizarre. Very few people at Apple even knew the program existed, seemingly only senior AppleCare support people. We could get audited for repair quality, but I don't remember that ever happening. Customer satisfaction was extremely important and basically determined the rate we got paid, so we were almost never late to appointments and typically tried to make the experience as nice as possible. Even Apple Store staff seemed baffled by us on the rare occasions we ran into each other. </p><p>There weren't a lot of us working in Chicago around 2008-2010, maybe 20 in total. The community was small and I quickly met most of my peers who worked at other independent retail shops. If our customer satisfaction numbers were high, Apple never really bothered us. They'd provide all the internal PDF repair guides, internal diagnostic tools and that was it. </p><p>It is still surprising that Apple turned us loose onto strangers without anyone from Apple speaking to us or making us watch a video. Our exam was mostly about not ordering too many parts and ensuring we could read the PDF guide of how to fix a Mac. A lot of the program was a clear holdover from the pre-iPod Apple, where resources were scarce and oversight minimal. As Apple Retail grew, the relationship to Apple Authorized Service Providers got more adversarial and controlling. But that's a story for another time.</p><h3 id="tools-etc">Tools etc </h3><p>For the first two years I used a Manhattan Portage bag, which looked nice but was honestly a mistake. My shoulder ended up pretty hurt after carrying a heavy messenger bag for 6+ hours a day. </p><figure><img src="https://www.manhattanportage.com/media/catalog/product/cache/5d6092f643b784d9c9e99823eee7dcab/1/7/1714_blk_angle_3_1.jpg" alt="" loading="lazy"></figure><p>The only screwdrivers I bothered with was Wiha precision screwdrivers. I tried all of them and Wiha were consistently the best by a mile. Wiha has a list of screwdrivers by Apple model available here: <a href="https://www.wihatools.com/blogs/articles/apple-and-wiha-tools">https://www.wihatools.com/blogs/articles/apple-and-wiha-tools</a></p><p>Macs of this period booted off of FireWire, so that's what I had with me. FireWire 800 LaCie drives were the standard issue drives in the field. </p><figure><img src="https://matduggan.com/content/images/2023/12/data-src-image-c131a17b-079c-4a33-8b40-cf18940b04ff.jpeg" alt="LaCie Rugged Triple 2TB 2TB 5400rpm FireWire 800, USB 3.0 Orange, SÃ¸lv  (LAC9000448) | Dustin.dk" loading="lazy" width="296" height="170"></figure><p>You'd partition it to have a series of OS X Installers on there (so you could restore the customer back to what they had before) along with a few bootable installs of OS X. These were where you'd run your diagnostic software. The most commonly used ones were as follows: </p><figure><a href="https://daisydiskapp.com/"><div><p>DaisyDisk, the most popular disk space analyzer</p><p>Get a visual breakdown of your disk space in form of an interactive map, reveal the biggest space wasters, and remove them with a simple drag and drop.</p><p><img src="https://daisydiskapp.com/favicon/favicon.ico" alt=""><span>Software&nbsp;Ambience&nbsp;Corp. All&nbsp;rights&nbsp;reserved.</span></p></div><p><img src="https://daisydiskapp.com/img/card-2023-12-02-14-58-14.jpg" alt=""></p></a></figure><figure><a href="https://www.alsoft.com/"><div><p>ALSOFT - Makers of DiskWarrior.</p><p>DiskWarrior is a utility program designed from the ground up with a totally different approach to preventing and resolving directory damage.</p><p><img src="https://images.squarespace-cdn.com/content/v1/5ad6666345776e48c58629d5/1565815245086-8A693B3YCQYVD33QWQG1/favicon.ico?format=100w" alt=""><span>ALSOFT</span></p></div><p><img src="https://images.squarespace-cdn.com/content/v1/5ad6666345776e48c58629d5/1566324726836-MEWGZJR0RS86656MB262/Spinning-Wheel-Flat.png" alt=""></p></a></figure><p><a href="https://www.cleverfiles.com/pro.html">https://www.cleverfiles.com/pro.html</a></p><ul><li><a href="https://www.temu.com/ul/kuiper/un9.html?subj=goods-un&amp;_bg_fs=1&amp;_p_jump_id=894&amp;_x_vst_scene=adg&amp;goods_id=601099521402742&amp;sku_id=17592237085426&amp;adg_ctx=a-ecc88057~c-707e76bf~f-dc1865d9&amp;_x_ads_sub_channel=shopping&amp;_p_rfs=1&amp;_x_ns_prz_type=3&amp;_x_ns_sku_id=17592237085426&amp;mrk_rec=1&amp;_x_ads_channel=google&amp;_x_gmc_account=5076073866&amp;_x_login_type=Google&amp;_x_ads_account=5695467342&amp;_x_ads_set=20797576552&amp;_x_ads_id=155487865083&amp;_x_ads_creative_id=681708980119&amp;_x_ns_source=g&amp;_x_ns_gclid=EAIaIQobChMIiaKbz6eygwMVmIpQBh0jAwd2EAQYASABEgL4wPD_BwE&amp;_x_ns_placement=&amp;_x_ns_match_type=&amp;_x_ns_ad_position=&amp;_x_ns_product_id=17592237085426&amp;_x_ns_target=&amp;_x_ns_devicemodel=&amp;_x_ns_wbraid=CjgKCAiAs6-sBhANEigAWPOIhhN-ri0r4C3iH_5qtalU-pCY1av0tKJFNNUPXftHpOHMNU57GgKV-g&amp;_x_ns_gbraid=0AAAAAo4mICG1MeRLHQ8GZ9YCr_BliyPV-&amp;_x_ns_targetid=pla-2195477599320&amp;gad_source=1&amp;gclid=EAIaIQobChMIiaKbz6eygwMVmIpQBh0jAwd2EAQYASABEgL4wPD_BwE" rel="noreferrer">Kapton tape to hold cables in place</a></li><li><a href="https://www.amazon.com/Fixinus-Universal-Spudger-Opening-Tablets/dp/B01GNYK0K6?th=1" rel="noreferrer">Black spudgers</a></li><li><a href="https://eshop.macsales.com/shop/newertech-universal-drive-adapter" rel="noreferrer">Universal drive cable</a></li></ul><figure><img src="https://electroncomputers.com/images/Mac-Repair-Services-North-York-Toronto.jpg" alt="Mac Repair North York" loading="lazy"><figcaption><span>Remember back when Macs were something you could fix? Crazy times</span></figcaption></figure><h3 id="911-truther">9/11 Truther </h3><p>One of my first calls was for a Mac Pro at a private residence. It was a logic board, which means the motherboard of the Mac. I wasn't thrilled, because removing and replacing the Mac Pro logic board was a time-consuming repair that required a lot of light. Instead of a clean workspace with bright lights I got a guy who would not let me go until I had watched how 9/11 was an inside job. </p><figure><img src="https://img.ricardostatic.ch/images/6cbd9f4b-7be8-4a91-abe4-5c7f90e12b1a/t_1000x750/mac-pro-41-2009-motherboard-logic-board" alt="Mac Pro 4.1 2009 Motherboard Logic Board | Kaufen auf Ricardo" loading="lazy"><figcaption><span>The logic board in question</span></figcaption></figure><p>"Look, you don't really think the towers were blown up by planes do you?" he said as he dug around this giant stack of papers to find...presumably some sort of Apple-related document. I had told him that I had everything I needed, but that I had a tight deadline and needed to start right now. "Sure, but I'll put the video on in the background and you can just listen to it while you work." So while I took a Mac Pro down to the studs and rebuilt it, this poorly narrated video explained how it was the CIA behind 9/11. </p><p>His office or, "command center", looked like a set of the X-Files. There were folders and scraps of paper everywhere along with photos of buildings, planes, random men wearing sunglasses. I think it was supposed to come across as if he was doing an investigation, but it reminded me more of a neighbor who struggled with hoarding. If there was an organizational system, I couldn't figure it out. Why was this person so willing to dedicate an large portion of their house to "solving a mystery" the rest of us had long since moved on from?</p><p>The Mac Pro answered all my questions when it booted up. The desktop was full of videos he had edited of 9/11 truth material along with website assets for where he sold these videos. This guy wasn't just a believer, he produced the stuff. When I finished, we had to run a diagnostic test to basically confirm the thing still worked as well as move the serial number onto the logic board. When it cleared diagnostic I took off, thanking him for his time and wishing him a nice day. He looked devastated and asked if I wanted to go grab a drink at the bar and continue our conversation. I declined, jogging to the L. </p><h3 id="the-doctors">The Doctors </h3><p>One of the rich folks I was sent out to lived in one of those short, super expensive buildings on Lake Shore Drive. For those unfamiliar, these shorter buildings facing the water in Chicago are often divided into a few large houses. Basically you pass through an army of doorman, get shown into an elevator that opens into the persons house. That was, if you could get through the doormen. </p><p>The staff in rich peoples houses want to immediately establish with any contractor coming into the home that they're superior to you. This happened to me <em>constantly</em>, from personal assistants to doormen, maids, nannies, etc. Doormen in particular liked to make a big deal of demonstrating that they could stop me from going up. This one stuck out because he made me take the freight elevator, letting me know "the main elevator is for people who live here and people who work here". I muttered about how I was also working there and he rolled his eyes and called me an asshole. </p><p>On another visit to a different building I had a doorman physically threaten "to throw me down" if I tried to get on the elevator. The reason was all contractors had to have insurance registered with the building before they did work there, even though I wasn't.....removing wires from the wall. The owner came down and explained that I wasn't going to do any work, I was just "a friend visiting". I felt bad for the doorman in that moment, in a dumb hat and ill-fitting jacket with his brittle authority shattered. </p><p>So I took the freight elevator up, getting let into what I would come to see as "the rich persons template home". My time going into rich peoples houses were always disappointing, as they are often a collection of nice items sort of strewn around. I was shown by the husband into the library, a beautiful room full of books with what I (assumed) were prints of paintings in nice frames leaning against the bookshelves. There was an iMac with a dead hard drive, which is an easy repair.</p><p>The process for fixing a hard drive was "boot to DiskWarrior, attempt to fix disk, have it fail, swap the drive". Even if DiskWarrior fixed the Mac and it booted, I would still swap the drive (why not and it's what I was paid to do) but then I didn't have to have the talk. This is where I would need to basically sit someone down and tell them their data was gone. "What about my taxes?!?" I would shake my head sadly. Thankfully this time the drive was still functional so I could copy the data over with a SATA to USB adapter. </p><p>As I reinstalled OS X, I walked around the room and looked at the books. I realized they were old, really old and the paintings on the floor were not prints. There were sketches by Picasso, other names I had heard in passing through going through art museums. When he came back in, I asked why there was a lot of art. "Oh sure, my dads, his big collection, I'm going to hang it up once we get settled." He, like his wife, didn't really acknowledge my presence unless I directed a question right at him. I started to google some of the books, my eyes getting wide. There was millions of dollars in this room gathering dust. He never made eye contact with me during this period and quickly left the room. </p><p>This seems strange but was really common among these clients. I truly think for many of the C-level type people whose house I went to, they didn't really even see me. I had people turn the lights off in rooms I was in, forget I was there and leave (while arming the security system). For whatever reason I instantly became part of the furniture. When I went to the kitchen for a drink of water, the maid let me know that they have lived there for coming up on 5 years. </p><p>This was surprising to me because the apartment looked like they had moved in two weeks ago. There were still boxes on the floor, a tv sitting on the windowsill and what I would come to understand was a "prop fridge". It had bottled water, a single bottle of expensive champagne, juices, fruit and often some sort of energy drink. No leftovers, everything gets swapped out before it goes bad and gets replaced. "They're always at work" she explained, grabbing her bag and offering to let me out before she locked up. They were both specialist doctors and this was apparently where they recharged their batteries. </p><p>After the first AppleCare Dispatch visit they would call me back for years to fix random problems. I don't think either of them ever learned my name. </p><h3 id="harpo-studio">HARPO Studio</h3><p>I was once called to fix a "high profile" computer at HARPO studios in Chicago. This was where they filmed the Oprah Winfrey Show, which I obviously knew of the existence of but had never watched. Often these celebrity calls went to me, likely because I didn't care and didn't particularly want them. I was directed to park across the street and told even though the signs said "no parking" that they had a "deal with the city". </p><p>This repair was suspicious and I got the sense that someone had name dropped Oprah to maybe get it done. AppleCare rarely sent me multiple parts unless the case was unusual or the person had gotten escalated through the system. If you emailed Steve Jobs back in the day and his staff approved a repair, it attached a special code to the serial number that allowed us to order effectively unlimited items against the serial number. However with the rare "celebrity" case, we would often find AppleCare did the same thing, throwing parts at us to make the problem go away. </p><p>The back area of HARPO was busy, with what seemed like an almost exclusively female staff. "Look it's important that if you see Oprah, you act normally, please don't ask her for an autograph or a photo". I nodded, only somewhat paying attention because never in a million years would I do that. This office felt like the set of The West Wing, with people constantly walking and talking along with a lot of hand motions. My guide led me to a back office with a desk on one side and a long table full of papers and folders. The woman told me to "fix the iMac" and left the room. </p><figure><img src="https://www.joshpabstphoto.com/wp-content/uploads/2015/01/harpo-studio-chicago-office-sterling-bay-joshpabstphoto-9-1920x1280.jpg" alt="harpo-studio-chicago-office-sterling-bay-joshpabstphoto-(9) â Architecture  Photography | Commercial Real Estate Photographer" loading="lazy"><figcaption><span>Not the exact office but you get the jist</span></figcaption></figure><p>I swapped the iMac hard drive and screen, along with the memory and wifi then dived under the desk the <em>second</em> Oprah walked in. The woman and Oprah had a conversation about scheduling someone at a farm, or how shooting at a farm was going and then she was gone. When I popped my head up, the woman looked at me and was like "can you believe you got to meet Oprah?" She had a big smile, like she had given me the chance of a lifetime. </p><p>The bummer about the aluminum iMac repairs is you have to take the entire screen off to get anything done. This meant I couldn't just run away and hide my shame after effectively diving under a table to escape Oprah, a woman who I am certain couldn't have cared less what came out of my mouth. I could have said "I love to eat cheese sometimes" and she would have nodded and left the room. </p><figure><img src="https://i.ytimg.com/vi/QZdWvQoSCQc/hqdefault.jpg" alt="NO TOOLS NEEDED How to replace your 27 inch iMac screen glass monitor -  YouTube" loading="lazy"></figure><p>So you have to pop the glass off (with suction cups, not your hands like a psycho as shown above), then unscrew and remove the LCD and then finally you get access to the actual components. Any dust that got on the LCD would stick and annoy people, so you had to try and keep it as clean as possible while moving quickly to get the swap done. The nightmare was breaking the thick cables that connected the screen to the logic board, something I did once and required a late night trip to an electronics repair guy who got me sorted out with a soldering iron. </p><p>The back alley electronics repair guy is the dark secret of the Dispatch world. If you messed up a part, pulled a cable or broke a connector, Apple could ask you to pay for that part. The Apple list price for parts were hilariously overpriced. Logic boards were like $700-$900, each stick of RAM was like $90 for ones you could buy on crucial for $25. This could destroy your pay for that month, so you'd end up going to Al, who ran basically a "solder Apple stuff back together" business in his garage. He wore overalls and talked a lot about old airplanes, which you'd need to endure in order to get the part fixed. Then I'd try to get the part swapped and just pray that the thing would turn on long enough for you to get off the property. Ironically his parts often lasted longer than the official Apple refurbished parts. </p><p>After I hid under the desk deliberately, I lied for years afterwards, telling people I didn't have time to say hi. In reality my mind completely blanked when she walked in. I stayed under the desk because I was nervous that everyone was going to look at me to be like "I loved when you did X" and my brain couldn't form a single memory of anything Oprah had ever done. I remembered Tom Cruise jumping on a couch but I couldn't recall if this was a good thing or a bad thing when it happened. </p><p>Oh and the car that I parked in the area the city didn't enforce? It had a parking ticket, which was great because I had borrowed the car. Most of the payment from my brush with celebrity went to the ticket and a tank of gas. </p><h3 id="brownstone-moms">Brownstone Moms</h3><p>One of the most common calls I got was to rich peoples houses in Lincoln Park, Streeterville, Old Town and a few other wealthy neighborhoods. They often live in distinct brownstone houses with small yards with a "public" entrance in the front, a family entrance on the side and then a staff entrance through the back or in the basement. </p><p>These houses were owned by some of the richest people in Chicago. The houses themselves were beautiful, but they don't operate like normal houses. Mostly they were run by the wives, who often had their own personal assistants. It was an endless sea of contractors coming in and out, coordinated by the mom and sometimes the nanny. </p><p>Once I was there, they'd pay me to do whatever random technical tasks existed outside of the initial repair. I typically didn't mind since I was pretty fast at the initial repair and the other stuff was easy, mostly setting up printers or routers. The sense I got was if the household made the AppleCare folks life a living hell, I would get sent out to make the problem disappear. These people often had extremely high expectations of customer service, which could be difficult at times.</p><p>There was a whole ecosystem of these small companies I started to run into more and more. They seemed to specialize in catering to rich people, providing tutoring services, in-house chefs, drivers, security and every other service under the sun. One of the AV installation companies and I worked together off the books after-hours to set up Apple TVs and Mac Minis as the digital media hubs in a lot of these houses. They'd pay me to set up 200 iPods as party favors or wire an iPad into every room.</p><p>Often I'd show up only to tell them their hard drive was dead and everything was gone. This was just how things worked before iCloud Photos, nobody kept backups and everything was constantly lost forever. Here they would often threaten or plead with me, sometimes insinuating they "knew people" at Apple or could get me fired. <em>Jokes on you people, I don't even know people at Apple</em> was often what ran through my head. Threats quickly lost their power when you realized nobody at any point had asked your name or any information about yourself. It's hard to threaten an anonymous person. </p><p>The golden rule that <em>every single one</em> of these assistants warned me about was not to bother the husband when he gets home. Typically these CEO-types would come in, say a few words to their kids and then retreat to their own area of the house. These were often TV rooms or home theaters, elaborate set pieces with $100,000+ of AV equipment in there that was treated like it was a secret lair of the house. To be clear, none of these men ever cared at all that I was there. They didn't seem to care that anybody was there, often barely acknowledging their wives even though an <em>immense</em> amount of work had gone into preparing for his return. </p><p>As smartphones became more of a thing, the number of "please spy on my teen" requests exploded. These varied from installing basically spyware on their kids laptops to attempting to install early MDM software on the kids iPhones. I was always uncomfortable with these jobs, in large part because the teens were extremely mean to me. One girl waited until her mom left the room to casually turn to me and say "I will pay you $500 to lie to my mom and say you set this up". </p><p>I was offended that this 15 year old thought she could buy me, in large part because she was correct. I took the $500 and told the mom the tracking software was all set up. She nodded and told me she would check that it was working and "call me back if it wasn't". I knew she was never going to check, so that part didn't spook me. I just hoped the kid didn't get kidnapped or something and I would end up on the evening news. But I was also a little short that month for rent so what can you do. </p><p><strong>Tip for anyone reading this looking to get into this rich person Mac business</strong></p><p>So the short answer is Time Machine is how you get paid month after month. Nobody checks Time Machine or pays attention to the "days since" notification. I wrote an AppleScript back in the day to alert you to Time Machine failures through email, but there is an app now that does the same thing: <a href="https://tmnotifier.com/">https://tmnotifier.com/</a></p><p>Basically when the backups fail, you schedule a visit and fix the problem. When they start to run out of space, you buy a new bigger drive. Then you backup the Time Machine to some sort of encrypted external location so when the drive (inevitably) gets stolen you can restore the files. The reason they keep paying you is you'll get a call at some point to come to the house at a weird hour and recover a PDF or a school assignment. That one call is how you get permanent standing appointments. </p><p>Nobody will ever ask you how it works, so just find the system you like best and do that. I preferred local Time Machine over something like remote backup only because you'll be sitting there until the entire restore is done and nothing beats local. Executives will often fill the "family computer" with secret corporate documents they needed printed off, so be careful with these backups. Encrypt, encrypt, encrypt then encrypt again. Don't bother explaining how the encryption works, just design the system with the assumption that someone will at some point put a CSV with your social security number onto this fun family iMac covered in dinosaur stickers. </p><h3 id="robbed-for-broken-parts">Robbed for Broken Parts</h3><p>A common customer for repairs would be schools, who would work with Apple to open a case for 100 laptops or 20 iMacs at a time. I liked these "mass repair" days, typically because the IT department for Chicago Public Schools would set us up with a nice clean area to work and I could just listen to a podcast and swap hard drives or replace top cases. However this mass repair was in one of Chicago's rougher neighborhoods. </p><p>Personal safety was a common topic among the dispatch folks when we would get together for a pizza and a beer. Everyone had bizarre stories but I was the only one not working out of my car. The general sense among the community was it was not an "if" but a "when" until you were robbed. Typically my rule was if I started to get nervous I'd "call back to the office" to check if a part had arrived. Often this would calm people down, reminding them that people knew where I was. Everyone had a story of getting followed back to their car and I had been followed back to the train once or twice. </p><p>On this trip though everything went wrong that could go wrong. My phone, the HTC Dream running v1 of Android had decided to effectively "stop phoning". It was still on but decided we were not, in fact, in the middle of a large city. I was instead in a remote forest miles away from a cell tower. I got to the school later than I wanted to be there, showing up at noon. When I tried to push it and come back the next day the staff let me know the janitors knew I would be there and would let me out. </p><p>So after replacing a ton of various Mac parts I walked out with boxes of broken parts in my bag and a bunch in an iMac box that someone had given me. My plan was I would head back home, get them checked in and labeled and then drop them off at a FedEx store. When I got out and realized it was dark, I started to accept something bad was likely about to happen to me. Live in a city for any amount of time and you'll start to develop a subconscious odds calculator. The closing line on this wasn't looking great. </p><p>Sure enough while waiting for the bus, I was approached by a man who made it clear he wanted the boxes. He didn't have a weapon but started to go on about "kicking the shit" out of me and I figured that was good enough for me. He clearly thought there was an iMac in the box and I didn't want to be here when he realized that wasn't true. I handed over my big pile of broken parts and sprinted to the bus that was just pulling up, begging the driver to keep driving. As a CTA bus driver, he had of course witnessed every possible horror a human can inflict on another human and was entirely unphased by my outburst. "Sit down or get off the bus". </p><p>When I got home I opened a chat with as Apple rep who seemed unsure of what to do. I asked if they wanted me to go to the police and the rep said if I wanted to I could, but after "talking to some people on this side" they would just mark the parts as lost in transit and it wouldn't knock my metrics. I thanked them and didn't think much more of the incident until weeks later when someone from Apple mailed me a small Apple notebook. </p><p>They never directly addressed the incident (truly the notebook might be unrelated) but I always thought the timing was funny. Get robbed, get a notebook. I still have the notebook. </p><figure><img src="https://imagedelivery.net/zTZJzgDLaZ7u1hvTz4LleQ/1b5c908d-6f92-4b7d-5c49-ad5dbf4db500/public" alt="" loading="lazy"></figure><p>Questions/comments/concerns? Find me on Mastodon: <a href="https://c.im/@matdevdug">https://c.im/@matdevdug</a></p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TinyLlama: An Open-Source Small Language Model (116 pts)]]></title>
            <link>https://arxiv.org/abs/2401.02385</link>
            <guid>38885054</guid>
            <pubDate>Fri, 05 Jan 2024 21:15:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2401.02385">https://arxiv.org/abs/2401.02385</a>, See on <a href="https://news.ycombinator.com/item?id=38885054">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2401.02385.pdf">Download PDF</a>
    <a href="https://browse.arxiv.org/html/2401.02385v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>We present TinyLlama, a compact 1.1B language model pretrained on around 1 trillion tokens for approximately 3 epochs. Building on the architecture and tokenizer of Llama 2, TinyLlama leverages various advances contributed by the open-source community (e.g., FlashAttention), achieving better computational efficiency. Despite its relatively small size, TinyLlama demonstrates remarkable performance in a series of downstream tasks. It significantly outperforms existing open-source language models with comparable sizes. Our model checkpoints and code are publicly available on GitHub at <a href="https://github.com/jzhang38/TinyLlama" rel="external noopener nofollow">this https URL</a>.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Guangtao Zeng [<a href="https://arxiv.org/show-email/ea2afa50/2401.02385">view email</a>]      <br>    <strong>[v1]</strong>
        Thu, 4 Jan 2024 17:54:59 UTC (1,783 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple Rejects the Hey Calendar from Their App Store (110 pts)]]></title>
            <link>https://world.hey.com/dhh/apple-rejects-the-hey-calendar-from-their-app-store-4316dc03</link>
            <guid>38884517</guid>
            <pubDate>Fri, 05 Jan 2024 20:34:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://world.hey.com/dhh/apple-rejects-the-hey-calendar-from-their-app-store-4316dc03">https://world.hey.com/dhh/apple-rejects-the-hey-calendar-from-their-app-store-4316dc03</a>, See on <a href="https://news.ycombinator.com/item?id=38884517">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <article>
      <div>
  <div><p>There should at least be a standard of double jeopardy when it comes to the app store monopoly regimes. If youâve managed to <a href="https://www.hey.com/apple/">overturn a rejection of your service</a> once, they canât come after you on the same service again later. We could have used that today!</p><p>But unfortunately there is no rule of law with the app stores, except that of the jungle, and Apple is the 800 lbs gorilla, ruling as it sees fit. So now <a href="https://hey.com/">HEY</a> is back on trial in their kangaroo court. This time with our new calendar feature, <a href="https://www.youtube.com/watch?v=SztU4232u_o">HEY Calendar</a>, which we dared make a separate app in service of users.&nbsp;</p><p>After spending 19 days to review our submission, causing us to miss a long-planned January 2nd launch date, Apple rejected our stand-alone free companion app âbecause it doesnât do anythingâ. That is because users are required to login with an existing account to use the functionality.</p><p>This is a ridiculous charge. The App Store is filled with high-profile applications that require an existing service account and simply presents a login screen when first launched. Here are just four:</p></div><div><p>Salesforce, JPMorgan, Netflix, and Google Calendar all greet the user with the same gate: Login with your existing account. There are thousands of other apps just like this. Some access enterprise services, like Salesforce. Some access consumer services, like JPMorgan. Some access streaming services, like Netflix. And, finally, some access calendar services that are part of a larger subscription suite you purchase on the web, like Google Calendar. And HEY Calendar!</p><p>But none of this even matters. Nowhere in the <a href="https://developer.apple.com/app-store/review/guidelines/#business">Apple App Store Guidelines</a> is there a prohibition on apps that require preexisting accounts! The only ruleset thatâs relevant to this discussion is that which governs who has to use in-app payments and who can avoid it.</p><p>Those were the rules <a href="https://twitter.com/dhh/status/1272968382329942017">we fought Apple over</a> when HEY originally launched back in 2020. Where we successfully managed to secure a carve-out. This is that carve-out from 3.1.3 (f):</p><figure>
      <a download="3-1-3f.jpeg" title="Download 3-1-3f.jpeg" data-click-proxy-target="lightbox_link_blob_1498691609" href="https://world.hey.com/dhh/4316dc03/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHNLd2NaT0ZSWiIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--9e47d2a9a99c45ed946615ccb759d3815eb068aa/3-1-3f.jpeg?disposition=attachment">
        <img src="https://world.hey.com/dhh/4316dc03/representations/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHNLd2NaT0ZSWiIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--9e47d2a9a99c45ed946615ccb759d3815eb068aa/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdDam9MWm05eWJXRjBTU0lKYW5CbFp3WTZCa1ZVT2hSeVpYTnBlbVZmZEc5ZmJHbHRhWFJiQjJrQ2dBZHBBZ0FGT2d4eGRXRnNhWFI1YVVzNkMyeHZZV1JsY25zR09nbHdZV2RsTURvTlkyOWhiR1Z6WTJWVSIsImV4cCI6bnVsbCwicHVyIjoidmFyaWF0aW9uIn19--824130a6fd2f596d29a6d245cf773fab0beee210/3-1-3f.jpeg" alt="3-1-3f.jpeg" srcset="https://world.hey.com/dhh/4316dc03/representations/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHNLd2NaT0ZSWiIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--9e47d2a9a99c45ed946615ccb759d3815eb068aa/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdDam9MWm05eWJXRjBTU0lKYW5CbFp3WTZCa1ZVT2hSeVpYTnBlbVZmZEc5ZmJHbHRhWFJiQjJrQ0FBOXBBZ0FLT2d4eGRXRnNhWFI1YVVFNkMyeHZZV1JsY25zR09nbHdZV2RsTURvTlkyOWhiR1Z6WTJWVSIsImV4cCI6bnVsbCwicHVyIjoidmFyaWF0aW9uIn19--f3f1b2037df56b6e7b02c335c36fe9999ab42b52/3-1-3f.jpeg 2x, https://world.hey.com/dhh/4316dc03/representations/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHNLd2NaT0ZSWiIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--9e47d2a9a99c45ed946615ccb759d3815eb068aa/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdDam9MWm05eWJXRjBTU0lKYW5CbFp3WTZCa1ZVT2hSeVpYTnBlbVZmZEc5ZmJHbHRhWFJiQjJrQ2dCWnBBZ0FQT2d4eGRXRnNhWFI1YVR3NkMyeHZZV1JsY25zR09nbHdZV2RsTURvTlkyOWhiR1Z6WTJWVSIsImV4cCI6bnVsbCwicHVyIjoidmFyaWF0aW9uIn19--6b62883c9596ea5ec874f8c026d734630c019ca2/3-1-3f.jpeg 3x" decoding="async" loading="lazy">
</a>
  </figure><p>As you can see, Email Services are <em>specifically</em> mentioned because HEY fought this battle once already back in 2020. HEY Calendar is a free companion app to that very same service.</p><p>Itâs even more frustrating because this one-service-many-apps strategy is exactly the same that Apple has taken with iCloud. Thatâs one subscription which is powered by a suite of individual apps. You have Mail, you have Calendar, you have Files. All connect to the same cloud service thatâs billed for once. Just like HEY.</p><p>But Apple has become so emboldened by a decade of free monopoly reign that they donât even feign a superficial adherence to their own rules. They carve out exceptions left and right to mega corporations theyâd rather not anger, then invent entirely new rules that arenât codified anywhere when it suits them, and finally rebuts every demand for consistency and predictability with âjust submit your app and weâll reviewâ. This is intolerable.</p><p>But itâs also highly profitable. Service revenue is the fastest growing part of Appleâs business, and none of that revenue comes easier than taking a 30% cut of the app economy.</p><p>So whatâs going to happen? I donât know, but I do know that weâll keep fighting. Weâre never going to roll over and pay Apple 30% in protection money to be left alone. Last time we found a way, and we will again.</p><p>Hopefully our example, and the countless others weâve seen over the years, will finally force competition authorities around the world to act. We have the Digital Markets Act coming in the EU in just a couple of months. That could very well be a game-changer. So too could the lawsuit by the American Department of Justice that was <a href="https://www.nytimes.com/2024/01/05/technology/antitrust-apple-lawsuit-us.html?smid=tw-nytimes&amp;smtyp=cur">just revealed to be imminent</a> today.&nbsp;</p><p>The last time the DOJ sued Microsoft in the late 90s/early 2000s, it inflicted a serious wound on Redmondâs capacity to capture markets, which gave us the rise of Google, Apple, and others. Hopefully that will happen again and a thousand free-market flowers will bloom once no longer deprived of access to sun, water, and customers.</p><p>One can only dream. But one should also fight. You donât get something for nothing.</p></div>
</div>

    </article>
  </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hard disk LEDs and noisy machines (133 pts)]]></title>
            <link>https://blogsystem5.substack.com/p/hard-disk-leds-and-noisy-machines</link>
            <guid>38883408</guid>
            <pubDate>Fri, 05 Jan 2024 19:19:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blogsystem5.substack.com/p/hard-disk-leds-and-noisy-machines">https://blogsystem5.substack.com/p/hard-disk-leds-and-noisy-machines</a>, See on <a href="https://news.ycombinator.com/item?id=38883408">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>The computers of yesteryear had this little feature known as blinking LED lights ð. They also had this other feature called noisy disks ð¾ and loud fans ðª­. Uh wait. Features? Why âfeaturesâ and not âannoyancesâ?!</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F582ae704-2dd0-4b93-a9ec-5fb42c2ca5bd_396x396.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F582ae704-2dd0-4b93-a9ec-5fb42c2ca5bd_396x396.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F582ae704-2dd0-4b93-a9ec-5fb42c2ca5bd_396x396.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F582ae704-2dd0-4b93-a9ec-5fb42c2ca5bd_396x396.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F582ae704-2dd0-4b93-a9ec-5fb42c2ca5bd_396x396.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F582ae704-2dd0-4b93-a9ec-5fb42c2ca5bd_396x396.jpeg" width="396" height="396" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/582ae704-2dd0-4b93-a9ec-5fb42c2ca5bd_396x396.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;normal&quot;,&quot;height&quot;:396,&quot;width&quot;:396,&quot;resizeWidth&quot;:396,&quot;bytes&quot;:21643,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F582ae704-2dd0-4b93-a9ec-5fb42c2ca5bd_396x396.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F582ae704-2dd0-4b93-a9ec-5fb42c2ca5bd_396x396.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F582ae704-2dd0-4b93-a9ec-5fb42c2ca5bd_396x396.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F582ae704-2dd0-4b93-a9ec-5fb42c2ca5bd_396x396.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>Front panel of a common PC case in the late 1990s. My Pentium MMX 166 was hosted in one of these.</figcaption></figure></div><p>You see, these bright lights and loud noises acted as canaries ð¦ in a performance mine. They gave developers a chance to notice when things were off performance-wise. If your code abused the CPU or the hard disk by mistake, you could tell right away.</p><p>Nowadays, developer machines tend to be quiet under heavy load, and the vast majority of laptops donât even have lights anymore. The obvious example are Macs: they havenât had hard disk LEDs for a really long time, and since the M1, they are silent and cold too.</p><p><span>These characteristics are nice from a usability perspective. Unfortunately, as a developer, you now need to first </span><em>imagine</em><span> that something is wrong before even deciding to look for a problem. If the thought never crosses your mind, then you may never look.</span></p><p>Let me give you a few examples of the kinds of inefficiencies that Iâm talking about. These would have been trivially noticed by the presence of indicators. These are all based on real-world situations I faced at some point in the (recent) past.</p><p><span>ðªµ In a project I worked on, our development builds started writing about 80 MB of log messages </span><em>per second</em><span> to disk. No matter how you look at it, thatâs </span><em>a lot</em><span> of disk traffic, and yetâ¦ the problematic code passed code review and was merged into the main branch.</span></p><p><span>The only indication that something was wrong was when </span><em>other</em><span> developers came asking for help because their local disk space was running out faster than usual. There was no other symptom behind the problem.</span></p><p>Youâd hope that this inefficiency would be caught while qualifying the new release for production because, in theory, such logging waste would translate in an increase in CPU consumption or network bandwidth. Butâ¦ Iâm not so sure the issue would have been noticed.</p><p>ð In another project I worked on, I noticed that Bazel took an incredibly long time to complete some actions. It wasnât until I looked in detail that I saw it stuck in a loop fetching the same remote artifact over and over again due to connection resets.</p><p>The build completed successfully after many minutes once Bazel gave up on the downloads and fell back local execution. There was no reason to suspect that something was wrong other than âthese actions are just hugeâ. In reality, though, there was a bug somewhere.</p><p><span>ð§± Just today, I was in a video call and noticed that my laptop was reading 100MB/s from disk non-stop. I concluded the meeting but the disk reads didnât stop. A quick peek at </span><code>top</code><span> showed something called </span><code>WallpaperVideoExtension</code><span> that seemed to have gone rogue.</span></p><p>This background process was consuming one full CPU, but such load wasnât enough to make the system feel slower nor noisier. I suppose I would eventually have noticed that the battery was running out quicker than usual, but maybe not.</p><p><span>Killing the process made the problem go away and the constant disk reads stopped. Looking online, I find other instances of </span><code>WallpaperVideoExtension</code><span> consuming lots of CPU and memory, so this seems to be a bug. But if itâs common, why wasnât it noticed in the first place?</span></p><p>In any case, this last scenario gives you a hint ð as to where Iâm going: how did I even notice this last problem? After all, my M1 Mac was working just fine: it was just slightly warmer than usual but there was no loud fan noise nor lights to tell me about disk activity.</p><p>The answer is simple: I have an omnipresent performance monitor in my screen that shows CPU load, memory pressure, disk I/O throughput, and network traffic. This monitor is always visible, taking little space in the menu bar or the task bar.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ba9b823-6f31-4f90-ac66-7adbd3d51902_646x1266.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ba9b823-6f31-4f90-ac66-7adbd3d51902_646x1266.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ba9b823-6f31-4f90-ac66-7adbd3d51902_646x1266.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ba9b823-6f31-4f90-ac66-7adbd3d51902_646x1266.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ba9b823-6f31-4f90-ac66-7adbd3d51902_646x1266.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ba9b823-6f31-4f90-ac66-7adbd3d51902_646x1266.png" width="646" height="1266" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7ba9b823-6f31-4f90-ac66-7adbd3d51902_646x1266.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1266,&quot;width&quot;:646,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:387258,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ba9b823-6f31-4f90-ac66-7adbd3d51902_646x1266.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ba9b823-6f31-4f90-ac66-7adbd3d51902_646x1266.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ba9b823-6f31-4f90-ac66-7adbd3d51902_646x1266.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ba9b823-6f31-4f90-ac66-7adbd3d51902_646x1266.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>iStat Menus on the macOS menu bar, with the panel for CPU usage tracking open.</figcaption></figure></div><p>Every time I sense something is a tiny bit off, I glance ð at the monitor. You cannot imagine how many times Iâve gone âhuh, thatâs interestingâ by seeing unexpected activity and then went on to discover big performance problems somewhere in the system.</p><p><span>My recommendation is that you stop what you are doing and go and install such a performance monitor </span><em>right now</em><span>. Iâd even argue that having one always visible should be a hard requirement for any development machine and corp IT departments should preinstall one.</span></p><p><span>Personally, Iâm a huge fan of </span><a href="https://bjango.com/mac/istatmenus/" rel="">iStat Menus</a><span> for macOS and have been using it for years. But if macOS is not your thing, you can find similar tools for other platforms like </span><a href="https://extensions.gnome.org/extension/3010/system-monitor-next/" rel="">system-monitor-next</a><span> for Gnome.</span></p><p>Unfortunately, these monitors only help if you develop on your local machineâa workflow thatâs becoming exceedingly rare. If, instead, you SSH into remote virtual machines to do your development or use VSCodeâs remote features, youâll need a different answer.</p><p>This is a situation I face right now. The modern ThinkStation I have in the garage is well-equipped with useful lightsâ¦ but I only access it over SSH for development so those lights and its disk noises are kinda useless from where I sit.</p><p><span>And Iâm not sure what the right answer here is. If you have been around for a while, you may remember </span><a href="http://gkrellm.srcbox.net/" rel="">GKrellM</a><span>, which I was an avid user of. This system monitor had the ability to display </span><em>remote</em><span> machine activity and Iâd love to have that again.</span></p><p><span>(</span><a href="https://twitter.com/jmmv/status/1735712759604711494" rel="">You can read the original of this text in its Twitter thread form.</a><span>)</span></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. moves closer to filing antitrust case against Apple (245 pts)]]></title>
            <link>https://www.nytimes.com/2024/01/05/technology/antitrust-apple-lawsuit-us.html</link>
            <guid>38883393</guid>
            <pubDate>Fri, 05 Jan 2024 19:18:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/01/05/technology/antitrust-apple-lawsuit-us.html">https://www.nytimes.com/2024/01/05/technology/antitrust-apple-lawsuit-us.html</a>, See on <a href="https://news.ycombinator.com/item?id=38883393">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/01/05/technology/antitrust-apple-lawsuit-us.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[In Europe, Trains Are Full, and More Are on the Way (131 pts)]]></title>
            <link>https://www.nytimes.com/2024/01/04/travel/europe-new-trains.html</link>
            <guid>38883213</guid>
            <pubDate>Fri, 05 Jan 2024 19:05:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/01/04/travel/europe-new-trains.html">https://www.nytimes.com/2024/01/04/travel/europe-new-trains.html</a>, See on <a href="https://news.ycombinator.com/item?id=38883213">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/01/04/travel/europe-new-trains.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[A rocket a day keeps the high costs away (1993) (105 pts)]]></title>
            <link>https://www.fourmilab.ch/documents/aRocketAday.txt</link>
            <guid>38882790</guid>
            <pubDate>Fri, 05 Jan 2024 18:38:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fourmilab.ch/documents/aRocketAday.txt">https://www.fourmilab.ch/documents/aRocketAday.txt</a>, See on <a href="https://news.ycombinator.com/item?id=38882790">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[How to build a thinking AI (104 pts)]]></title>
            <link>https://aithought.com/</link>
            <guid>38882747</guid>
            <pubDate>Fri, 05 Jan 2024 18:35:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aithought.com/">https://aithought.com/</a>, See on <a href="https://news.ycombinator.com/item?id=38882747">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<h4><strong>Thought is Structured by the Iterative Updating of Working Memory</strong>: </h4>







<h5>I<strong>MPLEMENTING THIS IN A MACHINE COULD ENABLE ARTIFICIAL GENERAL INTELLIGENCE</strong></h5>











<p><strong>Jared Edward Reser&nbsp;Ph.D., M.A., M.A.</strong><br></p>



<p><em><strong>Note:</strong> For readers with time constraints, a concise understanding of the core content can be attained in around ten minutes by examining the figures and accompanying captions.</em></p>



<p>.</p>



<figure data-wp-context="{  &quot;imageLoaded&quot;: false,
				&quot;initialized&quot;: false,
				&quot;lightboxEnabled&quot;: false,
				&quot;hideAnimationEnabled&quot;: false,
				&quot;preloadInitialized&quot;: false,
				&quot;lightboxAnimation&quot;: &quot;zoom&quot;,
				&quot;imageUploadedSrc&quot;: &quot;https://aithoughtcom.files.wordpress.com/2023/10/website-banner2-1.jpg&quot;,
				&quot;imageCurrentSrc&quot;: &quot;&quot;,
				&quot;targetWidth&quot;: &quot;4581&quot;,
				&quot;targetHeight&quot;: &quot;1968&quot;,
				&quot;scaleAttr&quot;: &quot;&quot;,
				&quot;dialogLabel&quot;: &quot;Enlarged image&quot;
			}" data-wp-interactive="{&quot;namespace&quot;:&quot;core/image&quot;}"><img data-attachment-id="435" data-permalink="https://aithought.com/blog/assembly-vs-ensemble-2/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/10/website-banner2-1.jpg" data-orig-size="4581,1968" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Assembly vs Ensemble&quot;,&quot;created_timestamp&quot;:&quot;1697720928&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;Assembly vs Ensemble&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Assembly vs Ensemble" data-image-description="" data-image-caption="<p>Assembly vs Ensemble</p>
" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/10/website-banner2-1.jpg?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/10/website-banner2-1.jpg?w=1024" width="4581" height="1968" data-wp-init="callbacks.initOriginImage" data-wp-on--click="actions.showLightbox" data-wp-on--load="actions.handleLoad" data-wp-watch--setstylesonresize="callbacks.setStylesOnResize" data-wp-watch="callbacks.setButtonStyles" src="https://aithoughtcom.files.wordpress.com/2023/10/website-banner2-1.jpg" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/10/website-banner2-1.jpg 4581w, https://aithoughtcom.files.wordpress.com/2023/10/website-banner2-1.jpg?w=150&amp;h=64 150w, https://aithoughtcom.files.wordpress.com/2023/10/website-banner2-1.jpg?w=300&amp;h=129 300w, https://aithoughtcom.files.wordpress.com/2023/10/website-banner2-1.jpg?w=768&amp;h=330 768w, https://aithoughtcom.files.wordpress.com/2023/10/website-banner2-1.jpg?w=1024&amp;h=440 1024w" sizes="(max-width: 4581px) 100vw, 4581px">        <div aria-label="" aria-modal="" role="" data-wp-body="" data-wp-bind--role="state.roleAttribute" data-wp-bind--aria-label="state.dialogLabel" data-wp-class--initialized="context.initialized" data-wp-class--active="context.lightboxEnabled" data-wp-class--hideanimationenabled="context.hideAnimationEnabled" data-wp-bind--aria-modal="state.ariaModal" data-wp-watch="callbacks.initLightbox" data-wp-on--keydown="actions.handleKeydown" data-wp-on--touchstart="actions.handleTouchStart" data-wp-on--touchmove="actions.handleTouchMove" data-wp-on--touchend="actions.handleTouchEnd" data-wp-on--click="actions.hideLightbox" tabindex="-1">
                <div>
<figure><img data-attachment-id="435" data-permalink="https://aithought.com/blog/assembly-vs-ensemble-2/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/10/website-banner2-1.jpg" data-orig-size="4581,1968" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Assembly vs Ensemble&quot;,&quot;created_timestamp&quot;:&quot;1697720928&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;Assembly vs Ensemble&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Assembly vs Ensemble" data-image-description="" data-image-caption="<p>Assembly vs Ensemble</p>
" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/10/website-banner2-1.jpg?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/10/website-banner2-1.jpg?w=1024" data-wp-bind--src="context.imageCurrentSrc" data-wp-style--object-fit="state.lightboxObjectFit" src="https://aithoughtcom.files.wordpress.com/2023/10/website-banner2-1.jpg?w=1024" alt=""></figure>
</div>
                <div>
<figure><img data-attachment-id="435" data-permalink="https://aithought.com/blog/assembly-vs-ensemble-2/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/10/website-banner2-1.jpg" data-orig-size="4581,1968" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Assembly vs Ensemble&quot;,&quot;created_timestamp&quot;:&quot;1697720928&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;Assembly vs Ensemble&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Assembly vs Ensemble" data-image-description="" data-image-caption="<p>Assembly vs Ensemble</p>
" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/10/website-banner2-1.jpg?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/10/website-banner2-1.jpg?w=1024" data-wp-bind--src="state.enlargedImgSrc" data-wp-style--object-fit="state.lightboxObjectFit" src="https://aithoughtcom.files.wordpress.com/2023/10/website-banner2-1.jpg?w=1024" alt=""></figure>
</div>
                
        </div></figure>



<p>.</p>



<p><strong>Abstract</strong></p>



<p>This article provides an analytical framework for how to simulate human-like thought processes within a computer. It describes how attention and memory should be structured, updated, and utilized to search for associative additions to the stream of thought. The focus is on replicating the dynamics of the mammalian working memory system, which features two forms of persistent activity: sustained firing (preserving information on the order of seconds) and synaptic potentiation (preserving information from minutes to hours). The article uses a series of over 40 original figures to systematically demonstrate how the iterative updating of these working memory stores provides functional structure to behavior, cognition, and consciousness.&nbsp;&nbsp;</p>



<p>In an AI implementation, these two memory stores should be updated continuously and in an iterative fashion, meaning each state should preserve a proportion of the coactive representations from the state before it. Thus, the set of concepts in working memory will evolve gradually and incrementally over time. This makes each state a revised iteration of the preceding state and causes successive states to overlap and blend with respect to the information they contain. Transitions between states happen as persistent activity spreads activation energy throughout the hierarchical network searching long-term memory for the most appropriate representation to be added to the global workspace. The result is a chain of associatively linked intermediate states capable of advancing toward a solution or goal. Iterative updating is conceptualized here as an information processing strategy, a model of working memory, a theory of consciousness, and an algorithm for designing and programming artificial general intelligence.</p>







<p><strong>Keywords</strong></p>



<p>artificial intelligence, artificial general intelligence, attention, consciousness, focus of attention, information processing, machine consciousness, neural assembly, neural network, recurrent systems, short-term memory, synaptic potentiation, systems neuroscience, superintelligence, working memory</p>







<figure></figure>







<figure></figure>







<h5><strong>Table of Contents:</strong></h5>



<p><strong>Abstract</strong></p>



<p><strong><u><a href="#introduction">Part I: Introduction</a></u></strong></p>



<p>1.1 Machine Superintelligence Requires a Thought Process</p>



<p>1.2 Iteration Defines the Workflow of Thought</p>



<p><strong><u><a href="#literature-review">Part II: Literature Review</a></u></strong></p>



<p>2.1 Interactions Between Sensory Memory, Working Memory, and Long-term Memory</p>



<p>2.2 The Focus of Attention Is Embedded within the Short-term Memory Store</p>



<p>2.3 Sustained Firing Maintains Information in the Focus of Attention</p>



<p>2.4 Synaptic Potentiation Maintains Information in the Short-term Store</p>



<p><strong><u><a href="#part3">Part III: Working Memory is Updated Iteratively</a></u></strong></p>



<p>3.1 Persistent Activity Causes Successive States to Overlap Iteratively</p>



<p>3.2 The Iterative Updating of Representations Allows Context to Shift</p>



<p>3.3 The Rate of Iterative Updating Varies with Demand</p>



<p>3.4 Iterative Updating Gives Rise to Mental Continuity</p>



<p><strong><u><a href="#part4">Part IV: Implications of the Model</a></u></strong></p>



<p>4.1 Iterative Updating Provides Structure to Associative Search</p>



<p>4.2 Multiassociative Search Spreads the Combined Activation Energy of Multiple Items</p>



<p>4.3 States Updated by the Products of Search Are Predictions</p>



<p>4.4 Iterative Updating Allows Progressive Changes to the Contents of Thought</p>



<p>4.5 Testing the Neurophysiological Validity of the Model</p>



<p><strong><u><a href="#part5">Part IV: Instantiating the Model Within a Computer</a></u></strong></p>



<p>5.1 AI Should Employ Iterative Updating</p>



<p>5.2 Designing an AI Capable of Iterative Updating</p>



<p>5.3 Modularity, Modality, and Imagery in AI</p>



<p>5.4 How to Train an AI that Employs Iterative Updating</p>



<p>5.5 Discussion and Conclusions</p>



<p><strong>References</strong></p>



<p>.</p>



<p id="introduction"><strong><u>Part I:</u></strong><span> Introduction</span></p>



<p id="1.1"><strong>1.1. <strong>Machine Superintelligence Requires a Thought Process</strong></strong></p>



<p>.</p>



<blockquote>
<p>âIt seems that the human mind has first to construct forms independently before we can find them in thingsâ¦ Knowledge cannot spring from experience alone, but only from a comparison of the inventions of the intellect with observed fact.â</p>



<p>Albert Einstein (1949)</p>
</blockquote>



<p>The above quote from Einstein suggests that for artificial intelligence (AI) to make sense of the world, it must go beyond training on data and think for itself. Incremental improvements to existing machine learning architectures will not yield knowledge creation or real understanding because they do not attempt to simulate thought or its reflective, analytical, or deliberative qualities. Although current artificial neural networks use various brain-inspired techniques such as attention, they do not use working memory the way mammals do. To do so would involve constructing a stream of thought by holding a set of representations coactive and continuously updating this set with the most pertinent associations. This results in an iterative system that embeds mental states within the states that came before them. Such a system would generate and refine knowledge by constantly comparing and contextualizing information.</p>



<p>The present article identifies the elements of mammalian working memory that make this iterative process possible and describes how to organize them within a computer using contemporary machine-learning technology. It also introduces several novel concepts, terms (Table 4), and illustrations (Figures 1-47) to explain how an iterative cognitive cycle will permit a computer program to make the state-space transitions necessary to achieve general intellectual faculties. By simulating ongoing, self-directed, open-ended thought, as described here, an artificial agent could construct its own predictions and associations, simulate hypothetical situations, synthesize novel ideas, and thereby further scientific and technological progress. Table 1 outlines some of the categorical traits of this model.</p>



<figure><img data-attachment-id="674" data-permalink="https://aithought.com/blog/screenshot-87/" data-orig-file="https://aithoughtcom.files.wordpress.com/2024/01/screenshot-87.png" data-orig-size="1902,1090" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-87" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2024/01/screenshot-87.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2024/01/screenshot-87.png?w=1024" loading="lazy" width="1024" height="586" src="https://aithoughtcom.files.wordpress.com/2024/01/screenshot-87.png?w=1024" alt="" srcset="https://aithoughtcom.files.wordpress.com/2024/01/screenshot-87.png?w=1024 1024w, https://aithoughtcom.files.wordpress.com/2024/01/screenshot-87.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2024/01/screenshot-87.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2024/01/screenshot-87.png?w=768 768w, https://aithoughtcom.files.wordpress.com/2024/01/screenshot-87.png 1902w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<p><strong>Table 1.</strong> Comparative Overview of Features of an AI Based on the Iterative Updating Model</p>



<p><em>This table provides context by summarizing some of the general characteristics of an intelligent system built in accordance with the architecture discussed here.</em></p>



<p id="1.2"><strong>1.2 Iteration Defines the Workflow of Thought </strong></p>



<p>AI research has yet to formalize and simulate the thinking process because psychology and neuroscience have completely ignored the crucial role of iteration. No contemporary models address iterative change in the contents of working memory. In many discussions, updating of the information held in working memory is considered to be complete rather than partial, meaning that after being updated, the contents from the previous state are entirely replaced (e.g., Pina et al., 2018; Niklaus et al., 2019). In other discussions, information can be updated without complete replacement, but only such as when working memory holds three words and then accommodates a fourth in addition to the first three (e.g., Miller et al., 2018; Manohar et al., 2019). These views compartmentalize the thinking process, isolating current states from what came before them.</p>



<p>In contrast, the account presented here explores the hypothesis that partial updating occurs continuously. As representations are added, others are subtracted, and others from the previous state remain due to persistent neural activity (Figure 1). This cascading persistence allows successive states to share a proportion of their content in common, creating complex causal relationships between them (Reser, 2011, 2012). This iterative perspective may be useful because it illuminates how the gradually transforming collection of representations in working memory allows the thinking process to progress as updated states elaborate intelligently on the states that came before them (Reser, 2013, 2016, 2022).</p>







<figure><img data-attachment-id="571" data-permalink="https://aithought.com/blog/image-29/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/12/image.png" data-orig-size="975,265" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/12/image.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/12/image.png?w=975" loading="lazy" width="975" height="265" src="https://aithoughtcom.files.wordpress.com/2023/12/image.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/12/image.png 975w, https://aithoughtcom.files.wordpress.com/2023/12/image.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/12/image.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/12/image.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 1.</strong> Two Types of Working Memory Updating Compared</p>



<p><em>Each row contains five rectangles labeled time one (t1) through time five (t5). Each rectangle corresponds to a state of working memory holding three items. In the top row, successive rectangles do not hold any of the same items, indicating complete updating. In the second row, two items are shared between successive rectangles, indicating partial updating. This article contends that the iterative nature exhibited by the second row is a fundamental attribute of the thinking process.</em></p>



<p>A familiar example of the concept of iteration is âiterative design.â It is a method of developing commercial products through a cyclic process of prototyping, testing, and improving. With this method, designs are assessed through user feedback and enhanced in an incremental fashion. Think of the installment histories of a popular product such as a cell phone, operating system, or car. The newest version of the product contains novel features but preserves many aspects of the previous version and even of versions before that. The workflow of human thought is interpreted here in a similar way (Figure 2). As mental representations in working memory are updated, the frame of reference is gradually replaced, and a thought about one scenario incrementally transitions into a thought about a related scenario. The result is a series of intermediate states capable of exploring a problem space and deriving a solution. This article will explore how this general process contributes to reasoning, mental modeling, executive processes, and consciousness.</p>







<figure><img data-attachment-id="46" data-permalink="https://aithought.com/iterative-updating-of-active-information-in-the-brain-1/" data-orig-file="https://aithoughtcom.files.wordpress.com/2022/03/iterative-updating-of-active-information-in-the-brain-1.jpg" data-orig-size="1106,639" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="iterative-updating-of-active-information-in-the-brain-1" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2022/03/iterative-updating-of-active-information-in-the-brain-1.jpg?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2022/03/iterative-updating-of-active-information-in-the-brain-1.jpg?w=1024" loading="lazy" width="1024" height="591" src="https://aithoughtcom.files.wordpress.com/2022/03/iterative-updating-of-active-information-in-the-brain-1.jpg?w=1024" alt="" srcset="https://aithoughtcom.files.wordpress.com/2022/03/iterative-updating-of-active-information-in-the-brain-1.jpg?w=1024 1024w, https://aithoughtcom.files.wordpress.com/2022/03/iterative-updating-of-active-information-in-the-brain-1.jpg?w=150 150w, https://aithoughtcom.files.wordpress.com/2022/03/iterative-updating-of-active-information-in-the-brain-1.jpg?w=300 300w, https://aithoughtcom.files.wordpress.com/2022/03/iterative-updating-of-active-information-in-the-brain-1.jpg?w=768 768w, https://aithoughtcom.files.wordpress.com/2022/03/iterative-updating-of-active-information-in-the-brain-1.jpg 1106w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p><strong>Fig. 2.</strong> Flowchart of Iterative Updating</p>



<p><em>In an iterative process, a set of components is modified repetitively to generate a series of updated states. Each state is an iteration as well as the starting point for the next iteration. One way to accomplish iterative modification is to alter a given state by retaining pertinent elements and then subtracting and adding others. In the brain, the content to be added and subtracted is determined by spreading activation.</em></p>



<p>This abstract, high-level model also offers an explanation for how the next iterative update to working memory is selected. The firing neurons that underlie the representations in working memory spread their combined excitatory and inhibitory effects to other cells throughout the cortex. Thus, the coactivation of the contents of working memory amounts to an associative search of long-term memory for applicable information (e.g., predictions, probabilities, and motor instructions). The nonactive (baseline) cells that receive the most spreading activation become active and comprise the representation(s) that will update working memory. Similarly, the representations that continue to receive activation energy are maintained in working memory. In contrast, those that receive reduced energy are subtracted from it. Performing search using a modified version of the previous search, and doing so repeatedly, amounts to a compounded form of search that ultimately enables the compounding of predictions and inferences.</p>



<p>Again, newly activated representations are added to the representations that have remained in working memory from the previous state. This updated set is used to conduct the next search. This cycle is then repeated in a loop to produce the thinking process. Thus, there is a direct structural correspondence between the turnover of persistent neural activity, the gradual updating of working memory, and the continuity of the stream of thought. Many of the major features of thought derived from introspection (Hamilton, 1860; Weger et al., 2018) are addressed by this hypothetical explanation, such as how mental context is conserved from one thought to the next, how one thought is associated with the next, and how it logically (or probabilistically) implies the next.</p>



<p>This article focuses on ongoing, internally generated activity within working memory and the emergent iterative pattern of information flow. This pattern, introduced in Figure 2, is elaborated on methodically through a series of over 40 figures that attempt to illustrate the âshapeâ of the thought process. Topics considered include the neural basis of items in working memory, variation in the rate of updating, interactions between multiple working memory stores, and how all of this can be implemented within neural network models to enhance the performance of AI. This work builds on these issues while assimilating current theoretical approaches and remaining consistent with prevailing knowledge. Part 2 reviews pertinent literature that forms the foundation of the iterative updating model. Parts 3 and 4 develop said model, and Part 5 applies it to AI.</p>



<p id="literature-review"><strong><u>Part II:</u></strong><span> Literature Review</span></p>



<p id="2.1"><strong>2.1 Interactions Between Sensory Memory, Working Memory, and Long-term Memory</strong></p>



<p>Working memory has been defined as the components of the mind that temporarily hold a limited amount of information in a heightened state of availability for use in ongoing information processing (Cowan, 2016). It involves holding ephemeral sensory and semantic information (e.g., objects, shapes, colors, locations, movement patterns, symbols, rules, concepts, numbers, and words) in attention until they are needed to execute an action or decision. It is one of multiple phases of memory and has been variously referred to as immediate memory and primary memory. It was conceptualized by William James (1842-1910) as the âtrailing edge of the conscious presentâ and a major determinant of which portions of new information will be perceived and which of those will be analyzed (James, 1890). Working memory is thought to facilitate various operations, such as planning, language comprehension, reasoning, decision making, and problem solving (Baddeley, 2012).</p>



<p>The working memory store is constantly updated with new items, which then fade over the course of seconds or minutes (some more quickly than others). Updating allocates processing resources to important information coming from the senses (e.g., novelties, needs, or threats) or from internal states (e.g., intentions, plans, or schemas). Most mental functions require the active maintenance of multiple items at once, along with systematic updating of these items (Baddeley, 2012). Active updating is necessary because the importance of individual items changes as processing demands change (Myers et al., 2017).</p>



<p>Research on working memory has traditionally relied on behavioral investigations (such as memory tasks) to study interactions and dissociations between memory systems. Experimental studies on the topic are concerned with capacity limits, rehearsal, interference, suppression of irrelevant information, removal of unnecessary information, and other regular phenomena. Theorists have tried to capture these regularities using abstract models.</p>



<p>From the late 1950s to the 1960s, memory researchers (e.g., Atkinson &amp; Shiffrin, 1968; Broadbent, 1958) developed models that conceptualized memory as being comprised of three interacting systems: (1) a sensory store that briefly holds and preprocesses sensory inputs, (2) an active short-term system capable of attending to this information over a time frame of seconds, and (3) a passive long-term system capable of maintaining information indefinitely (Fig. 3). Current models (including the present work) have retained many of these aspects.</p>







<figure><img data-attachment-id="456" data-permalink="https://aithought.com/blog/image-1-6/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/11/image-1.png" data-orig-size="975,315" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-1" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/11/image-1.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/11/image-1.png?w=975" loading="lazy" width="975" height="315" src="https://aithoughtcom.files.wordpress.com/2023/11/image-1.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/11/image-1.png 975w, https://aithoughtcom.files.wordpress.com/2023/11/image-1.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/11/image-1.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/11/image-1.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>







<p><strong>Fig. 3.</strong> Atkinson and Shiffrinâs Multi-store Model (1968)</p>



<p><em>This model depicts environmental stimuli received by the senses and held in sensory memory. If attended to, this stimulus information will enter short-term memory (i.e., working memory, shown in gray). If not rehearsed, it will be forgotten; if rehearsed, it will remain in short-term memory; and if sufficiently elaborated upon, it will be stored in long-term memory (shown in black), from which it can be retrieved later. Long-term memory is depicted in black here and throughout this article.</em></p>



<p>The multi-store model has been expanded upon in several pivotal ways. Studies performed by Alan Baddeley and Graham Hitch (1974, 1986) using dual-task interference experiments indicated that the capacity limitations for visual and verbal working memory are independent, leading the authors to categorize these two modalities as separable. This distinction led to the authorsâ influential multicomponent model, which divided working memory into two domain-specific stores: the visuospatial sketchpad and the phonological buffer (Fig. 4). These stores work in concert to construct, sustain, and modify mental imagery.</p>



<p>Baddeley and Hitch also envisioned a dedicated supervisory subsystem, which they named the âcentral executive,â that selected items for activity, shuttled information from one store to another, and made other processing decisions. Because researchers have not yet explicitly determined how the central executive, visuospatial sketchpad, and phonological buffer cooperate, they remain areas of active research and theoretical inquiry.</p>







<figure><img data-attachment-id="458" data-permalink="https://aithought.com/blog/image-2-4/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/11/image-2.png" data-orig-size="975,481" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-2" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/11/image-2.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/11/image-2.png?w=975" loading="lazy" width="975" height="481" src="https://aithoughtcom.files.wordpress.com/2023/11/image-2.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/11/image-2.png 975w, https://aithoughtcom.files.wordpress.com/2023/11/image-2.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/11/image-2.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/11/image-2.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 4.</strong> Baddeley and Hitchâs Multicomponent Model (1974)</p>



<p><em>In this model, the short-term store from Atkinson and Shiffrinâs model is split into four interacting components that together constitute working memory: the visuospatial sketchpad, the phonological buffer, the central executive, and the episodic buffer, which was added later (Baddeley, 2000). These components interact with long-term memory, represented by the bottom rectangle.</em></p>



<p>Bernard Baars developed the functional framework model, which combines the multi-store model (Fig.3) with the multicomponent model (Fig. 4) (Baars, 2007). This framework, adapted in Figure 5, integrates other cognitive constructs such as attention, consciousness, and planning. It also draws further subdivisions within long-term memory.</p>







<figure><img data-attachment-id="459" data-permalink="https://aithought.com/blog/image-3-4/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/11/image-3.png" data-orig-size="975,501" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-3" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/11/image-3.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/11/image-3.png?w=975" loading="lazy" width="975" height="501" src="https://aithoughtcom.files.wordpress.com/2023/11/image-3.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/11/image-3.png 975w, https://aithoughtcom.files.wordpress.com/2023/11/image-3.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/11/image-3.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/11/image-3.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 5.</strong> Baars and Gageâs Functional Framework (2007)</p>



<p><em>This model incorporates the multi-store model with the multicomponent model. Working memory activates long-term memories, knowledge, and skills, which are shown in the box at the bottom. Spontaneous (bottom-up) attention and voluntary (top-down) attention are symbolized as vectors.</em></p>



<p>In 1988, Bernard Baars introduced the global workspace model (Fig. 6). Therein, active contents in working memory are broadcast throughout the brain, stimulating unconscious long-term memories. These long-term memories then compete to enter the global workspace. This type of organization is known as a âblackboardâ architecture and can be traced back to Newel and Simon (1961). Many present-day computer science, neural, and psychological models assume a fleeting but centralized working memory capacity that acts as a common workspace where long-term memories become coactive and are exposed to one another (e.g., Dehaene, 2020; Ryan et al., 2019; Glushchenko et al., 2018).</p>







<figure><img data-attachment-id="461" data-permalink="https://aithought.com/blog/image-4-4/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/11/image-4.png" data-orig-size="725,540" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-4" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/11/image-4.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/11/image-4.png?w=725" loading="lazy" width="725" height="540" src="https://aithoughtcom.files.wordpress.com/2023/11/image-4.png?w=725" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/11/image-4.png 725w, https://aithoughtcom.files.wordpress.com/2023/11/image-4.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/11/image-4.png?w=300 300w" sizes="(max-width: 725px) 100vw, 725px"></figure>



<p><strong>Fig. 6.</strong> Baarâs Global Workspace Model (1988)</p>



<p><em>The brain has several lower order modules that are generally isolated from each other. Unconscious processes and environmental stimuli processed by these modules compete for access to the global workspace. The most salient inputs enter the workspace where they are integrated, stored temporarily, and made conscious. These results are then broadcast back to the rest of the brain.</em></p>



<p id="2.2"><strong>2.2 The Focus of Attention Is Embedded within the Short-term Memory Store</strong></p>



<p>Early models attempting to explain how long-term memory is transferred into working memory were influenced by computer science. They envisioned long-term memories being copied and transferred from long-term storage to a separate processing substrate (i.e., from the hard drive to random-access memory (RAM) to the central processing unit (CPU)). In a departure from this conception, several theorists (e.g., Cowan, 1984; Norman, 1968; Treisman, 1964) conceived that information is encoded into working memory when existing units of long-term memory are activated and attended to without being copied or transported. Today, this is commonly referred to as activated long-term memory.</p>



<p>Brain imaging studies support this view and provide evidence that units of long-term memory reside in the exact locations involved in processing this information during non-working memory scenarios (DâEsposito &amp; Postle, 2015). These findings suggest that information is not copied and transferred between dedicated registers, but activated right where it is (in situ) (Chein &amp; Fiez, 2010; Moscovitch et al., 2007). The concept may apply equally to artificial neural networks. Thus, although neurons are stationary, as long as they remain active, they continue to broadcast their encoded information to the neurons they project to.</p>



<p>Nelson Cowanâs embedded processes model (1988) reconciles the main features of the multi-store and multicomponent models with the concept of activated long-term memory. In Cowanâs model, the short-term memory store is comprised of units of long-term memory that are activated above baseline levels, such as memories that have been primed. This activation can last from seconds to hours. Thus, the short-term store of working memory is simply an active subset of the long-term store it is âembeddedâ within (Cowan, 1999).</p>



<p>The other key component of Cowanâs model is the focus of attention (FoA). The FoA holds consciously attended units of information and is embedded within the short-term store (Fig. 7). Units in the FoA comprise an even more active subset of the short-term store. Their elevated activity lasts from milliseconds to several seconds. Cowan and others consider the short-term store and the FoA together as constituting working memory (Cowan, 2005).</p>







<figure><img data-attachment-id="573" data-permalink="https://aithought.com/blog/image-1-7/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/12/image-1.png" data-orig-size="975,405" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-1" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/12/image-1.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/12/image-1.png?w=975" loading="lazy" width="975" height="405" src="https://aithoughtcom.files.wordpress.com/2023/12/image-1.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/12/image-1.png 975w, https://aithoughtcom.files.wordpress.com/2023/12/image-1.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/12/image-1.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/12/image-1.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 7.</strong> Cowanâs Embedded Processes Model (1988)</p>



<p><em>According to this model, short-term storage is an activated subset of long-term storage. Similarly, the focus of attention (FoA) is an attended subset of short-term storage. These stores interact with a store for sensory memory and a central executive.</em></p>



<p>During perception, task-relevant features from the sensory store are used to update the FoA. When attention shifts to other information, these items pass into the short-term store (Nyberg &amp; Eriksson, 2016). However, information demoted from the FoA to the short-term store can still influence automatic actions and be readily reactivated into the FoA (Manohar et al., 2019). If not reactivated, this information returns to inert long-term memory (through the processes of decay, inhibition, interference, or contamination) (Cowan, 2009). Some items that enter working memory are demoted almost immediately, whereas others remain active for sustained periods (Cowan, 2011). This feature, along with features of the other models discussed thus far, forms critical assumptions about updating subsumed by the present model. Figure 8 provides a summary of the forms of human memory.</p>







<figure><img data-attachment-id="574" data-permalink="https://aithought.com/blog/image-2-5/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/12/image-2.png" data-orig-size="975,611" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-2" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/12/image-2.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/12/image-2.png?w=975" loading="lazy" width="975" height="611" src="https://aithoughtcom.files.wordpress.com/2023/12/image-2.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/12/image-2.png 975w, https://aithoughtcom.files.wordpress.com/2023/12/image-2.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/12/image-2.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/12/image-2.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 8.</strong> Forms of Human Memory</p>



<p><em>Human memory can be divided into three phases, each of which can be decomposed into other forms.</em></p>



<p id="2.3"><strong>2.3 Sustained Firing Maintains Information in the Focus of Attention</strong></p>



<p>Understanding how the brain provides for working memory should be paramount when designing working memory for computers. The neurophysiological basis of the persistent activity responsible for working memory is an active research area. Single-cell recordings of neurons in primates reveal that information retention occurs via a cellular phenomenon known as sustained firing. Glutamatergic pyramidal neurons in the prefrontal cortex (PFC), parietal cortex, and other association cortices are specialized for sustained activity, allowing the cells to generate action potentials at elevated rates for several seconds at a time (Funahashi, 2007; Fuster, 2015). Sustained firing is thought to maintain the signal of information that the neuron encodes. A neuron in the PFC with a background firing rate of 10 Hz (typical for cortical cells) might increase its firing rate to 20 Hz when utilizing sustained firing to preserve mnemonic information temporarily.</p>



<p>One of the earliest of these studies provides an illustrative example. In 1973, Joaquin Fuster recorded the sustained electrical activity of PFC neurons in monkeys performing a delayed matching task. In the task, a macaque monkey watches the experimenter place food under one of two identical cups. A shutter is then lowered for a variable delay period, so the cups are not visible. After the delay, the shutter is raised, and the monkey is given one attempt to collect the food. Through training, the animal learns to choose the correct cup on the first attempt. Completing the task requires the animal to hold the location of the food in working memory during the delay period. Presumably, the monkey must sustain either a retrospective sensory representation of the foodâs location or a prospective representation of the motor plan needed to retrieve it.</p>



<p>Using implanted electrodes, Fuster could record from neurons in the PFC that fired throughout the delay period. He found that the sustained firing subsided once the monkey responded, suggesting that the observed neuronal activity represented the foodâs location while the cup was out of sight. This landmark study revealed the brainâs mechanism for keeping meaningful representations active without external input. It also suggested the presence of a dynamically updated pool of coactive neurons underlying thought and behavior. It is important to mention that processes besides sustained firing may be responsible for maintenance in the FoA (e.g., dynamic coding or activity states distributed across neuronal populations (Stokes, 2015; Jacob et al., 2018), yet iterative updating could apply to these as well.</p>



<p>Subsequent research has found that the duration of sustained firing predicts whether items will be remembered. When this delay-period activity is weak, the likelihood of forgetting is greater (Funahashi et al., 1993). Moreover, lesioning of the prefrontal and association cortices (which contain neurons with the greatest capacity for sustained firing) significantly impairs performance in these tasks. Consistent with this animal work, functional magnetic resonance imaging (fMRI) studies in humans show that activity in prefrontal and association areas persists during the delay period of similar working memory tasks. In fact, the magnitude of this activation positively correlates with the number of items subjects are instructed to hold in memory (Rypma et al., 2002).</p>



<p>Patricia Goldman-Rakic (1987, 1990, 1995) was the first to suggest that the phenomenon of sustained firing in the PFC is responsible for the retention interval exhibited by working memory. Further work by Fuster (2009), Goldman-Rakic (1995), and others has shown that neuronal microcircuits within the PFC maintain information in working memory via recurrent, excitatory glutamatergic networks of pyramidal cells (Baddeley &amp; Hitch, 1994; Miller &amp; Cohen, 2001). Many researchers now believe that sustained firing is critical in maintaining working memory. The evidence backing this assumption is provided by studies reporting positive correlations between sustained firing and working memory performance. For example, both human and animal subjects can retain information in mind as long as sustained firing persists (Rypma et al., 2002). This has been found using extracellular, electroencephalographic, and hemodynamic approaches (DâEsposito &amp; Postle, 2015).</p>



<p>Sustained firing in the PFC and parietal cortex is now assumed to underlie the capacity to internally maintain and update the contents of the FoA (Braver &amp; Cohen, 2000; Sarter et al., 2001). As a result, working memory, executive processing, and cognitive control are now widely thought to rely on the maintenance of activity in multimodal association areas that correspond to goal-relevant features and patterns (Baddeley, 2007; Fuster, 2002a; Moscovich, 1992; Postle, 2007). Sustained rates of action potentials allow responses throughout the brain to be modulated by prior history over multiple timescales, from milliseconds to tens of seconds.</p>



<p id="2.4"><strong>2.4 Synaptic Potentiation Maintains Information in the Short-term Store</strong></p>



<p>fMRI studies have suggested that the information represented by sustained firing corresponds only to the FoA, not the short-term store as a whole (Lewis-Peacock et al., 2012). This is because neuronal activity corresponding to items that have exited the FoA quickly drops to baseline firing rates. Nevertheless, information about the items may be rapidly and reliably recalled after a brief delay. It is thought that the passive retention of information in the short-term store but outside the FoA may be mediated by a different âactivity-silentâ neural mechanism, such as changes in synaptic potentiation (short-term synaptic plasticity) (LaRocque et al., 2014; Rose, 2016). The evidence supporting this is strong (Silvanto, 2017; Nairne, 2002). For example, synaptic strength can be temporarily modified by transient increases in the concentration of presynaptic calcium ions or by GluR1-dependent short-term potentiation (Silvanto, 2017). The information potentiated by these changes in synaptic weighting can be converted back into active neural firing if the memory is reactivated by a contextual retrieval cue (Nairne, 2002).</p>



<p>Thus, the maintenance of information in working memory is achieved by at least two neural phenomena operating in parallel that correspond to distinct states of prioritization: sustained firing, which maintains information in the FoA, and synaptic potentiation, which maintains information in the short-term store. Both mechanisms contribute to the initialization of long-term potentiation, including RNA synthesis, protein synthesis, and morphological synaptic changes that underlie the formation and consolidation of new long-term memories (Debanne, 2019). Table 2 summarizes the general properties of the four phases of human memory.</p>







<figure><img data-attachment-id="577" data-permalink="https://aithought.com/blog/screenshot-2/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/12/screenshot-2.png" data-orig-size="1117,722" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/12/screenshot-2.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/12/screenshot-2.png?w=1024" loading="lazy" width="1024" height="661" src="https://aithoughtcom.files.wordpress.com/2023/12/screenshot-2.png?w=1024" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/12/screenshot-2.png?w=1024 1024w, https://aithoughtcom.files.wordpress.com/2023/12/screenshot-2.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/12/screenshot-2.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/12/screenshot-2.png?w=768 768w, https://aithoughtcom.files.wordpress.com/2023/12/screenshot-2.png 1117w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p><strong>Table 2.</strong> General Characteristics of Four Forms of Memory</p>



<p><em>This table summarizes some of the major comparisons between four different forms of memory. The details addressed in this table are not definitive and are active areas of debate and research. (seeBaddeley et al., 2018; Christophel et al., 2017; Shipstead et al., 2015; Brydges et al., 2018; Cowan, 2017; Eriksson et al., 2015; Chia et al., 2018; Constantinidis et al., 2018).</em></p>



<p>Modern artificial neural networks used in AI utilize several memory features from the five models discussed in this literature review. They do not generally use analogs of sustained firing or synaptic potentiation, although some use a simplistic form of persistent activity known as recurrence. As Figure 9 illustrates, a recurrent neuron, such as that found in a recurrent neural network, reroutes its output back to its input. This allows it to hold the memory of an internal state, which can affect subsequent states. These machine learning nodes can use this recurrent feature to selectively store, update, or forget information based on their input and previous state. As we will see, this functionality permits them to uncover patterns in time (long-range dependencies from sequential inputs). Recurrent neurons, programmed properly, should permit artificial neural networks to simulate sustained firing and synaptic potentiation, as well as attain the cognitive properties discussed in upcoming sections, including the capacity to support a working memory that is updated iteratively.</p>







<figure><img data-attachment-id="578" data-permalink="https://aithought.com/blog/image-3-5/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/12/image-3.png" data-orig-size="975,364" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-3" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/12/image-3.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/12/image-3.png?w=975" loading="lazy" width="975" height="364" src="https://aithoughtcom.files.wordpress.com/2023/12/image-3.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/12/image-3.png 975w, https://aithoughtcom.files.wordpress.com/2023/12/image-3.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/12/image-3.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/12/image-3.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 9.</strong> Recurrency in Artificial Neural Networks Can Simulate Persistent Neural Activity</p>



<p><em>A. A simplified version of an artificial neuron used in computer science, with inputs and weights labeled. B. An artificial recurrent neuron in a hidden layer, passing information from an input layer to an output layer. This hypothetical neuron (inspired by Table 2) exhibits recurrency in its cell body and limited recurrency in some of its weights. Thus, it demonstrates an analog of both sustained firing and synaptic potentiation. C. The activity of this neuron is unfolded through time.</em></p>



<p>Persistent neural activity in the form of sustained firing and synaptic potentiation is time-limited. It runs out. When some neurons exit persistent activity and others enter it, working memory updating occurs. In other words, the updating of persistent activity provides the conceptual basis used by this article to view the previous five models from the perspective of iteration. The following section will discuss how this perspective provides insight into the process of thought.</p>



<p id="part3"><strong><u>Part III: </u></strong><span>Working Memory is Updated Iteratively</span></p>



<p><strong>3.1 Persistent Activity Causes Successive States to Overlap Iteratively</strong></p>



<p>In the preceding sections, we delved into the diverse array of models that define our understanding of working memory. However, a conspicuous gap emerges in this landscape: the omission of iterative updating as a core mechanism. This oversight is not just a minor detail, but rather a crucial element in furthering our comprehension of working memoryâs dynamics. In this section, we will explore how iterative updating occurs in synchrony at both the neural and psychological levels, bridging these domains, and offering new insights that extend current models.</p>



<p>Even though models of working memory do not acknowledge that content is updated iteratively, the nature of persistent activity strongly implies that iterative updating is pervasive. Allow me to use another analogy to explain why. Take the human population of Earth, for instance. In the next year, many people will pass away, others will be born, yet most will remain living. In the same sense, in one second, some of the brainâs neurons will stop exhibiting persistent activity, some new neurons will enter persistent activity, yet most will remain in persistent activity. The people and neurons that persist can influence subsequent states. In the same way that there could be no intergenerational knowledge transfer (culture) on a planet where generations do not overlap, there can be no thinking in a brain where spans of neural activity do not overlap.</p>



<p>The study of sustained firing has shown that the neocortex contains many neurons in persistent coactivity at any instant in time (Goldman-Rakic, 1995). Nevertheless, these coactive neurons could not have all started firing at the same time, nor could they all stop firing at the same time. This is similar to how the people on Earth are not all born at the same time and do not die at the same time. Because sustained firing has been shown to occur for different durations in different neurons (Fuster, 2008, 2002b), their spans of activity must be staggered and must only partially overlap with one another rather than completely coincide (Reser, 2016), as portrayed in Figure 10.</p>



<figure><img data-attachment-id="616" data-permalink="https://aithought.com/blog/persistant-activity-1-recovered/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/12/persistant-activity-2-recovered.jpg" data-orig-size="4313,1760" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Persistant Activity 1 [Recovered]&quot;,&quot;created_timestamp&quot;:&quot;1701870100&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;Persistant Activity 1 [Recovered]&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Persistant Activity 1 [Recovered]" data-image-description="" data-image-caption="<p>Persistant Activity 1 [Recovered]</p>
" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/12/persistant-activity-2-recovered.jpg?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/12/persistant-activity-2-recovered.jpg?w=1024" loading="lazy" width="1024" height="417" src="https://aithoughtcom.files.wordpress.com/2023/12/persistant-activity-2-recovered.jpg?w=1024" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/12/persistant-activity-2-recovered.jpg?w=1022 1022w, https://aithoughtcom.files.wordpress.com/2023/12/persistant-activity-2-recovered.jpg?w=2044 2044w, https://aithoughtcom.files.wordpress.com/2023/12/persistant-activity-2-recovered.jpg?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/12/persistant-activity-2-recovered.jpg?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/12/persistant-activity-2-recovered.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Persistant Activity 1 [Recovered]</figcaption></figure>



<p><strong>Fig. 10.</strong> A Set of 20 Neurons Exhibiting Sustained Firing</p>



<p><em>The sustained firing of 20 hypothetical neurons is shown here. The x-axis represents time. The spans of individual neurons overlap but are staggered and asynchronous. T1 and t2 are marked at the bottom. The two time periods share 10 of 20 active neurons in common. This figure exemplifies the transitional reconfiguration that distinguishes iterative updating.</em></p>



<p>If updates to the set of neurons in sustained firing involve partial rather than complete replacement, then these dynamics indicate an ongoing pattern of iteration and recursion. Iteration involves the application of a computational procedure to the results of a previous application. It is common in mathematics and computer science. Iterationâs sister algorithm, recursion, is the reapplication of a rule, definition, or procedure to successive results. A recursive function references itself. Self-referential routines are common in mathematics and computer science but mostly unknown in psychology. The terms âiterationâ and ârecursionâ uniquely capture different aspects of the present model, and both are used here depending on context.</p>



<p>The principles of iteration and recursion as they pertain to the present model are illustrated in Figure 11. At time 1 (t1), neuron âaâ has stopped firing. Neurons b, c, d, and e exhibit sustained coactivity. By time 2 (t2), neuron âbâ has stopped firing, while c, d, and e continue to fire, and âfâ begins to fire. In time 2, c, d, and e recur. The figure depicts iteration because the set of coactive neurons at time 2 (c, d, e, and f) includes a subset (c, d, and e) of the coactive neurons at time 1. In computer programming, the goal of iteration is to obtain successively closer approximations to the solution of a problem. In later sections, this article will advocate that the algorithm of thought utilizes iteration for the same purpose.</p>



<figure><img data-attachment-id="584" data-permalink="https://aithought.com/blog/image-5-4/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/12/image-5.png" data-orig-size="975,205" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-5" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/12/image-5.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/12/image-5.png?w=975" loading="lazy" width="975" height="205" src="https://aithoughtcom.files.wordpress.com/2023/12/image-5.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/12/image-5.png 975w, https://aithoughtcom.files.wordpress.com/2023/12/image-5.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/12/image-5.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/12/image-5.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 11.</strong> Depiction of Iteration in Neurons Exhibiting Sustained Firing</p>



<p><em>Each arc, designated by a lowercase letter, represents the time span during which a neuron exhibiting sustained firing remains active. The x-axis represents time. Dashed arcs represent neurons that have stopped firing, whereas full arcs denote neurons that are still active. The neurons shown here demonstrate iteration and recursion.</em></p>



<p>Given that at any point in time, we can expect there to be thousands of neurons engaged in sustained firing, we should expect the type of iterative pattern seen in Figure 11 to be ubiquitous. Furthermore, if examined on the order of hundreds of milliseconds, we should expect activity in the brain to be densely iterative. Iteration within the FoA causes consecutive brain states to be interrelated and autocorrelated as a function of the delay between them. Because a delineable subset of the active cells that characterize one brain state remain active in the next, each state is recursively nested within the one that precedes it. This allows the brain to record and keep track of its interactions with the environment (stateful) so that each interaction does not have to be handled based only on the information available at present (stateless).</p>



<p>It is asserted here that iterative updating should be considered inherent in any brain with neurons exhibiting persistent activity and that animals utilize it as a fundamental means of information processing. In particular, working memory may harness iteration in a way that allows potentially related representations to accumulate and coactivate despite delays between their initial appearances. This ensures that relevant processing products are temporarily sustained until a full suite of contextually related items is compiled to be used in aggregate to inform behavior.</p>



<figure><img data-attachment-id="587" data-permalink="https://aithought.com/blog/screenshot-3/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/12/screenshot-3.png" data-orig-size="809,715" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-3" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/12/screenshot-3.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/12/screenshot-3.png?w=809" loading="lazy" width="809" height="715" src="https://aithoughtcom.files.wordpress.com/2023/12/screenshot-3.png?w=809" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/12/screenshot-3.png 809w, https://aithoughtcom.files.wordpress.com/2023/12/screenshot-3.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/12/screenshot-3.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/12/screenshot-3.png?w=768 768w" sizes="(max-width: 809px) 100vw, 809px"></figure>







<p>The incremental updating expected at the neurophysiological level may be isomorphic with and provide a substrate for the incremental updating experienced on the psychological level. For example, a given line of thought does not change all at once but rather makes additive transitions that are grounded by content that remains unchanged. The subset of neurons that continue to exhibit persistent activity over the course of these incremental changes should be expected to embody the persisting subject of mental analysis. Stated differently, neurons with the longest-lasting activation likely correspond to the underlying topic of thought that remains as other contextual features come and go. This creates coherence and continuity between distinct epochs (Reser, 2016), as depicted in Figure 12. The present article posits that without the continuity made possible by iteration, thought as we know it cannot arise and will not be available to machines.</p>



<p>.</p>



<figure><img data-attachment-id="588" data-permalink="https://aithought.com/blog/image-6-3/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/12/image-6.png" data-orig-size="975,733" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-6" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/12/image-6.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/12/image-6.png?w=975" loading="lazy" width="975" height="733" src="https://aithoughtcom.files.wordpress.com/2023/12/image-6.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/12/image-6.png 975w, https://aithoughtcom.files.wordpress.com/2023/12/image-6.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/12/image-6.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/12/image-6.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 12.</strong> Venn Diagrams of Information Shared Between Successive States of Working Memory</p>



<p><em>These Venn diagrams depict informational overlap between successive states of working memory. The horizontal axis represents time. The small circles represent information within the FoA, while the large circles represent information within the short-term store. Diagrams 1 and 2 show no Venn overlap between states from different periods; 3 and 4 show overlap in the short-term store only; 5 and 6 show the short-term store of one state overlapping with the FoA of the neighboring state; and 7 and 8 show the FoA of separate states overlapping, suggesting attentive continuity. It may be plausible that Diagrams 1 and 2 roughly depict sampling of cortical activity hours apart, 3 and 4 depict sampling several minutes apart, 5 and 6 depict sampling every minute, and 7 and 8 depict sampling every second.</em></p>



<p>Diagram 1 of Figure 12 depicts two states of working memory whose contents do not overlap. We can assume that these states are from separate thoughts. Diagram 7 depicts two states whose contents overlap significantly. It is intended to represent a fractional transition in the thought process, such as two points in a line of reasoning. The overlapping informational content of the small circles shown in Diagram 7 indicates that the two states share neurons in common that exhibit sustained firing. The overlap of the large circles represents the sharing of potentiated synapses. Thus, the diagrams shown in Figure 12 depict updating as continuous change in active neurons and synapses. However, as the rest of this article will explore, partial change to the FoA may be more realistically depicted as iterative updates in discrete cognitive items.</p>







<figure><img data-attachment-id="482" data-permalink="https://aithought.com/blog/screenshot-80/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/11/screenshot-80.png" data-orig-size="2170,544" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-80" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/11/screenshot-80.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/11/screenshot-80.png?w=1024" loading="lazy" width="1024" height="256" src="https://aithoughtcom.files.wordpress.com/2023/11/screenshot-80.png?w=1024" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/11/screenshot-80.png?w=1024 1024w, https://aithoughtcom.files.wordpress.com/2023/11/screenshot-80.png?w=1021 1021w, https://aithoughtcom.files.wordpress.com/2023/11/screenshot-80.png?w=2042 2042w, https://aithoughtcom.files.wordpress.com/2023/11/screenshot-80.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/11/screenshot-80.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/11/screenshot-80.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p><a><strong>Table 3.</strong></a> Definition of Key Terms</p>



<p><strong>3.2 The Iterative Updating of Representations Allows Context to Shift</strong></p>



<p>Figure 13 depicts an FoA store that holds four mental representations at a time. We will refer to these representations as items (also known in psychology as chunks). In this example, one discrete item is replaced at each point in time. Thus, it could be conceptualized as a âsliding store.â The depiction of the FoA store as limited to four items is derived from an extensive literature review by Cowan (2001, 2005), which demonstrates that adults are generally able to recollect four items (plus or minus one) in situations when they cannot carry out chunking, rehearsal, or other memory strategies to aid them. This capacity of four items generally holds whether the items are numbers, words in a list, or visual objects in an array. The figures could alternatively feature seven items rather than four after less restrictively controlled research by George Miller (1956). While discussing the capacity of the FoA, Cowan remarked,</p>



<blockquote>
<p><em>âWhen people must recall items from a category in long-term memory, such as states of the United States, they do so in spurts of about three items on average. It is as if a bucket of short-term memory is filled from the well of long-term memory and must be emptied before it is refilled.â</em></p>



<p>Nelson Cowan (2009, p. 327)</p>
</blockquote>



<p>Yet, perhaps this bucket does not need to be emptied to be refilled. Perhaps it can be emptied and filled simultaneously. While naming states and repeating numbers may not necessitate this, rational thought may.</p>







<figure><img data-attachment-id="301" data-permalink="https://aithought.com/blog/image-1-3/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/04/image-1.png" data-orig-size="975,473" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-1" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/04/image-1.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/04/image-1.png?w=975" loading="lazy" width="975" height="473" src="https://aithoughtcom.files.wordpress.com/2023/04/image-1.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/04/image-1.png 975w, https://aithoughtcom.files.wordpress.com/2023/04/image-1.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/04/image-1.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/04/image-1.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 13.</strong> Abstract Schematic of Iterative Updating in the FoA</p>



<p><em>As with the following figures in this article, Figure 13 is an emblematic abstraction that uses a state-space model in discrete time. White spheres indicate active mental concepts (items), while black spheres indicate inactive ones. At time 1, item A has just been deactivated, while B, C, D, and E are coactive. This echoes the pattern of activity shown in Figure 11, except that the uppercase letters here represent items, whereas the lowercase letters in Figure 11 represent neurons. While coactive, these items (B, C, D, and E) spread their activation energy, resulting in the convergence of activity onto a new item, F. At time 2, B has been deactivated; C, D, and E remain active; and F has become active.</em></p>



<p>At time 2, three items from time 1 (C, D, and E) remain active and are combined with the update located in time 1 (F). This new set of items is then used to search for the next update (G). Items C and E demonstrate reiteration because they exhibit uninterrupted activity from time 1 through time 3. The longer these items are coactive, the more likely they will become associated and possibly âchunkâ or merge into a single item, âCEâ. While C and E remain active, their underlying neural circuits can be expected to impose sustained, top-down information processing biases on the targets they project to throughout the thalamocortical hierarchy. Items sustained enduringly in this way should be expected to influence the overarching theme of ongoing thought.</p>



<p>Imagine that item B represents your psychological concept of brownies, C represents your friend Cameron, D represents shopping, and E represents a grocery store. With these representations active in your FoA, you may form a mental image of your friend Cameron shopping for brownies at a grocery store. This scenario may cause you to remember Cameronâs preference for drinking milk when he eats brownies. Thus, your next thought may be about your friend shopping in the same store for milk. Some contextual factors (the place, person, and activity) remained the same even though another (the object being shopped for) changed. This kind of narrative about the same place and person could take several seconds and many rounds of iteration to play out. This example illustrates how iteration enables continuity by allowing context to shift incrementally, which, this paper contends, is a central hallmark of the thought process. Figure 14 offers a different narrative example.</p>







<figure><img data-attachment-id="360" data-permalink="https://aithought.com/blog/image-5/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/09/image.png" data-orig-size="975,321" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/09/image.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/09/image.png?w=975" loading="lazy" width="975" height="321" src="https://aithoughtcom.files.wordpress.com/2023/09/image.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/09/image.png 975w, https://aithoughtcom.files.wordpress.com/2023/09/image.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/09/image.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/09/image.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 14.</strong> Working Memory Updating Mediates Intelligent Transitions Between Mental States</p>



<p><em>This series illustrates the iterative working memory activity of a person who thinks about watering a plant. The person imagines a wilting plant with dry soil. This set of coactivates in working memory spreads neural activity, which converges on the concept of water. This new set, in turn, induces the ideation of using a watering can. The person then imagines tilting and then pouring the water from the watering can until they stop watering the plant.</em></p>



<p>Figure 15 expands on the schematic from Figure 13, exemplifying how working memory capacity can vary.</p>







<figure><img data-attachment-id="486" data-permalink="https://aithought.com/blog/image-10/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/11/image-10.png" data-orig-size="975,470" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-10" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/11/image-10.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/11/image-10.png?w=975" loading="lazy" width="975" height="470" src="https://aithoughtcom.files.wordpress.com/2023/11/image-10.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/11/image-10.png 975w, https://aithoughtcom.files.wordpress.com/2023/11/image-10.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/11/image-10.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/11/image-10.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 15.</strong> The Capacity Limit of Working Memory Varies</p>



<p><em>Four different examples of working memory capacity, from two to eight. The capacity of working memory can vary from trial to trial, person to person, and, presumably, from species to species. Large language models used in AI hold thousands of tokens in a rudimentary form of attention and update these coactive sets of tokens iteratively when forming predictions.</em></p>







<figure><img data-attachment-id="491" data-permalink="https://aithought.com/blog/image-13/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/11/image-13.png" data-orig-size="975,436" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-13" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/11/image-13.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/11/image-13.png?w=975" loading="lazy" width="975" height="436" src="https://aithoughtcom.files.wordpress.com/2023/11/image-13.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/11/image-13.png 975w, https://aithoughtcom.files.wordpress.com/2023/11/image-13.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/11/image-13.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/11/image-13.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 16.</strong> Four Updating Replacement Schedules</p>



<p><em>The item removed (evicted) can be the oldest entry in working memory (first in, first out), the newest entry (last in, first out), or anything in between. The least informative or relevant item should be the one selected for replacement.</em></p>



<p>Figure 17 exemplifies how the contents of working memory can correspond to either external stimuli or internal concepts. It is probably fair to say that in all mammals, but in very few computer programs, external and internal representations coactivate and interact in real time.</p>







<figure><img data-attachment-id="488" data-permalink="https://aithought.com/blog/image-11/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/11/image-11.png" data-orig-size="975,329" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-11" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/11/image-11.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/11/image-11.png?w=975" loading="lazy" width="975" height="329" src="https://aithoughtcom.files.wordpress.com/2023/11/image-11.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/11/image-11.png 975w, https://aithoughtcom.files.wordpress.com/2023/11/image-11.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/11/image-11.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/11/image-11.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 17.</strong> Working Memory Responds to and Navigates Interactions with the World</p>



<p><em>Items marked with an âSâ represent external stimuli, while items marked with a âCâ represent internally selected concepts. This series illustrates the working memory history of a driver responding to a green light that turns yellow. The yellow light in this context prompts the driver to check their distance to the intersection. When they find that the intersection is near, they accelerate. However, when the light turns red, this cues the driver to brake.</em></p>



<p><strong>3.3 The Rate of Iterative Updating Varies with Demand</strong></p>



<p>Although Figures 13-17 depict working memory updating one unit at a time, this varies according to processing demands. For instance, when an individual pursues a new train of thought, initiates a different task, or is exposed to a novel or unexpected stimulus, their attention shifts entirely from its previous focus. When this happens, the content of the FoA can change completely. In this scenario, attentional resources are reallocated to the new context, and rather than a graduated transition, an abrupt transition occurs without iteration. Figure 18 depicts various transitions in the FoA.</p>







<figure><img data-attachment-id="490" data-permalink="https://aithought.com/blog/image-12/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/11/image-12.png" data-orig-size="975,453" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-12" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/11/image-12.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/11/image-12.png?w=975" loading="lazy" width="975" height="453" src="https://aithoughtcom.files.wordpress.com/2023/11/image-12.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/11/image-12.png 975w, https://aithoughtcom.files.wordpress.com/2023/11/image-12.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/11/image-12.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/11/image-12.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 18.</strong> Four Possible State Transitions in the FoA</p>



<p><em>In the first diagram, there are four active items at time 1, which are marked as white spheres. At time 2, one of these four items has been replaced, so that one white sphere (B) becomes black (inactive) and a different black sphere (F) becomes white (active). Thus, 25% (1 Ã· 4) of the items have been updated between time 1 and time 2 without any change in the total number of active items. For clarity, most other figures in this article feature this single-item updating. However, in a store with four items, updating can occur in three other ways. The other diagrams in this figure depict 50%, 75%, and 100% updating.</em></p>



<p>Note that abrupt, noniterative updating is not possible in the short-term store. This is due to the slower nature of turnover in synaptic potentiation. Because the number of active representations is much higher and they subside much more slowly (minutes) than in the FoA (seconds), the short-term store will continue to exhibit substantial iterative overlap, even during complete shifts in focal attention. Thus, the rate of updating from one period to the next is expected to remain relatively stable in the short-term store. In contrast, the rate of updating in the FoA is expected to fluctuate markedly under different processing requirements.</p>



<p>We should expect the average percentage of updating within the FoA per unit time to be lower in animals with larger, more complex brains. During mammalian evolution, association cortices were greatly enlarged relative to sensory cortices (Striedter, 2005). This development increased the number of neurons capable of sustained firing, as well as their maximum duration (Sousa et al., 2017), despite increased metabolic costs (Mongillo et al., 2008). For primates, and humans in particular, the presence of highly developed association areas likely leads to (1) more and longer sustained activity, (2) extended coactivity of items, (3) a lower percentage of updating per second, and (4) a corresponding higher degree of continuity between iterations.</p>



<p>In animals, a lower percentage of iterative updating might correlate with greater working memory capacity and higher fluid and general intelligence. This can be conceptualized as a longer working memory half-life. The concept of a half-life could be used to quantify the persistence of information in both the FoA and the short-term store, where generally, the shorter the half-life of activity in working memory, the shorter the attention span. For instance, the half-life for the diagram in Figure 18 exhibiting 25% updating is two time intervals, whereas the half-life for 50% updating is only one time interval.</p>



<p>Figure 19 addresses the decay rate using an FoA capacity of seven items. The first diagram illustrates how neural activity in small-brained animals primarily models the present and adjusts this model with bits from the recent past. The second diagram illustrates how neural activity in large-brained mammals models the recent past and adjusts it with bits from the present.</p>







<figure><img data-attachment-id="592" data-permalink="https://aithought.com/blog/image-7-2/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/12/image-7.png" data-orig-size="975,479" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-7" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/12/image-7.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/12/image-7.png?w=975" loading="lazy" width="975" height="479" src="https://aithoughtcom.files.wordpress.com/2023/12/image-7.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/12/image-7.png 975w, https://aithoughtcom.files.wordpress.com/2023/12/image-7.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/12/image-7.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/12/image-7.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 19.</strong> Two Rates of Updating Carried Out Over Four Time Periods</p>



<p><em>In the first scenario, 71% (5 Ã· 7) updating is carried out over four time periods. In the second scenario, 29% (2 Ã· 7) updating is carried out. This comparison delineates the difference between unfocused, minimally overlapping thought (loose iterative coupling) and highly focused, closely overlapping thought (tight iterative coupling). To better illustrate this point, the capacity of the FoA is depicted here as seven items after Miller (1956). The Venn diagrams to the right illustrate the percentage of iterative updating in the FoA using the style of Figure 12.</em></p>



<p>The top diagram in Figure 19 covers a wider breadth of information, is more responsive and proceeds at a faster rate. However, it may be associated with an attention deficit, distractibility, and superficial associations. The bottom diagram is probably more conducive to concentrated attention, effortful/elaborative processing, and structured systematization of knowledge. This is because the search for the next state will be informed by a larger number of conserved parameters. Contrarily, in Diagram 1, more than half of the initial parameters are excluded after only one time interval because they could not be maintained. Thus, the next search performed loses precision and specificity. For example, it should be more difficult to solve a mathematical word problem in oneâs head using the updating strategy depicted in Diagram 1 relative to that in Diagram 2 because too many of the problemâs crucial elements would be forgotten prematurely and thus would not be available to contribute spreading activity in the search for a solution.</p>



<p>These two diagrams may represent the distinction not only between information processing in âlowerâ and âhigherâ animals but also between implicit and explicit processing in a single animal. Diagram 1 may be illustrative of implicit or system one processing (i.e., Kahnemanâs âthinking fastâ (2011)) and its impulsive, heuristic, intuitive approach. Diagram 2 may illustrate explicit or system two processing (i.e., âthinking slowâ) in which a problem is encountered that requires multiple processing steps, recruitment of executive attention, the prefrontal cortex, and the prolonged maintenance of intermediate results. Figure 20 is meant to convey that implicit and explicit processing exist on a continuum and that implicit processing may transition into explicit when dopaminergic centers are engaged by demand, novelty, surprise, curiosity, anticipated reward, or error feedback, increasing the duration of sustained firing in the neurons that represent prioritized contextual variables.</p>







<figure><img data-attachment-id="493" data-permalink="https://aithought.com/blog/image-15/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/11/image-15.png" data-orig-size="975,278" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-15" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/11/image-15.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/11/image-15.png?w=975" loading="lazy" width="975" height="278" src="https://aithoughtcom.files.wordpress.com/2023/11/image-15.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/11/image-15.png 975w, https://aithoughtcom.files.wordpress.com/2023/11/image-15.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/11/image-15.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/11/image-15.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 20.</strong> Dopamine May Reduce the Rate of Iterative Updating in Working Memory</p>



<p><em>A set of seven items is held in working memory. 57% (4 Ã· 7) updating is carried out over four time periods. At t5, the rate of updating is reduced to 14% (1 Ã· 7). This might happen when a person encounters a novel set of stimuli that causes the brain to release dopamine and shift from implicit processing (system one) to explicit attentive processing (system two). The activity of the items from t5 is sustained, and the concepts are anchored upon giving them more processing priority so that greater focus can be brought to bear on them. By t9, 57% updating resumes.</em></p>



<p>As Figure 21 illustrates, it may be the case that the rate of iterative updating decreases during a thought but then increases during the transition between thoughts. The first diagram in Figure 21 features a larger number (4 vs. 2) of individual instances of continuity (i.e., discrete thoughts) compared to the second diagram. The transitions between thoughts could be conceptualized as intermittent noniterative updating. As a cognitive strategy, the processing found in the second diagram is probably more conducive to staying on topic, comprehending complicated scenarios, and solving complex problems. Presumably, however, animals alternate between these two strategies depending on the situation. To demonstrate a capacity for flexible thought, an AI system should have this ability, along with the abilities presented in the last six figures.</p>







<figure><img data-attachment-id="593" data-permalink="https://aithought.com/blog/image-8-2/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/12/image-8.png" data-orig-size="975,287" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-8" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/12/image-8.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/12/image-8.png?w=975" loading="lazy" width="975" height="287" src="https://aithoughtcom.files.wordpress.com/2023/12/image-8.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/12/image-8.png 975w, https://aithoughtcom.files.wordpress.com/2023/12/image-8.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/12/image-8.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/12/image-8.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 21.</strong> Intermittent Noniterative Updating Marks a Boundary Between Thoughts</p>



<p><em>In both diagrams, most of the updating occurs at a rate of 20% (1 Ã· 5). However, the first diagram shows three intermittent updates of 80% (4 Ã· 5). The second shows only one intermittent update of 80%. This comparison delineates the difference between four brief thoughts occurring in quick succession and two more prolonged thoughts. The first strategy would result in small islands of associative connections among long-term memory items. The second strategy would result in longer sequences of iterated associations and, consequently, less fragmented learning.</em></p>



<p><strong>3.4 Iterative Updating Gives Rise to Mental Continuity</strong></p>



<p>Continuity is defined as the uninterrupted and consistent operation of something over a period of time. According to this model, continuity of thought involves a process in which a set of mental representations demonstrates gradual replacement across a series of processing states (Reser, 2016). Continuous, partial updating makes each mental state a reframed version of the last. This reframing process results in an updated group of conditions, modulating rather than replacing the conceptual blend created by the previous set of coactive items. The manner in which iteration permits relevant information from the past to conjoin and assimilate with information from the present may provide the connective tissue for the continuous nature of reflective thought and phenomenal consciousness. This distinct property, portrayed in most of this articleâs figures, may be necessary but insufficient for machine consciousness.</p>



<p>A few analogies may clarify the nature of iterative continuity. When it demonstrates continuity, we should expect the attentional âspotlightâ to move by degrees (e.g., the panning of a video camera) rather than abruptly (e.g., the saccade of an eye). The components within the spotlight vary smoothly. It is like the carousel function used in computer graphical interfaces where a collection of visible objects is updated as individual elements of the collection rotate into and out of view. This is similar to the morphing technique used in computer animation, where an image is transformed fluidly into another by maintaining certain features but changing others in small, gradual steps. Corresponding points on the before and after images are usually anchored and incrementally transfigured from one to the other in a process called âcrossfading.â It is also like the changes taking place within the set of interlocking teeth of two gears. As the gears turn and a new tooth is added to this set, a different tooth is subtracted, yet other teeth remain interdigitated. In literary terms, the subset of concepts that remain interdigitated constitutes the âthrough line,â connecting theme, or invisible thread that binds elements of a mental experience together. Mental continuity is an evolutionary process and, like natural selection, involves non-random retention and elimination of candidate structures leading to incremental modifications to a population.</p>



<p>In an earlier version of the present model (Reser, 2016), the subset of neurons demonstrating sustained firing over a series of states (represented by C, D, and E in Figure 13) was said to exhibit âstate-spanning coactivityâ (SSC). Over time, the set of coactive neurons shifts, creating âincremental change in state-spanning coactivityâ (icSSC). According to that model, the content of working memory is effectively in SSC, and as it progresses over time, the content exhibits icSSC. The iterative process of icSSC may provide continuity, not only to working memory but also to other constructs, such as attention, awareness, thought, and subjective experience.</p>



<p>There are some published articles that utilize iteration in describing various psychological phenomena (e.g., Shastri et al., 1999; Howard &amp; Kahana, 2002; Hummel &amp; Holyoak, 2003; Botvinick &amp; Plaut, 2006; Kounatidou et al., 2018). However, these models are not applied to modeling continuity in brain activity or consciousness. Although modern research on these topics appears to be nonexistent (Reser, 2016), William James (1842-1910) addressed the continuous nature of consciousness in his writings. In a lecture from 1909 entitled âThe Continuity of Experience,â James spoke about the âunits of our immediately felt life,â describing how these units blend together to form a continuous sheet of experience:</p>



<blockquote>
<p>âIt is like the log carried first by William and Henry, then by William, Henry, and John, then by Henry and John, then by John and Peter, and so on. All real units of experience overlap. Let a row of equidistant dots on a sheet of paper symbolize the concepts by which we intellectualize the world. Let a ruler long enough to cover at least three dots stand for our sensible experience. Then the conceived changes of the sensible experience can be symbolized by sliding the ruler along the line of dots. One concept after another will apply to it, one after another drop away, but it will always cover at least two of them, and no dots less than three will ever adequately cover it.â</p>



<p>William James (1909, p. 287)</p>
</blockquote>



<p>The above quote evinces that James had envisioned an iterative model of consciousness over a hundred years ago. Moreover, his minimum of three âdotsâ coincides with Cowanâs four (plus or minus one) items of working memory. The next section adds detail to the present account of the neural basis of the items in working memory and describes how active neurons search long-term memory for the next update.</p>



<figure><img data-attachment-id="495" data-permalink="https://aithought.com/blog/image-16/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/11/image-16.png" data-orig-size="975,433" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-16" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/11/image-16.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/11/image-16.png?w=975" loading="lazy" width="975" height="433" src="https://aithoughtcom.files.wordpress.com/2023/11/image-16.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/11/image-16.png 975w, https://aithoughtcom.files.wordpress.com/2023/11/image-16.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/11/image-16.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/11/image-16.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 22.</strong> A Representation of William Jamesâs Sliding Ruler</p>



<p><em>This figure is meant to convey William Jamesâs ruler analogy for the overlapping units of conscious experience. The ruler encompasses a set of dots. As the ruler slides down a line of equidistant dots, the set it contains is updated iteratively.</em></p>







<p id="part4"><span><a href="http://part4/"><strong><u>Part IV:</u></strong> Implications of the Model</a></span></p>



<p><strong>4.1 Iterative Updating Provides Structure to Associative Search</strong></p>



<p>Donald Hebb (1949) first posited that a group of cells firing simultaneously could represent a memory fragment in the mind for as long as the neurons remained active. He called these groups of coactive cells âassemblies.â Following Hebbâs lead, many neuroscientists today describe cortical architecture as essentially a network of hierarchically organized pattern-recognizing assemblies (Gurney, 2009; Meyer &amp; Damasio, 2009; Johnson-Laird, 1998; von der Malsburg, 1999). To recognize a complex entity, the network uses hierarchical pattern completion to locate and activate the group of assemblies that best represents the statistical function of the entityâs constituent features (Hawkins, 2004; Kurzweil, 2012).</p>



<p>On this groundwork and that of the preceding sections, the present model proposes that the engram for an item of working memory consists of a large set (ensemble) of cell assemblies located in multimodal cortical association areas (where cells encode complex conjunctive patterns). The ensemble is symbolic, and its assemblies, like the neurons that compose them, are subsymbolic. An ensemble of cells is not a stable, immutable group but a fuzzy set that varies every time the concept it encodes is activated (Reser, 2016). Thus, an individual item in the FoA would correspond to an ensemble, a distinct subset of the total set of assemblies active in that instant. Recent studies have suggested that items may be formed from alternative processes such as dynamic population codes or low-dimensional subspace representations (Panichello &amp; Buschman, 2021); however, we can expect even these would be updated iteratively.</p>







<figure><img data-attachment-id="595" data-permalink="https://aithought.com/blog/image-9-2/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/12/image-9.png" data-orig-size="975,200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-9" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/12/image-9.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/12/image-9.png?w=975" loading="lazy" width="975" height="200" src="https://aithoughtcom.files.wordpress.com/2023/12/image-9.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/12/image-9.png 975w, https://aithoughtcom.files.wordpress.com/2023/12/image-9.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/12/image-9.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/12/image-9.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 23.</strong> Concepts of Interest at Different Levels of Abstraction</p>



<p><em>1. A single neuron. 2. A neural assembly (indicated by a lower-case letter) composed of many nearby (local) neurons with similar receptive fields. An assembly (possibly a cortical minicolumn) is equivalent to a subsymbolic feature. 3. A neural ensemble (indicated by an upper-case letter) composed of many nonlocal assemblies. An ensemble is an engram for an item, concept, or mental representation. 4. Four items within the focus of attention of working memory. 5. Items in the focus of attention undergoing an iterative update.</em></p>



<p>The assemblies constituting an ensemble would be densely interconnected and have strong interactions between them. They would also have the tendency to be added to (or subtracted from) working memory as a discrete group, as shown in Figure 24.</p>







<figure><img data-attachment-id="63" data-permalink="https://aithought.com/11-coactive-neural-assemblies-and-ensembles-in-working-memory-and-the-focus-of-attention-1/" data-orig-file="https://aithoughtcom.files.wordpress.com/2022/03/11.-coactive-neural-assemblies-and-ensembles-in-working-memory-and-the-focus-of-attention-1.jpg" data-orig-size="4002,1743" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="11.-coactive-neural-assemblies-and-ensembles-in-working-memory-and-the-focus-of-attention-1" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2022/03/11.-coactive-neural-assemblies-and-ensembles-in-working-memory-and-the-focus-of-attention-1.jpg?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2022/03/11.-coactive-neural-assemblies-and-ensembles-in-working-memory-and-the-focus-of-attention-1.jpg?w=1024" loading="lazy" width="1024" height="445" src="https://aithoughtcom.files.wordpress.com/2022/03/11.-coactive-neural-assemblies-and-ensembles-in-working-memory-and-the-focus-of-attention-1.jpg?w=1024" alt="" srcset="https://aithoughtcom.files.wordpress.com/2022/03/11.-coactive-neural-assemblies-and-ensembles-in-working-memory-and-the-focus-of-attention-1.jpg?w=1022 1022w, https://aithoughtcom.files.wordpress.com/2022/03/11.-coactive-neural-assemblies-and-ensembles-in-working-memory-and-the-focus-of-attention-1.jpg?w=2043 2043w, https://aithoughtcom.files.wordpress.com/2022/03/11.-coactive-neural-assemblies-and-ensembles-in-working-memory-and-the-focus-of-attention-1.jpg?w=150 150w, https://aithoughtcom.files.wordpress.com/2022/03/11.-coactive-neural-assemblies-and-ensembles-in-working-memory-and-the-focus-of-attention-1.jpg?w=300 300w, https://aithoughtcom.files.wordpress.com/2022/03/11.-coactive-neural-assemblies-and-ensembles-in-working-memory-and-the-focus-of-attention-1.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p><strong>Fig. 24.</strong> Two Successive Instances of Coactive Assemblies in the FoA</p>



<p><em>The engrams for items B, C, D, E, and F are each composed of many assemblies of neurons active in association areas, represented by lowercase letters b, c, d, e, and f, respectively. At time 1, assemblies b, c, d, and e are active. At time 2, the assemblies for b have deactivated, while those for f have become active. Thus, time 2 is an iterated update of time 1.</em></p>



<p>The primate neocortex can hold a number of contextually related items coactive for several seconds at a time. This model proposes that these items are used to perform a global search function by spreading the combined electrochemical activation energy of their neural assemblies throughout the thalamocortical network. This activation energy converges on and activates inactive items in long-term memory that are highly associated with the current state of activity. This is similar to the case where being exposed to the words âcourse,â âcurrent,â âwet,â and âbankâ might result in the involuntary activation of the brainâs representation for the word âriver.â Hence, this model views each instantaneous state of active items in working memory as both a solution to the previous stateâs search and a set of parameters for the next search.</p>



<p>This description of search is compatible with spreading activation theory. According to that theory, the capacity for search in associative networks is derived from activation energy (in the form of action potentials) produced by active neural assemblies (Anderson, 1983). Some of this energy is excitatory, and some is inhibitory. Activation energy from active assemblies spreads in parallel to inactive assemblies that are structurally connected to (i.e., associated with) the active ones due to a history of Hebbian plasticity (Collins &amp; Loftus, 1975).</p>



<p>This activation energy propagates among assemblies through axons and dendrites and follows the weighted links of synapses. Ultimately, multiple alternative pathways originating from active assemblies converge on several of the same inactive items in long-term memory. The number of items converged on may be exceptionally large; however, not all of these can enter the FoA. The item(s) receiving the most excitatory energy is activated, becoming an iterative update to the FoA. We should expect this to be the concept most strongly psychologically associated with the items that converged upon it.</p>







<figure><img data-attachment-id="502" data-permalink="https://aithought.com/blog/image-18/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/11/image-18.png" data-orig-size="975,678" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-18" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/11/image-18.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/11/image-18.png?w=975" loading="lazy" width="975" height="678" src="https://aithoughtcom.files.wordpress.com/2023/11/image-18.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/11/image-18.png 975w, https://aithoughtcom.files.wordpress.com/2023/11/image-18.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/11/image-18.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/11/image-18.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 25. </strong>A Semantic Web Showing Associative Connections Between Concepts</p>



<p><em>Seventeen concepts (ensembles) are represented by circular nodes in a long-term memory network. The existence of an associative connection is indicated by a line, and its strength by the thickness of the line. The four items âred,â âtruck,â âsiren,â and âfireâ are currently coactive in this network, and thus spreading activation may select âfirefightersâ as the next iterative update.</em></p>



<p>Studies of semantic priming show that either conscious or subliminal exposure to a brief stimulus can temporarily increase the implicit availability of many associated concepts within long-term memory (Bargh &amp; Chartrand, 2000). For instance, in a lexical decision task, merely priming the word âwaterâ will speed up the recognition of various related words such as âfluid,â âsplash,â âliquid,â and âdrinkâ (Schvaneveldt &amp; Meyer, 1973). The standard interpretation of these findings is that activating the engram for âwaterâ unconsciously spreads to the engrams for many semantically related words. This activation is rapid, automatic, irrepressive and is theorized to be due to spreading activation in associative networks (Reisberg, 2010).</p>



<p>It may be reasonable to assume that updating working memory with a new item has a similar priming effect on spreading activation. This new item, added to the residual items, acts as an additional semantic retrieval cue, uniquely altering the field of items receiving activation. By assuming that updates to working memory are selected by its current contents, one can explain why new associations are marked by high contextual relevance and specificity. Combining this assessment with the earlier claims regarding iteration results in a system suited for producing a parade of complementary impressions, views, notions, and ideas.</p>



<p><strong>4.2 Multiassociative Search Spreads the Combined Activation Energy of Multiple Items</strong></p>



<p>âAssociationismâ is a longstanding philosophical position advocating that mental states determine their successor states by psychological associations between their contents. According to associationism, the sequence of ideas a person produces is essentially a matter of the preexisting links between stored associative memories (Shanks, 2010). William James believed one thought could induce another through a logical, correlative connection (1890). The face validity of associationism stems from the commonplace notion that one thought âsuggestsâ the next.</p>



<p>In his discussion of âthe succession of memories,â Plato identifies three principles of association: similarity (resemblance), contiguity (in time and place), and contrast (difference). Numerous other principles capable of linking mental states were added to this list by the nineteenth century, including simultaneity, affinity, reinstatement of the remainder, cause and effect, reason and consequence, means and end, and premise and conclusion (Hamilton, 1860). When any of these forms of association occur, they may simply involve an iterative update, selected by spreading activation, to join a global workspace of persistent items. Spreading activity operating in this way may help us reconcile incongruous items by locating the most compatible update. For example, it may help us find solutions to problems such as the trivia prompt, âThe name of a planet, an element, and a Roman god,â where each of the clues contribute independently to unconscious neural convergence onto the ensemble representing the construct of âmercuryâ (Reser, 2016).</p>



<p>The associationism school of thought primarily focused on a single logical associative relationship between one thought and another. This may provide only a limited explanation. The model presented here can be read as a version of associationism that escapes this limitation by assuming that all the neurons currently involved in working memory search cooperatively and probabilistically for the succeeding association. Thus, contiguous states are not only interrelated but are also interdependent. This cooperative search function may occur regardless of when the neurons started firing and irrespective of the item to which they belong.</p>



<p>Reser (2016) proposed that the selection of new items to be added to working memory might derive from the pooling of assembly activity in the cortical workspace. This unconscious, autonomous process, termed âmultiassociative search,â here operates as follows: As excitatory and inhibitory activation energy from assemblies representing the items currently in working memory spreads,</p>



<p><strong>(1)</strong> items that continue to receive sufficient activation energy remain active,</p>



<p><strong>(2)</strong> items that receive sufficiently reduced activation energy lose activity, and</p>



<p><strong>(3)</strong> inactive items that receive sufficient activation energy become active.</p>



<p>The item(s) receiving sufficient activation energy (through spatial and temporal summation) from both the present constellation of coactive assemblies (FoA) and potentiated synapses (STM) may be recalled autoassociatively (i.e., an active subset of the itemâs assemblies is sufficient to activate the rest of the item). This nonlinear, stochastic process should be taken to be responsible not only for finding and activating the next item(s) (Fig. 26) but also for determining the percentage of items updated in the FoA (Figs. 18, 19, and 20).</p>







<figure><img data-attachment-id="598" data-permalink="https://aithought.com/blog/image-10-2/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/12/image-10.png" data-orig-size="975,555" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-10" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/12/image-10.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/12/image-10.png?w=975" loading="lazy" width="975" height="555" src="https://aithoughtcom.files.wordpress.com/2023/12/image-10.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/12/image-10.png 975w, https://aithoughtcom.files.wordpress.com/2023/12/image-10.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/12/image-10.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/12/image-10.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 26.</strong> A Schematic for Multiassociative Search</p>



<p><em>Spreading activity from each of the assemblies (lowercase letters) of the four items (uppercase letters) in the FoA (B, C, D, and E) propagates throughout the cortex (represented by the field of assemblies above the items). This activates new assemblies that will constitute the newest item (F), which will be added to the FoA in the next state. The assemblies that constitute items B, C, D, and E are each individually associated with a very large number of potential items, but as a unique group, they are most closely associated with item F.</em></p>



<p>This procedure is executed unceasingly during waking consciousness. It takes sets of neural assemblies that have never been coactive before and uses their collective spreading activation to select the most applicable iterative update. At every moment, the set of assemblies in coactivity is unprecedented. However, the set of items in coactivity may not be. When the set of coactive items has been coactive at some point in the past, the spreading activity either converges on the same item that was selected the last time (recall) or it may converge on an altogether different item (novel inference). Regardless of which way this occurs, the process transforms the latent information inherent in the original set into new, manifest information by forcing it to interact with inert long-term memory. Each set of coactive items and the links between them can potentially be recorded to memory. Thus, every search creates new associative learning in the network, improving its future behavior and model of reality. Thus, multiassociative searching gives rise to multiassociative learning.</p>



<p>These concepts explain how long-term (non-hippocampal) semantic memory might be updated. New memories donât replace old ones; rather, they retune the connectional strengths between groups of items. For instance, in Figure 26, the associative relationship between F and B is strengthened, but mostly in the presence of items C, D, and E. As items demonstrate coactivity within working memory, we should expect their assemblies to exhibit a Hebbian propensity to wire together, forming statistical codependencies that support the learning process. Reoccurring examples of coactivity would lead to the formation of heavily encoded associations (Asok et al., 2019), which would persist as procedural and semantic knowledge.</p>



<p>Undoubtedly, many canonical information processing algorithms not mentioned here (see, e.g., Miller et al., 2018; Sreenivasan, 2019) also contribute to this search and play causal roles in this process. However, it may be parsimonious to assume that the subsymbolic components of the symbolic items of working memory work synergistically and in parallel to search for the updates to working memory in the way described. In other words, the production sequence of thought is not determined by semantic dependencies between symbols (e.g., rules, utilities, predicates, conditionals, functions, etc.) as in other cognitive architectures (e.g., ACT-R, Soar, Sigma, etc.). Instead, it is determined by syntactic dependencies among subsymbols. These dependencies may reconcile with declarative, symbolic knowledge at the psychological level. Nonetheless, they operate unconsciously below it. In other words, the outcomes of these âblindâ statistical searches only appear rational because they are based on a history of structured learning from orderly environmental patterns.</p>



<p>Note that, in the present model, the cortical assemblies constituting items currently in the FoA are not the only contributors to selecting the next item(s). Rather, all firing neurons that participate in the spreading of activation in the cortical workspace contribute definitions to this global search. Potentiated neurons in the short-term storeâas well as active neurons in sensory and motor cortex (semantic), hippocampus (episodic), basal ganglia (procedural), and other cortically connected subcortical neuronsâall contribute to multiassociative search. Figure 27 depicts this situation, in which a working memory store characterized by iterative updating selects its updates using spreading activation generated by several different neuroanatomical systems. The next section will discuss how iterative updating and multiassociative search work together to formulate not only associations but also predictions.</p>







<figure><img data-attachment-id="599" data-permalink="https://aithought.com/blog/image-11-2/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/12/image-11.png" data-orig-size="975,477" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-11" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/12/image-11.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/12/image-11.png?w=975" loading="lazy" width="975" height="477" src="https://aithoughtcom.files.wordpress.com/2023/12/image-11.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/12/image-11.png 975w, https://aithoughtcom.files.wordpress.com/2023/12/image-11.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/12/image-11.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/12/image-11.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 27.</strong> A Single Cycle of the Iterative Updating / Multiassociative Search Procedure</p>



<p><em>The FoA, the short-term store, as well as active neurons in the hippocampus, basal ganglia, sensory and motor cortices all contribute to the spreading activation that will select the next item(s) to be added to working memory. At time 1, two (K and L) of a potential five items are converged on, and these update the FoA in time 2.</em></p>



<p><strong>4.3 States Updated by the Products of Search Are Predictions</strong></p>



<p>The meaning of an event is determined by the events that came before it and by those that will come after it. Claude Shannon, the founder of information theory, knew this and was interested in predicting events based on their foregoing context. He introduced a hypothetical situation in which a person is tasked with guessing a randomly selected letter from a book (Shannon, 1951). Because there is no contextual information available, any response would be highly uninformed and made by chance. However, if this person is given the letter that comes before the unknown letter, a more informed guess can be made. The more previous letters known, the better the guess (Stone, 2015). For instance, if you knew the sequence of letters that precede an unknown letter was ât,â âh,â âi,â and ân,â then you would know that there is a high probability that the next letter is either âkâ or âg.â</p>



<p>As with letters in a word or words in a sentence, events occurring along a timeline in a natural environment are not independent or equiprobable. Rather, there are correlations and conditional dependencies between successive events. Knowledge of conditional dependencies allows us to predict what other people will do next and, sometimes, to even finish their sentences for them. Working memory enables the mind to capture and record long-term dependencies. This, in turn, permits animals to treat separate events as causally related variables that can be used to predict future events. By capturing the statistical structure of a sequence of recent occurrences (including rewards and punishments), working memory provides animals with a way to form an autoregressive interpretation of an unfolding scenario, forming associative expectations of it and responses to it.</p>



<p>The interaction between iterative updating and multiassociative search may form the basis for prediction in the brain. Consider the case in which four environmental stimuli present themselves in quick succession. This could involve any sequence of events, such as that involved in finding food. If each stimulus is attended to and persistently activated, the items representing these stimuli and their closest associations will have the chance to comingle in the FoA. Their coactivity may cause them to become associated by activity-dependent learning even though they never actually occurred simultaneously in the environment (trace conditioning). If this sequence of four stimuli is repeated frequently (as would be expected if there were conditional dependencies between them found in nature), then they will come to be strongly associated. The next time the first three stimuli appear, their very activity may be sufficient to search for and recruit the item representing the fourth stimulus from long-term memory. Consequently, the activation of this fourth item would be a prediction. Therefore, internally generated, self-directed thought can be conceptualized as an iterative procession of concatenated, associative predictions, each predicated on the prediction before it.</p>



<p>In Figure 28, Diagram 1 depicts a situation in which stimulus 1 (S1) is followed by stimulus 3 (S3) and results in the selection of response 1 (R1). This can be contrasted with Diagram 2, where S3 is preceded by a different stimulus (S2), and a completely different response is selected (R2). The persistent activity of the first stimulus influences the interpretation of S3, biasing the response accordingly. That is to say, the response to S3 is conditionally dependent on the stimulus that precedes it. Diagrams 1 and 2 have been adapted from a highly popular model of PFC function (Miller &amp; Cohen, 2001). Diagrams 3 and 4 take this idea further, relating it to the present model, communicating that when the first two stimuli are the same (S1 and S2) but the subsequent stimulus differs, the responses may also differ. These diagrams underscore the hypothesis that behavior is not merely directed by the differential selection of existing neural pathways underlying stimulus-response pairings (i.e., Miller &amp; Cohen, 2001) but rather by a series of multiassociative searches that utilize curated sets of memoranda to converge on the best response at each time step.</p>







<figure><img data-attachment-id="533" data-permalink="https://aithought.com/blog/fig-26/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/11/fig-26.jpg" data-orig-size="3725,1693" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fig-26" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/11/fig-26.jpg?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/11/fig-26.jpg?w=1024" loading="lazy" width="1024" height="465" src="https://aithoughtcom.files.wordpress.com/2023/11/fig-26.jpg?w=1024" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/11/fig-26.jpg?w=1024 1024w, https://aithoughtcom.files.wordpress.com/2023/11/fig-26.jpg?w=2046 2046w, https://aithoughtcom.files.wordpress.com/2023/11/fig-26.jpg?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/11/fig-26.jpg?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/11/fig-26.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p><strong>Fig. 28.</strong> Conditional Dependencies Between Consecutive Events</p>



<p><em>Each arc represents the span of time since an event occurred. S represents stimuli, R represents responses, and other capital letters represent items. To provide an illustrative example, let us suppose the variables named above correspond to the following events: S1 = friend, S2 = enemy, S3 = approach, S4 = depart, R1 = act friendly, R2 = act aggressive, R3 = wait, R4 = follow, A = foraging alone, B = feel hungry, C = find berries, D = not poisonous, Z = poisonous, Y = friend approaching, R5 = eat, R6 = donât eat, R7 = share berries, R8 = eat berries before friend arrives.</em></p>



<p>Diagrams 5 through 8 communicate that the full complement of items in working memory can be expected to show a pattern like that seen with the stimuli in Diagrams 1 through 4: each item affects the interpretation of the items after it and uniquely biases the search for a response to them. Accordingly, the arrows below Diagrams 5 through 8 indicate that, at each time step, the preceding items provide a frame of reference through which subsequent items are interpreted. Note that even though the responses in Diagrams 7 and 8 are reacting to the same four representations (B, C, D, and Y), they react to them differently because the order of items contextualizes the scenario differently. For instance, item C has a different meaning (dependency) when it follows Y versus when it precedes Y. Therefore, it elicits a different predictive response in Diagram 7 relative to Diagram 8.</p>



<p>Consider a situation in which a person writes with a pencil, and the lead breaks. This may cause the long-term memory representations for âwriting,â âpencil,â âlead,â and âbrokenâ to become active in the FoA. This combination of coactive items (conditioned from years of writing with a pencil in school) might result in the automatic spreading of activation to the representation for a âsharpener.â During another round of updating, the representation for âwritingâ may exit the FoA and be replaced by the pencil sharpenerâs location, such as âdesk drawer.â In this way, sets of coactive items can prompt others in advancing sequences capable of producing not only predictions but also adaptive behavior. Especially when the items being sustained are task-relevant, this kind of iterative system should be capable of incremental advancement toward a goal.</p>



<p><strong>4.4 Iterative Updating Allows Progressive Changes to the Contents of Thought</strong></p>



<p>In addition to accounting for the serial, cyclic, continuous, narrative, and predictive functions of thought processes, iterative updating may be a fundamental feature of reasoning. This section will provide brief explanations for why this might be the case.</p>



<p>According to the present model, iterative updating produces sequences of interdependent states in which each state is capable of representing the current status of a problem-solving procedure and updating it with a prediction. When this associative prediction is informed by meaningful causal dependencies learned from related experiences from the environment, it sets the cycle on a logical course. This makes it possible for a starting state to generate a chain of intermediate states that make progress toward a terminal solution state.</p>



<p>Iterative updating allows working memory to link a series of rapid, automatic associations so that they can furnish a foundation for each other, resulting in the assembly of complex content. This occurs when a series of linked searches culminates in a higher-order result that any single search on its own could not otherwise attain. A prolonged stretch of tightly recursive searches (where a large proportion of items are retained throughout several states, as in Figure 19, Diagram 2) may be slower and more error-prone but can address problems too unfamiliar or complicated to be solved by less iterative, implicit processing.</p>



<p>Generally speaking, short bouts of iteration engage crystallized intelligence and easy-to-reach network states, whereas instances of prolonged iteration use fluid intelligence and highly processed, difficult-to-reach states. Such highly elaborated states are comprised of select subsets of previous states from various points in the recent past. This corresponds to simple thoughts building constructively âon top ofâ each other to form complex thoughts. William James used the term âcompoundingâ to describe this concept:</p>



<blockquote>
<p>ââ¦complex mental states are resultants of the self-compounding of simpler onesâ¦. in the absence of souls, selves, or other principles of unity, primordial units of mind-stuff or mind-dust were represented as summing themselves together in successive stages of compounding and re-compounding, and thus engendering our higher and more complex states of mind.â</p>



<p>William James (1909, p. 185)</p>
</blockquote>



<p>Iterative updating may employ this compounding feature during logical or relational reasoning. The item or items that update the FoA create a context to be compared, contrasted, integrated, or otherwise reconciled with the context remaining from the previous state. This may be the same kind of reconciliation that occurs in formal logic. For instance, propositional logic combines simple statements using logical operators (subjects and predicates) and connectives (e.g., and, or, not, if, then, because, etc.) to produce complex rational statements. The operators of such a statement could be instantiated by items. This group of coactive items could imply a true statement or premise that, when updated in the next state, could invoke a related premise or lead to a conclusion. By creating strings of substantiated inferences in this way, multiassociative search could permit the construction of a logical case or argument, form new boundaries and affinities between groups of items, and build expectations about events that have never been encountered.</p>



<p>The compounding feature of iteration may also enable working memory to implement algorithms for use in reasoning and problem solving. All complex learned behaviors have algorithmic steps that must be executed in a specific sequence to reach completion (Botvinick, 2008). Activities such as hunting, tying shoes, and performing long division involve following an algorithm. Successive states of working memory could correspond to successive steps in an iterable process.</p>



<p>Iterative updating could be instrumental in implementing learned algorithms because virtually every step of an algorithm relates to the preceding and subsequent steps in some way. A new update could correspond to a behavior or mental operation required in the next step of the sequence of actions that need to be taken. The update could amount to a response, memory, or heuristic or provide top-down influence to a perception. Thus, multiassociative search converges on the most appropriate fragment of knowledge at each state of solving a routine or non-routine problem. An item inhibited or allowed to subside could correspond to an operation that has already been executed or is no longer needed.</p>



<p>Once the associations relevant to an algorithm have been learned and trained, multiassociative search can recruit the items necessary for each next step (Reser, 2016). For instance, performing long division by rote requires many trials, and proficiency may only be reached when the active items in each state have been trained to converge on the items necessary to perform the operation in the next step. After the first digit of the dividend is divided by the divisor, the prevailing state of working memory automatically activates the items necessary to take the whole number result and write it above the dividend. Cognitive algorithms may be constructed in this manner during learning, as trial, error, and repetition link recursive chains of states capable of assembling functional behaviors. At its core, this is a form of optimization that may use operant conditioning to provide feedback for incremental guess refinement.</p>



<p>Iterative updating could also conceivably play a role in the generation of schemas and mental models. Mental models are internal representations of external systems and the relationships between their parts (Cheng &amp; Holyoak, 2008). Iteration may afford the incremental modification of a model from its previous state, allowing capacity-limited, static models to be elaborated dynamically. Even dynamic systems can be modeled when their enduring features are held constant by persistent activity and the changing features are updated correspondingly. This enables tweaking the search parameters of interest to vary the simulation in stages, producing a systematic effort to investigate a structured problem space. Solving a complex multistep problem requires the FoA and short-term store to cooperate. For instance, one line of thought developing in the FoA may be temporarily suspended in the short-term store so that the FoA can be made available to solve a related subproblem. The FoA would iterate multiassociatively, progressing toward the solution to this subproblem. When the subsolution is reached, it could then be merged with the pending problem to create a hybrid solution state. This interleaving and eventual merger of states of progress would facilitate the decomposition of a problem that is too computationally taxing to be processed by the FoA alone (Fig. 29).</p>







<figure><img data-attachment-id="508" data-permalink="https://aithought.com/blog/image-20/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/11/image-20.png" data-orig-size="975,493" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-20" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/11/image-20.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/11/image-20.png?w=975" loading="lazy" width="975" height="493" src="https://aithoughtcom.files.wordpress.com/2023/11/image-20.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/11/image-20.png 975w, https://aithoughtcom.files.wordpress.com/2023/11/image-20.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/11/image-20.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/11/image-20.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 29.</strong> Merging Subproblems in Working Memory</p>



<p><em>An original problem is activated (M, N, O, P), and iterative updating is used to reach a subsolution (O, P, Q, R). This subsolution is saved in the short-term store, and a related subproblem (T, U, V, W) is introduced into the FoA. This subproblem iterates until a second subsolution is generated (U, V, W, X). Relevant items from the first subsolution (Q and R) are combined with those from the second subsolution (W and X) and iterated to generate a final solution (R, X, Y, Z). This pattern could be a fundamental aspect of human reasoning and creativity.</em></p>



<p>According to this interpretation, the short-term store holds the agentâs present objective, and the FoA produces lines of reasoning that interrogate that objective. These lines of reasoning update the objective, bringing it closer to resolution. This allows the agent to keep a present opportunity or threat in mind while considering possible responses before acting. In effect, previous threads of FoA sequences can be suspended in STM (or LTM) as interim results. These can then be retrieved rapidly if spreading activity reconverges on them. This permits working memory to deviate from its default behavior described thus far and employ a form of backward reference and conditional branching.</p>



<p>We have seen how continuity of thought can be established and then broken. However, Figure 29 demonstrates that instances of continuity can be reestablished, such as when one revisits a thought from the past. Other common thought patterns exemplifying related mental phenomena are illustrated in Figures 30-37.</p>







<figure><img data-attachment-id="510" data-permalink="https://aithought.com/blog/image-21/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/11/image-21.png" data-orig-size="944,506" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-21" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/11/image-21.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/11/image-21.png?w=944" loading="lazy" width="944" height="506" src="https://aithoughtcom.files.wordpress.com/2023/11/image-21.png?w=944" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/11/image-21.png 944w, https://aithoughtcom.files.wordpress.com/2023/11/image-21.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/11/image-21.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/11/image-21.png?w=768 768w" sizes="(max-width: 944px) 100vw, 944px"></figure>



<p><strong>Fig. 30.</strong> Reiterating Through an Earlier Sequence</p>



<p><em>A set of six items held in working memory is iteratively updated over the next three time steps, creating a self-contained thought. Starting at t5, attention shifts completely as an unrelated thought takes place using an entirely different set of items. From t9, the first sequence is reiterated as before. This might happen when someone revisits an earlier thought, such as rehashing a plan of action, retracing a set of previous steps, or retelling a story.</em></p>







<figure><img data-attachment-id="511" data-permalink="https://aithought.com/blog/image-22/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/11/image-22.png" data-orig-size="941,536" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-22" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/11/image-22.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/11/image-22.png?w=941" loading="lazy" width="941" height="536" src="https://aithoughtcom.files.wordpress.com/2023/11/image-22.png?w=941" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/11/image-22.png 941w, https://aithoughtcom.files.wordpress.com/2023/11/image-22.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/11/image-22.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/11/image-22.png?w=768 768w" sizes="(max-width: 941px) 100vw, 941px"></figure>



<p><strong>Fig. 31.</strong> Revisiting the Endpoint of an Earlier Iterative Sequence and Continuing It</p>



<p><em>Six items are modified over the first three time steps, creating a line of thought composed of four related states. Attention shifts completely at t5, and an unrelated thought occurs. Starting at t9, attention shifts back to the items from t4, which are iterated without using any of the items from t5 through t8. This might happen when someone picks up a thought where it left off and continues to think about the issues from the last point at which they were considered.</em></p>







<figure><img data-attachment-id="512" data-permalink="https://aithought.com/blog/image-23/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/11/image-23.png" data-orig-size="937,535" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-23" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/11/image-23.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/11/image-23.png?w=937" loading="lazy" width="937" height="535" src="https://aithoughtcom.files.wordpress.com/2023/11/image-23.png?w=937" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/11/image-23.png 937w, https://aithoughtcom.files.wordpress.com/2023/11/image-23.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/11/image-23.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/11/image-23.png?w=768 768w" sizes="(max-width: 937px) 100vw, 937px"></figure>



<p><strong>Fig. 32.</strong> Revisiting the Midpoint of an Earlier Iterative Sequence and Altering It</p>



<p><em>Six items are modified over seven time steps, creating a thought composed of eight related states. At t9, attention shifts back to a point in the middle of this sequence. This set or subproblem from t4 is then iterated without including any of the items that were introduced from t5 through t8. This creates an alternate branch and a âforkingâ of the iterative sequence. This might happen when someone decides to assume an intermediate step in a previous problem-solving sequence and solve the problem in a different way.</em></p>







<figure><img data-attachment-id="513" data-permalink="https://aithought.com/blog/image-24/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/11/image-24.png" data-orig-size="975,516" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-24" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/11/image-24.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/11/image-24.png?w=975" loading="lazy" width="975" height="516" src="https://aithoughtcom.files.wordpress.com/2023/11/image-24.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/11/image-24.png 975w, https://aithoughtcom.files.wordpress.com/2023/11/image-24.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/11/image-24.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/11/image-24.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 33.</strong> Multitasking Occurs when Two Independent Sequences Alternate</p>



<p><em>Two distinct threads of thought are iterated but never combined, alternating every third time step. This context switching could occur when someone is working on two separate tasks or problems simultaneously.</em></p>







<figure><img data-attachment-id="232" data-permalink="https://aithought.com/blog/eelaboration-1/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/02/eelaboration-1.png" data-orig-size="913,524" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="eelaboration-1" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/02/eelaboration-1.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/02/eelaboration-1.png?w=913" loading="lazy" width="913" height="524" src="https://aithoughtcom.files.wordpress.com/2023/02/eelaboration-1.png?w=913" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/02/eelaboration-1.png 913w, https://aithoughtcom.files.wordpress.com/2023/02/eelaboration-1.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/02/eelaboration-1.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/02/eelaboration-1.png?w=768 768w" sizes="(max-width: 913px) 100vw, 913px"></figure>



<p><strong>Fig. 34.</strong> Elaborating on a Stable Subset of Items</p>



<p><em>Three items are held constant as iteration elaborates on their statistical relationships with related concepts. This process would strengthen the connection between these first three items and explore how they are associated within different contexts.</em></p>







<figure><img data-attachment-id="233" data-permalink="https://aithought.com/blog/erevisit/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/02/erevisit.png" data-orig-size="913,521" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="erevisit" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/02/erevisit.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/02/erevisit.png?w=913" loading="lazy" width="913" height="521" src="https://aithoughtcom.files.wordpress.com/2023/02/erevisit.png?w=913" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/02/erevisit.png 913w, https://aithoughtcom.files.wordpress.com/2023/02/erevisit.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/02/erevisit.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/02/erevisit.png?w=768 768w" sizes="(max-width: 913px) 100vw, 913px"></figure>



<p><strong>Fig. 35.</strong> Progressing Backward to a Subset of an Earlier State of Coactive Items</p>



<p><em>Some lines of thought, by the end, return to the beginning. Here, the first set of coactive items is revisited and re-related to the outcome of the iterative sequence. This circularity could occur when one reconciles a predicted outcome with the original premise. This is probably a common thought pattern and can be contrasted with the previous figure, where the first three items never leave coactivity.</em></p>







<figure><img data-attachment-id="286" data-permalink="https://aithought.com/blog/image-1-2/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/03/image-1.png" data-orig-size="975,557" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-1" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/03/image-1.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/03/image-1.png?w=975" loading="lazy" width="975" height="557" src="https://aithoughtcom.files.wordpress.com/2023/03/image-1.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/03/image-1.png 975w, https://aithoughtcom.files.wordpress.com/2023/03/image-1.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/03/image-1.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/03/image-1.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 36.</strong> Linking the Beginning of an Iterative Sequence with the End Makes the Intermediate Steps Implicit</p>



<p><em>Six items are modified over nine time steps, creating a line of thought composed of ten related states. After t10, many states pass as indicated by the ellipsis. Then, later, the original six items reenter working memory. Because of Hebbian learning, these items recruit the same six-item solution reached previously without having to reiterate it. The way probability is modeled has changed due to the earlier iterative work, and multiassociative search is now capable of recruiting the final solution immediately. This is much more likely to happen when iteration involving the first six and last six items occurs, further entrenching their association. This may happen when one reflects on how their solution reconciles with the original problem state (Fig. 35).</em></p>



<p>Another commonplace pattern found in the updating of working memory may occur when an existing problem-solving process reaches an impasse. The newest addition to working memory is sometimes unhelpful or not task-relevant (e.g., because of prepotent associations formed during a similar but irrelevant task). In this case, it may be inhibited. The same items that recruited it would continue to spread activation energy without being able to reactivate it. This would force them to activate the next most pertinent item. Multiple rounds of âiterative inhibitionâ may be required before an appropriate item can be identified (Fig. 37). Each time a potential coactivate is vetted for exclusion, the search tree is restricted further. This situation might arise as one deliberates over different methods of completing the same task (e.g., âI should fax this letter. No, I should email it. No, I will text it insteadâ).</p>







<figure><img data-attachment-id="514" data-permalink="https://aithought.com/blog/image-25/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/11/image-25.png" data-orig-size="973,548" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-25" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/11/image-25.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/11/image-25.png?w=973" loading="lazy" width="973" height="548" src="https://aithoughtcom.files.wordpress.com/2023/11/image-25.png?w=973" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/11/image-25.png 973w, https://aithoughtcom.files.wordpress.com/2023/11/image-25.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/11/image-25.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/11/image-25.png?w=768 768w" sizes="(max-width: 973px) 100vw, 973px"></figure>



<p><strong>Fig. 37.</strong> Iterative Inhibition Excludes New Items in a Search for Something More Relevant</p>



<p><em>An original problem is activated in time 1 (B, C, D), and the spreading activity activates a new item at time 2 (E). Executive processes determine that E is not a suitable behavioral parameter and E is inhibited. With E unavailable, B, C, and D continue to spread activation energy that converges on F at time 2. The same iterative inhibition occurs with F at time 4. G is then activated, and iterative updating continues.&nbsp;&nbsp;</em></p>



<figure><img data-attachment-id="600" data-permalink="https://aithought.com/blog/image-12-2/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/12/image-12.png" data-orig-size="975,600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-12" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/12/image-12.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/12/image-12.png?w=975" loading="lazy" width="975" height="600" src="https://aithoughtcom.files.wordpress.com/2023/12/image-12.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/12/image-12.png 975w, https://aithoughtcom.files.wordpress.com/2023/12/image-12.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/12/image-12.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/12/image-12.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 38</strong>. Reconciling Disparate Situations with the Same Concept</p>



<p><em>Two seemingly different situations from t1 and t8 iterate with the same concept (seen twice, at t7 and t14). The items at t1 and t8 independently converge toward the idea of t7/t14 as they are reconciled with its fundamental attributes. Perhaps both situations can be explained or caused by the same underlying phenomena and thus are funneled toward this specific region in the conceptual landscape.</em></p>



<p>As the figures in this section suggest, iterative updating will tend to converge toward certain stable sets of items. These are attractor states that amount to beliefs, possibly to profound truths about reality. Iteration then reconciles these truths with other truths. All thinking is a narrowing down of combinations of items approaching reliable statements that can be generalized across situations. The present article itself is doing something very similar by attempting to reconcile the concept of iteration with numerous other related concepts. This section has considered how iteration of working memory content can create progress in information processing. The following section will consider how the model in general can be tested experimentally.</p>



<p><strong>4.5 Testing the Neurophysiological Validity of the Model</strong></p>



<p>Future work can use this framework to search for the neural signature of iteration within the brain (see Figs. 11, 12, 13 and 21). As shown in Figure 39, this search could utilize simultaneous recordings (electrodes inserted into live cortical tissue) to produce time-series analyses of incremental change in populations of coactive cortical neurons.</p>



<figure><img data-attachment-id="515" data-permalink="https://aithought.com/blog/image-26/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/11/image-26.png" data-orig-size="974,643" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-26" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/11/image-26.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/11/image-26.png?w=974" loading="lazy" width="974" height="643" src="https://aithoughtcom.files.wordpress.com/2023/11/image-26.png?w=974" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/11/image-26.png 974w, https://aithoughtcom.files.wordpress.com/2023/11/image-26.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/11/image-26.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/11/image-26.png?w=768 768w" sizes="(max-width: 974px) 100vw, 974px"></figure>



<p><strong>Figure 39.</strong> A Hypothetical Example of How Iterative Updating Could Be Found Using Electrodes</p>



<p><em>Single-cell recording from a large number of cells in association cortex could produce an activity profile exhibiting iterative updating. In this simplified figure, the x-axis represents time in seconds while the y-axis contains the recorded activity of 30 individual neurons, each remaining active for four seconds. Five neurons become active each second. Each group of five neurons that begin and end their period of activity at the same time is assumed to belong to an individual ensemble, or item, of working memory. Brackets at the bottom of the figure indicate the item to which each group of neurons belongs. This profile coincides precisely with the pattern introduced in Figure 11. Searching new and existing data for this kind of iterative pattern could provide strong support for the present model.</em></p>



<p>It is unclear whether it is possible to derive conclusive support for the present model using existing neuroimaging technology. Basic fMRI recording reveals the degree to which specialized brain modules exhibit involvement during a specific task but does not reveal the identity of the items or concepts involved. However, advanced recording techniques can demonstrate the onset and duration of brain responses to prepared stimuli, which could result in data similar to that in Figure 39. It should be possible to use the gain in temporal and spatial resolution to observe how the pattern of working memory activation changes over time. To that end, factorial designs that allow for the measurement of the BOLD signal for each volumetric cell should be able to test for differential activation in response to partial, as opposed to complete, updating of working memory.</p>



<p>Substantiating findings could be derived from neuroimaging experiments in which brain activity is recorded while participants complete a task that requires an algorithmic sequence of steps (e.g., long division). Each step of the task would need to be modeled separately. As the participant moves from one step to the next, the BOLD activity would be estimated for that particular step. A mixed model of a duration regressor covering the entire span of the problem along with individual regressors for each step would be needed to capture both the sustained attention required to solve the problem and the individual steps needed to progress from one stage to the next. It would be necessary to show that the sequence of mental representations posited as necessary to complete the task has a one-to-one correspondence with the time course of underlying cellular or hemodynamic changes. This may necessitate using multiple methods simultaneously, such as fMRI and EEG together or multivoxel pattern analysis, which has been used to resolve the addition and subtraction of individual cognitive items from working memory (Lewis-Peacock et al., 2012).</p>



<p>To validate the hypotheses put forth by the present model, it would be necessary to show that the activity in association areas underlying working memory contents can be partially rather than completely updated. Next, the goal would be to show that this partial updating happens constantly. Future studies should be able to resolve whether the iterative updating of cortical activity is continuous (at the level of neurons) or incremental, where entire items (and all their comprising neurons) are added or subtracted at once (Fig. 24). The line of reasoning suggested by this article predicts that the former may be true of the short-term store (i.e., Figure 12) while the latter may be true of the FoA (i.e., Figure 13).</p>



<p>Modern cognitive neuroscience is limited in its ability to match the components of brain states to the components of mental states. However, matching the iterative updating of ensembles to that of their corresponding items may provide a means to do so. The markers of iterative updating may establish an ordinality and translation strategy to decode the nature of the correspondence between temporary neural traces and their psychological manifestations.</p>



<p id="part5"><strong><u>Part V:</u></strong> Instantiating the Model Within a Computer</p>



<p><strong>5.1 AI Should Employ Iterative Updating</strong></p>



<p>Many researchers in the field of AI expect brain science to reveal breakthroughs that will provide essential guidance for the construction of intelligent machines (Haikonen, 2012). Some have suggested that AI may not need to emulate fine-grained molecular or cellular details of the brain to create human-level intellectual function (Bostrom, 2014). Instead, they suggest simulating an abstraction of the neurological mechanisms that produce intelligence (e.g., Hassabis et al., 2017; Butlin et al., 2023). The present model introduces abstractions that may be useful in this regard.</p>



<p>Specifically, the present model may help close the âcomputational explanatory gap,â which is an effort to understand how the parallel, subsymbolic computations involved in low-level neural networks could translate into the serial, symbolic-level algorithms involved in high-level cognition (Reggia et al., 2019). Figures 26 and 27 provide mechanistic accounts of how this gap could be bridged. Today, even state-of-the-art AI processing feats are generally only equivalent to a second or less of unconscious human processing (e.g., recognizing objects in a picture) (Goodfellow et al., 2017). To create more generally intelligent AI, these brief parallel processing sessions must be chained together into iterated sequences that more closely resemble symbolic thought. Iterative updating and multiassociative search may be instrumental in realizing this. As the rest of this section will detail, even though neither are recognized by psychology or neuroscience, they are both used in computer science.</p>



<p>Iterative updating, on its own, is not sufficient to elevate computer information processing to the cognitive domain. In fact, updating a memory store iteratively has been commonplace in computing for several decades. All computers using the Von Neumann architecture routinely update their temporary memory stores (i.e., static RAM and dynamic RAM). These stores, known as caches, have a resemblance to working memory. They hold information that is predicted to be useful so it can be readily available to the CPU. Cached information includes intermediate results from ongoing processing, as well as data and program instructions from the storage drive. Cache stores have a limited capacity, and because they are constantly tasked with holding new information, they must evict old information. These stores are updated iteratively as the least recently used (LRU) data are replaced (Comer, 2017). For example, a computerâs RAM holds billions of bytes coactive through time, adding and subtracting from this pool in the manner illustrated in Figure 2.</p>



<p>However, the next bytes of data processed by the CPU are not determined by the contents of the cache itself. Instead, the processing instruction sequence is determined by the next line of programmed, executable code. Thus, unlike the brain, computers do not make cached information globally accessible for use in multiassociative search. The various bytes of data within computer cache memory can certainly be considered coactive, but they are not âcospreading.â That is, they do not pool their activation energy to search long-term memory for relevant data as in human working memory (Fig. 26). No computer hardware or software does this as described here.</p>



<p>There are advanced AI systems that employ working memory, a global workspace, recursion, and various methods of updating (e.g., Goertzel, 2016). These include cognitive architectures (Gray, 2007), evolutionary computation (Sipper et al., 2018), soft computing (Konar, 2014), and some machine learning techniques. However, such software generally utilizes either preprogrammed symbolic rules or subsymbolic ones to transform one state into the next. Because these systems are incapable of transitioning between the two, they are usually restricted to formalized, narrow problem-solving domains (Haikonen, 2003).</p>



<p>Artificial neural networks are different in that they eschew preprogrammed rules. Like the brain, neural networks use parallel, distributed processing to train systems of subsymbolic nodes to come to recognize complex mathematical functions. Some neural networks, such as recurrent and long short-term memory networks, have nodes capable of persistent activity that is highly analogous to sustained firing (Fig. 9). The enduring activity of these recurrent nodes permits them to cache previous inputs in the form of activated long-term memory (Sherstinsky, 2020). This working memory pool is updated iteratively as recurrent neural nodes gain and lose activation. Similarly, the context window in transformer-based large language models is updated incrementally during training (reading) and inference (writing). Moreover, the tokens within the context window combine their spreading activation energy on each forward pass through the network in a search for the next predicted word. This behavior is similar to the present modelâs conception of multiassociative search, but without the integration of a serial, symbolic component (Reser, 2012). These models may use symbols, such as words, as inputs and outputs but do not contain internal representations of them.</p>



<p>To develop and manipulate true internal representations, AI working memory should be designed to run iterative updating in lockstep with multiassociative search. This is technically feasible in the near term. Because current artificial neural network technology is capable of sustained firing, synaptic potentiation, spreading activation, and Hebbian learning, everything discussed in this article thus far can be implemented by it. If an artificial neural network was engineered to do this in the manner presented in the preceding sections, the resulting system may exhibit some of the human qualities and functionality discussed thus far, including association and prediction formation, algorithm implementation, the compounding of intermediate results, progressive modification, self-directed intelligence, and attentive continuity. The most simplistic implementation is depicted in the figure below. This will be elaborated upon in the next section.</p>







<figure><img data-attachment-id="294" data-permalink="https://aithought.com/blog/traditional-neural-network-bcde-1/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/04/traditional-neural-network-bcde-1.jpg" data-orig-size="2258,1158" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="traditional-neural-network-bcde-1" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/04/traditional-neural-network-bcde-1.jpg?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/04/traditional-neural-network-bcde-1.jpg?w=1024" loading="lazy" width="1024" height="525" src="https://aithoughtcom.files.wordpress.com/2023/04/traditional-neural-network-bcde-1.jpg?w=1024" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/04/traditional-neural-network-bcde-1.jpg?w=1024 1024w, https://aithoughtcom.files.wordpress.com/2023/04/traditional-neural-network-bcde-1.jpg?w=2048 2048w, https://aithoughtcom.files.wordpress.com/2023/04/traditional-neural-network-bcde-1.jpg?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/04/traditional-neural-network-bcde-1.jpg?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/04/traditional-neural-network-bcde-1.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p><strong>Fig. 40.</strong> Oversimplified Neural Network Using Iterative Updating&nbsp;</p>



<p><em>This is a traditional, fully connected neural network with four active input nodes passing activation energy through hidden layers. This pass results in the activation of symbol âfâ in the output layer. This is a naÃ¯ve, vastly oversimplified implementation of the model proposed here that does not feature a global workspace, modularity, or multimodality. Also, in this illustration, the lowercase letters correspond to subsymbolic nodes rather than sets of assemblies that compose representational items (ensembles).</em></p>



<p><strong>5.2 Designing an AI Capable of Iterative Updating</strong></p>



<p>Implementing human-like working memory to a first approximation in an AI system would mean creating a connectionist program that spreads activity from active information, along with incoming activity from its sensors, to search for entailed information from long-term associative memory. Using this found information as a partial update and then repeating this process in a cycle would structure the architecture to be self-organizing.</p>



<p>Iterative updating and multiassociative search may first have to be explicitly programmed into the system using rule-based code until it becomes clear how to design a system where they emerge organically as they do in the brain. Hand-coded or not, they must be defined mathematically and unambiguously to be the basis of computer software. Multiassociative search can be expressed as a function (f) that maps input variables (x) of the current state of working memory to an output variable (y) used to update them. Each network state would be a search for the update applied to the next state. As a formal algorithm, it could be modeled as a stateless Markov process in discrete time, performing non-deterministic search. As a computable function, it could be instantiated by traditional or neuromorphic computer clusters and executed using brain emulation, hierarchical hidden Markov models, stochastic grammars, probabilistic programming languages, neural networks, or others.</p>



<p>The rest of this section will describe how this system could be constructed using an artificial neural network architecture. It could be realized through recurrent networks or spiking ones. Either way, layers of nodes should be used to model the pattern-recognizing assemblies discussed in Section 4.1. As in the brain, each level in the hierarchy must build a statistical model of the regularities in the level below it (Eliasmith, 2013). Hierarchical pattern recognition would be achieved when primitive nodes lower in the hierarchy converge on high-order patterns in higher layers (Hawkins, 2004; Kurzweil, 2012). Figure 41 caricatures how this is actualized by nonlinear transformations.</p>







<figure><img data-attachment-id="519" data-permalink="https://aithought.com/blog/image-27/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/11/image-27.png" data-orig-size="975,515" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-27" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/11/image-27.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/11/image-27.png?w=975" loading="lazy" width="975" height="515" src="https://aithoughtcom.files.wordpress.com/2023/11/image-27.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/11/image-27.png 975w, https://aithoughtcom.files.wordpress.com/2023/11/image-27.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/11/image-27.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/11/image-27.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 41</strong>. Hierarchical Pattern Recognition and Completion</p>



<p><em>Three subsymbolic line segments are detected by early visual cortex. These segments, corresponding to two wings and a beak, map onto three separate nodes. The nodes each fire at another node higher in the visual processing hierarchy that detects the coactivity (conjunction) of all three. In this case, that node detects the presence of a bird flying in the distance. This is an example of convergent pattern recognition made possible by hierarchical nonlinear transformations. Apparently, the prospect of a bird for dinner enters the focus of attention, creating an impulse to grab a bow and arrow. The neural engram for grabbing becomes active and fires action potentials at motor neurons responsible for the muscular contractions of each of the fingers. This is representative of divergent pattern completion. Essential to sending information to and from working memory in the mammalian brain, convergence and divergence should be emphasized in AI neural networks.</em></p>



<p>Nodes at the top of the hierarchy would constitute high-order subsymbolic patterns due to having receptive fields composed of various inputs from multiple layers of mounting complexity. These abstract nodes should be capable of recurrent activity simulating the sustained firing of pyramidal cortical neurons. This would prolong their activity as search parameters and dependency markers, as well as contribute to contextual structuring for extended periods.</p>



<p>To form item-like ensembles, a Hebbian learning rule would be needed to strengthen the weights between frequently coactive nodes. This must work in such a way that groups of highly associated subsymbolic nodes can form symbolic groups (perhaps across layers). These ensembles should be sparse and fuzzy and used to represent invariant, categorical patterns. Such an ensemble would be equivalent to an internal mental representation and should be made capable of enduring coactivity with other items. These items should be coactive within a graph-structured global workspace. Engineering such a workspace could conceivably necessitate an analog of neural binding (i.e., Klimesch et al., 2010) and synchronized, reentrant oscillations (Edelman, 2004) to integrate (i.e., Tononi, 2004) and unify multiple ensembles into a singular situational representation. This would amount to an emulation of the FoA.</p>



<p>When the simulated sustained firing abates, nodes should subsequently simulate synaptic potentiation. This would enable the network to maintain pertinent information in an emulated short-term store as cached assets. Nodes potentiated in this way would continue to bias the multiassociative workspace until they are either promoted back to the FoA or demoted back to inert long-term memory.</p>



<p>The AIâs simulated FoA and short-term memory stores would undergo iterative updating such that the overlap of persistent information is congruent with Figure 12 and information replacement is congruent with Figure 27. It is imperative that the FoA be designed to cache not only external stimuli but also internal concepts as in Figure 17. Information selection should be guided by multiassociative search as in Figure 26. Each update would amount to a truth-preserving associative transition in the processing stream underwritten by structural properties of the network, which in turn are based on past statistical analyses of reliable patterns from the physical world.</p>



<p><strong>5.3 Modularity, Modality, and Imagery in AI</strong></p>



<p>An implementation of this system would necessitate modular specialization. Each module would correspond to a compartmentalized neural network meant to simulate a different cortical or subcortical area of the mammalian brain. These separate networks would interconnect to form a single dynamical system. Coordinating this assemblage to implement the multiassociative algorithm would be a considerable engineering problem. Given that the human brain accomplishes this task, human neuroscience should be used as an archetype. Thus, the system could be constructed biomimetically and inspired by general neuroanatomical connectivity.</p>



<p>Not only would the nodes of each modular network be organized hierarchically, but the connections between modules would establish an even larger hierarchical structure. This stratified organization, beginning from unimodal networks and progressing to densely conjunctive multimodal networks, would mirror the gradient seen from sensory cortices to association cortices in mammals. Networks higher in the hierarchy would refer to denser space-time conjunctions and multidimensional levels of abstraction. The networks could be designed to emulate specific human cortical modules if they drew inspiration from anatomical connectivity. This would emphasize intrinsic, extrinsic, short-range, and long-range connections, along with the relevant proximities and proportionalities. Multimodal areas that may be pivotal to higher-order abstractions and, therefore, in need of being reverse-engineered in this way include the angular gyrus, Wernickeâs area, Brocaâs area, the dorsolateral PFC, the medial PFC, the supplementary motor area, and the frontal pole.</p>







<figure><img data-attachment-id="602" data-permalink="https://aithought.com/blog/image-13-2/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/12/image-13.png" data-orig-size="975,627" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-13" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/12/image-13.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/12/image-13.png?w=975" loading="lazy" width="975" height="627" src="https://aithoughtcom.files.wordpress.com/2023/12/image-13.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/12/image-13.png 975w, https://aithoughtcom.files.wordpress.com/2023/12/image-13.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/12/image-13.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/12/image-13.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 42.</strong> A Hierarchical Artificial Neural Network Structured to Integrate Information Across Modules</p>



<p><em>Each enclosed set of nodes represents a specialized neural network module wired to receive a different input modality. Networks at the bottom (left) of the hierarchy take input of a single modality from the environment. Other networks take input from multiple neural networks below them in the hierarchy. Spreading network activity would oscillate between the top and bottom of the hierarchy while allowing reentrant feedback (bidirectional signal exchange) within and between networks. This figure features 24 networks, each with 19 nodes. An actual build would necessitate dozens of networks, each with millions of nodes.</em></p>



<p>Each modular network in the system would take inputs from associative areas (global working memory) and use them to create their own unique corresponding set of outputs with the potential to contribute to the next update. Some of these modules may produce imagery. To understand how imagery can benefit AI, letâs discuss how it is formed in the brain. Neurons in sensory cortex respond to perceptual features from sensory input and fuse them into images known as topographic mappings (Moscovich et al., 2007). This imagery holds metric and compositional (precategorical) information. In addition to creating topographic mappings from patterns recognized in the external environment (bottom-up), sensory areas are thought to combine divergent (Fig. 41), top-down inputs from association cortices to generate internally derived scenery (Mellet et al., 1998; Miyashita, 2005). Generally, brain imaging research supports the idea that imagining something in the âmindâs eyeâ activates maps in early perceptual networks (Damasio, 1989; Hasegawa et al., 1998; Ohbayashi et al., 1999).</p>



<p>The sensory networks of our AI system should similarly construct topographic maps (retinotopic for vision, tonotopic for sound, etc.). There are already reliable methods for using neural networks to generate such âself-organizingâ maps (Hameed et al., 2019), and imagery generation by inverse neural networks is common today (Byeon et al., 2018). By creating a series of internally generated maps to match the iterative updating taking place in association areas, this system could produce iterated sequences of mental images. During this process, the topographic maps may use low-order perceptual knowledge (from prior probability) to depict associative relationships between higher-order items held in persistent activity. In so doing, the mental imagery that is formed may introduce valuable new informational content into working memory (such as features or objects incidental to the image itself). In other words, thinking and reasoning can be informed by logical information contained in visual and acoustic imagery.</p>



<p>As a given set of items in the FoA is updated, the set of unimodal, lower-order sensory maps held in synchrony with it would be updated correspondingly (Reser, 2011, 2012, 2013). In other words, after a mental image is formulated, it will likely be replaced by another image that uses many of the same working memory items as constraining parameters. Consecutive maps formed in this way could infuse video-like continuity into the imagery and could amount to a type of synthetic imagination. This form of hierarchical crosstalk between association and sensory areas, marked by mutual interactions (i.e., reciprocal causation), may allow an AI system to use mental imagery to see, hear, and thereby model hypothetical situations. This has been termed âprogressive imagery modificationâ (Reser, 2016) and is depicted in Figure 43.</p>







<figure><img data-attachment-id="604" data-permalink="https://aithought.com/blog/image-15-2/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/12/image-15.png" data-orig-size="975,548" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-15" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/12/image-15.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/12/image-15.png?w=975" loading="lazy" width="975" height="548" src="https://aithoughtcom.files.wordpress.com/2023/12/image-15.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/12/image-15.png 975w, https://aithoughtcom.files.wordpress.com/2023/12/image-15.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/12/image-15.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/12/image-15.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 43.</strong> Progressive Imagery Modification</p>



<p><em>At time 1, items B, C, D, and E are active in association networks. The spreading activation from these items provides independent yet interactive top-down bias signals to primary visual networks where a composite topographic map is built based on prior experience with these items. This gestalt sketch will introduce compatible content to working memory. Hence, at time 2, salient features created by the map from time 1 spread activation energy up the hierarchy, converging on the assemblies for item F. Item B becomes inactive while items C, D, E, and F diverge back down the hierarchy toward the primary visual network. The process repeats itself. Because of iterative updating, this process can create a logically connected series of related images.</em></p>



<p>Brain researchers believe that sensory areas deliver information in the form of fleeting sensory maps, whereas association areas deliver lasting perceptual expectations in the form of templates and that these interact to construct higher-order cognitive processes (Hawkins, 2004; Carpenter &amp; Grossberg, 2003). Progressive imagery modification (Fig. 43) could play an instrumental role in this reciprocal signaling between early, bottom-up sensory networks (where activity is metric, topographic, and transient) and top-down association networks (where activity is abstract, conceptual, and persistent) (Christophel et al., 2017). It could even enable an AI system to develop the kind of interplay between the central executive and the visuospatial sketchpad characteristic of the Baddeley (2000, 2007) model of working memory (Fig. 4). Further, this process of iterative modification could take place in other modules, such as language areas (where it is involved in the construction of speech), motor areas (where it is involved in action sequencing), and prefrontal areas (where it is involved in planning).</p>



<p>This general design could form the basis of a security precaution promoting AI safety and alignment. To human observers, the representation of knowledge in neural networks is distributed in such a complex manner that it is mostly inscrutable (Castelvecchi, 2016). This lack of transparency heightens the fear of superintelligent AI because it would be impossible to tell whether the AI was secretly harboring hostile motives (Bostrom, 2014). However, if the system was inherently obligated to build a composite topographic map of each state of working memory to initiate and inform the next state, then these maps could be displayed on a monitor for humans (or another AI) to view. A history of all visual and auditory maps could be saved to an external memory drive. This would ensure that all the AI systemâs mental imagery and inner speech are recorded for later inspection and interpretation. Hostile intentions would not have to be deciphered; they would be plain to see.</p>



<p><strong>5.4 How to Train an AI that Employs Iterative Updating</strong></p>



<p>The architecture described in the last three sections would not be limited to learning from discrete batches of curated input but could be exposed to continuous data streams from real-world scenarios that unfold through time. Also, the system would not suspend its activity every time it finishes a task. Rather, it would exhibit continuous, endogenous processing. The systemâs ontological and epistemological development would benefit from embodied, real-time, robotic interactions within physical, social, and intellectual training conditions. During exposure to these conditions, it would engage in unsupervised learning of time-series patterns from unlabeled data on a constant basis.</p>



<p>This would necessitate a compatible reward function to guide learning, reinforcement, and credit assignment. Said function should be based on the circuitry of the mammalian dopamine system, including the ventral tegmentum and nucleus accumbens. In mammals, novel appetitive or aversive events increase dopamine release. This ensures they are driven by predictors of food, sex, and pain. Representations of rewarding, punishing, salient, uncertain, or unpredicted events elicit dopaminergic activity in all vertebrates. This increased concentration of ambient dopamine leads to increases in sustained firing (Seamans &amp; Yang, 2004). Thus, dopamine neuromodulation drives an animalâs priorities, allowing them to prolong information about unique opportunities and threats (Seamans &amp; Robbins, 2010).</p>



<p>An analog of the dopamine systemâs network would be needed to remember and recognize appetitively stimulating combinations of items occurring in working memory and prioritize them by sustaining their activity (Fig. 46). This would allow groupings with constructive incentive value to bias processing for extended periods. If we want a superintelligent AI that can further human understanding, then we should design its appetitive system to be driven to mine information from literature and databases and use it to generate new associations between ensembles. Thus, this system should latch on to unprocessed frontiers in its knowledge space (sets of unreconciled items with incentive appeal), amounting to an algorithmic form of curiosity.</p>



<p>Functional, preset pathways (akin to an infantâs instinct to grasp something when its palm is touched) should be built into the direct connections between sensory (input) and motor (output) areas. This innate programming could come in the form of already-trained neural network modules that perform practical cognitive tasks (e.g., scene classification, paragraph comprehension, or natural language generation) embedded into the bottom of the hierarchy of this much more extensive network. For instance, a large language model could be used as a simulacrum of Brocaâs area (the human language area) and used to inform semantic development in the network at large. Such modules could orient the system toward effective performance on basic tasks, just as reflexes and prepared learning set developing animals on a track toward reproductive success. The machine would use operant feedback about its performance on these tasks to bootstrap learning.</p>



<p>Maturation of the AIâs neural network should approximate that observed in the human cortex. It should start by simulating the brain of an infant (Fuster, 2015). Initially, motor output should not be driven by higher-order association areas but rather by low-order sensory and motor modules. As low-level responses are practiced and refined, and pertinent algorithms are developed through trial and error (see Section 4.4), association networks could be slowly interposed between sensory and motor networks. As in the mammalian brain (Huttenlocher &amp; Dabholkar, 1997), sensory and motor areas should mature (myelinate) early in development, and association areas should mature late. Similarly, the capacity for persistent activity should start low but increase over developmental time.</p>



<p>Postponing the initialization of sustained firing would allow the formation of low-order associations between causally linked events that typically occur close together in time. This would focus the system on easy-to-predict aspects of its reality (e.g., correlations between occurrences in close temporal proximity). The consequent learning would erect a reliable scaffolding of highly predictable associations that could be used to substantiate higher-order, time-delayed associations later in development (Reser, 2016). In other words, the proportion of updating from one state to the next (Fig. 18) would start very high. This would be reversed over weeks to years as an increasing capacity for persistent working memory activity would be folded into the system.</p>



<p>A working memory store that uses iterative updating would be used to establish associations between related clusters of stimuli that appear close together in time from books, articles, lectures, speeches, videos, and experiences. Then, as the length of sustained firing is increased, temporally proximate contextual representations could be coactivated with other less proximate ones when multiassociative search deems them to be highly probabilistically related (i.e., they share a logical or analogical connection). Thus, two events that were never temporally local in the environment could be selected for joint iterative processing within the FoA (Fig. 29). This kind of reconciliation between separate (previously discrete) iterative threads could build and constantly retune a dynamic knowledge base of interconnected representations. After adequate training, the duration of persistent activity could be adjusted to outstrip that of humans, allowing the system to capture extremely long-term causal dependencies, resulting in the perception of high-order abstractions that would be imperceptible to humans.</p>



<p>Unlike biological brains, this system would be scalable (Fig. 44). There are straightforward ways to amplify the working memory of such a system beyond the physiological limitations of the human brain. These include:</p>



<ol>
<li>Increasing the total number of nodes in LTM</li>



<li>Increasing the number of nodes capable of being coactivated in the short-term store</li>



<li>Increasing the number of items capable of being coactivated in the FoA</li>



<li>Increasing the length of time these can remain active (increasing the half-life and decreasing the rate of updating (Fig. 19)</li>



<li>Increasing the number of tightly coupled iterations (thoughts) that can occur before attention is disrupted (Fig. 21)</li>
</ol>







<figure><img data-attachment-id="323" data-permalink="https://aithought.com/blog/ai-agent-5-1/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/05/ai-agent-5-1.jpg" data-orig-size="1260,602" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1683126284&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="ai-agent-5-1" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/05/ai-agent-5-1.jpg?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/05/ai-agent-5-1.jpg?w=1024" loading="lazy" width="1024" height="489" src="https://aithoughtcom.files.wordpress.com/2023/05/ai-agent-5-1.jpg?w=1024" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/05/ai-agent-5-1.jpg?w=1024 1024w, https://aithoughtcom.files.wordpress.com/2023/05/ai-agent-5-1.jpg?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/05/ai-agent-5-1.jpg?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/05/ai-agent-5-1.jpg?w=768 768w, https://aithoughtcom.files.wordpress.com/2023/05/ai-agent-5-1.jpg 1260w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p><strong>Fig. 44.</strong> Four Examples of Working Memory Activity Within the Focus of Attention</p>



<p><em>The figure compares the number of items and rate of updating between a human with a limited-capacity working memory, a human with a limited attentional store, a typical human, and a superintelligent AI agent. The AI agent can maintain a larger number of nodes over a longer period, ensuring that its perceptions and actions will be informed by a larger amount of recent information.</em></p>



<p>Under conditions of imperfect or incomplete information, the longer the backward memory span and the larger the number of related events that can be used in multiassociative search, the less uncertainty (information entropy) there is about the present state. However, in information theory, the length beyond which a backward memory span stops providing predictive information is known as the correlation length (Shannon, 1951; Stone, 2015). The working memory of a species can be seen as having a correlation length beyond which there is little predictive value to be had given its ecological niche. The long correlation length of the human FoA was likely permitted by our cognitively demanding foraging style, selection for social cognition, and the supervised learning, error feedback, and large number of training examples provided by prolonged and intensive maternal investment (Reser, 2006). However, there is no reason to believe that the length or breadth of the human FoA has been optimized for systemizing reality. It was probably constrained by several evolutionary factors that would not apply to computers.</p>







<figure><img data-attachment-id="408" data-permalink="https://aithought.com/blog/ai-comparison-5/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/09/ai-comparison-5.jpg" data-orig-size="4161,3181" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ai-comparison-5" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/09/ai-comparison-5.jpg?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/09/ai-comparison-5.jpg?w=1024" loading="lazy" width="1024" height="782" src="https://aithoughtcom.files.wordpress.com/2023/09/ai-comparison-5.jpg?w=1024" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/09/ai-comparison-5.jpg?w=1024 1024w, https://aithoughtcom.files.wordpress.com/2023/09/ai-comparison-5.jpg?w=2046 2046w, https://aithoughtcom.files.wordpress.com/2023/09/ai-comparison-5.jpg?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/09/ai-comparison-5.jpg?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/09/ai-comparison-5.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p><strong>Fig. 45</strong>. Venn Diagrams of Working Memory in Different Systems</p>



<p><em>These diagrams depict informational overlap between states of working memory in a span of ten seconds. The diagrams on the left use the format from Figure 12, while those on the right use the format from Figure 11. Diagram 1 shows zero overlap between working memory at times 1 and 2. This would make it more difficult for system 1, a hypothetical mouse, to make associations between events separated by the delay. For example, calling this mouseâs name and feeding it 10 seconds later may not condition it to come when called, whereas feeding it two seconds later might. Training an AI should involve a maturational process where the system begins learning with a minimal working memory span (e.g., Diagram 1) before gradually developing a superhuman capacity for working memory span (Diagram 4) as formative experiences accumulate.</em></p>



<p>Prolonging the duration of persistent activity will allow each search to be more specific and informed. This is because searches would be apprised by a larger number of specifications that stretch further back in time. It would also ensure that the system is less likely to allow crucial intermediate solutions to decay from working memory coactivity (i.e., a cache miss) before they are needed to form higher-order, compound inferences. The âthoughtsâ of such a system would be lengthy, highly focused, and tightly interwoven.</p>



<p>Now may be the time to start building large, state-of-the-art, iterative updating networks and training them as one would train a child with the expectation that aspects of intelligence will emerge. It is hoped that through exposure to experiences with systematic patterns, a system like that described above would construct an associative network capable of producing updates to its states of working memory that build functionally on previous states. This could lead to the capacity to make valid associative connections between probabilistically related events (Fig. 29), resulting in the discovery of relationships obscured by separations in space and delays in time. Simulating iterative updating and multiassociative search and enhancing them beyond human capacities could be instrumental in the effort to construct AI capable of common sense, insight, creativity, machine consciousness, and superintelligence.</p>



<p><strong>5.5 Discussion and Conclusions</strong></p>



<p>This article aims to introduce an internally consistent framework for understanding how neural activity gives rise to complex thought. It is intended to inspire more detailed hypotheses, experimental tests, and machine implementations. Previous models of working memory have attributed various high-level cognitive functions to the central executive (e.g., updating of items, coordination of modules, shifting between tasks, selective attention, gating, the construction of imagery, and others). Because the neural substrate of these advanced operations has never been delineated, the central executive remains a mysterious black box. This article has supported the case that executive functions emerge from collective processing interactions among specialized subsystems guided by iterative updating. If shown to have a tenable neural basis by future research, the concepts introduced in this article (Table 4) may amount to a viable alternative to the notion of the central executive found in other models. In so doing, they may provide an organizing mechanism for self-regulating thought in AI.</p>







<figure><img data-attachment-id="605" data-permalink="https://aithought.com/blog/screenshot-4/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/12/screenshot-4.png" data-orig-size="1026,721" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-4" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/12/screenshot-4.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/12/screenshot-4.png?w=1024" loading="lazy" width="1024" height="719" src="https://aithoughtcom.files.wordpress.com/2023/12/screenshot-4.png?w=1024" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/12/screenshot-4.png?w=1024 1024w, https://aithoughtcom.files.wordpress.com/2023/12/screenshot-4.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/12/screenshot-4.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/12/screenshot-4.png?w=768 768w, https://aithoughtcom.files.wordpress.com/2023/12/screenshot-4.png 1026w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p><strong>Table 4.</strong> Definition of Terms Used and Introduced in This Article</p>



<p>This article reconciled iterative updating with traditional models of working memory, including those discussed in the literature review. However, it can similarly be integrated with a variety of compatible frameworks that model the dynamics of item-like constructs, including those in Table 5. These models, along with many others, provide detailed mechanistic explanations for critical neurocognitive components underspecified by the present model.</p>



<figure><img data-attachment-id="606" data-permalink="https://aithought.com/blog/screenshot-5/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/12/screenshot-5.png" data-orig-size="1191,661" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-5" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/12/screenshot-5.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/12/screenshot-5.png?w=1024" loading="lazy" width="1024" height="568" src="https://aithoughtcom.files.wordpress.com/2023/12/screenshot-5.png?w=1024" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/12/screenshot-5.png?w=1024 1024w, https://aithoughtcom.files.wordpress.com/2023/12/screenshot-5.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/12/screenshot-5.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/12/screenshot-5.png?w=768 768w, https://aithoughtcom.files.wordpress.com/2023/12/screenshot-5.png 1191w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p><strong>Table 5.</strong> Other Models and Frameworks That Can Be Integrated with The Present Model</p>



<p>Working memory items in the FoA have been considered to be isomorphic with the contents of consciousness (Baars &amp; Franklin, 2003; Buchsbaum, 2013). This suggests that the subjects of conscious thought are held in working memory and operate according to the same (or similar) rules and capacity limitations. In the classic paradigm for working memory testing, subjects can retain approximately four items in mind. However, they are holding much additional declarative content. This is because they also maintain the task requirements, active sensory perceptions, and ongoing personal thoughts (which may be limited by cognitive load). The iterative updating function applies to all this conscious content, not just to the four items described by Cowan (2017) and others. The previous figures in this article have mainly used only two working memory stores (the FOA and short-term memory). Figure 46 uses an arbitrarily larger number of functionally specialized stores as an alternative to indicate that items may exist along a graded continuum of activation.</p>







<figure><img data-attachment-id="80" data-permalink="https://aithought.com/21-imagery-and-behavior-in-the-iterative-updating-model-of-working-sensory-and-short-term-memory/" data-orig-file="https://aithoughtcom.files.wordpress.com/2022/03/21.-imagery-and-behavior-in-the-iterative-updating-model-of-working-sensory-and-short-term-memory.jpg" data-orig-size="1431,780" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="21.-imagery-and-behavior-in-the-iterative-updating-model-of-working-sensory-and-short-term-memory" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2022/03/21.-imagery-and-behavior-in-the-iterative-updating-model-of-working-sensory-and-short-term-memory.jpg?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2022/03/21.-imagery-and-behavior-in-the-iterative-updating-model-of-working-sensory-and-short-term-memory.jpg?w=1024" loading="lazy" width="1024" height="558" src="https://aithoughtcom.files.wordpress.com/2022/03/21.-imagery-and-behavior-in-the-iterative-updating-model-of-working-sensory-and-short-term-memory.jpg?w=1024" alt="" srcset="https://aithoughtcom.files.wordpress.com/2022/03/21.-imagery-and-behavior-in-the-iterative-updating-model-of-working-sensory-and-short-term-memory.jpg?w=1024 1024w, https://aithoughtcom.files.wordpress.com/2022/03/21.-imagery-and-behavior-in-the-iterative-updating-model-of-working-sensory-and-short-term-memory.jpg?w=150 150w, https://aithoughtcom.files.wordpress.com/2022/03/21.-imagery-and-behavior-in-the-iterative-updating-model-of-working-sensory-and-short-term-memory.jpg?w=300 300w, https://aithoughtcom.files.wordpress.com/2022/03/21.-imagery-and-behavior-in-the-iterative-updating-model-of-working-sensory-and-short-term-memory.jpg?w=768 768w, https://aithoughtcom.files.wordpress.com/2022/03/21.-imagery-and-behavior-in-the-iterative-updating-model-of-working-sensory-and-short-term-memory.jpg 1431w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p><strong>Fig. 46.</strong> Imagery and Behavior in the Iterative Updating Model</p>



<p><em>Iteratively updated items in working memory interact with sensory cortices to progressively construct mental imagery. They also interact with motor cortices to progressively construct behavior. In the next state, the items in each working memory store will undergo partial replacement. The parameters used in the sensory and motor cortices will reflect this change, making their output an advancement on their previous output. This mirroring of each update will permit them to construct progressive imagery and behavior. Related cognitive processes are included as arrows. The dopamine system (ventral tegmentum) uses inputs from the amygdala and nucleus accumbens (N.A.) to determine which patterns of items match internal incentive templates and thus should be sustained.</em></p>



<p>âHigher-orderâ theories of consciousness hold that conscious thought arises when a mental state is concerned with a previous mental state. This includes thoughts about perceptions and thoughts about thoughts (Rosenthal, 2004). Following this line of reasoning, thoughts that iterate from previous thoughts exhibit a backward-referential quality and could be considered âhigher-order thoughts.â Because of its role in generating a continual production line of higher-order thoughts, iterative updating should be considered a candidate for the neural basis of consciousness. It ensures that the train of thought does not stop and go in discrete steps but is instead propelled continuously by the items that endure through time. While individual items may exit the FoA within seconds, the shared content across successive states keeps the proverbial train on track and sustains associative connections that interlink the advancing sequence of thoughts.</p>



<figure><img data-attachment-id="607" data-permalink="https://aithought.com/blog/screenshot-6/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/12/screenshot-6.png" data-orig-size="1196,734" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-6" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/12/screenshot-6.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/12/screenshot-6.png?w=1024" loading="lazy" width="1024" height="628" src="https://aithoughtcom.files.wordpress.com/2023/12/screenshot-6.png?w=1024" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/12/screenshot-6.png?w=1024 1024w, https://aithoughtcom.files.wordpress.com/2023/12/screenshot-6.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/12/screenshot-6.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/12/screenshot-6.png?w=768 768w, https://aithoughtcom.files.wordpress.com/2023/12/screenshot-6.png 1196w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p><strong>Table 6. </strong>Fundamental Features of the Iterative Updating Model</p>



<p>In his book <em>The River of Consciousness</em> (2017), Oliver Sacks asks, âBut how then do our frames, our momentary moments, hold together? How, if there is only transience, do we achieve continuity?â This article postulates that our moments overlap in their set of active representations and that this ongoing confluence results in a flowing progression of states. After asking the question, Sacks quotes William James. Each thought, in Jamesâs words, is an owner of the thoughts that went before and âdies owned, transmitting whatever it realized as itself to its own later proprietor.â James expounds further on this subject employing the analogy of a stream:</p>



<blockquote>
<p>âConsciousness, then, does not appear to itself chopped up in bits. Such words as âchainâ or âtrainâ do not describe it fitly as it presents itself in the first instance. It is nothing jointed; it flows. A âriverâ or a âstreamâ are the metaphors by which it is most naturally described. In talking of it hereafter let us call it the stream of thought, of consciousness, or of subjective life. [â¦] As the brain-changes are continuous, so do all these consciousnesses melt into each other like dissolving views. Properly they are but one protracted consciousness, one unbroken stream.â</p>



<p>William James (1890, p. 239)</p>
</blockquote>







<figure><img data-attachment-id="608" data-permalink="https://aithought.com/blog/image-16-2/" data-orig-file="https://aithoughtcom.files.wordpress.com/2023/12/image-16.png" data-orig-size="975,548" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-16" data-image-description="" data-image-caption="" data-medium-file="https://aithoughtcom.files.wordpress.com/2023/12/image-16.png?w=300" data-large-file="https://aithoughtcom.files.wordpress.com/2023/12/image-16.png?w=975" loading="lazy" width="975" height="548" src="https://aithoughtcom.files.wordpress.com/2023/12/image-16.png?w=975" alt="" srcset="https://aithoughtcom.files.wordpress.com/2023/12/image-16.png 975w, https://aithoughtcom.files.wordpress.com/2023/12/image-16.png?w=150 150w, https://aithoughtcom.files.wordpress.com/2023/12/image-16.png?w=300 300w, https://aithoughtcom.files.wordpress.com/2023/12/image-16.png?w=768 768w" sizes="(max-width: 975px) 100vw, 975px"></figure>



<p><strong>Fig. 47.</strong> Schematic Representation of Ongoing Iteration in the FoA and Short-term Memory Store</p>



<p><em>This graphic expands on previous figures, incorporating a larger number of the present modelâs theoretical features. These include the following: (1) the number of items coactive in the FoA (white spheres) at any point in time varies between three and five, (2) the percentage of updating in the FoA varies between 25% and 100%, (3) the order of entry into the FoA does not determine the order of exit, (4) items that exit the FoA briefly enter the short-term store (gray spheres) before deactivating completely (black spheres), and (5) items that have exited the FoA are capable of reentering the FoA.</em></p>



<p>The present model bears a resemblance to Jamesâs conception of a âstream of consciousness.â A stream is a distribution of points that slides through space and time. Figure 47 extends the activity schematized in this articleâs other figures over 18 points in time. This results in a depiction of brain activity, working memory, and thought that, shifting gradually, appears very much like a stream. The iterative updating of working memory sustains and shapes the flow of thought. Each new update is an influx of information that acts like a tributary, merging and interacting with the larger current of consciousness, contributing to its rate and direction. Simulating this stream within a computer could play an integral role in enabling an artificial agent to experience a cognitive continuum, traverse the expanse of consciousness, and explore the state-space of thought.</p>



<p>.</p>



<p><strong>References</strong></p>



<p>Anderson, J. R. (1983). A spreading activation theory of memory. Journal of Verbal Learning and Verbal Behavior, 22(3), 261-295.</p>



<p>Asok, A., Leroy, F., Rayman, J. B., &amp; Kandel, E. R. (2019). Molecular mechanisms of the memory trace. Trends in Neurosciences, 42(1), 14-22.</p>



<p>Atkinson, R. C., &amp; Shiffrin, R. M. (1968). Human memory: A proposed system and its control processes. In Spence, K. W., &amp; Spence, J. T., The psychology of learning and motivation (Volume 2), pp. 89-195. New York: Academic Press.</p>



<p>Atkinson, R. C., &amp; Shiffrin , R. M. (1969). Storage and retrieval processes in long-term memory. Psychological Review, 76(2), 179-193.</p>



<p>Averell, L., &amp; Heathcote, A. (2011). The form of the forgetting curve and the fate of memories. Journal of Mathematical Psychology, 55(1), 25-25.</p>



<p>Baars, B. J., &amp; Franklin, S. (2003). How conscious experience and working memory interact. Trends in Cognitive Sciences, 7, 166-172.</p>



<p>Baars, B. J. (2007). A framework. Baars, B. J., &amp; Gage, N. M. (Eds.), Cognition, brain, and consciousness: Introduction to cognitive neuroscience, p. 30. London: Academic Press.</p>



<p>Baars, B. J., &amp; Franklin, S. (2007). An architectural model of conscious and unconscious brain functions: Global Workspace Theory and IDA. Neural Networks, 20(9), 955-961.</p>



<p>Baddeley, A. (1986). Working memory. Oxford, UK: Clarendon Press.</p>



<p>Baddeley, A. D. (2000). The episodic buffer: A new component of working memory? Trends in Cognitive Science, 4, 417-423.</p>



<p>Baddeley, A. D., Hitch, G. J., &amp; Allen, R. J. (201). From short-term store to multicomponent working memory: The role of the modal model. Memory &amp; Cognition, 45, 575-588.</p>



<p>Baddeley, A. D. (2007). Working memory, thought and action. Oxford University Press.</p>



<p>Baddeley, A. D., &amp; Hitch, G. J. (1994). Developments in the concept of working memory. Neuropsychology, 8(4), 485-493.</p>



<p>Baddeley, A. D., &amp; Hitch, G. J. (1974). Working memory. In Bower, G. A. (Ed.), Recent advances in learning and motivation, Vol. 8, pp. 47-89. New York: Academic Press.</p>



<p>Baddeley, A. D. (2000). The episodic buffer: A new component of working memory? Trends in Cognitive Sciences, 4(11), 417-423.</p>



<p>Baddeley, A. D. (2012). Working memory: Theories, models and controversies. Annual Review of Psychology, 63, 1-29.</p>



<p>Bargh, J. A., &amp; Chartrand, T. L. (2000). Studying the mind in the middle: A practical guide to priming and automaticity research. In Reis, H., &amp; Judd, C. (Eds.), Handbook of research methods in social psychology, pp. 1-39. New York: Cambridge University Press.</p>



<p>Baronett, S. (2008). Logic. Upper Saddle River, NJ: Pearson Prentice Hall.</p>



<p>Bostrom N. (2014). Superintelligence: Paths, dangers, strategies. Oxford University Press.</p>



<p>Botvinick, M. M. (2008). Hierarchical models of behavior and prefrontal function. Trends in Cognitive Sciences, 12(5), 201-208.</p>



<p>Botvinick, M. M., &amp; Plaut, D. C. (2006). Short-term memory for serial order: A recurrent neural network model. Psychological Review, 113(2), 201-233.</p>



<p>Braver, T. S., &amp; Cohen, J. D. (2000). On the control of control: The role of dopamine in regulating prefrontal function and working memory. In Monsell, S., &amp; Driver, J. (Eds.), Attention and performance XVIII: Control of cognitive processes, pp. 713-737. Cambridge, MA: The MIT Press.</p>



<p>Broadbent, D. (1958). Perception and communication. London: Pergamon Press.</p>



<p>Brydges, C., Gignac, G. E., &amp; Ecker, U. K. H. (2018). Working memory capacity, short-term memory capacity, and the continued influence effect: A latent-variable analysis. Intelligence, 69, 177-122.</p>



<p>Buchsbaum, B. R. (2013). The role of consciousness in the phonological loop: Hidden in plain sight. Frontiers in Psychology, 4, 496.</p>



<p>Butlin, P., et al. (2023). Consciousness in artificial intelligence: Insights from the science of consciousness. arXiv:2308.08708</p>



<p>Byeon, W., Wang, Q., Srivastava, R. K., &amp; Koumoutsakos, P. (2018). ContextVP: Fully context-aware video prediction. The European Conference on Computer Vision (ECCV), pp. 753-769.</p>



<p>Carpenter, G. A., &amp; Grossberg, S. (2003). Adaptive resonance theory. In Arbib, M. A. (Ed.), The handbook of brain theory and neural networks, Second Edition, pp. 87-90. Cambridge, MA: The MIT Press.</p>



<p>Castelvecchi, D. (2016). Can we open the blackbox of AI: Artificial intelligence is everywhere. But before scientists trust it, they first need to understand how machines learn. Nature, 538, 7623.</p>



<p>Chein, J. M., &amp; Fiez, J. A. (2010). Evaluating models of working memory through the effects of concurrent irrelevant information. Journal of Experimental Psychology: General, 139, 117-137.</p>



<p>Cheng, P. C., &amp; Holyoak, K. J. (2008). Pragmatic reasoning schemas. In Adler, J. E., &amp; Rips, L. J. (Eds.), Reasoning: Studies of human inference and its foundations, pp. 827-842. Cambridge University Press.</p>



<p>Chia, W. J., Hamid, A. I. A., &amp; Abdullah, J. M. (2018). Working memory from the psychological and neurosciences perspectives: A review. Frontiers in Psychology, 27.</p>



<p>Christophel, T. B., Klink, P. C., Spitzer, B., Roelfsema, P. R., &amp; Haynes, J. (2017). The distributed nature of working memory. Trends in Cognitive Sciences, 21(2), 111-124.</p>



<p>Cohen, G. (2000). Hierarchical models in cognition: Do they have psychological reality? European Journal of Cognitive Psychology, 12(1), 1-36.</p>



<p>Collins, A. M., &amp; Loftus, E. F. (1975). A spreading-activation theory of semantic processing. Psychological Review, 82(6), 407-428.</p>



<p>Comer, D. (2017). Essentials of computer architecture. New York: Chapman and Hall.</p>



<p>Constantinidis, C., Funahashi, S., Lee, D., Murray, J. D., Qi, X., Wang, M., &amp; Arnsten, A. F. T. (2018). Persistent spiking activity underlies working memory. Journal of Neuroscience, 38(32), 7020-7028.</p>



<p>Cowan, N. (1984). On short and long auditory stores. Psychological Bulletin, 96(2), 341-370.</p>



<p>Cowan, N. (2001). The magical number 4 in short-term memory: A reconsideration of mental storage capacity. Behavioral and Brain Sciences, 24, 87-185.</p>



<p>Cowan, N. (2005). Working memory capacity. New York: Psychology Press.</p>



<p>Cowan, N. (1988). Evolving conceptions of memory storage, selective attention, and their mutual constraints within the human information-processing system. Psychological Bulletin, 104(2), 163-191.</p>



<p>Cowan, N. (2009). What are the differences between long-term, short-term, and working memory? Progress in Brain Research, 169, 323-338.</p>



<p>Cowan, N. (2011). The focus of attention as observed in visual working memory tasks: Making sense of competing claims. Neuropsychologia, 49, 1401-1406.</p>



<p>Cowan, N. (2017). The many face of working memory and short-term storage. Psychonomic Bulletin &amp; Review, 24(4), 1158-1170.</p>



<p>Crick, F., &amp; Koch, C. (2003). A framework for consciousness. Nature Neuroscience, 6(2), 119-126.</p>



<p>DâEsposito, M., &amp; Postle, B. R. (2015). The cognitive neuroscience of working memory. Annual Review of Psychology, 66, 115-142.</p>



<p>Damasio, A. R. (1989). Time-locked multiregional retroactivation: A systems level proposal for the neural substrates of recall and recognition. Cognition, 33, 25-62.</p>



<p>Debanne, D., Inglebert, Y., &amp; Russier, M. (2019). Plasticity of intrinsic neuronal excitability. Current Opinion in Neurobiology, 54, 73-82.</p>



<p>Dehaene, S. (2020). How we learn: Why brains learn better than any machineâ¦ for now. New York: Penguin Random House.</p>



<p>Ecker, U. K., Oberauer, K., &amp; Lewandowsky, S. (2014). Working memory updating involves item-specific removal. Journal of Memory and Language, 74, 1-15.</p>



<p>Edelman, G. (2004). Wider than the sky. Yale University Press.</p>



<p>Eriksson, J., Vogel, E. K., Lansner, A., Bergstrom, F., Nyberg, L. (2015). Neurocognitive architecture of working memory. Neuron, 88(1), 33-46.</p>



<p>Fuji, H., Ito, H., Aihara, K., Ichinose, N., &amp; Tsukada, M. (1998). Dynamical Cell Assembly Hypothesis â Theoretical possibility of spatio-temporal coding in the cortex. Neural Networks, 9(8),1303-1350.</p>



<p>Funahashi, S., Bruce, C. J., Goldman-Rakic, P. S. (1993). Dorsolateral prefrontal lesions and oculomotor delayed-response performance: evidence for mnemonic âscotomasâ. Journal of Neuroscience, 13(4), 1479-1497.</p>



<p>Funahashi, S. (2007). The general-purpose working memory system and functions of the dorsolateral prefrontal cortex. In Osaka, N., Logie, R. H., &amp; DâEsposito, M. (Eds.), The cognitive neuroscience of working memory, pp. 213-230. Oxford University Press.</p>



<p>Fuster, J. M. (2002a). Frontal lobe and cognitive development. Journal of Neurocytology, 31(3-5), 373-385.</p>



<p>Fuster, J. M. (2002b). Physiology of executive functions: The perception-action cycle. In Stuss, D. T., &amp; Knight, R. T. (Eds.), Principles of frontal lobe function, pp. 96-108. Oxford University Press.</p>



<p>Fuster, J. M. (1973). Unit activity in prefrontal cortex during delayed-response performance: Neuronal correlates of transient memory. Journal of Neurophysiology, 36(1), 61-78.</p>



<p>Fuster, J. M. (2009). Cortex and Memory: Emergence of a new paradigm. Journal of Cognitive Neuroscience, 21(11), 2047-2072.</p>



<p>Fuster, J. (2015). The prefrontal cortex (Fifth Edition). Oxford, UK: Academic Press, Elsevier.</p>



<p>Glushchenko, A., et al. (2018). Unsupervised language learning in OpenCog. In: IklÃ©, M., Franz, A., Rzepka, R., &amp; Goertzel B. (Eds.), Artificial general intelligence. AGI 2018. Lecture Notes in Computer Science, vol. 10999. Springer, Cham.</p>



<p>Goertzel, B. (2016). The AGI revolution. Humanity Press.</p>



<p>Goertzel, B., Pennachin, C., &amp; Geisweiller, N. (2014). Engineering general intelligence: A path to advanced AGI via embodied learning and cognitive synergy. Atlantis Press.</p>



<p>Goldman-Rakic, P. S. (1987). Circuitry of the prefrontal cortex and the regulation of behavior by representational memory. In Mountcastle, V. B., Plum, F., &amp; Geiger, S. R. (Eds.), Handbook of neurobiology, pp. 373-417. Bethesda, MD: American Physiological Society.</p>



<p>Goldman-Rakic, P. S. (1990). Cellular and circuit basis of working memory in prefrontal cortex of nonhuman primates. In Uylings, H. B. M., Eden, C. G. V., DeBruin, J. P. C., Corner, M. A., &amp; Feenstra, M. G. P. (Eds.), Progress in brain research, vol. 85, pp. 325-336. Elsevier Science Publications.</p>



<p>Goldman-Rakic, P. S. (1995). Cellular basis of working memory. Neuron, 14(3), 447-485.</p>



<p>Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016). Deep learning. Cambridge, MA: The MIT Press.</p>



<p>Gurney, K. N. (2009). Reverse engineering the vertebrate brain: Methodological principles for a biologically grounded programme of cognitive modeling. Cognitive Computation, 1(1), 29-41.</p>



<p>Gray, W. D. (2007). Integrated models of cognitive systems. Oxford University Press.</p>



<p>Haikonen, P. O. (2003). The cognitive approach to conscious machines. Exeter, UK: Imprint Academic.</p>



<p>Haikonen, P. O. (2012). Consciousness and robot sentience. Hackensack, NJ: World Scientific Publishing.</p>



<p>Hameed, A. A., Karlik, B., Salman, M. S., &amp; Eleyan, G. (2019). Robust adaptive learning approach to self-organizing maps. Knowledge-Based Systems, 171(1), 25-36.</p>



<p>Hamilton, W. (1890). In Mansel, H. L., &amp; and Veitch, J. (Eds.), 1860 lectures on metaphysics and logic, in Two Volumes. Vol. II. Logic. Boston: Gould and Lincoln.</p>



<p>Hawkins, J. (2004). On intelligence. New York: Times Books.</p>



<p>Hasegawa, I., Fukushima, T., Ihara, T., &amp; Miyashita, Y. (1998). Callosal window between prefronal cortices: Cognitive interaction to retrieve long-term memory. Science, 281, 814-818.</p>



<p>Hassabis, D., Kumaran, D., Summerfield, C., &amp; Botvinick, M. (2017). Neuroscience-inspired artificial intelligence. Neuron, 95, 245-258.</p>



<p>Hebb, D. (1949). The organization of behavior. New York: Wiley.</p>



<p>Hofstadter, D. (2007). I am a strange loop. New York: Basic Books.</p>



<p>Howard, M. W., &amp; Kahana, M. J. (2002). A distributed representation of temporal context. Journal of Mathematical Psychology, 46, 269-299.</p>



<p>Hummel, J. E., &amp; Holyoak, K. J. (2003). A symbolic-connectionist theory of relational inference and generalization. Psychological Review, 110(2), 220-264.</p>



<p>Huttenlocher, P. R., &amp; Dabholkar, A. S. (1997). Developmental anatomy of prefrontal cortex. In Krasnegor, N. A., Lyon, G. R., Goldman-Rakic, &amp; P. S. (Eds.), Development of the prefrontal cortex. Baltimore, MD: Paul H. Brookes Publishing Co.</p>



<p>Jacob, S. N., HÃ¤hnke, D., &amp; Nieder, A. (2018). Structuring of abstract working memory content by fronto-parietal synchrony in primate cortex. Neuron, 99(3), 588-597.</p>



<p>James, W. (1909). A pluralistic universe. Hibbert lectures at Manchester College on the present situation in philosophy. London: Longmans, Green, and Co.</p>



<p>James, W. (1890). The principles of psychology. New York: Henry Holt.</p>



<p>Johnson-Laird, P. N. (1998). Computer and the mind: An introduction to cognitive science. Harvard University Press.</p>



<p>Kaas, J. H. (1997). Topographic maps are fundamental to sensory processing. Brain Research Bulletin, 44(2), 107-112.</p>



<p>Kahneman, D. (2011). Thinking fast and slow. New York: Farrar, Straus, and Giroux.</p>



<p>Klimesch, W., Freunberger, R., &amp; Sauseng, P. (2010). Oscillatory mechanisms of process binding in memory. Neuroscience and Biobehavioral Reviews, 34(7), 1002-1014.</p>



<p>Konar A. (2014). Artificial intelligence and soft computing: Behavior and cognitive modeling of the human brain. Boca Raton, FL: CRC Press.</p>



<p>Kounatidou, P., Richter, M., &amp; SchÃ¶ner, G.. (2018). A neural dynamic architecture that autonomously builds mental models. In Rogers, T. T. Rau, M., Zhu, X., &amp; Kalish, C. W. (Eds.), Proceedings of the 40th Annual Conference of the Cognitive Science Society, pp. 643-648.</p>



<p>Kurzweil, R. (2012). How to create a mind. New York: Penguin Group.</p>



<p>Laird, J. E. (2012). The soar cognitive architecture. Cambridge, MA: The MIT Press.</p>



<p>Lansner, A. (2009). Associative memory models: From the cell-assembly theory to biophysically detailed cortex simulations. Trends in Neurosciences, 32(3),179-186.</p>



<p>LaRocque, J. J., Lewis-Peacock, J. A., &amp; Postle, B. R. (2014). Multiple neural states of representation in short-term memory? Itâs a matter of attention. Frontiers in Human Neuroscience, 8, 1-14.</p>



<p>Lewis-Peacock, J. A., Drysdale, A. T., Oberauer, K., &amp; Postle, B. R. (2012). Neural evidence for a distinction between short-term memory and the focus of attention. Journal of Cognitive Neuroscience, 24(1), 61-79.</p>



<p>Manohar, S. G., Zokaei, N., Fallon, S. J., Vogels, T. P., &amp; Husain, M. (2019). Neural mechanisms of attending to items in working memory. Neuroscience and Biobehavioral Reviews, 101, 1-12.</p>



<p>Mellet, E., Petit, L., Mazoyer, B., Denis, M., &amp; Tzourio, N. (1998). Reopening the mental imagery debate: Lessons from functional anatomy. Nueroimage, 8(2),129-139.</p>



<p>Meyer, K., Damasio, A. (2009). Convergence and divergence in a neural architecture for recognition and memory. Trends in Neurosciences, 32(7), 376-382.</p>



<p>Myers, N. E., Stokes, M. G., &amp; Nobre, A. C. (2017). Prioritizing information during working memory: Beyond sustained internal attention. Trends in Cognitive Sciences, 21(6), 449-461.</p>



<p>Miller, G. A. (1956). The magical number seven, plus or minus two: Some limits on our capacity for processing information. Psychological Review, 63(2), 81-97.</p>



<p>Miller, E. K., &amp; Cohen, J. D. (2001). An integrative theory of prefrontal cortex function. Annual Review of Neuroscience, 24, 167-202.</p>



<p>Miller, E. K., Lundqvist, M., &amp; Bastos, A. M. (2018). Working memory 2.0. Neuron, 100, 463-475.</p>



<p>Mongillo, G., Barak, O., &amp; Tsodyks, M. (2008). Synaptic theory of working memory. Science, 319, 1543-1546.</p>



<p>Moscovich, M. (1992). Memory and working-with-memory: A component process model based on modules and central systems. Journal of Cognitive Neuroscience, 4(3),257-267.</p>



<p>Moscovitch, M., Chein, J. M., Talmi, D., &amp; Cohn, M. (2007). Learning and memory. In Baars, B. J., &amp; Gage, N. M. (Eds.), Cognition, brain, and consciousness: Introduction to cognitive neuroscience, p. 234. London:&nbsp; Academic Press.</p>



<p>Miyashita, Y. (2005). Cognitive memory: cellular and network machineries and their top-down control. Science, 306, 435-440.</p>



<p>Nairne, J. S. (2002). Remembering over the short-term: The case against the standard model. Annual Review of Psychology, 53, 53-81.</p>



<p>Newell, A., &amp; Simon, H. A. Computer simulation of human thinking. Science, 134, 2011-2017.</p>



<p>Niklaus, M., Singmann, H., &amp; Oberauer, K. (2019). Two distinct mechanisms of selection in working memory: Additive last-item and retro-cue benefits. Cognition, 183, 282-302.</p>



<p>Norman, D. A. (1968). Toward a theory of memory and attention. Psychological Review, 75(6), 522-536.</p>



<p>Nyberg, L., Eriksson, J. (2016). Working memory: maintenance, updating, and the realization of intentions. Cold Spring Harbor Perspectives in Biology, 8(2), a021816.</p>



<p>Oberauer, K. (2002). Access to information in working memory: Exploring the focus of attention. Journal of Experimental Psychology: Learning, Memory, and Cognition, 28(3), 411-421.</p>



<p>Opitz B. (2010). Neural binding mechanisms in learning and memory. Neuroscience and Biobehavioral Reviews, 34(7), 1036-1046.</p>



<p>Panichello, M. F., &amp; Buschman, T. J. (2021). Shared mechanisms underlie the control of working memory and attention. Nature, 592, 601-605.</p>



<p>Pina, J. E., Bodner, M., &amp; Ermentrout, B. (2018). Oscillations in working memory and neural binding: a mechanism for multiple memories and their interactions. PLOS Computational Biology, 14(11), e1006517.</p>



<p>Postle, B. R. (2007). Activated long-term memory? The bases of representation in working memory. In Osaka, N., Logie, R. H., &amp; DâEsposito, M. (Eds.), The cognitive neuroscience of working memory. Oxford University Press.</p>



<p>Postle, B., et al. (2006). Repetitive transcranial magnetic stimulation dissociates working memory manipulation from retention functions in the prefrontal, but not posterior parietal, cortex. Journal of Cognitive Neuroscience, 18, 1712-1722.</p>



<p>Reggia, J. A., Katz, G. E., &amp; Davis, G. P. (2019). Modeling working memory to identify computational correlates of consciousness. Open Philosophy, 2, 252-269.</p>



<p>Reser, J. E. (2006). Evolutionary neuropathology &amp; congenital mental retardation: Environmental cues predictive of maternal deprivation influence the fetus to minimize cerebral metabolism in order to express bioenergetic thrift. Medical Hypotheses, 67(3), 529-544.</p>



<p>Reser, J. E. (2011). What determines belief: The philosophy, psychology and neuroscience of belief formation and change. Saarbrucken, Germany: Verlag Dr. Muller.</p>



<p>Reser, J. E. (2012). Assessing the psychological correlates of belief strength: Contributing factors and role in behavior. (Doctoral Dissertation). Retrieved from University of Southern California. Usctheses-m2627.</p>



<p>Reser, J. E. (2022). Artificial intelligence software structured to simulate human working memory, mental imagery, and mental continuity. arXiv:2204.05138</p>



<p>Reser, J. E. (2013). The neurological process responsible for mental continuity: Reciprocating transformations between a working memory updating function and an imagery generation system. Association for the Scientific Study of Consciousness Conference. San Diego CA, July 12-15.</p>



<p>Reser, J. E. (2016). Incremental change in the set of coactive cortical assemblies enables mental continuity. Physiology and Behavior, 167(1), 222-237.</p>



<p>Reisberg, D. (2010). Cognition: Exploring the science of the mind. New York: W. W. Norton &amp; Co.</p>



<p>Rose, N. S., LaFocque, J. J., Riggall, A. C., Gosseries, O., Starrett, M. J., &amp; Meyering, E. E. (2016). Reactivation of latent working memories with transcranial magnetic stimulation. Science, 354(6316), 1136-1139.</p>



<p>Rosenthal, D. M. (2004). Varieties of higher-order theory. In Gennaro, R. (Ed.), Higher-order theories of consciousness, pp. 17-44. Amsterdam: John Benjamins.</p>



<p>Ruchkin, D. S., Grafman, J., Cameron, K., &amp; Berndt, R. S. (2003). Working memory retention systems: A state of activated long-term memory. Behavioral and Brain Sciences, 26, 709-777.</p>



<p>Rushworth, M. F., Nixon, P. D., Eacott, M. J., &amp; Passingham, R. E. (1997). Ventral prefrontal cortex is not essential for working memory. Journal of Neuroscience, 17(12), 4829-4838.</p>



<p>Ryan, K., Agrawal, P., &amp; Franklin, S. (2019). The pattern theory of self in artificial general intelligence: A theoretical framework for modeling self in biologically inspired cognitive architectures. Cognitive Systems Research. In press.</p>



<p>Rypma, B., Berger, J. S., &amp; DâEsposito, M. (2002). The influence of working-memory demand and subject performance on prefrontal cortical activity. Journal of Cognitive Science, 14(5), 721-731.</p>



<p>Sacks, O. (2017). The river of consciousness. New York: Vintage Books.&nbsp;</p>



<p>Salmon, M. (2012). Arguments from analogy. Introduction to logic and critical thinking, pp. 132-142. Cengage Learning.</p>



<p>Sarter, M., Givens, B., &amp; Bruno, J. P. (2001). The cognitive neuroscience of sustained attention: where top-down meets bottom-up. Brain Research Reviews, 35(2), 146-160.</p>



<p>Schvaneveldt, R. W., &amp; Meyer, D.E. (1973). Retrieval and comparison processes in semantic memory. In Kornblum, S., Attention and performance: IV, pp. 395-409. New York: Academic Press.</p>



<p>Shanks, D. (2010). Learning: From association to cognition. Annual Review of Psychology, 1, 273-301.</p>



<p>Shannon, C. (1951). Prediction and entropy of printed English. Bell System Technical Journal, 30, 47-51.</p>



<p>Shastri, L. (1999). Advances in ShrutiâA neurally motivated model of relational knowledge representation and rapid inference using temporal synchrony. Applied Intelligence, 11(1), 79-108.</p>



<p>Sherstinsky A. (2020). Fundamentals of recurrent neural network (rnn) and long short-term memory (lstm) network. Physica D: Nonlinear Phenomena, 404, 132306.</p>



<p>Shipstead, Z., Harrison, T. L., &amp; Engle, R. W. (2015). Working memory capacity and the scope and control of attention. Attention, Perception, &amp; Psychophysics, 77(6), 1863-1880.</p>



<p>Seamans, J. K., &amp; Robbins, T. W. (2010). Dopamine modulation of the prefrontal cortex and cognitive function. The Dopamine Receptors, 373-398.</p>



<p>Seamans, J. K., &amp; Yang, C. R. (2004). The principal features and mechanisms of dopamine modulation in the prefrontal cortex. Progress in Neurobiology, 74(1), 1-58.</p>



<p>Silvanto, J. (2017). Working memory maintenance: Sustained firing or synaptic mechanisms? Trends in Cognitive Sciences, 21(3), 152-154.</p>



<p>Sipper, M., Fu, W., Ahuja, K., &amp; Moore, J. H. (2018). Investigating the parameter space of evolutionary algorithms. BioData Mining, 11(2).</p>



<p>Sreenivasan, K. K., &amp; DâEsposito, M. (2019). The what, where and how of delay activity. Nature Reviews Neuroscience. May 13.</p>



<p>Sousa, A. M. M., Meyer, K. A., Santpere, G., Gulden, F. O., &amp; Sestan, N. (2017). Evolution of the human nervous system function, structure, and development. Cell, 170(2), 226-247.</p>



<p>Sperling, G. (1960). The information available in brief visual representations. Psychological Monographs, 74, 1-29.</p>



<p>Stokes, M. G. (2015). âActivity-silentâ working memory in prefrontal cortex: A dynamic coding framework. Trends in Cognitive Science, 19(7), 395-405.</p>



<p>Stone, J. V. (2015). Information theory: A tutorial introduction. Sebtel Press.</p>



<p>Striedter, G. (2005). Principles of brain evolution. Sunderland, MA: Sinauer Associates.</p>



<p>Tomita, H., Ohbayashi, M., Nakahara, K., Hasegawa, I., &amp; Miyashita, Y. (1999). Top-down signalfrom prefrontal cortex in executive control of memory retrieval. Nature, 401, 699-703.</p>



<p>Tononi, G. (2010). An information integration theory of consciousness. BMC Neuroscience, 5, 42.</p>



<p>Treisman, A. M. (1964). Selective attention in man. British Medical Bulletin, 20, 12 16.</p>



<p>von der Malsburg, C. (1999). The what and why of binding: The modelerâs perspective. Neuron, 24, 95-104.</p>



<p>Weger, U., Wagemann, J., &amp; Meyer, A. (2018). Introspection in psychology: Its contribution to theory and method in memory research. European Psychologist, 23, 206-216.</p>



<p>Zanto, T. P., Rubens, M. T., Thangavel, A., &amp; Gazzaley, A. (2011). Causal role of the prefrontal cortex in top-down modulation of visual processing and working memory. Nature Neuroscience, 14, 656-661.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Best 7B LLM on leaderboards made by an amateur following a medium tutorial (148 pts)]]></title>
            <link>https://huggingface.co/CultriX/MistralTrix-v1</link>
            <guid>38882726</guid>
            <pubDate>Fri, 05 Jan 2024 18:34:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://huggingface.co/CultriX/MistralTrix-v1">https://huggingface.co/CultriX/MistralTrix-v1</a>, See on <a href="https://news.ycombinator.com/item?id=38882726">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	<!-- HTML_TAG_START --><h2>
	<a rel="noopener nofollow" href="#results" id="results">
		
	</a>
	<span>
		Results:
	</span>
</h2>
<p>T: ð¦
Model: CultriX/MistralTrix-v1 ð
Average: 73.39
ARC: 72.27
HellaSwag: 88.33
MMLU: 65.24
TruthfulQA: 70.73
Winogrande: 80.98
GSM8K: 62.77</p>
<h2>
	<a rel="noopener nofollow" href="#editdisclaimer" id="editdisclaimer">
		
	</a>
	<span>
		Edit/Disclaimer:
	</span>
</h2>
<p>Currently the #1 ranked 7B LLM on the LLM Leaderboards, woah!
I did not expect that result at all and am in no way a professional when it comes to LLM's or computer science in general,
just a guy that likes to nerd about and tinker around. </p>
<p>For those wondering how I achieved this, the answer is that I simply attempted to apply the techniques outlined in this amazing article myself: <a rel="noopener nofollow" href="https://towardsdatascience.com/fine-tune-a-mistral-7b-model-with-direct-preference-optimization-708042745aac">https://towardsdatascience.com/fine-tune-a-mistral-7b-model-with-direct-preference-optimization-708042745aac</a>
Therefore, all credit basically goes to the guy who wrote that. 
He offers the exact Colab notebook I used to train this model for free, as well as a really nice GitHub page I hope he doesn't mind me sharing: <a rel="noopener nofollow" href="https://github.com/mlabonne/llm-course/">https://github.com/mlabonne/llm-course/</a>
So huge thank you to him for sharing his knowledge and learning me a thing or two in the process!</p>
<h2>
	<a rel="noopener nofollow" href="#gguf" id="gguf">
		
	</a>
	<span>
		GGUF
	</span>
</h2>
<p>I attempted to quantisize the model myself, which again I pretty much have no clue about, but it seems to run fine for me when I test them:
<a rel="noopener nofollow" href="https://huggingface.co/CultriX/MistralTrix-v1-GGUF">https://huggingface.co/CultriX/MistralTrix-v1-GGUF</a></p>
<p>I'll say it one more time though:
"I am a complete beginner to all of this, so if these do end up sucking don't be surprised."</p>
<p>You have been warned :)</p>
<h2>
	<a rel="noopener nofollow" href="#description" id="description">
		
	</a>
	<span>
		Description:
	</span>
</h2>
<p>(trained on a single Colab GPU in less than a few hours)</p>
<p>MistralTrix-v1 is an zyh3826/GML-Mistral-merged-v1 model that has been further fine-tuned with Direct Preference Optimization (DPO) using Intel's dataset for neural-chat-7b-v3-1.
It surpasses the original model on several benchmarks (see results).</p>
<p>It is directly inspired by the RLHF process described by Intel/neural-chat-7b-v3-1's authors to improve performance. 
I used the same dataset and reformatted it to apply the ChatML template.</p>
<p>The code to train this model is available on Google Colab and GitHub. 
Fine-tuning took about an hour on Google Colab A-1000 GPU with 40GB VRAM.</p>
<h2>
	<a rel="noopener nofollow" href="#training-specifications" id="training-specifications">
		
	</a>
	<span>
		TRAINING SPECIFICATIONS
	</span>
</h2>
<blockquote>
<p>LoRA configuration
peft_config = LoraConfig(
    r=16,
    lora_alpha=16,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules=['k_proj', 'gate_proj', 'v_proj', 'up_proj', 'q_proj', 'o_proj', 'down_proj']
)</p>
</blockquote>
<blockquote>
<p>Model to fine-tune
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    load_in_4bit=True
)
model.config.use_cache = False</p>
</blockquote>
<blockquote>
<p>Reference model
ref_model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    load_in_4bit=True
)</p>
</blockquote>
<blockquote>
<p>Training arguments
training_args = TrainingArguments(
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4,
    gradient_checkpointing=True,
    learning_rate=5e-5,
    lr_scheduler_type="cosine",
    max_steps=200,
    save_strategy="no",
    logging_steps=1,
    output_dir=new_model,
    optim="paged_adamw_32bit",
    warmup_steps=100,
    bf16=True,
    report_to="wandb",
)</p>
</blockquote>
<blockquote>
<p>Create DPO trainer
dpo_trainer = DPOTrainer(
    model,
    ref_model,
    args=training_args,
    train_dataset=dataset,
    tokenizer=tokenizer,
    peft_config=peft_config,
    beta=0.1,
    max_prompt_length=1024,
    max_length=1536,
)</p>
</blockquote>
<!-- HTML_TAG_END --></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Harlequin: SQL IDE for Your Terminal (130 pts)]]></title>
            <link>https://github.com/tconbeer/harlequin</link>
            <guid>38882526</guid>
            <pubDate>Fri, 05 Jan 2024 18:20:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/tconbeer/harlequin">https://github.com/tconbeer/harlequin</a>, See on <a href="https://news.ycombinator.com/item?id=38882526">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">Harlequin</h2>
<p dir="auto"><a href="https://pypi.org/project/harlequin/" rel="nofollow"><img src="https://camo.githubusercontent.com/067fdd5a85ae1e0918a49d816d4a453ff0b98ca16bc57c0439ddd3b7dac99307/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6861726c657175696e" alt="PyPI" data-canonical-src="https://img.shields.io/pypi/v/harlequin"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/27f6294ba42f41326103352ca94fa23356fbfdcf28d4bb3f49722e1756e5552b/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f6861726c657175696e"><img src="https://camo.githubusercontent.com/27f6294ba42f41326103352ca94fa23356fbfdcf28d4bb3f49722e1756e5552b/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f6861726c657175696e" alt="PyPI - Python Version" data-canonical-src="https://img.shields.io/pypi/pyversions/harlequin"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/4503b749d9b924c2b9f40c16cddc0daa41fb848585051c991b2b326ce0e457d7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f72756e732532306f6e2d4c696e75782532302537432532304d61634f5325323025374325323057696e646f77732d626c7565"><img src="https://camo.githubusercontent.com/4503b749d9b924c2b9f40c16cddc0daa41fb848585051c991b2b326ce0e457d7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f72756e732532306f6e2d4c696e75782532302537432532304d61634f5325323025374325323057696e646f77732d626c7565" alt="Runs on Linux | MacOS | Windows" data-canonical-src="https://img.shields.io/badge/runs%20on-Linux%20%7C%20MacOS%20%7C%20Windows-blue"></a></p>
<p dir="auto">The SQL IDE for Your Terminal.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/tconbeer/harlequin/blob/main/harlequin.svg"><img src="https://github.com/tconbeer/harlequin/raw/main/harlequin.svg" alt="Harlequin"></a></p>
<h2 tabindex="-1" dir="auto">Installing Harlequin</h2>
<p dir="auto">After installing Python 3.8 or above, install Harlequin using <code>pip</code> or <code>pipx</code> with:</p>

<h2 tabindex="-1" dir="auto">Using Harlequin with DuckDB</h2>
<p dir="auto">From any shell, to open one or more DuckDB database files:</p>
<div dir="auto" data-snippet-clipboard-copy-content="harlequin &quot;path/to/duck.db&quot; &quot;another_duck.db&quot;"><pre>harlequin <span><span>"</span>path/to/duck.db<span>"</span></span> <span><span>"</span>another_duck.db<span>"</span></span></pre></div>
<p dir="auto">To open an in-memory DuckDB session, run Harlequin with no arguments:</p>

<p dir="auto">If you want to control the version of DuckDB that Harlequin uses, see the <a href="https://github.com/tconbeer/harlequin/blob/main/troubleshooting/duckdb-version-mismatch">Troubleshooting</a> page.</p>
<h2 tabindex="-1" dir="auto">Using Harlequin with SQLite and Other Adapters</h2>
<p dir="auto">Harlequin also ships with a SQLite3 adapter. You can open one or more SQLite database files with:</p>
<div dir="auto" data-snippet-clipboard-copy-content="harlequin -a sqlite &quot;path/to/sqlite.db&quot; &quot;another_sqlite.db&quot;"><pre>harlequin -a sqlite <span><span>"</span>path/to/sqlite.db<span>"</span></span> <span><span>"</span>another_sqlite.db<span>"</span></span></pre></div>
<p dir="auto">Like DuckDB, you can also open an in-memory database by omitting the paths:</p>

<p dir="auto">Other adapters can be installed using <code>pip install &lt;adapter package&gt;</code> or <code>pipx inject harlequin &lt;adapter package&gt;</code>, depending on how you installed Harlequin. For a list of known adapters provided either by the Harlequin maintainers or the broader community, see the <a href="https://harlequin.sh/docs/adapters" rel="nofollow">adapters</a> page in the docs.</p>
<h2 tabindex="-1" dir="auto">Getting Help</h2>
<p dir="auto">To view all command-line options for Harlequin and all installed adapters, after installation, simply type:</p>

<p dir="auto">To view a list of all key bindings (keyboard shortcuts) within the app, press F1. You can also view this list outside the app <a href="https://harlequin.sh/docs/bindings" rel="nofollow">in the docs</a>.</p>
<h2 tabindex="-1" dir="auto">More info at <a href="https://harlequin.sh/" rel="nofollow">harlequin.sh</a></h2>
<p dir="auto">Visit <a href="https://harlequin.sh/" rel="nofollow">harlequin.sh</a> for an overview of features and full documentation.</p>
<h2 tabindex="-1" dir="auto">Contributing</h2>
<p dir="auto">Thanks for your interest in Harlequin! Harlequin is primarily maintained by <a href="https://github.com/tconbeer">Ted Conbeer</a>, but he welcomes all contributions and is looking for additional maintainers!</p>
<h3 tabindex="-1" dir="auto">Providing Feedback</h3>
<p dir="auto">We'd love to hear from you! <a href="https://github.com/tconbeer/harlequin/issues/new">Open an Issue</a> to request new features, report bugs, or say hello.</p>
<h3 tabindex="-1" dir="auto">Setting up Your Dev Environment and Running Tests</h3>
<ol dir="auto">
<li>Install Poetry v1.2 or higher if you don't have it already. You may also need or want pyenv, make, and gcc.</li>
<li>Fork this repo, and then clone the fork into a directory (let's call it <code>harlequin</code>), then <code>cd harlequin</code>.</li>
<li>Use <code>poetry install --sync</code> to install the project (editable) and its dependencies (including all test and dev dependencies) into a new virtual env.</li>
<li>Use <code>poetry shell</code> to spawn a subshell.</li>
<li>Type <code>make</code> to run all tests and linters, or run <code>pytest</code>, <code>black .</code>, <code>ruff . --fix</code>, and <code>mypy</code> individually.</li>
</ol>
<h3 tabindex="-1" dir="auto">Opening PRs</h3>
<ol dir="auto">
<li>PRs should be motivated by an open issue. If there isn't already an issue describing the feature or bug, <a href="https://github.com/tconbeer/harlequin/issues/new">open one</a>. Do this before you write code, so you don't waste time on something that won't get merged.</li>
<li>Ideally new features and bug fixes would be tested, to prevent future regressions. Textual provides a test harness that we use to test features of Harlequin. You can find some examples in the <code>tests</code> directory of this project. Please include a test in your PR, but if you can't figure it out, open a PR to ask for help.</li>
<li>Open a PR from your fork to the <code>main</code> branch of <code>tconbeer/harlequin</code>. In the PR description, link to the open issue, and then write a few sentences about <strong>why</strong> you wrote the code you did: explain your design, etc.</li>
<li>Ted may ask you to make changes, or he may make them for you. Don't take this the wrong way -- he values your contributions, but he knows this isn't your job, either, so if it's faster for him, he may push a commit to your branch or create a new branch from your commits.</li>
</ol>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Boeing wants FAA to exempt MAX 7 from safety rules to get it in the air (418 pts)]]></title>
            <link>https://www.seattletimes.com/business/boeing-aerospace/boeing-wants-faa-to-exempt-max-7-from-safety-rules-to-get-it-in-the-air/</link>
            <guid>38882358</guid>
            <pubDate>Fri, 05 Jan 2024 18:08:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.seattletimes.com/business/boeing-aerospace/boeing-wants-faa-to-exempt-max-7-from-safety-rules-to-get-it-in-the-air/">https://www.seattletimes.com/business/boeing-aerospace/boeing-wants-faa-to-exempt-max-7-from-safety-rules-to-get-it-in-the-air/</a>, See on <a href="https://news.ycombinator.com/item?id=38882358">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-content">
    <p>Little noticed, days before the holiday break, the Federal Aviation Administration published a Boeing request for an exemption from key safety standards on the 737 MAX 7 â the still-uncertified smallest member of Boeingâs newest jet family. </p><p>Since August, earlier models of the MAX currently flying passengers in the U.S. have had to limit use of the jetâs engine anti-ice system after Boeing discovered a defect in the system with potentially catastrophic consequences.</p><p>The flaw could cause the inlet at the front end of the pod surrounding the engine â known as a nacelle â to break and fall off.</p><p>In an August Airworthiness Directive, the FAA stated that debris from such a breakup could penetrate the fuselage, putting passengers seated at windows behind the wings in danger, and could damage the wing or tail of the plane, âwhich could result in loss of control of the airplane.â</p><p>Dennis Tajer, a spokesperson for the Allied Pilots Association, the union representing 15,000 American Airlines pilots, said the flaw in the engine anti-ice system has âgiven us great concern.â </p><p>He said the pilot procedure the FAA approved as an interim solution â urging pilots to make sure to turn off the system when icing conditions dissipate to avoid overheating that within five minutes could seriously damage the structure of the nacelle â is inadequate given the serious potential danger.</p>
<p>âYou get our attention when you say people might get killed,â Tajer said. âWeâre not interested in seeing exemptions and accommodations that depend on human memory. â¦ Thereâs just got to be a better way.â</p><p>In its petition to the FAA, Boeing argues the breakup of the engine nacelle is âextremely improbableâ and that an exemption will not reduce safety.</p><p>âThe 737 MAX has been in service since 2017 and has accumulated over 6.5 million flight hours. In that time, there have been no reported cases of parts departing aircraft due to overheating of the engine nacelle inlet structure,â the filing states.</p><p>On Thursday, Boeing said in an emailed statement that it is âdeveloping a long-term solution that will undergo thorough testing and FAA review before being introduced to the 737 MAX fleet.â</p><p>In the meantime, Boeing said âinspections are ongoingâ to check for any damage to the nacelles on MAXs in service.</p><p>However, without an exemption from current safety regulations, the FAA cannot approve the final two MAX models, the MAX 7 and MAX 10, to fly passengers.</p>
<p>On Christmas Eve, just before the deadline for public input on the proposed MAX 7 exemption, the Foundation for Aviation Safety â a lobbying group set up by former Boeing manager and whistleblower <a href="https://www.seattletimes.com/business/boeing-737-max-was-plagued-with-production-problems-whistleblower-says/">Ed Pierson</a> following <a href="https://www.seattletimes.com/business/boeing-aerospace/boeing-737-max-crisis-2019-news-coverage/">the two deadly MAX crashes</a> â filed a submission calling on the FAA not to certify the airplane until Boeing fixes the safety defect. </p><p>âThe Foundation is alarmed at the FAA safety culture, allowing consideration of an exemption proposal â¦ for certification of a new airplane model with a known catastrophic failure (risk) resulting from a simple mistake by the flight crew,â the Foundationâs submission states.</p><h2>Warning: Donât forget to turn it off</h2><p>Industry analysts and Boeing investors have long anticipated MAX 7 certification being granted soon. The companyâs share price rose significantly toward year-end based partly on that expectation.</p><p>If the exemption is granted, certification can go ahead, allowing the MAX 7 to begin flying with Southwest Airlines. </p><p>Boeing would have until mid-2026 to design, test and certify a permanent fix for the engine anti-ice system defect that would then be retrofitted to all MAXs. </p><p>By then, there could be nearly 2,000 MAXs in service, meaning more than 4,000 engines needing the retrofit.</p>
<p>Until then, pilots would have to adhere to the limitation currently applied on the MAX 8 and MAX 9 models. After emerging from icy conditions into drier air they have to make sure they turn off the engine anti-ice system, which heats the inner barrel of the engine pod so that ice doesnât build up.</p><p>If they fail to do so, the system can quickly overheat the carbon composite material and damage the structural integrity of the engine pod. </p><p>The problem is thereâs no alert or indication to the crew that the system needs to be turned off. They just have to remember to do it. </p>      <p>If they forget, or are distracted by other tasks, the overheating can begin to damage the structure after just five minutes.</p><p>Tajer said itâs ânot uncommonâ for pilots on other aircraft to inadvertently leave the anti-ice system on when it is no longer needed. </p><p>On older 737s, for example, this would waste energy but not do any damage. The defect affects only the MAX, with engine inlets made from carbon composite rather than the metal used on older models.</p>
<p>Independent aviation safety consultant and pilot John Cox said heâs run the anti-ice system on the previous 737 âfor long periods of time.â</p><p>And heâs unsure how practical it is to ask a MAX flight crew to limit the time the system operates in dry air.</p><p>âIâve been in and out of cloud tops,â Cox said. âDo you turn it on, turn it off, turn it on, turn it off?â</p><p>âIf you are doing that and get distracted, and end up with the anti-ice off and you go back into clouds where you pick up inlet icing, the next time you turn it on, youâre going to ingest that ice,â he added.</p><p>After reviewing Boeingâs petition, Cox said heâd recommend the FAA turn it down.</p><p>âWith the possibility of such a failure and an Airworthiness Directive with significant limitation already in place, my vote would be to deny the exemption request,â Cox said. âYes, it would affect entry into service, but it could create an âunsafe conditionâ by the FAAâs own words.â</p>
<p>Michael Stumo, father of <a href="https://www.seattletimes.com/business/boeing-aerospace/for-victims-loved-ones-latest-boeing-737-max-tragedy-leaves-anguish-anger-and-lots-of-questions/">Samya Rose Stumo, who died in the second MAX crash of an Ethiopian Airlines jet in 2019</a>, said âBoeing claims to have learned its lessons with a new focus upon safety. That is not true.â </p><p>âBoeing is still avoiding safety rules rather than building safe aircraft,â Stumo said.</p><h2>A single point of failure?</h2><p><a href="https://www.regulations.gov/document/FAA-2023-2340-0001" target="_blank">Boeingâs petition</a> states that the potential breakup of the engine pod was discovered through analysis and flight testing and could happen only in the case of âmultiple, independent system failures during specific operational and environmental conditions.â</p><p>âBoeingâs quantitative risk assessment evaluated this scenario to be extremely improbable,â the filing concludes.</p><p>But <a href="https://www.seattletimes.com/business/boeing-aerospace/faa-safety-engineer-goes-public-to-slam-the-agencys-oversight-of-boeings-737-max/">Joe Jacobsen</a>, a retired FAA safety engineer and adviser to the Foundation for Aviation Safety, says the petition offers no evidence that this is not a single point of failure.</p><p>âA pilot forgetting to turn it off, thatâs all it takes,â said Jacobsen.</p>
<p>Mike Dostert, another retired FAA safety engineer and also an adviser to the foundation, concurs. </p><p>âAll it takes is for the system to be left on and you damage the structure,â said Dostert. âI donât see the multiple failures.â</p><p>Without any kind of crew alert to tell the pilots they should shut off the system, he said âthereâs a pretty good chance human error is going to occur.â</p><p>Notably, among the various regulations Boeing wants exempted from is one requiring the jetmaker to prove that any âsingle failure or malfunction or probable combination of failures (that) will jeopardize the safe operation of the airplane â¦ is extremely remote.â</p><p>Dostert added that this defect could overheat and damage both engines on the plane simultaneously, making such an event potentially even worse than several serious accidents in recent years when broken engine fan blades caused the inlet cowl to break off a single engine.</p><p>In 2018, <a href="https://www.seattletimes.com/business/boeing-aerospace/one-southwest-passenger-dead-others-injured-after-boeing-737-engine-blowout/">a passenger aboard a Southwest Airlines 737 died </a>when a broken fan blade destroyed an engine cowl. Shrapnel penetrated the aircraftâs fuselage and broke a cabin window beside the passenger.</p>
<p>The pod around the engine is part of the airframe and is the responsibility of Boeing, not the engine maker.</p><p>Dostert said an earlier nonfatal engine blowout on a Southwest flight in 2016 had also led to the inlet cowl departing the aircraft but no fix was made before the fatality in 2018.</p><p>Almost six years later, the fix for that broken fan blade scenario in older 737s is still in the works. In December, the FAA published a proposal that gives Boeing until the middle of 2028 to develop a retrofit that will strengthen the inlet cowls and fan casings.</p><p>âThereâs a pattern here,â Dostert said. âOf Boeing knowing about potentially catastrophic single failures, and not addressing them in an expeditious manner.â</p><h2>Equivalent safety to the MAX 8 and MAX 9</h2><p>In 2022, Boeing CEO Dave <a href="https://www.seattletimes.com/business/boeing-aerospace/boeing-ceo-threatens-to-cancel-737-max-10-unless-congress-acts/">Calhoun threatened to cancel the MAX 10</a> if Congress didnât amend a law granting permission to certify the jet without meeting the safety regulation for crew alerting systems included in the 2020 Aircraft Certification, Safety and Accountability Act.</p><p><a href="https://www.seattletimes.com/business/boeing-aerospace/congress-year-end-bill-clears-faa-to-certify-boeing-737-max-7-10-unchanged/">Congress bowed to the pressure and amended the law</a>, amounting to a safety exemption for the MAX 7 and MAX 10 models.</p>
<p>Boeing argues in its December petition that granting the new exemption, with the same procedural limitation on how the pilots use the engine anti-ice system that applies to the MAX 8 and MAX 9, will leave the MAX 7 no less safe than those two aircraft that are flying passengers every day.</p><p>But Cox said âthereâs a difference in an unsafe condition found on the existing fleet and an unsafe condition prior to certification.â</p><p>He said heâs uncomfortable with the idea of âcertifying an airplane with an acknowledged potential unsafe condition.â</p><p>With the MAX 8 and 9 already flying, Cox said the FAAâs only alternative to imposing the operational restriction on those jets was to ground the fleet.</p><p>âDo I think itâs worth grounding the fleet? No, I donât. Itâs a bit of a tough call,â Cox said. Limiting use of the anti-ice system in dry air is âprobably the best compromise that the FAA and Boeing could come up with and agree on.â</p><p>But for Boeingâs two still-to-be certified airplanes, the MAX 7 and MAX 10, he thinks an expedited permanent fix is a better approach.</p>
<p>âThey need to make it a very strong priority to minimize the time under which the engine is operating with this potential problem and to restore the anti-ice system to normal,â Cox said.</p><p>The FAA said in an emailed statement that it will investigate how the defect was missed during the MAXâs original development and certification and âwill issue a corrective action to ensure Boeingâs future certification programs â¦ are improved.â</p><p>The safety agency said it will rule on Boeingâs petition, but âthere is no specific timetable.â</p>    
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zeiss's "Holocam" turns glass windows into cameras (430 pts)]]></title>
            <link>https://www.digitalcameraworld.com/news/this-holographic-camera-turns-any-window-into-an-invisible-camera</link>
            <guid>38881981</guid>
            <pubDate>Fri, 05 Jan 2024 17:42:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.digitalcameraworld.com/news/this-holographic-camera-turns-any-window-into-an-invisible-camera">https://www.digitalcameraworld.com/news/this-holographic-camera-turns-any-window-into-an-invisible-camera</a>, See on <a href="https://news.ycombinator.com/item?id=38881981">Hacker News</a></p>
<div id="readability-page-1" class="page"><article aria-label="article" data-id="PrZExrLcG9GjPkTvfZ929L">
<header>
<nav aria-label="Breadcrumbs">
<ol>
<li>
<a href="https://www.digitalcameraworld.com/news" aria-label="Return to News" data-before-rewrite-localise="https://www.digitalcameraworld.com/news">News</a>
</li>
</ol>
</nav>



</header>
<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture><source type="image/webp" alt="Zeiss Holocam" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD-1920-80.jpg.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD.jpg"><source type="image/jpeg" alt="Zeiss Holocam" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD.jpg"><img src="https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD-320-80.jpg" alt="Zeiss Holocam" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD.jpg"></picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/tzwXNMkCUsLmT5HLhKdqaD.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: Zeiss)</span>
</figcaption>
</div>

<div id="article-body">
<p><a data-analytics-id="inline-link" href="https://www.digitalcameraworld.com/tag/zeiss" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.digitalcameraworld.com/tag/zeiss">Zeiss</a> is bringing its remarkable Holocam technology to <a data-analytics-id="inline-link" href="https://www.digitalcameraworld.com/news/ces-2024-everything-you-need-to-know-about-the-camera-and-tech-showcase" data-before-rewrite-localise="https://www.digitalcameraworld.com/news/ces-2024-everything-you-need-to-know-about-the-camera-and-tech-showcase">CES 2024</a>, which can turn any glass screen into a camera. This means that everything from the window in your car to the screen on your laptop to the glass on your front door can now possess an invisible image sensor.&nbsp;</p><p>Further, because the technology makes the camera completely transparent, it eliminates the need for cutouts or punch holes â&nbsp;meaning you can have direct eye contact with the person you're chatting to,&nbsp;because the camera can be placed anywhere on (or should that be <em>in</em>) the screen.&nbsp;</p><p>The Holocam technology "uses holographic in-coupling, light guiding and de-coupling elements to redirect the incoming light of a transparent medium to a hidden image sensor."</p><p>Zeiss' <a data-analytics-id="inline-link" href="https://www.digitalcameraworld.com/tag/ces" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.digitalcameraworld.com/tag/ces">CES</a> presentation is focused around its Multifunctional Smart Glass system in general, with a focus on applications in automobiles, so many of its use cases are based around how holography can improve in-car operability. However, it's easy to see how this could be truly transformative technology in the wider world.&nbsp;</p><p>Smart doorbells that don't need a separate camera module. Webcams that enable you to look anywhere on your screen. Parking cameras that can be completely hidden. Face or gesture recognition on any screen, including to unlock doors. Fatigue detection for drivers. Or, you know, phones and tablets without bloody notches or punch holes.</p><p>Using an entire pane of glass as a camera lens also opens some fascinating optical possibilities. Some of Zeiss' bullet points include "large aperture invisible camera" and "individual adjustment of orientation and size of the field of views." Which makes me wonder, what <em>is</em> the maximum aperture and focal range of a camera like this?</p><p>Of course, there's a darker potential for such technology. Given the current fear around hidden cameras in Airbnbs, the idea of every single window (or even shower door) in a rental property being able to spy on you is a little disconcerting.&nbsp;</p><p>Still, this is a fascinating bit of tech â&nbsp;and I'm super excited to see if and how it comes into everyday use.&nbsp;</p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" alt="Zeiss Holocam" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/XyNHNTGejZ3W4LVSEcg9QD-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/XyNHNTGejZ3W4LVSEcg9QD-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/XyNHNTGejZ3W4LVSEcg9QD-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/XyNHNTGejZ3W4LVSEcg9QD-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/XyNHNTGejZ3W4LVSEcg9QD-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/XyNHNTGejZ3W4LVSEcg9QD-1200-80.jpg.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-normal="https://vanilla.futurecdn.net/digitalcameraworld/media/img/missing-image.svg" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/XyNHNTGejZ3W4LVSEcg9QD.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/XyNHNTGejZ3W4LVSEcg9QD.jpg"><source type="image/jpeg" alt="Zeiss Holocam" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/XyNHNTGejZ3W4LVSEcg9QD-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/XyNHNTGejZ3W4LVSEcg9QD-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/XyNHNTGejZ3W4LVSEcg9QD-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/XyNHNTGejZ3W4LVSEcg9QD-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/XyNHNTGejZ3W4LVSEcg9QD-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/XyNHNTGejZ3W4LVSEcg9QD-1200-80.jpg 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-normal="https://vanilla.futurecdn.net/digitalcameraworld/media/img/missing-image.svg" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/XyNHNTGejZ3W4LVSEcg9QD.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/XyNHNTGejZ3W4LVSEcg9QD.jpg"><img src="https://cdn.mos.cms.futurecdn.net/XyNHNTGejZ3W4LVSEcg9QD-320-80.jpg" alt="Zeiss Holocam" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/XyNHNTGejZ3W4LVSEcg9QD-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/XyNHNTGejZ3W4LVSEcg9QD-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/XyNHNTGejZ3W4LVSEcg9QD-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/XyNHNTGejZ3W4LVSEcg9QD-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/XyNHNTGejZ3W4LVSEcg9QD-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/XyNHNTGejZ3W4LVSEcg9QD-1200-80.jpg 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-normal="https://vanilla.futurecdn.net/digitalcameraworld/media/img/missing-image.svg" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/XyNHNTGejZ3W4LVSEcg9QD.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/XyNHNTGejZ3W4LVSEcg9QD.jpg"></picture></p></div><figcaption itemprop="caption description"><span>Doors that only open if they recognize your face sounds cool â&nbsp;but then, we all know how that works (or doesn't) on phones </span><span itemprop="copyrightHolder">(Image credit: Zeiss)</span></figcaption></figure><p>Take a look at the <a data-analytics-id="inline-link" href="https://www.digitalcameraworld.com/buying-guides/best-dash-cam" data-before-rewrite-localise="https://www.digitalcameraworld.com/buying-guides/best-dash-cam">best dashs</a>, the <a data-analytics-id="inline-link" href="https://www.digitalcameraworld.com/buying-guides/best-indoor-security-camera" data-before-rewrite-localise="https://www.digitalcameraworld.com/buying-guides/best-indoor-security-camera">best indoo security cameras</a>, the <a data-analytics-id="inline-link" href="https://www.digitalcameraworld.com/buying-guides/best-spy-cameras" data-before-rewrite-localise="https://www.digitalcameraworld.com/buying-guides/best-spy-cameras">best spy cameras</a> and the <a data-analytics-id="inline-link" href="https://www.digitalcameraworld.com/buying-guides/best-hidden-camera-detector" data-before-rewrite-localise="https://www.digitalcameraworld.com/buying-guides/best-hidden-camera-detector">best hidden camera detectors</a>.&nbsp;</p>
</div>
<div>
<p><img src="https://cdn.mos.cms.futurecdn.net/flexiimages/tdeebvjhl11651144918.svg"></p>
<div>
<p><strong><span>Thank you for reading 5 articles this month* Join now for unlimited access</span></strong></p><p><strong><span>Enjoy your first month for just Â£1 / $1 / â¬1</span></strong></p>
</div>

<p><span>*Read 5 free articles per month without a subscription</span></p>
</div>
<div>
<p><img src="https://cdn.mos.cms.futurecdn.net/flexiimages/tdeebvjhl11651144918.svg">
</p>
<div>
<p><strong><span>Join now for unlimited access</span></strong></p><p>Try first month for just <strong>Â£1 / $1 / â¬1</strong></p>
</div>

</div>


<div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-PrZExrLcG9GjPkTvfZ929L"><section><p>The best camera deals, reviews, product advice, and unmissable photography news, direct to your inbox!</p></section></div>
<div id="slice-container-authorBio-PrZExrLcG9GjPkTvfZ929L"><p>The editor of Digital Camera World, James has 21 years experience as a journalist and started working in the photographic industry in 2014 (as an assistant to Damian McGillicuddy, who succeeded David Bailey as Principal Photographer for Olympus). In this time he shot for clients like Aston Martin Racing, Elinchrom and L'OrÃ©al, in addition to shooting campaigns and product testing for Olympus, and providing training for professionals. This has led him to being a go-to expert for camera and lens reviews, photo and lighting tutorials, as well as industry news, rumors and analysis for publications like <a href="https://www.awin1.com/awclick.php?awinmid=2961&amp;awinaffid=103504&amp;clickref=dcw-gb-3007255495896184000&amp;p=https%3A%2F%2Fwww.magazinesdirect.com%2Faz-magazines%2F6936429%2Fdigital-camera-magazine-subscription.thtml" target="_blank">Digital Camera Magazine</a>,&nbsp;<a href="https://www.awin1.com/awclick.php?awinmid=2961&amp;awinaffid=103504&amp;clickref=dcw-gb-6565833657202343000&amp;p=https%3A%2F%2Fwww.magazinesdirect.com%2Faz-magazines%2F6936659%2Fphotoplus-magazine-subscription.thtml" target="_blank">PhotoPlus: The Canon Magazine</a>,&nbsp;<a href="https://www.awin1.com/awclick.php?awinmid=2961&amp;awinaffid=103504&amp;clickref=dcw-gb-4247458655152168000&amp;p=https%3A%2F%2Fwww.magazinesdirect.com%2Faz-magazines%2F6936619%2Fnphoto-magazine-subscription.thtml" target="_blank">N-Photo: The Nikon Magazine</a>,&nbsp;<a href="https://www.awin1.com/awclick.php?awinmid=2961&amp;awinaffid=103504&amp;clickref=dcw-gb-1487400588188809500&amp;p=https%3A%2F%2Fwww.magazinesdirect.com%2Faz-magazines%2F6936439%2Fdigital-photographer-magazine-subscription.thtml" target="_blank">Digital Photographer</a> and Professional Imagemaker, as well as hosting workshops and talks at <a href="https://www.photographyshow.com/" target="_blank">The Photography Show</a>.&nbsp;He also serves as a judge for the Red Bull Illume Photo Contest. An Olympus and Canon shooter, he has a wealth of knowledge on cameras of all makes â&nbsp;and a fondness for vintage lenses and instant cameras.</p></div>

<div>
<h4>Related articles</h4>

</div>
</section>





</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Copilot key will eventually be required in new PC keyboards (110 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2024/01/ai-comes-for-your-pcs-keyboard-as-microsoft-adds-dedicated-copilot-key/</link>
            <guid>38881839</guid>
            <pubDate>Fri, 05 Jan 2024 17:31:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2024/01/ai-comes-for-your-pcs-keyboard-as-microsoft-adds-dedicated-copilot-key/">https://arstechnica.com/gadgets/2024/01/ai-comes-for-your-pcs-keyboard-as-microsoft-adds-dedicated-copilot-key/</a>, See on <a href="https://news.ycombinator.com/item?id=38881839">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      key change    â
</h4>
            
            <h2 itemprop="description">Copilot key will eventually be required in new PC keyboards, though not yet.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/01/copilot-key-800x450.jpg" alt="A rendering of Microsoft's Copilot key, as seen on a Surface-esque laptop keyboard.">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/01/copilot-key.jpg" data-height="1080" data-width="1920">Enlarge</a> <span>/</span> A rendering of Microsoft's Copilot key, as seen on a Surface-esque laptop keyboard.</p><p>Microsoft</p></figcaption>  </figure>

  




<!-- cache hit 173:single/related:88ddd4e64d064253a812495070227f7a --><!-- empty -->
<p>Microsoft pushed throughout 2023 to <a href="https://arstechnica.com/gadgets/2023/06/windows-11s-copilot-brings-ai-chat-to-desktops-in-first-public-preview/">add generative AI capabilities to its software</a>, even extending its new <a href="https://www.microsoft.com/en-us/windows/copilot-ai-features">Copilot AI assistant</a> to Windows 10 <a href="https://arstechnica.com/gadgets/2023/11/microsoft-is-revisiting-windows-10-by-backporting-the-copilot-ai-assistant/">late last year</a>. Now, those efforts to transform PCs at a software level is extending to the hardware: Microsoft is <a href="https://blogs.windows.com/windowsexperience/?p=178614">adding a dedicated Copilot key</a> to PC keyboards, adjusting the standard Windows keyboard layout for the first time since the Windows key first appeared on its <a href="https://en.wikipedia.org/wiki/Microsoft_ergonomic_keyboards#/media/File:MicrosoftNaturalKeyboardGen1.jpg">Natural Keyboard in 1994</a>.</p>
<p>The Copilot key will, predictably, open up the Copilot generative AI assistant within Windows 10 and Windows 11. On an up-to-date Windows PC with Copilot enabled, you can currently do the same thing by pressing Windows + C. For PCs without Copilot enabled, including those that aren't signed into Microsoft accounts, the Copilot key will open Windows Search instead (though this is sort of redundant, since pressing the Windows key and then typing directly into the Start menu also activates the Search function).</p>
<p>A <a href="https://www.youtube.com/watch?v=S1R08Qx6Fvs">quick Microsoft demo video</a> shows the Copilot key in between the cluster of arrow keys and the right Alt button, a place where many keyboards usually put a menu button, a right Ctrl key, another Windows key, or something similar. The exact positioning, and the key being replaced, may vary depending on the size and layout of the keyboard.</p>
<p>We asked Microsoft if a Copilot key would be required on OEM PCs going forward; the company told us that the key isn't mandatory now, but that it expects Copilot keys to be required on Windows 11 keyboards "over time." Microsoft often imposes <a href="https://techcommunity.microsoft.com/t5/windows-hardware-certification/windows-hardware-compatibility-program-guidance-for-windows-11/ba-p/3938433">some additional hardware requirements</a> on major PC makers that sell Windows on their devices, beyond what is strictly necessary to run Windows itself.</p>                                            
                                                        

<p>If nothing else, this new key is a sign of how much Microsoft wants people to use Copilot and its other generative AI products. Plenty of past company initiativesâBing, Edge, Cortana, and the Microsoft Store, to name a fewânever managed to become baked into the hardware like this. In the Windows 8 epoch, Microsoft required OEMs to <a href="https://learn.microsoft.com/en-us/previous-versions/windows/hardware/cert-program/windows-hardware-certification-requirements-for-client-and-server-systems?redirectedfrom=MSDN">build a Windows button into the display bezel</a> of devices with touchscreens, but that requirement eventually disappeared. If Copilot fizzles or is deemphasized the way Cortana was, the Copilot key could become a way to quickly date a Windows PC from the mid-2020s, the way that changes to the Windows logo date keyboards from earlier eras.</p>
<p>We'll definitely see more AI features from Microsoft this year, tooâMicrosoft Chief Marketing Officer Yusuf Medhi called 2024 "the year of the AI PC" in today's announcement.</p>
<p>Chipmakers like <a href="https://arstechnica.com/gadgets/2023/12/intel-intros-first-meteor-lake-chips-with-faster-gpus-and-worse-single-core-speed/">Intel</a>, <a href="https://arstechnica.com/gadgets/2023/12/amds-new-ryzen-8040-laptop-chips-look-a-lot-like-the-ryzen-7040-cpus/">AMD</a>, and <a href="https://arstechnica.com/gadgets/2023/10/qualcomm-snapdragon-x-elite-looks-like-the-windows-worlds-answer-to-apple-silicon/">Qualcomm</a> are all building neural processing units (NPUs) into their latest silicon, and we'll likely see more updates for Windows apps and features that can take advantage of this new on-device processing capability. Rumors also indicate that we could see a "<a href="https://www.theverge.com/2023/10/7/23907234/intel-windows-12-2024-refresh-launch">Windows 12</a>" release as soon as this year; while Windows 11 has mostly had AI features stacked on top of it, a new OS could launch with AI features more deeply integrated into the UI and apps, as well as additional hardware requirements for some features.</p>
<p>Microsoft says the Copilot key will debut in some PCs that will be announced at the Consumer Electronics Show this month. Surface devices with the revised keyboard layout are "upcoming."</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We don't need a DAC on the ESP32-S3 (133 pts)]]></title>
            <link>https://atomic14.substack.com/p/esp32-s3-no-dac</link>
            <guid>38881416</guid>
            <pubDate>Fri, 05 Jan 2024 17:03:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://atomic14.substack.com/p/esp32-s3-no-dac">https://atomic14.substack.com/p/esp32-s3-no-dac</a>, See on <a href="https://news.ycombinator.com/item?id=38881416">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div id="youtube2-oZ39VCUvKjw" data-attrs="{&quot;videoId&quot;:&quot;oZ39VCUvKjw&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/oZ39VCUvKjw?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div><p>So, thereâs no DAC on the ESP32-S3.</p><p>You would think this would be a bit of a downer if if you want to get audio out and use an analog amplifier.</p><p><span>But itâs actually surprisingly easy to output </span><strong>P</strong><span>ulse </span><strong>D</strong><span>ensity </span><strong>M</strong><span>odulated audio using Sigma Delta Modulation on the ESP32 and you can recover the audio signal by low pass filtering it - an RC filter can be sufficient for this. And thatâs what Iâm using in the video.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7012915f-2850-4b9c-829a-d1d8fee9b450_248x177.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7012915f-2850-4b9c-829a-d1d8fee9b450_248x177.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7012915f-2850-4b9c-829a-d1d8fee9b450_248x177.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7012915f-2850-4b9c-829a-d1d8fee9b450_248x177.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7012915f-2850-4b9c-829a-d1d8fee9b450_248x177.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7012915f-2850-4b9c-829a-d1d8fee9b450_248x177.png" width="248" height="177" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7012915f-2850-4b9c-829a-d1d8fee9b450_248x177.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:177,&quot;width&quot;:248,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2336,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7012915f-2850-4b9c-829a-d1d8fee9b450_248x177.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7012915f-2850-4b9c-829a-d1d8fee9b450_248x177.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7012915f-2850-4b9c-829a-d1d8fee9b450_248x177.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7012915f-2850-4b9c-829a-d1d8fee9b450_248x177.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>Though the Espressif docs do suggest a much better active filter.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef53e813-42ca-4c38-8a11-49c6ab276a70_1303x758.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef53e813-42ca-4c38-8a11-49c6ab276a70_1303x758.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef53e813-42ca-4c38-8a11-49c6ab276a70_1303x758.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef53e813-42ca-4c38-8a11-49c6ab276a70_1303x758.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef53e813-42ca-4c38-8a11-49c6ab276a70_1303x758.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef53e813-42ca-4c38-8a11-49c6ab276a70_1303x758.png" width="1303" height="758" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ef53e813-42ca-4c38-8a11-49c6ab276a70_1303x758.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:758,&quot;width&quot;:1303,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:84826,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef53e813-42ca-4c38-8a11-49c6ab276a70_1303x758.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef53e813-42ca-4c38-8a11-49c6ab276a70_1303x758.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef53e813-42ca-4c38-8a11-49c6ab276a70_1303x758.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef53e813-42ca-4c38-8a11-49c6ab276a70_1303x758.png 1456w" sizes="100vw"></picture></div></a></figure></div><p>Itâs pretty interesting to look at a PDM signal and view it in the frequency domain. Hereâs a piece of audio along with itâs spectrogram:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52c37f60-67a3-4392-989e-635a3793e882_2560x1440.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52c37f60-67a3-4392-989e-635a3793e882_2560x1440.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52c37f60-67a3-4392-989e-635a3793e882_2560x1440.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52c37f60-67a3-4392-989e-635a3793e882_2560x1440.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52c37f60-67a3-4392-989e-635a3793e882_2560x1440.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52c37f60-67a3-4392-989e-635a3793e882_2560x1440.jpeg" width="1456" height="819" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/52c37f60-67a3-4392-989e-635a3793e882_2560x1440.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:898112,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52c37f60-67a3-4392-989e-635a3793e882_2560x1440.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52c37f60-67a3-4392-989e-635a3793e882_2560x1440.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52c37f60-67a3-4392-989e-635a3793e882_2560x1440.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52c37f60-67a3-4392-989e-635a3793e882_2560x1440.jpeg 1456w" sizes="100vw"></picture></div></a></figure></div><p>And hereâs a simulated PDM version of the original audio. The sample rate of the PDM data is just over 1MHz and Iâm showing the spectrogram from 0 to 500KHz</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc97c6c1-fdea-4a61-89f3-40a3085c56a2_2560x1440.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc97c6c1-fdea-4a61-89f3-40a3085c56a2_2560x1440.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc97c6c1-fdea-4a61-89f3-40a3085c56a2_2560x1440.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc97c6c1-fdea-4a61-89f3-40a3085c56a2_2560x1440.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc97c6c1-fdea-4a61-89f3-40a3085c56a2_2560x1440.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc97c6c1-fdea-4a61-89f3-40a3085c56a2_2560x1440.jpeg" width="1456" height="819" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/dc97c6c1-fdea-4a61-89f3-40a3085c56a2_2560x1440.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:632200,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc97c6c1-fdea-4a61-89f3-40a3085c56a2_2560x1440.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc97c6c1-fdea-4a61-89f3-40a3085c56a2_2560x1440.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc97c6c1-fdea-4a61-89f3-40a3085c56a2_2560x1440.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc97c6c1-fdea-4a61-89f3-40a3085c56a2_2560x1440.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The PDM data just goes from -1 to 1 and changes density depending on the value of the original signal.</p><p>If we just look at the lower 8KHz of the spectrum then we can see what looks like our original signal.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8380d50e-abed-48be-a645-3944ab07abae_2560x1440.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8380d50e-abed-48be-a645-3944ab07abae_2560x1440.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8380d50e-abed-48be-a645-3944ab07abae_2560x1440.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8380d50e-abed-48be-a645-3944ab07abae_2560x1440.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8380d50e-abed-48be-a645-3944ab07abae_2560x1440.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8380d50e-abed-48be-a645-3944ab07abae_2560x1440.jpeg" width="1456" height="819" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8380d50e-abed-48be-a645-3944ab07abae_2560x1440.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:798744,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8380d50e-abed-48be-a645-3944ab07abae_2560x1440.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8380d50e-abed-48be-a645-3944ab07abae_2560x1440.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8380d50e-abed-48be-a645-3944ab07abae_2560x1440.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8380d50e-abed-48be-a645-3944ab07abae_2560x1440.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>So to recover the original audio we just apply a low pass filter - and hey presto, we have our original audio signal back!</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F866f1b69-d4f8-4717-800e-8ad34cb53beb_2560x1440.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F866f1b69-d4f8-4717-800e-8ad34cb53beb_2560x1440.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F866f1b69-d4f8-4717-800e-8ad34cb53beb_2560x1440.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F866f1b69-d4f8-4717-800e-8ad34cb53beb_2560x1440.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F866f1b69-d4f8-4717-800e-8ad34cb53beb_2560x1440.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F866f1b69-d4f8-4717-800e-8ad34cb53beb_2560x1440.jpeg" width="1456" height="819" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/866f1b69-d4f8-4717-800e-8ad34cb53beb_2560x1440.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1000408,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F866f1b69-d4f8-4717-800e-8ad34cb53beb_2560x1440.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F866f1b69-d4f8-4717-800e-8ad34cb53beb_2560x1440.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F866f1b69-d4f8-4717-800e-8ad34cb53beb_2560x1440.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F866f1b69-d4f8-4717-800e-8ad34cb53beb_2560x1440.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>So how to do we do this on the ESP32?</p><p>Thereâs a couple of options available to us.</p><p><span>The </span><a href="https://github.com/espressif/esp-idf/tree/b4268c874a4cf8fcf7c0c4153cffb76ad2ddda4e/examples/peripherals/sigma_delta/sdm_dac" rel="">example code</a><span> from Espressif suggests using a timer to output each sample using the </span><strong>sigmadelta_set_duty </strong><span>(you could also just use plain old PWM as well). This does work for audio data, and Iâve got some simple </span><a href="https://github.com/atomic14/esp32-pdm-audio/blob/main/src/audio_output/PDMTimerOuput.cpp" rel="">sample code</a><span> that will do it, but itâs not very efficient - weâre constantly interrupted by a timer to send out the next sample. Thereâs also quite a lot of code required if you want to stream samples out from some other source.</span></p><p>A much better way is to use the I2S peripheral which can also output PDM data. There are two annoying things with this which are highlighted in the timing diagram from the docs.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F673638ce-01af-4b32-8907-7ac64810a82a_1874x447.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F673638ce-01af-4b32-8907-7ac64810a82a_1874x447.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F673638ce-01af-4b32-8907-7ac64810a82a_1874x447.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F673638ce-01af-4b32-8907-7ac64810a82a_1874x447.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F673638ce-01af-4b32-8907-7ac64810a82a_1874x447.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F673638ce-01af-4b32-8907-7ac64810a82a_1874x447.png" width="1456" height="347" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/673638ce-01af-4b32-8907-7ac64810a82a_1874x447.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:347,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:89482,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F673638ce-01af-4b32-8907-7ac64810a82a_1874x447.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F673638ce-01af-4b32-8907-7ac64810a82a_1874x447.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F673638ce-01af-4b32-8907-7ac64810a82a_1874x447.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F673638ce-01af-4b32-8907-7ac64810a82a_1874x447.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The first issue is that it always wants to output a left and right channel. This is a bit awkward if we just want to feed the PDM signal straight into an analog audio amplifier or headphones. But we can get around this by just outputting the same value for both the left and right channels.</p><p>The second issue is that it always wants to output a clock signal - we donât really need this. My workaround for this was to just assign the clock to IO45 or IO46 - on the S3 you canât really use these pins for much as they are strapping pins and itâs best to just leave them alone. But you can use them for outputs once the ESP32 has started up.</p><p><span>There are âproperâ PDM amplifier ICs that will take this signal - for example the </span><a href="https://www.analog.com/media/en/technical-documentation/data-sheets/max98358.pdf" rel="">MAX98358</a><span> or the </span><a href="https://www.analog.com/media/en/technical-documentation/data-sheets/SSM2537.pdf" rel="">SSM2537</a><span>.</span></p><p>This all works surprisingly well, you can drive headphones directly from the PDM signal and most analog amplifiers will take the combined stereo PDM signal and will have a low enough bandwidth that theyâll just work.</p><p>You can even just drive a speaker with a really simple half or full bridge and get reasonable audio out (though it may be quite noisy).</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f1cc0a9-8de7-4c4e-89c3-027bd68e69d5_911x921.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f1cc0a9-8de7-4c4e-89c3-027bd68e69d5_911x921.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f1cc0a9-8de7-4c4e-89c3-027bd68e69d5_911x921.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f1cc0a9-8de7-4c4e-89c3-027bd68e69d5_911x921.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f1cc0a9-8de7-4c4e-89c3-027bd68e69d5_911x921.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f1cc0a9-8de7-4c4e-89c3-027bd68e69d5_911x921.png" width="911" height="921" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8f1cc0a9-8de7-4c4e-89c3-027bd68e69d5_911x921.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:921,&quot;width&quot;:911,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:40191,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f1cc0a9-8de7-4c4e-89c3-027bd68e69d5_911x921.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f1cc0a9-8de7-4c4e-89c3-027bd68e69d5_911x921.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f1cc0a9-8de7-4c4e-89c3-027bd68e69d5_911x921.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f1cc0a9-8de7-4c4e-89c3-027bd68e69d5_911x921.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Have a watch of the video and let me know what you think.</p><div id="youtube2-oZ39VCUvKjw" data-attrs="{&quot;videoId&quot;:&quot;oZ39VCUvKjw&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/oZ39VCUvKjw?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Facebook incorrectly reports personal blog to DigitalOcean for phishing (219 pts)]]></title>
            <link>https://social.lol/@robb/111704215593992932</link>
            <guid>38880713</guid>
            <pubDate>Fri, 05 Jan 2024 16:17:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://social.lol/@robb/111704215593992932">https://social.lol/@robb/111704215593992932</a>, See on <a href="https://news.ycombinator.com/item?id=38880713">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Drones are the new drug mules (106 pts)]]></title>
            <link>https://www.vice.com/en/article/qjvma7/drug-trafficking-smugglers-using-drones</link>
            <guid>38880224</guid>
            <pubDate>Fri, 05 Jan 2024 15:44:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vice.com/en/article/qjvma7/drug-trafficking-smugglers-using-drones">https://www.vice.com/en/article/qjvma7/drug-trafficking-smugglers-using-drones</a>, See on <a href="https://news.ycombinator.com/item?id=38880224">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Packets of heroin and a drone confiscated by Indian Border Security Force from near the border outpost of Ranian. Photo: Narinder Nanu/AFP via Getty Images.</p></div><div data-component="BodyComponentRenderer"><p><span data-component="TextBlock"><p>Last week border officials in the Punjab region of India <a href="https://www.hindustantimes.com/cities/chandigarh-news/107-drones-shot-down-442-kg-heroin-seized-in-2023-in-punjab-bsf-101704045498166.html" target="_blank">revealed</a> they intercepted 107 drug-carrying drones sent by smuggling gangs last year over the border from Pakistan, the highest number on record.&nbsp;</p></span><span data-component="TextBlock"><p>Most were carrying heroin or opium from Pakistan to be dropped and received by collaborators in the Punjab, notorious for having Indiaâs <a href="https://www.vice.com/en/article/k7ezwa/what-it-is-like-to-run-a-rehab-centre-in-punjab-india-a-state-with-drug-addiction">worst levels of opiate addiction</a>.&nbsp;</p></span></p><p><span data-component="TextBlock"><p>Last year the head of a police narcotics unit in Lahore, a city in Pakistan which borders the Punjab, was <a href="https://tribune.com.pk/story/2438041/top-cop-dismissed-over-drug-trafficking" target="_blank">dismissed</a> after he was suspected of running a drug trafficking gang sending drones over to India.&nbsp;&nbsp;&nbsp;</p></span><span data-component="TextBlock"><p>But the use of cheap flying robots instead of humans to smuggle drugs across borders is a worldwide phenomenon.&nbsp;</p></span><span data-component="TextBlock"><p>In September the Jordanian air force <a href="https://www.reuters.com/world/middle-east/jordan-downs-two-drones-carrying-drugs-syria-army-statement-2023-09-26/" target="_blank">shot down</a> two drones carrying crystal meth coming from Syria. It was the<a href="https://www.aljazeera.com/news/2023/9/5/jordan-shoots-down-drug-laden-drone-from-syria-in-ninth-incident-this-year" target="_blank"> ninth such drone</a> in 2023, according to Caroline Rose, a director at the New Lines Institute in Washington DC.</p></span><span data-component="TextBlock"><p>Drug smugglers from Syria, <a href="https://www.vice.com/en/article/v7v8k8/syria-captagon-pills-drug-trade">the worldâs largest producer of the black market amphetamine pill, captagon</a>, often use Jordan as a transit point to the wider Gulf Arab kingdoms and the global market. Rose thinks Syrian smugglers have increased the use of drones to smuggle captagon and meth due to a security clampdown at the Jordanian border which has made trafficking by land harder.&nbsp;</p></span><span data-component="TextBlock"><p>Drones sent by Mexican cartels carrying drugs such as cocaine, meth, and heroin regularly cross the U.S. border.&nbsp;</p></span><span></span><span data-component="TextBlock"><p>They are being used to shift drugs by air and sea between Africa and Europe.&nbsp;</p></span><span data-component="TextBlock"><p>Spanish police seized <a href="https://www.vice.com/en/article/dyvwmv/look-at-this-huge-drug-drone-seized-by-cops-in-spain">a massive drone with a wingspan of over four metres</a> capable of carrying up to 150 kilograms (330 pounds) of cargo in <a href="https://twitter.com/policia/status/1414875097752653826?s=20" target="_blank">a special compartment</a> in its nose, being used by a French smuggling gang to traffic drugs from Morocco to southern Spain. In 2022, police found three <a href="https://www.bbc.co.uk/news/world-europe-62040790" target="_blank">underwater drones</a> built to smuggle up to 200 kilograms (440 pounds) of drugs across the Strait of Gibraltar between Morocco and Spain.&nbsp;&nbsp;&nbsp;</p></span><span data-component="TextBlock"><p>Drones are being used to smuggle drugs into high security prisons worldwide from Brazil and France to Australia and <a href="https://www.youtube.com/watch?v=BezZxQF2pRw" target="_blank">across the U.S</a>.</p></span><span data-component="TextBlock"><p>In Canada, where 75 percent of prison contraband seizures are attributed to drone drops, there were <a href="https://www.cbc.ca/news/canada/british-columbia/drug-smuggling-drones-1.6822091" target="_blank">700 drone related incidents</a> in two years, including one where an inmate fatally overdosed on fentanyl that had been delivered into his prison by drone.</p></span></p><p><span data-component="TextBlock"><p>In October last year the U.K. government was forced to <a href="https://www.gov.uk/government/news/new-prison-no-fly-zones-for-drug-delivering-drones" target="_blank">introduce no fly zones </a>around all its prisons due to a âsharp increaseâ in the number of drones carrying drugs and mobile phones into jails.&nbsp;&nbsp;</p></span><span></span><span data-component="TextBlock"><p>Drug gangs are also using drones as eyes in the sky.&nbsp;</p></span><span data-component="TextBlock"><p>In Latin America and the Golden Triangle in Southeast Asia, drug trafficking cartels use them to scout out drug smuggling routes. In the U.K. they have been used by drug stash thieves to seek out rival weed farms and by guerilla weed growers to find suitable spots to set up illegal farms.&nbsp;</p></span><span data-component="TextBlock"><p>They are used by law enforcement too, from heat seeking drones spotting indoor cannabis farms in the U.K., to drones being used by police to catch street drug dealers in Kyrgyzstan in central Asia.</p></span><span data-component="TextBlock"><p>But drones will likely become an everyday part of drug dealing too, according to Peter Warren Singer, author of multiple books on national security and a Fellow at think tank New America, with legit medicines <a href="https://eu.freep.com/story/news/health/2023/03/16/university-of-michigan-medicine-drone-delivery-prescription-drugs-zipline/70013061007/" target="_blank">due to be delivered by drone</a> in the U.S. later this year and <a href="https://www.kcl.ac.uk/news/drones-opioid-overdose-reversal-kits-reach-people-faster-ambulances" target="_blank">maybe in the U.K. too</a>.&nbsp;&nbsp;</p></span><span data-component="TextBlock"><p>âWe are just scraping the surface of what is possible, as drone deliveries become more and more common in the commercial world, it will be the same with delivery of illicit goods. In our book, <em>Burn-In</em>, we explain how a future city will see drones zipping about delivering everything from groceries and burritos to drugs, both prescribed by a doctor or bought off a dealer.</p></span><span></span><span data-component="TextBlock"><p>âDrones have traditionally been used by governments and corporations for what are known as the "3 D's" jobs that are too dull, dirty, or dangerous for humans. For criminals, it is the same, except add in another D: Dependable. A drone doesn't steal the product and can't be arrested or snitch if caught.â&nbsp;</p></span></p><p><span data-component="TextBlock"><p>Liam OâShea, senior research fellow for organised crime and policing at defence and&nbsp;security thinktank RUSI, said drones were at the moment of limited value to wholesale traffickers and organised criminal gangs because of their range and the weight they can carry.&nbsp;</p></span><span data-component="TextBlock"><p>âIt makes sense that smugglers would seek to use drones. They are cheap and easy to acquire. They also lower the risks involved in some transactions, as smugglers do not have to be physically present during transactions. They offer opportunities for smuggling in areas where previous routes were too risky, such as prisons and over securitised borders.</p></span><span data-component="TextBlock"><p>âI expect them to be of greater value to smaller players and distributors dealing with smaller quantities. Wholesale drug traffickers will still need to use routes that facilitate smuggling at higher volume or using drones to make multiple trips, which entails risks of detection.&nbsp;</p></span><span data-component="TextBlock"><p>âThat may well change as improvements in technology improve dronesâ carrying capacity and crime groups are better able to access drones with greater capacity.â</p></span></p></div><div><p><h3>Get the latest from VICE News in your inbox. Sign up right here.</h3></p><p>By signing up, you agree to the<!-- --> <a href="https://vice-web-statics-cdn.vice.com/privacy-policy/en_us/page/terms-of-use.html">Terms of Use</a> <!-- -->and<!-- --> <a href="https://vice-web-statics-cdn.vice.com/privacy-policy/en_us/page/privacy-policy.html">Privacy Policy</a> <!-- -->&amp; to receive electronic communications from Vice Media Group, which may include marketing promotions, advertisements and sponsored content.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Archiving Steam games for fun and profit (135 pts)]]></title>
            <link>https://lorendb.dev/posts/archiving-steam-games-for-fun-and-profit/</link>
            <guid>38878830</guid>
            <pubDate>Fri, 05 Jan 2024 13:30:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lorendb.dev/posts/archiving-steam-games-for-fun-and-profit/">https://lorendb.dev/posts/archiving-steam-games-for-fun-and-profit/</a>, See on <a href="https://news.ycombinator.com/item?id=38878830">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
  <article>
    
    <div>
      <blockquote>
<p>tldr: if you want to create an archive of all your Steam games, check out <a href="https://github.com/LorenDB/download-steam-games">download-steam-games</a> on my GitHub. It has minimal documentation, but you should be able to get it running without too much trouble.</p>
</blockquote>
<p>I recently decided it would be cool to download some beta versions of <a href="https://www.kerbalspaceprogram.com/games-kerbal-space-program-2">KSP2</a> so I can revisit them in a year or so and laugh about how many terrible bugs there were in the original version of the game. I decided that it would make sense to download the game backup directly to my server, so I <code>ssh</code>ed into the server, installed Steam from the system repositories, and started a new <code>ssh -X</code> session. However, when I launched Steam, I realized that my serverâs connection to the internet is much too slow to run <code>ssh -X</code> in any sort of usable state. In fact, it was so slow that it apparently timed something out on Steamâs end and made it practically impossible to log in to Steam.</p>
<p>Undaunted, I started looking into <a href="https://developer.valvesoftware.com/wiki/SteamCMD">SteamCMD</a>. It turns out that while SteamCMD is intended for game server administrators, it will happily download any Steam game. It didnât take me long to install it and use it to download a game. However, itâs a bit of a pain running through a set of instructions in SteamCMD again and again for downloading multiple games, so I set out to script it.</p>
<h2 id="but-why-would-you-do-this">But why would you do this?</h2>
<p>Why wouldnât I do this? If you think Iâm crazy, just go read <a href="https://www.reddit.com/r/DataHoarder/">r/DataHoarder</a> for a while.</p>
<p>Seriously, while I donât expect Steam to disappear tomorrow, there is precedent for games to be removed from the platform; many of the original games on the platform have been removed. The oldest game still available (counting by which date it was made available on Steam) is the original <a href="https://store.steampowered.com/app/10">Counterstrike</a> with a game ID of 10. Games 1 through 9 arenât on the platform anymore, and Iâm sure they are far from the only games deleted from the platform. Archiving games allows me to avoid losing games that are removed from Steam. Also, sometimes enthusiasts like to be able to access old versions of games; one of the top posts of all time on r/DataHoarder is about <a href="https://www.reddit.com/r/DataHoarder/comments/o9cnj3/one_womans_quest_to_never_delete_anything_allowed/">somebody who hoarded an old Minecraft alpha</a>, giving Minecraft enthusiasts a chance at taking a more complete look at the evolution of the game.</p>
<h2 id="a-naÃ¯ve-bash-script">A naÃ¯ve bash script</h2>
<p>My first approach was to create a bash script to wrap SteamCMD with a nice syntax. Of course, I also wanted to bypass the interactive prompt. Letâs go through what I ended up building:</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>STEAM_ACCOUNT<span>=</span>
</span></span><span><span>GAME_NAME<span>=</span>
</span></span><span><span>GAME_STEAM_ID<span>=</span>
</span></span><span><span>GAME_FORCE_WINDOWS<span>=</span>
</span></span><span><span>GAME_BETA<span>=</span>
</span></span></code></pre></div><p>These variables control some basic stuff. <code>STEAM_ACCOUNT</code> is the account you logged into SteamCMD with; while SteamCMD caches credentials, you still have to issue the <code>login &lt;username&gt;</code> command every time you start it, so the script has to know what username to use. <code>GAME_NAME</code> doesnât have to be the actual game name; itâs just used to generate the filename for the final game archive. <code>GAME_STEAM_ID</code> is the numerical ID of the game you want to download; for example, KSP2 is <a href="https://store.steampowered.com/app/954850/Kerbal_Space_Program_2/"><code>954850</code></a>.</p>
<p><code>GAME_FORCE_WINDOWS</code> deserves a more detailed explanation. While I run Linux, some games do not have Linux builds available. For those games, I would like to save a backup of the Windows build instead. This will let me run the game via Proton later. Conveniently, SteamCMD allows you to override what platform you download the game for by setting <code>@sSteamCmdForcePlatformType &lt;platform&gt;</code>. <code>GAME_FORCE_WINDOWS</code> is used later as part of the SteamCMD script contents; therefore, if I want to add a Windows override, I can set <code>GAME_FORCE_WINDOWS</code> to <code>@sSteamCmdForcePlatformType windows</code>.</p>
<p>Finally, we have <code>GAME_BETA</code>. <a href="https://steamdb.info/">SteamDB</a> shows beta version identifiers for games; you can use those to download earlier versions of some games. This is something I want to use, given that the original purpose of this project was to archive early KSP2 builds.</p>
<p>The next bit of the script is simply logic to set each of these variables based on command line parameters. Iâve decided to skip it for brevity, as it is trivial bash logic. Moving on, we get this:</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>cat &gt; ~/.download-$GAME_NAME.txt <span>&lt;&lt; EOF
</span></span></span><span><span><span>$GAME_FORCE_WINDOWS
</span></span></span><span><span><span>force_install_dir $HOME/Steam/downloads/$GAME_NAME
</span></span></span><span><span><span>login $STEAM_ACCOUNT
</span></span></span><span><span><span>app_update $GAME_STEAM_ID $GAME_BETA validate
</span></span></span><span><span><span>quit
</span></span></span><span><span><span>EOF</span>
</span></span></code></pre></div><p>SteamCMD can be controlled by scripts. This is how weâre going to get around its interactive interface.</p>
<p>The first line of the script is the aforementioned platform override. After that, we use <code>force_install_dir</code> to force SteamCMD to download the game to a known location. In this version of the script, Iâve hardcoded it to <code>~/Steam/downloads</code>, since Iâve installed SteamCMD to <code>~/Steam</code>. Then we log in and issue the actual command to grab the app; once the app has downloaded, we quit SteamCMD.</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>PREVIOUS_DIR<span>=</span><span>$(</span>pwd<span>)</span>
</span></span><span><span>cd ~/Steam
</span></span><span><span>~/Steam/steamcmd.sh +runscript $HOME/.download-$GAME_NAME.txt
</span></span><span><span>cd $PREVIOUS_DIR
</span></span><span><span>rm ~/.download-$GAME_NAME.txt
</span></span></code></pre></div><p>Here we actually execute the script and then delete it to prevent clutter.</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>PREVIOUS_DIR<span>=</span><span>$(</span>pwd<span>)</span>
</span></span><span><span>cd ~/Steam/downloads
</span></span><span><span>tar --use-compress-program<span>=</span>pigz -cf $PREVIOUS_DIR/$GAME_NAME.tar.gz $GAME_NAME
</span></span><span><span>cd $PREVIOUS_DIR
</span></span><span><span>
</span></span><span><span>rm -r $HOME/Steam/downloads/$GAME_NAME
</span></span></code></pre></div><p>The final step is to compress the game folder into a single <code>.tar.gz</code> file. Again, weâre dumping the final archive into <code>~/Steam/downloads</code> for now. The only really unusual part of this is that Iâm telling <code>tar</code> to use <code>pigz</code> to do the gzip compression. This is because <code>pigz</code> will use all CPU cores, which is important when youâre archiving many gigabytes of game data.</p>
<p>This is all fine and good, but you still have to manually run the command for each game. To mitigate this, I created a <a href="https://paste.segfault.foo/loren/ac1cfff462804e70bdf85fb764328b19">simple script</a> that read a vaguely CSV-like file which listed games to download. That was definitely better than nothing, but it still felt pretty hacky.</p>
<h2 id="building-it-the-right-way">Building it the right way</h2>
<p>I decided to port my two scripts into one app. I chose to write the app in <a href="https://dlang.org/">D</a>; in retrospect, Python would probably have been a good choice simply because it comes preinstalled on pretty much every distro, but I much prefer D for pretty much anything. My ported script is pretty similar to the functionality shown above; however, I added various improvements. Paths are no longer hardcoded, itâs possible to download games for any and all platforms (Windows, macOS, and Linux), and game data is stored as a JSON file instead of in a weird custom-ish format.</p>
<p>The app, which Iâm calling <code>download-steam-games</code> (how original), is available <a href="https://github.com/LorenDB/download-steam-games">on GitHub</a>. Building it is a simple matter of running <code>dub build</code>. After that, you need to run <code>dub run -- --add-game</code> to add a game to the download list. After youâve added some games, you can use <code>dub run</code> to run the application in download mode. It will download all your games for every platform youâve specified, <code>.tar.gz</code> them, and put them in the output folder of your choosing.</p>
<h2 id="limitations">Limitations</h2>
<p>The app currently is somewhat limited: thereâs no functionality to reconfigure the settings, you canât specify beta versions with <code>--add-game</code>, and thereâs no progress reporting during download. However, I think itâs robust enough to actually use in production. I hope to address all of these issues soon, and while Iâm at it, Iâd like to add a feature to add a timestamp to the archive name so you can download many versions of the same game over time.</p>
<h2 id="conclusion">Conclusion</h2>
<p>This is a fun project that is helping get me hooked on data hoarding. If you start using my app to help hoard your own games, please leave a comment below! Iâd love seeing how many gigabytes (or terabytes) of games youâre hoarding.</p>
<h2 id="updates">Updates</h2>
<p>Shortly after writing this post, Iâve added some logging to the app. It ainât pefect, but it ainât terrible either.</p>







    </div>
    
  </article>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Duty to Document (2023) (143 pts)]]></title>
            <link>https://nicolasbouliane.com/blog/duty-to-document</link>
            <guid>38878779</guid>
            <pubDate>Fri, 05 Jan 2024 13:22:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nicolasbouliane.com/blog/duty-to-document">https://nicolasbouliane.com/blog/duty-to-document</a>, See on <a href="https://news.ycombinator.com/item?id=38878779">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
    <article>
        <h2>
            The duty to document
            <small>Posted on <time datetime="2023-05-02">May 2, 2023</time></small>
        </h2>
        
        <p>If you learn something the hard way, share your findings with others. You have blazed a new trail; now you must mark it for your fellow travellers. Sharing knowledge is an unreasonably effective way of helping others.</p>
<picture><source srcset="https://nicolasbouliane.com/images/content2x/annotated-map.jpg 1848w, https://nicolasbouliane.com/images/content1x/annotated-map.jpg 924w, https://nicolasbouliane.com/images/content0.75x/annotated-map.jpg 690w" type="image/jpeg"><source srcset="https://nicolasbouliane.com/images/content2x/annotated-map.webp 1848w, https://nicolasbouliane.com/images/content1x/annotated-map.webp 924w, https://nicolasbouliane.com/images/content0.75x/annotated-map.webp 690w" type="image/webp"><img alt="Hiking map with hand-drawn annotations" height="842" loading="lazy" src="https://nicolasbouliane.com/images/content2x/annotated-map.jpg" width="1842"></picture>
<p>I owe a debt of gratitude to those whose knowledge helped me debug software, repair bicycles, choose camping gear, start a business, and deal with anything life throws at me.</p>
<p>I repay that debt by marking my own trails. When I think âit should not have been this hard to find outâ, I make it easier to find out. Over the years, I have documented everything from <a href="https://nicolasbouliane.com/blog/ffmpeg-extract-subtitles">ffmpeg incantations</a> to <a href="https://www.openstreetmap.org/changeset/72463537">Uzbek petrol stations</a>, and made a career out of <a href="https://nicolasbouliane.com/projects/all-about-berlin">documenting German bureaucracy</a>.</p>
<p>I figure that if you have knowledge that could benefit thousands of people, and it costs you next to nothing to share that knowledge, itâs your duty to do it.</p>

<ul>
<li><a href="https://nicolasbouliane.com/blog/maps">A map for everything</a></li>
</ul>
    </article>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Consumer Reports finds 'widespread' presence of plastics in food (297 pts)]]></title>
            <link>https://www.reuters.com/business/healthcare-pharmaceuticals/consumer-reports-finds-widespread-presence-plastics-food-2024-01-04/</link>
            <guid>38878683</guid>
            <pubDate>Fri, 05 Jan 2024 13:10:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/business/healthcare-pharmaceuticals/consumer-reports-finds-widespread-presence-plastics-food-2024-01-04/">https://www.reuters.com/business/healthcare-pharmaceuticals/consumer-reports-finds-widespread-presence-plastics-food-2024-01-04/</a>, See on <a href="https://news.ycombinator.com/item?id=38878683">Hacker News</a></p>
Couldn't get https://www.reuters.com/business/healthcare-pharmaceuticals/consumer-reports-finds-widespread-presence-plastics-food-2024-01-04/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Everything will be alright in Iceland (147 pts)]]></title>
            <link>https://memoirsandrambles.substack.com/p/everything-will-be-alright-in-iceland</link>
            <guid>38878640</guid>
            <pubDate>Fri, 05 Jan 2024 13:03:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://memoirsandrambles.substack.com/p/everything-will-be-alright-in-iceland">https://memoirsandrambles.substack.com/p/everything-will-be-alright-in-iceland</a>, See on <a href="https://news.ycombinator.com/item?id=38878640">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F132c825c-729d-48b2-937d-8745f1c63236_2781x2086.jpeg" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F132c825c-729d-48b2-937d-8745f1c63236_2781x2086.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F132c825c-729d-48b2-937d-8745f1c63236_2781x2086.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F132c825c-729d-48b2-937d-8745f1c63236_2781x2086.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F132c825c-729d-48b2-937d-8745f1c63236_2781x2086.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F132c825c-729d-48b2-937d-8745f1c63236_2781x2086.jpeg" width="1456" height="1092" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/132c825c-729d-48b2-937d-8745f1c63236_2781x2086.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1092,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1493519,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F132c825c-729d-48b2-937d-8745f1c63236_2781x2086.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F132c825c-729d-48b2-937d-8745f1c63236_2781x2086.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F132c825c-729d-48b2-937d-8745f1c63236_2781x2086.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F132c825c-729d-48b2-937d-8745f1c63236_2781x2086.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>Picture of Fagradalsfjall taken by me in 2021</figcaption></figure></div><p>I was recently asked one of the best questions someone who's lived in a bunch of countries could be asked, surprisingly for the first time:</p><p>What did you learn from each place you lived in? What do people do there that you think could be applied elsewhere?</p><p>For Iceland, I believe I said something about people's contact with nature. Just about every Icelandic person has been on a hike, and they all seem to have a level of admiration and care for nature that's not as widespread elsewhere.</p><p>But in light of the most recent volcanic eruption, I got to thinking about something else.</p><p><span>There's a saying in Icelandic - </span><em>Ã¾etta reddast</em><span> - that means "everything will be alright", and, while many languages have a similar expression, this one is really embedded in Icelandic culture.</span></p><p>I remember the first time I felt an earthquake in my life, back when I lived there. I was reasonably worried, and started remembering things I'd seen as a child.</p><p><span>"</span><em>Should we get under a table?</em><span>" â I asked my Icelandic girlfriend at the time. She didn't seem too phased, and before she had a chance to answer, the quake stopped. "</span><em>Well, I guess it's all good now</em><span>".</span></p><p>There was also the time when I was convinced to âwalk upâ (turns out it was actually climb up) one of the ice pinnacles atop of SnaefellsjÃ¶kull. At the time I had no experience with crampons or an ice axe at all, yet the group of also amateurs from my ex-girlfriend's company were all pretty chill about the situation and pitched it as a seemingly easy thing.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0b9b5124-f0eb-4940-bae1-452cc71552a4_3000x4000.jpeg" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0b9b5124-f0eb-4940-bae1-452cc71552a4_3000x4000.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0b9b5124-f0eb-4940-bae1-452cc71552a4_3000x4000.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0b9b5124-f0eb-4940-bae1-452cc71552a4_3000x4000.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0b9b5124-f0eb-4940-bae1-452cc71552a4_3000x4000.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0b9b5124-f0eb-4940-bae1-452cc71552a4_3000x4000.jpeg" width="1456" height="1941" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0b9b5124-f0eb-4940-bae1-452cc71552a4_3000x4000.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1941,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2816635,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0b9b5124-f0eb-4940-bae1-452cc71552a4_3000x4000.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0b9b5124-f0eb-4940-bae1-452cc71552a4_3000x4000.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0b9b5124-f0eb-4940-bae1-452cc71552a4_3000x4000.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0b9b5124-f0eb-4940-bae1-452cc71552a4_3000x4000.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>SnaefellsjÃ¶kull, 2022.</figcaption></figure></div><p>On the way up there, quite a few of the people got scared, and I for one nearly lost my oversized crampon, which came off my foot and caused me to slide down this steep ice slope that led straight into a crevasse at the bottom. I managed to stop myself with an ice axe self-arrest, saved by having used my free time in the past to watch alpinism videos with self-arrest tutorials.</p><p>The thing is that living in Iceland requires a unique type of mentality, even if the Icelanders themselves don't necessarily think about it much.</p><p>To live essentially on top of a volcano or with a massive volcano nearby requires a mix of belief that everything will be okay, but also determination and preparedness to make it be so.</p><p>And in some ways you almost need to just to be willing to start over.</p><p>Before I lived there, the first time I visited Iceland I stayed in this farmer's cabin in the South, and he told us about how despite him being okay and his house staying up, he lost all of his sheep due to the ash from the 2010 EyjafjallajÃ¶kull eruption. </p><p>If you don't believe everything will be alright in the end - how do you keep going?</p><p>Yet despite the expression seemingly tossing the responsibility of making things good up to fate, it's also your responsibility to make it alright.</p><p>I was once told Icelandic consultants are particularly wanted during crises. They operate well in the post-catastrophe chaos, bringing both a necessary optimism and also an ability to prioritize and stay rational.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6bbd682-cb63-4233-8ffa-bebc54142773_3000x4000.jpeg" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6bbd682-cb63-4233-8ffa-bebc54142773_3000x4000.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6bbd682-cb63-4233-8ffa-bebc54142773_3000x4000.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6bbd682-cb63-4233-8ffa-bebc54142773_3000x4000.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6bbd682-cb63-4233-8ffa-bebc54142773_3000x4000.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6bbd682-cb63-4233-8ffa-bebc54142773_3000x4000.jpeg" width="1456" height="1941" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d6bbd682-cb63-4233-8ffa-bebc54142773_3000x4000.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1941,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:4415224,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6bbd682-cb63-4233-8ffa-bebc54142773_3000x4000.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6bbd682-cb63-4233-8ffa-bebc54142773_3000x4000.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6bbd682-cb63-4233-8ffa-bebc54142773_3000x4000.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6bbd682-cb63-4233-8ffa-bebc54142773_3000x4000.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Me with Fagradalsfjall (maybe too close) in the back.</figcaption></figure></div><p>The Fagradalsfjall eruption in 2021, which happened while I was still living there, marked the end of around 800 years of no volcanic activity in the Reykjanes peninsula, an area of significant economic importance that's also dangerously close to where the vast majority of Icelanders live - the ReykjavÃ­k capital region.</p><p>But having some of the world's best geologists and volcanologists in the world, a well-trained Search &amp; Rescue team, and a conscious population means Iceland feels ready to deal with this, and that everything will be okay. </p><p>You see this from how fast GrindavÃ­k, a town potentially in danger, was evacuated ahead of this 2023 eruption, an event somewhat analogous to the heroic effort of the Heimaey evacuation in 1973, where an entire island was evacuated in just a few hours after the alarm sounded for a surprise eruption. Plus they also managed to save the harbor, by pumping seawater and spraying it into the lava to redirect it.</p><p>I say all this to say that Icelanders are possibly better prepared than most of us to deal with life. </p><p>Because the Icelandic antifragility built up from generations of living in an island that seems to not want you there should not be mistaken as something applicable only in their little island.</p><p>It has made Icelanders well-prepared to deal with an inevitable part of all of our lives â crisis.</p><p>By contrast, Brazilians love to mention how we have no natural disasters. We don't get earthquakes, have no active volcanoes, no hurricanes, nothing.</p><p>Yet every year thousands of homes are lost, people die, and infrastructure is damaged just from the repercussions of the comparatively predictable rainy season.</p><p>I'm sure that both for our country, but also our personal lives, we have a lot to learn. </p><p><span>Because in my experience, despite its inherent optimism, </span><em>Ã¾etta reddast </em><span>often</span><em> </em><span>doesnât imply âitâll be taken care ofâ, but rather âweâll take care of itâ.</span></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[June 30th, 2024, will bring the End of Life (EOL) of CentOS Linux (2023) (201 pts)]]></title>
            <link>https://www.redhat.com/en/blog/fastest-road-centos-linux-red-hat-enterprise-linux</link>
            <guid>38878587</guid>
            <pubDate>Fri, 05 Jan 2024 12:56:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.redhat.com/en/blog/fastest-road-centos-linux-red-hat-enterprise-linux">https://www.redhat.com/en/blog/fastest-road-centos-linux-red-hat-enterprise-linux</a>, See on <a href="https://news.ycombinator.com/item?id=38878587">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-eq-pts="xxs-hr: 0, md-hr: 360, lg-hr: 450">
        <p><strong>June 30th, 2024</strong>. Before you read anything else, commit that date to memory.</p>

<p>June 30th, 2024, will bring the End of Life (EOL) of CentOS Linux, and Red Hat Enterprise Linux 7 (RHEL 7) will be reaching End of Maintenance (EOM). The good news is that these events wonât require a complete infrastructure overhaul. Tools are available to move from your current configuration to a place where youâll have years of support.</p>

<p>While June of â24 may sound a ways off, do not delay. It will be here faster than you think. Start planning now. Start moving soon. Give yourself plenty of runway, and donât forget that we arenât just your software vendor at Red Hat. We are your partners and are here to help you with these transitions.</p>

<p>If youâre like me when looking at a long-term, intensive project, some time is required to stare at a blank screen and process the task before me. Let me see if I can help drive you into action.</p>

<h2>The hard way</h2>

<p>In my days as a systems administrator, we didnât consider in-place conversions or upgrades. For one thing, it wasnât the straightforward process we have today. Secondly, new operating systems and hardware retirements went hand in hand. New OS? Time for a new server model! There are specific environments where that is the case.&nbsp;</p>

<p>You can certainly buy new hardware (or spin up new cloud instances) on the latest versions of RHEL and do a ârip-and-replace,â moving over only your application data. But for many, this isnât an ideal approach. What other options are there?</p>

<p>If you want to keep your application on the same version and focus solely on the operating system for this project, you can do that too. Look at setting up a RHEL 8 or 9 server and running it as a container host for Podman. Put your applications into a container, and viola. You can build your applications into pre-built application images or <a href="https://catalog.redhat.com/software/containers/search?vendor_name=Red%20Hat&amp;p=1&amp;q=UBI">Universal Base Images (UBI)</a>.</p>

<p>However, this will require a fair amount of work as well. There is an easier way. In what amounts to a 2-phase process, we can convert your CentOS Linux systems onto a supported version of RHEL and then execute an in-place upgrade.&nbsp;</p>

<h2>Convert from CentOS Linux</h2>

<p><strong>Pop Quiz</strong>: When does CentOS Linux 7.9 go EOL?</p>

<p>If you said June 30th, 2024, then I can write the rest of this blog post feeling accomplished!&nbsp;</p>

<p>Red Hat has created a way for users to move to a supported operating system in place using a supported process.</p>

<p>Why in-place? Think of all the configurations, user home directories, processes and packages you already have running on these systems. An in-place upgrade means all that customization doesnât go away. The other piece of good news is that the conversion process and the resulting server image are both supported by Red Hat! In other words, if something breaks during or after the conversion, you can open a support ticket and get the help you need.</p>

<p>Now, we are looking at the final days of CentOS Linux. Youâve got hundreds (or even thousands) of servers running various minor releases of CentOS Linux 7. Letâs walk through what a conversion process looks like:</p>

<p><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" frameborder="0" height="315" src="https://www.youtube.com/embed/xX7P4BzOcNg" title="YouTube video player" width="560"></iframe></p>

<ol>
<li aria-level="1">The first thing to do, if you are running anything older than CentOS Linux 7.9, is to upgrade all of your packages to the latest minor release.&nbsp;</li>
<li aria-level="1">Once you are running CentOS Linux 7.9 with all the packages on their latest available version, you can configure the convert2rhel repository.</li>
<li aria-level="1">Run the conversion!</li>
<li aria-level="1">Validate your applications and register your systems to <a href="https://www.redhat.com/en/technologies/management/insights">Red Hat Insights</a>.</li>
<li aria-level="1">Brace yourselfâ we arenât done just yet.</li>
</ol>

<p>If you want to get your hands dirty, we have a <a href="https://www.redhat.com/en/interactive-labs/migrate-red-hat-enterprise-linux-centos-linux">Convert2RHEL lab</a> on our website to try for yourself!</p>

<h2>In-place upgrade</h2>

<p>Time for a review! When does RHEL 7 go EOM? If you said June 30th, 2024, you nailed it!</p>

<p>Now, you should be looking at a fleet of systems running RHEL 7.9. Perhaps you already had a group of systems running earlier releases of RHEL 7. Now would be an excellent time to patch those to the latest available package set and the recently converted CentOS Linux systems.&nbsp;</p>

<p>Much like CentOS Linux, RHEL 7 has limited life left. Red Hat does offer Extended Lifecycle Support (ELS) subscriptions if that is a path of interest. However, these entitlements come with an added cost. For todayâs thought exercise, we are looking at how to keep your systems feeling fresh (read supported) without added expense or the need to rip-and-replace later.</p>

<p><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" frameborder="0" height="315" src="https://www.youtube.com/embed/VVVwg9IyqwQ" title="YouTube video player" width="560"></iframe></p>

<ol>
<li aria-level="1">Once the âyumâ command says there are no available packages left to update, your RHEL systems are ready to upgrade to the latest version of RHEL 8.</li>
<li aria-level="1">Install the Leapp tools.</li>
<li aria-level="1">Run the pre-upgrade assessment and remediate any identified issues.</li>
<li aria-level="1">Run the in-place upgrade.</li>
<li aria-level="1">Validate the upgraded systems and their applications.</li>
</ol>

<p>That is all there is to it! Sit back and take a deep breath. Even after June 2024, RHEL 8 will still have five years of maintenance support.&nbsp;</p>

<p>If youâd like to try an in-place upgrade for yourself, we have a <a href="https://www.redhat.com/en/interactive-labs/perform-in-place-upgrade-with-leapp">self-paced lab</a> over on our website.</p>

<h2>Wrap up</h2>

<p>June 30th, 2024â¦</p>

<p>Set a countdown on your phone. Put a reminder on your desktop. Grab a sticky note and put it on your mirror. Whatever you have to do. The date is rapidly approaching, and as a former sysadmin, I donât want to see you having to scramble at the last minute to find ways to support your systems.</p>

<p>June 30th, 2024â¦</p>

<p>My experiences were always building a new server, with a new OS, on a new hardware platform. In the perfect world that exists only in my imagination, I might consider one last full-scale replacement and go straight to RHEL 9, then keep pace with the in-place upgrades for RHEL 10 and beyond.</p>

<p>Sadly, technology, applications, industries and organizations donât always march to that drum. Complex dependencies, processes and resource availabilities limit our ability to stay on the âlatest and greatest.â</p>

<p>If that is the position you find yourself in, follow the links in this blog, watch our videos and engage our <a href="https://access.redhat.com/">Support </a>and <a href="https://www.redhat.com/en/services/consulting">Services</a> organizations. Red Hat is your partner in this.</p>

<h2>Further reading</h2>

<ul>
<li><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/converting_from_an_rpm-based_linux_distribution_to_rhel/index">Converting from an RPM-based Linux distribution to RHEL</a></li>
<li><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/upgrading_from_rhel_7_to_rhel_8/index#doc-wrapper">Upgrading from RHEL 7 to RHEL 8</a></li>
</ul>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An app can be a home-cooked meal (828 pts)]]></title>
            <link>https://www.robinsloan.com/notes/home-cooked-app/</link>
            <guid>38877423</guid>
            <pubDate>Fri, 05 Jan 2024 10:03:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.robinsloan.com/notes/home-cooked-app/">https://www.robinsloan.com/notes/home-cooked-app/</a>, See on <a href="https://news.ycombinator.com/item?id=38877423">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<stamp-thwack>
<label>From:</label> Robin Sloan<br>
<label>To:</label> the lab<br>
<label>Sent:</label> February 2020
</stamp-thwack>

<p>Have you heard about this new app called&nbsp;BoopSnoop?</p>
<p>It launched in the first week of January 2020, and almost immediately, it was downÂ­loaded by four people in three different time zones. In the years since, it has remained steady at four daily active users, with zero churn: a resounding success, exceeding every one of its creatorâs&nbsp;expectations.</p>
<p>ð</p>
<p>I&nbsp;made a messaging app for, and with, my family. It is ruthÂ­lessly simple; we love it; no one else will ever use it. I&nbsp;wanted to share a few notes about how and why I&nbsp;made it, both to (a) offer a nudge to anyone else considÂ­ering a similar project, and (b) suggest something a little larger about&nbsp;software.</p>
<figure>
<video loop="" muted="" autobuffer="" playsinline="" controls="">
<!-- <source src="/media/boopsnoop-smile-faststart.webm" type="video/webm"> -->
<source src="https://www.robinsloan.com/media/boopsnoop-smile-faststart.mp4" type="video/mp4">
Your browser canât play my video clip. Rats!
</video>
<figcaption>
Tap or click to unmute.</figcaption>
</figure>
<h2>Barely there</h2>
<p>My story begins with another app, now defunct, called&nbsp;Tapstack.</p>
<p>Opening the app, you saw a live feed from your phoneâs camera. Below, a grid of faces, some of them representing individuals, others repreÂ­senting groups. My grid had four cells: my mom, my dad, my sister, and a group collecting all three. Just like Snapchat or Instagram, you tapped to capture a photo, pressed to record a video. As soon as you lifted your finger, your message zipped away, with no editing, no reviewing. A âstackâ of messages awaited you in the corner, and, after you tapped through them, they were&nbsp;discarded.</p>
<p>It was all so simple that it was barely there. Tapstack more closely approxÂ­iÂ­mated a clear pane of glass than any app Iâve ever&nbsp;used.</p>
<p>For several years, Tapstack was the main channel for my familyâs communication. The app didnât lend itself to practical correÂ­sponÂ­dence or logisÂ­tical coordination; its strength was ambient presence. I&nbsp;met one of Tapstackâs designers once, and they told me it seemed espeÂ­cially popular with far-flung families: a diaspora app. Because there was no threading and no history, messages didnât carry the burden of an expected reply. Really, they were just a carrier wave for another sentiment, and that sentiment was always the same: Iâm thinking of&nbsp;you.</p>
<p>A selfie with coffee, a picture of an ice-covered pond, a video of my nephews acting silly: Iâm thinking of you, Iâm thinking of you, Iâm thinking of&nbsp;you.</p>
<p>It never seemed to me that Tapstack attracted a huge number of users. I&nbsp;donât know if the company ever made a cent. There was no adverÂ­tising in the app, and they never asked their users to&nbsp;pay.</p>
<p>Why didnât they ask us to&nbsp;pay?</p>
<p>In 2019, I&nbsp;felt a rising dread as the months ticked by and the app didnât receive a single update. Sure enough, in the fall, Tapstack announced that it was shutting down. It offered its users a way to export their data. It went&nbsp;gracefully.</p>
<p>It was, I&nbsp;have to say, a really great&nbsp;app.</p>
<h2>Here comes a new challenger</h2>
<p>My family all agreed we were going to need a replacement, and while my first instinct was to set up a group on Instagram or WhatsApp, the prospect of having our warm channel <span>surroundedâââ</span><wbr>encroached <span>uponâââ</span><wbr>by all that other garbage made me feel even sadder than the prospect of losing&nbsp;Tapstack.</p>
<p>So, instead of settling for a corporate messaging appââ¦â</p>
<p>I&nbsp;built one just for&nbsp;us.</p>
<p>Iâll show you the screen capture again, but the point is that thereâs not much to show. The app is a âmagic windowâ that captures photos and videos and shuttles them around. Messages wait in a queue and, once <span>viewedâââ</span><wbr>always full-screen, with no distractions, no prods to comment or <span>shareâââ</span><wbr>they disappear. That is literally it. The app has basically no interface. Thereâs a camera button and a badge in the corner, calm green, that indicates how many messages are&nbsp;waiting.</p>
<figure>
<video loop="" muted="" autobuffer="" playsinline="" controls="">
<!-- <source src="/media/boopsnoop-smile-faststart.webm" type="video/webm"> -->
<source src="https://www.robinsloan.com/media/boopsnoop-smile-faststart.mp4" type="video/mp4">
Your browser canât play my video clip. Rats!
</video>
<figcaption>
Tap or click to unmute.</figcaption>
</figure>
<p>Here are a few mildly technical observations. Feel free to skip ahead if this part doesnât interest&nbsp;you:</p>
<ul>
<li>
<p>Tapstack was simple to start with, and I&nbsp;made it even simpler. Unlike Tapstack, my app doesnât need a login system. It doesnât need an interface to create and manage contacts. It already knows exactly whoâs using it. (This makes me think about <a href="https://web.archive.org/web/20040411202042/http://www.shirky.com/writings/situated_software.html?utm_source=Robin_Sloan_sent_me">an old blog post</a> by Clay Shirky: âSituated software, by contrast, doesnât need to be <span>personalizedâââ</span><wbr>it is personal from its inception.â)</p>
</li>
<li>
<p>The core of the app is a camera view with the now-familiar tap/press for photo/video affordance. This is an <a href="https://github.com/Awalz/SwiftyCam?utm_source=Robin_Sloan_sent_me">off-the-rack open source component</a>; what a gift. I&nbsp;donât think this project would have been possible without&nbsp;it.</p>
</li>
<li>
<p>Besides the app itself, not much is required: an AWS S3 bucket to hold the photos and videos, a couple of AWS Lambda functions to shuffle things around when new messages are uploaded. The back end is actually fairly <span>elegantâââ</span><wbr>which is, uh, not usually my <span>styleâââ</span><wbr>but, again, thatâs only because itâs so simple. Thereâs barely anything&nbsp;there.</p>
</li>
<li>
<p>I&nbsp;distributed the app to my family using TestFlight, and in TestÂ­Flight it shall remain forever: a cozy, eternal&nbsp;beta.</p>
</li>
</ul>
<p>In a better world, I&nbsp;would have built this in a day, using some kind of modern, flexible HyperCard for&nbsp;iOS.</p>
<p>In our actual world, I&nbsp;built it in about a week, and roughly half of that time was spent wrestling with different flavors of code-signing and identity proviÂ­sioning and I&nbsp;donât even know what. I&nbsp;burned some incense and threw some stones and the gods of Xcode allowed me to&nbsp;pass.</p>
<p>Our actual world isnât totally broken. I&nbsp;do not take for granted, not for one millisecond, the open source compoÂ­nents and sample code that made this project possible. In the 21st century, as long as youâre operating within the bounds of the state of the art, programÂ­ming can feel delightÂ­fully Lego-like. All you have to do is rake your fingers through the&nbsp;bin.</p>
<p>I&nbsp;know I&nbsp;ought to pay it forward and publish the code for my app. Even if it doesnât work for anyone else as-is, it might provide a helpful <span>guideâââ</span><wbr>one I&nbsp;would have been grateful to have. But the code is marbled with application-specific values, well-salted with authenÂ­tiÂ­caÂ­tion keys. This app is Entirely <span>Itselfâââ</span><wbr>not a framework, not a <span>templateâââ</span><wbr>and thatâs insepÂ­aÂ­rable from the spirit in which it was made. Which brings me&nbsp;to:</p>
<h2>Cooking at home<a name="cooking-at-home"></a></h2>
<p>For a long time, I&nbsp;have struggled to articÂ­uÂ­late what kind of programmer I&nbsp;am. Iâve been writing code for most of my life; I&nbsp;can make many interÂ­esting and useful things happen on computers. At the same time, I&nbsp;would not last a day as a profesÂ­sional software engineer. Leave me in charge of a critical database and you will return to a smoldering&nbsp;crater.</p>
<p>Building this app, I&nbsp;figured it&nbsp;out:</p>
<p>I&nbsp;am the programÂ­ming equivÂ­aÂ­lent of a home&nbsp;cook.</p>
<p>The exhorÂ­taÂ­tion âlearn to codeâ has its founÂ­daÂ­tions in market value. âLearn to codeâ is suggested as a way up, a way out. âLearn to codeâ offers economic leverage, profesÂ­sional transformation. âLearn to codeâ goes on your&nbsp;resume.</p>
<p>But letâs substiÂ­tute a different phrase: âlearn to cookâ. People donât only learn to cook so they can become chefs. Some do! But many more people learn to cook so they can eat better, or more affordably. Because they want to carry on a tradition. Sometimes they learn because theyâre bored! Or even because they enjoy spending time with the person whoâs teaching&nbsp;them.</p>
<p>The list of reasons to âlearn to cookâ overflows, and only a handful have anything to do with the marketplace. Cooking reaches beyond buying and selling to touch nearly all of human experience. It connects to domesÂ­ticity and curiosity; to history and culture; to care and&nbsp;love.</p>
<p>Well, itâs the 21st century now, and I&nbsp;suspect that many of the people you love are waiting inside the pocket computer you are never long without, so I&nbsp;will gently suggest that perhaps coding might connect the same&nbsp;way.</p>
<p>When you liberate programÂ­ming from the requireÂ­ment to be profesÂ­sional and <small>scalable</small>, it becomes a different activity altogether, just as cooking at home is really nothing like cooking in a commerÂ­cial kitchen. I&nbsp;can report to you: not only is this different activity rewarding in almost exactly the same way that cooking for someone you love is rewarding, thereâs another feeling, too, specific to this realm. I&nbsp;have struggled to find words for this, but/and I&nbsp;think it might be the crux of the whole&nbsp;thing:</p>
<p>This messaging app I&nbsp;built for, and with, my family, it wonât change unless we want it to change. There will be no sudden redesign, no flood of ads, no pivot to chase a userbase inscrutable to us. It might go away at some point, but that will be our decision. What <em>is</em> this feeling? Independence? Security? Sovereignty?</p>
<p>Is it simplyââ¦âthe feeling of being&nbsp;home?</p>
<p><em>Update, February 2022:</em> Two years later, my family still uses BoopSnoop every day. I&nbsp;have added one (1) feature, at my motherâs&nbsp;request.</p>
<p><em>Update, February 2023:</em> Yep, still using it every&nbsp;day!</p>
<p>February&nbsp;2020, Oakland</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[YouTube demonetizes public domain 'Steamboat Willie' video after copyright claim (309 pts)]]></title>
            <link>https://mashable.com/article/youtube-demontizes-public-domain-steamboat-willie-disney-copyright-claim</link>
            <guid>38877321</guid>
            <pubDate>Fri, 05 Jan 2024 09:43:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mashable.com/article/youtube-demontizes-public-domain-steamboat-willie-disney-copyright-claim">https://mashable.com/article/youtube-demontizes-public-domain-steamboat-willie-disney-copyright-claim</a>, See on <a href="https://news.ycombinator.com/item?id=38877321">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="article" data-autopogo="">
<p>Planning to <a href="https://mashable.com/article/infestation-88-steamboat-willy-horror-game" target="_self"><u>utilize</u></a> new public domain works featuring Mickey Mouse this year? Well, here's a case you should certainly pay attention to.</p><p>On Thursday, voice actor and YouTuber Brock Baker uploaded a new video, titled "Steamboat Willie (Brock's Dub),"&nbsp; to his YouTube channel with more than 1 million subscribers.</p>
<p>The video contains the entirety of the 1928 Disney animated short "Steamboat Willie," with Baker providing his own comedic voice overs and sound effects throughout the less than 8 minute long cartoon.</p><blockquote>
<a href="https://twitter.com/BrockBaker/status/1743009587475665205" target="_blank" rel="noopener" title="(opens in a new window)">
Tweet may have been deleted
</a>
</blockquote>
<p>According to Baker, shortly after uploading the clip though, YouTube <a href="https://twitter.com/BrockBaker/status/1743009587475665205" target="_blank" title="(opens in a new window)"><u>demonetized</u></a> the video, evidently on behalf of the erstwhile copyright owner, Disney. Baker also shared a screenshot to his X account showing the video was also being blocked from view in some territories as well.</p><blockquote>
<a href="https://twitter.com/BrockBaker/status/1743014398011101539" target="_blank" rel="noopener" title="(opens in a new window)">
Tweet may have been deleted
</a>
</blockquote>
<p>Prior to this year, nothing here would be out of the ordinary. Disney is very protective of its copyrighted works and would likely be especially so of a film like <em>Steamboat Willie</em> as it stars its most iconic character, Mickey Mouse.</p><p>However, <em>Steamboat Willie</em> along with that 1928 version of Mickey Mouse, <a href="https://mashable.com/article/mickey-mouse-steamboat-willie-disney-public-domain" target="_self"><u>entered the public domain</u></a> on January 1, 2024. This means that a video like Baker's should be completely fine for the YouTuber to not only create and distribute, but monetize as well.</p><p>Baker could likely make a fair use or parody defense for his dubbed version of <em>Steamboat Willie</em>, but as Duke University's Jennifer Jenkins, a professor of law teaching intellectual property, <a href="https://mashable.com/article/mickey-mouse-steamboat-willie-public-domain-so-far" target="_self"><u>told Mashable this week</u></a>, he doesn't even need to make that argument. Public domain works are considered public property.&nbsp;</p><p>"Reproducing and adapting the footage in whatever way you like is legit," Jenkins told Mashable.</p><p>As soon as "Steamboat Willie" became public domain earlier this week, multiple different creative projects using the iconic mouse were announced. Some of these creative works include a <a href="https://variety.com/2024/film/news/steamboat-willie-horror-film-mickey-mouse-public-domain-copyright-1235849861/" target="_blank" title="(opens in a new window)"><u>horror movie</u></a> and a <a href="https://mashable.com/article/infestation-88-steamboat-willy-horror-game" target="_self"><u>video game</u></a>.</p>
<p>So, what happened with Baker's video? Mashable has reached out to YouTube to find out more information and will update this post when we hear back. However, due to how quickly Disney's copyright claim was issued after Baker uploaded his "Steamboat Willie" video, it's likely the video was a victim of the automated Content ID process.</p><p>"Videos uploaded to YouTube are scanned against a database of audio and visual content that's been submitted to YouTube by copyright owners," reads YouTube's policy page on its <a href="https://support.google.com/youtube/answer/2797370?hl=en" target="_blank" title="(opens in a new window)"><u>Content ID</u></a> feature. "When Content ID finds a match, it applies a Content ID claim to the matching video."</p><p>If this is the case, YouTube nor Disney appear to have updated the database to remove works that have recently entered the public domain. And, if so, it seems that should certainly be programmed into the Content ID system as an automated process, much like the valid claims are.</p><p>Mashable will keep you updated on the status of Baker's video.</p>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CellLVM: A proof-of-concept LLVM to Excel spreadsheet compiler (202 pts)]]></title>
            <link>https://belkadan.com/blog/2023/12/CellLVM/</link>
            <guid>38876863</guid>
            <pubDate>Fri, 05 Jan 2024 08:10:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://belkadan.com/blog/2023/12/CellLVM/">https://belkadan.com/blog/2023/12/CellLVM/</a>, See on <a href="https://news.ycombinator.com/item?id=38876863">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-2023-12-celllvm">
		<p>A few weeks ago I posted this:</p>

<video src="https://belkadan.com/blog/2023/12/CellLVM/CellLVM.mp4" poster="https://belkadan.com/blog/2023/12/CellLVM/celllvm.jpg" preload="metadata" width="699" controls="">
	<a href="https://belkadan.com/blog/2023/12/CellLVM/CellLVM.mp4">(screen recording)</a>
</video>

<p>Which, if youâre not interested in watching a video right now, is a proof-of-concept LLVM to Excel spreadsheet compiler.<!--more--></p>

<h3 id="what">What.</h3>

<p>The night before, I was talking with friends about <a href="https://en.wikipedia.org/wiki/Comma-separated_values">CSV</a>, in particular joking about alignment charts and what counted as âtrueâ CSV. Someone pointed out that assembly, as conventionally printed, could be a CSV, to which I responded</p>

<blockquote>
  <p>ooh, asm in Excel nearly wraps around to being a good idea<br>
your labels are row references</p>
</blockquote>

<p>As I lay in bed, I realized that this was a better match than I initially thought. Forget the CSV part, row references are what let Excel do <em>computation.</em> And while you could make that work with assembly, thereâs an alternative thatâs a much better fit: LLVM.</p>

<h3 id="ssa-format">SSA Format</h3>

<p><a href="https://llvm.org/">LLVM</a> is a library for building compilers and related toolsâthe one used by Swift and Rust, actually.<sup id="fnref:gcc" role="doc-noteref"><a href="#fn:gcc" rel="footnote">1</a></sup> At its core is a stripped-down language also called LLVM, or maybe â<a href="https://llvm.org/docs/LangRef.html">the LLVM instruction set</a>â. Whatâs unique about this language, besides being designed as an intermediate stage for compiling higher-level languages, is that every local variable is assigned a value exactly once, as a simple expression that can only depend on the variables that come before it. This is called <a href="https://en.wikipedia.org/wiki/Static_single-assignment_form">static single-assignment form</a>.</p>

<p>My insight, which I donât think is new, is that Excel formulas work the same way. Any cell with a formula has that formula defined up front, and values flow through the spreadsheet based on the references set in the formulasâjust like SSA. So it should be possible, for operations supported by both LLVM and Excel, to rewrite an LLVM function as an Excel sheet that performs the same computation!</p>

<p>I went to sleep excited about that idea. I woke up and realized the primary problem with it: what about loops?</p>

<h3 id="phi-nodes">Phi Nodes</h3>

<p>In order for SSA to represent branching control flow (such as a conditional increment), it has to have some notion of history when the branches join back up. The conventional way to do this is with a special kind of expression called a <em>phi node,</em> which basically says âif we came from the true block, use x<sub>1</sub> as the value; if we came from the else block, use x<sub>2</sub> as the valueâ. The name âphiâ isnât short for anything; itâs apparently just meant to be close to âfiâ, as in âifâ backwards.<sup id="fnref:args" role="doc-noteref"><a href="#fn:args" rel="footnote">2</a></sup> This form works for switches as well (there are just more possible predecessors), and even loops: the predecessor of a loop body might be the entry of the loop, or it might be the last block in the <em>previous</em> time through the loop.</p>

<p>But spreadsheets donât have loops, do they? I searched around a bit and discovered I was incorrect: Excel spreadsheets <em>do</em> support loops, in the form of âiterative calculationâ. As long as the formulas converge on a fixed point within a certain number of steps, Excel will find it. So now I need to figure out how to encode loops in such a way that they do, in fact, converge.</p>

<p>At this point I got up from my bed and started messing around in Google Sheets. (It was a weekend, I didnât have to go to work.) And I hit on a solution: a variation of the classic âprogram counterâ used by real CPUs. If you keep track of the number of blocks youâve visited, counting repeats, then you always know what the âcurrentâ block is, and more importantly what the âpreviousâ block was. Which means you can implement phi nodes.</p>

<p>Hereâs what a phi expression looks like in Excel:</p>

<table>
  <tbody>
    <tr>
      <td><code>=CHOOSE(</code></td>
      <td>A phi is a choiceâ¦</td>
    </tr>
    <tr>
      <td><code>  XMATCH(</code></td>
      <td>of values based on a sourceâ¦</td>
    </tr>
    <tr>
      <td><code>    MAX(</code></td>
      <td>which is the most recent (max) PCâ¦</td>
    </tr>
    <tr>
      <td><code>      IF(B5=ROW(),C5,0),</code></td>
      <td>of the branch in row 5, if it was coming hereâ¦</td>
    </tr>
    <tr>
      <td><code>      IF(B10=ROW(),C10,0),</code></td>
      <td>the branch in row 10, if it was coming hereâ¦</td>
    </tr>
    <tr>
      <td><code>      C7-0.5),</code></td>
      <td>and the current row, 7, as a last resortâ¦</td>
    </tr>
    <tr>
      <td><code>    {C5,C10,C7-0.5}),</code></td>
      <td>which we get as an index with <code>XMATCH</code>â¦</td>
    </tr>
    <tr>
      <td><code>  B4,B8,B7)</code></td>
      <td>and <code>CHOOSE</code> the correct value</td>
    </tr>
  </tbody>
</table>

<p>Not pretty but it gets the job done. And with that, I knew it was possible, and I set off to build the compiler.</p>

<h3 id="the-compiler">The Compiler</h3>

<p>The actual compiler is a scant 150 lines of code, partly because it barely implements anything, but also because itâs not actually doing much work. All of the hard parts are in LLVM (and its wrapper, <a href="https://github.com/llvm-swift/LLVMSwift">LLVMSwift</a>, which <a href="https://belkadan.com/source/LLVMSwift/">I did have to fork</a>) and <a href="https://libxlsxwriter.github.io/">xslxwriter</a> (and <a href="https://github.com/damuellen/xlsxwriter.swift">its own wrapper</a>). Without these pre-existing libraries, doing this in a day would have been impossible.</p>

<p>The compiler makes two passes over a single LLVM function: one to assign rows to instructions and basic blocks, and one to translate each instruction into a formula, 1:1. There are only three relevant columns: a label with the instruction type, the value of each instruction, and the âprogram counterâ described above. <a href="https://belkadan.com/source/CellLVM/">You can read the whole thing if you want.</a></p>

<p>The result is a command-line tool that takes LLVM bitcode as input and produces an xlsx file as output. It throws an error if thereâs more than one function in the input, or if thereâs an operation it doesnât support (like, say, subtraction). But I do consider it a valid proof of concept! And a successful project, of courseâwhich is important when <a href="https://belkadan.com/blog/2021/07/Keyboard-Pants/">I canât spend much time on computers outside of work these days.</a></p>

<p><a href="https://docs.google.com/spreadsheets/d/1_K4gMtS0GGviPAIFkhGZmXXFXvuaAatxcx2ulM1XZXk/edit">The output from the video above is on Google Sheets</a>, though youâll have to make your own copy if you want to ârunâ it. It adds its two inputs, then doubles them until the result is greater than 50. (Which is about all the current implementation knows how to handle.)</p>

<h3 id="future-directions-alloca">Future Directions: alloca</h3>

<p>One thing thatâs <em>not</em> implemented in this proof-of-concept is alloca, i.e. local variables. This is both inconvenient, because thatâs the default for a non-optimized build, and a definite missing piece for <em>truly</em> compiling LLVM to a spreadsheet. The thing is, LLVMâs load and store instructions are <em>definitely</em> imperative, in a way that spreadsheets arenât. So to actually represent a memory location, weâd probably need to express a load as âthe value of the most recent store with a matching locationâ, similar to how we represented a phi as âone of several values based on the most recent basic blockâ. Thereâs probably some trickiness around loops as wellâmaybe the âprogram counterâ actually should count instructions and not just basic blocks, so âmost recentâ can include âbut not in my futureâ.</p>

<p>Once here, itâs still a jump to <em>arbitrary</em> memory allocation, but maybe not as big of one as it could be. As long as stores are broken up into individual fields, we could say that column H represents heap memory, and column I the instant when it was last modified. This would be a formula involving <em>every store instruction in the program,</em> but it might work. I havenât tried to work out the details, though.</p>

<h3 id="future-directions-a-call-stack">Future Directions: A Call Stack</h3>

<p>Another major omission is function calls. For non-recursive functions this is mostly a weird kind of branch/phi combination, but for recursive functions we have a problem: all our local SSA variables need to do double duty! I donât have a good idea of how to do this one short of using <em>columns</em> to represent stack frames. (In which a stack overflow would be running out of columns that have the right formulas.) That would also be neat because you could <em>see the call stack,</em> but I havenât thought through if it would actually work.</p>



		<p>
			This entry was posted on
			<a href="https://belkadan.com/blog/2023/12">December</a>
			28,
			
				<a href="https://belkadan.com/blog/2023">2023</a>
				and is filed under
				<a href="https://belkadan.com/blog/technical">Technical</a>.
			
			
			
				Tags:
				
					<a href="https://belkadan.com/blog/tags/compilers">Compilers</a>, 
				
					<a href="https://belkadan.com/blog/tags/llvm">LLVM</a>, 
				
					<a href="https://belkadan.com/blog/tags/spreadsheets">Spreadsheets</a>, 
				
					<a href="https://belkadan.com/blog/tags/source-code">Source code</a>
				
			
		</p>
	</div></div>]]></description>
        </item>
    </channel>
</rss>